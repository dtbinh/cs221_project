Journal Artificial Intelligence Research 34 (2009) 521567Submitted 09/08; published 04/09Anytime Algorithm Optimal Coalition Structure GenerationTalal RahwanSarvapali D. RamchurnNicholas R. JenningsTR @ ECS . SOTON . AC . UKSDR @ ECS . SOTON . AC . UKNRJ @ ECS . SOTON . AC . UKSchool Electronics Computer Science,University Southampton, Southampton, SO17 1BJ, U.K.Andrea GiovannucciAGIOVANNUCCI @ IUA . UPF. EDUSPECS Laboratory, Pompeu Fabra University, Barcelona, Spain.AbstractCoalition formation fundamental type interaction involves creation coherentgroupings distinct, autonomous, agents order efficiently achieve individual collective goals. Forming effective coalitions major research challenge field multi-agentsystems. Central endeavour problem determining many possiblecoalitions form order achieve goal. usually requires calculating value every possible coalition, known coalition value, indicates beneficial coalitionwould formed. values calculated, agents usually need findcombination coalitions, every agent belongs exactly one coalition,overall outcome system maximized. However, coalition structure generation problemextremely challenging due number possible solutions need examined,grows exponentially number agents involved. date, therefore, many algorithmsproposed solve problem using different techniques ranging dynamic programming, integer programming, stochastic search suffer major limitationsrelating execution time, solution quality, memory requirements.mind, develop anytime algorithm solve coalition structure generation problem. Specifically, algorithm uses novel representation search space,partitions space possible solutions sub-spaces possible compute upperlower bounds values best coalition structures them. boundsused identify sub-spaces potential containing optimal solutionpruned. algorithm, then, searches remaining sub-spaces efficientlyusing branch-and-bound technique avoid examining solutions within searched subspace(s). setting, prove algorithm enumerates coalition structures efficientlyavoiding redundant invalid solutions automatically. Moreover, order effectively testalgorithm develop new type input distribution allows us generate reliable benchmarks compared input distributions previously used field. Given newdistribution, show 27 agents algorithm able find solutions optimal0.175% time required fastest available algorithm literature. algorithmanytime, interrupted would normally terminated, still provide solutionguaranteed within bound optimal one. Moreover, guarantees providequality solution significantly better provided previous stateart algorithms designed purpose. example, worst case distribution given 25agents, algorithm able find 90% efficient solution around 10% time takes findoptimal solution.c2009AI Access Foundation. rights reserved.fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS1. IntroductionMulti-agent systems considered important rapidly expanding area research artificialintelligence. due natural fit many real-world scenarios, wide variety applications (Jennings, 2001). Now, typically, agents multi-agent system need organizedroles, relationships, authority structures govern behaviour clearlydefined (Horling & Lesser, 2005). Different organizational paradigms include hierarchies, teams,federations, many others, strengths weaknesses, making suitable problems, less suitable others. Among organizational paradigmsbecoming increasingly important coalitions. Coalitions distinguishedorganizations goal-directed short-lived; i.e. coalitions formed purposemind, dissolved purpose longer exists, cease suitdesigned purpose, profitability lost agents depart (Horling & Lesser, 2005). Another defining feature within coalition, agents coordinate activities orderachieve coalitions goal(s), coordination takes place among agents belonging differentcoalitions (except coalitions goals interact). Moreover, organizational structure withincoalition usually flat (although could coalition leader acting representativegroup whole).area coalition formation received considerable attention recent research,proved useful number real-world scenarios multi-agent systems. example,e-commerce, buyers form coalitions purchase product bulk take advantage pricediscounts (Tsvetovat, Sycara, Chen, & Ying, 2000). e-business, groups agents formedorder satisfy particular market niches (Norman, Preece, Chalmers, Jennings, Luck, Dang,Nguyen, V. Deora, Gray, & Fiddian, 2004). distributed sensor networks, coalitions sensorswork together track targets interest (Dang, Dash, Rogers, & Jennings, 2006). distributedvehicle routing, coalitions delivery companies formed reduce transportation costssharing deliveries (Sandholm & Lesser, 1997). Coalition formation also used informationgathering, several information servers form coalitions answer queries (Klusch & Shehory,1996).Generally speaking, coalition formation process viewed composedthree main activities outlined (Sandholm, Larson, Andersson, Shehory, & Tohme,1999):1. Coalition Value Calculation: context, number coalition formation algorithmsdeveloped determine potential coalitions actually formed.so, typically calculate value coalition, known coalition value,provides indication expected outcome could derived coalitionformed. Then, computed coalition values, decision optimalcoalition(s) form taken. way value calculated depends probleminvestigation.electronic marketplace, example, value coalition buyers calculateddifference sum reservation costs coalition membersminimum cost needed satisfy requests members (Li & Sycara, 2002).information gathering, coalition value designed represent measureclosely information agents domains related (Klusch & Shehory, 1996). casesagents rationality bounded due computational complexity, value coalition522fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONmay represent best outcome achieve given limited computational resourcessolving problem (Sandholm & Lesser, 1997).2. Coalition Structure Generation: computed coalition values, coalition structure generation (CSG) problem involves partitioning set agents exhaustivedisjoint coalitions maximize social welfare. partition called coalitionstructure. example, given set agents = {a1 , a2 , a3 }, exist five possible coalition structures: {{a1 } , {a2 } , {a3 }}, {{a1 } , {a2 , a3 }}, {{a2 } , {a1 , a3 }}, {{a3 } , {a1 , a2 }},{{a1 , a2 , a3 }}.usually assumed every coalition performs equally well, given coalition structurecontaining (i.e. value coalition depend actions non-members).settings known characteristic function games (CFGs), value coalition given characteristic function. Many, clearly all, real-world multi-agentproblems happen CFGs (Sandholm et al., 1999).Note optimal solution CSG problem one maximizes social welfare.Now, unlike cooperative environment agents mainly concerned maximizing social welfare, agents selfish environment concerned maximizingutility. This, however, mean CSG algorithm cannot appliedselfish multi-agent systems. designer systems usually concerned raising overall efficiency system and, many cases, correspondsmaximizing social welfare. end, designer needs design enforcementmechanism motivates agents join optimal coalition structure and, orderso, first needs know structure is. Moreover, knowing value optimalcoalition structure, knowing value within bound optimal, allowsdesigner evaluate relative effectiveness coalition structure currently formedsystem.3. Pay-off Distribution: determined coalitions formed, importantdetermine rewards agent get order coalitions stable.Here, stability refers state agents incentive deviate coalitions belong (or little incentive weaker types stability). desirableensures agents devote resources chosen coalition rathernegotiating with, moving to, coalitions. ensures coalitionslast long enough actually achieve goals. analysis incentives longstudied within realm cooperative game theory. context, many solutionsproposed based different stability concepts. include Core, Shapley value, Kernel (more details found paper Osborne & Rubinstein,1994). Moreover, schemes developed transfer non-stable pay-off distributionsstable ones keeping coalition structure unchanged (Kahan & Rapoport, 1984,provide comprehensive review stability concepts transfer schemes game theory).Note, however, agents cooperative environment incentive dissolvecoalition improves performance system whole. Therefore, pay-off distribution less important, main concern generating coalition structuremaximize social welfare.523fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSOne challenging activities coalition structure generation,ndue number possible solutions grows exponentially (in O(nn ) (n 2 )number agents involved (n)). specifically, proved finding optimalcoalition structure NP-complete (Sandholm et al., 1999). combat complexity, numberalgorithms developed past years, using different search techniques (e.g.dynamic programming, integer programming, stochastic search). algorithms, however,suffer major limitations make either inefficient inapplicable, particularly givenlarger numbers agents (see Section 2 details).motivates aim develop efficient algorithm searching space possiblecoalition structures. detail, given CFG setting, wish develop algorithmsatisfies following properties:1. Optimality: run completion, algorithm must always able return solutionmaximizes social welfare.2. Ability prune: algorithm must able identify sub-spaces potentialcontaining optimal solution pruned search space.property critical given exponential nature problem (e.g. given 20 agents,number possible coalition structures 51,724,158,235,372).3. Discrimination: algorithm must able verify, search, foundoptimal solution, instead proceeding search hope better solutionfound.4. Anytime: algorithm able quickly return initial solution, improvequality solution searches space, finds optimal one.particularly important since agents might always sufficient time runalgorithm completion, especially given exponential size search space. Moreover,anytime makes algorithm robust failure; execution stoppedalgorithm would normally terminated, would still provide agentssolution better initial solution, intermediate one.5. Worst Case Guarantees: algorithm able provide worst-case guaranteesquality solution. Otherwise, generated solution could always arbitrarily worseoptimal one. guarantees important trading solutionquality search time. example, quality current solution knownworse than, say, 95% optimal one, still significant portionspace left searched, agents might decide worthwhile carrysearch. Obviously, better guarantees, likely agentsdecide stop searching better solution.research aims outlined above, paper makes following contributions stateart coalition structure generation:1. provide new representation space possible coalition structures. representation partitions space much smaller, disjoint sub-spaces explored524fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONindependently find optimal solution. opposed widely-used representation (Sandholm et al., 1999; Dang & Jennings, 2004), coalition structurescategorized based number coalitions contain, representation categorizescoalition structures sub-spaces based sizes coalitions contain. keyadvantage representation that, immediately scanning input algorithm(i.e. coalition values), compute average value coalition structures withinsub-space. Moreover, scanning input, also compute upper lowerbound value best coalition structure could found subspaces. Then, comparing bounds, possible identify sub-spacespotential containing optimal solution pruned. second majoradvantage representation allows agents analyse trade-offsize (i.e. number coalition structures within) sub-space improvementmay bring current solution virtue bounds. Hence, rather constrainingsolution fixed sizes, Shehory Kraus (1998) do, agents using representationmake informed decision sizes coalitions choose (sincesub-spaces defined sizes coalitions within coalition structures).2. develop novel, anytime, integer-partition based algorithm (called IP) coalitions structure generation uses representation discussed above, provides high guarantees quality solutions quickly. Moreover, IP guaranteed returnoptimal solution run completion.3. prove algorithm able enumerate coalition structures efficiently avoidingredundant invalid solutions. enumeration technique also allows us apply branchand-bound reduce amount search needed.4. many CSG algorithms literature evaluated using input distributionsdefined Larson Sandholm (2000), prove distributions biasedfar CSG problem concerned. Moreover, propose new distribution provetackles problem, making much suitable evaluating CSG algorithmsgeneral.5. evaluating time required return optimal solution, compare IPfastest algorithm guaranteed return optimal solution (i.e. Improved Dynamic Programming (IDP) algorithm Rahwan & Jennings, 2008b). comparison shows IPsignificantly faster. detail, IP empirically shown find optimal solution0.175% time taken IDP given 27 agents.6. benchmark IP previous anytime algorithms (Sandholm et al., 1999; Dang & Jennings, 2004), show provides significantly better guarantees qualitysolutions generates time. detail, empirically show that, various numbers agents, quality initial solution (i.e. solution found scanninginput) usually guaranteed least 40% optimal, opposed n2 (which meansexample, 10% 20 agents 8% 25 agents) Sandholm et al.s algorithmDang Jenningss algorithm. standard distributions evaluatealgorithm, also find usually terminates searching minute portions525fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSsearch space generates near-optimal solutions (i.e. > 90% optimal) searchingeven smaller portions search space (i.e. average around 0.0000002% searchspace). tremendous improvement aforementioned algorithms couldguarantee solutions higher 50% optimal searching whole space.Note significantly revised extended version previous papers (Rahwan, Ramchurn, Dang, & Jennings, 2007a; Rahwan, Ramchurn, Giovannucci, Dang, & Jennings, 2007b).Specifically, provide paper comprehensive review available algorithmsCSG literature. also provide detailed analysis IP algorithm, describe pseudo codefunctions used IP, prove correctness function searches differentsub-spaces. mathematical proof also provided regarding way size sub-space computed. Moreover, question validity standard value distributions usedliterature, propose new value distribution (called NDCS) suitable evaluatingCSG algorithms. Finally, benchmark algorithm improved dynamic programmingalgorithm (IDP) Rahwan Jennings (2008b) (instead standard DP algorithm).remainder paper organized follows. Section 2, describe algorithmscurrently available solving coalition structure generation problem, discussrelative advantages limitations. Section 3, present novel representation searchspace and, Section 4, present integer-partition based algorithm (IP), showing identifies sub-spaces pruned, searches remaining ones withoutgoing invalid redundant coalition structures, using branch-and-bound technique. Section 5 provides empirical evaluation algorithm, benchmarks current stateart CSG literature. Section 6 concludes paper outlines future work. alsoprovide, appendices, summary main notations employed, well detailed proofstheorems provided paper.2. Related WorkPrevious algorithms designed coalition structure generation problemclassified two main categories:Exact algorithms1 using heuristics, integer programming, dynamic programming.Non-exact algorithms using genetic algorithms, limiting search space way.Next, discuss advantages limitations algorithms fall withinclasses. Throughout paper, denote n number agents, ={a1 , a2 , , } set agents. Moreover, define order agents follows:ai , aj A, ai < aj iff < j, ai = aj iff = j. words, have: a1 < a2 < < .Finally, denote v(C) value coalition C, V (CS) value coalition structure CS.2.1 Exact Algorithms Coalition Structure Generationexact algorithms coalition structure generation. developed distinguished based whether use dynamic programming heuristics.1. Recall exact algorithm one always returns optimal solution exists (Evans & Minieka, 1992).526fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONfollows, outline features discuss relate ultimate goal developingefficient, anytime, optimal coalition structure generation algorithm.2.1.1 DYNAMIC P ROGRAMMINGconsider computationally efficient algorithms designed return optimal solution. Noteemphasis, here, providing guarantee performance algorithm worstcase scenarios. context, Yeh (1986) developed dynamic programming algorithm solvecomplete set partitioning problem. similar algorithm later developed Rothkopf,Pekec, Harstad (1995) solve winner determination problem combinatorial auctions.algorithms directly applied find optimal coalition structures, since problemsoriginally designed solve similar CSG problem.2 Also notealgorithms use basically technique and, therefore, computationalcomplexity. Thus, throughout paper, distinguish them, referdynamic programming (DP) algorithm. biggest advantage algorithm runsO(3n ) time (Rothkopf et al., 1995). significantly less exhaustive enumerationcoalition structures (which O(nn )). fact, DP polynomial size input.input includes 2n 1 values, following holds:O(3n ) = O(2(log2 3)n ) = O((2n )log2 3 )Therefore, computational complexity algorithm O(y log2 3 ), numbervalues input. While, one hand, algorithm literature guaranteedfind optimal coalition structure polynomial time (in size input), hand,main limitation DP generate solutions anytime, large memoryrequirement. Specifically, requires maintaining three tables memory containing 2n entrieseach.recently, Rahwan Jennings (2008b) developed Improved Dynamic Programmingalgorithm (called IDP) performs fewer operations requires less memory DP (e.g. given25 agents, performs 38.7% operations, requires 66.6% memory worstcase, 33.3% best). However, IDP return solutions anytime. mentioned earlier,undesirable, especially given large numbers agents, time required returnoptimal solution might longer time available agents.2.1.2 NYTIME LGORITHMS W ITH W ORST C ASE G UARANTEESSandholm et al. (1999) first introduce anytime algorithm coalition structure generation establishes bounds quality solution found far. view coalitionstructure generation process search call coalition structure graph (see Figure1). undirected graph, every node represents possible coalition structure. nodescategorized n levels, noted LV1 , , LVn level LVi contains coalition structurescontain coalitions. arcs represent mergers two coalitions followed upwards,splits coalition two coalitions followed downwards.2. involve partitioning set elements subsets based weights associatedevery possible subset.527fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSFigure 1: coalition structure graph 4 agents.Sandholm et al. (1999) proved that, order establish bound quality coalition structure, sufficient search first two levels coalition structure graph.case, bound would equal n, number searched coalition structures would2n1 . also proved bound tight; meaning better bound existssearch. Moreover, proved search algorithm (other onesearches first two levels) establish bound searching 2n1 coalition structuresfewer. because, order establish bound, one needs go subset coalition structures every coalition appears least once.3 implies smallest subsetcoalition structures searched bound established one everycoalition appears exactly once, subset occurs one containingcoalition structures belong first two levels graph.first two levels searched, additional time remains, would desirablelower bound search. Sandholm et al. (1999) developed algorithmpurpose. Basically, algorithm searches remaining levels one one, starting bottomlevel, moving upwards graph. Moreover, Sandholm et al. also proved boundimproved whenever algorithm finishes searching particular level. interestingthat, searching bottom level (which contains one coalition structure) bound dropshalf (i.e. = n2 ). Then, roughly speaking, divisor bound increases one every time3. Otherwise, coalition appear coalition structures, value coalition happened arbitrarily better value coalitions, every coalition structure containing wouldarbitrarily better not.528fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONtwo levels searched, seeing one level helps little (Sandholm et al.,1999).4algorithm advantage anytime, able provide worst case guarantees quality solution found far. However, algorithm two major limitations:algorithm needs search entire search space order boundbecome 1. words, return solution guaranteed optimal, algorithmsimply performs brute-force search. discussed Section 1, intractable evensmall numbers agents.bounds provided algorithm might large practical use. example,given n = 24, given algorithm finished searching levels LV1 , LV2 , LV24(which contain 8,388,609 coalition structures) bound would = n/2 = 12.means that, worst case, optimal solution 12 times better currentsolution. words, value current solution guaranteed worse8.33% value optimal solution. that, order reduce bound= n/4, four levels need searched, namely LV23 , LV22 , LV21 , LV20 .words, searching additional 119,461,563 coalition structures, valuesolution guaranteed worse 16.66% optimal value. Similarly,reduce bound = n/6, algorithm needs search additional 22,384,498,067,085coalition structures guarantee value solution worse 25%optimal value. Moreover, guarantee go beyond 50% entire spacesearched.Given limitations Sandholm et al.s (1999) algorithm, Dang Jennings (2004) developedanytime algorithm also establish bound quality solution found far,uses different search method. detail, algorithm starts searching top twolevels, well bottom one (as Sandholm et al.s algorithm does). that, however, insteadsearching remaining levels one one (as Sandholm et al. do), algorithm searchesspecific subsets remaining levels. Figure 2 compares performance algorithms, and, looking figure, see neither two algorithms significantlyoutperforms other.Note, however, algorithms meant case entire spaceeventually searched. enough time perform search,would used dynamic programming algorithm, performs search much quicker.Instead, algorithms mainly developed cases space largefully searched, even dynamic programming algorithm used.discussed two algorithms use similar techniques (i.e. Sandholm et al., 1999Dang & Jennings, 2004), discuss different approach also provide solutions anytime, establish worst-case guarantees quality solution. involves usestandard problem solving techniques rely general purpose solvers. detail, coalition structure generation problem formulated binary integer programming problem (orn n4. precise, depending number agents level searched, bound either= 2, 3, , n. However, ease discussion without loss generality, assume throughoutnpaper bound simply.529fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSFigure 2: Given 24 agents, figure shows, log scale, comparison bound provided Sandholm et al. (1999) provided Dang Jennings (2004), givendifferent numbers searched coalition structures.0-1 integer programming problem), since variable representing possible coalition eithertake value 1 (indicating belongs formed coalition structure) 0 (indicatingdoesnt). Specifically, given n agents, integer model CSG problem formulatedfollows:Maximize2nPv(Ci ) xii=1subject Z X = eTX {1, 0}nZ n 2n matrix zeros ones, X vector containing 2n binary variables,eT vector n ones. detail, every line Z represents agent, every columnrepresents possible coalition. X, element xi = 1 corresponds coalition Ciselected coalition structure. first constraint ensures selected coalitionsdisjoint exhaustive.integer programming problem typically solved applying linear relaxation coupledbranch-and-bound (Hillier & Lieberman, 2005). However, main disadvantage approach huge memory requirement, make applicable small numbers agents(see Section 5 details).530fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATION2.2 Non-Exact Algorithms Coalition Structure Generationalgorithms provide guarantees finding optimal solution, provideworst-case guarantees quality solutions. Instead, simply return good solutions.However, fact return solution quickly, compared algorithms,often makes class algorithms applicable, particularly given larger numbers agents.Generally speaking, long regularity search space (i.e., evaluationfunction arbitrary), genetic algorithms potential detect regularity hencefind coalition structures perform relatively effectively. end, Sen Dutta (2000)developed genetic algorithm coalition structure generation. algorithm starts initialset candidate solutions (i.e. set coalition structures) called population, gradually evolves towards better solutions. done three main steps: evaluation, selection,re-combination. detail, algorithm evaluates every member current population,selects members based evaluation, constructs new members selected onesexchanging modifying contents. details implementation foundpaper Sen Dutta (2000). main advantage algorithm return solutionsanytime, scales well increase number agents. However, mainlimitation solutions provides guaranteed optimal, even guaranteedwithin finite bound optimal. Moreover, even algorithm happens find optimalsolution, possible verify fact.Another algorithm belongs class algorithms one developed ShehoryKraus (1998). algorithm greedy operates decentralized manner. heuristicspropose (in order reduce complexity finding optimal coalition structure) involveadding constraints size coalitions allowed formed. Specifically,coalitions size q < n taken consideration. main advantage algorithmtake consideration overlapping coalitions.5 Moreover, Shehory Kraus provesolution provide guaranteed within bound optimal solution. However,optimal, mean best possible combination permitted coalitions. hand,algorithm provides guarantees quality solutions compared actual optimalcould found coalitions taken consideration.summarize, discussed earlier, main limitation algorithms provideguarantees solutions generate search terminate. However,algorithms scale well increase number agents, making particularlysuitable cases number agents large algorithm exponentialcomplexity executed time.discussing different approaches coalition structure generation problem,see approaches suffers major limitations, making either inefficientinapplicable. motivates aim develop efficient CSG algorithms appliedwider range problems, taking consideration objectives outlined Section1. mind, first present Section 3 novel representation search space,present Section 4 novel algorithm belongs first class aforementionedclassification. show, algorithm avoids limitations exist state-of-the-art5. solution containing overlapping coalitions means agents may participate one coalitiontime.531fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSalgorithms belonging class, meets design objectives placed Section 1 CSGalgorithms.3. Search Space Representationsection, describe novel representation search space (i.e. space possiblecoalition structures). Recall space representation employed existing anytime algorithms undirected graph (see Figure 1 example), vertices represent coalitionstructures (Sandholm et al., 1999; Dang & Jennings, 2004). representation, however, forcespossible solutions explored order guarantee optimal one found. Giventhis, believe ideal representation search space allow computation solutions anytime, establishing bounds quality, allow pruning spacespeed search. objective mind, section describe representation. particular, supports efficient search following reasons. First, partitionsspace smaller, independent, sub-spaces identify upper lower bounds,thus, compute bound solutions found search. Second, prunesub-spaces since identify ones cannot contain solution betterbest one found far. Third, since representation pre-determines size coalitions presentsub-space, agents balance preference certain coalition sizes costcomputing solution sub-spaces. Next, formally define representationsearch space, describe algebraic properties, describe compute worst case boundsquality solution representation allows us generate.3.1 Partitioning Search Spacepartition search space P defining sub-spaces contain coalition structuressimilar according criterion. particular criterion specify based integerpartitions number agents.6 Recall integer partition n multiset positiveintegers add exactly n (Andrews & Eriksson, 2004). example, given n = 4,five distinct partitions are: [4], [3, 1], [2, 2], [2, 1, 1], [1, 1, 1, 1].7 easily showndifferent ways partition set n elements directly mapped integer partitionsn, parts integer partition correspond cardinalities subsets (i.e.sizes coalitions) within set partition (i.e. coalition structure). instance, coalitionstructures {{a1 , a2 }, {a3 }, {a4 }} {{a4 , a1 }, {a2 }, {a3 }} mapped integer partition[2, 1, 1] since contain one coalition size 2, two coalitions size 1. defineaforementioned mapping function F : P G, G set integer partitions n.Thus, F defines equivalence relation P CS CS 00 iff F (CS) = F (CS 00 ) (i.e.sizes coalitions CS CS 00 ). Given this, pre-image8integer partition G, noted PG = F 1 [{G}], contains coalition structures correspond6. criteria could developed partition space smaller sub-spaces, one developallows us choose coalition structures certain properties show later.7. presentation clarity, square brackets used throughout paper (instead curly ones) distinguishmultisets sets.8. Recall pre-image inverse image G G F : P G subset P defined F 1 [{G}] ={CS P|F (CS) = G}.532fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONinteger partition G. Every pre-image represents sub-space representation.implies number sub-spaces representation numberpossible integer partitions, grows exponentially n. number, however, remainsinsignificant compared number possible coalitions coalition structures (e.g., given24 agents, number possible integer partitions 1575, number possiblecoalitions 16777215, number possible coalition structures nearly 4.4 1017 ).categorize sub-spaces levels based number parts within integer partitions. Specifically, level Pi = {PG : |G| = i} contains sub-spaces correspondinteger partition parts (see Figure 3 example 4 agents).9 follows, showcompute bounds sub-spaces (PG : G G) representation.Figure 3: example representation search space given 4 agents.3.2 Computing Bounds Sub-spacessub-space PG , possible compute upper lower bound valuebest10 coalition structure could found it. end, let Ls list coalitionssize s, let maxs , mins , avgs , maximum, minimum, average valuecoalitions Ls respectively. Moreover, givenQ integer partition G, let TG Cartesian productlists Ls : G. is, TG = sG (Ls )G(s) , G(s) multiplicity9. Note levels representation basically appear coalition structure graph,except coalition structures within level categorized sub-spaces. words, coalitionstructures belong sub-spaces Pi belong LVi .10. Throughout paper, coalition structure described best highest value.533fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSG. example, given G = [5, 4, 4, 4, 1, 1], TG = (L5 )1 (L4 )3 (L1 )2 . NoteTG contains many combinations coalitions considered invalid coalition structures.coalitions within combinations may overlap. example, T[2,1,1]contains following combination, {{a1 , a2 }, {a1 },{a3 }}, valid coalition structureagent a1 appears two coalitions. Now, consider value element (i.e.combination coalitions) TG sum values coalitions element,maximumvalue element TG take, denoted AXG , computed follows:PAXG = sG maxs G(s). Based this, easy demonstrate AXG upperbound value best coalition structure PG (since PG subset TG ).Similarly, minimumvalue element TG take, denoted ING , computedPfollows: ING =sG mins G(s). Although could intuitively considered lowerbound value best coalition structure (i.e. solution) PG , show actuallypossible compute higher (i.e. better) lower bound ING .detail, let AV GG average value coalition structures PG . Then,AV GG would lower bound value best coalition structure PG (since averagealways greater than, equal to, minimum). key point note, here, computeAV GG without go coalition structures PG . Instead, computesimply summing averages coalition lists (see Theorem 1), averagescomputed immediately scanning input, significantly smaller spacepossible coalition structures.Theorem 1. Let G = [g1 , , gi , , g|G| ] integer partition, let AV GG averagevalues coalition structures PG . Also, let avggi average valuescoalitions Lgi . Then, following holds:AV GG =|G|Xavggii=1Proof. See Appendix B.described novel representation search space, present (in following section)anytime algorithm uses representation search possible coalitions structureseventually find optimal one.4. Solving Coalition Structure Generation ProblemAssuming value every coalition C given characteristic functionv(C) R,Pvalue every coalition structure given function V (CS) = CCS v(C), goalsearch set possible coalition structures, noted P, order find optimalcoalition structure computed as:CS = arg max V (CS)CSP(1)given v(C) C 2A \{}. Note that, section, terms coalition structuresolution used interchangeably.Basically, novel anytime Integer-Partition based algorithm (which call IP) consistsfollowing two main steps:534fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATION1. Scanning input order compute bounds (i.e. AXG AV GG ) every subspace PG so, (at small cost):(a) find best coalition structures within particular sub-spaces.(b) prune sub-spaces based upper-bounds.(c) establish worst-case bound quality best solution found far.2. Searching within remaining sub-spaces techniques use allow us to:(a) avoid making unnecessary comparisons coalitions generate valid coalitionstructures (i.e. contain disjoint coalitions).(b) avoid computing coalition structure once.(c) apply branch-and-bound reduce amount search done.following sub-sections describe aforementioned steps detail. end,use CS 0 denote best coalition structure found far, G 0 G denote integerpartitions represent sub-spaces searched.4.1 Scanning Inputinput coalition structure generation problem value associated coalition,i.e. v(C) C 2A \{}. One way representing input use table containingevery coalition along value. Another way agree ordering coalitions,use list containing values ordered coalitions (i.e. first value listcorresponds first coalition, second value corresponds second coalition, on).use latter representation since require maintaining coalitionsmemory. detail, assume input given follows: v(Ls ) {1, 2, . . . , n},v(Ls ) list containing values coalitions size s. Moreover, assumecoalitions Ls ordered lexicographically. example, coalition {a1 , a2 , a4 }elements ordered according indices, coalition found {a1 , a2 , a3 }{a1 , a3 , a4 } list L3 (this depicted Figure 4). ordering easily generatedusing techniques used Rahwan Jennings (2007). Next, describe individualsteps algorithm depicts scanning process (see Algorithm 1).first, scan value one coalition size n (i.e. grand coalition). wouldvalue coalition structure P[n] (which sub-space P1 ). that,scan values coalitions size 1 (i.e. singleton coalitions), summingvalues, get value coalition structure P[1,1,...,1] (which sub-spacePn ). point (step 1), possible compute best coalition structure found far (i.e.CS 0 ).searched levels P1 Pn , show search level P2low cost scanning input. end, let G 2 = {G G : |G| = 2} setinteger partitions contain two parts each. Then, result assumed orderingb coalition structure CS = {C, C}b alwaysinput, two complementary coalitions C Cdiametrically positioned coalition lists L|C| L|Cb| , happens even |C| = |C 0 |.example, given 6 agents, coalitions {a1 } {a2 , a3 , a4 , a5 , a6 } diametrically positioned535fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSAlgorithm 1 : scanAndSearch() scan input, generate initial solutions bounds.Require: n, {v(Ls )}s{1,2,...,n}1: CS 0 arg maxCS{ {a1 ,...,an }, {{a1 },...,{an }} } V (CS)2: = 1 b n2 c3:sb n4:= sb {if cycling list.}5:end = b|v(Ls )|/2c6:else7:end = |v(Ls )|8:end9:Set maxs , maxsb, vmax , set sums , sumsb 010:x = 1 end {cycle lists v(Ls ) v(Lsb).}11:xb |v(Ls )| x + 112:v v(Ls )x , vb v(Lsb)xb {extract element x, xb v(Ls ), v(Lsb).}13:vmax < v + vb14:vmax v + vb15:xmax = x {record index v(Ls ) v located.}16:end17:maxs < v18:maxs v {record maximum value v(Ls ).}19:end20:maxsb < vb21:maxsb vb {record maximum value v(Lsb).}22:end23:sums sums + v , sumsb sumsb + vb24:end25:xbmax |v(Ls )| xmax + 126:V (CS 0 ) < V ({Lxs max , Lxsbbmax })27:CS 0 {Lxs max , Lxsbbmax } {update best coalition structure found far.}28:end29:avgs sums /|v(Ls )| , avgsb sumsb/|v(Lsb)| {compute averages.}30: end31: G 0 G \ G 232: G G 0 {compute upper lower bounds sub-space G 0 .}P33:AXG P sG maxs G(s)34:AV GG sG avgs G(s)35: end36: U B max[ V (CS 0 ), maxGG 0 [M AXG ] ]37: LB max[ V (CS 0 ), maxGG 0 [AV GG ] ]38:G 0 prune(G 0 , {M AXG }GG 0 , LB ){prune sub-spaces upperbound lower LB .}39:min[ n/2 , U B /V (CS 0 ) ] {compute worst-case bound V (CS 0 ).}40:return CS 0 , , {maxs }s{1,...,n} , G 0 , {M AXG }GG 0 , {AV GG }GG 0536fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONlists L1 L5 respectively, coalitions {a1 , a2 , a3 } {a4 , a5 , a6 } diametricallypositioned list L3 (see Figure 4 example 6 agents).Figure 4: example assumed ordering coalition lists.Based this, every integer partition G = [g1 , g2 ] G 2 , compute valuescoalition structures PG simply summing values coalitions scan lists v(Lg1 )v(Lg2 ), starting different extremities list. lists scanned (steps10 24), possible obtain two values sum maximized. Moreover,possible obtain indices lists values located (see xmax xbmaxcomputed steps 15 25 respectively). Then, obtaining indices, knowLg1 Lg2 find two coalitions belong best coalition structure P[g1 ,g2 ] (thiscomes fact position value v(Ls ) : {1, ..., n} exactly positioncorresponding coalition Ls ).Note, however, input includes v(Lg1 ) v(Lg2 ) (i.e. include Lg1Lg2 ). reason, algorithm required return coalition C given positionordered list L|C| . Rahwan Jennings (2007) developed polynomial-time algorithmexactly that. Therefore, use find required coalitions compose best coalitionstructure P{g1 ,g2 } (see steps 26 27).11scanning v(Lg1 ) v(Lg2 ), also compute maxg1 maxg2 (steps 17 22),well avgg1 avgg2 (step 29). Note that, Algorithm 1, scan v(Ls ) v(Lns ){1, . . . , b n2 c} implies maxs avgs computed {1, . . . , n}. Alsonote whole process linear size input (i.e. O(y) = 2n 1 sizeinput).11. Lxs mean extract element position x Ls .537fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGScomputed maxs avgs every size s, compute upper lower boundsevery sub-space (as steps 32 34). using bounds, possible compute upperbound U B lower bound LB value optimal coalition structure (see steps 3637). Hence, every sub-space PG upper bound AXG < LB pruned straightaway. prune function (used step 38) implemented Algorithm 2.Algorithm 2 :prune(G 0 , {M AXG }GG 0 , ) prune sub-spaces.1: G G 02:AXG {if upper bound PG lower .}3:G 0 G 0 \ G {remove G.}4:end5: end6: return G 0Another advantage scanning procedure allows us compute worst-case boundBvalue CS 0 follows: = min( n2 , V U(CS0 ) ) (see step 39). comes factSandholm et al. (1999) proved value best coalition structure levels LV1 , LV2LVn (corresponding P1 , P2 , Pn respectively) within bound n2 optimal.far, scanning input, calculated maxs avgs {1, . . . , n},searched levels P1 , P2 , Pn , calculated AXG AV GG sub-spaceswithin remaining levels (i.e. P3 , ..., Pn1 ), pruned sub-spaces,established worst-case bound quality best solution found far. Moreover,possible specify bound 1 within solution acceptable. detail,best solution found far fits within specified bound (i.e. ) searchrequired. Otherwise, sub-spaces pruned (if any) must searched.Next, specify search done.4.2 Selecting Searching Sub-SpaceGiven set sub-spaces left scanning input, select sub-space searched,find best coalition structure it. that, prune remaining sub-spacesupper bound lower best value found far. process selecting, searching,pruning, repeated either following termination conditions reached:best coalition structure found far fits within specified bound .remaining sub-spaces either searched pruned.seen Algorithm 3. Basically, algorithm works follows. sub-space PG00selected searched (step 2).12 PG00 searched (step 3), removed setremaining sub-spaces (step 4). that, check whether CS 0 modifiedsearch (step 5), and, case, every sub-space upper bound lower V (CS 0 )pruned (step 6).13 U B updated steps 8 9 respectively, current12. step 2, actually select integer partition, implies corresponding sub-section searched.13. Checking whether CS 0 belongs PG00 easily done checking whether sizes coalitions CS 0match parts G00 .538fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONbest solution fits within specified bound returned (steps 10 11). Otherwise,whole process repeated given remaining sub-spaces (if any). follows,elaborate sub-space selection strategy sub-space search algorithm sincekey parts algorithm.Algorithm 3 :searchSpace() search, prune, remaining sub-spaces.Require: G 0 , {M AXG }GG 0 , A,1: G 0 6=2:Select G00 {select integer partition represents next sub-spacesearched.}3:4:CS 0 searchList(G00 , 1, 1, A, CS 0 , CS) {search within PG00 update CS 0 .}G 0 G 0 \ G00{remove PG00 list sub-spaces yetsearched.}5:6:CS 0 PG00 {If CS 0 modified searching PG00 .}G 0 prune(G 0 , {M AXG }GG 0 , V (CS 0 )){prune sub-spacesupper bounds lower V (CS 0 ).}7:8:endU B max[ V (CS 0 ), maxGG 0 [M AXG ] ] {update upper bound valueoptimal coalition structure(s).}9:10:11:12:13:14:B0min[ V U(CS0 ) , ] {update worst-case bound V (CS ).}{if CS 0 within specified bound optimal.}return CS 0endendreturn CS 04.2.1 ELECTING UB -S PACEeasily seen that, unless search sub-spaces upper bound greaterV (CS 0 ), cannot verify CS 0 optimal solution. implies remains greater1 following sub-spaces searched: {PG : AXG V (CS )}. doneselecting next sub-space searched using following selection rule:Select G = arg max(M AXG )GG 0result selection strategy, sub-spaces upper bound lower V (CS )searched constitute significant portion search space (see Section 5.3details). Another result always beneficial search sub-space, evensub-space contain better solution one found far.selection strategy ensures U B reduced whenever sub-space searched, improvesworst-case guarantee quality current best solution.Note selection rule mainly cases optimal solution sought. casenear-optimal solution bound > 1 specified (e.g., = 1.05 meanssolution sought needs value least 95% optimal one),539fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSselection rules may used. example, one could select search smallest sub-spacecould, potentially, give value greater equal UB (hoping find acceptable solutionleast amount search). expressed as:Select G =arg min(|PG |)GG 0 :U BG UB|PG | size (i.e. number coalition structures in) PG . specifically, |PG |computed follows:Theorem 2. Let G = [g1 , . . . , g|G| ] integer partition, let |PG | number coalitionstructures PG . Moreover, let Csn binomial coefficient,14 let E(G) underlyingset G.15 Then, following holds:n(g1 +...+g|G|1 )1Cgn Cgng. . . Cg|G|2Q|PG | = 1sE(G) G(s)!Proof. See Appendix C.key point note that, given representation, specify cases computing optimal solution would costly and, given this, modify selection ruleaccordingly speed search.Another advantage able control sub-spaces searched agentschoose types coalition structures build according computational resourcesprivate preferences. example, argued computation time could reducedlimit size coalitions formed (Shehory & Kraus, 1998). However,costly, self-imposed constraint since possibly means neglecting number highly efficientsolutions. Instead, using IP, possible determine, ex-ante (i.e. performingsearch), sub-spaces promising according upper lower bounds. Thereforecomputation time focused sub-spaces gains traded-offcomputation time.cases, agents may need form q coalitions (Shehory & Kraus, 1995).example, may need perform q tasks therefore need divide q teams performtasks separately. Moreover, may wish coalitions maximum size zmay certain constraints amount resources available coalition. usingrepresentation, preferences naturally expressed search directed fitpreferences transparently. Formally, search space easily redefined follows:G 00 = {G G : |G| = g G : |g| z}cases agents express preferences coalition structures certainsizes, now, priori, balance preferences quality solutions14. Recall binomial coefficient represents number possible combinations size taken n elements,n!computed follows: Csn = k!(nk)!, n! factorial n.15. Recall underlying set E(G) multiset G subset G element G appearsE(G). example, {1, 2} underlying set [1, 1, 2].540fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONobtained. able determine worst-case bound optimalU Bsearch given sub-space generate (i.e. AVGG ). next describe searchchosen sub-space.4.2.2 EARCHING UB -S PACEGiven integer partition G = [g1 , g2 , , g|G| ] G, need cycle coalitionstructures belong PG order find best one. Here, without loss generality,assume g1 g2 , g|G| . Perhaps obvious way performing cyclationffprocess shown Figure 5. Here, variable CS = C1 , C2 , , C|G| used cycle thoughcoalition structures PG follows. First, C1 assigned one coalitions Lg1 .that, C2 used cycle Lg2 coalition overlap C1 found.that, C3 used cycle Lg3 coalition overlap {C1 , C2 } found.repeated every Ck CS assigned coalition Lgk . case, CS wouldvalid coalition structure belonging PG . value coalition structure calculatedcompared maximum value found far. that, coalitions CS updatedset CS another coalition structure PG . Here, coalition Ck updatedexamined possible instances Ck+1 , . . . , , C|G| overlap {C1 , . . . , Ck }.example, Figure 5, update C2 (step 5 figure) examinedpossible instances C3 overlap {C1 , C2 } (steps 2, 3, 4 figure). ensuresCS assigned different coalition structures, that, eventually, every possible coalitionstructure PG examined.Next, show process done without storing lists Lg1 , Lg2 , , Lg|G|memory. end, let LCgnk : 1 gk n list combinations size gktaken set {1, 2, , n}, combinations ordered lexicographically list.Given this, LCgnk Lgk contain subsets size gk taken set size n.difference LCgnk list combinations numbers Lgk list coalitionsagents. Now, Rahwan Jennings (2007) shown cycle combinationsLCgnk without storing entire list memory. Instead, one combination stored time.based assumed ordering implies last combination LCgnk always:{1, 2, , gk }.orderingalso implies that, given combination located index x list,fifi1 < x fiLCgnk fi, possible compute combination located index x 1 (fordetails, see paper Rahwan & Jennings, 2007). Hence, order go coalitionsLgk , use variable Mk cycle16 combinations LCgnk and, every instanceMk , extract corresponding coalition Ck Lgk using following operation:Ck = {ai | Mk }(2)example, given Mk = {2, 4, 5}, corresponding coalition would {a2 , a4 , a5 }. Sincedirect mapping (as defined equation 2) every combination LCgnk coalitionLgk , then, Mk cycle every combination LCgnk , cyclecoalitions Lgk .16. done initializing Mk last combination LCgnk (i.e. {1, 2, , gk }), iterativelyshifting Mk list paper Rahwan Jennings (2007), every combination LCgnkexamined.541fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSFigure 5: nave cyclation process cycling coalition structures sub-space.542fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONIntuitively, nave cyclation process, call NCP, viewed efficient.all, need find coalition structure PG maximum value,NCP guarantees find coalition structure. However, suffers following majorlimitations:1. NCP works searching ordered sets TG Cartesian product listsLs : G order find belong PG (i.e. contain disjointcoalitions). major limitation since space coalition structures already exponentially large, would counter-intuitive search even bigger space.example, given 28 agents, number coalition structures P[1,2,3,4,5,6,7]7.8 109 % number ordered sets T[1,2,3,4,5,6,7] . Note difference sizetwo spaces grows exponentially number agents involved.2. Although NCP generate ordered set twice, generates multiple ordered setscontaining coalitions, ordered differently. example, given = {a1 , , a7 }G = [2, 2, 3], NCP generates following ordered sets, h{a1 , a2 }, {a3 , a4 }, {a5 , a6 , a7 }ih{a3 , a4 }, {a1 , a2 }, {a5 , a6 , a7 }i, correspond coalition structure. Noteneed find best coalition structure and, order so, sufficient examinevalue every coalition structure once. words, operation resultscoalition structure generated considered redundant.would desirable, then, find way cycle lists Lg1 , . . . , Lg|G|valid combinations generated. words, would desirable Ck cyclesvalid coalitions Lgk , rather going every coalition Lgk verifyingwhether overlaps {C1 , . . . , Ck1 }. Moreover, order avoid performing redundantoperations, would desirable cyclation process guaranteed gocoalition structure once. Algorithm 4 describes novel cyclation process meetsrequirements.basic idea use searchList function cycle coalitions Lg1 .coalitions, searchList called recursively17 cycle coalitions Lg2overlap first coalition (i.e. one taken Lg1 ). Similarly, cyclingLg2 , searchList called recursively cycle coalitions Lg3overlap first two coalitions, on. repeated searchList calledcycle coalitions Lg|G| , case valid coalition structure (denoted CSAlgorithm 4) belongs PG . Then, CS value greater V (CS 0 ) CS 0updated accordingly. remainder section describes Algorithm 4 avoids generatinginvalid redundant coalition structures without making comparison coalitions. alsodescribes algorithm applies branch-and-bound technique speed search.Avoiding invalid coalition structures: Given G = [g1 , . . . , g|G| ], define following orderedsets agents: A1 , A2 , , A|G| , A1 contains n agents, Ak : 2 k |G| containsPk1n i=1gi agents. Moreover, assume agents Ak : 1 k |G| ordered17. searchList actually implemented code recursive function (due inefficiency recursivefunctions general). However, make Algorithm 4 easier understand, recursive form algorithmpresented paper.543fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSAlgorithm 4 :searchList(G, k, , Ak , CS 0 , CS) search sub-space.Require: {maxs }s{1, ,n} , {v(Ls )}s{1, ,n} , U B ,1: k > 1 gk 6= gk1 {if size repeated.}2:1 {reset .}3: endPk|A |4: Mk LCgk k Mk,1 n + 1i=1 (gk G(gk ))5:6:7:8:9:Ck {Ak,i | Mk } {extract Ck given Mk Ak .}k = |G| V (CS 0 ) < V (CS)CS 0 CS {updatecurrent best.}PPelse V (CS 0 ) < s{g1 , ,gk } v(Cs ) + s{gk+1 , ,gn } maxs {branchpotential finding coalition structure better CS 0 .}CS 0 searchList(G, k + 1, Mk,1 , \ C, CS 0 , CS){branch nextcoalition.}10:11:endBV U(CSV (CS 0 ) = AXG0){stop required solutionfound current best equal upper boundsub-space.}returnend14: end15: return CS 012:CS 013:ascendingly based indices (e.g. Ak contains agents a5 , a7 , a2 , orderwould Ak = ha2 , a5 , a7 i). words, assume that: Ak,1 < Ak,2 < < Ak,|Ak | ,Ak,i ith agent Ak .18 Now, given number coalitions C1 , C2 , , Cgk1 takenlists Lg1 , Lg2 , , Lgk1 respectively, show cycle coalitions Lgkoverlap aforementioned ones, without storing Lgk memory.detail, done using following modifications NCP:Instead using Mk cycle combinations LCgnk (as NCP), use|A |cycle combinations LCgk k .given instance Mk , extract corresponding coalition Ck Lgk usingfollowing operation: Ck = {Ak,i | Mk } (see step 5 Algorithm 4). example, givenMk = {1, 3, 5}, corresponding coalition contain agents a1 , a3 , a5 (asNCP). Instead, contains 1st , 3rd , 5th element Ak .differences ensure Mk cycles possible coalitions size gk takenAk (instead taken A). Based this, set Ak = A\{C1 , , Ck1 },ensure every instance Ck overlap coalitions C1 , , Ck1 .Figure 6 shows example given = A1 = {a1 , a2 , a3 , a4 , a5 , a6 , a7 } G = [2, 2, 3].seen, M1 = {1, 6} implies C1 contains 1st 6th agents A1 (i.e. implies18. Recall define order agents that, two agents ai , aj A, ai < aj iff< j. details, see Section 2.544fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONC1 = {a1 , a6 }). knowing agents belong C1 , assign A2belong C1 , i.e. A2 = {a2 , a3 , a4 , a5 , a7 } (see agents A2 ordered basedindices A). mentioned earlier, M2 would cycle possible coalitionssize 2 A2 , none coalitions would overlap C1 . Similarly, M2 = {3, 5}implies C2 contains 3rd 5th elements A2 (i.e. implies C2 = {a4 , a7 }),knowing agents belong C2 , assign A3 belong C1C2 (i.e. A3 = {a2 , a3 , a5 }), on.Figure 6: Example novel cyclation process, given = {a1 , a2 , a3 , a4 , a5 , a6 , a7 } G =[2, 2, 3].modified cyclation process (MCP), describe above, generates coalitionstructures PG (see Theorem 3), without performing comparisoncoalitions.Theorem 3. Given integer partition G G, every coalition structure PG generatedMCP.Proof. See Appendix D.Note, however, MCP suffers limitation NCP could generatecoalition structure (e.g. given G = [2, 2, 3], h{a1 , a2 }, {a3 , a4 }, {a5 , a6 , a7 }ih{a3 , a4 }, {a1 , a2 }, {a5 , a6 , a7 }i generated MCP). Next, showavoided.545fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSAvoiding redundant coalition structures: note that, using MCP, coalition structure generated twice repeated parts integer partitionG (e.g. ff G =[1, 2, 2, 3] G = [1, 4, 4, 4, 6]). MCP generates ordered sets C1 , , C|G| containing disjoint coalitions sizes match parts G (i.e. |Ck | = gk {1, , |G|}).Based this, ordered set CS generated MCP, then, ordered set CS 0contains coalitions different order (compared CS) also generatedMCP long sizes coalitions match parts G. This, course, happengk = gj : k 6= j. Based this, MCP needs modified casesrepeated parts G.19 modification done follows:|A |cycling combinations LCgk k , ensurePk first (i.e. smallest) elementMk (denoted Mk,1 ) satisfies: Mk,1 n + 1 i=1 (gk G(gk )), = Mk1,1gk = gk1 , = 1 otherwise (see step 4 Algorithm 4).illustrated Figure 6 using connected boxes. detail, M1 cyclescombinations LC27 contained boxes (e.g. cycle combinations {5, 6},{5, 7}, {6, 7}). Moreover, M2 cycles combinations LC25 containedboxes connected one M1 currently cycling. modification ensuresMk+1,1 Mk,1 gk+1 = gk . example, M1 cycling box LC27containing combinations smallest element 3, M1,1 = 3. case, M2cycles boxes LC25 containing combinations smallest element3 4 (see boxes connected Figure 6), ensures M2,1 M1,1 .final cyclation process (FCP), describe above, generates every coalition structurePG exactly once.Theorem 4. Given integer partition G G, every coalition structure PG generated exactlyFCP.Proof. See Appendix E.Note, however, given exponential size PG , would desirable avoidgenerating coalition structure potential value greater maximum onefound far. Next, show done using branch-and-bound technique.Applying Branch-and-Bound: mentioned earlier, cycling coalition structuresPG , update Ck examined possible instances {Ck+1 , . . . , C|G| }overlap {C1 , . . . , Ck }. words, update Ck examinedpossible coalition structures start {C1 , . . . , Ck }. However, knew nonecoalition structures could value greater maximum value found far,could update Ck straight away (i.e. without go possible instances{Ck+1 , . . . , C|G| }). order so, calculate upper bound values coalitionsadded {C1 , . . . , Ck }. Specifically, computed maxs every possible coalition19. Note coalition structures usually contain repeated coalition sizes (e.g. 99.6% given 20agents).546fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONsize {1, 2, . . . , n}, calculate upper bound, denoted AX[gk+1 ,...,g|G| ] ,follows:AX[gk+1 ,...,g|G| ] =|G|Xmaxgii=k+1Now, define VP({C1 , , Ck }) sum values coalitions C1 , , Ck (that is,kV (C1 , . . . , Ck ) =i=1 v(Ci )), V ({C1 , ..., Ck }) + AX[gk+1 ,...,g|G| ] represents upperbound value coalition structure could obtained coalition structure starting{C1 , , Ck } ending coalition sizes [gk+1 , . . . , g|G| ].Hence, V (CS 0 ) V ({C1 , ..., Ck }) + AX[gk+1 ,...,g|G| ] implies none coalition structures start {C1 , ..., Ck } end coalitions sizes: gk+1 , ..., g|G|value greater V (CS 0 ) (this checked step 8 Algorithm 4). hand,V (CS 0 ) < V ({C1 , . . . , Ck }) + AX[gk+1 ,...,g|G| ] implies could coalition structurestarts {C1 , , Ck } better current best coalition. However, stillnecessarily imply coalition structures need examined. because,algorithm moves next list, may find certain coalition structuresbetter current best. Formally, every coalition Cj : k < j < |G|, still have:V (CS 0 ) > V ({C1 , ..., Cj }) + AX[gj+1 ,...,g|G| ] . Figure 7 illustrates branch-and-boundtechnique applied searching sub-space.Figure 7: Applying branch-and-bound searching coalition structures subspace.547fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGS5. Performance Evaluationsection, empirically evaluate IP algorithm, benchmark stateart literature. Since IPs ability prune space depends closeness upperlower bounds actual optimal value, since closeness determined spreaddistribution coalition values, crucial IP tested different value distributions.Moreover, aim evaluate ability algorithm generate solutions anytime zoomhigh quality solutions rapidly.follows, first discuss validity properties different value distributionsuse test algorithm (Section 5.1). Then, benchmark algorithm fastestavailable algorithm literature (i.e. IDP) using aforementioned distributions (Section 5.2).Finally, empirically evaluate efficiency effectiveness algorithm generatingsolutions anytime (Section 5.3).5.1 Benchmarkingcommon practice benchmarking search heuristics choose standard instancesproblem compare various algorithms exist without giving priori knowledgetype input presented with. standard instances coalition structuregeneration problems defined used Larson Sandholm (2000) namely:201. Normal: v(C) |C| N (, 2 ) = 1 = 0.1.2. Uniform: v(C) |C| U (a, b) = 0 b = 1.use distributions benchmark algorithm, also question validitydistributions. because, previous work (Rahwan et al., 2007b), notednormal uniform distributions tend generate solutions small numbers coalitions. However, show that, coalition values picked Normal Uniform distributions(scaled size coalition), resulting distribution coalition structure valuesbiased (see Theorem 5). Given this, experiments defined according Normal Uniformdistributions could favour algorithms others.Theorem 5. coalition values taken normal distribution follows: CA, v(C) |C| N (, 2 ), taken uniform distribution follows: CA, v(C) |C| U (a, b), then, given coalition structure CS 0 : |CS 0 | > 1, exists anothercoalition structure CS 00 : |CS 00 | < |CS 0 | that:P V (CS 00 ) = V (CS ) > P V (CS 0 ) = V (CS )is, probability CS 00 optimal coalition structure greater CS 0 .Proof. See Appendix F.20. sub super-additive distributions also studied literature, cases usually knownpriori distribution coalition values actually types (in case known priorioptimal coalition structure is). Moreover, previous results distributions produced interestinginsights (Rahwan et al., 2007b) experiment these.548fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONremedy this, propose new input distribution tailored specifically CSG problem. distribution, define NDCS (Normally Distributed Coalition Structures),constructed generating coalition values following way:NDCS: v(C) N (, 2 ), = |C| =p|C|.case, turns value every possible coalition structure independentlydrawn normal distribution leads us following theorem:pTheorem 6. Iff have: C A, v(C) N (, 2 ), = |C| = |C|,following holds:CS P, V (CS) N (|A| , |A|)Proof. See Appendix G.Since NDCS distribution ensures every coalition structure value drawndistribution, ensures search space biased. Thus, efficiency search algorithmsfinding optimal coalition structure strongly tested cases.Using input distributions, benchmark algorithm state-of-theart algorithm, namely IDP (see Section 2). Note experiment anytimealgorithms since need search whole space find optimal value generallyfeasible within reasonable time, even small numbers agents. Also, shownRahwan et al. (2007b) industrial strength software CPLEX cannot handle inputs18 agents since runs memory therefore run experimentshere. graphs plot 95% confidence interval every point (given 800 runs 1520 agents 100 runs 21 25 agents).215.2 Experiment 1: Optimalityexperiment, compare algorithms performances given different numbers agents(from 15 27). time find optimal coalition structure measured terms clock time(in milliseconds) Intel 2.6GHz Quad Core PC 3Gigabytes RAM. algorithmscoded using JAVA 1.6. running times plotted log scale Figure 8.22 note IP-Xapplication IP distribution X, X NDCS, Normal, Uniform (as describedabove). seen, IP finds optimal coalition structure significantly faster IDPdistributions. best case (Uniform 27 agents) IP 570 times better IDP (i.e. takes0.175% time taken IDP) worst case (NDCS 16 agents) 1.7 times fasterIDP. also seen performance IP slowest given NDCS distribution(compared IP-Normal IP-Uniform). determine cause this, first discuss twomain problems affect performance IP:21. plotting 95% confidence interval, aim check statistical significance difference meanstaken point across different series. Thus, two points two different series overlapping confidenceintervals, equivalent saying null hypothesis validated (i.e. means significantly different)t-test = 0.05. confidence intervals overlap, means significantly different.22. running time IDP deterministic since runs O(3n ). Hence, recorded running time 25agents extrapolated results 27 agents.549fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSFigure 8: Time find optimal solution IDP, IP applied NDCS, Normal, Uniformdistributions.1. Pruning sub-spaces: higher upper bounds sub-spaces lower valueoptimal coalition structure, harder prune sub-spaces. deducedpruning function use Algorithm 2. Moreover, bigger sub-spaces higherupper bounds, longer algorithm take find optimal solution.algorithm always search sub-space highest upper bound checksolution found optimal.2. Branch-and-bound: higher upper bounds sub-spaces lower optimalcoalition structure value, harder prune branch-and-bound. deducedpruning applied step 8 Algorithm 4. because, applying branchand-bound within sub-space P{g1 ,g2 ,...,gn } , current best solution CS 0 comparedsum coalition values maximum value coalitions remaining coalitionsizes follows:V (CS 0 ) >XC{Lg1 , ,Lgk }v(C)+Xmaxg move next coalition structureg{gk+1 , ,gn }Now, best solution low compared upper bound, is:XV (CS 0 ) << U BG =maxgg{g1 , ,gn }then, branch-and-bound applied deeper (i.e. increasing variable k conditionabove) sub-space order make sure coalition structure evaluatedoptimal. Hence, worst case would search whole sub-space (i.e. applystep 9 Algorithm 4 increasing values k n).550fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONorder see different issues affect performance algorithm respectdifferent distributions, recorded value optimal coalition structure upper boundssub-spaces (given 21 agents) averaged 20 runs.23 also exactly recordedsize sub-space (i.e. number coalition structures per sub-space). resultsplotted Figure 9. note following distribution:Figure 9: Top: upper bounds optimal coalition structure value, bottom: size sub-spaces.Note values bottom graph plotted log scale. Pointsabscissa two graphs correspond sub-space. arrows showdirection search distribution.NDCS: biggest sub-spaces ones highest upper bounds. Hence,much harder prune large portions search space. Moreover, average optimal23. values upper bounds average optimal coalition structure rounded scaled easeexplanation clearer plot.551fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGScoalition structure value relatively low compared upper bounds bigger subspaces. Hence, applying branch-and-bound distribution hard.Normal: smaller sub-spaces ones highest upper bounds. Hence, pruninglarge portions space easily done searching smaller sub-spaces goodsolutions are. Moreover, value optimal coalition structure tends higherupper bounds large sub-spaces, relatively close highest upper bounds.Hence, easier branch-and-bound prune large portions sub-spaces.Uniform: upper bounds sub-spaces relatively high compareddistributions (i.e. close highest upper bound). fact, upper boundsactually nearly equal average optimal solution allows algorithm prunesub-spaces soon found optimal solution, happens almostimmediately scanning input.Finally, note Figure 9 shows portion space avoided given selectionstrategy described earlier Section 4.2. detail, recall strategy guaranteedavoid searching sub-spaces upper bound lower V (CS ). seenfigure, many sub-spaces (in case NDCS Uniform distributions) upperbound lower V (CS ), although sub-spaces relatively small. Moreover,case Normal distribution, almost sub-spaces upper bound lower V (CS ),among largest ones!studied performance IP terms completion time, next focus studyingability generate solutions anytime.5.3 Experiment 2: Anytime Qualityexperiment, evaluate anytime property algorithm, recording value solutions generated returning guaranteed optimal one.particular, recorded two indicative measures quality solutions. First, computedratio value current best solution optimal solution (obtained end(CS 0 )run). ratio noted ropt = VV (CS) . measure shows effective algorithmzooming good solutions. Second, recorded ratio rbound value cur0)rent best solution upper bound optimal value (i.e. rbound = V U(CSB ). measuretheoretical guarantee algorithm places quality solution (see Section 4.1).Ideally, algorithm able minimise difference ropt rbound minimaltime.results plotted Figure 10 distributions: NDCS, Normal, Uniform.24discuss results distributions turn.NDCS: seen, algorithm high quality guarantees (i.e. rbound > 90%)less half time required find optimal solution. also produces highquality solutions (i.e. ropt > 90%) within less 10% time required terminate.24. points plotted averages computed 500 runs 19 agents 22 agents, 100 runs 25 agents.error bars depict 95% confidence interval intervals results recorded.552fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONFigure 10: Quality (ropt ) bound (rbound ) generated solution. cases, x-axisrepresents time (in milliseconds) y-axis represents ratio solutionoptimal.553fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSNormal: case, algorithm able come guaranteed high quality solutionsmuch faster NDCS distribution. Moreover, case, high quality solutions(i.e. ropt > 90%) guaranteed (i.e. rbound > 90%) less 10% timefind optimal value. results fact upper bounds faroptimal value NDCS case.Uniform: expected earlier results presented Section 5.2, algorithm generateshigh quality solutions (i.e. ropt 100%) faster distributions (shortlyscanning input). Moreover, solutions guaranteed near-optimal (i.e.rbound > 99%) within 15% time find optimal.Next, compare worst-case guarantees provided IP provided Sandholm et al.s (1999) Dang Jenningss (2004) algorithms (see Figure 11). seen,algorithm significantly outperforms Dang Jenningss Sandholm et al.s distributions. particular, scanning input, IP able guarantee solution nearly40% (in worst case) optimal compared 10% algorithms. Moreover,guarantee usually reaches 100% searching minute portions search space (on averagearound 0.0000019% hardest distribution), guarantees provided algorithmsgo beyond 50% whole space searched. Also note generatehigh quality solutions (i.e. > 90%) searching even smaller portions search space(on average around 0.0000002% hardest distribution). Thus, actual computational time,25 agents example, able return solution guaranteed higher 90%optimal around 250 seconds worst case 300 milliseconds best case.6. Conclusions Future WorkCoalition formation, process group software agents come together agreecoordinate cooperate performance set tasks, important form interactionmulti-agent systems. coalitions improve performance individual agents and/orsystem whole, especially tasks cannot performed single agent, groupagents performs tasks efficiently. One challenging problems arisecoalition formation process coalition structure generation, involves partitioningset agents exhaustive disjoint coalitions social welfare maximized.paper, developed evaluated anytime integer-partition based algorithm (calledIP) finds optimal solutions much faster previous algorithm designed purpose.strength approach founded upon two main components:use novel representation search space partitions smaller, disjointsub-spaces explored independently find optimal solutions. representation,based integer partitions number agents involved, allows agentsbalance trade-offs preferences certain coalition sizes computation required find solution. Moreover, trade-offs made informedmanner since compute bounds sub-spaces search space. bounds allow us prune search space guarantee quality solution foundsearch. may also, depending distribution input values, allow us obtainoptimal solution almost immediately scanning input.554fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONFigure 11: Worst case bounds generated IP using Normal NDCS distributions comparedSandholm et al.s (1999) Dang Jenningss (2004) algorithms 25 agents.results Uniform distribution trivial since IP average finds optimalalmost immediately scanning input. Note error bars omittedIP results reasons clarity.555fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSdevise technique allows us cycle coalition structures within givensub-space. Unlike nave cyclation technique generates combinations coalitions,verifies whether combinations valid coalition structure, cyclation technique generates valid ones (thus, avoiding search space possible combinations coalitions, exponentially larger space coalition structures).addition, cyclation technique perform redundant operations since avoidsgenerating coalition structure once. Finally, applying branch-andbound technique, able identify coalition structures cannot improvequality solution found far, thus, avoid generating them.Altogether, components allow us make significant performance gains existingapproaches. detail, experiments show IP avoids searching search space,therefore, requires significantly less time, compared algorithms, order returnoptimal solution. example, IP outperforms IDP orders magnitude (0.175%time taken IDP 27 agents best case). Moreover, IP interrupted optimalvalue found, still return solutions close optimal (usually 95%optimal), high worst-case guarantees (usually 90%). solutionsalways better (above 40% optimal right scanning input) returnedSandholm et al.s (1999) Dang Jenningss (2004) algorithms (i.e. less 10%optimal). algorithms also search large portion search spaceable get better guarantees algorithm able prune find near-optimal solutionsrelatively quickly (above 90% optimal within 10% time find optimal solution25 agents).number important extensions IP could envisaged. example, recentlycombined IDP algorithm IP (IP-IDP) (Rahwan & Jennings, 2008a) exploreapproaches including linear programming techniques improve bounds used IP. However,extensions deal exponential input (i.e. 2n memory locations least nagents) IP. Therefore, important develop techniques extend approach order minimise cycling coalition values number agents increases.require adapting cyclation technique bound computation. Hence, futurework, need devise representations sub-spaces allow us cycle intelligentlylarger inputs develop new techniques compute bounds used branch-andbound algorithm. trying adapt approach problems, also aim determinedegree IP used solve common incomplete set partitioning problemsoccur combinatorial auctions (Rothkopf et al., 1995) crew scheduling (Hoffman & Padberg,1993). Finally, aim see whether patterns exploit algorithm also arisecombinatorial optimisation problems studied area combinatorics (e.g.,Kreher & Stinson, 1998; Papadimitriou & Steiglitz, 1998).7. Acknowledgmentsresearch paper undertaken part ALADDIN (Autonomous Learning AgentsDecentralised Data Information Systems) project jointly funded BAE SystemsEPSRC (Engineering Physical Research Council) strategic partnership (EP/C548051/1).Andrea Giovannucci funded Juan de la Cierva programme (JCI-2008-03006)EU funded Synthetic Forager project (ICT-217148-SF). also wish thank Professor Tuomas556fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONSandholm comments, well anonymous reviewers valuable commentsprevious versions paper. also grateful Dr. Viet Dung Dang contributionsearlier versions paper. Finally, wish thank Dr. W. T. Luke Teacy helpproofs anonymous reviewers constructive comments.557fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSAppendix A. Summary NotationainC|C|v(C)CSV (CS)CSU BLBCS 0LCsiLsv(Ls )maxsminsavgsPPiLViGG(s)E(G)GG2TGPGAXGINGAV GGFCSMkAkCsnP (x)IDPN (, 2 )U (a, b)roptrboundset agents.agent A.number agents A.coalition.cardinality C.value C.coalition structure.value CS.optimal coalition structure.upper bound V (CS ).lower bound V (CS ).best coalition structure found far.bound quality best solution found far.bound within solution acceptable.list possible combinations size taken set {1, 2, . . . , i}.list coalitions size ordered lexicographically.list containing values coalitions Ls .maximum value coalitions Ls .minimum value coalitions Ls .average value coalitions Ls .set possible coalition structures.ith level representation space possible coalition structures.ith level coalition structure graph.integer partition n.multiplicity G.underlying set G.set possible integer partitions n.set possible integer partitions n contain two parts each.Cartesian product lists Ls : G.sub-space (in space representation) corresponds G (i.e. pre-image G F ).maximum value elements TG .minimum value elements TG .average value elements TG .function maps coalition structure CS integer partition G that: C CS, g G : |C| = g.variable used cycle coalition structures PG .variable used cycle list combinations size gk .ordered set containing agents members C1 , . . . , Ck1 .binomial coefficient (i.e. number possible combinations size taken n elements).probability x.improved dynamic programming algorithm.Normal distribution mean variance 2 .Continuous Uniform distribution interval [a, b].ratio value current best solution value optimal solution.ratio value current best solution upper bound value optimalsolution.558fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONAppendix B. Proof Theorem 1.Let G = [g1 , g2 , . . . , g|G| ] containelements Gff natural ordering them, let PGreturn ordered coalition structures C1 , C2 , . . . , C|G| : Ci Lgi , order coalitions within coalition structure taken consideration. example, given n = 4 G =[1, 1, 2], two ordered coalition structures: h{a1 }, {a2 }, {a3 , a4 }i h{a2 }, {a1 }, {a3 , a4 }iPG correspond one coalition structure: {{a1 }, {a2 }, {a3 , a4 }} PG . Now, since number repetitions coalition structure PG same25 (e.g., exampleG = [1, 1, 2], coalition structures PG appear twice PG ), have:AV GG = AV GG(3)AV GG average value coalition structures PG . Now, define Nn (g1 , g2 , . . . , g|G| )number ordered coalition structures PG , have:AV GG =X1V (CS)Nn (g1 , g2 , . . . , g|G| )CSPG=X1Nn (g1 , g2 , . . . , g|G| )Xv(C)CSPG CCSMoreover, every coalition C Lgi , are: Nngi (g1 , g2 , . . . , gi1 , gi+1 , . . . , g|G| ) orderedcoalition structures C happens ith coalition. Based this, have:Nn (g1 , g2 , . . . , g|G| ) = |Lgi | Nngi (g1 , . . . , gi1 , gi+1 , . . . , g|G| )(4)Similarly, number times v(C) occurs ith position sum coalition valuesPG Nngi (g1 , . . . , gi1 , gi+1 , . . . , g|G| ). Given this, next compute AV GG follows:AV GG =|G|XX1Nngi (g1 , . . . , gi1 , gi+1 , . . . , g|G| ) v(C)Nn (g1 , g2 , . . . , g|G| )i=1 CLgi|G|=X X Nngi (g1 , . . . , gi1 , gi+1 , . . . , g|G| )v(C)Nn (g1 , g2 , . . . , g|G| )i=1 CLgi|G|XX1v(C) (following equation (4))|Lgi |i=1 CLgi|G|XX1=v(C)|Lgi |=i=1=|G|XCLgiavggii=125. Specifically, coalition structure repeated x! times contains x coalitions size.559fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSBased this, well (3), find that:AV GG =|G|Xavggii=1Appendix C. Proof Theorem 2.Generally speaking, given set B A, number possible combinations size|A||B|set B = A\B equal Cs. Based this, every coalition C size g1 ,ng1Cg2coalitions size g2 overlap it. Similarly, every disjoint coalitionsn(g +g +...+gi )(C1 , C2 , . . . , Ci ) sizes g1 , g2 , . . . , gi respectively, Cgi+1 1 2coalitions sizegi+1 overlap union C1 C2 . . . Ci .Based this, TG cartesian product lists Lgi : gi G, TG subset TGcontains elements (i.e. combinations coalitions) coalitions overlap,number elements TG computed follows:fi fin(g1 +...+g|G|1 )fi fi1. . . Cg|G|(5)fiTG fi = Cgn1 Cgng2Moreover, note combination coalitions {C1 , C2 , . . . , C|G| }, {1, 2, . . . , |G|} :|Ci | = gi , appears exactly PG (since considered unique coalition structure) couldappear TG (since ordering coalitions matters elements TG ).particular, gi appears x times G, every coalition structure PG corresponds x! elementsTG , coalitions size gi ordered differently elements. example,given G = [1, 2, 2, 2, 5], size 2 appears 3 times G means every coalition structure{C1 , C2 , C3 , C4 , C5 } PG corresponds 3! elements TG (since 3! number possiblepermutations C2 , C3 , C4 ). generalized follows:fi fifi fifiTG fiG = [g1 , g2 , . . . , g|G| ] G, |PG | =(6)G(g1 )! G(g2 )! . . . G(g|G| )!G(gi ) denotes multiplicity gi G. Then, (5) (6), find that:n(g1 +...+g|G|1 )1Cgn1 Cgng. . . Cg|G|2Q|PG | =sE(G) G(s)!E(G) underlying set G.Appendix D. Proof Theorem 3.Given integer partition G = [g1 , . . . , g|G| ] G, need prove coalition structuresPG generated MCP. Without loss generality, assume parts G560fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONincreasing order. is:g1 g2 . . . g|G|(7)Now, way MCP works generating ordered sets coalitions that, every ordered set,first coalition belongs Lg1 second belongs Lg2 on. Moreover, wayordered sets generated ensures coalitions ordered sets overlap.words, MCP generates subset TG , denoted TG , defined follows:26TG =ffC1 , ..., C|G| | {1, ..., |G|}, Ci |Ci | = gi j {1, ..., |G|} : j 6= i, Ci Cj =Then, given coalition structure CS PG , let TGCS subset TG containing orderedsets correspond CS. is:CSTG=EnDC1 , ..., C|G| | {1, ..., |G|}, Ci CS |Ci | = gi j {1, ..., |G|} : j 6= i, Ci Cj =(8){{a },{a2 },{a3 ,a4 }}1example, T[1,1,2]= {h{a1 }, {a2 }, {a3 , a4 }i , h{a2 }, {a1 }, {a3 , a4 }i}. Next, givenffcoalition structure CS PG , prove |TGCS | 1. end, let C1 , C2 , . . . , C|G|ordering coalitions belong CS. Then, (7) (8), see that:fififfC1 , C2 , . . . , C|G| TGCS iff |C1 | |C2 | . . . fiC|G| fi(9)fifisince least one way ordering coalitions CS |C1 | ... fiC|G| fi,least one ordered set TGCS . words, |TGCS | 1. This, turn, impliesevery coalition structure PG generated MCP.Appendix E. Proof Theorem 4.Given integer partition G = [g1 , . . . , g|G| ] G, let TeG set ordered sets generatedFCP. Moreover, given coalition structure CS PG , let TeGCS subset TeG containingordered sets correspond CS. is:nffTeGCS = C1 , C2 , . . . , C|G| TeG | {1, 2, . . . , |G|}, Ci CSNext, prove |TeGCS | = 1. define TG TGCS Appendix D. also assume,without loss generality, order (7) holds. Note that, G(gi ) = 1 {1, . . . , |G|},difference way FCP works way MCP works.27hand, exists {1, ..., |G|} G(gi ) > 1, difference FCPMCP FCP avoids coalition structures generated MCP. implies26. Recall TG cartesian product lists: Ls : G.27. Recall G(gi ) multiplicity gi G.561fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSthat:G(gi ) = 1 {1, . . . , |G|} TeG = TG CS PG , TeGCS = TGCSelse TeG TG CS PG , TeGCS TGCS(10)(11)ffNow, given coalition structure CS PG , let C1 , C2 , . . . , C|G| defined Appendix (i.e.ordering coalitions belong CS). Then, (9), find numberordered sets TGCS equalfifi number possible ways ordering coalitions CSfithat: |C1 | |C2 | ... C|G| fi. Based this, well (10) (11), distinguishtwo cases:G(gi ) = 1 {1, ..., |G|},fi wouldfi one possible way orderingficoalitions CS |C1 | ... C|G| fi (because every coalition CS uniquesize). implies |TGCS | = 1, (10), find |TeGCS | = 1.{1, ..., |G|} : G(gi ) > 1,fi thenfithere would multiple ways ordering coalitionsCS |C1 | ... fiC|G| fi, implies |TGCS | > 1. However, (11),know TeGCS subset TGCS . Then, proving TeGCS contains exactly oneordered sets TGCS , prove |TeGCS | = 1. precise, case have:|Cx | = |Cx+1 | = ... = |Cx+y |, every possible permutation coalitionsgenerated MCP, need prove one generated FCP.Based this, denote ck smallest28 agent Ck , sufficient proveFCP generates one permutation satisfies: cx < cx+1 < ... < cx+y . Noteagents Ak ordered Ak,1 < Ak,2 < < Ak,|Ak | . Based this, ck = Ak,i ,1 agents Ak smaller ck , since Ak+1 = Ak \Ck ,1 agents Ak+1 smaller ck . Therefore, ensure ck < ck+1 ,sufficient generate Ck+1 contain first (i.e. smallest) 1 agentsAk+1 . example, given Ak = ha1 , a4 , a5 , a7 , a8 , a9 Mk = {3, 5}, wouldCk = {a5 , a8 } ck = Ak,3 . implies Ak+1 contains two agents smallerck (namely, agents a1 a4 ). Therefore, ensure ck < ck+1 , sufficientgenerate Ck+1 contain first (i.e. smallest) two agents Ak+1 .done ensuring Mk+1 contain elements 1 2. words,done ensuring Mk+1,1 Mk,1 , direct result way FCP modified.proving |TeGCS | = 1 CS PG , prove FCP generates every coalition structurePG exactly once.28. Recall that, two agents ai , aj A, say ai smaller aj < j. comesassumed ordering set agents (see Section 2 detail).562fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONAppendix F. Proof Theorem 5first prove Theorem 5 normal distribution case (i.e. case C A, v(C)|C|N (, 2 )). Specifically, show coalition structures contain fewer coalitionslikely optimal. order prove this, first prove following lemmadeals properties normal distribution.Lemma 1. given value r R, two random variables Xa N (, 2 )Xb N (, b 2 ) < b , following holds:P (Xa > r) < P (Xb > r)(12)Proof. Given r R, let ,a2 (r) ,2 (r) cumulative distribution functionsbN (, 2 ) N (, b 2 ) respectively. is,1r,a2 (r) =1 + erf221,2 (r) =b2r1 + erfb 2RM2erf(M ) = 2 0 et error function. Then, order prove inequality(12) holds, sufficient prove that:,a2 (r) > ,2 (r)(13)bend, given < b , following holds, abs(M ) absolute value :rrabs> abs2b 2This, turn, implies that:erfr2> erfrb 2Based this, well fact erf(M ) 0, deduce (13) holds.Based lemma, given coalition structure CS 0 : |CS 0 | > 1, proveexists another coalition structure CS 00 : |CS 00 | < |CS 0 | that:P V (CS 00 ) = V (CS ) > P V (CS 0 ) = V (CS )detail, let CS 0 = {Cx1 , , Cx , Cy1 , , Cy } CS 00 = {Cx , Cy1 , , Cy }Cx = Cx1 Cx . Then, based properties normal distribution, have:v(Cx ) N |Cx | , |Cx |2 2(14)563fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSand:(15)v(Cx1 ) + + v(Cx ) N (|Cx1 | + + |Cx |) , (|Cx1 |2 + + |Cx |2 ) 22 denote mean variance distriNow, given coalition structure CS, let CS CSbution V (CS). Then, based (14) (15), have:XCS 00 = (|Cx | ) +(|C| )CCS 00 \{Cx }X222CS00 = (|Cx | ) +(|C| )2CCS 00 \{Cx }have:XCS 0 = ((|Cx1 | + + |Cx |) ) +CCS 0 \{C2CS(|Cx1 |2 + + |Cx |2 ) 2 +0 =(|C| )x1 , ,Cx }X(|C| )2CCS 0 \{Cx1 , ,Cx }Since |Cx | = |Cx1 | + + |Cx |, since CS 00 \ {Cx } = CS 0 \ {Cx1 , , Cx }, seedistribution V (CS 00 ) V (CS 0 ) differ way variances differ. Note that:|Cx |2 = (|Cx1 | + + |Cx |)2 > |Cx1 |2 + + |Cx |222implies CS0 < CS 00 . Therefore, based Lemma 1, find value r R:P (V (CS 0 ) > r) < P (V (CS 00 ) > r)words, likely CS 00 value greater r, implieslikely CS 00 optimal coalition structure.proved Theorem 5 normal distribution case, give intuition behindproof uniform distribution case (i.e. case C A, v(C) |C|U (a, b)). Specifically, assuming CS 0 CS 00 defined above, would v(Cx ) |Cx | U (a, b)and, coalition C {Cx1 , , Cx }, would v(C) |C| U (a, b). Then, easyverify P (v(Cx ) r) less P (v(Cx1 ) + + v(Cx ) r) high values r.intuition behind difference probabilities sum Uniformly distributed variables(called Uniform Sum distribution) results distribution giving lower probability lowhigh values, higher probability middle ranged values. Instead, uniformly distributedvariable, values equally probable. Therefore, given Uniform Sum distribution Uniform distribution minimum maximum values, Uniform distribution givehigher probability higher values. Hence, proof holds Uniform distributionwell.564fiAppendix G. Proof Theorem 6.Given following:C A, v(C) N (|C| , |C|)(16)need prove value every coalition structure independently drawnnormal distribution. Specifically, prove following holds:CS P, V (CS) N (|A| , |A|)(17)properties normal distribution, know that, two independent randomvariables, x x N (x , x 2 ) N (y , 2 ), have:(x + y) N (x + , x 2 + 2 )(18)Then, based (16) (18), two coalition values, v(C1 ) v(C2 ), satisfy following(since independent random variables):(v(C1 ) + v(C2 )) N (|C1 | + |C2 | , |C1 | + |C2 |)implies following true:!CS P,Xv(C)!NCCSX|C| ,CCSX|C|(19)CCSFinally, note assume following:CS P, V (CS) =Xv(C)(20)CCSCS P, C, C 0 CS, C C 0 =(21)Then, (19), (20), (21), find that:CS P, V (CS) N (|CCS | , |CCS |)implies (17) holds since CCS = A.ReferencesAndrews, G., & Eriksson, K. (2004). Integer Partitions. Cambridge University Press, Cambridge,UK.Dang, V. D., & Jennings, N. R. (2004). Generating coalition structures finite bound optimal guarantees. Proceedings Third International Joint Conference AutonomousAgents Multi-Agent Systems (AAMAS-04), pp. 564571.fiR AHWAN , R AMCHURN , G IOVANNUCCI , & J ENNINGSDang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition formationefficient data fusion multi-sensor networks. Proceedings Twenty First NationalConference Artificial Intelligence (AAAI-06), pp. 635640.Evans, J., & Minieka, E. (1992). Optimization Algorithms Networks Graphs, 2nd edition.Marcel Dekker, New York, USA.Hillier, F. S., & Lieberman, G. J. (2005). Introduction operations research. McGraw-Hill, NewYork, USA.Hoffman, K. L., & Padberg, M. (1993). Solving airline crew scheduling problems branch-andcut. Management Science, 39(6), 657682.Horling, B., & Lesser, V. (2005). survey multi-agent organizational paradigms. KnowledgeEngineering Review, 19(4), 281316.Jennings, N. R. (2001). agent-based approach building complex software systems. Communications ACM, 44(4), 3541.Kahan, J., & Rapoport, A. (1984). Theories Coalition Formation. Lawrence Erlbaum AssociatesPublishers, New Jersey, USA.Klusch, M., & Shehory, O. (1996). polynomial kernel-oriented coalition formation algorithmrational information agents. Proceedings Second International Conference MultiAgent Systems (ICMAS-96), pp. 157164.Kreher, D. L., & Stinson, D. R. (1998). Combinatorial Algorithms: Generation, Enumeration,Search (Discrete Mathematics applications). CRC Press.Larson, K., & Sandholm, T. (2000). Anytime coalition structure generation: average case study.Journal Experimental Theoretical Artificial Intelligence, 12(1), 2342.Li, C., & Sycara, K. P. (2002). Algorithm combinatorial coalition formation payoff divisionelectronic marketplace. Proceedings First International Joint ConferenceAutonomous Agents Multiagent Systems (AAMAS-02), pp. 120127.Norman, T. J., Preece, A. D., Chalmers, S., Jennings, N. R., Luck, M., Dang, V. D., Nguyen, T. D.,V. Deora, J. S., Gray, W. A., & Fiddian, N. J. (2004). Agent-based formation virtualorganisations. International Journal Knowledge Based Systems, 17(24), 103111.Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press, Cambridge MA,USA.Papadimitriou, C. H., & Steiglitz, K. (1998). Combinatorial Optimization: Algorithms Complexity. Dover Publications.Rahwan, T., & Jennings, N. R. (2007). algorithm distributing coalitional value calculationsamong cooperative agents. Artificial Intelligence, 171(89), 535567.Rahwan, T., & Jennings, N. R. (2008a). Coalition structure generation: dynamic programmingmeets anytime optimisation. Proceedings Twenty Third Conference ArtificialIntelligence (AAAI-08), pp. 156161.Rahwan, T., & Jennings, N. R. (2008b). improved dynamic programming algorithm coalitionstructure generation. Proceedings Seventh International Conference AutonomousAgents Multi-Agent Systems (AAMAS-08), pp. 14171420.566fiA N NYTIME LGORITHM PTIMAL C OALITION TRUCTURE G ENERATIONRahwan, T., Ramchurn, S. D., Dang, V. D., & Jennings, N. R. (2007a). Near-optimal anytimecoalition structure generation. Proceedings Twentieth International Joint ConferenceArtificial Intelligence (IJCAI-07), pp. 23652371.Rahwan, T., Ramchurn, S. D., Giovannucci, A., Dang, V. D., & Jennings, N. R. (2007b). Anytimeoptimal coalition structure generation. Proceedings Twenty Second ConferenceArtificial Intelligence (AAAI-07), pp. 11841190.Rothkopf, M. H., Pekec, A., & Harstad, R. M. (1995). Computationally manageable combinatorialauctions. Management Science, 44(8), 11311147.Sandholm, T. W., Larson, K., Andersson, M., Shehory, O., & Tohme, F. (1999). Coalition structuregeneration worst case guarantees. Artificial Intelligence, 111(12), 209238.Sandholm, T. W., & Lesser, V. R. (1997). Coalitions among computationally bounded agents. Artificial Intelligence, 94(1), 99137.Sen, S., & Dutta, P. (2000). Searching optimal coalition structures. Proceedings SixthInternational Conference Multi-Agent Systems (ICMAS-00), pp. 286292.Shehory, O., & Kraus, S. (1995). Task allocation via coalition formation among autonomous agents.Proceedings Fourteenth International Joint Conference Artificial Intelligence(IJCAI-95), pp. 655661.Shehory, O., & Kraus, S. (1998). Methods task allocation via agent coalition formation. ArtificialIntelligence, 101(12), 165200.Tsvetovat, M., Sycara, K. P., Chen, Y., & Ying, J. (2000). Customer coalitions electronicmarketplace. Proceedings Fourth International Conference Autonomous Agents(AA-01), pp. 263264.Yeh, D. Y. (1986). dynamic programming approach complete set partitioning problem. BITNumerical Mathematics, 26(4), 467474.567fiJournal Artificial Intelligence Research 34 (2009) 637-674Submitted 07/08; published 04/09Sentence Compression Tree TransductionTrevor Cohntcohn@inf.ed.ac.ukMirella Lapatamlap@inf.ed.ac.ukSchool InformaticsUniversity Edinburgh10 Crichton Street Edinburgh EH8 10AB, UKAbstractpaper presents tree-to-tree transduction method sentence compression.model based synchronous tree substitution grammar, formalism allows localdistortion tree topology thus naturally capture structural mismatches.describe algorithm decoding framework show modeltrained discriminatively within large margin framework. Experimental results sentencecompression bring significant improvements state-of-the-art model.1. IntroductionRecent years witnessed increasing interest text-to-text generation methods manynatural language processing applications, ranging text summarisation question answering machine translation. heart methods lies ability performrewriting operations. instance, text simplification identifies phrases sentencesdocument pose reading difficulty given user substitutes simpler alternatives (Carroll, Minnen, Pearce, Canning, Devlin, & Tait, 1999; Chandrasekar &Srinivas, 1996). question answering, questions often paraphrased order achieveflexible matching potential answers (Lin & Pantel, 2001; Hermjakob, Echihabi,& Marcu, 2002). Another example concerns reformulating written language rendernatural sounding speech synthesis applications (Kaji, Okamoto, & Kurohashi,2004).Sentence compression perhaps one popular text-to-text rewriting methods.aim produce summary single sentence retains importantinformation remaining grammatical (Jing, 2000). appeal sentence compressionlies potential summarization generally document compression, e.g.,displaying text small screens mobile phones PDAs (Vandeghinste & Pan,2004). Much current work literature focuses simplified formulationcompression task allow rewriting operations word deletion.Given input source sentence words x = x1 , x2 , . . . , xn , target compression formedremoving subset words (Knight & Marcu, 2002).Despite restricted word deletion, compression task remains challengingmodeling perspective. Figure 1 illustrates source sentence target compressiontaken one compression corpora used experiments (see Section 5 details).case, hypothetical compression system must apply series rewrite rules orderc2009AI Access Foundation. rights reserved.fiCohn & LapataVPWHNPRBWPexactlyNPVPNPNNSWHNPVBD PRP CCrecordsWPNPWHNPNPVBNWPNNSVBPVBNinvolvedrecordsinvolvedNNS VBPmade onesVPVP(a) SourceVP(b) TargetFigure 1: Example sentence compression showing source target trees. boldsource nodes show terminals need removed produce targetstring.WHNPRBWHNPWPWPNPNPNPVP(1)(2)(3)VPWHNPVPVPWHNPCCWHNPNPVP(4)(5)Figure 2: Example transduction rules, displayed pair tree fragments. left(source) fragment matched node source tree, matchingpart replaced right (target) fragment. Dotted lines denote variablecorrespondences, denotes node deletion.obtain target, e.g., delete leaf nodes exactly and, delete subtrees madeones, merge subtrees corresponding records involved.concretely, system must access rules like shown Figure 2. rulesdisplayed pair tree fragments left fragment corresponds sourceright target. instance, rule (1) states wh-noun phrase (WHNP)consisting adverb (RB) wh-pronoun (WP) (e.g., exactly what) rewrittenwh-pronoun (without adverb). two things note here. First,syntactic information plays important role, since deletion decisions limitedindividual words often span larger constituents. Secondly, large numbercompression rules varying granularity complexity (see rule (5) Figure 2).Previous solutions compression problem cast mostly supervisedlearning setting (for unsupervised methods see Clarke & Lapata, 2008; Hori & Furui, 2004;Turner & Charniak, 2005). Sentence compression often modeled generative framework638fiSentence Compression Tree Transductionaim estimate joint probability P (x, y) source sentence xtarget compression (Knight & Marcu, 2002; Turner & Charniak, 2005; Galley &McKeown, 2007). approaches essentially learn rewrite rules similar shownFigure 4 parsed parallel corpus subsequently use find bestcompression set possible compressions given sentence. approachesmodel compression discriminatively subtree deletion (Riezler, King, Crouch, & Zaenen,2003; Nguyen, Horiguchi, Shimazu, & Ho, 2004; McDonald, 2006).Despite differences formulation, existing models specifically designed sentence compression mind generally applicable tasks requiringcomplex rewrite operations substitutions, insertions, reordering. commonassumption underlying previous work tree structures representing sourcesentences target compressions isomorphic, i.e., exists edge-preservingbijection nodes two trees. assumption valid sentence compression hold rewriting tasks. Consequently, sentence compressionmodels restrictive; cannot readily adapted generation problemssince able handle structural lexical divergences. related issue concerns deletion operations often take place without consideringstructure target compression (the goal generate compressed string rathertree representing it). Without syntax-based language model (Turner & Charniak,2005) explicit generation mechanism licenses tree transformationsguarantee compressions well-formed syntactic structures.straightforward process subsequent generation analysis tasks.paper present sentence compression model deletion-specificaccount ample rewrite operations scales rewriting tasks. formulatecompression problem tree-to-tree rewriting using synchronous grammar (with ruleslike shown Figure 2). Specifically, adopt synchronous tree substitutiongrammar (STSG) formalism (Eisner, 2003) model non-isomorphic tree structuresefficient inference algorithms. show grammar inducedparallel corpus propose discriminative model rewriting taskviewed weighted tree-to-tree transducer. learning framework makes uselarge margin algorithm put forward Tsochantaridis, Joachims, Hofmann, Altun(2005) efficiently learns prediction function minimize given loss function.also develop appropriate algorithm used training (i.e., learningmodel weights) decoding (i.e., finding plausible compression model).Beyond sentence compression, hope work described mightrelevance tasks involving structural matching (see discussion Section 8).remainder paper structured follows. Section 2 provides overviewrelated work. Section 3 presents STSG framework compression modelemploy experiments. Section 5 discusses experimental set-up Section 6presents results. Discussion future work concludes paper.2. Related WorkSynchronous context-free grammars (SCFGs, Aho & Ullman, 1969) generalizationcontext-free grammar (CFG) formalism simultaneously produce strings two639fiCohn & Lapatalanguages. used extensively syntax-based statistical MT. Examplesinclude inversion transduction grammar (Wu, 1997), head transducers (Alshawi, Bangalore,& Douglas, 2000), hierarchical phrase-based translation (Chiang, 2007), several variantstree transducers (Yamada & Knight, 2001; Grael & Knight, 2004).Sentence compression bears resemblance machine translation. Instead translating one language another, translating long sentences shorter oneswithin language. therefore surprising previous work also adoptedSCFGs compression task. Specifically, Knight Marcu (2002) proposed noisychannel formulation sentence compression. model consists two components:language model P (y) whose role guarantee compression output grammatical channel model P (x|y) capturing probability source sentence xexpansion target compression y. decoding algorithm searches compression maximizes P (y)P (x|y). channel model stochastic SCFG,rules extracted parsed parallel corpus weights estimated usingmaximum likelihood. Galley McKeown (2007) show obtain improved SCFGprobability estimates Markovization. Turner Charniak (2005) note SCFGrules expressive enough model structurally complicated compressionsrestricted trees depth 1. remedy supplying synchronous grammar set general special rules. example, allow rules formhNP,NPi h[NP NP 1 CC NP 2 ], NP 1 (boxed subscripts added distinguishtwo NPs).work formulates sentence compression framework synchronous treesubstitution grammar (STSG, Eisner, 2003). STSG allows describe non-isomorphic treepairs (the grammar rules comprise trees arbitrary depth) thus suited textrewriting tasks typically involve number local modifications input text.Especially modification described succinctly terms syntactic transformations, dropping adjectival phrase converting passive verb phrase activeform. STSG restricted version synchronous tree adjoining grammar (STAG, Shieber& Schabes, 1990) without adjunction operation. STAG affords mild context sensitivity,however increased cost inference. SCFG STSG weakly equivalent, is,string languages identical produce equivalent tree pairs. example,Figure 2, rules (1)(4) expressed SCFG rules, rule (5) cannotsource target fragments two level trees. fact would impossibledescribe trees Figure 1 using SCFG. grammar rules therefore generalobtained Knight Marcu (2002) account elaborate treedivergences. Moreover, adopting expressive grammar formalism, naturally model syntactically complex compressions without specify additional rules(as Turner & Charniak, 2005).synchronous grammar license large number compressions given sourcetree. grammar rule typically score overall score compression sentence x derived. Previous work estimates scores generativelydiscussed above. opt discriminative training procedure allows incorporation manner powerful features. use large margin technique proposedTsochantaridis et al. (2005). framework attractive supports configurable loss function, describes extent predicted target tree differs640fiSentence Compression Tree Transductionreference tree. devising suitable loss functions model straightforwardlyadapted text rewriting tasks besides sentence compression.McDonald (2006) also presents sentence compression model uses discriminativelarge margin algorithm. model rich feature set defined compression bigramsincluding parts speech, parse trees, dependency information, without however making explicit use synchronous grammar. Decoding model amounts findingcombination bigrams maximize scoring function defined adjacent wordscompression intervening words dropped. model differsMcDonalds two important respects. First, capture complex tree transformations go beyond bigram deletion. tree-based, decoding algorithmbetter able preserve grammaticality compressed output. Second, treebased representation allows greater modeling flexibility, e.g., defining wide rangeloss functions tree string yield. contrast, McDonald define lossfunctions final compression.Although bulk research sentence compression relies parallel corporamodeling purposes, approaches use training data small amount.example work Hori Furui (2004), propose model automaticallytranscribed spoken text. method scores candidate compressions using languagemodel combined significance score (indicating whether word topical not),score representing speech recognizers confidence transcribing given wordcorrectly. Despite conceptually simple knowledge lean, model operatesword level. Since take syntax account, means deletingconstituents spanning several subtrees (e.g., relative clauses). Clarke Lapata (2008)show unsupervised models greatly improved linguistically motivatedconstraints used decoding.3. Problem Formulationmentioned earlier, formulate sentence compression tree-to-tree rewriting problemusing weighted synchronous grammar coupled large margin training process.model learns parallel corpus input (uncompressed) output (compressed) pairs(x1 , y1 ), . . . , (xn , yn ) predict target labeled tree source labeled tree x.capture dependency x weighted STSG definefollowing section. Section 3.2 discusses extract grammar parallelcorpus. rule score, ngram output tree,overall score compression sentence x derived. introduce scoringfunction Section 3.3 explain training algorithm Section 3.5. frameworkdecoding amounts finding best target tree licensed grammar given sourcetree. present chart-based decoding algorithm Section 3.4.3.1 Synchronous Grammarsynchronous grammar defines space valid source target tree pairs, muchregular grammar defines space valid trees. Synchronous grammars treated treetransducers reasoning space possible sister trees given tree, is,trees produced alongside given tree. essentially transducer641fiCohn & LapataAlgorithm 1 Generative process creating pair trees.initialize source tree, x = RSinitialize target tree, = RTinitialize stack frontier nodes, F = [(RS , RT )]node pairs, (vS , vT ) Fchoose rule hvS , vT h, ,rewrite node vS xrewrite node vTvariables, ufind aligned child nodes, (cS , cT ), vS vT corresponding upush (cS , cT ) Fendendx completetakes tree input produces tree output. grammar rules specifysteps taken transducer recursively mapping tree fragments input treefragments target tree. many families synchronous grammars (seeSection 2), elect use synchronous tree-substitution grammar (STSG). onesimpler formalisms, consequently efficient inference algorithms, stillcomplex enough model rich suite tree edit operations.STSG 7-tuple, G = (NS , NT , , , P, RS , RT ) N non-terminalsterminals, subscripts indicating source target respectively, P productions RS NS RT NT distinguished root symbols.production rewrite rule two aligned non-terminals X NS NTsource target:hX, h, ,(1)elementary trees rooted symbols X respectively. Notesynchronous context free grammar (SCFG) limits one level elementarytrees, otherwise identical STSG, imposes limits. Non-terminalleaves elementary trees referred frontier nodes variables.points recursion transductive process. one-to-one alignment frontiernodes specified . alignment represent deletion (or insertion)aligning node special symbol, indicates node presenttree. nodes aligned , allows subtrees deletedtransduction. disallow converse, -aligned nodes , would licenseunlimited insertion target tree, independently source tree. capabilitywould limited use sentence compression, also increasing complexityinference.grammar productions used generative setting produce pairs trees,transductive setting produce target tree given source tree. Algorithms 12 present pseudo-code processes. generative process (Algorithm 1) startstwo root symbols applies production rewrites symbolsproductions elementary trees. elementary trees might contain frontier nodes,642fiSentence Compression Tree TransductionAlgorithm 2 transduction source tree target tree.Require: complete source tree, x, root node labeled RSinitialize target tree, = RTinitialize stack frontier nodes, F = [(root(x), RT )]node pairs, (vS , vT ) Fchoose rule hvS , vT h, , matches sub-tree rooted vS xrewrite vTvariables, ufind aligned child nodes, (cS , cT ), vS vT corresponding upush (cS , cT ) Fendendcompletecase aligned pairs frontier nodes pushed stack, later rewrittenusing another production. process continues recursive fashion stackempty frontier nodes remaining , point two trees complete.sequence rewrite rules referred derivation, sourcetarget tree recovered deterministically.model uses STSG transductive setting, source tree giventarget tree generated. necessitates different rewriting process,shown Algorithm 2. start source tree, RT , target root symbol,aligned root node source, denoted root(x). choose productionrewrite pair aligned non-terminals productions source side, , matchessource tree. target symbol rewritten using . variablematching node source corresponding leaf node target tree pushedstack later processing.1 process repeats stack empty,therefore source tree covered. complete target tree.use term derivation refer sequence production applications. targetstring yield target tree, given reading non-terminals treeleft right manner.Let us consider compression example Figure 1. tree editing rulesFigure 2 encoded STSG productions Figure 3 (see rules (1)(5)). Production (1),reproduces tree pair (1) Figure 2, production (2) tree pair (2), on. notationFigure 3 (primarily space reasons) uses brackets ([]) indicate constituent boundaries.Brackets surround constituents non-terminal child nodes,terminals, non-terminals bracketed subtrees. boxed indices short-hand notationalignment, . example, rule (1) specify two WP non-terminalsaligned RB node occurs source tree (i.e., heads deleted subtree). grammar rules allow differences non-terminal category sourcetarget, seen rules (2)(4). also allow arbitrarily deep elementary trees,1. Special care must taken aligned variables. Nodes -aligned signify sourcesub-tree point deleted without affecting target tree. reason safelyignore source nodes deleted manner.643fiCohn & Lapata(1)(2)(3)(4)(5)(6)(7)(8)(9)(10)(11)(12)hWHNP, WHNPihS, NPihS, VPihS, VPihS, SihWP, WPihNP, NPihNNS, NNSihVP, VPihVBP, VBPihVP, VPihVBN, VBNiRules perform major tree editsh[WHNP RB WP 1 ], [WHNP WP 1 ]ih[S NP 1 VP ], NP 1h[S NP VP 1 ], VP 1h[S WHNP 1 ], VP 1h[S [S WHNP 1 2 ] [CC and] 3 ], [S WHNP 1 [S NP 2 VP 3 ]]iRules preserve tree structureh[WP what], [WP what]ih[NP NNS 1 ], [NP NNS 1 ]ih[NNS records], [NNS records]ih[VP VBP 1 VP 2 ], [VP VBP 1 VP 2 ]ih[VBP are], [VBP are]ih[VP VBN 1 ], [VP VBN 1 ]ih[VBN involved], [VBN involved]iFigure 3: rules Synchronous Tree Substitution Grammar (STSG) capable generating sentence pair Figure 1. Equivalently, grammar definestransducer convert source tree (Figure 1(a)) target tree(Figure 1(b)). rule rewrites pair non-terminals pair subtrees,shown bracketed notation.evidenced rule (5) trees depth two. Rules (6)(12) completetoy grammar describes tree pair Figure 1. rules copy partssource tree target, terminals (e.g., rule (6)) internal nodes children(e.g., rule (9)).Figure 4 shows grammar used transduce source treetarget tree Figure 1. first steps derivation also shown graphically Figure 5. start source tree, seek transduce root symboltarget root symbol, denoted S/S. first rule applied rule (5) Figure 3; source side, = [S [S WHNP S] [CC and] S], matches root source treerequisite target category, = S. matching part source treerewritten using rules target elementary tree, = [S WHNP [S NP VP]]. threethree variables annotated reflect category transformations requirednode, WHNP/WHNP, S/NP S/VP. process continues leftmostnodes, labeled WHNP/WHNP. Rule (1) (from Figure 3) applied, deletesnodes left child, shown RB/, retains right child. subsequent rule completestransduction WHNP node matching string exactly. algorithm continues visit variable node finishes variable nodes remaining,resulting desired target tree.3.2 Grammarprevious section outlined STSG formalism employ sentence compressionmodel, save one important detail: grammar itself. example, could obtain644fiSentence Compression Tree Transduction[S/S [S [WHNP exactly what] [S [NP records] [VP made it]]][CC and] [S [WHNP which] [S [NP ones] [VP involved]]]]5[S [WHNP/WHNP [RB exactly] [WP what]] [S [S/NP [NP records] [VP made it]][S/VP [WHNP which] [S [NP ones] [VP involved]]]]]1[S [WHNP [WP/WP what]] [S [S/NP [NP records] [VP made it]][S/VP [WHNP which] [S [NP ones] [VP involved]]]]]6[S [WHNP [WP what]] [S [S/NP [NP records] [VP [VBD made] [NP [PRP it]]]]][S/VP [WHNP which] [S [NP ones] [VP [VBP are] [VP [VBN involved]]]]]]]2[S [WHNP [WP what]] [S [NP [NNS/NNS records]][S/VP [WHNP which] [S [NP ones] [VP involved]]]]]8[S [WHNP [WP what]] [S [NP [NNS records]]][S/VP [WHNP which] [S [NP ones] [VP involved]]]]4[S [WHNP what] [S [NP records] [S/VP [NP ones] [VP involved]]]]3[S [WHNP what] [S [NP records] [VP/VP [VP [VBP are] [VP [VBN involved]]]]]]9[S [WHNP what] [S [NP records] [VP [VBP/VBP are] [VP/VP [VBN involved]]]]]10 [S [WHNP what] [S [NP records] [VP [VBP are] [VP/VP [VBN involved]]]]]11 [S [WHNP what] [S [NP records] [VP [VBP are] [VP [VBN/VBN involved]]]]]12 [S [WHNP [WP what]] [S [NP [NNS records]] [VP [VBP are] [VP [VBN involved]]]]]Figure 4: Derivation example sentence pair Figure 1. line shows rewrite step,denoted subscript identifies rule used. frontiernodes shown bold X/Y indicating symbol X must transducedsubsequent steps. sake clarity, internal nodesomitted.synchronous grammar hand, automatically corpus, combination.requirement grammar allows source trees training settransduced corresponding target trees. maximum generality, devisedautomatic method extract grammar parsed, word-aligned parallel compressioncorpus. method maps word alignment constituent level alignmentnodes source target trees. Pairs aligned subtrees next generalized createtree fragments (elementary trees) form rules grammar.first step algorithm find constituent alignment, defineset source target constituent pairs whose yields aligned one anotherword alignment. base approach alignment template method (Och & Ney,2004), uses word alignments define alignments ngrams (called phrasesSMT literature). method finds pairs ngrams least one word onengrams aligned word other, word either ngram alignedword outside ngram. addition, require ngrams syntacticconstituents. formally, define constituent alignment as:C = {(vS , vT ), ((s, t) (vS ) (vT ))(2)(@(s, t) (s (vS ) (vT )))}vS vT source target tree nodes (subtrees), = {(s, t)} set wordalignments (pairs word-indices), () returns yield span subtree (the minimummaximum word index yield) exclusive-or operator. Figure 6 shows645fiCohn & LapataVPWHNPNPRBWPNNSexactlyrecordsVPNPWHNPVBD PRP CCmadeWPNPVPNNS VBPonesVBNinvolvedVPWHNPNPRBWPNNSexactlyrecordsWHNPNPmadeNPVPWHNPVBD PRP CCWPNPVBNinvolvedNPRBWPNNSexactlyrecordsWHNPVPWHNPWHNPVBD PRP CCmadeWPNPVPNNS VBPonesWP NP VPVPNPVPVPNNS VBPonesVBNinvolvedFigure 5: Graphical depiction first two steps derivation Figure 4. sourcetree shown left partial target tree right. Variable nodesshown bold face dotted lines show alignment.word alignment constituent alignments licensed sentence pairFigure 1.next step generalize aligned subtree pairs replacing aligned child subtreesvariable nodes. example, Figure 6 consider pair aligned subtrees[S ones involved] [VP involved], could extract rule:hS,VPi h[S [WHNP [WP which]] [S [NP [NNS ones] [VP [VBP are] [VP [VBN involved]]]]]],[VP [VBP are] [VP [VBN involved]]]i(3)However, rule specific consequently useful transductionmodel. order applied, must see full subtree, highly unlikelyoccur another sentence. Ideally, generalize rule match manysource trees, thereby allow transduction previously unseen structures.example, node pairs labeled (VP1 , VP1 ), (VBP, VBP), (VP2 , VP2 ) (VBN, VBN)generalized nodes aligned constituents (subscripts added distinguish646fiSentence Compression Tree TransductionVPWHNPNPNPVPWHNP NPVPRBWP NNS VBD PRP CC WP NNS VBP VBNexactly records madeones involvedVPWHNP NPVPWP NNS VBP VBNrecords involvedFigure 6: Tree pair word alignments shown binary matrix. dark square indicatesalignment words row column. overlaid rectanglesshow constituent alignments inferred word alignment.two VP nodes). addition, nodes WHNP, WP, NP NNS sourceunaligned, therefore generalized using -alignment signify deletion.perform possible generalizations example,2 would producerule:hS,VPi h[S WHNP 1 ], VP 1(4)many possible rules extracted applying different legalcombinations generalizations (there 45 total example).Algorithm 3 shows minimial (most general) rules extracted.3 resultsminimal set synchronous rules describe tree pair.4 rulesminimal sense cannot made smaller (e.g., replacing subtreevariable) still honoring word-alignment. Figure 7 shows resulting minimalset synchronous rules example Figure 6. seen example,many rules extracted overly general. Ideally, would extract every ruleevery legal combination generalizations, however leads massive number rulesexponential size source tree. address problem allowing limitednumber generalizations skipped extraction process. equivalentaltering lines 4 7 Algorithm 3 first make non-deterministic decision whethermatch ignore match continue descending source tree. recursion depthlimits number matches ignored way. example, allow one2. generalizations mutually exclusive, take highest match trees.3. non-deterministic matching step line 8 allows matching options individually.implemented mutually recursive function replicates algorithm state processdifferent match.4. Algorithm 3 extension Galley, Hopkins, Knight, Marcus (2004) technique extractingSCFG word-aligned corpus consisting (tree, string) pairs.647fiCohn & LapataAlgorithm 3 extract(x, y, A): extracts minimal rules constituent-aligned treesRequire: source tree, x, target tree, y, constituent-alignment,1: initialize source target sides rule, = x, =2: initialize frontier alignment, =3: nodes vS , top-down4:vS null-aligned5:(vS , )6:delete children7:else vS aligned target node(s)8:choose target node, vT{non-deterministic choice}9:call extract(vS , vT , A)10:(vS , vT )11:delete children vS12:delete children vT13:end14: end15: emit rule hroot(), root()i h, ,level recursion extracting rules (S, VP) pair Figure 6, getadditional rules:hS,VPi h[S [WHNP WP ] 1 ], VP 1hS,VPi h[S WHNP [S NP VP 1 ]], VP 1two levels recursion, also get:hS,VPi h[S [WHNP [WP which]] 1 ], VP 1hS,VPi h[S [WHNP [WP which]] [S NP VP 1 ]], VP 1hS,VPi h[S WHNP [S [NP NNS ] VP 1 ]], VP 1hS,VPi h[S WHNP [S NP [VP VBD 1 VP 2 ]]], [VBD 1 VBD 2 ]iCompared rule (4) see specialized rules add useful structurelexicalisation, still sufficiently abstract generalize new sentences, unlikerule (3). number rules exponential recursion depth, fixed depthpolynomial size source tree fragment. set recursion depthsmall number (one two) experiments.guarantee induced rules good coverage unseen trees.Tree fragments containing previously unseen terminals non-terminals, even unseensequence children parent non-terminal, cannot matched grammar productions. case transduction algorithm (Algorithm 2) fail waycovering source tree. However, problem easily remedied adding newrules grammar allow source tree fully covered.5 node5. alternative, equally valid, techniques improving coverage simplify syntax trees.example, done explicitly binarizing large productions (e.g., Petrov, Barrett, Thibaux,& Klein, 2006) implicitly Markov grammar grammar productions (e.g., Collins, 1999).648fiSentence Compression Tree TransductionhS,SihWHNP,WHNPihWP,WPihS,NPihNP,NPihNNS,NNSihS,VPihS,VPihVP,VPihVBP,VBPihVP,VPihVBN,VBNih[S [S WHNP 1 2 ] CC 3 ], [S WHNP 1 [S NP 2 VP 3 ]]ih[WHNP RB WP 1 ], [WHNP WP 1 ]ih[WP what], [WP what]ih[S NP 1 VP ], NP 1h[NP NNS 1 ], [NP NNS 1 ]ih[NNS records], [NNS records]ih[S WHNP 1 ], VP 1h[S NP VP 1 ], VP 1h[VP VBP 1 VP 2 ], [VP VBP 1 VP 2 ]ih[VBP are], [VBP are]ih[VP VBN 1 ], [VP VBN 1 ]ih[VBN involved], [VBN involved]iFigure 7: minimal set STSG rules extracted aligned trees Figure 6.source tree, rule created copy node child nodes target tree.example, see fragment [NP DT JJ NN] source tree, add rule:hNP,NPi h[NP DT 1 JJ 2 NN 3 ], [NP DT 1 JJ 2 NN 3 ]irules, source node copied target tree, therefore transduction algorithm trivially recreate original tree. course, grammarrules work conjunction copying rules produce target trees.copy rules solve coverage problem unseen data, solverelated problem under-compression. occurs unseen CFG productionssource tree therefore applicable grammar rules copy rules,copy child nodes target. None child subtrees deleted unlessparent node deleted higher-level rule, case childrendeleted. Clearly, would add considerable modelling flexibility able delete some,all, children. reason, add explicit deletion rules sourceCFG production allow subsets child nodes deleted linguisticallyplausible manner.deletion rules attempt preserve important child nodes. measureimportance using head-finding heuristic Collins parser (Appendix A, Collins,1999). Collins method finds single head child CFG production using hand-codedtables non-terminal type. desire set child nodes, run algorithmfind matches rather stopping first match. order matchfound used ranking importance child. ordered list child nodesused create synchronous rules retain head 1, heads 12, . . . , heads.649fiCohn & Lapatafragment [NP DT JJ NN], heads found following order (NN, DT,JJ). Therefore create rules retain children (NN); (DT, NN) (DT, JJ, NN):hNP,NPi h[NP DT JJ NN 1 ], [NP NN 1 ]ihNP,NNi h[NP DT JJ NN 1 ], NN 1hNP,NPi h[NP DT 1 JJ NN 2 ], [NP DT 1 NN 2 ]ihNP,NPi h[NP DT 1 JJ 2 NN 3 ], [NP DT 1 JJ 2 NN 3 ]iNote one child remains, rule also produced without parent node,seen second rule above.3.3 Linear ModelSTSG defines transducer capable mapping source tree many possibletarget trees, little use without kind weighting towards grammatical treesconstructed using sensible STSG productions yield fluent compressed target sentences. Ideally model would define scoring function targettrees strings, however instead operate derivations. general, may manyderivations produce target tree, situation referred spurious ambiguity. fully account spurious ambiguity would require aggregating derivationsproduce target tree. would break polynomial-time dynamic program used inference, rendering inference problem NP-complete (Knight, 1999).end, define scoring function derivations:score(d; w) = h(d), wi(5)derivation6 consisting sequence rules, w model parameters,vector-valued feature function operator h, inner product.parameters, w, learned training, described Section 3.5.feature function, , defined as:XX(d) =(r, source(d)) +(m, source(d))(6)rdmngrams(d)r rules derivation, ngrams(d) ngrams yield targettree feature function returning vector feature values rule. Notefeature function access rule, r, also source tree, source(d),conditional model therefore overhead terms modelingassumptions complexity inference.second summand (6), ngrams yield target treefeature function ngrams. Traditional (weighted) synchronous grammarsallow features decompose derivation (i.e., expressed using firstsummand (6)). However, limiting requirement, ngram featuresallow modeling local coherence commonly used sentence compressionliterature (Knight & Marcu, 2002; Turner & Charniak, 2005; Galley & McKeown, 2007;6. derivation, d, fully specifies source, x = source(d), target tree, = target(d).650fiSentence Compression Tree TransductionClarke & Lapata, 2008; Hori & Furui, 2004; McDonald, 2006). instance, deletingsub-tree left right siblings, critical know new siblingsgrammatical configuration, also yield still forms coherent string.reason, allow ngram features, specifically conditional log-probabilityngram language model. Unfortunately, comes price ngram featuressignificantly increase complexity inference used training decoding.3.4 DecodingDecoding aims find best target tree licensed grammar given source tree.mentioned above, deal derivations place target trees. Decoding findsmaximizing derivation, , of:=argmaxscore(d; w)(7)d:source(d)=xx (given) source tree, source(d) extracts source tree derivationscore defined (5). maximization performed space derivationsgiven source tree, defined transduction process shown Algorithm 2.maximization problem (7) solved using chart-based dynamic programshown Algorithm 4. extends earlier inference algorithms weighted STSGs (Eisner, 2003) assume scoring function must decompose derivation,i.e., features apply rules terminal ngrams. Relaxing assumption leadsadditional complications increased time space complexity. equivalent using grammar intersection original grammar ngram languagemodel, explained Chiang (2007) context string transduction SCFG.algorithm defines chart, C, record best scoring (partial) target treesource node vS root non-terminal t. back-pointers, B, record maximizingrule store pointers child chart cells filling variable rule. chartalso indexed n 1 terminals left right edges target trees yieldallow scoring ngram features.7 terminal ngrams provide sufficient context evaluatengram features overlapping cells boundary chart cell combined anotherrule application (this operation performed boundary-ngrams function line15). best illustrated example. Using trigram features, n = 3, noderewritten [NP fast car] must store ngram context (the fast, fast car)chart entry. Similarly [VP skidded halt] would ngram context (skidded to,halt). applying parent rule [S NP VP] rewrites two trees adjacentsiblings need find ngrams boundary NP VP.easily retrieved two chart cells contexts. combine right edge NPcontext, fast car, left edge VP context, skidded to, get two trigramsfast car skidded car skidded to. trigrams fast car, skiddedhalt already evaluated child chart cells. newcombined chart cell given context (the fast, halt) taking left right7. Strictly speaking, terminals right edge required compression model wouldcreate target string left-to-right manner. However, algorithm generalallows reordering rules hPP,PPi h[PP 1 NP 2 ], [PP NP 2 1 ]i. rules requiredtext-rewriting tasks besides sentence compression.651fiCohn & LapataAlgorithm 4 Exact chart based decoding algorithm.Require: complete source tree, x, root node labeled RS1: let C[v, t, l] R chart representing score best derivation transducingtree rooted v tree root category ngram context l2: let B[v, t, l] (P, x NT L) corresponding back-pointers, consistingproduction source node, target category ngram contextproductions variables3: initialize chart, C[, , ] =4: initialize back-pointers, B[, , ] = none5: source nodes, vS x, bottom-up6:rules, r = hvS , h, , matches sub-tree rooted vS7:let target ngrams wholly contained8:let features vector, (r, x) + (m, x)9:let l empty ngram context10:let score, q 011:variables, u12:find source child node, cu , vS corresponding u13:let tu non-terminal target child node corresponding u14:choose child chart entry, qu = C[cu , tu , lu ]{non-deterministic choice lu }15:let boundary-ngrams(r, lu )16:update features, + (m, x)17:update ngram context, l merge-ngram-context(l, lu )18:update score, q q + qu19:end20:update score, q q + h, wi21:q > C[vS , Y, l]22:update chart, C[vS , Y, l] q23:update back-pointers, B[vS , Y, l] (r, {(cu , tu , lu )u})24:end25:end26: end27: find best root chart entry, l argmaxl C[root(x), RT , l]28: create derivation, d, traversing back-pointers B[root(x), RT , l ]edges two child cells. merging process performed merge-ngram-contextfunction line 17. Finally add artificial root node target tree n 1 artificialstart terminals one end terminal. allows ngram features appliedboundary ngrams beginning end target string.decoding algorithm processes source tree post-order traversal, findingset possible trees ngram contexts source node insertingchart. rules match node processed lines 624. feature vector,, calculated rule ngrams therein (line 8), ngrams bordering childcells filling rules variables (line 16). Note feature vector includesfeatures specific rule boundary ngrams, wholly contained652fiSentence Compression Tree Transductionchild cell. reason score sum scores child cell (line18) feature vector model weights (line 20). new ngram context, l,calculated combining rules frontier ngram contexts child cells (line17). Finally chart entry node updated score betters previous value(lines 2124).choosing child chart cell entry line 14, many different entriesdifferent ngram context, lu . affects ngram features, , consequentlyngram context, l, score, q, rule. non-determinism means everycombination child chart entries chosen variable, combinationsevaluated inserted chart. number combinations productnumber child chart entries variable. bounded O(|TT |2(n1)V )|TT | size target lexicon V number variables. Thereforeasymptotic time complexity decoding O(SR|TT |2(n1)V ) numbersource nodes R number matching rules node. high complexityclearly makes exact decoding infeasible, especially either n V large.adopt popular approach syntax-inspired machine translation addressproblem (Chiang, 2007). Firstly, use beam-search, limits number differentngram contexts stored chart cell constant, W . changes basecomplexity term, leading improved O(SRW V ) still exponentialnumber variables. addition, use Chiangs cube-pruning heuristiclimit number combinations. Cube-pruning uses heuristic scoring functionapproximates conditional log-probability ngram language model logprobability unigram model.8 allows us visit combinations best-firstorder heuristic scoring function beam filled.The beam rescoredusing correct scoring function. done cheaply O(W V ) time, leadingoverall time complexity decoding O(SRW V ). refer interested readerwork Chiang (2007) details.3.5 Trainingturn problem derivations scored model. given sourcetree, space sister target trees implied synchronous grammar often large,majority trees ungrammatical poor compressions. jobtraining algorithm find weights reference target trees high scoresmany target trees licensed grammar given lower scores.explained Section 3.3 define scoring function derivations. functiongiven (5) (7), reproduced below:f (d; w) =argmax hw, (d)i(8)d:source(d)=xEquation (8) finds best scoring derivation, d, given source, x, linear model.Recall derivation generates source tree x target tree. goal8. use conditional log-probability ngram language model ngram feature. orderuse ngram features, binary identity features specific ngrams, would first advisableconstruct approximation decomposes derivation use cube-pruning heuristic.653fiCohn & Lapatatraining procedure find parameter vector w satisfies condition:i, : source(d) = xi 6= di : hw, (di ) (d)i 0(9)xi , di ith training source tree reference derivation. condition statestraining instances reference derivation least high scoringderivations. Ideally, would also like know extent predicted targettree differs reference tree. example, compression differs goldstandard respect one two words treated differently compressionbears resemblance it. Another important factor length compression.Compressions whose length similar gold standard preferable longershorter output. loss function (yi , y) quantifies accuracy predictionrespect true output value yi .plethora different discriminative training frameworks optimizelinear model. Possibilities include perceptron training (Collins, 2002), log-linear optimisation conditional log-likelihood (Berger, Pietra, & Pietra, 1996) large marginmethods. base training Tsochantaridis et al.s (2005) framework learningSupport Vector Machines (SVMs) structured output spaces, using SVMstruct implementation.9 framework supports configurable loss function particularlyappealing context sentence compression generally text-to-text generation. also efficient training algorithm powerful regularization. lattercritical discriminative models large numbers features, would otherwiseover-fit training sample expense generalization accuracy. briefly summarizeapproach below; detailed description refer interested readerwork Tsochantaridis et al. (2005).Traditionally SVMs learn linear classifier separates two classeslargest possible margin. Analogously, structured SVMs attempt separate correctstructure structures large margin. learning objectivestructured SVM uses soft-margin formulation allows errors training setvia slack variables, :n1CXmin ||w||2 +, 0w, 2n(10)i=1i, : source(d) = xi 6= di : hw, (di ) (d)i (di , d)slack variables, , introduced training example, xi C constantcontrols trade-off training error minimization margin maximization.Note slack variables combined loss incurred linear constraints. means high loss output must separated larger marginlow loss output, much larger slack variable satisfy constraint. Alternatively, loss function used rescale slack parameters, caseconstraints (10) replaced hw, (di ) (d)i 1 (dii ,d) . Margin rescalingtheoretically less desirable scale invariant, therefore requires tuningadditional hyperparameter compared slack rescaling. However, empirical results show9. http://svmlight.joachims.org/svm_struct.html654fiSentence Compression Tree Transductionlittle difference two rescaling methods (Tsochantaridis et al., 2005). usemargin rescaling practical reason approximated accuratelyslack rescaling chart based inference method.optimization problem (10) approximated using algorithm proposedTsochantaridis et al. (2005). algorithm finds small set constraints fullsized optimization problem ensures sufficiently accurate solution. Specifically,constructs nested sequence successively tighter relaxation original problem using(polynomial time) cutting plane algorithm. training instance, algorithmkeeps track selected constraints defining current relaxation. Iteratingtraining examples, proceeds finding output radically violatesconstraint. case, optimization crucially relies finding derivationhigh scoring high loss compared gold standard. requires findingmaximizer of:H(d) = (d , d) hw, (di ) (d)i(11)search maximizer H(d) (11) performed decoding algorithm presented Section 3.4 extensions. Firstly, expanding (11)H(d) = (d , d) h(di ), wi + h(d), wi see second term constantrespect d, thus influence search. decoding algorithm maximizeslast term, remains include loss function search process.Loss functionsdecomposerules target ngrams derivation,PP, r) +(d(d , d) =nngrams(d) N (d , n), easily integratedrd Rdecoding algorithm. done adding partial loss, R (d , r) + N (d , n)rules score line 20 Algorithm 4 (the ngrams recovered ngram contextsmanner used evaluate ngram features).However, many loss functions decompose rules ngrams.order calculate losses chart must stratified loss functions arguments(Joachims, 2005). example, unigram precision measures ratio correctly predictedtokens total predicted tokens therefore loss arguments pair counts,(T P, F P ), true false positives. initialized (0, 0) updatedrule used derivation. equates checking whether target terminalreference string incrementing relevant value. chart extended (stratified)store loss arguments way ngram contexts stored decoding.means rule accessing child chart cell get multiple entries,different loss argument values well multiple ngram contexts (line 14 Algorithm4). loss argument rule application calculated rule lossarguments children. stored chart back-pointer list (lines2223 Algorithm 4). Although loss evaluated correctly completederivations, also evaluate loss partial derivations part cube-pruningheuristic. Losses large space argument values coarsely approximatedbeam search, prunes number chart entries constant size.reason, focused mainly simple loss functions relatively small spaceargument values, also use wide beam search (200 unique items 500items, whichever comes first).655fiCohn & LapataAlgorithm 5 Find gold standard derivation pair trees (i.e., alignment).Require: source tree, x, target tree,1: let C[vS , vT ] R chart representing maximum number rules used alignnodes vS x vT2: let B[vS , vT ] (P, x y) corresponding back-pointers, consisting productionpair aligned nodes productions variables3: initialize chart, C[, ] =4: initialize back-pointers, B[, ] = none5: source nodes, vS x, bottom-up6:rules, r = hvS , h, , matches sub-tree rooted vS7:target nodes, vT y, matching8:let rule count, j 19:variables, u10:find aligned child nodes, (cS , cT ), vS vT corresponding u11:update rule count, j j + C[cS , cT ]12:end13:n greater previous value chart14:update chart, C[vS , vT ] j15:update back-pointers, B[vS , vT ] (r, {(cS , cT )u})16:end17:end18:end19: end20: C[root(x), root(y)] 6=21:success; create derivation traversing back-pointers B[root(x), root(y)]22: enddiscussion far assumed given gold standard derivation, yiglossing issue find it. Spurious ambiguity grammar meansoften many derivations linking source target, none clearlycorrect. select derivation using maximum number rules,small, therefore provide maximum generality.10 found using Algorithm 5,chart-based dynamic program similar alignment algorithm inverse transductiongrammars (Wu, 1997). algorithm time complexity O(S 2 R) sizelarger two trees R number rules match node.3.6 Loss Functionstraining algorithm described highly modular theory support widerange loss functions. widely accepted evaluation metric text compression. zero-one loss would straightforward define inappropriate problem,10. also experimented heuristics, including choosing derivation random selectingderivation maximum minimum score model (all using search algorithmdifferent objective). these, maximum scoring derivation competitivemaximum rules heuristic.656fiSentence Compression Tree Transductionwould always penalize target derivations differ even slightly referencederivation. Ideally, would like loss wider scoring range discriminatederivations differ reference. may good compressions whereas others may entirely ungrammatical. reason developedrange loss functions draw inspiration various metrics used evaluatingtext-to-text rewriting tasks summarization machine translation.Loss functions defined derivations look item accessible includingtokens, ngrams CFG rules. first class loss functions calculates Hammingdistance unordered bags items. measures number predicted itemsappear reference, along penalty short output:hamming (d , d) = F P + max (l (T P + F P ), 0)(12)P F P number true false positives, respectively, comparingpredicted target, dT , reference, dT , l length reference.include second term penalize overly short output otherwise predicting littlenothing would incur penalty.created three instantiations loss function (12) over: 1) tokens,2) ngrams (n 3), 3) CFG productions. case, loss argument spacequadratic size source tree. Hamming ngram loss attempt definingloss function similar BLEU (Papineni, Roukos, Ward, & Zhu, 2002). latterdefined documents rather individual sentences, thus directly applicableproblem. Now, since losses operate unordered bags may rewarderroneous predictions, example, permutation reference tokens zerotoken-loss. less problem CFG ngram losses whose items overlap,thereby encoding partial order. Another problem loss functions describedpenalize multiply predicting item occurred reference. could problem function words common sentences.Therefore developed two additional loss functions take multiple predictionsaccount. first measures edit distance number insertions deletionspredicted reference compressions, bags-of-tokens. contrastprevious loss functions, requires true positive counts clippednumber occurrences type reference. edit distance given by:Xedit (d , d) = p + r 2min(pi , qi )(13)p q denote number target tokens predicted tree, target(d),reference, = target(d ), respectively, pi qi counts type i. lossarguments edit distance consist vector counts item typereference, {pi , i}. space possible values exponential size source tree,compared quadratic Hamming losses. Consequently, expect beam searchresult many search errors using edit distance loss.last loss function F1 measure, harmonic mean precision recall,measured bags-of-tokens. edit distance, calculation requires countsclipped number occurrences terminal type reference.657fiCohn & LapataRef:Pred:[S [WHNP [WP what]] [S [NP [NNS records]] [VP [VBP are] [VP [VBN involved]]]]][S [WHNP [WP what]] [S [NP [NNS ones]] [VP [VBP are] [VBN involved]]]]LossToken Hamming3-gram HammingCFG HammingEdit distanceF1ArgumentsP = 3, F P = 1P = 8, F P = 5P = 8, F P = 1p = (1, 0, 1, 1, 1)p = (1, 0, 1, 1, 1)Value1/45/141/921/4Table 1: Loss arguments values example predicted reference compressions.Note loss values compared different loss functions;values purely illustrative.therefore use loss arguments calculation. F1 loss given by:F1 (d , d) = 1Pmin(p ,q )2 precision recallprecision + recallP(14)min(p ,q )precision = p recall = q . F1 shares argumentsedit distance loss, also exponential space loss argument valuesconsequently subject severe pruning beam search used training.illustrate loss functions, present example Table 1. Here,prediction (Pred) reference (Ref) length (4 tokens), identical syntacticstructure, differ one word (ones versus records). Correspondingly, threecorrect tokens one incorrect, forms arguments token Hamming loss,resulting loss 1/4. ngram loss measured n 3 start endstring padded special symbols allow evaluation boundary ngrams.CFG loss records one incorrect CFG production (the preterminal [NNS ones])total nine productions. last two losses use arguments: vector valuescounts reference type. first four cells correspond what, records,involved, last cell records types. example, edit distance two(one deletion one insertion) F1 loss 1/4 (precision recall 3/4).4. Featuresfeature space defined source trees, x, target derivations, d. devised twobroad classes features, applying grammar rules ngrams target terminals.defined single ngram feature, conditional log-probability trigram languagemodel. trained BNC (100 million words) using SRI Language Modelingtoolkit (Stolcke, 2002), modified Kneser-Ney smoothing.rule hX,Y h, , i, extract features according templates detailedbelow. templates give rise binary indicator features, except explicitly stated.features perform boolean test, returning value 1 test succeeds 0otherwise. example rule corresponding features shown Table 2.658fiSentence Compression Tree TransductionType: Whether rule extracted training set, created copy rule and/orcreated delete rule. allows model learn preferencethree sources grammar rules (see row Type Table 2)Root: root categories source, X, target, , conjunction, X(see rows Root Table 2).Identity: source side, , target side, , full rule, (, , ). allowsmodel learn weights individual rules sharing elementary tree. Another feature checks rules source target elementary trees identical, =(see rows Identity Table 2).Unlexicalised Identity: identity feature templates replicated unlexicalised elementary trees, i.e., terminals removed frontiers (seerows UnlexId Table 2).Rule count: feature always 1, allowing model count number rulesused derivation (see row Rule count Table 2).Word count: Counts number terminals , allowing global preferenceshorter longer output. Additionally, record number terminalssource tree, used target terminal count find numberdeleted terminals (see rows Word count Table 2).Yield: features compare terminal yield source, (), target, ().first feature checks identity two sequences, () (). use identityfeatures terminal yields, terminal source (seerows Yield Table 2). also replicate feature templates sequencenon-terminals frontier (pre-terminals variable non-terminals).Length: Records difference lengths frontiers , whethertargets frontier shorter source (see rows Length Table 2).features listed defined rules grammar. includescopy delete rules, described Section 3.2, added addressproblem unseen words productions source trees test time. Manyrules applied training set, receive weight sharefeatures rules used training. However, training model learnsdisprefer coverage rules unnecessary model training set,described perfectly using extracted transduction rules. dual use trainingset grammar extraction parameter estimation results bias coveragerules. bias could addressed extracting grammar separate corpus,case coverage rules would useful modeling training settesting sets. However, solution problems, namely many targettrees training may longer reachable. bias possible solutionsinteresting research problem deserves work.659fiCohn & LapataRule: hNP,NNSi h[NP CD ADJP [NNS activists]], [NNS activists]iTypetype = training set1RootX = NP1Root= NNS1RootX = NP = NNS1Identity= [NP CD ADJP [NNS activists]]1Identity= [NNS activists]1Identity = [NP CD ADJP [NNS activists]] = [NNS activists]1UnlexId.unlex. = [NP CD ADJP NNS]1UnlexId.unlex. = NNS1UnlexId.unlex. = [NP CD ADJP NNS] = NNS1Rule count1Word counttarget terminals1Word countsource terminals 1Yieldsource = [activists] target = [activists]1Yieldterminal activists source target1Yieldnon-terms. source = [CD, ADJP, NNS] target = [NNS]1Yieldnon-terminal CD source target1Yieldnon-terminal ADJP source target1Yieldnon-terminal NNS source target1Lengthdifference length2Lengthtarget shorter1Table 2: Features instantiated synchronous rule shown above. featuresnon-zero values displayed. number source terminals calculated usingsource tree time rule applied.5. Experimental Set-upsection present experimental set-up assessing performancesentence compression model described above. give details corpora used, brieflyintroduce McDonalds (2006) model used comparison approach, explainsystem output evaluated.5.1 Corporaevaluated system three publicly available corpora. first Ziff-Daviscorpus, popular choice sentence compression literature. corpus originatescollection news articles computer products. created automaticallymatching sentences occur article sentences occur abstract (Knight& Marcu, 2002). two corpora11 created manually; annotators askedproduce target compressions deleting extraneous words source without changingword order (Clarke & Lapata, 2008). One corpus sampled written sources,11. Available http://homepages.inf.ed.ac.uk/s0460084/data/.660fiSentence Compression Tree TransductionCorpusCLspokenCLwrittenZiff-DavisArticles5082Sentences137014331084Training8829081020Development786332Testing41046232Table 3: Sizes various corpora, measured articles sentence pairs. data splittraining, development testing sets measured sentence pairs.British National Corpus (BNC) American News Text corpus, whereascreated manually transcribed broadcast news stories. henceforth refertwo corpora CLwritten CLspoken, respectively. sizes threecorpora shown Table 3.three corpora pose different challenges hypothetical sentence compressionsystem. Firstly, representative different domains text genres. Secondly,different compression requirements. Ziff-Davis corpus aggressivelycompressed comparison CLspoken CLwritten (Clarke & Lapata, 2008). CLspoken speech corpus, often contains incomplete ungrammatical utterancesspeech artefacts disfluencies, false starts hesitations. utterances varying lengths, wordy whereas others cannot reduced further. meanscompression system leave sentences uncompressed. Finally,note CLwritten average longer sentences Ziff-Davis CLspoken. Parserslikely make mistakes long sentences could potentially problematicsyntax-based systems like one presented here.Although model capable performing editing operation, reorderingsubstitution, learn training corpora. corpora containdeletions, therefore model learn transduction rules encoding, e.g.,reordering. Instead rules encode deleting inserting terminals restructuring internal nodes syntax tree. However, model capable general textrewriting, given appropriate training set learn perform additionaledits. demonstrated recent results adapting model abstractivecompression (Cohn & Lapata, 2008), edit permitted, deletion.experiments CLspoken CLwritten followed Clarke Lapatas (2008) partition training, test, development sets. partition sizes shown Table 3.case Ziff-Davis corpus, Knight Marcu (2002) defined developmentset. Therefore randomly selected (and held-out) 32 sentence pairs trainingset form development set.5.2 Comparison State-of-the-Artevaluated results McDonalds (2006) discriminative model. approach,sentence compression formalized classification task: pairs words sourcesentence classified adjacent target compression. Let x = x1 , . . . , xNdenote source sentence target compression = y1 , . . . , yM yi occursx. function L(yi ) {1 . . . N } maps word yi target index word661fiCohn & Lapatasource (subject constraint L(yi ) < L(yi+1 )). McDonald defines scorecompression sentence x dot product high dimensional featurerepresentation, f , bigrams corresponding weight vector, w,score(x, y; w) =Xhw, f (x, L(yj1 ), L(yj ))i(15)i=2Decoding framework amounts finding combination bigrams maximizescoring function (15). maximization solved using semi-Markov Viterbialgorithm (McDonald, 2006).model parameters estimated using Margin Infused Relaxed Algorithm(MIRA Crammer & Singer, 2003), discriminative large-margin online learning technique.McDonald (2006) uses similar loss function Hamming loss (see (12)) withoutexplicit length penalty. loss function counts number words falsely retaineddropped predicted target relative reference. McDonald employs rich featureset defined words, parts speech, phrase structure trees, dependencies.gathered adjacent words compression words dropped.Clarke Lapata (2008) reformulate McDonalds (2006) model context integerlinear programming (ILP) augment constraints ensuring compressedoutput grammatically semantically well formed. example, target sentencenegation, must included compression; source verb subject,must also retained compression. generate solve ILP everysource sentence using branch-and-bound algorithm. Since obtain performanceimprovements McDonalds model several corpora, also use comparisonmodel.summarize, believe McDonalds (2006) model good basis comparisonseveral reasons. First, good performance, treated state-of-theart model. Secondly, similar model many respects training algorithmfeature space differs one important respect: compression performedstrings trees. McDonalds system make use syntax trees,peripherally via feature set. contrast, syntax tree integral partmodel.5.3 Evaluationline previous work assessed models output eliciting human judgments.Following Knight Marcu (2002), conducted two separate experiments. firstexperiment participants presented source sentence target compressionasked rate well compression preserved important informationsource sentence. second experiment, asked rate grammaticalitycompressed outputs. cases used five point rating scale highnumber indicates better performance. randomly selected 20 sentences testportion corpus. sentences compressed automatically systemMcDonalds (2006) system. also included gold standard compressions. materialsthus consisted 180 (20 3 3) source-target sentences. Latin square design ensuredsubjects see two different compressions sentence. collected662fiSentence Compression Tree Transductionratings 30 unpaid volunteers, self reported native English speakers. studiesconducted Internet using WebExp,12 software package running Internetbased experiments.also report results using F1 computed grammatical relations (Riezler et al.,2003). Although F1 conflates grammaticality importance single score, nevertheless shown correlate reliably human judgments (Clarke & Lapata,2006). Furthermore, usefully employed development feature engineering parameter optimization experiments. measured F1 directed labeleddependency relations. models compressed output parsed using RASPdependency parser (Briscoe & Carroll, 2002). Note could extract dependencies directly output model since generates trees addition strings. However,refrained order compare models equal footing.6. Resultsframework presented Section 3 quite flexible. Depending grammar extraction strategy, choice features, loss function, different classes models derived.presenting results test set discuss specific model employedexperiments explain parameters instantiated.6.1 Model Selectionparameter tuning model selection experiments conducted development set CLspoken corpus. obtained syntactic analyses source targetsentences Bikels (2002) parser. corpus automatically aligned using algorithm finds set deletions transform source target.equivalent minimum edit distance script deletion operations permitted.expected, predicted parse trees contained number errors, althoughgold standard trees quantify error effect predictionoutput. notice, however, errors source trees test set alwaysnegatively affect performance model. many instances model ablerecover errors still produce good output compressions. recoveries,cases involved either deleting erroneous structure entirely preserving it.often resulted poor output tree, string yield acceptable cases. Lesscommonly, model corrected errors source using tree transformation rules.rules acquired training set errors source treetest tree. example, one transformation allows prepositional phrasemoved high VP attachment object NP attachment.obtained synchronous tree substitution grammar CLspoken corpus usingmethod described Section 3.2. extracted maximally general synchronous rules.complemented specified rules allowing recursion one ancestorgiven node.13 Grammar rules represented features described Section 4.important parameter modeling framework choice loss function.12. See http://www.webexp.info/.13. Rules pruned 5 variables 15 nodes.663fiCohn & LapataLossesHamming (tokens)Hamming (ngram)Hamming (CFG)Edit DistanceF1ReferenceRating3.383.283.223.303.154.28Std. dev1.051.130.911.201.130.70Table 4: Mean ratings system output (CLspoken development set) using differentloss functions.evaluated loss functions presented Section 3.6 follows. performed grid searchhyper-parameters (a regularization parameter feature scaling parameter,balances magnitude feature vectors scale loss function)14minimized relevant loss development set, used corresponding systemoutput. gold standard derivation selected using maximum number rulesheuristic, described Section 3.5. beam limited 100 unique items 200 itemstotal. grammar filtered allow 50 target elementary treesevery source elementary tree.next asked two human judges rate scale 1 5 systems compressionsoptimized different loss functions. get idea quality outputalso included human-authored reference compressions. Sentences given high numbersgrammatical preserved important information. mean ratingsshown Table 4. seen differences among losses large,standard deviation high. Hamming loss tokens performed bestmean rating 3.38, closely followed edit distance (3.30). chose formerlatter less coarsely approximated search. subsequent experimentsreport results using token-based Hamming loss.also wanted investigate synchronous grammar influences performance.default system described used general rules together specialized rulesrecursion depth limited one. also experimented grammar usesspecialised rules maximum recursion depth two grammar uses solelymaximally general rules. Table 5 report average compression rate, relations-basedF1 Hamming loss tokens different grammars. see addingspecified rules allows better F1 (and loss) despite fact search spaceremains same. observe slight degradation performance moving depth 2rules. probably due increase spurious ambiguity affecting search quality,also allowing greater overfitting training data. number transduction rulesgrammar also grows substantially increased depth 20,764maximally general extraction technique 33,430 62,116 specified rules depth14. found setting regularization parameter C = 0.01 scaling parameter 1 generallyyields good performance across loss functions.664fiSentence Compression Tree TransductionModelmax general rulesdepth 1-specified rulesdepth 2-specified rulesmax rulesmax scoringunigram LMbigram LMtrigram LMfeaturesrule featurestoken featuresCompression rate80.7979.7279.7179.7281.0376.8383.1279.7279.7283.0685.10Relations F165.0468.5666.4468.5665.5459.0567.7168.5668.5667.5168.31Loss341315328315344336317315315346341Table 5: Parameter exploration feature ablation studies (CLspoken development set).default system shown asterisk.1 2, respectively. growth grammar size exponential specificationdepth therefore small values used.also inspected rules obtained maximally general extraction techniquebetter assess rules differ obtained vanilla SCFG (see Knight &Marcu, 2002). Many rules (12%) deeper structure therefore wouldlicensed SCFG. due structural divergences source targetsyntax trees training set. 13% rules describe change syntacticcategory (X 6= ), therefore remaining 76% rules would allowableKnight Marcus transducer. proportion SCFG rules decreases substantiallyrule specification depth increased.Recall Section 3.3 scoring function defined derivations rathertarget trees strings, treat derivation using maximum number rulesgold standard derivation. sanity check, also experimented selectingderivation maximum score model. results Table 5 indicatelatter strategy effective selecting derivation maximum numberrules. conjecture due overfitting. training data usedextract grammar, derivations maximum score may consist rulesrare features model data well generalize unseen instances.Finally, conducted feature ablation study assess features usefultask. particularly interested see ngram features would bringbenefit, especially since increase computational complexity decodingtraining. experimented unigram, bigram, trigram language model. Noteunigram language model computationally expensive two modelsneed record ngram contexts chart. shown Table 5,unigram language model substantially worse bigram trigram deliversimilar performances. also examined impact features groupingtwo broad classes, defined rules defined tokens. aimsee whether underlying grammar (represented rule-based features) contributes665fiCohn & Lapatabetter compression output. results Table 5 reveal two feature groupsperform comparably. However, model using token-based features tends compressless. features highly lexicalized, model able generalize wellunseen data. conclusion, full feature set better counts twoablation sets, better compression rate.results reported measured string output. done firststripping tree structure compression output, reparsing, extracting dependencyrelations finally comparing dependency relations reference. However,may wish measure quality trees themselves, string yield.simple way measure this15 would extract dependency relations directlyphrase-structure tree output.16 Compared dependencies extracted predictedparses using Bikels (2002) parser output string, observe relation F1score increases uniformly tasks, 2.50% 4.15% absolute. Thereforesystems tree output better encodes syntactic dependencies tree resultingre-parsing string output. system part NLP pipeline, outputdestined down-stream processing, accurate syntax tree extremelyimportant. also true related tasks desired output tree, e.g.,semantic parsing.7. Model Comparisonsection present results test set using best performing modelprevious section. model uses grammar unlexicalized lexicalized rules(recursion depth 1), Hamming loss based tokens, features Section 4.model trained separately corpus (training portion). first discussresults using relations F1 move human study.Table 6 illustrates performance model (Transducer1) CLspoken, CLwritten, Ziff Davis. also report results corpora using McDonalds (2006)model (McDonald) improved version (Clarke ILP) put forward ClarkeLapata (2008). also present compression rate system reference goldstandard. cases tree transducer model outperforms McDonalds original modelimproved ILP-based version.Nevertheless, may argued model unfair advantage sincetends compress less models, therefore less likely make manymistakes. ensure case, created version modelcompression rate similar McDonald. done relatively straightforwardlymanipulating length penalty Hamming loss. smaller penaltywords model tend drop. Therefore, varied length penalty (andhyper-parameters) development set order obtain compression rate similar15. could alternatively measure tree metrics, tree edit distance. However, standardmeasures used parser evaluation (e.g., EVALB) would suitable, assume parseyield fixed. case reference target string often different systems output.16. extract dependency relations conversion tool CoNLL 2007 shared task, availablehttp://nlp.cs.lth.se/pennconverter/.666fiSentence Compression Tree TransductionModelTransducer1Transducer2McDonaldClarke ILPReferenceCLspokenCompression rate82.3069.8968.5677.7076.11Relations F166.6359.5847.4854.12ModelTransducer1Transducer2McDonaldClarke ILPReferenceCLwrittenCompression rate76.5261.0960.1271.9970.24Relations F158.0249.4848.3954.84ModelTransducer1McDonaldClarke ILPReferenceZiff DavisCompression rate67.4566.2648.6756.61Relations F156.5554.1246.77Table 6: Results CLspoken, CLwritten, Ziff Davis corpus (testing set); compressionrate relations-based F1.McDonald.17 model applied test set performance shownTable 6 Transducer2. refrained Ziff-Davis, since originaltransducer obtained compression rate comparable McDonald (67.45 vs. 66.26).seen, Transducer2 yields better F1 CLspoken CLwritten. differencesF1 statistically significant using Wilcoxon test (p < 0.01). Transducer1numerically outperforms McDonald Ziff-Davis, however difference significant(the Ziff-Davis test set consists solely 32 sentences).next consider results judgment elicitation study assessesdetail quality generated compressions. Recall participants judge compressed output two dimensions, grammaticality importance. comparedoutput system (Transducer2 CLspoken CLwritten Transducer1Ziff-Davis) output McDonald (2006) reference gold standard. Table 7illustrates examples compressions participants saw.17. matched compression rate McDonald scaling length penalty 0.50 0.25CLwritten CLspoken corpora, respectively. Another way control compression rate wouldmodify chart-based decoder fashion similar McDonald (2006). However, leavefuture work.667fiCohn & LapataS: wish parents teachers could like teacher,could communicate.M: wish teachers could like teacher.T: wish teachers could like this, could communicate.R: wish parents teachers could like this, couldcommunicate.S: Treasury refusing fund phase city technologycolleges.M: Treasury refusing fund colleges.T: Treasury refusing fund city technology colleges.R: Treasury refusing fund city technology colleges.S: Apparel makers use design clothes quickly producedeliver best-selling garments.M: Apparel makers use design clothes produce deliverbest-selling garments.T: Apparel makers use design clothes.R: Apparel makers use design clothes.S: Earlier week, conference call analysts, bank said boostedcredit card reserves $350 million.M: Earlier said credit card reserves $350 million.T: conference call analysts, bank boosted card reserves $350million.R: conference call analysts bank said boosted credit cardreserves $350 million.Table 7: Compression examples CLspoken, CLwritten, Ziff-Davis (S: source sentence, M: McDonald, 2006, T: transducer, R: reference gold standard)Table 8 shows mean ratings18 system (and reference) CLspoken,CLwritten, Ziff-Davis. carried Analysis Variance (Anova) examineeffect system type (McDonald, Transducer, Reference) compression ratings. Anova revealed reliable effect three corpora. used post-hoc Tukeytests examine whether mean ratings system differed significantly (p < 0.01).CLspoken corpus Transducer perceived significantly better McDonald, terms grammaticality importance. obtain resultCLwritten corpus. two systems achieve similar performances Ziff-Davis (thegrammaticality importance score differ significantly). Ziff-Davis seemsless challenging corpus CLspoken CLwritten less likely highlight differences among systems. example, Turner Charniak (2005) present several variantsnoisy-channel model, achieve compressions similar quality Ziff-Davis(grammaticality ratings varied 0.13 informativeness ratings 0.31human evaluation). cases Transducer McDonald yield significantly18. statistical tests reported subsequently done using mean ratings.668fiSentence Compression Tree TransductionModelTransducerMcDonaldReferenceCLspokenGrammaticality4.182.744.58Importance3.982.514.22ModelTransducerMcDonaldReferenceCLwrittenGrammaticality4.063.054.52Importance3.212.823.70ModelTransducerMcDonaldReferenceZiff-DavisGrammaticality4.073.984.65Importance3.233.224.12Table 8: Mean ratings compression output elicited humans ( : sig. diff. McDonald ( < 0.01); : sig. diff. Reference ( < 0.01); using post-hoc Tukeytests)worse performance Reference, save one exception. CLspoken corpus,significant difference Transducer gold standard.results indicate highly expressive framework good model sentence compression. several experimental conditions, across different domains,obtain better performance previous work. Importantly, model describedcompression-specific, could easily adapted tasks, corpora languages (forsyntactic analysis tools available). supervised, model learns fitcompression rate training data. sense, somewhat inflexible cannoteasily adapt specific rate given user imposed application (e.g.,displaying text small screens). Nevertheless, compression rate indirectly manipulated adopting loss functions encourage discourage compression directlydecoding stratifying chart length (McDonald, 2006).8. Conclusionspaper formulated sentence compression tree-to-tree rewriting task.19developed system licenses space possible rewrites using tree substitution grammar. grammar rule assigned weight learned discriminativelywithin large margin model (Tsochantaridis et al., 2005). specialized algorithm usedlearn model weights find best scoring compression model. argue19. source code freely available http://homepages.inf.ed.ac.uk/tcohn/t3.669fiCohn & Lapataproposed framework appealing several reasons. synchronous grammarprovides expressive power capture rewrite operations go beyond word deletionreordering, changes non-terminal categories lexical substitution. Sincedeletion-specific, model could ported rewriting tasks (see Cohn & Lapata,2008, example) without overhead devising new algorithms decodingtraining. Moreover, discriminative nature learning algorithm allows incorporation manner powerful features. rich feature space conjunctionchoice appropriate loss function afford greater flexibility fitting empiricaldata different domains tasks.evaluated model three compression corpora (CLspoken, CLwritten, ZiffDavis) showed cases yields results superior state-of-the-art (McDonald, 2006). experiments also designed assess several aspects proposedframework complexity synchronous grammar, choice loss function,effect various features, quality generated tree output. observedperformance improvements allowing maximally general grammar rules specifiedonce, producing larger lexicalized rules. concurs Galley McKeown(2007) also find lexicalization yields better compression output. choiceloss function appears less effect. devised three classes loss functionsbased Hamming distance, Edit distance F1 score. Overall, simple token-basedHamming loss achieved best results. conjecture due simplicityevaluated precisely many loss functions isnt affectedpoor parser output. feature ablation study revealed ngram features beneficial,mirroring similar finding machine translation literature (Chiang, 2007). Finally,found trees created generation algorithm accurate comparedoutput parser applied string output. augurs well use cascaded NLPpipeline, systems use compression output input processing,potentially make better use system output.Future extensions many varied. obvious extension concerns portingframework rewriting applications document summarization (Daume III &Marcu, 2002) machine translation (Chiang, 2007). Initial work (Cohn & Lapata, 2008)shows tree-to-tree transduction model presented easily adaptedsentence abstraction task compression takes place using rewrite operationsrestricted word deletion. Examples include substitution, reordering, insertion.future directions involve detailed feature engineering, including source conditioned features ngram features besides language model. research neededestablish suitable loss functions compression rewriting tasks. particularinteresting experiment loss functions incorporate wider rangelinguistic features beyond parts speech. Examples include losses based parse treessemantic similarity. Finally, experiments presented work use grammaracquired training corpus. However, nothing inherent formalizationrestricts us particular grammar. therefore plan investigate potential method unsupervised semi-supervised grammar induction techniquesrewriting tasks including paraphrase generation machine translation.670fiSentence Compression Tree TransductionAcknowledgmentsgrateful Philip Blunsom insightful comments suggestionsanonymous referees whose feedback helped substantially improve present paper.Special thanks James Clarke sharing implementations Clarke Lapatas(2008) McDonalds (2006) models us. acknowledge support EPSRC(grants GR/T04540/01 GR/T04557/01). work made use resourcesprovided Edinburgh Compute Data Facility (ECDF). ECDF partiallysupported eDIKT initiative. preliminary version work publishedproceedings EMNLP/CoNLL 2007.ReferencesAho, A. V., & Ullman, J. D. (1969). Syntax directed translations pushdown assembler. Journal Computer System Sciences, 3, 3756.Alshawi, H., Bangalore, S., & Douglas, S. (2000). Learning dependency translation modelscollections finite state head transducers. Computational Linguistics, 26 (1), 4560.Berger, A. L., Pietra, S. A. D., & Pietra, V. J. D. (1996). maximum entropy approachnatural language processing. Computational Linguistics, 22 (1), 3971.Bikel, D. (2002). Design multi-lingual, parallel-processing statistical parsing engine.Proceedings 2nd International Conference Human Language TechnologyResearch, pp. 2427, San Diego, CA.Briscoe, E. J., & Carroll, J. (2002). Robust accurate statistical annotation general text.Proceedings Third International Conference Language Resources Evaluation, pp. 14991504, Las Palmas, Gran Canaria.Carroll, J., Minnen, G., Pearce, D., Canning, Y., Devlin, S., & Tait, J. (1999). Simplifyingtext language impaired readers. Proceedings 9th Conference European Chapter Association Computational Linguistics, pp. 269270, Bergen,Norway.Chandrasekar, R., & Srinivas, C. D. B. (1996). Motivations methods text simplification. Proceedings 16th International Conference ComputationalLinguistics, pp. 10411044, Copenhagen, Danemark.Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33 (2),201228.Clarke, J., & Lapata, M. (2006). Models sentence compression: comparison acrossdomains, training requirements evaluation measures. Proceedings 21stInternational Conference Computational Linguistics 44th Annual MeetingAssociation Computational Linguistics, pp. 377384, Sydney, Australia.Clarke, J., & Lapata, M. (2008). Global inference sentence compression: integer linearprogramming approach. Journal Artificial Intelligence Research, 31, 399429.671fiCohn & LapataCohn, T., & Lapata, M. (2008). Sentence compression beyond word deletion. Proceedings 22nd International Conference Computational Linguistics, pp. 137144,Manchester, UK.Collins, M. (2002). Discriminative training methods hidden Markov models: theoryexperiments perceptron algorithms. Proceedings 2002 ConferenceEmpirical Methods Natural Language Processing, pp. 18, Morristown, NJ.Collins, M. J. (1999). Head-driven statistical models natural language parsing. Ph.D.thesis, University Pennsylvania, Philadelphia, PA.Crammer, K., & Singer, Y. (2003). Ultraconservative online algorithms multiclass problems. Machine Learning, 3, 951999.Daume III, H., & Marcu, D. (2002). noisy-channel model document compression.Proceedings 40th Annual Meeting thev Association ComputationalLinguistics, pp. 449456, Philadelphia, PA.Eisner, J. (2003). Learning non-isomorphic tree mappings machine translation.Companion Volume Proceedings 41st Annual Meeting AssociationComputational Linguistics, pp. 205208, Sapporo, Japan.Galley, M., Hopkins, M., Knight, K., & Marcu, D. (2004). Whats translation rule?.Proceedings 2004 Human Language Technology Conference NorthAmerican Chapter Association Computational Linguistics, pp. 273280,Boston, MA.Galley, M., & McKeown, K. (2007). Lexicalized Markov grammars sentence compression.Proceedings Human Language Technologies 2007: Conference NorthAmerican Chapter Association Computational Linguistics, pp. 180187,Rochester, NY.Grael, J., & Knight, K. (2004). Training tree transducers. Proceedings 2004 HumanLanguage Technology Conference North American Chapter AssociationComputational Linguistics, pp. 105112, Boston, MA.Hermjakob, U., Echihabi, A., & Marcu, D. (2002). Natural language based reformulationresource wide exploitation question answering. Proceedings 11th TextRetrieval Conference, Gaithersburg, MD.Hori, C., & Furui, S. (2004). Speech summarization: approach word extractionmethod evaluation. IEICE Transactions Information Systems, E87D(1), 1525.Jing, H. (2000). Sentence reduction automatic text summarization. Proceedings6th Applied Natural Language Processing Conference, pp. 310315, Seattle, WA.Joachims, T. (2005). support vector method multivariate performance measures.Proceedings 22nd International Conference Machine Learning, pp. 377384,Bonn, Germany.Kaji, N., Okamoto, M., & Kurohashi, S. (2004). Paraphrasing predicates writtenlanguage spoken language using web. Proceedings 2004 Human Language Technology Conference North American Chapter AssociationComputational Linguistics, pp. 241248, Boston, MA.672fiSentence Compression Tree TransductionKnight, K. (1999). Decoding complexity word-replacement translation models. Computational Linguistics, 25 (4), 607615.Knight, K., & Marcu, D. (2002). Summarization beyond sentence extraction: probabilisticapproach sentence compression. Artificial Intelligence, 139 (1), 91107.Lin, D., & Pantel, P. (2001). Discovery inference rules question answering. NaturalLanguage Engineering, 7 (4), 342360.McDonald, R. (2006). Discriminative sentence compression soft syntactic constraints.Proceedings 11th Conference European Chapter AssociationComputational Linguistics, pp. 297304, Trento, Italy.Nguyen, M. L., Horiguchi, S., Shimazu, A., & Ho, B. T. (2004). Example-based sentencereduction using hidden markov model. ACM Transactions Asian LanguageInformation Processing, 3 (2), 146158.Och, F. J., & Ney, H. (2004). alignment template approach statistical machinetranslation. Computational Linguistics, 30 (4), 417449.Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: method automaticevaluation machine translation. Proceedings 40th Annual Meeting thevAssociation Computational Linguistics, pp. 311318, Philadelphia, PA.Petrov, S., Barrett, L., Thibaux, R., & Klein, D. (2006). Learning accurate, compact,interpretable tree annotation. Proceedings 21st International ConferenceComputational Linguistics 44th Annual Meeting Association Computational Linguistics, pp. 433440, Sydney, Australia.Riezler, S., King, T. H., Crouch, R., & Zaenen, A. (2003). Statistical sentence condensationusing ambiguity packing stochastic disambiguation methods lexical-functionalgrammar. Proceedings 2003 Human Language Technology ConferenceNorth American Chapter Association Computational Linguistics, pp.118125, Edmonton, Canada.Shieber, S., & Schabes, Y. (1990). Synchronous tree-adjoining grammars. Proceedings 13th International Conference Computational Linguistics, pp. 253258,Helsinki, Finland.Stolcke, A. (2002). SRILM extensible language modeling toolkit. ProceedingsInternational Conference Spoken Language Processing, Denver, CO.Tsochantaridis, I., Joachims, T., Hofmann, T., & Altun, Y. (2005). Large margin methodsstructured interdependent output variables. Journal Machine LearningResearch, 6, 14531484.Turner, J., & Charniak, E. (2005). Supervised unsupervised learning sentencecompression. Proceedings 43rd Annual Meeting Association Computational Linguistics, pp. 290297, Ann Arbor, MI.Vandeghinste, V., & Pan, Y. (2004). Sentence compression automated subtitling:hybrid approach. Text Summarization Branches Out: Proceedings ACL-04Workshop, pp. 8995, Barcelona, Spain.673fiCohn & LapataWu, D. (1997). Stochastic inversion transduction grammars bilingual parsing parallelcorpora. Computational Linguistics, 23 (3), 377404.Yamada, K., & Knight, K. (2001). syntax-based statistical translation model. Proceedings 39th Annual Meeting Association Computational Linguistics,pp. 523530, Toulouse, France.674fiJournal Artificial Intelligence Research 34 (2009) 133-164Submitted 07/08; published 03/09Generic Preferences Subsets Structured ObjectsMaxim BinshtokRonen I. BrafmanMAXIMBI @ CS . BGU . AC . ILBRAFMAN @ CS . BGU . AC . ILComputer Science DepartmentBen-Gurion University, IsraelCarmel DomshlakDCARMEL @ IE . TECHNION . AC . ILFaculty Industrial Engineering ManagementTechnion, IsraelSolomon E. ShimonySHIMONY @ CS . BGU . AC . ILComputer Science DepartmentBen-Gurion University, IsraelAbstractVarious tasks decision making decision support systems require selecting preferredsubset given set items. focus problems individual items describedusing set characterizing attributes, generic preference specification required, is,specification work arbitrary set items. example, preferencescontent online newspaper form: viewing, newspaper containssubset set articles currently available. preference specification subsetprovided offline, able use select subset currently availableset articles, e.g., based tags. present general approach lifting formalismsspecifying preferences objects multiple attributes ones specify preferencessubsets objects. also show compute optimal subset givenspecification relatively efficient manner. provide empirical evaluation approachwell worst-case complexity results.1. IntroductionWork reasoning preferences focuses mostly task recognizing preferred elementswithin given set. However, another problem interest selecting optimal subsetelements. Optimal subset selection important problem many applications: choicefeature subsets machine learning, selection preferred bundle goods (as in, e.g., homeentertainment system), finding best set items display users screen, selecting bestset articles newspaper best members committee, etc.Earlier work problem mostly focused question one constructordering subsets elements given ordering elements set (Barbera, Bossert,& Pattanaik, 2004). main distinction made sets items mutuallyexclusive, sense one eventually materialize, sets itemsjointly materialize. formalism agnostic issue, although clearly motivatedlatter case. Barbera et al. note, past work focused case mutually exclusiveelements. This, example, would case selecting set alternativesdecision-maker (or nature) ultimately choose one (e.g., courses action). However,2009 AI Access Foundation. rights reserved.fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYsubstantial body work latter setting items might materialize jointly,individual items preferentially comparable.paper focuses somewhat different context set-preference specification. First,assume items subsets composed structured, sense setattributes associated them. example, items movies, attributes couldgenre, language, year, director; items politicians, attributes could politicalviews politicians various topics, party affiliation, level experience. Second,require generic preference specification, sense used diverse collectionsitems. example, specifying guidelines composition committee,guidelines generic, used induce preference relation subsets given setpoliticians, provided set attributes fixed. Third, assume preferentialordering individual items, although certainly captured one attributesdescribing items.instructive example type domain mind personalized onlinenewspapers. First, problem selection newspaper one subset selectionselect subset set available articles place newspaper. Second, databasearticles constantly changing. Therefore, approach requires explicitly specifying preferences inclusion specific item inappropriate, numberitems large, would require us constantly change preference specification set items changes. Finally, would want base approach methodtransforming ordering items ordering subsets items, wantrank item, obvious instances complementarity substitutability. instance, even prefer articles Britney Spears articles topic, twosimilar articles may less interesting set comprising one oneSpice Girls.1One recent work considers similar setting desJardins Wagstaff (2005),works specifying preferences abstract properties sets. particular, desJardinsWagstaff offer formalism preference specification users specify preferencesset values attribute attains within selected set items. One could assertwhether values attained attribute selected subset diverse concentratedaround specific value. addition, desJardins Wagstaff also suggest heuristic searchalgorithm finding good, though necessarily optimal, sets items.work, present general, two-tiered approach dealing set preferencessetting. approach combines language specifying certain types set properties,arbitrary preference specification language expressing preferences single, attributeditems. basic idea first specify set properties care about, specify preferencesvalues properties. specification induces preference ordering setsbased values sets provide properties interest. believe suggestedapproach intuitive powerful. Although paper focus particular setproperties devised relatively efficient optimization algorithm, generalform, two-tiered approach generalizes approach desJardins Wagstaff (2005)diversity specificity two set properties. principle, one express general1. realize common rules rationality may apply users preferences.134fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSproperties referring multiple attributes, well general conditional preferencesvalues properties.Essentially, approach re-states problem specifying preferences sets terms usedspecify preferences single items. formulation, items stand possible sets,attributes items (user-defined) set-property values. Thus, principle,approach allows us re-use formalism specifying preferences single items. paper consider two specific instantiations formalism: qualitative preferences basedCP TCP-nets (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004; Brafman, Domshlak, &Shimony, 2006a), quantitative preferences represented generalized additively independent(GAI) value functions (Bacchus & Grove, 1995; Fishburn, 1969). algorithm suggestcomputing optimal subset given qualitative preferences based similar optimization algorithm TCP-nets. number items case large, algorithmmodified substantially exploit special structure items. modifications enableus compute optimal subset faster.2. Specifying Set Preferencesformalism use set-preference specification makes one fundamental assumption:items sets interest built described terms attributes, valuesattributes distinguishes different items. shall use denote set individual items, X denote set attributes describing items. example, imagineitems question US senate members, attributes values are: Party affiliation (Republican, Democrat), Views (liberal, conservative, ultra conservative), Experience(experienced, inexperienced).2.1 Properties Items Properties Item SetsGiven set X item-describing attributes, first, already talk complex itemproperties, e.g., senate members liberal views, inexperienced, conservative senate members. formally, let X union attribute domains, is,X = {X = x | X X , x Dom(X)} ,let LX propositional language defined X usual logical operators. LXprovides us language describing complex properties individual items. Since itemsviewed models LX , write |= whenever item satisfiesproperty LX .Given language LX , specify arbitrary properties item sets basedattribute values items set, property least two Democrats,Democrats Republicans. generally, given item property LX ,talk number items set property , denote ||(S),is, ||(S) = |{o S|o |= }|. Often set implicitly defined, simply write ||.Thus, |Experience=experienced|(S) number experienced members S. Often, simplyabbreviate |experienced|.||() integer-valued property sets, also specify boolean set propertiesfollows: h|| REL ki, LX , REL relational operator integers, k Z135fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYnon-negative integer. property satisfied set |{o S|o |= }| REL k. runningexample use following three set properties:P1 : h|Party affiliation = Republican Political view = conservative| 2iP2 : h|Experience = experienced| 2iP3 : h|Political view = liberal| 1iP1 satisfied (only) sets least two members either Republican conservative.P2 satisfied sets least 2 experienced members. P3 satisfied sets least oneliberal.also write h|| REL ||i, similar interpretation. example, h|Republican| >|Democrat|i holds sets containing Republicans Democrats. even generallanguage could include arithmetic operators (e.g., require twice many Republicans Democrats)aggregate functions (e.g., average number years job). instancesgeneral notion specifying properties sets function attribute values setsmembers. paper, focus language relational operators restrictedequalities inequalities. clear, concrete setting eases presentation,restricting language allows us provide efficient subset-selection algorithms.Indeed, many ideas present apply general languages. particular,generality holds overall preference-specification methodology, search-overCSPs technique computing optimal subsets introduced later paper. However,specific techniques use implement ideas, bounds generation, specifictranslation properties CSPs, rely heavily use specific, restrictive languages.Finally, note important property preference specification approach independent actual set items available moment. generality important manyapplications reasoning set preferences must performed different,often initially unknown sets items. example, case specifying guidelinesselecting articles online newspaper, selecting set k results information query.2.2 Reasoning Set Preferencesspecified set properties interest, define preferences valuesproperties using preference specification formalism. discuss two specific formalisms, namely TCP-nets (Brafman et al., 2006a), extension CP-nets (Boutilier et al., 2004),Generalized Additively Independent (GAI)-value functions (Bacchus & Grove, 1995; Fishburn,1969). former formalism purely qualitative preference specification, yielding partialpreference order objects interest. latter quantitative specification formalismrepresent value function.Let P = {P1 , . . . , Pk } collection set properties. TCP-net P captures statements following two types:(1) Conditional Value Preference Statements. Pi1 = pi1 Pij = pij Pl = plpreferred Pl = p0l . is, Pi1 , . . . , Pij certain value, prefer one valuePl another value Pl .136fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTS(2) Relative Importance Statements. Pi1 = pi1 Pij = pij Pl importantPm . is, Pi1 , . . . , Pij certain value, prefer better value Pl evencompromise value Pm .statement allows us compare certain pairs item sets follows:- statement Pi1 = pi1 Pij = pij Pl = pl preferred Pl = p0l impliesgiven two sets S, 0 (1) Pi1 = pi1 Pij = pij holds, (2) satisfiesPl = pl 0 satisfies Pl = p0l , (3) 0 identical values propertiesexcept Pl , preferred 0 .- statement Pi1 = pi1 Pij = pij Pl important Pm impliesgiven two sets S, 0 (1) Pi1 = pi1 Pij = pij holds, (2)preferred value Pl , (3) 0 identical values attributes except PlPm , preferred 0 . (Notice care value Pm Plimproved.)refer reader work Brafman et al. (2006a) details TCP-nets,graphical structure, consistency, etc. algorithms paper, used TCP-nets,assume acyclic TCP-net Brafman et al.. latter property ensures consistencyprovided preferences, well existence certain good orderings P respectTCP-net.example, consider following preferences president forming committee.prefers least two members either Republican conservative, is, prefers P1P1 unconditionally. (Depending context, use P denote property Pvalue P = true. use P denote P = false.) P1 holds, prefers P2 P2 (that is, leasttwo experienced members), committee recommendations carry weight. P1 holds,prefers P2 P2 (that is, one inexperienced) would easier influencedecision. president unconditionally prefers least one liberal, is, prefersP3 P3 , give appearance balance. However, P3 less important P1P2 . additional external constraint (or possibly preference) total numbermembers three.2GAI value functions map elements interest (item sets case) real values quantifying thePrelative desirability elements. Structure-wise, GAI value functions formU (S) = i=1,...,n Ui (Pi (S)), Pi P subset properties. example, Presidents preferences imply following GAI structure: U (S) = U1 (P1 (S), P2 (S)) + U2 (P3 (S))Presidents conditional preferences P2 value tie P1 P2 together, independent P3 value. U1 would capture weight conditional preference, combinedabsolute preference P1 value. U2 would represent value property P3 .might quantify preferences follows: U1 (P1 , P2 ) = 10, U1 (P1 , P2 ) = 8, U1 (P1 , P2 ) = 2,U1 (P1 , P2 ) = 5; U2 (P3 ) = 1, U2 (P3 ) = 0. course, infinitely many quantificationspossible.2. external constraints, cardinality constraint, modeled preference highvalue/importance. fact, model cardinality constraints implementation.137fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONY1:2:3:4:5:6:7:8:9:10:11:12:Q {}SoptQ contains set UB(S) > Value(Sopt )argmaxS 0 Q UB(S 0 )Q QS\ {S 0 | LB(Sopt ) UB(S 0 )}Q Q {S {o} | \ S}argmaxS 0 Q Value(S 0 )Value(S) > Value(Sopt )Soptendendreturn SoptFigure 1: Subset-space branch-and-bound search optimal subset available items S.3. Finding Optimal Subsetgeneral, given preference specification set available items, goal findoptimal subset Sopt respect preference specification. is, set0 S, properties Sopt satisfies less desirable properties 0 satisfies.consider two classes algorithms finding optimal subset. two classesalgorithm differ space search. next section, describe comparativeempirical evaluation algorithms. running example use following setavailable items S:o1o2o3o4RepublicanRepublicanDemocratDemocratconservativeultra conservativeconservativeliberalinexperiencedexperiencedexperiencedexperienced3.1 Searching Sets Spaceobvious approach generating optimal subset search directly spacesubsets. priori approach attractive, indeed, shall see later implementation approach scale up. However, given often interested setssmall size heuristics used enhance search quality, thought worth exploringapproach.branch-and-bound (B&B) algorithm space sets depicted Figure 1. setS, algorithm assumes access upper bound UB(S) lower bound LB(S) estimatesmaximal value superset S. algorithm maintains queue Q sets, queueinitialized contain empty set. step, algorithm selects highest upper-boundset queue. Next, algorithm removes Q sets 0 upper bound UB(S 0 )good lower bound LB(S) selected set S, adds Q minimal(that is, one-item) extensions S. latter sets correspond successors searchspace. Different implementations algorithm differ sort queue. best-firstversion depicted pseudo-code sorts queue according heuristic value set,138fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTScase heuristic upper bound value sets supersets. contrast, depthfirst version always positions children newly expanded node front queue.implemented tested versions.method used generate bounds set must depend actual preference representation formalism, well type set properties used, idea naturalgiven quantitative value function. lower bound LB(S) use actual value Value(S)S. Note possible descendants lower values because, general,set-properties may monotonic (e.g., average value higher 5.) However, sincepossible solution, valid lower bound.upper bound, proceed follows: First, consider set-property valuesconsistent S. is, set property, examine values supersetspotentially provide property. example, consider P2 suppose contains singleexperienced member. currently, P2 holds. However, satisfy P2 add oneexperienced member. Thus, values P2 consistent S. contrast, twoexperienced members S, P2 inconsistent matter add S,never satisfy P2 . Next, given sets possible set-properties values respectset S, bound value supersets maximizing values locally.Specifically, GAI value function, look local function Ui , considerassignment it, among consistent values, would maximize Ui . Clearly, may resultoverall value overestimation, since know whether locally optimizing jointassignments consistent. Similar ideas used quantitative representations,various soft-constraint formalisms (Bistarelli, Fargier, Montanari, Rossi, Schiex, & Verfaillie,1999).Consider running example GAI value function end Section 2,consider searching optimal subset = {o1 , o2 , o3 , o4 } using depth-first version B&B.start empty set, property values provided empty set P1 , P2 , P3 . Thus,lower bound LB(), value empty-set, 5. upper bound UB(),consider best property values individually consistent extensions ,P1 , P2 , P3 , accumulative value 11. Sopt also initialized empty set,next generate children (only possible) selected set , singletonsets: {o1 }, {o2 }, {o3 }, {o4 }. Except {o4 }, lower upper bounds identicalempty set, inserted queue. {o4 } lower bound 6 upperbound 11. Suppose {o1 } first queue element, select expansion. resultsadding {o1 , o2 }, {o1 , o3 }, {o1 , o4 } queue, lower upper bounds sets(8, 11), (8, 11), (6, 11), respectively. Next, set {o1 , o2 } examined respect currentSopt = , Sopt assigned {o1 , o2 }. Since assumed depth-first version B&Bproceed expanding {o1 , o2 }, obtaining {o1 , o2 , o3 }, {o1 , o2 , o4 } lower upper boundsbeing, respectively, (10, 11) (11, 11). lower bound 11 {o1 , o2 , o4 } pruneaway rest nodes queue, done.important issue depth-first B&B order sets generated. implementation, node search space, items ordered according sumvalue properties help satisfy. example, initially, conservative membero1 could help us satisfy P1 .contrast quantitative preference representation formalisms, qualitative preferences typically induce partial ordering property collections. case, harder generate strict139fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYupper lower bounds must comparable possible solution. One way handlelinearize ordering require stronger property optimality respectresulting total order. Here, TCP-nets present good choice efficient simple way generating value function consistent acyclic TCP-net (Brafman& Domshlak, 2008). value function retains structure original network important make bounds computation efficient (notably, Ui depends small numberproperty values).3.2 Searching CSPsattractiveness item subsets evaluated terms fixed collection set-properties P,thus different sets provide identical property values equivalent perspective.immediate conclusion considering separately preferentially equivalent subsetsavailable items redundant. remove redundancy, suggest alternative methodsearch directly set-property value combinations. course, problem givenset-property value combination, obvious whether find actual subsetcombination properties. answer question, generate CSP satisfiableexists subset considered set-property values. overall searchprocedure schematically works follows.1. Systematically generate combinations set-property values.2. combination, search subset providing combination setproperty values.3. Output subset satisfying optimal (achievable) combination set-property values.make approach efficient possible, two things, namely:(1) Find way prune sub-optimal set-property value combinations early possible.(2) Given set-property value combination, quickly determine whether subset satisfiescombination.Considering first task, let P1 , . . . , Pk ordering set-properties P.3 Givenordering P, incrementally generate tree property combinations. root treecorresponds empty assignment P. node n corresponding partial assignmentP1 = p1 , . . . , Pj = pj , every possible value pj+1 property Pj+1 , tree containschild n corresponding partial assignment P1 = p1 , . . . , Pj = pj , Pj+1 = pj+1 .tree leaves correspond (all) complete assignments P. tree running exampledepicted Figure 2. Note that, implicitly, node tree associated (possiblyempty) set subsets S, notably, subsets provide set-property value combinationassociated node.search optimal set, expand tree set-property value combinationstrying expand tree nodes possible pruning certain value combinations P either3. Throughout paper, assume preference specifications using TCP nets, conditionalpreference (CP) arcs, importance arcs, conditional importance (CI) arcs. scheme implementations allow arcs, CI arcs force ordering set properties dynamic, may depend valueassignments previous properties. clarity exposition, thus preferred present technical details.140fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSP1P1P1 P2 P3P1 P2P1 P2P1 P2P1 P2 P3P1 P2 P3 P1 P2 P3P1 P2 P3P1 P2P1 P2 P3 P1 P2 P3P1 P2 P3Figure 2: Illustration search tree running example.sub-optimal respect set preferences, unsatisfiable respect S. standard wayis, again, using branch-and-bound search procedure, requires usderive effective upper lower bounds value best subset satisfying partial valuecombination P. addition, order associate properties values affectspruning ability throughout search process. get leverage bounds,would like explore children node decreasing order purported attractiveness.Moreover, fixing ordering set-properties themselves, would like propertiespotentially contribute appear earlier ordering. instance, P1 valuerunning example greater influence overall attractiveness subset valueP2 , thus P1 better branched first. addition, P1 preferred true, thussubtree corresponding P1 = true better explored first. Similarly, P2 preferredtrue P1 = true, preferred false, otherwise. ordering reflected treeFigure 2, left right pre-order traversal tree.Now, let us consider second task determining whether subset satisfies given setproperty value combination. Given partial assignment P, set following CSP.First, CSP boolean variable xi every available item oi S. example, CSPcontains variables x1 , . . . , x4 items o1 , . . . , o4 respectively. Intuitively, xi = 1 encodes oipart (searched for) subset S, whereas xi = 0 means oi subset.Next, translate every set-property value certain constraint variables.instance, [P1 ] = true, constraint C1 : x1 + x2 + x3 2 added CSP. NoteC1 explicitly encodes requirement (of P1 = true) subset least twoelements satisfy Republican conservative. {o1 , o2 , o3 } candidateseither Republican conservative. Alternately, [P1 ] = f alse, constraintC1 : x1 + x2 + x3 < 2 added CSP. Finally, specify value P1 ,constraints related P1 added all. Likewise, [P2 ] = true [P3 ] = truewould add constraints C2 : x2 + x3 + x4 2 C3 : x4 1, respectively. general,hard verify CSP constructed way concrete item set set-propertyvalue combination solvable subset satisfying . Moreover, CSPsolvable, solutions explicitly provides us subset S.worth briefly pointing difference CSPs generatetypical CSPs usually discussed literature. work general CSPs deals constraints141fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYsmall, typically two-variable, subsets problem variables. contrast, constraintsCSPs generated optimization process global, constraint possibly defined CSP variables. Yet another special property CSPs constructedpurposes sense meaningful talk partial assignmentscontextunassigned variables always regarded de facto assigned value 0 sincecorresponding items, default, belong subset search for.partial assignments set-properties P map CSPs, node tree setproperty value combinations maps CSP, entire tree viewed tree CSPs.important property tree-of-CSPs children CSP node CSPs obtainedadding one additional constraint parent CSP, notably constraint correspondingadditional property value want set satisfy. implies CSP nodetree unsatisfiable, descendants unsatisfiable well. fact, makestronger use nature search tree, recognizing reuse work doneparent node speed solution children. see latter, consider CSP Ctree-of-CSPs, child CSP C 0 C , let solution C . C 0 extends Cconstraint C, subset 0 ruled C also ruled C 0 . Hence, solvingC C 0 considers subsets order (that is, using ordering setelements), solving C 0 start leaf node corresponding S, solution generatedC . Moreover, constraint C represents boolean set property, solutionC 0 = C {C}, solution C {C}, sibling C 0 . Usingideas, share work done different CSP nodes tree-of-CSPs. fact, setproperties boolean, approach needs backtrack property (we callproperty limited backtracking), thereby considerably improving empirical performancealgorithm.overall branch-and-bound algorithm space CSPs depicted Figure 3. is,algorithm formulated case quantitative preference formalisms. formulationalgorithm qualitative case essentially same, minor technical differencesimportant computational property. CP/TCP-nets, guarantee limitedbacktracking required follow following guidelines. First, must order variables(line 1) order consistent topology network. Note TCP-nets, orderingmay conditional, is, order two variables may vary depending valueearlier variables. Second, line 2, property values must (possibly partially) orderedbest worst, given values parent properties (which must instantiatedearlier). case, first satisfiable set properties constitutes optimal choice (Brafmanet al., 2006a). Assuming solve intermediate nodes tree-of-CSPs, knowbacktrack level assuming boolean set-properties, but, again, backtracksmay occur integer-valued properties.node data structure used algorithm two attributes. search node n,n. captures partial assignment set-properties P associated node n,n.S captures subset satisfying n. exists, otherwise value false.functions Value, LB, UB semantics subset-space search algorithmFigure 1. pseudocode assume fixed ordering set-property values (line 2),one vary depending earlier values (and exploit implementation). Finally,142fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTS1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:Fix ordering set-properties PFix ordering values set property P PFix ordering available itemsQ {n[; ]}SoptQ emptyn pop(Q)construct-and-solve-csp(n)n.S 6= f alse UB(n.S) > Value(Sopt )Value(n.S) > Value(Sopt )Sopt n.SendLet P highest-ordered set property unassigned n.possible value p Pn0 [n. {P = p}; n.S]Q Q {n0 }. position n0 Q depends search strategyendendendreturn SoptFigure 3: CSP-space branch-and-bound search optimal subset available items S.pseudo-code leaves open choice search strategy used branch-and-bound,choice fully captured queue insertion strategy line 16.illustrate flow algorithm, let us consider running example. Recallexample already requirement discovered subset size 3, translatesconstraint C : x1 + x2 + x3 + x4 = 3. first CSP consider {C, C1 }constraints. Assume CSP variables ordered {x1 , x2 , x3 , x4 }, value 1 preceding value0 xi . case, first solution find S1 : x1 = 1, x2 = 1, x3 = 1, x4 = 0.next CSP adds constraint C2 . solving CSP, continue search (usingorder xi values) current solution S1 , turns satisfy C2well. Thus, virtually effort required solve CSP. Next, want also satisfy C3 .set constraints corresponds leaf node tree-of-CSPs corresponds completeassignment P1 P2 P3 set-properties. current item set Sopt = S1 liberal,continue assignment S2 : x1 = 1, x2 = 1, x3 = 0, x4 = 1 (requiring usbacktrack CSP-solution space assignments x4 x3 ). setsatisfies properties leftmost leaf node tree-of-CSPs. prove setproperty value combination optimal using upper/lower bounds, done. Otherwise,need explore additional nodes tree-of-CSPs. latter case, next CSP correspondP1 , P2 , P3 , constraints {C, C1 , C2 , C3 }. However, already solution node,exactly S1 . see that, note S1 solution parent current CSP,solution sibling {C, C1 , C2 , C3 }. Hence, since P3 boolean property, S1 mustsatisfy {C, C1 , C2 , C3 }.143fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONY3.3 Solving underlying CSPsalgorithm solving intermediate CSPs based well known backtrack-search algorithm, first presented Prosser (1993) simple iterative form. time,adapted algorithm well known enhancements CSP solving (such NoGoodrecording forward checking (FC)) specifics CSPs setting.Initially, variables values statically ordered least constrained(although also discuss experiments performed dynamic variable/value ordering).motivation static ordering two-fold. First, constraints much global,ordering preprocessing stage. Second, discussed previous section, staticordering allows us better utilize solutions CSPs solving descendent CSPs.basic backtrack algorithm, own, unsurpisingly performs quite poorlysetting, refined utilizing following observations techniques.Monotonicity improving constraints. operator constraint =items constrained property already current partial solution,one cannot satisfy constraint making additional assignments. property holdsconstraint operators < . Using observation, possible detectneed backtrack early search.Forward Checking. certain type forward checking performed constraints. Clearly, satisfying constraint requires least k items addedsubset, number remaining items satisfy desired property less k,search algorithm must backtrack.Can/Must strategy. can/must strategy corresponds advanced checkinteractions constraints. idea quite simple: (i) least p items mustadded constructed subset satisfy constraint Ci , (ii) q items addedconstructed subset without violating another constraint Cj , (iii) itemsadded property constrained Ci also property constrained Cj ,and, finally, (iv) p > q, Ci Cj cannot satisfied simultaneously. Moreover,assignments yet unassigned variables resolve conflict, thus situationdead end. kind reasoning allows discovery barren nodes quite earlysearch, pruning large portions search tree. reason correctly can/muststrategy, maintain data structure unique items pair constraints,well keep track number remaining items influence property constrainedCi influence properties constrained Cj .example, assume middle search two set properties:SP1 : |A1 = a| 5 SP2 : |A2 = b| 3. Suppose already picked 3 itemsinfluence SP1 2 items influence SP2 . result, satisfy SP1 , must addleast another two items influence satisfy SP2 add one iteminfluences SP2 . items choose {ok ...on } valueattribute A1 value b attribute A2 , obviously cannot satisfy SP1SP2 within setting, thus backtrack.Finally, discuss recording NoGoods, improvement basic backtracking algorithmproved impact setting.144fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTS3.3.1 N G OOD R ECORDINGstandard definition NoGood CSP literature partial assignment cannotextended full solution problem. learn NoGood, use prunecertain paths search tree. smaller NoGood, occasions use it,greater pruning power. Thus, interest recognize minimal NoGoods, differenttechniques developed perform NoGood resolution order produce bestgeneral NoGoods possible (see, e.g., Dechter, 1990; Schiex & Verfaillie, 1993; Dago & Verfaillie,1996).noted earlier, CSPs generate differ significantly typical binary CSPs.Consequently, NoGood recording algorithm adapted accordingly. particular, constraints global, makes sense try generating NoGoods global, too.Thus, instead recording assignments variables, record influence current assignment constraints. Every variable influences set constraints.4 Thus, NoGood,store influence set selected far constraints. Specifically, supposegenerated set S1 , recognized extensible set satisfying constraints.(This immediately follows fact backtracked set.) generate NoGood N records property associated constraint, many items satisfyingproperty occur S1 . Now, suppose encounter different set S2 effectN constraints. fewer options extend S2 extend S1 , knowS2 , well, cannot extended solution. However, options extendS2 S1 , cannot conclude S2 NoGood point. order better quantifyoptions available extend S1 record, beyond actual NoGood N , level (depth)assignment tree generated. Given CSP solver uses static variableordering, know encounter set generates properties NoGoodN , level higher S1 , safely prune extensions. reason is,additional extension options available S1 .correctness NoGood recording mechanism proposed depends staticvariable ordering, well specific value ordering variables CSP, namely,h1, 0i. show correctness, note NoGood used recorded.Consequently, node using NoGood would right search tree nodeNoGood recorded at. would like stress that, since constraints global,matter items added subset, rather influence itemsconstraints. two sets exactly influence constraints identicalrespect optimization process.3.3.2 EARCH LGORITHMprocedure depicted Figure 4 extends basic backtrack algorithm subroutine C PROVE altered include combination in-depth checks discussed earlier,utilize early conflict detection techniques, including NoGoods check. Also added callDD N G OOD subroutine recording NoGoods backtracking. P n, generatedinstance CSP problem variables indexed 1 |S| node tree-space search4. assume without loss generality every item set available items influences least one constraintconstraint set C , since items influence constraint safely eliminated.145fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYrespectively, inputs procedure. algorithm systematically tries assign valuesproblem variables, backtracking recording NoGoods facing dead end.1:2:3:4:5:6:7:8:9:10:11:12:13:consistent n.S satisfies n.not(consistent)H VALUES(P .vars[i]) C MPROVE(P )P.i L ABEL(P.i, consistent) . current CSP variable available values, try set, update consistencyelseDD N G OOD (P ,i). Record NoGoodP.i U NLABEL(P.i). BacktrackendP.i = 0. backtracked first indexed variable solution availablereturn falseendendreturn trueFigure 4: Conflict backtrack algorithm NoGood recording4. Experimental Resultsevaluate different algorithms using subset movie database publicly availableimdb.com. simulated scenario selecting movies three-day film festival accordingorganizers preferences. Three models growing complexity engineered reflectpreferences organizers; models defined terms 5, 9, 14 set-properties, respectively. addition, total number films constrained 5 (which actually modeledusing strong preference). Figure 5 depicts list P14 14 properties alterations; P5 P9 consist corresponding prefixes (SP1 SP5 , SP1 SP9 ,respectively) P14 . produce even complex problem instances cause many backtracksspace set-property assignments slightly altered 14-properties model, creating two0 P 00 .additional models denoted henceforth P14144.1 Preference SpecificationFigure 6 provides verbal description qualitative preferences film festival programused experiments. Figure 7 depicts TCP-net encodes preferences termsconcrete set-properties listed Figure 5. experiments GAI value functions,preferences quantified compiling TCP-net GAI value function ordersitems consistently TCP-net (Brafman & Domshlak, 2008). task empiricalevaluation find optimal subset set available movies {S400 , S1000 , S1600 , S3089 },Si corresponds set movies, respect five modelspreferences sets. experiments conducted using Pentium 3.4 GHz processor2GB memory running Java 1.5 Windows XP Professional. runtimes reported tablesseconds, indicating process incompletion four hours.146fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSSP1 = h|Year 2002| = 5iSP2 = h|Genre = Comedy| 2iSP3 = h|Genre = Thriller| 3iSP4 = h|Genre = Family| > 1iSP5 = h|Color = B&W| > 1iSP6 = h|Director = Spielberg| 1iSP6 = h|Director = Spielberg| 1iSP7 = h|Sound = Mono| 2iSP8 = h|Genre = War Genre = Film-noir| = 0iSP8 = h|Genre = War Genre = Film-noir| 4iSP8 = h|Genre = Film-noir| 4iSP9 = h|Location = North America| > 1iSP10 = h|Actor = Famous Actress = Famous| = 5iSP11 = h|Actress = Famous| 2iSP12 = h|Genre = Drama| 2iSP13 = h|Release Date < 1970| 1iSP14 = h|Net Profit 1000000| 2iSP14 = h|Net Profit 1000000| 5iFigure 5: Set-properties used modeling user preferences movies selection domain.0Alteration P14 , achieve backtracking - denoted P14000alteration P14achieve even backtracking - denoted P141. prefer new movies old movies, therefore prefer movies 2002 later, importantme.2. love comedies, thrillers family movies.3. prefer many movies black white (not one movie).4. movies new (after 2002) would prefer least 2 comedies.5. find least 2 comedies also prefer 1 family movie, less 3 thrillers.However right number family movies important right numberthrillers.6. movies new, prefer least 2 movies black white vintage touch.7. movies new, prefer least one movie directed Steven Spielberg, otherwise, dontlike newer films8. previous condition holds, number movies mono sound may greater 2.9. prefer war films film-noir festival. However condition satisfied,prefer films filmed North America importantpreferences movie color B&W.10. draw attention, prefer 5 movies famous actors actresses.11. highlight female roles, prefer least 2 movies famous actress.12. prefer least 2 dramas people tend think dramas sophisticated moviesgenre.13. prefer least one classical movie.14. prefer least one commercially successful movie, i.e. movie whose net profit onemillion dollars.Figure 6: Informal description assumed preferences selecting set movies filmfestival program.First, initial experiments quickly showed search space subsets (Table 1)scale up. 20 elements, converge optimal solution withinhour, even preference specification involved 5 set-properties. outcome holdscombinations qualitative quantitative preference specifications, depth-first best-firstschemes branch-and-bound, queue ordering based sets upper bound, lower bound,147fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYweighted combinations both. Table 1 provides snapshot corresponding results TCPnet specified nine set properties. table describes total number subsets generatedoptimal subset found (see column Subset Sopt ), total number subsetsgenerated optimal subset recognized optimal (under Subsets generated). DFS appears much effective BFS, branching factor larger databases overwhelmsapproach. Also, may thought larger databases easier quicklygenerate good sets, found moderately larger (e.g,. 25+) much larger (e.g., 3000)datasets, approach slow. Various improvements may possible, given muchbetter performance approach discussed later, unlikely make difference.SP2 : SP4 SP4SP2 : SP4 SP4SP2 : SP3 SP3SP2 : SP3 SP3SP1 : SP2 SP2SP1 : SP2 SP2SP1 SP1SP3SP2SP1SP4SP5SP6SP8SP1 SP6SP1 SP6SP1 SP6SP1 SP6::::SP7SP7SP7SP7SP9SP14SP7 SP9SP7 SP9SP7 SP9SP7 SP9::::SP14SP14SP14SP14SP8 : SP9 SP9SP8 : SP9 SP9SP8 SP9SP8 SP9SP8 SP9SP8 SP9::::SP12SP12SP12SP12SP12SP12SP12SP12SP12SP7SP7SP7SP7SP1 : SP6 SP6SP1 : SP6 SP6SP1 : SP5 SP5SP1 : SP5 SP5SP8 SP8SP7SP13SP11SP9 : SP13 SP13SP9 : SP13 SP13SP10 : SP11 SP11SP10 : SP11 SP11SP14SP14SP14SP14SP10SP14 : SP10 SP10SP14 : SP10 SP10Figure 7: TCP-net model preference sets movies film festival program.Next, consider CSP-space branch-and-bound search. particular, comparedtwo variants approach use dynamic static variable value orderings.follows, two variants denoted BB-D BB-S, respectively. staticvariable/value orderings usually considered weaker approach CSP solving, earliershown that, domain, static ordering allows certain optimizationspotential improve efficiency overall problem solving. particular, static variableordering allows record global NoGoods described Section 3.3.1; results algorithmsrecord NoGoods denoted name suffix +ng. addition, tried share148fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSS8S8S10S10S15S15S20S20MethodBFSDFSBFSDFSBFSDFSBFSDFSSubsets Sopt1883406727879114342840728407Subsets generated407563015048293510450430547486079231616Time (sec)0.560.192.340.4768.233.131584.6728.578Table 1: snapshot results subsets-space search. preferences specifiedTCP-net nine set properties.MethodS400S1000S1600S3089P5P5P5P5P5BB-DBB-SBB-S+incBB-S+ngBB-S+ng+inc0.30.140.050.170.050.770.140.10.10.111.300.170.120.150.134.020.250.180.210.19P9P9P9P9P9BB-DBB-SBB-S+incBB-S+ngBB-S+ng+inc0.430.140.060.170.061.420.240.140.250.142.420.260.170.340.186.580.340.150.350.17P14P14P14P14P14BB-DBB-SBB-S+incBB-S+ngBB-S+ng+inc0.660.170.060.30.12.030.430.150.570.194.691.090.431.060.3814.920.780.50.950.540P140P140P140P14BB-SBB-S+incBB-S+ngBB-S+ng+inc6.52.116.14.6827.12719.418.427825954.876.3230.2210.800P1400P1400P1400P1400P14BB-DBB-SBB-S+incBB-S+ngBB-S+ng+inc4113.48101.481.03110107.953705523269.9266.81630616643646.1646.833353013Set-propertiesTable 2: Empirical results evaluating CSP-space search procedures qualitative preference specification using TCP-nets.information consecutive CSP problem instances search tree CSPs;algorithms adopting technique denoted name suffix +inc.Table 2 depicts results evaluation variants CSP-space branch-and-boundsearch algorithm (Figure 3). First, table shows overhead maintaining NoGoodspay simple preference specifications. However, complex problems requiring intense CSP solving, use NoGood recording proved useful, letting us149fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYMethodS400S1000S1600S3089P5P9BB-SBB-S0.240.160.140.250.170.280.260.41P14P14BB-S+incBB-S+ng+inc38.91192376.40160.53494.981349.9Set-propertiesTable 3: Results CSP-space search quantitative preference specification using GAIvalue functions.solve previously unsolvable instances. Next, reader may notice table that, leastproblems used tests, contribution incremental approach substantial.instance, NoGood recording seems contribute much efficiency optimization process. Moreover, complex problems, switching incremental versionsometimes even leads performance degradation. appears overhead maintainingcopying partial solution cases pay off.next set experiments mirrored first one, GAI value functions insteadpurely qualitative TCP-nets. GAI functions obtained properly quantifyingqualitative preferences used first tests. Table 3 provides representative snapshotsresults. value functions set-properties P5 P9 basic branch-and-bound algorithmstatic variable/value orderings performs scales (with growing set alternatives S) quitewell. complex value functions larger set properties P14 performancesignificantly degrades, even incrementality-enhanced algorithm cannot solve problem instances 1000 CSP variables. hand, adding NoGoods recording provesdramatically improve performance, leading solving even largest problem instances.Tables 2 3 suggest qualitative difference performance CSP-space searchquantitative qualitative preference representation models. good reasons expectbehavior. First, compact qualitative models preference may (and typically do) admitone optimal (that is, non-dominated) solution. That, principle, makes finding oneoptimal solution easier. Second, preferences captured TCP-net, variableorderings ensuring first solution found optimal one. contrast, GAI valuefunctions, generate optimal solution, typically still explore search treeprove better solution exists. worst case, explore entire tree CSPs,forcing us explore number CSPs exponential |P|.summary, first conclusion taken experiments subsets-space searchfails escape trap large branching factor, stratified procedures CSP-spacesearch show much higher potential. problems require little backtracking spaceCSPs, latter procedures actually effective TCP-net GAI function preferencespecification. Obviously, procedure forced explore many different CSPs, performanceunavoidably degrades. note that, larger databases, backtracks often indicate inherentconflict desirable set-properties, conflicts might possibly recognized resolved off-line. work investigate issue, leaving optional directionfuture improvement.rather non-trivial example used section provides reader also opportunityassess suitability different preference specification languages. example, although150fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSused boolean-valued set properties, may argued natural-language preferencestatements would better expressed using integer-valued set properties. Similarly, users may findpreference specification formalism, soft-constraints (Bistarelli et al., 1999),naturally capture natural language preferences. opportunity usreemphasize while, obvious reasons, focus concrete choice language,believe two-tiered approach suggested far general.5. Complexity AnalysisThough reasonable runtimes obtained us empirically search CSPs,algorithm classes described worst-case exponential running time. begs question whether problem computationally hard. Obviously, external constraints,subset optimization NP-hard. show even without external constraints, problemtypically remains NP-hard, even significant restrictions problem.Naturally, complexity subset selection depends precise nature preferencespecification formalism used. results presented assume TCP-net-based specification. Hardness results model immediately apply GAI model, based existingreduction (Brafman & Domshlak, 2008). cases, problems tractable TCPnet model become NP-hard GAI model used, instead. Thus, unless stated otherwise,assume henceforth preferences properties specified TCP-net.analyzing complexity problem consider following problem parameters:n, overall number items data set.a, number attributes items.m, number set properties, i.e. number nodes TCP-net.k, maximal property formula size, defined number logical connectives (and, or, not)formula.maximum attribute domain size, i.e. maximum number distinct valuesattribute., number times attribute value appear dataset.5.1 NP-Hard ClassesTheorem 1. using TCP-based preferences set properties, finding optimal subsetgiven set items (POS) NP-hard even items described terms binary-valuedattributes, set properties atomic (that is, = 2 k = 0).Proof. proof polynomial reduction well-known NP-hard Vertex Cover (VC)problem. Given graph G = (V, E), vertex cover G vertex subset V 0 V coveringedges graph, is, every edge e E, vertex v V 0 e incidentv. optimization version VC corresponds finding minimal size vertex cover G.Given VC problem instance G = (V, E), construct POS problem instance specifying TCP-net N item set follows. vertex v V create item (denoted151fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYPe1 Pe1Pe2 Pe2Pe3 Pe3Pe1Pe2Pe3Pek Pek...PekSUMSUM = 0 SUM=1 SUM=2 . . . SUM=nFigure 8: TCP-net reduction VC POS proof Theorem 1.ov ), thus |S| = |V | = n items. edge e E define attribute X(denoted Xe ), thus |X | = |E| = attributes. attributes X definedbinary, {0, 1}, domain. item ov , value attribute Xe ov [Xe ] = 1e incident v G. Next, edge e E, define binary set propertyPe = h|Xe | > 0i takes value true least one item selected subset provides value 1 attribute Xe . addition, define single multi-valued empty set propertySUM h||i5 . domain SUM property defined integer-value range [0..n].Note that, construction, properties utilize one attribute per property, thus logicalconnectives, providing us k = 0. preferences set properties1. binary property Pe , preference value true, is, Pe Pe .2. empty property SUM simply prefer smaller values,(SUM = 0) (SUM=1) (SUM=2) . . . (SUM=n)edges TCP-net N , depicted Figure 8, importance arcs PeSUM, meaning would rather temporize value SUM propertyPe f alse.Proposition 1 ensures optimal subset POS problem constructed alwayscorresponds proper vertex cover G.Proposition 1. subset undominated respect constructed TCP-netN , every edge e E, Pe (S) = true.Proof. Given undominated (with respect N ) subset S, let Pe set propertyPe (S) = f alse. construction, exists item o[Xe ] = 1. Considering0 = {o}, 0 preferred respect N (i) 0 provideexactly values set properties except Pe SUM, (ii) provides preferred5. Since formula inside set property degenerate, fact equivalent h|true|i, every item selectionset comply it. set property simplest implementation counter152fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSvalue SUM 0 provides preferred value Pe , (iii) preferential improvement Pedominates SUM. Thus 0 dominates S, contradicting assumption undominated.Lemma 1. subset undominated respect constructed TCP-net N ,exists vertex cover VS G |VS | = |S|.Proof. proof straightforward. Let VS = {v | ov S}. undominatedrespect N , Proposition 1 Pe (S) = true binary edge-related propertiesPe . turn, Pe (S) = true implies o[Xe ] = 1 least one item S. construction,o[Xe ] = 1 vertex v covers edge e. Together mapping vertices Vitems bijective, latter implies |VS | = |S|.Lemma 2. exists minimal vertex cover G size exists subsetundominated respect N SUM(S) = s.Proof. Let undominated subset |S| = s. construction, Pe (S) = truebinary set properties Pe , SUM(S 0 ) = s. Lemma 1, exists vertex cover VSG |VS | = s. Suppose contrary VS minimal, is, exists vertexcover V 0 G |V 0 | < s. Now, construct subset 0 = {ov | v V 0 }. Since mappingV bijective, |S 0 | = |V 0 | < s, thus SUM(S 0 ) < s. Likewise,construction set properties V 0 vertex cover, Pe (S) = true Pe .This, however, implies 0 preferred respect N , contradicting statementundominated.Theorem 1 follows immediately Lemma 2 fact reduction clearlypolynomial.Theorem 2. Given TCP-based preferences set properties, finding optimal subset givenset items (POS) NP-hard even items described terms single attribute,set properties binary-valued, containing 2 logical connectives (that is,= 1 k = 2).Proof. proof polynomial reduction k-SAT, k 3. Given k-SAT probleminstance propositional variables V logical formula , construct POS problem instance specifying TCP-net N item set follows. variable v V , constructitem ov item ov , thus contains item every possible literal formula.value attribute X defined follows: item ol , A(ol ) = l (where lliteral, either v v, v V ). binary set properties P TCP-net N definedfollows.Properties ensuring variable assignment legitimate. variable v V ,Pv =h|X = v X = v| = 1i,is, S, Pv (S) = true contains exactly one items{ov , ov }.153fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYProperties ensuring satisfied. clause C = (l1 l2 l3 ...) :PC =h|X = l1 X = l2 X = l3 ...| 1iis, S, PC (S) = true contains least one item correspondingliteral C.Finally, complete preference specification, make properties independent (that is,TCP-net edges), properties prefer value true value false.illustrate construction, consider 3-SAT formula = (x z) (y) (x z).formula, construction leadsitemoxoxoyoyozozXxxzzSet properties:Px =h|X = x X = x| = 1iPy =h|X = X = y| = 1iPz =h|X = z X = z| = 1iPC1 =h|X = x X = X = z| 1iPC2 =h|X = y| 1iPC3 =h|X = x X = z| 1ishow finding undominated subset respect N equivalentfinding satisfying assignment . Let undominated respect N . showprovides value true set propositions Pv PC (in case call ultimatelypreferred subset) satisfiable.First, let ultimately preferred subset S. Given S, construct mapping: V 7 {true, f alse} A(v) = true ov S, A(v) = f alse ov S. Notewell-defined because, ultimately preferred subset S, Pv (S) = true, thus,v V , exactly one item {ov , ov } present S. Clearly, legal assignment. addition, PC (S) = true. Thus, clause C , least one itemX = li C belongs S. construction, implies satisfies clauses ,thus satisfiable.Converesly, suppose preferentially undominated respect N ,ultimately preferred. POS problem undominated subset S, showunsatisfiable. Assuming contrary, let satisfying assignment . Given A, constructsubset SA SA = {ol | literal l A}, show SA dominates respect N(contradicting assumed undominance S, finalizing proof Theorem 2).construction, since legal assignment V , Pv (SA ) = true set properties Pv . Also, since satisfying assignment , PC (SA ) = true setproperties PC . Therefore, SA actually ultimately preferred subset S. Finally, sinceset properties P preferentially independent N , value true always preferred valuef alse set properties, SA dominates respect N .Notice Theorems 1 2 subsume other. Theorem 1 poses restrictionnumber item attributes problem instance, restrict domain attributes.Theorem 2 restricts number attributes 1, restriction domain sizeattribute, restriction property size looser imposed Theorem 1.154fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSFinally, note tightening condition Theorem 2, allowing 1 connective set-property definition prevents us using reduction proofTheorem 2 respectibe satisfiability problems would polynomial-time solvable2-SAT problems. conjecture, however, fragment POS still NP-hard. fact,Section 5.3 show corresponding fragment POS GAI preference specification(instead TCP-nets) indeed NP-hard.5.2 Tractable ClassesSeveral tractable classes POS, obtained restricting problem class discussedTheorem 2, characterized single-attribute item description (that is, = 1), discussedbelow. trivially tractable (Section 5.2.1) non-trivially tractable (Section 5.2.2) cases,assume relational symbols either equalities inequalities, specificationproperty equalities (attribute = value) used, addition allow emptyset property specified. latter restriction due fact empty set propertysomewhat special, enriches descriptive power allowing one simulate additionalattribute certain cases, single-attribute restriction crucial tractability result.proceed actual results, note that, single-attribute item description,two set properties conflict demands backtracking choosing items (i.e.CSP solution). illustrate conflicts, consider following examples.1.1.a h|A = ai | 5i1.b h|A = ai | 3iSet property 1.a redundant, subsumed 1.b2.2.a h|A = | = 5i2.b h|A = | > 6iOne set properties must false.3.3.a h|A = al | < 7i3.b h|A = al | 9iOne set properties must false.conflicts set-properties resolved offline, prior actual process subsetselection, totally disregarding available items. Hence, within process subset selection,assume conflicts set properties. Consequently, subset selectiondone greedy manner.5.2.1 RIVIALLY RACTABLE C LASSTheorem 3. Finding optimal subset given set items (POS) respect TCP-netpreference specification P items described terms single attribute,set properties atomic (that is, = 1 k = 0).algorithm problem class Theorem 3 depicted Figure 9. algorithm runstime O(m2 n), number set properties n number available items S.loop line 4 algorithm iterates set properties, time checking compatibility previously considered properties, requires (m2 ) time. proceduresG ET ATISFYING ET () H ATISFYING ET () process item once.Hence, total running time algorithm O(m2 n).66. runtime analysis include ordering TCP-net variables assumed given. One waywould topological sort net, obviously done polynomial time.155fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONY1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:1:2:3:4:5:6:7:8:9:10:11:SoptFix preference ordering set properties PPassproperty P P(not (P .isSatisfied))P conflict PassSet next value P w.r.t. PasselseH ATISFYING ET(P )Sopt Sopt G ET ATISFYING ET(P )P .isSatisfied truePass Pass {P }endendendendreturn Soptprocedure G ET ATISFYING ET(P )itemproperty value defined P{o}end|S| P .op P .cardinalityreturnendendend procedure. Offline conflict resolution. cardinality satisfies PFigure 9: polynomial-time algorithm POS problems TCP-net preference specification, single-attribute item description, set properties atomic (that is,= 1 k = 0).5.2.2 N -T RIVIALLY RACTABLE C LASSend Section 5.1 mentioned complexity POS limiting setproperty description one logical connective still open problem. If, however,impose limitations summarized Table 4, show problem becomes tractable.Theorem 4. Finding optimal subset given set items (POS) respect TCP-netpreference specification P restricted Table 4.First discuss implicit limitations (or special problem properties) imposedexplicit limitations listed Table 4.156fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTS1. items one attribute (a = 1)2. property formulas 1 connective (k = 1), positive (that is,disallow negation)3. empty property disallowed4. number attribute value appearances limited = 1 (that is, valuesattribute domain cannot repeated)Table 4: Characteristics tractable subclass POS presented Section 5.2.2.1. restriction one attribute-value appearance data set provides one-toone correspondence attribute values items S. means itemuniquely represent specific attribute-value combination, vice versa.2. restriction single-attribute item description renders connective redundant.properties using logical connective form:X = xi X = xj .(Without loss generality assume 6= j, otherwise simply drop oneterms.) properties obviously cannot satisfied item two differentvalues attribute X. fact, set properties defined way equivalentproperty always f alse.3. relevant cardinalities set properties [0..2]. property defined usingone connective restriction number repetitions expressive enoughstate set property involving 2 items. value set property:h|A = ai = aj |opvalueigreater 2, op {, >}, cannot satisfied. op property<, value greater 2, substituted effectively equivalentset property op value = 2 .algorithm problem class Theorem 4 depicted Figure 10. algorithm bearssimilarity algorithm Figure 9, except procedures G ET ATISFYING ETH ATISFYING ET reason simultaneously satisfaction collections set-propertyvalues, utilizing 2-SAT solving. Specifically, Table 5 show validproperty POS problem translated 2-SAT CNF formula. Lemma 3prove correctness translation. note using 2-SATanswer question subset items satisfying already evaluated set-propertyvalues. procedures G ET ATISFYING ET H ATISFYING ET use aforementionedreduction 2-SAT provide answer polynomial time.Lemma 3. subset satisfying property-values Passsatisfying assignment 2-SAT formula constructed Pass .157fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYh|Xh|Xh|Xh|Xh|Xh|X= xi | > 2i infeasible= xi | 2i infeasible= xi | 1i substituted= xi | = 1i translated (vi ) clause= xi | 0i translated (vi vi ) clause= xi | = 0i translated (vi ) clauseProperties 0 logical connectivesh|X = xi X = xj | > 2i infeasibleh|X = xi X = xj | 2i substitutedh|X = xi X = xj | = 2i translated (vi )(vj ) clausesh|X = xi X = xj | 1i translated(vi vj ) clauseh|X = xi X = xj | = 1i translated(vi vj ) (vi vj ) clausesh|X = xi X = xj | 0i translated(vi vj ) clauseh|X = xi X = xj | = 0i translated (vi )(vj ) clausesProperties 1 logical connectiveTable 5: Translation set properties POS subclass Section 5.2.2 2-SAT.1:2:3:4:5:6:7:8:9:10:11:12:13:14:Fix preference ordering set properties PSoptPassproperty P P(not (P .isSatisfied))Set next value P w.r.t. PassH ATISFYING ET(Pass )Sopt G ET ATISFYING ET(Pass )P .isSatisfied truePass Pass {P }endendendreturn Sopt. Use reduction 2-SAT. Use reduction 2-SATFigure 10: poly-time algorithm POS problems TCP-net preference specification,characteristics Table 4.Proof. construction, injective correspondence properties POSproblem clauses 2-SAT problem. Every property P P injectively correspondscertain clause P . Every item injectively corresponds propositional variable vi V .Thus, correspondence selected subset assignment simplyvi = true S.158(1)fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTStranslation injective rather straightforward (without introducing auxiliaryclauses properties), trivial subset satisfies properties Passassignment satisfies clauses corresponding 2-SAT formula.shows correctness algorithm Figure 10, finalizes proof Theorem 4.5.3 Complexity POS: TCP-nets vs. GAI Preference Specificationrestrictions Table 4 able show POS problem TCP-netpreference specification tractable reduction 2-SAT, need backtracksearching attribute value space. interesting question is, specificationdone using GAI functions?Theorem 5. Finding optimal subset given set items (POS) respect GAI preference specification NP-hard even items described terms single attribute, setproperties binary-valued, containing 1 logical connective (that is, = 1k = 1).Proof. proof polynomial reduction MAX-2SAT. far item definitionsproperties concerned, reduction essentially reduction k-SATproof Theorem 2. is, variable v V , construct item ov item ov .value attribute X defined follows: item ol , A(ol ) = l (where lliteral, either v v, v V ). Set properties also proof Theorem 2,limited 2 variables per clauses (re-stated convenience below):variable v V :Pv =h|X = v X = v| = 1i,is, properties ensuring variable assignment legitimate.clause C = (l1 l2 ) :PC =h|X = l1 X = l2 | 1i,is, properties ensuring satisfied.value function specification legitimate variable assignments enforced,larger number clauses satisfied preferred. achieved using additively independentvalue function (i.e., factor contains single variable), values follows.clause-satisfying property value 1 true, 0 f alse. literalsatisfying property value 0 true, negative value 2m f alse,number clauses.Lemma 4. Given GAI value function item set constructed 2-CNF formula, exists subset value U (S) = p exists assignmentsatisfying p clauses .159fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYProof. Let subset non-negative value. implies construction (sinceclause-satisfying properties PC ) literal-satisfying properties must trueS, respective assignment constructed Equation 1. Conversely, letlegitimate assignment variables V . One define corresponding set SA ,(by construction) properties Pv true. Also, observe construction number PCset properties true SA number clauses satisfied assignmentA.theorem follows immediately properties construction set propertiespreferences.end Section 5.1 noted restrictions problem parameterssevere Theorem 2, limiting number logical connectives per set property1, longer show whether problem tractable NP-hard TCPnet preference specification. However, Theorem 5 shows that, preferences specified usingGAI value function, problem fact NP-hard. Moreover, problem class Theorem5 subsumes class Theorem 4, thus provides additional result showing eventhough TCP-net specification respective problem tractable, GAI preferencespecification becomes NP-hard.6. Related Workintroduction, mentioned closely related work desJardins Wagstaff (2005).approach, motivation provide user diverse collection values eitherreflect set possible choices better applications user must eventually selectsingle item, diversity selected set objective own. work PriceMessinger (2005) explicitly concerned problem. Specifically, considerproblem recommending items user, view type subset selection problem.example, suppose want recommend digital camera user. large set availablecameras, able recommend k cameras. Price Messinger consider questionselect set, proposing candidate set maximize expected valueusers choice set. suggest concrete algorithmic approach handling problem.input problem form partial representation users preferences (whichdiverse, work) naturally, concrete techniques different ours.papers share assumption ranking sets, common previous work discussedBarbera et al. (2004), ultimately one item selected set. However,necessarily start initial ranking single items, case, workdesJardins Wagstaff utilizes attribute value items selection process.Earlier work ranking subsets motivated problems college admissionsproblem (Gale & Shapley, 1962), need select best set fixed cardinality amongpool college candidates. admissions officer various criteria good class studentswishes come optimal choice. key questions concerned linework good properties set rankings whether simplerepresentation. example property set ranking may desirable following:given set S, replace member c member c0 obtain set 0 ,c0 preferred c, 0 preferred S. example representation ranking160fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSadditive representation items associated real values one set preferredanother sum elements values larger. would interesting study similar questioncontext structured objects.question ranking sets appears areas, logics preference likelihood.example, main question considered Halpern (1997) construct orderingformulas based ordering truth assignments. Formulas associated setworlds satisfied, hence, question comparing likelihood formulascorresponds ranking respective set models given initial rankingsingle models. Much work non-monotonic logics uses Shohams preference semantics (Shoham,1987), semantically, work (see, e.g., Kraus, Lehmann, & Magidor, 1990) viewedattempting answer opposite question define ranking single truth assignments givensome, possibly partial, ordering formulas, i.e., sets models.number lines work related specification solution methods. firstwork Russian Doll Search (RDS), well known algorithm combinatorial optimization,originally presented Verfaillie, Lematre, Schiex (1996) efficient algorithm Constraint Optimization Problems (COP). idea behind approach solve consecutively harderproblems. Initially, problem solved considering one variable. optimal resultprovides lower bound. iteration, additional variables considered, eventually original problem solved. using lower bound obtained previous iteration (andoptimizations) technique often able solve original problem efficiently. RecentlyRollon Larrosa (2007) extended Russian Doll Search support multi-objective optimizationproblems. multi-objective optimization problem goal optimize several parameters(attributes) variables problem. Usually parameters cannot simultaneouslyoptimized. technique Rollon Larrosa involves incremental solutionobjectives included, and, sense, related search CSPs approachincrementally consider set properties. Indeed, different desirable set propertiesviewed different objectives.Another related area Pseudo-Boolean Constraint (PBC) Satisfaction Problems (Sheini& Sakallah, 2005). PBC form:Xwi li k.li literals interpret values either 0 (false) 1 (true); wireal-valued coefficients; k integer. Thus Pseudo-Boolean CSPs special form integer programs, nicely represent cardinality constraints generate. Thus, one optionsolving type CSPs generated would using dedicated PBC solver. run several popular PBC solvers satisfiability instances generated optimization: Pueblo (Sheini &Sakallah, 2005), MiniSat (Een & Sorensson, 2005), Galena (Dixon & Ginsberg, 2002).solvers showed comparable results satisfiable cases, unsatisfiable cases, PBCsolvers showed better performance. appears due use linear programmingpreliminary test satisfiability.Another line work bears important connection winner determinationcombinatorial auctions. regular auctions, bidders bid single item. combinatorial auctions, bidders bid bundles items. Thus, bidders must provide preferences differentsubsets set auctioned items. goal combinatorial auctions allocate set161fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYgoods different bidders best manner (e.g., maximizing payment seller maximizing total welfare). differs problem selecting single optimal subsetconcerned. However, cases, preferences subsets must provided optimization algorithm. number subsets exponential number items, researcherscombinatorial auctions sought bidding languages succinctly describe preferencesinterest (Boutilier & Hoos, 2001; Nisan, 2006). distinguishes specification approachreliance existence item features desire provide generic specificationdepend concrete set items. Work combinatorial auctions also attempts breakspecification way. typically done specifying values small bundlesproviding rules deriving value larger sets values smaller sets.7. Conclusionsuggested simple, yet general approach lifting attribute-based preference specificationformalism one specifying preferences sets. focused one instantiation ideavia concrete language specifying set properties, suggested two methods computingoptimal subset given specification. One method based searching space explicitsubsets, searches implicit subsets represented CSPs. search spacesmeaningful regardless specific underlying preference specification algorithm althoughprecise search bounds generation method vary. focused two concrete popularspecification formalisms, one qualitative one quantitative, experiment provide complexity results. Although problem generally NP-hard, expected, experimentalresults quite encouraging.wish reemphasize choices, set property language preference specification formalism possible, may appropriate various cases. Indeed,interesting topic future research would see choices fit best natural application areas; whether algorithm presented paper modified handlelanguages; complexity optimal subset selection problem affectedchoices.Though incremental search CSPs appears better method optimal subset selection, leaves questions open. First, interesting question whether efficient NoGoodrecording scheme rely static variable value orderings exists. Intuitively,scheme exist since CSPs generated efficiently encoded SAT booleanCNF formula (Bailleux & Boufkhad, 2004; Een & Sorensson, 2005), clause learning wellknown technique SAT solving. Second, seen incremental approach usuallyimproves overall performance, contribution substantial really improvesperformance better individual CSP solving. begs two questions: (1) better utilize solutions across CSPs, (2) Would representing solving CSPs generated pseudo-booleanCSPs (Manquinho & Roussel, 2006) SAT instances lead faster solution times? Naturally,alternative approaches also feasible.Finally, various applications, set elements gradually changes, need adaptselected subset changes. example use approach chooseinteresting current articles, new articles constantly appear. likely casepreferred set similar current set, would like formulate incremental approachadapts changes quickly.162fiG ENERIC P REFERENCES UBSETS TRUCTURED BJECTSAcknowledgmentsPreliminary versions work appeared (Brafman, Domshlak, Shimony, & Silver, 2006b;Binshtok, Brafman, Shimony, Mani, & Boutilier, 2007). authors wish thank anonymousreviewers useful comments suggestions. Brafman supported part NSF grantIIS-0534662, Brafman Domshlak supported COST action IC0602, Binshtok, Brafman Shimony supported Deutsche Telekom Laboratories Ben-Gurion University,Paul Ivanier Center Robotics Research Production Management, LynnWilliam Frankel Center Computer Science.ReferencesBacchus, F., & Grove, A. (1995). Graphical models preference utility. Proceedings11th Annual Conference Uncertainty Artificial Intelligence (UAI), pp. 310, SanFrancisco, CA.Bailleux, O., & Boufkhad, Y. (2004). Full CNF encoding: counting constraints case. 7thInternational Conference Theory Applications Satisfiability Testing (SAT), Vancouver, BC, Canada.Barbera, S., Bossert, W., & Pattanaik, P. K. (2004). Handbook Utility Theory. Volume II: Extensions, chap. Ranking Sets Objects, pp. 893977. Kluwer Academic Publishers.Binshtok, M., Brafman, R. I., Shimony, S. E., Mani, A., & Boutilier, C. (2007). Computing optimalsubsets. Proceedings 22nd National Conference Artificial Intelligence (AAAI),pp. 12311236, Vancouver, BC, Canada.Bistarelli, S., Fargier, H., Montanari, U., Rossi, F., Schiex, T., & Verfaillie, G. (1999). Semiringbased CSPs valued CSPs: Frameworks, properties, comparison. Constraints, 4(3),275316.Boutilier, C., Brafman, R., Domshlak, C., Hoos, H., & Poole, D. (2004). CP-nets: tool representing reasoning conditional ceteris paribus preference statements. JournalArtificial Intelligence Research, 21, 135191.Boutilier, C., & Hoos, H. H. (2001). Bidding languages combinatorial auctions. Proceedings17th International Joint Conference Artificial Intelligence (IJCAI), pp. 12111217,Seattle, WS.Brafman, R. I., Domshlak, C., & Shimony, S. E. (2006a). graphical modeling preferenceimportance. Journal Artificial Intelligence Research, 25, 389424.Brafman, R. I., Domshlak, C., Shimony, S. E., & Silver, Y. (2006b). Preferences sets.Proceedings 21st National Conference Artificial Intelligence (AAAI).Brafman, R. I., & Domshlak, C. (2008). Graphically structured value-function compilation. Artificial Intelligence, 172, 325349.Dago, P., & Verfaillie, G. (1996). Nogood recording valued constraint satisfaction problems.ICTAI, pp. 132139.Dechter, R. (1990). Enhancement schemes constraint processing: Backjumping, learning,cutset decomposition. Artif. Intell., 41(3), 273312.163fiB INSHTOK , B RAFMAN , OMSHLAK , & HIMONYdesJardins, M., & Wagstaff, K. (2005). DD-PREF: language expressing preferencessets. Proceedings 20th National Conference Artificial Intelligence (AAAI), pp.620626, Pittsburgh, PA, USA.Dixon, H. E., & Ginsberg, M. L. (2002). Inference methods pseudo-Boolean satisfiabilitysolver. Proceedings 18th National Conference Artificial Intelligence (AAAI), pp.635640, Edmonton, Canada.Een, N., & Sorensson, N. (2005). Translating pseudo-boolean constraints SAT. JournalSatisability, Boolean Modeling Computation (JSAT), 2, 126.Fishburn, P. C. (1969). Utility Theory Decision Making. John Wiley & Sons.Gale, D., & Shapley, L. S. (1962). College admissions stability marriage. AmericanMathematical Monthly, 69, 915.Halpern, J. (1997). Defining relative likelihood partially-ordered preferential structures. JournalArtificial Intelligence Research, 7, 124.Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential modelscumulative logics. Artificial Intelligence, 44, 167207.Manquinho, V. M., & Roussel, O. (2006). first evaluation pseudo-boolean solvers. JournalSatisability, Boolean Modeling Computation (JSAT), 2, 103143.Nisan, N. (2006). Bidding languages combinatorial auctions. Cramton, P., Shoham, Y., &Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2. MIT Press.Price, B., & Messinger, P. (2005). Optimal recommendation sets: Covering uncertainty userpreferences. Proceedings 20th National Conference Artificial Intelligence (AAAI),pp. 541548, Pittsburgh, PA.Prosser, P. (1993). Hybrid algorithms constraint satisfaction problem. Computational Intelligence, 9, 268299.Rollon, E., & Larrosa, J. (2007). Multi-objective Russian Doll Search. Proceedings 22ndNational Conference Artificial Intelligence (AAAI), pp. 249254, Vancouver, BS, Canada.Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraint satisfactionproblems. ICTAI, pp. 4855.Sheini, H. M., & Sakallah, K. A. (2005). Pueblo: modern pseudo-boolean SAT solver. Proceedings Conference Design, Automation Test Europe (DATE), pp. 684685.Shoham, Y. (1987). semantics approach non-monotonic logics. Proceedings 10thInternational Joint Conference Artificial Intelligence (IJCAI), pp. 388392, Milan, Italy.Verfaillie, G., Lematre, M., & Schiex, T. (1996). Russian Doll Search solving constraint optimization problems. Proceedings 13th National Conference Artificial Intelligence(AAAI), pp. 181187, Portland, OR.164fiJournal Artificial Intelligence Research 34 (2009) 391442Submitted 07/08; published 03/09Solving #S Bayesian Inference Backtracking SearchFahiem BacchusShannon DalmaoToniann PitassiFBACCHUS @ CS . TORONTO . EDUTONI @ CS . TORONTO . EDUDepartment Computer ScienceUniversity TorontoToronto, OntarioCanada, M5S 3G4AbstractInference Bayes Nets (BAYES) important problem numerous applications probabilistic reasoning. Counting number satisfying assignments propositional formula(#S AT) closely related problem fundamental theoretical importance. problems,others, members class sum-of-products (S UM P ROD) problems. papershow standard backtracking search augmented simple memoization scheme(caching) solve sum-of-products problem time complexity least goodstate-of-the-art exact algorithm, also achieve best known time-spacetradeoff. Furthermore, backtrackings ability utilize flexible variable orderings allows usprove achieve exponential speedup standard algorithms UM P RODinstances.ideas presented utilized number solvers appliedvarious types sum-of-product problems. systems exploited fact backtrackingnaturally exploit problems structure achieve improved performance rangeproblem instances. Empirical evidence performance gain appeared published worksdescribing solvers, provide references works.1. IntroductionProbabilistic inference Bayesian Networks (BAYES) important well-studied problemnumerous practical applications probabilistic reasoning (Pearl, 1988). Counting numbersatisfying assignments propositional formula (#S AT) also well-studied problemfundamental theoretical importance. two problems known closely related.particular, decision versions #S BAYES #P-complete (Valiant, 1979b, 1979a;Roth, 1996), natural polynomial-time reductions problem(Darwiche, 2002; Sang, Beame, & Kautz, 2005b; Chavira, Darwiche, & Jaeger, 2006).direct relationship two problems arises observationinstances general sum products problem (S UM P ROD). Perhapsfundamental algorithm UM P ROD (developed general way Dechter 1999) basedidea eliminating variables problem one one following fixed order.algorithm called variable elimination (VE), core notion many state-of-the-art exactalgorithms UM P ROD (and BAYES).SAT, problem determining whether propositional formula satisfyingassignments, also instance UM P ROD, original Davis-Putnam algorithm (DP)determining satisfiability (Davis & Putnam, 1960) uses ordered resolution versionc2009AI Access Foundation. rights reserved.fiBACCHUS , DALMAO , & P ITASSIvariable elimination. However, DP never used practice performance far inferiormodern versions backtracking search based DPLL algorithm (Davis, Logemann, & Loveland,1962). fact DP provably less powerful modern versions DPLL equipped clauselearning (Hertel, Bacchus, Pitassi, & van Gelder, 2008).performance gap naturally raises question whether backtracking search couldused solve types UM P ROD problems efficiently variable elimination.paper, present general algorithmic framework using backtrack search methods (specifically DPLL) solve UM P ROD related problems.1 first show straightforward adaptation backtracking solving UM P ROD insufficient. However, examining sourcesinefficiency able develop simple caching schemes allow backtrackingalgorithm, #DPLL-Cache, achieve performance guarantees state-of-the-art exact algorithms UM P ROD, terms time space. Furthermore, prove backtrackingsnatural additional flexibility allows sometimes achieve exponential speedup existing algorithms. Specifically, present family UM P ROD instances #DPLL-Cacheachieves exponential speedup original versions three prominent algorithms UM P ROD.Besides theoretical results, also good reasons believe backtracking basedalgorithms potential perform much better worst case guarantees problemsarise real domains. fact, subsequent work investigated practical applicationideas presented problem counting satisfying assignments, BAYES, constraintoptimization successful results (Sang, Bacchus, Beame, Kautz, & Pitassi, 2004; Sanget al., 2005b; Sang, Beame, & Kautz, 2005a, 2007; Davies & Bacchus, 2007; Kitching & Bacchus,2008).outline paper follows. Section 2, define UM P ROD ; demonstrate #S ,BAYES, important problems instances class problems; discuss various graphtheoretic notions width used characterize complexity algorithms UM P ROD; review core state-of-the-art exact algorithms UM P ROD. Section 3,discuss DPLL-based algorithms caching solving #S UM P ROD provide worstcase complexity bounds algorithms. bounds best time spaceguarantees achieved currently known algorithms. Section 4, provide frameworkcomparing algorithms algorithms UM P ROD prove caching DPLLefficiently simulate known exact algorithms sometimes achieving super-polynomiallysuperior performance. Section 5 discuss work used algorithmicideas build practical solvers various problems. Finally, provide closing remarksSection 6.2. Backgroundsection, first define sum-of-products (S UM P ROD) class problems, illustrate BAYES, #S AT, important problems instances UM P ROD.show rest paper, backtracking search equipped different caching schemes1. notion backtracking previous set commitments utilized contexts, includingalgorithms UM P ROD. However, referring standard algorithmic paradigm backtrackingsearch explores single tree partial variable assignments depth-first manner. algorithmextensive history stretches back hundred years (Bitner & Reingold, 1975).392fiBACKTRACKING EARCH#SAT BAYESwell suited solving UM P ROD. key computational structure exploited algorithms UM P ROD explained graph theoretic notion width capturesstructure identified. Different notions width exist, present three different definitionsshow yield essentially equivalent measures complexity. different definitionshowever useful different algorithms easily analyzed using different definitions width. Finally, briefly review important exact algorithms solvingUM P ROD related problems.2.1 Sum-of-ProductsDechter (1999) shown BAYES many problems instancesgeneral problem called UM P ROD (sum-of-products). instance UM P ROD definedtuple hV, F, , i, V set discrete valued variables {X1 , . . . , Xn }, F setfunctions {f1 , . . . , fm } fi defined set variables Ei V, additionoperator, multiplication operator. range functions F depends problem,operators range commutative, associative,distributes . Typical examples involve functions range boolean domain,disjunction conjunction , reals, ordinaryaddition multiplication.Definition 1 (S UM P ROD) Given hV, F, , UM P ROD problem computeMMX1 X2MOfi (Ei ),Xn i=1i.e., sum () values (assignments) variables V product () functionsF evaluated assignments.number well known problems instances UM P ROD. describebelow.2.1.1 BAYES :BAYES problem computing probabilities Bayesian Network (BN). Developed Pearl(1988), Bayesian network triple (V, E, P) (V, E) describes directed acyclic graph,nodes V = {X1 , . . . , Xn } represent discrete random variables, edges represent directcorrelations variables, associated random variable Xi conditionalprobability table CPT (or function), fi (Xi , (Xi )) P, specifies conditional distributionXi given assignments values parents (Xi ) (V, E). BN represents joint distributionrandom variables V probability assignment (x1 , . . . , xn ) variablesQgiven equation Pr (x1 , . . . , xn ) = ni=1 fi (xi , (xi )), fi (xi , (xi )) fi evaluatedparticular assignment.generic BAYES problem compute posterior distribution variable Xi givenparticular assignment variables : i.e., Pr (Xi |). Since Xi finite setk values, problem reduced computing k values Pr (Xi = dj ),j = 1, . . . , k normalizing sum 1. values Pr (Xi = dj )computed making assignments well Xi = dj , summing393fiBACCHUS , DALMAO , & P ITASSIvariables joint distribution Pr (x1 , . . . , xn ). Given product decompositionPr (x1 , . . . , xn ), equivalent reducing functions fi P setting variablesassigned Xi = dj , summing product remaining variables; i.e.,instance UM P ROD.Computing Marginals common solving BAYES want compute marginals.is, instead wanting compute marginal Pr(Xi |) one particular variable Xi ,want compute marginal variables instantiated .2.1.2 ARKOV R ANDOM F IELDSMarkov Random Fields Markov Networks (MN) (Preston, 1974; Spitzer, 1971) similarBayesian Networks also define joint probability distribution set discreterandom variables V = {X1 , . . . , Xn } using set functions fi , called potentials,set variables Ei V. particular, probability assignment (x1 , . . . , xn ) variablesgiven normalized product fi evaluated values specified assignment:Qfi (Ei [x1 , . . . , xn ]). difficulty compute partition function, normalizing constant:Z=XXYfi (Ei ).Xn i=1X1Computing partition function thus instance UM P ROD.2.1.3 OST P ROBABLE E XPLANATIONProbable Explanation (MPE) problem finding probable complete assignmentvariables Bayes net (or Markov net) agrees fixed assignment subsetvariables (the evidence). evidence, , instantiation variables E V, MPEproblem computingmaxV Efi | (Ei E),i=1fi | reduction function fi instantiations variables E (yieldingfunction variables Ei E).2.1.4Let V = {X1 , X2 , . . . , Xn } collection n Boolean variables, let (V) k-CNFBoolean formula variables clauses {c1 , . . . , cm }. assignment Booleanvariables V satisfying makes formula True (i.e., () = 1). asks, given Booleanformula (V) k-CNF, satisfying assignment? viewing clause cifunction variables Ei (i.e., maps assignment variables TRUE assignmentsatisfies clause FALSE otherwise), see equivalent instanceUM P ROD hV, {c1 , . . . , cm }, , i:_X1_^Xn i=1394ci (Ei ).fiBACKTRACKING EARCH#SAT BAYES2.1.5 #SGiven k-CNF formula (V) boolean variables V = {X1 , . . . , Xn }, above, #Sproblem determining number satisfying assignments . viewing clauseci function variables Ei {0, 1} (i.e., maps satisfying assignments 1falsifying assignments 0), see #S equivalent instance UM P RODhV, {c1 , . . . , cm }, +, i:XX12.1.6 PTIMIZATIONXYci (Ei ).Xn i=1ECOMPOSED BJECTIVE F UNCTIONSLet V = {X1 , . . . , Xn } collection finite valued variables, optimization task findassignment values variables maximizes objective function O(V) (i.e.,function maps every complete assignment variables real value). many problemsdecomposed sum sub-objective functions {f1 , . . . , fm } fifunction subset variables Ei . problem cast UM P RODinstance hV, {f1 , . . . , fm }, max, +imax maxX1XnXfi (Ei ).i=12.2 Computational Complexity UM P RODUM P ROD computationally difficult problem. example, #S known completecomplexity class #P (Valiant, 1979b, 1979a) BAYES (Roth, 1996). Many special caseseasy remain hard #S AT, e.g., Valiant showed decision version #S #Phard even clause size, k, 2, Roth (1996) showed problem hard evenapproximate many cases easy, e.g., (V) monotone, Horn, 2-CNF.Despite worst case intractability, algorithms UM P ROD, e.g., variable eliminationalgorithm presented Dechter (1999), successful practice. key structure exploitedalgorithm, algorithms, functions fi many UM P ROD problemsoften relatively local fairly independent. is, often case sets variablesEi function fi depends small, function dependent smalllocal set variables, sets share variables other,functions fi fairly independent other. graph theoretic notion Tree Width usedmake intuitions precise.2.3 Complexity Measures Tree widthnatural hypergraph, H = (V, E), corresponding instance hV, F, , UM P ROD. hypergraph, V corresponds set V variables, every function fidomain set Ei , corresponding hyperedge, Ei .width hypergraph critical measure complexity essentially state-ofthe-art algorithms #S , BAYES, UM P ROD. three different (and well known)notions width define section. also show different notionswidth basically equivalent. equivalences known, although need state395fiBACCHUS , DALMAO , & P ITASSIprove basic properties, order analyze new algorithms, relate standardalgorithms.Definition 2 (Branch width) Let H = (V, E) hypergraph. branch decomposition Hbinary tree node labelled subset V . |E| many leaves, labels one-to-one correspondence hyperedges E. noden , let denote union leaf labeling subtree rooted n, let B denoteunion labelings rest leaves. label n set vertices vintersection B. branch width branch decomposition Hmaximum size labeling . branch width H minimum branch widthbranch decompositions H.Example 1 Figure 1 shows particular branch decomposition Tbd hypergraph H = (V, E)V = {1, 2, 3, 4, 5} E = {{1, 2, 3}, {1, 4}, {2, 5}, {3, 5}, {4, 5}}. Tbd branch width3.{}HHHHH{3, 4, 5}{3, 4, 5}HHHHH{2, 3, 4}{2, 5}{3, 5}{4, 5}HHH{1, 2, 3}{1, 4}Figure 1: branch decomposition branch width 3 H = {(1, 2, 3), (1, 4), (2, 5), (3, 5),(4, 5)}.Definition 3 (Elimination width) Let H = (V, E) hypergraph, let = v1 , . . . , vnordering vertices V , vi ith element ordering. induces sequencehypergraphs Hn , Hn1 , . . . , H1 H = Hn Hi1 obtained Hi follows.edges Hi containing vi merged one edge vi removed. Thus underlying. induced width H size largest edgevertices Hi v1 , . . . vi1hypergraphs Hn , . . . , H1 . elimination width H minimum induced widthorderings .Example 2 ordering = h1, 2, 3, 4, 5i hypergraph H Example 1 producesfollowing sequence hypergraphs:H5 = {(1, 2, 3), (1, 4), (2, 5), (3, 5), (4, 5)}H4 = {(2, 3, 4), (2, 5), (3, 5), (4, 5)}H3 = {(3, 4, 5), (3, 5), (4, 5)}H2 = {(4, 5), (4, 5)}H1 = {(5)}396fiBACKTRACKING EARCH#SAT BAYESinduced width H 3the edges (1, 2, 3) H1 , (2, 3, 4) H2 (3, 4, 5) H3achieve size.Tree width third notion width.Definition 4 (Tree width) Let H = (V, E) hypergraph. tree decomposition Hbinary tree node labelled subset V following way. First,every hyperedge e E, leaf node must label contains e. Secondly, givenlabels leaf nodes every internal node n contains v V label n pathtwo leaf nodes l1 l2 whose labels contain v.2 tree width tree decompositionH maximum size labeling minus 1, tree width H minimumtree width tree decompositions H.Example 3 Figure 2 shows Ttd tree decomposition H Example 1. Ttd tree width 3.{3, 4, 5}HHHHH{2, 3, 4, 5}HHH{1, 2, 3, 4}{2, 5}{3, 4, 5}HH{3, 5}{4, 5}HHH{1, 2, 3}{1, 4}Figure 2: Tree decomposition tree width 3 H Example 1.next three lemmas show three notions basically equivalent. proofsLemmas 2 3 given appendix.Lemma 1 (Robertson & Seymour, 1991) Let H hypergraph. branch width Htree width H plus 1, tree width H 2 times branch width H.Lemma 2 Let H = (V, E) hypergraph tree decomposition width w.elimination ordering vertices V induced width H w.Lemma 3 Let H hypergraph elimination width w. H tree decomposition tree width w.Letting TW (H), BW (H), EW (H) represent tree width, branch width eliminationwidth hypergraph H, lemmas give following relationship threenotions width: hypergraphs HBW (H) 1 TW (H) = EW (H) 2BW (H).2. Since labels internal nodes determined labels leaf nodes way, seenpair nodes n1 n2 tree decomposition every node lying path must contain vlabel v appears n1 n2 labels. commonly known running intersection property treedecompositions.397fiBACCHUS , DALMAO , & P ITASSI{4, 5}HHHH{3, 4, 5}{4, 5}HHHH{2, 3, 4, 5}{3, 5}HHH{1, 2, 3, 4}{2, 5}HHH{1, 2, 3}{1, 4}Figure 3: Tree decomposition hypergraph H Example 1 constructedordering = h1, 2, 3, 4, 5i.Example 4 tree decomposition Ttd H = {(1, 2, 3), (1, 4), (2, 5), (3, 5), (4, 5)} given Figure 2 property tree width twice branch width branchdecomposition Tbd H given Figure 1. Ttd obtain ordering = h1, 2, 3, 4, 5iused Example 2. (The proof Lemma 2, given appendix, shows elimination ordering constructed tree-decomposition.) shown Example 2,induced width 3, equal tree width tree decomposition Ttd constructed.Finally, ordering construct new tree decomposition H shown Figure 3.(The proof Lemma 3 shows tree decomposition constructed eliminationordering). induced width 3 and, indicated Lemma 3 tree decomposition constructedequal tree width 3.noted definition tree decompositions varies slightly definitionsappear literature, e.g., (Bodlaender, 1993). Following Robertson Seymour (1991)defined tree decompositions hypergraphs, rather graphs, madetwo extra restrictions simplify proofs results. First, restricted treedecompositions binary trees, second required hyperedge containedlabel leaf node tree decomposition. Usually tree decompositionsrestricted binary trees, require hyperedge contained nodes label(not necessarily leaf node).difficult show tree decomposition fails satisfy two restrictionsconverted tree decomposition satisfying restrictions without changing width.However, straight forward observe without two restrictions tree widthequal elimination width. Hence, restrictions change tree width.2.4 Exact Algorithms UM P RODNext briefly review three prominent exact algorithms BAYES. algorithms solvegeneral problem UM P ROD. algorithms fact nondeterministic algorithmsconsidered families procedures, member particular deterministic realization.398fiBACKTRACKING EARCH#SAT BAYES2.4.1 VARIABLE E LIMINATION :Variable bucket elimination (VE) (Dechter, 1999) fundamental algorithm UM P ROD.Variable elimination begins choosing elimination ordering, variables V = {X1 ,. . ., Xn }: X(1) , . . ., X(n) . (This nondeterministic part computation). firstphase, functions involving X(1) , collected together set FX(1) , new function,F1 computed summing X(1) . new function sums product functionsFX(1) X(1) values. Specifically, F1 function variables functionsFX(1) except X(1) , value assignment variablesF1 () =Xf (, X(1) = d).dvals(X(1) ) f FX(1)Summing X(1) induces new hypergraph, H1 , hyperedges corresponding setfunctions FX(1) replaced single hyperedge corresponding new function F1 .process continues sum X(2) H1 n variables summed out.Note sequence hypergraphs generated summing variables accordingsequence hypergraphs defines induced width (Definition 3).original Davis-Putnam algorithm (Davis & Putnam, 1960) based ordered resolutioninstance variable elimination. Consider applying variable elimination formulationgiven above. AT, new functions Fi computed stage need preserve whetherproduct functions FX(i) 0 1, exact number satisfying assignments needremembered. accomplished representing Fi symbolically set clauses.Furthermore, set clauses computed generating clauses obtainedresolving X(i) , discarding old clauses containing X(i) . resolution stepcorresponds summing operation, yields precisely Davis-Putnam (DP) algorithmsatisfiability.32.4.2 R ECURSIVE C ONDITIONING :Recursive conditioning (RC) (Darwiche, 2001) another type algorithm UM P ROD. Let= hV, F, , instance UM P ROD H underlying hypergraph. RCdivide conquer algorithm instantiates variables V break problemdisjoint components. proceeds solve components independently. original spaceefficient version recursive conditioning, specified Darwiche (2001), begins branchdecomposition H width w depth d, initially empty set instantiated variables. (Choosing nondeterministic part computation.) call algorithm RC-Spaceshow Algorithm 1.branch decomposition specifies recursive decomposition problem usedRC-Space follows. Let label (n) label node , let ST UM P ROD problemdefined variables functions contained . (In initial call complete branchdecomposition containing variables functions S, initially ST = S). Starting r,root , RC-Space solves reduced UM P ROD ST | assignments variables3. Rish Dechter (2000) previously made connection DP variable elimination. thusable show, DP runs time nO(1) 2O(w) , w branch width underlying hypergraph SATinstance.399fiBACCHUS , DALMAO , & P ITASSIlabel (left(r)) label (right(r)) yet instantiated , left(r) right (r) leftright children r. sum solution inputed instance ST | .renders set functions subtree leftChild (r) (i.e., leaf labels) disjointfunctions rightChild (r). Thus , RC-Space independently solvesubproblems specified leftChild (r)| rightChild (r)| (i.e., sum productsfunctions left/right subtree conditioned instantiations )multiply answers obtain solution ST | . leaf nodes, function fi associatednode variables instantiated, algorithm simply LOOKUP ficurrent value.Algorithm 1: RC-SpaceLinear Space Recursive Conditioning1234567891011RC-Space (T, )beginleaf nodereturn LOOKUP(value function labeling leaf node)p = 0; r = root (T )~x = variables label (left(r)) label (right(r)) uninstantiatedforall {instantiations ~x}p = p + RC-Space (leftChild (T ), ) RC-Space (rightChild (T ), )endreturn pendless space-efficient time-efficient version recursive conditioning, called RCCache, caches intermediate values reused reduce computation. Algorithm 2shows RC-Cache algorithm. Like RC-Space, invocation RC-Cache solves subproblem specified variables functions contained passed subtree . Since functionsshare variables label (root(T )) variables outside , instantiations subset, y, intersecting label (root(T )) affect form subproblem.Hence, RC-Cache return answer invoked y, evenassignments changed. RC-Cache, thus use index cache, storing computed result cache (line 13) returning immediately answer already cache(line 7).Propagation Since RC instantiates problems variables, propagation employed.is, RC perform additional inference compute implicit effects assignmentremaining problem ST | . example, functions UM P ROD problemclauses (e.g., solving #S AT) unit propagation performed. Propagationmake recursive conditioning effective. example, one remaining clauses becomesfalsified unit propagation, recursive conditioning immediately move nextinstantiation variables ~x. Similarly, unit propagation force value variablesencountered subsequent recursive calls, thus reducing number different instantiationsmust attempted recursive call. noted propagation reduceworst case complexity algorithm, UM P ROD problems propagation ineffective.however improve algorithms efficiency families problems.400fiBACKTRACKING EARCH#SAT BAYESAlgorithm 2: RC-CacheRecursive Conditioning caching123456789101112131415RC-Cache (T, )beginleaf nodereturn LOOKUP(value function labeling leaf node)= label (root(T ))InCache(T, y)return GetValue(T, y)p = 0; r = root (T )~x = variables label (left(r)) label (right(r)) uninstantiatedforall {instantiations ~x}p = p + RC-Cache (leftChild (T ), ) RC-Cache (rightChild (T ), )endAddToCache((T ,y), p)return pendRC-Cache+ simple extension RC used practice set variables ~xlabel (left(r) label (right (r)) (line 10 Algorithm 2) iteratively rather once.is, rather iterate complete assignments ~x instantiate variables onetime, performing propagation assignment. make propagation effective,since, e.g., empty clause might detected instantiating subset variables ~xthus number iterations loop might reduced.variables ~x set iteratively order assigned vary.Furthermore, order assignment vary dynamically. is, depending values assigned first k variables ~x, algorithm make different choicesunassigned variable ~x assign next.call extension RC-Cache uses incremental assignments dynamic variable ordering within set ~x, RC-Cache+ . RC-Cache+ uses caching scheme RC-Cache,flexibility variable ordering. noted however, RC-Cache+complete freedom variable ordering. must still follow inputed branch decomposition . is, variable chosen must come set ~x label (left(r)) label (right (r)).contrast DPLL based algorithms present next section, alwaysfree choose remaining unassigned variable next variable assign.Space-Time Tradeoff RC attractive feature achieve non-trivial space-timetradeoff, taking less time caches recursively computed values (RC-Cache), taking lessspace without caching (RC-Space). fact, Darwiche Allen (2002) show smoothtradeoff achieved, RC-Space RC-Cache two extremes.DPLL based algorithms presented share number features RC; also reducedecompose input problem making instantiations, gain efficiency caching, achievesimilar space-time tradeoff. However, algorithms based paradigm backtracking,rather divide conquer. particular, explore single backtracking treedecomposed subproblems solved separately rather solved interleaved401fiBACCHUS , DALMAO , & P ITASSIfashion. result, limited following decomposition scheme specified fixedbranch decomposition. see, limitation static decomposition scheme meansRC-Space RC-Cache must perform exponentially worse algorithms instances.2.4.3 AND/OR EARCH :recent work Dechter Mateescu (2007) shown notion AND/OR searchspaces (Nilsson, 1980) applied formalize divide conquer approach UM P RODproblems utilized RC. formulation structure guides AND/OR search algorithmpseudo tree. (Choosing pseudo tree nondeterministic part computation.)Definition 5 (Primal Graph) primal graph hypergraph H undirected graph Gvertices H edge connecting two vertices two verticesappear together hyperedge H.Definition 6 (Pseudo Tree) Given undirected graph G vertices edges (V, EG ), pseudotree G directed rooted tree vertices edges (V, ET ) (i.e., set verticesG), edge e G must connect vertex one ancestors.is, e = (v1 , v2 ) e EG e 6 ET implies either v1 ancestor v2 v2ancestor v1 .implies edge G connecting vertices lying different subtrees .Given UM P ROD problem = hV, F, , underlying hypergraph H, form G,primal graph H. vertices G variables problem V pair variablesappear together function F connected edge G. pseudo treeG property two vertices (variables S) appear functionsF ancestors descendants, cannot appear functions siblingsancestors siblings descendants siblings.implies variable v ancestors instantiated, variables contained children subtrees become disconnected. is, variables subtreeslonger appear functions together, resulting subproblems solved independently.AND/OR search algorithm utilizes fact solve subproblems independently, likerecursive conditioning.Example 5 Given hypergraph H = (V, E) V = {1, 2, 3, 4, 5} E = {{1, 2, 3},{1, 4},{2, 5}, {3, 5}}, primal graph H G = (V, EG ) EG = {(1, 2), (1, 3), (2, 3),(1, 4), (2, 5), (3, 5)}. H, primal graph G, pseudo tree G shown Figure 4.dotted lines shown pseudo tree edges G pseudo tree.seen diagram edges connect nodes ancestors.space efficient version AND/OR-Space search algorithm (Dechter & Mateescu,2007) shown Algorithm 3. solves UM P ROD instance = hV, F, , i, takinginput pseudo tree problem (i.e., hypergraph converted primal graphG, pseudo tree G), initially empty set instantiated variables . algorithm solves sub-problem original instance reduced instantiations , S| .sub-problem solved defined functions S| variables containedpassed sub-tree . Initially, empty original pseudo tree containingvariables, algorithm solves original problem S.402fiBACKTRACKING EARCH#SAT BAYES1123123445Hypergraph45235Primal GraphPseudo TreeFigure 4: hypergraph, primal graph, pseudo tree Example 5.nodes pseudo tree variables problem S, also attach noden set functions fns(n). function f F fns(n) (a) n scopef (b) variables scope f ancestors n . means ffully instantiated set arguments AND/OR search instantiates node (variable) n.Algorithm 3: AND/OR-SpaceLinear Space AND/OR search12345678910AND/OR-Space (T, )beginp = 0; r = root (T )STr = set subtrees rforall {instantiations r}Q= f fns(r) LOOKUP(value f {r = d})Qp = p + STr AND/OR-Space (T , {r = d})endreturn pendalgorithm operates variable r root pseudo tree . instantiation r algorithm computes , product functions F become fullyinstantiated assignment r, i.e., fns(r). invokes separate recursionchild r passing subtree rooted child recursive call. AND/OR search exploitsdecomposition separate recursions. r one child, problemdecomposedthere single reduced subproblem resulted instantiating r.Like RC, AND/OR search made time efficient expense using space.Algorithm 4 shows caching version AND/OR-Cache (called AND/OR graph search DechterMateescu (2007)). Let label (n) node n pseudo tree set ancestorsn appear function n descendant n . instantiations label (n) affect functions variables subtree rooted n.Hence, label (n) plays role root label passed branch decomposition RCCache: instantiations variables affect subproblem currently computed.403fiBACCHUS , DALMAO , & P ITASSIHence, like RC-Cache, AND/OR-Cache use instantiations subset, y, intersectinglabel (root(T )) along index cache.Finally, RC-Cache+ , propagation used decrease number branchesAND/OR search needs explore. example, recursive calls children rterminated one calls returns value zero.Algorithm 4: AND/OR-CacheAND/OR search caching12345678910111213AND/OR-Cache (T, )beginp = 0; r = root (T )= label (root (T ))InCache(T, y)return GetValue(T, y)STr = set subtrees rforall {instantiations r}Q= f fns(r) LOOKUP(value f {r = d})Qp = p + STr AND/OR-Cache (T , {r = d})endreturn pendAND/OR-Cache+ variable order dynamism employed AND/OR search.particular, variables along chain pseudo tree reordered without affectingdecompositions specified . chain sub-path none nodes, exceptperhaps last, one child. Figure 4 nodes 2, 3, 5 form chain. resultantextension, AND/OR-Cache+ , dynamically chose next instantiate variableschain starts root passed pseudo tree . (Marinescu Dechter (2006) referAND/OR-Cache+ AND/OR partial variable ordering. However utilizecaching version algorithm.)pass rest chain (and nodes below) next recursive call,chosen variable last chain invoke separate recursive call child. LikeRC-Cache+ , AND/OR-Cache+ complete freedom choice variableit mustchose variable top chain. Furthermore, AND/OR-Cache+ use cachingscheme bottom chain (i.e., variables chain instantiated) sincecache requires set variables instantiated. makes AND/OR-Cache+similar RC-Cache+ .2.4.4 E XACT LGORITHMSalgorithm commonly used BAYES join tree algorithm (Lauritzen & Spiegelhalter, 1988), also adapted solve kinds UM P ROD problems. join-treealgorithm first organizes primal graph UM P ROD problem tree clusteringvariables, performs message passing tree messages computedvariable elimination process. context BAYES main advantage join-tree algorithms404fiBACKTRACKING EARCH#SAT BAYEScompute marginals. compute posterior probability variablesgiven evidence.contrast, default version variable elimination computes posterior distributionsingle variable. However, Kask et al. (2005) show join-tree algorithm reducedversion remembers intermediate results runs timespace VE. Hence, results state comparing new backtracking basedalgorithms also hold join tree algorithm.Computing Marginals algorithms described above, i.e., VE, RC, AND/ORsearch, modified compute marginals solving BAYES without changeworst case complexity. particular, besides results Kask et al. (2005), Darwiche (2001)shown RC compute marginals BAYES problems extra bottom traversalsearch treeat doubling run time. technique applied AND/ORsearch algorithms. DPLL algorithms present here, Sang et al. (2005b) giveneven simpler scheme modifying computing marginals. Sang et al.sscheme involves maintaining extra information search require extratraversal search tree.Another algorithm mostly superseded cut-set conditioning (Pearl, 1988).idea identify subset variables set reduce underlying hypergraphUM P ROD tree. reduced UM P ROD easily solved. However,approach requires trying possible instantiations cut-set yielding runtime usuallyworse RC-Cache. Nevertheless, cutset conditioning potentially applied conjunctionexact algorithms (Mateescu & Dechter, 2005).Finally, important early algorithm called DDP presented Bayardo Pehoushek(2000). version DPLL utilized dynamic decomposition solving #S AT.terms algorithms discussed above, AND/OR-Space viewed versionDDP utilizes pseudo tree guide variable ordering. original presentation DDP,variable ordering could used including dynamic variable orderings. search continuedproblem decomposed independent components (tested search)point separate recursion used solve component. Hence, DDP explored AND/ORsearch tree, however tree need correspond pseudo tree original problem.(The DVO DSO AND/OR search schemes presented Mateescu Dechter (2005) alsoversions DDP run particular variable ordering heuristics). comparison algorithmspresent next section, Bayardo Pehoushek (2000) provide complexity analysisDDP, DDP use caching enhance performance, DDP still less flexibilityvariable ordering. particular, problem split independent componentssearch must solve components sequentially separate recursions. Inside recursionsearch branch variables current component. is, DDP cannot interleavesolution components like DPLL algorithms present here.2.5 Complexity Analysisknown algorithms BAYES, #S UM P ROD run exponential-time worst case.However, branch width underlying hypergraph instance, w, small,algorithms much efficient. shown algorithms VE, RCCache AND/OR-Cache discussed run time space nO(1) 2O(w) . note405fiBACCHUS , DALMAO , & P ITASSIcomplexity algorithms usually given terms tree width elimination width,branch width. However, Lemmas 1, 2, 3, concepts equivalent within factor2, therefore asymptotic complexity equivalently stated terms threenotions width (tree width, branch width, elimination width). analyzing backtrackingalgorithms, branch width somewhat natural, reason chosen statecomplexity results terms branch width.runtime variable elimination algorithm easily seen nO(1) 2O(w) .see this, notice algorithm proceeds n stages, removing one variable stage. Suppose algorithm run variable ordering elimination width v. algorithmremoves ith variable ith stage. ith stage, functions involving variablemerged obtain new function. indicated Section 2.4.1, computing new functioninvolves iterating overall possible instantiations variables. runtime stage therefore exponential number underlying variables new function, bounded v.Thus, runtime algorithm bounded nO(1) 2O(v) . Lemmas 1 2 3,elimination width v, branch width v + 1, therefore overall runtimeclaimed. also noted since new function must stored, space complexityvariable elimination time complexity, i.e., nO(1) 2O(w) .also shown run times RC-Cache RC-Cache+ bounded nO(1) 2O(w)(Darwiche, 2001). Further, nice time-space tradeoff. is, space-efficient implementation RC, RC-Space, runs time 2O(w log n) needs space linear sizeinput, RC-Cache space complexity equal time complexity, nO(1) 2O(w) .present proofs showing DPLL based algorithms achieve time time/spacebounds; proofs give bounds RC-Space, RC-Cache, RC-Cache+ special cases.Finally, shown AND/OR-Space runs time 2O(w log n) (Dechter & Mateescu,2007). Specifically, Dechter Mateescu show AND/OR-Space runs time exponentialheight inputed pseudo tree, Bayardo Miranker (1995) show height boundedw log n. Lemma 1 shows bound also holds branch width. Similarly, DechterMateescu (2007) show AND/OR-Cache runs time space bounded nO(1) 2O(w)exploiting close relationship pseudo trees elimination orders.Making algorithms deterministic. stated above, algorithms fact nondeterministic algorithms requiring different nondeterministically determined input. Hence,stated complexity bounds mean exists choice nondeterministic input (i.e.,variable ordering VE, branch decomposition RC, pseudo tree AND/ORsearch) algorithm achieve stated complexity bound.However, achieve runtime practice, need able find good branchdecomposition (variable ordering, pseudo tree) efficiently. Unfortunately, general problemcomputing optimal branch decomposition (i.e., one width equal branch widthH) NP-complete. However, Robertson Seymour (1995) present algorithm computingbranch decomposition branch width within factor 2 optimal runstime nO(1) 2O(w) , w branch width H. first running deterministic algorithmcompute good branch decomposition, one obtain deterministic versions RC-CacheRC-Cache+ run time space nO(1) 2O(w) , well deterministic version RC-Spaceruns linear space time 2O(w log n) . deterministic versions longer require accessnondeterministically determined choice achieve stated runtimes.406fiBACKTRACKING EARCH#SAT BAYESAlgorithm 5: DPLL SAT12345678910DPLL ()beginclausesreturn TRUEelse contains empty clausereturn FALSEelsechoose variable x appearsreturn (DPLL(|x=0 ) DPLL(|x=1 ))endSimilarly nearly optimal branch decomposition, use Lemmas 1-3 find nearlyoptimal elimination ordering, thus obtain deterministic version variable eliminationalgorithm runs time space nO(1) 2O(w) . finally, nearly optimal eliminationordering bucket-tree construction Dechter Mateescu (2007) used constructnearly optimal pseudo tree, thus obtain deterministic version AND/OR-Spaceruns linear space time 2O(w log n) , deterministic version AND/OR-Cache runstime space nO(1) 2O(w) .3. Using DPLL #S UM P RODpresent methods augmenting backtracking search different caching schemessolve UM P ROD time space guarantees least good exactalgorithm UM P ROD. ease presentation present DPLL-based algorithms solving#S AT, derive complexity results algorithms. Later discuss algorithmscomplexity results applied instances UM P ROD (like BAYES).3.1 DPLL #DPLL:DPLL nondeterministic algorithm AT, also used solve various generalizations AT, including #S (Dubois, 1991; Zhang, 1996; Birnbaum & Lozinskii, 1999; Littman,Majercik, & Pitassi, 2001). DPLL solves performing depth-first search spacepartial instantiations (i.e., standard backtracking search algorithm). nondeterministic partcomputation lies choice variable query (i.e., instantiate) nextsearch. operates problems encoded clause form (CNF).standard DPLL algorithm solving given Algorithm 5. use notation|x=0 |x=1 denote new CNF formula obtained reducing setting variable x0 1. Reducing x = 1 (x = 0) involves removing clauses containing x (x)removing falsified x (x) remaining clauses.DPLL nondeterministic procedure generates decision tree representing underlyingCNF formula. solving AT, decision tree traversed depth-first manner eithersatisfying path encountered, whole tree traversed (and paths falsify formula).nondeterminism algorithm occurs choice variable line 8. practice407fiBACCHUS , DALMAO , & P ITASSIAlgorithm 6: #DPLL #S (no caching)12345678910#DPLL ()// Returns probabilitybeginclausesreturn 1else contains empty clausereturn 0elsechoose variable x appearsreturn ( 12 #DPLL(|x=0 ) + 21 #DPLL(|x=1 ))endnondeterminism typically resolved via heuristic choice. Also, algorithm utilizes earlytermination disjunctive test line 9; i.e., first test returns TRUE second recursivecall made. Thus, algorithm stops finding first satisfying path.Note require DPLL perform unit propagation. particular, unit propagationalways realized choice variable line 8. particular, force DPLLalways chose variable appears unit clause whenever one exists,effect forcing DPLL perform unit propagation every variable instantiation. is,variable chosen, instantiated one values, input CNF reduced.reduced formula, |x=0 |x=1 , passed next recursive call may contain unit clauses.unit propagation, variables clauses would instantiated satisfy unit clauses.instead, force one variable chosen next, one instantiation would immediatelyfail due generation empty clause, would instantiate variablevalue unit propagation. Hence, since analyze DPLL nondeterministic algorithm,includes deterministic realizations perform unit propagation.simple modification DPLL allows count satisfying assignments. Algorithm 6 gives#DPLL algorithm counting. algorithm actually computes probability setsatisfying assignments uniform distribution. Hence, number satisfying assignmentsobtained multiplying probability 2n , n number variables .alternative would return 2 raised number unset variables whenever clauses(line 4) multiply recursively computed counts 21 (line 9).Known exponential worst-case time bounds DPLL also apply #DPLL: unsatisfiableformulas, algorithms traverse entire decision tree terminating. Althoughdecision tree small (e.g., immediate contradiction detected), familiesformulas decision tree must large. particular, implicit results Haken (1985)decision tree formulas encoding (negation the) propositional pigeonholeprinciple exponential size, thus DPLL #DPLL must take exponential-timeexamples. lower bound not, however, help us discriminate algorithms sinceknown algorithms #S BAYES take exponential-time worst-case. Nevertheless,#DPLL requires exponential time even instances efficiently solved competingalgorithms UM P ROD. see this, consider 3CNF formula 3n variables consisting408fiBACKTRACKING EARCH#SAT BAYESn clauses share variables. complete decision tree exponential size, therefore#DPLL require exponential time. contrast, since formula low tree widthsolved polynomial time VE, RC, AND/OR search.3.2 DPLL Caching:Given obvious application DPLL solve UM P ROD give exponentially worseperformance standard algorithms, examine ways modifying DPLLsolve #S (and thus BAYES UM P ROD) efficiently. understand source#DPLLs inefficiency consider following example.Example 6 following diagram shows run #DPLL = {(w x)(y z)}. nodeshows variable branched on, current formula #DPLL working on. left handbranches correspond setting branch variable FALSE, right variable setTRUE. empty formula indicated {}, formula containing empty clauseindicated {()}. diagram shows #DPLL encounters solves subproblem {(y z)}twice: along path (w = 0, x = 1) along path (w = 1). Noteexample unit propagation realized choice variable orderingafter w set FALSE,#DPLL chooses instantiate variable x since variable appears unit clause.w:{(x w))(y z)}HHHHHHHHx:{(x)(y z)}y:{(y z)}HHHHHHHH0:{()}y:{(y z)}HHHz:{(z)}z:{(z)}1:{}HH0:{()}1:{}1:{}HH0:{()}1:{}one considers example applying #DPLL disjoint sets clauses, becomesclear formulas #DPLL encounter subproblem exponential numbertimes.3.2.1 DPLLIMPLE C ACHING (#DPLL-S IMPLE C ACHE )One way prevent duplication apply memoization. indicated Example 6, associatedevery node DPLL tree formula f subtree rooted node tryingcompute number satisfying assignments f . performing depth-first searchtree, keep cache contains formulas f already solved, uponreaching new node tree avoid traversing subtree value correspondingformula already stored cache.Example 6 would cache {(y z)}, solve along path (w = 0, x = 1)thereby avoid traversing subtree (w = 1).409fiBACCHUS , DALMAO , & P ITASSIAlgorithm 7: #DPLL algorithm simple caching (#DPLL-SimpleCache)12345678910#DPLL-SimpleCache ()// Returns probabilitybeginInCache()// Also detects obvious formulas.return GetValue()elsechoose variable x appearsval = 12 #DPLL-SimpleCache (|x=0 ) + 21 #DPLL-SimpleCache (|x=1 )AddToCache(,val )return valendform caching, call simple caching (#DPLL-SimpleCache)easily implemented shown Algorithm 7.4 #DPLL, #DPLL-SimpleCache returnsprobability input formula ; multiplying 2n gives number satisfying assignments.addition formulas stored cache also following obvious formulas whosevalue easy compute. (1) empty formula {} containing clauses value 1. (2)formula containing empty clause value 0. Obvious formulas treatedimplicitly stored cache (they need explicitly stored cache, rather valuescomputed required).following (low complexity) subroutines used access cache. (1) AddToCache(, r):adds cache fact formula value r. (2) InCache(): takes input formulareturns true cache. (3) GetValue(): takes input formula knowncache returns stored value. various ways computing cache key .example, maintained sorted set sorted clauses, cached textstring. caching scheme nO(1) complexity.Surprisingly, simple caching, reasonably well. following theorem shows simplecaching achieves runtime bounded 2O(w log n) , w underlying branch width.complexity analysis earlier algorithms presented Section 2.5, simple caching algorithmalso made deterministic first computing branch decomposition within factor2 optimal (using Robertson-Seymour algorithm), running #DPLL-SimpleCachevariable ordering determined branch decomposition.Theorem 1 solving #S n variables, execution #DPLL-SimpleCacheruns time bounded 2O(w log n) w underlying branch width instance. Furthermore, algorithm made deterministic time guarantees.Although theorem shows #DPLL-SimpleCache fairly well, performancequite good best UM P ROD algorithms (which run time nO(1) 2O(w) ).4. Simple caching utilized (Majercik & Littman, 1998), without theoretical analysis.410fiBACKTRACKING EARCH#SAT BAYESAlgorithm 8: #DPLL algorithm component caching (#DPLL-Cache)12345678910111213141516#DPLL-Cache ()// Returns probability set disjoint formulasbeginInCache()// Also detects obvious formulas.return GetValue()else= RemoveCachedComponents()choose variable x appears component= ToComponents(|v=0 )#DPLL-Cache ( {} )+ = ToComponents(|v=1 )#DPLL-Cache ( {} + )AddToCache(, 21 GetValue( ) + 12 GetValue(+ ))#DPLL-SpaceRemoveFromCache( + )return GetValue()end3.2.2 DPLLC OMPONENT C ACHING (#DPLL-C ACHE )show sophisticated caching scheme allows #DPLL perform wellbest known algorithms. call new algorithm #DPLL-Cache, implementation givenAlgorithm 8.algorithm generalize cache deal sets formulas. First, say(single) formula known value stored cache obvious formula (andvalue implicitly stored cache). Given set formulas say set knowneither every known, whose value known zero. casessay value equal product values .generalize cache access subroutines. (1) InCache() generalizedtake input set formulas . returns true known defined. (2) SimilarlyGetValue() generalized take sets formulas input. returns product cachedvalues formulas .intuition behind #DPLL-Cache recognize variables set input formulamay become broken disjoint components, i.e., sets clauses share variablesother. Since components share variables compute number solutionscomponent multiply answers obtain total solution count. Thus, intendedGetValue called set disjoint components . case correctly returnsolution count i.e., product solution counts .algorithm creates standard DPLL tree, however caches component formulasvalues computed. keeps input decomposed form set disjoint components,components already cache (and thus value known) remove411fiBACCHUS , DALMAO , & P ITASSIparts inputreducing size problem still solve avoidingresolve components.new algorithm uses previously defined cache access subroutines along two additional (low complexity) subroutines. (1) ToComponents(): takes input formula , breaksset minimal sized disjoint components, returns set. (2) RemoveCachedComponents(): returns input set formulas known formulas removed. input#DPLL-Cache always set disjoint formulas. Hence, run #DPLL-Cache input formulainitially make call #DPLL-Cache (ToComponents()).ToComponents simply computes connected components primal graph generated. is, graph variables nodes, two nodes connectedcorresponding variables appear together (in polarity) clause . connectedcomponent primal graph (which computed simple depth-first traversalgraph Cormen, Leiserson, Rivest, & Stein, 2001), defines set variables whose clauses formindependent component .call #DPLL-Cache completes solution unknown componentsset inputed components . components known product valuescomponents returned line 4. Otherwise input set components reduced removing known components (line 6), must leave least one unknown componentpotentially reduces size remaining problem solved. variable unsolved component chosen branched on. Since variable appears componentassignment affect . particular, assignment might break smaller components (line 8 11). recursive call solve components passed, tworecursive calls value computed cached (line 12). Finally, since componentsinputed set solved value retrieved cache returned.Example 7 Figure 5 illustrates behavior #DPLL-Cache formula = {(a, b, c, x),(a, b, c), (a, b, c), (d, e, f, x), (d, e, f ), (d, e, f )}. Although problem could solvedsimpler search tree, use variable ordering generates interesting behavior.node shows variable branched on, current set components #DPLLCache working on. known components (i.e., already cache) markedasterisk ( ). branch variables set FALSE left branch TRUE right branch.empty formula indicated {}, formula containing empty clause indicated{()}. simply diagram use unit propagation simplify formula branchvariable set. avoids insertion diagram nodes unit clause variablesbranched on. Finally, note known formulas removed recursive call made, perline 6 Algorithm 8).root, x set false, broken two components a,b,c = {(a, b, c),(a, b, c), (a, b, c)}, d,e,f = {(d, e, f ), (d, e, f ), (d, e, f )}. search tree demonstratesmatter search interleaves branching variables different components,components still solved independently. see leftmost node treebranches f succeeds solving component {(e, f ), (e, f )}. component addedcache. Similarly, parent node branches b solves component {(b, c), (b, c)}.(The subcomponents + generated setting b, lines 8 11 Algorithm 8, performing unit propagation equal empty formula, {}, thus known). backtrackd, alternate value affect component {(b, c), (b, c)}, valueretrieved cache leaving component {(e, f )} solved. Branching e solves412fiBACKTRACKING EARCH#SAT BAYESx:{}HHHHHHH..a,b,c ,a:.d,e,fHHHHHHHHHH{(b, c)},{(b, c), (b, c)},b:d:d,e,fd,e,fHHnnHHHH{}{}HHHHH{(b, c), (b, c)} ,{(b, c), (b, c)},e:b:{(e, f )}{(e, f ), (e, f )}HHHHHH{}{}f:{(e, f ), (e, f )}{(e, f ), (e, f )}HHn nH{}{()}HnnH{}{}Figure 5: Search Space #DPLL-Cachecomponent. Backtracking {(e, f )} {(e, f ), (e, f )} solved,d,e,f value computed placed cache. backtracking a, alternate valueaffect component d,e,f , value retrieved cache leavingcomponent {(b, c)} solved. Branching b solves component,{(b, c)} {(b, c), (b, c)} solved a,b,c value computed placed cache.search backtrack try setting x TRUE.obtain following upper bound runtime #DPLL-Cache.Theorem 2 solving #S n variables, exists execution #DPLL-Cache runstime bounded nO(1) 2O(w) w underlying branch width instance. Furthermore,algorithm made deterministic time guarantees (as discussed Section 2.5).see #DPLL-Cache achieve level performance best UM P RODalgorithms.Finally, third variant #DPLL caching, #DPLL-Space , achieves nontrivial time-space tradeoff. algorithm natural variant #DPLL-Cache, modified removecached values linear space consumed. algorithm utilizes one additional subroutine. (6) RemoveFromCache(): takes input set formulas (a set components) removescache. splitting component variable instantiation computingvalue part, #DPLL-Space cleans cache removing sub-components,value whole component retained. Specifically, #DPLL-Space exactly like#DPLL-Cache, except calls RemoveFromCache( + ) returning (line 14).413fiBACCHUS , DALMAO , & P ITASSITheorem 3 solving #S n variables, execution #DPLL-Space usesspace linear instance size runs time bounded 2O(w log n) w underlyingbranch width instance. Furthermore, algorithm made deterministictime space guarantees.proofs Theorems 13 given appendix.3.3 Using DPLL Algorithms Instances UM P ROD:DPLL algorithms described section easily modified solve instancesUM P ROD. However, since #S #P complete many instances UM P ROD also solvedsimply encoding #S AT. example, approach readily applicable BAYESproved empirically successful (Sang et al., 2005b). Furthermore, encoding providedSang et al. (2005b) achieves complexity guarantees standard algorithms BAYES.(That is, CNF encoding tree width greater original Bayes Net). Noteencoding assigns non-uniform probabilities values variables. is, variable xprobability x = 0 might equal probability x = 1. easily accommodatedalgorithms: instead multiplying value returned recursive call 21 simplymultiply probability corresponding variable value (i.e., Pr (x = 0) Pr (x = 1)).hand, conversion #S inapplicable undesirable algorithmsmodified solve instances UM P ROD directly. UM P ROD, want computeL NmLj=1 fj (Ej ). DPLL chooses variable, Xi , value Xi recursivelyXnX1 . . .solves reduced problem F|Xi =d . (Hence, instead binary decision tree builds k-ary tree).reduced problem F|Xi =d computeX1...Xi1 Xi+1...MOfj (Ej )|Xi =d ,Xm j=1fj (Ej )|Xi =d fj reduced setting Xi = d. #DPLL-SimpleCache caches solutionreduced problem avoid recomputing it. example, remember reduced problemremembering original functions F remain (i.e., reduced constantvalue) set assignments reduced remaining functions. #DPLL-Cache cachessolution components reduced problem. example, remember componentremembering set original functions form component along set assignmentsreduced functions. compute current components finding connectedcomponents primal graph generated hypergraph UM P ROD instanceinstantiated variables removed. straightforward adaptation show threetheorems continue hold #DPLL, #DPLL-Cache, #DPLL-Space modified solve UM P ROD.Algorithm 9 shows #DPLL-Cache, example, modified solve general UM P ROD problems. algorithm takes input set components , like #DPLL-Cache,initially containing components original problem. algorithm fns(x) denotes setfunctions original problem (a) contain x scope, (b) fully instantiatedinstantiation x.414fiBACKTRACKING EARCH#SAT BAYESAlgorithm 9: UM P ROD-DPLL-Cache algorithm arbitrary UM P ROD problems12345678910111213141516UM P ROD-DPLL-Cache ()beginInCache()return GetValue()else= RemoveCachedComponents()choose variable x appears componentp=0foreach domain x= ToComponents(|x=d )Q= f fns(x) LOOKUP(value f {x = d})p = p + UM P ROD-DPLL-Cache( {} )endAddToCache(, p)return GetValue()end4. Comparing Algorithms BAYES #Ssection, prove DPLL based algorithms least powerful standardcomplete algorithms solving #S AT, provable powerful manyinstances. last feature important means solving UM P ROD usingDPLL augmented caching cases solve problems beyond reach manystandard complete algorithms.mentioned earlier, algorithms UM P ROD well new DPLL-based algorithms,actually nondeterministic algorithms require nondeterministically chosen input. (Thisinput viewed sequence bits). VE, nondeterministic bits encode elimination ordering; RC, nondeterministic bits encode branch decomposition; AND/ORsearch nondeterministic bits encode pseudo tree; DPLL based algorithms,nondeterministic bits encode underlying decision tree indicating variable queriednext backtracking process. Thus comparing power algorithms mustcareful nondeterminism resolved. example, operating badelimination ordering cannot expected run efficiently #DPLL-Cache operatinggood branching strategy. First present definitions allow us state resultsprecisely.Definition 7 Let f CNF formula. Define Time[VE](f ) minimal runtime variable elimination algorithm solving #S f , choices elimination orderings f .Similarly define Time[A](f ), equal RC-Cache, RC-Space, RC-Cache+ , AND/OR-Space,AND/OR-Cache, AND/OR-Cache+ , #DPLL-Cache, #DPLL-Space. (For example, Time[RCCache](f ) minimal runtime RC-Cache algorithm solving #S f , possiblebranch decompositions f .)415fiBACCHUS , DALMAO , & P ITASSIDefinition 8 Let B two nondeterministic algorithms #S AT. saypolynomial-time simulates B fixed polynomial p every CNF formula fTime[A](f ) p(Time[B](f )).following theorem shows RC-Cache RC-Cache+ polynomially simulate VE.proof theorem implicit results Darwiche (2001).Theorem 4 RC-Cache RC-Cache+ polynomially simulate VE.prove DPLL caching powerful previous algorithms.Theorem 5 #DPLL-Cache polynomially simulates RC-Cache, RC-Cache+ , AND/OR-Cache,AND/OR-Cache+ , VE. #DPLL-Space polynomially simulates RC-Space, AND/OR-SpaceDDP.5proof theorem given appendix. noted proof alsoimplies deterministic version #DPLL-Cache time (and space) complexity least good deterministic realization RC-Cache, RC-Cache+ , AND/ORCache, AND/OR-Cache+ , VE. Similarly, deterministic version #DPLL-Spacetime (and space) complexity least good deterministic realization RC-Space,AND/OR-Space DDP.prove DPLL caching cases run super-polynomially fasterprevious algorithms. proof given appendix.Theorem 6 None RC-Space, RC-Cache, AND/OR-Cache, AND/OR-Space polynomially simulate #DPLL-Cache, #DPLL-Space, #DPLL.theorem shows #DPLL-Cache/Space basic advantage standardalgorithms UM P ROD. is, problems RC, AND/OR search, requiretime super-polynomially greater #DPLL-Cache matter branch decomposition, pseudotree, variable ordering supplied with, even caching utilized. prooftheorem shows advantage #DPLL-Cache arises ability utilize dynamic variable orderings, branch order variables differently. flexibility dynamicvariable ordering instances gives rise increased opportunities contradictions therebysignificantly decreasing overall runtime.note Theorem 6 cover algorithms flexibilityvariable ordering, i.e., AND/OR-Cache+ , RC-Cache+ , DDP. open problem whether#DPLL-Cache superpolynomially faster algorithms instances, althoughconjecture Theorem 6 also true algorithms.particular, note #DPLL-Cache still greater flexibility variable orderingalgorithms. None algorithms complete flexibility variable ordering.AND/OR-Cache+ must select uninstantiated variable chain starts rootpassed pseudo tree; RC-Cache+ must select uninstantiated variable intersectionlabels left right children root passed branch decomposition; DDP mustselect uninstantiated variable component currently solving. contrast #DPLLCache select uninstantiated variable.5. DDP algorithm presented Bayardo Pehoushek (2000).416fiBACKTRACKING EARCH#SAT BAYESdifficulty proving Theorem 6 algorithms tradeoff flexibility variable ordering ability decompose problem. clearestexample occurs AND/OR-Cache+ . AND/OR-Cache+ passed pseudo treesimply single chain variables, complete flexibility variable ordering,time never decompose problem. Similarly, RC-Cache+ provided branchdecomposition large labels flexibility variable ordering,less effective decomposing problem. family problems used prove Theorem 6flexibility variable ordering needed achieve superpolynomial speedup, thusexample AND/OR-Cache+ achieve speedup completely sacrificing decomposition.#DPLL-Cache manage tradeoff flexibility variable ordering decomposing problem sophisticated ways. example, ability use variableordering encourages decomposition parts search tree using different variable orderings parts search tree. instance, Cachet system, based#DPLL-Cache, employs heuristic dynamically trades variables ability decomposeproblem ability refute current subtree (Sang et al., 2005a). (It employs weightedaverage number clauses variable satisfy variables VSID score Moskewicz,Madigan, Zhao, Zhang, & Malik, 2001). #DPLL-Cache also ability interleave solvingcurrent set components successively choosing variables different components.extend Theorem 6 cover AND/OR-Cache+ , RC-Cache+ DDP family problems exploiting features #DPLL-Cache would developed.5. Impact Practiceresults paper first presented conference paper (Bacchus, Dalmao, &Pitassi, 2003), since time number works influenced algorithmic ideaspresented here.Cachet system (Sang et al., 2004, 2005a) state art #S solver directly basedresults presented here. Cachet like #DPLL-Cache algorithm, based ideasdynamic decomposition components caching component solutions. advanceprevious #S solvers use caching remember previously solved componentsintegration clause learning. previous best #S solver, DDP solver (Bayardo& Pehoushek, 2000), also performed dynamic component detection neither componentcaching clause learning. results highlighted importance component cachingpossibility basing #S solver standard DPLL implementation thus making integrationclause learning feasible.Cachet resolved number issues making algorithms presented practical.included practical ways implementing caching components including method efficiently computing key could used cache lookup. (This method subsequentlyimproved Thurley, 2006). Cachet system also used solve BAYES, probableexplanation (MPE), weighted MAX-SAT problems encoding problems weighted#S problems (Sang et al., 2005b, 2007). approach proved successful, especially BAYES often much superior standard BAYES algorithms. applications#S Cachet system BAYES advanced Li et al. (2006, 2008).also noted practical #S solving applications problems likeBAYES also advanced period work RC algorithm application417fiBACCHUS , DALMAO , & P ITASSIcompiling CNF representations model counting tractable, e.g., (Darwiche, 2004;Chavira & Darwiche, 2006, 2008). work also illustrated value converting variousproblems weighted #S instances, utilization techniques like clause learning (incase integrated RC style algorithm). also considerable work advancing AND/OR search, e.g., (Dechter & Mateescu, 2004; Marinescu & Dechter, 2006; Dechter &Mateescu, 2007).One difference Cachet system RC AND/OR search based systems mentioned Cachet utilized dynamic decomposition scheme. particular, Cachet useddynamic variable ordering heuristic attempts trade variables ability decomposeproblem ability refute current subtree. variable ordering dynamicallydetermined search, Cachet cannot predict components generated search.Hence examine current component (i.e., component containing variableinstantiated) discover new components generated. Thus Cachet utilized approach likespecified Algorithm 8 function like ToComponents invoked newly reduced component (see line 8). ToComponents must linear computation find new components (e.g.,depth-first search union-find algorithm). addition, component must examineclauses contained component compute cache key.contrast, RC AND/OR search take input static precomputed decompositionscheme (i.e., branch decomposition pseudo tree). Hence, able find componentswithout extra work search, able efficiently compute cache keyscomponents. example, AND/OR search, algorithm simply follows suppliedpseudo tree. variable V along variables path root Vinstantiated, AND/OR search knows variables subtree rooted child Vforms independent component. Hence, detect components search constant time. Similarly, need examine clauses variables new componentscompute cache key. Instead compute cache key node pseudo tree rootscomponent set instantiations parents root appear clausesvariables component. Note that, set parents whose instantiations relevantcomputed search done search look currentvalues.Thus, using static decomposition scheme RC AND/OR search gain efficiencyCachet. However, statically computed decompositions always effectivedynamic scheme employed Cachet. First, useful override precomputed decomposition scheme drive search towards contradictions. gist Theorem 6shows dynamic flexibility variable ordering provide superpolynomial reductionssize explored search tree better exploiting contradictions. Second, static decompositions cannot account different values variables. is, formula arisesinstantiating variable V 0 quite different formula arises instantiating V 1. difference negatively affect performance RC AND/OR searchleast couple ways: components might generated predicted staticdecomposition scheme thus static scheme might fully exploit decomposition; duespecific changes formula generated particular instantiations, static decompositionscheme might inappropriate much search space.practice, Cachet displays performance least good systems built usingRC algorithm, cases performance superior (see empirical results presented418fiBACKTRACKING EARCH#SAT BAYESSang et al., 2004, 2005a). also noted #DPLL-Cache easily utilize staticdecomposition scheme gain efficiencies schemes. example, providedpseudo tree #DPLL-Cache follow ordering variables pseudo treeparents always instantiated children. Like AND/OR search knowchildren node pseudo tree root independent component, alsoable detect components constant time. Furthermore, would able utilizeefficient caching scheme AND/OR search. case advantage AND/OR search wouldwould freedom interleave solving components.6recent work algorithms also applied optimization problems (Kitching& Bacchus, 2008). work involved adding branch bound techniques decompositioncomponent caching described #DPLL-Cache. branch bound dynamic variableordering effective. particular, one wants branch variables drivevalue current path towards better value generate global boundeffective pruning rest search space. empirical results Kitching Bacchus(2008) show added flexibility #DPLL-Cache sometimes yield significant performance improvements AND/OR search even extra flexibility AND/OR-Cache+exploited.6. Final Remarkspaper studied DPLL caching, analyzing performance various typescaching #S AT. results apply immediately number instances UM P RODproblem including BAYES, since #S complete class #P. However, proofs alsomodified without much difficulty complexity results apply directly problemUM P ROD.sophisticated caching methods also explored solving Beame et al.(2003) showed methods considerably increase power DPLL.However, sophisticated caching methods currently practical due largeoverheads. related work, one results Aleknovich Razborov (2002) showedSAT could solved time nO(1) 2O(w) . results extend problem UM P RODasshown Section 2.1 SAT instance UM P ROD.proved theoretical point view, #DPLL-Cache efficient termstime space state-of-the-art exact algorithms UM P ROD. Moreover,shown specific instances, #DPLL-Cache substantially outperforms basic versionsalgorithms. empirical results presented works described Section 5 indicateadvantages often realized practice problems DPLL basedalgorithms yield significant performance improvements.number reasons DPLL based algorithms outperform traditionalalgorithms UM P ROD. Algorithms like join tree algorithm (which used manyBAYES inference systems), take advantage global structure interconnectionsfunctions characterized tree width branch width instance. DPLL algorithmshowever, also naturally exploit internal local structure within functions.accomplished instantiating variables reducing functions accordingly. lead6. Marinescu Dechter (2007) present method searching AND/OR tree best-first manner. methodalso interleave solving components, general best-first search exponential space overheads.419fiBACCHUS , DALMAO , & P ITASSIimprovements especially functions encoded way expose functionsinternal structure, encoding sets clauses (e.g., see Li et al., 2008). twoprominent examples structure exploited DPLL.First, subproblems might contain zero valued functions. case algorithmsneed recurse furtherthe reduced subproblem must value 0.7 correspondingsituation occurs one intermediate functions, Fi , produced summingvariables, value 0 setting inputs. obvious way fully exploitingsituation. achieve gains ignoring parts Fi domain map 0Fi appears product functions. However, still expend considerable effortcomputing intermediate function Fj many whose non-zero values might factirrelevant eventually multiplied zero values Fi .Second, input functions become constant prior variablesset (e.g., clause might become equivalent TRUE one literals becometrue), might become independent remaining variables. means subproblems f |xi =1 f |xi =0 might quite different underlying hypergraphs. DPLL-basedalgorithms take advantage fact, since work reduced problems separately.example, algorithms free use dynamic variable orderings, different variableordering used solving subproblem. VE, hand, decompose problemway, hence cannot take advantage structure.BAYES situation corresponds context-specific independence random variable X might dependent set variables W, Y, Z considering possible assignments variables (so f (X, W, Y, Z) one input functions), W = Truemight X becomes independent (i.e., f (X, W, Y, Z)|W =1 might function F (X, Z)rather F (X, Y, Z)). Previously ad-hoc methods proposed (Boutilier, Friedman,Goldszmidt, & Koller, 1996) take advantage kind structure.noted however, problems functions little internal structuresignificantly efficient algorithms (RC, AND/OR searchDPLL algorithms). uses simple multiplication summation operationsoverheads involved instantiating variables exploring AND/OR searchtree backtracking tree.RC AND/OR search share advantages VE. However,much flexibility DPLL algorithms. shown Theorem 6 fully exploitingzero valued functions instances require dynamic variable orderings lie outsiderange basic versions RC AND/OR search. Although proof coverenhanced versions RC AND/OR (RC-Cache+ AND/OR-Cache+ ), pointedeven versions flexibility DPLL algorithms. practice,empirical evidence provided Cachet system (Sang et al., 2004, 2005a) branchbound system described Kitching Bacchus (2008) support belief addedflexibility important practice.exploitation context-specific independence also poses problems RC AND/ORsearch algorithms. particular, static decomposition schemes employ incapablefully exploiting structureas pointed underlying hypergraphs subproblems arising different instantiations radically different. However, although DPLL7. #S corresponds situation clause becomes empty.420fiBACKTRACKING EARCH#SAT BAYESalgorithms principle able exploit structure, remains open problem find practicalways accomplishing this. Specifically, decomposition scheme computed prior searchsophisticated (and computationally complex) algorithms utilized. difficult overcomeoverhead methods used dynamically search (although see Livan Beek 2004 work direction). development methods light weightenough use search still effective selecting decomposition promoting variablesremains open problem.Finally, shown proof Theorem 5, RC AND/OR search possess intrinsicadvantages DPLL algorithms except perhaps conceptually simplicity. proof showsDPLL algorithms simulate RC AND/OR search way additionalcomputation required. Furthermore, pointed Section 5 algorithms also ableutilize static decomposition schemes obtaining efficiency gains RC AND/ORsearch.Recently, several papers (Sanner & McAllester, 2005; Mateescu & Dechter, 2007) madesignificant progress developing compact representations functions (rather tabularform), thereby potentially enhancing algorithms discussed paper (VE, RC, etc.)allowing exploit additional local structure within functions. interesting future stepwould combine unique dynamic features #DPLL-Cache one promisingcompact function representations try improve UM P ROD algorithms.Acknowledgments research funded governments Ontario CanadaNSERC PREA programs. results paper presented earlier conference paper (Bacchus et al., 2003). thank Michael Littman valuable conversations.Appendix A. ProofsA.1 Lemmas Relating Branch Width, Tree Width, Elimination WidthLemma 2 Let H = (V, E) hypergraph tree-decomposition width w.ordering vertices V induced width H w.Proof: Let H = (V, E) hypergraph tree width w let Ttd tree decompositionachieves width w. is, maximum sized label Ttd size w + 1. assumewithout loss generality labels leaves Ttd one-to-one correspondenceedges H. arbitrary node Ttd , let label (m) set vertices labelm, tree rooted m, vertices(m) union labels leaf nodes(i.e., hyperedges H appearing ), depth(m) distance root.Let x vertex H, let leaves(x) set leaves Ttd contain xlabel. define node(x) deepest common ancestor Ttd nodes leaves(x),depth vertex, depth(x), depth(node(x)). Note x label (node(x)), sincepath left-most leaf leaves(x) right-most leaf must pass node(x);x appear label node outside subtree rooted node(x), sinceleaf outside subtree contains x.Finally let = x1 , . . . , xn ordering vertices depth(y) < depth(x),must precede x ordering. use notation < x indicate precedes x421fiBACCHUS , DALMAO , & P ITASSIordering (and thus eliminated x). claim induced widthwidth Ttd , i.e., w.Consider Anode(x) , subtree rooted node(x), vertices(node (x)), union labelsleaves Anode (x) . make following observations vertices.1. vertices(node (x)) < x, labels node(x) node(y) must ancestornode(x) (or equal). < x implies depth(y) depth(x). must pathleaf Anode(x) containing node(y), since node (y) least high node(x)path must go node(x) (or must node(x) = node(y)). either caselabel (node(x)).2. vertices(node(x)) > x node(y) must lie inside Anode(x) node(y)must descendant node(x) (or equal). > x implies depth(y) depth(x).must path leaf containing node(y), since node(y)least deep node(x) must either path node(y) node(x),node(y) = node(x).Note condition 2 implies > x appears subtree node(x),hyperedges original hypergraph H containing must also subtreenode(x).claim hyperedge produced stage elimination process xi eliminatedcontained label (node(xi )). Since size set bounded w + 1, thus verifyinduced width bounded w (note hyperedge produced eliminationcontain xi label (node(xi )) does).base case x1 eliminated. hyperedges containing x1 contained subtree node(x1 ), thus hyperedge created x1 eliminated contained vertices(node (x1 )).vertices vertices(node (x1 )) follow x1 ordering must labelnode(x1 ) vertices(node(x1 )) label (node(x1 )).xi eliminated two types hyperedges might unioned together: (a)hyperedges containing xi part original hypergraph H, (b) hyperedges containing xi produced x1 , . . . , xi1 eliminated. original hyperedges, among leaves node(xi ), thus contained vertices(node(xi )).new hyperedge produced eliminating one previous variables, say variable y,hyperedge produced contained label (node (y)) induction, turn containedvertices(node(y)). subtree node(x) get hyperedge containedvertices(node(x)) since superset vertices(node (y)). Otherwise, node(y) lies anotherpart tree, label cannot contain x (no node outside subtree node(x) xlabel). Thus hyperedge created eliminated also cannot contain xi .sum hyperedge created xi eliminated contained vertices(node(xi )), sincehyperedges containing xi stage set. Furthermore, vertices x1 , . . . , xi1removed hyperedge, thus contains variables following xi ordering. Hence,(1) hyperedge contained label (node(xi )). 2Lemma 3 Let H hypergraph elimination width w. H tree-decompositiontree width w.422fiBACKTRACKING EARCH#SAT BAYESProof: (Proof Lemma 3) Let = x1 , . . . xn elimination ordering H.construct tree decomposition H using follows. Initially, |E| trees, size1, one corresponding edge e E. first merge trees containing xn bigger tree,Tn , leaving us new, smaller set trees. merge trees containing xn1bigger tree, Tn1 . continue way formed single tree, . filllabels intermediate vertices tree tree-decomposition. is,n two leaves contain vertex v, every node along pathn must also contain v label. hard see xi , tree Ti (createdmerging trees containing xi ) property label root (which connectsrest ) contained ei xi , ei hyperedge created xi eliminated.Basically, nodes xj , j > i, already contained Ti xi need label Ti root.Furthermore, xj j < contained Ti root label, xj must originalhyperedge variable xk k i: thus xj would appeared hyperedge ei generatedxi eliminated.Hence tree width final tree larger induced width . 2A.2 Complexity Results Caching Versions DPLLproof theorems 1 2 need common notation definitions. Let fk-CNF formula n variables clauses, let H underlying hypergraph associatedf branch width w. results Darwiche (2001), branch decompositionH depth O(log m) width O(w). Also results Robertson Seymour (1995),possible find branch decomposition, Tbd , Tbd branch width O(w) depthO(log m), time nO(1) 2O(w) . Thus main goal three theorems provestated time space bounds DPLL-based procedures, run staticordering easily obtainable Tbd .Recall leaves Tbd one-to-one correspondence clauses f .number vertices Tbd according depth-first preorder traversal Tbd . vertex numberedi, let fi denote subformula f consisting conjunction clauses correspondingleaves tree rooted i. Let Vars(fi ) set variables (sub)formula fi . Recallbranch decomposition label vertex i, label (i), set variablesintersection Vars(fi ) Vars(f fi ). node Tbd partitions clauses f threesets clauses: fi , fiL , fiR , fiL conjunction clauses leaves Tbdleft fi , fiR conjunction clauses leaves right fi .DPLL caching algorithms achieve stated run time bounds querying variables specific, static variable ordering. is, branch DPLL decision tree,DT , variables instantiated order. (In contrast dynamic variable ordering allows DPLL decide variable query next based assignmentsmade before. Thus different branches query variables different order.). variableordering used DT determined depth-first pre-ordering vertices branch decomposition Tbd labeling vertices. Let (i, 1), . . . , (i, ji ) denote variableslabel (i) appear label earlier vertex Tbd . Note since width Tbdw, ji w i. Let 1, . . . , z sequence vertex numbers Tbd . DPLL algorithm query variables underlying f following static order: = h(i1 , 1), (i1 , 2), . . . ,(i1 , j1 ), (i2 , 1), . . . , (i2 , j2 ), . . . , (is , 1), . . . , (is , js )i i1 < i2 < . . . < z, j1 , . . . , js w.423fiBACCHUS , DALMAO , & P ITASSINote vertices Tbd , nothing queried since variables label mayoccurred labels earlier vertices. notation allows vertices skipped.underlying complete decision tree, DT , created DPLL algorithms input f thustree j1 + j2 + . . . + js = n levels. levels grouped layers, ith layerconsisting ji levels. Note 2l nodes level l DT , identify particularnode level l (l, ) particular assignment first l variables ordering,((q, r), ), (q, r) lth pair ordering , before.DPLL algorithms carry depth-first traversal DT , keeping formulas cachealready solved along way. (For #DPLL-SimpleCache, formulas storedcache form f | , #DPLL-Cache #DPLL-Space, formulas storedvarious components ToComponents(f | ).) algorithm ever hits node formulacomputed already solved, avoid computation, thuscomplete depth-first search DT rather depth-first search pruned version DT .theorems, want get upper bound size pruned tree actually searchedalgorithm.Theorem 1 solving #S n variables, execution #DPLL-SimpleCacheruns time bounded 2O(w log n) w underlying branch width instance. Furthermore, algorithm made deterministic time guarantees.Proof: want show size subtree DT searched #DPLL-SimpleCache2O(w log n) . backtracking particular node (l, ) = ((q, r), ) level l DT ,formula put cache, already known, form f | . (Recall settingfirst l variables.) However, see although 2l different ways set , numberdistinct formulas form actually much smaller 2l . Consider partial assignment, ,set variables including (q, r), q r jq .number variables set (the length ) j1 + j2 + . . . + jq1 + r.Let denote partial assignment consistent variablescame labels vertices path root Tbd including vertex qset. idea reduction , removed assignmentsirrelevant fq fqR .Consider happens DPLL algorithm reaches particular node ((q, r), ) levell DT . point algorithm solving subproblem f | , thus, backtracknode, f | = fqL | fq | fqR | placed cache, already known. Notevariables subformula fqL set , thus either fqL | = 0, case nothing newput cache, fqL | = 1 case f | = fq | fqR | = fq | fqR | putcache. Thus, set distinct subformulas placed cache level l = (q, r)set subformulas form fq | fqR | , setting variables labelsroot vertex q, plus variables (q, 1), ..., (q, r). w variables,q depth Tbd (each label w variables since width Tbd ). Hencetotal number 2(wd) . implies number subtrees DTlevel l + 1 actually traversed #DPLL-SimpleCache 2 2wd = 2O(wd) ,depth node q Tbd . Let number nodes DT actually traversed#DPLL-SimpleCache. Then, n2O(wlog n) , since sum number nodesvisited every level DT node q Tbd O(log m) = O(log n).424fiBACKTRACKING EARCH#SAT BAYESAccounting time search cache, overall runtime #DPLL-SimpleCachet2 , number nodes DT traversed algorithm. Thus,#DPLL-SimpleCache runs time (n2O(wlog n) )2 = 2O(wlog n) . 2Theorem 2 solving #S n variables, exists execution #DPLL-Cache runstime bounded nO(1) 2O(w) w underlying branch width instance. Furthermore,algorithm made deterministic time guarantees.Proof: prove theorem placing bound number times #DPLL-Cachebranch variable xl . Using notation specified above, xl corresponds pair (q, r)ordering used #DPLL-Cache. is, xl rth new variable label vertex qbranch decomposition Tbd .#DPLL-Cache utilizes static ordering , branches on, queries, variablesaccording order, always reducing component containing variable xi currently due queried. However, since previously cached components always removed (byRemoveCachedComponents algorithm), variable xi turnqueried, component among active components contains xi . case, #DPLLCache simply moves next variable ordering, continuing advance findsfirst variable appear active component. branch variablereducing component appears in, leaving components unaltered.implies time #DPLL-Cache selects xl variable next branchmust case (1) xl appears active component. particular value componentalready cache. (2) variable prior xl ordering appears activecomponent. variables either assigned particular value previous recursiveinvocations, component appeared removed value alreadycache.branch decomposition Tbd let p qs parent (q must parent since rootempty label). claim whenever #DPLL-Cache selects xl next variable branchon, active component containing xl must component reduction fp whose formdetermined solely settings variables p r variables q alreadyset. case, 2(w+r) = 2O(w) different components xlappear in, hence #DPLL-Cache branch xl 2O(w) times time onecomponents gets stored cache.prove claim. label q consists variables appearing ps label variablesappearing label qs sibling. Since variables label (p) set, qsibling must identical set unqueried variables labels. Hence, q mustleft child p time right child visited ordering, xl alreadyqueried. Thus, time xl queried, fp affected current settinglabel (p) (as variables shares rest formula) first r queriedvariables label (q). is, fp 2(w+r) different configurations, thuscomponent containing xl also many different configurations.Thus n variables obtain bound number branches decision tree explored#DPLL-Cache n2O(w) . proof previous theorem, overall runtimequadratic number branches traversed, give claimed bound nO(1) 2O(w) . 2425fiBACCHUS , DALMAO , & P ITASSITheorem 3 solving #S n variables, execution #DPLL-Space usesspace linear instance size runs time bounded 2O(w log n) w underlyingbranch width instance. Furthermore, algorithm made deterministictime space guarantees.Proof: proof, natural work tree decomposition ratherbranch decomposition.Let f k-CNF formula n variables clauses let H underlying hypergraph associated f . begin tree decomposition Ttd depth O(log m) widthO(w) (computable time nO(1) 2O(w) ). assume without loss generality leavesTtd one-to-one correspondence clauses f . node Ttd partitions fthree disjoint sets clauses: fi , conjunction clauses leaves subtree Ttd rootedi, fiL , conjunction clauses leaves Ttd left fi , fiR , conjunctionclauses leaves Ttd right fi . #DPLL-Space query variables associatedlabels Ttd according depth-first preorder traversal. Let variables label (i) appearing earlier label path root node denoted S(i) = (i, 1), . . . , (i, ji ).non-leaf node j k left right children, variables S(i)exactly variables occur fj fk occur outside fi . let ctotal number nodes Ttd , #DPLL-Space query variables underlying ffollowing static order: S(1), S(2), . . . , S(c), S(i) may empty. underlyingdecision tree, DT , created #DPLL-Space complete tree n levels.identify particular node level l DT = (l, ) particular assignmentfirst l variables ordering, = ((q, r), ) (the r th variable S(q)).#DPLL-Space carries depth-first traversal DT , storing components formulascache solved. However, components formulas also popped cachetotal space ever utilized linear. algorithm hits node componentsformula computed known, avoid traversing subtree rooted node.Thus searches pruned version DT .(pruned) depth-first traversal DT , edge traversed traversed twice,direction. given time traversal, let E = E1 E2 set edgestraversed, E1 edges traversed forward direction,E2 edges traversed directions. edges E1 constitute partialpath p starting root DT . edge p labeled either 0 1. Let p1 , . . . , pkset subpaths p (beginning root) end 1-edge. Let 1 , . . . , k subrestrictionscorresponding p1 , . . . , pk except last variable originally assigned 1assigned 0. example, p (x1 = 0, x3 = 1, x4 = 0, x5 = 1, x6 = 0, x2 = 0),1 = (x1 = 0, x3 = 0), 2 = (x1 = 0, x3 = 1, x4 = 0, x5 = 0). informationcache time contains ToComponents(f |i ), k.node q Ttd corresponding subformula fq , context fq set variablesdefined follows. Let (q1 , . . . , qd ) denote vertices Ttd path root q (excluding q itself). context fq set Context (fq ) = S(q1 ) S(q2 ) . . . S(qd ).Intuitively, context fq set variables queried nodes lie along pathq. Note reach level l = (q, 1) DT , first variable S(q) queried,already queried many variables, including variables Context(fq ). Thus setvariables queried level l = (q, 1) partitioned two groups relative fq :426fiBACKTRACKING EARCH#SAT BAYESirrelevant variables, set Context(fq ) relevant variables. claim arbitrarylevel l = (q, r) DT , nodes level l actually traversed nodes ((q, r), )irrelevant variables (with respect fq ) set 0. total number nodeslevel l = (q, r) 2|Context(fq )|+r 2w log n . Since truelevels, total number nodes DT traversed bounded n2w log n . Thus,remains prove claim.Consider node = ((q, r), ) DT . is, = 1 2 . . . q1 b1 . . . br1 ,i, assignment variables S(i), b1 . . . br1 assignment first r 1variables S(q). Let context fq S(q1 ) . . . S(qd ), log n. supposeassigns 1 non-context (irrelevant) variable, say first assignment occurs ut ,tth variable u , u q 1. want show algorithm never traverses s.Associated partial path DT ; also call partial path . Considersubpath/subassignment p including ut = 1. traversed, starttraversing p. Since last bit p 1 (i.e., ut = 1) get point, storedcache ToComponents(f | ) exactly like p except last bit, ut , zero. Letj first node q1 , q2 , . . . qd property set variables S(j) queriedp. (On path q Ttd , j first node along path variables S(j)queried p.) ToComponents(f | ) consists three parts: (a) ToComponents(fjL | ), (b)ToComponents(fj | ), (c) ToComponents(fjR | ).consider path p extends p way DT , p shortest subpathvariables S(i) < j queried. restriction corresponding prefinement p variables S(1)S(2). . . S(j1) set. Since already set everything occurs j, go beyond p component ToComponents(f |p )already cache. ToComponents(f |p ) consists three parts: (a) ToComponents(fjL |p ),(b) ToComponents(fj |p ), (c) ToComponents(fjR |p ). set everything occurs j, formulas (a) known. Since p agree variables relevantfj , ToComponents(fj |p ) = ToComponents(fj | ) hence formulas (b) cache.Similarly formulas (c) cache since ToComponents(fjR |p ) = ToComponents(fjR | ).Thus components ToComponents(f |p ) cache, hence shownnever traverse beyond p hence never traverse s. Therefore total number nodes traversedlevel l = (q, r) 2wd , depth q Ttd , desired. yieldsoverall runtime 2O(w log n) .left argue space used linear instance size. total number formulasever stored cache simultaneously linear depth tree decomposition,O(log m). Since store restricted formula f | storing associated restriction, total space ever used O(n log m), linear input size. 2A.3 Comparing Algorithms BAYES #Sproving next theorem, first discuss detail structure search spaceexplored various versions RC, AND/OR search DDP. algorithms operateway. instantiate variables problem decomposes independentcomponents solve components separate recursions. Hence, solving CNFformula f generate AND/OR search tree (Dechter & Mateescu, 2007).427fiBACCHUS , DALMAO , & P ITASSIAND/OR search tree AO generated one algorithms solves #Sinstance f (a CNF formula), rooted tree. node n AO labeled formula n.fsubtree n generated solving n.f . root A0 labeled original formulaf . four different types nodes AO:Query nodes. query node q associated variable q.var two children correspondingtwo possible instantiations q.var . is, children labeled formulasq.f |q.var =0 q.f |q.var =1 . query node q generated search algorithm wheneverchooses instantiate q.var executes recursive calls two resultant reducedformulas.nodes. node, a, query node parent, one childrenquery nodes. node generated search algorithmdecomposes current formula two independent components following instantiation parent query nodes variable. components solvedone subtrees rooted nodes children. a.f splits componentsVfi , = 1, . . . , k, a.f = fi , ith child labeled fi . Note fishare variables. Hence, set query node variables appear subtreei-th child disjoint set query node variables appearing j-thchild j 6= i.Failure nodes. leaf nodes tree labeled formula containing emptyclause. caching used, failure nodes might also labeled formula cachealready shown unsatisfiable.Satisfying nodes. leaf nodes tree labeled formula containingclauses. caching used, satisfying nodes might also labeled satisfiableformula cache whose model count already know.Figure 6 shows example AND/OR search tree.node n AO also value, n.value, computed algorithm generates it.need distinguish zero values n.value = 0, non-zero values denotedn.value = 1. Every satisfying node value 1, every failure node value 0. querynode value 1 least one children value 1, node value1 children value 1. example, Figure 6 node value0, query node 2 value 1. Note children node AO mustvalue 1 except possibly right child. algorithms generating AO terminate searchnode soon discover value 0 childthis implies nodevalue 0. seen n.value = 0 n.f unsatisfiable n.value = 1 n.f satisfiable.Given node n AO, let AO(n) AND/OR subtree AO rooted n. satisfyingassignment ns formula n.f defines solution subtree S(n) AO(n). particular, S(n)connected subtree AO(n) rooted n (1) q query node S(n) S(n)also contains child q corresponding assignment made (i.e., [q.var ] valueassigned q.var , S(n) contain child labeled formula q.f |q.var =[q.var] ),(2) node S(n) S(n) contains children a, (3) contains failurenodes. example, solution subtree AND/OR tree shown Figure 6 (i.e., solutionsubtree root node) formed leaf nodes b, c, f, l; query nodes 1, 2, 3, 4, 5, 6,428fiBACKTRACKING EARCH#SAT BAYES111216n3861213!Eu7B!Ce45c17!!j19pqh1518g!b109f14lr!xz!vkwF ilFailurenode!Satisfying nodeQuery nodenodeFigure 6: example AND/OR search tree query nodes numbered 119, leaf nodes (bothfailure satisfying) numbered az, nodes labeled AE.7, 8; nodes A, B. particular, left value query nodes 1, 2, 3, 5, 6, 78, along right value query node 4 satisfy clauses formula 1.f . solutionsubtree AO(n) exists n.value = 1.Finally, AND/OR search tree say query node whose parent nodecomponent root. also classify root node component root. Figure 6 query nodes 1(the root node), 3, 6, 8, 4, 5, 9, 10, 12, 13, 17, 19 component roots.Theorem 5 #DPLL-Cache polynomially simulates RC-Cache, RC-Cache+ , AND/OR-Cache,AND/OR-Cache+ , VE. #DPLL-Space polynomially simulates RC-Space, AND/OR-SpaceDDP.Proof: Since RC-Cache polynomially simulates ignore proof: showing#DPLL-Cache polynomially simulates RC-Cache also shows polynomially simulates VE.Also assume proof algorithms use unit propagation,#DPLL-Cache/Space. explained Section 3.1, #DPLL-Cache/Space without unit propagationpolynomially simulate versions #DPLL-Cache/Space using unit propagation.429fiBACCHUS , DALMAO , & P ITASSIstated algorithms generate AND/OR search tree solving CNF formulaf . prove theorem first show AND/OR search tree solving f convertedpartial DPLL decision tree, DT , bigger. show DPLL algorithmssolve f using DT guide variable ordering. Thus, obtain result minimalruntime stated algorithms, must result generation AND/ORsearch tree AOmin , also achieved DPLL algorithms. particular, runpartial decision tree constructed AOmin , DPLL algorithms achieve polynomiallysimilar runtime. (This suffices prove theorem, need show existenceexecution DPLL algorithms achieving run time.)make distinction AND/OR search tree constructed partial decisiontree clear, use suffixes ao dt indicate elements AND/OR tree decisiontree respectively.DPLL decision trees contain query variables, satisfying nodes, failure nodes,satisfying failure nodes leaf nodes. construct partial decision tree DTAND/OR tree AO expanding left solution subtree S(nao ) every node nao AOnao .value = 1 linear sequence query variables DT using depth-first orderingquery variables S(nao ). nodes nao AO nao .value = 0 expansionattempted, case result sequence query nodes terminate failure nodes.Every node qdt DT pointer, dtao(qdt ) node qao AO, end construction pointers establish map nodes DT nodes AO. Initially, rootDT pointer root AO. Then, node qdt DT :1. dtao(qdt ) query node qao AO, make qdt query node create leftright child, ldt rdt , qdt DT . make qdt query variable qao (i.e.,qdt .var = qao .var ), set children point children qao (i.e., dtao(ldt )dtao(rdt ) set left right children qao AO).2. dtao(qdt ) node aao AO, reset dtao(qdt ) left childaao AO. apply first rule above, continue.3. dtao(qdt ) failure node AO set qdt failure node. case qdtchildren.4. dtao(qdt ) satisfying node AO examine path ao AO rootdtao(qdt ). Let rao last component root ao right sibling.(a) rao exists, node path rao dtao(qdt ) AO rightchild query node whose left child value 1, reset dtao(qdt )leftmost right sibling rao . node also component root, hence querynode AO. apply first rule above, continue.(b) Otherwise (either rao exist node path raoright child query node whose left child value 1), make qdt satisfyingnode. case qdt children.Rule 4 construction convert leftmost solution subtree node naoAO sequence query nodes DT performing depth-first traversal solutionsubtree. particular, solution subtree leftmost right sibling deepest component430fiBACKTRACKING EARCH#SAT BAYES111231612n4!13o17pe145bu1518x6c7!!qr19vw9!8fgz10ih!ljkFailure node!Satisfying nodeQuery nodeFigure 7: partial DPLL decision tree constructed AND/OR search tree Figure 6.query leaf nodes n numbered number corresponding node,dtao(n), AND/OR search tree.root depth-first successor satisfying leaf node. condition node routesibling right child query node whose left child value 1 ensuresperform depth-first traversal along leftmost solution subtree along subsequent solutionsubtrees. Figure 7 shows partial decision tree would constructed AND/ORsearch tree Figure 6.diagram, satisfying nodes whose pointers reset next component root usingrule 4a, numbered corresponding query node AND/OR tree followedleaf label corresponding satisfying node. example, node 5b Figure 7 representssatisfying child b node 4 Figure 6 redirected depth-first successor node 5(the leftmost right sibling deepest component root 4).another example, AND/OR tree, right child node 6 node C. Hence,decision tree, right child corresponding query node 6, becomes query node 9leftmost child node C (rule 2). Furthermore, reach satisfying node j AND/ORtree, proceed hence left child query node 10 decision tree becomesterminal satisfying node (rule 3). particular, although path root node 10AND/OR tree contains component root right sibling, namely node 6, path also containsnode C right child query node (node 6) whose left child (node 7) value 1.431fiBACCHUS , DALMAO , & P ITASSItwo things note. First, node ndt DT variables instantiated pathao A0 root dtao(n) instantiated values path dtDT root ndt . Since Rules 3 4b terminate paths, nodes dt insertedRules 1, 2, 4b. Rules 1 2 insert nodes dt whose parents already dt ,Rule 1 ensures values assigned AO. Finally, Rule 4a insertsnode adt dt one dtao(adt )s siblings already dt , hence siblings (and as)parent must already dt .Second, variable queried twice along path DT . is, node ndt DTancestor ndt ndt .var = ndt .var . path dt DT grown applicationsRules 1, 2, 4a. Since path AO queries variable twice, Rules 1 2 mustpreserve condition. Similarly Rule 4a moves new component root aao , set queryvariables aao AO disjoint set query variables already appearing dt .Using above, AND/OR search tree AO generated algorithms RCSpace, AND/OR-Space DDP solving formula f , construct correspondingpartial decision tree DT . show #DPLL-Space solve f exploring search treelarger DT . Note DT larger AO, hence show#DPLL-Space solve f polynomially similar run time, proving polynomiallysimulate RC-Space, AND/OR-Space DDP. (Note run time algorithmspolynomially related size search trees explore.)execute #DPLL-Space using variable ordering specified DT . is, startingroot rdt DT , #DPLL-Space always query variable current node DT , ndt .var ,descend ndt left child. backtracks ndt descend right child.Hence, need show #DPLL-Space must backtrack reaches leaf DT . is,explores search tree larger DT .First, #DPLL-Space reaches failure node DT must detect empty clause backtrack. Rule 3 construction failure node fdt DT must correspond failure nodedtao(fdt ) AO. Since variables instantiated path AO root dtao(fdt )instantiated values path DT root fdt , see emptyclause detected AO dtao(fdt ) #DPLL-Space must also detect empty clausefdt . (Note algorithm generated AO used unit propagation, assume#DPLL-Space well).Second, #DPLL-Space reaches satisfying node sdt DT must detect currentset components solved backtrack (line 4 Algorithm 8). Let dt path DTroot sdt , ao path AO dtao(sdt ) root, crdt node dtdtao(crdt ) component root AO (we say crdt component root dt ).claim (a) lao left sibling dtao(crdt ) AO, exists node ldt dtdtao(ldt ) = lao , lao .f satisfied dt ; (b) rao right sibling dtao(crdt )AO rao .f #DPLL-Spaces cache.Given claim (a) clauses original formula yet satisfied dt clausesrao .f nodes rao AO right siblings component root crdt dt (i.e.,rao right sibling component root dtao(crdt ) AO). #DPLL-Space arrived crdt ,prior reaching sdt , variables AO path root dtao(crdt ) alreadyinstantiated values dt . Thus, pao dtao(crdt )s parent AO, #DPLLSpace would recognized rao .f separate component instantiated pao .var ,would added rao .f list components (at line 8 11 Algorithm 8). Note that,432fiBACKTRACKING EARCH#SAT BAYESsolved rao .f would removed #DPLL-Spaces cache backtracks undoinstantiation pao .var . (At point solution pao children would combinedyield solution pao .f ).Furthermore, following variable ordering specified DT , #DPLL-Space would instantiate variables r.f along path dt . Hence, component #DPLL-Spaceslist components reaches ns must equal rao .f right sibling rao component root dt , claim (b) removed call RemoveCachedComponents()(line 6). leave #DPLL-Space empty list components solve, hence mustbacktrack sdt .prove claims. (a) see DT always visit children nodeAO left right order. is, inserting component root crdt path, mustfirst visit left siblings lao dtao(crdt ). inserting ldt path (with dtao(ldt ) = lao ),instantiate ldt start query nodes lao searching alternate instantiationsvariables able traverse leftmost solution subtree AO(lao ). traversalresults insertion path solution lao .f , DT inserts crdt pathusing Rule 4a.(b) observe sdt satisfying node DT application Rule 4b.Hence two possible cases. First, none component roots dtright sibling. case every clause original formula satisfied #DPLL-Space mustbacktrack. example, Figure 7 occurs leaf nodes l y.Otherwise, let crdt component root dt dtao(crdt ) right sibling AO,let ndt first node dt following crdt (i) ndt successor dt rightchild, (ii) dtao(ndt ) left child AO value 1. node ndt must exist, else sdtwould leaf node DT Rule 4a. #DPLL-Space arrived node crdtwould rao .f list components right siblings rao dtao(crdt ). mightalso unsolved components list. components, however, must equalrao .f right sibling rao component root dt preceding crdt , mustplaced list components prior #DPLL-Space reaching crdt . Then, #DPLL-Spacearrived ndt would taken left branch first. Thus would previously invokedright sibling components component list.#DPLL-Space invoked list components either solves every component,placing cache keeping backtracks nodefirst placed list, discovers one components unsatisfiable. onecomponents unsatisfiable, immediately backtrack point componentfirst placed list. particular, recursive calls list components contains knownunsatisfiable component return immediately since call InCache() detectlist components product equal zero.Hence, taking left branch ndt , #DPLL-Space, list components,components form rao .f right siblings component roots ndt dt , also lao .flao left child dtao(ndt ) AO. Since lao value 1, lao .f satisfiable, either#DPLL-Space solve components, placing value cache, discoverone components rao .f unsatisfiable backtrack without visiting sdt . Therefore,visit sdt would solved components could potentially list components,components would still cache since placed list arrivingsdt .433fiBACCHUS , DALMAO , & P ITASSIshows #DPLL-Space polynomially simulates RC-Space, AND/OR-Space DDP.RC-Cache AND/OR-Cache gain RC-Space AND/OR-Space solvecomponents once. is, arrive node nao generatedAND/OR tree AO, nao .f solved immediately backtrack.#DPLL-Cache gains efficiency #DPLL-Space. particular, need never solvecomponent once. Using caching removing previously solved componentslist components gives rise savings realized adding cachingAND/OR RC. Formally, construction partial decision tree DT used.AO mark nodes search terminated cache hit satisfying node (if cachedformula satisfiable) failure node (if cached formula unsatisfiable). Now, example,nodes satisfying failure nodes children componentssolved before. Applying construction AO gives rise partial decision tree DT ,shown #DPLL-Cache using DT guide variable choices explore searchtree size DT . proves #DPLL-Cache polynomially simulatesRC-Cache AND/OR-Cache.subtle point #DPLL-Cache might solve component pointsearch. particular, component first appears #DPLL-Caches list componentspreviously added unsatisfiable component, #DPLL-Cache backtrack without solving .Following DT , #DPLL-Cache enough work find first solution,proceed components list. search first solution, cacheunsatisfiable reductions found search. Thus, next time encountersfollow variable ordering extra work: cached unsatisfiable reductionsimmediately prune paths leading failure proceed directly first solution. components list satisfiable, eventually backtrack firstsolution continue solve . Hence, although #DPLL-Cache might encounter manytimes solving it, encounter, except first, require adding search treenumber nodes linear number variables . number nodes addedfirst encounter, first solution found, encounter finally solves, together equal number nodes required AO solve . Hence, encounters withoutsolving increase size #DPLL-Caches search tree polynomial.Finally, note construction given accommodates use dynamic variable orderingsorder variables varies branch branch AND/OR search tree. (Varyingvalue assigned along left right branch query variable also accommodated).is, proof also shows #DPLL-Cache polynomially simulates AND/OR-Cache+RC-Cache+ . 2Theorem 6 None RC-Space, RC-Cache, AND/OR-Cache, AND/OR-Space polynomially simulate #DPLL-Cache, #DPLL-Space, #DPLL.prove theorem first observe result Johannsen (Johannsen, 2001),#DPLL-Cache, #DPLL-Space, #DPLL solve negation propositional stringof-pearls principle (Bonet, Esteban, Galesi, & Johannsen, 1998) time nO(log n) , rundynamic variable ordering. prove (in Theorem 7) algorithms requiretime exponential n problem. Hence, none algorithms polynomially simulate#DPLL (or stronger #DPLL-Space #DPLL-Cache).434fiBACKTRACKING EARCH#SAT BAYESstring-of-pearls principle, introduced different form Clote Setzer (1998)explicitly Bonet et al. (1998) follows. bag pearls, colored redblue, n pearls chosen placed string. string-of-pearls principle says firstpearl string red last one blue, must red-blue blue-red pairpearls side-by-side somewhere string. negation principle, Sm,n , expressedvariables pi,j pj [n] j [m] pi,j represents whether pearl j mappedvertex string, pj represents whether pearl j colored blue (pj = 0) red (pj = 1).clauses SPm,n follows.(1) hole gets least one pearl:j=1 pi,j , [n].(2) hole gets one pearl: (pi,j pi,j ), [n] j [m] ,j [m], j 6= j .(3) pearl goes one hole: (pi,j pi ,j ), [n], [n], 6= , j [m].(4) leftmost hole gets assigned red pearl rightmost hole gets assigned blue pearl:(p1,j pj ) (pn,j pj ), j [m].(5) two adjacent holes get assigned pearls color: (pi,j pi+1,j pj pj ),1 < n, j [m], j [m], j 6= j , (pi,j pi+1,j pj pj ), 1 < n, j [m],j [m], j 6= j .Johannsen (Johannsen, 2001) shows SPn,n quasipolynomial size tree resolution proofs.follows #DPLL, #DPLL-Space #DPLL-Cache solve SPn,n quasipolynomial time.Lemma 4 (Johannsen, 2001) SPn,n solved time nO(log n) #DPLL, #DPLL-Space,#DPLL-Cache.Theorem 7 Let = 1/5. algorithms RC-Space, RC-Cache, AND/OR-Cache, AND/ORSpace, VE, #DPLL-Cache using static variable ordering, require time 2n solve SPn,n .Proof: seen proof Theorem 5 #DPLL-Cache using static variableordering polynomially simulate stated algorithms.Hence, suffices prove #DPLL-Cache static ordering requires time 2nSPm,n , = n. static ordering, mean variables queried accordingordering long mentioned current formula. is, allow variableskipped irrelevant formula currently consideration. visualize SPn,nbipartite graph, n vertices left, n pearls right. pearl variablepj corresponding n pearls, edge variable pi,j every vertex-pearl pair. (Notevariables corresponding vertices still refer them.)Fix particular total ordering underlying n2 + n variables, 1 , 2 , . . . , l . pearl j,let fanin (j) equal number edge variables pk,j incident pearl j one firstvariables queried. Similarly, vertex i, let fanin (i) equal number edge variables pi,kincident vertex one first variables queried. set pearls S, let fanin (S)equal number edge variables pk,j incident pearl j one firstvariables queried. Similarly set vertices S, fanin (S) equals number edge variablespi,k incident vertex one first variables queried. Let edgest (j)435fiBACCHUS , DALMAO , & P ITASSIedgest (S) defined similarly although set edges rather numberedges. clear context whether domain objects pearls vertices.use simple procedure, based particular ordering variables, markingpearl either C F follows. procedure, pearl may point markedC later overwritten F; however, pearl marked F, remainsF duration procedure. pearl j marked C particular pointtime, t, means point, color pearl already queried, fanin (j)less n , = 2/5. pearl j marked F particular point time t, meanspoint fanin (j) least n . (The color j may may queried.)pearl j unmarked time t, means color yet queried, fanin (j)less n .l 1 n2 +n, following. lth variable queried pearl variable (l = pjj), less n edges pi,j incident j queried far, mark pjC. Otherwise, lth variable queried edge variable (l = pi,j ) fanin l (j) n ,mark pearl j F (if already marked F). Otherwise, leave pearl j unmarked.Eventually every pearl become marked F. Consider first time eitherlot Cs, lot Fs. precisely, let first time either exactlyn Cs (and less many Fs) exactly n Fs (and less manyCs.) exactly n Cs occurs first, call case (a). Extend ta follows.Let +1 , . . . , +c largest segment variables pearl variables pj jalready marked F. ta = + c. Notice query immediately following taeither pearl variable pj currently unmarked, edge variable. hand,exactly n Fs occurs first, call case (b). Again, extend tb ensurequery immediately following tb either pearl variable pj currently unmarked,edge variable.intuition case (a) (a lot Cs), lot pearls colored prematurelythat is,know position mapped toand hence lot queries must asked.case (b) (a lot Fs), lot edge variables queried thus lot queries asked.proceed prove formally.begin notation definitions. Let f = SPn,n , let Vars(f ) denoteset variables underlying f . restriction partial assignment variablesunderlying f either 0 1. variable x unassigned , denote (x) = . LetDPLL tree based variable ordering . is, decision tree variablequeried level . Recall corresponding node v formula f |restriction corresponding partial path root v. tree traverseddepth-first search. vertex v corresponding path p traversed, check seef |p already cache. is, need traverse subtree rooted v.yet cache, traverse left subtree v, followed right subtree v.subtrees traversed, pop back v, store f |p cache.induces ordering vertices (and corresponding paths) traversedwheneverpop back vertex v (and thus, store value cache), put v (p) endcurrent order.Lemma 5 Let f SPn,n let static ordering variables. Let partial restrictionvariables. runtime #DPLL-Cache (f, ) less runtime #DPLLCache (f | , ), ordering unassigned variables consistent .436fiBACKTRACKING EARCH#SAT BAYESLemma 6 restriction , f | 6= 0 (pi,j ) = , pi,j occurs f | .Proof: Consider clause Ci = (pi,1 . . . pi,m ) f . Since pi,j clause, pi,joccur f | , Ci | must equal 1. Thus exists j 6= j (pi,j ) = 1.clause (pi,j pi,j )| = pi,j thus pi,j disappear f | . 2Corollary 1 Let total ordering Vars(f ). Let , partial restrictions setsexactly 1 , . . . , q sets exactly 1 , . . . , q , q < q. Suppose exists k = pi,jsets k (k ) = . either f | = 0 f | = 0 f | 6= f | .Case (a). Let total ordering Vars(f ) case (a) holds. Let P C denote setexactly n pearls marked C let P F denote set less n pearls (disjointP C ) marked F. Note (the color of) pearls P C queried time ta ;color pearls P F may queried time ta , color pearls P P C P Fqueried time ta . Note total number edges pi,jqueried n+ + n1+ 2n1+ .define partial restriction, , 2n variables 1 , . . . , ta follows.j P F , fix one-to-one mapping P F [n] range(j) edgesta (j)j. j P C , variable pi,j queried 1 , . . . ta , set pi,j 0. vertexvariables pi,j queried 1 , . . . , ta , map exactly one pearl jpj P P C P F . 2n i. (This arbitrary long consistentone-to-one mapping already defined P F .) remaining pj P P C P Fyet mapped to, set queried variables pi,j 0. pearls pj P Fqueried 1 , . . . , ta , assign fixed color pearl (all Red Blue)smallest Red/Blue gap large possible. Note gap size least n1 .sets variables 1 , . . . ta except variables pj , j P C . Since n variables,number restrictions 1 , . . . , ta consistent exactly 2n . Let denote setrestrictions.Let f = f |Ma let ordering unassigned variables consistent . (Theset unassigned variables is: pj , j P C , plus variables k , k > ta .) Let DPLLtree corresponding solving f . Lemma 5, suffices show #DPLL-Cacherun inputs f , takes time least 2n .Note first n variables queried pearl variables P C , thus setn2 paths height exactly n correspond set possible settings variables.want show vertex v height n (corresponding 2n settingsvariables P C ), v must traversed #DPLL-Cache, thus runtime least2n .Fix vertex v, corresponding path S. v traversed,occurs ordering, f | = f | . wantshow cannot happen. several cases consider.1a. Suppose || n 6= . partial assignmentsvariables P C inconsistent one another. easy check case,f | 6= f | .2a. Suppose || > n , (n + 1)st variable set edge variable pi,j .| | n , (pi,j ) = . Corollary 1, follows f | 6= f | .437fiBACCHUS , DALMAO , & P ITASSI3a. Suppose || > n (n + 1)st variable set pearl variable pj . (Again,know pj unset .) Since case (a), assume pj P P C P F .Call vertex bad P P F P C edgesta (i). bad, fanin ta (i) greatern 2n n/2. Since total number edges queried 2n1+ , followsnumber bad vertices 4n . implies find pair i, + 1vertices pearl j that: (1) pi,j queried 1 , . . . , ta ; (2) pi+1,j queried1 , . . . , ta ; (3) pj P P C P F thus pj also queried. Thus clause(pi,j pj pi+1,j pj )| disappear shrink f | , thus f | 6= f | .Case (b). Let total ordering Vars(f ) case (b) holds. let P C denote setless n pearls marked C let P F denote set exactly n pearls marked F.define partial restriction Mb 2n variables 1 , . . . , follows. Callvertex full variables pi,j queried 1 , . . . , tb . n full vertices.j P F , fix pair vertices Fj = (ij , ij ) [n]. Let union n sets Fjdenoted F . F following properties. (1) j, element Fj full; (2)j P F , Fj edgestb (j); (3) every two distinct elements F least distance 4 apart.Since f anintb (j) n , = 2/5 > , possible find sets Fj satisfying criteria.pi,j queried 1 , . . . tb , j P F 6 Fj , Mb set pi,j 0.j P C , variable pi,j queried 1 , . . . tb , set pi,j 0. full vertex , mapexactly one pearl j pj P P C P F . (Again arbitrary longconsistent one-to-one mapping.) remaining pj P P C P F yetmapped to, set queried variables pi,j 0. pearls pj P C , color Red.pearls pj P F queried, assign fixed color pearl.variables queried 1 , . . . tb set Mb edgevariables, pi,j , j P F , Fj . Let denote set 2n settings edgevariables j P F mapped exactly one element Fj . Let f = f |Mb letDPLL tree corresponding solving f , ordering unassignedvariables consistent . Lemma 5, suffices show #DPLL-Cache f takestime least 2n .Note first 2n variables queried variables Pij ,j , Pij ,j , j P F .nontrivial paths height 2n j P F mapped exactly onevertex Fj , since otherwise formula f set 0. Thus, nontrivial paths height2n correspond S. want show nontrivial vertex v height 2n(corresponding restrictions S), v must traversed #DPLL-Cache, thusruntime least 2n .Fix vertex v corresponding path S. want show ,occurs ordering, f | 6= f | . three cases consider.1b. Suppose || 2n . nontrivial, partial mappings pearlsj P F Fj , inconsistent one another. easy check casef | 6= f | .2b. Suppose || > 2n (2n + 1)st variable set edge variable pi,j .| | 2n , (pi,j ) = . Corollary 1, follows f | 6= f | .438fiBACKTRACKING EARCH#SAT BAYES3b. Suppose || > 2n (2n + 1)st variable set pearl variable pj .definition tb , assume pj P P C P F . reasoning similar case 3a,find vertices i, i+1, pearl j P P C P F none variable pi,j , pi+1,j , pjqueried 1 , . . . , tb . Thus clause (pi,j pj pi+1,j pj )| disappearshrink f | 1, therefore f | 6= f | .Thus two cases, #DPLL-Cache f takes time least 2n thus#DPLL-Cache f takes time least 2n . 2ReferencesAleknovich, A., & Razborov, A. (2002). Satisfiability, Branch-width Tseitin Tautologies.Annual IEEE Symposium Foundations Computer Science (FOCS), pp. 593603.Bacchus, F., Dalmao, S., & Pitassi, T. (2003). Algorithms Complexity Results #SATBayesian Inference. Annual IEEE Symposium Foundations Computer Science(FOCS), pp. 340351.Bayardo, R. J., & Pehoushek, J. D. (2000). Counting Models using Connected Components.Proceedings AAAI National Conference (AAAI), pp. 157162.Bayardo, R. J., & Miranker, D. P. (1995). space-time trade-off solving Constraint Satisfaction Problems. Proceedings International Joint Conference Artificial Intelligence(IJCAI), pp. 558562.Beame, P., Impagliazzo, R., Pitassi, T., & Segerlind, N. (2003). Memoization DPLL: FormulaCaching Proof Systems. IEEE Conference Computational Complexity, pp. 248264.Birnbaum, E., & Lozinskii, E. L. (1999). good old Davis Putnam procedure helps countingmodels. J. Artif. Intell. Research (JAIR), 10, 457477.Bitner, J. R., & Reingold, E. (1975). Backtracking programming techniques. CommunicationsACM, 18(11), 651656.Bodlaender, H. L. (1993). tourist guide Treewidth. Acta Cybernetica, 11(12), 121.Bonet, M., Esteban, J. L., Galesi, N., & Johannsen, J. (1998). Exponential separationsrestricted resolution cutting planes proof systems. Annual IEEE Symposium Foundations Computer Science (FOCS), pp. 638647.Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independenceBayesian Networks. Uncertainty Artificial Intelligence, Proceedings Annual Conference (UAI), pp. 115123.Chavira, M., & Darwiche, A. (2006). Encoding CNFs empower component analysis. TheoryApplications Satisfiability Testing (SAT), pp. 6174.Chavira, M., & Darwiche, A. (2008). probabilistic inference weighted model counting.Artificial Intelligence, 172(6-7), 772799.Chavira, M., Darwiche, A., & Jaeger, M. (2006). Compiling relational bayesian networks exactinference. Int. J. Approx. Reasoning, 42(1-2), 420.Clote, P., & Setzer, A. (1998). PHP, st-connectivity odd charged graphs. Proof ComplexityFeasible Arithmetics, Vol. 39 DIMACS Series, pp. 93117. AMS.439fiBACCHUS , DALMAO , & P ITASSICormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2001). Introduction Algorithms. 2ndEdition. McGraw Hill.Darwiche, A., & Allen, D. (2002). Optimal time-space tradeoff probabilistic inference. European Workshop Probabilistic Graphical Models. Available www.cs.ucla.edu/darwiche.Darwiche, A. (2001). Recursive conditioning. Artificial Intelligence, 126, 541.Darwiche, A. (2002). logical approach factoring belief networks. Proceedings International Conference Principles Knowledge Representation Reasoning, pp. 409420.Darwiche, A. (2004). New advances compiling CNF decomposable negation normal form.Proceedings European Conference Artificial Intelligence (ECAI), pp. 328332.Davies, J., & Bacchus, F. (2007). Using reasoning improve #SAT solving. ProceedingsAAAI National Conference (AAAI), pp. 185190.Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving. Communications ACM, 4, 394397.Davis, M., & Putnam, H. (1960). computing procedure quantification theory. JournalACM, 7, 201215.Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial Intelligence,113, 4185.Dechter, R., & Mateescu, R. (2004). Mixtures deterministic-probabilistic networksAND/OR search space. Uncertainty Artificial Intelligence, Proceedings Annual Conference (UAI), pp. 120129.Dechter, R., & Mateescu, R. (2007). AND/OR search spaces graphical models. Artificial Intelligence, 171(2-3), 73106.Dubois, O. (1991). Counting number solutions instances satisfiability. TheoreticalComputer Science, 81, 4964.Haken, A. (1985). intractability resolution. Theoretical Computer Science, 39, 297305.Hertel, P., Bacchus, F., Pitassi, T., & van Gelder, A. (2008). Clause learning effectively psimulate general propositional resolution. Proceedings AAAI National Conference(AAAI).Johannsen, J. (2001). Exponential incomparability tree-like ordered resolution. Unpublished manuscript, available http://www.tcs.informatik.uni-muenchen.de/jjohanns/notes.html.Kask, K., Dechter, R., Larrosa, J., & Dechter, A. (2005). Unifying tree decompositions reasoninggraphical models. Artificial Intelligence, 166(1-2), 165193.Kitching, M., & Bacchus, F. (2008). Exploiting decomposition constraint optimization problems.Proceedings Principles Practice Constraint Programming (CP), pp. 478492.Lauritzen, S., & Spiegelhalter, D. (1988). Local computation probabilities graphical structures application expert systems. Journal Royal Statistical Society SeriesB, 50(2), 157224.440fiBACKTRACKING EARCH#SAT BAYESLi, W., & van Beek, P. (2004). Guiding real-world sat solving dynamic hypergraph separator decomposition. Proceedings International Conference Tools ArtificialIntelligence (ICTAI), pp. 542548.Li, W., van Beek, P., & Poupart, P. (2006). Performing incremental Bayesian Inference dynamicmodel counting. Proceedings AAAI National Conference (AAAI), pp. 11731179.Li, W., van Beek, P., & Poupart, P. (2008). Exploiting causal independence using weighted modelcounting. Proceedings AAAI National Conference (AAAI).Littman, M. L., Majercik, S. M., & Pitassi, T. (2001). Stochastic boolean satisfiability. J. AutomatedReasoning, 27(3), 251296.Majercik, S. M., & Littman, M. L. (1998). Maxplan: new approach probabilistic planning.Proceedings International Conference Artificial Intelligence Planning Scheduling (AIPS), pp. 8693.Marinescu, R., & Dechter, R. (2006). Dynamic orderings AND/OR branch-and-bound searchgraphical models. Proceedings European Conference Artificial Intelligence(ECAI), pp. 138142.Marinescu, R., & Dechter, R. (2007). Best-first AND/OR search graphical models. Proceedings AAAI National Conference (AAAI), pp. 11711176.Mateescu, R., & Dechter, R. (2007). AND/OR multi-valued decision diagrams weighted graphical models. Uncertainty Artificial Intelligence, Proceedings Annual Conference(UAI).Mateescu, R., & Dechter, R. (2005). AND/OR cutset conditioning. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 230235.Moskewicz, E., Madigan, C., Zhao, M., Zhang, L., & Malik, S. (2001). Chaff: Engineeringefficient sat solver. Proc. Design Automation Conference (DAC).Nilsson, N. J. (1980). Principles Artificial Intelligence. Tioga.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems (2nd edition). Morgan Kaufmann,San Mateo, CA.Preston, C. (1974). Gibbs States Countable Sets. Cambridge University Press.Rish, I., & Dechter, R. (2000). Resolution versus search: Two strategies SAT. JournalAutomated Reasoning, 24(1), 225275.Robertson, N., & Seymour, P. (1991). Graph minors X. obstructions tree-decomposition. JournalCombinatorial Theory, Series B, 52, 153190.Robertson, N., & Seymour, P. (1995). Graph minors XIII. disjoint paths problem. JournalCombinatorial Theory, Series B, 63, 65110.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82(12), 273302.Sang, T., Bacchus, F., Beame, P., Kautz, H. A., & Pitassi, T. (2004). Combining component cachingclause learning effective model counting. Theory Applications SatisfiabilityTesting (SAT).441fiBACCHUS , DALMAO , & P ITASSISang, T., Beame, P., & Kautz, H. A. (2005a). Heuristics fast exact model counting. TheoryApplications Satisfiability Testing (SAT), pp. 226240.Sang, T., Beame, P., & Kautz, H. A. (2005b). Performing Bayesian Inference weighted modelcounting. Proceedings AAAI National Conference (AAAI), pp. 475482.Sang, T., Beame, P., & Kautz, H. A. (2007). dynamic approach MPE weighted MAXSAT. Proceedings International Joint Conference Artificial Intelligence (IJCAI),pp. 173179.Sanner, P., & McAllester, D. (2005). Affine algebraic decision diagrams (aadds) applications structured probabilistic inference. Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp. 13841390.Spitzer, F. L. (1971). Markov random fields Gibbs ensembles. American Mathematical Monthly,78, 14254.Thurley, M. (2006). sharpSATCounting models advanced component caching implicitBCP. Theory Applications Satisfiability Testing (SAT), pp. 424429.Valiant, L. G. (1979a). complexity enumeration reliability problems. SIAM JournalComputing, 9, 410421.Valiant, L. G. (1979b). Complexity Computing Permanent. Theoretical Computer Science, 8, 189201.Zhang, W. (1996). Number models satisfiability sets clauses. Theoretical ComputerScience, 155, 277288.442fiJournal Artificial Intelligence Research 34 (2009) 569-603Submitted 07/08; published 04/09Learning Document-Level Semantic PropertiesFree-Text AnnotationsS.R.K. BranavanHarr ChenJacob EisensteinRegina BarzilayBRANAVAN @ CSAIL . MIT. EDUHARR @ CSAIL . MIT. EDUJACOBE @ CSAIL . MIT. EDUREGINA @ CSAIL . MIT. EDUComputer Science Artificial Intelligence LaboratoryMassachusetts Institute Technology77 Massachusetts Avenue, Cambridge 02139Abstractpaper presents new method inferring semantic properties documents leveraging free-text keyphrase annotations. annotations becoming increasingly abundant duerecent dramatic growth semi-structured, user-generated online content. One especiallyrelevant domain product reviews, often annotated authors pros/conskeyphrases real bargain good value. annotations representativeunderlying semantic properties; however, unlike expert annotations, noisy: lay authorsmay use different labels denote property, labels may missing. learnusing noisy annotations, find hidden paraphrase structure clusters keyphrases.paraphrase structure linked latent topic model review texts, enabling system predict properties unannotated documents effectively aggregate semanticproperties multiple reviews. approach implemented hierarchical Bayesian modeljoint inference. find joint inference increases robustness keyphrase clusteringencourages latent topics correlate semantically meaningful properties. Multiple evaluations demonstrate model substantially outperforms alternative approaches summarizingsingle multiple documents set semantically salient keyphrases.1. IntroductionIdentifying document-level semantic properties implied text core problem naturallanguage understanding. example, given text restaurant review, would usefulextract semantic-level characterization authors reaction specific aspects restaurant, food service quality (see Figure 1). Learning-based approaches dramaticallyincreased scope robustness semantic processing, typically dependentlarge expert-annotated datasets, costly produce (Zaenen, 2006).propose use alternative source annotations learning: free-text keyphrases produced novice users. example, consider lists pros cons often accompanyreviews products services. end-user annotations increasingly prevalent online,grow organically keep pace subjects interest socio-cultural trends. Beyondpragmatic considerations, free-text annotations appealing linguistic standpointcapture intuitive semantic judgments non-specialist language users. many real-worlddatasets, annotations created documents original author, providing direct windowsemantic judgments motivated document text.c2009AI Access Foundation. rights reserved.fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYpros/cons: great nutritional value... combines all: amazing product, quick friendly service, cleanliness, great nutrition ...pros/cons: bit pricey, healthy... awesome place go health conscious. really great low calorie dishespublish calories fat grams per serving.Figure 1: Excerpts online restaurant reviews pros/cons phrase lists. reviews assertrestaurant serves healthy food, use different keyphrases. Additionally,first review discusses restaurants good service, annotatedkeyphrases.major obstacle computational use free-text annotations inherently noisy fixed vocabulary, explicit relationship annotation keyphrases,guarantee relevant semantic properties document annotated. example,pros/cons annotations accompanying restaurant reviews Figure 1, underlyingsemantic idea expressed different ways keyphrases great nutritional valuehealthy. Additionally, first review discusses quality service, annotated such.contrast, expert annotations would replace synonymous keyphrases single canonical label, would fully label semantic properties described text. expert annotationstypically used supervised learning methods. demonstrate paper, traditionalsupervised approaches perform poorly free-text annotations used instead clean, expertannotations.paper demonstrates new approach handling free-text annotation contexthidden-topic analysis document text. show regularities text clarify noiseannotations example, although great nutritional value healthy differentsurface forms, text documents annotated two keyphrases likelysimilar. modeling relationship document text annotations large dataset,possible induce clustering annotation keyphrases help overcomeproblem inconsistency. model also addresses problem incompleteness noviceannotators fail label relevant semantic topics estimating topics predicteddocument text alone.Central approach idea document text associated annotations reflectsingle underlying set semantic properties. text, semantic properties correspondinduced hidden topics similar growing body work latent topic models,latent Dirichlet allocation (LDA; Blei, Ng, & Jordan, 2003). However, unlike existing work topicmodeling, tie hidden topics text clusters observed keyphrases. connectionmotivated idea text associated annotations grounded shared setsemantic properties. modeling properties directly, ensure inferred hiddentopics semantically meaningful, clustering free-text annotations robustnoise.approach takes form hierarchical Bayesian framework, includes LDA-stylecomponent word text generated mixture multinomials. addition, also incorporate similarity matrix across universe annotation keyphrases,570fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSconstructed based orthographic distributional features keyphrases. modelmatrix generated underlying clustering keyphrases, keyphrasesclustered together likely produce high similarity scores. generate wordsdocument, model two distributions semantic properties one governed annotationkeyphrases clusters, background distribution cover properties mentionedannotations. latent topic word drawn mixture two distributions.learning model parameters noisily-labeled training set, apply model unlabeleddata.build system extracts semantic properties reviews products services.system uses training corpus includes user-created free-text annotations pros consreview. Training yields two outputs: clustering keyphrases semantic properties,topic model capable inducing semantic properties unlabeled text. clusteringannotation keyphrases relevant applications content-based information retrieval,allowing users retrieve documents semantically relevant annotations even surfaceforms differ query term. topic model used infer semantic propertiesunlabeled text.topic model also used perform multi-document summarization, capturing keysemantic properties multiple reviews. Unlike traditional extraction-based approaches multidocument summarization, induced topic model abstracts text review representation capturing relevant semantic properties. enables comparison reviews evenuse superficially different terminology describe set semantic properties.idea implemented review aggregation system extracts majority sentimentmultiple reviewers product service. example output produced systemshown Figure 6. system applied reviews 480 product categories, allowing usersnavigate semantic properties 49,490 products based total 522,879 reviews.effectiveness approach confirmed several evaluations.summarization single multiple documents, compare properties inferred model expert annotations. approach yields substantially better resultsalternatives research literature; particular, find learning clustering free-textannotation keyphrases essential extracting meaningful semantic properties dataset.addition, compare induced clustering gold standard clustering produced expertannotators. comparison shows tying clustering hidden topic model substantiallyimproves quality, clustering induced system coheres well clusteringproduced expert annotators.remainder paper structured follows. Section 2 compares approach previous work topic modeling, semantic property extraction, multi-document summarization.Section 3 describes properties free-text annotations motivate approach. modeldescribed Section 4, method parameter estimation presented Section 5.Section 6 describes implementation evaluation single-document multi-documentsummarization systems using techniques. summarize contributions consider directions future work Section 7. code, datasets expert annotations used paperavailable online http://groups.csail.mit.edu/rbg/code/precis/.571fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAY2. Related Workmaterial presented section covers three lines related work. First, discuss workBayesian topic modeling related technique learning free-text annotations.Next, discuss state-of-the-art methods identifying analyzing product propertiesreview text. Finally, situate summarization work landscape prior researchmulti-document summarization.2.1 Bayesian Topic ModelingRecent work topic modeling literature demonstrated semantically salient topicsinferred unsupervised fashion constructing generative Bayesian model document text. One notable example line research Latent Dirichlet Allocation (LDA; Bleiet al., 2003). LDA framework, semantic topics equated latent distributions wordstext; thus, document modeled mixture topics. class modelsused variety language processing tasks including topic segmentation (Purver, Kording,Griffiths, & Tenenbaum, 2006), named-entity resolution (Bhattacharya & Getoor, 2006), sentimentranking (Titov & McDonald, 2008b), word sense disambiguation (Boyd-Graber, Blei, & Zhu,2007).method similar LDA assigns latent topic indicators worddataset, models documents mixtures topics. However, LDA model unsupervised,provide method linking latent topics external observed representationsproperties interest. contrast, model exploits free-text annotations datasetensure induced topics correspond semantically meaningful properties.Combining topics induced LDA external supervision first considered BleiMcAuliffe (2008) supervised Latent Dirichlet Allocation (sLDA) model. inductionhidden topics driven annotated examples provided training stage. perspective supervised learning, approach succeeds hidden topics mediatedocument annotations lexical features. Blei McAuliffe describe variational expectationmaximization procedure approximate maximum-likelihood estimation models parameters. tested two polarity assessment tasks, sLDA shows improvement modeltopics induced unsupervised model added features supervisedmodel.key difference model sLDA assume access cleansupervision data training. Since annotations provided algorithm free-textnature, incomplete fraught inconsistency. substantial difference inputstructure motivates need model simultaneously induces hidden structure freetext annotations learns predict properties text.2.2 Property Assessment Review Analysismodel applied task review analysis. Traditionally, task identifying properties product review texts cast extraction problem (Hu & Liu, 2004; Liu,Hu, & Cheng, 2005; Popescu, Nguyen, & Etzioni, 2005). example, Hu Liu (2004) employassociation mining identify noun phrases express key portions product reviews. polarity extracted phrases determined using seed set adjectives expanded via WordNet572fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSrelations. summary review produced extracting property phrases present verbatimdocument.Property extraction refined PINE (Popescu et al., 2005), another systemreview analysis. PINE employs novel information extraction method identify noun phrasescould potentially express salient properties reviewed products; candidatespruned using WordNet morphological cues. Opinion phrases identified using set handcrafted rules applied syntactic dependencies extracted input document. semanticorientation properties computed using relaxation labeling method finds optimal assignment polarity labels given set local constraints. Empirical results demonstrate PINEoutperforms Hu Lius system opinion extraction identifying polarity opinion words.two feature extraction methods informed human knowledge way opinionstypically expressed reviews: Hu Liu (2004), human knowledge encoded usingWordNet seed adjectives; Popescu et al. (2005), opinion phrases extracted via handcrafted rules. alternative approach learn rules feature extraction annotateddata. end, property identification modeled classification framework (Kim &Hovy, 2006). classifier trained using corpus free-text pro con keyphrasesspecified review authors. keyphrases compared sentences reviewtext; sentences exhibit high word overlap previously identified phrases marked proscons according phrase polarity. rest sentences marked negative examples.Clearly, accuracy resulting classifier depends quality automatically induced annotations. analysis free-text annotations several domains shows automatically mapping even manually-extracted annotation keyphrases document text difficulttask, due variability keyphrase surface realizations (see Section 3). argue restpaper, beneficial explicitly address difficulties inherent free-text annotations.end, work distinguished two significant ways property extraction methods described above. First, able predict properties beyond appear verbatim text.Second, approach also learns semantic relationships different keyphrases, allowingus draw direct comparisons reviews even semantic ideas expressed usingdifferent surface forms.Working related domain web opinion mining, Lu Zhai (2008) describe systemgenerates integrated opinion summaries, incorporate expert-written articles (e.g., review online magazine) user-generated ordinary opinion snippets (e.g., mentionsblogs). Specifically, expert article assumed structured segments, collectionrepresentative ordinary opinions aligned segment. Probabilistic Latent Semantic Analysis(PLSA) used induce clustering opinion snippets, cluster attached oneexpert article segments. clusters may also unaligned segment, indicatingopinions entirely unexpressed expert article. Ultimately, integrated opinion summary combination single expert article multiple user-generated opinion snippetsconfirm supplement specific segments review.works final goal different aim provide highly compact summary multitude user opinions identifying underlying semantic properties, rather supplementingsingle expert article user opinions. specifically leverage annotations users alreadyprovide reviews, thus obviating need expert article template opinion inte-573fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYgration. Consequently, approach suitable goal producing concise keyphrasesummarizations user reviews, particularly review taken authoritative.work closest methodology approach review summarizer developed TitovMcDonald (2008a). method summarizes review selecting list phrasesexpress writers opinions set predefined properties (e.g.,, food ambiance restaurantreviews). system access numerical ratings set properties,training set providing examples appropriate keyphrases extract. Similar sLDA, methoduses numerical ratings bias hidden topics towards desired semantic properties. Phrasesstrongly associated properties via hidden topics extracted part summary.several important differences work summarization methodTitov McDonald. method assumes predefined set properties thus cannot captureproperties outside set. Moreover, consistent numerical annotations required training,method emphasizes use free-text annotations. Finally, since Titov McDonaldsalgorithm extractive, facilitate property comparison across multiple reviews.2.3 Multidocument Summarizationpaper also relates large body work multi-document summarization. Researcherslong noted central challenge multi-document summarization identifying redundantinformation input documents (Radev & McKeown, 1998; Carbonell & Goldstein, 1998; Mani& Bloedorn, 1997; Barzilay, McKeown, & Elhadad, 1999). task crucial significancemulti-document summarizers operate related documents describe factsmultiple times. fact, common assume repetition information among related sourcesindicator importance (Barzilay et al., 1999; Radev, Jing, & Budzikowska, 2000; Nenkova,Vanderwende, & McKeown, 2006). Many algorithms first cluster sentences together,extract generate sentence representatives clusters.Identification repeated information equally central approach multi-documentsummarization method selects properties stated plurality users, thereby eliminating rare and/or erroneous opinions. key difference algorithm existing summarization systems method identifying repeated expressions single semantic property.Since existing work multi-document summarization focuses topic-independentnewspaper articles, redundancy identified via sentence comparison. instance, Radev et al.(2000) compare sentences using cosine similarity corresponding word vectors. Alternatively, methods compare sentences via alignment syntactic trees (Barzilay et al., 1999;Marsi & Krahmer, 2005). string- tree-based comparison algorithms augmentedlexico-semantic knowledge using resources WordNet.approach described paper perform comparisons sentence level. Instead, first abstract reviews set properties compare property overlap acrossdifferent documents. approach relates domain-dependent approaches text summarization (Radev & McKeown, 1998; White, Korelsky, Cardie, Ng, Pierce, & Wagstaff, 2001; Elhadad& McKeown, 2001). methods identify relations documents comparingabstract representations. cases, abstract representation constructed using off-the-shelfinformation extraction tools. template specifying types information select craftedmanually domain interest. Moreover, training information extraction systems requirescorpus manually annotated relations interest. contrast, method require574fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSIncompletenessPropertyGood foodGood serviceGood priceBad foodBad serviceBad priceAverageRecallPrecisionF-score0.7360.3290.5000.5160.4750.6900.5780.9680.8210.7070.7620.6330.6450.8490.8360.4690.5860.6150.5430.6670.688InconsistencyKeyphrase Top KeyphraseCountCoverage %2338.32728.92041.81623.72022.01530.622.633.6Table 1: Incompleteness inconsistency restaurant domain, six major properties prevalent reviews. incompleteness figures recall, precision, F-scoreauthor annotations (manually clustered properties) gold standard propertyannotations. Inconsistency measured number different keyphrase realizationsleast five occurrences associated property, percentage frequencycommonly occurring keyphrases used annotate property.averages bottom row weighted according frequency property occurrence.manual template specification corpora annotated experts. abstract representationsinduce linguistically rich extraction templates, nevertheless enable usperform in-depth comparisons across different reviews.3. Analysis Free-Text Keyphrase Annotationssection, explore characteristics free-text annotations, aiming quantify degreenoise observed data. results analysis motivate development learningalgorithm described Section 4.perform investigation domain online restaurant reviews using documents downloaded popular Epinions1 website. Users website evaluate products providingtextual description opinion, well concise lists keyphrases (pros cons)summarizing review. Pros/cons keyphrases appealing source annotations onlinereview texts. However, contributed independently multiple users thus unlikelyclean expert annotations. analysis, focus two features free-text annotations: incompleteness inconsistency. measure incompleteness quantifies degreelabel omission free-text annotations, inconsistency reflects variance keyphrasevocabulary used various annotators.test quality user-generated annotations, compare expert annotations produced systematic fashion. annotation effort focused six propertiescommonly mentioned review authors, specifically shown Table 1. Givenreview property, task assess whether reviews text supports property.annotations produced two judges guided standardized set instructions. contrastauthor annotations website, judges conferred training session ensure consistency completeness. two judges collectively annotated 170 reviews, 30 annotated1. http://www.epinions.com/575fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYProperty: good pricerelatively inexpensive, dirt cheap, relatively cheap, great price, fairly priced, well priced, reasonableprices, cheap prices, affordable prices, reasonable costFigure 2: Examples many different paraphrases related property good price appearpros/cons keyphrases reviews used inconsistency analysis.both. Cohens Kappa, measure inter-annotator agreement ranges zero one,0.78 joint set, indicating high agreement (Cohen, 1960). average, review textannotated 2.56 properties.Separately, one judges also standardized free-text pros/cons annotations170 reviews. reviews keyphrases matched six properties. standardization allows direct comparison properties judged supported reviewstext properties described reviews free-text annotations. find many semantic properties judged present text user annotated average,keyphrases expressed 1.66 relevant semantic properties per document, text expressed2.56 properties. gap demonstrates frequency authors omitted relevant semanticproperties review annotations.3.1 Incompletenessmeasure incompleteness, compare properties stated review authors formpros cons stated review text, judged expert annotators.comparison performed using precision, recall F-score. setting, recall proportionsemantic properties text review author also provided least one annotationkeyphrase; precision proportion keyphrases conveyed properties judged supportedtext; F-score harmonic mean. results comparison summarizedleft half Table 1.incompleteness results demonstrate significant discrepancy user expertannotations. expected, recall quite low; 40% property occurrences statedreview text without explicitly mentioned annotations. precision scores indicateconverse also true, though lesser extent keyphrases express propertiesmentioned text.Interestingly, precision recall vary greatly depending specific property.highest good food, matching intuitive notion high food quality would key salientproperty restaurant, thus likely mentioned text annotations. Conversely, recall good service lower users, high quality service apparentlykey point summarizing review keyphrases.3.2 Inconsistencylack unified annotation scheme restaurant review dataset apparent acrossreviewers, annotations feature 26,801 unique keyphrase surface forms set 49,310 totalkeyphrase occurrences. Clearly, many unique keyphrases express semantic propertyFigure 2, good price expressed ten different ways. quantify phenomenon, judges576fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSFigure 3: Cumulative occurrence counts top ten keyphrases associated good serviceproperty. percentages total 1,210 separate keyphrase occurrencesproperty.manually clustered subset keyphrases associated six previously mentioned properties. Specifically, 121 keyphrases associated six major properties chosen, accounting10.8% keyphrase occurrences.use manually clustered annotations examine distributional pattern keyphrasesdescribe underlying property, using two different statistics. First, numberdifferent keyphrases property gives lower bound number possible paraphrases.Second, measure often common keyphrase used annotate property,i.e., coverage keyphrase. metric gives sense diffuse keyphrases withinproperty are, specifically whether one single keyphrase dominates occurrences property.Note value overestimate true coverage, since considering tenthkeyphrase occurrences.right half Table 1 summarizes variability property paraphrases. Observeproperty associated numerous paraphrases, found multiple timesactual keyphrase set. importantly, frequent keyphrase accounted thirdproperty occurrences, strongly suggesting targeting labels learninglimited approach. illustrate last point, consider property good service, whosekeyphrase realizations distributional histogram appears Figure 3. cumulative percentagefrequencies frequent keyphrases associated property plotted. top fourkeyphrases account three quarters property occurrences, even within limitedset keyphrases consider analysis, motivating need aggregate considerationkeyphrases.next section, introduce model induces clustering among keyphrasesrelating keyphrase clusters text, directly addressing characteristics data.577fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYxhczwkeyphrase cluster modelkeyphrase cluster assignmentkeyphrase similarity valuesdocument keyphrasesdocument keyphrase topicsprobability selecting insteadselects word topicsbackground word topic modelword topic assignmentlanguage models topicdocument wordsDirichlet(0 )x` Multinomial()(Beta(= ) x` = x`0s`,`0Beta(6= ) otherwise= [d,1 . . . d,K ](d,k1x` = k l hdotherwiseBeta(0 )cd,n Bernoulli(d )Dirichlet(0 )(Multinomial(d ) cd,n = 1zd,nMultinomial(d ) otherwisek Dirichlet(0 )wd,n Multinomial(zd,n )Figure 4: plate diagram model. Shaded circles denote observed variables, squaresdenote hyperparameters. dotted arrows indicate constructed deterministically x h. use refer small constant probability mass.578fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONS4. Model Descriptionpresent generative Bayesian model documents annotated free-text keyphrases.model assumes annotated document generated set underlying semantic topics.Semantic topics generate document text indexing language model; approach,also associated clusters keyphrases. way, model viewed extensionLatent Dirichlet Allocation (Blei et al., 2003), latent topics additionally biasedtoward keyphrases appear training data. However, coupling flexible,words permitted drawn topics represented keyphrase annotations.permits model learn effectively presence incomplete annotations, stillencouraging keyphrase clustering cohere topics supported document text.Another critical aspect model desire ability use arbitrary comparisonskeyphrases, addition information surface forms. accommodategoal, treat keyphrase surface forms generated model. Rather, acquirereal-valued similarity matrix across universe possible keyphrases, treat matrixgenerated keyphrase clustering. representation permits use surfacedistributional features keyphrase similarity, described Section 4.1.advantage hierarchical Bayesian models easy change partsmodel observed parts hidden. training, keyphrase annotationsobserved, hidden semantic topics coupled clusters keyphrases. accountwords related semantic topics, topics may associated keyphrases. testtime, model presented documents keyphrase annotations hidden.model evaluated ability determine keyphrases applicable, based hiddentopics present document text.judgment whether topic applies given unannotated document based probability mass assigned topic documents background topic distribution.annotations, background topic distribution capture entirety documentstopics. task involving reviews products services, multiple topics may accompanydocument. case, topic whose probability threshold (tuned developmentset) predicted supported.4.1 Keyphrase Clusteringhandle hidden paraphrase structure keyphrases, one component model estimatesclustering keyphrases. goal obtain clusters cluster correspond welldefined semantic topic e.g., healthy good nutrition grouped singlecluster. overall joint model generative, generative model clustering could easilyintegrated larger framework. approach would treat keyphrasescluster generated parametric distribution. However, representation wouldpermit many powerful features assessing similarity pairs keyphrases, stringoverlap keyphrase co-occurrence corpus (McCallum, Bellare, & Pereira, 2005).reason, represent keyphrase real-valued vector rather surfaceform. vector given keyphrase includes similarity scores respect every observed keyphrase (the similarity scores represented Figure 4). model similarityscores generated cluster memberships (represented x Figure 4). two keyphrases579fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYLexicalcosine similarity surface forms two keyphrases, represented word frequency vectors.Co-occurrencekeyphrase represented vector co-occurrence values.vector counts many times keyphrases appear documentsannotated keyphrase. example, similarity vectorgood food may include entry tasty food, valuewould number documents annotated good foodcontain tasty food text. similarity twokeyphrases cosine similarity co-occurrence vectors.Table 2: two sources information used compute similarity matrix experiments.final similarity scores linear combinations two values. Note cooccurrence similarity contains second-order co-occurrence information.Figure 5: surface plot keyphrase similarity matrix set restaurant reviews, computed according Table 2. Red indicates high similarity, whereas blue indicates lowsimilarity. diagram, keyphrases grouped according expertcreated clustering, keyphrases similar meaning close together. strong seriessimilarity blocks along diagonal hint information could inducereasonable clustering.580fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSclustered together, similarity score generated distribution encouraging high similarity; otherwise, distribution encouraging low similarity used.2features used producing similarity matrix given Table 2, encompassing lexicaldistributional similarity measures. implemented system takes linear combinationtwo data sources, weighting sources equally. resulting similarity matrix keyphrasesrestaurant domain shown Figure 5.described next section, clustering keyphrases, model takes advantagetopic structure documents annotated keyphrases, addition informationindividual keyphrases themselves. sense, differs traditional approaches paraphraseidentification (Barzilay & McKeown, 2001; Lin & Pantel, 2001).4.2 Document Topic Modelinganalysis document text based probabilistic topic models LDA (Blei et al.,2003). LDA framework, word generated language model indexedwords topic assignment. Thus, rather identifying single topic document, LDA identifiesdistribution topics. High probability topic assignments identify compact, low-entropylanguage models, probability mass language model topic divided amongrelatively small vocabulary.model operates similar manner, identifying topic word, denoted zFigure 4. However, LDA learns distribution topics document, deterministically construct document-specific topic distribution clusters representeddocuments keyphrases figure. assigns equal probability topicsrepresented keyphrase annotations, small probability topics. Generatingword topics way ties together clustering language models.noted above, sometimes keyphrase annotation represent semantictopics expressed text. reason, also construct another background distribution topics. auxiliary variable c indicates whether given words topic drawndistribution derived annotations, background model. Representing chidden variable allows us stochastically interpolate two language models. addition, given document likely also discuss topics coveredkeyphrase. account this, model allowed leave clusters empty, thusleaving topics independent keyphrases.4.3 Generative Processmodel assumes observed data generated stochastic process involving hiddenparameters. section, formally specify generative process. specification guidesinference hidden parameters based observed data, following:L keyphrases, vector s` length L denoting pairwise similarity scoreinterval [0, 1] every keyphrase.document d, bag words wd length Nd . nth word wd,n .2. Note model similarity score independent draw; clearly assumption strong, duesymmetry transitivity. Models making similar assumptions independence related hidden variablespreviously shown successful (for example, Toutanova & Johnson, 2008).581fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYdocument d, set keyphrase annotations hd , includes index ` document annotated keyphrase `.number clusters K, large enough encompass topics actualclusters keyphrases, well word-only topics.observed variables generated according following process:1. Draw multinomial distribution K keyphrase clusters symmetric Dirichletprior parameter 0 .32. ` = 1 . . . L:(a) Draw `th keyphrases cluster assignment x` Multinomial().3. (`, `0 ) = (1 . . . L, 1 . . . L):(a) x` = x`0 , draw s`,`0 Beta(= ) Beta(2, 1), encouraging scores biasedtoward values close one.(b) x` 6= x`0 , draw s`,`0 Beta(6= ) Beta(1, 2), encouraging scores biasedtoward values close zero.4. k = 1 . . . K:(a) Draw language model k symmetric Dirichlet prior parameter 0 .5. = 1 . . . D:(a) Draw background topic model symmetric Dirichlet prior parameter 0 .(b) Deterministically construct annotation topic model , based keyphrase clusterassignments x observed document annotations hd . Specifically, let H settopics represented phrases hd . Distribution assigns equal probabilityelement H, small probability mass topics.4(c) Draw weighted coin Beta(0 ), determine balanceannotation background topic models .(d) n = 1 . . . Nd :i. Draw binary auxiliary variable cd,n Bernoulli(d ), determines whethertopic word wd,n drawn annotation topic model background model .ii. Draw topic assignment zd,n appropriate multinomial indicatedcd,n .iii. Draw word wd,n Multinomial(zd,n ), is, language model indexedwords topic.3. Variables subscripted zero fixed hyperparameters.4. Making hard assignment zero probability topics creates problems parameter estimation.probability 104 assigned topics represented keyphrase cluster memberships.582fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONS5. Parameter Estimationmake predictions unseen data, need estimate parameters model. Bayesianinference, estimate distribution parameter, conditioned observed datahyperparameters. inference intractable general case, sampling approaches allowus approximately construct distributions parameter interest.Gibbs sampling perhaps generic straightforward sampling technique. Conditional distributions computed hidden variable, given variables model.repeatedly sampling distributions turn, possible construct Markov chainwhose stationary distribution posterior model parameters (Gelman, Carlin, Stern, &Rubin, 2004). use sampling techniques natural language processing previouslyinvestigated many researchers, including Finkel, Grenager, Manning (2005) Goldwater,Griffiths, Johnson (2006).present sampling equations hidden variables Figure 4. priorkeyphrase clusters sampled based hyperprior 0 keyphrase cluster assignmentsx. write p( | . . .) mean probability conditioned variables.p( | . . .) p( | 0 )p(x | ),= p( | 0 )p(x` | )`= Dirichlet(; 0 )Multinomial(x` ; )`= Dirichlet(; 0 ),i0 0 + count(x` = i). conditional distribution derived based conjugacymultinomial Dirichlet distribution. first line follows Bayes rule, secondline conditional independence cluster assignments x given keyphrase distribution .Resampling equations k derived similar manner:p(d | . . .) Dirichlet(d ; 0d ),p(k | . . .) Dirichlet(k ; k0 ),P0 = +0d,i = 0 + count(zn,d = cn,d = 0) k,i0count(wn,d = zn,d = k).0building counts , consider cases cn,d = 0, indicating topic zn,dindeed drawn background topic model . Similarly, building counts k0 ,consider cases word wd,n drawn topic k.resample , employ conjugacy Beta prior Bernoulli observation likelihoods, adding counts c prior 0 .p(d | . . .) Beta(d ; 0d ),Pcount(c=1)d,n0n.= 0 + Pn count(cd,n = 0)583fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYkeyphrase cluster assignments represented x, whose sampling distribution depends, s, z, via :p(x` | . . .) p(x` | )p(s | x` , x` , )p(z | , , c)p(x` | )p(s`,`0 | x` , x`0 , )p(zd,n | )`0 6=`cd,n =1= Multinomial(x` ; )Beta(s`,`0 ; x` ,x`0 )Multinomial(zd,n ; ) .`0 6=`cd,n =1leftmost term equation prior x` . next term encodes dependencesimilarity matrix cluster assignments; slight abuse notation, write x` ,x`0denote = x` = x`0 , 6= otherwise. third term dependence word topicszd,n topic distribution . compute final result probability expressionpossible setting x` , sample normalized multinomial.word topics z sampled according topic distribution , background distribution, observed words w, auxiliary variable c:p(zd,n | . . .) p(zd,n | , , cd,n )p(wd,n | zd,n , )(Multinomial(zd,n ; )Multinomial(wd,n ; zd,n )=Multinomial(zd,n ; )Multinomial(wd,n ; zd,n )cd,n = 1,otherwise.x, zd,n sampled computing conditional likelihood possible settingwithin constant proportionality, sampling normalized multinomial.Finally, sample auxiliary variable cd,n , indicates whether hidden topic zd,ndrawn . c depends prior hidden topic assignments z:p(cd,n | . . .) p(cd,n | )p(zd,n | , , cd,n )(Bernoulli(cd,n ; )Multinomial(zd,n ; )=Bernoulli(cd,n ; )Multinomial(zd,n ; )cd,n = 1,otherwise.Again, compute likelihood cd,n = 0 cd,n = 1 within constant proportionality,sample normalized Bernoulli distribution.Finally, model requires values fixed hyperparameters 0 , 0 , 0 , 0 , tunedstandard way based development set performance. Appendix C lists hyperparametersvalues used domain experiments.One main applications model predict properties supported documentsannotated keyphrases. test time, would like compute posterior estimateunannotated test document d. Since annotations present, property predictionbased text component model. estimate, use Gibbs samplingprocedure, restricted zd,n , stipulation cd,n fixed zero zd,nalways drawn . particular, treat language models known; accuratelyintegrate possible language models, use final 1000 samples language modelstraining opposed using point estimate. topic, probability exceedscertain threshold, topic predicted. threshold tuned independently topicdevelopment set. empirical results present Section 6 obtained manner.584fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSFigure 6: Summary reviews movie Pirates Caribbean: Worlds End P R ECIS.summary based 27 documents. list pros cons generated automatically using system described paper. generation numerical ratingsbased algorithm described Snyder Barzilay (2007).6. Evaluation Summarization Qualitymodel document analysis implemented P R ECIS,5 system performs single-multi-document review summarization. goal P R ECIS provide users effective accessreview data via mobile devices. P R ECIS contains information 49,490 products servicesranging childcare products restaurants movies. products, systemcontains collection reviews downloaded consumer websites Epinions, CNET,Amazon. P R ECIS compresses data product short list pros conssupported majority reviews. example summary 27 reviews moviePirates Caribbean: Worlds End shown Figure 6. contrast traditional multidocument summarizers, output system sequence sentences, rather listphrases indicative product properties. summarization format follows format pros/conssummaries individual reviewers provide multiple consumer websites. Moreover, brevitysummary particularly suitable presenting small screens mobiledevices.automatically generate combined pros/cons list product service, first applymodel review. model trained independently product domain (e.g., movies)using corresponding subset reviews free-text annotations. annotations also provideset keyphrases contribute clusters associated product properties.5. P R ECIS accessible http://groups.csail.mit.edu/rbg/projects/precis/.585fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYmodel trained, labels review set properties. Since set possible propertiesreviews product, comparison among reviews straightforwardproperty, count number reviews support it, select property partsummary supported majority reviews. set semantic properties convertedpros/cons list presenting common keyphrase property.aggregation technology applicable two scenarios. system applied unannotated reviews, inducing semantic properties document text; conforms traditional way learning-based systems applied unlabeled data. However, modelvaluable even individual reviews include pros/cons keyphrase annotations. Duehigh degree paraphrasing, direct comparison keyphrases challenging (see Section 3).inferring clustering keyphrases, model permits comparison keyphrase annotationssemantic level.remainder section provides set evaluations models ability capturesemantic content document text keyphrase annotations. Section 6.1 describes evaluationsystems ability extract meaningful semantic summaries individual documents,also assesses quality paraphrase structure induced model. Section 6.2 extendsevaluation systems ability summarize multiple review documents.6.1 Single-Document EvaluationFirst, evaluate model respect ability reproduce annotations present individual documents, based document text. compare wide variety baselinesvariations model, demonstrating appropriateness approach task. addition,explicitly evaluate quality paraphrase structure induced model comparinggold standard clustering keyphrases provided expert annotators.6.1.1 E XPERIMENTAL ETUPsection, describe datasets evaluation techniques used experimentssystem automatic methods. also comment hyperparameters tunedmodel, sampling initialized.Statistic# reviewsavg. review lengthavg. keyphrases / reviewRestaurants5735786.33.42Cell Phones11121056.94.91Digital Cameras39711014.24.84Table 3: Statistics datasets used evaluationsData Sets evaluate system reviews three domains: restaurants, cell phones,digital cameras. reviews downloaded Epinions website; used user-authoredpros cons associated reviews keyphrases (see Section 3). Statistics datasetsprovided Table 3. domains, selected 50% documents training.consider two strategies constructing test data. First, consider evaluating semanticproperties inferred system expert annotations semantic properties presentdocument. end, use expert annotations originally described Section 3 test586fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSset;6 reiterate, annotations 170 reviews restaurant domain,hold 50 development set. review texts annotated six properties accordingstandardized guidelines. strategy enforces consistency completeness ground truthannotations, differentiating free-text annotations.Unfortunately, ability evaluate expert annotations limited cost producing annotations. expand evaluation domains, use author-written keyphraseannotations present original reviews. annotations noisy presenceproperty annotation document strong evidence document supports property,inverse necessarily true. is, lack annotation necessarily implyrespective property hold e.g., review good service-related keyphrase maystill praise service body document.experiments using free-text annotations, overcome pitfall restricting evaluation predictions individual properties documents annotatedproperty antonym. instance, evaluating prediction good service property,select documents either annotated good service bad service-relatedkeyphrases.7 reason, semantic property evaluated unique subset documents. details development test sets presented Appendix A.ensure free-text annotations reliably used evaluation, compareresults produced expert annotations whenever possible. shown Section 6.1.2, free-textevaluations produce results cohere well obtained expert annotations, suggestinglabels used reasonable proxy expert annotation evaluations.Evaluation Methods first evaluation leverages expert annotations described Section 3.One complication expert annotations marked level semantic properties,model makes predictions appropriateness individual keyphrases. addressrepresenting expert annotation commonly-observed keyphrasemanually-annotated cluster keyphrases associated semantic property. example,annotation semantic property good food represented common keyphrase realization, great food. evaluation checks whether keyphrase within clusterskeyphrases predicted model.evaluation author free-text annotations similar evaluation expertannotations. case, annotation takes form individual keyphrases rather semanticproperties. noted, author-generated keyphrases suffer inconsistency. obtain consistentevaluation mapping author-generated keyphrase cluster keyphrases determinedexpert annotator, selecting common keyphrase realizationcluster. example, author may use keyphrase tasty, maps semantic clustergood food; select common keyphrase realization, great food. expertevaluation, check whether keyphrase within clusters predicted model.Model performance quantified using recall, precision, F-score. computedstandard manner, based models representative keyphrase predictions comparedcorresponding references. Approximate randomization (Yeh, 2000; Noreen, 1989) usedstatistical significance testing. test repeatedly performs random swaps individual results6. expert annotations available http://groups.csail.mit.edu/rbg/code/precis/.7. determination made mapping author keyphrases properties using expert-generated gold standardclustering keyphrases. much cheaper produce expert clustering keyphrases obtain expertannotations semantic properties every document.587fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYcandidate system, checks whether resulting performance gap remains leastlarge. use test valid comparing nonlinear functions random variables, F-scores, unlike common methods sign test. Previous workused test include evaluations Message Understanding Conference (Chinchor, Lewis, &Hirschman, 1993; Chinchor, 1995); recently, Riezler Maxwell (2005) advocateduse evaluating machine translation systems.Parameter Tuning Initialization improve models convergence rate, perform twoinitialization steps Gibbs sampler. First, sampling done keyphrase clusteringcomponent model, ignoring document text. Second, fix clustering sampleremaining model parameters. two steps run 5,000 iterations each. full joint modelsampled 100,000 iterations. Inspection parameter estimates confirms model convergence. 2GHz dual-core desktop machine, multithreaded C++ implementation modeltraining takes two hours dataset.model needs provided number clusters K.8 set K large enoughmodel learn effectively development set. restaurant data set K 20. cellphones digital cameras, K set 30 40, respectively. values tuned usingdevelopment set. However, found long K large enough accommodate significant number keyphrase clusters, additional account topics keyphrases,specific value K affect models performance. hyperparametersadjusted based development set performance, though tuning extensive.previously mentioned, obtain document properties examining probability masstopic distribution assigned property. probability threshold set property viadevelopment set, optimizing maximum F-score.6.1.2 R ESULTSsection, report performance model, comparing array increasinglysophisticated baselines model variations. first demonstrate learning clustering annotation keyphrases crucial accurate semantic prediction. Next, investigate impactparaphrasing quality model accuracy considering expert-generated gold standard clustering keyphrases another comparison point; also consider alternative automatically computedsources paraphrase information.ease comparison, results experiments shown Table 5 Table 6,summary baselines model variations Table 4.Comparison Simple Baselines first evaluation compares model four navebaselines. four treat keyphrases independent, ignoring latent paraphrase structure.Random: keyphrase supported document probability one half.results baseline computed expectation, rather actually run. baselineexpected recall 0.5, expectation select half correctkeyphrases. precision average proportion annotations test setnumber possible annotations. is, test set size n properties, property8. requirement could conceivably removed modeling cluster indices drawn Dirichletprocess prior.588fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSRandomkeyphrase supported document probability one half.Keyphrase textkeyphrase supported document appears verbatim text.Keyphrase classifierseparate support vector machine classifier trained keyphrase.Positive examples documents labeled authorkeyphrase; documents considered negative examples.keyphrase supported document keyphrases classifier returnspositive prediction.Heuristic keyphraseclassifierSimilar keyphrase classifier, except heuristic methods used attempt reduce noise training documents. Specifically wishremove sentences discuss keyphrases positive examples.heuristic removes positive examples sentencesword overlap given keyphrase.Model cluster textkeyphrase supported document paraphrases appeartext. Paraphrasing based models keyphrase clusters.Model cluster classifierseparate classifier trained cluster keyphrases. Positive examples documents labeled author keyphrasecluster; documents negative examples. keyphrasescluster supported document clusters classifier returnspositive prediction. Keyphrase clustering based model.Heuristic model clusterclassifierSimilar model cluster classifier, except heuristic methods used reduce noise training documents. Specifically wish removepositive examples sentences discuss keyphrasesclusters. heuristic removes positive examples sentencesword overlap keyphrases given cluster.Keyphrase clustering based model.Gold cluster modelvariation model clustering keyphrases fixedexpert-created gold standard. text modeling parameters learned.Gold cluster textSimilar model cluster text, except clustering keyphrases according expert-produced gold standard.Gold cluster classifierSimilar model cluster classifier, except clustering keyphrasesaccording expert-produced gold standard.Heuristic gold clusterclassifierSimilar heuristic model cluster classifier, except clusteringkeyphrases according expert-produced gold standard.Independent cluster modelvariation model clustering keyphrases first learnedkeyphrase similarity information only, separately text.resulting independent clustering fixed text modeling parameters learned. variations key distinction full modellack joint learning keyphrase clustering text topics.Independent cluster textSimilar model cluster text, except clustering keyphrasesaccording independent clustering.Independent clusterclassifierSimilar model cluster classifier, except clustering keyphrasesaccording independent clustering.Heuristic independentcluster classifierSimilar heuristic model cluster classifier, except clusteringkeyphrases according independent clustering.Table 4: summary baselines variations model compared.589fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYMethod12345678910111213141516modelRandomKeyphrase textKeyphrase classifierHeuristic keyphrase classifierModel cluster textModel cluster classifierHeuristic model cluster classifierGold cluster modelGold cluster textGold cluster classifierHeuristic gold cluster classifierIndependent cluster modelIndependent cluster textIndependent cluster classifierHeuristic independent cluster classifierRecall0.9200.5000.0480.7690.8390.2270.7210.7310.9360.3390.6931.0000.7450.2200.5860.592RestaurantsPrec. F-score0.353 0.5100.346 0.4090.500 0.0870.353 0.4840.340 0.4840.385 0.2860.402 0.5160.366 0.4880.344 0.5020.360 0.3490.366 0.4790.326 0.4920.363 0.4880.340 0.2660.384 0.4640.386 0.468Table 5: Comparison property predictions made model series baselinesmodel variations restaurant domain, evaluated expert semantic annotations.results divided according experiment. methods modelsignificantly better results using approximate randomization indicatedp 0.05, p 0.1.590fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSMethod12345678910111213141516modelRandomKeyphrase textKeyphrase classif.Heur. keyphr. classif.Model cluster textModel cluster classif.Heur. model classif.Gold cluster modelGold cluster textGold cluster classif.Heur. gold classif.Indep. cluster modelIndep. cluster textIndep. cluster classif.Heur. indep. classif.Recall0.9230.5000.0770.9050.9970.4160.8590.9100.9920.5410.8650.9970.9840.3820.7530.881RestaurantsPrec. F-score0.623 0.7440.500 0.5000.906 0.1420.527 0.6660.497 0.6640.613 0.4960.711 0.7780.567 0.6980.500 0.6650.604 0.5710.720 0.7860.499 0.6650.528 0.6870.569 0.4570.696 0.7240.478 0.619Recall0.9710.5000.1711.0000.8450.8290.8761.0000.9240.9140.8100.9690.8380.7240.6381.000Cell PhonesPrec. F-score0.537 0.6920.489 0.4940.529 0.2590.500 0.6670.474 0.6070.547 0.6590.561 0.6840.464 0.6340.561 0.6980.497 0.6440.559 0.6610.468 0.6310.564 0.6740.481 0.5780.472 0.5430.464 0.634Digital CamerasRecall Prec. F-score0.905 0.586 0.7110.500 0.501 0.5000.715 0.642 0.6760.942 0.540 0.6870.845 0.531 0.6520.812 0.596 0.6870.927 0.568 0.7040.942 0.568 0.7090.962 0.510 0.6670.903 0.522 0.6610.874 0.674 0.7610.971 0.508 0.6670.945 0.519 0.6700.469 0.476 0.4730.496 0.588 0.5380.969 0.501 0.660Table 6: Comparison property predictions made model series baselinesmodel variations three product domains, evaluated author free-text annotations. results divided according experiment. methodsmodel significantly better results using approximate randomization indicatedp 0.05, p 0.1. Methods perform significantly bettermodel p 0.05 indicated .591fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYPniappears ni times, expected precisioni=1 mn . instance, restaurantsgold standard evaluation, six tested properties appeared total 249 times 120documents, yielding expected precision 0.346.Keyphrase text: keyphrase supported document appears verbatimtext. Precision high recall low, model unable detectparaphrases keyphrase text. instance, first review Figure 1,cleanliness would supported appears text; however, healthy wouldsupported, even though synonymous great nutrition appear.Keyphrase classifier:9 separate discriminative classifier trained keyphrase. Positive examples documents labeled author keyphrase; documents considered negative examples. Consequently, particular keyphrase,documents labeled synonymous keyphrases would among negative examples.keyphrase supported document keyphrases classifier returns positive prediction.use support vector machines, built using SVMlight (Joachims, 1999) featuresmodel, i.e.,word counts.10 partially circumvent imbalanced positive/negativedata problem, tuned prediction thresholds development set maximize F-score,manner tuned thresholds model.Heuristic keyphrase classifier: baseline similar keyphrase classifier above, attempts mitigate noise inherent training data. Specifically, givenpositive example document may contain text unrelated given keyphrase. attemptreduce noise removing positive examples sentences wordoverlap given keyphrase. keyphrase supported document keyphrasesclassifier returns positive prediction.11Lines 2-5 Tables 5 6 present results, using gold annotations originalauthors annotations testing. model outperforms three baselines evaluationsstrong statistical significance.keyphrase text baseline fares poorly: F-score random baseline threefour evaluations. expected, recall baseline usually low requireskeyphrases appear verbatim text. precision somewhat better, presencesignificant number false positives indicates presence keyphrase textnecessarily reliable indicator associated semantic property.Interestingly, one domain keyphrase text perform well digital cameras.believe prevalence specific technical terms keyphrases useddomain, zoom battery life. technical terms also frequently usedreview text, making recall keyphrase text substantially higher domainevaluations.9. Note classifier results reported initial publication (Branavan, Chen, Eisenstein, & Barzilay, 2008)obtained using default parameters maximum entropy classifier. Tuning classifiers parameters allowed ussignificantly improve performance classifier baselines.10. general, SVMs additional advantage able incorporate arbitrary features, sakecomparison restrict using features across methods.11. thank reviewer suggesting baseline.592fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSkeyphrase classifier baseline outperforms random keyphrase text baselines,still achieves consistently lower performance model four evaluations. Notably,performance heuristic keyphrase classifier worse keyphrase classifier except one case.alludes difficulty removing noise inherent document text.Overall, results indicate methods learn predict keyphrases without accounting intrinsic hidden structure insufficient optimal property prediction. leads ustoward extending present baselines clustering information.important assess consistency evaluation based free-text annotations (Table 6) evaluation uses expert annotations (Table 5). absolute scoresexpert annotations dataset lower scores free-text annotations, ordering performance various automatic methods across two evaluation scenarios.consistency maintained rest experiments well, indicating purposerelative comparison different automatic methods, method evaluatingfree-text annotations reasonable proxy evaluation expert-generated annotations.Comparison Clustering-based Approaches previous section demonstratesmodel outperforms baselines account paraphrase structure keyphrases.ask whether possible enhance baselines performance augmentingkeyphrase clustering induced model. Specifically, introduce three systems, nonetrue baselines, since use information inferred model.Model cluster text: keyphrase supported document paraphrasesappears text. Paraphrasing based models clustering keyphrases.use paraphrasing information enhances recall potential cost precision, dependingquality clustering. example, assuming healthy great nutritionclustered together, presence healthy text would also indicate support greatnutrition, vice versa.Model cluster classifier: separate discriminative classifier trained clusterkeyphrases. Positive examples documents labeled author keyphrasecluster; documents negative examples. keyphrases clustersupported document clusters classifier returns positive prediction. Keyphraseclustering based model. keyphrase classifier, use support vector machines trained word count features, tune prediction thresholds individual cluster development set.Another perspective model cluster classifier augments simplistic text modelingportion model discriminative classifier. Discriminative training often considered powerful equivalent generative approaches (McCallum et al., 2005),leading us expect high level performance system.Heuristic model cluster classifier: method similar model cluster classifier above,additional heuristics used reduce noise inherent training data. Positiveexample documents may contain text unrelated given cluster. reduce noise,sentences word overlap clusters keyphrases removed.keyphrases cluster supported document clusters classifier returns positive prediction. Keyphrase clustering based model.593fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYLines 6-8 Tables 5 6 present results methods. expected, using clusteringkeyphrases baseline methods substantially improves recall, low impactprecision. Model cluster text invariably outperforms keyphrase text recall keyphrasetext improved addition clustering information, though precision worse cases.phenomenon holds even cameras domain, keyphrase text already performs well.However, model still significantly outperforms model cluster text evaluations.Adding clustering information classifier baseline results performance sometimesbetter models. result surprising, model cluster classifier gainsbenefit models robust clustering learning sophisticated classifier assigningproperties texts. resulting combined system complex model itself,potential yield better performance. hand, using simple heuristic reducenoise present training data consistently hurts performance classifier, possiblydue reduction amount training data.Overall, enhanced performance methods, contrast keyphrase baselines,aligned previous observations entailment research (Dagan, Glickman, & Magnini, 2006),confirming paraphrasing information contributes greatly improved performance semanticinference tasks.Impact Paraphrasing Quality previous section demonstrates one centralclaims paper: accounting paraphrase structure yields substantial improvements semantic inference using noisy keyphrase annotations. second key aspect researchidea clustering quality benefits tying clusters hidden topics documenttext. evaluate claim comparing models clustering independent clusteringbaseline. also compare gold standard clustering produced expert human annotators. test impact clustering methods, substitute models inferred clusteringalternative examine resulting semantic inferences change. comparisonperformed semantic inference mechanism model, well model clustertext, model cluster classifier heuristic model cluster classifier baselines.add gold standard clustering model, replace hidden variables correspond keyphrase clusters observed values set according gold standard clustering.12 parameters trained modeling text. model variation, goldcluster model, predicts properties using inference mechanism original model.baseline variations gold cluster text, gold cluster classifier heuristic gold cluster classifierlikewise derived substituting automatically computed clustering gold standard clusters.additional clustering obtained using keyphrase similarity information. Specifically, modify original model learns keyphrase clustering isolationtext, learns property language models. framework, keyphrase clusteringentirely independent review text, text modeling learned keyphraseclustering fixed. refer modification model independent cluster model.model treats document text mixture latent topics, reminiscent modelssupervised latent Dirichlet allocation (sLDA; Blei & McAuliffe, 2008), labels acquiredperforming clustering across keyphrases preprocessing step. previous experiment, introduce three new baseline variations independent cluster text, independent clusterclassifier heuristic independent cluster classifier.12. gold standard clustering created part evaluation procedure described Section 6.1.1.594fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSLines 9-16 Tables 5 6 present results experiments. gold cluster modelproduces F-scores comparable original model, providing strong evidence clusteringinduced model sufficient quality semantic inference. application expertgenerated clustering baselines (lines 10, 11 12) yields less consistent results, overallevaluation provides little reason believe performance would substantially improvedobtaining clustering closer gold standard.independent cluster model consistently reduces performance respect full jointmodel, supporting hypothesis joint learning gives rise better prediction. independentclustering baselines, independent cluster text, independent cluster classifier heuristic independent cluster classifier (lines 14 16), also worse counterparts use modelclustering (lines 6 8). observation leads us conclude expert-annotatedclustering always improve results, independent clustering always degrades them.supports view joint learning clustering text models important prerequisitebetter property prediction.ClusteringModel clustersIndependent clustersRestaurants0.9140.892Cell Phones0.8760.759Digital Cameras0.9450.921Table 7: Rand Index scores models clusters, learned keyphrases text jointly, compared clusters learned keyphrase similarity. Evaluation cluster qualitybased gold standard clustering.Another way assessing quality automatically-obtained keyphrase clusteringquantify similarity clustering produced expert annotators. purposeuse Rand Index (Rand, 1971), measure cluster similarity. measure varies zeroone, higher scores indicating greater similarity. Table 7 shows Rand Index scoresmodels full joint clustering, well clustering obtained independent cluster model.every domain, joint inference produces overall clustering improves upon keyphrasesimilarity-only approach. scores confirm joint inference across keyphrasesdocument text produces better clustering considering features keyphrases alone.6.2 Summarizing Multiple Reviewslast experiment examines multi-document summarization capability system.study models ability aggregate properties across set reviews, compared baselinesaggregate directly using free-text annotations.6.2.1 DATA E VALUATIONselected 50 restaurants, five user-written reviews restaurant. Ten annotatorsasked annotate reviews five restaurants each, comprising 25 reviews per annotator.used six salient properties annotation guidelines previous restaurantannotation experiment (see Section 3). constructing ground truth, label propertiessupported least three five reviews.595fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYMethodmodelKeyphrase aggregationModel cluster aggregationGold cluster aggregationIndep. cluster aggregationRecall0.9050.0360.2380.2260.214Prec.0.3250.7500.8700.8260.720F-score0.4780.0680.3740.3550.330Table 8: Comparison aggregated property predictions made model seriesbaselines use free-text annotations. methods model significantly better results using approximate randomization indicated p 0.05.make property predictions set reviews model baselinespresented below. automatic methods, register prediction system judgesproperty supported least two five reviews.13 recall, precision, F-scorecomputed aggregate predictions, six salient properties marked annotators.6.2.2 AGGREGATION PPROACHESevaluation, run trained version model described Section 6.1.1. Notekeyphrases provided model, though provided baselines.obvious baseline summarizing multiple reviews would directly aggregatefree-text keyphrases. annotations presumably representative reviews semanticproperties, unlike review text, keyphrases matched directly other. firstbaseline applies notion directly:Keyphrase aggregation: keyphrase supported restaurant least two fivereviews annotated verbatim keyphrase.simple aggregation approach obvious downside requiring strict matching independently authored reviews. reason, consider extensions aggregationapproach allow annotation paraphrasing:Model cluster aggregation: keyphrase supported restaurant least twofive reviews annotated keyphrase one paraphrases. Paraphrasingaccording models inferred clustering.Gold cluster aggregation: model cluster aggregation, using expert-generatedclustering paraphrasing.Independent cluster aggregation: model cluster aggregation, using clusteringlearned keyphrase similarity paraphrasing.13. three corroborating reviews required, baseline systems produce positive predictions, leadingpoor recall. Results setting presented Appendix B.596fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONS6.2.3 R ESULTSTable 8 compares baselines model. model outperforms annotationbased baselines, despite access keyphrase annotations. Notably, keyphrase aggregation performs poorly, makes predictions, result requirementexact keyphrase string match. before, inclusion keyphrase clusters improves performance baseline models. However, incompleteness keyphrase annotations (seeSection 3) explains recall scores still low compared model. incorporatingdocument text, model obtains dramatically improved recall, cost reduced precision,ultimately yielding significantly improved F-score.results demonstrate review summarization benefits greatly joint modelreview text keyphrases. Nave approaches consider keyphrases yield inferior results,even augmented paraphrase information.7. Conclusions Future Workpaper, shown free-text keyphrase annotations provided novice usersleveraged training set document-level semantic inference. Free-text annotationspotential vastly expand set training data available developers semantic inferencesystems; however, shown, suffer lack consistency completeness.overcome problems inducing hidden structure semantic properties, correspondclusters keyphrases hidden topics text. approach takes formhierarchical Bayesian model, addresses text keyphrases jointly.model implemented system successfully extracts semantic properties unannotated restaurant, cell phone, camera reviews, empirically validating approach. experiments demonstrate necessity handling paraphrase structure free-text keyphraseannotations; moreover, show better paraphrase structure learned joint frameworkalso models document text. approach outperforms competitive baselines semanticproperty extraction single multiple documents. also permits aggregation acrossmultiple keyphrases different surface forms multi-document summarization.work extends actively growing literature document topic modeling. topic modeling paraphrasing posit hidden layer captures relationship disparate surfaceforms: topic modeling, set latent distributions lexical items, paraphrasingrepresented latent clustering phrases. show two latent structures linked,resulting increased robustness semantic coherence.see several avenues future work. First, model draws substantial power features measure keyphrase similarity. ability use arbitrary similarity metrics desirable;however, representing individual similarity scores random variables compromise,clearly independent. believe problem could avoided modeling generationentire similarity matrix jointly.related approach would treat similarity matrix across keyphrases indicatorcovariance structure. model, would learn separate language models keyphrase,keyphrases rated highly similar would constrained induce similar languagemodels. approach might possible Gaussian process framework (Rasmussen &Williams, 2006).597fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYCurrently focus model identify semantic properties expressed givendocument, allows us produce summary properties. However, mentionedSection 3, human authors give equal importance properties producing summarypros cons. One possible extension work would explicitly model likelihoodtopic annotated document. might avoid current post-processing stepuses property-specific thresholds compute final predictions model output.Finally, assumed semantic properties unstructured. reality,properties related interesting ways. Trivially, domain reviews would desirablemodel antonyms explicitly, e.g., restaurant review simultaneously labeledgood bad food. relationships properties, hierarchical structures, couldalso considered. suggests possible connections correlated topic model BleiLafferty (2006).Bibliographic NotePortions work previously presented conference publication (Branavan et al., 2008).current article extends work several ways, notably: development evaluationmulti-document review summarization system uses semantic properties inducedmethod (Section 6.2); detailed analysis distributional properties free-text annotations(Section 3); expansion evaluation include additional domain sets baselinesconsidered original paper (Section 6.1.1).Acknowledgmentsauthors acknowledge support National Science Foundation (NSF) CAREER grant IIS0448168, Microsoft Research New Faculty Fellowship, U.S. Office Naval Research(ONR), Quanta Computer, Nokia Corporation. Harr Chen supported National Defense Science Engineering NSF Graduate Fellowships. Thanks Michael Collins, ZoranDzunic, Amir Globerson, Aria Haghighi, Dina Katabi, Kristian Kersting, Terry Koo, Yoong KeokLee, Brian Milch, Tahira Naseem, Dan Roy, Christina Sauper, Benjamin Snyder, Luke Zettlemoyer,journal reviewers helpful comments suggestions. also thank Marcia Davidsonmembers NLP group MIT help expert annotations. opinions, findings,conclusions recommendations expressed article authors, necessarily reflect views NSF, Microsoft, ONR, Quanta, Nokia.598fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSAppendix A. Development Test Set StatisticsTable 9 lists semantic properties domain number documents usedevaluating properties. noted Section 6.1.1, gold standard evaluationcomplete, testing every property document. Conversely, free-text evaluationsproperty use documents annotated property antonymnumber documents differs semantic property.DomainRestaurants (gold)RestaurantsCell PhonesCamerasPropertypropertiesGood foodBad foodGood priceBad priceGood serviceBad serviceGood receptionBad receptionGood battery lifePoor battery lifeGood priceBad priceSmallLargeGood priceBad priceGood battery lifePoor battery lifeGreat zoomLimited zoomDevelopment documents50Test Documents1208817931666914033675912028578416856113511023469Table 9: Breakdown property development test sets used evaluations section 6.1.2.599fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYAppendix B. Additional Multiple Review Summarization ResultsTable 10 lists results multi-document experiment, variation aggregationrequire automatic method predict property three five reviews predictproperty product, rather two presented Section 6.2. baseline systems,change causes precipitous drop recall, leading F-score results substantially worsepresented Section 6.2.3. contrast, F-score model consistent acrossevaluations.MethodmodelKeyphrase aggregationModel cluster aggregationGold cluster aggregationIndep. cluster aggregationRecall0.7260.0000.0240.0360.036Prec.0.3650.0001.0001.0001.000F-score0.4860.0000.0470.0680.068Table 10: Comparison aggregated property predictions made model seriesbaselines use free-text annotations. Aggregation requires three five reviewspredict property, rather two Section 6.2. methodsmodel significantly better results using approximate randomization indicatedp 0.05.Appendix C. Hyperparameter SettingsTable 11 lists values hyperparameters 0 , 0 , 0 used experiments domain.values arrived tuning development set. cases, 0 set(1, 1), making Beta(0 ) uniform distribution.Hyperparameters000Restaurants0.00010.0010.001Cell Phones0.00010.00010.0001Cameras0.00010.10.001Table 11: Values hyperparameters used domain across experiments.600fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSReferencesBarzilay, R., McKeown, K., & Elhadad, M. (1999). Information fusion context multidocument summarization. Proceedings ACL, pp. 550557.Barzilay, R., & McKeown, K. R. (2001). Extracting paraphrases parallel corpus. Proceedings ACL, pp. 5057.Bhattacharya, I., & Getoor, L. (2006). latent Dirichlet model unsupervised entity resolution.Proceedings SIAM International Conference Data Mining.Blei, D. M., & Lafferty, J. D. (2006). Correlated Topic Models. Advances NIPS, pp. 147154.Blei, D. M., & McAuliffe, J. (2008). Supervised topic models. Advances NIPS, pp. 121128.Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. Journal MachineLearning Research, 3, 9931022.Boyd-Graber, J., Blei, D., & Zhu, X. (2007). topic model word sense disambiguation.Proceedings EMNLP, pp. 10241033.Branavan, S. R. K., Chen, H., Eisenstein, J., & Barzilay, R. (2008). Learning document-level semantic properties free-text annotations. Proceedings ACL, pp. 263271.Carbonell, J., & Goldstein, J. (1998). use MMR, diversity-based reranking reorderingdocuments producing summaries. Proceedings ACM SIGIR, pp. 335336.Chinchor, N. (1995). Statistical significance MUC-6 results. Proceedings 6th ConferenceMessage Understanding, pp. 3943.Chinchor, N., Lewis, D. D., & Hirschman, L. (1993). Evaluating message understanding systems:analysis third message understanding conference (MUC-3). Computational Linguistics, 19(3), 409449.Cohen, J. (1960). coefficient agreement nominal scales. Educational PsychologicalMeasurement, 20(1), 3746.Dagan, I., Glickman, O., & Magnini, B. (2006). PASCAL recognising textual entailment challenge. Lecture Notes Computer Science, 3944, 177190.Elhadad, N., & McKeown, K. R. (2001). Towards generating patient specific summaries medicalarticles. Proceedings NAACL Workshop Automatic Summarization, pp. 3240.Finkel, J. R., Grenager, T., & Manning, C. (2005). Incorporating non-local information information extraction systems Gibbs sampling. Proceedings ACL, pp. 363370.Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2004). Bayesian Data Analysis (2nd edition).Texts Statistical Science. Chapman & Hall/CRC.Goldwater, S., Griffiths, T. L., & Johnson, M. (2006). Contextual dependencies unsupervisedword segmentation. Proceedings ACL, pp. 673680.Hu, M., & Liu, B. (2004). Mining summarizing customer reviews. Proceedings SIGKDD,pp. 168177.Joachims, T. (1999). Making Large-Scale Support Vector Machine Learning Practical, pp. 169184.MIT Press.601fiB RANAVAN , C HEN , E ISENSTEIN , & BARZILAYKim, S.-M., & Hovy, E. (2006). Automatic identification pro con reasons online reviews.Proceedings COLING/ACL, pp. 483490.Lin, D., & Pantel, P. (2001). Discovery inference rules question-answering. Natural LanguageEngineering, 7(4), 343360.Liu, B., Hu, M., & Cheng, J. (2005). Opinion observer: Analyzing comparing opinionsweb. Proceedings WWW, pp. 342351.Lu, Y., & Zhai, C. (2008). Opinion integration semi-supervised topic modeling. Proceedings WWW, pp. 121130.Mani, I., & Bloedorn, E. (1997). Multi-document summarization graph search matching.Proceedings AAAI, pp. 622628.Marsi, E., & Krahmer, E. (2005). Explorations sentence fusion. Proceedings EuropeanWorkshop Natural Language Generation, pp. 109117.McCallum, A., Bellare, K., & Pereira, F. (2005). conditional random field discriminativelytrained finite-state string edit distance. Proceedings UAI, pp. 388395.Nenkova, A., Vanderwende, L., & McKeown, K. (2006). compositional context sensitive multidocument summarizer: exploring factors influence summarization. ProceedingsSIGIR, pp. 573580.Noreen, E. (1989). Computer-Intensive Methods Testing Hypotheses: Introduction. JohnWiley Sons.Popescu, A.-M., Nguyen, B., & Etzioni, O. (2005). OPINE: Extracting product features opinions reviews. Proceedings HLT/EMNLP, pp. 339346.Purver, M., Kording, K. P., Griffiths, T. L., & Tenenbaum, J. B. (2006). Unsupervised topic modelling multi-party spoken discourse. Proceedings COLING/ACL, pp. 1724.Radev, D., Jing, H., & Budzikowska, M. (2000). Centroid-based summarization multiple documents: Sentence extraction, utility-based evaluation user studies. ProceedingsANLP/NAACL Summarization Workshop.Radev, D., & McKeown, K. (1998). Generating natural language summaries multiple on-linesources. Computational Linguistics, 24(3), 469500.Rand, W. M. (1971). Objective criteria evaluation clustering methods. JournalAmerican Statistical Association, 66(336), 846850.Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes Machine Learning. MITPress.Riezler, S., & Maxwell, J. T. (2005). pitfalls automatic evaluation significancetesting MT. Proceedings ACL Workshop Intrinsic Extrinsic EvaluationMeasures Machine Translation and/or Summarization, pp. 5764.Snyder, B., & Barzilay, R. (2007). Multiple aspect ranking using good grief algorithm.Proceedings NAACL/HLT, pp. 300307.Titov, I., & McDonald, R. (2008a). joint model text aspect ratings sentiment summarization. Proceedings ACL, pp. 308316.602fiL EARNING OCUMENT-L EVEL EMANTIC P ROPERTIES F REE -T EXT NNOTATIONSTitov, I., & McDonald, R. (2008b). Modeling online reviews multi-grain topic models.Proceedings WWW, pp. 111120.Toutanova, K., & Johnson, M. (2008). Bayesian LDA-based model semi-supervised part-ofspeech tagging. Advances NIPS, pp. 15211528.White, M., Korelsky, T., Cardie, C., Ng, V., Pierce, D., & Wagstaff, K. (2001). Multi-documentsummarization via information extraction. Proceedings HLT, pp. 17.Yeh, A. (2000). accurate tests statistical significance result differences. Proceedings COLING, pp. 947953.Zaenen, A. (2006). Mark-up barking wrong tree. Computational Linguistics, 32(4), 577580.603fiJournal Artificial Intelligence Research 34 (2009) 339-389Submitted 06/08; published 03/09Identification Pleonastic Using WebYifan LiPetr MusilekMarek ReformatLoren Wyard-Scottyifan@ece.ualberta.camusilek@ece.ualberta.careform@ece.ualberta.cawyard@ece.ualberta.caDepartment Electrical Computer EngineeringUniversity AlbertaEdmonton, AB T6G 2V4 CanadaAbstractsignificant minority cases, certain pronouns, especially pronoun it,used without referring specific entity. phenomenon pleonastic pronounusage poses serious problems systems aiming even shallow understanding naturallanguage texts. paper, novel approach proposed identify uses it:extrapositional cases identified using series queries web, cleftcases identified using simple set syntactic rules. system evaluated foursets news articles containing 679 extrapositional cases well 78 cleft constructs.identification results comparable obtained human efforts.1. IntroductionAnaphora resolution, associates word phrase (the anaphor) previouslymentioned entity (the antecedent), active field Natural Language Processing (NLP)research. important role many applications non-trivial level understanding natural language texts desired, notably information extractionmachine translation. illustrate, information extraction system trying keep trackcorporate activities may find dealing news Microsoft today announcedadopting XML default file format next major version MicrosoftOffice software . . . would impossible provide insight Microsoftsintention without associating pronominal anaphors antecedent,Microsoft.Adding already complex problem finding correct antecedent, pronounsalways used fashion shown earlier example. well-knownpronouns, especially it, occur without referring nominal antecedent,antecedent all. Pronouns used without antecedent, often referredpleonastic structural, pose serious problem anaphora resolution systems. Manyanaphora resolution systems underestimate issue choose implement specificmodule handle pleonastic pronouns instead input sanitized manuallyexclude cases. However, high frequency pronoun usage general pleonasticcases particular warrants phenomenon deserves serious treatment.pronoun it, accounts pleonastic pronoun usages, farfrequently used pronouns British National Corpus (BNC). Wall StreetJournal Corpus (WSJ; Marcus, Marcinkiewicz, & Santorini, 1993), upon study2009 AI Access Foundation. rights reserved.fiLi, Musilek, Reformat, & Wyard-Scottbased, accounts 30% personal pronoun usage. percentagecases lacks nominal antecedent also significant: previous studies reportedfigures 16% 50% (Gundel, Hedberg, & Zacharski, 2005) analysisbased upon WSJ corpus results value around 25%, halfpleonastic cases.Applying criteria similar established Gundel et al. (2005), usagegenerally categorized follows. instances analyzed shownitalics; corresponding antecedents, extraposed clauses, clefted constituentsmarked underlining.1. Referential nominal antecedent[0006:002]1 thrift holding company said expects obtain regulatory approvalcomplete transaction year-end.refers thrift holding company.2. Referential clause antecedent[0041:029] board insurance company financial problems,insists made secret it.refers fact person board insurance company.[0102:002-003] Everyone agrees nations old bridges needrepaired replaced. theres disagreement it.it, together do, refers action repairing replacing bridge.3. antecedent Pleonastic(a) Extraposition[0034:020] doesnt take much get burned.infinitive clause get burned extraposed original positionfilled expletive it. equivalent non-extraposed sentence getburned doesnt take much.[0037:034] shame meeting never took place.equivalent non-extraposed sentence meeting never took placeshame.(b) Cleft2[0044:026] disturbing, educators, students, blamedmuch wrongdoing.equivalent non-cleft version disturbing, educators, students,blamed much wrongdoing.1example sentences selected WSJ corpus, locations encoded format [article:sentence].2claim cleft pronouns classified expletive (Gundel, 1977; Hedberg, 2000).Nevertheless, change fact pronouns nominal antecedents; hence cleftsincluded analysis.340fiIdentification Pleonastic Using Web[0591:021] partly reason exchange last week began tradingstock basket product . . .equivalent non-cleft version exchange last week began tradingstock basket product partly reason.(c) Local Situation[0207:037] unpleasant evening . . .category consists instances related weather, time, distance,information local situation. Since texts reviewed study lackinstances subtypes, weather time cases discussed.4. Idiomatic[0010:010] governor couldnt make it, lieutenant governor welcomedspecial guests.paper focuses pleonastic cases (the third category), subclass carriesunique syntactic and/or semantic signatures. idiomatic category, consistingnon-anaphoric cases well, less coherent identification much subjectivenature, making less attractive target.paper organized follows: Section 2 provides brief survey related worktoward classification identification pleonastic it; Section 3 proposesweb-based approach identification pleonastic it; Section 4 demonstrates proposedmethod case study; Section 5 follows evaluation; finally, Section 6 discussesfindings presents ideas future work.2. Previous WorkEvans (2001) pointed out, usage covered serious surveys Englishgrammar, (e.g. Sinclair, 1995) also provide classifications based semanticcategories. recent study, Gundel et al. (2005) classify third-person personal pronounsfollowing comprehensive hierarchy:Noun phrase (NP) antecedentInferrableNon-NP antecedentFactSituationPropositionReasonActivityEventFull cleftAtmosphericTruncated cleftpleonasticPleonasticFull extrapositionTruncated extrapositionIdiomExophoricIndeterminate341fiLi, Musilek, Reformat, & Wyard-ScottWithout going details category, apparent lengthlist phenomenon pleonastic it, generally pronouns without explicitnominal antecedents, painstakingly studied linguists. However, despiteidentified one open issues anaphora resolution (Mitkov, 2001), work automaticidentification pleonastic relatively scarce. date, existing studies area fallone two categories: one wherein rule-based approach used, usingmachine-learning approach.2.1 Rule-based ApproachesPaice Husk (1987) together Lappin Leass (1994) provide examples rulebased systems make use predefined syntactic patterns word lists. PaiceHusk approach employs bracketing patterns . . . . . . meetsyntactic restrictions extraposition cleft. matched portions sentencesevaluated rules represented word lists. example, . . . ruleprescribes one task status words, good bad, must present amidconstruct. order reduce false positives, general restrictions applied sentencefeatures construct length intervening punctuation.Lappin Leasss (1994) approach employs set detailed rulesModaladj Cogv-ed S, Modaladj Cogv predefinedlists modal adjectives (e.g. good useful ) cognitive verbs (e.g. think believe),respectively. Compared Paice Husks (1987) approach, method muchrestrictive, especially rigidly-specified grammatical constraints. example,clear original Lappin Leass paper whether system would ablerecognize sentences [0146:014] isnt clear, however, whether . . . despite claimsystem takes syntactic variants consideration.Lappin Leasss (1994) approach part larger system, evaluationprovided. Paice Husk (1987) approach, hand, evaluates impressively.accuracy 93.9% determining pleonastic constructs data usedrule development, without using part-of-speech tagging parsing.rule-based systems rely patterns represent syntactic constraints wordlists represent semantic constraints. makes relatively easy implementmaintain. However, features also make less scalable challengedlarge unfamiliar corpora, accuracies deteriorate. example, Paice Husk(1987) noticed nearly 10% decrease accuracy rules developed using one subsetcorpus applied another subset without modifications. Boyd, Gegg-Harrison,Byron (2005) also observed significant performance penalty approachapplied different corpus. words, rule-based systems gooddesigned be. Denber (1998) suggested using WordNet (Fellbaum, 1998) extendword lists, doubtful helpful would considering enormous numberpossible words included existing lists number inapplicable wordsidentified approach.342fiIdentification Pleonastic Using Web2.2 Machine-learning ApproachesRecent years seen shift toward machine-learning approaches, shed new lightissue. Studies Evans (2001, 2000) Boyd et al. (2005) examples class.systems employ memory-based learning grammatical feature vectors; Boyd et al.sapproach also includes decision tree algorithm produces less ideal results.attempt place uses seven categories, including pleonastic nominal anaphoricamong others, Evans uses 35 features encode information position/proximity,lemmas, part-of-speech, related pronoun components interest,words noun phrases, sentence. Evans reported 73.38% precision69.25% recall binary classification pleonastic cases, overall binary classificationaccuracy 71.48%. later study featuring MARS3 , fully automatic pronoun resolutionsystem employs approach, Mitkov, Evans, Orasan (2002) reportedsignificantly higher binary classification accuracy 85.54% approach appliedtechnical manuals.Boyd et al.s (2005) approach targets pleonastic alone. uses 25 features,concern lengths specific syntactic structures; also included part-of-speechinformation lemmas verbs. study reports overall precision 82% recall71%, and, specifically, recalls extrapositional cleft constructs 81%45%, respectively.addition, Clemente, Torisawa, Satou (2004) used support vector machinesfeature-set similar proposed Evans (2001) analyze biological medical texts,reported overall accuracy 92.7% higher memory-basedlearning implementation. Ng Cardie (2002) built decision tree binary anaphoricityclassification types noun phrases (including pronouns) using C4.5 inductionalgorithm. Ng Cardie reported overall accuracies 86.1% 84.0% MUC-6MUC-7 data sets. Categorical results, however, reported possibledetermine systems performance pronouns. Using automatically induced rules,Muller (2006) reported overall accuracy 79.6% detecting non-referentialspoken dialogs. inter-annotator agreement study conducted paper indicatesdifficult even humans classify instances spoken dialogs. findingsupported experiences.Machine-learning approaches able partly circumvent restrictions imposedfixed word lists rigid grammatical patterns learning. However, advantagealso comes price training required initial development phasedifferent corpora re-training preferable since lemmas part feature sets. Sinceexisting approaches fall within area supervised learning (i.e. training data needmanually classified), limited number lemmas gather training maylead degraded performance unfamiliar circumstances. Moreover, features usedlearning unable reliably capture subtleties original sentences, especially considering non-technical documents. example, quantitative featuresfrequently used machine-learning approaches, position distance, become lessreliable sentences contain large number adjuncts. Additionally, meaningslemmas often domain-dependent vary local structural lexical3Available online http://clg.wlv.ac.uk/demos/MARS/343fiLi, Musilek, Reformat, & Wyard-Scottenvironment nuances cannot captured lemma features alone. short,machine-learning approaches generally deliver better performance classifyingrule-based counterparts do, inherent problems.3. Web Based Approachsyntactic patterns semantics various clause constituents play important rolesdetermining third-person personal pronoun pleonastic. role grammar quiteobvious since extrapositions clefts must follow grammatical patternsdefined. example, commonly seen type it-extraposition followspattern:+ copula + status + subordinate clause[0089:017]easysee ancient art ropes.contrast, role semantics plays little obscure one sits startsdream exceptions (Paice & Husk, 1987) analogous [0074:005] . . . takenmeasures continue shipments work stoppage. vis-a-vis [0367:044] . . . didnttake rocket scientist change road bike mountain bike . . . , referentialpleonastic cases share syntactic structure. Despite less overt role, failureprocess semantic information result severe degradation performance.observation supported word-list-based systems dramatic decay accuracyconfronted text obtained word lists from.Like every classification system, proposed system strives cover many casespossible time perform classification accurately possible. achievethis, attempts make good use syntactic semantic information embeddedsentences. set relaxed yet highly relevant syntactic patterns first appliedinput text filter syntactically inviable cases. Unlike matching routinesprevious approaches, process avoids detailed specification syntactic patterns. Instead,tries include every piece text containing construct possible interest. Differentlevels semantic examinations performed subtype pleonastic constructs.reasons discussed later Section 3.2.2, semantic analysis performed clefts.WordNet-based analysis used identify weather/time cases amongsamples examined systems development stage, cases pertaining classrelatively uniform manner expression. complex populous class,extrapositions, candidates subjected series tests performed queriesweb. Results queries provide direct evidence specific configurationclause constituents generally used.reason corpus-based approach chosen versus applying manually constructed knowledge sources, word list WordNet, fourfold:1. Manually constructed knowledge sources, regardless comprehensive are,contain small portion general world knowledge. particular settingsstudy, general world knowledge used making judgementswords allowed serve matrix verb extraposition, evensubtle, specific sense word permitted.344fiIdentification Pleonastic Using Web2. Manually compiled knowledge sources subject specific manners organizationmay satisfy systems needs. Taking WordNet example, identifieslarge number various relationships among entities, information mainlyorganized along axes synonyms, hypernyms (kind-of relationship), holonyms(part-of relationship) etc., surroundings particular wordinterest study.3. Natural languages evolving quickly. Taking English example, year newwords incorporated language4 rules grammarimmune changes either. Using large frequently-updated corpusweb allows system automatically adapt changes language.4. importantly, corpora collect empirical evidence language usage.sample size large enough, case web, statistics specificconstruct generally used corpora employed indicator speakersintention.proposed approach also inspired Hearsts (1992) work mining semanticrelationships using text patterns, many quests followed direction (Berland & Charniak, 1999; Poesio, Ishikawa, im Walde, & Vieira, 2002; Markert,Nissim, & Modjeska, 2003; Cimiano, Schmidt-Thieme, Pivk, & Staab, 2005). Unlikeinvestigations focus semantic relationship among noun phrases, pleonasticpronoun identification problem mandates complex queries built accordingoriginal sentences. However, binary nature problem also makes simplerapply comparative analysis results multiple queries, which, turn, leads betterimmunity noise.Figure 1 illustrates general work flow proposed system. sentence firstpreprocessed obtain dependency tree part-of-speech tags, passedsyntactic filtering component determine whether minimum grammatical requirements pleonastic constructs met. also syntactic filteringprocess clefts weather/time expressions identified using syntactic cuesWordNet respectively. candidate extrapositions thereafter used instantiatevarious queries search engines; results returned queries serve parametersfinal decision-making mechanism.3.1 Preprocessingpreprocessing component transforms syntactic information embedded naturallanguage texts machine-understandable structures. preprocessing stage,word assigned part-of-speech tag, whole sentence parsed using dependency grammar (DG) parser. simplicitys sake, current system designed useWSJ corpus, already tagged parsed context-free grammar (CFG). headpercolation table similar proposed Collins (1999) used obtain head component phrase. rest phrase constituents rearranged4Metcalf Barnhart (1999) compiled chronicle many important additions vocabularyAmerican English.345fiLi, Musilek, Reformat, & Wyard-ScottFigure 1: Illustration system work flow broken three processing stages preprocessing, syntactic filtering, web-based analysis.head component form dependency tree using procedure detailed Xia Palmer(2001). Figure 2 illustrates syntactic structure sentence WSJ corpus.original CFG parse tree derived dependency structure shown side-by-side.Head entities underlined CFG diagram circled DG diagram.Figure 2: Illustration sentences syntactic structure, annotated WSJcorpus (left) head percolation (right).346fiIdentification Pleonastic Using Webshown Figure 2, function tags (e.g. SBJ, TMP, CLR) tracing informationpresent context-free parse tree ported dependency tree.real-world parsers usually produce tags. Except deliberate omission,parse trees contain essentially information, presented different manners.study, dependency structure preferred popular phrase structuremainly explicit marking head components complementing/modifying relationships among various components. feature helpfulinstantiating search-engine queries.3.2 Syntactic Filteringsyntactic filtering process determines whether clause meets grammatical requirements extraposition cleft construct matching clause respectivesyntactic patterns.3.2.1 ExtrapositionsIt-extrapositions occur clause dislocated ordinary position replacedit. it-extraposition usually follows pattern:matrix clausez}|noun phraseadjective phrase+prepositional phraseitsubject +verb phrase|{zmatrix verb phrase{+ extraposed clause}(1)pattern summarizes general characteristics subject it-extrapositions,pronoun assumes subject position. matrix verb (the verb following it)main copula be, serves equate associate subject ensuing logicalpredicate, must followed either noun phrase, adjective phrase, prepositionalphrase.5 special requirement matrix verb phrase otherwise. Similarly,almost restriction placed upon extraposed clause except full clauseeither introduced without complementizer (e.g. [0037:034] shamemeeting never took place.) led that, whether, if, one wh-adverbs (e.g.how, why, when, etc.). constraints developed generalizing small portionWSJ corpus largely accordance patterns identified Kaltenbock(2005). Compared patterns proposed Paice Husk (1987), also covercases . . . , . . . . . . whether , allow broader rangecandidates considering sentences explicitly marked (such [0037:034]).configuration covers sentences as:5copula verbs receive treatment. arrangement made accommodatecases verbs seem appear immediately followed extraposed clause.347fiLi, Musilek, Reformat, & Wyard-Scott[0529:009] Since cost transporting gas important producers ability sell it, helps input access transportationcompanies.[0037:034] shame meeting never took place.[0360:036] insulting demeaning say scientists needed new crisesgenerate new grants contracts . . .6[0336:019] wont clear months whether price increase stick.Except case last sentence, constructs generally overlookedprevious rule-based approaches identified Section 2.1. last sample sentenceillustrates, plus sign (+) pattern serves indicate forthcoming componentrather suggest two immediately adjacent components.common grammatical variants pattern also recognized system,including questions (both direct indirect), inverted sentences, parenthetical expressions (Paice & Husk, 1987). expands patterns coverage sentencesas:[0772:006] remembered hard outsider become accepted . . .[0562:015] sooner vans hit road morning, easierus fulfill obligation.[0239:009] Americans seems followed Malcolm Forbess hot-air leadtaken ballooning heady way.Aside subject matrix clause, extrapositional also appearobject position. system described captures three flavors object extraposition.first type consists instances followed object complement:[0044:014] Mrs. Yeargin fired prosecuted unusual SouthCarolina law makes crime breach test security.case system inserts virtual copula object objectcomplement (a crime), making construct applicable pattern subject extraposition. example, underlined part prior example translates crimebreach test security.two kinds object extraposition relatively rare:Object verb (without object complement)[0114:007] Speculation company asking $100 million operation said losing $20 million year . . .Object preposition[1286:054] see kids dont play truant . . .cases cannot analyzed within framework subject extraposition thusmust approached different pattern:verb + [preposition] object + full clause(2)6Neither insulting demeaning Paice Husks (1987) list task status words thereforecannot activate . . . pattern.348fiIdentification Pleonastic Using Webcurrent system requires full clauses start complementizer that.restriction, however, included simplify implementation. Although object expositions common clauses led that, full clauses without leadingcomplementizer also acceptable.According Kaltenbocks (2005) analysis special cases noun phrasesappear extraposed component, amazing number theologianssided Hitler. noted noun phrases semantically close subordinateinterrogative clauses therefore considered marginal case extraposition. However, cases found corpus annotation processconsequently excluded study.3.2.2 CleftIt-clefts governed slightly restricted grammatical pattern. Following Hedberg(1990), it-clefts expressed follows:subject + copula + clefted constituent + cleft clause(3)cleft clause must finite (i.e. full clause relative clause); clefted constituents restricted either noun phrases, clauses, prepositional phrases.7 Examplessentences meeting constraints include:[0296:029] total relationship important.[0267:030] also law school Mr. OKicki first wifefirst seven daughters.[0121:048] market goes down, figure paper profits Im losing.addition, another non-canonical probably even marginal case also identifiedcleft:[0296:037] really understand Filipinos feel passionatelyinvolved father figure want dispose yetneed.Text following structure sample, wh-adverb immediately precedes it,captured using syntactic pattern appending virtual prepositional phrasematrix copula (e.g. reason), missing information alreadygiven.examples represents possible syntactic construct it-clefts.difficult tell second third cases apart respective extrapositionalcounterparts, even difficult differentiate first case ordinary copulasentence restrictive relative clause (RRC). example, following sentence,[0062:012] precisely kind product thats created municipal landfillmonster, editors wrote.slightly modified version,[0062:012] kind product thats created municipal landfill monster, editors wrote.7Adjective adverb phrases also possible relatively less frequent excludedanalysis.349fiLi, Musilek, Reformat, & Wyard-Scottsimilar construction. However, latter considered cleft constructfirst RRC construct. make things worse, pointed many (e.g. Boydet al., 2005, p.3, example 5), sometimes impossible make distinction withoutresorting context sentence.Fortunately, majority cases syntactic features, especially cleftedconstituent, provide useful cues. it-cleft construct, cleft clause constitute head-modifier relationship clefted constituent, instead forms existential exhaustive presupposition8 (Davidse, 2000; Hedberg, 2000; Lambrecht, 2001).example, figure paper profits Im losing. implies context something (and one thing) speaker going lose, associates paperprofits it. significant difference semantics often leaves visible traces syntactic layer, which, applicability proper nouns clefted constituents,obvious. Others less obvious. system utilizes following grammatical cuesdeciding construct it-cleft9 :clefted constituent:Proper nouns10 pronouns, cannot modified RRC;Common nouns without determiner, generally refer kinds11 ;Plurals, violate number agreement;Noun phrases grounded demonstratives possessives,modified RRCs, unambiguously identify instances, making unnecessary cases employ RRC;Noun phrases grounded definite determiner the, modified-preposition whose object also noun phrase groundedplural. constructs usually sufficient introducing uniquely identifiable entities (through association), thus precluding need additional RRCmodifiers. words kind, sort, likes considered exceptionsrule;Adverbial constructs usually appear complements. example,phrases denoting location (here, etc.) specific time (today, yesterdayetc.), clause led when;Full clauses, gerunds, infinitives.subordinate clause:constructs appear awkward used RRC. example, one wouldgenerally avoid using sentences place dirty,8applies canonical clefts, include class represented [0267:030].construct considered it-cleft conditions met.10exceptional cases proper names used additional determiners RRC modifiers, John TV last night, c.f. Sloats (1969) account.11validity assertion debate (Krifka, 2003). Nevertheless, considering particularsyntactic setting discussion, highly unlikely bare noun phrases used denote specificinstances.9350fiIdentification Pleonastic Using Webbetter alternatives. current implementation two patterns consideredinappropriate RRCs, especially syntactic settings described Equation 3: A) subordinate verb phrase consists copula verbadjective; B) subordinate verb phrase consists elementverb itself.Combined:clefted constituent prepositional phrase subordinate clausefull clause, case [0267:030], construct classifiedcleft12 .rules based heuristics may exceptions, making lessideal guidelines. Moreover, mentioned earlier, cleft cases cannot toldapart RRCs grammatical means. However, experiments show rulesrelatively accurate provide appropriate coverage, least WSJ corpus.3.2.3 Additional FiltersAside patterns described earlier sections, additional filters installedeliminate semantically unfit constructs therefore reducing number tripssearch engines. filtering rules follows:clause identified subordinate clause subsequently processedextraposition cleft, number commas, dashes colons clauseeither zero one, rule adopted Paice Husks(1987) proposal.Except copula be, sentences matrix verbs appearing perfect tenseconsidered either extraposition cleft.subject multiple verb phrases, sentence consideredeither extraposition cleft.Sentences noun phrase matrix logical predicate together subordinaterelative clause considered extraposition.Sentences matrix verb preceded modal auxiliaries could wouldsubordinate clause led wh-adverb considered extraposition.example, [0013:017] . . . could complete purchase next summer bidone approved . . . considered extraposition.Except first, rules optional deactivated case introducefalse-negatives.3.3 Using Web Corpusfirst question regarding using web corpus whether regardedcorpus all. Kilgarriff Grefenstette (2003) pointed out, following definition12case cleft, chances extraposition. assumption, therefore,affect overall binary classification.351fiLi, Musilek, Reformat, & Wyard-Scottcorpus-hood corpus collection texts considered object languageliterary study, answer yes. fundamental problem resolved, remainsfind whether web effective tool NLP tasks.corpus, web far well-balanced error-free. However,one feature corpus even remotely comparable size. oneknows exactly big is, major search engines already indexes billionspages. Indeed, web large sometimes misspelled word yield tensthousands results (try word neglectible). sends mixed signal usingweb corpus: good side, even relatively infrequent terms yield sizable results;bad side, web introduces much noise manually-compiled corpora do.Markert Nissims (2005) recent study evaluating different knowledge sourcesanaphora resolution, web-based method achieves far higher recall ratioBNC- WordNet-based, time yielding slightly lower precision.Similar things said webs diverse unbalanced composition,means used universal knowledge source one manageget overwhelmed non-domain-specific information.said, still hard overstate benefits web offers.largest collection electronic texts natural language, hosts good portiongeneral world knowledge, also stores information using syntaxdefines language. addition, devoid systematic noise introducedmanually-constructed knowledge sources compilation process (e.g. failureinclude less frequent items inflexible ways information organization). Overall, webstatistically reliable instrument analyzing various semantic relationships storednatural languages means examples.also suggested Kilgarriff (2007) many others, technically difficultexploit web use local corpus often dangerous rely solelystatistics provided commercial search engines. mainly due factcommercial search engines designed corpus research. Worse, designgoals even impede uses. example, search engines skew order results usingnumber different factors order provide users best results. Combinedfact return results certain thresholds, making essentiallyimpossible get unbiased results. annoyances include unreliable result counts, lackadvanced search features13 , unwillingness provide unrestricted accessAPIs. new search engine specifically designed corpus research available,seems work around restrictions live rest.3.4 Design Search Engine Queriesdiscussed previous sections, it-extrapositions cannot reliably identified using syntactic signatures alone combination synthetic knowledge bases. overcomeartificial limitations imposed knowledge sources, proposed system resorts webnecessary semantic information.13example, wildcard () feature Google, could immensely useful query construction, longer restricts results single words since 2003; Yahoos ability support alternate wordswithin quoted texts limited, MSN offer feature all.352fiIdentification Pleonastic Using Websystem employs three sets query patterns: what-cleft, comparative expletive test, missing-object construction. set provides unique perspectivesentence question. what-cleft pattern designed find sentence investigation valid what-cleft counterpart. Since it-extrapositions what-cleftssyntactically compatible (as shown Section 3.4.1) valid readings usuallyobtained transformations one construct other, validity what-cleftindicative whether original sentence extrapositional. comparativeexpletive test patterns straightforward directly check whether instancereplaced entities cannot used expletively contextextrapositional it. alternate construct invalid, original sentencedetermined expletive. third set patterns supplemental. intendedidentifying relatively rare phenomenon missing-object construction,may reliably handled previous pattern sets.Designing appropriate query patterns important step efforts exploitlarge corpora knowledge sources. complex queries web, especiallyimportant suppress unwanted uses certain components, could result different word senses, different sentence configuration, speakers imperfect commandlanguage. example, query shame could return valid extrapositional construct RRC shame perpetuated life;query right could return valid what-clefts sentencesought right . . . study employs three different approachescurb unwanted results:first important measure comparative analysis pairs similarlyconstructed queries sent search engine ratios result countsused decision. method effective problems caused differentsentence configuration bad language usage, since generally neither contributefraction results large enough significantly affect ratio. method alsoprovides normalized view web interest studyexactly frequently specific construct used, whether likelycarry specific semantic meaning used.second measure use stubs query patterns, detailed followingsections. Stubs help ensure outcomes queries syntactically semantically similar original sentences partly resolve problems causedword sense difference.Finally, infeasible use comparative analysis, part query resultsvalidated obtain estimated number valid results.3.4.1 Query Pattern I: What-cleftfirst query pattern,+ verb phrase + copula + stub(4)what-(pseudo-)cleft construct encompasses matrix-level information foundit-extraposition. pattern obtained using three-step transformation illustrated353fiLi, Musilek, Reformat, & Wyard-Scottbelow:1)2)3)+ verb phrase + clauseeasysee ancient art ropes. [0089:017]clause+verb phrasesee ancient art ropes easy.+ verb phrase + copula + clauseeasysee ancient art ropes.+ verb phrase + copula + stubeasy(5)Step 1 transforms original sentence (or clause) corresponding non-extrapositionform removing pronoun restoring information canonical subjectverb-complement order. example, clause see . . . considered realsubject moved back canonical position. non-extraposition form subsequently converted step 2 what-cleft highlights verb phrase. Finally,step 3, subordinate clause reduced stub enhance patterns coverage.choice stub depends structure original subordinate clause: usedoriginal subordinate clause infinitive, gerund, . . . infinitive construct14 .rest cases, original complementizer, that, casecomplementizer, used stub. use stub pattern imposes syntacticconstraint, addition ones prescribed pronoun copula is,demands subordinate clause present query results. choice stubs also reflects,certain degree, semantics original texts therefore seen weaksemantic constraint.examples what-cleft transformation:[0059:014] remains unclear whether bond issue rolled over.remains unclear whether[0037:034] shame meeting never took place.shamewhat-cleft pattern identifies whether matrix verb phrase capablefunctioning constituent it-extraposition. Information subordinate clausesdiscarded construct used relatively infrequently adding extra restrictionsquery prohibit yielding results many cases.it-extraposition constructs appears . . . said . . .valid non-extraposition counterpart, what-cleft versions often bearcertain degrees validity queries instantiated pattern often yield results(albeit many) reputable sources. also worth noting although inputoutput constructs transformation syntactically compatible,necessarily equivalent terms givenness (whether information one sentence14According Hamawand (2003), . . . infinitive construct carries distinct semantics; reducinginfinitive alone changes function. However, exceptional cases, find reductiongenerally acceptable. i.e. lost semantics affect judgment expletiveness.354fiIdentification Pleonastic Using Webentailed previous discourse). Kaltenbock (2005) noted percentageextrapositional constructs carrying new information varies greatly dependingcategory text. contrast, what-cleft generally expresses new informationsubordinate clause. presupposed contents two constructs different, too.What-clefts, according Gundel (1977), it-clefts derived,existential exhaustive presuppositions carried it-cleft counterparts.hand, it-extrapositions, semantically identical correspondingnon-extrapositions, lack presuppositions or, most, imply weaker strength(Geurts & van der Sandt, 2004). discrepancies hint derived what-cleftstronger expression original extraposition, may queriesinstantiated pattern tend yield considerably less results.Another potential problem pattern omission subordinate verb,occasionally leads false positives. example, differentiatehelps input access transportation companies helps expandhorizon. deficiency accommodated additional query patterns.3.4.2 Query Pattern II: Comparative Expletiveness Testsecond group patterns provides simplified account original textdifferent flavors. execution, results individual queries compared assessexpletiveness subject pronoun. set patterns takes following generalform:pronoun + verb phrase + simplified extraposed clause(6)difference among individual patterns lies choice matrix clause subjectpronoun: it, which, who, this, he. patterns instantiated submittedsearch engine, number hits obtained version far outnumberversions combined original text it-extraposition; otherwisenumber hits least comparable. behavior reflects expletive naturepronoun it-extraposition, renders sentence invalid replacedpronouns pleonastic use.simplified extraposed clause take different forms depending originalstructure:Original Structureinfinitive (to meet you). . . infinitive15 (for see document)gerund (meeting you)full clause led complementizer(it shame meeting never took place)full clause without complementizer(it shame meeting never took place)Simplifiedinfinitive + stubinfinitive + stubgerund + stubcomplementizer + stub+ stubTable 1: Simplification extraposed clause15. . . passive-infinitive transformed active voice (e.g. products sold sellproducts).355fiLi, Musilek, Reformat, & Wyard-ScottSimilar case Pattern I, stub used syntactic constraintsemantic cue. Depending type search engine, stub either the,widely used determiner, combination various determiners, personalpronouns possessive pronouns, indicate subsequent noun phrase.case infinitive construct involves subordinate clause led wh-adverb that,complementizer used stub. arrangement guarantees results returnedquery conform original text syntactically semantically. null valueused stubs object position original text lacks nominal object.illustrate rules transformation, consider following sentence:[0044:010] teacher said OK use notes test,said.relevant part sentence is:+ verb phrase + clauseOKuse notes testApplying clause simplification rules, first query obtained:+ verb phrase + simplified clauseOKusesecond query generated simply replacing pronoun alternativepronoun:alternative pronoun + verb phrase + simplified clauseOKuseGoogle reports 94,200 hits query, one page found using alternativequery. Since pronoun used much broader context, replacingalone hardly makes balanced comparison. Instead, combination which, who, this,used, illustrated following examples:[0044:010] teacher said OK use notes test,said.)(ok usewhich/who/this/he[0089:017]( easy see) ancient art ropes.easy seewhich/who/this/hespecial set patterns used object extrapositions16 accommodate uniquesyntactic construct:verb + [preposition] pronoun + + stub(7)Stubs chosen according rules main pattern set, however onealternative pronoun used.16Instances containing object complements treated framework subject extrapositionincluded here.356fiIdentification Pleonastic Using Web[0114:007] Speculation company asking $100 millionoperationsaid)to losing $20 million year . . .(3.4.3 Query Pattern III: Missing-object ConstructionOne search engine annoyance ignore punctuation marks. means onesearch text matches specific pattern string, sentencesend pattern string. stubs used Pattern II generally helpful excluding sentences semantically incompatible original searchresults. However, circumstances stub attached queries (wherequery results ideally consist sentences end query string),search engine may produce results needed. Sentences conforming pattern+ copula + missing-object construction, (referring book) easyread, present one situation. unique construction specialtreatment needed missing-object construction usually it-extrapositioncounterpart object present, example easy read book . Sincemissing-object constructions virtually (only shorter) extrapositional counterparts, good chance identified extrapositions.following additional examples missing-object construction:[0290:025] non-violent civil disobedience centerpiece, ratherlawful demonstration may attract crime, difficultjustify.[0018:024-025] price new shares set. Instead, companiesleave marketplace decide.[0111:005] declined elaborate, say, seemed rightthing minute.Two sets patterns proposed17 identify likes foregoing examples.first pattern, compound adjective test, inspired Nannis (1980) study consideringeasy-type adjective followed infinitive (also commonly termed tough construction)single complex adjective. pattern takes formstub + adjectivebase -to -verb(8)stub, serving limit outcome query noun phrases, takes combination determiners a/an alone; original adjective also converted base formadjectivebase comparative superlative form. Expanding Nannis originalclaims, pattern used evaluate adjectives18 well constructs furnished. . . infinitive complements. following example demonstrates patternsusage:17Preliminary experiments confirmed effectiveness patterns. However, due sparsenesssamples belonging class, included reported evaluation.18based observation compounds ready-to-fly (referring model aircrafts)exist, hard obtain complete enumeration easy-type adjectives.357fiLi, Musilek, Reformat, & Wyard-Scott[0258:024] machine uses single processor, makes easier programcompeting machines using several processors.easy-to-programsecond set consists two patterns used comparative analysisgeneral profile:+ verbgerund + stub(9)verbgerund gerund form original infinitive. complementizerused sole purpose ensuring verbgerund appears subject subordinateclause sentences returned queries. words, phrases computerprogramming pattern matching excluded. first pattern, stubcombination prepositions (currently chosen); second one,combination determiners alone used. example:[0258:024] machine uses single processor, makes easier programcompeting machinesusing)several processors.(in|fromprogrammingset patterns tests transitivity verb semantic environment similaroriginal sentence. verb used transitively often, patterndeterminers yield results, vice versa. supported precedingsample sentences, usually-transitive verb used without object19 good indicatormissing-object construction sentence diagnosed referential.3.4.4 Query InstantiationPatterns must instantiated information found original sentencessubmitted search engine. Considering general design principles system,advisable instantiate patterns original texts significantly reducesqueries coverage. Instead, object matrix verb phrase truncatedmatrix verb expanded order obtain desired level coverage.truncation process provides different renditions based structure originalobject:Adjective phrases:head word used. head word modified too,modifier also retained order better support . . . constructmaintain compatibility semantics original text.Common noun phrases:possessive ending/pronoun, -preposition:phrase replaced $PRPS$ plus head word. $PRPS$ either listpossessive pronouns one widely used, depending calibersearch engine used. example, location expanded || | | | | location.19omitted object preposition (e.g. difficult account for.) effect,identifiable syntactic means alone.358fiIdentification Pleonastic Using Webdeterminers:phrase replaced choice $DTA$, $DTTS$, $DTTP$, combination$DTA$ $DTTS$, plus head word. $DTA$ list (or one the)general determiners (i.e. a, an, etc.). $DTTS$ refers combinationdefinite article singular demonstratives that. $DTTP$plural counterpart $DTTS$. choice based configurationoriginal text maintain semantic compatibility.without determiner:head word used.Proper nouns pronouns:phrase replaced $PRP$, list (or one the) personal pronouns.Prepositional phrases:object preposition truncated recursive operation.Numeric values:phrase lot used instead.Matrix verbs expanded include simple past tense third person singular present form aid WordNet generic patterns.applicable, particles also remain attached verb.Generally speaking, truncation expansion good ways boosting patternscoverage. However, current procedures truncation still crude, especiallyhandling complex phrases. example, phrase reckless course action([0198:011]) yields $PRPS$ course, results total loss original semantics.enhancements truncation process may improve performanceimprovement likely limited due endless possibilities language usageconstraints imposed search engines.Aside truncating expanding original texts, stepped-down versionPattern II, denoted Pattern II0 , also provided enhance systems coverage.current scheme simply replace extraposed clause new stuboriginal extraposed clause infinitive, . . . infinitive, gerund construct.example,[0089:017]( easy see) ancient art ropes.easywhich/who/this/hesituations, downgraded version applied.3.5 Binary Classification It-extrapositionFive factors taken consideration determining whether sentence questionit-extraposition:Estimated popularity what-cleft construct (query Pattern I)denotedW = nw vw359fiLi, Musilek, Reformat, & Wyard-Scottnw number results reported search engine, vwpercentage valid instances within first batch snippets (usually 10, dependingsearch engine service) returned query. Validation performedcase-sensitive regular expression derived original query. Since whatcleft pattern capitalized beginning, regular expression looksinstances appearing beginning sentence. particularly importantvalidate results what-cleft queries search engines produceresults based interpretation original query. example, Googlereturns pages containing Whats found query found that,might helpful counterproductive purposestudy.Result comparative expletiveness test (query Pattern II)denotednXr=nitnit number results obtained original version query,nX total number results produced replacing pronounswho. smaller ratio r is, likely sentenceinvestigated extraposition. Extrapositional sentences usually producer value 0.1 less. versions query yield insufficient results(max(nit , nX ) < Nmin ), r takes value Rscarce = 1000. Since it-extrapositionsrelatively rare, better assume sentence extrapositionalinsufficient data judge otherwise. case nX sufficientversion query produces result (nX >= Nmin nit = 0), r takesvalue Rzero = 100. Values Rzero Rscarce large numbers chosen arbitrarily,mainly visualization purposes. words Rzero Rscarce hintsentence probably extrapositional, however neither indicates degreelikelihood.Result stepped-downcomparative expletiveness testn000denoted r0 = nX0 , nit nX number results returnedversion alternate version stepped-down queries (c.f. Section 3.4.4,Page 359). stepped-down queries simplified versions queries usedcalculate r. Due simplification, r0 usually sensitive extrapositions.However queries stepped-down versions, case original queriesreused, causing r0 = r. Similar way r defined, r0 also takes valuesRscarce Rzero special situations.Synthesized expletivenessnew variable R defined based values r, nit , nX , r0 :(R=r, max(nit , nX ) Nmin ,r0 , max(nit , nX ) < Nmin .original queries yield enough results, R takes value r since originalqueries better preserve sentence context generally accurate. However,360fiIdentification Pleonastic Using Weboriginal queries fail, system resorts back-up method usingstepped-down queries bases judgement results instead. Overall, Rseen synthesized indicator subject pronoun generally usedsimilar syntactic semantic setting original sentence.Syntactic structure sentencedenoted S, binary variable indicating sentence investigation belongssyntactic construct prone generating false-positives. averagewhat-cleft queries yield fewer results less reliable since cannotused provide comparative ratios. However, still useful last linedefence curb impacts certain syntactic constructs repeatedly causecomparative expletive tests produce false-positives. Currently one constructidentified verb infinitive construct, helps inputeveryone expects post results tomorrow . Therefore,(S=TRUE, sentence matches verb infinitive,FALSE, otherwise.final binary classification it-extraposition, E, defined follows:(E=((R < Rexp ) (W > Nmin )), = TRUE,(R < Rexp ),= FALSE.(10)Nmin Rexp , set 10 0.15 respectively study, threshold constantschosen based upon empirical observations. words, system recognizes instance extrapositional unlikely (by comparing R Rexp ) alternativepronoun used place syntactic semantic settings. verbinfinitive constructs, also required sentence viable what-cleft variant(by comparing W Nmin ).worth noting todays major commercial search engines return exactnumber results query rather estimates. negative effectsomewhat mitigated basing final decision ratios instead absolute numbers.4. Case Studybetter illustrate system work flow, two sample sentences selected WSJcorpus taken whole process. first sample, [0231:015], classifiedit-extraposition; other, [0331:033] (with preceding sentence providing context),referential case nominal antecedent. particulars implementationalso discussed here.[0231:015] fund manager life-insurance company said three factors makedifficult read market direction.[0331:032-033] recent report classifies stock hold. appearssort hold one makes heading door.361fiLi, Musilek, Reformat, & Wyard-Scott4.1 Syntactic FilteringFirst, syntactic structures sentence identified dependencies amongconstituents established, shown Figures 3 4.Figure 3: Syntactic structure [0231:015] (fragment)Figure 4: Syntactic structure [0331:033] (fragment). Readings B, indicatedDG parse tree, discussed text.362fiIdentification Pleonastic Using Websample sentence [0231:015], expletive appears object verb makesfollowed object complement difficult, therefore virtual copula (tagged VBX)created dependency tree order treat framework subjectit-extrapositions. [0331:033], two different readings produced one assumingappears matrix verb (reading A, c.f. Figure 4), taking (readingB). accomplished drilling chain verbs beginning parentverb node. top chain, system starts recursive processfind verbs infinitives directly attached current node movesnewly found node. process interrupted current verb node furnishedelements verbal adverbial complements/modifiers.filtering process, various components sentences identified, listedTable 2.Sentence0231:0150331:0330331:033ReadingBMatrixVerbObjectdifficultappearssortConjunctionSubordinateSubject VerbObjectread directionsortOneTable 2: Component breakdown case study samples4.2 Pattern InstantiationUsing components identified Table 2, five queries generated reading,listed Tables 3-5. Patterns II0 -it II0 -others refer stepped-down versions(c.f. Section 3.4.4, Page 359) II-it II-others respectively. queries showngenerated specifically Google take advantage features available Google.use alternative search engine Yahoo, component expansions determinerlists turned off, separate queries need prepared individual pronouns.order get accurate results, queries must enclosed double quotessent search engines.PatternII-itII-othersII0 -itII0 -othersQueryis|was|s difficult is|wasis|was|s difficult read the|a|an|no|this|these|their|his|ourwhich|this|who|he is|was|s difficult read the|a|an|no|this|these|their|his|ouris|was|s difficultwhich|this|who|he is|was|s difficultTable 3: Queries [0231:015]363Results106039601536.3 1061.5 105fiLi, Musilek, Reformat, & Wyard-ScottPatternII-itII-othersII0 -itII0 -othersQueryappears|appeared is|wasappears|appeared the|a|an|no|this|these|their|his|ourwhich|this|who|he appears|appeared the|a|an|no|this|these|their|his|ourappears|appearedwhich|this|who|he appears|appearedResults447.5 1043.2 1052.2 1062.6 106Table 4: Queries [0331:033], ReadingPatternII-itII-othersII0 -itII0 -othersQueryis|was|s its|my|our|his|her|their|your sort is|wasis|was|s its|my|our|his|her|their|your sort the|a|an|no|this|these|they|we|he|their|his|ourwhich|this|who|he is|was|s its|my|our|his|her|their|your sortthe|a|an|no|this|these|they|we|he|their|his|ourII-itII-othersResults00000Table 5: Queries [0331:033], Reading B4.3 Query Results Classificationevery reading, number results five queries (nw Pattern I;nit II-it; nX II-others; n0it II0 -it; n0X II0 -others) obtainedsearch engine; first 10 results what-cleft query also validated obtainestimated percentage (vw ) valid constructs. W (= nw vw ), r(= nX /nit ), r0 (= n0X /n0it ),R (choosing either r r0 depending whether max(nit , nX ) 10)calculated accordingly, recorded Table 6.Query[0231:015][0331:033].A[0331:033].Bnw1060440vw70%0%-nit39607.5E40nX1533.2E50n0it6.3E62.2E60n0X1.5E52.6E60W74200r0.044.31000r00.021.21000R0.044.31000Table 6: Query results case study sample sentencesappears suspicious vw set 0 reading [0331:033].A, meansvalid instances found. quick look returned snippets reveals that, indeed, none10 snippets queried contents beginning sentence. Also notereading [0331:033].B, r r0 , consequently R set Rscarce = 1000since query produced enough results.decided Table 2 readings [0231:015] [0331:033].B bearverb infinitive construct, hence = FALSE; [0331:033].A = TRUE.Applying Equation 10 Section 3.5, [0231:015] [0331:033].B, final classification364fiIdentification Pleonastic Using WebE based whether R sufficiently small (R < 0.15). [0331:033].A, systemalso needs check whether what-cleft query returned sufficient valid results (W > 10).final classifications listed Table 7.Sentence[0231:015][0331:033][0331:033]ReadingBW74200FALSETRUEFALSER0.044.31000EreadingYESEYESTable 7: Final binary classification case study sample sentencesSince neither readings [0331:033] classified such, sentence it-extrapositionconstruct.5. Evaluationorder provide comprehensive picture systems performance, twofold assessment used. first evaluation, system exposed sentence collectionassisted development. Accordingly, results obtained evaluation reflect,certain degree, systems optimal performance. second evaluation aims revealing systems performance unfamiliar texts running developed systemrandom dataset drawn rest corpus. Two additional experiments alsoconducted provide estimation systems performance whole corpus.Three performance measures used throughout section: precision, recall,balanced F-measure (van Rijsbergen, 1979). Precision defined ratio correctlyclassified instances specific category (or collection categories) numberinstances identified system belonging category (categories). words,Pprecision calculated P = PT+FP , P F P number true positivesfalse positives respectively. Recall defined ratio correctly classified instancesspecific category (or collection categories) total number instancesPcategory (categories), R = PT+FN , F N denotes number false negatives.Finally, F-measure weighted harmonic mean precision recall used indicatesystems overall performance. precision recall weighted equally, usedRstudy, balanced F-measure defined F = P2P+R.Following Efron Tibshiranis (1993) Bootstrap method, 95% confidence intervalsobtained using 2.5th 97.5th percentiles bootstrap replicatesprovided alongside system performance figures indicate reliability. numberreplicates arbitrarily set B = 9999, much greater commonlysuggested value 1000 (e.g., see Davison & Hinkley, 1997; Efron & Tibshirani, 1993)pleonastic instances sparse. case precision recall value 100%,bootstrap percentile method reports interval 100%-100%, makes little sense.Therefore, situation adjusted Wald interval (Agresti & Coull, 1998) presentedinstead. two systems compared, approximate randomization test (Noreen,1989) similar used Chinchor (1992) performed determine differencestatistical significance. significance level = 0.05 number shuffles R = 9999,chosen arbitrarily, used significance tests performed.365fiLi, Musilek, Reformat, & Wyard-Scott5.1 Development Datasetpurpose study, first 1000 occurrences WSJ corpusmanually annotated authors20 . part set also inspected orderdetermine values constants specified Section 3.5, develop surfacestructure processor. annotation process facilitated custom-designed utilitydisplays sentence within context represented nine-sentence window containingsix immediately preceding sentences, original, two sentences follow.Post-annotation review indicates presentation corpus sentences worked well.Except (less 0.5%) cases, authors found need resort broadercontexts understand sentence; circumstances valid antecedentslocated outside context window antecedent found within it.CategoryNominal AntecedentClause AntecedentExtrapositionCleftWeather/TimeIdiomGrand TotalInstances7566011813918261000Percentage75.60%6.00%11.80%1.30%0.90%1.80%2.60%100.00%Table 8: Profile development dataset according authors annotationTable 8 summarizes distribution instances dataset according authorsconsensus. category labeled consists mostly instances fit wellcategories, e.g. identified nominal antecedent pluralantecedent inferred, well certain confusing instances. twenty-six instances,two might remotely recognized one types interests study:[0101:007] though size loan guarantees approved yesterday significant, recent experience similar program Central Americaindicates could take several years new Polish government fully use aid effectively.[0296:048] comic try pretend theyre still master race.Neither instance identified anaphoric. However, first construct neithervalid non-extraposition version valid what-cleft version, making difficult justifyextraposition, second case considered refer atmospherearoused action detailed when-clause.order assess whether pleonastic categories well-defined abilityordinary language users identify pleonastic instances, two volunteers, native Englishspeakers, invited classify instances development dataset. helpconcentrate pleonastic categories, volunteers required assigninstance one following categories: referential, extraposition, cleft, weather/time,20Annotations published online appendix http://www.ece.ualberta.ca/~musilek/pleo.zip.366fiIdentification Pleonastic Using Webidiom. referential category covers instances nominal antecedentsclause antecedents, well instances inferrable antecedents. Table 9 outlinesannotators performance reference authors consensus. degree agreementannotators, measured kappa coefficient (; Cohen, 1960), also giventable.CategoryPrecisionReferential99.38%Extraposition82.54%Cleft38.46%Weather/Time 66.67%Idiom39.39%Overall Accuracy/Volunteer 1Recall F-measure95.49%88.14%76.92%44.44%72.22%93.50%97.40%85.25%51.28%53.33%50.98%Precision96.38%88.68%72.73%75.00%50.00%Volunteer 2Recall F-measure98.10%79.66%61.54%33.33%61.11%94.20%97.23%83.93%66.67%46.15%55.00%.749.795.369-.005.458.702Except Weather/Time category (p = 0.5619), values statistically significant p <0.0001.Table 9: Performance volunteer annotators development dataset (evaluatedusing authors annotation reference) degree inter-annotator agreement measured Cohens kappa (). authors annotations refittedsimplified annotation scheme used volunteers.many factors contributing apparently low values Table 9,notably skewed distribution categories inappropriate communicationclassification rules. Di Eugenio Glass (2004) others pointed out, skewed distribution categories negative effect value. Since distributioninstances dataset fairly unbalanced, commonly-accepted guidelineinterpreting values ( > 0.67 > 0.8 thresholds tentative definite conclusions respectively; Krippendorff, 1980) may directly applicable case.addition, classification rules communicated annotators orally examples not-so-common cases, object it-extrapositions, mightwell understood annotators. Another interesting note resultsstrong tendency annotators (albeit different cases) classifyit-clefts it-extrapositions. Rather taking sign cleft categorywell-defined, believe reflects inherent difficulties identifying instances pertainingcategory.5.2 BaselinesTwo baselines available comparison WSJ annotation, done manuallyprovided corpus; results replication Paice Husks (1987)algorithm (PHA). cautioned that, given subjectivity issues discussedpaper lack consensus certain topics field linguistics, recall ratiospresented baseline results forthcoming results proposed systemcompared quantitatively. example, original Paice Husk algorithmrecognize certain types object extrapositions always distinguish367fiLi, Musilek, Reformat, & Wyard-Scottindividual types pleonastic it; WSJ corpus neither special annotationparenthetical (c.f. Section 3.2.1, Page 348, [0239:009]) established annotationpolicy certain types object extrapositions (Bies, Ferguson, Katz, & MacIntyre, 1995).attempts made correct issues.Table 10 summarizes performance baselines development dataset.expected, Paice Husks (1987) algorithm perform well since WSJarticles different from, tend sophisticated than, technicalessays algorithm designed for. Compared originally reported precision93% recall 96%, replicated PHA yields 54% 75% respectivelydevelopment dataset. performance replica largely line Boyd et al.(2005) obtained implementation algorithm different dataset.MeasurementReferenceIdentified BaselineBaseline True PositivesPrecisionRecallF-measureWSJ AnnotationExtrapositionCleft11813881287b1298.86%100%73.73% 92.31%84.47% 96.00%Replicated PHAOveralla14019410554.12%75.00%62.87%Includes clefts, extrapositions, time/weather cases.Based manual inspection, two cases originally annotated extrapositional WSJdetermined inappropriate. See discussions below.bTable 10: Performance baselines development dataset, evaluatedauthors annotation.31 (118 87) extrapositional cases annotated WSJ brokenfollowing categories followed respective number instances:CategoryUnrecognizedObject without complementParentheticalInappropriate non-extrapositionAgentless passiveseems/appears . . .worth . . .OthersValid non-extraposition. . .OthersTotalItems312189423102831Table 11: Profile false negatives WSJ annotation reference authorsannotation368fiIdentification Pleonastic Using Webstating Characteristic extraposition final clause replaceit, Bies et al. (1995) define class narrowest sense. Since interpretationdefinition entirely subjective matter, way determining real coverageannotations. However, portions corpus reviewed,practice annotation entirely consistent.Two sentences marked extraposition corpus annotators consensusindicates otherwise. Considering golden standard status WSJ corpus,also listed here:[0277:040] Moreover, member Mitsubishi group, headedone Japans largest banks, sure win favorable loan.[0303:006] compromises convince Washingtons liberalssimply stay course, administration straycourse issues.first sentence considered dubious likely referring companymember Mitsubishi group. second one considered cleft actually alsomarked cleft corpus. Since case corpus annotations,extraposition marking considered mistake manually removed.Paice Husk (1987) algorithm suffers false-positive . . . . . .construct detection, may fixed incorporating part-of-speech phrase structure information together additional rules. However, fixes greatly complicateoriginal system.5.3 Resultsdevelopment dataset, results produced proposed system follows:Extraposition118116113Cleft131313Weather/Time9109Overalla140139136Precision95% C.I.b97.41%94.07-100.00%100.00%79.74-100.00%90.00%66.67-100.00%97.84%95.21-100.00%Recall95% C.I.b95.76%91.79-99.12%100.00%79.74-100.00%100.00%73.07-100.00%97.14%93.98-99.34%F-measure95% C.I.96.58%93.98-98.72%100.00%-94.74%80.00-100.00%97.49%95.45-99.21%MeasurementReferenceIdentifiedTrue PositivesbCombining extraposition, cleft, weather/time one category.Adjusted Wald intervals reported extreme measurements.Table 12: Performance system development dataset, evaluated using authors annotation reference.369fiLi, Musilek, Reformat, & Wyard-Scottstatistical significance tests reveal information regarding systems performance comparison two volunteers baselines:Compared volunteer annotators, systems better performance threepleonastic categories statistically significant.extraposition category, difference WSJ annotations (higher)precision system statistically significant.Compared Paice Husks (1987) algorithm, systems higher precisionstatistically significant.Target SystemVolunteer 1Volunteer 2WSJ AnnotationReplicated PHAExtrapositionCleftWeather/TimeF-measure+ /p < .001 F-measure+ /p < .001 F-measure+ /p = .033F-measure+ /p < .001 F-measure+ /p = .007 F-measure+ /p = .025Precision /p = .630 F-measure+ /p = 1.00(All Categories) Precision+ /p < .001Table 13: Results statistical significance tests presented formatTest Statisticsign /p-value. plus sign (+ ) indicates system performsbetter reported measurement; otherwise minus sign ( ) used. faircomparisons made precision recall, F-measure usedtest statistic; otherwise applicable measurement reported.Using authors annotation reference, system outperforms human volunteers. higher performance usually desirable, particular case, couldindicate possible problems design experiment. Since English languageused speakers also shaped group people, impractical system speaks better English human counterparts do. Oneplausible clue paradox analytic approach needed gain insightissue pronoun classification, casual English speakers seeperspective. Green Hecht (1992) many others indicated, capable userslanguage necessarily ability formulate linguistic rules. However,kinds analytic skills prerequisite order explicitly classify pronoun onemany categories. Thus, true performance casual speakers measuredability comprehend produce various pleonastic constructs. addition,factors, time constraints imperfections category definitionsconveyed, may also play role limiting volunteers performance. authorsannotation, hand, much less influenced issues therefore considered expert opinion experiment. shown Section 5.2, WSJ annotationextrapositions clefts, also considered expert opinion, highly compatibleauthors. differences two annotations mostly attributednarrower definition extraposition adopted WSJ annotators. Therefore,WSJ annotations precision 98.86% extrapositions (when verified authors370fiIdentification Pleonastic Using Webannotation) probably appropriate hint upper-limit practically importantsystem performance.extraposition category, 279 individual cases passed syntactic filtersevaluated search engine queries. Results queries obtained Googleweb service, Google SOAP21 Search API. three (116 113) cases false-positivescaused missing-object constructions corrected using patterns detailedSection 3.4.3.five (118 113) false-negative cases listed below:[0283:013] newspaper said past time Soviet Union createunemployment insurance retraining programs likeWest.[0209:040] one thing say sterilize, another successfully pollinate plant, said.[0198:011] Sen. Kennedy said . . . would reckless courseaction President Bush claim authority without congressional approval.[0290:049] Worse, remained well-meaning naive presidentUnited States administer final infamy upon foughtdied Vietnam.[0085:047] easy roll something comprehensive, makepay, Mr. Jacob says.Sentence [0283:013] misplaced weather/time. Sentence [0209:040] properly handled syntactic processing subcomponent. Sentences [0198:011] [0290:049] involvecomplex noun phrases (underlined) object position matrix verbsdifficult reduce something generic, head noun pronoun, still remain confident original semantics maintained. last case,sentence [0085:047], fails full queries (containing part subordinate clause)failed yield enough results stepped-down versions overwhelmed noise.last four false-negatives annotated correctly WSJ corpus. systemsrecall ratio 87 verified WSJ extraposition annotations therefore 95.40%, comparableoverall recall.5.4 System Performance Parser OutputThus far, system evaluated based assumption underlyingsentences tagged parsed (almost) perfect accuracy. Much effortmade reduce dependency. example, tracing information function tagsoriginal phrase structures deliberately discarded; system also tries searchpossible extraposed cleft clauses marked complements matrix object.However, deficiencies tagging parsing may still impact systems performance.Occasionally, even golden standard manual markups appear problematic happenget way task.21Simple Object Access Protocol XML-based message protocol web services.371fiLi, Musilek, Reformat, & Wyard-Scotttherefore necessary evaluate system sentences automaticallytagged parsed order answer question well would performreal world. Two state-of-the-art parsers employed study: reranking parserCharniak Johnson (2005), Berkeley parser Petrov, Barrett, Thibaux,Klein (2006). systems performance respective interpretationsdevelopment dataset sentences reported Tables 14 15. Table 16 comparessystems real-world performance various baselines.MeasurementReferenceIdentifiedTrue PositivesPrecision95% C.I.bRecall95% C.I.bF-measure95% C.I.bExtraposition11811411096.49%92.68-99.20%93.22%88.43-97.41%94.83%91.60-97.49%Cleft131212100.00%78.40-100.00%92.31%73.33-100.00%96.00%84.62-100.00%Weather/Time910990.00%66.67-100.00%100.00%73.07-100.00%94.74%80.00-100.00%Overalla14013613297.06%93.92-99.32%94.29%90.18-97.81%95.65%93.08-97.90%Combining extraposition, cleft, weather/time one category.Adjusted Wald intervals reported extreme measurements.Table 14: Performance system development dataset parsed Charniakparser, using authors annotation reference.Extraposition118114111Cleft131110Weather/Time998Overalla140134130Precision95% C.I.97.37%94.07-100.00%90.91%70.00-100.00%88.89%62.50-100.00%97.01%93.81-99.32%Recall95% C.I.94.07%89.47-98.18%76.92%50.00-100.00%88.89%62.50-100.00%92.86%88.44-96.91%F-measure95% C.I.95.69%92.75-98.17%83.33%62.50-96.55%88.89%66.67-100.00%94.89%92.02-97.35%MeasurementReferenceIdentifiedTrue PositivesCombining extraposition, cleft, weather/time one category.Table 15: Performance system development dataset parsed Berkeleyparser, using authors annotation reference.372fiIdentification Pleonastic Using WebComparing System Performance Charniak Parser Output to:Target SystemExtrapositionCleftWeather/TimeSystem w/o Parser F-measure /p = .131 F-measure /p = 1.00 F-measure= /p = 1.00Volunteer 1F-measure+ /p = .001 F-measure+ /p < .001 F-measure+ /p = .030Volunteer 2F-measure+ /p < .001 F-measure+ /p = .041 F-measure+ /p = .021WSJ AnnotationPrecision /p = .368 F-measure= /p = 1.00Replicated PHA(All Categories) Precision+ /p < .001Comparing System Performance Berkeley Parser Output to:Target SystemExtrapositionCleftWeather/TimeSystem w/o Parser F-measure /p = .380 F-measure /p = .128 F-measure /p = 1.00Volunteer 1F-measure+ /p < .001 F-measure+ /p = .014 F-measure+ /p = .061Volunteer 2F-measure+ /p < .001 F-measure+ /p = .314 F-measure+ /p = .046WSJ AnnotationPrecision /p = .627 F-measure /p = .374Replicated PHA(All Categories) Precision+ /p < .001Table 16: Results statistical significance tests comparing systems performanceparser output various systems, presented formatTest Statisticsign /p-value. plus sign (+ ) indicates proposed systemperforms better target system reported measurement; equalsign (= ) indicates tie; otherwise minus sign ( ) used. fair comparisonsmade precision recall, F-measure used teststatistic; otherwise applicable measurement reported.significance tests reveal that:using parser statistically significant influence systems performance;system outperforms volunteer annotators identifying it-extrapositions;regardless parser used, difference systems performanceWSJ annotation statistically significant;regardless parser used, system outperforms Paice Husk (1987)algorithm.5.5 Correlation Analysis ExtrapositionsFigures 5 8 illustrate correlation decision factors trueexpletiveness pronoun question. 279 items passed initial syntacticfiltering process included dataset first 116 extrapositionalrest separated break X-axis. arrangement made order bettervisualize contrast positive group negative group. Figures 68, different grey levels used indicate number results returnedqueries darker shade, popular construct question web.constant Rexp = 0.15 also indicated break Y-axis.373fiLi, Musilek, Reformat, & Wyard-Scottillustrated, factors identified Section 3.5 good indicators expletiveness. W(Figure 5) weakest four factors due number false positives producedincorrect language usage. clear evidence web noisier ordinary corporaresults counts web may appropriate sole decision-makingfactor. comparison, r (Figure 6) almost perfect correlation expletivenessinstances. However, full versions queries usually return fewer results manycases yield results expletive cases (unfilled items plotted top graphindicate cases enough results, c.f. Section 3.5). stepped-down versionsqueries (Figure 7), less accurate themselves, serve well usedback up, illustrated R plot (Figure 8). Part false-positive outliersR plot produced full queries expressions habitually associated it,[0135:002] . . . said expects post sales current fiscal year . . . .used pronoun, expressions usually describe information quoted personorganization already named earlier sentence, making naturalchoice subject pronoun. Normally problematic expressions take form verbinfinitive-complement, i.e. S=TRUE. According decision process describedSection 3.5, W also considered situation, effectively eliminates noise.374fiIdentification Pleonastic Using WebFigure 5: scatter plot illustrating correlation W (the estimated numbervalid results returned what-cleft queries) expletivenessinstance. extrapositional instances arranged left side plotrest cases right. query returns valid results,corresponding item shown hollow circle bottom plot.375fiLi, Musilek, Reformat, & Wyard-ScottNumberResultsFigure 6: scatter plot illustrating correlation r (the ratio hit countproduced expression substitute pronouns original expression) expletiveness instance. extrapositional instancesarranged left side plot rest cases right.items shaded according hit counts produced correspondingoriginal expressions. query returns insufficient results, corresponding itemshown hollow unshaded circle top plot.376fiIdentification Pleonastic Using WebNumberResultsFigure 7: scatter plot illustrating correlation r0 (similar rstepped-down queries) expletiveness instance. extrapositional instances arranged left side plot rest casesright. items shaded according hit counts producedcorresponding original expressions. query returns insufficient results,corresponding item shown hollow unshaded circle top plot.377fiLi, Musilek, Reformat, & Wyard-ScottNumberResultsFigure 8: scatter plot illustrating correlation R (synthesized expletiveness;takes value r complex queries produce enough results,takes value r0 fail so) expletivenessinstance. extrapositional instances arranged left side plotrest cases right. items shaded accordinghit counts produced corresponding original expressions. query returnsinsufficient results, corresponding item shown hollow unshaded circletop plot.5.6 Generalization Studyorder evaluate well system generalizes, 500 additional sample sentencesrandomly selected rest WSJ corpus test dataset. distributioninstances comparable development dataset, shown Table 17.378fiIdentification Pleonastic Using WebCategoryNominal AntecedentClause AntecedentExtrapositionCleftWeather/TimeIdiomGrand TotalInstances3752463861113500Percentage75.00%4.80%12.60%1.60%1.20%2.20%2.60%100.00%Table 17: Profile test dataset according authors annotationshown Table 18, overall level inter-annotator agreement slightly higherdevelopment dataset. Except idiom category, categorical valuesalso higher counterparts development dataset. discrepancylikely due chance, since two volunteers worked independently starteddifferent datasets (Volunteer 1 started development dataset Volunteer 2 startedtest dataset).CategoryPrecisionReferential98.48%Extraposition87.10%Cleft29.41%Weather/Time 100.00%Idiom31.82%Overall Accuracy/Volunteer 1Recall F-measure95.12%85.71%62.50%50.00%53.85%91.80%96.77%86.40%40.00%66.67%40.00%Precision97.30%80.00%57.14%100.00%47.06%Volunteer 2Recall F-measure96.83%82.54%50.00%50.00%61.54%92.80%97.07%81.25%53.33%66.67%53.33%.797.811.490.665.280.720values statistically significant p < 0.0001.Table 18: Performance volunteer annotators test dataset (evaluated usingauthors annotation reference) degree inter-annotator agreementmeasured Cohens kappa (). authors annotations refittedsimplified annotation scheme used volunteers.MeasurementReferenceIdentified BaselineBaseline True PositivesPrecisionRecallF-measureWSJ AnnotationExtrapositionCleft63854652696.30% 100.00%82.54%75.00%88.89%85.71%Replicated PHAOveralla77975556.70%71.43%63.22%Includes clefts, extrapositions, time/weather cases.Table 19: Performance baselines test dataset, evaluated authorsannotation.379fiLi, Musilek, Reformat, & Wyard-ScottTable 19 summarizes performance baselines test dataset. two(54 52) false-positive extrapositions WSJ annotation listed togetherrespective context:[1450:054-055] Another solution cities might consider giving special prioritypolice patrols small-business areas. cities losing businesssuburban shopping centers, may wise business investmenthelp keep jobs sales taxes within city limits.[1996:061-062] think go turn things around. toughthing cant.first case considered referential, second case believed referhypothetical situation introduced when-clause.5.6.1 Performance Analysistest dataset, system able maintain precision; exhibits slight deterioration recall overall performance still within expectations. findingssummarized Table 20.Extraposition636058Cleft866Weather/Time676Overalla777370Precision95% C.I.b96.67%91.38-100.00%100.00%64.26-100%85.71%50.00-100.00%95.89%90.77-100.00%Recall95% C.I.b92.06%84.85-98.25%75.00%40.00-100.00%100.00%64.26-100.00%90.91%84.15-97.01%F-measure95% C.I.94.31%89.60-98.11%85.71%57.14-100.00%92.31%66.67-100.00%93.33%88.75-97.10%MeasurementReferenceIdentifiedTrue PositivesbCombining extraposition, cleft, weather/time one category.Adjusted Wald intervals reported extreme measurements.Table 20: Performance system test dataset, evaluated using authorsannotation reference.149 instances evaluated extraposition using queries, covering 62 63 extrapositions. excluded case introduced form direct question, whose particularssyntactic processing subsystem prepared for. four false negatives,three involve noun phrases matrix object position. One two cleftsrecognized arises imperfect processing corpus. addition, false positiveweather/time category caused verb hail , treated nounsystem.five (63 58) false-negative extraposition cases annotated corpusWSJ annotation agrees six clefts identified proposed system. Thus380fiIdentification Pleonastic Using Websystems recall ratio verified WSJ annotations 90.38% extraposition 100%cleft.Target SystemVolunteer 1Volunteer 2WSJ AnnotationReplicated PHAExtrapositionCleftWeather/TimeF-measure+ /p = .041 F-measure+ /p = .005 F-measure+ /p = .248F-measure+ /p = .002 F-measure+ /p = .119 F-measure+ /p = .254Precision /p = .697 F-measure= /p = 1.00(All Categories) Precision+ /p < .001Table 21: Results statistical significance tests, presented formatTest Statisticsign /p-value. plus sign (+ ) indicates system performsbetter reported measurement; equal sign (= ) indicates tie; otherwiseminus sign ( ) used. fair comparisons made precisionrecall, F-measure used test statistic; otherwise applicablemeasurement reported.MeasurementReferenceIdentifiedTrue PositivesPerformance Charniak Parser OutputExtrapositionCleft Weather/Time638658775566Overalla777267Precision95% C.I.94.83%88.24-100.00%85.71%50.00-100.00%85.71%50.00-100.00%93.06%86.36-98.51%Recall95% C.I.b87.30%78.26-95.08%75.00%37.50-100.00%100.00%64.26-100.00%87.01%78.95-94.12%F-measure95% C.I.90.91%84.75-95.77%80.00%50.00-100.00%92.31%66.67-100.00%89.93%84.30-94.57%Performance Berkeley Parser OutputExtrapositionCleft Weather/Time638658575656Overalla777067MeasurementReferenceIdentifiedTrue PositivesPrecision95% C.I.b96.55%91.11-100.00%100.00%59.90-100.00%85.71%50.00-100.00%95.71%90.28-100.00%Recall95% C.I.b88.89%80.60-96.23%62.50%25.00-100.00%100.00%64.26-100.00%87.01%79.22-93.90%F-measure95% C.I.92.56%87.14-96.97%76.92%40.00-100.00%92.31%66.67-100.00%91.16%85.94-95.52%bCombining extraposition, cleft, weather/time one category.Adjusted Wald intervals reported extreme measurements.Table 22: Performance system test dataset using parser-generated output,evaluated using authors annotation reference.381fiLi, Musilek, Reformat, & Wyard-ScottResults significance tests, summarized Table 21, reveal following additionalinformation systems performance test dataset:systems higher performance recognizing it-extrapositions volunteersstatistically significant;extraposition category, difference WSJ annotations (higher) precision system statistically significant;system outperforms Paice Husk (1987) algorithm, differencestatistically significant.Tables 22 23 outline systems performance test dataset parsersused. Again, parsers cause slight deteriorations system performance. However,changes statistically significant. either parser used, system ableperform well WSJ annotations.Comparing System Performance Charniak Parser Output to:Target SystemExtrapositionCleftWeather/TimeSystem w/o Parser F-measure /p = .125 F-measure /p = 1.00 F-measure= /p = 1.00Volunteer 1F-measure+ /p = .298 F-measure+ /p = .013 F-measure+ /p = .247Volunteer 2F-measure+ /p = .022 F-measure+ /p = .269 F-measure+ /p = .246WSJ AnnotationPrecision /p = .886 F-measure /p = 1.00Replicated PHA(All Categories) Precision+ /p < .001Comparing System Performance Berkeley Parser Output to:Target SystemExtrapositionCleftWeather/TimeSystem w/o Parser F-measure /p = .501 F-measure /p = 1.00 F-measure= /p = 1.00Volunteer 1F-measure+ /p = .131 F-measure+ /p = .035 F-measure+ /p = .256Volunteer 2F-measure+ /p = .009 F-measure+ /p = .308F-measure+ /p = .27WSJ AnnotationPrecision /p = .809 F-measure /p = 1.00Replicated PHA(All Categories) Precision+ /p < .001Table 23: Results statistical significance tests comparing systems performanceparser output various systems, presented formatTest Statisticsign /p-value. plus sign (+ ) indicates source system performs better reported measurement; equal sign (= ) indicates tie;otherwise minus sign ( ) used. fair comparisons madeprecision recall, F-measure used test statistic; otherwiseapplicable measurement reported.5.6.2 Estimated System Performance Whole Corpusrelative sparseness clefts makes hard assess real effectiveness proposedapproach. compensate this, approximate study conducted. First, instanceswhole corpus processed automatically using proposed approach. identified382fiIdentification Pleonastic Using Webcleft instances merged already annotated corpusform evaluation dataset 84 sentences, subsequently verified manually. 76instances 84 considered valid cleft constructs authors. Respectiveperformances proposed approach WSJ annotation reported Table 24;differences statistically significant.SystemWSJProposedApproachTotal76Identified66CommonPrecision6395.45%95% C.I.: 89.55-100.00%Recalla82.94%74.32-90.79%F-measurea88.73%82.86-93.79%76757093.33%95% C.I.: 87.50-98.65%92.11%85.53-97.40%92.72%87.84-96.65%reported recall ratios F-measures synthetic dataset cannot extendedwhole corpus.Table 24: Estimated system performance it-cleft identification entire corpusThree false positives produced proposed approach actually extrapositions22 , expected (c.f. Footnote 12, Page 351). Thus, binary classificationpleonastic it, items cleft category higher contributions overallprecision category. whole corpus annotated,impossible obtain precise recall figures either WSJ annotations proposedapproach. However, since rest corpus (other synthetic dataset)contain true positives either system contains number false-negativessystems, proposed system maintain higher recall ratioWSJ annotations whole corpus.similar experiment conducted extrapositions using sentences alreadyannotated corpus. 656 annotated extrapositional instances manually verified637 (97.10%) turn valid cases. system produced queries 623instances consequently recognized 575 them, translating 90.27% (95% C.I. 89.0193.56%) recall ratio verified annotations. Given fact developmentdataset test dataset proposed system yields slightly higher recall wholedataset subsets identified WSJ annotations, performanceextrapositions whole WSJ corpus likely remain 90% recall.Similar situation test based random cases, large portion falsepositives contributed imperfect handling surface structures noun phrasesmatrix object position, particularly form takes/took . . . . . .additional experiments, seems particular construct addresseddifferent pattern, what/whatever takes verb, eliminates noun phrase.Alternatively, construct could possibly assumed extrapositional without issuingqueries all.22kind cleft separated extrapositions using additional pattern attachesprepositional phrase subordinate verb. However, number samples justifyinclusion study.383fiLi, Musilek, Reformat, & Wyard-Scott6. Discussionpaper novel pleonastic-it identification system proposed. Unlike precursors,system classifies extrapositions submitting queries web analyzing returnedresults. set rules also proposed classification clefts, whose particular mannercomposition makes difficult apply web-based approach. Componentsproposed system simple effectiveness independent type textprocessed. shown generalization tests, system maintains precisionrecall degrades small margin confronted unfamiliar texts.indication general principles behind system over-fitted textderived. Overall, evaluated WSJ news articlesconsidered difficult type nonfiction system capable producing resultspar slightly inferior casually trained humans.systems success important implications beyond particular problempleonastic-it identification. First, shows web used answer linguistic questions based upon simplistic semantic relationships. Second,comparative study effective means get highly accurate results web despite fact noisier manually compiled corpora. addition, successsimple guidelines used identifying clefts may serve evidence speakersintention heavily reflected surface structures utterance, bidmake distinguishable similarly constructed sentences.problems left unaddressed current study, notably handlingcomplex noun phrases prepositional phrases. Generally speaking, approachquery instantiation somewhat crude. solve noun-phrase issue, finer-grained querydowngrading proposed, viz. first supply query original noun phrase,head noun, finally adjective modifies head noun, one.effectiveness approach determined. discussed Section 5.6.2, specialrule used verb take. This, however, may open door exception-basedprocessing, contradicts principle system provide unified approachpleonastic pronoun identification. Overall, much data experimentsneeded query instantiation procedures finalized.Aside two sets patterns currently use, informationused assess validity possible extraposition. example, extrapositionsmatrix verbs much likely remain present tense past tense,noun phrases (if any) matrix object position likely indefinite,extraposed clauses generally longer matrix verb phrases. fuzzy-baseddecision system multiple input variables could possibly provide significant performancegains.Although system able yield reasonable performances output eitherparser tested, introduce additional errors final results. combineddataset development test items, parsers cause statistically significant deteriorations performance significance level 0.1 (Charniak parser: p=0.008 F-measureextrapositions; p=0.071 F-measure clefts). possible incorporatingpattern-based method compensate problems caused imperfect parsingimprove recall ratios; however, data needed confirm this.384fiIdentification Pleonastic Using WebAnother concern syntactic processing component used system limited.limitation, caused designers lack exposure large variety differentconstructs, essentially different problem imposed limited numberpatterns previous systems. Eventually, proposed system, limitationeliminated. illustrate, current design able correctly process sentences likedifference make buy; however, takes minor effort correctupgrading subsystem recognizes pre-posed objects. upgrade,may performed manually even automatically machine-learningapproaches, solves one syntactic problems moves system closer ablerecognize grammatically valid constructs. contrast, take considerablyeffort patch rigidly defined rules upgrade word lists rule-basedsystems achieve comparable performances.writing article, Google deprecated SOAP-based search API.move makes technically difficult precisely replicate results reported studysince search engines lack ability process alternate expressions (i.e. WordAWordB ) embedded within quoted query. use different search engine, matrix verbsexpanded instead converted respective third-personsingular present form only. Stubs also simplest form only, describedearlier sections. preliminary experiments also seems possible replacecombination which/who/this/he alone, plus necessary changes maintainnumber agreement among constituents queries. changes maynegative effects final outcome system, unlikely severe.Like NLP tasks, classifying usage inherently difficult, evenhuman annotators already knowledge problem one thingspeak language, another clearly explain rationale behind specificconstruct. Although widely accepted extrapositional expletive, lineextrapositional cases referential ones sometimes thin.clearly manifested existence truncated extrapositions (Gundel et al., 2005),obviously valid referential readings. Similar things said relationshipamong three pleonastic categories well idioms. example, Paice Husk classifyremains . . . idiom construct classified extrapositionevaluations. Aside applying syntactic guidelines proposed study,assumed annotation process extraposition either validnon-extraposed reading valid what-cleft reading. also assumed cleftgenerate valid non-clefted reading joining clefted constituent directly cleftclause without leading relative pronoun adverb. light subjective natureproblem, annotations published web online appendix betterserve readers.ReferencesAgresti, A., & Coull, B. A. (1998). Approximate better exact interval estimation binomial proportions. American Statistician, 52 (2), 119126.Berland, M., & Charniak, E. (1999). Finding parts large corpora. Proceedings 37th annual meeting Association Computational Linguistics385fiLi, Musilek, Reformat, & Wyard-ScottComputational Linguistics, pp. 5764.Bies, A., Ferguson, M., Katz, K., & MacIntyre, R. (1995). Bracketing guidelines Treebank II style. Tech. rep. MS-CIS-95-06, Department Computer InformationScience, University Pennsylvania.Boyd, A., Gegg-Harrison, W., & Byron, D. (2005). Identifying non-referential it: machinelearning approach incorporating linguistically motivated patterns. ProceedingsACL Workshop Feature Engineering Machine Learning Natural LanguageProcessing, pp. 4047. Association Computational Linguistics.Charniak, E., & Johnson, M. (2005). Coarse-to-fine n-best parsing maxent discriminative reranking. Proceedings 43rd Annual Meeting AssociationComputational Linguistics (ACL05), pp. 173180, Morristown, NJ, USA. AssociationComputational Linguistics.Chinchor, N. (1992). statistical significance MUC-4 results. Proceedings4th conference Message understanding (MUC4), pp. 3050, San Mateo, CA.Morgan Kaufmann.Cimiano, P., Schmidt-Thieme, L., Pivk, A., & Staab, S. (2005). Learning taxonomic relations heterogeneous evidence. Buitelaar, P., Cimiano, P., & Magnini, B.(Eds.), Ontology Learning Text: Methods, Applications Evaluation, Frontiers Artificial Intelligence Applications, pp. 5973. IOS Press, Amsterdam.Clemente, J. C., Torisawa, K., & Satou, K. (2004). Improving identification nonanaphoric using support vector machines. Proceedings InternationalJoint Workshop Natural Language Processing Biomedicine Applications(NLPBA/BioNLP04).Cohen, J. (1960). coefficient agreement nominal scales. Educational Psychological Measurement, 20 (1), 3746.Collins, M. (1999). Head-Driven Statistical Models Natural Language Parsing. Ph.D.thesis, University Pennsylvania.Davidse, K. (2000). constructional approach clefts. Linguistics, 38 (6), 11011131.Davison, A. C., & Hinkley, D. V. (1997). Bootstrap Methods Application. Cambridge series statistical probabilistic mathematics. Cambridge University Press,Cambridge, UK.Denber, M. (1998). Automatic resolution anaphora English. Tech. rep., EastmanKodak Co.Di Eugenio, B., & Glass, M. (2004). kappa statistic: second look. ComputationalLinguistics, 30 (1), 95101.Efron, B., & Tibshirani, R. (1993). Introduction Bootstrap. Chapman Hall,New York, USA.Evans, R. (2000). comparison rule-based machine learning methods identifyingnon-nominal it. Christodoulakis, D. (Ed.), Proceedings 2nd InternationalConference Natural Language Processing (NLP00), Vol. 1835 Lecture NotesComputer Science, pp. 233241, Berlin. Springer.386fiIdentification Pleonastic Using WebEvans, R. (2001). Applying machine learning toward automatic classification it.Literary Linguistic Computing, 16 (1), 4557.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press,Cambridge, Mass., USA.Geurts, B., & van der Sandt, R. (2004). Interpreting focus. Theoretical Linguistics, 30 (1),144.Green, P. S., & Hecht, K. (1992). Implicit explicit grammar: empirical study. AppliedLinguistics, 13 (2), 168184.Gundel, J., Hedberg, N., & Zacharski, R. (2005). Pronouns without NP antecedents:know pronoun referential?. Branco, A., McEnery, T., & Mitkov,R. (Eds.), Anaphora Processing: Linguistic, Cognitive Computational Modelling,pp. 351364. John Benjamins, Amsterdam, Netherlands.Gundel, J. K. (1977). cleft sentences come from?. Language, 53 (3), 543559.Hamawand, Z. (2003). For-to complement clauses English: cognitive grammar analysis.Studia Linguistica, 57 (3), 171192.Hearst, M. A. (1992). Automatic acquisition hyponyms large text corpora.Proceedings 14th international conference Computational Linguistics, pp.539545.Hedberg, N. (1990). Discourse Function Cleft Sentences English. Ph.D. thesis,University Minnesota.Hedberg, N. (2000). referential status clefts. Language, 76 (4), 891920.Kaltenbock, G. (2005). It-extraposition English: functional view. International JournalCorpus Linguistics, 10 (2), 119159.Kilgarriff, A. (2007). Googleology bad science. Computational Linguistics, 33 (1), 147151.Kilgarriff, A., & Grefenstette, G. (2003). Introduction special issue Webcorpus. Computational Linguistics, 29 (3), 333347.Krifka, M. (2003). Bare NPs: Kind-referring, indefinites, both, neither?. ProceedingsSemantics Linguistic Theory (SALT) XIII, New York, USA. CLC Publications.Krippendorff, K. (1980). Content Analysis: Introduction Methodology. Sage Publications, Inc., Beverly Hills, USA.Lambrecht, K. (2001). framework analysis cleft constructions. Linguistics,39 (3), 463516.Lappin, S., & Leass, H. J. (1994). algorithm pronominal anaphora resolution. Computational Linguistics, 20 (4), 535561.Marcus, M. P., Marcinkiewicz, M. A., & Santorini, B. (1993). Building large annotatedcorpus English: Penn Treebank. Computational Linguistics, 19 (2), 313330.Markert, K., & Nissim, M. (2005). Comparing knowledge sources nominal anaphoraresolution. Computational Linguistics, 31 (3), 367402.387fiLi, Musilek, Reformat, & Wyard-ScottMarkert, K., Nissim, M., & Modjeska, N. N. (2003). Using web nominal anaphoraresolution. Dale, R., van Deemter, K., & Mitkov, R. (Eds.), ProceedingsEACL Workshop Computational Treatment Anaphora, pp. 3946.Metcalf, A., & Barnhart, D. K. (1999). America Many Words: WordsShaped America. Houghton Mifflin, Boston, USA.Mitkov, R. (2001). Outstanding issues anaphora resolution. Gelbukh, A. (Ed.),Proceedings 2nd International Conference Computational LinguisticsIntelligent Text Processing (CICLing01), Vol. 2004 Lecture Notes ComputerScience, pp. 110125, Berlin. Springer.Mitkov, R., Evans, R., & Orasan, C. (2002). new, fully automatic version Mitkovsknowledge-poor pronoun resolution method. Gelbukh, A. F. (Ed.), Proceedings3rd International Conference Computational Linguistics Intelligent TextProcessing (CICLing02), Vol. 2276 Lecture Notes Computer Science, pp. 168186,London, UK. Springer-Verlag.Muller, C. (2006). Automatic detection nonreferential spoken multi-party dialog.Proceedings 11th Conference European Chapter AssociationComputational Linguistics (EACL06), pp. 4956.Nanni, D. L. (1980). surface syntax constructions easy-type adjectives.Language, 56 (3), 568581.Ng, V., & Cardie, C. (2002). Identifying anaphoric non-anaphoric noun phrasesimprove coreference resolution. Proceedings 19th international conferenceComputational linguistics (COLING02), pp. 17, Morristown, NJ, USA. AssociationComputational Linguistics.Noreen, E. W. (1989). Computer-Intensive Methods Testing Hypotheses : Introduction. Wiley-Interscience, New York, USA.Paice, C. D., & Husk, G. D. (1987). Towards automatic recognition anaphoricfeatures english text: impersonal pronoun it. Computer Speech & Language,2 (2), 109132.Petrov, S., Barrett, L., Thibaux, R., & Klein, D. (2006). Learning accurate, compact,interpretable tree annotation. Proceedings 21st International ConferenceComputational Linguistics 44th annual meeting ACL (ACL06), pp.433440, Morristown, NJ, USA. Association Computational Linguistics.Poesio, M., Ishikawa, T., im Walde, S. S., & Vieira, R. (2002). Acquiring lexical knowledgeanaphora resolution. Proceedings Third International ConferenceLanguage Resources Evaluation, pp. 12201224.Sinclair, J. (Ed.). (1995). Collins COBUILD English Grammar. Harper Collins, London,U.K.Sloat, C. (1969). Proper nouns English. Language, 45 (1), 2630.van Rijsbergen, C. J. (1979). Information Retrieval (2nd edition). Butterworth-Heinemann,Newton, MA, USA.388fiIdentification Pleonastic Using WebXia, F., & Palmer, M. (2001). Converting dependency structures phrase structures.Proceedings first international conference Human language technologyresearch (HLT01), pp. 15, Morristown, NJ, USA. Association ComputationalLinguistics.389fiJournal Artificial Intelligence Research 34 (2009) 209-253Submitted 06/2008; published 03/2009Mechanisms Making Crowds TruthfulRadu Jurcaradu.jurca@gmail.comGoogle Inc., SwitzerlandBoi Faltingsboi.faltings@epfl.chEcole Polytechnique Federale de Lausanne (EPFL)Artificial Intelligence Laboratory (LIA)CH-1015 Lausanne, SwitzerlandAbstractconsider schemes obtaining truthful reports common hidden signallarge groups rational, self-interested agents. One example online feedbackmechanisms, users provide observations quality product serviceusers accurate idea quality expect. However,(i) providing feedback costly, (ii) many motivations providingincorrect feedback.problems addressed reward schemes (i) cover cost obtainingreporting feedback, (ii) maximize expected reward rational agentreports truthfully. address design incentive-compatible rewards feedbackgenerated environments pure adverse selection. Here, correlationtrue knowledge agent beliefs regarding likelihoods reportsagents exploited make honest reporting Nash equilibrium.paper extend existing methods designing incentive-compatible rewardsalso considering collusion. analyze different scenarios, where, example,agents collude. scenario investigate whether collusion-resistant,incentive-compatible reward scheme exists, use automated mechanism design specifyalgorithm deriving efficient reward mechanism.1. Introductionincreasing number applications artificial intelligence extract knowledge largegroups agents, also termed wisdom crowds. One example online feedback forums (also known reputation mechanisms) obtaining informationproducts services. testimonies previous buyers disclose hidden, experience-related(Parasuraman, Zeithaml, & Berry, 1985), product attributes quality, reliability,ease use, etc., observed purchase. previously unavailableinformation allows buyers make better, efficient decisions, eliminatesproblems would otherwise lead collapse online markets1 .Recent studies, however, raise important questions regarding ability existing reputation mechanisms reflect real quality product. First, absence clearincentives drives users voice opinions. example, Hu, Pavlou,1. Akerlof (1970) warns Market Lemons, asymmetric information drives all, exceptworst quality sellers market.c2009AI Access Foundation. rights reserved.fiJurca & FaltingsZhang (2006) Admati Pfleiderer (2000) show Amazon2 ratings booksCDs follow great probability bi-modal, U-shaped distributionsratings either good, bad. controlled experiments itemsreveal normally distributed opinions, authors conclude users moderate outlook unlikely report. Talwar, Jurca, Faltings (2007) identify another factorpromotes rating, namely desire contribute something new previouslysubmitted reports. cases, reputation mechanism collects unrepresentativesample reviews necessarily informative average user.Second, even distressful, users intentionally lie order gain externalbenefits distorted reputation. Harmon (2004) reports authors write fakereviews Amazon order boost sale books, trash reputationcompeting titles. White (1999) describes manipulation techniques pushing songscharts, Elliott (2006) Keates (2007) identify problems associated fake hotelreviews travel reputation site TripAdvisor.com. Although still see high levelsaltruistic (i.e., honest) reporting, increasing awareness gains mademanipulating online reputation likely attract dishonest reporting future.problems solved reputation mechanism rewards users reportingfeedback. First, reward cover cost reporting, users leavefeedback allow reputation mechanism estimate precisely qualityproducts services. Second, honest feedback yield higher rewards lying,rational agents find best interest truthful. technique limitedreputation mechanisms, applies generally setting private signalinferred reports crowd self-interested rational agents.reader might already ask whether reasonable assume explicitpayments 3 incentivise users change reporting behavior. Although humansknown sometimes act irrationally, many examples online systems rewards successfully promoted elicitation private information. Prediction markets,example, consistently outperform traditional prediction tools (Figlewski, 1979; Pennock,Debnath, Glover, & Giles, 2002) users seem equally motivated fake realmoney (Servan-Schreiber, Wolfers, Pennock, & Galebach, 2004). Another exampleESP Game4 extracted impressive volume image tags rewarding playersvirtual points. Moreover, future online economy likely contain increasing numbers automated agents, design, programmed behave rationallymaximize utility.Fundamental results mechanism design literature (dAspremont & Grard-Varet,1979; Cremer & McLean, 1985) show side payments designed createincentive agents reveal private opinions truthfully. best paymentschemes constructed based proper scoring rules (Kandori & Matsushima, 1998;Johnson, Pratt, & Zeckhauser, 1990; Clemen, 2002), exploit correlationobservations different buyers good.2. http://www.amazon.com3. term payments general includes non-monetary rewards preferential access resources,social status bonus points.4. http://www.espgame.org/210fiMechanisms Making Crowds TruthfulMiller, Resnick, Zeckhauser (2005) adapt results online feedback forumscharacterized pure adverse selection. environments, buyers observeinnate quality attributes products service providers, possibly noise.role reputation mechanism signaling, i.e. aggregate reports buyersaccurate estimates attributes. Examples situation product ratingforums Amazon, ePinions Bizrate, services providedmachines networks anonymous fashion.contrast reputation mechanisms also used sanctioning role counter moralhazard. exists environments provider vary quality attributesparticular buyer strategic manner. role reputation mechanismspread information seller misbehavior increase cost make unattractive.example environment seller ratings online marketplaces.two roles reputation complementary, solve two important problems associated online markets (Dellarocas, 2006). signaling role actsinformation asymmetries, allows agents accurately identify capable partners.sanctioning role, hand, acts cheating incentives encourages honestbehavior.Like Miller et al. (2005), concentrate paper pure signaling mechanismsignore effects associated moral hazard. set users assumed experienceproduct service, possibly noise, later report privately perceivedquality signal central reputation mechanism. product service assumedconsistent quality time, quality observed different users modeledrandomly drawn distribution. assumptions quite commonservices delivered automated systems like web services intelligent agents, failuresdegradation performance due random events plannedstrategic operator.reputation mechanism scores every submitted feedback comparing another report (called reference report) submitted different usergood. Miller et al. (2005) prove existence general incentive-compatible paymentshonest reporting Nash equilibrium, expected reward large enoughcover effort reporting.Intuitively, incentive-compatible payments exploit correlation privatesignal observed agent, agents beliefs regarding reference report. Differentquality signals trigger different updates agents private beliefs (by Bayes Law),thus modify agents expectations regarding value reference report. payingreporters according well submitted feedback improves public predictorreference report (tested actual reference report, assumed honest), agentsincentive align public predictor private beliefs, thus reporttruth. Honest reporting becomes Nash equilibrium.Unfortunately, honest reporting Nash Equilibrium (NE) mechanism. Jurca Faltings (2005) show binary incentive-compatible payment mechanisms using single reference report several equilibria; moreover, least one lyingequilibrium gives agents higher expected payoffs truthful NE. bringsforth problem collusion, rational agents could potentially coordinate lyingequilibrium gives higher payoff honest equilibrium.211fiJurca & Faltingssimplest lying equilibrium agents always report same, thusleading perfect prediction reference reports. product service realworld occasional defects, truthful reporting always noisy predictorreference report, thus able match payoff lying strategy.overcome problem using single several reference reports. startobservation real world, even perfect products servicesoccasionally defective. Thus, reward reports predict slightlyimperfect situation. key idea score report set least 4 referencereports, reward report according distribution reference reports,without considering order. giving higher reward matching onereference reports, possible give higher expected payoff truthful reportingequilibrium.difficult see scale rewards obtain characteristic, useautomated mechanism design (Conitzer & Sandholm, 2002) compute rewardssatisfy criteria. technique first applied problem JurcaFaltings (2006) compute minimal payments required ensure honest reportingreputation information. Jurca Faltings (2007a) augment technique formulatingrequirement collusion safety additional constraints desired mechanism.paper extends previous work presenting unified framework designing incentivecompatible, collusion resistant rewards broader set collusion scenarios.concretely, vary complexity collusion scenario along three dimensions.First, consider size coalition, study happensagents become part lying coalition. complexity coordination seconddimension, consider cases colluders necessary sophisticationcoordinate different reporting strategies. Finally, third dimension addressestransfer utilities includes settings colluders make side-paymentscolluders.However, combinations formally treated; contain contradictory assumptions (e.g., colluders assumed capable side-payments, also assumedcapable coordinate different strategies) lead trivial impossibility results (e.g., collusion resistance clearly impossible one strategic agent controls online identities,exactly scenario agents collude may transfer payments among themselves).paper proceeds follows. Section 2 formally introduces model, Section 3introduces incentive-compatible payment mechanisms presents properties. Section 4 addresses design collusion-resistant reward mechanisms differentscenarios. Finally discuss related work future directions improve results.2. Modelconsider online market number rational buyers (or agents) experienceproduct (or service). quality product remains fixed, definesproducts (unknown) type. finite set possible types, denotes memberset. assume buyers shareP common belief regarding prior probabilityP r[], product type . P r[] = 1.212fiMechanisms Making Crowds Truthfulpurchase, every buyer perceives binary signal quality (i.e., truetype) product. 1 denotes high quality signal captures satisfactionbuyer product. 0, hand, denotes low quality signal,buyers dissatisfaction product. Every product type characterizeddifferent probability distribution signals perceived buyers. Let P r[1|]probability buyer product type satisfied (i.e., observes qualitysignal 1). P r[1|1 ] 6= P r[1|2 ] 1 6= 2 , P r[1|] assumed common knowledge.make simpler reader follow formal notation, presentnumerical example. example extended introduce new notation,serve subsequent sections illustrate results.Example. Alice, owner old house, needs plumbing work done. knowsgood (type G ) bad (type B ) plumbers, good plumbers provide highquality service much higher probability: e.g., P r[1|G ] = 0.9 P r[1|B ] = 0.15. Alicepicks plumber Yellow Pages, given reputation source, believesplumber, Bob, likely good: e.g., P r[G ] = 0.8 P r[B ] = 0.2. Therefore,Alice expects get good service probability P r[G ]P r[1|G ] + P r[B ]P r[1|B ] = 0.75.central reputation mechanism asks every buyer submit feedback. Buyers assumed rational,reporttruth. set pure reporting strategiesconstrainedbuyer = s(0), s(1)|s(0),s(1)Q2 , Q2 = {0, 1} set quality signals, = s(0), s(1) denotes strategy according buyer announcess(0) Q2 observes low quality, s(1) Q2 observes high quality.often call reports 0 1 negative, respectively positive report.ease notation, name four members set honest strategy (s),lying strategy (slie ), always reporting one strategy (spos ) always reporting0 strategy (sneg ):= (0, 1) buyer reports 0 observes low quality 1 observeshigh quality;slie = (1, 0) buyer reports 1 observes low quality 0 observeshigh quality;spos = (1, 1) buyer reports 1 regardless observation;sneg = (0, 0) buyer reports 0 regardless observation;reputation mechanism rewards buyers submitted reports. paymentreceived buyer depend information available reputation mechanism:namely, reports submitted buyers, common knowledge regardingenvironment (probability distribution types, conditional probability distributionsquality signals). assume reputation mechanism updates public reputationinformation batches N reports. agents submitted N reportsbatch assumed access public information, motivatescommon priors assumption beginning section. rest paperanalyze reward mechanisms work static sets N reports; real settings,213fiJurca & Faltingshowever, mechanisms designed batches sizeN.Note reputation mechanism (i) know true type product,(ii) cannot purchase product order get first-hand experience regardingquality.Discarding notation dependence common knowledge, paymentmechanism (employed reputation mechanism) function : Q2 (Q2 )N 1 R+ ,(ri , ri ) 0 amount paid buyer reports ri Q2N 1 buyers report ri (Q2 )N 1 . reports ri also called reference reportsagent i, since constitute reference computing payment agent i.constrain payments non-negative online forums cannot impose punishmentsreporters.order reports important, therefore simplify payment mechanism) rassuming (ri , ri ) = (ri , riri contain numberpositive reports. compact description payment mechanism thus givenamounts (r, n) n {0, 1, . . . , N 1} number positive reports submittedreference reporters.payoff expected agent depends distribution reference reports.agents report honestly, distribution reference reports computedprior beliefs, true observation, oi Q2 agent i. probabilityexactly n positive reports submitted N 1 agents is:P r[n|oi ] =XP r[n|]P r[|oi ];(1)P r[n|] binomial probability distribution function, P r[|oi ] computed Bayes Law:N 1N 1nP r[1|]n 1 P r[1|];nXP r[oi |]P r[]P [|oi ] =; P r[oi ] =P r[oi |]P r[];P r[oi ]P r[n|] =Example. Bob plumber gets work done, Alice observes result learnssomething new Bobs type. Alice sees good work, posterior belief regardingtype Bob P r[G |1] = 1P r[B |1] = 0.96 (computed Bayes Law), therefore,Alice believe client get good service Bob probability:P r[1|1] = P r[1|G ]P r[G |1] + P r[1|B ]P r[B |1] = 0.87. hand, Alicehappy work done Bob, posterior belief be: P r[G |0] = 1 P r[B |0] =0.32, expect another client receive good service Bob probability:P r[1|0] = P r[1|G ]P r[G |0] + P r[1|B ]P r[B |0] = 0.39.reputation mechanism offers Alice following reward scheme: report paidmatches reference report. negative report paid $2.62, positive reportpaid $1.54. Consequently, reward scheme formally described (0, 0) = 2.62,(1, 1) = 1.54, (1, 0) = (0, 1) = 0. Assuming reference report truthful,one easily verify Alice maximizes expected payment reporting truth:Alice experiences good service plumber, expects client also gets214fiMechanisms Making Crowds Truthfulgood service probability 87%. Assuming client reports truthfully, Alicesexpected payment is: .871.54+.130 = 1.34 reports good service, .870+.132.62 =0.34 reports bad service; Likewise, Alice experiences bad service, expectsreference report negative probability 1 .39 = .61. case, expectedpayment is: .39 1.54 + .61 0 = 0.6 reports good service, .39 0 + .61 2.62 = 1.6reports bad service. cases, honest reporting better lying $1.numerical example specifies payments dollars mentionvalue service object reputation report. specifically avoid dependence reward mechanism value goods traded market. Instead,relate rewards marginal gain telling truth, monetary unitdefined minimum expected loss agent miss-reports instead tellingtruth.strategy profile vector (si )i=1,...,N , prescribing reporting strategy siagent i. sometimes use notation = (si , si ), si strategyprofile agents except i; i.e., si = (sj ), j = 1, . . . , 1, + 1, . . . , N . Givenprofile reporting strategies (si , si ), let [n, si ] describe belief agent regardingdistribution reference reports, when:n N 1 agents observe high quality signal, 1N 1 agents reporting according strategy profile si ;Given n si , agent believes probability [n, si ](x) x reference reportspositive. si (oi ) Q2 value report prescribed strategy si given trueobservation oi , expected payoff agent is:V (si , si |oi ) =N1XP r[n|oi ]n=0N1X[n, si ](x) si (oi ), x ;(2)x=0Throughout paper restrict attention pure reporting strategiespure strategy equilibria. reason behind choice grounded practical considerations: mixed strategies mixed strategy equilibria complex difficultunderstand, therefore unlikely observed practical applications. Acknowledginglimitations brought assumption, still believe results valuablenumber practical scenarios.3. Incentive-Compatible Payment Mechanismssection study general payment mechanisms incentive-compatible, withoutworrying collusion resistance. payment mechanism incentive-compatiblehonest reporting Nash Equilibrium (NE): i.e., agent gain lyingagents report honestly. Formally, let (si , si ) strategy profile agents reporthonestly. optimal agent report truth if, observation oi ,honest report maximizes agents expected payoff:V (si , si |oi ) > V (si , si |oi ); si \ {s}, oi Q2 ;Since reference reports truthful, expected payoff agent is:V (si , si |oi ) =N1Xn=0215P r[n|oi ] (oi , n);fiJurca & Faltingsincentive-compatibility constraints become:N1XP r[n|oi ] (oi , n) >n=0N1XP r[n|oi ] (1 oi , n); oi Q2 ;(3)n=0Practical mechanisms, however, need offset lying incentives offering certain marginstruth-telling. Honest reporting must better lying least margin ,chosen mechanism designer offset external benefits agent might obtainlying. Rewriting (3) account margin , incentive-compatible paymentmechanism satisfies constraints:N1XP r[n|1] (1, n) (0, n) ;n=0N1XP r[n|0] (0, n) (1, n) ;(4)n=0formalizing intuition profitable report positively (respectively negatively) observing high (respectively low) quality.Kandori Matsushima (1998), Miller et al. (2005) show possibleconstruct payment mechanisms satisfy constraints (4), based scoring rules.Jurca Faltings (2006) build existence result describe algorithmcomputes optimal (i.e., budget minimizing) payment mechanism. uselatter approach paper, obvious practical advantages designing incentivecompatible reputation mechanism cheaply possible.expected payment honest reporter (in truthful NE) weighted sumexpected payment agent truthfully reports 1, expectedpayment agent truthfully reports 0:N1N1hXXE V (si , si ) = P r[1]P r[n|1] (1, n) + P r[0]P r[n|0] (0, n);n=0(5)n=0P r[1] (respectively P r[0]) prior probabilitiesP agent perceive high(respectively low) quality, defined as: P r[oi ] = P r[oi |]P r[].payment scheme minimizes budget required pay one honest reporttherefore solves linear optimization problem:LP 3.1.N1N1hXXmin E V (si , si ) = P r[1]P r[n|1] (1, n) + P r[0]P r[n|0] (0, n);n=0s.t.N1Xn=0P r[n|1] (1, n) (0, n) ;n=0N1XP r[n|0] (0, n) (1, n) ;n=0(0, n), (1, n) 0; n = {0, 1, . . . , N 1};216fiMechanisms Making Crowds TruthfulAlthough numerical algorithms efficiently solve LP 3.1, analytical solution helpsus gain additional insights structure incentive-compatible payment mechanisms.turns LP 3.1 simple solution:Proposition 3.1. incentive-compatible payment scheme minimizes expectedpayment honest reporter (defined LP 3.1) is:(0, n) = 0, n 6= 0;(1, n) = 0, n 6= N 1P r[N 1|0] + P r[N 1|1];P r[N 1|1]P r[0|0] P r[N 1|0]P r[0|1]P r[0|0] + P r[0|1](1, N 1) =;P r[N 1|1]P r[0|0] P r[N 1|0]P r[0|1](0, 0) =Proof.optimal payment mechanism symmetric rewards perfect consensus amongreporters: i.e., agent gets rewarded report agrees reportagents. reason consensus rewards optimal comes structureincentive compatible constraints. Clearly must least two positive payments: onerewarding negative report configuration reference reports, rewardingpositive report configuration reference reports. proof (the fulldetails available Appendix A) shows enough two positive payments, corresponding configurations reference reports must reflectconsensus.first part intuitively simpler motivate. properties Bayesian updatesmakes always exist n1 n2 P r[n1 |0] > P r[n1 |1]P r[n2 |1] > P r[n2 |0] (e.g., configuration n1 agents report 1 becomesprobable negative experience, configuration n2 agents report1 becomes likely positive experience). potentially infinite payments,fact n1 n2 exist makes possible satisfy incentive compatible constraints;therefore payment mechanism two positive payments (0, n1 ) (1, n2 )incentive compatible. formal proof Appendix uses dual formulation showthing.second part proof shows expected payment minimizedscheme rewards consensus (i.e., n1 = 0 n2 = N 1). dual LP 3.1 revealsexpected payment agent proportional ratios P r[n1 |1]/P r[n1 |0]P r[n2 |0]/P r[n2 |1]. ratios reflect relative change agents beliefs followingsubjective private experience. e.g., P r[n1 |1]/P r[n1 |0] reflects relative changebelief n1 agents report 1, given positive opposed negative experience.Likewise, P r[n2 |0]/P r[n2 |1] relative change belief n2 agents report1, given negative opposed positive experience. following lemma showsratios (and therefore expected payment agent) minimized n1 = 0n2 = N 1.Lemma 3.1. Given set types , probability distributions P r[1|], prior beliefP r[n+1|1]types P r[] number agents N , PP r[n|1]r[n|0] < P r[n+1|0] n = 0 . . . N 1.217fiJurca & Faltingsfull proof Lemma also provided Appendix A.mechanisms5paymentsatisfy incentive compatibility constraintssimilar property: must least two values reference reports, n1 < n2 ,that:(0, n1 ) > (1, n2 )(1, n2 ) > (0, n2 );requirement n1 < n2 direct consequence Lemma 3.1. (0, n1 )(1, n2 ) scaled appropriately6 , rational agent prefers bet n1 observeslow quality, bet n2 observes high quality.exactly property makes impossible design incentive-compatiblemechanism honest reporting unique NE one reference report(Jurca & Faltings, 2005). n1 n2 constrained take values 0, respectively 1,(0, 0) > (0, 1), (1, 1) > (1, 0), illustrated example Section 2. Therefore,constant reporting strategies always reporting 0 1 also Nash Equilibria. Moreover,since expected payment honest reporter linear combination (0, 0)(1, 1), least one constant reporting equilibrium generates higher payoffreporters honest equilibrium. Hence vulnerability payment mechanismlying colluders.Using several reference reports not, default, eliminate problem. resultProposition 3.1 shows incentive-compatible constraints alone, also generate rewardschemes vulnerable conformity rating (i.e, everybody reports thing).cases, nevertheless, payment schemes based several reference reportsconstrained reward agreement, one could specify conditions, addeddesign problem generate collusion-resistant mechanisms.next section. assume N > 2 agents system analyzesupplementary constraints added design problem order deter collusion.consider several collusion scenarios, whenever possible present algorithmoutputs reward mechanism incentive-compatible collusion-resistant.4. Collusion-resistant, Incentive-compatible Rewardsideal reward mechanism deters coalition, matter big, even every colluder may use different strategy side-payments possible. mechanism, unfortunately, trivially impossible: given agents may collude use side-paymentssubsidize agents might otherwise quit coalition, payment mechanismdoesnt leverage encourage honest reporting. Whatever payment scheme,coalition adopt strategy maximizes total revenue, regardlesstruth.Positive results may obtained imposing restrictions possible lyingcoalitions. first restriction agents collude. agents altruisticnature report honestly moral social reasons. agents aware5. One might wish, example, design mechanism minimizes expectedbudgetpaid NPNbuyers. case,objectivefunctionproblemLP3.1is:B=Pr[n]n (1, n 1) +n=0(N n) (0, n) , P r[n] prior probability n N buyers observe high quality;6. (1, n1 ) (0, n2 ) typically 0218fiMechanisms Making Crowds Truthfulcollusion opportunities, cannot contacted forming coalition. Social legal normscollusion may furthermore create prejudices deter agents enteringcoalition.second restriction addresses complexity coordination among colluders.Symmetric collusion strategies prescribe colluders reporting accordingstrategy. coordination symmetric strategies simple, requires oneanonymous access publicly available source information specifies colludingstrategy. Intuitively, role coordination device may played public bloganalyzes mechanisms informs potential colluders profitablesymmetric colluding strategy. Asymmetric collusion strategies, hand, requiresignificantly complex coordination. Since every colluder may use different reportingstrategy, coordination device must know identity colluder instructingcollusion strategy. often unfeasible, either colluders might wantreveal identity thus create trace misbehavior, identitycolluders cannot known actual reporting takes place.third restriction addresses availability side-payments colluders (ortransferable utilities). Even rewards offered reputation mechanismmonetary, kind micro-payments would required among colludersdifficult expensive implement. Side-payments even less feasible rewardsoffered reputation mechanism kind, currency controlreputation mechanism (e.g., Yahoo points Slashdot karma cannot transferredeven users wanted to). conversion subjective resources real moneyafterwards transferred even difficult transfer itself.One notable exception side-payments feasible strategic entitycontrols number online identities, sybils (Cheng & Friedman, 2005). Here,controlling agent interested maximizing overall revenue (i.e., sum revenuesobtained sybils), side-payments physically occur7 .summarize, address collusion scenarios where:agents become part lying coalition,colluders coordinate using different strategies,colluders make side-payments colluders.remaining seven restricted collusion scenarios (see Table 1) addressing five. exclude settings utilities transferred coalitionrestricted symmetric strategies. discussed previous paragraph, transferableutilities mostly characteristic sybil attacks, strategic agent controlsseveral online identities. believe unreasonable assume strategic agentcannot coordinate online identities controls asymmetric strategy profiles.scenarios involving non-transferable utilities, collusion resistance emergeconsequence honest reporting (or attractive enough) equilibrium.7. Whenever rewards non-monetary, overall utility controlling agent usually lesssum utilities sybils. Slashdot, example, ten users bad karma worth oneuser good karma. Nevertheless, keep simplicity assumption additive utilitiescontrolling agent.219fiJurca & FaltingsagentscolludeagentscolludeNon-Transferable UtilitiessymmetricasymmetricstrategiesstrategiesSection 4.1Section 4.2Section 4.3Section 4.4Transferable Utilitiessymmetricasymmetricstrategiesstrategiesunreasonable impossibleassumptionprevent collusionunreasonableSection 4.5assumptionTable 1: Different collusion scenarios.agents may collude, honest reporting dominant equilibrium impossible.Therefore, resort designing reward schemes honest reporting uniqueNash equilibrium, Pareto-optimal Nash equilibrium. fraction agentsmay collude (non-colluders assumed report honestly) also consider designingrewards make honest reporting dominant strategy colluders. followingsubsections address one collusion scenario, describe possible methods designingcollusion-resistant, incentive-compatible reward mechanisms.4.1 Full Coalitions Symmetric Strategies, Non-Transferable Utilitiesassume agents (i) coordinate (before purchasesproduct) (pure) reporting strategy, (ii) cannot make side-paymentsone another. simple form coordination colluders considerably simplifiesproblem mechanism designer; supplementary constraint incentivecompatible payment mechanism ensure none pure symmetric strategyprofiles NE.4.1.1 Unique Nash equilibrium.set pure strategies finite (and contains 3 lying strategies) therefore exhaustively enumerate constraints prevent corresponding symmetric lying strategyprofiles NE:spos (always reporting 1) NE rational agent would rather report 0 instead1 given agents follow spos :(0, N 1) > (1, N 1);(6)sneg (always reporting 0) NE rational agent would rather report 1instead 0 given agents follow sneg ;(1, 0) > (0, 0);(7)slie NE least one agent (either observing 1 0) would rather reporttruth. Given agents always lie, N 1 n reference reportspositive whenever n high quality signals actually observed:220fiMechanisms Making Crowds TruthfuleitherN1XP r[n|0] (0, N 1 n) (1, N 1 n) > 0;n=0N1XP r[n|1] (1, N 1 n) (0, N 1 n) > 0;(8)n=0objective function (5), constraints (4), (6), (7) (8) define optimalincentive-compatible payment mechanism also collusion-resistant sense explained beginning section (i.e., honest reporting unique pure-strategysymmetric NE). compute payments, mechanism designer must solve two linearoptimization problems, one corresponding branch constraint (8).Proposition 4.1. Collusion-resistant, incentive-compatible rewards require minimum N =4 agents.Proof. Proposition direct consequence Proposition 3.1, considersupplementary constraints (7) (6) prevent high rewards unanimous agreement.discussed proof Proposition 3.1, incentive compatible reward mechanismrequires two distinct configuration reference reports denoted n1 n2 that:configuration n1 (i.e., n1 reference reports positive) agent reporting0 rewarded agent reporting 1: e.g., (0, n1 ) > (1, n1 )configuration n2 (i.e., n2 reference reports positive) agent reporting1 rewarded agent reporting 0: e.g., (1, n2 ) > (0, n2 )n1 < n2 (proven Lemma 3.1)collusion positive report (all agents report 1) prevented n2 6= N 1,otherwise (1, N 1) would greater (1, N 1), spos would NE.Likewise, collusion negative report (all agents report 0) preventedn1 6= 0 otherwise (0, 0) > (1, 0), sneg would NE. Unless N 4constraints n1 6= 0; n1 < n2 n2 6= N 1 cannot simultaneously satisfied.words, must exist rich enough set possible configuration reference reportsorder satisfy collusion resistance incentive compatible constraints.Taking plumber example described Section 2 N = 4 agents, conditionaldistribution reference reports computed according Eq. (1):01P r[0|]0.41790.0255P r[1|]0.22970.0389P r[2|]0.11680.2356P r[3|]0.23560.7experience negative, two types (G B ) become almost equally likelyagents private belief. mix distribution reference reports inducedtwo types generates U-shaped distribution described first rowtable. However, experience positive, good type becomes dominant,distribution reference reports almost entirely dictated P r[n|G ] (the second rowtable). optimal collusion-resistant, incentive-compatible payment mechanismfollowing:221fiJurca & Faltings(, )0100112.370206.2930small positive value, guaranteed margin truth-telling = 1.N > 4 payment mechanism looks rewards report oneagents agree submitted report. time, opposing consensusrewarded small amount .Payments exactly structure represent general solution designproblem context. Moreover, payments always exist:Proposition 4.2. Given set types , probability distributions P r[1|], prior belieftypes P r[], number agents N 4, following payment system honestreporting unique symmetric NE:(0, n) = 0, n 6= 1, N 1; (1, n) = 0, n 6= 0, N 2; (0, N 1) = (1, 0) =P r[1|1]P r[1|0]P r[1|1]P r[N 2|0]P r[N 2|1] conditionP r[1|0]P r[N 2|0]P r[N 2|1]P r[1|0]P r[1|1] condition B(0, 1) =P r[N 2|1]+P r[N 2|0]P r[1|0]Potherwiser[N 2|1]P r[N 2|0]P r[1|1]P r[N 2|1]P r[1|0]P r[1|1]P r[N 2|0]P r[N 2|1] conditionP r[N 2|0]P r[N 2|0]P r[Ncondition B(1, N 2) =2|1]P r[1|0]P r[1|1]P r[1|1]+P r[1|0]P r[1|0]P r[N 2|1]P r[N 2|0]P r[1|1] otherwiseP r[1|0]P r[1|1] > P r[N 2|0]P r[N 2|1]P r[N 2|1] > P r[1|1]A=P r[N 2|1]2 P r[1|1]2 > P r[1|0]P r[1|1] P r[N 2|0]P r[N 2|1]P r[N 2|0]P r[N 2|1] > P r[1|0]P r[1|1]^P r[1|0] > P r[N 2|0]B=P r[1|0]2 P r[N 2|0]2 > P r[N 2|0]P r[N 2|1] P r[1|0]P r[1|1]^Proof. straight-forward check small enough, payments describedproposition verify constraints (4), (6) (7). Moreover, payments minimizeexpected payment honest reporter.4.1.2 Pareto-optimal Nash equilibrium.less strict notion collusion resistance requires honest reporting Pareto-optimalNE. intuition stable (i.e., equilibrium) coalition necessarily makecolluders worse honest equilibrium. Assuming non-transferable utilities,colluders benefit coalition cannot subsidize ones make loss,hopefully, latter refuse join coalition first place. see towardsend subsection, payment mechanisms honesty Pareto-optimal NEsignificantly cheaper payments designed unique honest NE.payment mechanism honest reporting Pareto-optimal equilibriumsolves following optimization problem:222fiMechanisms Making Crowds TruthfulLP 4.1.N1N1hXXmin E V (si , si ) = P r[1]P r[n|1] (1, n) + P r[0]P r[n|0] (0, n);n=0s.t.N1Xn=0P r[n|1] (1, n) (0, n) ;n=0N1XP r[n|0] (0, n) (1, n) ;n=0(1, N 1) < E V (si , si ) ;(0, 0) < E V (si , si ) ;PN 1_n=0 P r[n|0] (0, N 1 n) (1, N 1 n) > 0PN 1P r[n|1] (1, Nn=0 lie1 n) (0, N 1 n) > 0lieE V (si , si ) < E V (si , si ) ;(0, n), (1, n) 0; n = {0, 1, . . . , N 1};first two constraints make honest reporting Nash equilibrium. next twoconstraints prevent lying colluders spos sneg get higher rewards honestequilibrium. constraints always easier satisfy constraints (6), (7)prevent equilibria spos sneg . last constraint requires symmetricprofile every agent lies either NE, generates expected payofflower honest equilibrium. expected payoff agent reporting accordingslie everybody else reports according slie is:1NXlieE V (slieP r[n|0]P r[0] (1, N 1 n) + P r[n|1]P r[1] (0, N 1 n) ;, si ) =n=0One remark LP 4.1 always optimal consider constraintlimits expected payoff colluder slie expected payoff obtainedhonest equilibrium (i.e., third inequality disjunctive constraint LP 4.1).Numerical simulations performed random problems show 40- 50% problemscollusion-resistant payments cheaper eliminating altogether symmetric lyingequilibrium slie : i.e., either first, second inequality last constraintLP 4.1 easier satisfy third inequality.either case, resulting optimal payments following structure:(0, 0) = (1, N 1) = E V (si , si ) . values prevent lying coalitionsspos sneg Pareto-dominate honest reporting equilibrium;(0, 1) > 0 (1, N 2) > 0 scaled satisfy incentive-compatibilityconstraints, easiest three inequalities prevent coalition slie ;payments 0.plumber example Section 2 payments following:(, )0101.30014.520223201.26301.30fiJurca & Faltingspayments much smaller ones generated mechanism honestreporting unique equilibrium. therefore observe fundamental tradeoffstrongness collusion resistance guarantees offered mechanism, pricemechanism pay enforce guarantees. collusion scenario describedsection, Proposition 4.2 shows always possible design mechanismhonest reporting unique equilibrium. Nevertheless, mechanism honestreporting Pareto-optimal, unique, significantly cheaper. seetradeoff subsequent scenarios.move next collusion scenario, let us briefly analyze influence N(i.e., number reports available mechanism) properties mechanism.Jurca Faltings (2006) show incentive-compatibility constraints easiersatisfy N becomes larger. Intuitively, property consequence structuredesign problem: number constraints LP 3.1 independent N , however,number variables increases N . Therefore, dual LP 3.1 constant numbervariables, increasing number constraints. Moreover, constraints dualalso harder satisfy, means maximization objective dualdecrease N . Hence objective primal, i.e., cost mechanism, alsodecreases N . Without going technical details, true collusionresistant mechanisms: larger values N , collusion-resistance constraints becomeeasier satisfy mechanism lower cost. subsequent sections maintainproperty: information helps mechanism designer specify better targetedrewards, turn decreases total cost mechanism.4.2 Full Coalitions Asymmetric Strategies, Non-Transferable Utilitiesnext collusion scenario considering N agents coordinateasymmetric collusion strategies, without able make side-payments oneanother. N agents different reporting strategy, collusionstrategy profile denoted = (si ), = 1, . . . , N , si reporting strategyagent i.distinguish two cases, communication (and therefore coordination collusion strategy profile) happens agents perceivequality signals product purchase. latter case, payment schemesatisfy incentive-compatibility constraints. former case, honest reportingnever unique Nash equilibrium mechanism; however, honest reportingPareto-optimal Nash equilibrium.Proposition 4.3. agents communicate coordinate reports perceivingquality signals, strict incentive-compatible payment mechanisms exist.Proof. Consider two settings, identical except observation agent i.setting I, agent observes oi = 0, setting II, agent observes oi = 1; settingsagents observe n high quality signals. incentive-compatible mechanism requiresreport 0 setting I, 1 setting II. Assume agents report truthfully;communication phase (happening signals perceived) agent learnssettings reference reports contain n positive reports. incentive-compatiblepayment mechanism requires that:224fiMechanisms Making Crowds Truthful(0, n) > (1, n) - honest reporting strictly better setting ;(1, n) > (0, n) - honest reporting strictly better setting II;Clearly impossible.previous proposition formalizes intuition truth-telling may exante Nash equilibrium. reference reports must unknown agent orderallow design incentive-compatible payments.4.2.1 Unique Nash equilibrium.communication takes place agents observe signals, incentivecompatible payments exist, always accept Nash equilibria agents lie:Proposition 4.4. agents communicate coordinate reports perceivingquality signals, payment mechanism unique honest reporting Nash equilibrium.Proof. proof shows full coalition always find profile constant reportingstrategies, = (si ), = 1, . . . , N , si {sneg , spos } NE.define family reporting strategy profiles s(n) = (si ) n N agentsalways report 1, N n agents always report 0: i.e.,si = spos , A1 ; si = sneg , A0 ;|A1 | = n, |A2 | = N n;A1 A0 = ; A1 A0 = {1, 2, . . . , N };(9)Assume payment mechanism defined (, ) accepts honest reportingunique NE. seen Section 3 incentive-compatible constraints (4)imply existence n1 < n2 {0, 1, . . . , N 1} (0, n1 ) > (1, n1 ),(1, n2 ) > (0, n2 ).non-transferable utilities, strategy profile s(n2 + 1) NEone n2 + 1 agents report 1 would rather report 0:(0, n2 ) > (1, n2 );one N n2 1 agents report 0 would rather report 1:(1, n2 + 1) > (0, n2 + 1);first inequality cannot true choice n2 ; therefore, must(1, n2 + 1) > (0, n2 + 1).Similarly, s(n2 + 2) NE iff either (0, n2 + 1) > (1, n2 + 1) (impossible),(1, n2 + 2) > (0, n2 + 2). Continuing argument find (1, N 1) > (0, N 1)makes s(N ) (i.e., agents report 1) Nash equilibrium. Hence resultproposition.Proposition 4.4 holds regardless number reports, N , available reputationmechanism. proof shows incentive-compatible reward schemes property n {0, . . . , N 1}, either (1, n) > 0 (1, n + 1) < (0, n + 1),225fiJurca & Faltings(1, N 1) > 0. first case, coalition adopt lying strategy n + 1agents always report 1, N n1 agents always report 0. structure paymentsmakes coalition stable, agent finds profitable deviate coalition.second case payment scheme vulnerable everybody always reporting 1.4.2.2 Pareto-optimal Nash equilibrium.lying equilibria always exist scenario, necessarily Pareto-dominatehonest reporting NE. Take example incentive-compatible payments solveLP 3.1, additional constraints (0, 0) = 0 (1, N 1) = 0. stablecoalition form strategy profiles s(n2 + 1) s(n1 ), n2 + 1 (respectively n1 )agents always report 1 others always report 0 regardless observation.equilibrium, however, Pareto-dominate truthful one: agents report 0get reward, whereas get rewarded honest equilibrium.payment mechanism improved setting (0, n1 1) = (1, n2 +1) =, small positive value. modification eliminates equilibria s(n2 + 1)s(n1 ) instead introduces equilibria s(n2 +2) s(n1 1). equilibriaextremely unattractive (some agents get paid , others dont get paid all)dominated honest equilibrium.Proposition 4.5. Given set types , conditional probabilities P r[1|], priorbelief types P r[], N = 4 agents, following payment scheme honest reportingPareto-optimal Nash equilibrium:(, )01001x>0020y>030values x depend probabilities P r[1|] P r[], small positivevalue.Proof. payments similar Proposition 4.2 except consensusrewarded small amount instead discouraged. way mechanismthree NE: honest reporting, always reporting 1 always reporting 0. lyingequilibria, however, generate much lower revenues (assuming, course, smallenough); therefore, honest reporting Pareto-optimal equilibrium. proofmechanism 3 NE based brute force: x taking values specifiedProposition 4.2, verify strategy profile NE. details presentedAppendix B.general reward mechanisms based N > 4 reports, honest reporting becomePareto-optimal NE considering lying strategy profiles, s, adding designproblem either following linear constraints:V (si , si |oi ) < V (si , si |oi ) i, oi si ;E V (si , si ) < E V (si , si ) i;(10)first constraint ensures strategy profile NE, consists disjunction 8 linear inequalities: reporting strategy si = (si (0), si (1)) S,226fiMechanisms Making Crowds Truthfulagent reporting according si incentive deviate either observing 0,observing 1. four strategies one possible deviationobserved signal, hence 8 inequalities. second constraint ensuresPareto-dominate honest equilibrium, consists similar disjunction 4inequalities. Note two strategy profiles represent different permutationsset N reporting strategies generate constraints. Therefore,N +3different constraints imposing honesty Pareto-optimal NE, consisting3disjunction 12 linear inequations. resulting optimization problemdisjunctive linear program transformed mixed integer linear program(Sherali & Shetty, 1980).Unfortunately, complexity resulting optimization problem exponentialnumber N reporters considered payment mechanism. Since paymentmechanism depends current belief types , reputation mechanism mightrequired frequently update payments order reflect changing beliefs.large values N clearly infeasible.therefore consider special family payment mechanisms designedefficiently make honest reporting Pareto-optimal NE. basic idea considerpayments similar Proposition 4.5, reward reportone reference reports agree. Consensus positive negative feedback alsorewarded small amount , payments zero:(, )01001x>002. . . N-30. . . 00. . . 0N-20y>0N-10Figure 1: Payment mechanism N > 4 agents.payment mechanism depends 2 parameters, x must scaledprevent lying strategy profile become NE Pareto-dominating honestequilibrium. Note strategy profile one agent reports accordingspos sneg become successful collusion strategy. least two agents alwaysreport 1, none agents ever want report 0 (as (0, n) = 0 n 2).Similarly least two agents always report 0, none agents ever wantreport 1. Nevertheless, consensus equilibria yield small payoffs, significantlylower payoff honest reporting equilibrium.Following intuition proof Proposition 4.5, many remaining lyingstrategy profiles cannot NE regardless values x y. Let us consider setpotential lying equilibrium strategy profiles:= {(n0 sneg , n1 spos , n s, nl slie )| n0 + n1 + n + nl = N };(11)n0 {0, 1} agents always report 0, n1 {0, 1} agents always report 1, n/ {N 1, N }agents report honestly nl agents always lie. cardinality 4(N 1). profileNE strategy si s, agent reporting according siincentive deviate another reporting strategy given agentskeep reporting according si . Let oi Q2 signal observed agent i. report227fiJurca & Faltingsprescribed strategy si ri = si (oi ) Q2 , given small enough ignored,expected payoff agent is:P r[1|oi , si ] x ri = 0P r[N 2|oi , si ] ri = 1P r[1|oi , si ] P r[N 2|oi , si ] probabilities exactly 1, respectivelyN 2 N 1 agents report positively given observation oistrategy profile si .deviation reporting 1 ri profitable observation oi if:P r[1|oi , si ] x P r[N 2|oi , si ] > 0 ri = 0P r[N 2|oi , si ] P r[1|oi , si ] x > 0 ri = 1conditions make NE therefore expressed set 8inequalities following structure:aj x bj > 0; aj , bj > 0ak x + bk > 0; ak , bk > 0bmaxj ajj > mink abkk system inequations infeasible, positivevalues x corresponding strategy profile NE. However,bmaxj ajj < mink abkk , values x make NE, therefore,design problem must specify constraint prevents Pareto-dominatinghonest NE. corresponding constraint disjunction inequalities: 2restricting x values make NE, 3 limit expectedpayments colluders expected payment honest equilibrium.Since 4(N 1) potential lying strategy profiles, optimization problemdefining x 4N 2 constraints: 2 linear incentive-compatible constraints4(N 1) disjunctive linear constraints. transformation mixed integerlinear program involves adding 4(N 1) integer variables, worst case,result exponential-time (in N ) complexity design problem.Fortunately, eliminate strategy profiles analytically. turnspayment mechanism Figure 1 accept Nash Equilibriumstrategy profile lest one agent reports truthfully another agent reportsaccording slie :Proposition 4.6. Let = (n0 sneg , n1 spos , n s, nl slie ) strategy profilen0 agents always report 0, n1 agents always report 1, n agents report honestly nlagents always lie. (n 6= 0 nl 6= 0) (n0 = 1 n1 = 1), cannot Nash equilibriumpayment mechanism described Figure 1.Proof. reasons explained above, restricted number agents alwaysreporting 0 1 following cases: (i) n0 = 0, n1 = 0, (ii) n0 = 1, n1 = 0, (iii)n0 = 0, n1 = 1 (iv) n0 = 1, n1 = 1. cases, consider strategy profilesn 1 agents honest, remaining agents lie according slie . profileshow values x simultaneously satisfy equilibrium constraintshonest lying agent. Moreover, n0 = n1 = 1 show strategy228fiMechanisms Making Crowds Truthfulprofiles agents honest agents lie, cannot Nash equilibria.technical details proof given Appendix C.remaining lying strategy profiles considered computing values xfollowing:s1 = (N slie ) agents lie; constraints prevent equilibrium alsoconsidered LP 4.1;s2 = sneg , (N 1) slie one agent always reports 0, agents lie;s3 = spos , (N 1) slie one agent always reports 1, agents lie;solution x therefore found constant time.4.3 Partial Coalitions Symmetric Strategies, Non-Transferable Utilitiessection move attention full partial coalitions, agentsbecome part lying coalition. non-colluders assumed report honestly,reports used mechanism deter partial lying coalition. JurcaFaltings (2005) show trusted reports (reports trusted true) usefulpreventing lying coalitions; nevertheless, important difference previous work,here, honest reports cannot identified selectively used reputationmechanism.4.3.1 Unique Pareto-otpimal Nash equilibrium.start Section 4.1, assuming symmetric collusion strategies sidepayments available among colluders. number colluders Ncol < N , remaining N = N Ncol report honestly. 3 symmetric pure lying strategies,appropriate constraints ensure none becomes Nash equilibrium,Pareto-dominates honest equilibrium.Concretely, let Pr[|] probability distribution reports submitted noncolluders, Pr[n|oi ] probability n N agents report positively givenobservation oi Q2 . Likewise, let Pr[|] probability distribution reportssubmitted colluders: i.e., Pr[n|oi ] probability n Ncol 1colluders report positively.payment scheme makes honest reporting unique Nash equilibriumcolluders minimizes expected payment honest reporter solves followingoptimization problem:229fiJurca & Faltingsmins.t.E V (si , si ) ;NXP r[n|0] (0, n) (1, n) ;n=0NXP r[n|1] (1, n) (0, n) ;n=0N_ Xoi Q2n=0N_ Xoi Q2Pr[n|oi ] (0, n) (1, n) < 0n=0N_ Xoi Q2Pr[n|oi ] (1, n + Ncol 1) (0, n + Ncol 1) < 0Pr[n|oi ]n=0Ncol 1XPr[Ncol 1 x|oi ] (1 oi , n + x) (oi , n + x) < 0x=0(0, n), (1, n) 0; n = {0, 1, . . . , N 1};besides first two incentive-compatibility constraints, third, forth fifthconstraints encourage deviations symmetric collusion spos , sneg slie respectively. resulting optimization problem disjunctive linear program.Finally, honest reporting made Pareto-optimal equilibrium modifyingoptimization problem disjunctive constraints preventing equilibriumlying symmetric strategies, also specify inequalities limiting payoff receivedcolluder expected payment honest reporter:colluders spos gain less honest equilibrium:NXPr[n|oi ] (1, n + Ncol 1) < E V (si , si ) ;n=0colluders spos gain less honest equilibrium:NXPr[n|oi ] (0, n) < E V (si , si ) ;n=0colluders slie expect gain less honest equilibrium:Xoi =0,1P r[oi ]NXn=0Pr[n|oi ]NXcol 1Pr[Ncol 1 x|oi ] (1 oi , n + x) < E V (si , si ) ;x=0numerical simulation show optimization problem defined alwaysaccepts solution. therefore conjecture always possible design incentivecompatible, collusion resistant rewards restrictions discussed section.formal proof result remains future work.4.4 Partial Coalitions Asymmetric Strategies, Non-Transferable Utilitiesopposed Section 4.3, section consider practical scenariocolluders also employ asymmetric lying strategies: i.e., strategy profiles = (si ),230fiMechanisms Making Crowds Truthful= 1, . . . Ncol . Side payments allowed among colluders, concernedequilibrium Ncol agents become part coalition; remainingN = N Ncol agents assumed report honestly.4.4.1 Unique Pareto-optimal Nash equilibrium.mechanism makes honest reporting Nash equilibrium follows guidelines derived Proposition 4.5 scenario agents collude: namelyreputation mechanism must consider N = 4 reports, mechanism rewards consensussmall positive payment , otherwise pays report threefour reports agree. proof Proposition 4.5 shows payment scheme acceptsthree Nash equilibria:agents report honestly,agents always reports 0,agents always report 1..restriction made section least one become partcoalition (and thus reports truth) restricts set equilibria one,agents report truthfully. Even remaining three agents collude, NEpayment mechanism described Proposition 4.5 report truth.General payment mechanisms based N > 4 agents designed followingmethodology Section 4.2: consider strategy profiles colludersuse, add constraints design problem (i) lying strategy profileNE, (ii) NE lying strategy profile Pareto-dominates honest reporting NE.Concretely, let SNcol set strategy profiles colluders use:SNcol = {(n0 sneg , n1 spos , n s, nl slie )|n0 + n1 + n + nl = Ncol }= (n0 sneg , n1 spos , n s, nl slie ) SNcol strategy profile n0Ncol colluders always report 0, n1 colluders always report 1, n colluders report honestly,nl colluders always lie. colluders report according strategy profile s, let(s, s) = (n0 sneg , n1 spos , (n + N ) s, nl slie ) strategy profile used Nagents, N = N Ncol non-colluders report honestly.Honest reporting unique Nash equilibrium colluders if:V si , (si , s)|oi < V si , (si , s)|oi(12)colluder observation oi . Similarly, Pareto-dominate honestreporting equilibrium if:hE V si , (si , s) < E V (si , si )(13)colluder i.Lets compare constraints expressed similar constraints Section4.2 described Eq. (10). note two important differences. First, inequalities apply231fiJurca & FaltingsNcol colluders, entire set agents, strategy profileNE N agents, might still Nash equilibrium colluders. Take,example, case colluders lie: i.e., = (Ncol slie ). strategy profileagents therefore (s, s) = (Ncol slie , N s). may well possible that:lying colluder finds optimal report according slie given N agents reporthonestly Ncol 1 agents report lies;honest reporter would rather file negative report positive experience, givenN 1 agents report honestly Ncol agents lie.(s, s) NE considering agents, equilibrium subsetcolluders. Similarly, possible colluders gain better (s, s) honest reportersgain less, (s, s) Pareto-dominates honest equilibrium colluders,agents. constraints (12) (13) therefore stricter counterparts(10), non-colluders assumed unconditionally report truth without takingaccount actions lying coalition.Second, separately consider constraint (12), honest reportingenforced unique NE colluders, disjunction constraints (12) (13),honest reporting enforced Pareto-optimal NE colluders. presencehonest reports makes possible design payment mechanisms honestyunique NE, alternative available assumptions Section 4.2.cases, constraints preventing lying equilibria (or preventing lying equilibriadominating honest equilibrium) represented disjunction linear inequalities,consequently, conjunction mixed integer linear constraints. resulting designproblem MILP, and, discussed Section 4.2, worst-time complexity growsexponentially number N agents.Section 4.2, use payment mechanism Figure 1 reducecomplexity design problem honest reporting unique Pareto-optimalNE. Proposition 4.6, know that:NE, one colluder reports according sneg spos ;honest reporter liar cannot regard strategies optimal givenone agents reports according sneg sposTherefore, remaining colluding strategy profiles must considered designing payments x following:(Ncol slie ) colluders lie;(sneg , (Ncol 1) slie ) one colluder always reports 0 others always lie;(spos , (Ncol 1) slie ) one colluder always reports 1 others always lie;232fiMechanisms Making Crowds Truthful4.4.2 Stronger equilibrium notion.evaluating reward mechanisms accepts unique Pareto-optimal honestreporting Nash equilibrium, let us note subgame restricted strategiesNcol colluders accepts stronger equilibrium concept Nash equilibrium.fraction colluders small enough, available honest reports makecolluder incentive report honestly matter colludersreporting. abuse notation slightly call equilibrium dominant equilibrium.Nevertheless, honest reporting dominant strategy given N honest reporters.Pr[|] describes probability distribution N honest reports, cnumber positive reports submitted Ncol 1 colluders, payments (, )make honest reporting dominant strategy, minimize payment honestreporter, defined following optimization problem:LP 4.2.N1N1XXmin E V (si , si ) = P r[1]P r[n|1] (1, n) + P r[0]P r[n|0] (0, n);n=0s.t.NXn=0Pr[n|0] (0, n + c) (1, n + c) ;n=0NXPr[n|1] (1, n + c) (0, n + c) ;n=0c {0, . . . Ncol 1},(0, n), (1, n) 0; n = {0, 1, . . . , N 1};remaining question large may colluding fraction be, collusionresistant, incentive-compatible mechanisms exist.Proposition 4.7. half agents collude, (i.e., Ncol > N/2),incentive-compatible payment mechanism make truth-telling dominant strategycolluders.Proof. intuition behind proof following: Ncol > N/2, Ncol 1colluders submit least many reports remaining N Ncol honest reporters.Therefore, sequence honest reports, corrected carefully chosen sequencecolluding reports, lying profitable.Formally, let us extract system inequalities defined LP 4.2, subsetcorresponding c = {0, . . . , N }. subset exists since N < Ncol 1. Let us form233fiJurca & Faltingsfollowing optimization problem:minP r[1]N1XP r[n|1] (1, n) + P r[0]n=0NXs.t.N1XP r[n|0] (0, n);n=0Pr[n|0] (0, n + c) (1, n + c) ; c = 0 . . . Nn=0NXPr[n|1] (1, n + c) (0, n + c) ; c = 0 . . . Nn=0(0, n), (1, n) 0; n = {0, 1, . . . , N 1};Let yc0 yc1 dual variables corresponding constraints colludingagents report c positive signals, agent observes 0, respectively 1. dual problembecomes:Ncol 1maxX(yc0 + yc1 );c=0s.t.nXc=0nXPr[n c|0]yc0 Pr[n c|1]yc1 P r[0]P r[n|0]; n = 0 . . . NPr[n c|1]yc1 Pr[n c|0]yc0 P r[1]P r[n|1]; n = 0 . . . Nc=0NXPr[N + 1 c|0]yc0 Pr[N + 1 c|1]yc1 P r[0]P r[N + n + 1|0]; n = 0 . . . Nc=n+1NXPr[N + 1 c|1]yc1 Pr[N + 1 c|0]yc0 P r[1]P r[N + n + 1|1]; n = 0 . . . Nc=n+1One easily verify dual problem accepts solutions:yc1 = Pr[c|0] const,yc0 = Pr[c|1] const;(14)positive constants. dual problem therefore unbounded, makesprimal infeasible.bound Proposition 4.7 also tight. Consider numerical example Section 2, assume reputation mechanism N = 4 reports. following paymentsresistant collusion Ncol = 2 agents:(, )0101.575013.5750202.203300.943example, Alice observes 1, reporting 1 better reporting 0 reportcolluder:Pr[0|1] (1, 0) + Pr[1|1] (1, 1) + Pr[2|1] (1, 2) = 1.715;Pr[0|1] (0, 0) + Pr[1|1] (0, 1) + Pr[2|1] (0, 2) = 0.715;Pr[0|1] (1, 1) + Pr[1|1] (1, 2) + Pr[2|1] (1, 3) = 1.138;Pr[0|1] (0, 1) + Pr[1|1] (0, 2) + Pr[2|1] (0, 3) = 0.138;234fiMechanisms Making Crowds TruthfulPr[0|1] = 0.0385, Pr[1|1] = 0.1830 Pr[2|1] = 0.7785 probabilities0, 1, 2 N = 2 non-colluders report positively, given Alice observed highquality.general case, design problem 2Ncol different constraints, therefore,expect budget required reputation mechanism grow Ncol .resort numerical simulations study average cost incentive-compatible,collusion-resistant reputation mechanism fraction colluders increases. randomlygenerated 5000 problems follows:set possible types randomly chosen 2 20;type, , probability, P r[1|], buyers observe high qualityrandomly chosen 0 1;consider reward mechanisms 5, 10, 15, 20 25 agents.problem every number agents varied number colluders 1N/2. Figure 2 plots average normalized cost collusion-resistant mechanismfunction colluding fraction, Ncol /N . One see collusion resistance comesalmost free long less one third population colludes. boundcost increases exponentially, makes mechanisms impractical.average normalized cost15N=10N=15N=20N=25105000.10.20.3colluding fraction0.40.5Figure 2: average cost mechanism increase colluding fraction. costnormalized cost corresponding incentive-compatible mechanismcollusion-resistant.Figure 2 seems contradict observation made Section 4.1 mechanismlower cost higher values N . However, costs plotted235fiJurca & Faltingshorizontal axis describing absolute (not relative) number colluders, orderlines reversed: red line showing cost mechanism smallest numberreference reports (N = 10) highest values.also used numerical simulations investigate tightness bound setProposition 4.7. Table 2 presents distribution maximum collusion thresholdrandomly generated problems. 95% problems actually ablemax = bN/2ccompute payment mechanisms resist maximum coalition size Ncoldescribed Proposition 4.7. settings, however, mechanismvulnerable coalition fractions significantly smaller one half. sufficientconditions characterize settings accept robust mechanisms exactly onehalf colluders subject future research.max = bN/2c.Table 2: Distribution maximum coalition bound. Ncolmax = 2N = 5, Ncolmax = 5N = 10, Ncolmax = 7N = 15, Ncolmax = 10N = 20, Ncolmax = 12N = 25, NcolDistribution max coalition size (in %)max , N max 1, . . . , 1][Ncolcol[99.98, 0.02][99.5, 0.36, 0.1, 0.04, 0][98.88, 0.54, 0.38, 0.08, 0.1, 0.02, 0][97.1, 0.86, 0.78, 0.56, 0.34, 0.2, 0.1, 0.04, 0.02, 0][96.3, 0.98, 0.76, 0.58, 0.48, 0.4, 0.24, 0.1, 0.1, 0.04, 0.02, 0]also compared performance reward mechanisms employ differentequilibrium concepts. Figure 3 compares average normalized cost collusion-resistantpayment mechanism honest reporting is: (i) dominant strategy, (ii) uniqueNE, (iii) Pareto-optimal NE. plots generated solving 100 randomlygenerated problems, N = 10 N = 15 agents. Computing payment mechanismsatisfies constraints (12) (13) requires significantly time, hencelower number generated problems. Moreover, capabilities solver exceededpayments using 15 agents. Nevertheless, loss computational efficiencyclearly rewarded lower cost mechanism, coverage greater coalitions.4.5 Partial Coalitions Asymmetric Strategies, Transferable Utilitieslast scenario assume one strategic agent controls number fake onlineidentities, sybils. agents perspective, individual revenues obtainedsybil irrelevant; objective agent maximize cumulated revenue obtainedsybils.fact utilities transferable makes problem mechanism designersignificantly harder. previous scenarios, constraints made incentivecompatible mechanism collusion-resistant ensured lying coalitions either unstableunprofitable. However, transferable utilities allow colluders subsidize others,non-equilibrium colluding strategies still exist. Therefore, necessary (andsufficient) condition collusion resistance context requires cumulatedrevenue coalition maximized reporting truth.236fiMechanisms Making Crowds Truthful2.52.2Dominant EQUnique NEQParetooptimal NEQ2average normalized costaverage normalized cost2Dominant EQUnique NEQParetooptimal NEQ1.511.81.61.41.210.80.60.5123456number colluders7892(a) N=10 agents46810number colluders1214(b) N=15 agentsFigure 3: Average normalized cost collusion-resistant payment mechanism. Differentequilibrium concepts.Another difference settings Sections 4.2 4.4 colluders coordinatereporting strategy observing quality signals. assumption supportedinterpretation one strategic entity controls several fake online identities.Concretely, looking payment mechanism following property: whenever Ncol colluding agents observe c high quality signals, cumulated revenue maximized reporting c positive reports. underlying assumption non-colluders(the N = N Ncol agents) reporting honestly. revenue coalitionreports r (out Ncol ) computed follows. r colluders report positivelyrewarded (1, r 1 + n), Ncol r colluders report negatively rewarded(0, r + n); n number positive reports submitted (honest) non-colluders.expected revenue coalition therefore:V (r|c) =NXPr[n|c] r (1, r 1 + n) + (Ncol r) (0, r + n) ;(15)n=0Pr[n|c] probability n N honest agents report positively, givenc Ncol colluders observed high quality signals.Honest reporting best strategy coalition, c {0, . . . Ncol },arg maxr V (r|c) = c:NXn=0Pr[n|c] c (1, c 1 + n) + (Ncol c) (0, c + n) r (1, r 1 + n)(16)(Ncol r) (0, r + n) ; r 6= c {0, . . . Ncol }cheapest incentive-compatible, collusion-resistant payment mechanism minimizesobjective function (5) linear constraints (16):237fiJurca & FaltingsLP 4.3.N1N1hXXmin E V (si , si ) = P r[1]P r[n|1] (1, n) + P r[0]P r[n|0] (0, n);n=0s.t.n=0(16) true, c, r {0, . . . Ncol }, c 6= r(0, n), (1, n) 0; n = {0, 1, . . . , N 1};example described Section 2, assuming Alice controls Ncol = 3 differentonline identities may submit feedback Bob, following payments basedN = 6 reports deter Alice lying:(, )01020.8545.541028.7820030044.40059.984.31Even Alice controlled Ncol = 5 N = 6 reports, still find paymentsmake honest reporting rational. payments, however, significantly higher:(, )0103455153010556921378467436153736400511252585turns general case, one honest report enough allow designincentive-compatible payments also deter sybil attacks size N 1. examplepayments presented proposition below:Proposition 4.8. Given set types , conditional probabilities P r[1|], priorbelief types P r[] number N reports, following payments encourage honestreporting strategic agent controls N 1 different reports:SR(0, 0)SR(1, 0)SR(1, N 1); (0, 1) =; (1, N ) =;NcolNcolNcol(x + 1)SR(1, x) xSR(0, x + 1)(0, x + 1) =; x = 1...N 1Ncol(N 1 x)SR(0, x + 1) (N 2 x)SR(1, x)(1, x) =; x = 1...N 1Ncol(0, 0) =SR(i, j), {0, 1}, j = {0, . . . , N 1} proper scoring rule: e.g., SR(i, j) =log(Pr[i|j]).Proof. expected payment agent controls N 1 different identities, observesc N 1 positive signals reports r positive reports reputation mechanismcomputed Eq. (15):V (r|c) = P r[0|c] r (1, r 1) + (N 1 r) (0, r) +P r[1|c] r (1, r) + (N 1 r) (0, r + 1)= . . . = P r[0|c]SR(0, r) + P r[1|c]SR(1, r);238fiMechanisms Making Crowds Truthfuldefinition proper scoring rule strictly maximized r = c: i.e.V (c|c) V (r|c) > 0 r 6= c. scaling scoring rule appropriately (i.e., multiplication addition constant), honest reporting made better lyingleast margin .Proposition 4.8 grantees existence incentive-compatible collusion resistant rewardsone report controlled strategic agent. However, seenexample Section 2, payments expensive, hence unpractical.therefore used numerical simulations evaluate marginal cost increasing collusionresistance, increase number colluders (i.e., reports controlled agent).Section 4.4, generated 5000 random problems computed optimal paymentsN = 5,10,15,20 25 reports. case, gradually increased coalition size(i.e., Ncol ) 1 N 1.Figure 4 plots average normalized cost collusion-resistant mechanismfunction coalition fraction. cost grows exponentially coalition fractioncovers one half entire population. behavior also observed Section 4.4 evaluated cost incentive-compatible, collusion-resistant mechanismsabsence transferable utilities (Figure 2). However, payments requiredassumption non-transferable utilities significantly smaller payments derivedsection settings transferable utilities.average normalized cost15N=10N=15N=20N=25105000.20.40.6colluding fraction0.81Figure 4: average cost mechanism increase colluding fraction (settingtransferable utilities). cost normalized cost correspondingincentive-compatible mechanism collusion resistant.239fiJurca & Faltingsmechanisms defined present previous sections assume mechanism designer knows total number colluders. Formally, mechanism designedrobust collusion Ncol agents necessarily robust coalitionsizes smaller Ncol . Take example mechanism defined Proposition 4.8:strategic agent controls less N 1 identities observes less N 1 qualitysignals, therefore less precise beliefs signals received (and reported)non-colluders. noisy beliefs make cases, smaller coalitionmay regard certain lying strategy profitable honest reporting. onecaveat, however: colluders know lying strategy provably inefficientaccess information (i.e., remaining N 1 reports). therefore believe practical purposes, mechanism designed robust Ncolcolluders effectively deter coalitions smaller Ncol .5. Related WorkOne interesting alternative payment schemes encourage honest feedback developmechanisms make best interest providers truthfully reveal hiddenquality attributes. truthful declaration quality eliminates need reputationmechanisms significantly reduces cost trust management.Braynov Sandholm (2002), example, consider exchanges goods moneyprove market agents trusted degree deserve trustedequally efficient market complete trustworthiness. scaling amounttraded product, authors prove possible make rational sellerstruthfully declare trustworthiness. However, assumptions made tradingenvironment (i.e. form cost function selling price supposedsmaller marginal cost) common electronic markets.Another interesting work addresses trustworthiness reputation informationGoodwill Hunting mechanism Dellarocas (2002). mechanism works eBay-likemarkets provides way make sellers indifferent lying truthfully declaringquality good offered sale. particularity work goodsadvertised buyers reputation mechanism, modify askingprice initially set seller. reputation mechanism thus compensates momentarygains losses made seller misstating quality good, createsequilibrium sellers find rational truthfully announce quality. majoradvantage mechanism works even sellers offer various goodsdifferent values.Mechanisms encouraging honest reporting also present number commercialapplications. famous perhaps ESP Game (von Ahn & Dabbish, 2004),designed encourage human users label web images. game8 pairs two usersrandom, shows image. player must individually write tagsimage, without able see tags written partner. soon twoplayer write tag, gain points pass next picture. goalget many points possible fixed amount time. Intuitively, gamesimple strategy: players must write many correct tags possible, since image8. http://www.espgame.org240fiMechanisms Making Crowds Truthfulsee synchronization device allows reach agreement tag.game successful, authors claim way, images webtagged several months.incentive mechanism behind ESP game has, however, several problems. First,vulnerable cheating strategies group players agree reach agreementsimple tag like the. strategy could posted popular blogexposed rapidly ESP players. simple collusion strategies give colluderssignificant competitive advantage, detriment game designers collectgarbage tags. problem partly addressed taboo lists containingconfirmed tags already submitted picture.second problem rewards equal possible tags. Picasso,players match tag painting equally rewarded players correctlyidentify painting Picasso. gives incentives players concentratesimplest possible tags like person, man, woman, etc, without spending effortprovide informative tags. problem partly corrected GoogleImage Labeler9 , franchise ESP Game, rewards players inversely proportionalfrequency tag agree on. However, exact algorithm computingrewards public. Yahoo! also known use version ESP Game tagcollection images.Another example commercial application using payment mechanisms encouragehonest reporting Amazons Mechanical Turk10 . role system providemarketplace human users solve tasks difficult machines,easy people (i.e., short translations, tagging, face recognition, natural language search,etc). Task owners pay workers answering tasks, also specifypayment rules: e.g., worker gets paid (or receives bonus) answer confirmeddifferent worker solving task.number feedback forums reward raters independently based impactreviews users. ePinion.com, example, professional reviewers getpaid depending votes expressed normal users, purchases madereading reviews. Another example startup Friend2Friend.com11 allows usersgain commissions recommending products friends.Central results paper principle automated mechanism design(AMD). mechanism created automatically (using optimization algorithms)specific problem instance, given specific information available mechanism designer. idea important advantages since (a) used address classesproblems known manually designed mechanisms, (b) circumvent impossibility results restricting mechanism one particular setting, (c)generate better mechanisms capitalizing specific information availablepresent setting, (d) shifts effort mechanism design machine.Since first introduced Conitzer Sandholm (2002), AMD used generateseveral impressive results. Conitzer Sandholm (2003a) (a) reinvented Mayersonauction maximizes sellers expected revenue single-object auction, (b) created9. http://images.google.com/imagelabeler/10. http://www.mturk.com/mturk/welcome11. http://www.friend2friend.com/241fiJurca & Faltingsexpected revenue maximizing combinatorial auctions, (c) created optimal mechanismspublic good problem. Guo Conitzer (2007) use AMD optimally redistributepayments generated VCG mechanism, Conitzer Sandholm (2007) incrementallydesign incentive compatible mechanisms, Hajiaghayi, Kleinberg, Sandholm (2007)focus AMD online settings. Conitzer Sandholm (2003b) show AMDpotentially exponentially faster settings structured preferences allowconcise representation input. Conitzer Sandholm (2004) describe efficientalgorithm AMD mechanism deterministic, allow paymentsone type-reporting agent. AMD also used design multi-stage mechanismsreduce burden information elicitation querying agents relevantinformation (Sandholm, Conitzer, & Boutilier, 2007). results paper addalready long list results obtained AMD.results Section 4 mostly related literature implementation theoryincentive contracts principle-(multi)agent settings. main goal implementation theory characterize space social choice rules implementablemechanism given game-theoretic equilibrium concept. complete information settings, well established results characterize necessary sufficient conditions socialchoice rule (SCR) implementable dominant strategy Nash equilibrium.example, SCRs implemented dominant strategies strategy-proof(Gibbard, 1973), SCRs Nash-implemented must satisfy propertymonotonicity veto power (Maskin, 1999). Unfortunately, SCRs practical interest satisfy monotonicity requirement. Fortunately, non-monotonic SCRsimplemented undominated Nash equilibria (Palfrey & Srivastava, 1991), subgameperfect equilibria multi-stage mechanisms. Another relaxation extends setimplementable SCRs consider virtual implementation, socially optimal outcome required occur probability close one (Matsushima, 1988; Abreu &Sen, 1991).environments incomplete information agents private informationshared agents. truthful revelation private informationensured social choice rules Bayesian incentive-compatible. Moreover, Bayesianmonotonicity condition necessary Bayesian implementation (Jackson, 1991). MooreRepullo (2005) characterize SCRs virtually Bayesian implemented purestrategies, derive necessary sufficient conditions incentive compatibilityvirtual monotonicity.However, applying implementation theory feedback reporting setting (anenvironment incomplete information) provides nothing constraintspayment function honest reporting unique Bayesian Nash equilibrium.implementation theory terms, set possible world states consists combinationsN privately perceived quality signal (one signal agent). outcome spacecontains possible sets N feedback reports possible combinations N positivepayments made N agents. desirable SCR contains social choice functionsmap possible states world (i.e., set privately perceived signals)outcomes reported feedback correspond privately perceived signals).Implementation theory tells SCR must incentive compatible (i.e., socialchoice functions prescribe outcomes payments agents make truthfully242fiMechanisms Making Crowds Truthfulreveal private information) Bayesian monotone (i.e., social choice functionsprescribe outcomes payments received agents make honest reportingunique equilibrium). results Section 4 translate requirements practicalconstraints allow computation payment functions (and therefore social choicefunctions) Bayesian Nash implementable.number papers discuss incentive contracts principal offer severalagents whose effort levels private. reward received agent dependsoutput observed principal, declarations agents. Holmstrom(1982), (1988), Li Balachandran (2000) show efficient contracts existalso incentive-compatible collusion-proof. feedback reporting problemsimilar, differs one major aspect: reputation mechanism designer (i.e., principal)observe direct signal correlated reporters (i.e., agents) privateinformation.6. Discussion Future WorkThroughout paper considered pure reporting strategies. Extending resultsmixed -strategy equilibria remains open question, poses non-trivial computationalproblems: constraints required prevent mixed equilibria longer linear,significantly increases complexity design problem.paper limit investigation binary settings quality signalobserved agents feedback reported reputation mechanism either 01. extension n-ary feedback conceptually straight-forward (see AppendixD), resulting mechanism design problem becomes exponentially complexincrease number possible feedback values. remains challenge future workdesign efficient algorithms able quickly compute incentive-compatiblecollusion-resistant reward mechanisms non-binary feedback.Another challenge relax requirement common prior information. modelintroduce Section 2 assumes agents share prior beliefs regardingprobability positive negative feedback. Jurca Faltings (2007b) show incentivecompatible reward schemes still designed agents small amounts privateinformation. However, methodology cannot easily extended also addresscollusion.Yet another direction future research design payment mechanismsresistant complex collusion scenarios, where, example, several strategicagents, controlling several fake identities, try manipulate reporting mechanism.believe, however, many practical scenarios techniquespresented paper successfully used ensure safety collusion. Oneexample monitoring service quality. Jurca, Binder, Faltings (2007) describeframework monitoring quality web service based client feedback. ideaestimate quality delivered service provider directly reportsclients. approach much cheaper precise compared traditionalmonitoring devices proxy analyze communication clientserver. Nevertheless, mechanism must provide incentives honest reportingalso discourage lying coalitions. feedback settings often binary, specifies243fiJurca & Faltingswhether certain service level agreements (SLA) met provider.quality provider defined capacity fulfill SLA, usually becomespublic information. quality time defines priors designing mechanismtime + 1, quite natural majority clients consider priorspublic knowledge.Many tasks Amazons Mechanical Turk also fit model used paper.example, certain tasks ask human raters specify whether two descriptions referitem not. tasks, raters must vote thumbs piece news,must tag photographs contain certain visual clue, human face. answertasks modeled binary feedback signal (e.g., itemsnot, positive negative vote, photograph contains human face) answersdifferent users may considered conditionally independent given descriptiontask. Moreover, conditional probabilities may quite often assumed commonknowledge: example, assumption 98% raters correctly identifyhuman face decent quality photograph, natural, also likelybelief internet-savvy humans.generally, believe techniques useful providing incentives humanraters label training data supervised machine learning algorithms. Many practicalclassifiers binary (e.g., photograph contains certain feature, word misspelled not) composed binary classifiers (e.g., recognizing hand-writtendigit). framework similar Mechanical Turk harvest power crowdsproduce extensive training sets different algorithms.Another potential application collaborative question answering forums likeYahoo! Answers. forums users may post questions remain open predefinedperiod time. period, users write new answers, vote existinganswers. voting mechanism essential differentiating good bad answers,proper incentives may ensure higher participation accurate results.forums especially vulnerable collusion, since author providing best answeroften rewarded forum points, public recognition, benefits. biggestchallenge contexts obtain accurate estimates different probabilitiesenter design problem. example, prior probability high quality answerestimated history site. hand, conditional probabilityuser find given answer high quality complicated estimate. example,mechanism designer might use natural language processing algorithm figuredegree matching question answer. designer could also searchdocuments contain keywords related question answer, analyzedocuments refine matching degree answer given question. Generaluser statistics also factored estimate likelihood random user findgiven answer useful. Although estimates inevitably noisy, might workwell enough average user.results fully extended feedback sets arbitrary size, techniquespaper relevant feedback reporting scenarios. mention onesupplementary examples, ESP game, every photo tag assumed drawnfinite set concepts, conditional probabilities seeing certain tag244fiMechanisms Making Crowds TruthfulNon-Transferable Utilitiessymmetricasymmetricstrategiesstrategiesagentscolludeagentscollude-unique honest NE;-Pareto-optimalhonest NE-unique honest NE;-Pareto-optimalhonest NE-Pareto-optimalhonest NE-unique honest NE;-Pareto-optimalhonest NE;-sometimes honestdominant strategy);(not Ncol N2Transferable Utilitiessymmetricasymmetricstrategiesstrategiesunreasonableassumptionimpossible prevent collusionunreasonableassumption-(sybilattack),coalitionmaximizes revenue reportinghonestly;Table 3: Summary results.estimated using word frequencies different languages, image recognition techniques,historical data regarding distribution tags similar photos.7. Conclusiononline feedback reputation become increasingly important sources information,explicit measures must guarantee honest reporting best interest participants. Previous work shows possible construct payment mechanismsmake honest reporting Nash equilibrium, agents expect get rewardedtruthful report lie. Unfortunately, mechanisms also equilibriareporters lie. creates collusion opportunities, since several agents coordinatelies order improve revenues.paper addressed design incentive-compatible payments alsoresistant collusion. consider different collusion scenarios (i)agents collude, (ii) colluders coordinate symmetric asymmetric strategyprofiles, (iii) colluders transfer payments other. Table 3 summarizesresults obtained scenario.Section 4.1 assume agents may collude cannot make side-paymentsother. showed incentive-compatible payments efficiently constructedhonest reporting unique pure strategy symmetric NE, Pareto-optimalpure symmetric NE. Section 4.2 keep assumptions, investigate asymmetric collusion strategies. find incentive-compatible payment mechanism alsoaccepts asymmetric lying equilibria. Nevertheless, payment mechanismshonest reporting Pareto-optimal NE.Sections 4.3 4.4 assume fraction agents may collude, noncolluders report honestly. colluders coordinate symmetric strategy profilescannot make side-payments other, payments always exist honestreporting made unique NE (with lower payments) Pareto-optimal NE.colluders coordinate asymmetric strategies (Section 4.4), payments stilldevised make honest reporting unique Pareto-optimal NE. less one halfpopulation collude, payments sometimes devised make honestreporting dominant strategy. Numerical simulations, however, show payments245fiJurca & Faltingsrequired deter coalition fractions greater one third become exponentially expensive.Finally, Section 4.5 describes incentive-compatible payments resistant sybilattacks: i.e., strategic agents creates several fake identities order manipulatepayment mechanism. designer ensure set reports submittedcoalition reflects aggregated experience coalitions. Individual colludersnecessarily report truth, overall, reputation mechanism obtains correctinformation.Acknowledgmentsauthors wish thank anonymous reviewers helpful comments suggestions.Appendix A. Proof Proposition 3.1solving LP 3.1, let us write corresponding dual problem:max y0 + y1 ;s.t.P r[n|0]y0 P r[n|1]y1 P r[0]P r[n|0]P r[n|1]y1 P r[n|0]y0 P r[1]P r[n|1]n {0, . . . , N 1};y0 (respectively y1 ) dual variable corresponding constraintagent observes 0 (respectively 1). dividing first set constraints P r[n|0]second set constraints P r[n|1], have:y0 y1 P r[n|1]/P r[n|0] P r[0], n {0, . . . , N 1};y1 y0 P r[n|0]/P r[n|1] P r[1], n {0, . . . , N 1};Clearly, among 2(N 1) constraints dual problem, two active, correP r[n|0]sponding to: n1 = arg minn PP r[n|1]r[n|0] , n2 = arg minn P r[n|1] . follows twovariables LP 3.1 non-zero values (i.e., (0, n1 ) 6= 0 (1, n2 ) 6= 0),satisfy linear equations:P r[n1 |0] (0, n1 ) P r[n2 |0] (1, n2 ) = ;P r[n1 |1] (0, n1 ) + P r[n2 |1] (1, n2 ) = ;remaining part proof show n1 = 0 n2 = N 1. that,P r[n+1|1]prove PP r[n|1]r[n|0] < P r[n+1|0] n = 0, 1, . . . , N 2.246fiMechanisms Making Crowds TruthfulP r[n|1]P r[n + 1|0] P r[n|0]P r[n + 1|1] =XP r[]XP r[1|]P r[0|]P r[n|]P r[]P r[n + 1|]P r[1]P r[0]XXP r[0|]P r[1|]P r[]P r[]P r[n|]P r[n + 1|]Pr[0]Pr[1]=XP r[]XXP r[1|]P r[0|](N 1 n)P r[1|]P r[n|]P r[]P r[n|]P r[1]P r[0](n + 1)P r[0|]XP r[0|]P r[1|](N 1 n)P r[1|]P r[]P r[n|]P r[n|]P r[0]P r[1](n + 1)P r[0|]X2(N 1 n)=P r[]P r[1|]P r[n|](n + 1)P r[1]P r[0]!XXP r[1|]2P r[]P r[0|]P r[n|]P r[]P r[n|]< 0;P r[0|]P r[]ptheCauchy-Schwartz inequality applied vectors ( P r[]P r[0|]P r[n|])P r[1|] P r[]P r[n|]() .P r[0|]Appendix B. Proof Proposition 4.5idea proof show find positive values xpayment scheme defined Proposition 4.5 three NE: honest reporting, everybodyreporting 0 everybody reporting 1.NE n agents report according slie 4 n agents report honestly.Proposition 4.2 know x found prevent equilibriumagents lie. Similarly, incentive-compatible constraints ensure strategy profileone agent always lies three agents always report truth cannot NE. Letus show profile = (3 slie , s) three agents lie one agent reportstruth. honest reporter observing low quality signal report honestlyif:P r[2|0]x P r[1|0]y > 0;honest agent reports positive report observing high quality if:P r[2|1]x + P r[1|1]y > 0;P r[1|1]However, Lemma 3.1 PP r[1|0]r[2|0] > P r[2|1] , two inequalities neversimultaneously satisfied.Consider profile = (2 slie , 2 s) two agents lie two agents reporttruth NE. One honest reporter reports truth if:(3P r[3|0] + 2P r[1|0])x (3P r[0|0] + 2P r[2|0])y > 0;(3P r[3|1] + 2P r[1|1])x + (3P r[0|1] + 2P r[2|1])y > 0;liar, hand, reports according slie if:(3P r[0|1] + 2P r[2|1])x (3P r[3|1] + 2P r[1|1])y > 0;(3P r[0|0] + 2P r[2|0])x + (3P r[3|0] + 2P r[1|0])y > 0;247fiJurca & Faltings4 inequalities satisfied3P r[3|1] + 2P r[1|1] < 3P r[0|1] + 2P r[2|1];3P r[0|0] + 2P r[2|0] < 3P r[3|0] + 2P r[1|0];impossible.NE one agent always reports 1, n agents report according slie 3 nagents report honestly. Clearly, 3 agents report honestly, agent always reporting1 incentive deviate report 0 observing low quality. Consider strategyprofile = (spos , 2 s, slie ) one agent reports according spos , two agents reporthonestly one agent reports according slie . liar, slie equilibrium iff:Pr[0|0]x + Pr[1|0]y > 0;Pr[0|1]x Pr[1|1]y > 0;Pr[n|oi ] probability n 2 honest reporters observe 1, givenobservation oi Q2 . Lemma 3.1, Pr[1|1] > Pr[1|0] , inequationsP r[0|1]P r[0|0]cannot hold simultaneously.Consider strategy profile = (spos , s, 2 slie ) one agent reports accordingspos , one agent reports honestly two agents report according slie . agentreporting honestly, iff:Pr[2|0]x Pr[0|0]y > 0;Pr[2|1]x + Pr[0|1]y > 0;Pr[n|oi ] probability n 2 liars observe 1, given observationoi Q2 . impossible since Lemma 3.1Pr[0|0]Pr[2|0]>Pr[0|1].Pr[2|1]neglie , (3n)Similartechniquesusedprovestrategyprofile,nssneg , spos , n slie , (2 n) NE. Therefore, constraint (besidesincentive-compatibility constraints) acting payments x intended preventlying equilibrium. x take exactly values described Proposition 4.2.Appendix C. Proof Proposition 4.6Consider strategy profile = n s, (N n) slie n 1 agents reporthonestly, others always lie. NE, honest reporter must expecthigher payment reporting truth, liar must expect higher payment lying.Consider honest reporter observing 0. report negative signalP r[ri = 1|0]x > P r[ri = N 2|0]y, P r[ri = 1|0] P r[ri = N 2|0]probabilities exactly 1, respectively N 2 remaining N 1 agents reportpositive signals. Exactly one agents reports positive signal when:one honest reporters observes low quality, liars observehigh quality,honest reporters observe low quality, one liars observe highquality.248fiMechanisms Making Crowds TruthfulP r[ri = 1|0] =XP r[|0]Xn 1N nP r[1|]P r[0|]n2P r[1|]N n +1N nn 1N nP r[|0]P r[0|]n1P r[1|]N n1 P r[0|]0N n 1(n 1)!(N n + 1)!(n)!(N n)!P r[N n + 1|0] +P r[N n 1|0](N 1)!(N 1)!(n 1)!(N n)!=(N n + 1)P r[N n + 1|0] + nP r[N n 1|0] ;(N 1)!=Similarly,P r[ri = N 2|0] =(n 1)!(N n)!(N n + 1)P r[n 2|0] + nP r[n|0] ;(N 1)!Hence honest reporter incentive truthfully submit negative reportif:(N n + 1) P r[N n + 1|0]x P r[n 2|0]y + n P r[N n 1|0]x P r[n|0]y > 0;hand, honest reporter submit positive report observing highquality signal if:(N n + 1) P r[n 2|1]y P r[N n + 1|1]x + n P r[n|1]y P r[N n 1|1]x > 0;Exactly reasoning leads following two inequations liar:(N n) P r[n 1|0]y P r[N n|0]x + (n + 1) P r[n + 1|0]y P r[N n 2|0]x > 0;(N n) P r[N n|1]x P r[n 1|1]y + (n + 1) P r[N n 2|1]x P r[n + 1|1]y > 0;exist x four inequalities satisfied time if:(N n + 1)P r[n 2|0] + nP r[n|0](N n + 1)P r[n 2|1] + nP r[n|1]<(N n + 1)P r[N n + 1|0] + nP r[N n 1|0](N n + 1)P r[N n + 1|1] + nP r[N n 1|1](N n)P r[n 1|0] + (n + 1)P r[n + 1|0](N n)P r[n 1|1] + (n + 1)P r[n + 1|1]<(N n)P r[N n|1] + (n + 1)P r[N n 2|1](N n)P r[N n|0] + (n + 1)P r[N n 2|0]equivalently:(N n + 1)P r[n 2|0] + nP r[n|0](N n + 1)P r[N n + 1|0] + nP r[N n 1|0]<(N n + 1)P r[n 2|1] + nP r[n|1](N n + 1)P r[N n + 1|1] + nP r[N n 1|1](N n)P r[n 1|1] + (n + 1)P r[n + 1|1](N n)P r[N n|1] + (n + 1)P r[N n 2|1]<(N n)P r[n 1|0] + (n + 1)P r[n + 1|0](N n)P r[N n|0] + (n + 1)P r[N n 2|0]However, one show that:(N n + 1)P r[n 2|0] + nP r[n|0](N n)P r[N n|1] + (n + 1)P r[N n 2|1]<(N n)P r[N n|0] + (n + 1)P r[N n 2|0](N n + 1)P r[n 2|1] + nP r[n|1](N n + 1)P r[N n + 1|0] + nP r[N n 1|0](N n)P r[n 1|1] + (n + 1)P r[n + 1|1]<(N n + 1)P r[N n + 1|1] + nP r[N n 1|1](N n)P r[n 1|0] + (n + 1)P r[n + 1|0]249fiJurca & Faltingsmeans honest reporter liar cannot believe strategiesoptimal (given strategies agents).Consider strategy profile = (sneg , n s, N n 1 slie ) one agentalways reports 0, n 1 agents report honestly, N n 1 1 agents always lie.honest reporter liar believe NE if:nPr[N n 2|0] + (N n)Pr[N n|0] x Pr[n 1|0]ynPr[N n 2|1] + (N n)Pr[N n|1] x + Pr[n 1|1]y(n + 1)Pr[N n 3|0] + (N n 1)Pr[N n 1|0] x + Pr[n|0]y(n + 1)Pr[N n 3|1] + (N n 1)Pr[N n 1|1] x Pr[n|1]y>0>0(17)>0>0Pr[j|oi ] probability j N 2 agents observe high quality signals,given observation oi .Nevertheless,Pr[n 1|0]Pr[n|0]<Pr[n|1]P r[n 1|1]nPr[N n 2|0] + (N n)Pr[N n|0](n + 1)Pr[N n 3|0] + (N n 1)Pr[N n 1|0]<nPr[N n 2|1] + (N n)Pr[N n|1](n + 1)Pr[N n 3|1] + (N n 1)Pr[N n 1|1]means inequalities (17) never simultaneously satisfied.Using exactly technique one show that:= spos , n s, (N n 1) slie one agent always reports 0, n 1 agentsreport honestly, N n 1 1 agents always lie NE;= sneg , spos , n s, (N n 2) slie one agent always reports 0, oneagent always reports 1, n 0 agents report honestly, N n 1 0 agents alwayslie NE.Appendix D. Extending results n-ary feedbackassumed far agent observe report two signals: 0 1.framework extended n-ary feedback imposing supplementary constraintsdesign problems. example, lets assume set quality signals (and feedbackreports) contains elements: Q = {q1 , q2 , . . . qM }. incentive compatibility constraintsequivalent (4) become:XP r[ri |qj ] (qj , ri ) (qk , ri ) ; qj , qk Q;ri Q(N 1)qj Q signal actually observed agent i, qk Q every lie agentcould report, ri Q(N 1) configuration N 1 reference reports.compared (4) three observations become apparent. First, 2 constraintsbinary feedback case must replaced (M 1) constraints n-ary feedback250fiMechanisms Making Crowds Truthfulsetting. Second, size constraint grows sum N terms sum1CN+M 2 terms (all possible unordered sequences N 1 signals drawn Q). Finally,1reward mechanism defined CN+M 2 payments instead 2N .constraints suffer similar blowup, makes design problemgeneral n-ary feedback case significantly harder solve.ReferencesAbreu, D., & Sen, A. (1991). Virtual Implementation Nash Equilibria. Econometrica,59, 9971022.Admati, A., & Pfleiderer, P. (2000). Noisytalk.com: Broadcasting opinions noisy environment. Working Paper 1670R, Stanford University.Akerlof, G. A. (1970). market lemons: Quality uncertainty market mechanism. Quarterly Journal Economics, 84 (3), 488500.Braynov, S., & Sandholm, T. (2002). Incentive Compatible Mechanism Trust Revelation.Proceedings AAMAS, Bologna, Italy.Cheng, A., & Friedman, E. (2005). Sybilproof reputation mechanisms. ProceedingWorkshop Economics Peer-to-Peer Systems (P2PECON), pp. 128132.Clemen, R. T. (2002). Incentive contracts strictly proper scoring rules. Test, 11,167189.Conitzer, V., & Sandholm, T. (2002). Complexity mechanism design. ProceedingsUncertainty Artificial Intelligence Conference (UAI).Conitzer, V., & Sandholm, T. (2003a). Applications Automated Mechanism Design.Proceedings UAI-03 Bayesian Modeling Applications Workshop.Conitzer, V., & Sandholm, T. (2003b). Automated Mechanism Design StructuredOutcome Space..Conitzer, V., & Sandholm, T. (2004). Algorithm Automatically Designing Deterministic Mechanisms without Payments. Proceedings AAMAS-04.Conitzer, V., & Sandholm, T. (2007). Incremental Mechanism Design. ProceedingsIJCAI.Cremer, J., & McLean, R. P. (1985). Optimal Selling Strategies UncertaintyDiscriminating Monopolist Demands Interdependent. Econometrica, 53 (2),34561.dAspremont, C., & Grard-Varet, L.-A. (1979). Incentives Incomplete Information.Journal Public Economics, 11, 2545.Dellarocas, C. (2002). Goodwill Hunting: Economically Efficient Online Feedback.Padget, J., & et al. (Eds.), Agent-Mediated Electronic Commerce IV. Designing Mechanisms Systems, Vol. LNCS 2531, pp. 238252. Springer Verlag.Dellarocas, C. (2006). Strategic Manipulation Internet Opinion Forums: ImplicationsConsumers Firms. Management Science, 52 (10), 15771593.251fiJurca & FaltingsElliott, C. (2006). Hotel Reviews Online: Bed Hope, Half-Truths Hype.New York Times.Figlewski, S. (1979). Subjective information market efficiency betting market.Journal Political Economy, 87 (1), 7588.Gibbard, A. (1973). Manipulation Voting Schemes: General Result. Econometrica, 41,587601.Guo, M., & Conitzer, V. (2007). Worst-Case Optimal Redistribution VCG Payments.Proceedings EC07, pp. 3039.Hajiaghayi, M., Kleinberg, R., & Sandholm, T. (2007). Automated Online MechanismDesign Prophet Inequalities. Proceedings AAAI07.Harmon, A. (2004). Amazon Glitch Unmasks War Reviewers. New York Times.Holmstrom, B. (1982). Moral Hazard Teams. Bell Journall Economics, 13, 324340.Hu, N., Pavlou, P., & Zhang, J. (2006). Online Reviews Reveal Products TrueQuality?. Proceedings ACM Conference Electronic Commerce (EC 06).Jackson, M. O. (1991). Bayesian Implementation. Econometrica, 59, 461477.Johnson, S., Pratt, J., & Zeckhauser, R. (1990). Efficiency Despite Mutually Payoff-RelevantPrivate Information: Finite Case. Econometrica, 58, 873900.Jurca, R., Binder, W., & Faltings, B. (2007). Reliable QoS Monitoring Based ClientFeedback. Proceedings 16th International World Wide Web Conference(WWW07), pp. 10031011, Banff, Canada.Jurca, R., & Faltings, B. (2005). Enforcing Truthful Strategies Incentive CompatibleReputation Mechanisms. Internet Network Economics (WINE05), Vol. 3828LNCS, pp. 268277. Springer-Verlag.Jurca, R., & Faltings, B. (2006). Minimum Payments Reward Honest ReputationFeedback. Proceedings ACM Conference Electronic Commerce (EC06),pp. 190199, Ann Arbor, Michigan, USA.Jurca, R., & Faltings, B. (2007a). Collusion Resistant, Incentive Compatible FeedbackPayments. Proceedings ACM Conference Electronic Commerce (EC07),pp. 200209, San Diego, USA.Jurca, R., & Faltings, B. (2007b). Robust Incentive-Compatible Feedback Payments.Fasli, M., & Shehory, O. (Eds.), Trust, Reputation Security: Theories Practice,Vol. LNAI 4452, pp. 204218. Springer-Verlag, Berlin Heidelberg.Kandori, M., & Matsushima, H. (1998). Private observation, communication collusion.Econometrica, 66 (3), 627652.Keates, N. (2007). Deconstructing TripAdvisor. Wall Street Journal, page W1.Li, S., & Balachandran, K. (2000). Collusion proof transfer payment schemes multipleagents. Review Quantitative Finance Accounting, 15, 217233.Ma, C. (1988). Unique implementation incentive contracts many agents. ReviewEconomic Studies, 555572.252fiMechanisms Making Crowds TruthfulMaskin, E. (1999). Nash Equilibrium Welfare Optimality. Review Economic Studies,66, 2328.Matsushima, H. (1988). New Approach Implementation Problem. JournalEconomic Theory, 45, 128144.Miller, N., Resnick, P., & Zeckhauser, R. (2005). Eliciting Informative Feedback: PeerPrediction Method. Management Science, 51, 1359 1373.Moore, J., & Repullo, R. (2005). characterization virtual Bayesian implementation.Games Economic Behavior, 50, 312331.Palfrey, T., & Srivastava, S. (1991). Nash-implementation using Undominated Strategies.Econometrica, 59, 479501.Parasuraman, A., Zeithaml, V., & Berry, L. (1985). Conceptual Model Service QualityImplications Future Research. Journal Marketing, 49, 4150.Pennock, D., Debnath, S., Glover, E., & Giles, C. (2002). Modeling information incorporation markets application detecting explaining events. Proc.18th Conf. Uncertainty Artifcial Intelligence, pp. 405411.Sandholm, T., Conitzer, V., & Boutilier, C. (2007). Automated Design Multistage Mechanisms. Proceedings IJCAI07.Servan-Schreiber, E., Wolfers, J., Pennock, D., & Galebach, B. (2004). Prediction markets:money matter. Electronic Markets, 14 (3).Sherali, H., & Shetty, C. (1980). Optimization Disjunctive Constraints. SpringerVerlag.Talwar, A., Jurca, R., & Faltings, B. (2007). Understanding User Behavior Online Feedback Reporting. Proceedings ACM Conference Electronic Commerce(EC07), pp. 134142, San Diego, USA.von Ahn, L., & Dabbish, L. (2004). Labeling Images Computer Game. ProceedingsACM CHI.White, E. (1999). Chatting Singer Pop Charts. Wall Street Journal.253fiJournal Artificial Intelligence Research 34 (2009) 499-520Submitted 10/08; published 3/09Exploiting Single-Cycle SymmetriesContinuous Constraint ProblemsVicente Ruiz de AnguloCarme Torrasruiz@iri.upc.edutorras@iri.upc.eduInstitut de Robotica Informatica Industrial (CSIC-UPC)Llorens Artigas 4-6, 08028-Barcelona, Spain.WWW home page: www.iri.upc.eduAbstractSymmetries discrete constraint satisfaction problems explored exploited last years, symmetries continuous constraint problems received attention. focus permutations variables consistingone single cycle. propose procedure takes advantage symmetriesinteracting continuous constraint solver without interfering it. key conceptprocedure classes symmetric boxes formed bisecting n-dimensionalcube point dimensions time. analyze classesquantify function cube dimensionality. Moreover, propose simplealgorithm generate representatives classes number variableshigh rates. problem example chemical field cyclic n-roots problemused show performance approach practice.1. IntroductionSymmetry exploitation discrete constraint satisfaction problems (CSPs) receivedgreat deal attention lately. Since CSPs usually solved using AI search algorithms,approaches dealing symmetries fall two groups: entail reformulatingproblem adding constraints search (Flener, Frisch, Hnich, Kiziltan, & Miguel, 2002;Puget, 2005), break symmetries along search (Meseguer & Torras, 2001;Gent, 2002). Permutations variables, interchangeability values commonlyaddressed symmetries repertoire techniques developed,relying computational group theory.contrary, symmetries largely disregarded continuous constraintsolving, despite important growth theory applications fieldrecently experienced (Sam-haroud & Faltings, 1996; Benhamou & Goualard, 2000; Jermann& Trombettoni, 2003; Porta, Ros, Thomas, & Torras, 2005). Continuous (or numerical)constraint solving often tackled using Branch-and-Prune (B&P) algorithms (Hentenryck,Mcallester, & Kapur, 1997; Vu, Silaghi, Sam-Haroud, & Faltings, 2005), iterativelylocate solutions inside initial domain box, alternating box subdivision (branching)box reduction (pruning) steps.Motivated molecular conformation problem, paper dealsimple type box symmetry, namely domain variables (i.e., box dimensions) undergo single-cycle permutation leaving constraints invariant. clear,cycle involves n variables, algorithm handles n 1 symmetries (excludingc2009AI Access Foundation. rights reserved.fiRuiz de Angulo & Torrasidentity) generated cycle composition. Since computational gainshown roughly proportional n, longest cycle appearing problem formulation chosen input algorithm.single-cycle permutation leaves constraints unchanged form constraint symmetry terminology introduced Cohen, Jeavons, Jefferson, Petrie,Smith (2006). Note constraint symmetry also solution symmetry,way around. Thus, symmetries deal subset possible solutionsymmetries; advantage assessed (although perhaps difficultfind) problem formulation, therefore operative.approach exploit symmetries continuous constraint problems requiresinitial domain symmetric variables n-cube, starts subdividingcube point along dimensions once. Since box symmetry transitiverelation, subboxes resulting subdivision fall equivalence classes. Then,B&P algorithm (or similar continuous constraint solver) called subboxesrepresentatives symmetry equivalence class. Finally, solution found,symmetric ones generated. Note symmetry handling doesnt interfereinside workings constraint solver.2. Symmetry Continuous Constraint Problemsinterested solving following general continuous Constraint Satisfaction Problem (continuous CSP): Find points x = (x1 , . . . , xn ) lying initial box Rn satisfyingconstraints f1 (x) C1 , . . . , fm (x) Cm , fi function fi : Rn R, Ciinterval R.particular feature require Continuous Constraint Solver (CCS)work axis-aligned box Rn input. Also, assumeCCS returns solution boxes. Note CCS returning solution points limit case stillcontained framework.say function : Rn Rn point symmetry problem existsassociated permutation fi (x) = f(i) (s(x)) Ci = C(i) , = 1, . . . , m.consider symmetry property relates points equivalent regardscontinuous CSP. Concretely, definition one concludex solution problem iff s(x) solution problem.Let two symmetries continuous CSP associated permutations. easy see composition symmetries s(t()) also symmetryassociated permutation (t ()).interesting type symmetries permutations (bijective functions set ontoitself) components x. Let finite set. cycle length k permutationexist distinct elements a1 , . . . ak (ai ) = (a(i+1)mod k )(z) = z element z D. cycle represented (a1 , . . . ak ).Every permutation expressed composition disjoint cycles (i.e, cycles withoutcommon elements), unique order factors. Composition cyclesrepresented concatenation, example (a1 , . . . ak )(b1 , . . . bl ). paper focusparticular type permutations, namely constituted single cycle.500fiExploiting Single-Cycle Symmetriessimplest form1 , s(x1 , x2 , . . . xn ) = (x(1) , x(2) , . . . x(n) ) = (x2 , x3 ...xn , x1 ),(i) = (i + 1) mod n.Example: n = 3, = 4, x = (x1 , x2 , x3 ) [1, 1] [1, 1] [1, 1],f1 (x) :x21 + x22 + x23 [5, 5] x21 + x22 + x23 = 5f2 (x) :2x1 x2 [0, ] 2x1 x2 > 0f3 (x) :2x2 x3 [0, ] 2x2 x3 > 0f4 (x) :2x3 x1 [0, ] 2x3 x1 > 0exists symmetry s(x1 , x2 , x3 ) = (x2 , x3 , x1 ), need reordering variables. constraint permutation associated (1) = 1, (2) = 3,(3) = 4, (4) = 2.Generally unique symmetry given problem. exists symmetrys, example s2 (x) = s(s(x)) another symmetry. general, using conventiondenoting s0 (x) identity mapping, {si (x), = 0 . . . n1} set different symmetriesobtained composing s(x) itself, > n si (x) =si mod n (x). Thus, single-cycle symmetry generates composition n 1 symmetries,excluding trivial identity mapping. may different numbers cycles.Imagine example continuous CSP n = 4 permutation variables (12 3 4) symmetry. Then, permutation obtained composing twice, (1 3)(2 4),also symmetry problem, different number cycles, longestcycle length two instead four. Besides, former permutation cannot generatedlatter. algorithm presented paper deals compositionssingle-cycle symmetry, even single-cycle symmetries.gain obtained proposed algorithm shown roughly proportionalnumber different compositions selected symmetry. Therefore, severalsingle-cycle symmetries exist continuous CSP problem, algorithm usedgenerating symmetries composition, i.e., longestcycle. Note single-cycle permutations dealing need encompassproblem variables, since remaining ones considered fixed (unitary cycles).3. Box SymmetrySince continuous constraint solvers work boxes, turn attention setpoints symmetric belonging box B Rn . 2Let single-cycle symmetry corresponding circular variable shifting introduced preceding section, B = [x1 , x1 ]. . .[xn , xn ] box Rn . box symme1. general, variables must arranged suitable order one apply circular shifting. Thus, general form single-cycle symmetry s(x) = h1 (g(h(x))),h(x1 , . . . xn ) = (x(1) , . . . , x(n) ), n general permutation orders variables,g(x1 , . . . , xn ) = (x(1) , . . . x(n) ) circular shifting above. Thus, cycle defining symmetry expressed = 1 ((())). Since reordering change substantiallypresented concepts algorithms, simplified notation paper assuming ordercomponent variables appropriate one, i.e., = .2. set {s(x) s.t. x B} also box s(x) = (s1 (x), . . . , sn (x)) = (g1 (x(1) ), . . . , gn (x(n) )),si i-th component s, arbitrary permutation, gi : R R functioninterval R {gi (x) s.t. x I} also interval R.501fiRuiz de Angulo & Torrastry function defined S(B) = {s(x) s.t. x B} = [x(1) , x(1) ] . . . [x(n) , x(n) ] =[x2 , x2 ] . . . [xn , xn ] [x1 , x1 ]. box symmetry function also associated constraint permutation , associated s. denote composedtimes. say, then, B1 B2 symmetric boxes exists s.t. (B1 ) = B2 .Box symmetry equivalence relation defining symmetry equivalence classes. LetR(B) set different boxes symmetry class B, R(B) = {S (B), {0, . . . , n1}}. instance, box B 0 = [0, 4] [2, 5] [2, 5] [0, 4] [2, 5] [2, 5], R(B 0 ) composed0 (B 0 ) = B 0 , 1 (B 0 ) = [2, 5][2, 5][0, 4][2, 5][2, 5][0, 4] 2 (B 0 ) = [2, 5][0, 4][2, 5][2, 5][0, 4][2, 5]. Note 3 (B 0 ) B 0 subsequent applicationsbox symmetry would repeat sequence boxes. define period P (B)box B P (B) = |R(B)|. easily shown R(B) = {S (B), {0, . . . , P (B) 1}}.example, box B 0 , R(B 0 ) = {S 0 (B 0 ), 1 (B 0 ), 2 (B 0 )} P (B 0 ) = 3.Box symmetry implications continuous CSP, direct consequencepoint symmetry case:solution inside box B, solution inside symmetricboxes either.box B B solution iff (B ) (B) solution box {1 . . . P (B)1}.Sketch proof first statement: Assume solution inside Bsolution xsol inside (B). definition box symmetry exists point x0sol Bxsol = si (x0sol ). Using property highlighted Section 2 deduce x0solmust also solution, contradicts hypothesis.Sketch proof second statement: solution box box least solutionpoint inside. Assume B B solution box containing solution point xsol . Inside(B ) point si (xsol ) that, property highlighted Section 2, mustalso solution. Conversely, assume (B ) B solution box. Thus containsleast solution point, xsol . definition symmetric box, point symmetricpoint x0sol B xsol = si (x0sol ). Using property Section 2 concludex0sol must also solution and, thus, B solution box.statements rephrased follows :set solution boxes contained box B SolSet, set solution boxescontained symmetric box (B) {S (B ) s.t. B SolSet}means solutions inside B found, solutions insidesymmetric boxes (B), {1 . . . P (B) 1} available without hard calculations.following sections show exploit property save much computing timemeta-algorithm uses CCS tool without interfering it.3.1 Box Symmetry Classes Obtained Bisecting n-cubealgorithm propose exploit box symmetry makes use symmetry classesformed bisecting n-dimensional cube n (i.e., period 1) dimensionstime point, resulting 2n boxes. denote L Htwo subintervals original range divided. example, n = 2,502fiExploiting Single-Cycle Symmetriesfollowing set boxes {L L, L H, H L, H H} whose periods 1, 2,2 1, respectively. symmetry classes are: {L L}, {L H, H L},{H H}. Representing two intervals L H 0 1, respectively, droppingsymbol, sub-boxes coded binary numbers. Let SRn setrepresentatives, formed choosing smallest box binary order class.example, SR2 = {00, 01, 11}. Note cube n partitioned thoughtset binary numbers length n, SRn nothing subsetwhose elements different circular shift.algorithm exploiting symmetries way uses SRn explainednext section. Afterwards, Sections 6 7, study many components SRn has,distributed and, importantly, generated.4. Algorithm Exploit Box SymmetryAlgorithm 1: CSym1 algorithm.Input: n-cube, [xl , xh ] [xl , xh ].single-cycle box symmetry, S.Continuous Constraint Solver, CCS.Output: set boxes covering solutions.5SolutionBoxSet EmptySetx SelectBisectionPoint(xl , xh )foreach b SRnB GenerateSubBox(b, xl , xh , x )SolutionBoxSet SolutionBoxSet ProcessRepresentative(B)6return SolutionBoxSet1234symmetry exploitation algorithm propose uses CCS external routine.internals CCS must modified known.idea first divide initial box number symmetry classes. Next, oneneeds process representative class CCS. end, applyingbox symmetries solution boxes obtained way, one would get solutionslying space covered whole classes, i.e., initial box. advantageprocedure CCS would process fraction initial box. Assuminginitial box n-cube covering interval [xl , xh ] dimensions,directly apply classes associated SRn . procedure exploit single-cycle symmetriesway presented Algorithm 1.Since SRn set codes real boxes need translation codesboxes given initial box. operator GenerateSubBox(b, xl , xh , x ) returnsbox V = V1 Vn corresponding code b = b1 . . . bn [xl , xh ] rangeinitial box dimensions x point interval bisected:([xl , x ] bi = 0,Vi =(1)[x , xh ] bi = 1.503fiRuiz de Angulo & Torraspoint x calculated SelectBisectionPoint(xl , xh ) xl << xh , reasonable one (xl + xh )/2. iterations line 4 generate setrepresentative boxes that, together symmetries, cover initial n-cube.ProcessRepresentative(B) returns solution boxes associated B, is,solutions inside R(B), still words, solutions inside B inside symmetricboxes. ProcessRepresentative(B) based property stated end Section3, allows obtain solutions class B processing BCCS. SolSet set solutions found inside representative box class, B.ApplySymmetry(SolSet, ) calculates set solutions box (B) applyingboxes SolSet. Since number symmetries B P (B), benefitsexploiting symmetries class representative proportional period.xAlgorithm 2: ProcessRepresentative function.Input: box, B.single-cycle box symmetry, S.Continuous Constraint Solver, CCS.Output: set solution boxes contained B symmetric boxes.4SolSet CCS(B)otalSolSet SolSeti=1: P (B) 1otalSolSet otalSolSet ApplySymmetry(SolSet, )5return otalSolSet123correctness algorithm easy check. set boxes searches explicitly implicitly (by means symmetry) solutions U = {R(B) s.t. B representative}.fact, U set boxes formed bisecting initial box dimensionstime point. U covers whole initial box and, thus, algorithm findssolutions problem. Moreover, finds solution box once,boxes U volume common (they share wall).4.1 Discussion Efficiency CSYM1CSym1 algorithm launches CCS algorithm |SRn | small boxes insteadoriginal large one. Three factors affect efficiency compared standardapproach:1. Fraction domain processed. fraction original domain directlydealt CCS. fraction function periods SRn components. One element period p represents class formed p boxes, oneprocessed CCS. Since boxes classes equal size,fraction calculated dividing number representativesn|P |SRn |total number boxes classes, |SR2n =P (B) . expected time gainPBSRnP (B)ninverse quantity, BSRdenoted IFDP (Inverse Fraction|SRn |Domain Processed). n grows (see Section 6), majority elements504fiExploiting Single-Cycle SymmetriesSRn period n, thus IFDP tends n. However, low n, IFDPsignificantly smaller n. main factor determining efficiencyCSym1.2. Smaller processed boxes. Since CCS initial boxes using CSym1 2n timessmaller original initial box, average size boxes processedCCS also smaller standard case. Prune (box reduction contraction)step carried quickly smaller boxes Branch-and-Prune algorithms.fact, best Branch-and-Prune algorithms box contraction operators exhibitingsecond-order convergence, contraction rate requires small enough boxeshold practice.3. Number representatives. disadvantage fractioning excessivelyinitial domain. see noting that, using original large initialbox, contraction operator lowers upper bound symmetric variable,information could used lower upper bound variable manyrepresentative boxes SRn . commented above, contraction operator wouldact strongly representatives themselves, loss parallelizationeffect anyway present. factor irrelevant small-length cycle symmetries,say n = 6, |SRn | small (see Section 6 again) comparednumber boxes CCS must process general. However, n approaches20, number representatives begins become overwhelming.5. Two Illustrative Examplestwo problems solved Branch-and-Prune CCS presentedPorta, Ros, Thomas, Corcho, Canto, Perez (2008). polytope-based methodsimilar Sherbrooke E. C. (1993) global consistency, exhibits quadraticconvergence. machine used carry experiments paper 2.5 GhzG5 Apple computer.5.1 CycloheptaneMolecules modeled mechanical chains making reasonable approximations.two atoms joined chemical bond, one assume rigid linkthem. Thus, first approximation bond lengths constant. second oneangles two consecutive bonds also constant. words,distances atoms subchain three atoms assumed constant.configurations atoms molecule satisfy distance constraints, sometimesdenoted rigid-geometry hypothesis, valid conformations molecule kinematicsense. constraints induced rigid-geometry hypothesis particularly strongmolecule topology forms loops, cycloalkanes. problem findingvalid conformations molecule formulated distance-geometry (Blumenthal,1953) problem distances points (atoms) fixed known,one must find set values unknown (variable) distances compatibleembedding points R3 . unknown distances found solving set505fiRuiz de Angulo & Torrasconstraints consisting equalities inequalities determinants formed subsetsfixed variable distances (Blumenthal, 1953).d2d3d1d7d5d6d4Figure 1: Cycloheptane. Disks represent carbon atoms. Constant variable distancesatoms represented continuous dashed lines, respectively.Figure 2: Three-dimensional projection cycloheptane solutions. lightest (yellow)boxes solutions found inside representatives using CCS (line 1Algorithm 2). colored boxes solutions obtained applyingsymmetries yellow boxes (line 4 Algorithm 2).Figure 1 displays known unknown distances cycloheptane, molecule basically composed ring seven carbon atoms. distance two consecutive atomsring constant equal everywhere. distance two atoms connected506fiExploiting Single-Cycle Symmetriesatom also known constant matter atoms. problem underconstrained, infinite number solutions dimensionality 1. problem severalsymmetries. use one them, s(d1 , . . . , d7 ) = (d(1) , d(2) , . . . , d(7) ) = (d2 , d3 . . . , d7 , d1 ).length cycle symmetry n = 7, IFDP 6.4.number boxes processed using raw CCS without symmetry handling 1269,using CSym1 total number 196, giving ratio 6.47 IFDP. problemsolved 4.64 minutes using CSym1, compares favorably 31.6 minutesspent using algorithm Porta et al. (2008) alone, reduction factor 6.81,slightly greater IFDP. means that, although number representatives beginsrelevant (|SR7 | = 20), factor 2 Section 4.1 determining factor 3section, since (small) time overhead introduced handling box symmetriesalso included reported time. Figure 2 shows projection d1 , d2 d3solutions obtained using CSym1. solutions found inside five representative boxesperiod seven, containing 16, 1, 4, 64 1 solution boxes, respectively, chosen levelresolution. total number solutions boxes therefore 7(16+1+4+64+1)= 602.5.2 Cyclic n-roots Problemfollowing polynomial equation system n = 5 instance so-called cyclicn-roots problem described Bjorck Froberg (1991).x1 + x2 + x3 + x4 + x5 = 0x1 x2 + x2 x3 + x3 x4 + x4 x5 + x5 x1 = 0x1 x2 x3 + x2 x3 x4 + x3 x4 x5 + x4 x5 x1 + x5 x1 x2 = 0x1 x2 x3 x4 + x2 x3 x4 x5 + x3 x4 x5 x1 + x4 x5 x1 x2 + x5 x1 x2 x3 = 0(2)x1 x2 x3 x4 x5 1 = 0ten real solutions problem. system single-cycle symmetry:s(x1 , . . . , x5 ) = (x2 , x3 , x4 , x5 , x1 ), well multiple-cycle symmetry consideredpaper. Thus, cycle length n = 5, |SR5 | = 8, IFDP 4. runningCCS alone using initial box [10, 10]5 , number processed boxes 399,exploiting aforementioned symmetry CSym1 algorithm number reduces66. last case, two solutions found representative box period 5,symmetry led ten solutions. Running times 16.86 seconds (CCS alone)2.08 seconds (CSym1) giving gain eight. double IFDP,highlights benefits factor 2 Section 4.1 bring efficacyapproach. number representatives small compared number boxesprocessed CCS alone, making factor 3 Section 4.1 irrelevant case.Table 1 contains results n=4 n=8 cyclic n-roots problem [10, 10]ndomain, except n=8 domain [5, 5]8 . n=4 n=8continuum solutions which, chosen resolution, produces 992 2435 solutionboxes, respectively. this, number processed boxes n=5 smallern=4, logically smaller also n=6 n=8. Two observations507fiRuiz de Angulo & TorrasIFDPnumber processed boxes CCS alonenumber processed boxes CSym1rate processed boxestime CCS alonetime CSym1time gain CSym1n=4n=5n= 6n=72.718555003.712.03.04.04.0399666.016.92.18.14.533435106.6642.095.86.76.43899150707.720442.02689.77.6n=8(reduced domain)7.1108647133048.2227355.227296.58.3Table 1: Results n-cyclic roots problem. Times given seconds.made. First, time gains always higher corresponding IFDPs, implyingpreponderance factor 2 Section 4.1 factor 3. Second, time gain follows ratheraccurately rate number processed boxes using CCS alone usingCSym1.Tests cyclic n-roots problem using classical CCSP solver, RealPaver (Granvilliers & Benhamou, 2006), carried (Jermann, 2008). results preliminary difficult expose concisely, since great variability depending issuespruning method used (RealPaver offers several options) problemcoded (factorized not). every case, however, observed time gains greaterexpected IFDP.6. Analysis SRn : Counting Number ClassesLet us define quantities interest:-Nn : Number elements SRn .-FP n : Number elements SRn correspond full-period boxes, i.e., boxes periodn.-Nnm : Number elements SRn 1s.-FP nm : Number elements SRn correspond full-period boxes 1s.Polyas theorem (Polya & Read, 1987) could used determine quantities given n building possibly huge polynomial elucidatingcoefficients. present simpler way calculating and, time, makereader familiar concepts used algorithm generate SRn .begin looking expression FP n . number 1s allowed,total number binary numbers 2n . periods exist binarynumbers divisors n. Thus, following equation holds:Xp FP p = 2n .pdiv(n)Segregating p = n,508(3)fiExploiting Single-Cycle SymmetriesXn FP n +p FP p = 2n ,(4)pFP p .n(5)pdiv(n), p<nsolving FP n :FP n =2nnXpdiv(n), p<nrecurrence simple baseline condition: FP 1 = 2.Then, Nn follows easilyNn =XFP p .(6)pdiv(n)Segregating p = n, efficient formula obtained:Nn =2n+nXpdiv(n), p<nnpFP p .n(7)formula valid n > 1. remaining case N1 = 2.nuse similar techniques obtain FP nm Nnm .binary numbers1s n 0s. binary numbers circular shifts others(like 011010 110100). number shifted versions binary number periodbox represented binary number. example, 1010, period 2,another shifted version, 0101. binary number representing box period pnseen concatenation n/p numbers length n/p= p period p. meansconcatenated numbers full-period, n/p1s. Thus, numberbinary numbers period p shifted numbers counted (i.e., numbern. common divisors n m, denoteclasses period p) FP n/pn/pdiv(n, m), periods. Since p shifted versions binary numberperiod p, writeXnn=p FP n/p.(8)n/ppdiv(n,m)change variable f = n/p getXf div(n,m)nFP nf mf =fn.(9)Note index summation goes values before.segregate case f = 1 summand,Xnnn FP nm +FP nf mf =,(10)ff div(n,m), f >1and, finally, obtain509fiRuiz de Angulo & TorrasFP nm =nnFP nf mfXff div(n,m), f >1.(11)recurrence relation FP nm computed using followingbaseline conditions:(0=1FP nn , FP n0n > 1n = 1(12)Nnm obtained adding number classes period:Nnm =XFP nf mf .(13)f div(n,m)Segregating f = 1, efficient formula obtained:Nnm =n+Xn)FP nf mf ,f(14)(1 p)FP p mp ,(15)(1f div(n,m), f >1carrying change variable p = n/f :Nnm =n+Xnpdiv(n,m), p<nNote change summation range. equation valid whenever > 0< n. Otherwise, Nnm = 1.possible extend concept FP n (and FP nm ) reflect number membersp):SRn period p (and 1s), denote Nnp (NnmNnppNnm(0=FP pp/ div(n)otherwise(0=FP p, mpnp/ div(n, m)otherwise(16)(17)Figure 3(a) displays number classes (Nn ) function n. curve indicatesexponential-like behavior. confirmed Figure 3(b) using larger logarithmicscale, curve appears almost perfectly linear. Figure 4 exampledistribution classes period n = 12. Figure 5 shows percentage full-periodclasses SRn (100 Nnn /Nn ). One see percentage classes period differentn significant low n, approaches quickly 0 n grows. Finally, Figures 6(a)6(b) display distribution classes SRn number 1s n = 12n = 100, respectively. majority classes concentrates interval middlegraphic, around n/2. interval becomes relatively smaller n grows.510finumber classes symmetric boxes350300250200150100500246810121x10111x10101x1091x1081x1071x1061x1051x1041x1031x1021x101105box dimensionality (i.e., number variables)1015202530(b)Figure 3: Number elements SRn function n.100101123435box dimensionality (i.e., number variables)(a)number classes symmetric boxesnumber classes symmetric boxesExploiting Single-Cycle Symmetries56789101112box periodFigure 4: Number elements SR12 distributed period.51140fiRuiz de Angulo & Torras7. Generating SRn , Classes Symmetric Boxesnaive procedure obtain SRn would initially generate boxes originated bisectingn-dimensional cube point dimensions time. Then, onecheck boxes set detect whether circular shiftothers. complete process generating SRn way involves huge numberoperations even rather small dimensions. Although SRn ns could precomputed stored database, suggest algorithm capable calculatingSRn fly without significant computational overhead.percentage full-period classes1008060402002468101214161820box dimensionality (i.e., number variables)Figure 5: Percentage full-period elements SRn function n.number classes symmetric boxesnumber classes symmetric boxesmade counting, distinguish different subsets SRn basis number1s period:-SRnm : Subset elements SRn 1s.-SRpnm : Subset elements SRn 1s period p.SRpn : Subset elements SRn period p.global point view, generation SRn carried follows. First,SRn0 generated, constituted always unique member. Afterwards, SRnm7060504030201000246810121x10278x10266x10264x10262x10260020406080100number 1s codenumber 1s code(a)(b)Figure 6: Number elements SRn distributed number 1s. (a) n =12. (b) n=100.512fiExploiting Single-Cycle Symmetries= 1 . . . n generated. generation SRnm divided SRpnm ,p div(n, m), compose it. algorithm ClassGen described generatesfull-period representatives given number variables n > 1 number ones> 0, i.e., generates SRnnm . representatives lower period p div(n, m)obtained concatenating one block n/p = f times. Therefore, order obtainSRpnm , generate SRpp algorithm, concatenate elementsff times. Thus, without loss generality, follows describe workingsalgorithm ClassGen computes codes full period, namely n.use compact coding binary numbers representing boxes consistingordered lists chains numbers. first number code number 0sappearing first 1 binary number. i-th number code > 1number 0s (i1)-th i-th 1s binary number. example,number 0100010111 codified 13100. length numerical codificationnumber 1s codified binary number, denoted m.binary numbers cannot codified way, last digit0. But, except zeros case, always element classcodified correctly (for example 0011 element class 0110). objectiverepresentative class, rather advantage, halfboxes already eliminated beginning. zeros box, SRn0 , commonevery n, generated separately, already mentioned.codification allows determine box full-period waybinary representation: box period n iff number circular shifts lowerlength numerical chain result never equal original. instance,example full-period, 22, corresponding 001001, not. differencethat, new representation, shifts must compared.code box seen number base n m. full-period box,circular shifts code different numbers, arranged strictly increasingnumerical order. take representative box class largest elementclass expressed code (which smallest expressed binary number).example, class 130 two elements represented coding,013 301, latter chosen representative class.Note box belonging SRnm n 0s or, equivalently, sumcomponents code n m.output algorithm codes length m, whose sum componentsn m, representatives class full-period. Codes lengthwhose components sum desired number rather easy generate systematically.representativeness full-period conditions difficult guarantee efficiently.handle exploiting properties codes stated below, makeuse definition i-compability.say code i-compatible compatible position sub-chainbeginning position > 1 ending last position (thus length + 1)strictly smaller numerical terms sub-chain length beginningfirst position. example, 423423 compatible positions 2 3,4-compatible.513fiRuiz de Angulo & TorrasProperty 1 code class representative full-period iff i-compatibles.t. 1 < 6 m.Thus, instead comparing chains length (i.e., code shifted versions),determine code validity comparing shorter sub-chains. second property helpsus devise still faster simpler algorithm:Property 2 code i-compatible sub-chain position + l equalsub-chain position 1 1 + l code also compatible positions + 1+ l.Algorithm 3: CodeValidity algorithm.Input: code length expressed array, A.Output: boolean value indicating whether code valid, i.e., whetherfull-period class representative.12345678910i2ctrol 1V alidCode TrueV alidCode & <A[i] > A[ctrol] V alidCode F alseelse A[i] < A[ctrol] ctrol 1else ctrol ctrol + 1;ii+1/* A[i] = A[ctrol] */A[m] A[ctrol] V alidCode F alsereturn ValidCodeproperty interesting permits checking validity codetravelling along once, shown Algorithm 3. trick decisioni-compatibility delayed position following numbersbeginning string, finally resolves positively, compatibilityintermediate numbers also guaranteed. Hence, i-compatibility either resolvedsimple comparison requires l comparisons. latter case, either compatibilityl positions also resolved (if outcome positive) compatibility intermediatepositions doesnt matter (because outcome negative and, thus, code labellednon valid without checks). ctrol variable charge maintaining last indexhead sub-chain compared current compatibility check.examining compatibility current position i, value lowerctrol position, code sure i-compatible therefore must worry(i + 1)-compatibility back-warding ctrol first position. value ctrolposition equal current position i, compatibility position stillascertained, continue advancing current ctrol positions equalitydisappears. words, condition must fulfilled non rejectinginvalid code position514fiExploiting Single-Cycle SymmetriesAlgorithm 4: ClassGen algorithm.Input: sum numbers remain written right (fromposition pos m), sum.index next position written, pos.index current control element, whose value cannot surpassednext position, ctrol.length code, m.Array class codes generated, A.Output: set codes representing classes, SR.123456789101112131415161718SR EmptySetpos =sum < A[ctrol]A[m] sumSR {A};/* otherwise, SR remain EmptySet */elsepos = 1LowerLimit = dsum/meU pperLimit sumelseLowerLimit = 0U pperLimit Minimum(A[ctrol], sum)= U pperLimit LowerLimitA[pos]= A[ctrol]Sand pos 6= 1/* = A[ctrol] = U pperLimit */SR SR ClassGen(sum i, pos + 1, ctrol + 1, m, A)else/* < A[ctrol] pos = 1 */SR SR ClassGen(sum i, pos + 1, 1, m, A)1920return SRA[i] 6 A[ctrol],(18)condition transformed A[i] < A[ctrol] = resolve lastpending compatibility checks. aside, note codes generalraw binary numbers, representativeness full-periodness definedway both. Therefore, three properties CodeValidity algorithm apply alsoraw binary numbers.rather direct way generate SRnnm would generate codes lengthwhose sum components n (the number zeros expressed binarynumber) filter CodeValidity. Instead, taken515fiRuiz de Angulo & Torrasefficient approach, generating codes satisfy conditions needchecked explicitly CodeValidity. Therefore, Algorithm 3 (presented claritypurposes) used.main procedure obtain full-period representatives 1s, i.e., SRnnm ,recursive program presented Algorithm 4. ClassGen(n m, 1, 1, m, A),array length m, must called obtain SRnnm , given n > 1, > 0.call procedure writes single component code position indicatedparameter pos, beginning pos = 1, subsequently incrementedrecursive call. recursion finishes rightmost end code, pos = m.first parameter, sum, sum components code remain written.range values written position pos limited LowerLimit U pperLimit,except last position m. following show correctness algorithmverifying limits chosen satisfy two requirements code:sum numbers code completed algorithm must nm. First,recall initial call algorithm done using parameter sum = n m.position 1 pos < number written must greaterequal sum numbers still written, quantity represented sum,subsequent positions possible write positive integers, leastzeros. condition imposed U pperLimit line 9 pos = 1 line 12(juxtaposed code validity conditions) 1 < pos < m. number writtenpos substracted sum parameter next recursive call. Finally,pos = m, possibility satisfy sum condition assign valuesum last element code.code validity conditions, CodeValidity, numberwritten position pos must smaller equal A[ctrol] 1 < pos < m,strictly lower A[ctrol] pos = m. conditions reflectedU pperLimit assignments made lines 12 3, respectively. LowerLimit usually(pos < 1, line 4) set smallest possible element codes, 0.beginning code (pos = 1, line 8) tight value chosen since,value lower upper rounded value dsum/me, way distributeremains sum among positions code without putting valuegreater initial one, would make code non-representative.maintenance ctrol variable similar within CodeValidityalgorithm: write pos something strictly minor A[ctrol], ctrol back-wardedfirst position. Otherwise, ctrol incremented 1 next recursive call writepos + 1.output algorithm list valid codes decreasing numerical order.instance, output obtained requesting SR993 ClassGen(6, 1, 1, 3, A) is: {600,510, 501, 420, 411, 402, 330, 321, 312}. example, case recursionarrives pos = without returning valid code frustrated code 222, whose lastnumber written code full-period.Figure 7 displays quantitative results reflect efficiency ClassGen.dashed line accounts complete times required generate class representatives516fiExploiting Single-Cycle Symmetriestotal timemillions representatives per second1.4201.21150.8100.6total time (seconds)number representatives (millions/second)250.450.20510152025300dimensionality (number variables)Figure 7: Total time (dashed line) generate SRn , rates generation (continuousline) class representatives function n.SRn n = 2 n = 30. worth noting SR30 requires secondentirely generated. continuous line encodes division |SRn | time requiredgenerate SRn , measured millions class representatives generated second.evident efficiency ClassGen high even grows slightlyn. behavior shows dead-ends recursion statistically insignificant,proves tightness bounds used enforce values code numbers.8. Conclusionsapproached problem exploiting symmetries continuous constraint satisfaction problems using continuous constraint solvers. approach general makeuse box-oriented CCS black-box procedure. particular symmetriestackled single-cycle permutations problem variables.suggested strategy bisect domain, n-cube initial box, simultaneouslydimensions point. forms set boxes grouped boxsymmetry classes. representative class selected processed CCSsymmetries representative applied resulting solutions.way, solutions within whole initial domain found, processed fraction set representatives CCS. time savingsobtained processing representative applying symmetries solutions tendproportional number symmetric boxes representative. Therefore, symmetry exploitation complete full-period representatives, since maximumnumber symmetric boxes. Another factor improves efficiency could517fiRuiz de Angulo & Torrasexpected considerations smaller average size boxes processedCCS approach.also studied automatic generation classes resulting bisectingn-cube analyzed numerical properties. algorithm generating classespowerful, eliminating convenience pre-calculated table. numericalanalysis classes revealed average number symmetries class representatives tends quickly n number variables, n, grows. good news,since n maximum number symmetries attainable single-cycle symmetriesn variables, leading time reductions factor close n. Nevertheless, small nstill significant fraction representatives maximum numbersymmetries. Another weakness proposed strategy exponential growthnumber classes function n.problems small large n tackled refined subdivisioninitial domain box symmetry classes, left near future work.also currently approaching extension work deal permutationsproblem variables composed several cycles. Another complementary research lineaddition constraints search CCS. constraints specificsymmetry class. Finally, extension Branch-and-Bound algorithms nonlinearoptimization could envisaged.Acknowledgmentsextended version work presented CP 2007 (Ruiz de Angulo & Torras, 2007).authors acknowledge support Generalitat de Catalunya consolidatedRobotics group, Spanish Ministry Science Education, project DPI200760858, Comunitat de Treball dels Pirineus project 2006ITT-10004.ReferencesBenhamou, F., & Goualard, F. (2000). Universally quantified interval constraints.Springer-Verlag (Ed.), CP 02: Proceedings 6th International ConferencePrinciples Practice Constraint Programming, pp. 6782.Bjorck, G., & Froberg, R. (1991). faster way count solutions inhomogeneoussystems algebraic equations, applications cyclic n-roots. J. Symb. Comput.,12 (3), 329336.Blumenthal, L. (1953). Theory aplications distance geometry. Oxford UniversityPress.Cohen, D., Jeavons, P., Jefferson, C., Petrie, K. E., & Smith, B. M. (2006). Symmetrydefinitions constraint satisfaction problems. Constraints, 11 (2-3), 115137.Flener, P., Frisch, A., Hnich, B., Kiziltan, Z., & Miguel, I. (2002). Breaking row columnsymmetries matrix models. CP 02: Proceedings 8th International Conference Principles Practice Constraint Programming, pp. 462476. Springer.518fiExploiting Single-Cycle SymmetriesGent, I. P. (2002). Groups constraints: Symmetry breaking search.Proceedings CP-02, LNCS 2470, pp. 415430. Springer.Granvilliers, L., & Benhamou, F. (2006). Realpaver: interval solver using constraintsatisfaction techniques. ACM Trans. Mathematical Software, 32, 138156.Hentenryck, P. V., Mcallester, D., & Kapur, D. (1997). Solving polynomial systems usingbranch prune approach. SIAM Journal Numerical Analysis, 34, 797827.Jermann, C., & Trombettoni, G. (2003). Inter-block backtracking : Exploiting structure continuous csps. In: 2nd International Workshop Global ConstrainedOptimization Constraint Satisfaction, pp. 1530. Springer.Jermann, C. (2008). Personal communication..Meseguer, P., & Torras, C. (2001). Exploiting symmetries within constraint satisfactionsearch. Artif. Intell., 129 (1-2), 133163.Polya, G., & Read, R. (1987). Combinatorial enumeration groups, graphs chemicalcompounds. Springer-Verlag.Porta, J. M., Ros, L., Thomas, F., Corcho, F., Canto, J., & Perez, J. (2008). Completemaps molecular loop conformational spaces. Journal Computational Chemistry,29 (1), 144155.Porta, J. M., Ros, L., Thomas, F., & Torras, C. (2005). branch-and-prune solverdistance constraints. IEEE Trans. Robotics, 21, 176187.Puget, J.-F. (2005). Symmetry breaking revisited. Constraints, 10 (1), 2346.Ruiz de Angulo, V., & Torras, C. (2007). Exploiting single-cycle symmetries branchand-prune algorithms. CP 07: Proceedings 13th International ConferencePrinciples Practice Constraint Programming, pp. 864871.Sam-haroud, D., & Faltings, B. (1996). Consistency techniques continuous constraints.Constraints, 1, 85118.Sherbrooke E. C., P. N. M. (1993). Computation solution nonlinear polynomialsystems. Computer Aided Geometric Design, 10, 379405.Vu, X.-H., Silaghi, M., Sam-Haroud, D., & Faltings, B. (2005). Branch-and-prune searchstrategies numerical constraint solving. Tech. rep. LIA-Report 7, Swiss FederalInstitute Technology (EPFL).519fiJournal Artificial Intelligence Research 34 (2009) 1-25Submitted 04/08; published 1/09Interactive Policy LearningConfidence-Based AutonomySonia ChernovaManuela Velososoniac@cs.cmu.eduveloso@cs.cmu.eduComputer Science Dept.Carnegie Mellon UniversityPittsburgh, PA USAAbstractpresent Confidence-Based Autonomy (CBA), interactive algorithm policylearning demonstration. CBA algorithm consists two components takeadvantage complimentary abilities humans computer agents. first component, Confident Execution, enables agent identify states demonstrationrequired, request demonstration human teacher learn policy basedacquired data. algorithm selects demonstrations based measure actionselection confidence, results show using Confident Execution agent requires fewer demonstrations learn policy demonstrations selectedhuman teacher. second algorithmic component, Corrective Demonstration, enablesteacher correct mistakes made agent additional demonstrationsorder improve policy future task performance. CBA individual components compared evaluated complex simulated driving domain. completeCBA algorithm results best overall learning performance, successfully reproducingbehavior teacher balancing tradeoff number demonstrationsnumber incorrect actions learning.1. IntroductionLearning demonstration growing area artificial intelligence research explorestechniques programming autonomous agents demonstrating desired behaviortask. demonstration-based approaches, teacher, typically human, shows agentperform task. agent records demonstrations sequences stateaction pairs, learns policy reproduces observed behavior.Many learning demonstration approaches inspired way humans animalsteach other, aiming provide intuitive method transfer human task knowledgeautonomous systems. Compared exploration-based methods, demonstration learningoften reduces learning time eliminates frequently difficult task definingdetailed reward function (Smart, 2002; Schaal, 1997).article, present interactive demonstration learning algorithm, ConfidenceBased Autonomy (CBA), enables agent learn policy interactionhuman teacher. learning approach, agent begins initial knowledgelearns policy incrementally demonstrations acquired practices task.demonstration consists training point representing correct action performedparticular state. agents state represented using n-dimensional feature vectorc2009AI Access Foundation. rights reserved.fiChernova & Velosocomposed continuous discrete values. agents actions boundfinite set action primitives, basic actions combined together performoverall task. Given sequence demonstrations (si , ai ), state si teacherselected action ai A, goal agent learn imitate teachers behaviorgeneralizing demonstrations learning policy mapping possiblestates actions A.method gathering demonstrations heart demonstration learningalgorithms. CBA performs function two algorithmic components: ConfidentExecution, enables agent select demonstrations real time interactsenvironment using automatically calculated confidence thresholds, Corrective Demonstration, enables teacher improve learned policy correctmistakes additional demonstrations. complete Confidence-Based Autonomyalgorithm provides fast intuitive method policy learning, incorporating shareddecision making learner teacher. experimental evaluation,highlight strengths learning components compare learning performancefive different demonstration selection techniques. results indicate complexdomain, Confident Execution algorithm reduces number demonstrations requiredlearn task compared demonstration selection performed human teacher.Additionally, find teachers ability correct mistakes performed agentcritical optimizing policy performance.Section 2, discuss related work learning demonstration. presentoverview complete Confidence-Based Autonomy learning algorithm Section 3,followed detailed descriptions Confident Execution Corrective Demonstrationcomponents Sections 4 5, respectively. Section 6, present experimentalevaluation complete algorithm components complex simulated drivingdomain. Section 7 presents summary discussion possible extensions work.2. Related Workwide variety algorithms policy learning demonstration proposedwithin machine learning robotics communities. Within context reinforcementlearning (Sutton & Barto, 1998), demonstration viewed source reliableinformation used accelerate learning process. number approachestaking advantage information developed, deriving modifyingreward function based demonstrations (Thomaz & Breazeal, 2006; Abbeel & Ng,2004; Papudesi, 2002; Atkeson & Schaal, 1997), using demonstration experiencesprime agents value function model (Takahashi, Hikita, & Asada, 2004; Price &Boutilier, 2003; Smart, 2002; Schaal, 1997).Demonstration also coupled supervised learning algorithms policylearning, including Locally Weighted Regression low level skill acquisition (Grollman &Jenkins, 2007; Browning, Xu, & Veloso, 2004; Smart, 2002), Bayesian networks high levelbehaviors (Lockerd & Breazeal, 2004; Inamura, Inaba, & Inoue, 1999), k-nearestneighbors algorithm fast-paced games robot navigation tasks (Saunders, Nehaniv,& Dautenhahn, 2006; Bentivegna, Ude, Atkeson, & Cheng, 2004). recent survey covers2fiInteractive Policy Learning Confidence-Based Autonomydemonstration learning algorithms detail (Argall, Chernova, Browning,& Veloso, 2009).addition policy learning demonstration, several areas research alsoexplored algorithms demonstration selection. Within machine learning research, activelearning (Blum & Langley, 1997; Cohn, Atlas, & Ladner, 1994) enables learner queryexpert obtain labels unlabeled training examples. Aimed domainslarge quantity data available labeling expensive, active learning directsexpert label informative examples goal minimizing numberqueries. context reinforcement learning, Ask Help framework enablesagent request advice agents confused action take,event characterized relatively equal quality estimates possible actions givenstate (Clouse, 1996). Similarly motivated techniques used robotics identifysituations robot request demonstration teacher (Grollman &Jenkins, 2007; Lockerd & Breazeal, 2004; Nicolescu, 2003; Inamura et al., 1999).closely related work Dogged Learning algorithm (Grollman & Jenkins, 2007),confidence-based learning approach teaching low-level robotic skills. algorithm,robot indicates teacher certainty performing various elements task.teacher may choose provide additional demonstrations based feedback.similarly motivated, work differs Dogged Learning algorithm numberways, important use classification instead regression policylearning, algorithms ability adjust confidence threshold data insteadusing fixed value.3. Confidence-Based Autonomy OverviewConfence-Based Autonomy algorithm enables human user train task policydemonstration. algorithm consists two components:Confident Execution (CE): algorithm enables agent learn policy baseddemonstrations obtained regulating autonomy requesting helpteacher. Demonstrations selected based automatically calculated classificationconfidence thresholds.Corrective Demonstration (CD): algorithm enables teacher improvelearned policy correcting mistakes made agent supplementarydemonstrations.Figure 1 shows interaction components. Using Confident Execution algorithm, agent selects states demonstration real time interactsenvironment, targeting states unfamiliar current policy actionuncertain. timestep, algorithm evaluates agents current state activelydecides autonomously executing action selected policy requestingadditional demonstration human teacher.assume underlying model agents task MDP. agents policyrepresented learned using supervised learning based training data acquireddemonstrations. Confidence-Based Autonomy combined supervised3fiChernova & VelosoFigure 1: Confidence-Based Autonomy learning process.learning algorithm provides measure confidence classification. policyrepresented classifier C : (a, c, db), trained using state vectors si inputs,actions ai labels. classification query, model returns model-selectedaction A, action selection confidence c, decision boundary db highestconfidence query (e.g. Gaussian component GMMs).effectively select demonstrations, learner must able autonomously identifysituations demonstration provide useful information improve policy.Confident Execution selects agent autonomy request demonstration basedmeasure action-selection confidence c returned classifier. Given currentstate learner, algorithm queries policy obtain confidence selectingaction state, regulates autonomy based confidence. learnerexecutes returned action ap confidence c threshold , determineddecision boundary classifier, db. Confidence threshold indicatesagent uncertain action take, seeks help teacherform demonstration. Receiving additional demonstration, ad , low confidencesituation improves policy, leading increased confidence, therefore autonomy,future similar states. training data becomes available, quality policyimproves autonomy agent increases entire task performedwithout help teacher. Section 4 compare two methods using classificationconfidence select states demonstration.Using Confident Execution algorithm, agent incrementally acquires demonstrations explores environment. practices task, agent uses policylearned point make decisions demonstration autonomous execution. However, relying policy learning complete, algorithm likely4fiInteractive Policy Learning Confidence-Based Autonomymake mistakes due factors overgeneralization classifier incompletedata area state space. address problem article introducessecond algorithmic component, Corrective Demonstration, allows teacher provide corrections agents mistakes. Using method, incorrect actionobserved, teacher provides additional demonstration agent indicatingaction executed place. addition indicating wrong action selected, method also provides algorithm correct action performplace, ac . correction therefore informative negative reinforcementpunishment techniques common algorithms, leading agent learn quicklymistakes.Together, Confident Execution Corrective Demonstration form interactive learning algorithm learner human teacher play complimentary roles. learnerable identify states demonstration required; fact, results showalgorithm able better human teacher due differences perceptionrepresentation abilities. teacher, hand, possesses expert knowledgeoverall task, applied performing demonstrations spotting executionmistakes. function agent cannot perform yet learneddesired behavior. way, Confidence-Based Autonomy takes advantagecomplimentary abilities human agent. Sections 4 5 present ConfidentExecution Corrective Demonstration components detail.4. Confident Execution AlgorithmConfident Execution policy learning algorithm agent must select demonstration examples, real time, interacts environment. timestep,algorithm uses thresholds determine whether demonstration correct actionagents current state provide useful information improve agents policy.demonstration required, agent requests help teacher, updates policy based resulting action label. Otherwise agent continues perform taskautonomously based policy.two distinct situations agent requires help teacher,unfamiliar states ambiguous states. unfamiliar state occurs agent encounters situation significantly different previously demonstrated state,represented outlying points Figure 2. want demonstrateevery possible state, therefore need model generalize, would like preventover-generalization truly different states.Ambiguous states occur agent unable select multiple actionscertainty. situation result demonstrations different actions similarstates make accurate classification impossible, region overlapping data classesFigure 2. cases, additional demonstrations may help disambiguate situation.goal Confident Execution algorithm divide state space regionshigh confidence (autonomous execution) low confidence (demonstration)unfamiliar ambiguous regions fall low confidence areas. Given world state,two evaluation criteria used select demonstration autonomy:5fiChernova & VelosoNearest Neighbor distance: Given = N earestN eighbor(s), distancecurrent state nearest (most similar) training datapoint, agent may actautonomously distance threshold dist .Classification confidence: Given c, classification confidence current state,agent may act autonomously value c confidence thresholdconf .methods calculating thresholds dist conf presented Sections 4.1 4.2.section, continue discussion Confident Execution algorithm assumingvalues given.Algorithm 1 presents details Confident Execution algorithm. assumepreexisting knowledge task, initialize algorithm empty settraining points . Since classifier initially available, threshold conf initializedinfinity ensure agent controlled demonstration initiallearning stage. Distance threshold dist initialized 0.main learning algorithm consists loop (lines 4-20), iterationrepresents single timestep. behavior algorithm determined whetheragent currently executing action. action progress, algorithm performsadditional computation timestep (line 20). action complete,algorithm evaluates state determine next action perform (lines 6-18).Evaluation begins obtaining agents current state environment (line 6).information used calculate nearest neighbor distance querylearned classifier C obtain policy action ap confidence c. valuescompared confidence distance thresholds decide demonstrationautonomy (line 9). similar states previously observed, learned modelconfident selection, algorithm finishes timestep initiating autonomousFigure 2: Outlying points regions overlapping data classes represent unfamiliarambiguous state regions, respectively.6fiInteractive Policy Learning Confidence-Based AutonomyAlgorithm 1 Confident Execution Algorithm1: {}2: conf inf3: dist 04: true5:actionComplete6:GetSensorData()7:= NearestNeighbor(s)8:(ap , c, db) C(s)9:c > conf < dist10:ExecuteAction(ap )11:else12:RequestDemonstration()13:ad GetTeacherAction()14:ad 6= N U15:{(s, ad )}16:C UpdateClassifier(T )17:(conf , dist ) UpdateThresholds()18:ExecuteAction(ad )19:else20://do nothingexecution policy selected action ap (line 10). Otherwise initiates requestteacher demonstration (lines 12-18).agent requests demonstration pausing indicating teacherdemonstration required. Note assume domain allows agent pauseexecution. Following demonstration request, algorithm checks whether demonstration performed (lines 13-14). teachers response available, new trainingdatapoint consisting current state corresponding demonstrated action adadded training set (line 15). model classifier retrained, thresholdvalues updated, executing teacher selected action (lines 16-18).teachers response immediately available, timestep terminateswhole process repeated next iteration. agent senses state, performsthreshold comparison checks demonstration. non-blocking mechanismenables agent wait demonstration teacher without losing awarenesssurroundings. cases agents environment dynamic, maintainingdate information important state may change time initialrequest demonstration. Associating action label agents recentstate, one teacher likely responding to, therefore critical learningaccurate model. Additionally, changes environment result agent attaininghigh confidence state without actions own. cases, autonomous executiontask automatically resumed. summary, demonstration request made,actions taken agent either demonstration receivedteacher, changes environment result high confidence state.7fiChernova & VelosoUsing approach, Confident Execution enables agent incrementally acquiredemonstrations representing desired behavior. datapoints acquired, fewerstates distant training data encountered, performance classificationconfidence improve, autonomy agent increases. Task learning completeagent able repeatedly perform desired behavior without requesting demonstrations. following sections present methods calculating distanceconfidence thresholds.4.1 Distance Thresholdpurpose distance threshold evaluate similarity agentscurrent state previous demonstrations. evaluation metric uses nearest neighbordistance, defined Euclidian distance query closest pointdataset. agent state query, obtain nearest neighbor distance representingsimilar previously demonstrated state. value compared distancethreshold dist .value distance threshold dist calculated function average nearestneighbor distance across dataset demonstrations. Evaluating average similaritystates provides algorithm domain-independent method detectingoutliers, points unusually far previously encountered states. trials article,value dist set three times average nearest neighbor distance acrossdataset.alternate method detecting outliers would use classification confidencerequest demonstrations low confidence states. However, situations ariseconfidence directly correlated state similarity. example, many classifiersset datapoints encircling empty region, similar shape donut, would resulthighest classification confidence associated empty center region farprevious demonstrations. Distance provides reliable prediction similarity, evencases.4.2 Confidence Thresholdconfidence threshold used select regions uncertainty pointsmultiple classes overlap. agents perspective, points regions representdemonstrations two distinct actions states appear similar, difficultdistinguish based sensor data. problem frequently arises demonstrationlearning number reasons, teachers inability demonstrate taskconsistently, noise sensor readings, inconsistency agentsteachers sensing abilities. would like set confidence threshold valueprevents either model classifying overlapping region high confidence1 .following section discuss use limitations single fixed threshold value.present algorithm using multiple adjustable thresholds Section 4.2.2.1. See Section 7.2 discussion data regions.8fiInteractive Policy Learning Confidence-Based Autonomy(a)(b)(c)Figure 3: Examples fixed threshold failure cases: (a) Fully separable data classesoverly conservative threshold value (b) Overlapping data classes overlygeneral threshold value (c) Data classes different distributions commonthreshold value4.2.1 Single Fixed Thresholdsingle, fixed confidence threshold value provides simple mechanism approximatehigh confidence regions state space. Previous algorithms utilizing classification confidence threshold behavior arbitration used manually-selected single thresholdvalue (Inamura et al., 1999; Lockerd & Breazeal, 2004; Grollman & Jenkins, 2007). However, choosing appropriate value difficult constantly changing datasetmodel. Figure 3 presents examples three frequently encountered problems.Figure 3(a) presents case two action classes distinct fully separable.model trained dataset able classify points complete accuracy, withoutmisclassifications. However, current threshold value classifies 72% pointshigh confidence, marking remaining 28% points uncertain. case,lower threshold value would preferred would allow model generalizefreely. resulting larger high confidence region would reduce number redundantdemonstrations without increasing classification error rate either data class.Figure 3(b) presents example opposite case, stricter threshold valuewould preferred. example data classes overlap, resulting middle regionpoints cannot classified high accuracy. higher threshold value wouldprevent classification points region either data class, initiating insteadrequest demonstration would allow teacher disambiguate situation.Figure 3(c) presents case datapoints two data classesdifferent distributions. fixed threshold value appropriate left class, 42%points right class labeled low confidence.Classification complex multi-class data depends upon multiple decision boundaries.Using value decision boundaries exacerbate problems highlightedabove, single value often cannot found constrains model classificationareas allowing generalization others. resulting effect agent requestsmany demonstrations things already knows, demonstrationsunlearned behavior. address problem, present algorithm calculatingunique threshold value decision boundary.9fiChernova & Veloso(a)(b)(c)Figure 4: Autonomy threshold calculation: (a) Example dataset, highlighted overlapping region (b) Learned decision boundary, misclassified points markedconfidence values (c) Learned threshold values data class, low confidence region containing overlapping points remains center.4.2.2 Multiple Adjustable Thresholdssection, contribute algorithm calculating confidence thresholddecision boundary, customized unique distribution points. analysis,assume able query classifier obtain confidence score representinglikelihood particular input belongs within specified decision boundary.algorithm begins dividing dataset training test set trainingclassifier C. resulting learned model used classify withheld test set,correct action labels known. algorithm calculates unique confidencethreshold decision boundary based confidence scores misclassified points.Given confidence scores set points mistakenly classified decision boundary,assume future classifications confidences values likelymisclassifications well. threshold therefore calculated functionconfidence scores.Specifically, define classified point tuple (o, a, , c), originalobservation, demonstrated action label, model-selected action, cmodel action confidence. Let Mi = {(o, ai , , c)|am 6= ai } set pointsmistakenly classified decision boundary i. confidence thresholdPvalue setMicaverage classification confidence misclassified points: conf = |Mi | . takeaverage avoid overfitting noisy data. values, based maximum standarddeviation, used conservative estimate required. threshold value 0indicates misclassifications occurred model able generalize freely.Figure 4 presents example threshold calculation process. Figure 4(a) presentssmall sample dataset, rectangular box figure highlights region statespace points classes overlap. Figure 4(b) shows learned decisionboundary (in case SVM) separating two data classes. Six misclassified pointsmarked (mis-)classification confidences returned model. Misclassified pointsside decision boundary used calculate respective confidencethresholds. Figure 4(c) shows confidence threshold lines values based10fiInteractive Policy Learning Confidence-Based Autonomy(a)(b)(c)Figure 5: Multiple adjustable thresholds applied failure cases shown Figure 3.calculations. resulting low confidence region middle image capturesnoisy datapoints.Given multi-threshold approach, classification new points performed firstselecting action class highest confidence query. comparisonline 9 Algorithm 1 performed using threshold decision boundaryhighest confidence query. Using method, threshold valuelikely decision boundary represent point used decide demonstrationautonomy.Figure 5 shows example failure cases discussed Section 4.2.1 addressedmulti-thresholded approach. Customizing threshold value unique datadistribution enables algorithm correctly classify 100% points Figures 5(a)(c). Since misclassifications, model generalizes freely examples.dataset Figure 5(b), perfect classification possible, confidencethresholds set overlapping region falls low confidence area.example uses Gaussian mixture model, elliptical confidence gradient aroundmean results large low confidence area even far overlapping region.classification methods, Support Vector Machines, drawback.presented multi-threshold approach algorithm independent, Figure 6 presentsclassification results four different classification methods: Gaussian mixture models, random forests (RF), Support Vector Machine quadratic kernel, SVM radialbasis function (RBF) kernel. table summarizes classification performancealgorithm lists threshold values models.AlgorithmGMMRFSVM quad.SVM RBFCorrect-Misclas.-Unclass.98.6% 0.4% 1.0%99.1% 0.1% 0.8%98.5% 0.1% 1.4%98.9% 0.1% 1.0%Thresholds(0, 0, 0.012)(0.14, -0.355)(335.33, -68.77)(0.825, -0.268)Table 1: Classifier comparison.11fiChernova & Veloso(a) Gaussian mixture model(b) Random Forest(c) SVM (quadratic)(d) SVM (RBF)Figure 6: Classification dataset high low confidence regions using different classification methods.5. Corrective Teacher Demonstrationpresented Confident Execution algorithm enables agent identify unfamiliarambiguous states prevents autonomous execution situations. However, statesincorrect action selected high confidence autonomous executionstill occur, typically due over-generalization classifier. article presentCorrective Demonstration algorithm which, coupled Confident Execution, enablesteacher correct mistakes made agent. Algorithm 2 combines CorrectiveDemonstration (lines denoted ) Confident Execution presents completeConfidence-Based Autonomy algorithm.Corrective Demonstration technique comes play time agent executesautonomous action. action selected autonomous execution, algorithmrecords agents state led decision saves value within variable sc(line 11). execution autonomously selected action, algorithm checksteacher demonstration every timestep (lines 22-23). corrective demonstrationmade, new training datapoint consisting recorded demonstration state sccorrective action ac added training set (line 24). classifier thresholdsretrained using new information.12fiInteractive Policy Learning Confidence-Based AutonomyAlgorithm 2 Confidence-Based Autonomy algorithm: Confident Execution CorrectiveDemonstration1: {}2: conf inf3: dist 04: true5:GetSensorData()6:actionComplete7:(ap , c, db) C(s)8:= NearestNeighbor(s)9:c > conf < dist10:ExecuteAction(ap )11:sc12:else13:RequestDemonstration()14:ad GetTeacherAction()15:ad 6= N U16:{(s, ad )}17:C UpdateClassifier(T )18:(conf , dist ) UpdateThresholds()19:ExecuteAction(ad )20:else21:autonomousAction22:ac GetTeacherAction()23:ac 6= N U24:{(sc , ac )}25:C UpdateClassifier(T )26:(conf , dist ) UpdateThresholds()Using algorithm, teacher observes autonomous execution agentcorrects incorrect actions. Unlike previous demonstration techniqueagent given next action perform, correction performed relationagents previous state mistake made. example, observingdriving agent approaching close behind another car, teacher able indicateinstead continuing drive forward, agent mergingpassing lane. way, addition indicating wrong action performed,Corrective Demonstration also provides algorithm actionperformed place. technique effective negative reinforcement,punishment, techniques common algorithms, leading agent learn quicklymistakes.13fiChernova & VelosoFigure 7: Screenshot driving simulator. agent, black car currentlycenter lane, drives fixed speed must navigate around cars avoidcollisions. road consists five lanes: three traffic lanes two shoulderlanes.6. Evaluation Comparisonsection present evaluation comparison complete Confidence-BasedAutonomy algorithm components simulated car driving domain (Abbeel & Ng,2004), shown Figure 7.6.1 Domain Descriptiondriving domain, agent represents car driving busy highway.learners car travels fixed speed 60 mph, cars move lanespredetermined speeds 20 40 mph. road three normal lanesshoulder lane sides; agent allowed drive shoulder passcars, cannot go off-road. Since learner cannot change speed, mustnavigate cars use shoulder lanes avoid collision. agentlimited three actions: remaining current lane, shifting one lane leftright current position (A = {forward,left,right}). teacher demonstrates taskkeyboard interface. simulator framerate 5 fps pauseddemonstration requests.agents state represented by: = {l, dl , dc , dr }. State feature l discrete valuesymbolizing agents current lane number. remaining three features, denotedletter d, represent distance nearest car three driving lanes(left, center right). distance features continuously valued [-25,25] range;note nearest car lane behind agent. Distance measurementscorrupted noise create complex testing environment. agents policyrelearned time 10 new demonstrations acquired.driving domain presents varied challenging environment; car distancesdiscretized rounding nearest integer value, domain would contain600,000 possible states. Due complexity domain, agent requires large14fiInteractive Policy Learning Confidence-Based Autonomynumber demonstrations initialize classifier, resulting nearly constant demonstration requests early training process. simplify task teacher, addshort 300 datapoint, approximately 60 second, non-interactive driving demonstrationsession initialize learning process. learning stage required, simplifies task teacher continuous demonstration preferred frequentpauses demonstration requests.performance learning algorithm evaluated time 100 new demonstrations acquired. evaluation, agent drove 1000 timesteps roadsegment fixed consistent traffic pattern. road segment usedtraining, instead algorithm trained using randomly generated car traffic pattern.Since algorithm aims imitate behavior expert, true reward functionexists evaluate performance given policy. present two domain-specific evaluation metrics capture key characteristics driving task. first evaluationmetric agents lane preference, proportion time agent spendslane course trial. metric provides estimate similarity drivingstyles. Since demonstrated behavior attempts navigate domain without collisions,second evaluation metric number collisions caused agent. Collisionsmeasured percentage total timesteps agent spends contactanother car. Always driving straight colliding every car middle lane results30% collision rate.6.2 Experimental Resultspresent performance evaluation comparison following demonstrationselection techniques:G Teacher-guided, demonstrations selected teacher without confidence feedback algorithm without ability perform retroactivecorrectionsCES Confident Execution, demonstrations selected agent using singlefixed confidence thresholdCEM Confident Execution, demonstrations selected agent using multipleadjustable confidence thresholdsCD Corrective Demonstration, demonstrations selected teacher performed corrections response mistakes made agentCBA complete Confidence-Based Autonomy algorithm combining ConfidentExecution using multiple adjustable confidence thresholds Corrective Demonstrationdemonstration selection method, underlying policy agent learnedusing multiple Gaussian mixture models, one action class (Chernova & Veloso,2007). Videos driving task available www.cs.cmu.edu/soniac.Figure 8 presents performance results five algorithms respectdefined lane preference collision metrics. describe discuss elements15fiChernova & VelosoFigure 8: Evaluation agents driving performance 100-demonstration intervalsfive demonstration selection methods. bar graphs indicatepercentage time agent spent road lane. Values barindicate percentage collision timesteps accrued evaluation trial.teacher performance bar right figure shows teachers drivinglane preference collision rate evaluation road segment. goalalgorithm achieve performance similar teacher.16fiInteractive Policy Learning Confidence-Based Autonomyfigure detail following sections. evaluation, figure presents barrepresenting composite graph showing percentage time spent agentlane. value bar indicates number demonstrations uponevaluated policy based. value bar indicates percentage incurredcollisions evaluation.bar right figure shows performance teacher evaluation road segment. evaluation indicates teacher prefers drive centerleft lanes, followed preference left shoulder, right shoulder right lane.teacher also successfully avoids collisions, resulting collision rate 0%. goallearning algorithm achieve driving lane pattern similar teacheralso without collisions. Note that, described previous section, policy learninginitialized 300-demonstration dataset algorithms. initializationresults identical performance across algorithms initial learning segment.6.2.1 G Demonstration Selectiontop row Figure 8 summarizes performance teacher-guided demonstrationselection approach. approach, teacher performed training alternatingobserving performance agent selecting demonstrations that, opinion,would improve driving performance. teacher selected training examples withoutreceiving feedback action selection confidence, without ability providecorrective demonstrations incorrect actions already executed agent.Instead, teacher required anticipate data would improve policy.training process terminated teacher saw improvement agentperformance.Figure 8 shows results agents performance evaluations 100-demonstrationintervals throughout learning process. similarity driving lane preferenceagent improves slowly course learning, significant fluctuations.example, 500 demonstrations, agents preference drive empty leftshoulder, thereby incurring collisions. One hundred demonstrations later, policyshifted prefer center lane. However, agent yet learned avoidcars, resulting 38.8% collision rate. policy stabilizes approximately 1100demonstrations, representing driving style similar teacher, smallnumber collisions. Without confidence feedback agent, difficultteacher select exact termination point learning. Training continued until,1300 demonstrations, learners policy showed little improvement. final policyresulted lane preference similar expert, 2.7% collisionrate.6.2.2 CES Demonstration Selectionsecond row Figure 8 presents results Confident Execution algorithmsingle autonomy threshold. demonstration selection approach, demonstrationsselected agent learning terminated agent stopped requestingdemonstrations performed actions autonomously. autonomy threshold value17fiChernova & Velososelected hand evaluated multiple performance trials. Results best fixedthreshold presented.Compared teacher-guided approach, policy learned using CES algorithmstabilizes quickly, achieving performance similar teachers 700 demonstrations. number collisions low persistent, even agent gains fullconfidence stops requesting demonstrations 1008 demonstrations. final lanepreference similar expert, collision rate 3.8%.6.2.3 CEM Demonstration Selectionthird row Figure 8 presents results Confident Execution algorithmmultiple autonomy thresholds, calculated using algorithm presented Section 4.2.2. demonstration selection methods, CEM required fewest numberdemonstrations learn task, completing learning 504 demonstrations.result indicates use multiple adjustable thresholds successfully focuses demonstration selection informative areas state space greatly reducing numberredundant demonstrations. Throughout learning process, number Gaussiancomponents within model varied 9 41. large variation highlightsimportance automating threshold calculation process, since hand-selecting individualthresholds component would impractical. lane preference final policysimilar expert. However, agent still maintained small collisionrate 1.9%.6.2.4 CD Demonstration Selectionevaluation first three algorithms highlights difficulty driving problem.approaches able select demonstrations resulted policymimics overall driving style teacher. However, policies resultedsmall number collisions, typically occurred agent merged closeanother vehicle touched bumper. mistakes difficult correct usingtechniques evaluated far. Even within teacher guided demonstration selectionmethod, human teacher full control demonstration training data,time collision observed incorrect decision already madealgorithm. Instead, retroactive demonstration required correct already mademistakes, Corrective Demonstration algorithm.fourth row Figure 8 present evaluation demonstration selectionusing Corrective Demonstration algorithm. approach, demonstrationsselected teacher corrections response mistakes made agent.Behavior corrected teacher included collisions, well incorrect lane preference(e.g. always driving shoulder) rapid oscillations lanes. enableteacher accurately perform corrections, simulation slowed 5 2 framesper second. Learning terminated agent required corrections.shown Figure 8, complete training process using Corrective Demonstration took 547demonstrations, achieving final policy correctly imitates teachers driving style0% collision rate. following section, discuss performance comparescomplete CBA algorithm.18fiInteractive Policy Learning Confidence-Based Autonomy6.2.5 CBA Demonstration Selectionfinal row Figure 8 presents evaluation complete Confidence-Based Autonomy algorithm, combines CEM CD. Using approach, learning completeagent longer requests demonstrations able perform driving taskwithout collisions. Using CBA agent required total 703 demonstrations learntask, successfully learning navigate highway without collisions.analyze impact two CBA learning components comparing numberdistribution demonstrations acquired algorithm learning process.section refer learning components CBA CBA-CE CBA-CDdifferentiate algorithm evaluations presented previous sections. Notebehavior Confident Execution component dependent upon method usedset autonomy thresholds. evaluation use multiple adjustable thresholdscalculated average value misclassified points.Figure 9(a), datapoint along x-axis represents number demonstrationsrequested using CBA-CE (top) initiated teacher using CBA-CD (bottom)100-timestep interval, approximately 40 seconds simulator runtime (excluding pausesdemonstration requests). Since first three 100-demonstration timesteps consist entirely non-interactive demonstration, values timesteps 100 and, duescaling, exceed bounds graph. Figure 9(b) shows cumulative numberdemonstrations component, total, grows respect training time.complete training process lasts approximately hour half.Analysis graphs shows demonstrations occur early trainingprocess. Importantly, Confident Execution accounts 83% total number demon-(a)(b)Figure 9: (a) Timeline showing number demonstrations initiated agentConfident Execution (top) initiated teacher Corrective Demonstrations (bottom) changes course training. (b)cumulative number demonstrations acquired component, total,time.19fiChernova & Velosostrations, indicating agent guides learning. demonstration requests occur first minutes training agent encountersmany novel states classification confidence remains low. agent requirescorrections stage many mistakes prevented requesting demonstration instead performing low confidence action. Corrective Demonstration playsgreatest role towards end training process, accounts 73% final100 demonstrations. stage learning agents action selection confidencehigh enough rarely asks demonstrations. policy already closely imitatesteachers driving style small number collisions remain. Corrective Demonstrationenables teacher fine-tune policy eliminate collisions. result highlightsimportance Corrective Demonstration, whether alone conjunction anotherselection technique, optimizing policy performance.CBA achieves similar final performance compared CD algorithm evaluatedprevious section, requires approximately 150 additional demonstrations learnpolicy. additional demonstrations attributed Confident Execution demonstration requests served increase classification confidence changeoutcome agents action. Viewed another way, datapoints correspond statesagent would performed correct action even askeddemonstration. result appears allowing agent make mistakescorrecting fact, done CD evaluation, may best demonstrationselection approach respect performance metrics defined overallnumber demonstrations.However, eliminating ability request demonstrations utilizing retroactive correction several drawbacks, namely requiring constant full attentionteacher, and, importantly, requiring agent make many mistakes learnscorrect policy. comparison, CBA algorithm enables agent request demonstrations low confidence states, thereby avoiding many incorrect actions. originallane preference collision metrics take difference account focusfinal policy performance agent.evaluate difference algorithms, additionally examine numbercollisions agent incurs course learning. Using CD algorithm,agent incurs 48% collisions (278 vs. 188) training using CBA.Therefore, allowing agent request demonstrations low-confidence states,CBA algorithm requires slightly greater number demonstrations greatly reducingnumber incorrect actions performed learning. reduction numberaction errors significant due importance many learning domains, especiallyrobotic applications errors may pose dangers system.summary, evaluation shown ability retroactively correct mistakescrucial optimizing policy eliminating collisions. best performanceachieved Corrective Demonstration Confidence-Based Autonomy methods,CD requiring fewer demonstrations incurring greater number collisionstraining. choice CD CBA therefore viewed tradeoffnumber demonstrations frequency undesired actions training.fact, CD special case CBA autonomy threshold set classifypoints high confidence. Adjusting selectiveness CBA autonomy thresholds20fiInteractive Policy Learning Confidence-Based Autonomycould, therefore, provide user sliding control mechanism effects agentstendency perform autonomous actions versus demonstration requests. Importantly,note overall number demonstrations required either approach lessteacher-guided method tiny fraction overall state space.7. Discussionsection, discuss several promising directions future work, well numberexisting extensions presented learning methods.7.1 Evaluation Non-Technical Userspresented demonstration learning algorithm provides fast intuitive methodprogramming adapting behavior autonomous agents. believe generalrepresentation classifier-independent approach makes CBA usable wide rangeapplications. One particular application interest use demonstration learningenable non-technical users program autonomous agents. believe CBA wouldhighly suitable application assume teacher technicalknowledge policy learning, requiring teacher expert task.results presented article obtained using single teacher, oneauthors. Additional studies could evaluate algorithm usability performance wideruser base, non-programmers particular.7.2 Representation Action ChoicesDemonstration-based learning provides natural intuitive interface transferring human task knowledge autonomous agents. However, operating rich environments,agents inevitably face situations multiple actions equivalently applicable.example, agent encounters obstacle directly path option movingleft right avoid it. surrounding space empty, directions equally validperforming desired task. Human demonstrators faced choice equivalentactions typically perform demonstrations consistently, instead selecting amongapplicable actions arbitrarily time choice encountered. result, trainingdata obtained agent lacks consistency, identical, nearly identical, statesassociated different actions. presented CBA algorithm, inconsistentdemonstrations would result persistent region low confidence, leading agentrepeatedly request demonstrations within inconsistent domain region. successfully extended CBA identify regions state space conflicting demonstrationsrepresent choice multiple actions explicitly within agents policy (Chernova & Veloso, 2008a).7.3 Improvement Beyond Teacher Performancepolicy learned Confidence-Based Autonomy algorithm inherently limitedquality demonstrations provided human teacher. Assumingteacher expert task, approach aims imitate behavior teacher.However, many domains teacher demonstrations may suboptimal limited21fiChernova & Velosohuman ability. Several demonstration learning approaches developed enableagent learn experiences addition demonstrations, thereby improvingperformance beyond abilities teacher (Stolle & Atkeson, 2007; Smart, 2002).Extending CBA algorithm include similar capability remains promising directionfuture work. Possible approaches include incorporating high-level feedback (Argall,Browning, & Veloso, 2007) reward signal (Thomaz & Breazeal, 2006) teacher,well filtering noisy inaccurate demonstrations.7.4 Policy Use LearningCBA algorithm considers learning complete agent able performrequired behavior, repeatedly correctly, without requesting demonstrationsrequiring corrections. policy learning complete, standard procedurevast majority policy learning algorithms turn learning process freezepolicy. approach also used algorithm, proposecontinuing use Confident Execution component may long-term benefitsbeyond policy learning. particular, algorithms ability identify anomalous statesmay enable agent detect notify user system errors unexpected input.studies needed evaluate use algorithm, believemechanism would provide useful safety feature long-term autonomous operationnegligible cost performing threshold comparison timestep.7.5 Richer Interactionpresented demonstration learning approach relies limited form interaction agent teacher. agent requests demonstrations teacher,teacher responds single recommended action. level interactiontypical traditional active learning approaches, fails take full advantagevast task knowledge teacher possesses. believe extending algorithminclude richer interaction abilities could provide faster intuitive trainingmethod. Many promising directions future research exist area. example,developing domain-independent dialog exchange agent teacher incorporates clarification questions high level advice could speed learning enableagent represent high level goals task. ability play back rewinddemonstration sequences would additionally enable teacher agent reexaminereevaluate past learning experiences.7.6 Application Single-Robot Multi-Robot SystemsLearning demonstration techniques extensively studied within roboticscommunity due interactive nature fast learning times. work,shown CBA algorithm highly effective learning variety single-robot tasks(Chernova & Veloso, 2007, 2008a).Furthermore, many complex tasks require collaboration multiple robots.now, one greatest challenges preventing demonstration learning algorithmsgeneralizing multi-robot domains problem limited human attention,22fiInteractive Policy Learning Confidence-Based Autonomyfact teacher able pay attention to, interact with, robotstime. Based CBA algorithm, developed first multi-robotdemonstration learning system addresses limited human attention problemtaking advantage fact Confident Execution component CBA preventsautonomous execution actions low-confidence states (Chernova & Veloso, 2008b).flexMLfD system utilizes individual instances CBA robot, learneracquires unique set demonstrations learns individual task policy. preventingautonomous execution low-confidence states, CBA makes learner robust periodsteacher neglect, allowing multiple robots taught time.8. Conclusionarticle presented Confidence-Based Autonomy, interactive algorithm policylearning demonstration. Using algorithm, agent incrementally learnsaction policy demonstrations acquired practices task. CBA algorithmcontains two methods obtaining demonstrations. Confident Execution componentenables agent select demonstrations real time interacts environment,using confidence distance thresholds target states unfamiliarcurrent policy action uncertain. Corrective Demonstration component allowsteacher additionally perform corrective demonstrations incorrect actionselected agent. teacher retroactively provides demonstrations specific errorcases instead attempting anticipate errors ahead time. Combined, techniquesprovide fast intuitive approach policy learning, incorporating shared decisionmaking learner teacher.Experimentally, used complex simulated driving domain compare five methodsselecting demonstration training data: manual data selection teacher, confidencebased selection using single fixed threshold, confidence-based selection using multipleautomatically calculated thresholds, corrective demonstration, confidence-based selection combined corrective demonstration. Based evaluation, concludeconfidence-based methods able select informative demonstrationshuman teacher. single multiple threshold approaches, multiple adjustablethreshold technique required significantly fewer demonstrations focusing onto regionsuncertainty reducing number redundant datapoints. best final policy performance, however, achieved Corrective Demonstration complete ConfidenceBased Autonomy algorithms, achieved lane preference similarteacher without collisions. Together, demonstration selection algorithms representtradeoff number demonstrations frequency undesired actionstraining. Corrective Demonstration required slightly fewer demonstrationslearn final policy, compared CBA resulted significant increase numbererrors made agent course learning process. CBA algorithm,therefore, provides best demonstration selection method domains incorrectactions desirable training process.23fiChernova & VelosoAcknowledgmentsresearch partially sponsored Department Interior, National BusinessCenter contract no. NBCHD030010 SRI International subcontract no.03-000211, BBNT Solutions subcontract no. 950008572, via prime Air Forcecontract no. SA-8650-06-C-7606. views conclusions contained documentauthors interpreted representing official policies,either expressed implied, sponsoring institution, U.S. governmententity. Additional thanks Paul Rybski making simulation package available.ReferencesAbbeel, P., & Ng, A. (2004). Apprenticeship learning via inverse reinforcement learning.Proceedings International Conference Machine Learning, New York, NY,USA. ACM Press.Argall, B., Chernova, S., Browning, B., & Veloso, M. (2009). survey robot learningdemonstration. Robotics Autonomous Systems, appear.Argall, B., Browning, B., & Veloso, M. (2007). Learning demonstration critique human teacher. Second Annual Conference Human-Robot Interactions(HRI 07), Arlington, Virginia.Atkeson, C. G., & Schaal, S. (1997). Robot learning demonstration. ProceedingsInternational Conference Machine Learning, pp. 1220, San Francisco, CA,USA. Morgan Kaufmann Publishers Inc.Bentivegna, D. C., Ude, A., Atkeson, C. G., & Cheng, G. (2004). Learning actobservation practice. International Journal Humanoid Robotics, 1 (4).Blum, A. L., & Langley, P. (1997). Selection relevant features examples machinelearning. Artificial Intelligence, 97 (1-2), 245271.Browning, B., Xu, L., & Veloso, M. (2004). Skill acquisition use dynamicallybalancing soccer robot. Proceedings Nineteenth National Conference ArtificialIntelligence, pp. 599604.Chernova, S., & Veloso, M. (2007). Confidence-based policy learning demonstrationusing gaussian mixture models. Proceedings International ConferenceAutonomous Agents Multiagent Systems, pp. 18.Chernova, S., & Veloso, M. (2008a). Learning equivalent action choices demonstration.Proceedings International Conference Intelligent Robots Systems,pp. 12161221.Chernova, S., & Veloso, M. (2008b). Teaching collaborative multi-robot tasksdemonstration. Proceedings IEEE-RAS International Conference Humanoid Robots.Clouse, J. A. (1996). integrating apprentice learning reinforcement learning. Ph.D.thesis, University Massachisetts, Department Computer Science.Cohn, D., Atlas, L., & Ladner, R. (1994). Improving generalization active learning.Machine Learning, 15 (2), 201221.24fiInteractive Policy Learning Confidence-Based AutonomyGrollman, D., & Jenkins, O. (2007). Dogged learning robots. IEEE InternationalConference Robotics Automation, pp. 24832488.Inamura, T., Inaba, M., & Inoue, H. (1999). Acquisition probabilistic behavior decision model based interactive teaching method. Proceedings NinthInternational Conference Advanced Robotics, pp. 523528.Lockerd, A., & Breazeal, C. (2004). Tutelage socially guided robot learning. Proceedings IEEE/RSJ International Conference Intelligent Robots Systems,pp. 34753480.Nicolescu, M. N. (2003). framework learning demonstration, generalizationpractice human-robot domains. Ph.D. thesis, University Southern California.Papudesi, V. (2002). Integrating advice reinforcement learning. Masters thesis, University Texas Arlington.Price, B., & Boutilier, C. (2003). Accelerating reinforcement learning implicitimitation.. Journal Artificial Intelligence Research, 19, 569629.Saunders, J., Nehaniv, C. L., & Dautenhahn, K. (2006). Teaching robots moulding behavior scaffolding environment. Proceeding 1st ACM SIGCHI/SIGARTconference Human-robot interaction, pp. 118125, New York, NY, USA. ACMPress.Schaal, S. (1997). Learning demonstration. Advances Neural Information Processing Systems, pp. 10401046. MIT press.Smart, W. D. (2002). Making Reinforcement Learning Work Real Robots. Ph.D. thesis,Department Computer Science, Brown University, Providence, RI.Stolle, M., & Atkeson, C. G. (2007). Knowledge transfer using local features. Proceedings IEEE International Symposium Approximate Dynamic ProgrammingReinforcement Learning, pp. 2631.Sutton, R., & Barto, A. (1998). Reinforcement Learning: Introduction. MIT Press,Cambridge, MA.Takahashi, Y., Hikita, K., & Asada, M. (2004). hierarchical multi-module learning systembased self-interpretation instructions coach. Proceedings RoboCup 2003:Robot Soccer World Cup VII, pp. 576 583.Thomaz, A. L., & Breazeal, C. (2006). Reinforcement learning human teachers: Evidence feedback guidance implications learning performance. Proceedings Twenty-First Conference Artificial Intelligence, pp. 10001005.25fiJournal Artificial Intelligence Research 34 (2009) 707-755Submitted 08/08; published 04/09Efficient Informative Sensing using Multiple RobotsAmarjeet SinghAndreas KrauseCarlos GuestrinWilliam J. KaiserAMARJEET @ EE . UCLA . EDUKRAUSEA @ CALTECH . EDUGUESTRIN @ CS . CMU . EDUKAISER @ EE . UCLA . EDUAbstractneed efficient monitoring spatio-temporal dynamics large environmental applications, water quality monitoring rivers lakes, motivates use robotic sensorsorder achieve sufficient spatial coverage. Typically, robots bounded resources,limited battery limited amounts time obtain measurements. Thus, careful coordinationpaths required order maximize amount information collected, respectingresource constraints. paper, present efficient approach near-optimally solving NP-hard optimization problem planning informative paths. particular, firstdevelop eSIP (efficient Single-robot Informative Path planning), approximation algorithmoptimizing path single robot. Hereby, use Gaussian Process model underlying phenomenon, use mutual information visited locations remainderspace quantify amount information collected. prove mutual informationcollected using paths obtained using eSIP close information obtained optimalsolution. provide general technique, sequential allocation, used extendsingle robot planning algorithm, eSIP, multi-robot problem. procedureapproximately generalizes guarantees single-robot problem multi-robot case.extensively evaluate effectiveness approach several experiments performed in-fieldtwo important environmental sensing applications, lake river monitoring, simulationexperiments performed using several real world sensor network data sets.1. IntroductionGlobal climate change corresponding impetus sustainable practices environment-relatedactivities brought forth challenging task observing natural phenomena exhibiting dynamics space time. Observing characterizing dynamics high fidelitycritical answering several questions related policy issues monitoring controlunderstanding biological effects activity microbes organisms living (or dependenton) environments. Monitoring algal bloom growth lakes salt concentration rivers,illustrated Fig. 1, specific examples related phenomena interest biologistsenvironment scientists (MacIntyre, 1993; Ishikawa & Tanaka, 1993; MacIntyre, Romero, & Kling,2002).Monitoring environmental phenomena, algal bloom growth lake, requires measuring physical processes, nutrient concentration, wind effects solar radiation, amongothers, across entire spatial domain. One option acquire data processes wouldstatically deploy set sensing buoys (Reynolds-Fleming, Fleming, & Luettich, 2004). Duelarge spatial extent observed phenomena, approach would require large numbersensors order obtain high fidelity data. spatio-temporal dynamics environmentsc2009AI Access Foundation. rights reserved.fiS INGH , K RAUSE , G UESTRIN & K AISER(a) Confluence San Joaquin Merced River(b) Lake Fulmor, San Jacinto mountain reserveFigure 1: Deployment sites used performing path planning in-field.motivate use actuated sensors robots carrying sensors together efficient approachplanning paths actuated sensors. actuated sensors used past(Dhariwal et al., 2006) measuring phenomena various locations hence providingbiologists critical information state lake.Typically however, robots strict resource constraints, storage battery energy,limits distance travel number measurements acquireobserved phenomena varies significantly. constraints necessitate careful motion planningrobots coordinating paths order maximize amount collected information,satisfying given resource constraints. paper, tackle important problemseeking informative paths collection robots, subject constraints cost incurredrobot, e.g. due limited battery capacity.order optimize paths robots, first need quantify informativenessparticular chosen path. work, adopt approach spatial statistics employprobabilistic models spatial phenomena. Using models, informativeness viewedterms uncertainty prediction phenomena unobserved locations, givenobservations made mobile robots subset locations (the selected path). particular, use rich class probabilistic models called Gaussian Processes (GPs) (Rasmussen &Williams, 2006) shown accurately model many spatial phenomena (Cressie, 1991),apply mutual information (MI) criterion (Caselton & Zidek, 1984) quantify reductionuncertainty achieved selected robot paths.Unfortunately, problem finding optimal collection paths, maximizing mutualinformation criterion, NP-hard search problem, typically intractable even smallspatial phenomena. paper, develop approximation algorithm efficientlyfinds provably near-optimal solution optimization problem. key insightallow us obtain algorithm mutual information (and several notionsinformativeness (as discussed Krause Guestrin, 2007) satisfies submodularity, intuitivediminishing returns property - making new observation helps madeobservations far, less already made many observations (Krause et al., 2008).problem optimizing path single robot maximize submodular functionvisited locations studied Chekuri Pal (2005), developed algorithm, recursivegreedy, strong theoretical approximation guarantees. Unfortunately, running time708fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSapproach quasi-polynomial: scales log , possible sensing locations. propertymakes algorithm impractical environmental sensing applications, typical numbers(M ) observation locations reaching several hundreds more. paper, present twotechniques spatial decomposition branch bound search overcoming limitations recursive-greedy approach Chekuri et al., making practical real world sensingproblems. call efficient approach single robot path planning eSIP (efficient Single-robotInformative Path planning).provide general approach, sequential-allocation, used extendsingle robot algorithm, eSIP, multi-robot setting. furthermore provegeneralization leads minimal reduction (independent number mobile robots)approximation guarantee provided single robot algorithm. combine eSIP sequentialallocation develop first efficient path planning algorithm (eMIP) coordinates multiplerobots, resource constraint, order obtain highly informative paths, i.e. pathsmaximize given submodular function, mutual information. exploiting submodularity, prove strong theoretical approximation guarantees algorithm.extensively evaluate effectiveness approach several experiments performedin-field two important environmental sensing applications, lake river monitoring. rivercampaign executed confluence two rivers, Merced river San Joaquin river, California August 7-11, 2007. Fig. 1a displays aerial view San Joaquin deployment site.lake campaign executed lake located University California, Merced campusAugust 10-11, 2007. Fig. 1b displays aerial view lake Fulmor. campaigns,Networked Info Mechanical System (NIMS) (Jordan et al., 2007), cable based robotic system,used perform path planning observing two dimensional vertical plane (cross-section).addition analyzing data deployments, provide extensive experimental analysisalgorithm several real world sensor network data sets, including data collected usingrobotic boat lake Fulmor (Dhariwal et al., 2006).manuscript organized follows. formally introduce Multi-robot InformativePath Planning (MIPP) problem Section 2. Section 3, discuss sequential-allocationapproach extending single robot path planning algorithm multi-robot settingpreserving approximation guarantees. review recursive-greedy algorithm proposedChekuri et al. (Section 5), example single-robot algorithm. Subsequently, presentspatial decomposition (Section 6) branch bound techniques (Section 7) drastically improve running time recursive-greedy make practical real world sensingapplications. Section 8, evaluate approach in-field experiments well simulations real world sensing datasets. Section 9, review related work, presentconclusions Section 10. proofs results presented Appendix.2. Multi-robot Informative Path Planning Problemformally define Multi-robot Informative Path Planning (MIPP) problem. assumespatial domain phenomenon discretized finitely many sensing locations V.subset V, let I(A) denote sensing quality, i.e. informativeness, observingphenomenon locations A. Details appropriate choices sensing quality given below.also associate location v V, sensing cost C(v) > 0, quantifying expensesobtaining measurement location v. traveling two locations, u v, robot in-709fiS INGH , K RAUSE , G UESTRIN & K AISERcurs traveling cost C(u, v) > 0. robot traverses path space: st-path P sequencel locations starting node s, finishing t. cost C(P) path P = (s = vP1 , v 2 , . . . , vl =l1t) sum sensing costs traveling costs along path, i.e. C(P) =i=2 C(vi ) +PlC(v,v).casel=2,costpathPinvolvetravelingcosti1i=2starting finishing locations C(s, t). use notation P refer sequencenodes path, subset sensing locations P V (ignoring sequence). collection k paths P = {P1 , . . . , Pk }, one robot, I(P) = I(P1 Pk ) denotes sensing quality paths, quantifies amount information collected k paths.goal MIPP problem find collection P k paths, specified starting finishinglocation si ti (not necessarily different), path bounded cost C(Pi ) Bspecified budget B, paths informative, i.e. I(P) large possible.Formally, problem defined as:max I(ki=1 Pi ); subject C(Pi ) B, {1, . . . , k}.Pi V(1)lake monitoring example goal performing surface monitoring using boats,first discretized two-dimensional surface lake finitely many sensing locations (asdepicted Fig. 1b). single robot scenario, seek find informative pathP1 (in terms predicting algal bloom content) starting location finishing locationt. experiment cost C(vi ) corresponds energy required making chlorophyll relatedmeasurements (indicators amount algal bloom). traveling cost C(vi1 , vi ) correspondsenergy consumption traveling location vi1 vi . budget B quantifies totalenergy stored boats battery.2.1 Quantifying Informativeness:quantify sensing quality I? model spatial phenomena, common approachspatial statistics use rich class probabilistic models called Gaussian Processes (GPs, c.f.,Rasmussen Williams, 2006). models associate random variable Xv locationv V. joint distribution P (XV ) used quantify uncertainty predictionP (XV\A | XA = xA ) phenomena unobserved locations XV\A , making observationsXA = xA small subset locations. quantify uncertainty use, example,mutual information (MI) criterion (as discussed Caselton Zidek, 1984). setlocations, P, MI criterion defined as:MI(A) H(XV\A ) H(XV\A | XA )(2)H(XV\A ) entropy unobserved locations V \ A, H(XV\A | XA )conditional entropy locations V \ sensing locations A. Hence mutual informationmeasures reduction uncertainty unobserved locations. Therefore, lake monitoringexample, would like select locations reduce uncertainty algal bloomcontent prediction lake environment. Conveniently, GP, mutual information criterioncomputed efficiently analytically (Caselton & Zidek, 1984). effectiveness mutualinformation select informative sensing locations studied Krause et al. (2008). Severalalternative information criteria entropy (Ko et al., 1995), information disk model (Bai et al.,2006) alphabetical optimality criterion A-, D- E-optimal also usedassociate sensing quality observation locations related problem domain.710fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS2.2 Submodularity:Even consider constraints length paths robots, problemselecting locations maximize mutual information NP-hard (Krause et al., 2008). Hence,general, likely cannot expect able efficiently find optimal set locations.Instead, goal efficiently find near-optimal solutions, sensing quality(e.g. mutual information), provably close optimal sensing quality.key observation, allow us obtain strong approximation guarantees,mutual information satisfies following diminishing returns property (Krause et al., 2008):locations already sensed, less information gain sensing newlocation. intuition formalized concept submodularity: function f submodular(Nemhauser et al., 1978) if:B V V \ B; f (A s) f (A) f (B s) f (B).(3)Another intuitive property sensing quality monotonic1 , means I(A) I(B)B V. Hence, select sensing locations, collectinformation. Lastly, mutual information normalized, i.e. I() = 0.thus define MIPP problem problem optimizing paths length Bk robots, selected sensing locations maximize normalized, monotonic submodular function I(). definition MIPP problem allows approach appliedmonotonic submodular objective function, mutual information. generalizationuseful, several notions informativeness shown satisfy submodularity (Krause& Guestrin, 2007).2.3 Online vs Offline Path Planning:Many robotic path planning applications, search rescue, involve uncertain environmentscomplex dynamics partially observed. Informative path planning selectingbest locations observe subject given sensing constraints, uncertain environmentsnecessitates trade exploration (gathering information environment)exploitation (using current belief state environment effectively). distinguish two different classes algorithms: nonadaptive (offline) algorithms, plan commitpaths observations made, adaptive (online) algorithms, updatereplan new information collected. online offline settings NP-hard optimization problems. paper, discuss approximation algorithms offline settingexploit known belief environment efficient path planning. plan work towards extending approach exploration-exploitation trade-off incorporate online modeladaptation future.3. Approximation Algorithm MIPPproblem optimizing path single robot (i.e. k = 1) maximize submodular function visited locations, constrained upper bound (B) path cost, first studiedChekuri Pal (2005). review recursive-greedy algorithm detail Section 5.1. monotonicity holds approximately mutual information (Krause et al., 2008), however sufficientpurposes paper.711fiS INGH , K RAUSE , G UESTRIN & K AISER1Algorithm:sequential-allocationInput: B, k, starting / finishing locations s1 , . . . , sk , t1 , . . . , tk , VOutput: set informative paths P1 , . . . , Pn2 begin3A0 ;41 k// Performing path planning ith robot5Pi SP P (si , ti , B, Ai1 , V);// Committing previously selected locations6Ai Ai1 Pi ;7return P1 , . . . , Pk ;8 endAlgorithm 1: Sequential allocation algorithm multi robot path planning using single robot path planning algorithm SPP. Output set paths P1 , . . . , Pk provides approximation guarantee 1 +approximation guarantee single robot path planning algorithm SP P .lake monitoring problem, seek plan multiple paths, one robot. One possibility apply single-path algorithm product graph, i.e. plan path tupleslocations simultaneously representing locations robots. However, straightforwardapplication single-robot planning algorithm would lead increase running timeexponential number robots, therefore intractable practice. awaresub-exponential approximation algorithm challenging multiple-robot path planningproblem. paper, present simple algorithm multi-robot scenario exploitapproximation algorithm single robot case, recursive-greedy algorithm,discussed Chekuri Pal (2005), (almost) preserve approximation guarantee,avoiding exponential increase running time.algorithm, sequential-allocation, successively applies single robot path planning algorithm k times get paths k robots. Hereby, planning jth path, approach takesaccount locations already selected previous j 1 paths. Committing (approximately) best possible path stage moving next stage makes approachgreedy terms paths.pseudocode algorithm presented Algorithm 1 Fig. 2 illustrates approachthree robots. algorithm takes input budget constraint B, number available robotsk, starting finishing location available robot s1 , . . . , sk , t1 , . . . , tk complete setdiscrete observation locations V select from. Let us assume single robot pathplanning algorithm, SP P , takes input starting location si , finishing location ti , budgetconstraint B, set locations already selected observation set possible observationlocations visited. Fig. 2, three robots starting finishing location.planning path first robot (i = 1), input set already selected observationlocations empty. subsequent stage, commit locations selected previousstages pass already observed locations input next call SP P . Let Ai1 locations already visited paths P1 , . . . , Pi1 , A0 = . residual information, IAi1path P unvisited locations defined IAi1 (P) = I(Ai1 P)I(Ai1 ). verifiednormalized, monotonic submodular function, residual information712fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSFigure 2: Illustration sequential allocation algorithm three robots, starting finishinglocation.IAi1 . Thus, stage use SP P find informative path respect modifiedresidual sensing quality function. Fig. 2, planning P2 , locations selected P1 considered sensing quality function used IP1 . Similarly, evaluating path P3 , locationsselected P1 P2 taken account sensing quality function used IP1 P2 .Perhaps surprisingly, straight-forward greedy sequential allocation approach guaranteed perform almost well black box algorithm used path planning. formally,assume -approximate algorithm single robot problem, i.e. algorithm which,starting budget B monotonic submodular function f , guaranteed find path recovering least fraction 1/ optimal information achievable budget.case, following theorem proves sequential allocation procedure approximationguarantee close well:Theorem 1. Let approximation guarantee single path instance informativepath planning problem. sequential-allocation algorithm achieves approximation guarantee (1 + ) MIPP problem. special case, robots starting(si = sj , i, j) finishing locations (ti = tj , i, j), approximation guarantee improves1/(1 exp (1/)) 1 + .work Blum et al. (2003) proved Theorem 1 special case additive (modular)sensing quality functions. paper, extend result general submodular functions.example -approximate algorithm single robot problem, next section,review recursive-greedy algorithm proposed Chekuri Pal (2005). algorithmapproximation guarantee O(log2 |P |), |P | number locations visitedoptimal solution P . Hence, algorithm, performance guarantee obtainedMIPP problem sequential allocation O(log2 |P |) well2 .2. order apply sequential allocation recursive-greedy algorithm, can, planning ith path, simplypass set nodes visited previous 1 paths input parameter R, illustrated Algorithm 2.713fiS INGH , K RAUSE , G UESTRIN & K AISER(a)(b)(c)(d)Figure 3: Illustration performance simple greedy approaches compared optimal approach.4. Note Greedy Path Planningwork Krause et al. (2008) considered sensor placement problem, subset Vk locations selected order maximize mutual information, without considering pathcosts. exploiting submodularity property MI, proved discretization Vfine enough GP satisfies mild regularity conditions, greedily selecting locations basedcriterion near-optimal. specifically, greedy algorithm (which call GreedySubsetfollowing), selecting first locations Ai , picks location maximum residualinformation i.e. vi+1 = argmaxv IAi ({v}) sets Ai+1 = Ai {vi+1 }. GreedySubset henceiteratively adds locations increase mutual information most. Using result proposedNemhauser et al. (1978) performance greedy algorithm submodular functions,work Krause et al. (2008) showed GreedySubset selects sets achieve mutualinformation least (1 1/e) OPT , OPT optimal mutual information amongsets size, small error incurred due discretization.strong performance greedy algorithm unconstrained (no traveling costs locations) case motivates question whether simple greedy approach could performwell complex path planning setting considered paper. difficultgive general impossibility statement question, several natural extensions greedyalgorithm shown perform arbitrarily badly.example, consider setting define cost C(A) set nodes costcheapest path connecting nodes A. Assuming locations Ai already picked,natural extension greedy algorithm add location v improvesbenefit-cost ratioIA (v)v = argmax,vV\A CAi (v)714fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSCAi (v) = C(Ai {v}) C(Ai ) increase cost adding v already selectedlocations Ai .Fig. 3 shows small example illustrating intuitive greedy procedure perform arbitrarily poorly compared optimal approach. example illustrated Fig. 3a,starting finishing location 2B total available budget. reward associated observation location displayed parenthesis corresponding locations.ease illustration, assume reward associated observation locationmodular function (instead submodular function). Traveling cost associatedcorresponding edges example. Starting location s, possible options first observationlocation select either o1 , g1 t. Observation location o1 lead cluster n (=B/) locations separated traveling cost associated reward 1 (except o1associated reward ). o1 separated g1 traveling cost B/2rest locations cluster assumed unreachable location outsidecluster. Observation location g1 lead series (= B/) locations, separatedprevious one traveling cost associated reward 2.illustrated Fig. 3b, optimal approach would select o1 first location, payingtraveling cost B/2 earning small reward . robot observes o1 ,observe rest (B/ 1) locations cluster, providing reward 1 return backspending total 2B traveling cost. Thus, total reward collected optimalapproach, example, 1(B/ 1) + .illustrated Fig. 3c, greedy approach based reward-cost ratio select g1first observation location (with highest reward cost ratio 2). Since o1 distance B/2away g1 provides reward , approach continue along series, observing locations till gm returning back s. Total reward collected approach2B. hand, simple greedy approach based reward (as illustrated Fig. 3d)simply select first observation location return back s, collecting total reward1. Since ratio B/ arbitrarily large 0, reward collected simple intuitivegreedy approaches (2B 1) arbitrarily poor compared reward collectedoptimal approach (1(B/ 1) + ).Although, reward function considered example assumed modular function, submodular optimal reward also arbitrarily large, compared submodular rewardcollected simple greedy approaches (the difference submodular modular rewarddepend correlation selected observation locations). insight necessitatesdevelopment complex algorithms path planning considered paper.5. Recursive-greedy Algorithmreview recursive-greedy algorithm proposed Chekuri Pal, since formsbasis efficient single robot path planning approach. basic strategy algorithmdivide-and-conquer approach. path starting location (s) finishing location (t)middle location (vm ) number locations (or different 1)either side vm path. Thus, problem finding path dividedtwo smaller subproblems finding smaller subpaths (s vm vm t) concatenatingsmall subpaths. number locations, subpaths either sidemiddle node different costs, i.e. budget total path split two smaller715fiS INGH , K RAUSE , G UESTRIN & K AISER1Algorithm:recursive-greedy (RG)Input: s,t,B,R,iterOutput: informative path P2 begin3c(s, t) > B4return Infeasible;5P s, t;6Base case: iter=0 return P;7fR (P);// Trying location middle node8foreach vm V// Trying possible budget splits91 B1 B// Planning subpath one side middle node10P1 RG(s, vm , B1 , R, iter 1);// Planning subpath side middle node,committing nodes selected first subpath11P2 RG(vm , t, B B1 , R P1 , iter 1);12fR (P1 P2 ) >13P P1 P2 ;14fR (P);15return P;16 endAlgorithm 2: Recursive greedy algorithm single robot instance MIPP proposed Chekuri Pal(2005). Output path P provides approximation guarantee IX (P) IX (P )/ d1 + log ke, representsubmodular reward function, P represent optimal path k represent number nodes optimalpath.budgets (not necessarily equal), one subpath. Searching best middle locationtrying possible budget splits either side middle location, optimizing completepath, would result exhaustive search optimal solution therefore prohibitively expensive. Instead performing exhaustive search, recursive-greedy algorithmfollows simple greedy strategy, wherein possible budget splits possiblemiddle nodes considered, one first plan optimal subpath one side middle location,commit planned subpath optimize subpath side. path,consisting independently optimized subpath svm subpath vm optimized subject observation locations already selected vm , may result suboptimal path. Nonetheless,Chekuri Pal proved path approximation guarantee O(log2 |P |),|P | number locations visited optimal solution P .order implement greedy approach, recursive calls planning second subpath similarly done sequential allocation optimize residual reward functionmeasures incremental gain taking account information already obtained locations selected first subpath. formally, let set P1 refer locations selectedfirst subpath, consider residual submodular function fP1 set locations716fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSfP1 (A) = f (A P1 ) f (P1 ). P2 set locations second subpath, holdsf (P1 ) + fP1 (P2 ) = f (P1 P2 ). Hence, first recursive call (with submodular function f )returns path P1 , second recursive call (with submodular function fP1 ) returns path P2 ,sum scores subproblems exactly equals score concatenated path.Let us formalize intuitive description recursive-greedy algorithm. pseudocode algorithm presented Algorithm 2. inputs algorithm startinglocation s, finishing location t, upper bound path cost B, parameter R definesresidual submodular function function needs maximized definedfR (P) = f (P R) f (R), parameter represents recursion depth. maximumnumber locations selected stage calculated using recursion depth 2i .base case (recursion depth = 0), algorithm simply returns path P = (s, t) (ifcost c(s, t) B).recursive case, algorithm searches path maximum reward iteratingpossible locations (that reached given budget constraint) middle locations(Line 8), i.e. locations could possibly split required path two subpaths equal number locations either side. middle location, algorithm explores possiblesplits available budget (Line 9) across two subpaths either side middle location.Reducing recursion depth 1, subpath, ensures number locationsselected either side middle location. However, exploring second subpath,algorithm commits locations selected first subpath passing inputresidual parameter (Line 11). two subpaths found way concatenatedprovide complete path. algorithm stores best possible path alreadysearched problem space, replacing better path whenever path found.5.1 Structure Search Probleminstructive consider recursive structure generated recursive-greedy algorithm.Fig. 4 illustrates example structure running recursive-greedy lake sensingapplication given starting (s) finishing (t) location upper bound path cost(B). search using recursive-greedy represented graphically sum-max tree.root max node representing objective finding path maximum possible reward,cost path bounded budget B. max node, childrensearch tree represent sum nodes corresponding sum rewards collected two subpathseither side middle location. Therefore, end first iteration, graphical representation max node root several sum nodes children, feasible middlelocation possible budget splits around middle location. partial tree end firstiteration shown Fig. 4a.sum node, formed end first iteration, algorithm applied recursively left subpath. Thus first step second iteration seeks find vm pathmaximum possible reward budget constraint corresponding respective budget splitsum node. Then, approach commits selected locations left side, recurses right subpath (to search vm path), given selected locations. result,sum node two max nodes children, representing objective find subpathmaximum reward either side selected middle location. algorithm greedycommits locations selected first subpath optimizing second subpath.717fiS INGH , K RAUSE , G UESTRIN & K AISER(a) recursive-greedy first iteration(b) recursive-greedy second iterationFigure 4: Illustration recursive greedy algorithm, proposed Chekuri Pal, lake sensing application.Sum-max tree presents graphical representation problem space.partial tree end second iteration shown Fig. 4b. Despite greedy nature,recursive-greedy approach provides following approximation guarantee:Theorem 2. (Chekuri & Pal, 2005) Let P = (s = v0 , v1 , . . . , vk = t) optimal s-t-pathsolution. Let P path returned RG(s, t, B, R, i). d1 + log ke, IX (P)IX (P )/ d1 + log ke.1Hence, recursive-greedy solution P obtains least fraction d1+logoptimal2 keinformation, k n, i.e. total number locations traversed optimal pathsmaller total number locations discretized spatial domain. Referring back Theorem 1, MIPP problem using recursive-greedy single robot path planning approach,= d1 + log ke.5.2 Running Timeinspecting recursive structure, running time recursive-greedy algorithm seenquasi-polynomial. specifically, running time algorithm O((M B)O(log2 ) ),B budget constraint = |V| total number possible observation locations.So, even small problem = 64 locations, exponent 6, resultinglarge computation time, making algorithm impractical observing several real world physicalprocesses.large computational effort required recursive-greedy attributed two issues: 1)large branching factor max nodes recursion tree (sum nodes possiblemiddle node possible budget split across middle node) 2) (possibly) unnecessaryrecursion exploring subtrees problem space provide us improved reward compared current best solution. following sections, propose two complementaryapproaches (can used independently others) intended ameliorate concerns: spatial decomposition technique, branch bound approach. Spatial decomposition718fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSStarting nodeStarting cell CsEnding nodeEnding cell CtCsMiddle cell CmCtP1, budget = BP2, budget = BeBIncomingpath P1b(a) Spatial decomposition phenomenoncSmoothed pathExiting pathP2Cell center(b) Cell paths travel within cells(c) Cell paths path smoothingFigure 5: Illustration spatial decomposition recursive-eSIP using surface sensing lake environmentexample. sensing domain ((a), top) decomposed grid cells ((a), bottom). recursive-eSIP jointly optimizescell-paths ((b), top) allocations experiments cells ((b), bottom). Within cells, locations connectedcell center. recursive-eSIP concatenates paths between-cell within cell paths ((c), top) finally heuristicsapplied eMIP smooth path ((c), bottom).(discussed Section 6) seeks reduce high branching factor (i.e. number sum nodessearch tree) clustering sensing locations running recursive-greedyclusters instead actual sensing locations. Branch bound (discussed Section 7) seeksavoid unnecessary recursion maintaining lower upper bound possible rewardsubtree search tree pruning tree accordingly. two approaches, togethersequential-allocation (discussed Section 3) provide efficient algorithm multi robotinformative path planning.6. Spatial Decomposition Approximating MIPP SD-MIPPsection, explain detail process spatial decomposition corresponding improvements running time achieved process. approach assumes travelingcost arbitrary locations given euclidean distance.intuitive approach improving running time spatially decompose sensingregion smaller sub-regions, containing cluster sensing locations. thus thinkplanning informative paths deciding sub-regions explore, decidinglocations sense within sub-regions. idea exploring sub-regions motivatesdecomposition sensing domain smaller regions (cells). run recursivegreedy algorithm cells instead actual sensing locations. Since size cellularregion small, traveling cost within cell ignored3 . ignore traveling costwithin cells, sensing locations inside selected cells chosen using GreedySubsetapproach (as proposed Krause et al., 2008), taking advantage strong approximation guar3. may robotic platforms non-holonomic motion constraints make small motions much challenging thus traveling cost smaller distances within cell may become non-negligible. systems,large traveling cost smaller motions, system specific constraints may possible accountperforming cellular decomposition greedy algorithm may constrained select locationsclose).719fiS INGH , K RAUSE , G UESTRIN & K AISERantee unconstrained setting discussed Section 4. Fig. 5 presents illustrationapproach explained follows:1. decompose sensing region, containing finitely many discrete sensing locations (c.f.,e = {C1 , C2 , . . . , CN } (c.f., Fig. 5a,Fig. 5a, top), collection non-overlapping cells Vbottom). distance two cells defined distance centroidscells. cell Ci contains set locations vi V, representing sensing locations, coordinates locations, euclidean metric space, lie withinboundary containing cell.2. approximate original MIPP problem spatially decomposed MIPP problem,e SD-MIPP, jointly optimize cell-paths Ve (c.f., Fig. 5b,SD-MIPP problem V.top) using recursive-greedy algorithm, allocation observations withincells visited paths using GreedySubset algorithm. Thus, allocating measurements cell, ignore traveling cost within cell (c.f., Fig. 5b, bottom). Sincecells large, simplification leads small additional costSD-MIPP solution transformed back original MIPP problem.3. transfer (approximate) SD-MIPP solution, consisting cell-path allocationobservations cells (c.f., Fig. 5c, top), back original MIPP problem. smoothpath (c.f., Fig. 5c, bottom) using heuristics, e.g. tour-opt heuristics discussedLin (1965).Dual optimization cell paths budget allocation observations within visited cellmotivated splitting available budget budget Bt traveling cells budget making experiments sensing locations within visited cells. split easilyincorporated recursive-greedy algorithm well required paths recursivegreedy optimized observation locations cells containing locations. Formally,SD-MIPP problem following: want find path PC = (Cs = Ci1 , . . . , Cil = Ct ),robot starting cell Cs containing starting node finishing cell Ct containingfinishing node t, travel cost Bt . travel budget measured termsdistances centers visited cells, cost traveling within cells defined 0.addition, visited cell Cij PC , want select set sensing locations Aij ,total experimental cost (for making observations within visited cells) upper bounded, i.e. C(Ai1 Ail ) , information I(Ai1 Ail ) large possible.optimal SD-MIPP solution uses optimal split budget Bt . simplifypresentation, rescale costs cells form uniform grid quadratic cellswidth L, assume sensing cost Cexp constant locations. assumptionseasily relaxed, allow us relate path costs number cells traversed,simplify discussion.following lemma states exists SD-MIPP version (PC ) MIPP-optimalpath (P ), (almost) cost, information.Lemma 3. Let P = (s = v0 , v1 , . . . , vl = t) optimal s-t-path solution MIPP, constrainedbudget B. exists corresponding SD-MIPP path PC = (Cs = Ci1 , . . . , Cil = Ct ),traversing locations Ai1 Ail , budget 2 2B + 4L collectinginformation.720fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSAlgorithm: eMIPe k, starting / finishing locations s1 , . . . , sk , t1 , . . . , tkInput: B,Output: collection informative paths P1 , . . . , Pk2 begin3Perform spatial decomposition cells;4Find starting ending cells Csi Cti ;5R ;// Path planning robot6= 1 k// Trying different combination travelingexperimental budgeteiter = 0 blog2 Bc7itere8B 2 ;09Piterrecursive-eSIP (Csi , Cti ,Be ,R,iter);010Smooth Piterusing tour-opt heuristics;0 );11Pi argmaxiter I(Piter12R R Pi ;13return P1 , . . . , Pk ;14 endAlgorithm 3: eMIP algorithm informative multi robot path planning. Procedure Line 7 Line 111effectively implements eSIP algorithm. eSIP repeated (Line 6) using sequential allocation describedSection 3 (Line 6) get paths robot i.present algorithm finding approximately optimal solution SD-MIPP,show solutiongives us approximate solution original MIPP problem,slightly increased cost 2 2B + 4L, ensuring optimal solution MIPP existscorresponding SD-MIPP setting.6.1 Algorithm SD-MIPPe smooths pathseMIP algorithm solves SD-MIPP problem Vselected observation locations provide solution MIPP. Let us first clarify algorithmicnomenclature specifically:recursive-eSIP: implements approach similar recursive-greedy selecting pathe greedily selects observation locations within visited cell using GreedySubset;VeSIP: iterates different values traveling budget calling recursive-eSIP corresponding values input smoothing output path recursive-eSIP usingtour-opt heuristics;eMIP: effectively implements sequential-allocation eSIP single robot path planning algorithmcomplete algorithm works follows: outer loop (Line 6 Algorithm 3) implementssequential allocation algorithm performing path planning multiple robots. procedure721fiS INGH , K RAUSE , G UESTRIN & K AISERinside outer loop (Line 7 Line 11 Algorithm 3) implements eSIP algorithm. procedure iterates different combination traveling experimental budget, allocating Bt(= 2iter ) total budget traveling cells, (= Bt ) making experiments within visited cells. Stepping Bt powers 2 results faster performance(log2 instead iterations). increase input budget factor 2, exponentialincrease traveling budget guaranteed try traveling budget, Bt (= 2iter BtApp ) BtApptraveling budget best approximation path. Since overall budget increasedfactor 2, remaining experimental budget also guaranteed experimentalbudget corresponding best approximation path. Therefore, exponential increase travelingbudget increase required budget factor 2. eSIP procedurecalls recursive-eSIP (explained Algorithm 4), selecting cells visit, greedily allocatingobservations visited cells. Finally, eSIP procedure calls tour-opt heuristics smoothoutput path recursive-eSIP.recursive-eSIP procedure takes input starting cell Cs , finishing cell Ct , experimental budget , residual R indicating locations visited thus far (initially passed emptyeMIP), maximum recursion depth, iter (initially passed log2 Bt eMIP). then:1. Iterate possible choices middle cells Cm (such are, almost, equalfe (of available experimentalnumber cells either side Cm ) budget splits Bbudget ) spend making experiments subpaths Cs Cm Cm Ctfe either linearly (more accurate) exponentially(c.f., Fig. 5b). budget splits B(faster) spaced, described below.2. Recursively find subpath P1 Cs Cm , constrained budget B 0 , leaving remainingbudget (Be B 0 ) subpath P2 . Reducing recursion depth (iter) 1,subpaths P1 P2 , ensures equal number cells visited either side Cm .lowest level recursion depth 0 signifies cell selected corresponding path.lowest recursion level, use GreedySubset algorithm (c.f., Section 4)select sensing locations based residual information function IR constrainedbudget B 0 . illustration, black locations middle cell Cm Fig. 5b bottom,selected GreedySubset algorithm budget B 0 = 4 providemaximum improvement mutual information.3. commit locations selected P1 , recursively find subpath P2Cm Ct , experimental budget B 0 . Committing locations selected P1requires greedily select sensing locations lowest recursion level basedresidual information function IRP1 .4. Finally, concatenate locations obtained P1 P2 output best pathalgorithm (c.f., Fig. 5c, top).6.2 Linear vs. Exponential Budget SplitsStep 1 recursive-eSIP procedure (as explained Section 6.1) considers different budget splitsfe left right subpaths. Similar recursive greedy algorithm, one chooseB0 Bfe = {0, 1, 2, 3, . . . , 1, } linearly spaced. Since branching factor proportionalBnumber considered splits, linear budget splits leads large amount computation effort.722fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS123456789101112131415Algorithm: recursive-eSIPInput: Cs , Ct , , R, iterOutput: informative path P Cs Ctbegin(d(Cs , Ct ) > 2iter L) return Infeasible;// Greedy node selection within starting finishing cellP GreedySubsetBe ,R (vi : vi Cs Ct );(iter = 0) return P;reward IR (P);// Trying cell middle cellforeach Cm C// Trying possible budget splitfeB 0 B// Planning subpath one side middle cellP1 recursive-eSIP (Cs , Cm , B 0 , R, iter 1);// Planning subpath side middle cellcommitting nodes selected first subpathP2 recursive-eSIP (Cm , Ct , B 0 , R P1 , iter 1);(IR (P1 .P2 ) > reward)P P1 .P2 ;reward IR (P);return P;endAlgorithm 4: recursive-eSIP procedure path planning.fe = {0, 20 , 21 , 22 , . . . , 2log2 } {Be ,alternative consider exponential splits: B0122 , Be2 , Be2 , . . . , 0}. case, branching factor logarithmic experimentalbudget. Even though guaranteed find solutions linear budget splits,theoretically (as given Lemmas 4 7) empirically (as illustrated Fig. 14c14d) show performance gets slightly worse case, compared significantimprovement running time. addition two ways splitting budget, also confe = {0, 20 , 21 , 22 , . . . , 2log2 }),sidered one-sided exponential budget splits (i.e. Breduces branching factor factor 2 compared exponential splits defined above. Although provide theoretical guarantees third possibility, experimentally foundperform well (c.f., Section 8).6.3 Algorithmic Guaranteesalgorithm greedy two ways:recursion depth 0, sensing locations selected greedily based mutual information criterion.exploring subpath P2 , recursive-eSIP procedure commits locations selectedsubpath P1 .723fiS INGH , K RAUSE , G UESTRIN & K AISERDue greedy steps, recursive-eSIP approximation algorithm necessarily find optimal solution. following lemma, however, guarantees performance boundpath output eSIP procedure:Lemma 4. Let PC = (Cs = C1 , . . . , Ck = Ct ) optimal solution single robot instancee optimal set locations selected withinSD-MIPP, constrained budget B,b solution returned eSIP. I(P)b 11/e I(P ).visited cell Cj . Let PC1+log k26.4 Solving MIPP ProblemNow, need transfer approximately optimal solution obtained SD-MIPP back MIPP.path cells, observation locations selected greedily within visited cell, transformed path observation locations connecting locations selected cell Cijcells center, (as indicated Fig. 5b bottom), connecting selected centers path (Fig. 5ctop), finally expanding resulting tree tour traversing tree twice (by traversingedge tree direction, set nodes connected tree convertedset nodes connected path). traversal results tour twicelong shortest tour connecting selected vertices. (Of course, even better solutionobtained applying improved approximation algorithm TSP, algorithm proposedChristofides, 1976). following Theorem completes analysis algorithm:Theorem 5. Let P optimal solution single robot instance MIPP problemb achieving informationbudget constraint B. Then, eSIP algorithm find solution P11/e), whose cost 2(2 2B + 4L)(1 + L 2 )bvalue least I(P)I(P1+log2 NCexpfe 2(2 2B + 4L)(1 + L 2 )N log2 32case linear budget split BCexpfe .case exponential budget split Bperformance guarantee w.r.t. number cells N instead number sensinglocations, case work Chekuri Pal (2005). However, input budgetconstraint violated amount based size cells spatial decomposition.violation input budget constraint leads tradeoff computation effort additionalcost incurred tuned based specific application requirements. size cellsmall (in limit reducing cell observation location), number cells largeresult higher computation time reduced additional cost. hand,size cell large, computation time small algorithm needs pay higheradditional traveling cost.Running time analysis eSIP straightforward. algorithm calls routine recursive-eSIPlog2 B times. TI time evaluate mutual information I, time computinggreedy subset Tgs (Line 4, Algorithm 4) O(NC2 TI ), NC maximum numberlocations per cell. recursion step try cells reached available traveling budget (Line 7, Algorithm 4). possible experimental budget split, tryfe among two subpaths P1 P2 (Line 8,(linearly exponentially spaced) splits Be following proposition statesAlgorithm 4). recursion depth would log2 (min(N, B)).running time eSIP:724fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSProposition 6. worst case runningtime eSIP linearly spaced splits experimentalbudget Tgs log2 B(N B)log2 N , exponentially spaced splits experimentalbudget Tgs log2 B(2N log2 B)log2 NComparing running time recursive-greedy algorithm (O((M B)O(log2 ) )), notereduction B log2 B base, log number locations (log2 ) lognumber cells (log2 N ) exponent. two improvements turn impractical recursivegreedy approach much viable algorithm.Varying number cells (and correspondingly size cell) results trade-offcomputation effort traveling cost within cell ignored eSIPalgorithm. Proposition 6 states computation effort directly proportional numbercells N. Therefore increase number cells, corresponding computation efforteSIP algorithm also increase. hand, reducing number cells resultincreasing size cell. Since eSIP algorithm ignores traveling cost withincell, larger cell size imply larger traveling cost ignored eSIP algorithm hencelarger overshoot cost resultant output path input budget B. Lemma 3 statescorresponding additional cost incurred output path calculated using eSIP algorithm termscell size L. Based specific application requirements, one decide appropriate number cells fine tune trade-off computation effort additional path costincurred. Fig. 14f shows corresponding collected reward vary significantlyvaried number cells application observing temperature lake environment.7. Branch Boundspatial decomposition technique effectively enables trade-off running time complexity achieved approximation guarantee. However, eSIP algorithm still solvesuper-polynomial, albeit sub-exponential, search problem. following, describe severalbranch bound techniques allow reduction computation effort makingapproach tractable real world sensing experiments.7.1 Problem Representationspecific structure search space representation motivated many proposed branchbound approaches. Similarly recursive structure recursive-greedy algorithm (discussedSection 5), recursive-eSIP problem structure also represented sum-max tree,shown Fig. 6a. small difference exists selection observation locations alongsolution path. case recursive-greedy, sum nodes traversed selectedpath represents physical observation location. However, case recursive-eSIP, sumnode selected path represents cell corresponding traversed path. observationlocations sum node selected greedily, within corresponding cell, based availableexperimental budget. Using sum-max tree problem structure, explain proposedbranch bound approaches prune parts tree provide improvementcurrently known best solution path. proposed branch bound techniquesoutlined recursive-eSIP procedure presented Algorithm 5.725fiS INGH , K RAUSE , G UESTRIN & K AISER1Algorithm: recursive-eSIP branch boundInput: Cs , Ct , , R, iter, rewardLB,Output: informative path P Cs Ct2345678910begin(d(Cs , Ct ) > 2iter L)return InfeasibleP GreedySubsetBe ,R (vi : vi Cs Ct );(iter = 0)return Pf ilterCells Ci Ci s.t. d(Cs , Ci ) 2iter L/2 d(Ci , Ct ) 2iter L/2 ;foreach Cm f ilterCellsfeB 0 B12// Calculating upper bound using GreedySubsetU BP1 calculateU B(Cs , Cm , B 0 , iter 1, R);U BP2 calculateU B(Cs , Cm , B 0 , iter 1, R);13((U BP1 + U BP2 ) > rewardLB)1115// Calculating lower bound P1heurP1 heuristicOP(Cs , Cm , B 0 , R, iter 1);LBP1 max(IR (heurP1 ), rewardLB U BP2 );16// Recursive search P1P1 recursive-eSIP (Cs , Cm , B 0 , R, iter 1, LBP1 , );1418// Calculating lower bound P2heurP2 heuristicOP(Cm , Ct , B 0 , R P1 , iter 1);LBP2 max(IRP1 (heurP2 ), rewardLB IR (P1 ));19// Recursive search P2P2 recursive-eSIP (Cm , Ct , B 0 , R P1 , iter 1, LBP2 , );17(Iresid (P1 .P2 ) > rewardLB)P P1 .P2 ;rewardLB Iresid (P1 .P2 );2021222324return P;endAlgorithm 5: recursive-eSIP procedure branch bound approaches efficient path planning.procedure corresponds max node search space input rewardLB representing calculated lowerbound. sum node search space effectively combines recursive calls subpaths (implemented Line 16 Line 19). Since recursion reduces traveling budget (2iter L) half, initial pruningLine 8 removes cells reached next recursion step. Line 15 Line 18 calculate lowerbound subpaths either side selected middle cell. Input represents scaling factor oneb 11/e I(P )sub-approximation heuristics. Approximation guarantee output path P given I(P)1+log2 Nsubmodular reward function P optimal path.726fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS(a) sum-max tree(b) Pruning sum nodes(c) Tighter lower boundsFigure 6: Illustration branch & bound approach. (a) shows sum-max tree representing search space.max node selects middle cell budget allocation, sum node combines two subpaths either sideselected middle cell. (b) shows upper bound sum node (e.g. value 18 Sum2 ), smallerlower bound parent max node (e.g. value 20 Max1 ) used prune branches search tree. (c)shows lower bound max nodes tightened (e.g. value 7 Max6 improved 9 using upper bound 11sibling axn7 lower bound 20 grandparent Max1 ) allow pruning otherwise maypossible (e.g. pruning Sum4 upper bound value 8).7.2 Efficient Search Problem Spacenaive implementation recursive-eSIP, entire recursion tree would eventually traversed.However, many considered subpaths may highly suboptimal. Several heuristicsproposed past similar path planning problem empirical efficiency claims, withoutapproximation guarantee. use one heuristic (c.f., Chao et al., 1996, hereafter referredheuristicOP) calculate solution path satisfying budget constraints, trying maximize collected reward. Since path efficiently calculated small computationeffort, use path initial known solution. total reward collected path usedinput lower bound (input variable rewardLB Algorithm 5) root max node. Sincecomputation effort associated heuristicOP small, also used rest max nodessearch tree calculate lower bound nodes (discussed detail Section 7.2.2).child sum nodes, upper bound collected reward calculated exploiting submodularity reward function (procedure calculateU B called Line 11 12727fiS INGH , K RAUSE , G UESTRIN & K AISER1Algorithm:calculateUBInput: Cs , Ct , , iter, ROutput: upper bound UB information gain2 begin// Selecting set reachable cells3possibleCells Ci Ci s.t. d(Cs , Ci ) + d(Ci , Ct ) 2iter L ;// Greedy node selection within reachable cells4P GreedySubsetBe ,R (vi : vi possibleCells);5UB Iresid (P);6return U B;7 endAlgorithm 6: Procedure calculating upper bound max nodes. Upper bound child max nodes addedobtain upper bound parent sum node.Algorithm 5 explained detail Algorithm 6). need process sum nodechildren upper bounds greater current best solution (Line 13 Algorithm 5).current best solution parent max node updated collected rewardchild sum nodes greater previously known best solution reward (Line 20 Algorithm 5).Fig. 6b presents graphical illustration concept. completely exploring branchSum1 , current best solution value 20 updated lower bound Max1 . smaller lowerbound (18) Sum2 results pruning sub-branch rooted Sum2 . However, nodes Sum3upper bound (24) higher current best solution (20), need exploredpotentially provide solution path better reward current best solution.7.2.1 U PPER B OUND Sum N ODESAlgorithm 6 presents calculateUB procedure obtaining upper bound collectedreward max node used recursive-eSIP (Line 11, 12 Algorithm 5) pruningsearch space. upper bound sum node calculated adding upper boundchild max nodes. calculate upper bounds relaxing path constraints, findingoptimal set reachable locations path (P1 P2 ). Since problem NPhard, exploit submodularity reward function approximate using GreedySubsetalgorithm. Fig. 7 illustrates example calculating upper bound. first calculate setreachable locations w.r.t. remaining traveling budget. locations contained withincells Ci reachable cells Cs Ct (Line 3 Algorithm 6). boundary reachablelocations illustrated ellipse Fig. 7.Then, run GreedySubset algorithm greedily select best possible locationspossible reachable locations (Line 4 Algorithm 6). example, Vi Vj selectedusing GreedySubset Fig. 7. Since GreedySubset guarantees constant factor (11/e) approximation (Nemhauser et al., 1978), multiplying resulting information value (1 1/e)1 providesupper bound information achievable path (and hence corresponding max childnode). Therefore, Fig. 7 reward collected locations Vi (MI(Vi )) Vj (MI(Vj ))multiplied factor (1 1/e)1 provides upper bound collected reward. However, sincepath cost constraint relaxed, total cost observing Vi Vj (dsi + dij + djt ) may728fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSFigure 7: Illustration calculating upper bound using GreedySubset.available budget B. Fig. 6c, example, use calculateUB get upper bounds13 Max6 11 Max7 , resulting upper bound 13 + 11 = 24 Sum3 4 .7.2.2 L OWER B OUND Max N ODES :Effective pruning subtree rooted sum nodes would require calculating lower boundsparent max node efficiently. One way calculate lower bounds exploring one branchcompletely (as explained Section 7.2). procedure computationally expensive. Instead, implement two ways acquiring lower bounds faster: Using heuristicOP 5(as explained obtaining initial best solution), based current best solutiongrandparent max node. use larger two different lower bounds.Fig. 6c illustrates graphical presentation procedure calculating lower boundsusing current best solution grandparent max node. call procedure altLB. calculate upper bound (exploiting submodularity) 11 Max7 node. node Max6 , sincegrandparent node Max1 lower bound 20, subtree rooted Max6 providereward least 9 (20 - 11) explored further. lower bound value 9 calculated usingaltLB tighter lower bound provided heuristic (7), enabled pruning branchSum4 (with upper bound 8).Lines 15 18 Algorithm 5 illustrate altLB procedure. using altLB, lowerbound subpath P1 (in Line 15), calculated using upper bound subpath P2 .hand, calculating lower bound using altLB subpath P2 (in Line 18), exact rewardP1 (IR (P1 )) used instead upper bound. Since actual reward always tightercalculated upper bound, lower bound calculated subpath P2 (using altLB) tighterlower bound calculated subpath P1 . motivates exploring subpath higherexperimental budget first upper bound unexplored subpath (with lower experimental budget) tighter making lower bound first subpath tighter6 . heuristic4. even compute tighter online bounds maximizing monotonic submodular functions, discussedNemhauser et al. (1978).5. heuristicOP proposed modular functions found provide good solution paths evensubmodular setting.6. note higher experimental budget, GreedySubset (used calculate upper bound) potentiallyselect locations far apart (since path cost constraint ignored). path cost constraintincorporated, locations become infeasible make upper bound loose.729fiS INGH , K RAUSE , G UESTRIN & K AISERexploring subpath higher experimental budget first also exploited improvecomputation effort.Maintaining lower bound node search tree also makes approach anytime,i.e. search terminated point even completed. current best solutiongraph already searched available early termination. Early terminationparticularly advantageous scenarios required obtain best possible path traversedrobot hard upper bound available time calculate path.7.2.3 N ODE RDERINGillustration Fig. 6b demonstrates better currently known solution likely helpincreased pruning search tree. order improve current best solution faster,max node explore sum nodes decreasing order upper bounds. intuitiveidea higher upper bound likely indicator higher reward value. Thus upper boundLine 11 12 Algorithm 5 calculated separately rest computation (inloops implemented Line 9 10 Algorithm 5) executed decreasing orderupper bound. approach similar node ordering employed improve pruningefficiency Depth First Branch Bound (DFBnB) (Zhang & Korf, 1995).7.2.4 UB - APPROXIMATIONUpper lower bounds derived explained potentially loose. addressissue, trade collected information improved execution time, introducingseveral sub-approximation heuristics. first heuristic, node ordering performed,explore top K sum nodes. heuristic, termed sub-approximation (Ibaraki et al.,1983), found effective practice.second heuristic, instead comparing lower bound parent max node directlyupper bound child sum nodes (when deciding subproblems prune), scalelower bound factor > 1 (Line 13 Algorithm 5). scaling often allows usprune many branches would pruned otherwise. Unfortunately, optimisticpruning also potentially cause us prune branches pruned, decrease information collected algorithm. practice, sufficiently small values,procedure speed algorithm significantly, without much effect quality solution. performance comparison computation effort collected reward using severalreal world sensing datasets discussed Section 8.2.8. Experimental Resultsperformed several experiments in-field well simulation (using real world sensingdatasets) demonstrate usefulness proposed algorithm several diverse environmentalsensing applications. In-field experiments performed using Networked InfoMechanicalSystem (NIMS) (Jordan et al., 2007), tethered robotic system. Real world sensing datasets usedperforming scaling multi robot experiments simulation collected using eithernetwork static sensors robotic boat.730fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS(a) Schematic representation system(b) Image captured performing path planningFigure 8: Aquatic based NIMS (NIMS-AQ)is platform NIMS family used performing path planninglake environment.8.1 In-field ExperimentsSeveral experiments performed in-field demonstrate applicability modeling phenomenon Gaussian Process using eMIP perform path planning diverse aquatic sensing applications. include river monitoring application objective studying saltconcentration, lake monitoring several applications interest limnologists.applications, NIMS used monitor cross-section (two dimensional vertical planeenvironment) aquatic environment. phenomenon interest modeled Gaussian Process use mutual information criterion submodular reward function, quantifying informativeness observation locations. learned Gaussian Process model mutualinformation objective provided input eMIP subset locations outputalgorithm subsequently observed, using NIMS robotic platform. order quantifyefficiency approach, predict phenomenon unobserved locations computeroot mean square (RMS) error predicted phenomenon ground truth (calculatedobserving uniformly spaced locations path planning experiment).8.1.1 ROBOTIC P LATFORM :Aquatic Networked InfoMechanical Systems platform (NIMS-AQ) latest familyNIMS systems (Jordan et al., 2007; Pon et al., 2005; Borgstrom et al., 2006), developed specificallyaquatic applications used lake deployment. family NIMS systemssuccessfully deployed several terrestrial aquatic sensing applications. 2006 alone,NIMS used several successful campaigns forests (La Selva, Costa Rica James Reserve,California), rivers (San Joaquin, California Medea Creek, California), lake (Lake Fulmor, California), mountain ecosystems (White Mountains, California),Fig. 8a displays schematic view system. basic infrastructure system includes rigid sensing tower supported two Hobie FloatCat pontoons7 catamaran configuration. actuation module resides top sensing tower drives horizontal cablevertical payload cable (horizontal vertical motion respectively) across cross-sectionaquatic environment. Power system provided two deep cycle marine batteries housedtop pontoons. horizontal drive cable kept center-aligned craft using guide7. Developed Hobie Cat Company.731fiS INGH , K RAUSE , G UESTRIN & K AISER(a) Observed distribution raster scan August 11(b) Predicted distribution observing locationsoutput eMIPFigure 9: Distribution electrical conductivity (microSiemens per centimeter) observed confluence SanJoaquin river, California. Points represent observation locations corresponding experiment.pulleys repositioned based type aquatic environment NIMS-AQsampling (flowing still water conditions). Fig. 8b shows NIMS-AQ performing path planninglake environment.8.1.2 ENSING R IVER E NVIRONMENTfirst in-field application approach executed confluence two distinct rivers,Merced river San Joaquin river, California August 7-11, 2007 (hereafter referredSan Joaquin deployment). Fig. 1a displays aerial view San Joaquin deployment site.scientific objective confluence zone characterize transport mixing phenomenaconfluence two distinct rivers Merced river (relatively low salinity) agriculturaldrainage-impacted San Joaquin River (relatively high salinity) observing several parametersmay indicate mixing behavior two streams. river observations useful answering important questions pertaining spatio-temporal variability velocity water qualitydynamics resulting pollutant inputs, hydrodynamic mixing regimes, biogeochemical cycling processes distributed time space. Understanding mixing patterns important policy issues related water distribution river ecosystems (Brekkeet al., 2004).total width observed cross-section 40 meters maximum depth 1.4 meters (closer middle cross-section). Several experiments executed pastcharacterize mixing phenomena confluence site (Singh et al., 2007a; Harmon et al.,2007). Primary experimental design campaigns comprised making observationsuniformly spaced locations two dimensional cross-section (hereafter referred raster scan)repeating experiments several times understand spatial temporal dynamicsenvironment. experiments took several hours, thus restricting experimentssmall number cross-sections (one two) within limited deployment time. However,detailed understanding confluence environment would require observing multiple crosssections, within limited time frame. necessitates use adaptive sampling approachmodel observed phenomenon, make observations small number locations basedmodel effectively predict phenomenon unobserved locations.732fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSMixing patterns characterized confluence observing electrical conductivityindicated amount salt concentration water. Fig. 9a displays typical distributioncross-section confluence zone x-axis representing distance along cross-sectiony-axis representing depth. Low concentration electrical conductivity towards lowerx values contributed clear water Merced river end displaying highconcentration salts carried San Joaquin river. first use data one rasterscan performed first day deployment (displaying similar characteristics) learnnon-stationary Gaussian Process model, using covariance function parameterization describedKrause Guestrin (2007). parameters chosen maximizing marginal likelihood (Rasmussen & Williams, 2006). non-stationary process learned dividingcomplete region smaller sub-regions combining locally-stationary GPssub regions.total 114 locations observed raster scan used learning GPmodel. set 16 locations selected total 114 (14%) using eMIP algorithmstarting finishing location either end cross-section displayed Fig. 9a.set 16 observation locations observed next days. requireddwelling time8 30 seconds observing electrical conductivity, large reduction number observation locations resulted significant reduction experimental time well (14% comparedraster scan).Since environmental phenomena exhibit spatial temporal dynamics, performed rasterscans experiment get measure ground truth electrical conductivity.predicted electrical conductivity, computed making observations subset 16locations selected using eMIP, compared ground truth. Fig. 9b displays predicted distribution specific conductivity points representing observed locations outputeMIP. Fig. 9a displays distribution observed using raster scan performedpath planning experiment.RMS error predicted distribution raster scan performed pathplanning experiment 45.99 S/cm. hand, RMS error predicteddistribution raster scan performed path planning experiment 53.87 S/cm.RMS error two raster scans performed path planning experiment, indicating temporal variation environment, 57.55 S/cm. Low RMS errorpredicted distribution, compared RMS error raster scans performedpath planning experiment clearly indicates effectiveness approachmodeling path planning environments. Path planning experiments performeddays also demonstrated similar prediction accuracy, maintaining significant reduction total experimental time.8.1.3 ENSING L AKE E NVIRONMENTsecond set in-field experiments executed lake campus University California, Merced August 10-11, 2007 (hereafter referred lake deployment). sitechosen based convenience accessibly located university campus similarity several lakes interest diverse limnology applications, includingstudy growth patterns algal bloom. Nuisance algal bloom impair beneficial use8. Time sensor kept static get accurate measurement.733fiS INGH , K RAUSE , G UESTRIN & K AISER(a) Observed distribution raster scan August 11(b) Predicted distribution observing locationsoutput eMIPFigure 10: Distribution temperature (o C) little UC Merced campus. Points represent observation locationscorresponding experiment.aquatic systems, blocking sunlight underwater vegetation, consuming oxygen water,producing surface scum odors. growth pattern algal bloom lake dependentspatial temporal dynamics temperature, dissolved nutrients light occurring different layers environment. Thus, temperature one critical parameter observelake environment controls several physical processes occurring low flow aquaticenvironments (in contrast San Joaquin river environment considerable waterflow).total width observed cross-section 70 meters, maximum depth1.81 meters. Similarly San Joaquin deployment, first learned non-stationary GP modelusing temperature data one raster scans performed August 10. Fig. 10a displaystypical surface distribution temperature observed raster scan lake. total89 locations observed raster scan. set 15 locations selected 89locations (17%) using eMIP algorithm starting ending location either endcross-section displayed Fig. 10a. set 15 observation locations observednext day using NIMS robotic platform. Similar San Joaquin deployment, performedraster scans experiment get measure ground truth temperaturedistribution. predicted temperature, computed making observations subsetlocations selected using eMIP, compared ground truth. smaller dwelling time10 seconds (required measuring temperature) cover entire length lakecross-section, reduction experimental time 50% (when compared raster scan).Fig. 10b displays predicted distribution temperature points representing observedlocations output eMIP. Fig. 10a displays distribution observed using raster scan performed path planning experiment. RMS error predicted distributionraster scan performed path planning experiment 0.73 C. hand,RMS error predicted distribution raster scan performed path planningexperiment 0.82 C. RMS error two raster scans performedpath planning experiment, indicating temporal variation environment, 1.25 C.low RMS error predicted distribution raster scans, comparisontemporal variation exhibited lake environment, indicates effectiveness approachlow-flow lake environment well.734fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS8.2 Experiments Sensing DatasetsSeveral experiments performed simulation using real world sensing datasets analyzescaling algorithm different approaches varying experimental cost, exponentialincrease budget split, varying size cells spatial decomposition comparisonseveral heuristics, among others. Three different datasets, collected real world sensing applications, used experiments. first dataset consists measurements temperatureLake Fulmor, James Reserve (hereafter referred lake temperature dataset). Fig. 1b displaysaerial view Lake Fulmor. robotic boat, part Networked Aquatic Microbial ObservingSystem (NAMOS) (Dhariwal et al., 2006), used collect surface temperature data aroundlake, width around 50 meters length around 250 meters. discussed earlier, understanding temperature distribution prime importance limnology since governs several physicalphenomena occurring lake environment, including growth algal bloom.average speed boat approximately 0.4 m/s. Half total measurements (218different sensing locations) used learn nonstationary Gaussian Process model maximizing marginal likelihood (Rasmussen & Williams, 2006), remaining measurementsused experimentation. divided lake 22 cells (except experimentsstudying effect changing size cell spatial decomposition), distanceadjacent cell approximately 21 meters. Based average speed, motivated typicalmeasurement duration roughly 25 seconds, set experiment cost 10.5 meters (exceptexperiment understanding effect scaling experimental cost).second dataset, used data existing deployment 52 wireless sensor moteslearn amount temperature variability Intel Research Laboratory, Berkeley (hereafterreferred Berkeley temperature dataset). sensing locations lie within bounding regionlength 45 meters width 40 meters. divided complete region uniform grid containing 20 equal sized cells, determined experimental cost 9 meters (approximate distancetravel adjacent cells). learned GP model discussed Krause et al. (2006).Finally, explored performance algorithm precipitation dataset collected167 regions equal area, approximately 50 km apart, years 1949-1994. followedpreprocessing model learning described work Krause et al. (2008). large physicalspread sensing regions makes dataset unconventional mobile robot path planningapplication. avoid unrealistic scenario, normalized coordinates regions liewithin bounding region length 7 meters width 9 meters, keeping actual sensingdata observed location. divided complete region uniform grid 20 cellsexperimental cost 1.4 meters (approximate traveling distance adjacent cells).plots comparing performance algorithm, x-axis represent totalcost path including traveling cost selected locations sensingcost selected location (translated distance discussed above). comparingcomputation effort measure performance, seconds, y-axis drawn logarithmic scale.computation effort running code implemented Matlab 3.2 GHz dual processorcore 4 GB RAM. comparing collected reward measure performance, y-axisrepresent mutual information (submodular reward function) collected making observationsselected locations.735fi51010Recursivegreedy410Collected RewardExecution Time (seconds)INGH , K RAUSE , G UESTRIN & K AISER310210eMIP11001060Recursivegreedy86eMIP46080100 120 140 160Cost output path (meters)80100120140160Cost output path (meters)(a) Comparison computation effort(b) Comparison collected rewardFigure 11: Comparison eMIP recursive-greedy subset Berkeley temperature dataset 23 sensing51510subapproximationSubapprox: 10%subapproximationCollected RewardExecution Time (seconds)locations.Subapprox: 10%Subapprox: 20%Best Possible 20subproblems010200250300350400Subapprox: 20%105Best possible 20subproblems0200450250300Uniform density350400450Cost output path(meters)Cost output path(meters)(a) Comparison computation effort(b) Comparison collected rewardFigure 12: Comparison computation effort collected reward several sub-approximation heuristics usedimprove running time eMIP lake temperature dataset. Significant improvement execution time observed,particularly longer paths, without significant reduction collected reward.8.2.1 C OMPARISON R ECURSIVE - GREEDY LGORITHM :compare performance approach recursive-greedy algorithm, proposedChekuri et al., selected subset 23 locations total 52 locations Berkeleytemperature dataset. small subset locations selected since running time recursivegreedy quasi-polynomial large complete dataset. Fig. 11a Fig. 11bdisplay comparison computation effort collected reward smaller datasettwo algorithms. evident plots, approach provides significant improvementrunning time (of several orders magnitude higher budget values) (almost) collected reward. Since recursive greedy algorithm essentially search procedure greedilyrestricted search space, result also indicates exhaustive search paths intractableeven small real world sensing problem. sudden jump execution time eMIP Fig. 11abudget = 100 meters due additional iteration step (c.f., Line 7 Algorithm 3) added dueincrease input budget constraint. Thereafter, additional increase budget results increase experimental budget. Since recursive-eSIP computes efficientlysmall problem, additional increase experimental budget increase computation effortsignificantly.736fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS300Distance (meters)250Lake BoundaryStartingLocation200Cells150eMIP Path1005000Possible observationlocations50100150200Distance (meters)250300Figure 13: Illustration path selected using eMIP lake temperature dataset.8.2.2 C OMPARISON U NIFORM AMPLE PACING :compared performance eMIP simple uniform sample spacing algorithm, referredUniform density. case Uniform density, starting finishing given locations,greedily select two observation locations within nearest cells compute corresponding path cost path reward. Uniform density algorithm output best possible pathamongst possible simple uniform sample spacing algorithms due greedy observation selectionwithin cell. Fig. 12b, compares collected reward Uniform density eMIPlake temperature dataset. Increased collected reward eMIP, compared Uniform density, empirically justifies complexity eMIP. Additionally, eMIP also provides strong approximationguarantee possible uniform sample spacing algorithm. Fig. 13 illustratespath selected eMIP lake temperature dataset, demonstrating eMIP tendcause uniform sample spacing. traversed cells, location selectedobservation, others many three observation locations selected withincell.8.2.3 C OMPARISON UB - APPROXIMATION H EURISTICS :Various sub-approximation heuristics discussed Section 7 compared empirically analyzeutility improving execution time corresponding reduction collected reward,any. displayed Fig. 12a compares heuristics computation effort,sub-approximation heuristic provides improvement execution time scenariobranch bound heuristics sub-approximation heuristics used.improvement higher values input budget observed lower bound increasedfactor (= 1.2 20%). Fig. 12b displays corresponding comparison heuristicscollected reward. interesting observe none sub-approximation approachesresulted considerable reduction collected reward.737fi5108Cost = 1.124Cost = 0.56Collected RewardExecution Time (seconds)INGH , K RAUSE , G UESTRIN & K AISERCost = 0.8410Cost = 0.56310Cost = 1.4210152025Cost output path (meters)Cost = 0.846Cost = 1.125514Collected RewardLinear variation4Exponential variationends31030Exponential variationends12Linear variation108Exponential increase 0210200Exponential variation 02503003504006200450250300350400450Cost output path(meters)Cost output path(meters)(c) Computation effort variation experimentalbudget split using lake temperature dataset(d) Collected reward variation experimental budget split using lake temperature dataset51020Grid: 20 cells4Collected RewardExecution Time (seconds)2025Cost output path (meters)(b) Collected reward variation sensing cost usingprecipitation dataset1010Cost = 1.4431530(a) Computation effort variation sensing cost using precipitation datasetExecution Time (seconds)7Grid: 14 cells10310210Grid: 22 cells0Grid: 22 cells10Grid: 20 cells5Grid: 33 cells110Grid: 14 cells1520040060000800Grid: 33 cells200400600800Cost output path(meters)Cost output path(meters)(e) Computation effort variation grid sizespatial decomposition using lake temperature dataset(f) Collected reward variation grid size spatial decomposition using lake temperature datasetFigure 14: Comparison collected reward computation effort variation several approaches used eMIP.738fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS8.2.4 VARIATION ENSING C OST:Fig. 14a Fig. 14b compare computation effort collected reward sensing costvaried precipitation dataset. reduction experimental cost, locationsobserved total input budget resulting increased collected reward. However,experiments, computation effort approximately same. Due diversityenvironmental applications, sensing cost depend sensors (settling time) scaledynamics occurring observed phenomena. experiment indicates eMIP useddiverse range sensing costs, per demands diverse environmental applications.8.2.5 VARIATION E XPERIMENTAL B UDGET PLIT:discussed Section 6, strategy exponentially increasing experimental budget splitresults increased additional path length required guarantee approximation factorcollected reward. performed several experiments available datasets analyzeempirical performance increasing budget splits exponentially. Fig. 14c Fig. 14d comparescomputation effort collected reward linear increase, one sided exponential variation0 two-sided exponential variation 0 budget B lake temperaturedataset. Since smaller number budget splits considered recursive-eSIP caseexponential increase, computation effort smaller compared linear increasebudget splits. Interestingly, small reduction collected reward,budget values, exponential increase employed. Hence, even though theoreticalapproximation guarantee exponential increase experimental budget weaker, empiricallycollected reward linear exponential increase budget splits foundcomparable wide range input budgets.8.2.6 NALYSIS PATIAL ECOMPOSITION :discussed Section 6, conversion SD-MIPP solution (a cell path) solutionMIPP (a path observation locations) result additional path length exceeding inputbudget B. additional path length depend size cell (or size grid coveringcomplete spatial domain) SD-MIPP problem result trade-off computationeffort. Variation grid-size result corresponding variation traveling costneighboring cells. result opportunity travel cells denser gridinput budget constraint. However, keep experimental cost constant across varyinggrid size (since experiment cost depends observed phenomena independentspatial decomposition), scaled accordingly, proportion traveling costneighboring cells. Fig. 14f compares collected reward varying grid sizes laketemperature dataset, changing grid size 14 33 cells. interesting observechange grid size (almost) negligible effect collected reward. hand,increase grid density resulted larger number cells path planningperformed thus leading increased computation effort input budget. comparisoncomputation effort varying grid size displayed Fig. 14e. Note drastic increasecomputation time grid discretization made finer.739fi16203 RobotsTotal RMS ErrorTotal Collected RewardINGH , K RAUSE , G UESTRIN & K AISER152 Robots10142 Robots123 Robots101 Robot52002503003504008200250300350400450Average cost output path per robot (meters)450Average cost output path per robot (meters)(a) Collected reward starting location(b) RMS error starting location15253 RobotsTotal RMS ErrorTotal Collected Reward1 Robot202 Robots15Single Robot10520025030035052 Robots3 Robots0250300350400450Average cost output path per robot (meters)400Average cost output path per robot (meters)(c) Collected reward different starting locationStart 3101 Robot(d) RMS error different starting locationBoundaryCells133Start 273Start 1Robot-2Robot-1Robot-3(e) Paths selected using MIPPFigure 15: Analysis experiments performed multiple robots different (optimized) starting location usinglake temperature dataset.8.2.7 ULTI - ROBOT E XPERIMENTSevaluated performance eMIP multi-robot algorithm simulation using several sensing datasets. Fig. 15 displays empirical analysis several experiments using lake temperature dataset. first experiment performed robot starting startinglocation. Fig. 15a Fig. 15b display collected reward root mean square (RMS) errornumber robots varied one three. Due sequential-allocation ap-740fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSproach (wherein remove locations already selected selecting locationsnext robot) information never hurts principle, collected reward increases numberrobots increased hence corresponding root mean square error predictionunobserved locations gets reduced. However, incremental change performance onetwo robots larger incremental change two three robots, expectedsubmodularity (diminishing returns) property mutual information.Fig. 15c Fig. 15d display collected reward RMS error different starting location chosen robot. scenario, set four starting locations pre-determinedlocation one end lake (see reference Fig. 15e three four startinglocations marked). starting location three robots selected greedily basedcollected information. different starting location selected opposite endlake second robot, incremental change collected reward (and corresponding decreaseroot mean square error) number robots increased one two much highercorresponding change starting location chosen second robotwell. However, similar scenario starting location, incremental changenumber robots increased one two higher compared numberrobots increased two three (due submodularity mutual information). Fig. 15eillustrates selected paths three robots selected using eMIP.9. Related Worklarge body related work theory path planning applications. Approximation algorithms proposed several related problems. Variants path planningstudied field Operations Research Traveling Salesman Problem (TSP)Vehicle Routing Problem (VRP). robotics, several path planning approachesstudied applications Simultaneous Localization Mapping (SLAM) searchexploration. sensor networks geostatistics, closely related work studies optimal placementstatic sensors modeling phenomenon Gaussian Processes. Several adaptive sampling approaches studied decide subset locations observe order understandphenomenon dynamics effectively. addition, similar approaches explored planning pathsmobile robots acting data mules, collecting data sampled network static sensors.9.1 Operations Researchinteresting special case MIPP problem given case node fixedreward, goal find path maximizes sum rewards (Traveling SalesmanProblem Profits, TSPP, Feillet et al., 2005). sum rewards modular (additive)function, special case submodular functions. subcategory TSPP optimization problem defined maximize collected reward keeping associated cost lessgiven budget B. studied Orienteering Problem (OP) selective TSP (Laporte &Martello, 1990), Maximum Collection Problem (Kataoka & Morito, 1988) literature.additivity assumption made orienteering problem unrealistic informative pathplanning setting, assumes information provided adjacent locations independent,whereas would typically expect strong amount correlation. fact, observationsindependent, would point selecting observations spatial prediction.741fiS INGH , K RAUSE , G UESTRIN & K AISERpaper, hence study general orienteering problem submodular reward functions,proposed earlier Submodular Orienteering Problem (Chekuri & Pal, 2005).9.1.1 ULTIPLE - PATH E XTENSIONS :extension TSPP multiple paths studied Vehicle Routing Problem Profits(VRPP) literature. Like TSPP, several variants VRPP previously considered.Prize Collecting VRP (PCVRP) (Tang & Wang, 2006) class VRPP objective determine subset customers visit minimize total distance traveled,minimize vehicles used maximize collected reward. multi-robot version OP(in case additive reward functions) studied Team Orienteering Problem I-Minget al. (1996) Multiple Tour Maximum Collection Problem Butt Ryan (1999).9.1.2 K NOWN PPROXIMATIONS RIENTEERING P ROBLEM :OP known NP-hard (Golden et al., 1987). Several versions OP studiedliterature classified starting (and finishing) location (root)pre-specified not. case unrooted OP (when starting location specified), approximation guarantees known Prize Collecting TSP k-TSP easily extended (Johnsonet al., 2000). several constant factor approximations known PC-TSP k-TSPproblems best one 2 approximation (Garg, 2005). However extensionapply rooted version problem best path unrooted version maycontain root may far away root thus leading violation budget constraint.rooted OP, Arkin et al. (1998) gave (2 + ) approximation OP geometricsettings. Blum et al. (2003) gave first constant factor approximation rooted OP generalundirected graphs. also extended algorithm multi-path OP. running timealgorithm, though polynomial, large (more specifically, O(n5 log( 1 )) totalreward path). Recently Chekuri et al. (2008) gave polynomial time algorithm OPundirected graphs improved approximation guarantee (2 + ). problem formulationspecified starting location (s) finishing location (t) falls category rooted OPsubmodular (non-additive) reward function.Another classification OP done based symmetry space possiblelocations. approximation guarantees hold true symmetric spaces (undirectedgraphs). Obtaining good approximation algorithm directed (asymmetric) orienteering problem stated open problem Blum et al. (2003). Chekuri Pal (2005) gave firstapproximation algorithm O(log n) guarantee runs quasi-polynomial running time.running time recently improved independently two different works (Chekuri et al., 2008;Nagarajan & Ravi, 2007), proposing poly-time approximation algorithm providing approximation guarantee O(log2 n), though using different approaches. metric space conversion procedure used spatial decomposition approach limits eMIP symmetric spacesonly.9.1.3 EQUENTIAL LLOCATION :Blum et al. (2003) proposed sequential allocation approach extend algorithms single-robotorienteering multiple robot setting, special case additive (modular) rewardfunctions. paper, generalize result submodular reward functions. initial742fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSversion paper published (Singh et al., 2007b), realized sequential-allocationprocedure instance maximizing submodular function subject matroid constraint (Calinescu et al., 2007). define partition matroid disjoint union = M1 Mkk ground sets Mi , one robot. set Mi contains feasible paths robot i.collection 2M subsets P |P Mi | 1 (i.e. P correspondscollection paths, constraint pick one set Mi ) formsindependent sets partition matroid. Hence, problem finding collection maximallyinformative paths problem finding independent set matroid maximizing submodular function. Current work progress Goundan Schulz (2008) provides general resultsperformance sequential allocation procedure setting, used provesequential allocation results originally presented Singh et al. (2007b).9.2 Robotic Applicationsconsiderable work path planning robotics community several applications,including simultaneous localization mapping (SLAM) search exploration. Severaldifferent approaches studied applications, including auction based algorithms, data-adaptive approaches information gain based algorithms.9.2.1 IMULTANEOUS L OCALIZATION APPING :goal Simultaneous Localization Mapping (SLAM) build maps environmentperforming exploration environment objective estimate robot positionworld features simultaneously. Several approaches optimizing different objective functionsproposed perform path planning SLAM. Bourgault et al. (2002) proposed explorationframework using occupancy grid (OG) environment model (performing spatial decompositionobserved environment) objective maximize mutual information OG map.Stachniss et al. (2005) developed greedy algorithm selecting next location visitmaximize information gain map.contrast approaches, Sim Roy (2005) attempted optimize entire trajectory, next step, algorithm introduces approximations without theoretical bounds. Simmons et al. (2000) proposed distributed approach exploration mappingmultiple robots minimizing overlap information gain amongst multiple robots.provided quantitative results simulation provide theoretical boundsapproach. little work SLAM setting upper bound total cost path.addition, aware approaches SLAM carry approximation guaranteeseither single multi-robot cases. interesting direction future work would analyzeapplicability approach SLAM setting.9.2.2 EARCH E XPLORATION :search exploration application involves path planning robot goal searchingmoving target(s) given environment, e.g. target surveillance security applicationspatient tracking health care domain. Performing path planning using stochastic inference providesadvantage robustness sensing motion uncertainty though added complexity computational intractability. Roy Earnest (2006) proposed approach effectively computetrajectories target tracking based maximizing mutual information (evaluated using change743fiS INGH , K RAUSE , G UESTRIN & K AISERvariance probability distribution). used particle filter approach, performing clustering particles followed path planning clusters. Lau et al. (2006) formulatedtarget tracking indoor environments generalization NP-complete optimal searcher path(OSP) problem (Trummel & Weisinger, 1986). sought optimize probability detectionwithin given time horizon accounting undetected target probability functionpreviously visited locations search. used several branch bound approachesspeed search process. objective maximizing information gain subject budgetconstraints path cost makes eMIP suitable candidate performing path planningproblems.Ryan (2008) used approach partitioning search space subgraphs multi-robotpath planning. take conceptually similar approach, also reducing search space decomposing space regions performing path planning regions. However,address complex utility functions, quantifying informativeness visited locationslimited specific graph structures stacks, halls, cliques, rings casework Ryan (2008). Recently, Thompson Wettergreen (2008) used eMIP algorithmnear-term path planning performing autonomous exploration surficial units AmboyCrater Mojave desert, California.9.2.3 P LANNING YSTEMS PPLICATIONS :Certain applications robotic path planning used plan graphs (Blum & Furst, 1997) computeestimate resources time required achieve goals states encounteredsearch process. case over-subscription planning problem wherein subset goalsaccomplished within limited time resources available planning system,work Smith (2004) used orienteering heuristic provide ordered set goalsconsidered planner. Briel et al. (2004) proposed several heuristics efficiently solvingover-subscription planning problem. However, earlier proposed heuristics,reward function considered modular (additive). eMIP used efficiently solve oversubscription planning problem submodular setting strong approximation guarantees.9.3 Sensor NetworksPhenomenon modeling decide optimal placement set static sensors well studiedsensor networks geostatistics communities. Gaussian Process models spatial phenomena studied extensively (Cressie, 1991). Guestrin et al. (2005) proved that, casephenomena governed Gaussian Process models, selecting placement sensors greedilybased mutual information near-optimal. Krause et al. (2006) extended work includecommunication cost sensors optimizing sensor placement. communication constrained setting, similar path planning problem considered paper, greedyalgorithm performs badly, involved algorithms developed. Batalin et al. (2004)showed combining static mobile sensing devices, even simple scenario, resultsignificant improvement sensing performance. scenario, combinationstatic mobile sensing devices available, several approaches optimal placement staticsensors combined eMIP observe given phenomenon efficiently.744fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTS9.3.1 DATA C OLLECTION ENSOR N ETWORK :different scenario mobile robot combined network static sensorsimprove lifetime sensor network performing tours collecting data sampledstatic network. Somasundara et al. (2007) showed problem collecting dataenvironment shows spatial temporal dynamics NP-complete providedinteger linear programming formulation same. compared performance severalheuristics simulation single multi-robot scenario. Meliou et al. (2007) proposednonmyopic approach application data gathering tours using algorithm submodularorienteering (SOP) black box. provided strong approximation guarantees extensiveempirical evaluation indicates applicability approach applications.setting, eMIP used orienteering algorithm provide better approximation guaranteeaddition improved running time.9.3.2 DAPTIVE AMPLING E NVIRONMENTAL PPLICATIONS :Recent advances robotics opened opportunities high fidelity monitoring dynamicenvironmental sensing applications. Rahimi et al. (2004) explored several policies adaptivelysampling environment. Singh et al. (2006) proposed multiscale adaptive sampling approachuniformly sampling environment first stage followed sampling locations orderminimize mean square error most. also extended approach multiple robots,although without providing theoretical bounds. Using several in-field experiments wellsimulations using real world sensing datasets, demonstrate several environmentalphenomenon effectively sampled adaptively using eMIP.10. Conclusions Future Workpaper, presented eSIP, approximation algorithm efficient planning informativepaths. eSIP near-optimally solves NP-hard problem maximizing collected informationupper bound path-cost. eSIP algorithm builds recursive-greedy algorithmChekuri Pal (2005). eSIP preserves approximation guarantees recursive-greedy,overcoming computational intractability spatial-decomposition several branchbound approaches. also presented general approach, sequential-allocation, extendssingle-robot algorithm, eSIP, multiple-robot setting providing provably strongapproximation guarantee.also provide extensive empirical evaluation demonstrate effectiveness approachreal world sensing applications. performed several in-field experiments two importantenvironmental sensing applications lake monitoring (at small lake UC Merced campus)river monitoring (at San Joaquin river, California). Networked Info Mechanical System (NIMS)used robotic system performing path planning deploymentsdemonstrate practicality algorithm. also performed extensive simulation experimentsusing several real world sensor network data sets. global climate change correspondingimpetus sustainable practices, expect efficient path planning approaches helpaddress challenge monitoring environment-related activities effectively.future, plan explore applicability algorithm application domainsSLAM search rescue. plan work towards understanding limitations745fiS INGH , K RAUSE , G UESTRIN & K AISERlearning static GP model real world scenarios, extend approach online model adaptation.Acknowledgmentswould like thank Maxim Batalin helpful discussions, Bin Zhang providing lakedata set Michael Stealey, Henry Pai Victor Chen help river lake deployment. work partially supported NSF Grants No. CNS-0509383, CNS-0625518, CNS0331481, ANI-00331481, CCR-0120778, ECCS-0725441, ONR MURI W911NF0710287gift Intel. Carlos Guestrin partly supported Alfred P. Sloan Fellowship IBMFaculty Fellowship. Andreas Krause partially supported Microsoft Research GraduateFellowship.APPENDIXTheorem-1. Let approximation guarantee single path instance informativepath planning problem. sequential-allocation algorithm achieves approximation guarantee (1 + ) MIPP problem. special case, robots starting(si = sj , i, j) finishing locations (ti = tj , i, j), approximation guarantee improves1/(1 exp (1/)) 1 + .Proof Theorem 1. case robots start finish location, lettotal reward collected optimal solution. Additionally, define differencereward collected optimal solution, approximation algorithm,end stage i. Hence, 0 = .Let Ai = P1 Pi nodes selected approximation algorithm stage(A0 = ), let P = {P1 , . . . , Pk } denote collection paths chosen optimal solution.) f (Ai ) =Consider residual reward fAi . find fAi (P ) = f (Ai P ) f (Ai ) f (P Pdue monotonicity f . path Pj fAi (Pj ) k1 , j fAi (Pj ) <= fAi (P ), contradicting monotonic submodularity fAi . Hence path PjfAi (Pj ) k1 , thus approximation algorithm guaranteed find path Pi1fAi (Pi ) k.difference reward collected optimal solution reward collectedAlgorithm 1 stage + 1 most:i+1 (1 1/k)i ,(1 1/k)i+1 .Thus k stages, difference reward bounded k (11/k)k exp (1/).Hence, reward collect Algorithm 1 least (1 exp (1/)) times optimal reward,resulting approximation factor 1/(1 exp (1/)).case robot different starting finishing location, let Pi setnodes visited optimal path stage i. Let Oi set nodes visited optimalpath stage i, i.e., Oi = ij=1 Pj , O0 = O1 = P1 . reward collected746fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSapproximation algorithm stage bounded as:fAi1 (Pi ) 1/(fAi1 (Pi )).k stages, total collected reward given as:kXkXfAi1 (Pi ) 1/(fAi1 (Pi )).i=1(4)i=1Since left hand side telescopic sum, get:kXfAi1 (Pi ) = f (ki=1 Pi ) = f (Ak ).(5)i=1right hand side (RHS):kXR.H.S. = 1/(fAi1 (Pi )),i=1kX= 1/( (f (Pi Ai1 ) f (Ai1 ))).i=1Adding Oi1 terms using submodularity property, getkXR.H.S. 1/( (f (Oi Ai1 ) f (Oi1 Ai1 ))),i=1= 1/ [f (O1 ) 0 + f (O2 A1 ) f (O1 A1 ) + + f (Ok Ak1 ) f (Ok1 Ak1 )] .Rearranging terms, get:"R.H.S. 1/ f (Ok Ak1 )k1X#(f (Oi Ai ) f (Oi Ai1 )) .i=1Using monotonicity (f (Ok Ak1 ) f (Ok )) submodularity f ( f (Oi Ai ) f (OiAi1 ) f (Ai ) f (Ai1 )), get"#k1XR.H.S. 1/ f (Ok )(f (Ai ) f (Ai1 )) ,i=1= 1/ [f (Ok ) f (Ak1 )] .Using monotonicity (f (Ak ) f (Ak1 )), getR.H.S. 1/ [f (Ok ) f (Ak )] .Substituting Equation (5) (6) Equation (4), get:f (Ak ) 1/ [f (Ok ) f (Ak )] ,747(6)fiS INGH , K RAUSE , G UESTRIN & K AISERthus:f (Ak ) 1/( + 1)f (Ok ).resulting approximation guarantee (1 + ).theorem proof inspired proof multi-path orienteering providedBlum et al. (2003).Lemma 3. Let P = (s = v0 , v1 , . . . , vl = t) optimal s-t-path solution MIPP, constrained budget B. exists corresponding SD-MIPP path PC = (Cs = Ci1 , . . . , Cin =Ct ), traversing locations Ai1 Ail , budget 2 2B + 4L collectinginformation.Proof Lemma 3. Let P optimal path MIPP, constrained budget B. need ensure MIPP transformed SD-MIPP, PC corresponding optimal solution,enough budget PC feasible new problem domain. recall,new problem domain, SD-MIPP, traveling new cell costs L (distance centroidsadjacent cells), irrespective sensing location within cell.L124356Figure 16: Illustration increased budget requirement SD-MIPP.corresponding SD-MIPP, optimal path may make 4 experiments 4 differentcells (Cells 1,2,3 4 Fig. 16) sharing common vertex, sensing location differentcell close common vertex, requiring infinitesimally small traveling cost. Increasing budget 4L accounts case. Furthermore, paying additional costL traveling two corners edge cell, PC make experiments 2 newcells (Cells 5,6 Fig. 16. Thus, total number cells visited PC upper bounded2(B/L) + 4. Hence, budget 2B + 4L suffices render PC feasible SD-MIPP solution.convert MIPP two-dimensionalEuclidean distance corresponding L1 distance,budget needs increased 2B ensure P feasible L1 metric. Accountingconversion Euclidean distance L1 , total budget B requiredSD-MIPP,ensure feasibility optimal solution MIPP, upper bounded 2 2B + 4L.Lemma 4. Let PC = (Cs = C1 , . . . , Ck = Ct ) optimal solution single robot instancee optimal set locations selected withinSD-MIPP, constrained budget B,bb 11/e I(P ).visited cell Cj . Let P solution returned eSIP. I(P)C1+log k2Proof Lemma 4. prove induction length n optimal path. Let Fg (=(1 1/e)) constant factor due greedy selection sensing locations within cell.748fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSAlso assume budget constraint SD-MIPP problem. case n = 1, iter = 0Algorithm 4 select greedy subset nodes set Cs = Ct . giveapproximation guarantee Fg (Krause et al., 2008) compared optimal set numberobservations selected cell (and hence information obtained optimal SD-MIPPpath visiting cell).Now, assuming induction hypothesis holds n = k/2, get:FgIX (P ),(1 + log(k/2))FgIX (P ).log kIX (P)hold true traveling budget Bek/2 experimental budget Bek/2 . Let usanalyze case n = k. Let P1 optimal path Cs Ck/2 constrained budget B 0 .Since increase experimental budget split linearly, B 0 vary 0 Bek , Bektraveling cost visiting k cells. Since cost less Bek/2 , using inductionhypothesis,FgIX (P1 ).(7)IX (P1 )log kSimilarly, X 0 = X P1 following approximation guarantee holds true P2 :IX 0 (P2 )FgIX 0 (P2 ).log kdefinition submodular function:IX 0 (P2 ) = I(P2 P1 X) I(P1 X),= IX (P1 P2 ) IX (P1 ).Substituting (8), getIX 0 (P2 )Fg(IX (P1 P2 ) IX (P1 )).log kUsing monotonicity I,IX 0 (P2 )Fg(IX (P2 ) IX (P)).log kAdding (7), finally get:Fg(IX (P1 ) + IX (P2 ) IX (P)),log k(Fg + log k) IX (P) Fg (IX (P1 ) + IX (P2 )),IX (P)(1 + log k) IX (P) Fg (IX (P1 ) + IX (P2 )).Since IX submodular function,(1 + log k) IX (P) Fg (IX (P )),Fg(IX (P )).IX (P)1 + log k749(8)fiS INGH , K RAUSE , G UESTRIN & K AISERproof inspired analysis recursive greedy algorithm submodularorienteering proposed Chekuri Pal (2005).case exponential budget splits, budget needs increased, albeit sub-linearly:Lemma 7. Let PC = (Cs = Ci1 , . . . , CiN = Ct ) optimal SD-MIPP solution constrainede Let P solution returned eMIP exponential splits experimentalbudget B.3e I(P) 11/e I(P ).budget, started increased budget N log2 2 B.C1+log NProof Lemma 7. set paths eMIP considers exponential splits let us callexponential paths general strict subset linear paths considered linearsplits. proof Lemma 4 indeed shows path returned eMIP achieves factor11/e1+log N less information optimal exponential path. need show increasing3budget factor N log2 2 guarantees optimal linear path feasible exponential path.Every exponential path represented complete binary tree, whereby every internal nodegiven level tree corresponds choice middle node experimental budget allocationleft right sub-path corresponding recursion level. Further, every leaf treecorresponds set observations selected visited cell. Consider tree representinge inner node, restriction exponential splits leadoptimal linear path budget B.situation, either left right sub-path receives less experimental budget allocatedoptimal path. proof strategy turn new tree 0 , selectsobservations corresponds valid exponential path. order achieve this, annotateinner node v, receives Bv experimental budget optimal linear allocation,new feasible exponential budget Bv0 Bv . suffices show root R holds0 (n)log2 3/2 B = (3/2)log2 n B . Label edges 0 1, sub-pathBRRRcorresponding edge labeled 1 receives smaller part linear budget split. Hence,eleaf v path k ones receives Bv (1/2)k total linear budget requirement B.00Let us derive bounds Bv bottom up. prove induction Bv (3/2) Bvheight v (distance leaves). suffice condition Br0 (3/2)log2 n Br ,want prove. leaves v clearly Bv0 = Bv sufficient, since split done hencereward collected linear exponential split same. Let v inner nodechildren l r, w.l.o.g., left child l annotated 0. construction, Br Bv /2.induction hypothesis, Bl0 (3/2)m1 Bl , Br0 (3/2)m1 Br . choose Bv0 = Bl0 + 2Br0 ,find feasible exponential budget split allocating least Bl0 l Br0 r.split require increasing budget exponentially till suffice r allocating rest l.ensure always budget split suffice r exponential budget irrespectivewhether represents P1 P2 , need exponential splits sides, tryingexponential increase 0 (Bexp ) Bv Bexp cases r represents P1 P2respectively. Bv0 (3/2)m1 Bl + 2(3/2)m1 Br = (3/2)m1 Bv + (3/2)m1 Br(3/2)m Bv .Theorem 5. Let P optimal solution single robot instance MIPP problemb achieving informationbudget constraint B. Then, eSIP algorithm find solution P11/e2b)value least I(P) 1+log N I(P ), whose cost 2(2 2B + 4L)(1 + L Cexp23fe 2(2 2B + 4L)(1 + L 2 )N log2 2case linear budget split BCexpfe .case exponential budget split B750fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSProof Theorem 5. Let B budget requirement SD-MIPP according Lemma 4 (orLemma 7 case exponential splits) P corresponding solution returned eMIP.Let Cexp cost making observation sensing location. Maximum numbersensing locations visited P CB. Since account traveling sensingexplocations, additional cost equivalent traveling centroid visited cellscorresponding sensing location paid solution SD-MIPP transformedbackget solution MIPP. sensing location, maximum additional cost L 2 incurredtraveling sensing location returning back centroid, L lengthcell. Thus additional costsolution path MIPP problem, transformed SD-MIPP2problem upper bounded BLCexp . Since eMIP considers exponential budget splitstraveling experimental budget, increase budget another factor 2 guaranteessplit defined optimal MIPP solution feasible. Combining analysis Lemma 3Lemma 4 completes proof.ReferencesArkin, E. M., Mitchell, J. S. B., & Narasimhan, G. (1998). Resource-constrained geometric networkoptimization. Symposium Computational Geometry, pp. 307316.Bai, X., Kumar, S., Xua, D., Yun, Z., & Lai, T. H. (2006). Deploying wireless sensors achievecoverage connectivity. Proceedings 7th ACM international symposiumMobile ad hoc networking computing, pp. 131142.Batalin, M. A., Rahimi, M., Yu, Y., Liu, D., Kansal, A., Sukhatme, G. S., Kaiser, W. J., Hansen, M.,Pottie, G. J., Srivastava, M., & Estrin, D. (2004). Call response: experiments samplingenvironment. Proceedings 2nd international conference Embedded networkedsensor systems, pp. 2538.Blum, A., Chawla, S., Karger, D. R., Lane, T., Meyerson, A., & Minkoff, M. (2003). Approximationalgorithms orienteering discounted-reward tsp. Annual Symposium FoundationComputer Science (FOCS), p. 46.Blum, A. L., & Furst, M. L. (1997). Fast planning planning graph analysis. ArtificialIntelligence, 90, 16361642.Borgstrom, P. H., Stealey, M. J., Batalin, M. A., & Kaiser, W. J. (2006). NIMS3D: novel rapidlydeployable robot 3-dimensional applications. IEEE/RSJ International ConferenceIntelligent Robots Systems, Beijing, China.Bourgault, F., Makarenko, A., Williams, S., Grocholsky, B., & Durrant-Whyte, H. (2002). Information based adaptive robotic exploration. IEEE/RSJ International Conference IntelligentRobots Systems (IROS), pp. 540545.Brekke, L. D., Miller, N. L., Bashford, K. E., Quinn, N. W., & Dracup, J. A. (2004). Climate changeimpacts uncertainty water resources san joaquin river basin, california. JournalAmerican water resource association, 40, 149164.Briel, M. V. D., Sanchez, R., Do, M. B., & Kambhampati, S. (2004). Effective approaches partialsatisfaction (over-subscription) planning. AAAI, pp. 562569. AAAI Press.751fiS INGH , K RAUSE , G UESTRIN & K AISERButt, S. E., & Ryan, D. M. (1999). optimal solution procedure multiple tour maximumcollection problem using column generation. Computers Operations Research, 26, 427441.Calinescu, G., Chekuri, C., Pl, M., & Vondrk, J. (2007). Maximizing submodular set function subject matroid constraint (extended abstract). Integer Programming CombinatorialOptimization (IPCO), Vol. 4513 Lecture Notes Computer Science, pp. 182196.Caselton, W., & Zidek, J. (1984). Optimal monitoring network design. Statistics ProbabilityLetters.Chao, I.-M., Golden, B. L., & Wasil, E. A. (1996). fast effective heuristic orienteeringproblem. European Journal Operations Research, 88, 475489.Chekuri, C., Korula, N., & Pal, M. (2008). Improved algorithms orienteering related problems. Proc. 19th Annual ACM-SIAM Symposium Discrete Algorithms (SODA08).SIAM. appear.Chekuri, C., & Pal, M. (2005). recursive greedy algorithm walks directed graphs. AnnualSymposium Foundation Computer Science (FOCS), pp. 245253.Christofides, N. (1976). Worst-case analysis new heuristic traveling salesman problem.Tech report,CMU.Cressie, N. A. C. (1991). Statistics Spatial Data. Wiley.Dhariwal, A., Zhang, B., Stauffer, B., Oberg, C., Sukhatme, G. S., Caron, D. A., & Requicha, A. A.(2006). Networked aquatic microbial observing system. IEEE International ConferenceRobotics Automation (ICRA).Feillet, D., Dejax, P., & Gendreau, M. (2005). Traveling salesman problem profits. Transportation Science, 39(2), 188205.Garg, N. (2005). Saving epsilon: 2-approximation k-mst problem graphs. ACMSymposium Theory Computing (STOC), pp. 396402.Golden, B., Levy, L., & Vohra, R. (1987). orienteering problem. Naval Research Logistics, 34,307318.Goundan, P. R., & Schulz, A. S. (2008). Revisiting greedy approach submodular set functionmaximization.. Working paper, MIT.Guestrin, C., Krause, A., & Singh, A. P. (2005). Near-optimal sensor placements gaussian processes. International Conference Machine Learning (ICML).Harmon, T. C., Ambrose, R. F., Gilbert, R. M., Fisher, J. C., Stealey, M., & Kaiser, W. J. (2007).High-resolution river hydraulic water quality characterization using rapidly deployablenetworked infomechanical systems (NIMS RD). Environmental Engineering Science, 24(2),151159.I-Ming, C., Golden, B., & Wasil, E. (1996). team orienteering problem. European JournalOperation Research, 88, 464474.Ibaraki, T., Muro, S., Murakami, T., & Hasegawa, T. (1983). Using branch-and-bound algorithmsobtain suboptimal solutions. Mathematical Methods Operations Research, 27(1), 177202.752fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSIshikawa, T., & Tanaka, M. (1993). Diurnal stratification effects wind-induced currentswater qualities lake kasumigaura, japan. Journal Hydraulic Research, 31(3), 307322.Johnson, D. S., Minkoff, M., & Phillips, S. (2000). prize collecting steiner tree problem: theorypractice. Symposium Discrete Algorithms (SODA), pp. 760769.Jordan, B. L., Batalin, M. A., & Kaiser, W. J. (2007). NIMS RD: rapidly deployable cable basedrobot. IEEE International Conference Robotics Automation (ICRA), Rome, Italy.Kataoka, S., & Morito, S. (1988). algorithm single constraint maximum collectionproblem. Journal Operational Research Society Japan, 31, 515530.Ko, C.-W., Lee, J., & Queyranne, M. (1995). exact algorithm maximum entropy sampling.Operations Research, 43(4), 684691.Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.AAAI Nectar track.Krause, A., Singh, A., & Guestrin, C. (2008). Near-optimal sensor placements Gaussian processes: Theory, efficient algorithms empirical studies. Journal Machine LearningResearch (JMLR), Vol. 9, pp. 235284.Krause, A., & Guestrin, C. (2007). Nonmyopic active learning gaussian processes:exploration-exploitation approach. International Conference Machine Learning(ICML), pp. 449456.Krause, A., Guestrin, C., Gupta, A., & Kleinberg, J. (2006). Near-optimal sensor placements: Maximizing information minimizing communication cost. Proceedings fifth international conference Information processing sensor networks (IPSN), pp. 210.Laporte, G., & Martello, S. (1990). selective travelling salesman problem. Discrete AppliedMathematics, 26, 193207.Lau, H., Huang, S., & Dissanayake, G. (2006). Probabilistic search moving targetindoor environment. IEEE/RSJ International Conference Intelligent Robots Systems(IROS), pp. 33933398.Lin, S. (1965). Computer solutions traveling salesman problem. Bell System TechnicalJournal, 44, 22452269.MacIntyre, S. (1993). Vertical mixing shallow, eutrophic lake: Possible consequenceslight climate phytoplankton. Limnology Oceanography, 38(4), 798817.MacIntyre, S., Romero, J. R., & Kling, G. W. (2002). Spatial-temporal variability surface layerdeepening lateral advection embayment lake victoria, east africa. LimnologyOceanography, 47(3), 656671.Meliou, A., Krause, A., Guestrin, C., & Hellerstein, J. M. (2007). Nonmyopic informative pathplanning spatio-temporal models. Association Advancement Artificial Intelligence(AAAI), pp. 602607.Nagarajan, V., & Ravi, R. (2007). Poly-logarithmic approximation algorithms directed vehiclerouting problems. Proc. 10th Internat. Workshop Approximation Algorithms Combinatorial Optimization Problems (APPROX07), Vol. 4627 LNCS, pp. 257270. Springer.753fiS INGH , K RAUSE , G UESTRIN & K AISERNemhauser, G., Wolsey, L., & Fisher, M. (1978). analysis approximations maximizingsubmodular set functions. Mathematical Programming, 14, 265294.Pon, R., Batalin, M., Gordon, J., Rahimi, M., Kaiser, W., Sukhatme, G., Srivastava, M., & Estrin,D. (2005). Networked infomechanical systems: mobile wireless sensor network platform.Proceedings fifth international conference Information processing sensor networks (IPSN), pp. 376381.Rahimi, M., Pon, R., Kaiser, W., Sukhatme, G., Estrin, D., & Srivastava, M. (2004). Adaptivesampling environmental robotics. IEEE International Conference RoboticsAutomation (ICRA).Rasmussen, C. E., & Williams, C. K. (2006). Gaussian Process Machine Learning. AdaptiveComputation Machine Learning. MIT Press.Reynolds-Fleming, J. V., Fleming, J. G., & Luettich, R. A. (2004). Portable autonomous verticalprofiler estuarine applications. Estuaries, 25, 142147.Roy, N., & Earnest, C. (2006). Dynamic action spaces information gain maximization searchexploration. American Control Conference.Ryan, M. R. K. (2008). Exploiting subgraph structure multi-robot path planning. JournalArtificial Intelligence Research (JAIR), Vol. 31, pp. 497542.Sim, R., & Roy, N. (2005). Global a-optimal robot exploration slam. IEEE InternationalConference Robotics Automation (ICRA).Simmons, R. G., Apfelbaum, D., Burgard, W., Fox, D., Moors, M., Thrun, S., & Younes, H. (2000).Coordination multi-robot exploration mapping. Association AdvancementArtificial Intelligence (AAAI), pp. 852858.Singh, A., Nowak, R., & Ramanathan, P. (2006). Active learning adaptive mobile sensing networks. Proceedings fifth international conference Information processingsensor networks (IPSN), pp. 6068.Singh, A., Batalin, M. A., Chen, V., Stealey, M. J., Jordan, B., Fisher, J., Harmon, T., Hansen, M., &Kaiser, W. J. (2007a). Autonomous robotic sensing experiments san joaquin river. IEEEInternational Conference Robotics Automation (ICRA), pp. 49874993, Rome, Italy.Singh, A., Krause, A., Guestrin, C., Kaiser, W. J., & Batalin, M. A. (2007b). Efficient planninginformative paths multiple robots. International Joint Conference Artificial Intelligence (IJCAI), pp. 22042211, Hyderabad, India.Smith, D. E. (2004). Choosing objectives over-subscription planning. International ConferenceAutomated Planning Scheduling (ICAPS).Somasundara, A. A., Ramamoorthy, A., & Srivastava, M. B. (2007). Mobile element schedulingdynamic deadlines. IEEE Transactions Mobile Computing, Vol. 6, pp. 395410.Stachniss, C., Grisetti, G., & Burgard, W. (2005). Information gain-based exploration using raoblackwellized particle filters. Robotics Science Systems (RSS).Tang, L., & Wang, X. (2006). Iterated local search algorithm based large-scale neighborhood prize-collecting vehicle routing problem. International Journal AdvancedManufacturing Technology, 113.754fiE FFICIENT NFORMATIVE ENSING USING ULTIPLE ROBOTSThompson, D. R., & Wettergreen, D. (2008). Intelligent maps autonomous kilometer-scale science survey. International Symposium Artificial Intelligence, Robotics AutomationSpace (iSAIRAS).Trummel, K. E., & Weisinger, J. R. (1986). complexity optimal searcher path problem.Operations Research, 34(2), 324327.Zhang, W., & Korf, R. E. (1995). Performance linear-space search algorithms. Artificial Intelligence, 79(2), 241292.755fiJournal Artificial Intelligence Research 34 (2009) 605635Submitted 11/08; published 04/09Inferring Shallow-Transfer Machine Translation RulesSmall Parallel CorporaFelipe Sanchez-MartnezMikel L. Forcadafsanchez@dlsi.ua.esmlf@dlsi.ua.esDepartament de Llenguatges Sistemes InformaticsUniversitat dAlacant, E-03071 Alacant (Spain)Abstractpaper describes method automatic inference structural transfer rulesused shallow-transfer machine translation (MT) system small parallelcorpora. structural transfer rules based alignment templates, like usedstatistical MT. Alignment templates extracted sentence-aligned parallel corporaextended set restrictions derived bilingual dictionaryMT system control application transfer rules. experiments conductedusing three different language pairs free/open-source MT platform Apertium showtranslation quality improved compared word-for-word translation (whentransfer rules used), resulting translation quality close obtainedusing hand-coded transfer rules. method present entirely unsupervisedbenefits information rest modules MT system inferredrules applied.1. IntroductionMachine translation (MT) may defined use computer translate textone natural language, source language (SL), another, target language (TL). MTdifficult mainly natural languages highly ambiguous also twolanguages always express content way (Arnold, 2003).different ways MT problem approached may classifiedaccording nature knowledge used development MT system.point view, one distinguish corpus-based rule-based approaches;although, hybrid approaches also possible.Corpus-based approaches MT, example-based MT (EBMT; Nagao, 1984;Carl & Way, 2003) statistical MT (SMT; Brown et al., 1993; Knight, 1999), use largecollections parallel texts source knowledge engine learnsperform translations. parallel text text one language together translationanother language; large collection parallel texts usually referred parallelcorpus. Although corpus-based approaches MT grown interest lastyears, require large amounts, order tens millions words, paralleltext achieve reasonable translation quality (Och, 2005). vast amount parallelcorpora available many under-resourced language pairs demanding MT services.Rule-based MT (RBMT) systems use knowledge form rules explicitly codedhuman experts attempt codify translation process. RBMT systems heavily depend linguistic knowledge, morphological bilingual dictionaries (containingc2009AI Access Foundation. rights reserved.fiSanchez-Martnez & ForcadaSLtextAnalysisSL IRTransferTL IRGenerationTLtextFigure 1: Scheme general transfer-based MT system.lexical, syntactic even semantic information), part-of-speech disambiguation rulesmanually disambiguated corpora, large set rules. process building RBMTsystem involves considerable human effort order develop necessary linguistic resources (Arnold, 2003).Generally, RBMT systems work parsing (or analyzing) SL text, usually creatingintermediate (symbolic) representation (IR), text TL generated (Hutchins & Somers, 1992). According nature IR used, RBMT systemmay said either interlingua transfer-based. interlingua MT system usessingle IR independent languages involved translation; advantageusing language-independent IR transfer module needs developednew language pair; disadvantage IR used difficult design hardimplement, even so, open-domain tasks. contrast, transfer-based MT systemuses two IRs, one languages involved; advantage easingdesign development IRs used, cost develop transfermodule new language pair.Transfer-based MT systems usually work applying, addition lexical transfermappings, set structural transfer rules SL IR created analysis,order transform TL IR TL text finally generated (seeFigure 1). level analysis, therefore degree abstraction provided IR,varies depending related languages involved are. Translating distantlanguages (such English Japanese) requires deep analysis (syntactic semantic),translation related languages (for example Romance languages)achieved shallow parsing. call last type transfer-based systemsshallow-transfer MT systems.1.1 Overviewpaper focuses automatic inference small parallel corpora set structural (shallow-)transfer rules used shallow-transfer RBMT systems convertSL IR TL IR TL text generated. developmenttransfer rules requires qualified people code manually; therefore, automaticinference may save part human effort. method present entirely unsupervised benefits information rest modules MT systeminferred rules applied, line method proposed Sanchez-Martnez et al.(2008) train part-of-speech taggers unsupervised way use MT.approach existing bilingual dictionary used guide inference structural transfer rules (see below), bilingual entries dictionary learned.approach aimed inference transfer rules small parallelcorpora1 application open-domain tasks. Note small parallel corpora may1. Small compared size corpora commonly used build corpus-based MT systems (Och, 2005).606fiInferring Shallow-Transfer MT Rules Small Parallel Corporainsufficient obtain wide-coverage bilingual dictionaries, demonstrated resultsobtained translating state-of-the-art SMT system trained smallparallel corpora (see section 5). Notice manually building bilingual dictionarylanguage pair usually much easier developing shallow structural transfer rules it,moreover, former task partially automated.method propose automatic inference shallow-transfer rules parallel corpora based alignment template (AT) approach initially proposeduse SMT framework (Och, 2002; Och & Ney, 2004). definedgeneralization performed aligned phrase2 pairs (or translation units) using wordclasses.adapt approach RBMT framework, ATs extended setrestrictions control application structural shallow-transfer rules. end:bilingual dictionary RBMT system inferred rulesintegrated used ensure lexical content bilingual phrase pairextracted training corpus (see section 2.2) reproduced MTsystem;linguistically motivated word classes used generalize extracted bilingualphrase pairs, deriving ATs them; and,set restrictions, derived bilingual dictionary RBMT system,attached control application part transfer rule; extensiondefinition called extended AT.extended ATs extracted training corpora, transfer rulesgenerated them. experiments reported section 5, shallow-transfer rulesused Apertium MT engine (see appendix A) generated directly ApertiumsXML-based structural transfer language. interesting property inferred ruleshuman-readable may, therefore, edited human experts improveperformance supplemented new rules; MT developers use methodinfer initial set rules improve focusing difficult issues.method (Sanchez-Martnez & Forcada, 2007) predecessor (SanchezMartnez & Ney, 2006) already presented conferences; here, explainmethod detail, test two additional language pairs use training corporadifferent sizes evaluate impact size translation quality. Moreover,paper perform detailed analysis inferred rules results obtained;end, provide confidence intervals, allow better interpretationresults achieved. also discuss process followed build parallel corpora usedlearn transfer rules.2. purpose paper, stick terminology used Och Ney (2004)definition SMT practitioners, phrase refer text segment, necessarilywell-formed syntactic constituent.607fiSanchez-Martnez & Forcada1.2 Related Workattempts learn automatically semi-automatically structuraltransformations needed produce correct translations TL. approachesclassified according translation framework learned rules applied.approaches learn transfer rules used RBMT. Probst et al. (2002)Lavie et al. (2004) developed method learn transfer rules MT involving underresourced languages (such Quechua) limited resources. end, smallparallel corpus (of thousand sentences) built help small set bilingualspeakers two languages. parallel corpus obtained translating controlledcorpus language resources (English Spanish) under-resourcedlanguage means elicitation tool. tool also used graphically annotateword alignments two sentences. Finally, hierarchical syntactic rules,seen constituting context-free transfer grammar, inferred alignedparallel corpus.Menezes Richardson (2001) propose method infer transfer mappings (rules)source target languages. Prior acquisition transfer mappings,align nodes source target parse trees using existing bilingual lexiconlook word correspondences. Then, following best-first strategy usingsmall alignment grammar method aligns remaining (not-aligned) nodes.alignments nodes parse trees obtained, frequenciescomputed sufficient context retained disambiguate competing mappingstranslation time. approach greatly differs one Menezes Richardson:(i) use syntactic parser, bilingual dictionary alignment grammarobtain word alignments sentence-aligned parallel corpus, usestatistical methods; (ii) use bilingual dictionary, use discarduseless bilingual phrases derive restrictions control application ATs,computation word alignments; (iii) approachambiguity solve translation time.Caseli et al. (2006) propose method infer bilingual resources (structural transferrules bilingual dictionaries) used shallow-transfer MT aligned parallelcorpora. Previously generation transfer rules, alignment blocks (sequencesaligned words) built translation examples found parallel corpusconsidering three different types word alignments according geometry (crossings,unaligned words, etc.). Then, shallow-transfer rules built three-step procedure.first step, identify patterns two phases, monolingual bilingual;second step method generates shallow-transfer rules deriving monolingualbilingual constraints, also seen rule itself; finally, third step rulesfiltered order solve ambiguity caused rules matching SL sequencewords. inferred rules human-readable, inferred methodpropose, may therefore also edited human experts. approach differsCaseli et al. rules induced: approach uses bilingual phrasepairs without concerned type alignments words, wayCaseli et al. induce rules depends type alignment blocks. addition,approach ever produce one rule matching sequence608fiInferring Shallow-Transfer MT Rules Small Parallel CorporaSL items, therefore ambiguity needs solved. Furthermore, inferbilingual dictionary; instead, use existing bilingual dictionary guide inferenceshallow-transfer rules, control application inferred rules.EBMT framework, researchers dealt problem inferringkind translation rules called translation templates (Kaji et al., 1992; Brown, 1999; Cicekli& Guvenir, 2001). translation template defined bilingual pair sentencescorresponding units (words phrases) coupled replaced variables. LiuZong (2004) provide interesting review different research works dealingtranslation templates. Brown (1999) uses parallel corpus linguistic knowledgeform equivalence classes (both syntactic semantic) perform generalizationbilingual examples collected. method works replacing wordcorresponding equivalence class using set grammar rules replace patternswords tokens general tokens. Cicekli Guvenir formulate acquisitiontranslation templates machine learning problem, translation templateslearned differences similarities observed set different translationexamples, using morphological information all. Kaji et al. use bilingual dictionarysyntactic parser determine correspondences translation unitslearning translation templates. approach differs applied EBMTframework because, one hand, transfer rules generated methodpropose mainly based lexical forms (consisting lemma, lexical categorymorphological inflection information) and, hand, flatter,less structured non-hierarchical, makes suitable shallow-transfer MT.Moreover, way translation rules chosen application greatly differschosen EBMT framework.Finally, SMT framework use (Och & Ney, 2004) seenintegration translation rules statistical translation models, since generalization abstraction, transformations apply translating SL TLusing word classes.rest paper organized follows: next section reviews alignmenttemplate (AT) approach; section 3 explains ATs extended set restrictionsorder use generate shallow-transfer rules used RBMT (section 4).Section 5 describes experiments conducted results achieved. Finally, section 6discusses method described outlines future research lines.2. Alignment Template Approachalignment template (AT) approach (Och, 2002; Och & Ney, 2004) introducedSMT framework one feature functions maximum entropy model (Och& Ney, 2002) try generalize knowledge learned specific phrase similarphrases.performs generalization bilingual phrase pairs using word classes insteadwords. z = (Sm , Tn , A) consists sequence Sm SL word classes, sequenceTn n TL word classes, set pairs = {(i, j) : [1, n] j [1, m]}alignment information TL SL word classes two sequences.609fiSanchez-Martnez & Forcadametrequestpersonalmi nal ha ido checsfti ersetip psaFigure 2: Alignment words English sentence personal requestmet Spanish sentence mi peticion personal ha sido satisfecha. alignmentinformation represented binary matrix.Learning set ATs sentence-aligned parallel corpus consists of: (i) computation word alignments, (ii) extraction bilingual phrase pairs, (iii)generalization bilingual phrase pairs using word classes instead wordsthemselves.2.1 Word Alignmentsvariety methods, statistical (Och & Ney, 2003) hybrid (Caseli et al., 2005),3 mayused compute word alignments (sentence-aligned) parallel corpus. experiments reported section 5, word alignments obtained training classical statisticaltranslation models translate language L1 language L2 (and vice versa)computing Viterbi alignments previously estimated translation models.Viterbi alignment SL TL sentences defined alignment whose probability maximal translation models previously estimated. resulting Viterbialignments A1 A2 (one translation direction) symmetrizedrefined intersection method proposed Och Ney (2003, p. 33). Symmetrizationneeded order allow SL word aligned one TL word; otherwise,wrong alignments obtained SL word actually corresponds one TLword.Figure 2 shows word alignment SpanishEnglish sentence pair. alignmentinformation represented binary matrix value 1 (large black squares)means words corresponding positions aligned; analogously, value 0(small black squares) means words aligned.3. Caseli et al.s (2005) method hybrid prior application heuristics, uses statisticaltool (NATools) obtain probabilistic bilingual dictionary (Simoes & Almeida, 2003).610fiInferring Shallow-Transfer MT Rules Small Parallel Corpora2.1.1 Trainingorder train translation models calculate Viterbi alignments pairaligned sentences found training corpus free/open-source GIZA++ toolkit4 (Och& Ney, 2003) used default parameters.computation word alignments consists of:1. training IBM model 1 (Brown et al., 1993) 5 iterations; model, wordorder affect alignment probabilities;2. training HMM alignment model (Vogel et al., 1996) 5 iterations; alignmentmodel property making alignment probabilities explicitly dependentalignment position previous word;3. training IBM model 3 (Brown et al., 1993) 5 iterations; model,probability alignment depends positions aligned wordslength SL TL sentences. addition, IBM model 3 also introduces fertilities;fertility word defined number aligned words language.finally,4. training IBM model 4 (Brown et al., 1993) 5 iterations; model identicalIBM model 3 except fact models reordering phrases maymoved around units.Note obtaining Viterbi alignments statistical translation modelslonger used.2.2 Extraction Bilingual Phrase PairsBilingual phrase pairs automatically extracted word-aligned sentence pairs.Usually, extraction bilingual phrase pairs (Zens et al., 2002) performed considering possible pairs certain length ensuring that: (i) words consecutive,(ii) words within bilingual phrase pair aligned words outside.set BP(wS J1 , wT I1 , A) bilingual phrases extracted word-alignedsentence pair (wS1 , . . . , wSJ ), (wT1 , . . . , wTI ) may formally expressed follows:, wT i+n):BP(wS J1 , wT I1 , A) = {(wS j+mj(i0 , j 0 ) : j j 0 j + i0 + n}.However, approach bilingual phrase pairs also required first lastwords sides (source target) aligned least one word side.5Integrating additional constraints, previous equation may rewritten as:, wT i+n):BP(wS J1 , wT I1 , A) = {(wS j+mj4. http://www.fjoch.com/GIZA++.html5. Experiments conducted without requirement show significant degradation translation quality achieved inferred rules.611fiSanchez-Martnez & Forcada((i0 , j 0 ) : j j 0 j + i0 + n)(k [i, + n] : (wSj , wTk ) A)(k 0 [i, + n] : (wSj+m , wTk0 ) A)(l [j, j + m] : (wSl , wTi ) A)(l0 [j, j + m] : (wSl0 , wTi+n ) A)}.Figure 3 shows set bilingual phrase pairs one SL word extractedword-aligned SpanishEnglish sentence pair shown Figure 2.2.3 Generalizationgeneralization bilingual phrase pairs simply done using word classes insteadwords themselves; end, function maps single words word classesdefined. use word classes allows description word reorderings, prepositionchanges divergences SL TL. Och Ney (2004) use automaticallyobtained (Och, 1999) word classes extract ATs SMT. However, RBMT, linguistically motivated word classes related used remaining modules MTsystem must used (see section 3.1).3. Alignment Templates Shallow-Transfer Machine Translationapply approach shallow-transfer MT system, parallel corpusATs learned must intermediate representation (IR) used translationengine. shallow-transfer MT transformations apply mainly related lexicalforms; therefore, IR used translation engine usually consists lemma, lexicalcategory morphological inflection information word.order convert parallel corpus IR used engine, analysismodules (morphological analyzers part-of-speech taggers) engine usedanalyze sides parallel corpus computing word alignments.analyzing sides parallel corpus have, word, lemma, lexical categorymorphological inflection information. Note generalizations performedword alignments bilingual phrase pair extraction using word classes basedmorphological information (see next section).3.1 Word-Class Definitiontransformations apply mainly based lexical category inflectioninformation SL TL words, function maps words word classes mapword word class representing lexical category morphological inflectioninformation (such verb, preterite tense, third person, plural).Using lexical category morphological inflection information define setword classes allows method learn general syntactic rules reorderingagreement rules, verb tense changes, among others. However, order learn lexicalchanges, preposition changes auxiliary verb usage, words assignedsingle-word classes representing lexical form, discussed next.612fiInferring Shallow-Transfer MT Rules Small Parallel Corporarequestpersonaln lonacti rspe pemetdoechsftisaharequestha ido personaln lona n hcti rspe perequestpersonalmi nal hacti ersep prequestpersonalmi nal ha idocti ersep prequestpersonalmi nalcti ersep pmetha ido chesftisarequestpersonaln al haci sonsierep pmetrequestpersonaln nal ha checsfti ersetip psaFigure 3: Set bilingual phrase pairs (see section 2.2) extracted word-aligned SpanishEnglish sentence pair shown Figure 2. Note bilingual phrase pairs containing one wordwhole word-aligned sentence pair omitted.613fiSanchez-Martnez & ForcadaPauloestarvann nro e ulePaviues(noun.loc)a-(pr)(verb.inf)anar-(vaux.pres.3rd.pl))pl r) c)d. n -(p .lort.3 e oun(np.(vberR = {w1 =verb.*, w3 =noun.*}Figure 4: Example SpanishCatalan bilingual phrase (left), corresponding (right)obtained word replaced corresponding word class, TL restrictions (seesection 3.2) Spanish-to-Catalan translation. Words boldface correspond lexicalizedcategories (see section 3.1). Word classes horizontal axis correspond SL (Spanish)vertical axis TL (Catalan).3.1.1 Lexicalized Categoriesset (lexicalized) categories usually involved lexical changes prepositionsauxiliary verbs may provided. words whose lexical category setlexicalized categories (from on, lexicalized words) lemma also used definingword class belong to. way, lexicalized words placed single-wordclasses representing particular lexical form. example, prepositions consideredlexicalized categories, words would different word classes, evenlexical category morphological inflection information, whereas words bookhouse would word class (noun, singular).Typically set lexicalized categories subset set closed categories,is, grow addition new words lexicon: pronouns, auxiliaryverbs, prepositions, conjunctions, etc. typical lexicalized words prepositions,usually many different translations depending SL context.Figure 4 shows example SpanishCatalan bilingual phrase generalization performed word replaced corresponding word class; wordsboldface correspond lexicalized categories. shown Figure 4 generalizes,one hand, use auxiliary Catalan verb anar express past perfect(preterite) tense and, hand, preposition change refers location name, name city country. Note lexicalized words (e.g.anar-(vaux.pres.3rd.pl), en-(pr)) coexist non-lexicalized categories (e.g. (verb.inf), (noun.loc)) without distinction.3.2 Extending Definition Alignment Templatesection 2 defined tuple z = (Sm , Tn , A) alignmentSL TL word classes considered. definition extendedz = (Sm , Tn , A, R), set restrictions, R, TL inflection informationnon-lexicalized categories, added control application part transfer rule.614fiInferring Shallow-Transfer MT Rules Small Parallel Corpora(adj.m.sg)(noun.m.sg)el-(art.m.sg))g) g ).s .f.s .f.sgf.rt un dj-(a (ael (R = {w2 =noun.m.*, w3 =adj.*}Figure 5: SpanishCatalan TL restrictions inflection information Spanishto-Catalan translation (see section 3.2).3.2.1 TL Restrictionstranslating (see section 4.3.1), is, applying inferred ATs, TLinflection information non-lexicalized words taken corresponding (aligned)TL word class applied, bilingual dictionary; this,restrictions needed order prevent applied certain conditionswould produce incorrect translation.illustrate need restrictions let us consider would happentranslating Spanish phrase la silla roja 6 Catalan applying extendedshown Figure 5, applied case. generalizespropagation masculine gender article adjective translating SL(Spanish) noun feminine singular SL (same article adjective)masculine equivalent Catalan, case silla. applyingextended Figure 5, morphological generator (see Appendix A) inflectlexical form cadira-(noun.m.sg), exist Catalan,7 cadira feminine.taking account restrictions TL inflection information, onereferring w2 extended Figure 5, prevent applicationapplication would produce incorrect lexical form inflect, running example.TL restrictions obtained bilingual dictionary MT systeminferred transfer rules integrated. Bilingual dictionaries may explicitly codeinflection information translation SL lexical form, inflectioninformation changes one language other. TL restrictions could derivedkinds bilingual dictionaries; however, extraction easier secondcase, is, changes inflection information explicitly coded.experiments (see section 5) Apertium MT platform used; Apertium bilingual dictionaries, changes inflection information explicitly coded.following two examples show, one hand, SpanishCatalan bilingual entry and,hand, restriction TL inflection information Spanish-to-Catalantranslation derived bilingual entry:86. Translated English red chair.7. Note lexical category morphological inflection information TL lexical form inflecttaken TL part AT.8. Lemmas tags <l> </l> (left) correspond Spanish words; analogously, lemmastags <r> </r> (right) correspond Catalan words. Lexical category inflection informationcoded tag <s> (symbol ), first one lexical category.615fiSanchez-Martnez & ForcadaBilingual entry without change inflection information<e><p><l>castigo<s n="noun"/></l><r>castig<s n="noun"/></r></p></e>Restriction: w=noun.*Bilingual entry gender changes feminine (Spanish) masculine(Catalan)<e><p><l>calle<s n="noun"/><s n="f"/></l><r>carrer<s n="noun"/><s n="m"/></r></p></e>Restriction: w=noun.m.*seen, restrictions provide lexical category morphological inflection information lexical form translation time lookingbilingual dictionary; star end restriction means rest inflection information restricted. second bilingual entry would responsiblerestrictions attached w2 shown Figure 5. appliednoun (w2 ) masculine TL (see next section know ATs applied); noteinflection information w3 restricted all; w3 refersadjective masculine feminine, gender depends gendernoun qualifies.4. Generation Apertium Transfer Rulessection describes automatic generation Apertium structural shallow-transferrules; note, however, generation transfer rules shallow-transfer MTsystems would also feasible following approach presented here.structural transfer Apertium (see appendix A) uses finite-state pattern matchingdetect, usual left-to-right, longest-match way, fixed-length patterns lexical formsprocess performs corresponding transformations. (generic) shallow-transferrule consists sequence lexical forms detect transformations needapplied them.4.1 Discarding Useless Bilingual Phrase Pairsbilingual phrase pairs useful inference transfer rules, since generalization would performed cannot used RBMT;precisely, bilingual phrase pairs satisfying one following conditions useless,therefore, discarded:616fiInferring Shallow-Transfer MT Rules Small Parallel CorporaSL TL non-lexicalized words aligned. translating SL nonlexicalized word (see next section) inflection information taken alignedTL word class, therefore corresponding alignment must exist.bilingual phrase pair cannot reproduced MT system transfer rules used. happens translation equivalent bilingualdictionary differs one observed bilingual phrase. Note TL restrictions extracted bilingual dictionary, translation equivalentsagree extracted could end set restrictions making senseall.4.2 Selecting Alignment Templates Usedecide ATs take account generation rules, method providedfrequency count threshold. ATs whose frequency count thresholddiscarded. experiments, two different ways interpreting frequency counttested:use directly frequency count c,use modified frequency count c0 = c(1 + log(l)), l stands lengthSL part AT.second approach aims solving problem caused fact longer ATslower frequency counts may accurate take context account.similar approach used (Mikheev, 1996) work learning part-of-speechguessing rules favor longer suffixes shorter ones.4.3 Rule Generationrule consists set U extended ATs sequence SL word classes,different sequences TL word classes, different alignment information different setTL restrictions. Formally may expressed follows:U = {(Sm , Tn , A, R) Z : Sm = U },(1)Z refers whole set ATs U sequence SL word classesATs U common. Note rule matches different sequence U SL wordclasses and, therefore, ambiguity application shallow-transfer rulestranslation time.rule U coded Apertiums XML-based transfer language. code generatedrule applies always frequent U satisfies TL restrictions R;therefore, competing ATs selected according frequency. default AT,translates word word, always added lowest frequency count.TL restrictions one applied none remaining ATs appliedTL restrictions met.check restrictions TL inflection information met,translation non-lexicalized word retrieved bilingual dictionary; then,617fiSanchez-Martnez & Forcadaretrieved morphological attributes (lexical category inflection information) compared specified corresponding restriction; applicablerestrictions hold.4.3.1 Application Alignment Templatecode generated Apertiums XML-based transfer language appliesguided sequence Tn TL word classes. actions perform unit Tndepend type word class:word class corresponds non-lexicalized word, translation lemmaaligned SL (non-lexicalized) word retrieved looking bilingual dictionary; then, lexical category morphological inflection informationprovided TL word class attached translated lemma;word class corresponds lexicalized word, introduced is; rememberword classes belonging lexicalized words represent complete lexical forms consistinglemma, lexical category morphological inflection information.Note information SL lexicalized words taken account applying given (just detecting it).following example illustrates shown Figure 4 would appliedorder translate Spanish Catalan input text vivieron en Francia.9text segment, morphological analysis part-of-speech tagging, transformedMT engine SL IR vivir -(verb.pret.3rd.pl) en-(pr) Francia-(noun.loc),becomes input structural transfer module. applied orderspecified TL part. word classes corresponding non-lexicalized words,aligned SL words translated TL (Catalan) looking bilingualdictionary: vivir translated viure Francia translated Franca. Then,inflection information provided TL part (see Figure 4) attachedtranslated lemma. Finally, word classes corresponding lexicalized words copiedoutput appear TL part AT. running example structuraltransfer output would TL IR anar -(vaux.pres.3rd.pl) viure-(verb.inf) a-(pr)Franca-(noun.loc), morphological generation module would transformCatalan phrase van viure Franca.9. Translated English lived France.618fiInferring Shallow-Transfer MT Rules Small Parallel Corpora5. Experimentsapproach presented paper tested translation directionsSpanishCatalan (es-ca) SpanishGalician (es-gl) language pairs,Spanish-to-Portuguese (es-pt) translation.10,11parallel corpora used training different sources. SpanishCatalanparallel corpora come El Periodico de Catalunya,12 daily newspaper publishedCatalan Spanish; SpanishGalician parallel corpora come Diario Oficial deGalicia,13 official publication autonomous government Galicia publishedGalician Spanish; SpanishPortuguese parallel corpora come JRCAcquis Multilingual Parallel Corpus (Steinberger et al., 2006)14 contains EuropeanUnion (EU) law applicable EU member states.test importance amount parallel corpora available trainingused corpora different sizes. precisely, used training corpora around0.25, 0.5, 1.0, 1.5, 2.0 million words language. corpora builtway that, language pair, larger corpora include shorter ones. Noteword alignments computed different training corpus isolationextraction extended ATs used inference shallow-transferrules.explained section 3.1, set categories usually involved lexical changesneeds provided definition word classes learn syntactictransformations, also lexical transformations. end, small set eight tenlexicalized categories used language. common lexicalized categoriesare: prepositions, pronouns, determiners, subordinate conjunctions, relatives, modal verbsauxiliary verbs.length bilingual phrase pairs extracted used obtain ATsrestricted maximum 7 SL words experiments. Remember section 2.2extract bilingual phrases pair word-aligned sentences possible pairs(within certain length) considered; restricting length makingproblem computationally affordable.respect frequency count threshold used select set ATs takeaccount (see section 4.2), tested frequency count thresholds 5 40translation tasks selection criteria. frequency count used evaluationone giving best translation edit rate (TER; Snover et al., 2006) translatingcorpus, similar one used testing, 1 000 sentences (see Table 1); Table 5(page 627) provide thresholds used rules inferred corpus2.0 million words language.10. linguistic data used freely downloaded http://sf.net/projects/apertium, packagesapertium-es-ca-1.0.2 (around 12 800 bilingual entries), apertium-es-gl-1.0.4 (around 10 800 bilingual entries) apertium-es-pt-0.9.2 (around 11 000 bilingual entries); number bilingual entriesreported correspond lemma-based entries.11. possible criticism used standard translation task test approach;done Apertium linguistic resources (morphological bilingual dictionaries)necessary standard tasks available.12. http://www.elperiodico.com13. http://www.xunta.es/diario-oficial14. http://wt.jrc.it/lt/Acquis/619fiSanchez-Martnez & ForcadaLanguage pairsentenceses-ca1 000es-gl1 000es-pt1 000wordses: 22 583ca: 22 451es: 22 698gl: 20 970es: 23 561pt: 22 941Table 1: Number sentences number words language different corpora usedselect frequency count threshold used evaluation. threshold finally used dependstranslation task; see Table 5 page 627 know threshold usedtranslation task rules inferred parallel corpus 2.0 million wordslanguage.5.1 Evaluationperformance presented approach compared MT systemtransfer rules used (word-for-word MT), MT system using hand-coded transfer rules,15 using state-of-the-artSMT system trained using parallel corpora. latter usedfree/open-source SMT toolkit Moses (Koehn et al., 2007) SRILM language modelling toolkit (Stolcke, 2002). training SMT system done follows:16 First,translation model trained using 90% training corpus. Then, 5-gramlanguage model trained using SRILM toolkit whole training corpus. Finally, minimum error rate training algorithm (Och, 2003) used remaining 10%training corpus adjust weight feature.17 features usedSMT system used Moses default: 5 phrase-table features (source-to-targettarget-to-source phrase translation probabilities, source-to-target target-to-sourcelexical weightings, phrase penalty), distance-based cost (total number word movements), sentence word count, TL model.Translation performance evaluated using two different measures; one hand,translation edit rate (TER; Snover et al., 2006), hand, bilingualevaluation understudy (BLEU; Papineni et al., 2002); cases evaluationcorpora used confidence intervals measures reportedgiven (see below).5.1.1 Confidence intervalsConfidence intervals MT quality measures calculated bootstrap resampling method described Koehn (2004). general, bootstrap resampling methodconsists estimating precision sample statistics (in case, translation qualitymeasures) randomly resampling replacement (that is, allowing repetitions)full set samples (Efron & Tibshirani, 1994); MT, sentences respective15. corresponding Apertium language packages.16. detailed training instructions visit http://www.statmt.org/wmt09/baseline.html.17. minimum error rate training used BLEU evaluation measure.620fiInferring Shallow-Transfer MT Rules Small Parallel CorporaLanguage pairsentenceses-ca2 400es-gl2 450es-pt2 000wordses: 55 064ca: 54 730es: 55 826gl: 51 603es: 55 814pt: 53 762Table 2: Number sentences number words language different test corporaused evaluation.reference translations. method property assumptions madeunderlying distribution variable, case, MT quality measure.calculation confidence intervals consists following steps:1. translation performance evaluated large number times, experiments1 000 times, using randomly chosen sentences test corpus, counterpart sentences reference corpus;2. calculated measures sorted ascending order;3. top q% bottom q% elements removed list.that, remaining values interval [a, b]. interval approximatesprobability 1 2q/100 range values quality measure reported liestest corpora number sentences equal used carry evaluation.5.1.2 Evaluation corporaTable 2 shows number sentences number SL TL words differenttest corpora used evaluation inferred rules translation considered. test corpora come independent parallel corpora, different source,relation used training. precisely, test corpora SpanishCatalan SpanishGalician comes Revista Consumer Eroski (Alcazar, 2005),18magazine addressed consumers published Spanish, Catalan, Galician Basque;test corpora SpanishPortuguese comes shared evaluation task 2008workshop SMT.195.2 ResultsFigure 6 shows TER BLEU scores, together respective 95% confidenceintervals, achieved translation direction SpanishCatalan language pairusing training corpora different sizes. error rates reported are: (a) resultsfrequency count directly used select set ATs use rules generation,(b) results achieved state-of-the-art SMT system trained corpora, (c)18. http://revista.consumer.es19. http://www.statmt.org/wmt08/wmt08-eval.tar.gz621fiSanchez-Martnez & ForcadaCatalan (SL)... els gossos catalogats de perillosos hande tenir una asseguranca ...... es va descobrir en el cacauet ...... va tenir un infart de miocardi ...... els fonaments cientfics per considerarfuncionals diversos aliments son ...... lenveja es manifesta ...... cal preservar-lo de la llum ...Spanish (TL)... los perros catalogados de peligrososdeben tener seguro ..... se descubrio en el cacahuete ...... tuvo un infarto de miocardio ...los fundamentos cientficos para considerar funcionales varios alimentos son ...la envidia se manifiesta ...... hay que preservarlos de la luz ...Table 3: Translation examples Catalan-to-Spanish translation. translations reportedproduced using automatically inferred rules; words boldface indicate changesrespect word-for-word translation; indicates word deleted respect word-forword translation.results achieved using hand-coded transfer rules, (d) results wordfor-word translation (when structural transformations applied). results achievedmodified frequency count described section 4.2 used select set ATsuse reported since indistinguishable practice achievedusing directly frequency count; reason, considered restexperiments. Notice cases, except SMT results, linguisticdata (morphological bilingual dictionaries) used. Catalan-to-Spanishtranslations produced automatically inferred rules shown Table 3.Results Figure 6 show that, expected, translation quality achievedinferred transfer rules better word-for-word translation, even smallparallel corpus around 0.5 million words language used; note however,case Spanish-to-Catalan translation confidence intervals overlap trainingcorpus 0.25, 0.5 1.0 million words, overlap smaller latter.Results Figure 6 also show SMT system performs worse rules automatically inferred parallel corpus even worse word-for-wordtranslation. training corpora used large enough learnwide-coverage bilingual lexicon and, consequently, words translate unknown SMT system. Remember approach learns transfer rulesparallel corpus, bilingual entries, bilingual dictionary usedhand-coded rules, automatically inferred rules word-for-word translation.section 5.2.1 (page 626) discuss results achieved SMT systembilingual dictionary corresponding Apertium package added SMT trainingdata.Figure 7 shows, translation direction SpanishGalician language pair,MT quality measures translation setups reported SpanishCatalan Figure 6.SpanishGalician language pair shows results agreement obtainedSpanishCatalan; however, improvement Galician-to-Spanish translation quality,compared word-for-word translation, smaller. addition, improvement obtainedcase SpanishCatalan increasing amount corpora used training greater622fiInferring Shallow-Transfer MT Rules Small Parallel CorporaSpanish Catalan287270BLEU (% words)26TER (% words)74AT-countSMThandw4w242220186866646260AT-countSMThandw4w58165614540.25 0.511.5Millions words20.25 0.511.5Millions words2Catalan Spanish267270BLEU (% words)24TER (% words)74AT-countSMThandw4w222018686664626058AT-countSMThandw4w56165414520.25 0.511.5Millions words20.25 0.511.5Millions words2Figure 6: TER BLEU scores (vertical axis), respective 95% confidence intervals,translation direction SpanishCatalan language pair using training corporadifferent sizes (horizontal axis). AT-count refers result achieved count directlyused select set ATs use; SMT refers result achieved state-of-the-art SMTsystem trained parallel corpora; hand refers results achieved hand-codedtransfer rules used; w4w (word word) refers result achieved transfer rulesused.623fiSanchez-Martnez & ForcadaSpanish Galician267472BLEU (% words)24TER (% words)76AT-countSMThandw4w22201816706866646260AT-countSMThandw4w58145612540.25 0.511.5Millions words20.25 0.511.5Millions words2Galician Spanish247674BLEU (% words)22TER (% words)78AT-countSMThandw4w201816727068666462AT-countSMThandw4w60145812560.25 0.511.5Millions words20.25 0.511.5Millions words2Figure 7: TERs BLEU scores (vertical axis), respective 95% confidence interval,translation direction SpanishGalician language pair using training corporadifferent sizes (horizontal axis). measures reported correspond results achievedusing different MT setups (as described Figure 6).624fiInferring Shallow-Transfer MT Rules Small Parallel CorporaSpanish Portuguese706626BLEU (% words)68TER (% words)28AT-countSMThandw4w6462605824222018AT-countSMThandw4w56165452140.25 0.511.5Millions words20.25 0.511.5Millions words2Figure 8: TER BLEU scores (vertical axis), respective 95% confidence intervals,Spanishto-Portuguese translation using training corpora different sizes (horizontalaxis). measures reported correspond results achieved using different MT setups(see Figure 6).SpanishGalician, shown slope curve.significant frequent patterns learned training corpora selectedearly. Note method unlikely perform worse word-for-word translation(when rules used).Concerning Spanish-to-Portuguese translation, Figure 8 shows TER BLEUscores achieved different sizes training corpora used. Notice automaticallyinferred rules perform better word-for-word translation, although confidenceintervals show large overlap. worth mentioning confidence intervals obtainedhand-coded transfer rules also overlap automatically inferred rulesword-for-word translation. rest experiments SMT system performsworse training corpus large enough learn wide-coverage bilinguallexicon.difference results achieved using hand-coded transfer rulesusing rules (word-for-word translation) small compared resttranslation tasks considered paper. Moreover, TER BLEU scores obtainedpoor although Spanish Portuguese two related languages, and, therefore,translating difficult task. Indeed, evaluationhand-coded transfer rules performed using evaluation corpus referencetranslation post-edited (corrected) version MT output producedhand-coded rules shows TER 10%.poor results obtained Spanish-to-Portuguese may explained factevaluation corpus, well training corpora used, may builttranslating one language (say Spanish Portuguese) other, translating625fiSanchez-Martnez & Forcadaes-caca-eses-glgl-eses-ptAT-countTEROOV (%)[15.8, 16.7]4.3%[15.0, 15.9]4.9%[14.7, 15.6]9.3%[13.9, 14.7]10.2%[54.2, 56.0]3.8%SMT+dictionaryTEROOV (%)[18.0, 19.0]3.4%[15.5, 16.4]3.8%[16.2, 17.1]6.9%[13.6, 14.4]8.2%[57.2, 59.0]3.1%SMTTEROOV (%)[20.1, 21.2]5.7%[17.7, 18.7]6.1%[19.1, 20.0]18.7%[18.0, 18.8]21.1%[62.4, 64.1]12.6%Table 4: 95% confidence intervals TER ratio out-of-vocabulary (OOV) wordstest corpus translated: rules automatically obtained parallel corpora (AT-count),SMT system trained parallel corpora (SMT), SMT system trainedparallel corpora plus corresponding Apertium bilingual dictionary (SMT+dictionary).data reported correspond case training corpus 2.0 million wordslanguage.third language (possibly English French).20 causes reference translationdifferent compared translations automatically performed, thus givinghigh TERs. hand, may also cause alignments obtainedtraining corpora unreliable, shown percentage discarded bilingual phrasepairs. percentage is, training corpora, around 54% Spanish-to-Portuguesetranslation, 22% SpanishCatalan language pairs, around 20%SpanishGalician language pair.5.2.1 Adding bilingual dictionary SMT training dataaim testing whether difference translation performanceshallow-transfer rules SMT system due fact Apertium useswide-coverage, manually-built bilingual dictionary, added bilingual dictionarycorresponding Apertium package SMT training data (Tyers et al., 2009).21worth noting adding bilingual dictionary training corpusimprove vocabulary coverage SMT systems inferred, also helps wordalignment process adding word-to-word alignment, gives additional advantageSMT system respect systems; bilingual dictionary addedcorpus used learn used automatic inference shallow-transfer rules.Table 4 shows 95% confidence intervals TER ratio out-of-vocabulary(OOV) words test corpus translated means Apertium shallowtransfer rules automatically obtained form parallel corpus 2.0 million wordslanguage (AT-count); translated using SMT system trainedparallel corpus (SMT); and, translated SMT system trained par20. Remember training corpora contains European Union law evaluation corpus comesEuropean Parliament proceedings.21. Apertium bilingual dictionaries contain lemma-based bilingual entries expandedinclude possible inflected forms adding SMT training data. inflectinglemma-based bilingual entries bilingual dictionary added SMT training data consists(approximately) 1.8 million entries SpanishCatalan, 1.2 million entries SpanishGalician,0.9 million entries SpanishPortuguese.626fiInferring Shallow-Transfer MT Rules Small Parallel Corporaes-caca-eses-glgl-eses-ptfreq.count81413625numberrules32 16517 93014 76428 5735 402rulesused8 1336 7853 7774 8982 636% used25.3%37.8%25.6%17.1%48.8%% performingword-for-word2.77%2.08%1.16%1.51%1.18%Table 5: translation task, following data shown: frequency count thresholdused, number rules generated, number (and percentage rules) usedtranslation corresponding evaluation corpus, percentage rule applications endperforming word-for-word translation. data reported correspond rules obtainedtraining corpora 2.0 million words language.allel corpus containing original corpus 2.0 million words language pluscorresponding Apertium bilingual dictionary (SMT+dictionary).results Table 4 show that, expected, SMT results improvebilingual dictionary added training corpus; note however, results obtainedes-ca, ca-es, es-gl, es-pt still worse achieved automaticallyinferred rules, although ca-es SMT+dictionary confidence interval shows largeoverlap automatically inferred rules. translation taskSMT+dictionary system provides better results automatically inferred rulesgl-es task, although confidence interval overlaps automaticallyinferred rules. cases ratio OOV words SMT+dictionaryautomatically inferred rules words present bilingual dictionaryappear training corpus.5.2.2 Analysis inferred rulesTable 5 shows, translation task, frequency count threshold used generation rules, number rules obtained number usedtranslation corresponding evaluation corpus; remember frequency countthreshold used translation task one minimizing TER translatingcorpora described Table 1. data reported Table 5 correspond rules inferredlargest training corpora (2.0 million word language). Note numberinferred rules varies depending translation task; instance, number ruleses-ca around twice number rules ca-es, produceminimum TER less rules happen needed case ca-es.data Table 5 reveal, one hand, percentage rules finally usedtranslate corresponding evaluation corpus varies depending translation task,and, hand, percentage rules end applying default(which performs word-for-word translation, see section 4) depends translationtask, although always 3%.Figure 9 shows Spanish-to-Catalan translation, top, number rulesobtained number rules used translation evaluation corpus,627fiSanchez-Martnez & Forcadagrouped rule length (number SL word classes); and, bottom, numberrule applications number rule applications end performing word-forword translation (apply default AT); generation rules frequency countthreshold 8 used. Notice rules unit length, i.e. rules processsingle SL word class: needed bilingual dictionary leavestranslation decisions open, gender number wordsmasculine feminine, singular plural, TL. data figurecorrespond rules inferred form largest training corpora used; case,rest training corpora, similar behaviour obtained; happensremaining translation tasks.Figure 9 shows rules generated process SL patterns 3 4 wordclasses; number rules processing 7 SL word classes low. Rememberextraction bilingual phrase pairs length restricted 7 SL words.Finally, worth mentioning number inferred rules high comparednumber hand-coded rules. Note, however, automatically inferred rulesspecific lexicalized hand-coded ones. Hand-coded rules use macros complexcontrol flow statements allow treat phenomena rule.6. Discussionpaper focused inference structural transfer rules used MT,precisely inference shallow-transfer rules. describes extendapproach introduced SMT framework order use generate shallow-transferrules used RBMT. end, small amount linguistic information,addition linguistic data used MT engine, used order learnsyntactic changes, also lexical changes apply translating SL texts TL.linguistic information consists small set lexical categories involved lexicalchanges (prepositions, pronouns, etc.) easily provided expert.approach tested using data three existing language pairsfree/open-source shallow-transfer MT engine Apertium; precisely, presented approach tested translation directions SpanishCatalan SpanishGalician languages pairs, Spanish-to-Portuguese translation. languagepair, training corpora different sizes used test importancesize training corpora available.evaluation done, cases, using independent parallel corpora, comingindependent source, relation parallel corpora used training.evaluation translation quality achieved automatically inferred rulescompared using hand-coded shallow-transfer rules, word-for-wordtranslation, using state-of-the-art SMT system trained parallelcorpora. cases automatically inferred rules perform better SMT system;moreover, Apertium bilingual dictionary added SMT training dataone translation task performed slightly better automatically inferred rules. Noticeapproach, unlike Caseli et al. (2006), aimed learning shallow-transferrules, bilingual entries, used bilingual dictionary providedcorresponding Apertium language-pair package.628fiInferring Shallow-Transfer MT Rules Small Parallel CorporaRules generated actually used test corpus12000rules generatedrules usedNumber rules1000080006000400020000123456Rule length (number SL word classes)7Rule applications applications end word word test corpus7000rule applicationsrules perform word-for-word6000Number rules500040003000200010000123456Rule length (number SL word classes)7Figure 9: Spanish-to-Catalan translation, rules generated used translationcorresponding evaluation corpus (top), number rule applications numberapplications end performing word-for-word translation (bottom). Reported datagrouped rule length (number SL word classes).629fiSanchez-Martnez & Forcadaevaluation inferred rules translation directions SpanishCatalan SpanishGalician language pairs show improvement translationquality compared word-for-word translation, even small parallel corpusused. case Spanish-to-Portuguese translation, small improvement: confidence intervals show large overlap.knowledge, first time approach extended useRBMT; important property inferred rules edited humanexperts improve them. means developers RBMT systems usemethod obtain set initial transfer rules refined linguists;proceeding way, human experts focus difficult issues writingaccurate transfer rules MT, required rules automatically obtainedparallel corpora. point view, great advantage corpusbased approaches MT, SMT, because, approach, automatically generatedrules coexist hand-coded ones.respect parallel corpus used training, results achieved inferredrules Spanish-to-Portuguese translation show procedure followed buildparallel corpus, is, way translation one languageone performed, deserves special attention. opinion, may concludedparallel corpora built translating third language mayappropriate task inferring rules used RBMT, especially languagesinvolved closely related third language not.must mentioned software implementing method described paperreleased free/open-source software GNU GPL license22 freelydownloaded http://apertium.sf.net, package name apertium-transfer-tools.public availability source code ensures reproducibility experimentsconducted allows researchers improve approach discussed here, savingimplement algorithms again. addition, methodimplemented way integrates Apertium free/open-sourceMT platform (see appendix A); benefits, one hand, research usesApertium research platform, hand, people developing new languagepairs Apertium.plan improve generated rules using linguistic criteria extractionbilingual phrase pairs generalized ATs. Note experimentsreported paper bilingual phrase pairs extracted training corpus withoutworrying whether well-formed syntactic constituents not. also plan studyuse lexicalized categories flexible way. would interestcontext-dependent lexicalized categories, is, categories lexicalizedcontexts, others; would improve generalization performedextended ATs reduce number inferred rules.Another improvement plan achieve extension present approachrules translation less-related language pairs inferred. Recently,transfer Apertium extended translate divergent languagessplitting structural transference phase 3 stages: first one detects word patterns22. http://www.gnu.org/licenses/gpl-2.0.html630fiInferring Shallow-Transfer MT Rules Small Parallel Corporalexicaltransferlpostmorph.part-of-speechmorph.struct.SLTLgeneratoranalyzertaggergeneratortransfertexttextFigure 10: Main modules free/open-source shallow-transfer MT engine Apertium usedexperiments (see appendix A).called chunks; second one operates sequences chunks; finally, third one makesfinishing operations within chunks detected first stage. approachcould extended detecting chunks training parallel corpus using linguistic criteriamentioned previous paragraph, using Marker Hypothesis (Green, 1979),done Gough Way (2004), extracting ATs based chunk classes insteadword classes, done now. case, would worth testing methodpresent translation less-related languages using longer ATs largertraining corpora.AcknowledgmentsWork funded Spanish Ministry Education Science European Social Fund research grant BES-2004-4711, Spanish Ministry Industry,Tourism Commerce projects TIC2003-08681-C02-01, FIT340101-2004-3FIT-350401-2006-5, Spanish Ministry Education Science projectTIN2006-15071-C03-01. authors thank anonymous referees suggesting significant improvements paper Francis Tyers proof-reading it.Appendix A. Apertium Machine Translation Platformappendix briefly describes free/open-source shallow-transfer MT engine Apertium23 (Armentano-Oller et al., 2006) used experiments. Apertium followsshallow-transfer approach shown Figure 10:morphological analyzer tokenizes text surface forms delivers,surface form, one lexical forms consisting lemma, lexical categorymorphological inflection information.part-of-speech tagger (categorial disambiguator) chooses, using first-orderhidden Markov model (Cutting et al., 1992; Baum & Petrie, 1966), one lexicalforms corresponding ambiguous surface form.lexical transfer module reads SL lexical form delivers corresponding TL lexical form looking bilingual dictionary.23. MT engine, documentation, linguistic data different language pairs downloadedhttp://apertium.sf.net.631fiSanchez-Martnez & Forcadastructural transfer module (parallel lexical transfer) uses finite-statechunker detect patterns, articlenounadjective, lexical formsneed processed word reorderings, agreement, etc., performsoperations. module applies structural transfer rules automaticallyinferred parallel corpora using method paper.morphological generator delivers TL surface form TL lexical form,suitably inflecting it.post-generator performs orthographic operations contractions (e.g.Spanish de+el del ) apostrophations (e.g. Catalan el+institut linstitut).Apertium MT engine completely independent linguistic data usedtranslate given language pair. Linguistic data coded using XML-based formats,24allows easy data transformation maintenance.ReferencesAlcazar, A. (2005). Towards linguistically searchable text. Proceedings BIDE (BilbaoDeusto) Summer School Linguistics 2005, Bilbao. Universidad de Deusto.Armentano-Oller, C., Carrasco, R. C., CorbA-Bellot, A. M., Forcada, M. L., Ginest-Rosell,M., Ortiz-Rojas, S., Perez-Ortiz, J. A., Ramrez-Sanchez, G., Sanchez-Martnez, F., &Scalco, M. A. (2006). Open-source Portuguese-Spanish machine translation. Computational Processing Portuguese Language, Proceedings 7th InternationalWorkshop Computational Processing Written Spoken Portuguese, PROPOR2006, Vol. 3960 Lecture Notes Computer Science, pp. 5059. Springer-Verlag.Arnold, D. (2003). translation difficult computers. Computers Translation:translators guide. Benjamins Translation Library.Baum, L. E., & Petrie, T. (1966). Statistical inference probabilistic functions finitestate Markov chains. Annals Mathematical Statistics, 37 (6), 15541563.Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., & Mercer, R. L. (1993). mathematicsstatistical machine translation: Parameter estimation. Computational Linguistics,19 (2), 263311.Brown, R. D. (1999). Adding linguistic knowledge lexical example-based translationsystem. Proceedings Eighth International Conference TheoreticalMethodological Issues Machine Translation (TMI-99), pp. 2232.Carl, M., & Way, A. (Eds.). (2003). Recent Advances Example-Based Machine Translation, Vol. 21. Springer.Caseli, H. M., Nunes, M. G. V., & Forcada, M. L. (2005). LIHLA: lexical aligner basedlanguage-independent heuristics. Anais V Encontro Nacional de InteligAa nciaArtificial (ENIA 2005), pp. 641650.24. XML formats (http://www.w3.org/XML/) type linguistic data definedconveniently-designed XML document-type definitions (DTDs) may found inside Apertiumpackage.632fiInferring Shallow-Transfer MT Rules Small Parallel CorporaCaseli, H. M., Nunes, M. G. V., & Forcada, M. L. (2006). Automatic induction bilingual resources aligned parallel corpora: application shallow-transfer machinetranslation. Machine Translation, 20 (4), 227245. Published 2008.Cicekli, I., & Guvenir, H. A. (2001). Learning translation templates bilingual translation examples. Applied Intelligence, 15 (1), 5776.Cutting, D., Kupiec, J., Pedersen, J., & Sibun, P. (1992). practical part-of-speech tagger. Proceedings Third Conference Applied Natural Language Processing.Association Computational Linguistics, pp. 133140.Efron, B., & Tibshirani, R. J. (1994). introduction Bootstrap. CRC Press.Gough, N., & Way, A. (2004). Robust large-scale EBMT marker-based segmentation.Proceedings 10th International Conference Theoretical MethodologicalIssues Machine Translation, pp. 95104, Baltimore, MD.Green, T. (1979). necessity syntax markers. Two experiments artificial languages. Journal Verbal Learning Behavior, 18, 481496.Hutchins, W. J., & Somers, H. L. (1992). Introduction Machine Translation. AcademicPress.Kaji, H., Kida, Y., & Morimoto, Y. (1992). Learning translation templates bilingualtext. Proceedings 14th Conference Computational Linguistics, pp. 672678. Association Computational Linguistics.Knight, K. (1999). statistical machine translation tutorial workbook. 35 pages. (http://www.isi.edu/natural-language/mt/wkbk.rtf).Koehn, P. (2004). Statistical significance tests machine translation evaluation. Proceedings Conference Empirical Methods Natural Language Processing, pp.388395.Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B.,Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., & Herbst, E.(2007). Moses: Open source toolkit statistical machine translation. Proceedings Annual Meeting Association Computational Linguistics (ACL),demonstration session.Lavie, A., Probst, K., Peterson, E., Vogel, S., Levin, L., Font-Llitjos, A., & Carbonell,J. (2004). trainable transfer-based machine translation approach languageslimited resources. Proceedings Workshop European AssociationMachine Translation (EAMT-2004).Liu, Y., & Zong, C. (2004). technical analysis translation templates. ProceedingsIEEE International Conference Systems, Man & Cybernetics (SMC), pp.47994803. IEEE.Menezes, A., & Richardson, S. D. (2001). best-first alignment algorithm automaticextraction transfer mappings bilingual corpora. Proceedings ACLWorkshop data-driven machine translation, pp. 3946.633fiSanchez-Martnez & ForcadaMikheev, A. (1996). Unsupervised learning word-category guessing rules. ProceedingsThirty-Fourth Annual Meeting Association Computational Linguistics,pp. 327333.Nagao, M. (1984). framework mechanical translation English Japaneseanalogy principle. Elithorn, A., & Banerji, R. (Eds.), Artifical HumanIntelligence, pp. 173180. North-Holland.Och, F. J. (1999). efficient method determining bilingual word classes. EACL99:Ninth Conference European Chapter Association Computational Lingustics, pp. 7176.Och, F. J. (2002). Statistical machine translation: single-word models alignmenttemplates. Ph.D. thesis, RWTH Aachen University. (http://www-i6.informatik.rwth-aachen.de/publications/download/520/Och--2002.pdf).Och, F. J. (2003). Minimum error rate training statistical machine translation.41st Annual Meeting Association Computational Linguistics, pp. 160167,Sapporo, Japan.Och, F. J. (2005). Statistical machine translation: Foundations recent advances. TutorialMT Summit X. (http://www.mt-archive.info/MTS-2005-Och.pdf).Och, F. J., & Ney, H. (2002). Discriminative training maximum entropy modelsstatistical machine translation. Proceedings 40th Annual MeetingAssociation Computational Lingustics (ACL), pp. 295302.Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignmentmodels. Computational Linguistics, 29 (1), 1951.Och, F. J., & Ney, H. (2004). alignment template approach statistical machinetranslation. Computational Linguistics, 30 (4), 417449.Papineni, K., Roukos, S., Ward, T., & Zhu, W. J. (2002). BLEU: method automatic evaluation machine translation. Proceeding 40th Annual meetingAssociation Computational Linguistics, pp. 311318.Probst, K., Levin, L., Peterson, E., Lavie, A., & Carbonell, J. (2002). MT minoritylanguages using elicitation-based learning syntactic transfer rules. Machine Translation, 17 (4), 245270.Sanchez-Martnez, F., & Forcada, M. L. (2007). Automatic induction shallow-transferrules open-source machine translation. Proceedings 11th ConferenceTheoretical Methodological Issues Machine Translation (TMI 2007), pp. 181190.Sanchez-Martnez, F., & Ney, H. (2006). Using alignment templates infer shallow-transfermachine translation rules. Lecture Notes Computer Science 4139, ProceedingsFinTAL, 5th International Conference Natural Language Processing, pp. 756767.Sanchez-Martnez, F., Perez-Ortiz, J. A., & Forcada, M. L. (2008). Using target-languageinformation train part-of-speech taggers machine translation. Machine Translation, 22 (1-2), 2966.634fiInferring Shallow-Transfer MT Rules Small Parallel CorporaSimoes, A., & Almeida, J. (2003). NATools - statistical word aligner workbench. Procesamiento del Lenguaje Natural, 31, 217224.Snover, M., Dorr, B., Schwartz, R., Micciulla, L., & Makhoul, J. (2006). study translation edit rate targeted human annotation. Proceedings 7th ConferenceAssociation Machine Translation Americas, Visions FutureMachine Translation, pp. 223231, Cambridge, MA, USA.Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., Tufis, D., & Varga, D.(2006). JRC-Acquis: multilingual aligned parallel corpus 20+ languages.Proceedings 5th International Conference Language Resources Evaluation (LREC).Stolcke, A. (2002). SRILM extensible language modeling toolkit. ProceedingsInternational Conference Spoken Language Processing, pp. 901904, Denver, CO.Tyers, F. M., Dugast, L., & Park, J. (2009). Rule-based augmentation training dataBretonFrench statistical machine translation. Proceedings 13th AnnualConference European Associtation Machine Translation, Barcelona, Spain.press.Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation. COLING 96: 16th International Conference Computational Linguistics, pp. 836841.Zens, R., Och, F. J., & Ney, H. (2002). Phrase-based statistical machine translation. KI2002: Advances Artificial Intelligence: Proceedings 25th Annual German ConferenceAI, Vol. 2479 Lecture Notes Computer Science, pp. 1832. Springer-Verlag.635fiJournal Artificial Intelligence Research 34 (2009) 757821Submitted 11/08; published 04/09Conservative Inference RuleUncertain Reasoning IncompletenessMarco Zaffalonzaffalon@idsia.chGalleria 2IDSIACH-6928 Manno (Lugano), SwitzerlandEnrique Mirandamirandaenrique@uniovi.esDepartment Statistics Operations ResearchUniversity OviedoC-Calvo Sotelo, s/n33007 Oviedo, SpainAbstractpaper formulate problem inference incomplete informationgeneral terms. includes modelling process responsible incompleteness,call incompleteness process. allow process behaviour partlyunknown. use Walleys theory coherent lower previsions, generalisationBayesian theory imprecision, derive rule update beliefs incompletenesslogically follows assumptions, call conservative inference rule.rule remarkable properties: abstract rule update beliefsapplied situation domain; gives us opportunity neither optimisticpessimistic incompleteness process, necessary conditiondraw reliable strong enough conclusions; coherent rule, sensecannot lead inconsistencies. give examples show new rule appliedexpert systems, parametric statistical inference, pattern classification,discuss generally view incompleteness processes defended wellconsequences.1. Introductionconsider general inference problem: want draw conclusions Zobservation facts . Z variables related, senseobserving value may change beliefs value z targetvariable Z assumes Z.1Although apparently simple, setting already captures main featuresmany important problems, making inference expert systems, learning valuesstatistical parameters data, learning data classify new objectsone set preestablished categories (i.e., so-called pattern classification),others.1. Throughout paper, shall maintain convention using capital letters variables, corresponding calligraphic letters spaces possibilities, lower-case letters elementsspaces.c2009AI Access Foundation. rights reserved.fiZaffalon & Miranda(V )isit AsiaSmo(K)ing+?Tu(B)erculosisLung cance(R)Bronc(H)itis+B (O)r R+s=Abnorma(L) X-raysDyspne(A)Figure 1: Bayesian network called Asia. letters parentheses denote variablescorresponding nodes. variable, say X, binary states x0yes x00 no.Let us make concrete help graphical language Bayesiannetworks (Pearl, 1988):2 consider well-known Asia net displayed Figure 1,intended model artificial medical problem. nodes Bayesian networkvariables arcs model probabilistic dependencies them; node holdsprobability distribution node given joint state parent nodes.probabilities making distributions also called parameters network.Now, assume network (both graph parameters) provideddomain expert, field expert systems. Say networkused diagnosing lung cancer; case R target node others usedpredict value R. Therefore case Z corresponds R vector(V, K, B, H, O, L, A). another situation, may want infer parametersdata. example, denote chance tuberculosis conditionalrecent visit Asia, say sample joint values B Vwish infer value . problem so-called parametric inference,Z corresponds sample D. Finally, say goal use Asianet learn data diagnose lung cancer, i.e., predict state Rnext patient see, characterise vector (V, K, B, H, O, L, A). case2. results present paper restricted case Bayesian networks, sinceapplied Bayesian networks, often use convey intuition easily.758fiConservative Inference Ruleneed collect, data set D, values variables networkpast patients. data set exploited infer parameters Asia net,used classification predicting value R case expert systems.Therefore, focus pattern classification, Z corresponds so-called classvariable, namely R, tuple (D, V, K, B, H, O, L, A).common feature previous examples observing usefulinferring Z, indeed reason introduced model.subtle point observing important realise: often,observation fact coincide fact itself. example, considerAsia network, focusing problem parametric inference: case, may wellhappen make mistakes collecting values B V sample; mightinstance mix yes values values. useful regard situationrelated two levels information: latent level actual sample recordsright values variables, manifest level observed sample, relatedto, necessarily coincide actual sample, going usedinference. exploit paradigm based latent manifest levelgenerally powerful conceptual tool. instance, use Asia networkexpert system, may case certain patient characterised vectorvalues (v 0 , k 00 , b00 , h00 , o0 , l0 , a0 ), possible access values variables HA. Therefore observation characteristics patient (?, ?, ?, h00 , ?, ?, a0 ),denote symbol missing value question mark. Again, thinkformer vector latent latter manifest. generally speaking, ideaunderlying present discussion devices use observe , whateverare, may let us see exactly is.order account problem, explicitly model observationnew variable W , taking values finite set W possible observations. call Wobservation . previous terminology, W manifest variable latentone. words, regard W output process observing facts,called observational process paper (other authors call measurementprocess). think many different types observational processes. paperrestrict attention special case observational processes called incompletenessprocesses (IPs). IPs processes lead set-valued observations coarsening facts.special case IPs missingness processes, i.e., turn factsentire possibility space.example, process prevented variables observedexpert system case coarsening process: turned fact (v 0 , k 00 , b00 , h00 , o0 , l0 , a0 )observation (?, ?, ?, h00 , ?, ?, a0 ), regarded set 25 completevectors obtained replacing question marks values unobserved variablespossible ways. hand, take fact considerationsingle variable, say V , process makes V observed missingnessprocess writing question mark equivalent writing entire possibility spacevariable.33. IPs makes sense introduce additional variable W even incompleteobservations possibility space ; case Asia net, happens759fiZaffalon & MirandaMissing coarsened data indeed commonplace expert systems,evidence inference task based usually incomplete. arisefrequently also many fields; data mining, mention one, missing datapervasive problem applications well important theoretical area research.words, challenges posed IPs widespread. also means problemincomplete information appears fundamental component general taskuncertain reasoning; conceptually deep leads complicated problems practice.Moreover, powerful theoretical tools general task uncertainreasoning, Bayes rule generalisations, tools uncertainreasoning incompleteness general case. Currently, popular approachbased assumption IP produces incompleteness coarsening factsrandom, means non-selectively. assumption models non-selectivenesscalled coarsening random (or CAR, see Gill et al., 1997), missing random (orMAR, see Little & Rubin, 1987) special case missingness processes (see also Jaeger,2008). CAR implies incompleteness non-informative ignored; thuscreates formal basis applying methods developed complete informationincomplete case. example, assume vector (?, ?, ?, h00 , ?, ?, a0 )created CAR IP, allowed infer value R sole basis subvector (h00 , a0 ); precisely, aim computing posterior probability R = r0 ,CAR allows us write P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) = P (R = r0 |H = h00 , = a0 ).case general.fact, incompleteness may well informative. example, Asia network,may case information whether person Asiaprovided frequency two groups. example incompletenessgenerated within communication protocol, giving information keypart communication. somewhat selective way reporting information, albeitfrequent, compatible CAR assumption. pointed long agoShafer (1985), also outlined implications well complicationsuncertain reasoning: among these, fact modelling IPs difficult task.recently, used argue frequent use CAR (Grunwald &Halpern, 2003); large agreement scientific community CARstrong, hence inappropriate many situations (see Manski, 2003).De Cooman Zaffalon (2004) tried remedy approach IPs alternativeCAR based coherent lower previsions (Walley, 1991), i.e., closed convex setsprobabilities also called credal sets Levi (1980). led rule updatingbeliefs incomplete information expert systems called conservative updating rule(CUR).regard CAR optimistic approach incomplete information, CURregarded pessimistic: assume nearly anythingIP, practice leads inference based working set factsconsistent (i.e., completions of) incomplete information hand.previous example wish compute posterior probability R = r0 ,CUR leads us consider 25 completions vector (?, ?, ?, h00 , ?, ?, a0 ), i.e.,symbol ? possible value variable; observations contain question marks mustnecessarily possibility space W .760fiConservative Inference Rule(v, k, b, h00 , o, l, a0 ), v V, k K, b B, O, l L, computeP (r0 |v, k, b, h00 , o, l, a0 ). posterior inference summarised lowerupper probabilities P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) := minv,k,b,o,l P (r0 |v, k, b, h00 , o, l, a0 )P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) := maxv,k,b,o,l P (r0 |v, k, b, h00 , o, l, a0 ). words,inference imprecise, i.e., width interval determined lower upper probabilities need zero, logical consequence ignorance CURassumes IP. interesting side remark, CUR flexible CAR dealingincomplete data: eventually lead conclusions dependvariable. W variable certain point derivation cancels out.CUR drawbacks. forces us always assume ignorance IP, evenknow process CAR, instance. could case previousexample might know variables B, O, L subject CAR IP;using CUR obliged ignore information take completions,above; would lead inference much weak. Furthermore, CURdeveloped expert systems only. cannot applied parametric inferenceparameter space infinite, limitation assumptions leadingCUR may sometimes prevent applied generally.paper attempt get best CAR CUR. assume IPactually made two parts, one acts CAR process another unknownus. use theory coherent lower previsions derive corresponding rule,call conservative inference rule (CIR).CIR following properties:Much like traditional, CAR-based, updating, unlike CUR, ruleabstract task updating beliefs basis observations. such,applied every situation. CIR, different applications follow simply givingdifferent meanings facts , observations W , quantity Zinterested.CIR allows variables involved analysis, except W , take valuesinfinite spaces (CUR allows finite spaces). allows us easily focusstatistical problems goal inference often value continuousparameter, problems also use auxiliary continuous variableslater marginalised build model.deal incomplete observations, missing ones CUR.Finally, importantly, CIR shown lead self-consistent (or coherent) inferencestrong sense Walley (1991, Section 7.1.4(b)).CIR leads treat information made incomplete CAR IP similarly traditional updating, subject unknown one similarly CUR. example, consider vector (?, ?, ?, h00 , ?, ?, a0 ) assuming variables B, O, L subjectCAR IP V, K IP whose behaviour unknown us. CIR leads followingposterior lower upper probabilities R = r0 : P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) :=minv,k P (r0 |v, k, h00 , a0 ) P (R = r0 |W = (?, ?, ?, h00 , ?, ?, a0 )) := maxv,k P (r0 |v, k, h00 , a0 ).If, addition, know two completions V, K make sense, say (v 0 , k 00 )761fiZaffalon & Miranda(v 00 , k 0 ) (this means unknown IP coarsening rather missingness process),ability CIR deal coarsening processes allows take advantageinformation, leading informative lower upper probabilities obtained optimising two completions. Furthermore, CIR leads inference based,predecessors, facts, W variable.organisation material paper follows attept make paper accessible also readers prefer go formal proofs behind CIR.particular, paper logically divided two parts. first part, includingSection 5, intended describe obtained CIR scope application. Therefore part briefly gives introductory material needed defineCIR, notions coherent lower previsions Section 2 incompletenessprocesses Section 3. definition CIR given Section 4. discuss significance compare CUR Section 4.1. show CIR appliedprobabilistic expert systems (Section 5.1), parametric inference (Section 5.2), patternclassification (Section 5.3), time giving also example. first part also discuss number properties consequences wider view IPs defending(e.g., Sections 5.2.25.2.3). (Section 5.3.2) particularly importantdata mining; depends fact usually possible learnIP data, yet inferences may critically depend it.second part paper technical works foundations CIR.aim, first give advanced notions coherent lower previsions Section 6,updating, independence, coherence sense Walley (1991).state number probabilistic assumptions Section 7.1, including CAR, discussSection 7.2 (CAR also discussed Appendix A) derive CIR Section 7.3.parts even technical, needed show applying CIRcannot lead inconsistencies, relegated Appendix B.2. Coherent Lower Previsionsgive short introduction concepts results behavioural theoryimprecise probabilities shall need introduce conservative inference rule.refer reader work Walley (1991) in-depth study coherent lowerprevisions, paper Miranda (2008) survey theory.Consider possibility space . may represent instance set possible outcomesexperiment. theory coherent lower previsions, beliefslikelihood outcomes represented means lower previsions gambles :Definition 1 Given possibility space , gamble bounded real-valued function. set gambles denoted L(). lower prevision P real functionaldefined set gambles K L().gamble f represents random reward, depends priori unknown value. lower prevision P set gambles K represents subjects supremum acceptablebuying prices gambles, sense > 0 f K, subjectdisposed accept uncertain reward f P (f ) + , P (f ) also seen762fiConservative Inference Ruleconstant gambles identically equal real values P (f ) , respectively.4Intuitively, lower previsions represent lower expectations gambles: subjectdisposed buy gamble anything smaller expected reward; however, lackknowledge probability different rewards may enable givelower bound expectation, accepting buying price smaller bound.bound lower prevision gamble.shall use IA denote special type gamble: indicator function set A,i.e., function whose value 1 elements 0 elsewhere. shall sometimesuse notation P (A) lower prevision P (IA ) confusion possible.Consider variables X1 , . . . , Xn , taking values sets X1 , . . . , Xn , respectively.subset J {1, . . . , n} shall denote XJ (new) variableXJ := (Xj )jJ ,takes values product spaceXJ := jJ Xj .shall also use notation X n X{1,...,n} . identify possibility spaceX n.Definition 2 Let J subset {1, . . . , n}, let J : X n XJ so-calledprojection operator, i.e., operator drops elements vector X ncorrespond indexes J. gamble f X n called XJ -measurablex, X n , J (x) = J (y) implies f (x) = f (y). shall denote KJ setXJ -measurable gambles.notion means value f takes depends components x X nbelong set J.5one-to-one correspondence XJ -measurable gambles X ngambles XJ : given XJ -measurable gamble f X n , define f 0 XJf 0 (x) := f (x0 ), x0 element J1 (x); conversely, given gamble g XJ ,gamble g 0 X n given g 0 (x) := g(J (x)) XJ -measurable.Let subset {1, . . . , n}, let P (XO ) lower prevision set KOXO -measurable gambles. say P coherent following threeconditions hold f, g KO , > 0:(C1) P (f ) inf f .(C2) P (f ) = P (f ).4. say gamble f P (f ) + desirable subject, f P (f ) almostdesirable. follows interpretation set desirable (resp., almost-desirable) gamblesclosed addition multiplication non-negative reals, gamble fdominates desirable gamble g also desirable (resp., almost-desirable).5. notion related common notion measurability implies gamble f : X n Rindeed measurable mapping consider -field {J1 (A) : XJ } initial space-field final space.763fiZaffalon & Miranda(C3) P (f + g) P (f ) + P (g).Coherence means subject cannot raise lower prevision P (f ) gambleconsidering acceptable buying transactions implied gamblesdomain.Remark 1 (Coherent upper previsions) Although paper shall workcoherent lower previsions, supremum acceptable buying prices, shall also usetimes so-called coherent upper previsions. upper prevision gamble f , P (f ),represents infimum acceptable selling price f subject, sense> 0 transaction P (f ) f + desirable him.Taking account interpretation, follows upper lower previsionsmust conjugate functions, sense P (f ) = P (f ) gambles f .shall work almost exclusively lower previsions, use upper previsionsrefer conjugate functions helps simplify notation. Finally,say upper prevision coherent conjugate lower prevision.important point introduce particular case coherent lower previsionsspecial interest us: linear previsions.Definition 3 lower prevision P (XO ) set KO linear coherentP (f + g) = P (f ) + P (g) f, g KO .Linear previsions correspond case subjects supremum acceptable buyingprice (lower prevision) coincides infimum acceptable selling price (or upper prevision) every gamble domain. coherent lower prevision P (XO ) linear,denote P (XO ). linear prevision corresponds expectation operator (withrespect Dunford integral, see book Bhaskara Rao & Bhaskara Rao, 1983)respect finitely additive probability.One interesting feature linear previsions allows us easily characterise coherence.Definition 4 P (XO ) said dominate P (XO ) P (f ) P (f ) every XO -measurablegamble f .lower prevision P (XO ) coherent lower envelope closed6convex7 set dominating linear previsions, denote M(P (XO )). followsalso P (XO ) lower envelope set extreme points M(P (XO )). denoteset extreme points M(P (XO )) ext(M(P (XO )).Example 1 Assume subject information outcome variablesXO belongs finite subset XO , nothing more. modelbeliefs so-called vacuous lower prevision P (XO ) given P (f ) := minA f ()every f KO . set M(P (XO )) dominating linear previsions corresponds6. weak* topology, smallest topology evaluation functionals givenf (P ) := P (f ), f L(), continuous.7. is, linear previsions P1 , P2 set (0, 1), linear prevision P1 + (1 )P2also belongs set.764fiConservative Inference Rulefinitely additive probabilities P (XO ) satisfying constraint P (A) = 1. Among these,extreme points degenerate probability measures respect A,follows linear prevision M(P (XO )) convex combination these.Consider two disjoint subsets O, {1, . . . , n}, 6= . P (XO |XI ) representssubjects behavioural dispositions gambles depend outcomevariables {Xk , k O}, coming know outcome variables {Xk , k I}.such, defined set gambles depend values variablesonly,8 i.e., set KOI XOI -measurable gambles X n . Given gamble fx XI , P (f |XI = x) represents subjects supremum acceptable buying pricegamble f , came know variable XI took value x (and nothing else).thus consider gamble P (f |XI ) XI , x XI takes value P (f |XI = x).Definition 5 functional P (|XI ) maps gamble f domain KOIgamble P (f |XI ) called conditional lower prevision.definition well posed sets {I1 (x) : x XI } form partition X n .possible confusion variables involved lower prevision, shalluse notation P (f |x) P (f |XI = x). particular, P (y|x) mean P (Iy |x)pairs values x, y.Walleys theory conditional lower prevision P (XO |XI ) defined KOI requiredself-consistent, separately coherent. Separate coherence means one handsubject knows variable XI taken value x, cannot raise (conditional)lower prevision P (f |x) gamble considering acceptable buying transactionsimplied gambles domain, hand betodds event XI = x observed it.case, domain linear set gambles, definition following:Definition 6 conditional lower prevision P (XO |XI ) separately coherentx XI , f, g KOI , > 0:(SC1) P (f |x) inf 1 (x) f ().(SC2) P (f |x) = P (f |x).(SC3) P (f + g|x) P (f |x) + P (g|x).Using conditions, see clearly separately coherent conditional lowerprevision also regarded lower bound conditional expectation. also follows= , separate coherence coincides notion coherence introduced above.Given separately coherent conditional lower prevision P (XO |XI ) domain KOI ,see P (XO |x) defined set XO -measurable gambles, fKOI , P (f |x) = P (g|x), g XO -measurable gamble given g(w) = f (I c (w), x)w X n .8. refer work Miranda De Cooman (2005) Walley (1991) general definitionsfollowing notions section terms partitions, domains necessarily(these) linear sets gambles.765fiZaffalon & Mirandaunconditional case, also consider conditional upper previsions,represent subjects infimum acceptable selling prices gambles f KOI ,coming know value variables XI (and nothing else). P (f |x) =P (f |x) gambles f . Similarly, conditional lower prevision P (XO |XI )set KOI linear separately coherent P (f + g|x) = P (f |x) +P (g|x) x XI f, g KOI . Conditional linear previsions correspondcase subjects supremum acceptable buying price (lower prevision) coincidesinfimum acceptable selling price (or upper prevision) every gamble domain.separately coherent conditional lower prevision P (XO |XI ) linear, denoteP (XO |XI ).conditional lower prevision P (XO |XI ) dominates P (XO |XI ) P (f |x) P (f |x)every XOI -measurable gamble f every x XI . conditional lower previsionP (XO |XI ) separately coherent lower envelope closedconvex set dominating conditional linear previsions, denote M(P (XO |XI )).bit abuse notation, since actually every x XI set M(P (XO |x))set linear previsions. follows also P (XO |XI ) lower envelope setextreme points M(P (XO |XI )), say P (XO |XI ) extreme pointM(P (XO |XI )) every x XI , P (XO |x) extreme point closed convex setM(P (XO |x)). denote set extreme points M(P (XO |x)) ext(M(P (XO |x))).Example 2 Consider following experiment: subject throws coin; lands heads,selects ball urn red white balls unknown composition; landstails, selects ball urn red blue balls also unknown composition. LetX1 result first experiment, values {heads, tails}, X2 colorball drawn second experiment, values {red, white, blue}.may model using conditional prevision P (X2 |X1 ) P (X2 |X1 = heads)vacuous {red, white}, P (X2 |X1 = tails) vacuous {red, blue}. extremepoints M(P (X2 |X1 )) conditional previsions P (X2 |X1 ), P (X2 |heads)degenerate either red white, P (X2 |tails) degenerate either red blue.3. Basic Settingsection introduce basic assumptions spaces considered modelincompleteness process.3.1 Domainmentioned Introduction, paper consider problem drawingconclusions value target variable Z takes Z informationvalue another variable takes set Y. paper shall assumeset finite, set Z possible values target variable Z infinite.3.2 Incompleteness Processuncommon devices use get information , whateverare, may let us see exactly is. this, explicitly model observation766fiConservative Inference Rulenew variable W , taking values finite set W possible observations. callW observation . W represents outcome observational process.paper focus observational processes called incompleteness processes,turn fact entire possibility space, also nonempty subsetspossibility space.Remark 2 (Concerning W variable) remark necessary introducevariable W even quite common habit applications dealvariables Z . possibility drop W depends assumptions done.instance, assume CAR/MAR W variable certain point derivationcancels out, leading formulae involve Z . one confuseoperational procedures theoretical representation needed derivationrule. theoretical derivation take account latent level information,represented , need coincide manifest level, namely W , henceneed model process leads W . also necessaryassumptions made paper lead eventuallydrop W . Moreover, distinction latent manifest level newproposal all: contrary, present, somewhat implicitly, even original worksMAR (Little & Rubin, 1987) fully explicitly recent works (Grunwald &Halpern, 2003).focus representing IP. start characterising IP so-calledmulti-valued map (this idea modelling IP multi-valued map goes backessentially Strassen, 1964). connects facts observations: Y,gives us set (y) W observations IP may turn fact y. requireset nonempty:(y) 6= .(IP1)Take example Asia network. fact consideration instance :=(v 0 , k 00 , b00 , h00 , o0 , l0 , a0 ) vector (V, K, B, H, O, L, A), taken equal , (y)represents set incomplete instances may generated IP startingy. instance, IP may (y) equal set 27 incompleteinstances obtained (v 0 , k 00 , b00 , h00 , o0 , l0 , a0 ) giving possibility replace valuesvector question marks possible ways.makes possible associate, observation w W, set facts mayoriginate it: i.e.,{w} := {y : w (y)}.Asia network, observation might w = (?, ?, ?, h00 , ?, ?, a0 ). (y) definedabove, {w} set 25 completions (?, ?, ?, h00 , ?, ?, a0 ). (y) might alsodefined differently, instance allowing replacements valuesvector question marks (the possibility replace values question marks mightalso depend values variables vector take jointly). case{w} would subset 25 completions. important set {w}allow us identify value uniquely, unless singleton. tellsus IPs observational processes produce W coarsening , i.e., yieldingobservation w corresponding set {w} possible values expect767fiZaffalon & Mirandaencompass (this expectation formalised Section 7.1.2). follows IPsgeneralisation the, perhaps popular, missingness processes, considertwo possibilities: either {w} singleton Y, case saidmissing. case Asia net, could characterise missingness process writing(y) = {(v, k, b, h, o, l, a), (?, ?, ?, ?, ?, ?, ?)} = (v, k, b, h, o, l, a) Y.9 {w} = ,w cannot produced Y, therefore eliminated W withoutconsequences; shall henceforth assumew W {w} 6= .(IP2)Finally, define w W set facts w compatibleobservation:{w} := {y : (y) = {w}}.3.3 Refining Facts, Observations, Incompleteness Processsection, add structure incompleteness process representingcombination two different incompleteness processes, act different partsfact. model two parts writing := (Y , ), two newvariables, values Y, respectively, = Y. analogous way,regard observation W observation W jointly observationW , hence write W := (W , W ). again, W W two new variables,values W W, respectively, W = W W.additional variables introduced indeed allow us think two new IPs: first actsvariable , leading observation W , thus characterised certain multi-valuedmap ; second acts variable , leading observation W , characterisedanother multi-valued map . call unknown IP CAR IP, respectively,former aim modelling IP whose behaviour unknown uslatter CAR IP.Assuming(y) = (y) (y)(IP3)allows us regard two IPs, taken together, single incompleteness process introduced Section 3.2, i.e., one maps (Y , ) = (W , W ) = W . on,call overall IP. Assumption (IP3) follows consequence intentionmodel problems two IPs observe different parts fact thereforeinteract. discussed length end Section 7.2.impose assumptions unknown CAR IP. Considersets {w} , {w} , {w} , {w} , defined obvious way basis .following assumptions resemble Assumptions (IP1)(IP2) motivatedarguments:(y) 6=(IP4)9. avoid confusion, may worth outlining whether process coarsening missingnessprocess depends focus on. case Asia network, instance, processmissingness process single variable net (i.e., yields either value variablequestion mark) simultaneously coarsening process vector variables (in senseyield vector values vector made entirely question marks).768fiConservative Inference Rule(y) 6=(IP5)w W {w} 6=(IP6)w W {w} 6= .(IP7)also impose additional requirement unknown IP:w W {w} = .(IP8)means start implementing idea ignoranceprocedure used unknown IP select observation starting fact.(y) = (y) (y) implies {w} = {w} {w} {w} ={w} {w} w W. shows (IP4)(IP7) imply (IP1)(IP2).4. Conservative Inference Rulenotations introduced far finally allow us write definition conservativeinference rule. extent, assume beliefs (Z, ) formjoint lower prevision P 1 .Definition 7 (Conservative inference rule) Consider gamble g Z w W,assume P 1 ({w} ) > 0. Let {w}1 := {y {w} : P 1 (y, {w} ) > 0}, defineR(g|y, {w} ) :=infP P 1 :P (y,{w} )>0P (g|y, {w} ){w}1 . letR(g|w) := min R(g|y, {w} ).(CIR)y{w}1Later, Section 7.3, shall see definition actually follows theoremcertain number assumptions.Let us clarify intuition behind definition R(g|w). goal update beliefscertain function g Z make observation w . Rememberw regarded pair (w, w), w part observation originatedunknown IP w originated CAR IP. conservative inferencerule prescribes update beliefs adopting lower prevision R(g|w) computedFormula (CIR). means (i) consider completions w propertyconditioning event (Y = y, {w} ) positive upper probability P 1 ;(ii) compute updated beliefs events: applyingBayes rule linear prevision dominates P 1 event positiveprobability, create set posterior linear previsions whose lower envelopeR(g|y, {w} ); finally, define lower prevision R(g|w) minimum lowerprevisions obtained completions considered. minimum, particular,meaning conservative possible respect data madeincomplete unknown IP: deal considering complete datacould IP started operating. hand, data subjectCAR IP treated usual, is, conditioning set completions {w} .769fiZaffalon & Miranda4.1 Significance Conservative Inference Rulethink CIR generalisation two kinds updating rules. generalisestraditional updating rule, one that, instance, prescribes discarding missing observations. CIR coincides rule case IP made CAR component.hand, CAR component, overall IP unknown, CIRsimilar (but powerful than) so-called conservative updating rule (CUR) proposed De Cooman Zaffalon (2004). components present, CIR actsmix traditional updating CUR.CUR, CIR imprecise-probability rule: generally leads lower upperexpectations, partially determined decisions. follows, part, allows P 1imprecise. Yet, even take linear prevision P1 , CIR turnsimprecise-probability rule: imprecision arises logical consequence ignoranceunknown IP.4.1.1 Comparison CURinstructive analyse deeply difference CIR CUR. extent,let us first give definition CUR using notation introduced far:Definition 8 (Conservative updating rule) Assume Z finite set, =W = W , is, overall IP entirely unknown. Furthermore, assumeoriginated missing values: means regard vector-valued,components either observed precisely missing. Assume also P 1 (y) > 0{w} . every gamble g Z, defineR(g|y) :=infP P 1 :P (y)>0P (g|y){w} . letR(g|w) := min R(g|y).y{w}(CUR)major differences CIR CUR discussed below.first difference CUR allows unknown IP present.so, CUR model beliefs stronger ignorance IP, CURbased inferences conservative necessary. CIR tries remedyallowing mixed states knowledge made ignorance CAR. makes CIRflexible rule lead strong enough conclusions many applications.far important difference CIR CUR generality application. theory used derive CUR restricted case P 1 directlyassessed rather obtained number conditional unconditionallower previsions, possibly together notion independence.case, instance, statistical inference involves using certain numberlower previsions model prior knowledge likelihood function notion independence (or exchangeability) build P 1 . Although one apply CURalso general common conditions, theory guarantee770fiConservative Inference RuleCUR leads self-consistent inference cases. CIR, hand,shown Sections 7.3 lead coherent inference wide spectrumconditions, cover nearly practical situations. meansapplying CIR always leads probabilities self-consistent well consistentoriginal assessments. (Observe since CUR special case CIR,proofs finally show CUR also leads self-consistent inference.) words,CIR much CUR rule general task updating beliefs basedobservation facts. this, similar spirit traditional updating,typically use every situation: e.g., case expert systems wellupdate beliefs given data problems statistical inference. CIR, differentapplications follow simply giving different meanings facts (Y , ), observations(W , W ), quantity Z interested. Section 5 give examplesshow done variety cases.three characteristics make CIR flexible CUR.first CIR allows target space infinite, CUR definedcase finite spaces.second CIR deals general incompleteness processes, CURspecial case processes may originate missing informationvariables consideration. related restriction mentioneddefinition CUR. characteristic CIR important aimingobtain strong conclusions possible: taking advantage partially observedfacts, CIR leads general stronger conclusions CUR.third somewhat technical. CUR requires every element {w}given positive upper probability. CIR requires entire set {w} .difference important practice. see this, consider applicationsquite common represent deterministic relations among variables degenerateprobabilities equal zero one. relations naturally give rise zero upperprobabilities: every joint state variables satisfy relationzero upper probability definition. CUR cannot used applications. CIRcan, simply leads neglect states zero upper probabilities:precisely, given observation (w, w), leads consider compatible facts(y, {w} ) possible condition given positive upperprobability, or, words, {w}1 .Section 5.1 show differences CIR CUR impactexample.4.1.2 Originality CIRSomething interesting note CIR, traditional updating CUR, basedvariables Z : i.e., applying CIR one need considerW -variables. makes CIR particularly simple use. Another consideration concernsoriginality: best knowledge, CIR appears first time.771fiZaffalon & Mirandacontributions literature similar CIR case statistical model learningsamples made incomplete unknown missingness process (e.g., Manski, 2003; Ramoni& Sebastiani, 2001; Zaffalon, 2002). surprising, intuition takecompletions incomplete sample actually natural. awarework proposing, especially deriving, abstract general rule update beliefsincomplete information CIR.5. Applicationsfollowing sections shall show CIR leads easily several different rules according applications study, present number examples.make things simpler go details multi-valued maps used; shalltake W set nonempty subsets Y, assume hypothesesdone throughout paper hold. adopt similar considerations CAR IP.5.1 CIR Expert SystemsProbabilistic expert systems represent key quantities domain vector variables,section assumed take values finite spaces. Onevariables target, i.e., variables objective inference. remainingones introduced extent inferring value target.Asia network Figure 1 represents well-known artificial example expert systemmedical domain. supposed expert provided graph wellprobabilities define Asia network, reported Table 1. want usenetwork make diagnosis, first choose target node, R B.collect information patient, well results medical tests, X-rays,make available network instantiating related nodes graphobserved values. Finally, query network update probability target nodegiven evidence inserted.usually nodes, apart target node, instantiatedvalues missing, way network compute belief updating dependsassumptions them. traditional way entails marginalisingequivalent assuming subject MAR process. specialcase CIR obtained dropping unknown IP. general version CIR offersflexibility treatment, produce different solution, illustrateexample below. also use coarsened observations show set-valuedobservations may enter picture probabilistic inference CIRCAR case.Example 3 Say senior doctor hospital find desk reportjunior colleague certain patient visited. patient came hospitalstate dyspnea (A = a0 ). colleague visited patient findsign bronchitis (H = h00 ). also made questions patient collectbackground information. remembered ask something smokingwell recent trip Asia; end clear determinateenough got know patient concerned one two772fiConservative Inference RuleV = v00.01K = k00.5B=b0v00.05v 000.01R=r0k00.1k 000.01H = h0k00.6k 000.3= o0b0 r01b0 r001L=l0o00.98o000.05A=a0o0 h00.9o0 h000.7b00 r01b00 r000o00 h00.8o00 h000.1Table 1: Asia example: probabilities variable (first column) graph conditionalvalues parent variables. state prime corresponds yes.773fiZaffalon & Mirandathings. unexperienced colleague thought situation serious sentpatient back home. instead bit cautious. fact suspectpatient might hidden information privacy reasons, although recogniseknow reasons. Overall, implicitly assuming existenceunknown IP variables V K leads {w} = {(v 0 , k 00 ), (v 00 , k 0 )},denote w value W corresponds observation (V, K). wordsregard (v 0 , k 00 ) (v 00 , k 0 ) two possible completions informationlack (V, K).Let us make two remarks proceeding: (i) unknown IP coarseningprocess, missingness process, allows us restrict completions(V, K) two elements; (ii) despite name unknown IP (also very)informative use coarsened rather missing values.finally judge remaining variables subject MAR IP. reasonable colleague simply decided patient test. caseprobability missingness one independently actual values variablesconsideration. instructive stress case MAR IP colleague.point ready diagnosis. first run algorithm Bayesiannets using completion (v 0 , k 00 ), obtaining posterior probability cancer 0.052tuberculosis 0.258; run algorithm more, case usingcompletion (v 00 , k 0 ), leads 0.423 updated probability cancer 0.042tuberculosis. question first run suggestsdiagnose tuberculosis, second diagnose cancer. Sinceidea one right completion (V, K), admit ablediscriminate tuberculosis cancer time. words, modeltelling information weak draw useful conclusion,implicitly suggesting collect stronger information. order so, invitepatient next visit, explaining importance knowing whetherAsia, something actually confirms, thus letting know eventually V = v 0K = k 00 . updated probabilities 0.052 cancer 0.258 tuberculosis.basis, ask patient undergo X-rays, turn abnormal (L = l0 ),leading 0.151 0.754, respectively, probabilities cancer tuberculosis,diagnose tuberculosis.Consider might happen assuming variables subject CAR/MARIP, common Bayesian nets. case, information initially= a0 , H = h00 , (V, K) {(v 0 , k 00 ), (v 00 , k 0 )}. CAR allows usforget W write (V, K) belongs {(v 0 , k 00 ), (v 00 , k 0 )}. eventeasy incorporate Bayesian network: enough insert new node Asianetwork child V K state yes probability one(V, K) {(v 0 , k 00 ), (v 00 , k 0 )}. new node instantiated state yes.point, running algorithm Bayesian nets yields probabilities cancertuberculosis conditional = a0 , H = h00 , (V, K) {(v 0 , k 00 ), (v 00 , k 0 )}, 0.4180.045, respectively. would make suspect cancer; moreover, mightwell induce take following erroneous course reasoning: since probabilitycancer high even without knowing exact values V K, trying obtaininformation waste time; must rather focus concrete evidence774fiConservative Inference RuleX-rays make diagnosis. obtaining positive X-rays test (L = l0 ) wouldenforce beliefs even raising probability cancer 0.859, leadingmistaken diagnosis.considerations limited expert systems based precise probability; completely analogous considerations would done case expert systems modelknowledge using closed convex sets mass functions (or, equivalently, coherent lowerprevision lower envelope) CIR also suited. Credal networks,example, provide modelling capabilities (Cozman, 2000, 2005).easy rephrase expert system models setting paper. Sayexpert system based vector variables (Z, Y1 , . . . , Ym , Y1 , . . . , Yn ), Ztarget variable, others subject unknown CARIP, respectively. sufficient write := (Y1 , . . . , Ym ), := (Y1 , . . . , Yn ),consider set joint mass functions (Z, ), equivalently lowerprevision P 1 made taking lower envelope, given. inference expertsystem, quite general form, corresponds compute R(g|w, w), wobservation vector w vector.consider cases make things clearer. extreme, alreadymentioned, case = 0, means CAR IP.updating rule follows CIR traditional updating: R(g|w) = R(g|{w} ).Say that, even specific, g indicator function Iz z Z,00{w} = {(y1 , . . . , yj , yj+1, . . . , yn0 ) : yj+1Yj+1 , . . . , yn0 Yn )}, i.e., firstj variables observed precisely, others missing. updating rulebecomes:R(g|{w} ) = R(Iz |y1 , . . . , yj , Yj+1 , . . . , Yn ) = R(Iz |y1 , . . . , yj ),equal inf P P 1 :P (y1 ,...,yj )>0 P (z|y1 , . . . , yj ). latter updating rule implemented credal networks; P 1 linear prevision, rule used Bayesiannetworks.Consider extreme: n = 0, i.e., unknown IP.Similarly previous case, say g indicator function z; {w} =0 , . . . , 0 ) : 00{(y1 , . . . , yi , yi+1i+1 Yi+1 , . . . , ym Ym )}. CIR becomes R(g|w) =minyi+1 Yi+1 ,...,ym Ym inf P P 1 :P (y1 ,...,ym )>0 P (z|y1 , . . . , ym ). case nearly coincidesconservative updating rule proposed De Cooman Zaffalon (2004),differences already discussed Section 4.1. differences important: instance,CUR cannot deal coarsened observations makes impossible use modelobservation Example 3. would even prevent CUR appliedgenerally example: one hand, presence logical gateAsia network creates states zero upper probability (e.g., B = b0 , R = r0 , = o00 )incompatible assumptions underlying CUR; other, since domainknowledge (i.e., Asia net) built number conditional mass functions,cannot guarantee CUR leads self-consistent inference proof dealextended case. know CIR instead lead self-consistent inferenceconsequence Corollary 3 Appendix B.neither n equal zero, CIR becomes mix two extreme casesillustrated, example: leads treat variables subject CAR IP775fiZaffalon & Mirandatraditional updating, treating subject unknown IP similarlyCUR does. Mixing two things advantage greater expressivity: allows usrepresent beliefs overall IP two extremes.conclude section briefly discussing problem computationsCIR special case CUR.context classification Bayesian nets according CUR, AntonucciZaffalon (2007) proved NP-hardness result, well given exact algorithm.algorithm variant variable elimination algorithm better complexitytraditional algorithms Bayesian nets (implicitly using CAR): works lineartime polytree networks (i.e., one pathtwo nodes graph dropping orientation arcs) also numbergeneral nets; remaining ones takes exponential time. Moreover, anotherpaper, Antonucci Zaffalon (2006) shown missing observationsproblem CIR-updating Bayesian nets traditional (i.e., MAR-based)updating credal nets equivalent. exploited recent paper (Antonucci &Zaffalon, 2008, Section 9) show NP-hardness CIR-updating Bayesian nets,give procedure solve problem via existing algorithms credal nets. ideabehind procedure relatively straightforward, takes inspiration methodproposed Pearl (1988, Section 4.3) represent instantiated node Bayesian netusing equivalent formulation: formulation based removing instantiationnode adding dummy child actually instantiated certain value.approach basically taken CIR-updating case node missingunknown way; CIR imposes deal considering possible instantiations.Considering dummy-child method shown equivalent usingsingle imprecise-probability dummy child instantiated unique value.way node originally missing unknown way treated nodemissing random, dummy child simply instantiated imprecise-probabilitynode. consequence, original Bayesian net becomes credal network taskbecomes computation MAR-based updating net. Since alreadymany algorithms designed task, described transformation allows one solveCIR-updating problem via known algorithms MAR-updating problem credal nets.Yet, MAR-updating credal networks difficult problem MAR-updatingBayesian nets, NP-hard also polytrees (De Campos & Cozman, 2005). ThereforeCIR-updating appears demanding MAR- CUR-updating.necessarily going problem practice approximate algorithms credal netsnowadays allow one solve updating problems large-scale networks (e.g., Antonucciet al., 2008).5.2 CIR Parametric Statistical Inferencestatistical problem parametric inference, given sample use updatebeliefs so-called parameter, say , values . admissible valuesindex family data generation models consider possible problemconsideration. exclude possibility set infinite,often case statistics.776fiConservative Inference Rulesetting, fact thus true, hence complete, sample. representfollowing vector variables:D1D2(1):= . ...DNelements sample also called units data. assume on,variables Di space possibilities every i.exemplify problem parametric statistical inference focusingAsia Bayesian network Figure 1: frequent step construction Bayesiannets inference network parameters data set. Say, instance,interested evaluating chance person suffers tuberculosis knowperson made recent visit Asia. extent might exploitdata set variables B V , one below::=(b0 , v 0 )(b0 , v 00 )(b0 , v 00 )(b00 , v 00 )(b00 , v 0 )(b00 , v 0 ),(2)assume addition data generated according identicalindependently distributed (IID) process.parametric inference relying tools Bayesian statistics. meanscompute posterior linear prevision (i.e., posterior expectation) P (g|y),certain function g : R. obtained integrating posterior density function, obtained turn Bayes rule applied prior density function, likelihoodfunction (or likelihood ) L() := P (y|).case, common choice prior would Beta density : Bs,t0 ()00st 1 (1 )s(1t )1 , t0 positive real hyper-parameters respectivelyoverall strength prior knowledge prior expectation . case0data set (2), choice leads posterior expectation equal 1+st3+s .0Setting := 1 t0 := 1/2, namely, Perks prior (see Perks, 1947), obtain 1+st3+s = 0.375,regarded approximation true parameter value.Imprecise probability approaches parametric inference often extend Bayesian statistical methods working set prior density functions, updatingBayes rule, whenever possible, using likelihood function, thus obtaining setposteriors. example imprecise Dirichlet model proposed Walley (1996a).notation terminology, means imprecise case parametric inferencebased unconditional lower prevision P 1 (, ), obtained means prior P 1 ()likelihood P (Y |) rule called marginal extension, updatedposterior lower prevision R(|Y ) procedure called regular extension. Marginalregular extension introduced precisely Section 6.777fiZaffalon & Mirandaprevious example related data set (2) variables binary,imprecise Dirichlet model called imprecise Beta model (Bernard, 1996), easilyapplied follows. idea consider set Beta densities fixed priorstrength, say = 1: i.e., set Bs,t0 = 1 t0 (0, 1).10 setregarded single imprecise prior states prior probability categoryb0 lies (0, 1), seems reasonable way model state prior ignoranceBayesian prior, Perks above. imprecise prior leads imprecise0posterior expectation : compute it, enough reconsider expression 1+st3+slet t0 take values (0, 1); leads interval [0.25, 0.50] delimited000lower upper posterior probabilities obtained 1+st3+s = 0 = 1,respectively. Again, interval estimate11 appears much reasonablereliable precise posterior expectation obtained Bayesian approach, takingespecially account sample available infer parameter considerationsize three!real problems often face complication dealincompleteness statistical data: rather complete sample y, may givenincomplete sample w, i.e., one corresponds set {w} complete samples.set {w} arises consequence missingness partial observability values.data set (2) might instance turned incompleteness process followingincomplete data set:0 0(b , v )(b0 , v 00 )(b0 , ?)(3)w :=(b00 , v 00 ) .(b00 , ?)(?, v 0 )example {w} set eight complete data sets obtained replacingquestion marks possible ways.question parametric inference incomplete sample.represent unit Vector (1) regarding generic variable Di pair (Yi , Yi ),let := (Y1 , . . . , YN ), := (Y1 , . . . , YN ), = (Y , ).easy use CIR address question parametric inference incompletedata, know subject CAR IP, know IP acts. Observing plays role Z, obtain CIR prescribes using followingrule: R(g|w) = miny{w}1 R(g|y, {w} ), rewrites alsoR(g|w, w) = miny{w}1infP P 1 :P (y,{w} )>0P (g|y, {w} ),(4)10. reason exclude extreme points interval avoid creating conditioning eventszero lower probability discuss implications. present setup restrictive,shown closed interval would eventually lead inferences.11. important aware intervals conceptually different tools Bayesiancredible intervals, arise second-order information chance. present intervalsarise ignorance unknown IP, something makes set IPs consistentassumptions second-order information. Stated differently,counterpart intervals precise case point estimates, credible intervals,instead compared imprecise credible intervals (e.g., see Walley, 1996a, Section 3).778fiConservative Inference Ruleimprecision (, ) originates via prior imprecision only. prove Corollary 4Appendix B rule leads self-consistent inference.regard lower expectation Equation (4) arising two kinds imprecise beliefs. first beliefs model lower prevision P 1 ().remaining beliefs embodied likelihood function. imprecise knowledge, too,since actually multiple likelihood functions, unknown IP,model using different conditional previsions P (|y, {w} ) {w}1 .words, working incomplete data according CIR equivalent working setposteriors arise applying Bayes rule, whenever possible, prior-likelihoodpair model.case data set (2), might know order create incompletesample (3) it, variable B subject MAR missingness process,might know kind missingness process acted variable V ;case, generic unit (2) written pair (yi , yi ). Say focuscomputing posterior expectation , chosen person sufferstuberculosis know person made recent visit Asia. Sayalso use Perks prior Bayesian case, order getdistracted discussion prior imprecision. case, outer minimum (4)corresponds minimising four completions variable V ; following infimumcorresponds take account Perks prior. four completions mentioned giverise four different data sets contain single missing value last unit.them, compute lower probability category b0 conditional v 0 , usingExpectation-Maximisation algorithm (Dempster, Laird, & Rubin, 1977) together Perksprior, obtaining four values: 0.63, 0.87, 0.50, 0.83 (these values rounded seconddigit). lower probability minimum: 0.5; analogously, maximumupper probability: 0.87. think two values delimiting intervalprobability consideration: [0.5, 0.87]. width interval reflectsignorance missingness process V .consider Bayesian case, using B V MAR assumption,common learning parameters data sets. case, ExpectationMaximisation algorithm together Perks prior yields estimate probabilityequal 0.86. Apart unrealistic precision estimate obtainedsmall data set, observe using MAR arbitrarily led us close upperextreme interval [0.5, 0.87]. even questionable considerBayesian estimate complete data set (2) close lower extreme.summary, using CIR able obtain interval estimates arguablyrealistic point estimates provided traditional methodsMAR assumption justified. also follows exploiting option given CIRuse models prior knowledge carefully model available information,absence information, imprecise Dirichlet model.Finally, example illustrates, working multiple likelihoods consequencetaking possible completions incomplete part sample subjectunknown IP. intuitive procedure; therefore, surprising analogousprocedures already advocated missing data context robust statistical inference (see, e.g., Manski, 2003; Ramoni & Sebastiani, 2001; Zaffalon, 2002). Actually,779fiZaffalon & Mirandadiscussion (and following) section regarded formal justificationcited approaches point view theory coherent lower previsions.also regarded generalisation approaches considersjoint presence CAR unknown IP, allows one workincomplete rather missing data.5.2.1 IID+ID Caseprevious section, made hypotheses generation completesample. However, practice frequent deal independent identicallydistributed data (also called multinomial data), indeed already assumed IIDdata (2). multinomial data, units identically distributed conditional, helps simplifying developments. Call space possibilities commonunits. assume finite (as shall derivation CIRrule Section 7.3), parameter defined vector [d ]dD , genericelement represents aleatory probability = d. follows vector[d ]dD , whose generic element P (d|); subset |D|-dimensionalunit simplex. Taking accountQNunits also independent conditional ,follows likelihood factorises i=1 di .complete data IID, may reasonable assume also overall IPindependently distributed (ID). assumption allows us represent observationcomplete sample vector, i.e., incomplete sample:W1W2W := . ...WNgeneric unit Wi observation Di . Remember regard Dipair (Yi , Yi ); consequence, also regard Wi pair variables (Wi , Wi ),Wi Wi observations Yi Yi , respectively. Finally, let W := (W1 , W2 , . . . , WN )W := (W1 , W2 , . . . , WN ). example sufficient consider data set (3),instance W current language; generic unit instanceWi = (Wi , Wi ), Wi corresponds variable V Wi B.Using newly introduced notation, form CIR takes following (withobvious meaning symbols):R(g|w, w) =min(y1 ,...,yN ){w}1R(g|y1 , . . . , yN , {w1 } , . . . , {wN } ),(5)R(g|y1 , . . . , yN , {w1 } , . . . , {wN } ) equalinfP P 1 ,P (y1 ,...,yN ,{w1 } ,...,{wN } )>0P (g|y1 , . . . , yN , {w1 } , . . . , {wN } ).rule leads self-consistent inference established Corollary 4 Appendix B.Moreover, new formulation shows ID assumption incompleteness process leads practice inhibiting certain types coarsening: create logical780fiConservative Inference Ruleconnections different units. one hand, confirms expressive powercoarsening. other, suggests applications might easier forgetID assumption simply focus specification kind coarseningbehaviour. approach appears intuitive hence accessible especiallypeople little experience statistics might involved analysis.5.2.2 Full IID Case?reasonable assume IP identically distributed besides independently distributed? consequences assumption?start addressing second question. IID complete data, genericelement fixed aleatory probability, denoted . Call W spacepossibilities common variables Wi , = 1, . . . , N . IID IP, genericelement w W fixed aleatory probability produced conditional d, let us. follows w fixed unconditional aleatory probability produced:call Pww := dD dw , means process produces elements W alsomultinomial. seems considerably simplify setup considered far, thusregarded advantage full IID assumption (this advantage clear practicalconsequences case pattern classification, illustrated Section 5.3.2.)hand, turn address first question, possible advantages seem dwarfed strength assumption itself. indeed questionableassumption may largely valid applications. IPs often generatedsophisticated behaviour patterns involve humans, complex agents,regarded protocols communications. case giving givinginformation fundamental intelligent part communication. Assumingcase IP IID, seems much strong assumption. fact,fundamental difference data-generating processes (giving rise Z )observational processes (giving rise W ). believe essence differencenumber cases make much sense assume observationalprocess identically distributed, IID make sense, least reasonableapproximation many data-generating processes.5.2.3 CAR Unitsconsidered IID+ID setup Section 5.2.1 gives us opportunity slightlyextend analysis done far. idea since overall IP needidentically distributed, may happen act CAR process units. Saycertain unit 0 entirely coarsened random. question form takes CIR now.easy see defining := (Y1 , . . . , YN ), := (D0 , Y1 , . . . , YN ),corresponding observation variables W := (W1 , . . . , WN ), W := (W0 , W1 , . . . , WN ),lead following rule:R(g|w, w) =min(y1 ,...,yN ){w}1R(g|y1 , . . . , yN , {w0 } , {w1 } , . . . , {wN } ).781fiZaffalon & Mirandaparticular, Unit 0 missing, i.e., {w0 } = D, rule prescribes discard unitconsideration:R(g|w, w) =min(y1 ,...,yN ){w}1R(g|y1 , . . . , yN , {w1 } , . . . , {wN } ).observation particularly important applications may well casepractice units entirely missing non-selective way. CIR tells usunits, Unit 0 above, going alter beliefs Z.situation obviously different units turned missing unitsunknown process; case justification discard them. correct wayproceed make missing values part observed data, applyCIR again. would lead us consider completions missing unitsaccount.5.3 CIR Pattern Classificationsection focuses problems pattern classification, special case so-called predictiveinference. Loosely speaking, kind inference concerned predicting futureelements sequence based available part sequence itself. classificationproblem, available sequence represented following matrix:C1 F1C2 F2(6).... ...CNFNgeneric line i, unit i, matrix represents object described pairvariables relabel Di := (Ci , Fi ) consistent notation usedparametric inference. Variable Ci represents characteristic objectinterested, call class. Denote set classes C. definition patternclassification, C finite set. Variable Fi represents features objectinformative class.try make clear example focused Asia network.Say data set records state variables Asia networknumber persons. Say also interested classifying people smokersnonsmokers. case, value Ci , i.e., class variable i-th persondata set, state variable K Asia network person i. Variable Fivector remaining variables Asia network person; words,Fi represents profile person data set.consider next element sequence, represented unitDN +1 := (CN +1 , FN +1 ), also called unit classify. previous example, DN +1would next person see. goal classification predict valueCN +1 assumes given values variables; example amountspredict whether next person smoker given profile person,relationship profiles classes suggested historical data.words, framework CN +1 Z (D1 , . . . , DN , FN +1 ) .782fiConservative Inference RulePredicting class c0 CN +1 regarded action uncertain reward gc0 ,whose value gc0 (c) depends value c CN +1 actually assumes. case preciseprobability, optimal prediction class copt maximises expected reward:P (gcopt |d1 , . . . , dN , fN +1 ) P (gc0 |d1 , . . . , dN , fN +1 ),c0 C.previous expression equivalent next:P (gcopt gc0 |d1 , . . . , dN , fN +1 ) 0,c0 C.similar expression used imprecise probability: case optimalclass one undominated, i.e., c0 C:12P (gcopt gc0 |d1 , . . . , dN , fN +1 ) > 0.Despite similarity notation, important realise fundamentaldifference two cases: precise probability always leads determinate prediction,imprecise probability not. imprecise probability progression accordingstronger beliefs lead less indeterminate decisions, completely determinedones (see paper De Cooman & Zaffalon, 2004, Section 2.10, wider discussiondecision making imprecise probability).discussion point highlighted precise impreciseprobabilities, predictions based (upper, hence lower) previsions functionsg : C R. order address issue incompleteness pattern classification,therefore, without loss generality, restrict attention task updating beliefsCN +1 .task usually regarded made two distinct steps. first concernedlearning sample, represented Matrix (6), probabilistic modelrelationship features classes. second applying model observedvalue fN +1 FN +1 order finally compute (lower) prevision gamble g.illustrate two steps case IID data; general cases treatedanalogously.Bayesian framework, first step often done way similar parametricinference. One defines family density functions may responsible producingunits data, indexes admissible values (usually continuous)parameter , assesses prior density . prior likelihood leadvia Bayes rule posterior density conditional (d1 , . . . , dN ). second stepcorresponds use posterior together density (or mass function)DN +1 conditional , obtain (integrating out) so-called predictive posterior:i.e., mass function CN +1 conditional (d1 , . . . , dN , fN +1 ), embodieswanted probabilistic model relationship features classes. Computingposterior prevision P (g|d1 , . . . , dN , fN +1 ) trivial point.situation similar imprecise case, difference using setprior densities, i.e., lower prior P 1 (), leads lower predictive prevision:P (g|d1 , . . . , dN , fN +1 ) :=infP P 1 :P (d1 ,...,dN ,fN +1 )>0P (g|d1 , . . . , dN , fN +1 ).12. Walley (1991) calls maximality related decision criterion. See work Troffaes (2007)comparison criteria.783fiZaffalon & Mirandaready address issue incomplete data using CIR. must firstdefine variables subject CAR unknown IP. respectfeature variables, assume generic variable Fi (i = 1, . . . , N + 1) equalpair (Fi , Fi ), usual meaning symbols. Define vectors :=(C1 , F1 , . . . , CN , FN , FN +1 ), := (F1 , . . . , FN , FN +1 ). make things readable,also define Yi := (Ci , Fi ), Yi := Fi , = 1, . . . , N ; YN +1 := FN +1 , YN +1 := FN +1 .obviously arbitrariness definitions vectors ,might well case applications require different choices. presentdefinitions done illustrative purposes.definitions, CIR leads following rule update beliefs g:R(g|w, w) = min(y1 ,...,yN +1 ){w}1 inf P P 1 :P (y1 ,...,yN +1 ,{w1 } ,...,{wN +1 } )>0P (g|y1 , . . . , yN +1 , {w1 } , . . . , {wN +1 } ).(7)Corollary 5 proves rule leads self-consistent inference. Equation (7) statesone consider (i) set possible completions part observed sampleoriginated unknown IP, Ni=1 {wi }1 ; (ii) set possible completions partunit classify originated unknown IP, {wN +1 }1 ; (iii) set (possible)precise priors, dominating prior lower prevision P 1 ().choices, problem becomes computation posterior expectation gsingle Bayesian (i.e., precise-probability) classifier. consider possiblechoices (i)(iii) above, working (7) amounts work set Bayesian classifiers.set posterior expectations originated Bayesian classifiers summarised (7)lower expectation.look problem also another point view. Imprecision produceslower expectation (7) regarded originated three components. firstpresence multiple priors. second presence multiple likelihoods,consistent certain completion part sample originatedunknown IP. third component set-valued observation part FN +1features unit classify, regard imprecise description objectclassify.5.3.1 ExampleLet us focus initial example Section 5.3 interestedclassifying people either smokers nonsmokers. make things easier, take gc00-1 loss function, i.e., compute posterior probabilities rather expectationsorder issue classification. Moreover, take graph Asia net representprobabilistic dependencies variables involved (yet, assumenet parameters given, learning parameters data part inferentialtask classification solve). make example handy, assumepeople want classify miss information variables V , B,O, L Asia net, missingness MAR: is, variablesconstitute FN +1 . implies, (7), actually discard variables V , B,O, L consideration: equivalently work inference task relyinglearning set variables K, R H alone. holds working784fiConservative Inference Rule(7) amounts work set Bayesian classifiers, property holdsthem.13 consequence, turns portion Asia netrelevant classification displayed Figure 2. structure,Smo(K)ing+Lung cance(R)Bronc(H)itisFigure 2: naive sub-network Asia net related variables K, R H.feature variables represented disconnected children class variable callednaive network. use precise-probability classifier, best known naiveBayes classifier (Duda & Hart, 1973).Say learning set, originated IID process, following::=(r0 , h00 , k 0 )(r0 , h00 , k 0 )(r0 , h0 , k 0 )(r0 , h0 , k 0 )(r00 , h0 , k 0 )(r00 , h0 , k 00 )(r00 , h0 , k 00 )(r00 , h00 , k 00 )(r00 , h00 , k 00 )(r0 , h00 , k 00 ).data set characterised strong positive relationship smoking cancerweak positive relationship smoking bronchitis. Learning naive Bayesapplying model four joint instances feature variables,obtain following predictions:(r0 , h0 , k 0 )(r0 , h00 , k 0 )(8)(r00 , h0 , k 00 ) ,(r00 , h00 , k 00 )used Perks prior naive Bayes14 experiments. replaceprior imprecise one, obtain extension naive Bayes imprecise13. proof relationship specific classifier found work Corani Zaffalon (2008,Section 3.1.2).14. Modified described Zaffalon (2001, Section 5.2) (refer Perks prior defined analogyIDM section) make comparison easier.785fiZaffalon & Mirandaprobability. moreover define prior P 1 () model state priorignorance, similarly done case parametric inference, obtainimprecise-probability classifier instance so-called naive credal classifier 2(or NCC2, see Corani & Zaffalon, 2008). reinterpret NCC2 set naive Bayesclassifiers. present case, classifier per precise prior consistent(i.e., dominating) imprecise one.way NCC2 issues classification specific instance R H understoodeasily terms set naive Bayes classifiers corresponds: classificationNCC2 union classes issued naive Bayes classifiers set.15means naive Bayes classifiers issue class, classificationNCC2 determinate, i.e., made single class. Otherwise, disagreementamong naive Bayes classifiers, NCC2 issues entire set K, i.e., indeterminateclassification.16obtain determinate predictionsinfer NCC2 learning set d,17reported (8): means information data strong enough smoothcontribution precise prior used NCC2 favor single class.move interesting examples introducing missing values. Considerfollowing two instances classify missing information cancer:(?, h0 ).(9)(?, h00 )treatment instances different naive Bayes NCC2. NCC2naturally embed assumption R H made missing unknownprocess, deal considering two completions question markinstance. words, classification NCC2 only, before, equalunion classes delivered equivalent set naive Bayes classifiers, unionalso taken respect two completions instance classify.hand, naive Bayes assume MAR deal incomplete instances,lead discard R conditioning variables.classifications issued naive Bayes NCC2 respectively:(?, h0 , k 0 )(?, h0 , K),.(?, h00 , k 00 )(?, h00 , K)words, naive Bayes knowing state bronchitis sufficient determinewhether person smoker not, despite weak relationship learning settwo characteristics; NCC2 cautious believes possibledetermine smoking state missing, necessarily ignorable way,value important predictor variable. hand, checkedmissing variable H instead R, naive Bayes NCC2 agree15. case class variable binary.16. total indeterminacy consequence class variable binary; cases output setclasses subset classes, least informative one. cases, classificationpartially indeterminate, carries therefore useful information.17. predictions NCC2 computed open-source software freely available addresshttp://www.idsia.ch/giorgio/jncc2.html.786fiConservative Inference Ruleprediction determinate: knowing person cancer tells us personsmoker, vice versa.situation become even critical naive Bayes use incompletelearning set wd := (w1 , . . . , wN ) rather d,wd :=(r0 , h00 , k 0 )(r0 , h00 , k 0 )(r0 , ?, k 0 )(r0 , ?, k 0 )(r00 , ?, k 0 )(r00 , h0 , k 00 )(r00 , h0 , k 00 )(r00 , ?, k 00 )(r00 , ?, k 00 )(r0 , ?, k 00 ).originated data set turning values H missingcomplete portion data set suggests H good predictor K.going problem naive Bayes, still deal incompletenessassuming MAR, leads compute counts learning set discardingmissing values. NCC2, hand, implicitly considers complete data setsconsistent wd. Therefore case NCC2 regarded set naiveBayes classifiers obtained considering precise priors previously describedrelationship NCC2 likelihoods arise complete data setsconsistent wd.Running classifiers predict class units (9), obtain naiveBayes predicts first person smoker second is, casesposterior probability equal 0.90 ! NCC2, reasonably, outputs K cases,way say information enough make reliable prediction.example also points NCC2 correctly suspends judgment even instancesprecise models naive Bayes actually confident (for detailspoint, see Section 4.4 paper Corani & Zaffalon, 2008).5.3.2 Failure Empirical EvaluationsConsider question IID vs. ID assumption IP, discussed Section 5.2.2, placed context classification. make things easier, focusfinite possibility spaces, assume addition CAR IP presentclasses always observed precisely (i.e., singletons).first interesting thing note following. Recall imposing full IIDassumption (i.e., IID data-generating process IP) implies(set-valued) observations regarded outcomes multinomial process. This,together fact classes always observed precisely, enables us discard-variables consideration: necessary one learn relationship classes features directly using W -variables. makeclear, consider case incomplete samples originated missing values.787fiZaffalon & Mirandafull IID assumption implies case one allowed regard symbol ? missing value possible value, proceed traditional learning methodscase complete samples. shows full IID assumption classificationmakes CIR collapse traditional updating rule, although applied W -variables.makes things easier deal with, thus regarded advantagefull IID assumption classification. already argued IID assumptionIP strong, turn consider weaker ID assumption also patternclassification, consider tenable.Let us focus simple classification setting complete data generatedIID way, IP ID. problem predict class unitclassify given features previous units (1, . . . , N ). already mentionedSection 5.3, usually done precise case following maximum expected utilityapproach. Call model acts way precise classifier.common practice precise classifiers measure accuracy empirically.simplest form, obtained randomly splitting available data learningtest set, inferring classifier former testing latter. simple,yet powerful, idea responsible much success popularity classification,enables one relatively confident well classifier performs previouslyunseen data. Unfortunately, key characteristic lost cannot assumeunknown IP IID.see why, consider (for = 1, . . . , N + 1) Boolean class variable Ci twoBoolean feature variables Ai Bi , Fi = Fi = (Ai , Bi ). Assume classresult exclusive logical disjunction two attributes: i.e., class equals oneeither first second attribute equals one, both. Assumecomplete data eventually turned incomplete data (unknown) IP whoseaction make Bi missing (Ai , Bi ) = (1, 0), i. Let WAiWBi observation variables Ai Bi , respectively. IP characterisedP (WBi =?|Ai = 1, Bi = 0) = 1, observing pattern (WAi = 1, WBi =?)implies Ci = 1 certainty. conditions, precise classifier clearly expectedlearn BN +1 missing irrelevant predict CN +1 , whose value coincidesvalue +1 . Since true available data, partitioninglearning test set nothing confirm it: prediction accuracy pattern(WAN +1 = 1, WBN +1 =?) perfect, i.e., 100%. IP identically distributed,happens classifier put work operative environment, IPchanges, particular making Bi missing (Ai , Bi ) = (1, 1); or,words: P (WBi =?|Ai = 1, Bi = 1) = 1. put work practice, classifieralways wrong pattern (WAN +1 = 1, WBN +1 =?), prediction accuracy dropping0%.course example designed illustrate extreme situation. However,experiments real data sets done without using extreme unknown IP, reportedCorani Zaffalon (2008, Section 4.6), show phenomenon indeed severelybias empirical measures performance. appears point fact: empiricalevaluations doomed failure general data made incomplete nonIID unknown process.788fiConservative Inference Ruleconsiderations may profound implications classification, generally data analysis. fields scientific research rest two fundamental pillars: (i)assumptions made develop certain model (e.g., classifier) tenable; (ii)empirical evaluations reliable. crucial point pillars mayfragile incomplete data, unable sustain credible models conclusions.way left cope critical issues seems necessarily rely tenableassumptions. involves recognising incompleteness process may IID.6. Advanced Notions Coherent Lower Previsionsintroduce advanced notions coherent lower previsions needrest paper, particular derivation CIR Section 7.6.1 Coherence Number Conditional Lower PrevisionsReconsider setup introduced Section 2 made variables X1 , . . . , Xnsubject expresses beliefs. practice, provide assessments disjoint subsetsO, {1, . . . , n}; thus uncommon model subjects beliefs using finite numberdifferent conditional lower previsions. Formally, going consider shallcall collections conditional lower previsions.Definition 9 Let P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) conditional lower previsions respective domains K1 , . . . , Km L(X n ), Kj set XOj Ij -measurable gambles,18j = 1, . . . , m. called collection X n j1 6= j2 {1, . . . , m},either Oj1 6= Oj2 Ij1 6= Ij2 .means two different conditional lower previsions giving informationset variables XO , conditional set variables XI .Even conditional lower previsions collection separately coherent,need coherent one another, collection could still express inconsistentbeliefs. able model joint coherence, first introduce new concepts.Remember use IA denote indicator function set A, i.e., functionwhose value 1 elements 0 elsewhere.Definition 10 gambles f domain KOI conditional lower previsionP (XO |XI ), x XI , shall denote G(f |x) gamble takesP valuenI1 (x) (y)(f (y)P (f |x)) X , G(f |XI ) gamble equal xXI G(f |x).(almost-)desirable gambles subject: behavioural interpretation P (f |x) supremum acceptable buying price f contingent x, gambleG(f |x)+I1 (x) equivalent buying f price P (f |x), provided XI = x,therefore desirable. Since happens arbitrarilyP small, deduce transaction G(f |x) almost-desirable. G(f |XI ) = xXI G(f |x) also almost-desirablefollows rationality principle sum gambles almost-desirablesubject also almost-desirable.1918. use Kj instead KOj Ij order alleviate notation confusion possiblevariables involved.19. case infinite XI need add another rationality principle (Walley, 1991, Sect. 6.3.3).789fiZaffalon & MirandaDefinition 11 XI -support S(f ) gamble f KOI givenS(f ) := {I1 (x) : x XI , f I1 (x) 6= 0},(10)i.e., set conditioning events restriction f identically zero.Definition 12 Let P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) separately coherent. coherent fj Kj , j = 1, . . . , m, j0 {1, . . . , m}, f0 Kj0 , z0 XIj0 ,B {I1(z0 )}j=1 Sj (fj )j0XsupGj (fj |XIj ) Gj0 (f0 |z0 ) (x) 0,xBj=1Sj (fj ) XIj -support fj , defined Equation (10).restrict supremum subset X n gamble f 0 f < 0subset X n desirable subject.notion Definition 12 sometimes also called joint (or strong) coherence.strongest notion self-consistency Walleys theory, regarded uniqueaxiom theory. intuition behind notion ableraise conditional lower prevision gamble taking account acceptabletransactions implicit conditional previsions. Let us make clearer. AssumeDefinition 12 fails, > 0XGj (fj |XIj ) Gj0 (f0 |z0 ) (x) < 0,(11)j=1(z0 )}every x B {I1j=1 Sj (fj ). consequence,j0Gj0 (f0 |z0 ) Iz0 = Iz0 (f0 (P j0 (f0 |z0 ) + ))XGj (fj |XIj ),j=1(z0 )}taking account inequality holds trivially elements outside {I1j0j=1 Sj (fj ), class consequence Equation (11). since righthand side sum almost-desirable gambles, means left-hand sidealso almost-desirable. means price strictly smaller P j0 (f0 |z0 ) +acceptable buying price gamble f0 , conditional z0 . contradictsinterpretation P j0 (f0 |z0 ) supremum acceptable buying price.Example 4 (Walley, 1991, Example 7.3.5) Let X1 , X2 two random variables takingvalues X1 = X2 = {1, 2, 3}, assume make somewhat contradictory assessments X1 = 1 X2 = 1, X1 = 2 X2 = 2, X2 = 1 X1 = 2, X2 = 2 X1 = 1X1 = 3 X2 = 3. assessments modelled conditional previsionsP (X1 |X2 ) P (X2 |X1 ) givenP (f |X2 = 1) = f (2, 1), P (f |X2 = 2) = f (1, 2), P (f |X2 = 3) = f (3, 3)P (f |X1 = 1) = f (1, 1), P (f |X1 = 2) = f (2, 2), P (f |X1 = 3) = f (3, 3)790fiConservative Inference Rulegamble f X1 X2 . see coherent, consider gamblesf1 = I{(1,2),(2,1)} , f2 = I{(1,1),(2,2)} , f3 = 0. follows Equation (10) S1 (f2 ) ={{1} X2 , {2} X2 } S2 (f1 ) = {X1 {1}, X1 {2}}.G(f1 |X2 ) + G(f2 |X1 ) G(f3 |X1 = 1) = G(f1 |X2 ) + G(f2 |X1 ) < 0set {(x1 , x2 ) B B S1 (f2 ) S2 (f1 ) {11 (1)}} = X1 X2 \ {(3, 3)}.6.2 Coherence Graphscollection lower previsions given graphical representation call coherence graph (Miranda & Zaffalon, 2009). coherence graph directed graph made twotypes nodes: actual dummy nodes. Dummy nodes one-to-one correspondencelower previsions collection; actual nodes represent variables X1 , . . . , Xn .?K?V?RBUHw? - sff??LFigure 3: coherence graph originated A1+ -representable collection: P 1 (V ),P 2 (K), P 3 (B|V ), P 4 (R|K), P 5 (H|K), P 6 (O|B, R), P 7 (L|O), P 8 (A|O, H).Figure 3 shows coherence graph conditional distributions owned nodesAsia network represent lower previsions, i.e., P 1 (V ), P 2 (K), P 3 (B|V ),P 4 (R|K), P 5 (H|K), P 6 (O|B, R), P 7 (L|O), P 8 (A|O, H). order avoid confusion,stress coherence graph built set lower previsions,arising graphical models. use Asia network illustrative purposes.Moreover, building coherence graph Asia net, completely disregardindependence information coded net, focus list conditionaldistributions. Also, coherence graph irrespective whether conditionalassessments linear not.adopt conventions display coherence graph: denote actual nodesletter corresponding variable; dummy nodes instead denoted blacksolid circles labelled. Finally, dummy node single parentsingle child, show arrow entering node, make graph simplersee.collection lower previsions turned coherence graph turninglower previsions subgraph called D-structure: directed graph consistingdummy node, directed predecessors (i.e., parents) successors (i.e., children),791fiZaffalon & Mirandaarcs connecting dummy node parents children. parentsdummy node actual nodes corresponding variables right-hand sideconditioning bar prevision related dummy node. childrenactual nodes corresponding variables left-hand side conditioningbar. example, D-structure P 1 (V ) subgraph Figure 3 consisting V ,dummy parent, arc connecting them; D-structure P 6 (O|B, R)subgraph consisting actual nodes B, R, O, dummy child first twoparent last one, three arcs connecting them.order distinguish coherence graph graphical models Bayesiannets, note coherence graph cannot deduce independence nodesgraph: instance, Figure 3 cannot conclude variables L, independentgiven O, H. reason instances conditional previsionscoherence graph variables L dependent.Coherence graphs different forms, forms implicationcoherence related collection lower previsions. paper focuscoherence graphs called type A1+ : coherence graphs acyclicproperty actual node graph exactly one parent. indeed casegraph Figure 3. general class graphs A1 graphs, definedsimilarly A1+ case difference actual node graphrequired one parent.coherence graph type A1+ (resp. A1), say related collectionlower prevision A1+ -representable (resp. A1-representable). A1-representable collectionsinteresting separate coherence lower previsions collectionequivalent joint coherence, shown Miranda Zaffalon (2009, Proposition 4).means A1-representable collections known coherent irrespectivenumbers make lower previsions, provided give rise separatelycoherent lower previsions.6.3 Updating Coherent Lower PrevisionsOne updating rule used lower previsions regular extension:Definition 13 Let P coherent lower prevision, f KOI x XI elementP (x) > 0, P nconjugate upper prevision derivedP . regularP (f Ix )extension R(f |x) R(f |x) := inf P (x) : P M(P ), P (x) > 0 .Recall M(P ) set linear previsions P domain L(X n ) dominate P .XI finite P (x) > 0 x XI , conditional lower prevision R(XO |XI )defined regular extension coherent P . definition shows regularextension also nice sensitivity analysis interpretation: i.e., applying Bayes ruledominating linear previsions whenever possible. Perhaps reason, regularextension proposed used number times literature updatingrule (e.g., De Campos, Lamata, & Moral, 1990; De Cooman & Zaffalon, 2004; Fagin &Halpern, 1991; Jaffray, 1992; Walley, 1981, 1991, 1996b).Example 5 Assume know coin loaded, sense either always landsheads tails, know which. Let Xi outcome throw792fiConservative Inference Rule= 1, 2. beliefs (X1 , X2 ) may modelled vacuous lower prevision P{(heads, heads), (tails, tails)}. apply regular extension define R(X2 |X1 ), obtainR(X2 = heads|X1 = heads) = 1, R(X2 = tails|X1 = tails) = 1,taking account P (heads, heads) + P (tails, tails) = 1 linear prevision PM(P ).6.4 Products Conditional Lower Previsionsshall later use generalisation marginal extension theorem (Walley, 1991, Theorem 6.7.2) established Miranda De Cooman (2007).Definition 14 Let P 1 (XO1 ), P 2 (XO2 |XI2 ), . . . , P (XOm |XIm ) separately coherent conditional lower previsions respective domains K1 , . . . , Km , I1 = Ij =nj1i=1 (Ii Oi ) = Ij1 Oj1 j = 2, . . . , m. marginal extension L(X )givenP (f ) = P 1 (P 2 (. . . (P (f |XIm )| . . . )|XI2 )),smallest unconditional coherent lower prevision (jointly) coherentP 1 (XO1 ), P 2 (XO2 |XI2 ), P 3 (XO3 |XI3 ), . . . , P (XOm |XIm ).see definition makes sense, note gamble f X n ,P (f |XIm ) gamble XIm , hence belongs domain P m1 (XOm1 |XIm1 );P m1 (P (f |XIm )|XIm1 ) gamble XIm1 belongs therefore domainP m2 (XOm2 |XIm2 ); repeating argument, P 2 (. . . (P (f |XIm )| . . . )|XI2 )gamble XI2 = XO1 belongs domain unconditional prevision P 1 .idea behind construction marginal extension that,hierarchical information, way combine joint prevision follow orderinformation structured. reduces, instance, law total probabilitycase linear previsions finite spaces. applicable generalsituations: combine finite number previsions, two them;dealing infinite spaces; lower previsions instead linearones.give next notion conditional independence coherent lower previsionsshall use following.Definition 15 Consider three variables, Xi , Xj , Xk , coherent conditional lower prevision P (Xi , Xj |Xk ). Xi Xj strongly independent conditional Xk Xi Xjstochastically independent given Xk extreme points M(P (Xi , Xj |xk ))xk Xk .previous definition allows joint beliefs created marginal ones, common independence precise probability: consider coherent conditional lower previsions P (Xi |Xk ) P j (Xj |Xk ). build so-called strong product P sp (Xi , Xj |Xk ),793fiZaffalon & Mirandai.e., least-committal lower prevision follows assumption strongindependence, lower envelope following set:Msp :={P (Xi , Xj |Xk ) := Pi (Pj (Xj |Xi , Xk )|Xk ) s.t.xk Xk ,Pi (Xi |xk ) ext(M(P (Xi |xk ))), P (Xj |xk ) ext(M(P j (Xj |xk )),xi Xi , Pj (Xj |xi , xk ) := P (Xj |xk )},Pj (Xj |Xi , Xk ) defined using stochastic independence, linear previsionP (Xi , Xj |Xk ) obtained applying marginal extension theorem.Strong independence relatively straightforward generalisation stochastic independence imprecision. also notion immediately given sensitivityanalysis interpretation: since every xk Xk extreme point M(P sp (Xi , Xj |xk ))satisfies stochastic independence, interpret P sp (Xi , Xj |Xk ) model arisingpartial knowledge underlying linear prevision P (Xi , Xj |Xk ) known satisfystochastic independence. words, P sp (Xi , Xj |Xk ) could regarded obtainedlisting number candidate linear previsions P (Xi , Xj |Xk ), satisfiesstochastic independence, taking lower envelope.also remarked imprecise case, work sets probabilities previsions, unique extension notion stochastic independenceprobability measures (see Campos & Moral, 1995; Couso et al., 2000; Miranda, 2008,Section 4). notion considered strongest, therefore informative, possibilities considered references above.20notion alternative strong independence instance epistemic irrelevanceproposed Walley (1991, Section 9.1.1).Definition 16 Given coherent lower previsions P (Xi |Xj , Xk ) P (Xi |Xk ), sayXj epistemically irrelevant Xi conditional Xk holds P (Xi |Xj , Xk ) =P (Xi |Xk ).Epistemic irrelevance naturally suited behavioural interpretation: Xj irrelevantXi given Xk context Xk beliefs subject Xi , expressedcoherent lower prevision P (Xi |Xk ), change getting know valueXj . sensitivity analysis interpretation epistemic irrelevance possible general joint created marginal information epistemic irrelevance,related extreme points necessarily satisfy stochastic independence. fact, strongindependence implies epistemic irrelevance converse implication hold.Moreover, irrelevance asymmetric notion: knowing Xj irrelevant Xiimply Xi irrelevant Xj . One create symmetric notion epistemic independence (see, e.g., Walley, 1991; Miranda, 2008) requiring Xj irrelevantXi Xi irrelevant Xj ; still, strong independence implies epistemic independenceway around hold.Strong independence expressed means epistemic irrelevance togetherrequirement. Consider P (Xi |Xk ) P j (Xj |Xk ); want create strong20. related fact never holds precise previsions convex setone element satisfy stochastic independence; therefore requiring extreme pointscredal set, ones keeping behavioural information, amounts go far possibledirection independence.794fiConservative Inference Ruleproduct using epistemic irrelevance. first write P j (Xj |Xi , Xk ) = P j (Xj |Xk ),strong independence implies epistemic irrelevance. apply marginal extensiontheorem create so-called irrelevant product P ip (Xi , Xj |Xk ) = P (P j (Xj |Xi , Xk )|Xk ),least committal lower prevision follows marginals assumption epistemic irrelevance. terms sets dominating linear previsions,marginal extension theorem states P ip (Xi , Xj |Xk ) lower envelope setMip :={P (Xi , Xj |Xk ) = Pi (Pj (Xj |Xi , Xk )|Xk ) : xi Xi , xk Xk ,Pi (Xi |xk ) ext(M(P (Xi |xk ))), Pj (Xj |xi , xk ) ext(M(P j (Xj |xi , xk )))}.Even xk Xk sets ext(M(P j (Xj |xi , xk ))), xi Xi , identical one anotherirrelevance condition, building joint prevision P (Xi , Xj |Xk )forced choose extreme point them. makesdifference Mip Msp , fact write Msp way similarMip follows:Msp :={P (Xi , Xj |Xk ) = Pi (Pj (Xj |Xi , Xk )|Xk ) : xi Xi , xk Xk ,Pi (Xi |xk ) ext(M(P (Xi |xk ))), Pj (Xj |xi , xk ) ext(M(P j (Xj |xi , xk )))s.t. Pj (Xj |x0i , xk ) = Pj (Xj |x00i , xk ) x0i = x00i }.words, think strong product obtained procedureuse irrelevant product, additional requirement xk Xk ,extreme points chosen ext(M(P j (Xj |xi , xk ))), xi Xi , must coincide every time.shall use observation Section 7.1.3.7. Derivation CIRnext sections state number assumptions, discuss them, eventually usederive CIR.7.1 Modelling Beliefsaim section represent beliefs vector (Z, Y, W ). intendmodel beliefs using coherent lower previsions. refer Sections 2 6 and,generally, book Walley (1991) concepts results shall need.way represent beliefs (Z, Y, W ) coherent lower prevision L(ZW), representing joint beliefs variables. But, precise probability,often easier build joint models composition simpler conditionalunconditional models. shall therefore start focusing following lower previsions,illustrate clarity coherence graph Figure 4:(LP1) coherent lower prevision, denoted P 1 , set XZ,Y -measurable gambles;(LP2) separately coherent conditional lower prevision P 2 (W |Z, ) set XZ,Y,W measurable gambles, modelling beliefs W given value (z, y) taken(Z, ).795fiZaffalon & Miranda)Z?j??Wqq?z*?WFigure 4: coherence graph initial conditional lower previsions express beliefs (Z, Y, W ).(LP3) conditional lower prevision P 3 (W |Z, Y, W ) L(Z W), representingbeliefs W given value (Z, Y, W ) takes.coherent lower prevision P 1 intended express beliefs domaininterest, modeled variables Z . words, P 1 expressbeliefs facts. conditional lower prevision P 2 (W |Z, ) concernedbeliefs unknown incompleteness process. Finally, conditional lowerprevision P 3 (W |Z, Y, W ) express beliefs CAR incompleteness process.exactly done detailed next sections. moment, goingbuild joint coherent lower prevision (Z, Y, W ) lower previsions listed(LP1)(LP3). done marginal extension theorem introduced Section 6.4.present case, generalised marginal extension theorem states lowerprevision P givenP (f ) = P 1 (P 2 (P 3 (f |Z, Y, W )|Z, ))gambles f Z W smallest (using point-wise ordering lowerprevisions) coherent lower prevision L(Z W) jointly coherentlower previsions listed (LP1)(LP3). implies, example, P coincidescoherent lower prevision P 1 domain. smallest lower previsioncoherent assessments, P captures behavioural implications presentP 1 , P 2 (W |Z, ) P 3 (W |Z, Y, W ), without making additional assumptions; shalltherefore use model beliefs vector (Z, Y, W ).P also lower envelope closed convex set M(P ) dominating linearprevisions. useful purposes paper construct set explicitly.Consider set()XM0 := P : P (g) = P1 (hg ), hg (z, y) :=g(z, y, w)P2 (w|z, y)P3 (w|z, y, w) ,(12)wg L(Z, Y, W), P1 ext(M(P 1 )), P2 (W |z, y) ext(M(P 2 (W |z, y)))P3 (W |z, y, w) ext(M(P 3 (W |z, y, w))) (z, y, w) Z W. M(P ) =CH(M0 ), operator CH() stands convex closure. consequence, Pcalculated lower envelope class M0 .796fiConservative Inference Rule7.1.1 Domain BeliefsConsider variables Z , represent facts. Beliefs facts, formcoherent lower prevision P 1 , specific domain consideration; reason,call domain beliefs. case Asia network, P 1 would correspond simplyjoint mass function coded network itself.shall impose minimal assumption domain beliefs, P 1 mustflexible tool possible order express beliefs wide range domains.task postponed focusing different kind beliefs, call beliefsincompleteness process.7.1.2 Beliefs Incompleteness Processnaturally conditional type: formalise believe modusoperandi overall IP, i.e., procedure turns facts observations.represent beliefs assumptions satisfied conditional lowerprevision P 2 (W |Z, ), related unknown IP, P 3 (W |Z, Y, W ), related CARIP. start unknown IP.unknown IP introduced formalise idea incompleteness processnearly ignorant. term nearly emphasise that, despitedeep kind ignorance, something assumed known unknown IP. onething, produces incompleteness basis . formally, assumeseparately coherent conditional lower prevision P 2 (W |Y )P 2 (f |z, y) = P 2 (f |y)(BIP1)XW ,Y,Z -measurable gambles f (z, y) (Z, Y).(BIP1) states observing different values Z change beliefsW , know value takes Y. assumption turns coherence graphFigure 4 Figure 5. Assumption (BIP1) arises somewhat naturally withininterpretation IPs observational processes, regard unknown IPprocess takes input outputs W . Still, important assumptionfollowing developments, therefore discussed detail Section 7.2.)Z??Wqq?z*?WFigure 5: coherence graph Figure 4 application Assumption (BIP1).797fiZaffalon & Mirandasecond thing assume unknown IP related perfectionmulti-valued map :21(BIP2)P 2 ((y)c |y) = 0.words, assumption practically exclude possibilityY, unknown IP may lead observations outside (y). Note welldefined, important assume (y) nonempty required (IP4). Rememberthat, elsewhere, use P refer conjugate upper prevision P ; seeRemark 1 details.Nothing assumed unknown IP. led introduceassumptions CAR IP, first two analogous (BIP1) (BIP2),respectively. first one existence separately coherent conditional lower prevision P 3 (W |Y )P 3 (f |z, y, w) = P 3 (f |y)(BIP3)XW,Y,Z -measurable gambles f (z, y, w) (Z, Y, W). assumption turnscoherence graph Figure 5 Figure 6.)Z??Wq?WFigure 6: coherence graph Figure 5 application Assumption (BIP3).second assumption perfection multi-valued map :P 3 ((y)c |y) = 0.(BIP4)Again, assumption made possible (IP5).assume something substantial CAR IP. Indeed, CAR IPintroduced model process produces incompleteness random fashion,say, way related underlying value takes Y.model belief follows:w W, {w} P 3 (w|y) = P 3 (w|y) = w ,(BIP5)Pw positive constants satisfy w(y) w = 1, restrictionw (y) justified (BIP4).assumption usually called coarsening random (or CAR, see Gill et al., 1997).special case missingness processes, one usually refers CAR missing random(or MAR, see Little & Rubin, 1987). CAR/MAR probably frequently imposed21. could argued assumption corresponding one CAR IP, is, (BIP4), followdefinition multi-valued maps. nevertheless, state assumptions explicitlyclarity.798fiConservative Inference Ruleassumption IPs literature; embodies idea IP non-selective (ornon-malicious) producing observations. Together (BIP4), makes conditionalprevision P 3 (W |Y ) precise: i.e., beliefs CAR IP determinate (theyconditional expectation respect probability distribution). importantpoint must require explicitly compatible CAR assumption(see Appendix details); leads assumption reportedSection 3.3: assumeleads (BIP5) admissible system linear constraints,(IP9)is, one solution.characterised unknown CAR IPs, also determine way interact make overall IP; imposingassumption strong independence, introduced Section 6.4:W W strongly independent conditional Y.(BIP6)assumption discussed Section 7.2.227.1.3 Joint Beliefssection aim constructing joint coherent lower prevision P mentionedbeginning Section 7.1. that, need first find explicit representationsassessments related unknown CAR IP, basis Assumptions (BIP1)(BIP6). joint constructed using marginal extension theorem mentionedbeginning section, taking account assumption strong independence (BIP6).Consider unknown IP. Assumption (BIP1) allows us focus attentionconditional lower prevision P 2 (W |Y ). Thanks Assumption (BIP2), knowY, P 2 (W |y) gives lower probability one (y). Since know nothing else,take P 2 (W |y) least-committal lower prevision, i.e., smallest separatelycoherent conditional lower prevision assigns probability one (y). lowerprevision also called vacuous relative (y), given P 2 (f |y) = min{f (w, y) :w (y)} XW ,Y -measurable gamble f .2322. similarities model developed section traditional hiddenMarkov models (see instance Rabiner, 1989). First, focus distinction twolevels information, latent manifest one, discussed Introduction. reasonconcerned explicit representation observational process, relatesW variables, case coincides incompleteness process. referFigure 6, make things concrete, see W -variables manifest dependdirectly related hidden -variables. common representation hidden Markovmodels. Second, Assumption (BIP6) could interpreted kind Markovianity property. Yet,also differences: major one two W -variables related order (such time order),generally explicitly representing order model. Anotherquantify probabilistic information observation conditional related hidden variableset conditional mass functions rather single one. gives us expressivity keymodel unknown IP.23. follows implication (BIP2) actually equivalence.799fiZaffalon & MirandaUsing indicator functions, easily write extreme points M(P 2 (W |y)). Let: W {0, 1} indicator function (y). write rather I{}simplify notation. ext(M(P 2 (W |y))) = {I : (y)}. concludes definitionP 2 (W |y) also P 2 (W |z, y), given coincide. Yet, dealingP 2 (W |z, y), shall use slightly different formulation: ext(M(P 2 (W |z, y)) = {I(z,y) :(z, y) (y)}. reason extended notation (z, y) allows us know,addition vertex, value (z, y) focus, and, consequently, focusspecific lower prevision P 2 (W |z, y). Hence, shall see mapping ZW (z, y), (z, y) belongs (y).situation somewhat easier CAR IP. Similarly previous case,know restrict attention conditional lower prevision P 3 (W |Y ),thanks (BIP3). also know conditional lower prevision P 3 (W |Y )actually precise (we shall denote P3 (W |Y ) on), P3 (W |y) consistssingle mass function determined Assumption (BIP5): i.e., mass function assignsprobability P (w|y) = w I{w} (y) generic element w W.point define coherent lower prevision P models beliefsvalue (Z, Y, W ) assume jointly. rewriting Expression (12) accordingprevious arguments using addition (BIP6):M0 := {P : P (g) = P1 (hg ), hg (z, y) =Pww g(z, y, w)I(z,y) (w)I{w} (y)I{w} (y),P1 ext(M(P 1 )), (z, y) (y) s.t. (z, y) = (z 0 , 0 ) = 0 ,(z, y, w) Z W},(13)introduced new term I{w} (y). term actually redundant,introduced convenient next developments. seeredundant, note I{w} (y) = 0 implies w/ (y) hence, since (z, y) (y)definition, I(z,y) (w) = 0. usage (BIP6), hand, leadssubstantial introduction requirement (z, y) = (z 0 , 0 ) = 0 .needed represent strong independence means epistemic irrelevance, discussedend Section 6.4. lower envelope P set M0 thus constructed thereforecalled strong product assessments P 1 (Z, ), P 2 (W |Y ), P3 (W |Y ).strong product coherent lower prevision, also coherentP 1 (Z, ), P 2 (W |Y ), P3 (W |Y ), follows Corollary 1 Appendix B. Importantly,also case coherent lower prevision P 1 (Z, ) constructed modular waysmaller pieces information (i.e., joint coherent number smallerpieces information), provided coherence graph representing A1+ ;situation often case. case, instance, examplesSections 5.15.3, shown Corollaries 35 Appendix B.7.1.4 Assumption Domain BeliefsRecall introduced W way model observations, hence beliefsconsistent possibility observation. extent,seems necessary least believe {w} produced:w W P ({w} ) > 0,800(DB1)fiConservative Inference Ruletaking account coherence implies P ({w} ) = P 1 ({w} ). Assumption (DB1)equivalent existence extreme point P1 M(P 1 ) P1 ({w} ) > 0.following proposition shows assumption sufficient make beliefs consistentpossibility observation w.Proposition 1 Assumption (DB1) implies P (w) := P (Z, Y, w) > 0.Proof. Let P1 extreme point M(P 1 ) satisfying P1 ({w} ) > 0, existsEquation (DB1), take (z, y) = w {w} . joint P constructedEquation (13) satisfies P (w) = w P1 ({w} ) > 0. Hence, P (w) > 0. 27.2 Assumptions Discusseddiscuss (BIP1), (BIP5) (BIP6) detail. assumptions quiteweak relatively easy accept. Assumptions (BIP2) (BIP4) may exceptionsmakes sense consider IPs imperfect (or lie),scope present paper.start Assumption (BIP5), i.e., CAR. CAR models processcoarsen facts specific purpose. CAR excludes way many common important processes. Consider medical domain, example, focusing diagnosticapplication. fact case might describe information patient, gender,age, lifestyle, also results medical tests. Conclusions would madepossible diseases. IP case (at least part it) often results interactiondoctor patient; indeed, usually systematic bias reporting,asking for, symptoms present instead symptoms absent;bias report, ask for, urgent symptoms others (Peot & Shachter, 1998).Furthermore, doctor typically prescribes subset possible diagnostic tests,according personal views cost/benefit criteria.24 Overall, process describednon-CAR definition, incompleteness arises following patterns dependspecific facts consideration.Descriptions one support idea CAR strong meansinformal arguments. also formal level, recent research suggested CARassumed hold less frequently appears practice (Grunwald &Halpern, 2003); one also remember way test CAR statistically(Manski, 2003), always degree arbitrariness assuming it.taken account order put CAR balanced perspective.say CAR rejected priori, situations CARcompletely justified. Consider one notable example: case knowmissing probability equal one. case related IP clearly satisfies MAR:probability missingness one irrespective value . broadly speaking, MARholds processes produce missingness unintentional way. cases,24. seems support idea shall hardly get ever rid incompleteness: often, incompletenesshappen mistake, rather, generated deliberately. cases actually representspatterns knowledge (indeed, one often tell disease patient was, not, suspectedlooking medical tests doctor did, not, prescribe). sense,seems incompleteness doomed deeply rooted many, most, real problems;such, appears fundamental, indissoluble, component uncertain reasoning.801fiZaffalon & Mirandaassuming MAR would lead results far weak. CAR IP modellingframework presented Section 7.1.2 designed account situations: i.e.,provide one flexibility stating beliefs incompleteness process withoutadopt necessarily worst-case approach (as opposed best case embodiedCAR/MAR), kind unknown IP.unknown IP designed model ones ignorance incompleteness process.makes sense adopt conservative approach model IPs practice, two specificreasons: first, IPs may difficult processes model. special caseobservational processes, often result human-to-human interaction,complex factors; number cases actually regarded resultcommunication protocol. medical example intended illustrate this.saying anything new: difficulty modelling IPs pointed already longago (Shafer, 1985; Grunwald & Halpern, 2003). IPs difficult objects handle alsosecond reason: IP models tightly dependent specific situations. Considermedical example: different doctors typically ask different questions diagnosedisease, even hospital. changing hospital, one find entirely differentprocedures diagnose disease, procedures depend local culture,money available make tests, ones, local time constraints.words, even one able model IP specific situation, model maylonger appropriate another doctor charge diagnosis, onetries apply IP model another hospital, perhaps another country. summary,modelling IP (especially precise way) may present serious practical difficulties,as, contrast domain beliefs (e.g., medical knowledge), way informationaccessed may well depend particular environment system used;means models IP may easily reusable, may therefore costly.arguments support considering conservative approach model IPeffectively implemented, reason introducing unknown IPSection 7.1.2. Recall unknown IP actually nearly unknown,require (BIP1) holds. hand, observe dropping (BIP1) coulddraw vacuous conclusions Z. see this, suppose want predictprobability Z = z given certain observation w. Assume endsection CAR IP, order make things easier. withoutassuming (BIP1), could exclude possibility IP produces wZ 6= z, probability Z = z zero. way, could excludepossibility IP produces w Z = z, probability Z = zone. course, intermediate randomised cases would also possible,probability would vacuous. emphasise, perhaps surprisingly, completeignorance IP consistent possibility drawing useful conclusions.said this, still useful wonder whether (BIP1) reasonable presentsetup. easier rewrite (BIP1) somewhat natural form. focusspecial case spaces possibilities finite precise beliefsunknown IP. multiply sides equation P (w|z, y) = P (w|y)conditional probability z given y, obtaining P (z, w|y) = P (z|y)P (w|y). newequation states variables Z W independent conditional . words,original assumption equivalent saying already know fact y, making802fiConservative Inference Ruleobservation w completely superfluous predicting target variable. appearsnothing else precise characterisation problems incomplete missinginformation: problems characterised fact somethingmissing actually measured, problem missing information disappears.case, observation w would carry information z via implicationsfact y: would say something z also own. meansinformation useful predict target variable included definitionpossible facts (see work De Cooman & Zaffalon, 2004 discussionassumption called MDI related assumption consideration).conclude section discussing Assumption (BIP6), namely strong independenceW W conditional . discuss assumption one could principleconsider weaker notions independence replace strong independence.reason used strong independence kind general framework developed technically quite difficult embed judgmentsindependence W W conditional . hand, problem strongindependence easily lend full behavioural interpretation unlike notions, epistemic irrelevance independence. acknowledgebehavioural interpretation important way guide mathematicaldevelopments one comes decision making.Yet, one could argue inference rule, CIR, follows assumptionsweakest possible one (if exclude rule leads vacuous posterior expectationslead informative conclusion) part related unknownIP, leads consider replacements missing informationpossible latent data. Therefore one could conjecture replacing strong independenceW W conditional weaker notion independence, inference rulecould either stay lead vacuous inferences. Whatever outcome, choicestrong independence would even reasonable.7.3 Derivation CIRorder formulate basic problem paper sufficiently general way, focusproblem updating beliefs generic function g : Z R, posterior beliefsconditional W = w. precise case, would done computingP (g|w) =P (gIw ),P (w)provided P (w) > 0.Something similar done imprecise case, case uncommonP (w) zero. case, obtain infinite number conditional lowerprevisions coherent P (W ). already discussed De CoomanZaffalon (2004), proposed regular extension effective updating rule.natural choice also sensitivity analysis interpretation coherentlower previsions, pointed Section 6.3, therefore also choicepursue. Using regular extension entails additional rationality assumptionreported Walley (1991, Appendix J3); coherence unconditional lower prevision derived trivial present context, W finite (see Appendix B803fiZaffalon & Mirandadetails). also recall P (w) > 0, regular extension providescoherent updated lower prevision.form CIR rule given Definition 7 Section 4 derived next theorem.important remark theorem hold, need require spaceunknown IP finite, necessary results establishAppendix B. reason infinite class {w}1 definetheorem may empty w W, making rule inapplicable.Theorem 1 (Conservative inference rule theorem) Consider gamble g Zw W. Let {w}1 := {y {w} : P 1 (y, {w} ) > 0}, let us define regular extensionR(g|y, {w} ) =infP P 1 :P (y,{w} )>0P (g|y, {w} ){w}1 .R(g|w) = E 1 (g|w) := min R(g|y, {w} ).y{w}1Proof. First all, prevision P constructed using Equation (13),XXP (w) = wP (y, {w} ) = wP (y, {w} ),(14)y{w} ,(z,y)=wyY,(z,y)=ww W, second equality follows Assumption (BIP2), also takingaccount mapping depends value . Similarly, alsoXXP (gIy,{w} ) = wP (gIy,{w} )P (gIw ) = wy{w} ,(z,y)=wyY,(z,y)=ww W gamble g Z.Fix w W, define := {P P 1 : P (w) > 0}, M1 := {P P 1 : P (y, {w} ) >0 {w} }. gambles g Z, R(g|w) = inf{P (g|w) : P M}E 1 (g|w) = inf{P (g|y, {w} ) : P M1 }.start proving E 1 (g|w) R(g|w). this, going prove{w} P M1 P (y, {w} ) > 0 P 0P 0 (g|w) P (g|y, {w} ). Consider P , let P1 restriction L(Z Y).P1 P 1 . Let mapping (z, y) = w (z 0 , 0 ) 6= w 0 6= y.construct mapping Assumption (IP8) set {w} empty,0therefore every 0 {w} w 6= w 0 {w0 } . Let P 0 Pjoint prevision constructed P1 using Equation (13). Taking accountEquation (14), see prevision satisfies P 0 (w) = w P 0 (y, {w} ) = w P (y, {w} ) >0. consequence,P 0 (g|w) =w P 0 (gIy,{w} )P (gIy,{w} )P 0 (gIw )=== P (g|y, {w} ),P 0 (w)w P 0 (y, {w} )P (y, {w} )last equality holds P (y, {w} ) > 0. Hence, deduce E 1 (g|w)R(g|w).804fiConservative Inference Ruleshow converse inequality. going prove PP 0 M1 P (g|w) P 0 (g|y, {w} ). Consider P M.PPw y{w} ,(z,y)=w P (gIy,{w} )P (gIw )y{w} ,(z,y)=w P (gIy,{w} )PP=P (g|w) ==.P (w)w y{w} ,(z,y)=w P (y, {w} )y{w} ,(z,y)=w P (y, {w} )Define := {y {w} s.t. P (y, {w} ) > 0, (z, y) = w}. Since P (w) > 0, followsEquation (14) set nonempty, equality expressedPyI P (gIy,{w} )P (g|w) = P.yI P (y, {w} )Applying Lemma 3 Appendix deduce existence y1PP (gIy1 ,{w} )y{w} ,(z,y)=w P (gIy,{w} )P.P (y1 , {w} )y{w} ,(z,y)=w P (y, {w} )Let P1 restriction P L(Z Y). Consider mapping (z, y) = w= y1 (z 0 , 0 ) 6= w 0 . construct mappingAssumption (IP8) set {w} empty, therefore every 0 {w}0w 6= w 0 {w0 } . Let P 0 P joint prevision constructed P1using Equation (13). prevision satisfies P 0 (y1 , {w} ) = P (y1 , {w} ) > 0. Moreover,PP 0 (gIy1 ,{w} )P (gIy1 ,{w} )y{w} ,(z,y)=w P (gIy,{w} )0PP (g|y1 , {w} ) = 0= P (g|w),=P (y1 , {w} )P (y1 , {w} )y{w} ,(z,y)=w P (y, {w} )second equality follows P 0 = P = P1 L(Z Y). deduceE 1 (g|w) R(g|w) consequence equal. 2important point whether lower prevision defined CIR ruletheorem going coherent initial assessments: P 1 (Z, ), P 2 (W |Y ), P3 (W |Y ).want case want CIR lead self-consistent inference. questiongiven positive answer Theorem 3 Appendix B.Moreover, theorem also deduce (in subsequent Corollary 2) coherence also maintained much general conditions: one hand,examples application CIR rule discussed Sections 5.15.3,P 1 (Z, ) obtained making strong product number conditional lower previsions P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ). consider set variables interest{X1 , . . . , Xn } contains {Z, } include W . assume moreovercoherence graph associated P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) A1+ ,follows (see Appendix B)i=1 (Ii Oi ) = i=1 Oi = {1, . . . , n}. instancesituation given Figure 7.Corollary 2 Appendix B shows coherence also holds general situation.hand, corollary also proves coherence maintained applyregular extension finite number conditioning events, thus actually creatingadditional finite number coherent lower previsions original assessments:assessments going jointly coherent. another important resultpractice one indeed often conditions number events. theoretical results giveus guarantees CIR rule well-behaved.805fiZaffalon & MirandaRBHw? - sff??ZFigure 7: general model.8. Conclusionspaper introduced new rule update beliefs incompletenesscalled conservative inference rule (CIR). CIR designed explicitly takingconsideration problem modelling process makes observations incomplete, called incompleteness process (or IP). representedprocess made two sub-processes, one non-selective anotherunknown us. consequence, CIR deals differently data knowncoarsened random ones. first case CIR treats usingCAR/MAR assumption, taking completions incomplete data.CIR regarded generalisation traditional, Bayesian rule updatebeliefs recently proposed conservative updating rule (De Cooman & Zaffalon,2004). CIR generalisation two rules enables one consider mixed situations. make CIR quite flexible rule applications. Moreover,enables CIR avoid risk overconfident IP, problemtraditional updating, well avoid over-pessimistic may happenconservative updating rule.CIR also general rule. used coarsened missing data,statistics well expert systems, applied predict statetarget variable irrespective cardinality space possibilities. indeedtried illustrate characteristics using number application domains. Moreover,using examples shown CIR makes quite difference traditionalCAR/MAR-based way dealing incomplete data: examples traditionalupdating shown lead conclusions hardly justifiable evidencehand, and, even worse, way user may realise this.cases CIR instead naturally cautious clearly communicates userlimits strength possible conclusions, logical consequence strength(or weakness) available information.Finally, CIR nice theoretical properties, notably coherent rule.Loosely speaking, means using CIR possible give rise probabilisticinconsistencies. seen Theorem 3 Appendix B, assumptionsrequire coherence CIR fairly general: initial assessments specialkind, characterised using graphical structure called coherence graphtype A1+ , require possibility spaces involved analysisfinite conditioning events spaces positive upper probability.806fiConservative Inference Rulehypotheses guarantee use Walleys notion regular extension updatebeliefs assessments thus obtained coherent initial assessments.like conclude section commenting also bit assumptionsconsidered construction model open problemsderive work.One point requirement spaces possibilities finite. couldrelaxed taking account conditional prevision defined regular extensioncoherent unconditional derived even infinite case. However,cannot guarantee third point Lemma 2 Appendix B holdsgeneral situations, point necessary proof Theorem 3. relatednotion conglomerability discussed much detail Walley (1991). open problemwould extend results general situations addressing questionconglomerability. hand, said, results applicable eventarget space Z variable interest, Z, infinite. allowed us, instance,model parametric inference case parameter space infinite, discussedSection 5.2. Moreover, assuming upper probability values Zpositive, allows us include case prior beliefs parameterprecise parameter space infinite, coincides traditional setup.Another important point assumption domains lower previsions:required instance P 1 (Z, ) defined set XZY -measurablegambles. Similar considerations made P 2 (W |Y ) P 3 (W |Y ).requirements met, still apply results extending assessmentsusing notion natural extension given Walley (1991). easy seeextensions satisfy hypotheses theorems. considerations allow uscover particular case lower probabilities instead lower previsions.interesting feature CIR rule derived Theorem 1 allows usmake passage updated information Z knowing observation Winformation Z knowing value takes. think keyusing vacuous linear previsions express information providesW , i.e., components incompleteness process either unknownrandom. open problem determine whether possibilities allowingus analogous property. Similarly, would interesting studyassumptions incompleteness process weakened.conclude, CIR new rule update beliefs incompleteness, general,based solid theoretical foundations. gives us first time opportunityavoid optimistic pessimistic incompleteness process, thuscreating basis draw credible strong enough conclusions number applications.say regard CIR last word subject. contrary,seems us research IPs far scratched surface uncertain reasoningincompleteness. particular, probably number applicationsrules stronger CIR (yet based tenable assumption traditional updating)needed. Developing rules appears important research avenue.investigation probably directed primarily creating new assumptionsIPs make resulting rule stronger still general enough. way couldusing starting point framework developed here. particular, one could807fiZaffalon & Mirandatake Assumptions (IP1)(IP9), (BIP3)(BIP6) (DB1) are, strengtheningrelated unknown IP, is, (BIP1) (BIP2). machinery usedderive CIR could used derive new rule follows strongerassumptions. new assumptions impose whether lead ruleuseful domain-specific matter future investigation.AcknowledgmentsPreliminary work topic paper appeared proceedings ISIPTA 05:fourth International Symposium Imprecise Probabilities Applications(Zaffalon, 2005). like thank reviewers paper commentshelped improve clarity readability. work partially supported SwissNSF grants n. 200020-116674/1 200020-121785/1, projects TIN2008-06796C04-01, MTM2007-61193.Appendix A. CAR Assumption (IP9)important realise multi-valued maps consistentCAR assumption. example: take := {1, 2, 3, 4}, W := {a, b, c}, definemulti-valued map (1) := {a, b}, (2) := {b, c}, (3) := {a, c}, (4) := {a, b, c}.(BIP5), P3 (a|1) = P3 (a|3) = P3 (a|4) = , P3 (b|1) = P3 (b|2) =P3 (b|4) = b , P3 (c|2) = P3 (c|3) = P3 (c|4) = c . Requiring addition nonnegativity probabilities conditional mass functions normalised, leadsfollowing system linear constraints:+ b = 1b + c = 1+ c = 1+ b + c = 1, b , c 0.system solution, adding first three equations deduce +b +c =1.5, incompatible fourth equation. Therefore CAR processconsistent defined above.example shows order define properly, need add (IP9)assumption (IP5) (IP7): system linear constraints originated(BIP5) solution, namely, admissible. Checking admissibilityeasy finite hence number constraints system; allowsone use standard techniques linear programming solve problem.example also points another question, concerns relationship Gillet al.s well-known CAR everything theorem (Gill et al., 1997, Section 2). Looselyspeaking, theorem states, precise probability context, always possibledefine CAR process; example seems contradict theorem.order show actually contradiction, need represent examplesetup Gill et al.s paper, focused random sets. means808fiConservative Inference Ruleregard W variable takes values powerset Y, hence CARIP intended function maps elements subsets itself.make transition, identify element w W correspondingset {w} ; example, possible values W , interpreted random set,{1, 3, 4}, {1, 2, 4}, {2, 3, 4}. intuition element 1coarsened CAR IP set {1, 3, 4} {1, 2, 4}; element 2 {1, 2, 4}{2, 3, 4}; element 3 {1, 3, 4} {2, 3, 4}; element 4 {1, 3, 4}, {1, 2, 4}{2, 3, 4}. correspondence really consistent, also need make surezero probability assigned elements power set correspondsets {w} , w W; necessary (BIP4) Gill et al.ssetup explicitly use notion multi-valued mapping. backgroundtake closer look relationship example Gill et al.s theorem.theorem states, language, matter W distributed,one find unconditional mass function CAR process lead Wdistributed way. select unconditional mass function randomset W respects constraint assigning zero probabilities above, actuallyimplementing multi-valued map example, know CARprocess consistent it.key solve paradox Gill et al. allow CAR-IP probabilities P3 (Y 0 |y)non-zero set 0 includes y, sets determinedmulti-valued map, do. freedom makes possible always find CAR process.Consider example above, assume W distributed uniformlythree sets {1, 3, 4}, {1, 2, 4}, {2, 3, 4}: i.e., assigned probability equal 13 .make choice consistent CAR process choosing {1,3,4} := {1,2,4} :={2,3,4} := 13 (i.e., := b := c := 31 ) if, addition, set {1} := {2} := {3} := 13 ,i.e., allow CAR process able potentially output three sets.since know three sets cannot really returned, obliged alsoset P (1) := P (2) := P (3) := 0, thus solving problem, although arguably somewhatartificial way.Indeed, since forced set zero probability elements Y, onemight wonder elements included set Y. Precisely observationalready used source criticism Gill et al.s CAR everything theorem(Grunwald & Halpern, 2003, Section 4.4), leading authors latter paper saycases like actually CAR process. formulation basedmulti-valued map simply confirms statement alternative way.Appendix B. Coherence CIRappendix, going prove assessments constructionconservative inference rule satisfy notion coherence moreover alsocoherent probabilistic assessment deduce using CIR.so, want cover also case unconditional prevision P 1 (Z, ) constructednumber conditional unconditional previsions, typicalcase practice. shall use notations established Section 2 Section 6.809fiZaffalon & Mirandaconsider variables X1 , . . . , Xn taking values respective sets X1 , . . . , Xn , takecollection conditional previsions P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ).start lemma shows A1 graphs naturally entail notion ordercorresponding lower previsions: particular, possible permute indexeslower previsions way admissible paths two dummynodes index origin precedes destination.25Lemma 1 coherence graph {P 1 (XO1 |XI1 ), . . . , P (XOm |XIm )} A1,may assume without loss generality k = 1, . . . , m, Ok (k1i=1 Ii ) = .Proof. start proving Ok (mi=1 Ii ) = k. Assume ex-absurdohold. k {1, . . . , m} f (k) 6= k Ok (k) 6= .Define z0 := 1, zk := f (zk1 ) k 1. must {zk } {z0 , . . . , zk1 } = k 1,establish cycle coherence graph, contradicting thus A1. Hence,|{z0 , z1 , . . . , zk1 }| = k k 1, means zm exist, or, equivalently,Ozm1 Ii = = 1, . . . , m. Hence, k Ok (mi=1 Ii ) = .assume without loss generality k = m.prove k 6= Ok (m1i=1 Ii ) = . Assume ex-absurdohold. k {1, . . . , 1} g(k) 6= k,Ok Ig(k) 6= . Define z0 := 1, zk := g(zk1 ) k 1. must {zk } {z0 , . . . , zk1 } =k 1, establish cycle coherence graph, contradicting thusA1. Hence, |{z0 , z1 , . . . , zk1 }| = k k 1, means zm1exist, or, equivalently, Ozm2 Ii = = 1, . . . , 1. Hence, k 6=Ok (m1i=1 Ii ) = . assume without loss generality k = 1.similar reasoning allows us deduce existence order {1, . . . , m}Ok (jk Ij ) = k = 1, . . . , m. Finally assume without loss generalityorder coincides natural order. 2restrict attention particular case A1+ graphs. Lemma 1,collection P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) A1+ -representable, assume withoutloss generality I1 = . Let A1 := , Aj := j1i=1 (Ii Oi ) j = 2, . . . , + 1, letP 0j (XOj |XAj Ij ) given set Hj XAj+1 -measurable gambles j = 1, . . . ,P 0j (f |z) := P j (f (z, )|Ij (z))z XAj Ij f Hj . Since P j (XOj |XIj ) separately coherent j =1, . . . , m, P 0j (XOj |XAj Ij ). Moreover, thanks Lemma 1 {O1 , . . . , Om }forms partition {1, . . . , n} focus A1+ graphs, sets indexesconditional variables P 01 (XO1 ), . . . , P 0m (XOm |XAm Im ) form increasing sequencehence satisfy hypotheses generalised marginal extension theorem.consequence, P 01 (XO1 ), . . . , P 0m (XOm |XAm Im ) also coherent.similar reasoning shows take j = 1, . . . , conditional linear prevision0 (XPj0 (XOj |XAj Ij ) dominates P 0j (XOj |XAj Ij ), P10 (XO1 ), . . . , PmOm |XAm Im )jointly coherent. Moreover, since {O1 , . . . , Om } partition {1, . . . , n}, Theorem 325. order notion similar graph-theoretic notion topological ordering, applieddummy nodes.810fiConservative Inference RuleMiranda De Cooman (2007) implies prevision P X n coherent0 (Xassessments P10 (XO1 ), . . . , PmOm |XAm Im )0P (f ) = P10 (P20 (. . . (Pm(f |XAm Im )| . . . )|XA2 I2 )).(15)0 (Xwords, P10 (XO1 ), . . . , PmOm |XAm Im ) give rise unique joint lower prevision.Definition 17 Assume P (XOj |XAj Ij ) dominates P 0j (XOj |XAj Ij )j = 1, . . . ,inf P (XOj |XAj Ij ) = P 0j (XOj |XAj Ij ).coherent lower prevision P defined P := inf P , P coherent previsiondetermined P (XO1 ), . . . , P (XOm |XAm Im ) Equation (15), called lower envelopemodel.Intuitively, lower envelope model joint lower prevision built numberconditional unconditional assessments. interest lower envelope models arisescommon practice build joint models smaller conditionalunconditional ones, use joint model draw conclusions. Lowerenvelope models abstract procedure general case coherent lower previsions.particular cases lower envelope models, consider following:1. j = 1, . . . , consider P (XOj |XAj Ij ) M(P 0j (XOj |XAj Ij )),P marginal extension P 01 (XO1 ), . . . , P 0m (XOm |XAm Im ).2. j = 1, . . . , take P (XOj |XAj Ij ) set extreme pointsM(P 0j (XOj |XAj Ij )), additional requirement P (XOj |z) = P (XOj |z 0 )Ij (z) = Ij (z 0 ), lower envelope model P called strong productP 1 (XO1 ), . . . , P (XOm |XIm ).paper, make inferences using strong product. results Miranda De Cooman (2007), let Pj (XOj |XIj ) extreme point M(P j (XOj |XIj ))j = 1, . . . , build linear prevision P manner described above,P, P1 (XO1 |XA1 I1 ), . . . , Pm (XOm |XAm Im ) coherent. Moreover, deduce following:Theorem 2 Let P 1 (XO1 ), . . . , P (XOm |XIm ) A1+ -representable collection, letP lower envelope model associated it. P , P 1 (XO1 ), . . . , P (XOm |XIm )coherent.Proof. consequence marginal extension theorem Miranda De Cooman(2007) previsions P , P (XO1 |XA1 I1 ), . . . , P (XOm |XAm Im ) coherent. Applying Theorem 8.1.6 Walley (1991), deduce lower envelopesfamilies, lower previsions P , P 01 (XO1 |XA1 I1 ), . . . , P 0m (XOm |XAm Im ),also coherent. result follows applying gamble f Kj belongs Hj ,P 0j (f |XAj Ij )(x) = P 0j (f (Aj Ij (x), )|Aj Ij (x)) = P j (f (Ij (x), )|Ij (x))x X n. 2following useful corollary theorem:811fiZaffalon & MirandaCorollary 1 Let P strong product P 1 (Z, ), P 2 (W |Y ), P3 (W |Y ), constructedSection 7.1.3. P coherent also jointly coherent original assessmentsP 1 (Z, ), P 2 (W |Y ), P3 (W |Y ). holds also P 1 (Z, ) constructed jointcoherent number smaller pieces information, provided coherence graphrepresenting A1+ .Proof. P coherent lower prevision follows lower envelopeset linear previsions. coherence P 1 (Z, ), P 2 (W |Y ), P3 (W |Y ) followsTheorem 2, coherence graph P 1 (Z, ), P 2 (W |Y ), P3 (W |Y ) A1+ ,evident Figure 6. general situation P 1 (Z, ) constructedmodular way result follows similarly coherence graph representingassessments together P 2 (W |Y ), P3 (W |Y ) also A1+ . 2prove next use regular extension derive new conditional previsionsP m+1 (XOm+1 |XIm+1 ), . . . , P m+k (XOm+k |XIm+k ) strong product P , conditional previsions coherent initial assessments. this, need establishfirst following:Lemma 2 Let P , P (XO |XI ) coherent unconditional conditional previsions, XIfinite. Let R(XO |XI ) defined P using regular extension z XI P (z) > 0,equal P (XO |z) P (z) = 0. Then:1. P , R(XO |XI ) coherent.2. R(XO |XI ) P (XO |XI ).3. P P , P (XO |XI ) coherent P dominatesP (XO |XI ).Proof. Since XI finite set, apply Theorem 6.5.4 book Walley(1991) deduce coherence P , R(XO |XI ) equivalent P (Iz (f R(f |z))) = 0z XI .26 P (z) = 0, trivial. P (z) > 0, follows Walley (1991,Appendix J3).second statement, consider z XI P (z) > 0, f KOI . Assumeex-absurdo R(f |z) < P (f |z). follows definition regular extensionP P P (z) > 0 P (f |z) < P (f |z). Since P (z) > 0,follows generalised Bayes rule P (f |z) unique value satisfying 0 =P (Iz (f P (f |z))). consequence, given P (f |z) > P (f |z), Iz (f P (f |z))Iz (f P (f |z)), whence0 = P (Iz (f P (f |z))) P (Iz (f P (f |z))) P (Iz (f P (f |z)) = 0,using since P , P (XO |XI ) coherent satisfy generalised Bayes rule.implies P (Iz (f P (f |z))) = P (Iz (f P (f |z))) = 0, two differentvalues P (Iz (f )) = 0. contradiction.26. called generalised Bayes rule. P (x) > 0, unique value P (G(f |x)) =P (Ix (f P (f |x))) = 0 holds.812fiConservative Inference Rulefinally establish third statement. Consider P P , z XI . P (z) > 0,f KOI P (f |z) uniquely determined generalised Bayes ruledominates regular extension R(f |z). Hence, P (f |z) R(f |z) P (f |z),last inequality follows second statement. Finally, P (z) = 0, taking elementP (XO |z) M(P (XO |z)) P (Iz (f P (f |z))) = 0 f KOI .completes proof. 2establish next result, need introduce consistency notion conditional lower previsions less restrictive coherence:Definition 18 Let P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) separately coherent conditional previsions. weakly coherent fj Kj , j = 1, . . . , m, j0 {1, . . . , m},f0 Kj0 , z0 XIj0 ,XsupGj (fj |XIj ) Gj0 (f0 |z0 ) (x) 0.xX n(16)j=1intuition behind notion subject raise conditionallower prevision P j0 (f0 |z0 ), represents supremum acceptable buying price f0contingent z0 , positive , using desirable gambles G1 (f1 |XI1 ),. . . ,Gm (fm |XIm ).difference notion (strong) coherence supremum sum Equation (16) required non-negative whole space X n , necessarilyleast one summands non-zero. implies condition holds triviallygambles f0 , f1 , . . . , fm elements w X n belongset {I1(z0 )}j=1 Sj (fj ).j0Miranda Zaffalon (2009, Theorem 1), P 1 (XO1 |XI1 ), . . . , P (XOm |XIm )weakly coherent joint lower prevision P (X1 , . . . , Xn ) pairwisecoherent conditional lower prevision P j (XOj |XIj ) collection. Similar resultshold case focus collections made linear previsions, differencejoint whose existence equivalent weak coherence linear, too. However,behavioural interpretation, number weakly coherent conditional lower previsionsstill present forms inconsistency; see Walley (1991, Example 7.3.5) exampleWalley (1991, Chapter 7), Walley, Pelessoni, Vicig (2004), Miranda (2009)discussion.Theorem 3 Let P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) separately coherent conditional lowerprevisions whose associated coherence graph A1+ . Let P strong product. Considerdisjoint Om+j , Im+j j = 1, . . . , k. Assume XIm+j finite j = 1, . . . , kP (z) > 0 z XIm+j , define P m+j (XOm+j |XIm+j ) using regular extensionj = 1, . . . , k.P , P 1 (XO1 |XI1 ), . . . , P m+k (XOm+k |XIm+k ) coherent.Proof. Let denote set linear previsions constructed combining extremepoints M(P j (XOj |XIj )), j = 1, . . . , m, manner described Equation (15).strong product P lower envelope M.813fiZaffalon & MirandaSince XIm+j finite j = 1, . . . , k, follows [Appendix J3] book Walley(1991) P P m+j (XOm+j |XIm+j ) coherent. Applying Theorem 1 MirandaZaffalon (2009), deduce previsions P , P 1 (XO1 |XI1 ), . . . , P m+k (XOm+k |XIm+k )weakly coherent. Hence, Theorem 7.1.5 Walley (1991) implies sufficesshow P 1 (XO1 |XI1 ), . . . , P m+k (XOm+k |XIm+k ) coherent. Consider fi Ki =1, . . . , + k, j0 {1, . . . , + k}, z0 XIj0 , f0 Kj0 , let us provesup"m+kXB#[fi P (XOi |XIi )] Iz0 (f0 P j0 (f0 |z0 )) () 0(17)i=1B {I1(z0 )} m+ki=1 Si (fi ).j0Assume first j0 {m + 1, . . . , + k}. Equation (17) hold,> 0#"m+kXsup[fi P (XOi |XIi )] Iz0 (f0 P j0 (f0 |z0 )) () = < 0.I1 (z0 )i=1j0Since P (z0 ) > 0 assumption, follows definition regular extensionP P (z0 ) > 0 Pj0 (f0 |z0 ) P j0 (f0 |z0 ) < 2 .definition elements M, Pi (XOi |XIi ) M(P (XOi |XIi )), = 1, . . . , m,P coherent Pi (XOi |XIi ) = 1, . . . , m. hand, applyingLemma 2, j = 1, . . . , k, conditional prevision Pm+j (XOm+j |XIm+j )dominates P m+j (XOm+j |XIm+j ) coherent P . Note Pj0 (XOj0 |z0 ) uniquelydetermined P Bayess rule P (z0 ) > 0.Using conditional previsions, deduce X n ,"m+k#X[fi Pi (XOi |XIi )] Iz0 (f0 Pj0 (f0 |z0 )) ()i=1"m+kXi=1whence"m+kX#[fi P (XOi |XIi )] Iz0 (f0 P j0 (f0 |z0 )) () + ,2#[fi Pi (XOi |XIi )] Iz0 (f0 Pj0 (f0 |z0 )) ()i=12I1(z0 ).j0PLet us denote g := m+ki=1 [fi Pi (XOi |XIi )] Iz0 (f0 Pj0 (f0 |z0 )).coherence P, Pj (XOj |XIj ) j = 1, . . . , + k implies P (g) = 0. alsoP (g) P (gIz0 ) 2 P (z0 ) < 0, first inequality holds g 0 sinceassuming Equation (17) hold. contradiction.Assume next j0 {1, . . . , m}, let us prove existence linear previsionQ conditional previsions Pj (XOj |XIj ) M(P j (XOj |XIj )) coherent Qj = 1, . . . , + k Pj0 (f0 |z0 ) = P j0 (f0 |z0 ) Q(B) > 0 B {I1(z0 )}j0m+ki=1 Si (fi ).814fiConservative Inference RuleAssume first P (z0 ) > 0. P P (z0 ) > 0.prevision determined (and therefore coherent with) conditional previsionsP1 (XO1 |XI1 ), . . . , Pm (XOm |XIm ), Pi (XOi |XIi ) belongs M(P (XOi |XIi ))= 1, . . . , m.Let Pj00 (XOj0 |XIj0 ) extreme point M(P j0 (XOj0 |XIj0 )) Pj00 (f0 |z0 ) =P (f0 |z0 ), let Q element determined conditional previsionsP1 (XO1 |XI1 ), . . . , Pj00 (XOj0 |XIj0 ), . . . , Pm (XOm |XIm ). Since coherence graphP 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) A1, Lemma 1 implies assume without loss generality k = 1, . . . , m, Ok (k1i=1 Ii ) = . Since moreover {O1 , . . . , Om } forms partition {1, . . . , n}, deduce Ii i1j=1 Oj0 1Oj , whence value Q XIj0 -measurable= 1, . . . , n. particular, Ij0 jj=1gambles uniquely determined P1 (XO1 |XI1 ), . . . , Pj0 1 (XOj0 1 |XIj0 1 ). consequence, Q(z0 ) = P (z0 ) > 0.Consider conditional previsions Pm+j (XOm+j |XIm+j ) pairwise coherentQ dominate P m+j (XOm+j |XIm+j ) j = 1, . . . , k. previsionsLemma 2. previsionsQ, P1 (XO1 |XI1 ), . . . , Pj00 (XOj0 |XIj0 ), . . . , Pm (XOm |XIm ),Pm+1 (XOm+1 |XIm+1 ), . . . , Pm+k (XOm+k |XIm+k )satisfy conditions stated above, B = I1(z0 ).j0P (z0 ) = 0, two possibilities: either fm+1 = = fm+k = 0,Equation (17) holds P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) coherent;j1 {1, . . . , k} fm+j1 6= 0. case, consider set BSm+j1 (fm+j1 ). set form B = I1(z1 ) z1 XIm+j1 .m+j1P (z1 ) > 0 assumption, Q Q(z1 ) > 0.definition M, Pi (XOi |XIi ) M(P (XOi |XIi )), = 1, . . . , m,Q coherent Pi (XOi |XIi ) = 1, . . . , m. Consider prevision Pj00 (XOj0 |z0 )M(P j0 (XOj0 |z0 )) Pj00 (f0 |z0 ) = P j0 (f0 |z0 ), define conditionalprevision Pj00 (XOj0 |XIj0 )Pj00 (f |z)(Pj00 (f |z0 ) z = z0=Pj0 (f |z0 ) otherwise.0Since Q(z0 ) = P (z0 ) = 0, given f Kj0 Q(Pj0 (f |XIj0 )) = Q(Pj0 (f |XIj0 )) =Q(f ), last equality follows coherence Q Pj0 (XOj0 |XIj0 ).Hence, Q Pj00 (XOj0 |XIj0 ) coherent. hand, applying Lemma 2,j = 1, . . . , k, Pm+j (XOm+j |XIm+j ) P m+j (XOm+j |XIm+j )coherent Q. deduceQ, P1 (XO1 |XI1 ), . . . , Pj00 (XOj0 |XIj0 ), . . . , Pm+k (XOm+k |XIm+k )satisfy stated conditions, B = I1(z1 ).m+j1815fiZaffalon & Mirandatake previsions, deduce X n ,#"m+kX[fi Pi (XOi |XIi )] Iz0 (f0 Pj0 (f0 |z0 )) ()i=1"m+kX#[fi P (XOi |XIi )] Iz0 (f0 P j0 (f0 |z0 )) ().i=1Pm+kLet us denote g :=i=1 [fi Pi (XOi |XIi )] Iz0 (f0 Pj0 (f0 |z0 )). coherence QPj (XOj |XIj ) j = 1, . . . , + k implies Q(g) = 0. Consider set B{I1(z0 )} m+ki=1 Si (fi ) Q(B) > 0. Equation (17) hold,j0must > 0 s.t. supB g() = < 0. Since also follows g() 0,deduce Q(g) Q(gIB ) Q(B) < 0. contradiction.conclude Equation (17) holds consequence previsionsP , P 1 (XO1 |XI1 ),. . . ,P m+k (XOm+k |XIm+k ) coherent. 2Next use results apply CIR rule general frameworks.necessary examples application CIR rule discussed Sections 5.15.3.Corollary 2 Let {X1 , . . . , Xn } set variables contains {Z, }include W . Assume coherence graph associated P 1 (XO1 |XI1 ),. . . , P (XOm |XIm )A1+ . Let P strong productP 1 (XO1 |XI1 ), . . . , P (XOm |XIm ), P (W |Y ), P (W |Y ).Assume XIm+j finite j = 1, . . . , k P (z) > 0 z XIm+j , defineP m+j (XOm+j |XIm+j ) using regular extension j = 1, . . . , k. Then:(i) P , P 1 (XO1 |XI1 ), . . . , P (XOm+k |XIm+k ), P (W |Y ), P (W |Y ) coherent.(ii) P (Z|W ) one previsions derive strong product P using regularextension, P (Z|W ) satisfies Equation (CIR).Proof. First all, P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ), P (W |Y ), P (W |Y ) satisfy hypotheses Theorem 2: associated coherence graph A1+ {W, XO1 , . . . , XOm }set variables interest. Hence, strong product P coherentassessments. moreover use regular extension build updated modelsP m+j (XOm+j |XIm+j ) using regular extension j = 1, . . . , k, follows Theorem 3conditional lower previsions P m+1 (XOm+j |XIm+1 ), . . . , P m+k (XOm+k |XIm+k )coherent P , P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ), P (W |Y ), P (W |Y ).Secondly, strong product P coincides one obtain using unconditional lower prevision P (XO1 , . . . , XOm ) obtain making strong product P 1 (XO1 |XI1 ), . . . , P (XOm |XIm ) one hand conditional assessmentsP (W |Y ), P (W |Y ) hand: results Miranda De Cooman (2007),extreme points set M(P (XO1 , . . . , XOm )) obtained applying marginalextension extreme points M(P 1 (XO1 |XI1 )),. . . ,M(P (XOm |XIm )). Hence,updated prevision P (Z|W ) obtain regular extension also satisfies Equation (CIR)case. 2816fiConservative Inference RuleCorollary 3 Updating credal network finite number times CIR leads coherentinference.Proof. enough observe probabilistic assessments used build credalnetworks lead A1+ coherence graph, detailed Theorem 8 Miranda Zaffalon(2009), graph, supplemented parts P (W |Y ) P (W |Y ),remains A1+ graph. result follows Corollary 2. 2Corollary 4 parametric inference finite number times CIR accordingRules (4) (5) leads coherent inference.Proof. coherence Rule (4) ensured Corollary 2 since coherence graphoverall assessments used A1+ , shown Figure 8. holds Rule (5)?/RWW??Figure 8: coherence graph parametric statistical inference.observe also case related coherence graph A1+ , illustratedFigure 9. 2?/Y1?W1jsRY1...W1...?/YNRWNWN?YN?Figure 9: coherence graph parametric statistical inference IID+ID case.Corollary 5 Computing finite number posterior predictive lower previsions CIRclassification according Rule (7) leads coherent inference.Proof. coherence Rule (7) ensured Corollary 2 since coherence graphoverall assessments used A1+ , shown Figure 10. 2817fiZaffalon & Miranda?s9/Y1?W1zs?RY1...W1...?//RYNRYNYN +1WNWNWN +1 WN +1???YN +1qZ?Figure 10: coherence graph pattern classification IID+ID case.Lemma 3 Consider bj 0, cj > 0 j = 1, . . . , n. j1!Pnbjj=1 bjPn1.(18)cj1j=1 cjPProof. Assume ex-absurdocjP nk=1 bk< bj , makingnk=1 ckEquation (18) hold. j = 1, . . . , m,sum j sides inequality obtainPnnnXXXcj nk=1 bkPn=bk <bj ,k=1 ckj=1k=1j=1contradiction. 2ReferencesAntonucci, A., & Zaffalon, M. (2006). Equivalence Bayesian credal netsupdating problem. Lawry, J., Miranda, E., Bugarin, A., Li, S., Gil, M. A.,Grzegorzewski, P., & Hryniewicz, O. (Eds.), Proceedings third internationalconference Soft Methods Probability Statistics, pp. 223230, Netherlands.Springer.Antonucci, A., & Zaffalon, M. (2007). Fast algorithms robust classification Bayesiannets. International Journal Approximate Reasoning, 44 (3), 200223.Antonucci, A., & Zaffalon, M. (2008). Decision-theoretic specification credal networks:unified language uncertain modeling sets Bayesian networks. InternationalJournal Approximate Reasoning, 49 (2), 345361.Antonucci, A., Zaffalon, M., Sun, Y., & de Campos, C. P. (2008). Generalized loopy 2U:new algorithm approximate inference credal networks. Jaeger, M., & Nielsen,T. D. (Eds.), Proceedings fourth European Workshop Probabilistic GraphicalModels, pp. 1724.Bernard, J.-M. (1996). Bayesian interpretation frequentist procedures Bernoulliprocess. American Statistician, 50 (1), 713.818fiConservative Inference RuleBhaskara Rao, K. P. S., & Bhaskara Rao, M. (1983). Theory Charges. Academic Press,London.Campos, L., & Moral, S. (1995). Independence concepts convex sets probabilities.Besnard, P., & Hanks, S. (Eds.), UAI-95, pp. 108115, San Mateo. Morgan Kaufmann.Corani, G., & Zaffalon, M. (2008). Learning reliable classifiers small incompletedata sets: naive credal classifier 2. Journal Machine Learning Research, 9,581621.Couso, I., Moral, S., & Walley, P. (2000). survey concepts independence impreciseprobability. Risk, Decision Policy, 5, 165181.Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120 (2), 199233.Cozman, F. G. (2005). Graphical models imprecise probabilities. International JournalApproximate Reasoning, 39 (23), 167184.De Campos, C. P., & Cozman, F. G. (2005). inferential complexity bayesiancredal networks. IJCAI-05, pp. 13131318. IJCAI.De Campos, L. M., Lamata, M. T., & Moral, S. (1990). concept conditional fuzzymeasures. International Journal Intelligent Systems, 5, 237246.De Cooman, G., & Zaffalon, M. (2004). Updating beliefs incomplete observations.Artificial Intelligence, 159 (12), 75125.Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incompletedata via EM algorithm. Journal Royal Statistical Society, 39 (1), 138.Duda, R. O., & Hart, P. E. (1973). Pattern Classification Scene Analysis. Wiley, NewYork.Fagin, R., & Halpern, J. Y. (1991). new approach updating beliefs. Bonissone,P. P., Henrion, M., Kanal, L. N., & Lemmer, J. F. (Eds.), Uncertainty ArtificialIntelligence, Vol. 6, pp. 347374. North-Holland, Amsterdam.Gill, R., Van der Laan, M., & Robins, J. (1997). Coarsening random: characterisations,conjectures counter-examples. Lin, D.-Y. (Ed.), Proceedings first SeattleConference Biostatistics, pp. 255294. Springer.Grunwald, P., & Halpern, J. (2003). Updating probabilities. Journal Artificial IntelligenceResearch, 19, 243278.Jaeger, M. (2008). Ignorability statistical probabilistic inference. Journal ArtificialIntelligence Research, 24, 889917.Jaffray, J.-Y. (1992). Bayesian updating belief functions. IEEE Transactions Systems, Man Cybernetics, 22, 11441152.Levi, I. (1980). Enterprise Knowledge. MIT Press, London.Little, R. J. A., & Rubin, D. B. (1987). Statistical Analysis Missing Data. Wiley, NewYork.Manski, C. F. (2003). Partial Identification Probability Distributions. Springer-Verlag,New York.819fiZaffalon & MirandaMiranda, E. (2008). survey theory coherent lower previsions. InternationalJournal Approximate Reasoning, 48 (2), 628658.Miranda, E. (2009). Updating coherent previsions finite spaces. Fuzzy Sets Systems,160 (9), 12861307.Miranda, E., & De Cooman, G. (2005). Coherence independence non-linear spaces.Tech. rep., Universidad Rey Juan Carlos, Spain. Downloadable addresshttp://bellman.ciencias.uniovi.es/emiranda/.Miranda, E., & De Cooman, G. (2007). Marginal extension theory coherent lowerprevisions. International Journal Approximate Reasoning, 46 (1), 188225.Miranda, E., & Zaffalon, M. (2009). Coherence graphs. Artificial Intelligence, 137 (1),104144.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann, San Mateo.Peot, M. A., & Shachter, R. D. (1998). Learning dont observe. Cooper,G. F., & Moral, S. (Eds.), Uncertainty Artificial Intelligence (ProceedingsFourteenth Conference), pp. 439446. Morgan Kaufmann Publishers, San Francisco,CA.Perks, W. (1947). observations inverse probability including new indifferencerule. J. Inst. Actuar., 73, 285312.Rabiner, L. (1989). tutorial hidden markov models selected applications speechrecognition. Proceedings IEEE, 77 (2), 257286.Ramoni, M., & Sebastiani, P. (2001). Robust learning missing data. Machine Learning,45 (2), 147170.Shafer, G. (1985). Conditional probability. International Statistical Review, 53, 261277.Strassen, V. (1964). Mefehler und Information. Zeitschrift fur Wahrscheinlichkeitstheorieund Verwandte Gebiete, 2, 273305.Troffaes, M. C. M. (2007). Decision making uncertainty using imprecise probabilities:introductory overview. International Journal Approximate Reasoning, 45 (1),1729.Walley, P. (1981). Coherent lower (and upper) probabilities. Tech. rep. Statistics ResearchReport 22, University Warwick, Coventry.Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall,New York.Walley, P. (1996a). Inferences multinomial data: learning bag marbles. J.R. Statist. Soc. B, 58 (1), 357.Walley, P. (1996b). Measures uncertainty expert systems. Artificial Intelligence, 83 (1),158.Walley, P., Pelessoni, R., & Vicig, P. (2004). Direct algorithms checking consistecymaking inferences conditional probability assessments. Journal StatisticalPlanning Inference, 126 (1), 119151.820fiConservative Inference RuleZaffalon, M. (2001). Statistical inference naive credal classifier. De Cooman, G.,Fine, T. L., & Seidenfeld, T. (Eds.), ISIPTA 01: Proceedings Second International Symposium Imprecise Probabilities Applications, pp. 384393,Netherlands. Shaker.Zaffalon, M. (2002). Exact credal treatment missing data. Journal Statistical PlanningInference, 105 (1), 105122.Zaffalon, M. (2005). Conservative rules predictive inference incomplete data.Cozman, F. G., Nau, R., & Seidenfeld, T. (Eds.), ISIPTA 05: ProceedingsFourth International Symposium Imprecise Probabilities Applications,pp. 406415, Manno, Switzerland. SIPTA.821fiJournal Artificial Intelligence Research 34 (2009) 675-706Submitted 11/08; published 04/09Planning Chain Causal Graphs VariablesDomains Size 5 NP-HardOmer Gimenezomer.gimenez@upc.eduDept. de Llenguatges Sistemes InformaticsUniversitat Politecnica de CatalunyaJordi Girona, 1-308034 Barcelona, SpainAnders Jonssonanders.jonsson@upf.eduDept. Information Communication TechnologiesUniversitat Pompeu FabraRoc Boronat, 13808018 Barcelona, SpainAbstractRecently, considerable focus given problem determining boundarytractable intractable planning problems. paper, study complexity planning class Cn planning problems, characterized unary operatorsdirected path causal graphs. Although one simplest forms causal graphsplanning problem have, show planning intractable Cn (unless P = NP),even domains state variables bounded size. particular, show planexistence Ckn NP-hard k 5 reduction Cnf-Sat. Here, k denotesupper bound size state variable domains. result reduces complexitygap class Ckn cases k = 3 k = 4 only, since C2n known tractable.1. Introductionongoing effort planning community determine complexity different classes planning problems. Known tractable classes usually characterizedsimple causal graph structure accompanied additional restrictions variablesoperators. However, boundary tractable intractable planning problemsstill clearly established. present paper contributes novel complexity resultclass planning problems simple causal graph structure literature,effort reduce complexity gap.problem determining tractable classes planning problems purely theoretical interest. instance, complex planning problems projected onto tractablefragments planning problems generate heuristics used search (Katz &Domshlak, 2008b). Also, causal graph heuristic (Helmert, 2006) exploits hierarchical structure planning problem transforming tractable form: first,translates propositional variables multi-valued variables, process simplifiescausal graph problem; then, keeps relaxing problem causal graphbecomes acyclic.present paper aims study complexity planning problems class Cn ,defined Domshlak Dinitz (2001). class Cn contains planning problemsc2009AI Access Foundation. rights reserved.fiGimenez & JonssonCknk=2k {3, 4}k5Plan generationPEXPEXPMacro plan generationP?IntractablePlan existenceP?NP-hardTable 1: Overview complexity results class Ckn .multi-valued variables chain causal graphs, i.e., causal graph directed path(implying operators unary). notation n indicates number statevariables unbounded. particular, study complexity plan existence Cn ,i.e., determining whether exists plan solves planning problem Cn .Even though planning problems Cn exhibit extremely basic form causal structure, i.e., linear dependence state variables, solving planning problems Cnnecessarily tractable, even impose additional restrictions. Let Ckn subclassCn state variables domains size k. known class C2npolynomial-time solvable (Brafman & Domshlak, 2003) plan existence classCn NP-hard (Gimenez & Jonsson, 2008a). aim study complexity planexistence classes between, namely Ckn k 3.Domshlak Dinitz (2001) showed solvable instances C3n requireexponentially long plans. means polynomial-time plan generationalgorithm Ckn k 3, case C2n . However, ruleexistence polynomial-time algorithm determines plan existence class Ckn ,even algorithm generates plans succinct form, like Jonsson (2007)Gimenez Jonsson (2008a). incompatible Cn NP-hard.paper, prove plan existence class Ckn NP-hard k 5.words, even causal graph directed path domains statevariables restricted contain 5 values, deciding whether planexists solving corresponding planning problem NP-hard. result impliessufficient planning problem exhibit linear variable dependence restrictedvariable domain sizes; additional restrictions necessary make planning tractable.Table 1 shows overview complexity results class Ckn date.Macro plan generation mean algorithm generating compact representationsolution, work Jonsson (2007) Gimenez Jonsson (2008a).Intractable result column means complexity yet unknowncannot P unless P = NP (else plan existence would P). row k = 2 dueBrafman Domshlak (2003), column plan generation due DomshlakDinitz (2001), contributions present paper marked boldface. Notenovel result subsumes Gimenez Jonsson (2008a), showed NP-hardnessk = O(n).paper organized follows. Section 2 relate results previous work,Section 3 introduce notation used throughout. Section 4 give formalproof reduction Cnf-Sat planning problems C11n . main result,5reduction Cnf-Sat planning problems Cn , proved Section 5. Although11result C5n subsumes C11n , believe intuitive idea behind Cn676fiChain Causal Graphs Domains Size 5reduction easier understand, may interest anyone trying prove hardnessresults similar circumstances. Section 6 discuss complexity remainingclasses C3n C4n .also prove correctness third reduction, time Cnf-Sat C7n ,7Appendix A. reductions C11n Cn previously appeared conference paper(Gimenez & Jonsson, 2008b), present paper provides formal proof correctness.2. Related Workcomplexity planning studied extensively last twenty years (Bylander, 1994; Chapman, 1987; Erol, Nau, & Subrahmanian, 1995). Many tractable classesplanning problems exploit notion causal graph one way another. Knoblock(1994) usually credited introducing causal graph work hierarchicalplanning. Williams Nayak (1997) required planning problems acyclic causalgraphs effort ensure tractability. Jonsson Backstrom (1998) defined class3S planning problems, also acyclic causal graphs, showed plan existencetractable class.Domshlak Dinitz (2001) introduced class Cn planning problems studiedpaper, well several related classes, particular causal graphstructure. Brafman Domshlak (2003) designed polynomial-time algorithm solving planning problems binary state variables polytree causal graphs boundedindegree, proving planning tractable class C2n . Brafman Domshlak(2006) presented complexity results related tree-width causal graph. KatzDomshlak (2008a) used causal graph structure prove several complexity resultsoptimal planning.Jonsson (2007) Gimenez Jonsson (2008a) designed polynomial-time algorithmssolve planning problems restricted causal graphs generating hierarchymacros. Recently, Chen Gimenez (2008) showed complexity planningintractable unless size largest connected component causal graph boundedconstant. Consequently, causal graph structure alone enough guaranteetractability, implying additional restrictions needed.3. NotationThroughout paper, use [i..n] denote set {i, . . . , n}.Let V set state variables, let D(v) finite domain state variablev V . define state function V maps state variable v Vvalue s(v) D(v) domain. partial state p function subset Vp Vstate variables maps state variable v Vp p(v) D(v). frequently usenotation (v1 = x1 , . . . , vk = xk ) denote partial state p defined Vp = {v1 , . . . , vk }p(vi ) = xi vi Vp .planning problem tuple P = hV, init, goal, Ai, V set variables, initinitial state, goal partial goal state, set operators. operator= hpre(a); post(a)i consists partial state pre(a) called pre-condition677fiGimenez & Jonssonv1v2v3v4v5Figure 1: Example causal graph planning problem class Ck5 .partial state post(a) called post-condition. Operator applicable states(v) = pre(a)(v) v Vpre(a) , applying operator state resultsnew state (v) = post(a)(v) v Vpost(a) (v) = s(v) otherwise.partial plan planning problem P sequence operators a1 , . . . , ak Ak ,k 0, a1 applicable initial state init and, [2..k], aiapplicable following application a1 , . . . , ai1 starting init. Note partial plannecessarily solve P . plan solving P partial plan goalstate goal satisfied following application a1 , . . . , ak . P solvableexists plan .causal graph planning problem P directed graph (V, E) statevariables nodes. edge (u, v) E u 6= v existsoperator u Vpre(a) Vpost(a) v Vpost(a) . Figure 1 shows examplecausal graph form directed path. structure causal graph impliesoperator unary, i.e., post-condition specified single variablev, pre-condition specified (at most) v predecessor v causalgraph.paper study class Ckn planning problems, defined follows:Definition 3.1. planning problem P belongs class Ckn causalgraph P directed path and, v V , |D(v)| k.planning problems Ckn , domain transition graph, DTG, state variablev labelled, directed graph (D(v), E ) values domain v nodes.edge (x, y) E label l D(v ) exists operatorhv = l, v = x; v = yi A, v predecessor v causal graph. edgewithout label indicates pre-condition corresponding operator defined valone. edge one label indicates existence multiple operatorspre- post-condition v different pre-conditions v .4. C11n NP-hardsection prove C11n NP-hard reduction Cnf-Sat. words,every CNF formula F associate planning instance P11 (F ) C11n P11 (F )solvable F satisfiable. first describe planning problem P11 (F ),explain intuitive idea behind reduction, finally provide formal proofcorrectness.Let F = C1 Ck CNF formula k clauses n variables x1 , . . . , xn .define planning problem P11 (F ) = (V, init, goal, A) follows. variable set V{si | [1..2n 1]} {vs } {vij | [1..k], j [1..n]} {ve } {ei | [1..2n 1]},domains D(si ) = D(ei ) = D(ve ) = {0, 1} [1..2n 1], D(vs ) = {0, 1, x},D(vij ) = {gx , g0 , g1 , ax , a0 , a1 , b0 , b1 , cx , c0 , c1 } [1..k], j [1..n]. initial statedefined init(si ) = init(ei ) = init(ve ) = 0, [1..2n 1], init(vs ) = x, init(vij ) = ax678fiChain Causal Graphs Domains Size 5s1s2n1vsv1nv11vk1vkne1e2n1Figure 2: Causal graph planning problem P11 (F ).0110001011x100 011Figure 3: DTGs variables s1 , s2 , . . . , s2n1 , vs .[1..k], j [1..n], goal state partial state defined goal(vin ) = gx[1..k], goal(ve ) = 0, goal(ei ) = (i mod 2) [1..2n 1].providing formal definition operators A, give intuitive overviewplanning problem P11 (F ). this, present causal graph P11 (F ) wellDTGs state variable. reader interested formal proofcorrectness reduction may skip Section 4.2, introduce formaldefinitions operators order prove several theoretical properties P11 (F ).4.1 Intuitionplanning problem P11 (F ) associated CNF formula F consists three parts,clearly defined role. three parts illustrated Figure 2, showing causalgraph P11 (F ). first part P11 (F ) corresponds state variables s1 , . . . , s2n1 , vs ,second part corresponds state variables v11 , . . . , v1n , . . . , vk1 , . . . , vkn , thirdpart corresponds state variables , e1 , . . . , e2n1 . role first part generatemessage corresponding assignment variables CNF formula F .role second part verify whether assignment satisfies clause Ci ,remember fact (using value state variable vin ). Finally, role third partmake sure message propagated way end chain.DTGs state variables s1 , . . . , s2n1 , vs appear Figure 3. state variablesused generate assignment variables x1 , . . . , xn CNF formula F .this, operators P11 (F ) defined way value vs changex either 0 1, 0 1 change back x. Thus, applyingoperators P11 (F ) possible generate sequence x, m1 , x, . . . , x, mn , x valuesvs , mj {0, 1} j [1..n].define message sequence m1 , . . . , mn n symbols (either 0 1) corresponding sequence values vs . follows, refer symbolsbits message. value x used separator distinguish consecutivebits message. Given message m, assignment defined (xj ) = mjj [1..n]. Thus, assignment x1 determined first choice whetherchange value vs x 0 1, on. purpose remaining statevariables si first part restrict message contain n bits.679fiGimenez & Jonsson(a)(b)a0g0a0g0c0b0c0b0a0,b0,g000x0gx1ax1xcxxgxa1,b1,g11xax,cx,gxa0,b0,g0xax,cx,gxaxax,cx,gxa0,b0,g0ax,cx,gxa1,b1,g1ax,cx,gxcxxa1,b1,g1g1a1c1b1g1a1b1ax,cx,gxc1(c)a0g0a0,b0c0,g0cx,gx g0gxc1,g1cx,gx g1axa1,b1g1c0b0ax,cxc0c0cxc1cxax,cxa1cxcxc1b1cxc1Figure 4: DTGs (a) v11 , (b) vi1 > 1, (c) vij j > 1. Dashed edgesexplained text.DTGs state variables vij , [1..k] j [1..n], appear Figure 4.dashed edges DTGs indicate corresponding operators depend CNFformula F . example, assignment (x1 ) = 1 satisfies clause C1 , edgev11 = ax label 1 Figure 4(a) points g1 , else points b1 . Likewise, (x1 ) = 0satisfies C1 , edge v11 = ax label 0 points g0 , else points b0 .Recall role second part check whether assignment generatedfirst part satisfies CNF formula F . clause Ci variable xjF , main function state variable vij check whether assignment (xj ) = mjsatisfies Ci . this, state variable vij acts finite state automaton propagatesbit message keeping track j-th bit message arrives.Since domain size state variables restricted, way vij countnumber bits received. Instead, fact j-th bit arrived indicatedvi(j1) . Moreover, last state variable vin clause Ci rememberwhether Ci satisfied assignment variable xj .summary, state variable vij second part performs following functionsvalues operators:1. Propagate message generated vs .2. Check whether assignment xj (the j-th bit m) satisfies clause Ci .680fiChain Causal Graphs Domains Size 500a0,a1,b0,b1, 0g0,g1axcxgx1011011Figure 5: domain transition graph variables , e1 , . . . , e2n1 .3. Remember whether Ci satisfied assignment xl , l j.4. j < n Ci satisfied, propagate fact.5. j < n, let vi(j+1) know (j + 1)-th bit message arrived.Note third function strictly necessary j = n. However, includingstate variables makes reduction compact symmetry.Next, briefly describe vij implements functions. valuedomain vij subscript 0, 1, x. propagate message, vij always movesvalue whose subscript matches predecessor (in case v11 , subscriptmatch value vs ). Unless Ci satisfied assignment xl , l < j,value vij remains subdomain {a0 , a1 , ax } prior arrival j-th bit.clause Ci encoded dashed edges DTGs variables vij .operators j-th bit mj arrives, vij moves ax gmjassignment (xj ) = mj satisfies Ci , bmj otherwise. fact value vijsubdomain {g0 , g1 , gx } indicates Ci satisfied assignmentxl , l j. fact propagated way vin since subsequent state variableCi forced move value subdomain {g0 , g1 , gx } whenever valuepredecessor {g0 , g1 , gx }. Whether clause Ci satisfied checkeddefining goal state vin = gx .Finally, j < n vij moves bmj , vi(j+1) moves amj . there, vijchoice move cx , causing vi(j+1) return ax . next bit arrives, vijmoves either c0 c1 , correctly indicating vi(j+1) (j + 1)-th bit arrived.Consequently, vi(j+1) moves either g0 (g1 ) b0 (b1 ), depending whetherassignment xj+1 satisfies Ci . Hence, values type b used delay transitionvi(j+1) value type either b g. mechanism allowsvariable vij react j-th bit. clause Ci , operators vi1 definedvi1 always reacts first bit.DTGs state variables , e1 , . . . , e2n1 appear Figure 5. functionstate variables make sure n bits message propagated endcausal graph. state variable (strictly speaking, planner solving planningproblem) never forced select operator, choose propagate bitmessage instead wait next bit arrive acting. turn, may causeanother state variable incorrectly conclude clause (not) satisfied.variables third part prevent happening, since goal state definedway cannot reached unless bits message arrive endcausal graph.681fiGimenez & JonssonVariables1si ,[2..2n 1]vsOperatorhs1 = 0; s1 = 1ihsi1 = 0, si = 0; si = 1ihsi1 = 1, si = 1; si = 0ihs2n1 = 0, vs = x; vs = mihs2n1 = 1, vs = m; vs = xiQualifier{0, 1}{0, 1}Table 2: Operators variables s1 , s2 , . . . , s2n1 , vs .4.2 Formal Proofsection, prove C11n NP-hard showing planning problem P11 (F )solvable formula F satisfying assignment. start with, provideformal definitions operators P11 (F ). operators s1 , . . . , s2n1 , vs appearTable 2, corresponding DTGs appear Figure 3. operators variables vij ,[1..k] j [1..n], appear Table 3, DTGs appear Figure 4. Finally,operators , e1 , . . . , e2n1 appear Table 4, DTGs appear Figure 5.reduce space requirement use shorthand definitions operators.words, hv = m, v = c; v = mi, {a, b}, denotes existence two operatorshv = a, v = c; v = ai hv = b, v = c; v = bi. Similarly, hv {a, b}, v = c; v = di denotesexistence two operators hv = a, v = c; v = di hv = b, v = c; v = di. statevariables vij also introduce reference numbers allow us easily refer operators.Furthermore, operators conditional properties CNF formula F ;operator exists indicated property satisfied. example, operatorhv22 = c0 , v23 = ax ; v23 = g0 exists clause C2 satisfied x3 , operatorhv22 = c0 , v23 = ax ; v23 = b0 exists C2 satisfied x3 . use set notationxj Ci denote literal xj appears clause Ci .proof organized follows. begin series technical definitionslemmas (4.14.6) related operators implications. Definition 4.7 introduces notion admissible plans, Lemma 4.8 states plan solving P11 (F )admissible. Next, Lemma 4.10 establishes admissible plan correspondsassignment variables CNF formula F , operator choicesplan forced given assignment. Finally, Lemma 4.13 determines exact sequencevalues taken state variable execution admissible plan, makingpossible check whether goal state reached end execution. Theorem4.14 concludes admissible plans solving P11 (F ) correspondingsatisfying assignments F .Definition 4.1. Given partial plan P11 (F ) variable v V , (v) numbertimes value v changed operators .Lemma 4.2. partial plan P11 (F ), holds(si ) [1..2n 1],(vs ) 2n.682fiChain Causal Graphs Domains Size 5Variablev11vi1 ,[2..k]vij ,[1..k],j [2..n]Ref.(1)(2)(3)(4)(5)(6)(7)(8)(9)(1)(2)(3)(4)(5)(6)(7)(8)(9)(10)(11)(12)(13)(14)(15)(16)(17)(18)(19)(20)(21)Operatorhvs = 1, v11 = ax ; v11 = g1hvs = 1, v11 = ax ; v11 = b1hvs = 0, v11 = ax ; v11 = g0hvs = 0, v11 = ax ; v11 = b0hvs = m, v11 = cx ; v11 = cmhvs = m, v11 = gx ; v11 = gmhvs = x, v11 = bm ; v11 = cxhvs = x, v11 = cm ; v11 = cxhvs = x, v11 = gm ; v11 = gxhv(i1)n {a1 , b1 , g1 }, vi1 = ax ; vi1 = g1hv(i1)n {a1 , b1 , g1 }, vi1 = ax ; vi1 = b1hv(i1)n {a0 , b0 , g0 }, vi1 = ax ; vi1 = g0hv(i1)n {a0 , b0 , g0 }, vi1 = ax ; vi1 = b0hv(i1)n {am , bm , gm }, vi1 = cx ; vi1 = cmhv(i1)n {am , bm , gm }, vi1 = gx ; vi1 = gmhv(i1)n {ax , cx , gx }, vi1 = bm ; vi1 = cxhv(i1)n {ax , cx , gx }, vi1 = cm ; vi1 = cxhv(i1)n {ax , cx , gx }, vi1 = gm ; vi1 = gxhvi(j1) = c1 , vij = ax ; vij = g1hvi(j1) = c1 , vij = ax ; vij = b1hvi(j1) = c0 , vij = ax ; vij = g0hvi(j1) = c0 , vij = ax ; vij = b0hvi(j1) {am , bm }, vij = ax ; vij =hvi(j1) = gm , vij = ax ; vij = gmhvi(j1) = cm , vij = cx ; vij = cmhvi(j1) {cm , gm }, vij = gx ; vij = gmhvi(j1) {ax , cx }, vij = ; vij = axhvi(j1) = cx , vij = bm ; vij = cxhvi(j1) = cx , vij = cm ; vij = cxhvi(j1) {cx , gx }, vij = gm ; vij = gxQualifierx1 C1x1/ C1x1 C1x1/ C1{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}x1 Cix1/ Cix1 Cix1/ Ci{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}xj Cixj/ Cixj Cixj/ Ci{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}Table 3: Operators variables v11 , . . . , vkn .Variablehvkne1ei , [2..2n 1]Operator{a0 , a1 , b0 , b1 , g0 , g1 },hvkn {ax , cx , gx },hve = 1, e1hve = 0, e1hei1 = 1, eihei1 = 0, ei= 0; = 1i= 1; = 0i= 0; e1 = 1i= 1; e1 = 0i= 0; ei = 1i= 1; ei = 0iTable 4: Operators variables , e1 , . . . , e2n1 .683fiGimenez & JonssonProof. induction i. = 1, variable s1 change once, (s1 ) 1.[2..2n 1], follows inspection operators cannot change valuesi twice without changing value si1 (the operator setting si1 si1 = 0 pre-condition, operator resetting si 0 si1 = 1pre-condition). Since change value si initial state withoutfirst changing value si1 , follows (si ) (si1 ) + 1 (i 1) + 1 =induction. argument holds variable vs predecessor s2n1 , (vs )(s2n1 ) + 1 (2n 1) + 1 = 2n.Lemma 4.3. partial plan P11 (F ) vij , [1..k] j [1..n],holds (vij ) (v ), v predecessor vij causal graph.Proof. before, follows inspection operators cannot changevalue vij twice without changing value v between. see this, notesubscript value D(vij ) either x, 0, 1. operator vij either changesvalue one subscript x one subscript 0 (1), v also valuesubscript 0 (1), one subscript 0 (1) one subscript x, v also valuesubscript x (the argument holds v11 , although values predecessorvs x, 0, 1 without subscripts).Note value vij cannot change initial state without first changingvalue v , since v value subscript 0 1 value vij changeinitial value ax . Consequently, value vij cannot change timesvalue v , (vij ) (v ) claimed.Lemma 4.4. vij , [1..k] j [1..n], partial state (v = x, vij = y),v predecessor vij causal graph, one applicable operatorchanging value vij .Proof. inspecting operators easy see pair operators vijdifferent pre-conditions. exception rule operators existsimultaneously due properties CNF formula F (e.g. operators (1) (2)).Lemma 4.5. partial plan P11 (F ), holds(ve ) (vkn ),(e1 ) (ve ),(ei ) (ei1 ) [2..2n 1].Proof. Let v variable among , e1 , . . . , e2n1 , let v predecessor causalgraph. before, cannot change value v twice without changing value vbetween. v {e1 , . . . , e2n1 }, operator setting v 1 requires v = 1,operator resetting v 0 requires v = 0. v = , operator setting v 1 requiresv value subscript 0 1, operator resetting v 0 requires vvalue subscript x. Note that, either case, cannot change value vinitial state without first changing value v . Thus, (v) (v )variables, claimed.684fiChain Causal Graphs Domains Size 5turn problem finding plan solves P11 (F ).Lemma 4.6. Let plan solves P11 (F ).(ei ) 2n [1..2n 1],(ve ) 2n.Proof. descending induction i. = 2n 1, goal(e2n1 ) = 1, valuee2n1 change least initial value init(e2n1 ) = 0, implying (e2n1 )1 = 2n (2n 1). [1..2n 2], assume (ei+1 ) 2n (i + 1) holdsinduction. Lemma 4.5 follows (ei ) (ei+1 ) 2n (i + 1). However,since goal(ei ) 6= goal(ei+1 ) since solves P11 (F ), follows (ei ) 6= (ei+1 ).Hence (ei ) > (ei+1 ), follows (ei ) 2n i, claimed.argument applies e1 predecessor , since goal(ve ) = 0 6= 1 = goal(e1 ), yielding(ve ) 2n.Definition 4.7. admissible plan planning problem P11 (F ) partial plan(si ) = i, (vs ) = (v11 ) = . . . = (vkn ) = (ve ) = 2n, (ei ) = 2n i,[1..2n 1].Lemma 4.8. plan solves P11 (F ) admissible.Proof. Lemmas 4.3 4.5 (vs ) (v11 ) (vkn ) (ve ). But,Lemmas 4.2 4.6, values equal 2n, since 2n (vs ) (ve ) 2n.proof Lemma 4.2 (si ) (si1 ) + 1, [2..2n 1],(vs ) (s2n1 ) + 1, together Lemma 4.2 (vs ) = 2n implies (si ) = i,[1..2n 1]. proof Lemma 4.6 (ve ) > (e1 ), (ei ) > (ei+1 ),[1..2n 2], (e2n1 ) 1, together Lemma 4.6 (ve ) = 2n implies(ei ) = 2n i, [1..2n 1].Please note converse Lemma 4.8 true, is, admissible planssolve planning problem P11 (F ).consequence Lemma 4.8, find plan solves P11 (F ) needconsider admissible plans. particular, admissible plan changes value variable vsexactly 2n times, generating sequence 2n + 1 values. Note value vs alwayschanges x either 0 1, back x.Definition 4.9. Let admissible plan, let x, m1 , x, . . . , x, mn , x sequence2n + 1 values variable vs takes execution , mj {0, 1}j [1..n]. use denote message m1 , . . . , mn induced , usedenote formula assignment (xj ) = mj j [1..n].turns out, operators part admissible plan completelydetermined message induced .Lemma 4.10. Let admissible plan P11 (F ) let induced message.operators changing value variable vij , [1..k] j [1..n], wellsequence values variable vij takes execution , completelydetermined .685fiGimenez & JonssonProof. v {v11 , . . . , vkn }, let v causal graph predecessor. proofLemma 4.3 know cannot change value v twice without changing valuev between, initial state, change value vchange value v. definition admissible know (v ) = (v) = 2n.way admissible plan change value v 2n times without changingvalue v 2n times first change value v , v, v , on.Now, Lemma 4.4 know that, given partial state (v = x, v = y),one applicable operator changing value v. Thus, time admissibleplan changes value v value v , one operator so.plan choice select operator since allowed change valuev changing value v. Consequently, sequence values takenv completely determined, operators v, well sequence valuestakes on, completely determined also. proof follows double inductionj, since sequence values taken vs (the predecessor v11 ) completelydetermined message .follows Lemma 4.10 relevant degree freedom admissibleplan selecting elements message , repeatedly deciding whether movevs = 0 vs = 1 vs = x. selected, operator choicesforced, else plan admissible. particular, message uniquestate executing admissible plan starting init results s. remainsdetermine whether unique state matches goal state.Remark. Note Lemma 4.10 mention operator order admissible plan.Indeed, change order operators admissible plan without makingplan inadmissible. example, let v1 , v2 , v3 three consecutive variablescausal graph, let ha11 , a12 , a13 , a21 , a22 , a23 subsequence operators changingvalues, aji j-th operator changing value vi . subsequenceha11 , a12 , a21 , a13 , a22 , a23 achieves result. long partial order haji , aji+1 , aj+1respected j, change operator order please.proceed determine sequence values variable vij , [1..k] j[1..n], takes execution admissible plan induced message .First, define satisficing index clauses, sequence values plan.Definition 4.11. Let admissible plan induced message = m.clause Ci , let satisficing index Ti [1..n+1] smallest number (xTi ) =mTi satisfies Ci . number exists, Ti = n + 1.Definition 4.12. Let admissible plan. clause Ci [1..2n + 1],let sequence values Qti () vector n values representing, variablevij , j [1..n], t-th value taken vij execution .following lemma key understanding idea behind reduction C11n , sincespecifies sequences values admissible plan induces execution.Lemma 4.13. Let assignment variables x1 , . . . , xn formula F .686fiChain Causal Graphs Domains Size 51) Existence. exists admissible plan planning problem P11 (F ) induced assignment = .2) Claim. Let Qti sequences values described Part 3) lemma.admissible plans = sequences values Qti () = Qti ,[1..k] [1..2n + 1].3) Sequence values. sequence values Qti , [1..k] [1..2n + 1],follows.a) j < Ti ,njj1z }| {c x cxQi2j1 =2jQi = cmj cmj2j+1=c x cxQiaxbmjcxz }| {ax axamj amjax axaxgmjgxz }| {ax axgmj gmjgx gxb) j = Ti ,njj1Qi2j1Q2jQ2j+1z }| {c x cx== cmj cmj=c x cxc) j > Ti ,jTinjz }| {gx gxgmj gmjgx gxz }| {gx gxgmj gmjgx gxTi 1Qi2j1Q2jQ2j+1z }| {=c x cx= cmj cmj=c x cxgxgmjgxProof. proving lemma, must check definition Qti given Part 3consistent. necessary due overlapping statements, namely, everyodd 1 2n + 1, sequence Qti defined twice, Qi2j1 j = 2t ,another time Qi2j +1 j = 2t . However, sequences values well-defined+1definitions Qi2j1 Q2jmatch combination j j = j 1,shown following table.jQi2j +1 = Qi2j1Case (a)z }| { z }| {cx cx ax axCase (b)z }| { z }| {cx cx ax axCase (c)z }| { z }| {cx cx gx gxCase (c)z }| { z }| {cx cx gx gxjj1 < j < Ti :Case (a)j1 < j = Ti :Case (a)Ti 1j = Ti + 1 n:Case (b)Ti 1Ti + 1 < j n:Case (c)687njnjnTi +1nTi +1fiGimenez & JonssonNow, prove Parts 2 3 lemma. Assume admissible plan inducedassignment = . proof proceeds double induction j. particular,2j+1prove validity three statements type Qi2j1 , Q2j, assuming, Qistatements type Qi (for < t) statements type Qi2j 1 , Q2jQi2j +1 (for j < j) already hold. first prove validity Qi2j1 . j = 1,Qi2j1 = Q1i = ax ax Cases (a) (b) corresponds initial state vi1 , . . . , vin(note Case (c) cannot hold j = 1). j > 1 know that, since statementsconsistent, Qi2j1 = Qi2j +1 j = j 1, hence correctness Qi2j1 followsinduction j.2j+1Next, prove statements relative Q2j. Consider variable vQiprecedes vi1 causal graph, values number 2j 1, 2j, 2j + 1 takesexecution . = 1, v = vs values x, mj , x. > 1,v = v(i1)n and, induction i, values ax , amj , ax j < Ti1 j < n;ax , bmj , cx j = n < Ti1 ; ax , gmj , gx j = Ti1 ; gx , gmj , gx j > Ti1 .proof divided 6 parts, depending values j Ti .I) 1 = j < Ti . Consider following table, write instead mj = m1simplify notation.vvi12j 1{x, ax , gx }ax{m, , bm , gm }2j2j + 1 {x, ax , cx , gx }vi2axvinaxthree rows table correspond values number 2j 1, 2j, 2j + 1variables v , vi1 , . . . , vin . first column corresponds possible valuespredecessor v vi1 take on. first row given Qi2j1 , second2j+1third rows, filled, correspond Q2j.QiLet A2j operator causing 2j-th value vi1 . According previoustable, pre-condition A2j must compatiblehv {m1 , am1 , bm1 , gm1 }, vi1 = axis, values variables v vi1 A2j applied. Since Ti > 1, (x1 ) =m1 satisfy clause Ci , operator A2j must one labelled (2)(4) Table 3. (Only one operators applicable, depending valuem1 whether v vs v(i1)n .) either case, application A2j causesvalue vi1 become bm1 , fill blank previous table.vvi1vi22j 1{x, ax , gx }axax2j{m, , bm , gm } bm (2, 4)2j + 1 {x, ax , cx , gx }vinaxway, check A2j+1 , operator causing (2j + 1)-th valuevi1 , must one labelled (7) Table 3; new value vi1 cx .688fiChain Causal Graphs Domains Size 5remaining variables, easy check variables vi2 , . . . , vin become am1 , dueoperators type (14), become ax , due operators type (18).table complete:vvi1vi2 vin2j 1{x, ax , gx }axax ax2j{m, , bm , gm } bm (2, 4) (14)2j + 1 {x, ax , cx , gx }cx (7)ax ax (18)shows Case (a) Lemma 4.13 holds j = 1 Ti > 1.II) 1 = j = Ti . proof similar Case (I). Since Ti = 1, (x1 ) = m1satisfies clause Ci . result, admissible operators causing 2j-th valuevi1 labelled (1) (3). either case, value vi1 becomes gm1 .Consequently, admissible operators vi2 , . . . , vin different before.resulting table:vvi1vi2 vin2j 1{x, ax , gx }axax ax2j{m, , bm , gm } gm (1, 3) gm gm (15)2j + 1 {x, ax , cx , gx }gx (9)gx gx (21)III) 1 < j < Ti . case, remaining ones, show resulting table.always write = mj . follows, omit column v since possiblevalues always same.vi1vi2 vi(j1)vijvi(j+1) vin2j 1 cxc x cxaxax axcm (5)cm cm (16) bm (11, 13)(14)2j2j + 1 cx (8)cx cx (20) cx (19)ax ax (18)IV) 1 < j = Ti .vi1vi2 vi(j1)vijvi(j+1) vin2j 1 cxc x cxaxax axcm (5)cm cm (16) gm (10, 12)gm gm (15)2j2j + 1 cx (8)cx cx (20) gx (21)gx gx (21)V) 1 = Ti < j.vi1vi2 vin2j 1 gxgx gx2jgm (6) gm gm (17)2j + 1 gx (9) gx gx (21)VI) 1 < Ti < j.vi1vi2 vi(Ti 1)viTi vin2j 1 cxc x cxgx gx2jcm (5)cm cm (16) gm gm (17)cx cx (20) gx gx (21)2j + 1 cx (8)689fiGimenez & Jonssonremains check Case (a) Lemma 4.13 follows parts (I) (III),Case (b) parts (II) (IV), Case (c) parts (V) (VI). proves Part2 3 lemma.Finally, note existence admissible plan directly follows previousdiscussion, since always specified operators used every situation,assumed existence. proves Part 1 lemma.Theorem 4.14. exists plan solves planning problem P11 (F )exists assignment satisfies CNF formula F .Proof. : Given assignment satisfies F , construct admissible plan whoseinduced formula assignment equals , choosing sequence values vs accordingly. follows Ti n clause Ci , since exists variable xj(xj ) = mj satisfies Ci . Then, Q2n+1form indicated Case (b) (c) Lemma4.13. either case, (2n + 1)-th value variable vin gx , required goal state.plan thus solves P11 (F ).: Let plan solves planning problem P11 (F ). Lemma 4.8 planadmissible. show contradiction = satisfies F . Assume not.exists clause Ci satisfied , implying Ti = n + 1. Since n < Ti , (2n + 1)-thvalue variable vin cx according Case (a) Lemma 4.13. contradicts solvingP11 (F ), since goal value vin cx gx .Proposition 4.15. Plan existence C11n NP-hard.Proof. largest variable domains planning problem P11 (F ) variablesv11 , . . . , vkn , contain 11 values. proof follows immediately well-knownNP-hardness Cnf-Sat, Theorem 4.14, fact produce planningproblem P11 (F ) polynomial time given CNF formula F .4.3 Exampleillustrate reduction using small example CNF formula F = (x1 x2 ) oneclause two variables x1 x2 . variable set corresponding planning problemP11 (F ) V = {s1 , s2 , s3 , vs , v11 , v12 , , e1 , e2 , e3 }. admissible plan inducefour different messages (0, 0), (0, 1), (1, 0), (1, 1). message (0, 0) correspondsassignment satisfy F . plan solves P11 (F ) inducedmessage (0, 1) appears Table 5. Note that, following execution plan, goal stategoal = (v12 = gx , = 0, e1 = 1, e2 = 0, e3 = 1) satisfied desired; last value changevariable appearing goal state marked using boldface.5. C5n NP-hardsection, describe reduction Cnf-Sat C5n . CNF formula Fassociate planning problem P5 (F ). clause Ci variable xj F , P5 (F ) contains1 , domain D(v 1 ) = {a , , , b }, v 2 , domain D(v 2 ) =two state variables vijx 0 1 xijijij2 , D(v 2 ) = {a , b , b }.{ax , a0 , a1 , b0 , b1 }. values a0 a1 omitted vinx 0 1690fiChain Causal Graphs Domains Size 5...hs1 = 0, s2 = 0; s2 = 1ihs2 = 1, s3 = 1; s3 = 0ihs3 = 0, vs = x; vs = 1ihvs = 1, v11 = cx ; v11 = c1hv11 = c1 , v12 = ax ; v12 = g1hv12 = g1 , = 0; = 1ihve = 1, e1 = 0; e1 = 1ihs1 = 0; s1 = 1ihs1 = 1, s2 = 1; s2 = 0ihs2 = 0, s3 = 0; s3 = 1ihs3 = 1, vs = 1; vs = xihvs = x, v11 = c1 ; v11 = cxhv11 = cx , v12 = g1 ; v12 = gxhv12 = gx , = 1; = 0ihs3 = 0, vs = x; vs = 0ihvs = 0, v11 = ax ; v11 = b0hv11 = b0 , v12 = ax ; v12 = a0hv12 = a0 , = 0; = 1ihve = 1, e1 = 0; e1 = 1ihe1 = 1, e2 = 0; e2 = 1ihe2 = 1, e3 = 0; e3 = 1ihs2 = 0, s3 = 0; s3 = 1ihs3 = 1, vs = 0; vs = xihvs = x, v11 = b0 ; v11 = cxhv11 = cx , v12 = a0 ; v12 = axhv12 = ax , = 1; = 0ihve = 0, e1 = 1; e1 = 0ihe1 = 0, e2 = 1; e2 = 0i...Table 5: plan solves planning problem P11 (F ) example formula F .(a)(b)(c)(d)a0a0a0a0a0x0b0xaxbxaxxxb1axax b0axax b1bxaxaxa11ax a0axa1ax bxaxaxa1a1b0a0axa0bxax(e)b0ax bxa1ax a1a1ax bxb1ax bxa1b11 , (b) v 1 , > 1, (c) v 1 , j > 1, (d) v 2 , j < n, (e) v 2 .Figure 6: DTGs (a) v11i1ijijstate variables s1 , . . . , s2n1 , vs , , e1 , . . . , e2n1 , well domains corresponding2 .operators, before, except predecessor vkn1 ) = init(v 2 ) = , [1..k]initial state new state variables init(vijxij1j [1..n], goal state goal(vi1 ) = ax , [1..k]. Table 6 lists operators1 v 2 , [1..k] j [1..n], Figure 6 shows corresponding DTGs.variables vijijTable 6 also lists new operators variable , different pre-conditions2 .predecessor vkn5.1 Intuitionreduction C5n based following idea: instead using explicit valueremember clause satisfied, goal remain initial value ax .way able reduce size variable domains needed reduction.Somewhat surprisingly, new reduction uses fewer total operators C11n .691fiGimenez & JonssonVariable1v111,vi1[2..k]1,vij[1..k],j [2..n]2,vij[1..k],j [1..n 1]2 ,vin[1..k]Ref.(1)(2)(3)(4)(5)(6)(7)(8)(9)(10)(11)(12)(13)(14)(15)(16)(17)(18)(19)(20)(21)(22)Operator1 = ; v1 =hvs = m, v11x 111 = ; v1 =hvs = x, v1111x1 = ; v1 = bhvs = x, v1111x1 = ; v1 =2= bm , vi1hv(i1)nx i121 = ; v1 =hv(i1)n= ax , vi1xi121 = ; v1 = bhv(i1)n= ax , vi1i1x1 = ; v1 =2= , vijhvi(j1)x ij21 = ; v1 =hvi(j1)= ax , vijijx1 = b ; v1 =2= bm , vijhvi(j1)x ij112hvi(j1) = ax , vij = ; vij = bx1 = , v2 = ; v2 =hvijx ijij1 = , v2 = ; v2 =hvijxx ijij221hvij = , vij = ax ; vij = bm1 = , v2 = b ; v2 =hvijxx ij1 ij1 = b , v2 = b ; v2 =hvijx ij1 ijx1 = , v2 = b ; v2 =hvijx ij0 ijx1 = b , v2 = b ; v2 =hvijx ij0 ijx1 = , v2 = ; v2 = bhvinx1 = , v2 = b ; v2 =hvinx1x1 = b , v2 = b ; v2 =hvinx1x1 = , v2 = b ; v2 =hvinxx01 = b , v2 = b ; v2 =hvinx0x2 = b , v = 0; v = 1ihvknee2 = , v = 1; v = 0ihvknx eeQualifier{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}xnj+1 Cixnj+1/ Cixnj+1 Cixnj+1/ Ci{0, 1}x1 Cix1/ Cix1 Cix1/ Ci{0, 1}1 , v 2 , v , [1..k] j [1..n].Table 6: Operators variables vijeij692fiChain Causal Graphs Domains Size 5reduction C5n also uses another new idea. reduction C11n , informationpropagated forward, i.e., variable vij changed value according valuepredecessor vi(j1) . reduction C5n , however, constructed information propagated forward (in particular, bits message) informationpropagated backwards (the index bit currently checking). planningproblem arranged variable v may several applicable operators,one satisfies pre-condition applicable action successor v . resultvalue v time + 1 depends value v time t.explain planning problem P5 (F ) bit detail. Due backwardpropagation mechanism, bits message checked reverse order.words, vin checks first bit, vi(n1) checks second bit, vi1 checks n-th2 check whether (n j + 1)-th bit satisfies clause C ,bit. purpose vij1 inform v 2whereas purpose vij(nj+2)-thbitarrived.i(j1)1 also keeps track whether C satisfied first (n j + 1)Implicitly, vijbits.Assume without loss generality message 0 0. Let us see happenscorresponding assignment satisfy clause Ci . Upon arrival first bit,2 move b . requires v 1 = pre-condition,state variable vin00l , j [1..n 1] l {1, 2}, . Next, v 2turn requires state variables vij01 = b . turn, requires statemove back ax , requires pre-condition vinxl , j [1..n 1] l {1, 2}, . v 1 moves bvariables vijxx2a0 , requiring vi(n1) = b0 pre-condition.1 b following (nj +1)We see that, long clause remains unsatisfied, vijx1 b following last bit. Assumeth bit. particular, means vi1x2 moves b , requires v 1(n j + 1)-th bit satisfies clause Ci . vij0xij1move ax instead bx . there, way vi(j1)bx following1 following last bit, satisfying goal(n j + 2)-th bit. particular, vi1xstate.5.2 Formal Proofproof C5n organized much way C11n . Note variabless1 , . . . , s2n1 , vs , , e1 , . . . , e2n1 before, Lemmas 4.2 4.6 still applyP5 (F ). easy check Lemmas 4.3, 4.5 4.8 also hold P5 (F ). However,Lemma 4.4 longer holds, since several operators share preconditions, namelyoperators (2) (3), (5) (6), (8) (10), (11) (13). spite this,operators sequences values admissible plan completely determinedinduced message , P11 (F ) (as shown Lemma 4.10):Lemma 5.1. Let admissible plan P5 (F ) let induced message.l , [1..k], j [1..n], l {1, 2},operators changing value variable vijl takes execution ,well sequence values variable vijcompletely determined .1 , assume without loss generality value .Proof. First consider variable v1101 , namely (2), changing valueGiven (vs = x), two applicable operators v11693fiGimenez & Jonssonax , (3), changing value bx . first sight, admissible plan choose either.2 pairHowever, admissible, change value v111 . Note v 1 = , v 2 either two values, namelyvalue changes v11011112 , admissible operator v 2 (12),a0 b0 . value v110111 = . Thus, changes value v 1 b longer admissible,pre-condition v11xx112 b , correct choice dependschoose operator (2). value v1102 (16)CNF formula F . xn satisfies clause C1 , admissible operator v111 = , choose operator (2). Otherwise, admissiblepre-condition v11x21 = b , choose operator (3).operator v11 (17) pre-condition v11x2 .1either case, operator choice v11 forced given value v111 , [2..k], v 1 , [1..k] j [2..k],reasoning applies variables vi1ij2 , [1..k] j [1..n 1], corresponding operators sharevijpre-conditions. degree freedom admissible plan selecting inducedmessage choosing operators vs accordingly. remaining operator choicesand, consequently, sequences values completely determined induced message.prove lemma similar Lemma 4.13, establishing sequence values takenstate variables P5 (F ) execution admissible plan.Definition 5.2. Let admissible plan P5 (F ). clause Ci[1..2n + 1], let sequence values Qti () vector 2n elements representing,l , j [1..n] l {1, 2}, t-th value taken variable v lvariable vijijl ]. define diagonal valueexecution . Let us denote value Qt ()[vij1qji (), [1..k] j [1..n], value Q2j+1 ()[vi(nj+1)].Lemma 5.3. Let assignment variables x1 , . . . , xn formula F .1) Existence. exists admissible plan planning problem P5 (F ) inducedassignment = .2) Claim. Let qji described Part 3) lemma. admissible plans= diagonal values qji () = qji [1..k] j [1..n].3) Diagonal values. diagonal values qji , [1..k] j [1..n],follows.a) j < Ti , qji = bx .b) j Ti , qji = ax .Proof. Note that, according Lemma 5.1, diagonal values qji (), alsofull sequences values Qti (), completely determined admissible plan .prove, then, admissible plans exist assignment , claimed Part 1,diagonal values match expression given Part 3. prove two factscareful, general analysis planning problem P5 (F ), explaininganalysis implies lemma. Incidentally, sequences values Qti () also694fiChain Causal Graphs Domains Size 5obtained analysis; study importantpurposes.l variable P (F ). Clearly,Let admissible plan, let v = vij5subscript t-th value Q ()[v] v takes depends parity t, sinceoperators affecting v change subscript x = {0, 1} back x.Namely, subscript Qt ()[v] x = 2p 1, = 2p, p-thbit message .1,Now, j [2..n 1] [1..k], consider t-th values variables vij2 , v1viji(j+1) take on, = 2p 1, 2p, 2p + 1. previous observation subscriptsimplies (trivially) know something values.1 ] Qt ()[v 2 ] Qt ()[v 1Qt ()[vijiji(j+1) ]= 2p 1 {ax , bx }ax{ax , bx }= 2p{am , bm }= 2p + 1 {ax , bx }ax{ax , bx }1] affects values diagonal,study value Q2p1 ()[vi(j+1)2p112p+112p2()[vi(j+1)] = ax , check()[vij ]. Qnamely Q ()[vij ] Qone possible outcome.12]1]Rule]Qt ()[vi(j+1)Qt ()[vijQt ()[vij= 2p 1 {ax , bx }axax= 2p(11)(7)= 2p + 1ax(8)ax(12){ax , bx }is, value type ax propagated along diagonal another value ax .call Propagation Rule I.1] = bx .study possible outcomes Q2p1 ()[vi(j+1)2p22p+11case, values Q ()[vij ] Q()[vij ] diagonal depend whetherp-th bit message clause Ci satisfied xnj+1 = (c.f.operators (14)(17) (18)(22) Table 6). Ci satisfied xnj+1 = m, followsvalues must bm ax . Propagation Rule II.1]2]1Rule IIQt ()[vijQt ()[vijQt ()[vi(j+1)]= 2p 1 {ax , bx }axbxbm(13)(9)= 2p= 2p + 1ax(8)ax(14, 16){ax , bx }contrary, clause Ci satisfied, values must bm bx .call Propagation Rule III.12]1]Rule III Qt ()[vijQt ()[vi(j+1)]Qt ()[vij= 2p 1 {ax , bx }axbx= 2pbm(13)(9)= 2p + 1bx(10)ax(15, 17){ax , bx }695fiGimenez & JonssonFinally, let us consider cases j = 1 j = n, treated2 values type . Also noteprevious analysis. Note variables vin1 cannot take value b time < 2n + 1, cannot change further,variables vi1xsince pre-conditions operators (1)(3), = 1, (4)(6), [2..k],1 = b . Thus, possible outcome two variablescompatible vi1xp < n following.12 ]1 ]]Qt ()[v(i+1)1Qt ()[vinQt ()[vin= 2p 1 {ax , bx }axax= 2pbm(18)(4)ax(19, 21; 20, 22)ax(5)= 2p + 1 {ax , bx } (8; 10)1] either ax bx , using operatorsNote that, p = n, value Q2p+1 ()[v(i+1)11 ,(5) (6). reader check similar analysis applies variable v11operators (1)(3) take role operators (4)(6).Let us summarize previous analysis following table.t=1t=2t=3t=4...121vi1vi1vi2ax ax axax...= 2n 2= 2n 1 ax= 2n= 2n + 11 v221vinvi(n1)vi(n1)axax ax axbmaxbm...bmaxbmaxfirst row previous table contains initial state planning problem:variables set ax . leftmost column rightmost column contain values1 v 2 . Then, values b right column propagatedtaken variables vi1along diagonals using three propagation rules already discussed: value typeyields values type according Rule I; value type b yields value typeclause satisfied Rule II, type b satisfied, Rule III.applies propagating values first row: since type a,values top-left triangle type a, according Rule I. Note also longestdiagonal coincides diagonal values qji Definition 5.2.discussion proceed prove lemma. Let assignment formulaF . existence plan = implied analysis already donel ], since shown operators used case producevalues Qt [vijactual changes value.1 ],Finally, consider diagonal values qji () j = 1, . . . , n, is, values Q3 ()[vin512n+11Q ()[vi(n1) ], . . ., Q()[vi1 ]. Let j < Ti Case (a), is, first j bitsmessage , assigned variables x1 , . . . , xj , satisfy clause Ci . Consequently,2j+1 ()[v 11 ], q = Q5 ()[v 1diagonal values q1i = Q3 ()[vin2i(n+1j) ] musti(n1) ], . . ., qj = Q696fiChain Causal Graphs Domains Size 5bx , according Rule III. contrary, assume j Ti Case (b),follows qpi = bx p < Ti due Rule III, qpi = ax p = Ti due Rule II,qpi = ax j p > Ti due Rule I.Theorem 5.4. exists valid plan solving planning problem P5 (F )exists assignment satisfies CNF formula F .Proof. : Lemma 5.3, existence assignment satisfies F impliesadmissible plans = satisfy qji () = qji . Since Ti n [1..k], followsqni = ax , required goal state P5 (F ). plan thus solves P5 (F ).: Let plan solving planning problem P5 (F ). Since Lemma 4.8 holdsP5 (F ), plan admissible. show contradiction = satisfies F .Assume not. exists clause Ci satisfied . Thus, Lemma 5.3 implies1 following execution b .qji () = bx j [1..n]. particular, value vi1x1)=a .contradicts solving P5 (F ), since bx different goal state goal(vi1xProposition 5.5. Plan existence C5n NP-hard.Proof. largest variable domains planning problem P5 (F ) variables2 , [1..k] j [1..n 1], contain 5 values. proof follows immediatelyvijNP-hardness Cnf-Sat, Theorem 5.4, fact produceplanning problem P5 (F ) polynomial time given CNF formula F .6. Discussionpaper, shown problem determining whether solution plan existsplanning problems class Ckn NP-hard whenever k 5. contrast, BrafmanDomshlak (2003) developed polynomial-time algorithm generating plans solveplanning problems class C2n . said intermediate cases, namelyCkn k {3, 4}? follows, sketch arguments tractabilitycases. Although discussion mostly based intuition gained studyingclasses, might prove helpful someone trying determine complexity.one hand, seems likely us plan existence C4n also NP-hard.reduction C5n uses one type state variable whose domain larger 4, namely2 . Finding reduction C4 seems possible, although likely difficult sincevijnavailable options become increasingly restricted state variable domains get smaller.particular, tried failed find reduction C4n .Domshlak Dinitz (2001) showed exist planning problems C3nexponential length minimal solutions. Although often indicates planning classdifficult, imply plan existence intractable. exemplifiedJonsson Backstrom (1998) define class planning problems exponentiallength minimal solutions plan existence could checked polynomial time.present authors (Gimenez & Jonsson, 2008a) showed even plan generationparticular class could done polynomial time, resulting plans givencompact format macros.second argument favor hardness C3n may multiple waystransition two values variable. example, consider planning problem697fiGimenez & Jonssontwo actions changing value variable v 0 1, namely= hv = 0, v = 0; v = 1i = hv = 1, v = 0; v = 1i. Since variables 3 values,possible neither v = 0 v = 1 hold current state. planner wouldthus choose whether satisfy v = 0 v = 1. contrast, C2n twoactions could replaced single action hv = 0; v = 1i since one alwaysapplicable. consequence, even minimal plan length bounded planningproblem C3n , may exponentially many plans length (in fact,main idea behind reductions).Another observation regards number possible domain transition graphsstate variable. k 2, possible show state variable Ckn may22k (k1) distinct domain transition graphs. words, number graphs growsexponentially k. particular, state variables C2n 24 = 16 distinctgraphs, number C3n 218 . Although large number possibilitiesguarantee hardness, clear expressive power C3n much higherC2n .evidence provided suggests C3n significantly harder C2n . However,sure C3n hard enough intractable. State variables threevalues lend well type reduction presented, sincepropagating message requires three values. reduction C3n , ideaunderlying may message-passing mechanism exploited.hand, maybe way determine plan existence C3n polynomial time.algorithm would take consideration multiple (but finite) combinations domaintransition graphs three values, well inherent structure graphs. knowexpressive power domain transition graphs 5 values large handlepolynomial time; maybe case using 3 values.Acknowledgmentswork partially funded APIDIS MEC grant TIN2006-15387-C03-03.Appendix A. C7n NP-hardappendix, describe modify reduction C11n resultingplanning problem, call P7 (F ), needs variable domains size 7. reduction previously appeared conference paper (Gimenez & Jonsson, 2008b), withoutproof. main idea reduction same, construction used checkassignment satisfies clause Ci involved. Previously, used n variables {vij }j[1 . . n] whose role was, essentially, check whether j-th bit (xj )propagated message satisfies Ci . modified reduction, variable vij replaced1 , v 2 , v 3 , collectively play role. variablesthree variables vijijijs1 , . . . , s2n1 , vs , , e1 , . . . , e2n1 , well domains corresponding operators,3 .before, except predecessor vkn1 ) = D(v 3 ) = {a , , , b , b , b , g }domains new variables D(vijx 0 1 x 0 1 xij2D(vij ) = {gx , g0 , g1 , ax , a0 , a1 , bx } [1..k], j [1..n]. initial state1 ) = init(v 2 ) = init(v 3 ) = , [1..k] j [1..n], goalvariables init(vijxijij698fiChain Causal Graphs Domains Size 5Variable1v111,vi1[2..k]1,vij[1..k],j [2..n]Ref.(1)(2)(3)(4)(5)(6)(7)(1)(2)(3)(4)(5)(6)(7)(8)(9)(10)(11)(12)(13)(14)(15)(16)(17)Operator1 = ; v1 = ghvs = 1, v11xx 111 = ; v1 = bhvs = 1, v11x 1111 = ; v1 = ghvs = 0, v11xx 111 = ; v1 = bhvs = 0, v11x 1101 = g ; v1 = bhvs = m, v11x 111 = b ; v1 = bhvs = m, v11x 111 = b ; v1 = bhvs = x, v1111x31 = ; v1 = ghv(i1)n{a1 , b1 }, vi1xx i11 = ; v1 = b3{a1 , b1 }, vi1hv(i1)nx i11113hv(i1)n {a0 , b0 }, vi1 = ax ; vi1 = gx31 = ; v1 = bhv(i1)n{a0 , b0 }, vi1x i1031 = g ; v1 = bhv(i1)n{am , bm }, vi1x i131 = b ; v1 = bhv(i1)n{am , bm }, vi1x i1113hv(i1)n {ax , bx }, vi1 = bm ; vi1 = bx31 = ; v1 = ghvi(j1)= b1 , vijx ijx113hvi(j1) = b1 , vij = ax ; vij = b131 = ; v1 = ghvi(j1)= b0 , vijx ijx1 = ; v1 = b3= b0 , vijhvi(j1)x ij031 = ; v1 = ghvi(j1)= gx , vijx ijx113hvi(j1) = , vij = ax ; vij =31 = g ; v1 = bhvi(j1)= bm , vijx ij31 = b ; v1 = bhvi(j1) = bm , vijx ij31 = ; v1 =hvi(j1){ax , bx }, vijxij1 = b ; v1 = b3= bx , vijhvi(j1)ijxQualifierx1 C1x1/ C1x1 C1x1/ C1{0, 1}{0, 1}{0, 1}x1 Cix1/ Cix1 Cix1/ Ci{0, 1}{0, 1}{0, 1}xj Cixj/ Cixj Cixj/ Ci{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}1 , [1..k] j [1..n].Table 7: Operators variables vij2 ) = g , [1..k]. Table 7 shows operators variables v 1 , [1..k]state goal(vinxij2 v 3 , [1..k]j [1..n], Table 8 shows operators variables vijijj [1..n]. Figures 7 8 shows corresponding domain transition graphs. Table 8 alsoshows new operators variable , different pre-conditions3 .predecessor vknA.1 Intuitionintuition behind reduction C7n largely C11n . planningproblem P7 (F ) corresponding CNF formula F consists three parts, firstthird identical P11 (F ). Thus, difference lies second part. Recallreduction C11n , clause Ci variable xj F , planningproblem P11 (F ) contains state variable vij performs following functions:1. Propagate message generated vs .699fiGimenez & JonssonVariable2,vij[1..k],j [1..n]Ref.(18)(19)(20)(21)(22)(23)(24)(25)(26)(27)(28)(29)(30)(31)3,vij[1..k],j [1..n]Operator1 {a , b }, v 2 = ; v 2 =hvijx ijij1 = g , v2 = ; v2 = ghvijxx ijx ij1 = b , v2 = g ; v2 = ghvijijx ij1 = b , v2 = b ; v2 =hvijx ijij1 = , v2 = ; v2 =hvijx ijijx1 = b , v2 = ; v2 = bhvijxijx ij1 = b , v2 = g ; v2 = ghvijx ijijx2 = , v3 = ; v3 =hvijijx ij2 = g , v3 = ; v3 = ghvijxx ijx ij2 = g , v3 = g ; v3 = bhvijijx ij2 {a , g }, v 3 = b ; v 3 = bhvijx ijij2 = , v3 = ; v3 =hvijx ijijx332hvij = bx , vij = ; vij = bx2 {b , g }, v 3 = b ; v 3 = bhvijxx xijij3hvkn {a0 , a1 , b0 , b1 }, = 0; = 1i3 {a , b }, v = 1; v = 0ihvknx xeeQualifier{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}{0, 1}2 , v 3 , v , [1..k] j [1..n].Table 8: Operators variables vijeij(a)(b)(c)b0b0a00ax00bxgx1xax11a0a0,b0 b0a0,b0xgxa1, b1a1, b1axbxb0bxaxgxa1b1axbxb1ax,bxb1b0ax,bxa0b1b0b0bxbxgxb1bxb1a1a1b11 , (b) v 1 [2..k], (c) v 1 [1..k], j [2..n].Figure 7: DTGs (a) v11iji12. Check whether assignment xj (the j-th bit m) satisfies clause Ci .3. Remember whether Ci satisfied assignment xl , l j.4. j < n Ci satisfied, propagate fact.5. j < n, let vi(j+1) know (j + 1)-th bit message arrived.first fourth function propagate information thus performedstate variables information lost. However, functionsperformed different state variables. idea behind reduction C7n split vij1 , performs second function, v 2 , performs third,three variables: vijij3vij , performs fifth.700fiChain Causal Graphs Domains Size 5(a)(b)a0g0b0a0bxbxa0,b0gxgxg1b0axbxaxa1,b1b1bxaxa1a0axb0bxg0a0,g0axbxgxbx,gxbxgxbx,gxaxb1a1a1bxa1,g1g1b12 (b) v 3 [1..k], j [1..n].Figure 8: DTGs (a) vijijbefore, message propagated using subscripts values domains1 movesstate variables. j-th bit mj message arrives, state variable vij1 movesax gx assignment (xj ) = mj satisfies Ci , bmj otherwise. vijgx , forced move bmj next, forgetting Ci satisfied. However,1 g , subsequent state variables C also move g , propagatingvalue vijxx2 able rememberfact Ci satisfied. Consequently, state variable vinCi satisfied remaining within subdomain {g0 , g1 , gx }.1 moves b , causing v 2 v 3 move .(xj ) = mj satisfy Ci , vijmjmjijij1321there, vij , vij , vij move bx . next bit arrives, vij moves b0 (b1 ),2 move (a ) v 3 b (b ). indicates v 1causing vij0101iji(j+1) (j + 1)-thbit arrived, causing act accordingly. before, operators defined1 always reacts first bit clause C .vi1A.2 Formal ProofSince variables s1 , . . . , s2n1 , vs , , e1 , . . . , e2n1 before, Lemmas 4.24.6 apply P7 (F ). However, Lemma 4.3 violated since sometimes possiblechange value variable twice without changing value predecessor (e.g.using operators (1) (5)). Consequently, Lemma 4.8, states planssolve P11 (F ) admissible, longer holds P7 (F ).l ) variables middleprove equivalent lemmas P7 (F ), redefine (vijcausal graph:l , [1..k], j [1..n],Definition A.1. Given partial plan variable vijl ) number subscript changes v l execution .l {1, 2, 3}, let (vijijl , [1..k], j [1..n],Lemma A.2. partial plan P7 (F ) vijl ) (v ), v predecessor v l causall {1, 2, 3}, holds (vijijgraph.l . operatorProof. Follows immediately inspection operators vijlchanges subscript vij z {0, 1, x} pre-condition v subscript z (or1 predecessor v ). operators changing valuevalue z case v111 g pre-condition v subscript (or value) different x,vijx1 since pre-condition v 1 .operators change subscript vijxij701fiGimenez & Jonsson3 ).Lemma A.3. partial plan P7 (F ), (ve ) (vkn3 ) denotesProof. Note (ve ) still denotes number value changes , (vkn3 . time change value v neednumber subscript changes vkne3change subscript vkn between. addition, first value change requires3 different initial state. Thus, (v ) (v 3 ).subscript vkneknDefinition A.4. admissible plan planning problem P7 (F ) partial plan1 ) = . . . = (v 3 ) = (v ) = 2n, (e ) = 2n i,(si ) = i, (vs ) = (v11ekn[1..2n 1].Lemma A.5. plan solves planning problem P7 (F ) admissible.1 ) (v 3 ) (v ).Proof. Lemmas A.2 A.3 (vs ) (v11eknuse Lemmas 4.2 4.6 apply reasoning proof Lemma4.8.l exactly 2nwords, admissible plan change subscript vijl extra time moving g . However,times, although change value vijxl ), cannot prove equivalent Lemma 4.10even new definition (vijl , l {1, 2}, choose follow predecessor g withoutP7 (F ), since variable vijxmaking plan inadmissible. Consequently, sequences values Qti () admissibleplan longer completely determined induced message . Nevertheless,still prove lemma similar Lemma 4.13.Definition A.6. Let admissible plan. clause Ci [1..2n + 1],let sequence values Qti () vector 3n elements representing, variablel , j [1..n] l {1, 2, 3}, first value following (t 1)-th subscript changevijl execution .vijLemma A.7. Let assignment variables x1 , . . . , xn formula F .1) Existence. exists admissible plan planning problem P7 (F ) inducedassignment = .2) Claim. Let Qti sequences values described Part 3) lemma.satisfies F , exists admissible plan = Qti () = Qti ,[1..2n+1] [1..k]. satisfy clause Ci , admissibleplans = Qti () = Qti , [1..2k + 1].3) Sequence values. sequence values Qti , [1..k] [1..2n + 1],follows.a) j < Ti ,j1Qi2j1Q2jQ2j+1nj}|{zz}|{bx bx bx bx bx bxax ax axax ax ax ax ax ax== bm bm bm bm bm=bx bx bx bx bx bxbx bx bxax ax ax ax ax ax702fiChain Causal Graphs Domains Size 5b) j = Ti ,j1Qi2j1Q2j2j+1Qinjz}|{z}|{=bx bx bx bx bx bxax ax axax ax ax ax ax ax= bm bm bm bm bm gm bm bm gm bm bm gm bm=bx bx bx bx bx bxbx gx bxbx gx bx bx gx bxc) j > Ti ,jTiTi 1Qi2j1Q2j2j+1Qinjzz}|{}|{}|{zbx gx bx bx gx bx bx gx bx bx gx bx bx gx bx= bx bx bx bx bx bx= bm bm bm bm bm gm bm bm gm bm bm gm bm bm gm bm bm gm bm= bx bx bx bx bx bxbx gx bx bx gx bx bx gx bx bx gx bx bx gx bxProof. Note similarity lemma Lemma 4.13. before, must showoperators, time Tables 7 8, whose post-conditions equal values2j+1given Qi2j1 , Q2j. Again, must check consistency statementsQi2j +12j1j = j 1. implies, Lemma 4.13, statementsQiQiQi2j1 valid, due initial state ax ax induction j.2j+1remains show statements Q2jalso valid.Qiproof divided six parts Lemma 4.13. Note that,contrast lemma, aim show that, satisfies F , existsadmissible plan given Qti , admissible plans form.sometimes execution plan one operator could chosen,resulting plan would still admissible. tables follow, alikeproof Lemma 4.13, indicate operator choice leadsdesired Qti , use boldface remark operators forced. addextra row tables indicate sometimes need apply two operatorsvariable changing subscript. disparities respect Lemma 4.13occur parts II IV proof, require Ti n, is, satisfying clauseCi , fixed i. Thus, satisfy clause Ci , admissible planssequences values Qti [1..2n + 1].I) 1 = j < Ti .1 v2 v31 v 2 v 3 |k [2..n]vi1viki1 i1ik ik2j 1 ax ax axax ax ax2jbm (2, 4; 18; 25) (13; 18; 25)ax ax ax (16; 22; 29)2j + 1 bx bx bx (7; 23; 30)II) 1 = j = Ti .1 v2 v31 v 2 v 3 |k [2..n]vi1viki1 i1ik ik2j 1 ax ax axax ax axgx gx gx (1, 3; 19; 26)gx gx gx (12; 19; 26)2jbm gm bm (5; 20; 27)bm gm bm (14; 20; 27)bx gx bx (7; 24; 31)bx gx bx (17; 24; 31)2j + 1703fiGimenez & JonssonIII) 1 < j < Ti .1 v 2 v 3 |k [1..j 1] v 1 v 2 v 31 v 2 v 3 |k [j + 1..n]vikvikij ij ijik ikik ik2j 1b x bx bxax ax axax ax ax2jbm bm (6, 15; 21; 28) bm (9, 11; 18; 25) (13; 18; 25)bx bx bx (7, 17; 23; 31)bx bx bx (17; 23; 30)ax ax ax (16; 22; 29)2j + 1IV) 1 < j = Ti .1 v 2 v 3 |k [1..j 1] v 1 v 2 v 31 v 2 v 3 |k [j + 1..n]vikvikij ij ijik ikik ik2j 1b x bx bxax ax axax ax axbm bm (6, 15; 21; 28) gx gx gx (8, 10; 19; 26)gx gx gx (12; 19; 26)2jbm bmbm gm bm (14; 20; 27)bm gm bm (14; 20; 27)2j + 1bx bx bx (7, 17; 23; 31)bx gx bx (17; 24; 31)bx gx bx (17; 24; 31)V) 1 = Ti < j.1 v 2 v 3 |k [2..n]1 v2 v3vikvi1i1 i1ik ik2j 1bx gx bxbx gx bx2jbm gm bm (6; 20; 28) bm gm bm (15; 20; 28)2j + 1bx gx bx (7; 24; 31)bx gx bx (17; 24; 31)VI) 1 < Ti < j.1 v 2 v 3 |k [1..T 1] v 1 v 2 v 3 |k [T ..n]vikik ikik ik ik2j 1bx bx bxbx gx bx2jbm bm (6, 15; 21; 28)bm gm bm (15; 20; 28)2j + 1bx bx bx (7, 17; 23; 31)bx gx bx (17; 24; 31)Theorem A.8. exists plan solves planning problem P7 (F )exists assignment satisfies CNF formula F .Proof. : Given assignment satisfies F , construct admissible plan whoseinduced formula assignment equals , choosing sequence values vs accordingly. follows clause Ci , Ti n, since exists variable xj(xj ) = mj satisfies Ci . Since n Ti , exists admissible plan Qi2n+1form indicated Case (b) (c) Lemma A.7. either case, (2n + 1)-th2 g , required goal state. plan thus solves P (F ).value variable vinx7: Let plan solves planning problem P7 (F ). Lemma A.5 planadmissible. show contradiction = satisfies F . Assume not.exists clause Ci satisfied . Thus, Lemma A.7 applies sequence2 following executionvalues Q2n+1. particular, means value vinbx according Case (a) lemma. contradicts solving P7 (F ), since bx2 )=g .different goal state goal(vinxProposition A.9. Plan existence C7n NP-hard.704fiChain Causal Graphs Domains Size 5Proof. largest variable domains planning problem P7 (F ) variables1 , . . . , v 3 , contain 7 values. proof follows immediately NP-hardnessv11knCnf-Sat, Theorem A.8, fact produce planning problem P7 (F )polynomial time given CNF formula F .ReferencesBrafman, R., & Domshlak, C. (2003). Structure Complexity Planning UnaryOperators. Journal Artificial Intelligence Research, 18, 315349.Brafman, R., & Domshlak, C. (2006). Factored Planning: How, When, Not.Proceedings 21st National Conference Artificial Intelligence, pp. 809814.Bylander, T. (1994). computational complexity propositional STRIPS planning.Artificial Intelligence, 69, 165204.Chapman, D. (1987). Planning conjunctive goals. Artificial Intelligence, 32(3), 333377.Chen, H., & Gimenez, O. (2008). Causal Graphs Structurally Restricted Planning.Proceedings 18th International Conference Automated Planning Scheduling, pp. 3643.Domshlak, C., & Dinitz, Y. (2001). Multi-Agent Off-line Coordination: Structure Complexity. Proceedings 6th European Conference Planning, pp. 277288.Erol, K., Nau, D., & Subrahmanian, V. (1995). Complexity, Decidability UndecidabilityResults Domain-Independent Planning. Artificial Intelligence, 76(1-2), 7588.Gimenez, O., & Jonsson, A. (2008a). Complexity Planning Problems SimpleCausal Graphs. Journal Artificial Intelligence Research, 31, 319351.Gimenez, O., & Jonsson, A. (2008b). Search Tractability Boundary PlanningProblems. Proceedings 18th International Conference Automated PlanningScheduling, pp. 99106.Helmert, M. (2006). Fast Downward Planning System. Journal Artificial IntelligenceResearch, 26, 191246.Jonsson, A. (2007). Role Macros Tractable Planning Causal Graphs.Proceedings 20th International Joint Conference Artificial Intelligence, pp.19361941.Jonsson, P., & Backstrom, C. (1998). Tractable plan existence imply tractableplan generation. Annals Mathematics Artificial Intelligence, 22(34), 281296.Katz, M., & Domshlak, C. (2008a). New Islands Tractability Cost-Optimal Planning.Journal Artificial Intelligence Research, 32, 203288.Katz, M., & Domshlak, C. (2008b). Structural Patterns Heuristics via Fork Decompositions. Proceedings 18th International Conference Automated PlanningScheduling, pp. 182189.Knoblock, C. (1994). Automatically generating abstractions planning. Artificial Intelligence, 68(2), 243302.705fiGimenez & JonssonWilliams, B., & Nayak, P. (1997). reactive planner model-based executive.Proceedings 15th International Joint Conference Artificial Intelligence, pp.11781185.706fiJournal Artificial Intelligence Research 34 (2009) 297-337Submitted 06/08; published 03/09Monte Carlo Sampling Methods ApproximatingInteractive POMDPsPrashant DoshiPDOSHI @ CS . UGA . EDUDepartment Computer ScienceUniversity Georgia415 Boyd GSRCAthens, GA 30602Piotr J. GmytrasiewiczPIOTR @ CS . UIC . EDUDepartment Computer ScienceUniversity Illinois Chicago851 S. Morgan StChicago, IL 60607AbstractPartially observable Markov decision processes (POMDPs) provide principled frameworksequential planning uncertain single agent settings. extension POMDPs multiagentsettings, called interactive POMDPs (I-POMDPs), replaces POMDP belief spaces interactivehierarchical belief systems represent agents belief physical world, beliefsagents, beliefs others beliefs. modification makes difficulties obtaining solutions due complexity belief policy spaces even acute.describe general method obtaining approximate solutions I-POMDPs based particle filtering (PF). introduce interactive PF, descends levels interactive beliefhierarchies samples propagates beliefs level. interactive PF able mitigate belief space complexity, address policy space complexity. mitigatepolicy space complexity sometimes also called curse history utilize complementary method based sampling likely observations building look ahead reachabilitytree. approach completely address curse history, beats back cursesimpact substantially. provide experimental results chart future work.1. IntroductionInteractive POMDPs (I-POMDPs) (Gmytrasiewicz & Doshi, 2005; Seuken & Zilberstein, 2008)generalization POMDPs multiagent settings offer principled decision-theoreticframework sequential decision making uncertain multiagent settings. I-POMDPs applicable autonomous self-interested agents locally compute actions executeoptimize preferences given believe interacting others possiblyconflicting objectives. Though POMDPs used multiagent settings,strong assumption agents behavior adequately represented implicitly (say,noise) within POMDP model (see Boutilier, Dean, & Hanks, 1999; Gmytrasiewicz & Doshi,2005, examples). approach adopted I-POMDPs expand traditional state spaceinclude models agents. models sophisticated intentional models,ascribe beliefs, preferences, rationality others analogous notion agentc2009AI Access Foundation. rights reserved.fiD OSHI & G MYTRASIEWICZtypes Bayesian games (Harsanyi, 1967; Mertens & Zamir, 1985). models, finitestate machines, ascribe beliefs rationality agents call subintentionalmodels. agents beliefs within I-POMDPs called interactive beliefs, nestedanalogously hierarchical belief systems considered game theory (Mertens & Zamir, 1985;Brandenburger & Dekel, 1993; Heifetz & Samet, 1998; Aumann, 1999), theoretical computerscience (Fagin, Halpern, Moses, & Vardi, 1995) hyper-priors hierarchical Bayesianmodels (Gelman, Carlin, Stern, & Rubin, 2004). Since interactive beliefs may infinitelynested, Gmytrasiewicz Doshi (2005) defined finitely nested I-POMDPs computable specializations infinitely nested ones. Solutions finitely nested I-POMDPs map agents statesbelief environment agents models policies. Consequently, I-POMDPsfind important applications agent, human, mixed agent-human environments. potentialapplications include path planning multi-robot environments, coordinating troop movementsbattlefields, planning course treatment multi-treatment therapy, explaining commonly observed social behaviors (Doshi, Zeng, & Chen, 2007).However, optimal decision making uncertain multiagent settings computationally hardrequiring significant time memory resources. example, problem solving decentralized POMDPs shown lie NEXP-complete class (Bernstein, Givan, Immerman, &Zilberstein, 2002). Expectedly, exact solutions finitely nested I-POMDPs difficult computewell, due two primary sources intractability: (i) complexity belief representation proportional dimensions belief simplex, sometimes called cursedimensionality. (ii) complexity space policies, proportional numberpossible future beliefs, also called curse history.sources intractability exist POMDPs also (see Pineau, Gordon, & Thrun, 2006;Poupart & Boutilier, 2004) curse dimensionality especially acute I-POMDPs.I-POMDPs complexity belief space even greater; beliefs mayinclude beliefs physical environment, possibly agents beliefs agentsbeliefs, beliefs others, on. Thus, contributing factor cursedimensionality level belief nesting considered. total number agent modelsgrows exponentially increase nesting level, solution complexity.observe one approach solving finitely nested I-POMDP investigate collapsing model traditional POMDP, utilize available approximation methods applyPOMDPs. However, transformation POMDP straightforward. particular,seem possible model update agents nested beliefs part transition function POMDP. transition function would include nested beliefs require solutionsothers models defining it, thus quite different standard ones currentPOMDP approaches apply.article, present first set generally applicable methods computing approximately optimal policies finitely nested I-POMDP framework demonstrating computational savings. Since agents belief defined agents models, may complexinfinite space, sampling methods able approximate distributions large spaces arbitrary accuracy promising approach. adopt particle filter (Gordon, Salmond, & Smith,1993; Doucet, Freitas, & Gordon, 2001) point departure. growing empirical evidence (Koller & Lerner, 2001; Daum & Huang, 2002) particle filters unable significantlyreduce adverse impact increasing state spaces. Specifically, number particles neededmaintain error exact state estimation increases number dimensions increase.298fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPHowever, rate convergence approximate posterior true one independentdimensions state space (Crisan & Doucet, 2002) weak assumptions. words,may need particles maintain error state space increases, rateerror reduces remains unchanged, regardless state space. Furthermore, sampling approachesallow us focus resources regions state space considered likelyuncertain environment, providing strong potential computational savings.generalize particle filter, specifically bootstrap filter (Gordon et al., 1993),multiagent setting, resulting interactive particle filter (I-PF). generalizationtrivial: simply treat agent automaton whose actions follow fixedknown distribution. Rather, consider case agents intentional possess beliefs, capabilities preferences. Subsequently, propagation step I-PF becomescomplicated standard PF. projecting subject agents belief time,must project agents belief, involves predicting action anticipating observations. Mirroring hierarchical character interactive beliefs, interactive particle filteringinvolves sampling propagation hierarchical levels beliefs. empiricallydemonstrate ability I-PF flexibly approximate state estimation I-POMDPs,show computational savings obtained comparison regular grid based implementation.However, sample identical number particles nesting level, total numberparticles associated complexity, continues grow exponentially nesting level.combine I-PF value iteration sample sets thereby providing general waysolve finitely nested I-POMDPs. approximation method anytime applicable agentsstart prior belief optimize finite horizons. Consequently, method finds applications online plan computation. derive error bounds approach applicablesingly-nested I-POMDPs discuss difficulty generalizing bounds multiply nestedbeliefs. empirically demonstrate performance computational savings obtainedmethod standard test problems well larger uninhabited aerial vehicle (UAV) reconnaissance problem.I-PF able flexibly mitigate belief space complexity, address policy space complexity. order mitigate curse history, present complementary methodbased sampling observations building look ahead reachability tree value iteration. translates considering future beliefs value iteration agentlikely given belief. approach similar spirit sparse samplingtechniques used generating partial look ahead trees action selection reinforcementlearning (Kearns, Mansour, & Ng, 2002; Wang, Lizotte, Bowling, & Schuurmans, 2005)online planning POMDPs (Ross, Pineau, Paquet, & Chaib-draa, 2008). approachesapplied single agent reinforcement learning problems, focus multiagent settingrecursively apply technique solve models agents nesting level. Observation sampling also recently utilized DEC-POMDPs (Seuken & Zilberstein, 2007),shown improve performance large problems. note approachcompletely address curse history, beats back impact difficulty computingI-POMDP solutions, substantially. report additional computational savings obtainedcombine method I-PF, provide empirical results support.Rest article structured following manner. review various state estimation methods relevance, use particle filters previous works Section 2.Section 3, review traditional particle filtering technique concentrating bootstrap filters299fiD OSHI & G MYTRASIEWICZparticular. briefly outline finitely nested I-POMDP framework Section 4 multiagent tiger problem used illustration Section 5. Section 6, discuss representationsnested beliefs inherent difficulty formulating them. order facilitate understanding,give decomposition I-POMDP belief update Section 7. present I-PFapproximates finitely nested I-POMDP belief update Section 8. followed methodutilizes I-PF compute solutions I-POMDPs, Section 9. also commentasymptotic convergence compute error bounds approach. Section 10, reportperformance approximation method simple larger test problems. Section 11,provide technique mitigating curse history, report empirical results.Finally, conclude article outline future research directions Section 12.2. Related WorkSeveral approaches nonlinear Bayesian estimation exist. Among these, extended Kalman filter (EKF) (Sorenson, 1985), popular. EKF linearises estimation problemKalman filter applied. required probability density function (p.d.f.) still approximatedGaussian, may lead filter divergence, therefore increase error.approaches include Gaussian sum filter (Sorenson & Alspach, 1971), superimposing gridstate space belief evaluated grid points (Kramer & Sorenson,1988). latter approach, choice efficient grid non-trivial, method sufferscurse dimensionality: number grid points must considered exponentialdimensions state space. Recently, techniques utilize Monte Carlo (MC) samplingapproximating Bayesian state estimation problem received much attention. techniques general enough, that, applicable linear, well as, non-linear problemdynamics, rate convergence approximation error zero independent dimensions underlying state space. Among spectrum MC techniques, twoparticularly well-studied sequential settings Markov chain Monte Carlo (MCMC) (Hastings,1970; Gelman et al., 2004), particle filters (Gordon et al., 1993; Doucet et al., 2001). Approximating I-POMDP belief update using former technique, may turn computationallyexhaustive. Specifically, MCMC algorithms utilize rejection sampling (e.g. Hastings, 1970)may cause large number intentional models sampled, solved, rejected, oneutilized propagation. addition, complex estimation process I-POMDPs makestask computing acceptance ratio rejection sampling computationally inefficient. AlthoughGibbs sampling (Gelman et al., 2004) avoids rejecting samples, would involve samplingconditional distribution physical state given observation history model other,distribution others model given physical state. However, distributionsneither efficient compute easy derive analytically. Particle filters need reject solvedmodels compute new model replacement, propagating solved models timeresampling them. intuitively amenable approximating I-POMDP belief updateproduce reasonable approximations posterior computationally feasible.Particle filters previously successfully applied approximate belief updatecontinuous state space single agent POMDPs (Thrun, 2000; Poupart, Ortiz, & Boutilier, 2001).Thrun (2000) integrates particle filtering Q-learning learn policy, Poupart etal. (2001) assume prior existence exact value function present error bound analysis substituting POMDP belief update particle filters. Loosely related work300fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPsampling algorithms appear (Ortiz & Kaelbling, 2000) selecting actions influencediagrams, work focus sequential decision making. multiagent setting, particle filters employed collaborative multi-robot localization (Fox, Burgard, Kruppa,& Thrun, 2000). application, emphasis predicting position robot,actions robots, critical step approach. Additionally, facilitate fast localization, beliefs robots encountered motion considered fullyobservable enable synchronization.Within POMDP literature, approaches sampling methods also appearedaddress curse dimensionality. important class algorithms prescribe substitutingcomplex belief space simpler subspace (Bertsekas, 1995; Tsitsiklis & Roy, 1996; Poupart& Boutilier, 2003; Roy, Gordon, & Thrun, 2005). premise methods beliefs distributions physical states contain information required orderplan near-optimally. Poupart Boutilier (2003) use Krylov subspaces (Saad, 1996) directlycompress POMDP model, analyze effect compression decision quality.ensure lossless compression, i.e. decision quality compressed belief compromised, transition reward functions must linear. Roy et al. (2005) proposed using principalcomponent analysis (Collins, Dasgupta, & R.E.Schapire, 2002) uncover low dimensional beliefsubspace usually encompasses robots potential beliefs. method based observation beliefs along many real-world trajectories exhibit degrees freedom.effectiveness methods problem specific; indeed, possible encounter problemssubstantial belief compression may occur. applied I-POMDP framework,effectiveness compression techniques would depend, example, existence agentmodels whose likelihoods within agents belief change successive belief updatesexistence correlated agent models. Whether models exist practice topicfuture work.Techniques address curse history POMDPs also exist. Poupart Boutilier (2004)generate policies via policy iteration using finite state controllers bounded number nodes.Pineau et al. (2006) perform point-based value iteration (PBVI) selecting small subset reachable belief points step belief simplex planning belief points.Doshi Perez (2008) outline challenges develop PBVI I-POMDPs. Thoughmethod mitigating curse history conceptually close point based selection methods,focus plan computation initial belief known previously mentioned methodstypically utilized offline planning. approximate way solving POMDPs onlineRTBSS approach (Paquet, Tobin, & Chaib-draa, 2005; Ross et al., 2008) adopts branch-andbound technique pruning look ahead reachability tree. approach focuses selectingbest action expand complementary approach sampling observations.Further, extension multiagent setting formalized I-POMDPs may trivial dueneed bounding heuristic function whose formulation multiagent settings remainsinvestigated.3. Background: Particle Filter Single Agent Settingact rationally uncertain settings, agents need track evolution state time,based actions perform available observations. single agent settings,state estimation usually accomplished technique called Bayes filter (Russell & Norvig,301fiD OSHI & G MYTRASIEWICZ2003). Bayes filter allows agent maintain belief state world giventime, update belief time action performed new sensory information arrives.convenience approach lies fact update independent past perceptsaction sequences. agents belief sufficient statistic: fully summarizesinformation contained past actions observations.operation Bayes filter decomposed two-step process:Prediction: agent performs new action, at1 , prior belief state updated:Zt1 t1P r(s |a , b ) =bt1 (st1 )T (st |st1 , at1 )dst1(1)st1Correction: Thereafter, observation, ot , received, intermediate belief state,P r(|at1 , bt1 ), corrected:P r(st |ot , at1 , bt1 ) = O(ot |st , at1 )P r(st |at1 , bt1 )(2)normalizing constant, transition function gives uncertain effectperforming action physical state, observation function giveslikelihood receiving observation state performing action.Particle filters (PF) (Gordon et al., 1993; Doucet et al., 2001) specific implementationsBayes filters tailored toward making Bayes filters applicable non-linear dynamic systems.Rather sampling directly target distribution often difficult, PFs adoptmethod importance sampling (Geweke, 1989), allows samples drawntractable distribution called proposal distribution, . example, P r(S |ot , at1 , bt1 )target posterior distribution, (S |ot , at1 , bt1 ) proposal distribution, support(S |ot , at1 , bt1 ) includes support P r(S |ot , at1 , bt1 ), approximate targetposterior sampling N i.i.d. particles {s(n) , n = 1...N } according (S |ot , at1 , bt1 )assigning particle normalized importance weight:w(se (n) )P r(s(n) |ot , at1 , bt1 )w(n) = PNw(se (n) ) =(s(n) |ot , at1 , bt1 )e (n) )n=1 w(strue probability, P r(s|ot , at1 , bt1 ), approximated by:t1P rN (s|o ,t1,b)=NXw(n) (s s(n) )n=1a.s.() Dirac-delta function. N , P rN (s|ot , at1 , bt1 ) P r(s|ot , at1 , bt1 ).applied recursively several steps, importance sampling leads large varianceweights. avoid degeneracy, Gordon et al. (1993) suggested inserting resampling step,would increase population particles high importance weights.beneficial effect focusing particles high likelihood regions supported observations increasing tracking ability PF. Since particle filtering extends importancesampling sequentially appends resampling step, also called sequential importancesampling resampling (SISR).302fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPgeneral algorithm particle filtering technique given Doucet et al. (2001).concentrate specific implementation algorithm, previously studiedvarious names MC localization, survival fittest, bootstrap filter. implementation maintains set N particles denoted ebt1 independently sampled prior,bt1 , takes action observation input. particle propagated forwards time,using transition kernel environment. particle weighted likelihoodperceiving observation state particle represents, given observationfunction O. followed (unbiased) resampling step, particles picked proportionately weights, uniform weight subsequently attached particle.outline algorithm bootstrap filter Fig. 1. Crisan Doucet (2002) outline rigorousproof convergence algorithm toward true posterior N .Function PARTICLEFILTER(ebt1 , at1 , ot ) returns ebt1. ebtmp , ebtImportance Sampling2. s(n),t1 ebt13.Sample s(n),t (S |at1 , s(n),t1 )4.Weight s(n),t importance weight:we(n) = O(ot |s(n),t , at1 )5. ebtmp (s(n),t , we(n) )P(n) = 16. Normalize we(n) Nn=1 wSelection7. Resample replacement N particles {s(n),t , n = 1...N }set ebtmp according importance weights.8. ebt {s(n),t , n = 1...N }9. return ebtend functionFigure 1: particle filtering algorithm approximating Bayes filter.Let us understand working PF context simple example single agenttiger problem (Kaelbling, Littman, & Cassandra, 1998). single agent tiger problem resemblesgame show agent choose open one two doors behind lies eithervaluable prize dangerous tiger. Apart actions open doors, subject optionlistening tigers growl coming left, right door. However, subjects hearingimperfect, given percentages (say, 15%) false positive false negative occurrences.Following Kaelbling et al. (1998), assume value prize 10, pain associatedencountering tiger quantified -100, cost listening -1.Let agent prior belief according uninformed locationtiger. words, believes probability 0.5 tiger behind left door (TL),similar probability tiger behind right door (TR). see agentapproximately updates belief using particle filter when, say, listens (L) hears growlleft (GL). Fig. 2 illustrates particle filtering process. Since agent uninformedtigers location, start equal number particles (samples) denoting TL (lightly303fiD OSHI & G MYTRASIEWICZGL~t-1bi~ tmpbiPropagateWeight~tbiResampleLCorrection stepPrediction stepFigure 2: Particle filtering state estimation single agent tiger problem. light darkparticles denote states TL TR respectively. particle filtering process consiststhree steps: Propagation (line 3 Fig. 1), Weighting (line 4), Resampling (line 7).shaded) TR (darkly shaded). initial sample set approximately representative agentsprior belief 0.5. Since listening change location tiger, compositionsample set remains unchanged propagation. hearing growl left, light particlesdenoting TL tagged larger weight (0.85) likely responsibleGL, dark particles denoting TR (0.15). Here, size particle proportionalweight attached particle. Finally, resampling step yields sample set time step t,contains particles denoting TL TR. sample set approximately representsupdated belief 0.85 agent tiger behind left door. Note propagationcarries task prediction shown Eq. 1 approximately, correction step (Eq. 2)approximately performed weighting resampling.4. Overview Finitely Nested I-POMDPsI-POMDPs (Gmytrasiewicz & Doshi, 2005) generalize POMDPs handle multiple agents.including models agents state space. focus finitely nested I-POMDPshere, computable counterparts I-POMDPs general. simplicity presentationlet us consider agent, i, interacting one agent, j. arguments generalizesetting two agents straightforward manner.Definition 1 (I-POMDPi,l ). finitely nested interactive POMDP agent i, I-POMDPi,l , is:I-POMDPi,l = hISi,l , A, Ti , , Oi , Riwhere:ISi,l set interactive states defined ISi,l = Mj,l1 , l 1, ISi,0 = S,1set states physical environment, Mj,l1 set possible models agent j.1. agents participating interaction, K > 2, ISi,l = K1j=1 Mj,l1304fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPmodel, mj,l1 Mj,l1 , defined triple, mj,l1 = hhj , fj , Oj i, fj : Hj (Aj )agent js function, assumed computable, maps possible histories js observations, Hj ,distributions actions. hj element Hj , Oj function, also computable,specifying way environment supplying agent input. simplicity, maywrite model mj,l1 mj,l1 = hhj ,b j i,b j consists fj Oj .specific class models (l 1)th level intentional models, j,l1 , agent j: j,l1 =hbj,l1 , A, j , Tj , Oj , Rj , OCj i. bj,l1 agent js belief nested level l1, bj,l1 (ISj,l1 ),OCj js optimality criterion. Rest notation standard. may rewrite j,l1 as,b j includes elements intentional modelj,l1 = hbj,l1 , bj i, bjbelief called agent js frame. intentional models analogous types usedBayesian games (Harsanyi, 1967).mentioned Gmytrasiewicz Doshi (2005), may also ascribe subintentionalmodels, SMj , constitute remaining models Mj,l1 . Examples subintentional modelsfinite state controllers fictitious play models (Fudenberg & Levine, 1998).consider models here, could accommodated straightforward manner.order promote understanding, let us define finitely nested interactive state spaceinductive manner:ISi,0 = S,j,0 = {hbj,0 , bj : bj,0 (ISj,0 ), = Aj },ISi,1 = j,0 ,j,1 = {hbj,1 , bj : bj,1 (ISj,1 )},ISi,l...= j,l1 , j,l...= {hbj,l , bj : bj,l (ISj,l )}.Recursive characterizations state spaces analogous appeared previouslygame-theoretic literature (Mertens & Zamir, 1985; Brandenburger & Dekel, 1993; Battigalli &Siniscalchi, 1999) led definitions hierarchical belief systems.proposed mathematical formalizations type spaces Bayesian games. Additionally,nested beliefs are, general, analogous hierarchical priors utilized Bayesian analysishierarchical data (Gelman et al., 2004). Hierarchical priors arise unknown priors assumeddrawn population distribution, whose parameters may unknown therebymotivating higher level prior.= Ai Aj set joint moves agents.Ti transition function, Ti : [0, 1] describes results agents actionsphysical states world. (It assumed actions directly change physical stateonly, see Gmytrasiewicz & Doshi, 2005).set agent observations.Oi observation function, Oi : [0, 1] gives likelihood perceivingobservations state resulting performing action. (It assumed physicalstate directly observable, models agent.)Ri defined as, Ri : ISi R. agent allowed preferences physicalstates models agents, usually physical state matter.305fiD OSHI & G MYTRASIEWICZ4.1 Belief UpdateAnalogous POMDPs, agent within I-POMDP framework also updates belief actsobserves. However, two differences complicate belief update multiagentsettings, compared single agent ones. First, since state physical environmentdepends actions performed agents, prediction physical state changesmade based predicted actions agent. probabilities others actionsobtained based models. Second, changes models agentincluded update. Specifically, since agents model intentional updateagents beliefs due new observation included. words, agentupdate beliefs based anticipates agent observes updates.belief update function agent finitely nested I-POMDP framework is:Rbti (ist ) =ist1 :bjt1 =bjtt1 )bt1i,l (isPat1jt1t1 , ot ) (st1 , at1 , st )P r(at1j |j,l1 ) Oi (s ,Pt1t1 , ot ) ist1(SEbt (bt1jj,l1 , aj , oj ) bj,l1 ) Oj (s ,otjj(3)normalization constant, Dirac-delta function, SEbt () abbreviationjt1t1denoting belief update, P r(at1Bayes rationalj |j,l1 ) probability ajt1agent described j,l1 .j also modeled I-POMDP, belief update invokes js belief update (via termt1SEbt (bt1j,l1 , aj , oj )), turn invokes belief update on. recursion beliefjnesting bottoms 0th level. level, belief update agent reduces POMDPbased belief update. 2 illustration belief update, additional details I-POMDPs,compare multiagent planning frameworks, see (Gmytrasiewicz & Doshi, 2005).manner similar belief update POMDPs, following proposition holdsI-POMDP belief update. proposition results noting Eq. 3 expresses beliefterms parameters previous time step only. complete proof belief updateproposition given Gmytrasiewicz Doshi (2005).Proposition 1. (Sufficiency) finitely nested I-POMDPi,l agent i, current belief, i.e.,probability distribution set j,l1 , sufficient statistic past historyobservations.4.2 Value Iterationlevel l belief state I-POMDPi,l associated value reflecting maximum payoffagent expect belief state:RERi (is, ai )bi,l (is)d is+U (hbi,l , bi i) = maxai AiisISi,l(4)Pt1bP r(oi |ai , bi,l )U (hSEbi (bi,l , ai , oi ), i)oi2. 0th level model POMDP: agents actions treated exogenous events folded T, O, R.306fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPPwhere, ERi (is, ai ) = aj Ri (is, ai , aj )P r(aj |j,l1 ) (since = (s, j,l1 )).Eq. 4 basis value iteration I-POMDPs, succinctly rewritten U =HU t1 , H commonly known value backup operator. Analogous POMDPs, Hisotonic contracting, thereby making value iteration convergent (Gmytrasiewicz &Doshi, 2005).Agent optimal action, ai , case finite horizon discounting, elementset optimal actions belief state, OP (i ), defined as:OP (hbi,l , bi i) = argmaxai AiRERi (is, ai )bi,l (is)d is+isISi,lPoibP r(oi |ai , bi,l )U (hSEbi (bi,l , ai , oi ), i)(5)5. Example: Multiagent Tiger Problemillustrate approximation methods, utilize multiagent tiger problem example.multiagent tiger problem generalization single agent tiger problem outlined Section 3multiagent setting. sake simplicity, restrict two-agent setting,problem extensible agents straightforward way.two-agent tiger problem, agent may open doors listen. make interactioninteresting, addition usual observation growls, added observation doorcreaks, depends action executed agent. Creak right (CR) likely dueagent opened right door, similarly creak left (CL). Silence (S) goodindication agent open doors listened instead. assume accuracycreaks 90%, accuracy growls 85% before. Again, tiger location chosenrandomly next time step agents opened doors current step. alsoassume agents payoffs analogous single agent version. Note resultassumption agents actions impact original agents payoffs directly,rather indirectly resulting states matter original agent. Table 1 quantifiesfactors.agent makes choice multiagent tiger problem, may find useful considerbelieves location tiger, well whether agent listenopen door, turn depends agents beliefs, preferences capabilities.particular, agent open doors, tigers location next timestep would chosen randomly. information agent tigers location tillthen, would reduce zero. simplify situation somewhat assuming agentjs properties, except beliefs, known i, js time horizon equal is.words, uncertainty pertains js beliefs frame.6. Representing Prior Nested Beliefsmentioned, infinity intentional models agent. Since agent unawaretrue models interacting agents ex ante, must maintain belief possible candidatemodels. complexity space precludes practical implementations I-POMDPs307fiD OSHI & G MYTRASIEWICZhai , ajhOL,hOR,h, OLih, ORihL, LihL, LiState****TLTRTL0.50.50.50.51.00TR0.50.50.50.501.0hai , ajhOR, ORihOL, OLihOR, OLihOL, ORihL, LihL, ORihOR, LihL, OLihOL, LiTransition function: Ti = TjTL10-10010-100-1-110-1-100TR-10010-10010-1-1-100-110hai , ajhOR, ORihOL, OLihOR, OLihOL, ORihL, LihL, ORihOR, LihL, OLihOL, LiTL10-100-10010-110-1-100-1TR-1001010-100-1-100-110-1Reward functions agents jhai , ajhL, LihL, LihL, OLihL, OLihL, ORihL, ORihOL,hOR,StateTLTRTLTRTLTRh GL, CL0.85*0.050.15*0.050.85*0.90.15*0.90.85*0.050.15*0.051/61/6h GL, CR0.85*0.050.15*0.050.85*0.050.15*0.050.85*0.90.15*0.91/61/6h GL,0.85*0.90.15*0.90.85*0.050.15*0.050.85*0.050.15*0.051/61/6h GR, CL0.15*0.050.85*0.050.15*0.90.85*0.90.15*0.050.85*0.051/61/6h GR, CR0.15*0.050.85*0.050.15*0.050.85*0.050.15*0.90.85*0.91/61/6h GR,0.15*0.90.85*0.90.15*0.050.85*0.050.15*0.050.85*0.051/61/6hai , ajhL, LihL, LihOL, LihOL, LihOR, LihOR, Lih, OLih, ORiStateTLTRTLTRTLTRh GL, CL0.85*0.050.15*0.050.85*0.90.15*0.90.85*0.050.15*0.051/61/6h GL, CR0.85*0.050.15*0.050.85*0.050.15*0.050.85*0.90.15*0.91/61/6h GL,0.85*0.90.15*0.90.85*0.050.15*0.050.85*0.050.15*0.051/61/6h GR, CL0.15*0.050.85*0.050.15*0.90.85*0.90.15*0.050.85*0.051/61/6h GR, CR0.15*0.050.85*0.050.15*0.050.85*0.050.15*0.90.85*0.91/61/6h GR,0.15*0.90.85*0.90.15*0.050.85*0.050.15*0.050.85*0.051/61/6Observation functions agents j.Table 1: Transition, reward, observation functions multiagent tiger problem.simplest settings. Approximations based sampling use finite set sample pointsrepresent complete belief state.order sample nested beliefs first need represent them. Agent level 0 belief,defbi,0 (S), vector probabilities physical state: bi,0 = h pi,0 (s1 ), pi,0 (s2 ),. . ., pi,0 (s|S| ) i. first second subscripts bi,0 denote agent level nesting,P|S|respectively. Since belief probability distribution, q=1 pi,0 (sq ) = 1. refer constraintP|S|1simplex constraint. may write, pi,0 (s|S| ) = 1 q=1 pi,0 (sq ), subsequently,|S| 1 probabilities needed specify level 0 belief.tiger problem, let s1 = L s2 = R. example level 0 belief tigerdefproblem, bi,0 = hpi,0 (T L), pi,0 (T R)i, h0.7, 0.3i assigns probability 0.7 L 0.3R. Knowing pi,0 (T L) sufficient complete specification level 0 belief.308fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPAgent first level belief, bi,1 (S j,0 ), vector densities js level 0 beliefs,one combination state js frame possibly distinct other. Hence,hs,bj0.5060.5040.504<TR,m><TR, >(p )j,0(pj,0)0.5060.50.498pp i,1i,1>0.502<TL,p p<TL,m>(p(p ) )j,0i,1 i,1j,0b ||S||hs,bhs,bjb j | densities: bi,1 def|S||= h pi,1 j 1 , pi,1 j 2 , . . ., pi,1i, hs, bj ik ,b j | particular state js frame combination. simplex conk = 1, . . . , |S||straint, sum integrals level 1 densities level 0 beliefs must 1. observelevel 1 densities may represented using family probability distributionsexponential family (Dobson, 2002) polynomials allow approximation functionarbitrary accuracy. such, densities could exhibit shape given satisfy simplexconstraint.0.5020.50.4980.4960.4960.4940.49400.20.40.6p(TL)j,00.8010.20.4p0.6j,00.810.81(TL)0.80.80.70.7<TR, >pp<TR,m>(p (p) )i,1j,0 j,0i,1<TL,m>> (p )p<TL,p(p )i,1 i,1j,0j,0(a)0.60.50.40.30.20.60.50.40.30.20.10.10000.20.4p0.6j,00.8010.20.4p(TL)0.6j,0(TL)(b)Figure 3: Example level 1 beliefs two-agent tiger problem. (a) According belief,uninformed js level 0 beliefs. Since marginal plot 0.5, alsounaware location tiger. (b) Agent believes j likely knows locationR 0.5 hT L,bR 1 hT L,btiger ( 0 pi,1(pj,0 )dpj,0 0.5 pi,1(pj,0 )dpj,0 ), though unawaremarginal plot 0.5.defhT L,bhT R,bexample level 1 belief i, bi,1 = hpi,1 j , pi,1 j i, tiger problem one accordinguninformed js level 0 beliefs location tiger (see Fig. 3(a)).superscript, bj , agent js frame known i. Another example level 1 belief oneaccording believes j likely knows location tiger (Fig. 3(b)).Agent second level belief, bi,2 (S j,1 ), vector densities js level 1 beliefsstate js intentional frame. comparison level 0 level 1 beliefs, representing doubly-nested beliefs beliefs deeper nestings trivial.distributions density functions whose representations need finite. example, let js309fiD OSHI & G MYTRASIEWICZsingly-nested belief densities represented using family polynomials. Then, doublynested belief js densities vector normalized mathematical functions variablesvariables parameters lower-level densities. lower level densities polynomials could degree therefore number coefficients, functionsrepresent doubly-nested beliefs may indefinite number variables. Thus computable representations level 2 beliefs trivially obtained. formalize observation usingProposition 2, shows multiply-nested beliefs necessarily partial functions failassign probability elements (lower level beliefs) domain.Proposition 2. Agent multiply nested belief, bi,l , l 2, strictly partial recursive function.Proof. briefly revisit definition nested beliefs: bi,l (ISi,l ) = (S j,l1 ) = (Sb j i), Bj,l1 level l 1 belief simplexb j set frames j.hBj,l1 ,b j i). state frame spacesbasis case, let l = 2, bi,2 (S hBj,1 ,discrete, bi,2 may represented using collection density functions js beliefs, onehs,bdiscrete state js frame combination, pi,2 j (bj,1 ), bj,1 Bj,1 . Notice that, bj,1singly-nested, collection densities js level 0 beliefs, one statedefhs,bhs,bi i|S||bhs,b|frame combination. Thus, mentioned let bj,1 = h pj,1 1 , pj,1 2 , . . ., pj,1i.Recall Section 4 models therefore belief density functions assumedhs,bi i1computable. Let x program length bits, l(x), encodes, say pj,1g. define complexity density function,g(x) =hs,bpj,1 1 }.hs,bpj,1 1 ,as:, languagehs,bCg (pj,1 1 )= min {l(x) :Cg () minimum length program language g computes argument.3hs,observe l(x) proportional number parameters describe pj,1 1 .number parameters density need bounded, l(x) consequently complexitydensity may finite. Intuitively, equivalent saying density couldshape.hs,bjAssume, way contradiction, level 2 density function, pi,2hs,pi,2 jtotal recursivetotal, haltfunction. Construct Turing machine, , computes it.inputs. Specifically, read set symbols input tape describe level 1 densityfunction (the program, x), finished reading halts leaves number 01 output tape. number output density function encoded . Noteexecute input program x, simply parses enable identification. Thusuniversal Turing machine. mentioned previously, minimum length program (and hencecomplexity) encodes level l density function may infinite. Thus size setsymbols input tape , l(x), may infinite, may halt. contradiction.hs,bThus, pi,2 j partial recursive function.argument may extended inductively levels nesting.multiply-nested beliefs general form partial recursive functions defined every possible lower level belief domain, restrictions complexity3. Note complexity, Cg , within constant Kolmogorov complexity (Li & Vitanyi, 1997) densitybi i1hs,function, pj,1.310fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPnested beliefs (where complexity defined Proposition 2) needed allow computability well-defined. One way focus attention limited representationsinvolving bounded number parameters.complications, general-purpose language representing nested beliefsbeyond scope article attempt here; topic continuing investigations. Instead, utilize specific examples doubly-nested deeply nested beliefsexperiments remainder article.7. Decomposing I-POMDP Belief UpdateAnalogous Eqs. 1 2 Bayes filter, decompose I-POMDP belief update twosteps. decomposition facilitates better understanding belief update, alsoplays pivotal role development approximation.t1Prediction: agent, say i, performs action at1, agent j performs aj ,predicted belief state is:t1 t1P r(ist |at1, aj , bi,l ) =Rt1bt1 (ist1 )P r(at1j |j,l1 )t1 :bjt1 =bjt i,lPt1t1 t1Ti (st1 , at1otj Oj (s , ai , aj , oj ), aj , )t1t1(SEbt (bt1j,l1 , aj , oj ) bj,l1 )j(6)Dirac-delta function, SEbt () abbreviation belief update, P r(at1jjt1t1| j,l1) probability at1Bayes rational agent described j,l1.jCorrection: agent perceives observation, oti , corrected belief state weightedsum predicted belief states possible action j:t1P r(ist |oti , at1, bi,l ) =Xt1t1 t1 t1Oi (st , at1, aj , oi )P r(is |ai , aj , bi,l )(7)at1jnormalizing constant.Equations 6 7 along Proposition 1 may seen generalization single agentBayes filter (see Section 3) multiagent setting. general level, equations representapplication update hierarchical priors given observed data (Gelman et al., 2004)problem state estimation multiagent settings.8. Interactive Particle Filter Multiagent Settingpresented algorithm traditional bootstrap filter Section 3. mentioned before,bootstrap filter MC sampling based randomized implementation POMDP belief update(Bayes filter). generalize implementation approximate I-POMDP belief updatesteps presented previously Section 7.311fiD OSHI & G MYTRASIEWICZ8.1 Descriptiongeneralization PF multiagent case, call interactive particle filter(I-PF), similar basic PF, involves key steps importance sampling selection.resulting algorithm inherits convergence properties original algorithm (Doucet et al.,2001). Specifically, approximate posterior belief generated filter converges truth(as computed Eqs. 6 7) number particles (N ) tends infinity. Note presenceagents affect convergence because, (a) exact belief update providesstationary point similarly reasons presence agents, (b) explicitly modelagents actions due nonstationarity environment vanishes.extension PF multiagent setting turns nontrivialfaced predicting agents action(s), requires us deal interactive beliefhierarchy. Analogously I-POMDP belief update, I-PF reduces traditional PFone agent environment.I-PF, described Fig. 4, requires initial set N particles, ebt1k,l , approximatelyt1representative agents prior belief, along action, ak , observation, otk ,level belief nesting, l > 0. per convention, k stand either agent j, k(n)agent, j i, appropriate. particle, isk , sample set represents agentspossible interactive state, agents belief may set particles. Formally,(n)(n)(n)(n)(n)(n)isk = hs(n) , k i, k = hebk,l1 , bk i. Note ebk,0 probability distributionphysical state space.generate ebt1k,l sampling N particles prior nested belief. Given prior nestedbelief, simple recursive procedure first uses marginals physical statesframes current nesting level sample state frame agent. sampleN particles density lower level beliefs, conditioned sampled state framecombination. belief multiply nested, operation recursively performed bottominglowest level agents flat (level 0) beliefs sampled.interactive particle filtering proceeds propagating particle forward time. However, opposed traditional particle filtering, one-step process: (i) orderperform propagation, agents action must known. model ascribedagent intentional, obtained solving agents model (using algorithm APPROXPOLICY described later Section 9) find distribution actions,action sampled (lines 34 Fig. 4). Specifically, OPT set optimal actions obtainedsolving model, P r(ak ) = |OP1 | ak OPT, 0 otherwise. (ii) Additionally,analogous exact belief update, agents possible observations, mustupdate model (line 6). model intentional, must update belief state. l > 1,updating agents belief requires recursively invoking I-PF performing belief update (lines 1214). recursion depth belief nesting terminates level nestingbecomes one, LEVEL0BELIEFUPDATE, described Fig. 5, performed (lines 810).4addition using agents observation weighting, agents observations also participate weighting process (lines 1516). latter allows us distinguish js beliefslikely given physical state. Though propagation weighting steps generate |k |Nappropriately weighted particles, resample N particles (line 19), using unbiased4. physical state space also continuous large, would replace level 0 belief updatetraditional particle filter. However, so, would loose theoretical bounds given Section 9.1312fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPt1 t1Function I-PARTICLEFILTER (ebk,l, ak , ok , l > 0) returns ebtk,ltmpee1. bk,l , bk,lImportance Sampling(n),t1(n),t1t12. isk= hs(n),t1 , kebk,l(n),t1(n),t13.P r(Ak |k) APPROXPOLICY(k, l 1)(n),t1t14.Sample akP r(Ak |k)// Sample agents actiont1 (n),t15.Sample s(n),t Tk (S |akt1 , ak,s) // Sample physical state6.ok k// Update agents belief7.(l = 1)// I-POMDP singly nested(n),t(n),t1 t18.bk,0 LEVEL0BELIEFUPDATE(bk,0 , ak, ok )(n),t(n),t b(n)9.k hbk,0 , k(n),t(n),t10.iskhs(n),t , k11.else// I-POMDP multiply nested(n),t(n),t1 t1ee12.bk,l1 I-PARTICLEFILTER(bk,l1 , ak , ok , l 1)(n),t(n),t(n)13.k h ebk,l1 , bk(n),t(n),t14.iskhs(n),t , k(n),t(n)t115.Weight isk : wt Ok (otk |s(n),t , akt1 , ak)(n)(n)(n),t t1 t116.Adjust weight: wt wt Ok (ok |s, ak , ak )(n),t(n)ebtmp17.(isk , wt )k,lPN(n)(n)18. Normalize wt n=1 wt = 1Selection(n),t19. Resample replacement N particles {isk , n = 1...N }tmpset ebk,l according importance weights.(n),te20. btk,l {isk , n = 1...N }21. return ebtk,lend functionFigure 4: Interactive particle filtering approximating I-POMDP belief update. nestingfilters used update levels belief. k denotes either agent j, kagent, j i, appropriate. Also see Fig. 6 visualization.resampling scheme. Lines 215 represent simulation prediction step (Eq. 6), lines1620 simulated implementation correction step (Eq. 7).alternative approach within propagation step sample agents observationhidden variable. may update belief given sampled observation.Although statistically equivalent approach, involves additional step sampling,contributes sources error I-PF. particular, lesser number particles,agents beliefs resulting low probability observations may appear resampledposterior. agents low probability observations less likely sampled.original agents observation independent others belief, particles identicalphysical states different beliefs weighted equally. beliefs resultinglow probability observations less frequent sample set, less likely pickedresampled posterior. comparison, weighting using agents observation removes313fiD OSHI & G MYTRASIEWICZt1 t1Function LEVEL0BELIEFUPDATE (bk,0, ak , ok ) returns btk,0t1t11. P r(ak ) 1/ak// agents action noise2. st3.sum 04.st15.P r(st |st1 , akt1 ) 0t16.akAk// Marginalize noise+t1t17.P r(st |st1 , akt1 ) Tk (st |st1 , akt1 , ak)P r(ak)+t1 t1 t1 t18.sum P r(s |s , ak )bk (s )9.P r(otk |st , akt1 ) 0t110.akAk// Marginalize noiset1t1 +t1 t111.P r(ok |s , ak ) Ok (ok |s , ak , ak )P r(ak)t112.bk,0 (s ) P r(ok |s , ak ) sum13. Normalize belief, btk14. return btkend functionFigure 5: level 0 belief update similar exact POMDP belief updateagents actions treated noise. example, noise may simply uniformdistribution agents actions.intermediate sampling step source error expense temporarily generatinglarger number particles. Based preference reduced approximation error computationalefficiency, one two alternative steps may used.visualization I-PF implementation shown Fig. 6. Note number particlesgrows exponentially nesting level, due approach becomes intractablelarger number levels. method limit number particles descendnesting level needed address source complexity. one line future work.Notice I-PF could also viewed recursive implementation approximatelyRao-Blackwellised particle filter (RBPF) (Doucet, de Freitas, Murphy, & Russell, 2000),conditional distribution models updated using RBPF. Doshi (2007) presentedRao-Blackwellised I-PF (RB-IPF), conditional distribution updated using variationalKalman filter. Although performance RB-IPF improves I-PF, restricted priorbeliefs Gaussian could generalized beyond single level nesting.8.2 Illustration I-PFillustrate operation I-PF using multiagent tiger problem introduced Section 5.sake simplicity consider prior belief singly nested, i.e. l = 1. procedurerecursively performed deeply nested beliefs. Let uninformed js level 0 beliefs,location tiger (see Fig. 3(a)). demonstrate operation I-PFcase listens (L) hears growl left creaks, hGL,Si.Fig. 7, show initial sample set, ebt1i,1 , consisting N = 2 particles approximately representative singly-nested beliefs. Since assume js frame known,314fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPtimedepthokbt1btmpbk,lk,lPropagationWeightk,lResamplet1akb(n),t1bk,l1(n) (n)(n) (n), k ,, k ,b (n),t1b (n),tk,l2k,l2(n) (n)(n) (n)s, k ,s, k ,b (n),tb (n),t1k,1k,1Level 1(n),tk,l1(n) (n)(n) (n)s, k,s, k,t1b kb kFigure 6: illustration nesting I-PF. Colors black gray distinguish filteringtwo agents. propagation step involves updating agents beliefs,perform particle filtering beliefs. filtering terminates reacheslevel 1 nesting, level 0 belief update performed agent.~ t-1b i,1t-1<st- 1 = TL, b j,0= 0.5><st- 1 = TR, b t-1j,0 = 0.5>ait-1 =LFigure 7: initial sample set 2 particles approximately representative bt1i,1 shownFig. 3(a).particle interactive state consisting tigers location js level 0 belief. Let belief0.5 j sampled flat line densities.315fiD OSHI & G MYTRASIEWICZ~ t-1bi,1<st- 1 = TL, b t-1j,0 = 0.5>t-1j =L<st- 1 = TR, b t-1j,0 = 0.5>t-1j =Lt-1=LFigure 8: initial sample set js optimal action shown particle.mentioned before, propagation particles time step 1 two-stepprocess. first step, solve js POMDP compute optimal action belief 0.5.js action listen since know location tiger. depict Fig. 8.~ t-1b i,1PropagationL,GRL,GL< st = TL , b j,0= 0.15>1 . Sample ~ T(S|st-1 ,ait-1 ,ajt-1 )2 . forall otj bj,0= SEj (bj,0t -1,ajt-1 ,ojt )= 0.85>< = TL, bj,0L,GRt-1=L< = TR, bj,0= 0.85>L,GL< = TR, b j,0= 0.15>Figure 9: propagation particles time step 1 time step t. involves samplingnext physical state updating js beliefs anticipating observations (denotedusing dashed arrows). j may receive one two observations, 4particles propagated sample set.second step propagation sample next physical state particle usingtransition function. Since j listen, location tiger remains unchanged. Next,must update js beliefs. anticipating j might observe, updating beliefexactly given optimal action listening. Since j could receive one two possible observationsGL GR particle splits two. shown using dashed arrows goingparticles initial sample set particles propagated sample set, Fig. 9. jhears GL, updated belief 0.85 (that tiger behind left door), otherwise 0.15hears GR. level belief nesting greater one, js belief update would performedrecursively invoking interactive particle filter js beliefs.316fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPoit =GL,S~ t-1bi,1Propagation~bi,1 tmpWeighting< = TL , bj,0t = 0.15>w = 0.15*0. 765 = 0. 115< = TL , bj,0t = 0.85>w = 0.85*0. 765 = 0. 650< = TR , bj,0t = 0.85>w = 0.15*0. 135 = 0. 020ait-1 =L<st- 1 = TR , bj,0t = 0.15>w = 0.85*0. 135 = 0. 115Figure 10: weighting step two step process: particle first weighted likelihood j receives observations, followed adjusting weight usingprobability making observation hGL,Si. Note resulting weights shownnormalized.part weighting, first weight particle probability j receivingobservations. Particles larger weights contain beliefs j likely. Thereafter,scale weight probability observing growl left creaks,hGL,Si. understand weighting process, lets focus single particle. Weightingremaining particles analogous.consider particle top right sample set, ebtmpi,1 , shown Fig. 10. Agent jslevel 0 belief 0.85 particle due j hearing growl left listening.probability j making observation given observation function, tigerleft 0.85. adjust weight probability perceiving hGL,Si tigerleft agents listening. probability given observation function0.765 (see Table 1). final weight attached particle 0.65. Note weightsshown Fig. 10 normalized. normalization belief tiger left0.85 (obtained adding normalized weights particles st =TL), 0.15 tigerright. note conforms expectations.final step I-PF unbiased resampling particles using weightsdistribution. prevent exponential growth number particles 5 , resample N particlesresulting sample set, ebti,1 , approximately representative exactly updated belief.belief nested deeper levels, mentioned example forms bottom steprecursive filtering process.8.3 Performance I-PFpart empirical investigation performance I-PF, show, using standardpseudo-distance metric visually, approximates exact state estimation closely.5. propagation steps, N |j |t particles sample set.317fiD OSHI & G MYTRASIEWICZ=GL,S~bi,1t-1Propagation~bi,1 tmpWeighting~bi,1tResampling< = TL , bj,0t = 0.85>< = TL , bj,0t = 0.85>t-1ai =LFigure 11: final step unbiased resampling using weights distribution.begin utilizing extended versions standard test problems proceed demonstrate performance larger problem.8.3.1 ULTIAGENT IGER ACHINE AINTENANCE P ROBLEMSanalysis, first utilize two-agent tiger problem two physical states, described Section 5, two-agent version machine maintenance problem (MM) (Smallwood & Sondik, 1973) described detail Appendix A, three physical states.problems physical states, interactive state space tends get large includes modelsagent. Due absence general approximation techniques I-POMDPs,use grid based numerical integration implementation exact filter baseline approximation comparison. obtained points numerical integration superimposing regulargrids differing resolutions interactive state space.lineplots Fig. 12 show quality I-PF based approximation, measuredKL-Divergence becomes better number particles increases, problem domains.remains true level 1 2 beliefs. KL-Divergence measures differencetwo probability distributions giving relative entropy filtered posterior respectnear-exact one obtained numerical integration. Note performance IPF remains consistent two-state tiger three-state MM problem. However, level2 belief approximations require considerably particles compared level 1 approximations,achieve similar performance, indicating performance I-PF affected levelnesting. data point lineplots average 10 runs I-PF multiple prior beliefstates. case tiger problem, posterior used comparison one obtainedagent listens hears growl left creaks. MM problem, posteriorobtained manufactures perceives defect product, used comparison. Twoprior level 1 beliefs agent playing tiger problem shown Fig. 3.considered level 2 belief according agent unaware tigers location believesequal probabilities either level 1 beliefs shown Fig. 3 likely. utilizedanalogous beliefs machine maintenance problem.comparison run times I-POMDP belief update implemented using grid basednumerical integration I-PF shown Table. 2. varied number grid points318fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPMultiagent TigerMultiagent Machine Maintenance600Level 1Level 2Level 1Level 2600KL-DivergenceKL-Divergence500400300200100500400300200100001010010001000010No. Particles (N)100100010000No. Particles (N)(i)(ii)Figure 12: Anytime performance I-PF function number particles, (i) multiagent tiger problem, (ii) multiagent machine maintenance problem. performanceI-PF significantly improves increase number particles leadingtoward convergence true posterior. vertical bars standard deviations.BeliefProblemMultiagentTigerLevel1MultiagentMMMultiagentTigerLevel2MultiagentMMMethodI-PFGridbasedI-PFGridbasedI-PFGridbasedI-PFGridbasedN=5000.148s0.001s21.65s0.18s0.452s0.009s1m 0.28s0.21s2m 23.28s1.1s34m 40.36s0.55s1m 37.59s0.17s24m 55.33s4.77sN=10000.332s0.007s1m 25.19s1.02s0.931s0.0146s3m 27.87s0.13s11m 41.30s1.52s77m 2.9s4.88s8m 27.29s1.65s56m 21.97s5.73sTable 2: Comparison average running times grid based numerical integration I-PFimplementations platform (Pentium IV, 1.7GHz, 512MB RAM, Linux).number particles two implementations, respectively. use initial beliefsflat, number grid points particles provides comparable approximationquality. I-PF implementation significantly outperforms numerical integration based implementation, providing comparable performance quality. Additionally, run timesgrid based implementation increase significantly move two-state tiger prob319fiD OSHI & G MYTRASIEWICZlem three-state MM problem, comparison increase I-PF level 1 beliefs.Since level 1 multiagent tiger model 6 observations comparison 2 multiagentMM, run times decrease move tiger MM problem level 2 beliefs.Despite using equal number grid points particles, reduced run time I-PFcomparison grid based approach due to: (i) iterating grid points orderobtain belief interactive state consideration. contrast, I-PF iteratesparticles level propagating weighting obtain posterior; (ii)I-PF solves models approximately comparison solving exactly grid points;(iii) grid based belief update considers optimal actions model, I-PFsamples single action distribution propagates corresponding particle usingaction.Level 1 Beliefs Multiagent Tiger ProblemExactParticle FilterExactParticle FilterPr(TL,b_j)Pr(TR,b_j)Pr (TL,p )Pr (TR,p )jj2552041531025100332.502.5020.2Prb_j(TL)j0.8Time steps (T)0.41.50.620.2Time steps (T)0.4Prb_jj (TL)1 11.50.60.81 1Figure 13: exact approximate p.d.f.s successive filtering steps. peaksapproximate p.d.f.s align correctly exact p.d.f.s, areasapproximate exact p.d.f.s approximately equal.order assess quality approximations successive belief updates, graphedprobability density functions produced I-PF exact belief update. densitiesarising three filtering steps level 1 belief agent (Fig. 3(a)) tigerproblem, shown Fig. 13. approximate p.d.f. average 10 runs I-PFcontained 5000 particles, shaped using standard Gaussian kernel. GmytrasiewiczDoshi (2005) provide explanation exact I-POMDP belief update shown here. Briefly,prior belief flat line, posterior becomes segmented segments correspondbeliefs j likely based predicted action anticipated observations j. heightsegment proportional likelihood js possible observation. action observationsequence followed hL, GL, Si, hL, GL, Si, hOR, GL, Si. seen, I-PF producesgood approximation true densities.320fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDP8.3.2 UAV R ECONNAISSANCE P ROBLEMUnmanned agents UAVs finding important applications tasks fighting forestfires (Casbeer, Beard, McLain, Sai-Ming, & Mehra, 2005; Sarris, 2001), law enforcement (Murphy& Cycon, 1998) reconnaissance warfare. agents must operate complex environmentscharacterized multiple parameters affect decisions, including, particularly warfare,agents may antagonistic preferences. task complicatedagent may possess noisy sensors unreliable actuators.consider task UAV performs low-altitude reconnaissance potentiallyhostile theater may populated agents conflicting objectives serve groundreconnaissance targets (see Fig. 14(a)). facilitate analysis, divide UAVs operatingtheater 33 grid sectors consider ground reconnaissance target (T ), couldlocated 9 sectors. example, target could terrorist may hidingsafe house located sector. course, UAV unaware sector contains ,aware location. assist goal spotting moving sector containingit, UAV may receive noisy communication informs rows (similar coloredsectors Fig. 14) likely contain , though uncertainty. UAV optionmoving four cardinal directions adjacent sector, hovering currentlocation listening communications.target may informed (by collaborators) could danger spottedUAV although high uncertainty, case may move adjacent diagonalsector. Note actions both, UAV agent may affect physical stateproblem. formulate decision problem UAV below:physical state, s={rowi , sidei centeri , rowT , sideT centerT }, rowi sideicenteri indicate row location UAV whether UAV located side columnscenter column, respectively; joint action space, = Ai , Ai = {moveN ,. . .,moveW ,listen} = {moveN ,. . .,moveW ,listen}. Here, movex moves UAV target direction indicated x, listen denotes act receiving communications locationUAV; Observation space UAV is, = {top-row (TR), center-row (CR), bottomrow (BR)}, example, TR indicates corresponding target one threesectors top row; Transition function is, Ti : [0, 1]. Ti models factUAV target move deterministically surrounding sector; Observation function,Oi : [0, 1] gives likelihood UAV informed correct rowtarget located; Reward function, Ri : [0, 1] formalizes goalspotting reconnaissance target. UAV moves sector containing target , assumetarget spotted game ends.target may move, beneficial anticipate actions. Thus, UAVtracks possible beliefs may location UAV. assumeUAV aware objectives conflict own, probabilities observations,therefore frame. point size complexity problem, involving 36 physicalstates, 5 actions 3 observations agent.Analogously previous problem sets, measured quality estimation providedI-PF larger problem. Fig. 14(b), show KL-Divergence approximatedistribution number particles allocated I-PF increased. KL-Divergencedecreases rapidly increase number particles level 1 2 beliefs. However,321fiD OSHI & G MYTRASIEWICZ1600Level 1Level 21400KL-Divergence12001000800600400200010(a)1001000No. Particles (N)10000(b)BeliefLevel1Level2MethodI-PFGridbasedI-PFN=5002.929s0.894s3m 37.07s4.22sN=1002m 55.52s25.61sN=10005.251s0.492s7m 16.42s0.27sN=20011m 10.43s56.724s(c)Figure 14: (a) operating theater UAV i. problem may flexibly scaled addingtargets sectors. (b) posterior obtained I-PF approaches exactnumber particles increase. (c) Comparison average running timesnumerical integration I-PF implementations platform (Xeon, 3.0GHz,2GB RAM, Linux).notice magnitude divergence larger lower numbers particles comparisonprevious problems. is, part, due larger state space problem demonstratesI-PF fully address curse dimensionality. Thus, many particlesneeded reach comparable levels divergence. also show comparison run timesI-POMDP belief update implemented using I-PF grid based numerical integrationtable Fig. 14(c). identical number particles grid points selected,provided comparable qualities estimations. unable run numerical integrationimplementation level 2 beliefs problem.9. Value Iteration Sample SetsI-PF represents belief agent i, bi,l , using set N particles, ebi,l , value functione denote required backup operator,backup operator operates samples needed. Let H322fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPe approximate value function, backup operation, Uet = HeUe t1 , is:UX1 X(n)t1eeebbeeERi (is , ai )+P r(oi |ai , bi,l )U (hI-PF(bi,l , ai , oi ), i)U (hbi,l , i) = maxai Ai Noiis(n) ebi,l(8)=discount factor I-PF()algorithm shown Fig. 4. set optimal action(s) given approximate belief, OPT(hebi,l , bj i),ERi (is(n) , ai )P(n) , , )P r(a | (n) ),jj jaj Ri (scalculated returning action(s) maximum value:PP1OP (hebi,l , bi i) = argmaxP r(oi |ai , ebi,l )ERi (is(n) , ai ) +Nai Aiis(n) ebi,le (hI-PF(ebi,l , ai , oi ), bi i)Uoi(9)Equations 8 9 analogous Eqs. 4 5 respectively, exact integration replacede HMonte Carlo integration, exact belief update replaced I-PF. Note HN .algorithm computing approximately optimal finite horizon policy tree given initialbelief using value iteration l > 0 shown Fig. 18 Appendix B.9.1 Convergence Error Boundsuse randomizing techniques PFs means value iteration necessarilyconverge. because, unlike exact belief update, posteriors generated PFfinitely many particles guaranteed identical identical input. non-determinisme N . 6approximate belief update rules isotonicity contraction Hinability guarantee convergence value iteration implies must approximateinfinite horizon policy approximately optimal finite horizon policy. Let U valuee value approximate U valueoptimal infinite horizon policy, Uoptimal t-horizon policy tree. error bound (using supremum norm || ||) is,e || = ||U U + U Ue || ||U U || + ||U Ue || (triangle inequality). Note||U U0first term, ||U U ||, bounded ||U U ||. bound second term calculatedbelow:e U ||E = ||UeUe t1 HU t1 ||= ||HeUe t1 H Ue t1 + H Ue t1 HU t1 ||= ||H(add zero)t1t1t1t1eeee||H UH U || + ||H UHU || (triangle inequality)eUe t1 H Ue t1 || + ||Ue t1 U t1 ||||H(contracting H)t1t1t1eee||H UH U || + EeUe t1 H Ue t1 ||. analysis follows focusturn attention calculating ||He t1 , Uet = HeUe t1 , bi,1 singly nested belieflevel 1 beliefs. Let U = H U6. One may turn PFs deterministic belief update operators (de-randomization) generating several posteriorsinput. representative posterior formed taking convex combination different posteriors.example, Thrun (2000) uses k-nearest neighborhood approach purpose.323fiD OSHI & G MYTRASIEWICZe |. Letworst error made: bi,1 = argmax |U Ue policy tree (alpha vector)bi,1 Bi,1optimal ebi,1 (the sampled estimate bi,1 ), policy tree optimal bi,1 .use Chernoff-Hoeffding (C-H) upper bounds (Theorem A.1.4, pg 265 Alon & Spencer, 2000) 7 ,well-known tool analyzing randomized algorithms, derive confidence threshold 1e , within 2 true estimate U (= E[]):observed estimate, Uemay write,e > U + ) e2N 2 /(emax emin )2P r(Uee < U ) e2N 2 /(emax emin )2P r(Uee > U + Ue < U ) = P r(Ue > U + ) + P r(Ue < U )P r(Ueeeee > U + Ue < U )P r(Ueelast term zero, equation becomes:e < Ut ) 2e2N 2 /(emax emin )2e > Ut + UP r(Ueee > U + Ue < U ) 1 P r(U Ue U + ).may replace P r(Ueeesimple operations, inequality becomes:e Ut + ) 1 2e2N 2 /(emax emin )2P r(Ut Uee within 2 true estimate U , least 1 . have:Let probability Ue2 /(e1 = 1 2e2Nmin )max e2confidence probability least 1 , error bound is:=r(emaxemin )2 ln(2/)2N(10)Rminemaxemin may loosely upper bounded Rmax1. Note Eq. 10 alsoused derive number particles, N , given . get desired bound, noteleast probability 1 error bound 2 probability worsteUe t1 H Ue t1 || (1 )2 + Rmax Rmin .possible suboptimal behavior may result: ||H1final error bound obtains:RminE (1 )2 + Rmax1+ E t1)min )(1+ (Rmax R= (1 ) 2(11(1)2t)(geometric series)(11)defined Eq. 10.7. horizon t, samples ebi,1 i.i.d. However, horizons less t, samples generated I-PFexhibit limited statistical independence, independent research (Schmidt, Siegel, & Srinivasan, 1995) revealsC-H bounds still apply.324fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPProposition 3 (Error Bound). singly nested t-horizon I-POMDPi,1 , error introducedapproximation technique upper bounded given by:e U || (1 )||U2(1 )(Rmax Rmin )(1 )+1(1 )2defined Eq. 10.levels belief nesting greater one, js beliefs also approximately represented usingsamples. Hence approximation error due sampling, also due possibleincorrect prediction js actions based approximate beliefs. Since even slight deviationexact belief may lead action turns worst value comparedoptimal action, seems difficult derive bounds useful tighter usualRmindifference best worst possible behavior ( Rmax) case.(1)29.2 Computational SavingsSince complexity solving I-POMDPs dominated complexity solving modelsagents analyze reduction number agent models must solved.K+1-agent setting number particles bounded N level, particle ebt1k,llevel l contains K models level l 1. Solution level l 1 models requiressolution lower level models recursively. upper bound number modelssolved O((KN )l1 ). Given K level l 1 models particle, Npossibly distinct particles, need solve O((KN )l ) models. upper bound numbermodels solved polynomial K fixed nesting level. contrastedO((K| |K )l ) models need solved exact case, exponential K. Here,among spaces models agents, largest space theoretically countablyinfinite. Typically, N | |K , resulting substantial reduction computation. However, notetotal number particles exponential nesting level, l. makes solutions largenesting levels still intractable.10. Empirical Performancegoal experimental analysis demonstrate empirically, (a) reduction errorincreasing sample complexity, (b) savings computation time approximation technique used. use multiagent tiger problem introduced previously, multiagentversion machine maintenance (MM) problem (see Appendix A) test problems.single-agent versions problems simple, multiagent versions sufficientlycomplex motivate use approximation techniques solve them. Additionally,demonstrate approach scales larger problems applying UAV reconnaissanceproblem well.10.1 Multiagent Tiger Machine Maintenance Problemsdemonstrate reduction error, construct performance profiles showing increaseperformance computational resources case particles allocated approximation algorithm. Figs. 15(a) (c) show performance profile curves agentprior belief level 1 belief described previously Fig. 3(a), suitably modified MM325fiD OSHI & G MYTRASIEWICZMultiagent Tiger Problem0Expected RewardExpected Reward0-5-10-15-20-25-5-10-15-20-25-30-301101001000No. Particles (N)H=2:ExactH=2:Approx1H=3:ExactH=3:Approx10No. Particles (N)H=2:ExactH=2:Approx100H=3:ExactH=3:Approx(a)(b)Multiagent Machine Maintenance Problem1Expected RewardExpected Reward10.50-0.5-10.50-0.5-11101001000No. Particles (N)H=2:ExactH=2:Approx10000H=3:ExactH=3:Approx110No. Particles (N)H=2:ExactH=2:Approx(c)100H=3:ExactH=3:Approx(d)Figure 15: Anytime performance profiles: multiagent tiger problem using (a) level 1,(b) level 2 belief prior agent i. multiagent MM using (c) level 1,(d) level 2 belief prior. approximate policies gradually improve employincreasing number particles.problem. expected average rewards both, horizon 2 3 approach optimal expectedreward number particles increases. show analogous plots level 2 beliefFigs. 15(b) (d). cases average rewards accumulated 23 horizon policy tree (computed using APPROXPOLICY algorithm Fig. 18) playingagent j simulated tiger MM problems plotted. compensate randomness sampling, generated policy tree 10 times independently other, averaged326fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDP100 runs time. Within run, location tiger js prior beliefs sampledaccording prior belief. js policy computed using algorithm Fig. 18.ProblemErrorMultiagenttigerObs.EtWorstObs.EtWorstMultiagentMMt=2N=100 N=10005.61064.7341.53209.000.280.234.582.058.84t=3N=100 N=10004.392.76120.9077.57298.100.460.408.793.6412.61Table 3: Comparison worst case observed errors, theoretical error bounds trivialRminerror bound ( Rmax).(1)2Table 3, compare empirically determined error bound difference optimalexpected reward worst observed expected reward theoretical error bound (=0.1,=0.9) Section 9.1, horizons 2 3. theoretical error bounds appear loose dueworst-case nature analysis (expectedly) much tighter trivial worst bounds,become better number particles increases.ProblemMultiagenttigerMethodGridSBMultiagentMMGridSBt=237.84s0.6s1.44s0.05s5m 26.57s0.07s5.75s0.01sRun timest=3t=411m 22.25s*1.34s1m 44.29s 19m 16.88s0.6s17.5s20m 45.69s*0.29s34.52s3m 24.9s0.01s0.04st=5***17m 58.39s0.57sTable 4: Run times Pentium IV 2.0 GHz, 2.0GB RAM Linux. * = program ranmemory.Table 4 compares average run times sample-based approach (SB) grid basedapproach, computing policy trees different horizons starting level 1 belief.values policy trees generated two approaches similar. run times demonstrateimpact curse dimensionality grid based method shown higher run timesMM problem comparison tiger problem. I-PF based implementation thoughimmune curse reduces impact, affected curse history, illustratedhigher run times tiger problem (branching factor reachability tree: |Ai ||i | = 18)compared MM problem (branching factor:|Ai ||i | = 8). unable computesolutions using grid based implementation problems horizons beyond 3.327fiD OSHI & G MYTRASIEWICZExpected Reward12108642ProblemMethodUAVRecon.SBRun timest=2t=38m 50.03s 20m 59.23s5.26s4.09s0101001000No. Particles (N)H=2:ApproxH=3:Approx(a)(b)Figure 16: (a) Anytime performance profile UAV reconnaissance problem horizons 23. Notice profile flattens number particles reaches 1,000greater, thereby indicating corresponding average reward close optimal.(b) Run times obtaining policy Xeon 3.0 GHz, 2.0GB RAM Linux.horizon 2, used 500 particles 100 particles used horizon 3.see (a), rewards policies numbers particles much lessconverged values.10.2 UAV Reconnaissance Problemevaluate performance approach UAV reconnaissance problem, introduced previously Section 8.3. mentioned, larger problem consisting 36 physicalstates, 5 actions 3 observations. show level 1 performance profile problemFig. 16(a) horizons 2 3. Due size problem, unable computeexact value optimal policies. before, data point average reward obtainedsimulating horizon 2 3 policy two-agent setting. Agent initial belief one accordinguncertain physical state models agent. observeprofiles tend flatten number particles increases. corresponding expected rewardtherefore close optimal value policies.also show time taken generate good quality horizon 2 3 policy average.indicate indeed possible obtain (approximate) policies large problems,times needed somewhat large. Notice times significantly greater runtimes multiagent tiger MM problems. is, part, due larger state space and,show later article, part due larger numbers actions observationsagent.11. Sampling Look Ahead Reachability TreeAlthough able solve I-POMDPs large state spaces, unable generatesolutions large horizons. main reason exponential growth look aheadreachability tree increasing horizons; referred curse history.time step t, could (|Ai ||i |)t1 reachable belief states agent i. example,328fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPmultiagent tiger problem, second time step could 18 possible belief states, 324third time step, 0.1 million fifth time step.mitigate curse history, reduce branching factor look ahead reachabilitytree sampling possible observations agent may receive. approachcompletely address curse history, beats back impact curse substantially.reachability tree expansion phase, agents actions used propagate belief.t1et1Observations sampled propagated belief, oti P r(i |at1, bi,l ) bi,lpropagated belief. value iteration phase, value backed (possibly) partialreachability tree, agent performs action optimal root node tree.convenience, let us label approach reachability tree sampling (RTS).RTS shares conceptual underpinnings belief expansion models PBVI (Pineauet al., 2006), differs method applicable online policy tree generation IPOMDPs, compared PBVIs use offline policy generation POMDPs. also similarsparse sampling technique proposed selecting actions exploration reinforcementlearning (Kearns et al., 2002) online planning POMDPs (Ross et al., 2008) samplinglook ahead trees. distinction focus sampling observations given propagatedmultiagent beliefs, latter approaches focused settings single agent learning. Consequently, process computing sampling distribution experimental settings differ.11.1 Computational Savingsconsider computational savings result sampling observations look aheadreachability tree. sampling Ni < |i | observations propagated belief withinreachability tree, time step t, obtain (|Ai ||Ni |)t1 possible belief states,assuming worst case occurs end sampling Ni distinct observations.comparison (|Ai ||i |)t1 belief states complete reachability tree. Typically,experiments demonstrate, number distinct sampled observations less |i |, resultingsignificant computational savings.MethodSB-No-RTSSB-RTSt=21.44s0.05s0.86s0.02st=31m 44.29s0.6s15.17s1.6sRun timest=4t=519m 16.88s*17.5s2m 52.9s4m 13.43s6.51s27.51st=6*t=7*7m 29.9s47.98s11m 51.57s20.05sTable 5: Run times multiagent tiger problem Pentium IV 2.0 GHz, 2.0GB RAMLinux. * = program ran memory.illustration computational savings compare run times computingpolicy tree multiagent tiger (Table 5) UAV reconnaissance (Table 6) problemssingly-nested beliefs. compare value iteration reachability tree sampled (SBRTS) value iteration reachability tree sampling (SB-No-RTS), algorithmgiven Fig. 18. SB-RTS multiagent tiger problem, sampled eight timesobservation distribution fifth horizon six times thereafter. algorithms,used similar number particles I-PF. tiger problem total 6 observations,329fiD OSHI & G MYTRASIEWICZSB-RTS compute policy faster, able compute seven timehorizons. compared performance SB-No-RTS, results demonstrateapproach sampling reachability tree could yield significant computational savings.MethodSB-No-RTSSB-RTSt=28m 50.03s5.26s8m 23.86s20.46sRun timest=320m 59.23s4.09s19m 25.54s89.08st=4*121m 16.2s592sTable 6: Run times UAV reconnaissance problem Xeon 3.0 GHz, 2.0GB RAMLinux. * = program ran memory.However, see Table 6, approach yield significant savings contextUAV problem small horizons. space observations problem small(3 distinct observations), majority often selected sampling. Hence, smallerhorizons 2 3, observe significant decrease size look aheadreachability tree. However, reduction look ahead trees horizon 4 enough allowcomputation corresponding policy, though run time considerable. unableobtain case RTS. Thus, UAV problem reveals important limitationtechnique may provide significant computational savings space observationssmall, particularly small horizons.11.2 Empirical Performancepresent performance profiles Fig. 17 multiagent tiger problem partial lookahead reachability trees built sampling observations. Similar previous experiments,performance profiles reflect average rewards accumulated following actionprescribed root approximate policy tree built online. plot average rewardaccumulated 10 independent trials consisting 100 runs each, numberobservation samples, Ni gradually increased. Within run, location tigerjs prior beliefs sampled according prior level 1 belief. Since combined RTSI-PF, addition varying Ni , also vary number particles, Np , employedapproximate beliefs. expected performance profiles, expected reward initially increasessharply, flattening Ni becomes large sampled observation distribution reachestrue one. Reflecting intuition, plots Np = 100 exhibit slightly better expected rewardsaverage Np = 50. increase large, note consistent acrossobservation samples. also obtained average reward similar number trialsrandom policy (null hypothesis) used i. horizon 3, random policy gathered averagereward -84.785 ( 37.9847), -108.5 ( 41.56) horizon 4. Even small numberobservation samples, RTS significantly better random policy thereby demonstratingusefulness partial tree expansion. However, note random policy poor baselinecomparison used due absence similar approximations I-POMDPs.330fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPMultiagent Tiger Problem0Expected RewardExpected Reward0-5-10-15-20-5-10-15-20-25Np=50Np=100-25Np=50Np=100-30248162No. Obs. Samples4816No. Obs. Samples(a)(b)Figure 17: Performance profiles multiagent tiger problem (a) horizon 3, (b)horizon 4 look ahead tree built sampling observations.Due small number observations MM UAV reconnaissance problems,observe significant increases expected reward observations sampled. Hence,show performance profiles problems.observed empirical expected reward close optimal expected rewarddistinct observations sampled building reachability tree. observation combined computational savings demonstrated Section 11.1 indicateapproximation approach viable. Additionally, varying parameters Np Ni ,flexibly, though partially, control effects curses dimensionality history,respectively, solutions according application requirements. interesting line futurework investigate interplay parameters.12. Discussiondescribed randomized methods obtaining approximate solutions finitely nested I-POMDPsbased novel generalization particle filtering multiagent settings. generalizationstraightforward confronted interactive belief hierarchy multiagentsettings. proposed interactive particle filter descends levels interactive beliefhierarchies, samples propagates beliefs level. sampling methodsparticle filters unable completely avoid curse dimensionality, serve focuscomputational resources elements model matter agent.However, interactive particle filter address policy space complexity. Thoughvalue iteration using sample sets guaranteed converge asymptotically, established useful error bounds singly-nested I-POMDPs. generalization multiply-nested beliefsproved difficult continue investigate it. provided performance profilesmultiagent tiger machine maintenance problems, demonstrated scalability usinglarger UAV reconnaissance problem.experiments show approach saves computation space modelsscale (usefully) large values time horizons needs combined methods331fiD OSHI & G MYTRASIEWICZdeal curse history. order reduce impact curse history, proposedsample observations constructing look ahead tree reachability analysis phasepolicy computation. sparse sampling technique effectively reduces branching factortree allows computation solutions larger horizons demonstrated.method scale approximation technique pick subset actions additionsampling observations building reachability tree. dampens exponentialgrowth reachability tree increasing horizons, permits solutions larger horizons.However, approach must used cautiously want leave critical actionspolicy.Specific approaches speeding computation also remain explored. mentioned, number particles interactive particle filter grows exponentially numbernesting levels. regard, assign monotonically decreasing number particlesrepresent beliefs nested deeper levels exploiting insight cognitive psychology beliefsnested deeper levels less likely influence optimal policy? Thus, decrease particles sampled rate r < 1, Np /(1 r) particles total, resultingcomputational savings.Finally, regards appropriate strategy level use nested models, note analogy classical POMDPs, amount detail modeling information included therein.Adding nested level modeling analogous including details POMDP formulation. Then, solution I-POMDP optimal given level detail included model,like classical POMDPs.Acknowledgmentsresearch supported part grant #FA9550-08-1-0429 AFOSR part grantsIRI-9702132 IRI-0119270 NSF. Versions parts article previously appeared(Doshi & Gmytrasiewicz, 2005a) (Doshi & Gmytrasiewicz, 2005b). acknowledgereviewers useful comments.Appendix A. Multiagent Machine Maintenance Problemextend traditional single agent version machine maintenance (MM) problem (Smallwood & Sondik, 1973) two-agent cooperative version. original MM problem involvedmachine containing two internal components operated single agent. Either one components machine may fail spontaneously production cycle. internal componentfailed, chance operating upon product, cause productdefective. agent may choose manufacture product (M) without examining it, examine product (E), inspect machine (I), repair (R) next production cycle.examination product, subject may find defective. course, componentsfailed, probability product defective greater.transition function, observation functions, reward functions two agents,j, shown Table 7. Apart including two agents operate machineproduction cycle, increased nondeterminism original problem makerealistic. also beneficial effect producing richer policy structure.332fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPhai , ajState not-defective defectivehM,M/Ei*0.50.5hM,I/Ri*0.950.05hE,M/Ei 0-fail0.750.25hE,M/Ei 1-fail0.50.5hE,M/Ei 2-fail0.250.75hE,I/Ri*0.950.05hI/R,*i*0.950.05hai , ajState not-defective defectivehM/E,Mi*0.50.5hI/R,Mi*0.950.05hM/E,Ei 0-fail0.750.25hM/E,Ei 1-fail0.50.5hM/E,Ei 2-fail0.250.75hI/R,Ei*0.950.05h*,I/Ri*0.950.05Observation functions agents j.hai , ajState 0-fail 1-fail 2-failhM/E,M/Ei 0-fail 0.810.180.01hM/E,M/Ei 1-fail0.00.90.1hM/E,M/Ei 2-fail0.00.01.0hM,I/Ri0-fail1.00.00.0hM,I/Ri1-fail 0.950.050.0hM,I/Ri2-fail 0.950.00.05hE,I/Ri0-fail1.00.00.0hE,I/Ri1-fail 0.950.050.0hE,I/Ri2-fail 0.950.00.05hI/R,*i0-fail1.00.00.0hI/R,*i1-fail 0.950.050.0hI/R,*i2-fail 0.950.00.05Transition function agents j: Ti = Tjhai , ajhM,MihM,EihM,IihM,RihE,MihE,EihE,IihE,RihI,MihI,EihI,IihI,RihR,MihR,EihR,IihR,Ri0-fail1.8051.5550.4025-1.09751.55551.3050.1525-1.34750.40250.1525-1.0-2.5-1.0975-1.3475-2.5-41-fail 2-failhai , aj0-fail0.950.5hM,Mi1.8050.70.25hM,Ei1.555-1.025 -2.25hM,Ii0.4025-1.525 -1.75hM,Ri -1.09750.70.25hE,Mi1.5550.450.0hE,Ei1.305-1.275-2.5hE,Ii0.1525-1.775-2.0hE,Ri-1.3475-1.025 -2.25hI,Mi0.4025-1.275-2.5hI,Ei0.1525-3.00-5.00hI,Ii-1.0-3.5-4.5hI,Ri-2.5-1.525 -1.75hR,Mi -1.0975-1.775-2.0hR,Ei-1.3475-3.5-4.5hR,Ii-2.5-4-4hR,Ri-4Reward functions agents j.1-fail0.950.7-1.025-1.5250.70.45-1.275-1.775-1.025-1.275-3.00-3.5-1.525-1.775-3.5-42-fail0.50.25-2.25-1.750.250.0-2.5-2.0-2.25-2.5-5.00-4.5-1.75-2.0-4.5-4Table 7: Transition, observation reward functions multiagent MM problem.Appendix B. Algorithm Value Iteration Sample Setsshow algorithm computing approximately optimal finite horizon policy tree giveninitial belief using value iteration l > 0. l = 0, algorithm reduces POMDPpolicy tree computation carried exactly.8 algorithm consists usual two steps:compute look ahead reachability tree horizon part reachability analysis (seeSection 17.5 Russell & Norvig, 2003) lines 2-6 perform value backup reachability8. large problems, exact POMDP solutions may replaced approximate ones. so, errorbounds longer applicable approximation technique considered.333fiD OSHI & G MYTRASIEWICZtree, lines 7-28. value beliefs leaves reachability tree simply one-stepexpected reward resulting best action.Function APPROXPOLICY(k , l > 0) returns (Ak )(n)(n)1. eb0k,l {isk , n = 1...N |isk bk,l k }//Initial sampled beliefReachability Analysis2. reach(0) eb0k,l3. 1 14.reach(t)t15.ebk,lreach(t 1), ak Ak , ok kt16.reach(t) I-PARTICLEFILTER(ebk,l, ak , ok , l)Dynamic Programming7. 1 downto 08.ebtk,l reach(t)e (h ebt , bk i) , OPT(h ebt , bk i)9.Uk,lk,l10.ak Ake (hebt , bk i) 011.Uakk,l(n),t(n)12.isk= hs(n),t , k ebtk,l(n)(n)13.P r(Ak |k ) APPROXPOLICY(k , l 1)14.ak Ak+ 1(n)(n),te (hebt , bk i), ak , ak )P r(ak |k )15.Uakk,lN R(s16.(t < )17.ok k18.sum 0, ebt+1k,l reach(t + 1)[|k |ak + ok ](n),t(n)19.isk= hs(n),t , k ebtk,l(n)(n)20.P r(Ak |k ) APPROXPOLICY(k , l 1)t+121.ak Ak ,Sk+(n)t+122.sum Ok (ok |s , ak , ak )P r(is(n),t+1 |is(n),t , ak , ak )P r(ak |k )+e t1 (ebt+1 )e (hebt , bk i)N1 sum U23.Uakk,lk,le (hebt , bk i))eaT (hebt , bk i) previously best U24.new value Uk,lk,lke (hebt , bk i) > Ue (hebt , bk i)25.(Uakk,lk,le (hebt , bk i) Ue (hebt , bk i)26.Uakk,lk,l27.OPT(hebk,l , bk i)28.OPT(hebtk,l , bk i) ak29. ak Ak30.(ak OPT(heb0k,l , bk i)131.P r(ak |k )|OPT(heb0k,l ,bk i)|32.else33.P r(ak |k ) 034. return P r(Ak |k )Figure 18: Computing approximately optimal finite horizon policy tree given model containinginitial sampled belief. l = 0, exact POMDP policy tree computed.334fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPReferencesAlon, N., & Spencer, J. (2000). Probabilistic Method. John Wiley Sons.Aumann, R. J. (1999). Interactive epistemology i: Knowledge. International Journal GameTheory, 28, 263300.Battigalli, P., & Siniscalchi, M. (1999). Hierarchies conditional beliefs interactive epistemology dynamic games. Journal Economic Theory, 88(1), 188230.Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity decentralized control markov decision processes. Mathematics Operations Research, 27(4),819840.Bertsekas, D. (1995). Dynamic Programming optimal control. Athena Scientific.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptionscomputational leverage. Journal Artificial Intelligence Research, 11, 194.Brandenburger, A., & Dekel, E. (1993). Hierarchies beliefs common knowledge. JournalEconomic Theory, 59, 189198.Casbeer, D., Beard, R., McLain, T., Sai-Ming, L., & Mehra, R. (2005). Forest fire monitoringmultiple small uavs. American Control Conference, pp. 35303535.Collins, M., Dasgupta, S., & R.E.Schapire (2002). generalization principal component analysisexponential family. Neural Information Processing Systems (NIPS), pp. 617624.Crisan, D., & Doucet, A. (2002). survey convergence results particle filtering methodspractitioners. IEEE Transactions Signal Processing, 50(3), 736746.Daum, F., & Huang, J. (2002). Mysterious computational complexity particle filters. Conference Signal Data Processing Small Targets, SPIE Proceedings Series, pp. 418426,Orlando, FL.Dobson, A. (2002). Introduction Generalized Linear Models, 3rd Ed. Chapman Hall.Doshi, P. (2007). Improved state estimation multiagent settings continuous large dscretestate spaces. Twenty Second Conference Artificial Intelligence (AAAI), pp. 712717.Doshi, P., & Gmytrasiewicz, P. J. (2005a). Approximating state estimation multiagent settingsusing particle filters. Autonomous Agents Multi-agent Systems Conference (AAMAS),pp. 320327.Doshi, P., & Gmytrasiewicz, P. J. (2005b). particle filtering based approach approximatinginteractive pomdps. Twentieth National Conference Artificial Intelligence (AAAI), pp.969974.Doshi, P., & Perez, D. (2008). Generalized point based value iteration interactive pomdps.Twenty Third Conference Artificial Intelligence (AAAI), pp. 6368.Doshi, P., Zeng, Y., & Chen, Q. (2007). Graphical models online solutions interactive pomdps.Autonomous Agents Multiagent Systems Conference (AAMAS), pp. 809816, Honolulu, Hawaii.Doucet, A., de Freitas, N., Murphy, K., & Russell, S. (2000). Rao-blackwellised particle filteringdynamic bayesian networks. Uncertainty Artificial Intelligence (UAI), pp. 176183.335fiD OSHI & G MYTRASIEWICZDoucet, A., Freitas, N. D., & Gordon, N. (2001). Sequential Monte Carlo Methods Practice.Springer Verlag.Fagin, R., Halpern, J., Moses, Y., & Vardi, M. (1995). Reasoning Knowledge. MIT Press.Fox, D., Burgard, W., Kruppa, H., & Thrun, S. (2000). probabilistic approach collaborativemulti-robot localization. Autonomous Robots Heterogenous Multi-Robot Systems, 8(3),325344.Fudenberg, D., & Levine, D. K. (1998). Theory Learning Games. MIT Press.Gelman, A., Carlin, J., Stern, H., & Rubin, D. (2004). Bayesian Data Analysis, Second Edition.Chapman Hall/CRC.Geweke, J. (1989). Bayesian inference econometric models using monte carlo integration. Econometrica, 57, 13171339.Gmytrasiewicz, P., & Doshi, P. (2005). framework sequential planning multiagent settings.Journal Artificial Intelligence Research, 24, 4979.Gordon, N., Salmond, D., & Smith, A. (1993). Novel approach non-linear/non-gaussian bayesianstate estimation. IEEE Proceedings-F, 140(2), 107113.Harsanyi, J. C. (1967). Games incomplete information played bayesian players. Management Science, 14(3), 159182.Hastings, W. K. (1970). Monte carlo sampling methods using markov chains applications.Biometrika, 57, 97109.Heifetz, A., & Samet, D. (1998). Topology-free typology beliefs. Journal Economic Theory,82, 324341.Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially observablestochastic domains. Artificial Intelligence, 101, 99134.Kearns, M., Mansour, Y., & Ng, A. (2002). sparse sampling algorithm near-optimal planninglarge markov decision processes. Machine Learning, 49, 193208.Koller, D., & Lerner, U. (2001). Sampling factored dynamic systems. Doucet, A., Freitas,N. D., & Gordon, N. (Eds.), Sequential Monte Carlo Methods Practice. Springer.Kramer, S. C., & Sorenson, H. (1988). Recursive bayesian estimation using piecewise constantapproximations. Automatica, 24, 789801.Li, M., & Vitanyi, P. (1997). Introduction Kolmogorov Complexity Applications.Springer.Mertens, J., & Zamir, S. (1985). Formulation bayesian analysis games incompleteinformation. International Journal Game Theory, 14, 129.Murphy, D., & Cycon, J. (1998). Applications mini vtol uav law enforcement. SPIE3577:Sensors, C3I, Information, Training Technologies Law Enforcement.Ortiz, L., & Kaelbling, L. (2000). Sampling methods action selection influence diagrams.Seventeenth National Conference Artificial Intelligence (AAAI), pp. 378385, Austin, TX.Paquet, S., Tobin, L., & Chaib-draa, B. (2005). online pomdp algorithm complex multiagentenvironments. International Conference Autonomous Agents Multiagent Systems(AAMAS), pp. 970977, Utrecht, Netherlands.336fiM ONTE C ARLO AMPLING ETHODS PPROXIMATING I-POMDPPineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based value iteration large pomdps.Journal Artificial Intelligence Research, 27, 335380.Poupart, P., & Boutilier, C. (2003). Value-directed compression pomdps. Neural InformationProcessing Systems (NIPS), pp. 15471554.Poupart, P., & Boutilier, C. (2004). Vdcbpi: approximate algorithm scalable large-scalepomdps. Neural Information Processing Systems (NIPS), pp. 10811088.Poupart, P., Ortiz, L., & Boutilier, C. (2001). Value-directed sampling methods belief monitoringpomdps. Uncertainty Artificial Intelligence (UAI), pp. 453461.Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms pomdps.Journal Artificial Intelligence Research (JAIR), 32, 663704.Roy, N., Gordon, G., & Thrun, S. (2005). Finding approximate pomdp solutions beliefcompression. Journal Artificial Intelligence Research (JAIR), 23, 1 40.Russell, S., & Norvig, P. (2003). Artificial Intelligence: Modern Approach (Second Edition).Prentice Hall.Saad, Y. (1996). Iterative Methods Sparse Linear Systems. PWS, Boston.Sarris, Z. (2001). Survey uav applications civil markets. IEEE Mediterranean ConferenceControl Automation, p. 11.Schmidt, J. P., Siegel, A., & Srinivasan, A. (1995). Chernoff-hoeffding bounds applicationslimited independence. SIAM Journal Discrete Mathematics, 8(2), 223250.Seuken, S., & Zilberstein, S. (2007). Improved memory bounded dynamic programming decentralized pomdps. Uncertainty Artificial Intelligence (UAI), pp. 20092015.Seuken, S., & Zilberstein, S. (2008). Formal models algorithms decentralized decisionmaking uncertainty. Journal Autonomous Agents Multiagent Systems, 17(2),190250.Smallwood, R., & Sondik, E. (1973). optimal control partially observable markov decisionprocesses finite horizon. Operations Research, 21, 10711088.Sorenson, H. W., & Alspach, D. L. (1971). Recursive bayesian estimation using gaussian sums.Automatica, 7, 465479.Sorenson, H. W. (Ed.). (1985). Kalman Filtering: Theory Application. IEEE Press, New York.Thrun, S. (2000). Monte carlo pomdps. Neural Information Processing Systems (NIPS), pp.10641070.Tsitsiklis, J., & Roy, B. V. (1996). Feature-based methods large scale dynamic programming.Machine Learning, 22, 5994.Wang, T., Lizotte, D., Bowling, M., & Schuurmans, D. (2005). Bayesian sparse sampling onlinereward optimization. International Conference Machine Learning (ICML), pp. 956963.337fiJournal Artificial Intelligence Research 34 (2009) 61-88Submitted 04/08; published 02/09Asynchronous Forward Bounding Distributed COPsAmir GershmanAmnon MeiselsRoie ZivanAMIRGER @ CS . BGU . AC . IL@ CS . BGU . AC . ILZIVANR @ CS . BGU . AC . ILDepartment Computer Science,Ben-Gurion University Negev,Beer-Sheva, 84-105, IsraelAbstractnew search algorithm solving distributed constraint optimization problems (DisCOPs)presented. Agents assign variables sequentially compute bounds partial assignmentsasynchronously. asynchronous bounds computation based propagation partialassignments. asynchronous forward-bounding algorithm (AFB) distributed optimizationsearch algorithm keeps one consistent partial assignment times. algorithm described detail correctness proven. Experimental evaluation shows AFB outperformssynchronous branch bound many orders magnitude, produces phase transitiontightness problem increases. analogous effect phase transitionobserved local consistency maintenance applied MaxCSPs. AFB algorithmenhanced addition backjumping mechanism, resulting AFB-BJ algorithm.Distributed backjumping based accumulated information bounds values processing concurrently queue candidate goals next move back. AFB-BJ algorithmcompared experimentally DisCOP algorithms (ADOPT, DPOP, OptAPO) shownefficient algorithm DisCOPs.1. IntroductionDistributed Constraint Optimization Problem (DisCOP) general framework distributedproblem solving wide range applications Multi-Agent Systems generatedsignificant interest researchers (Modi, Shen, Tambe, & Yokoo, 2005; Zhang, Xing, Wang, &Wittenburg, 2005; Petcu & Faltings, 2005a; Mailler & Lesser, 2004; Ali, Koenig, & Tambe, 2005;Silaghi & Yokoo, 2006). DisCOPs composed agents, holding one variables.variable domain possible value assignments. Constraints among variables (possiblyheld different agents) assign costs combinations value assignments. Agents assign valuesvariables communicate other, attempting generate solution globallyoptimal respect costs constraints (Modi et al., 2005; Petcu & Faltings, 2004).wide scope motivation research DisCOP, since distributed COPselegant model many every day combinatorial problems distributed nature. Takeexample large hospital composed many wards. ward constructs weekly timetableassigning nurses shifts. construction weekly timetable involves solving constraintoptimization problem ward. nurses every ward qualified workEmergency Room. Hospital regulations require certain number qualified nurses (e.g.Emergency Room) shift. imposes constraints among timetables different wardsgenerates complex Distributed COP (Solotorevsky, Gudes, & Meisels, 1996).c2009AI Access Foundation. rights reserved.fiG ERSHMAN , EISELS , & Z IVANAnother example sensor networks tracking problem (Zhang, Xing, Wang, & Wittenburg,2003; Zhang et al., 2005), task assign sensors tracking targets,maximal number targets tracked sensor collection. solved usingDisCOP model.DisCOP modeling also solve problems like log based reconciliation (Chong & Hamadi,2006), copies data base exist several physical locations. Users perform actionsdata base copies, user local copy. actions cause data base change,initially copies identical, later actions change longeridentical. Logs user actions kept. problem merge logs, single logkeeps many actions possible. always possible keep local logs intact,since actions constrained actions (for example reconcile deletionitem database later print update it).DisCOPs represent real life problems cannot solved centrally severalreasons, among lack autonomy, single point failure privacy agents.hospital wards example, wards want maintain degree autonomy local problemsinvolving constraints every single nurse. sensor example, sensors smallmemory computing power therefore cannot solve problem centralized fashion.database example, centralization possible, issues network bottleneck, computingpower single point failure encourage looking distributed solution.present paper proposes new distributed search algorithm DisCOPs, AsynchronousForward-Bounding (AFB). AFB algorithm agents assign variables generate partialsolution sequentially. innovation proposed algorithm lies propagating partial solutions asynchronously. Propagation partial solutions enables asynchronous updating boundscost, early detection need backtrack, hence algorithms name AFB. formpropagating bounds asynchronously turns generate efficient form concurrentcomputation participating agents. efficient algorithms use asynchronousassignment processes, especially hard instances DisCOPs.overall framework AFB algorithm based Branch Bound scheme. Agentsextend partial solution long lower bound cost exceed global bound,cost best solution found far. proposed AFB algorithm, statesearch process represented data structure called Current Partial Assignment (CPA). CPAstarts empty initializing agent records assignments sends next agent.cost CPA sum costs constraints includes. Besides current assignmentcost, agents maintain CPA lower bound updated according informationreceive yet unassigned agents. agent receives CPA, adds assignmentslocal variables partial assignment received CPA, assignment lower boundsmaller current global upper bound found. Otherwise, backtracks sendingCPA former agent revise assignment.agent succeeds extend assignment CPA sends forward copies updatedCPA, requesting unassigned agents compute lower bound estimations cost partialassignment. assigning agent receive estimations asynchronously time useupdate lower bound CPA.Gathering updated lower bounds future assigning agents, may enable agent discoverlower bound CPA sent forward higher current upper bound (i.e. inconsistent). discovery triggers creation new CPA copy CPA sentforward. agent resumes search trying replace inconsistent assignment. time62fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPstamp mechanism proposed Nguyen, Sam-Hroud, Faltings (2004) used MeiselsZivan (2007) used agents determine updated CPA discard obsolete CPAs.concurrency AFB algorithm achieved fact forward-bounding performed concurrently asynchronously agents. form asynchronicity similaremployed Asynchronous Forward-Checking (AFC) algorithm distributed constraintsatisfaction problems (DisCSPs) (Meisels & Zivan, 2006; Meseguer & Jimenez, 2000). AFBenhanced backjumping (Zivan & Meisels, 2007), resulting algorithm performs concurrently distributed forward bounding backjumping prunes search space DisCOPsefficiently. demonstrated extensive experimental evaluation Section 6 AF Bdemonstrates phase transition randomly generated DisCOPs (Larrosa & Schiex, 2004).extensive evaluation includes comparisons performance AF B best DisCOPsearch algorithms. include asynchronous branch bound like ADOPT (Modi et al., 2005),well algorithms based principles - DPOP (Petcu & Faltings, 2005a) usestwo passes pseudo-tree Opt AP O,that divides DisCOP sub-problems (Mailler &Lesser, 2004).plan paper follows. Distributed Constraint Optimization presented Section 2. Section 3, AF B algorithm full details presented. Section 4 versionAF B algorithm enhanced conflict directed backjumping (CBJ) presented. correctness proof AF B algorithm presented Section 5. Section 6 extensive empiricalevaluation AF B algorithm presented. AF B compared state art DisCOPalgorithms, ADOP like AF B include centralization problems dataDP OP Opt AP (Petcu & Faltings, 2005a; Mailler & Lesser, 2004), baseddifferent principles. Conclusions presented Section 7.2. Distributed Constraint OptimizationFormally, DisCOP tuple < A, X , D, R >. finite set agents A1 , A2 , ..., . Xfinite set variables X1 ,X2 ,...,Xm . variable held single agent (an agent may holdone variable). set domains D1 , D2 ,...,Dm . domain Di contains finite setvalues assigned variable Xi . R set relations (constraints). constraintC R defines none-negative cost every possible value combination set variables,form C : Di1 Di2 . . . Dik R+ {0}. binary constraint refers exactly twovariables form Cij : Di Dj R+ {0}. binary DisCOP DisCOPconstraints binary. assignment (or label) pair including variable, valuevariables domain. partial assignment (PA) set assignments, variableappears once. vars(PA) set variables appear PA, vars(P A) = {Xi |Di (Xi , a) P A}. constraint C R form C : Di1 Di2 . . . Dik R+ {0}applicable PA Xi1 , Xi2 , . . . , Xik vars(P A). cost partial assignment PAsum applicable constraints PA assignments PA. full assignment partialassignment includes variables (vars(P A) = X ). goal find full assignmentminimal cost.paper, assume agent owns single variable, use term agentvariable interchangeably, assume agent Ai holds variable Xi (Modi et al., 2005; Petcu &Faltings, 2005a; Mailler & Lesser, 2004). assume constraints binarydelay delivering message finite (Yokoo, 2000a; Modi et al., 2005). Furthermore, assumestatic final order agents, known agents participating search process (Yokoo,63fiG ERSHMAN , EISELS , & Z IVANFigure 1: example DisCOP. variable two values R B, constraintsform shown table left.2000a). assumptions commonly used DisCSP DisCOP algorithms (Yokoo, 2000a;Modi et al., 2005).Example 1 example DisCOP presented figure 1. 4 variables, variableheld different agent. domains variables contain exactly two values R B.Lines variables represent (binary) constraints. cost constraints showntable left. partial assignment {(X1 , R)} cost zero, since constraintapplicable it. partial assignment {(X1 , R), (X4 , R)} also cost zero, sinceconstraint applicable it. partial assignment {(X1 , R), (X2 , R)} cost two, dueconstraint C1,2 . partial assignment {(X1 , R), (X2 , R), (X3 , B)} cost four, dueconstraints C1,2 , C2,3 , C1,3 . One solution {(X1 , R), (X2 , B), (X3 , R), (X4 , R)}cost five. solution since full assignment lower cost.3. Asynchronous Forward BoundingAFB algorithm single up-to-date current partial assignment passed among agents.Agents assign variables hold up-to-date CPA.CPA unique message passed agents, carries partial assignmentagents attempt extend complete optimal solution assigning variablesit. CPA also carries accumulated cost constraints assignments contains,well unique time-stamp.Due asynchronous nature algorithm, multiple CPAs may present instant,however single CPA includes update date partial assignment. CPAhighest timestamp.one agent performs assignment single CPA time. Copies CPAsent forward concurrently processed multiple agents. unassigned agent computeslower bound cost assigning value variable, sends bound back agent64fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPperformed assignment. assigning agent uses bounds prune sub-spacessearch-space contain full assignment cost lower best full assignmentfound far. total order among agents assumed (A1 assumed first agent order,assumed last).detail, every agent adds assignment CPA sends forward copies CPA,messages term FB CPA, agents whose assignments yet CPA. agentreceiving FB CPA message computes lower bound cost increment caused addingassignment variable. estimated cost sent back agent sent FB CPAmessage via FB ESTIMATE messages. computation bound detailed section 3.1.Notice possible assigning agent already sent CPA forward timeestimations received. estimations indicate CPA exceeds bound, agentgenerate new CPA, different local assignment (and higher timestamp associatedit) continue search new CPA. timestamping mechanism insuresobsolete CPA (eventually) discarded regardless current location. timestampmechanism described section 3.3.3.1 AFB - Computing Lower Bound Estimation Cost Incrementcomputation lower bound cost increment caused adding assignmentagents local variable done follows.Denote cost((i, v), (j, u)) cost assigning Ai = v Aj = u. agent Aivalue domain v Di , denote minimal cost assignment (i,v) incurredagent Aj hj (v) = minuDj (cost((i, v), (j, u))). define h(v), total cost assigningvalue v, sum hj (v) j > i. Intuitively, h(v) lower bound costconstraints involving assignment Ai = v agents Aj j > i. Notebound computed per agent, since independent assignments higher priorityagents.agent Ai , receives F B CP message, compute every v Dicost increment assigning v value, i.e. sum cost v assignmentsincluded CP A, h(v). sum these, denoted f (v). lowest calculated f (v)among values v Di chosen lower bound estimation cost increment agentAi .Figure 2 presents constraint network. Large ovals represent variables small circles represent values. presented constraint network, A1 already assigned value v1 A2 , A3 , A4unassigned. Let us assume cost every constraint one. cost v3 increaseone due constraint current assignment thus f (v3 ) = 1. Since v4 constrainedv8 v9 , assigning value trigger cost increment A4 performs assignment.Therefore h(v4 ) = 1 admissible lower bound cost constraints valuelower priority agents. Since v4 conflict assignments CPA, f (v4 ) = 1well. f (v5 ) = 3 assignment conflicts assignment CPA additionconflicts values two remaining agents.Since h(v) takes account constraints Ai lower priority agents (Aj s.t. j > i),unassigned lower priority agents need estimate cost constraints Ai . Therefore,estimations accumulated summed agent initiated forwardbounding process compute lower bound cost complete assignment extendedCPA.65fiG ERSHMAN , EISELS , & Z IVANFigure 2: simple DisCOP, demonstrationformally define:Definition 1 CPA current partial assignment, containing assignments made agentsA1 , . . . , Ai1 .Let us define notions past, local future costs definitions 2, 3 4.Definition 2 PC (Past-Cost) added cost assignments made higher priority agentsCPA (the costs incurred agents A1 , . . . , Ai1 .Definition 3 LC(v) (Local-Cost) cost incurred CPA Ai would assign value vadd CPA. Therefore,XLC(v) =cost((i, v), (j, w))(Aj ,w)CPDefinition 4 FC(v) (Future-Cost) sum lower bounds cost increments causedagents Ai+1 , . . . , CPA additional assignment Ai = v.XF C(v) =minwDj (f (w)), s.t Ai = v added CPj>idefinitions allow us compute lower bound cost full assignmentextended CPA, use bound order prune parts search space. agent(Ai ) receives CPA, question, lower bound would extendedassignment Ai = v. PC LC(v) known agent, FC(v) computedtime, requesting future agents (lower priority agents) compute lower boundssend back Ai . sum PC + LC(v) + FC(v) composes lower bound, usedprune search spaces. happen agent knows full assignment already66fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPfound cost lower sum, therefore exploring search-space would leadbetter cost solutions.Thus, asynchronous forward bounding enables agents early detection partial assignmentscannot extended complete assignments cost smaller known upper bound,initiate backtracks early possible.3.2 AFB - Algorithm DescriptionAFB algorithm run agents DisCOP. agent first calls procedureinit responds messages receives ERM E message. algorithmpresented Figure 3.1. computation bounds, time-stamping mechanismshown, explained text.initialization, agent updates B cost best full assignment found farsince assignment found, set infinity (line 1). first agent (A1 ) createsempty CPA begins search process calling assign CPA (lines 3-4), order findvalue assignment variable.agent receiving CPA (when received CPA MSG), first makes sure relevant. timestamp mechanism used determine relevance CPA explained Section 3.3.CPAs time-stamp reveals date CPA, message discarded.case, agent processing message already received message implyingassignment agent higher priority itself, changed.message discarded, agent saves received PA local CPA variable (line 7). Then,agent checks received PA (without assignment variable) exceedallowed cost B (lines 8-10). exceed bound, tries assign valuevariable (or replace existing assignment case one already) calling assign CPA (line13). bound exceeded, backtrack initiated (line 11) CPA sent higherpriority agent, since cost already high (even without assignment variable).Procedure assign CPA attempts find value assignment, current agent, withinbounds current CPA. First, estimates related prior assignments cleared (line 19). Next,agent attempts assign every value domain already try. CPA arrivedwithout assignment variable, tries every value domain. Otherwise, searchvalue continued value following last assigned value. assigned value mustsum cost CPA lower bound cost increment causedassignment exceed upper bound B (lines 20-22). value found,assignment higher priority agent must altered, backtrack called (line 23).Otherwise, agent assigns selected value CPA.agent last agent (An ), complete assignment reached, accumulated cost lower B, broadcasted agents (line 27). broadcast informagents new bound cost full assignment, cause update upperbound B.agent holding CPA (An ) continues search, updating bound B, callingassign CPA (line 29). current value picked call, since CPAs costassignment equal B, procedure requires cost lower B.agent continue search, testing values, backtracking case leadimprovement.67fiG ERSHMAN , EISELS , & Z IVANprocedure init:1. B2. (Ai = A1 )3.generate CP A()4.assign CP A()received (FB CPA, Aj , P A)5. f estimation based received P A.6. send (F B EST IM E, f , P A, Ai ) Ajreceived (CPA MSG, P A)7. CP P8. empCP P9. empCP contains assignment Ai , remove10. (T empCP A.cost B)11.backtrack()12. else13. assign CP A()received (FB ESTIMATE, estimate, P , Aj )14. save estimate15. ( CPA.cost + saved estimates) B )16. assign CP A()received (NEW SOLUTION, P A)17. B CP P18. B P A.costprocedure assign CPA:19. clear estimations20. CP contains assignment Ai = w, remove21. iterate (from last assigned value) Di foundv Di s.t. CP A.cost + f (v) < B22. value exists23.backtrack()24. else25.assign Ai = v26. CP full assignment27.broadcast (NEW SOLUTION, CPA )28.B CP A.cost29.assign CP A()30. else31.send(CPA MSG, CPA) Ai+132.forall j >33.send(FB CPA, Ai , CPA) Ajprocedure backtrack:34. clear estimates35. (Ai = A1 )36.broadcast(TERMINATE)37. else38.send(CPA MSG, CPA) Ai1Figure 3: procedures AFB Algorithm68fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPagent holding CPA last agent (line 30), CPA sent forwardnext unassigned agent, additional value assignment (line 31). Concurrently, forward boundingrequests (i.e. FB CPA messages) sent lower priority agents (lines 32-33).Agent receiving forward bounding request (when received FB CPA) agent Aj ,uses time-stamp mechanism ignore irrelevant messages. message relevant,agent computes estimate (lower bound) cost incurred lowest cost assignmentvariable (line 5). exact computation estimation described Section 3.1 (itminimal f (v) v Di ). estimation attached message sent backsender, FB ESTIMATE message.agent receiving bound estimation (when received FB ESTIMATE) lower priorityagent Aj (in response forward bounding message) ignores estimate alreadyabandoned partial assignment (identified using time-stamp mechanism). Otherwise, savesestimate (line 14) checks new estimate causes current partial assignment exceedbound B (line 15). case, agent calls assign CP (line 16) order changevalue assignment (or backtrack case valid assignment cannot found).call backtrack made whenever current agent cannot find valid value (i.e.bound B). case, agent clears saved estimates, sends CPA backwardsagent Ai1 (line 38). agent first agent (nowhere backtrack to), terminate broadcastends search process agents (line 36). algorithm reports optimal solutioncost B, full assignment cost B CP A.3.3 Time-Stamp Mechanismmentioned previously, AFB uses time-stamp mechanism (Nguyen et al., 2004; Meisels &Zivan, 2007) determine relevance CPA. requirements mechanismgiven two messages two different partial assignments, must determine oneobsolete. obsolete partial assignment one abandoned search processone assigned agents changed assignment. requirement accomplishedtime-stamping mechanism following way. agent keeps local running-assignmentcounter. Whenever performs assignment increments local counter. Whenever sendsmessage containing assignment, agent copies current counter onto message.message holds vector containing counters agents passed through. i-th elementvector corresponds Ai counter. vector fact time-stamp. lexicographicalcomparison two vectors reveal time-stamp up-to-date.agent saves copy knows up-to-date time-stamp. receivingnew message newer time-stamp, agent updates local saved latest time-stamp.Suppose agent Ai receives message time-stamp lexicographically smallerlocally saved latest, comparing first 1 elements vector. meansmessage based combination assignments already abandoned messagediscarded. messages time-stamp first 1 elemental equal greaterlocally saved best time-stamp message processed further.vectors counters might appear require lot space, number assignmentsgrow exponentially number agents. However, agent (Ai ) resets local counterzero time assignments higher priority agents altered, counters remain small(log size value domain), mechanism remain correct.69fiG ERSHMAN , EISELS , & Z IVAN3.4 AFB - Example RunSuppose run AFB DisCOP figure 1. X1 create empty CPA, assign first valueR pass CPA X2 . CPA travel X2 , X3 finally X4 , agentassigning first value (R) along way finally X4 full assignmenttotal accumulated cost 8. cost broadcasted agents (line 27 figure 3.1)new upper bound (instead infinity). Next, X4 call assign CP procedure (line 29).call result new assignment X4 , value B, since resulting full assignmentcost 7. cause another broadcast update upper bound anothercall assign CP A. next call, X4 empty domain forced backtrackCPA X3 . CPA contains assignments X1 = X2 = X3 = R, total accumulated cost6 upper bound. Therefore X3 call assign CP (line 13). Examiningremaining values, X3 explores assignment B result CPA cost 4(line 21), current upper bound B. CPA sent X4 (line 31). X4 callsassign CP procedure (line 13). value R result CPA cost 6, betterupper bound B 7, therefore broadcasted (line 27). next value, B, exploredX4 results CPA cost 5, also broadcasted. CPA sent backwards X3 .X3 values try, also backtracks CPA, X2 . X2 assigns next value, B,sends CPA X3 . addition X2 also sends copies CPA FB CPA messages X3X4 (line 33). X3 receives FB CPA, computes estimation 3 (because X3R would increase CPAs cost 3 B would increase 4), sendsinformation back X2 (line 6). Suppose X4 also receives F B CP A, repliesestimation 1. CPA explores sub-search X2 = B (passing X3X4 ), estimations arrive X2 . X2 saves estimations adds up. leadsdiscovery backtrack needed, since CPAs cost 1 (because X1 = R, X2 = B)additional estimations 4 results sum equal upper bound B (line 15). Therefore,X2 abandons assignment attempts assign next value (calling assign CP - line 16).Since X2 values, call results backtrack (line 23). CPA sent backtrackhigher timestamp value CPA previously sent forward X2 , former CPAwould eventually discarded.3.5 Discussion - Concurrency, Robustness, Privacy Asynchronicitypoint time run AFB, single most-up-to-date CPA system.agent adds assignment holds it, assignments performed sequentially. Onemight think would necessarily result poor performance, search process trytake advantage existing multiple computational resources available it. concurrencyAFB comes use forward-bounding mechanism. CPA held oneagent, many copies sent forward, collection agents compute concurrently lowerbounds CPA. CPA advances next agent, process repeats,unassigned agents constantly kept working, either receive CPA,need compute bounds partial assignment.degree asynchronicity similar employed Asynchronous Forward-CheckingAFC algorithm DisCSPs (Meseguer & Jimenez, 2000; Meisels & Zivan, 2006). AFC performssimilar process agents receive forward-checking messages agents performed assignments. unassigned agents perform forward-checking (checking leastone value consistent previous assignments). AFB agents compute lower70fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPbound local cost increment due assignments made previous agents. Duesimilarity named algorithm Asynchronous Forward-Bounding.AFBs approach quite different used asynchronous assignments algorithmsADOPT ABT (Modi et al., 2005; Bessiere, Maestre, Brito, & Meseguer, 2005).algorithms search process attempts perform assignments concurrently collectionagents. Since many agents assigning variables simultaneously, probabilitymust handled algorithm, current agents view assignments made agentsincorrect. due fact agents concurrently alter assignments. algorithmmust able deal uncertainty.search process performs assignments asynchronously may expected save timesince agents need wait assignments past agents reach them, done sequentially assigning algorithm. However, asynchronously assigning algorithms must also dealinconsistencies caused message delay. example, several higher priority agents changeassignments messages received (the others delayed) computationperformed based inconsistent agent view. type scenario, computation based inconsistent partial assignment, completely avoided sequentially assigningalgorithms.One variation AFB algorithm agents sent FB-CPA messages, sendmessages subset target agents direct constraint sendingagent. may useful communication agents limited (agents may communicate agents direct conflict) would keep algorithm correct.change may two effects. First, less agents return bounds sending agents.bounds significant (greater zero) since take account constraints assignments previous agents (which may conflicted with) also constraintsreceiving agent agents lower priority (constraint unassigned agents). Receiving lesslower bounds would invalidate correctness algorithm may cause search process needlessly explore sub-spaces could discovered dead-ends. Second,detection obsolete CPAs may delayed since less agents receive higher timestamp (whichFB-CPA may contain). mechanism would remain correct since eventually another FB-CPACPA would reach agent receive FB-CPA, however may taketime single cycle messages (in words, time travel timesingle message two agents). AFB algorithm intentionally presented algorithm sends FB messages unassigned agents, since constraint communicationagents assumed. case constraints exist, one attempts reduce numbermessages sent algorithm, variation explored.Privacy considered one main motivations solving problems distributively. common model distributed search algorithms DisCSPs DisCOPs enables assignmentsNogoods passed among agents (Yokoo, Ishida, Durfee, & Kuwabara, 1992; Yokoo, 2000b;Bessiere et al., 2005; Modi et al., 2005; Zivan & Meisels, 2006; Meisels & Zivan, 2007). AF B follows model proposed Yokoo, sending assignments forward bounds partial assignments(N ogoods) backwards. additional privacy drawback AF B fact agents learnassignments non neighboring agents via CPAs receive neighbors.problem easily solved AF B simple use encryption. every pair neighboringagents share encryption key, agent would able learn assignmentsneighbors receives CPA. use limited encryption DisCOP algorithmsrecently proposed DP OP (Greenstadt, Grosz, & Smith, 2007).71fiG ERSHMAN , EISELS , & Z IVANIf, due privacy, constraints partially known two constrained agents,part constraint known constrained agents, bound computationmechanism must adjusted AFB. type constraints discussed DisCSP algorithms (Brito, Meisels, Meseguer, & Zivan, 2008). best knowledge, DisCOP solverfar handled constraints. remains interesting possible extension AFB partfuture work.Robustness another important aspect distributed search algorithm. assumedmessages delivered order sent messages lost. Howevermessage passing susceptible losses corruption data, AFB may terminate (if, say,CPA message lost). also possible local data held agents corrupt (duemechanical failure example). solution would build self-stabilizing algorithm.Self stabilization distributed systems (Dijkstra, 1974) ability system respondtransient failures eventually reaching maintaining legal state. self stabilizing versionshown simple DFS algorithm DisCSPs (Collin, Dechter, & Katz, 1999). Basedself-stabilizing DFS algorithm, self-stabilizing version DPOP developed (Petcu &Faltings, 2005b). However self-stabilizing DisCSP/DisCOP solvers bestauthors knowledge. Clearly, thorough study robustness self-stabilizationrequired DisCOP algorithms.conclude, AFB algorithm includes concurrent computation multiple agents, withoutdeal uncertainty comes asynchronous assignments. agentreceives message containing partial assignment knows certainty given partial assignment one supposed receive, result network delay inconsistency.Therefore, AFB concurrent computation certainty working consistent partial assignments. results much better performance hard instances random DisCOPs,demonstrated empirical evaluation section 6.4. AFB CBJcentralized distributed CSPs backjumping accomplished maintaining datastructures allow agent deduce latest agent (in order assignmentsmade) whose changed assignment could possibly lead solution. agentfound, assignments following agents unmade search process backjumpsagent (Prosser, 1993).similar process designed branch bound based solvers COPs DisCOPs.Consider sequence assignments agents A1 , A2 , A3 , A4 , A5 A5 determinednone possible value assignments lead full assignment cost lower costbest full assignment found far. Clearly, A5 must backtrack.chronological backtracking, search process would simply return previous agent,namely A4 , change assignment. However, A5 sometimes determine valuechange A4 would suffice reach full assignment lower cost. Intuitively, A5 safelybackjump A3 , compute lower bound cost full assignment extendedassignments A1 , A2 A3 , show bound greater equal cost bestfull assignment found far. intuitive basis backjumping added AFB.formally, let us consider scenario Ai decides backtrack, costbest full assignment found far B (e.g. upper bound current state search).current partial assignment includes assignments agents A1 , ..., Ai1 .72fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPDefinition 5 CPA[1..k] set assignments made agents A1 , . . . , Ak current partialassignment. define CP A[1..0] = {}.Definition 6 FA[k] set full assignments, include assignments appearingCPA[1..k]. words, set contains full assignments extendedassignments appearing CPA[1..k]. Naturally, FA[0] set possible full assignments.backtrack, instead simply backtracking previous agent, Ai performs followingactions: computes lower bound cost full assignment FA[i-2]. boundsmaller B, backtracks Ai1 like would chronological backtracking. However,bound greater equal B, backtracking Ai1 would little good. valuechange Ai1 alone could result full assignment cost lower B. result, Ai knowssafely backjump Ai2 . may possible Ai backjump even further, dependinglower bound cost full assignmentFA[i-3]. bound smaller B, backjumps Ai2 . Otherwise, knows safelybackjump Ai3 . Similar checks made necessity backjump further.backjumping procedure relies computation lower bounds sets full assignments (FA[k]). Next, show Ai compute lower bounds. Let us definenotions past, local future costs definitions 7, 8 9.Definition 7 PC (Past-Costs) vector size n+1, k-th element (0 k n)equal cost CPA[1..k].Definition 8 LC(v) (Local-Costs) vector size n + 1 computed Ai held it,k-th element (0 k n)XLC(v)[k] =cost(Ai = v, Aj = vj )(Aj ,vj )CP s.t jkSince CPA held Ai includes assignments A1 , . . . , Ai1 ,j i, LC(v)[i 1] = LC(v)[j]Intuitively, LC(v)[i] accumulated cost value v Ai , respect assignmentsCPA[1..i].Definition 9 FCj (v) (Future-Costs) vector size n+1, k-th element (0 k n)contains lower bound cost assigning value Aj respect partial assignment CPA[1..k]. Assume structure held agent Ai . k CPA[1..k] containsassignment Ai = v, k < value v Ai irrelevant appear CPA[1..k].vectors provide additive lower bounds full assignments start currentCPA k, FA[k]. PC[k] isPthe exact cost first k assignments, LC(v)[k] exact costassignment Ai = v, j>i F Cj (v)[k] lower bound assignments Ai+1 , ..., .Therefore, sumXFALB(v)[k] = LC(v)[k] + P C[k] +F Cj (v)[k]j>i73fiG ERSHMAN , EISELS , & Z IVANFigure 4: example DisCOPFull Assignment Lower Bound cost full assignment extended CPA[1..k]Ai = v.FA[k] contains full assignments extended CPA[1..k], limited assignmentsAi = v. go FALB(v)[k], possible values v Di produce lowerbound assignment FA[k].Definition 10 FALB[k] = minvDi (F ALB(v)[k]).FALB[k] lower bound cost full assignment extended CPA[1..k].distributed branch bound algorithm, bound computed Ai . PC - costprevious agents sent along value assignment messages Ai . LC(v) - costassigning v Ai computed Ai . Ai requests agents ordered it, Aj (j > i),compute FCj send results back Ai . part already existing AFB mechanismforward bounding.AFB algorithm (Gershman, Meisels, & Zivan, 2007) Ai already requests unassignedagents compute lower bounds CPA send back results. additional boundsneeded backjumping easily added existing AFB framework.4.1 Backjumping Exampledemonstrate backjumping possibility, consider DisCOP Figure 4 (again, large ovalsrepresent variables small circles represent values). Let us assume search beginsA1 assigning value sending CP forward A2 . A2 , A3 , A4 , A5 assignvalue get full assignment cost 12. search continues, fullyexploring sub-space A1 = a, A2 = a, best assignment found A1 = a, A2 =a, A3 = b, A4 = a, A5 = b total cost B=6. Assume A3 holding CPreceiving future agent (A4 A5 ). A3 exhausted value domain mustbacktrack. computes:F ALB(a)[1] = P C[1] + LC(a)[1] + (F C4 (a)[1] + F C5 (a)[1])74fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COP= 0 + 2 + (3 + 2) = 7F ALB(b)[1] = P C[1] + LC(b)[1] + (F C4 (b)[1] + F C5 (b)[1])= 0 + 1 + (3 + 2) = 6F ALB[1] = min(F ALB(a)[1], F LAB(b)[1]) = 6F ALB[1] B, therefore A3 knows full assignment extended {A1 = a} would costleast 6. full assignment cost already discovered, need explorerest sub-space, safely backjump search process back A1 , changevalue b. Backtracking A2 leaves search process within {A1 = a} sub-space,A3 knows cannot lead full assignment lower cost.4.2 AFB-BJ AlgorithmAFB-BJ algorithm run agents DisCOP. agent first calls procedure init responds messages receives TERMINATE message. algorithmpresented figures 5 6. pure AFB, timestamping mechanism used messages.timestamping mechanism used AFB used AFB-BJ determine messages relevant obsolete. simplicity choose omit pseudo-code detailing calculation LC, PC, FC FALB, described Section 4.1.algorithm starts agent calling init awaiting messages termination.first, agent updates B cost best full assignment found far sinceassignment found, set infinity (line 1). first agent (A1 ) creates emptyCPA begins search process calling assign CPA (lines 3-4), order find valueassignment variable.agent receiving CPA (when received CPA MSG), checks time-stamp associatedit. date CP discarded. message discarded, agent savesreceived PA local CPA variable (line 7). case CPA received higher priorityagent, estimations future agents F Cj longer relevant discarded,domain values must reordered updated cost (lines 9-11). Then, agent attemptsassign next value calling assign CPA (line 16) backtrack needed (line 14).Procedure assign CPA attempts find value assignment, current agent. assignedvalue must sum cost CPA lower bound cost incrementcaused assignment exceed upper bound B (lines 23). value found,assignment higher priority agent must altered, backtrack called (line 25).full assignment found better best full assignment known far,broadcast agents (line 29). succeeding assign value, CPA sent forwardnext unassigned agent (line 33). Concurrently, forward bounding requests (i.e. FB CPA messages)sent lower priority agents (lines 34-35).agent receiving bound estimation (when received FB ESTIMATE) lower priorityagent Aj (in response forward bounding message) ignores estimate alreadyabandoned partial assignment (identified using time-stamp mechanism). Otherwise, savesestimate (line 17) checks new estimate causes current partial assignment exceedbound B (line 18). case, agent calls assign CP (line 19) order changevalue assignment (or backtrack case valid assignment cannot found).75fiG ERSHMAN , EISELS , & Z IVANprocedure init:1. B2. (Ai = A1 )3.generate CP A()4.assign CP A()received (FB CPA, Aj , P A)5. V estimation vector PA[1..k] (0 k n)6. send (F B EST IM E, V , P A, Ai ) Ajreceived (CPA MSG, P A, Aj )7. CP P8. empCP P9. (j = 1)10. j re-initialize F Cj (v)11. reorder domain values v Di LC(v)[i] (from low high)12. (T empCP contains assignment Ai ) remove13. (T empCP A.cost B)14. backtrack()15. else16. assign CP A()received (FB ESTIMATE, V , P , Aj )17. F Cj (v) V18. ( FALB(v)[i] B )19. assign CP A()received (NEW SOLUTION, P A)20. B CP P21. B P A.costFigure 5: Initialization message handling procedures AFB-BJ Algorithmcall backtrack made whenever current agent cannot find valid value (i.e.bound B). case, agent calls backtrackTo() compute agent CPAsent, backtracks search process (by sending CPA) back agent.agent first agent (nowhere backtrack to), terminate broadcast ends search processagents (line 37). algorithm reports optimal solution cost B,full assignment corresponding cost B CP A.function backtrackTo computes agent CPA sent. kernelbackjumping (BJ) mechanism. goes candidates, j 1 1, lookingfirst agent finds chance reaching full assignment lower costB. FALB(v)[j-1] lower bound cost full assignment extended CPA[1..j-1],PC[j]-PC[j-1] cost added CPA Aj assignment. Since Aj picked lowest costvalue domain (its domain ordered line 11), addition two components76fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPprocedure assign CPA:22. CP contains assignment Ai = w, remove23. iterate (from last assigned value) Di first value satisfyingv Di s.t. CP A.cost + f (v) < B24. value exists25.backtrack()26. else27.assign Ai = v28.CP full assignment29.broadcast (NEW SOLUTION, CPA )30.B CP A.cost31.assign CP A()32.else33.send(CPA MSG, CPA, Ai ) Ai+134.forall j >35.send(FB CPA, Ai , CPA) Ajprocedure backtrack:36. (Ai = A1 )37.broadcast(TERMINATE)38. else39.j backtrackTo()40.remove assignments Aj+1 , .., Ai CP41.send(CPA MSG, CPA, Ai ) Ajfunction backtrackTo:42. j = 1 downto 143.foreach v Di44.( FALB(v)[j-1] + (PC[j] - PC[j-1]) < B )45.return j46. broadcast(TERMINATE)Figure 6: assigning backtracking procedures AFB-BJ Algorithm.produces accurate lower bound cost full assignment extended CPA[1..j-1].safely added FALB since adds lower bound cost incrementagent FALB include lower bound.Example 2 example presented section 4.1, A3 computed FALB(b)[1] addedpast costs partial assignments (cost incurred A1 ), local cost A3 , lowerbound cost increment future agents (A4 A5 ). sum safely add costadded A2 know A2 picked lowest cost assignment.addition helps tighten FALB reduce search. combined bound smallerB, surely combination assignments made Aj following agent couldraise cost, already high. case even backjumping back A1 provehelpful, search process terminated (line 46).77fiG ERSHMAN , EISELS , & Z IVAN5. Correctness AFBorder prove correctness AF B two claims must established. First, algorithmterminates second algorithm terminates global upper bound B costoptimal solution. prove termination one show AF B algorithm never goesendless loop. prove last statement enough show partial assignmentcannot generated once.Lemma 1 AF B algorithm never generates two identical CPAs.Assume negation Ai highest priority agent (first order assignments)generates CPA second time. lets consider possible events immediatelypreceded creation.Case 1 - Ai received CPA message lower priority agent. Let us denote agent Aj ,j > i. Ai received message, executed lines 7-13 (see Figure 3.1). procedurebacktrack line 14 executed since know Ai generated CPA, procedure wouldso. Therefore line 16 executed, procedure assign CPA invoked. Ai executedlines 22-24. Line 25 executed since invoking backtrack procedure could leadcreation CPA. Therefore, line 24 value described line 23 found exist.Line 23 searches value Ai remaining value domain, exploring value previouslyattempted current set assignments higher priority agents. Since assumed Aihighest priority agent generates CPA second time, combination higherpriority assignments repeat itself. Therefore, since Ai received current set higherpriority assignments Ai re-pick local value, set high priority assignmentsrepeat itself, therefore Ai cannot pick value would generate CPAsecond time.Case 2 - Ai received CPA message higher priority agent. Let us denote agentAj , j < i. Since assumed Ai highest priority agent generates CPAsecond time, combination higher priority assignments repeat itself. Thereforevalue Ai would assign next would generate unique CPA, one could generatedbefore.Case 3 - Ai received CPA message itself. cannot since Ai never sendsmessage itself.Case 4 - Ai received FB ESTIMATE message Aj . j > since FB ESTIMATEsent response FB CPA messages. sent (line 34) agents lower priorityAi . Since message caused creation CPA, condition line 19 mustevaluated true, procedure assign CPA line 19 invoked. Similar case 1, lines 22-24executed line 25 not. Similar case 1, value found line 23. valuerepeat value previously picked current set higher priority agent assignments.time agent received current set higher priority agent assignments dueassumption Ai first generate CPA twice.Case 5 - procedure init invoked. cannot since CPAs previously generated, CPA generated must unique.events could immediately preceded creation second identical CPA,therefore impossible event occur. completes proof lemma.Termination follows immediately Lemma 1.78fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPNext, one needs prove upon termination complete assignment, correspondingoptimal solution, B CP (see Figure 3.1). one point terminationAF B algorithm, procedure backtrack. So, one needs prove search partialassignment lead solution lower cost B discarded. Let us consider possiblecases agent discards CPA, changes value skips value let us showcannot be. Skipping changing value done inside procedure assign CPAlines 22-24. v value skipped over, condition line 23 holdsCP A.cost + f (v) B. Since B B CP A, CP A.cost + f (v) B B CPmeans v could possibly lead solution cost lower B CP termination. Letus consider possible cases value changed. occurs inside procedureassign CPA. Let us consider possible cases procedure invoked resultvalue change.Case 1 - invoking assign CPA init procedure (line 4). solution could lost sincefirst assignment performed, part search space skippedassignment.Case 2 - invoking assign CPA inside assign CPA procedure (line 31). happensnew best (so far) solution found. obviously changing assignment would losesolution since saved broadcasted new current solution. discardedbetter solution later found.Case 3 - invoking assign CPA following received FB ESTIMATE message (line 19).current partial assignment safely discarded, knowing solution lost sincecondition line 18 indicated current partial assignment lower bound exceedsbest solution found far.Case 4 - invoking assign CPA following received CPA MSG message (line 16) Ajj > i. means CPA returned backtrack fully exploring current sub-space,therefore changing current assignment would lead potential solution lost.Case 5 - invoking assign CPA following received CPA MSG message (line 16) Ajj < i. means CPA received higher priority agent. Ai yet pickassignment, assignment make lose potential solutions.Therefore, value skipped change CPA lead losspotential solution. remaining event may lead solution skippedCPA discarded. done time-stamping mechanism occursagent knows existence up-to-date CPA. CPA created agentchanged assignment calling assign CPA. showed case better solutionlost, therefore safe discard CPA.conclusion, event value skipped changed CPA discarded, possible better solution lost. Therefore termination, AFB algorithm reports best solutionpossible. completes correctness proof AF B algorithm.order prove correctness AFB-BJ algorithm first prove correctness proposed backjumping method show combination AFB violate AFBscorrectness proven.order prove correctness backjumping method one need show noneagents assignments algorithm backjumps over, lead solution lowercost current upper bound. condition performing backjumping agent Aj(line 44) lower bound cost full assignment extended assignments79fiG ERSHMAN , EISELS , & Z IVANFigure 7: Total non-concurrent computational steps AFB, ADOPT SBB low density(p1 =0.4) Max-DisCSPA1 , .., Aj1 assignment cost Aj exceeds global upper bound B. Since Aj pickedlowest cost value remaining domain (as domain ordered), extending assignmentsA1 , .., Aj1 must lead cost greater equal B. Therefore, backjumping back Aj1cannot discard potentially lower cost solutions. completes correctness proofAFB-BJ backjumping (function backtrackTo) method.Assuming correctness AFB, order prove correctness composite algorithmAFB-BJ enough prove consistency lower bounds computed agents AFBBJ. lower bounds computed AFB-BJ include FC, LC PC described section 4. PCcontained CPA, updated agent receives adds assignment (notshown code). LC(v) computed current agent Ai whenever assigns v valueassignment. FCj computed Aj line 5 (in figure 5), sent back Ai line 6. Aireceives saves line 17. lower bounds contained inside vectors correctPC exactly calculated holding CPA, LC exactly calculated currentagent Ai , bounds FCj bounds computed AFB provencorrect lower bounds assignment Aj . FCj bounds accurate basedcurrent partial assignment since timestamp mechanism prevents processing boundsbased obsolete CPA. Whenever CPA altered higher priority agent, previousbounds cleared (line 10 figure 5). completes correctness proof AF B BJ.6. Experimental Evaluationexperiments performed simulator agents simulated threadscommunicate message passing. Distributed Optimization problems usedpresented experiments random Max-DisCSPs. network constraints,experiments, generated randomly selecting probability p1 constraint among pairvariables probability p2 , occurrence violation (a non zero cost) among twoassignments values constrained pair variables. uniform random constraints networksn variables, values domain, constraints density p1 tightness p2 commonlyused experimental evaluations CSP algorithms (cf. (Prosser, 1996)). Max-CSPs commonlyused experimental evaluations constraint optimization problems (COPs) (Larrosa & Schiex,80fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPFigure 8: Total number messages sent AFB, ADOPT SBB low density (p1 =0.4) MaxDisCSP(a)(b)Figure 9: (a) Number none-concurrent steps performed ADOPT, AFB, AFB-minC AFBBJ high density Max-DisCSP (p1 = 0.7). (b) closer look p2 > 0.92004). experimental evaluations DisCOPs include graph coloring problems (Modi et al.,2005; Zhang et al., 2005), subclass Max-DisCSP.order evaluate performance distributed algorithms, two independent measuresperformance used - run time, form non-concurrent steps computation (Zivan &Meisels, 2006b), communication load, form total number messages sent (Lynch,1997; Yokoo, 2000a).first set experiments, performance AF B compared two algorithms.synchronous B&B algorithm (SBB) (Hirayama & Yokoo, 1997) asynchronous distributed optimization algorithm (ADOP ) (Modi et al., 2005). Figure 7 presents average runtime number non-concurrent computation steps, randomly generated Max-DisCSPsn = 10 agents, domain size = 10, constraint tightness p1 = 0.4. Figure 8 compares81fiG ERSHMAN , EISELS , & Z IVAN(a)(b)Figure 10: (a) Number messages sent ADOPT, AFB, AFB-minC AFB-BJ high densityMax-DisCSP (p1 = 0.7). (b) closer look p2 > 0.9algorithms problems total number messages sent. figuresclear ADOPT outperforms basic algorithm SBB, accordance past experimental evaluation two algorithms (Modi et al., 2005). also clear AFB outperformsADOPT large margin tight (high p2 ) problems. true measures.second set experiments includes ADOPT algorithm three versions AFB algorithm: AFB, AFB-minC - variation AFB includes dynamic ordering values basedminimal cost (of current CPA), AFB-BJ composite backjumping forwardbounding algorithm. AFB-BJ uses value ordering heuristic AFB-minC. selected order show improved performance AFB-BJ indeed arise backjumping feature value ordering heuristic.Figure 9 presents average run-time number non-concurrent computation steps,algorithms: ADOPT, AFB, AFB-minC AFB-BJ, Max-DisCSPs n = 10 agents,domain size = 10, constraint density p1 = 0.7. Asynchronous optimization (ADOPT)much slower standard version AFB. Also clear figure, value orderingheuristic greatly improves AFBs performance. added backjumping improves performancemuch further. RHS figure provides zoom section graphp2 = 0.9 p2 = 0.98. tight problems, ADOPT terminate reasonableamount time terminated manually (and thus missing graph).tightness values higher p2 > 0.9 AFB variants demonstrate phasetransition. phase transition behavior AFB algorithms similar lookahead algorithms centralized Max-CSPs (Larrosa & Meseguer, 1996; Larrosa & Schiex, 2004).explanation phase transition problem difficulty increase exponentiallytightness point. problem becomes over-constrained manycombinations produce highest cost possible combinations fact equal quality,easily pruned intelligent search.82fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPFigure 11: Number Non-Concurrent Constraint Checks (NCCCs) performed several DisCOPsolvers high density Max-DisCSP (p1 = 0.7) linear scale (top) logarithmic scale (bottom)Figure 10 presents total number messages sent algorithms. resultsmeasurement closely match results run-time, measured non-concurrent steps.83fiG ERSHMAN , EISELS , & Z IVANFigure 12: Number Non-Concurrent Constraint Checks (NCCCs) performed several DisCOPsolvers low density MaxDisCSP (p1 = 0.4) logarithmic scalesee ADOPT exponentially rapid growth messages. explanationgrowth simple. Following message agent receives ADOPT, several VALUE messagessent lower priority agents, single COST message sent higher priority agent (Modiet al., 2005). average, least two messages sent every message received, thereforetotal number messages system increases exponentially time.third batch experiments, includes comparison two additional DisCOP solvers DPOP (Petcu & Faltings, 2005a) OptAPO (Mailler & Lesser, 2004). DPOP performslinear number computational steps, step performs exponential number computations. number messages DPOP linear (2n) number agents. Similar ADOPT,DPOP also uses pseudo-tree ordering agents use orderingalgorithms. OptAPO performs partial centralization problem, agents solvepart problem charge of. Therefore, algorithms, evaluation measuresuse number (non-concurrent) computational steps inappropriate, since stepsexponentially time consuming. reason, performance algorithms must evaluated different metric. canonical choice number non-concurrent constraint checks(N CCCs). implementation independent measure includes computations performed withinevery single step (Zivan & Meisels, 2006b, 2006a, 2006). number messages sent alsogood measure case, since DPOP sends exponentially large messages (but linearnumber them) algorithms send exponential amount messageslinear size. Thus present results using N CCCs metric. repeat experimental setup previous experiment randomly generated problems, report totalnumber non-concurrent constraint checks (NCCCs) figure 11. results presentedlogarithmic linear scales.experiment OptAPO, SBB ADOPT terminate reasonable timeharder problem instances therefore partially absent graphs. computation84fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPDPOP composed agent sending message containing subtrees optimal costevery possible combination higher priority constrained agents. given constraint densitysize message agent sends would effected changing constraint tightness. Therefore, computation performed agent unaffected changing constrainttightness (p2 ). DPOPs run time expected remain roughly tightness valuesexperiment. problems low constraint tightness DPOPs performance poorcompared rest algorithms. However, problem tightness increases gapDPOPs run time rest algorithms narrows, p2 = 0.9 DPOP OptAPOSBB roughly run time. p2 = 0.99 DPOP outperforms ADOPT, OptAPO SBB(which terminate). AFB variants outperform DPOP whole range constrainttightness orders magnitude. OptAPO appears perform slightly better SBBAFB clearly outperforms orders magnitude. AFB variations produce phasetransition reported previous experiments, AF B BJ comes best performingalgorithm solving random DisCOPs.results similar experiment low density (p1 = 0.4) Max-DisCSPs presentedfigure 12 (notice logarithmic scale). high density problems, DPOP performance unaffected problem tightness, producing roughly similar results tightness values.low tightness values, OptAPO AFB vastly superior DPOP OptAPO slightly outperforms AFB. tightness increases, OptAPO increases exponentially run-time becomeworst performing algorithm. AFB outperforms DPOP tightness values except p2 = 0.9.7. ConclusionsAsynchronous Forward-Bounding algorithm (AF B) uses asynchronous concurrent constraint propagation top distributed Branch Bound scheme. forward-boundingprotocol AF B maintains local consistency, prevents exploration dead-ends searchspace. run-time network load AFB evaluated asynchronous simulatorrandomly generated ax DisCSP s. results evaluation revealed phase-transitionAF Bs performance, tightness problems increased beyond point.DisCOP solver reported display behavior. similar phase-transition previouslyreported centralized COP solvers, part work Larrosa et. al. (Larrosa & Meseguer,1996; Larrosa & Schiex, 2004). phase-transition observed reported occurCOP solvers, enforce strong enough form local consistency (Larrosa & Meseguer, 1996;Larrosa & Schiex, 2004). therefore attribute behavior AFB concurrent enforcementlocal consistency.AF B extended. One extension include value ordering heuristic. good ordering heuristic minimum-cost heuristic, values lower cost due assignmentshigher priority agents selected first. named version algorithm AFB-minC.experiments, use heuristic substantially improved performance AF B.extension AF B enhanced backjumping mechanism. adding smallamount information bounding messages, agents detect lower boundcurrent partial assignment large (i.e. state inconsistent backtracking required)able check whether backtracking previous agent indeed help reducelower bound resulting partial assignment consistent. Otherwise, search processbacktracks even further. resulting algorithm, AFB-BJ, performs significantly betterversions AFB. comparing AFB-minC AFB-BJ, shown backjumping85fiG ERSHMAN , EISELS , & Z IVANindeed affect performance, improvement standard AF B resultaddition ordering heuristic.AF B algorithm compared two algorithms based branch & boundmechanism distributed form - ADOPT SBB (Yokoo, 2000b; Modi et al., 2005).experimental evaluation clearly demonstrates substantial difference performancealgorithms. Asynchronous distributed optimization (ADOP ) outperforms SBB, AF B outperforms ADOP large margin measures performance. best knowledge evaluation ADOP increasingly tighter problems. experimentalevaluations measured ADOP scalability (by increasing number variables) increasing difficulty (tightness) problems fixed size. exponential growth numbermessages ADOP also apparent Figures 8 10(a). Outperforming AF B twoextended versions AF B, AFB-minC AFB-BJ, AFB-BJ best performance.proposed value ordering heuristic improves performance, adding backjumpingmechanism top that, performance even enhanced.Although AF B ADOP perform concurrent computation nature concurrency useddifferent. Concurrency ADOP achieved performing asynchronous assignments. algorithm agent picks value assignment free changetime. Multiple agents may change assignments concurrently. Asynchronous assignmentsintroduce degree uncertainty regard consistency current partial assignment known agent. fact, scenarios agent may base computationinconsistent partial assignment, combination assignments performed higherpriority agents aware others most-up-to-date assignment.Two algorithms used comparisons AF B - ADOP DP OP - usepseudo-tree ordering agents, allows independent subproblems solved concurrently.good pseudo-tree ordering problematic find (it NP-hard find optimal ordering),sometimes even best ordering good enough, due structure specific problem. Overall, orderings become less useful dealing problems high constraintdensity.order evaluate performance AFB, compared tested twoadditional DisCOP algorithms. DPOP OptAPO use branch bound findoptimal solution. DPOP algorithm delivers possible partial assignments pseudo-treeperforms exponential number constraints checks two passes pseudo-tree (Petcu& Faltings, 2005a). OptAPO partitions DisCOP sub-problems, solved mediatorsub-problem (Mailler & Lesser, 2004). performance algorithms expecteddifferent algorithms use branch & bound search. fact, performance DPOPrandomly generated DisCOPs independent tightness problems. resultsextensive empirical evaluations algorithms random DisCOPs described section 6conclusive. AFB algorithm best performing DisCOP algorithm randomlygenerated DisCOPs measures performance. performs less non-concurrent constraintschecks sends smaller number messages.essence, idea behind AF B summed follows - run sequential assignmentoptimization process concurrently run parallel many additional processes check consistency partial assignment. main search process slow. point time oneagent holds current partial assignment order extend it. Concurrency achieved viaforward bounding, performed concurrently.86fiA SYNCHRONOUS F ORWARD B OUNDING ISTRIBUTED COPresults experimental evaluation show adding concurrent maintenance boundssequential assignment process results efficient optimization algorithm (AF B). algorithm outperforms concurrent algorithms hard instances random DisCOPs.ReferencesAli, S. M., Koenig, S., & Tambe, M. (2005). Preprocessing techniques accelerating DCOPalgorithm ADOPT.. AAMAS, pp. 10411048.Bessiere, C., Maestre, A., Brito, I., & Meseguer, P. (2005). Asynchronous Backtracking withoutadding links: new member ABT Family. Artificial Intelligence, 161:1-2, 724.Brito, I., Meisels, A., Meseguer, P., & Zivan, R. (2008). Distributed Constraint SatisfactionPartially Known Constraints. Constraints, press.Chong, Y., & Hamadi, Y. (2006). Distributed Log-based Reconciliation. Proc. ECAI-06, pp.108113.Collin, Z., Dechter, R., & Katz, S. (1999). Self-Stabilizing Distributed Constraint Satisfaction.Chicago Journal Theoretical Computer Science, 5.Dijkstra, E. W. (1974). Self-stabilizing systems spite distributed control. Commun. ACM,17(11), 643644.Gershman, A., Meisels, A., & Zivan, R. (2007). Asynchronous Forward-Bounding Backjumping. Distributed Constraints Reasonning workshop, IJCAI-2007 Hyderabad, India.Greenstadt, R., Grosz, B., & Smith, M. D. (2007). SSDPOP: improving privacy DCOPsecret sharing. AAMAS 07: Proceedings 6th international joint conferenceAutonomous agents multiagent systems, pp. 13 New York, NY, USA. ACM.Hirayama, K., & Yokoo, M. (1997). Distributed Partial Constraint Satisfaction Problem.. CP,pp. 222236.Larrosa, J., & Meseguer, P. (1996). Phase transition MAX-CSP. Proc. ECAI-96 Budapest.Larrosa, J., & Schiex, T. (2004). Solving Weighted CSP Maintaining Arc Consistency.. ArtificialIntelligence, 159, 126.Lynch, N. A. (1997). Distributed Algorithms. Morgan Kaufmann Series.Mailler, R., & Lesser, V. (2004). Solving Distributed Constraint Optimization Problems UsingCooperative Mediation. Proceedings Third International Joint Conference Autonomous Agents MultiAgent Systems (AAMAS04), pp. 438445. ACM.Meisels, A., & Zivan, R. (2006). Asynchronous Forward-checking Distributed CSPs. Constraints, 16, 132156.Meisels, A., & Zivan, R. (2007). Asynchronous Forward-checking Distributed CSPs. Constraints, 12(1).Meseguer, P., & Jimenez, M. A. (2000). Distributed Forward Checking. Proc. CP-2000 WorkshopDistributed Constraint Satisfaction Singapore.Modi, P. J., Shen, W., Tambe, M., & Yokoo, M. (2005). ADOPT: asynchronous distributed constraints optimization quality guarantees. Artificial Intelligence, 161:1-2, 149180.87fiG ERSHMAN , EISELS , & Z IVANNguyen, T., Sam-Hroud, D., & Faltings, B. (2004). Dynamic Distributed Backjumping. Proc.5th workshop distributed constraints reasoning DCR-04 Toronto.Petcu,A., & Faltings, B. (2004).value ordering heuristic distributed resource allocation.Proc. CSCLP04, Lausanne, Switzerlandhttp://liawww.epfl.ch/Publications/Archive/Petcu2004.pdf.Petcu, A., & Faltings, B. (2005a). Scalable Method Multiagent Constraint Optimization..Proc. IJCAI-05, pp. 266271.Petcu, A., & Faltings, B. (2005b). S-DPOP: Superstabilizing, Fault-containing Multiagent Combinatorial Optimization. Proceedings National Conference Artificial Intelligence,AAAI-05, pp. 449454.Prosser, P. (1993). Hybrid Algorithms Constraint Satisfaction Problem. ComputationalIntelligence, 9, 268299.Prosser, P. (1996). Empirical Study Phase Transitions Binary Constraint Satisfaction Problems. Artificial Intelligence, 81, 81109.Silaghi, M. C., & Yokoo, M. (2006). Nogood based asynchronous distributed optimization(ADOPT-ng).. Proc. AAMAS06, pp. 13891396.Solotorevsky, G., Gudes, E., & Meisels, A. (1996). Modeling Solving Distributed ConstraintSatisfaction Problems (DCSPs). Constraint Processing-96, pp. 5612 New Hamphshire.Yokoo, M. (2000a). Algorithms Distributed Constraint Satisfaction: Review. AutonomousAgents & Multi-Agent Sys., 3, 185207.Yokoo, M. (2000b). Distributed Constraint Satisfaction Problems. Springer Verlag.Yokoo, M., Ishida, T., Durfee, E., & Kuwabara, K. (1992). Distributed Constraint SatisfactionFormalizing Distributed Problem Solving. IEEE Intern. Conf. Distrb. Comp. Sys., pp. 614621.Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2003). analysis application distributedconstraint satisfaction optimization algorithms sensor networks. Proc. 2nd Intern.Joint Conf. Autonomous Agents & Multi-Agent Systems (AAMAS-03), pp. 185192 Melbourne, Australia.Zhang, W., Xing, Z., Wang, G., & Wittenburg, L. (2005). Distributed stochastic search distributed breakout: properties, comparishon applications constraints optimization problems sensor networks. Artificial Intelligence, 161:1-2, 5588.Zivan, R., & Meisels, A. (2006). Dynamic Ordering Asynchronous Backtracking DisCSPs.Constraints, 11, 179197.Zivan, R., & Meisels, A. (2007). Conflict directed Backjumping MaxCSPs. IJCAI-2007Hyderabad, India.Zivan, R., & Meisels, A. (2006a). Concurrent search distributed CSPs.. Artif. Intell., 170(4-5),440461.Zivan, R., & Meisels, A. (2006b). Message delay DisCSP search algorithms. Annals Mathematics Artificial Intelligence, 46(4), 415439.88fiJournal Artificial Intelligence Research 34 (2009) 165208Submitted 07/08; published 03/09Behavior Bounding:Efficient Method High-Level Behavior ComparisonScott Wallacewallaces@vancouver.wsu.eduWashington State University Vancouver14204 NE Salmon Creek AvenueVancouver, WA 98686Abstractpaper, explore methods comparing agent behavior human behaviorassist validation. exploration begins considering simple method behaviorcomparison. Motivated shortcomings initial approach, introduce behaviorbounding, automated model-based approach comparing behavior inspired,part, Mitchells Version Spaces. show behavior bounding usedcompactly represent human agent behavior. argue relatively low amountshuman effort required build, maintain, use data structures underliebehavior bounding, provide theoretical basis arguments using notionsPAC Learnability. Next, show empirical results indicating approach effectiveidentifying differences certain types behaviors performs wellcompared initial benchmark methods. Finally, demonstrate behaviorbounding produce information allows developers identify fix problemsagents behavior much efficiently standard debugging techniques.1. Introductionpast decades, intelligent systems asked perform increasinglycomplex mission critical tasks domains medical diagnosis (Shortliffe, 1987)simulated aerial combat (Jones et al., 1999). Despite number successes,complex agents yet become fully integrated mainstream software. Muchimpasse may attributable fact developing agents often extremelytime consuming expensive.Development requires three high-level steps: specification, implementation, validation. difficulties associated step determined properties agenttask intended perform. paper, focus class agents terminteractive human-level agents. agents typified training simulationsagents participate mixed human-computer teams accomplish particular training objective (e.g., Swartout et al., 2001; Traum et al., 2003; Jones et al., 1999; Rickel et al., 2002).domains, agent plays role normally fulfilled expert human mayavailable training episodes. agents distinguished three properties.First, agents performance judged based ability behave human expertwould behave similar situation. design criterion often particularly importanttraining simulations agents operate part mixed human-computer team playing role normally occupied another person. Second, like humans themselves,interactive human-level agents must interact external, typically complex,c2009AI Access Foundation. rights reserved.fiWallaceenvironment order perform many tasks. Finally, unlike situation faceddesign problems, complete specifications correct behavior often impracticableimpossible obtain. This, unfortunately, well documented property manysystems built model human domain experts (e.g., Tsai, Vishnuvajjala, & Zhang, 1999;Weitzel & Kerschberg, 1989; Lee & OKeefe, 1994; Menzies, 1999). interactive humanlevel agents, specification task performed typically comes directlyhuman domain expert, result, comparing agents behaviorgold standard way determine design criteria met.good example interactive human-level agent TacAir-Soar (Jones et al., 1999).TacAir-Soar flies virtual military planes part simulated training exercise. Teammatesmay TacAir-Soar agents human counterparts. agents intendedused enough human participants complex exercise,agents must model expert-level behavior closely achieve trainingresults fully human team used. Thus, acceptable agents simplyachieve correct final states (e.g., shooting enemy planes). Instead,agent must pursue trajectory state/action space emulates humanstrajectory (behavior). complex domains, meeting requirement challengingexpert may perform task differently different occasions.many human-level agents, development steps specification implementationoften woven together knowledge acquisitionthe processdeveloper interviews human expert identify encode parameters correctbehavior. Often, process involves exposing rules procedures governexpert decomposes task series goals, subgoals primitive actions (taskdecomposition). rules procedures elicited, developer encodeknowledge form usable underlying agent architecture.traditional approach knowledge acquisition rarely free errors. processtask decomposition works well enough identify relationships task goalssubgoals considered useful means acquiring encoding taskknowledge (e.g., Lee & OKeefe, 1994; Yen & Lee, 1993; Yost, 1996). However, finerlevel granularity, knowledge acquisition highly prone errors. part, duefact human participants stretched beyond areas expertise.domain expert, means communicating tasks performed insteadsimply performing them. engineer, means understanding problem space wellenough determine translate experts descriptions instructionsinterpreted computer applied appropriate situations. Althoughalternative methods knowledge acquisition proposed tested within limitedsetting (e.g., van Lent & Laird, 1999), part incorporatedwidespread use. result, developing complex intelligent agents remains timeconsuming difficult process.distinguishing characteristic work presented previous stated assumption correct specifications difficult impossible obtain. contrastmajority recent agent validation approaches using model checking temporal logic(e.g., Bordini, Fisher, Visser, & Wooldridge, 2004, 2006; Fisher, 2005). systems seekidentify implementation errors proving whether particular implementation upholdsstrict logical constraints (specifications). underlying assumption model checking166fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonerrors originate implementationnot specification. assumptionviolated, system must tested gold standard behavior ensure correctness specification cannot fully trusted. sense, testing methods proposedpaper viewed complementary approach achieving objective:correctly functioning agent.work distinguished typical machine learning approachesinterested creating artifacts help person validate existing agentsbehaviorwe necessarily need learn produce behavior. approachintended applications current learning systems unable perform welluntrusted end users. revisit distinction traditional machinelearning approaches Sections 4 10.1.1 Manual Semi-Automated Behavior Comparisonstandard approach test-based validation requires knowledge developer domain expert monitor agents behavior large number scenarios(Kirani, Zualkernan, & Tsai, 1994; Tsai et al., 1999). Although standard, clearapproach number significant drawbacks. Principal amongparticipation two humans required assess agents performance test.time validation takes place, however, gross inadequacies agents behaviorcorrected. Thus, although likely errors still exist,manifestations probably relatively far between. means muchtime spent validation useful identifying problems agents behavior.improve upon standard validation approach, semi-automated methodmakes efficient use domain expert developers time would highlydesirable could substantially decrease cost testing. paper, exploreissue meaningfully compare two actors trajectories state/action/goalspace (i.e., behavior) given set examples.Comparison, paper, simply means identifying actors trajectoriessimilar different one another. Thus, interested comparison goes wellbeyond simply indicating two actors achieved final states. Rather, takeaccount actions performed motivations behind actions. coulddone simply comparing observed trajectories directly, inferring general modelactors trajectories comparing models. either case, key challengeinterested producing artifacts easy human interpretcould used assist tasks validation.potential uses behavior comparison extend well beyond agent validationmany tasks humans may want know two actors perform tasks differently. Scoring modified (non-speech based) Turing test, example, requires humansperform comparison two actors behavior. Similarly, consider human supervisorexamining students performance lesson intelligent tutoring training system. examination review could facilitated tutoring system capablecomparing students behavior differed internal gold standard couldrelay information instructor manner easy interpret.applications, basic process comparing behavior artifacts produced167fiWallaceremains constant. differences stem source behavior (e.g., humanmachine, expert novice) results used (to identify programming errors,score test, evaluate students performance). simplicity cohesiveness,paper focus using behavior comparisons aid agent validation problem,discussion results also applied tasks well.1.2 Outlineremainder paper, examine two methods comparing interactive goaloriented behavior exhibited human-level agents human counterparts. begin describing primitive representation behavior uponbuild comparison methods. Next, describe simple sequence-based comparison, deficiencies method lead us examine sophisticated model-basedapproaches.main contributions paper fourfold. First, Section 4, identify requirements useful comparison system. Then, beginning Section 5, describe novelmodel-based approach comparing two actors behavior. approach, called behaviorbounding, uses hierarchical behavior representation built observationshuman computer-agent behavior. Third, demonstrate behavior bounding meetsrequirements useful behavior comparison system support claimstheoretical empirical evidence. Finally, show information behaviorboundings comparison significantly aid process identifying problems agentsbehavior, thus speeding agent validation significant factor.2. Behavior Tracesprimitive, behavior represented trajectory though state/action/goalspace refer behavior trace. behavior trace sequence tuplesB = ((s, G, a)0 , (s, G, a)1 , . . . , (s, G, A)n ) tuple (s, G, a)i indicates environmental state (s), goals pursued actor (G), action performed(a) ith sampling point. actors goals directly observable mustexplicitly provided actor performing task. Goals important purposesinterested actors do, also interestedmotivation behind actions.project, make three main assumptions nature actors goals.First, assume actors goals part actors internal state. goalssimply given task description. Although task certainly informs goalselection, goals arise interactions agents internal desiresenvironmental situations encountered task. Second, assume actorsgoals change environment changes task moves toward completion.means goals used structure agents task subtasks appropriategoals subgoals generally differ distinct phases task. Third, assumeactors choice goals (and actions) based upon static set knowledge.is, agent learn.Note defined it, behavior trace give complete informationagents internal state. Indeed, actor likely perform potentially large168fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonamount reasoning order select G a. example, actor may performexpected utility calculation look-ahead search. However, process information explicitly represented G completely absent behaviortrace. Although provides us limited amount informationperform behavior comparison, also ensures possible collect behavioreither human computer agent actors.Behavior capture process collecting information actor build behavior trace. noted above, limiting information behavior trace critical ensurebehavior capture possible. state action portion behavior tracecaptured simply observing actor perform specified task. Depending whetheractor human computer agent, way actor records goalschange task vary. computer agent, (G, s) pairs simply written file task performance. human expert, goal annotations madeverbally task performance immediately following task completion suggestedvan Lent Laird (1999).3. Sequence-Based Comparisonsimple approach comparing actors behavior performed followingsteps:Acquire set behavior traces human expert agent specified task.sets, H A, represent human experts agents behavior respectivelynumber different trials.Extract relevant symbols behavior traces. information gatheredobservation may irrelevant detecting errors. example, human expertsbehavior never changes given different values state symbol z, z likelyirrelevant detecting errors. step, salient symbols sets Hused create two new sets sequences H .Compare sequence , contents H . Compute minimal numberedit operations (insert, delete, modify) would required transform h,h sequence H initially similar a. edit operationindicates potential error.Report deviations (after removing redundancies) humans agentsbehavior. report summarizes potential errors.simple approach performs detailed analysis behavior simply checkingagent expert reach final (goal) state. way, agentsexternally observable behavior well aspects internal reasoning processinspected ensure consistency human experts. addition, methodologyability identify large number possible errors accesssalient properties behavior trace. However, simple approach also suffersnumber potentially serious flaws.169fiWallace1. actors behavior represented set sequences. complexitydomain increases likely two effects noticed: average lengthsequences H grow (i.e., complex tasks take longer solve),sequences composed larger number symbols (e.g., statespace become richer). number distinct sequences lengthsP maxlmin lmax composed symbols grows ll=lsl . Thus, enumeratingminspace likely infeasible. Moreover, interactive human-level agentstypically solve problems number different ways, typically operatewithin complex domains, likely sequential approach describedsection particularly susceptible effect.2. sequence based comparison fails make assumptions actorsbehavior may constrained. is, sequential behavior representation providesmethod expressing priori knowledge symbols placed relativeone another within particular sequence. Instead, representation completelyunconstrained; sequences length l constructed making l independentsymbol selections. Although makes possible use simple approachvariety behavior (even behavior completely unstructured), also makesimpossible leverage regularities might exist large classes goal directedtasks (such fact unlocking door must always accomplisheddoor opened).4. Model Based Approachesimprove upon simple sequence-based method error detection, propose comparison method leverages abstract representation actors behavior. callmethods model-based compare instances actors behavior directly (as simple sequential approach would). Instead, methods compareabstract representations actors behavior (models), identify similarities differences underlying behavior. Central approach considerationsinfluenced models design. choice models guided following designrequirements:Low Complexity behavior model must significantly less complex representations define agent itself. requirement violated, two problemsmay result. First, constructing model (either hand, automaticallyobservational framework) likely difficult constructing agentsknowledge base. Second, understanding model behavior representslikely easier examining agents internal representation.comparison used validate agents underlying knowledge base,clearly undesirable results recursive validation problem. However,achieve low complexity requirement using model represents behaviorrelatively high level abstraction compared agents internal implementation.Low Human Effort human effort required build behavior model must remainlow. argued one main uses behavior comparison would170fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonreduce cost validating human-level agent. low human effort requirementviolated, original validation costs (due, example, time requirementsexamining numerous test scenarios) simply replaced new costs,resulting net benefit. achieve low cost requirement usingautomated system build behavior representations series observationslittle human supervision.Compatibility must possible build use behavior model humanactors software agents. discussed previous sections, behavior comparisonnumber potential applications, many rely able examinehuman software agent behavior. Thus, contents model must limiteddata collected either types participants. Section 2,described behavior traces could collected human actorscomputer agents. result, achieve requirement using modelbuilt behavior traces.Efficiency computational costs associated building using model mustbecome infeasible complexity domain increases. Although primarymotivation automated behavior comparison replace human effort computational effort, must careful construct model waybecome impossible use. achieve requirement using abstractmodel actors behavior grow directly function numberbehaviors encapsulates.Efficacy good model must effective identifying similarities differencestwo actors behavior. perhaps basic requirement presented.However, desire effective model captures subtleties actorsbehavior likely direct conflict previously presented requirements.result, good model must balance need represent actors behavior preciselythus able distinguish similarities differences behavioroverall needs. Unfortunately, little priori assuranceparticular model effective. requirement must addressedtheoretical empirical testing model implemented.Note unlike traditional machine learning tasks, necessarily needproduce model used perform task. is, need learnpolicy set plan operators. described above, trade-offmodels efficacy complexity. one end spectrum executable modelstask. Here, efficacy maximized, model would necessarily complexwould likely difficult human use validate behaviorlooking directly hand coded rules procedures. models certainly valuablegoal learn behavior directly set examples, variety approachespursued machine learning literature; closely related discussedlater Section 10. approach, however, attempts target different pointefficacy/complexity spectrum model cannot perfectly describe many complextasks, result model examined much quickly agents171fiWallaceinternal implementation. Thus, standard approach machine learning literatureempirically evaluate learned model comparing optimal modelhand-coded model, interested something else: namely, whether modelmaintain efficacy complex environments whether improve persons abilityquickly uncover fix problems existing agents. Sections 8.2 9 examineissues.4.1 Model-Based DiagnosisPrior work model-based diagnosis (e.g., Anrig & Kohlas, 2002; Lucas, 1998) examineddetect errors given model correct behavior. general, however, modelssystems relatively complicated intended identify problems mechanicalsolid state devices opposed software agents. CLIPS-R (Murphy & Pazzani,1994) system designed expressly ensure correct software agent behavior, bearssimilarity approach.CLIPS-R, behavior model consists set tuples (S , CSf , CE ),specifies initial world state (S ), set constraints describing acceptable final worldstates (CSf ), execution constraints (CE ) must met task performed. Final state constraints indicate facts environment agent musteither true false task complete (e.g., (not (gas-empty car))). Notefinal state constraints define behavior model classical planning sense;description sequence events lead final state. informationprovided execution constraints (C E ), represented finite state machinedescribing acceptable orderings agents observable actions. Execution constraintsused describe relationships actions. example, constraint mightspecify action unlock-door always proceed open-door. Superficially,requirements CLIPS-R approach seem relatively simple meet. However, twoserious problems exist.First, specifying exact set execution constraints required correct operationsimilar writing conditions rules. execution constraints govern behaviorfine level granularity, likely similarly difficult designvalidate agents rule base (a recursive validation problem). case,requirements low complexity low human effort would violated.hand, constrain behavior higher level granularity, task level,efficacy requirement called question: powerful enough workcomplex environments human-level agents?second serious problem arises CLIPS-R approach provides little guidancedetermine appropriate constraints, especially appropriate execution constraints.benefits approach hinge completely developers ability enumerateadequate appropriate execution constraints particular task. Yet developerenumerate constraints required judge whether agents behavior correct,included agents knowledge base directly?noted although problems mentioned may encounteredCLIPS-R used particular agent, likely become obvious(and problematic) complexity agent domain increases. already noted,172fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonexactly types agents environments interest us, concernsraised particularly salient work interactive human-level agents.contrast, original CLIPS-R work (Murphy & Pazzani, 1994) examines systemsability correctly identify flaws two simple agents whose knowledge bases containnine fifteen rules respectively. agents examined CLIPS-R work performedtasks akin classification highly interactive tasksinterest us.5. Behavior Boundingimprovement CLIPS-R simple method presented Section 3,approach behavior comparison, called behavior bounding, automatically efficientlybuilds concise high-level models human experts agents behavior examining behavior traces meet first three requirements described Section 4.human experts behavior model used identify boundaries acceptable behaviormanner reminiscent Mitchells Version Spaces (Mitchell, 1982). Potential errorsreported comparing model agent behavior boundaries. Behavior bounding used identify programming errors agents knowledge base alsoidentify discrepancies experts explanation task performedexpert actually performs task. contrast high-level modelbuilt similarly agents knowledge base (as, presumably, CLIPS-R) using indirectinformation interviews determine constraints met taskperformance.5.1 Hierarchical ModelBehavior bounding leverages assumption although knowledge acquisition highlyprone errors respect details task performed, high-levelinformation (specifically general relationships goals, sub-goals primitive actions) much reliable. Behavior boundings hierarchical behavior representationinspired hierarchical models used And/Or trees, HTN planning (Erol, Hendler,& Nau, 1994) GOMS modeling (John & Kieras, 1996) encode variety waysparticular tasks accomplished. Conceptually, behavior bounding encodesthree relationships. First, identifies decomposition relationships goals, sub-goalsprimitive actions. Second, identifies ordering relationships nodeshierarchy. Finally, behavior bounding identifies goals actions instantiatedsaving generalized parameters (i.e., features internal world state directlyassociated goals actions begin pursued).hierarchical behavior representation (HBR) used approach And/Ortree binary temporal constraints representing relationships actorsgoals actions. representation, internal nodes correspond goals leavescorrespond primitive actions. nodes children indicate set sub-goals primitiveactions relevant accomplishing specified goal.Figure 1 illustrates small subsection hierarchical behavior representation. Goalnodes drawn ovals primitive actions rectangles. constraintsrepresented standard fashion arc across child nodes; temporal constraints173fiWallaceFly-MissionAchieve-WaypointSetAltitudeComputeHeadingReturn-to-BaseSetHeadingContactTowerSetVHFSetUHFContactTeammatesEnsureAdequateFuelSendMessageFigure 1: Hierarchical Behavior Representationrepresented directed arcs sibling nodes. Note total ordersiblings possible required representation. semantics nodesrepresentation necessarily indicate one subgoal (or action) requiredaccomplish given goal. Rather, node indicates simply complete setsubgoals (or actions) always required accomplish task. Thus, semanticsnodes preclude use temporal relations; merely state ordermultiple goals/actions occur indeed one pursued.HBR viewed simple constraint model based observationsactors behavior. encodes relationships Fisher uses temporallogic models agents (Fisher, 2005): namely step rules (what goals/actions expect next);sometimes rules (what goals/actions expect future). result, HBRcould used source types temporal logic constraints required modelchecking (as case human-level agents) expert capable providinglogical constraints directly.5.2 Building HBR Behavior Traces: OverviewSection 6 present detailed explanation HBR acquired behaviortraces along underlying algorithm. Here, present conceptual overviewprocess describing partial behavior trace left-hand side Figure 2used build HBR right side figure.Initially, begin empty HBR. behavior trace (Figure 2, left hand side)processed single pass, reading beginning end. new goals actions174fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonencountered, nodes added hierarchical representation. hierarchy goalsactor currently pursuing indicated behavior trace lines levelindentation. example, goal stack generated incrementally beginningselection top-level goal decomposed lower-level goalbegin decomposed series primitive actions. goal considered completedlonger member actors goal stack. example, Figure 2, goalAchieve-Waypoint completed actor commits performing new goallevel abstraction (i.e., goal Return-to-Base selected). behaviortrace processed, requirements goal completion tracked including subgoalsnecessary accomplish current goal ordering well parametersgoal respective subgoals. requirements represented descendantshierarchy constraints them. Note action subgoalencountered multiple contexts (as descendant two distinct parents) HBRcreate node context. appropriate parameters associatedgoal/action interaction sibling goals/actions likely dependhigher-level context.generation process results HBR right-hand side Figure 2 (noteparameters associated goal action, listed behavior tracesegment, displayed improve clarity figure). goal nodes (ovals)children type And. addition, siblings totally ordered indicatedtemporal constraints (directed arcs siblings). highly constrained natureHBR (And goals total ordering) typical representations built singlebehavior trace. behavior traces used generate structure, HBRgeneralized cover input observations.structural topological level, generalization occurs two ways. firstconstraint turned constraint. example, Achieve-Waypointgoal every time observed, completed pursuingthree subgoals: Set-Altitude; Compute-Heading; Set-Heading. secondbehavior trace indicated Achieve-Waypoint successfully completed performingsubgoal Set-Heading, Achieve-Waypoint would become nodecorrespondingly indicate require subgoals accomplished.Similarly, generalization binary temporal constraints occurs needed represent observed orderings goals actions. Returning example Figure 2,Achieve-Waypoint observed occur once. Thus, representation HBRindicates total order three subgoals. Achieve-Waypoint performedsecond time new sequence three subgoals, ordering constraintswithin HBR would change. example, Achieve-Waypoint performedpursing: Compute-Heading; Set-Altitude; Set-Heading, order, temporalconstraint Set-Altitude Compute-Heading would removed. process building HBR underlying algorithm discussed detailSection 6.Generalization also occurs parameters associated goal action, effectively expanding set parameters associated node obser-175fiWallaceSet goal: Fly-MissionSet goal parameter: (altitude 30000)Set goal parameter: (patrol-speed 800)Set goal: Achieve-WaypointSet goal parameter: (waypoint AZ-12)Set goal parameter: (threat-level low)Set goal parameter: (ETA 10 minutes)Action: (set-altitude 30000)Action: (compute-heading AZ-12)Action: (set-heading)Set goal: Return-to-Base...Fly-MissionAchieve-WaypointSetAltitudeComputeHeadingReturn-to-BaseSetHeadingFigure 2: Constructing hierarchical behavior representation behavior tracevations made1 . Consider Figure 2 parameter associated Set-Altitude30000. later see Set-Altitude performed parameter 20000, HBRcontain generalization two observations, namely Set-Altitudeparameters range 2000030000. parameter associated goal action generalized cover observations behavior traces. numerical parameters,generalization performed expanding acceptable range include new value.symbolic parameters, generalization performed adding new symbol setacceptable values.5.3 Representational SimplicityHBR discussed clearly much less complex representation behavioragents underlying knowledge base. Indeed, hierarchical structure ensuresconstraints cannot formed arbitrary goals actions. property also meansHBR may less complex even model used CLIPS-R, allowsarbitrary finite state machine describe acceptable sequences external actions.Behavior bounding ensures high-level model behavior abstracting away internaldata-structures agent may use perform task cannot representedhierarchy. possible store arbitrarily complex information HBR,unlikely happen practice. Consider, example, depth first search usesopen list discriminate alternative behaviors. final result search(a goal action) naturally captured HBR, forcing HBR capture detailssearch impractical requires pushing information captured open listgoal hierarchy.specifically, consider agent using search select two potential actions: Set-Altitude; Set-Heading. First, note search process wouldrepresented behavior boundings HBR agent explicitly made searchinggoal. However, even Search explicit goal, information open-list (statesstill need tested) would available HBR made ex1. purposes paper, parameter generalization less interesting structural generalization.include brief discussion mainly completeness.176fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonplicit parameter goal. Even formulation, however, would leave large amountinformation search process unrepresented HBR. Specifically,search encapsulated single goal without substructure, would impossibledetermine manner various search nodes visited. order representinformation, would need push relevant data structures (in caseopen-list) goal hierarchy itself. Thus, would need create explicit goals(state, open-list) pair. approach pushing arbitrary information goalhierarchy clearly undesirable unlikely occur frequently well designedagent. Thus, reasonably certain behavior boundings HBR alwayshigh-level, abstract, representation agents (or actors) behavior.representational limitations HBR leads us ask: agents behaviorrepresented using simple structure, programmedrepresentation begin with? hypothesis representation sufficientcompletely capture agents behavior, sufficient generate behavior.human-level agents rely intermediate data-structures availableenvironment structure goal hierarchy (for example agents uselook-ahead select next goal action, perform expected utility calculation).Rather, hypothesis representation provided behavior bounding sufficientidentify large class errors agent behavior without sacrificing efficiency. Moreover,hypothesize behavior bounding help identify potential problem spotsagents knowledge (e.g., ordering actions specific goal) even exact errorcannot identified.5.4 Representational Assumptionscontrast behavior representation used simple comparison describedSection 3, HBR makes three strong assumptions organization actorsknowledge effects organization actors behavior. assumptionsincrease efficiency efficacy error detection certain types human-level agents.first assumption used behavior bounding actors goals organizedhierarchically, abstract goals located toward top tree. Hierarchical taskstructure exploited number agents agent architectures, thus assumptionparticularly limiting. also assume point problem solvingprocess actor pursues set goals belonging different levels hierarchy.set, referred goal stack, corresponds path hierarchy beginningtop node descending concrete sub-goal currently pursuedactor. goal stack assumption implies concurrent goals (two goalssimultaneously pursued depth hierarchy) cannot modeled explicitlyHBR. One way circumvent limitation implement concurrent goalsnested goals. test architecture (Soar) directly support concurrentgoals, approach typically taken achieve behavior. seeSection 8.2.5, approach allow us create use HBR may also resultrepresentational problems. hierarchical goal assumptions described provideimportant benefit constraining acceptable orderings goal actions agentmay pursue. property analyzed detail Section 8.1.177fiWallacesecond assumption leveraged behavior bounding relates independencegoals. HBR, temporal constraints formed sibling nodes,And/Or classification determines nodes children must performedparticular task. makes easy constrain way particular goal achieved,difficult represent constraints arbitrary parts hierarchy. Althoughmay cause problems agent implementations, property significant benefits.importantly, decreases number observations required buildmodel. Consider task requires completing two goals, could fulfilledfour distinct ways. behavior represented ordered pair (a 1 , a2 ) indicatingaction taken fulfill goals one two respectively. sequential representation makesassumptions goal independence (such one described Section 3) wouldrequire sixteen distinct observations cover acceptable behavior space (onedistinct (a1 , a2 ) pair). contrast, behavior bounding would require four observationslong set observations included every possible value 1 every possiblevalue a2 2 . impact efficiency significant direct result leveragingassumption goals likely add regular structure actors behavior.Finally, recall Section 5.1 third assumption upon behavior boundingbuilt. knowledge acquisition relatively reliable correctly identifyinggeneral goal/subgoal relationships expert uses perform target task even thoughprocess knowledge acquisition prone errors attempting identifyrules necessary encode task. assumption provides justificationusing behavior representation focuses relationships goals, subgoalsprimitive actions purposefully neglecting much internal informationactor may use select behavior.net effect building HBR based assumptions model meetscriteria set forth Section 4. model likely much conciseagents implementation (low complexity)we learning complete plan operators,instead generalization actors trajectories goal/action space. addition,HBR generated automatically examining actors behavior traces thusmeeting second requirement (low human effort). behavior tracescaptured either human computer agent actors, HBR meets third requirement(compatibility). following sections, present method behavior boundinguses HBR perform comparisons. addition, examine remaining tworequirements ideal model-based approach (efficiency efficacy) detail.6. Learnabilitysection, examine two aspects behavior boundings hierarchical representation:effort required create maintain it, ability represent behavior efficiently.requirements addressed overall learnability representation.is, representation learned observations (as suggested),requires human effort initiate learning process. learning procedureefficient, data structures growth limited, say hierarchy2. Thus, a1 , a2 {1, 2, 3, 4} pairs (1, 1), (2, 2), (3, 3), (4, 4), would sufficient coveracceptable behavior space behavior bounding sequential representation.178fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonrepresents behavior efficiently thus meets fourth requirement (efficiency) outlinedSection 4.Create-Hierarchy(B, H)1 W empty tree2 lastStk nil // previous goal/action stack3 (s, G, a) B45= 0 length[lastStk]67Goal-Completed(lastStk[i])8hg Find-Node(H, lastStk[i])9hg = nil1011Add-SubTree(H, Parent(lastStk[i]), lastStk[i])12else13Generalize(H, hg , W, lastStk[i])14gi [G, a]1516pg Parent(gi )17wg Find-Node(W, pg , gi )18wg = nil1920wg Add-Node(W, pg , gi )21Constrain-Children(W, pg )22else23Out-of-Order(W, pg , wg )24Update-Constraints(W, pg , wg )25Generalize(wg , gi )26lastStk [G, a]27 return HFigure 3: Create-Hierarchy algorithmSection 5.2 presented overview process behind building HBRbehavior trace. Create-Hierarchy algorithm (Figure 3) specifies process explicitly. algorithm takes two arguments input: B, behavior trace; H, HBRrepresenting previously observed behavior (or nil behavior yet observed).Create-Hierarchy returns new HBR covering behavior H new observation B. Thus, calling procedure single behavior trace B H nil generateshierarchical representation single behavior trace examining way goalsdecompose subgoals primitive actions task performance. Iteratively callingCreate-Hierarchy different behavior traces augment generalize Hcovers example traces. algorithm executed O(lN 2 ) time l179fiWallace(maximum) length behavior trace N number nodes goalhierarchy.Classifying sample complexity hierarchical representation straightforward.Hausslers equation (Haussler, 1988; Mitchell, 1997), know numbertraining examples required consistent learner learn target concept (with probability (1 ) error bound ) hypothesis space (H) where:11ln(|H|) + ln(1)HBR viewed ordered tuple P = (p 1 , p2 , . . . , p|N | ) pituple containing type node (either Or) well listL = (l1 , l2 , . . . , l|N | ) la = 1 iff gi ordered la . Note since orderingconstraints occur siblings, length list L would need2length |N | degenerate case. size hypothesis space bounded 2 |N |+|N |worst case, based shape hierarchy may much smaller. Substituting size hypothesis space back Equation 1 find indeed growpolynomially:11(|N |2 + |N |) ln(2) + ln(2)indicates required sample size polynomial respect numbergoals hierarchy (|N |). This, together fact time requiredincorporate new behavior trace learned HBR also polynomial |N |, showsrepresentation PAC-Learnable. means HBR efficiently representsaggregate behavior well individual instance behavior, thus meeting fourthrequirement.7. Identifying Errorsgeneral, view behavior comparison method algorithm dividesspace possible behaviors two regions: behaviors likely consistentexpert, behaviors likely inconsistent expert. simplecomparison method described Section 3 enumerating consistent behaviors.model used behavior bounding, however, allows us divide space possiblebehaviors efficiently refined regions without enumerating contents.Intuitively, idea organize HBRs lattice; individual points latticeused define boundaries different quality behaviors manner reminiscentMitchells Version Spaces (Mitchell, 1982).Recall hierarchical behavior representation hierarchy nodes corresponding goals, subgoals primitive actions. Nodes linked hierarchically basedgoal/subgoal decomposition relationships observed behavior traces. HBRviewed consisting two parts:1. basic structure hierarchy nodes labeled namesgoals, subgoals actions connected parent/child relationshipsmanner corresponds observed behavior.180fiBehavior Bounding: Efficient Method High-Level Behavior Comparison2. set constraints imposed upon nodes basic structure. Constraints include And/Or typing nodes, binary temporal constraints, constraints allowable parameter space goal, subgoal, action.constraints formed specific general learning algorithm,generalization process creates lattice HBRs related following manner: 1)share basic structure; 2) differ specificity constraints.Thus, hierarchical behavior representation allows us define ordering specificgeneral space behavior hierarchies starting maximally constrainedhierarchy (at top) iteratively removing constraints none remain.Behavior bounding leverages ordering hierarchies efficiently partitionbehavior space different regions. process begins using traces expert behavior (the specification) create corresponding HBR. created, identifynode occupies ordered space (call node Figure 4). node (the upperboundary node) allows us easily determine agents behavior likely correct.definition, correct behavior must consistent expert behavior. agent whosebehavior representation specialization experts (i.e., lies generalization lattice) exhibits behavior consistent experts therefore likelycorrect. sequential approach behavior comparison, upper boundarynode allows us partition behavior space two regions: correct, incorrect.second partition formed node representing completely unconstrainedversion experts goal hierarchy. node illustrated bottom Figure 4 (labeled B). contains basic structure (goal/subgoal relationships) may constituteacceptable agent behavior result could used identify behavior representationsknown incorrect (because agents behavior hierarchy topologically inconsistent experts behavior hierarchy). representations would goaldecomposition structure inconsistent (i.e., contained different parent/child relationships than) lower boundary (nodes right side Figure 4 labeled neitherless specific A).Together, upper lower boundaries create three regions behavior space.Nodes specialization experts behavior (above upper boundary node)correspond behavior likely correct. Nodes specializationunconstrained version experts goal hierarchy (the lower boundary node) correspond behaviors known incorrect. region upperlower boundary nodes corresponds behavior likely incorrect perhapslower probability region lower boundary node 3 .Mitchell (1997) defines version space subset hypotheses (from hypothesisspace) consistent given set training examples. ordering hypothesisspace specific general, Mitchells learning algorithm (Mitchell, 1982, 1997) identifiesversion space without enumerating contents. Instead, version space representedconcepts (hypotheses ordered hypothesis space) form upper lower3. assume easier ensure HBR reflects correct agent topologyensure constraints upper boundary nodes HBR adequately generalized. practice,degree assumption holds depend properties agent HBRcorresponding lower boundary node formed (see Section 11 alternative method).181fiWallaceboundaries. S-Set G-Set specify specific hypothesesgeneral hypotheses version space respectively. training examplesobtained, S-Set becomes progressively general G-Set becomes increasingly specific converge correct hypothesis.Mitchells S-Set G-Set used delimit set consistent hypotheseswithout enumerating them, upper lower boundary nodes approach servesimilar purpose. upper boundary node (UBN) plays similar role S-Set.However, S-Set used incrementally converge correct hypothesis (andbecomes increasingly general), upper boundary node viewed correcthypothesis. Thus UBNs value delimiting portion lattice consistentspecification. lower boundary node, hand, plays similar roleG-Set. But, G-Set identifies hypotheses inconsistent training data,lower boundary node simply identifies HBRs latticedistinct topological structure.boundaries established, quickly determine whetherarbitrary HBR specialization either boundary node. analysis, clearlydone polynomial time respect number distinct goals, subgoals,actions, allows us quickly determine degree behaviors two actors are,not, consistent one another. inconsistencies uncovered process formbasis behavior boundings error report displayed either standard textformat visually using graphical user interface. remainder paper,use terminology appropriate comparing two actors playing roles either expertnovice. actor referred expert represents correct behavior specification.actor referred novice expect exhibit partially incorrect behavior.described Section 1, roles could played either software agents humansdepending situation hand.8. Error Identification Efficacypoint, provided good deal support behavior boundingHBR presenting analytical arguments behalf. final criteria mustaddressed efficacy respect identifying errors. this, examine twocomponents HBR. First, provide analytic results indicating effectivenessunconstrained hierarchical representation (the lower boundary) identifying behaviorknown incorrect. Second, provide empirical evidence behaviorbounding whole effective distinguishing correct incorrect behavior.8.1 Lower Boundary Nodefirst glance, obvious much behavior classified lower boundarynode. Without And/Or constraints binary temporal constraints, lower boundarynode specifies subgoals belong goals. specification,lower boundary node constrains set allowable goal/sub-goal/action sequences.effectiveness simple constraint mechanism quite surprising.Consider unconstrained behavior representation branching factor b depthd. Without loss generality, assume nodes uniquely labeled. simplicity,182fiBehavior Bounding: Efficient Method High-Level Behavior ComparisonSpecificG1SG1,2SG1,1A1A2Behavior RepresentationsInconsistent BA3G1SG1,1A1SG1,2A2A3G1G1A1SG1,2SG1,1A3A5A7BA1A2A3GeneralFigure 4: Imposing Order Behavior Space1e+06B=2B=4B=6Maximum Sequences (log(log(y))1000001000010001001010.123456Depth Hierarchy78Figure 5: Filtering Capability Lower Boundary Node183fiWallacealso assume level hierarchy, actor completes current goalstarting next goal. Then, could define actors behavior sequence symbolschosen lowest level unconstrained hierarchy. behavior sequencesPjlength bd , symbol repeated, b! |s = d1j=0 b possible sequencesconsistent goal decomposition unconstrained hierarchy. contrast,bd ! sequences symbols may placed without necessarily conformingunconstrained hierarchy. hierarchical structures reasonable size, makeslower boundary node effective filtering exponential number potential behaviorsequences. example, small hierarchical structure depth 4 branching factor2, 1 approximately 6.4 108 possible sequences length 16 consistentgoal decomposition specified unconstrained hierarchy. Figure 5 illustratesfiltering capability lower boundary node. x-axis figure indicatesdepth hierarchy lines plotted branching factors 2,4, 6. y-axisindicates ratio possible sequences accepted goal hierarchy number totalpossible sequences unconstrained symbol set size; note y-axisdoubly-logarithmic (log log(y) plotted).Although lower boundary node extremely simple data structure, information stores significant value. Used alone, identify large (exponentiallyincreasing) number behavior sequences inconsistent experts goal decomposition structure therefore incorrect.8.2 Empirical Evaluationempirical study two aims. First, want determine whether behavior boundingidentifies errors agent behavior well enough considered useful purposesvalidation. Second, want compare behavior boundings effectivenesssimple sequential approaches described Section 3. end, implemented behavior bounding along two versions sequential approach serve benchmarks.first benchmark, M1 , extracts sequence actions = (a 0 , a1 , . . . , )behavior trace B = ((s, G, a)0 , (s, G, a)1 , . . . , (s, G, a)n ) second benchmark, M2 ,extracts sequence goals G = (G 0 , G1 , . . . , gn ) B. cases comparisonperformed computing minimal edit distance two behavior traces. Remembersequential methods particularly efficient representations; grow exponentially length behavior trace exponential sample complexity.However, reason, make interesting benchmarks efficacy.Performance judged based ability to: 1) correctly identify errors agent behavior;2) identify errors occurred; 3) produce minimal amounts spuriousinformation reporting errors. make assessment, must compareerrors identified automated comparison record errors manuallyidentified known actually occurred. requires manual inspectionbehavior traces taxonomic classification possible differences. followingsubsections begin describing errors classified move discussexperimental method assessment process detail.184fiBehavior Bounding: Efficient Method High-Level Behavior Comparison8.2.1 Behavioral Differencessimplest level, differences (potential errors) identified single discrepancy two particular symbols behavior traces particular pairgoals actions. type mismatch occur one three ways. before,refer desired behavior captured experts behavior traces, untrustedimperfect behavior captured novices behavior traces.Commission novices behavior trace experts behavior trace containgoal action symbol specified location goals actions inconsistent, error commission occurred. example, consider agent flyingtactical military aircraft patrolling air space two waypoints. Assumespecification correct behavior dictates agent travel way-pointsenemy aircraft spotted point agent contact command center receive clearance engage enemy. situation, errorcommission would occur agent contacts wingman instead commandcenter proceeds enter engagement.Omission experts behavior trace contains goal action symbolcorresponding symbol novices behavior trace, error omission.Following example above, omission would occur agent immediately beginsengage enemy without interjecting substitute goal action replacemissing call command center.Intrusion final simple error type, intrusion, identical omission exceptgoal action symbol occurs novices behavior trace expertsbehavior trace. intrusion would occur agent contacts command centerreceives clearance engage enemy proceeds continuewaypoint returning back engage enemy.experiments, often relatively straightforward classify errorsthree categories. However, situations enough differences twoactors behavior difficult determine whether deviation commissionone forms. situations, marked error belonging eithercategory considered acceptable comparison method identify either form.one simple errors listed occurs, may possibleidentify relationship them. call related errors compound errors noteuncovering single compound error preferable identifying many simple errorscompound error concise description underlying problem. Noteclearly cannot consider possible relationships multiple errorswould problematic computational implications. Rather, interested relationships occur frequently practice. identify two compound errors. firstmisplacement error two goal action symbols transposed novicesbehavior trace; often due incomplete specification constraints onegoals actions take part error. second duplication errorone goal action symbols reoccurs inappropriately. computer agents,185fiWallaceE1 Primary (P)Mismatch Error (M)E2 & E3:Commission Errors(C), togethercreate E1.also Primary Errorscausal chain.SalienceE1 (P,M)E2 (P,C)E4 (S,C)E5 (S,I)E3 (P,C)E6 (S,I)E7 (S,I)E3 gives rise 3Secondary Errors(S)happenIntrusions (I)Figure 6: Multiple related errors result salience hierarchytype error often occurs termination condition particular goalaction incorrectly specified.Errors also occur among subsequences behavior trace. typically happensnovice begins pursue incorrect goal. situation, causalrelationship initial error sequence errors follows. define twoerror forms based attributes: primary error first causally linkedsequence errors, secondary errors subsequent errors sequence. Althoughproblems right, secondary errors corrected simply correctingprimary error. Often occur higher level goal incorrectly selectednaturally led entire sequence incorrect behavior.compound errors salient simple errors conciselydescribe multiple simple errors well interactions them, primary errorsalient secondary errors follow. Note since single erroract primary secondary error (if hierarchy cascading errors occurs),primary/secondary relationship creates corresponding salience hierarchy. Figure 6illustrates relationship. Towards top primary compound errors towardbottom secondary individual errors. Correcting error level hierarchyalso resolve descendant errors.8.2.2 MethodIdeally, empirical evaluation would directly examine much human effort savedusing behavior comparison methods development number complexhuman-level agents. However, developing complex agents interested timeconsuming task developing multiple independent versions beyond scopeexperiment. Instead, selected approach identifies effectiveness errordetection methods without directly examining development time. Using method,evaluate effectiveness error detection method examining ability identifydifferent types errors development versions (novice versions) particular agent.examining number true errors detected, well false negatives false positives,186fiBehavior Bounding: Efficient Method High-Level Behavior Comparison1. Acquire specification correct (expert) behavior.2. Construct set flawed novice agents.3. Identify general differences comparing experts novicesknowledge.4. Acquire suitable behavior traces expert novice.5. Manually catalog errors novice behavior trace.6. Construct individual experiments partitioning behavior tracesmultiple groups.7. Evaluate well error detection method identifies catalogederrors.Figure 7: overview steps evaluation processobtain measure relative strengths weakness approach withoutdirectly examining development time impacted ongoing project. evaluationprocess described seven high level steps outlined Figure 7 described detailbelow.evaluation begins specification correct behavior. normal development circumstances, specification correctness would domain experts behavior. experiments, however, replace domain expert correctly specifiedexpert-level agent, E, whose behavior attempt reproduce. idea replacinghuman expert software agent may initially seem counterintuitive. all,research seeks, large part, make easier create agents reproduce human behavior, behavior software agents. However, approach offers significantadvantages evaluations methods.first advantage gained replacing human domain expert expertlevel agent ensure expert-level agent novice agent(the agent validated) represent knowledge similar manner.provides means determining experts novices behavior differ mightotherwise availablenot examine instances actors behaviordetermine differences, also directly compare knowledge guidesbehavior. attribute important conducting performance assessments.second advantage gained replacing human expert software agenttest error detection methods efficacy without influencedcomplications knowledge acquisition process. Moreover, since ultimately believemany aspects human-level behavior duplicated software agents, replacinghuman expert expert-level software agent change generalitymeasurements. hand, examining behavior already encodedsoftware agents knowledge, potential methodology bias us187fiWallacetoward examining behaviors easy encode software opposed completebreadth human behavior.expert-level agents, well novice agents described implementedSoar (Laird, Newell, & Rosenbloom, 1987), forward-chaining rule based system. Soarprovides natural constructs defining goal-subgoal relationships required behavior bounding. addition, Soar provides programming interface allows behaviortraces captured easily. Although Soar naturally compatible behavior bounding, means agent architecture fits criteria. rule basedsystems use task decomposition basis problem solving even goal hierarchy must implemented agents working memory. agent design easilydone CLIPS (Giarratano & Riley, 1998) demonstrated Wallace Laird (2000).Apart rule-based systems, many agent architectures allow developers defineagents knowledge base behavior using task decomposition relations. Twoexamples PRS (Ingrand, Georgeff, & Rao, 1992) PRODIGY (Veloso et al., 1995).Given expert-level agent (E), begin second step constructing novice agents(N0 , . . . , Nn ) partially correct implementations final desired behavior.novices partially correct since pursue different sequences goals actionsexpert-level agent. differences arise novice-level agentsknowledge expert-level agent. Instead, portion novicesknowledge base purposely corrupted. expert/novice pair (E, N ) laterexamined comparison methods identify similarities differencesactors behavior.Novices constructed number different ways, focus novicesgenerated introducing random changes expert-level agent. Introducing random changes helps ensure examine wide range possible errorsminimize potential bias experiments results. Moreover, effectively maintaining large body shared knowledge expert novice agents,straightforward map novice agents correct knowledge onto experts knowledgewell isolate problematic knowledge specific portion novices knowledge base.allows us take maximum advantage fact using expert-levelagent opposed human domain expert mitigates complicationsarise counting elements confusion matrix.major drawback constructing novice-level agents fashionunclear whether manner manipulate agents knowledge base representative flaws would occur naturally development process.comparison methods examined novice-level agents knowledge base directly, wouldindeed serious concern. However, comparison methods identify errorsphenomenologicallyby examining agents behavior. result, main concernnovice-level agents construct generate types observableerrors development version agents. novice-level agents create flaws covererror types identified Section 8.2.1. Thus, high degreeconfidence changes introduced following experiments represent manyobservable errors would expect see actual development environment.constructed set novice-level agents, must determine exactset behavioral errors capable producing. third step requires careful188fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonmanual examination knowledge used by, behavior produced by,novice expert. begin process documenting errors analyzingnovices knowledge differs experts knowledge. Based analysis,often identify general situations novices behavior diverge expertsbehavior. general situations provide high-level description errorsarise. example, might able determine novice fail performspecific action trying accomplish particular goal, might pursue goalinappropriate occasions. However, consider difficult predictbehavior intelligent agent simply examining knowledge, surprisingmany cases hard determine exact forms general errorsmay manifest using information differences agents knowledge alone.information require examinations behavior traces collected nextstep.fourth step acquire concrete examples experts novices behaviorgathering behavior traces, BT E BTNi , used compare agentsbehavior. situations including examined study, human-level agentscapable performing specified task many different ways. order examinesignificant range behaviors, traces selected randomly pool possiblebehaviors examined ensure two properties hold: 1) two behavior tracesidentical; 2) predicted errors actually occur least one novicesbehavior trace.examining novices behavior traces ensure second propertyholds, also perform fifth step process cataloging specific formforms error manifests. way, annotate attributes error(e.g., whether primary secondary, omission commission). includes detailsmay clear initial assessment actors knowledge differed(step 3). information cataloged process used later determineset errors detected particular approach.Cataloging errors occur behavior trace extremely tedious processrepresenting bulk experimental effort. result, try maximize usebehavior trace constructing families individual experiments evaluateimpact different sets observational data without capturing inspecting new behaviortraces.Instead simply running one experiment (E, N ) pair, run multiple experiments using different subsets observational data. process beginsactor pair (E, Ni ) selected behavior traces, BT Ni BTE ,captured inspected. point, split observations numbersubsets: nij BTNi ek BTE form individual experiments. single experimentconsists examining comparison methods performance pair subsets (n ijek ). family experiments contains experiments compare n ij ekparticular novice/expert pair. Thus, comparing four expert/novice pairs resultsfour experiment families although total number individual experiments may muchlarger. constructing experiment families way, able examine impactdifferent observational data without overwhelmed manual inspection task.189fiWallacepoint ready begin evaluating individual error detectionmethods. important recall error detection method relies examiningexamples behavior suffers potential problem unless error manifestsexamples examined, cannot detected. Thus, goal experimentsdetermine many errors occur novice behavior tracesidentified particular error detection method. validation approach reliestesting, cannot hope identify errors occur captured behaviortraces.Given two sets behavior traces, one corresponding expert-level agentcorresponding novice agents, automated error detection method examinestraces prepares report indicating similarities differences behaviors.report less useful depending well error detection methodperforms. definition, expert-level agent standard correct behavior,true differences instances inappropriate behavior errors. examininginformation report, determine whether information summarymaps error forms identified manual examination novices behavior traces.so, instances true positives (correctly detected errors) improve errordetection methods performance score. time also want identify manytrue negatives (as well false positives false negatives) identified. Usedreal validation setting, opposed evaluation setting, process would muchsame. critical difference determining whether information summarymaps true errors false positives would likely require additional investigationeither manually examining examples behavior examining novice agentsknowledge base.8.2.3 Counting Errorserror forms identified Section 8.2.1 form sets mutually exclusivemembership forms salient others, must carefultrue false positives negatives calculated. Consider, example, highlevel error description pilot always contact control tower priorinitiating landing. Suppose error manifests two ways: pilot failingcontact control tower completely, pilot contacting control towerlanding initiated. Depending circumstances, manifestations may takeform omission first case, omission plus intrusion secondcase. addition, since second case involves action moved inappropriatelocation agents behavior sequence, also instance misplacement error.means depending set behavior traces examined, high levelerror may manifest single simple error (perhaps omission), set threeerrors (two simple errors misplacement). Exactly calculate errorsrecognized depends errors manifest behavior traces,errors detected automated system.approach counting generalized following rules:190fiBehavior Bounding: Efficient Method High-Level Behavior Comparisonsimple errors (omission, commission, intrusion) detected, counttrue false positive depending whether correspond actual errorsnovices behavior.compound errors (duplication, misplacement) detected correctly, count true positives compound error simple errors comprise compounderror. compound error detected incorrectly count false positive.primary error (first error causal string) detected correctly, count truepositives primary error secondary errors (subsequent errorscausal string) causally linked it.False negatives counted first finding set errors identifiederror detection method. count incremented minimum numberadditional errors required cover true errors.One side effects counting method number errors reported(RP ) error detection method may longer sum FP + TP. Instead,one piece information report map multiple true positives, thus TPRP FP. illustrate differences brevity reports identify similar numberstrue positives, introduce metric Report Density use assesscomparison methods performance.Report Density =TPRPreport density makes reference number errors go unidentifiedparticular behavior comparison metric, complete assessment requires usesecond metric. experiments, use sensitivity calculated follows:Sensitivity =TPTP + FNSensitivity measurements fall range [0, 1]. sensitivity goes one, errorsidentified information summary. Conversely, sensitivity goes zero,errors identified data summary. Thus, favor comparison methodsobtain higher report density without sacrificing sensitivity. following twosubsections put experimental framework assessment metrics described thus faruse evaluating performance behavior bounding benchmark sequentialmethods two distinct domains.8.2.4 Object Retrieval Domainfirst test environment simulated object retrieval domain agent mustnavigate grid-based world find collect pre-specified object (initial results appear Wallace & Laird, 2003). environment relatively simplediscrete (no real valued sensors) deterministic (no exogenous events). addition,agents operating environment generate behavior sequences relatively short length:191fiWallace1BBactiongoalSensitiviy0.80.60.40.201234567Experiment FamilyFigure 8: Sensitivity object retrieval domainExpert BehaviorPPPPPBPBPNovice BehaviorPPBPPPPPBPPBPBPPPBPFigure 9: Limitations behavior boundings HBR experiment family sevenapproximately 20 30 goal action elements generated agent visits approximately 65 states. agents complete goal hierarchy maximum depth 5contains 32 goal action nodes together. Although environment simple manyways, serve reasonable test behavior bounding. Critically, correct behaviorobject retrieval domain requires reasoning (e.g., route planning) relies datastructures fully represented within goal/sub-goal hierarchy.Figure 8 illustrates sensitivity across seven experiment families objectretrieval domain (ordering figure arbitrary). figure illustrates two main phenomena. first obvious overall, behavior bounding better identifying behavior errors either goal action based sequential comparison methods.fact, behavior bounding equals betters sensitivity combined action goalsequence described Section 3 final experiment family. poor performance final experiment family second phenomena. due limitationshierarchical representation discuss below.192fiBehavior Bounding: Efficient Method High-Level Behavior Comparison8BBactiongoalReport Density765432101234567Experiment FamilyFigure 10: Report Density object retrieval domainseventh experiment family, experts behavior contains traces particular goal decomposed two ways. simplicity, well call problematic goal P .first way expert completes P pursuing two subgoals, B, followingsequence: A, B, A. second decomposition performed pursuing subgoals simplified sequence: A, B. Importantly, expert never attemptfollowing decomposition: P B, A. However, first behavior trace processedform hierarchical behavior representation, over-generalization occurs. discussedpreviously, HBR contains single node represent instance identicallynamed goals lineage. Thus first trace, containing decompositionP A, B, A, processed, three nodes formedone P , A, B respectively.accommodate fact observed occur B, temporalconstraints completely generalized two nodes. situation illustratedleft hand side Figure 9. Unfortunately, behavior representation fails capturefact expert would never perform P B, A. Thus, novices behaviortraces processed (illustrated right hand side Figure 9), little surpriseHBR produced differences detected expertnovice. contrast, error readily identified goal-based benchmark approach(M2 ). could address particular problem using modified version HBRdescribe Section 11.2. However, even approach requires additional changesagents internal representation particular behavior encoded correctly.Behavior boundings ability detect errors maintaining concise reportsillustrated relatively high report density (see Figure 10). Recall report densitymeasures amount useful information error detection methods summary. Scoresone indicate average one error could detected discrepancy indicatedsummary; scores less one indicate summary contains false positives. Reportdensity scores higher one also possible reports remain exceedinglyconcise identifying high-level errors correspond multiple low-level errors.behavior boundings ability concisely represent relationships goals via decomposition ordering constraints, well suited identifying misplacement goal-level193fiWallace1BBactiongoalSensitiviy0.80.60.40.20123456Experiment FamilyFigure 11: Sensitivity MOUT domainprimary errors. Moreover, structures compared relatively small (compared set sequences compared sequential approach) behavior boundingmaintain relatively low false positive count.Behavior boundings performance object-retrieval environment encouraging.Overall, performs well benchmark sequential comparison approaches eventhough internal representation behavior constrained desires maintainefficiency across environments differing complexity.8.2.5 MOUT Domaincontrast object retrieval domain, MOUT Environment represents significantincrease overall complexity. environment built top Unreal, commercial 3-Dvideo game. continuous, non-deterministic (exogenous events occur frequently)much longer sequence lengths object retrieval domain: 30 200goal/action elements generated agent visits approximately 4000 distinct statesper behavior trace (the state typically changes many times selection newgoal action). goal hierarchy MOUT domain larger objectretrieval domain containing 44 nodes maximum depth 6. Equally importantadded complexity environment fact MOUT built independentlyresearch behavior comparison techniques. Thus, provides important referencepoint judging overall effectiveness techniques.Figure 11 illustrates behavior boundings sensitivity compared sequentialapproaches. Results particularly dramatic, behavior boundingfewer instances zero sensitivity (inability identify errors) either sequential approaches. addition, figure points inherent scaling problems associatedsequential method illustrates dramatic effects complicated environments. Experiment families three six behavior boundings sensitivity dropszero worthy note. Here, errors due one aspect hierarchicalbehavior representation becoming over-generalized.194fiBehavior Bounding: Efficient Method High-Level Behavior Comparison0.3BBactiongoalReport Density0.250.20.150.10.050123456Experiment FamilyFigure 12: Report Density MOUT domainbehavior boundings strengths better illustrated examine reportdensity, Figure 12. Compared either sequential approaches, behaviorboundings report density exceedingly high. cases true errors detected,report density averages near 0.20, detecting one true error every five differencesreported summary. Even though report density lower relatively simpleobject-retrieval domain, still high enough useful testing agents knowledgebase. Equally worthy note fact even two benchmarks methodssensitive behavior bounding, usefulness error reports questionablebest due exceedingly low report density.Although behavior bounding clearly outperformed sequential methods MOUTdomain, obvious room improvement. identify efficacy lowcompared object-retrieval domain, looked back domainnovice-level agents examined.One noticeable source false positives due called floating operators. Floatingoperators performed service parent goal. Essentially, goalsactions occur opportunistically, potentially location goal hierarchyorder respond dynamics environment without explicitly suspendingcanceling agents goals. agent architectures, floating operators maybetter described concurrent top-level goals. Soar support concurrent goals,however, floating operators prevailing method encoding typeopportunistic behavior.floating operators work service parent goal, effectivelybreak paradigm hierarchical behavior representation effectstwofold. First, likely cause over-generalization inappropriately changingparents node type Or. Second, limited observations available, floatingoperators result representations novice agents behavior inconsistentstructure experts behavior representation (i.e., floating operator mayobserved different parts experts novices hierarchy). situation195fiWallace0.7BB (if)BBReport Density0.60.50.40.30.20.10123456Experiment FamilyFigure 13: Report Density MOUT domain ignoring floating operatorsresult behavior representation fails satisfy basic structure requirementslower boundary node.number potential methods could used circumvent problems. One method would create level indirection experts nativebehavior representation presented behavior traces. preprocessing behavior traces, would possible modify topology expertsgoal hierarchy floating operators longer appeared (i.e., mappedstatic locations hierarchy). Although could help circumvent issues floating operators, may require significant engineering resources process behavior traces.importantly, however, introduces another source errors confusionprobably best avoided result. Another approach would tag floating operatorscould treated differently Create-Hierarchy algorithm 4 . wouldincrease initial cost using behavior bounding validate agent likelycost would remain minor. third method simply ignore floating operatorsaltogether. Although this, course, potential reducing number errorsdetected, also likely significant payoff terms reducing false positives. Moreover, floating operators fit naturally behavior boundingsstructure, likely errors occur floating operators might missedeven included HBR.Figure 13 illustrates effect report density floating operators ignored(note change scale y-axis). expected, number false positives reduced, thusincreasing report density experiment families 3 6 (where errorscorrectly identified either method). Although effect somewhat subtle,raise average report density (excluding experiment families 3 6) nearly factor2, 0.18 0.35, effect makes already acceptable error summaryuseful.4. may possible tag floating operators automatically based occur goalhierarchy generalizations cause, would safest require knowledge engineerprovide tags behavior comparison performed.196fiBehavior Bounding: Efficient Method High-Level Behavior ComparisonModificationManifestationDistinct BehaviorsConsistent BTsAvg. BT LengthExpertNovice-ANovice-BN/AN/A4N/A67New ProposalIntrusion12469Missing PreferenceCommission8468Table 1: Properties expert & novice agents validation efficacy test9. Efficacy Validation Toolshown behavior bounding acceptable performance two domainsdistinct complexity argued would well suited detecting errors manygoal oriented environments. However, point, hypothesizederror reports provided behavior bounding decrease validation cost;provided direct evidence.substantiate claim, performed experiment five human participantsattempted find correct flaws agents behavior without information behavior boundings error report 5 . previous experiments, agentsimplemented Soar architecture. participant member Soar researchgroup least six months Soar programming experience. Participants identified twobehavior flaws: one with, one without aid behavior boundings error report.unaided situation, participants relied standard debugging tools techniquesalready practice using. flaw identified, participantscorrected agents knowledge using VisualSoar, standard Soar development environment. aided situation, participants given behavior boundings error reporthelp make sense agents behavior. Thus, experiments presented below,two conditions: aided, unaided. Condition within-subject variable,say participant experiences both.test-bed agent taken object retrieval domain discussed Section 8.2.4.initial setup followed similar lines earlier experiments. began constructingexpert-level agent exhibited correct behavior. agent could perform taskfour distinct similar ways required 78 Soar rules encode. Note normaluse, observations correct behavior likely come human experts. However,creating correct agent first, possible describe precisely flawed agents differideal (both behavior implementation). property criticalexperiment.creating expert-level agent, constructed two novice-level agents (Novice-ANovice-B). participants task identify correct behavioral differencesnovice agents expert-level agent. participant wouldvalidate novice agents (using different method one), one primary5. Initial results reported Wallace (2007).197fiWallacedesires construct novice-level agents way would similarlydifficult validate. help ensure case, limited differencesnovices experts knowledge single rule. case Novice-A, one ruleadded resulted agent performing different sequence actions expert.case Novice-B, preference rule removed resulting two discrepancies: oneparameters agents internal goal, another parameters agentsprimitive action. Aside differences mentioned above, behavior novicelevel agents similar expert respects.Table 1 illustrates important properties expert-level novice-levelagents. first second rows indicate change made constructnovice agents form error results changes. third rowindicates many distinct behavior traces agent capable generating. valueimportant gives indication many behavior traces user mightneed examine order get good understanding range behavior agentcapable producing. fourth row indicates many novices behavior tracesconsistent expert behavior traces (i.e., error free). Finally, fifth row indicatesaverage length agents behavior trace. gives indicationmuch information must examined instance behavior.worth noting flaws introduced agents minor standards. experiment, flawed behavior result deadlocks infinite loops.Indeed, viewed classical sense, agents necessarily flawed.successful achieving desired final state (finding lost object). However,agents pursue trajectories state/action/goal space, participants task determine trajectories differ find correctfault causes difference.none participants used, even seen, graphical behavior comparisons generated behavior bounding, given short, 15 minute, tutorialbecome familiar graphical behavior summary provided interface. addition, participants asked read short summary provided descriptiondebugging task, summary agents behavior, plain English descriptionsalient goals actions would pursued task performance. overviewintended familiarize users agents domain without requiringparticipant build agent ground up.point, participants randomly assigned agent validate. attemptedmitigate bias varying order aided unaided tests presentedwell pairing agent validation method. experiment,asked participants indicate ready modify agents knowledgearticulate changes believed required. allowed us measureamount time needed identify behavioral flaw well total time requiredcorrect agents behavior.first phase debugging session, participants identified noviceagents behavior differed standard set correct expert-level agent.unaided situation, specific instructions given identify errors. Participantsfree look errors using whatever debugging techniques developedcourse working Soar. Similarly, aided situation specific instructions198fiBehavior Bounding: Efficient Method High-Level Behavior Comparison35IdentifyCorrectFix30Unaided252015105005101520Aided253035Figure 14: Time required identify correct errors using two techniquesidentify errors given. Participants generalized tutorial experienceinterpret information behavior boundings error report identify changeswould required make flawed agents behave correctly. situations,participant correctly identified error flawed agents behavior (e.g., sayingnovice always perform action X action Y), elapsed time recorded.call time required identify error.second phase debugging session began participant determinedready try modifying flawed agents knowledge order correctobserved error. Regardless whether error identified using standard techniquesbehavior bounding first phase, participants used VisualSoar editing environment(a standard part Soars development environment) portion task.participant made changes, re-examined novice agents behavior ensureproblem fact corrected. participant confidentproblem resolved, clock stopped time spent beginningphase one end phase two recorded time needed correct agentsbehavior6 .Figure 14 shows time spent participant aided unaided taskshighlights benefits behavior bounding. x-coordinate indicates time spentdebugging aided situation information behavior boundings error summaryused y-coordinate indicates time spent unaided situation6. cases participant believed agents behavior correctedfact errors remained.199fiWallaceparticipants normal debugging techniques used. Three sets points plotted:time identify error; time correct error; time required fix (i.e.,difference time correct time identify). line = x also plottedreference; points lie left line indicate participant performedbetter (i.e., faster) aided situation.cluster points nearest origin (labeled fix legend) indicatebehavior bounding little effect time required fix agentsknowledge error identified. Instead, behavior boundings impact, expected,comes reduction time required identify error. leads reductionoverall time required validation task. paired t-test used determinestatistical significance three timed operations illustrated figure.surprisingly, test confirms statistically significant performance advantage gainedusing information behavior bounding time identify timecorrect error (p = .0006, p = .0002 respectively). paired t-test indicatestatistically significant difference times required simply fix error aidedunaided situations (p = .85), matching expectations.data, seems safe conclude error report provided behaviorbounding does, fact, provide information relevant identifying differencestwo agents behavior useful isolating faulty knowledge. Although onelevel results may considered best cases constructed errorsbelieved would demonstrate effectiveness behavior bounding, numberreasons results may conservative side optimistic.First, would expect HBR useful complexity domainagents behavior increasesdevelopers wishing examine raw behavior tracesneed look longer traces traces complex environments whereasHBR, need view one data structure. Second, test conductedclearly influenced design behavior boundings user interface. conductedformal experiments increase quality interface, quite possible futureimplementations would capable delivering information effectively user,thus producing increase efficiency.10. Related Worknoted previously Section 4, number areas artificial intelligence, particularly machine learning addressed problems closely related examined here.following subsections, briefly comment salient areas.10.1 Plan Recognitionbehavior comparison described related keyhole plan recognition (Albrecht,Zukerman, & Nicholson, 1998), closely, team monitoring overhearingwork Kaminka, Pynadath, Tambe (2002). team monitoring, objectivedetermine task agent set agents performing given limited observationsactions communications pass them. Plan recognition possible, part, complete team-level plan allows monitoring system identifyagents goals observational information acquired. enough information ob200fiBehavior Bounding: Efficient Method High-Level Behavior Comparisontained, single plan identified ascribed agent(s). behavior comparison,objective similar. salient difference work plan recognitiongiven plan library; instead attempting recreate modelexecution series observations order determine whether actorspursue goals manner (i.e., plan library).10.2 Learning Observationnumber systems (e.g, van Lent & Laird, 1999; Wang, 1995; Konik & Laird, 2006)also developed learn procedural rules plan operators observationsexpert behavior. Wangs OBSERVER (Wang, 1995) learns STRIPS style operators;van Lents KnoMic (van Lent & Laird, 1999) learns production rules Soar agentarchitecture Koniks system (Konik & Laird, 2006) creates first order logic ruleslater converted Soar productions. three systems use similar behavior tracesapproach, although Wangs OBSERVER works primitive actionsnotion non-atomic goals thus need annotate behavior traces.systems, Koniks demonstrated within complex domain (a 3-Dvirtual environment agent must learn successfully navigate series rooms).key difference approach lies fundamental premise.interested learning simple concise model behavior outsidethird-party use validate existing (but untrusted) agent, systems aimlearn agents knowledge altogether. learning complete task knowledge clearlyimportant goal community, remain set important task domains (e.g.,military mission critical applications) learned systems often treatedskepticism human coded systems still preferred. approach described,however, could useful help bridge gap allowing skeptical parties validatebehavior learned systems. Thus, may seem surface solvinglearning executable task knowledge problem one also solves behavior comparisonproblem outlined, casein mission critical applications, agentsbehavior still requires validation human loop sign correctness.Moreover, knowledge learned instead engineered, validation task likelybecome much difficult one document system field questionsfunction particular component.10.3 Hierarchical Reinforcement LearningReinforcement Learning seeks provide methods agent learn approximate optimal behavioral strategy interacting environment. reinforcement learning, optimality defined reward function outside agentscontrol (it part environment) agent learns interactionenvironment maximize function. Traditional (flat) approaches reinforcementlearning Q-Learning (Watkins & Dayan, 1992) may require long training timeconverge optimal policy. Price Boutilier (2003) show reinforcement learningfacilitated observing mentor perform task Hierarchical ReinforcementLearning (Dietterich, 2000; Andre & Russell, 2002; Marthi, Russell, Latham, & Guestrin,201fiWallace2005) seeks, part, reduce complexity learning problem useexternal domain knowledge form programmer-defined action hierarchy.traditional Reinforcement Learning (RL) Hierarchical Reinforcement Learning (HRL) differ significantly approach three fundamental ways. First,method described previous subsection, goal (H)RL learnexecutable model behavior, model used help validate system.Second, (H)RL, models learned via interaction environmentenvironmentally defined reward function. Instead, interested learning directlyobservation expert behavior without experimental interaction environment.Finally, unlike RL HRL, assume existence reward functionmoreover interested optimal behavior sense close approximation human behavior.Aside important differences, commonality Hierarchal Reinforcement Learning approach stems behavior model. open issueDietterichs presentation MAXQ (Dietterich, 2000) restated Barto Mahadevan (2003) whether programmer-supplied information (the MAXQ task-graph)Hierarchical Reinforcement Learning could acquired automatically. subtaskMAXQ task-graph three tuple hT , Ai , Ri i. Ti (si ) partitions state spaceactive states Si terminal states Ti (a subtask executed current stateSi ). Ai set actions performed achieve subtask Ri (s0 |s, a)pseudo reward function indicating desirable terminal state subtask.approach could used help construct part MAXQ task graph directlyobservations. First, goal/subgoal hierarchy build used directly identifyAi , set actions performed subtask. Second, task parameterslearn tied information state (this relation observed directlybehavior trace). information combined temporal constraints learngoal/action nodes could used identify conditions task couldentered (some properties active states identified predicate ). Togethercould help construct MAX-Q task graph based observations expertsperformance.10.4 Inverse Reinforcement LearningInverse Reinforcement Learning (IRL) (e.g., Abbeel & Ng, 2004; Ramachandran & Amir,2007) attempts reconstruction implicit reward function given set example behaviors. IRL combination RL used simple domains reproduce behaviorexplicit reward function. would permit system to, example,learn model human experts behavior 1) reconstructing experts implicit rewardfunction observing example behaviors 2) interacting environmentgenerate policy maximizes implicit reward. Together, technologies providepotentially powerful alternative learning observation methods described previously. However, best knowledge IRL yet demonstrated withinhierarchical setting, learning observation methods still present currentstate art learning hierarchical task knowledge.202fiBehavior Bounding: Efficient Method High-Level Behavior Comparison11. Extensions Behavior Bounding Future Directionsexperiments behavior bounding yielded encouraging results. Yet,complex MOUT domain, results leave room improvement. Section 5,noted representational limitations behavior boundings HBR. Here,examine extensions behavior bounding could positively affect performancebriefly describe promising direction future work. leave implementationextensions detailed discussion future work.11.1 Manual Definition Lower Boundary Nodeitself, lower boundary minimal specification parameters necessarycorrect behavior. is, contain constraints required discriminatecorrect incorrect behavior. Although suggested lower boundary node easily formed completely generalizing upper boundary node, betterapproach may construct manually.hierarchy represented lower boundary node simply identifies spacepotentially acceptable goal decompositions. result, would logical createstructure early design phase expert knowledge acquired agent.Lee OKeefe (1994) well Yen Lee (1993) argued independentlyconstructing overview ways goals decompose sub-goals primitiveactions important step knowledge acquisition. Moreover, argue identifyingrelationship goals, sub-goals primitive actions helps organize agentsknowledge serves foundation knowledge acquisition. Thus, maycase constructing lower boundary node manually process introduces littleadditional effort part domain expert knowledge engineer.fact, may actually benefit knowledge acquisition making process structureddirected.constructing lower boundary node hand relatively low cost process,reasonable ask manual effort could leveraged improve behavior boundingsperformance. One use manually constructed HBR help validate agentsdesign early implementation process. generally believed earliervalidation take place, less costly be. constructing lower boundaryhand, may possible identify whether agent adheres constraintsstatically analyzing knowledgewithout needing see agent interactenvironment.11.2 Sometimes/Always ConstraintsAnother potentially useful modification HBR would change associationnode type constraints. current version behavior bounding,constraints associated parent goal nodes. Alternatively, might associate similarlabels child nodes Sometimes Always. Although change subtle,would offer modestly representational power. semantics nodeseasily covered: node simply one children Alwaysnode one children Sometimes. semantics Sometimes203fiWallaceAlways also make possible encapsulate new decomposition relations occurAnd/Or relation.Recall problematic behavior Section 8.2.4 HBR fails correctly encodeproper decomposition relations (specifically goal P decompose subgoalsA, B, subgoals A, B B, A). Sometimes/Always constraintsencode decomposition, albeit additional layer subgoal addedtask specification. introducing two new subgoals P decomposes C , 7C decomposes , B decomposes , would able encodecorrect behavioral patterns respect P, A, B caveatinterject two new goals C D. course, point discussion justifyad-hoc modifications task structure, rather show concrete instanceSometimes/Always constraints may add beneficial representational power.Sometimes/Always constraints effect learnability construction costHBR. tested modification detail, preliminary resultsMOUT data sets indicate minor improvement performance domain.11.3 Additional EnhancementsTwo additional enhancements HBR also left future work. first abilitydeal concurrent goals actions. Soar support concurrent operators,cannot tested within exiting system. However, support addedHBR, may possible avoid issues associated floating eventsencountered MOUT domain. second enhancement would allowone node constructed represent given action/goal within particular context.current representation, two sibling nodes name (thereexactly one node represent identically named goal/actions within context).keeps representation simple, also held responsible representationalproblems like one discussed Section 8.2.4. disadvantage approachunclear new nodes added hierarchy. new node addedtime goal/action pursued, hierarchy grows much rapidly (directlyfunction length behavior tracing) increasing computational complexitydecreasing rate generalization.11.4 Behavior Bounding Runtime Environmentpromising direction additional future work use ideas presented paper,specifically constraints contained upper-boundary nodes behavior representation, monitor agents behavior runtime. approach, recentlybegun explore, provides mechanism determining agent may makinginappropriate decisions (Wallace, 2005b, 2005a). Inconsistencies agents desiredcourse action constraints specified upper boundary node could usedenforce social policies interaction protocols groups agents dynamically adjust agents degree autonomy begins make questionably choices.Moreover, high-level constraints specified hierarchical behavior model require7.indicates ALWAYS node204fiBehavior Bounding: Efficient Method High-Level Behavior Comparisondirect knowledge agents underlying implementation language (only goaldecomposition). means approach could also used safeguardimplementation errors agents built third parties may adequatelyvalidated.12. Contributionsintroduced behavior bounding, model-based approach comparing two actorsbehavior. novel approach uses hierarchical behavior representation motivateddesire build high-level model behavior observations either humancomputer agent performance efficient create maintain effective use.demonstrated behavior bounding meets requirements providingtheoretical empirical support claims. Finally, shown information behavior boundings comparison significantly aid process identifyingproblems agents behavior, thus speeding knowledge-base validation significantfactor.Acknowledgmentswould like thank John Laird help reviewing early versions paper, alongmembers UM Soar research group participated user study. Portionswork supported Office Naval Research contract N61339-99-C-0104.ReferencesAbbeel, P., & Ng, A. Y. (2004). Apprenticeship learning via inverse reinforcement learning.Proceedings Twenty First International Conference Machine Learning,pp. 18.Albrecht, D. W., Zukerman, I., & Nicholson, A. E. (1998). Bayesian models keyholeplan recognition adventure game. User Modeling User-Adapted Interaction,8 (1-2), 547.Andre, D., & Russell, S. J. (2002). State abstraction programmable reinforcementlearning agents. Proceedings Eighteenth National Conference ArtificialIntelligence, pp. 119125.Anrig, B., & Kohlas, J. (2002). Model-based reliability diagnostic: common framework reliability diagnostics. Stumptner, M., & Wotawa, F. (Eds.), DX02Thirteenth International Workshop Principles Diagnosis, pp. 129136, Semmering, Austria.Barto, A. G., & Mahadevan, S. (2003). Recent advances hierarchical reinforcementlearning. Discrete Event Dynamic Systems: Theory Applications, 13, 343379.Bordini, R. H., Fisher, M., Visser, W., & Wooldridge, M. (2004). State-space reductiontechniques agent verification. AAMAS 04: Proceedings Third InternationalJoint Conference Autonomous Agents Multiagent Systems, pp. 896903.205fiWallaceBordini, R. H., Fisher, M., Visser, W., & Wooldridge, M. (2006). Verifying multi-agentprograms model checking. Autonomous Agents Multi-Agent Systems, 12, 239256.Dietterich, T. G. (2000). Hierarchical reinforcement learning MAXQ functiondecomposition. Journal Artificial Intelligence Research, 13, 227303.Erol, K., Hendler, J., & Nau, D. S. (1994). HTN planning: Complexity expressivity.Proceedings Twelfth National Conference Artificial Intelligence, pp. 11231128. AAAI Press/MIT Press.Fisher, M. (2005). Temporal development methods agent-based systems. AutonomousAgents Multi-Agent Systems, 10, 4166.Giarratano, J., & Riley, G. (1998). Expert Systems: Principles Programming. PWSPublishing Co., Boston, MA.Haussler, D. (1988). Quantifying inductive bias: AI learning algorithms Valiants learning framework.. Artificial Intelligence, 36, 177221.Ingrand, F. F., Georgeff, M. P., & Rao, A. S. (1992). architecture real-time reasoningsystem control. IEEE Expert, 7 (6), 3344.John, B. E., & Kieras, D. E. (1996). GOMS family user interface analysis techniques:Comparison contrast. ACM Transactions ComputerHuman Interaction, 3 (4),320351.Jones, R. M., Laird, J. E., Nielsen, P. E., Coulter, K. J., Kenny, P., & Koss, F. V. (1999).Automated intelligent pilots combat flight simulation. AI Magazine, 20 (1), 2742.Kaminka, G. A., Pynadath, D. V., & Tambe, M. (2002). Monitoring teams overhearing:multi-agent plan-recognition approach. Journal Artificial Intelligence Research,17, 83135.Kirani, S. H., Zualkernan, I. A., & Tsai, W.-T. (1994). Evaluation expert system testingmethods. Communications ACM, 37 (11), 7181.Konik, T., & Laird, J. E. (2006). Learning goal hierarchies structured observationsexpert annotations. Machine Learning, 64 (13), 263287.Laird, J. E., Newell, A., & Rosenbloom, P. S. (1987). Soar: architecture generalintelligence. Artificial Intelligence, 33 (1), 164.Lee, S., & OKeefe, R. M. (1994). Developing strategy expert system verificationvalidation. IEEE Transactions Systems, Man Cybernetics, 24 (4), 643655.Lucas, P. (1998). Analysis notions diagnosis. Artificial Intelligence, 105, 295343.Marthi, B., Russell, S., Latham, D., & Guestrin, C. (2005). Concurrent hierarchical reinforcement learning. Proceedings International Joint Conference ArtificialIntelligence 2005, pp. 779785.Menzies, T. (1999). Knowledge maintenance: state art. Knowledge Engineering Review, 14 (1), 146.Mitchell, T. M. (1982). Generalization search. Artificial Intelligence, 18 (2), 203226.206fiBehavior Bounding: Efficient Method High-Level Behavior ComparisonMitchell, T. M. (1997). Machine Learning. McGraw-Hill.Murphy, P. M., & Pazzani, M. J. (1994). Revision production system rule-bases.Proceedings Eleventh International Conference Machine Learning, pp. 199207. Morgan Kaufmann.Price, B., & Boutilier, C. (2003). Accelerating reinforcement learning implicitimitation. Journal Artificial Intelligence Research, 19, 569629.Ramachandran, D., & Amir, E. (2007). Bayesian inverse reinforcement learning. Proceedings International Joint Conference Artificial Intelligence 2007, pp. 25862591.Rickel, J., Marcella, S., Gratch, J., Hill, R., Traum, D., & Swartout, W. (2002). Towardnew generation virtual humans interactive experiences. IEEE IntelligentSystems, 17 (4), 3238.Shortliffe, E. H. (1987). Computer programs support clinical decision making. JournalAmerican Medical Association, 258 (1), 6166.Swartout, W., Hill, R., Gratch, J., Johnson, W. L., Kyriakakis, C., LaBore, C., Lindheim,R., Marsella, S., Miraglia, D., Moore, B., Morie, J., Rickel, J., Thiebaux, M., Tuh,L., Whitney, R., & Douglas, J. (2001). Toward holodeck: Integrating graphics,sound, character story. Proceedings Fifth International ConferenceAutonomous Agents, pp. 409416.Traum, D., Rickel, J., Gratch, J., & Marsella, S. (2003). Negotiation tasks hybridhuman-agent teams simulation-based training. AAMAS 03: ProceedingsSecond International Joint Conference Autonomous Agents MultiagentSystems, pp. 441448.Tsai, W.-T., Vishnuvajjala, R., & Zhang, D. (1999). Verification validationknowledge-based systems. IEEE Transactions Knowledge Data Engineering,11 (1), 202212.van Lent, M. C., & Laird, J. E. (1999). Learning hierarchical performance knowledgeobservation. Proceedings 1999 International Conference MachineLearning, pp. 229238.Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planning learning: PRODIGY architecture. Journal TheoreticalExperimental Artificial Intelligence, 7 (1), 81120.Wallace, S. A. (2005a). Abstract behavior representations self-assessment. AAAISpring Symposium Meta-Cognition Computation (ASSMC 2005). AAAI Technical Report SS-05-04., pp. 120125.Wallace, S. A. (2005b). S-Assess: library self-assessment. Proceedings FourthInternational Conference Autonomous Agents Multiagent Systems (AAMAS05), pp. 256263.Wallace, S. A. (2007). Enabling trust behavior metamodels. AAAI Spring Symposium Interaction Challenges Intelligent Agents (ASSICIA 2007). AAAI Technical Report SS-07-04., pp. 124131.207fiWallaceWallace, S. A., & Laird, J. E. (2000). Toward methodology AI architecture evaluation:Comparing Soar CLIPS. Jennings, N., & Lesperance, Y. (Eds.), IntelligentAgents VI Proceedings Sixth International Workshop Agent Theories,Architectures, Languages (ATAL-99), Lecture Notes Artificial Intelligence, pp.117131. Springer-Verlag, Berlin.Wallace, S. A., & Laird, J. E. (2003). Behavior Bounding: Toward effective comparisonsagents & humans. Proceedings Eighteenth International Joint ConferenceArtificial Intelligence, pp. 727732.Wang, X. (1995). Learning observation practice: incremental approach planning operator acquisition. Proceedings Twelfth International ConferenceMachine Learning, pp. 549557.Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8, 279292.Weitzel, J. R., & Kerschberg, L. (1989). Developing knowledge-based systems: Reorganizingsystem development life cycle. Communications ACM, 32 (4), 482488.Yen, J., & Lee, J. (1993). task-based methodology specifying expert systems. IEEEExpert, 8 (1), 815.Yost, G. R. (1996). Implementing Sisyphus-93 task using Soar/TAQL. InternationalJournal Human-Computer Studies, 44, 281301.208fiJournal Artificial Intelligence Research 34 (2009) 443-498Submitted 08/08; published 03/09Wikipedia-based Semantic InterpretationNatural Language ProcessingEvgeniy GabrilovichShaul Markovitchgabr@yahoo-inc.comshaulm@cs.technion.ac.ilDepartment Computer ScienceTechnionIsrael Institute TechnologyTechnion City, 32000 Haifa, IsraelAbstractAdequate representation natural language semantics requires access vast amountscommon sense domain-specific world knowledge. Prior work field basedpurely statistical techniques make use background knowledge, limitedlexicographic knowledge bases WordNet, huge manual effortsCYC project. propose novel method, called Explicit Semantic Analysis (ESA),fine-grained semantic interpretation unrestricted natural language texts. methodrepresents meaning high-dimensional space concepts derived Wikipedia,largest encyclopedia existence. explicitly represent meaning text termsWikipedia-based concepts. evaluate effectiveness method text categorization computing degree semantic relatedness fragments naturallanguage text. Using ESA results significant improvements previous stateart tasks. Importantly, due use natural concepts, ESA modeleasy explain human users.1. IntroductionRecent proliferation World Wide Web, common availability inexpensive storagemedia accumulate time enormous amounts digital data, contributedimportance intelligent access data. sheer amount data availableemphasizes intelligent aspect accessno one willing capable browsingsmall subset data collection, carefully selected satisfy onesprecise information need.Research artificial intelligence long aimed endowing machines abilityunderstand natural language. One core issues challenge represent language semantics way manipulated computers. Prior worksemantics representation based purely statistical techniques, lexicographic knowledge, elaborate endeavors manually encode large amounts knowledge. simplestapproach represent text semantics treat text unordered bag words,words (possibly stemmed) become features textual object.sheer ease approach makes reasonable candidate many information retrievaltasks search text categorization (Baeza-Yates & Ribeiro-Neto, 1999; Sebastiani,2002). However, simple model reasonably used texts fairly long,performs sub-optimally short texts. Furthermore, little address twomain problems natural language processing (NLP), polysemy synonymy.c2009AI Access Foundation. rights reserved.fiGabrilovich & MarkovitchLatent Semantic Analysis (LSA) (Deerwester, Dumais, Furnas, Landauer, & Harshman,1990) another purely statistical technique, leverages word co-occurrence information large unlabeled corpus text. LSA use explicit human-organizedknowledge; rather, learns representation applying Singular Value Decomposition(SVD) words-by-documents co-occurrence matrix. LSA essentially dimensionality reduction technique identifies number prominent dimensions data,assumed correspond latent concepts. Meanings words documentsrepresented space defined concepts.Lexical databases WordNet (Fellbaum, 1998) Rogets Thesaurus (Roget, 1852)encode important relations words synonymy, hypernymy, meronymy.Approaches based resources (Budanitsky & Hirst, 2006; Jarmasz, 2003) map textwords word senses, use latter concepts. However, lexical resources offerlittle information different word senses, thus making word sense disambiguationnearly impossible achieve. Another drawback approaches creationlexical resources requires lexicographic expertise well lot time effort, consequently resources cover small fragment language lexicon. Specifically,resources contain proper names, neologisms, slang, domain-specific technicalterms. Furthermore, resources strong lexical orientation predominantly contain information individual words, little world knowledge general.inherently limited individual words, approaches require extra levelsophistication handle longer texts (Mihalcea, Corley, & Strapparava, 2006); example,computing similarity pair texts amounts comparing word one textword text.Studies artificial intelligence long recognized importance knowledgeproblem solving general, natural language processing particular. Backearly years AI research, Buchanan Feigenbaum (1982) formulated knowledgepower hypothesis, postulated power intelligent program performtask well depends primarily quantity quality knowledgetask.computer programs face tasks require human-level intelligence, natural language processing, natural use encyclopedia endow machinebreadth knowledge available humans. are, however, several obstaclesway using encyclopedic knowledge. First, knowledge available textualform, using may require natural language understanding, major problemright. Furthermore, even language understanding may enough, texts writtenhumans normally assume reader possesses large amount common-sense knowledge,omitted even detailed encyclopedia articles (Lenat, 1997). Thus,circular dependencyunderstanding encyclopedia articles requires natural languageunderstanding capabilities, latter turn require encyclopedic knowledge.address situation, Lenat colleagues launched CYC project, aimsexplicitly catalog common sense knowledge humankind.developed new methodology makes possible use encyclopedia directly,without need manually encoded common-sense knowledge. Observe encyclopedia consists large collection articles, provides comprehensiveexposition focused single topic. Thus, view encyclopedia collection con444fiWikipedia-based Semantic Interpretationcepts (corresponding articles), accompanied large body text (the articlecontents). propose use high-dimensional space defined concepts orderrepresent meaning natural language texts. Compared bag words LSAapproaches, using concepts allows computer benefit huge amounts worldknowledge, normally accessible humans. Compared electronic dictionariesthesauri, method uses knowledge resources order magnitude larger,also uniformly treats texts arbitrarily longer single word. Evenimportantly, method uses body text accompanies concepts orderperform word sense disambiguation. show later, using knowledge-rich conceptsaddresses polysemy synonymy, longer manipulate mere words. callmethod Explicit Semantic Analysis (ESA), uses knowledge concepts explicitlydefined manipulated humans.approach applicable many NLP tasks whose input document (or shorternatural language utterance), output decision based document contents.Examples tasks information retrieval (whether document relevant), textcategorization (whether document belongs certain category), comparing pairsdocuments assess similarity.1Observe documents manipulated tasks given formencyclopedic knowledge intend useplain text. key observation allows uscircumvent obstacles enumerated above, use encyclopedia directly, withoutneed deep language understanding pre-cataloged common-sense knowledge.quantify degree relevance Wikipedia concept input text comparingtext article associated concept.Let us illustrate importance external knowledge couple examples. Without using external knowledge (specifically, knowledge financial markets), one inferlittle information brief news title Bernanke takes charge. However, usingalgorithm developed consulting Wikipedia, find following conceptshighly relevant input: Ben Bernanke, Federal Reserve, ChairmanFederal Reserve, Alan Greenspan (Bernankes predecessor), Monetarism (an economic theory money supply central banking), inflation deflation. anotherexample, consider title Apple patents Tablet Mac. Without deep knowledge hitech industry gadgets, one finds hard predict contents news item. UsingWikipedia, identify following related concepts: Apple Computer2 , Mac OS (theMacintosh operating system) Laptop (the general name portable computers,Tablet Mac specific example), Aqua (the GUI Mac OS X), iPod (another prominent product Apple), Apple Newton (the name Apples early personal digitalassistant).ease presentation, examples showed concepts identifiedESA relevant input. However, essence method representing meaning text weighted combination Wikipedia concepts. Then,1. Thus, consider tasks machine translation natural language generation, whose outputincludes new piece text based input.2. Note correctly identify concept representing computer company (Apple Computer)rather fruit (Apple).445fiGabrilovich & Markovitchdepending nature task hand either use entire vectors concepts,use relevant concepts enrich bag words representation.contributions paper twofold. First, propose new methodologyuse Wikipedia enriching representation natural language texts. approach,named Explicit Semantic Analysis, effectively capitalizes human knowledge encodedWikipedia, leveraging information cannot deduced solely input textsprocessed. Second, evaluate ESA two commonly occurring NLP tasks, namely, textcategorization computing semantic relatedness texts. tasks, using ESAresulted significant improvements existing state art performance.Recently, ESA used researchers variety tasks, consistently provedsuperior approaches explicitly used large-scale repositories humanknowledge. Gurevych, Mueller, Zesch (2007) re-implemented ESA approachGerman-language Wikipedia, found superior judging semantic relatednesswords compared system based German version WordNet (GermaNet). Chang,Ratinov, Roth, Srikumar (2008) used ESA text classification task without explicittraining set, learning knowledge encoded Wikipedia. Milne Witten(2008) found ESA compare favorably approaches solely based hyperlinks,thus confirming wealth textual descriptions Wikipedia exlicitly superiorusing structural information alone.2. Explicit Semantic Analysismeaning word cat? One way interpret word cat viaexplicit definition: cat mammal four legs, belongs feline species,etc. Another way interpret meaning cat strength associationconcepts know: cat relates strongly concepts feline pet, somewhatless strongly concepts mouse Tom & Jerry, etc.use latter association-based method assign semantic interpretation wordstext fragments. assume availability vector basic concepts, C1 , . . . , Cn ,represent text fragment vector weights, w1 , . . . , wn , wi representsstrength association Ci . Thus, set basic concepts viewedcanonical n-dimensional semantic space, semantics text segment correspondspoint space. call weighted vector semantic interpretation vectort.canonical representation powerful, effectively allows us estimatesemantic relatedness text fragments distance space. followingsection describe two main components scheme: set basic concepts,algorithm maps text fragments interpretation vectors.2.1 Using Wikipedia Repository Basic Conceptsbuild general semantic interpreter represent text meaning varietytasks, set basic concepts needs satisfy following requirements:1. comprehensive enough include concepts large variety topics.446fiWikipedia-based Semantic Interpretation2. constantly maintained new concepts promptly addedneeded.3. Since ultimate goal interpret natural language, would like conceptsnatural, is, concepts recognized used human beings.4. concept Ci associated text di , determine strengthaffinity term language.Creating maintaining set natural concepts requires enormous effort manypeople. Luckily, collection already exists form Wikipedia, onelargest knowledge repositories Web. Wikipedia available dozens languages,English version largest all, contains 300+ million words nearlyone million articles, contributed 160,000 volunteer editors. Even though Wikipediaeditors required established researchers practitioners, open editing approach yields remarkable quality. recent study (Giles, 2005) found Wikipedia accuracyrival Encyclopaedia Britannica. However, Britannica order magnitudesmaller, 44 million words 65,000 articles (http://store.britannica.com, visitedFebruary 10, 2006).appropriate encyclopedia, article comprises comprehensive expositionsingle topic. Consequently, view Wikipedia article defining conceptcorresponds topic. example, article artificial intelligence definesconcept Artificial Intelligence, article parasitic extraction circuitdesign defines concept Layout extraction.3 body articles criticalapproach, allows us compute affinity concepts wordsinput texts.important advantage approach thus use vast amounts highly organized human knowledge. Compared lexical resources WordNet, methodologyleverages knowledge bases orders magnitude larger comprehensive.Importantly, Web-based knowledge repositories use work undergo constantdevelopment breadth depth steadily increase time. Compared LatentSemantic Analysis, methodology explicitly uses knowledge collected organizedhumans. semantic analysis explicit sense manipulate manifest concepts grounded human cognition, rather latent concepts used LSA. Therefore,call approach Explicit Semantic Analysis (ESA).2.2 Building Semantic InterpreterGiven set concepts, C1 , . . . , Cn , set associated documents, d1 , . . . , dn , buildsparse table n columns corresponds concept, rowscorresponds word occurs i=1...n di . entry [i, j] table correspondsTFIDF value term ti document dj[i, j] = tf (ti , dj ) logn,dfi3. use titles articles convenient way refer articles, algorithm treatsarticles atomic concepts.447fiGabrilovich & Markovitchterm frequency defined(tf (ti , dj ) =1 + log count(ti , dj ), count(ti , dj ) > 0,0,otherwisedfi = |{dk : ti dk }| number documents collection containterm ti (document frequency).Finally, cosine normalization applied row disregard differences documentlength:[i, j][i, j] pPr,2l=1 [i, j]r number terms.semantic interpretation word ti obtained row table . is,meaning word given vector concepts paired TFIDF scores,reflect relevance concept word.semantic interpretation text fragment, ht1 , . . . , tk i, centroid vectorsrepresenting individual words. definition allows us partially perform word sensedisambiguation. Consider, example, interpretation vector term mouse.two sets strong components, correspond two possible meanings: mouse (rodent) mouse (computing). Similarly, interpretation vector word screenstrong components associated window screen computer screen. textfragment purchased mouse screen, summing two interpretation vectors boost computer-related components, effectively disambiguating words.Table also viewed inverted index, maps word listconcepts appears. Inverted index provides efficient computationdistance interpretation vectors.Given amount information encoded Wikipedia, essential controlamount noise present text. discarding insufficiently developed articles,eliminating spurious association articles words. done settingzero weights concepts whose weights given term low (seeSection 3.2.3).2.3 Using Link Structurenatural electronic encyclopedia provide cross-references formhyperlinks. result, typical Wikipedia article many links entriesarticles conventional printed encyclopedias.link structure used number ways. Observe link associatedanchor text (clickable highlighted phrase). anchor text always identicalcanonical name target article, different anchor texts used referarticle different contexts. example, anchor texts pointing FederalReserve include Fed, U.S. Federal Reserve Board, U.S. Federal Reserve System,Board Governors Federal Reserve, Federal Reserve Bank, foreign reservesFree Banking Era. Thus, anchor texts provide alternative names, variant spellings,related phrases target concept, use enrich article texttarget concept.448fiWikipedia-based Semantic InterpretationFurthermore, inter-article links often reflect important relations conceptscorrespond linked articles. explore use relations feature generationnext section.2.3.1 Second-order InterpretationKnowledge concepts subject many relations, including generalization, meronymy(part of), holonymy synonymy, well specific relations capital of,birthplace/birthdate etc. Wikipedia notable example knowledge repositoryfeatures relations, represented hypertext links Wikipediaarticles.links encode large amount knowledge, found article texts.Consequently, leveraging knowledge likely lead better interpretation models.therefore distinguish first-order models, use knowledge encodedWikipedia articles, second-order models, also incorporate knowledge encodedinter-article links. Similarly, refer information obtained inter-articlelinks second-order information.rule, presence link implies relation concepts connects.example, article United States links Washington, D.C. (countrycapital) North America (the continent country situated). also linksmultitude concepts, definitely related source concept, albeitdifficult define relations; links include United States DeclarationIndependence, President United States, Elvis Presley.However, observations reveal existence link always implytwo articles strongly related.4 fact, many words phrases typical Wikipediaarticle link articles entries corresponding concepts.example, Education subsection article United States gratuitouslinks concepts High school, College, Literacy rate. Therefore, orderuse Wikipedia links semantic interpretation, essential filter linked conceptsaccording relevance text fragment interpreted.intuitive way incorporate concept relations examine number top-scoringconcepts,Eto boost scores concepts linked them. Let ESA(1) (t) =(1)(1)w1 , . . . , wn interpretation vector term t. define second-level interpretation term(2)ESA(2) (t) = w1 , . . . , wn(2)(2)wi(1)= wiX+E(1)wj{j|link(cj ,ci )}Using < 1 ensures linked concepts taken reduced weights.experiments used = 0.5.4. opposite also truethe absence link may simply due oversight. Adafre de Rijke(2005) studied problem discovering missing links Wikipedia.449fiGabrilovich & Markovitch2.3.2 Concept Generality Filternew concepts identified links equally useful. Relevance newlyadded concepts certainly important, criterion. Supposegiven input text Google search. additional concept likelyuseful characterize input: Nigritude ultramarine (a specially crafted meaninglessphrase used search engine optimization contest) Website? suppose inputartificial intelligence concept likely contribute representationinput, John McCarthy (computer scientist) Logic? believeexamples, second concept would useful overly specific.Consequently, conjecture add linked concepts sparingly, takinggeneral concepts triggered them. judgegenerality concepts? may tricky achieve general case (no punintended), propose following task-oriented criterion. Given two concepts ca cb ,compare numbers links pointing them. Then, say ca generalcb number incoming links least order magnitude larger, is,log10 (#inlinks(ca )) log10 (#inlinks(cb )) > 1.show examples additional concepts identified using inter-article links Section 4.5.1. Section 4.5.4 evaluate effect using inter-article links additionalknowledge source. section also specifically examine effect usinggeneral linked concepts (i.e., adding concepts general conceptstriggered them).3. Using Explicit Semantic Analysis Computing SemanticRelatedness Textssection discuss application semantic interpretation methodologyautomatic assessment semantic relatedness words texts.53.1 Automatic Computation Semantic Relatednessrelated cat mouse? preparing manuscript writing article? ability quantify semantic relatedness texts underlies many fundamental tasks computational linguistics, including word sense disambiguation, informationretrieval, word text clustering, error correction (Budanitsky & Hirst, 2006). Reasoning semantic relatedness natural language utterances routinely performedhumans remains unsurmountable obstacle computers. Humans judge textrelatedness merely level text words. Words trigger reasoning much deeperlevel manipulates conceptsthe basic units meaning serve humans organizeshare knowledge. Thus, humans interpret specific wording documentmuch larger context background knowledge experience. Lackingelaborate resources, computers need alternative ways represent texts reasonthem.Explicit Semantic Analysis represents text interpretation vectors high-dimensional space concepts. representation, computing semantic relatedness texts5. Preliminary results research reported Gabrilovich Markovitch (2007a).450fiWikipedia-based Semantic InterpretationBuilding Semantic Interpreterword1wordiBuilding weightedinverted indexWikipediawordnWeighted listconcepts(= Wikipediaarticles)Weightedinverted indexUsing Semantic InterpreterText1SemanticinterpreterVectorcomparisonRelatednessestimationText2WeightedvectorWikipediaconceptsFigure 1: Knowledge-based semantic interpretersimply amounts comparing vectors. Vectors could compared using varietymetrics (Zobel & Moffat, 1998); use cosine metric throughout experimentsreported paper. Figure 1 illustrates process.3.2 Implementation Detailsused Wikipedia snapshot November 11, 2005. parsing Wikipedia XMLdump, obtained 1.8 Gb text 910,989 articles. Although Wikipedia almostmillion articles, equally useful feature generation. articles correspond overly specific concepts (e.g., Metnal, ninth level Mayan underworld),otherwise unlikely useful subsequent text categorization (e.g., specific dateslist events happened particular year). articles short,cannot reliably classify texts onto corresponding concepts. developed setsimple heuristics pruning set concepts, discarding articles fewer100 non stop words fewer 5 incoming outgoing links. also discard articles describe specific dates, well Wikipedia disambiguation pages, category pageslike. pruning, 171,332 articles left defined concepts usedfeature generation. processed text articles first tokenizing it, removingstop words rare words (occurring fewer 3 articles), stemmed remainingwords; yielded 296,157 distinct terms.451fiGabrilovich & Markovitch3.2.1 Preprocessing Wikipedia XML DumpWikipedia data publicly available online http://download.wikimedia.org.data distributed XML format, several packaged versions available: article texts,edit history, list page titles, interlanguage links etc. project, use articletexts, ignore information article authors page modification history.building semantic interpreter, perform number operations distributedXML dump:simplify original XML removing fields used featuregeneration, author ids last modification times.Wikipedia syntax defines proprietary format inter-article links, whereas namearticle referred enclosed brackets (e.g., [United States]). maparticles numeric ids, article build list ids articles refersto. also count number incoming outgoing links article.Wikipedia defines redirection mechanism, maps frequently used variant namesentities canonical names. examples, United States Americamapped United States. resolve redirections initial preprocessing.Another frequently used mechanism templates, allows articles includefrequently reused fragments text without duplication, including pre-definedoptionally parameterized templates fly. speed subsequent processing,resolve template inclusions beginning.also collect anchor texts point article.preprocessing stage yields new XML file, used building featuregenerator.3.2.2 Effect Knowledge BreadthWikipedia constantly expanded new material volunteer editors contributenew articles extend existing ones. Consequently, conjectured additioninformation beneficial ESA, would rely larger knowledge base.test assumption, also acquired newer Wikipedia snapshot March 26,2006. Table 1 presents comparison amount information two Wikipediasnapshots used. number articles shown table reflects total numberarticles date snapshot. next table line (the number conceptsused) reflects number concepts remained pruning explainedbeginning Section 3.2.following sections confirm using larger knowledge base beneficialESA, juxtaposing results obtained two Wikipedia snapshots. Therefore,dimensionality reduction performed, input text fragment represented space 171,332 features (or 241,393 features case laterWikipedia snapshot); course, many features zero values, featurevectors sparse.452fiWikipedia-based Semantic InterpretationCombined article textNumber articlesConcepts usedDistinct termsWikipedia snapshotNovember 11, 20051.8 Gb910,989171,332296,157Wikipedia snapshotMarch 23, 20062.9 Gb1,187,839241,393389,202Table 1: Comparison two Wikipedia snapshots3.2.3 Inverted Index Pruningeliminate spurious association articles words setting zero weightsconcepts whose weights given term low.algorithm pruning inverted index operates follows. first sortconcepts given word according TFIDF weights decreasing order.scan resulting sequence concepts sliding window length 100, truncatesequence difference scores first last concepts windowdrops 5% highest-scoring concept word (which positioned firstsequence). technique looks fast drops concept scores, would signifyconcepts tail sequence loosely associated word (i.e.,even though word occurred articles corresponding concepts,truly characteristic article contents). evaluated principled approachesobserving values first second derivatives, data seemednoisy reliable estimation derivatives. researchers studied use derivativessimilar contexts (e.g., Begelman, Keller, & Smadja, 2006), also foundderivative alone sufficient, hence found necessary estimate magnitudepeaks means. Consequently, opted use simple efficient metric.purpose pruning eliminate spurious associations conceptsterms, mainly beneficial pruning inverted index entries commonwords occur many Wikipedia articles. Using criteria, analyzedinverted index Wikipedia version dated November 11, 2005 (see Section 3.2.2).majority terms, either fewer 100 concepts non-zero weight,concept-term weights decreased gracefully qualify pruning. prunedentries 4866 terms total 296,157 terms. Among terms whose conceptvector pruned, term link largest number concepts non-zeroweight106,988of retained 838 concepts (0.8%); another example,concept vector term number pruned 52,244 entries 1360 (2.5%).average, 24% concepts retained. pruning rates secondWikipedia version (dated March 23, 2006) similar these.3.2.4 Processing TimeUsing world knowledge requires additional computation. extra computation includes(one-time) preprocessing step semantic interpreter built, wellactual mapping input texts interpretation vectors, performed online. standard workstation, parsing Wikipedia XML dump takes 7 hours, building453fiGabrilovich & Markovitchsemantic interpreter takes less hour. semantic interpreter built,throughput (i.e., generation interpretation vectors textual input) several hundred words per second. light improvements computing semantic relatednesstext categorization accuracy report Sections 3 4, believeextra processing time well compensated for.3.3 Empirical Evaluation Explicit Semantic AnalysisHumans innate ability judge semantic relatedness texts. Human judgementsreference set text pairs thus considered correct definition, kind goldstandard computer algorithms evaluated. Several studies measuredinter-judge correlations found consistently high (Budanitsky & Hirst, 2006;Jarmasz, 2003; Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, & Ruppin, 2002a),r = 0.88 0.95. findings expectedafter all, consensus allowspeople understand other. Consequently, evaluation amounts computingcorrelation ESA relatedness scores human judgments.better evaluate Wikipedia-based semantic interpretation, also implemented semantic interpreter based another large-scale knowledge repositorythe Open DirectoryProject (ODP, http://www.dmoz.org), largest Web directory date. caseODP, concepts Ci correspond categories directory (e.g., Top/Computers/Artificial Intelligence), text di associated concept obtained poolingtogether titles descriptions URLs catalogued corresponding category. Interpretation text fragment amounts computing weighted vector ODPconcepts, ordered affinity input text. built ODP-based semanticinterpreter using ODP snapshot April 2004. implementation detailsfound previous work (Gabrilovich & Markovitch, 2005, 2007b).3.3.1 Test Collectionswork, use two datasets best knowledge largest publiclyavailable collections kind.6 test collections, use correlationcomputer-assigned scores human scores assess algorithm performance.assess word relatedness, use WordSimilarity-353 collection (Finkelstein et al.,2002a; Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, & Ruppin, 2002b),contains 353 noun pairs representing various degrees similarity.7 pair 1316 human judgements made individuals university degrees either mothertongue-level otherwise fluent command English language. Word pairsassigned relatedness scores scale 0 (totally unrelated words) 10 (very muchrelated identical words). Judgements collected word pair averaged6. Recently, Zesch Gurevych (2006) discussed automatic creation datasets assessing semanticsimilarity. However, focus work automatical generation set sufficientlydiverse word pairs, thus relieving humans need construct word lists manually. Obviously,establishing gold standard semantic relatedness word pair still performed manuallyhuman judges.7. previous studies (Jarmasz & Szpakowicz, 2003) suggested word pairs comprisingcollection might culturally biased.454fiWikipedia-based Semantic Interpretationproduce single relatedness score.8 Spearmans rank-order correlation coefficient usedcompare computed relatedness scores human judgements; non-parametric,Spearmans correlation coefficient considered much robust Pearsonslinear correlation. comparing results studies, computedSpearmans correlation coefficient human judgments based raw data.document similarity, used collection 50 documents AustralianBroadcasting Corporations news mail service (Lee, Pincombe, & Welsh, 2005; Pincombe,2004). documents 51 126 words long, covered variety topics.judges 83 students University Adelaide, Australia, paidsmall fee work. documents paired possible ways,1,225 pairs 812 human judgements (averaged pair). neutralize effectsordering, document pairs presented random order, order documentswithin pair randomized well. human judgements averagedpair, collection 1,225 relatedness scores 67 distinct values. Spearmanscorrelation appropriate case, therefore used Pearsons linear correlationcoefficient.Importantly, instructions human judges test collections specifically directedparticipants assess degree relatedness words texts involved. example,case antonyms, judges instructed consider similar ratherdissimilar.3.3.2 Prior Worknumber prior studies proposed variety approaches computing word similarityusing WordNet, Rogets thesaurus, LSA. Table 2 presents results applyingapproaches WordSimilarity-353 test collection.Jarmasz (2003) replicated results several WordNet-based methods, comparednew approach based Rogets Thesaurus. Hirst St-Onge (1998) viewedWordNet graph, considered length directionality graph path connecting two nodes. Leacock Chodorow (1998) also used length shortest graphpath, normalized maximum taxonomy depth. Jiang Conrath (1997),later Resnik (1999), used notion information content lowest node subsuming two given words. Lin (1998b) proposed computation word similarity basedinformation theory. See (Budanitsky & Hirst, 2006) comprehensive discussionWordNet-based approaches computing word similarity.According Jarmasz (2003), Rogets Thesaurus number advantages comparedWordNet, including links different parts speech, topical groupings, variety relations word senses. Consequently, method developed authorsusing Rogets source knowledge achieved much better results WordNet-basedmethods. Finkelstein et al. (2002a) reported results computing word similarity using8. Finkelstein et al. (2002a) report inter-judge agreement 0.95 WordSimilarity-353 collection.also performed assessment inter-judge agreement dataset. Following Snow,OConnor, Jurafsky, Ng (2008), divided human judges two sets averaged numericjudgements word pair among judges set, thus yielding (353 element long) vectoraverage judgments set. Spearmans correlation coefficient vectors two sets0.903.455fiGabrilovich & MarkovitchLSA-based model (Deerwester et al., 1990) trained Grolier Academic American Encyclopedia. Recently, Hughes Ramage (2007) proposed method computing semantic relatedness using random graph walks; results WordSimilarity353 dataset competitive reported Jarmasz (2003) Finkelstein et al.(2002a).Strube Ponzetto (2006) proposed alternative approach computing word similarity based Wikipedia, comparing articles whose titles words occur. discussapproach greater detail Section 5.1.Prior work assessing similarity textual documents based comparingdocuments bags words, well LSA. Lee et al. (2005) compared numberapproaches based bag words representation, used binary tfidfrepresentation word weights variety similarity measures (correlation, Jaccard,cosine, overlap). authors also implemented LSA-based model trained setnews documents Australian Broadcasting Corporation (test documents whosesimilarity computed came distribution). results experimentsreported Table 3.3.3.3 Resultsbetter understand Explicit Semantic Analysis works, let us consider similarity computation pairs actual phrases. example, given two phrases scientific articlejournal publication, ESA determines following Wikipedia concepts foundamong top 20 concepts phrase: Scientific journal, Nature (journal),Academic publication, Science (journal), Peer review. computesimilarity RNA DNA, following concepts found shared amongtop 20 lists: Transcription (genetics), Gene, RNA, Cell (biology).presence identical concepts among top concepts characterizing phraseallows ESA establish semantic similarity.Table 2 shows results applying methodology estimating relatednessindividual words, statistically significant improvements shown bold. valuesshown table represent Spearmans correlation human judgmentsrelatedness scores produced different methods. Jarmasz (2003) comparedperformance 5 WordNet-based metrics, namely, proposed Hirst St-Onge(1998), Jiang Conrath (1997), Leacock Chodorow (1998), Lin (1998b), Resnik(1999). Table 2 report performance best metrics, namely,Lin (1998b) Resnik (1999). WikiRelate! paper (Strube & Ponzetto, 2006),authors report results many 6 different method variations, reportperformance best one (based metric proposed Leacock Chodorow,1998).see, ESA techniques yield substantial improvements previous stateart results. Notably, ESA also achieves much better results another recentlyintroduce method based Wikipedia (Strube & Ponzetto, 2006). provide detailedcomparison approach latter work Section 5.1. Table 3 shows resultscomputing relatedness entire documents. tables, show statisticalsignificance difference performance ESA-Wikipedia (March 26, 2006456fiWikipedia-based Semantic InterpretationAlgorithmWordNet-based techniques (Jarmasz, 2003)Rogets Thesaurus-based technique (Jarmasz, 2003)LSA (Finkelstein et al., 2002a)WikiRelate! (Strube & Ponzetto, 2006)MarkovLink (Hughes & Ramage, 2007)ESA-Wikipedia (March 26, 2006 version)ESA-Wikipedia (November 11, 2005 version)ESA-ODPSpearmanscorrelationhuman judgements0.350.550.560.500.550.750.740.65Stat.significance(p-value)4 10161.3 1063.4 1068 1091.6 1060.0044Table 2: Spearmans rank correlation word relatedness scores human judgementsWordSimilarity-353 collectionAlgorithmBag words (Lee et al., 2005)LSA (Lee et al., 2005)ESA-Wikipedia (March 26, 2006 version)ESA-Wikipedia (November 11, 2005 version)ESA-ODPPearsonscorrelationhuman judgements0.10.50.600.720.710.69Stat.significance(p-value)4 10195 1080.07Table 3: Pearsons correlation text relatedness scores human judgements Lee etal.s document collectionversion) algorithms9 using Fishers z-transformation (Press, Teukolsky,Vetterling, & Flannery, 1997, Section 14.5).test collections, Wikipedia-based semantic interpretation superiorODP-based one; word relatedness task, superiority statistically significantp < 0.005. believe two factors contribute phenomenon. First, axesmulti-dimensional interpretation space ideally independent possible.hierarchical organization Open Directory reflects generalization relationconcepts obviously violates independence requirement. Second, increaseamount training data building ODP-based semantic interpreter, crawledURLs listed ODP. allowed us increase amount textual data severalorders magnitude, also brought non-negligible amount noise,common Web pages. hand, Wikipedia articles virtually noise-free,9. Whenever range values available, compared ESA-Wikipedia best-performing methodrange.457fiGabrilovich & Markovitchmostly qualify Standard Written English. Thus, textual descriptions Wikipediaconcepts arguably focused ODP concepts.also essential note experiments, using newer Wikipedia snapshotleads better results (although difference performance two versionsadmittedly small).evaluated effect using second-order interpretation computing semanticrelatedness texts, yielded negligible improvements. hypothesizereason finding computing semantic relatedness essentially uses availableWikipedia concepts, second-order interpretation slightly modify weightsexisting concepts. next section, describes application ESA textcategorization, trim interpretation vectors sake efficiency, considerhighest-scoring concepts input text fragment. scenario, secondorder interpretation positive effect actually improves accuracy textcategorization (Section 4.5.4). happens selected Wikipedia conceptsused augment text representation, second-order approach selectively addshighly related concepts identified analyzing Wikipedia links.4. Using Explicit Semantic Analysis Text Categorizationsection evaluate benefits using external knowledge text categorization.104.1 Background Text CategorizationText categorization (TC) deals assigning category labels natural language documents. Categories come fixed set labels (possibly organized hierarchy)document may assigned one categories. Text categorization systemsuseful wide variety tasks, routing news e-mail appropriate corporatedesks, identifying junk email, correctly handling intelligence reports.majority existing text classification systems represent text bag words,use variant vector space model various weighting schemes (Salton & McGill,1983). Thus, features commonly used text classification weighted occurrencefrequencies individual words. State-of-the-art systems text categorization use varietyinduction techniques, support vector machines, k-nearest neighbor algorithm,neural networks. bag words (BOW) method effective easy mediumdifficulty categorization tasks category document identified severaleasily distinguishable keywords. However, performance becomes quite limiteddemanding tasks, dealing small categories short documents.various attempts extend basic BOW approach. Several studiesaugmented bag words n-grams (Caropreso, Matwin, & Sebastiani, 2001; Peng& Shuurmans, 2003; Mladenic, 1998; Raskutti, Ferra, & Kowalczyk, 2001) statisticallanguage models (Peng, Schuurmans, & Wang, 2004). Others used linguistically motivatedfeatures based syntactic information, available part-of-speech taggingshallow parsing (Sable, McKeown, & Church, 2002; Basili, Moschitti, & Pazienza, 2000).Additional studies researched use word clustering (Baker & McCallum, 1998; Bekker10. Preliminary results research reported Gabrilovich Markovitch (2006).458fiWikipedia-based Semantic Interpretationman, 2003; Dhillon, Mallela, & Kumar, 2003), neural networks (Jo, 2000; Jo & Japkowicz,2005; Jo, 2006), well dimensionality reduction techniques LSA (Deerwesteret al., 1990; Hull, 1994; Zelikovitz & Hirsh, 2001; Cai & Hofmann, 2003). However,attempts mostly limited success.believe bag words approach inherently limited, usepieces information explicitly mentioned documents,vocabulary consistently used throughout. BOW approach cannot generalizewords, consequently words testing document never appeared trainingset necessarily ignored. synonymous words appear infrequently trainingdocuments used infer general principle covers cases. Furthermore,considering words unordered bag makes difficult correctly resolve sensepolysemous words, longer processed native context.shortcomings stem fact bag words method access wealthworld knowledge possessed humans, therefore easily puzzled facts termscannot easily deduced training set.4.2 Using ESA Feature Generationpropose solution augments bag words knowledge-based features.Given document classified, would like use ESA represent documenttext space Wikipedia concepts. However, text categorization crucially differentcomputing semantic relatedness (cf. Section 3) two important respects.First, computing semantic relatedness essentially one-off task, is, givenparticular pair text fragments, need quantify relatedness priorexamples specific task. cases, words text fragments likelymarginal usefulness, especially two fragments one word long.happens data available us limited two input fragments,cases share words, all.hand, supervised text categorization, one usually given collectionlabeled text documents, one induce text categorizer. Consequently,words occur training examples serve valuable featuresthisbag words approach born. observed earlier work (Gabrilovich& Markovitch, 2005, 2007b), ill-advised completely replace bag wordsgenerated concepts, instead advantageous enrich bag words. Rather,opt augment bag words carefully selected knowledge concepts, becomenew features document. refer process feature generation,actually construct new document features beyond bag words.Second, enriching document representation text categorization possibleWikipedia concepts extremely expensive computationally, machine learningclassifier learned augmented feature space. representation obviouslytakes lot storage space, cannot processed efficiently multitudeconcepts involved (whose number easily reach hundreds thousands). Therefore,text categorization task, prune interpretation vectors retain numberhighest-scoring concepts input text fragment.459fiGabrilovich & MarkovitchUsing multi-resolution approach feature generation believe considering document single unit often misleading: text might diversereadily mapped right set concepts, notions mentioned briefly mayoverlooked. Instead, partition document series non-overlapping segments(called contexts), generate features finer level. context mappednumber Wikipedia concepts knowledge base, pooling conceptstogether describe entire document results multi-faceted classification. way,resulting set concepts represents various aspects sub-topics covereddocument.Potential candidates contexts simple sequences words, linguistically motivated chunks sentences paragraphs. optimal resolution document segmentation determined automatically using validation set. earlier work (Gabrilovich & Markovitch, 2005, 2007b), proposed principled multiresolution approach simultaneously partitions document several levels linguistic abstraction (windows words, sentences, paragraphs, taking entire documentone big chunk), performs feature generation levels. relysubsequent feature selection step eliminate extraneous features, preservinggenuinely characterize document.essential emphasize using multi-resolution approach makes senseinterpretation vectors pruned retain number highest-scoring concepts context. explained above, exactly case text categorization.Without pruning, producing interpretation vectors context summingwould equivalent simply multiplying weight concept constantfactor. order explain situation different presence pruning, let usconsider example. Suppose long document mentions particulartopic last paragraph. Since topic central document, N topscoring concepts documents interpretation vector unlikely cover topic.Although likely covered concepts I, concepts lower weightgoing pruned. However, produce interpretation vectors alsoparagraph document, retain N highest-scoring concepts each,concepts generated last paragraph cover . Consequently, representation joined set concepts generated document. many text categorizationtasks, documents labeled particular topic even mention topic briefly,hence generating features describing topics important.Feature generation Feature generation performed prior text categorization.document transformed series local contexts, representedinterpretation vectors using ESA. top ten concepts vectors pooled together,give rise generated features document, added bag words.Since concepts approach correspond Wikipedia articles, constructed features alsocorrespond articles. Thus, set features generated document viewedrepresenting set Wikipedia articles relevant document contents.constructed features used conjunction original bag words.resulting set optionally undergoes feature selection, discriminative featuresretained document representation.460fiWikipedia-based Semantic InterpretationBasicfeaturesFeatureselectionSelectedfeaturesLabeleddocumentsFeaturevaluationInductionalgorithmClassifierClassifierClassifieddocumentsLabeledfeaturevectorsTrainingTestingTestingdocumentsFeaturevaluationFigure 2: Standard approach text categorization.Feature generationFeatureconstructionFeatureselectionGeneratedfeaturesWikipediaLabeleddocumentsFeaturevaluationInductionalgorithmClassifierLabeledfeaturevectorsFigure 3: Induction text classifiers using proposed framework feature generation.Figure 2 depicts standard approach text categorization. Figure 3 outlinesproposed feature generation framework; observe Feature generation box replacesFeature selection box framed bold Figure 2.essential note use encyclopedia simply increase amounttraining data text categorization; neither use text corpus collectword co-occurrence statistics. Rather, use knowledge distilled encyclopediaenrich representation documents, text categorizer inducedaugmented, knowledge-rich feature space.461fiGabrilovich & Markovitch4.3 Test Collectionssection gives brief description test collections used evaluate methodology. provide much detailed description test collections Appendix B.1. Reuters-21578 (Reuters, 1997) historically often used dataset text categorization research. Following common practice, used ModApte split (9603 training,3299 testing documents) two category sets, 10 largest categories 90 categoriesleast one training testing example.2. 20 Newsgroups (20NG) (Lang, 1995) well-balanced dataset 20 categoriescontaining 1000 documents each.3. Movie Reviews (Movies) (Pang, Lee, & Vaithyanathan, 2002) defines sentimentclassification task, reviews express either positive negative opinionmovies. dataset 1400 documents two categories (positive/negative)4. Reuters Corpus Volume (RCV1) (Lewis, Yang, Rose, & Li, 2004)800,000 documents. speed experiments, used subset RCV1 17,808 training documents (dated 2027/08/96) 5,341 testing ones (2831/08/96). FollowingBrank, Grobelnik, Milic-Frayling, Mladenic (2002), used 16 Topic 16 Industrycategories constitute representative samples full groups 103 354 categories,respectively. also randomly sampled Topic Industry categories 5 sets10 categories each.115. OHSUMED (Hersh, Buckley, Leone, & Hickam, 1994) subset MEDLINE,contains 348,566 medical documents. document contains title, two-thirds(233,445) also contain abstract. document labeled average 13 MeSH12categories (out total 14,000). Following Joachims (1998), used subset documents1991 abstracts, taking first 10,000 documents training next10,000 testing. limit number categories experiments, randomlygenerated 5 sets 10 categories each.13Using 5 datasets allows us comprehensively evaluate performanceapproach. Specifically, comparing 20 Newsgroups two Reuters datasets (Reuters21578 Reuters Corpus Volume 1), observe former substantiallynoisy since data obtained Usenet newsgroups, Reuters datasetssignificantly cleaner. Movie Reviews collection presents example sentimentclassification, different standard (topical) text categorization. Finally,OHSUMED dataset presents example comprehensive taxonomy 14,000categories. explain next section, also used dataset create collectionlabeled short texts, allowed us quantify performance methodtexts.Short Documents also derived several datasets short documents testcollections described above. Recall one-third OHSUMED documentstitles abstract, therefore considered short documents as-is. usedrange documents defined above, considered without abstracts;yielded 4,714 training 5,404 testing documents. datasets, created11. full definition category sets used available Table 8 (see Section B.4).12. http://www.nlm.nih.gov/mesh13. full definition category sets used available Table 9 (see Section B.5).462fiWikipedia-based Semantic Interpretationshort document original document taking title latter (withexception Movie Reviews, documents titles).noted, however, substituting title full document poormans way obtain collection classified short documents. documents firstlabeled categories, human labeller saw document entirety. particular,category might assigned document basis facts mentionedbody, even though information may well missing (short) title. Thus, takingcategories original documents genuine categories title oftenmisleading. However, know publicly available test collections shortdocuments, decided construct datasets explained above. Importantly, OHSUMEDdocuments without abstracts classified humans; workingOHSUMED-derived dataset thus considered pure experiment.4.4 Experimentation Procedureused support vector machines14 learning algorithm build text categorizers, sinceprior studies found SVMs best performance text categorization (Sebastiani,2002; Dumais, Platt, Heckerman, & Sahami, 1998; Yang & Liu, 1999). Following establishedpractice, use precision-recall break-even point (BEP) measure text categorizationperformance. BEP defined terms standard measures precision recall,precision proportion true document-category assignments among assignments predicted classifier, recall proportion true document-categoryassignments also predicted classifier. obtained either tuningclassifier precision equal recall, sampling several (precision, recall) pointsbracket expected BEP value interpolating (or extrapolating, eventsampled points lie side).two Reuters datasets OHSUMED report micro- macro-averagedBEP, since categories differ size significantly. Micro-averaged BEP operatesdocument level primarily affected categorization performance larger categories.hand, macro-averaged BEP averages results individual categories, thussmall categories training examples large impact overall performance.Reuters datasets (Reuters-21578 RCV1) OHSUMED used fixedtrain/test split defined Section 4.3, consequently used macro sign test (S-test)(Yang & Liu, 1999) assess statistical significance differences classifier performance. 20NG Movies performed 4-fold cross-validation, used paired t-testassess significance. also used non-parametric Wilcoxon signed-ranks test (Demsar, 2006) compare baseline FG-based classifiers multiple data sets.latter case, individual measurements taken (micro- macro-averaged) BEPvalues observed dataset.14. used SVM light implementation (Joachims, 1999) default parameters. earlierwork feature selection (Gabrilovich & Markovitch, 2004), conducted thorough experimentationwide range values C parameter, found major importancedatasets; consequently, leave parameter default setting well.463fiGabrilovich & Markovitch4.4.1 Text Categorization Infrastructureconducted experiments using text categorization platform designdevelopment named Hogwarts 15 (Davidov, Gabrilovich, & Markovitch, 2004). optedbuild comprehensive new infrastructure text categorization, surprisingly software tools publicly available researchers, available allowlimited control operation. Hogwarts facilitates full-cycle text categorizationincluding text preprocessing, feature extraction, construction, selection weighting, followed actual classification cross-validation experiments. system currentlyprovides XML parsing, part-of-speech tagging (Brill, 1995), sentence boundary detection,stemming (Porter, 1980), WordNet (Fellbaum, 1998) lookup, variety feature selectionalgorithms, TFIDF feature weighting schemes. Hogwarts 250 configurableparameters control modus operandi minute detail. Hogwarts interfacesSVM, KNN C4.5 text categorization algorithms, computes standard measurescategorization performance. Hogwarts designed particular emphasisprocessing efficiency, portably implemented ANSI C++ programming languageC++ Standard Template Library. system built-in loaders Reuters-21578(Reuters, 1997), RCV1 (Lewis et al., 2004), 20 Newsgroups (Lang, 1995), Movie Reviews(Pang et al., 2002), OHSUMED (Hersh et al., 1994), additional datasetseasily integrated modular way.document undergoes following processing steps. Document text first tokenized, title words replicated twice emphasize importance. Then, stopwords, numbers mixed alphanumeric strings removed, remaining wordsstemmed. bag words next merged set features generateddocument analyzing contexts explained Section 4.2, rare features occurringfewer 3 documents removed.Since earlier studies found BOW features indeed useful SVM textcategorization16 (Joachims, 1998; Rogati & Yang, 2002; Brank et al., 2002; Bekkerman,2003; Leopold & Kindermann, 2002; Lewis et al., 2004), take bag wordsentirety (with exception rare features removed previous step). generatedfeatures, however, undergo feature selection using information gain criterion.17 Finally,feature weighting performed using ltc TF.IDF function (logarithmic term frequencyinverse document frequency, followed cosine normalization) (Salton & Buckley, 1988;Debole & Sebastiani, 2003).4.4.2 Baseline Performance Hogwartsdemonstrate performance basic text categorization implementation (column Baseline Table 4) consistent state art reflectedpublished studies (all using SVM). Reuters-21578, Dumais et al. (1998) achieved15. Hogwarts School Witchcraft Wizardry educational institution attended Harry Potter(Rowling, 1997).16. Gabrilovich Markovitch (2004) described class problems feature selection bagwords actually improves SVM performance.17. course, feature selection performed using training set documents.464fiWikipedia-based Semantic Interpretationmicro-BEP 0.920 10 categories 0.870 categories. 20NG18 , Bekkerman(2003) obtained BEP 0.856. Pang et al. (2002) obtained accuracy 0.829 Movies19 .minor variations performance due differences data preprocessingdifferent systems; example, Movies dataset worked raw HTML filesrather official tokenized version, order recover sentence paragraphstructure contextual analysis. RCV1 OHSUMED, direct comparison published results difficult limited category sets date spandocuments speed experimentation.4.4.3 Using Feature Generatorcore engine Explicit Semantic Analysis implemented explained Section 3.2.used multi-resolution approach feature generation, classifying document contexts level individual words, complete sentences, paragraphs, finally entiredocument.20 context, features generated 10 best-matching conceptsproduced feature generator.4.5 Wikipedia-based Feature Generationsection, report results experimental evaluation methodology.4.5.1 Qualitative Analysis Feature Generationstudy process feature generation number actual examples.Feature Generation per se illustrate approach, show features generatedseveral text fragments. Whenever applicable, provide short explanations generatedconcepts; cases, explanations taken Wikipedia (Wikipedia, 2006).Text: Wal-Mart supply chain goes real timeTop 10 generated features: (1) Wal-Mart; (2) Sam Walton; (3) Sears HoldingsCorporation; (4) Target Corporation; (5) Albertsons; (6) ASDA; (7) RFID; (8)Hypermarket; (9) United Food Commercial Workers; (10) Chain storeSelected explanations: (2) Wal-Mart founder; (5) prominent competitors WalMart; (6) Wal-Mart subsidiary UK; (7) Radio Frequency Identification,technology Wal-Mart uses extensively manage stock; (8) superstore(a general concept, Wal-Mart specific example); (9) labor union18. comparison results reported Bekkerman (2003) administered single test run (i.e.,without cross-validation), taking first 3/4 postings newsgroup training, resttesting.19. comparison results reported Pang et al. (2002) administered single test run (i.e.,without cross-validation), taking first 2/3 data opinion type training, resttesting.20. 20NG dataset exception, owing high level intrinsic noise renders identificationsentence boundaries extremely unreliable, causes word-level feature generation producemany spurious classifications. Consequently, dataset restrict multi-resolution approachindividual paragraphs entire document only.465fiGabrilovich & Markovitchtrying organize Wal-Marts workers; (10) general concept,Wal-Mart specific exampleparticularly interesting juxtapose features generated fragmentscontain ambiguous words. end, show features generated two phrasescontain word bank two different senses, Bank America (financialinstitution) Bank Amazon (river bank). readily seen, feature generation methodology capable performing word sense disambiguationconsidering ambiguous words context neighbors.Text: Bank AmericaTop 10 generated features: (1) Bank; (2) Bank America; (3) BankAmerica Plaza (Atlanta); (4) Bank America Plaza (Dallas); (5) MBNA(a bank holding company acquired Bank America); (6) VISA (creditcard); (7) Bank America Tower, New York City; (8) NASDAQ; (9) MasterCard; (10) Bank America corporate CenterText: Bank AmazonTop 10 generated features: (1) Amazon River; (2) Amazon Basin; (3) Amazon Rainforest; (4) Amazon.com; (5) Rainforest; (6) Atlantic Ocean; (7)Brazil; (8) Loreto Region (a region Peru, located Amazon Rainforest);(9) River; (10) Economy Brazilmethod, however, 100% accurate, cases generates featuressomewhat relevant even irrelevant input text. example, show outcome feature generation title earlier article(Gabrilovich & Markovitch, 2006). concept, show list input wordstriggered (the words stemmed sorted decreasing ordercontribution).Text: Overcoming Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization Encyclopedic KnowledgeTop 10 generated features:1. Encyclopedia (encyclopedia, knowledge, Wikipedia, text)2. Wikipedia (Wikipedia, enhance, encyclopedia, text)3. Enterprise content management (category, knowledge, text, overcome, enhance)4. Performance problem (bottleneck, category, enhance)5. Immanuel Kant (category, knowledge, overcome)6. Tooth enamel (brittleness, text, enhance)7. Lucid dreaming (enhance, text, knowledge, category)8. Bottleneck (bottleneck)9. Java programming language (category, bottleneck, enhance)466fiWikipedia-based Semantic Interpretation10. Transmission Control Protocol (category, enhance, overcome)generated features clearly relevant input, Encyclopedia,Wikipedia, Enterprise content management. Others, however, spurious,Tooth enamel Transmission Control Protocol. Since processfeature generation relies bag words matching concepts input text,suffers BOW shortcomings mentioned (Section 4.1). Consequently,features generated corresponding Wikipedia articles happenshare words input text, even though words characteristicarticle whole. explained above, method successfully operatepresence extraneous features due use feature selection.way, generated features informative predicting document categoriesfiltered out, informative features actually retained learningclassification model.Using Inter-article Links Generating Additional Features Section 1,presented algorithm generates additional features using inter-article links relations concepts. follows, show series text fragments,fragment show (a) features generated regular FG algorithm, (b) featuresgenerated using Wikipedia links, (c) general features generated using links.see examples, features constructed using links often relevantinput text.Text: Google searchRegular feature generation: (1) Search engine; (2) Google Video; (3) Google;(4) Google (search); (5) Google Maps; (6) Google Desktop; (7) Google (verb);(8) Google News; (9) Search engine optimization; (10) Spamdexing (search enginespamming)Features generated using links: (1) PageRank; (2) AdWords; (3) AdSense; (4)Gmail; (5) Google Platform; (6) Website; (7) Sergey Brin; (8) Google bomb; (9)MSN Search; (10) Nigritude ultramarine (a meaningless phrase used searchengine optimization contest 2004)general features only: (1) Website; (2) Mozilla Firefox; (3) PortableDocument Format; (4) Algorithm; (5) World Wide WebText: programming toolsRegular feature generation: (1) Tool; (2) Programming tool; (3) Computersoftware; (4) Integrated development environment; (5) Computer-aided software engineering; (6) Macromedia Flash; (7) Borland; (8) Game programmer;(9) C programming language; (10) Performance analysisFeatures generated using links: (1) Compiler; (2) Debugger; (3) Source code;(4) Software engineering; (5) Microsoft; (6) Revision control; (7) Scriptinglanguage; (8) GNU; (9) Make; (10) Linuxgeneral features only: (1) Microsoft; (2) Software engineering; (3)Linux; (4) Compiler; (5) GNU467fiGabrilovich & Markovitch4.5.2 Effect Feature GenerationTable 4 shows results using Wikipedia-based feature generation, significantimprovements (p < 0.05) shown bold. different rows table correspondperformance different datasets subsets, defined Section 4.3.consistently observed larger improvements macro-averaged BEP, dominatedcategorization effectiveness small categories. goes line expectationscontribution encyclopedic knowledge especially prominent categories training examples. Categorization performance improved virtuallydatasets, notable improvements 30.4% RCV1 18% OHSUMED.Using Wilcoxon test, found Wikipedia-based classifier significantly superior baseline p < 105 micro- macro-averaged cases. resultsclearly demonstrate advantage knowledge-based feature generation.prior work (Gabrilovich & Markovitch, 2005, 2007b), also performedfeature generation text categorization using alternative source knowledge, namely,Open Directory Project (ODP). results using Wikipedia competitiveusing ODP, slight advantage Wikipedia. Observe also Wikipediaconstantly updated numerous volunteers around globe, ODP virtuallyfrozen nowadays. Hence, future expect obtain improvementsusing newer versions Wikipedia.Effect Knowledge Breadth also examined effect performing featuregeneration using newer Wikipedia snapshot, explained Section 3.2.2. Appendixreports results experiment, show small consistent improvement dueusing larger knowledge base.4.5.3 Classifying Short Documentsconjectured Wikipedia-based feature generation particularly usefulclassifying short documents.Table 5 presents results evaluation datasets defined Section 4.3.majority cases, feature generation yielded greater improvement short documents regular documents. Notably, improvements particularly highOHSUMED, pure experimentation short documents possible (see Section 4.3).According Wilcoxon test, Wikipedia-based classifier significantly superiorbaseline p < 2 106 . findings confirm hypothesis encyclopedic knowledge particularly useful categorizing short documents,inadequately represented standard bag words.4.5.4 Using Inter-article links Concept RelationsUsing inter-article links generating additional features, observed improvements text categorization performance short documents. see Table 6,absolute majority cases using links generate general featuressuperior strategy. explain Section 2.3, inter-article links viewed relationsconcepts represented articles. Consequently, using links allows us468fiWikipedia-based Semantic InterpretationDatasetBaselinemicro macroBEP BEPReuters-21578 (10 cat.) 0.925 0.874Reuters-21578 (90 cat.) 0.877 0.602RCV1 Industry-160.642 0.595RCV1 Industry-10A0.421 0.335RCV1 Industry-10B0.489 0.528RCV1 Industry-10C0.443 0.414RCV1 Industry-10D0.587 0.466RCV1 Industry-10E0.648 0.605RCV1 Topic-160.836 0.591RCV1 Topic-10A0.796 0.587RCV1 Topic-10B0.716 0.618RCV1 Topic-10C0.687 0.604RCV1 Topic-10D0.829 0.673RCV1 Topic-10E0.758 0.742OHSUMED-10A0.518 0.417OHSUMED-10B0.656 0.500OHSUMED-10C0.539 0.505OHSUMED-10D0.683 0.515OHSUMED-10E0.442 0.54220NG0.854Movies0.813Wikipediamicro macroBEP BEP0.932 0.8870.883 0.6030.645 0.6170.448 0.4370.523 0.5660.468 0.4310.595 0.4590.641 0.6120.843 0.6610.798 0.6820.723 0.6560.699 0.6180.839 0.6880.765 0.7550.538 0.4920.667 0.5340.545 0.5220.692 0.5460.462 0.5750.8620.842Improvementmicro macroBEPBEP+0.8% +1.5%+0.7% +0.2%+0.5% +3.7%+6.4% +30.4%+7.0% +7.2%+5.6% +4.1%+1.4% -1.5%-1.1% +1.2%+0.8% +11.8%+0.3% +16.2%+1.0% +6.1%+1.7% +2.3%+1.2% +2.2%+0.9% +1.8%+3.9% +18.0%+1.7% +6.8%+1.1% +3.4%+1.3% +6.0%+4.5% +6.1%+1.0%+3.6%Table 4: effect feature generation long documents469fiGabrilovich & MarkovitchDatasetBaselinemicro macroBEP BEPReuters-21578 (10 cat.) 0.868 0.774Reuters-21578 (90 cat.) 0.793 0.479RCV1 Industry-160.454 0.400RCV1 Industry-10A0.249 0.199RCV1 Industry-10B0.273 0.292RCV1 Industry-10C0.209 0.199RCV1 Industry-10D0.408 0.361RCV1 Industry-10E0.450 0.410RCV1 Topic-160.763 0.529RCV1 Topic-10A0.718 0.507RCV1 Topic-10B0.647 0.560RCV1 Topic-10C0.551 0.471RCV1 Topic-10D0.729 0.535RCV1 Topic-10E0.643 0.636OHSUMED-10A0.302 0.221OHSUMED-10B0.306 0.187OHSUMED-10C0.441 0.296OHSUMED-10D0.441 0.356OHSUMED-10E0.164 0.20620NG0.699Wikipediamicro macroBEP BEP0.877 0.7930.803 0.5060.481 0.4370.293 0.2560.337 0.3630.294 0.3270.452 0.3790.474 0.4340.769 0.5420.725 0.5440.643 0.5640.573 0.5070.735 0.5630.670 0.6530.405 0.2990.383 0.2560.528 0.4130.460 0.4020.219 0.2800.749ImprovementmicromacroBEPBEP+1.0%+2.5%+1.3% +5.6%+5.9% +9.2%+17.7% +28.6%+23.4% +24.3%+40.7% +64.3%+10.8% +5.0%+5.3% +5.9%+0.8%+2.5%+1.0% +7.3%-0.6%+0.7%+4.0% +7.6%+0.8% +5.2%+4.2% +2.7%+34.1% +35.3%+25.2% +36.9%+19.7% +39.5%+4.3% +12.9%+33.5% +35.9%+7.1%Table 5: Feature generation short documents470fiWikipedia-based Semantic InterpretationDatasetBaselinemicroBEPReuters-21578 (10 cat.) 0.868Reuters-21578 (90 cat.) 0.793RCV1 Industry-160.454RCV1 Topic-160.76320NG0.699DatasetReuters-21578 (10 cat.)Reuters-21578 (90 cat.)RCV1 Industry-16RCV1 Topic-1620NGmacroBEP0.7740.4790.4000.529WikipediaWikipedia+ linksmicro macroBEP BEP0.877 0.7930.803 0.5060.481 0.4370.769 0.5420.749Improvementbaseline+1.0% +2.5%+1.3% +5.6%+5.9% +9.2%+0.8% +2.5%+7.1%micro macroBEP BEP0.878 0.7960.804 0.5060.486 0.4450.769 0.5390.753Improvementbaseline+1.2% +2.8%+1.4% +5.6%+7.1% +11.3%+0.8% +1.9%+7.7%Wikipedia+ links(more generalfeatures only)micro macroBEPBEP0.880 0.8010.809 0.5070.488 0.4440.775 0.5450.756Improvementbaseline+1.4% +3.5%+2.0% +5.8%+7.5% +11.0%+1.6% +3.0%+8.1%Table 6: Feature generation short documents using inter-article linksidentify additional concepts related context analyzed, leads betterrepresentation context additional relevant generated features.5. Related Worksection puts methodology context related prior work.past, number attempts represent meaning naturallanguage texts. Early research computational linguistics focused deep natural languageunderstanding, strived represent text semantics using logical formulae (Montague,1973). However, task proved difficult little progress madedevelop comprehensive grammars non-trivial fragments language. Consequently,mainstream research effectively switched statistically-based methods (Manning& Schuetze, 2000).Although studies tried explicitly define semantic representation,modus operandi frequently induces particular representation system. Distributional similarity methods (Lee, 1999) compute similarity pair words w1 w2 comparingdistributions words given two, e.g., comparing vectors probabilities P (v|w1 ) P (v|w2 ) large vocabulary V words (v V ). Therefore,techniques seen representing meaning word w vector conditionalprobabilities words given w. Dagan, Marcus, Markovitch (1995) refinedtechnique considering co-occurrence probabilities word left right contextual neighbors. example, word water would represented vectorleft neighbors drink, pour, clean, vector right neighborsmolecule, level, surface. Lin (1998a) represented word meaning considering syntactic roles words co-occur sentence. example,471fiGabrilovich & Markovitchsemantics word water would represented vector triples (water,obj-of, drink) (water, adj-mod, clean). Qiu Frei (1993) proposed methodconcept-based query expansion; however, expanded queries additional wordsrather features corresponding semantic concepts.Latent Semantic Analysis probably similar method prior research,explicitly represents meaning text fragment. LSA manipulatingvector so-called latent concepts, obtained SVD decompositionword-by-document matrix training corpus. CYC (Lenat, 1995; Lenat, Guha, Pittman,Pratt, & Shepherd, 1990) represents semantics words elaborate networkinterconnected richly-annotated concepts.contrast, method represents meaning piece text weighted vectorknowledge concepts. Importantly, entries vector correspond unambiguoushuman-defined concepts rather plain words, often ambiguous. ComparedLSA, approach benefits large amounts manually encoded human knowledge,opposed defining concepts using statistical analysis training corpus. ComparedCYC, approach streamlines process semantic interpretation dependmanual encoding inference rules. exception LSA, prior approachessemantic interpretation explicitly represent semantics individual words, requireextra level sophistication represent longer texts. Conversely, approach representsmeaning texts uniform way regardless length.5.1 Semantic Similarity Semantic Relatednessstudy deal semantic relatedness rather semantic similaritysemantic distance, also often used literature. extensive surveyrelatedness measures, Budanitsky Hirst (2006) argued notion relatednessgeneral similarity, former subsumes many different kind specificrelations, including meronymy, antonymy, functional association, others.maintained computational linguistics applications often require measures relatednessrather narrowly defined measures similarity. example, word sensedisambiguation use related words context, merely similar words.Budanitsky Hirst (2006) also argued notion semantic distance mightconfusing due different ways used literature.approach estimating semantic relatedness words somewhat reminiscentdistributional (or co-occurrence) similarity (Lee, 1999; Dagan, Lee, & Pereira, 1999). Indeed, compare meanings words comparing occurrence patterns acrosslarge collection natural language documents. However, compilation documents arbitrary, rather, documents aligned encyclopedia articles,focused single topic. Furthermore, distributional similarity methodsinherently suitable comparing individual words, method computesimilarity arbitrarily long texts.Prior work field mostly focused semantic similarity words, using R&G(Rubenstein & Goodenough, 1965) list 65 word pairs M&C (Miller & Charles, 1991)list 30 word pairs. similarity relation considered, using lexical resourcesoften successful enough, reaching Pearsons correlation 0.700.85 human472fiWikipedia-based Semantic Interpretationjudgements (Budanitsky & Hirst, 2006; Jarmasz, 2003). case, lexical techniqueseven slight edge ESA-Wikipedia, whose correlation human scores 0.723M&C 0.816 R&G. 21 However, entire language wealth consideredattempt capture general semantic relatedness, lexical techniques yield substantially inferior results (see Table 2). WordNet-based technique, considergeneralization (is-a) relation words, achieve correlation 0.330.35human judgements (Budanitsky & Hirst, 2006; Jarmasz, 2003). Jarmasz & SzpakowiczsELKB system (Jarmasz, 2003) based Rogets Thesaurus (Roget, 1852) achieves highercorrelation 0.55 due use richer set relations.Studying semantic similarity relatedness words related assessing similarityrelations. example task establish word pairs carpenter:woodmason:stone relationally similar, words pairs stand relation(profession:material). State art results relational similarity based LatentRelational Analysis (Turney, 2006, 2005).Sahami Heilman (2006) proposed use Web source additional knowledgemeasuring similarity short text snippets. end, defined kernel functionsends two snippets queries search engine, compares bags wordstwo sets returned documents. major limitation techniqueapplicable short texts, sending long text query search engine likelyreturn even results all. hand, approach applicabletext fragments arbitrary length. Additional studies explored Web gatherinformation computing word similarity include (Turney, 2001) (Metzler, Dumais, &Meek, 2007). main difference works method latteruses structured representation human knowledge defined Wikipedia concepts.above-mentioned based techniques inherently limited individual words,adaptation comparing longer texts requires extra level complexity (Mihalceaet al., 2006). contrast, method treats words texts essentiallyway.Strube Ponzetto (2006) also used Wikipedia computing semantic relatedness.However, method, called WikiRelate!, radically different ours. Given pairwords w1 w2 , WikiRelate! searches Wikipedia articles, p1 p2 , respectivelycontain w1 w2 titles. Semantic relatedness computed based variousdistance measures p1 p2 . measures either rely textspages, path distances within category hierarchy Wikipedia. approach,hand, represents word weighted vector Wikipedia concepts. Semanticrelatedness computed comparing two concept vectors.Thus, differences two approaches are:1. WikiRelate! process words actually occur titles Wikipedia articles.ESA requires word appears within text Wikipedia articles.2. WikiRelate! limited single words ESA compare texts length.21. WikiRelate! (Strube & Ponzetto, 2006) achieved relatively low scores 0.310.54 domains.473fiGabrilovich & Markovitch3. WikiRelate! represents semantics word either text articleassociated it, node category hierarchy. ESA muchstructured semantic representation consisting vector Wikipedia concepts.Indeed, shown Section 3.3, richer representation ESA yields much betterresults.5.2 Feature Generation Text Categorizationdate, quite attempts made deviate orthodox bag wordsparadigm, usually limited success. particular, representations based phrases(Lewis, 1992; Dumais et al., 1998; Fuernkranz, Mitchell, & Riloff, 1998), named entities(Kumaran & Allan, 2004), term clustering (Lewis & Croft, 1990; Bekkerman, 2003)explored. However, none techniques could possibly overcome problemunderlying various examples reviewed paperlack world knowledge.Feature generation techniques found useful variety machine learning tasks(Markovitch & Rosenstein, 2002; Fawcett, 1993; Matheus, 1991). techniques searchnew features describe target concept better ones suppliedtraining instances. number proposed feature generation algorithms (Pagallo & Haussler, 1990; Matheus & Rendell, 1989; Hu & Kibler, 1996; Murphy & Pazzani, 1991; Hirsh& Japkowicz, 1994) led significant improvements performance range classification tasks. However, even though feature generation established research areamachine learning, works applied text processing (Kudenko & Hirsh,1998; Mikheev, 1998; Cohen, 2000; Scott, 1998; Scott & Matwin, 1999). contrastapproach, techniques use exogenous knowledge.prior work (Gabrilovich & Markovitch, 2005, 2007b), assumed externalknowledge available form generalization hierarchy, used Open DirectoryProject example. method, however, number drawbacks,corrected using Wikipedia.First, requiring knowledge repository define is-a hierarchy limits choiceappropriate repositories. Moreover, hierarchical organization embodies one particularrelation nodes (generalization), numerous relations, relatedness, meronymy/holonymy chronology, ignored. Second, large-scale hierarchiestend extremely unbalanced, relative size branches disproportionately large small due peculiar views editors. phenomena indeedcommon ODP. example, Top/Society branch heavily dominated onechildrenReligion Spirituality; Top/Science branch dominatedBiology child; considerable fraction mass Top/Recreation concentratedPets. Finally, learn scope every ODP concept, short textual descriptionsconcepts augmented crawling Web sites cataloged ODP. procedureallowed us accumulate many gigabytes worth textual data, price, textsobtained Web often quite far formal writing plagued noise.Crawling typical Web site often brings auxiliary material littlesite theme, legal disclaimers, privacy statements, help pages.paper proposed use world knowledge encoded Wikipedia, arguably largest knowledge repository Web. Compared ODP, Wikipedia474fiWikipedia-based Semantic Interpretationpossesses several advantageous properties. First, articles much cleaner typicalWeb pages, mostly qualify standard written English. Although Wikipedia offersseveral orthogonal browsing interfaces, structure fairly shallow, proposetreat Wikipedia essentially hierarchy. way, mapping tex fragments ontorelevant Wikipedia concepts yields truly multi-faceted classification text, avoidsproblem unbalanced hierarchy branches. Moreover, requiring knowledgerepository hierarchically organized, approach suitable new domains,ontology available. Finally, Wikipedia articles heavily cross-linked, wayreminiscent linking Web. conjectured links encode many interesting relations concepts, constitute important source informationaddition article texts. explored using inter-article links Section 4.5.4.5.2.1 Feature Generation Using Electronic DictionariesSeveral studies performed feature construction using WordNet electronic dictionary(Fellbaum, 1998) domain-specific dictionaries (Scott, 1998; Scott & Matwin,1999; Urena-Lopez, Buenaga, & Gomez, 2001; Wang, McKay, Abbass, & Barlow, 2003;Bloehdorn & Hotho, 2004).Scott Matwin (1999) attempted augment conventional bag-of-words representation additional features, using symbolic classification system Ripper (Cohen,1995). study evaluated features based syntactically22 statistically motivatedphrases, well WordNet synsets 23 . latter case, system performed generalizations using hypernym hierarchy WordNet, completely replaced bag wordsbag synsets. using hypernyms allowed Ripper produce generalcomprehensible rules achieved performance gains small classification tasks, performance benefits could obtained larger tasks, even suffereddegradation classification accuracy. Consistent published findings(Lewis, 1992; Dumais et al., 1998; Fuernkranz et al., 1998), phrase-based representationalso yield significant performance benefits bag-of-words approach.24Urena-Lopez et al. (2001) used WordNet conjunction Rocchio (Rocchio, 1971)Widrow-Hoff (Lewis, Schapire, Callan, & Papka, 1996; Widrow & Stearns, 1985, Chapter 6) linear classifiers fine-tune category vectors. Wang et al. (2003) used MedicalSubject Headings (MeSH, 2003) replace bag words canonical medical terms;Bloehdorn Hotho (2004) used similar approach augment Reuters-21578 documentsWordNet synsets OHSUMED medical documents MeSH terms.noted, however, WordNet originally designed powerfulknowledge base, rather lexical database suitable peculiar lexicographersneeds. Specifically, WordNet following drawbacks used knowledge basetext categorization:22. Identification syntactic phrases performed using noun phrase extractor built top partspeech tagger (Brill, 1995).23. synset WordNet notion sense shared group synonymous words.24. Sebastiani (2002) casts use bag words versus phrases utilizing lexical semantics rathercompositional semantics. Interestingly, bag-of-words approaches (notably, KNN) may consideredcontext-sensitive assume independence either features (terms) categories (Yang& Pedersen, 1997).475fiGabrilovich & MarkovitchWordNet fairly small coveragefor test collections used paper,50% unique words missing WordNet. particular, many propernames, slang domain-specific technical terms included WordNet,designed general-purpose dictionary.Additional information synsets (beyond identity) limited.WordNet implements differential rather constructive lexical semanticstheory, glosses accompany synsets mainly designed distinguishsynsets rather provide definition sense concept. Usage examplesoccasionally constitute part gloss serve purpose. Withoutauxiliary information, reliable word sense disambiguation almost impossible.WordNet designed professional linguists trained recognize minutedifferences word senses. result, common words far many distinctsenses useful information retrieval (Mihalcea, 2003); example, wordmake many 48 senses verb alone. fine-grained distinctionssynsets present additional difficulty word sense disambiguation.approach techniques use WordNet manipulate collectionconcepts. However, number crucial differences. previous studiesperformed feature generation individual words only. approach handle arbitrarily long short text fragments alike. Considering words context allows approachperform word sense disambiguation. Approaches using WordNet cannot achieve disambiguation information synsets limited merely words,Wikipedia concepts associated huge amounts text. Even individual words,approach provides much sophisticated mapping words concepts,analysis large bodies texts associated concepts. allows us representmeaning words (or texts) weighted combination concepts, mapping wordWordNet amounts simple lookup, without weights. Furthermore, WordNetsenses word mutually exclusive. approach, concepts reflect differentaspects input, thus yielding weighted multi-faceted representation text.Appendix illustrate limitations WordNet specific example,juxtapose WordNet-based Wikipedia-based representation.5.2.2 Using Unlabeled Examplesbest knowledge, exception studies used WordNet,attempts date automatically use large-scale repositories structured background knowledge feature generation. interesting approach using nonstructured background knowledge proposed Zelikovitz Hirsh (2000). workuses collection unlabeled examples intermediaries comparing testing examplestraining ones. Specifically, unknown test instance appearresemble labeled training instances, unlabeled examples similar mayused bridges. Using approach, possible handle situationtraining test document words common. unlabeled documentsutilized define cosine similarity metric, used KNN algorithmactual text categorization. approach, however, suffers efficiency problems,476fiWikipedia-based Semantic Interpretationlooking intermediaries compare every two documents makes necessary explorecombinatorial search space.subsequent paper, Zelikovitz Hirsh (2001) proposed alternative way useunlabeled documents background knowledge. work, unlabeled texts pooledtogether training documents compute Latent Semantic Analysis (LSA) (Deerwester et al., 1990) model. LSA analyzes large corpus unlabeled text, automaticallyidentifies so-called latent concepts using Singular Value Decomposition. resultingLSA metric facilitates comparison test documents training documents. addition unlabeled documents significantly increases amount data wordco-occurrence statistics estimated, thus providing solution text categorization problems training data particularly scarce. However, subsequent studies foundLSA rarely improve strong baseline established SVM, often even resultsperformance degradation (Wu & Gunopulos, 2002; Liu, Chen, Zhang, Ma, & Wu, 2004).contrast LSA, manipulates virtual concepts, methodology relies usingconcepts identified described humans.6. Conclusionspaper proposed Explicit Semantic Analysisa semantic interpretation methodology natural language processing. order render computers knowledgeworld, use Wikipedia build semantic interpreter, represents meaningtexts high-dimensional space knowledge-based concepts. concepts correspond Wikipedia articles, methodology provides fully automatic way tapcollective knowledge tens hundreds thousands people. conceptbased representation text contains information cannot deduced inputtext alone, consequently supersedes conventional bag words representation.believe important aspects proposed approach abilityaddress synonymy polysemy, arguably two important problemsNLP. Thus, two texts discuss topic using different words,conventional bag words approach able identify commonality.hand, mere fact two texts contain word necessarilyimply discuss topic, since word could used two texts twodifferent meanings. believe concept-based representation allows generalizationsrefinements partially address synonymy polysemy.Consider, example, following text fragment (taken Appendix C): groupEuropean-led astronomers made photograph appears planet orbitinganother star. so, would first confirmed picture world beyond solarsystem. fifth concept generated fragment Extrasolar planet,exactly topic text, even though words mentioned input.generated concepts (e.g., Astronomy Planetary orbit) also highlycharacteristic astronomy-related texts. additions enrich text representation,increase chances finding common features texts. also essential notethat, course, generated concepts need match features documents.Even concepts match, gain valuable insights document contents.477fiGabrilovich & Markovitchsucceeded make automatic use encyclopedia without deep language understanding, specially crafted inference rules relying additional common-sense knowledgebases. made possible applying standard text classification techniques matchdocument texts relevant Wikipedia articles.Empirical evaluation confirmed value Explicit Semantic Analysis two common tasks natural language processing. Compared previous state art,using ESA results significant improvements automatically assessing semantic relatedness words texts. Specifically, correlation computed relatedness scoreshuman judgements increased r = 0.56 0.75 (Spearman) individual wordsr = 0.60 0.72 (Pearson) texts. contrast existing methods, ESA offersuniform way computing relatedness individual words arbitrarily long textfragments. Using ESA perform feature generation text categorization yielded consistent improvements across diverse range datasets. Recently, performancebest text categorization systems became similar, previous work mostly achieved smallimprovements. Using Wikipedia source external knowledge allowed us improveperformance text categorization across diverse collection datasets.noted although recent study (Giles, 2005) found Wikipedia accuracy rival Encyclopaedia Britannica, arguably Wikipedia articlesequally high quality. one hand, Wikipedia notion featured articles(http://en.wikipedia.org/wiki/Featured Article), consideredbest articles Wikipedia, determined Wikipedias editors. Currently, fewer0.1% articles achieve status. hand, many articles incomplete (socalled stubs), might even contain information incorrect representconsensus among editors. Yet cases, Wikipedia content might pronespamming, despite editorial process attempts review recent changes. believemethod overly susceptible cases, long majority contentcorrect. Arguably, except outright vandalism, spamming would likely modifyarticles contain information related topic article, importantessential majority readers. long newly added content remainsrelevant gist article, method likely able correctly determineinput texts article relevant for. However, proper evaluation robustnessmethod presence imperfect content beyond scope article.believe research constitutes step towards enriching natural languageprocessing humans knowledge world. hope Explicit SemanticAnalysis also useful NLP tasks beyond computing semantic relatednesstext categorization, intend investigate future work. Recently,used ESA improve performance conventional information retrieval (Egozi,Gabrilovich, & Markovitch, 2008). work, augmented queries documentsgenerated features, documents indexed augmented space wordsconcepts. Potthast, Stein, Anderka (2008) Sorg Cimiano (2008) adaptedESA multi-lingual cross-lingual information retrieval.another recent study, Gurevych et al. (2007) applied methodology computingword similarity German, also information retrieval task searched jobdescriptions given users description career interests, found method superiorWordNet-based approach. Importantly, study also confirms method478fiWikipedia-based Semantic Interpretationeasily adapted languages English, using version Wikipediacorresponding desired target language.future work, also intend apply ESA word sense disambiguation. Currentapproaches word sense disambiguation represent contexts contain ambiguous wordsusing bag words augmented part-of-speech information. believe representation contexts greatly improved use feature generation mapcontexts relevant knowledge concepts. Anecdotal evidence (such examples presented Section 4.5.1) implies method promise improving state artword sense disambiguation. work capitalized inter-article links Wikipediaseveral ways, future work intend investigate elaborate techniquesleveraging high degree cross-linking Wikipedia articles.Wiki technology underlying Wikipedia project often used nowadays variety open-editing initiatives. include corporate intranets use Wiki primarydocumentation tool, well numerous domain-specific encyclopedias topics rangingmathematics Orthodox Christianity.25 Therefore, believe methodologyalso used augmenting document representation many specialized domains.also essential note Wikipedia available numerous languages, differentlanguage versions cross-linked level concepts. believe informationleveraged use Wikipedia-based semantic interpretation improving machinetranslation.work proposes methodology Explicit Semantic Analysis using Wikipedia.However, ESA also implemented using repositories human knowledgesatisfy requirements listed Section 2.1. Section 3.3 reported resultsbuilding ESA-based semantic interpreter using Open Directory Project (Gabrilovich& Markovitch, 2005, 2007b). Zesch, Mueller, Gurevych (2008) proposed use Wiktionary computing semantic relatedness. future work, intend implementESA using additional knowledge repositories.Finally, readers interested using Wikipedia work, main softwaredeliverable described work Wikipedia preprocessor (WikiPrep), available onlinepart SourceForge open-source project http://wikiprep.sourceforge.net.Acknowledgmentsthank Michael D. Lee Brandon Pincombe making available document similarity data. also thank Deepak Agarwal advice assessing statistical significanceresults computing semantic relatedness. work partially supported fundingEC-sponsored MUSCLE Network Excellence.first authors current address Yahoo! Research, 2821 Mission College Blvd, SantaClara, CA 95054, USA.25. See http://en.wikipedia.org/wiki/Category:Online encyclopedias longer list examples.479fiGabrilovich & MarkovitchAppendix A. effect knowledge breadth text categorizationappendix, examine effect performing feature generation using newerWikipedia snapshot, defined Section 3.2.2. see Table 7, usinglarger amount knowledge leads average greater improvements text categorization performance. Although difference performance two versionsadmittedly small, consistent across datasets (a similar situation happens assessingrole external knowledge computing semantic relatedness, see Section 3.3.3).DatasetBaselinemicroBEPReuters-21578 (10 cat.) 0.925Reuters-21578 (90 cat.) 0.877RCV1 Industry-160.642RCV1 Industry-10A 0.421RCV1 Industry-10B 0.489RCV1 Industry-10C 0.443RCV1 Industry-10D 0.587RCV1 Industry-10E 0.648RCV1 Topic-160.836RCV1 Topic-10A0.796RCV1 Topic-10B0.716RCV1 Topic-10C0.687RCV1 Topic-10D0.829RCV1 Topic-10E0.758OHSUMED-10A0.518OHSUMED-10B0.656OHSUMED-10C0.539OHSUMED-10D0.683OHSUMED-10E0.44220NG0.854Movies0.813AveragemacroBEP0.8740.6020.5950.3350.5280.4140.4660.6050.5910.5870.6180.6040.6730.7420.4170.5000.5050.5150.542Wikipedia(26/03/06)micro macroBEP BEP0.935 0.8910.883 0.6000.648 0.6160.457 0.4500.527 0.5590.458 0.4240.607 0.4480.649 0.6070.842 0.6590.802 0.6890.725 0.6600.697 0.6270.838 0.6870.762 0.7520.545 0.4900.667 0.5290.553 0.5270.694 0.5500.461 0.5880.8590.850Improvement(26/03/06)micro macroBEPBEP+1.1% +1.9%+0.7% -0.3%+0.9% +3.5%+8.6% +34.3%+7.8% +5.9%+3.4% +2.4%+3.4% -3.9%+0.2% +0.3%+0.7% +11.5%+0.8% +17.4%+1.3% +6.8%+1.5% +3.8%+1.1% +2.1%+0.5% +1.3%+5.2% +17.5%+1.7% +5.8%+2.6% +4.4%+1.6% +6.8%+4.3% +8.5%+0.6%+4.5%+2.50% +6.84%Improvement(05/11/05)micro macroBEPBEP+0.8% +1.5%+0.7% +0.2%+0.5% +3.7%+6.4% +30.4%+7.0% +7.2%+5.6% +4.1%+1.4% -1.5%-1.1% +1.2%+0.8% +11.8%+0.3% +16.2%+1.0% +6.1%+1.7% +2.3%+1.2% +2.2%+0.9% +1.8%+3.9% +18.0%+1.7% +6.8%+1.1% +3.4%+1.3% +6.0%+4.5% +6.1%+1.0%+3.6%+2.11% +6.71%Table 7: effect feature generation using newer Wikipedia snapshot (datedMarch 26, 2006)480fiWikipedia-based Semantic InterpretationAppendix B. Test Collections Text CategorizationAppendix provides detailed description test collections used evaluateknowledge-based feature generation text categorization.B.1 Reuters-21578data set contains one year worth English-language stories distributedReuters newswire 19861987, arguably often used test collectiontext categorization research. Reuters-21578 cleaned version earlier release namedReuters-22173, contained errors duplicate documents.collection contains 21578 documents (hence name) SGML format. those,12902 documents categorized, i.e., assigned category label marked belongingcategory. documents explicit classification; is,reasonably belong categories (judged content), marked so. Several train/test splits collection defined, ModApte (Modified Apte)commonly used one. ModApte split divides collection chronologically,allocates first 9603 documents training, rest 3299 documents testing.documents labeled 118 categories; 016 labels per document,average 1.04. category distribution extremely skewed: largest category(earn) 3964 positive examples, 16 categories one positive example.Several category sets defined collection:10 largest categories (earn, acq, money-fx, grain, crude, trade, interest, ship, wheat, corn).90 categories least one document training set one testing set(Yang, 2001).Galavotti, Sebastiani, Simi (2000) used set 115 categories least onetraining example (three categories, cottonseed, f-cattle sfr trainingexamples ModApte split).full set 118 categories least one positive example either trainingtesting set.Following common practice, used ModApte split two category sets, 10 largestcategories 90 categories least one training testing example.B.2 20 Newsgroups (20NG)20 Newsgroups collection (Lang, 1995) comprised 19997 postings 20 Usenetnewsgroups. documents single label, defined name newsgroupsent to; 4% documents cross-posted, hence severallabels. newsgroup contains exactly 1000 positive examples, exceptionsoc.religion.christian contains 997.categories quite close scope, example, comp.sys.ibm.pc.hardwarecomp.sys.mac.hardware, talk.religion.misc soc.religion.christian. document481fiGabrilovich & Markovitchposted single newsgroup may reasonably considered appropriate groups(the author may simply known similar groups, thus cross-postedmessage); naturally poses additional difficulty classification.noted Internet news postings informal, therefore documents frequently contain non-standard abbreviated words, foreign words, propernames, well large amount markup characters (used attribution authorshipmessage separation).B.3 Movie ReviewsMovie Reviews collection (Pang et al., 2002) presents example sentiment classification, different standard (topical) text categorization. collectioncontains 1400 reviews movies, half express positive sentiment (opinion)movie, half negative. reviews collected rec.arts.movies.reviewsnewsgroup, archived Internet Movie Database (IMDB, http://www.imdb.com).classification problem case determine semantic orientation document, rather relate content one predefined topics. problemarguably difficult topical text categorization, since notion semantic orientation quite general. saw collection opportunity apply feature generationtechniques new task.Recent works semantic orientation include (Turney & Littman, 2002; Turney, 2002;Pang et al., 2002).26 two former studies used unsupervised learning techniques basedlatent semantic indexing, estimating semantic distance given documenttwo reference words represent polar opinions, namely, excellent poor.latter work used classical TC techniques.B.4 Reuters Corpus Version 1 (RCV1)RCV1 newest corpus released Reuters (Lewis et al., 2004; Rose, Stevenson, &Whitehead, 2002). considerably larger predecessor, contains 800,000news items, dated August 20, 1996 August 19, 1997. stories labeled3 category sets, Topics, Industries Regions.Topics close nature category set old Reuters collection(Reuters-21578). 103 topic codes, 3.24 categories per documentaverage. topics organized hierarchy, Hierarchy Policy required category assigned document, ancestors hierarchyassigned well. result, many 36% Topic assignments26. field genre classification, attempts establish genre document, somewhat relatedsentiment classification. Examples possible genres radio news transcripts classified advertisements. work Dewdney, VanEss-Dykema, MacMillan (2001) cast problem textcategorization, using presentation features addition words. presentation features includedpart speech tags verb tenses, well mean variance statistics sentence word length,punctuation usage, amount whitespace characters. Using support vector machines actualclassification, authors found performance due presentation features alone leastgood achieved plain words, combined feature set usually resultedimprovement several percentage points.482fiWikipedia-based Semantic Interpretationdue four general categories, CCAT, ECAT, GCAT, MCAT. Consequently, micro-averaged performance scores dominated categories(Lewis et al., 2004), macro-averaging becomes interest.27 Minimum CodePolicy required document assigned least one Topic one Regioncode.Industries fine-grained Topics, therefore harder classification. categories also organized hierarchy, although HierarchyPolicy partially enforced them. 351,761 documents labeledIndustry codes.Region codes correspond geographical places, subdivided countries, regional groupings economic groupings. Lewis et al. (2004) argueRegion codes might suitable named entity recognition text categorization.experiments used Topic Industry categories. Due sheer sizecollection, processing categories set would unreasonably long, allowingconduct experiments. speed experimentation, used subset corpus17,808 training documents (dated August 2027, 1996) 5341 testing documents(dated August 2831, 1996). Following scheme introduced Brank et al. (2002),used 16 Topic 16 Industry categories, constitute representative samplefull groups 103 354 categories, respectively. also randomly sampled TopicIndustry categories 5 sets 10 categories each. Table 8 gives full definitioncategory sets used.noted Lewis et al. (2004), original RCV1 distribution contains numbererrors; particular, documents conform either Minimum CodeHierarchy Policy, labeled erratic codes. Lewis et al. (2004) proposed procedurecorrect errors, defined new version collection, named RCV1-v2 (asopposed original distribution, referred RCV1-v1 ). experimentsbased RCV1-v2.B.5 OHSUMEDOHSUMED (Hersh et al., 1994) subset MEDLINE database, contains348,566 references documents published medical journals period 19871991.reference contains publication title, two-thirds (233,445) also containabstract. document labeled several MeSH categories (MeSH, 2003).14,000 distinct categories collection, average 13 categories perdocument. OHSUMED frequently used information retrieval text categorizationresearch.Following Joachims (1998), used subset documents 1991 abstracts,taking first 10,000 documents training next 10,000 testing. limitnumber categories experiments, randomly generated 5 sets 10 categorieseach. Table 9 gives full definition category sets used.27. micro-averaged scores Topic codes much higher macro-averaged ones, seeSection 4.4.2.483fiGabrilovich & MarkovitchSet nameTopic-16Topic-10ATopic-10BTopic-10CTopic-10DTopic-10EIndustry-16Industry-10AIndustry-10BIndustry-10CIndustry-10DIndustry-10ECategories comprising sete142, gobit, e132, c313, e121, godd, ghea, e13, c183, m143,gspo, c13, e21, gpol, m14, c15e31, c41, c151, c313, c31, m13, ecat, c14, c331, c33m132, c173, g157, gwea, grel, c152, e311, c21, e211, c16c34, c13, gtour, c311, g155, gdef, e21, genv, e131, c17c23, c411, e13, gdis, c12, c181, gpro, c15, g15, c22c172, e513, e12, ghea, c183, gdip, m143, gcrim, e11, gvioi81402, i79020, i75000, i25700, i83100, i16100, i1300003, i14000,i3302021, i8150206, i0100132, i65600, i3302003, i8150103, i3640010,i9741102i47500, i5010022, i3302021, i46000, i42400, i45100, i32000, i81401,i24200, i77002i25670, i61000, i81403, i34350, i1610109, i65600, i3302020, i25700,i47510, i9741110i25800, i41100, i42800, i16000, i24800, i02000, i34430, i36101,i24300, i83100i1610107, i97400, i64800, i0100223, i48300, i81502, i34400, i82000,i42700, i81402i33020, i82003, i34100, i66500, i1300014, i34531, i16100, i22450,i22100, i42900Table 8: Definition RCV1 category sets used experimentsAppendix C. Additional Examples Feature Generation TextCategorizationAppendix, list number additional feature generation examples.Text: development T-cell leukaemia following otherwise successful treatment three patients X-linked severe combined immune deficiency (X-SCID)gene-therapy trials using haematopoietic stem cells led re-evaluationapproach. Using mouse model gene therapy X-SCID, findcorrective therapeutic gene IL2RG act contributor genesisT-cell lymphomas, one-third animals affected. Gene-therapy trialsX-SCID, based assumption IL2RG minimally oncogenic,may therefore pose risk patients.Top 10 generated features: (1) Leukemia; (2) Severe combined immunodeficiency; (3) Cancer; (4) Non-Hodgkin lymphoma; (5) AIDS; (6) ICD-10 ChapterII: Neoplasms; Chapter III: Diseases blood blood-forming organs,certain disorders involving immune mechanism; (7) Bone marrow transplant; (8) Immunosuppressive drug; (9) Acute lymphoblastic leukemia; (10) Multiple sclerosisSelected explanations: (4) particular cancer type; (6) disease code ICDInternational Statistical Classification Diseases Related Health ProblemsText: Scientific methods biology484fiWikipedia-based Semantic InterpretationSet nameOHSUMED-10AOHSUMED-10BOHSUMED-10COHSUMED-10DOHSUMED-10ECategories comprising set(parentheses contain MeSH identifiers)B-Lymphocytes (D001402);Metabolism, Inborn Errors (D008661);Creatinine (D003404); Hypersensitivity (D006967);Bone Diseases, Metabolic (D001851); Fungi (D005658);New England (D009511); Biliary Tract (D001659);Forecasting (D005544); Radiation (D011827)Thymus Gland (D013950); Insurance (D007341);Historical Geographic Locations (D017516);Leukocytes (D007962); Hemodynamics (D006439);Depression (D003863); Clinical Competence (D002983);Anti-Inflammatory Agents, Non-Steroidal (D000894);Cytophotometry (D003592); Hydroxy Acids (D006880)Endothelium, Vascular (D004730);Contraceptives, Oral, Hormonal (D003278);Acquired Immunodeficiency Syndrome (D000163);Gram-Positive Bacteria (D006094); Diarrhea (D003967);Embolism Thrombosis (D016769);Health Behavior (D015438); Molecular Probes (D015335);Bone Diseases, Developmental (D001848);Referral Consultation (D012017)Antineoplastic Immunosuppressive Agents (D000973);Receptors, Antigen, T-Cell (D011948);Government (D006076); Arthritis, Rheumatoid (D001172);Animal Structures (D000825); Bandages (D001458);Italy (D007558); Investigative Techniques (D008919);Physical Sciences (D010811); Anthropology (D000883)HTLV-BLV Infections (D006800);Hemoglobinopathies (D006453); Vulvar Diseases (D014845);Polycyclic Hydrocarbons, Aromatic (D011084);Age Factors (D000367); Philosophy, Medical (D010686);Antigens, CD4 (D015704);Computing Methodologies (D003205);Islets Langerhans (D007515); Regeneration (D012038)Table 9: Definition OHSUMED category sets used experiments485fiGabrilovich & MarkovitchTop 10 generated features: (1) Biology; (2) Scientific classification; (3) Science; (4) Chemical biology; (5) Binomial nomenclature; (6) Nature (journal);(7) Social sciences; (8) Philosophy biology; (9) Scientist; (10) HistorybiologySelected explanations: (5) formal method naming species biologyText: quavering voices, parents grandparents killed WorldTrade Center read names victims solemn recitation today, markingthird anniversary terror attacks. ceremony one many plannedUnited States around world honor memory nearly 3,000 victims9/11.Top 10 generated features: (1) September 11, 2001 attack memorials services; (2) United Airlines Flight 93; (3) Aftermath September 11, 2001attacks; (4) World Trade Center; (5) September 11, 2001 attacks; (6) Oklahoma City bombing; (7) World Trade Center bombing; (8) Arlington NationalCemetery; (9) World Trade Center site; (10) Jewish bereavementSelected explanations: (2) one four flights hijacked September 11, 2001;(6) terrorist attack Oklahoma City 1995; (8) American military cemeteryText: U.S. intelligence cannot say conclusively Saddam Hussein weaponsmass destruction, information gap complicating White House effortsbuild support attack Saddams Iraqi regime. CIA advised topadministration officials assume Iraq weapons mass destruction.agency given President Bush smoking gun, according U.S.intelligence administration officials.Top 10 generated features: (1) Iraq disarmament crisis; (2) Yellowcake forgery; (3) Senate Report Pre-War Intelligence Iraq; (4) Iraq weaponsmass destruction; (5) Iraq Survey Group; (6) September Dossier; (7) Iraqwar; (8) Scott Ritter; (9) Iraq War Rationale; (10) Operation Desert FoxSelected explanations: (2) falsified intelligence documents Iraqs allegedattempt purchase yellowcake uranium; (6) paper Iraqs weapons massdestruction published UK government 2002; (8) UN weapons inspectorIraq; (10) US UK joint military campaign Iraq 1998another example, consider pair contexts contain word jaguar,first one contains ambiguous word sense car model, secondonein sense animal.Text: Jaguar car modelsTop 10 generated features: (1) Jaguar (car); (2) Jaguar (S-Type); (3)Jaguar X-type; (4) Jaguar E-Type; (5) Jaguar XJ; (6) Daimler Motor Company; (7) British Leyland Motor Corporation; (8) Luxury vehicles; (9) V8engine; (10) Jaguar RacingTop 10 generated features: (2), (3), (4), (5) particular Jaguar car models;(6) car manufacturing company became part Jaguar 1960; (7)486fiWikipedia-based Semantic Interpretationanother vehicle manufacturing company merged Jaguar; (9) internalcombustion engine used Jaguar car models; (10) Formula One teamused Jaguar promote brand nameText: Jaguar (Panthera onca)Top 10 generated features: (1) Jaguar; (2) Felidae; (3) Black panther;(4) Leopard; (5) Puma; (6) Tiger; (7) Panthera hybrid; (8) Cave lion; (9)American lion; (10) KinkajouTop 10 generated features: (2) family include lions, tigers, jaguars,related feline species; (10) another carnivore mammalalso show number examples generating features using inter-article links.Text: artificial intelligenceRegular feature generation: (1) Artificial intelligence; (2) A.I. (film); (3)MIT Computer Science Artificial Intelligence Laboratory; (4) Artificiallife; (5) Strong AI; (6) Swarm intelligence; (7) Computer Science; (8) Frameproblem; (9) Cognitive science; (10) Carl HewittFeatures generated using links: (1) Robot; (2) John McCarthy (computer scientist); (3) Artificial consciousness; (4) Marvin Minsky; (5) Planner programming language; (6) Actor model (a model concurrent computation formulatedCarl Hewitt colleagues); (7) Logic; (8) Scientific Community Metaphor;(9) Natural language processing; (10) Lisp programming languagegeneral features only: (1) Robot; (2) Massachusetts Institute Technology; (3) Psychology; (4) Consciousness; (5) Lisp programming languageText: group European-led astronomers made photograph appearsplanet orbiting another star. so, would first confirmed pictureworld beyond solar system.Regular feature generation: (1) Planet; (2) Solar system; (3) Astronomy; (4)Planetary orbit; (5) Extrasolar planet; (6) Pluto; (7) Jupiter; (8) Neptune; (9)Minor planet; (10) MarsFeatures generated using links: (1) Asteroid; (2) Earth; (3) Oort cloud (apostulated cloud comets); (4) Comet; (5) Sun; (6) Saturn; (7) Moon; (8) Mercury(planet); (9) Asteroid belt; (10) Orbital periodgeneral features only: (1) Earth; (2) Moon; (3) Asteroid; (4) Sun; (5)National Aeronautics Space AdministrationText: Nearly 70 percent Americans say careful eat,even say diet essential good health, according new nationwide healthpoll obesity ranked second among biggest health concerns.Regular feature generation: (1) Veganism; (2) Vegetarianism; (3) Obesity; (4)Atkins Nutritional Approach; (5) Binge eating disorder; (6) Dick Gregory; (7)Nutrition; (8) Super Size Me; (9) Health insurance; (10) Eating disorder487fiGabrilovich & MarkovitchSelected explanations: (1) philosophy avoiding animal-derived food; (6)American nutritionist; (7) documentary film individual eatsMcDonalds fast food one full month.Features generated using links: (1) Raw food diet; (2) Diabetes mellitus; (3)Healthy eating; (4) Body mass index; (5) Omega-3 fatty acid (an important nutritional component); (6) Dieting; (7) Milk; (8) United States28 ; (9) Hypertension;(10) Egg (food)general features only: (1) United States; (2) Diabetes mellitus; (3) Cancer; (4) Food; (5) McDonaldsAppendix D. Comparing Knowledge Sources Feature Generation:Wikipedia versus WordNetdemonstrate shortcomings WordNet source knowledge-based feature generation, juxtapose WordNet-based Wikipedia-based feature generation samplesentence examined Section 4.5.1 (we repeat Wikipedia context classificationsreaders convenience).used WordNet version 1.6. follows, WordNet synsets denoted curlybraces, noun verb synsets followed immediate hypernym (more generalsynset), applicable.Text: Wal-Mart supply chain goes real timerelevant Wikipedia classifications:Wal-MartSam Walton Wal-Mart founderSears Holdings Corporation, Target Corporation, Albertsons prominent competitors Wal-MartRFID Radio Frequency Identification, technology Wal-Mart usesextensively manage stockHypermarket superstore, general concept Wal-Mart specificexampleUnited Food Commercial Workers labor union tryingorganize Wal-Marts workersWordNet :{Wal-Mart} { }; (word found WordNet){supply} {indefinite quantity}; {supply} {economic process}; {provision,providing, supply supplying} {activity};28. classification quite interesting, issue discussed input text fragment characteristic American life style.488fiWikipedia-based Semantic Interpretation{supply provide, render, furnish} {give}; {issue, supply} {distribute};{provide, supply ply, cater} {give}; {add, append, supply} {state, say,tell};{chain, concatenation} {series}; {chain, chemical chain} {unit, buildingblock}; {chain} {ligament}; {chain} {business, concern, business concern,business organization}; {chain} {restraint, constraint}; {chain} {linearunit}; {range, mountain range, range mountains, chain, mountain chain,chain maountains} {geological formation, geology, formation}; {iron, irons,chain, chains} {shackle, bond, hamper, trammel, trammels}; {chain, string,strand} {necklace};{chain} {fasten, fix, secure};{go, spell, tour, turn} {shift, work shift, duty period}; {crack, fling, go, pass,whirl, offer} {attempt, effort, endeavor, endeavour, try}; {go, go game}{board game};{travel, move, go, locomote}; {go, proceed, move} {act, move}; (28verb senses omitted brevity){real number, real}; {real (Spanish coin)};{real, existent}; {real (no less stated)}; {real, true}; {real (nottaken lightly)}; {real, tangible}; {actual, genuine, literal, real}; {real (economics)}; {substantial, real, material}; {real (of property)}; {veridical, real};{real (founded practical matters)};{very, really, real, rattling};{time, clip} {case, instance, example}; {time} {time period, period,period time, amount time}; {time} {moment, minute, second, instant}; {time} {abstraction}; {clock time, time} {reading, meter reading}; {fourth dimension, time} {dimension}; {time} {experience}; {meter,time} {rhythmicity}; {prison term, sentence, time} {term};{clock, time} {quantify, measure}; {time} {schedule}; {time}{determine, shape, influence, regulate}; {time} {adjust, set};Evidently, WordNet classifications overly general diverse context wordscannot properly disambiguated. Furthermore, owing lack proper names, WordNetcannot possibly provide wealth information encoded Wikipedia, easily overcomes drawbacks WordNet. methodology proposed suffershortcomings.489fiGabrilovich & MarkovitchReferencesAdafre, S. F., & de Rijke, M. (2005). Discovering missing links Wikipedia. ProceedingsWorkshop Link Discovery: Issues, Approaches Applications (LinkKDD2005), pp. 9097.Baeza-Yates, R., & Ribeiro-Neto, B. (1999). Modern Information Retrieval. Addison Wesley,New York, NY.Baker, D., & McCallum, A. K. (1998). Distributional clustering words text classification. Croft, B., Moffat, A., Van Rijsbergen, C. J., Wilkinson, R., & Zobel, J. (Eds.),Proceedings 21st ACM International Conference Research DevelopmentInformation Retrieval, pp. 96103, Melbourne, AU. ACM Press, New York, US.Basili, R., Moschitti, A., & Pazienza, M. T. (2000). Language-sensitive text classification.Proceedings RIAO-00, 6th International Conference Recherche dInformationAssistee par Ordinateur, pp. 331343, Paris, France.Begelman, G., Keller, P., & Smadja, F. (2006). Automated tag clustering: Improving searchexploration tag space. Proceedings Collaborative Web TaggingWorkshop, conjunction 15th International World Wide Web Conference,Edinburgh, Scotland.Bekkerman, R. (2003). Distributional clustering words text categorization. Mastersthesis, Technion.Bloehdorn, S., & Hotho, A. (2004). Boosting text classification semantic features.Proceedings MSW 2004 Workshop 10th ACM SIGKDD ConferenceKnowledge Discovery Data Mining, pp. 7087.Brank, J., Grobelnik, M., Milic-Frayling, N., & Mladenic, D. (2002). Interaction featureselection methods linear classification models. Workshop Text Learningheld ICML-2002.Brill, E. (1995). Transformation-based error-driven learning natural language processing: case study part speech tagging. Computational Linguistics, 21 (4),543565.Buchanan, B. G., & Feigenbaum, E. (1982). Forward. Davis, R., & Lenat, D. (Eds.),Knowledge-Based Systems Artificial Intelligence. McGraw-Hill.Budanitsky, A., & Hirst, G. (2006). Evaluating wordnet-based measures lexical semanticrelatedness. Computational Linguistics, 32 (1), 1347.Cai, L., & Hofmann, T. (2003). Text categorization boosting automatically extractedconcepts. Proceedings 26th International Conference Research Development Information Retrieval, pp. 182189.Caropreso, M. F., Matwin, S., & Sebastiani, F. (2001). learner-independent evaluationusefulness statistical phrases automated text categorization. Chin, A. G.(Ed.), Text Databases Document Management: Theory Practice, pp. 78102.Idea Group Publishing, Hershey, US.490fiWikipedia-based Semantic InterpretationChang, M.-W., Ratinov, L., Roth, D., & Srikumar, V. (2008). Importance semanticrepresentation: Dataless classification. Proceedings 23rd AAAI ConferenceArtificial Intelligence, pp. 830835.Cohen, W. W. (1995). Fast effective rule induction. Proceedings 12th InternationalConference Machine Learning (ICML-95), pp. 115123.Cohen, W. W. (2000). Automatically extracting features concept learning web.Proceedings 17th International Conference Machine Learning.Dagan, I., Lee, L., & Pereira, F. C. N. (1999). Similarity-based models word cooccurrenceprobabilities. Machine Learning, 34 (13), 4369.Dagan, I., Marcus, S., & Markovitch, S. (1995). Contextual word similarity estimationsparse data. Computer Speech Language, 9 (2), 123152.Davidov, D., Gabrilovich, E., & Markovitch, S. (2004). Parameterized generation labeleddatasets text categorization based hierarchical directory. Proceedings27th ACM International Conference Research Development InformationRetrieval, pp. 250257.Debole, F., & Sebastiani, F. (2003). Supervised term weighting automated text categorization. Proceedings SAC-03, 18th ACM Symposium Applied Computing,pp. 784788.Deerwester, S., Dumais, S., Furnas, G., Landauer, T., & Harshman, R. (1990). Indexinglatent semantic analysis. Journal American Society Information Science,41 (6), 391407.Demsar, J. (2006). Statistical comparison classifiers multiple data sets. JournalMachine Learning Research, 7, 130.Dewdney, N., VanEss-Dykema, C., & MacMillan, R. (2001). form substance:Classification genres text. Workshop HLT KM held ACL-2001.Dhillon, I., Mallela, S., & Kumar, R. (2003). divisive information-theoretic feature clustering algorithm text classification. Journal Machine Learning Research, 3,12651287.Dumais, S., Platt, J., Heckerman, D., & Sahami, M. (1998). Inductive learning algorithmsrepresentations text categorization. Proceedings 7th ACM International Conference Information Knowledge Management, pp. 148155.Egozi, O., Gabrilovich, E., & Markovitch, S. (2008). Concept-based feature generationselection information retrieval. AAAI08.Fawcett, T. (1993). Feature Discovery Problem Solving Systems. Ph.D. thesis, UMass.Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press, Cambridge, MA.Finkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin,E. (2002a). Placing search context: concept revisited. ACM TransactionsInformation Systems, 20 (1), 116131.491fiGabrilovich & MarkovitchFinkelstein, L., Gabrilovich, E., Matias, Y., Rivlin, E., Solan, Z., Wolfman, G., & Ruppin,E. (2002b). WordSimilarity-353 test collection..Fuernkranz, J., Mitchell, T., & Riloff, E. (1998). case study using linguistic phrasestext categorization WWW. Sahami, M. (Ed.), Learning Text Categorization: Proceedings 1998 AAAI/ICML Workshop, pp. 512. AAAI Press,Madison, Wisconsin.Gabrilovich, E., & Markovitch, S. (2004). Text categorization many redundant features:Using aggressive feature selection make SVMs competitive C4.5. Proceedings21st International Conference Machine Learning, pp. 321328.Gabrilovich, E., & Markovitch, S. (2005). Feature generation text categorization using world knowledge. Proceedings 19th International Joint ConferenceArtificial Intelligence, pp. 10481053, Edinburgh, Scotand.Gabrilovich, E., & Markovitch, S. (2006). Overcoming brittleness bottleneck usingWikipedia: Enhancing text categorization encyclopedic knowledge. Proceedings 21st National Conference Artificial Intelligence, pp. 13011306.Gabrilovich, E., & Markovitch, S. (2007a). Computing semantic relatedness using wikipediabased explicit semantic analysis. Proceedings 20th International Joint Conference Artificial Intelligence, pp. 16061611.Gabrilovich, E., & Markovitch, S. (2007b). Harnessing expertise 70,000 human editors: Knowledge-based feature generation text categorization. Journal MachineLearning Research, 8, 22972345.Galavotti, L., Sebastiani, F., & Simi, M. (2000). Experiments use feature selectionnegative evidence automated text categorization. Borbinha, J., & Baker, T.(Eds.), Proceedings ECDL-00, 4th European Conference Research AdvancedTechnology Digital Libraries, pp. 5968, Lisbon, Portugal.Giles, J. (2005). Internet encyclopaedias go head head. Nature, 438, 900901.Gurevych, I., Mueller, C., & Zesch, T. (2007). be? electronic career guidancebased semantic relatedness. Proceedings 45th Annual MeetingAssociation Computational Linguistics.Hersh, W., Buckley, C., Leone, T., & Hickam, D. (1994). OHSUMED: interactiveretrieval evaluation new large test collection research. Proceedings17th ACM International Conference Research Development InformationRetrieval, pp. 192201.Hirsh, H., & Japkowicz, N. (1994). Bootstrapping training-data representations inductivelearning: case study molecular biology. Proceedings Twelfth NationalConference Artificial Intelligence, pp. 639644.Hirst, G., & St-Onge, D. (1998). Lexical chains representations context detectioncorrection malapropisms. WordNet: Electronic Lexical Database, pp.305332. MIT Press, Cambridge, MA.Hu, Y.-J., & Kibler, D. (1996). wrapper approach constructive induction.Thirteenth National Conference Artificial Intelligence, pp. 4752.492fiWikipedia-based Semantic InterpretationHughes, T., & Ramage, D. (2007). Lexical semantic relatedness random graph walks.Proceedings Conference Empirical Methods Natural Language Processing(EMNLP).Hull, D. A. (1994). Improving text retrieval routing problem using latent semanticindexing. Croft, W. B., & Van Rijsbergen, C. J. (Eds.), Proceedings 17th ACMInternational Conference Research Development Information Retrieval, pp.282289, Dublin, Ireland. Springer Verlag, Heidelberg, Germany.Jarmasz, M. (2003). Rogets thesaurus lexical resource natural language processing.Masters thesis, University Ottawa.Jarmasz, M., & Szpakowicz, S. (2003). Rogets thesaurus semantic similarity.Proceedings International Conference Recent Advances Natural LanguageProcessing, pp. 111120.Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based corpus statisticslexical taxonomy. Proceedings 10th International Conference ResearchComputational Linguistics, pp. 5763.Jo, T. (2000). Neurotextcategorizer: new model neural network text categorization.Proceedings International Conference Neural Information Processing, pp.280285, Taejon, South Korea.Jo, T. (2006). Dynamic Document Organization using Text Categorization Text Clustering. Ph.D. thesis, University Ottawa.Jo, T., & Japkowicz, N. (2005). Text clustering using NTSO. Proceedings International Joint Conference Neural Networks, pp. 558563.Joachims, T. (1998). Text categorization support vector machines: Learning manyrelevant features. Proceedings European Conference Machine Learning,pp. 137142.Joachims, T. (1999). Making large-scale SVM learning practical. Schoelkopf, B., Burges,C., & Smola, A. (Eds.), Advances Kernel Methods Support Vector Learning, pp.169184. MIT Press.Kudenko, D., & Hirsh, H. (1998). Feature generation sequence categorization. Proceedings 15th Conference American Association Artificial Intelligence,pp. 733738.Kumaran, G., & Allan, J. (2004). Text classification named entities new eventdetection. Proceedings 27th ACM International Conference ResearchDevelopment Information Retrieval, pp. 297304.Lang, K. (1995). Newsweeder: Learning filter netnews. Proceedings 12th International Conference Machine Learning, pp. 331339.Leacock, C., & Chodorow, M. (1998). Combining local context WordNet similarityword sense identification. WordNet: Electronic Lexical Database, pp. 265283.MIT Press, Cambridge, MA.Lee, L. (1999). Measures distributional similarity. Proceedings 37th AnnualMeeting ACL, pp. 2532.493fiGabrilovich & MarkovitchLee, M. D., Pincombe, B., & Welsh, M. (2005). comparison machine measures textdocument similarity human judgments. 27th Annual Meeting CognitiveScience Society (CogSci2005), pp. 12541259.Lenat, D. B. (1995). CYC: large-scale investment knowledge infrastructure. Communications ACM, 38 (11).Lenat, D. B. (1997). 2001 2001: Common sense mind HAL. HALsLegacy, pp. 194209. MIT Press.Lenat, D. B., Guha, R. V., Pittman, K., Pratt, D., & Shepherd, M. (1990). CYC: Towardsprograms common sense. Communications ACM, 33 (8).Leopold, E., & Kindermann, J. (2002). Text categorization support vector machines:represent texts input space. Machine Learning, 46, 423444.Lewis, D. D. (1992). evaluation phrasal clustered representations textcategorization task. Proceedings 15th ACM International ConferenceResearch Development Information Retrieval, pp. 3750.Lewis, D. D., & Croft, W. B. (1990). Term clustering syntactic phrases. Proceedings13th ACM International Conference Research Development InformationRetrieval, pp. 385404.Lewis, D. D., Schapire, R. E., Callan, J. P., & Papka, R. (1996). Training algorithmslinear text classifiers. Proceedings 19th ACM International ConferenceResearch Development Information Retrieval, pp. 298306.Lewis, D. D., Yang, Y., Rose, T., & Li, F. (2004). RCV1: new benchmark collectiontext categorization research. Journal Machine Learning Research, 5, 361397.Lin, D. (1998a). Automatic retrieval clustering similar words. Proceedings17th International Conference Computational Linguistics 36th Annual MeetingAssociation Computational Linguistics, pp. 768774.Lin, D. (1998b). information-theoretic definition word similarity. Proceedings15th International Conference Machine Learning, pp. 296304.Liu, T., Chen, Z., Zhang, B., Ma, W.-y., & Wu, G. (2004). Improving text classificationusing local latent semantic indexing. ICDM04, pp. 162169.Manning, C. D., & Schuetze, H. (2000). Foundations Statistical Natural Language Processing. MIT Press.Markovitch, S., & Rosenstein, D. (2002). Feature generation using general constructorfunctions. Machine Learning, 49 (1), 5998.Matheus, C. J. (1991). need constructive induction. Birnbaum, L., & Collins, G.(Eds.), Proceedings Eighth International Workshop Machine Learning, pp.173177.Matheus, C. J., & Rendell, L. A. (1989). Constructive induction decision trees.Proceedings 11th International Conference Artificial Intelligence, pp. 645650.494fiWikipedia-based Semantic InterpretationMeSH (2003). Medical subject headings (MeSH).http://www.nlm.nih.gov/mesh.National Library Medicine.Metzler, D., Dumais, S., & Meek, C. (2007). Similarity measures short segments text.Proceedings 29th European Conference Information Retrieval, pp. 1627.Mihalcea, R. (2003). Turning wordnet information retrieval resource: Systematicpolysemy conversion hierarchical codes. International Journal Pattern Recognition Artificial Intelligence (IJPRAI), 17 (1), 689704.Mihalcea, R., Corley, C., & Strapparava, C. (2006). Corpus-based knowledge-basedmeasures text semantic similarity. AAAI06, pp. 775780.Mikheev, A. (1998). Feature lattices maximum entropy models. Proceedings17th International Conference Computational Linguistics, pp. 848854.Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. Language Cognitive Processes, 6 (1), 128.Milne, D., & Witten, I. (2008). effective, low-cost measure semantic relatednessobtained wikipedia links. Proceedings AAAI-08 Workshop WikipediaArtificial Intelligence, conjunction 23rd AAAI Conference ArtificialIntelligence.Mladenic, D. (1998). Turning Yahoo automatic web-page classifier. Proceedings13th European Conference Artificial Intelligence, pp. 473474.Montague, R. (1973). proper treatment quantification ordinary English.Hintikka, J., Moravcsik, J., & Suppes, P. (Eds.), Approaches Natural Language, pp.373398. Reidel, Dordrecht.Murphy, P. M., & Pazzani, M. J. (1991). ID2-of-3: Constructive induction M-of-N concepts discriminators decision trees. Proceedings 8th InternationalConference Machine Learning, pp. 183188. Morgan Kaufmann.Pagallo, G., & Haussler, D. (1990). Boolean feature discovery empirical learning. MachineLearning, 5 (1), 7199.Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up? Sentiment classification usingmachine learning techniques. Proceedings Conference Empirical MethodsNatural Language Processing, pp. 7986.Peng, F., Schuurmans, D., & Wang, S. (2004). Augmenting naive Bayes classifiersstatistical language models. Information Retrieval, 7 (3-4), 317345.Peng, F., & Shuurmans, D. (2003). Combining naive Bayes n-gram language modelstext classification. Proceedings 25th European Conference InformationRetrieval Research (ECIR-03), pp. 335350.Pincombe, B. (2004). Comparison human latent semantic analysis (LSA) judgementspairwise document similarities news corpus. Tech. rep. DSTO-RR-0278, Information Sciences Laboratory, Defence Science Technology Organization, Department Defense, Australian Government.Porter, M. (1980). algorithm suffix stripping. Program, 14 (3), 130137.495fiGabrilovich & MarkovitchPotthast, M., Stein, B., & Anderka, M. (2008). wikipedia-based multilingual retrievalmodel. European Conference Information Retrieval.Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1997). NumericalRecipes C: Art Scientific Computing. Cambridge University Press.Qiu, Y., & Frei, H. (1993). Concept based query expansion. Proceedings ACMInternational Conference Research Development Information Retrieval.Raskutti, B., Ferra, H., & Kowalczyk, A. (2001). Second order features maximizingtext classification performance. De Raedt, L., & Flach, P. (Eds.), ProceedingsEuropean Conference Machine Learning (ECML), Lecture notes ArtificialIntelligence (LNAI) 2167, pp. 419430. Springer-Verlag.Resnik, P. (1999). Semantic similarity taxonomy: information-based measureapplication problems ambiguity natural language. Journal ArtificialIntelligence Research, 11, 95130.Reuters (1997). Reuters-21578 text categorization test collection, Distribution 1.0. Reuters.daviddlewis.com/resources/testcollections/reuters21578.Rocchio, J. J. (1971). Relevance feedback information retrieval. SMART RetrievalSystem: Experiments Automatic Document Processing, pp. 313323. Prentice Hall.Rogati, M., & Yang, Y. (2002). High-performing feature selection text classification.Proceedings International Conference Information Knowledge Management (CIKM02), pp. 659661.Roget, P. (1852). Rogets Thesaurus English Words Phrases. Longman Group Ltd.Rose, T., Stevenson, M., & Whitehead, M. (2002). Reuters Corpus Volume 1fromyesterdays news tomorrows language resources. Proceedings Third International Conference Language Resources Evaluation, pp. 713.Rowling, J. (1997). Harry Potter Philosophers Stone. Bloomsbury.Rubenstein, H., & Goodenough, J. B. (1965). Contextual correlates synonymy. Communications ACM, 8 (10), 627633.Sable, C., McKeown, K., & Church, K. W. (2002). NLP found helpful (at least onetext categorization task). Conference Empirical Methods Natural LanguageProcessing, pp. 172179.Sahami, M., & Heilman, T. (2006). web-based kernel function measuring similarityshort text snippets. WWW06, pp. 377386. ACM Press.Salton, G., & Buckley, C. (1988). Term weighting approaches automatic text retrieval.Information Processing Management, 24 (5), 513523.Salton, G., & McGill, M. (1983).McGraw-Hill.Introduction Modern Information Retrieval.Scott, S. (1998). Feature engineering symbolic approach text classification. Mastersthesis, U. Ottawa.Scott, S., & Matwin, S. (1999). Feature engineering text classification. Proceedings16th International Conference Machine Learning, pp. 379388.496fiWikipedia-based Semantic InterpretationSebastiani, F. (2002). Machine learning automated text categorization. ACM ComputingSurveys, 34 (1), 147.Snow, R., OConnor, B., Jurafsky, D., & Ng, A. Y. (2008). Cheap fast - good?evaluating non-expert annotations natural language tasks. ProceedingsConference Empirical Methods Natural Language Processing.Sorg, P., & Cimiano, P. (2008). Cross-lingual information retrieval explicit semanticanalysis. Working Notes CLEF Workshop.Strube, M., & Ponzetto, S. P. (2006). WikiRelate! Computing semantic relatedness usingWikipedia. AAAI06, pp. 14191424, Boston, MA.Turney, P. (2002). Thumbs thumbs down? Semantic orientation applied unsupervised classification reviews. Proceedings 40th Annual MeetingAssociation Computational Linguistics, pp. 417424.Turney, P. (2005). Measuring semantic similarity latent relational analysis. ProceedingsNineteenth International Joint Conference Artificial Intelligence (IJCAI-05),pp. 11361141, Edinburgh, Scotland.Turney, P. (2006). Similarity semantic relations. Computational Linguistics, 32 (3), 379416.Turney, P., & Littman, M. L. (2002). Unsupervised learning semantic orientationhundred-billion-word corpus. Tech. rep. ERB-1094, National Research CouncilCanada.Turney, P. D. (2001). Mining web synonyms: PMI-IR versus LSA TOEFL.Proceedings Twelfth European Conference Machine Learning, pp. 491502.Urena-Lopez, A., Buenaga, M., & Gomez, J. M. (2001). Integrating linguistic resourcesTC WSD. Computers Humanities, 35, 215230.Wang, B. B., McKay, R., Abbass, H. A., & Barlow, M. (2003). comparative studydomain ontology guided feature extraction. Proceedings 26th AustralianComputer Science Conference (ASCS-2003), pp. 6978.Widrow, B., & Stearns, S. (1985). Adaptive Signal Processing. Prentice Hall.Wikipedia (2006). Wikipedia, free encyclopedia.. http://en.wikipedia.org.Wu, H., & Gunopulos, D. (2002). Evaluating utility statistical phrases latentsemantic indexing text classification. IEEE International Conference DataMining, pp. 713716.Yang, Y. (2001). study thresholding strategies text categorization. Proceedings24th International Conference Research Development InformationRetrieval, pp. 137145.Yang, Y., & Liu, X. (1999). re-examination text categorization methods. Proceedings22nd International Conference Research Development InformationRetrieval, pp. 4249.Yang, Y., & Pedersen, J. (1997). comparative study feature selection text categorization. Proceedings 14th International Conference Machine Learning,pp. 412420.497fiGabrilovich & MarkovitchZelikovitz, S., & Hirsh, H. (2000). Improving short-text classification using unlabeled background knowledge assess document similarity. Proceedings 17th International Conference Machine Learning, pp. 11831190.Zelikovitz, S., & Hirsh, H. (2001). Using LSI text classification presencebackground text. Proceedings Conference Information KnowledgeManagement, pp. 113118.Zesch, T., & Gurevych, I. (2006). Automatically creating datasets measures semanticrelatedness. Proceedings ACL Workshop Linguistic Distances, pp. 1624,Sydney, Australia.Zesch, T., Mueller, C., & Gurevych, I. (2008). Using wiktionary computing semanticrelatedness. Proceedings 23rd AAAI Conference Artificial Intelligence,pp. 861866.Zobel, J., & Moffat, A. (1998). Exploring similarity space. ACM SIGIR Forum, 32 (1),1834.498fiJournal Artificial Intelligence Research 34 (2009) 255-296Submitted 10/08; published 03/09Unsupervised Methods Determining Object RelationSynonyms WebAlexander Yatesyates@temple.eduTemple UniversityComputer Information Sciences1805 N. Broad St.Wachman Hall 303APhiladelphia, PA 19122Oren Etzionietzioni@cs.washington.eduUniversity WashingtonComputer Science EngineeringBox 352350Seattle, WA 98195-2350Abstracttask identifying synonymous relations objects, synonym resolution,critical high-quality information extraction. paper investigates synonym resolution context unsupervised information extraction, neither hand-taggedtraining examples domain knowledge available. paper presents scalable, fullyimplemented system runs O(KN log N ) time number extractions, N ,maximum number synonyms per word, K. system, called Resolver, introducesprobabilistic relational model predicting whether two strings co-referential basedsimilarity assertions containing them. set two million assertionsextracted Web, Resolver resolves objects 78% precision 68% recall,resolves relations 90% precision 35% recall. Several variations Resolversprobabilistic model explored, experiments demonstrate appropriateconditions variations improve F1 5%. extension basic Resolversystem allows handle polysemous names 97% precision 95% recall dataset TREC corpus.1. IntroductionWeb Information Extraction (WIE) systems (Zhu, Nie, Wen, Zhang, & Ma, 2005; Agichtein,2006; Etzioni, Cafarella, Downey, Kok, Popescu, Shaked, Soderland, Weld, & Yates, 2005)extract assertions describe relation arguments Web text. example:(is capital of, D.C., United States)WIE systems extract hundreds millions assertions containing millions different strings Web (e.g., TextRunner system Banko, Cafarella, Soderland,Broadhead, & Etzioni, 2007). One problem becomes real challenge scaleWIE systems often extract assertions describe real-world objectrelation using different names. example, WIE system might also extractc2009AI Access Foundation. rights reserved.fiYates & Etzioni(is capital city of, Washington, U.S.)describes relationship contains different name relationargument.Synonyms prevalent text, Web corpus exception. data settwo million assertions extracted Web crawl contained half-dozen differentnames United States Washington, D.C., three capitalrelation. top 80 commonly extracted objects average 2.9 extractednames per entity, several many 10 names. top 100 commonlyextracted relations average 4.9 synonyms per relation.refer problem identifying synonymous object relation names synonymresolution. Previous techniques focused one particular aspect problem, eitherobjects relations. addition, techniques often depend large set trainingexamples, tailored specific domain assuming knowledge domainsschema. Due number diversity relations extracted, techniquesfeasible WIE systems. Schemata available Web, hand-labelingtraining examples relation would require prohibitive manual effort.response, present Resolver, novel, domain-independent, unsupervised synonymresolution system applies objects relations. Resolver clusters synonymous names together using probabilistic model informed string similaritysimilarity assertions containing names. similarity metric outperformsused similar systems cross-document entity coreference (e.g., Mann & Yarowsky,2003) paraphrase discovery (Lin & Pantel, 2001; Hasegawa, Sekine, & Grishman, 2004)respective tasks object relation synonym resolution. key questionsanswered Resolver include:1. possible effectively cluster strings large set extractions setssynonyms without using domain knowledge, manually labeled training data,external resources unavailable context Web Information Extraction?Experiments include empirical demonstration Resolver resolveobjects 78% precision 68% recall, relations 90% precision 35%recall.2. scale synonym resolution large, high-dimensional data sets? Resolverprovides scalable clustering algorithm runs time O(KN log N ) numberextractions, N , maximum number synonyms per word, K. theorycompares well even fast approximate solutions clustering large data setslarge-dimensional spaces, practice Resolver successfully runset assertions extracted 100 million Web pages.3. formalize unsupervised synonym resolution, practical benefitso? Resolver provides unsupervised, generative probabilistic modelpredicting whether two object relation names co-refer, experiments showsignificantly outperforms previous metrics distributional similarity.particular, outperforms related metric based mutual information (Lin & Pantel,2001) 193% AUC object clustering, 121% relation clustering.256fiUnsupervised Methods Determining Object Relation Synonyms4. possible use special properties functions inverse functions improveprecision synonym resolution algorithm? basic version Resolversprobabilistic model object synonymy independent relation extraction. However, intuitively clear certain relations, especially functionsinverse functions, provide especially strong evidence synonymy.Several extensions Resolver system show without hurting recall,precision object merging improved 3% using functions.5. Resolver handle polysemous names, different meanings differentcontexts? basic version Resolver assumes every name singlemeaning, present extension basic system able automaticallyhandle polysemous names. manually-cleaned data set polysemous namedentities TREC corpus, Resolver achieves precision 97.3% recall94.7% detecting proper noun coreference relationships, able outperformprevious work accuracy requiring large, unannotated corpus input.next section discusses previous work synonym resolution. Section 3 describesproblem synonym resolution formally introduces notation terminologyused throughout. Section 4 introduces Resolvers probabilistic model. Section5 describes Resolvers clustering algorithm. Section 6 presents experimentsbasic Resolver system compare performance performance previouswork synonym resolution. Section 7 describes several extensions basic Resolversystem, together experiments illustrating gains precision recall. Section8 develops extension Resolver relaxes assumption every stringsingle referent, compares Resolver experimentally previous work crossdocument entity resolution. Finally, Section 9 discusses conclusions areas futurework.2. Previous WorkSynonym resolution encompasses two tasks, finding synonyms extracted objectsrelations. Synonym resolution objects similar task cross-documententity resolution (Bagga & Baldwin, 1998), objective cluster occurrencesnamed entities multiple documents coreferential groups. Pedersen Kulkarni(Pedersen & Kulkarni, 2007; Kulkarni & Pedersen, 2008) cluster peoples names Webdocuments emails using agglomerative clustering heuristic similarity function.Li, Morie, Roth (2004a, 2004b) use Expectation-Maximization graphicalmodel databases common nicknames, honorifics, titles, etc.to achieve high accuracycross-document entity resolution task. Mann Yarowsky (2003) use combinationextracted features term vectors including proper names context cluster ambiguousnames Web. use Cosine Similarity Metric (Salton & McGill, 1983) togetherhierarchical agglomerative clustering. Resolvers main contribution bodywork proposes new, formal similarity measure works objectsrelations, demonstrates theoretically empirically scalemillions extractions. Web People Search Task (WEPS) (Artile, Sekine, & Gonzalo,2008), part SemEval 2007, involved 16 systems trying determine clusters documents257fiYates & Etzionicontaining references entity ambiguous person names like Kennedy.Section 6, show Resolver significantly outperforms Cosine Similarity Metricclustering experiments. experiments (Section 8) show Resolverable achieve similar, slightly higher performance Li et al. dataset,relying resources besides large corpus.Coreference resolution systems, like synonym resolution systems, try merge referencesobject, apply arbitrary noun phrases rather namedentities. difficulty general problem, work considered techniques informed parsers (e.g., Lappin & Leass, 1994) training data (e.g., Ng & Cardie,2002; McCarthy & Lehnert, 1995). Cardie Wagstaff (1999) use set extracted grammatical semantic features ad-hoc clustering algorithm perform unsupervisedcoreference resolution, achieving better performance MUC-6 coreference tasksupervised system. recently, Haghighi Klein (2007) use graphical model combining local salience features global entity features perform unsupervised coreference,achieving F1 score 70.1 MUC-6. Two systems use automatically extracted information help make coreference resolution decisions, much like Resolver does. Kehler,Appelt, Taylor, Simma (2004) use statistics automatically-determined predicateargument structures compare contexts pronouns potential antecedents.find adding information system relies morpho-syntactic evidencepronoun resolution provides little benefit. Bean Riloff (2004) use targetedextraction patterns find semantic constraints relationship pronounsantecedents, show use improve anaphora-resolutionsystem. Coreference resolution difficult general task synonym resolutionobjects since deals arbitrary types noun phrases. However, systems coreference resolution also information available form local sequencesalience information, lost extraction process, addressrelation synonymy.Synonym resolution relations often called paraphrase discovery paraphrase acquisition NLP literature (e.g., Barzilay & Lee, 2003; Sekine, 2005). Previous workarea (Barzilay & Lee, 2003; Barzilay & McKeown, 2001; Shinyama & Sekine, 2003;Pang, Knight, & Marcu, 2003) looked use parallel, aligned corpora,multiple translations text multiple news reports story, findparaphrases. Brockett Dolan (2005) used manually-labeled data train supervised model paraphrases. PASCAL Recognising Textual Entailment Challenge(Dagan, Glickman, & Magnini, 2006) proposes task recognizing two sentencesentail one another, given manually labeled training data, many authors submittedresponses challenge. Resolver avoids use labor-intensive resources, reliessolely automatically acquired extractions large corpus.Several unsupervised systems paraphrase discovery focused using corpusbased techniques cluster synonymous relations. Sekine (2005) uses heuristic similaritymeasure cluster relations. Davidov Rappoport (2008) use heuristic clusteringmethod find groups relation patterns used extract instances. Hasegawaet al. (2004) automatically extract relationships large corpus cluster relations,using Cosine Similarity Metric (Salton & McGill, 1983) hierarchical clusteringtechnique like Resolvers. DIRT system (Lin & Pantel, 2001) uses similarity mea258fiUnsupervised Methods Determining Object Relation Synonymssure based mutual information statistics identify relations similar givenone. Resolver provides formal probabilistic model similarity technique,applies objects relations. Section 4.3 contains fuller description differences Resolver DIRT, Section 6 describes experiments showResolvers superior performance precision recall clustering using mutualinformation similarity metric employed DIRT, well Cosine Similarity Metric.Resolvers method determining similarity two strings examplebroad class metrics called distributional similarity metrics (Lee, 1999),significant advantages traditional distributional similarity metrics synonymresolution task. metrics based underlying assumption, calledDistributional Hypothesis, Similar objects appear similar contexts. (Hindle, 1990)Previous distributional similarity metrics, however, designed comparing wordsbased terms appearing document, rather extracted properties.two important consequences: first, extracted properties nature sparserappear narrow window around words consist longer strings(at least, pairs words); second, extracted shared property provides strongerevidence synonymy arbitrary word appears together synonym,extraction mechanism designed find meaningful relationships. Resolversmetric designed take advantage relational model provided Web InformationExtraction. Section 4.3 fully describes difference Resolvers metricCosine Similarity Metric (Salton & McGill, 1983), example traditionaldistributional similarity metric. Experiments Section 6 demonstrate Resolveroutperforms Cosine Similarity Metric.many unsupervised approaches object resolution databases, unlikealgorithm approaches depend known, fixed, generally small schema.Ravikumar Cohen (2004) present unsupervised approach object resolution using Expectation-Maximization hierarchical graphical model. Several recent approaches leverage domain-specific information heuristics object resolution.example, many (Dong, Halevy, & Madhavan, 2005; Bhattacharya & Getoor, 2005, 2006)rely evidence observing strings appear arguments relationsimultaneously (e.g., co-authors publication). useful informationresolving authors citation domain, rare find relations similar properties extracted assertions. None approaches applies problem resolvingrelations. Winkler (1999) provides survey area. Several supervised learning techniques make entity resolution decisions (Kehler, 1997; McCallum & Wellner, 2004; Singla& Domingos, 2006), course systems depend availability training data,even significant number labeled examples per relation interest.One promising new approach clustering relational domain Multiple Relational Clusterings (MRC) algorithm (Kok & Domingos, 2007). approach, thoughspecific synonym resolution, find synonyms set unlabeled, relational extractions without domain-specific heuristics. approach quite recent, fardetailed experimental comparison conducted.Resolvers probabilistic model partly inspired ball-and-urns abstractioninformation extraction presented Downey, Etzioni, Soderland (2005) Resolverstask probability model different theirs, many modeling as259fiYates & Etzionisumptions (such independence extractions) made cases simplifyderivation models.Previous work Resolver (Yates & Etzioni, 2007) discussed basic versionprobabilistic model initial experimental results. work expands previous work includes new experimental comparison established mutualinformation-based similarity metric; new extension basic system (property weighting); full proofs three claims; description fast algorithm calculatingExtracted Shared Property model.3. Formal Synonym Resolution Problemsynonym resolution system WIE takes set extractions input returnsset clusters, cluster containing synonymous object strings relation strings.precisely, input data set containing extracted assertions form =(r, o1 , . . . , ), r relation string oi object string representingarguments relation. Throughout work, assertions assumed binary,n = 2.output synonym resolution system clustering, set clusters,strings D. Let set distinct strings D. clustering set C 2Sclusters C distinct, cover whole set:[=ScCc1 , c2 C. c1 c2 =cluster output clustering constitutes systems conjecture stringsinside cluster synonyms, string outside cluster synonymstring cluster.3.1 Single-Sense Assumptionformal representation synonym resolution described makes important simplifying assumption: assumed every string belongs exactly one cluster.language, however, strings often multiple meanings; i.e., polysemous. Polysemous strings cannot adequately represented using clustering stringbelongs exactly one cluster. paper, make single-sense assumption, Section 8 illustrates extension Resolver awayassumption.example representational trouble posed polysemy, consider namePresident Roosevelt. certain contexts, name synonymous PresidentFranklin D. Roosevelt, contexts synonymous President TheodoreRoosevelt. However, President Franklin D. Roosevelt never synonymous President Theodore Roosevelt. clustering three names, using notionclustering described above, synonymy relationships accurately represented.Others described alternate kinds clustering take polysemy account.example, soft clustering allows string assigned many different clusters260fiUnsupervised Methods Determining Object Relation Synonymssenses. One variation idea assign probability distribution every string,describing prior probability string belongs cluster (Li & Abe, 1998;Pereira, Tishby, & Lee, 1993). representations capture prior informationstrings. is, represent idea particular string belongcluster, probability belongs cluster, whether particular instancestring actually belong cluster. third type clustering, explicitrepresentation, stores instance string separately. string instance assignedcluster appropriate instances context. Word sense disambiguationsystems assign senses WordNet (Miller, Beckwith, Fellbaum, Gross, & Miller.,1990) implicitly use kind clustering (e.g., Ide & Veronis, 1998; Sinha & Mihalcea,2007).3.2 Subproblems Synonym Resolutionsynonym resolution problem divided two subproblems: first, measuresimilarity, probability synonymy, pairs strings S; second,form clusters elements cluster high similarity oneanother, relatively low similarity elements clusters.Resolver uses generative, probabilistic model finding similaritystrings. strings si sj , let Ri,j random variable event sifdenote event Rsj refer entity. Let Ri,ji,j true, Ri,j denoteevent false. Let Dx denote set extractions contain string|D , )x. Given S, first subtask synonym resolution find P (Ri,jsisjpairs si sj . second subtask takes probability scores pairsstrings input. output clustering S. Sections 4 5 cover Resolverssolutions subtask respectively.4. Models String Comparisonsprobabilistic model provides formal, rigorous method resolving synonymsabsence training data. two sources evidence: similarity strings(i.e., edit distance) similarity assertions appear in.second source evidence sometimes referred distributional similarity (Hindle, 1990).Section 4.1 presents simple model predicting whether pair strings synonymous based string similarity. Section 4.2 presents model called ExtractedShared Property (ESP) Model predicting whether pair strings co-refer baseddistributional similarity. Section 4.3 compares ESP model methodscomputing distributional similarity give intuition behaves. Finally, Sections 4.4 4.5 present method combining ESP model string similaritymodel come overall prediction synonymy decisions two clustersstrings.4.1 String Similarity ModelMany objects appear multiple names substrings, acronyms, abbreviations,simple variations one another. Thus string similarity important source261fiYates & Etzionievidence whether two strings co-refer (Cohen, 1998). Resolvers probabilistic StringSimilarity Model (SSM) assumes similarity function sim(s1 , s2 ): ST RIN G ST RIN G[0, 1]. model sets probability s1 co-referring s2 smoothed versionsimilarity:sim(s1 , s2 ) + 1P (Ri,j|sim(s1 , s2 )) =+increases, probability estimate transitions 1/ (at = 0) valuesimilarity function (for large ). particular choice make little differenceResolvers results, long chosen resulting probabilitynever one zero. experiments below, = 20 = 5. Monge-Elkan stringsimilarity function (Monge & Elkan, 1996) used objects, Levenshtein stringedit-distance function used relations (Cohen, Ravikumar, & Fienberg, 2003).4.2 Extracted Shared Property ModelExtracted Shared Property Model (ESP) outputs probability two strings corefer based similarity extracted assertions appear. example,extractions (invented, Newton, calculus) (invented, Leibniz, calculus)appeared data, Newton Leibniz would judged similar contextsextracted data.formally, let pair strings (r, s) called property object stringassertion (r, o, s) (r, s, o) D. pair strings (s1 , s2 ) instancerelation string r assertion (r, s1 , s2 ) D. Equivalently, propertyp = (r, s) applies o, instance = (s1 , s2 ) belongs r. ESP model outputsprobability two strings co-refer based many properties (or instances)share.example, consider strings Mars Red Planet, appear data 65926 times respectively. extracted assertions, share four properties.example, (lacks, Mars, ozone layer) (lacks, Red Planet, ozone layer) appearassertions data. ESP model determines probability Mars RedPlanet refer entity observing k, number properties applyboth; n1 , total number extracted properties Mars; n2 , total numberextracted properties Red Planet.ESP models extraction assertions generative process, much like URNSmodel (Downey et al., 2005). string si , certain number, Pi , propertiesstring written balls placed urn. Extracting ni assertions contain siamounts selecting subset size ni labeled balls.1 Properties urncalled potential properties distinguish extracted properties.model synonymy decisions, ESP uses pair urns, containing Pi Pj ballsrespectively, two strings si sj . subset Pi balls exactlabels equal-sized subset Pj balls. Let size subset Si,j . Crucially,ESP model assumes synonymous strings share many potential propertiespossible, though potential properties extracted both. non1. Unlike URNS model, balls drawn without replacement. TextRunner data containsone mention extraction, drawing without replacement tends model data accurately.262fiUnsupervised Methods Determining Object Relation Synonymssynonymous strings, set shared potential properties strict subset potentialproperties string. Thus central modeling choice ESP model is: si) number shared potential properties (S )sj synonymous (i.e., Ri,j = Ri,ji,jequal number potential properties smaller urn (min(Pi , Pj )), twofstrings synonymous (Ri,j = Ri,j) number shared potential propertiesstrictly less number properties smaller urn (Si,j < min(Pi , Pj )).ESP model makes several simplifying assumptions order make probabilitypredictions. suggested ball-and-urn abstraction, assumes ballstring equally likely selected urn. data sparsity, almostproperties rare, would difficult get better estimate priorprobability selecting particular potential property. Second, balls drawn oneurn independent draws urn. finally, assumes without knowingvalue k, every value Si,j equally likely, since better information.). derivationGiven assumptions, derive expression P (Ri,jsketchedbelow; see Appendix complete derivation. First, noteP Pjni nj total ways extracting ni nj assertions si sj . Given particular valueSi,j , number ways ni nj assertions extractedshare exactly k givenCount(k, ni , nj |Pi , Pj , Si,j ) =Si,jkassumptions,Pr,s0P (k|ni , nj , Pi , Pj , Si,j ) =Si,j kr+sr+srPi Si,j Pj Si,jni (k+r) nj (k+s)Count(k, ni , nj |Pi , Pj , Si,j )Pi P jni(1)(2)njLet Pmin = min(Pi , Pj ). result follows Bayes Rule assumptionsabove:Proposition 1 two strings si sj Pi Pj potential properties (or instances),appear extracted assertions Di Dj |Di | = ni |Dj | = nj ,share k extracted properties (or instances), probability si sj co-refer is:P (Ri,j|Di , Dj , Pi , Pj ) =P (k|ni , nj , Pi , Pj , Si,j = Pmin )XP (k|ni , nj , Pi , Pj , Si,j )(3)Si,jkSi,j PminSubstituting equation 2 equation 3 gives us complete expression probabilitylooking for.depends two hidden parameters, P P . SinceNote probability Ri,jjunsupervised synonym resolution labeled data estimate parametersfrom, parameters tied number times respective strings si sjextracted: Pi = N ni . discussion experimental methods Section 6 explainsparameter N set.Appendix B illustrates technique calculating ESP model efficiently.263fiYates & Etzioni4.3 Comparison ESP Distributional Similarity MetricsDiscovery Inference Rules Text (DIRT) (Lin & Pantel, 2001) systemsimilar previous work Resolver goals, DIRTs similarity metricdifferent ESP. Like ESP, DIRT operates triples extracted strings producessimilarity scores relations comparing distributions one relations argumentsanothers. DIRT system, however, extraction mechanism baseddependency parser. focus differences two systems similarity metrics,compare performance set extracted triples produced TextRunner,since extracted triples used DIRT available us. refer mutualinformation-based similarity metric employed DIRT system sM . importantnote sM describe implementation similarity metricdescribed Lin Pantel (2001), complete DIRT system.briefly describe sM applies set extractions. sM originallyapplied relation strings, simplicity describe way here,readily generalized metric computing similarity two argument-1strings two argument-2 strings. notational convenience, let Dx=s setextractions contain string position x. example, D2=Einstein would containextraction (discovered, Einstein, Relativity), extraction (talked with,Bohr, Einstein). Similarly, let Dx=s1 ,y=s2 set extractions contain s1s2 positions x respectively. Finally, let projection set extractions= {(d1 , d2 , d3 )} onto one dimensions x given by:projx (D) = {s|d1 ,d2 ,d3 .dx = (d1 , d2 , d3 ) D}sM uses mutual information score determine much weight givestring set extractions similarity computation. string positionx, mutual information relation r position 1 given by:|D1=r,x=s | |D|mi1,x (r, s) = log|D1=r | |Dx=s |sM calculates similarity two relations first calculating similaritysets first arguments relations, similaritysets second arguments. Let r1 r2 two relations, let positionargument compared x. similarity function used is:Xmi1,x (r1 , a) + mi1,x (r2 , a)simx (r1 , r2 ) =aprojx (D1=r1 )projx (D1=r2 )Xmi1,x (r1 , a) +Xmi1,x (r2 , a)aprojx (D1=r2 )aprojx (D1=r1 )final similarity score two relations geometric average similarity scoresargument:psM (r1 , r2 ) = sim2 (r1 , r2 ) sim3 (r1 , r2 )(4)Applying sM metric entities rather relations simply requires projecting ontodifferent dimensions relevant tuple sets.264fiUnsupervised Methods Determining Object Relation Synonymssignificant difference sM similarity metric ESP modelsM metric compares x arguments one relation x argumentsother, compares arguments one relation arguments other,finally combines scores. contrast, ESP compares (x, y) argument pairs onerelation (x, y) pairs other. sM metric advantagelikely find matches two relations sparse data, disadvantagematches find necessarily strong evidence synonymy. effect,capturing intuition synonyms argument types domainsranges, certainly possible non-synonyms similar domains ranges.Antonyms obvious example. Synonyms defined domains ranges,rather mapping them, ESP better captures similaritymapping. Experiments (Section 6) compare ESP similarity metricsM , given Equation 4.previously mentioned, large body previous work similarity metrics(e.g., Lee, 1999). compare ESP one popular metrics,Cosine Similarity Metric (CSM), previously used synonym resolutionwork (Mann & Yarowsky, 2003; Hasegawa et al., 2004). Like traditional distributionalsimilarity metrics, CSM operates context vectors, rather extracted triples. However, ESP model similar CSM regard. extracted string,effect creates binary vector properties, ones representing properties applystring zeros representing not. example, string Einstein wouldcontext vector one position property (discovered, Relativity),zero position property (invented, light bulb). ESP CSMcalculate similarities comparing vectors.specific metric used compute CSM two vectors ~x ~y given by:simCSM (~x, ~y ) ==~x ~y||~x|| ||~y ||PyixiqqPP 22xiyiOften, techniques like term weighting TFIDF (Salton & McGill, 1983) used CSMcreate vectors boolean, rather dimensions different weightsaccording informative dimensions are. experimented TFIDF-likeweighting schemes, number times extraction extracted usedterm frequency, number different strings property applies useddocument frequency. However, found weighting schemes negative effectsperformance, ignore them. two boolean vectors, CSM reducessimple computation number shared properties k number extractionsstring, n1 n2 respectively. given by:simCSM boolean (~x, ~y ) =kn1 n2(5)CSM determines similar two context vectors dimension, addsscores weighted sum. contrast, ESP highly non-linear number265fiYates & EtzioniSimilarityshared properties. number matching contexts grows, weightadditional matching context also grows. Figure 1 compares behavior ESP CSMnumber shared properties two strings increases. Holding numberextractions fixed assuming boolean vectors CSM, behaves linear functionnumber shared properties. hand, ESP shapethresholding function: low value threshold point around k = 10,point probability estimate starts increasing rapidly. effect ESPmuch lower similarity scores CSM small numbers matching contexts, muchhigher scores larger numbers matching contexts. threshold switchesdepends n1 n2 , well P1 P2 , show experimentallymethod estimating P1 P2 , though simple, effective. Experiments Section6 compare ESP model CSM, computed using Equation 5.CSMESP05101520Number shared propertiesFigure 1: behavior Extracted Shared Property (ESP) model CosineSimilarity Model (CSM) number shared properties twostrings varies. graph shows similarity results using two hypothetical strings20 extracted properties each. ESP, property multiple N = 2. removedscale axis, since scales two metrics directly comparable,shape curves remains same.4.4 Combining Evidencepotential synonymy relationship, Resolver considers two pieces probabilistice evidence ESP, let E evidence SSM.evidence. Let Ei,ji,jmethod combining two uses Nave Bayes assumption piece evidence266fiUnsupervised Methods Determining Object Relation Synonymsconditionally independent, given synonymy relationship:eeP (Ei,j, Ei,j|Ri,j ) = P (Ei,j|Ri,j )P (Ei,j|Ri,j )(6)Given simplifying assumption, combine evidence find probabilitycoreference relationship applying Bayes Rule sides (we omit i, j indicesbrevity):P (Rt |E )P (Rt |E e )(1 P (Rt ))(7)P (Rt |E , E e ) = Pei{t,f } P (R |E )P (R |E )(1 P (R ))4.5 Comparing Clusters Stringsalgorithm merges clusters strings one another, using models. However,models give probabilities synonymy decisions two individual strings,two clusters strings.experimented several different methods determining probabilitysynonymy individual probability scores pair strings, one takencluster. Initially, followed work Snow, Jurafsky, Ng (2006) incorporatingtransitive closure constraints probabilistic modeling, made independenceassumptions. approach provides formal probabilistic framework problemsimple efficient calculate. experiments, found simply takingmean geometric mean (or even harmonic mean) string pair scores providedslightly improved results. completeness, provide brief explanationprobabilistic method combining string pair scores cluster pair scores.Let clustering set synonymy relationships pairs stringssynonymy relationships obey transitive closure property. let probabilityset assertions given clustering C be:P (D|C) =CRi,jP (Di Dj |Ri,j)fRi,jCf)P (Di Dj |Ri,j(8)metric used determine two clusters merged likelihood ratio,probability set assertions given merged clusters probability givenoriginal clustering. Let C 0 clustering differs C two clustersC merged C 0 , let C set synonymy relationships C 0true, corresponding ones C false. metric given by:0QCRi,jP (D|C )/P (D|C) = Q|D )(1 P (Rt ))P (Ri,jji,jC (1Ri,j|D ))P (Rt )P (Ri,jji,j(9)|D ) may supplied SSM, ESP, combinationprobability P (Ri,jjmodel. experiments, let prior SSM model 0.5. ESP1)=combined models, set prior P (Ri,jmin(Pi ,Pj ) , Pi Pj numberpotential properties si sj respectively.267fiYates & Etzioni5. Resolvers Clustering AlgorithmSynonym resolution Web requires clustering algorithm scale hugenumber strings sparse, high-dimensional space. requirements difficultclustering algorithm. hand, words handfulsynonyms, clusters tend quite small. Greedy agglomerative approaches wellsuited type clustering problem, since start smallest possible clustersmerge needed.Resolver clustering algorithm version greedy agglomerative clustering,key modification allows scale sparse, high-dimensional spaces hugenumbers elements. standard greedy clustering algorithm begins comparing pairdata points, greedily merges closest pair. biggest hurdle scalingalgorithm initial step comparing every pair data points requires O(N 2 )comparisons N points. Several proposed techniques able speedprocess practice filtering initial pairs points compared; buildwork provide novel technique new bound O(N log N ) comparisons,mild assumptions.algorithm outlined Figure 2. begins calculating similarity scorespairs strings, steps 1-4. scores sorted best cluster pairs mergedpair clusters score threshold. novel part algorithm, step4, compares pairs clusters share property, long axclusters share property. step limits number comparisons madeclusters, reason algorithms improved efficiency, explained below.algorithm compares every pair clusters potential merged,assuming two properties data. First, assumes pairs clusters sharedproperties worth comparing. Since number shared properties key sourceevidence approach, clusters almost certainly merged, evencompared, assumption quite reasonable. Second, approach assumesclusters sharing properties apply many strings (at least ax) needcompared. Since properties shared many strings provide little evidencestrings synonymous, assumption reasonable synonym resolution.use ax = 50 experiments. Less 0.1% distinct propertiesthrown using cutoff, discarded properties apply many strings(at least ax), number comparisons grows squarenumber strings property applies to, restriction drastically cutstotal number comparisons made. Table 1 shows number comparisons madenave method comparing pairs strings set 2 million extractions,number comparisons Resolver makes experiments. algorithmachieves reduction factor 136 objects 486 relations numbercomparisons made. unoptimized implementation Resolver able clusterstrings extractions approximately 30 minutes. Resolver also runlarger set containing 100 million extractions 1 million distinct strings,able cluster approximately 3.5 days single machine.268fiUnsupervised Methods Determining Object Relation SynonymsE := {e = (r, a, b)|(r, a, b) extracted assertion}:= {s|s appears relation argument string E}Cluster := {}Elements := {}1. S:Cluster[s] := new cluster idElements[Cluster[s]] := {s}2. Scores := {}, Index := {}3. e = (r, a, b) E:property := (a, b)Index[property] := Index[property] {Cluster[r]}property := (r, a)Index[property] := Index[property] {Cluster[b]}property := (r, b)Index[property] := Index[property] {Cluster[a]}4. property p Index:|Index[p]| < Max:pair {c1 , c2 } Index[p]:Scores[{c1 , c2 }] := similarity(c1 , c2 )5. Repeat merges performed:Sort ScoresU sedClusters := {}Repeat Scores empty top score < hreshold:{c1 , c2 } := removeT opP air(Scores)neither c1 c2 U sedClusters:Elements[c1 ] := Elements[c1 ] Elements[c2 ]e Elements[c2 ]:Cluster[e] := c1delete c2 ElementsU sedClusters := U sedClusters {c1 , c2 }Repeat steps 2-4 recalculate ScoresFigure 2: Resolvers Clustering Algorithm5.1 Algorithm AnalysisLet set extracted assertions. following analysis2 shows one iterationmerges takes time O(|D| log |D|). Let N C number comparisons stringsstep 4. simplify analysis, consider properties contain relationstring argument 1 string. Let P roperties set propertiesapply fewer ax strings, let Stringsp set strings particular2. ax parameter allowed vary log |D|, rather remaining constant, analysisleads slightly looser bound still better O(|D|2 ).269fiYates & EtzioniNum. StringsCompareResolverSpeedup9,79710,15147,985,70651,516,325352,177105,915136x486xObjectsRelationsTable 1: Resolvers clustering algorithm cuts number comparisons madepairs strings clustering data set 2.1 million TextRunnerextractions. Compare lists number comparisons wouldmade every string compared every one. Resolver reduces comparisons object strings factor 136 compared baseline,comparisons relations strings factor 486.property p applies to. number comparisons given size unionset comparisons made property, upper-bounded summaximum number comparisons made property:fifififi[fififi{pair = {s1 , s2 }|pair Stringsp }fifiNC = fififipP ropertiesX|{pair = {s1 , s2 }|pair Stringsp }|pP ropertiesX=pP roperties|Stringsp | (|Stringsp | 1)2Since Stringsp contains ax elements, upper-bound expressionNCXpP roperties|Stringsp | (M ax 1)2=(M ax 1)2(M ax 1)|D|2XpP roperties|Stringsp |Plast step bounds p |Stringsp | |D|, since numberP extractions equalnumber times property extracted. Since p |Stringsp | summingproperties apply fewer ax strings, |D| may greater sum.Overall, analysis shows N C linear |D|. Note general boundquite loose properties apply small number strings, far fewerax.Step 5 requires time O(|D| log |D|) sort comparison scores perform one iteration merges. largest cluster size K, worst case algorithm take270fiUnsupervised Methods Determining Object Relation SynonymsK iterations (and best case take log K). experiments, algorithmnever took 9 iterations.analysis thus far related computational complexity |D|, sizeinput data set extractions. existing techniques, however, analyzedterms |S|, number distinct strings clustered. order relate twokinds analysis, observe linguistic data naturally obeys Zipf distributionfrequency distinct strings. is, commonstring appears many times1 zextractions; next-most common appears roughlytimes often parameter21 zz; next common appears roughly 3 times often; on. parameter zknown Zipf parameter, naturally-occurring text typically observedaround 1 (Zipf, 1932; Manning & Schuetze, 1999). characterize Zipfdistribution input data set extractions, rewriteP number extractions|D| terms number distinct strings |S|, since |D| = sS frequency(s). Followingline thought conclusion, find z < 1, data set,|D| grows linearly |S|, complexity O(|D| log |D|) equivalent complexityO(|S| log |S|). z = 1, O(|D| log |D|) equivalent bound O(|S| log2 |S|).z > 1, bound O(|S|z log |S|). z = 2 asymptotic boundO(|S|2 log |S|) worse O(|S|2 ) bound comparing string pairs, highvalue z highly unlikely naturally occurring text. details completeanalysis, see Appendix C.5.2 Relation Speed-Up TechniquesMcCallum, Nigam, Ungar (2000) proposed widely-used technique pre-processingdata set reduce number comparisons made clustering. use cheapcomparison metric place objects overlapping canopies, use expensive metric cluster objects appearing canopy. Resolver clusteringalgorithm fact adaptation canopy method: like Canopies method,uses index eliminate many comparisons would otherwise need made.method adds restriction strings compared share highfrequency properties. Canopy method works well high-dimensional data manyclusters, case problem. contribution observerestrict comparisons novel well-justified way, obtain new theoreticalbound complexity clustering text data.merge/purge algorithm (Hernandez & Stolfo, 1995) assumes existenceparticular attribute data set sorted attribute, matching pairsappear within narrow window one another. algorithm O(M log )number distinct strings. However, attribute set attributescomes close satisfying assumption context domain-independent informationextraction.Resolvers clustering task part reduced task nearest-neighbor search,several recent systems developed fast new algorithms. reduction worksfollows: nearest-neighbor retrieval techniques used find similarstring every distinct string corpus, Resolvers merge criteria decidepairs actually merge. Several fastest nearest-neighbor techniques271fiYates & Etzioniperform approximate nearest-neighbor search: given error tolerance , techniquesreturn neighbor query node q 1 + times far qtrue nearest neighbor q.Examples nearest-neighbor techniques divided use hash-basedtree-based indexing schemes. Locality-Sensitive Hashing uses combination hashing1functions retrieve approximate nearest neighbors time O(n 1+ ) error tolerance .given query point q willing accept neighbors distancetwice distance true nearest neighbor ( = 2), running time1O(n 2 ) = O( n) find single nearest neighbor (Gionis, Indyk, & Motwani, 1999).recently, tree-based index structures metric cover trees (Beygelzimer, Kakade,& Langford, 2006) hybrid spill trees (Liu, Moore, Gray, & Yang, 2004), offeredcompetitive even better performance Locality-Sensitive Hashing. tree-basedalgorithms complexity O(d log n), dimensionality space, findsingle nearest neighbor. Metric trees offer exact nearest-neighbor search, spill treesoffer faster search practice cost finding approximate solutions usingspace index. indexing schemes powerful tools nearest-neighbor search,dependence dimensionality space makes costly applycase. Resolver operates space hundreds thousands dimensions (the numberdistinct extract properties), fastest techniques appliedspaces around thousand dimensions (Liu et al., 2004). Resolver determinesexact nearest neighbor, fact exact distance relevant pairs pointsmild assumptions stated above, operating huge-dimensional space.5.3 Resolver ImplementationResolver currently exists Java package containing 23,338 lines code. separatemodules calculating Extracted Shared Property Model String SimilarityModel, well clustering extractions. basic version system accepts filecontaining tuples strings input, one tuple per line. Optionally, accepts manuallylabeled clusters input well, use output precision recall scores.output system two files containing object clusters relation clusters sizetwo more, respectively. Optionally, system also outputs precision recall scores.Several options allow user run extensions basic Resolver system,discussed Section 7.Resolver currently part TextRunner demonstration system. demonstration system available keyword searches Webhttp://www.cs.washington.edu/research/textrunner/. demonstration system containsextractions several hundred million Web documents. extractions fedResolver resulting clusters added TextRunner index keyword searches return results member cluster containing keywordsearched for, displayed results condensed members clusterrepeated.272fiUnsupervised Methods Determining Object Relation Synonyms6. ExperimentsSeveral experiments test Resolver ESP, demonstrate improvementrelated techniques paraphrase discovery, sM (Lin & Pantel, 2001) CosineSimilarity Metric (CSM) (Salton & McGill, 1983; Hasegawa et al., 2004; Mann & Yarowsky,2003). first experiment compares performance various similarity metrics,shows Resolvers output clusters significantly better ESPs SSMs,ESPs clusters turn significantly better sM CSMs. secondexperiment measures sensitivity ESP model hidden parameter, showswide range parameter settings, able outperform sMCSM models.6.1 Experimental Setupmodels tested data set 2.1 million assertions extracted Web crawl.models run assertions, compare objects relations appearleast 25 times data, give distributional similarity models sufficient dataestimating similarity. Although restriction limits applicability Resolver,note intuitive necessary unsupervised clustering, sincesystems definition start knowledge string. must see numberexamples reasonable expect make decisions them. also noteDowney, Schoenmackers, Etzioni (2007) shown different problembootstrapping techniques leverage performance high-frequency examples buildaccurate models low-frequency items.proper nouns3 compared, relation strings contain punctuation capital letters compared. helps restrict experiment stringsless prone extraction errors. However, models use stringsfeatures. all, data contains 9,797 distinct proper object strings 10,151 distinctproper relation strings appear least 25 times. created gold standard data setmanually clustering subset 6,000 object 2,000 relation strings. total, goldstandard data sets contains 318 true object clusters 330 true relation clustersleast 2 elements each.noted previously (Section 3.1), polysemous strings pose particular representationaltrouble creating gold standard data set, since correct clustering captures synonymy relationships polysemous strings, general. adoptedfollowing data-oriented strategy: polysemous strings clustered stringsunless match every sense strings appeared data.example, two U.S. Presidents named Roosevelt: Theodore RooseveltFranklin Delano Roosevelt. applying criterion above, gold standard data contained cluster FDR President Franklin Roosevelt, since referred FranklinDelano Roosevelt unambiguously dataset. Likewise, President Theodore RooseveltTeddy Roosevelt put cluster. terms Roosevelt PresidentRoosevelt, however, used various places refer men, could3. following heuristic used detect proper nouns: string consisted alphabeticcharacters, whitespace, periods, first character every word capitalized, consideredproper noun. Otherwise, not.273fiYates & Etzioniclustered either Franklin Roosevelt cluster Theodore Roosevelt cluster.Since set senses data, gold standard contained separatecluster containing two strings. Section 8.2 describes extension Resolverhandles polysemous names. criterion polysemy prevented 480 potential mergesgold standard data set object clusters might synonymous. prevented merges usually affected acronyms, first names, words like Agency mightrefer number institutions, represent less 10% strings goldstandard object data set.addition gold standard data set evaluation, manually created dataset development data containing 5 correct pairs objects, 5 correct pairs relations,also 5 examples incorrect pairs each. 20 examples usedevaluation data. development data used estimate value ESP modelshidden parameter N , called property multiple (see Section 4.2). used simple hillclimbing search procedure find value N separately objects relations,found N = 30 worked best objects development data, N = 500 relations.Although amount data required set parameter effectively small,nevertheless important topic future work come method estimateparameter completely unsupervised manner order fully automate Resolver.comparisons, calculated Cosine Similarity Metric (CSM) using technique described Section 4.3 Equation 5, sM metric defined Equation4.6.2 Clustering Analysisfirst experiment compares precision recall clusterings output five similaritymetrics: two kinds previous work used paraphrase discovery, CSM sM ; twocomponents Resolver, ESP SSM; full Resolver system.precision recall clustering measured follows: hypothesis clustersmatched gold clusters hypothesis cluster matches onegold cluster, vice versa. mapping computed number elementshypothesis clusters intersect elements matching gold clusters maximized.intersecting elements marked correct. elements hypothesis clusterintersect corresponding gold cluster marked incorrect, irrelevantappear gold clustering all. Likewise, gold cluster elementsmarked found matching hypothesis cluster contains element, foundotherwise. precision defined number correct hypothesis elements clusterscontaining least two relevant (correct incorrect) elements, divided total numberrelevant hypothesis elements clusters containing least two relevant items. recalldefined number found gold elements gold clusters size least two, dividedtotal number gold elements clusters size least two. considerclusters size two order focus interesting cases.model requires threshold parameter determine scores suitablemerging. experiments arbitrarily chose threshold 3 ESP model(that is, data needs 3 times likely given merged cluster unmergedclusters order perform merge) chose thresholds models hand274fiUnsupervised Methods Determining Object Relation SynonymsObjectsModelCSMsMESPSSMResolverPrec.0.510.520.560.620.71Rec.0.360.380.410.530.66RelationsF10.420.440.470.570.68Prec.0.620.610.790.850.90Rec.0.290.280.330.250.35F10.400.380.470.390.50Table 2: Comparison cosine similarity metric (CSM), sM , Resolver components(SSM ESP), Resolver system. Bold indicates score significantlydifferent score row p < 0.05 using chi-squared test onedegree freedom. Using test, Resolver also significantly different ESP,sM , CSM recall objects, sM , CSM SSM recall relations.Resolvers F1 objects 19% increase SSMs F1. Resolvers F1 relations28% increase SSMs F1. significance tests performed F1 values.difference ESP would roughly even precisionrecall, although relations harder improve recall. Table 2 shows precisionrecall models.6.3 Sensitivity AnalysisESP model requires parameter number potential properties string,performance ESP strongly sensitive exact value parameter.described Section 4.2, assume number potential properties multipleN number extractions string. experiments, chose valuesN = 30 objects N = 500 relations, since worked well held-out data.However, Tables 3 4 show, actual values parameters may vary largerange, still enabling ESP outperform sM CSM.experiments, measured precision recall similarity metrics,without performing clustering. used similarity metrics sort pairs strings(but pairs share least property) descending order similarity.place threshold similarity, measure precision numbercorrect synonym pairs similarity greater divided total number pairssimilarity greater . measure recall number correct synonym pairssimilarity greater divided total number correct synonym pairs.varying , create precision-recall curve measure area underneathcurve.tables highlight two significant results. First, objects relationsESP model outperforms CSM sM large amount parameter settings varyclose factor two either direction value determined developmentdata. Thus although required small amount data determine valueparameter, performance ESP overly sensitive exact value. Second,275fiYates & EtzioniMetricAUCFraction Max. AUCImprovement BaselineCSMsMESP-10ESP-30ESP-50ESP-90SSMResolver0.00610.00830.0190.0240.0220.0180.180.220.0110.0140.0330.0410.0370.0310.310.38-21%0%136%193%164%121%0%23%Table 3: Area precision-recall Curve (AUC) object synonymy. ESPmodel significantly outperforms sM CSM AUC wide range parameter settings. Likewise, Resolver significantly outperforms SSM AUC.maximum possible AUC less one many correct string pairs shareproperties, therefore compared clustering algorithm. third columnshows score fraction maximum possible area curve,objects 0.57. improvement baseline column shows much ESP curvesimprove sM , much Resolver improves SSM.MetricAUCFraction Max. AUCImprovement BaselineCSMsMESP-50ESP-250ESP-500ESP-900SSMResolver0.00350.00440.00480.00870.00960.0100.0220.0290.0340.0420.0460.0830.0930.0980.240.31-19%0%9.5%98%121%133%0%31%Table 4: Area precision-recall Curve (AUC) relation synonymy.ESP model significantly outperforms sM CSM AUC wide rangeparameter settings. Likewise, Resolver significantly outperforms SSMAUC. maximum possible area less one many correct string pairsshare properties, therefore compared clustering algorithm.third column shows score fraction maximum possible area curve,relations 0.094. improvement baseline shows much ESPcurves improve sM , much Resolver improves SSM.276fiUnsupervised Methods Determining Object Relation SynonymsESP model clearly provides significant boost performance SSM model,Resolvers performance significantly improves SSMs.6.4 Discussionexperiments, ESP outperforms CSM sM . sensitivity analysis showsremains true wide range hidden parameters ESP, objectsrelations. Moreover, ESPs improvement comparison metrics holds truemetrics used clustering data. sM performance largely CSMevery experiment. Somewhat surprisingly, sM performs worse relation clusteringobject clustering, even though designed relation similarity.results show three distributional similarity models perform SSMmodel objects relations, similarity experimentsclustering experiments. one exception clustering experiment relations,SSM poor recall, thus lower F1 score ESP CSM.expected, since ESP, sM , CSM make predictions based noisy signal.example, Canada shares properties United States data U.S. does,even though Canada appears less often U.S. Importantly, though, significantimprovement precision recall using combined model using SSMalone. Resolvers F1 19% higher SSMs objects, 28% higher relationsclustering experiments.Interestingly, distributional similarity metrics (ESP, sM , CSM) perform significantly worse task ranking string pairs clustering task. One reasontask ranking string pairs measure performance comparingcluster two strings cluster two strings. greedy clustering processone used Resolver, large groups correct clusters formed longsimilarity metrics rank correct pair strings near top, ableimprove estimates similarity comparing clusters. issue requiresinvestigation.clearly room improvement synonym resolution task. Error analysisshows Resolvers mistakes due three kinds errors:1. Extraction errors. example, US News gets extracted separately World Report,Resolver clusters together share almostproperties.2. Similarity vs. Identity. example, Larry Page Sergey Brin get merged,Angelina Jolie Brad Pitt, Asia Africa.3. Multiple word senses. example, two President Bushes; also,many terms like President Army refer multiple distinct entities.Extraction systems improving accuracy time, addresserrors. next two sections develop techniques address second thirdkinds errors, respectively.277fiYates & Etzioni7. Similar Identical Pairserror analysis suggests, similar objects exact synonyms makelarge fraction Resolvers errors. section describes three techniques dealingerrors.example, Resolver likely make mistake pair Virginia WestVirginia. share many properties type (U.S. states),high string similarity. Perhaps easiest approach determiningtwo synonymous simply collect data them. highlysimilar, certainly share properties; different governors,example. However, highly similar pairs two, amount data requireddecide identical may huge, simply unavailable.Fortunately, sophisticated techniques making decisions available data. One approach consider distribution words occur candidate synonyms. Similar words likely separated conjunctions (e.g., VirginiaWest Virginia) domain-specific relations hold two objectstype (e.g., Virginia larger West Virginia). hand, synonymslikely separated highly specialized phrases a.k.a. Section 7.1describes method using information distinguish similar identicalpairs.second approach consider candidate synonyms behave contextrelations special distributions, like functions inverse functions. example,x capital relation inverse function: every argument one xargument4 . capitals extracted West Virginia Virginia, mayruled synonymous pair capitals seen different.hand, Virginia VA share capital, much stronger evidence twoshared random property, town calledSpringfield located there. Section 7.2 describes method eliminating similar pairsdifferent values function inverse function, Section7.3 illustrates technique assigning different weights different evidence basedclose functional property is. Section 7.4 gives results techniques.7.1 Web Hitcounts Synonym Discoverynames two similar objects may often appear together sentence,relatively rare two different names object appear sentence.Moreover, synonymous pairs tend appear idiosyncratic contexts quite differentcontexts seen similar pairs. Resolver exploits fact queryingWeb determine often pair strings appears together certain contexts largecorpus. hitcount high, Resolver prevent merge.Specifically, given candidate synonym pair s1 s2 , Coordination-Phrase Filteruses discriminator phrase (Etzioni et al., 2005) form s1 s2 . computes4. also function.278fiUnsupervised Methods Determining Object Relation Synonymsvariant pointwise mutual information, givencoordination score(s1 , s2 ) =hits(s1 s2 )2hits(s1 ) hits(s2 )filter removes consideration candidate pair coordination scorethreshold, determined small development set. resultscoordination-phrase filtering presented below.Coordination-Phrase Filter uses one possible context candidate synonym pairs. simple extension use multiple discriminator phrases include common context phrases like unlike. complex approach could measuredistribution words found candidate pair, compare distributiondistributions found known similar known identical pairs.important avenues investigation.One drawback approach requires text containing pair objectsclose proximity. pair rare strings, data extremely unlikely occurtype test exacerbates data sparsity problem. following two sections describetwo techniques suffer particular problem.7.2 Function FilteringFunctions inverse functions help distinguish similar identical pairs.example, Virginia West Virginia different capitals: respectively, RichmondCharleston. facts extracted, Resolver knowscapital relation inverse function, ought prevent Virginia West Virginiamerging.Given candidate synonym pair x1 x2 , Function Filter prevents mergesstrings different values function. precisely, decides twostrings y1 y2 match string similarity high threshold. preventsmerge x1 x2 exists function f extractions f (x1 , y1 ) f (x2 , y2 ),extractions y1 y2 match (and vice versa inversefunctions). Experiments described Section 7.4 show Function Filter improveprecision Resolver without significantly affecting recall.Function Filter requires knowledge relations actually functionsinverse functions. Others investigated techniques determining propertiesrelations automatically (Popescu, 2007); experiments, pre-defined list functionsused. Table 5 lists set functions used experiments Function Filter.functions selected manually inspecting set 500 common relationsTextRunners extractions, selecting reliably functional.met criteria, partly polysemy data, partly extractionnoise.7.3 Function WeightingFunction Filter uses functions inverse functions negative evidence,also possible use positive evidence. example, relation marriedstrictly one-to-one, people set spouses small. pair279fiYates & Etzionicapitalnamedheadquarteredborncapital citynamedheadquarteredbornTable 5: set functions used Function Filter.strings extracted spousee.g., FDR President Roosevelt shareproperty (married, Eleanor Roosevelt)this far stronger evidence two stringsidentical shared random property, (spoke to, reporters).several possibilities incorporating insight Resolver. First,technique need method estimating function-ness property,close property functional. define degree relationnumber values expected hold true given x value. call propertyhigh-degree expected apply many strings (highly non-functional), low-degreeexpected apply strings (close functional).degree property may estimated relation involved propertyset extractions relation, may based many objectsproperty applies to. example, 100 unique extractions marriedrelation, 80 unique x argument strings 100 extractions,average x string participates 100/80 = 1.25 married relations. One method mightassign every property containing married relation statistic degree.hand, suppose two extractions property (married, John Smith).second method assign degree 2 property.also two possible ways incorporate degree information ESPmodel. ESP model may altered directly models degrees properties process selecting balls urns, vastly complicates modelmay make much computationally expensive. second option reweightnumber shared properties strings based TF-IDF style weightingproperties, calculate ESP model using parameter instead. requires modifying ESP model handle non-integer values number sharedproperties.experiments far, one set options explored, others remainfuture investigation. Weighted Extracted Shared Property Model (W-ESP) setsdegree property number extractions property. Second, stringssi sj share properties p P , sets value number shared propertiessi sjXpP1degree(p)ESP model changed handle continuous values number sharedproperties changing factorials gamma functions, using Stirlings approximationwhenever possible.280fiUnsupervised Methods Determining Object Relation SynonymsModelPrec.Rec.F1ResolverResolverResolverResolverResolver0.710.740.780.710.780.660.660.680.650.680.680.700.730.680.73++++Function FilteringCoordination Phrase FilteringWeighted ESPFunction Coord. Phrase FilteringTable 6: Comparison object merging results Resolver system, Resolver plusFunction Filtering, Resolver plus Coordination-Phrase Filtering, Resolverusing Weighted Extracted Shared Property Model, Resolver plustypes filtering. Bold indicates score significantly different Resolversscore p < 0.05 using chi-squared test one degree freedom. Resolver+Coordination Phrase Filterings F1 objects 28% increase SSMs F1, 7%increase Resolvers F1.Unlike Function Filter, W-ESP model require additional knowledgerelations functional. unlike Coordination-Phrase Filter,require Web hitcounts training phase. works extracted data, is.7.4 Experimentsextensions Resolver attempt address confusion similar identicalpairs. Experiments extensions, using datasets metrics Section 6demonstrate Function Filter (FF) Coordination-Phrase Filter (CPF) boostResolvers precision. Unfortunately, W-ESP model yielded essentially improvementResolver.Table 6 contains results experiments. coordination-phrase filtering,Resolvers F1 28% higher SSMs objects, 6% higher Resolvers F1without filtering. function filtering promising idea, FF provides smaller benefitCPF dataset, merges prevents are, exceptions,subset merges prevented CPF. part due limited numberfunctions available data.Function Filter Coordination-Phrase Filter consistently blocked mergeshighly similar countries, continents, planets, people data, wellsmaller classes. biggest difference CPF consistently hitcountssimilar pairs tend confused identical pairs. Perhaps amountextracted data grows, functions extractions functions extracted,allowing Function Filter improve.Part appeal W-ESP model requires none additional inputstwo models require, applies property, rather subsetrelations like Function Filter. Like TFIDF weighting Cosine SimilarityMetric, W-ESP model uses information distribution propertiesdata weight property. data extracted TextRunner, neither W-ESPTFIDF weighting seems positive effect. experiments required test281fiYates & Etzioniwhether W-ESP might prove beneficial data sets TFIDFpositive effect.8. Resolver Cross-Document Entity Resolutionpoint, made single-sense assumption, assumption everytoken exactly one meaning. assumption defensible small domains,named entities relations rarely multiple meanings, even causeproblems: example, names Clinton Bush refer two major playersAmerican politics, well host people. extractions takenmultiple domains, assumption becomes problematic.describe refinement Resolver system handles task CrossDocument Entity Resolution (Bagga & Baldwin, 1998), tokens names maymultiple referents, depending context. experiment compares Resolverexisting entity resolution system (Li et al., 2004a), demonstrates Resolverhandle polysemous named entities high accuracy. extension could theoreticallyapplied highly polysemous tokens common nouns, yetempirically demonstrated.8.1 Clustering Polysemous Names ResolverRecall synonym resolution task defined finding clusters set distinctstrings found set extractions (Section 3). Cross-Document Entity Resolutiondiffers synonym resolution requires clustering set stringoccurrences, rather set distinct strings. example, suppose documentcontains two occurrences token DP, one means Design Pattern onemeans Dynamic Programming. Synonym resolution systems treat DP singleitem, implicitly cluster occurrences DP together. Cross-Document EntityResolution system treats occurrence DP separately, therefore potentialput occurrence separate cluster mean different things. way,Cross-Document Entity Resolution system potential handle polysemous namescorrectly.change task definition, sources evidence similarity sparser.occurrence named entity input, Resolver single TextRunner extraction describing occurrence. achieve reasonable performance, needsinformation context named entity appears. change Resolvers representation entity occurrences include nearest E named entitiestext surrounding occurrence. is, entity occurrence x representedset named entities y, appears among nearest E entities text surrounding x. Suppose, instance, e1 occurrence DP Bellman Viterbicontext, e2 another occurrence OOPSLA Factory context. e1would represented set {Bellman, Viterbi}, e2 would represented set{Factory, OOPSLA}.Table 7 summarizes major ways extended Resolver handle polysemous names. extensions place, Resolver proceed cluster occurrencesentities less way clusters entity names synonym resolution.282fiUnsupervised Methods Determining Object Relation SynonymsOriginal ResolverExtended ResolverInputset distinct strings S,S, set extracted properties s.SSM ComparesESP ComparesOutputCharacter sequencesSets extracted propertiesclustering set distinct stringsbag string occurrences O,occurrence O,set named entities appearing close context.Character sequencesSets named entitiesclustering set stringoccurrencesTable 7: differences original Resolver system extended Resolver system handling polysemous names.SSM model works above, ESP model calculates probabilities coreferencebased sets named entities context rather extracted properties. clusteringalgorithm eliminates comparisons occurrences share part contexts,common contextual elements. end, Resolver produces sets coreferential entity occurrences, used annotate extractions containing entityoccurrences coreference relationships.8.2 Experiment Cross-Document Entity Resolutiontested Resolvers ability handle polysemous names data set 300 documents 1998-2000 New York Times articles TREC corpus (Voorhees, 2002). Liet al. (2004b) automatically ran named-entity tagger documents manuallycorrected identify approximately 4,000 occurrences peoples names.manually annotated occurrences form gold standard set coreferential clusters.named entity occurrence data set, extracted set closest Enamed entities, E set 100, represent context named entity occurrence.ran Resolver cluster entity occurrences. set ESPs latent parameter N30, experiments above. development data set mergethreshold, used following strategy: arbitrarily picked single occurrencecommon name data set (Al Gore), found somewhat uncommon variantname (Vice President Al Gore), set threshold value similarityscore pair (7.5). every round merging Resolvers clustering algorithm,filtered top 20 proposed merges using Coordination Phrase Filter,threshold used previous experiments.Li et al. propose generative model entity coreference compare against.model requires databases information titles, first names, last names, genders, nicknames, common transformations attributes peoples names help computeprobability coreference. uses Expectation-Maximization given data setcompute parameters, inference algorithm O(N 2 ) number wordoccurrences N . Full details provided Li et al. (2004b).283fiYates & EtzioniResolverLi et al.PrecisionRecallF197.391.594.794.096.092.7Table 8: Resolver outperforms system Li et al. Cross-Document Entity Resolution task involving polysemous peoples names. Differences statisticallysignificant precision recall using two-tailed Chi-Square testone degree freedom (p < 0.01, = 910.9 precision = 20.6recall).Following Li et al., evaluate clusters using precision recall calculated follows:let Op set entity occurrence pairs predicted coreferential (i.e.,belong cluster), let Oa denote set correct coreferential pairs,|Op Oa ||Op Oa |calculated manual clustering. precision P = |O, recall R = |O,p|a|RF1 = P2P+R.Table 8 shows results running Resolver data set, well bestresults reported Li et al. (2004b) data. 5 follow-up work, Li et al. (2004a)demonstrate unsupervised model outperforms three supervised techniqueslearn parameters much different attributes (first name, honorifics, etc.) contributesimilarity occurrence pairs.terms absolute performance, Resolver quite accurate dealing polysemous names data set. performance data set significantly higherTextRunner extractions, partly extra information available termscontexts occurrences, partly starting manually labellednamed entities, rather noisy extractions.Resolvers precision significantly higher Li et al.s, roughly equal recall.large sample sizes, differences precision recall statistically significant (two-tailed Chi-Square test one degree freedom, p < 0.01).comparison Li et al.s system, Resolvers SSM model much less sophisticated,compensates using Web data strong measure distributional similarity.need rely manually curated databases expert knowledge domain,case, similarity peoples names.9. Conclusion Future Workshown unsupervised scalable Resolver system able find clusterscoreferential object names extracted relations precision 78% recall5. follow-up work, Li et al. (2004a) report F1 score 95.1 task using appearsmodel data, result calculated testing model 6 random splitsdata averaging score. access random splits. One possible reasonreported results different splitting test data reduces number coreferencerelations need found potential number incorrect coreference relations causesystem confusion.284fiUnsupervised Methods Determining Object Relation Synonyms68% aid coordination-phrase filtering, find clusters coreferentialrelation names precision 90% recall 35%. demonstrated significantimprovements using existing similarity metrics task employing novelprobabilistic model synonymy. much cleaner set extractions TRECcorpus, demonstrated Resolver able achieve 97% precision 95% recallemploying extension allowed cluster different senses namedifferent groups.Perhaps critical aspect extending Resolver refining ability handlepolysemy. experiments needed test ability handle new types polysemous named entities extracted data manually cleaned,case Li et al.s data. addition, plan incorporate ESP model systemunsupervised coreference resolution, including common nouns pronouns.extend model include aspects local salience, important coreferencedecisions noun phrases proper names.Currently setting ESP models single hidden parameter using developmentset. required amount data small, model might accurateeasier use hidden parameter set sampling data, rather usingdevelopment set must manually assembled. is, Resolver could inspectsubstantial portion data, measure often new properties appearremaining data. rate appearance new properties offer strong signalset hidden parameter.Several extensions Resolver dealt ruling highly similar non-synonyms(Section 7), varying degrees success boosting Resolvers precision. alsoconsidered another extension Resolver seeks use mutual recursion boostrecall, much like semi-supervised information extraction techniques use mutual bootstrapping entities patterns increase recall (Riloff & Jones, 1999). methodbegins clustering objects, clusters relations using merged object clustersproperties (rather raw object strings), clusters objects using relationclusters properties, on. Although far unable boost performance Resolver using technique TextRunner data, experiments artificialsimulations suggest suitable conditions, mutual recursion could boost recallmuch 16%. remains important area future work determinenatural data technique indeed useful, investigate methodsincreasing Resolvers recall.Acknowledgmentsresearch supported part Temple University, NSF grants IIS-0535284IIS-0312988, ONR grant N00014-08-1-0431 well gifts Google, carriedUniversity Washingtons Turing Center Temple Universitys CenterInformation Science Technology. would like thank anonymous reviewersJAIR associate editor charge paper helpful comments suggestions.would also like thank KnowItAll group University Washingtonfeedback support.285fiYates & EtzioniAppendix A. Derivation Extracted Shared Property ModelExtracted Shared Property (ESP) Model introduced Section 4. methodcalculating probability two strings synonymous, given share certainnumber extractions data set. appendix gives derivation model.Let si sj two strings, set extracted properties Ei Ej . Let UiUj set potential properties string, contained respective urns.Let Si,j number properties shared two urns, |Ui Uj |. Let Ri,jrandom variable synonymy relationship si sj , Ri,j = Ri,jfdenoting event are, Ri,jnot. ESP model statesprobability selecting observed number matching propertiesprobability Ri,jtwo urns containing matching properties, divided probability selectingobserved number matching properties two urns may contain matchingnon-matching properties:Proposition 2 two strings si sj |Ui | = Pi |Uj | = Pj potential properties(or instances), min(Pi , Pj ) = Pmin ; appear extracted assertions Ei Ej|Ei | = ni |Ej | = nj ; share k extracted properties (or instances),probability si sj co-refer is:P (Ri,j|Ei , Ej , Pi , Pj ) =PminkPPj Pminr+s Pi Pminni (k+r) nj (k+s)rPi Si,j Pj Si,jSi,j PSi,j k r+sr,s0r+srkni (k+r) nj (k+s)PkSi,j Pminr,s0Si,j kr+s(10)ESP model makes several simplifying assumptions:1. Balls drawn urns without replacement.2. Draws one urn independent draws urn.3. ball string equally likely selected urn: U = {u1 , . . . , um }X denotes random draw U , P (X = ui ) = |U1 | every ui .4. prior probability Si,j , given number properties Ui Uj , uniform:0smin(Pi ,Pj ) P (Si,j = s|Pi , Pj ) = min(Pi1,Pj )+15. Given extracted properties two strings number potential propertieseach, probability synonymy depends number extracted propertieseach, number shared properties extractions:|E , E , P , P ) = P (Rt |k, n , n , P , P ).P (Ri,jjjjji,j6. Two strings synonymous share many potential properties(|U U | = min(P , P )).possible: Ri,jjjproving Proposition 2, prove simple property urns assumptionsabove.286fiUnsupervised Methods Determining Object Relation SynonymsLemma 1 Given n draws without replacement urn containing set propertiesU , probability selecting particular set U |U1 | |S| = n, zero otherwise.( |S| )Proof Lemma 1: Let U = {u1 , . . . , um } denote elements U , let X1 , . . . , Xndenote independent draws urn. n = 1, P (S = {ui }) = P (X1 = ui ) = |U1 |assumption 3 above. suppose n = n0 , lemma holds everyn 0 < n0 .P (S = {x1 , . . . , xn0 |xi U }) =X=X=P (S n0 1 = {x1 , . . . , xi1 , xi+1 , . . . , xn0 })P (Xn = xi )11|U ||U | n0 + 1n0 1X (n0 1)!(|U | n0 + 1)!|U |!===1|U | n0 + 1n0 (n0 1)!(|U | n0 + 1)(|U | n0 )!|U |!(|U | n0 + 1)n0 !(|U | n0 )!|U |!1|U |n02Proof Proposition 2:|E , E , P , P ), somethingbegin transforming desired expression, P (Ri,jjjderived urn model. assumptions 5 6, getP (Ri,j|Ei , Ej , Pi , Pj ) = P (Si,j = Pmin |k, ni , nj , Pi , Pj )(11)Then, applying Bayes Rule, getP (Si,j = Pmin |k, ni , nj , Pi , Pj ) =P (k|Si,j = Pmin , ni , nj , Pi , Pj )P (Si,j = Pmin |ni , nj , Pi , Pj )PkSi,j Pmin P (k|ni , nj , Pi , Pj )P (Si,j |ni , nj , Pi , Pj )(12)Since assumed uniform prior Si,j (assumption 4), prior terms vanish,leavingP (k|Si,j = Pmin , ni , nj , Pi , Pj )P (Ri,j|Ei , Ej , Pi , Pj ) = P(13)kSi,j Pmin P (k|ni , nj , Pi , Pj )second step derivation find suitable expressionP (k|Si,j , ni , nj , Pi , Pj )287fiYates & Etzioniprobability written fully as:XP (k|Si,j , ni , nj , Pi , Pj ) =Ei Ui :|Ei |=niEj Uj :|Ej |=nj|Ei Ej |=kXEi Ui :|Ei |=niEj Uj :|Ej |=njP (Ei , Ej |Si,j , ni , nj , Pi , Pj )P (Ei , Ej |Si,j , ni , nj , Pi , Pj )(14)assumption 2, P (Ei , Ej ) = P (Ei )P (Ej ). Lemma 1, P (Ei ) terms equal, sincesets size ni , likewise P (Ej ) terms. Thus, get desired probabilityexpression, simply need count number ways taking subsets twourns share k properties.X1P (k|Si,j , ni , nj , Pi , Pj ) =Ei Ui :|Ei |=niEj Uj :|Ej |=nj|Ei Ej |=kX1(15)Ei Ui :|Ei |=niEj Uj :|Ej |=nj=PiniCount(k, ni , nj |Si,j , Pi , Pj )Count(ni , nj |Si,j , Pi , Pj )(16)ways picking set Ei ,Count(ni , nj |Si,j , Pi , Pj ) =PiPjninj(17)complete derivation, need expression Count(k, ni , nj | Si,j , Pi , Pj ).involves splitting relevant sets several parts. First Ui Uj containshared unshared properties. Let Ti,j = Ui Uj , Vi = Ui Ti,j , Vj = Uj Ti,j . Second,selected sets urn, Ei Ej , properties come setshared properties set unshared properties. Let K = Ei Ej , Fi = (Ei Ti,j ) K,Fj = (Ej Ti,j ) K.sets defined, set Ei Ej composed three distinct subsets:shared subset (K); subset also selected shared potential properties, Ti,j ,shared (Fi Fj ); remaining elements, chosencomplements shared properties (Vi Vj ). Since subsets distinct,count separately multiply results arrive final count.number ways selecting shared subset clearly Ski,j . sizes FiFj unknown, however, must sum possibilities. Let r = |Fi |, = |Fj |.Si,j k remaining shared potentialproperties Ti,j chooser + elements Fi Fj , r+sways split two distinct subsets.ni (k + r) elements left choose Ei , nj (k + s) elements left chooseEj . must selected unshared potential properties Vi Vj ,sizes Pi Si,j Pj Si,j respectively. Putting pieces together,288fiUnsupervised Methods Determining Object Relation SynonymsCount(k, ni , nj |Si,j , Pi , Pj ) =Pj Si,jr+sPi Si,jSi,j X Si,j kni (k + r) nj (k + s)r+skr,s(18)ranges r somewhat involved. must obey following constraints:1. r, 02. r ni k Pi + Si,j3. nj k Pj + Si,j4. r ni k5. nj k6. r + Si,j kPlugging Equation 18 Equation 16, turn Equation 13 yieldsdesired result. 2Appendix B. Fast Calculation Extracted Shared Property ModelESP model expensive calculate done wrong way. use two techniquesspeed calculation immensely. reference, full formulation model is:P (Ri,j|k, ni , nj , Pi , Pj ) =PminkPPj Pminr+s Pi Pminni (k+r) nj (k+s)rPi Si,j Pj Si,jSi,j PSi,j k r+sr,s0r+srkni (k+r) nj (k+s)PkSi,j Pminr,s0Si,j kr+s(19)Note equation involves three sums, ranging O(Pmin ), O(ni ), O(nj ) valuesrespectively. effect, O(n3 ) number extractions string. Furthermore,step requires expensive operation calculating binomial coefficients. Fortunately,several easy ways drastically speed calculation.First, Stirlings approximation used calculate factorials (and thereforebinomial function). Stirlings approximation given by:n1nn! 2n +3enavoid underflow overflow errors, log probabilities used everywhere possible.calculation done using simple multiplications logarithm calculations.Stirlings formula converges n! like O( n1 ); practice proved accurate enoughapproximation n! n > 100. ESPs implementation, values n!calculated once, stored future use.289fiYates & EtzioniSecond, calculation P (k|n1 , n2 , P1 , P2 ) sped simplifying expression get rid two sums. result following equivalent expression, assumingwithout loss generality P2 P1 :P (k|n1 , n2 , P1 , P2 ) =P2 +1n2 +1Pn2rr=k kP2 P1n2 n1P1 rn1 k(20)simplification removes two sums, therefore changes complexity calculating ESP O(P2 n2 n1 ) O(n2 ). sufficient data set, largerdata sets might necessary introduce sampling techniques improve efficiencyeven further.Appendix C. Better Bound Number Comparisons MadeResolver Clustering AlgorithmSection 4 showed Resolver clustering algorithm initially makes O(N log N ) comparisons strings data, N number extractions. Heuristic methods like Canopies method (McCallum et al., 2000) require O(M 2 ) comparisons,number distinct strings data. claim O(N log N ) asymptoticallybetter O(M 2 ) Zipf-distributed data.Zipf-distributed data controlled shape parameter, call z. claimholds true shape parameter z < 2, shown below. Fortunately, naturaldata shape parameter usually close z = 1, Resolver dataobserved z < 1.Let set distinct strings set extractions D. PS, let freq(s)denote number times appears extractions. Thus |D| = sS freq(s).Let = |S| N = |D|.Proposition 3 observed Zipf distribution shape parameter z,1. z < 1, N = (M )2. z = 1, N = (M log )3. z > 1, N = (M z )Proof: Let s1 , . . . , sM elements rank order highest frequency string(s1 ) lowest frequency string (sM ). Since observed Zipf distribution shapezparameter z, freq(si ) = Miz . Given assumptions, z determine numberextractions made:XNM,z =freq(s)(21)sSX Mziz=1iM290(22)fiUnsupervised Methods Determining Object Relation Synonymsbuild recurrence relation value N changes (holding z constant)notingN2M,z =X1i2M= (2M )z(2M )zizX 11iMiz(23)+ (2M )z= 2z NM,z + fz (M )X+1i2M1iz(24)(25)P)zfz (M ) = +1i2M (2Miz .two important properties fz (M ).z)z1. Note every term sum fz (M ) less (2Mz = 2 . Thus fz (M )bounded 2z , z held constant, fz (M ) = O(M ).2. Every term sum least 1, fz (M ) fz (M ) = (M ); combiningtwo facts yields fz (M ) = (M ).two properties fz (M ) used below.use recurrence relation Master Recurrence Theorem (Cormen,Leiserson, & Rivest, 1990) prove three claims proposition. reference,Master Recurrence Theorem states following:Theorem 1 Let 1 b 1 constants, let f (n) function, let (n)defined non-negative integers recurrence(n) = (n/b) + f (n)T(n) bounded asymptotically follows.1. f (n) = O(nlogb ) constant > 0, (n) = (nlogb )2. f (n) = (nlogb ), (n) = (nlogb log n)3. f (n) = (nlogb a+ ), constant > 0, af (n/b) cf (n)constant c < 1 sufficiently large n, (n) = (f (n)).First consider case z > 1. recurrence NM,z clearly made fitform Theorem 1 setting = 2z , b = 2, f = fz (M ). Since fz (M ) bounded2z = O(M ), also clearly bounded O(M logb ) = O(M z ),take anything (0, z 1). Thus case one Theorem 1 applies,NM,z = (M logb ) = (M z ).Next consider case z = 1. Since fz=1 (M ) = (M ) (M logb ) = (M ),case two Theorem 1 applies. Thus NM,z=1 = (M logb log ) = (M log ).Finally, consider case z < 1. Unfortunately, regularity condition case3 Theorem 1 hold fz (M ). Instead using Theorem 1, resort proofinduction.291fiYates & EtzioniSpecifically, show induction whenever z < 1 2, NM,z c ,z2zc = Max( 2 2+1 , 22z ). First, consider case = 2:2X2zN2,z =i=1ziz= 2 +12z + 12=2cMprove induction case.NM,z 2z NM/2,z + fz (M/2)2z cM/2 + fz (M/2)z(by induction hypothesis)z2 cM/2 + 2 M/2= cM (2z1 + 2z1 /c)2 2z)cM (2z1 + 2z12z= cM(by definition c)2data used Resolver experiments Section 4 shape parameter z < 1,bound number comparisons made O(N log N ) = O(M log ). z = 1,bound O(N log N ) = O(M log log(M log )) = O(M log2 ). z > 1,bound O(M z log ). z = 2 would asymptotic performance O(M 2 log )worse O(M 2 ). past experience guide, high value zunlikely extractions naturally occurring text.ReferencesAgichtein, E. (2006). Web Information Extraction User Information Needs: TowardsClosing Gap. IEEE Data Engineering Bulletin issue Web-Scale Data, Systems,Semantics, December.Artile, J., Sekine, S., & Gonzalo, J. (2008). Web people search: results first evaluationplan second. Proceeding 17th international conferenceWorld Wide Web.Bagga, A., & Baldwin, B. (1998). Entity-based cross-document coreferencing usingvector space model. COLING-ACL.Banko, M., Cafarella, M. J., Soderland, S., Broadhead, M., & Etzioni, O. (2007). Openinformation extraction web. IJCAI.292fiUnsupervised Methods Determining Object Relation SynonymsBarzilay, R., & Lee, L. (2003). Learning Paraphrase: Unsupervised Approach UsingMultiple-Sequence Alignment. Proc. NAACL-HLT.Barzilay, R., & McKeown, K. (2001). Extracting paraphrases parallel corpus.Proceedings ACL/EACL.Bean, D., & Riloff, E. (2004). Unsupervised learning contextual role knowledgecoreference resolution. Proceedings Annual Meeting North AmericanChapter Association Computational Linguistics (HLT/NAACL).Beygelzimer, A., Kakade, S., & Langford, J. (2006). Cover trees nearest neighbor.Proceeings 23rd International Conference Machine Learning (ICML).Bhattacharya, I., & Getoor, L. (2005). Relational Clustering Multi-type Entity Resolution. 11th ACM SIGKDD Workshop Multi Relational Data Mining.Bhattacharya, I., & Getoor, L. (2006). Query-time entity resolution. KDD.Brockett, C., & Dolan, W. B. (2005). Support vector machines paraphrase identificationcorpus construction. International Workshop Paraphrasing.Cardie, C., & Wagstaff, K. (1999). Noun Phrase Coreference Clustering. ProceedingsJoint Conference Empirical Methods Natural Language ProcessingLarge Corpora.Cohen, W. W. (1998). Providing database-like access web using queries basedtextual similarity. Proceedings ACM SIGMOD International ConferenceManagement Data.Cohen, W., Ravikumar, P., & Fienberg, S. (2003). comparison string distance metricsname-matching tasks. IIWeb.Cormen, T. H., Leiserson, C. E., & Rivest, R. L. (1990). Introduction Algorithms.MIT Press.Dagan, I., Glickman, O., & Magnini, B. (2006). PASCAL Recognising Textual Entailment Challenge. Lecture Notes Computer Science, 3944, 177190.Davidov, D., & Rappoport, A. (2008). Unsupervised Discovery Generic RelationshipsUsing Pattern Clusters Evaluation Automatically Generated SAT AnalogyQuestions. Proceedings ACL.Dong, X., Halevy, A., & Madhavan, J. (2005). Reference reconciliation complex information spaces. SIGMOD.Downey, D., Etzioni, O., & Soderland, S. (2005). Probabilistic Model RedundancyInformation Extraction. IJCAI.Downey, D., Schoenmackers, S., & Etzioni, O. (2007). Sparse information extraction: Unsupervised language models rescue. ACL.293fiYates & EtzioniEtzioni, O., Cafarella, M., Downey, D., Kok, S., Popescu, A., Shaked, T., Soderland, S.,Weld, D., & Yates, A. (2005). Unsupervised named-entity extraction web:experimental study. Artificial Intelligence, 165 (1), 91134.Gionis, A., Indyk, P., & Motwani, R. (1999). Similarity search high dimensions viahashing. Proceedings 25th Conference Large Databases (VLDB).Haghighi, A., & Klein, D. (2007). Unsupervised Coreference Resolution NonparametricBayesian Model. Proceedings ACL.Hasegawa, T., Sekine, S., & Grishman, R. (2004). Discovering relations among namedentities large corpora. Proceedings ACL.Hernandez, M. A., & Stolfo, S. J. (1995). merge/purge problem large databases.SIGMOD.Hindle, D. (1990). Noun classification predicage-argument structures. ACL.Ide, N., & Veronis, J. (1998). Word Sense Disambiguation: State Art. Computational Linguistics, 24 (1), 140.Kehler, A. (1997). Probabilistic coreference information extraction. EMNLP.Kehler, A., Appelt, D., Taylor, L., & Simma, A. (2004). (non)utility predicateargument frequencies pronoun interpretation. Proceedings Annual Meeting North American Chapter Association Computational Linguistics(HLT/NAACL).Kok, S., & Domingos, P. (2007). Statistical predicate invention. ProceedingsTwenty-Fourth International Conference Machine Learning.Kulkarni, A., & Pedersen, T. (2008). Name Discrimination Email Clustering UsingUnsupervised Clustering Similar Contexts. Journal Intelligent Systems (SpecialIssue: Recent Advances Knowledge-Based Systems Applications), 17 (13), 3750.Lappin, S., & Leass, H. J. (1994). algorithm pronominal anaphora resolution. Computational Linguistics, 20 (4), 535561.Lee, L. (1999). Measures distributional similarity. Proceedings 37th ACL.Li, H., & Abe, N. (1998). Word clustering disambiguation based co-occurence data.COLING-ACL, pp. 749755.Li, X., Morie, P., & Roth, D. (2004a). Identification tracing ambiguous names:Discriminative generative approaches. Proceedings National ConferenceArtificial Intelligence (AAAI), pp. 419424.Li, X., Morie, P., & Roth, D. (2004b). Robust reading: Identification tracingambiguous names. Proc. Annual Meeting North American AssociationComputational Linguistics (NAACL), pp. 1724.294fiUnsupervised Methods Determining Object Relation SynonymsLin, D., & Pantel, P. (2001). DIRT Discovery Inference Rules Text. KDD.Liu, T., Moore, A. W., Gray, A., & Yang, K. (2004). investigation practical approximate nearest neighbor algorithms. Proceedings 22nd Annual ConferenceNeural Information Processing Systems (NIPS).Mann, G., & Yarowsky, D. (2003). Unsupervised personal name disambiguation. CoNLL.Manning, C. D., & Schuetze, H. (1999). Foundations Statistical Natural Language Processing. MIT Press.McCallum, A., Nigam, K., & Ungar, L. (2000). Efficient clustering high-dimensional datasets application reference matching. KDD.McCallum, A., & Wellner, B. (2004). Conditional models identity uncertaintyapplication noun coreference. NIPS.McCarthy, J., & Lehnert, W. (1995). Using decision trees coreference resolution.Proceedings Fourteenth International Conference Artificial Intelligence.Miller, G. A., Beckwith, R., Fellbaum, C., Gross, D., & Miller., K. J. (1990). IntroductionWordNet: on-line lexical database. International Journal Lexicography, 3(4),235312.Monge, A. E., & Elkan, C. (1996). Field Matching Problem: Algorithms Applications. Knowledge Discovery Data Mining, pp. 267270.Ng, V., & Cardie, C. (2002). Improving machine learning approaches coreference resolution. ACL.Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based alignment multiple translations: Extracting paraphrases generating new sentences. ProceedingsHLT/NAACL.Pedersen, T., & Kulkarni, A. (2007). Unsupervised Discrimination Person Names WebContexts. Proceedings Eighth International Conference Intelligent TextProcessing Computational Linguistics.Pereira, F., Tishby, N., & Lee, L. (1993). Distributional clustering English words.Proceedings 31st ACL.Popescu, A.-M. (2007). Information Extraction Unstructured Web Text. Ph.D. thesis,University Washington.Ravikumar, P., & Cohen, W. W. (2004). hierarchical graphical model record linkage.UAI.Riloff, E., & Jones, R. (1999). Learning Dictionaries Information Extraction Multilevel Bootstrapping. Proceedings Sixteenth National Conference ArtificialIntelligence, pp. 474479.295fiYates & EtzioniSalton, G., & McGill, M. (1983). Introduction Modern Information Retrieval. McGrawHill.Sekine, S. (2005). Automatic Paraphrase Discovery based Context Keywords NE Pairs. International Workshop Paraphrasing.Shinyama, Y., & Sekine, S. (2003). Paraphrase acquisition information extraction.International Workshop Paraphrasing.Singla, P., & Domingos, P. (2006). Entity Resolution Markov Logic. ICDM.Sinha, R., & Mihalcea, R. (2007). Unsupervised graph-based word sense disambiguationusing measures word semantic similarity. Proceedings IEEE InternationalConference Semantic Computing (ICSC 2007).Snow, R., Jurafsky, D., & Ng, A. Y. (2006). Semantic taxonomy induction heterogenous evidence. COLING/ACL.Voorhees, E. (2002). Overview TREC-2002 question-answering track. TREC.Winkler, W. (1999). state record linkage current research problems. Tech. rep.,U.S. Bureau Census, Washington, D.C.Yates, A., & Etzioni, O. (2007). Unsupervised resolution objects relationsweb. Proceedings HLT-NAACL.Zhu, J., Nie, Z., Wen, J.-R., Zhang, B., & Ma, W.-Y. (2005). 2D Conditional Random FieldsWeb Information Extraction. Proceedings 22nd International ConferenceMachine Learning.Zipf, G. K. (1932). Selective Studies Principle Relative Frequency Language.296fiJournal Artificial Intelligence Research 34 (2009) 89-132Submitted 8/08; published 2/09Policy Iteration Decentralized ControlMarkov Decision ProcessesDaniel S. Bernsteinbern@cs.umass.eduChristopher Amatocamato@cs.umass.eduDepartment Computer ScienceUniversity MassachusettsAmherst, 01003 USAEric A. Hansenhansen@cse.msstate.eduDepartment CS EngineeringMississippi State UniversityMississippi State, MS 39762 USAShlomo Zilbersteinshlomo@cs.umass.eduDepartment Computer ScienceUniversity MassachusettsAmherst, 01003 USAAbstractCoordination distributed agents required problems arising many areas, including multi-robot systems, networking e-commerce. formal frameworkproblems, use decentralized partially observable Markov decision process (DECPOMDP). Though much work done optimal dynamic programming algorithmssingle-agent version problem, optimal algorithms multiagent caseelusive. main contribution paper optimal policy iteration algorithmsolving DEC-POMDPs. algorithm uses stochastic finite-state controllers represent policies. solution include correlation device, allows agents correlateactions without communicating. approach alternates expandingcontroller performing value-preserving transformations, modify controllerwithout sacrificing value. present two efficient value-preserving transformations: onereduce size controller improve value keepingsize fixed. Empirical results demonstrate usefulness value-preserving transformationsincreasing value keeping controller size minimum. broaden applicability approach, also present heuristic version policy iteration algorithm,sacrifices convergence optimality. algorithm reduces sizecontrollers step assuming probability distributions agentsactions known. assumption may hold general, helps produce higherquality solutions test problems.1. IntroductionMarkov decision processes (MDPs) provide useful framework solving problemssequential decision making uncertainty. settings, agents must basedecisions partial information system state. case, often better usegeneral framework partially observable Markov decision processes (POMDPs).Even general problems team decision makers,c2009AI Access Foundation Morgan Kaufmann Publishers. rights reserved.fiBernstein, Amato, Hansen, & Zilbersteinlocal observations, must act together. Domains types problems ariseinclude networking, multi-robot coordination, e-commerce, space exploration systems.decentralized partially observable Markov decision process (DEC-POMDP) provideseffective framework model problems. Though model recognizeddecades (Witsenhausen, 1971), little work provably optimal algorithmsit.hand, POMDPs studied extensively past decades(Smallwood & Sondik, 1973; Simmons & Koenig, 1995; Cassandra, Littman, & Zhang, 1997;Hansen, 1998a; Bonet & Geffner, 2000; Poupart & Boutilier, 2003; Feng & Zilberstein, 2004;Smith & Simmons, 2005; Smith, Thompson, & Wettergreen, 2007). well knownPOMDP reformulated equivalent belief-state MDP. belief-state MDPcannot solved straightforward way using MDP methods continuousstate space. However, Smallwood Sondik showed implement value iterationexploiting piecewise linearity convexity value function. work openeddoor many algorithms, including approximate approaches policy iteration algorithmspolicy represented using finite-state controller.Extending dynamic programming POMDPs multiagent case straightforward. one thing, clear define belief state consequently formbelief-state MDP. multiple agents, agent uncertainty observationsbeliefs agents. Furthermore, finite-horizon DEC-POMDP problemtwo agents complete higher complexity class single-agent version(Bernstein, Givan, Immerman, & Zilberstein, 2002), indicating fundamentallydifferent problems.paper, describe extension policy iteration algorithm single agentPOMDPs multiagent case. single agent case, algorithm convergeslimit, thus serves first nontrivial optimal algorithm infinite-horizonDEC-POMDPs. optimal approaches (Hansen, Bernstein, & Zilberstein, 2004; Szer,Charpillet, & Zilberstein, 2005) several approximate algorithms developedfinite-horizon DEC-POMDPs (Peshkin, Kim, Meuleau, & Kaelbling, 2000; Nair, Pynadath,Yokoo, Tambe, & Marsella, 2003; Emery-Montemerlo, Gordon, Schnieder, & Thrun, 2004;Seuken & Zilberstein, 2007), locally optimal algorithms proposedinfinite-horizon case (Bernstein, Hansen, & Zilberstein, 2005; Szer & Charpillet, 2005;Amato, Bernstein, & Zilberstein, 2007).algorithmic framework, policies represented using stochastic finite-state controllers. simple way implement give agent local controller.case, agents policies independent. general class policies includesallow agents share common source randomness without sharing observations. define class formally, using shared source randomness called correlationdevice. use correlated stochastic policies DEC-POMDP context novel.importance correlation recognized game theory community (Aumann,1974), little work algorithms finding correlated policies.iteration algorithm consists two phases. exhaustive backups,add nodes controller, value-preserving transformations, changecontroller without sacrificing value. first provide novel exposition existing single90fiPolicy Iteration DEC-POMDPsagent algorithms using two-phase view, go describe multiagentextension.many possibilities value-preserving transformations. paper,describe two different types, performed efficiently using linear programming. first type allows us remove nodes controller, secondallows us improve value controller keeping size fixed. empiricalresults demonstrate usefulness value-preserving transformations obtaining highvalues keeping controller size minimum.note work serves unify generalize previous work dynamic programming DEC-POMDPs. first algorithm finite-horizon case (Hansen et al., 2004)extended infinite-horizon case viewed interleaving exhaustive backupscontroller reductions. bounded policy iteration algorithm DEC-POMDPs (Bernstein et al., 2005), extends POMDP algorithm proposed Poupart Boutilier(2003), viewed lens framework repeated application specificvalue-preserving transformation.optimal algorithm usually able return optimal solutionpractice, also introduce heuristic version policy iteration algorithm.approach makes use initial state information focus policy search reducescontroller size step. accomplish this, forward search initial statedistribution used construct set belief points agent would visit assumingagents use given fixed policies. search conducted agent policyiteration takes place using belief points guide removal controller nodes.assumption agents use fixed policies causes algorithm longeroptimal, performs well practice. show concise higher-valuedsolutions produced compared optimal method resources exhausted.remainder paper organized follows. Section 2 introduces formalmodels sequential decision making. Section 3 contains novel presentation existingdynamic programming algorithms POMDPs. section 4, present extensionpolicy iteration POMDPs DEC-POMDP case, along convergence proof.discuss heuristic version policy iteration section 5, followed experimentsusing policy iteration heuristic policy iteration section 6. Finally, section 7 containsconclusion discussion possible future work.2. Formal Model Distributed Decision Makingbegin description formal framework upon work based.framework extends well-known Markov decision process allow distributed policyexecution. also define optimal solution model discuss two differentrepresentations solutions.2.1 Decentralized POMDPsdecentralized partially observable Markov decision process (DEC-POMDP) defined for~ T, R, ,~ Oi,mally tuple hI, S, A,finite set agents.91fiBernstein, Amato, Hansen, & ZilbersteinAgentAgents, rSystema1AgentSystemo, rSystemo1, ra2o2, rAgent(a)(b)(c)Figure 1: (a) Markov decision process. (b) Partially observable Markov decision process.(c) Decentralized partially observable Markov decision process two agents.finite set states, distinguished initial state s0 .~ = iI Ai set joint actions, Ai set actions agent i.~ state transition function, defining distributions states: SAresult starting given state agent performing action.~ < reward function set agents set joint actionsR :state.~ = iI set joint observations, contains observations agent i.~~ observation function, defining distributions observationsO:Aset agents result agent performing action endinggiven state.special case DEC-POMDP one agent called partiallyobservable Markov decision process (POMDP).paper, consider case process unfolds infinite sequencestages. stage, agents simultaneously select action, receivesglobal reward based reward function local observation based observationfunction. Thus, transitions, rewards observations depend actionsagents, agent must act based local observations. illustratedFigure 1. objective agents maximize expected discounted sumrewards received, thus cooperative framework. denote discountfactor require 0 < 1.DEC-POMDP, decisions agent affect agents domain,due decentralized nature model agent must choose actions based solelylocal information. agent receives separate observation usuallyprovide sufficient information efficiently reason agents, solving DECPOMDP optimally becomes difficult. example, agent may receive different92fiPolicy Iteration DEC-POMDPs(a)(b)Figure 2: set horizon three policy trees (a) two node stochastic controllers (b)two agent DEC-POMDP.piece information allow common state estimate estimateagents decisions calculated. single estimates crucial single agentproblems, allow agents history summarize concisely,generally available DEC-POMDPs. seen complexity finite-horizonproblem least two agents, NEXP-complete (Bernstein et al., 2002)thus practice may require double exponential time. Like infinite-horizon POMDP,optimally solving infinite-horizon DEC-POMDP undecidable may require infiniteresources, method able provide solution within optimal finitetime memory. Nevertheless, introducing multiple decentralized agents causes DECPOMDP significantly difficult single agent POMDP.2.2 Solution Representationslocal policy agent mapping local action observation histories actionsjoint policy set policies, one agent problem. mentionedabove, optimal solution DEC-POMDP joint policy maximizesexpected sum rewards received finite infinite steps problem.infinite-horizon problems, rewards discounted maintain finite sum. Thus,optimal solution joint policy provides highest value starting given initialstate problem.finite-horizon problems, local policies represented using policy tree seenFigure 2a. Actions represented arrows stop figures (where agentmove given direction stay is) observations labeled wl wrseeing wall left right respectively. Using representation, agenttakes action defined root node seeing observation, choosesnext action defined respective branch. continues actionleaf node executed. example, agent 1 would first move left wall seenright, agent would move left again. wall seen left, agentmove final step. policy tree record entire local historyagent fixed horizon tree independent others93fiBernstein, Amato, Hansen, & Zilbersteinexecuted decentralized manner. representation useful finite-horizonproblems, infinite-horizon problems would require trees infinite height.Another option used paper condition action selection internalmemory state. solutions represented set local finite-state controllers(seen Figure 2b). controllers operate similar way policy treesdesignated initial node following action selection node,controller transitions next node depending observation seen. continuesinfinite steps problem. Throughout paper, controller states referrednodes help distinguish system states.infinite number nodes may required define optimal infinite-horizon DECPOMDP policy, discuss way produce solutions within optimalfixed number nodes. deterministic action selection node transitionssufficient define -optimal policy, memory limited stochastic action selectionnode transition may beneficial. simple example illustrating POMDPsgiven Singh (1994), easily extended DEC-POMDPs. Intuitively,randomness help agent break costly loops result forgetfulness.formal description stochastic controllers POMDPs DEC-POMDPs givensections 3.2.1 4.1.1 respectively, example seen Figure 2b. Agent 2begins node 1 moves probability 0.89 stays place probability0.11. agent stayed place wall seen left (observation wl),next step, controller would transition node 1 agent would usedistribution actions again. wall seen right instead (observation wr),0.85 probability controller transition back node 1 0.15probability controller transition node 2 next step. finite-statecontroller allows infinite-horizon policy represented compactly rememberingaspects agents history without representing entire local history.3. Centralized Dynamic Programmingsection, cover main concepts involved dynamic programming single agent case. provide foundation multiagent dynamic programmingalgorithm described following section.3.1 Value Iteration POMDPsValue iteration used solve POMDPs optimally. algorithm complicatedMDP counterpart, efficiency guarantees. However, practiceprovide significant leverage solving POMDPs.begin explaining every POMDP equivalent MDP continuousstate space. Next, describe value functions MDP special structureexploited. ideas central value iteration algorithm.3.1.1 Belief State MDPsconvenient way summarize observation history agent POMDPbelief state, distribution system states. receives observations,94fiPolicy Iteration DEC-POMDPsagent update belief state remove observations memory. Let bdenote belief state, let b(s) represent probability assigned state b.agent chooses action belief state b subsequently observes o, componentsuccessor belief state obeys equationPP (o|a, s0 ) sS P (s0 |s, a)b(s)0 0b (s ) =,P (o|b, a)"P (o|b, a) =X#0P (o|a, )s0X0P (s |s, a)b(s) .sSNote simple application Bayes rule.shown Astrom (1965) belief state constitutes sufficient statisticagents observation history, possible define MDP belief statesfollows. belief-state MDP tuple h, A, T, Ri,set distributions S.set actions (same before).(b, a, b0 ) transition function, definedX(b, a, b0 ) =P (b0 |b, a, o)P (o|b, a).oOR(b, a) reward function, definedR(b, a) =Xb(s)R(s, a).sScombined belief-state updating, optimal solution MDP usedoptimal solution POMDP constructed. However, sincebelief state MDP continuous, |S|-dimensional state space, traditional MDP techniquesimmediately applicable.Fortunately, dynamic programming used find solution belief stateMDP. key result making dynamic programming practical proved SmallwoodSondik (1973), showed Bellman operator preserves piecewise linearityconvexity value function. Starting piecewise linear convex representationV , value function V t+1 piecewise linear convex, computed finitetime.represent piecewise linear convex value function, one need store valuefacet system state. Denoting set facets , store || |S|dimensional vectors real values.PFor single vector, , define valuebelief state b V (b, ) = sS b(s)(s). Thus, go set vectorsvalue belief state, use equationXV (b) = maxb(s)(s).sS95fiBernstein, Amato, Hansen, & Zilbersteins1s1s2(a)s2(b)Figure 3: piecewise linear convex value function POMDP two states (a)non-minimal representation piecewise linear convex value functionPOMDP (b).Figure 3a shows piecewise linear convex value function POMDP two states.Smallwood Sondik proved optimal value function finite-horizonPOMDP piecewise linear convex. optimal value function infinite-horizonPOMDP convex, may piecewise linear. However, approximatedarbitrarily closely piecewise linear convex value function, value iterationalgorithm constructs closer closer approximations, shall see.3.1.2 Pruning VectorsEvery piecewise linear convex value function minimal set vectors represents it. course, possible use non-minimal set represent function.illustrated Figure 3b. Note removal certain vectors changevalue belief state. Vectors necessary keep memory.Formally, say vector dominated belief states b, vector\ V (b, ) V (b, ).dominated vectors necessary, would useful methodremoving them. task often called pruning, efficient algorithm basedlinear programming. given vector , linear program Table 1 determineswhether dominated. variables found make positive, addingset improves value function belief state. not, dominated.gives rise simple algorithm pruning set vectors obtain minimalset . algorithm loops , removes vector , solves linearprogram using \ . dominated, returned .turns equivalent way characterize dominance useful.Recall vector dominated, single vectorvalue least high states. sufficient exist set vectorsbelief states, one vectors set value least high vectorquestion.96fiPolicy Iteration DEC-POMDPsVariables: , b(s)Objective: Maximize .Improvement constraints:Xb(s)(s) +Xb(s)(s)Probability constraints:Xb(s) = 1,b(s) 0Table 1: linear program testing whether vector dominated.12convex combination3s1s2Figure 4: dual interpretation dominance. Vector 3 dominated belief stateseither 1 2 . equivalent existence convex combination1 2 dominates 3 belief states.shown set exists convex combinationvectors value least high vector question states.shown graphically Figure 4. take dual linear program dominancegiven previous section, get linear program solution vectorprobabilities convex combination. dual view dominance first usedPOMDP context Poupart Boutilier (2003), useful policy iteration,explained later.3.1.3 Dynamic Programming Updatesection, describe implement dynamic programming update govalue function Vt value function Vt+1 . terms implementation, aim takeminimal set vectors represents Vt produce minimal set vectors t+1represents Vt+1 .97fiBernstein, Amato, Hansen, & Zilbersteinvector could potentially included t+1 represents value actionassignment vectors observations. combination action transitionrule hereafter called one-step policy. value vector one-step policydetermined considering action taken, resulting state transitionedobservation seen value assigned vector step t. given viaequationXit+1 (s) = R(s, (i)) +P (s0 |s, (i))P (o|(i), s0 )t (i,o) (s0 ),s0 ,oindex vector, (i) action, (i, o) index vectortransition upon receiving observation discount factor.details derivation use formula provided Zhang Zhang (2001).|A||t ||| possible one-step policies. simple way construct t+1evaluate possible one-step policies apply pruning algorithm Larksmethod (Lark III, 1990). Evaluating entire set one-step policies hereaftercalled performing exhaustive backup. turns ways performdynamic programming update without first performing exhaustive backup.describe two approaches this.first approach uses fact simple find optimal vectorparticular belief state. belief state b, optimal action determined viaequation"#XP (o|b, a)V (T (b|a, o)) .= argmaxaA R(b, a) +observation o, subsequent belief state, computed usingBayes rule. get optimal transition rule, (o), take optimal vectorbelief state corresponding o.Since backed-up value function finitely many vectors, must finite setbelief states backups must performed. Algorithms identify beliefstates include Smallwood Sondiks one-pass algorithm (1973), Chengs linear supportrelaxed region algorithms (Cheng, 1988), Kaelbling, Cassandra LittmansWitness algorithm (1998).second approach based generating pruning sets vectors. Insteadgenerating vectors pruning, techniques attempt prune generation phase. first algorithm along lines incremental pruning algorithm(Cassandra et al., 1997). Recently, improvements made approach (Zhang& Lee, 1998; Feng & Zilberstein, 2004, 2005).noted theoretical complexity barriers DP updates. Littmanet al. (1995) showed certain widely believed complexity theoretic assumptions,algorithm performing DP update worst-case polynomialquantities involved. Despite fact, dynamic programming updates successfully implemented part value iteration policy iteration algorithms,described subsequent sections.98fiPolicy Iteration DEC-POMDPs3.1.4 Value Iterationimplement value iteration, simply start arbitrary piecewise linear convexvalue function, proceed perform DP updates. corresponds value iterationequivalent belief state MDP, thus converges -optimal value functionfinite number iterations.Value iteration returns value function, policy needed execution.MDP case, use one-step lookahead, using equation"#XX(b) = argmaxaAR(s, a)b(s) +P (o|b, a)V ( (b, o, a)) ,sS(b, o, a) belief state resulting starting belief state b, taking action a,receiving observation o. note state estimator must used well trackbelief state. Using fact vector corresponds one-step policy,extract policy value vectors:!X(b) = argmaxkb(s)k (s)size resulting set dominant vectors may remain exponential, manycases much smaller. significantly simplify computation.completely observable case, Bellman residual provides bounddistance optimality. Recall Bellman residual maximum distance acrossbelief states value functions successive iterations. possible findmaximum distance two piecewise linear convex functions polynomial timealgorithm uses linear programming (Littman et al., 1995).3.2 Policy Iteration POMDPsvalue iteration, POMDP viewed belief-state MDP, policy mappingbelief states actions. early policy iteration algorithm developed Sondik usedpolicy representation (Sondik, 1978), complicated meetsuccess practice. shall describe different approach performed bettertest problems. approach, policy represented finite-state controller.3.2.1 Finite-State ControllersUsing finite-state controller, agent finite number internal states. actionsbased internal state, transitions internal states occurobservations received. Internal states provide agents kind memory,crucial difficult POMDPs. course, agents memory limited numberinternal states possesses. general, agent cannot remember entire historyobservations, would require infinitely many internal states. example finitestate controller seen considering one agents controller Figure 2b.operation single controller agent decentralized case.formally define controller tuple hQ, , A, , i,99fiBernstein, Amato, Hansen, & ZilbersteinQ finite set controller nodes.set inputs, taken observations POMDP.set outputs, taken actions POMDP.: Q action selection function, defining distribution actionsselected node.: Q Q transition function, defining distribution resultingnodes initial node action taken.state starting node controller, expected discounted sumrewards infinite horizon. computed using following system linearequations, one q Q:XXV (s, q) =P (a|q) R(s, a) +P (o, s0 |s, a)P (q 0 |q, a, o)V (s0 , q 0 ) .s0 ,o,q 0P (a|q) probability action taken node q P (q 0 |q, a, o)probability controller transition node q 0 node q action takenobserved.sometimes refer value controller belief state. belief state b,definedXV (b) = maxb(s)V (s, q).qThus, assumed that, given initial state distribution, controller startednode maximizes value distribution. execution begun, however,belief state updating. fact, possible agent encounterbelief state twice different internal state time.3.2.2 Algorithmic Frameworkdescribe policy iteration algorithm abstract terms, focusing key components necessary convergence. subsequent sections, present different possibilitiesimplementation.Policy iteration takes input arbitrary finite-state controller. first phaseiteration consists evaluating controller, described above. Recall value iterationinitialized arbitrary piecewise linear convex value function, representedset vectors. policy iteration, piecewise linear convex value function arisesevaluation controller. controller node value pairedstate. Thus, node corresponding vector thus linear value functionbelief state space. Choosing best node belief state yields piecewise linearconvex value function.second phase iteration dynamic programming update. value iteration, update produces improved set vectors, vector correspondsdeterministic one-step policy. set vectors produced case,100fiPolicy Iteration DEC-POMDPsInput: finite state controller, parameter .1. Evaluate finite-state controller solving system linear equations.2. Perform dynamic programming update add set deterministic nodescontroller.3. Perform value-preserving transformations controller.4. Calculate Bellman residual. less (1 )/2, terminate.Otherwise, go step 1.Output: -optimal finite-state controller.Table 2: Policy Iteration POMDPs.actions transition rules one-step policy cannot removed memory.new vector actually node gets added controller. probability distributions added nodes deterministic. is, exhaustive backup contextcreates new node possible action possible combinations observationsdeterministic transitions current controller. results one-step policies considered dynamic programming update described above.|A||t ||| possible one-step polices, number also defines number new nodesadded controller exhaustive backup.Finally, additional operations performed controller. manyoperations, describe two possibilities following section. restrictionplaced operations decrease value belief state.operation denoted value-preserving transformation.complete algorithm outlined Table 2. guaranteed converge finitestate controller -optimal belief states within finite number steps. Furthermore, Bellman residual used obtain bound distance optimality,value iteration.3.2.3 Controller Reductionsperforming DP update, potential nodes dominated get addedcontroller. However, update performed, old nodes may becomedominated. nodes cannot simply removed, however, nodes may transitionthem. dual view dominance useful. Recall nodedominated, convex combination nodes value least highstates. Thus, remove dominated node merge dominatingconvex combination changing transition probabilities accordingly. operationproposed Poupart Boutilier (2003) built upon earlier work Hansen (1998b).Formally, controller reduction attempts replace node q Q distributionP (q) nodes q Q \ q S,XV (s, q)P (q)V (s, q).qQ\q101fiBernstein, Amato, Hansen, & ZilbersteinVariables: , x()Objective: MaximizeImprovement constraints:V (s, ) +Xx()V (s, )Probability constraints:Xx() = 1,x() 0Table 3: dual linear program testing dominance vector . variable x()represents P ().achieved solving linear program Table 3. nodes used rathervectors, replace x() x(q) dual formulation provides probability distribution nodes dominate node q. Rather transitioning q,distribution used instead. shown distribution foundused merging, resulting controller value-preserving transformationoriginal one.3.2.4 Bounded Backupsprevious section, described way reduce size controller withoutsacrificing value. method described section attempts increase valuecontroller keeping size fixed. focuses one node time, attemptschange parameters node value controller least highbelief states. idea approach originated Platzman (1980),made efficient Poupart Boutilier (2003).method, node q chosen, parameters conditional distributionP (a, q 0 |q, o) determined. Determining parameters works follows.assume original controller used second step on, try replaceparameters q better ones first step. words, lookparameters satisfy following inequality:XXV (s, q)P (a|q) R(s, a) +P (q 0 |q, a, o)P (o, s0 |s, a)V (s0 , q 0 )s0 ,o,q 0S. Note inequality always satisfied original parameters.However, often possible get improvement.new parameters found solving linear program, shown Table 4.Note size linear program polynomial sizes POMDPcontroller. call process bounded backup acts like dynamic programming102fiPolicy Iteration DEC-POMDPsVariables: , x(a), x(a, o, q 0 )Objective: MaximizeImprovement constraints:V (s, q) +Xx(a)R(s, a) +x(a) = 1,a,Xx(a, o, q 0 ) = x(a)q0x(a, o, q 0 )P (o, s0 |s, a)V (s0 , q 0 )s0 ,o,q 0Probability constraints:XXx(a) 0,a, o, q 0x(a, o, q 0 ) 0Table 4: linear program solved bounded backup. variable x(a) represents P (a|q), variable x(a, o, q 0 ) represents P (a, q 0 |q, o).backup memory constraints. see this, consider set nodes generated DPbackup. nodes dominate original nodes across belief states, everyoriginal node, must convex combination nodes set dominateoriginal node states. bounded backup finds convex combination.shown bounded backup yields value-preserving transformation. Repeated application bounded backups lead local optimum, nonenodes improved further. Poupart Boutilier (2003) showed local optimum reached nodes value function touching value functionproduced performing full DP backup. illustrated Figure 5.4. Decentralized Dynamic Programmingprevious section, presented dynamic programming POMDPs. key partPOMDP theory fact every POMDP equivalent belief-state MDP.result known DEC-POMDPs, making difficult generalize value iterationmultiagent case. lack shared belief-state requires new set toolsdeveloped solving DEC-POMDP. step direction, able developoptimal policy iteration algorithm DEC-POMDPs includes POMDP versionspecial case. algorithm focus section.first show extend definition stochastic controller multiagentcase. Multiagent controllers include correlation device, source randomnessshared agents. shared randomness increases solution quality minimallyincreasing representation size without adding communication. single agent case,policy iteration alternates exhaustive backups value-preserving transforma103fiBernstein, Amato, Hansen, & Zilbersteinvalue functionDP updatevalue functioncontrollers1s2Figure 5: local optimum bounded backups. solid line value functioncontroller, dotted line value function controller resultsfull DP update.tions. convergence proof given, along efficient transformations extendpresented previous section.4.1 Correlated Finite-State Controllersjoint policy agents represented using stochastic finite-state controlleragent. section, first define type controller agents actindependently. provide example demonstrating utility correlation,show extend definition controller allow correlation among agents.4.1.1 Local Finite-State Controllerslocal controller, agents node based local observations received,agents action based current node. local controllers definedway POMDP controllers above, agent possessing controlleroperates independently others. before, stochastic transitions action selectionallowed.formally define local controller agent tuple hQi , , Ai , , i,Qi finite set controller nodes.set inputs, taken local observations agent i.Ai set outputs, taken actions agent i.: Qi Ai action selection function agent i, defining distributionactions selected node agents controller.: Qi Ai Qi transition function agent i, defining distributionresulting nodes initial node action taken agents controller.functions parameterize conditional distribution P (ai , qi0 |qi , oi ) represents combined action selection node transition probability agent i.104fiPolicy Iteration DEC-POMDPsABBABBAAAAABBA+RRRs1s2+RBBFigure 6: DEC-POMDP correlated joint policy yields rewardoptimal independent joint policy.taken together, agents controllers determine conditional distribution P (~a, ~q 0 |~q, ~o).denoted independent joint controller. following subsection, showindependence limiting.4.1.2 Utility Correlationjoint controllers described allow agents correlate behaviorvia shared source randomness. use simple example illustrate utilitycorrelation partially observable domains agents limited memory.example generalizes one given Singh (1994) illustrate utility stochasticpolicies partially observable settings containing single agent.Consider DEC-POMDP shown Figure 6. problem two states, two agents,two actions per agent (A B). agents one observation,thus cannot distinguish two states. example, considermemoryless policies.Suppose agents independently randomize behavior using distributionsP (a1 ) P (a2 ). agents choose either B according uniform distribution,receive expected reward R2 per time step, thus expected long-termRreward 2(1). straightforward show independent policy yields higherreward one states.Next, let us consider even larger class policies agents may actcorrelated fashion. words, consider joint distributions P (a1 , a2 ). Considerpolicy assigns probability 21 pair AA probability 12 pair BB.yields average reward 0 time step thus expected long-term reward0. difference rewards obtained independent correlated policiesmade arbitrarily large increasing R.105fiBernstein, Amato, Hansen, & Zilberstein4.1.3 Correlated Joint Controllersprevious subsection, established correlation useful facelimited memory. subsection, extend definition joint controller allowcorrelation among agents. this, introduce additional finite-state machine,called correlation device, provides extra signals agents time step.device operates independently DEC-POMDP process, thus provideagents information agents observations. fact, random numbersnecessary operation could determined prior execution time made availableagents.Formally, correlation device tuple hQc , c i, Qc set nodes c :Qc Qc state transition function. step, device undergoes transition,agent observes state.must modify definition local controller take state correlationdevice input. Now, local controller agent conditional distributionform P (ai , qi0 |qc , qi , oi ). correlation device together local controllers formjoint conditional distribution P (~a, ~q 0 |~q, ~o), ~q = hqc , q1 , . . . , qn i. refercorrelated joint controller. Note correlated joint controller |Qc | = 1effectively independent joint controller. Figure 7 contains graphical representationprobabilistic dependencies correlated joint controller.value function correlated joint controller computed solving~following system linear equations, one ~q Q:V (s, ~q) =XP (~a|~q) R(s, ~a) +XP (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)V (s0 , ~q 0 ) .s0 ,~o,~q0~asometimes refer value controller initial state distribution.distribution b, definedV (b) = maxq~Xb(s)V (s, ~q).assumed that, given initial state distribution, controller started jointnode maximizes value distribution.worth noting correlation increase value set fixed-size controllers,value achieved larger set uncorrelated controllers. Thus,correlation way make better use limited representation size, requiredproduce set optimal controllers. formalized following theorem,proved Appendix A. theorem asserts existence uncorrelated controllers;determining much extra memory needed replace correlation device remainsopen problem.Theorem 1 Given initial state correlated joint controller, always existsfinite-size joint controller without correlation device produces leastvalue initial state.106fiPolicy Iteration DEC-POMDPsa1q1q2a2q2o2qco1q1Figure 7: graphical representation probabilistic dependencies correlated jointcontroller two agents.example above, higher value achieved two node uncorrelated controllers agent. problem starts s1 , first node agent would choosetransition second node would choose B. second node wouldtransition back first node. resulting policy consists agents alternatingRchoosing AA BB, producing expected long-term reward 1higher correlated one node policy value 0. Thus, doubling memoryagent problem sufficient remove correlation device.4.2 Policy Iterationsection, describe policy iteration algorithm. first extend definitionsexhaustive backup value-preserving transformation multiagent case. Followingthat, provide description complete algorithm, along convergence proof.4.2.1 Exhaustive Backupsintroduced exhaustive backups section dynamic programming POMDPs.stated one way implement DP update perform exhaustive backup,prune dominated nodes created. efficient implementationsdescribed thereafter. implementations involved interleaving pruning node generation.multiagent case, open problem whether pruning interleavednode generation. Nodes removed, show later subsection,convergence require exhaustive backups. define DP updates multiagentcase, instead make exhaustive backups central component algorithm.exhaustive backup adds nodes local controllers agents once,leaves correlation device unchanged. agent i, |Ai ||Qi ||i | nodes addedQ local controller, one one-step policy. Thus, joint controller grows|Qc | |Ai ||Qi ||Oi | joint nodes.Note repeated application exhaustive backups amounts brute force searchspace deterministic policies. converges optimality, obviously quiteinefficient. single agent case, must modify joint controller107fiBernstein, Amato, Hansen, & Zilbersteinadding new nodes. convergence, modifications must preserve value sensemade formal following section.4.2.2 Value-Preserving Transformationsextend definition value-preserving transformation multiagent case.following subsection, show definition allows convergence optimalitynumber iterations grows.dual interpretation dominance helpful understanding multiagent valuepreserving transformations. Recall POMDP, say node dominatedconvex combination nodes value least high states. Thoughdefined value-preserving transformation terms value function across beliefstates, could equivalently defined every node original controllerdominating convex combination new controller.multiagent case, concept belief state MDP, takesecond approach mentioned above. particular, require dominating convexcombinations exist nodes local controllers correlation device. transformation controller C controller qualifies value-preserving transformationC D, defined below.~ R,~ respectively.Consider correlated joint controllers C node sets Qsay C exist mappings fi : Qi Ri agent fc : Qc RcXV (s, ~q)P (~r|~q)V (s, ~r)~r~ Note relation transitive value-preserving~q Q.transformations also value-preserving transformations C.~ R.~ Examplessometimes describe fi fc single mapping f : Qefficient value-preserving transformations given later section. following subsection, show alternating exhaustive backups value-preservingtransformations yields convergence optimality.4.2.3 Algorithmic Frameworkpolicy iteration algorithm initialized arbitrary correlated joint controller.first part iteration, controller evaluated via solution system linearequations. Next, exhaustive backup performed add nodes local controllers.Finally, value-preserving transformations performed.contrast single agent case, Bellman residual testing convergence -optimality. resort simpler test -optimality based discountrate number iterations far. Let |Rmax | largest absolute valueimmediate reward possible DEC-POMDP. algorithm terminates iterationt+1 |Rmax |1. point, due discounting, value policy stepless . Justification test provided convergence proof. completealgorithm sketched Table 5.proving convergence, state key lemma regarding ordering exhaustivebackups value-preserving transformations. proof deferred Appendix.108fiPolicy Iteration DEC-POMDPsInput: correlated joint controller, parameter .1. Evaluate correlated joint controller solving system linear equations.2. Perform exhaustive backup add deterministic nodes local controllers.3. Perform value-preserving transformations controller.t+1|Rmax |4. 1, number iterations far, terminate. Else gostep 1.Output: correlated joint controller -optimal states.Table 5: Policy Iteration DEC-POMDPs.Lemma 1 Let C correlated joint controllers, let C resultsperforming exhaustive backups C D, respectively. C C D.Thus, value-preserving transformation mapping controller Cexhaustively backed up, value-preserving transformation mapping controllerC D. allows value-preserving transformations performed exhaustivebackups, ensuring value lost backup. state provemain convergence theorem policy iteration.Theorem 2 , policy iteration returns correlated joint controller -optimalinitial states finite number iterations.Proof: Repeated application exhaustive backups amounts brute force searchspace deterministic joint policies. Thus, exhaustive backups, resultingcontroller optimal steps initial state. Let integer large enought+1 |Rmax |. possible discounted sum rewards time steps small1enough optimality time steps implies -optimality infinite horizon.recall lemma, states performing value-preserving transformations backup provides least much value performing backup.inductive argument, performing steps policy iteration value-preserving transformation result exhaustive backups. argued large enough t, valuecontroller resulting exhaustive backups within optimal states.Thus, result steps policy iteration also within optimal states. 24.3 Efficient Value-Preserving Transformationssection, describe extend controller reductions bounded backupsmultiagent case. show operations value-preservingtransformations.4.3.1 Controller ReductionsRecall single agent case, node removed belief states,another node value least high. equivalent dual interpretation node109fiBernstein, Amato, Hansen, & Zilbersteinremoved exists convex combination nodes value leasthigh across entire state space.Using dual interpretation, extend rule removing nodesmultiagent case. rule applies removing nodes either local controllercorrelation device. Intuitively, considering removal node local controllercorrelation device, consider nodes controllers parthidden state.precisely, suppose considering removing node qi agent local controller. this, need find distribution P (qi ) nodes qi Qi \ qiS, qi Qi , qc Qc ,V (s, qi , qi , qc )XP (qi )V (s, qi , qi , qc ).qiQi represents set nodes agents. Finding distributionformulated linear program, shown Table 6a. case, successfinding parameters 0. linear program polynomial sizesDEC-POMDP controllers, exponential number agents.successful finding parameters make 0, mergedominated node convex combination nodes changing incoming linksdominated controller node redirected based distribution P (qi ).point, chance ever transitioning qi , thus removed.rule correlation device similar. Suppose consideringremoval node qc . case, need find distribution P (qc ) nodes qc Qc \ qc~~q Q,V (s, ~q, qc )XP (qc )V (s, ~q, qc ).qc~ set tuples local controller nodes,Note abuse notation use Qexcluding nodes correlation device. previous case, finding parametersdone using linear programming. shown Table 6b. linear program alsopolynomial sizes DEC-POMDP controllers, exponentialnumber agents.following theorem, states controller reductions value-preservingtransformations.Theorem 3 controller reduction applied either local node node correlation device value-preserving transformation.Proof: Suppose replaced agent node qi distribution nodesQi \ qi . Let us take fi identity map nodes except qi , mapnew distribution. take fc identity map, take fj identitymap j 6= i. yields complete mapping f . must show f satisfiescondition given definition value-preserving transformation.110fiPolicy Iteration DEC-POMDPs(a) Variables: , x(qi )Objective: MaximizeImprovement constraints:s, qi , qcV (s, qi , qi , qc ) +Xx(qi )V (s, qi , qi , qc )qiProbability constraints:Xqix(qi ) = 1,x(qi ) 0qi(b) Variables: , x(qc )Objective: MaximizeImprovement constraints:s, ~q V (s, ~q, qc ) +Xx(qc )V (s, ~q, qc )qcProbability constraints:Xqcx(qc ) = 1,x(qc ) 0qcTable 6: (a) linear program solved find replacement agent node qi .variable x(qi ) represents P (qi ). (b) linear program solved findreplacement correlation node qc . variable x(qc ) represents P (qc ).Let Vo value function original controller, let Vn value functioncontroller qi removed. controller reduction requiresVo (s, ~q)XP (~r|~q)Vo (s, ~r)~r~ Thus,~q Q.Vo (s, ~q) =XP (~a|~q) R(s, a) +XP (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)Vo (s0 , ~q 0 )s0 ,~o,~q0~aX~aP (~a|~q) R(s, a) +XP (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)s0 ,~o,~q0111X~r0P (~r|~q)Vo (s, ~r 0 )fiBernstein, Amato, Hansen, & Zilberstein=XP (~a|~q) R(s, a) +XP (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)P (~r|~q)Vo (s, ~r 0 )s0 ,~o,~q 0 ,~r0~a~ Notice formula right Bellman operator~q Q.new controller, applied old value function. Denoting operator Tn ,system inequalities implies Tn Vo Vo . monotonicity, k 0,Tnk+1 (Vo ) Tnk (Vo ). Since Vn = limk Tnk (Vo ), Vn Vo . sufficientf satisfy condition definition value-preserving transformation.argument removing node correlation device almost identicalone given above. 24.3.2 Bounded Dynamic Programming Updatesprevious section, described way reduce size controller withoutsacrificing value. Recall single agent case, could also use bounded backupsincrease value controller keeping size fixed. techniqueextended multiagent case. previous section, extension reliesimproving single local controller correlation device, viewing nodescontrollers part hidden state.first describe detail improve local controller. this, chooseagent i, along node qi . Then, oi , search new parametersconditional distribution P (ai , qi0 |qi , oi ).search new parameters works follows. assume original controllerused second step on, try replace parameters qi betterones first step. words, look parameters satisfying followinginequality:XXV (s, ~q)P (~a|~q) R(s, a) +P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)V (s0 , ~q 0 )~as0 ,~o,~q0S, qi Qi , qc Qc . search new parameters formulatedlinear program, shown Table 7a. size polynomial sizes DEC-POMDPjoint controller, exponential number agents.procedure improving correlation device similar procedureimproving local controller. first choose device node qc , consider changingparameters first step. look parameters satisfying following inequality:XXP (~a|~q) R(s, a) +P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)V (s0 , ~q 0 )V (s, ~q)~as0 ,~o,~q0~~q Q.previous case, search parameters formulated linear program.shown Table 7b. linear program also polynomial sizes DECPOMDP joint controller, exponential number agents.following theorem states bounded backups preserve value.112fiPolicy Iteration DEC-POMDPs(a) Variables: , x(qc , ai ), x(qc , ai , oi , qi0 )Objective: MaximizeImprovement constraints:s, qi , qcXV (s, ~q, qc ) +P (ai |qc , qi )[x(qc , ai )R(s, ~a) +~aX0x(c, ai , oi , qi0 )P (qi|qc , qi , ai , oi )s0 ,~o,~q 0 ,qc0P (~o, s0 |s, ~a)P (qc0 |qc )V (s0 , ~q 0 , qc0 )]Probability constraints:Xqcx(qc , ai ) = 1,qc , ai , oix(qc , ai , oi , qi0 ) = x(qc , ai )qi0aiqc , aiXx(qc , ai ) 0,qc , ai , oi , qi0x(qc , ai , oi , qi0 ) 0(b) Variables: , x(qc0 )Objective: MaximizeImprovement constraints:s, ~q V (s, ~q, qc ) +XP (~a|qc , ~q)[R(s, ~a) +XP (~q 0 |qc , ~q, ~a, ~o)s0 ,~o,~q 0 ,qc0~a0P (s , ~o|s, ~a)x(qc0 )V (s0 , ~q 0 , qc0 )]Probability constraints:qc0Xx(qc0 ) = 1,qc0x(qc0 ) 0qc0Table 7: (a) linear program used find new parameters agent node qi .variable x(qc , ai ) represents P (ai |qi , qc ), variable x(qc , ai , oi , qi0 ) representsP (ai , qi0 |qc , qi , oi ). (b) linear program used find new parameterscorrelation device node qc . variable x(qc0 ) represents P (qc0 |qc ).113fiBernstein, Amato, Hansen, & ZilbersteinTheorem 4 Performing bounded backup local controller correlation deviceproduces new correlated joint controller value-preserving transformationoriginal.Proof: Consider case node qi agent local controller changed.define f deterministic mapping nodes original controllercorresponding nodes new controller.Let Vo value function original controller, let Vn value functionnew controller. Recall new parameters P (ai , qi0 |qc , qi , oi ) must satisfyfollowing inequality S, qi Qi , qc Qc :XXVo (s, ~q)P (~a|~q) R(s, a) +P (~q 0 |~q, ~a, ~o)P (s0 , ~o|s, ~a)Vo (s0 , ~q 0 ) .~as0 ,~o,~q0Notice formula right Bellman operator new controller, appliedold value function. Denoting operator Tn , system inequalities impliesTn Vo Vo . monotonicity, k 0, Tnk+1 (Vo ) Tnk (Vo ). SinceVn = limk Tnk (Vo ), Vn Vo . Thus, new controller value-preservingtransformation original one.argument changing nodes correlation device almost identical onegiven above. 24.4 Open Issuesnoted beginning section known way convert DECPOMDP equivalent belief-state MDP. Despite fact, able developprovably convergent policy iteration algorithm. However, policy iteration algorithmPOMDPs desirable properties besides convergence, yetable extend multiagent case. Two properties described below.4.4.1 Error Boundsfirst property existence Bellman residual. single agent case,possible compute bound distance optimality using two successive valuefunctions. multiagent case, policy iteration produces sequence controllers,value function. However, way obtain error boundvalue functions. now, bound distance optimality, must considerdiscount rate number iterations completed.4.4.2 Avoiding Exhaustive Backupsperforming DP update POMDPs, possible remove certain nodesconsideration without first generating them. Section 3, gave high-level descriptiondifferent approaches this. DEC-POMDPs, however, defineDP update instead used exhaustive backups way expand controller. Sinceexhaustive backups expensive, would useful extend sophisticatedpruning methods POMDPs multiagent case.114fiPolicy Iteration DEC-POMDPsInput: joint controller, desired number centralized belief points k, initial stateb0 fixed policy agent .1. Starting b0 , sample set k belief points agent assumingagents use fixed policy.2. Evaluate joint controller solving system linear equations.3. Perform exhaustive backup add deterministic nodes local controllers.4. Retain nodes contribute highest value belief points.5. agent, replace nodes lower value combinationnodes belief point.6. controller sizes parameters change terminate. Else go step 2.Output: new joint controller based sampled centralized belief points.Table 8: Heuristic Policy Iteration DEC-POMDPs.Unfortunately, case POMDPs, proofs correctness methodsuse fact exists Bellman equation. Roughly speaking, equation allows usdetermine whether potential node dominated analyzing nodes wouldsuccessors. currently analog Bellman equationDEC-POMDPs, able generalize results.one exception statement, however. exhaustive backupperformed agents except one, type belief state spaceconstructed agent question using system states nodesagents. POMDP node generation methods applied agent.general, though, seems difficult rule node one agent generatingnodes agents.5. Heuristic Policy Iterationoptimal policy iteration method shows set controllers value arbitrarily close optimal found, resulting controllers may large manyunnecessary nodes may generated along way. exacerbated factalgorithm cannot take advantage initial state distribution must attemptimprove controller initial state. way combat disadvantages,developed heuristic version policy iteration removes nodes basedvalue given set centralized belief points. call centralized belief pointsdistributions system state general could knownfull observability problem. result, algorithm longer optimal,often produce concise controllers higher solution quality giveninitial state distribution.115fiBernstein, Amato, Hansen, & Zilberstein5.1 Directed Pruningheuristic policy iteration algorithm uses sets belief points direct pruning process algorithm. two main advantages approach: allows simultaneous pruning agents focuses controller certain areas belief space.first discuss benefits simultaneous pruning mention advantagesfocusing small areas belief space.mentioned above, pruning method used optimal algorithm alwaysremove nodes could removed agents controllers without losingvalue. pruning requires agent consider controllers agents,nodes removed one agent, agents may able prune nodes. Thuspruning must cycle agents ceases agent removenodes. time consuming causes controller much largerneeds be.Like game theoretic concept incredible threats1 , set suboptimal policiesagent may useful agents may employ similarly suboptimal policies. is, pruning conducted agent holding agentspolicies fixed, polices useful set agent policies retained,matter quality agent policies. agents policies mayretained highest value used conjunction suboptimal policies agents. cases, removing set suboptimalpolicies simultaneously controller size reduced least maintaining value.simultaneous pruning could reduce controller sizes thus increase scalabilitysolution quality. may possible define value-preserving transformationproblems, finding nontrivial automated way maintaining optimality algorithm remains open question.advantage considering smaller part state space already shownproduce drastic performance increases POMDPs (Ji, Parr, Li, Liao, & Carin, 2007;Pineau, Gordon, & Thrun, 2003) finite-horizon DEC-POMDPs (Seuken & Zilberstein,2007; Szer & Charpillet, 2006). POMDPs, problem many states beliefspace large dimensionality, many parts may never visited optimal policy.Focusing subset belief states allow large part state space ignoredwithout significant loss solution quality.problem large state space compounded DEC-POMDP case.uncertainty state, also policies agents.consequence, generalized belief space includes possible distributionsstates system current policies agents must considered guaranteeoptimality. results huge space contains many unlikely states policies.uncertainty policies agents may utilize allow belief updatesnormally calculated DEC-POMDPs, showed above, doneassuming probability distribution actions agents. limits numberpolicies need considered agents distributions chosen well,may permit high-valued solution found.1. incredible threat irrational strategy agent knows receive lower value choosingit. possible agent choose incredible threat strategy, irrational so.116fiPolicy Iteration DEC-POMDPsVariables: , x(qi ) belief point bObjective: MaximizeImprovement constraints:b, qiXXb(s)x(qi )V (qi , qi , s) V (~q, s)XProbability constraints:qix(qi ) = 1 qi x(qi ) 0qiTable 9: linear program used determine node q agent dominatedpoint b initial nodes agents controllers. node qmay dominated distribution nodes, variable x(qi ) represents P (qi ),probability starting node q agent i.5.2 Belief Set Generationmentioned above, heuristic policy iteration algorithm constructs sets belief pointsagent later used evaluate joint controller remove dominatednodes. generate belief point set, start initial state making assumptions agents, calculate resulting belief state actionobservation pair agent. fixing policies agents, belief state update calculated way similar described POMDPs section 3.1.1.procedure repeated resulting belief state desired numberpoints generated new points visited.formally, assume agents fixed distribution action choicesystem state. is, know P (~ai |s) determine probabilitystate results given belief point agents action observation. derivationlikelihood state s0 , given belief state b, agent action ai observation oishown below.P (s0 |ai , oi , b) =XP (s0 , ~ai , ~oi , s|ai , oi , b)~ai ,~oi ,so|s, b, ~a, s0 )P (s0 , s, ~a, b)~ai ,~oi ,s P (~P=P (oi , ai , b)o|s, ~a, s0 )P (s0 |s, ~a, b)P (~a, s, b)~ai ,~oi ,s P (~P=P (oi , ai , b)o|s, ~a, s0 )P (s0 |s, ~a)P (~ai |a, s, b)P (~a, s, b)~ai ,~oi ,s P (~P=P (oi , ai , b)0 )P (s0 |s, ~P(~|s,~,a)P (~ai |ai , s, b)P (s|ai , b)P (ai , b)~ai ,~oi ,sP=P (oi , ai , b)117fiBernstein, Amato, Hansen, & ZilbersteinP=o|s, ~a,~ai ,~oi ,s P (~0 )P (s0 |s, ~a)P (~ai |s)b(s)P (oi |ai , b)XP (oi |ai , b) =P (~o|s, ~a, s0 )P (s0 |s, ~a)P (~ai |s)b(s)ai ,oi ,s,s0Thus, given action probabilities agents, i, transition observation models system, belief state update calculated.5.3 Algorithmic Frameworkprovide formal description approach Table 8. Given desired numberbelief points, k, random action observation selection agent, setspoints generated described above. search begins initial stateproblem continues given number points obtained. new pointsfound, process repeated ensure diverse set produced. arbitrary initialcontroller evaluated value state initial node agentscontroller retained. exhaustive backup procedure exactly one usedoptimal algorithm, updating controller takes place two steps. First,k belief points, highest-valued set initial nodes found. accomplishthis, value beginning combination nodes agents calculatedk points best combination kept. allows nodes contributevalues simultaneously pruned. Next, node agent prunedusing linear program shown Table 9. distribution nodes given agenthigher value belief points initial nodes agents controllers,pruned replaced distribution. new controllers evaluatedvalue compared value previous controller. process backingpruning continues controller parameters continue change.Similar bounded policy updates used conjunction pruningoptimal policy iteration algorithm, nonlinear programming approach (Amato et al., 2007)used improve solution quality heuristic case. accomplish this, insteadoptimizing controller initial belief state problem, belief pointsconsidered used. simple way achieve maximize sumvalues initial nodes controllers weighted probabilities givenpoint. approach used pruning step may improve valuecontrollers.6. Dynamic Programming Experimentssection describes results experiments performed using policy iteration.flexibility algorithm, impossible explore possible ways implementingit. However, experiment different implementation strategies gainidea algorithm works practice. experiments run 3.40GHzIntel Pentium 4 2GB memory. Three main sets experiments performedsingle set test problems.118fiPolicy Iteration DEC-POMDPsfirst set experiments focused exhaustive backups controller reductions.results confirm value improvement obtained iterated applicationtwo operations. improvement demonstrated also incorporating boundedupdates. However, exhaustive backups expensive, algorithm unablecomplete iterations test problems.second set experiments, addressed complexity issues usingbounded backups, exhaustive backups. bounded backups, ableobtain higher-valued controllers keeping memory requirements fixed. examinedsizes initial local controllers correlation device affected valuefinal solution.third set experiments examined complexity issues caused exhaustive backups using point-based heuristic. allowed heuristic policy iteration algorithmcomplete iterations optimal algorithm so, increased solutionquality largest solvable controllers. incorporating Amato et al.s NLP approach,heuristic algorithm becomes slightly less scalable heuristic pruning alone,amount value improvement per step increases. causes resulting controllersdomain highest value approach.6.1 Test Domainssection, describe three test domains, ordered size problem representation. problem, transition function, observation function, rewardfunctions described. addition, initial state specified. Although policy iterationrequire initial state input, one commonly assumed usedheuristic version algorithm. different initial states tried problem,qualitatively similar results obtained. domains, discount factor 0.9utilized.loose upper bound, centralized policy calculated problemagents share observations central agent decisions agentsmade central agent. results POMDP number states,action observation sets Cartesian products agents action observationsets. value POMDP policy provided below, DEC-POMDP policiesconstrained, optimal value may much lower.Two Agent Tiger Problemtwo agent tiger problem consists 2 states, 3 actions 2 observations (Nair et al.,2003). domain includes two doors, one leads tiger largetreasure. agent may open one doors listen. either agent opens doortiger behind it, large penalty given. door treasure behindopened tiger door not, reward given. agents choose action(i.e., opening door) larger positive reward smaller penalty givenreward cooperation. agent listens, small penalty given observation seennoisy indication door tiger behind. listening changelocation tiger, opening door causes tiger placed behind one119fiBernstein, Amato, Hansen, & Zilbersteindoor equal probability. problem begins tiger equally likely locatedbehind either door. optimal centralized policy problem value 59.817.Meeting Gridproblem, 16 states, 5 actions 4 observations, two robots must navigatetwo-by-two grid. robot sense whether walls left right,goal spend much time possible square agent.actions move up, down, left, right, stay square. robotattempts move open square, goes intended direction probability0.6, otherwise either goes another direction stays square. movewall results staying square. robots interferecannot sense other. reward 1 agents share square,0 otherwise. initial state places robots diagonally acrossoptimal centralized policy problem value 7.129.Box Pushing Problemproblem, 100 states, 4 actions 5 observations consists two agentsget rewarded pushing different boxes (Seuken & Zilberstein, 2007). agents beginfacing bottom corners four-by-three grid available actionsturning right, turning left, moving forward staying place. 0.9 probabilityagent succeed moving otherwise stay place, two agentsnever occupy square. middle row grid contains one large boxmiddle two small boxes. small boxes moved single agent, largebox moved agents pushing time. upper rowgrid considered goal row, boxes pushed into. possible deterministicobservations agent consist seeing empty space, wall, agent, smallbox large box. reward 100 given agents push large boxgoal row 10 given small box moved goal row. penalty -5given agent cannot move -0.1 given time step. boxmoved goal row, environment resets original start state. optimalcentralized policy problem value 183.936.6.2 Exhaustive Backups Controller Reductionssection, present results using exhaustive backups together controllerreductions. domain, initial controllers agent contained single nodeself loop, correlation device. problem, first actionproblem description used. resulted repeated actions openingleft door two agent tiger problem, moving meeting grid problemturning left box pushing problem. reason starting smallest possiblecontrollers see many iterations could complete running memory.iteration, performed exhaustive backup, alternatedagents, performing controller reductions nodes could removed. boundeddynamic programming results, reductions completed bounded updatesalso performed agents. experiments, attempted improve nodes120fiPolicy Iteration DEC-POMDPsIteration0123Two Agent Tiger, |S| = 2, |Ai | = 3, |i | = 2Exhaustive SizesController ReductionsBounded Updates(1, 1)-150 (1,1 1s)-150 (1,1 1s)(3, 3)-137 (3,3 1s)-20 (3,3 12s)(27, 27)-117.8 (15, 15 7s)-20 (15, 15 89s)(2187, 2187)-98.9 (255, 255 1301s) -20* (255, 255 3145s)Iteration012Meeting Grid, |S| = 16, |Ai | = 5, |i | = 4Exhaustive SizesController ReductionsBounded Updates(1, 1)2.8 (1,1 1s)2.8 (1,1 1s)(5, 5)3.4 (5,5 7s)3.8 (5,5 145s)(3125, 3125)3.7 (80,80 821s)4.78* (125,125 1204s)Iteration012Box Pushing, |S| = 100, |Ai | = 4, |i | = 5Exhaustive SizesController ReductionsBounded Updates(1, 1)-2 (1,1 4s)-2 (1,1 53s)(4, 4)-2 (2,2 108s)6.3 (2,2 132s)(4096, 4096)12.8 (9,9 755s)42.7* (16,17 714s)Table 10: Results applying exhaustive backups, controller reductions bounded updates test problems. second column contains sizes controllersexhaustive backups performed. third column containsresulting value, sizes controllers, time required controller reductionsperformed iteration. fourth column displays quantities bounded updates also used. * denotes backuppruning performed, bounded updates exhausted given resources.agent turn value could improved node agent.iteration, recorded sizes controllers produced, noted sizes wouldcontroller reductions performed. addition, recorded valueinitial state total time taken reach given result.results shown Table 10. exhaustive backups add many nodes,unable complete many iterations without exceeding memory limits. expected,smallest problem led largest number iterations completed. Althoughcould complete many iterations running memory, use controllerreductions led significantly smaller controllers compared approach applyingexhaustive backups. Incorporating bounded updates requires extra time, ableimprove value produced step, causing substantial improvement cases.also interesting notice controller sizes using bounded updatesalways controller reductions completed. seentwo iterations meeting grid box pushing problems.occur bounded updates change node value thus change numberlocation nodes pruned. box pushing problem, two agents also121fiBernstein, Amato, Hansen, & Zilbersteindifferent size controllers two steps. occur, even symmetric problems,set actions necessary single agent.6.3 Bounded Dynamic Programming Updatessaw previous experiments, exhaustive backups fill memoryquickly. leads naturally question much improvement possible withoutexhaustive backups. section, describe experiment repeatedlyapplied bounded backups, left size controller fixed. experimenteddifferent starting sizes local controllers correlation device.define trial run algorithm follows. start trial run, sizechosen local controllers correlation device. action selectiontransition functions initialized deterministic, outcomes drawn accordinguniform distribution. step consists choosing node uniformly randomcorrelation device one local controllers, performing bounded backupnode. 200 steps, run considered over. practice, found values oftenstabilized fewer steps.varied sizes local controllers maintaining number nodesagent, varied size correlation device 1 2. domain,increased number nodes required number steps could completedfour hours. general, runs required significantly less time terminate.combination sizes, performed 20 trial runs recorded best value runs.three problems, able obtain solutions higher valueexhaustive backups. Thus, see even though repeated application boundedbackups optimality guarantee, competitive algorithmdoes. However, noted performed exhaustive comparison.could made different design decisions approaches concerning startingcontrollers, order nodes considered, factors.Besides comparing exhaustive backup approach, wanted examine effectsizes local controllers correlation device value. Figure 8 showsgraph best values plotted controller size. found that, part,value increases increase size correlation device one nodetwo nodes (essentially moving independent correlated). worth notingsolution quality somewhat high variance problem, showing setting goodinitial parameters important high-valued solutions.small controllers, best value tends increase controller size. However,large controllers, always case. explained consideringbounded backup works. new node parameters acceptable, must decreasevalue combination states, nodes controllers, nodescorrelation device. becomes difficult numbers nodes increase, thuseasier get stuck local optimum. readily seen two agent tigerproblem extent meeting grid problem. Memory exhaustedphenomenon takes place box pushing problem.122fiPolicy Iteration DEC-POMDPs(a)(b)(c)Figure 8: Best value per trial run plotted size local controllers, (a)two agent tiger problem, (b) meeting grid problem (c) boxpushing problem. solid line represents independent controllers (a correlationdevice one node), dotted line represents joint controller includingtwo-node correlation device. Times ranged 1s one node controllerswithout correlation four hours largest controller found correlationproblem.6.4 Heuristic Dynamic Programming Updatesobserved above, optimal dynamic programming approach complete smallnumber backups resources exhausted. Similarly, using bounded updatesfixed size controllers generate high value solutions, difficult pickcorrect controller size initial parameters. alternative approaches,also present experiments using heuristic dynamic programming algorithm.Like optimal policy iteration experiments, initialized single node controllersagent self loops correlation device. first actions usedbackups performed memory exhausted. set belief pointsproblem generated given initial state distribution distributionactions agents. meeting grid box pushing problems,123fiBernstein, Amato, Hansen, & Zilbersteinassumed agents chose action equal probability regardless state.two agent tiger problem, assumed state agents listen probability 0.8open door probability 0.1. simple heuristic policy chosen allowstate space sampled search. number belief points usedtwo agent tiger meeting grid problems ten twenty points usedbox pushing problem.iteration, performed exhaustive backup pruned controllersdescribed steps four five Table 8. nodes contributed highestvalue belief point retained node examined using linearprogram Table 9. results NLP approach, also improved setcontrollers heuristic pruning optimizing nonlinear program whose objectivesum values initial nodes weighted belief point probabilities.report value produced optimal heuristic approaches iterationcould completed four hours memory limits machine used.nonlinear optimization performed NEOS server, provides setmachines varying CPU speeds memory limitations.values iteration problem given Figure 9. see heuristic policy iteration (HPI) methods able complete iterations optimalmethods consequence produce higher values. fact, results HPIalmost always exactly optimal policy iteration algorithm withoutbounded updates iterations completed optimal approach. Thus,improvement occurs primarily due larger number backups performed.also see incorporating bounded updates improves value optimalalgorithm, incorporating NLP approach heuristic approach produces even highervalue. Optimizing NLP requires small time overhead, substantially increasesvalue iteration. results highest controller value problem. UsingNLP also allows heuristic policy iteration converge six node controlleragent two agent tiger problem. Unfortunately, solution knownsuboptimal. heuristic algorithm, unexpected, notedeven suboptimal solutions heuristic approach outperform methodstest problems.6.5 Discussiondemonstrated policy iteration used improve correlatedindependent joint controllers. showed using controller reductions togetherexhaustive backups efficient terms memory using exhaustive backupsalone. However, due complexity exhaustive backups, even approach couldcomplete iterations test problems.Using bounded backups alone provided good way deal complexity issues.bounded backups, able find higher-valued policies previousapproach. experiments, able understand sizes localcontrollers correlation device affect final values obtained.heuristic policy iteration algorithm, demonstrated improvementdealing complexity issues. heuristic approach often able continue124fiPolicy Iteration DEC-POMDPs(a)(b)(c)Figure 9: Comparison dynamic programming algorithms (a) two agent tigerproblem, (b) meeting grid problem (c) box pushing problem.value produced policy iteration without bounded backupswell heuristic policy iteration without optimizing NLPcompared iteration time memory limit reached.improving solution quality past point optimal algorithm exhausts resources.efficient use limited representation size achieved incorporating NLPapproach well. fact, heuristic algorithm NLP improvements stepprovided results least equal highest value obtained problemsometimes markedly higher approaches. Furthermore, farknow, results highest published values three test domains.7. Conclusionpresent policy iteration algorithm DEC-POMDPs. algorithm uses novel policy representation consisting stochastic finite-state controllers agent alongcorrelation device. define value-preserving transformations show alternatingexhaustive backups value-preserving transformations leads convergence125fiBernstein, Amato, Hansen, & Zilbersteinoptimality. also extend controller reductions bounded backups single agentcase multiagent case. operations value-preserving transformationsprovably efficient. Finally, introduced heuristic version algorithmscalable produces higher values test problems. algorithm servesfirst nontrivial exact algorithm DEC-POMDPs, provides bridge largebody work dynamic programming POMDPs.work provides solid foundation solving DEC-POMDPs, much work remainsaddressing challenging problem instances. focused solving general DECPOMDPs, efficiency approaches could improved using structure foundcertain problems. would allow specialized representations solution techniquesincorporated. describe key challenges general approach, alongpreliminary algorithmic ideas extend work policy iteration.Approximation Error Bounds Often, strict optimality requirements cause computational difficulties. good compromise search policies withinbound optimal. framework easily generalized allow this.Instead value-preserving transformation, could define -value-preserving transformation, insures value states decreases . performtransformations modifications linear programs. simply needrelax requirement value returned. easily shown using-value-preserving transformation step leads convergence policywithin 1optimal states.controller reductions, relaxing tolerance may lead smaller controllersvalue sacrificed. bounded backups, may help escaping localoptima. Though relaxing tolerance bounded backup could lead decreasevalue states, small downward step could lead higher value overalllong run. currently working testing hypotheses empirically.General-Sum Games general-sum game, set agents,set strategies, strategy profile defined tuple strategies agents.agent assigns payoff strategy profile. agents may noncooperative,strategy profile may assigned different values agent.DEC-POMDP model extended general-sum game allowingagent reward function. case, strategies local policies,strategy profile joint policy. model often called partially observable stochasticgame (POSG). Hansen et al. (2004) presented dynamic programming algorithm finitehorizon POSGs. algorithm shown perform iterated elimination dominatedstrategies game. Roughly speaking, eliminates strategies usefulagent, regardless strategies agents.Work remains done extending notion value-preserving transformationnoncooperative case. One possibility redefine value-preserving transformationsvalue preserved agents. closely related idea Paretooptimality. general-sum game, strategy profile said Pareto optimalexist another strategy profile yields higher payoff agents. seemspolicy iteration using revised definition value-preserving transformation would tendmove controller direction Pareto optimal set. Another possibility126fiPolicy Iteration DEC-POMDPsdefine value-preserving transformations respect specific agents. agenttransforms controller, joint controller move towards Nash equilibrium.Handling Large Numbers Agents general DEC-POMDP representation presented paper grows exponentially number agents, seen growthset joint actions observations well transition, reward observationfunctions. Thus representation feasible large numbers agents. However,compact representation possible agent interacts directlyagents. separate state space agent, factored transition probabilities,reward function sum local reward functions clusters agents.case, problem size exponential maximum number agents interactingdirectly. idea closely related recent work graphical games (La Mura, 2000;Koller & Milch, 2003).compact representation, next question answer whetheradapt policy iteration work efficiently representation. indeed seemspossible. value-preserving transformations presented, nodesagents considered part hidden state agent consideration.techniques modify controller agent get value improvement possiblehidden states. agents state transitions rewards dependagent, need consider agents nodes part hidden state.specific compact representation along extensions different algorithms proposedNair et al. (2005).Acknowledgmentsthank Martin Allen, Marek Petrik Siddharth Srivastava helpful discussionswork. Marek Siddharth, particular, helped formalize prove Theorem 1.anonymous reviewers provided valuable feedback suggestions. Support workprovided part National Science Foundation grants IIS-0535061IIS-0812149, NASA cooperative agreement NCC-2-1311, Air ForceOffice Scientific Research grants F49620-03-1-0090 FA9550-08-1-0181.Appendix A. Proof Theorem 1correlation device produces sequence values agents observe. Let Xset possible infinite sequences generated correlation device.Let Vx (~q0 , s0 ) value correlated joint controller respect correlationsequence x X, initial nodes ~q0 agent controllers, initial state s0 problem.refer Vx (~q0 , s0 ) simply Vx value sequence x, given controllersagents. define regular sequence sequence generatedregular expression. prove Theorem 1, establish following property.Lemma 2 value sequence, whether regular non-regular, approximatedwithin sequence.Proof: property holds thanks discount factor used infinite-horizon DECPOMDPs. Given sequence x value Vx , determine another sequence x0127fiBernstein, Amato, Hansen, & Zilberstein|Vx0 Vx | < . sequence x0 constructed choosing first k elements x,choosing arbitrary regular non-regular sequence remaining elements.kRmaxlong k chosen (1), |Vx0 Vx | < . 2Theorem 1 Given initial state correlated joint controller, always existsfinite-size joint controller without correlation device produces leastvalue initial state.Proof: Let E represent expected value joint controller correlationdevice. Let V = {Vx | x X} set values produced possible correlationdevice sequences. Let inf sup represent infimum supremum V respectively.break proof two cases, depending relation expectation versussupremum. show case regular sequence found producesleast value E. regular sequence found, sequencegenerated finite-state controller embedded within agent. Thus,finite number nodes added agents controllers provide equal greatervalue, without using correlation device.Case (1) inf E < supBased Lemma 2, regular sequence x approximate supremumwithin . choose = sup E, Vx sup = E.Case (2) E = supregular sequence, x, Vx = E, choose sequence.regular sequence exists, show E 6= sup. give somewhat informalargument, formally proven using cylinder sets discussed Parker(2002). begin first choosing regular sequence. construct neighborhood around sequence (as described Lemma 2) choosing fixed length prefixprefixPlength k well-defined probability definedP sequence.P0)1 |q 0 ) . . .k1 |q k2 ) P (q 0 ) probability distributionP(qP(qcc cccqc0qc1qck1 P (qcinitial node correlation device P (qci |qci1 ) represents probability transitioning correlation device node qci node qci1 . set sequences possessprefix probability equal prefix. assumed existsregular sequence value less supremum, always choose prefixlength values sequences set less supremum.probability set nonzero value sequences lesssupremum, E 6= sup, contradiction.Therefore, regular sequence found provides least valueexpected value correlated joint controller. allows uncorrelated jointcontroller produce least value given correlated one. 2Appendix B. Proof Lemma 1ease exposition, prove lemma assumption correlationdevice. Including correlation device straightforward unnecessarily tedious.128fiPolicy Iteration DEC-POMDPsLemma 1 Let C correlated joint controllers, let C resultsperforming exhaustive backups C D, respectively. C C D.Proof: Suppose given controllers C D, C D. Call sets joint~ R,~ respectively. follows exists functionnodes controllers Q~fi : Qi Ri agent ~q QV (s, ~q)XP (~r|~q)V (s, ~r).~rdefine functions fi map two controllers C D. oldnodes, define fi produce output fi . remains specify results fiapplied nodes added exhaustive backup. New nodes C mappeddistributions involving new nodes D.describe mapping formally, need introduce new notation. Recallnew nodes deterministic. new node ~r controller D, nodes actiondenoted ~a(~r), transition rule denoted ~r 0 (~r, ~o). Now, mappings fi definedP (~r|~q) = P (~a(~r)|~q)YXP (~q 0 |~q, ~a(~r), ~o)P (~r 0 (~r, ~o)|~q 0 )q~ 0~~q controller C ~r controller D.must show mapping f satisfies inequality given definitionvalue-preserving transformation. nodes added exhaustivebackup, straightforward. new nodes ~q controller C,S,V (s, ~q) =XP (~a|~q) R(s, ~a) +XP (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)V (s0 , ~q 0 )~o,s0 ,~q0~aXP (~a|~q) R(s, ~a) +XP (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)~o,s0 ,~q0~aXP (~r 0 |~q 0 )V (s0 , ~r 0 )~r0=XP (~a|~q) R(s, ~a) +XP (s0 , ~o|s, ~a)P (~q 0 |~q, ~a, ~o)P (~r 0 |~q 0 )V (s0 , ~r 0 )~o,s0 ,~q 0 ,~r0~a=X=XP (~r|~q) R(s, ~a(~r)) +XP (s0 , ~o|s, ~a(~r))V (s0 , ~r 0 (~r, ~o))~o,s0~rP (~r|~q)V (s, ~r).~r2129fiBernstein, Amato, Hansen, & ZilbersteinReferencesAmato, C., Bernstein, D. S., & Zilberstein, S. (2007). Optimizing memory-bounded controllers decentralized POMDPs. Proceedings Twenty-Third ConferenceUncertainty Artificial Intelligence.Astrom, K. J. (1965). Optimal control Markov decision processes incomplete stateestimation. Journal Mathematical Analysis Applications, 10, 174205.Aumann, R. J. (1974). Subjectivity correlation randomized strategies. JournalMathematical Economics, 1, 6796.Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity decentralized control Markov decision processes. Mathematics Operations Research,27 (4), 819840.Bernstein, D. S., Hansen, E. A., & Zilberstein, S. (2005). Bounded policy iteration decentralized POMDPs. Proceedings Nineteenth International Joint ConferenceArtificial Intelligence, pp. 12871292.Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic searchbelief space. Proceedings Fifth International Conference AI PlanningScheduling, pp. 5261.Cassandra, A., Littman, M. L., & Zhang, N. L. (1997). Incremental pruning: simple, fast,exact method partially observable Markov decision processes. ProceedingsThirteenth Annual Conference Uncertainty Artificial Intelligence, pp. 5461.Cheng, H.-T. (1988). Algorithms Partially Observable Markov Decision Processes. Ph.D.thesis, University British Columbia.Emery-Montemerlo, R., Gordon, G., Schnieder, J., & Thrun, S. (2004). Approximate solutions partially observable stochastic games common payoffs. ProceedingsThird International Joint Conference Autonomous Agents Multi AgentSystems, pp. 136143.Feng, Z., & Zilberstein, S. (2004). Region-based incremental pruning POMDPs.Proceedings Twentieth Conference Uncertainty Artificial Intelligence, pp.146153.Feng, Z., & Zilberstein, S. (2005). Efficient maximization solving POMDPs. Proceedings Twentieth National Conference Artificial Intelligence, pp. 975980.Hansen, E. (1998a). Solving POMDPs searching policy space. ProceedingsFourteenth Annual Conference Uncertainty Artificial Intelligence, pp. 211219.Hansen, E. A. (1998b). Finite-Memory Control Partially Observable Systems. Ph.D.thesis, University Massachusetts Amherst, Amherst, Massachusetts.Hansen, E. A., Bernstein, D. S., & Zilberstein, S. (2004). Dynamic programming partiallyobservable stochastic games. Proceedings Nineteenth National ConferenceArtificial Intelligence, pp. 709715.Ji, S., Parr, R., Li, H., Liao, X., & Carin, L. (2007). Point-based policy iteration.Proceedings Twenty-Second National Conference Artificial Intelligence, pp.12431249.130fiPolicy Iteration DEC-POMDPsKaelbling, L. P., Littman, M. L., & Cassandra, A. R. (1998). Planning actingpartially observable stochastic domains. Artificial Intelligence, 101 (1-2), 99134.Koller, D., & Milch, B. (2003). Multi-agent influence diagrams representing solvinggames. Games Economic Behavior, 45 (1), 181221.La Mura, P. (2000). Game networks. Proceedings Sixteenth Conference Uncertainty Artificial Intelligence, pp. 335342.Lark III, J. W. (1990). Applications Best-First Heuristic Search Finite-Horizon Partially Observed Markov Decision Processes. Ph.D. thesis, University Virginia.Littman, M. L., Cassandra, A. R., & Kaelbling, L. P. (1995). Learning policies partiallyobservable environments: Scaling up. Proceedings Twelfth International Conference Machine Learning, pp. 362370.Nair, R., Pynadath, D., Yokoo, M., Tambe, M., & Marsella, S. (2003). Taming decentralizedPOMDPs: Towards efficient policy computation multiagent settings. ProceedingsEighteenth International Joint Conference Artificial Intelligence, pp. 705711.Nair, R., Varakantham, P., Tambe, M., & Yokoo, M. (2005). Networked distributedPOMDPs: synthesis distributed constraint optimization POMDPs. Proceedings Twentieth National Conference Artificial Intelligence, pp. 133139.Parker, D. A. (2002). Implementation Symbolic Model Checking Probabilistic Systems.Ph.D. thesis, University Birmingham, Birmingham, England.Peshkin, L., Kim, K.-E., Meuleau, N., & Kaelbling, L. P. (2000). Learning cooperate viapolicy search. Proceedings Sixteenth International Conference UncertaintyArtificial Intelligence, pp. 489496.Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: anytime algorithm POMDPs. Proceedings Eighteenth International Joint ConferenceArtificial Intelligence, pp. 10251031.Platzman, L. K. (1980). feasible computational approach infinite-horizon partiallyobserved Markov decision processes. Tech. rep., Georgia Institute Technology.Reprinted Working Notes 1998 AAAI Fall Symposium Planning UsingPartially Observable Markov Decision Processes.Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. ProceedingsAdvances Neural Information Processing Systems 16.Seuken, S., & Zilberstein, S. (2007). Improved memory-bounded dynamic programmingdecentralized POMDPs. Proceedings Twenty-Third Conference Uncertainty Artificial Intelligence.Simmons, R., & Koenig, S. (1995). Probabilistic navigation partially observable environments. Proceedings Fourteenth International Joint Conference ArtificialIntelligence, pp. 10801087.Singh, S. (1994). Learning Solve Markovian Decision Processes. Ph.D. thesis, UniversityMassachusetts, Amherst, Massachusetts.131fiBernstein, Amato, Hansen, & ZilbersteinSingh, S. P., Jaakkola, T., & Jordan, M. I. (1994). Learning without state-estimationpartially observable markovian decision processes. Proceedings EleventhInternational Conference Machine Learning, pp. 284292.Smallwood, R. D., & Sondik, E. J. (1973). optimal control partially observableMarkov processes finite horizon. Operations Research, 21 (5), 10711088.Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysisimplementation. Proceedings Twenty-First Conference UncertaintyArtificial Intelligence, pp. 542547.Smith, T., Thompson, D. R., & Wettergreen, D. S. (2007). Generating exponentially smallerPOMDP models using conditionally irrelevant variable abstraction. ProceedingsSeventeenth International Conference Applied Planning Scheduling.Sondik, E. J. (1978). optimal control partially observable Markov processesinfinite horizon: Discounted costs. Operations Research, 26, 282304.Szer, D., & Charpillet, F. (2005). optimal best-first search algorithm solving infinitehorizon DEC-POMDPs. Proceedings Sixteenth European ConferenceMachine Learning, pp. 389399.Szer, D., & Charpillet, F. (2006). Point-based dynamic programming DEC-POMDPs.Proceedings Twenty-First National Conference Artificial Intelligence, pp.12331238.Szer, D., Charpillet, F., & Zilberstein, S. (2005). MAA*: heuristic search algorithmsolving decentralized POMDPs. Proceedings Twenty-First ConferenceUncertainty Artificial Intelligence, pp. 576590.Witsenhausen, H. S. (1971). Separation estimation control discrete time systems.Proceedings IEEE, 59 (11), 15571566.Zhang, N. L., & Lee, S. S. (1998). Planning partially observable Markov decisionprocesses: Advances exact solution methods. Proceedings FourteenthConference Uncertainty Artificial Intelligence, pp. 523530.Zhang, N. L., & Zhang, W. (2001). Speeding convergence value iteration partially observable Markov decision processes. Journal Artificial Intelligence Research,14, 2951.132fiJournal Artificial Intelligence Research 34 (2009) 2759Submitted 12/07; published 01/09Heuristic Search Approach PlanningContinuous Resources Stochastic DomainsNicolas Meuleaunicolas.f.meuleau@nasa.govNASA Ames Research CenterMail Stop 269-3Moffet Field, CA 94035-1000, USAEmmanuel Benazeraebenazer@laas.frLAAS-CNRS, Universite de Toulouse7, av. du Colonel Roche31077 Toulouse Cedex 4, FranceRonen I. Brafmanbrafman@cs.bgu.ac.ilDepartment Computer ScienceBen-Gurion UniversityBeer-Sheva 84105, IsraelEric A. Hansenhansen@cse.msstate.eduDepartment Computer Science EngineeringMississippi State UniversityMississippi State, MS 39762, USAMausammausam@cs.washington.eduDepartment Computer Science EngineeringUniversity WashingtonSeattle, WA 981952350, USAAbstractconsider problem optimal planning stochastic domains resource constraints,resources continuous choice action step depends resource availability. introduce HAO* algorithm, generalization AO* algorithm performssearch hybrid state space modeled using discrete continuous state variables, continuous variables represent monotonic resources. Like heuristic searchalgorithms, HAO* leverages knowledge start state admissible heuristic focuscomputational effort parts state space could reached start statefollowing optimal policy. show approach especially effective resourceconstraints limit much state space reachable. Experimental results demonstrateeffectiveness domain motivates research: automated planning planetaryexploration rovers.1. IntroductionMany NASA planetary exploration missions rely rovers mobile robots carry suitescientific instruments use characterizing planetary surfaces transmitting information backEarth. difficulties communicating devices distant planets, direct humancontrol rovers tele-operation infeasible, rovers must able act autonomouslysubstantial periods time. example, Mars Exploration Rovers (MER), aka, SpiritOpportunity, designed communicate ground twice per Martian day.Autonomous control planetary exploration rovers presents many challenges researchautomated planning. Progress made meeting challenges. example,planning software developed Mars Sojourner MER rovers contributed significantlyc2009AI Access Foundation. rights reserved.fiMeuleau, Benazera, Brafman, Hansen & Mausamsuccess missions (Bresina, Jonsson, Morris, & Rajan, 2005). many importantchallenges must still addressed achieve ambitious goals future missions (Bresina,Dearden, Meuleau, Ramakrishnan, Smith, & Washington, 2002).Among challenges problem plan execution uncertain environments. planetarysurfaces Mars, uncertainty terrain, meteorological conditions, staterover (position, battery charge, solar panels, component wear, etc.) turn, leadsuncertainty outcome rovers actions. Much uncertainty resourceconsumption. example, factors slope terrain affect speed movement ratepower consumption, making difficult predict certainty long take rovertravel two points, much power consume so. limitscritical resources time battery power, rover plans currently conservativebased worst-case estimates time resource usage. addition, instructions sentplanetary rovers form sequential plan attaining single goal (e.g., photographinginteresting rock). action unintended outcome causes plan fail, roverstops waits instructions; makes attempt recover achieve alternativegoal. result under-utilized resources missed science opportunities.past decade, great deal research generate conditionalplans domains uncertain action outcomes. Much work formalized frameworkMarkov decision processes (Puterman, 1994; Boutilier, Dean, & Hanks, 1999). However,Bresina et al. (2002) point out, important aspects rover planning problem adequatelyhandled traditional planning algorithms, including algorithms Markov decision processes.particular, traditional planners assume discrete state space small discrete numberaction outcomes. automated planning planetary exploration rovers, critical resourcestime battery power continuous, uncertainty domain resultseffect actions variables. requires conditional planner branchdiscrete action outcomes, availability continuous resources, plannermust able reason continuous well discrete state variables.Closely related challenges uncertain plan execution continuous resourceschallenge over-subscription planning. rovers future missions much improvedcapabilities. Whereas current MER rovers require average three days visit single rock,progress areas automatic instrument placement allow rovers visit multiple rocksperform large number scientific observations single communication cycle (Pedersen,Smith, Deans, Sargent, Kunz, Lees, & Rajagopalan, 2005). Moreover, communication cycleslengthen substantially distant missions moons Jupiter Saturn, requiring longerperiods autonomous behavior. result, space scientists future missions expectedspecify large number science goals once, often present known oversubscription planning problem. refers problem infeasible achieve goals,objective achieve best subset goals within resource constraints (Smith, 2004).case rover, multiple locations rover could reach, many experimentsrover could conduct, combinations infeasible due resource constraints.planner must select feasible subset maximizes expected science return. actionoutcomes (including resource consumption) stochastic, plan maximizes expected sciencereturn conditional plan prescribes different courses action based resultsprevious actions, including resource availability.paper, present implemented planning algorithm handles problemstogether: uncertain action outcomes, limited continuous resources, over-subscription planning.formalize rover planning problem hybrid-state Markov decision process, is, Markovdecision process (MDP) discrete continuous state variables, use continuousvariables represent resources. planning algorithm introduce heuristic search algorithmcalled HAO*, Hybrid-state AO*. generalization classic AO* heuristic search algorithm (Nilsson, 1980; Pearl, 1984). Whereas AO* searches discrete state spaces, HAO* solves28fiHAO*planning problems hybrid domains discrete continuous state variables. handlehybrid domains, HAO* builds earlier work dynamic programming algorithms continuoushybrid-state MDPs, particular, work Feng et al. (2004).Generalizing AND/OR graph search hybrid state spaces poses complex challenge,consider special case problem. particular, continuous variables used representmonotonic resources. search best conditional plan allows branchingvalues discrete variables, availability resources, violateresource constraint.well-known heuristic search efficient dynamic programminguses reachability analysis guided heuristic focus computation relevant parts statespace. show problems resource constraints, including over-subscription planningproblems, heuristic search especially effective resource constraints significantly limitreachability. Unlike dynamic programming, systematic forward search algorithm AO* keepstrack trajectory start state reachable state, thus check whethertrajectory feasible violates resource constraint. pruning infeasible trajectories, heuristicsearch algorithm dramatically reduce number states must considered findoptimal policy. particularly important domain discrete state space huge(exponential number goals), yet portion reachable initial state relativelysmall, due resource constraints.2. Problem Formulation Backgroundstart formal definition planning problem tackling. special casehybrid-state Markov decision process, first define model. discussinclude resource constraints formalize over-subscription planning model. Finallyreview class dynamic programming algorithms solving hybrid-state MDPs, sincealgorithmic techniques incorporated heuristic search algorithm developSection 3.2.1 Hybrid-State Markov Decision Processhybrid-state Markov decision process, hybrid-state MDP, factored Markov decision processdiscrete continuous state variables. define tuple (N, X, A, P, R),N discrete state variable, X = {X1 , X2 , ..., Xd } set continuous state variables, setactions, P stochastic state transition model, R reward function. describeelements detail below. hybrid-state MDP sometimes referred simply hybridMDP. term hybrid refer dynamics model, discrete. Anotherterm hybrid-state MDP, originates Markov chain literature, general-stateMDP.Although hybrid-state MDP multiple discrete variables, plays role algorithms described paper, so, notational convenience, model discrete componentstate space single variable N . focus continuous component. assumeNdomain continuous variable Xi X closed interval real line, X = Xihypercube continuous variables defined. state set hybrid-stateMDP set possible assignments values state variables. particular, hybridstate pair (n, x) n N value discrete variable, x = (xi ) vectorvalues continuous variables.State transitions occur result actions, process evolves according Markovianstate transition probabilities Pr(s0 | s, a), = (n, x) denotes state actions0 = (n0 , x0 ) denotes state action a, also called arrival state. probabilitiesdecomposed into:29fiMeuleau, Benazera, Brafman, Hansen & Mausamdiscrete marginals Pr(n0 |n, x, a). (n, x, a),Pr(n0 |n, x, a) = 1;Rcontinuous conditionals Pr(x0 |n, x, a, n0 ). (n, x, a, n0 ), x0 X Pr(x0 |n, x, a, n0 )dx0 =1.Pn0 Nassume reward associated transition function arrival state only, letRn (x) denote reward associated transition state (n, x). complex dependenciespossible, sufficient goal-based domain models consider paper.2.2 Resource Constraints Over-Subscription Planningmodel rover planning problem, consider special type MDP objectiveoptimize expected cumulative reward subject resource constraints. make followingassumptions:initial allocation one non-replenishable resources,action minimum positive consumption least one resource,resources exhausted, action taken.One way model MDP resource constraints formulate constrained MDP,model widely studied operations research community (Altman, 1999).model, action incurs transition-dependent resource cost, Cai (s, s0 ), resourcei. Given initial allocation resources initial state, linear programming used findbest feasible policy, may randomized policy. Although constrained MDP modelsresource consumption, include resources state space. result, policy cannotconditioned upon resource availability. problem resource consumption eitherdeterministic unobservable. good fit rover domain, resourceconsumption stochastic observable, rover take different actions dependingcurrent resource availability.adopt different approach modeling resource constraints resources includedstate description. Although increases size state space, allows decisionsmade based resource availability, allows stochastic model resource consumption. Sinceresources rover domain continuous, use continuous variables hybrid-state MDPrepresent resources. Note duration actions one biggest sources uncertaintyrover problems, model time one continuous resources. Resource constraintsrepresented form executability constraints actions, (x) denotes setactions executable state (n, x). action cannot executed state satisfyminimum resource requirements.discussed incorporate resource consumption resource constraints hybridstate MDP, next discuss formalize over-subscription planning. rover planningproblem, scientists provide planner set goals would like rover achieve,goal corresponds scientific task taking picture rock performinganalysis soil sample. scientists also specify utility reward goal. Usuallysubset goals feasible resource constraints, problem find feasibleplan maximizes expected utility. Over-subscription planning planetary exploration roversconsidered Smith (2004) van den Briel et al. (2004) deterministic domains.consider over-subscription planning stochastic domains, especially domains stochasticresource consumption. requires construction conditional plans selection goalsachieve change depending resource availability.over-subscription planning, utility associated goal achieved once;additional utility achieved repeating task. Therefore, discrete state must include setBoolean variables keep track set goals achieved far rover, one Boolean30fiHAO*variable goal. Keeping track already-achieved goals ensures Markovian reward structure,since achievement goal rewarded achieved past. However, alsosignificantly increases size discrete state space. Maintaining history information ensureMarkovian reward structure simple example planning non-Markovian rewards (Thiebaux,Gretton, Slaney, Price, & Kabanza, 2006).2.3 Optimality Equationrover planning problem consider special case finite-horizon hybrid-state MDPtermination occurs indefinite number steps. Bellman optimality equationproblem takes following form:Vn (x)=Vn (x)=0 (n, x) terminal state; otherwise,"ZXmaxPr(n0 | n, x, a)Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0 .aAn (x)n0 N(1)x0define terminal state state actions eligible execute, is, (x) = .use terminal states model various conditions plan termination. includes situationgoals achieved; situation resources exhausted;situation action results error condition requires executing safe sequencerover terminating plan execution. addition terminal states, assume explicitinitial state denoted (n0 , x0 ).Assuming resources limited non-replenishable, every action consumesresource (and amount consumed greater equal positive quantity c), planexecution terminate finite number steps. maximum number steps boundedinitial resource allocation divided c, minimal resource consumption per step. actualnumber steps usually much less indefinite, resource consumption stochasticchoice action influences resource consumption. number steps takesplan terminate bounded indefinite, call bounded-horizon MDP contrastfinite-horizon MDP. However, note bounded-horizon MDP convertedfinite-horizon MDP specifying horizon equal maximum number plan steps,introducing no-op action taken terminal state.Note usually difference number plan steps time plan takesexecute. Since model time one continuous resources, time takes executeplan step state action dependent, stochastic.Given hybrid-state MDP set terminal states initial state (n0 , x0 ), objectivefind policy, : (N X) A, maximizes expected cumulative reward; specifically,optimal policy value function satisfies optimality equation given Equation (1).rover domain, cumulative reward equal sum rewards goals achievedreaching terminal state direct incentive save resources; optimal solution savesresources allows achieving goals. However, framework general enoughallow reasoning cost availability resources. example, incentiveconserving resources could modeled specifying reward proportional amountresources left unused upon entering terminal state. Note framework allows reasoningcost availability resources without needing formulate problemmulti-objective optimization, stay standard decision-theoretic framework.2.4 Dynamic Programming Continuous-State Hybrid-State MDPsplanning problem consider finite-horizon hybrid-state MDP, solvedalgorithm solving finite-horizon hybrid-state MDPs. algorithms solving hybridstate (and continuous-state) MDPs rely form approximation. widely-used approach31fiMeuleau, Benazera, Brafman, Hansen & MausamFigure 1: Value function initial state simple rover problem: optimal expected returnfunction two continuous variables (time energy remaining).discretize continuous state space finite number grid points solve resultingfinite-state MDP using dynamic programming interpolation (Rust, 1997; Munos & Moore,2002). Another approach parametric function approximation; function associateddynamic programming problem value function policy function approximatedsmooth function k unknown parameters. general, parametric function approximationfaster grid-based approximation, drawback may fail converge, mayconverge incorrect solution. Parametric function approximation used algorithmssolving continuous-state MDPs besides dynamic programming. Reinforcement learning algorithmsuse artificial neural networks function approximators (Bertsekas & Tsitsiklis, 1996). approachsolving MDPs called approximate linear programming extended allow continuouswell discrete state variables (Kveton, Hauskrecht, & Guestrin, 2006).review another approach solving hybrid-state (or continuous-state) MDPs assumesproblem special structure exploited dynamicprogramming algorithm.Rstructure assumed approach ensures convolution x0 Pr(x0 | n, x, a, n0 )(Rn0 (x0 )+Vn0 (x0 ))dx0 Equation (1) computed exactly finite time, value function computeddynamic programming piecewise-constant piecewise-linear. initial idea approachdue work Boyan Littman (2000), describe class MDPs called time-dependentMDPs, transitions take place along single, irreversible continuous dimension.describe dynamic programming algorithm computing exact piecewise-linear value functiontransition probabilities discrete rewards piecewise linear. Feng et al. (2004)extend approach continuous state spaces one dimension, consider MDPsdiscrete transition probabilities two types reward models: piecewise constant piecewiselinear. Li Littman (2005) extend approach allow transition probabilitiespiecewise-constant, instead discrete, although extension requires approximationdynamic programming algorithm.problem structure exploited algorithms characteristic Mars rover domainover-subscription planning problems. Figure 1 shows optimal value functionsinitial state typical Mars rover problem function two continuous variables:time energy remaining (Bresina et al., 2002). value functions feature set humpsplateaus, representing region state space similar goals pursuedoptimal policy. sharpness hump plateau reflects uncertainty achievinggoal(s). Constraints impose minimal resource levels attempting actions introduce32fiHAO*sharp cuts regions. Plateau regions expected reward nearly constant representregions state space optimal policy same, probability distributionfuture histories induced optimal policy nearly constant.structure value function exploited partitioning continuous statespace finite number hyper-rectangular regions. (A region hyper-rectangleCartesian product intervals dimension.) hyper-rectangle, value functioneither constant (for piecewise-constant function) linear (for piecewise-linear function).resolution hyper-rectangular partitioning adjusted fit value function. Large hyperrectangles used represent large plateaus. Small hyper-rectangles used represent regionsstate space finer discretization value function useful, edgesplateaus curved hump time energy available. natural choicedata structures rectangular partitioning continuous space kd-trees (Friedman, Bentley,& Finkel, 1977), although choices possible. Figures 6 10 Section 4.1 show valuefunctions initial state simple rover planning problem, created piecewise-constantpartitioning continuous state space.continuous-state domains transition reward functions similarly partitionedhyper-rectangles. reward function action piecewise-constant (or piecewiselinear) representation value function. transition function partitions state spaceregions set outcomes action probability distribution setoutcomes identical. Following Boyan Littman (2000), relative absolute transitionssupported. relative outcome viewed shifting region constant . is,two states x region, transition probabilitiesP r(x0 |x, a) P r(y 0 |y, a)defined term probability , = (x0 x) = (y 0 y). absolute outcomemaps states region single state. is, two states x region,P r(x0 |x, a) = P r(x0 |y, a). view relative outcome pair (, p), p probabilityoutcome, view absolute outcome pair (x0 , p). assumesfinite number non-zero probabilities, i.e., probability distribution discretized,means state action, finite set states reached non-zero probability.representation guarantees dynamic programming update piecewise-constant valuefunction results another piecewise-constant value function. Feng et al. (2004) showtransition functions finite horizon, exists partition continuous spacehyper-rectangles optimal value function piecewise constant linear.restriction discrete transition functions strong one, often means transitionfunction must approximated. example, rover power consumption normally distributed,thus must discretized. (Since amount power available must non-negative,implementation truncates negative part normal distribution renormalizes.) continuous transition function approximated appropriately fine discretization, Feng etal. (2004) argue provides attractive alternative function approximation approachesapproximates model solves approximate model exactly, rather findingapproximate value function original model. (For reason, sometimes referfinding optimal policies value functions, even model approximated.)avoid discretizing transition function, Li Littman (2005) describe algorithm allowspiecewise-constant transition functions, exchange approximation dynamic programming algorithm. Marecki et al.(2007) describe different approach class problemsprobability distributions resource consumptions represented phase-type distributions dynamic programming algorithm exploits representation. Although usework Feng et al. (2004) implementation, heuristic search algorithm developnext section could use approach representing computing valuefunctions policies hybrid-state MDP.33fiMeuleau, Benazera, Brafman, Hansen & Mausam3. Heuristic Search Hybrid State Spacesection, present primary contribution paper: approach solving specialclass hybrid-state MDPs using novel generalization heuristic search algorithm AO*.particular, describe generalization algorithm solving hybrid-state MDPscontinuous variables represent monotonic constrained resources acyclic plan foundsearch algorithm allows branching availability resources.motivation using heuristic search potentially huge size state space,makes dynamic programming infeasible. One reason size existence continuousvariables. even consider discrete component state space, sizestate space exponential number discrete variables. well-known, AO*effective solving planning problems large state space considers statesreachable initial state, uses informative heuristic function focusstates reachable course executing good plan. result, AO* often findoptimal plan exploring small fraction entire state space.begin section review standard AO* algorithm. considergeneralize AO* search hybrid state space discuss properties generalizedalgorithm, well efficient implementations.3.1 AO*Recall AO* algorithm AND/OR graph search problems (Nilsson, 1980; Pearl, 1984).graphs arise problems choices (the components), choicemultiple consequences (the component), case planning uncertainty.Hansen Zilberstein (2001) show AND/OR graph search techniques used solvingMDPs.Following Nilsson (1980) Hansen Zilberstein (2001), define AND/OR graphhypergraph. Instead arcs connect pairs nodes ordinary graph, hypergraphhyperarcs, k-connectors, connect node set k successor nodes. MDPrepresented hypergraph, node corresponds state; root node corresponds startstate, leaf nodes correspond terminal states. Thus often use word state refercorresponding node hypergraph representing MDP. k-connector correspondsaction transforms state one k possible successor states, probability attachedsuccessor probabilities sum one. paper, assume AND/OR graphacyclic, consistent assumption underlying MDP bounded-horizon.AND/OR graph search, solution takes form acyclic subgraph called solutiongraph, defined follows:start node belongs solution graph;every non-terminal node solution graph, exactly one outgoing k-connector (corresponding action) part solution graph successor nodes also belongssolution graph;every directed path solution graph terminates terminal node.solution graph maximizes expected cumulative reward found solving followingsystem equations,0 terminalstate; otherwise,PV (s) =(2)000maxaA(s)P0r(s |s, a) (R(s ) + V (s )) ,V (s) denotes expected value optimal solution state s, V calledoptimal evaluation function (or value function MDP terminology). Note identical34fiHAO*optimality equation hybrid-state MDPs defined Equation (1), latter restricteddiscrete state space. keeping convention literature MDPs, treatvalue-maximization problem even though AO* usually formalized solving cost-minimizationproblem.state-space search problems formalized AND/OR graphs, optimal solutiongraph found using heuristic search algorithm AO* (Nilsson, 1980; Pearl, 1984). Likeheuristic search algorithms, advantage AO* dynamic programming findoptimal solution particular starting state without evaluating problem states. Therefore,graph usually supplied explicitly search algorithm. implicit graph, G, specifiedimplicitly start node start state successor function generates successorsstates state-action pair. search algorithm constructs explicit graph, G0 , initiallyconsists start state. tip leaf state explicit graph said terminalgoal state (or state action taken); otherwise, saidnonterminal. nonterminal tip state expanded adding explicit graph outgoingk-connectors (one action) successor states already explicit graph.AO* solves state-space search problem gradually building solution graph, beginningstart state. partial solution graph defined similarly solution graph, differencetip states partial solution graph may nonterminal states implicit AND/OR graph.partial solution graph defined follows:start state belongs partial solution graph;every non-tip state partial solution graph, exactly one outgoing k-connector (corresponding action) part partial solution graph successor states alsobelongs partial solution graph;every directed path partial solution graph terminates tip state explicit graph.value partial solution graph defined similarly value solution graph.difference tip state partial solution graph nonterminal, valuepropagated backwards. Instead, assume admissible heuristic estimateH(s) maximal-value solution graph state s. heuristic evaluation function H saidadmissible H(s) V (s) every state s. recursively calculate admissible heuristicestimate V (s) optimal value state explicit graph follows:0 terminal state,V (s) =nonterminal tip state,H(s) isP000maxaA(s)s0 P r(s |s, a) (R(s ) + V (s )) otherwise.(3)best partial solution graph determined time propagating heuristic estimatestip states explicit graph start state. mark action maximizesvalue state, best partial solution graph determined starting rootgraph selecting best (i.e., marked) action reachable state.Table 1 outlines AO* algorithm finding optimal solution graph acyclic AND/ORgraph. interleaves forward expansion best partial solution value update stepupdates estimated state values best partial solution. simplest version AO*,values expanded state ancestor states explicit graph updated.fact, ancestor states need re-evaluated expanded statereached taking marked actions (i.e., choosing best action state). Thus,parenthetical remark step 2(b)i Table 1 indicates parent s0 state addedZ unless estimated value state changed state reached states0 choosing best action state s0 . AO* terminates policy expansion step35fiMeuleau, Benazera, Brafman, Hansen & Mausam1. explicit graph G0 initially consists start state s0 .2. best solution graph nonterminal tip state:(a) Expand best partial solution: Expand nonterminal tip state best partialsolution graph add new successor states G0 . new state s0 addedG0 expanding s, s0 terminal state V (s0 ) := 0; else V (s0 ) := H(s0 ).(b) Update state values mark best actions:i. Create set Z contains expanded state ancestors explicitgraph along marked action arcs. (I.e., include ancestor statesexpanded state reached following current best solution.)ii. Repeat following steps Z empty.A. Remove Z state descendant G0 occurs Z.PB. Set V (s) := maxaA(s) s0 P r(s0 |s, a) (R(s0 ) + V (s0 )) mark best actions. (When determining best action resolve ties arbitrarily, give preference currently marked action.)(c) Identify best solution graph nonterminal states fringe3. Return optimal solution graph.Table 1: AO* algorithm.find nonterminal states fringe best solution graph. point, best solutiongraph optimal solution.Following literature AND/OR graph search, far referred solution foundAO* solution graph. following, AO* used solve MDP, sometimesfollow literature MDPs referring solution policy. also sometimes referpolicy graph, indicate policy represented form graph.3.2 Hybrid-State AO*consider generalize AO* solve bounded-horizon hybrid-state MDP. challengeface applying AO* problem challenge performing state-space search hybridstate space.solution adopt search aggregate state space represented AND/ORgraph node distinct value discrete component state.words, node AND/OR graph represents region continuous state spacediscrete value same. Given partition continuous state space, use AND/ORgraph search techniques solve MDP parts state space reachablestart state best policy.However, AND/OR graph search techniques must modified important ways allow searchhybrid state space represented way. particular, longer correspondence nodes AND/OR graph individual states. node correspondscontinuous region state space, different actions may optimal different hybrid states associated search node. case rover planning, example,best action likely depend much energy time remaining, energy timecontinuous state variables.address problem still find optimal solution, attach search node setfunctions (of continuous variables) make possible associate different values, heuristics,actions different hybrid states map search node. before, explicit36fiHAO*search graph consists nodes edges AND/OR graph generated far,describes states considered far search algorithm. differenceuse complex state representation set continuous functions allowsrepresentation reasoning continuous part state space associated searchnode.begin describing complex node data structure, describe HAO*algorithm.3.2.1 Data Structuresnode n explicit AND/OR graph G0 consists following:value discrete state variable.Pointers parents children explicit graph policy graph.Openn () {0, 1}: Open list. x X, Openn (x) indicates whether (n, x)frontier explicit graph, i.e., generated yet expanded.Closedn () {0, 1}: Closed list. x X, Closedn (x) indicates whether (n, x)interior explicit graph, i.e., already expanded.Note that, (n, x), Openn (x) Closedn (x) = . (A state cannot openclosed.) parts continuous state space associated nodeneither open closed. explicit graph contains trajectory start stateparticular hybrid state, hybrid state considered generated, even searchnode corresponds generated; states neither open closed.addition, non-terminal states open closed. Note refer openclosed nodes; instead, refer hybrid states associated nodes openclosed.Hn (): heuristic function. x X, Hn (x) heuristic estimate optimalexpected cumulative reward state (n, x).Vn (): value function. open state (n, x), Vn (x) = Hn (x). closed state(n, x), Vn (x) obtained backing values successor states, Equation (4).n () A: policy. Note defined closed states only.Reachablen () {0, 1}: x X, Reachablen (x) indicates whether (n, x) reachableexecuting current best policy beginning start state (n0 , x0 ).assume various continuous functions, represent information hybrid states associated search node, partition state space associated nodediscrete number regions, associate distinct value action region. Givenpartitioning, HAO* algorithm expands evaluates regions hybrid state space,instead individual hybrid states. finiteness partition important order ensuresearch frontier extended finite number expansions, ensure HAO*terminate finite number steps. implementation HAO*, described Section 4, use piecewise-constant partitioning continuous state space proposed Feng etal. (2004). However, method discrete partitioning could used, provided conditionholds; example, Li Littman (2005) describe alternative method partitioning.Note two forms state-space partitioning used algorithm. First, hybrid statespace partitioned finite number regions, one discrete state,37fiMeuleau, Benazera, Brafman, Hansen & Mausamregions corresponds node AND/OR graph. Second, continuous state space associated particular node partitioned smaller regions based piecewise-constantrepresentation continuous function, one used Feng et al. (2004).addition complex representation nodes AND/OR graph, algorithmrequires complex definition best (partial) solution. standard AO*, oneto-one correspondence nodes individual states means solution policyrepresented entirely graph, called (partial) solution graph, single actionassociated node. HAO* algorithm, continuum states associatednode, different actions may optimal different regions state space associatedparticular node. HAO* algorithm, (partial) solution graph sub-graph explicitgraph defined follows:start node belongs solution graph;every non-tip node solution graph, one outgoing k-connectors partsolution graph, one action optimal hybrid state associatednode, successor nodes also belongs solution graph;every directed path solution graph terminates tip node explicit graph.key difference definition may one optimal action associatednode, since different actions may optimal different hybrid states associatednode. policy represented solution graph, continuous functions n (.)Reachablen (.). particular, (partial) policy specifies action reachable regioncontinuous state space. best (partial) policy one satisfies following optimalityequation:Vn (x)=Vn (x)= Hn (x) (n, x) nonterminal open state,"ZX=maxPr(n0 | n, x, a)Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0 .Vn (x)0 (n, x) terminal state,aAn (x)n0 N(4)x0Note optimality equation satisfied regions state space reachablestart state, (n0 , x0 ) following optimal policy.3.2.2 AlgorithmTable 2 gives high-level summary HAO* algorithm. outline, AO*algorithm, consists iteration three steps; solution (or policy) expansion, usedynamic programming update current value function policy, analysis reachabilityidentify frontier solution eligible expansion. detail, modified severalimportant ways allow search hybrid state space. following, discuss modificationsthree steps.Policy expansion nodes current solution graph identified one openregions associated nodes selected expansion. is, one regionshybrid state space intersection Open Reachable chosen expansion. actionsapplicable states open regions simulated, results actions addedexplicit graph. cases, means adding new node AND/OR graph.cases, simply involves marking one regions continuous state space associatedexisting node open. specifically, action leads new node, node addedexplicit graph, states corresponding node reachable expandedregion(s) action consideration marked open. action leads38fiHAO*1. explicit graph G0 initially consists start node corresponding start state (n0 , x0 ),marked open reachable.2. Reachablen (x) Openn (x) non-empty (n, x):(a) Expand best partial solution: Expand one region(s) open states frontierexplicit state space reachable following best partial policy. Add newsuccessor states G0 . cases, requires adding new node AND/ORgraph. cases, simply involves marking one regions continuousstate space associated existing node open. States expanded region(s)marked closed.(b) Update state values mark best actions:i. Create set Z contains node(s) associated expanded regionsstates ancestor nodes explicit graph along marked action arcs.ii. Decompose part explicit AND/OR graph consists nodes Zstrongly connected components.iii. Repeat following steps Z empty.A. Remove Z set nodes (1) belong connectedcomponent, (2) descendant nodes occurs Z.B. every node n connected component states (n, x)expanded region node n, setVn (x) :="maxaAn (x)XPr(n0 | n, x, a)ZPr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0 ,x0n0 Nmark best action. (When determining best action resolve ties arbitrarily, give preference currently marked action.) Repeatlonger change value nodes.(c) Identify best solution graph nonterminal states frontier. stepupdates Reachablen (x).3. Return optimal policy.Table 2: HAO* algorithm.existing node, region(s) Markov states node reachable expandedregion(s) marked closed, marked open. Expanded regions state space markedclosed. Thus, different regions associated node opened expandeddifferent times. process illustrated Figure 2. figure, nodes correspondingdistinct value discrete state represented rectangles, circular connectors representactions. node, see many distinct continuous regions exist. regionsee whether closed (C) open (O), whether reachable initial state (R)executing current best policy (OPT). instance, Figure 2(a), node At(Start)single region marked closed reachable, node Lost two regions: smallest, openreachable, largest, closed unreachable.Dynamic programming standard AO*, value newly-expanded node n mustupdated computing Bellman backup based value functions children n39fiMeuleau, Benazera, Brafman, Hansen & MausamAt(Start)At(Loc1)At(Start)CCRRNavigate(Start, Loc1)At(Loc1)OPTCRNavigate(Start, Loc1)OPTRNavigate(Loc1, Loc2)LostCLostRCCRAt(Loc2)PanoramicCamera(a) expansionPanoramicCamera(b) expansionFigure 2: Expanding region state space. (a) expansion: nodes At(Start),At(Loc1) Lost previously created. unique region At(Loc1)next region expanded. (b) expansion: action Navigate(Loc1, Loc2)applied expanded region added graph. action leadeither preexisting node Lost, new node At(Loc2). expanded region (inAt(Loc1)), well continuous regions reachable (in Lost At(Loc2)),highlighted dotted framed. Following expansion, expanded region closed.Discrete state At(Loc2) added graph reachable regionsopen. Additionally, new open regions added node Lost.explicit graph. expanded region state space associated node n,action evaluated, best action selected, corresponding continuous value functionassociated region. continuous-state value function computed evaluatingcontinuous integral Equation (4). use method computing integral.implementation, use dynamic programming algorithm Feng et al. (2004). reviewedSection 2.4, show continuous integral x0 computed exactly, longtransition reward functions satisfy certain conditions. Note that, hybrid-statedynamic programming techniques Feng et al. (2004), dynamic programming backups mayincrease number pieces value function attached updated regions (Figure 3(a)).expanded regions continuous state space associated node n reevaluated, new values must propagated backward explicit graph. backwardpropagation stops nodes value function modified, root node.standard AO* algorithm, summarized Figure 1, assumes AND/OR graphsearches acyclic. extensions AO* searching AND/OR graphs containcycles. One line research concerned find acyclic solutions AND/OR graphscontain cycles (Jimenez & Torras, 2000). Another generalization AO*, called LAO*, allowssolutions contain cycles loops order specify policies infinite-horizon MDPs (Hansen& Zilberstein, 2001).40fiHAO*At(Start)At(Loc1)C C CAt(Start)CCRRNavigate(Start, Loc1)At(Loc1)OPTC C CR R RNavigate(Loc1, Loc2)LostCOPTCRAt(Loc2)OPTR R RNavigate(Loc1, Loc2)OPTNavigate(Start, Loc1)At(Loc2)PanoramicCameraR(a) Dynamic programmingLostCRRRCPanoramicCamera(b) Reachability analysisFigure 3: Dynamic programming reachability analysis (Figure 2 continued). (a) Dynamic programming: optimal policy reevaluated Navigate(Loc1, Loc2) appearsoptimal continuous states At(Loc2). Node At(Loc1) represented finerpartition continuous state space illustrate fact backup increasednumber pieces value function associated expanded region. (b) Reachability analysis: newly created region At(Loc2) becomes reachable, wellregions Lost reached Navigate(Loc1, Loc2).Given assumption every action positive resource consumption,loops state space problem resources available decrease step.surprisingly, loops AND/OR graph. possible AND/ORgraph represents projection state space onto smaller space consistsdiscrete component state. example, possible rover returnsite visited before. rover actually state, since fewer resourcesavailable. AND/OR graph represents projection state space includecontinuous aspects state, resources, means rover visit stateprojects node AND/OR graph state visited earlier, shown Figure 4.result, loops AND/OR graph, even loops part AND/ORgraph corresponds solution. sense, phantom loopsappear projected state space, real state space.Nevertheless must modify dynamic programming (DP) algorithm deal loops.loops real state space, know exact value functionupdated finite number backups performed correct order, one backup performedstate visited along path start state expanded node(s).multiple states map AND/OR graph node, continuous regionstate space associated particular node may need evaluated once. identifyAND/OR graph nodes need evaluated once, use following two-stepalgorithm.41fiMeuleau, Benazera, Brafman, Hansen & MausamAt(Start)At(Location1)energy = 80At(Location1)energy = 50At(Location1)At(Start)energy = 100At(Location2)energy = 65At(Location2)energy = 35At(Location2)Figure 4: Phantom loops HAO*: solid boxes represent Markov states. Dashed boxes representsearch nodes, is, projection Markov states discrete components. Arrowsrepresent possible state transition. Bold arrows show instance phantom loopsearch space.First, consider part AND/OR graph consists ancestor nodesexpanded node(s). set Z nodes identified beginning DP step.decompose part graph strongly connected components. graph stronglyconnected components acyclic used prescribe order backups almostway standard AO* algorithm. particular, nodes particular componentbacked nodes descendant components backed up. Notecase acyclic graph, every strongly connected component single node. possibleconnected component one node loops AND/OR graph.loops AND/OR graph, primary change DP step algorithmoccurs time perform backups nodes connected component onenode. case, nodes connected component evaluated. Then, repeatedlyre-evaluated value functions nodes converge, is, changevalues nodes. loops real state space, convergenceguaranteed occur finite number steps. Typically, occurs small numbersteps. advantage decomposing AND/OR graph connected componentsidentifies loops localizes effect small number nodes. experiments testdomain, nodes graph need evaluated DP step,small number nodes (and often none) need evaluated once.Note decomposition nodes Z connected components method improvingefficiency dynamic programming step, required correctness. alternative repeatedly updating nodes Z values converge also correct, althoughlikely result many useless updates already converged nodes.Analysis reachability Change value function lead change optimal policy,and, thus, change states visited best policy. This, turn, affectopen regions state space eligible expanded. final step, HAO* identifiesbest (partial) policy recomputes Reachablen nodes states explicit graph,follows (see Figure 3(b)). node n best (partial) solution graph, considerparents n0 solution graph, actions lead one parents n.Reachablen (x) support Pn (x),X ZPn (x) =Reachablen0 (x0 ) Pr(n | n0 , x0 , a) Pr(x | n0 , x0 , a, n)dx0 ,(5)(n0 ,a)nX42fiHAO*is, Reachablen (x) = {x X : Pn (x) > 0}. Equation (5), n set pairs (n0 , a)best action n0 reachable resource level:n = {(n0 , a) N : x X, Pn0 (x) > 0, n0 (x) = a, Pr(n | n0 , x, a) > 0} .clear restrict attention state-action pairs n , only.performing reachability analysis, HAO* identifies frontier state spaceeligible expansion. HAO* terminates frontier empty, is, findhybrid states intersection Reachable Open.3.3 Convergence Error Boundsnext consider theoretical properties HAO*. First, reasonable assumptions,prove HAO* converges optimal policy finite number steps. discussuse HAO* find sub-optimal policies error bounds.proof convergence finite number steps depends, among things,assumption hybrid-state MDP finite branching factor. implementation,means region state space represented hyper-rectangle, setsuccessor regions action represented finite set hyper-rectangles.assumption assumption number actions finite, follows everyassignment n discrete variables, set{x|(n, x)is reachable initial state using fixed sequence actions}union finite number open closed hyper-rectangles. assumption viewedgeneralization assumption finite branching factor discrete AND/OR graph uponfinite convergence proof AO* depends.Theorem 1 heuristic functions Hn admissible (optimistic), actions positive resource consumptions, continuous backups action application computable exactly finitetime, branching factor finite, then:1. step HAO*, Vn (x) upper-bound optimal expected return (n, x),(n, x) expanded HAO*;2. HAO* terminates finite number steps;3. termination, Vn (x) equal optimal expected return (n, x), (n, x) reachableoptimal policy, i.e., Reachablen (x) > 0.Proof: (1) proof induction. Every state (n, x) assigned initial heuristic estimate,Vn (x) = Hn (x) Vn (x) admissibility heuristic evaluation function. makeinductive hypothesis point algorithm, Vn (x) Vn (x) every state (n, x).backup performed state (n, x),"ZXVn (x) =maxPr(n0 | n, x, a)Pr(x0 | n, x, a, n0 ) (Rn0 (x0 ) + Vn0 (x0 )) dx0aAn (x)x0n0 N"maxaAn (x)Xn0 N0ZPr(n | n, x, a)000Pr(x | n, x, a, n ) (Rn0 (x ) +x0= Vn (x) ,last equality restates Bellman optimality equation.43Vn0 (x0 )) dx0fiMeuleau, Benazera, Brafman, Hansen & Mausam(2) action positive, bounded below, resource consumption, resourcesfinite non-replenishable, complete implicit AND/OR graph must finite.reason, graph turned finite graph without loops: Along directed loopgraph, amount maximal available resources must decrease positivelower-bound amount resources consumed action. node graph mayexpanded number times bounded number ancestor. (Each time newancestor discovered, may lead update set reachable regions node.)Moreover, finite branching factor implies number regions considered within nodebounded (because finite ways reaching node, contributes finitenumber hyper-rectangles). Thus, overall, number regions considered finite,processing required region expansion finite (because action application backupscomputed finite time). leads desired conclusion.(3) search algorithm terminates policy start state (n0 , x0 ) complete,is, lead unexpanded states. every state (n, x) reachablefollowing policy, contradictory suppose Vn (x) > Vn (x) since implies completepolicy better optimal. Bellman optimality equation Equation (1), knowVn (x) Vn (x) every state complete policy. Therefore, Vn (x) = Vn (x).HAO* converges optimal solution, stopping algorithm early allows flexibletrade-off solution quality computation time. assume that, state,done action terminates execution zero reward (in rover problem, wouldstart safe sequence), evaluate current policy step algorithmassuming execution ends time reach leaf policy graph. assumption,error current policy step algorithm bounded. showusing decomposition value function described Chakrabarti et al.(1988) HansenZilberstein (2001). note point algorithm, value function decomposedtwo parts, gn (x) hn (x),gn (x)=gn (x)=0 (n, x) open state, fringe greedy policy; otherwise,ZX0Pr(n | n, x, )Pr(x0 | n, x, , n0 ) (Rn (x) + gn0 (x0 )) dx0 ,(6)x0n0 Nhn (x)= Hn (x) (n, x) open state, fringe greedy policy; otherwise,ZXhn (x) =Pr(n0 | n, x, )Pr(x0 | n, x, , n0 ) hn0 (x0 )dx0 ,(7)n0 Nx0action maximizes right-hand side Equation (4). Note Vn (x) =gn (x) + hn (x). use decomposition value function bound error best policyfound far, follows.Theorem 2 step HAO* algorithm, error current best policy boundedhn0 (x0 ).Proof: state (n, x) explicit search space, lower bound optimal value givengn (x), value achieved current policy done actionexecuted fringe states, upper bound given Vn (x) = gn (x) + hn (x), establishedTheorem 1. follows hn0 (x0 ) bounds difference optimal valuecurrent admissible value state (n, x), including initial state (n0 , x) ).Note error bound initial state hn0 (x0 ) = Hn0 (x0 ) start algorithm;decreases progress algorithm; hn0 (x0 ) = 0 HAO* converges optimalsolution.44fiHAO*3.4 Heuristic Functionheuristic function Hn focuses search reachable states likely useful.informative heuristic, scalable search algorithm. implementationHAO* rover planning problem, described detail next section, usedsimple admissible heuristic function assigns node sum rewards associatedgoals achieved far. Note heuristic function dependsdiscrete component state, continuous variables; is, function Hn (x)constant values x. obvious heuristic admissible, since representsmaximum additional reward could achieved continuing plan execution. Althoughobvious heuristic simple could useful, experimental results presentSection 4 show is. considered additional, informed heuristic function solvedrelaxed, suitably discretized, version planning problem. However, taking accounttime required compute heuristic estimate, simpler heuristic performed better.3.5 Expansion PolicyHAO* works correctly converges optimal solution matter continuous region(s)node(s) expanded iteration (step 2.a). quality solution mayimprove quickly using heuristics choose region(s) fringe expandnext.One simple strategy select node expand continuous regions nodeopen reachable. preliminary implementation, expanded (the open regions of)node likely reached using current policy. Changes valuestates greatest effect value earlier nodes. Implementing strategy requiresperforming additional work involved maintaining probability associated state.probabilities available, one could also focus expanding promising node,is, node integral Hn (x) times probability values x highest,described Mausam, Benazera, Brafman, Meuleau, Hansen (2005).Hansen Zilberstein (2001) observed that, case LAO*, algorithm efficientexpand several nodes fringe performing dynamic programming explicitgraph. cost performing update node largely dominates costexpanding node. expand one node fringe iteration, mightperform DP backups expand several nodes common ancestors proceedingDP. limit, might want expand nodes fringe algorithm iteration.Indeed, variant LAO* proved efficient (Hansen & Zilberstein, 2001).case LAO*, updates expensive loops implicit graph. HAO*,update region induces call hybrid dynamic programming module openregion node. Therefore, technique likely produce benefit.Pursuing idea, allowed algorithm expand nodes fringedescendants fixed depth iteration. defined parameter, called expansionhorizon denoted k, represent, loosely speaking, number times whole fringeexpanded iteration. k = 1, HAO* expands open reachable regionsnodes fringe recomputing optimal policy. k = 2, expands regionsfringe children updating policy. k = 3 also consider grandchildren regions fringe, on. k tends infinity, algorithm essentiallyperforms exhaustive search: first expands graph reachable nodes, performs onepass (hybrid) dynamic programming graph determine optimal policy. balancingnode expansion update, expansion horizon allows tuning algorithm behaviorexhaustive search traditional heuristic search. experiments showed value k5 10 optimal solve hardest benchmark problems (see section 4).45fiMeuleau, Benazera, Brafman, Hansen & MausamStartObsPt3UnsafeC4ObsPt4FeaturelessC6W2W3W1ObsPt5ObsPt2AudienceDemolabel: WaypointName: Rock: IP + CHAMPObsPt1Far: Science Cam.Figure 5: K9 rover (top left) developed Jet Propulsion Laboratory NASA AmesResearch Center prototype MER rovers. used test advanced roversoftware, including automated planners rovers activities. Right: topological map2004 demo problem. Arrows labeled IP + CHAMP represent opportunitydeploy arm rock (instrument placement) take pictureCHAMP Camera. Arrows labeled Science Cam represent opportunity takeremote picture rock Science Camera.3.6 Updating Multiple Regionsexpansion policies described based expanding open regions one severalnodes simultaneously. allow leveraging hybrid-state dynamic programming techniquesFeng et al. (2004) Li Littman (2005). techniques may compute singleiteration piecewise constant linear value functions cover large range continuous states,possibly whole space possible values. particular, back one iterationcontinuous states included given bounds.Therefore, several open regions node expanded iterationHAO*, update simultaneously backing-up subset continuous statesincludes regions. instance, one may record lower bounds upper boundscontinuous variable expanded regions, compute value function covershyper-rectangle bounds.modification algorithm impact convergence. long valueexpanded regions computed, convergence proof holds. However, execution time may adversely affected expanded regions proper subset region continuous states46fiHAO*(a) Value function Vn (.) initial node.first plateau corresponds analyzing R1, second plateau analyzing R2, third plateauanalyzing R1 R2.(b) policy n (.) startingnode shows partitions resource space different actionsoptimal. Dark: action; Grey:navigation R2; Light: analysisR1.Figure 6: (a) Optimal value function initial state simple rover problem possiblevalues continuous resources (time energy remaining). value functionpartitioned 3476 pieces. (b) Optimal policy set states.backed-up. case, values states open reachable uselessly computed,deviates pure heuristic search algorithm.However, modification may also beneficial avoids redundant computation.Hybrid-state dynamic programming techniques manipulate pieces value functions. Thus, severalexpanded regions included piece value function, value computedonce. practice, benefit may outweigh cost evaluating useless regions. Moreover, costreduced storing value functions associated node graph,computed values irrelevant regions saved case regions become eligible expansion(i.e., open reachable) later. Thus, variant HAO* fully exploits hybrid-state dynamicprogramming techniques.4. Experimental Evaluationsection, describe performance HAO* solving planning problems simulatedplanetary exploration rover two monotonic continuous-valued resources: time batterypower. Section 4.1 uses simple toy example problem illustrate basic stepsHAO* algorithm. Section 4.2 tests performance algorithm using realistic, real-sizeNASA simulation rover analyzes results experiments. simulation usesmodel K9 rover (see Figure 5) developed Intelligent Systems (IS) demo NASAAmes Research Center October 2004 (Pedersen et al., 2005). complex real-size modelK9 rover uses command names understandable rovers execution language,plans produced algorithm directly executed rover. experimentsreported Section 4.2, simplify NASA simulation model way.47fiMeuleau, Benazera, Brafman, Hansen & MausamFigure 7: First iteration HAO* toy problem. explicit graph marked dim edgessolution graph marked thick edges. Tip nodes 4, 5, 6 7 shownconstant heuristic functions expanded nodes 1, 2 3 shown backedvalue functions.planning problem consider, autonomous rover must navigate planar graphrepresenting surroundings authorized navigation paths, schedule observationsperformed different rocks situated different locations. subset observationalgoals achieved single run due limited resources. Therefore, oversubscribedplanning problem. also problem planning uncertainty since action uncertainpositive resource consumptions probability failing.significant amount uncertainty domain comes tracking mechanism usedrover. Tracking process rover recognizes rock based certain featurescamera image associated rock. mission operations, problem instancecontaining fixed set locations, paths, rocks built last panoramic camera imagesent rover. logical rock problem instance corresponds real rock,rover must associate two basis features detected instruments,including camera. rover moves camera image changes, rover must keep trackfeatures image evolve. process uncertain subject faults resultlosing track rock. practice, tracking modeled following way:order perform measurement rock, rover must tracking rock.navigate along path, must tracking one rocks enables following path.set rocks enable path part problem definition given planner.decision start tracking rock must made rover begins move.rover starts moving, may keep track rock already tracked voluntarily stoptracking it, cannot acquire new rock tracked initially.48fiHAO*Figure 8: Second iteration HAO* toy problem.rover may randomly lose track rocks navigating along path. probability losing track rock depends rock path followed, partproblem definition given planner.way reacquire rock whose track lost, intentionally accident.number rocks tracked strongly influences duration resource consumptionnavigate actions. higher number rocks tracked, costly navigatealong path. rover stop regularly check record aspectrock tracked. creates incentive limit number rocks trackedrover given set goals chosen path intends follow.So, rover initially selects set rocks track tries keep set small possiblegiven goals. starts moving, may lose track rocks, may causereconsider set goals pursue route get corresponding rocks.also purposely stop tracking rock longer necessary given goals leftachieve.implementation HAO* uses dynamic programming algorithm developed Feng etal. (2004) summarized Section 2.4 order perform backups hybrid state space,partitions continuous state-space associated node piecewise-constant regions. usesmultiple-region updates described Section 3.6: upper bound resourceexpanded regions computed, states included bounds minimalpossible resource levels updated.experiments, use variant HAO* algorithm described Section 3.5,parameter k sets number times whole fringe expanded iteration HAO*;allows behavior algorithm tuned exhaustive search heuristic search.used expansion horizon k = 2 simple example Section 4.1 default expansionhorizon k = 7 larger examples Section 4.2. Section 4.2.3 describes experimentsdifferent expansion horizons.49fiMeuleau, Benazera, Brafman, Hansen & MausamFigure 9: Third iteration HAO* toy problem.implementation HAO* uses simple heuristic described Section 3.4, augmentedsmall amount domain knowledge. value Hn (x) state (n, x) essentially equalsum utilities goals yet achieved n. However, rover already movedcertain rock tracked state n, goals requiring rock trackedincluded sum. reflects fact that, rover moved, cannot start trackingrock more, thus goals require rock tracked unreachable. resultingheuristic admissible (i.e., never underestimates value state), straightforwardcompute. Note depend current resource levels, functions Hn (x)constant values x.4.1 Examplebegin simple example rover planning problem order illustrate stepsalgorithm. solve example using implementation HAO* usesolve realistic examples considered Section 4.2.example, targets two rocks, R1 R2, positioned locations L1 L2,respectively. rovers initial location L1, direct path L1 L2.Analyzing rock R1 yields reward 10 analyzing rock R2 yields reward 20. roversaction set simplified. Notably, features single action Pic(Rx) represents stepsanalyzing rock Rx, stop tracking actions removed.Figure 6 shows optimal value function optimal policy found HAO* startingdiscrete state, resources ranging whole space possible values. Figures 7, 8 9show step-by-step process HAO* solves problem. Using expansion horizonk = 2, HAO* solves problem three iterations, follows:Iteration 1: shown Figure 7, HAO* expands nodes 1, 2 3 computes heuristicfunction new tip nodes 4, 5, 6 7. backup step yields value function estimatesnodes 1, 2 3. HAO* identifies best solution graph new fringe node 6.50fiHAO*(a) 1012 pieces.(b) 3465pieces.(c) 6122pieces.Figure 10: Optimal value functions initial state simple rover problem increasing initial resource levels (from left right). optimal return appears threedimensional function carved reachable space heuristic function.problemnameRover1Rover2Rover3Rover4roverlocations77911pathsgoalsfluentsactions1011162035663041495143567381discretestates(approx.)1.1 1092.2 10125.6 10142.3 1015reachablediscretestates61352552039322866explicitgraphoptimalpolicylongestbranch2341068243043215048434435354343Table 3: Size benchmark rover problems.Iteration 2: shown Figure 8, HAO* expands nodes 6, 8, 9 10, startingprevious fringe node 6, computes heuristic functions new tip nodes 11, 12 13.heuristic value node 12 zero because, state, rover lost track R2already analyzed R1. backup step improves accuracy value functionseveral nodes. Node 11 new fringe node since 12 terminal node.Iteration 3: shown Figure 9, HAO* expands node 11 node 14. search endsiteration open node optimal solution graph.comparison, Figure 10 shows value function found HAO* varies different initialresource levels. figures, unreachable states assigned large constant heuristic value,value function reachable states appears carved plateau heuristic.4.2 PerformanceNow, describe HAO*s performance solving four much larger rover planning problems usingNASA simulation model. characteristics problems displayed Tables 3. Columnstwo six show size problems terms rover locations, paths, goals. also showtotal number fluents (Boolean state variables) actions problem. Columns seventen report size discrete state space. total number discrete states two raisedpower number fluents. Although huge state space, limited numberstates reached start state, depending initial resource levels. eighthcolumn Table 3 shows number reachable discrete states initial time energy levelsset maximum value. (The maximum initial resource levels based scenario2004 demo represent several hours rover activity.) shows simple reachability51fiMeuleau, Benazera, Brafman, Hansen & Mausam7005004003002001000reachablecreatedexpandedoptimal policy600Number discrete states600Number discrete states700reachablecreatedexpandedoptimal policy5004003002001000100000200000300000Initial energy40000005000000200040006000Initial time800010000800010000800010000800010000(a) Rover16000reachablecreatedexpandedoptimal policy5000Number discrete statesNumber discrete states6000400030002000100000100000200000300000Initial energy40000040003000200010000500000reachablecreatedexpandedoptimal policy50000200040006000Initial time(b) Rover225000reachablecreatedexpandedoptimal policy20000Number discrete statesNumber discrete states250001500010000500000100000200000 300000Initial energy40000020000150001000050000500000reachablecreatedexpandedoptimal policy0200040006000Initial time(c) Rover325000reachablecreatedexpandedoptimal policy20000Number discrete statesNumber discrete states250001500010000500000100000200000 300000Initial energy40000020000150001000050000500000reachablecreatedexpandedoptimal policy0200040006000Initial time(d) Rover4Figure 11: Number nodes created expanded HAO* vs. number reachable discrete states.graphs left column obtained fixing initial time maximum valuevarying initial energy. graphs right column obtained fixinginitial energy maximum value varying initial time. Results obtainedk = 7.52fiHAO*analysis based resource availability makes huge difference. partly due factplanning domain, close K9 execution language, allow many fluentstrue simultaneously. Columns nine ten show number discrete states explicitgraph optimal policy. precisely, former number nodes created HAO*,is, subset reachable discrete states. number reachable discrete states, thussize graph explore, may seem small compared discrete combinatorial problemssolved AI techniques. iteration, continuous approximation two-dimensionalbackup necessary evaluate hybrid state space associated graph. Finally, lastcolumn Table 3 shows length longest branch optimal policy initialresource levels set maximum value.largest four instances (that is, Rover4) exactly problem October 2004demo. considered large rover problem. example, much largerproblems faced MER rovers never visit one rock single planning cycle.4.2.1 Efficiency Pruningfirst set simulations, try evaluate efficiency heuristic pruning HAO*, is,portion discrete search space spared exploration use admissibleheuristics. purpose, compare number discrete states reachable givenresource level number nodes created expanded HAO*. also considernumber nodes optimal policy found algorithm.Results four benchmark problems presented Figure 11. curves obtainedfixing one resource maximum possible value varying 0 maximum.Therefore, represent problems mostly one resource constraining. result show,notably, single resource enough constrain reachability state space significantly.surprisingly, problems become larger initial resources increase, discretestates become reachable. Despite simplicity heuristic used, HAO* able by-passsignificant part search space. Moreover, bigger problem, leveragealgorithm take simple heuristic.results quite encouraging, number nodes created expandedalways reflect search time. Therefore, examine time takes HAO* produce solutions.4.2.2 Search TimeFigure 12 shows HAO* search time set experiments. curves exhibitmonotonicity and, instead, appear show significant amount noise. surprisingsearch time always increase increase initial levels resource, althoughsearch space bigger. shows search complexity depend size searchspace alone. factors must explain complexity peaks observed Figure 12.number nodes created expanded algorithm contain noise,reason peaks computation time must time spent dynamic programmingbackups. Moreover, search time appears closely related complexity optimal policy.Figure 13 shows number nodes branches policy found algorithm, wellnumber goals pursued policy. shows that: (i) cases, increasing initialresource level eliminates need branching reduces size optimal solution; (ii)size optimal policy and, secondarily, number branches, explains peakssearch time curves. Therefore, question is: large solution graph induce long timespent backups? two possible answers question: backups take longerand/or backups performed. first explanation pretty intuitive.policy graph contains many branches leading different combinations goals, value functionscontain many humps plateaus, therefore many pieces, impacts complexitydynamic programming backups. However, time empirical evidence53fi1818161614141212Search time (s)Search time (s)Meuleau, Benazera, Brafman, Hansen & Mausam10861086442200100000200000300000Initial energy40000005000000200040006000Initial time80001000040006000Initial time800010000180160160140140120120Search time (s)Search time (s)(a) Rover1180100806010080604040202000100000200000300000Initial energy400000050000002000250002000020000Search time (s)Search time (s)(b) Rover225000150001000050000150001000050000100000200000 300000Initial energy40000005000000200040006000Initial time8000100000200040006000Initial time80001000020000200001500015000Search time (s)Search time (s)(c) Rover310000500001000050000100000200000 300000Initial energy4000000500000(d) Rover4Figure 12: HAO* search time. graphs left column obtained fixing initial timemaximum value, graphs right column obtained fixinginitial energy maximum. Results obtained k = 7.54fiHAO*confirm hypothesis. Conversely, observe peak Figure 12 comes increasenumber backups. work required explain this.4.2.3 Expansion Horizonresults Section 4.2.1 show HAO* leverage even simple admissible heuristic prunelarge portion search space. necessarily follow HAO* outperformexhaustive search algorithm creates graph reachable states, executes one passdynamic programming graph find optimal policy. Although HAO* expands smallergraph exhaustive search, must evaluate graph often. Section 3.5,introduced parameter k expansion horizon order allow adjustment trade-offtime spent expanding nodes time spent evaluating nodes. study influenceparameter algorithm.Figure 14 shows number nodes created expanded HAO* functionexpansion horizon four benchmark problem instances. surprisingly, algorithm createsexpands nodes expansion horizon increases. Essentially, behaves likeexhaustive search k increased. two smallest problem instances, large enoughvalues k, number visited states levels total number reachable statesreached. two largest problem instances, interrupt experiments k reached25 search time became long.Figure 15 shows effect expansion horizon search time HAO*. smallestproblem instance (Rover1), HAO* clear advantage exhaustive search (withk > 20), even though explores fewer nodes. three larger problem instances, HAO*clear advantage. Rover2 problem instance, search time HAO* levelsk = 25, indicating limit reachable states reached. However, durationexhaustive search several times longer HAO* smaller settings k. benefitsHAO* clearer two largest problem instances. k increased, algorithmquickly overwhelmed combinatorial explosion size search space, simulationseventually need interrupted search time becomes long. probleminstances smaller settings k, HAO* able efficiently find optimal solutions.Overall, results show clear benefit using admissible heuristics prunesearch space, although expansion horizon must adjusted appropriately order HAO*achieve favorable trade-off node-expansion time node-evaluation time.5. Conclusionintroduced heuristic search approach finding optimal conditional plans domains characterized continuous state variables represent limited, consumable resources. HAO*algorithm variant AO* algorithm that, best knowledge, first algorithm deal following: limited continuous resources, uncertain action outcomes,over-subscription planning. tested HAO* realistic NASA simulation planetary rover,complex domain practical importance, results demonstrate effectiveness solvingproblems large solved straightforward application dynamic programming. effective heuristic search exploit resource constraints, well admissibleheuristic, order limit reachable state space.implementation, HAO* algorithm integrated dynamic programming algorithm Feng et al. (2004). However HAO* integrated dynamic programmingalgorithms solving hybrid-state MDPs. Feng et al. algorithm finds optimal policieslimiting assumptions transition probabilities discrete, rewards either piecewiseconstant piecewise-linear. recently-developed dynamic programming algorithms hybridstate MDPs make less restrictive assumptions, also potential improve computational55fiMeuleau, Benazera, Brafman, Hansen & Mausam30320210100100000200000 300000Initial energy4000004005000005NodesBranchesGoals430320210100200040006000Initial time8000Number branches goals450Number nodes40Number nodes5NodesBranchesGoalsNumber branches goals50010000(a) Rover145330215100100000200000 300000Initial energy4000006005000005NodesBranchesGoals445330215100200040006000Initial time8000Number branches goals475Number nodesNodesBranchesGoals60Number nodes5Number branches goals75010000(b) Rover245330215100100000200000 300000Initial energy4000006005000005NodesBranchesGoals445330215100200040006000Initial time8000Number branches goals475Number nodesNodesBranchesGoals60Number nodes5Number branches goals75010000(c) Rover360340220100100000200000 300000Initial energy4000008005000005NodesBranchesGoals460340220100200040006000Initial time8000Number branches goals4100Number nodesNodesBranchesGoals80Number nodes5Number branches goals100010000(d) Rover4Figure 13: Complexity optimal policy: number nodes, branches, goals optimalpolicy setting Figure 11.56fiHAO*700Number discrete states600Number discrete states6000createdexpanded500400300200100005101520Expansion horizon4000300020001000025createdexpanded50000510(a) Rover114000Number discrete statesNumber discrete states30createdexpanded14000100008000600040002000025(b) Rover216000createdexpanded120001520Expansion horizon12000100008000600040002000051015Expansion horizon020(c) Rover3051015Expansion horizon20(d) Rover4Figure 14: Influence expansion horizon number nodes visited algorithm.efficiency (Li & Littman, 2005; Marecki et al., 2007). Integrating HAO* one algorithmscould improve performance further.several interesting directions work could extended. developing HAO*, made assumptions every action consumes resource resourcesnon-replenishable. Without assumptions, state could revisited optimalplan could loops well branches. Generalizing approach allow plans loops,seems necessary handle replenishable resources, requires generalizing heuristic searchalgorithm LAO* solve hybrid MDPs (Hansen & Zilberstein, 2001). Another possible extensionallow continuous action variables addition continuous state variables. Finally, heuristicsearch approach could combined approaches improving scalability, hierarchical decomposition (Meuleau & Brafman, 2007). would allow handle even larger statespaces result number goals over-subscription planning problem increased.Acknowledgmentswork funded NASA Intelligent Systems program, grant NRA2-38169. Eric Hansensupported part NASA Summer Faculty Fellowship funding MississippiSpace Grant Consortium. work performed Emmanuel Benazera workingNASA Ames Research Center Ronen Brafman visiting NASA Ames Research Center,consultants Research Institute Advanced Computer Science. Ronen Brafmansupported part Lynn William Frankel Center Computer Science, Paul IvanierCenter Robotics Production Management, ISF grant #110707. Nicolas Meuleauconsultant Carnegie Mellon University NASA Ames Research Center.57fiMeuleau, Benazera, Brafman, Hansen & Mausam6018001600140040Search time (s)Search time (s)5030201000800600400100120020005101520Expansion horizon0250510(a) Rover1303000025000Search time (s)20000Search time (s)25(b) Rover2250001500010000500001520Expansion horizon2000015000100005000051015Expansion horizon020(c) Rover3051015Expansion horizon20(d) Rover4Figure 15: Influence expansion horizon overall search time.ReferencesAltman, E. (1999). Constrained Markov Decision Processes. Chapman HALL/CRC.Bertsekas, D., & Tsitsiklis, J. (1996). Neural Dynamic Programming. Athena Scientific, Belmont,MA.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptionscomputational leverage. Journal Artificial Intelligence Research, 11, 194.Boyan, J., & Littman, M. (2000). Exact solutions time-dependent MDPs. Advances NeuralInformation Processing Systems 13, pp. 17. MIT Press, Cambridge.Bresina, J., Dearden, R., Meuleau, N., Ramakrishnan, S., Smith, D., & Washington, R. (2002).Planning continuous time resource uncertainty: challenge AI. ProceedingsEighteenth Conference Uncertainty Artificial Intelligence, pp. 7784.Bresina, J., Jonsson, A., Morris, P., & Rajan, K. (2005). Activity planning mars explorationrovers. Proceedings Fifteenth International Conference Automated PlanningScheduling, pp. 4049.Chakrabarti, P., Ghose, S., & DeSarkar, S. (1988). Admissibility AO* heuristics overestimate. Aritificial Intelligence, 34, 97113.Feng, Z., Dearden, R., Meuleau, N., & Washington, R. (2004). Dynamic programming structured continuous Markov decision problems. Proceedings Twentieth ConferenceUncertainty Artificial Intelligence, pp. 154161.58fiHAO*Friedman, J., Bentley, J., & Finkel, R. (1977). algorithm finding best matches logarithmicexpected time. ACM Trans. Mathematical Software, 3(3), 209226.Hansen, E., & Zilberstein, S. (2001). LAO*: heuristic search algorithm finds solutionsloops. Artificial Intelligence, 129, 3562.Jimenez, P., & Torras, C. (2000). efficient algorithm searching implicit AND/OR graphscycles. Artificial Intelligence, 124, 130.Kveton, B., Hauskrecht, M., & Guestrin, C. (2006). Solving factored MDPs hybrid stateaction variables. Journal Artificial Intelligence Research, 27, 153201.Li, L., & Littman, M. (2005). Lazy approximation solving continuous finite-horizon MDPs.Proceedings Twentieth National Conference Artificial Intelligence, pp. 11751180.Marecki, J., Koenig, S., & Tambe, M. (2007). fast analytical algorithm solving markov decisionprocesses real-valued resources. Proceedings 20th International Joint ConferenceArtificial Intelligence (IJCAI-07, pp. 25362541.Mausam, Benazera, E., Brafman, R., Meuleau, N., & Hansen, E. (2005). Planning continuous resources stochastic domains. Proceedings Nineteenth International JointConference Artificial Intelligence, pp. 12441251. Professional Book Center, Denver, CO.Meuleau, N., & Brafman, R. (2007). Hierarchical heuristic forward search stochastic domains.Proceedings 20th International Joint Conference Artificial Intelligence (IJCAI-07),pp. 25422549.Munos, R., & Moore, A. (2002). Variable resolution discretization optimal control. MachineLearning, 49 (2-3), 291323.Nilsson, N. (1980). Principles Artificial Intelligence. Tioga Publishing Company, Palo Alto, CA.Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving. AddisonWesley.Pedersen, L., Smith, D., Deans, M., Sargent, R., Kunz, C., Lees, D., & Rajagopalan, S. (2005).Mission planning target tracking autonomous instrument placement. Proceedings2005 IEEE Aerospace Conference., Big Sky, Montana.Puterman, M. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming.Wiley, New York, NY.Rust, J. (1997). Using randomization break curse dimensionality. Econimetrica, 65, 487516.Smith, D. (2004). Choosing objectives over-subscription planning. Proceedings FourteenthInternational Conference Automated Planning Scheduling, pp. 393401.Thiebaux, S., Gretton, C., Slaney, J., Price, D., & Kabanza, F. (2006). Decision-theoretic planningnon-Markovian rewards. Journal Artificial Intelligence Research, 25, 1774.van den Briel, M., Sanchez, R., Do, M., & Kambhampati, S. (2004). Effective approaches partialsatisfation (over-subscription) planning. Proceedings Nineteenth National ConferenceArtificial Intelligence, pp. 562569.59fi