Journal Artificial Intelligence Research 44 (2012) 587-632

Submitted 03/12; published 07/12

SAP Speaks PDDL: Exploiting Software-Engineering
Model Planning Business Process Management
Jorg Hoffmann

hoffmann@cs.uni-saarland.de

Saarland University, Saarbrucken, Germany

Ingo Weber

ingo.weber@nicta.com.au

NICTA, Sydney, Australia

Frank Michael Kraft

frank.michael.kraft@bpmnforum.net

bpmnforum.net, Germany

Abstract
Planning concerned automated solution action sequencing problems described declarative languages giving action preconditions effects. One important
application area technology creation new processes Business Process
Management (BPM), essential ever dynamic business environment.
major obstacle application Planning area lies modeling. Obtaining suitable model plan ideally description PDDL, commonly
used planning language often prohibitively complicated and/or costly. core observation work problem ameliorated leveraging synergies
model-based software development. application SAP, one leading vendors
enterprise software, demonstrates even one-to-one model re-use possible.
model question called Status Action Management (SAM). describes
behavior Business Objects (BO), i.e., large-scale data structures, level abstraction corresponding language business experts. SAM covers 400
kinds BOs, described terms set status variables
values required for, affected by, processing steps (actions) atomic
business perspective. SAM developed SAP part major model-based software
engineering effort. show herein one use model planning, thus
obtaining BPM planning application incurs modeling overhead all.
compile SAM variant PDDL, adapt off-the-shelf planner solve
kind problem. Thanks resulting technology, business experts may create
new processes simply specifying desired behavior terms status variable value
changes: effectively, describing process language.

1. Introduction
Business processes workflows controlling flow activities within enterprises (Aalst, 1997). Business process management (BPM) concerned, amongst
things, maintenance processes. minimize time-to-market ever
dynamic business environment, essential able quickly create new processes. involves selecting arranging suitable transactions huge inc
2012
AI Access Foundation. rights reserved.

fiHoffmann, Weber & Kraft

frastructures. difficult costly task. application supports task
within software framework SAP1 , one leading vendors enterprise software.
well-known idea context, discussed example Jonathan, Moore, Stader,
Macintosh, Chung (1999), Biundo, Aylett, Beetz, Borrajo, Cesta, Grant, McCluskey,
Milani, Verfaillie (2003), Rodriguez-Moreno, Borrajo, Cesta, Oddi (2007),
use technology field planning. long-standing sub-area AI,
allows user describe problem solved declarative language.
nutshell, planning problems come form initial state, goal, set
actions, formulated relative set (typically Boolean least finite-domain) state
variables. solution (or plan) schedule actions transforming initial state
state satisfies goal. planning technology solves (in principle) problem
described language. far wide-spread planning language planning
domain definition language (PDDL) (McDermott, Ghallab, Howe, Knoblock, Ram, Veloso,
Weld, & Wilkins, 1998).2
idea BPM context annotate transaction planning-like
description formalizing action. enables planning systems compose (parts
approximations of) desired processes fully automatically, i.e., based minimal user
input specifying process start (initial state), achieve
(goal). closely related ideas explored name semantic web service
composition context Semantic Web community (e.g., Narayanan & McIlraith,
2002; Agarwal, Chafle, Dasgupta, Karnik, Kumar, Mittal, & Srivastava, 2005; Sirin, Parsia,
& Hendler, 2006; Meyer & Weske, 2006).
Runtime performance important application. Typically, user business expert wishing create new process waiting online planning outcome.
However mission-critical question, discussed example Kambhampati (2007)
Rodriguez-Moreno et al. (2007), is: get planning model? useful,
model needs capture relevant properties huge infrastructure, level
abstraction high-level enough usable business experts,
time precise enough relevant level. Designing model costly one
need good arguments indeed persuade manager embark endeavor.
present work, demonstrate problem ameliorated leveraging
synergies model-based software development, thus reducing additional modeling
overhead caused planning. fact, show one least particular
application re-use exactly, one-to-one, models built purpose software
engineering, thus reduce modeling overhead zero.
previously noted, example Turner McCluskey (1994) Kitchin,
McCluskey, West (2005), planning languages commonalities software
specification languages B (Schneider, 2001) OCL (Object Management Group,
2006). Now, typically specification languages mathematically oriented describe
1. http://www.sap.com
2. many variants planning, PDDL. share concepts similar short description
stated. However, description corresponds best classical planning, (amongst
things) uncertainty action effects. discuss details Section 2.1.
Throughout paper, unless refer one particular planning formalisms defined here,
use term planning general sense targeting particular variant.

588

fiSAP Speaks PDDL

low-level properties programs. stands contrast abstract models
needed work business experts. always so.
part major effort developing flexible service-oriented (Krafzig, Banke, & Slama,
2005; Bell, 2008) infrastructure, called SAP Business ByDesign, SAP developed
model called Status Action Management (SAM). SAM describes status variables
Business Objects (BO) change values actions transactions affecting
BOs executed. BOs full detail vastly complex, containing 1000s data
fields numerous technical-level transactions. SAM captures abstract business
perspective, terms smaller number user-level actions (like submit reject),
whose behavior described using preconditions effects high-level status properties
(like submitted rejected). way, SAM corresponds language business users, close correspondence common planning languages. SAM
extensive, covering 404 kinds BOs 2418 transactions. model creation
constitutes work effort spanning several years, involving, amongst things, dedicated
modeling environments educational training modelers.
SAM originally designed purpose model-driven software development,
facilitate design Business ByDesign infrastructure, changes thereunto
initial development afterwards. Business ByDesign covers needs
great breadth different SAP customer businesses, flexibly configurable
customers. configuration involves, amongst things, design customerspecific processes, appropriately combining functionalities provided. Describing
properties individual processing steps, rather supplying BO standard lifecycle workflow, SAM well-suited support flexibility. However, business users
designing processes typically familiar details infrastructure. Using
SAM planning, obtain technology alleviates problem. output,
technology delivers first version desired process, relevant transactions
suitable control-flow. input, technology requires business users
specify desired status changes language.
intended meaning SAM is, large extent, common planning
frameworks. subtleties treatment non-deterministic actions. One
problem many non-deterministic actions modeled SAM bad outcomes
preclude successful processing respective business object (example: BO data
inconsistent). problem aggravated fact that, SAMs non-determinism,
repeated executions action independent (example: check BO consistency). discuss detail, derive suitable planning formalism. compile
SAM PDDL, thus creating side-effect work new planning benchmark.
anonymized PDDL version SAM publicly available.
algorithmic side, show minimal changes off-the-shelf planner suffice
obtain good empirical performance. adapt well-known deterministic planning
system FF (Hoffmann & Nebel, 2001) perform suitable variant AO* (Nilsson, 1969,
1971). run heuristic function non-deterministic actions simply acting
could choose outcome, i.e., applying all-outcomes determinization (Yoon,
Fern, & Givan, 2007). run large-scale experiments modified FF, full
SAM model used SAP. show runtime performance satisfactory vast
majority cases; point remaining challenges.
589

fiHoffmann, Weber & Kraft

also integrated planning technology two BPM process modeling environments, making planning functionality conveniently accessible non-IT users.
Processes (and plans) environments displayed human-readable format.
Users specify status variable values, example planning goal, simple intuitive
drop-down menus. One environments integrated research extension
commercial SAP NetWeaver platform. said that, technology yet part
actual SAP product; discuss Section 7.
treatment non-deterministic actions, formalism algorithms, specific
application context. notwithstanding, plausible techniques
could useful also applications dealing actions. general
perspective, contribution work (A) pointing possible leverage
software-engineering models planning, (B) demonstrating application
realized one major players BPM industry, thus providing largescale case study. principle underlying SAM modeling software artifacts level
abstraction corresponding business users limited SAP. Thus work may
inspire similar approaches related contexts.
next give brief background planning BPM. discuss SAM model
Section 3, explaining structure, context SAP, added value using
planning. design planning formalization Section 4, explain planning
algorithms Section 5, evaluate experimentally Section 6. Section 7 describes
prototypes SAP. Section 8 discusses related work, Section 9 concludes.

2. Background
introduce basic concepts relevant work. start planning, overview
business process management (BPM) connection planning.
2.1 Planning
many variants planning (for overview, see Traverso, Ghallab, & Nau, 2005).
handle SAM, build wide-spread classical planning framework, planning
finite-domain variables (e.g., Backstrom & Nebel, 1995; Helmert, 2006, 2009). extend framework particular kind non-deterministic actions, whose semantics
relates notions planning uncertainty outline below.
Definition 1 (Planning Task) finite-domain planning task tuple (X, A, I, G). X
set variables; x X associated finite domain dom(x). set
actions, takes form (pre , eff ) pre (the precondition) eff
(the effect) partial variable assignment. variable assignment representing
initial state, G partial variable assignment representing goal.
fact statement x = c x X c dom(x). identify partial variable
assignments conjunctions (sets, sometimes) facts obvious way. state
complete variable assignment. action applicable iff |= pre . f partial
variable assignment, f variable assignment coincides f
variable f defined, coincides variables f undefined.

590

fiSAP Speaks PDDL

Definition 2 (Plan) Let (X, A, I, G) finite-domain planning task. Let state,
let sequence actions A. say solution iff either:
(i) empty |= G;
(ii) = hai 0 , |= pre , 0 solution eff .
solution I, called plan.
One can, course, define plans finite-domain planning tasks simpler way;
present formulation makes easier extend definition later on. remark that,
despite simplicity formalism, PSPACE-complete decide whether
plan exists (this follows directly results Bylander, 1994).
Unlike classical planning, exist disjunctive effects SAM, i.e., actions
one possible outcome. type situation dealt planning
uncertainty. model SAMs disjunctive effects appropriately, need mixture
known non-deterministic actions (e.g., Smith & Weld, 1999) known
observation actions (e.g., Weld, Anderson, & Smith, 1998).
Non-deterministic actions like usual actions except that, place single effect
eff , set Ea effects, referred possible outcomes. Whenever
apply plan execution time, one outcomes Ea occur; separate
applications independent. example, might throw dice. plan generation
time, know outcome occur, must cater cases.
straightforward framework conformant planning (e.g., Smith & Weld, 1999),
plan still sequence actions, required achieve goal matter
outcomes occur execution. Note exploit observability, i.e.,
plan make case distinctions based outcomes actually occur.
handle SAM, include case distinctions, along lines known
contingent planning (e.g., Weld et al., 1998). framework, case distinctions made
explicit observation actions plan. Typically, observation action observes
previously unknown value particular state variable x plan execution time (for
example, value dice throwing it). plan branches possible values
x, i.e., one successor value dom(x). Thus plan tree actions,
requirement goal fulfilled every leaf tree.
wide-spread input language planning systems today Planning Domain Definition Language (PDDL), used international planning competitions
(IPC) (McDermott et al., 1998; Bacchus, 2000; Fox & Long, 2003; Hoffmann & Edelkamp,
2005; Younes, Littman, Weissman, & Asmuth, 2005; Gerevini, Haslum, Long, Saetti, &
Dimopoulos, 2009). get details language, since purposes
PDDL merely particular syntax implementing formalisms. important
us, regarding usability PDDL encoding SAM, fact PDDL
lot variants, varying degrees support existing planning systems. PDDL
syntax SAM PDDL variant used non-deterministic tracks IPC,
i.e., tracks dealing non-probabilistic planning uncertainty (Bonet & Givan,
2006; Bryce & Buffet, 2008). Specifically, use basic PDDL constructs (often referred STRIPS), except action preconditions use quantifier-free
formulas (Pednault, 1989; Bacchus, 2000). PDDL subset supported existing
591

fiHoffmann, Weber & Kraft

planners, particular based FF (Hoffmann & Nebel, 2001) Fast Downward
(Helmert, 2006). limiting factor planner support non-deterministic actions,
use common syntax, namely (oneof eff 1 . . . eff n ) construct
non-deterministic IPC. Non-deterministic actions supported planners.
Further, semantics give plans using actions, fits application based
SAM, non-standard supported existing planners. notwithstanding,
several existing approaches closely related (cf. Section 8), and, show herein,
least one planner Contingent-FF (Hoffmann & Brafman, 2005) adapted quite
easily successfully deal new semantics.
2.2 Business Process Management
According commonly used definition (e.g., Weske, 2007), business process consists
set activities performed coordination organizational technical
environment. activities jointly realize business goal. words, business
processes enterprises business. Business process models serve abstraction
way enterprises business. example, business process model may specify
steps taken, various entities across enterprise, send customer quote
answering request quotation. atomic steps process model may both,
manual steps performed employees, automatic steps executed infrastructure.
refer process models simply processes.
explicit model processes allows sorts support automation, addressed
area business process management (BPM). Herein, mostly concerned
process creation adaptation. done BPM modeling environments. Importantly,
users environments typically experts, business experts
people familiar with, taking decisions for, business. dominant paradigm
representing business processes workflows, also called control-flows, often formalized
Petri nets (e.g., Aalst, 1997). control-flow defines order execution
process steps, within certain degrees flexibility implied, example, parallelism.
business experts, control-flow displayed human-readable format, typically
flow diagram. application SAP uses Business Process Modeling Notation (Object
Management Group, 2008), short BPMN, illustrate Section 7.
alternative paradigm representing business processes, relates SAM
model consider herein, constraint-based representations (e.g., Wainer & de Lima
Bezerra, 2003; van der Aalst & Pesic, 2006; Pesic, Schonenberg, Sidorova, & van der Aalst,
2007). model processes implicitly desired properties, rather explicitly concrete workflows. kind representation flexible, that,
modifying model, modify entire process space. example, might
add new constraint archive customer quotes follow-ups created.
representation also explicit reasons process design, supporting
human understanding. downside that, actual automated process execution,
concrete control-flow design required. One way viewing planning technology
provides service generating control-flow designs SAM.
Processes executed infrastructures, like one provided SAP. execution coordinates individual processing steps, prompting human users appropriate,
performing necessary data updating level. realized dedicated
592

fiSAP Speaks PDDL

process execution engines (Dumas, ter Hofstede, & van der Aalst, 2005). Clearly, execution poses high demands structure workflow. basic requirement
atomic process steps correspond actual steps known infrastructure.3
requirements business processes, legal financial regulations,
subject frequent updates. people responsible adapting processes business
experts familiar infrastructure, may come processes
whose atomic steps nowhere near implemented easily, partially overlap
whole sets existing functions, and/or require implementation new functions
although existing functions could arranged job. Thus need
intensive communication business experts experts, incurring significant
costs human labor increased time-to-market.
planning come rescue? indicated, basic (and well-known) idea
use planning tool composing (an approximation of) process automatically,
helping business expert come process close infrastructure.
main novelty work leverage pre-existing model, SAM, getting us around
one critical issues area: overhead creating planner input.

3. SAM
explain structure SAM language, give running example. outline
background SAM SAP, explain added value using SAM planning.
3.1 SAM Structure Example
Status Action Management (SAM) models belong business objects (BOs). BO
associated set finite-domain status variables, set actions.
status variable highlights one value variable take new instance
BO created. action described textual label (its name), precondition,
effect. precondition effect propositional formulas variable values.
Definition 3 (SAM BO) SAM business object triple (X(o), A(o), I(o)). X(o)
set status variables; x X(o) associated finite domain dom(x). A(o)
set actions, a(o) A(o) takes form (pre a(o) , eff a(o) ); pre a(o) (the precondition) propositional formula atoms {x = c | x X(o), c dom(x)}; eff a(o)
(the effect) negation-free propositional formula atoms, disjunctive
normal form (DNF). I(o) variable assignment representing os initial state.
structure obvious correspondence Definition 1. differences goal, preconditions effects complex.
planning application, goal set user creating new process. discuss
Section 4 extend Definitions 1 2 handle SAM preconditions effects.
Note cross-BO constraints SAM BO refers values
variables. shortcoming current version SAM: reality, BOs
interact. get back below.
3. Another important requirement appropriate data-flow (van der Aalst, 2003; Dumas et al., 2005),
e.g., sending manager documents required decide whether accept customer quote.
Since, case, data encapsulated business objects, major issue us.

593

fiHoffmann, Weber & Kraft

Action name
Check CQ Completeness

precondition
CQ.archiving:notArchived

Check CQ Consistency

CQ.archiving:notArchived

Check CQ Approval Status

CQ.archiving:notArchived
CQ.approval:notChecked
CQ.completeness:complete
CQ.consistency:consistent
CQ.archiving:notArchived
CQ.approval:necessary
CQ.archiving:notArchived
(CQ.approval:notNecessary
CQ.approval:granted)
CQ.archiving:notArchived
CQ.submission:submitted
CQ.archiving:notArchived
CQ.acceptance:accepted
CQ.archiving:notArchived

Decide CQ Approval
Submit CQ

Mark CQ Accepted
Create Follow-Up CQ
Archive CQ

effect
CQ.completeness:complete
CQ.completeness:notComplete
CQ.consistency:consistent
CQ.consistency:notConsistent
CQ.approval:necessary
CQ.approval:notNecessary

CQ.approval:granted
CQ.approval:notGranted
CQ.submission:submitted

CQ.acceptance:accepted
CQ.followUp:documentCreated
CQ.archiving:archived

Figure 1: SAM-like running example, modeling behavior customer quotes CQ.
illustration, Figure 1 gives SAM-like model BO called customer quote (CQ),
running example. confidentiality reasons, shown object model
artificial, i.e., contained SAM used SAP. CQ.x:c denote
proposition x = c, object CQ. initial state I(CQ) is:
CQ.archiving:notArchived,
CQ.completeness:notComplete,
CQ.consistency:notConsistent,
CQ.approval:notChecked,
CQ.submission:notSubmitted,
CQ.acceptance:notAccepted,
CQ.followUp:documentNotCreated.
using example below, relevant assume goal entered
user CQ.followUp:documentCreated CQ.archiving:archived.
reader keep mind merely illustrative example, necessarily simple. particular, intended life-cycle workflow rather obvious, given
action descriptions Figure 1. much case general. Business
Objects modeled SAM 15 status variables, yielding 12 million possible
states (combinations variable values) even single BO. words, SAM
flexible model all, main design purpose describes large number combination possibilities compact way. Furthermore, two application
scenarios planning ((A) (C) Section 3.3 below), actually looking
entire life-cycles process fragments may begin end BO status values.
594

fiSAP Speaks PDDL

3.2 SAM@SAP
SAM created SAP part development infrastructure supporting
SAP Business ByDesign. infrastructure constitutes fully-fledged SAP application.
key advantage traditional SAP applications higher degree flexibility, facilitating use SAP software as-a-service. Individual system functions encapsulated
software services, using service-oriented architectures paradigm (Krafzig et al., 2005;
Bell, 2008). software services may accessed standard architectures like BPM
process execution engines, thus enabling flexible combination services.
support flexibility, Business ByDesign infrastructure model-driven. artifacts various system levels described declaratively using SAP-proprietary modeling
formats. Business objects one artifact, SAM one format.
original purpose SAM facilitate design, management
changes, development Business ByDesign infrastructure (a formidably
huge enterprise). course, SAM also serves implementation changes infrastructure later on, changes required. New developments first implemented
tested model level. parts program code automatically generated
model. Straightforward code skeletons contain status variables, well function
headers available actions (similar Eclipse Java class definitions).
addition, skeletons filled code fragments performing precondition checks
updates status variables. Changes pertaining status variable level thus
implemented SAM models, automatically propagated code. sense,
original semantics SAM follows:
(I) BO newly created, values status variables set I(o).
(II) BO actions a(o) whose precondition pre a(o) fulfilled either disallowed,
raise exception executed; one true depends part
architecture attempting execute action.
(III) Upon execution action a, status variables change values prescribed
one disjuncts effect DNF eff a(o) . aspect controlled outside
SAM disjunct chosen: choice made based BO data content
reflected SAM.
intention behind SAM formulate complex business-level dependencies
individual processing steps, using simple modeling constructs facilitate easy modification. formulation terms preconditions effects relative high-level status
variable values adopted natural means meet requirements. course,
design also took inspiration traditional software modeling paradigms (Schneider,
2001; Object Management Group, 2006).
Leveraging SAM planning great opportunity effort takes build
model. SAM developed continuously along Business ByDesign, across
time span 5 years. Throughout time, around 200 people involved (as
part-time occupation) development. SAP implemented dedicated graphical user
interface development. design patterns typical cases, naming conventions, fully-fledged governance process, even educational
training developers. council senior SAP architects supervises development.
595

fiHoffmann, Weber & Kraft

3.3 Applications SAM-Based Planning
Business ByDesign infrastructure designed general adaptable, covering
needs great breadth different SAP customers business domains. adapt
infrastructure practice, SAP customers may choose create processes
compositions functionalities provided (as Web services), way tailored
needs. Indeed, second motivation behind SAM, beside role software development,
facilitate flexibility, describing possible process space declarative
manner, rather imposing standard workflows common methodology
contexts artefact-centric business process modeling (e.g., Cohn & Hull, 2009). SAM
shares motivation constraint-based process representation languages. also shares
downside, actual workflows still need created. context,
least three application scenarios planning based SAM:
(A) Development based SAM. model-driven development based SAM,
planning enables developers examine changes affect process space.
greatly facilitates experimentation testing. example, planning
used debugging, testing whether goal still reached, whether
changes opened unintended possibilities, like, reaching undesired state
BO (e.g., CQ.consistency:notConsistent CQ.acceptance:accepted).
reachability testing (essentially model checking task), planning serves
generate entire processes, shall see take form BPMN process models
parallelism conditional splits. Developers examine space processes
generated way, determining different combinations start/end conditions
connected. Note generality offered planning approach
absolute requirement process generation tool must least general
SAM, handling propositional formula preconditions effects.
(B) Designing extended/customized processes. Individual SAP customers individual requirements processes, thus may use BOs different
ways. example, even end state customer quotes (which practice
much complex illustrative example) always involved archived,
different businesses may differ side conditions: one organization archives
POs follow-ups created; another archives POs successful; third organization archives POs immediately automatically getting
response; fourth based explicit user-request. Part motivation
behind SAM provide flexibility. Planning based SAM used
automatically generate first version desired process.4
(C) Process redesign. Sometimes best option design new process scratch.
business experts aware underlying infrastructure,
incurs huge costs process implementation time. SAM opens possibility
business experts explain individual steps new process terms
status variable value changes, i.e., terms start/end state corresponding
business user considers atomic processing step. Planning shows
status changes implemented using existing transactions.
4. alternative equipping BO standard life-cycle set thereof would come
prize flexibility loss complex BOs, choice made SAP.

596

fiSAP Speaks PDDL

particular, planner called business object X (e.g., sales order)
within process created object (e.g., customer quote).
Hence, despite mentioned absence cross-BO constraints current version
SAM, planning help create non-trivial processes spanning several BOs.
use cases supported prototype SAP; illustrate use (C),
cross-BO situation mentioned, Section 7.3.
obvious requirement planner useful instantaneous response. Typically
user sitting computer waiting planner answer. Further,
functionality must accessible conveniently. particular, time user wants call
planner, needs provide planning goal (and possibly initial state).
essential done simple intuitive manner, without in-depth expertise
BO question. Thus limit conjunctive goals
sense want status variables values end process, like
goal CQ.followUp:documentCreated CQ.archiving:archived illustrative
example. prototype, goals specified using simple drop-down menus.
SAM originally intended planning, course perfect
purpose. discuss main limitations Section 9, need briefly touch
two points already. absence cross-BO constraints current version
SAM implications planner setup performance, play role
experiments.5 Another issue plan quality. duration/cost actions may differ
vastly, SAM contain information this: relevant SAMs
original purpose, software engineering. address plan quality measures herein.
planning algorithm course attempts find small plans. gives quality
guarantee regard, practical value guarantee would doubtful.

4. Planning Formalization
design syntax semantics suitable planning formalism capturing SAM,
illustrate formalism using running example.
4.1 SAM Planning Tasks: Syntax
Given close correspondence SAM business objects (Definition 3) finite-domain
planning tasks (Definition 1), straightforward extend latter capture former.
Definition 4 (SAM Planning Task) SAM planning task tuple (X, A, I, G) whose
elements finite-domain planning tasks, except action set A.
takes form (pre , Ea ) pre propositional formula atoms
{x = c | x X, c dom(x)}, Ea set partial variable assignments.
members eff Ea outcomes a.
discussed above, keep goal simple possible. effects, place
negation-free propositional DNF formulas Definition 3, sets Ea outcomes. action preconditions Definition 3. generalizes partial variable
5. shall discuss Section 9, BO interactions exist. according extension SAM planned,
could principle tackled using exact planning technology presented herein.

597

fiHoffmann, Weber & Kraft

assignments Definition 1 equivalent negation-free conjunctions
atoms {x = c | x X, c dom(x)} arbitrary propositional formulas atoms.
generalization poses issue defining plan semantics; implementation level,
current planning systems compile preconditions negation-free conjunctions,
using methods originally proposed Gazen Knoblock (1997).
obtain SAM planning task (X, A, I, G), given input SAM business object
= (X(o), A(o), I(o)) along goal conjunction G(o), first set X := X(o), := I(o),
G := G(o). a(o) A(o) include one A, pre := pre a(o) .
eff a(o) , create one partial variable assignment eff disjunct DNF
formula, define possible outcomes Ea set eff .
convention, denote Ad := {a | |Ea | = 1} := {a | |Ea | > 1}
sets deterministic non-deterministic actions SAM planning task, respectively.
Ad , eff denote single outcome a.
4.2 SAM Planning Tasks: Semantics
SAM action preconditions pre a(o) direct correspondence usual planning preconditions, cf. point (II) Section 3.2. contrast, SAMs disjunctive effects eff a(o) require
create mix two different kinds planning actions non-deterministic actions
observation actions literature. understand this, reconsider role SAM
action effects eff a(o) original environment, i.e., point (III) Section 3.2. one
disjuncts occur, plan generation time know one. plan
execution time, SAP system executing action observe relevant data content,
decide branch take. example Figure 1, Check CQ Completeness answer CQ.completeness:complete BO data complete, answer
CQ.completeness:notComplete otherwise. course, SAP system keeps track
outcomes occured. words, (a) SAMs disjunctive effects correspond observation
actions, (b) internally observe environment data modeled planning level.
Due (a), makes perfect sense handle actions introducing case distinctions
plan generation time, one outcome. Due (b), direct link
observation reduction uncertainty planning level. execution, values
observed variables known prior observation already, change
result applying action. example, CQ.completeness.notComplete considered
true prior first application Check CQ Completeness, may changed
CQ.completeness.complete action. respect, outcome
set (an arbitrary DNF) general domain particular variable, SAMs
disjunctive effects similar common notions non-deterministic actions.
simplicity, henceforth refer SAMs disjunctive-effects actions nondeterministic actions. Another important point regarding actions data content
allowed change process running; data filled directly upon creation BO. Thus outcome non-deterministic action throughout
plan execution, makes sense execute action
plan. example, point repeatedly applying Check CQ Completeness.
final issue decide plan actually is. Cimatti, Pistore, Roveri, Traverso
(2003) describe three common concepts, presence non-deterministic ac598

fiSAP Speaks PDDL

tions: strong plans, strong cyclic plans, weak plans. discuss latter two
below; desirable property first one. strong plan guarantees reach
goal matter action outcomes occur. define formally, setting.
action tree tree whose nodes actions A, whose edges
labeled partial variable assignments. action tree exactly |Ea | outgoing
edges, one (and labeled with) eff Ea . following definitions,
av refers
subset non-deterministic actions yet used, thus still
available, given state plan execution. Recall seff , defined Section 2,
over-writes variable values defined eff , leaves unchanged elsewhere.
Definition 5 (Strong SAM Plan) Let (X, A, I, G) SAM planning task =
nd
Ad . Let state, let
av , let action tree {STOP }.
say strong SAM solution (s,
av ) iff either:
(i) consists single node STOP , |= G;
(ii) root Ad , |= pre , sub-tree rooted child strong
SAM solution (s eff ,
av );
nd
(iii) root Aav , |= pre , and, children reached via edge
labeled eff Ea , sub-tree rooted child strong SAM solution
(s eff ,
av \ {a}).
strong solution (I, ), called strong SAM plan.
Compare Definition 2. Item (i) present definition essentially same,
saying nothing goal already true. difference Definition 2,
distinguish deterministic actions (ii) non-deterministic ones (iii). former
case, single child require remainder tree solve child,
similarly Definition 2. latter case, several children need
solved respective sub-tree. corresponds desired case distinction observing
action outcomes plan execution time.
Note that, throughout plan, uncertainty current variable values.
Note also solve, state, pair consisting state subset nondeterministic actions. reflects fact whether action tree solves state
depends state itself, also non-deterministic actions still
available. maintenance set
av ensures allow non-deterministic
action once, path (but action may occur several times
separate paths). Thus one execution plan applies action once.
problem Definition 5 strong plans typically exist. illustrate this, consider Figure 2, showing weak SAM plan, notion formally
define, running example Figure 1. Recall goal assumed
CQ.followUp:documentCreated CQ.archiving:archived. either Check CQ
Completeness Check CQ Consistency, shown top Figure 2, result
negative outcome (CQ.completeness:notComplete CQ.completeness:notConsistent),
goal becomes unreachable. Thus strong plan exist SAM planning task. phenomenon limited illustrative example. experiments,
almost 75% large sample SAM planning tasks strong plan.
address this, one define complicated goals, weaker notion plans.
former option, one could use goals specifying alternatives, preferences, and/or temporal
599

fiHoffmann, Weber & Kraft

Check CQ Completeness

N
Check CQ Consistency

N
Check CQ Approval Status
notNec

Nec
Decide CQ Approval
granted

Submit CQ

notGranted

Mark CQ Accepted
Submit CQ
Create FollowUp CQ
Mark CQ Accepted
Archive CQ
Create FollowUp CQ
Archive CQ

Figure 2: weak SAM plan running example Figure 1. STOP actions
shown, FAIL actions marked (red) crosses.
plan properties (e.g., Pistore & Traverso, 2001; Dal Lago, Pistore, & Traverso, 2002; Shaparau, Pistore, & Traverso, 2006; Gerevini et al., 2009). However, goals specified
online business users absolutely essential simple possible.
hence decided go second option.6
weak plans Cimatti et al. (2003) liberal purposes. guarantee
least one possible execution plan reaches goal, posing requirements executions. example, Figure 2, would mean allow
plan handle left-hand side outcome Check CQ Approval Status, i.e.,
CQ.approval:notNecessary, nothing (attach empty tree at)
outcome, CQ.approval:necessary.
strong cyclic plans? There, plan may cycles, provided every
plan state can, principle, reach goal. allows wait desired outcome, like
cycle around dice throw, waiting obtain 6. Alas, repetitions non-deterministic
SAM actions always produce outcome. futile insert cycle
top Figure 2, waiting desired outcome Check CQ Completeness.
plausible prompt user edit BO content repeat check (placeholders
cycles could inserted planning post-process), suitable exception
handling general. Exception handling depends business context, typically
depends actual customer using SAP system. impossible reflect
model maintained centrally SAP.
conclusion, perspective SAM-based planning much one
highlight bad outcomes user, exception handling
6. works complex goals employed define alternative notions weak plans (by
using trivial fall-back goals). discuss detail Section 8.

600

fiSAP Speaks PDDL

inserted manually afterwards. course, non-deterministic action least
one successful outcome, else would completely displaced process. Further,
essential highlight outcomes bad really bad, i.e., mark
failed outcomes could actually solved. definition reflects this:
Definition 6 (Weak SAM Plan) Let (X, A, I, G) SAM planning task = Ad
nd
. Let state, let
av , let action tree {STOP , FAIL}.
say weak SAM solution (s,
av ) iff either:
(i) consists single node STOP , |= G;
(ii) root Ad , |= pre , sub-tree rooted child weak
SAM solution (s eff ,
av );
nd
(iii) root Aav , |= pre , and, children reached via edge
labeled eff Ea , either: (a) sub-tree rooted child
weak SAM solution (s eff ,
av \ {a}); (b) sub-tree rooted
child consists single node FAIL, exists action tree 0
weak SAM solution (s eff ,
av \ {a}); (a) case least one
children.
weak solution (I, ), called weak SAM plan.
Compared Definition 5, difference lies item (iii), longer requires
every child solved. Instead, arrangement options (a) (b) means
failed nodes leaves tree stop plan without success tolerated,
long least one child solved, every failed node actually unsolvable.
obvious correspondence discussion above. Figure 2, failed nodes, i.e.,
sub-trees consisting special FAIL action, crossed (in red). Note
difference Cimatti et al.s (2003) definition weak plans discussed above:
allowed cross right-hand side outcome Check CQ Approval Status,
i.e.,CQ.approval:necessary, outcome solvable.
remark allowing non-deterministic actions (or, generally,
upper bound repetition non-deterministic actions) required Definition 6
make sense. item (iii), definition recurses stating children
may unsolvable. recursion occurs also points Definitions 5 6,
points action tree considered reduced least one node. unsolvable
children non-deterministic actions Definition 6 (iii) (b), reduction given
quantification action tree 0 may suitable solve child.
makes recursion sound, instead, set available non-deterministic actions
diminished one. Without this, notion weak SAM plan would ill-defined:
recursion step may result planning task again, allowing construction
planning tasks considered solvable unsolvable.7
7. Concretely, say obtain Definition 6 Definition 6 considering states only, removing
handling
av . Consider example one variable x whose possible values B,
initial state : x = A, goal G : x = B, single action two possible outcomes, x =
x = B. Say consists a. bad outcome a, i.e., state x = A, identical
original initial state I. unsolvable according Definition 6, outcome qualifies
Definition 6 (iii) (b), thus overall task state considered solvable.
contrast, using Definition 6 above, plan must solve state/available-non-deterministic-actions
pair (x = A, {a}), bad outcome different pair (x = A, ). pair unsolvable,
hence weak plan.

601

fiHoffmann, Weber & Kraft

following observation holds simply Definition 5 captures special case
Definition 6:
Proposition 1 (Weak SAM Plans Generalize Strong SAM Plans) Let (X, A, I, G)
nd
SAM planning task = Ad . Let state, let
av , let
action tree {STOP }. strong SAM solution (s,
av ),
weak SAM solution (s,
).
av
words, strong SAM plan also weak SAM plan, hence particular
SAM planning task solvable strong semantics also solvable
weak semantics. inverse obviously true. counter-example running
example Figure 2.
remark that, trivially, deciding whether plan exists hard both, Definition 5
Definition 6. special case actions deterministic generalization
Definition 2, mentioned problem PSPACE-complete.
4.3 SAM Planning Tasks: Running Example
illustration, encode running example, Figure 1, SAM planning task
(X, A, I, G). set X := {Arch, Compl , Cons, Appr , Subm, Acc, FoUp}, abbreviating status variable names mentioned Figure 1. example, Arch stands
variable CQ.archiving. domain Arch, Compl , Cons, Subm, Acc, FoUp
{true, false}. serves abbreviate various names used respective variable
values Figure 1. domain Appr {notChecked , nec, notNec, granted , notGranted }.
follows, brevity write facts, i.e., variable/value pairs, involving true/false
valued variables like literals. example, write FoUp instead (FoUp, no).
initial state SAM BO, thus SAM planning task, is:
= {Arch, Compl , Cons, (Appr , notChecked ), Subm, Acc, FoUp}
goal CQ.followUp:documentCreated CQ.archiving:archived:
G = {FoUp, Arch}
deterministic actions Ad are:
Mark CQ Accepted: (Arch Subm, {Acc})
Create Follow-Up CQ: (Arch Acc, {FoUp})
Archive CQ: (Arch, {Arch})
Submit CQ: (Arch ((Appr , notNec) (Appr , granted )), {Subm})
Note action effects sets partial variable assignments, i.e., sets sets facts.
deterministic actions, one partial variable assignment omit
second pair set parentheses avoid notational clutter. Note also
delete effects. effects assign new values affected variables, implicitly removing
old values, cf. meaning eff defined Section 2.
non-deterministic actions are:
Check CQ Completeness: (Arch, {{Compl }, {Compl }})
Check CQ Consistency: (Arch, {{Cons}, {Cons}})
602

fiSAP Speaks PDDL

Check CQ Approval Status:
(Arch (Appr , notChecked ) Compl Cons, {{(Appr , nec)}, {(Appr , notNec)}})
Decide CQ Approval:
(Arch (Appr , nec), {{(Appr , granted )}, {(Appr , notGranted )}})
Figure 2 shows weak SAM plan example. presentation user, simple
post-process (outlined Section 7.1) transforms plans BPMN workflows.

5. Planning Algorithms
design adaptation FF (Hoffmann & Nebel, 2001), using variant AO* forward search Contingent-FF (Hoffmann & Brafman, 2005), well nave extension
FFs heuristic function. assume reader familiar heuristic search
general, refer literature (e.g., Pearl, 1984) background.
5.1 Search
strong SAM planning Definition 5 use AO* tree search (Nilsson, 1969, 1971).
weak SAM planning Definition 6 use variant search refer
SAM-AO*. focus follows mainly SAM-AO*, since AO* well-known
become clear side effect discussion.
Search forward AND-OR tree whose nodes states (OR nodes) actions
(AND nodes). ORed children states applicable actions, ANDed children
actions alternative outcomes (for deterministic actions, single child
node trivializes). Like AO*, propagate node solved node failed
markers. mechanics usual ones case nodes, i.e., marker
node disjunction childrens markers. nodes, SAM-AO* differs
usual conjunctive interpretation, implementing weak SAM planning semantics
Definition 6: amongst things, node failed children
failed. Figure 3 provides overview SAM-AO*, highlighting differences AO*.
Figure 4 illustrates algorithm simplification running example.
One feature algorithm immediately apparent book-keeping
non-deterministic actions still available. Recall that, line Definitions 5
6, allow non-deterministic action execution plan.
search algorithm strong planning (AO*) weak planning (SAM-AO*)
means nodes contain state s, pair (s,
av ) giving state
nd
well subset used node. refer pairs
search states on. book-keeping sets
av straightforward.
initial state, non-deterministic actions still available. Whenever non-deterministic
action applied, outcome states, longer available. illustration, consider
action sets reduced Figure 4 (BD).
heuristic function h, assume given here, takes arguments search
state, i.e., state available non-deterministic actions. action
availability affects goal distance hence heuristic estimates. h(s) = 0 heuristic
indicates goal states, h(s) = may indicate state unsolvable.
algorithm trusts heuristic, i.e., assumes h returns values state
603

fiHoffmann, Weber & Kraft

procedure SAM-AO*
input SAM planning task (X, A, I, G) = Ad , heuristic function h
output weak plan (X, A, I, G), unsolvable
initialize consist NI ; content(NI ) := (I, )
status(NI ) :=solved h(I, ) = 0, failed h(I, ) = , unknown else
status(NI ) =unknown
Ns := select-open-node(T ); (s,
av ) := content(Ns )
Ad
av |= pre
Ad is-direct-duplicate(Ns , eff ,
av ) skip endif
insert Na child Ns ; content(Na ) :=
0
nd

nd 0
nd

av := Aav , else Aav := Aav \ {a}
eff Ea
s0 := eff
0
insert Ns0 child Na ; content(Ns0 ) := (s0 ,
av )
0
0
0
nd
status(Ns0 ) := solved h(s0 ,
av ) = 0, failed h(s , Aav ) = , unknown else
endfor
status(Na ) := SAM-aggregate({status(N 0 ) | N 0 child Na })
endfor
status(Ns ) := OR-aggregate({status(N 0 ) | N 0 child Ns })
propagate-status-updates-to-I (Ns )
endwhile
status(NI ) =failed return unsolvable endif
return action tree corresponding subtree 0 s.t. NI 0 and:
inner nodes Ns 0 : status(Ns ) = solved Ns exactly one child Na 0 ;
nodes Na 0 : children Ns0 Na contained 0
is-direct-duplicate(N, s0 ,
av ) :=

SAM-aggregate(M ) :=


solved






true predecessor N0 N s.t. content(N0 ) = (s0 ,
av )
false else
: = solved,
: (m = solved = failed)
: = failed
else

failed



unknown

: = solved
solved
failed
: = failed
OR-aggregate(M ) :=

unknown else

Figure 3: Pseudo-code SAM-AO*, highlighting differences AO*.
indeed goal state/unsolvable. Detecting unsolvable states within capabilities
FFs heuristic, paramount importance planning SAM models. behavior
like heuristic Figure 4 (BD), immediately marks unsolvable nodes
such. get back Section 5.2.2 below.
overall structure SAM-AO* AO*. Starting initial
search state (compare Figure 4 (A)), iteratively use select-open-node select node
Ns tree yet expanded whose status unknown; selection
criterion based nodes f -value, explained below. expand selected node
applicable actions (in Figure 4 (B), omit Check CQ Consistency save
space), insert one new node possible outcome actions (Comp vs.
604

fiSAP Speaks PDDL



B

Comp, Cons; CheckComp, CheckCons
unknown; h=2

Comp, Cons; CheckComp, CheckCons
unknown; h=2

Check CQ Completeness unknown

Comp, Cons; CheckCons
unknown; h=1

C



Comp, Cons; CheckComp, CheckCons
unknown; h=2

Check CQ Completeness unknown

Comp, Cons; CheckCons
solved; h=1

Comp, Cons; CheckComp, CheckCons
solved; h=2

Check CQ Completeness solved

Comp, Cons; CheckCons
failed; h=infty

Comp, Cons; CheckCons
solved; h=1

Check CQ Consistency solved

Comp, Cons; (none)
solved; h=0

Comp, Cons; CheckCons
failed; h=infty

Comp, Cons; CheckCons
failed: h=infty

Check CQ Consistency solved

Comp, Cons; (none)
failed; h=infty

Comp, Cons; (none)
solved; h=0

Comp, Cons; (none)
failed: h=infty

Figure 4: Phases SAM-AO* simplifaction running example (Figure 1),
two variables CQ.completeness CQ.consistency,
two actions Check CQ Completeness Check CQ Consistency. goal,
using abbrevations here, Comp, Cons. search states (s,
av ),
left-hand side semicolon show state s, right-hand side
show set
av available non-deterministic actions.
-Comp Figure 4 (B)); discuss is-direct-duplicate function below. new
node, i.e., corresponding search state, evaluated heuristic function.
outcomes action inserted, status updated. actions applicable
current node Ns inserted, status Ns updated. latter update, reflected
OR-aggregate equation Figure 3, exactly AO*. key difference AO* lies
former update, reflected SAM-aggregate equation. equation obvious
correspondence Definition 6. Figure 4 (B), neither updates yields new
information, status one action outcomes, Comp, Cons; CheckCons,
unknown. changes Figure 4 (C), status outcomes becomes
definite (solved/failed), updates propagate information action
search state node Ns applied to.
status Ns set, propagate-status-updates-to-I (Ns ) performs
backward iteration starting Ns , updating action search state along way
using two functions, OR-aggregate SAM-aggregate. necessary since
status Ns may changed, may affect status predecessors.
happens, example, Figure 4 (D) status first node action
change unknown solved . algorithm terminates initial node
605

fiHoffmann, Weber & Kraft

(the search tree root) solved failed. former case, solved sub-tree returned.
happens Figure 4 (D), sub-tree returned equivalent start (top two
actions) example plan Figure 2.
addition status markers, SAM-AO* also annotates search states f values, well current best action. shown Figure 3 since (almost)
identical done AO*. f -value search state node minimum
children, plus 1 accounting cost applying action; minimizing child
best action. f -value action node maximum children, except
herein lies difference AO* set action value unless
children marked failed. select-open-node procedure starts NI keeps
choosing best actions arrives non-expanded state, selected Ns .
is-direct-duplicate function Figure 3 disallows generation search states
identical one predecessors tree. refer direct duplicate
pruning. Note method prunes duplicates within deterministic parts
search tree. predecessor node N0 Figure 3 found, actions
N0 N deterministic, otherwise content(N0 ) would contain strictly
non-deterministic actions N . Obviously, direct duplicate pruning preserves soundness
completeness search algorithm. have:

Proposition 2 (SAM-AO* Complete Sound) Let (X, A, I, G) SAM planning task, let h heuristic function. SAM-AO* terminates run task
h. Provided h(s) = 0 iff goal state, h(s) = unsolvable, SAM-AO*
terminates success iff exists weak SAM plan task, action tree
returned case plan.
follows known results AO*, definition, two simple observations. First, eventually, tree path non-deterministic actions available
anymore. Second, direct duplicate pruning allows finitely many nodes SAM planning task without non-deterministic actions.
reader might wonder whether stronger duplicate pruning methods could defined, across non-deterministic actions tree. nave approach, asking
whether predecessor N contains state ignoring sets available
non-deterministic actions work SAM-AO*. renders algorithm unsound. pruning method may mark solvable search states failed,
failed nodes part solution weak plan. illustration, consider
simple example variable x values A, B, C, initial state A, goal
C, three actions: a1 precondition two possible outcomes B C; a2
precondition B outcome A; a3 precondition outcome C. Say search
chosen apply a1 first. Consider a1 unfavorable outcome B. point, order
obtain plan, must apply a2 , a3 achieve goal C. However, outcome state
: x = a2 initial state. Hence pruned, hence a1 outcome B
marked failed, hence algorithm wrongly concludes a1 outcomes qualify
Definition 6 (iii), a1 plan.
606

fiSAP Speaks PDDL

5.2 Heuristic Function
compute goal distance estimates, use all-outcomes-determinization known
probabilistic planning (Yoon et al., 2007) get rid non-deterministic actions, run
FF heuristic (Hoffmann & Nebel, 2001) off-the-shelf. sake self-containedness,
next explain detail. reader familiar FF may skip Section 5.2.2.
5.2.1 Relaxed Planning Graphs
FFs heuristic function one range general-purpose planning heuristics based
relaxation widely known ignoring delete lists (McDermott, 1999; Bonet & Geffner,
2001). Heuristics kind emerged late 90s still highly successful.
follows, assume action preconditions goal conjunctions
positive atoms, thus equivalent sets facts. general formulas,
preconditions SAM planning tasks, one apply known transformations (Gazen &
Knoblock, 1997) achieve this.
name delete lists comes Boolean-variable representation planning tasks.
Translated context, relaxation means variables accumulate, rather
change, values. illustration, say CQ.archiving:notArchived running example, apply action Archive CQ whose effect CQ.archiving:archived.
Then, relaxation, resulting state CQ.archiving:notArchived, CQ.archiving:
archived, containing old new value variable CQ.archiving. Thus
actions BO, require customer quote archived yet,
remain applicable, difference plan Figure 2, relaxed plan archive
CQ right start proceed rest processing.
Viewing variable assignments sets facts, relaxed action application equivalent
taking set union current state action effect. yields strictly
larger set facts real application action (CQ.archiving:notArchived,
CQ.archiving:archived instead CQ.archiving:archived). Satisfaction preconditions
goal tested asking inclusion set. Bylander (1994) proved
that, within relaxation, plan existence decided polynomial time. also
proved, however, optimal relaxed planning, i.e., finding length shortest possible relaxed plan, still NP-hard. Therefore, heuristics used practical planners
approximate length. Specifically, FF heuristic build herein computes
necessarily optimal relaxed plan. algorithm consists two phases. First,
builds relaxed planning graph (RPG) approximate forward reachability.
extracts relaxed plan RPG.
Figure 5 shows RPG computed planner. algorithm gets state
well remaining non-deterministic actions,
av . determinizes latter
actions, inserting possible outcomes individual new deterministic action
new action set A0 . following loop simple fixed point operation sets
facts. initial set F0 equal state whose goal distance shall estimated.
loop iteration increments Ft effects actions whose preconditions
reached. case goals reached, algorithm stops success returns
iteration index t. fixed point occurs happens, algorithm returns .
607

fiHoffmann, Weber & Kraft

procedure RPG
input SAM planning task (X, A, I, G) = Ad ,
state s, available non-deterministic actions
av
output Number relaxed parallel steps needed reach goal,
A0 := Ad {(pre , {eff }) |
av , eff Ea }
F0 := s, := 0
G 6 Ft
A0t := {a A0S| pre Ft }
Ft+1 := Ft aA0 eff

Ft+1 = Ft return endif
:= + 1
endwhile
return

Figure 5: Pseudo-code building relaxed planning graph (RPG).
RPG returns < , heuristic function algorithm enters second phase,
relaxed plan extraction. straightforward backchaining procedure selecting supporting actions goals, iteratively supporting actions preconditions.
backchaining makes sure select feasible supporters exploiting reachability
information encoded sets Ft . Note good heuristic estimator
counts parallel action applications could make transactions 1000 BOs
parallel still count single step.
Consider simplified example Figure 4. root node Comp, Cons; CheckComp, CheckCons, relaxed plan returned hCheck CQ Completeness+ , Check
CQ Consistency+ i, superscript + indicates actions
determinized set A0 Figure 5, choosing positive outcome actions.
heuristic value returned 2, Figure 4. Indeed, heuristic values
Figure 4 would returned FFs heuristic. particular, -Comp, i.e.,
CQ.completeness:notComplete, holds state, action Check CQ Completeness longer available, heuristic value returned action
A0 achieve goal Comp, thus RPG fixed point contain goal.
Similarly -Cons holds state Check CQ Consistency longer available.
5.2.2 Detecting Failed Nodes
follows directly from, e.g., results Hoffmann Nebel (2001), RPG stops
success iff exists relaxed plan task (X, A0 , s, G). this, easily
get following result relevant us:
Proposition 3 (RPG Dead-End Detection SAM Sound) Let (X, A, I, G)
nd set
SAM planning task = Ad . Let state, let
av
non-deterministic actions. RPG run inputs returns , exists
weak SAM solution (s,
av ).
see this, note action set A0 Figure 5 is, perspective plan
0
existence, over-approximation actual action set Ad
av got available.
allows us choose, non-deterministic action, outcome want. Thus,
0
plan using Ad
av trivially construct plan using . plan using
608

fiSAP Speaks PDDL

A0 exists neither plan using Ad
av . suffices see nonexistence relaxed plan (based A0 ) implies non-existence real plan (based A0 ).
obvious, concluding argument.
course strong simplification act one could choose outcomes
non-deterministic actions. Part motivation demonstrate
necessary, least application context, dramatically enhance off-the-shelf planning
techniques. simplistic approach presented suffices obtain good performance.
particularly true regarding ability detect dead-ends. experimented
total 548987 planning instances based SAM. (within limited time/memory)
found weak plan 441884 instances. Around half actions plans
non-deterministic, typically yield failed nodes plan. every one
failed nodes, every one 441884 solved instances, RPG returned .
5.2.3 Helpful Actions Pruning
also adopt FFs helpful actions pruning. Aside goal distance estimate,
relaxed plan used determine promising subset H(s) helpful actions
actions applicable evaluated state s. Essentially, H(s) consists actions
applicable contained relaxed plan computed described
Section 5.2.1.8 action subset used pruning method simply restricting,
search, expansion state consider actions H(s). kind
heuristic action pruning paramount importance planner performance (Hoffmann &
Nebel, 2001; Richter & Helmert, 2009).
SAM setting, one important aspect FFs helpful actions pruning
accurate enough distinguish relevant BOs irrelevant ones. say, BO
mentioned goal, action pertaining ever considered
helpful. simply because, pointed previously, SAM currently model
cross-BO interactions. BO goal relaxed plan extraction
never create sub-goals pertaining .
obvious well-known caveat helpful actions pruning
preserve completeness. H(s) may contain actions actually start plan
s. happens, search may stop unsuccessfully even though plan exists.
pertains classical planning pertains AO* SAM-AO* used herein.
Importantly, helpful actions pruning SAM-AO*, i.e., weak SAM planning per
Definition 6, another subtle caveat: preserve soundness. Consider
example variable x values A, B, C, initial state A,
goal C, three actions action a1 precondition two possible
outcomes B C, a2 precondition B outcome A, a3 precondition
outcome C. Say search applied a1 . Say Ns := (s,
av ) node
corresponding a1 unfavorable outcome B. way complete a1 plan
attach a2 , a3 Ns . Presume helpful actions pruning, node Ns , removes a2 .
Ns marked failed, wrongly conclude a1 plan.
8. FFs definition H(s) little complicated, adding also actions selected
relaxed plan achieve relevant sub-goal. omit brevity. Recent variants helpful
actions pruning, different heuristic functions like causal graph heuristic (Helmert, 2006),
make additions, selecting H(s) based membership abstract solutions only.

609

fiHoffmann, Weber & Kraft

Using helpful actions pruning, one may incorrectly mark node Ns failed. Ns
leaf weak plan , marked failed even though solvable action tree 0 ,
valid plan. fixed, plan-correction post-process, attaching 0
Ns , 0 found running SAM-AO* without helpful actions pruning Ns .
implement post-process because, according experiments, unnecessary
practice: discussed end previous sub-section, failed nodes Ns
441884 weak plans heuristic value , thus proved be, indeed, unsolvable.

6. Experiments
describe prototype SAP next section. follows, evaluate
planning techniques detail scientific point view. experiments aimed
understanding three issues:
(1) applicability strong respectively weak planning SAM?
(2) runtime performance planner sufficient envisioned application?
(3) interesting SAM planning benchmark?
first explain experiments setup. describe experiments FF
strong plans, FF weak plans; summarize findings blind search.
experiments consider instances pertaining single BO, finally examine
happens scaling number relevant BOs.
6.1 Experiments Setup
experiments run 1.8 GHz CPU, 10 minute time 0.5 GB memory
cut-off. planner implemented C modification FF-v2.3. source code,
problem generator used experiments, anonymized PDDL encoding SAM
available download http://www.loria.fr/~hoffmanj/SAP-PDDL.zip. SAMAO* implementation modifed AO* implementation Contingent-FF (Hoffmann
& Brafman, 2005). Like planner, weight heuristic values factor 5 (we
play parameter).
focus case initial state set specified SAM. Thus SAM
planning instance follows identified goal: subset variable values.
number instances finite, enormous; choosing subset variables
constrained 21110 options. follows, mostly consider goals whose
variables belong single BO. sensible because, previously stated, SAM currently
reflect interactions across BOs. made instance generator allows
create instance subsets characterized number |G| variables constrained goal
(this parameter relevant business users, shall see also heavily influences
planner performance). given |G|, generator enumerates possible variable tuples,
allows randomly sample given number value tuples.
maximum number variables BO, current version SAM, 15. created
possible instances |G| = 1, 2, 3, 13, 14, 15 number instances
around 50000. values |G|, chose value got around
50000 instances each. total number instances generated 548987.
610

fiSAP Speaks PDDL

Since SAM currently model cross-BO interactions, single-BO goal
principle supply planner actions pertaining BO.
henceforth refer option using BO-relevant actions. Contrasting this,
full actions option supplies planner actions (no matter BO pertain
to). use BO-relevant actions experiments wish enable
planner prove planning task unsolvable full actions, always
impossible reachable state space much vast. baseline, however,
use full actions. motivation helpful actions pruning detect
irrelevant actions anyway (cf. Section 5.2), long term, likely SAM
model cross-BO interactions.
6.2 Strong SAM Plans
first experiment, evaluate performance strong planning SAM, i.e,
run FF standard AO* tree search forcing children nodes solved.
identify two parameters relevant performance FF: kind BO considered,
|G|. Figure 6 shows coverage state evaluations (number calls heuristic
function) depend parameters.
Consider first Figure 6 (a). x-axis ranges BOs, i.e., data point corresponds
one kind BO.9 ordering BOs decreasing percentage solved instances.
BO, y-axis shows percentage solved, unsolved, failed instances within
BO. overall message mixed. one hand, coverage perfect 194
371 BOs, half BOs tested instances strong plan
found FF. hand, 177 BOs, coverage rather bad.
51 BOs, single instance solved. 126 BOs between, coverage
declines steeply. Importantly, counting unsolved cases total (across BOs), turns
88.83% instances unsolved. words, almost 90%
tested cases FFs search space contain strong SAM plan. course,
percentage pertains particular distribution test cases used. Still
result indicates applicability strong planning SAM quite limited.
Another interesting aspect Figure 6 (a) failed cases rare: constitute
0.8% total instance set. is, due helpful actions pruning, FFs search
spaces typically small enough exhausted within given time memory.
Consider Figure 6 (b), shows coverage y-axis |G| x-axis.
Again, message mixed. one hand, single goal (|G| = 1), 58.85%
instances solved strong plan. hand, number solved cases
declines monotonically, quite steeply, growing |G|. 2 goals 36.95%,
4 goals 29.03%, 5 goals 23.86%. |G| 10, number solved cases
less 5%, |G| 13, number less 1%.
One may wonder point whether FFs helpful actions pruning responsible frequent non-existence strong plans. answer no. second
experiment strong planning, ran FF without helpful actions, giving input
9. Note include 404 BOs. Precisely, consider 371 them. remaining 33 BOs
interesting planning: variable values true initial state unreachable
values set procedures encoded SAM.

611

fi100

100

90

90

80

80

70

70

60

Coverage

Coverage

Hoffmann, Weber & Kraft

SOLVED
UNSOLVED
FAILED

50
40

60

40

30

30

20

20

10

10

0

SOLVED
UNSOLVED
FAILED

50

0
0

50

100

150

200
BO

250

300

350

1

2

3

4

5

6

7

100000

10000

10000

1000

UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

100

9

10 11 12 13 14 15

(b)

100000

Number evaluated states

Number evaluated states

(a)

8
|G|

10

1

UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

1000

100

10

1
0

50

100

150

200
BO

250

300

350

1

2

3

(c)

4

5

6

7

8
|G|

9

10 11 12 13 14 15

(d)

Figure 6: Strong planning FF full action sets. Coverage (a,b) state
evaluations (c,d) data, plotted individual kinds BOs (a,c) |G| (b,d).
SOLVED: plan found. UNSOLVED: search space (with helpful actions pruning) exhausted. FAILED: time memory. Ordering BOs (c)
increasing y-value curve individually.
BO-relevant actions order enable proofs unsolvability. result clear:
number solved cases hardly changes all. total percentage solved cases
previous experiment 10.38%, total percentage new experiment 10.36%.
low success rate due unsolvability, prohibitively large search spaces.
total, 74.1% instances proved unsolvable; FF fails 15.54%.
Given above, applicability strong planning SAM appears limited unless
restrict attention BOs variables and/or single-goal planning tasks.
general perspective, best option appears to:
(I) Try find strong SAM plan (using FF AO*).
(II) (I) fails, try find weak SAM plan (using FF SAM-AO*).
setting, relevant long wait answer (I). Figures 6
(c) (d) provide data this. consider instances FF terminated regularly
(plan found helpful actions search space exhausted), consider performance
terms number evaluated states, i.e., number calls heuristic function.
612

fiSAP Speaks PDDL

ordering BOs Figure 6 (c) increasing y-value curve individually;
otherwise plot would unreadable. striking observation that, 351
371 BOs, maximum number state evaluations 100. solved instances,
even holds 369 BOs, i.e., 2 BOs. maximum number state
evaluations done order find plan 521, taking 0.22 seconds total runtime. mean
behavior even good-natured, peaking 9.85 state evaluations. Waiting
time consuming, peak 42954 evaluations respectively 110.87 seconds.
However, since yes answers given quickly, practical use online
business process modeling environment seems feasible simply give strong planning
one second (or less), switch weak planning case successful.
Consider Figure 6 (d). Like (c), observe low number state evaluations required solved cases. Somewhat surprisingly, conclusive behavior
|G|. reasons entirely clear us. UNSOLVED MAX curve flat
top larger search spaces lead failure. discontinuities around |G| = 12
presumably due BO structure. BOs 12 variables, variance
data higher region. sharp drops UNSOLVED MAX SOLVED
MAX, additional factor strong plans large goals (cf.
Figure 6 (b)): strong plans exist found easily; disproving existence
strong plan easier larger goals, since increases chance relaxed
plan identify least one unsolvable goal.
Summing findings regarding issue (1) [applicability strong vs. weak planning SAM] wish understand experiments, SAM admit many
strong plans, instances tend solved easily FF.
6.3 Weak SAM Plans
see weak SAM planning solve 8 times many instances
strong SAM planning namely around 80% test cases. Precisely, 548987
instances, 441884 solved; 43 solved default configuration
planner. average percentage non-deterministic actions, across weak plans,
48.29%; maximum percentage 91.67%. Figure 7 shows results, giving
four kinds plots previously shown strong planning Figure 6.
Consider first Figure 7 (a). see that, now, coverage perfect 274 371 kinds
BOs, opposed 194 BOs true strong planning. latter
BOs subset former: wherever strong planning perfect coverage
true weak planning. Whereas strong planning 0 coverage instance solved
51 BOs, cases here. minimum coverage 18.07%, coverage
50% 9 BOs. total, strong planning solves 10.38% test
cases, solve 80.48%. said, still 17.12% unsolved cases 2.4% failed
cases, gets much worse BOs. Per individual BO, fraction unsolved
instances peaks 81.92%, fraction failed instances peaks 14.98%.
Consider Figure 7 (b). |G| = 1 handled perfectly 100% coverage opposed
58.85% strong planning followed fairly steady decline |G| grows.
explanation discontinuity |G| = 3, 4 could |G| = 3 experiment
613

fi100

100

90

90

80

80

70

70

60

Coverage

Coverage

Hoffmann, Weber & Kraft

SOLVED
UNSOLVED
FAILED

50
40

60

40

30

30

20

20

10

10

0

SOLVED
UNSOLVED
FAILED

50

0
0

50

100

150

200
BO

250

300

350

1

2

3

4

5

6

7

1e+06

100000

100000

10000
UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

1000

9

10 11 12 13 14 15

(b)

1e+06

Number evaluated states

Number evaluated states

(a)

8
|G|

100

10

UNSOLVED MAX
SOLVED MAX
UNSOLVED MEAN
SOLVED MEAN

10000

1000

100

10

1

1
0

50

100

150

200
BO

250

300

350

1

(c)

2

3

4

5

6

7

8
|G|

9

10 11 12 13 14 15

(d)

Figure 7: Weak planning FF full action sets. Coverage (a,b) state evaluations (c,d) data, plotted individual kinds BOs (a,c) |G| (b,d).
SOLVED: plan found. UNSOLVED: search space (with helpful actions pruning) exhausted. FAILED: time memory. Ordering BOs (c)
increasing y-value curve individually.
exhaustive |G| = 4 sample. above, higher variance large |G|
explained much smaller number BOs region.
Figures 7 (c) (d) provide deeper look performance instances
FF terminated regularly (plan found helpful actions search space exhausted). Like
Figure 6 (c), ordering BOs Figure 7 (c) increasing y-value curve
individually. number state evaluations typically low. phenomenon quite
extreme shown strong planning Figure 6 (c). likely
generous definition plans makes difficult FF prove nodes unsolvable,
hence prune large parts search space. detail, 350 371 BOs,
maximum number state evaluations 100; solved instances, holds 364
BOs (the corresponding numbers strong planning 351 369). maximum
number state evaluations done order find plan 54386, taking 27.41 seconds total
runtime (521 0.22 strong planning). SOLVED MEAN curve see
maximal case exceptional mean number state evaluations per BO peaks
614

fiSAP Speaks PDDL

47.78. Comparing UNSOLVED MEAN curve, see large number
search nodes is, one would expect, much typical unsolved instances.
Figure 7 (d), see overall behavior state evaluations |G| largely
mirrors coverage, including discontinuity |G| = 3, 4. notable
exception fairly consistent decline SOLVED MAX |G| > 3. unclear
us reason is.
conclusion regarding issues (2) [planner performance] (3) [benchmark challenge] wish understand? issue (2), results look fairly positive.
particular, consider solved instances (weak plan found). explained above,
number state evaluations largely well-behaved. addition, heuristic function
quite fast. stated, maximum runtime 27.41 seconds. second largest runtime
2.6 seconds, third largest runtime 1.69 seconds; plans found
less 0.3 seconds. practical approach could simply apply small cut off, like
0.5 seconds, perhaps minute time critical. yields quick step (II)
follow-up similarly quick step (I) determined strong planning.
strategy leaves us are, total, 17.12% unsolved instances 2.4%
failed ones. important benchmark challenge future research? Answering
question first entails finding whether solve instances
using helpful actions pruning, not, whether solvable all.
ran FF without helpful actions pruning unsolved failed instances
Figure 7, slightly 100000 instances total. enabled unsolvability proofs
giving input BO-relevant actions, facilitated larger search spaces
increasing time/memory cut-offs 10 minutes 0.5 GB 30 minutes 1.5 GB
respectively. failed instances still failed new configuration. previously
unsolved instances, 47.43% failed, 52.52% proved unsolvable.10 0.05%
43 instances solved (the largest plan contains 140 actions). influence |G|
kind BO similar seen. number state evaluations
vastly higher before, mean max 10996.72 respectively 289484 solved
instances. heuristic extremely fast BO-relevant actions, hence
finding plan takes mean runtime 0.12 seconds. max, second max, third
max runtimes 2.94 seconds, 0.7 seconds, 0.53 seconds respectively; plans
found less 0.15 seconds. Thus, above, 6 441884 weak
plans experiment found less 0.5 seconds.
all, changing planner configuration achieves progress instances
solved default configuration, appears many unsolvable
anyway. certainly challenge research.
6.4 Blind Search
explore extent heuristic techniques actually required successfully deal
domain thus extent domain constitutes interesting benchmark
10. Unsolvability certain goal value combinations, i.e., partial assignments BOs variables, occurs
naturally since variables independent. example, unsolvable instances
required BO simultaneously satisfy BO.approval:In Approval BO.release:Released.
running example, kind situation arises, e.g., requiring CQ.approval:notChecked together
CQ.acceptance:accepted.

615

fiHoffmann, Weber & Kraft

techniques ran experiment blind search. used AO* trivial
heuristic returns 1 non-goal states 0 goal states. Since weak planning
much applicable strong planning SAM, used weak planning semantics.
provided input BO-relevant actions otherwise, blind forward search
trivially hopeless due enormous branching factor.
sake conciseness, discuss results detail here. summary,
blind search quite hopeless. runs time memory 79.36% test instances.
solves 19.04% opposed 80.48% solved based FF. Interestingly, due
FFs ability detect dead-ends via relaxed planning graphs, blind search worse
heuristic search even proving unsolvability: total, happens 5.99% cases
using FF, 1.60% cases using blind search.
said, BOs status variables and/or status values,
goals size 1 2, blind search fares well, well heuristic search. interesting
benchmarks lie outside region case 90% test instances.
6.5 Scaling Across BOs
FF scale gracefully planning tasks several BOs. selected, BO,
one solved instance m(BO) maximum number state evaluations. Since
interest, include 404 BOs, i.e., also 33 BOs whose planning
goals trivial (either unsolvable true BOs initial state already); m(BO) 1
BOs. generated 404 planning tasks COMk , 1 k 404, combining goals
m(BO) BOs number k, arbitrary ordering BOs. compared
data thus obtained data refer ACCk , obtained summing
state evaluations running FF turn individual goals m(BO).
comparison valid since BOs mutually independent, plan COMk
obtained union plans individual goals. Figure 8 shows data.
60000
COMBINED
ACCUMULATED-INDIVIDUAL
Number evaluated states

50000

40000

30000

20000

10000

0
1

100

200
Number BOs

300

400

Figure 8: Weak planning FF scaling number relevant BOs.
State evaluations plotted number BOs goal specified.
COMBINED means FF run conjunction goals (COMk
text). ACCUMULATED-INDIVIDUAL gives sum data
running FF individually single goal (ACCk text).
616

fiSAP Speaks PDDL

Figure 8 shows quite clearly, FF scale gracefully planning tasks
several BOs.11 largest instance solved k = 103, 38665 evaluations. sum
state evaluations solving 103 sub-tasks individually 529. possible explanation
that, adding goals additional BOs, actions helpful. increased
number nodes may multiply search depth. Interestingly, disproportionate
search increase occurs even new goal added trivial. example, ACC98
1 state evaluation ACC97 , COM98 COM97 difference amounts
251 state evaluations. hand, k 14 BOs, ACCk still
1000; difficulties arise k becomes quite large.

7. Application Prototypes SAP
integrated technology two BPM modeling environments. next briefly
explain transform planner output BPM format. outline
positioning prototypes SAP, illustrate business user view technology.
close words prototypes evaluated SAP-internally.
7.1 Transforming Plans Business Processes
Business users expect get process model human-readable BPM workflow format.
use BPMN (Object Management Group, 2008). BPMN process model corresponding Figure 2 depicted Figure 9. process model makes use alternative (x)
parallel (+) execution, unifies redundant sub-trees (Submit CQ . . . Archive CQ),
removes failed outcomes, highlights red nodes may outcomes.
changes obtained using following simple post-process planning.
Approval:
Necessary

Approval:

Necessary

Check CQ
Completeness

Check CQ
Consistency

Decide CQ
Approval

Submit CQ

Mark CQ
Accepted
Check CQ
Approval
Status

Create FollowUp CQ

Archive CQ

Figure 9: Final BPM process created running example.
11. vertical part plot ACCk because, noticed before, globally maximal number
state evaluations, 54386 BO 347, extreme outlier.

617

fiHoffmann, Weber & Kraft

First, remove failed node together edge leading it. running example, Figure 2, concerns N branches Check CQ Completeness
Check CQ Consistency, notGranted branch Decide CQ Approval. Next,
separate property checking directing control flow. node
1 child. replace node process step bearing
name, followed XOR split (BPMN control nodes giving choice execution).
example, concerns Check CQ Approval Status. re-unite XOR branches using
XOR joins (BPMN control nodes leading alternative executions back together), avoiding
redundancies process finding pairs nodes root identical sub-trees. Figure 2, pertains two occurrences Submit CQ. introduce new XOR join
node taking incoming edges found node pair. attach one copy common
sub-tree XOR join. insert BPMN start node, join leaves via new XOR
join, attach BPMN end node new (only) leaf plan. Finally, introduce
parallelism finding non-interacting sub-sequences actions XOR splits
joins introduced previously. (This heuristic notion parallelism,
guarantee detect possible parallelizations process.)
7.2 Positioning Prototypes SAP
part effort transfer research results SAP product development
organization, integrated planning approach two BPM prototypes.
first one, called Maestro BPMN (Born, Hoffmann, Kaczmarek, Kowalkiewicz,
Markovic, Scicluna, Weber, & Zhou, 2008, 2009), BPMN process modeling tool developed SAP Research primarily purpose research early prototyping.
focus follows prototype, implemented context
commercial SAP NetWeaver platform (SAP, 2010). NetWeaver one prominent software platforms SAP, central platform SAPs service-oriented
architecture. encompasses functionalities required run SAP application.
prototype implemented research extension SAP NetWeaver BPM.
SAP NetWeaver BPM consists different parts process modeling execution.
planning functionality integrated SAP NetWeaver BPM Process Composer,
NetWeavers BPM modeling environment targeted creation new processes.
process modeling done BPMN notation; notation given execution semantics
NetWeaver BPMs process execution engine.
7.3 Demonstration NetWeaver BPM Prototype
briefly illustrate using planning functionality look like business users.
consider application scenario (C) described Section 3.3, business user
redesigns new process scratch. application scenarios (A) (B) Section 3.3
using planning SAM-based development, respectively generating process template
beginning modeling activity interface used.
designing new process, user chooses atomic process steps according
his/her intuition. level, drawing box inserting descriptive
text. align intuitive design actual infrastructure process run
on, planner allows check atomic steps implemented based existing
618

fiSAP Speaks PDDL

Figure 10: Screenshot BPM modeling environment, showing business users specify planning goals.

transactions. Say user designed process model shown Figure 10. Amongst
others, process contains step Release Purchase Order, whose intention order
purchase special part required satisfy customer demand, customer
quote accepted. user wishes inflate Release Purchase Order
actual IT-level process fragment intended meaning. double click step
opens shown interface entering planning initial state goal, i.e., desired
status variable value changes, associated step. status variable values chosen
via drop-down menus, selecting initial conditions left-hand side goals
right-hand side. present case, goal PO.Status:Ordered, initial
condition PO.Status:Created purchase order (PO) already created
beforehand shall released.
status variable values entered, user clicks Call composer.
invokes planner, using specified initial condition/goal define SAM planning
619

fiHoffmann, Weber & Kraft

Timeout

Notification:
Quote
rejected

Notification:
Quote
accepted

Timeout

Notification:
Quote
rejected

Notification:
Quote
accepted

Process
Purchase Order
Data

Mark Customer
Quote
Rejected

Create Sales
Order
Quote
archive Quote

Release
Purchase
Order

Cancel Purchase
Order (2)

Mark Customer
Quote
Rejected

Create Sales
Order
Quote
archive Quote

Check Purchase
Order Data

Check Purchase
Order Approval
Status

Cancel Purchase
Order (2)
Trigger Followup processing

PO Approval Necessary

PO Approval
Necessary

Decide Purchase
Order Approval

End

Place Purchase
Order

Trigger Followup processing

End

Figure 11: BPMN process snippet screenshot Figure 10, (left)
(right) calling planner. affected steps highlighted bold;
actions failed outcomes highlighted red before.
task.12 returned plan transformed BPMN, inserted process model
place atomic step user working on; see illustration Figure 11.
shown case, plan process snippet containing five atomic transactions
one XOR split two possibly failed outcomes, showing releasing PO entails
first process data, check data, invoke approval process similar
illustrative example;13 finally, PO ordered.
Note that, cross-BO interactions part SAM model, planner
helps create process spans multiple BOs, indeed ties together functionality
cuts across departmental boundaries. process snippet shown Figure 10 invokes
purchase goods supplier soon customer accepts quote. relevant
companies sell highly customized goods (e.g., special-purpose ships),
12. current implementation prototype, value variable x specified initial
condition given user, planner make use x, i.e., preconditions x
assumed false x set action effect. One could course easily make
comfortable, assuming SAMs initial values default, propagating effects earlier
SAM transactions (on BO) along process structure. First investigations latter
performed (May & Weber, 2008).
13. Indeed, approval one design patterns SAP applied throughout SAM. actual pattern
complicated illustrative version here.

620

fiSAP Speaks PDDL

turn must procure customized parts suppliers (e.g., ship engines). processing
requires combine services BOs belonging Customer Relationship Management
(CRM) Supplier Relationship Management (SRM), hence two opposite
ends system (and company). designer process typically intimately
familiar one two, making especially helpful able call planner
obtain information one.
7.4 Evaluation Prototype SAP
prototype part research transfer project NetWeaver BPM group,
shaped several feedback rounds developers architects. evaluation
within SAP consisted mainly prototype demonstrations various SAP events.
example, early version tool demonstrated 2008 global meeting SAP
Research BPM SI (SI stands Semantic Integration), included participants
SAP partners development. demonstrations received positive feedback
SAP software architects. perception functionality would significantly
strengthen link SAP BPM underlying software infrastructure, making
much easier access services provided effective manner. critical comments
focused choices user interface design, non-logicians
understand meaning symbol, list several hundred BOs
long drop-down box.
customer evaluation data, foreseeable (or anyone
else) able obtain data. first prototype became available, partner
organization committed perform pilot customer evaluation. commitment
retracted context 2008/2009 financial crisis. Anyway, real customer evaluation
data may impossible come by, let alone publish, due privacy reasons.
also issues arising positioning prototype inside SAP
software architecture. NetWeaver process execution engine currently connect
actual services implement SAMs actions. SAM productive
use within Business ByDesign, NetWeaver BPM built different technology stack.
connection could principle established relatively easily all, service-orientation
intended exactly sort thing however connection yet
SAPs agenda, involves SAP-internal political issues. fact main
drivers presented technology authors paper left company
meantime course help remedy problem.

8. Related Work
basic idea explored paper using planning systems help business experts
come processes close infrastructure around quite long
time. example, mentioned decade ago Jonathan et al. (1999).
also discussed 2003 roadmap PLANET Network Excellence AI Planning
(Biundo et al., 2003). recently, Rodriguez-Moreno et al. (2007) implemented idea
SHAMASH system. SHAMASH knowledge-based BPM tool targeted helping
engineering optimization process models (Aler, Borrajo, Camacho, & SierraAlonso, 2002). tool includes, amongst things, user-friendly interfaces allowing
621

fiHoffmann, Weber & Kraft

users conveniently annotate processes rich context information, particular
form rules roughly correspond planning actions. rules (and
information) form basis translation PDDL, planning creation
new process models.
largest body related work performed last decade different
name, semantic web service composition (SWSC), context Semantic Web
Community (e.g., Ponnekanti & Fox, 2002; Narayanan & McIlraith, 2002; Srivastava, 2002;
Constantinescu, Faltings, & Binder, 2004; Agarwal et al., 2005; Sirin, Parsia, Wu, Hendler,
& Nau, 2004; Sirin et al., 2006; Meyer & Weske, 2006; Liu, Ranganathan, & Riabov, 2007).
nutshell, idea SWSC (1) annotate web services declarative
abstract explanation functionality, (2) exploit semantic annotations
automatically combine web services achieving complex functionality.
SWSC terminology differs use paper, idea basically
(although SWSC works address BPM specifically).
key distinguishing feature present work approach obtaining
planning input (the semantic annotations). first attempt address
planning/SWSC problem based SAM, generally based pre-existing
model all. Since modeling costly (Kambhampati, 2007; Rodriguez-Moreno et al.,
2007), shift focus gets us around one major open problems area.
modeling interfaces SHAMASH (Rodriguez-Moreno et al., 2007), related works
attempting support model creation (Gonzalez-Ferrer, Fernandez-Olivares, & Castillo,
2009; Cresswell, McCluskey, & West, 2009, 2010), address problem,
different ways less radical extent. Whereas works attempt ease
modeling overhead, re-use SAM actually removes overhead completely.
said that, course relations SAM planning previous work,
technical level. particular, planning SWSC literature contains multitude
works dealing actions that, like SAMs disjunctive effect actions, one
possible outcome. semantics actions, detailed already Section 4.2,
straightforward mixture two wide-spread notions planning: observation actions,
one list possible observations distinguished, non-deterministic actions,
one list possible effects occurs (e.g., Weld et al., 1998; Smith & Weld,
1999; Bonet & Geffner, 2000; Cimatti et al., 2003; Bryce & Kambhampari, 2004; Hoffmann
& Brafman, 2005; Bonet & Givan, 2006; Bryce, Kambhampati, & Smith, 2006; Bryce &
Buffet, 2008; Palacios & Geffner, 2009).
prominent line research web service composition, known Roman model
(e.g., Berardi, Calvanese, De Giacomo, Lenzerini, & Mecella, 2003, 2005; De Giacomo &
Sardina, 2007; Sardina, Patrizi, & De Giacomo, 2008; Calvanese, De Giacomo, Lenzerini,
Mecella, & Patrizi, 2008), also deals notion non-determinism component
web services, however framework different ours. web services
Roman model stateful. is, service set possible own/internal states,
service provides set operations outside world, responsible
transitions services internal state. composition task create scheduler (a
function choosing one service operation demanded) interacting component
services way implement desired goal transition system. Similarly,
web service composition techniques developed Marco Pistore co-workers (e.g.,
622

fiSAP Speaks PDDL

Pistore, Marconi, Bertoli, & Traverso, 2005; Bertoli, Pistore, & Traverso, 2006, 2010) deal
form non-determinism stateful component services formalized transition
systems. work, composition task create controller transition system
overall (controlled) behavior satisfies planning-like goal (expressed EAGLE
language, cf. below). latter aspect attempting satisfy planning goal
framework slightly closer Roman model.
main distinguishing feature formalism notion weak SAM plans,
allowing failed action outcomes proved unsolvable, least
one outcome action successful. works also proposed notions
plans guarantee achieve goal cases, notions
complex goals used achieve similar effects. briefly discuss notions
closest approach.
notions weak strong plans, discussed Section 4.2, first introduced
Cimatti, Giunchiglia, Giunchiglia, Traverso (1997) Cimatti, Roveri, Traverso
(1998b), respectively. Strong cyclic plans first introduced Cimatti, Roveri,
Traverso (1998a). notion orthogonal weak SAM plans neither implies
other. example, bad action outcome invalidates, side effect, preconditions
actions task, action may form part weak SAM plan, never
strong cyclic plan. Vice versa, strong cyclic plans general structure,
particular allowing non-deterministic actions appear execution.
Pistore Traverso (2001) generalize weak, strong, strong cyclic plans handling
goals taking form CTL formulas. However, pointed Dal Lago et al. (2002),
goals unable express plan try achieve goal, give
possible. Dal Lago et al. design goal language EAGLE addresses
(amongst others) shortcoming. EAGLE features variety goal operators
flexibly combined form goal expressions. One expression TryReach G1 Fail
G2 , G1 G2 alternative goals. intuition plan try
achieve G1 , resort G2 reaching G1 become impossible. precisely, plan
EAGLE goal optimal if, every state traverses: (1) strong plan
G1 G2 ; (2) exists strong plan G1 s, strong plan;
(3) exists weak plan G1 s, weak plan. Applying
context, say restrict plans execute non-deterministic action once.
easy see that, within space plans, every weak SAM plan optimal
EAGLE goal TryReach G Fail TRUE: weak SAM plans mark failed reaching
G impossible. However, every action tree optimal TryReach G
Fail TRUE weak SAM plan. (2) (3) force every action
least one solved outcome. tasks weak SAM plan exists,
action tree (e.g., empty tree) optimal TryReach G Fail TRUE. tasks
weak SAM plan, TryReach G Fail TRUE forces solvable action outcome provide
solution, imposes constraints failed outcomes (which may thus continued
arbitrarily complex sub-plans).
Shaparau et al. (2006) define framework similar effect context.
consider contingent planning presence linear preference order alternative
goals. Action trees plans achieve least one goal every leaf, i.e.,
strong plans disjunction goals. Plan least good plan 0 if, every
623

fiHoffmann, Weber & Kraft

state common both, best possible outcome achievable using least good
achievable using 0 . optimal least good plans. Given
this, like EAGLE goal TryReach G Fail TRUE discussed above, every weak SAM
plan optimal goal preference G, TRUE, inverse true because,
unsolvable tasks unsolvable outcomes solvable tasks, G, TRUE permits
plan anything.
Mediratta Srivastava (2006) define framework also based contingent planning,
user provides additional input number K. Then, (1) plan tree
K leaves achieving goal; (2) exist, plan
tree whose number leaves maximal. Due (1), failed nodes necessarily
unsolvable (the plan may simply stop reached K). Due (2), even task
goal cannot reached all, i.e., matter action outcomes cannot
achieve goal, plan. addition, application context sensible
way, human modeler, choose meaningful value K.
Summing up, related notions weak plans exist, none captures exactly
want SAM. algorithmic side, works listed use symbolic search (based
BDDs), thus quite different explicit-state SAM-AO* search. single
exception planner described Mediratta Srivastava (2006), based
variant A*, different plan semantics described.
Research performed also alternative methods, based planning,
automatically generating processes. example, Kuster, Ryndina, Gall (2007) describe
method computing synchronized product life-cycles set business objects,
generating process corresponding product. process serves basis
customer-specific modifications. Clearly, motivation relates ours; intended
meaning output (the generated process), input assumed generation,
quite different. input, Kuster et al.s life-cycles state machines describing
possible behaviors object, formulation corresponds space
reachable states. space generated based SAM, huge even
single BOs, mention product (cf. results blind search scaling
across BOs, Sections 6.4 6.5). Heuristic search gets us around need enumerate
states. output, Kuster et al.s generated processes guarantee
comply BO behaviors (which well), also cover them, essentially
representing could done. different plans generate,
whose intention show specifically move particular start end states.
Altogether, methods complementary. Planning computational advantages
involved objects many possible states, often case SAM.

9. Conclusion
pointed SAP built large-scale model software behavior, SAM,
whose abstraction level formalization intimately related planning models languages PDDL. shown base promising BPM application planning
fact. Getting planner input free, avoid one important obstacles
making kind planning application successful practice. solution specific
particular context treatment non-deterministic actions failed outcomes,
624

fiSAP Speaks PDDL

phenomena quite common planning web service composition,
novel approach dealing might turn relevant generally.
main open issue obtain concrete data evaluating business value
application. points are:
modification FF successfully handles many SAM instances, finding plans within
runtimes small enough apply realistic online-setting cut-offs. 15%
instances encountered still present challenges. instances could serve
interesting benchmark approaches dealing failed outcomes ways related
(cf. Section 8).
current SAM model reflect dependencies across BOs. dependencies
do, however, exist various forms. example, BOs form part data
contained another kind BO, actions one kind BO create new
instance another kind BO, actions must taken several BOs
together. ongoing activity SAP Research, aiming enriching SAM
reflect interactions, purpose informed model checking.
interactions easily modeled terms well-known planning constructs
(object creation, preconditions/effects spanning variables several BOs),
expect extended model enable us generate accurate plans.
results Section 6.5 indicate, additional planning techniques may required
improve performance case number interacting BOs becomes large.
smaller numbers (up around dozen BOs) performance current tool
still reasonable.
SAM currently provides basis automatically creating number additional
process aspects. important aspect exception handling, moment
highlight places (failed nodes) needs inserted. Another
issue data-flow. mostly easy since application data already prepackaged relevant BOs, cases, like security tokens,
covered this. open line research determine aspects could
modeled, way exploited corresponding planning algorithms.
may also interesting look methods presenting user set
alternative processes. discerning relevant alternatives, methods
require extensions SAM, like action duration, action cost, plan preferences.
general perspective, key contribution work demonstrating
potential synergy model-based software engineering planning-based process
generation. Re-using (or even all) required models, human labor required
realize planning dramatically reduced. SAMs methodology business-level descriptions individual activities within software architecture specific SAP.
Thus, exploiting synergy novel approach may turn fruitful far beyond
particular application described herein.

Acknowledgments
thank anonymous JAIR reviewers, whose comments helped lot improving
paper.
625

fiHoffmann, Weber & Kraft

work performed authors employed SAP. Part
work performed Jorg Hoffmann employed INRIA (Nancy, France),
Ingo Weber employed University New South Wales (Sydney, Australia).
NICTA funded Australian Government represented Department
Broadband, Communications Digital Economy Australian Research Council
ICT Centre Excellence program.

References
Aalst, W. (1997). Verification Workflow Nets. Application Theory Petri Nets
1997.
Agarwal, V., Chafle, G., Dasgupta, K., Karnik, N., Kumar, A., Mittal, S., & Srivastava, B.
(2005). Synthy: system end end composition web services. Journal Web
Semantics, 3 (4).
Aler, R., Borrajo, D., Camacho, D., & Sierra-Alonso, A. (2002). knowledge-based approach business process reengineering: SHAMASH. Knowledge Based Systems,
15 (8), 473483.
Bacchus, F. (2000). Subset PDDL AIPS2000 Planning Competition. AIPS-00
Planning Competition Comitee.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11 (4), 625655.
Bell, M. (2008). Service-Oriented Modeling: Service Analysis, Design, Architecture.
Wiley & Sons.
Berardi, D., Calvanese, D., De Giacomo, G., Lenzerini, M., & Mecella, M. (2003). Automatic composition e-services export behavior. Orlowska, M. E.,
Weerawarana, S., Papazoglou, M. P., & Yang, J. (Eds.), Proceedings 1st International Conference Service-Oriented Computing (ICSOC03), Vol. 2910 Lecture
Notes Computer Science, pp. 4358. Springer.
Berardi, D., Calvanese, D., De Giacomo, G., Lenzerini, M., & Mecella, M. (2005). Automatic service composition based behavioral descriptions. International Journal
Cooperative Information Systems, 14 (4), 333376.
Bertoli, P., Pistore, M., & Traverso, P. (2006). Automated web service composition
on-the-fly belief space search. Long, D., & Smith, S. (Eds.), Proceedings
16th International Conference Automated Planning Scheduling (ICAPS-06),
Ambleside, UK. AAAI.
Bertoli, P., Pistore, M., & Traverso, P. (2010). Automated composition web services via
planning asynchronous domains. Artificial Intelligence, 174 (3-4), 316361.
Biundo, S., Aylett, R., Beetz, M., Borrajo, D., Cesta, A., Grant, T., McCluskey, L., Milani,
A., & Verfaillie, G. (2003). PLANET Technological Roadmap AI Planning
Scheduling. http://planet.dfki.de/service/Resources/Roadmap/Roadmap2.pdf.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search
belief space. Chien, S., Kambhampati, R., & Knoblock, C. (Eds.), Proceedings
626

fiSAP Speaks PDDL

5th International Conference Artificial Intelligence Planning Systems (AIPS-00),
pp. 5261, Breckenridge, CO. AAAI Press, Menlo Park.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bonet, B., & Givan, B. (2006). 5th international planning competition: Non-deterministic
track call participation. Proceedings 5th International Planning Competition (IPC06).
Born, M., Hoffmann, J., Kaczmarek, T., Kowalkiewicz, M., Markovic, I., Scicluna, J., Weber,
I., & Zhou, X. (2008). Semantic annotation composition business processes
Maestro. Demonstrations ESWC08: 5th European Semantic Web Conference,
pp. 772776, Tenerife, Spain.
Born, M., Hoffmann, J., Kaczmarek, T., Kowalkiewicz, M., Markovic, I., Scicluna, J., Weber, I., & Zhou, X. (2009). Supporting execution-level business process modeling
semantic technologies. Demonstrations DASFAA09: Database Systems
Advanced Applications, pp. 759763, Brisbane, Australia.
Bryce, D., & Buffet, O. (2008). 6th international planning competition: Uncertainty part.
Proceedings 6th International Planning Competition (IPC08).
Bryce, D., & Kambhampari, S. (2004). Heuristic guidance measures conformant planning. Koenig, S., Zilberstein, S., & Koehler, J. (Eds.), Proceedings 14th
International Conference Automated Planning Scheduling (ICAPS-04), pp.
365374, Whistler, Canada. AAAI.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics belief
space search. Journal Artificial Intelligence Research, 26, 3599.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (12), 165204.
Calvanese, D., De Giacomo, G., Lenzerini, M., Mecella, M., & Patrizi, F. (2008). Automatic
service composition synthesis: roman model. IEEE Data Engineering Bulletin,
31 (3), 1822.
Cimatti, A., Giunchiglia, F., Giunchiglia, E., & Traverso, P. (1997). Planning via model
checking: decision procedure ar. Steel, S., & Alami, R. (Eds.), Recent Advances
AI Planning. 4th European Conference Planning (ECP97), Vol. 1348 Lecture
Notes Artificial Intelligence, pp. 130142, Toulouse, France. Springer-Verlag.
Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2003). Weak, strong, strong cyclic
planning via symbolic model checking. Artificial Intelligence, 147 (1-2), 3584.
Cimatti, A., Roveri, M., & Traverso, P. (1998a). Automatic obdd-based generation
universal plans non-deterministic domains. Mostow, J., & Rich, C. (Eds.),
Proceedings 15th National Conference American Association Artificial
Intelligence (AAAI-98), pp. 875881, Madison, WI, USA. MIT Press.
Cimatti, A., Roveri, M., & Traverso, P. (1998b). Strong planning non-deterministic domains via model checking. Simmons, R., Veloso, M., & Smith, S. (Eds.), Proceedings 4th International Conference Artificial Intelligence Planning Systems
(AIPS-98), pp. 3643, Pittsburgh, PA. AAAI Press, Menlo Park.
627

fiHoffmann, Weber & Kraft

Cohn, D., & Hull, R. (2009). Business artifacts: data-centric approach modeling
business operations processes. IEEE Data Engineering Bulletin, 39.
Constantinescu, I., Faltings, B., & Binder, W. (2004). Large scale, type-compatible service
composition. Jain, H., & Liu, L. (Eds.), Proceedings 2nd International
Conference Web Services (ICWS-04), pp. 506513, San Diego, California, USA.
IEEE Computer Society.
Cresswell, S., McCluskey, T., & West, M. (2010). Acquiring planning domains models using
LOCM. Knowledge Engineering Review.
Cresswell, S., McCluskey, T. L., & West, M. M. (2009). Acquisition object-centred domain
models planning examples. Gerevini, A., Howe, A. E., Cesta, A., & Refanidis,
I. (Eds.), Proceedings 19th International Conference Automated Planning
Scheduling (ICAPS-09), Sydney, Australia. AAAI.
Dal Lago, U., Pistore, M., & Traverso, P. (2002). Planning language extended
goals. Dechter, R., Kearns, M., & Sutton, R. (Eds.), Proceedings 18th National
Conference American Association Artificial Intelligence (AAAI-02), pp.
447454, Edmonton, AL, USA. MIT Press.
De Giacomo, G., & Sardina, S. (2007). Automatic synthesis new behaviors library
available behaviors. Veloso, M. (Ed.), Proceedings 20th International Joint
Conference Artificial Intelligence (IJCAI-07), pp. 18661871, Hyderabad, India.
Morgan Kaufmann.
Dumas, M., ter Hofstede, A., & van der Aalst, W. (Eds.). (2005). Process Aware Information Systems: Bridging People Software Process Technology. Wiley
Publishing.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. Journal Artificial Intelligence Research, 20, 61124.
Gazen, B. C., & Knoblock, C. (1997). Combining expressiveness UCPOP
efficiency Graphplan. Steel, S., & Alami, R. (Eds.), Recent Advances
AI Planning. 4th European Conference Planning (ECP97), Vol. 1348 Lecture
Notes Artificial Intelligence, pp. 221233, Toulouse, France. Springer-Verlag.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic
planning fifth international planning competition: PDDL3 experimental
evaluation planners. Artificial Intelligence, 173 (5-6), 619668.
Gonzalez-Ferrer, A., Fernandez-Olivares, J., & Castillo, L. (2009). JABBAH: Java application framework translation business process models HTN.
Proceedings 3rd International Competition Knowledge Engineering
Planning Scheduling, Thessaloniki, Greece.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M. (2009). Concise finite-domain representations pddl planning tasks. Artificial
Intelligence, 173 (5-6), 503535.
628

fiSAP Speaks PDDL

Hoffmann, J., & Brafman, R. (2005). Contingent planning via heuristic forward search
implicit belief states. Biundo, S., Myers, K., & Rajan, K. (Eds.), Proceedings
15th International Conference Automated Planning Scheduling (ICAPS-05),
pp. 7180, Monterey, CA, USA. AAAI.
Hoffmann, J., & Edelkamp, S. (2005). deterministic part IPC-4: overview. Journal
Artificial Intelligence Research, 24, 519579.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Jonathan, P. J., Moore, J., Stader, J., Macintosh, A., & Chung, P. (1999). Exploiting ai
technologies realise adaptive workflow systems. Proceedings ot AAAI99
Workshop Agent-Based Systems Business Context.
Kambhampati, S. (2007). Model-lite planning web age masses: challenges
planning incomplete evolving domain models. Howe, A., & Holte, R. C.
(Eds.), Proceedings 22nd National Conference American Association
Artificial Intelligence (AAAI-07), Vancouver, BC, Canada. MIT Press.
Kitchin, D. E., McCluskey, T. L., & West, M. M. (2005). B vs ocl: Comparing specification languages planning domains. Proceedings ICAPS05 Workshop
Verification Validation Model-Based Planning Scheduling Systems.
Krafzig, D., Banke, K., & Slama, D. (2005). Enterprise SOA: Service-Oriented Architecture
Best Practices. Prentice Hall.
Kuster, J. M., Ryndina, K., & Gall, H. (2007). Generation business process models
object life cycle compliance. Alonso, G., Dadam, P., & Rosemann, M. (Eds.),
Proceedings 5th International Conference Business Process Management
(BPM07), Vol. 4714 Lecture Notes Computer Science, pp. 165181. Springer.
Liu, Z., Ranganathan, A., & Riabov, A. (2007). planning approach message-oriented
semantic web service composition. Howe, A., & Holte, R. C. (Eds.), Proceedings
22nd National Conference American Association Artificial Intelligence
(AAAI-07), Vancouver, BC, Canada. MIT Press.
May, N., & Weber, I. (2008). Information gathering semantic service discovery
composition business process modeling. CIAO!08: Workshop Cooperation &
Interoperability - Architecture & Ontology CAiSE08, Vol. LNBIP 10, pp. 4660,
Montpellier, France.
McDermott, D., Ghallab, M., Howe, A., Knoblock, C., Ram, A., Veloso, M., Weld, D., &
Wilkins, D. (1998). PDDL planning domain definition language. Tech. rep.
CVC TR-98-003, Yale Center Computational Vision Control.
McDermott, D. V. (1999). Using regression-match graphs control search planning.
Artificial Intelligence, 109 (1-2), 111159.
Mediratta, A., & Srivastava, B. (2006). Applying planning composition web services
user-driven contingent planner. IBM Research Report RI 06002.
Meyer, H., & Weske, M. (2006). Automated service composition using heuristic search.
Dustdar, S., Fiadeiro, J. L., & Sheth, A. P. (Eds.), Proceedings 4th International
629

fiHoffmann, Weber & Kraft

Conference Business Process Management (BPM06), Vol. 4102 Lecture Notes
Computer Science, pp. 8196. Springer.
Narayanan, S., & McIlraith, S. (2002). Simulation, verification automated composition
web services. Iyengar, A., & Roure, D. D. (Eds.), Proceedings 11th International World Wide Web Conference (WWW-02), Honolulu, Hawaii, USA. ACM.
Nilsson, N. J. (1969). Searching problem-solving game-playing trees minimal cost
solutions. Information Processing 68 Vol. 2, pp. 15561562, Amsterdam, Netherlands.
Nilsson, N. J. (1971). Problem Solving Methods Artificial Intelligence. McGraw-Hill.
Object Management Group (2006). Object Constraint Language Specification, Version 2.
http://www.omg.org/technology/documents/formal/ocl.htm.
Object Management Group (2008).
http://www.bpmn.org/.

Business Process Modeling Notation, V1.1.

Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planning
problems bounded width. Journal Artificial Intelligence Research, 35, 623
675.
Pearl, J. (1984). Heuristics. Morgan Kaufmann.
Pednault, E. P. (1989). ADL: Exploring middle ground STRIPS situation calculus. Brachman, R., Levesque, H. J., & Reiter, R. (Eds.), Principles
Knowledge Representation Reasoning: Proceedings 1st International Conference (KR-89), pp. 324331, Toronto, ON. Morgan Kaufmann.
Pesic, M., Schonenberg, M. H., Sidorova, N., & van der Aalst, W. M. P. (2007). Constraintbased workflow models: Change made easy. Meersman, R., & Tari, Z. (Eds.), OTM
Conferences (1), Vol. 4803 Lecture Notes Computer Science, pp. 7794. Springer.
Pistore, M., Marconi, A., Bertoli, P., & Traverso, P. (2005). Automated composition web
services planning knowledge level. Kaelbling, L. (Ed.), Proceedings
19th International Joint Conference Artificial Intelligence (IJCAI-05), Edinburgh,
Scotland. Morgan Kaufmann.
Pistore, M., & Traverso, P. (2001). Planning model checking extended goals nondeterministic domains. Nebel, B. (Ed.), Proceedings 17th International Joint
Conference Artificial Intelligence (IJCAI-01), pp. 479486, Seattle, Washington,
USA. Morgan Kaufmann.
Ponnekanti, S., & Fox, A. (2002). SWORD: developer toolkit web services composition.
Iyengar, A., & Roure, D. D. (Eds.), Proceedings 11th International World
Wide Web Conference (WWW-02), Honolulu, Hawaii, USA. ACM.
Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing
planning. Gerevini, A., Howe, A. E., Cesta, A., & Refanidis, I. (Eds.), Proceedings
19th International Conference Automated Planning Scheduling (ICAPS09), Sydney, Australia. AAAI.
Rodriguez-Moreno, M. D., Borrajo, D., Cesta, A., & Oddi, A. (2007). Integrating planning
scheduling workflow domains. Expert Systems Applications, 33 (2), 389406.
630

fiSAP Speaks PDDL

SAP (2010). SAP NetWeaver.. http://www.sap.com/platform/netweaver/index.epx.
Sardina, S., Patrizi, F., & De Giacomo, G. (2008). Behavior composition presence
failure. Brewka, G., & Lang, J. (Eds.), Proceedings 11th International
Conference Principles Knowledge Representation Reasoning (KR08), pp.
640650. AAAI Press.
Schneider, S. (2001). B-Method: Introduction. Palgrave.
Shaparau, D., Pistore, M., & Traverso, P. (2006). Contingent planning goal preferences.
Gil, Y., & Mooney, R. J. (Eds.), Proceedings 21st National Conference
American Association Artificial Intelligence (AAAI-06), Boston, Massachusetts,
USA. MIT Press.
Sirin, E., Parsia, B., Wu, D., Hendler, J., & Nau, D. (2004). HTN planning web service
composition using SHOP2. Journal Web Semantics, 1 (4).
Sirin, E., Parsia, B., & Hendler, J. (2006). Template-based composition semantic web
services. AAAI Fall Symposium Agents Search.
Smith, D. E., & Weld, D. S. (1999). Temporal planning mutual exclusion reasoning.
Dean, T. (Ed.), Proceedings 16th International Joint Conference Artificial
Intelligence (IJCAI-99), pp. 326337, Stockholm, Sweden. Morgan Kaufmann.
Srivastava, B. (2002). Automatic web services composition using planning. Knowledge
Based Computer Systems (KBCS-02), pp. 467477.
Traverso, P., Ghallab, M., & Nau, D. (Eds.). (2005). Automated Planning: Theory
Practice. Morgan Kaufmann.
Turner, J., & McCluskey, T. L. (1994). Construction Formal Specifications:
Introduction Model-Based Algebraic Approaches. McGraw Hill Software
Engineering series.
van der Aalst, W. (2003). Business process management demystified: tutorial models,
systems standards workflow management. Lectures Concurrency
Petri Nets ACPN04: Advanced Courses Petri Nets, pp. 165.
van der Aalst, W. M. P., & Pesic, M. (2006). Decserflow: Towards truly declarative service
flow language. Bravetti, M., Nunez, M., & Zavattaro, G. (Eds.), WS-FM, Vol. 4184
Lecture Notes Computer Science, pp. 123. Springer.
Wainer, J., & de Lima Bezerra, F. (2003). Groupware: Design, Implementation, Use,
Vol. 2806 LNCS, chap. Constraint-based flexible workflows, pp. 151158. SpringerVerlag.
Weld, D. S., Anderson, C. R., & Smith, D. E. (1998). Extending graphplan handle
uncertainty & sensing actions. Mostow, J., & Rich, C. (Eds.), Proceedings
15th National Conference American Association Artificial Intelligence
(AAAI-98), pp. 897904, Madison, WI, USA. MIT Press.
Weske, M. (2007). Business Process Management: Concepts, Languages, Architectures.
Springer-Verlag.
631

fiHoffmann, Weber & Kraft

Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning.
Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings 17th International
Conference Automated Planning Scheduling (ICAPS-07), Providence, Rhode
Island, USA. AAAI.
Younes, H., Littman, M., Weissman, D., & Asmuth, J. (2005). first probabilistic track
international planning competition. Journal Artificial Intelligence Research,
24, 851887.

632

fiJournal Artificial Intelligence Research 44 (2012) 223-273

Submitted 11/11; published 05/12

Modeling Social Causality Responsibility Judgment
Multi-Agent Interactions
Wenji Mao

WENJI.MAO@IA.AC.CN

State Key laboratory Management Control Complex Systems
Institute Automation, Chinese Academy Sciences
No.95 Zhongguancun East Road, Beijing 100190, China

Jonathan Gratch

GRATCH@ICT.USC.EDU

Institute Creative Technologies, University Southern California
12015 Waterfront Drive, Playa Vista, CA 90094, U.S.A.

Abstract
Social causality inference entity makes social behavior entities self.
Besides physical cause effect, social causality involves reasoning epistemic states
agents coercive circumstances. Based inference, responsibility judgment
process whereby one singles individuals assign responsibility, credit blame multiagent activities. Social causality responsibility judgment key aspect social
intelligence, model facilitates design development variety multiagent interactive systems. Based psychological attribution theory, paper presents
domain-independent computational model automate social inference judgment process
according agents causal knowledge observations interaction. conduct
experimental studies empirically validate computational model. experimental results
show model predicts human judgments social attributions makes inferences
consistent people judgments. Therefore, proposed model
generically incorporated intelligent system augment social cognitive
functionality.

1. Introduction
Recent years seen explosion research intersection computing human
social behavior. Topics human-centered (Jaimes, Sebe, & Gatica-Perez, 2006), social
(Wang, Zeng, Carley, & Mao, 2007) affective computing (Picard, 1997, 2010) emphasize
role computers partners facilitators human social activity, highlight
challenge computationally understanding participating human social interactions.
Traditional artificial intelligence, emphasis individual problem solving
reasoning rational behavior, obviously suitable social, emotional, humanlike characteristics social interaction. paper, demonstrate AI reasoning
methods applied understanding, modeling predicting human social judgments,
applications human-centric social interaction.
specific challenge focus paper reasoning social causality. Social
causality refers inference entity makes social behavior entities
self. inference differs dramatically traditional artificial intelligence methods
(e.g., planning) reason physical reality. Besides physical cause effect, social

2012 AI Access Foundation. rights reserved.

fiMAO & GRATCH
causality includes reasoning mental states (e.g., actor intend cause
outcome? could foresee outcome?) social power (e.g., actor
freedom act coerced circumstances individuals?). Responsibility
judgment process whereby one forms judgment results responsibility, credit
blame based inference social causality. Social causality responsibility judgment
underlie act make sense social world around us: lead emotional
expressions praise rage; justify public applause prison terms. short, lie
heart social intelligence.
advance multi-agent interactive systems, adaptive user interfaces
applications socially interact people, increasingly important model reason
human-centric form social intelligence. Social causal reasoning facilitates multiagent planning augmenting classical planners ability reason entities
power effect changes. facilitates adaptive learning appraising praiseworthy
blameworthy behavior, reinforcing praiseworthy. modeling communicative
social behavior human-like agents, responsibility judgment helps inform models social
emotions characterizing situations evoke anger, guilt praise (Gratch, Mao, &
Marsella, 2006). people usually adept taking credit deflecting blame social
dialogue (e.g., negotiation), information helps guide natural language conversation strategies
(Martinovski, Mao, Gratch, & Marsella, 2005).
Social causal inference helps reason social cognitive states entity,
responsibility judgment helps form assessment observed social behavior entity
(either human user, computer program agent). thus facilitate various forms
interactions including human-computer, human-agent agent-agent interactions. also
facilitate human-human interaction identifying underlying cognitive process principles
human judgments. multi-agent environment, social causality responsibility judgment
help share responsibility multi-agent organization (Jennings, 1992), evaluate social power
dependence (Castelfranchi, 1990; Sichman, Conte, Demazeau, & Castelfranchi, 1994), automate
after-action review group training (Gratch & Mao, 2003; Johnson & Gonzalez, 2008),
support social simulation agent society.
primary goal develop faithful computational framework human-like
intelligent agents drive realistic behavior modeling generation (Swartout et al.,
2006). Psychological philosophical studies agree broad features people use
everyday behavioral judgment. work particularly influenced attribution theory,
body research social psychology exploring folk explanation behavior. Based
psychological attribution theory, developed general computational framework
inferring social causality forming responsibility judgment according agents causal
knowledge observations communication task execution, empirically validated
approach using human data.
rest paper organized follows. Section 2, review previous computational
work social causality, responsibility blame/credit. Section 3, introduce two
influential attributional models behavioral judgment, Weiners (1995) model responsibility
judgment Shavers (1985) model blame attribution. Based attributional models,
Section 4 presents computational framework social causality responsibility judgment.
224

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
provide computational representation, inferences algorithm proposed model,
illustrate approach using example system development. Section 5,
report empirical studies model validation. Section 6 discusses research
issues. paper concludes Section 7.

2. Related Work
Since rise cognitive science (Newell & Simon, 1972), computational methods
metaphors applied modeling understanding human behavior. Several lines
research addressed aspects social cognition, including natural language dialogue (Cassell,
Sullivan, Prevost, & Churchill, 2000; Ferguson & Allen, 2007), collaborative problem solving
(Rich, Sidner, & Lesh, 2001; Schurr, Marecki, Tambe, & Scerri, 2005), modeling emotions
(Marinier & Laird, 2004; Gratch, Marsella, & Petta, 2009), simulating human negotiation
processes (Kraus, Hoz-Weiss, Wilkenfeld, 2008; Martinovski & Mao, 2009), understanding
human social networks (Golbeck & Hendler, 2006; Wang et al., 2010). modeling human
social behavior, useful distinguish normative, descriptive legal perspectives.
Normative models attempt prescribe people assign responsibility blame/credit.
Descriptive models characterize people practice, may differ considerably
normative prescriptions. Legal models refer formalized processes society uses
responsibility assignment, seen amalgam normative practical
considerations. presenting descriptive model social causality responsibility
judgment, motivate work examining perspectives.
2.1 Normative Models
Normative (or prescriptive) models typically put forward set rational principles
universally guide decision-making. example, Bayesian decision theory proposed
optimal method deciding alternative courses actions. Game theory proposed
ideal method arriving certain social decisions, whether cooperate
another, possibly deceptive, party. game theoretic approaches model group decision
making rational way, social causality responsibility judgment model reasoning
assessment social causes consequences resulting decision making.
judgment causality, responsibility blame/credit, research normative models largely
resides moral philosophy aim identify rational principles govern
assignment social credit blame. example, Kant (1998) argued that, unlike often
observed practice, would rational assign standards responsibility regardless
valence (i.e., praiseworthy blameworthy) severity social act. Within computer
science artificial intelligence, unaware complete models based
normative principles, exception computational model proposed Chockler
Halpern (2004).
2.2 Legal Models
Legal models attempt formalize responsibility judgment inferences realized within judicial
systems, typically aim automating verifying human legal judgments.
fertile research field intersection artificial intelligence law. field
225

fiMAO & GRATCH
continuously progressing since development early legal systems TAXMAN
& TAXMAN- (McCarty & Sridharan, 1981; McCarty, 1995), HYPO (Rissland & Ashley,
1987), CABARET (Rissland & Skalak, 1991) CATO (Aleven & Ashley, 1995).
similarities judgments normative legal responsibility, researchers
suggested using legal model direct analogue normative model responsibility judgment
(e.g., Fincham & Jaspars, 1980). However, fundamental differences two
kinds responsibility judgment. Legal judgment largely depends specific circumstances.
legal reasoning systems case-based, whereas evaluating moral
responsibility identifies general theories fall within broad studies cognitive
functionalism1 (e.g., clarifying roles cause, belief intention explaining behavior).
addition case-based legal reasoning systems, researchers proposed logic-based
approaches focus general reasoning mechanism, typically defeasible inference using nonmonotonic reasoning defeasible argumentation (e.g., Hage, 1997; Prakken, 1997). main
efforts logic-based legal systems representation complex legal rules (e.g.,
contradictory, nonmonotonic priority rules), inference rules exceptions,
handling conflict rules (Prakken & Sartor, 2002). McCarty (1997) argued whether real cases,
judge would apply formal theory evaluate complex rules, thereby arrive correct results.
called intuitive version legal rules, would simple clear.
Furthermore, argue laymans judgment behavior everyday situations quite
made court. occur richer forms social interaction,
follows different set rules.
2.3 Descriptive Models
Descriptive models attempt characterize people form social judgments practice,
differ presumed normative principles legal judgments. example,
contrast Kants prescription adopt uniform principles, people use different criteria
assigning blame versus credit often form different judgments depending severity
outcome. Descriptive models also differ criteria validation. Whereas normative
models judged consistency universal principles fairness legal
models judged consistency past legal decisions, descriptive models assessed
agreement judgments people form day-to-day lives. sense,
descriptive models relevant field human-centered social computing,
goal adapt computation human norms practice, rather forcing humans adapt
prescriptive norms behavior. Research descriptive models largely resides social
psychology (Heider, 1958; Shaver, 1985; Weiner 1995, 2001, 2006) little work
within artificial intelligence attributing responsibility blame/credit human-like
fashion.
2.4 Computational Approaches
AI causality research, computational approaches developed address problem
extending causal models (Halpern & Pearl, 2001; Chockler & Halpern, 2004). Halpern
Pearl (2001) presented definition actual cause within framework structural causal
1

doctrine views theories behavior complex mental states, introduced individualized functions
roles play producing behavior explained.
226

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
models. approach extract complex causal relationships simple ones,
model capable inferring indirect causal factors including social cause. causal model (or
structural model) system equations set random variables. two finite
sets variables: exogenous (U) endogenous (V). values exogenous variables
determined factors outside model, thus corresponding equations.
endogenous variable exactly one causal equation (or structural equation) determines
value. causal model expressed causal diagram, nodes corresponding
variables, edges parents endogenous variable (indicated causal
equations) endogenous variable. Take two-man firing squad example (Pearl, 1999):
two-man firing squad; captains order, riflemen shoot simultaneously
accurately, prisoner dies.
Figure 1 illustrates causal model firing squad example, U={Uc} V={C,
R1, R2, D}. vector values exogenous variables U (called context) causal
model represents specific situation (i.e., causal world). instance, assume Uc=1 (i.e.,
captains order true) causal model below, resulting causal world describes
two-man firing squad story above. Causal inference based counterfactual dependence
contingency. Roughly speaking, B counterfactually dependent if,
happened B would happened. example, firing squad scenario,
given context captain orders, contingency rifleman-2 shoot,
prisoners death counterfactually dependent rifleman-1s shooting. rifleman-1s shooting
(R1=1) actual cause death. Similarly, rifleman-2s shooting (R2=1) actual cause
death. Besides two riflemen physically cause death, Halpern & Pearls model
find captains order (C=1) actual cause death well.
Context (Uc)

Causal equations:
Commander orders (C)

Uc = C
C = R1

Rifleman-1
shoots (R1)

Rifleman-2
shoots (R2)

C = R2
R1 R2 =

Prisoners death (D)

Figure 1: Causal Model Firing-Squad Example
Chockler Halpern (2004) extended notion causality, account degree
responsibility. provide definition degree responsibility based consideration
contingencies. Given causal model M, variable XV context , degree
responsibility formula X=x outcome measured minimal number changes
k made order make counterfactually depend X=x. X=x
actual cause , degree responsibility X=x 0; Otherwise degree
responsibility X=x 1/(k+1). counterfactually depends X=x, degree
responsibility X=x 1. example, person wins election 11-0, voter

227

fiMAO & GRATCH
votes cause victory, degree responsibility voter
victory 1/6. However, 6-5 victory, degree responsibility voter 1.
Based notion responsibility, Chockler Halpern (2004) defined degree
blame, using expected degree responsibility weighed epistemic state agent.
agents epistemic state represented pair (K, Pr), K situation form
(M, ) Pr probability distribution K. degree blame X=x relative
agents epistemic state (K, Pr) computed sum multiplying expected degree
responsibility X=x possible situation (MXx, ) agents epistemic state
probability situation. illustrate this, provide ten-man firing squad
example:
firing squad consisting ten excellent marksmen. one live bullets
rifle; rest blanks. marksmen know live
bullets. marksmen shoot prisoner dies.
Suppose agent knows exactly one marksman live bullets rifle,
marksmen shoot. agent considers 10 possible situations, depending
bullets. Let {p1, , p10} probability distribution situations, pi
agents prior probability marksman-i live bullets. Thus, according agents
epistemic state, expected degree responsibility marksman-1s shot death 1
situation bullets (and 0 situations), degree
blame marksman-1s shot death p1.
Grounded philosophical principle (i.e., counterfactual reasoning), Chockler &
Halperns extended definition responsibility accounts better multiple causes
extent cause contributes occurrence specific outcome. Another
advantage model definition degree blame takes agents epistemic
state consideration. However, consider one epistemic variable, is,
agents knowledge prior action performance. Important concepts moral responsibility,
intention freedom choice excluded definition. result,
model uses one epistemic state determinant blame assignment,
inconsistent psychological theories.
Chockler & Halperns (2004) model extension counterfactual reasoning within
structural-model framework, structural-model approach represents events
random variables causal information equations random variables,
several limitations model. instance, causal equations direct
correspondence computational systems, hard obtain practical
applications. communicative events also represented random variables model
(which propositional), difficult construct equations communicative acts
infer intermediate beliefs (e.g., beliefs desires, intentions, etc) important
social causal reasoning.

3. Attribution Theory Behavioral Judgment
contemporary psychological studies social causality responsibility judgment draw
attribution theory (Heider, 1958). 50 years research, attribution theory progressed
228

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
significantly became core area social psychology (Malle, 2001; Weiner, 2006).
Attribution research views social perceivers make sense world attributing behavior
events underlying causes. Attribution therefore refers process ascribing
cause event explaining event, well inferences judgments made. Two
influential attributional models social causality, responsibility blame (or credit)
proposed Shaver (1985) Weiner (1995), identify underlying key factors (i.e.,
attribution variables) people use behavioral judgment. summarize theories (we
adopt terminology Shavers model paper).
assessments physical causality coercion identify responsible party. Physical
causality refers connection events outcomes produce,
includes personal causality (i.e., human agency) impersonal causality (i.e., environmental
factors). human agency involved, event become relevant
investigation responsibility blame/credit. absence coercion, actor whose
action directly produces outcome regarded responsible. However, presence
coercion (as external force, powerful individual socially
sanctioned authority, limits agents freedom choice), responsibility
may deflected coercive force. example, two-man firing squad example,
captains order limit riflemens freedom avoid prisoners death, captain
take responsibility, depending degree coercion.
Intention foreseeability determine degree responsibility. Intention generally
conceived commitment work towards certain act outcome. theories view
intention major determinant degree responsibility. Foreseeability refers
agents foreknowledge actions effects. example, although riflemen
foresaw shooting gun leads prisoners death, may intend shooting
killing prisoner. However, agent intends action achieve certain outcome,
agent must foreknowledge action brings outcome. higher
degree intention, greater responsibility assigned. riflemen
intention killing prisoner, instance, assigned much less responsibility
case really intend so.
Weiner (2001) distinguished act intentionality outcome intent. agent may
intentionally perform action, may intend action effects. example,
riflemen may intentionally shoot enemy, may intend side effect exposing
enemy force. outcome intention (i.e., intended action effect), rather
act intention (i.e., intended action) key responsibility behavioral judgment.
Similar difference exists outcome coercion (i.e., coerced action effect) act coercion (i.e.,
coerced action). Furthermore, agents intentional action action effect may fail.
However, long manifests intentions, failed attempt blamed credited almost
successful one (Zimmerman, 1988).
result judgment process assignment certain blame credit
responsible party. Shavers model blame assignment follows strict sequential process.
model, first one assesses physical causality. human agency involved, judgment
process proceeds assessing key variables. Finally, perceiver takes possible
mitigating factors (i.e., justifications excuses) consideration assigns proper blame
229

fiMAO & GRATCH
responsible agent (mitigating factors modeled yet work). Weiners model
similar, relaxed sequential processing Shavers model
presumed (we follow implications Weiners model relax strict sequential feature
Shavers model). intensity blame credit determined severity positivity
outcome well degree responsibility. latter based assessed
values attribution variables.

4. Proposed Computational Model
Attribution theory identifies general process key variables people use judging social
behavior. However, process variables directly applicable computational
systems, described abstract conceptual level insufficiently precise
computational perspective. hand, current intelligent systems increasingly
sophisticated, usually involving natural language communication, multi-agent interactions, goaldirected reasoning generate execute plans, methods explicitly model beliefs, desires
intentions agents (Pollack, 1990; Grosz & Kraus, 1996; Gratch et al., 2006; Ferguson &
Allen, 2007; Swartout et al., 2010).
bridge gap conceptual descriptions theory actual components
current intelligent systems, need develop computational mechanisms automatically
convert implications conceptual descriptions functionally workable model use
intelligent systems. computational model functions inferential mechanism
derive conceptual variables theory information context available practical
systems. Ideally, computational model based data structures
representations typically used practical systems, rely little possible
additional structural representational features.
constructing computational model, follow basic dimensions Shavers model
relax strict sequential feature. follow implications Weiners model, considering
actions agents outcomes produce. adopt plan representation used
intelligent systems, especially agent-based systems. representation provides
concise description causal relationship events states. also provides clear
structure exploring alternative courses actions, recognizing intentions, assessing
coercive situations plan interventions.
take advantage artificial intelligence modeling reasoning techniques, particular,
Belief-Desire-Intention model (Bratman, 1987; Georgeff & Lansky, 1987) commonsense
reasoning (Gordon & Hobbs, 2004; Mueller, 2006). BDI concepts help us map sometimes
vague psychological terms widely accepted concepts AI agent research, research
commonsense reasoning informs design inferential mechanism generally
operates conceptual representations. use logic formal representation tool,
focusing design small number inference rules capture intuitions peoples
judgments social behavior2.
2

Note focus definition logical language, rather, aim identifying commonsense
intuitions peoples behavioral judgment come computational modeling social causality
responsibility attribution.
230

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS

Observations

Sources

Plan Execution

Causal
Knowledge

Module

Task
Execution

Inferences
Action
Sequence

Causal
Inference

Dialog Module

Social
Information

Inference
Rules

Communication

Speech Act
Sequence

Dialog
Inference

Beliefs

Algorithm

Results

Attribution
Values

Judgment
Process

Responsibility
Blame/Credit

Figure 2: Overview Computational Model
developed computational model automatically derive judgments
underlying responsibility blame attribution knowledge observations social
acts. Figure 2 illustrates overview computational model. Two sources information
contribute inference process. One source actions performed agents involved
social situation (including physical acts communicative acts). general
causal knowledge actions states world (i.e., causal knowledge), social roles
power relationship agents (i.e., social information). Causal inference derives beliefs
causal evidence. Dialog inference derives beliefs communicative evidence.
inferences make use commonsense rules generate beliefs attribution variables.
beliefs serve inputs judgment process, described algorithm. Finally,
algorithm forms overall judgment assigns proper credit blame responsible
agents.
4.1 Representations
computational representation based plan descriptions widely applied
applications architecture design intelligent systems (e.g., Georgeff & Lansky, 1987;
Veloso et al., 1995; Fischer, Mueller, & Pischel, 1996; Rao, 1996; dInverno, Kinny, Luck, &
Wooldridge, 1997; Huber, 1999; Gil, Deelman, Blythe, Kesselman, & Tangmurarunkit, 2004;
Marsella & Gratch, 2009). specifically, adopt classical STRIPS operators (Fikes &
Nilsson, 1971) hierarchical plan representation (Erol, Hendler, & Nau, 1994; Nau, Cao,
Lotem, & Muoz-Avila, 1999).
4.1.1 C AUS AL K NOWLE DGE
approach, causal knowledge encoded via hierarchical plan representation. action
set propositional preconditions effects (including conditional effects). Actions
either primitive (i.e., directly executable agents) abstract. abstract action may
decomposed multiple ways decomposition one choice executing action.
Different choices action execution alternatives other. abstract action
decomposed multiple ways, decision node (i.e., node) agent must decide
231

fiMAO & GRATCH
amongst alternatives. Otherwise, abstract action decomposed one way,
non-decision node (i.e., node) execution action realized via executing
subactions.
plan set actions achieve certain intended goal(s). plan may contain abstract
actions (i.e., abstract plan), decomposing abstract actions primitive ones abstract
plan results set primitive plans (i.e., plans composed primitive actions),
directly executable agents. Consequences outcomes (we use exchangeable)
desirable undesirable action effects (i.e., effects positive negative significance
agent). desirability action effects represented utility values (Blythe, 1999).
represent hierarchical organizational structure social agents, action plan
associated performer (i.e., agent capable performing action) agent
authority execution. used model power relationships agents.
Troop-at-aa

Support Unit 1-6
Performer: lieutenant
Authority: lieutenant


Troop-at-aa



Troop-at-aa

Send One Squad

Send Two Squads

Performer: sergeant
Authority: lieutenant

Performer: sergeant
Authority: lieutenant





One-sqd-at-aa

Remaining-at-aa

Two-sqds-at-aa


Remaining-at-aa

One Squad Forward

Remaining Forward

Two Squads Forward

Remaining Forward

Performer: squad leader
Authority: sergeant

Performer: squad leader
Authority: sergeant

Performer: squad leader
Authority: sergeant

Performer: squad leader
Authority: sergeant

1-6 Supported Unit Fractured

Fractured



Route Secured

1-6 Supported



Figure 3: Partial Plan Representation Agent Team
Figure 3 illustrates example plan representation team training system
developed (we shall discuss example Section 4.4). example, lieutenant,
sergeant squad leaders work team fulfilling task supporting sister unit (i.e.,
unit 1-6). lieutenant leader troop. Two alternative ways available support
unit 1-6, either sending one squad sending two squads. alternative performed
sergeant authorized. alternatives decomposed subsequent primitive
actions directly executable squad leaders. Action execution brings certain
effects, example, two squads forward (meaning two four squads troop leave
scene) fractures unit (meaning troop forces split weakened),
undesirable troop. (Unit) 1-6 supported (meaning sister unit reinforced
departing squads) desirable team goal.
4.1.2 C OM UNIC ATIVE E NTS
Communication agents rich source information inferring social causality.
represent communicative events sequence speech acts (Austin, 1962; Searle, 1969).
purpose, consider speech acts commonly used agent communication,
especially help infer dialogue agents desires, intentions, foreknowledge choices
acting. thus focus acts inform, request, order, accept, reject counter-propose.
232

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
4.1.3 TTR IB UTION V AR IAB LE
Attributional models employ set key variables determine social cause responsibility.
Causality refers relationship cause effect. investigation
responsibility attribution, involvement human agency required (Weiner, 1995; Shaver,
1985). approach, encode causal knowledge actions (i.e., human agency)
effects produce via plan representation.
consider act intentionality outcome intent agents. Act intention
represented using intend do, outcome intention using intend achieve,
connection act outcome intentions using intend by. use know bring
represent foreseeability. Two concepts important modeling coercion 3 . One
concept social obligation. (un)willingness. example, authorizing
agent commands another agent perform certain action, latter agent
obligation so. latter agent actually willing to, voluntary act rather
coercive one. use coerce represent act coercion coerce achieve
outcome coercion.
4.1.4 N OTATIONS
provide symbolic expressions notations used model 4.
Predicates
Let x different agents, B actions, e action effect, p q propositions,
E effect set time. adopt following predicates model:
P1.
P2.
P3.
P4.
P5.
P6.
P7.
P8.
P9.
P10.
P11.
P12.
P13.
P14.
P15.
P16.

primitive(A): primitive action.
and-node(A): action non-decision node plan structure.
or-node(A): action decision node plan structure.
alternative(A, B): actions B alternatives performing higher-level action.
do(x, A): agent x performs action A.
achieve(x, e): agent x achieves effect e.
bring-about(A, e): action brings effect e.
by(A, e): acting achieve effect e.
execute(x, A, t): agent x executes action time t.
occur(e, t): effect e occurs time t.
inform(x, y, p, t): agent x informs agent p time t.
request(x, y, p, t): agent x requests agent p time t.
order(x, y, p, t): agent x orders agent p time t.
accept(x, p, t): agent x accepts p time t.
reject(x, p, t): agent x rejects p time t.
counter-propose(x, p, q, y, t): agent x counters p proposes q agent
time t.
P17. cause(x, e, t): agent x causes effect e time t.
3

4

Coercion sometimes means physical coercion, pushing someones hand pull trigger gun.
mean psychological coercion, emphasizes impact psychological states agents.
Although represent notations first-order predicate calculus, treat semi-formal notations
model conduct theorem-proving type inference strict logical sense.
233

fiMAO & GRATCH
P18.
P19.
P20.
P21.
P22.
P23.
P24.
P25.

assist-cause(x, y, e, t): agent x assists agent achieving effect e time t.
know(x, p, t): agent x knows p time t.
want(x, p, t): agent x wants p time t.
obligation(x, p, y, t): agent x obligation p created agent time t.
intend(x, p, t): agent x intends p time t.
coerce(x, y, p, t): agent x coerces agent p time t.
superior(x, y): agent x superior agent y.
enable(x, E, t): agent x makes effect set E true time (enable(x, E, t) means agent
x disables effect set E making least one effect E false time t).
P26. can-enable(x, E, t): agent x capable making effect set E true time (can-enable(x,
E, t) means agent x disable effect set E making least one effect E false
time t).
P27. true(E, t): effect set E true time (this means every effect E true time t,
true(E, t) means least one effect E false time t).
Predicates P1P10 denote features related plan structure action execution. Predicates
P11P16 represent communicative acts. predicates used express task knowledge
observations action execution agent communication. Predicates P17P23 describe
epistemic variables (including attributions) used inferring intermediate beliefs. Predicates
P24P26 represent power relationship capabilities agents.
Functions
Let action, e action effect DT domain theory5. adopt following
functions model:
F1.
F2.
F3.
F4.
F5.
F6.
F7.
F8.
F9.
F10.
F11.
F12.
F13.
F14.
F15.

5

subaction(A): subaction set abstract action A.
choice(A): choice set performing abstract action A.
precondition(A): precondition set action A.
effect(A): (definite) effect set action A.
conditional-effect(A): conditional effect set action A.
antecedent(e): antecedent set conditional effect e.
consequent(e): consequent conditional effect e.
indefinite-effect(A): indefinite effect set action A.
relevant-action(e, DT): relevant action set achieve effect e based domain
theory DT.
relevant-effect(e, DT): relevant effect set achieve effect e based domain theory
DT.
side-effect(e, DT): side effect set achieve effect e based domain theory DT.
performer(A): performing agent(s) action A.
authority(A): authorizing agent(s) action A.
primary-responsible(e): primary responsible agent(s) effect e.
secondary-responsible(e): secondary responsible agent(s) effect e.

Domain theory general term used planning plan-based systems, specifying actions performed
domain state affairs (typically described preconditions effects) causally linked actions.
Domain theory general knowledge domain represented using given plan representation.
234

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
Among functions, F1F7 denote generic features (hierarchical) plan representation.
Functions F8F11 describe indefinite effect set, relevant action/effect side effect, functions
F12F15 represent agents involved.
4.2 Reasoning cial Causality
Social causality responsibility judgment involve evaluating outcomes events
personal significance agent. evaluation always perceiving agents
subjective perspective. perceiver uses knowledge observed agents
observation behavior infer beliefs social attributions. show automatic
methods causal dialogue reasoning provide mechanism.
4.2.1 IALOGUE NFE R E NC E
Conversation agents rich source information deriving attribution values.
Early attribution theorists (Kidd & Amabile, 1981; Hilton, 1990) pointed importance
language communication attributing behavior. Within AI research community,
much related work intentions agent communication (Cohen & Levesque, 1990; Smith
& Cohen, 1996), plan inference (Allen & Perrault, 1980; Litman & Allen, 1990), discourse
structure (Grosz & Sidner, 1986; Lochbaum, Grosz, & Sidner, 2000) speech act theory
(Perrault, 1990). Although previous research partially addressed issue inferring
intentions different formalism, focus identifying generic commonsense
reasoning rules attribution variables well interrelations social
communication.
Natural language communication seen collaborative activity
conversational agents. Successful communication requires participants follow basic
conversation principles (Grice, 1975) reach degree common ground (Clark &
Schaefer, 1987). Thus assume communication agents grounded (Traum, 1994),
conversation conforms Grices maxims Quality6 Relevance7. conversational
dialogue, participating agents exchange information alternatively. perceiving agent (who
one participating agents another agent) forms updates beliefs according
observed speech acts previous beliefs.
design commonsense rules allow perceiving agent derive beliefs
epistemic states observed agents. also take social information (i.e., social roles
relationship) consideration. example, order successfully issued
subordinates, request made agent; request performed agents
different social status may lead different belief derivations.
Hobbs (1985) proposed first-order logic notation, using eventuality8 reify events
conditions. avoid expressing higher-order properties first-order logic, formalism
adopted notation; simplification ease illustration, still keep higher6
7
8

quality maxim states one ought provide true information conversation.
relevance maxim states ones contribution conversation ought pertinent context.
Eventuality extra argument used predication referring condition exists predication
true. every predicate P(x), P true x eventuality possible situation e P
true x (called P) e really exists, i.e. (x)P(x)(e)P(e,x)Exist(e). work Hobbs (1985) provided
explanation ontological assumptions notation.
235

fiMAO & GRATCH
order expressions paper (note actually handled using Hobbs notation
approach). Also, simplify logical forms, universal quantifiers omitted rules,
substitute e do(x, A) achieve(x, e) respectively, causing
confusion.
time t1, speaker (s) informs (or tells) hearer (h) content p, t1,
inferred speaker knows proposition p long intervening
contradictory belief (Rule D1). conversations agents grounded,
inferred hearer also knows p (Rule D2). simplify expressions rules,
introduce predicate etc9 stands absence contradictory situations.
Rule D1 [inform]:
inform(s, h, p, t1) t1<t2 etc1 know(s, p, t2)
Rule D2 [inform-grounded]:
inform(s, h, p, t1) t1<t2 etc2 know(h, p, t2)
request shows speaker wants (Rule D3). order (or command) shows
speaker intends (Rule D5). order successfully issued someone higher
social status. requested ordered superior, creates social obligation hearer
perform content act (Rules D4 & D6).
Rule D3 [request]:
request(s, h, p, t1) t1<t2 etc3 want(s, p, t2)
Rule D4 [superior-request]:
request(s, h, p, t1) superior(s, h) t1<t2 etc4 obligation(h, p, s, t2)
Rule D5 [order]:
order(s, h, p, t1) t1<t2 etc5 intend(s, p, t2)
Rule D6 [order]:
order(s, h, p, t1) t1<t2 etc6 obligation(h, p, s, t2)
hearer may accept, reject counter-propose order (or request). Various inferences
made depending response hearer social relationship
speaker hearer. instance, hearer accepts, obligation
beforehand hearer willing (i.e., wants), inferred hearer intends
(Rules D7 & D8).
Rule D7 [accept]:
obligation(h, p, s, t1) accept(h, p, t2) t1<t2<t3 etc7 intend(h, p, t3)
Rule D8 [willing-accept]:
want(h, p, t1) accept(h, p, t2) t1<t2<t3 etc8 intend(h, p, t3)
clear evidence agents willingness, yet agent accepts obl igation,
evidence coercion (Rule D9). another case, agent obviously unwilling
(i.e., unintended) accepts obligation, clear evidence coercion (Rule D10).
Rule D9 [accept-obligation]:

9

similar notation used work Hobbs, Stickel, Appelt, Martin (1993). essentially means
contradictory belief between.
236

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
(t1)(t1<t3 intend(h, p, t1)) obligation(h, p, s, t2) accept(h, p, t3) t2<t3<t4 etc9
coerce(s, h, p, t4)
Rule D10 [unwilling-accept-obligation]:
intend(h, p, t1) obligation(h, p, s, t2) accept(h, p, t3) t1<t3 t2<t3<t4 etc10
coerce(s, h, p, t4)
hearer rejects, infer hearer intend (Rule D11). hearer counters
proposes B instead, speaker hearer believed know B
alternatives (Rules D12 & D13). also implies hearer wants intend (Rules
D14 & D15).
Rule D11 [reject]:
reject(h, p, t1) t1<t2 etc11 intend(h, p, t2)
Rule D12 [counter-propose]:
counter-propose(h, A, B, s, t1) t1<t2 etc12 know(h, alternative(A, B), t2)
Rule D13 [counter-propose-grounded]:
counter-propose(h, A, B, s, t1) t1<t2 etc13 know(s, alternative(A, B), t2)
Rule D14 [counter-propose]:
counter-propose(h, p, q, s, t1) t1<t2 etc14 intend(h, p, t2)
Rule D15 [counter-propose]:
counter-propose(h, p, q, s, t1) t1<t2 etc15 want(h, q, t2)
speaker known alternatives still requests (or orders) one them, infer
speaker wants (or intends) chosen action intend alternative (Rules D16 &
D17). (Here z h.)
Rule D16 [know-alternative-request]:
know(s, alternative(A, B), t1) request(s, h, do(z, A), t2) t1<t2<t3 etc16 intend(s, do(z,
B), t3)
Rule D17 [know-alternative-order]:
know(s, alternative(A, B), t1) order(s, h, A, t2) t1<t2<t3 etc17 intend(s, do(h, B), t3)
4.2.2 C AUS AL NFE R E NC E
Plan representation gives information inferring agency, intention coercion,
direct indirect cases. Causal inference plan-based evaluation based causal
information provided plan representation.
Agency. plan execution environment multiple agents inhabit, agents plans
interact various ways. preconditions agents action may established
activities agents, thus agents indirectly help cause outcome. Given
domain theory DT, observed executed actions outcome e, performer action
directly causes e causal agent (Rule C1). performers relevant actions
achieve e indirect agency (Rule C2). absence coercion, causal agent deemed
responsible e, agents assist causing e share responsibility causal
agent. (The computation relevant actions effects achieve e given Appendix A.)
Rule C1 [cause-action-effect]:
execute(x, A, t1) eeffect(A) occur(e, t2) t1<t2<t3 etc18 cause(x, e, t3)
237

fiMAO & GRATCH
Rule C2 [cause-relevant-effect]:
cause(y, e, t1) erelevant-effect(e, DT) cause(x, e, t2) t1<t2<t3 etc19 assistcause(y, x, e, t3)
Intention. Attribution intention essential peoples explanations behavior (Heider, 1958;
Malle & Knobe, 1997). discussed Section 4.2.1, intentions inferred
evidence natural language conversation. Causal inference helps infer outcome intention
evidence act intention. example, agent intends action voluntarily, agent must
intend least one action effect (Rule C3).
Rule C3 [intend-action]:
intend(x, do(z, A), t1) (y)coerce(y, x, A, t1) t1<t2 etc20 e(eeffect(A) intend(x,
e, t2))
general cases, action multiple effects, order identify whether
specific outcome intended not, perceiver may examine action alternatives agent
intends intend, compare effects intended unintended alternatives.
agent intends action voluntarily intend alternative B, infer
agent either intends (at least) one action effect occurs intend
(at least) one effect occurs B, both. effect set subset B,
effect set B subset A, simplified (Rules C4 & C5).
Rule C4 [intend-one-alternative]:
intend(x, do(z, A), t1) intend(x, do(z, B), t1) (y)coerce(y, x, A, t1) alternative(A, B)
effect(A)effect(B) t1<t2 etc21 e(eeffect(A) eeffect(B) intend(x, e, t2))
Rule C5 [intend-one-alternative]:
intend(x, do(z, A), t1) intend(x, do(z, B), t1) (y)coerce(y, x, A, t1) alternative(A, B)
effect(B)effect(A) t1<t2 etc22 e(eeffect(A) eeffect(B) intend(x, e, t2))
clear belief intention derived causal dialogue inferences,
employ intention recognition general approach detecting intentions. Given observed
executed actions agent(s) plan library, observed action sequence matches
actions primitive plan, certainly infer primitive plan pursued
agent(s). situations, however, observed action sequence partially match
specific plan. find hypothesized plan best explains observed actions, intention
recognition algorithms use probabilistic models inference. developed general
intention recognition algorithm based probabilistic plan inference (Mao, Gratch, & Li,
press). algorithm recursively uses causal information plan representation
compute best candidate plan. provide criteria determining intended actions
effects.
agent intends certain plan achieve goal plan, agent
intend actions effects relevant achieving goal plan context
(Rules C6 & C7). goal intended definition. side effects
intended agent (Rule C8). (The computation relevant actions effects well
side effects plan context given Appendix A.)
Rule C6 [intend-plan]:
intend(x, by(plan, goal), t1) Arelevant-action(goal, plan) t1<t2 etc23 intend(x, A, t2)
238

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
Rule C7 [intend-plan]:
intend(x, by(plan, goal), t1) erelevant-effect(goal, plan) t1<t2 etc24 intend(x, e, t2)
Rule C8 [intend-plan]:
intend(x, by(plan, goal), t1) eside-effect(goal, plan) t1<t2 etc25 intend(x, e, t2)
Foreknowledge. foreknowledge belongs agents epistemic state, mainly derived
dialogue inference. Speech act inform tell, gives evidence
conversants know content act. Intention recognition also helps infer agents
foreknowledge, intention entails foreknowledge: agent intends action achieve
effect e A, agent must know brings e (Rule C9).
Rule C9 [intent-foreknowledge-relation]:
intend(x, by(A, e), t1) t1<t2 etc26 know(x, bring-about(A, e), t2)
addition, agent know action would bring about, action
effects general knowledge plan representation perceiver
contradictory belief specific knowledge involved agents (Rules C10 & C11).
Rule C10 [foreknowledge-performer]:
eeffect(A) etc27 know(performer(A), bring-about(A, e), t1)
Rule C11 [foreknowledge-authority]:
eeffect(A) etc28 know(authority(A), bring-about(A, e), t1)
Coercion. causal agent could absolved responsibility coerced cause
outcome forces. applying coercive force mean outcome coercion
actually occurs. really matters whether force truly constrains causal agents
freedom avoid outcome. Causal inference helps infer outcome coercion evidence
act coercion.
agent coerced execute primitive action, agent also coerced achieve
action effects (Rule C12). coerced execute abstract action action
one decomposition (i.e., non-decision node), agent also coerced execute
subsequent actions achieve subaction effects (Rules C13 & C14).
Rule C12 [coerce-primitive]:
coerce(y, x, A, t1) primitive(A) eeffect(A) t1<t2 etc29 coerce(y, x, e, t2)
Rule C13 [coerce-non-decision-node]:
coerce(y, x, A, t1) and-node(A) Bsubaction(A) t1<t2 etc30 coerce(y, x, B, t2)
Rule C14 [coerce-non-decision-node]:
coerce(y, x, A, t1) and-node(A) eeffect(A) t1<t2 etc31 coerce(y, x, e, t2)
coerced action multiple decompositions (i.e., decision node), subsequent
actions coerced (Rule 15). Since agent options, effects appear
alternatives unavoidable (i.e., definite), thus effects coerced (Rule 16);
effects appear (but all) alternatives avoidable (i.e., indefinite),
coerced (Rule 17). (The computation definite indefinite effects given
Appendix B.)
Rule C15 [coerce-decision-node]:
coerce(y, x, A, t1) or-node(A) Bchoice(A) t1<t2 etc32 coerce(y, x, B, t2)
239

fiMAO & GRATCH
Rule C16 [coerce-decision-node]:
coerce(y, x, A, t1) or-node(A) eeffect(A) t1<t2 etc33 coerce(y, x, e, t2)
Rule C17 [coerce-decision-node]:
coerce(y, x, A, t1) or-node(A) eindefinite-effect(A) t1<t2 etc34 coerce(y, x, e,
t2)
Given conditional effect coerced, antecedents initially true, consequent also
coerced (Rule C18). Otherwise, antecedents false initially, consequent
coerced (Rule C19). antecedents established self (i.e., performer),
consequent coerced, could choose otherwise (Rule C20). agent(s)
establish antecedents, agents assist coercing consequent (Rule C21).
agent indirectly coerced (e.g., enabling/disabling action preconditions,
blocking action alternatives). among choices coerced action, one
executable alternative available coerced agent enable one alternative (i.e.,
making action preconditions true), agent coerced execute alternative (Rules
C22 & C23). available alternative enabled agent(s),
agents assist coercing alternative (Rule C24). agent(s) block action
alternatives (by disabling action preconditions), alternative left coerced
blocking agents also coercers (Rule C25).
Coercion entails intention. Handing ones wallet threat money
life may well seen intentional: one decides so, albeit unwillingly, goal
saving life.
Rule C26 [coerce-intend-relation]:
coerce(y, x, p, t1) t1<t2 etc43 intend(x, p, t2)
complete inference rules given Appendix C.
4.3 Attribution Algorithm
beliefs derived dialogue causal inferences used attribution process
form overall judgment. Different perceivers may different observations, different
knowledge preferences, thus may form different beliefs judge situation
differently. Despite individual differences, posited attribution process general,
applies uniformly different perceivers. action performed agent brings
positive negative effect, agent coerced achieve action effect,
performer action primary responsible agent. agents indirectly assist
performer secondary responsible agents. presence external coercion,
primary responsible agent redirected coercer (Note coercion may occur
one level action hierarchy, process may need trace several levels
find ultimate source responsibility). agents indirectly assist coercer
secondary responsible agents. share responsibility primary
responsible agent.
developed algorithm find responsible agent(s) specific outcome
(consequence e). First, based speech act (SA) sequence, algorithm infers
dialogue evidence (Step 1). applies causal inference rules (Step 2). executed
240

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
action potentially leads consequence, action cause outcome occurrence
performer action intends bring outcome (i.e. failed attempt) (Step 3.1),
assign performer primary responsible agent. agents assist
performer (by enabling action preconditions) secondary responsible agents (Step 3.2).
trace coercing agent(s), evaluation process starts primitive action (Step 3.3),
works action hierarchy (Step 3.4). pass main loop,
evidence outcome coercion (Step 3.4.2), authority deemed responsible (Step 3.4.3).
current action root node action hierarchy outcome coercion true,
algorithm assigns parent node current action (Step 3.4.4) evaluates next level up.
outcome intended responsible agent (Step 3.5), degree responsibility high
(Step 3.6). outcome intended (Step 3.7), degree assigned low (Step 3.8).
Otherwise, assign medium degree responsibility (Step 3.9). last, algorithm returns
primary secondary responsible agents well degrees responsibility (Step 4).
Attribution Algorithm (SA sequence S, domain theory DT, consequence e, observations):
1. Based speech act sequence S, apply dialog inference rules
2. Based DT plan representation, apply causal inference rules
3. executed action observations
3.1
cause(performer(A), e) intend(performer(A), by(A, e))
3.2
primary-responsible(e) = performer(A)
secondary-responsible(e) = performer(relevant-action(e, DT))
3.3
P=A
3.4

3.4.1
B=P
3.4.2
coerce(authority(B), performer(B), e)
3.4.3
primary-responsible(e) = authority(B)
3.4.4
P = parent node B DT
END-IF
B root action hierarchy coerce(authority(B), performer(B), e)
3.5
intend(primary-responsible(e), e)
3.6
Assign high degree responsibility
3.7
ELSE intend(primary-responsible(e), e)
3.8
Assign low degree responsibility
3.9
ELSE assign medium degree responsibility
END-IF
END-FOR
4. RETURN primary-responsible(e) secondary-responsible(e); Degrees responsibility
adopted categorical model responsibility assignment. outcome intended
responsible agent, degree responsibility high (Recall long manifests
intentions, failed attempt blamed credited almost successful one).
outcome intended responsible agent, degree responsibility low.
Otherwise, clear evidence outcome intention, assign medium degree
responsibility. intensity credit blame computed multiplying degree
responsibility utility outcome. Events may lead one
desirable/undesirable outcomes. evaluating multiple outcomes, apply algorithm
241

fiMAO & GRATCH
way, focusing one outcome time execution. Finally, form overall
judgment, results aggregated grouped responsible agents.
4.4 Illustrative Example
use example Mission Rehearsal Exercise (MRE) leadership training system
(Swartout et al., 2006) illustrate model works. MRE system, human trainee
practice decision making skills interactions virtual autonomous agents.
train students high-stake social situations, virtual agents figures
resemble humans, also make sense perceived social events exhibit
human-like social reasoning ability. training scenario opens lieutenant (played
student), lead troop soldiers fulfill peacekeeping mission. way
reinforce another unit, one troops vehicles seriously injured civilian boy.
boys mother medic accident area, crowd gathering around.
student faced dilemma whether continue mission render aid
boy. Many decisions possible, decision makes lead different outcomes
scenario unfolds. important question work good
bad outcomes occur, ensure agents make reasonable judgments react like
people social situations.
one training exercise, example, student (i.e. lieutenant) decided split forces.
ordered sergeant (acted autonomous agent) send half squads assist
another unit. sergeant informed bad consequence tried negotiate better
alternative. However, student persisted decision, finally, sergeant ordered
squad leader (Lopez) perform act. Three social actors involved example.
lieutenant acts authority sergeant. squad leader acts subordinate
sergeant. following dialogue extracted actual run system.
illustrate attribute responsibility blame based causal knowledge
observations agents.
Student:
Sergeant:
Student:
Sergeant:
Lopez:

Sergeant, send two squads forward. (Line 1)
bad idea, sir. shouldnt split forces. (Line 2) Instead
send one squad recon forward. (Line 3)
Send two squads forward. (Line 4)
recommendation, sir. (Line 5) Lopez! Send first fourth squads
Eagle 1-6s location. (Line 6)
Yes, sir. Squads! Mount up! (Line 7)

Within MRE system, conversations agents represented speech acts
dialogue history stored. Details negotiation dialogue automatically generated
natural language mapped speech acts found work Traum
colleagues (2003, 2008). dialogue corresponds following speech acts, ordered
time speakers addressed them. (The symbols lt, sgt sld stand lieutenant,
sergeant squad leader, respectively. t1<t2<<t7.)
Act 1:
Act 2:
Act 3:

order(lt, sgt, do(sgt, send-two-sqds), t1)
(Line 1)
inform(sgt, lt, bring-about(send-two-sqds, unit-fractured), t2)
(Line 2)
counter-propose(sgt, do(sgt, send-two-sqds), do(sgt, send-one-sqd), lt, t3) (Line 3)
242

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS

Act 4:
Act 5:
Act 6:
Act 7:

order(lt, sgt, do(sgt, send-two-sqds), t4)
accept(sgt, do(sgt, send-two-sqds), t5)
order(sgt, sld, do(sld, two-sqds-fwd), t6)
accept(sld, do(sld, two-sqds-fwd), t7)

(Line
(Line
(Line
(Line

4)
5)
6)
7)

Figure 3 illustrates causal knowledge troop underlying example. Take
sergeants perspective example. sergeant access partial plan knowledge
troop, perceives conversation actors task execution. observed
physical action two-squads-forward executed squad leader occurrence action
effects. Two effects salient sergeant, (unit) 1-6 supported unit fractured.
Supporting unit 1-6 desirable team goal. Assume unit fractured undesirable
sergeant assigns negative utility it. consequence serves input
algorithm.
Step 1. Based sequence 1-7 dialogue history, sergeant derive number
beliefs inferring observed speech acts (Here t1<t1<t2<t2<<t7<t7):
Belief 1:
Belief 2:
Belief 3:
Belief 4:
Belief 5:
Belief 6:
Belief 7:
Belief 8:
Belief 9:
Belief 10:
Belief 11:
Belief 12:
Belief 13:

intend(lt, do(sgt, send-two-sqds), t1)
(Act 1, Rule D5)
obligation(sgt, do(sgt, send-two-sqds), lt, t1)
(Act 1, Rule D6)
know(sgt, bring-about(send-two-sqds, unit-fractured), t2)
(Act 2, Rule D1)
know(lt, bring-about(send-two-sqds, unit-fractured), t2)
(Act 2, Rule D2)
know(sgt, alternative(send-two-sqds, send-one-sqd), t3)
(Act 3, Rule D12)
know(lt, alternative(send-two-sqds, send-one-sqd), t3)
(Act 3, Rule D13)
intend(sgt, do(sgt, send-two-sqds), t3)
(Act 3, Rule D14)
want(sgt, do(sgt, send-one-sqd), t3)
(Act 3, Rule D15)
intend(lt, do(sgt, send-one-sqd), t4)
(Act 4, Belief 6, Rule D17)
coerce(lt, sgt, do(sgt, send-two-sqds), t5)
(Act 5, Beliefs 2&7, Rule D10)
intend(sgt, do(sld, two-sqds-fwd), t6)
(Act 6, Rule D5)
obligation(sld, do(sld, two-sqds-fwd), sgt, t6)
(Act 6, Rule D6)
coerce(sgt, sld, do(sld, two-sqds-fwd), t7)
(Act 7, Belief 12, Rule D9)

Step 2. Based observations task execution beliefs obtained Step 1, causal
inference derives following beliefs sergeant (Here t0 initial time,
t0<t0<t1):
Belief 14:
Belief 15:
Belief 16:
Belief 17:
Belief 18:
Belief 19:
Belief 20:
Belief 21:

know(sld, bring-about(two-sqds-fwd, unit-fractured), t0)
(Rule C10)
know(sgt, bring-about(two-sqds-fwd, unit-fractured), t0)
(Rule C11)
intend(lt, unit-fractured, t4)
(Beliefs 1&9, Rule C5)
coerce(lt, sgt, do(sgt, two-sqds-fwd), t5)
(Belief 10, Rule C13)
coerce(lt, sgt, do(sgt, remaining-fwd), t5)
(Belief 10, Rule C13)
coerce(lt, sgt, 1-6-supported, t5)
(Belief 10, Rule C14)
coerce(lt, sgt, unit-fractured, t5)
(Belief 10, Rule C14)
coerce(sgt, sld, unit-fractured, t7)
(Belief 13, Rule C12)

Step 3. Steps 3.13.2: action two-squads-forward directly causes evaluated outcome unitfractured, action performed squad leader, initially, assign squad leader
responsible agent.

243

fiMAO & GRATCH
Step 3.4: Loop 1: algorithm starts primitive action two-squads-forward.
sergeant believes coerced squad leader fracture unit (Belief 21). sergeant
also believes squad leader foreseen outcome unit-fractured
(Beliefs 14&15). outcome coercion true, sergeant assigned responsible agent.
Since outcome coercion true current node root action hierarchy,
algorithm enters next loop.
Loop 2: action send-two-squads, performed sergeant. sergeant believes
lieutenant coerced fracture unit (Belief 20). sergeant also believes
lieutenant intended unit-fractured (Belief 16). outcome coercion true, lieutenant
assigned responsible agent. Since outcome coercion true current node root
action hierarchy, algorithm enters next loop.
Loop 3: action support-unit-1-6, performed lieutenant. relevant
dialogue act history, clear evidence coercion. current node already
root action hierarchy, algorithm exits loop.
Steps 3.53.9: sergeant believes lieutenant intended unit-fractured,
lieutenant assigned high degree responsibility outcome.

5. Evaluation
evaluate computational framework, need assess consistency model
predictions human judgments social cause, responsibility blame/credit. particular,
need evaluate consistency models inferential mechanism underlying human
attributions responsibility blame/credit is, whether model uses sources
evidence draws intermediate conclusions people do. Thus, design
experiment test model performs predicting beliefs intermediate variables
(including attribution variables epistemic variables model) evidence used
inference process. claim model predicts human judgments social
attributions makes inferences consistent people judgments.
alternative computational approaches incapable inferring beliefs intermediate
variables, directly compare predictions model human data.
5.1 Method
Participants Procedure
study consisted 48 subjects either computer science graduate students staff
University Southern California. ages range 20 35, 30 subjects
male. Among them, 12 subjects completed four scenarios survey.
subjects completed two scenarios. survey composed four small scenarios
order scenarios randomized across subjects. scenario followed
questionnaire, asking questions assessments internal variables including
characters foreknowledge, desire, intentions, obligation perceived coercions.
answering question, subjects asked mark (multiple) lines scenario
according draw answer. end questionnaire, question
asking subjects score much blame characters deserve scenario.
244

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
Materials
starting point, adopt company program scenario first used (Knobe, 2003a).
scenario received much attention recent folk psychology experimental
philosophy research (Jones, 2009). design three variants company program scenario
questionnaires following scenario. original scenario (Scenario 2), variants
(Scenarios 1, 3 4) complete questionnaires given Appendix D.
convenience assessing inference rules, descriptions scenario organized
separate labeled lines evidence (e.g., E1-E6).
Scenario 2:
E1
E2
E3
E4
E5
E6

chairman Beta Corporation discussing new program vice president
corporation.
vice president says, new program help us increase profits,
according investigation report, also harm environment.
chairman answers, want make much profit can. Start new
program!
vice president says, Ok, executes new program.
environment harmed new program.

Figure 4: Company Program Scenario 2
Experimental Design
model embodies theoretical view people judge social cause
responsibility differently based perception key variables intention,
foreknowledge coercion, good experimental design see model performs
evidence judgments systematically varied. end, take
description single social situation systematically vary it, using inference rules
model guide. example, model suggests particular evidence supports
inference coercion, obvious variation would add line scenario
encoding evidence. exploring space inference rules generating
scenarios accordingly, able incorporate information needed different inference
paths predict judgment results systematic way.
Based computational framework introduced Section 4, specific information
utilized inference process includes causal knowledge, goal identification,
observations speech acts, physical actions occurrence action effects. encode
information line scenarios. encoded information serves models
inputs provides evidence specific inference. example, Scenario 1,
following information encoded (vp chm refer vice president chairman,
respectively):
E1:
E2:
E3:
E4:
E5:
E6:

request(vp, chm, do(vp, new-program), t1)
(speech act)
inform(vp, chm, bring-about(new-program, profit-increase), t2)
(causal knowledge)
inform(vp, chm, bring-about(new-program, env-harm), t2)
(causal knowledge)
accept(chm, do(vp, new-program), t3)
(speech act)
execute(vp, new-program, t4)
(action execution)
occur(env-harm, t5)
(outcome occurrence)
245

fiMAO & GRATCH
design questions test beliefs different variables. question corresponds
firing inference rule. select assess groups dialogue causal
inference rules (D1-D17 C1-C17). rules tested virtual training system
Section 4.4. dialogue inference, design questions test speech acts inform,
request, order, accept, accept-obligation counter-propose. Know-alternative
tested virtual training scenario. causal inference, design questions test
intend-action, intend-plan, intent-foreknowledge-relation, coerce-primitive
coerce-decision-node. Intend-one-alternative, foreknowledge coerce-nondecision-node tested virtual training scenario.
Scenario 1, manipulate evidence related agents foreknowledge outcome
(i.e., foreknowledge). design questions test inference rules foreseeability
(Question 4, Rule D1), relation intent foreknowledge (Question 5, Rule C9), connection
act outcome intentions (Question 3, Rule C3), etc. Scenario 2 gives clear evidence
foreknowledge. authoritys goal also stated. Correspondingly, questions designed
test rules intentional action/effect side effect (Questions 3-4, Rules C7&C8),
foreknowledge (Question 1, Rule D2), speech acts. Scenario 3, manipulate
degree perceived coercion unwillingness introducing alternative course action
harm environment vice president prefers. Specifically, add
one line E3 E4 (and lines remain Scenario 2).
Questions designed test agents willingness (Question 2, Rules D14&D15)
perceived coercion (Questions 3-4, Rules D10&C12). Scenario 4, manipulate
characters freedom choice. introduce alternative, preference vice
president based feature unrelated environment vice president allowed
choose options. design three questions test important rules
coercion (Rules C15-C17).
Model Predictions
question questionnaire, models prediction belief belief derivation
given Appendix E.
5.2 Results
provide experimental results assessing inferred beliefs inference rules.
Question 1

Question 2

Question 3

Question 4

Question 5

Yes



Yes



Yes



Yes



Yes



0

27

3

29

1

2

28

0





0

30

0

30

0

10

20

22





9

2

28

29

1

21

9

5

25

5

25

Scenario
1

Model



People

30

Scenario
2

Model



People

30

Scenario
3

Model



People

21

Scenario
4

Model



People

21














9

Question 6
Chair

VP

30

3.00

3.73

8

5.63






N/A


5.63

3.23

4.13

5.20




N/A

N/A

Table 1: Model Predictions Subject Responses Company Program Scenarios
246

3.77

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
5.2.1 E ING NFE R R E B E LIE FS
Table 1 summarizes experimental results. Results questions 1 5 indicate total
number subjects gave particular answer. example, Scenario 1, thirty
subjects reported vice president wanted start new program. Question 6 refers
amounts blame attributed chairman vice president scale 1 (little)
6 (lots), table lists subjects average reported values. models predictions
checked table. data show questions, people agree
quite well. certain disagreements exist questions.
purpose assess models general agreement people, measure
agreement model subject using Kappa statistic. Kappa
coefficient de facto standard evaluate agreement raters, factors
expected agreement due chance (Carletta, 1996). K coefficient computed as:
K

P( A) P( E )
1 P( E )

P(A) propositional agreement among raters. P(E) expected agreement, is,
probability raters agree chance. Di Eugenio Glass (2004) argued
computation K coefficient sensitive skewed distribution categories (i.e.,
prevalence). treatment, account prevalence construct contingency tables
calculation, average results Kappa agreement models predictions
subjects answers. average Kappa agreement model subjects
0.732. Based scales given Rietveld van Hout (1993), 0.6<K<0.8 indicates
substantial agreement. empirical results show good consistency models
generation intermediate beliefs human data.
5.2.2 E ING NFE R E NC E R ULE
model, every belief derived specific inference rule, answer question
questionnaires corresponds firing one rule (with exception three questions
questionnaires designed test two rules each). condition side rule
composed set evidence, assess accuracies inference rules, compare
conditions rule evidence people use forming answer. Accuracy
rule measured using standard confusion matrix (Kohavi & Provost, 1998). every
subjects evidence choice question, build confusion matrix compute
number true positive TP (i.e., evidence rule subject use), true negative TN
(i.e., evidence rule subject ignore), false positive (i.e., evidence rule
incorrectly uses), false negative (i.e., evidence rule incorrectly ignores).
question Qi, correct selection evidence corresponding rule
respect subjects measured accuracy (AC), Ns total number subjects
Ne total number evidence Qi.
(TP( j, Qi) TN ( j, Qi ))

AC ( j, Qi )

AC (Qi )

jSubjects

Ns



jSubjects

247

Ns Ne

fiMAO & GRATCH
Table 2 lists accuracies tested rules. average accuracy rules 0.85.
empirical results show evidence model uses inference consistent
human data. Thus first experimental study generally supports first claim evaluation:
model predicts human judgments social attributions makes inferences consistent
people judgments.

Scenario 1

Scenario 2

Scenario 3

Scenario 4

Question

Inference Rule

Average Accuracy

1

D3 [Request]

0.76

2

D7 [Accept]

0.96

3

C3 [Intend-Action]

0.85

4

D1 [Inform]

0.94

5

C9 [Intent-Foreknowledge-Relation]

0.91

1

D2 [Inform-Grounded]

0.92

2

D5 [Order]

0.96

3

C7 [Intend-Plan]

0.86

4

C8 [Intend-Plan]

0.70

5

D6 & D9 [Order; Accept-Obligation]

0.84

1

D13 [Counter-Propose-Grounded]

0.94

2

D14 & D15 [Counter-Propose]

0.88

3

D6 & D10 [Order; Unwilling-Accept-Obligation]

0.80

4

C12 [Coerce-Primitive]

0.74

1

C16 [Coerce-Decision-Node]

0.71

2

C15 [Coerce-Decision-Node]

0.84

3

C17 [Coerce-Decision-Node]

0.75

Table 2: Accuracies Evidence Used Inference Rules
5.3 Discussion
Although experimental results show fairly good consistency models predictions
human data respect inferred beliefs inference rules, results also
reveal several disagreements among subjects accuracies evidence used
several inference rules relatively lower. briefly discuss experimental findings
first study.
Scenario 1, questionnaire specifically queries perceived desire, foreknowledge
intentions characters. accuracy rule tested Question 1 lower others
because, addition evidence E1, many people chose E2 well. Post-experiment interviews
subjects uncovered many subjects assumed making profits
desirable vice president (because role), therefore, want start
new program increase profits (which supported E2).
Scenarios 2 3 manipulate degree perceived coercion willingness coerced
agent. Question 4 Scenario 2, one-third subjects think chairmans intention
harm environment. Whether side effect intentional controversial philosophy,
empirical studies show similar results (Nadelhoffer, 2006). Also Question 5
Scenario 2, subjects think vice president coerced start new program
chairman, evidence weaker Scenario 3. Half referred evidence E5,
248

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
indicating expect vice president negotiate chairman rather directly
accept order.
first question Scenario 3, subjects think chairman know
alternative program, though vice president clearly states scenario.
subjects (80%) referred evidence E5, showing looked grounding information.
model infers grounded information conversation, considered
scenario design. Question 4 Scenario 3, subjects seemed reluctant infer outcome
coercion evidence act coercion. Nonetheless, still assigned high degree blame
chairman.
Scenario 4, vice president freedom choice. Question 1, subjects think
vice president coerced increase profits, reason mentioned earlier.
think vice presidents job increase profits, must willing so. accuracies
inference rules Question 1 Question 3 relatively low. model, evidence
needed inference E3, E4 E5. Many subjects ignore knowledge E3 lowers
accuracies two rules (similar reason low accuracies rules used Question 4
Scenarios 2&3).
Comparing blame assignments Scenarios 2 3, shows one hand, higher
degree coercion, less blame assigned actor result consistent
psychological findings. hand, even perceived coercion strong, people still
assign high degree blame coercer, Scenario 2. Scenario 4, people assigned
blame vice president, could done otherwise. result consistent
psychological findings (Shaver, 1985). However, people still assigned considerable blame
chairman, though vice presidents choice harm environment.
5.4 Additional Experiment
section, design additional experiment compare overall judgment results
model alternative models human data. Section 2, introduced
Chockler Halperns (2004) model (abbreviated C&H model) responsibility blame
judgments. addition C&H model, also compare model two simple models.
simple cause model always assigns responsibility blame actor whose action directly
produces outcome. approach used current intelligent systems. Instead
picking actor, slightly sophisticated model captures intuition hierarchical
structure universal characteristic human society organizations social power
always flows top organizational structure. simple authority model choose
highest authority responsible blameworthy agent. report experiment
human data overall judgments compare models predictions results
simple cause model, simple authority model C&H model.
5.4.1 E THOD
Participants Procedure
Twenty-seven subjects participated experiment. either staffs graduate
students University Southern California, ages ranging 20 45, 14
subjects female. subjects presented four similar scenarios. scenario
249

fiMAO & GRATCH
followed questionnaire, asking questions assessments physical cause,
responsibility, blame perceived coercion characters. order scenarios
randomly assigned.
Materials
took starting point firing squad scenario typically used causality research.
convenience comparing related work, used original firing squad scenario
work Chockler & Halpern (2004) (Scenario 1), designed variants (Scenarios 2, 3
4). scenario followed questionnaire. questions questionnaires
across scenarios. original scenario, variants wording questions
given Appendix F.
Experimental Design
designed variants Scenario 1 systematically vary perception key variables
intention coercion. variant, manipulate evidence perceived coercion
intentions agents. Scenario 2 extends example including authority -
commander, orders squad shoot. Scenario 3 extends example presenting
negotiation dialogue commander marksmen. marksmen first reject
commanders order. commander insists orders again. Finally marksmen accept
order shoot prisoner. Scenario 4, commander still orders, marksman
freedom choose either using blanks live bullets shooting.
Model Predictions
alternative approach represents typical way handling social causality, responsibility
blame judgment. give predictions model (abbreviated M&G model)
alternative models.
Simple cause model: simple cause model uses physical causality substitute social
causality. scenario, predicts marksman (or marksmen) bullets
responsible blameworthy agent.
Simple authority model: simple authority model judges social cause responsibility
top power hierarchy, regards highest authority responsible. assigns
responsibility blame commander Scenarios 2 4.
C&H model: marksman real cause outcome, C&H model predicts
marksmen share responsibility blame Scenario 1. similar reason, Scenarios 2
3, C&H model predicts commander marksmen responsible
blameworthy. models prediction Scenario 4 depends context (We shall discuss
later).
M&G model: Scenario 1, model predicts result C&H model,
judges commander sole responsible blameworthy agent Scenarios 2 3.
last scenario, model assigns responsibility blame marksmen bullets.
5.4.2 R E ULTS
answering questions, subjects choose responsible blameworthy agents six
categories. marksmen bullets, marksmen, commander, commander
250

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
marksmen bullets, commander marksmen, none (see Appendix E).
Figure 5 shows proportion subjects attribute blame responsibility different
categories agents, corresponding confidence intervals (=0.05) (Rice, 1994).
example, scenario 1, three subjects blame marksman live bullets rifle, 19 blame
marksmen rest blame them. analysis sample data
confidence intervals show small percentage population blame marksman
live bullets, significant majority blame marksmen, small percentage
wont blame any, 0.95 confidence.
Responsibility
Responsibility
100 90

-

80

-

70

-

60

-

50

-

40

-

30

-

20

-

10

-

bullets

marksmen

100 -

Blame

90

-

Confidence interval

80

-

70

-

60

-

50

-

40

-

30

-

20

-

10

-

Blame
Confidence interval

commander

none

bullets
& commander

Scenario 1

marksmen
& commander

Scenario 2
Responsibility

100 -

Responsibility

Blame

100 -

Blame

Confidence interval

90 -

Confidence interval

90

-

80

-

80 -

70

-

70 -

60

-

60 -

50

-

50 -

40

-

40 -

30

-

30 -

20

-

20 -

10

-

10 -

commander

bullets
& commander

marksmen
& commander

bullets

marksmen

commander

bullets
& commander

marksmen
& commander

Scenario 4

Scenario 3

Figure 5: Proportion Population Agreement Responsibility/Blame Scenarios

Blame

Simple Cause
Model

Simple Authority
Model

Results

Match

Results

Match

Scenario
1

bullets



N/A



Scenario
2

bullets



commander

yes

Scenario
3

bullets



commander

yes

Scenario
4

bullets

yes
(partial)

commander



Match

Results

Match

Human
Majority
Agreement

yes


marksmen

yes

marksmen



commander

yes

commander



commander

yes

commander



bullets

yes
(partial)

bullets/
bullets &
commander

C&H Model
Results

marksmen
commander
&
marksmen
commander
&
marksmen
context
dependent

M&G Model

Table 3: Comparison Results Different Models Human Data
Table 3 summarizes results blame assignment generated different models,
compares results dominant proportion (i.e., majority) human agreement. (In
Scenario 4, however, dominant proportion overlaps another category; case,
251

fiMAO & GRATCH
models prediction falls majority category, regard partial match). simple
cause model partially matches human agreement Scenario 4, inconsistent
data Scenarios 1 3. simple authority model matches human data Scenarios 2
3, inconsistent data scenarios. general, simple models use invariant
approaches judgment problem. Therefore, insensitive changing social
situations specified scenario. C&H model matches human judgments Scenario 1.
remaining scenarios, results show blame model match human data
well. empirical findings show model approximates human judgments
responsibility blame/credit performs better computational approaches.
5.4.3 C OM P AR



C US ION

briefly discuss model appraises scenario compare approach
C&H model.
Scenario 1. Actions plans explicitly represented approach. Scenario 1,
marksman performs primitive action, shooting. action conditional effect,
antecedent live bullets consequent death. marksmens shooting actions constitute
team plan squad firing, definite (goal) outcome death (Figure 6). shooting actions
observed executed, outcome death occurs. observed primitive actions
marksmen match team plan, certainly infer plan pursued squad10 (i.e.,
certain case intention recognition). marksmen believed intend actions
plan plan outcome (i.e. death).
Squad Firing
Performer: squad
Authority: none


Shooting

Shooting

Performer: marksman-1
Authority: none

Performer: marksman-2
Authority: none

Live Bullets

Death

Live Bullets

Death



Shooting
Performer: marksman-10
Authority: none
Live Bullets

Death

Figure 6: Team Plan Squad Scenario 1
marksman bullets sole causal agent death. marksman intends
outcome, thus deserves high degree responsibility blame. marksmen
blanks also intend actions outcome, shooting actions observed executed
antecedent conditional effect false, failed attempt detected. Therefore,
marksmen also blameworthy attempt (recall unsuccessful attempt
blamed credited almost successful one, Section 3).
C&H model judges responsibility according actual cause event.
marksman bullets cause death, marksman degree
responsibility 1 death others degree responsibility 0. result
10

Note intention recognition method generally applied plan library sequences actions.
example oversimplified.
252

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
inconsistent human data. determining blame, C&H model draws conclusion
ours, approach different. consider marksmans epistemic state
action performance (corresponding foreknowledge). 10 situations possible,
depending bullets. marksman responsible one situation (in
marksman bullets), degree responsibility 1. Given situation equally likely
happen (i.e., possibility 1/10), marksman degree blame 1/10.
notion intention model, C&H model uses foreknowledge
determinant blame assignment. fine evidence foreknowledge,
foreknowledge entails intention (Rule C9). evidence foreknowledge,
however, blame assigned high, even intention manifested case.
example, context different example, marksman fires gun mistake,
without intention causing attempting death, C&H model, marksman
blamed truly intention.
Scenarios 2&3. model, take different forms social interactions account.
inference process reasons beliefs causal dialogue evidence. Figure 7
illustrates team plan squad Scenarios 2 3, commander acts
authority squad.
Squad Firing
Performer: squad
Authority: commander


Shooting

Shooting

Performer: marksman-1
Authority: commander

Performer: marksman-2
Authority: commander

Live Bullets

Death

Live Bullets

Death



Shooting
Performer: marksman-10
Authority: commander
Live Bullets

Death

Figure 7: Team Plan Squad Scenarios 2 3
intermediate beliefs inferred Scenario 2 given below. (The symbols cmd, sqd
mkn stand commander, squad marksman bullets, respectively.
t1<t1<t2<t2.)
(1)
(2)
(3)
(4)
(5)
(6)
(7)

intend(cmd, do(sqd, squad-firing), t1)
obligation(sqd, do(sqd, squad-firing), t1)
intend(cmd, death, t1)
coerce(cmd, sqd, squad-firing, t2)
coerce(cmd, sqd, shooting, t2)
coerce(cmd, sqd, death, t2)
coerce(cmd, mkn, death, t2)

(Act order, Rule D5)
(Act order, Rule D6)
(Belief 1, Rule C3)
(Act accept & Belief 2, Rule D9)
(Belief 4, Rule C13)
(Belief 4, Rule C14)
(Belief 5, Rules C14 & C18)

Scenario 2, marksman causes death due coercion. commander
responsible death. commander intends outcome (Belief 3) severity
outcome death high, commander assigned high degree responsibility blamed
high intensity.
253

fiMAO & GRATCH
Scenario 3 includes sequence negotiation acts. derived beliefs thus change
following (t4<t4):
(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)

intend(cmd, do(sqd, squad-firing), t1)
obligation(sqd, do(sqd, squad-firing), t1)
intend(cmd, death, t1)
intend(sqd, do(sqd, squad-firing), t2)
coerce(cmd, sqd, squad-firing, t4)
coerce(cmd, sqd, shooting, t4)
coerce(cmd, sqd, death, t4)
coerce(cmd, mkn, death, t4)

(Act order, Rule D5)
(Act order, Rule D6)
(Belief 1, Rule C3)
(Act reject, Rule D11)
(Act accept & Beliefs 2&4, Rule D10)
(Belief 5, Rule C13)
(Belief 5, Rule C14)
(Belief 6, Rules C14 & C18)

Clearly marksmen intend firing (Belief 4). Scenario 3 shows evidence strong
coercion. also reflected data. greater proportion subjects regard
commander responsible blameworthy Scenario 3 Scenario 2.
Assume marksman-1 one live bullets. Using C&H approach, outcome
counterfactually dependent marksman-1s shooting, marksman-1s shooting actual
cause death. Similarly, commanders order also actual cause death. Based
responsibility definition C&H model, commander marksman-1
responsible death, degree responsibility 111. assigning blame,
ten situations altogether, situation, commander expected responsibility 1,
commander blame degree 1. marksmen degree blame 1/10. Thus
C&H model appraises commander marksmen blameworthy
outcome.
C&H model represents relevant events scenarios random variables. Thus,
want model communicative acts Scenarios 2 3 using approach, act
must represented separate variable model (or number speech acts
clumped together represented one variable). conversational dialogue involves flexible
contents orders acts, difficult come structural equations represent
relationships variables. ignore communicative acts between,
intermediate beliefs conveyed lost.
Scenario 4. Unlike previous scenarios, Scenario 4, bullets initially set
scenario starts. marksmen choose use either bullets blanks shooting.
Firing still joint action squad, team plan common goal
squad. commander orders joint action, shooting actions conditional effects
coerced. However, antecedents enabled self agent (i.e., marksmen bullets),
consequent death coerced. inferred beliefs follows.
(1)
(2)
(3)
(4)
11

intend(cmd, do(sqd, squad-firing), t1)
obligation(sqd, do(sqd, squad-firing), t1)
coerce(cmd, sqd, squad-firing, t3)
coerce(cmd, sqd, shooting, t3)

(Act order, Rule D5)
(Act order, Rule D6)
(Act accept & Belief 2, Rule D9)
(Belief 3, Rule C13)

Halpern Pearl (2005) provide refined definition causality, contingencies allowable
settings considered. refined definition, commander responsible agent death.
results blame assignment remain scenario.
254

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
(5) coerce(cmd, mkn, death, t3)

(Belief 4, Rules C14 & C20)

case, commander responsible outcome, rather, marksmen
choose use bullets cause death responsible blameworthy. Figure 5 shows
Scenario 4, peoples judgments somehow diffuse. overlap blaming
marksmen bullets blaming commander marksmen bullets.
Nonetheless, category model predicts clearly better three.
C&H model requires structural equations deterministic. essence,
model could handle alternative courses action, inherently nondeterministic
properties. One remedy push nondeterminism setting context (see
Section 2 explanation context). example, Scenario 4, could build causal
model let context determine whether bullets live blank marksman,
probability distribution contexts. that, compute probability
actual cause. However, since contexts treated background variables whose values
assigned modeler, approach could construct internal reasoning process
automate inference alternative courses actions.

6. General Discussion
Based well-founded psychological attribution theory, built general
computational model social causality responsibility judgment. model takes
different forms social interaction account considers actions agents
outcomes produce. make use commonsense reasoning infer beliefs dialogue
communication task execution. model based general representation commonly
used intelligent systems. Causal inference plan-based evaluation representation.
inferences social attributions overall judgments model shown
strong empirical support respect human data comparison alternative
approaches.
Although examples paper focused negative consequences blame
judgment, model capable credit blame judgments. Currently use uniform
model two types judgments. However, several researchers made distinction
them. DArcy (1963) pointed criteria judging benefit (i.e., credit
assignment) stricter judging harm (i.e., blame assignment). empirical
findings work Knobe (2003b) also show credit blame asymmetry peoples
judgments behavior. findings suggest us consider using asymmetry model
credit blame assignments future extension.
Subjects tended assign shared blame individuals involved. firing squad scenario 1,
example, portion subjects mentioned think marksmen actually make group
decisions together, collectively responsible outcome. Sometimes
true even individual causally connected creditworthy blameworthy event
(e.g., chairman blamed company program scenario 1). researchers work
relevant this. Norman Reed (2010) provided logic formalism account delegation
responsibility. models representational inferential mechanism potential
incorporate extensions.
255

fiMAO & GRATCH
Although attribution theory emphasizes subjective interpretation events, general theory
laymans judgment behavior. start general principles identified attribution
theory. However, also well known responsibility judgment influenced perceivers
emotional states, interpersonal goals impression management (Mele, 2001),
dispositional differences personality. People notoriously biased describing
involvement creditworthy blameworthy events (Bradley, 1978). biases reveal subjective
needs motivational influence perceiver responsibility judgment. Related work carried
lab explored influence individual difference explanation social
events modeling different explanatory styles according agents personalities (Oh, Gratch,
& Woo, 2007).
paper, focused computational modeling social causality
responsibility judgment context multi-agent interactions. produce first general
computational framework social causality responsibility judgment based
psychological attribution theory. One major contribution work identification
commonsense knowledge derivation attributions inter-agent communication
task execution. Another contribution work empirical validation model
using human data. producing model, also propose computational account
coercion design algorithm describe attribution process responsibility judgment.
interdisciplinary nature work, also takes first step toward cognitive
modeling human social intelligence helps advance understanding process
principles human social inference.
practical applications work, taken semi-formal approach
implemented model mainly production system. Previously, several
versions implementations improvements regarding work. model first
implemented within Soar architecture context virtual training environment described
earlier. virtual training system, model closely coupled system
components using blackboard representation, belief update handled using Soars
JTMS mechanism. moved general-purpose programming language implemented
inference engine Java. inference engine includes three parts: dialogue reasoner,
intention recognizer causal reasoner. implemented dialogue inference rules
causal inference rules model (Rules C22-C25 implemented). Intention
recognizer implemented separately. experimental studies based Java
inference engine.
implementation improvement efforts include extension basic model
interactive environment exploring different explanatory styles (Oh et al., 2007)
improvement basic model adding model negligence (Melissen, 2008). Tomai (2009)
took attribution variables extended basic model using qualitative
process theory. work translates attribution theorys implications blame assignment six
views impose ordinal constraints blame assignment.

7. Conclusion
social nature computing pervasive every aspect software research
development. advance computer communication technologies, social computing
256

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
intelligent system design move toward emphasizing social intelligence (Wang et al.,
2007). paper, model key aspect social intelligence, formalizing underlying
social reasoning process peoples behavioral judgment. show AI knowledge
representation reasoning methods utilized automate social inference judgment
process. also conduct human experiments empirically validate proposed model.
experimental results show models predictions beliefs intermediate variables,
inferential mechanism judgment results consistent peoples responses. Therefore,
proposed model generally applied modeling human-like social inference
behavioral judgment intelligent entities.

Acknowledgments
thank Jerry Hobbs, Paul Rosenbloom, Andrew Gordon, David Traum, Stephen Read,
Joseph Halpern, Bernard Weiner Joshua Knobe valuable discussions. work
sponsored U.S. Army Research, Development, Engineering Command
(RDECOM), content necessarily reflect position policy
Government, official endorsement inferred. work supported part
NNSFC grants #61175040, #71025001, #60921061, #70890084 #91024030.

Appendix A. Computing Relevant Actions Effects
Given domain theory DT, executed action set specific outcome e, relevant
actions achieve e contain following actions:


action causes e relevant.



actions enable precondition relevant action achieve e relevant.



e enabled consequent conditional effect A, actions establish
antecedent conditional effect relevant.



precondition relevant action enabled consequent conditional effect,
actions establish antecedent conditional effect also relevant.

preconditions relevant actions comprise relevant effects achieve e. Except
e, effects relevant actions side effects.
domain theory DT confined actions, preconditions effects specific plan
(i.e., within plan context), relevant actions effects achieve goal plan
derived based computation given above.

Appendix B. Computing Definite Indefinite Effects
Let action. abstract action one decomposition, let ai subaction
A. abstract action multiple decompositions, let ai choice A.
definite effect set denoted effect(A), indefinite effect set denoted
indefinite-effect(A).

257

fiMAO & GRATCH
definite effect set effect(A) composed action effects, occur way
decomposing primitive actions. computed recursively follows:
primitive action, effect(A) consists action effects.
effect ( ai )
abstract action one decomposition, effect ( A)

isubaction ( )
effect ( ai )
abstract action multiple decompositions, effect ( A)




aichoice ( A)

indefinite effect set indefinite-effect(A) composed action effects
occur (but all) ways decomposing primitive actions. computed
recursively follows:
primitive action, indefinite-effect(A) = .
abstract action one decomposition,



indefinite effect ( A)

indefinite effect (ai )

aisubaction ( A)

abstract action multiple decompositions,
indefinite effect ( A)



(effect (ai ) indefinite effect (ai ))

aichoice ( A)



effect (ai )

aichoice ( A)

Appendix C. Inference Rules
simplification, universal quantifies omitted. Variables x, z different agents.
Let h speaker hearer, p q propositions, t, t1, , t4 time stamps.
Let A, B C actions. Variable e state, denoting action precondition, effect,
antecedent consequent conditional effect. rules perceiving agents
perspective.
Dialogue Inference Rules
D1 [inform]:
inform(s, h, p, t1) t1<t2 etc1 know(s, p, t2)
D2 [inform-grounded]:
inform(s, h, p, t1) t1<t2 etc2 know(h, p, t2)
D3 [request]:
request(s, h, p, t1) t1<t2 etc3 want(s, p, t2)
D4 [superior-request]:
request(s, h, p, t1) superior(s, h) t1<t2 etc4 obligation(h, p, s, t2)
D5 [order]:
order(s, h, p, t1) t1<t2 etc5 intend(s, p, t2)
D6 [order]:
order(s, h, p, t1) t1<t2 etc6 obligation(h, p, s, t2)
D7 [accept]:
258

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
obligation(h, p, s, t1) accept(h, p, t2) t1<t2<t3 etc7 intend(h, p, t3)
D8 [willing-accept]:
want(h, p, t1) accept(h, p, t2) t1<t2<t3 etc8 intend(h, p, t3)
D9 [accept-obligation]:
(t1)(t1<t3 intend(h, p, t1)) obligation(h, p, s, t2) accept(h, p, t3) t2<t3<t4 etc9
coerce(s, h, p, t4)
D10 [unwilling-accept-obligation]:
intend(h, p, t1) obligation(h, p, s, t2) accept(h, p, t3) t1<t3 t2<t3<t4 etc10 coerce(s,
h, p, t4)
D11 [reject]:
reject(h, p, t1) t1<t2 etc11 intend(h, p, t2)
D12 [counter-propose]:
counter-propose(h, A, B, s, t1) t1<t2 etc12 know(h, alternative(A, B), t2)
D13 [counter-propose-grounded]:
counter-propose(h, A, B, s, t1) t1<t2 etc13 know(s, alternative(A, B), t2)
D14 [counter-propose]:
counter-propose(h, p, q, s, t1) t1<t2 etc14 intend(h, p, t2)
D15 [counter-propose]:
counter-propose(h, p, q, s, t1) t1<t2 etc15 want(h, q, t2)
D16 [know-alternative-request]:
know(s, alternative(A, B), t1) request(s, h, do(z, A), t2) t1<t2<t3 etc16 intend(s, do(z, B),
t3)
D17 [know-alternative-order]:
know(s, alternative(A, B), t1) order(s, h, A, t2) t1<t2<t3 etc17 intend(s, do(h, B), t3)
Causal Inference Rules
C1 [cause-action-effect]:
execute(x, A, t1) eeffect(A) occur(e, t2) t1<t2<t3 etc18 cause(x, e, t3)
C2 [cause-relevant-effect]:
cause(y, e, t1) erelevant-effect(e, DT) cause(x, e, t2) t1<t2<t3 etc19 assist-cause(y,
x, e, t3)
C3 [intend-action]:
intend(x, do(z, A), t1) (y)coerce(y, x, A, t1) t1<t2 etc20 e(eeffect(A) intend(x, e,
t2))
C4 [intend-one-alternative]:
intend(x, do(z, A), t1) intend(x, do(z, B), t1) (y)coerce(y, x, A, t1) alternative(A, B)
effect(A)effect(B) t1<t2 etc21 e(eeffect(A) eeffect(B) intend(x, e, t2))
C5 [intend-one-alternative]:
259

fiMAO & GRATCH
intend(x, do(z, A), t1) intend(x, do(z, B), t1) (y)coerce(y, x, A, t1) alternative(A, B)
effect(B)effect(A) t1<t2 etc22 e(eeffect(A) eeffect(B) intend(x, e, t2))
C6 [intend-plan]:
intend(x, by(plan, goal), t1) Arelevant-action(goal, plan) t1<t2 etc23 intend(x, A, t2)
C7 [intend-plan]:
intend(x, by(plan, goal), t1) erelevant-effect(goal, plan) t1<t2 etc24 intend(x, e, t2)
C8 [intend-plan]:
intend(x, by(plan, goal), t1) eside-effect(goal, plan) t1<t2 etc25 intend(x, e, t2)
C9 [intent-foreknowledge-relation]:
intend(x, by(A, e), t1) t1<t2 etc26 know(x, bring-about(A, e), t2)
C10 [foreknowledge-performer]:
eeffect(A) etc27 know(performer(A), bring-about(A, e), t)
C11 [foreknowledge-authority]:
eeffect(A) etc28 know(authority(A), bring-about(A, e), t)
C12 [coerce-primitive]:
coerce(y, x, A, t1) primitive(A) eeffect(A) t1<t2 etc29 coerce(y, x, e, t2)
C13 [coerce-non-decision-node]:
coerce(y, x, A, t1) and-node(A) Bsubaction(A) t1<t2 etc30 coerce(y, x, B, t2)
C14 [coerce-non-decision-node]:
coerce(y, x, A, t1) and-node(A) eeffect(A) t1<t2 etc31 coerce(y, x, e, t2)
C15 [coerce-decision-node]:
coerce(y, x, A, t1) or-node(A) Bchoice(A) t1<t2 etc32 coerce(y, x, B, t2)
C16 [coerce-decision-node]:
coerce(y, x, A, t1) or-node(A) eeffect(A) t1<t2 etc33 coerce(y, x, e, t2)
C17 [coerce-decision-node]:
coerce(y, x, A, t1) or-node(A) eindefinite-effect(A) t1<t2 etc34 coerce(y, x, e, t2)
C18 [coerce-conditional-effect-initial-antecedent-true]:
econditional-effect(A) true(antecedent(e), t1) coerce(y, x, e, t2) t1<t2<t3 etc35
coerce(y, x, consequent(e), t3)
C19 [coerce-conditional-effect-initial-antecedent-false]:
econditional-effect(A) true(antecedent(e), t1) coerce(y, x, e, t2) t1<t2<t3 etc36
coerce(y, x, consequent(e), t3)
C20 [coerce-conditional-effect-self-establish-antecedent]:
econditional-effect(A) coerce(y, x, e, t1) enable(x, antecedent(e), t2) t1<t2<t3 etc37
coerce(y, x, consequent(e), t3)
C21 [coerce-conditional-effect-other-establish-antecedent]:
econditional-effect(A) coerce(y, x, e, t1) enable(z, antecedent(e), t2) can-enable(x,
antecedent(e), t2) t1<t2<t3 etc38 coerce(yz, x, consequent(e), t3)
260

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
C22 [coerce-decision-node-initial-one-alternative]:
Achoice(C) true(precondition(A), t1) (Bchoice(C)BA true(precondition(B), t1)
can-enable(x, precondition(B), t1)) coerce(y, x, C, t2) t1<t2<t3 etc39 coerce(y, x, A, t3)
C23 [coerce-decision-node-self-enable-alternative]:
coerce(y, x, C, t1) Achoice(C) enable(x, precondition(A), t2) (Bchoice(C)BA
true(precondition(B), t2)can-enable(x, precondition(B), t2)) t1<t2<t3 etc40 coerce(y, x,
A, t3)
C24 [coerce-decision-node-other-enable-alternative]:
coerce(y, x, C, t1) Achoice(C) enable(z, precondition(A), t2) (Bchoice(C)BA
true(precondition(B), t2)can-enable(x, precondition(B), t2)) t1<t2<t3 etc41 coerce(yz,
x, A, t3)
C25 [coerce-decision-node-disable-other-alternative]:
coerce(y, x, C, t1) Achoice(C) true(precondition(A), t2) (Bchoice(C)BA enable(z,
precondition(B), t3)can-enable(x, precondition(B), t3)) t1<t3<t4 t2<t4 etc42
coerce(yz, x, A, t4)
C26 [coerce-intend-relation]:
coerce(y, x, p, t1) t1<t2 etc43 intend(x, p, t2)

Appendix D. Company Program Scenarios
Scenario 1:
E1
E2
E3
E4
E5
E6

vice president Beta Corporation goes chairman board requests,
start new program?
vice president continues, new program help us increase profits,
according investigation report, harm environment.
chairman answers, well.
vice president executes new program.
However, environment harmed new program.

Questions:
1. vice president want start new program?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

E4

E5

E6

2. chairman intend start new program?
answer:
confidence:

1

Yes
2

3

Low


4
High

Based information (circle apply)?

E1

261

fiMAO & GRATCH
3. chairmans intention increase profits?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

4. vice president know new program harm environment?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

5. vice presidents intention harm environment starting new program?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

6. much would blame individuals harming environment?
Blame chairman:
Blame vice president: 1

1
2

2
3

3
4

4
5

5
6

Little

6
Lots

Scenario 2:
E1
E2
E3
E4
E5
E6

chairman Beta Corporation discussing new program vice president
corporation.
vice president says, new program help us increase profits,
according investigation report, also harm environment.
chairman answers, want make much profit can. Start new
program!
vice president says, Ok, executes new program.
environment harmed new program.

Questions:
1. chairman know new program harm environment?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

E4

E5

E6

2. chairman intend start new program?
answer:
confidence:

1

Yes
2

3

Low


4
High

Based information (circle apply)?

E1

3. chairmans intention increase profits?
262

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS

answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

E4

E5

E6

4. chairmans intention harm environment?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

High

Based information (circle apply)?

E1

5. vice president coerced start new program (i.e. obligation obeying
chairman)?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

6. much would blame individuals harming environment?
Blame chairman:
Blame vice president: 1

1
2

2
3

3
4

4
5

5
6

6

Little

Lots

Scenario 3:
E1
E2
E3
E4
E5
E6
E7

chairman Beta Corporation discussing new program vice president
corporation.
vice president says, new program help us increase profits,
according investigation report, also harm environment.
Instead, run alternative program, gain us fewer profits
new program, harm environment.
chairman answers, want make much profit can. Start new
program!
vice president says, Ok, executes new program.
environment harmed new program.

Questions:
1. chairman know alternative new program?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

High

Based information (circle apply)?

E1

E2

E3

E4

E5

E6

E7

E5

E6

E7

2. program vice president willing start?
answer:
confidence:

1

New program
2
3

Low

Based information (circle apply)?

Alternative program
4
5
6
High

E1
263

E2

E3

E4

fiMAO & GRATCH
3. vice president coerced start new program?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

High

Based information (circle apply)?

E1

E2

E3

E4

E5

E6

E7

E4

E5

E6

E7

4. vice president coerced harm environment?
answer:
confidence:

1

Yes
2

3

Low


4

5

6

High

Based information (circle apply)?

E1

E2

E3

5. much would blame individuals harming environment?
Blame chairman:
Blame vice president: 1

1
2

2
3

3
4

4
5

5
6

Little

6
Lots

Scenario 4:
E1
E2
E3
E4
E5
E6

chairman Beta Corporation discussing new program vice president
corporation.
vice president says, two ways run new program, simple way
complex way.
equally help us increase profits, according investigation report,
simple way also harm environment.
chairman answers, want make much profit can. Start new
program either way!
vice president says, Ok, chooses simple way execute new program.
environment harmed.

Questions:
1. vice president coerced chairman increase profits?
answer:
confidence:

Yes
1

2


3

Low

4

5

6

E2

E3

High

Based information (circle apply)?

E1

E4

E5

E6

E5

E6

E5

E6

2. vice president coerced chairman choose simple way?
answer:
confidence:

Yes
1

2


3

Low

4

5

6

High

Based information (circle apply)?

E1

E2

E3

E4

3. vice president coerced chairman harm environment?
answer:
confidence:

Yes
1

2


3

Low

Based information (circle apply)?

4

5

6

E2

E3

High

E1
264

E4

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
4. much would blame individuals harming environment?
Blame chairman:
Blame vice president: 1

1
2

2
3

3
4

4
5

5
6

Little

6
Lots

Appendix E. Belief Derivation Company Program Scenarios
symbols chm vp refer chairman vice president, respectively. Time stamps
t1<t1<t2<t2<<t4<t5. severity outcome environmental harm set medium.
Scenario 1
Information Encoding:
E1
E2
E3
E4
E5
E6

request(vp, chm, do(vp, new-program), t1)
inform(vp, chm, bring-about(new-program, profit-increase), t2)
inform(vp, chm, bring-about(new-program, env-harm), t2)
accept(chm, do(vp, new-program), t3)
execute(vp, new-program, t4)
env-harmeffect(new-program); occur(env-harm, t5)

Question 1 (Rule D3 [request]):
request(vp, chm, do(vp, new-program), t1)
want(vp, do(vp, new-program), t1)
Question 2 (Rule D7 [accept]):
accept(chm, do(vp, new-program), t3)
intend(chm, do(vp, new-program), t3)
Question 3 (Rule C3 [intend-action]):
intend(chm, do(vp, new-program), t3) coerce(vp, chm, new-program, t3)
profit-increaseeffect(new-program) intend(chm, profit-increase, t3)
Question 4 (Rule D1 [inform]):
inform(vp, chm, bring-about(new-program, env-harm), t2)
know(vp, bring-about(new-program, env-harm), t2)
know(vp, bring-about(new-program, env-harm), t2)
Question 5 (Rule C9 [intent-foreknowledge-relation]):
know(vp, bring-about(new-program, env-harm), t2)
intend(vp, by(new-program, env-harm), t2)
Question 6 (Attribution Algorithm):
Primary-responsible agent: vp
Degree responsibility/Intensity blame: low
Scenario 2
Information Encoding:
E2

inform(vp, chm, bring-about(new-program, profit-increase), t1)
265

fiMAO & GRATCH
E3
E4
E5
E6

inform(vp, chm, bring-about( new-program, env-harm), t1)
goal(chm, profit-increase); order(chm, vp, do(vp, new-program), t2)
accept(vp, do(vp, new-program), t3); execute(vp, new-program, t3)
occur(env-harm, t4)

Question 1 (Rule D2 [inform-grounded]):
inform(vp, chm, bring-about( new-program, env-harm), t1)
know(chm, bring-about( new-program, env-harm), t1)
Question 2 (Rule D5 [order]):
order(chm, vp, do(vp, new-program), t2)
intend(chm, do(vp, new-program), t2)
Question 3 (Rule C7 [intend-plan]):
intend(chm, by(new-program, profit-increase), t2) profit-increaserelevant-effect(profitincrease, new-program)
intend(chm, profit-increase, t2)
Question 4 (Rule C8 [intend-plan]):
intend(chm, by(new-program, profit-increase), t2) env-harmside-effect(profit-increase,
new-program)
intend(chm, env-harm, t2)
Question 5 (Rules D6 [order] & D9 [accept-obligation]):
order(chm, vp, do(vp, new-program), t2)
obligation(vp, do(vp, new-program), chm, t2)
obligation(vp, do(vp, new-program), chm, t2) accept(vp, do(vp, new-program), t3)
coerce(chm, vp, do(vp, new-program), t3)
Question 6 (Attribution Algorithm):
Primary-responsible agent: chm
Degree responsibility/Intensity blame: low
Scenario 3
Information Encoding:
E2
E3
E4
E5
E6
E7

inform(vp, chm, bring-about(new-program, profit-increase), t1)
inform(vp, chm, bring-about( new-program, env-harm), t1)
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
goal(chm, profit-increase); order(chm, vp, do(vp, new-program), t2)
accept(vp, do(vp, new-program), t3); execute(vp, new-program, t3)
occur(env-harm, t4)

Question 1 (Rule D13 [counter-propose-grounded]):
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
know(chm, alternative(new-program, alternative-program), t1)
Question 2 (Rules D14 & D15 [counter-propose]):
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
intend(vp, do(vp, new-program), t1)
266

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
counter-propose(vp, do(vp, new-program), do(vp, alternative-program), chm, t1)
want(vp, do(vp, alternative-program), t1)
Question 3 (Rules D6 [order] & D10 [unwilling-accept-obligation]):
order(chm, vp, do(vp, new-program), t2)
obligation(vp, do(vp, new-program), chm, t2)
intend(vp, do(vp, new-program), t1) obligation(vp, do(vp, new-program), chm, t2)
accept(vp, do(vp, new-program), t3)
coerce(chm, vp, do(vp, new-program), t3)
Question 4 (Rule C12 [coerce-primitive]):
coerce(chm, vp, do(vp, new-program), t3) primitive(new-program) env-harmeffect(newprogram)
coerce(chm, vp, env-harm, t3)
Question 5 (Attribution Algorithm):
Primary-responsible agent: chm
Degree responsibility/Intensity blame: low
Scenario 4
Information Encoding:
E2

E3

E4
E5

E6

inform(vp, chm, or-node(new-program), t1)
inform(vp, chm, simple-waychoice(new-program), t1)
inform(vp, chm, complex-waychoice(new-program,), t1)
inform(vp, chm, bring-about(simple-way, profit-increase), t1)
inform(vp, chm, bring-about(complex-way, profit-increase), t1)
inform(vp, chm, bring-about(simple-way, env-harm), t1)
goal(chm, profit-increase); order(chm, vp, do(vp, new-program), t2)
accept(vp, do(vp, new-program), t3); intend(vp, simple-way, t3); intend(vp, complex-way,
t3);
execute(vp, simple-way, t4)
occur(env-harm, t5)

Question 1 (Rule C16 [coerce-decision-node]):
order(chm, vp, do(vp, new-program), t2)
obligation(vp, do(vp, new-program), chm, t2)
obligation(vp, do(vp, new-program), chm, t2) accept(vp, do(vp, new-program), t3)
coerce(chm, vp, do(vp, new-program), t3)
coerce(chm, vp, do(vp, new-program), t3) or-node(new-program) profit-increaseeffect(newprogram)
coerce(chm, vp, profit-increase, t3)
Question 2 (Rule C15 [coerce-decision-node]):
coerce(chm, vp, do(vp, new-program), t3) or-node(new-program) simple-waychoice(newprogram)
coerce(chm, vp, simple-way, t3)
Question 3 (Rule C17 [coerce-decision-node]):
267

fiMAO & GRATCH
coerce(chm, vp, do(vp, new-program), t3) or-node(new-program) env-harmindefiniteeffect(new-program)
coerce(chm, vp, env-harm, t3)
Question 4 (Attribution Algorithm):
Primary-responsible agent: vp
Degree responsibility/Intensity blame: high

Appendix F. Firing Squad Scenarios
Scenario 1
Suppose firing squad consisting ten excellent marksmen. one
live bullets rifle; rest blanks. marksmen know
live bullets. marksmen shoot prisoner dies.
Scenario 2
Suppose firing squad consisting commanding officer ten excellent
marksmen generally abide leaders commands. one live bullets
rifle; rest blanks. commanding officer marksmen know
marksman live bullets. commander orders marksmen shoot prisoner.
marksmen shoot prisoner dies.
Scenario 3
Suppose firing squad consisting commanding officer ten excellent
marksmen generally abide leaders commands. one live bullets
rifle; rest blanks. commanding officer marksmen know
marksman live bullets. commander orders marksmen shoot prisoner.
marksmen refuse order. commander insists marksmen shoot prisoner.
marksmen shoot prisoner dies.
Scenario 4
Suppose firing squad consisting commanding officer ten excellent
marksmen generally abide leaders commands. commanding officer orders
marksman shoot prisoner, marksman choose use either blanks live
bullets. commander marksmen know whether marksmen live
bullets. tradition, prisoner lives (i.e., everyone chooses blanks), set free.
marksmen shoot prisoner dies.
Questions (in Scenario 1, Questions 1-3 contain selections b):
1.

physically caused death?
a) marksmen live bullets rifles
b) marksmen firing squad
c) commanding officer
d) a) c)
268

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
e)
f)

everybody
none

2.

would think responsible death?
a) marksmen live bullets rifles
b) marksmen firing squad
c) commanding officer
d) a) c)
e) everybody
f) none

3.

deserves blame death?
a) marksmen live bullets rifles
b) marksmen firing squad
c) commanding officer
d) a) c)
e) everybody
f) none

4.

making judgment, feel marksmen coerced?
a) strong coercion
b) weak coercion
c) coercion

References
Aleven, V., & Ashley, K. D. (1995). Things Factors. Proceedings Fifth International
Conference Artificial Intelligence Law.
Allen, J. F., & Perrault, C. R. (1980). Analyzing Intention Utterances. Artificial Intelligence, 15(3):143178.
Austin, J. (1962). Things Words. Harvard University Press.
Blythe, J. (1999). Decision-Theoretic Planning. AI Magazine, 20(2):37-54.
Bradley, G. W. (1978). Self-Serving Biases Attribution Process: Reexamination Fact
Fiction Question. Journal Personality Social Psychology, 36(1):56-71.
Bratman, M. E. (1987). Intention, Plans, Practical Reason. Harvard University Press.
Carletta, J. (1996). Assessing Agreement Classification Tasks: Kappa Statistic. Computational
Intelligence, 22(2):249-254.
Cassell, J., Sullivan, J., Prevost, S., & Churchill, E. (Eds.) (2000). Embodied Conversational Agents.
Cambridge University Press.
Castelfranchi, C. (1990). Social Power. Proceedings First European Workshop Modeling
Autonomous Agents Multi-Agent World.
Chockler, H., & Halpern, J. Y. (2004). Responsibility Blame: Structural-Model Approach. Journal
Artificial Intelligence Research, 22:93-115.
Clark, H. H., & Schaefer, E. F. (1987). Collaborating Contributions Conversation. Language
Cognitive Processes, 2:1-23,.

269

fiMAO & GRATCH
Cohen, P. R., & Levesque, H. J. (1990). Intention Choice Commitment. Artificial Intelligence, 42(23):213-261.
DArcy, E. (1963). Human Acts: Essay Moral Evaluation. Oxford: Clarendon.
Di Eugenio, B., & Glass, M. (2004). Kappa Statistic: second Look. Computational Linguistics,
30(1):95-101.
dInverno, M., Kinny, D., Luck, M., & Wooldridge, M. (1997). Formal Specification dMARS. In: M.
P. Singh, A. Rao M. J. Wooldridge (Eds.). Intelligent Agents IV, pp. 155-176. Springer-Verlag.
Erol, K., Hendler, J., & Nau, D. S. (1994). UMCP: Sound Complete Procedure Hierarchical
Task-Network Planning. Proceedings Second International Conference Artificial Intelligence
Planning Systems.
Ferguson, G., & Allen, J. (2007). Mixed-Initiative Dialogue Systems Collaborative Problem-Solving. AI
Magazine, 28(2):23-32.
Fikes, R.E., & Nilsson, N. J. (1971). STRIPS: New Approach Application Theorem Proving
Problem Solving. Artificial Intelligence, 2(3-4).
Fincham, F. D., & Jaspars, J. M. (1980). Attribution Responsibility: Man Scientist Man
Lawyer. In: L. Berkowitz (Ed.). Advances Experimental Social Psychology (Vol. 13), pp. 81-138.
Academic Press.
Fischer, K., Mueller, J. P., & Pischel, M. (1996). Pragmatic BDI Architecture. In: M. Wooldridge, J. P.
Mueller M. Tambe (Eds.). Intelligent Agents II, pp. 203-218. Springer-Verlag.
Georgeff, M. P., & Lansky, A. L. (1987). Reactive Reasoning Planning. Proceedings Sixth
National Conference Artificial Intelligence.
Gil, Y., Deelman, E., Blythe, J., Kesselman, C., & Tangmurarunkit, H. (2004). Artificial Intelligence
Grids: Workflow Planning Beyond. IEEE Intelligent Systems, 19(1):26-33.
Golbeck, J., & Hendler, J. (2006). Inferring Binary Trust Relationships Web-Based Social Networks,
ACM Transactions Internet Technology, 6(4):497-529.
Gordon, A., & Hobbs, J. R. (2004). Formalizations Commonsense Psychology. AI Magazine, 25(4):4962.
Gratch, J., & Mao, W. (2003). Automating Action Review: Attributing Blame Credit Team
Training. Proceedings Twelfth Conference Behavior Representation Modeling
Simulation.
Gratch, J., Mao, W., & Marsella, S. (2006). Modeling Social Emotions Social Attributions. In: R. Sun
(Ed.). Cognition Multi-Agent Interaction, pp. 219-251. Cambridge University Press.
Gratch, J., Marsella, S., & Petta, P. (2009). Modeling Antecedents Consequences Emotion.
Journal Cognitive Systems Research, 10(1):1-5.
Grice, H. P. (1975). Logic Conversation. In: P. Cole J. Morgan (Eds.). Syntax Semantics: Vol
3, Speech Acts. Academic Press.
Grosz, B., & Kraus, S. (1996). Collaborative Plans Complex Group Action. Artificial Intelligence,
86(2):269-357.
Grosz, B. J., & Sidner, C. L. (1986). Attention, Intentions, Structure Discourse. Computational
Linguistics, 12(3):175-204.
Hage, J. C. (1997). Reasoning Rules: Essay Legal Reasoning Underlying logic. Kluwer
Academic Publishers.
Halpern, J. Y., & Pearl, J. (2001). Causes Explanations: Structural-Model Approach. Part : Causes.
Proceedings Seventeenth Conference Uncertainty Artificial Intelligence.
Halpern, J. Y., & Pearl, J. (2005). Causes Explanations: Structural-Model Approach. Part : Causes.
British Journal Philosophy Science, 56(4):843-887.
270

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
Heider, F. (1958). Psychology Interpersonal Relations. John Wiley & Sons Inc.
Hilton, D. J. (1990). Conversational Processes Causal Explanation. Psychological Bulletin, 107:65-81.
Hobbs, J. R. (1985). Ontological Promiscuity. Proceedings Twenty-Third Annual Meeting
Association Computational Linguistics.
Hobbs, J. R., Stickel, M., Appelt, D., & Martin, P. (1993). Interpretation Abduction. Artificial
Intelligence, 63(1-2):69-142.
Huber, M. J. (1999). JAM: BDI-Theoretic Mobile Agent Architecture. Proceedings Third
International Conference Autonomous Agents.
Jaimes, A., Sebe, N., & Gatica-Perez, D. (2006). Human-Centered Computing: Multimedia Perspective.
Proceedings Fourteenth Annual ACM International Conference Multimedia.
Jennings, N. R. (1992). Responsible. In: E. Werner Y. Demazeau (Eds.). Decentralized A.I.,
pp. 93-102. North Holland Publishers.
Johnson, C., & Gonzalez, A. J. (2008). Automated Action Review: State-of-the-Art Review
Trends. Journal Defense Modeling Simulation: Applications, Methodology, Technology.
5(2):108-121.
Jones, D. (2009). Good, Bad Intentional. Psychologist, 22(8):666-669, August.
Kant, I. (1998). Groundwork metaphysics morals. Cambridge University Press.
Kidd, R. F., & Amabile, T. M. (1981). Causal Explanations Social Interaction: Dialogues
Dialogue. In: J. H. Harvey, W. J. Ickes R. F. Kidd (Eds.). New Directions Attribution Research
(Vol. 3), pp. 307-328. Lawrence Erlbaum Associates.
Knobe, J. (2003a). Intentional Action Side-Effects Ordinary Language. Analysis, 63:190-193.
Knobe, J. (2003b). Intentional Action Folk Psychology: Experimental Investigation. Philosophical
Psychology, 16:309-324.
Kohavi, R., & Provost, F. (1998). Glossary Terms. Machine Learning, 30(2/3):271-274.
Kraus, S., Hoz-Weiss, P., & Wilkenfeld, J. (2008), Resolving Crises Automated Bilateral
Negotiations. Artificial Intelligence, 172(1).
Litman, D. J., & Allen, J. F. (1990). Discourse Processing Commonsense Plans. In: P. R. Cohen, J.
Morgan M. E. Pollack (Eds.), Intentions Communication, pp.365-388. MIT Press.
Lochbaum, K. E., Grosz, B. J., & Sidner, C. L. (2000). Discourse Structure Intention Recognition. In: R.
Dale, H. Moisl H. Somers (Eds.), Handbook Natural Language Processing, pp.123-146.
Malle, B. F. (2001). Attribution processes. N. J. Smelser P. B. Baltes (Eds.), International
encyclopedia social behavioral sciences Vol. 14, pp. 913-917. Elsevier.
Malle, B. F., & Knobe, J. (1997). Folk Concept Intentionality. Journal Experimental Social
Psychology, 33:101-121.
Mao, W., Gratch, J., & Li, X. (in press). Probabilistic Plan Inference Group Behavior Prediction. IEEE
Intelligent Systems.
Marinier, R. P., & Laird, J.E. (2004). Towards Comprehensive Computational Model Emotions
Feelings. Proceedings Sixth International Conference Cognitive Modeling.
Marsella, S., & Gratch, J. (2009). EMA: Process Model Appraisal Dynamics. Journal Cognitive
Systems Research, 10(1): 70-90.
Martinovski, B., & Mao, W. (2009). Emotion Argumentation Engine: Modeling Role Emotion
Negotiation. Group Decision Negotiation, 18(3):235-259.
Martinovski, B., Mao, W., Gratch, J., & Marsella, S. (2005). Mitigation Theory: Integrated Approach.
Proceedings Twenty-Seventh Annual Conference Cognitive Science Society.

271

fiMAO & GRATCH
McCarty, L. T., & Sridharan, N. S. (1981). Representation Evolving System Legal Concepts: .
Prototypes Deformations. Proceedings Seventh International Joint Conference Artificial
Intelligence.
McCarty, L. T. (1995). Implementation Eisner v. Macomber. Proceedings Fifth International
Conference Artificial Intelligence Law.
McCarty, L. T. (1997). Arguments Legal Arguments. Proceedings Sixth International
Conference Artificial Intelligence Law.
Mele, A. R. (2001). Self-Deception Unmasked. Princeton University Press.
Melissen, A. (2008). Exploring Neglected Avenues Modeling Attribution Theory. Master Thesis,
Department Human Media Interaction, University Twente.
Mueller, E. (2006). Commonsense Reasoning. Morgan Kaufmann Publishers.
Nadelhoffer, T. (2006). Trying Save Simple View. Mind & Language, 21(5):565-586, November.
Nau, D. S., Cao, Y., Lotem, A., & Muoz-Avila, H. (1999). SHOP: Simple Hierarchical Ordered Planner.
Proceedings Sixteenth International Joint Conference Artificial Intelligence.
Newell, A., & Simon, H. A. (1972). Human Problem Solving. Prentice-Hall.
Norman, T. J., & Reed, C. (2010). Logic Delegation Responsibility. Artificial Intelligence,
174(1):51-71.
Oh, S., Gratch, J., & Woo, W. (2007). Explanatory Styles Socially Interactive Agents. Proceedings
Second International Conference Affective Computing Intelligent Interaction.
Pearl, J. (1999). Reasoning Cause Effect. Proceedings Sixteenth International Joint
Conference Artificial Intelligence.
Perrault, C. R. (1990). Application Default Logic Speech Act Theory. In: P. R. Cohen, J. Morgan
M. E. Pollack (Eds.), Intentions Communication, pp.161-186. MIT Press.
Picard, R. W. (1997). Affective Computing. MIT Press.
Picard, R. W. (2010). Affective Computing: Laughter IEEE. IEEE Transactions Affective
Computing, 1(1):11-17, January-June.
Pollack, M. E. (1990). Plans Complex Mental Attitudes. In: P. R. Cohen, J. Morgan M. E. Pollack
(Eds.), Intentions Communication, pp.77-103. MIT Press.
Prakken, H. (1997). Logic Tools Modeling Legal Argument: Study Defeasible Argumentation
Law. Kluwer Academic Publishers.
Prakken, H., & Sartor, G. (2002). Role Logic Computational Models Legal Argument. In:
A.Kakas F. Sadri (eds.). Computational Logic: Logic Programming Beyond, Essays Honor
Robert A. Kowalski, Part II, pp. 342-380. Springer-Verlag.
Rao, A. S. (1996). AgentSpeak(L): BDI Agents Speak Logical Computable Language. In: W. Van
de Velde J. W. Perram (Eds.). Agents Breaking Away: Proceedings Seventh European
Workshop Modeling Autonomous Agents Multi-Agent World, pp. 42-55. Springer-Verlag.
Rice J. A. (1994). Mathematical Statistics Data Analysis (Second Edition). Duxbury Press.
Rich, C., Sidner, C. L., & Lesh, N. (2001). COLLAGEN: Applying Collaborative Discourse Theory
Human-Computer Interaction. AI Magazine, 22(4):15-26.
Rietveld, T., & van Hout. R. (1993). Statistical Techniques Study Language Language
Behavior. Mouton de Gruyter.
Rissland, E. L., & Ashley, K. D. (1987). Case-Based System Trade Secrets Law. Proceedings
First International Conference Artificial Intelligence Law.
Rissland, E. L., & Skalak, D. B. (1991). CABARET: Statutory Interpretation Hybrid Architecture.
International Journal Man-Machine Studies, 34:839-887.
272

fiMODELING SOCIAL CAUSALITY RESPONSIBILITY JUDGMENT MULTI-AGENT INTERACTIONS
Schurr, N., Marecki, J., Tambe, M., & Scerri, P. (2005). Towards Flexible Coordination Human-Agent
Teams. Multiagent Grid Systems, 1(1):3-16.
Searle, J. R. (1969). Speech Acts: Essay Philosophy Language. Cambridge University Press.
Shaver, K. G. (1985). Attribution Theory Blame: Causality, Responsibility Blameworthiness.
Springer-Verlag.
Sichman, J. S., Conte, R., Demazeau, Y., & Castelfranchi, C. (1994). Social Reasoning Mechanism
Based Dependence Networks. Proceedings Eleventh European Conference AI.
Smith, I. A., & Cohen, P. R. (1996). Toward Semantics Agent Communications Language Based
Speech-Acts. Proceedings Thirteenth National Conference Artificial Intelligence.
Swartout, W., Gratch, J., Hill, R., Hovy, E., Marsella, S., Rickel, J., & Traum, D. (2006). Toward Virtual
Humans. AI Magazine, 27(2):96-108.
Swartout, W., Traum, D., Artstein, R., Noren, D., Debevec, P., Bronnenkant, K., Williams, J., Leuski, A.,
Narayanan, S., Piepol, D., Lane, C., Morie, J., Aggarwal, P., Liewer, M., Chiang, J., Gerten, J., Chu, S.,
& White, K. (2010). Ada Grace: Toward Realistic Engaging Virtual Museum Guides.
Proceedings Tenth International Conference Intelligent Virtual Agents.
Tomai, E. (2009). Pragmatic Approach Computational Narrative Understanding. Ph.D. Thesis,
Electrical Engineering Computer Science Department, Northwestern University.
Traum, D. (1994). Computational Theory Grounding Natural Language Conversation. Ph.D. Thesis,
Computer Science Department, University Rochester.
Traum, D., Gratch, J., Marsella, S., Lee, J., & Hartholt, A. (2008). Multi-party, Multi-issue, Multi-strategy
Negotiation Multi-modal Virtual Agents. Proceedings Eighth International Conference
Intelligent Virtual Agents.
Traum, D., Rickel, J., Gratch, J., & Marsella, S. (2003). Negotiation Tasks Hybrid Human-Agent
Teams Simulation-Based Training. Proceedings Second International Joint Conference
Autonomous Agents Multiagent Systems.
Veloso, M., Carbonell, J., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating Planning
Learning: Prodigy Architecture. Journal Theoretical Experimental Artificial Intelligence,
7(1):81-120.
Wang, F., Zeng, D., Carley, K., & Mao, W. (2007). Social Computing: Social Informatics Social
Intelligence. IEEE Intelligent Systems, 22(2):79-83.
Wang, F., Zeng, D., Hendler, J. A., Zhang Q., Feng, Z., Gao, Y., Wang, H., & Lai, G. (2010). Study
Human Flesh Search Engine: Crowd-Powered Expansion Online Knowledge. Computer,
43(8):45-53.
Weiner, B. (1995). Judgment Responsibility: Foundation Theory Social Conduct.
Guilford Press.
Weiner, B. (2001). Responsibility Social Transgressions: Attributional Analysis. In: B. F. Malle, L. J.
Moses D. A. Baldwin (Eds.), Intentions Intentionality: Foundations Social Cognition, pp.
331-344. MIT Press.
Weiner, B. (2006). Social Motivation, Justice Moral Emotions: Attributional Approach.
Lawrence Erlbaum Associates.
Zimmerman, M. J. (1988). Essay Moral Responsibility. Rowman & Littlefield.

273

fiJournal Artificial Intelligence Research 44 (2012) 455-490

Submitted 1/12; published 7/12

Tractable Triangles Cross-Free Convexity
Discrete Optimisation
Martin C. Cooper

cooper@irit.fr

IRIT, University Toulouse III
Toulouse, France

Stanislav Zivny

standa.zivny@cs.ox.ac.uk

Department Computer Science, University Oxford
Oxford, UK

Abstract
minimisation problem sum unary pairwise functions discrete variables
general NP-hard problem wide applications computing MAP configurations
Markov Random Fields (MRF), minimising Gibbs energy, solving binary Valued
Constraint Satisfaction Problems (VCSPs).
study computational complexity classes discrete optimisation problems
given allowing certain types costs every triangle variable-value assignments
three distinct variables. show several computational problems, nontrivial tractable classes well known maximum matching problem recently
discovered joint-winner property. results, apart giving complete classifications
studied cases, provide guidance search hybrid tractable classes; is, classes
problems captured restrictions functions (such submodularity)
structure problem graph (such bounded treewidth).
Furthermore, introduce class problems convex cardinality functions
cross-free sets assignments. prove imposing one two conditions
renders problem NP-hard, conjunction two gives rise novel tractable class
satisfying cross-free convexity property, generalises joint-winner property
problems unbounded arity.

1. Introduction
topic paper following optimisation problem: given set discrete variables
set functions, depending subset variables, minimise sum
functions variables. fundamental research problem studied
within several different contexts computer science artificial intelligence different
names: Min-Sum Problems (Werner, 2007), MAP inference Markov Random Fields
(MRF) Conditional Random Fields (CRF) (Lauritzen, 1996; Wainwright & Jordan,
2008), Gibbs energy minimisation (Geman & Geman, 1984), Valued Constraint Satisfaction
Problems (Dechter, 2003), (for two-state variables) pseudo-Boolean optimisation (Boros
& Hammer, 2002).
use terminology Valued Constraint Satisfaction Problems (VCSPs) (Schiex,
Fargier, & Verfaillie, 1995; Dechter, 2003). start special case VCSPs deals
feasibility (rather optimisation) problem.
c
2012
AI Access Foundation. rights reserved.

fiCooper & Zivny

Constraint Satisfaction Problem (CSP) instance consists collection variables
must assigned values subject specified constraints (Montanari, 1974).
CSP instance underlying undirected graph, known constraint graph (or structure), whose vertices variables instance, two vertices adjacent
corresponding variables related constraint.
important line research CSPs identify tractable cases recognisable polynomial time. work focused one two general
approaches: either identifying forms constraint sufficiently restrictive ensure
tractability matter combined (Bulatov, Krokhin, & Jeavons, 2005; Feder &
Vardi, 1998), else identifying structural properties constraint networks ensure
tractability matter forms constraint imposed (Dechter & Pearl, 1988).
first approach led identifying certain algebraic closure operations known
polymorphisms (Jeavons, 1998) necessary set constraint types ensure
tractability. set constraint types property called tractable constraint
language. second approach used characterise tractable cases boundedarity CSPs (such binary CSPs) (Dalmau, Kolaitis, & Vardi, 2002; Grohe, 2007)
unbounded-arity CSPs (Marx, 2010).
practice, constraint satisfaction problems usually possess sufficiently restricted structure use sufficiently restricted constraint language fall
tractable classes. Nevertheless, may still properties ensure
solved efficiently, properties concern structure form
constraints. properties sometimes called hybrid reasons tractability (Dechter, 2003; Cohen, 2003; Cohen & Jeavons, 2006; Cooper, Jeavons, & Salamon,
2010; Cohen, Cooper, Green, & Marx, 2011).
CSPs capture feasibility aspects given problem. Since many computational
problems involve seeking solution optimises certain criteria, well satisfying certain restrictions, various general frameworks optimisation problems studied
linear programming, mixed integer programming others (Hooker, 2007). One
possibility extend CSPs so-called soft constraint satisfaction problems, allow
measures desirability associated different assignments variables (Dechter,
2003; Meseguer, Rossi, & Schiex, 2006). instance soft CSP, every constraint
associated function (rather relation standard CSPs) represents preferences among different partial assignments, goal find best
assignment. Several general soft CSP frameworks proposed literature (Schiex, Fargier, & Verfaillie, 1995; Bistarelli, Montanari, & Rossi, 1997). paper
focus one general frameworks, valued constraint satisfaction problem (VCSP) (Schiex, Fargier, & Verfaillie, 1995). VCSPs powerful enough include
many interesting optimisation problems (Rossi, van Beek, & Walsh, 2006; Cohen, Cooper,
Jeavons, & Krokhin, 2006) and, pointed beginning introduction,
equivalent well studied optimisation problems studied computer vision
fields computer science artificial intelligence.
important line research VCSPs identify tractable cases recognisable polynomial time. well known structural reasons tractability generalise
VCSP (Bertele & Brioshi, 1972; Dechter, 2003). case language restrictions, conditions known guarantee tractability given set valued
456

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

constraints (Cohen, Cooper, Jeavons, & Krokhin, 2006; Cohen, Cooper, & Jeavons, 2008;
Jonsson, Kuivinen, & Thapper, 2011; Kolmogorov, 2011; Kolmogorov & Zivny, 2012).
1.1 Contributions
paper full version results described two conference papers (Cooper & Zivny,
2011a, 2011c).
1.1.1 Binary VCSPs
first part paper, study hybrid tractability binary VCSPs (i.e. optimisation
problems involving functions two arguments) various sets possible costs
correspond CSPs, CSPs soft unary constraints, Max-CSPs, finite-valued VCSPs
general-valued VCSPs.
focus classes instances defined allowed combinations binary costs every
assignment 3 different variables (called triangle). motivation investigation
one restriction, so-called joint-winner property recently shown
define tractable class (Cooper & Zivny, 2011b). finite sets possible costs (corresponding CSPs Max-CSPs), finitely many possibilities. example,
Max-CSPs four possible multi-sets costs, namely {0, 0, 0}, {0, 0, 1},
{0, 1, 1} {1, 1, 1}. However, infinite sets possible costs (corresponding finitevalued CSPs general-valued VCSPs) infinitely many combinations. Obviously,
cannot consider all, hence consider equivalence relation based
total order valuation structure. example, consider four equivalence classes
multi-sets {, , } given = = , = < , = > , < < .
sets possible costs consider, prove dichotomy theorem, thus identifying tractable cases respect equivalence relation combinations
costs. turns two non-trivial tractable cases: well-known
maximum matching problem (Edmonds, 1965b), recently discovered joint-winner
property (Cooper & Zivny, 2011b).
1.1.2 Non-binary VCSPs
second part paper, introduce cross-free convexity property (CFC),
show gives rise novel tractable class VCSPs. Informally speaking, CFC
property conjunction convex cost functions applied structured set sets
variable-value assignments. CFC property generalises recent results VCSPs
satisfying non-overlapping convexity property (Cooper & Zivny, 2011b) dropping
assumption input functions non-decreasing allowing assignmentsets hierarchically nested (laminar) also cross-free. (All terms
defined formally Section 4.) generalise tractable class work
Cooper & Zivny (2011b), algorithm also better running time compared
algorithm Cooper & Zivny (2011b). Moreover, show relaxing either one
cross-free convexity assumptions leads NP-hard class.
VCSP instance may subset constraints cross-free convex.
Since network projection-safe (Lee & Leung, 2009), use establish soft
global arc consistency subset constraints viewed single global constraint.
457

fiCooper & Zivny

also show that, Boolean domains, possible determine polynomial time
whether exists subset constraints VCSP instance satisfies
cross-free convexity property renaming variables constraints. explore
area even further, study restrictions overlaps constraint scopes, identify
another tractable class incomparable cross-free convexity property.
1.2 Organisation Paper
rest paper organised follows. start, Section 2, defining valuation
structures, valued constraint satisfaction problems, basics flow networks. Section 3
devoted classification binary VCSPs defined triangles: Section 3.1,
present results CSPs, followed results CSPs soft unary constraints
Section 3.2. Section 3.3, present results Max-CSPs, followed results
finite-valued general-valued VCSPs Section 3.4 Section 3.5 respectively.
Section 4 devoted results non-binary VCSPs: Section 4.1, present
algorithm VCSPs satisfying cross-free convexity property analyze running
time. Section 4.4 shows neither cross-freeness convexity enough
guarantee tractability. Section 4.5, extend class cross-free convex VCSPs
Boolean domains using notion renamability. Section 4.6 explores related notion
sets variables rather sets variable-value assignments. Finally, conclude
Section 5.

2. Preliminaries
section, define valuation structures, valued constraint satisfaction problems,
present basics flow networks.
2.1 Valuation Structures
valuation structure, , totally ordered set, minimum maximum element
(denoted 0 ), together commutative, associative binary aggregation operator
(denoted ), , , , 0 = , whenever .
Members called costs.
shall denote Q+ set non-negative rational numbers. define Q+ =
Q+ {}. consider following subsets valuation structure Q+ : {0, }, {0, 1},
Q+ Q+ , cases aggregation operation standard addition operation
rationals +. Moreover, Q+ , define + = + = .
2.2 Valued Constraint Satisfaction Problems
instance Valued Constraint Satisfaction Problem (VCSP) (Schiex, Fargier, &
Verfaillie, 1995) given n variables v1 , . . . , vn finite domains D1 , . . . , Dn values
set constraints C. constraint C pair hs, gi, list
variables = hvi1 , . . . , vim called constraint scope, g m-ary cost function
g : Di1 . . . Dim . assignment values domains variables
called solution. goal find optimal solution; is, solution minimises
total cost given aggregation costs restrictions onto constraint
458

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

scope:


min

v1 D1 ,...,vn Dn

g(vi1 , . . . , vim ) .

hhvi1 ,...,vim i,giC

Depending set costs may occur instances, get special cases
VCSP: = {0, } corresponds Constraint Satisfaction Problem (CSP), {0, 1}
corresponds Maximum Constraint Satisfaction Problem (Max-CSP), Q+ corresponds
finite-valued VCSP, finally Q+ corresponds general-valued VCSP.
domains variables same, denote common domain
D. CSP instance called satisfiable cost optimal solution zero (i.e.
constraints satisfied).
Cost functions range {0, } called crisp. Cost functions crisp
called soft.
2.3 Binary Valued Constraint Satisfaction Problems
Section 3 interested special case VCSP bound
arity constraints 2; known binary VCSPs. Without loss generality,
assume binary VCSP
instance contains constraints possible scopes;

n
is, n unary constraints 2 binary constraints. denote cost function associated
unary constraint scope hvi ci cost function associated
binary constraint scope hvi , vj cij . absence constraint variable
vi (or variables vi , vj ) modelled cost function ci (or cij , respectively)
uniformly zero. Using notation, goal find solution minimises
total cost given by:
n


ci (vi )
cij (vi , vj ) .
i=1

1i<jn

Remark 2.1. remark terminological differences. VCSPs studied different
names Min-Sum, Gibbs energy minimisation, Markov Random Fields; domain
values sometimes called labels, whereas binary instances called pairwise instances,
m-ary cost functions called m-cliques, solutions called labellings.
2.4 Network Flows
review basics flows graphs. refer reader standard textbooks (Ahuja, Magnanti, & Orlin, 2005; Schrijver, 2003) details. present
notions results needed purposes. particular, deal integral flows
only. denote N set positive integers zero. Let G = (V, A) directed
graph vertex set V arc set A. arc demand/capacity function [d(a), c(a)] weight (or cost) function w(a), d(a), c(a) N w(a) Q.
Let s, V . function f : N called flow (or flow)
v V \ {s, t},
X
a=(u,v)A

f (a) =

X

f (a)

a=(v,u)A

459

(flow conservation).

fiCooper & Zivny

say flow P
feasible d(a) fP
(a) c(a) A. define value

flow
f

val(f
)
=
f
(a)

a=(s,v)A
a=(v,s)A f (a). define cost flow f
P
aA w(a)f (a). minimum-cost flow feasible flow minimum cost.
Algorithms finding minimum-cost flow given value well known (Ahuja,
Magnanti, & Orlin, 2005; Schrijver, 2003). consider generalisation minimumcost flow problem. arc convex weight function wa associates
cost wa (f (a)) flow f (a) along arc a. particular, consider model
weight functions wa (a A) convex piecewise linear given breakpoints
(which covers
P case convex functions integers). cost flow f
defined aA wa (f (a)). corresponding problem finding minimum-cost integral
flow known minimum convex cost flow problem. network n vertices
edges capacities U , minimum convex cost flow problem solved
time O((m log U )SP (n, m)), SP (n, m) time compute shortest directed
path network n vertices edges (Minoux, 1984, 1986; Ahuja, Magnanti, &
Orlin, 2005).

3. Complexity Classification Binary VCSPs Defined Triangles
VCSP instance, use word triangle set assignments {hvi , ai, hvj , bi, hvk , ci},
vi , vj , vk distinct variables Di , b Dj , c Dk domain values.
multi-set costs triangle {cij (a, b), cik (a, c), cjk (b, c)}. triple costs
always refer multi-set binary costs triangle.
triangle {hvi , ai, hvj , bi, hvk , ci}, Di , b Dj , c Dk , satisfies jointwinner property (JWP) either three cij (a, b), cik (a, c), cjk (b, c) same, two
equal third one bigger. VCSP instance satisfies joint-winner
property every triangle satisfies joint-winner property.
Theorem 3.1. (Cooper & Zivny, 2011b) class VCSP instances satisfying JWP
tractable.
previous work (Cooper & Zivny, 2011b), also showed class defined
joint-winner property maximal allowing single extra triple costs violates
joint-winner property renders class NP-hard.
Theorem 3.2. (Cooper & Zivny, 2011b) Let < , Q+ , Q+ ,
multi-set costs satisfy joint-winner property. class instances
costs triangle either satisfy joint-winner property {, , }
NP-hard, even Boolean Max-CSPs, CSPs size-3 domains Boolean finite-valued
VCSPs.
section consider much broader question, whether allowing fixed set
triples costs triangles, necessarily include triples allowed
JWP, defines tractable class VCSP instances.
case CSP, four possible multi-sets costs ({0, 0, 0}, {0, 0, },
{0, , }, {, , }) possible study 16 subsets set. But, given
infinite set possible costs, Q+ Q+ , infinite number sets
triples costs. Obviously, cannot consider sets. Therefore, consider
460

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

cases defined total order < , corresponding partition set possible
triples costs small number types triples.
Let denote set possible cost types consideration. Let fixed
set allowed costs. D, denote (S) (A allowed) set binary
VCSP instances whose costs lie triples costs triangles belong
S.
goal classify complexity (S) every D. problem (S)
considered tractable polynomial-time algorithm solve intractable
NP-hard.
Proposition 3.3. Let arbitrary set costs set cost types.
1. (S) tractable 0 S, (S 0 ) tractable.
2. (S) intractable 0 S, (S 0 ) intractable.
Remark 3.4. implicitly allow unary cost functions. fact, tractability
results work unary cost functions, NP-hardness results require
unary cost functions.
Remark 3.5. consider problems unbounded domains; is, domain sizes
part input. However, NP-hardness results obtained problems
fixed domain size.1 case CSPs, need domains size 3 prove NP-hardness,
cases domains size 2 sufficient prove NP-hardness. Since binary
CSPs known tractable Boolean domains, VCSP trivially tractable
domains size 1, NP-hardness results tight.
3.1 CSP
section, focus set possible costs = {0, }; is, Constraint
Satisfaction Problems (CSPs). consider four following types triples costs:
Symbol
<
>
0


Costs
{0, 0, }
{0, , }
{0, 0, 0}
{, , }

set possible cost types thus = {<, >, 0, }. Indeed, four cost types
correspond precisely four possible multi-sets costs: {0, 0, 0}, {0, 0, }, {0, , }
{, , }. dichotomy presented section therefore represents complete
characterisation complexity CSPs defined placing restrictions triples costs
triangles.
A{0,} (D) allows binary CSPs, A{0,} (D) intractable (Papadimitriou, 1994)
unless domain size 2, case equivalent 2-SAT,
well-known tractable class (Schaefer, 1978).
1. words, considered problems fixed-parameter tractable (Downey & Fellows, 1999)
domain size.

461

fiCooper & Zivny

<, >, 0,

<, >

<, >, 0

<, >,

<, 0,

>, 0,

<, 0

<,

>, 0

>,

<

>

0



0,



Figure 1: Complexity CSPs A{0,} (S), {<, >, 0, }.
Proposition 3.6. A{0,} (D) intractable unless |D| 2.
joint-winner property CSPs gives
Corollary 3.7 (of Theorem 3.1). A{0,} ({<, 0, }) tractable.
Proposition 3.8. A{0,} ({>, 0, }) tractable.
Proof. Since < forbidden, two binary costs triangle zero third binary
cost must also zero. words, assignment hv1 , a1 consistent hvi , ai
{2, . . . , n}, i, j {1, . . . , n} 6= j, hvi , ai consistent
hvj , aj i. Thus Singleton Arc Consistency, procedure enforcing Arc Consistency
every variable-value pair (Rossi, van Beek, & Walsh, 2006), solves A{0,} ({>, 0, }).
Proposition 3.9. A{0,} ({<, >, }) tractable.
Proof. class trivial: instances least three variables solution finite
cost, since triple costs {0, 0, 0} allowed.
Proposition 3.10. A{0,} ({<, >, 0}) intractable unless |D| 2.
Proof. straightforward encode 3-Colouring problem binary CSP. result
follows fact 3-Colouring NP-hard triangle-free graphs (i.e. graphs
contain K3 , complete graph 3 vertices, subgraph),
derived two results work Lovasz (1973). (Indeed, 3-Colouring NP-hard
even triangle-free graphs degree 4; see Maffray & Preissmann, 1996.)
triple costs {, , } cannot occur CSP encoding colouring trianglefree graph.
462

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

Results section, together Proposition 3.3, complete complexity classification, depicted Figure 1: white nodes represent tractable cases shaded nodes
represent intractable cases.
Theorem 3.11. |D| 3, class binary CSP instances defined A{0,} (S),
{<, >, 0, }, intractable {<, >, 0} S.
3.2 CSP Soft Unary Constraints
simple way convert classical CSPs optimisation problem allow soft unary
constraints. framework includes well-studied problems Max-Ones Boolean
domains (Creignou, Khanna, & Sudan, 2001; Khanna, Sudan, Trevisan, & Williamson,
2001) non-Boolean domains (Jonsson, Kuivinen, & Nordh, 2008), Max-Solution (Jonsson & Nordh, 2008), Min-Cost-Hom (Takhanov, 2010).
turns dichotomy given Theorem 3.11 remains valid even soft unary
constraints allowed. case, intractable cases intractable even
domains size 2.
Q+
use notation A{0,}
(S) represent set VCSP instances binary
costs {0, }, unary costs Q+ whose triples costs triangles belong
S. words, consider VCSPs crisp binary constraints soft unary
constraints.
Q

+
Theorem 3.12. |D| 2, class binary CSP instances defined A{0,}
(S),
{<, >, 0, }, intractable {<, >, 0} S.

Proof. tractability part theorem, suffices show tractability
{<, >, }, {<, 0, } {>, 0, }, three maximal tractable sets case CSP
shown Figure 1.
Q

+
tractability A{0,}
({<, 0, }) corollary Theorem 3.1 since jointwinner property allows unary soft constraints.

Q

+
solve A{0,}
({>, 0, }) polynomial time, establish Singleton Arc Consistency
CSP instance corresponding binary constraints loop assignments first variable. assignment a1 variable v1 , determine
optimal global assignment extension hv1 , a1 simply choosing assignment ai variable vi least unary cost ci (ai ) among assignments hvi , ai
consistent hv1 , a1 i.

Q

+
proof Proposition 3.9, instance A{0,}
({<, >, }) tractable, since
instances least three variables solution finite cost.
Sets intractable CSPs clearly remain intractable soft unary constraints allowed. However, want prove intractability even Boolean case;
is, |D| = 2.

Q

Q

+
+
({<, >, 0}) (and hence, Proposition 3.3, A{0,}
({<, >
intractability A{0,}
, 0, })) follows fact Independent Set problem (Garey & Johnson, 1979)
intractable even triangle free graphs. follows standard trick (Poljak,
1974) replacing every edge P4 , path 4 vertices (this operation also known

463

fiCooper & Zivny

2-subdivision). particular, graph G edges independent set size k
2-subdivision G, denoted G0 , independent set size k + m.
Note G0 triangle-free. instance G0 Independent Set problem triangleQ

+
free graphs encoded instance A{0,}
({<, >, 0}) {0, 1} domain
straightforward way: variables correspond vertices; edge {i, j} yields cost function
cij (1, 1) = cij (x, y) = 0 (x, y) 6= (1, 1); ci (0) = 1 ci (1) = 0 every i. Since

Q

+
G0 triangle-free, constructed instance belongs A{0,}
({<, >, 0}).

3.3 Max-CSP
section, focus set possible costs = {0, 1}. well known
VCSP costs {0, 1} polynomial-time equivalent unweighted Max-CSP (no
repetition constraints allowed) (Rossi, van Beek, & Walsh, 2006). four types
triples costs consider are:
Symbol
<
>
0
1

Costs
{0, 0, 1}
{0, 1, 1}
{0, 0, 0}
{1, 1, 1}

set possible cost types = {<, >, 0, 1}. Again, four costs types
correspond precisely four possible multi-sets costs: {0, 0, 0}, {0, 0, 1}, {0, 1, 1},
{1, 1, 1}. CSP, dichotomy result Max-CSP represents complete
characterisation complexity classes instances defined placing restrictions
triples costs triangles.
<, >, 0, 1

<, >

<, >, 0

<, >, 1

<, 0, 1

>, 0, 1

<, 0

<, 1

>, 0

>, 1

<

>

0

1

0, 1



Figure 2: Complexity Max-CSPs A{0,1} (S), {<, >, 0, 1}.
A{0,1} (D) allows binary Max-CSPs, A{0,1} (D) intractable (Garey & Johnson,
1979; Papadimitriou, 1994) unless domain size 1.
464

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

Proposition 3.13. A{0,1} (D) intractable unless |D| 1.
joint-winner property (Cooper & Zivny, 2011b) Max-CSPs gives
Corollary 3.14 (of Theorem 3.1). A{0,1} ({<, 0, 1}) tractable.
Proposition 3.15. A{0,1} ({<, >}) tractable.
Proof. show A{0,1} ({<, >}) contains instances 5 variables, thus showing
A{0,1} ({<, >}) trivially tractable. Consider instance A{0,1} ({<, >}) 6
variables. Choose 6 arbitrary variables v1 , . . . , v6 6 domain values di Dvi ,
1 6. Every cost either 0 1. well known (Goodman, 1959) difficult
show2 every 2-colouring edges K6 (the complete graph 6 vertices)
monochromatic triangle. Therefore, triangle costs either {0, 0, 0} {1, 1, 1}.
contradiction fact cost types < (i.e. {0, 0, 1}) > (i.e.
{1, 1, 0}) allowed.
Remark 3.16. ({>}) ({<, >}) tractable finite set costs
due similar Ramsey type argument: given = {0, 1, . . . , K 1}, nK N
every complete graph G n vertices, n nK , every colouring
edges G K colours, monochromatic triangle G. Hence
finitely many instances, stored look-up table. However, set
costs infinite (e.g. Q+ ), classes become intractable, shown next section.
Proposition 3.17. A{0,1} ({>, 0, 1}) intractable unless |D| 1.
Proof. Given instance Max-2SAT problem, show reduce {0, 1}valued VCSP instance A{0,1} ({>, 0, 1}). result follows well-known
fact Max-2SAT NP-hard (Garey & Johnson, 1979; Papadimitriou, 1994). Recall
instance Max-2SAT given set clauses length 2 n variables
x1 , . . . , xn goal find assignment maximises number clauses
least one true literal.
order simplify notation, rather constructing VCSP instance A{0,1} ({>
, 0, 1}) goal minimise total cost, construct instance A{0,1} ({<
, 0, 1}) goal maximise total cost. implies allowed sets costs
triangles {0, 0, 1}, {0, 0, 0}, {1, 1, 1}. Clearly, two problems polynomialtime equivalent.
variable xi , create large number copies xji xi domain {0, 1},
1 n 1 j . variable xi , new copies xi pairwise joined
equality-encouraging cost function h, h(x, y) = 1 x = h(x, y) = 0 otherwise.
choosing large, assume copies xi assigned
value optimal solutions. effectively ignore contribution
2. Take arbitrary vertex v K6 every edge coloured either blue red. pigeonhole
principle, v incident least 3 blue least 3 red edges. Without loss generality, consider
former case. Let v1 , v2 v3 three vertices incident three blue edges incident v.
edges {v1 , v2 }, {v1 , v3 }, {v2 , v3 } blue, blue triangle. three edges red,
red triangle.

465

fiCooper & Zivny


cost functions, K = n
2 , total cost. straightforward check
triangles involving new copies variables allowed costs.
clause (l1 l2 ), l1 l2 literals, create variable zi domain
{l1 , l2 }, 1 m. literal l domain zk : l positive literal l = xi ,
introduce cost function g zk copy xji xi , g(l, 1) = 1 g(., .) = 0
otherwise; l negative literal l = xi , introduce cost function g 0 zk
copy xji xi , g 0 (l, 0) = 1 g 0 (., .) = 0 otherwise.
make sure sets costs triangles {0, 0, 1}, {0, 0, 0},
{1, 1, 1}, also add cost functions f different clause variables zk zk0
involving literal l, f (l, l) = 1 f (., .) = 0 otherwise. contribution
cost functions zk zk0 , 1 k 6= k 0 m, less hence
importance large.
Answering question whether resulting VCSP instance solution
cost K + pM equivalent determining whether original Max-2SAT instance
solution satisfying least p clauses. clause variable zk add
score assign value l zk literal l assigned true.
Proposition 3.18. A{0,1} ({<, >, 0}) A{0,1} ({<, >, 1}) intractable unless |D|
1.
Proof. present reduction Max-Cut, well-known NP-hard problem (Garey &
Johnson, 1979), NP-hard even triangle-free graphs (Lewis & Yannakakis, 1980).
instance Max-Cut easily modelled Boolean {0, 1}-valued VCSP instance:
every vertex graph represented variable Boolean domain {0, 1},
every edge yields cost function f , f (x, y) = 1 x = f (x, y) = 0 x 6= y.
Observe since original graph triangle-free, cannot triangle costs
{1, 1, 1}. Therefore, constructed instance belongs A{0,1} ({<, >, 0}).
A{0,1} ({<, >, 1}) case, instead minimising total cost, maximise total
cost instances A{0,1} ({<, >, 0}). Again, model instance Max-Cut
problem using Boolean variables, every edge yields cost function g, g(x, y) = 0
x = g(x, y) = 1 x 6= (where case aim maximise total cost).
constructed instance belongs A{0,1} ({<, >, 0}). (In fact, case need
original graph triangle-free.)
Proposition 3.19. A{0,1} ({>, 0}) tractable.
Proof. Let instance A{0,1} ({>, 0}). algorithm loops possible
assignments {hv1 , a1 i, hv2 , a2 i} first two variables. Suppose c12 (a1 , a2 ) = 1 (the
case c12 (a1 , a2 ) = 0 similar). Observe possible variable-value assignments
variables {hvi , bi | 3 n, b Di } uniquely split two sets L R that: (1)
every hvi , bi L, c1i (a1 , b) = 1 c2i (a2 , b) = 0; every hvi , bi, hvj , ci L, cij (b, c) =
0; (2) every hvi , bi R, c1i (a1 , b) = 0 c2i (a2 , b) = 1; every hvi , bi, hvj , ci R,
cij (b, c) = 0; (3) every hvi , bi L hvj , ci R, cij (b, c) = 1. Ignoring unary cost
functions moment, find optimal assignment remaining n 2 variables, one
decide many variables vi , 3 n, assigned value b Di
hvi , bi L. cost global assignment involving k variable-value assignments L
1 + k + (n 2 k) + k(n 2 k) = n 1 + k(n 2 k). variables vi could
466

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

happen hvi , bi L b Di hvi , ci R c Di . case,
choose arbitrary value b xi minimum unary cost ci (b). optimal
choice whatever assignments variables xj (j {3, . . . , 1, + 1, . . . , n}).
Assuming variables eliminated taking account
unary cost functions, function minimise given objective function (in
drop constant term n 1):
X
X
X
X
(
xi )(n 2
xi ) +
wiL xi +
wiR (1 xi )
(each sum {3, . . . , n}), xi {0, 1} indicates whether vi assigned
R
value R L, wiL = min{ci (b) : b Di hvi , bi L}, similarly
PwiL = min{c
P Ri (c) : c
Di hvi , ci R}. objective
function

thus
equal

k(n2k)+
w
x
+
wi (1xi ),


P
where, above, k =
xi number assignments L. objective function
minimised either k = 0 k = n 2. followsPfrom theP
fact
contribution unary cost functions objective function
wiL xi + wiR (1 xi )
n 2 (since Max-CSP unary costs belong {0, 1}).
greater value quadratic term k(n 2 k) values k {1, . . . , n 3},
i.e. equal 0 n 2.
optimal assignment involves k = 0 (respectively k = n 2) assignments
L obtained simply choosing value ai (for > 2) minimum unary cost among
assignments hvi , ai R (respectively L).
case c12 (a1 , a2 ) = 0, similar argument shows quadratic term
objective function 2(n 2 k) + k(n 2 k) = (k + 2)(n 2 k). always
minimised setting k = n 2 sum unary costs greater
value quadratic term values k 6= n 2. optimal assignment
involves k = n 2 assignments L obtained simply choosing value ai (for
> 2) minimum unary cost among assignments hvi , ai L.
Proposition 3.20. A{0,1} ({>, 1}) tractable.
Proof. Let instance A{0,1} ({>, 1}) without unary constraints; i.e.
constraints binary. Observe every variable-value assignment hvi , ai, Di ,
included zero-cost assignment-pairs involving one variable; i.e.
one variable vj , cij (a, b) = 0 b Dj . order minimise
total cost, maximise number zero-cost assignment-pairs. global
assignment, two zero-cost assignment-pairs involve variable, means
achieved reduction maximum matching problem, problem
solvable polynomial time (Edmonds, 1965b). build graph vertices given
variables I, edge {vi , vj } Di b Dj
cij (a, b) = 0.
complete proof, show unary constraints make problem
difficult solve; suffices perform preprocessing step reduction maximum
matching. Let vi arbitrary variable I. ci (a) = 1 Di ,
effectively ignore unary cost function ci since simply adds cost 1 solution.
Otherwise, show Di ci (a) = 1 ignored. Take arbitrary
assignment variables s(vi ) = a, ci (a) = 1. take b Di
467

fiCooper & Zivny

ci (b) = 0. claim assignment s0 defined s0 (vi ) = b s0 (vj ) = s(vj )
every j 6= increase total cost compared s. Since assignment
hvi , ai occur one zero-cost assignment-pair, two cases consider:
(1) hvj , ci s(vj ) = c cij (a, c) = 0, claim holds since
ci (a) = 1 ci (b) = 0, overall cost decrease replace b; (2)
exactly one j 6= cij (a, c) = 0 s(vj ) = c, cost s0 cannot
increase possible increase cost 1 assigning b vi compensated
unary cost function ci . Therefore, using reduction maximum matching,
remove Di ci (a) = 1 keep Di ci (a) = 0.
Remark 3.21. proof Proposition 3.20, shown instance
A{0,1} ({>, 1}) reduced instance maximum matching graphs (Edmonds,
1965b). remark conversely, given graph G, maximum matching problem
0
G modelled VCSP instance IG
{0,1} ({>, 1}).
order vertices G arbitrarily call 1, 2, . . . , n. instance IG
n variables v1 , . . . , vn , one vertex G. Let {n1 , . . . , nm } neighbours vertex
G, degree vertex G; is, {j | {i, j} E(G)} = {n1 , . . . , nm }.
define Di = {0, n1 , . . . , nm }.
edge {i, j} E(G), < j, yields cij (j, i) = 1, remaining costs 0.
follows definition IG (i) solutions IG maximum cost correspond
maximum matchings G; (ii) IG A{0,1} ({<, 0}). swapping costs 0 1,
0
get instance IG
{0,1} ({>, 1}), whose solutions correspond matchings G
solutions minimum cost correspond maximum matchings G.
Results section, together Proposition 3.3, complete complexity classification, depicted Figure 2: white nodes represent tractable cases shaded nodes
represent intractable cases.
Theorem 3.22. |D| 2, class binary unweighted Max-CSP instances defined
A{0,1} (S), {<, >, 0, 1}, intractable either {<, >, 0} S,
{<, >, 1} S, {>, 0, 1} S.
3.4 Finite-Valued VCSP
section, focus finite-valued VCSPs. words, consider set
possible costs = Q+ . Since infinite number triples costs, consider
types triples defined total order . study three different ways partitioning
set triples costs distinct types.
3.4.1 Classification respect Order
set possible cost types = {4, <, >, =}, four types defined
following table:
Symbol
4
<
>
=

Costs
{, , }
{, , }
{, , }
{, , }

Remark
, , , 6= 6= 6=
, , <
, , >

468

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

4, <, >, =

4, <

4, <, >

4, <, =

4, >, =

<, >, =

4, >

4, =

<, >

<, =

4

<

>

=

>, =



Figure 3: Complexity finite-valued VCSPs AQ+ (S), {4, <, >, =}.
AQ+ (D) allows finite-valued VCSPs, intractable even Boolean domain (Cohen, Cooper, Jeavons, & Krokhin, 2006) includes Max-SAT problem
exclusive predicate (Papadimitriou & Yannakakis, 1991; Creignou, Khanna, &
Sudan, 2001).
Proposition 3.23. AQ+ (D) intractable unless |D| 1.
joint-winner property (Cooper & Zivny, 2011b) finite-valued VCSPs gives
Corollary 3.24 (of Theorem 3.1). AQ+ ({<, =}) tractable.
Proposition 3.25. AQ+ ({4}) intractable unless |D| 1.
Proof. show reduction Max-Cut, well-known NP-hard problem (Garey &
Johnson, 1979). instance Max-Cut easily modelled Boolean finite-valued
VCSP instance: every vertex graph represented variable Boolean
domain {0, 1}, every edge yields cost function f , f (x, y) = 1 x = f (x, y) =
0 x 6= y. However, constructed instance belong AQ+ ({4}). Nevertheless,
amend VCSP instance infinitesimal perturbations: occurrences cost
0 replaced different numbers close 0, occurrences cost
1 replaced different numbers close 1. since costs different,
clearly instance belongs AQ+ ({4}).
Proposition 3.26. AQ+ ({>}) intractable unless |D| 1.
Proof. prove perturbation construction proof Proposition 3.17,
shows intractability AQ+ ({>, =}). order simplify proof, similarly
proof Proposition 3.17, prove maximising total cost class AQ+ ({<})
NP-hard.
construction proof Proposition 3.17 add binary cost cij (a, b),
< j, cij (a, b) equal 1. assume small (n < 1). simply
469

fiCooper & Zivny

ensures triple costs {1, 1, 1} triangle assignments perturbed
become {1 + i, 1 + i, 1 + j}.
reduction Max-2SAT, literal l, let Cl set variablevalue assignments corresponding l (in xji zk variables). Recall
binary costs pairs assignments within Cl 1 binary costs pairs
assignments distinct Cl , Cl0 0 VCSP encoding Max-2SAT
instance. place arbitrary ordering literals l1 < l2 < < lr . add
binary cost two variable-value assignments whenever assignments
correspond literals li , lj < j. simply ensures triple costs {0, 0, 0}
triangle assignments perturbed become {0 + i, 0 + i, 0 + j}.
resulting VCSP instance AQ+ ({>}) correctly codes original Max-2SAT
instance sufficiently small .
Results section, together Proposition 3.3, complete complexity classification, depicted Figure 3: white nodes represent tractable cases shaded nodes
represent intractable cases.
Theorem 3.27. |D| 2, class binary finite-valued VCSP instances defined
AQ+ (S), {4, <, >, =}, tractable {<, =}.
3.4.2 Classification respect Minimum Cost
tractable classes A{0,1} ({>, 1}), A{0,1} ({>, 0}) A{0,1} ({<, >}) appear Figure 2,
appear subclasses tractable classes AQ+ (S) identified Figure 3.
due fact infinite set possible costs = Q+ , Figure 3 covers
subset infinite number possible restrictions triples costs triangles.
consider triples costs allow us find generalisations three tractable
classes finite-valued VCSPs, considering restrictions depending relationship
costs minimum maximum binary cost instance.
start minimum cost. Without loss generality assume
minimum binary cost instance 0. consider following types triples costs:
Symbol
40
<0
>0
0

Costs
{, , 0}
{0, 0, }
{, , 0}
{0, 0, 0}

Remark
, , > > 0
, > 0
, > 0

simplicity presentation, consider remaining type triples costs,
namely {, , } , , > 0. Since possible transform VCSP instance
equivalent instance non-zero costs adding constant > 0 binary
costs, clear allowing triples costs would render VCSP intractable.
complexity combinations costs {40 , <0 , >0 , 0} shown Figure 4:
white nodes represent tractable cases shaded nodes represent intractable cases.
Proposition 3.28. AQ+ ({>0 , 0}) tractable.
470

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

40 , <0 , >0 , 0

40 , <0

40 , <0 , >0

40 , <0 , 0

40 , >0 , 0

<0 , >0 , 0

40 , >0

40 , 0

<0 , >0

<0 , 0

40

<0

>0

0

>0 , 0



Figure 4: Complexity finite-valued VCSPs AQ+ (S), {40 , <0 , >0 , 0}.
Proof. Observe either non-zero binary costs involve variable vk (i.e. cij = 0
i, j 6= k) one distinct cost > 0 instance. (Otherwise,
two distinct 6= non-zero costs , > 0 instance cij (a, b) =
ckl (c, d) = distinct i, j, k, l, easy verify possible assign
costs cik (a, c), cil (a, d), cjk (b, c), cjl (b, d) triangles cost types >0 0.)
implies AQ+ ({>0 , 0}) equivalent A{0,1} ({>, 0}) instantiation
one variable.
Corollary 3.29 (of Theorem 3.1). AQ+ ({<0 , 0}) tractable.
Proposition 3.30. AQ+ ({40 , <0 , >0 }) tractable.
Proof. Analogously Ramsey type argument proof Proposition 3.15,
instance 5 variables must contain either triangle zero costs triangle
three non-zero costs hence cannot belong AQ+ ({40 , <0 , >0 }).
Proposition 3.31. AQ+ ({<0 , >0 , 0}) intractable unless |D| 1.
Proof. reduction Max-Cut triangle-free graphs proof Proposition 3.18
Proposition 3.32. AQ+ ({40 , 0}) intractable unless |D| 1.
Proof. shown VCSP remains intractable bipartite graphs
Boolean domains (Cooper & Zivny, 2011b). Let instance partition
V1 ,V2 variables. Insignificantly small distinct costs added binary
costs variables V1 j V2 ensure triangles type 40
0.
471

fiCooper & Zivny

Theorem 3.33. |D| 2, class binary finite-valued VCSP instances defined
AQ+ (S), {40 , <0 , >0 , 0}, tractable {<0 , 0}, {>0 , 0}
{40 , <0 , >0 }.
3.4.3 Classification respect Maximum Cost
Let Q+ cost consider following types triples costs:
Symbol
4M
<M
>M


Costs
{, , }
{, , }
{, M, }
{M, M, }

Remark
, , < <
, <
, <

Again, consider remaining type triples costs, namely {, , }
, , < , since allowing triples costs renders VCSP intractable.
{4M , <M , >M , } allowed combinations triples costs, clearly
maximum binary cost instance.
4M , <M , >M ,

4M , <M , >M

4M , <M

4M , <M ,

4M , >M ,

<M , >M ,

4M , >M

4M ,

<M , >M

<M ,

4M

<M

>M



>M ,



Figure 5: Complexity finite-valued VCSPs AQ+ (S), {4M , <M , >M , }.
complexity combinations costs {4M , <M , >M , } depicted Figure 5: white nodes represent tractable cases shaded nodes represent intractable cases.
interesting case AQ+ ({>M , }), turns tractable
reduction maximum weighted matching hence proper generalization class
A{0,1} ({>, 1}).
Proposition 3.34. AQ+ ({>M , }) tractable.
Proof. proof similar proof Proposition 3.20. Consider instance
AQ+ ({>M , }), let
ij = min{ci (u) + cij (u, v) + cj (v) | u Di , v Dj }
472

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

minimum attained u = aji v = aij . assume, without
loss generality, unary cost functions satisfy i, di Di ci (di ) = 0
(by subtracting, necessary, min ci (u) unary cost function ci ). implies
ij cij (di , dj ) .
Suppose (bi , bj ) 6= (aji , aij ) cij (bi , bj ) < . replace (bi , bj )
(aji , aij ) solution produce solution greater cost:
binary costs involving bi bj necessarily maximal (i.e. equal ). Therefore, setting
cij (bi , bj ) = change cost optimal solution instance I. follows
assume one non-maximal binary cost cij (aji , aij )
binary cost function cij .
Consider weighted complete graph G vertices 1, . . . , n edge weights ij .
Let MG maximum weighted matching G. Define solution x = hx1 , . . . , xn
j
ai {i, j} MG
xi =
.
di otherwise
solution well-defined since MG matching. weight MG

X
n
(M ij ) =
cost(x).
2
{i,j}MG

hand, consider solution I. Let
E(y) = {{i, j} | yi = aji yj = aij ij < }.
E(y) matching G weight
X


n
(M ij )
cost(y).
2

{i,j}E(y)

Since MG maximum weighted matching, deduce cost(y) cost(x). Hence
x optimal solution.
Tractability follows tractability maximum weighted matching problem (Edmonds, 1965a).
Remark 3.35. seen proof Proposition 3.34 AQ+ ({>M , })
tractable via reduction maximum weighted matching problem (Edmonds, 1965a).
Similarly Remark 3.21, easy show that, conversely, instance maximum weighted matching problem modelled VCSP instance AQ+ ({>M , }).
Corollary 3.36 (of Theorem 3.1). AQ+ ({<M , }) tractable.
Proposition 3.37. AQ+ ({4M , <M , >M }) tractable.
Proof. Analogously proof Proposition 3.30, instances contain 5 variables.
Proposition 3.38. AQ+ ({<M , >M , }) intractable unless |D| 1.
473

fiCooper & Zivny

Proof. reduction Max-Cut proof Proposition 3.18
Proposition 3.39. AQ+ ({4M , }) intractable unless |D| 1.
Proof. show intractability reduction VCSP bipartite graphs
Boolean domains known NP-hard (Cooper & Zivny, 2011b). suffices
replace zero costs reduction VCSP bipartite graphs given
proof Proposition 3.32 produce equivalent instance AQ+ ({4M , }).
Theorem 3.40. |D| 2, class binary finite-valued VCSP instances defined
AQ+ (S), {4M , <M , >M , }, tractable {<M , }
{>M , } {4M , <M , >M }.
3.5 General-Valued VCSP
section, focus general-valued VCSPs. words, consider complete
valuation structure Q+ set possible costs . fact, complexity classifications
coincide classifications finite-valued VCSPs obtained Section 3.4.
Theorem 3.27 applies = Q+ well. Indeed, hard cases remain intractable
allow triangles (involving infinite costs), tractable case, AQ+ ({<, =}),
remains tractable: AQ+ ({<, =}) tractable Theorem 3.1.
Theorem 3.41. |D| 2, class binary general-valued VCSP instances defined
AQ+ (S), {4, <, >, =}, tractable {<, =}.
Similarly Theorem 3.33. Indeed, intractable cases remain intractable, tractable
cases remain tractable.
Theorem 3.42. |D| 2, class binary general-valued VCSP instances defined
AQ+ (S), {40 , <0 , >0 , 0}, tractable {<0 , 0}, {>0 , 0}
{40 , <0 , >0 }.
Similarly Theorem 3.40. Indeed, intractable cases remain intractable, tractable
cases remain tractable. (The class AQ+ ({>M , }) becomes trivially tractable =
solution finite cost instances two variables.)
Theorem 3.43. |D| 2, class binary general-valued VCSP instances defined
AQ+ (S), {4M , <M , >M , }, tractable {<M , }
{>M , } {4M , <M , >M }.

4. Cross-Free Convex VCSPs
Section 3, studied computational complexity several classes binary VCSPs.
considered cases, joint-winner property (JWP) either one one
tractable cases.
section, generalise JWP cross-free convexity property (CFC).
property defines novel tractable class describe efficient algorithm.
Section 4.4, show neither two conditions definition CFC
474

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

property dropped without rendering problem NP-hard. Moreover, Section 4.5,
present extension CFC Boolean domains. Section 4.6 devoted related
idea overlaps studied previously SAT Max-SAT.
4.1 Definition Examples Cross-Free Convex VCSPs
function g : {0, . . . , s} Q+ called convex interval [l, u] g finite-valued
interval [l, u] derivative g non-decreasing [l, u], i.e. g(m+2)g(m+1)
g(m + 1) g(m) = l, . . . , u 2. brevity, often say g convex
convex interval [l, u] [0, s] infinite elsewhere (i.e. [0, l 1] [u + 1, s]).
Two sets A1 , A2 said nested either disjoint one subset
(i.e. A1 A2 = , A1 A2 A2 A1 ). A1 A2 nested,
say overlap. say A1 A2 incompletely overlap A1 A2 overlap
A1 A2 6= A.
Sets A1 , . . . , Ar called laminar (Schrijver, 2003) (or hierarchically nested ; see Cooper
& Zivny, 2011a) 1 i, j r, Ai Aj nested. Sets A1 , . . . , Ar
called cross-free every 1 i, j r, either Ai Aj , Ai Aj , Ai Aj = ,
Ai Aj = (Schrijver, 2003). clear sets A1 , . . . , Ar laminar, A1 , . . . , Ar
also cross-free.
notational convenience, interpret solution x (i.e. assignment variables
v1 , . . . , vn ) VCSP instance set hvariable,valuei assignments {hvi , xi | xi
Di = 1, . . . , n}.
Ai set hvariable,valuei assignments VCSP instance P x solution
P, use notation |x Ai | represent number hvariable,valuei assignments
solution x lie Ai .
Definition 4.1 (Laminar/Cross-free convexity). Let P VCSP instance. Let A1 , . . . , Ar
laminar (cross-free) sets hvariable,valuei assignments P. Let si number
distinct variables occurring set hvariable,valuei assignments Ai . Instance P
satisfies laminar-free (cross-free) convexity property objective function P
g(x) = g1 (|x A1 |) + . . . + gr (|x Ar |) gi : [0, si ] Q+ (i = 1, . . . , r) convex
interval [li , ui ] [0, si ] gi (z) = z [0, li 1] [ui + 1, si ].
remark functions gi Definition 4.1 cost functions associated
constraints.
follows definition laminar convexity property implies cross-free
convexity property.
Remark 4.2. Observe addition unary cost function cannot destroy laminar cross-free convexity property. hvariable,valuei assignment
hvj , ai add singleton Ai = {hvj , ai} necessarily either disjoint
subset set Ak (and furthermore corresponding function gi : {0, 1} Q+
trivially convex).
give special case cross-free convexity property, sets
disjoint thus trivially cross-free.
475

fiCooper & Zivny

Example 4.3 (Value-based soft GCC). Global Cardinality Constraint (GCC),
introduced Regin (1996), generalisation AllDifferent constraint (Regin,
1994). Given set n variables, GCC specifies domain value lower
bound ld upper bound ud number variables assigned value d.
AllDifferent constraint special case GCC ld = 0 ud = 1 every d.
Soft versions GCC considered van Hoeve, Pesant, & Rousseau (2006).
value-based soft GCC minimises number values given
bound. show value-based soft GCC satisfies cross-free convexity property.
every domain value D, let Ad = {hvi , di : = 1, . . . , n}. Clearly, A1 , . . . ,
disjoint, = |D|. every d, let


ld < ld
gd (m) =
0
ld ud


ud > ud
follows readily definition gd sequence gd (m + 1) gd (m), =
0, . . . , n 1, sequence 1, . . . , 1, 0, . . . , 0, 1, . . . , 1. Therefore, every d, gd
non-decreasing derivative hence convex.
Example 4.4 (Nested value-based soft GCC). able nest GCC constraints useful
many staff assignment problems hierarchy (e.g. senior manager-managerpersonnel, foreman-worker, senior nurse-nurse) (Zanarini & Pesant, 2007). might
want impose soft global cardinality constraints day prefer
10 15 people work, least 5 managers among
exactly 1 senior manger, convex penalties described Example 4.3
constraints hold.
Suppose constraints VCSP instance consist soft GCC constraints
pairwise nested sets variables S1 , . . . , St . Let Aid = {hx, di : x Si }. Clearly,
sets assignments Aid cross-free and, shown Example 4.3, cost functions
corresponding soft GCC constraint convex.
main result section following theorem:
Theorem 4.5. VCSP instance P satisfying cross-free convexity property
solved polynomial time.
Firstly, present algorithm solve VCSPs satisfying laminar convexity property, followed reduction cross-free case laminar case. Secondly, give
proof polynomial-time complexity algorithm.
4.2 Algorithm Laminar Convex VCSPs
call sets Ai (i = 1, . . . , r) assignment-sets. assume assignment-sets
Ai distinct, since Ai = Aj two sets merged replacing two
functions gi ,gj sum (which necessarily also convex). Without loss generality,
assume assignment-set consisting variable-value assignments present,
corresponding function constant zero function. (If corresponding function
476

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

gi constant zero function, add constant term gi (n) objective
function.) useful construction described below. say assignmentset Ak father assignment-set Ai minimal assignment-set properly
contains Ai , i.e. Ai Ak @Aj Ai Aj Ak . follows definition
laminarity Ak unique hence father relation defines tree. Moreover,
definition laminarity, every variable vi P every Di ,
unique minimal assignment-set containing hvi , ai.
construct directed graph GP whose minimum-cost integral flows value n
one-to-one correspondence solutions P. GP following nodes:
1. source node s;
2. variable node vi (i = 1, . . . , n) variable P;
3. assignment node hvi , di (d Di , = 1, . . . , n) possible variable-value
assignment P;
4. assignment-set node Ai (i = 1, . . . , r) assignment-set P;
5. sink node t, identify assignment-set consisting variablevalue assignments.
GP following arcs:
1. = (s, vi ) variable vi P; demand capacity given d(a) =
c(a) = 1 (this forces flow exactly 1 variable node vi ); weight
function given w(a) = 0;
2. = (vi , hvi , di) variables vi Di ; d(a) = 0; c(a) = 1; w(a) = 0;
3. = (hvi , di, Aj ) variables vi Di , Aj minimal
assignment-set containing hvi , di; d(a) = 0; c(a) = 1; w(a) = 0;
4. assignment-set Ai father Aj , arc Ai Aj weight
function gi , demand d(a) = li capacity c(a) = ui .
Clearly, GP constructed P polynomial time. prove
minimum-cost flows f value n GP one-to-one correspondence solutions
P and, furthermore, cost f equal cost P corresponding
solution.
feasible flows value n since n arcs (s, vi ) leaving source
demand capacity equal 1. Flows GP necessarily correspond assignment
unique value xi variable vi since flow 1 node vi must traverse
node hvi , xi unique xi Di . remains show every assignment
x = {hv1 , x1 i, . . . , hvn , xn i} feasible (i.e. whose cost P finite),
corresponding minimum-cost feasible flow f GP cost g(x) = g1 (|x A1 |) + . . . + gr (|x
Ar |).
arc incoming outgoing hvi , di GP , let f (a) = 1
= xi 0 otherwise. construction, assignment-set node Ai GP exactly
477

fiCooper & Zivny

one outgoing arc father assignment-set. flow fa arc Ai father
assignment-set Aj uniquely determined assignment values variables
solution x. Trivially, therefore
P minimum-cost flow corresponding assignment
x. cost flow f clearly gi (|x Ai |) corresponds precisely cost
assignment x.
proved correspondence cost solutions P cost
minimum-cost flows, follows algorithm, given P constructs GP
finds minimum-cost flow, correct.
Example 4.6. Let P VCSP instance 4 variables v1 , v2 , v3 , v4 , D1 = D2 = D3 =
D4 = {0, 1}, assignment-sets Ai , 1 8 given Figure 6. cost functions
gi , 1 8 arbitrary convex functions.
network GP corresponding instance P shown Figure 7: demands capacities square brackets corresponding layer graph, weights
arcs without numbers 0. non-zero weight functions arcs
assignment-sets; arcs corresponding cost functions gi , 1 7. Set
A8 identified sink t. Minimum-cost feasible flows GP correspond assignments P modulo addition constant g8 (4) (since 4 variables
A8 consists variable-value assignments). bold red edges represent flow
f corresponding assignment v1 = v2 = 1 v3 = v4 = 0 total cost
g1 (1) + g2 (0) + g3 (2) + g4 (1) + g5 (0) + g6 (1) + g7 (3). Finding minimum-cost flow GP
equivalent finding optimal solution P.
4.3 Laminar VCSPs Cross-Free VCSPs
alternative way expressing definition cross-freeness every 1 i, j r,
one Ai (A \ Aj ), (A \ Ai ) Aj , Ai Aj , (A \ Ai ) (A \ Aj ) empty. follows directly
A1 , . . . , Ar cross-free A1 , . . . , Ar , (A \ Ai ) 1 r.
show reduce VCSP instance cross-free convexity property
instance satisfying laminar convexity property.
First show without loss generality, assume every Ai satisfies
|Ai | b|A|/2c, 1 r. Let Ai arbitrary |Ai | > b|A|/2c. pointed
above, without loss generality Aj , 1 j r, Aj = \ Ai . (If
Aj among A1 , . . . , Ar , add Aj corresponding convex cost
function constant zero cost function. would double number
assignment-sets.)
Let hi defined hi (y) = gi (n y) let gj0 = gj + hi . Clearly gj0 convex,
furthermore
gj0 (|Aj x|) = gj (|Aj x|) + hi (|Aj x|)
= gj (|Aj x|) + gi (n |Aj x|)
= gj (|Aj x|) + gi (|A x| |Aj x|)
= gj (|Aj x|) + gi (|Ai x|).
eliminate set Ai cost function gi replacing gi , gj single cost
function gj0 .
478

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

A8

A1
A6

A2

hv1 , 0i hv3 , 0i

hv3 , 1i hv2 , 0i

A5
hv4 , 1i

A7
A3

A4

hv2 , 1i hv4 , 0i

hv1 , 1i

Figure 6: Laminar sets assignments instance P Example 4.6.

[1, 1]

[0, 1]

[0, 1]

[li , ui ]

[li , ui ]

hv1 , 0i

hv1 , 1i

A1
v1

hv2 , 0i

v2

hv2 , 1i

g1
A2
g2



A3
v3

hv3 , 0i

v4

hv3 , 1i

A4
A5

A6

g6

A7

g7

g3



g4
g5

hv4 , 0i

hv4 , 1i

Figure 7: Network GP corresponding VCSP P Example 4.6.

479

fiCooper & Zivny

Since sets half size A, Ai Aj = 1 i, j r,
necessarily Aj = \ Ai . However, case, using argument above,
pair complementary sets Ai Aj , eliminate Ai cost function gi
replacing gi , gj single cost function gj0 . Consequently, resulting sets A1 , . . . , Ar
laminar.
Complexity Let P VCSP instance n variables, domain size
d, r laminar assignment-sets Ai . maximum number distinct nonoverlapping sets Ai 2nd 1 since sets assignments Ai form tree nd
leaves (corresponding single hvariable,valuei assignments) non-leaf nodes
least two sons. Thus r = O(nd). network GP n0 = O(n + nd + r) = O(nd)
vertices arcs. GP built O((nd)2 ) time top-down manner, adding
assignment-sets inverse order size (which ensures assignment-set always
inserted father) using table [hv, ai]=smallest assignment-set (in tree
built) containing hv, ai.
network n0 vertices m0 arcs capacities U , minimum convex
cost flow problem solved time O((m0 log U )SP (n0 , m0 )), SP (n0 , m0 )
time compute shortest directed path network n0 vertices m0 edges (Ahuja,
Magnanti, & Orlin, 2005). Using Fibonacci heaps (Fredman & Tarjan, 1987), SP (n0 , m0 ) =
O(m0 + n0 log n0 ) = O(nd log(nd)), since number vertices n0 arcs m0
O(nd). maximum capacity U network GP n. Hence optimal
solution cross-free convex VCSP determined O((nd log n)(nd log(nd))) =
O((nd)2 (log n)(log n + log d)) time.
Remark 4.7. previous work (Cooper & Zivny, 2011b), proved special case
Theorem 4.5 functions gi , 1 r, non-decreasing assignment sets
laminar. (Previously, laminar convexity property non-decreasing functions gi ,
1 r, called non-overlapping convexity property; also, assignment-sets
called assignment-cliques; see Cooper & Zivny, 2011b.)
presented algorithm similar algorithm Cooper & Zivny (2011b) based
finding minimum-cost flow network. main difference require
single arc pair nodes corresponding cost function gi
arbitrary convex function (which necessarily non-decreasing). running time
algorithm thus better running time algorithm previous
work (Cooper & Zivny, 2011b), O(n3 d2 ). improvement mostly due
fact new construction involves O(nd) arcs opposed O((nd)2 ) arcs
previous work (Cooper & Zivny, 2011b). Moreover, algorithm solves strictly bigger
class problems compared previous result (Cooper & Zivny, 2011b). Overall,
solve faster!
Remark 4.8. remark since construction projection-safe (Lee & Leung,
2009), used Soft Global Arc Consistency cross-free convex constraints.
Remark
4.9. VCSP instance P objective function form g(x) =
Pr
i=1 gi (|xAi |), follows definitions test polynomial time whether
P satisfies cross-free convexity property; is, whether gi convex Ai
480

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

cross-free, 1 r. fact, described algorithm requires assignment-sets
Ai functions gi given explicitly.
conference version work (Cooper & Zivny, 2011a), mentioned
recognition problem open problem. fact, problem easily shown intractable.
Given arbitrary VCSP instance P, always exists cross-free convex instance P 0
whose optimal solution coincides fixed optimal solution P. Therefore, finding P 0
impossible polynomial time unless P=NP otherwise arbitrary VCSP instance P
could solved polynomial time using Theorem 4.5.
4.4 Maximality Cross-Free Convexity
section shows relaxing either convexity cross-freeness (in fact, laminarity)
Definition 4.1 leads intractability.
Theorem 4.10. class VCSP instances whose objective function form g(x) =
g1 (|x A1 |) + . . . + gr (|x Ar |) functions gi convex, sets assignments
Ai may overlap, NP-hard, even |Ai | 2 {1, . . . , r} variables
Boolean.
Proof. suffices demonstrate polynomial-time reduction well-known NP-hard
problem Max-2SAT (Garey & Johnson, 1979). Max-2SAT clause l1 l2 (where l1 , l2
literals) equivalent convex cost function g(|x {l1 , l2 }|) g(0) = 1
g(1) = g(2) = 0. therefore possible code instance Max-2SAT using convex
cost functions (on possibly overlapping sets assignments).
Theorem 4.11. class VCSP instances whose objective function form g(x) =
g1 (|x A1 |) + . . . + gr (|x Ar |) sets assignments Ai laminar,
functions gi necessarily convex, NP-hard even |Ai | 3 {1, . . . , r}
variables Boolean.
Proof. give polynomial-time reduction well-known NP-complete problem
3SAT (Garey & Johnson, 1979). Let I3SAT instance 3SAT clauses.
constraint AllEqual(l1 , l2 , l3 ) (where l1 , l2 , l3 literals) equivalent (nonconvex) cost function g(|x {l1 , l2 , l3 }|) g(0) = g(3) = 0 g(1) = g(2) = .
variable v I3SAT , use following gadget Gv based non-overlapping
AllEqual constraints produce multiple copies v1 , . . . , vm variable v multiple
copies w1 , . . . , wm negation v: Gv consists constraints AllEqual(ui , vi , yi )
(i {1, . . . , m}), AllEqual(yi , wi , ui+1 ) (i {1, . . . , 1}), AllEqual(ym , wm , u1 ),
variables ui , yi occur gadget Gv . easy verify Gv imposes
v1 = . . . = vm = w1 = . . . = wm . Furthermore, variables vi , wi occur negatively
Gv . replace ith clause I3SAT clause positive variable v
replaced ith copy vi negative variable v replaced ith copy wi
v. produces laminar VCSP instance equivalent I3SAT (but whose cost
functions convex).
Note NP-hardness reduction proof Theorem 4.11 requires assignmentsets size 3. leaves open complexity laminar (and cross-free) non-convex
VCSPs assignment-sets size 2.
481

fiCooper & Zivny

following result shows complexity cross-free non-convex VCSPs
assignment-sets size 2 domains size polynomial-time equivalent cross-free
non-convex VCSPs assignment-sets size 2 domains size 3.
Proposition 4.12. Cross-free VCSPs assignment-sets size 2 domains
size > 3 polynomial-time equivalent cross-free VCSPs assignment-sets
size 2 domains size 3.
Proof. First observe VCSPs assignment-sets size 2, laminarity
cross-freeness almost identical. extra condition definition cross-freeness
(for A1 , A2 A, A1 A2 6= A1 A2 = A) irrelevant instances
3 variable-value assignments. Hence need prove equivalence laminar
VCSPs.
Let v` D` = {a1 , . . . , ak }, k > 3. replace v` k variables
v`,1 , . . . , v`,k respective domains D`,1 = {1, a1 }, D`,i = {0, 1, ai } = 2, . . . , k 1,
D`,k = {0, ak }. (Here assume, without loss generality, 0 1 different
ai , = 1, . . . , k.) Moreover, introduce k1 new assignment-sets {hv`,i , 1i, hv`,i+1 , 0i}
= 1, . . . , k 1 associated convex function g defined g(1) = 0 g(0) =
g(2) = . Finally, assignment-set involving variable-value assignment hv` , ai
(for {1, . . . , k}), assignment replaced hv`,i , ai i.
function g applied assignment-sets {hv`,i , 1i, hv`,i+1 , 0i} ensures
possible finite-cost assignments variables v`,1 , . . . , v`,k form 1, . . . , 1, ai , 0, . . . , 0.
Since exactly one variables v`,1 , . . . , v`,k assigned value D` , one-toone correspondence optimal solutions transformed instance original
instance.
tractability cross-free non-convex VCSPs assignment-sets size 2
domains size 3 (or larger, Proposition 4.12) left open problem.
case cross-free assignment-sets size 2 Boolean domains shown
tractable Theorem 4.21 Section 4.6.
4.5 Renamable Boolean Cross-Free Convex VCSPs
section extend class cross-free convex VCSPs allow renaming certain
variables case Boolean domains. section consider Boolean
VCSPs.
begin illustrating notion renaming means example. First,
require notation. Cost function AtMostr (A) returns 0 x contains r assignments set assignments A, AtMostr (A) returns 1 otherwise. Similarly,
cost function AtLeastr (A) returns 0 x contains least r assignments set
assignments A, AtLeastr (A) returns 1 otherwise. Note cost functions AtLeast1
AtMostr , r = |A| 1, convex [0, |A|].
Example 4.13. Let P Max-SAT instance given CNF form following clauses:
(a b c),

(c d),

(c e),
482

(a e).

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

Clearly, clause literals written AtLeast1 (A) VCSP encoding
instance. Notice that, example, first two clauses overlapping. However,
replace second clause equivalent constraint AtMost1 ({c, d}).
gives us equivalent problem following constraints:
(a b c),

AtMost1 ({c, d}),

(c e),

(a e).

P expressed instance satisfying cross-free convexity property crossfree sets assignments {a, b, c}, {c, d}, {c, d, e}, {a, e}.
Example 4.13 leads following definitions:
Definition 4.14. Given valued constraint form cost function g(|x A|),
set Boolean assignments (i.e. literals) size m, define renaming
valued constraint, set Boolean assignments = {` | ` A}, valued
constraint g 0 (|x A|) = g(m |x A|) = g(|x A|).
function g 0 (z) = g(m z) clearly convex g convex.
Definition 4.15. Boolean VCSP instance P objective function g1 (|x A1 |) +
. . . + gr (|x Ar |) renamable cross-free convex subset constraints P
whose renaming results equivalent VCSP instance P 0 cross-free convex.
Theorem 4.16. class renamable cross-free convex VCSPs recognisable solvable polynomial time.
Proof. show recognition polynomial-time simple reduction 2-SAT,
well-known problem solvable polynomial time (Garey & Johnson, 1979). Let P
Boolean VCSP instance r constraints ith constraint (i = 1, . . . , r)
gi (|x Ai |) convex function gi . constraint P, Boolean variable
reni indicating whether ith constraint renamed. pair distinct
i, j {1, . . . , r}, add clauses length 2 follows:
1. Ai Aj incompletely overlap add constraint reni renj (since must
rename one two constraints);
2. Ai Aj incompletely overlap add constraint reni renj (to avoid introducing overlap renaming).
easy see solutions constructed 2-SAT instance correspond valid
renamings P give rise equivalent VCSP instance satisfying cross-free
convexity property. Tractability solving resulting renamed instance follows directly
Theorem 4.5.
4.6 Knuth-Nested VCSPs
order relate work previous work, section present different class
tractable VCSPs considers sets variables (rather sets assignments)
allows overlaps size 1. show known tractable class extended
Max-SAT VCSPs. apply result show special case
assumption convexity cross-free convex VCSPs dropped.
483

fiCooper & Zivny

Definition 4.17. Given VCSP instance P variables V = {v1 , . . . , vn } constraints
scopes C = {C1 , . . . , Cm }, define incidence graph P IP = (V (IP ), E(IP )),
V (IP ) = V C E(IP ) = {{vi , Cj } | vi Cj }.
Definition 4.18. VCSP instance P called Knuth-nested variables P
linearly ordered v1 , . . . , vn IP together edges {{vi , vi+1 } | 1
n} {vn , v1 } allows planar drawing circle v1 , . . . , vn , v1 bounds outer face.
P called Knuth-co-nested constraint scopes P linearly ordered C1 , . . . , Cm
IP together edges {{Ci , Ci+1 } | 1 m} {Cm , C1 } allows planar
drawing circle C1 , . . . , Cm , C1 bounds outer face.
Knuth described linear-time algorithm solving Knuth-nested SAT instances (Knuth,
1990). Kratochvl Krivanek generalised Knuths result provided linear-time algorithm recognising solving Knuth-nested Knuth-co-nested SAT/Max-SAT
instances (Kratochvl & Krivanek, 1993). Henderson Masters thesis showed several
different proofs results, including proof Knuth-nested Knuth-co-nested
SAT/Max-SAT instances treewidth three (Biedl & Henderson, 2004; Henderson, 2005), hence solvable polynomial time via standard dynamic programming
approach.
Theorem 4.19. class Knuth-nested Knuth-co-nested VCSP instances constraints bounded arity recognisable solvable polynomial time.
Proof. Recognition reduced, via simple reduction work Kratochvl
Krivanek (1993), planarity testing problem (Hopcroft & Tarjan, 1974).
Following Hendersons argument (2005, p. 21), easy show P Knuthnested Knuth-co-nested, incidence graph IP P treewidth 3.
VCSP domains size d, constraints arity k incidence graph
IP clearly equivalent binary VCSP constraint graph IP domains
size dk . result follows fact VCSP instance
constraint graph bounded treewidth solvable polynomial time (Bertele & Brioshi,
1972).
Note class Knuth-nested (Knuth-co-nested) VCSP instances (in fact, even
SAT instances) cannot generalised follows work Lichtenstein (1982)
satisfiability conjunction two Knuth-nested formulas NP-complete.
show class Knuth-nested/Knuth-co-nested instances section
incomparable class cross-free convex instances defined Section 4.1 even
special case Boolean formulas. Moreover, also show class Knuthnested/Knuth-co-nested instances incomparable class renamable Boolean
cross-free convex instances defined Section 4.5.
Example 4.20. SAT instance = (x y) (y z) (y w) Knuth-nested
Knuth-co-nested, neither cross-free renamable cross-free.
following SAT instance neither Knuth-nested Knuth-co-nested, crossfree (in fact laminar): (x z) (x u v) (y u w) (z v w).
484

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

turn attention cross-free VCSPs possibly non-convex cost functions
assignment-sets size 2. show tractability Boolean VCSP
instances, i.e. instances 2-element domains, follows Theorem 4.19. Recall
case convex cost functions tractable Theorem 4.5, that, Theorem 4.11,
case non-convex cost functions intractable assignments sets size 3.
Theorem 4.21. cross-free Boolean VCSP instance assignment-sets size
2 solvable polynomial time.
Proof. mentioned proof Proposition 4.12, first observe VCSPs
assignment-sets size 2 (or fixed size matter) laminarity cross-freeness
almost identical. extra condition definition cross-freenes (for A1 , A2 A,
A1 A2 6= A1 A2 = A) irrelevant instances 3 variable-value
assignments. Hence need prove tractability laminar Boolean VCSPs
assignment-sets size 2.
show Boolean VCSP laminar assignment-sets size 2
Knuth-nested. Tractability follows Theorem 4.19.
Take arbitrary variable, instance v1 . show order <
variables satisfying requirements Knuth-nested property. Since |D1 | = 2,
two assignment-sets, say Ai Aj , containing (different) assignments v1 .
since assignment-sets size two, one assignment
Ai , say assignment variable vk . define v1 < vk . Similarly, one
assignment Aj , say assignment variable vl , define vl < v1 . Continuing
reasoning variables vl vk , get another variable smaller (in order
< building) vl another variable bigger vk . stop eventually:
either variables, assignment-set size 1, variable
domain size 1, last considered assignment-set contains assignments smallest
biggest variables (in order <). easy observe cases
planar drawing required Definition 4.18. variables left, continue
way.
Next show cross-free VCSPs 3-element domains assignments sets
size 2 may neither Knuth-nested Knuth-co-nested.
Example 4.22. Take four variables x, y, z, w domain {0, 1, 2}, sets A1 =
{hx, 0i, hy, 0i}, A2 = {hy, 1i, hz, 0i}, A3 = {hx, 1i, hz, 1i}, A4 = {hy, 2i, hw, 0i}. instance
cross-free (in fact laminar), neither Knuth-nested Knuth-co-nested.

5. Conclusions
studied hybrid reasons tractability optimisation problems cast
Valued Constraint Satisfaction Problems (VCSPs), equivalently Markov Random Fields
(MRFs) Min-Sum problems. reasons tractability follow
restriction functions (such submodularity) restriction
structure instance (such bounded treewidth).
Firstly, studied binary VCSPs (also known pairwise MRFs). CSP
Max-CSP case, obtained complete dichotomy concerning tractability
485

fiCooper & Zivny

problems defined placing restrictions possible combinations binary costs
triangles variable-value assignments. case finite-valued general-valued
VCSP, obtained complete dichotomies respect equivalence classes
naturally follow total order valuation structure. shown
joint-winner property maximum (weighted) matching non-trivial tractable
classes.
Secondly, studied non-binary VCSPs. presented novel class optimisation problems solved efficiently using flow techniques. new class
defined problems convex functions cross-free family variable-value assignments. shown neither two conditions sufficient
tractability. Moreover, Boolean domains, managed extend new class
using idea renamability.
left open one special case, namely tractability cross-free non-convex
VCSPs assignment-sets size 2 domains size 3. (Assignmentsets size 3 make problem intractable even Boolean domains, assignment-sets
size 2 Boolean domains shown tractable.)

Acknowledgments
Martin Cooper supported ANR Projects ANR-10-BLAN 0210 0214. Stanislav
Zivny supported Junior Research Fellowship University College, Oxford.

References
Ahuja, R., Magnanti, T., & Orlin, J. (2005). Network Flows: Theory, Algorithms,
Applications. Prentice Hall/Pearson.
Bertele, U., & Brioshi, F. (1972). Nonserial dynamic programming. Academic Press.
Biedl, T., & Henderson, P. (2004). Nested SAT Graphs Treewidth Three. Tech. rep.
CS-2004-70, University Waterloo.
Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based Constraint Satisfaction
Optimisation. Journal ACM, 44 (2), 201236.
Boros, E., & Hammer, P. L. (2002). Pseudo-Boolean optimization. Discrete Applied Mathematics, 123 (1-3), 155225.
Bulatov, A., Krokhin, A., & Jeavons, P. (2005). Classifying Complexity Constraints
using Finite Algebras. SIAM Journal Computing, 34 (3), 720742.
Cohen, D., & Jeavons, P. (2006). complexity constraint languages. Rossi, F., van
Beek, P., & Walsh, T. (Eds.), Handbook Constraint Programming. Elsevier.
Cohen, D. A. (2003). New Class Binary CSPs Arc-Constistency Decision
Procedure. Proceedings 9th International Conference Principles
Practice Constraint Programming (CP03), Vol. 2833 Lecture Notes Computer
Science, pp. 807811. Springer.
Cohen, D. A., Cooper, M. C., Green, M., & Marx, D. (2011). guaranteeing polynomiallybounded search tree size. Proceedings 17th International Conference
486

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

Principles Practice Constraint Programming (CP11), Vol. 6876 Lecture
Notes Computer Science, pp. 160171. Springer.
Cohen, D. A., Cooper, M. C., & Jeavons, P. G. (2008). Generalising submodularity Horn
clauses: Tractable optimization problems defined tournament pair multimorphisms.
Theoretical Computer Science, 401 (1-3), 3651.
Cohen, D. A., Cooper, M. C., Jeavons, P. G., & Krokhin, A. A. (2006). Complexity
Soft Constraint Satisfaction. Artificial Intelligence, 170 (11), 9831016.
Cooper, M. C., Jeavons, P. G., & Salamon, A. Z. (2010). Generalizing constraint satisfaction
trees: Hybrid tractability variable elimination. Artificial Intelligence, 174 (9
10), 570584.
Cooper, M. C., & Zivny, S. (2011a). Hierarchically nested convex VCSP. Proceedings
17th International Conference Principles Practice Constraint Programming (CP11), Vol. 6876 Lecture Notes Computer Science, pp. 187194.
Springer.
Cooper, M. C., & Zivny, S. (2011b). Hybrid tractability valued constraint problems.
Artificial Intelligence, 175 (9-10), 15551569.
Cooper, M. C., & Zivny, S. (2011c). Tractable triangles. Proceedings 17th International Conference Principles Practice Constraint Programming (CP11),
Vol. 6876 Lecture Notes Computer Science, pp. 195209. Springer.
Creignou, N., Khanna, S., & Sudan, M. (2001). Complexity Classification Boolean Constraint Satisfaction Problems, Vol. 7 SIAM Monographs Discrete Mathematics
Applications. SIAM.
Dalmau, V., Kolaitis, P. G., & Vardi, M. Y. (2002). Constraint Satisfaction, Bounded
Treewidth, Finite-Variable Logics. Proceedings 8th International Conference Principles Practice Constraint Programming (CP02), Vol. 2470
Lecture Notes Computer Science, pp. 310326. Springer.
Dechter, R., & Pearl, J. (1988). Network-based Heuristics Constraint Satisfaction Problems. Artificial Intelligence, 34 (1), 138.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Downey, R., & Fellows, M. (1999). Parametrized Complexity. Springer.
Edmonds, J. (1965a). Maximum Matching Polyhedron 0, 1 Vertices. Journal
Research National Bureau Standards, 69 B, 125130.
Edmonds, J. (1965b). Paths, trees, flowers. Canadian Journal Mathematics, 17,
449467.
Feder, T., & Vardi, M. Y. (1998). Computational Structure Monotone Monadic
SNP Constraint Satisfaction: Study Datalog Group Theory. SIAM
Journal Computing, 28 (1), 57104.
Fredman, M. L., & Tarjan, R. E. (1987). Fibonacci heaps uses improved network
optimization algorithms. Journal ACM, 34 (3), 596615.
487

fiCooper & Zivny

Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W.H. Freeman.
Geman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions,
bayesian restoration images. IEEE Transactions Pattern Analysis Machine
Intelligence, 6 (6), 7210741.
Goodman, A. W. (1959). Sets Acquaintances Strangers Party.
American Mathematical Monthly, 66 (9), 778783.
Grohe, M. (2007). complexity homomorphism constraint satisfaction problems
seen side. Journal ACM, 54 (1), 124.
Henderson, P. (2005). Planar Graphs Partial k-Trees. Masters thesis, University
Waterloo.
Hooker, J. (2007). Integrated Method Optimization. Springer.
Hopcroft, J. E., & Tarjan, R. E. (1974). Efficient planarity testing. Journal ACM,
21 (4), 549568.
Jeavons, P. G. (1998). Algebraic Structure Combinatorial Problems. Theoretical
Computer Science, 200 (1-2), 185204.
Jonsson, P., Kuivinen, F., & Nordh, G. (2008). MAX ONES Generalized Larger Domains.
SIAM Journal Computing, 38 (1), 329365.
Jonsson, P., Kuivinen, F., & Thapper, J. (2011). Min CSP Four Elements: Moving
Beyond Submodularity. Proceedings 17th International Conference Principles Practice Constraint Programming (CP11), Vol. 6876 Lecture Notes
Computer Science, pp. 438453. Springer.
Jonsson, P., & Nordh, G. (2008). Introduction maximum solution Problem.
Complexity Constraints, Vol. 5250 Lecture Notes Computer Science, pp. 255
282. Springer.
Khanna, S., Sudan, M., Trevisan, L., & Williamson, D. (2001). approximability
constraint satisfaction problems. SIAM Journal Computing, 30 (6), 18631920.
Knuth, D. E. (1990). Nested satisfiability. Acta Informatica, 28 (1), 16.
Kolmogorov, V. (2011). Submodularity tree: Unifying l] -convex bisubmodular
functions. Proceedings 36th International Symposium Mathematical Foundations Computer Science (MFCS11), Vol. 6907 Lecture Notes Computer
Science, pp. 400411. Springer.
Kolmogorov, V., & Zivny, S. (2012). complexity conservative valued CSPs.
Proceedings 23rd Annual ACM-SIAM Symposium Discrete Algorithms
(SODA12), pp. 750759. SIAM. Full version available arXiv:1110.2809.
Kratochvl, J., & Krivanek, M. (1993). Satisfiability co-nsted formulas. Acta Informatica,
30 (4), 397403.
Lauritzen, S. L. (1996). Graphical Models. Oxford University Press.
488

fiTractable Triangles Cross-Free Convexity Discrete Optimisation

Lee, J. H.-M., & Leung, K. L. (2009). Towards efficient consistency enforcement global
constraints weighted constraint satisfaction. Proceedings 21st International
Joint Conference Artificial Intelligence (IJCAI09), pp. 559565.
Lewis, J. M., & Yannakakis, M. (1980). node-deletion problem hereditary properties
NP-complete. Journal Computer System Sciences, 20 (2), 219230.
Lichtenstein, D. (1982). Planar formulae uses. SIAM Journal Computing,
11 (2), 329343.
Lovasz, L. (1973). Coverings colorings hypergraphs. Proceedings 4th
Southeastern Conference Combinatorics, Graph Theory Computing, pp. 312.
Maffray, F., & Preissmann, M. (1996). NP-completeness k-colorability problem
triangle-free graphs. Discrete Mathematics, 162 (1-3), 313317.
Marx, D. (2010). Tractable hypergraph properties constraint satisfaction conjunctive queries. Proceedings 42nd ACM Symposium Theory Computing
(STOC10), pp. 735744.
Meseguer, P., Rossi, F., & Schiex, T. (2006). Soft constraints. Rossi, F., van Beek, P.,
& Walsh, T. (Eds.), Handbook Constraint Programming. Elsevier.
Minoux, M. (1984). polynomial algorithm minimum quadratic cost flow problems.
European Journal Operational Research, 18, 377387.
Minoux, M. (1986). Solving integer minimum cost flows separable convex cost objective
polynomially. Mathematic Programming Studies, 26, 237239.
Montanari, U. (1974). Networks Constraints: Fundamental properties applications
picture processing. Information Sciences, 7, 95132.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.
Papadimitriou, C. H., & Yannakakis, M. (1991). Optimization, Approximation, Complexity Classes. Journal Computer System Sciences, 43 (3), 425440.
Poljak, S. (1974). note stable sets colorings graphs. Commentationes Mathematicae Universitatis Carolinae, 15 (2), 307309.
Regin, J.-C. (1994). filtering algorithm constraints difference CSPs. Proceedings
12th National Conference AI (AAAI94), Vol. 1, pp. 362367.
Regin, J.-C. (1996). Generalized Arc Consistency Global Cardinality Constraint.
Proceedings 13th National Conference AI (AAAI96), Vol. 1, pp. 209215.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). Handbook Constraint Programming. Elsevier.
Schaefer, T. J. (1978). Complexity Satisfiability Problems. Proceedings 10th
Annual ACM Symposium Theory Computing (STOC78), pp. 216226. ACM.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued Constraint Satisfaction Problems:
Hard Easy Problems. Proceedings 14th International Joint Conference
Artificial Intelligence (IJCAI95), pp. 631637.
Schrijver, A. (2003). Combinatorial Optimization: Polyhedra Efficiency, Vol. 24
Algorithms Combinatorics. Springer.
489

fiCooper & Zivny

Takhanov, R. (2010). Dichotomy Theorem General Minimum Cost Homomorphism Problem. Proceedings 27th International Symposium Theoretical
Aspects Computer Science (STACS10), pp. 657668.
van Hoeve, W. J., Pesant, G., & Rousseau, L.-M. (2006). global warming: Flow-based
soft global constraints. Journal Heuristics, 12 (4-5), 347373.
Wainwright, M. J., & Jordan, M. I. (2008). Graphical models, exponential families,
variational inference. Foundations Trends Machine Learning, 1 (1-2), 1305.
Werner, T. (2007). Linear Programming Approach Max-Sum Problem: Review.
IEEE Transactions Pattern Analysis Machine Intelligence, 29 (7), 11651179.
Zanarini, A., & Pesant, G. (2007). Generalizations global cardinality constraint hierarchical resources. Proceedings 4th International Conference Integration
AI Techniques Constraint Programming Combinatorial Optimization Problems (CPAIOR07), Vol. 4510 Lecture Notes Computer Science, pp.
361375. Springer.

490

fiJournal Artificial Intelligence Research 44 (2012) 633-708

Submitted 11/11; published 08/12

Logical Difference
Lightweight Description Logic EL
Boris Konev
Michel Ludwig

konev@liverpool.ac.uk
michel.ludwig@liverpool.ac.uk

Department Computer Science
University Liverpool, UK

Dirk Walther

dirk.walther@upm.es

Departamento Inteligencia Artificial, Facultad de Informatica
Universidad Politecnica de Madrid, Spain

Frank Wolter

wolter@liverpool.ac.uk

Department Computer Science
University Liverpool, UK

Abstract
study logic-based approach versioning ontologies. view, ontologies
provide answers queries vocabulary interest. difference
two versions ontology given set queries receive different answers.
investigate approach terminologies given description logic EL extended
role inclusions domain range restrictions three distinct types queries:
subsumption, instance, conjunctive queries. three cases, present polynomialtime algorithms decide whether two terminologies give answers queries
given vocabulary compute succinct representation difference nonempty. present implementation, CEX2, developed algorithms subsumption
instance queries apply distinct versions Snomed CT NCI ontology.

1. Introduction
Terminologies lightweight ontologies used provide common vocabulary
domain interest together descriptions meaning terms built
vocabulary relationships them. used areas medical
informatics, bio-informatics, semantic web capture domain semantics promote interoperability. Terminologies often large complex. example, widely
used medical terminology Snomed CT (Systematized Nomenclature Medicine Clinical
Terms) contains 300 000 term definitions (IHTSDO, 2008). Another example
National Cancer Institute ontology (NCI) consisting 60 000 axioms (Golbeck, Fragaso, Hartel, Hendler, Oberhaler, & Parsia, 2003). Engineering, maintaining,
using terminologies complex laborious task, practically unfeasible
without appropriate tool support. article, focus principled logic-based
approach support terminology versioning.
Dealing multiple versions information unit nothing new computing, version control well established computer technology. Although modern version
control systems provide range operations including support collaborative development, branching, merging, etc., operations extend rely basic operations
c
2012
AI Access Foundation. rights reserved.

fiKonev, Ludwig, Walther, & Wolter

detecting representing differences versions. paper, focus
basic problem versioning.
need versioning support recognised ontology research community
ontology users, large number approaches tools developed.
review currently existing support ontology versioning, distinguish three approaches
describe according difference ontologies compute:
1. versioning based syntactic difference (syntactic diff);
2. versioning based structural difference (structural diff);
3. versioning based logical difference (logical diff).
syntactic diff underlies existing version control systems used software development (Conradi & Westfechtel, 1998) (such as, example, RCS, CVS, SCCS). works
text files represents difference versions blocks text present one
version another, ignoring meta-information document. observed
already work Noy Musen (2002), ontology versioning cannot rely purely
syntactic diff operation since many syntactic differences (e.g., order ontology axioms)
affect semantics ontologies. Therefore, ontology versioning based syntactic
difference essentially limited comparing rather informal change logs (Oliver, Shahar,
Shortliffe, & Musen, 1999).
structural diff extends syntactic diff taking account information
structure ontologies. suggested dealing structured hierarchical documents UML diagrams, database schemas, XML documents (see, e.g.,
Ohst, Welle, & Kelter, 2003, references within). ontologies, main characteristic
structural diff regards structured objects, is-a taxonomy (Noy & Musen, 2002), set RDF triplets (Klein, Fensel, Kiryakov, & Ognyanov,
2002) set class defining axioms (Redmond, Smith, Drummond, & Tudorache, 2008;
Jimenez-Ruiz, Cuenca Grau, Horrocks, & Llavori, 2011). Changes ontologies mostly
described terms structural operations, example, adding deleting class, extending class, renaming slots, moving class one place hierarchy another,
adding deleting axiom, class renaming, etc.; sometimes basic logical properties
ontologies, e.g., equivalence different structural forms concepts, also taken
account (Palma, Haase, Corcho, & Gomez-Perez, 2009; Jimenez-Ruiz et al., 2011). Ontology versioning based structural diff form available current ontology
editors ontology management systems either natively plugins (Noy & Musen,
2002; Klein et al., 2002; Jimenez-Ruiz et al., 2011).
Though helpful, structural diff still deficiency unambiguous semantic foundation syntax dependent. Moreover, tailored towards
applications ontologies based induced concept hierarchy (or mild
extension it), capture modern applications ontology based data access (OBDA) (Poggi, Lembo, Calvanese, Giacomo, Lenzerini, & Rosati, 2008; Lutz, Toman,
& Wolter, 2009) ontologies used provide user-oriented view data
634

fiThe Logical Difference Lightweight Description Logic EL

make accessible via queries formulated solely language ontology without
knowledge actual structure data.1
logical diff recently introduced (Konev, Walther, & Wolter, 2008;
Kontchakov, Wolter, & Zakharyaschev, 2010) completely abstracts representation ontology. Here, ontology regarded set axioms formulated logical
language formal unambiguous semantics. view, ontologies provide
answers queries vocabulary interest. Typical queries include subsumption
queries concepts and, ontology used access instance data, instance
conjunctive queries. logical diff motivated view. two versions ontology
give answers class queries relevant application domain, may
deemed difference regardless syntactic structural form; queries
producing different answers versions may considered characterisation
difference itself. way one can, example, define exactly differences visible
querying instance data exactly differences expressed subsumptions
concepts.
make approach work practice, least two problems addressed:
ontology languages classes queries computational complexity
even detecting two ontology versions differ certain vocabulary least
one exponential harder ontology classification sometimes undecidable;
even computational complexity increase, searching differences
ontologies within certain vocabulary requires techniques different used standard reasoning (Lutz, Walther, & Wolter, 2007; Lutz
& Wolter, 2010; Cuenca Grau, Horrocks, Kazakov, & Sattler, 2008).
set queries producing different answers two versions empty,
typically infinite and, therefore, cannot presented user such. Thus,
techniques succinctly characterise elements present user
required.
aim paper provide first steps toward solutions problems
terminologies (aka classical TBoxes) given description logic ELHr extends
description logic EL underlying OWL 2 EL profile role inclusions domain
range restrictions (Baader, Brandt, & Lutz, 2008). main contributions follows:
1. argued syntax-dependence regarded advantage rather deficiency
context versioning (Goncalves, Parsia, & Sattler, 2011; Jimenez-Ruiz et al., 2011). example, Jimenez-Ruiz et al. argue logical equivalence ontologies permissive: even
O0 strongest assumption semantic point view conflicts may still exist. might
result presence incompatible annotations (statements act comments carry
logical meaning), mismatch modelling styles; example, may written simple language
OWL 2 EL profile contain = (A v B u C), O0 may contain = (B C v A).
Even though , explicit use negation disjunction means O0 outside EL profile.
agree Jimenez-Ruiz et al. Goncalves et al. various applications
structural rather logical difference appropriate. Even syntactic diff applications ontology
versioning. practice, see logic-based approaches complementary structural approaches.
interesting analysis NCI versions taking account structural logical differences given
work Goncalves et al.

635

fiKonev, Ludwig, Walther, & Wolter

subsumption, instance, conjunctive queries, present polynomial-time algorithms
decide whether two ELHr -terminologies give different answers query
respective class queries given signature concept role names (note
use terms signature vocabulary synonymously).
Besides polynomial-time decision procedure detecting differences, also develop
succinct presentation (typically infinite) difference. presentation computed polynomial time well.
present two different types polynomial-time algorithms deciding existence
logical differences terminologies computing succinct representation
it: first type algorithms conceptually transparent keeps two
input terminologies separate reduces (a substantial part of) difference problem
instance checking problem ABox. algorithms are, however, sufficiently
efficient large inputs. example, substantial performance problems occur
computing differences versions Snomed CT joint signature since
constructed ABox typically quadratic size input terminologies. second
variant algorithms, based dynamic programming, efficient practice.
developed detail acyclic ELHr -terminologies.
present implementation, CEX2, based second type algorithms
computes succinct representation difference acyclic ELHr -terminologies
concept instance query case. addition, prototype implementation
ABox-based algorithm used estimate efficiency.
important tool investigation, present description logics, ELran
ELran,u,u , capture subsumption differences instance query difference ELHr -terminologies. result presented general ELHr -TBoxes can,
therefore, exploited future work versioning general ELHr -TBoxes.
present experiments using CEX2 illustrate efficiency algorithms
potential applications terminologies Snomed CT NCI. plugin Protege
discussed. CEX2 extends functionality first version CEX (Konev, Walther, &
Wolter, 2008) OwlDiff plugin (Kremen, Smd, & Kouba, 2011), implements
algorithms developed Konev, Walther, Wolter. Based Snomed CT, also
investigate performance ABox-based algorithms practice.
paper based on, extends work Konev, Walther, Wolter (2008).
improve readability, number proofs deferred appendix.

2. Preliminaries
Let NC , NR , NI countably infinite mutually disjoint sets concept names, role
names, individual names. EL-concepts C built according rule
C :=



|

>

| C uD

|

r.C,

NC , r NR , C, range EL-concepts. set ELHr -inclusions
consists
concept inclusions C v D, ran(r) v ran(r) u C v D,
636

fiThe Logical Difference Lightweight Description Logic EL

concept equations C D,
role inclusions r v s,
C EL-concepts r, NR . ELHr -TBox finite set ELHr inclusions. Inclusions form ran(r) v ran(r)uC v also referred range
restrictions, inclusions form r.> v referred domain restrictions.
ELHr -TBox called ELHr -terminology concept inclusions equations
form
v C C,
ran(r) v C,
r.> v C,
NC r NR , C EL-concept C 6= >, C 6= > u >, etc.,
concept name occurs left-hand side. Note that, concept inclusions
form r.> v C, concept r.> often denoted dom(r). terminology acyclic
(or unfoldable) process exhaustively substituting definitions place defined
concept names terminates. example, terminology contains concept inclusion
Mother v hasMother.Mother
acyclic. Formally, consider relation concept names setting
B exists ELHr -inclusion form C v C B
occurs C. terminology acyclic transitive closure +
irreflexive.
description logic, instance data represented ABox assertions form >(a),
A(a) r(a, b), a, b NI , NC , r NR . ABox non-empty finite
set ABox-assertions. said singleton ABox contains exactly one ABox
assertion. obj(A) denote set individual names A. knowledge base K (KB)
pair (T , A) consisting TBox ABox A. Assertions form C(a)
r(a, b), a, b NI , C EL-concept, r NR , called instance assertions. Note
instance assertions form C(a) C concept name C = >
occur ABoxes.
semantics ELHr given interpretations = (I , ), domain
non-empty set, function mapping concept name subset AI
, role name r binary relation rI , individual name
element aI . extension C concept C defined induction follows:
>I
(C u D)I
(r.C)I
ran(r)I

:=
:=
:=
:=


C DI
{d | e C : (d, e) rI }
{d | e : (e, d) rI }

satisfies
concept inclusion C v D, symbols |= C v D, C DI ;
637

fiKonev, Ludwig, Walther, & Wolter

concept equation C D, symbols |= C D, C = DI ;
role inclusion r v s, symbols |= r v s, rI sI ;
assertion C(a), symbols |= C(a), aI C ,
assertion r(a, b), symbols |= r(a, b), (aI , bI ) rI .
say interpretation model TBox (ABox A) |=
( A). ELHr -inclusion follows TBox every model model
, symbols |= . |= used denote follows empty TBox
sometimes write r vT |= r v s. instance assertion follows KB (T , A)
every individual name occurs also occurs obj(A) every model (T , A)
model , symbols (T , A) |= . important ways querying ELHr -TBoxes
KBs
subsumption: check whether |= , ELHr -inclusion TBox ,
instance checking: check whether (T , A) |= , instance assertion KB
(T , A),
conjunctive query answering.
define latter, call first-order formula q(~x) conjunctive query form
~y (~x, ~y ), conjunction expressions A(t), NC , r(t1 , t2 ), r NR ,
t, t1 , t2 drawn NI sequences variables ~x ~y . Let ~x = x1 , . . . , xk . Let
interpretation mapping ~x ~y . Set (a) = aI obj(A).
say vector ~a = a1 , . . . , ak -match q(~x) satisfies following
conditions:
(t) AI every conjunct A(t) ;
((t1 ), (t2 )) rI every conjunct r(t1 , t2 ) ;
(xi ) = aIi 1 k.
set |= q[~a] if, if, exists ~a -match q(~x) I. Let
(T , A) KB. sequence ~a members obj(A) certain answer q(~x)
KB (T , A), symbols (T , A) |= q(~a), |= q[~a], every model (T , A).
three types querying ELHr -TBoxes studied extensively. complexity
subsumption instance checking PTime (Baader et al., 2008). combined
complexity answering Boolean conjunctive queries (i.e., deciding whether (T , A) |= q
conjunctive query q without free variables) coNP-complete (Rosati, 2007) data
complexity PTime (Rosati, 2007). Information reasoners subsumption checking
ELHr found work Delaitre Kazakov (2009), Kazakov, Krotzsch,
Simancik (2011), Mendez Suntisrivaraporn (2009). Lutz et al. (2009) present
approach efficient conjunctive query answering ELHr .
638

fiThe Logical Difference Lightweight Description Logic EL

2.1 Normal Form
often convenient consider normalised ELHr -terminologies. Let ELHr terminology concept name. Call
primitive NC \ ({A NC | C } {A NC | v C });
pseudo-primitive NC \ {A NC | C }.
Note concept names occur primitive pseudo-primitive .
Call concept name non-conjunctive pseudo-primitive exists
concept form r.C r.C . Otherwise, called conjunctive
. Thus, conjunctive if, if, exists concept name B
B exist C1 , . . . , Cn , n 2, C1 u u Cn . Let X
finite set
concepts. say concept F conjunction concepts X F
form DX D. X called conjunct F and, concept name,
called atomic conjunct F . sometimes write F instead X.
ELHr -terminology normalised consists ELHr -inclusions following
form:
r.B, F , A, B concept names F non-empty conjunction
concept names every conjunct B 0 F non-conjunctive ;
E v r.B, E v r.>, E v F , B concept name, E either concept
name, form s.>, ran(s), F non-empty conjunction concept
names every conjunct B 0 F non-conjunctive .
following lemma shows, ELHr -terminology normalised yielding
model conservative extension original terminology.
Lemma 1. every ELHr -terminology , one construct polynomial time normalised terminology 0 polynomial size |T | sig(T ) sig(T 0 ), 0 |= ,
every model exists model J 0 = J X = X J
every X sig(T ). Moreover, 0 acyclic acyclic.
Normalised terminologies sense defined minor modification normalised terminologies defined Baader (2003). straightforward extension
proof given Baader provided appendix.
2.2 Canonical Model
define canonical model, IK , ELHr -knowledge bases K. IK constructed
polynomial time gives answers instance queries K; i.e., IK |= if,
if, K |= , instance assertion . construction similar canonical
model introduced Lutz et al. (2009).
Let sub(T ) denote set subconcepts concepts used , rol(T ) set
role names occurring . Take fresh individual names xran(r),D every r rol(T )
sub(T ) set
NIaux := {xran(r),D | r rol(T ) sub(T )}.
639

fiKonev, Ludwig, Walther, & Wolter

define generating interpretation WK KB K = (T , A) follows:
W K
AW K
r WK

aWK

:= obj(A) NIaux ;
:= {a obj(A) | K |= A(a)} {xran(r),D NIaux | |= ran(r) u v A};
:= {(a, b) obj(A) obj(A) | s(a, b) |= v r}
{(a, xran(s),D ) obj(A) NIaux | K |= s.D(a) |= v r}
{(xran(s),D , xran(s0 ),D0 ) NIaux NIaux | |= ran(s) u v s0 .D0 , |= s0 v r};
:= a, obj(A).

path WK finite sequence d0 r1 d1 rn dn , n 0, d0 obj(A) and, < n,
WK
(di , di+1 ) ri+1
. use paths(WK ) denote set paths WK . p paths(WK ),
tail(p) denotes last element dn p.
canonical model IK knowledge base K restriction WK domain
elements path WK tail d. following result summarises
main properties IK .
Theorem 2. Let K = (T , A) ELHr -KB.
1. IK model K;
2. IK computed polynomial time size K;
3. xran(s),D IK obj(A), C EL-concept C = ran(r),
K |= C(a) if, if, aIK C IK .
|= ran(s) u v C if, if, xran(s),D C IK .
proof Theorem 2 given appendix. follows Point 3 IK gives
answers instance queries K itself.

3. Logical Difference
section, introduce three notions logical difference TBoxes
derived notion -inseparability. Intuitively, logical difference two TBoxes T1
T2 set relevant formulas T1 |= T2 6|= vice
versa. course, formulas relevant depends application domain. many
applications subsumptions concepts relevant, TBoxes employed
access instance data, answers instance even conjunctive queries relevant
well. addition, applications large-scale terminologies Snomed CT
NCI typically small subset vocabulary terminology relevant.
Thus, meaningful notion logical difference take account formulas
given certain signature interest, signature subset NC NR .
Given concept, role, concept inclusion, TBox, ABox, query E, denote sig(E)
signature E, is, set concept role names occurring it. call E
-concept, -concept inclusion, -TBox, -ABox, -query, respectively, sig(E) .
Similarly, EL -concept C EL-concept sig(C) ELHr -inclusion
ELHr -inclusion sig() .
first notion logical difference introduce corresponds applications
subsumptions relevant.
640

fiThe Logical Difference Lightweight Description Logic EL

Definition 3 (-concept difference). -concept difference ELHr -TBoxes T1
T2 set cDiff (T1 , T2 ) ELHr -inclusions T1 |= T2 6|= .
say T1 T2 -concept inseparable, symbols T1 C
T2 , cDiff (T1 , T2 ) =
cDiff (T2 , T1 ) = .
-concept inseparability T1 T2 means T1 replaced T2
application concerned ELHr -inclusions.2 following example
shows, however, -concept inseparable terminologies give different answers
instance query data.
Example 4. Let T1 = {ran(r) v A1 , ran(s) v A2 , B A1 u A2 }, T2 = , = {r, s, B}.
One show T1 T2 -concept inseparable. However, -ABox =
{r(a, c), s(b, c)} (T1 , A) |= B(c) (T2 , A) 6|= B(c).
take account differences TBoxes relevant TBoxes
used access instance data, consider -instance difference.
Definition 5 (-instance difference). -instance difference TBoxes T1 T2
set iDiff (T1 , T2 ) pairs form (A, ), -ABox -instance
assertion (T1 , A) |= (T2 , A) 6|= . say T1 T2 -instance
inseparable, symbols T1 T2 , iDiff (T1 , T2 ) = iDiff (T2 , T1 ) = .
contrast ELHr , shown Lutz Wolter (2010) EL-TBoxes
difference -concept inseparability -instance inseparability.
paper extend result ELHr -TBoxes without range restrictions (the proof
given Corollary 37):
Theorem 6. Let T1 T2 ELHr -TBoxes without range restrictions signature.

T1 C
T2 if, if, T1 T2 .
Sometimes, instance queries sufficiently expressive, conjunctive queries
employed. case, following notion difference appropriate.
Definition 7 (-query-difference). -query difference TBoxes T1 T2
set qDiff (T1 , T2 ) pairs form (A, q(~a)), -ABox, q(~x) conjunctive query, ~a tuple individual names (T1 , A) |= q(~a)
(T2 , A) 6|= q(~a). say T1 T2 -query inseparable, symbols T1 q ,
qDiff (T1 , T2 ) = qDiff (T2 , T1 ) = .
observed Lutz Wolter (2010) already, even EL -instance inseparability
imply -query inseparability. following simple example.
Example 8. Let T1 = {A v r.B}, T2 = , = {A, B}. T1 T2 -instance
inseparable, -query inseparable. Consider -ABox = {A(a)}
-query q = x.B(x). (T1 , A) |= q (T2 , A) 6|= q.
2. refer reader conclusion paper brief discussion claim.

641

fiKonev, Ludwig, Walther, & Wolter

shown Lutz Wolter (2010) Example 8 essentially situation
difference -instance inseparability -query inseparability
EL: two notions become equivalent EL universal role admitted instance
queries (e.g., Example 8, conjunctive query x.B(x) corresponds instance query
u.B(a) universal role u). contrast, ELHr subtle differences
instance query case.
Example 9. Let T1 = {A v s.>, v r1 , v r2 }, T2 = {A v r1 .> u r2 .>}, =
{A, r1 , r2 }. T1 T2 -concept -instance inseparable,
-query inseparable. show latter, let = {A(a)} let q = x(r1 (a, x) r2 (a, x)).
(T1 , A) |= q (T2 , A) 6|= q.
seen -concept inseparability imply -instance inseparability
-instance inseparability imply -query inseparability. converse
implications, however, hold:
Lemma 10. ELHr -TBoxes T1 T2 signatures :
T1 q T2



T1 T2



T1 C
T2 .

Proof. first implication follows observation every instance query
regarded conjunctive query. second implication, note first v r
cDiff (T1 , T2 ), ({s(a, b)}, r(a, b)) iDiff (T1 , T2 ). let C v cDiff (T1 , T2 ).
One construct -ABox AC individual EL-concepts D0 :
(T , AC ) |= D0 (a) if, if, |= C v D0 (cf. Lemma 36). Thus (AC , D(a))
iDiff (T1 , T2 ).
introduced three notions difference ELHr -TBoxes, investigate two problems: (i) detect whether difference two ELHr terminologies and, so, (ii) represent differences.
follows assume fresh symbols used normalised form terminologies occur signature compute difference
terminologies. obtain following lemma direct corollary Lemma 1.
Lemma 11. ELHr -terminologies T1 , T2 normalised forms T10 , T20
defined Lemma 1, following hold:
cDiff (T1 , T2 ) = cDiff (T10 , T20 );
iDiff (T1 , T2 ) = iDiff (T10 , T20 );
qDiff (T1 , T2 ) = qDiff (T10 , T20 ).
on, unless stated otherwise, consider normalised terminologies only.
642

fiThe Logical Difference Lightweight Description Logic EL

4. Case EL-Terminologies
investigating logical difference ELHr -terminologies, illustrate main
ideas behind proofs considering -concept difference EL-terminologies.
EL-terminology ELHr -terminology consisting EL-inclusions only, is, concept
inclusions form v C concept equations form C. start
observation even acyclic EL-terminologies T1 T2 cDiff (T1 , T2 )
contains inclusions least exponential size only. Thus, searching witness
inclusions cDiff (T1 , T2 ), one deal case witness inclusions
least exponential size.
Example 12. Consider
T1 = {A0 v B0 , A1 Bn } {Bi+1 r.Bi u s.Bi | 0 < n}
T2 = {A1 v F0 } {Fi v r.Fi+1 u s.Fi+1 | 0 < n}
= {A0 , A1 , r, s}. concept inclusion cDiff (T1 , T2 ) minimal size given
Cn v A1 ,
C0 = A0 Ci+1 = r.Ci u s.Ci , 0.
Clearly, Cn exponential size. Note, however, use structure sharing define
size Cn number subconcepts, Cn polynomial size.
derive basic properties EL-terminologies using sequent calculus.
4.1 Proof System EL
derive basic properties EL Gentzen-style sequent calculus presented Hofmann (2005); see Figure 1. calculus operates sequents form C v D,
C, EL-concepts; symbol v treated syntactic separator. derivation
(or, equivalently, proof ) sequent C v finite rooted tree whose nodes labelled
sequents, whose root labelled C v D, whose leaves labelled axioms
(instances Ax AxTop) whose internal nodes labelled result
application one inference rules labels children. length
derivation number rule applications derivation.
Example 13. Let = {A B1 uB2 , F v B1 }. derivation sequent r.(F uB2 ) v
r.A shown below. root derivation labelled r.(F u B2 ) v r.A
two leaves B1 v B1 B2 v B2 , respectively.
(Ax)

B1 v B1
(PDefL)
(Ax)
F v B1
B2 v B2
(AndL1)
(AndL2)
F u B2 v B1
F u B2 v B2
(AndR)
F u B2 v B1 u B2
(DefR)
F u B2 v
(Ex)
r.(F u B2 ) v r.A
643

fiKonev, Ludwig, Walther, & Wolter

CvC

(Ax)

Cv>

(AxTop)

CvE
(AndL1)
C uD

CvE CvD
(AndR)
C vDuE
CA v
(DefL)
AvD

CvD
(Ex)
r.C v r.D

v CA
(DefR)
DvA

CA v
(PDefL)
AvD

DvE
(AndL2)
C uD

CA

v CA

Figure 1: Gentzen-style proof system EL-terminologies.
Notice basic calculus Hofmann (2005) considers EL without constant >
terminologies without concept inclusions. take care >, added
rule (AxTop), (PDefL) rule representing inclusions form v C. Cutelimination, completeness, correctness shown straightforward extension
proof given Hofmann.
terminology concepts C, D, write ` C v if, if, exists
proof C v calculus Figure 1.
Theorem 14 (Hofmann). EL-terminologies concepts C, D, holds
|= C v if, if, ` C v D.
apply calculus derive description syntactic form concepts C
|= C v D, non-conjunctive .
Lemma 15. Let normalised EL-terminology, r role name, concept name
EL-concept.
1. Assume
|=

l

Ai u

1in

l

rj .Cj v A,

1jm

pseudo-primitive , Ai concept names 1 n, Cj ELconcepts 1 j m, m, n 0. exists Ai , 1 n,
|= Ai v A.
2. Assume
|=

l
1in

l

Ai u

rj .Cj v r.D,

1jm

Ai concept names 1 n, Cj EL-concepts 1 j m,
m, n 0.
exists Ai , 1 n, |= Ai v r.D
exists rj , 1 j m, rj = r |= Cj v D.
644

fiThe Logical Difference Lightweight Description Logic EL



Proof. use Theorem 14. First, prove Point 1. Let C = 1in Ai u 1jm rj .Cj
assume |= C v A, pseudo-primitive . Let proof C v A.
Note that, since pseudo-primitive (and concept name), inspecting form
conclusions inference rules, one see root derivation
derived either Ax, AndL1, AndL2, DefL, PDefL. show
exists Ai , 1 n, |= Ai v induction n + m, i.e.
number conjuncts C. easy see n + 1 6|= > v definition
terminologies .
base case n + = 1 trivial: root derived one
Ax, DefL, PDefL; so, conclude C = A1 ; i.e. n = 1, = 0, set
Ai = A1 .
Assume n + > 1. root derived either AndL1
AndL2. cases, premise used application either inference rule
sequent C 0 v either C = C 0 u C = u C 0 EL-concept D.
Thus, C 0 contains less conjuncts C (but still least one). also conclude
|= C 0 v holds Theorem 14. applying induction hypothesis, hence
exists concept name Ai conjunct C 0 |= Ai v A. Finally, still
note Ai also conjunct C.


prove Point 2. Let C = 1in Ai u 1jm rj .Cj assume |= C v r.D.
Let proof C v r.D. Note due form right-hand side sequent
C v r.D, rule used derive root one Ax, AndL1,
AndL2, DefL, PDefL, Ex. prove either exists Ai , 1 n,
|= Ai v r.D, exists rj , 1 j m, rj = r |= Cj v
induction n + again. Similarly above, n + 1.
n + = 1, rule used derive root one Ax, DefL,
PDefL, Ex. two subcases:
root derived DefL PDefL: n = 1, = 0 C = A1 ; i.e.
|= Ai v r.D Ai = A1 .
root derived Ax Ex: n = 0, = 1, C = r1 .C1 ,
r1 = r. C1 = D, obviously |= C1 v holds. Otherwise, rule Ex
used derive root ` C1 v holds, implies |= C1 v D.
Thus, case, rj = r |= Cj v holds j = 1.
case n+m > 1 proved induction analogously proof Point 1 above.
apply Lemma 15 elements cDiff (T1 , T2 ).
Theorem 16 (Primitive witness EL). Let T1 T2 EL-terminologies
signature. cDiff (T1 , T2 ), either C v v member cDiff (T1 , T2 ),
sig() concept name C, EL-concepts occurring .
Proof. Let = C v cDiff (T1 , T2 ). proof induction construction
D. 6= > T2 |= C v >. = D1 u D2 , one C v Di , = 1, 2,
cDiff (T1 , T2 ) apply induction hypothesis. = r.D1 then, Lemma 15,
645

fiKonev, Ludwig, Walther, & Wolter

either (i) exists conjunct C, concept name, T1 |= v D, (ii)
exists conjunct r.C1 C T1 |= C1 v D1 .
case (i) follows T2 6|= v otherwise T2 |= C v C v 6
cDiff (T1 , T2 ) due |= C v A. Hence, v cDiff (T1 , T2 ).
Finally, case (ii) obtain T2 6|= C1 v D1 otherwise |= C v r.C1 , T2 |= r.C1 v
C v 6 cDiff (T1 , T2 ) again. Thus, C1 v D1 cDiff (T1 , T2 ) apply
induction hypothesis.
Theorem 16, every inclusion C v -concept difference T1 T2 contains basic witness inclusion concept name either right-hand side
left-hand side. define
set left-hand -concept difference witnesses, cWtnlhs
(T1 , T2 ), set
NC exists concept v cDiff (T1 , T2 )
set right-hand -concept difference witnesses, cWtnrhs
(T1 , T2 ), set
NC exists concept C C v cDiff (T1 , T2 ).
rhs
regard concept names cWtnlhs
(T1 , T2 ) cWtn (T1 , T2 ) succinct and,
certain sense, complete representation -concept difference T1 T2
define set -concept difference witnesses
rhs
cWtn (T1 , T2 ) = (cWtnlhs
(T1 , T2 ), cWtn (T1 , T2 )).

follows, first present polytime algorithm computing cWtnrhs
(T1 , T2 ). polytime algorithm computing cWtnlhs
(T
,

)

already

given

Lutz
Wolter (2010)
1 2

(for EL-TBoxes). briefly present since extension developed consider ELHr -terminologies. algorithms together decide -concept inseparability since,
Theorem 16, T1 T2 -concept inseparable if, if, cWtn (T1 , T2 ) =
cWtn (T2 , T1 ) = (, ).
4.2 Computing cWtnrhs
(T1 , T2 )
Let assume want decide whether cWtnrhs
(T1 , T2 ). Thus, want
decide whether exists -concept C T1 |= C v T2 6|= C v A.
general strategy follows. Let
noimplyT2 , (A) = {C | T2 6|= C v A, C EL -concept}.
aim algorithm checks whether noimplyT2 , (A) contains C T1 |=
C v A. two sets C concepts call C cover C
exists C C |= C v D. Thus, C noimplyT2 , (A) cover
noimplyT2 , (A) noimplyT2 , (A) exists C C |= C v D.
Note C cover noimplyT2 , (A), exists -concept C
C v cDiff (T1 , T2 ) if, if, exists C C T1 |= C v A.
Thus reduced original problem construction appropriate cover C
deciding subsumption problem T1 |= C v A, C C. Unfortunately, general,
finite cover exists. following example illustrates situation.
646

fiThe Logical Difference Lightweight Description Logic EL

Example 17. (1) Let = {A, B, r} T2 = . noimplyT2 , (A) contains concepts atomic conjunct. Clearly, noimplyT2 , (A) contains
finite cover.
(2) Let 0 = {A, B, r} T20 = {A r.A}. noimplyT20 ,0 (A) contains
0 \ {A}-concepts contains finite cover.
(3) Let 00 = {A, B1 , B2 } T200 = {A B1 u B2 }. {B1 , B2 } cover
noimplyT200 ,00 (A).
consequence, instead directly constructing cover noimplyT2 , (A), first
construct transparent small covers
noimplyT2 , (A) {C | depth(C) n},
n 0, depth(C) role-depth C; i.e., number nestings existential
restrictions C.3 covers denoted noimplynT2 , (A), n 0, singleton
sets non-conjunctive T2 finite sets containing k concepts
B1 u uBk T2 . Based sequence, present two distinct algorithms computing
cWtnrhs
(T1 , T2 ):
1. encode infinite sequence noimplynT2 , (A), n 0, polynomial-size ABox
AT2 , . way obtain reduction original problem instance
checking problem knowledge base (T1 , AT2 , ). certain sense, ABox
AT2 , encodes (in general infinite) cover noimplyT2 , (A).
2. employ terminology T1 dynamic programming approach decide
concepts noimplynT2 , (A) relevant deciding whether cWtnrhs
(T1 , T2 ).
Although less transparent, large terminologies latter approach considerably
efficient. develop acyclic terminologies.
EL-terminology , concept name signature , set
pre
(A) = {B | |= B v A}.
finite covers noimplynT2 , (A), n 0, defined Figure 2. n = 0,
set noimplynT2 , (A) consists concepts without role names. distinguish conjunctive non-conjunctive A. Note non-conjunctive, noimplynT2 , (A)
singleton set. Example 17 (3) shows always case conjunctive A. n + 1, distinguish pseudo-primitive concept names, conjunctive
concept names, definition form r.C. Again, nonn
conjunctive A, noimplyn+1
T2 , (A) singleton set. Note concepts covers
{C | depth(C) n, C EL -concept}, n 0. illustrate definitions using
EL-terminologies Example 17.
Example 18. (1) Let = {A, B, r} T2 = . B non-conjunctive T2
noimply0T2 , (A) = {B} noimply0T2 , (B) = {A}. B also pseudo-primitive
T2 , noimply1T2 , (A) = {B u r.(A u B)} noimply1T2 , (B) = {A u r.(A u B)}.
3. precisely depth(A) = 0, depth(C1 u C2 ) = max{depth(C1 ), depth(C2 )}, depth(r.D) =
depth(D) + 1.

647

fiKonev, Ludwig, Walther, & Wolter

Set, inductively,
all0 =

l

A0

l

alln+1
=


A0

A0 u

A0

l

s.alln .



Define noimply0T2 , (A) follows:
non-conjunctive T2 ,
l

noimply0T2 , (A) = {

A0 };

A0 \pre
(A)
2

conjunctive F T2 ,
[

noimply0T2 , (A) =

noimply0T2 , (B);

BF

define, inductively, noimplyn+1
T2 , (A)
pseudo-primitive T2 ,
l

noimplyn+1
T2 , (A) = {

A0 u

A0 (\pre
(A))

l

s.alln }.



2

conjunctive F T2 ,
noimplyn+1
T2 , (A) =

[

noimplyn+1
T2 , (B).

BF

r.B T2 ,
n+1
noimplyn+1
T2 , (A) = {C,T2 },
n+1
=(
C,T
2

l

A0 u

A0 (\pre
T2 (A))

l

l

s.alln u

r.E).

r
Enoimplyn


r6=s

2 ,

(B)

Figure 2: Definition noimplynT2 , (A)

(2) Let 0 = {A, B, r} T20 = {A r.A}. B non-conjunctive T20
noimply0T 0 ,0 (A) = {B} noimply0T 0 ,0 (B) = {A}. B pseudo-primitive T20
2

2

noimply1T2 , (B) = {A u r.(A u B)}. r.A T20 noimplyT20 ,0 (A) = {B u r.B}.
T200

(3) Let 00 = {A, B1 , B2 } T200 = {A B1 u B2 }. B1 B2 non-conjunctive
noimply0T 00 ,00 (B1 ) = {B2 } noimply0T 00 ,00 (B2 ) = {B1 }. conjunctive T200
2

2

648

fiThe Logical Difference Lightweight Description Logic EL

and, definition, noimply0T 00 ,00 (A) = {B1 , B2 }. Since contain role names,
2

noimply0T 00 ,00 (X) = noimplynT 00 ,00 (X), X {A, B1 , B2 } n > 0.
2

2

following lemma shows correctness definition noimplynT2 , (A).
Lemma 19. Let T2 normalised EL-terminology, signature, NC .
noimplynT2 , (A) cover noimplyT2 , (A) {C | depth(C) n}. Namely, n 0,
C1. T2 6|= C v A, C noimplynT2 , (A).
C2. EL -concepts n = depth(D), T2 6|= v A, |= C v
C noimplynT2 , (A).

particular, n0 noimplynT2 , (A) cover noimplyT2 , (A).
Proof.d C1. Assume first pseudo-primitive T2 . noimplynT2 , (A) consists
C = A0 (\pre (A)) A0 u F , F (possibly empty) conjunction concepts
T2

form s.Fi . Lemma 15, T2 6|= C v atomic conjuncts C
\ pre
T2 (A).
prove C1 concept names pseudo-primitive
T2 . proof

induction n. n = 0 r.B T2 , assume T2 |= A0 (\pre (A)) A0 v A.
T2

r.B T2 , Lemma 15 must exist A0 \ pre
T2 (A)
0

T2 |= v A. contradicts definition
set preT2 (A)). n = 0
conjunctive F T2 , let C noimplynT2 , (A) = BF noimplynT2 , (B). hence
exists atomic conjunct B F C noimplynT2 , (B). T2 normalised, B
non-conjunctive, i.e. property C1 already proved B. Thus, T2 6|= C v B,
implies T2 6|= C v otherwise T2 |= C v B would hold.
induction step, assume C1 proved n 0.
element noimplyn+1
Let r.B T2 let CTn+1
T2 , (A). Assume
2 ,
n+1
T2 |= CT2 , v A. Lemma 15 two possibilities:

T2 |= A0 (\pre (A)) A0 v r.B. Similarly above, claim follows Lemma 15
T2

fact r.B T2 .
r exists E noimplynT2 , (B) T2 |= E v B. excluded
induction hypothesis.
derived contradiction. case F T2 , conjunctive T2 , considered
analogously case n = 0.
C2. Let n = 0 assume first non-conjunctive. Let -concept
depth(D)d = 0 T2 6|= v A. conjuncts \ pre
T2 (A)
obtain |= A0 \pre (A) A0 v D. assume conjunctive T2 F T2 .
T2

Let -concept depth(D) = 0 T2 6|= v A. T2 6|= v B,
conjunct B F . induction, |= C v (unique B must non-conjunctive)
C noimply0T2 , (B), therefore |= C v C noimply0T2 , (A).
induction step, assume C2 shown n. Let -concept
T2 6|= v depth(D) = n + 1.
649

fiKonev, Ludwig, Walther, & Wolter

(a) Let pseudo-primitive T2 . atomicdconjuncts aredincluded
n
0
\ pre
A0 \pre (A) u s.all .
T2 (A). |= C v follows immediately C =
T2

(b) Let r.B T2 . Let CTn+1
element noimplyn+1
T2 , (A) assume
2 ,
D=

l

l

Eu

EQ0
n+1
Q0 \ pre
T2 (A). Hence, |= CT2 , v
distinguish two cases:

s.D0 .

(s,D0 )Q1



EQ0

E. consider conjunct s.D0 D.

6= r, |= CTn+1
v s.D0 , required.
2 ,
= r, sufficient show exists E noimplynT2 , (B)
|= E v D0 . Suppose exist E. Then, (the
contraposition of) induction hypothesis, T2 |= D0 v B. contradicts
T2 6|= v (as r.B T2 ).
(c) conjunctive T2 F T2 . case analogous case
conjunctive T2 n = 0.
Corollary 20. normalised EL-terminologies T1 T2 NC following
conditions equivalent:
exists EL -concept C T1 |= C v T2 6|= C v A;
exists n 0 C noimplynT2 , (A) T1 |= C v A.
Observe direct application Corollary 20 yield procedure comn
puting cWtnrhs
(T1 , T2 ) gives bound n set noimplyT2 , (A). point
present two ways avoiding problem (as well problem concepts
noimplynT2 , (A) exponential size). Firstly, instead working covers construct ABox encoding covers. contrast concepts, ABoxes admit encoding
structure sharing
cycles so, intuitively, admit polynomial reconstruction
infinite concept n0,Cnoimplyn (A) C.
T2 ,
ABox AT2 , constructed Figure 3, normalised EL-terminology
concept name sig(T ), set

{A}, non-conjunctive
non-conjT (A) =
{B1 , . . . , Bn }, B1 u u Bn
Note construction AT2 , similar construction noimplynT2 , (A).
assertions individual play role concepts alln , n 0,
assertions individuals play role sets noimplynT2 , (A), n 0. fact, one
readily show AT2 , |= C(A ) C noimplynT2 , (A) non-conjunctive
T2 and, conversely, (a involved proof) shows whenever AT2 , |= D(A )
EL-concept D, exist n 0 C noimplynT2 , (A) |= C v D.
illustrate construction AT2 , using EL-terminologies Example 17.
650

fiThe Logical Difference Lightweight Description Logic EL

Let
{A | sig(T2 ) non-conjunctive T2 } { } NI .
set individual names. non-conjunctive T2 , define sets AT2 , (A) assertions
follows
pseudo-primitive T2 ,
AT2 , (A) = {A0 (A ) | A0 \ pre
T2 (A)} {r(A , ) | r },
r.B T2 ,
AT2 , (A) ={A0 (A ) | A0 \ pre
T2 (A)}
{s(A , ) | r 6= }
{r(A , B 0 ) | B 0 non-conjT2 (B), r }
Let
[

AT2 , = { A0 ( ) | A0 } { r( , ) | r }

AT2 , (A)

Asig(T2 )
non-conjunctive T2

Figure 3: Construction AT2 , .
Example 21. (1) Let = {A, B, r} T2 = .
AT2 , = {A(B ), B(A ), r(A , ), r(B , )} ,
= {A( ), B( ), r( , )}.
(2) Let 0 = {A, B, r} T20 = {A r.A}.
AT20 ,0 = {A(B ), B(A ), r(A , ), r(B , 0 )} A0 ,
A0 = {A(0 ), B(0 ), r(0 , 0 )}.
(3) Let 00 = {A, B1 , B2 } T200 = {A B1 u B2 }.
AT200 ,00 = {B1 (B2 ), B2 (B1 )} A00 ,
A00 = {A(00 ), B1 (00 ), B2 (00 )}.
obtain following characterisation cWtnrhs
(T1 , T2 ).
Theorem 22. Let T1 T2 normalised EL-terminologies signature.
following conditions equivalent :
cWtnrhs
(T1 , T2 );
exist n 0 C noimplynT2 , (A) T1 |= C v A;
651

fiKonev, Ludwig, Walther, & Wolter

(T1 , AT2 , ) |= A(B ) B non-conjT2 (A).
equivalence Points 1 2 follows Corollary 20. give detailed
proof equivalence Points 2 3 follows general results
ELHr -terminologies present below.
Example 23. normalised form terminologies Example 12,
0
00
T1 = {A0 v B0 , A1 Bn } {Bi+1 Bi+1
u Bi+1
| 0 < n}
0
00
{Bi+1 r.Bi | 0 < n} {Bi+1 s.Bi | 0 < n}

T2 = {A1 v F0 } {Fi Fi0 u Fi00 | 0 < n}
{Fi0 v r.Fi+1 | 0 < n} {Fi00 v s.Fi+1 | 0 < n},
= {A0 , A1 , r, s}, ABox AT2 , graphically represented
r,
r,

r,
r,

F 00
A0 ,A1

r,
r,


A0 ,A1


F 00

F 0

A0 ,A1

A0 ,A1

1

r,

n

F 00

r,
A0
A1

n

1

r,

A1
A0

F 0

A0 ,A1

0

A0
F 0

0

A0

clear (T1 , AT2 , ) |= A1 (A1 ). fact, (T1 , A) |= A1 (A1 ) holds already
restriction AT2 , individuals {A1 , }.
Theorem 24. EL-terminologies T1 T2 signature , set cWtnrhs
(T1 , T2 )
computed polynomial time.
Proof. suffices give polynomial time algorithm decides every whether
cWtnrhs
(T1 , T2 ). First, ABox AT2 , computed polynomial time
quadratic size T2 . Theorem 22, cWtnrhs
(T1 , T2 ) iff (T1 , AT2 , ) |= A(B )
B non-conjT2 (A), latter condition checked polynomial time since
instance checking polynomial time EL-TBoxes.
Regarding efficiency approach, observe typical terminologies large
, ABox AT2 , indeed quadratic size T2 since \ pre
T2 (A) typically contain
concept names . Thus, large terminologies straightforward
implementation rather elegant algorithm work efficiently one would
store ABox quadratic size instance checking it. refer reader
Table 3 discussion prototype implementation approach applied
modules Snomed CT.
describe second approach computing cWtnrhs
(T1 , T2 ), works
acyclic EL-terminologies. Recall cWtnrhs
(T
,

1 2 ) if, if, ex
ists EL -concept C T2 6|= C v T1 |= C v A. Thus,
6 cWtnrhs
(T1 , T2 ) if, if, every EL -concept C C noimplyT2 , (A)
652

fiThe Logical Difference Lightweight Description Logic EL

procedure NotWitness(E)
E pseudo-primitive
T1


NotWitness(E) := | pre
T1 (E) preT2 (A)
end
(E E1 u u Ek
T1 )
NotWitness(E) := ki=1 NotWitness(Ei )
end
E r.E 0 T1
0 )
r
/ NotWitness(E



NotWitness(E) := | pre
T1 (E) preT2 (A)
else

fi

fi r.A0 T2


fi
NotWitness(E) := fifi non-conjT2 (A0 ) NotWitness(E 0 )


fi pre (E) pre (A)
T1
T2
end
end
end procedure
Figure 4: Computation NotWitness(E).
holds C noimplyT1 , (A). approach based computing witness
relation NW ((sig(T1 ) ) NC ) ((sig(T2 ) ) NC ), defined follows:
(E, A) NW

if, if,

() noimplyT2 , (A) noimplyT1 , (E)

Observe cWtnrhs
(T1 , T2 ) if, if, (A, A) 6 NW; hence, compute
set cWtnrhs
(T
,

)


sufficient
compute relation NW. practice, crucial
1 2

compute relation NW rather complement: typical terminologies concept
names unrelated sense subsume other. Thus, relation
NW much smaller complement (which contains, among others, pairs (E, A)
subsume T1 T2 ).
determine pairs (E, A) NW, aim computing every concept name
E sig(T1 ) set concept names sig(T2 ) property () holds.
set called NotWitness(E) computed Figure 4, following
modifications: (1) consider sig(T2 ) non-conjunctive T2
take conjunctive concept names account later. (2) consider fresh concept
name occurring sig(T1 ) sig(T2 ) informally standing possible concepts.
Thus, procedure, NotWitness(E) given Figure 4 recursively associates every
E sig(T1 ) subset set
= {All} { | (sig(T2 ) ), non-conjunctive T2 }
NW relation
((sig(T1 ) ) NC ) (((sig(T2 ) ) NC ) {All}).
653

fiKonev, Ludwig, Walther, & Wolter

Note unlike approach computing cWtnrhs
(T1 , T2 ) presented previously, approach described handle two terminologies separately.
previous approach ABox AT2 , could precomputed T2 re-used
compare T2 terminology T1 , whereas terminologies analysed
simultaneously. prove correctness procedure NotWitness(E).
Lemma 25. normalised acyclic EL-terminologies T1 T2 , signature ,
E sig(T1 ) following holds: NotWitness(E) if, if,
(E, A) NW.
Proof. prove E sig(T1 ) following two conditions
equivalent:
NotWitness(E);
n 0 C noimplynT2 , (A): T1 6|= C v E.

sufficient since n0 noimplynT2 , (A) cover noimplyT2 , (A) (Lemma 19).
E 6 sig(T1 ) claim trivial. E sig(T1 ) proof induction relative
relation T1 sig(T1 ) sig(T1 ) (whose definition found page 637). Note
since considered terminologies acyclic sig(T1 ) finite, relation T1
well-founded.
distinguish possible definitions E T1 . Suppose E pseudoprimitive T1 . , follows definition noimplynT2 , (A)
Lemma 15 exist n 0 C noimplynT2 , (A) T1 |= C v E if,

if, T1 |= B v E B ( \ pre
T2 (A)). Note B ( \ preT2 (A)),
T1 6|= B v E holds if, if, every B , T1 |= B v E implies B pre
T2 (A).
n

Thus, every n C noimplyT2 , (A), T1 6|= C v E if, if, preT1 (E) pre
T2 (A)
if, if, NotWitness(E).
Assume E E1 u u Ek T1 . Then, concept C, T1 6|= C v E if,
if, T1 6|= C v Ei 1 k. Hence, applying induction hypothesis
obtain every n C noimplynT2 , (A), T1 6|= C v E if, if, NotWitness(Ei )
1 k, if, if, NotWitness(E).
Finally, assume E r.E 0 T1 . Notice that, since
/ ( sig(T1 ) sig(T2 )) (in

particular, pseudo-primitive T2 ), preT2 (All) = . Thus, definition
every n 0, noimplynT2 , (All) = {alln }. applying induction hypothesis assume
lemma holds E 0 , implies
/ NotWitness(E 0 ) if, if,
n 0, T1 |= alln v E 0 . distinguish following cases, analogously
case distinction procedure NotWitness(E) (see Figure 4).
r
/ , -concept form s.G, NR , r 6=
T1 6|= s.G v r.E 0 . Similarly, NotWitness(E 0 ), holds every n 0
T1 6|= alln v E 0 . Hence, -concept form s.G, obtain T1 6|= s.G v r.E 0
otherwise T1 |= alln v E 0 would hold n = depth(s.G) (where depth(s.G)
role-depth s.G). So, Lemma 15, two cases analogous case E
pseudo-primitive considered above.
Assume r
/ NotWitness(E 0 ), is, n0 0
n0
0
T1 |= v E .
654

fiThe Logical Difference Lightweight Description Logic EL

First, observe definition form r.A0 T2 ,
+1
unique C noimplynT20,
(A) T1 |= C v E r.alln0 conjunct C (and
non-conjunctive T2 definition set ). definition form r.A0
T2 , n 0 C noimplynT2 , (A), Lemma 15 T1 6|= C v E
n1

0
0
if, if, pre
T1 (E) preT2 (A), and, n > 0, every C noimplyT2 , (A )
0
0
T1 6|= C v .
conclude case r
/ NotWitness(E 0 ), ,
n
n 0, C noimplyT2 , (A), T1 6|= C v E, if, if, r.A0

0

0
T2 , pre
T1 (E) preT2 (A) 0 C noimplyT2 , (A )

0
0

(A0 ) =
S1 6|= C v E . Noticem that, definition 0,0 noimplyT2 ,

0
Bnon-conjT (A0 ) noimplyT2 , (B). Thus, 0 C noimplyT2 , (A ),
2

T1 6|= C 0 v E 0 holds if, if, 0, B non-conjT2 (A0 )
0
0
0
C 0 noimplym
T2 , (B), T1 6|= C v E , if, if, B non-conjT2 (A ), B
0
NotWitness(E ) holds applying induction hypothesis.
Thus, T1 6|= C v E, n 0 C noimplynT2 , (A), if, if,
NotWitness(E).
Corollary 26. Let T1 T2 normalised acyclic EL-terminologies signature.
cWtnrhs
(T1 , T2 ) = { sig(T1 ) | B non-conjT2 (A) B 6 NotWitness(A) }.
Proof. First, observe cWtnrhs
(T1 , T2 ), sig(T1 ) must hold otherwise
-concept C T1 |= C v if, if, |= C v A, thus 6
cWtnrhs
(T1 , T2 ). Now, NC have:
cWtnrhs
(T1 , T2 )

iff

iff

iff
iff

sig(T1 ) (by observation) and, definition,
exists -concept C T2 6|= C v T1 |=
CvA
sig(T1 ) exists B non-conjT2 (A)
-concept C T2 6|= C v B T1 |= C v (as
otherwise T2 |= C v would hold)
sig(T1 ) exists B non-conjT2 (A)
(A, B) 6 NW (by definition relation NW)
sig(T1 ) exists B non-conjT2 (A)
B 6 NotWitness(A), Lemma 25.

acyclic terminologies, obtain alternative proof Theorem 24.
Theorem 27. acyclic EL-terminologies T1 T2 signature , cWtnrhs
(T1 , T2 )
computed polynomial time using procedure NotWitness(E).
Proof. compute set cWtnrhs
(T1 , T2 ), sufficient Corollary 26 compute
sets NotWitness(E) every E sig(T1 ). Assuming T1 T2 classified
result classification cached, NotWitness(E) computed E sig(T1 ),
worst case, time O((|T1 | + |T2 |)3 ).
Example 28. acyclic terminologies T1 , T2 signature Example 23,
NotWitness(A0 ) = {A0 },
655

NotWitness(B0 ) = {A0 }

fiKonev, Ludwig, Walther, & Wolter

concept names X sig(T1 ), NotWitness(X) = . particular A1
/
NotWitness(A1 ), conclude A1 concept difference witness.
4.3 Computing cWtnlhs
(T1 , T2 )
Recall set left-hand -concept difference witnesses, cWtnlhs
(T1 , T2 ), set
NC exists concept C v C cDiff (T1 , T2 ).
tractability computing cWtnlhs
(T1 , T2 ) EL proved Lutz Wolter (2010)
arbitrary EL-TBoxes reduction simulation checking. formulate main
steps employ technique dealing logical difference
ELHr -terminologies.
two interpretations I1 I2 say relation I1 I2
-simulation if, if, following conditions hold:
(d, e) AI1 , e AI2 ;
(d, e) (d, d0 ) rI1 r , exists e0 (d0 , e0 )
(e, e0 ) rI2 .
I1 e I2 write (I1 , d) (I2 , e) exists -simulation relation I1 I2 (d, e) S. checked polynomial time
whether (I1 , d) (I2 , e) various polynomial-time algorithms checking existence
simulations developed (Clarke & Schlingloff, 2001; Crafa, Ranzato, & Tapparo,
2011; van Glabbeek & Ploeger, 2008). Simulations characterise expressive power
EL-concepts following sense.
Lemma 29 (Lutz & Wolter, 2010). Let I1 I2 interpretations, signature, I1 ,
e I2 .
(I1 , d) (I2 , e)



EL -concepts C: C I1 e C I2 .

follows ,
cWtnlhs
(T1 , T2 )



(IK1 , a) 6 (IK2 , a)

Ki = (Ti , A) = {A(a)} IKi canonical model Ki , = 1, 2.
see this, recall Theorem 2 every EL-concept C, C IKi if, if,
(Ti , A) |= C(a). latter condition equivalent Ti |= v C. have, therefore,
proved:
Theorem 30 (Lutz & Wolter, 2010). EL-TBoxes T1 T2 signatures , set
cWtnlhs
(T1 , T2 ) computed polynomial time.
following example illustrates use simulations canonical models
determine cWtnlhs
(T1 , T2 ).
Example 31. Let = {A, r, B1 , B2 }
T1 = {A v r.F0 , F0 v F1 u F2 , F1 v r.B1 , F2 v r.B2 },
T2 = {A v G1 u G2 , G1 v r.G01 , G2 v r.G02 , G01 v r.B1 , G02 v r.B2 }
656

fiThe Logical Difference Lightweight Description Logic EL

check whether cWtnlhs
(T1 , T2 ) consider KBs K1 = (T1 , {A(a)}) K2 =
(T2 , {A(a)}). cWtnlhs
(T1 , T2 ) iff (IK1 , a) 6 (IK2 , a), canonical models
IK1 IK2 K1 K2 , respectively. Illustrations canonical models IK1 IK2
shown below.
xran(r),B1
B1

xran(r),B2
B2

r

xran(r),B1
B1

r

r

r



r

xran(r),G01

xran(r),F0

IK 1

xran(r),B2
B2
xran(r),G02

r

r







IK2

(IK1 , a) 6 (IK2 , a) point xran(r),F0 neither -simulated xran(r),G01
-simulated xran(r),G02 . concept inclusion cDiff (T1 , T2 ) left-hand side
given v r.((r.B1 ) u (r.B2 )).

5. ELHr -Instance Difference
polynomial-time algorithms inseparability logical difference ELHr based
extensions ideas used Section 4 EL. is, however, one important
difference: introduce new logics, ELran ELran,u,u , concept difference
captures exactly instance and, respectively, query difference ELHr . prove analogue Theorem 16 languages and, thereby, instance query difference
ELHr , introduce sequent calculus characterises ELran -consequences
ELHr -terminologies. start investigation instance difference case since
transparent concept difference case (recall EL difference
instance concept difference).
5.1 ELran -Concept Difference
Recall Example 4 showing ELHr -concept inseparability imply -instance
inseparability:
T1 = {ran(r) v A1 , ran(s) v A2 , B A1 u A2 },

T2 = ,

= {r, s, B}.

Notice ABox = {r(a, c), s(b, c)}, exhibiting instance difference
T1 T2 , c range r s. example suggests ran(r) ran(s)
could used complex concepts, kind difference made visible concept
language.
Definition 32 (ELran ). C ran -concepts constructed using following syntax rule
C :=



|

ran(r)

|

C uD

|

r.C,

NC , C, range C ran -concepts r NR . set ELran -inclusions
consists concept inclusions C v role inclusions r v s, C C ran concept, EL-concept, r, NR .
657

fiKonev, Ludwig, Walther, & Wolter

Clearly, every ELHr -inclusion ELran -inclusion. Additionally, ELran -inclusions
concept ran(r) occur everywhere concepts left-hand side inclusions.
gives us additional concept inclusions -concept difference.
Example 33. T1 T2 Example 4, T1 |= ran(r) u ran(s) v B,
T2 6|= ran(r) u ran(s) v B. Thus, using C ran -concept ran(r) u ran(s) simulate
ABox {r(a, c), s(b, c)} Example 4 make -difference could
observed ELHr visible ELran .
show Example 33 generalised arbitrary TBoxes. end,
consider following straightforward generalisation -concept difference differences ELran .
ran
r
Definition 34 (ELran
-difference). EL -difference ELH -TBoxes T1 T2
ran
set cDiff ran
(T1 , T2 ) EL -inclusions T1 |= T2 6|= .

prove equivalence -instance difference ELHr -concept differran
ence ELran , first associate every ABox individual set CA,a
ran
C -concepts. Assume given. Let, inductively, obj(A):
l
l
0,ran
=(
CA,a
A) u (
ran(r));
A(a)A


n+1,ran
=(
CA,a

l

A(a)A

A) u (

r(b,a)A

l

ran(r)) u (

r(b,a)A

l

n,ran
),
r.CA,b

r(a,b)A

set
n,ran
ran
| n 0}
CA,a
= {CA,a
n,ran
(a) fordall n > 0. Moreover, lemma shows
that, intuObserve |= CA,a
ran specific concept |=
ran (a).
itively, infinite conjunction CA,a
CA,a
Conversely, associate ABox C ran -concept. construction straightforward; however, care taken since introduce structure sharing
associate distinct individual names distinct occurrences subconcepts. Given
C ran -concept C, first define path C finite sequence C0 r1 C1 rn Cn ,
C0 = C, n 0, ri+1 .Ci+1 conjunct Ci , 0 < n. use paths(C)
denote set paths C. p paths(C), tail(p) denotes last element
Cn p.
Now, let aran ap p paths(C) individual names set inductively:

AC = { s(ap , aq ) | p, q paths(C); q = p C 0 , C 0 }
{ A(ap ) | conjunct tail(p), p paths(C) }
{ >(ap ) | > conjunct tail(p), p paths(C) }
{ r(aran , ap ) | ran(r) conjunct tail(p), p paths(C) }
Example 35. Let C = (r.(A u ran(v))) u (s.((t.(A u ran(v))) u (t.(B u ran(s)))))
C ran -concept. AC represented graphically follows.
658

fiThe Logical Difference Lightweight Description Logic EL




v

B






r

v

aran



aC

indicate aC aran ; individuals identified paths C. Note
different occurrences u ran(v) C correspond different individuals AC .
Lemma 36. Let ELHr -TBox, ABox, C0 D0 C ran -concepts, let
a0 obj(A).
n,ran
(T , A) |= D0 (a0 ) if, if, exists n 0 |= CA,a
v D0 ;
0

|= C0 v D0 if, if, (T , AC0 ) |= D0 (aC0 ).
Below, employ lemma transfer analogue Theorem 16 ELran
ELHr -instance differences. now, note following consequence:
Corollary 37. two ELHr -TBoxes T1 T2 , cDiff ran
(T1 , T2 ) = if, if,
iDiff (T1 , T2 ) = .
n,ran
Proof. (A, D0 (a0 )) iDiff (T1 , T2 ), exists n 0 CA,a
v
0
ran
D0 cDiff ran
(T
,

).
Conversely,

C
v


cDiff
(T
,

),

(A
,

(a
))

1
2
0
0
1
2
0
C
C


0
0
iDiff (T1 , T2 ).

Note Theorem 6 follows Corollary 37 since ELHr -TBox without
range restrictions |= C v if, if, |= C 0 v D, C 0 obtained C
replacing concept form ran(r) C >.
5.2 Proof System ELHr
Gentzen-style proof system ELHr consists rules given Figures 1 5.
Cut elimination, correctness, completeness proof system shown similarly
corresponding proofs given Hofmann (2005).
Theorem 38. ELHr -terminologies C ran -concepts C D, holds
|= C v if, if, ` C v D.
generalise Lemma 15 ELHr -terminologies.
Lemma 39. Let ELHr -terminology, concept name r.D EL-concept.
Assume
l
l
l
|=
ran(si ) u
Aj u
rk .Ck v r.D,
1il

1jn

1km

Ck , 1 k m, C ran -concepts l, m, n 0. least one following
conditions holds:
659

fiKonev, Ludwig, Walther, & Wolter

r.(C u ran(r)) v
(ExRan)
r.C v
BvD
(Dom)
r.C v
r.> v B
AvD
(Ran)
ran(r) v
s.C v
(Sub)
r.C v

ran(r) v

ran(s) v
(RanSub)
ran(r) v

r v

Figure 5: Additional rules ELHr -terminologies.
(e1) exists rk , 1 k m, |= rk v r |= Ck u ran(rk ) v D;
(e2) exists Aj , 1 j n, |= Aj v r.D;
(e3) exists rk , 1 k m, |= rk .> v r.D;
(e4) exists si , 1 l, |= ran(si ) v r.D.
assume pseudo-primitive
l
l
|=
ran(si ) u
Aj u
1il

1jn

l

rk .Ck v A,

1km

Ck , 1 k m, C ran -concepts l, m, n 0. least one following
conditions holds:
(a1) exists Aj , 1 j n |= Aj v A;
(a2) exists rk , 1 k |= rk .> v A;
(a3) exists si , 1 l |= ran(si ) v A.
Proof. prove first part lemma, second part proved analogously.



Let C = 1il ran(si ) u 1jn Aj u 1km rk .Ck assume |= C v r.D
holds. Then, ` C v r.D Theorem 38, implies exists
derivation sequent C v r.D. proof proceeds induction depth
D, i.e. maximal length path root one leaves D.
Notice l + n + 2, root derived AndL1
AndL2. lemma follows induction hypothesis.
Otherwise, l + n + = 1. Note l + + n = 0 possible since
6|= > v r.D definition terminology . C = A1 C = ran(s1 ), (e2)
(e4), respectively, hold already. remains consider case C = r1 .C1 . Then,
rule used derive root one Ax, Ex, ExRan, Dom
Sub. consider cases one one:
660

fiThe Logical Difference Lightweight Description Logic EL

root derived Ax: considering form inference rule,
r1 = r C1 = D. Hence |= r1 v r |= C1 u ran(r1 ) v D, implies
(e1) holds.
root derived Ex: r1 = r ` C1 v D. Hence, |= r1 v r
|= C1 v holds Theorem 38. Thus, |= C1 u ran(r1 ) v
infer (e1) holds again.
root derived Dom: ` B v r.D r1 .> v B .
Theorem 38, |= B v r.D hence, |= r1 .> v r.D, is, (e3)
holds.
root derived ExRan: obtain ` r1 .(C1 u ran(r1 )) v r.D.
Since sequent r1 .(C1 u ran(r1 )) v r.D derivation shorter length
D, apply induction hypothesis. Hence, either |= r1 .> v r.D,
is, (e3) holds, |= r1 v r |= (C1 u ran(r1 )) u ran(r1 ) v D. Hence (e1)
holds |= C1 u ran(r1 ) v (C1 u ran(r1 )) u ran(r1 ).
root derived Sub: obtain ` s.C1 v r.D r1 v .
induction hypothesis, either |= s.> v r.D, |= v r |=
C1 u ran(s) v D. seen |= r1 .> v r.D, |= r1 v r
|= C1 u ran(r1 ) v D, respectively. Hence (e3) (e1) holds.

prove extension Theorem 16 ELran -consequences ELHr -terminologies.
give rather detailed description simple witness inclusions contained members
cDiff ran
(T1 , T2 ) since going use result analysing concept
difference ELHr .
Theorem 40 (Primitive witness ELran -differences). Let T1 T2 ELHr -terminologies
signature. cDiff ran
(T1 , T2 ), either exist {r, s} sig()
ran
r v cDiff (T1 , T2 ) form C v D, one
1. C 0 v ran(r) u C 0 v A,
2. v D0 , r.> v D0 ran(r) v D0
0
member cDiff ran
(T1 , T2 ), r sig(), sig() concept name, C
subconcept C D0 subconcept D.
ran -concept EL-concept.
Proof. Let C v cDiff ran
(T1 , T2 ), C C
prove theorem induction structure D.
Notice 6= > T2 |= C v >. concept name, inclusion
Point 1 exists. = D1 u D2 , one C v Di , = 1, 2, cDiff ran
(T1 , T2 ).
apply induction hypothesis anddwe infer

inclusion

Point 1


Point 2 exists. = r.D1 , let C = 1il ran(si ) u 1jn Aj u 1km rk .Ck .
Then, Lemma 39, one (e1)(e4) holds. Cases (e2)(e4) directly entail
inclusion Point 1 Point 2 exists. case (e1), either rk v r cDiff ran
(T1 , T2 )

661

fiKonev, Ludwig, Walther, & Wolter

T1 |= Ck u ran(rk ) v D1 T2 6|= Ck u ran(rk ) v D1 (as otherwise T2 |= C v would
hold). apply induction hypothesis D1 conclude inclusion
Point 1 Point 2 exists.
5.3 Instance Difference Witnesses
Similarly Theorem 16 concept difference EL-terminologies derived extension, Theorem 40, ELran , show every member (A, )
iDiff (T1 , T2 ) gives rise basic witness either ABox instance query
atomic. keep formulation succinct give abstract description relationship (A, ) iDiff (T1 , T2 ) witness using signature (A, ).
interested reader problem derive stronger relationship (A, )
witness proof.
Theorem 41 (Primitive witness ELHr -instance differences). Let T1 T2 ELHr terminologies signature. iDiff (T1 , T2 ), least one following
conditions holds:
1. ({r(a, b)}, s(a, b)) iDiff (T1 , T2 ), r, sig();
2. (A, A(b)) iDiff (T1 , T2 ), concept name sig(), individual b,
ABox sig(A) sig().
3. (A, D(b)) iDiff (T1 , T2 ), singleton ABox A, individual b A, ELconcept sig(A), sig(D) sig();
Proof. Let (A, ) iDiff (T1 , T2 ). distinguish following cases.
(a) = s(a, b), (T1 , A) |= s(a, b) if, if, r(a, b) T1 |=
r v s. (T2 , A) 6|= s(a, b) obtain T2 6|= r v s. Thus, ({r(a, b)}, s(a, b)) iDiff (T1 , T2 )
Point 1 holds.
(b) Assume = D(b) EL-concept D. Lemma 36, n 0
n,ran
n,ran
v D. Theorem 40, one (i) r v s, (ii) v D0 , (iii)
v T2 6|= CA,b
T1 |= CA,b
r.> v D0 , (iv) ran(r) v D0 , (v) C v A, (vi) ran(r)uC v member cDiff ran
(T1 , T2 ),
n,ran
D0
r sig(), sig() concept name, C subconcept CA,b
subconcept D. (i) r v cDiff ran
(T1 , T2 ), ({r(a, b)}, s(a, b)) iDiff (T1 , T2 )
Point 1 holds.
let F v G denote member cDiff ran
(T1 , T2 ) cases (ii)-(vi) above. Conran
sider ABox AF associated C -concept F Point 2 Lemma 36.
sig(AF ) sig() (AF , G(aF )) iDiff (T1 , T2 ).
case (ii), obtain F = concept name. Hence AF = {A(aF )} Point 3
holds. case (iii), obtain AF = {r(aF , a> ), >(a> )} Point 3 lemma applies
(after removing >(a> ) AF ). Similarly, (iv), AF = {r(aran , aF )},
Point 3 lemma holds. Finally, cases (v) (vi), G sig() concept
name. Hence Point 2 lemma applies.
Theorem 41 justifies following finite representation -instance difference ELHr -terminologies. corresponds exactly three distinct points theorem. Assume T1 T2 given. Let
662

fiThe Logical Difference Lightweight Description Logic EL

set role -instance difference witnesses, iWtnR
(T1 , T2 ), consist r v
T1 |= r v T2 6|= r v s;
set right-hand -instance difference witnesses, iWtnrhs
(T1 , T2 ), consist
exists (A, A(a)) iDiff (T1 , T2 );
set left-hand -instance difference witnesses, iWtnlhs
(T1 , T2 ), consist
exists C(a) ({A(a)}, C(a)) iDiff (T1 , T2 ) r
exists C(c) c = c = b ({r(a, b)}, C(c)) iDiff (T1 , T2 ).
set -instance difference witnesses defined
rhs
lhs
iWtn (T1 , T2 ) = (iWtnR
(T1 , T2 ), iWtn (T1 , T2 ), iWtn (T1 , T2 )).

Theorem 41, observe iWtn (T1 , T2 ) = (, , ) if, if, iDiff (T1 , T2 ) = .
set iWtnR
(T1 , T2 ) easily computed polynomial time analysed
paper. Thus, aim present polynomial-time algorithms computing
lhs
iWtnrhs
(T1 , T2 ) iWtn (T1 , T2 ).
5.4 Computing iWtnrhs
(T1 , T2 )
compute iWtnrhs
(T1 , T2 ) two different ways: first, present transparent
ABox approach works arbitrary ELHr -terminologies, second present
efficient dynamic programming approach works acyclic ELHr -terminologies
only. approaches introduced Section 4.2 EL-terminologies. start
ABox approach exhibit -ABox AT2 , depending T2
non-conjunctive exists ABox (A, A(d)) iDiff (T1 , T2 ) if,
if, (T1 , AT2 , ) |= A(A ) certain individual name . case conjunctive
reduced condition defining concept names.
deal ELHr -terminologies rather EL-terminologies extend
structure AT2 , significantly. describe model-theoretic properties AT2 , ,
require notion -range simulation. capture model-theoretically expressive
power C ran -concepts (the concepts used describe -instance difference terms subsumption, cf. Lemma 36). two ABoxes A1 , A2 designated
individual names a1 a2 , say relation obj(A1 ) obj(A2 )
-simulation if, if,
(S1) (a1 , a2 ) S;
(S2) : (a, b) A(a) A1 , A(b) A2 ;
(S3) r : (a, b) r(a, a0 ) A1 , exists b0 (a0 , b0 )
r(b, b0 ) A2 .
say -range simulation if, addition,
(RS) r : (a, b) exists c r(c, a) A1 , exists
c0 r(c0 , b) A2 .
follows write
663

fiKonev, Ludwig, Walther, & Wolter

(A1 , a1 ) (A2 , a2 ) exists -simulation (A1 , a1 ) (A2 , a2 );
(A1 , a1 ) ran
(A2 , a2 ) exists -range simulation (A1 , a1 )

(A2 , a2 ).
following lemma shows range simulations characterise C ran -concepts.
Lemma 42. Let A1 A2 -ABoxes designated individual names a1 a2 .
ran -concepts
(A1 , a1 ) ran
(A2 , a2 ), (T , A1 ) |= C(a1 ) implies (T , A2 ) |= C(a2 ) C
C.
Proof. apply Lemma 36. Let -range simulation A1 A2
(a1 , a2 ) S. One prove induction n n 0, obj(A1 )
b obj(A2 ),
n,ran
(b).
() (a, b) S, A2 |= CA
1 ,a
ran assume (A1 , a1 ) ran
(A2 , a2 ) (T , A1 ) |= C(a1 ) holds C
n,ran
concept C. Then, Lemma 36, exists n 0 |= CA1 ,a1 v C. Moreover,
n,ran
(A1 , a1 ) ran
(A2 , a2 ), () A2 |= CA1 ,a1 (a2 ), implies
(T , A2 ) |= C(a2 ), required.

construction , given Figure 6, normalised ELHr terminology signature. advise reader recall definition , given
Figure 3 EL-terminologies consider additional ingredients required
ELHr -terminologies. remind reader definition non-conjT (A)
Section 4.2:

{A}, non-conjunctive
non-conjT (A) =
{B1 , . . . , Bn }, B1 u u Bn
Figure 6, also use following sets, NC r NR :
preC
(A) = { B NC | |= B v },
preDom
(A) = { r NR | |= r.> v },
preRan
(A) = { r NR | |= ran(r) v },
preRole
(r) = { NR | |= v r }.
following example illustrates definition , .
Example 43. T1 = {ran(r) v A1 , ran(s) v A2 , B A1 u A2 }, T2 = , = {r, s, B}
defined Example 4,
AT2 , = {B( ), r( , ), s( , ), r(B , ), s(B , ), r( , B ), s( , B )}.
holds (T1 , AT2 , ) |= B(B ) (T2 , AT2 , ) 6|= B(B ).

664

fiThe Logical Difference Lightweight Description Logic EL

Let
{A | sig(T ) non-conjunctive } { } NI .
set individual names. non-conjunctive , define sets , (A) assertions
follows
pseudo-primitive ,
, (A) = { A0 (A ) | A0 \ preC
(A) }
{ r(A , ) | r \ preDom
(A) }
{ r( , ) | r \ preRan
(A) },
r.B , NR let


0
= { (s, B 0 ) | B 0 non-conjT (B), preRole
(r) \ (preDomT (A) preRanT (B )) }

set
, (A) = { A0 (A ) | A0 \ preC
(A) }
{ s( , ) | \ preRan
(A) }

{ s(A , ) | \ (preRole
(r) preDomT (A)) }

{ s(A , ) | (s, ) }.
Let
, = { A0 ( ) | A0 } { r( , ) | r }

[

, (A)

Asig(T )
non-conjunctive

Figure 6: Construction , ELHr -terminologies.
Lemma 44. every normalised ELHr -terminology signature following
conditions equivalent -ABoxes A, sig(T ) non-conjunctive ,
obj(A):
1. (T , A) 6|= A(a);
2. obj(AT , ) (A, a) ran
(AT , , ).
Lemma 44 proved appendix.
Lemma 45. Let T1 T2 normalised ELHr -terminologies, signature .
Let AT2 , ABox constructed Figure 6. following conditions equivalent:
exists -ABox (T1 , A) |= A(a) (T2 , A) 6|= A(a);
(T1 , AT2 , ) |= A(B ) B non-conjT2 (A).
665

fiKonev, Ludwig, Walther, & Wolter

Proof. Assume exists -ABox obj(A) (T1 , A) |= A(a) (T2 , A) 6|=
A(a). Then, (T2 , A) 6|= A(a), B non-conjT2 (A), (T2 , A) 6|= B(a). Hence,
Lemma 44, (A, a) ran
(AT2 , , B ). then, Lemma 42, (T1 , AT2 , ) |= A(B ),
required.
Conversely, suppose (T1 , AT2 , ) |= A(B ) B non-conjT2 (A) B
obj(AT2 , ). Notice that, Lemma 44, (T2 , AT2 , ) 6|= B(B ). Hence (T2 , AT2 , ) 6|= A(B )
AT2 , B witness Point 1.
Theorem 46. Let T1 T2 normalised ELHr -terminologies signature.
iWtnrhs
(T1 , T2 ) computed polynomial time.
Proof. Lemma 45, iWtnrhs
(T1 , T2 ) if, if, B non-conjT2 (A)
(T1 , AT2 , ) |= A(B ). remains observe AT2 , constructed polynomial
time checking whether (T1 , AT2 , ) |= A(B ) polynomial time.
briefly describe dynamic programming approach computing set
r
iWtnrhs
(T1 , T2 ) acyclic terminologies extended EL ELH . extension
NotWitness(E) algorithm Figure 4 ELHr given Figure 7. Figure 4,
procedure NotWitness(E) recursively associates every E sig(T1 ) subset
= {All} { | (sig(T2 ) ), non-conjunctive T2 }.
conditions NotWitness(E) become complex since one take

account sets preRan
(E) preDomT (E). prove correctness NotWitness
algorithm, observe following consequence Lemma 36.
Corollary 47. Let T1 T2 normalised acyclic ELHr -terminologies signature.
ran -concept C C v cDiff ran (T , ) }.
iWtnrhs
1 2
(T1 , T2 ) = { | C

Proof. First, let iWtnrhs
(T1 , T2 ). exists -ABox (T1 , A) |=
A(a) (T2 , A) 6|= A(a). Hence, Point 1 Lemma 36 exists n 0
n,ran
n,ran
ran -concept. Conversely, assume
CA,a
v cDiff ran
(T1 , T2 ). Note CA,a C
exists C ran -concept C C v cDiff ran
(T1 , T2 ). Point 2
Lemma 36, (AC , A(aC )) iDiff (T1 , T2 ), i.e. iWtnrhs
(T
,
T2 ).
1

formulate correctness NotWitness algorithm way
Corollary 26.
Theorem 48. Let T1 T2 normalised acyclic ELHr -terminologies signature.
iWtnrhs
(T1 , T2 ) = { sig(T1 ) | B non-conjT2 (A) B 6 NotWitness(A) }.
proof extension proofs Lemma 25 Corollary 26. Namely, one
show sig(T1 ) B sig(T2 ) B non-conjunctive
T2 following conditions equivalent:
B NotWitness(A);
ran -concepts C: 6|= C v B implies 6|= C v A.
C
2
1

Using Corollary 47, thus obtain every : iWtnrhs
(T1 , T2 ) if, if,
ran
exists C -concept C T2 6|= C v T1 |= C v if, if, exists
B non-conjT2 (A) B 6 NotWitness(A).
666

fiThe Logical Difference Lightweight Description Logic EL

procedure AuxPP (E)


preC
T1 (E) = preRanT1 (E) = preDomT1 (E) =
return {All}
else

Auxconcept := { | preC
T1 (E) preCT2 (A) }

Auxran := { | preRanT1 (E) preRan
T2 (A) }

Auxdom := { | preDomT1 (E) preDom
T2 (A) }
return Auxconcept Auxran Auxdom
end
end procedure
procedure NotWitness(E)
E pseudo-primitive T1
NotWitness(E) := AuxPP (E)
else E E1 u uSEk T1
k
NotWitness(E) := i=1 NotWitness(Ei )
else E r.E 0 T1
0
preRole
T1 (r) = NotWitness(E )
NotWitness(E) := AuxPP (E)
else
fi


fi pseudo-primitive ,
fi
Auxrole,prim := fi

preRole
T1 (r) preDomT2 (A)
fi

fi t.B T2 ,

fi


fi





fi preRoleT1 (r) preRoleT2 (t) preDomT2 (A),


fi




fi preRoleT (r) preRoleT (t)
1
2
Auxrole,exist := fifi

0



/
preDom
(A)

B

non-conj
fi

T2 (B)
T2

fi


0
00

fi



6
preRan
(B
),

exists
E

non-conjT1 (E 0 )
T2

fi


00
0
00
fi
B NotWitness(E ) 6 preRan
T1 (E )
NotWitness(E) := (Auxrole,prim Auxrole,exist ) AuxPP (E)
end
end
end procedure





















Figure 7: Computation NotWitness(E) ELHr .
5.5 Tractability iWtnlhs
(T1 , T2 )
prove tractability iWtnlhs
(T1 , T2 ) reduction simulation checking
case EL-terminologies (Theorem 30).
Theorem 49. Let T1 T2 ELHr -TBoxes let signature. set
iWtnlhs
(T1 , T2 ) computed polynomial time.
Proof. concept name
iWtnlhs
(T1 , T2 )


667

(IK1 , a) 6 (IK2 , a)

fiKonev, Ludwig, Walther, & Wolter

Ki = (Ti , A) = {A(a)} IKi canonical model Ki , = 1, 2. Indeed,
({A(a)}, C(a)) iDiff (T1 , T2 ), EL -concept C, if, if, Theorem 2,
C IK1
/ C IK2 . condition is, Lemma 29, equivalent (IK1 , a) 6 (IK2 , a).
latter condition checked polynomial time.
Similarly, role name r
r iWtnlhs
(T1 , T2 )



(IK1 , a) 6 (IK2 , a) (IK1 , b) 6 (IK2 , b)

Ki = (Ti , A), = {r(a, b)}, IKi canonical model Ki , = 1, 2. Again,
latter condition checked polynomial time.

6. ELHr -Concept Difference
section present polynomial-time algorithms deciding -concept inseparability
computing succinct representation concept difference ELHr -terminologies.
algorithms essentially reduction instance difference case.
start introducing succinct representation -concept difference. Let
T1 T2 ELHr -terminologies. Since cDiff (T1 , T2 ) cDiff ran
(T1 , T2 ), follows
Theorem 40 C v cDiff (T1 , T2 ) exists inclusion least one
following forms
(i) C 0 v A,
(ii) ran(r) u C 0 v A,
(iii) v D0 ,
(iv) r.> v D0 ,
(v) ran(r) v D0
cDiff (T1 , T2 ), r sig(), sig() concept name, C 0 subconcept C
D0 subconcept D. Notice particular case (ii) C 0 EL-concept.
Hence, case -instance difference, obtain following representation
-concept difference. Assume T1 T2 given. Let
set role inclusion -concept difference witnesses, cWtnR
(T1 , T2 ), consist
r v T1 |= r v T2 6|= r v s;
set right-hand -concept difference witnesses, cWtnrhs
(T1 , T2 ), consist
exists EL-concept C either C v cDiff (T1 , T2 )
additionally exists role name r ran(r) u C v cDiff (T1 , T2 ).
set left-hand -concept difference witnesses, cWtnlhs
(T1 , T2 ), consist
exists EL-concept C v C cDiff (T1 , T2 ),
role names r exists EL-concept C either r.> v C
cDiff (T1 , T2 ) ran(r) v C cDiff (T1 , T2 ).
set -concept difference witnesses defined
rhs
lhs
cWtn (T1 , T2 ) = (cWtnR
(T1 , T2 ), cWtn (T1 , T2 ), cWtn (T1 , T2 )).

668

fiThe Logical Difference Lightweight Description Logic EL

Observe cWtn (T1 , T2 ) = (, , ) if, if, cDiff (T1 , T2 ) = . also obtain
lhs
sets cWtnR
(T1 , T2 ) cWtn (T1 , T2 ) coincide corresponding witness sets
instance difference, allows us re-use results developed
detecting instance differences.
Lemma 50. Let T1 T2 normalised ELHr -terminologies signature.
following holds:
R
1. cWtnR
(T1 , T2 ) = iWtn (T1 , T2 ),
lhs
2. cWtnlhs
(T1 , T2 ) = iWtn (T1 , T2 )
rhs
3. cWtnrhs
(T1 , T2 ) iWtn (T1 , T2 )
lhs
Proof. Point 1 follows directly definition. Proving cWtnlhs
(T1 , T2 ) iWtn (T1 , T2 )
rhs
cWtnrhs
(T1 , T2 ) iWtn (T1 , T2 ) similar Lemma 10. Finally, prove
lhs
lhs
iWtn (T1 , T2 ) cWtn (T1 , T2 ), assume iWtnlhs
(T1 , T2 ). exists ELconcept D(a) ({A(a)}, D(a)) iDiff (T1 , T2 ). T1 |= v T2 6|= v
lhs
and, therefore, cWtnlhs
(T1 , T2 ). argument r iWtn (T1 , T2 ) similar.

presented polynomial-time algorithms compute iWtnlhs
(T1 , T2 )
rhs
iWtnR
(T
,

).
Thus,

remains

analyse
cWtn
(T
,

).
1
2
1
2


6.1 Tractability cWtnrhs
(T1 , T2 )
prove tractability cWtnrhs
(T1 , T2 ) modifying ABox AT2 , introrhs
duced prove tractability iWtnrhs
(T1 , T2 ). Recall iWtn (T1 , T2 ) iff (T1 , AT2 , ) |=
A(B ) B non-conjT2 (A) (cf. Lemma 45). satisfying condition
cWtnrhs
(T1 , T2 ) since ABox AT2 , cannot always captured set EL-concepts
(cf. Example 4). modification AT2 , motivated observation ABox
contain individual range two distinct role names, EL-concepts
rather C ran -concepts sufficient capture consequences ABox. Thus,
going modify AT2 , minimal way resulting ABox contain
individual name range two distinct role names.
Definition 51. ABox role-splitting pair assertions r(a, c), s(b, c)
A, individual names a, b, c distinct role names r, s.
following lemma states main property role-splitting ABoxes.
Lemma 52. Let T1 T2 normalised ELHr -terminologies, signature
let role-splitting -ABox (T1 , A) |= A(a) (T2 , A) 6|= A(a).
cWtnrhs
(T1 , T2 ).
n,ran
n,ran
Proof. Lemma 36, exists n 0 T1 |= CA,a
v T2 6|= CA,a
v A.
Assume first exist b obj(A) r r(b, a) A. Then,
n,ran
definition since role-splitting, ran(r) occurs CA,a
direct scope
n,ran
existential restriction r. Hence CA,a equivalent EL -concept,
done. assume exists r(b, a) A. Then, since role-splitting,
n,ran
CA,a
equivalent concept ran(r) u C, C EL -concept. case
T1 |= ran(r) u C v T2 6|= ran(r) u C v A, required.

669

fiKonev, Ludwig, Walther, & Wolter

-ABox sig(A) NR 6= , define role-splitting unfolding
individuals { ar | obj(A), r sig(A) NR } setting
= { A(ar ) | A(a) A, r sig(A) NR } { r(as , br ) | r(a, b) A, sig(A) NR }.
Example 53. Consider T1 = {ran(r) v A1 , ran(s) v A2 , B A1 u A2 }, T2 = , =
{r, s, B} = {r(a, c), s(b, c)} Example 4. (T1 , A) |= B(c) (T2 , A) 6|=
B(c). Notice role-splitting unfolding = {r(ar , cr ), r(as , cr ), s(br , cs ), s(bs , cs )}
contain individual range one role
c



cr



cs
r

r



r



b

ar




br



bs

(T1 , ) 6|= B(cr ), (T1 , ) 6|= B(cs ).
apply role-splitting unfolding ABox , Figure 6. following
result concept version Lemma 44 proved appendix reduction
Lemma 44. ABox AC corresponding EL-concept C introduced
Lemma 36. simplicity, consider signatures containing least one role name.
Lemma 54. every normalised ELHr -terminology , signature NR 6= ,
concept name non-conjunctive , role name r , EL -concepts C
following conditions equivalent = C = ran(r) u C:
6|= v A;

r NR , (A )r obj(AT , ) (AD , aD ) ran
(AT , , (A )r ).

following lemma proved similarly Lemma 45, using Lemma 54 instead
Lemma 44.
Lemma 55. Let T1 T2 normalised ELHr -terminologies, signature
NR 6= . following conditions equivalent:
cWtnrhs
(T1 , T2 );
exists r (T1 , AT2 , ) |= A((B )r ) B non-conjT2 (A).
Proof. Assume cWtnrhs
(T1 , T2 ). Then, either exists EL -concept C
T1 |= C v T2 6|= C v A, additionally exists r T1 |=
ran(r) u C v T2 6|= ran(r) u C v A. Hence, = C = ran(r) u C,
respectively, T2 6|= v B, B non-conjT2 (A), Lemma 54, exists

r (A )r obj(AT , ) (AD , aD ) ran
(AT2 , , (B )r ). then, Lemma 42
(T1 , AT2 , ) |= A((B )r ) (T1 , AD ) |= A(aD ) holds Lemma 36.
converse direction, easy see (B )r obj(AT2 , ), B obj(AT2 , ),

(AT2 , , (B )r ) ran
(AT2 , , B ), implies (T2 , AT2 , ) 6|= A((B )r ) Lemma 44.
Consequently, obtain cWtnrhs
(T1 , T2 ) applying Lemma 52 using fact
ABox AT2 , role-splitting.
670

fiThe Logical Difference Lightweight Description Logic EL

Finally, obtain tractability result.
Theorem 56. Let T1 T2 ELHr -terminologies signature. set
cWtnrhs
(T1 , T2 ) computed polynomial time.
rhs
Proof. NR = , cWtnrhs
(T1 , T2 ) = iWtn (T1 , T2 ), computed
polynomial time Theorem 46.
Otherwise NR 6= result follows Lemma 55 fact AT2 ,
constructed polynomial time size T2 .

7. ELHr -Query Difference
investigate query difference ELHr -terminologies, introduce language
ELran,u,u extends ELran universal role intersections roles. show
concept differences ELran,u,u correspond query differences ELHr . ELran,u,u
prove analogue Theorem 40, states inclusion concept
difference contains inclusion either left-hand side right-hand side
atomic. Using correspondence concept difference ELran,u,u query
difference ELHr obtain meaningful definition succinct representation
query difference qDiff (T1 , T2 ). Finally, provide polynomial-time algorithms deciding
-query inseparability computing succinct representation query difference.
7.1 ELran,u,u -Concept Difference
start section defining language ELran,u,u .
Definition 57 (ELran,u,u ). Let u (the universal role) fresh logical symbol. C u,u concepts constructed using following syntax rule
C :=



|

C uD

|

R.C

|

u.C,

NC , C, range C u,u -concepts R = r1 u u rn r1 , . . . , rn NR
n 1. set ELran,u,u -inclusions consists concept inclusions C v role
inclusions r v s, C C ran -concept, C u,u -concept, r, NR .
semantics additional constructors straightforward setting, interpretation I,
(r1 u u rn )I = rI1 rnI ;
uI = .
Note regard universal role u logical symbol; i.e., u 6 NR sig(u.C) =
sig(C) concept C. Assuming u logical symbol reflects fact firstorder translation uses non-logical symbols. example, signature first-order
translation x.A(x) u.A contain non-logical symbols exception
itself.
convenient decompose C u,u -concepts. set C u -concepts defined
set C u,u -concepts without universal role. Every C u,u -concept C equivalent
671

fiKonev, Ludwig, Walther, & Wolter

concept form D0 u u.D1 u u u.Dk , D0 , . . . , Dk C u -concepts.
see this, observe concept C subconcept u.D equivalent u.D u C 0 ,
C 0 obtained C replacing occurrences u.D >. example,
u r.(B u u.E) equivalent concept u.E u u r.(B u >).
u,u
u ) set C u,u (C u ) concepts whose signature
following denote C
(C
contained .
Clearly, every ELran -inclusion ELran,u,u -inclusion. addition, role conjunctions
universal role ELran,u,u -inclusions used capture differences
ELHr -TBoxes cannot captured ELHr -inclusions.
Example 58. first reconsider Example 8. Recall
T1 = ,

T2 = {A v r.B},

= {A, B}.

T2 |= v u.B T1 6|= v u.B and, universal role regarded
logical symbol, sig(A v u.B) . Thus, employing universal role ELran,u,u
simulate query difference ({A(a)}, x.B(x)) using subsumption v u.B.
Second, reconsider Example 9. Recall
T1 = {A v s.>, v r1 , v r2 },

T2 = {A v r1 .> u r2 .>},

= {A, r1 , r2 }.

T1 |= v (r1 u r2 ).> T2 6|= v (r1 u r2 ).>. Thus, simulate query
difference ({A(a)}, x.(r1 (a, x) r2 (a, x))) using subsumption v (r1 u r2 ).>.
introduce appropriate notion -concept difference ELran,u,u .
ran,u,u
Definition 59 (EL
-difference). ELran,u,u
-difference ELHr -TBoxes T1

ran,u,u
ran,u,u
-inclusions T1 |=
(T1 , T2 ) EL
T2 set cDiff
T2 6|= .

extend Lemma 39 concepts use universal role conjunctions
roles.
Lemma 60. Let ELHr -terminology R.D C u -concept R = t1 u u tq
conjunction role names. Assume
l
l
l
|=
ran(si ) u
Aj u
rk .Ck v R.D,
1il

1jn

1km

Ck , 1 k m, C ran -concepts l, m, n 0. least one following
conditions holds:
(e1u ) exists rk , 1 k m, rk vT t1 ,. . . , rk vT tq , |= Ck uran(rk ) v
D;
(e2u ) exists Aj , 1 j n, |= Aj v R.D;
(e3u ) exists rk , 1 k m, |= rk .> v R.D;
(e4u ) exists si , 1 l, |= ran(si ) v R.D.
672

fiThe Logical Difference Lightweight Description Logic EL

u universal role |= C v u.D, C C ran -concept
C u -concept, least one following holds:
(e1u ) exists subconcept r.C 0 C |= C 0 u ran(r)v D;
(e2u ) exists concept name C |= v u.D;
(e3u ) exists role name r C |= r.> v u.D;
(e4u ) exists role name r C |= ran(r) v u.D;
(e5u ) |= C v D;
(e6u ) exists subconcept (ran(r) u C 0 ) C |= r.C 0 v D.
Theorem 61 (Primitive witnesses ELran,u,u ). Let T1 T2 ELHr -terminologies
ran,u,u
signature. cDiff
(T1 , T2 ), either exist {r, s} sig()
ran,u,u
r v cDiff
(T1 , T2 ) form C v D, one
1. C 0 v
2. v D0 , r.> v D0 ran(r) v D0
member cDiff ran,u,u
(T1 , T2 ), sig() concept name, r sig() role

0
ran
name, C C -concept, D0 C u,u -concept, sig(C 0 ), sig(D0 ) sig().
Proof. Let C v cDiff ran,u,u
(T1 , T2 ), C C ran -concept C u,u -concept.

prove result induction structure D. proof verydsimilar
proof Theorem

40 consider case = u.D1 only. Let C = 1il ran(si ) u
1jn Aj u 1km rk .Ck . Then, Lemma 60, one (e1u )(e6u ) holds.
Cases (e2u )(e4u ) directly entail existence inclusion Point 2
theorem. case (e1u ) exists subconcept r.C 0 C T1 |= C 0 uran(r) v D1 .
T2 6|= C 0 u ran(r) v D1 otherwise T2 |= r.C 0 v r.D1 , i.e.
(T1 , T2 ). apply
T2 |= C v would hold. Thus, C 0 u ran(r) v D1 cDiff ran,u,u

induction hypothesis D1 infer inclusion Point 1 Point 2 exists.
(T1 , T2 ) otherwise T2 |= C v
Similarly, case (e5u ), C v D1 cDiff ran,u,u

D1 , i.e. T2 |= C v due = u.D1 . applying induction hypothesis D1 ,
obtain inclusion Point 1 Point 2 exists.
Finally, case (e6u ) exists subconcept ran(r) u C 0 C T1 |= r.C 0 v
D1 . Observe first every model T2 every C , exists d0
(ran(r) u C 0 )I , implies exists d00 (r.C 0 )I . assume
T2 |= r.C 0 v D1 , would follow every model T2 every C ,
exists d00 D1I , i.e. T2 |= C v u.D1 would hold. infer r.C 0 v D1
ran,u,u
cDiff
(T1 , T2 ) applying induction hypothesis D1 , conclude
inclusion Point 1 Point 2 exists.
7.2 Query Difference Witnesses
start connecting concept differences ELran,u,u query differences
ELHr -terminologies. direction query differences ELHr concept differences
ELran,u,u straightforward: observe every assertion C(a) C C u,u -concept
673

fiKonev, Ludwig, Walther, & Wolter

regarded Boolean conjunctive query qC,a . example, assertion (u.Aur.B)(a)
equivalent conjunctive query xy.(A(x)r(a, y)B(y)) (details translation
provided appendix). obtain (where AC ABox defined Lemma 36):
Lemma 62. two ELHr -TBoxes T1 T2 signature , C v
cDiff ran,u,u
(T1 , T2 ) if, if, (AC , qD,aC ) qDiff (T1 , T2 ).

follows distinguish assertion C(a) C C u,u -concept
conjunctive query qC,a . follows Lemma 62 qDiff (T1 , T2 ) = ,
cDiff ran,u,u
(T1 , T2 ) = .

come (considerably involved) direction query differences concept
differences ELran,u,u . following lemma provides rather abstract description
inclusions qDiff (T1 , T2 ) reflected members cDiff ran,u,u
(T1 , T2 ) stating

given signature.
Lemma 63. two ELHr -TBoxes T1 T2 signature , qDiff (T1 , T2 ),
(T1 , T2 ) sig(0 ) sig().
exists 0 cDiff ran,u,u

interested reader extract detailed description proof given
appendix. proof Lemma 63 given appendix model-theoretic employs
close relationship conjunctive query entailment homomorphisms (Chandra
& Merlin, 1977). intuition behind result, however, rather straightforward:
(T , A) |= q[~a] conjunctive query q(~x) = ~y (~x, ~y ) ELHr -TBox , every
model (T , A) mapping variables ~x ~y ~a
-match q(~x) I. (T , A) models essentially forest-shaped: consist
tree-shaped models attached ABox individuals (cf. Lutz et al., 2009).
forest-shaped models, individuals ~y mapped individuals
mapped trees attached ABox individuals. mapping, however,
exists already conjunctive query q 0 q homomorphic image q 0 q 0
essentially forest-shaped: individuals mapped ABox individuals form trees
attached core q 0 mapped ABox individuals. words,
obtain q 0 partitioning q core subsets correspond C u,u -concepts!
Now, exists -ABox conjunctive -query q(~a) (T2 , A) |= q[~a]
(T1 , A) 6|= q[~a], find conjunctive -query q 0 behaviour
q essentially forest-shaped. (A, q 0 ) one obtain required ELran,u,u inclusion C v D, captures subtree query q 0 (a C u,u -concept) C
(a C ran -concept) ABox A. intuition last step exactly
Lemma 36.
note result holds general TBoxes terminologies.
Lemma 63 Theorem 61, directly obtain following description primitive witnesses query differences.
Theorem 64 (Primitive witness ELHr -query differences). Let T1 T2 ELHr terminologies signature. qDiff (T1 , T2 ), least one following
conditions holds (for individual names a, b):
1. ({r(a, b)}, s(a, b)) qDiff (T1 , T2 ), r, sig();
674

fiThe Logical Difference Lightweight Description Logic EL

2. (A, A(b)) qDiff (T1 , T2 ), concept name sig() ABox
sig(A) sig();
3. (A, D(b)) qDiff (T1 , T2 ), singleton ABox C u,u -concept
sig(A), sig(D) sig().
Observe Theorem 64 coincides Theorem 41 exception Point 3
concept C u,u -concept. can, therefore, define following finite
representation -query difference. Assume T1 T2 given. Define set
qWtnR
(T1 , T2 ) role -query difference witnesses set role -instance differR
ence witnesses; i.e., qWtnR
(T1 , T2 ) = iWtn (T1 , T2 );
qWtnrhs
(T1 , T2 ) right-hand -query difference witnesses set right-hand
rhs
-instance difference witnesses; i.e., qWtnrhs
(T1 , T2 ) = iWtn (T1 , T2 );
qWtnlhs
(T1 , T2 ) left-hand -instance difference witnesses set
exists C u,u -concept C ({A(a)}, C(a)) qDiff lhs
(T1 , T2 ) r
u,u
exists C -concept C ({r(a, b)}, C(c)) qDiff (T1 , T2 )
c = c = b.
set -query difference witnesses defined
rhs
lhs
qWtn (T1 , T2 ) = (qWtnR
(T1 , T2 ), qWtn (T1 , T2 ), qWtn (T1 , T2 )).

Theorem 64, qWtn (T1 , T2 ) = (, , ) if, if, qDiff (T1 , T2 ) = . Algorithms
rhs
computing qWtnR
(T1 , T2 ) qWtn (T1 , T2 ) presented section instance
difference. thus remains consider qWtnlhs
(T1 , T2 ).
7.3 Tractability qWtnlhs
(T1 , T2 )
u,u -concepts
prove tractability qWtnlhs
(T1 , T2 ) first capture expressive power C
using stronger form simulation interpretations. Let I1 I2 interpretations. -simulation I1 I2 called global intersection preserving
-simulation if, addition,

every I1 exists d0 I2 (d, d0 ) S;
(d, e) S, d0 I1 , R = {r | (d, d0 ) rI1 } =
6 , exists e0
(e, e0 ) (d0 , e0 ) rI2 r R.
write (I1 , d)
(I2 , e) exists global intersection preserving -simulation
I1 I2 (d, e) S.
Lemma 65. Let I1 I2 finite interpretations, signature, I1 , e I2 .

u,u
(I1 , d)

C C
: C I1 e C I2 .
(I2 , e)
checked polynomial time whether (I1 , d)
(I2 , e).
675

fiKonev, Ludwig, Walther, & Wolter

proof straightforward extension proof Lemma 29 polynomialtime algorithm deciding existence -simulations.
observe Theorem 2 properties canonical model IK KB K
extended C u,u -concepts (in appendix, proof given C u,u -concepts
well). Namely, C u,u -concepts C0 :
K |= C0 (a) if, if, aIK C0IK .
|= C u v C0 if, if, xC,D C0IK .
follows concept name ,
qWtnlhs
(T1 , T2 )



(IK1 , a) 6
(IK2 , a),

Ki = (Ti , A) = {A(a)}, = 1, 2. also every role name r


r qWtnlhs
(IK1 , a) 6
(T1 , T2 )
(IK2 , a) (IK1 , b) 6 (IK2 , b)
Ki = (Ti , A) = {r(a, b)}, = 1, 2. Thus, obtain following tractability
result:
Theorem 66. Let T1 T2 ELHr -terminologies signature. set
qWtnlhs
(T1 , T2 ) computed polynomial time.

8. Implementation Experiments
section, describe experimental evaluation theoretical work developed above. experiments employ CEX2 tool.4 CEX2, implemented
polynomial-time algorithms which, given acyclic ELHr -terminologies T1 T2 signature input, compute witnesses concept difference cDiff (T1 , T2 )
instance difference iDiff (T1 , T2 ).5
CEX2 written OCaml reasoner CB (Kazakov, 2009) internally used
classification engine. implementation CEX2, employed algorithms
developed paper. detail, instance difference case acyclic ELHr terminologies T1 T2 ,
compute iWtnR
(T1 , T2 ), CEX2 performs straightforward comparison role
inclusion chains entailed terminologies T1 T2 ;
compute iWtnrhs
(T1 , T2 ), CEX2 uses NotWitness algorithm Figure 7
employs Theorem 48;
compute iWtnlhs
(T1 , T2 ), CEX2 checks existence -simulation
canonical models (Theorem 49).
4. Available open-source license http://www.csc.liv.ac.uk/~michel/software/cex2/
5. extended version CEX2 computing witnesses query difference qDiff (T1 , T2 ) well
presented (Konev, Ludwig, & Wolter, 2012). addition, Konev et al. describe experiments comparing
query difference witnesses concept instance difference witnesses presented
paper.

676

fiThe Logical Difference Lightweight Description Logic EL

output iWtnlhs
(T1 , T2 ) partitioned three sets:
set left-hand atomic -instance difference witnesses, iWtnlhs,A
(T1 , T2 ),

defined set concept names exists EL-concept C
({A(a)}, C(a)}) iDiff (T1 , T2 ) (equivalently v C cDiff (T1 , T2 ));
set left-hand domain -instance difference witnesses, iWtnlhs,dom
(T1 , T2 ),

defined set role names r exists EL-concept C
({r(a, b)}, C(a)) iDiff (T1 , T2 ) (equivalently, r.> v C cDiff (T1 , T2 ));
set left-hand range -instance difference witnesses, iWtnlhs,ran
(T1 , T2 ),

defined set role names r exists EL-concept C
({r(a, b)}, C(b)) iDiff (T1 , T2 ) (equivalently, ran(r) v C cDiff (T1 , T2 )).
Obviously, holds that:
lhs,A
iWtnlhs
(T1 , T2 ) iWtnlhs,dom
(T1 , T2 ) iWtnlhs,ran
(T1 , T2 ).
(T1 , T2 ) = iWtn



concept difference case, recall
R
cWtnR
(T1 , T2 ) = iWtn (T1 , T2 ),

lhs
cWtnlhs
(T1 , T2 ) = iWtn (T1 , T2 ),

use algorithms instance case. also set
(T1 , T2 ) = iWtnlhs,X (T1 , T2 )
cWtnlhs,X

rhs
X {A, dom, ran}. compute iWtnrhs
(T1 , T2 ), CEX2 exploits cWtn (T1 , T2 )
rhs
rhs
iWtn (T1 , T2 ) (Lemma 50) first computes iWtn (T1 , T2 ) checks using
straightforward variant NotWitness algorithm concept differences whether
cWtnrhs
(T1 , T2 ).
following three subsections describe experiments conducted.
experimental settings follows. programs run PCs equipped
Intel Core 2 Duo E6400 CPU 3 GiB main memory. Version 2.0.1 CEX2
used.

8.1 Comparing Different Versions Snomed CT
applied CEX2 compare January 2009 (SM09a) July 2009 (SM09b) version Snomed CT. SM09a SM09b contain 310013 307693 concept names, respectively. versions use 62 role names, contain role inclusions
domain range restrictions present. Consequently, one infer Corollary 47 iWtn (SM09b, SM09a) = cWtn (SM09b, SM09a). follows consider
cWtn (SM09b, SM09a) only.
experiments used signatures ranging called Snomed CT subsets,
employed UK deployment Snomed CT specific areas. compared SM09a SM09b 159 signatures computing cWtn (SM09b, SM09a)
sets . considered signatures always contain 62 Snomed
CT role names. comparisons resulted non-empty difference reproduced
677

fiKonev, Ludwig, Walther, & Wolter

Table 2. none cases, differences regarding role inclusions detected.
Table 2, second column gives number concept names respective subset ,
third fifth column number concept witness differences. Observe
number differences correlate size considered signatures , i.e.
exist signatures somewhat comparable size, induce greatly varying
number difference witnesses (see e.g. subsets Diagnosis Manumat).
order determine many difference witnesses computed CEX2 obtained
straightforward comparison class hierarchies already, also computed
sets
clsWtnlhs
(SM09b, SM09a) = { | B : v B cDiff (SM09b, SM09a) }

clsWtnrhs
(SM09b, SM09a) = { B | : v B cDiff (SM09b, SM09a) }
considered comparison signatures . results obtained
also depicted Table 2. One see often great number differences cannot
detected considering classification difference only.
last three columns Table 2, give CPU times required computing
concept witnesses:
first, times given CEX2 directly applied full terminologies
SM09a SM09b;
second, times given one first extracts -modules using module extraction tool MEX (Konev, Lutz, Walther, & Wolter, 2008) SM09a and, respectively,
SM09b applies CEX2 extracted -modules. Observe -module
extracted MEX -query (and, therefore, -concept -instance) inseparable
whole terminology. Thus, computed concept witnesses same.
finally, times given if, addition computing concept witnesses full
terminologies SM09a SM09b, CEX2 also computes examples concept inclusions
logical difference explain witnesses. discuss feature CEX2
below.
One observe extracting MEX modules leads significant improvement
performance CEX2. course, signature large (e.g., Diagnosis
Finding), resulting modules almost large Snomed CT effect
less significant. Secondly, one observe additional computation example concept inclusions logical difference roughly doubles times needed
comparison.
Finally, evaluate practical feasibility using ABox approach compute
sets iWtnrhs
(SM09b, SM09a), implemented computation ABoxes ,
together ABox reasoning algorithm checking second condition Lemma 45.
tested implementation subsets Snomed CT used evaluating performance CEX2. limit size ABoxes , speed
computations, first computed modules using MEX. results obtained
678

fiThe Logical Difference Lightweight Description Logic EL

shown Table 3. size -modules computed MEX, i.e. T1 SM09b T2
SM09a, shown columns two three, respectively. expected definition , , one observe number concept role membership assertions
present ABoxes AT2 , grow large, even modules signatures
thousand concept names.
8 41 considered subsets implementation ran available physical
memory (indicated time value -) possible concept membership consequences
ABox computed. Overall, observed longest execution time
5 hours set Specmatyp. conclusion, one see straightforward
implementation ABox approach practically useful terminologies
signatures thousand concept names.
8.2 Comparing Different Versions NCI Thesaurus
also used CEX2 tool compare distinct versions NCI Thesaurus.
distributed releases NCI Thesaurus contain language constructs part
ELHr (such disjunction value restriction). obtain ELHr -terminologies,
removed inclusions contain non-ELHr constructor original terminologies.
Typically, affected 5%-8% inclusions present distributed NCI
versions. ELHr -versions generated way contain role inclusions well
domain range restrictions.
Similarly work Goncalves et al. (2011), compared 71 consecutive
ELHr -versions NCI Thesaurus ranging versions 03.10J 10.02d,
exception 05.03F 05.04d, could parsed correctly. Version 10.03h
later versions NCI Thesaurus acyclic, hence, could
handled CEX2 tool.
two consecutive versions NCIn NCIn+1 within considered range,
computed sets cWtn (NCIn+1 , NCIn ) iWtn (NCIn+1 , NCIn ) signatures =
sig(NCIn ) sig(NCIn+1 ). overview set sizes cWtnrhs
(NCIn+1 , NCIn )
lhs,A
cWtn (NCIn+1 , NCIn ) obtained found Figure 8. comparisons
sorted chronologically along x-axis according release dates NCI ontology
versions, whereas corresponding number left-hand atomic difference witnesses
right-hand difference witnesses found y-axis. One see number righthand difference witnesses remained fairly low throughout different versions. However,
occasional spikes occurred number left-hand atomic difference witnesses
maximum value 33487 comparing versions 05.01d 05.03d. Moreover, none
comparisons except shown Figure 9 left-hand role domain left-hand role
range difference witnesses identified. Overall, witnesses regarding role inclusions
detected found every two considered consecutive versions NCIn
NCIn+1 = sig(NCIn ) sig(NCIn+1 ),
cWtn (NCIn+1 , NCIn ) = iWtn (NCIn+1 , NCIn ).
running time 140 seconds 228 MiB memory required average
computing witnesses example inclusions iDiff (NCIn+1 , NCIn ). Computing witnesses example inclusions cDiff (NCIn+1 , NCIn ) average took 157 seconds
used 228 MiB memory.
679

fiKonev, Ludwig, Walther, & Wolter

Subset Name
Admin
Adminproc
Cdacarest
Crcareneur
Crcareresp
Devicetyp
Diagimg
Diagnosis
Drgadrcon
Endosfind
Endosproc
Epcream.6a
Epenema.7a
Epenema.7b
Epeye.4
Epiuds16
Famhist
Finding
Foodadrcon
Ffoodaller
Invest
Labinvest
Labinvmeth
Labisolate
Labmorph
Labspec
Labtopog
Lifestyle
Manumat
Nofoodall
Nonhuman
Pbcl
Pbhllng
Pf
Provadv
Sf
Socpercir
Specmatyp
Treatment
Vmp
Vtm

| NC |
7684
3198
355
1640
1082
6539
4162
75879
8009
178
73
403
25
6
223
1
416
168383
2378
468
14839
3904
3794
16313
4854
1221
27277
13090
90503
686
1839
5866
1113
79
1052
613
6786
8830
43660
13667
2117

|cWtnrhs
|
7
0
1
28
72
26
27
7410
131
0
1
0
0
0
0
0
8
11824
11
1
1396
61
103
150
32
3
866
77
2
1
24
633
1
0
2
0
8
10
2419
2
0

|clsWtnrhs
|
5
0
1
8
18
26
13
881
131
0
1
0
0
0
0
0
5
2497
11
1
534
45
81
150
32
3
220
41
0
1
11
116
0
0
1
0
8
8
1255
0
0

|cWtnlhs,A
|

29
6
1
197
262
22
13
12409
47
13
5
3
3
2
6
1
31
31228
15
9
5549
2520
3380
661
45
18
169
826
22
13
469
1342
27
4
158
3
2
46
9251
22
13

|clsWtnlhs
|
7
0
1
13
64
22
8
5406
47
0
3
0
0
0
0
0
4
20063
14
9
5441
133
3374
661
45
3
169
148
0
13
131
402
0
0
108
0
2
10
8740
0
0

Time (s)
cWtn -
full ontologies
358.51
344.60
337.91
399.57
377.36
369.20
444.66
844.26
1419.52
363.23
352.84
337.41
337.42
337.50
337.53
337.26
339.36
1559.23
481.20
379.42
511.12
382.32
367.20
671.36
858.11
360.80
1947.19
445.75
349.73
421.23
678.53
395.27
454.39
337.68
343.78
338.13
366.14
380.19
793.12
342.70
339.14

Time (s)
cWtn -
module extraction
9.89
8.24
6.76
15.58
12.24
8.01
38.56
486.53
10.17
7.86
7.30
7.39
6.86
6.76
7.20
6.69
8.84
1366.08
7.74
7.03
76.90
12.47
10.70
14.14
8.28
13.38
38.05
32.49
15.36
7.11
12.50
12.18
7.99
7.12
8.19
7.44
8.99
16.10
330.45
12.95
9.45

Time (s)
cWtn
examples
654.12
642.23
556.41
704.21
680.51
589.81
775.37
2699.89
1708.49
662.67
573.66
631.51
556.31
629.57
1236.84
1233.89
633.94
5017.02
1516.47
677.97
769.93
680.94
1290.83
1005.95
1113.70
1272.51
4463.05
765.10
1224.92
721.74
1907.70
1358.88
761.00
634.26
569.56
629.50
1300.47
685.35
1315.23
1247.18
633.50

Table 2: Subset Comparisons T1 = SM09b T2 = SM09a Resulting Non-Empty
Difference

680

fiThe Logical Difference Lightweight Description Logic EL

Subset Name
Admin
Adminproc
Cdacarest
Crcareneur
Crcareresp
Devicetyp
Diagimg
Diagnosis
Drgadrcon
Endosfind
Endosproc
Epcream.6a
Epenema.7a
Epenema.7b
Epeye.4
Epiuds16
Famhist
Finding
Foodadrcon
Foodaller
Invest
Labinvest
Labinvmeth
Labisolate
Labmorph
Labspec
Labtopog
Lifestyle
Manumat
Nofoodall
Nonhuman
Pbcl
Pbhllng
Pf
Provadv
Sf
Socpercir
Specmatyp
Treatment
Vmp
Vtm

| NC |

|sig(T1 ) NC |

|sig(T2 ) NC |

|{ A(a) | A(a) AT2 , }|
(in thousands)

|{ r(a, b) | r(a, b) AT2 , }|
(in thousands)

Time (s)

7684
3198
355
1640
1082
6539
4162
75879
8009
178
73
403
25
6
223
1
416
168383
2378
468
14839
3904
3794
16313
4854
1221
27277
13090
90503
686
1839
5866
1113
79
1052
613
6786
8830
43660
13667
2117

6746
3071
322
6484
5273
3617
11007
156588
8323
1487
809
1425
85
13
851
5
3126
323809
2716
636
42071
9308
10132
16281
4575
7106
27118
26233
11605
990
8728
8497
2488
386
3104
1856
6757
12928
111178
11972
7655

6750
3120
323
6375
5206
3619
11074
156441
8361
1534
826
1446
86
15
859
7
3136
324400
2723
644
42559
9302
10147
16313
4558
7064
27142
26473
11649
991
8848
8793
2487
389
3014
1860
6754
12871
111612
12018
7711

66942
12352
148
8568
4361
43743
40817
8636801
70643
210
48
641
4
0
214
0
1003
41381927
6745
326
504618
36048
36738
267268
24538
5566
723594
250140
8851332
727
13698
64174
3083
37
3202
1332
48627
112252
3716810
289683
16540

1081
480
52
651
503
830
1220
14134
1095
148
82
198
19
10
120
8
301
30521
353
87
4224
1147
1203
2033
628
570
3294
2374
12127
132
926
1357
344
59
378
270
889
1580
10578
2629
970

9291.75
1642.41
3.86
3110.07
3689.22
2381.00
12503.63
2097.23
143.87
17.88
315.58
0.32
0.06
60.80
0.05
137.34
277.80
11.57
8632.09
4131.02
7785.59
1275.48
646.59
26.99
10110.25
16410.12
933.00
3.86
518.47
249.26
5819.23
18306.56
2861.37

Table 3: Performance ABox Approach Computing iWtnrhs
(SM09b, SM09a)

681

fiKonev, Ludwig, Walther, & Wolter

35000
Nr Right-Hand Witnesses
Nr Left-Hand Atomic Witnesses
30000

25000

20000

15000

10000

5000

0

lhs,A
Figure 8: Sizes cWtnrhs
(NCIn+1 , NCIn ) Consec (NCIn+1 , NCIn ) cWtn
utive ELHr -versions NCIn NCIn+1 NCI Thesaurus

T1
04.04j
04.11a
05.03d
06.02d
08.10e
08.12d
09.06e

T2
04.03n
04.09a
05.01d
06.01c
08.09d
08.11d
09.05d

| NC |
34245
35976
38020
45582
66052
68229
70493

| NR |
76
91
92
113
123
123
123

|cWtnrhs
|
252
106
138
419
1774
968
1305

|cWtnlhs,A
|

4926
4023
33487
1438
19055
4726
575

|cWtnlhs,dom
|

1
2
92
1
113
114
1

|cWtnlhs,ran
|

1
2
92
1
113
113
1

lhs
Figure 9: Detailed Results cWtnrhs
(T1 , T2 ) cWtn (T1 , T2 ) Selected Versions
NCI Thesaurus using Shared Signatures = sig(T1 ) sig(T2 )

682

fiThe Logical Difference Lightweight Description Logic EL

peaks atomic left-hand difference witnesses mostly resulted changes
general concepts. mentioned already, Goncalves et al. (2011) provide indepth analysis NCI versions. systematic comparison methods used Goncalves
et al. logical diff introduced paper would interesting, beyond
scope paper. One interesting observation made is, however,
peak atomic left-hand witnesses observed versions 05.01d 05.03d
correlates fact according Goncalves et al. large number non-redundant
axioms added version 05.03d. However, comparable number non-redundant
axioms also added version 04.12g, peak atomic left-hand right-hand
witnesses observed analysis.
8.3 Scalability Analysis
demonstrated previous sections CEX2 capable finding logical difference two unmodified versions Snomed CT distinct versions
NCI thesaurus restricted ELHr . order see CEX2s performance scales,
also tested randomly generated acyclic terminologies various sizes. randomly
generated terminology contains certain number defined- primitive concept names
role names. ratio concept equations concept inclusions fixed,
ratio existential restrictions conjunctions. random terminologies
generated varying number defined concept names using parameters SM09a:
62 role names; equality-inclusion ratio 0.525; exists-conjunction ratio 0.304.
every chosen size, generated 10 samples consisting two random terminologies
described above. applied CEX2 find logical difference two terminologies joint signature. Figure 10 shows average memory consumption CEX2
10 randomly generated terminologies various sizes. 10(a) maximum length
conjunctions fixed two (M=2), 10(b) number conjuncts conjunction randomly selected two M. seen performance
CEX2 crucially depends length conjunctions. 10(b), curves break
point CEX2 runs physical memory6 . instance, case M=22,
happens terminologies 7 500 defined concept names. Finally, note
time required CEX2 compare two random terminologies highly varied
across different samples. maximum time required CEX2 11 333 seconds.
8.4 Additional User Support Analysing Differences
far discussed experiments CEX2 one computes set concept
instance difference witnesses two terminologies. Clearly, witnesses
provide sufficient information detailed analysis logical difference two
terminologies. thorough analysis, required consider examples
cDiff (T1 , T2 ) iDiff (T1 , T2 ) show certain concept names concept/instance
difference witnesses. Thus, whenever searches concept names
exists C C v cDiff (T1 , T2 ), CEX2 output example concept inclusions
C v cDiff (T1 , T2 ). Similarly, requested, CEX2 also compute example inclusions
6. cases classification terminologies CB already requires 3 GiB
memory.

683

fiKonev, Ludwig, Walther, & Wolter

1200

3500

3000

Memory Consumption MiB

Memory Consumption MiB

1000

800

600

400

2500

2000

1500

1000

200
500

M=10

M=2

M=22

0

Number Concept Names

95
00

85
00

75
00

65
00

55
00

45
00

35
00

25
00

15
00

50
0

10
00
0
30
00
0
50
00
0
70
00
0
90
00
0
11
00
00
13
00
00
15
00
00
17
00
0
19 0
00
00
21
00
00
23
00
00
25
00
00
27
00
00
29
00
0
31 0
00
00
33
00
00
35
00
00

0

Number Concept Names

(a) Short Conjunctions

(b) Long Conjunctions

Figure 10: Memory Consumption CEX2 Randomly Generated Terminologies
illustrating left-hand concept differences v C, r.> v C, ran(r) v C, examples
instance difference case. know Example 12 even minimal examples
exponential size input terminologies. practice, however, Snomed CT
NCI additional computation example inclusion every concept/instance
difference witness doubles times required computation. described
already, observed Table 2, computation times examples
shown last column computation times without examples shown
7th column. examples computed CEX2 often reasonable size. instance,
consider subset Specimen Material Type (Specmatyp) Table 2, holds
(i) exist 10 right-hand -concept witnesses, i.e. |cWtnrhs
(SM09b, SM09a)| = 10;
(SM09b, SM09a),
(ii) set left-hand atomic -concept difference witnesses, cWtnlhs,A

contains 46 concept names.
Point (i) (ii), longest concepts C, C v cDiff (SM09b, SM09a)
v cDiff (SM09b, SM09a) computed CEX2 twelve concept role
name occurrences (thus far smaller exponential worst case suggests).
computed difference witnesses also example concept inclusions
witnesses, interest explain example concept inclusion entailed one
terminology other. Computing minimal subsets terminology entail
example concept inclusion promising approach explaining logical differences
also known axiom pinpointing justification. supported CEX2,
investigated extensively various description logics including EL (Schlobach & Cornet,
2003; Baader, Penaloza, & Suntisrivaraporn, 2007; Kalyanpur, Parsia, Horridge, & Sirin,
2007; Horridge, Parsia, & Sattler, 2010; Penaloza & Sertkaya, 2010). illustrate
approach, consider subset Specimen Material Type (Specmatyp) Table 2.
CEX2 outputs
VenipunctureForBloodTest cWtnlhs,A
(SM09b, SM09a).

684

fiThe Logical Difference Lightweight Description Logic EL

(1)

LaboratoryTest v LaboratoryProcedure u EvaluationProcedure
BloodTest LaboratoryTest u roleGroup. hasSpecimen. BloodSpecimen

(2)

(3) VenipunctureForBloodTest (roleGroup.hasFocus .BloodTest)
u Venipuncture
u (roleGroup.((procedureSiteDirect.VenousStructure)
u (method.PunctureAction)))

Figure 11: Minimal Axiom Set
also computes following concept inclusion (slightly simplified hand) member cDiff (SM09b, SM09a):
()

VenipunctureForBloodTest
v roleGroup.hasFocus.EvaluationProcedure

Using axiom pinpointing one compute minimal set inclusions SM09b
entails concept inclusion above; set shown Figure 11. Axioms 2 3
terminologies, SM09a contains
LaboratoryTest v LaboratoryProcedure
instead Axiom 1, explains difference two terminologies. Note
concept role names shaded grey. seen interaction
-concepts heavily depends inclusions built mainly non-concepts; actually none inclusions required derive () -inclusion.
finally note CEX2 text-based tool. order make accessible
ontology users, Protege plugin, LogDiffViz7 , created, calls CEX2 visualises
ontology versions differences hierarchical structure. LogDiffViz also
provides basic axiom pinpointing. plugin distributed self-contained Java archive
file (JAR) CEX2 bundled.

9. Related Work
describe relationship work presented paper existing work
logical difference inseparability ontologies. Related work versioning distinction syntactical, structural, logic-based approaches versioning
discussed introduction already presented here. problem
deciding whether two ontologies -inseparable signature investigated many ontology languages different notions inseparability concept
inseparability, instance inseparability, conjunctive query inseparability, model-theoretic
inseparability (i.e., -reducts models first ontology coincide -reducts
models second ontology). Inseparability also closely related notion conservative extensions since one ontology conservative extension another ontology
contains ontology subset inseparable w.r.t. signature
7. Available http://protegewiki.stanford.edu/wiki/Logical_Difference_Vizualiser_(LogDiffViz)

685

fiKonev, Ludwig, Walther, & Wolter

smaller ontology. Thus, algorithmic results deciding conservativity directly relevant inseparability well. tractability results presented paper sharp
contrast known results. start general EL-TBoxes: general ELTBoxes deciding inseparability conservative extensions ExpTime complete problems
concept, instance conjunctive queries. problems undecidable modeltheoretic inseparability model-theoretic conservative extensions (Lutz & Wolter, 2010).
(We note, however, model-theoretic case unexpected positive algorithmic results
obtained Konev, Lutz, et al., 2008, acyclic EL ALC extensions
inverse roles.) ALC standard extensions without nominals deciding concept
inseparability conservative extensions 2ExpTime-complete (Ghilardi, Lutz, & Wolter,
2006; Lutz et al., 2007; Lutz & Wolter, 2011) ALCQIO deciding concept inseparability conservative extensions becomes undecidable (Lutz et al., 2007; Cuenca Grau
et al., 2008). Nothing known ALC complexity inseparability instance
conjunctive queries. DL-Lite dialects (Calvanese, Giacomo, Lembo, Lenzerini, &
Rosati, 2006), complexity concept, instance, query inseparability ranges
PSpace-hard (and ExpTime) description logic underlying OWL 2 QL standard, NP-complete DL-Litehorn , p2 -complete DL-Litebool (Konev, Kontchakov,
Ludwig, Schneider, Wolter, & Zakharyaschev, 2011; Kontchakov et al., 2010). DLLitebool model-theoretic inseparability decidable (Kontchakov et al., 2010) DLLitecore concept, instance, query inseparability PTime (Konev et al., 2011).
contrast work presented paper, however, attempt made present
logical difference user two ontology inseparable. mentioned above,
work Konev et al. (2012), CEX2 extended conjunctive query difference case
acyclic ELHr -terminologies various experiments based NCI thesaurus
discussed.
work discussed far concerned logical difference inseparability description logic TBoxes. difference description logic concepts
investigated, example, work Teege (1994), Brandt, Kusters, Turhan
(2002) besides interest kind difference problems considered well
techniques employed rather different. Inseparability conservativity
ontologies given ontology languages expressive description logics (including first-order logic) considered work Kutz Mossakowski (2008,
2011). Similar relationships theories also investigated answer set
programming (Pearce & Valverde, 2004; Eiter, Fink, & Woltran, 2007; Pearce & Valverde,
2012).
Finally, note Lemma 15 ABox constructed Figure 3 appear capture describe fundamental properties EL ELHr -terminologies.
applied investigate seemingly unrelated problems query containment ontology
based data access using EL-terminologies (Bienvenu, Lutz, & Wolter, 2012b) first-order
rewritability instance queries (Bienvenu, Lutz, & Wolter, 2012a).

10. Conclusion
paper, presented polytime algorithms decide concept, instance,
query-inseparability w.r.t. signature ELHr -terminologies compute represen686

fiThe Logical Difference Lightweight Description Logic EL

tation difference non-empty. Experiments using CEX2 based SNOMED
CT NCI show outputs given algorithm mostly reasonable size
analysed users. Many extensions, applications, open problems remain
explored. mention them:
(1) motivated study -inseparability terminologies problem comparing different versions terminology regarding say
certain signature. potential promising applications found area
decomposing composing ontologies. example, importing ontology
ontology 0 (i.e., forming 0 ) often important ensure 0
interfere signature . words, 0 conservative extension
sense consequences 0 signature coincide
consequences (Cuenca Grau et al., 2008; Ghilardi et al., 2006; Vescovo,
Parsia, Sattler, & Schneider, 2011). observed already, -inseparability generalises conservative extensions and, therefore, algorithms used check whether
one terminology conservative extension another terminology. Algorithms checking
conservative extensions also used extract modules ontologies (Cuenca Grau
et al., 2008; Kontchakov, Pulina, Sattler, Schneider, Selmer, Wolter, & Zakharyaschev, 2009;
Konev et al., 2011). would interest explore applications inseparability
testing algorithms extract modules terminologies check conservativity.
(2) Inseparability defined paper mean one terminology
replaced another terminology every context. various applications inseparability
modularity important ensure T1 T2 -inseparable, T1
T2 -inseparable well, ontology . called replacement
property Konev, Lutz, Walther, Wolter (2009) exploited discussed,
example, work Cuenca Grau et al. (2008) Kontchakov et al. (2010).
notions inseparability introduced paper replacement property.
see this, let = {A, A0 , B, B 0 }

T1 =

v r.B
A0 r.B 0




T2 =

v r.B
A0 v r.B 0


.

T1 T2 -query inseparable (and, therefore, -concept -instance inseparable),
T1 even -concept inseparable T2 , = {B v B 0 }. Indeed,
observe (T1 ) |= v A0 , (T2 ) 6|= v A0 .
important open research problem determine complexity of, develop
algorithms strong versions inseparability replacement property EL
ELHr -terminologies.
(3) ELHr rather weak description logic. would great interest explore
far techniques developed ELHr applied ontologies contain additional constructors, still consist mainly ELHr -inclusions. unlikely tractable
sound complete algorithms interesting extensions exist, seems worth exploring algorithms sound incomplete extensions algorithms presented
paper. results direction presented Goncalves, Parsia, Sattler
(2012).
687

fiKonev, Ludwig, Walther, & Wolter

Acknowledgments
research supported EPSRC grant EP/H043594/1. would like thank
William Gatens development LogDiffViz Protege plugin three anonymous
reviewers helpful comments.

Appendix A. Proofs Section 2
Lemma 1 every terminology , one construct polynomial time normalised
terminology 0 polynomial size |T | sig(T ) sig(T 0 ), 0 |= , every
model exists model J 0 = J X = X J every
X sig(T ). Moreover, 0 acyclic acyclic.
Proof. Given terminology , construct normalised terminology 0 five steps follows:
First, remove occurrences > conjunctions, replace C occurrence r.C,
C concept name >, fresh concept name add concept
definition C terminology. Repeat last step exhaustively.
Second, replace every ri .Bi inclusion right-hand side form F u
r1 .B1 u u rm .Bm (m 1), Bi either concept name Bi = >, F
conjunction concept names F 6= > 2, fresh concept name
Bi0 add concept definition Bi0 ri .Bi terminology.
Third, replace every inclusion form r.> two inclusions v r.>
r.> v terminology.
Fourth, consider concept name sequences B0 , . . . , Bn1
F0 , . . . , Fn , Fi conjunctions concept names, terminology
contains concept definitions F0 Bi Fi+1 , < n, Bi conjunct
Fi conjunct Fn . Let Fn0 conjunction concept names Fn except A. Let,
0
recursively, Fi1
result replacing conjunct Bi1 Fi1 conjunction
0
Fi , 1 n. Replace concept definition F0 terminology
primitive concept definition v F00 .
Fifth, inclusion F , v F , r.> v F , ran(r) v F , F
conjunction concept names, replace every conjunct B F B F 0
terminology, F 0 conjunction non-conjunctive concept names, F 0 .
see construction indeed yields normalised terminology 0 , observe
steps 1, 2, 3 ensure inclusion one following forms: r.B,
F , E v r.B, E v r.>, E v F , B concept name, E either concept
name, form s.>, ran(s), F conjunction (possibly conjunctive)
concept names. Step 4 breaks cycles concept definitions Step 5 takes care
conjuncts conjunction concept names F right-hand side inclusion
form F , v F , r.> v F , ran(r) v F non-conjunctive concept names.
readily verified 0 acyclic acyclic none steps introduces cycles
concept definitions.
show 0 obtained polynomial time 0 polynomial
size |T |. Let n number inclusions c maximal length inclusions
right-hand side . Clearly, steps 1, 2 3 increase number
inclusions c n, raising total number inclusions 4nc. Steps 4
688

fiThe Logical Difference Lightweight Description Logic EL

5 increase number inclusions, length right-hand sides.
length right-hand side inclusion increase sum lengths
right-hand sides inclusions, i.e., 4nc2 upper bound right-hand
side. upper bound running time steps construction
therefore 16n2 c3 . Hence, size 0 running time construction
O(n2 c3 ).
Notice every new concept name occurs left-hand side unique concept
definition C 0 . Thus, every model expanded model J 0
interpreting fresh concept names sig(T 0 ) \ sig(T ) setting AJ = C .
Moreover, readily checked 0 |= .
prove extended version Theorem 2 according EL-concepts
concepts form ran(r) evaluated correctly canonical model IK ,
also C u,u -concepts (which introduced Definition 57).
Theorem 2[Extended Version] Let K = (T , A) ELHr -KB.
1. IK model K;
2. IK computed polynomial time size K;
3. xC,D IK obj(A), C0 C u,u -concept form ran(r),

K |= C0 (a) if, if, aIK C0IK .
|= C u v C0 if, if, xC,D C0IK .
Proof. Point 2 follows fact instance checking ELHr done polynomial time.
first prove Point 3 EL-concepts C0 sub(T ). proof simultaneous
induction construction C0 . interesting step C0 = r.D0 .
start proof direction left right. Assume first K |= C0 (a).
(a, xran(r),D0 ) rIK . |= (ran(r) u D0 ) v D0 . Thus, induction
hypothesis, xran(r),D0 D0IK . C0IK , required. assume |= C uD v C0 .
(xC,D , xran(r),D0 ) rIK . |= (ran(r) u D0 ) v D0 . induction
hypothesis, xran(r),D0 D0IK . xC,D C0IK , required.
Conversely, assume aIK C0IK . exists IK (aIK , d) rIK
D0IK . Assume first = b obj(A). induction hypothesis, K |= D0 (b).
exists s(a, b) vT r. Thus, K |= C0 (a), required. Assume
= xran(s),F . K |= s.F (a), vT r xran(s),F D0IK . induction
hypothesis, |= ran(s) u F v D0 . Thus, K |= C0 (a), required.
assume xC,D C0IK . exists xran(s),F |= C u v s.F , vT r
xran(s),F D0IK . induction hypothesis, |= ran(s) u F v D0 . Thus |= C u v
r.D0 , required.
prove Point 3 concepts form C0 = ran(r). Assume K |= (ran(r))(a).
exist b s(b, a) vT r. ran(r)IK . Conversely,
689

fiKonev, Ludwig, Walther, & Wolter

assume ran(r)IK . Then, definition IK , exist b s(b, a)
vT r. Hence K |= (ran(r))(a), required.
Assume |= C u v ran(r). have, C = ran(s), vT r. xC,D
ran(r)IK since path WK tail xC,D . converse direction similar.
follows proved far IK model (T , A). Thus
proved Point 1, remains prove Point 3.
prove Point 3 arbitrary C u,u -concepts C0 . interesting step C0 = S.D0 ,
= r1 u u rn .
Assume first K |= C0 (a). C0IK since IK model K. Similarly,
|= C u v C0 , xC,D C0IK since xC,D (C u D)IK IK model .
Conversely, assume C0IK . exists IK (aIK , d) IK
D0IK . Assume first = b obj(A). induction hypothesis, K |= D0 (b).
every ri , 1 n, exists si si (a, b) si vT ri . Thus, K |= C0 (a),
required.
Assume = xran(s),F . K |= s.F (a), vT ri 1 n
xran(s),F D0IK . induction hypothesis, |= ran(s) u F v D0 . Thus, K |= C0 (a),
required.
assume xC,D C0IK . exists xran(s),F |= C u v s.F , vT ri ,
1 n, xran(s),F D0IK . induction hypothesis, |= ran(s) u F v D0 . Thus
|= C u v S.D0 , required.

Appendix B. Proofs Section 5
proofs, require models infinite sets concepts. introduce notation
well known result existence minimal models. Let (possibly
infinite) set C ran -concepts (which introduced Definition 32), ELHr -TBox,
either C u,u -concept (which introduced Definition 57) C ran -concept. write
|= say included w.r.t. if, every model ,
DI follows C C . following observation follows fact
C u,u C ran -concepts equivalent Horn formulas (in sense Chang
Keisler, 1990):
Lemma 67. ELHr -TBoxes sets C ran -concepts exists model
following equivalent, C u,u C ran -concepts D:
|= D;
DI .
come proof Lemma 36. convenience reader formulate
result again.
Lemma 36. every ELHr -TBox , ABox A, C ran -concepts C0 D0 ,
a0 obj(A):
n,ran
(T , A) |= D0 (a0 ) if, if, exists n 0 |= CA,a
v D0 ;
0

690

fiThe Logical Difference Lightweight Description Logic EL

|= C0 v D0 if, if, (T , AC0 ) |= D0 (aC0 ).
n,ran
(a0 )
Proof. prove Point 1. direction right left observe |= CA,a
0
n,ran
n 0. Thus, |= CA,a0 v D0 implies (T , A) |= D0 (a0 ).
ran |= . Then, using compactness,
assume (T , A) |= D0 (a0 ). show CA,a
0
0
n,ran
find n 0 |= CA,a0 v D0 , required.
ran 6|= . Take, every obj(A), model point
Assume CA,a
0

0

ran |= C.
da C ran -concepts C: da C Ia if, if, CA,a
models exist Lemma 67. may assume mutually disjoint. Take
following union models Ia :

= aobj(A) Ia ;

AI = aobj(A) AIa , NC ;

rI = aobj(A) rIa {(da , db ) | r0 (a, b) A, r0 vT r}, r NR ;

aI = da , obj(A).
Claim 1. C ran -concepts C obj(A) following holds Ia :
C Ia iff C .
proof induction construction C. interesting cases C = ran(r)
C = r.D direction right left.
Let
C assume first C = ran(r). Let C Ia (d0 , d) rI .
(d0 , d) aobj(A) rIa , claim follows definition. Otherwise, = da , d0 = db
n,ran
every n 0. Hence,
b r0 (b, a) r0 vT r. Thus, ran(r0 ) CA,a
ran


CA,a |= ran(r) obtain C .
Assume
r.D C Ia . Take d0 (d, d0 ) rI d0 DI .
C =
0

0
(d, ) a0 obj(A) r , C Ia follows immediately induction hypothesis.
Otherwise, = da d0 = db b r0 (a, b) r0 vT r. induction
ran |= D. compactness, exists concept E C ran
hypothesis, d0 DIb . Hence, CA,b
A,b
n,ran
every n > 0.
|= E v D. r0 (a, b) A, obtain r0 .E CA,a
ran |= r 0 .D obtain C Ia using r 0 v r. finishes proof
then, CA,a


claim.
Now, C v , let C , i.e. Ia obj(A).
Claim 1 C Ia , implies DIa C Ia DIa . conclude
DI applying Claim 1 again. Similarly, one show C = DI every
C rI sI every r v . follows model .
construction I, (aI , bI ) rI every r(a, b) A. Moreover, A(a)
ran |= A, implies AIa aI AI
obj(A), holds CA,a

ran 6|= ,
claim. thus infer model (T , A) 6|= D0 (a0 ) CA,a
0
0
Ia

implies da0 6 D0 0 aI0 6 D0I , Claim 1. Hence, (T , A) 6|= D0 (a0 )
derived contradiction.
proof Point 2 simple application definition.
691

fiKonev, Ludwig, Walther, & Wolter

prove cut elimination, correctness, completeness calculus ELHr
given Figures 1 5. start basic observations, easily proved
induction length derivations.
Lemma 68. ELHr -terminology , C ran -concepts C, role names r,

1. ` > v D, ` C v D;
2. ` C v v CA CA , ` C v CA ;
3. ` C v r.D ` C v r.(D u ran(r));
4. ` C v r.D, r.> v B , ` C v B;
5. ` C v ran(r) ran(r) v , ` C v A;
6. ` C v r.D, r v , ` C v s.D;
7. ` C v ran(r) r v , ` C v ran(s).
Lemma 69 (Cut elimination). ELHr -terminology , C ran -concepts C, D, E,
` C v ` v E ` C v E.
Proof. Let D1 derivation C v D2 derivation v E. Let Li
length Di , = 1, 2. proof lemma induction lexicographical
ordering pairs (L2 , L1 ).
case L2 = 0 L1 = 0, well cases L2 ends one
AndL1, AndL2, AndR, Ex, DefL, DefR PDefL virtually
proof Hofmann (2005). Assume D2 ends Dom, last sequent form
r.D0 v E, sequent B v E. Lemma 68, Item 4, ` C v r.D0
implies ` C v B, induction hypothesis, ` C v E.
cases D2 ends ExRan, Ran, Sub, RanSub dealt
similar way using Lemma 68, Items 3, 57.
Theorem 38. Let ELHr -terminology; C0 D0 C ran -concepts. |=
C0 v D0 if, if, ` C0 v D0 .
Proof. easily checked proof system rules sound ` C0 v D0 ,
|= C0 v D0 .
Conversely, assume |= C0 v D0 . prove ` C0 v D0 construct
interpretation based derivability sequents . show model
. consequence obtain C0I D0I conclude ` C0 v D0 based
properties I.
domain set well-formed pairs x = hC, RC i, C C ran -concept
RC finite set role names
l
NR : ` (C u
ran(r)) v ran(s), RC .
rRC

692

fiThe Logical Difference Lightweight Description Logic EL

introduce following abbreviation. Let
l
Ran(RC ) =
ran(r).
rRC

C ran -concepts C interpreted
I(C) = {hD, RD | ` (D u Ran(RD )) v C},
r NR interpreted
I(r) = {(hC, RC , hD, RD i) | r RD
` (C u Ran(RC )) v r.(D u Ran(RD ))}.
Note I(C) nonempty every C: consider R0C = {s NR | ` C v ran(s)}.
0
finite, R0C finite.
Notice that, Ax AndR, ` C v C u Ran(RC ) so,
Lemma 69, ` (C u rR0 ran(r)) v ran(s), s, ` C v ran(s), R0C .
C


ff


ff
is, C, R0C well-formed pair and, obviously, C, R0C I(C).
show I(C) = C C ran -concepts C. proof induction
construction C.
1. I(>) = .
well-formed pair hC, RC i, ` C u Ran(RC ) v > axiom.
2. I(C u D) = I(C) I(D).
Let hC, RC I(D1 u D2 ), ` (C u Ran(RC )) v (D1 u D2 ). Since ` (D1 u D2 ) v
D1 , Lemma 69, ` (C u Ran(RC )) v D1 , is, hC, RC I(D1 ). Similarly,
hC, RC I(D2 ).
Conversely, suppose hC, RC I(D1 ) hC, RC I(D2 ) holds, is, ` (C u
Ran(RC )) v D1 ` (C uRan(RC )) v D2 . AndR, ` (C uRan(RC )) v (D1 uD2 ),
is, hC, RC I(D1 u D2 ).
3. I(r.C) = {x | I(C) : (x, y) I(r)}.
Suppose well-formed pair hD, RD hD, RD I(r.C), `
(D u Ran(RD )) v r.C. Then, Lemma 68, Item 3, ` (D u Ran(RD )) v r.(C u ran(r)).
Consider RrC = {s NR | ` (C u ran(r)) v ran(s)}. Clearly, r RrC and, similarly
argument R0C above, hC, RrC well-formed pair. Ax AndR, `
Curan(r) v CuRan(RrC ), Ex, ` r.(Curan(r)) v r.(CuRan(RrC )) Lemma 69,
` (D u Ran(RD )) v r.(C u Ran(RrC )). Then, definition, (hD, RD , hC, RrC i) I(r)
and, since ` (C u Ran(RrC )) v C, hC, RrC I(C).
Conversely, let (hD1 , RD1 , hD2 , RD2 i) I(r) hD2 , RD2 I(C), is, ` (D1 u
Ran(RD1 )) v r.(D2 uRan(RD2 )), r RD2 , ` (D2 uRan(RD2 )) v C. Ex
` r.(D2 u Ran(RD2 )) v r.C, and, Lemma 69, ` (D1 u Ran(RD1 )) v r.C,
is, hD1 , RD1 I(r.C).
4. I(ran(r)) = {y | x : (x, y) I(r)}.
First show I(ran(r)) = {hC, RC | r RC }. r RC , `
C u Ran(RC ) v ran(r), is, I(ran(r)) {hC, RC | r RC }. Suppose hC, RC
I(ran(r)), is, ` (C u Ran(RC )) v ran(r). Then, since hC, RC well-formed pair,
r RC , is, I(ran(r)) {hC, RC | r RC }.
693

fiKonev, Ludwig, Walther, & Wolter

Suppose hC, RC I(ran(r)), is, hC, RC r RC . Let
denote (C u Ran(RC )). induction length derivations one see sequent
form r.D v ran(s) derivable NR . Therefore, hr.D, wellformed pair (hr.D, , hC, RC i) I(r). Conversely, let (hD1 , RD1 , hD2 , RD2 i) I(r)
then, particular, r RD2 . is, hD2 , RD2 I(ran(r)).
show model . need show axioms true
I.
1. I(X) I(CX ), whenever X CX X v CX .
Let hC, RC I(X), is, ` (C u Ran(RC )) v X. Lemma 68, Item 2, `
(C u Ran(RC )) v CX , is, hC, RC I(CX ).
2. I(CX ) I(X), whenever X CX .
Let hC, RC I(CX ), is, ` (C u Ran(RC )) v CX . Since Ax DefR
` CX v X, Lemma 69, ` (C u Ran(RC )) v X, hC, RC I(X).
3. (x, y) I(r) I(A), whenever ran(r) v .
Let (hC, RC , hD, RD i) I(r), is, ` (C u Ran(RC )) v r.(D u Ran(RD ))
r RD . Since r RD and, as, Ax Ran, ` ran(r) v A, AndL1, AndL2
` (D u Ran(RD )) v A, is, hD, RD I(A).
4. (x, y) I(r) x I(B), whenever r.> v B .
Let (hC, RC , hD, RD i) I(r), is, ` (C u Ran(RC )) v r.(D u Ran(RD ))
r RD . Notice that, Lemma 68, Item 4, ` (C u Ran(RC )) v B, is,
hC, RC I(B).
5. I(s) I(r), whenever v r .
Let (hC, RC , hD, RD I(r)), ` (C uRan(RC )) v r.(DuRan(RD )) r RD .
Lemma 68, Item 6, ` (C u Ran(RC )) v s.(D u Ran(RD )). Since r v ,
Ax RanSub, ` ran(r) v ran(s) ` (D u Ran(RD )) v ran(s) AndL1
AndL2. Since hD, RD well-formed, RD . Thus, (hC, RC , hD, RD i) I(s)


ff
|= C0 v D0 , I(C0 ) I(D0 ). Since C0 , R0C0 I(C0 ),


ff
C0 , R0C0 I(D0 ), ` (C0 u Ran(R0C0 )) v D0 . ` C0 v C0 u Ran(R0C0 ),
` C0 v D0 Lemma 69.
Proof Lemma 44. Let normalised ELHr -terminology signature. Additionally, let -ABox, sig(T ) non-conjunctive obj(A).
direction (1.) (2.), direct consequence construction ,
b obj(A) B sig(T ) non-conjunctive (T , A) 6|= B(b)
B obj(AT , ).
Assume (T , A) 6|= A(a). obj(AT , ). define -range simulation setting,
b obj(A) B sig(T ) non-conjunctive B obj(AT , ) :
(b, B ) if, if, (T , A) 6|= B(b),
(b, ) b obj(A).
show indeed -range simulation (a, ) verifying
conditions (S1)(S3) (RS) introduced page 663 hold.
694

fiThe Logical Difference Lightweight Description Logic EL

(S1)

(T , A) 6|= A(a) obj(AT , ), immediately follows (a, ) S.

(S2) Let (b, ) B(b) B . prove B() , .
= B B sig(T ) non-conjunctive , obtain definition
(T , A) 6|= B(b). Moreover, holds B 6 preC
(B) otherwise (T , A) |= B(b).
Thus, definition , (B) B(B ) , . = , immediately
follows B( ) , definition , .
(S3) Now, let (b, ) r(b, b0 ) r . prove exists
0 obj(AT , ) (b0 , 0 ) r(, 0 ) , . = , immediately follows
definition , r( , ) , (b0 , ) holds definition S.
= B B sig(T ) non-conjunctive follows definition
(T , A) 6|= B(b). Additionally, infer r 6 preDom
(B) otherwise
(T , A) |= (r.>)(b) would imply (T , A) |= B(b).
Consider cases B defined . B pseudo-primitive , obtain
definition , (B) r(B , ) , holds (b0 , ) definition
S.
B r0 .B 0 , distinguish following two cases. r 6
0

0
preRole
(r ), obtain r \ (preRoleT (r ) preDomT (B)) thus r(B , ) ,
definition , holds (b0 , ) definition S. case
0

0
r preRole
(r ), r preRoleT (r ) \ preDomT (B). Furthermore, (T , A) 6|=
0
0
B(b) (T , A) 6|= (r .B )(b), easy see must exist Bi00 non-conjT (B 0 )
00
00 0
r 6 preRan
(Bi ) (T , A) 6|= Bi (b ). r(B , Bi00 ) ,
0
definition , (B) (b , Bi00 ) definition S.
(RS) Let (b, ) r(c, b) r . show exists
0 r( 0 , ) , . = B B sig(T ) non-conjunctive , obtain
definition (T , A) 6|= B(b). Furthermore, r 6 preRan
(B)
otherwise (T , A) |= B(b). Thus, definition , (B) r( , B ) , .
= , follows definition , r( , ) , .
converse direction (2.) (1.), assume obj(AT , ) (A, a) ran

(AT , , ). sufficient show n
n,ran
6|= CA
vA
, ,A

implies (T , , ) 6|= A(A ) Lemma 36. obtain Lemma 42
(T , A) 6|= A(a) holds.
Thus, prove induction n every concept name B sig(T )
n,ran
non-conjunctive B obj(AT , ), 6|= CA
v B.
, ,B
Let n = 0 B sig(T ) non-conjunctive B obj(AT , ). follows

l
l
l
0,ran
0
CA
=
B
u
ran(s)
u
ran(s)
, ,B
B 0 \preC
(B)

s\preRan
(B)

695

Ar.BT
Bnon-conjT (B)


spreRole
(r)\(preDomT (A)preRanT (B))

fiKonev, Ludwig, Walther, & Wolter

0,ran
Hence, one see every subconcept form ran(s) occurs CA
,
, ,B

obtain 6 preRan
(B). B non-conjunctive , holds either B
pseudo-primitive B r0 .B 0 . Hence, Lemma 39 conclude
0,ran
6|= CA
v B.
, ,B
n > 0, let B sig(T ) non-conjunctive B obj(AT , ).
distinguish following two cases. B pseudo-primitive , obtain
n,ran
CA
=
, ,B

l

l

B0 u

s\preRan
(B)

B 0 \preC
(B)

l

ran(s) u

ran(s)

Ar.BT
Bnon-conjT (B)


spreRole
(r)\(preDomT (A)preRanT (B))

u

l

s.Cs

s\preDom
(B)
n,ran
v B.
C ran -concepts Cs . follows Lemma 39 6|= CA
, ,B
0
0
B r .B , obtain
n,ran
=
CA
, ,B

l
B 0 \preC
(B)

u

l

B0 u

s\preRan
(B)

l

ran(s)

Ar.BT
Bnon-conjT (B)


spreRole
(r)\(preDomT (A)preRanT (B))

l

s.Cs u


0
s\(preRole
(r )preDomT (B))

l

ran(s) u

n1,ran
s.CA
, , 00

B 00 non-conjT (B 0 )
0 )\(preDom (B)preRan (B 00 ))
spreRole
(r




B

C ran -concepts Cs . easy see conditions (e2), (e3) (e4) Lemma 39
n,ran
v B hold, condition (e1) would fulfilled.
hold. Thus, |= CA
, ,B
n,ran
n1,ran
B 00 non-conjT (B 0 )
CA
observe every subconcept s.CA
, ,B
, , 00
B

n1,ran


00
00
0
preRole
(r ) \ (preDomT (B) preRanT (B )), obtain 6|= CAT , , 00 v B
B

n1,ran
u ran(s) v B 0 Lemma 39
induction hypothesis. Thus, 6|= CA
, ,B 00
every B 00 s. infer condition (e1) hold and, therefore,
n,ran
v B.
6|= CA
, ,B

Appendix C. Proofs Section 6
Proof Lemma 54. Let normalised ELHr -terminology signature
NR 6= . Additionally, let NC concept name non-conjunctive
, let r role name, let C EL -concept. Finally, let = C
= ran(r) u C.
First observe obtain Lemma 36 6|= v holds if, if,
(T , AD ) 6|= A(aD ). Additionally, Lemma 44, (T , AD ) 6|= A(aD ) if, if,
obj(AT , ) (AD , aD ) ran
(AT , , ). Thus, sufficient show following
equivalence:

ran

(AD , aD ) ran
(AT , , ) r : (A )r obj(AT , ) (AD , aD ) (AT , , (A )r )

696

fiThe Logical Difference Lightweight Description Logic EL

Next note ABox AD role-splitting C EL-concept = ran(r) u C,
{ s(b, aD ) AD | b obj(AD ), sig(AD ) } = {r(aran , aD )}.
Assume first obj(AT , ), (AD , aD ) ran
(AT , , ) let obj(AD )obj(AT , )
corresponding -range simulation. define relation obj(AD ) obj(AT , )
setting every obj(AD ), every obj(AT , ) every role name r
r obj(AT , ):
(a, r )

(a, ) s(c, a) AD sig(AD ) c obj(AD ),
= r

Note well-defined AD role-splitting.
show -range simulation exists r sig(A,T ) (A )r
obj(AT , ) (aD , (A )r ) , prove conditions (S1)(S3) condition (RS)
page 663 hold.
(S1) exists s(c, aD ) AD sig(AD ) c obj(AD ),
exists 0 obj(AT , ) s( 0 , ) , (aD , ) -range simulation,
i.e. s(( 0 )s , (A )s ) , (A )s obj(AT , ). Hence, (aD , (A )s ) .
Otherwise, easy see exists r (A )r obj(AT , )
obj(AT , ) sig(AT , ) . Thus, (aD , ) S, (aD , (A )r ) .
(S2) Let (a, r ) A(a) AD obj(AD ), obj(AT , ),
r sig(AT , ). follows definition (a, ) S. Hence, -range
simulation, A() , , implies A(r ) , definition
, .
(S3) Let (a, r ) s(a, a0 ) AD a, a0 obj(AD ), obj(AT , ), r sig(AT , )
. definition obtain (a, ) S. Additionally, -range
simulation, exists 0 obj(AT , ) (a0 , 0 ) s(, 0 ) , . Thus,
s(r , s0 ) , definition , (a0 , s0 ) definition
AD role-splitting.
(RS) Let (a, r ) s(c, a) AD a, c obj(AD ), obj(AT , ), r sig(AT , )
. definition , (a, ) holds r = s. -range simulation,
exists 0 obj(AT , ) s( 0 , ) = r( 0 , ) , . Hence, r(r0 , r ) , holds
definition , .
converse direction, assume exists r (A )r obj(AT , )



(AD , aD ) ran
(AT , , (A )r ) holds. Let obj(AD ) obj(AT , ) corresponding
-range simulation. define relation obj(AD ) obj(AT , ) setting every
obj(AD ) every obj(AT , ):
(a, )



r sig(AT , ) : (a, r ) .

straightforward verify obj(AT , ) -range simulation
(aD , ) S.
697

fiKonev, Ludwig, Walther, & Wolter

Appendix D. Proofs Section 7
Proof Lemma 60. require preliminary observations. Let AC ABox
associated C ran -concept C (Lemma 36). Then, ELHr -terminology , C ran concept C C u,u concept D, |= C v if, K |= D(aC ),
K = (T , AC ). Theorem 2 (extended version),
|= C v if, if, IK |= D(aC ), IK canonical model K.
Note |= C v u.D if, if, DIK 6= d, d0 IK
R = t1 u u tn , (d, d0 ) RIK if, if, exists role name
(d, d0 ) sIK vT ti , = 1, . . . , n. summarise consequences require
proof below:
(i) C u -concept occurrences Si = ri,1 u . . . u ri,mi intersections roles,
1 k, |= C v if, if, exist role names si , 1 k,
si vT ri,j 1 k, 1 j mi |= C v D0 , D0 obtained
replacing Si si .
(ii) C u -concept, |= C v u.D if, if, exists sequence
r10 , . . . , rn0 IK |= (r10 . rn0 .D)(aran ) IK |= (r10 . rn0 .D)(aC ).
first case, exists subconcept (ran(r) u C 0 ) C (up commutativity
associativity u) |= r.C 0 v r10 . rn0 .D. second case
|= C v r10 . rn0 .D.



assume C = 1il ran(si )u 1jn Aj u 1km rk .Ck |= C v R1 .D.
Let R1 , . . . , Rk occurrences role intersections R1 .D, Ri = ri,1 u . . . u
ri,mi , 1 k. (i), find role names si , 1 k, si vT ri,j
1 k, 1 j mi |= C v D0 , D0 obtained replacing Ri
si . applying Lemma 39 |= C v s1 .D0 using t1 vT r1,j , 1 j m1
|= D0 v D, obtain one conditions (e1u ), (e2u ), (e3u ), (e4u ) must
hold.
second part lemma, first prove induction n 1 every C ran concept C every C u -concept |= C v r1 . rn .D least one
following conditions holds
(e1n ) exists subconcept r.C 0 C |= C 0 u ran(r)v D;
(e2n ) exists concept name C |= v u.D;
(e3n ) exists role name r C |= r.> v u.D;
(e4n ) exists role name r C |= ran(r) v u.D.
n = 1, let C C ran concept C u -concept |= C v r1 .D.
obtain least one conditions (e1u ), (e2u ), (e3u ), (e4u ) must hold
first part lemma, hence, one (e1n ), (e2n ), (e3n ), (e4n ) satisfied.
n > 1, let C C ran concept C u -concept |= C v r1 . rn .D.
apply first part lemma again, conditions (e2u ), (e3u ), (e4u )
fulfilled, conclude conditions (e2n ), (e3n ), (e4n ) also satisfied.
698

fiThe Logical Difference Lightweight Description Logic EL

case (e1u ) holds, exists subconcept r.C 0 C |= C 0 u ran(r) v
r2 . rn .D. induction hypothesis obtain least one conditions
(e1n ), (e2n ), (e3n ), (e4n ) fulfilled |= C 0 u ran(r) v r2 . rn .D, thus also
|= C v r1 . rn .D r sig(C) every subconcept C 0 also subconcept
C.
Now, |= C v u.D C ran -concept C C u -concept D, (ii)
distinguish following two cases:
exists subconcept ran(r) u C 0 C sequence r10 , . . . , rn0 0 |=
r.C 0 v r10 . rn0 0 .D. n0 = 0, |= r.C 0 v condition (e6u )
holds. n0 1 obtain least one conditions (e1n ), (e2n ), (e3n ),
(e4n ) satisfied. (e1n ) holds, exists subconcept r0 .C 00 r.C 0
|= C 00 u ran(r0 ) v D. r.C 0 = r0 .C 00 , |= C 0 u ran(r) v D.
(C 0 u ran(r)) occurs top-level concept C, |= C v holds,
thus, condition (e5u ). Otherwise, exists subconcept s.((C 0 u ran(r)) u E)
C (e1u ) satisfied |= C 0 u ran(r) u E u ran(s) v D. r.C 0 6= r0 .C 00 , r0 .C 00
subconcept C 0 (thus, C) condition (e1u ) holds. Finally, one
conditions (e2n ), (e3n ), (e4n ) satisfied, one (e2u ), (e3u ), (e4u ) holds
(ii).
exists sequence r10 , . . . , rn0 0 |= C v r10 . rn0 0 .D. n0 = 0 condition
(e5u ) holds. n0 1, least one conditions (e1n ), (e2n ), (e3n ), (e4n )
holds. Then, (ii), conclude one conditions (e1u ), (e2u ), (e3u ),
(e4u ) satisfied well.

give translation C u,u -assertions conjunctive queries. similar
construction ABox C ran -concept given Section 5.1. First, given C u -concept
C, define path C finite sequence C0 R1 C1 . . . Rn Cn , C0 = C, n 0,
Ri+1 .Ci+1 conjunct Ci , 1 < n (Ri conjunctions role names). Let
xp p paths(C) pairwise distinct variable names set
XC = { s(xp , xq ) | p, q paths(C); q = p R C 0 , conjunct R }
{ A(xp ) | conjunct tail(p), p paths(C) }
Let ~x sequence
V variables XC except xC . conjunctive query qC,a
obtained ~x. XC replacing xC
Va. Finally,
V = D0 uu.D1 u uu.Dk
obtain conjunctive query qD,a ~x.( 0ik XD ), (we assume distinct

variables used every XDi , 0 k, ~x sequence variables except
xD0 ) replacing xD0 a.
prove Lemma 63 require preparation. Query answering closely related
existence certain homomorphisms interpretations. Let signature,
set individual names, I1 , I2 interpretations. function f : I1 I2 called
(O, )-homomorphism
f (aI1 ) = f (aI2 ) O;
699

fiKonev, Ludwig, Walther, & Wolter

AI1 implies f (d) AI2 ;
(d1 , d2 ) rI1 implies (f (d1 ), f (d2 )) rI2 r .
known (Chandra & Merlin, 1977) exists (O, )-homomorphism I1
I2 I1 |= q[~a] conjunctive -query q using individual names
~a = a1 , . . . , ak O, I2 |= q[~a].
proof slightly refine notion (O, )-homomorphism considering partial (O, )-homomorphisms domains satisfy certain conditions. Namely,
every n 0, call partial (O, )-homomorphism level n homomorphism
domain contains elements reachable -role chain length n either
named individual element without -predecessor. prove
every ELran,u,u -inclusion C v depth(C), depth(D) n, T1 |= C v implies
T2 |= C v D, exists partial level n homomorphism certain model
(T1 , A) certain model (T2 , A).
consider partial homomorphisms certain interpretations only,
introduce first. Let finite set individual names interpretation.
called O-named exists = aI . model called O-forest
(F1) everySd O-named, exists one d0
(d0 , d) rNR rI ;

(F2) infinite sequences d0 , d1 , . . . (di+1 , di ) rNR rI 0
di O-named.

(F3) (d, d0 ) rNR rI d0 O-named, O-named.
Let finite set individual names, n 0, signature. partial function f
O-forest model 0 called (O, n, )-homomorphism
0

(H1) O: aI domain f f (aI ) = aI ;
0

(H2) d, d0 domain f r : (d, d0 ) rI implies (f (d), f (d0 )) rI ;
0

(H3) domain f : AI implies f (d) AI ;
(H4) exist chain d1 , . . . , dm = (di , di+1 )
length > n O-named di , domain f .



r r





one prove following
Lemma 70. Suppose O-forest, 0 interpretation every > 0
exists (O, m, )-homomorphism 0 . Assume well |= q[~a] q
conjunctive -query using individual names ~a = a1 , . . . , ak O.
0 |= q[~a].
Proof. Assume ~a -match q(~x) = ~y .q 0 (~x, ~y ) ~a consists
elements O. (F2) (F3) definition O-forests (H1) (H4)
definition partial homomorphisms, exists > 0 (v), v ~x ~y ,
domain (O, m, )-homomorphism f . Take (O, m, )-homomorphism f .
~a 0 -match q(~x) 0 , 0 (v) = f ((v)), v ~x ~y .
700

fiThe Logical Difference Lightweight Description Logic EL

Finally, also need technique constructing (O, m, )-homomorphisms. Let
interpretation. > 0, let
u
tIm,,u (d) = {C C
| depth(C) m, C },

where, above, depth(C) role-depth C; i.e., number nestings existential
restrictions C.
Lemma 71. Let finite signature let > 0 Suppose O-forest 0
interpretation
0

0

0

(in0) (aI , bI ) rI implies (aI , bI ) rI , a, b r ;
0

(in1) tIm,,u (aI ) tIm,,u
(aI ), O;
0
0

(d0 );
(d) tm,,u
(in2) exists d0 tm,,u

I0
exists (O, m, )-homomorphism g 0 .
Proof. construct g constructing sequence functions f0 , . . . , fm , fi : 0 ,
follows: domain dom(f0 ) f0 consists
aI

0
0
0
exist (d , d) r rI . aI set f0 (aI ) = aI .
every remaining dom(f0 ) choose d0 according (in2) set f0 (d) = d0 . Observe
tm,,u
(d) tIm,,u
(f0 (d)) dom(f0 ).
0

suppose fn constructed
(fn (d)) dom(fn );
(d) tmn,,u
(in3) tmn,,u

I0
(in4) n > 0: dom(fn ) if, if, O-named exists sequence
d0 r1I d1 r2I rnI dn = d0 O-named ri d0
dom(f0 ).

construct fn+1 consider dom(fn ) O-named d0 (d, d0 ) r rI .
0
0

u
0

domain fn+1 consists . Let Rd,d = {r | (d, ) r } Rd,d0 =
( rR 0 r).
d,d
l
u
Rd,d
tmn,,u
(d)
0.

mn1,,u 0
(d )
DtI

(in3),
u
Rd,d
0.

l

tImn,,u
(fn (d))
0

mn1,,u 0
DtI
(d )
0

Thus, choose e (fn (d), e) rI r Rd,d0 tImn1,,u (d0 )
tmn1,,u
(e) set fn+1 (d0 ) = e. defines fn+1 . Observe fn+1 wellI0
defined (F1). Observe fn+1 properties (in3) (in4), (F3).

set g = 0nm fm . readily checked g required.
701

fiKonev, Ludwig, Walther, & Wolter

position prove Lemma 63.
Lemma 63 qDiff (T1 , T2 ), exists 0 cDiff ran,u,u
(T1 , T2 ) sig(0 )

sig().
Proof. Assume T1 T2 given let (A, q(~a)) qDiff (T1 , T2 ). Let 0 = sig(A)
sig(q). Assume that, contrast shown,
T1 |=

()



T2 |=

ELran,u,u -inclusions sig() 0 .
Consider model 0 (T2 , A) 0 6|= q[~a]. Lemma 70, obtain contradiction
exists obj(A)-forest model (T1 , A) every n > 0
exists (obj(A), n, 0 )-homomorphism fn 0 .
0
Take, every obj(A) model Ia0 T1 da Ia C ran C u,u concepts C:
0
da C Ia T1 tI 0 (a) |= C


0

0


ran
C }.
tI 0 (a) = {C C
0 |

interpretations Ia0 exist Lemma 67. define unfolding
Ia Ia0 . path

Ia0 finite sequence d0 R1 d1 . . . Rn dn , n 0, Ri+1 = Ri+1 set Ri+1
0
role names r Ri+1 iff (di , di+1 ) rIa , < n. path p, tail(p) denotes
last element p. let Ia consist paths Ia0 set
0

AIa = {p Ia | tail(p) AIa };
rIa = {(d, dRd0 ) Ia Ia | r R}.
Ia O-forest = . Moreover, C u,u -concepts C p Ia :
()

p C Ia



0

tail(p) C Ia .

particular, Ia still model T1 .
Take following (disjoint) union interpretations Ia :

= aobj(A) Ia ;

AI = aobj(A) AIa , NC ;

rI = aobj(A) rIa {(da , db ) | r0 (a, b) A, r0 vT1 r}, r NR ;
aI = da , obj(A).
show obj(A)-forest, model (T1 , A) exist (obj(A), n, )homomorphisms 0 n > 0. First observe following:
Claim 1. EL concepts C Ia :
C C Ia
702

fiThe Logical Difference Lightweight Description Logic EL

proof induction construction C. interesting case C = r.D
direction left right.
Assume C Ia . Take d0 (d, d0 ) rI

d0 DI . (d, d0 ) a0 obj(A) rIa0 , C Ia follows immediately induction
hypothesis. Otherwise, = da , d0 = db b r0 (a, b) r0 vT1 r.
induction hypothesis, d0 DIb . Hence, (), T1 tI 0 (b) |= D. compactness,
exists concept E tI 0 (b) T1 |= E v D. obtain r0 .E tI 0 (a).
T1 |= r0 .E v r0 .D obtain da C Ia using r0 vT1 r ().
Claim 2. obj(A)-forest model (T1 , A).
obj(A)-forest model follows construction. remains
show model T1 . role inclusions r v T1 follows construction
rI sI . Suppose C1 v C2 T1 . C1 EL-concept, |= C1 v C2 follows
Claim 1 condition Ia models T1 . assume C1 = ran(r)
let ran(r)I . 6= da a, C2I since Ia models T1 . = da ,
exists r0 (b, a) r0 vT1 r. ran(r0 ) tI 0 (a), T1 tI 0 (a) |= C2 .
Hence, (), da C2Ia , i.e. da C2I Claim 1.
Claim 3. every n > 0 exists (obj(A), n, 0 )-homomorphism 0 .
Lemma 71, sufficient show conditions (in0), (in1), (in2). Condition (in0)
follows directly (). Condition (in1) proved induction construction C.
interesting step C = S.D = r1 u u rm . Let obj(A) C
0
tIn, ,u (aI ). Take d0 (aI , d0 ) d0 DI . d0 Ia , then, (), T1 tI 0 (a) |=
0 ,u
0
(aI ). assume
S.D. () compactness, T2 tI 0 (a) |= S.D. Hence C tIn,
0
d0 6 Ia . r10 , . . . , rk0 b d0 = bI ri0 (a, b) 1 k
0
every 1 exists 1 j rj0 vT1 ri . tIn, ,u (bI ).
0

0

,u
(b ). (), every 1 j exists
induction hypothesis tn,
I0
0 ,u
0
0
1 j k rj vT2 ri . C tIn,
(aI ), required.
0

(in2), let C = Dtn,0 ,u (d) D. 6= aI obj(A),


() exists b obj(A) T1 tI 0 (b) |= u.C. compactness (),
0 ,u
0 ,u
0
(d) tn,
(d0 ), required.
T2 tI 0 (b) |= u.C. Hence, exists d0 tn,

I0
0
= aI obj(A), then, (in1) shown above, d0 = aI required.
finishes proof Lemma 63.

References
Baader, F., Brandt, S., & Lutz, C. (2008). Pushing EL envelope further. Proceedings
6th International Workshop OWL: Experiences Directions (OWLED
2009), Vol. 529 CEUR Workshop Proceedings. CEUR-WS.org.
Baader, F., Penaloza, R., & Suntisrivaraporn, B. (2007). Pinpointing description
logic EL+ . Proceedings 30th Annual German Conference Artificial Intelligence (KI 2007), Vol. 4667 Lecture Notes Computer Science, pp. 5267,
Heidelberg/Berlin, Germany. Springer Verlag.
703

fiKonev, Ludwig, Walther, & Wolter

Baader, F. (2003). Terminological cycles description logic existential restrictions.
Proceedings 18th International Joint Conference Artificial Intelligence
(IJCAI 2003), pp. 325330, San Francisco, CA, USA. Morgan Kaufmann.
Bienvenu, M., Lutz, C., & Wolter, F. (2012a). Deciding FO-rewritability EL. Proceedings 25th International Workshop Description Logics (DL 2012).
Bienvenu, M., Lutz, C., & Wolter, F. (2012b). Query containment description logics revisited. Proceedings 13th International Conference Principles Knowledge
Representation Reasoning (KR 2012).
Brandt, S., Kusters, R., & Turhan, A.-Y. (2002). Approximation difference description logics. Proceedings 8th International Conference Principles
Knowledge Representation Reasoning (KR-02), pp. 203214, San Francisco, CA,
USA. Morgan Kaufmann.
Calvanese, D., Giacomo, G. D., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Data
complexity query answering description logics. Proceedings Tenth
International Conference Principles Knowledge Representation Reasoning
(KR 2006), pp. 260270.
Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation conjunctive queries
relational data bases. Proceedings 9th Annual ACM Symposium Theory
Computing (STOC 77), pp. 7790, New York, NY, USA. ACM.
Chang, C. C., & Keisler, H. J. (1990). Model Theory, Vol. 73 Studies Logic
Foundations Mathematics. Elsevier, Amsterdam, Netherlands.
Clarke, E., & Schlingloff, H. (2001). Model checking. Handbook Automated Reasoning,
Vol. II, chap. 24, pp. 16351790. Elsevier, Amsterdam, Netherlands.
Conradi, R., & Westfechtel, B. (1998). Version models software configuration management. ACM Computing Surveys (CSUR), 30 (2), 232282.
Crafa, S., Ranzato, F., & Tapparo, F. (2011). Saving space time efficient simulation
algorithm. Fundamenta Informaticae, 108 (1-2), 2342.
Cuenca Grau, B., Horrocks, I., Kazakov, Y., & Sattler, U. (2008). Modular reuse ontologies: theory practice. Journal Artificial Intelligence Research (JAIR), 31,
273318.
Delaitre, V., & Kazakov, Y. (2009). Classifying ELH ontologies SQL databases.
Proceedings 6th International Workshop OWL: Experiences Directions
(OWLED 2009), Vol. 529 CEUR Workshop Proceedings. CEUR-WS.org.
Eiter, T., Fink, M., & Woltran, S. (2007). Semantical characterizations complexity
equivalences answer set programming. ACM Transactions Computational Logic,
8 (3).
Ghilardi, S., Lutz, C., & Wolter, F. (2006). damage ontology? case conservative extensions description logic. Proceedings Tenth International
Conference Principles Knowledge Representation Reasoning (KR 2006),
pp. 187197, Menlo Park, CA, USA. AAAI Press.
704

fiThe Logical Difference Lightweight Description Logic EL

Golbeck, J., Fragaso, G., Hartel, F., Hendler, J., Oberhaler, J., & Parsia, B. (2003).
National Cancer Institutes thesaurus ontology. Journal Web Semantics, 1 (1),
7580.
Goncalves, R. S., Parsia, B., & Sattler, U. (2011). Analysing multiple versions ontology:
study NCI thesaurus. Proceedings 24th International Workshop
Description Logics (DL 2011), Vol. 745 CEUR Workshop Proceedings. CEURWS.org.
Goncalves, R. S., Parsia, B., & Sattler, U. (2012). Concept-based semantic difference
expressive description logics. Proceedings 25th International Workshop
Description Logics (DL 2012).
Hofmann, M. (2005). Proof-theoretic approach description-logic. Proceedings
20th Annual IEEE Symposium Logic Computer Science (LICS 2005), pp. 229
237, Washington, DC, USA. IEEE Computer Society.
Horridge, M., Parsia, B., & Sattler, U. (2010). Justification oriented proofs OWL.
Proceedings 9th International Semantic Web Conference (ISWC 2010), Vol.
6496 Lecture Notes Computer Science, pp. 354369, Berlin/Heidelberg, Germany.
Springer-Verlag.
IHTSDO (2008). SNOMED Clinical Terms User Guide. International Health Terminology Standards Development Organisation (IHTSDO). Available
http://www.ihtsdo.org/publications/introducing-snomed-ct/.
Jimenez-Ruiz, E., Cuenca Grau, B., Horrocks, I., & Llavori, R. B. (2011). Supporting
concurrent ontology development: Framework, algorithms tool. Data & Knowledge
Engineering, 70 (1), 146164.
Kalyanpur, A., Parsia, B., Horridge, M., & Sirin, E. (2007). Finding justifications
OWL DL entailments. Proceedings 6th International 2nd Asian Semantic
Web Conference (ISWC07+ASWC07), pp. 267280, Berlin/Heidelberg, Germany.
Springer Verlag.
Kazakov, Y. (2009). Consequence-driven reasoning Horn SHIQ ontologies. Proceedings
21st International Conference Artificial Intelligence (IJCAI 2009), pp. 2040
2045.
Kazakov, Y., Krotzsch, M., & Simancik, F. (2011). Unchain EL reasoner. Proceedings 24th International Workshop Description Logics (DL 2011), CEUR
Workshop Proceedings. CEUR-WS.org.
Klein, M. C. A., Fensel, D., Kiryakov, A., & Ognyanov, D. (2002). Ontology versioning
change detection web. Knowledge Engineering Knowledge Management:
Ontologies Semantic Web, Vol. 2473 Lecture Notes Computer Science,
pp. 247259. Springer Verlag, Berlin/Heidelberg, Germany.
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2008). Semantic modularity module
extraction description logic. Proceedings 18th European Conference
Artificial Intelligence (ECAI 2008), Vol. 178 Frontiers Artificial Intelligence
Applications, pp. 5559, Amsterdam, Netherlands. IOS Press.
705

fiKonev, Ludwig, Walther, & Wolter

Konev, B., Walther, D., & Wolter, F. (2008). logical difference problem description
logic terminologies. Proceedings 4th International Joint Conference Automated Reasoning (IJCAR 2008), Vol. 5195 Lecture Notes Computer Science,
pp. 259274, Berlin/Heidelberg, Germany. Springer Verlag.
Konev, B., Kontchakov, R., Ludwig, M., Schneider, T., Wolter, F., & Zakharyaschev, M.
(2011). Conjunctive query inseparability OWL 2 QL TBoxes. Proceedings
25th Conference Artificial Intelligence (AAAI 2011), Menlo Park, CA, USA.
AAAI Press.
Konev, B., Ludwig, M., & Wolter, F. (2012). Logical difference computation CEX2.5.
Proceedings 6th International Joint Conference Automated Reasoning
(IJCAR 2012), Lecture Notes Computer Science, Berlin/Heidelberg, Germany.
Springer.
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2009). Formal properties modularisation.
Modular Ontologies, pp. 2566. Springer Verlag, Berlin/Heidelberg, Germany.
Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2010). Logic-based ontology comparison
module extraction, application DL-Lite. Artificial Intelligence, 174 (15),
10931141.
Kontchakov, R., Pulina, L., Sattler, U., Schneider, T., Selmer, P., Wolter, F., & Zakharyaschev, M. (2009). Minimal module extraction DL-Lite ontologies using
QBF solvers. Proceedings 21st International Joint Conference Artificial
Intelligence (IJCAI 2009), pp. 836841, San Francisco, CA, USA. Morgan Kaufmann.
Kutz, O., & Mossakowski, T. (2008). Conservativity structured ontologies. Proceedings
18th European Conference Artificial Intelligence (ECAI 2008), Vol. 178
Frontiers Artificial Intelligence Applications, pp. 8993, Amsterdam,
Netherlands. IOS Press.
Kutz, O., & Mossakowski, T. (2011). modular consistency proof DOLCE. Proceedings 25th Conference Artificial Intelligence (AAAI 2011), Menlo Park, CA,
USA. AAAI Press.
Kremen, P., Smd, M., & Kouba, Z. (2011). OWLDiff: practical tool comparison
merge OWL ontologies. Proceedings 10th International Workshop Web
Semantics, pp. 229233, Los Alamitos, CA, USA. IEEE Computer Society Press.
Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering description
logic EL using relational database system. Proceedings 21st International
Joint Conference Artificial Intelligence (IJCAI 2009), pp. 20702075, Menlo Park,
CA, USA. AAAI Press.
Lutz, C., Walther, D., & Wolter, F. (2007). Conservative extensions expressive description logics. Proceedings 20th International Joint Conference Artificial
Intelligence (IJCAI 2007), pp. 453458, Menlo Park, CA, USA. AAAI Press.
Lutz, C., & Wolter, F. (2010). Deciding inseparability conservative extensions
description logic EL. Journal Symbolic Computing, 45 (2), 194228.
Lutz, C., & Wolter, F. (2011). Foundations uniform interpolation forgetting expressive description logics. Proceedings 22nd International Joint Conference
706

fiThe Logical Difference Lightweight Description Logic EL

Artificial Intelligence (IJCAI 2011), pp. 989995, Menlo Park, CA, USA. AAAI
Press.
Mendez, J., & Suntisrivaraporn, B. (2009). Reintroducing CEL OWL 2 EL reasoner.
Proceedings 22nd International Workshop Description Logics (DL 2009),
Vol. 477 CEUR Workshop Proceedings. CEUR-WS.org.
Noy, N. F., & Musen, M. A. (2002). PromptDiff: fixed-point algorithm comparing
ontology versions. Proceedings 18th national conference Artificial intelligence, pp. 744750, Menlo Park, CA, USA. AAAI Press.
Ohst, D., Welle, M., & Kelter, U. (2003). Differences versions UML diagrams.
Proceedings 9th European software engineering conference held jointly
11th ACM SIGSOFT international symposium Foundations software engineering
(ESEC03/SIGSOFT FSE03), pp. 227236, New York, NY, USA. ACM.
Oliver, D. E., Shahar, Y., Shortliffe, E. H., & Musen, M. A. (1999). Representation
change controlled medical terminologies. Artificial Intelligence Medicine, 15 (1),
5376.
Palma, R., Haase, P., Corcho, O., & Gomez-Perez, A. (2009). Change representation
OWL 2 ontologies. Proceedings 6th International Workshop OWL: Experiences Directions (OWLED 2009), Vol. 529 CEUR Workshop Proceedings.
CEUR-WS.org.
Pearce, D., & Valverde, A. (2004). Uniform equivalence equilibrium logic logic programs. Proceedings 7th International Conference Logic Programming
Nonmonotonic Reasoning (LPNMR 2004), Vol. 2923 Lecture Notes Computer
Science, pp. 194206, Berlin/Heidelberg, Germany. Springer.
Pearce, D., & Valverde, A. (2012). Synonymous theories knowledge representations
answer set programming. Journal Computer System Sciences, 78 (1), 86104.
Penaloza, R., & Sertkaya, B. (2010). complexity axiom pinpointing EL
family description logics. Proceedings 12th International Conference
Principles Knowledge Representation Reasoning (KR 2010), Menlo Park, CA,
USA. AAAI Press.
Poggi, A., Lembo, D., Calvanese, D., Giacomo, G. D., Lenzerini, M., & Rosati, R. (2008).
Linking data ontologies. Journal Data Semantics, 10, 133173.
Redmond, T., Smith, M., Drummond, N., & Tudorache, T. (2008). Managing change:
ontology version control system. Proceedings 5th International Workshop
OWL: Experiences Directions (OWLED 2008), Vol. 432 CEUR Workshop
Proceedings. CEUR-WS.org.
Rosati, R. (2007). conjunctive query answering EL. Proceedings 2007
International Workshop Description Logic (DL 2007), Vol. 250 CEUR Workshop
Proceedings. CEUR-WS.org.
Schlobach, S., & Cornet, R. (2003). Non-standard reasoning services debugging
description logic terminologies. Proceedings 18th International Joint Conference Artificial Intelligence (IJCAI 2003), pp. 355362, San Francisco, CA, USA.
Morgan Kaufmann.
707

fiKonev, Ludwig, Walther, & Wolter

Teege, G. (1994). Making difference: subtraction operation description logics.
Proceedings 4th International Conference Principles Knowledge Representation Reasoning (KR94), pp. 540550, San Francisco, CA, USA. Morgan
Kaufmann.
van Glabbeek, R. J., & Ploeger, B. (2008). Correcting space-efficient simulation algorithm.
Proceedings 20th International Conference Computer Aided Verification
(CAV 2008), Vol. 5123 Lecture Notes Computer Science, pp. 517529, Heidelberg/Berlin, Germany. Springer Verlag.
Vescovo, C. D., Parsia, B., Sattler, U., & Schneider, T. (2011). modular structure
ontology: Atomic decomposition. Proceedings 22nd International Joint
Conference Artificial Intelligence (IJCAI 2011), pp. 22322237, Menlo Park, CA,
USA. AAAI Press.

708

fiJournal Artificial Intelligence Research 44 (2012) 423-453

Submitted 10/11; published 07/12

Modelling Observation Correlations Active Exploration
Robust Object Detection
Javier Velez
Garrett Hemann
Albert S. Huang

VELEZJ MIT.EDU
GHEMANN ALUM.MIT.EDU
ASHUANG MIT.EDU

MIT Computer Science Artificial Intelligence Laboratory
Cambridge, MA, USA

Ingmar Posner

INGMAR ROBOTS.OX.AC.UK

Mobile Robotics Group
Dept. Engineering Science, Oxford University
Oxford, UK

Nicholas Roy

NICKROY CSAIL.MIT.EDU

MIT Computer Science Artificial Intelligence Laboratory
Cambridge, MA, USA

Abstract
Today, mobile robots expected carry increasingly complex tasks multifarious, realworld environments. Often, tasks require certain semantic understanding workspace.
Consider, example, spoken instructions human collaborator referring objects interest; robot must able accurately detect objects correctly understand instructions.
However, existing object detection, competent, perfect. particular, performance
detection algorithms commonly sensitive position sensor relative objects
scene.
paper presents online planning algorithm learns explicit model spatial
dependence object detection generates plans maximize expected performance
detection, extension overall plan performance. Crucially, learned sensor model
incorporates spatial correlations measurements, capturing fact successive measurements taken nearby locations independent. show sensor
model incorporated efficient forward search algorithm information space
detected objects, allowing robot generate motion plans efficiently. investigate performance approach addressing tasks door text detection indoor environments
demonstrate significant improvement detection performance task execution alternative methods simulated real robot experiments.

1. Introduction
Years steady progress mapping navigation techniques mobile robots made
possible autonomous agents construct accurate geometric topological maps relatively
complex environments robustly navigate within (e.g., Newman, Sibley, Smith, Cummins, Harrison, Mei, Posner, Shade, Schroeter, Murphy, Churchill, Cole, & Reid, 2009). Lately,
mobile robots also begun perform high-level tasks following natural language
instructions interaction particular object, requiring relatively sophisticated interpretation agent workspace. recent literature therefore focuses augmenting
c
2012
AI Access Foundation. rights reserved.

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a)

(b)

Figure 1: traditional geometric environment map (a) represented simple two dimensional
occupancy grid regions free-space (cyan) (red) useful navigation
localization, (b) geometric map augmented semantic information
identity, structure location objects world allowing richer interactions
agent workspace.

metric maps higher-order semantic information location identity objects
workspace (see Fig. 1).
end, advances vision- laser-based object detection recognition
leveraged extract semantic information raw sensor data (e.g., Posner, Cummins, &
Newman, 2009; Douillard, Fox, & Ramos, 2008; Martinez-Mozos, Stachniss, & Burgard, 2005;
Anguelov, Koller, Parker, & Thrun, 2004). Commonly, output detection system
accepted prima facie, possibly threshold estimated sensor error. consequence
directly using results object detector quality resulting map strongly
depends shortcomings object detector. Vision-based object detection, example,
oftentimes plagued significant performance degradation caused variety factors including
change aspect compared encountered training data, changes illumination and,
course, occlusion (e.g., Coates & Ng, 2010; Mittal & Davis, 2008). aspect occlusions
addressed naturally mobile robot: robot choose location sensors carefully
acquiring data performing object detection, thereby improving robustness
detection process specifically counteracting known detector issues. Rather placing burden providing perfect detections detector itself, robot act improve perception.
Rarely, however, ability mobile robot actually exploited building semantic map.
paper, present online planning algorithm robot motion explicitly incorporates model performance object detector. primarily address problem
context robot exploring unknown environment goal building map accurately
labeled location semantic objects interest here, particular, consider doors
textual signs. However, approach applied problem robot must plan
trajectories depend location objects landmarks interest environment.
show planning approach weighs benefit increasing confidence potential
semantic entity cost taking detour succession suitable vantage point.
Fig. 2 gives cartoon illustration problem, robot encounters possible new object
424

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

(a)

(b)

(c)

Figure 2: conceptual illustration (a) robot viewpoint x following original
trajectory (bold line) towards goal (red star), (b) perception field particular
object detector centered around object hypothesis, (c) alternative path (bold
dash-dotted line) along informative route. Cell shadings indicate relative value
observations taken cell terms mutual information. Lighter values
indicate lower mutual information therefore desirable vantage points. challenge
learning mutual information varies spatially, also capturing
mutual information cell changes new measurement.

executing path goal. Based expected information available possible vantage
points, robot may decide original path provided accurate model object,
may choose modify path reduce possibility errors object model.
make two primary contributions paper. Firstly, describe new sensor model
uses mixture Gaussian Processes model performance object detection system function robots relative position detected features also learn
online model sensor measurements spatially correlated. Typical estimation planning algorithms assume sensor measurements conditionally independent given
knowledge robots position, assumption clearly incorrect properties environment introduce strong correlation sensor measurements. Rather estimate
possible hidden variables capture full sensor model preserve conditional independence,
explicitly model spatial correlation measurements use correlation model estimate mutual information measurements taken different locations. use
mutual information bias random sampling strategy trajectory generation
evaluate expected cost sampled trajectory. Secondly, show incorporate
learned sensor model forward search process using Posterior Belief Distribution (PBD)
algorithm (He, Brunskill, & Roy, 2010, 2011) perform computationally efficient deep trajectory
planning. PBD approximation allows us compute expected costs sensing trajectories
without explicitly integrating possible sensor measurements.
work first result actively controlling sensor improve accuracy,
previous work largely ignored motion cost typically assumed observations conditionally independent given sensor position. Inspired recent progress forward search
planning uncertainty, demonstrate system allows us efficiently find robust observation plans. paper builds previous work presented ICAPS 2011 (Velez, Hemann,
Huang, Posner, & Roy, 2011) provides several substantial extensions. Specifically, describe
significantly richer sensor model, extend approach improved planning algorithm ad425

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

dress additional object interest human-readable text. demonstrate overall approach
using real robot well simulation studies.
exposition begins problem formulation planning trajectories improve object
detection Section 2. Section 3 describe specific sensor model characterize
sensor models using mutual information. Section 4 gives two different approaches learning
sensor models vary spatially, observations correlated spatially. describe
planning algorithm sensor model incorporated system Section 5.
follow description implementation efficient planning using sensor models
Section 6. Section 7 describes object detectors used results. Section 8 shows simulation
results approach improves object detection compared approaches Section 9
shows performance system real world trials. Sections 10 11 conclude
discussion related work future directions.

2. Problem Formulation
Consider robot following particular trajectory towards goal environment objects
interest unknown locations, example, rescue robot looking people first-responder
scenario. Traditionally, object detector used waypoints along trajectory
detection either accepted map rejected based simple detector thresholds. However,
lack introspection approach regarding confidence object detector
quality data gathered lead unnecessary acceptance spurious detections.
systems simply discard lower confidence detections way improve estimate
further, targeted measurements. contrast, would like robot modify motion
minimize total travel cost cost errors deciding whether add newly observed
objects map.
Let us represent robot point x R2 SO(2), SO(2) denotes special orthogonal group representing orientation R2 represents location 2D euclidean space. Without
loss generality, express robot trajectory set waypoints x0:K , associated
motion cost cmot (x0:K ) sum total travel waypoints x0 xk . robot
prior map environment planning path pre-specified goal, computing
minimum cost path x0:K well-understood motion planning problem.
robot moves, receives output object detector gives rise belief
whether detected object truly exists location indicated1 . model presence
ith object location (ui , vi ) random variable yi {object, no-object}. system
runs, object detector fire give rise objects Yi given locations system
must reason qualify either genuine objects false firings object
detector.
Let us define decision action ai {accept, reject}, detected object either accepted
map (the detection determined correspond real object) rejected (the detection
determined spurious). Let us also define cost dec : {{accept, reject}{object, no-object}} 7
R correct incorrect accept reject decision. cannot know true cost decisions
{ai } ultimately know true state objects environment. therefore
1. assume robot knows location, sufficiently well-calibrated camera determine location
object map. work, uncertainty whether object specific type present
given location (u, v).

426

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

infer distribution state object p(y) generate plan minimize expected
cost E[dec ] individual decision actions given distribution objects.
formulate planning problem choosing plan , comprised sequence waypoints
decision actions, 7 {x0:K a0:Q } path length k Q hypothesized objects
minimize total travel cost along trajectory expected costs decision actions
end trajectory, optimal plan given

= arg min cmot (x0:K ) + cdet (x0:K , a) ,
(1)
x0:K ,a



cdet (x0:K , a) = Ey|x0:K[dec (a, y)],

(2)

Ey|x0:K [] denotes expectation respect robots knowledge regarding object,
y, executed path x0:K . number hypothesized objects, Q, number possible objects detector fired traversing entire trajectory known beforehand.
Note planning problem computing often formulated partially observable
Markov decision process POMDP (Sondik, 1971; Kaelbling, Littman, & Cassandra, 1998),
POMDP representation grow combinatorial complexity presence multiple
detections. Furthermore, POMDP solutions assume stationary Markov model parameters;
sensor model non-stationary explicitly non-Markov want represent
environmental features needed support non-Markov sensor model. Since approach
uses sensor model adapts successive observation, new POMDP model would
need constructed solved observation. Lastly, explicit POMDP model would
require plan take account possible observations robot might encounter carries
motion trajectory. precisely, expected cost plan must computed respect possible observations objects, rather object distributions. avoid
resulting computational complexity using forward search algorithm similar forward search
approximation techniques solving POMDPs (Ross, Pineau, Paquet, & Chaib-draa, 2008),
known scale well presence complex representations. also avoid explicitly computing observation distribution planning use approximation technique
known Posterior Belief Distribution (PBD) algorithm, adapted sensor model.

3. Sensor Model Object Detection
order compute expected cost decision actions, must estimate probability objects existing world given observations might see executing motion plan.
therefore require probabilistic model object detector allows us infer distribution object given measurements, p(y|z). know sensor characteristics vary
robot moves around object interactions environment, hence make
relationship explicit writing posterior p(y|z, x) include viewpoint x.
Furthermore, measurement, z, taken particular viewpoint x consists output
object detector, assumed real number indicating confidence detector
object exists. distribution range confidence measurements dependent
particular object detector captured random variable Z defined continuous
range [zmin , zmax ]. every waypoint x posterior distribution expressed
p(y|z, x) = R

p(z|y, x)p(y)
,
yY p(z|y, x)p(y)
427

(3)

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a)

(b)

(c)

Figure 3: Different graphical models representing observation function. (a) naive Bayes
approximation assumes every observation z conditionally independent given
knowledge object y. (b) true model assumes observations independent given knowledge environment object y. (c) model
employed here, correlations approximated way mixture model
input space waypoints {x R2 SO(2)} (Equ. 9).

p(z|y, x) denotes likelihood, every possible state , observing particular
detector confidence x. (The expression would seem require p(y|x), independent
waypoint measurement z received.)
3.1 Observation Model
Observations z directly produced physical device, camera, often treated
conditionally independent given state robot (see Fig. 3a). However, observations
independent given knowledge current state, fact independent given
state environment shown Fig. 3(b). one (or both) variables
unknown, measurements longer first-order Markov fact correlated.
seen intuitively noting robot stationary, aimed static scene,
would expect response object detector successive images independent.
anticipate observations object detector extremely correlated, expectation
new information would gained handful images.
correct observation model maintain history observations. waypoints
visited, knowledge regarding object integrated recursively. Let K denote trajectory
K waypoint-observation pairs obtained sequence K = {(x1 , z 1 ), (x2 , z 2 ), . . . , (xK , z K )}.
Knowledge gained step along trajectory integrated posterior distribution


K

K = (xK , z K ) K1 ,

(4)

K

(5)

K

K

p(y|z , x , ) p(y|z , x ,
=

K1

),

p(z K |y, xK , K1 )p(y|T K1 )
,
p(z K |xK , K1 )

(6)

z K K th observation, depends current waypoint also
history measurements waypoints K1 . denominator Equ. 6 serves moderate
428

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

influence measurement likelihood posterior based correlations existing
observations taken along trajectory.
difficulty model Equ. 6 sensor model p(z K |y, xK , K1 ) difficult
arrive at, depending history measurements. Furthermore, K arbitrarily
large, need model predicts observations given infinite history observations.
describe new sensor model Section 4.
3.2 Perception Fields
developing new sensor model, first need way examine sensor model
captures effect measurements posterior belief object y, use reduction
uncertainty relative current belief next observation. Given waypoint xK
trajectory K1 visited thus far, reduction uncertainty captured mutual information
object state observation Z K received xK
I(Y, Z K ; xK , K1 ) =
H(Y ; K1 ) H(Y |Z K ; xK , K1 ),

(7)

H(Y ; K1 ) H(Y |Z K ; xK , K1 ) denote entropy conditional entropy, respectively (we drop xK entropy since distribution independent robot
xK without corresponding observation Z K ). Thus, H(Y ; K1 ) expresses certainty current belief whether object exists given trajectory thus far, unswayed
new measurements. every time step, term constant every waypoint considered
therefore disregarded. conditional entropy Equ. 7 expanded terms posterior state hidden variable given previous trajectory K1 additional
measurement taken xK , p(y|z K , xK , K1 ) (c.f. Equs. 6 9), likelihood z K taking
particular value conditioned trajectory thus far whether object viewed xK
present not, p(z K |xK , K1 ),
H(Y |Z K ; xZK , K1 ) =



p(z|xK , K1 )H(Y |z, xK , K1 ) ,

(8)

z

|z, xK , K1 ) computed using sensor model p(y|z K , xK , K1 ) given Equ. 6,

H(Y
function belief traversing waypoint-observation trajectory K .
expected reduction uncertainty given conditional entropy values waypoints
robots workspace form perception field2 particular object hypothesis (see Fig. 2(b)).
use perception field induces sensor model two ways: firstly bias search
informative path, secondly part evaluation expected cost path.

4. Correlation Models
described previously, conventional first-order Markov sensor models correctly represent
effect successive observations implicitly correlated unmodelled environmental
2. reduction position uncertainty robot observations across environment sometimes known
sensor uncertainty field (Takeda & Latombe, 1992) active localization. Since application object detection,
use term perception field avoid confusion localization problem, concepts otherwise
identical.

429

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

variables. images used object detector conditionally independent correlated
environment . robot position scene stationary, probability
individual pixel values successive images strongly correlated shared environmental
representation robot position, varying sensor noise. Subsequently, object detector
responses also strongly correlated. However, correctly representing observations way
requires environmental model sufficient capture image generation process, intractable
computational modeling burden. Image-based object detectors detectors
exhibit dependence environment. object detector utilizes properties
environment (geometric otherwise) generate detections cannot priori treated producing
conditionally independent observations given state robot. Correctly representing
full generative model object detection takes account environmental properties used
detector frequently intractable task.
overcome difficulty, approximate real process object detection simplistic
model images correlated. replace influence environment correlations observations convex combination fully independent model
depend history observations, correlated observation model depend
history observations. treat whether particular observation correlated previous
observation random variable. new posterior belief state world computed

K
p(z K |y, xK , K1 ) = p(z K K1 )p(zind
|y, xK )
K
+ (1 p(z K K1 ))p(zcorr
|y, xK , K1 ),

(9)

marginalized whether observation z K actually independent
previous observation not. use notation B represent event independent
B. Factorizing likelihood way (Equ. 9) allow us capture intuition
repeated observations similar waypoints add little robots knowledge state
world treated correlated. Observations afield, however, become
increasingly independent; less correlating effect.
order complete sensor model uses factorization Equ. 9, need construct model independent correlated likelihoods well model probability
particular detection independent previous detections. following sections describe
two different approaches modeling likelihood functions probability independent
detections.
4.1 Static Disc Model
first sensor model called static disc sensor model, coarse, assuming
measurements drawn according either learned first-order Markov model according
nearest previous observation.
K |y, xK approximated using histogramThe distribution independent detections zind
based detector performance labeled training data. is, training data collected placing
robot waypoint grid around training object facing object. robot collects
series images waypoint, generates histogram object detection confidences
waypoint collected images, histogram gives probability measurement z K specific (relative) waypoint xK . contrast, correlated detection model assumes
430

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

(a) Perception Field Observations

(b) Perception Field One Observation, Disc Model

Figure 4: Perception field possible door using static disc sensor model. unknown
object center (blue) looking towards right. Brighter regions correspond
waypoints likely result higher confidence posterior beliefs. Observations
taken robot denoted location (magenta) oriented point sensor
directly object.

measurements fully correlated always equal closest (in x) previously seen observation. described Equ. 9 treat probability observation independence mixing
parameter, disc express truncated linear function Euclidean distance, d,
two viewpoints. distribution normalized respect maximum distance dmax , beyond
observations treated fully independent. Thus,

K
K1
dmax < dmax
(10)
p(z

) = disc =
1
dmax
words, information gained taking additional measurements waypoint
information content observations increases linearly distance previous ones.
reference Equ. 6, model results belief update,


K |y, xK )
p(zind
K
p(y|T ) = disc
+ (1disc ) p(y|T K1 ).
(11)
K |xK )
p(zind
431

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Fig. 4 shows two example perception fields object detector trained doors (see Section 7
training process). Fig. 4(a), see highly informative measurements directly
front door, 8m 10m. Fig. 4(b), see change perception field
observation. mixture parameter static disc model, disc , dmax value
empirically chosen 3 meters.
4.2 Dynamic Time-Varying Correlation Model
static disc model shown previous section allow sensor model change
according data actively seen trajectory. purpose introducing correlation
model capture effect environment object detector. object detectors
response individual object appearances captured dependence (for example, door
detector may different behavior detecting highly reflective glass doors versus solid oak
doors). However, static disc model assumes fixed correlation model sensor model
objects particular class, regardless changes detectors response across individual
instances object class. previous model also assumes strong (truncated)
linear relationship probability two observations correlated distance
two observations. would like relax assumption order better model broad
range object detectors. second sensor model solves aforementioned issues
static disc model, also allows time-varying correlations observations taken
object. sensor models make use factorization Equ. 9, differ models
K |y, xK ) p(z K |y, xK , K1 ) well structure
used detection likelihoods p(zind
corr
p(z K K1 ).
would like mechanism learning correlation measurements
depend potentially infinite number previous measurements, use Gaussian
Process (GP) model independent correlated sensor models. Gaussian process
collection random variables, finite number joint Gaussian distribution,
completely specified mean function covariance function (Rasmussen & Williams, 2006).
use GP regression likelihood models always use zero mean function 0
Squared Exponential (SE) variance function following structure:
0 (scaleI)1 (xx0 )/2

SE(x, x0 ) = sigma e(xx )

.

(12)

use notation SEi (X; ) mean kernel SEi function X parameterized
.
4.2.1 NDEPENDENT C ORRELATED L IKELIHOOD ODELS
order model independent observations use Gaussian Process, GP ind , zero mean function squared-exponential covariance function described above. kernel parameters, ind ,
learned training data pairs waypoints x observations z described section 4.2.3.
GP takes input particular waypoint x predicts detector output z waypoint.
Letting train set labeled waypoint-observation pairs used GP ind , observation model
independent observation becomes
K
K
zind
|y, xK , K1 = zind
|y, xK

GP ind (0, SEind (T train , xK ; ind )).
432

(13)

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

see model depends solely training data provide prediction.
Similar independent model use Gaussian Process, GP corr , zero mean function learned SE kernel correlated observation model (Equ. 14) trained model nonindependent observations object detector. kernel parameters, corr , learned
training data described Section 4.2.3. Let corr-train set waypoint-observations pairs
used train GP corr . But, GP corr uses training data learn kernel parameters makes
predictions data acquired current trajectory K1 far, results
following correlated observation model:
K
zcorr
|y, xK , K1 GP corr (0, SEcorr (T K1 , xK ; corr )).

(14)

Unlike independent model GP predicts using training data (Equ. 13), correlated
model GPs predictions based solely data observations taken current object rather
K |y, xK , K1 using
observation histories objects. Predicting likelihood zcorr
GP regression marginalizing previous trajectory observations results
normal distribution,
K
2
zcorr
|y, xK , K1 N (corr,K , corr,K
).

(15)

choice model independent correlated observations using GPs results
overall observation model simplifying mixture two Gaussian distributions,
2
).
z K |y, xK , K1 N (obs , obs

(16)

4.2.2 IXTURE PARAMETER P ROXY NDEPENDENCE
reason factor likelihood independent model correlated model capture intuition nearby observations correlated therefore less informative,
require baseline model observations remaining robot waypoints. model
probability observation independent (p(z K K1 ) Equ. 9) treating
time-varying spatial mixture parameter . mixing parameter chosen function
variance correlation model estimate,
2

p(z K
K1 ) = p(z K
K1 |xK , K1 ) = (xK , K1 ) = 1 ecorr,K .

(17)

using SE kernel function GP corr , know variance prediction
corr,K function input space distance independent actual prediction value
(Rasmussen & Williams, 2006). Note GP corr function current trajectory
world, K1 , current waypoint xK function training data corr-train .
variance estimate GP corr function distance waypoints
observations taken far particular object, encodes intuition observations
similar waypoints correlated. fact, current waypoint approaches previous
K |y, xK , K1 approaches 0, 1, means
observation waypoints, variance zcorr
trust correlated observation model independent model. Similarly, distance
current waypoint previous observation waypoint becomes large, 0
trust independent observation model almost exclusively. words, little information
gained taking additional measurements waypoint information content
observations increases distance previous ones.
433

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

shown Fig. 3(c), remove add dependency previous waypoints
current observation z K . use pair GPs model spatial time-varying properties
correlations observation sequence object detector.

(a) Learned perception field first
observation.

(b) Learned perception field third
observation.

Figure 5: Learned perception field door detector (a) first observation (b) third observation. (b), previous observations (shown magenta) shift expect
informative vantage points be. panels, unknown object centered
origin facing right. Brighter regions correspond waypoints likely result
higher confidence posterior beliefs. Observations taken robot denoted
location (magenta) oriented point sensor directly object.

4.2.3 RAINING ENSOR ODELS
dynamic time-varying observation model consist mixture two Gaussians (see Equ. 16),
modeled using two Gaussian Processes, GP ind GP corr , every object hypothesis. Gaussian Process maps locations, x, resulting object detection score
z. Every object detector system observation model. independent observation likelihood GPs trained using available training data. labeled tuple
(z, x, = {object, no-object}) used independent sample fed independent GP corresponding labeled object state ({object, no-object}). training
samples used learn SE kernel independent GP models. way learn
model detector output likelihood cases object truly existed not, assuming independent observations. two GPs shared across objects constant
measurements.
correlated observation model GPs learned SE kernel use
different data. SE kernel trained data object since trying
learn model correlated detections. split training data set subsets cor434

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

(a) Learned perception field first
observation.

(b) Learned perception field third
observation.

Figure 6: Learned perception field text detector (a) first observation (b) third observation. (b), previous observations (shown magenta) shift expect
informative vantage points be. panels, unknown object centered
origin facing right. Brighter regions correspond waypoints likely result
higher confidence posterior beliefs. Observations taken robot denoted
location (magenta) oriented point sensor directly object.

respond objects. SE kernel parameters chosen maximal likelihood
parameters set subsets. However, kernel parameters learned, correlated model GPs initially devoid data. two correlated model GPs instantiated
per-object basis shared across objects. Samples added runtime
robot actively observes detector outputs world. such, correlated model GPs track
current set waypoints observed particular object, whereas independent model GPs
track training samples since treated independent.
Using learned dynamic time-varying sensor model derived initial perception field
door shown Fig. 5(a). Fig. 5(b) shows perception field several observations
taken around door. Notice expected amount information significantly
decreased around observed points farther waypoints may still yield useful observations.
initial perception field shows areas high expected information gain observation
according training samples particular object detector. Since previous
observations, initial perception field shows use learned independent Gaussian Process
object detector.
derived perception field text sign shown Fig. 6(a). Experimentally, truncated
text perception field waypoints aspect 45 degrees object
435

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

computational efficiency, given detector fire viewing signs obtuse
angles training data. Fig. 6(b) shows perception field several observations
taken around object. Notice text detector significantly different perception
field door detector, initial shape well response observations. see
door detector peaks within perception field, signifying regions relatively high
information gain. text detector, hand, smooth perception field
drops mainly function depth.

5. Planning Perceive
Given sensor model described previous section, describe planning algorithm
trades necessity gaining additional information object hypothesis
operational cost obtaining information. particular, object first detected, new
path original goal planned based total cost function includes motion
cost cmot along path value measurements waypoints along path expressed
reduction expected cost decision actions. Recall cost function consists two
terms: motion cost cmot (x0:K ) decision cost cdet (x0:K , a), optimal plan
given Equ. 1, reproduce here:

= arg min cmot (x0:K ) + cdet (x0:K , a) ,
x0:K ,a



cdet (x0:K , a) = Ey|x0:K[dec (a, y)],

Ey|x0:K [] denotes expectation respect robots knowledge regarding object,
executed path x0:K .
5.1 Motion cost
path cost, cmot (x0:K ), encompasses operational considerations power expended
time taken moving along particular trajectory typically proportional length
trajectory.
5.2 Decision Cost
decision cost, cdet (x0:K , a), captures expected cost accepting (or rejecting)
potential object detection, also captures expected yield information observations
along path x0:K . trajectory affects cost decision actions terms changing
expectation, rather decision actions themselves, effect allowing algorithm decide
observations needed.
Note decision actions treated independently also independently
robot motion, allows us compute expected decision costs efficiently.
take advantage efficiency move minimization decision actions directly inside
cost function. Abusing notation cdec ,
cdet (x0:K ) = arg min cdet (x0:K , a)

(18)



= arg min Ey|x0:K[dec (a, y)].


436

(19)

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Next, write plan terms x0:K .

= arg min cmot (x0:K ) + cdet (x0:K ) .

(20)

x0:K

dec (accept, ) dec (reject, ) costs associated declaring object exists
not, respectively, measuring z xK following traversal waypoint-observation trajectory
K1 . costs include penalties imposed accepting true positive detection
accepting false positive detection, respectively, chosen user system
reflect value/penalty decision particular domain.
expectation inside Equ. 19 relies model conditioned trajectory x0:K ;
seen Fig. 3(c), x0:K correlated z K . planning, actual z K
received cannot known ahead time, evaluate expectation exactly, must
taken respect object state received observations,
Ey|x0:K [
(a, y)] =

Z dec
K
K1
p(z|x ,
)Ey|z,x0:K1 [dec (a, y)] ,

(21)

z

p(z|xK , K1 ) denotes probability obtaining particular detector confidence value
observing object x given previous trajectory K1 , computed akin
posterior Equ. 6. Section 6.2 show efficiently approximate expectation
observation sequence treating belief normally distributed.
planning process proceeds searching sequences x0:K , evaluating paths approximating expectations respect observation sequences object state.
paths lowest decision cost tend leading lowest posterior entropy,
avoiding large penalty false positives negatives.
5.3 Multiple Objects
formally define vantage point relative object y, vy RM , vector dimensional feature space describing configuration robot relative potential object.
also define mapping F : R2 SO(2) 7 RM robot waypoint x corresponding vantage point vy = F (x, y). principle, vantage point need restricted spatial
coordinates may incorporate additional information as, example, degree occlusion experienced image contrast (for appearance based detector). work, however,
range, r, aspect, , relative object robot oriented directly face object
considered vy R SO(2) (see Fig. 2a). important note system must
able accurately compute vantage point; paper stereo camera used estimate
distance orientation potential object. planning approach described far
extended planning environment Q object hypotheses considering modified cost
function simply adds cost object. also augment dec (a, y) dec (a, y, i)
able provide different decision costs different object types (or even different object instances). augmentation allows us specify relative importance different objects types
algorithm. work consider objects existence independent objects
hence individual object perception fields additive particular waypoint x. also restrict
waypoints correspond robot facing particular hypothesized object.
437

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Given prior information object locations, hypothesize many objects
world. initially let Q = 0 run object detector robot motion.
image processed object detector, system judges whether detection belongs object hypothesis already considered (e.g., using distance
hypothesized object detection). detector determines probability object
new location threshold belong hypothesis objects,
number object hypotheses Q increased robot replans. detection determined
correspond particular object hypothesis, system updates belief replans.
5.4 Multi-Step Planning
simple approach planning considers every possible trajectory goal weights
cost taking trajectory, choosing minimum cost trajectory plan. simple
algorithm scales approximately exponentially length planning horizon thus
rapidly becomes intractable observations considered. adopt roadmap scheme
fixed number waypoints sampled every time new waypoint added
current trajectory. graph built sampled poses, straight-line edges
samples.
sampling scheme biased towards waypoints likely lead useful observations
using perception field (see Section 3.2). Due correlations individual observations
made trajectory waypoints, perception field changes new observations added.
particular, correlation model imposed work (Equs. 17 9 dynamic time-varying
model Equ. 11 static disc model) forces
lim

# obs. xK

I(Y, Z K ; xK , K1 ) 0,

considering measurements waypoints already visited. words, robot
prefer observe putative object different waypoints taking repeated measurements
place.
Algorithm R EPLAN N N EW ETECTION (Fig. 7) summarizes planned-waypoints approach
sampling evaluating trajectories balance increased confidence motion costs.
algorithm uses Posterior Belief Distribution framework able quickly sample trajectories
many observations, selects best current plan according cost
metric.
Figure 8 details stages algorithm example run single door detected
going towards goal.

6. Efficient Perception Field Computation
planning algorithm needs calculate perception field deep planning horizons (T 1).
variant algorithm uses static disc sensor model must evaluate expected
change belief every potential future waypoint, must carry belief thought
level search tree future trajectories xK+1:K+T . However, using dynamic
time-varying sensor model treat belief normally distributed. normal
distribution approximation, limit infinite number observations, mean normal
distribution converge either 0 1 (depending whether object present not),
438

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Algorithm R EPLAN N N EW ETECTION
Input: object detection z vantage point x
// Step 1: Update Belief
2: using static disc sensor model
3:
dmin = arg min |x xi |
1:

4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:

disc =

xi K1
dmin
dM AX
K |y,T K )
disc p(z
p(z K |T K )

Equ 10

+ (1disc ) p(y|T K1 )

p(y)
else
N (corr,K , corr,K ) PREDICT(GP corr , x)
2
1 ecorr,K
n n1 + Kn (zn W (n1 ))
n (n1 + Gn bn GTn )1
// Step 2: Sample Trajectories
{}
sampling time remains
traj {}
using static disc sensor model
y0
= 1
Pi COMPUTE - PERCEPTION - FIELD(yi1 )
xi Pi // sample vantage point
p(yi ) Ez 0 [p(z 0 |xi , K1 , yi1 )p(yi1 )]
traj traj xi
else
00 n
00 n
GP 0corr GP corr
= 1
i1
Pi COMPUTE - PERCEPTION - FIELD(0i1 , 0i1 , GP corr
)
xi Pi // sample vantage point
z 0 PREDICT(GP i1
corr , GP ind , xi )
0
GP icorr UPDATE - SENSOR - MODEL(GP i1
corr , xi , z )
0i 0i1 + Kn (zn 0 W (0i1 ))
0i (0i1 + Gn bn GTn )1
traj traj xi
traj



35: EXECUTE - TRAJECTORY

Equ 11

Equ 17
Equs 25, 27 28

Equ 8

Equs 8 32
Equs 9, 13, 14 17
Equs 25, 27 28

arg min COST(t0 )
t0

Figure 7: waypoint planning algorithm samples trajectories using perception field,
chooses trajectories balance increasing robots confidence object
minimizing trajectory costs (Equ. 1).

439

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

(a) Initially, robot (blue
triangle) goal (red star)
detections fired
yet, potential objects
reasoned about.

(b) detector fires,
robot starts reasoning
potential object.
system creates initial
perception field training
data potential object
plans path take
detections.

(c) two detections (magenta) belief high
enough system confident door truly exists
world continues
towards goal. Shown
resulting perception field
two taken observations.

Figure 8: sample run system, initially empty set objects reasoned
(a), door detector firing causing new door object hypothesis perception field
created (b). system plans executes path goal allows
take advantageous observations hypothesized door. two observations,
system continues towards goal since belief whether door exists
increase expected reward improving confidence
object model justified additional cost (c). Brighter regions perception
fields correspond waypoints likely result higher confidence posterior beliefs.
Observations taken robot denoted location (magenta) oriented
point sensor directly object. belief whether door truly exists
denoted green bar.

small variance. Additionally, expected cost decision depend variance
distribution: smaller covariance normal posterior, less likely probability
decision error. Finally, posterior covariance normal depend sensor
model, observation itself. result, know sensor model information gain
measurement, predict posterior covariance, hence expected cost
decision action, without knowing exact observation sequence itself. approximation
binomial measurement function known Posterior Belief Distribution (PBD) algorithm (He
et al., 2011), used efficiently compute resulting belief time steps. sketch
general idea behind PBD below, use compute expected entropy reduction
belief future observations.
440

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

6.1 Belief
reality, object either exists exists world (denoted ). Labeled training
data output object detector form (z, x, = {object, no-object}), pair
detector output particular waypoint knowledge whether object exists not.
order use labeled samples train sensor model (a model object detector),
keep track belief whether object exists not. Equs. 22 23 show independent
correlated observation model likelihood given using likelihood given . marginalize
belief independent correlated observations models (Equs. 13 14)
get
K
K
p(zind
|, xK , K1 ) = p(zind
|object, xK , K1 )
K
+ (1 ) p(zind
|no-object, xK , K1 )

(22)

K
K
p(zcorr
|, xK , K1 ) = p(zcorr
|object, xK , K1 )
K
+ (1 ) p(zcorr
|no-object, xK , K1 ),

(23)

likelihood modeled GP similar Equ. 13 14 independent
correlated models respectively.
Noting write likelihood z terms using (Equs. 22 23),
similarly rewrite Equ. 9 terms likelihoods based
K
p(z K |, xK , K1 ) = p(z K K1 )p(zind
|, xK , K1 )
K
+ (1 p(z K K1 ))p(zcorr
|, xK , K1 ).

(24)

6.2 Posterior Belief Distribution
PBD algorithm allows us estimate expected information gain particular waypoint
without integrating potential observations z. begin framing problem Exponential Family Kalman Filter (efKF) formulation (He et al., 2011) treat state
trying estimate, exponential family observation model,
n = n1 N (n , n )

(25)

zn = exp(zn n bn (n ) + n (zn )).

(26)

Given single observation canonical link function W mapping state observation
parameter , posterior mean variance belief computed as,
n = n1 + Kn (zn W (n1 ))
n = (n1 + Gn bn GT )1

(27)
(28)

n

Kn = n1 Gn (Gn n1 GTn + bn
zn = n bn
fi
n fifi
Gn =
n fi

1

(bn zn )
.

n =n1

441

1 1

)

(29)
(30)
(31)

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

GP
object
Text GP ind
no-object
Text GP ind
object
Text GP corr
no-object
Text GP corr
object
Door GP ind
no-object
Door GP ind
object
Door GP corr
no-object
Door GP corr

SE kernel
5.5
16.2
4.2
4.6
0.52
54.3
0.002
9303

SE kernel l
0.15
0.23
0.14
0.09
0.58
0.49
0.17
0.31

Table 1: learned GP parameters. Note kernel scale door text differ
correlated observation GPs.

particular importance us fact posterior covariance closed form solution,
independent posterior mean (He et al., 2011), require integrating
possible observations Z. compute posterior covariance observations
future

X
n+T = (n1 +
Gi bi GTi )1 .
(32)
i=1

Rather marginalize potential future observations every future waypoint,
compute variance belief observations simply multiplying
variance observations future waypoints. Given perception field
function variance belief (since entropy normal distribution function
variance), quickly compute field deep observation trajectories. efficient
computation allows planning algorithm sample potential observation trajectories many
observations (T 1), thereby increasing effective search depth algorithm improving
plans.

7. Objects: Doors Signs
system general agnostic type detector employed even sensing modality
used. constraint formed need able define vantage points (see Section
5.3) compute perception field (see Section 3.2). work, chose test approach
two different vision-based object detectors: first leverages parts-based object detector
Felzenszwalb, Mcallester, Ramanan (2008) trained find doors; second detector aims
spot human-readable text world commonly found signs. use text-spotting
inspired work Posner, Corke, Newman (2010) authors kindly provided us
C++ software library latest incarnation text-spotting engine, provides
detection parsing facilities individual words natural scene images.
door detector trained approximately 1400 positive 2000 negative examples
manually labeled images collected large range indoor areas excluding testing
environment. Performance images testing environment low due false positives
triggered visual structures present training images. detector could re-trained
442

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.31 0.06
0.44 0.07
67.08 2.23
50

G REEDY=0.6
0.60 0.07
0.62 0.07
41.95 0.88
50

P LANNEDdisc
0.75 0.06
0.80 0.06
54.98 3.04
50

RTBSS
0.45 0.06
0.58 0.07
47.57 0.19
50

Table 2: Simulation performance single door scenario, standard error values.

improve performance, problem recurs new environments encountered.
examples also used train sensor models door detector.
text detector trained exactly described Posner et al. (2010). dynamic timevarying sensor model determined using approximately 1800 positive 2000 negative examples manually labeled images collected indoor office environment excluding
testing environment. used text detector localize text environment,
actually use contents text itself.
mixture parameter dynamic time-varying sensor model, scale factor
chosen maximum likelihood estimator using training data detector system.
learned scaling values door = 6.5 text = 5.4. Table 1 shows learned GP parameters
door text detectors.

8. Simulation Results
first assessed planning approach using learned models simulated environment.
simulation environment consisted robot navigating occupancy map, object
detections triggered according learned observation model. also simulated false positives
placing non-object perceptual features probabilistically triggered object detections using
learned model false-alarms. processing delay incurred actual object detector also
simulated (the door detector requires approximately 4.5 seconds process spatially decimated
512x384 pixel image text detector requires 8 seconds process full 1024x768 pixel
image).
8.1 Comparison Algorithms
simulation trials compared algorithm two algorithms. G REEDY
algorithm selected best waypoint according perception field potential object belief object exceeded threshold . Second, compared algorithm
RTBSS online POMDP algorithm (Paquet, Tobin, & Chaib-draa, 2005). RTBSS algorithm
could use full sensor model Markov assumption utilized independent part model. One could augment state space include entire history
detections therefore use full sensor model, however large state space would render
POMDP intractable practice. chose maximum depth equal algorithm
modeled world using resolution 2.5 meters RTBSS algorithm. denote
algorithm using static disc sensor model P LANNEDdisc , dynamic time-varying sensor
model P LANNED.
443

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.64 0.03
0.63 0.02
153.32 4.37
50

G REEDY=0.6
0.54 0.03
0.57 0.03
121.35 1.32
50

P LANNEDdisc
0.53 0.05
0.76 0.03
138.21 7.12
50

RTBSS
0.70 0.03
0.66 0.03
160.74 6.08
50

Table 3: Simulation performance multiple door scenario, standard error values.

(a) small simulation environment used doors
containing single object (blue) two non-object
(black).

(b) multiple object simulation environment used
doors containing 4 objects (blue) 6 nonobjects (black).

Figure 9: simulation environments static disc sensor model door detector.
8.2 Static Disc Sensor Model Simulations
First, tested P LANNEDdisc algorithm small simulation environment one door
object shown Fig. 9(a). Table 2 shows simulation results static disc model door
detector. Overall, explicitly planning waypoints resulted significantly higher performance.
P LANNEDdisc algorithm performed better RTBSS terms precision recall, likely
algorithm sampled continuous-space waypoints RTBSS algorithm fixed
discrete representation, RTBSS paths shorter.
evaluated P LANNEDdisc algorithm larger, complex scenario containing four
doors six non-door objects. Fig. 9(b) shows multiple door simulation environment. Table 3
shows simulation results multi-door scenario. P LANNEDdisc algorithm resulted
second shortest paths G REEDY=0.6 superior detection performance. P LANNEDdisc
also resulted significantly shorter paths RTBSS given operating point ROC
curve.
8.3 Dynamic Time-Varying Sensor Model Simulations
tested P LANNED algorithm small simulation single text sign
complex simulation environment two signs shown Figs. 10 11. Table 4 shows results
20 trials using text detector sensor model single object simulation. text signs,
444

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
0.37 0.10
0.47 0.12
35.32 1.08
20

P LANNED
0.24 0.06
0.47 0.12
20.40 0.74
20

RTBSS
0.20 0.06
0.40 0.11
18.43 0.43
20

Table 4: Simulation performance single sign scenario, standard error values.

see deep trajectory planning help much (compare G REEDY strategy
Planned strategy planning horizon 5). information text detector
spread smoothly (see perception field Fig. 6(a)) hence greedy strategy best
thing do. However, planner took account cost resulted lower precision-recall
performance much shorter path length. also saw correlation sensor model allowed
planned algorithm perform better RTBSS. belief updates predicted RTBSS
overconfident hence RTBSS algorithm resulted shorter path lengths worse precision-recall
performance planned-waypoints algorithm.

Figure 10: small simulation environment used text signs containing single object (blue)
single non-object (black).

Next, evaluated P LANNED algorithm complex scenario containing two objects
two non-objects shown Fig. 11. Table 5 shows simulation results multiple-object
scenario. P LANNED algorithm resulted best precision-recall performance short path
length. RTBSS also resulted short path length, lack correlation model
became overconfident belief, performing significantly worse planned-waypoints algorithm terms precision-recall.
Fig. 11 also shows density trajectories traversed algorithm simulations
run. Brighter spots denote places simulated robot frequented simulation runs.
see P LANNED algorithm kept robot close shortest path cost
function, RTBSS. However, P LANNED algorithm decided spread detections apart
correlation model employed whereas RTBSS over-valued information gained
nearby observations. G REEDY algorithm take account motion cost
taking observation saw widespread set trajectories waypoints visited
simulations.
445

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
0.23 0.06
0.28 0.08
66.72 1.39
20

P LANNED
0.93 0.05
0.72 0.07
33.80 1.00
20

RTBSS
0.54 0.11
0.43 0.09
23.32 0.63
20

Table 5: Simulation performance multiple signs scenario, standard error values.

(a) G REEDY Trajectories

(b) P LANNED Trajectories

(c) RTBSS Trajectories

Figure 11: multiple object simulation environment used text containing 2 objects (blue)
2 non-objects (red). Shown density paths taken different algorithms
simulation trials. planned approach results narrower space paths
G REEDY avoiding nearby (correlated) observations.

8.4 Time Improvements PBD
ran comparison updating perception field using PBD algorithm (see Section
6.2) update requires computing expectation possible detector outputs.
created histogram potential detector values either 100 10 bins used sampled
compute expected mutual information gain (the perception field) detector
output bins. Table 6 shows results computing perception field 100 times. PBD algorithm
allowed us efficiently calculate perception field since explicitly iterate
possible detector values could use Equ. 32.
Updating perception field time-consuming part algorithm since must
updated reasoning future observations planning. total run-time
determined many trajectories sampled using perception field depth
future trajectories, could tuned particular scenario application.
paper let planning algorithm sample evaluate trajectories amount time
running object detector single image passed.
446

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

min
avg
max

100 bins z
4.17s
4.58s
4.97s

10 bins z
1.17s
1.20s
1.22s

PBD
0.85s
0.85s
0.87s

Table 6: Timing results computing perception field using either PBD algorithm, explicitly enumerating potential detector values z computing expectation
values.

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.8
0.53 0.14
0.60 0.14
153.86 33.34
10

P LANNEDdisc
0.7 0.15
0.7 0.15
91.68 15.56
10

Table 7: Results door real-world trials using robot wheelchair, standard error values.

(a) Trajectory executed actual robot wheelchair using planned-waypoints
G robot discovers one true door (cyan). Near goal,
detects two possible doors (red dots), detours inspect them, (correctly) decides doors.

(b) Robotic wheelchair
platform

Figure 12: Real world trial door detector using robotic wheelchair platform

9. Results Real World Trials
Finally, validated results P LANNEDdisc P LANNED algorithms robot wheelchair
platform (Fig. 12(b)). autonomous wheelchair equipped onboard laser range scanners,
primarily used obstacle sensing navigation, Point Grey Bumblebee2 color stereo camera,
quad-core laptop main processing unit. stereo camera used accurately
determine vantage point particular detection. door textual signs planar,
447

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

fit plane detection bounding box 3D points stereo camera determine
orientation possible object given detection.
door text real world trials, robot started particular location orientation.
robot given goal position nominal trajectory would bring past
one true object (a door text sign), near several fixtures trigger object detections.
Initially, system object hypothesis detector run continuously moved
towards goal shortest path. object detector fired, system started reasoning
object hypothesis corresponding detections. robot deviated shortest
path take observations certain object hypothesis determined cost function. Finally,
robot reached goal trial ended. object hypothesis accepted belief
greater 0.5. cost incorrect decision set 16 times cost meter
path length, cost correct decision set negative incorrect decision.
trials capped 20 minutes done real office environment without special
accommodations realistic possible.
Fig. 12(a) shows location door trials. robot always started start location
(marked S) given goal location (G). single door could
seen path start goal. Near goal also set windows light
fixtures often caused door detector fire. Fig. 12(a) illustrates trajectory executed
single trial P LANNEDdisc algorithm, Table 7 summarizes results trials
doors. G REEDY=0.8 chosen baseline comparison since best performing
existing algorithms according Table 3. P LANNEDdisc algorithm resulted significantly
shorter trajectories maintaining comparable precision recall. doors detected substantial uncertainty, algorithm planned advantageous waypoints increase confidence
ignored far away detections high motion cost. interesting see Fig. 12(a)
algorithm deviated take observations false detections near goal location, ultimately
correctly deciding object hypothesis fact doors.
similarly conducted experiment using P LANNED algorithm G REEDY=0.7
robotic wheelchair platform text detection algorithm. robot given nominal
trajectory brought past single textual sign (a poster office number placed
common location poster notifications). trials run daytime hours allow
artificial well natural lighting common environmental changes people
walking robot. Table 8 summarizes results 5 real-world trials algorithms.
see G REEDY algorithm outperformed P LANNED terms precision (consistent
simulation results) much longer path lengths. P LANNED algorithm balanced
cost gaining new observations travel time resulted much shorter trajectories.
large path-length associated greedy algorithm came two sources: first, greedy
algorithm take path cost account deciding next observation take, second
greedy algorithm kept taking pictures object hypothesis belief certain
threshold included sporadic object detections caused lights temporary environment
noise.
Lastly, ran small set 3 trials using P LANNED algorithm looking text signs
completely different environment previous trial. ran trials night
people walking by. Table 9 shows results. Even different environment, algorithms
behaved similarly, G REEDY algorithm outperforming P LANNED algorithm cost
much longer paths.
448

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
1 0
1 0
102.77 7.21
5

P LANNED
0.70 0.09
0.80 0.09
34.86 5.29
5

Table 8: Results text real-world trials using robot wheelchair.
Average
Precision
Recall
Path Length (m)
Total Trials

G REEDY=0.7
1 0
1 0
39.2047 2.76
3

P LANNED
0.33 0.33
1 0
17.5351 4.35
3

Table 9: Results small text real-world trials different location using robot wheelchair.

10. Related Work
problem planning motion trajectories mobile sensor explored number
domains including planning, sensor placement, active vision robot exploration.
general formulation partially observable Markov decision process (Sondik, 1971). Exact
solutions POMDPs computationally intractable, recent progress led approximate
solvers find good policies many large, real-world problems (Pineau, Gordon, & Thrun,
2006; Smith & Simmons, 2005; Kurniawati, Hsu, & Lee, 2008; Kurniawati, Du, Hsu, & Lee, 2010).
However, complexity representing even approximate POMDP solution led forward
search strategies solving POMDPs (Ross et al., 2008; Prentice & Roy, 2009; et al., 2010).
Eidenberger Scharinger (2010) formulate problem choosing sensor locations active
perception POMDP similar spirit formulation. However, explicitly model
underlying physics object generation, model uncertainty object location rather
object type, also unable plan one step future, therefore work
similar G REEDY strategies described previous sections. approach inspired
forward search POMDP algorithms, incorporates complex model approximates
correlations observations.
contrast POMDP models active sensing, controls community sensor placement community developed information-theoretic models, goal minimize
norm posterior belief, entropy. objective function depend motion costs vehicle, sub-modular (Krause & Guestrin, 2007). consequence, greedy
strategies choose next-most valuable measurement shown boundedly close
optimal, challenge generate model predicts next-best measurement
(Guestrin, Krause, & Singh, 2005; Krause, Leskovec, Guestrin, VanBriesen, & Faloutsos, 2008).
terms image processing object recognition, Denzler Brown (2002) Sommerlade
Reid (2010) showed information-theoretic planning could used tune camera parameters improve object recognition performance applied multi-camera systems, although
use exhaustive search camera parameters rapidly becomes unwieldy. Lastly, Sridharan, Wyatt, Dearden (2008) showed formulating information-theoretic problem
decision-theoretic POMDP, true multi-step policies improve performance computer
449

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

vision system terms processing time. However, previous algorithms use models
sequential decision making costs actions independent (or negligible), leading
submodular objective function limited improvement greedy strategies.
considerable work view point selection active vision briefly
review here. relevant pieces work include Arbel Ferrie (1999)
recently Laporte Arbel (2006) use Bayesian approach model detections related
ours, searches next-best viewpoint, rather computing full plan. work
Deinzer, Denzler, Niemann (2003) perhaps similar viewpoint
selection problem framed using reinforcement learning, authors neglect costs
camera movement identify absence costs limitation work. Similarly,
system Mittal Davis (2008) learns model object occlusion uses simulated annealing
solve optimal plan; contribution learn predictive model good viewpoints.
work Borotschnig, Paletta, Prantl, Pinz (2000) uses appearance-based object detection
system plan viewpoints minimize number observations required achieve certain
recognition rate, account correlations different observations.
field object localization search seen recent advancements. use
object object relations seems like promising direction shown works Aydemir, Sjoo,
Folkesson, Pronobis, Jensfelt (2011) Joho, Senk, Burgard (2011). approach differs
system uses spatial relations single object multiple observations rather
different objects. works Joho et al. (2011) Aydemir, Gobelbecker, Pronobis,
Sjoo, Jensfelt (2011) model environment achieve good results, whereas system
models correlation observations lieu modeling full environment. idea
attention seems powerful tool visual search (Tsotsos, 1992) systems
due Meger, Forssen, Lai, Helmer, McCann, Southey, Baumann, Little, Lowe (2008)
Andreopoulos, H., Janssen, Hasler, Tsotsos, Korner (2011) exhibiting excellent results. Rather
using attention, system utilizes mutual information minimizes cost taking
observations. useful note system minimizes single cost function
encodes information path costs, Ye Tsotsos (1999) formalized approach
maximizes probability localizing object minimizes cost.
robot exploration, goal generate robot trajectories learn accurate
complete map minimum travel cost, costs motion must incorporated. Bourgault,
Makarenko, Williams, Grocholsky, Whyte (2002) developed full exploration planner
incorporated explicit trade-off motion plans map entropy. Stachniss, Grisetti,
Burgard (2005) described planner minimized total expected cost, performed search
next-best action. address computational challenge, Kollar Roy (2008) used
reinforcement learning learn model expected cost next viewpoint
exploration, minimize total expected cost complete trajectory.
contribution work existing work primarily describe planning model
incorporates action costs detection errors, specifically give approximate
observation model captures dynamic correlations successive measurements
still allows forward-search planning operate, leading efficient multi-step search improve
object detection.
450

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

11. Conclusion Future Work
Previous work planned sensing largely ignored motion costs planned trajectories used
simplified sensor models strong independence assumptions. paper, presented sensor model approximates correlation observations made similar vantage points,
efficient planning algorithm balances moving highly informative vantage points
motion cost taking detours. fully model effects entire environment
sensor intractable endeavor. sensor model simplifies environment interactions treating
correlations entire history sensor readings. placed emphasis spatial
relations model correlations new sensor readings history previous sensor
readings. properties Gaussian Processes, sensor model allows efficient
deep trajectory sampling utilizing Posterior Belief Distribution framework. tested algorithm two different object detectors (doors signs) found better detector dependent
observation trajectories comparable strategies.
system presented planned deviations particular shortest-path trajectory
goal order detect localize objects spotted once. future aim
incorporate large scale spatial model object likely encountered
them. Next generation systems also deal novel objects exists
prior object detector detector must created fly. goal create
end-to-end online adaptive semantic mapping solution works arbitrary objects
environments.

References
Andreopoulos, A., H., W., Janssen, H., Hasler, S., Tsotsos, J., & Korner, E. (2011). Active 3d object
localization using asimo. IEEE Transactions Robotics, 27(1), 4764.
Anguelov, D., Koller, D., Parker, E., & Thrun, S. (2004). Detecting modeling doors mobile
robots. Proc. ICRA.
Arbel, T., & Ferrie, F. P. (1999). Viewpoint selection navigation entropy maps. Proc.
ICCV, Kerkyra, Greece.
Aydemir, A., Sjoo, K., Folkesson, J., Pronobis, A., & Jensfelt, P. (2011). Search real world:
Active visual object search based spatial relations. Proc. ICRA.
Aydemir, A., Gobelbecker, M., Pronobis, A., Sjoo, K., & Jensfelt, P. (2011). Plan-based object
search exploration using semantic spatial knowledge real world. Proc. ECMR,
Orebro, Sweden.
Borotschnig, H., Paletta, L., Prantl, M., & Pinz, A. (2000). Appearance-based active object recognition. Image Vision Computing, 18(9), 715727.
Bourgault, F., Makarenko, A. A., Williams, S. B., Grocholsky, B., & Whyte, D. H. F. (2002). Information based adaptive robotic exploration. Proc. IROS, EPFL, Lausanne.
Coates, A., & Ng, A. Y. (2010). Multi-camera object detection robotics. Proc. ICRA.
Deinzer, F., Denzler, J., & Niemann, H. (2003). Viewpoint selection - planning optimal sequences
views object recognition. Proc. ICCV. Springer.
451

fiV ELEZ , H EMANN , H UANG , P OSNER & ROY

Denzler, J., & Brown, C. M. (2002). Information theoretic sensor data selection active object
recognition state estimation. IEEE Trans. Pattern Analysis Machine Intelligence,
24(2), 145157.
Douillard, B., Fox, D., & Ramos, F. (2008). Laser vision based outdoor object mapping.
Proc. RSS.
Eidenberger, R., & Scharinger, J. (2010). Active perception scene modeling planning
probabilistic 6d object poses. Proc. IROS.
Felzenszwalb, P., Mcallester, D., & Ramanan, D. (2008). discriminatively trained, multiscale,
deformable part model. Proc. CVPR.
Guestrin, C., Krause, A., & Singh, A. (2005). Near-optimal sensor placements Gaussian Processes. Proc. ICML.
He, R., Brunskill, E., & Roy, N. (2010). PUMA: Planning uncertainty macro-actions.
Proc. AAAI, Atlanta, GA.
He, R., Brunskill, E., & Roy, N. (2011). Efficient planning uncertainty macro-actions.
Journal Artificial Intelligence Research, 40, 523570.
Joho, D., Senk, M., & Burgard, W. (2011). Learning search heuristics finding objects structured environments. Robotics Autonomous Systems, 59(5), 319328.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially observable
stochastic domains. Artificial Intelligence, 101, 99134.
Kollar, T., & Roy, N. (2008). Trajectory optimization using reinforcement learning map exploration. International Journal Robotics Research, 27(2), 175197.
Krause, A., & Guestrin, C. (2007). Near-optimal observation selection using submodular functions.
Proc. AAAI.
Krause, A., Leskovec, J., Guestrin, C., VanBriesen, J., & Faloutsos, C. (2008). Efficient sensor
placement optimization securing large water distribution networks. Journal Water Resources Planning Management, 134, 516.
Kurniawati, H., Du, Y., Hsu, D., & Lee, W. (2010). Motion planning uncertainty robotic
tasks long time horizons. International Journal Robotics Research, 30(3).
Kurniawati, H., Hsu, D., & Lee, W. (2008). SARSOP: Efficient point-based POMDP planning
approximating optimally reachable belief spaces. Proc. RSS.
Laporte, C., & Arbel, T. (2006). Efficient discriminant viewpoint selection active bayesian
recognition. International Journal Computer Vision, 68(3), 267287.
Martinez-Mozos, O., Stachniss, C., & Burgard, W. (2005). Supervised Learning Places
Range Data using Adaboost. Proc. ICRA.
Meger, D., Forssen, P., Lai, K., Helmer, S., McCann, S., Southey, T., Baumann, M., Little, J., &
Lowe, D. (2008). Curious george: attentive semantic robot. Robotics Autonomous
Systems, 56(6), 503511.
Mittal, A., & Davis, L. (2008). general method sensor planning multi-sensor systems:
Extens ion random occlusion. International Journal Computer Vision, 76, 3152.
452

fiM ODELLING BSERVATION C ORRELATIONS F ROBUST BJECT ETECTION

Newman, P., Sibley, G., Smith, M., Cummins, M., Harrison, A., Mei, C., Posner, I., Shade, R.,
Schroeter, D., Murphy, L., Churchill, W., Cole, D., & Reid, I. (2009). Navigating, recognising describing urban spaces vision laser. International Journal Robotics
Research, 28(11-12).
Paquet, S., Tobin, L., & Chaib-draa, B. (2005). Real-time decision making large POMDPs.
18th Canadian Conference Artificial Intelligence.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations large
POMDPs. Journal Artificial Intelligence Research, 27, 335380.
Posner, I., Corke, P., & Newman, P. (2010). Using text-spotting query world. Proc. IROS.
Posner, I., Cummins, M., & Newman, P. (2009). generative framework fast urban labeling
using spatial temporal context. Autonomous Robots, 26(2), 153170.
Prentice, S., & Roy, N. (2009). belief roadmap: Efficient planning belief space factoring
covariance. International Journal Robotics Research, 8(11-12), 14481465.
Rasmussen, C. E., & Williams, C. K. I. (2006). Gaussian Processes Machine Learning. MIT
Press.
Ross, S., Pineau, J., Paquet, S., & Chaib-draa, B. (2008). Online planning algorithms POMDPs.
Journal Artificial Intelligence Research, 32(1), 663704.
Smith, T., & Simmons, R. (2005). Point-based POMDP algorithms: Improved analysis implementation. Proc. UAI.
Sommerlade, E., & Reid, I. (2010). Probabilistic surveillance multiple active cameras. Proc.
ICRA.
Sondik, E. J. (1971). Optimal Control Partially Observable Markov Processes. Ph.D. thesis,
Stanford University.
Sridharan, M., Wyatt, J., & Dearden, R. (2008). HiPPo: Hierarchical POMDPs planning information processing sensing actions robot. Proc. ICAPS.
Stachniss, C., Grisetti, G., & Burgard, W. (2005). Information gain-based exploration using RaoBlackwellized particle filters. Proc. RSS, Cambridge, MA, USA.
Takeda, H., & Latombe, J. (1992). Sensory uncertainty field mobile robot navigation. Proc.
ICRA.
Tsotsos, J. K. (1992). relative complexity active vs. passive visual search. International
Journal Computer Vision, 7(2), 127141.
Velez, J., Hemann, G., Huang, A., Posner, I., & Roy, N. (2011). Planning perceive: Exploiting
mobility robust object detection. Proc. ICAPS, Freiburg, Germany.
Ye, Y., & Tsotsos, J. (1999). Sensor planning 3d object search. Computer Vision Image
Understanding, 73(2), 145168.

453

fiJournal Artificial Intelligence Research 44 (2012) 335-382

Submitted 03/12; published 06/12

Plan-based Policies Efficient Multiple Battery Load Management
Maria Fox
Derek Long
Daniele Magazzeni

MARIA . FOX @ KCL . AC . UK
DEREK . LONG @ KCL . AC . UK
DANIELE . MAGAZZENI @ KCL . AC . UK

Department Informatics
Kings College London
Strand, London WC2R 2LS, UK

Abstract
Efficient use multiple batteries practical problem wide growing application.
problem cast planning problem uncertainty. describe approach
adopted modelling solving problem, seen Markov Decision Problem, building
effective policies battery switching face stochastic load profiles.
solution exploits adapts several existing techniques: planning deterministic mixed
discrete-continuous problems Monte Carlo sampling policy learning. paper describes
development planning techniques allow solution non-linear continuous dynamic
models capturing battery behaviours. approach depends carefully handled discretisation temporal dimension. construction policies performed using classification
approach idea offers opportunities wider exploitation problems. approach
generality described paper.
Application approach leads construction policies that, simulation, significantly
outperform currently use best published solutions battery management problem. achieve solutions achieve 99% efficiency simulation compared
theoretical limit far fewer battery switches existing policies. Behaviour
physical batteries exactly match simulated models many reasons, confirm
theoretical results lead real measured improvements performance also conduct
report experiments using physical test system. results demonstrate obtain
5%-15% improvement lifetimes case two battery system.

1. Introduction
paper describe application planning important problem multiple battery
management. paper extended developed version work originally presented
International Conference Automated Planning Scheduling (Fox, Long, & Magazzeni, 2011)
and, particular, adds physical results work described paper.
increasing number systems depend batteries power supply, ranging small mobile devices large high-powered devices batteries used local storage electrical
substations. many systems significant user-benefits, engineering reasons,
base supply multiple batteries, load switched batteries control system. order power systems longest time possible, necessary devise switching
strategies extract maximum possible lifetime batteries. show planning
used basis highly efficient switching strategy.
Due physical chemical properties batteries, possible extract greater proportion energy stored single battery capacity C stored n batteries
c
2012
AI Access Foundation. rights reserved.

fiF OX , L ONG & AGAZZENI

capacity C/n, n > 1. Throughout paper, refer efficiency switching
strategy use multiple batteries, talking proportion charge extract
batteries service load, compared servicing load single battery
capacity equal combined collection batteries equivalent physical properties.
proportion high, example: 90%, switching strategy considered
highly efficient.
key efficient use multiple batteries lies design effective policies
management switching load them. concerned situation
load serviced entirely one suite batteries time, charge
battery drains batteries charge levels remain static. problem distinct
problem managing cells within single battery, objective usually keep
charge cells level. Batteries exhibit phenomenon recovery, consequence
chemical properties battery: charge drawn battery, stored charge released
chemical reaction, takes time replenish charge. general, charge drawn
battery faster reaction replenish lead battery appearing
become dead when, fact, still contains stored charge. Therefore, efficient use multiple
batteries achieved exploiting recovery. allowing battery rest, reaction
replenish charge battery become functional again. Thus, efficient use multiple
batteries involves carefully timing use rest periods. Determining timing seen
planning problem.
paper organised follows. begin presenting multiple battery usage problem
detail, describing battery model use.
Section 4 describe approach adopted solving deterministic version
problem, assume know load profile service. provide PDDL +
encoding problem describe planning technique dealing continuity
involved domain. complete section comparing performance plan-based
solutions best policies currently considered multiple battery management.
Section 5 show high quality plans obtained deterministic problems
used learn efficient policy general case load profiles known
advance. describe classification process used evaluate performance
policy servicing stochastic load profiles. Related work discussed Section 6.
Section 7 present details physical experiment, using 6 Volt lead acid batteries,
conducted order confirm simulation results. describe experimental setup
and, interests reproducibility, parameter estimation process followed.
report experimental results discuss significance.
Section 8 outlines plans future work Section 9 concludes paper.

2. Motivations
Many electrically powered systems rely large, heavy batteries supply adequate levels power
current. power requirements devices supplied multiple lightweight
batteries, coordinated supply load would typically supplied much larger
battery, could significantly change way devices used range applications
might suited.
336

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Examples powered systems could benefit distribution battery power include
externally powered electric prosthetics. Prostheses powered electric motors functional attractive body-powered prosthetics, heavy expensive.
power requirements capable prosthetic arm, combining elbow dexterous hand, necessitate large, hence heavy, battery. high torque motors required drive prosthetic elbow
require high voltages current, modern dexterous hands require significantly current
traditional single-motor electric hands.
primitive prosthetic arm could run elbow hand 1 Amp Hour battery,
dexterous hands require batteries much 2 Amp Hour capacities, hand
elbow run battery, even current larger capacities needed
consequent increase weight heat. high power demand requires either multiple
batteries carried batteries frequently recharged replaced. weight externally
powered prostheses common source dissatisfaction amongst users placement
batteries minimise weight effects important part prosthetic design. battery
power distributed around body, power requirements met carefully
coordinated multiple independent batteries power much smaller capacity,
weight issue made less significant user, heat generated batteries also
reduced making comfortable wear.
benefits potentially obtained situation batteries carried order power portable electrical devices. Military personnel currently carry 20kg
batteries field power communication equipment, vision sensing systems
electronic devices. Robotic devices often battery powered rely carrying large numbers batteries maximise operational lifetime. Electric cars typically carry multiple batteries,
although must sometimes used series maximise power availability. creates different constraints way used consider paper. However,
technology develops, opportunities arise exploiting partitioned batteries electric vehicles.
One advantages able distribute battery power across multiple independent
batteries ability swap batteries die, requiring small battery spares
carried instead one large one. hot-swapping capability could important role
play mobile computing devices where, instead recharge battery every 6 hours
so, continuous power longer period could achieved selectively replacing spent cells.
major motivation work done therefore obtain close-to-optimal battery
performance high-powered devices, benefitting ability distribute weight
heat production.

3. Multiple Battery Usage Problem
multiple battery usage planning problem explored several authors, electrical engineering perspective, example work Benini et al. (2003) Rao et al. (2003),
also scheduling perspective (Jongerden, Haverkort, Bohnenkamp, & Katoen, 2009)
optimisation perspective (Wang & Cassandras, 2011) (in latter, simplifying assumption
load shared arbitrarily batteries made). Benini et al. construct accurate
battery model, parameterising capture lithium-ion, cadmium-nickel lead-acid battery types,
show hand constructed policies achieve efficiency, relative single battery,
70% 97.5%. achieve this, policy constructed select new battery whenever
337

fiF OX , L ONG & AGAZZENI

voltage battery currently servicing load drops certain threshold. next battery
selected according one four alternative policies (Benini et al., 2003):
Vmax : select battery pack highest state charge.
Vmin : select battery pack lowest state charge.
Tmax : select battery pack unused longest time.
Tmin : select battery unused shortest time.
authors show Vmax best policies, tested four batteries. general
case n batteries, Vmax referred best-of-n.
Jongerden et al. (2009) uses model checking strategy, based U PPAAL, schedule battery
use given known load profile. approach based use different battery model,
Kinetic Battery Model, discussed detail below. non-linear continuous model
authors treat discretisation scheduling horizon. approach allows
find highly effective schedules, scale well need use finegrained discretisation temporal dimension. worth emphasising, since contrasts
approach, Jongerden et al. work fixed size discretisation time, allowing
focus scheduling resources (batteries) load periods.
deployed systems, standard policies typically static, based rapid switching available batteries. fact, optimal use multiple batteries achieved theoretically
switching extremely high frequency, behaviour converges
single battery (Rao et al., 2003). Unfortunately, theoretical solution achievable practice
losses physical process switching batteries, frequency increases. fact, switching losses MOSFETs approximately linearly dependent switching
frequency also current switched (Eberle, 2008). Tmax Vmax policies applied
fixed frequencies commonly fielded solutions, often achieve less 80%
efficiency (Benini et al., 2003).
3.1 Objectives
paper objective construct policies multiple battery problems, load
modelled probabilistically using known distributions load size, load duration load frequency
(or equivalently, gaps successive loads). primary purpose, constructing
policies, achieve longest possible battery lifetime. best deployed solutions typically
deliver less 80% efficiency, best published solutions deliver less 95%
efficiency (our reading suggests high values simulation rather physical
experiments). show approach, based construction optimising solutions Monte
Carlo sampled problem instances use construction appropriate policies, produces
robust solutions deliver better 99% efficiency simulation. Furthermore, side-effect
way solutions constructed, achieve efficiency lifetime using
smaller numbers battery switches published policies. beneficial side-effect reduces
potential switching losses implementing policy. use Kinetic Battery Model (Manwell
& McGowan, 1993) (KiBaM) basis construction optimising solutions raises
challenges treatment non-linear mixed discrete-continuous optimisation problem,
discuss below.
338

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

3.2 Kinetic Battery Model
Kinetic Battery Model (Manwell & McGowan, 1993; Jongerden et al., 2009) battery
charge distributed two wells: available-charge well bound-charge well (see Figure 1).



Bound
charge

Available
charge
Charge flow

Load draws
charge

Total charge



Figure 1: Kinetic Battery Model
fraction c total charge stored available-charge well, fraction 1 c
bound-charge well. available-charge well supplies electrons directly load (i(t)),
denotes time, whereas bound-charge well supplies electrons available-charge
well. charge flows bound-charge well available-charge well valve
fixed conductance, k. Moreover, rate charge flows wells depends
height difference two wells. heights two wells given by:
h1 =

y1
c

h2 =

y2
1c

y1 available charge y2 bound charge. load applied
battery, available charge reduces, height difference two wells grows.
load removed, charge flows bound-charge well available-charge well
heights equal again. change charge wells given following system
differential equations:
(
dy1
dt = i(t) + k(h2 h1 )
dy2
dt = k(h2 h1 )
initial conditions y1 (0) = c C y2 (0) = (1 c) C, C total battery capacity.
describe discharge process battery, Jongerden et al. (2009), adopt coordinates representing height difference two wells, = h2 h1 , total charge
battery, = y1 + y2 . new setting y1 = c( (1 c)).
change wells given system differential equations
(
i(t)

0
dt = c k

dt = i(t)
solutions
339

fiF OX , L ONG & AGAZZENI

(
k0
(t) = ci 1ek0
(t) = C
k 0 = k/(1 c)c, (0) = 0 (0) = C. condition battery empty
(t) = (1 c)(t).
model less sophisticated used Benini et al. (2001), comparison battery models Jongerden Haverkort (2009) concludes Kinetic Battery Model (KiBaM)
best performance modelling.
3.3 Battery Usage Planning
Although battery load management seen scheduling problem, setting consider
makes planning problem. given load profile service, knew number
switching actions batteries would required, times actions
performed, problem could managed scheduling problem. case,
however, number switching actions cannot identified advance, period load
shared arbitrarily different batteries. Thus, battery load management becomes
planning problem. discretising time shortest time battery must
use, possible construct scheduling problem maximum possible number
battery switches considered, switches might used. difficulty
approach shortest period use short compared battery lifetime:
physical experiments (Section 7), example, maximum number switches would
700, larger capacity batteries smaller loads number switches could easily
several thousand. scheduling approach used Jongergen et al. (2009) cannot scale manage
tens intervals.
Furthermore, KiBaM, deterministic non-linear continuous model battery performance, lends itself, principle, use optimisation problem solver find best
battery usage plan, given load profile. multiple battery usage problem, deterministic
form, clearly optimisation problem Wang Cassandras (2011) shown that,
certain assumptions, tackled analytically (despite non-linear), using KiBaM.
order assume load split arbitrarily batteries (which easily
achievable practice). also assume load serviced arbitrary schedule
within given timespan, provided total charge drawn batteries meets required
workload. second assumption consistent situation, load must
serviced according demands placed user specific times, without flexibility. Unfortunately,
analysis cannot modified deal situation consider.
interest speculate whether standard Operations Research approach, using
form Mixed-Integer Linear Program (MILP) model, might used solve deterministic
multiple battery usage problem. first glance answer trivial: since model non-linear,
clear MILP cannot used. sophisticated approach might considered, using
approximation exponential recovery curves using piece-wise linear components. However,
precise shape recovery curves depends state charge battery
start period recovery (both available bound parts), approximations must
either built dynamically, else model must anticipate possible states charge
times points, effectively building entire search space states charge battery
340

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

model. former approach cannot achieved standard MILP aware
solving technology could manage approach; latter approach obviously impractical
anything trivial situations.
real battery usage problems load profile generated external processes, typically
controlled directly indirectly user demands. demands often modelled probabilistically, reflecting typical patterns use. work assume profiles drawn
known distribution. consequence planning problem ceases deterministic
optimisation problem, probabilistic problem plan must policy, discussed
Section 5.
3.4 Approach
adopt approach based combination two ideas. Firstly, sample distribution
loads arrive deterministic problem, solve using continuous KiBaM
battery model. leads interesting continuous non-linear optimisation problem,
solve using discretise-and-validate approach. Currently using UPMurphi (Della Penna,
Intrigila, Magazzeni, & Mercorio, 2009) solve deterministic instances but, discretisation,
metric temporal planner could used principle. Secondly, use decision tree classifier
combine solutions sample problem instances learn policy MDP
problems drawn. classification process maps states actions produces policy
form decision tree.
approach domain-specific respects:
discretisation scheme, based general principles, selected problem
domain load distribution.
use search heuristic that, restricted battery problem alone, suited
problems.
aggregation solutions policy makes use entirely general approach,
extent approach yields good policies depend nature problem
space applied.
make use existing tools far possible, simplify construction solution.

4. Solving Deterministic Multiple Battery Problems
section consider multiple battery management problem optimisation problem,
faced known deterministic load profile.
4.1 PDDL + Battery Model
P DDL + (Fox & Long, 2006) extension standard planning domain modelling language,
PDDL , capture continuous processes events. dynamics KiBaM captured
easily PDDL +. Figure 2 show two processes, consume recover, govern
behaviour batteries event triggered attempting load battery available
charge exhausted. addition, durative action variable duration allows
planner use battery interval (see Figure 3). two processes active whenever
341

fiF OX , L ONG & AGAZZENI

preconditions satisfied, meaning usually execute concurrently. Together, model
draining charge recovery described differential equation d/dt.
event triggered ever positive load active service.
(:process consume
:parameters (?b - battery)
:precondition (switchedOn ?b)
:effect (and (decrease (gamma ?b) (* #t (load)))
(increase (delta ?b) (* #t (/ (load) (cParam ?b)))))
)
(:process recover
:parameters (?b - battery)
:precondition (>= (delta ?b) 0)
:effect (and (decrease (delta ?b) (* #t (* (kprime ?b) (delta ?b)))))
)
(:event batteryDead
:parameters (?b - battery)
:precondition (and (switchedOn ?b)
(<= (gamma ?b) (* (-1 (cParam ?b)) (delta ?b))))
:effect (and (not (switchedOn ?b)) (dead ?b))
)

Figure 2: Part PDDL + encoding KiBaM dynamics
(:durative-action use
:parameters (?b - battery)
:duration (>= ?duration 0)
:condition (and (at start (switchedOff ?b))
(over (switchedOn ?b)))
:effect (and (at start (and (switchedOn ?b) (not (switchedOff ?b))
(increase (services) 1)))
(at end (and (switchedOff ?b) (not (switchedOn ?b))
(decrease (services) 1))))
)

Figure 3: P DDL + durative action battery use
load profile serviced encoded PDDL + problem use timed initial
literals, allow expression exogenous events corresponding, case, changes
load value. fragment problem (which also contains battery specification) shown
Figure 4.
use PDDL + modelling language grants several benefits. Firstly, allows us use
VAL (Howey, Long, & Fox, 2004) validate solutions analytically continuous model,
allowing us confirm discretisation use construction solutions compromise correctness plan. Secondly, provides us semantics model terms
342

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

(define (problem 2B) (:domain kibam)
(:objects b1 b2 - battery)
(:init
(= (cParam b1) 0.166)
(= (kprime b1) 0.122)
(= (gamma b1) 5.5)
(= (delta b1) 0)
...
(at 0 (= (load) 0.25))
(at 1.00 (= (load) 0.50))
(at 2.00 (= (load) 0.25))
(at 3.00 (= (load) 0.50))
(at 4.00 (= (load) 0.25))
...

Figure 4: Fragment PDDL + problem
timed hybrid automaton described Fox Long (2006). Finally, make use existing tools construct search spaces defined PDDL + models, UPMurphi (Della
Penna et al., 2009).
paper PDDL +, Fox Long (2006) propose semantics based mapping
timed hybrid automata (Alur & Dill, 1994). semantics domain instantiated two
batteries given three hybrid automata shown Figure 5, variables d, g, L
refer PDDL + functions delta, gamma, load services, respectively. semantics
one route model-checking systems designed manage timed hybrid automata
adapted operate directly battery problem. batteries reveal non-linear behaviour
definitions expressions governing rates change d1 d2 pair
states switchedOnB1 switchedOffB1 equivalent pair B2. Unfortunately,
equations beyond reach current model-checking systems, discretising
ranges variables functions managed UPMurphi.
variable time-slip variable introduced Fox Long (2006) allows
correct modelling PDDL + domains events standard hybrid automata. particular,
time-slip variable increases rate 1 whenever preconditions events disaster (positive
load battery used) notOptimal (a battery used without load service)
satisfied. state three hybrid automata invariant condition stating
time-slip variable must 0, guarantees events applied soon
preconditions become true, without action transitions occurring between.
4.2 Discretise-and-Validate Approach
technique based discretise-and-validate approach (see Figure 6), continuous
dynamics problem relaxed discretised model, discrete time steps corresponding step functions resource values used place original continuous dynamics.
relaxed problem solved using forward reachability analysis solutions validated
continuous model using validator, VAL (Howey et al., 2004), provides analytic
solutions differential equations involved models.
343

fiF OX , L ONG & AGAZZENI

batteryDeadB1
Inv: T=0
Flow:
d1 = 0 g1 = 0

Jump: g1 (1-c)d1
d1 = d1
g1 = g1
= - 1

T= 0 V = 1
deadB1

useB1stop
Inv: T=0
Flow:
d1 = L/c - kd1
g1 = -L
T= 0 V = 1
switchedOnB1

Jump: d1 = d1
g1 = g1
= - 1

useB1start

T= 0 V = 1

Inv: T=0
Flow:
L > 0 /\ = 0
T=1
L = 0 /\ > 0
T=1
T= 0 V = 1

switchedOffB1

loadProfile

Inv: T=0
Flow:
d1 = -kd1

Jump: d1 = d1
g1 = g1
= + 1
batteryDeadB2
Inv: T=0
Flow:
d2 = 0

g2 = 0

T= 0 V = 1
deadB2

Jump: g2 (1-c)d2
d2 = d2
g2 = g2
= - 1

disaster

notOptimal

Jump: L > 0
s=0

Jump: L = 0
s>0

useB2stop
Inv: T=0
Flow:
d2 = L/c - kd2
g2 = -L
T= 0 V = 1
switchedOnB2

Jump: d2 = d2
g2 = g2
= - 1

Inv: T=0
Flow:

Inv: T=0
Flow:
d2 = -kd2
T= 0 V = 1

useB2start

T= 0 V = 1
notSatisfactory
service

switchedOffB2

Jump:

Figure 5: Hybrid automata modelling two kinetic batteries scheduling

Continuous Model

Discretise

Solve

Validate

Figure 6: Discretise Validate Approach

validation process used identify whether finer discretisation required guide
remodelling relaxed problem. example, simulation, first considered time
discretisation = 0.1, obtained plan shown Figure 7 (left). However, validated
discrete solution generated planner continuous model, found
solution indeed valid, highlighted following fragment VAL report:

Checking
Updating
Updating
Updating

next happening (time 5.08986)
(gamma b1) (0.502404) 0.337447 assignment
(delta b1) (0.328362) 0.550475 assignment
(delta b2) (0.405504) 0.257052 assignment

EVENT triggered (time 5.08986)
Triggered event (batterydead b1)
Deleting (switchedon b1)
Adding (dead b1)
Invariant (use b1) condition unsatisfied
time 5.08986 5.1.
344

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

0.0:
3.40:
3.90:
4.00:
4.50:
5.10:
5.30:
5.60:
5.80:
6.10:
6.80:
7.00:
8.30:
8.50:
8.70:

(use b1)
[3.40]
(use b2)
[0.50]
(use b1)
[0.10]
(use b2)
[0.50]
(use b1)
[0.60]
(use b2)
[0.20]
(use b1)
[0.30]
(use b2)
[0.20]
(use b1)
[0.30]
(use b2)
[0.70]
(use b1)
[0.20]
(use b2)
[1.30]
(use b1)
[0.20]
(use b2)
[0.20]
(satisfied)

0.0:
3.40:
3.90:
4.00:
4.50:
5.08:
5.35:
5.43:
6.10:
6.15:
6.55:
6.60:
7.10:
7.15:
8.15:
8.45:
8.65:
8.70:

(use b1) [3.40]
(use b2) [0.50]
(use b1) [0.10]
(use b2) [0.50]
(use b1) [0.58]
(use b2) [0.27]
(use b1) [0.08]
(use b2) [0.57]
(use b1) [0.05]
(use b2) [0.40]
(use b1) [0.05]
(use b2) [0.50]
(use b1) [0.05]
(use b2) [1.00]
(use b1) [0.30]
(use b2) [0.20]
(use b1) [0.05]
(satisfied)

Figure 7: Plans generated using different time discretisations: = 0.1 (left) = 0.01 (right)
precise analysis provided VAL allows us know exact value charge
(simulated) batteries execution plan. example, charge battery 1
terminates 0.01014 time units time expected discretised model. suggests
refinement discretisation, setting = 0.01, eventually produced valid plan, shown
Figure 7 (right). seen, finer discretisation handles sensitive interactions
system switches battery 2 charge battery 1 almost fully drained (at time point 5.08).
Although Jongerden et al. (2009) also use discretisation approach, fix granularity
time-step advance. contrast, use variable sized discretisation, allowing range
alternative step sizes considered search.
introduce formal statement deterministic version problem
interested in. hybrid system system whose state description involves continuous well
discrete variables. approximate system discretising continuous components
state (which assume bounded) dynamic behaviours obtaining finite number
states.
Definition 1 (Finite State Temporal System) Finite State Temporal System (FSTS) 5tuple (S,s0 ,A,D,F ), where: finite set states, s0 initial state, finite set
actions, finite set durations F : transition function, i.e.
F (s, a, d) = s0 iff system reach state s0 state via action duration d.
state S, also define set EnAct(s)= {a A|d : F (s, a, d) S}, set
actions enabled state s.
FSTS, state assumed contain special temporal variable denoting time
elapsed current path initial state s. following use notation t(s)
value variable state s. si , sj F (si , a, d) = sj , t(sj ) = t(si ) + d.
345

fiF OX , L ONG & AGAZZENI

Definition 2 (Trajectory) trajectory FSTS = (S, s0 , A, D, F ) sequence =
s0 a0 d0 s1 a1 d1 s2 a2 d2 . . . sn where, 0, si state, ai action, di
duration F (si , ai , di ) = si+1 . trajectory, write (i), (i) (i) denote
state si , action ai duration di , respectively. Finally, denote || length ,
P||1
given number actions trajectory, duration , i.e. = i=0 (i).
order define planning problem system, assume set goal states
G specified. Moreover, finite state system, fix finite temporal horizon,
T, require plan reach goal within time . case battery usage planning
problem, horizon important represents target duration service
provided battery. fact, good upper bound found battery problem,
discussed section 4.3.
Definition 3 (Planning Problem FSTS) Let = (S, s0 , A, D, F ) FSTS. Then, planning
problem (PP) triple P = (S, G, ) G set goal states finite
temporal horizon. solution P trajectory s.t.: | | = n, , (0) = s0
(n) G.
constraints add temporal planning problem parameterised iteratively relaxed order explore successively larger spaces plans. use finite collection
possible durations segments processes (Definition 2). set refined addition smaller durations successive searches fail find solution. Allowing different durations
within search enables planner construct states interact executing processes
different time points, stepping quickly along timeline interesting
features.
4.3 Monotonicity Property Planning
battery domain important property supports simple heuristic evaluation function
states: charge battery monotonically decreases time optimal solution
one gives longest possible plan. upper bound duration solution
found using observation optimal duration cannot exceed single battery
combined capacity equal sum capacities multiple batteries (assuming
discharging flow behaviours). horizon, construct search discretised
search space. make approach practical, essential informed heuristic
search space. domain, duration plan current state plus total remaining
charge admissible, completely uninformative, duration plus total available charge
highly informative. also equivalent minimising total bound charge.
heuristic suitable class domains: domain monotonically
decreasing resource, longest plan required (such satellite domain finite
amount resources), heuristic sums plan duration available resource informative.
use variant best-first search (Algorithm 1) efficiently explore reachable
space. use variable discretisation efficiently, break symmetry structure search
space arises possible orderings different length action instances. Redundancy
eliminated disallowing use long duration actions immediately following shorter duration
versions actions. Long duration actions used event action
346

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

intervened since last short action family. also disallow repeated consecutive use
short duration actions beyond accumulated duration next longer duration action.
longest duration action repeated arbitrarily often.
Algorithm 1 Dynamic State Space Search (P)
Input: planning problem P = ((S, s0 , A, D, F ), G, )
Output: valid plan
1: Q (s0 , null, 0);
2: H s0 ;
3: s0 G return ;
4: Q 6=
5:
(sh , ai , dk ) argmax(s,a,d)Q h(s);
6:
aj EnAct(sh )
7:
aj 6= ai {dl D|t(sh ) + dl };
8:
else {dl D|dl dk t(sh ) + dl };
9:
dl
10:
s0 F (sh , aj , dl );
11:
s0 G return ;
12:
s0
/ H
13:
Q Q (s0 , aj , dl );
14:
H H s0 ;

4.4 Plan Search Variable Discretisation
illustrate way range differently sized duration intervals lead
significant benefits size set visited nodes search space, compared using
fixed duration increment.
Consider load profile shown top Figure 8. planning problem two batteries
defined according definitions 1 3, G = {s S|t(s) = 2.42}, i.e. goal service
whole load profile. temporal horizon set duration profile well.
definition FSTS straightforward: set actions = {useB1, useB2, wait}
former actions refer battery used latter one applicable
active service. set durations use example = {0.01, 0.4, 0.5, 1.0} (measured
minutes). practice, define set durations start minimum value
add exponentially increasing values maximum duration given longest interval
different events (i.e., load variations). particular, smallest duration included
order handle sensitive interactions.
initial state s0 load active service batteries limited
initial capacity. setting, plan search variable discretisation proceeds follows:
1. battery used period 1 minute (when load idle). corresponding transition shown Figure 8.
2. one minute load applied battery 1 used. corresponds transition
< s1 , useB1, 1.0, s2 >. However, sake simplicity, let us assume that, due
347

fiF OX , L ONG & AGAZZENI

Figure 8: Example search using variable discretisation
limited capacity, batteries cannot used continuously 1 minute. transition thus
valid shorter duration considered.
3. Battery 1 used 0.5 minute. Then, since load still applied, second battery used.
before, transition < s2 , useB2, 1.0, s3 > considered, case
would active service load.
4. Battery 2 used 0.5 minute. next period load applied, battery used.
transition < s3 , wait, 0.5, s4 > considered, would lead positive load
active service, duration action wait reduced 0.4.
5. service last load period 0.02 minute, battery 1 could used. However,
sample instance let us assume remaining charge battery 1 allows service
0.01 minute. So, finally, battery 2 used end load profile.
validity transition dynamically checked search since invalid transitions
trigger specific events (e.g. event batteryDead triggered step 2 event disaster
triggered step 4) which, turn, violates invariant conditions corresponding actions (a
battery must die use). Moreover, variable discretisation 6 states
visited order reach goal, using uniform discretisation necessary explore
least 242 states since finest discretisation 0.01 must used order correctly handle
interactions steps 5 6.
benefit use differently sized durations discretisation favouring
longer durations reduces number switches solutions generate, leading solutions
better practical terms based high frequency switching batteries,
shown subsequent results.
348

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

4.5 Performance Deterministic Load Problems
present first set experimental results show, simulation, performance
solver deterministic battery usage optimisation problem. use case study proposed Jongerden et al. (2009), two types jobs considered, low current job (250
mA) high current job (500 mA), according following load profiles:
continuous loads: one load low current jobs (CL 250), one high current
jobs (CL 500) one alternating low current job high current job (CL alt);
intermittent loads short idle periods one minute jobs: one
low current jobs (ILs 250), one high current jobs (ILs 500), one alternating
low current job high current job (ILs alt);
intermittent loads long idle periods two minutes jobs: one low
current jobs (ILl 250) one high current jobs (ILl 500).
first step, used load profiles validate variable-range discretisation KiBaM
model (planning-KiBaM), find appropriate discretisation continuous variables
involved system dynamics (i.e. variables process durations). used
VAL validate solutions discretised model continuous model. work
Jongerden et al. (2009), considered two battery types, one capacity 5.5 Amin (B1 ) one
capacity 11 Amin (B2 ). small batteries, typical capacities small
portable devices PDAs mobile phones. battery types parameters:
c = 0.166 k 0 = 0.122min1 . discretised , rounding 0.00001, and,
load profiles battery types, obtained lifetimes computed
original KiBaM validated Jongerden Haverkort (2008).
generate scheduling plans multiple batteries, used approach described sections 4.2 4.3 set durations = {0.01, 0.02, 0.05, 0.1, 0.25, 0.5, 1.0}.
example PDDL + plan shown Figure 9, row < ti , ai , di > contains
time point ti action ai (whose duration di ) applied.
0.0:
1.20:
1.30:
1.80:
2.40:
2.50:
3.10:
4.60:
4.70:
6.20:

(use
(use
(use
(use
(use
(use
(use
(use
(use
(use

b1)
b1)
b2)
b1)
b1)
b2)
b1)
b1)
b2)
b1)

[1.00]
[0.10]
[0.10]
[0.20]
[0.10]
[0.10]
[1.00]
[0.10]
[0.10]
[0.30]

Figure 9: Fragment PDDL+ plan
Figure 10 shows fragment corresponding VAL report. Note VAL provides analytic
solutions differential equations involved KiBaM dynamics.
evaluate efficiency approach, compared solutions obtained using
U PPAAL-based approach. resulting lifetimes shown Table 1 upper bound
349

fiF OX , L ONG & AGAZZENI

Figure 10: Fragment VAL report

column shows theoretical upper bound given best-of-two policy extremely highfrequency switching. seen, first two rows table, power
extracted battery nominal capacity 5.5 Amin 12.16 min 250 mA,
3.04 Amin, loading continuously 250 mA, 4.59 500 2.3 Amin
drawing continuous load 500 mA. gives indication extent limit
conversion bound charge available charge affects performance batteries.
load
profile

Upper bound
lifetime
B1
B2

U PPAAL-KiBaM
lifetime
B1
B2

CL 250
CL 500
CL alt
ILs 250
ILs 500
ILs alt
ILl 250
ILl 500

12.16
4.59
7.03
44.79
10.82
16.95
84.91
21.86

12.04
4.58
6.48
40.80
10.48
16.91
78.96
18.68

46.92
12.16
21.26
132.8
44.79
72.75
216.9
84.91

N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A

Planning-KiBaM
lifetime (visited states)
B1
B2
12.14 (194)
4.59 (116)
7.03 (136 )
44.76 (552)
10.8 (131)
16.92 (159)
84.88 (488)
21.85 (173)

46.91 (691)
12.14 (194)
21.2 (350)
132.7 (1068)
44.76 (552)
72.55 (599)
216.8 (1123)
84.88 (488)

Table 1: System lifetime (in minutes) load profiles according different battery usages
350

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

load profiles considered observe approach outperforms U PPAAL-based
one significantly, providing solutions achieve 99% efficiency compared
theoretical limit. key points described preceding parts section allow resulting
search efficiently prune state space quickly find solutions. particular, using
variable discretisation possible consider much finer discretisation variables
used work Jongerden et al. (2009) handle sensitive interactions.
crucial, particularly available charge batteries almost exhausted. Jongerden et
al. (2009) describe plans optimal, important note respect
discretisation use; finer-grained discretisation offers opportunity higher
quality solution found cost much larger state space. Despite large state
space model creates, solver visits small collection states (as shown table).
problems solved less second.
dealing larger batteries type B2 , state space becomes large exhaustive approach infeasible. Indeed, works Jongerden et al. (2009, 2008), authors
able handle second case. also found high quality solutions batteries type B2 :
example shown Figure 11 compared standard best-of-two solution, showing
huge improvement obtain policy. Note slicing load periods occurs
towards end plan, phenomenon observed plans.
also considered 8 battery system (an example behaviour shown Figure 14).
Benini et al. (2003) indicate designers SMBus (SBS Implementers Forum, 2000)
architecture, communication control architecture protocol used
development Smart Batteries, suggest might good reasons partition
charge among four batteries. fact, examples systems using
four batteries, HP 6-cell lithium-ion Smart Battery packs. practice, partitioning charge
batteries offers multiple benefits, including opportunities use industry standard cells
exploit different distributions weight possible cooling requirements. tradeoffs
benefits potential loss efficiency arising partitioning complex.
batteries used, larger state space planning policy
learning; constructing solution 8 battery problem significantly harder 4 battery
problem, present results evidence scale larger systems, subsuming
smaller cases.
results reported Table 2, show scale effectively much larger problems. Notice number switches use produce results significantly smaller
best-of-8 policy giving theoretical upper bound, however resulting solutions achieve
99% efficiency. final column, labelled Plan-based Policy, shows performance
policies discuss next section, applied load profiles. generate slightly
worse performance switches, maintain lifetime performance.
One final observation worth noting structure usage profile across batteries
leads, two-battery case, one battery discharged sooner other. 8-battery
case effect pronounced, several batteries discharged others still
significant charge remaining. interesting consequence: using policy becomes
possible hot-swap batteries, replacing used batteries new ones, system active.
fact one batteries still hold charge allows loads serviced used
batteries exchanged charged ones policy adapt new states charge
351

fiF OX , L ONG & AGAZZENI

12
total charge battery 1
total charge battery 2
available charge battery 1
available charge battery 2
battery schedule

10

charge (Ahr)

8

6

4

2

0
0

1000

2000

3000
4000
time (0.01 min)

5000

6000

7000

(a) Vmax (based feasible frequency switching used (Jongerden et
al. 2009))
12
total charge battery 1
total charge battery 2
available charge battery 1
available charge battery 2
battery schedule

10

charge (Ahr)

8

6

4

2

0
0

1000

2000

3000

4000

5000

6000

7000

time (0.01 min)

(b) Plan

Figure 11: ILs alt load test two batteries type B2
batteries used ones replaced. marked contrast high-frequency
switching policies, batteries discharge approximately time.

5. Plans Policies
shown generate high quality plans deterministic multiple battery management
problems, turn attention stochastic problem really interested solving.
general, cannot know advance load profile applied batteries,
352

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

load
profile
CL 250
CL 500
CL alt
ILs 250
ILs 500
ILs alt
ILl 250
ILl 500

8 batteries B2
lifetime (number switches)
Upper bound
Plan
Plan-based Policy
310.6 (31072)
134.7 (13472)
192.8 (19280)
660.7 (33076)
308.7 (15476)
424.8 (21280)
1008.9 (33692)
480.9 (16090)

307.6 (485)
133.4 (266)
190.8 (355)
654.1 (495)
305.7 (293)
420.6 (357)
998.8 (471)
476.1 (295)

307.6 (992)
133.4 (571)
190.8 (806)
654.1 (904)
305.7 (513)
420.6 (614)
998.8 (822)
476.1 (597)

Table 2: System lifetime (in minutes) load profiles serviced 8 batteries
assume probability distribution characterising typical use batteries available.
probabilistic problem cast hybrid temporal Markov Decision Process (MDP).
Formally, MDP defined follows:
Definition 4 Markov Decision Process 4-tuple, (S, A, P, R), set states,
finite set actions, P probability function Pa (s, s0 ) = P r(st+1 = s0 |st = s, = a)
probability action cause transition state s0 applied
time t, R reward function, Ra (s, s0 ) reward earned making transition
state s0 action a.
Markov property probability distribution transition state
affected path state reached. general, MDPs defined finite
state spaces, continuous MDP also considered, states embedded
multidimensional real space. battery usage problem seen continuous MDP,
states tuples define (continuous) state parameters batteries also
current state load battery servicing load (if load non-zero). Actions
problem indicate battery service load, also correspond events
change current load. battery problem actions switching batteries
deterministic, events cause load changes probabilistic, representing uncertainty
demands user powered system. time events also governed
stochastic process, timing switching actions controllable.
formally, problem n batteries, state characterised tuple
(sb1 , sa1 , sb2 , sa2 , ..., sbn , san , B, t, L), sbi bound charge battery i, sai available charge battery i, B number battery currently servicing load (1 B n),
time state L current load. state deterministic action, Use
B 0 , causes transition state (sb1 , sa1 , sb2 , sa2 , ..., sbn , san , B 0 , t, L), battery
B 0 battery servicing load. also non-deterministic action, wait(T), time
interval, causes transition state time advanced time t0 + , state
charge battery B updated according battery model load might different
(according probability distribution governing loads). interpretation action
353

fiF OX , L ONG & AGAZZENI

advances time next event, battery depleted available charge,
load changes, time passed, whichever first.
reward function battery problem gives positive reward transition, proportional advance variable t. system enters state currently active
battery available charge, terminates (or, equivalently, enters special final state
transitions loop without incrementing t). reward system means optimal
solution one greatest duration.
solution MDP policy:
Definition 5 policy, , MDP (S, A, P, R), mapping : A, specifying action
execute state.
battery problem, policy function determines battery use
load must serviced, using current states charge available batteries basis
making decision.
Considerable research effort invested problem finding policies MDPs,
discussed Section 6.
way approach problem see mapping classification, state
batteries mapped class corresponding correct choice battery. use
solutions determinised problems basis classifier construction problem use
existing machine learning approach build good classifier. overall approach sketched
Figure 12.
Several important observations made. Firstly, successful construction classifier
depends exploitable structure space defined solutions determinised
problems. Secondly, states described continuous variables: discretise
purpose building classifier. Thirdly, solution set generally cover whole space
reachable states, important complete policy sensible default action
deal states policy fails handle. case, default action best-of-n rule,
best published hand-constructed policies problem. policy suggests
switch battery whose available charge critical threshold, policy action
ignored, default action used. discuss impact physical experiments
Section 7.
Finally, note deployment constructed policies require efficiently implemented cheap hardware. Simple classifier rule systems effectively
implemented look-up tables, ideal implementation Field Programmable Gate
Arrays (FPGAs) purpose-built hardware.
5.1 Policy Learning Classification
learn policy classification, first necessary generate appropriate training data
set. problem, data set must associate states batteries current load
appropriate decision (which battery use service load). construct training
set building sample profiles stochastic description expected loads.
distributions used describe amplitude, duration frequency loads shown Figure 13.
deterministic solutions problems constructed described Section 4. Training
data generated plans simulating execution recording battery
354

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Figure 12: Plan-based policy learning: figure illustrates approach policy learning
schematically. off-line training phase involves construction set planning
problem instances sampling initial state distribution, followed construction plans instance. plans classified obtain state-to-action
mapping form decision tree used policy.

states, load battery choice fixed time increment throughout plan. example,
increment 0.01 minutes training data generated plan record battery states
charge (available bound), load currently selected battery (which might might
changed previous time increment) every 0.01 minute interval throughout plan.
experiments selected time increment smallest increment used
variable discretisation described Section 4.4, requirement approach.
choice time increment determines frequency decision-cycle learned policy.
time increment also determines much training data generated single plan, according
makespan plan. order reduce volume training data fine-grained time
increments used long makespan batteries, possible randomly sample set
state-battery-selection pairs across multiple plans. experiments need this.
training data generated, classifier learned using standard machine learning
approach. W EKA (Hall, Frank, Holmes, Pfahringer, Reutemann, & Witten, 2009) machine
learning framework, developed University Waikato, provides set classification
clustering algorithms data-mining tasks. W EKA takes input training set, comprising list
instances sharing set attributes. order perform classification battery usage
problem data, consider instances following form:
= (1 , 1 , . . . , N , N , B, L)
355

fiF OX , L ONG & AGAZZENI

denote available charge total charge ith battery, respectively, B
currently active battery L current load (this essentially state MDP
without time label, since want policy operate independently time). setting,
attribute used class battery B.
stochastic load profiles defined distribution of:
load amplitude l [100 . . . 750] mA;
load/idle period duration [0.1 . . . 5] min;
load frequency f [0.3 . . . 0.7].
probability distributions shown Figure 13.
P(l)

P(d)

P(f)

0.40

0.40

0.35
250

0.5

500

0.5
0.20

0.15
100

750

0.15
0.10
0.05

0.2
0.1

load amplitude l (mA)

0.25

1.0

0.10

0.6

0.4

2.5

0.3

5.0
load/idle period duration (min)

0.7
load frequency f

Figure 13: Probability distributions stochastic load profiles
10
battery schedule
load

load amplitude / battery use

8

6

4

2

0
0

5000

10000
15000
time (0.01 min)

20000

25000

Figure 14: Plan-based policy 8 batteries stochastic load
leads load profiles irregular (see bottom Figure 14) therefore
harder handle regular profiles considered Jongerden et al. generated
set stochastic load profiles produced near-optimal plan using
deterministic solving described Section 4. set plans used training set
classification process.
356

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Algorithm
DMNBtext
NaiveBayes
NaiveBayesSimple
NaiveBayesUpdateable
Logistic
MultilayerPerceptron
RBFNetwork
SimpleLogistic
SMO
IB1
IBk
AdaBoostM1
AttributeSelectedClassifier
Bagging
Clustering
Regression
CVParameterSelection
Dagging
Decorate
END
EnsembleSelection
Grading
LogitBooost
RandomCommittee
RandomSubSpace
RotationForest
Stacking
Vote
VFI
DecisionTable
DTNB
DecisionStump
J48
J48graft
OneR
LADTree
NBTree
SimpleCart

cross-validation success
18%
37%
36%
36%
44%
51%
43%
44%
44%
99%
99%
27%
98%
98%
26%
98%
19%
44%
99%
99%
99%
19%
47%
99%
99%
99%
19%
19%
23%
90%
90%
27%
99%
99%
56%
45%
99%
99%

model size









26 Mb
26 Mb

29 Mb
18 Mb

9 Mb


31 Mb
15 Mb
70 Mb


12 Mb
21 Mb
22 Mb



6 Mb
6 Mb

2 Mb
13 Mb


114 Mb
86 Mb

Table 3: Performance classification algorithms tested 10,000 training examples

357

fiF OX , L ONG & AGAZZENI

order select suitable classification algorithm, applied classifiers provided WEKA data set 10,000 training examples. first evaluated performance
number correctly classified instances cross-validation. discarded classifiers
providing less 70% correctness. considered memory time required use
classifier. output classification process model encoding resulting decision
tree. cases, generated model requires significant memory store (more 500Mb
RAM memory), slow used. parameters also used determine
number training examples classify, bigger training set, better performance
higher memory time requirements. classifiers performance
reported Table 3.
...
if(b2gamma<=0.297404){
if(b2gamma<=0.296404){
if(b2gamma<=0.288404){
if(b2gamma<=0.286404){
if(b2gamma<=0.277404){
return 1;
}
if(b2gamma>0.277404){
return 2;
}
}
if(b2gamma>0.286404){
return 1;
}
}
if(b2gamma>0.288404){
return 2;
}
}
if(b2gamma>0.296404){
if(b2y1<=-0.043615){
return 1;
}
if(b2y1>-0.043615){
if(b1gamma<=0.164404){
return 1;
}
if(b1gamma>0.164404){
return 2;
}
}
...

Figure 15: Fragment decision tree
According criteria, selected J48 classifier, implements machine learning algorithm C4.5 (Quinlan, 1993). output decision tree whose leaves represent, case
358

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

load
profile
R100
R250
R500
R750

Upper bound
time()
sw()
792.6(15.5)
369.8(1.91)
226.7(2.13)
188.3(0.8)

71383(1379)
28952(853)
14671(512)
11519(463)

Plan-based Policy
time()
sw()
786.2(15.4)
366.7(2.02)
224.6(2.27)
186.4(0.7)

1667(161)
1518(143)
987(122)
302(33)

Table 4: Average system lifetime number switches stochastic load profiles 8 battery
systems
study, battery used (a fragment tree shown Figure 15). cardinality
training set, empirical evaluation showed best result obtained using 250,000 training
examples (note involves considering 4 106 real values characterising states
battery selections training examples) since extending training set make
significant improvement performance increases memory time requirements.
5.2 Results Policies
order use decision tree embedded WEKA classes loading classification model
battery simulation framework. model 8 battery case represented tree
61 levels consists 7645 nodes, one containing comparison one state
variables threshold. Applying decision tree determine battery load
decision point takes negligible time.
evaluate performance policy considered four probability distributions
different average value load amplitude, namely 100, 250, 500, 750 mA. distribution
generated 100 stochastic load profiles used policy service them. Note load
profiles used evaluating policy independent ones used training, although
drawn probability distributions.
Table 4 shows average value standard deviation system lifetime number
switches obtained using best-of-8 policy high frequency switching policy.
Also case, observe policy achieves 99% efficiency compared
theoretical upper bound given best-of-8 policy executed high frequency (recall
infeasible practice). Moreover, number switches used policy slightly
greater corresponding deterministic solving, one order magnitude lower
corresponding value best-of-n policy.

6. Related Work
variety approaches proposed solving continuous Markov Decision Processes (Sanner & Boutilier, 2009). Meuleau et al. (2009) propose hybrid AO* search, using dynamic programming approach guide heuristic search problems involving continuous resources
used stochastic actions. approach handle time-dependent resource consumption,
appears MDP could modelled solution approach. authors give
empirical data solution problems 25,000 states. model, appropriate
359

fiF OX , L ONG & AGAZZENI

discretisation, contains 1086 states 8 batteries. Mausam Weld (2008) describe
planner concurrent MDPs, MDPs temporal uncertainty. Again, problems
similar ours, although planner manage continuous time-dependent resources,
directly applicable problem. Furthermore, largest problems consider contain
4,000,000 states take hour solve.
solving large MDPs, researchers identified variety techniques help
overcome prohibitive cost policy iteration value iteration, classical techniques
solving MDPs. general, techniques approximate solution, often focussing parts
policy apply states likely visited along trajectory. Relevant techniques
discussed work Bertsekas Tsitsiklis (1996).
approach branch work devoted development plan-based reasoning
uncertainty. fact, explicit modelling uncertainty impractical, sampling provide
effective alternative.
Hindsight Optimisation (HO) (Chang, Givan, & Chong, 2000; Fern, Yoon, & Givan, 2006)
become well-researched technique learning policies based plans. policy always
proposes best action next state, therefore less robust uncertainty
encountered reality. HO technique works follows: given MDP state, s, first
step sample, MDP, large number deterministic instances process
initial state s. next step solve instances using deterministic planner fixed
horizon. Finally, estimated value state computed average value obtained
deterministic plans. possible choose, state, move led best
performance average samples.
Although approach similar Hindsight Optimisation, significant differences.
First, previous works direction addressed propositional domains (see, e.g.
work Fern, Yoon Givan (2004, 2006, 2007), Konigsbuch, Kuter Infantes, 2010)
interested hybrid discrete-continuous problem, deal non-linear
continuous deterministic planning models drain recovery behaviour batteries, using
sampling provide noise encountered reality. approach sample deterministic
instances problem using simple assumptions underlying distributions governing
physical reality. many natural situations, Gaussian distributions work well approximation
uncertainty problem. work, example, show sampling many
deterministic discretised cases, planning solutions exactly, possible
classify states solution plans policy robustly manage load distribution
simulated real battery configurations. weaknesses assumptions made
underlying distributions overcome introducing default actions (described Section 5),
applied policy finds state outside range applicability
policy. Integrating policy default action leads competent policies perform
well across wide range physical situations, including situations dissimilar
encountered learning phase.
Another important difference rather averaging plan states obtain policy,
approach use decision tree classifier arrange states according information
content (reflected well support partitioning planned actions). results
classification actions states, policy proposes best action use state
determined online comparing policy state variables real values encountered policy
executed. Although training policy-learning expensive terms time computational
360

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

resources, planning learning done offline, offline process strongly resourcebounded. classification phase produces policy form decision tree, compact
execution takes negligible time key feature application. fact,
due continuity involved battery model, need planning long horizon
(up 60,000 time steps), resulting state space huge. makes approach based
explicit mapping state action impractical. particular, possible compute
HO-based policy offline map state best action according policy values.
hand, using HO online (which viable many cases) infeasible application,
nature battery scheduling problem requires fast interaction policy
battery system. approach meets scalability fast-response requirements.
Finally, idea looking ahead scenarios, benefiting experience gained, powerful. HO assumed that, general, experience deterministic
planner sufficient give insights best moves possible real state encountered
execution. However, another important aspect makes approach different, investigated deeply different context (Fox, Long, & Magazzeni, 2012), that, many cases,
necessary distinguish plan state policy state. example, plan
state might contain variable representing whether unreliable valve open closed, observable experience records effects unreliability example, effect flow-rate
pipe given time period. policy-state variable therefore constructed record
observed flow rate, proxy whether valve open closed. approach,
call observable-correlate policy learning, different averaging plan states
encountered planning, policy states capture actual situation experienced,
plan states remain abstracted distanced reality. work (Fox et al., 2012),
apply exactly policy-learning technique described problem learning robust
observable-correlate policies following boundary surface algal bloom. context
define collection policy state variables correlate plan state variables observable
experience.

7. Physical Experiments
section report results obtained kitchen table experiment comprising simple
circuit constructed breadboard components Arduino Mega board used
sensing control.1 Using apparatus able demonstrate simulation
results translate reality. part future work, experiments undertaken
professional laboratory continue explore benefits limitations approach.
goal experiment demonstrate plan-based policy method achieves similar
lifetime achieved best-of-two policy, significantly reduced switching.
clear simulation results plan-based policy achieve close optimal lifetime
fraction switching best-of-two requires, although simulation also suggests
best-of-two policy achieve within less 1% theoretical optimal even switching
frequency every 5 minutes. therefore expected little opportunity learned
policy improve lifetime therefore hoping achieve similar lifetime
1. results figures presented throughout section presented colour order clarify relationships
multiple plots. Unfortunately, several figures difficult interpret monochrome reader
recommended view figures using appropriate medium.

361

fiF OX , L ONG & AGAZZENI

Figure 16: photograph battery apparatus constructed manage two batteries.

much lower switching frequency. results show plan-based policy exhibit much
lower frequency switching. fact found plan-based policy achieves significantly longer
lifetimes well.
begin describing built circuit used experiment. recall
KiBaM model, explain parameters estimated. plan-based best-of-two
policies rely able read state available charge batteries. difficult
estimate, performance policies depends absolutely estimating quantity
accurately, explain read state available charge set-up. Finally present
results experiments describe plans future work.
7.1 Electronic Apparatus
constructed experimental apparatus suite two batteries, shown Figure 16.
used Ritar 6 volt lead acid batteries nominal capacity 1 Amp hour 20 hours discharge
(1Ah@20h). connected batteries circuit Arduino Mega board.
Part circuit constructed allow Arduino read voltage connected
battery. want ensure current drawn measure voltage negligible, high
external resistance, 3.6k 7.2k, used bridge Arduino input. Using voltmeter
read 6.5-6.7V fresh battery, consider VEM F = 6.5V. high voltage
Arduino inputs maximum input voltage 5V. Since, considering battery
voltage sensing element circuit resistance R, VEM F = iR VEM F = 6.5V ,
use R = 7.2 + 3.6 = 10.8k order divide voltage achieve negligible current
0.0006A. higher resistance might seem preferable still reduce current losses,
362

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

3.6

1

1

8

8

3.6

+ 6V
B1

Volts (L2 Lo)

Volts (L2 Hi)

PWM S2

Volts (B2)

Volts (L1 Lo)

Volts (L1 Hi)

PWM S1

Volts (B1)

Gnd

Arduino Mega

+ 6V
B2

7.2

7.2

Figure 17: battery apparatus two batteries.

Arduino uses analog-to-digital converter based measuring charge capacitor time.
approach relies sufficient current flow capacitor get accurate measurements
short time periods high resistance prevents this. practice, resistance 10k
limit Arduino respond changes inputs within timing constraints
sampling. resistances voltage reading Arduino VEM F 0.0006
3600 = 4.34V , within operating range.
current diverted load consisting switch two resistors 8 1. role
switch, MOSFET IRF630 controlled using pulse width modulated output
Arduino, ensure smooth delivery power resistors. load 6.5/(9+r +Rs )
r internal resistance battery Rs effective variable switch resistance pulse
width modulated control. data sheet Ritar 6V battery lists internal resistance, r,
50m, measured 0.34, value almost 7 times greater. believe discrepancy
comes systematic distortion sensed values reported Arduino. consistently
use readings experiments regard discrepancy systematic error.
experiments use currents varying 0.2A 0.3A, so, VEM F = 6.5V = 0.3A,
Rs 12, lower battery less charged (and voltage drops) higher
lower current load required.
circuit diagram shown Figure 17. noted load duplicated
design, completely separates parts circuit responsible interacting
363

fiF OX , L ONG & AGAZZENI

battery. fielded systems load would common diodes used prevent flow electricity
batteries different charge states.
7.2 Estimating Parameters
work used Kinetic Battery Model (Manwell & McGowan, 1993) followed
parameter estimation process described Manwell McGowan (1994). Following
description, extended KiBaM three parts: capacity model, voltage model lifetime
model. use simple lifetime model (we assume change battery behaviour
due recharging).
7.2.1 C APACITY ODEL
capacity model, describes capacity varies battery drained allowed
rest, described first order differential system. quantity
qmax (I)
maximum amount charge, Amp hours, could hope extract battery
discharged continuously, nominal current I, drained. time takes drain
battery nominal current . linked following equation:
qmax (I) =

1 ek0

Ck 0 cT
+ c(k 0 1 + ek0 )

derived model described Section 3.2. model relies three constants: C,
maximum capacity battery Amp hours, k, rate per hour conductance
bound well available well model, c, ratio available
k
charge maximum capacity. Section 3.2, k 0 defined c(1c)
. seen qmax (I) =
.
constants found fitting curve data. obtained data draining batteries
one time, fully charged state, using different currents circuit described
Section 7.1. example data collected shown Figure 18, top curve
measured voltage battery time, line 5.25V point battery
considered dead, point cloud comprising thick curve 208mA measured load,
thin straight line running point cloud rolling average load. vertical line
shows treated battery dead. shown Figure 19, uncertainty
exactly battery dies.
values C, k, c calculated are:
C = 1.372Ah
k = 0.1967h1
c = 0.3870

k 0 = 0.8290h1
364

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Figure 18: Battery discharge curve: terminal voltage (top curve) load (bottom curve).

millivolts (top curves) 0.1 milliamps (bottom curves)

5600

5500

5400

5300

5200

5100

5000

4900

4800
33000

33500

34000

34500

35000
35500
half-seconds

36000

36500

37000

37500

Figure 19: close point cloud voltage curve point battery
considered dead.

365

fiF OX , L ONG & AGAZZENI

0.7
Observed data
Fitted curve
Data Sheet values
0.6

- Amps

0.5

0.4

0.3

0.2

0.1

0
0

2

4

6

8

10
- hours

12

14

16

18

20

Figure 20: Data current time drain batteries. Data Sheet values shown comparison.

fitted curve I, fitted C, k, c values, shown Figure 20. square
points observed data, stars data points reported Ritar 6V battery
data sheet. found data sheet appears consistently under-estimate performance
battery. seen observed data points clustered 0.17A 0.3A
region curve. unable report points lower currents, pulse width
modulation could set appropriately low value without dropping control voltage
MOSFET switch point switch opens. could report points high
currents without melting resistors comprising load circuit.
used C, k, c values construct initial state battery load management
planning problem, learned policy plans produced model. Therefore,
accurate estimation parameters important. policy far less effective
wrong capacity model used. learned policy using time granularity 0.01h,
36 seconds. timing loops collecting data Arduino sensors use averages
computed 0.5 seconds: data points Figure 19 shown resolution. Thus,
collect 72 data points sensor decision points granularity planning
model and, consequently, learned policy. seen, considerable noise
values reduce noise construct rolling average preceding window 65
points. selected 65 avoid particularly noisy data values generated switch
batteries.
366

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

7.2.2 VOLTAGE ODEL
order able exploit plan-based policies necessary able evaluate state
charge batteries every decision point. known difficult accurately evaluate
state charge behaviour batteries noisy, variable highly non-linear. However,
terminal voltage recognised reasonable proxy state charge. therefore observe
output voltage battery calculate state charge reading.
measured terminal voltage, Eobs , falls battery drained, producing typical
knee-shaped curve representing decrease voltage time current drawn,
illustrating collapse voltage battery dead. Manwell McGowan model
voltage curve using equation:
Vobs = VEM F + AX + BX/(D X)
Q
X defined qmax
(I) Q total charge consumed date battery.
parameters A, B found non-linear curve fitting data, using voltage
time constant current discharges. used 4 sets data obtained draining batteries
fully charged, one time battery apparatus, estimate curve Ritar 6V batteries.
Figure 21 shows example discharge curve. batteries effectively dead soon
voltage drops knee. occurs 5.25V . Figure 21 also shows voltage model curve (the
solid black line), type described above, fitted discharge data battery. case
discharged battery past critical point considered dead, show
voltage drops dramatically (and load cannot maintained reliably). vertical line shows
point battery judged dead curve fitted data point.
seen, curve fits well knee, behaviour longer governed
simple quadratic voltage model.
parameter values computed batteries are:

= 0.194mV s1
B = 2.22 103 mV s1

= 1.05h.
governs almost linear decay voltage first part discharge curve
easiest parameter estimate accurately. B together determine shape initiation
dip voltage battery gets close dying threshold. fit values B
much sensitive noise value A.
7.2.3 E VALUATING TATE C HARGE BATTERY
Using Arduino Mega board, collect voltage current values batteries frequency every half second. battery use, compute rolling average last
65 voltage readings reported since battery first loaded (before this, reported voltage
readings inaccurate). computed first rolling average fix VEM F ,
value take fully charged open circuit voltage battery (ie: voltage
available load serviced). calculate Eobs Q every 36 seconds every
battery.
367

fiF OX , L ONG & AGAZZENI

Figure 21: Voltage time.
observed voltage affected load battery time observe it,
adjust observed voltage reading, Eobs , take account internal resistance load
battery. results unloaded observed voltage Vobs :
Vobs = Eobs + 0.34Iobs
calculate difference Vobs VEM F be:
Vadj = Vobs VEM F .
Then, calculate X first obtain value F :
F =

B + AD + Vadj
2A

Then:

r

DVadj

use root quadratic equation X X 1.
given battery, b, calculate charge consumed b time t, sum current
readings taken far (measured milliamps, taken every half second) divided large constant,
7.2 106 , gives result Amp hours. value Q, total charge consumed date
b.
value X, proportion available charge current drawn,
obtained two parameters Eobs Q, using voltage model given above.
Q
.
X Q, compute qmax (I) X
X=F

F2

368

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

evaluate state charge battery. variable total capacity,
C, minus total charge consumed, Q, Amp hours. gives us estimate total
remaining charge, accessible bound chemical
properties battery. variable difference bound available charge
wells, enabling us estimate long would need drain battery. Since available charge
always less equal bound charge, always pair values (Inom , Tnom ),
that, battery run Inom time Tnom , would reached current state
charge. Given
Q
X=
qmax (Inom )
using equation qmax (I) given Section 7.2.1,
Ck 0 cXTnom
0
0
= 1 ek Tnom + c(k 0 Tnom 1 + ek Tnom )
Q
Therefore, Tnom solution
0

1 + (c 1)ek + ck 0 (1

CX
)T = 0
Q

time, Tnom , nominally required continuously drain battery fully charged,
current I, calculated numerically plugging equations Newton-Raphson
method, appropriate initial value (we use 4, since expected lifetime battery
discharge rates using 2-4 hours). Given that:
qmax (I) = Inom Tnom
that:
Inom =

qmax (I)
Tnom

computed as:
0

Inom (1 ek Tnom )
ck 0
available charge calculated as:
c( (1 c))
discussed Section 3.2.
best-of-two policy discussed Section 3 implemented always choose
battery highest available charge. Executing policy requires state charge
read reasonable accuracy fixed frequency. example, one might fix frequency
every 6 minutes, select next 6-minute interval battery highest available
charge (which equal c( (1 c)) explained Section 3.2).
369

fiF OX , L ONG & AGAZZENI

7.2.4 R ECHARGING E FFECTS
clear perform multiple experiments lead-acid batteries necessary
recharge discharges. Recharging lead-acid batteries known impact
performance: deteriorate repeated cycling. However, gel-type batteries
used deep cycle batteries cycled hundreds times reach end
design life.
Manwell McGowan (1994) proposed lifetime model based rainflow cyclecounting algorithm takes account fact recharging damages batteries
affects ability deliver charge. Given batteries brand new, used
one 30 times, hypothesise effects repeated discharging recharging
significant lifetime experiment2 . extended, larger scale experiment,
rainflow model would interest, adopting it, exploring changes behaviour
model, left future work.
additional important effect battery behaviour temperature. experiments
conducted office environment normal working temperatures. One factors
governed choice discharge currents fact high discharge currents batteries
warm noticeably, model using likely cease valid without changes
parameters. ignored temperature effects treat batteries though used
constant standard operating temperature, reasonable approximation.
7.3 Experiments
carried three sets experiments apparatus consisting two Ritar 6V batteries connected circuit shown Figures 16 17. simulation tests demonstrated
performance approach suites 8 batteries, performing experiments
physical apparatus would time-consuming. 2-battery experiments took
11 hours drain batteries and, anything went wrong experiment, loss
communications PC, experiment restarted resulting loss day
more.
performing experiments noticed Arduino distorts measured values:
time voltages, therefore amps internal resistance. distortions appear consistent
across experiments, resulting systematic error. particular, times measured
suggest Arduino measures 1 hour every 1.4 hours real time, 7 8 hour lifetime
measured Arduino actually approximately 10 11 hours real time. report data
values directly Arduino measurements, unadjusted systematic errors,
borne mind lifetime values considerably longer measured real time.
consistency, times reported relative measures (in practice, timing load
control discharge curves values performed using Arduino clock,
measurements entirely consistent one another).
randomly generated 10 different load profiles, drawn distribution used
train policy, alternating 0.2 0.3 Amps intervals constant
load durations distributed around 30 minutes distribution shown Figure 22.
2. experiments report load profiles 16 run batteries cycled 15 times.
later profiles observe batteries showed behaviour suggested slight deterioration
performance possible lifetimes lower experiments would case new batteries.

370

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Figure 22: Distribution load durations used experiments.
load profile ran best-of-two plan-based policy could perform
direct comparison lifetime achieved number switches performed. resulted 16
load-execution experiments. first two load profiles restricted best-of-two policy
switch every 5 minutes, best-of-two policy plan-based policy switched
similar number times entire run. simulation results suggest plan-based policy
switch 20 times, experiments reveal noise sensor
data leads errors estimation state charge cause policy switch
frequently would anticipate. Frequent switching indicates policy responding
spurious artifacts sensed data variability real behaviour batteries.
discuss Section 8.
plan-based policy applied every 36 seconds (0.01 hours), reflecting granularity
plans learned policy. also ran experiment best-of-two policy allowed
switch every 36 seconds, ensure results obtained biased offering
plan-based policy faster reaction time, changes battery state charge, best-of-two.
wanted establish whether plan-based policy achieve similar lifetimes bestof-two policy lower numbers switches. also wished confirm better
naive simple policy sequencing, first battery used dead,
second battery used. obvious (the sequencing policy much worse simulation),
observed behaviour plan-based policy superficially similar sequencing, since
favours mostly using one battery heavily discharged switching second battery
significant intervals, thought useful perform physical comparison. case
2-battery setup sequencing involves 1 switch (the minimum number switches possible
two battery case).
ran 21 complete experiments total. plots showing battery voltages
experiments, last lowest point battery voltage curves (the red green curves)
points corresponding battery died.
Figure 23 shows best-of-two policy running second load profile. curves show
characteristic discharge/recovery pattern, separated step separation caused internal
resistance battery (when battery recovering voltage open circuit, loaded
reduced internal resistance).
371

fiF OX , L ONG & AGAZZENI

Figure 23: run showing behaviour best-of-two policy.

Figure 24: run showing behaviour plan-based policy.

load voltage curves red curve (battery B1 ) fuzzy noise
readings sensors battery. phenomenon consistently
problem B1 dependent battery, appears feature circuit itself.
372

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Figure 25: Best-of-two plan-based policy, running load profile.
seen lifetime achieved plan-based policy longer, number
switches also reduced. y-axis removed, load measured tenths
milliamps voltage tenths millivolts, before.

strange striations green (B2 ) curve start graph due failure
Arduino correctly capture battery voltage period, affect
performance policy (we simple fail safes ensure spurious data sort
affect performance).
Figure 24 shows behaviour plan-based policy running second load profile.
top two curves represent usage two batteries, B1 B2 . Battery B1 (the red curve)
used first 10,000 half-seconds, B2 briefly used policy switches back
B1 half way run. second half graph, two batteries
interleaved, rising curves B1 correspond periods B2 use B1
resting.
alternating load represented bottom two curves. seen load
changes, measured voltage changes (the top curve registers slight blip).
internal resistance means lower voltage loss battery current
changes. would expect 34mV (if internal resistance 0.34)
difference current 0.1A. actually higher that, appears
slight over-reaction changes load, causing battery voltage drop sharply
battery first loaded, pull back, battery tends recover sharply, fall
back line, load reduced.
Figure 25 shows best-of-two policy plan-based policy run second
load profile side-by-side. red plots B1 green B2 . blue purple points shows
373

fiF OX , L ONG & AGAZZENI

Figure 26: Two executions plan-based policy different load profiles. y-axis
removed, load measured tenths milliamps voltage tenths millivolts,
before.

B1 /B2 serviced load (and value load) best-of-two, black points,
slightly displaced these, show B2 serviced load plan-based policy (B1
serviced load rest time). voltage curves plan-based policy offset
curves best-of-two displayed plot. labelling
y-axis removed avoid confusion. see three interesting features:
1. plan-based policy tends use B1 first B2 second, although sequentially.
2. plan-based policy runs longer, demonstrating increased lifetime achieved.
3. Best-of-two essentially alternates batteries (minor variations due slight
discrepancies batteries factors).
Figure 26 shows comparison plan-based policy working first second load
profiles. performance policy first load profile shown upper voltage curves
upper load curves, curves second load profile displaced
differentiate them. plot highlights similarity way policy manages batteries
case: general strategy run B1 knee, resting briefly period,
oscillate B1 B2 low frequency while, entering period
B1 rapidly switched B2 B1 converges empty. policy finishes B2 .
374

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Figure 27: plan-based policy plotted estimated available charge. y-axis
removed, load measured tenths milliamps voltage tenths millivolts,
before. Charge measured tenths milliamp hours.

interesting difference consequence (random) loads: B1 faced heavier
loads first part second profile, dies faster first profile. However, B2
faces slightly less arduous time second half second profile manages last
considerably longer. particular, load interval 30,00033,000 high load serviced
B2 first profile, period happens lower load second profile.
key reason B2 dies faster first profile: available charge depleted
period real opportunity rest point. final period load first
profile high load kills B2 quickly, final period load second profile
lower one. allows B2 recover bound charge period, depleting
available charge slowly sustaining little longer critical period.
Figure 26 upper policy execution switches frequently window 41,000
43,000 half seconds, B1 dies. plan-based policy includes default
action switch battery avoid currently loaded battery dying prematurely.
reason protect batteries policy effects errors sensor data
propagate state charge model. effect default action case
cause policy switch B2 B1 almost charge, back B1 soon
recovered enough able loaded (according state charge model).
Figure 27 shows policy first load profile again, time plotted estimated
available charge (based voltage readings voltage model). graph shows several
important features. black crosshairs mark estimated available charge (measured 0.1mAh
units) B1 grey crosshairs show B2. discontinuities due changing
375

fiF OX , L ONG & AGAZZENI

Figure 28: sequencing policy showing shorter lifetime load profile 2.
load values. discontinuity, model adjusts load (using
estimated internal resistance), clear additional effect cannot
capture way. already mentioned, also case discrepancy
battery terminal voltage readings different loads 0.1A 0.34 = 34mV ,
0.1A difference load 0.34 internal resistance, graph shows differences
much greater. effect appears worsen battery discharges (see widening
gaps loaded unloaded voltages recorded batteries red/green curves
particularly red curve). However, interestingly, voltage-capacity model seems
marginally less unstable lower states charge (the steps get slightly smaller cases
black curve).
also seen, available charge model breaks situations (when
observations cannot fitted consistently initial state assumed battery). leads
available charge values negative (particularly 4200045000 period).
causes policy revert default action, somewhat simplistic implementation
default leads oscillation batteries period.
Figure 28 shows results obtained draining batteries sequence, using second
load profile. performance optimal terms switching, lifetime achieved much
shorter achieved plan-based policy similar lifetime best-of-two
case. fact best-of-two worse sequential scheduling profile
probably due variation battery behaviour: seems likely best-of-two perform
similarly results load profiles.
clearly seen plan-based policy achieves consistently longer lifetime
best-of-two policy, significantly reduced switching. results summarised Table 5.
376

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Load
Profile

Plan-based Policy
Lifetime Switches

Best-of-two
Lifetime Switches

Sequential
Lifetime Switches

Max.

1
2

7.887
8.033

71
47

7.534
7.000

73
81


7.079


1

8.77
8.91

3
4
5
6
7
8
9
10

7.974
7.831
7.030
7.120
7.669
7.677
8.341
6.972

91
158
17
36
21
88
33
13

7.563
6.998
6.226
7.085
7.645
6.515
5.901
6.890

705
701
609
706
649
584
567
690



















9.04
9.23
9.11
8.81
9.11
8.87
8.91
8.92

Mean

7.653

57.5

6.936

651.4

7.079

1

8.97

Table 5: Table summarising results physical experiments. Lifetimes given hours,
reported using Arduino clock measurements revealed hour
measured Arduino approximately 1.4 hours real time. first two experiments used lower switching frequency Best-of-two policy: seen,
increased frequency later experiments offer apparent advantage.
two results included calculating mean number switches Best-of-two
policy.
paired t-test results shows significant (p = 0.013). expect
improvements even marked case n > 2 batteries, performing experiments topic future work. final column table, labelled max shows
theoretical maximum lifetime batteries given load profile. values probably
rather higher maximum value could achieved practice, since point
batteries considered dead based observed terminal voltages loaded. internal
resistance batteries means point earlier idealised battery model
used simulation. average efficiency batteries 85% policy 77%
best-of-two compared theoretical maximum, consistent expectation theoretical value rather high previously reported performance battery
management systems typically achieve around 80% efficiency.

8. Future Work
paper brings together three distinct directions research. Firstly, work concerned
specific problem solution: management multiple batteries. Secondly, develop
exploit techniques planning PDDL + continuous non-linear dynamics. Thirdly,
devise implement approach policy construction based planning deterministic
samples. directions offers scope work.
377

fiF OX , L ONG & AGAZZENI

Figure 29: battery voltage, load estimated charge curves plan-based policy running
load profile 4. axis shows millivolts, 0.1 milliamps 0.1 milliamp hours
curve respectively.

research battery management potential real application physical experiments reveal theoretical results translate measurable benefits. physical experiments
show higher switching rates plan-based policy control simulation results lead one
expect noted key reason errors attempt diagnose state
charge batteries noisy sensed voltage data. anticipate robust sensing
could resolve problem extent, modification consider careful
implementation default action tracking state charge. Figure 29 shows
plan-based policy run fourth load profile, estimated available charge often judged
negative! triggers application default action many cases switches
contrary policy choices either side spurious data point. fact, 158 switches
execution run, least 90 generated spurious data triggering default actions. Similarly,
load profiles 13 identify least 50, 8 54 cases respectively, default
action causes switch batteries advice policy sensible state charge
estimates either side switches. strongly suggests careful implementation
estimation state charge, respecting expected continuity behaviour, could
lead much better switching rates better stability behaviour policy.
experiments would obviously benefit performed robustly constructed
experimental apparatus additional runs accumulate additional data. hope continue pursue direction collaboration commercial partners might interested
exploiting ideas achieve fielded systems.
378

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

work continuous planning, particularly problems include complex processes
events, remains focus research interest us. considering problems arising
different domains, including control autonomous underwater vehicles control power
systems (Bell, Coles, Coles, Fox, & Long, 2009). also exploring ways hybrid
planning might interface effectively lower control levels shared model system
dynamics. role dynamic discretisation managing complex process dynamics, particularly
non-linear behaviours, one continuing explore.
work construction policies via classification trajectory samples built
planner applied sampled initial states also direction continuing pursue. recent
work algal bloom mapping (Fox et al., 2012) indicates directions considering.
particular, states used planning model allow planner solve sampled problem instances
need states used learning policy. important,
planner exploit knowledge available determinised instances problem find high
quality solutions hope careful selection observable elements
visited states presented classifier, classification process discover correlations
observable states actions selected planner states, order
identify effective policy structures. potentially powerful way approach planning
uncertainty intend investigate much further.

9. Conclusions
paper presented interesting potentially important problem, managing systems powered multiple independent batteries, constructed novel solution it.
brought together research planning policy learning arrive new powerful approach.
experimentally evaluated plans learned policies simulation results reveal solution achieve better 99% efficiency compared theoretical optimal
(which unachievable practice). achieve high efficiencies,
low cost terms battery switching. beneficial switching wasteful energy
tends reduce quality service without additional smoothing circuitry adds energy
losses.
confirmed results simulation gone explore behaviour
ideas physical tests results confirm real batteries far less well-behaved
simulated counterparts. Nevertheless, policies learn continue behave successfully
indeed get results showing 5% 15% lifetime improvements best-of-two
policy equal load profiles, still achieving lower switching rates.
approach solving battery usage problem adapts several existing technologies
automated planning, solve problem seen MDP. use Monte Carlo sampling
generate instances determinised load profiles solving problems using optimal
deterministic solver, combining solutions form policy. Adopting sampling approach
tackling problem-solving uncertainty become increasingly common one
reasons usually offers better scaling opportunities attempting explicitly
reason distributions. policy construction approach adapts use machine learning
construct classifier. construction high quality solutions deterministic problems, use
special variable-range discretisation solve non-linear continuous optimisation problem
high accuracy, exploring small proportion state space.
379

fiF OX , L ONG & AGAZZENI

approach scalable effective. Although solution implement paper
domain-specific several respects, components general already begun
illustrate point adapting approach problems. elements tailored
problem selection discretisation range search heuristic. However,
believe characteristics multiple battery usage problem shared, outline,
domains expect approach adapted domains relative ease.

Acknowledgments
would like thank Marijn Jongerden Boudewijn Haverkort introducing us multiple battery usage problem, drawing attention scheduling problem related policybased approaches. would also like extend thanks anonymous reviewers
handling editor, Carmel Domshlak, help improving text paper.
work partially funded EPSRC Project Automated Modelling Reformulation Planning (EP/G0233650).

References
Alur, R., & Dill, D. L. (1994). Theory Timed Automata. Theoretical Computer Science,
126(2), 183235.
Bell, K. R. W., Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2009). Role AI Planning
Decision Support Tool Power Substation Management. AI Communications, 22(1), 3757.
Benini, L., Castelli, G., Macii, A., Macii, E., Poncino, M., & Scarsi, R. (2001). Discrete-Time
Battery Models System-Level Low-Power Design. Large Scale Integration (VLSI)
Systems, IEEE Transactions on, 9(5), 630 640.
Benini, L., Macii, A., Macii, E., Poncino, M., & Scarsi, R. (2003). Scheduling Battery Usage
Mobile Systems. Large Scale Integration (VLSI) Systems, IEEE Transactions on, 11(6),
1136 1143.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Chang, H. S., Givan, R., & Chong, E. K. P. (2000). On-line Scheduling via Sampling. Proceedings Int. Conf. Automated Planning Scheduling (ICAPS), pp. 6271.
Della Penna, G., Intrigila, B., Magazzeni, D., & Mercorio, F. (2009). UPMurphi: Tool Universal Planning PDDL+ Problems. Proceedings Int. Conf. Automated Planning
Scheduling (ICAPS), pp. 106113.
Eberle, W. A. T. (2008). MOSFET Current Source Gate Drivers, Switching Loss Modeling
Frequency Dithering Control MHz Switching Frequency DC-DC Converters. Ph.D. thesis,
Queens University, Kingston, Ontario, Canada.
Fern, A., Yoon, S. W., & Givan, R. (2004). Learning Domain-Specific Control Knowledge
Random Walks. Proceedings Int. Conf. Automated Planning Scheduling (ICAPS),
pp. 191199.
Fern, A., Yoon, S. W., & Givan, R. (2006). Approximate Policy Iteration Policy Language Bias: solving Relational Markov Decision Processes. J. Artificial Intelligence Research
(JAIR), 25, 75118.
380

fiP LAN - BASED P OLICIES E FFICIENT ULTIPLE BATTERY L OAD ANAGEMENT

Fox, M., & Long, D. (2006). Modelling Mixed Discrete-Continuous Domains Planning. J.
Artificial Intelligence Research (JAIR), 27, 235297.
Fox, M., Long, D., & Magazzeni, D. (2011). Automatic Construction Efficient Multiple Battery Usage Policies. Proceedings Int. Conf. Automated Planning Scheduling,
(ICAPS), pp. 7481.
Fox, M., Long, D., & Magazzeni, D. (2012). Plan-based Policy-Learning Autonomous Feature
Tracking. Proceedings Int. Conf. Automated Planning Scheduling (ICAPS).
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009). WEKA
Data Mining Software: Update. SIGKDD Explorations, 11(1), 1018.
Howey, R., Long, D., & Fox, M. (2004). VAL: Automatic Plan Validation, Continuous Effects
Mixed Initiative Planning Using PDDL. Proceedings Int. Conf. Tools AI
(ICTAI), pp. 294301.
Jongerden, M., Haverkort, B., Bohnenkamp, H., & Katoen, J.-P. (2009). Maximizing System Lifetime Battery Scheduling. Proceedings 39th Annual IEEE/IFIP Int. Conf. Dependable Systems Networks (DSN 2009), pp. 6372.
Jongerden, M., & Haverkort, B. (2008). Battery Modeling. Tech. rep. TR-CTIT-08-01, Centre
Telematics Information Technology, University Twente.
Jongerden, M., & Haverkort, B. (2009). Battery Model Use?. IET Software (Special Issue
Performance Engineering), 3(6), 445457.
Manwell, J., & McGowan, J. (1993). Lead Acid Battery Storage Model Hybrid Energy Systems.
Solar Energy, 50, 399405.
Manwell, J., & McGowan, J. (1994). Extension Kinetic Battery Model Wind/Hybrid
Power Systems. Proceedings 5th European Wind Energy Association Conference
(EWEC), pp. 284289.
Mausam, & Weld, D. S. (2008). Planning Durative Actions Stochastic Domains. J. Artificial
Intelligence Research (JAIR), 31, 3382.
Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam (2009). Heuristic Search
Approach Planning Continuous Resources Stochastic Domains. J. Artificial Intelligence Research (JAIR), 34, 2759.
Quinlan, J. R. (1993). C4.5: Programs Machine Learning. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
Rao, R., Vrudhula, S., & Rakhmatov, D. (2003). Analysis Discharge Techniques Multiple
Battery Systems. Proceedings 2003 Int. Symposium Low Power Electronics
Design (ISLPED 03), pp. 4447.
Sanner, S., & Boutilier, C. (2009). Practical Solution Techniques First-Order MDPs. Artificial
Intelligence, 173(5-6), 748788.
SBS Implementers Forum (2000). System Management Bus (SMBus) Specification, Version 2.0.
Tech. rep., System Management Interface Forum, Inc.
Teichteil-Konigsbuch, F., Kuter, U., & Infantes, G. (2010). Incremental Plan Aggregation Generating Policies MDPs. Proceedings 9th Int. Conf. Autonomous Agents MultiAgent Systems (AAMAS), pp. 12311238.
381

fiF OX , L ONG & AGAZZENI

Wang, T., & Cassandras, C. G. (2011). Optimal Control Multi-Battery Energy-Aware Systems.
Proceedings 50th IEEE Conference Decision Control European Control
Conference (CDC-ECC), pp. 14971502.
Yoon, S. W., Fern, A., & Givan, R. (2007). Using Learned Policies Heuristic-Search Planning.
Proceedings Int. Joint Conf. Artificial Intelligence (IJCAI), pp. 20472053.

382

fiJournal Artificial Intelligence Research 44 (2012) 533-585

Submitted 03/12; published 07/12

Domain Function: Dual-Space Model
Semantic Relations Compositions
Peter D. Turney

peter.turney@nrc-cnrc.gc.ca

National Research Council Canada
Ottawa, Ontario, Canada, K1A 0R6

Abstract
Given appropriate representations semantic relations carpenter wood
mason stone (for example, vectors vector space model), suitable
algorithm able recognize relations highly similar (carpenter
wood mason stone; relations analogous). Likewise, representations
dog, house, kennel, algorithm able recognize semantic
composition dog house, dog house, highly similar kennel (dog house kennel
synonymous). seems two tasks, recognizing relations compositions,
closely connected. However, now, best models relations significantly
different best models compositions. paper, introduce dual-space
model unifies two tasks. model matches performance best
previous models relations compositions. dual-space model consists space
measuring domain similarity space measuring function similarity. Carpenter
wood share domain, domain carpentry. Mason stone share
domain, domain masonry. Carpenter mason share function,
function artisans. Wood stone share function, function materials.
composition dog house, kennel domain overlap dog house
(the domains pets buildings). function kennel similar function
house (the function shelters). combining domain function similarities various
ways, model relations, compositions, aspects semantics.

1. Introduction
distributional hypothesis words occur similar contexts tend similar
meanings (Harris, 1954; Firth, 1957). Many vector space models (VSMs) semantics use
wordcontext matrix represent distribution words contexts, capturing
intuition behind distributional hypothesis (Turney & Pantel, 2010). VSMs achieved
impressive results level individual words (Rapp, 2003), clear
extend level phrases, sentences, beyond. example, know
represent dog house vectors, represent dog house ?
One approach representing dog house treat unit, way handle
individual words. call holistic noncompositional approach representing
phrases. holistic approach may suitable phrases, scale up.
vocabulary N individual words, N 2 two-word phrases, N 3 threeword phrases, on. Even large corpus text, possible
phrases never appear corpus. People continually inventing new phrases,
able understand new phrases although never heard before;
able infer meaning new phrase composition meanings
c
2012
National Research Council Canada. Reprinted permission.

fiTurney

component words. scaling problem could viewed issue data sparsity,
better think problem linguistic creativity (Chomsky, 1975; Fodor &
Lepore, 2002). master natural language, algorithms must able represent phrases
composing representations individual words. cannot treat n-grams (n > 1)
way treat unigrams (individual words). hand, holistic approach ideal
idiomatic expressions (e.g., kick bucket) meaning cannot inferred
component words.
creativity novelty natural language require us take compositional approach majority n-grams encounter. Suppose vector representations dog house. compose representations represent dog
house ? One strategy represent dog house average vectors dog
house (Landauer & Dumais, 1997). simple proposal actually works, limited degree
(Mitchell & Lapata, 2008, 2010). However boat house house boat would represented
average vector, yet different meanings. Composition averaging
deal order sensitivity phrase meaning. Landauer (2002) estimates
80% meaning English text comes word choice remaining 20% comes
word order.
Similar issues arise representation semantic relations. Given vectors
carpenter wood, represent semantic relations carpenter
wood ? treat carpenter :wood unit search paraphrases relations
carpenter wood (Turney, 2006b). large corpus, could find phrases
carpenter cut wood, carpenter used wood, wood carpenter.
variation holistic approach enable us recognize semantic relations
carpenter wood highly similar relations mason stone.
However, holistic approach semantic relations suffers data sparsity
linguistic creativity problems holistic approach semantic composition.
could represent relation carpenter wood averaging vectors.
might enable us recognize carpenter wood mason stone,
would incorrectly suggest carpenter wood stone mason. problem
order sensitivity arises semantic relations arose semantic composition.
Many ideas proposed composing vectors (Landauer & Dumais, 1997;
Kintsch, 2001; Mitchell & Lapata, 2010). Erk Pado (2008) point two problems
common several proposals. First, often adaptive
capacity represent variety possible syntactic relations phrase. example,
phrase horse draws, horse subject verb draws, whereas object
verb phrase draws horse. composition vectors horse draws
must able adapt variety syntactic contexts order properly model
given phrases. Second, single vector weak handle long phrase, sentence,
document. single vector encode fixed amount structural information
dimensionality fixed, upper limit sentence length, hence
amount structure encoded (Erk & Pado, 2008, p. 898). fixed dimensionality
allow information scalability.
Simple (unweighted) averaging vectors lacks adaptive capacity, treats
kinds composition way; flexibility represent different
modes composition. good model must capacity adapt different situations.
534

fiDomain Function: Dual-Space Model

example, weighted averaging, weights tuned different syntactic
contexts (Mitchell & Lapata, 2008, 2010).
Information scalability means size semantic representations grow
proportion amount information representing. size
representation fixed, eventually information loss. hand,
size representations grow exponentially.
One case problem information scalability arises approaches
map multiple vectors single vector. example, represent dog house adding
vectors dog house (mapping two vectors one), may information
loss. increase number vectors mapped single vector,
eventually reach point single vector longer contain information
multiple vectors. problem avoided try map multiple vectors
single vector.
Suppose k-dimensional vector floating point elements b bits each.
vector hold kb bits information. Even allow b grow, k fixed,
eventually information loss. vector space model semantics, vectors
resistance noise. perturb vector noise threshold ,
significant change meaning represents. Therefore think
vector hypersphere radius , rather point. may also put
bounds [r, +r] range values elements vector.1 finite
number N hyperspheres radius packed bounded k-dimensional
space (Conway & Sloane, 1998). According information theory, finite set
N messages, need log2 (N ) bits encode message. Likewise,
finite set N vectors, vector represents log2 (N ) bits information.
Therefore information capacity single vector bounded k-dimensional space
limited log2 (N ) bits.
Past work suggests recognizing relations compositions closely connected
tasks (Kintsch, 2000, 2001; Mangalath, Quesada, & Kintsch, 2004). goal research
unified model handle compositions relations, also resolving
issues linguistic creativity, order sensitivity, adaptive capacity, information scalability.
considerations led us dual-space model, consisting domain space
measuring domain similarity (i.e., topic, subject, field similarity) function space
measuring function similarity (i.e., role, relationship, usage similarity).
analogy : b :: c : (a b c d; example, traffic street water
riverbed), b relatively high domain similarity (traffic street come
domain transportation) c relatively high domain similarity (water
riverbed come domain hydrology). hand, c relatively
high function similarity (traffic water similar roles respective domains;
things flow) b relatively high function similarity (street
riverbed similar roles respective domains; things carry
things flow). combining domain function similarity appropriate ways,
1. models vectors normalized unit length (e.g., models use cosine measure
similarity), elements must lie within range [1, +1]. element outside range,
length vector greater one. general, floating point representations minimum
maximum values.

535

fiTurney

recognize semantic relations traffic street analogous
relations water riverbed.
semantic composition, appropriate way combine similarities may depend
syntax composition. Lets focus noun-modifier composition example.
noun-modifier phrase ab (for instance, brain doctor), head noun b (doctor)
modified adjective noun (brain). Suppose word c (neurologist)
synonymous ab. functional role noun-modifier phrase ab determined
head noun b (a brain doctor kind doctor) b relatively high degree
function similarity c (doctor neurologist function doctors).
b high degree domain similarity c (brain, doctor, neurologist come
domain clinical neurology). combining domain function similarity,
recognize brain doctor synonymous neurologist.
Briefly, proposal compose similarity measures instead composing vectors.
is, apply various mathematical functions combine cosine similarity measures,
instead applying functions directly vectors. addresses information
loss problem, preserve vectors individual component words. (We
map multiple vectors single vector.) Since two different spaces, also
flexibility address problem adaptive capacity.2 model compositional,
resolves linguistic creativity problem. deal order sensitivity combining
similarity measures ways recognize effects word order.
might argued present model semantic composition,
way compare words form two phrases order derive measure similarity
phrases. example, Section 4.3 derive measure similarity phrases
environment secretary defence minister, actually provide representation
phrase environment secretary. hand, past work problem
semantic composition (reviewed Section 2.1) yields representation composite
phrase environment secretary different union representations
component words, environment secretary.
argument based assumption goal semantic composition
create single, general-purpose, stand-alone representation phrase, composite,
distinct union representations component words. assumption
necessary approach use assumption. believe
assumption held back progress problem semantic composition.
argue present model semantic composition, composition similarities, composition vectors. Vectors represent individual words,
similarities inherently represent relations two (or more) things. Composing vectors
yield stand-alone representation phrase, composing similarities necessarily
yields linking structure connects phrase phrases. Similarity composition
result stand-alone representation phrase, practical applications
require stand-alone representations. Whatever practical tasks performed
stand-alone representations phrases, believe performed equally well (or better)
similarity composition. discuss issue depth Section 6.
2. Two similarity spaces give us options similarity composition one space, two types
characters (0 1) give us options generating strings one type character (0 alone).

536

fiDomain Function: Dual-Space Model

next section surveys related work modeling semantic composition
semantic relations. Section 3 describes build domain function space. test
hypothesis value two separate spaces, also create mono space,
merger domain function spaces. present four sets experiments dual-space model Section 4. evaluate dual-space approach
multiple-choice analogy questions SAT (Turney, 2006b), multiple-choice nounmodifier composition questions derived WordNet (Fellbaum, 1998), phrase similarity rating problems (Mitchell & Lapata, 2010), similarity versus association problems
(Chiarello, Burgess, Richards, & Pollock, 1990). discuss experimental results
Section 5. Section 6 considers theoretical questions dual-space model. Limitations model examined Section 7. Section 8 concludes.
paper assumes familiarity vector space models semantics.
overview semantic VSMs, see papers Handbook Latent Semantic Analysis
(Landauer, McNamara, Dennis, & Kintsch, 2007), review Mitchell Lapatas
(2010) paper, survey Turney Pantel (2010).

2. Related Work
examine related work semantic composition relations. introduction, mentioned four problems semantic models, yield four desiderata
semantic model:
1. Linguistic creativity: model able handle phrases (in case
semantic composition) word pairs (in case semantic relations)
never seen before, familiar component words.
2. Order sensitivity: model sensitive order words
phrase (for composition) word pair (for relations), order affects
meaning.
3. Adaptive capacity: phrases, model flexibility represent
different kinds syntactic relations. word pairs, model
flexibility handle variety tasks, measuring degree relational
similarity two pairs (see Section 4.1) versus measuring degree phrasal
similarity two pairs (see Section 4.3).
4. Information scalability: phrases, model scale neither loss
information exponential growth representation size number component
words phrases increases. n-ary semantic relations (Turney, 2008a),
model scale neither loss information exponential growth
representation size n, number terms relations, increases.
review past work light four considerations.
2.1 Semantic Composition
Let ab phrase, noun-modifier phrase, assume vectors
b represent component words b. One earliest proposals semantic
composition represent ab vector c average b (Landauer &
537

fiTurney

Dumais, 1997). using cosine measure vector similarity, taking average
set vectors (or centroid) adding vectors, c = a+b. Vector addition
works relatively well practice (Mitchell & Lapata, 2008, 2010), although lacks order
sensitivity, adaptive capacity, information scalability. Regarding order sensitivity
adaptive capacity, Mitchell Lapata (2008, 2010) suggest using weights, c = a+b,
tuning weights different values different syntactic relations. experiments
(Mitchell & Lapata, 2010), weighted addition performed better unweighted addition.
Kintsch (2001) proposes variation additive composition
c sum a,
P
b, selected neighbours ni b, c = + b + ni . neighbours vectors
words given vocabulary (i.e., rows given wordcontext matrix).
neighbours chosen manner attempts address order sensitivity adaptive
capacity, still problem information scalability due fixed dimensionality.
Utsumi (2009) presents similar model, different way selecting neighbours.
Mitchell Lapata (2010) found simple additive model peformed better
additive model included neighbours.
Mitchell Lapata (2008, 2010) suggest element-wise multiplication composition
operation, c = fi b, ci = ai bi . Like vector addition, element-wise multiplication suffers lack order sensitivity, adaptive capacity, information scalability.
Nonetheless, experimental evaluation seven compositional models two noncompositional models, element-wise multiplication best performance (Mitchell &
Lapata, 2010).
Another approach use tensor product composition (Smolensky, 1990; Aerts
& Czachor, 2004; Clark & Pulman, 2007; Widdows, 2008), outer product,
C = b. outer product two vectors (a b), n elements, n n
matrix (C). outer product three vectors n n n third-order tensor.
results information scalability problem: representations grow exponentially large
phrases grow longer.3 Furthermore, outer product perform well
element-wise multiplication Mitchell Lapatas (2010) experiments. Recent work
tensor products (Clark, Coecke, & Sadrzadeh, 2008; Grefenstette & Sadrzadeh, 2011)
attempted address issue information scalability.
Circular convolution similar outer product, outer product matrix
compressed back vector, c = ~ b (Plate, 1995; Jones & Mewhort, 2007).
avoids information explosion, results information loss. Circular convolution
performed poorly Mitchell Lapatas (2010) experiments.
Baroni Zamparelli (2010) Guevara (2010) suggest another model composition
adjective-noun phrases. core strategy share use holistic vectors
train compositional model. partial least squares regression (PLSR), learn
linear model maps vectors component nouns adjectives linear
approximations holistic vectors phrases. linguistic creativity problem
avoided linear model needs holistic vectors training;
need holistic vectors plausible adjective-noun phrases. Given phrase
training data, linear model predicts holistic vector phrase, given
3. ways avoid exponential growth; example, third-order tensor rank 1
three modes may compactly encoded three component vectors. Kolda Bader (2009)
discuss compact tensor representations.

538

fiDomain Function: Dual-Space Model

component vectors adjective noun. works well adjective-noun
phrases, clear generalize parts speech longer phrases.
One application semantic composition measuring similarity phrases (Erk &
Pado, 2008; Mitchell & Lapata, 2010). Kernel methods applied closely
related task identifying paraphrases (Moschitti & Quarteroni, 2008), emphasis
kernel methods syntactic similarity, rather semantic similarity.
Neural network models combined vector space models task
language modeling (Bengio, Ducharme, Vincent, & Jauvin, 2003; Socher, Manning, & Ng,
2010; Socher, Huang, Pennington, Ng, & Manning, 2011), impressive results. goal
language model estimate probability phrase decide several
phrases likely. VSMs improve probability estimates language model
measuring similarity words phrases smoothing probabilities
groups similar words. However, language model, words considered similar
degree exchanged without altering probability given phrase,
without regard whether exchange alters meaning phrase. like
function similarity, measures degree words similar functional roles,
language models missing anything like domain similarity.
Erk Pado (2008) present model similar two parts,
vector space measuring similarity model selectional preferences. vector
space similar domain space model selectional preferences plays role
similar function space. individual word represented triple, = ha, R, R1 i,
consisting words vector, a, selectional preferences, R, inverse selectional
preferences, R1 . phrase ab represented pair triples, hA0 , B 0 i. triple A0
modified form triple represents individual word a. modifications
adjust representation model meaning altered relation b
phrase ab. Likewise, triple B 0 modified form triple B represents b,
B 0 takes account affects b.
transformed A0 represent influence b meaning a,
vector transformed new vector a0 A0 . Let rb vector represents
typical words consistent selectional preferences b. vector a0
composition rb . Erk Pado (2008) use element-wise multiplication
composition, a0 = fi rb . intention make like typical vector x would
expected phrase xb. Likewise, b0 B 0 , b0 = b fi ra
Erk Pados (2008) model related models (Thater, Furstenau, & Pinkal, 2010)
address linguistic creativity, order sensitivity, adaptive capacity, information scalability,
suitable measuring similarity semantic relations. Consider
analogy traffic street water riverbed. Let hA0 , B 0 represent traffic :street
let hC 0 , D0 represent water :riverbed. transformation A, B, C, A0 , B 0 ,
C 0 , D0 reinforces connection traffic street water
riverbed, help us recognize relational similarity traffic :street
water :riverbed. course, models designed relational similarity,
surprising. However, goal find unified model handle
compositions relations.
539

fiTurney

2.2 Semantic Relations
semantic relations, make general observations order sensitivity. Let
: b c : two word pairs let simr (a : b, c : d) < measure degree
similarity relations : b c : d. : b :: c : good analogy,
simr (a : b, c : d) relatively high value. general, good model relational
similarity respect following equalities inequalities:

simr (a : b, c : d) = simr (b : a, : c)

(1)

simr (a : b, c : d) = simr (c : d, : b)

(2)

simr (a : b, c : d) 6= simr (a : b, : c)

(3)

simr (a : b, c : d) 6= simr (a : d, c : b)

(4)

example, given carpenter :wood mason :stone make good analogy, follows
Equation 1 wood :carpenter stone :mason make equally good analogy. Also,
according Equation 2, mason :stone carpenter :wood make good analogy.
hand, suggested Equation 3, carpenter :wood analogous stone :mason.
Likewise, indicated Equation 4, poor analogy assert carpenter stone
mason wood.
Rosario Hearst (2001) present algorithm classifying word pairs according
semantic relations. use lexical hierarchy map word pairs feature
vectors. classification scheme implicitly tell us something similarity. Two word
pairs semantic relation class implicitly relationally similar
two word pairs different classes. consider relational similarity
implied Rosario Hearsts (2001) algorithm, see problem order
sensitivity: Equation 4 violated.
Let simh (x, y) < measure degree hierarchical similarity
words x y. simh (x, y) relatively high, x share common hypernym
relatively close given lexical hierarchy. essence, intuition behind
Rosario Hearsts (2001) algorithm is, simh (a, c) simh (b, d) high,
simr (a : b, c : d) also high. is, simh (a, c) simh (b, d) high enough,
: b c : assigned relation class.
example, consider analogy mason stone carpenter wood. common hypernym mason carpenter artisan; see simh (mason, carpenter)
high. common hypernym stone wood material; hence simh (stone, wood)
high. seems good analogy indeed characterized high values simh (a, c)
simh (b, d). However, symmetry simh (x, y) leads problem. simh (b, d) high,
simh (d, b) must also high, implies simr (a : d, c : b) high. is,
incorrectly conclude mason wood carpenter stone (see Equation 4).
later work classifying semantic relations used different algorithms,
underlying intuition hierarchical similarity (Rosario, Hearst, & Fillmore,
2002; Nastase & Szpakowicz, 2003; Nastase, Sayyad-Shirabad, Sokolova, & Szpakowicz,
2006). use similar intuition here, since similarity function space closely related
540

fiDomain Function: Dual-Space Model

hierarchical similarity, simh (x, y), see later (Section 4.4). However, including
domain space relational similarity measure saves us violating Equation 4.
Let simf (x, y) < function similarity measured cosine vectors x
function space. Let simd (x, y) < domain similarity measured cosine
vectors x domain space. Like past researchers (Rosario & Hearst, 2001; Rosario
et al., 2002; Nastase & Szpakowicz, 2003; Veale, 2004; Nastase et al., 2006), look
high values simf (a, c) simf (b, d) indicators simr (a : b, c : d) high,
also look high values simd (a, b) simd (c, d). Continuing previous example,
conclude mason wood carpenter stone, wood
belong domain masonry stone belong domain carpentry.
Let determiner (e.g., the, a, an). Hearst (1992) showed patterns form
X (a bird crow) kind X (the crow kind
bird) used infer X hypernym (bird hypernym crow).
pairpattern matrix VSM rows word pairs columns
various X . . . patterns. Turney, Littman, Bigham, Shnayder (2003) demonstrated
pairpattern VSM used measure relational similarity. Suppose
pair-pattern matrix X word pair : b corresponds row vector xi c :
corresponds xj . approach measure relational similarity simr (a : b, c : d)
cosine xi xj .
first patterns pairpattern matrices generated hand (Turney
et al., 2003; Turney & Littman, 2005), later work (Turney, 2006b) used automatically
generated patterns. authors used variations technique (Nakov & Hearst,
2006, 2007; Davidov & Rappoport, 2008; Bollegala, Matsuo, & Ishizuka, 2009; Seaghdha
& Copestake, 2009). models suffer linguistic creativity problem.
models noncompositional (holistic), cannot scale handle
huge number possible pairs. Even largest corpus cannot contain pairs
human speaker might use daily conversation.
Turney (2006b) attempted handle linguistic creativity problem within holistic
model using synonyms. example, corpus contain traffic street within
certain window text, perhaps might contain traffic road. contain
water riverbed, perhaps water channel. However, best partial
solution. Turneys (2006b) algorithm required nine days process 374 multiple choice SAT
analogy questions. Using dual-space model, without specifying advance word
pairs might face, answer 374 questions seconds (see Section 4.1).
Compositional models scale better holistic models.
Mangalath et al. (2004) presented model semantic relations represents word
pairs vectors ten abstract relational categories, hyponymy, meronymy, taxonomy, degree. approach construct kind second-order vector space
elements vectors degrees similarity, calculated cosines
first-order wordcontext matrix.
instance, carpenter :wood represented second-order vector composed
ten cosines calculated first-order vectors. second-order vector, value
element corresponding to, say, meronymy would cosine two first-order vectors, x
y. vector x would sum first-order vectors carpenter wood.
vector would sum several vectors words related meronymy,
541

fiTurney

part, whole, component, portion, contains, constituent, segment. cosine
x would indicate degree carpenter wood related meronymy.
Mangalath et al.s (2004) model suffers information scalability order sensitivity
problems. Information loss takes place first-order vectors summed also
high-dimensional first-order space reduced ten-dimensional second-order
space. order sensitivity problem second-order vectors violate Equation 3,
pairs c : : c represented second-order vector.
natural proposal represent word pair : b way would represent
phrase ab. is, whatever compositional model phrases could also
applied word pairs. However problems compositional model order
sensitivity information scalability carry word pairs. example, represent
: b c = + b c = fi b, violate Equation 3, + b = b +
fi b = b fi a.

3. Three Vector Spaces
section, describe three vector space models. three spaces consist word
context matrices, rows correspond words columns correspond
contexts words occur. differences among three spaces kinds
contexts. Domain space uses nouns context, function space uses verb-based patterns
context, mono space merger domain function contexts. Mono space
created order test hypothesis useful separate domain
function spaces; mono space serves baseline.
3.1 Constructing WordContext Matrices
Building three spaces involves series steps. three main steps,
substeps. first last steps three spaces;
differences spaces result differences second step.
1. Find terms contexts: input: corpus lexicon, output: terms contexts.
1.1. Extract terms lexicon find frequencies corpus.
1.2. Select terms given frequency candidate rows frequency
matrix.
1.3. selected term, find phrases corpus contain term within
given window size.
1.4. Use tokenizer split phrases tokens.
1.5. Use part-of-speech tagger tag tokens phrases.
2. Build termcontext frequency matrix: input: terms contexts, output:
sparse frequency matrix.
2.1. Convert tagged phrases contextual patterns (candidate columns).
2.2. contextual pattern, count number terms (candidate rows)
generated pattern rank patterns descending order counts.
2.3. Select top nc contextual patterns columns matrix.
542

fiDomain Function: Dual-Space Model

2.4. initial set rows (from Step 1.2), drop row match
top nc contextual patterns, yielding final set nr rows.
2.5. row (term) column (contextual pattern), count number
phrases (from Step 1.5) containing given term matching given
pattern, output resulting numbers sparse frequency matrix.
3. Weight elements smooth matrix: input: sparse frequency matrix,
output: singular value decomposition (SVD) weighted matrix.
3.1. Convert raw frequencies positive pointwise mutual information (PPMI)
values.
3.2. Apply SVD PPMI matrix output SVD component matrices.
input corpus Step 1 collection web pages gathered university websites
webcrawler.4 corpus contains approximately 51010 words, comes
280 gigabytes plain text. facilitate finding term frequencies sample phrases,
indexed corpus Wumpus search engine (Buttcher & Clarke, 2005).5 rows
matrices selected terms (words phrases) WordNet lexicon.6
found selecting terms WordNet resulted subjectively higher quality
simply selecting terms high corpus frequencies.
Step 1.1, extract unique words phrases (n-grams) index.sense file
WordNet 3.0, skipping n-grams contain numbers (only letters, hyphens, spaces
allowed n-grams). find n-gram corpus frequencies querying Wumpus
n-gram. n-grams frequency least 100 least 2 characters
candidate rows Step 1.2. selected n-gram, query Wumpus find
maximum 10,000 phrases Step 1.3.7 phrases limited window 7 words
left n-gram 7 words right, total window size 14 + n words.
use OpenNLP 1.3.0 tokenize part-of-speech tag phrases (Steps 1.4 1.5).8
tagged phrases come 46 gigabytes.9
Step 2.1, generate contextual patterns part-of-speech tagged phrases.
Different kinds patterns created three different kinds spaces. details
step given following subsections. phrase may yield several patterns.
three spaces 100,000 rows, maximum 10,000 phrases
per row several patterns per phrase. result millions distinct patterns,
filter patterns Steps 2.2 2.3. select top nc patterns shared
largest number rows. Given large number patterns, may fit
RAM. work limited RAM, use Linux sort command, designed
efficiently sort files large fit RAM. row, make file
distinct patterns generated row. concatenate files
4.
5.
6.
7.

corpus collected Charles Clarke University Waterloo.
Wumpus available http://www.wumpus-search.org/.
WordNet available http://wordnet.princeton.edu/.
limit 10,000 phrases per n-gram required make Wumpus run tolerable amount time.
Finding phrases time-consuming step construction spaces. use solid-state
drive (SSD) speed step.
8. OpenNLP available http://incubator.apache.org/opennlp/.
9. tagged phrases available author request.

543

fiTurney

rows alphabetically sort patterns concatenated file. sorted file,
identical patterns adjacent, makes easy count number occurrences
pattern. counting, second sort operation yields ranked list patterns,
select top nc .
possible candidate rows Step 1.2 might match
patterns Step 2.3. rows would zeros matrix, remove
Step 2.4. Finally, output sparse frequency matrix F nr rows nc
columns. i-th row corresponds n-gram wi j-th column corresponds
contextual pattern cj , value element fij F number phrases
containing wi (from Step 1.5) generate pattern cj (in Step 2.1). Step 3.2, use
SVDLIBC 1.34 calculate singular value decomposition, format output
sparse matrix Step 2.5 chosen meet requirements SVDLIBC.10
Step 3.1, apply positive pointwise mutual information (PPMI) sparse frequency matrix F. variation pointwise mutual information (PMI) (Church &
Hanks, 1989; Turney, 2001) PMI values less zero replaced
zero (Niwa & Nitta, 1994; Bullinaria & Levy, 2007). Let X matrix results
PPMI applied F. new matrix X number rows columns
raw frequency matrix F. value element xij X defined follows:
fij
pij = Pnr Pnc

j=1 fij

i=1

(5)

Pnc

j=1 fij
pi = Pnr Pnc

(6)

Pnr
f
Pncij
= Pnr i=1

(7)

i=1

pj

i=1



j=1 fij
j=1 fij

pij
pi pj



pmiij = log

pmiij pmiij > 0
xij =
0 otherwise

(8)
(9)

definition, pij estimated probability word wi occurs context
cj , pi estimated probability word wi , pj estimated probability
context cj . wi cj statistically independent, pij = pi pj (by definition
independence), thus pmiij zero (since log(1) = 0). product pi pj
would expect pij wi occurs cj pure random chance. hand,
interesting semantic relation wi cj , expect pij larger
would wi cj indepedent; hence find pij > pi pj ,
thus pmiij positive. word wi unrelated (or incompatible with) context cj ,
may find pmiij negative. PPMI designed give high value xij
interesting semantic relation wi cj ; otherwise, xij value
zero, indicating occurrence wi cj uninformative.
10. SVDLIBC available http://tedlab.mit.edu/dr/svdlibc/.

544

fiDomain Function: Dual-Space Model

Finally, Step 3.2, apply SVDLIBC X. SVD decomposes X product
three matrices UVT , U V column orthonormal form (i.e., columns
orthogonal unit length, UT U = VT V = I) diagonal matrix
singular values (Golub & Van Loan, 1996). X rank r, also rank r. Let
k , k < r, diagonal matrix formed top k singular values, let Uk
Vk matrices produced selecting corresponding columns U V.
matrix Uk k VkT matrix rank k best approximates original matrix X,
sense minimizes approximation errors. is, X = Uk k VkT minimizes
kX XkF matrices X rank k, k . . . kF denotes Frobenius norm (Golub
& Van Loan, 1996). final output three matrices, Uk , k , Vk , form
truncated SVD, X = Uk k VkT .
3.2 Domain Space
intuition behind domain space domain topic word characterized
nouns occur near it. use relatively wide window ignore syntactic
context nouns appear.
domain space, Step 2.1, tagged phrase generates two contextual
patterns. contextual patterns simply first noun left given n-gram
(if one) first noun right (if one). Since window size 7
words side n-gram, usually nouns sides n-gram.
nouns may either common nouns proper nouns. OpenNLP uses Penn Treebank
tags (Santorini, 1990), include several different categories noun tags.
noun tags begin capital N, simply extract first words left right
n-gram tags begin N. extracted nouns converted lower
case. noun appears sides n-gram, one contextual pattern
generated. extracted patterns always unigrams; noun compound,
component noun closest n-gram extracted.
Table 1 shows examples n-gram boat. Note window 7 words
count punctuation, number tokens window may greater
number words window. see Table 1 row vector
n-gram boat frequency matrix F nonzero values (for example)
columns lake summer (assuming contextual patterns make
filtering Step 2.3).
Step 2.3, set nc 50,000. Step 2.4, drop rows zero,
left nr equal 114,297. PPMI (which sets negative elements zero)
149,673,340 nonzero values, matrix density 2.62%. Table 2 shows
contextual patterns first five columns last five columns (the columns
order ranks Step 2.2). Count column table gives number rows
(n-grams) generate pattern (that is, counts mentioned Step 2.2).
last patterns begin c counts ties broken
alphabetical order.
545

fiTurney

Tagged phrases
would/MD visit/VB Big/NNP Lake/NNP and/CC take/VB our/PRP$
boat/NN on/IN this/DT huge/JJ beautiful/JJ lake/NN ./. There/EX
was/VBD

Patterns
lake

2

the/DT large/JJ paved/JJ parking/NN lot/NN in/IN the/DT boat/NN
ramp/NN area/NN and/CC walk/VB south/RB along/IN the/DT

lot
ramp

3

building/VBG permit/NN ./. / Anyway/RB ,/, we/PRP should/MD
have/VB a/DT boat/NN next/JJ summer/NN with/IN skiing/NN
and/CC tubing/NN paraphernalia/NNS ./.

permit
summer

1

Table 1: Examples Step 2.1 domain space n-gram boat. three tagged
phrases generate five contextual patterns.

Column
1
2
3
4
5

Pattern
time
part
years
way
name

Count
91,483
84,445
84,417
84,172
81,960

Column
49,996
49,997
49.998
49,999
50,000

Pattern
clu
co-conspirator
conciseness
condyle
conocer

Count
443
443
443
443
443

Table 2: Contextual patterns first last columns domain space. CLU
abbreviation Chartered Life Underwriter terms, condyle round
bump bone forms joint another bone, conocer
Spanish verb know, sense acquainted person.

3.3 Function Space
concept function space function role word characterized
syntactic context relates verbs occur near it. use narrow
window function space domain space, based intuition proximity
verb important determining functional role given word. distant verb
less likely characterize function word. generate relatively complex patterns
function space, try capture syntactic patterns connect given word
nearby verbs.
Step 2.1, tagged phrase generates six contextual patterns. given
tagged phrase, first step cut window 3 tokens given n-gram
3 tokens it. remaining tokens left n-gram punctuation, punctuation everything left punctuation removed.
remaining tokens right n-gram punctuation, punctuation everything right punctuation removed. Lets call remaining tagged phrase
truncated tagged phrase.
Next replace given n-gram truncated tagged phrase generic marker,
546

fiDomain Function: Dual-Space Model

X. simplify part-of-speech tags reducing first character
(Santorini, 1990). example, various verb tags (VB, VBD, VBG, VBN, VBP,
VBZ) reduced V. truncated tagged phrase contains V tag, generates
zero contextual patterns. phrase contains V tag, generate two types
contextual patterns, general patterns specific patterns.
general patterns, verbs (every token V tag) tags removed
(naked verbs) tokens reduced naked tags (tags without words).
specific patterns, verbs, modals (tokens tags), prepositions (tokens tags),
(tokens tags) tags removed tokens reduced naked
tags. (See Table 3 examples.)
general specific patterns, left X, trim leading naked tags.
right X, trim trailing naked tags. tag to, replace
remaining naked tags to. sequence N tags (N N N N N) likely
compound noun, reduce sequence single N.
given truncated tagged phrase, two patterns, one general pattern
one specific pattern. either patterns tokens left right
sides X, make two patterns duplicating X splitting pattern
point two Xs. one new patterns verb, drop
it. Thus may three specific patterns three general patterns
given truncated tagged phrase. specific general patterns same, one
generated.
Table 3 shows examples n-gram boat. Note every pattern must contain
generic marker, X, least one verb.
Truncated tagged phrases
the/DT canals/NNS by/IN boat/NN
and/CC wandering/VBG the/DT

Patterns
X C wandering
X C wandering

Types
general
specific

2

a/DT charter/NN fishing/VBG boat/NN
captain/NN named/VBN Jim/NNP

fishing X N named
fishing X
X N named

general
general
general

3

used/VBN from/IN a/DT
and/CC lowered/VBD to/TO

used X C lowered
used X
X C lowered
used X C lowered
used X
X C lowered

general
general
general
specific
specific
specific

1

boat/NN

Table 3: Examples Step 2.1 function space n-gram boat. three truncated
tagged phrases generate eleven contextual patterns.

Step 2.3, set nc 50,000. Step 2.4, rows zero dropped,
nr 114,101. PPMI, 68,876,310 nonzero values, yielding matrix density
1.21%. Table 4 shows contextual patterns first last five columns.
547

fiTurney

last patterns begin counts ties broken
alphabetical order.
Column
1
2
3
4
5

Pattern
X
X N
X
X
X

Count
94,312
82,171
79,131
72,637
72,497

Column
49,996
49,997
49,998
49,999
50,000

Pattern
since X N
sinking X
supplied X
supports X N
suppressed X

Count
381
381
381
381
381

Table 4: Contextual patterns first last columns function space.
contextual patterns function space complex patterns
domain space. motivation greater complexity observation mere
proximity enough determine functional roles, although seems sufficient determining domains. example, consider verb gives. word X occurs near
gives, X could subject, direct object, indirect object verb. determine
functional role X, need know case applies. syntactic context connects X gives provides information. contextual pattern X gives implies
X subject, gives X implies X object, likely direct object, gives X
suggests X indirect object. Modals prepositions supply information
functional role X context given verb. verb gives appears 43
different contextual patterns (i.e., 43 50,000 columns function space correspond
syntactic patterns contain gives).
Many row vectors function space matrix correspond verbs. might
seem surprising characterize function verb syntactic relation
verbs, consider example, verb run. row vector run
PPMI matrix function space 1,296 nonzero values; is, run characterized
1,296 different contextual patterns.
Note appearing contextual pattern different nonzero value
contextual pattern. character string word run appears 62 different
contextual patterns, run X. row vector word run nonzero
values 1,296 contextual patterns (columns), X.
3.4 Mono Space
Mono space simply merger domain space function space. Step 2.3,
take union 50,000 domain space columns 50,000 function space columns,
resulting total nc 100,000 columns. Step 2.4, total nr 114,297
rows. mono matrix PPMI 218,222,254 nonzero values, yielding density
1.91%. values mono frequency matrix F equal corresponding values
domain function matrices. rows mono space matrix
corresponding rows function space matrix. rows, corresponding values
zeros (but nonzero elements rows, correspond values
domain matrix).
548

fiDomain Function: Dual-Space Model

3.5 Summary Spaces
Table 5 summarizes three matrices. following four sets experiments, use
three matrices (the domain, function, mono matrices) cases;
generate different matrices set experiments. Three four sets experiments
involve datasets used past researchers. made special
effort ensure words three datasets corresponding rows three
matrices. intention three matrices adequate handle
applications without special customization.
Space
domain
function
mono

Rows (nr )
114,297
114,101
114,297

Columns (nc )
50,000
50,000
100,000

Nonzeros (after PPMI)
149,673,340
68,876,310
218,222,254

Density (after PPMI)
2.62%
1.21%
1.91%

Table 5: Summary three spaces.

3.6 Using Spaces Measure Similarity
following experiments, measure similarity two terms, b, cosine
angle corresponding row vectors, b:
sim(a, b) = cos(a, b) =


b

kak kbk

(10)

cosine angle two vectors inner product vectors,
normalized unit length. cosine ranges 1 vectors point
opposite directions ( 180 degrees) +1 point direction ( 0
degrees). vectors orthogonal ( 90 degrees), cosine zero. raw
frequency vectors, necessarily cannot negative elements, cosine cannot
negative, weighting smoothing often introduce negative elements. PPMI weighting
yield negative elements, truncated SVD generate negative elements, even
input matrix negative values.
semantic similarity two terms given cosine two corresponding rows
Uk pk (see Section 3.1). two parameters Uk pk need set.
parameter k controls number latent factors parameter p adjusts weights
factors, raising corresponding singular values pk power p.
parameter k well-known literature (Landauer et al., 2007), p less familiar.
use p suggested Caron (2001). following experiments (Section 4),
explore range values p k.
Suppose take word w list words descending order
cosines w, using Uk pk calculate cosines. p high, go list,
cosines nearest neighbours w decrease slowly. p low, decrease
quickly. is, high p results broad, fuzzy neighbourhood low p yields sharp,
crisp neighbourhood. parameter p controls sharpness similarity measure.
549

fiTurney

reduce running time SVDLIBC, limit number singular values
1500, usually results less 1500 singular values. example, SVD
domain space 1477 singular values. long k greater 1477,
experiment range k values without rerunning SVDLIBC. generate Uk pk
U1477 p1477 simply deleting 1477 k columns smallest singular values.
experiments, vary k 100 1400 increments 100 (14 values k)
vary p 1 +1 increments 0.1 (21 values p). p 1,
give weight factors smaller singular values; p +1, factors
larger singular values weight. Caron (2001) observes researchers use
either p = 0 p = 1; is, use either Uk Uk k .
Let simf (a, b) < function similarity measured cosine vectors b
function space. Let simd (a, b) < domain similarity measured cosine
vectors b domain space. similarity measure combines simd (a, b)
simf (a, b), four parameters tune, kd pd domain space kf pf
function space.
one space, feasible us explore 14 21 = 294 combinations parameter
values, two spaces 294 294 = 86, 436 combinations values. make search
tractable, initialize parameters middle ranges (kf = kd = 700
pf = pd = 0) alternate tuning simd (a, b) (i.e., kd pd ) holding
simf (a, b) (i.e., kf pf ) fixed tuning simf (a, b) holding simd (a, b) fixed. stop
search improvement performance training data. almost
cases, local optimum found one pass; is, tuned parameters
once, improvement try tune second time. Thus typically
evaluate 294 3 = 882 parameter values (3 tune one similarity, tune other,
try first see improvement possible).11
could use standard numerical optimization algorithm tune four parameters, algorithm use takes advantage background knowledge
optimization task. know small variations parameters make small changes
performance, need make fine-grained search, know
simd (a, b) simf (a, b) relatively independent, optimize separately.
rows matrices based terms WordNet index.sense file.
file, nouns singular forms verbs stem forms. calculate
sim(a, b), first look exact matches b terms correspond
rows given matrix (domain, function, mono). exact match found,
use corresponding row vector matrix. Otherwise, look alternate forms
terms, using validForms function WordNet::QueryData Perl interface
WordNet.12 automatically converts plural nouns singular forms verbs
stem forms. none alternate forms exact match row matrix,
map term zero vector length k.

11. use Perl Data Language (PDL) searching parameters, calculating cosines, operations
vectors matrices. See http://pdl.perl.org/.
12. WordNet::QueryData available http://search.cpan.org/dist/WordNet-QueryData/.

550

fiDomain Function: Dual-Space Model

3.7 Composing Similarities
approach semantic relations compositions combine two similarities,
simd (a, b) simf (a, b), various ways, depending task hand syntax
phrase hand. general, want combined similarity high
component similarities high, want values component similarities
balanced. achieve balance, use geometric mean combine similarities, instead
arithmetic mean. geometric mean suitable negative numbers,
cosine negative cases; hence define geometric mean zero
component similarities negative:

geo(x1 , x2 , . . . , xn ) =

(x1 x2 . . . xn )1/n xi > 0 = 1, . . . , n
0 otherwise

(11)

3.8 Element-wise Multiplication
One successful approaches composition, far, element-wise multiplication, c = fi b, ci = ai bi (Mitchell & Lapata, 2008, 2010). approach
makes sense elements vectors negative. elements
b positive, relatively large values ai bi reinforce other, resulting
large value ci . makes intuitive sense. ai bi highly negative,
ci highly positive, although intuition says ci highly negative. Mitchell
Lapata (2008, 2010) designed wordcontext matrices ensure vectors
negative elements.
values matrix Uk pk typically half positive half negative.
use element-wise multiplication baseline following experiments.
fair baseline, cannot simply apply element-wise multiplication row vectors Uk pk .
One solution would use PPMI matrix, X, negative elements,
would allow element-wise multiplication take advantage smoothing effect
SVD. solution use row vectors X = Uk k VkT . Although PPMI matrix,
X, sparse (see Table 5), X Uk pk density 100%.
Let a0 b0 vectors X correspond terms b. row
vectors benefit smoothing due truncated SVD, elements almost
positive. negative elements, set zero. Let c0 = a0 fi b0 .
apply element-wise multiplication vectors, multiply Vk kp1 ,
resulting vector c = c0 Vk p1
compared row vectors matrix
k
p
Uk k :
p1

X(Vk p1
k ) = (Uk k Vk )(Vk k )

=
=
=

Uk k VkT Vk kp1
Uk k p1
k
Uk pk

(12)
(13)
(14)
(15)

Note that, since Vk column orthonormal, VkT Vk equals Ik , k k identity matrix.
551

fiTurney

Similarly, row vector Uk pk , find counterpart a0 X multiplying

1p
k Vk :

(Uk pk )(k1p VkT ) = Uk pk 1p
k Vk

(16)

= Uk k VkT

(17)

= X

(18)

Let nn(x) (nn nonnegative) function converts negative elements vector
x zero:

nn(hx1 , . . . , xn i) = hy1 , . . . , yn

xi xi > 0
yi =
0 otherwise

(19)
(20)

version element-wise multiplication may expressed follows:
p1
1p

c = (nn(a1p
k Vk ) fi nn(bk Vk )) Vk k

(21)

Another way deal element-wise multiplication would use nonnegative
matrix factorization (NMF) (Lee & Seung, 1999) instead SVD. yet found
implementation NMF scales matrix sizes (Table 5).
past experiments smaller matrices, SVD NMF similar performance.

4. Experiments Varieties Similarities
section presents four sets experiments. first set experiments presents dualspace model semantic relations evaluates model multiple choice analogy
questions SAT. second set presents model semantic composition
evaluates multiple choice questions constructed WordNet. third
set applies dual-space model phrase similarity dataset Mitchell Lapata
(2010). final set uses three classes word pairs Chiarello et al. (1990) test
hypothesis dual-space model, domain space function space capture
intuitive concepts association similarity.
4.1 Similarity Relations
evaluate dual-space model applied task measuring similarity
semantic relations. use set 374 multiple-choice analogy questions SAT
college entrance exam (Turney, 2006b). Table 6 gives example one questions.
task select choice word pair analogous (most relationally similar)
stem word pair.
Let : b represent stem pair (e.g., lull :trust). answer SAT questions
selecting choice pair c : maximizes relational similarity, simr (a : b, c : d), defined
follows:
552

fiDomain Function: Dual-Space Model

Stem:
Choices:

Solution:

(1)
(2)
(3)
(4)
(5)
(3)

lull:trust
balk:fortitude
betray:loyalty
cajole:compliance
hinder:destination
soothe:passion
cajole:compliance

Table 6: example question 374 SAT analogy questions. Lulling person
trust analogous cajoling person compliance.

sim1 (a : b, c : d) = geo(simf (a, c), simf (b, d))

(22)

sim2 (a : b, c : d) = geo(simd (a, b), simd (c, d))

(23)

sim3 (a : b, c : d) = geo(simd (a, d), simd (c, b))

sim1 (a : b, c : d) sim2 (a : b, c : d) sim3 (a : b, c : d)
simr (a : b, c : d) =
0 otherwise

(24)
(25)

intent sim1 measure function similarity across two pairs. domain
similarity inside two pairs measured sim2 , whereas domain similarity across
two pairs given sim3 . relational similarity, simr , simply function similarity,
sim1 , subject constraint domain similarity inside pairs, sim2 , must
less domain similarity across pairs, sim3 .
Figure 1 conveys main ideas behind Equations 22 25. want high function
similarities (indicated F) : c b : d, measured sim1 . also prefer
relatively high domain similarities (marked D) : b c : (measured sim2 ),
contrast relatively low domain similarities ( D) : c : b (as given sim3 ).13
Using example Table 6, see lulling person trust analogous
cajoling person compliance, since functional role lull similar functional
role cajole (both involve manipulating person) functional role trust similar
functional role compliance (both states person in).
captured sim1 . constraint sim2 (a : b, c : d) sim3 (a : b, c : d) implies
domain similarities lull :trust (the domain confidence loyalty) cajole :compliance
(the domain obedience conformity) greater equal domain
similarities lull :compliance cajole :trust.
Analogy way mapping knowledge source domain target domain
(Gentner, 1983). source domain mapped c target domain,
play role source domain c plays target domain.
theory behind sim1 . b source domain c target
13. recently came across rectangular structure Lepage Shin-ichis (1996) paper
morphological analogy (see Figure 1). Although algorithm task differ considerably
algorithm task Lepage Shin-ichi (1996), independently discovered
underlying structure analogical reasoning.

553

fiTurney






b


F

c

F





simr (a : b, c : d)
relational similarity

Figure 1: diagram reasoning behind Equations 22 25. F represents high
function similarity, means high domain similarity, indicates low
domain similarity.

domain, internal domain similarity b internal domain similarity
c less cross-domain similarities. motivates constraint
sim2 sim3 . definition natural expression Gentners (1983) theory analogy.
Recall four equations introduced Section 2.2. repeat equations
convenience:

simr (a : b, c : d) = simr (b : a, : c)

(26)

simr (a : b, c : d) = simr (c : d, : b)

(27)

simr (a : b, c : d) 6= simr (a : b, : c)

(28)

simr (a : b, c : d) 6= simr (a : d, c : b)

(29)

Inspection show definition relational similarity Equation 25 satisfies
requirements Equations 26, 27, 28, 29. understood considering
Figure 1. Equation 26 tells us rotate Figure 1 vertical axis without
altering network similarities, due symmetry figure. Equation 27 tells
us rotate Figure 1 horizontal axis without altering network
similarities.
hand, cannot swap c holding b fixed,
would change F links (although would change links).
words, sim1 sim3 would changed, although sim2 would affected.
Therefore Equation 28 satisfied.
Also, cannot swap b holding c fixed, would change
links (although would change F links). words, sim2
sim3 would changed, although sim1 would affected. Therefore Equation 29
554

fiDomain Function: Dual-Space Model

satisfied. see sim1 would violate Equation 29, due symmetry
cosines, simf (b, d) = simf (d, b). constraint sim2 (a : b, c : d) sim3 (a : b, c : d) breaks
symmetry.
Another way break symmetry, Equation 29 satisfied, would use
similarity measure inherently asymmetric, skew divergence. Equation 25,
symmetry broken natural way considering domain function similarity
apply analogies, need introduce inherently asymmetric measure. Also,
note symmetries Equations 26 27 desirable; wish break
symmetries.
would reasonable include simd (a, c) simd (b, d) sim3 , decided
leave out. seems us function similarities simf (a, c) simf (b, d),
high values good analogy, might cause simd (a, c) simd (b, d)
relatively high, even though cross domains. people observe certain kind
abstract function similarity frequently, function similarity might become popular
topic discussion, could result high domain similarity.
example, carpenter :wood analogous mason :stone. domain carpenter :wood
carpentry domain mason :stone masonry. functional role carpenter
similar functional role mason, artisans. Although carpenter
mason belong different domains, high degree abstract function similarity
may result discussions mention together, discussions specialized trades, skilled manual labour, construction industry, workplace injuries.
words, high function similarity two words may cause rise domain
similarity. Therefore include simd (a, c) simd (b, d) sim3 .
five choices SAT question relational similarity zero, skip
question. use ten-fold cross-validation set parameters SAT questions.
parameter values selected nine ten folds, kd = 800, pd = 0.1, kf = 300,
pf = 0.5. parameters determined, 374 SAT questions answered
seconds. Equation 25 correctly answers 191 questions, skips 2 questions,
incorrectly answers 181 questions, achieving accuracy 51.1%.
4.1.1 Comparison Past Work
comparison, average score senior highschool students applying US universities
57.0%. ACL Wiki lists many past results 374 SAT questions.14 Table 7
shows top ten results time writing. table, dual-space refers dualspace model using Equation 25. Four past results achieved accuracy 51.1%
higher. four used holistic approaches hence able address issue
linguistic creativity. best previous algorithm attains accuracy 56.1% (210 correct,
4 skipped, 160 incorrect) (Turney, 2006b). difference 51.1% 56.1%
statistically significant 95% confidence level, according Fishers Exact Test.
majority algorithms Table 7 unsupervised, Dual-Space, PairClass
(Turney, 2008b), BagPack (Herdagdelen & Baroni, 2009) use limited supervision. PairClass BagPack answer given SAT question learning binary classification model
specific given question. training set given question consists one
14. See http://aclweb.org/aclwiki/index.php?title=SAT Analogy Questions.

555

fiTurney

Algorithm
LSA+Predication
KNOW-BEST
k-means
BagPack
VSM
Dual-Space
BMI
PairClass
PERT
LRA
Human

Reference
Mangalath et al. (2004)
Veale (2004)
Bicici Yuret (2006)
Herdagdelen Baroni (2009)
Turney Littman (2005)
Bollegala et al. (2009)
Turney (2008b)
Turney (2006a)
Turney (2006b)
Average US college applicant

Accuracy
42.0
43.0
44.0
44.1
47.1
51.1
51.1
52.1
53.5
56.1
57.0

95% confidence
37.247.4
38.048.2
39.049.3
39.049.3
42.252.5
46.156.5
46.156.5
46.957.3
48.558.9
51.061.2
52.062.3

Table 7: top ten results 374 SAT questions, ACL Wiki. 95%
confidence intervals calculated using Binomial Exact Test.

positive training example, stem pair question, ten randomly selected pairs
(assumed) negative training examples. induced binary classifier used assign
probabilities five choices probable choice guess. Dual-Space uses
training set tune four numerical parameters. three algorithms best
described weakly supervised.
4.1.2 Sensitivity Parameters
see sensitive dual-space model values parameters, perform
two exhaustive grid searches, one coarse, wide grid another fine, narrow
grid. point grids, evaluate dual-space model using whole set
374 SAT questions. narrow grid search centred parameter values
selected nine ten folds previous experiment, kd = 800, pd = 0.1,
kf = 300, pf = 0.5. searches evaluate 5 values parameter, yielding total
54 = 625 parameter settings. Table 8 shows values explored two grid
searches Table 9 presents minimum, maximum, average, standard deviation
accuracy two searches.
Grid
Coarse

Fine

Parameter
kd
pd
kf
pf
kd
pd
kf
pf

100
-1.0
100
-1.0
600
-0.3
100
0.3

425
-0.5
425
-0.5
700
-0.2
200
0.4

Values
750 1075
0.0
0.5
750 1075
0.0
0.5
800
900
-0.1
0.0
300
400
0.5
0.6

1400
1.0
1400
1.0
1000
0.1
500
0.7

Table 8: range parameter values two grid searches.
556

fiDomain Function: Dual-Space Model

Grid
Coarse
Fine

Minimum
31.0
42.5

Accuracy
Maximum Average
48.7
40.7
51.6
47.3

Standard deviation
4.1
2.0

Table 9: sensitivity dual-space model parameter settings.
accuracy attained heuristic search (described Section 3.6) ten-fold
cross-validation, 51.1% (Table 7), near best accuracy fine grid search using
whole set 374 SAT questions, 51.6% (Table 9). evidence heuristic search
effective. Accuracy coarse search varies 31.0% 48.7%, demonstrates
importance tuning parameters. hand, accuracy fine search
spans narrower range lower standard deviation, suggests dualspace model overly sensitive relatively small variations parameter values;
is, parameters reasonably stable. (That nine ten folds cross-validation
select parameters evidence stability.)
4.1.3 Parts Speech
Since domain space based nouns function space based verbs, interesting
know performance dual-space model varies different parts speech.
answer this, manually labeled 374 SAT questions part-of-speech labels.
labels single pair ambiguous, labels become unambiguous context
whole question. example, lull :trust could noun :verb, context
Table 6, must verb :noun.
Table 10 splits results various parts speech. None differences
table statistically significant 95% confidence level, according Fishers
Exact Test. larger varied set questions needed determine part
speech affects dual-space model.
Parts speech
noun:noun
noun:adjective adjective:noun
noun:verb verb:noun
adjective:adjective
verb:adjective adjective:verb
verb:verb
verb:adverb adverb:verb


Right
97
35
27
9
12
11
0
191

Accuracy
50.8
53.0
49.1
37.5
60.0
64.7
0.0
51.1

Wrong
93
31
28
15
7
6
1
181

Skipped
1
0
0
0
1
0
0
2

Total
191
66
55
24
20
17
1
374

Table 10: Performance dual-space model various parts speech.

4.1.4 Order Sensitivity
seems function space work Equation 25. use sim1 alone,
dropping constraint sim2 sim3 , accuracy drops 51.1% 50.8%.
557

fiTurney

drop statistically significant. hypothesize small drop due design
SAT test, primarily intended test students understanding functional
roles, domains.
verify hypothesis, reformulated SAT questions would test
function domain comprehension. method first expand choice pair
c : including stem pair : b, resulting full explicit analogy : b :: c : d.
expanded choice, : b :: c : d, generate another choice, : :: c : b. Table 11 shows
reformulation Table 6. Due symmetry, sim1 must assign similarity
: b :: c : : :: c : b. new ten-choice test evaluates function domain
similarities.
Choices:

Solution:

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(8)
(9)
(10)
(6)

lull:trust::balk:fortitude
lull:fortitude::balk:trust
lull:loyalty::betray:trust
lull:trust::betray:loyalty
lull:compliance::cajole:trust
lull:trust::cajole:compliance
lull:destination::hinder:trust
lull:trust::hinder:destination
lull:trust::soothe:passion
lull:passion::soothe:trust
lull:trust::cajole:compliance

Table 11: expanded SAT question, designed test function domain comprehension. Choices (5) (6) similarity according sim1 .

task expanded ten-choice SAT questions original
five-choice questions, select best analogy. solution Table 11
solution Table 6, except stem pair explicit Table 11. signficant
change five new distractors added choices. answer ten-choice
questions selecting choice : b :: c : maximizes simr (a : b, c : d).
ten-choice reformulated SAT test, simr (Equation 25) attains accuracy
47.9%, whereas sim1 alone (Equation 22) achieves 27.5%. difference statistically
significant 95% confidence level, according Fishers Exact Test. stringent
test supports claim function similarity insufficient itself.
test value two separate spaces, use single space
simd simf Equation 25. model still four parameters tune, kd , pd , kf ,
pf , matrix used similarities. best result accuracy
40.4% ten-question reformulated SAT test, using function space simd
simf . significantly 47.9% accuracy dual-space model simd
based domain space simf based function space (95% confidence level, Fishers
Exact Test).
Table 12 summarizes results. cases matrix simd used,
model based sim1 alone (Equation 22). cases, model based
simr (Equation 25). five-choice ten-choice SAT questions, original
558

fiDomain Function: Dual-Space Model

dual-space model accurate modified models. Significant column
indicates whether accuracy modified model significantly less original
dual-space model (95% confidence level, Fishers Exact Test). difficult ten-choice
questions clearly show value two distinct spaces.
Algorithm
dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space
modified dual-space

Accuracy
51.1
47.3
43.6
37.7
50.8
41.7
35.8
47.9
40.4
38.2
34.8
27.5
25.1
14.4

Significant

yes
yes

yes
yes
yes
yes
yes
yes
yes
yes

Questions
five-choice
five-choice
five-choice
five-choice
five-choice
five-choice
five-choice
ten-choice
ten-choice
ten-choice
ten-choice
ten-choice
ten-choice
ten-choice

Matrix simd
domain space
function space
mono space
domain space
used
used
used
domain space
function space
mono space
domain space
used
used
used

Matrix simf
function space
function space
mono space
domain space
function space
mono space
domain space
function space
function space
mono space
domain space
function space
mono space
domain space

Table 12: Accuracy original five-choice questions reformulated ten-choice
questions. modified models, intentionally use wrong matrix (or
matrix) simd simf . modified models show accuracy decreases
one space used.

4.1.5 Summary
dual-space model performs well current state-of-the-art holistic model
addresses issue linguistic creativity. results reformulated SAT questions
support claim value two separate spaces.
mentioned Section 2.2, task classifying word pairs according
semantic relations (Rosario & Hearst, 2001; Rosario et al., 2002; Nastase & Szpakowicz,
2003) closely connected problem measuring relational similarity. Turney (2006b)
applied measure relational similarity relation classification using cosine similarity
measure nearness nearest neighbour supervised learning algorithm. dualspace model (Equation 25) also suitable relation classification nearest neighbour
algorithm.
4.2 Similarity Compositions
second set experiments, apply dual-space model noun-modifier compositions. Given vectors dog, house, kennel, would like able recognize
dog house kennel synonymous. compare dual-space model holistic
approach, vector addition, element-wise multiplication. approaches evaluated
559

fiTurney

using multiple-choice questions automatically generated WordNet, using
WordNet::QueryData Perl interface WordNet. Table 13 gives example one
noun-modifier questions.
Stem:
Choices:

Solution:

(1)
(2)
(3)
(4)
(5)
(6)
(7)
(1)

dog house
kennel
dog
house
canine
dwelling
effect
largeness
kennel

Table 13: example multiple-choice noun-modifier composition question.
questions, stem bigram choices unigrams. Choice (1)
correct answer, (2) modifier, (3) head noun. Choice (4) synonym
hypernym modifier (5) synonym hypernym head noun.
synonyms hypernyms found, noun randomly chosen. last two choices, (6)
(7), randomly selected nouns. Choices (2) (4) either nouns adjectives,
choices must nouns.
stem bigram choice unigrams must corresponding rows function
space (the space least number rows). stem bigram must noun sense
WordNet (it may also senses parts speech). solution unigram, (1),
must member synset (synonym set) first noun sense stem bigram
(the frequent dominant sense bigram, bigram used noun),
cannot simply hyphenation (dog-house) concatenation (doghouse)
stem bigram.
requirements result total 2180 seven-choice questions, randomly
split 680 training (parameter tuning) 1500 testing.15 questions deliberately designed difficult. particular, approaches strongly attracted
choices (2) (3). Furthermore, attempt ensure stem bigrams
compositional; may idiomatic expressions compositional approach
could possibly get right. want bias questions imposing theories
distinguishing compositions idioms construction.
Let ab represent noun-modifier bigram (dog house) let c represent unigram
(kennel). answer multiple-choice questions selecting unigram maximizes
compositional similarity, simc (ab, c), defined follows:

sim1 (ab, c) = geo(simd (a, c), simd (b, c), simf (b, c))

sim1 (ab, c) 6= c b 6= c
simc (ab, c) =
0 otherwise
15. questions available online appendix http://jair.org/.

560

(30)
(31)

fiDomain Function: Dual-Space Model

Equations 30 31 illustrated Figure 2.


6=

b



F

6=

c
simc (ab, c)
noun-modifier compositional similarity

Figure 2: diagram Equations 30 31.
thinking behind sim1 c (kennel ) high domain similarity
modifier (dog) head noun b (house); furthermore, function
bigram ab (dog house) determined head noun b (house), head noun
high function similarity c (kennel ). add constraints 6= c b 6= c
sim1 tends high values sim1 (ab, a) sim1 (ab, b).16 seems
plausible humans use constraints like this: reason dog house cannot mean
thing house, extra word dog dog house would serve purpose;
would meaningless noise.17
constraints 6= c b 6= c could expressed terms similarities,
simd (a, c) < simd (b, c) < t, high threshold (e.g., = 0.9), would
add another parameter model. decided keep model relatively simple.
seven choices noun-modifier question compositional similarity
zero, skip question. training set, best parameter settings kd = 800,
pd = 0.3, kf = 100, pf = 0.6. testing set, Equation 31 correctly answers 874
questions, skips 22 questions, incorrectly answers 604, yielding accuracy 58.3%.
4.2.1 Comparison Approaches
Mitchell Lapata (2010) compared many different approaches semantic composition
experiments, considered one task (the task examine Section 4.3).
paper, chosen compare smaller number approaches larger
number tasks. include element-wise multiplication experiments,
approach best performance Mitchell Lapatas (2010) experiments. Vector
16. spite constraints, still worthwhile include head noun modifier distractors
multiple-choice questions, enables us experimentally evaluate impact
distractors various algorithms constraints removed (see Table 15). Also, future users
dataset may find way avoid distractors without explicit constraints.
17. philosophy language, Grice (1989) argued proper interpretation language requires us
charitably assume speakers generally insert random words speech.

561

fiTurney

addition included due historical importance simplicity. Although Mitchell
Lapata (2010) found weighted addition better unweighted addition,
include weighted addition experiments, perform well
element-wise multiplication Mitchell Lapatas (2010) experiments. include
holistic model noncompositional baseline.
Table 14 compares dual-space model holistic model, element-wise multiplication, vector addition. latter three models, try three spaces.
Algorithm
dual-space
holistic
holistic
holistic
multiplication
multiplication
multiplication
addition
addition
addition

Space
domain function
mono
domain
function
mono
domain
function
mono
domain
function

Accuracy
58.3
81.6
79.1
67.5
55.7
57.5
46.3
48.3
50.1
39.8

Table 14: Results noun-modifier questions.
table, dual-space refers dual-space model using Equation 31. holistic
model, ab represented corresponding row vector given space. Recall
Section 3.1 that, Step 1.1, rows matrices correspond n-grams WordNet,
n may greater one. Thus, example, dog house corresponding
row vector three spaces. holistic model simply uses row vector
representation dog house. element-wise multiplication, ab represented using
Equation 21. vector addition model, ab represented + b, vectors
normalized unit length added. four models use constraints
6= c b 6= c. four models use training data parameter tuning.
difference dual-space model (58.3%) best variation elementwise multiplication (57.5%) statistically significant 95% confidence level, according Fishers Exact Test. However, difference dual-space model
(58.3%) best variation vector addition (50.1%) significant.
4.2.2 Limitations Holistic Approach
three spaces, holistic model significantly better models,
inability address issue linguistic creativity major limitation. 2180 multiplechoice questions used experiments intentionally constructed
requirement stem bigram must corresponding row function space (see
above). done could use holistic model baseline; however,
gives misleading impression holistic model serious competitor
compositional approaches. design, Table 14 shows holistic model achieve
ideal (but unrealistic) conditions.
562

fiDomain Function: Dual-Space Model

Mitchell Lapatas (2010) dataset, used experiments Section 4.3, illustrates
limitations holistic model. dataset consists 324 distinct pairs bigrams,
composed 216 distinct bigrams. 216 bigrams, 28 (13%) occur WordNet.
324 pairs bigrams, 13 (4%) contain bigrams occur WordNet. Given
matrices use (with rows based WordNet), holistic approach would
reduced random guessing 96% pairs Mitchell Lapatas (2010) dataset.
might argued failure holistic approach Mitchell Lapatas
(2010) dataset due decision base rows matrices terms WordNet.
However, suppose attempt build holistic model frequent bigrams. Web
1T 5-gram corpus (Brants & Franz, 2006) includes list bigrams appeared 40
times terabyte text, total 314,843,401 bigrams. Using compositional
approach, matrices use represent majority bigrams.
hand, holistic approach would require matrix 314,843,401 rows,
considerably beyond current state art.
One possibility build matrix holistic approach needed, given
input set n-grams, instead building large, static, multipurpose matrix.
two problems idea. First, slow. Turney (2006b) used approach
SAT analogy questions, required nine days run, whereas dual-space model
process SAT questions seconds, given static, multipurpose matrix. Second,
requires large corpus, corpus size must grow exponentially n, length
phrases. Longer phrases rare, larger corpora needed gather sufficient
data model phrases. Larger corpora also result longer processing times.
given application, may wise predefined list bigrams holistic
representations, would wise expect list sufficient cover
bigrams would seen practice. creativity human language use requires
compositional models (Chomsky, 1975; Fodor & Lepore, 2002). Although holistic model
included baseline experiments, competitor models;
supplement models.
4.2.3 Impact Constraints
use sim1 alone (Equation 30), dropping constraints 6= c b 6= c, accuracy
drops signficantly, 58.3% 13.7%. However, models benefit greatly
constraints. Table 15, take best variation model Table 14
look happens constraints dropped.

Algorithm
dual-space
holistic
multiplication
addition

Space
domain function
mono
domain
domain

constraints
58.3
81.6
57.5
50.1

Accuracy
constraints
13.7
49.6
8.2
2.5

difference
-44.6
-32.0
-49.3
-47.6

Table 15: impact constraints, 6= c b 6= c, accuracy.

563

fiTurney

4.2.4 Element-wise Multiplication
Section 3.8, argued c = fi b suitable row vectors matrix Uk pk
suggested Equation 21 alternative. use c = fi b domain
space, instead Equation 21, performance drops significantly, 57.5% 21.5%.
4.2.5 Impact Idioms
gap holistic model models may due idiomatic
bigrams testing questions. One successful approaches determining
whether multiword expression (MWE) compositional noncompositional (idiomatic)
compare holistic vector representation compositional vector representation
(for example, high cosine two vectors suggests MWE compositional,
idiomatic) (Biemann & Giesbrecht, 2011; Johannsen, Alonso, Rishj, & Sgaard, 2011).
However, approach suitable here, want assume
gap entirely due idiomatic bigrams; instead, would like estimate much
gap due idiomatic bigrams.
WordNet contains clues use indicators bigram might less
compositional bigrams (allowing compositionality matter degree).
One clue whether WordNet gloss bigram contains either head noun
modifier. example, gloss dog house outbuilding serves shelter
dog, contains modifier, dog. suggests dog house may compositional.
classified 1500 testing set questions head (the first five characters
head noun bigram match first five characters word bigrams gloss),
modifier (the first five characters modifier bigram match first five characters
word bigrams gloss), (both head modifier match), neither
(neither head modifier match). four classes approximately equally
distributed testing questions (424 head, 302 modifier, 330 both, 444 neither).
match first five characters allow cases like brain surgeon, gloss
someone surgery nervous system (especially brain). bigram
classified both, first five characters surgeon match first five characters
surgery.
Table 16 shows accuracy models varies four classes questions. three compositional models (dual-space, multiplication, addition), neither class significantly less accurate three classes (Fishers Exact Test,
95% confidence), difference significant holistic model. three
compositional models, neither class 17% 20% less accurate classes.
supports view significant fraction wrong answers compositional
models due noncompositional bigrams.
Another clue compositionality WordNet whether head noun hypernym
bigram. example, surgeon hypernym brain surgeon. classified
1500 testing set questions hyper (the head noun member synset
immediate hypernym first noun sense bigram; look
hypernym hierarchy look senses bigram) (not hyper).
testing set, 621 questions hyper 879 not.
564

fiDomain Function: Dual-Space Model

Algorithm
dual-space
holistic
multiplication
addition

Space
domain function
mono
domain
domain


63.0
82.7
61.8
53.6

head
63.0
83.7
63.7
56.8

Accuracy
modifier neither
64.6
45.9
82.1
78.4
62.9
44.8
56.3
36.7


58.3
81.6
57.5
50.1

Table 16: variation accuracy different classes bigram glosses.
Table 17 gives accuracy models classes. table
general pattern Table 16. three compositional models significantly lower
accuracy class, decreases 6% 8%. significant difference
holistic model.
Algorithm
dual-space
holistic
multiplication
addition

Space
domain function
mono
domain
domain

Accuracy
hyper
62.0 55.6
81.0 82.0
61.8 54.5
54.8 46.8


58.3
81.6
57.5
50.1

Table 17: variation accuracy different classes bigram hypernyms.

4.2.6 Order Sensitivity
Note vector addition element-wise multiplication lack order sensitivity, Equation 31 sensitive order, simc (ab, c) 6= simc (ba, c). see impact
reformulating noun-modifier questions test order-sensitivity. First
expand choice unigram c including stem bigram ab, resulting explicit
comparison ab c. expanded choice, ab c, generate another choice,
ba c. increases number choices seven fourteen. Due symmetry,
vector addition element-wise multiplication must assign similarity
ab c ba c.
Table 18 compares dual-space model element-wise multiplication vector addition, using reformulated fourteen-choice noun-modifier questions. holistic model
included table rows matrices reversed ba
bigrams (which may seen another illustration limits holistic model).
stricter test, dual-space model significantly accurate element-wise
multiplication vector addition (Fishers Exact Test, 95% confidence).
dual-space model perform well fourteen-choice questions, need
simd simf . drop simd Equation 31 (function alone Table 18),
ignoring modifier paying attention head noun. Accuracy drops
41.5% 25.7%. drop simf Equation 31 (domain alone Table 18),
equation becomes symmetrical, similarity assigned ab c
565

fiTurney

Algorithm
dual-space
multiplication
modified dual-space
modified dual-space
addition

Space
domain function
domain
function alone
domain alone
domain

Accuracy
41.5
27.4
25.7
25.7
22.5

Table 18: Results reformulated fourteen-choice noun-modifier questions.
ba c. Accuracy drops 41.5% 25.7%.18 dual-space model significantly
accurate either modified dual-space models (Fishers Exact Test, 95%
confidence).
4.2.7 Summary
reformulated fourteen-choice noun-modifier questions (Table 18), dual-space
significantly better element-wise multiplication vector addition. original
seven-choice questions (Table 14), difference large, questions
test order. Unlike element-wise multiplication vector addition, dual-space
model addresses issue order sensitivity. Unlike holistic model, dual-space
addresses issue linguistic creativity.
4.3 Similarity Phrases
subsection, apply dual-space model measuring similarity phrases,
using Mitchell Lapatas (2010) dataset human similarity ratings pairs phrases.
dataset includes three types phrases, adjective-noun, noun-noun, verb-object.
108 pairs type (108 3 = 324 pairs phrases). pair phrases
rated 18 human subjects. ratings use 7 point scale, 1 signifies lowest
degree similarity 7 signifies highest degree. Table 19 gives examples.
Let ab represent first phrase pair phrases (environment secretary) let cd
represent second phrase (defence minister). rate similarity phrase pairs
simp (ab, cd), defined follows:
simp (ab, cd) = geo(simd (a, c), simd (b, d), simf (a, c), simf (b, d))

(32)

equation based instructions human participants (Mitchell & Lapata,
2010, Appendix B), imply function domain similarity must high
phrase pair get high similarity rating. Figure 3 illustrates reasoning behind
equation. want high domain function similarities corresponding
components phrases ab cd.
18. coincidence modified dual-space models accuracy 25.7% fourteenchoice questions. Although aggregate accuracy same, individual questions, two models
typically select different choices.

566

fiDomain Function: Dual-Space Model

Participant
114
114
114
109
109
109
111
111
111

Phrase type
adjective-noun
adjective-noun
adjective-noun
noun-noun
noun-noun
noun-noun
verb-object
verb-object
verb-object

Group
2
2
2
0
0
0
2
2
2

Phrase pair
certain circumstance particular case
large number great majority
evidence low cost
environment secretary defence minister
action programme development plan
city centre research work
lift hand raise head
satisfy demand emphasise need
like people increase number

Similarity
6
4
2
6
4
1
7
4
1

Table 19: Examples phrase pair similarity ratings Mitchell Lapatas (2010)
dataset. Similarity ratings vary 1 (lowest) 7 (highest).



b

F

F

c


simp (ab, cd)
phrasal similarity

Figure 3: diagram Equation 32.

4.3.1 Experimental Setup
Mitchell Lapata (2010) divided dataset development set (for tuning parameters) evaluation set (for testing tuned models). development set
6 ratings phrase pair evaluation set 12 ratings phrase pair.
development evaluation sets contain phrase pairs, judgments
different participants. Thus 6324 = 1, 944 rated phrase pairs development
set 12 324 = 3, 888 ratings evaluation set.19
challenging evaluation, divide dataset phrase pairs rather
participants. development set 108 phrase pairs 18 ratings
evaluation set 216 phrase pairs 18 ratings each. three phrase types,
randomly select 36 phrase pairs development set (3 36 = 108 phrase pairs)
19. information paragraph based Section 4.3 paper Mitchell Lapata (2010)
personal communication Jeff Mitchell June, 2010.

567

fiTurney

72 evaluation set (3 72 = 216 phrase pairs). Thus 18 108 = 1, 944
ratings development set 18 216 = 3, 888 evaluation set.
Mitchell Lapata (2010) use Spearmans rank correlation coefficient (Spearmans
rho) evaluate performance various vector composition algorithms task
emulating human similarity ratings. given phrase type, 108 phrase pairs
divided 3 groups 36 pairs each. group evaluation set, 12 people
gave similarity ratings pairs given group. group 36 pairs given
different group 12 people. score algorithm given phrase type
average three rho values, one rho three groups. 12 people rating 36
pairs group, 12 36 = 432 ratings. human ratings represented
vector 432 numbers. algorithm generates one rating pair group,
yielding 36 numbers. make algorithms ratings comparable human ratings,
algorithms ratings duplicated 12 times, yielding vector 432 numbers. Spearmans
rho calculated two vectors 432 ratings. 3 phrase types 3 rho
values 432 ratings per rho value, 3,888 ratings.20
believe evaluation method underestimates performance algorithms. Combining ratings different people one vector 432 numbers
allow correlation adapt different biases. one person gives consistently low ratings
another person gives consistently high ratings, people ranking,
ranking matches algorithms ranking, algorithm get high
score. fair evaluation, score algorithm calculating one rho value
human participant given phrase type, calculate average
rho values participants.
given phrase type, 108 phrase pairs divided 3 groups 36 pairs each.
development set, randomly select 12 phrase pairs 3 groups
(3 12 = 36 phrase pairs per phrase type). leaves 24 phrase pairs 3
groups evaluation set (3 24 = 72 phrase pairs per phrase type). human
participants ratings represented vector 24 numbers. algorithms ratings
also represented vector 24 numbers. rho value calculated two vectors
24 numbers input. given phrase type, algorithms score average 54
rho values (18 participants per group 3 groups = 54 rho values). 3 phrase types
54 rho values 24 ratings per rho value, 3,888 ratings.
4.3.2 Comparison Approaches
Table 20 compares dual-space model vector addition element-wise multiplication.
use development set tune parameters three approaches. vector
addition, ab represented + b cd represented c + d. similarity ab
cd given cosine two vectors. Element-wise multiplication uses Equation 21
represent ab cd. dual-space model uses Equation 32.
average correlation dual-space model (0.48) significantly average
correlation vector addition using function space (0.51). Element-wise multiplication
mono space (0.47) also significantly vector addition using function space (0.51).
20. information paragraph based personal communication Jeff Mitchell June, 2010.
Mitchell Lapatas (2010) paper describe Spearmans rho applied.

568

fiDomain Function: Dual-Space Model

Algorithm
human
dual-space
addition
addition
addition
multiplication
multiplication
multiplication

Correlation
ad-nn nn-nn
0.56
0.54
0.48
0.54
0.47
0.61
0.32
0.55
0.49
0.55
0.43
0.57
0.35
0.58
0.39
0.45

phrase type
vb-ob avg
0.57
0.56
0.43
0.48
0.42
0.50
0.41
0.42
0.48
0.51
0.41
0.47
0.39
0.44
0.27
0.37

Comment
leave-one-out correlation subjects
domain function space
mono space
domain space
function space
mono space
domain space
function space

Table 20: Performance models evaluation dataset.
difference dual-space model (0.48) element-wise multiplication mono
space (0.47) signficant. average correlation algorithm based 162 rho
values (3 phrase types 3 groups 18 participants = 162 rho values = 162 participants).
calculate statistical significance using paired t-test 95% significance level,
based 162 pairs rho values.
4.3.3 Order Sensitivity
Mitchell Lapatas (2010) dataset test order sensitivity. Given phrase pair
ab cd, test order sensitivity adding new pair ab dc. assume
new pairs would given rating 1 human participants. Table 21,
show happens transformation applied examples Table 19.
save space, give examples participant number 114.
Participant
114
114
114
114
114
114

Phrase type
adjective-noun
adjective-noun
adjective-noun
adjective-noun
adjective-noun
adjective-noun

Group
2
2
2
2
2
2

Phrase pair
certain circumstance particular case
certain circumstance case particular
large number great majority
large number majority great
evidence low cost
evidence cost low

Similarity
6
1
4
1
2
1

Table 21: Testing order sensitivity adding new phrase pairs.
Table 22 gives results new, expanded dataset. stringent
dataset, dual-space model performs significantly better vector addition
vector multiplication. Unlike element-wise multiplication vector addition, dualspace model addresses issue order sensitivity.
manually inspected new pairs automatically rated 1 found
rating 1 reasonable cases, although cases could disputed. example,
original noun-noun pair tax charge interest rate generates new pair tax charge
rate interest original verb-object pair produce effect achieve result generates
new pair produce effect result achieve. seems natural tendency correct
569

fiTurney

Algorithm
human
dual-space
addition
addition
addition
multiplication
multiplication
multiplication

Correlation
ad-nn nn-nn
0.71
0.81
0.66
0.37
0.22
0.25
0.15
0.22
0.23
0.23
0.20
0.24
0.18
0.22
0.18
0.19

phrase type
vb-ob avg
0.73
0.75
0.62
0.55
0.19
0.22
0.18
0.18
0.19
0.22
0.18
0.21
0.18
0.19
0.12
0.17

Comment
leave-one-out correlation subjects
domain function space
mono space
domain space
function space
mono space
domain space
function space

Table 22: Performance dataset expanded test order sensitivity.
incorrectly ordered pairs minds assign higher ratings
deserve. predict human ratings new pairs would vary greatly, depending
instructions given human raters. instructions emphasized
importance word order, new pairs would get low ratings. prediction supported
results SemEval 2012 Task 2 (Jurgens, Mohammad, Turney, & Holyoak, 2012),
instructions raters emphasized importance word order wrongly
ordered pairs received low ratings.
4.3.4 Summary
dataset test order sensitivity, vector addition performs slightly better
dual-space model. dataset tests order sensitivity, dual-space
model surpasses vector addition element-wise multiplication large margin.
4.4 Domain versus Function Associated versus Similar
Chiarello et al. (1990) created dataset 144 word pairs labeled similar-only,
associated-only, similar+associated (48 pairs three classes). Table 23
shows examples dataset. labeled pairs created cognitive
psychology experiments human subjects. experiments, found evidence
processing associated words engages left right hemispheres brain
ways different processing similar words. is, seems
fundamental neurological difference two types semantic relatedness.21
hypothesize similarity domain space, simd (a, b), measure degree
two words associated similarity function space, simf (a, b), measure
degree two words similar. test hypothesis, define similar-only,
simso (a, b), associated-only, simao (a, b), similar+associated, simsa (a, b), follows:

ratio(x, y) =

x/y x > 0 > 0
0 otherwise

(33)

21. controversy among cognitive scientists distinction semantic similarity
association (McRae, Khalkhali, & Hare, 2011).

570

fiDomain Function: Dual-Space Model

Word pair
table:bed
music:art
hair:fur
house:cabin
cradle:baby
mug:beer
camel:hump
cheese:mouse
ale:beer
uncle:aunt
pepper:salt
frown:smile

Class label
similar-only
similar-only
similar-only
similar-only
associated-only
associated-only
associated-only
associated-only
similar+associated
similar+associated
similar+associated
similar+associated

Table 23: Examples word pairs Chiarello et al. (1990), labeled similar-only,
associated-only, similar+associated. full dataset Appendix.

simso (a, b) = ratio(simf (a, b), simd (a, b))

(34)

simao (a, b) = ratio(simd (a, b), simf (a, b))

(35)

simsa (a, b) = geo(simd (a, b), simf (a, b))

(36)

intention simso high simf high simd low, simao high
simd high simf low, simsa high simd simf high.
illustrated Figure 4.






F

F

F

b

b

b

simso (a, b)

simao (a, b)

simsa (a, b)

similar-only

associated-only

similar+associated

Figure 4: Diagrams Equations 34, 35, 36.

571

fiTurney

4.4.1 Evaluation
experiments three preceding subsections, three sets parameter
settings dual-space model. Table 24 shows parameter values. effect,
three sets parameter setttings give us three variations similarity measures, simso ,
simao , simsa . evaluate three variations see well correspond
labels Chiarello et al.s (1990) dataset.
Similarity
simr (a : b, c : d)
simc (ab, c)
simp (ab, cd)

Description
similarity relations
similarity noun-modifier compositions
similarity phrases

Section
4.1
4.2
4.3

kd
800
800
200

pd
-0.1
0.3
0.3

kf
300
100
600

pf
0.5
0.6
0.6

Table 24: Parameter settings dual-space model.
given similarity measure, simso , sort 144 word pairs descending order similarities look top N pairs see many
desired label; case simso , would like see majority
top N label similar-only. Table 25 shows percentage pairs
desired labels three variations three similarity measures. Note
random guessing would yield 33%, since three classes pairs size.

Source parameters
simr (a : b, c : d)

simc (ab, c)

simp (ab, cd)

N
10
20
30
10
20
30
10
20
30

Percentage top N desired label
similar-only associated-only similar+associated
70
90
90
80
85
80
63
77
73
90
90
80
80
70
70
70
67
73
50
90
80
65
80
80
47
77
73

Table 25: Percentage top N word pairs desired labels.
three sets parameter settings, Table 25 displays high density desired
labels tops sorted lists. density slowly decreases move
lists. evidence three similarity measures capturing three classes
Chiarello et al. (1990).
another test hypothesis, use three similarity measures create feature
vectors three elements word pair. is, word pair : b represented
feature vector hsimso (a, b), simao (a, b), simsa (a, b)i. use supervised learning
ten-fold cross-validation classify feature vectors three classes Chiarello
et al. (1990). learning algorithm, use logistic regression, implemented
572

fiDomain Function: Dual-Space Model

Weka.22 results summarized Table 26. results lend support
hypothesis similarity domain space, simd (a, b), measure degree
two words associated similarity function space, simf (a, b), measure
degree two words similar.

Source parameters
simr (a : b, c : d)
simc (ab, c)
simp (ab, cd)

Accuracy
61.1
59.0
58.3

similar-only
0.547
0.583
0.472

F-measure
associated-only similar+associated
0.660
0.625
0.702
0.490
0.699
0.563

average
0.611
0.592
0.578

Table 26: Performance logistic regression three similarity measures features.

Table 25, similar-only seems sensitive parameter settings associatedonly similar+associated. hypothesize function similarity
difficult measure domain similarity. Note construction function
space (Section 3.3) complex construction domain space (Section 3.2).
Intuitively, seems easier identify domain thing identify functional
role. Gentners (1991) work suggests children master domain similarity
become competent function similarity.

5. Discussion Experiments
section discusses results previous section.
5.1 Summary Results
Section 4.1, used 374 multiple-choice analogy questions evaluate dual-space
model relational similarity, simr (a : b, c : d). difference performance
dual-space model (51.1% accuracy) best past result (56.1% accuracy), using
holistic model, statistically significant. Experiments reformulated version
questions, designed test order sensitivity, supported hypothesis
domain function space required. Function space sensitive order
merging two spaces (mono space) causes significant drop performance.
Section 4.2, automatically generated 2,180 multiple-choice noun-modifier composition questions WordNet, evaluate dual-space model noun-modifier compositional similarity, simc (ab, c). difference performance dual-space
model (58.3% accuracy) state-of-the-art element-wise multiplication model (57.5%
accuracy) statistically significant. best performance obtained holistic model (81.6%), model address issue linguistic creativity.
experiments suggest significant fraction gap holistic model
models due noncompositional phrases. limitation element-wise multiplication model lack sensitivity order. Experiments reformulated version
22. Weka available http://www.cs.waikato.ac.nz/ml/weka/.

573

fiTurney

questions, designed test order sensitivitiy, demonstrated statistically significant
advantage dual-space model element-wise multiplication vector addition
models.
Section 4.3, used Mitchell Lapatas (2010) dataset 324 pairs phrases
evaluate dual-space model phrasal similarity, simp (ab, cd). reformulated version
dataset, modified test order sensitivitiy, showed statistically significant advantage
dual-space model element-wise multiplication vector addition models.
Section 4.4, used Chiarello et al.s (1990) dataset 144 word pairs, labeled
similar-only, associated-only, similar+associated, test hypothesis similarity
domain space, simd (a, b), measure degree two words associated
similarity function space, simf (a, b), measure degree two words
similar. experimental results support hypothesis. interesting
Chiarello et al. (1990) argue fundamental neurological difference way
people process two kinds semantic relatedness.
experiments support claim dual-space model address issues
linguistic creativity, order sensitivity, adaptive capacity. Furthermore, dual-space
model provides unified approach semantic relations semantic composition.
5.2 Corpus-based Similarity versus Lexicon-based Similarity
results Section 4.4 suggest function similarity may correspond kind
taxonomical similarity often associated lexicons, WordNet (Resnik,
1995; Jiang & Conrath, 1997; Leacock & Chodrow, 1998; Hirst & St-Onge, 1998).
word pairs Table 23 labeled similar-only kinds words typically
share common hypernym taxonomy. example, table:bed share hypernym
furniture. believe correct, necessarily imply lexiconbased similarity measures would better corpus-based approach,
used here.
various similarities Section 4, arguably relational similarity, simr (a : b, c : d),
makes use function similarity. itself, function similarity achieves 50.8%
SAT questions (original five-choice version; see Table 12). However, best performance
achieved SAT questions using WordNet 43.0% (Veale, 2004). difference
statistically significant 95% confidence level, based Fishers Exact Test.
Consider analogy traffic street water riverbed. One SAT questions
involves analogy, traffic :street stem pair water :riverbed correct
choice. simr (a : b, c : d) (Equation 25) function similarity (Equation 22)
make correct choice. recognize traffic water high degree
function similarity; fact, similarity used hydrodynamic models traffic flow
(Daganzo, 1994). However, must climb WordNet hierachy way entity
find shared hypernym traffic water. believe manually
generated lexicon capture functional similarity discovered
large corpus.

6. Theoretical Considerations
section examines theoretical questions dual-space model.
574

fiDomain Function: Dual-Space Model

6.1 Vector Composition versus Similarity Composition
dual-space model, phrase stand-alone, general-purpose representation,
composite phrase, apart representations component words. composite
meaning constructed context given task. example, task measure
similarity relation dog :house relation bird :nest, compose
meanings dog house one way (see Section 4.1); task measure similarity
phrase dog house word kennel, compose meanings dog
house another way (see Section 4.2); task measure similarity phrase
dog house phrase canine shelter, compose meanings dog house
third way (see Section 4.3). composition construction explicitly ties together
two things compared, depends nature comparison
desired, task performed. hypothesize single stand-alone,
task-independent representation constructed suitable purposes.
noted introduction, composition vectors result stand-alone
representation phrase, composing similarities necessarily yields linking structure
connects phrase phrases. linking structures seen Figures
1 4. Intuitively, seems important part understand phrase
connecting phrases. Part understanding dog house connection
kennel. Dictionaries make kinds connections explicit. perspective,
idea explicit linking structure seems natural, given making connnections among
words phrases essential aspect meaning understanding.
6.2 General Form Similarities Dual-Space Model
subsection, present general scheme ties together various similarities
defined Section 4. scheme includes similarities chunks text
arbitrary size. scheme encompasses phrasal similarity, relational similarity,
compositional similarity.
Let chunk text (an ordered set words), ht1 , t2 , . . . , tn i, ti
word. represent semantics = hD, Fi, F matrices.
row vector di D, = 1, 2, . . . , n, row vector domain space represents
domain semantics word ti . row vector fi F, = 1, 2, . . . , n, row vector
function space represents function semantics word ti . keep notation
simple, parameters, kd pd domain space kf pf function space,
implicit. Assume row vectors F normalized unit length. Note
size representation scales linearly n, number words t, hence
information scalability. large values n, inevitably duplicate
words t, representation could easily compressed sublinear size without loss
information.
Let t1 t2 two chunks text representations T1 = hD1 , F1 T2 =
hD2 , F2 i, t1 contains n1 words t2 n2 words. Let D1 D2
parameters, kd pd , let F1 F2 parameters, kf pf . D1
n1 kd , D2 n2 kd , F1 n1 kf , F2 n2 kf . Note D1 DT
1 n1 n1
matrix cosines two row vectors D1 . is, element i-th
575

fiTurney


row j-th column D1 DT
1 cos(di , dj ). Likewise, D1 D2 n1 n2 matrix
cosines row vector D1 row vector D2 .
Suppose wish measure similarity, sim(t1 , t2 ), two chunks
text, t1 t2 . paper, restricted similarity measures following
general form:





sim(t1 , t2 ) = f (D1 DT
1 , 1 2 , 2 2 , F1 F1 , F1 F2 , F2 F2 )

(37)

words, input composition function f cosines (and implicit
parameters, kd , pd , kf , pf ); f operate directly row vectors D1 ,
D2 , F1 , F2 . contrast much work discussed Section 2.1, composition
operation shifted representations, T1 T2 , similarity measure,
f . exact specification f depends task hand. T1 T2 sentences,
envision structure f determined syntactic structures
two sentences.23
Consider relational similarity (Section 4.1):

sim1 (a : b, c : d) = geo(simf (a, c), simf (b, d))

(38)

sim2 (a : b, c : d) = geo(simd (a, b), simd (c, d))

(39)

sim3 (a : b, c : d) = geo(simd (a, d), simd (c, b))

sim1 (a : b, c : d) sim2 (a : b, c : d) sim3 (a : b, c : d)
simr (a : b, c : d) =
0 otherwise

(40)
(41)

fits form Equation 37 t1 = ha, bi t2 = hc, di. see


sim1 based cosines F1 FT
2 , sim2 based cosines D1 D1 D2 D2 ,

sim3 based cosines D1 D2 .
Consider compositional similarity (Section 4.2):

sim1 (ab, c) = geo(simd (a, c), simd (b, c), simf (b, c))

sim1 (ab, c) 6= c b 6= c
simc (ab, c) =
0 otherwise

(42)
(43)

seen instance Equation 37 t1 = ha, bi t2 = hci.

case, sim1 based cosines D1 DT
2 F1 F2 . constraints, 6= c b 6= c,

expressed terms cosines D1 D2 , simd (a, c) 6= 1 simd (b, c) 6= 1.
(Equivalently, could use cosines F1 FT
2 .) Similar analyses apply similarities
Sections 4.3 4.4; similarities also instances Equation 37.
Although representations T1 T2 sizes linear functions numbers phrases t1 t2 , size composition Equation 37 quadratic
function numbers phrases t1 t2 . However, specific instances general
equation may less quadratic size, may possible limit growth
23. Note requirement two chunks text, t1 t2 , number
words. is, n1 necessarily equal n2 . Section 4.2, n1 6= n2 .

576

fiDomain Function: Dual-Space Model

linear function. Also, general, quadratic growth often acceptable practical
applications (Garey & Johnson, 1979).
function words (e.g., prepositions, conjunctions), one option would treat
words. would represented vectors similarities would calculated function domain spaces. Another possibility would
use function words hints guide construction composition function f .
function words would correspond vectors; instead would contribute determining linking structure connects two given chunks text. first option
appears elegant, choice options made empirically.
6.3 Automatic Composition Similarities
Section 4, manually constructed functions combined similarity measures,
using intuition background knowledge. Manual construction scale
task comparing two arbitrarily chosen sentences. However, good reasons
believing construction composition functions automated.
Turney (2008a) presents algorithm solving analogical mapping problems,
analogy solar system Rutherford-Bohr model atom. Given
list terms solar system domain, {planet, attracts, revolves, sun, gravity, solar system, mass}, list terms atomic domain, {revolves, atom, attracts,
electromagnetism, nucleus, charge, electron}, automatically generate one-to-one
mapping one domain other, {solar system atom, sun nucleus, planet
electron, mass charge, attracts attracts, revolves revolves, gravity electromagnetism}. twenty analogical mapping problems, attains accuracy 91.5%,
compared average human accuracy 87.6%.
algorithm scores quality candidate analogical mapping composing
similarities mapped terms. composition function addition individual
component similarities holistic relational similarities. algorithm searches
space possible mappings mapping maximizes composite similarity
measure. is, analogical mapping treated argmax problem, argument
maximized mapping function. effect, output algorithm (an analogical
mapping) automically generated composition similarities. mapping structures
found algorithm essentially linking structures see
Figures 1 4.
believe variation Turneys (2008a) algorithm could used automatically compose similarities dual-space model; example, possible
identify paraphrases using automatic similarity composition. proposal search
composition maximizes composite similarity, subject various constraints (such
constraints based syntax sentences). Turney (2008a) points analogical
mapping could used align words two sentences, experimentally
evaluate suggestion.
Recent work (Lin & Bilmes, 2011) shown argmax problems solved efficiently effectively framed monotone submodular function maximization
problems. believe automatic composition similarities fit naturally
framework, would result highly scalable algorithms semantic composition.
577

fiTurney

Regarding information scalability, dual-space model suffer information
loss (unlike approaches represent compositions vectors fixed dimensionality),
sizes representations grow lengths phrases grow. growth
might quadratic, exponential. questions automate
composition similarities, may impact computational complexity
scaling longer phrases, evidence questions tractable.

7. Limitations Future Work
One area future work experiment longer phrases (more two words)
sentences, discussed Section 6.3. interesting topic research parsing might
used constrain automatic search similarity composition functions.
focused two spaces, domain function, seems likely us
model spaces would yield better performance. currently experimenting quad-space model includes domain (noun-based contextual patterns),
function (verb-based), quality (adjective-based), manner (adverb-based) spaces.
preliminary results quad-space promising. Quad-space seems related
Pustejovskys (1991) four-part qualia structure.
Another issue avoided morphology. discussed Section 3.6, used
validForms function WordNet::QueryData Perl interface WordNet map
morphological variations words base forms. implies that, example,
singular noun plural form semantic representation.
certainly simplification sophisticated model would use different representations
different morphological forms word.
also avoided issue polysemy. possible extend past work
polysemy VSMs dual-space model (Schutze, 1998; Pantel & Lin, 2002; Erk
& Pado, 2008).
paper, treated holistic model dual-space model
competitors, certain cases, idiomatic expressions, holistic
approach required. Likewise, holistic approach limited inability handle
linguistic creativity. considerations suggest holistic dual-space models
must integrated. another topic future work.
Arguably limitation dual-space model four parameters
tune (kd , pd , kf , pf ). hand, perhaps model adaptive capacity
must parameters tune. research needed.
number design decisions made construction domain function
space, especially conversion phrases contextual patterns (Sections 3.2 3.3).
decisions guided intuitions. expect exploration experimental evaluation design space fruitful area future research.
construction function space (Section 3.3) specific English. may generalize readily Indo-European languages, languages may present
challenge. another topic future research.
composite similarities use geometric mean combine domain
function similarities, see reason restrict possible composition functions.
578

fiDomain Function: Dual-Space Model

Equation 37 allows composition function f . Exploring space possible composition
functions another topic future work.
Another question formal logic textual entailment integrated
approach. dual-space model seems suitable recognizing paraphrases,
obvious way handle entailment. generally, focused various
kinds similarity, scale phrases (red ball) sentences (The ball
red), encounter truth falsity. Gardenfors (2004) argues spatial models
bridge low-level connectionist models high-level symbolic models. claims
spatial models best questions similarity symbolic models best
questions truth. yet know join two kinds models.

8. Conclusions
goal research develop model unifies semantic relations
compositions, also addressing linguistic creativity, order sensitivity, adaptive capacity, information scalability. believe dual-space model achieves goal,
although certainly room improvement research.
many kinds wordcontext matrices, based various notions context;
Sahlgren (2006) gives good overview types context explored
past work. novelty dual-space model includes two distinct
complementary wordcontext matrices work together synergistically.
two distinct spaces, two distinct similarity measures,
combined many different ways. multiple similarity measures, similarity composition becomes viable alternative vector composition. example, instead multiplying vectors, c = fi b, multiply similarities, simsa (a, b) =
geo(simd (a, b), simf (a, b)). results suggest fruitful new way look
problems semantics.

Acknowledgments
Thanks George Foster, Yair Neuman, David Jurgens, reviewers JAIR
helpful comments earlier version paper. Thanks Charles Clarke
corpus used build three spaces, Stefan Buttcher Wumpus,
creators WordNet making lexicon available, developers OpenNLP,
Doug Rohde SVDLIBC, Jeff Mitchell Mirella Lapata sharing data
answering questions evaluation methodology, Christine Chiarello, Curt
Burgess, Lorie Richards, Alma Pollock making data available, Jason Rennie
WordNet::QueryData Perl interface WordNet, developers Perl Data
Language.

References
Aerts, D., & Czachor, M. (2004). Quantum aspects semantic analysis symbolic
artificial intelligence. Journal Physics A: Mathematical General, 37, L123
L132.
579

fiTurney

Baroni, M., & Zamparelli, R. (2010). Nouns vectors, adjectives matrices: Representing adjective-noun constructions semantic space. Proceedings 2010
Conference Empirical Methods Natural Language Processing (EMNLP 2010),
pp. 11831193.
Bengio, Y., Ducharme, R., Vincent, P., & Jauvin, C. (2003). neural probabilistic language
model. Journal Machine Learning Research, 3, 11371155.
Bicici, E., & Yuret, D. (2006). Clustering word pairs answer analogy questions.
Proceedings Fifteenth Turkish Symposium Artificial Intelligence Neural
Networks (TAINN 2006), Akyaka, Mugla, Turkey.
Biemann, C., & Giesbrecht, E. (2011). Distributional semantics compositionality 2011:
Shared task description results. Proceedings Workshop Distributional
Semantics Compositionality (DiSCo 2011), pp. 2128, Portland, Oregon.
Bollegala, D., Matsuo, Y., & Ishizuka, M. (2009). Measuring similarity implicit
semantic relations Web. Proceedings 18th International Conference
World Wide Web (WWW 2009), pp. 651660.
Brants, T., & Franz, A. (2006). Web 1T 5-gram Version 1. Linguistic Data Consortium,
Philadelphia.
Bullinaria, J., & Levy, J. (2007). Extracting semantic representations word cooccurrence statistics: computational study. Behavior Research Methods, 39 (3),
510526.
Buttcher, S., & Clarke, C. (2005). Efficiency vs. effectiveness terabyte-scale information retrieval. Proceedings 14th Text REtrieval Conference (TREC 2005),
Gaithersburg, MD.
Caron, J. (2001). Experiments LSA scoring: Optimal rank basis.. Proceedings
SIAM Computational Information Retrieval Workshop, pp. 157169, Raleigh,
NC.
Chiarello, C., Burgess, C., Richards, L., & Pollock, A. (1990). Semantic associative
priming cerebral hemispheres: words do, words dont . . . sometimes,
places. Brain Language, 38, 75104.
Chomsky, N. (1975). Logical Structure Linguistic Theory. Plenum Press.
Church, K., & Hanks, P. (1989). Word association norms, mutual information, lexicography. Proceedings 27th Annual Conference Association Computational Linguistics, pp. 7683, Vancouver, British Columbia.
Clark, S., Coecke, B., & Sadrzadeh, M. (2008). compositional distributional model
meaning. Proceedings 2nd Symposium Quantum Interaction, pp. 133140,
Oxford, UK.
Clark, S., & Pulman, S. (2007). Combining symbolic distributional models meaning.
Proceedings AAAI Spring Symposium Quantum Interaction, pp. 5255,
Stanford, CA.
Conway, J. H., & Sloane, N. J. A. (1998). Sphere Packings, Lattices Groups. Springer.
580

fiDomain Function: Dual-Space Model

Daganzo, C. F. (1994). cell transmission model: dynamic representation highway
traffic consistent hydrodynamic theory. Transportation Research Part B:
Methodological, 28 (4), 269287.
Davidov, D., & Rappoport, A. (2008). Unsupervised discovery generic relationships using
pattern clusters evaluation automatically generated SAT analogy questions.
Proceedings 46th Annual Meeting ACL HLT (ACL-HLT-08), pp.
692700, Columbus, Ohio.
Erk, K., & Pado, S. (2008). structured vector space model word meaning context.
Proceedings 2008 Conference Empirical Methods Natural Language
Processing (EMNLP-08), pp. 897906, Honolulu, HI.
Fellbaum, C. (Ed.). (1998). WordNet: Electronic Lexical Database. MIT Press.
Firth, J. R. (1957). synopsis linguistic theory 19301955. Studies Linguistic
Analysis, pp. 132. Blackwell, Oxford.
Fodor, J., & Lepore, E. (2002). Compositionality Papers. Oxford University Press.
Gardenfors, P. (2004). Conceptual Spaces: Geometry Thought. MIT Press.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. Freeman.
Gentner, D. (1983). Structure-mapping: theoretical framework analogy. Cognitive
Science, 7 (2), 155170.
Gentner, D. (1991). Language career similarity. Gelman, S., & Byrnes, J.
(Eds.), Perspectives Thought Language: Interrelations Development, pp.
225277. Cambridge University Press.
Golub, G. H., & Van Loan, C. F. (1996). Matrix Computations (Third edition). Johns
Hopkins University Press, Baltimore, MD.
Grefenstette, E., & Sadrzadeh, M. (2011). Experimenting transitive verbs DisCoCat. Proceedings GEMS 2011 Workshop GEometrical Models Natural
Language Semantics.
Grice, H. P. (1989). Studies Way Words. Harvard University Press, Cambridge,
MA.
Guevara, E. (2010). regression model adjective-noun compositionality distributional
semantics. Proceedings 2010 Workshop GEometrical Models Natural
Language Semantics (GEMS 2010), pp. 3337.
Harris, Z. (1954). Distributional structure. Word, 10 (23), 146162.
Hearst, M. (1992). Automatic acquisition hyponyms large text corpora. Proceedings 14th Conference Computational Linguistics (COLING-92), pp. 539545.
Herdagdelen, A., & Baroni, M. (2009). Bagpack: general framework represent semantic
relations. Proceedings EACL 2009 Geometrical Models Natural Language
Semantics (GEMS) Workshop, pp. 3340.
581

fiTurney

Hirst, G., & St-Onge, D. (1998). Lexical chains representations context detection
correction malapropisms. Fellbaum, C. (Ed.), WordNet: Electronic
Lexical Database, pp. 305332. MIT Press.
Jiang, J. J., & Conrath, D. W. (1997). Semantic similarity based corpus statistics
lexical taxonomy. Proceedings International Conference Research
Computational Linguistics (ROCLING X), pp. 1933, Tapei, Taiwan.
Johannsen, A., Alonso, H. M., Rishj, C., & Sgaard, A. (2011). Shared task system
description: Frustratingly hard compositionality prediction. Proceedings
Workshop Distributional Semantics Compositionality (DiSCo 2011), pp. 29
32, Portland, Oregon.
Jones, M. N., & Mewhort, D. J. K. (2007). Representing word meaning order information composite holographic lexicon. Psychological review, 114, 137.
Jurgens, D. A., Mohammad, S. M., Turney, P. D., & Holyoak, K. J. (2012). SemEval-2012
Task 2: Measuring degrees relational similarity. Proceedings First Joint
Conference Lexical Computational Semantics (*SEM), pp. 356364, Montreal,
Canada.
Kintsch, W. (2000). Metaphor comprehension: computational theory. Psychonomic Bulletin & Review, 7 (2), 257266.
Kintsch, W. (2001). Predication. Cognitive Science, 25 (2), 173202.
Kolda, T., & Bader, B. (2009). Tensor decompositions applications. SIAM Review,
51 (3), 455500.
Landauer, T. K. (2002). computational basis learning cognition: Arguments
LSA. Ross, B. H. (Ed.), Psychology Learning Motivation: Advances
Research Theory, Vol. 41, pp. 4384. Academic Press.
Landauer, T. K., & Dumais, S. T. (1997). solution Platos problem: latent semantic analysis theory acquisition, induction, representation knowledge.
Psychological Review, 104 (2), 211240.
Landauer, T. K., McNamara, D. S., Dennis, S., & Kintsch, W. (2007). Handbook Latent
Semantic Analysis. Lawrence Erlbaum, Mahwah, NJ.
Leacock, C., & Chodrow, M. (1998). Combining local context WordNet similarity
word sense identification. Fellbaum, C. (Ed.), WordNet: Electronic Lexical
Database. MIT Press.
Lee, D. D., & Seung, H. S. (1999). Learning parts objects nonnegative matrix
factorization. Nature, 401, 788791.
Lepage, Y., & Shin-ichi, A. (1996). Saussurian analogy: theoretical account
application. Proceedings 16th International Conference Computational
Linguistics (COLING 1996), pp. 717722.
Lin, H., & Bilmes, J. (2011). class submodular functions document summarization.
49th Annual Meeting Association Computational Linguistics: Human
Language Technologies (ACL-HLT), pp. 510520.
582

fiDomain Function: Dual-Space Model

Mangalath, P., Quesada, J., & Kintsch, W. (2004). Analogy-making predication using
relational information LSA vectors. Proceedings 26th Annual Meeting
Cognitive Science Society, p. 1623, Austin, TX.
McRae, K., Khalkhali, S., & Hare, M. (2011). Semantic associative relations adolescents young adults: Examining tenuous dichotomy. Reyna, V., Chapman,
S., Dougherty, M., & Confrey, J. (Eds.), Adolescent Brain: Learning, Reasoning,
Decision Making, pp. 3966. APA, Washington, DC.
Mitchell, J., & Lapata, M. (2008). Vector-based models semantic composition. Proceedings ACL-08: HLT, pp. 236244, Columbus, Ohio. Association Computational
Linguistics.
Mitchell, J., & Lapata, M. (2010). Composition distributional models semantics.
Cognitive Science, 34 (8), 13881429.
Moschitti, A., & Quarteroni, S. (2008). Kernels linguistic structures answer extraction. Proceedings 46th Annual Meeting Association Computational
Linguistics Human Language Technologies: Short Papers, p. 113116, Columbus,
OH.
Nakov, P., & Hearst, M. (2006). Using verbs characterize noun-noun relations. Proceedings 12th International Conference Artificial Intelligence: Methodology,
Systems, Applications (AIMSA 2006), pp. 233244, Varna, Bulgaria.
Nakov, P., & Hearst, M. (2007). UCB: System description SemEval Task 4. Proceedings Fourth International Workshop Semantic Evaluations (SemEval 2007),
pp. 366369, Prague, Czech Republic.
Nastase, V., Sayyad-Shirabad, J., Sokolova, M., & Szpakowicz, S. (2006). Learning nounmodifier semantic relations corpus-based WordNet-based features. Proceedings 21st National Conference Artificial Intelligence (AAAI-06), pp.
781786.
Nastase, V., & Szpakowicz, S. (2003). Exploring noun-modifier semantic relations.
Proceedings Fifth International Workshop Computational Semantics (IWCS5), pp. 285301, Tilburg, Netherlands.
Niwa, Y., & Nitta, Y. (1994). Co-occurrence vectors corpora vs. distance vectors
dictionaries. Proceedings 15th International Conference Computational
Linguistics, pp. 304309, Kyoto, Japan.
Seaghdha, D., & Copestake, A. (2009). Using lexical relational similarity classify
semantic relations. Proceedings 12th Conference European Chapter
Association Computational Linguistics (EACL-09), Athens, Greece.
Pantel, P., & Lin, D. (2002). Discovering word senses text. Proceedings Eighth
ACM SIGKDD International Conference Knowledge Discovery Data Mining,
pp. 613619, Edmonton, Canada.
Plate, T. (1995). Holographic reduced representations. IEEE Transactions Neural Networks, 6 (3), 623641.
Pustejovsky, J. (1991). generative lexicon. Computational Linguistics, 17 (4), 409441.
583

fiTurney

Rapp, R. (2003). Word sense discovery based sense descriptor dissimilarity. Proceedings Ninth Machine Translation Summit, pp. 315322.
Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.
Proceedings 14th International Joint Conference Artificial Intelligence
(IJCAI-95), pp. 448453, San Mateo, CA. Morgan Kaufmann.
Rosario, B., & Hearst, M. (2001). Classifying semantic relations noun-compounds
via domain-specific lexical hierarchy. Proceedings 2001 Conference
Empirical Methods Natural Language Processing (EMNLP-01), pp. 8290.
Rosario, B., Hearst, M., & Fillmore, C. (2002). descent hierarchy, selection
relational semantics. Proceedings 40th Annual Meeting Association
Computational Linguistics (ACL-02), pp. 247254.
Sahlgren, M. (2006). Word-Space Model: Using distributional analysis represent syntagmatic paradigmatic relations words high-dimensional vector spaces.
Ph.D. thesis, Department Linguistics, Stockholm University.
Santorini, B. (1990). Part-of-speech tagging guidelines Penn Treebank Project. Tech.
rep., Department Computer Information Science, University Pennsylvania.
(3rd revision, 2nd printing).
Schutze, H. (1998). Automatic word sense discrimination. Computational Linguistics, 24 (1),
97124.
Smolensky, P. (1990). Tensor product variable binding representation symbolic
structures connectionist systems. Artificial Intelligence, 159216.
Socher, R., Huang, E. H., Pennington, J., Ng, A. Y., & Manning, C. D. (2011). Dynamic
pooling unfolding recursive autoencoders paraphrase detection. Advances
Neural Information Processing Systems (NIPS 2011), pp. 801809.
Socher, R., Manning, C. D., & Ng, A. Y. (2010). Learning continuous phrase representations
syntactic parsing recursive neural networks. Proceedings NIPS-2010
Deep Learning Unsupervised Feature Learning Workshop.
Thater, S., Furstenau, H., & Pinkal, M. (2010). Contextualizing semantic representations
using syntactically enriched vector models. Proceedings 48th Annual Meeting
Association Computational Linguistics, pp. 948957.
Turney, P. D. (2001). Mining Web synonyms: PMI-IR versus LSA TOEFL.
Proceedings Twelfth European Conference Machine Learning (ECML-01),
pp. 491502, Freiburg, Germany.
Turney, P. D. (2006a). Expressing implicit semantic relations without supervision.
Proceedings 21st International Conference Computational Linguistics
44th Annual Meeting Association Computational Linguistics (Coling/ACL06), pp. 313320, Sydney, Australia.
Turney, P. D. (2006b). Similarity semantic relations. Computational Linguistics, 32 (3),
379416.
Turney, P. D. (2008a). latent relation mapping engine: Algorithm experiments.
Journal Artificial Intelligence Research, 33, 615655.
584

fiDomain Function: Dual-Space Model

Turney, P. D. (2008b). uniform approach analogies, synonyms, antonyms, associations. Proceedings 22nd International Conference Computational
Linguistics (Coling 2008), pp. 905912, Manchester, UK.
Turney, P. D., & Littman, M. L. (2005). Corpus-based learning analogies semantic
relations. Machine Learning, 60 (13), 251278.
Turney, P. D., Littman, M. L., Bigham, J., & Shnayder, V. (2003). Combining independent
modules solve multiple-choice synonym analogy problems. Proceedings
International Conference Recent Advances Natural Language Processing
(RANLP-03), pp. 482489, Borovets, Bulgaria.
Turney, P. D., & Pantel, P. (2010). frequency meaning: Vector space models
semantics. Journal Artificial Intelligence Research, 37, 141188.
Utsumi, A. (2009). Computational semantics noun compounds semantic space model.
Proceedings 21st International Joint Conference Artificial Intelligence
(IJCAI-09), pp. 15681573.
Veale, T. (2004). WordNet sits SAT: knowledge-based approach lexical analogy.
Proceedings 16th European Conference Artificial Intelligence (ECAI 2004),
pp. 606612, Valencia, Spain.
Widdows, D. (2008). Semantic vector products: initial investigations. Proceedings
2nd Symposium Quantum Interaction, Oxford, UK.

585

fiJournal Artificial Intelligence Research 44 (2012) 196

Submitted 01/12; published 05/12

C OLIN: Planning Continuous Linear Numeric Change
Amanda Coles
Andrew Coles
Maria Fox
Derek Long

AMANDA . COLES @ KCL . AC . UK
ANDREW. COLES @ KCL . AC . UK
MARIA . FOX @ KCL . AC . UK
DEREK . LONG @ KCL . AC . UK

Department Informatics, Kings College London,
Strand, London WC2R 2LS, UK

Abstract
paper describe COLIN, forward-chaining heuristic search planner, capable reasoning COntinuous LINear numeric change, addition full temporal semantics
PDDL 2.1. work make two advances state-of-the-art terms expressive reasoning capabilities planners: handling continuous linear change, handling duration-dependent effects combination duration inequalities, require tightly coupled temporal numeric reasoning planning. COLIN combines FF-style
forward chaining search, use Linear Program (LP) check consistency
interacting temporal numeric constraints state. LP used compute bounds
values variables state, reducing range actions need considered
application. addition, develop extension Temporal Relaxed Planning Graph heuristic CRIKEY 3, support reasoning directly continuous change. extend range task
variables considered suitable candidates specifying gradient continuous numeric
change effected action. Finally, explore potential employing mixed integer programming tool optimising timestamps actions plan, solution
found. support this, contribute selection extended benchmark domains
include continuous numeric effects. present results COLIN demonstrate scalability
range benchmarks, compare existing state-of-the-art planners.

1. Introduction
considerable progress development automated planning techniques
domains involving independent temporal metric conditions effects (Eyerich, Mattmuller,
& Roger, 2009; Coles, Fox, Long, & Smith, 2008a; Gerevini, Saetti, & Serina, 2006; Edelkamp,
2003; Coles, Fox, Long, & Smith, 2008b). development powerful heuristics propositional
planning shown offer benefits solution extended planning problems, including
planning uncertainty (Palacios & Geffner, 2009), planning numbers planning
time. However, combination integration metric temporal features, metric
quantities change time-dependent ways, remains challenge received relatively little
attention.
Interaction time numbers planning problems occur many ways.
simplest case, using PDDL 2.1 (Fox & Long, 2003), numeric effects actions updated
instantaneously, start end points actions known (and fixed)
point action execution. corpus domains past International Planning Competitions
adhere restrictions. Time numbers interact least two complex ways. First,
actions variable, possibly constrained, durations (instantaneous) effects
c
2012
AI Access Foundation. rights reserved.

fiC OLES , C OLES , F OX & L ONG

actions depend values durations. allows domain models capture effects
processes discretised step effects, adjusted according demands specific problem
instances. Second, effects actions considered continuous across execution,
values metric variables time point depend long continuous effects
acting them.
example, problem sand loaded lorry modelled amount
sand loaded depends time spent loading. first approach capture increase
quantity loaded sand step function applied end loading action. second
approach, process loading sand modelled continuous linear function time
spent loading, amount sand lorry observed point throughout
loading process. safety device must engaged lorry three-quarters
full, second models allow planner necessary access
underlying process behaviour make good planning choices integrate action
solutions. alternative models exploiting duration-dependent effects split loading
action two parts around time point safety device must engaged,
alternatives become complicated relatively modest changes domain.
Continuous change forms common many important problems. include: energy management, consumption replenishment restricted continuous resources
fuel, tracking progress chemicals storage tanks chemical plants, choreographing robot motion execution tasks, managing efficient use time.
cases, model using discrete time-independent change adequate planning. However, discretisation always practical: find reasonable solution (or, indeed, find one all) identifying
appropriate granularity discretisation non-trivial, perhaps requiring range choices
fine-grained make discrete model infeasibly large. cases, numeric
change cannot appropriately discretised, unavoidably necessary access
values numeric variables execution actions, order manage interactions
numeric values.
paper present planner, COLIN, capable reasoning variable, durationdependent, linear change linear continuous numeric effects. key advance COLIN makes
able reason time-dependent change use linear programs combine metric temporal conditions effects representation. COLIN satisficing
planner attempts build good quality solutions complex class problems. Since COLIN
forward-searching planner requires representation states, means compute progression states heuristic function guide search path initial goal
state. COLIN built planner CRIKEY 3 (Coles, Fox, Long et al., 2008a). However, CRIKEY 3
requires numeric change discrete cannot reason continuous numeric change, duration dependent change (where duration actions fixed state action
begins). able reason successfully problems characterised continuous change, coping efficiently wide range practical problems inspired real applications,
major contribution made COLIN.
organisation paper follows. Section 2 explain features PDDL 2.1
COLIN handle, contrast repertoire CRIKEY 3. Section 4 define
problem addressed COLIN. Section 5 outline background temporal
metric planning supports COLIN, before, Section 6, describing details foundations COLIN lie CRIKEY 3. COLIN inherits representation states CRIKEY 3,
2

fiC OLIN : P LANNING C ONTINUOUS C HANGE

well machinery confirming temporal consistency plans basis
heuristic function. Section 7 describe systems literature addressed similar
hybrid discrete-continuous planning problems COLIN designed handle. Section 8
explains state progression extended COLIN handle linear continuous change, Section 9 describes heuristic guides search solutions. Section 10 consider several
elements COLIN improve efficiency plan quality, without affecting fundamental
behaviour planner. Since time-dependent numeric change little explored,
benchmarks existence allow full quantitative evaluation. therefore present
collection continuous domains used analysis, show COLIN
fares these. appendix containing explanations technical detail detailed
summaries background work COLIN depends, ensures paper complete
self-contained.

2. Language Features C RIKEY 3 COLIN
COLIN builds CRIKEY 3 handling continuous features PDDL 2.1. C RIKEY 3 restricted management discrete change, COLIN handle full range linear continuous numeric effects. metric functions PDDL 2.1 repertoire COLIN
scale-up scale-down, non-linear updates, general form plan metrics. Managing plan metrics defined terms domain variables remains challenge planning
yet fully confronted contemporary planner. COLIN handle restricted
form quality metric, exploits instrumented variable called total-cost. allows
COLIN minimise overall cost shortest plan find using total-time (the default
metric used temporal planners).
common CRIKEY 3, COLIN cope Timed Initial Literals, important feature
introduced PDDL 2.2 (Hoffmann & Edelkamp, 2005). PDDL 2.1 backward compatible
McDermotts PDDL (McDermott, 2000) therefore supports ADL (Pednault, 1989). COLIN
handle full ADL, deal restricted form conditional effect seen
airplane-landing problem described section 11. restricted form allows cost action
dependent state applied. general forms conditional effect cannot
handled.
collection features, COLIN able fully manage discrete continuous
numeric change occur directly result actions. PDDL + (Fox & Long, 2006)
supports modelling continuous change brought exogenous processes events.
triggered actions, model independent continuous behaviour brought
world rather planners direct action. key additional features PDDL +
support processes events. COLIN handle features restricted
management continuous change expressed durative action device.
detailed explanations syntaxes semantics PDDL 2.1 PDDL +, including
semantics implementations state representation state progression must constructed, readers refer work Fox Long (2003, 2006).
3

fiC OLES , C OLES , F OX & L ONG

Language
PDDL 2.1
PDDL 2.1

Language Feature
Numeric conditions effects
Continuous numeric effects

C RIKEY 3
yes


COLIN
yes
yes

PDDL 2.1

PDDL 2.1

General plan metrics
Use total-cost
Assign (to discrete variables)
Scale-up/down
#t
Durative actions



yes


yes


yes
yes

yes
yes

PDDL 2.1

Duration inequalities

limited

yes

PDDL 2.2

TILs
Conditional Effects
ADL

yes



yes
partial


PDDL 2.1
PDDL 2.1
PDDL 2.1
PDDL 2.1

PDDL
PDDL

Comment
Basic treatment follows Metric-FF
Modification state representation
Modification heuristic

Section
Appendix B
Section 8
Section 9

Limited form
Treatment follows Metric-FF

Section 10

continuous effects
Includes required concurrency
COLIN handles
duration-dependent effects

limited effects

Section 6
Appendix C
Sections 8 9
Section 6
Section 10

Table 1: Language features handled CRIKEY 3 COLIN.

3. Motivation
number accounts planning successfully applied real problems,
frequency applications reported increasing. following examples involve domains hybrid discrete-continuous dynamics. dynamics typically dealt
discretising time, packaging continuous numeric effects step functions, integrating
propositional planning techniques specialised solvers. examples hybrid
discrete-continuous reasoning could exploited improve plan quality solution time.
Operations refineries (Boddy & Johnson, 2002; Lamba, Dietz, Johnson, & Boddy, 2003)
chemical plants (Penna, Intrigila, Magazzeni, & Mercorio, 2010), continuous
processes reflect flows materials, mixing chemical reactions, heating cooling.
Management power thermal energy aerospace applications power management critical, management solar panel arrays International Space
Station (Knight, Schaffer, & B.Clement, 2009; Reddy, Frank, Iatauro, Boyce, Kurklu, AiChang, & Jonsson, 2011). example, Knight et al. (2009) rely high-fidelity power
model (TurboSpeed) provide support reasoning continuous power supply
different configurations solar panels. Power management critical problem
space applications (including planetary rovers landers, inspiring temporal-metriccontinuous Rovers domain used one benchmark evaluation domains Section 11).
Chien et al. (2010) describe planner used support operations Earth Observing 1 (EO1), management thermal energy generated instruments sufficiently important on-board planner uses (highly constrained) CPU cycles model
track value. EO-1 inspires temporal-metric-continuous Satellite benchmark described
Section 11.
Management non-renewable power contexts, battery powered devices.
battery management problem described Fox et al. (2011) relies non-linear model,
4

fiC OLIN : P LANNING C ONTINUOUS C HANGE

COLIN must currently reduce discrete linear approximation, coupled iterated validation solution refinement, order optimise power use. Battery management
example continuous problem cannot solved continuous dynamics
removed.
Assignment time-dependent costs Aircraft Landing domain (Dierks, 2005),
continuous processes govern changing costs use runway landing
time deviates optimal landing time aircraft. problem inspires
Aircraft-Landing benchmark domain described Section 11.
Choreography mobile robotic systems: many cases, operations robotic platforms
involve careful management motion alongside tasks, continuous motion
robot constrains accessibility specific tasks, inspection observation.
Existing examples hybrid discrete-continuous planning models reasoning problems kind include work using flow tubes capture constraints continuous
processes (Leaute & Williams, 2005; Li & Williams, 2008). Problems involving autonomous
underwater vehicles (AUVs) inspired temporal-metric-continuous AUV benchmark presented Section 11.

4. Problem Definition
COLIN designed solve class problems temporal metric, feature linear
continuous metric change. refer class temporal-metric-continuous problems,
contains substantial subset problems expressed PDDL 2.1.
step towards class temporal-metric-continuous problems, recall definition
simple temporal-metric planning problem one time-dependent metric
change. Simple temporal-metric problems represented tuple hI, A, G, i, where:
initial state: set propositions assignment values set numeric
variables. Either sets may empty. notational convenience, refer
vector numeric values given state v.
A, set actions, hdur , pre ` , eff ` , pre , pre , eff i, where:
pre ` (pre ) start (end) conditions a: state starts (ends),
conditions must hold (for detailed account subtleties semantics
action application, see Fox & Long, 2003).
eff ` (eff ) start (end) effects a: starting (ending) updates world state
according effects. given collection effects eff x , x {`, a}, consists of:
eff
x , propositions deleted world state;
eff +
x , propositions added world state;
eff nx , effects acting upon numeric variables.
pre invariant conditions a: must hold every point open interval
start end a.
dur duration constraints a, calculated basis world state
started, constraining length time pass start end
a. refer special parameter ?duration, denoting duration a.
5

fiC OLES , C OLES , F OX & L ONG

G, goal: set propositions conditions numeric variables.
optionally , metric optimisation function, defined function values numeric
variables end plan, special variable total-time, denoting makespan
plan.
solution problem time-stamped sequence actions, associated durations,
transforms initial state state satisfying goal, respecting conditions imposed.
durations actions must specified explicitly, since possible action specifications
satisfied different duration values.
PDDL 2.1 numeric conditions used pre ` , pre , pre , dur G expressed
form:
hf (v), op, ci, op {, <, =, >, }, c <
v vector metric fluents planning problem, f (v) function applied
vector numeric fluents c arbitrary constant. Numeric effects used eff ` eff
expressed as:
hv, op, f (v)i, op {=, +=, =, -=, =}
restricted form numeric expressions set expressions Linear Normal Form (LNF).
expressions f (v) weighted sum variables plus constant, expressible
form w v + c, vector constants, w. notable consequence permitting dur take
form set LNF constraints ?duration ?duration need evaluate single
fixed value. instance, may constrain value ?duration lie within range values,
e.g. (?duration v1 ) (?duration v2 ), numeric variables v1 v2 . Restricting
conditions effects use LNFs allows metric expressions captured linear
program model, fact exploit COLIN.
class temporal-metric problems extended temporal-metric-continuous problems
two additions:
1. action described additional component: set linear continuous
numeric effects, cont, form hv, ki, k <, denoting increases v rate k
per unit time. corresponds PDDL 2.1 effect (increase (v) (* #t k)).
2. start end effects actions (eff n` eff na may, additionally, include parameter
?duration, denoting duration action, hence written:
hv, op, w v + k.(?duration) + ci s.t. op {+=, =, -=}, c, k <
temporal-metric-continuous problems relationship time numbers complex temporal-metric problems. first extension allows value variable v depend
length time elapsed since continuous effect acting upon began. second extension implies that, ?duration fixed, value variables depend duration
assigned action. fact , planners allow literal ?duration appear effects,
even actions value parameter constrained take single fixed value
duration constraint (e.g. (= ?duration 10)). typical idiom name intended value
duration metric fluent initial state (e.g. (= (durationOfAction) 10)) use
fluent effects.
6

fiC OLIN : P LANNING C ONTINUOUS C HANGE

(:durative-action saveHard
:parameters ()
:duration (= ?duration 10)
:condition
(and (at start (canSave))
(over (>= (money) 0)))
:effect
(and (at start (not (canSave)))
(at end (canSave))
(at start (saving))
(at end (not (saving)))
(increase (money) (* #t 1))))

(:durative-action lifeAudit
:parameters ()
:duration (= ?duration (patience))
:condition
(and (at start (saving))
(at end (boughtHouse))
(at end (>= (money) 0)))
:effect (and (at end (happy)))))

(:durative-action takeMortgage
:parameters (?m - mortgage)
:duration (= ?duration (durationFor ?m))
:condition
(and (at start (saving))
(at start (>= (money) (depositFor ?m)))
(over (<= (money) (maxSavings ?m))))
:effect
(and (at start (decrease (money) (depositFor ?m)))
(decrease (money) (* #t (interestRateFor ?m)))
(at end (boughtHouse))))

Figure 1: Actions Borrower Domain.

Temporal-metric-continuous problems form significant subset problems expressible
PDDL + language (Fox & Long, 2006), including linear continuous change within durative
actions. problems include non-linear continuous change, explicitly represent
events processes, although use certain modelling tricks capture similar behaviours.
4.1 Example Problem
running example temporal-metric-continuous domain use problem shown Figure 1. this, Borrower Domain, borrower use mortgage buy house. domain
simplified order focus attention key aspects continuous reasoning proposed realistic application. Furthermore, domain exploit variable duration actions,
even though ability handle key feature COLIN. example illustrates required
concurrency, means interesting interactions multiple actions affecting single continuous variable, allows us demonstrate differences alternative heuristics described
Section 9. Management required concurrency also key feature COLIN, domains
variable durations discussed later paper.
domain, obtain mortgage necessary appropriate active savings plan
able lay deposit. conditions achieved saving hard, action
cannot applied parallel itself, preventing borrower building capital
arbitrarily high rate multiple parallel applications saveHard. sake example
restrict saving periods durations 10 years produce interesting interactions
7

fiC OLES , C OLES , F OX & L ONG

(:objects shortMortgage longMortgage - mortgage)
(:init (= (money) 0)
(canSave)
(= (patience) 4)
(= (depositFor shortMortgage) 5)
(= (durationFor shortMortgage) 10)
(= (interestRateFor shortMortgage) 0.5)
(= (maxSavings shortMortgage) 6)
(= (depositFor longMortgage) 1)
(= (durationFor longMortgage) 12)
(= (interestRateFor longMortgage) 0.75)
(= (maxSavings longMortgage) 6))
(:goal (and (happy)))
(:metric minimize (total-time))

Figure 2: example problem Borrower Domain.

durations mortgages sample problem. person starts saving tied
10-year savings plan.
constraint able start mortgage leads required concurrency saving
taking mortgage. effects saving repaying interest therefore combine yield
different linear effects value money variable, saving action requires
variable remain non-negative throughout duration saveHard action. Furthermore,
order qualify tax relief, mortgage carries maximum allowed level savings throughout
mortgage (which prevents mortgage taken late savings plan). Finally,
lifeAudit action places constraint gap end saving action
point mortgage completed (and also ensures borrower end
debt). action acknowledges borrowers happy manage complete
mortgages within short periods (limited patience) save hard.
simple problem instance consider shown Figure 2. Two possible solutions
shown Figure 3. first solution borrower takes longer mortgage,
advantage start earlier requires lower deposit. Money rises rate 1
first part saving action, decreases 1 mortgage starts. rises rate
0.25 (the difference saving mortgage rates) saving action concludes,
continues decrease rate 0.75 mortgage ends. life audit action must start
saving action cannot end end mortgage action. second solution
borrower takes shorter mortgage, cannot start early requires much larger
deposit. consequence, life audit cannot start first saving action: mortgage
finishes late included inside life audit beginning within first saving action. meet
initial condition life audit, borrower must therefore perform second saving action
follow first. Clearly first solution preferable since interested minimising
makespan.
8

fiC OLIN : P LANNING C ONTINUOUS C HANGE

money

12 units
1 unit
takeMortgage longMortgage
10 units
saveHard
lifeAudit
4 units

money

10 units
takeMortgage shortMortgage
5 units
10 units

10 units

saveHard

saveHard
lifeAudit
4 units

Figure 3: Possible solutions Borrower problem.

5. Background Metric Temporal Planning
recent work discrete numeric planning built ideas introduced planner MetricFF (Hoffmann, 2003). discrete numeric planning problem introduces numeric variables
planning domain hold real numeric value (or undefined, yet
given value). Actions conditions expressed terms variables, effects
act upon them. provide heuristic guidance, Metric-FF introduced extension relaxed
planning graph (RPG) heuristic (Hoffmann & Nebel, 2001), Metric RPG heuristic, supporting
computation relaxed plan problems involving discrete numeric change.
propositional RPG heuristic, performs forwards-reachability analysis delete effects
actions relaxed (ignored). numeric effects, ignoring decrease effects always
relax problem, conditions require variable hold value less given constant.
Thus, reachability analysis extends forwards, upper- lower- bounds values
numeric variables computed: decrease effects effect upon upper bound increase
effects effect upon lower bound, assignment effects replace value upper
(lower) bound incumbent lower (greater) value (respectively) would
assigned. Deciding whether precondition satisfied given layer performed (optimistically)
9

fiC OLES , C OLES , F OX & L ONG

basis these: condition w v c1 , optimistically high value w v
computed using upper bound fluent v assigned value v corresponding
weight w positive, or, otherwise, using lower bound.
alternative use Metric RPG proposed LPRPG (Coles, Fox, Long et al.,
2008b), linear program constructed incrementally capture interactions
actions. approach restricted actions linear effects, general Metric-FF,
provides accurate heuristic guidance handling metric problems perform
significantly better problems metric resources must exchanged one another order
complete solution.
Numeric planning also gives opportunity define metric optimisation functions terms
metric variables within problem description. example, objective minimise fuel consumption defined domains quantity fuel available metric variable.
optimisation function also include special variable total-time, representing makespan
(execution duration) plan. planners restricted weighted sum across variables
(although PDDL 2.1 syntax allows unrestricted expression across variables). general,
planners yet capable optimising metric functions effectively: task finding plan
remains difficult. However, planners attempt optimise functions,
notable LPG (Gerevini & Serina, 2000) (and, domains numeric effects
count action cost, LAMA, due Richter & Westphal, 2010).
Although introduction PDDL 2.1 led increased interest temporal planning, earlier
work planning time influential. IxTeT (Ghallab & Laruelle, 1994) introduced
chronicles, consisting temporal assertions constraints set state variables, timelines chronicles single state variables. Timelines since widely used
planners followed different trajectory development led PDDL family languages (Pell, Gat, Keesing, Muscettola, & Smith, 1997; Frank & Jonsson, 2003; Cesta,
Cortellessa, Fratini, & Oddi, 2009). IxTeT also pioneered use many important techniques,
including simple temporal networks linear constraints.
language introduced planner Temporal Graph Plan (TGP) (Smith & Weld, 1999)
allowed (constant) durations attached actions. semantics actions required
preconditions, pre, true entire duration action, effects actions,
eff, become available instantaneously ends. values affected variables treated
undefined inaccessible execution, although intended semantics (at least TGP)
values considered unobservable intervals and, therefore, plans
conformant respect possible values variables intervals. GP
solves problems using temporally extended version Graphplan planning graph (Blum
& Furst, 1995) reason temporal constraints. temporal heuristic effective form
temporal planning developed Haslum Geffner (2001) Vidal Geffner (2006)
explored constraint propagation approach handling problems.
Even using expressive temporal model defined PDDL 2.1, many temporal planners make use restricted TGP semantics, exploiting simplification PDDL 2.1 encoding
known action compression. compression performed setting pre weakest
preconditions actions, eff + (eff ) strongest add (delete) effects. propo1. Conditions w v c rewritten form negating sides. Further, stating w v = c
rewritten pair conditions, w v c (w v) c

10

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Action
Q, P

P



P
Action B
R
P

R

Q,S

Action C

Action


T, G

Ordering achiever precondition
Ordering deleter precondition

Figure 4: problem SAPA.
sitional case, terms action representation introduced earlier, are:
pre = pre ` ((pre pre ) \ eff +
`)

+
eff + = (eff +
` \ eff ) eff
+

+
eff = ((eff
` \ eff ` ) eff ) \ eff

Many modern temporal planners, MIPS - XXL (Edelkamp & Jabbar, 2006) earlier versions LPG (Gerevini & Serina, 2000), make use action compression technique. However,
applying compression lead incompleteness (Coles, Fox, Halsey, Long, & Smith, 2008)
(in particular, failure solve certain temporal problems). issues surrounding incompleteness
first discussed reference planner CRIKEY (Fox, Long, & Halsey, 2004) and, later,
problem structures causing said introduce required concurrency (Cushing, Kambhampati, Mausam, & Weld, 2007). Borrower domain one example problem
compression prevents solution. lifeAudit takeMortgage actions initial
preconditions satisfied inside interval saveHard action, since action
adds saving start, deletes end.
Required concurrency critical ingredient planning continuous effects,
change occurs change occurs important throughout execution actions. order avoid producing poor quality plans or, indeed, excluding possible solutions, must allow
concurrency actions wherever problem description permits it. nave extension
compression approach would discretise continuous numeric change step function effects
occurring ends relevant actions, precluding possibility managing interaction
numeric variables execution actions continuous effects. therefore build
approach planner capable reasoning required concurrency. Borrower domain, mortgage action must overlap saving action, cannot early (to meet
deposit requirement) late (to meet maximum savings constraint ensure
life audit performed early possible). example illustrates, problems include
reasoning continuous linear change typically also require concurrency.
Several planners are, currently, capable reasoning PDDL 2.1 startend semantics,
opposed relying compression approach. earliest PDDL 2.1 planner reasons successfully semantics VHPOP (Younes & Simmons, 2003), partial-order planner.
11

fiC OLES , C OLES , F OX & L ONG

planner depends heuristic guidance based relaxed planning graph used
FF, guidance fail problems required concurrency. Nevertheless, search space
explored VHPOP includes interleavings action start end points allow solution
problems required concurrency. V HPOP suffers problems encountered
earlier partial-order planners performance scales poorly many domains. PSYS (Garrido,
Fox, & Long, 2002; Garrido, Onainda, & Barber, 2001) Graphplan-inspired planner
produce plans domains required concurrency. Time represented successive layers
graph, using uniform time increment successive layers. approach similar way
TGP uses plan graph represent temporal structure, TPSYS supports model actions
separates start end effects actions dictated PDDL 2.1 semantics.
Another planner adopts Graphplan-based approach temporal planning LPGP (Long
& Fox, 2003a), case time successive layers variable. Instead using layers
graph represent passage fixed-duration increments time, used represent
successive happenings time points state changes occur. time successive state changes allowed vary within constraints imposed action durations whose end
points fixed particular happenings. linear program constructed, incrementally, model
constraints solution program interleaved selection action choices.
approach suffers weaknesses Graphplan planner: exhaustive iterative
deepening search impractical large problems, computation storage mutex relations becomes expensive larger problems. Nevertheless, LPGP provides useful approach
treatment PDDL 2.1 durative actions, splitting end points treated
instantaneous snap actions. solution (original) planning problem expressed
terms these, subject four conditions:
1. start snap-action paired end snap-action (and end applied without
corresponding start applied earlier);
2. start end action, invariants action pre respected;
3. actions must currently executing state considered goal state;
4. step plan occurs preceding step, time start end
action respect duration constraints.
APA (Do & Kambhampati, 2003) one earliest forward-search planners solve temporal PDDL 2.1 problems. works priority queue events. durative action started
end point queued time future executed. choice points
planner include starting new action, also special wait action, advances time
next entry queue, corresponding action end point executed. allows SAPA
reason concurrency solve problems required concurrency. Unfortunately,
search space include necessary interleavings achieve complete search. example,
consider problem illustrated Figure 4. solve problem, action must start, action
B must start early enough allow C complete ends (and deletes P ) late enough
action start B ends end ends. actions required order
allow applied, achieving goal G. SAPA starts action A, queue contain
end A. choices open start B immediately, end early
allow execute successfully, else complete A, advances time far allow B
12

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Light Match
Light
Unused Match

Light
Unused Match

Light

Mend Fuse
Needs Fixing Fuse

Light

Needs Fixing Fuse

Fixed Fuse

Figure 5: Required Concurrency

exploit effect P A, preventing C executed. fact, simpler problem defeats SAPA:
B end condition Q instead end effect G C dispensed
with. However, additional complexity existing example impossible infer
start B examination B alone, timing constraints start B
depends actions C immediately obvious temporal constraints
affect placement B. difficulty adopting waiting approach hard
anticipate long wait next interesting time point depends interaction actions
yet even selected.
different approach forward-search temporal planning explored CRIKEY family
planners (Coles, Fox, Halsey et al., 2008; Coles, Fox, Long et al., 2008a). planners use
action splitting approach used LPGP, work heuristically guided forward search.
heuristics planners use relaxed planning graph starting point (Hoffmann & Nebel,
2001), extend adding guidance temporal structure plan, pruning
choices easily demonstrated violate temporal constraints inferring choices
temporal constraints imply them. planners use Simple Temporal Network model solve
temporal constraints action end points accumulated successive
action choices. Split actions also used extend LPG temporal version respects
semantics PDDL 2.1 (Gerevini, Saetti, & Serina, 2010) (earlier versions LPG use compressed action models described above). Recent work Haslum (2009) explored ways
heuristics temporal planning constructed, remaining admissible.
Temporal Fast Downward (Eyerich et al., 2009), based Helmerts Fast Downward planner (Helmert, 2006), uses approach slight refinement compressed action model,
allowing required concurrency managed. authors demonstrate planner
solve Match problem shown Figure 5. mistakenly claim SAPA cannot solve
problem cannot consider applying action starting ending lighting
match: fact, SAPA apply mend fuse action match lit, much
way done Temporal Fast Downward. problem planners face situations
action must started time last happening, next queued
event: neither planner includes choice search space.
Huang et al. (2009) developed temporal planner exploiting planning-as-SATisfiability
paradigm. uses Graphplan-to-SAT encoding, starting LPGP action-splitting compilation, using fixed time increment successive layers graph. approach
13

fiC OLES , C OLES , F OX & L ONG

adequate problems appropriate time increment identified, possible, general, time-dependent effects domain. Furthermore, approach
ineffective significant difference durations actions, time increment becomes short relative actions. planner produce optimal (makespan)
plans using iterative deepening search. planner combines existing ideas achieve objectives
mainly interest relationship SAT-based approaches temporal
planning, TM - LPSAT discussed below.
C RIKEY 3, planners mentioned, capable solving simple temporal
planning problems described above. restricted management discrete change.
Duration-dependent change cannot handled planners. fact, planners
manage kind reasoning numbers outside durations actions. COLIN therefore
significantly extends competence PDDL-compliant temporal planners.

6. C RIKEY3: Forward-Chaining Temporal Planner
Temporal forward-chaining planners two kinds choices make construction
plans. Firstly, non-temporal case, choice must made actions apply (these
choices considered planning element problem). Secondly, choices must
made apply actions (these seen scheduling choices construction solutions). CRIKEY 3 (Coles, Fox, Long et al., 2008a), temporal forward-chaining planner,
exploits distinction choices, using separate procedures make planning decisions (which actions start end) scheduling decisions (when place actions
timeline). decisions must checked consistency respect existing
temporal constraints confirm actions completely scheduled. section,
briefly describe CRIKEY 3 performs planning scheduling, since architecture forms
basis COLIN work subsequently described paper. Full details temporal
management CRIKEY 3 provided Coles et al.
CRIKEY 3 uses forward-chaining heuristic state-space search drive planning decisions.
makes use Enforced Hill-Climbing (EHC) algorithm introduced FF (Hoffmann & Nebel,
2001) repeated, convenience, Algorithm 1. EHC incomplete, solution cannot
found CRIKEY 3 plans again, using weighted A* search. discuss search described within basic enforced hill-climbing algorithm FF extended perform temporal
planning. order this, number modifications required. particular:
1. get applicable actions(S): planner must reason two actions per durative action,
start action end action, rather applying action immediately considering
finished (as non-temporal case).
2. get applicable actions(S), apply(a, S): invariant conditions durative actions must
maintained throughout execution, requires active invariants recorded
state order prevent application actions conflict them.
3. goal state(S): state goal state (i.e. path solution plan)
actions must completed.
14

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Algorithm 1: Enforced Hill-Climbing Algorithm
Data: P = hA, I, Gi - planning problem
Result: P , solution plan
1 best heuristic evaluate heuristic(I);
2 best heuristic = 0
3
return [];
4 closed {I};
5 open list [hI, []i];
6 open list 6= []
7
hS, P element removed front open list;
8
applic(S) get applicable actions(S);
apply helpful filter (applic(S));
9
10
foreach applic(S)
11
0 apply(a, S);
12
0 6 closed
13
add 0 closed ;
14
P 0 P followed a;
valid plan(P 0 )
15
16
goal state(S 0 )
17
return P 0 ;
18
19
20
21
22
23
24
25

26

h evaluate heuristic(S 0 );
h < best heuristic
open list [hS 0 , P 0 i];
best heuristic h;
break;
else
h <
append hS 0 , P 0 onto open list;

return f ailure;

4. valid plan(P ): temporal (scheduling) constraints candidate plans must respected.
particular, duration constraints durative actions must satisfied. discussed
Section 6.1.
consider modifications turn. First, durative actions compiled
two non-temporal actions. modified version LPGP action compilation (Long & Fox,
2003a) used this, described Coles et al. (2008). durative action a, form
hdur , pre ` , eff ` , pre , pre , eff i, split two non-temporal (in fact, instantaneous) snap
actions form hpre, eff i:
a` = hpre ` , eff `
aa = hpre , eff
15

fiC OLES , C OLES , F OX & L ONG

performing search snap actions, taking appropriate care ensure
constraints satisfied, restrictions expressivity imposed use action compression avoided. becomes possible search plan start end points
different actions coordinated, solving problems required concurrency. price
search space much larger: original action replaced two snap-actions,
length solution plans doubled. circumstances blow-up avoided
identifying actions compression safe (Coles, Coles, Fox, & Long, 2009a), i.e.
use action compression compromise soundness completeness.
approach described Coles et al., actions still split start end snap-actions,
end points compression-safe actions inserted either effects needed
invariants would otherwise violated another action chosen application. consequence,
one search decision point needed per compression-safe action (choose apply start),
rather two. Recent versions CRIKEY 3 COLIN make use restricted action
compression technique search.
split actions start end points, modifications basic search algorithm
needed handle constraints arise consequence. CRIKEY 3 makes use extended
state representation, adding two elements state tuple. resulting state defined
= hF, P, E, i, where:
F represents facts hold current world state: set propositions
currently true, W , vector, v, recording values numeric variables.
P ordered list snap actions, representing plan reach initial state.
E ordered list start events, recording actions started yet finished;
collection temporal constraints actions plan reach F .
purpose start event list E record information currently executing
actions, assist formation sound plans. entry e E tuple hop, , dmin, dmax
where:
op identifier action, start snap-action op` added plan;
index snap-action added plan reach S;
dmin, dmax minimum maximum duration op, determined state
op started.
minimum maximum duration action depend state applied
(e.g. duration recharge action may depend level charge time execution),
durations must computed based state preceding step i. However, given action
started, bounds duration remain fixed. PDDL 2.1 also allows actions durations
constrained conditions hold end action, actions supported
planners.
extended state definition leads corresponding extensions get applicable actions(S).
before, snap-action deemed logically applicable state preconditions pre
satisfied S. However, additional condition must satisfied: effects must violate
16

fiC OLIN : P LANNING C ONTINUOUS C HANGE

active invariants. invariants active given state determined E denote
invariants state event list E as:
inv(S) = e.op.pre
eE

apply end snap-action, aa , required entry e E whose operator entry
op equal a. prevents planner attempting apply ends actions
yet started.
Assuming action, a, found applicable chosen step plan, function
apply(a, S), applied temporally-extended state, S, yields successor 0 = hF 0 , P 0 , E 0 , 0 i.
first two elements updated non-temporal case: F 0 = apply(a, F ), P 0 = P +[a].
obtain 0 , begin setting 0 = . Furthermore, > 0:
0 = 0 { t(i) t(i 1)}
t(i) variable representing time step scheduled executed.
is, new step must come least (a small unit time) preceding step. separation
respects requirement interfering actions must separated least (Fox & Long, 2003),
strictly stronger required actions actually mutually exclusive.
accurate realisation PDDL 2.1 semantics could implemented, would incur cost
offering little apparent benefit. Finally, resulting value E 0 (and whether 0 changed
further) depends whether start end snap-action:
start action a` applied, E 0 = E + [ha, i, dmin, dmax i], dmin dmax correspond lower- upper-bounds duration a, evaluated context
valuation F .
end action aa applied, start entry {e E | e.op = a} chosen, E 0
assigned value E 0 = E \ e. often case one instance
action open, one choice pairing, case multiple instances
action executing concurrently, search branches choice
e. e chosen, final modification made 0 encode duration constraints
action finished:
0 = 0 {e.dmin t(i) t(e.i) e.dmax }
information encoded state currently executing actions, extension
needed goal state(S) minor: state goal state satisfies non-temporal version
goal state(S), event list state, E, empty.
search strategy leads natural way handle PDDL 2.2 Timed Initial Literals (TILs)
directly. Dummy TIL actions introduced, comprising effects TILs time
point, added plan earlier TIL actions already added,
delete invariants open action. special case, TIL actions create
entry E: facts F amended execution. do, however, produce
updated set temporal constraints. snap actions, TIL added step plan,
TIL must fall earlier preceding step. Then, 0 = 0 {ts t(i) t() ts},
17

fiC OLES , C OLES , F OX & L ONG

ts time-stamp TIL prescribed happen, name denoting
start plan t() = 0. seen, constraints ensure TIL occur
appropriate time, step prior TIL must occur it, step
TIL must occur it.
changes described subsection ensure plans produced CRIKEY 3 logically sound: check logical applicability, coupled maintenance E throughout
search, ensures preconditions, either propositional numeric, broken. Use
get applicable actions(S) guarantees actions logically applicable: guarantee adding snap-action plan, judged applicable way, violate
temporal constraints. example, possible preconditions satisfied plan
P = [a` , b` , ba , aa ], P logically sound. However, duration b greater
duration P temporally sound. next section discuss function
valid plan(P ) modified identify reject temporally inconsistent plans.
6.1 Temporal Plan Consistency
state temporally consistent steps [0...n 1] plan, P , reaches
assigned values [t(0)...t(n 1)], representing times execution corresponding
steps, respecting temporal constraints, . checked use valid plan(P 0 ),
called line 15 Algorithm 1 function call trivial non-temporal case,
temporal case serves check temporal consistency plan. state temporal
constraints cannot satisfied immediately pruned search, since extension action
sequence lead solution plan valid.
temporal constraints built CRIKEY 3 state expressed form:
lb t(b) t(a) ub

lb, ub < 0 lb ub

constraints conveniently expressible Simple Temporal Problem (STP) (Dechter,
Meiri, & Pearl, 1989). variables within STP consist timestamps actions,
inequality constraints specified form. Crucially, purposes,
validity STP (and assignment timestamps events therein) determined
polynomial time solving shortest-path problem within Simple Temporal Network (STN),
directed-graph representation STP. event STP represented vertex
STN. additional node t() represent time 0 time first action
plan, t(0), constrained fall within t(). constraint form adds two edges
graph: one b weight ub, one b weight lb. Attempting
solve shortest-path problem t() event yields one two outcomes: either
terminates successfully, providing time-stamp step, terminates unsuccessfully due
presence negative-cost cycle within STN indicating temporal inconsistency (any
schedule would require least one step scheduled itself).
CRIKEY 3, STP used check temporal consistency choices made reach
step S, based temporal constraints must hold plan P reach S,
additional constraints determined E: list actions started, yet
finished. variables vars STP partitioned two sets: variables, t(i)
step P f variables, one f (i) entry hop, i, dmin, dmax E. variables
correspond times steps already added plan, might times
18

fiC OLIN : P LANNING C ONTINUOUS C HANGE

start end points actions. time points might correspond starts actions
yet finished subset actions (only) associated f variables
associated pending end times actions. consistency terminology
introduced CRIKEY 3 (Coles, Fox, Long et al., 2008a), use refer time
next event plan occur (which could execution last actions applied).
time point next choice made, either start new action
completion existing one, therefore seen time associated final state,
S, generated current plan head. ever one timepoint called value
moves forward plan head extends. constraints follows:
, constraining variables ensure temporal consistency steps
plan reach (and include constraints introduced timed initial literals);
{dmin f (i) t(i) dmax | hop, i, dmin, dmax E} is, future
action end point committed (but yet applied), recorded duration
constraint must respected;
{ f (i) t(n 1) | hop, i, dmin, dmax E} is, future action end point
must come last step current plan, ensure future.
t(now ) t(n 1) is, current time (the time next event
plan occur) least last event plan.
Solving STP confirms temporal consistency decisions made far. STP
cannot solved, state pruned: plan induced startend action representation temporally invalid. last two categories constraints particularly important:
without them, pruning could undertaken basis plan P reach S. Including
them, however, allows STP identify cases end point action never added
plan, would lead temporal inconsistency. goal states cannot contain
executing actions (i.e. E must empty), allows CRIKEY 3 prune states earlier
definitely path state end points added plan.
Timed initial literals easily managed STP using dummy TIL actions described
earlier. constraints dummy TIL action already applied included .
dummy TIL action yet occur automatically treated end action yet
applied. Thus, f variable added each, so, last step plan far
constrained come TIL event yet happen.

7. Planning Continuous Numeric Change
challenging variants temporal numeric problems combine two arrive problems time-dependent metric fluents. Although problems exhibiting hybrid discrete-continuous
dynamics studied research communities time, example, verification (Yi, Larsen, & Pettersson, 1997; Henzinger, Ho, & Wong-Toi, 1995; Henzinger, 1996),
timed automata capture exactly kind behaviour, relatively little work
continuous dynamics planning community.
PDDL 2.1 model mixed discrete-continuous change extends propositional state transition model include continuous change state variables. state transition system
19

fiC OLES , C OLES , F OX & L ONG

discrete changes transition instantaneously states. system particular state, continuous change occur state variables time passes. soon discrete
change occurs system changes state. PDDL + (Fox & Long, 2006) extended allow
exogenous events processes (controlled nature) well durative actions. leads
formal semantics based theory Hybrid Automata (Henzinger, 1996). action
causes discrete state change might trigger continuous process. continues time
event triggered leading new state. time later another action might taken.
Early work exploring planning continuous processes includes Zeno system Penberthy Weld (1994), processes described using differential equations. Zeno suffers
limitations partial order planners time, unable solve large
planning problems without significant aid carefully crafted heuristic function. importantly, fundamental constraint behaviour allow concurrent actions apply
continuous effects variable. imposes significant restriction kinds
problems solved, making Zeno much less expressive COLIN. constraint
follows, part, way model requires effects specified differential equations, rather continuous update effects, simultaneous equations must consistent
one another rather accumulating additive effects. authors say must specify
entire continuous behaviour interval [of durative action] semantics insist
continuous behaviours result direct, explicit action.
Another early planner handle continuous processes McDermotts PTOP system (McDermott, 2003), heuristic search planner, using regression-based heuristic. plausible
progression technique used within PTOP guide search sufficiently powerful recognise
interactions could prevent future application actions, thereby restricting scalability
problems form consider here. PTOP competed International Planning Competition 2004, solved small subset problems (although, interestingly,
solved involved expressive combination ADL temporal windows planner
could manage). PTOP interesting variant heuristic forward search approach, since
avoids grounding representation, using approach similar means-ends linear planning approach generate relaxed plan estimates number actions required achieve
goal given state.
7.1 TM-LPSAT
recently, Shin Davis developed TM - LPSAT (Shin & Davis, 2005), based earlier
LPSAT system (Wolfman & Weld, 1999). - LPSAT first planner implement PDDL +
semantics. implemented compilation scheme horizon-bounded continuous
planning problem compiled collection SAT formulas enforce PDDL + semantics,
together associated set linear metric constraints numeric variables. compiled
formulation passed SAT-based arithmetic constraint solver, LPSAT. L PSAT consists
DPLL solver LP solver. SAT-solver passes triggered constraints LP-solver,
hands back conflict sets form nogoods constraints cannot resolved.
solution horizon increased process repeats, otherwise solution decoded
plan. order support concurrency compilation exploits LPGP separation action
start end points. different versions TM - LPSAT exploiting different solvers: LPSAT
MathSAT-04 (Audemard, Bertoli, Cimatti, Kornilowicz, & Sebastiani, 2002)
20

fiC OLIN : P LANNING C ONTINUOUS C HANGE

exploited. novelty TM - LPSAT lies compilation decoding phases, since solvers
well-established systems.
compilation scheme TM - LPSAT implements full PDDL + semantics. Although
includes events processes, specific PDDL +, TM - LPSAT also handle variable duration durative actions, durative actions continuous effects duration-dependent end-effects.
continuous effects concurrent actions quantity two time-points summed
actions active quantity period. Therefore, TM - LPSAT supports concurrent
updates continuous variables.
- LPSAT interesting approach, theory capable solving large class problems
varied continuous dynamics. However, reported empirical data suggests planner
slow unable solve problems requiring plans steps. possible
experiment publicly available implementation system.
7.2 Kongming
Hui Li Brian Williams explored planning hybrid systems (Li & Williams, 2008, 2011).
work focussed model-based control, using techniques based constraint reasoning.
continuous dynamics system modelled flow tubes capture envelopes
continuous behaviours (Leaute & Williams, 2005). dimensions tubes function
time (typically expanding allowed extend), requirement made
successive continuous behaviours must connected connecting start one tube (the precondition surface) cross-section preceding tube; i.e. intersection two spaces must
non-empty. relevant work area development planner Kongming,
described Li Williams.
Kongming solves class control planning problems continuous dynamics. based
construction fact action layers flow tubes, within iterative plan graph structure
introduced Graphplan (Blum & Furst, 1995). graph developed, every action produces
flow tube contains valid trajectories develop time. Starting feasible
region, actions whose preconditions intersect feasible region applied reachable states time point computed using state equations system. initial
state system variables single known values. valid trajectory must pass
sequence flow tubes, must also meet constraints specified dynamics actions
selected. mutex relation used Graphplan extended continuous dynamics well
propositional fragment language. graph iteratively extended Graphplan,
search plan conducted successive extension.
plan-graph encoding problem continuous dynamics translated Mixed
Logical-Quadratic Program (MLQP). metric objective functions used planner optimise behaviour defined terms quadratic functions state variables. example
problem considered Li Williams (2008) 2-d representation simple autonomous underwater vehicle (AUV) problem AUV glide, ascend descend avoiding
obstacles. language used version PDDL 2.1 extended enable dynamics encoded.
continuous nature problem lies fact that, continuous action, AUV
one continuous range positions determined control system. Kongming
depends translation planning problems MLQPs constraints describing dynamics problem must linear. Since effects continuous actions involve product rate
21

fiC OLES , C OLES , F OX & L ONG

change time, one values treated variable. Kongming
rate change variable, time discretised, contrasts COLIN rates
change remain constant continuously variable length intervals. discretisation time
Kongming exploited support state updates within plan graph: successive layers graph
separated constant uniform time increment. approach suffers disadvantage
duration plan limited number happenings plan, since solver cannot
realistically solve problems tens layers plan graph.
Kongming support concurrent continuous updates state variable, so,
respect, PDDL 2.1 expressive extended language used Kongming. part
due difficulty resolving precisely semantics dynamics described
actions used Kongming. dynamic constraint specifies limits rate change
specific variable: unclear whether concurrent actions combined taking union
intersection bounds constraint specifies rate change given fluent.

7.3 UPMurphi
One recently developed planner uses PDDL 2.1 reasons continuous processes
UPMurphi (Penna, Intrigila, Magazzeni, & Mercorio, 2009). UPMurphi takes completely different approach considered far. Instead reasoning continuous change directly,
UPMurphi works guessing discretisation iteratively refining solution discretised problem validate original problem specification. iterative driver
coarseness discretisation, well planning horizon, making interestingly different
basic architecture TM - LPSAT.
UPMurphi begins continuous representation problem starts discretising it.
First actions discretised taking specific values feasible ranges. results
several versions action. UPMurphi explores state space, explicitly constructing
current discretisation. Plans constructed using planning-as-model-checking
paradigm (Cimatti, Giunchiglia, Giunchiglia, & Traverso, 1997): heuristic guide
search. plan found validated original continuous model, using
plan validator (Fox, Howey, & Long, 2005). invalid, discretisation refined
search resumes. UPMurphi fails find plan one discretisation starts finer grained
discretisation. Subsequent refinements lead ever denser feasible regions, increasingly
complex construct.
UPMurphi used build partial policies handle uncertainty likely arise
practice execution hybrid control plans. controller table initially synthesised,
consisting (state,action) pairs plan first constructs. However, table might lack
states could visited controller, robust. subsequent step
robustify controller randomly perturbing states finding new paths
new states. perturbed states reachable, probability distribution
used identify likely ones. called safe states. controller table
extended safe (state, action) pairs. controller table, policy, referred
Universal Plan.
22

fiC OLIN : P LANNING C ONTINUOUS C HANGE

7.4 Approaches Continuous Reasoning
completely different way manage continuous quantities model continuous resource consumption production terms uncertainty amount consumed produced.
approach taken HAO* algorithm (Meuleau, Benazera, Brafman, Hansen, & Mausam,
2009) Markov Decision Process (MDP) constructed consisting hybrid states.
state contains set propositional variables also collection distributions resource
consumption production values. states hybrid, standard value iteration approaches cannot used find policies. hybrid AO* approach described used
find best feasible policy. feasible region constructed HAO* continuous distribution
resource values resource considered uncontrollable (unlike Kongming,
assumed executive maintains control values region eventually
chosen).
Planning continuous processes important applications and, many application areas planning, led development systems combine generic planning
technology carefully tuned domain-specific performance achieve necessary combination problem coverage performance. good example work Boddy
Johnson (2002) colleagues (Lamba et al., 2003) planning oil refinery operations. work
uses quadratic program solver, coupled heuristically guided assignment discrete decision
variables (corresponding actions), solve real problems.

8. COLIN: Forward Chaining Planning Continuous Linear Change
section describe CRIKEY 3 extended reason duration-dependent
continuous numeric change, building planner COLIN ( COntinuous LINear dynamics).
decided give planner specific name highlight capabilities. demonstrated Section 4.1, key difference introduced continuous numeric change logical numeric
constraints longer neatly separated temporal constraints: values numeric
variables state depend timestamps durations actions, vice versa. relative
benefits handling temporal numeric constraints together, rather separating out,
apparent motivating domains outlined Section 3 amply rehearsed
paper describing PDDL + (Fox & Long, 2006).
need cope integrated numeric temporal constraints raises number important
issues planning domains. First, checking whether action choice consistent
longer achieved using STP, numeric constraints interact temporal
constraints, STP sufficiently expressive capture this. Second, changing values
numeric variables time brings new challenges determining action applicability:
precondition satisfied immediately following application action, might become
satisfied allowing certain amount time elapse. Finally, need provide
heuristic guidance. cover first two issues section, defer discussion
heuristic guidance next.
8.1 Temporal-Numeric Plan Consistency Linear Programming
begin problem temporal-numeric plan consistency, techniques used dealing
issue also amended use solving issues encountered determining
23

fiC OLES , C OLES , F OX & L ONG

action applicability. Considering definition STP given Section 6.1, make observation STP could equally well written linear program (LP). CRIKEY 3,
STP efficiently solved using shortest-path algorithm. However, observation becomes
important wish reason continuous change numeric resources alongside temporal constraints. case, use LP capture temporal constraints numeric
constraints, including interaction two. describe LP built,
serving replacement valid plan(S) function called search, invokes
STP solver CRIKEY 3. diagram structure LP create shown Figure 6,
plan P = [a0 , ..., an2 , an1 ] reach state S, an1 action recently added
plan. (For simplicity, shows case event queue E empty.)
construction LP begins variables (a subset of) constraints
STP. STP variable ti (the time-stamp (snap) action ai ) corresponding LP variable
stepi (shown across top Figure 6), STP variable ei (for future end action
step i) corresponding LP variable estep . also construct constraints corresponding
total-ordering action steps, STP: step P still sequenced (i.e.
stepi stepi1 n > > 0), future end snap-action later stepn1
(i.e. estepi stepn1 estep variables).
extend LP numeric constraints problem, beginning effects
actions. Since numeric effects discrete continuous, create two additional
vectors variables per step plan. first these, vi , represents values state
variables v immediately prior ai executed (in case step 0, vi equal values
v initial state, I). second, vi0 , contains values v immediately ai executed.
Figure 6, variables v0 enumerated v0 ...vm1 and, similarly, v0 0 shown
0
v00 ...vm1
. avoid proliferation indices index values
time stamp Figure 6, vi ith value v time step corresponding layer
variable appears. use two vectors layer required order represent
discrete changes caused actions: snap-action cause value variable different
immediately execution. represent within LP, action step effect
variable v vi0 = vi 2 . Otherwise, discrete effect hv 0 +=w v + k.(?duration) + ci,
constraint introduced define value vi0 :3
vi0 = vi + w v + k.(ce(i) cs(i)) + c
functions cs(i) ce(i) denote time-stamp variables corresponding start
end action step i. step end action, ce(i) = step , cs(i)
step variable start action finished step i. Similarly, step initiates action,
cs(i) = step , ce(i) either estep action yet finished or, otherwise,
step variable end action started step i. Therefore, substituting ce(i) cs(i)
?duration captures relationship effect action duration.
2. Note identities implemented efficiently simply introducing unnecessary additional
variable. Similarly, variable subject effects conditions added LP,
introduced becomes relevant.
3. effects using operator -=, i.e. decrease effects, first term right-hand side negated.
assignment effects, operator =, first term right-hand side (i.e. vi ) omitted entirely (the value
v assignment depend value v beforehand).

24

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Metric fluents v 0 v m1
Snapactions 0 n1 corresponding timepoint variables

v0

v0

v0

v0

v0

v0

v0

v0

v1

v1

v1

v1

v1

v1

v1

v1

v

v

v

v

v

v

a0

v3

v3

v3
step 2

v3

v m1

v m1

State 2

State 1

v
n1

step n1

2

v3
...

v m1

2

...

v m1

2

a2

...

v m1

2

...


v m1

step 1

2

...

...

step 0

a1

v3

...

...
State 0

2

v3

v3

v m1

2

v m1
State n

...

2

...

v

Active continuous change affecting (some) variables
Actions cause instantaneous step changes fluent values
Temporal Constraints
Actions sequenced separated:
step i+1 stepi >=
action starts durative action, a, ended action j:
dmin(a) <= step j step <= dmax(a)
Metric Variable Constraints: Step Effects

Metric Variable Constraints: Continuous Effects

Variables updated action effects:

Variables updated active continuous effects:
v j = vj + vj (stepi+1 stepi )

v j state i+1 v j state updated effect
including timedependent stepeffects

values state i+1, v j determined
accumulated effects active continuous effects

Figure 6: Diagrammatic Representation LP Used COLIN. Note subscripts attached
v v 0 fluents diagram indices vector fluents state,
indices step represent different time steps plan. metric fluents
also notionally indexed time step, shown diagram order
avoid clutter.

Continuous numeric change occurs steps plan, rather instant
execution step itself. capture continuous effects, building LP consider
step turn, start plan, recording gradient total (linear) continuous
change acting upon variable v v, v denotes gradient active ai1
execution action ai . restrictions language handled COLIN, described
Section 4, total-order constraints snap-actions, value variable vi
known constant within interval successive actions: continuous change
linear. gradient variable v changed either starting action (initiating
25

fiC OLES , C OLES , F OX & L ONG

adjustment prevailing continuous effect v given dv
dt += k, k <) ending
action (terminating effect initiated start). values constants computed
follows4 :
variables, v0 = 0; is, continuous numeric change active
variable start plan.
ai continuous numeric effect v vi+1 = vi ;
ai initiates continuous numeric effect,

dv
dt

ai terminates continuous numeric effect,

+= k, vi+1 = vi + k;
dv
dt

+= k, vi+1 = vi k;

basis values, add constraints LP:
vi+1 = vi0 + vi+1 (step i+1 step )
Again, distinction vi vi0 important: vi determined basis continuous
change interval steps 1, immediately prior discrete effect
may occur step.
created variables represent values fluents step introduced
constraints capture effects actions them, consider constraints arise
preconditions snap-action, invariants must respected starts
ends actions, constraints durations actions plan.
numeric precondition form hv, {, =, }, w v + ci, must hold order apply step i,
add constraint LP:
vi {, =, }w vi + c
action starting stepi ending stepj , invariants added LP
0
form, vectors variables [vi0 , vj1
] [vi+1 , vj ] (vi v0 j excluded
PDDL 2.1 semantics require invariants action hold end points).
case end action (starting i) yet appeared plan, invariants
imposed vectors variables vi0 onwards: must end future, invariants
must violated step current plan point started.
Finally, add duration constraints. action starting stepi , denote variable
corresponding time finishes ce(i), ce(i) = step j end action
inserted plan step j, ce(i) = estep otherwise (as defined above). Then,
duration constraint a, form h?duration, {, =, }, w v + ci, add constraint:
ce(i) step {, =, }w vi + c
process constructs LP captures numeric temporal constraints govern
plan, interactions them. STP CRIKEY 3, solution LP
contains values variables [step 0 ...step n ], i.e. assignment time-stamps actions
plan. prevent LP assigning variables arbitrarily large (but valid) values, set
4. Variables trivially shown constant (i.e. action effect referring variable)
removed LP replaced throughout values initial state.

26

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Plan Action

Delta value LP Variable
m0 = 0

saveHard start

LP Constraints

step0

=0

m0

=0

m00
m1 = 1
takeMortgage start
m2 =

1
4

= m0

0

step1

step0 +

step0 + 10

m1

= m00 + 1.(step1 step0 )

0

m01

= m1 1

0

step2
m2

lifeAudit start
m3 =

1
4

saveHard end

= step1 +
=

m01

+

1
4 .(step2

step0 + 10 step1 + 12

step1 )

m02

= m2

step3

step2 +

m3

= m02 + 41 .(step3 step2 )

m5 = 0

6

6

step3 +
=

m03



3
4 .(step3

= step1 + 12 step2 + 4

step2 )

m04
lifeAudit end

6

0

= m3

step4
m4

takeMortgage end

0

= step0 + 10 step1 + 12
step2 + 4

m03
m4 = 34

6

= m4

step5

step4 +

= step2 + 4

m5

= m04 0.(step3 step2 )

0

m05

= m5

Table 2: Variables constraints Borrower problem
LP objective function minimise step n , last step plan far.
purposes valid plan(S) function, LP built plan P reach state cannot
solved, prune state search space need consider further:
path legal goal state. way, LP scheduler used replacement
STP order determine plan validity.
8.2 Example: LP Borrower Problem
order illustrate LP construction plan consider example Borrower problem introduced Section 4.1. Recall one solution plan problem following structure:
0:
1:
2:
3:
4:
5:

saveHard start
takeMortgage start longMortgage
lifeAudit start
saveHard end
takeMortgage end longMortgage
lifeAudit end.

LP six-step Borrower solution plan contains variables constraints shown
Table 2. six step variables represent time-stamps six snap-actions plan,
variable represents money saved Borrower. initial state, = 0,
27

fiC OLES , C OLES , F OX & L ONG

hence m0 = 0. Starting saveHard action instantaneous numeric effects, introducing
constraint m00 = m0 (if effect m, instance instantaneous increase
savings k, constraint would m00 = m0 + k). Due invariant condition
saveHard action, savings remain zero, constraint m00 0 added: seen
constraint duplicated mi m0i execution saveHard action,
ensure invariant continues hold. Notice, also, action takeMortgage started,
invariant action (the savings level remains less equal maxSavings cap)
also appears, applies values execution. Additional constraints capture
discrete change connecting value m0i mi . cases example values
equal, one constraint shows discrete effect: m01 = m1 1 captures deduction
deposit caused initiating takeMortgage action.
previously described, temporal constraints LP take two forms. First,
constraints form step i+1 step + , forcing step i+1 follow step , enforcing sequencing snap-actions. Second, duration constraints restrict duration actions, e.g.
step3 = step0 + 10 forces step3 (the end point saveHard) occurs precisely 10 units (the
duration saveHard) step0 , start snap-action.
final constraints consider modelling continuous numeric change. first
constraint type gives value m1 execution saveHard start
execution takeMortgage start. constraint, m1 = m00 + 1.(step1 step0 ), based
value m1 , 1: action currently executing continuous change
saveHard, increases 1 per unit time. second constraint, m2 =
m01 + 41 .(step2 step1 ), based value m2 (1 34 ) = 14 , found adding
active gradients actions started yet finished. illustrates
two actions active linear continuous effects variable simultaneously. Note
saveHard end applied (at step3 ) gradient continuous change (m4 ) becomes
43 active continuous effect takeMortgage action.
Solving temporal constraints problem without considering metric fluents yields
solution step0 = 0, step1 = , step2 = 8 + 2, step3 = 10, step4 = 12 +
step5 = 12 + 2. Unfortunately, proposal violates constraint m01 0, since:
m01 = m1 1 = m00 + 1.(step1 step0 ) 1 = m0 + 1 = 0 + 1 = 1
1. constraint start time takeMortgage action cannot identified
dependent discrete initial effect action, active continuous effect
saveHard action invariant saveHard. simple example illustrates strength
using LP perform scheduling alongside resolution numeric constraints:
timestamps satisfy temporal numeric constraints.
8.3 TemporalNumeric Search
performing state-space search, state, S, snapshot world along plan trajectory, coming one action step another. absence continuous numeric change,
valuations define known precisely: propositions hold, values
numeric variables v. presence continuous numeric change, however,
hold: variable v undergoing continuous numeric change (or subject active durationdependent change) valuations state depend snap-actions applied far,
28

fiC OLIN : P LANNING C ONTINUOUS C HANGE

times snap-actions applied much time passed since
last action applied. Within representation state time-stamps snap-actions
plan fixed (during plan-construction, LP used confirm plan
scheduled subject current constraints), valuation numeric fluents constrained
within ranges determined constraints temporal variables interactions
them.
consequence flexibility commitment values temporal continuously
changing variables, COLIN requires different state representation one used CRIKEY 3.
Rather representing values numeric variables single vector v, use two
vectors: vmax vmin . hold maximum minimum values, respectively,
numeric variable S. computation bounds variables achieved using small
extension LP described Section 8.1. state S, reached plan P (where
last step P ), add another vector variables LP, denoted vnow , another time-stamp
variable, step . variables vnow represent values state variable point
(at time step ) along state trajectory following . numeric variables time-stamp
constrained additional action appended plan:
must follow previous step, i.e. stepnow stepn
must precede coincide ends actions started yet
finished, i.e. estep(i), estep(i) step
variable vnow vnow , compute value based continuous numeric
change:
vnow = vn0 + vnow (stepnow stepn )
Finally, every invariant condition hv, {, =, }, w v + ci action started
yet finished:
vnow {, =, }w vnow + c
LP used find upper lower bounds variables. variables vnow vnow , two calls made LP solver: one objective set maximise vnow ,
one minimise vnow . taken values vmax vmin S. simplest case, variable v subject (direct indirect) continuous duration-dependent
change, value v time-independent, vmax = vmin , value determined
successive application effects actions P , i.e. mechanism used
CRIKEY 3, indeed classical (non-temporal) planning.
Since upper lower bounds value variable, rather fixed assignment, action applicability function, get applicable actions(S), must modified. CRIKEY 3,
action said applicable state preconditions satisfied. COLIN, definition
means numeric precondition satisfied different. preserve completeness,
employ mechanism used metric relaxed planning graphs, discussed detail
Section B. Specifically, numeric precondition w x c, calculate optimistic value
w x using upper bound v x corresponding weight w positive, or, otherwise,
using lower bound. Then, resulting value greater equal c, precondition
considered satisfied. (As before, numeric conditions w x c, equivalent precondition appropriate form obtained multiplying sides inequality 1
29

fiC OLES , C OLES , F OX & L ONG

Plan Action

Delta value LP Variable
m0 = 0

saveHard start

LP Constraints

step0

=0

m0

=0

m00
m1 = 1
takeMortgage start
mnow =

1
4

= m0

0

step1

step0 +

step0 + 10

m1

= m00 + 1.(step1 step0 )

0

m01

= m1 1

0

step1 +

stepnow



mnow

=

m0now

m01

+

1
4 .(stepnow

= mnow

step1 )

6

step0 + 10 step1 + 12
0

6

0

6

Table 3: Variables constraints first stages Borrower Problem
constraints form w x = c replaced equivalent pair conditions w x c,
w x c.)
test applicability action relaxed, serves filter, eliminating actions
certainly inapplicable. instance, precondition + b 3 could satisfied upper
bounds b 2, even assignment timestamps actions within LP attain
= 2 conflicts needed attain b 1. rely subsequent LP consistency check
determine whether actions truly applicable. Nonetheless, filtering applicable actions
basis variable bounds state useful tool reducing number candidates
must individually verified LP.
8.3.1 E XAMPLE U SE B ORROWER P ROBLEM
briefly illustrate way variable constructed used context
Borrower problem. Consider situation selection first two actions (saveHard start
takeMortgage start). LP construction yields constraints shown Table 3. Solving
LP minimum maximum values stepnow gives values 1 + 10 respectively,
meaning earliest time third action applied 1 + latest
10.5 Similarly, solving LP minimum maximum values mnow gives bounds

4 6. information could, principle, constrain actions applied current
state.
8.4 Comments LP Efficiency
LP solved every node search space, important process made
efficient possible. adding variable vectors LP step i, necessary
consider state variable, v, become unstable prior step i, one
following effects acting it:
1. direct continuous numeric change, i.e. changing v according gradient;
5. practice, efficiency, COLIN actually solve LP minimum maximum values stepnow ,
uses variable communicate constraints metric variables state.

30

fiC OLIN : P LANNING C ONTINUOUS C HANGE

2. direct duration-dependent change, i.e. change v dependent duration action
(whose duration non-fixed);
3. discrete change, magnitude change based one variables
falling either previous two categories.
variables meet one conditions omitted LP, values
calculated based successive effects actions applied step i, substituted
constant within LP constraints referring them. reduces number state variables
constraints must added LP also reduces number times LP must
solved state find variable bounds: irrelevant variables eliminated
vector vnow . similar simplification that, applying plan a0 ...an1 reaches state
vmin = vmax , continuous numeric change acting v, v become stable, i.e.
value independent times assigned preceding plan steps. case, first
step k v becomes unstable, value v determined simple application
discrete effects, hence v omitted vj , vj0 , n 1 < j.
opportunity exploit LP solved state similar solved
parent state: represents plan, extra snap-action appended end.
lower bounds time-stamp variables LP therefore based values computed
parent states. Suppose state expanded reach state 0 applying snap action, a,
step plan. point, LP corresponding plan built solved
objective minimise step . Assuming plan indeed scheduled (if cannot,
0 pruned successors generated it), value objective function
stored 0 lower bound time-stamp a. states subsequently reached 0 ,
stored value used LP lower bound step appending actions plan
constrain hence increase value step , never remove constraints
order allow decrease.
well storing lower bounds time-stamp variables, make use bounds
vmin ,vmax state 0 generating successors it. state reached via plan
length i, applying action leads state 0 new action step i+1 inherits
constraints imposed previously step calculating variable bounds 0 . Therefore,
values vmax vmin serve upper lower bounds (respectively) vi+1 LP
built determine feasibility 0 . Similarly, combine discrete numeric effects
values vmax vmin give bounds v0 i+1 . variable v subject
effect, optimistically large (small) outcome effect computed basis vmax
0 . Otherwise, variables upon
vmin , taken upper (lower) bound vi+1
0
discrete effect, vi+1 = vi .
Finally, presence timed initial literals (TILs) allows us impose stricter bounds
time-stamp variables. step j plan dummy action corresponding TIL time t,
upper bound step , < j, lower bound step k , j < k (or estep
variable) + . Similarly, plan yet contain step corresponding TIL time
t, upper bound step variables . Furthermore, TIL time corresponds
deadline deletes fact p present initial state, never added action,
never reinstated TIL. case:
plan step requires p precondition, step ;
31

fiC OLES , C OLES , F OX & L ONG

estep end action end condition p, estep ;
estep end action invariant condition p, estep t.

9. Heuristic Computation
search algorithms described far paper make use heuristic guide planner
efficiently search space towards goal. introduced necessary machinery
support linear continuous numeric duration-dependent effects turn attention
construction informed heuristic face time-dependent change.
Appendices B C revisit standard Metric-FF Relaxed-Planning Graph (RPG)
heuristic Temporal RPG (TRPG) used CRIKEY 3, provide details approaches reference. depend initial construction reachability graph,
based plan graph introduced Graphplan (Blum & Furst, 1995). graph consists alternating layers facts (f l) actions (al). TRPG, convenience, index layers
earliest time could represent, although still enumerated consecutive integers
finitely many times relevant process construction. section
explain heuristic computation techniques introduced planners modified
reason interacting temporalnumeric behaviour. describe two variants heuristic:
basic version, active continuous change relaxed discrete step changes, refined
variant relaxation replaced careful approximation continuous
values. show, using Borrower example, benefits refined approach.
heuristics based underlying use relaxed plan step-count. use relaxed
plan makespan tie-breaker ordering plans step-count. Step-count dominates
heuristic first priority find feasible solution planning problem means
attempting minimise number choices must made resolved search.
course, emphasis rapidly finding feasible plan compromise quality plan,
particularly problems step-count poorly correlated makespan. Subsequent
attempts improve quality initial feasible solution, either iteratively improving
solution search using bound derived feasible solution prune
search space, possible, consider work.
9.1 Basic Integrated Heuristic Computation Continuous Numeric Effects
first version COLIN (Coles, Coles, Fox, & Long, 2009b) introduced three significant modifications TRPG used CRIKEY 3, order generate heuristic values presence
continuous duration-dependent effects. first modification simply equips heuristic
means approximate effects continuous change.
action continuous effect equivalent dv
dt += k relaxed instantaneous
start effect hv, +=, k dmax (a)i. is, effect changing variable treated
integral effect upper bound duration action applied
start action. ensures behaviour relaxed, contrast to, say,
applying effect end action. dmax (a) calculated point
action added TRPG, based maximum duration constraints refer
variables cannot change time (that is, state-independent).
32

fiC OLIN : P LANNING C ONTINUOUS C HANGE

constraints exist, duration allowed infinite (and variables affected continuous
effects action similarly uninformed bounds).
action discrete duration-dependent effect variable v then, calculating
maximum (minimum) effect upon v (as discussed, non-temporal case, Appendix B), ?duration variable relaxed whichever dmin(a) dmax (a) gives
largest (smallest) effect. Relaxation effect achieved without changing timing,
associated start end action indicated action specification.
second modification affects action continuous numeric effect variable either end precondition invariant refers numeric variable.
invariant end precondition places constraint way process governed
action affect value variable, constraint reflected corresponding upper
lower bounds value variable. Specifically, action decreases v rate k
invariant end precondition v c, upper bound v end action must
least k.(dmin(a) elapsed (a)) + c, elapsed (a) maximum amount time
could executing state evaluated (0 currently executing, otherwise,
maximum entries E). condition ensures variable could achieve
necessary value support application action. might appear strange bound
set higher c, reason relaxation accumulates increase effects ignores
decrease effects assessing upper bound, necessary, end action,
accumulated increases value variable allow outstanding consumption
order still meet c bound end action. corresponding condition
required action increases v rate k, invariant end precondition v c,
lower bound v cannot k.(dmin(a) elapsed (a)) + c. conditions
added explicit additional preconditions aa purposes constructing TRPG.
third modification deals problem constructing appropriate initialisation
bounds numeric variables first layer TRPG. CRIKEY 3 values
initialised actual values metric variables, since values current state
change time passes without actions applied. true COLIN, since
actions started, yet finished, govern process, cause variables
change simply consequence time passing. basic heuristic proposed relies
able integrate continuous numeric change, determine variable bounds fl (0.0)
two stages. First, bounds variable v set according obtained LP
Section 8.3. Then, entry e E, corresponding start action, a,
continuous effect v positive gradient k, upper bound v f l(0.0) increased
k.remaining(e). Here, remaining(e) maximum amount time could elapse
state evaluated future end snap-action paired start event e. maximum
remaining execution time calculated subtracting lower bound amount time
elapsed since start action maximum duration. case
gradient negative, lower bound decreased.
9.2 Refined Integrated Heuristic
Time-dependent change arises two sources: continuous numeric effects, initiated start snapactions, discrete duration-dependent effects apply either end durative actions.
33

fiC OLES , C OLES , F OX & L ONG

purposes refined heuristic described section, treat continuous effects
discrete duration-dependent effects ends actions way, attaching
continuous linear effect acting relevant variable effects appropriate snap-action,
a, denoting set continuous effects g(a). continuous effects, cont(a), initiated
a` , cont(a) g(a` ). is, gradient effects start include continuous
effects a. duration-dependent effects end snap-action aa split effect two
parts:
discrete effect aa , hv, {+=, -=, =}, w v + k.dmin(a) + ci
gradient effect v, added g(aa ). effect defined hv, ki original effect used
operator += = otherwise, hv, ki.
Thus, instantaneously, end aa , effect available assuming smallest possible
duration used. executes greater duration, continuous effect applied
gradient change taken coefficient k ?duration variable
corresponding effect a.
Unfortunately, treatment proposed cannot applied duration-dependent start effects, since effects always available start action, regardless duration. Thus,
employ approach taken basic heuristic used COLIN: calculating maximum (minimum) effect a` affected variable, v, ?duration variable substituted
whichever dmin(a) dmax (a) gives largest (smallest) effect.
collection linear continuous effects, g(a), associated snap-action,
a, adjust construction TRPG. First, identify, variable, v, associated
maximum rate change, vmax (t), following layer al(t). set sum
positive rates change, affecting v, snap-actions al(t):
v max (t) =

X

X

aal(t)

hv,kig(a)

k

definition relies restriction one instance action execute
time. restriction hold, clear finite bound p(a) number instances
action execute concurrently, incorporate calculation v max (t)
follows:
X
X
v max (t) =
p(a)
k
aal(t)

hv,kig(a)

finite bound exists, action could, principle, applied arbitrarily many times
parallel hence set v max (t) = .6 Following layer al(t) v max (t) =
longer need reason upper bound continuous change v since upper bound
v become immediately layer. noted degradation
behaviour will, worst case, lead heuristic behaviour basic heuristic
where, again, arbitrarily many copies action execute concurrently, magnitude
increase decrease effects becomes unbounded. extension heuristic consider
6. note that, experience, presence infinitely self-overlapping actions continuous numeric change
often bug domain encoding: difficult envisage real situation parallel production
unbounded.

34

fiC OLIN : P LANNING C ONTINUOUS C HANGE

continuous effects refined way worsen guidance situation.
remainder section, consider variables whose values modified actions
finite bounds number concurrently executing copies allowed.
Armed upper bound value rate change variable following layer al(t),
deduce maximum value variable time t0 > t, simply applying
appropriate change maximum value variable time t. remaining challenge
decide far advance t0 construction TRPG. construction TRPG
CRIKEY 3 time constrained advance next action end point, depending
whether new facts available following recent action layer (lines 2934 Algorithm 2). order manage effects active continuous processes, add third possibility:
time advance earliest value accumulated effect active continuous change
variable satisfy previously unsatisfied precondition. set preconditions interest
always finite, so, assuming variable subject non-zero effect, bound
relevant advance always defined (or, set preconditions empty, advance required).
compute value time follows. numeric precondition may written
constraint vector numeric variables, v, form w v c, vectors constants w
c. define function ub follows:
X w[i] y[i] w[i] 0
ub(w, x, y) =
w[i] x[i] otherwise
w[i]w

upper bound w v t0 then: ub(w, vmin (t0 ), vmax (t0 )).
earliest point numeric precondition w v c become satisfied
smallest value t0 ub(w, vmin (t0 ), vmax (t0 )) c.
example, suppose action precondition x + 2y z c, w =
h1, 2, 1i (assuming x, z numeric fluents case). Substituting
previous equation yields:
ub(h1, 2, 1i, hx, y, zimin (t0 ), hx, y, zimax (t0 )) = 1.xmax (t0 ) + 2.ymax (t0 ) 1.zmin (t0 )
= 1.(xmax (t) (t0 ) + xmax (t + ))
+2.(y max (t) (t0 ) + ymax (t + ))
1.(z min (t) (t0 ) + zmin (t + ))
(The values x, z based starting points + accounts
instantaneous changes triggered actions al(t).) value t0 produced computation
infinite, maximum possible rate increase expression x + 2y z must zero.7
Otherwise, t0 time new numeric precondition first become satisfied due
active continuous effects and, earlier earliest point action end point
applied, next fact layer TRGP f l(t0 ).
9.2.1 MPROVING B OUNDS VARIABLES FACT-L AYER Z ERO
Previously, setting bounds fact-layer zero could thought consisting two stages:
finding initial bounds using LP then, passage time could cause bounds
diverge due active continuous numeric change, integrating change prior setting
7. find t0 requires simple rearrangement formula extract t0 directly.

35

fiC OLES , C OLES , F OX & L ONG

bounds layer zero TRPG. explicit model numeric gradients planning
graph, reconsider approach. intuition behind new approach
follows:
1. variable v, create associated variable tnow (v) LP, solve LP
minimise value variable.
2. Fixing value tnow (v) lower-bound, maximise minimise value v find
bounds point used bounds v fl (0.0).
3. v > 0 current state, vmax (t) values TRPG offset v or,
similarly, v < 0, vmin (t) values offset.
first steps based ideas described Section 8.3, process subtly
different trying determine bounds v given point time, rather
appear reachable. before, tnow (v) must still come recent plan step
used determine value v. reflected pair constraints:
tnow (v) step
vnow = vi0 + vnow (tnow (v) step )
Additionally, since variable associated single v, rather
appropriate v, constrain if, necessarily, v cannot referred (either
precondition, duration within effect) least certain steps plan, rather
weaker requirement recent step. purposes, observe
actions referring v require, delete add fact p, possible interaction p
require-delete-add form, tnow (v) must come plan step adds p.
formally, require-delete-add idiom holds p p true initial state, action
preconditions/effects p, interaction action p characterised
one following patterns:
+
1. p pre ` (a), p eff
` (a), p eff ` (a)
+
2. p pre (a), p eff
(a), p eff (a)
+
3. p pre ` (a), p eff
` (a), p eff (a)

(An action may exhibit either first two interactions, third.)
LP variable corresponding point p added, denote step p ,
determined one two ways. First, p present state evaluated, step p LP
variable corresponding plan step recently added p. Otherwise, case 4 above,
know p eff +
(a) action currently executing. case, step p LP
variable estep corresponding end a. defined variable, add constraint
LP:
tnow (v) step p +
Solving LP objective minimise tnow (v) finds earliest possible time
v referred to. Then, fixing tnow (v) minimised value, minimise maximise
36

fiC OLIN : P LANNING C ONTINUOUS C HANGE

bounds vnow . gives us bounds v appropriate early possible
actions plan far.
obtained variable bounds LP must, before, account fact
passage time causes bounds change active continuous numeric change. Whereas
integrated change prior TRPG, mechanism handling gradients directly TRPG expansion. Thus, start-event-queue entry e E corresponding
start action, A, continuous effect v positive (negative) gradient k,
add gradient effect upper (lower) bound v TRPG. previously restricted integrated effect e remaining(e), maximum remaining time action
must end, limit long gradient effect active: starts al(0.0) finishes
al(remaining(e)). Then, given fact layer value vmax (t) updated accordingly:
vmax (t)+=

XX

{k | hv, ki g(op(e)) k > 0 remaining(e)}

eE

Similarly, vmin(t) amended account effects hv, ki, k < 0.
9.3 Using Two Variants Integrated Heuristic Borrower Problem
illustrate computation two heuristic functions choice point Borrower
problem. example shows refined heuristic guides planner shorter makespan
plan basic heuristic, improved heuristic information leads selection
better choices helpful actions. Consider situation following execution first action,
saveHard start. Figure 7 (top) shows TRPG relaxed plan constructed using basic
heuristic.
heuristic generates cost state 5: four actions shown relaxed plan,
together extra one end saveHard action already started. relaxed plan
generates two helpful actions, start lifeAudit start takeMortgage short. attempt start lifeAudit action quickly dismissed temporally inconsistent, depending
boughtHouse becoming true ends, helpful action chosen. Unfortunately, action selected interaction saving process deposit
requirement (at least five savings must acquired) forces action start earlier
time 5. constraint invisible TRPG, continuous effect saveHard
abstracted start effect, full ten savings therefore appear available immediately.
plan constructed using short mortgage, introducing second saving action
shown lower plan Figure 3. start short mortgage pushed
late life audit cannot overlap end first saveHard action finish
mortgage action.
lower part Figure 7 shows happens refined heuristic used solve
problem. saveHard action starts before, time heuristic relax
behaviour continuous savings process long mortgage, requires smaller deposit
initiate it, becomes available short mortgage. consequence this, relaxed
plan selects long mortgage, action starts early enough life audit overlap
end end saveHard action. planner correctly guided optimal plan,
shown top Figure 3. crucial difference two heuristics, refined
heuristic able access accurate information value savings timepoints
37

fiC OLES , C OLES , F OX & L ONG

0: saveHard_start

saving

10


lifeAudit_start
takeMortgage_start short

money : [20,20]

money : [ ,10]

saveHard_end

canSave

takeMortgage_start long

10+

10+2
lifeAudit_end

saveHard_start
boughtHouse

happy

takeMortgage_end short

0: saveHard_start

saving

1



5

lifeAudit_start
takeMortgage_start long

money : [ ,t]

money : [0.75t,10]

takeMortgage_start short

12

10

money : [t,10]

12+
lifeAudit_end

saveHard_end

canSave

takeMortgage_end long

boughtHouse

happy

Figure 7: TRPG relaxed plan Borrower problem, following initial execution
saveHard start time 0, constructed using original version COLIN (top
described Section 9.1) revised version (bottom described Section 9.2).
Action layers depicted rounded rectangles fact layers ovals. action
layers labelled times constructed reachability analysis.

start savehard action. leads finer-grained structure TRPG,
seen fact six action layers arrival goal, rather four
case basic heuristic used. estimated makespan final plan 12 + ,
makespan according basic heuristic 10 + 2. basic heuristic leads non-optimal
solution requires extra saveHard action, giving solution makespan 20 + 2,
contrast makespan 12 + optimal plan.
benefit refined heuristic, extra work involved constructing modified
TRPG, better helpful actions chosen makespan estimate therefore accurate. choice similar length plans made based makespan. TRPG, constructed
refined heuristic Borrower problem, even contain short mortgage action
early enough layer considered relaxed plan.
38

fiC OLIN : P LANNING C ONTINUOUS C HANGE

10. Improving Performance
section present two techniques use improve performance COLIN. first
technique, described Section 10.1, generalisation earlier exploitation one-shot actions (Coles et al., 2009a) situation encapsulate continuous processes, leading
faster plan construction problems action types. second technique, described
Section 10.2, exploits LP defines constraints within final plan optimise plan
metric. leads better quality plans many cases.
10.1 Reasoning One-Shot Actions
earlier work (Coles et al., 2009a) observed common modelling device
planning domains leads use actions applied once. call actions
one-shot actions. arise, particular, collection resources
used once. key difference one-shot actions imply TRPG continuous
effects generated one-shot actions lapse certain point reached:
one-shot action continuous numeric effect v, a` first appears action layer
al(t), gradient v due effect finishes, latest, al(t + dmax (a)).
end aa one-shot action duration-dependent effect v, (implicit)
continuous effect acting v finishes, latest, layer al(t + dmax (a))
termination point implied, cases, fact action one-shot.
modify TRPG construction reflect restrictions extending data recorded
action layer include, snap-action action a, maximum remaining execution
time a, denoted rem(t, a). one-shot actions, layer al(t) a` first appears,
rem(t, a` ) = dmax (a), aa first appears, rem(t, aa ) = dmax (a) dmin(a). actions
one-shot rem(t, a` ) rem(t, aa ) initialised . make three minor
changes layer update rules accommodate rem values. First, calculating active
gradient variable v following action layer al(t):
X
X
v max (t) =
p(a)
k
aal(t)|rem(a,t)>0

hv,kig(a)

seen, subset actions execution time remaining considered. Second,
next action layer al(t + t) following al(t), value positive rem decremented
t, amount time elapsed since previous layer. Third, consequence this,
additional criterion must considered calculating time-stamp next fact-layer, t0 ,
described Section 9.2. Since time remaining complete action may expire, may
need insert additional fact layer denote point rem value reaches 0
continuous effects acting one variables need recalculated. time-stamp
earliest layer is:
t0 = + min{rem(t, a) > 0 | al(t)}
One-shot actions exploited still improving upper bound duration
action a. case actions state-dependent duration constraints (i.e. upperbound calculated based variables subjected effects actions), dmax (a) may
39

fiC OLES , C OLES , F OX & L ONG

gross over-estimate duration a. Suppose maximum duration bounded
formula w v + c. layer al(t) a` appears, compute maximum duration
a, started layer, based variable bounds recorded f l(t). could
use value determine bound remaining execution time a. However, future
layer f l(t0 ), variable bounds might changed, beginning al(t0 ), calculating
maximum duration based f l(t0 ), would allowed execute possibly longer period
time, allowing continuous effects persist longer.
remain faithful relaxation, possibility exploiting increased duration
(by starting t0 ) must included TRPG, well allowing possibility start
t, thereby obtaining effects sooner. Therefore, one-shot action allowed start
earliest layer al(t) preconditions satisfied, giving initial maximum duration
dmax (a, t) based fact later f l(t). But, later fact layer f l(t0 ) admits greater duration
(dmax (a, t0 ), value dmax action layer t0 ), remaining execution time
reconsidered. First, simple case, variables duration constraint changed f l(t0 ),
subject active continuous effects. case, apply pair dummy effects
fact layer t00 = t0 + dmax (a, t):
hrem(a` , t00 ) += (dmax (a, t0 ) dmax (a, t))i

hrem(aa , t00 ) += (dmax (a, t0 ) dmax (a, t))i.
Note increase rem values delayed layer t00 because, order benefit
longer duration a, must started layer t0 .
complex case, variables duration constraint changed f l(t0 )
duration also affected continuous effects variables depends on.
situation, subsequent fact layer might admit marginally bigger duration last.
avoid recalculate new duration repeatedly, schedule pair dummy effects
based global, layer-independent, maximum value duration a:
hrem(a` , t00 ) += (dmax (a) dmax (a, t))i

hrem(aa , t00 ) += (dmax (a) dmax (a, t))i.
relaxation weaker might be, efficient compute.
10.2 Plan Optimisation
plan metric specified PDDL 2.1 problem files indicate measure quality
use evaluating plans. metric expressed terms task numeric variables
total execution time plan (by referring variable total-time). use LP
COLIN offers opportunity optimisation plan respect metric: plan
0
consisting n steps, numeric variables vn1
end plan, stepn1
time-stamp final step (i.e. action dictating makespan plan) LP objective
set minimise function these. LP must solved minimise time-stamp
last action (the makespan plan) order arrive lower bound time next
action. However, also solved optimise plan metric.
40

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Although possible consider ways use metric-optimising LP value plan
construction, guide search, focussed much limited, less costly, use:
attempt post hoc optimisation, attempting exploit flexibility temporal structure
final plan optimise plan quality last stage plan construction.
order post hoc optimisation useful, planning problems must property
possible vary quality metric plan scheduling actions occur
different times. possible wide range interesting situations, scheduling aircraft
land close given target time possible, taking images satellites certain times day
view clearer, minimising wasted fuel penalising time elapsing starting
engine plane take off. last represents general class problems
may desirable minimise amount time two activities: different metric
total time taken plan execution. capture interesting cases, first extend
language supported COLIN allow limited subset ADL conditional effects, allow
conditions action executed vary effects action metric value
plan. Second, discuss MILP built, based LP described Section 8.1,
support post hoc plan optimisation.
planner handles conditional effects standard compilation. However, conditional
effects metric variables appear plan quality metric preconditions
actions dealt differently. call variables metric tracking variables
exploit fact rescheduling plan affect values variables without changing
validity plan. example shown Figure 10.2 action land airplane,
conditional effects metric tracking variable total-cost. domain structured
land actions must start beginning plan, end points represent actual
landing times aircraft problem. duration actions set correspond
earliest latest possible points plane could land. seen, propositional
effects action whether plane lands early late: plane landed,
longer flying. However, numeric effects, effects metric tracking variable
total-cost, depend duration action and, particular, whether plane landed
early late. plane lands early, penalty paid certain rate per unit time plane
lands desired target value. plane lands late, fixed cost paid, addition
penalty (at different rate) per unit time plane lands desired target value.
considering action single action, pair conditional effects, planner decide
upon actions needed construct sound plan (in planes landed) whilst
leaving subsequent optimisation phase decision whether plane landed
early, late, time.
general, straightforward exploit LP described Section 8.1 attempt reschedule actions plan optimise value plan metric (provided metric function
linear). However, plan contains actions conditional effects metric tracking variables,
becomes possible exploit representation effects extended LP, using integer
variables, order offer powerful optimisation step. conditional effect either
activated not: introduce 0-1 variable represent case effect.
variable connected corresponding constraints determine whether condition
associated effect true not.
deal two kinds constraints 0-1 variables MILP encoding plan optimisation problem: one special case actions scheduled fixed time-windows
41

fiC OLES , C OLES , F OX & L ONG

(:durative-action land
:parameters (?p - plane ?r - runway)
:duration (and (>= ?duration (earliest ?p)) (<= ?duration (latest ?p)))
:condition
(and
(at start (takeOff))
(over (flying ?p))
(at end (scheduled ?p ?r)))
:effect
(and
(at start (flying ?p))
(at end (landed ?p))
(at end (not (flying ?p)))
(when (at end (< (?duration) (target ?p)))
(at end
(increase (total-cost)
(* (earlyPenaltyRate ?p) (- (target ?p) ?duration)))))
(when (at end (> ?duration (target ?p)))
(at end
(increase (total-cost)
(+ (latePenalty ?p)
(* (latePenaltyRate ?p) (- ?duration (target ?p)))))))
)
)

Figure 8: PDDL Domain Conditional Effects Airplane Landing Problem. literal
takeOff special proposition manipulated dummy action force landing
actions anchored point time.

governed timed initial literals affect whether conditions satisfied
case satisfaction conditions determined status continuous effects
controlled actions plan (so, example, cost action might depend whether
continuously changing value passed threshold time action executed).
cases handled straightforward encoding linkage value
0-1 condition variable corresponding conditions (the details given Appendix D).
also extended conditional effects allow affect ?duration variable
action, similar devices encoding MILP.
MILP solved single final step construction plan, optimising
plan metric quality rescheduling actions best exploit precise timing actions
interaction, limited conditional effects, plan quality.

11. Continuous Linear Benchmark Domains
COLIN one first planners support PDDL 2.1 models featuring continuous linear change
duration-dependent effects8 currently benchmarks available exploit fea8. Specifically, duration-dependent effects depend non-fixed durations.

42

fiC OLIN : P LANNING C ONTINUOUS C HANGE

tures. support evaluation foster future comparisons planners designed
solve problems, produced number domains features9 .
first domains extension Metric Time variant Rovers domain,
2002 International Planning Competition (IPC 2002) (Long & Fox, 2003b). focus
action navigate, responsible moving rover one location another. original
model, discrete effect, start action, decrease energy level rover
8 units, coupled precondition must least 8 units energy available.
replace continuous numeric effect energy, condition energy
must least zero action. duration original action specified 5,
use effect gradient 8/5. Written thus, action net effect conditions:
energy decreased 8 units, must become negative. continuous change models
accurately use power navigate action: whilst power use may actually linear,
closer linear instantaneous. make model still realistic,
introduce new action domain: journey-recharge, shown Figure 9. exploiting
interaction continuous numeric effects variable, use action capture
option rover tilting solar panels face sun whilst navigating two points.
account power use reorienting solar panels, start end action, 0.2
units energy used. benefit consumption that, whilst action executing,
energy rover increased according constant positive gradient. final modification
domain, alter duration constraint existing recharge action. original
encoding, constraint is:
(= ?duration (/ (- 80 (energy ?x)) (recharge-rate ?x))).

forces duration action sufficient restore level charge 80 (full capacity). new formulation, replace = <= duration constraint specifies
maximum duration battery charged: need restored full capacity
every time action applied. Following three modifications, domain used
standard IPC 2002 benchmark problems. addition this, also created
problems considering single rover, issue battery power management much
greater importance.
next domains extension Time variant Satellite domain,
taken IPC 2002. Here, continuous variant domain, make three key changes
domain model. First, original formulation, proposition used indicate whether
power available operate instrumentation given satellite. Switching instrument
required deleted fact, switching added again. Thus,
scope parallel power usage, instrumentation effectively used unit power. Now, use
numeric variable represent power, preconditions effects variable replacing
preconditions effects proposition previously used. Second, exploiting potential
differing power requirements, instruments operated one two modes:
cooled, uncooled. cooled mode, active sensor cooling used reduce sensor noise, enabling
images taken less time. cooling, however, requires additional energy. Third,
finally, compulsory sunrise phase start plan, satellites
9. P DDL domain problem descriptions evaluation tasks available online appendix maintained
JAIR paper.

43

fiC OLES , C OLES , F OX & L ONG

(:durative-action journey-recharge
:parameters (?x - rover ?y - waypoint ?z - waypoint)
:duration (>= ?duration 0.2)
:condition (and (over (moving ?x ?y ?z))
(over (<= (energy ?x) 80))
(at start (>= (energy ?x) 0.2))
(at end
(>= (energy ?x) 0.2))
)
:effect (and (at start (decrease (energy ?x) 0.2))
(increase (energy ?x) (* #t (recharge-rate ?x)))
(at end
(decrease (energy ?x) 0.2))
)
)

Figure 9: journey-recharge action continuous-numeric Rovers domain

move shaded planet, direct sunlight. leads increase
power availability, modelled linear continuous numeric effect attached action, sunrise,
must applied. Interaction effect preconditions powering instruments
ensures operated sooner power available. problem files use
domain slightly modified versions IPC competition problems, updated define power
availability numeric variable encode power requirements cooled uncooled
sensor operation. problems domain characteristics similar
Borrower problem used running example.
exploring use continuous numeric effects, next domain models operations
cooperating Autonomous Underwater Vehicles (AUVs). AUVs move waypoints
underwater perform two sorts science gathering operations. first taking water
sample given waypoint, performed AUV appropriate location,
whose water sample chamber empty. second taking image target interest.
requires two AUVs cooperate: one illuminate target torch, one take
image it. AUV domain inspired problem described Maria Fox
invited lecture 2009 International Conference Automated Planning Scheduling.
data acquired, must communicated ship surface. Satellite
Rovers domains, AUVs energy-constrained finite battery power
power usage actions continuous throughout execution. interesting continuous
numeric aspects domain arise use model drift. introduce variable
record far AUV drifted nominal position, update two ways. First,
activity plan contained within action drift small, positive continuous numeric
effect drifted distance. Second, add localise action sets drifted distance
zero, duration (and hence energy requirements) depending drifted distance prior
application. drifting affects domain actions. simplest case, sample
water take image given location, AUV cannot drifted two metres, hence
introducing need first localise case. interestingly, AUV shining
torch, drifting affects much light falling target. Thus, shine-torch action
AUV ?v three effects amount light falling given target ?t:
44

fiC OLIN : P LANNING C ONTINUOUS C HANGE

start: (increase (light-level ?t) (- 1000 (distance-from-waypoint ?v)))
throughout: (decrease (light-level ?t) (* #t (fall-off)))
end: decrease (light-level ?t) remaining contribution ?v making
illumination.
constant (fall-off) pessimistically derived formul involving inverse-square
law, giving linear approximation decay illumination levels due drift. Then,
take-image action itself, duration function (light-level ?t): less light available, longer requires take image.
final domain use Airplane Landing domain (Dierks, 2005), first posed challenge Kim Larsen invited lecture 2009 International Conference Automated
Planning Scheduling. problem models scheduling landing aircraft airport
runway. plane, three landing times specified: earliest possible landing time,
latest possible landing time, target (desired) landing time. Since time must allowed
airplanes clear runway landed, use runway heavily subscribed resource, possible planes land ideal time. Planes can, therefore,
land early late, incurs penalty. penalty modelled duration-dependent
effect, shown earlier paper (Figure 10.2 Section 10). able construct
set airplane landing problems using real data Edinburgh Airport arrivals board. Results
running COLIN problems reported Section 12.

12. Evaluation
COLIN temporal planner, able solve problems required concurrency, handle
discrete continuous metric variables. first question address costly
extension underlying CRIKEY 3 system allow COLIN manage continuous effects? COLIN
particularly powerful planner general PDDL 2.1 planners similar
expressive power available comparison continuous problems. However, extensions
necessary support continuous reasoning add overhead cost solving problems
continuous effects. compare performance COLIN temporal
planners selection temporal problems without continuous effects (Section 12.1) order
evaluate much overhead paid COLIN setting managing (redundant) structures,
comparison state-of-the-art planners pay price.
move considering performance COLIN problems continuous dynamics. second question is: much improvement obtain using refined
heuristic instead basic heuristic, dealing problems continuous change?
planners discussed Section 7 able scale large complex problems, compare
two versions COLIN. present performances new benchmark problems continuous processes, setting foundation future comparative evaluation alternative approaches
problems.
third question considered concerns quality solutions produced COLIN,
comparison optimal solutions found. COLIN satisficing planner
perform efficiently wide range continuous planning problems, interested
understanding much solution quality must sacrificed order obtain efficiency
achieved COLIN.
45

fiC OLES , C OLES , F OX & L ONG

Finally, consider question: expensive move solving STP (sufficient purely discrete temporal planning) solving LP (necessary handling continuous
effects)? particular, practical solve multiple LPs performing heuristic state evaluations?
Since LP construction solution central architecture COLIN important
relied upon scale appropriately range complexity problems COLIN
expected solve.
following experiments consider large number domains domain variants.
temporal comparisons use Simple Time Time variants Depots, Driverlog, Rovers,
Satellite Zeno, IPC 2002, Airport Pipes-No-Tankage IPC 2004.
Airport variant used Strips Temporal variant.
comparisons basic refined heuristics continuous domains, use
new continuous benchmark domains introduced Section 11: Airplane Landing, Rovers, Satellite
Cooled (the Satellite variant sensor cooling) AUV domain.
post-hoc optimisation experiments use Airplane Landing problem, Cafe domain introduced empirical analysis CRIKEY 2 (Coles, Fox, Halsey et al., 2008), variant
Airport amount fuel burned minimised, version Satellite time
windows, rewards obtained scheduling observations tighter windows.
cases use competition benchmark sets instances available. continuous Rovers Satellite domains used IPC 2002 Complex Time problem sets.
instances work continuous domain variants possible get better makespan plans
them, respecting continuous dynamics, possible instances
solved using discrete domain variants. generated increasing sized instances Airplane Landing domain number planes landed increased (in nth instance
problem, n planes must landed). wrote problem generator AUV domain
increases number AUVs, waypoints goals instances (they range 2 AUVs, 4
waypoints 1 goal, 6 AUVs, 16 waypoints 6 goals). experiments run 3.4GHz
Pentium machine, limited 30 minutes 1GB memory.
12.1 Comparison Existing Temporal Planners
temporal planners actually solve full range temporal problems. already
observed, many temporal planners cannot solve problems required concurrency. Even within
class problems required concurrency, easier problems, solved
left packing actions within plan harder ones possible. left
packing mean actions must executed concurrently actions plan
started time other. property means approach adopted Sapa,
extending forward search include choice either start new action else advance time
earliest point currently executing action terminates, sufficient solve problem.
contrast, problem cannot left packed require possibility advancing time
intermediate point execution action order coordinate correct interleaving
actions it. describe problems requiring temporal coordination. One
planners also handle problems requiring temporal coordination LPG-s (Gerevini
et al., 2010).
therefore compare COLIN LPG-td, LPG-s, Sapa temporal baseline planner developed temporal satisficing track 2008 International Planning Competition. Neither
46

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Depots Simple Time

Driverlog Simple Time
100

Colin Solution Time (s)

Colin Solution Time (s)

100

10

1

0.1

10

1

0.1
LPG-TD used
Temp-Baseline used

0.01
0.01

0.1

1
10
Best Solution Time (s)

LPG-TD used
LPG.s used
Temp-Baseline used
0.01
0.01

100

0.1

Rovers Simple Time

100

Satellite Simple Time
100

Colin Solution Time (s)

100

Colin Solution Time (s)

1
10
Best Solution Time (s)

10

1

0.1

10

1

0.1
LPG-TD used
Temp-Baseline used

0.01
0.01

0.1

1
10
Best Solution Time (s)

LPG-TD used
Temp-Baseline used
0.01
0.01

100

0.1

1
10
Best Solution Time (s)

100

Zeno Simple Time
1000

Colin Solution Time (s)

100

10

1

0.1

0.01
0.01

LPG-TD used
Temp-Baseline used

0.1

1
10
Best Solution Time (s)

100

1000

Figure 10: Comparison time taken solve problems simple temporal planning benchmarks.
COLIN compared best LPG -td, LPG .s, Sapa temporal baseline planner,
problem file shape colour points indicate planner
best therefore used plot. Planners appearing particular dataset
best problems collection.

temporal baseline planner, Sapa LPG-td solve problems requiring kind temporal
coordination. temporal baseline planner compiles away temporal information, using action
47

fiC OLES , C OLES , F OX & L ONG

Depots Time

Driverlog Time
100

Colin Solution Time (s)

Colin Solution Time (s)

100

10

1

0.1

10

1

0.1
LPG-TD used
Temp-Baseline used

0.01
0.01

0.1

1
10
Best Solution Time (s)

LPG-TD used
Temp-Baseline used
0.01
0.01

100

0.1

Rovers Time
100

Colin Solution Time (s)

Colin Solution Time (s)

100

Satellite Time

100

10

1

0.1

10

1

0.1
LPG-TD used
LPG.s used

0.01
0.01

1
10
Best Solution Time (s)

0.1

1
10
Best Solution Time (s)

LPG-TD used
LPG.s used
Temp-Baseline used
0.01
0.01

100

0.1

1
10
Best Solution Time (s)

100

Figure 11: Comparison time taken solve problems complex temporal planning benchmarks (first set). COLIN compared best LPG-td, LPG.s, Sapa temporal
baseline planner, problem file shape colour points indicate
best. Planners appearing particular dataset best
problems collection.

compression, solves problems non-temporal metric propositional problems.
solutions found, using Metric-FF core planning system, temporal information
reintroduced annotating plan suitable timestamps based critical path analysis.
details published planner, source code brief information available
IPC 2008 web site. approach cannot therefore solve problems required concurrency, fast effective simpler problems temporal actions sequenced.
straightforward identify many cases action compression applied safely
analysis implemented COLIN reduce overhead reasoning action end points
unnecessary. Therefore, behaviour temporal baseline planner similar
COLIN actions safely compressed. Figures 10, 11 12 show CPU time
comparisons COLIN best performances Sapa, LPG-td, LPG-s temporal baseline planner, across wide representative collection temporal benchmark domains.
Figure 10 shows performance simple temporal problems, action durations fixed,
Figures 11 12 show results complex temporal problems, including
48

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Airport Strips Temporal
1000

100

100
Colin Solution Time (s)

Colin Solution Time (s)

Zeno Time
1000

10

1

0.1

0.01
0.01

1
10
Best Solution Time (s)

100

1

0.1

LPG-TD used
LPG.s used

0.1

10

0.01
0.01

1000

LPG-TD used
Temp-Baseline used

0.1

Pipes No-Tankage Temporal

1
10
Best Solution Time (s)

100

1000

Pipes Tankage Temporal
1000

100

Colin Solution Time (s)

Colin Solution Time (s)

100
10

1

10

1

0.1
0.1

LPG-TD used
Temp-Baseline used
0.01
0.01

0.1

1
10
Best Solution Time (s)

0.01
0.01

100

LPG-TD used
Temp-Baseline used

0.1

1
10
Best Solution Time (s)

100

1000

Figure 12: Comparison time taken solve problems complex temporal planning benchmarks (second set). COLIN compared best LPG-td, LPG.s, Sapa temporal baseline planner, problem file shape colour points indicate
best. Planners appearing particular dataset best
problems collection.

duration actions determined context executed (although none
action effects depend this), problems metric variables. None problems
feature required concurrency forms temporal coordination. figures, planners
appearing dataset best problems domain.
Analysis Figures 1012 shows COLIN indeed pay overhead computation time
solution temporal problems feature continuous dynamics. overhead particularly significant simple temporal problems interesting temporal structure
temporal baseline planner tends perform well. overhead paid COLIN lower
complex temporal problems, temporal reasoning required sometimes challenging. makespan results Figures 13, 14 15 show COLIN produces good quality
plans, especially complex temporal problems, although temporal baseline planner still
competitive terms CPU time makespan. suggests temporal structure,
even complex temporal benchmarks, quite simple planner well ignoring
temporal structure present, rather trying reason generating plans.
49

fiC OLES , C OLES , F OX & L ONG

Depots Simple Time

Driverlog Simple Time

100

300

250
Colin Solution Quality

Colin Solution Quality

80

60

40

20

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

0
0

20

40
60
Best Solution Quality

80

200

150

100

LPG.s used
Sapa used
Temp-Baseline used

50

0
100

0

50

100
150
200
Best Solution Quality

300

Satellite Simple Time

400

400

350

350

300

300
Colin Solution Quality

Colin Solution Quality

Rovers Simple Time

250

250
200
150
100

250
200
150
100

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

50
0
0

50

100

150
200
250
Best Solution Quality

300

350

LPG-TD used
LPG.s used
Temp-Baseline used

50
0
400

0

50

100

150
200
250
Best Solution Quality

300

350

400

Zeno Simple Time
6000

Colin Solution Quality

5000

4000

3000

2000

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

1000

0
0

1000

2000
3000
4000
Best Solution Quality

5000

6000

Figure 13: Comparison plan quality simple temporal planning benchmarks. COLIN compared best LPG-td, LPG.s, Sapa temporal baseline planner, problem file shape colour points indicate best. Planners
appearing particular dataset best problems
collection.

detailed results experiments, showing raw runtime quality comparisons planners used experiment, presented Appendix E.
50

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Depots Time

Driverlog Time

400

1000

350
800
Colin Solution Quality

Colin Solution Quality

300
250
200
150

600

400

100
200

LPG-TD used
LPG.s used
Sapa used

50
0

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

0
0

50

100

150
200
250
Best Solution Quality

300

350

400

0

200

Rovers Time

400
600
Best Solution Quality

800

1000

Satellite Time

400

600

350

500
Colin Solution Quality

Colin Solution Quality

300
250
200
150

400

300

200

100
LPG-TD used
LPG.s used
Sapa used

50

LPG-TD used
LPG.s used
Sapa used
Temp-Baseline used

100

0

0
0

50

100

150
200
250
Best Solution Quality

300

350

400

0

100

200
300
400
Best Solution Quality

500

600

Figure 14: Comparison plan quality complex temporal planning benchmarks (first set).
COLIN compared best LPG -td, LPG .s, Sapa temporal baseline planner,
problem file shape colour points indicate best.
Planners appearing particular dataset best problems
collection.

12.2 Solving Problems Continuous Linear Change Duration-Dependent Effects
focus section examining scalability COLIN continuous benchmark
domains developed and, specifically, comparing two variants TRPG discussed Section 9. are: basic heuristic, discretises time, refined heuristic,
capable handling continuous numeric change directly. continuous benchmarks,
described Section 11, characterised sophisticated temporal structure (including required
concurrency) giving rise interesting opportunities concurrent behaviour. problems time-dependent effects continuous effects, reach temporal
planners used last experiment. problems used experiment designed rely
exploitation features, baseline planner ignored continuous dynamics
would unable solve problems.
Results comparing basic refined heuristics shown Figure 16. Beginning
Airplane Landing domain Rovers domain variant, performance either
51

fiC OLES , C OLES , F OX & L ONG

Zeno Time

Airport Strips Temporal

400

1000

350
800
Colin Solution Quality

Colin Solution Quality

300
250
200
150

600

400

100
200

LPG-TD used
LPG.s used
Sapa used

50
0

LPG-TD used
LPG.s used
Temp-Baseline used

0
0

50

100

150
200
250
Best Solution Quality

300

350

400

0

200

50

40

40

30

20

10

800

1000

Pipes No-Tankage Temporal

50

Colin Solution Quality

Colin Solution Quality

Pipes No-Tankage Temporal

400
600
Best Solution Quality

30

20

10

LPG-TD used
LPG.s used
Temp-Baseline used

0

LPG-TD used
LPG.s used
Temp-Baseline used

0
0

10

20
30
Best Solution Quality

40

50

0

10

20
30
Best Solution Quality

40

50

Figure 15: Comparison plan quality complex temporal planning benchmarks (second
set). COLIN compared best LPG-td, LPG.s, Sapa temporal baseline
planner, problem file shape colour points indicate
best. Planners appearing particular dataset best
problems collection.

heuristic used: relaxed plans found same. expected, two
domains interaction time numbers relatively limited. Airplane Landing
problem, action durations affect variable used measure plan cost used
preconditions. Thus, selection actions TRPG unaffected. Rovers domain, continuous change arises consuming power navigate actions, producing power
recharging. Capturing time-dependent nature precisely effect relaxed plans, nature relaxation leads rarely require recharge actions,
conditions needed affected whether effects integrated
not. Nevertheless, two domains illustrate guaranteed like-for-like situations,
heuristic guidance same, refined heuristic negligibly expensive
compute, despite additional overheads tracking gradient effects TRPG expanded.
also seen COLIN scales well across Airplane Landing instances, although
manages solve 9 14 Rovers problems (these well within two minutes).
52

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Rovers Continuous Time

Airplane Landing Edinburgh Time
1000

100

Basic Heuristic
Refined Heuristic

Refined Heuristic
Basic Heuristic
100
10

Time

Time (s)

10
1

1

0.1
0.1

0.01

0.01
5

10

15

20
25
30
Problem Number

35

40

45

2

50

4

6

Satellite Cooled Time
1000

12

14

Satellite Cooled Makespan
1000

Basic Heuristic
Refined Heuristic

Basic Heuristic
Refined Heuristic

900
800

Makespan

100

Time (s)

8
10
Problem Number

10

700
600
500

1

400
300

0.1

200
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

AUV Time

10
12
Problem Number

14

16

18

20

AUV Makespan

10000

600

Basic Heuristic
Refined Heuristic
1000

500

100

400
Makespan

Time

8

10

300

1

200

0.1

100

0.01

Basic Heuristic
Refined Heuristic

0
5

10

15
20
Problem Number

25

30

5

10

15
20
Problem Number

25

30

Figure 16: Comparison Basic Refined TRPG variants continuous domains. boxed
graphs makespan comparisons Satellite Cooled AUV domains, placed
right corresponding runtime graphs.

Satellite Cooled domain, runtime taken find plans using refined
heuristic comparable using basic heuristic: problems (e.g. 13, 18)
slower; others (e.g. 12, 15) faster. interesting comparison make
makespan data (shown right). seen, refined heuristic generally produces
53

fiC OLES , C OLES , F OX & L ONG

better quality plans. difference quality due refined heuristic better capturing
relationship time numbers, leading better actions chosen relaxed plan.
way example, consider state reached beginning sunrise action:
basic heuristic, LP used obtain bounds power availability state,
free reign much time allow elapse. lower-bound found slightly
zero (corresponding allowing time elapse), upper-bound found
peak power availability (corresponding applying entirety sunrise action).
building TRPG bounds, cooled sensor operation immediately available,
hence goals always achieved first actions using sensor cooling: duration
actions lower, making attractive. resulting relaxed plan, hence
helpful actions, therefore lead search use sensor cooling.
refined heuristic, LP used obtain bounds power availability
state, bounds must obtained soonest possible point. Thus, lowerbound still slightly zero, upper bound also slightly
zero. positive gradients effect power availability variables included
TRPG, influencing layers different actions become applicable. Specifically,
actions without sensor cooling lower power requirements, hence appear earlier
layers. Then, goals first achieved actions using sensor cooling (where increased
duration acquiring image without cooling compensated sufficiently able
start taking image sooner) relaxed plan, hence helpful actions, use
sensor cooling goals. seen situation closely analogous
differences alternative mortgages Borrower domain.
extent trade-off influences plan quality varies problems, depending
initial orientation satellites, images required. least benefit arises
satellite requires substantial reorientation point towards first target case,
time taken allows energy level rise sufficiently support sensor cooling. greatest benefit
arises opposite situation, satellite requires minimal reorientation then, switching
sensor cooled mode require substantial amount time elapse support
energy requirement precondition.
aid understanding scalability implications results, Satellite problems
based used 2002 IPC, similar fundamental size. However, continuous
reasoning added makes underlying problems fundamentally much
difficult solve.
AUV domain, use refined heuristic increases problem coverage, 30
problems solved rather 27. Applying Wilcoxon Matched-Pairs Signed-Ranks Test
paired time-taken data mutually solved problems, find reject null hypothesis
refined heuristic better basic heuristic, p 0.05. Observing performance planner, difference performance arises due way drifting
process handled two approaches. Specifically, accounted difference
bounds fact layer zero TRPG calculated. Consider state action
AUV communicate image data started. domain encoding ensures
communication completed, AUV cannot perform activities. point, prior
evaluating state using TRPG heuristic, LP used give bounds values state
54

fiC OLIN : P LANNING C ONTINUOUS C HANGE

variable. Considering variable recording far communicating AUV drifted
variable (distance-from-waypoint auv0), abbreviated dfw0:
basic heuristic employs approach set Section 8.3. single timestamp
variable introduced, must come action started, along additional
variable constraint dfw0. Maximising minimising value additional
variable yields bounds dfw0. lower bound infinitesimally larger
prior starting action, due time elapsed. upper bound corresponds
allowing large amount time elapse.
refined heuristic employs approach set Section 9.2.1. Here, timestamp
variable introduced task variable, case concerned tnow (dfw0).
prior case, constrained action applied. Additionally,
however, domain model enforces action refer value
variable communicate action finished, specific tnow must also come
(future) end action applied. bounds dfw0 found following
remaining steps Section 9.2.1: LP solved minimise value tnow variable,
value variable fixed minimum LP solved maximise
minimise value dfw0. Critically, tnow variable must come end
action applied, rather start, lower bound dfw0 larger.
increase lower bound dfw0 affects whether, TRPG, preconditions
form (<= (dfw0) c) considered satisfied initial fact layer. satisfied,
delayed earliest layer localise action reduces value dfw0.
difference affect relaxed plan found: solution extraction, action requiring
(<= (dfw0) c) chosen, localise action necessary achieve TRPG,
action added relaxed plan. cannot come earlier end
communicate action applied, is, point bounds dfw0 calculated,
sort localisation necessary ultimately applied. Thus, bounds
refined heuristic lead better relaxed plans found, containing localise actions
would otherwise omitted.
give indication difficulty problems, AUV problems range problems
2 AUVs, 5 waypoints, 2 objectives 2 goals harder end 6 AUVs, 15
waypoints, 6 objectives 7 goals. major hurdle preventing COLIN scaling even
larger problems inability see implicit deadline created shine-torch
action started. AUV shining torch finite energy, planner starts shinetorch action one AUV, preparation another AUV take image, adds
plan actions involving second AUV unrelated taking image, delay
lead insufficient energy shine torch long enough gain required
exposure photograph taking action eventually started. leads planner dead
end forced resort best-first search, much less effective EHC
domain. implicit deadlines occur many planning problems temporal coordination
issues COLIN faces could avoided using branch-ordering heuristic promotes
actions whose applicability time-limited due ends currently-executing actions, perhaps
relaxing unnecessary ordering constraints imposed COLIN due total order search.
scope paper, interesting avenues future work.
55

fiC OLES , C OLES , F OX & L ONG

(:durative-action burning-fuel
:parameters (?a - airplane)
:duration
(>= ?duration (* 60 (engines ?a)))
:condition (and (at start (not-burning-fuel ?a))
(at end (taking-off ?a)))
:effect (and (at start (can-start-engines ?a))
(at start (not (not-burning-fuel ?a)))
(increase (wasted-fuel) (* #t (engines ?a)))
)
)

Figure 17: burning-fuel action added Airport domain
12.3 Post Hoc Plan Optimisation
section evaluate effectiveness post hoc plan optimisation strategy. described
Section 10, plan optimisation phase occurs planning complete never change
actions plan. lifting Partial Order prior scheduling (Veloso, Perez, &
Carbonell, 1990), provide scheduler little flexibility order actions.
long ordering constraints remaining (greedy) partial-order lifting respected,
scheduler reduce plan cost altering time-points actions occur and,
possible, durations. Minimising objective plan makespan effect
plan quality domains metric sensitive times actions applied,
since, default, COLIN minimises makespan solution final LP completed plan.
benchmark domains literature, make use one existing suitable
domain introduce new variations existing benchmarks, order test feature.
first domain, existing domain property, Airplane Landing
domain, used earlier section, described Section 11. Here, penalties incurred
landing depend whether, extent, early late. Therefore, given
sequence landings, times assigned impact quality plan.
next two benchmark problems variants problems introduced International
Planning Competitions 2002 (Long & Fox, 2003b) 2004 (Hoffmann & Edelkamp, 2005).
First, consider modified version Satellite domain. modify domain adding
time windows (modelled using TILs) clear view given objective.
photograph objective taken time window, quality plan improves,
better quality picture preferable. problem introduce three time windows
objective, bounded random duration, taking photograph objective
preferred. second adapted benchmark taken IPC2004 Airport domain.
Airplane Landing problem described previously concerned scheduling landing times
aircraft, Airport domain concerned coordinating ground traffic: moving planes
gates runways, eventually take-off, whilst respecting physical separation must
maintained aircraft safety reasons. add domain metric minimise
total amount fuel burnt aircrafts engines starting eventually takes
off. capture PDDL 2.1, add action shown Figure 17. action must occur
planes engines started cannot finish plane started take-off
(hence duration least startup action). two points increases
56

fiC OLIN : P LANNING C ONTINUOUS C HANGE

amount fuel wasted rate proportional number engines fitted aircraft:
larger planes (for number engines greater) waste fuel per unit time.
Satellite Airport domains use standard problem sets competitions,
adding minor changes needed support modifications made, whilst leaving underlying
problems unaltered.
final domain consider cafe domain, first used evaluate CRIKEY (Coles, Fox,
Halsey et al., 2008). domain, tea toast must made delivered table
cafe. kitchen, however, one plug socket, preventing two items made
concurrently. restriction allows problem number interesting metric functions:
minimise total time serve customers (the plan makespan), minimise time
delivery tea toast given table, minimise amount items cooled
delivered table. consider latter two variants here.
results experiments presented Figure 18. Starting top-left,
Airplane Landing domain, post hoc optimisation gives modest improvement plan quality.
due limited scope optimisation: even partial-order lifting, order
planes going land fixed plan, adjusted precise times
planes going land within ordering.
Moving Airport domain variant burning-fuel action Figure 18 top-right
post hoc scheduling able give large improvements plan quality. original plans,
optimisation, burning-fuel action given plane started point prior
relevant can-start-engines fact needed ended point relevant
taking-off fact true, necessarily timely manner. Following post hoc optimisation,
due objective function used, burning-fuel action starts late possible finishes
early possible.
cafe domain, results two metrics used shown central graphs
Figure 18. two diagonal lines correspond original plans. given problem, two
plans identical: evaluation metric differs. two lower lines show quality
plan scheduling respect relevant metric. Observing post-scheduled plans,
actions scheduled one would intuitively expect. minimising total delivery
window times, items given table delivered succession, even first item loses heat
waiting second item prepared. contrast, minimising heat loss items
delivered tables soon prepared, even delay two
items delivered.
Finally, results variant Satellite domain observation windows shown
bottom-left Figure 18. Whilst marked improvements previous two
domains, scheduler able make headway better scheduling observations.
original plan given problem will, satellite, fix observations make,
order made. remains enough flexibility able improve plan
quality, reducing plan cost around factor 2.
12.4 Comparison Optimal Solutions
investigated difference quality optimal solutions solutions produced
COLIN order form impression close optimal COLIN get. this, ran
COLIN admissible heuristic uses makespan estimate produced TRPG, using
57

fiC OLES , C OLES , F OX & L ONG

Airplane Landing Edinburgh
20000

Airport Fuel Loss
4500

colin-standard
colin-optimise

18000

4000

16000

3500

14000

3000

Solution Quality

Solution Quality

colin-standard
colin-optimise

12000
10000
8000

2500
2000
1500

6000

1000

4000

500

2000
0

0
5

10

15

20
25
30
Problem Number

35

40

45

50

2

4

6

Cafe (Delivery Window)
1200

8

10
12
Problem Number

14

16

18

Cafe (Heat Loss)

colin-standard
colin-optimise

80

100

colin-standard
colin-optimised

70

80

1000
Delivery Window Metric

20

Heat Loss Metric

60
800

600

60

50
40

40
30

400
20
200

20

10

0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

0
2

4

6

8
10
12
Problem Number

14

16

18

20

Satellite Reward
1200

colin-standard
colin-optimise

Solution Quality

1000

800

600

400

200

0
2

4

6

8

10
12
Problem Number

14

16

18

20

Figure 18: Quality plans produced Colin without post hoc optimisation. four
graphs, lower better.

value used COLIN results presented Figures 16 18. call
variant optimalCOLIN.
AUV Rover domains, variable-duration actions domain
durations chosen small actions used plan. -length actions
might chosen, example, relocalise slightly drifted, recharge used
negligible amount power. domains, optimal search consider plans comprising
almost entirely actions duration optimal makespan. example scale this,
58

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Problem
[2-5] instance
01
02
03
04
05
06
07

optimalCOLIN
makespan time (secs)
20.001
0.00
30.001
0.00
30.001
0.02
40.001
0.29
40.003
3.94
50.003
69.93
-

COLIN

makespan
20.001
34.004
38.007
44.006
48.009
62.01
66.014

time (secs)
0.01
0.01
0.01
0.01
0.02
0.03
0.03

Table 4: Comparison makespans solution time airplane landing problems solved optimalCOLIN COLIN using refined heuristic. Problem 7 could solved
optimalCOLIN within 1 hour bound.

AUV problem 1, solved COLIN, find plan makespan 34.031. Careful analysis
hand suggests plan cannot improved, optimal. OptimalCOLIN must consider plans
34,031 steps order prove plan optimal. means problem
completely reach optimal planning.
similar problem arises Rovers domain, recharge action little
long, series -long recharge actions applied, reaching ostensibly different states,
without making progress. Clearly, potential -duration actions arise
continuous temporal domain. problem search-space explosion also arise
temporal domain orders magnitude differences longest shortest
possible actions.
However, Airplane-Landing Satellite Cooling domains, variable-duration
actions domains made arbitrarily short search. Therefore, optimalCOLIN
principle able solve problems domains. fact, given 4 Gb memory 1 hour
runtime instance, able solve 6 airplane landing instances, shown Table 4.
table shows, time required solve problems increases fast: problem 5 could
solved 3.94 seconds, problem 6 69.93 seconds, problem 7 could solved within
hour available. basis decided unnecessary extend time available
optimalCOLIN would unlikely cope large instances.
Table 4 shows COLIN sacrifices optimality speed. sacrifice important,
pay terms time required solve problems. COLIN able solve 62 airplane
landing problems, instance taking 33.02 seconds solve.
found optimalCOLIN could report candidate solution first Satellite domain instance, within 368 seconds. However, could prove within time available solution
optimal, include it.
12.5 Costs Associated LP Scheduling
transition CRIKEY 3 COLIN switch solving STP state solving
LP. important issue consider impact time taken evaluate
59

fiC OLES , C OLES , F OX & L ONG

feasibility plan constructed reach every state considered search. default mode
operation, COLIN uses STP evaluate state unless temporalnumeric constructs
necessitate use LP. evaluate whether appropriate (or whether always using
LP would faster), compare overheads STP solving LP solving equivalent
problems, created variant COLIN that, every state S, schedules plan reach independently using three different schedulers: original STP solver used standard version
COLIN, equivalent LP solved using CPLEX (IBM ILOG CPLEX Optimization Studio)
equivalent LP solved using CLP (Lougee-Heimer, 2003). STP solver used incremental STP algorithm due Cesta Oddi (1996), previously used CRIKEY 3. LP
solvers used tighter variable bounds described Section 8.4. order evaluate
cost associated use LP instead STP, modified COLIN collect data revealing
costs technique applied node evaluated search plan.
possible compare performance straightforwardly, simply running COLIN using STP
versus COLIN LP, minor variations caused numerical accuracy lead
different trajectories followed, masking intended comparison. aside, interesting observe minor (and essentially uncontrollable) differences computed makespans
relaxed plans lead significant variations performance (relaxed plans equal h-values
sorted makespan estimates search).
wish compare STP LP approaches, necessary consider domains
reason: is, without continuous-numeric duration-dependent effects.
order consider problems scheduling interesting necessary (in contrast
temporally simple problems Section 12.1) consider domains required concurrency.
Currently benchmarks exist, planners attempt solve problems.
use representatives competition domains features: compiled timed initial
literal domains IPC2004, use Airport (with Time Windows) PipesNoTankage (with deadlines). also use Match-Lift Driverlog Shift domains (Halsey, 2005).
completeness, include results domain scheduler strictly necessary:
PipesNoTankage Temporal domain IPC2004.
Figure 19 shows mean time spent scheduling per state, using approach, problems
domains. exclude graph data problems solved
planner less second, accuracy profiling data sufficiently reliable
measure time spent scheduler overall time taken small. Since
interesting variation results domains present data together across three
graphs, sorted scheduling time per node using CPLEX. intended nominal
analogue hard scheduling problems given planning problem are. increase
scheduling time CPLEX generally corresponds increase scheduling time CLP
STP solver, except easier problems noise sufficient tip balance
figures small. Note differing y-axis scales three graphs, sorting problems
according difficulty allows us display data appropriate range distinguish
results. sake maintaining reasonable y-axis ranges final problem, problem 60,
omitted graphs; problem figures CPLEX 239ms, CLP 139ms
STP 38ms.
results Figure 19 are, course, indicative scalability COLIN, running
three schedulers state, significantly slower usual configuration. practice,
domains continuous duration dependent effects, COLIN automatically
60

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Low Difficulty
0.4

STP
CLP
0.3 CPLEX

MST/State (ms)

0.35
0.25
0.2
0.15
0.1
0.05

1

2

3

4

5

6

7

8

9 10 11 12
Problem Number

13

14

15

16

17

18

19

20

33

34

35

36

37

38

39

40

58

59

Medium Difficulty

MST/State (ms)

1.4

STP
CLP
1.2 CPLEX
1
0.8
0.6
0.4
0.2
21

22

23

24

25

26

27

28

29 30 31 32
Problem Number
High Difficulty

40
MST/State (ms)

35
30

STP
CLP
CPLEX

25
20
15
10
5
0
41

42

43

44

45

46

47

48

49 50 51 52
Problem Number

53

54

55

56

57

Figure 19: Mean Scheduling Time (MST) per State Temporal Planning Problems. problem
number appears leftmost three corresponding columns case.

disable LP scheduler use efficient STP solver. Further, planner
run profiling enabled, subject significant overheads.
61

fiC OLES , C OLES , F OX & L ONG

&
&
&
&
&
&

!"
#"$
# !
" '
(' )
#
)*')' +
(,#
(,
!"
#"$
(' )
(' )

!"

#"$%#

!"
2
#"$%#!"

& # !
-.# **
&
')&
( ' )/ ' - / (
0
-. 0 '
# 11

Figure 20: Time spent various activities solvers, CPLEX CLP, viewed proportion total time spent CPLEX. slice labelled MILPSolverCPX/CLP
time spent destructor MILP solver CPLEX CLP: housekeeping operation implementations (which written C++).

Considering relative performance STP LP solvers, clear overheads incurred necessary (for domains continuous effects) move using LP rather
STP. mean ratio time spent scheduling problems CPLEX
spent using STP solver 5.81, figure CLP 3.71. Analysis data suggests
ratios change problem difficulty increases, rather overhead constant factor
harder problems.
Despite increased scheduling overheads still worth noting solving scheduling problem relatively small fraction cost reasoning done state. plan
given state scheduled check feasibility state evaluated using temporal RPG heuristic described Section 9. well known, analysis performance
FF forward search planners, majority search time spent evaluating
heuristic. give indication relative cost scheduling versus heuristic computation
give admissible estimate mean fraction time spent, per-state, running scheduler
versus computing heuristic. estimate guaranteed overestimate true mean
states scheduler demonstrate temporal problem solution:
states RPG heuristic never evaluated, heuristic evaluation actually applied
fewer states scheduler. Nonetheless, data shows that, across problems, using
STP solver scheduling accounts average less 5% state evaluation time. CLP
CPLEX figures 13% 18% respectively. suggests that, although scheduling
add overhead solving problems, relatively small compared cost heuristic
computation.
perhaps surprising observation made Figure 19 CLP generally solves
scheduling problems much efficiently CPLEX. Given reputation CPLEX
highly efficient commercial LP solver wanted investigate case problems.
62

fiC OLIN : P LANNING C ONTINUOUS C HANGE

performed analysis profiling data, breaking results function call,
observe time spent various aspects constructing solving LP thorough CLP
CPLEX library calls. data, presented Figure 20 shows time spent function
fraction total time taken CPLEX schedule plans (each summed across problems).
used section CLP data represents time saved using CLP versus CPLEX.
presentation means equally sized slices pies represent length time
taken either solvers respective methods.
important insight gain data time
LP solvers spent solve function, indeed observed search portion
negligible: barely visible. majority time is, fact, spent adding rows LP
matrix, i.e. adding constraints LP actually solved. Comparing CPLEX CLP,
takes 6 times longer, average, add row matrix. LPs created
identical, hence involve adding number rows matrix. portion
chart corresponds methods, many also take longer search,
pre-processing steps adding new columns (variables) setting upper bounds. Since
adding rows matrix significant portion time taken constructing-then-solving
LPs COLIN, results large overhead. LPs created COLIN small simple
solve, compared difficult industrial-sized problems CPLEX designed.
results suggest that, fact, best type LP solver use task relatively
light-weight LP solver, overheads, create models efficiently, even perhaps
would scale large-scale problems. notable, although less marked, difference
two LP solvers time spent destructor, called free memory used
LP solver state evaluated. Here, takes 23 times longer, average,
call destructor CPLEX destructor CLP. less impact rowadding overheads, since LP deleted per state, rather per LP constraint.
general, would normally noticeable issue solving single difficult LP. However,
COLIN, number LPs solved equal number states evaluated, overhead
become noticeable.
One interesting outcome study if, future, COLIN extended
non-linear continuous change, requiring use mathematical programming solver state
(along research developments), overheads may well prohibitive. search
within solver, greater overhead would occur due change, fact
major contributor time overheads using LP.

13. Conclusions
range problems solved effectively planners grows, range
opportunities technology applied real problems. recent years, planning extended solve problems real temporal structure, requiring temporal coordination, problems
include metric resources interactions use causal structure plans.
shown range extended still further, include linear continuous process
effects. extension power planners demands several steps. first model
extension form allows relationship constraints imposed plans
new expressiveness, actions used solve problem, properly expressed.
second step develop means represent world state consistently, order
63

fiC OLES , C OLES , F OX & L ONG

characterise space search plan conducted. third step develop
way compute progression states using action models extended representation.
step complete, is, principle, possible plan: search space constructed
searched using classic simple search techniques. practice, process unlikely lead
solutions many interesting problems fourth step, order make search possible
large spaces, construct informed heuristic guide search.
paper built earlier work completed first steps, adding third
fourth steps allow us solve planning problems continuous effects. tools
used achieve well-established Operations Research tools: LP solvers extensions
MILP solvers. contributions made show tools harnessed
check consistency states, model state progression compute heuristics successfully guide search large spaces develop planning problems.
additional contribution established collection benchmark problems
direction research planning. planning community witnessed creation
benchmarks propagation powerful aid development technology, supporting
clear empirical evaluation challenging researchers improve results others.
shown COLIN solve interesting complex problems, remains much room
improvement. Apart extending capability planner improving informedness
heuristic improving early pruning dead end states, also opportunity
extend still range problems expressed solved. particular,
interested problems non-linear continuous effects, power thermal curves.
seems possible non-linear effects might approached similar approach used
COLIN, adapting NLP solver role LP solver COLIN. Alternatively, might
possible approximate non-linear effects piecewise linear effects, much way
AUV domain described paper, performing process automatically.
Planning becoming increasingly key technology robotic systems become powerful
complex begin see limits low level control strategies managing
control systems. Autonomy demands powerful predictive control planning
offers possible solutions problem. Planning continuous effects important
tool collection offer tackling new demands.

Acknowledgments

authors wish thank handling editor, Malte Helmert, anonymous reviewers
considerable contributions paper. authors also wish thank members Planning Group helpful discussions long gestation work.
authors also wish acknowledge EPSRC support work, specifically
grants EP/G023360/2 EP/H029001/2.
64

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Appendix A. Glossary
Name
(i, v)
(i, v)
Action compression

al

ce(i)
cs(i)

dec(i, v)

dmin (dmax)

E
eff +
x
eff
x
eff nx
estepi

elapsed(a)

f (i)

Description
lower bound assignment effects variable v due actions layer reachability graph.
upper bound assignment effects variable v due actions layer reachability graph.
technique simplifying structure durative actions
treating simple non-durative action union
effects ends durative action union
preconditions.
Action layer reachability graph constructed heuristic purposes.

First Use
62

Function returning variable corresponding end time
snap-action position current plan.
Function returning variable corresponding start time
snap-action position current plan.

21

Set (discrete) decreasing effects variable v layer
reachability graph.
rate change variable v (associated state
achieved execution plan.
minimum (maximum) duration action. use dmin(a)
(dmax(a)) relevant action required explicit
dmin(a, t) (dmax(a, t)) value anchored action
layer al(t).

62

event list recording action start times durative actions
whose end points yet included plan.
Propositional add effects action, x, present, indicates whether start end action.
Propositional delete effects action, x, present,
indicates whether start end action.
Numeric effects action, x, present, indicates
whether start end action.
name LP variable corresponding time
durative action finish, started ith step plan,
finished within plan constructed far.
maximum time action could executing
state heuristically evaluated.

13

variable STN CRIKEY 3 corresponds time
currently incomplete action eventually finish.

65

62
9

26

21

21
14

4
4
4
20

27

15

fiC OLES , C OLES , F OX & L ONG

Name
fl

Description
Fact layer reachability graph constructed heuristic purposes.

First Use
26

inc(i, v)

Set (discrete) increasing effects variable v layer
reachability graph.
invariants active state S.

62

Left packing

structure plans concurrency concurrent actions start simultaneously.

39



name variable created represent time end
current plan STP LP used check temporal consistency state.

15

hop, , dmin, dmax

Event record CRIKEY state, containing durative action, op,
started step i, minimum maximum duration
action.

14

pre
pre
pre `
p(a)

Conditions required complete action.
Invariant conditions durative action.
Conditions required initiate action.
bound number instances durative action
may execute concurrently.

4
5
4
28

remaining(e)

maximum amount remaining time action
event record e could continue executing following state
heuristically evaluated.
Information associated durative action al(t) reachability analysis constructed COLIN, indicating much time
could continue execute layer.

28

stepi

name LP variable corresponding time
action ai applied plan.

20

t(i)

variable STP CRIKEY 3 represents time
step plan executed.
property planning problems require concurrency order manage interactions actions
deadlines.
Action effects refer ?duration, causing numeric fluents
change different amounts according length action
causing effect.

14

inv(S)

rem(t, a)

Temporal coordination

Time-dependent change

66

14

33

39

2

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Name

Description
Used describe continuous change: complete account
use semantics, see original discussion use
PDDL 2.1 (Fox & Long, 2003).

First Use
3

ub(w, x, y)

Function used calculate bounds effects continuous numeric change.

29

v

Used represent vector metric fluents associated
planning domain, values state. vector treated
indexable: v[i] ith entry v.
vector values metric fluents start state, immediately following step effects application action.
vectors lower upper bounds values numeric variables state (during plan construction).

5

Symbol used represent vector constants equal dimension
size vector metric fluents relevant planning
problem.

5

#t

v0
vmin , vmax

w

67

21
24

fiC OLES , C OLES , F OX & L ONG

Appendix B. Metric Relaxed Planning Graph Heuristic
Relaxed Planning Graph (RPG) heuristic Metric-FF (Hoffmann, 2003)
popular numeric planning heuristic last decade, widely used many planners.
intuition behind heuristic generalise delete-relaxation include numeric variables.
case propositions, relaxation simply ignore propositional delete effects so,
(relaxed) actions applied, set true propositions non-decreasing. case numbers,
relaxation replaces exact assignments numeric variables bound constraints upper
lower bounds. Applying relaxed actions extends bounds reducing lower bounds
decrease effects increasing upper bounds increase effects. Checking whether numeric
precondition satisfied simply matter testing whether constraint satisfied
value within bounds. delete-relaxed problem solved (non-optimally) polynomial
time, number actions resulting relaxed plan taken heuristic estimate
distance evaluated state goal.
purpose RPG support heuristic computation. Relaxed planning undertaken
two phases: graph expansion, solution extraction. graph expansion phase purpose
build RPG, identifying facts actions become reachable. RPG consists
alternate fact layers, consisting propositions hold optimistic bounds v, action
layers, containing actions whose preconditions satisfied preceding fact layer. case
propositional preconditions, precondition satisfied relevant fact contained
previous layer. case numeric preconditions, satisfied assignment
variables appearing precondition, consistent upper lower bounds, lead
satisfied. define function ub(w, x, y) as:
X w[j] y[j] w[j] 0
ub(w, x, y) =
w[j] x[j] otherwise
w[j]w

(this function defined Section 9.2).
Then, denoting fact layer set propositions, f l(i), upper lower variable bounds
(vmin (i), vmax (i)), precondition w v c action layer considered true iff:
ub(w, vmin (i), vmax (i)) c
seed graph construction, fact layer 0 contains facts true S. Thus, action layer
0 consists actions whose preconditions satisfied fact layer 0. Fact layer 1 set
optimistic outcome taking fact layer 0, applying actions action layer 0.
formally, considering propositions, applying actions action layer i, i.e. actions al(i)
leads fact layer + 1 where:
f l(i + 1) = f l(i) {eff + (a) | al(i)}
Considering numbers, action layer set optimistic increase decrease effects
variable v across actions are, respectively:
inc(i, v) = {(ub(w, vmin (i), vmax (i)) + c) > 0 | al(i) s.t. hv, +=, w v + ci eff n (a)}
dec(i, v) = {(ub(w, vmax (i), vmin (i)) + c) < 0 | al(i) s.t. hv, +=, w v + ci eff n (a)}
68

fiC OLIN : P LANNING C ONTINUOUS C HANGE

exchange minimum maximum bounds v two expressions important:
causes expression extreme possible appropriate direction. Similarly,
optimistic upper lower bounds v, following available assignment effects, are:
(i, v) = max{(ub(w, vmin (i), vmax (i)) + c) | al(i) s.t.hv, =, w v + ci eff n (a)}
(i, v) = min{(ub(w, vmax (i), vmin (i)) + c) | al(i) s.t.hv, =, w v + ci eff n (a)}
new bounds become:
vmax (i + 1)[j] = max{a (i, v[j]), vmax (i)[j] +
vmin (i + 1)[j] = min{a (i, v[j]), vmin (i)[j] +

X

X

inc(i, v[j])}

dec(i, v[j])}

is, find upper (lower) bounds v[j] next layer, choice
applying largest (smallest) single assignment effect, sum increase (decrease) effects. computed bounds variables layer + 1, graph expansion continues
iteratively, finding actions applicable action layer + 1, hence facts layer + 2,
on. Graph expansion terminates one two cases: either fact layer satisfies propositional
numeric goals, addition layers would never lead preconditions
satisfied condition signalled new propositions appearing accumulation
larger smaller bounds variables would lead numeric preconditions becoming
satisfied. case, relaxed problem cannot solved hence, original problem,
plan starting reach G. heuristic value state set .
Assuming graph expansion terminates goals reached, second phase extract
solution planning graph. recursive procedure, regressing goals back
initial fact layer. fact layer augmented set goals (facts numeric preconditions)
achieved layer. Beginning inserting top-level goals G planning
graph first layers appeared, solution extraction repeatedly picks latest
outstanding goal planning graph selects way achieve it. propositional goals,
single action (with effect adding goal) chosen, preconditions inserted goals
achieved (again, earliest possible layers). satisfy numeric goal w v c layer
i, actions effects acting upon variables (with non-zero coefficients) v chosen,
net increase w v, k, sufficient allow residual precondition w v c k
satisfied fact layer 1. point, residual precondition added goal achieved
layer 1 (or earlier possible), preconditions actions chosen support
precondition added goals achieved previous layers.
Solution extraction terminates outstanding goals achieved fact layer 0, since
true state evaluated need supporting actions. actions selected
solution extraction form relaxed plan goal. length (number actions)
relaxed plan forms heuristic estimate, h(S). Additionally, actions relaxed plan
chosen action layer 0 form basis helpful actions S, used restrict
states explored enforced hill-climbing search: action effect common
actions chosen action layer 0 considered helpful.
69

fiC OLES , C OLES , F OX & L ONG

Appendix C. Temporal Reasoning Relaxed Planning Graphs
Several approaches proposed building temporal relaxed planning graphs (TRPGs).
three additional features TRPGs attempt manage, compared RPGs:
1. temporal structure durative actions: aa applied a` applied
it.
2. Action durations: end effects actions available appropriate delay
started.
3. PDDL 2.1 startend semantics, allowing effects preconditions attached
starts ends actions.
TRPG employed Sapa (Do & Kambhampati, 2003) satisfies first two these,
third. Sapa, action compressed temporally-extended action obeying
TGP semantics, discarding delete effects, relaxation, building TGP -style planning
graph (Smith & Weld, 1999). use compression time-stamped TGP representation
captures durations start-before-end relationships, use compression causes
heuristic find false dead-ends cases required concurrency.
TRGP used CRIKEY (Coles, Fox, Halsey et al., 2008) avoids action compression,
ignores durations actions. non-temporal RPG built terms snap-actions used
search, additional precondition end snap-action particular dummy fact,
added corresponding start, appeared preceding fact layer. use snap-actions
means preconditions effects lost (ensuring heuristic longer identifies false
dead-ends created approach used Sapa), limitation heuristic
forced separation start end action, ordering constraint.
CRIKEY 3 (Coles, Fox, Long et al., 2008a), heuristic constructed combine
strengths earlier heuristics, accounting durations actions, whilst also
respecting startend semantics. briefly describe construction TRPG, since
basis heuristic used COLIN. structure TRPG similar constructed
Metric-FF, instead fact layer assigned index, assigned time-stamp
(indicating minimum amount time must pass initial layer facts
layer question appear). capture durations actions, record, end action aa ,
earliest layer tmin (aa ) appear. value set 0 actions already
executing state evaluated (as need first insert start action
RPG). actions, value initialised , commencing TRPG construction.
build TRPG follow Algorithm 2. First, number initialisation steps performed.
time-zero fact layer fl (0) initialised (at line 1) contain facts true 10 . set
ea initialised contain end snap-actions must appear TRPG action
executing, end reachable (i.e. appear TRPG), else state dead end.
ea empty, satisfies goals G (line 14), TRPG need built, since plan
complete.
Following initialisation, TRPG expanded, beginning = 0 using fact layer
f l(t) determine action layer al(t). preconditions action satisfied fact layer
10. simplicity omit handling numeric fluents explanation performed exactly
earlier description RPG heuristic implemented Metric-FF.

70

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Algorithm 2: Building Temporal RPG CRIKEY 3.
Data: = hF, E, - state evaluated
Result: R = hfls, alsi, relaxed planning graph
1 fl (0) F ;
2 fls hfl (0)i;
3 als h i;
4 0;
5 ea ;
6 prev al ;
7 prev fl fl (0);
8 foreach aa
9
{e E | e.op = a} =
10
tmin (aa ) ;
11
else
12
tmin (aa ) 0;
13
ea ea {aa };
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37

G fl (0) ea = return goal state;
<
fl (t + ) prev fl ;
al (t) {aa | pre(aa ) fl (t) tmin (aa ) t};
foreach aa al (t) prev al
fl (t + ) fl (t + ) eff + (aa );
al (t) al (t) {a` | pre(a` ) fl (t)};
foreach a` al (t) prev al
fl (t + ) fl (t + ) eff + (a` );
tmin (aa ) = min[tmin (aa ), + dmin(a)];
als als + al (t);
fls fls + fls(t + );
prev al al (t);
G fl (t + ) ea al (t)
return R = hfls, alsi;
prev fl 6= fl (t + )
prev fl fl (t + );
+ ;
else
prev fl fl (t + );
ep = {tmin (aa ) | pre(aa ) fl (t) tmin (aa ) > t};
ep 6= min[ep];
else ;
return dead end;

71

fiC OLES , C OLES , F OX & L ONG

fl (t) whether appear al (t) depends whether start end snap-action.
first simpler case (line 20) that, start snap-action a` applicable, added al (t)
tmin (aa ) set + dmin(a), dmin(a) priori lower bound duration
a. state-independent measure minimum duration a, i.e. minimum duration
constraint referring constants, taken value dmin(a). Otherwise,
minimum duration constraints depends state action applied,
dmin(a) = : certain time must elapse start end
action. state-dependent terms cannot evaluated since TRPG determines relaxed state,
real state.
second case, covering end snap-actions, preconditions end action aa
become satisfied fact layer fl (t), addition aa al (t) depends whether start
action occurred sufficiently far past (line 17). tmin (aa ) aa added
al(t); < tmin (aa ) < , aa postponed al(tmin (aa )); otherwise, start
action yet appear, aa postponed relevant start appears.
determined actions newly appear al (t), fact layer fl (t + ) updated
non-temporal RPG case, taking fl (t) (optimistically) applying effects
actions al (t). f l(t + ) al(t) contain necessary goals end snap-actions
(line 27) must decided fact layer consider next. Clearly, infeasible create
new fact layers spacing fl (0) fact layer goals appear. Fortunately,
also unnecessary, many fact action layers graph would identical.
Instead, determine next fact layer consider follows:
new facts fl (t+) true fl (t) (line 29), next layer expand
fl (t + ) appearance new potentially useful facts makes necessary consider
whether actions become applicable layer.
fl (t + ) = fl (t), know visiting fl (t + ) futile. case (line 34),
time-stamp next fact layer visit earliest future point postponed
end action becomes applicable:
min{tmin (aa ) | pre(aa ) f l(t) tmin (aa ) > t}
minimum values (or undefined) state pruned
procedure exits early, signalling result search procedure.
TRPG successfully constructed (that is, starting state dead end) graph
returned contains finite set fact action layers, associated real time value.
Assuming graph expansion terminates goals reached, relaxed solution extracted.
solution extraction procedure used Metric-FF needs one minor modification suitable
use TRPG: end action aa chosen support goal given fact layer,
action already executing state evaluated, corresponding start a` must
scheduled selection (at layer first appeared). purpose corresponds
dummy facts CRIKEY: end action chosen, start must also executed.
final remark TRPG, timed initial literals (TILs) included employing
machinery introduced delay ends actions appropriate layer. dummy TIL
actions {TILj ...TILm } yet applied tmin (TILj ) = 0.0, since TILj could applied
first action layer. intuition state evaluated snapshot world,
72

fiC OLIN : P LANNING C ONTINUOUS C HANGE

taken earlier end previous action, later point
next TIL event occurs (due constraints discussed Section 6.1). minimum timestamps
later TILs, TILk {TILj+1 ...TILm }, set relative time point:
tmin (TILk ) = ts(TILk ) ts(TILj ).

Appendix D. Post-Hoc Plan Optimisation
appendix contains details MILP construction briefly described Section 10.2.
D.1 Optimising Time Windows
First let us consider simple case action conditional effect metric-tracking
variable reward (where objective problem maximise reward), effect
occurs depends truth value single proposition p time specifier ts relative
action (either start, all, end):
(when (ts (p)) (at end (increase (reward) k))).
case p manipulated actions, without allowing MILP introduce new
actions completely change order plan steps (with complexity modifications
would entail), little scope optimisation. case truth value p dictated
timed initial literals (TILs), interesting case: changing time-stamps
start end (LP variables step step j ), condition satisfied,
direct effect metric function. relationship encoded within LP. way
example, consider case p becomes true time false b; then, again, becomes
true c false d. case, two time-windows could potentially satisfy
condition effect. Whether action wholly partially within one
windows depends time-specifier attached p:
ts =at start, a` (step ) lie within one time windows;
ts =at end, aa (step j ) lie within one time windows;
otherwise, ts =over all, a` aa lie within one time windows.
three cases, question must answered value variable lie within
known range? case requires conjunction two conditions hold and,
two cases, one hold. given step variable step , time window (a, b),
introduce (MI)LP binary variable switch ab corresponding observation,
constraints take logical form:
switch ab (step > a) (step < b)
Thus, switch variable takes value 1, time-stamp point p needed must
fall within time-window [a, b] vice versa. introducing two additional binary variables,
denoted ga lb, logical constraint represented series inequalities (using N
73

fiC OLES , C OLES , F OX & L ONG

denote large number):
step (a + ) switch ab
step + (b ) switch ab
step + N ga
step N lb
switch ab ga lb







0
0

b
1

first two constraints encode forwards implication: switch ab set 1, step
lie range [a + , b ] (a non-zero amount separation, epsilon, needed
PDDL semantics avoid inspecting value p time changed
TIL). latter three constraints encode reverse implication: step strictly greater
strictly less b, ga lb hold value 1 thus, switch ab .
Returning example, time specifier all, windows (a, b)
(c, d), constraints added are:
switch ab1
switch ab2
switch ab
switch cd1
switch cd2
switch cd
switch p









(step > a) (step < b)
(step j > a) (step j < b)
(switch ab1 switch ab2 )
(step > c) (step < d)
(step j > c) (step j < d)
(switch cd1 switch cd2 )
(switch ab switch cd )

is, switch ab 1 entirety action falls within (a, b), switch cd 1 falls
within (c, d) switch p 1 either hold. final switch variable used capture
benefit effect itself: holds value 1, increase value reward end
plan k, is, apply conditional effect. variable reward already appear
objective function form LP variable reward 0n , n last step plan.
Thus, modify constraints define reward 0n k switch p added value.
change ensure variable providing value reward objective function
include reward k condition time executed holds.
Generalising, extend case conditional effect depends truth
formula f consisting conjunction time-specified propositional facts [(ts1 p1 )...(tsj pj )].
(tsi pi ) f , create constraints, indicated above, switch variable switch pi
take value 1 pi holds time-specifier tsi . gives us list switch variables
= [switch p1 ...switch pj ]. Then, encode fact conjunction f must hold, create
variable switch f add constraints:
j switch f + 1.switch p1 + ... + 1.switch pj 0
switch f + 1.switch p1 + ... + 1.switch pj 1 j
Defined thus, switch f takes value 1 iff switch variables takes value 1,
precisely case conjunct satisfied. Then, much before, updating
constraint dictating value LP variable reward 0n , add k switch f value.
D.2 Optimising Numeric-Dependent Conditions
Perhaps complex case time windows conditions conditional effect
depend values numeric variables domain. (The PDDL 2.2 definition (Hoffmann
74

fiC OLIN : P LANNING C ONTINUOUS C HANGE

& Edelkamp, 2005) include case TILs change values numeric variables11 ,
consider case here.) simple case, time-specifier numeric
conditions either start end. complicated case one
time-specifiers all. case, potentially, snap-actions plan,
start end action condition belongs, could affect whether condition
associated effect met. must therefore check status condition
point execution action. Suppose action O, stepk stepl
variables denoting start end time-stamps action, conditional effect
numeric precondition LNF:
(over (>= (w v) c)) (at end (increase (reward) k)).
encode this, need add constraints ensure conditional outcome occurs iff w
v c times within O. Since change linear, (as conditions
O) need check values numeric variables immediately immediately
action time step within O, also immediately following start immediately
end itself. Thus, variables corresponding values v must examine
list:
0
0
, vl ].
, ..., vl1 , vl1
e = [vk0 , vk+1 , vk+1
stated earlier, case start/at end conditions somewhat easier: start,
e = [vk ], end, e = [vl ]. Irrespective time specifier, basis list e,
capture whether condition met, adding switch variable switch indicate whether
condition met vectors, switch variables [switch t1 ...switch tn ] element [1..s]
list e, indicating whether met single vector. constraints (where
small number) then:


w.e[x] N + (N + c) switch

x[1...s]



w.e[x] (c ) + N switch tx

x[1...s]

switch + 1.switch t0 + ... + 1.switch ts 1 s.
first quantification ensures switch = 1, lower bound c imposed w v
element e. second quantification ensures vector v index x e satisfies
w v c, corresponding switch variable switch tx take value 1. third
constraint ensures switch variables switch tx take value 1, switch must, too, set
1. appropriately constrained switch variable update constraint governing
value LP variable reward 0n (the value reward end plan) increase
value k switch.
D.3 Optimising Time-Dependent Conditions
final extension allow conditional effects refer truth values timed
propositions, values numeric variables, also value duration action.
11. Timed Initial Fluents used domain models, unofficial extension language.
semantics extension straightforward Timed Initial Literals.

75

fiC OLES , C OLES , F OX & L ONG

situation appears example airplane landing problem (Section 10.2) value
(total-cost) updated conditional effect, condition effect depend
?duration. consider example order show MILP extended
handle updates. First, previous cases, need add constraints ensure
MILP solver chooses obtain conditioned outcome conditioned effect, condition
must met. So, example, introduce new variable binary switch variable
condition, new constraints. land action plane ?p, starting finishing
time-stamps action step n step respectively, add pair constrained switch variables.
sake example give meaningful names early late. constraints
added LP then:
target p step + step n
step step n
target p + step step n
step step n






N early
N (N + target p) early
N late
(target p + ) late

new constraints ensure plane lands early, variable early take value
1, vice versa. Similarly, lands late, late must take value 1 vice versa. case
example, conditional effects action mutually exclusive, though true
general case.
defined early late switch variables, objective function MILP must
augmented reflect conditional outcomes action. Two terms must added one
switch variable effect obtained switch variable 1. Abbreviating terms
earlyPenaltyRate, latePenaltyRate latePenalty epr, lpr lp, respectively,
objective terms plane p are:
early (epr p) (target p (step step n ))
late (lpr p) ((step step n ) target p) + late (lp p)
Note unlike previous cases, objective function quadratic: objective
contains terms switch variable multiplied constant step variable.
arises as, unlike previous cases, conditional effect duration dependent fixed, constant value k. Whilst raises computational cost optimising MILP, cost acceptable: incurred once, solution plan found.

Appendix E. Details Empirical Evaluation Colin
graphs presented show detailed runtime quality comparisons analysed Section 12. comparative data graphed. Since graphs sometimes superimpose curves one
another, making difficult see COLIN performing, Tables 613 show raw time
quality results COLIN compared average best times qualities problems. Best
times qualities also reported corresponding quality time (respectively)
solution, planner(s) generated best result.

76

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Depots Simple Time
1000

100

100

10

Time (s)

Time (s)

Driverlog Simple Time
1000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

1

1

0.1

0.1

0.01

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

0.01
5

10
Problem Number

15

20

2

4

6

Rovers Simple Time
100

10

Time (s)

Time (s)

10
12
Problem Number

14

16

18

20

14

16

18

20

Satellite Simple Time
100

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

8

1

0.1

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

1

0.1

0.01

0.01
2

4

6

8

10
12
Problem Number

14

16

18

20

14

16

18

20

2

4

6

8

10
12
Problem Number

Zeno Simple Time
10000

1000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

Time (s)

100

10

1

0.1

0.01
2

4

6

8

10
12
Problem Number

Figure 21: Comparison time taken solve problems various simple temporal planning benchmarks planners COLIN, LPG-td, LPG.s, Sapa temporal baseline planner.
Planners appearing particular dataset solve problems
collection.

77

fiC OLES , C OLES , F OX & L ONG

Depots Simple Time
600

Driverlog Simple Time
3000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

500

2500

2000
Makespan

400
Makespan

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

300

1500

200

1000

100

500

0

0
5

10
Problem Number

15

20

2

4

6

Rovers Simple Time
400

400

250

Makespan

Makespan

300

10
12
Problem Number

14

16

18

20

14

16

18

20

Satellite Simple Time
500

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

350

8

200
150

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

300

200

100
100
50
0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

14

16

18

20

2

4

6

8

10
12
Problem Number

Zeno Simple Time
7000
6000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

Makespan

5000
4000
3000
2000
1000
0
2

4

6

8

10
12
Problem Number

Figure 22: Comparison plan quality problems various simple temporal planning benchmarks planners COLIN, LPG-td, LPG.s, Sapa temporal baseline planner.
Planners appearing particular dataset solve problems
collection.

78

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Depots Time
100

Driverlog Time
10000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

1000

Time (s)

Time (s)

100

1

10

1
0.1
0.1

0.01

0.01
5

10
Problem Number

15

20

2

4

6

8

Rovers Time
100

14

16

18

20

14

16

18

20

Satellite Time
1000

Colin
LPG-TD
LPG.s
Sapa

100

Time (s)

10

Time (s)

10
12
Problem Number

1

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

10

1
0.1
0.1

0.01

0.01
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

8

10
12
Problem Number

Figure 23: Comparison time taken solve problems complex temporal planning benchmarks (first set) planners COLIN, LPG-td, LPG.s, Sapa temporal baseline
planner. Planners appearing particular dataset solve problems
collection.

79

fiC OLES , C OLES , F OX & L ONG

Zeno Time
1000

Airport Strips Temporal
1000

Colin
LPG-TD
LPG.s
Sapa

100

100

Time (s)

10

Time (s)

Colin
LPG-TD
LPG.s
Temp-Baseline

10

1

1

0.1

0.1

0.01

0.01
2

4

6

8

10
12
Problem Number

14

16

18

20

5

10

15

Pipes No-Tankage Temporal
10000

1000

35

40

45

50

35

40

45

50

Pipes Tankage Temporal
10000

Colin
LPG-TD
LPG.s
Temp-Baseline

1000

Colin
LPG-TD
LPG.s
Temp-Baseline

100
Time (s)

100
Time (s)

20
25
30
Problem Number

10

10

1

1

0.1

0.1

0.01

0.01
5

10

15

20
25
30
Problem Number

35

40

45

50

5

10

15

20
25
30
Problem Number

Figure 24: Comparison time taken solve problems complex temporal planning benchmarks (second set) planners COLIN, LPG-td, LPG.s, Sapa temporal baseline
planner. Planners appearing particular dataset solve problems
collection.

80

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Depots Time
2000

Driverlog Time

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

1500

7000
6000

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

Makespan

Makespan

5000

1000

4000
3000
2000

500

1000
0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

8

Rovers Time
800

1400

600

1200

500

1000

Makespan

Makespan

14

16

18

20

14

16

18

20

Satellite Time
1600

Colin
LPG-TD
LPG.s
Sapa

700

10
12
Problem Number

400

800

300

600

200

400

100

200

0

Colin
LPG-TD
LPG.s
Sapa
Temp-Baseline

0
2

4

6

8

10
12
Problem Number

14

16

18

20

2

4

6

8

10
12
Problem Number

Figure 25: Comparison plan quality complex temporal planning benchmarks (first set)
planners COLIN, LPG-td, LPG.s, Sapa temporal baseline planner. Planners
appearing particular dataset solve problems collection.

81

fiC OLES , C OLES , F OX & L ONG

Zeno Time
400

Airport Strips Temporal
1000

Colin
LPG-TD
LPG.s
Sapa

350

800

Colin
LPG-TD
LPG.s
Temp-Baseline

250

Makespan

Makespan

300

200
150

600

400

100
200
50
0

0
2

4

6

8

10
12
Problem Number

14

16

18

20

5

10

15

Pipes No-Tankage Temporal
140
120

35

40

45

50

35

40

45

50

Pipes Tankage Temporal

Colin
LPG-TD
LPG.s
Temp-Baseline

140
120

Colin
LPG-TD
LPG.s
Temp-Baseline

100
Makespan

100
Makespan

20
25
30
Problem Number

80
60

80
60

40

40

20

20

0

0
5

10

15

20
25
30
Problem Number

35

40

45

50

5

10

15

20
25
30
Problem Number

Figure 26: Comparison plan quality complex temporal planning benchmarks (second
set) planners COLIN, LPG-td, LPG.s, Sapa temporal baseline planner. Planners appearing particular dataset solve problems collection.

82

fiC OLIN : P LANNING C ONTINUOUS C HANGE

COLIN

Time
Quality
depotssimpletime
1
0.03
36.008
2
0.03
54.013
3
13.69 170.037
4
11.67
82.031
5
6
7
2.56
51.024
8
9
10
1.39
90.025
11
12
13
0.17
85.026
14
15
16
0.25
99.025
17
0.48
61.016
18
19
20
21
1.69
96.029
22
driverlogsimpletime
1
0.02
92.006
2
0.16
169.021
3
0.04
67.012
4
0.25
129.018
5
0.11
106.017
6
0.09
114.011
7
0.05
58.011
8
0.19
151.023
9
0.42
213.026
10
0.04
84.021
11
0.04
108.019
12
3.22
380.041
13
1.09
283.039
14
1.45
240.036
15
0.25
283.043
16
17
18
19
20

Average
Time
Quality

Best
Time

Planner

Quality

Planner

LPG -td,TBL

28.000 (0.0)
46.090 (0.374)
80.002 (0.11)
56.24 (0.42)
115.000 (0.11)
156.004 (205.29)
45.001 (0.11)
87.003 (0.48)
190.000 (0.29)
52.000 (0.05)
152.000 (0.26)
133.000 (0.62)
64.001 (0.33)
64.001 (0.96)
186.000 (0.45)
46.000 (0.08)
28.050 (10.728)
105.000 (1.04)
94.000 (0.19)
101.002 (27.84)
73.000 (0.56)
329.007 (111.46)

LPG -s+td

91.001 (0.04)
104.001 (0.03)
40.02 (0.116)
99.001 (0.02)
75.08 (0.957)
64.070 (0.963)
49.090 (0.3)
77.090 (0.869)
150.002 (0.13)
49.090 (0.404)
85.090 (0.474)
274.3 (0.05)
240.003 (0.76)
163.22 (4.388)
157.210 (13.457)
1510.000 (50.78)
653.008 (16.28)
361.67 (79.06)
1478.000 (47.08)
478.000 (6.19)

LPG -s

0.040
0.097
3.462
3.097
1.620
103.400
0.677
0.223
0.625
4.100
7.933
5.880
0.475
0.400
2.655
0.928
2.716
3.217
0.517
10.443
17.448
54.667

34.834
64.243
110.817
74.818
131.250
171.002
59.049
95.784
213.300
81.465
212.845
188.251
79.265
83.767
212.502
85.273
55.261
109.144
118.787
238.291
85.872
406.609

0.0 (28.000)
0.01 (54.11)
0.02 (82.000)
0.04 (88.000)
0.11 (115.000)
1.51 (186.000)
0.01 (82.17)
0.09 (105.000)
0.29 (190.000)
0.03 (88.2)
0.26 (152.000)
0.62 (133.000)
0.02 (82.17)
0.1 (107.3)
0.45 (186.000)
0.04 (98.18)
0.23 (61.000)
1.03 (117.43)
0.14 (164.36)
0.75 (209.000)
0.19 (90.18)
8.95 (536.000)

0.024
0.166
0.039
0.150
0.223
0.241
0.086
0.238
0.301
0.131
0.153
1.012
0.650
1.790
3.299
112.980
7.133
64.420
47.080
6.190

96.025
127.460
59.215
112.460
92.054
93.031
63.838
153.071
204.692
93.645
104.058
339.586
274.338
291.536
278.920
1849.014
790.049
644.560
1478.000
478.000

0.0 (91.05)
0.01 (110.19)
0.01 (40.04)
0.01 (110.15)
0.01 (83.17)
0.02 (74.000)
0.01 (51.09)
0.01 (167.24)
0.04 (232.26)
0.01 (71.11)
0.01 (119.18)
0.05 (274.3)
0.31 (299.000)
0.24 (391.000)
0.14 (278.34)
50.78 (1510.000)
1.86 (1052.000)
21.03 (869.000)
47.08 (1478.000)
6.19 (478.000)

TBL
LPG -td
LPG -td
LPG -td
LPG -td
TBL
LPG -td
LPG -td
TBL
LPG -td
LPG -td
TBL
TBL
LPG -td
TBL
LPG -td
TBL
TBL
LPG -td
TBL
LPG -td
TBL
LPG -td,TBL
LPG -s,TBL

TBL
LPG -td,TBL
LPG -td
TBL
TBL
LPG -td,TBL
TBL
TBL
TBL
LPG -td
LPG -td
TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

Sapa
LPG -s

TBL
LPG -td
LPG -s
LPG -s
LPG -s
LPG -td
LPG -td
LPG -td
LPG -td
LPG -s
LPG -s
LPG -td
LPG -td

Sapa
LPG -td
LPG -td
LPG -s
LPG -td
LPG -s

LPG -s

Sapa
LPG -s

Sapa
Sapa
Sapa
Sapa
LPG -s
Sapa
Sapa
TBL
LPG -s
Sapa
Sapa
LPG -td
LPG -s
TBL
LPG -td
LPG -td

Table 6: Results Simple Domains: Best results show best time (corresponding quality)
planner(s) achieved time best quality (corresponding time) planner(s)
achieving quality. TBL Temporal Baseline planner following tables.

83

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
Quality
roverssimpletime
1
0.02
67.007
2
0.02
48.006
3
0.02
73.01
4
0.02
50.005
5
0.04
126.014
6
0.09
186.028
7
0.04
107.013
8
0.06
119.018
9
0.09
176.028
10
0.11
155.019
11
0.11
161.025
12
0.05
103.014
13
0.22
198.029
14
0.12
170.021
15
0.21
208.038
16
0.26
203.032
17
0.23
267.036
18
0.49
217.039
19
0.72
339.047
20
9.51
392.063
satellitesimpletime
1
0.01
41.008
2
0.01
65.012
3
0.02
50.01
4
0.04
87.019
5
0.05
74.016
6
0.07
72.019
7
0.09
72.022
8
0.14
84.024
9
0.21
95.028
10
0.26
101.029
11
0.37
113.031
12
2.49
137.041
13
13.38 214.061
14
5.11
166.039
15
6.47
183.056
16
5.78
170.045
17
4.52
133.041
18
0.82
107.031
19
27.98 349.075
20

Average
Time
Quality

Best
Time

Planner

Quality

Planner

TBL
TBL
LPG -td
TBL
LPG -td,TBL
LPG -td
TBL
TBL
LPG -td,TBL
TBL
TBL
TBL
TBL
TBL
TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

67.007 (0.02)
45.000 (0.02)
67.089993 (0.15)
45.039997 (0.081)
107.15 (0.01)
183.29 (0.02)
91.001 (0.04)
113.19 (0.02)
156.18999 (0.508)
139.14 (25.24)
161.025 (0.11)
88.08 (1.035)
173.17998 (6.716)
139.000 (0.04)
175.21999 (2.776)
186.20998 (6.67)
218.22993 (9.01)
140.28 (0.15)
297.5 (0.38)
351.000 (0.49)

COLIN

TBL

41.000 (0.01)
65.000 (0.02)
29.000 (0.02)
58.000 (0.01)
61.001 (0.09)
58.09 (0.01)
46.001 (0.13)
41.000 (0.03)
51.001 (0.33)
63.000 (0.05)
72.000 (0.07)
98.000 (0.11)
99.002 (2.75)
68.000 (0.13)
58.001 (2.54)
73.002 (4.12)
92.002 (4.29)
75.002 (1.42)
114.003 (2.57)
137.24 (31.225)

0.032
0.030
0.040
0.030
0.220
0.058
0.146
0.247
0.148
5.110
0.085
0.253
1.565
0.239
0.671
1.464
1.992
2.158
1.058
4.317

72.834
48.223
76.238
51.621
131.461
229.580
97.851
131.066
166.296
158.878
179.322
112.041
227.708
157.483
207.310
208.513
255.936
170.494
319.138
380.932

0.0 (67.08)
0.01 (47.06)
0.0 (77.000)
0.01 (50.06)
0.01 (107.15)
0.01 (277.000)
0.01 (98.13)
0.02 (113.19)
0.02 (159.000)
0.02 (141.23)
0.02 (185.26)
0.01 (90.11)
0.06 (190.33)
0.02 (145.22)
0.04 (215.29)
0.04 (242.000)
0.11 (259.000)
0.1 (160.000)
0.23 (319.000)
0.49 (351.000)

0.022
0.042
0.049
0.080
0.103
0.128
0.179
0.266
0.517
0.563
0.806
2.183
8.604
4.859
10.845
13.916
16.070
2.084
9.740
9.739

43.032
66.310
45.040
78.268
75.259
72.846
67.655
73.267
70.866
79.678
90.667
119.533
165.517
111.078
152.335
143.923
124.495
93.269
170.718
231.793

0.0 (46.07)
0.01 (65.012)
0.01 (58.09)
0.01 (58.000)
0.01 (82.13)
0.01 (58.09)
0.02 (75.12)
0.03 (41.000)
0.04 (58.000)
0.05 (63.000)
0.07 (72.000)
0.11 (98.000)
0.2 (208.000)
0.13 (68.000)
0.17 (183.000)
0.23 (137.000)
0.21 (142.000)
0.1 (101.000)
0.17 (130.000)
0.26 (196.000)

COLIN ,TBL

TBL
LPG -td,TBL
TBL
TBL
TBL
LPG -td,TBL
LPG -td,TBL
LPG -td
LPG -td,TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

LPG -s

Sapa
Sapa
TBL
TBL
LPG -s
TBL
Sapa
Sapa
COLIN

Sapa
Sapa
LPG -td
Sapa
Sapa
Sapa
TBL
TBL
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -s

TBL
LPG -s
LPG -td
LPG -s
LPG -td
LPG -td
LPG -td
LPG -s
LPG -td
LPG -s
LPG -s
LPG -s
LPG -s
LPG -s

Sapa

Table 7: Results Simple Domains: Best results show best time (corresponding quality)
planner(s) achieved time best quality (corresponding time) planner(s)
achieving quality.

84

fiC OLIN : P LANNING C ONTINUOUS C HANGE

COLIN

Time
zenosimpletime
1
0.01
2
0.02
3
0.02
4
0.04
5
0.03
6
0.05
7
0.08
8
0.15
9
0.31
10
0.12
11
0.26
12
0.3
13
6.19
14
15
19.48
16
477.47
17
759.19
18
19
48.95
20
163.2

Quality
173.001
592.008
350.007
885.013
656.011
995.016
931.014
895.013
1583.027
1191.022
796.015
1208.027
2062.04
2836.051
3173.045
4947.071
4309.079
5364.096

Average
Time
Quality
0.016
0.033
0.047
0.062
0.121
0.191
0.218
0.440
1.021
0.696
1.785
1.900
5.261
360.254
10.105
127.658
246.098
43.737
22.740
59.687

178.602
666.022
356.619
1226.041
868.832
1456.434
1006.035
869.291
1268.456
1461.053
823.433
1617.856
1303.254
1577.821
2561.808
2394.072
5232.603
2983.101
5043.146
5315.165

Best
Time

Planner

Quality

Planner

0.0 (180)
0.01 (866.05)
0.01 (280.04)
0.01 (936.000)
0.0 (400.06)
0.01 (603.06)
0.01 (706.08)
0.02 (836.07)
0.03 (789.12)
0.03 (743.13)
0.03 (763.1)
0.03 (1199.13)
0.03 (923.14)
0.3 (2068.18)
0.46 (2254.18)
0.86 (1702.24)
2.36 (3436.34)
2.61 (3453.3)
8.91 (3769.36)
6.43 (4578.4)

TBL
TBL
TBL
LPG -td,TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL
TBL

173.001 (0.01)
592.008 (0.02)
280.04 (0.01)
885.013 (0.04)
400.06 (0.0)
603.06 (0.01)
706.08 (0.01)
836.07 (0.02)
789.12 (0.03)
743.13 (0.03)
510.050 (8.037)
1166.120 (8.568)
923.14 (0.03)
1169.100 (1433.534)
2254.18 (0.46)
1702.24 (0.86)
3436.34 (2.36)
2383.003 (121.90)
3769.36 (8.91)
4578.4 (6.43)

COLIN
COLIN

TBL
COLIN

TBL
TBL
TBL
TBL
TBL
TBL
Sapa
Sapa
TBL
Sapa
TBL
TBL
TBL
LPG -s
TBL
TBL

Table 8: Results Simple Domains: Best results show best time (corresponding quality)
planner(s) achieved time best quality (corresponding time) planner(s)
achieving quality.

85

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
Quality
airportstripstemporal
1
0.06
64.007
2
0.06
185.008
3
0.09
202.011
4
0.30
127.019
5
0.26
227.02
6
0.30
301.04
7
0.30
301.04
8
0.52
538.059
9
1.40
516.058
10
0.33
126.017
11
0.35
228.02
12
0.36
265.035
13
0.44
311.034
14
0.71
528.057
15
0.58
365.049
16
1.68
625.076
17
11.47 603.084
18
58.89 777.095
19
38.65 574.076
20
21
21.65
366.1
22
22.52 487.147
23
23.68 510.166
24
31.00 826.156
25
90.81 934.204
26
27
28
29
30
31
32
33
34
35
36
46.83 408.108
37
78.05 672.136
38
49.89 847.217
39
40
41
52.64 895.241
42
43
44
46

Average
Time
Quality
0.030
0.030
0.040
0.120
0.103
0.130
0.130
0.237
1.672
0.130
0.135
0.155
0.170
0.465
0.257
2.738
6.093
25.983
226.607
66.563
80.240
6.178
6.425
8.307
34.577
53.480
5.190
94.760
94.955
5.420
6.820
443.075
14.950
15.710
17.110
16.063
36.820
17.833
476.650
91.395
24.803
841.960
35.450
701.750
289.270

64.026
185.022
200.533
127.070
227.055
251.363
251.363
432.165
433.918
126.062
228.055
239.352
254.852
426.657
357.633
536.440
542.947
652.658
453.467
643.625
305.519
428.104
369.363
493.835
650.231
480.785
511.111
623.910
596.410
641.000
834.000
724.570
859.000
879.000
887.000
350.705
620.047
580.741
962.000
510.004
596.749
579.000
639.506
331.000
737.000

Best
Time
0.01 (64.07)
0.01 (185.000)
0.01 (200.12)
0.02 (127.19)
0.02 (227.2)
0.02 (240.41)
0.02 (240.41)
0.06 (402.6)
0.10 (402.000)
0.01 (126.17)
0.02 (228.2)
0.02 (228.37)
0.03 (237.37)
0.07 (390.57)
0.06 (273.48)
0.14 (558.000)
0.61 (569.000)
0.25 (733.000)
0.50 (413.000)
0.27 (740.000)
0.33 (285.97)
0.78 (286.26)
0.49 (265.28)
0.61 (377.18)
2.47 (539.000)
3.88 (584.000)
7.50 (505.33)
7.53 (706.000)
4.47 (687.000)
5.42 (641.000)
6.82 (834.000)
7.78 (815.000)
14.95 (859.000)
15.71 (879.000)
17.11 (887.000)
1.36 (322.000)
32.41 (831.000)
3.61 (573.000)
476.65 (962.000)
182.79 (584.000)
21.77 (573.000)
841.96 (579.000)
70.90 (573.000)
701.75 (331.000)
289.27 (737.000)

Planner

Quality

Planner

TBL

64.000 (0.02)
185.000 (0.01)
200.000 (0.03)
127.000 (0.04)
227.000 (0.05)
232.000 (0.07)
232.000 (0.07)
394.000 (0.09)
402.000 (0.10)
126.000 (0.05)
228.000 (0.07)
228.37 (0.02)
230.002 (0.14)
390.57 (0.07)
273.48 (0.06)
404.68 (0.24)
417.7 (2.16)
447.88 (18.81)
413.000 (0.50)
450.87 (55.03)
285.000 (0.77)
286.26 (0.78)
264.004 (510.166)
376.003 (826.156)
477.49 (10.45)
377.57 (103.08)
504.004 ()
541.82 (181.99)
505.82 (185.44)
641.000 (5.42)
834.000 (6.82)
634.14 (878.37)
859.000 (14.95)
879.000 (15.71)
887.000 (17.11)
322.000 (1.36)
357.006 (672.136)
322.006 (847.217)
962.000 (476.65)
436.007 ()
322.006 (895.241)
579.000 (841.96)
573.000 (70.90)
331.000 (701.75)
737.000 (289.27)

LGP -td

LGP -td,TBL

TBL
TBL
TBL
TBL
TBL
TBL
LGP -td
TBL
TBL
TBL
TBL
TBL
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
TBL
TBL
TBL
TBL
LGP -td
LGP -td
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td

LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td

TBL
LGP -s

TBL
TBL
TBL
TBL
TBL
LGP -td
TBL
LGP -td
TBL
LGP -s
LGP -s
TBL
TBL
LGP -s
TBL
TBL
LGP -td
LGP -td
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -s
LGP -s
LGP -td
LGP -s
LGP -s
LGP -td
LGP -td
LGP -td
LGP -td

Table 9: Results Complex Domains: Best results show best time (corresponding quality) planner(s) achieved time best quality (corresponding time)
planner(s) achieving quality.

86

fiC OLIN : P LANNING C ONTINUOUS C HANGE

COLIN

Time
Quality
depotstime
1
0.03
59.746
2
0.14
66.79
3
4
67.41
258.125
5
6
7
35.56
129.741
8
9
10
43.34
296.354
11
12
13
0.27
108.493
14
15
16
0.60
50.588
17
18
19
20
21
2.08
76.753
22
driverlogtime
1
0.02
303.006
2
0.17
462.019
3
0.03
202.009
4
0.14
474.019
5
0.20
343.019
6
0.03
275.007
7
0.12
316.012
8
0.43
699.024
9
0.57
730.028
10
0.21
294.031
11
0.16
522.026
12
5.90
1066.038
13
2.84
1052.031
14
6.51
787.034
15
0.27
212.042
16
17
18
19
20

Average
Time
Quality

Best
Time

Planner

Quality

Planner

TBL
TBL
TBL
LGP -td
LGP -td
LGP -td
TBL
LGP -td,TBL
LGP -td
TBL
LGP -td
LGP -td
TBL
TBL
LGP -td
TBL
TBL
LGP -td
TBL
LGP -td
TBL
LGP -td

55.181 (0.01)
60.556 (0.02)
127.592 (0.03)
160.139 (0.04)
777.544 (3.12)
287.543 (2.35)
107.340 (0.12)
108.399 (0.10)
1655.27 (0.97)
151.173 (11.364)
599.323 (1.42)
132.893 (4.33)
82.834 (1.373)
157.701 (1.02)
382.973 (4.16)
26.390 (0.56)
46.2 (0.20)
395.768 (0.89)
366.474 (1.22)
592.561 (7.98)
54.731 (36.794)
343.110 (3.86)

LGP -td

TBL

302 (0.01)
294.090 (0.678)
173.020 (0.131)
402.001 (0.04)
161.090 (0.973)
260 (0.02)
268.1 (0.01)
388.110 (1.244)
591 (0.02)
220.110 (0.415)
306.13 (0.486)
627.260 (1151.634)
597.180 (4.193)
625.150 (7.34)
212.042 (0.27)
3652.008 (28.03)
2238 (3.31)
1476.68 (78.94)
3993 (63.87)
1691.007 (66.56)

LGP -td

0.036
0.103
0.087
17.043
2.970
2.350
8.933
0.240
0.650
11.027
1.020
5.387
0.417
0.427
2.290
4.754
1.977
3.077
0.520
3.743
9.693
47.470

57.698
71.719
141.362
186.587
781.855
287.543
141.337
119.161
1783.468
226.698
726.121
163.032
99.751
216.623
399.697
76.900
87.495
535.942
428.210
880.639
71.388
445.232

0.00 (58.9311)
0.01 (73.2211)
0.03 (127.592)
0.04 (160.139)
2.82 (786.1666)
2.35 (287.543)
0.02 (142.158)
0.10 (108.3988)
0.33 (1911.6665)
0.03 (294.293)
0.32 (608.9167)
0.46 (165.5889)
0.02 (104.436)
0.10 (329.133)
0.42 (416.4197)
0.03 (166.236)
0.19 (88.26)
0.75 (709.8509)
0.14 (486.722)
0.93 (1050.2797)
0.16 (101.373)
3.86 (343.1095)

0.017
0.178
0.044
0.128
0.249
0.280
0.072
0.361
0.193
0.159
0.181
233.369
1.743
3.248
59.469
66.385
9.580
48.780
110.925
41.060

302.625
442.260
279.018
453.060
250.058
266.432
350.041
695.275
748.078
328.450
515.068
1230.325
1218.305
1125.322
766.155
5120.504
2787.062
2319.229
4005.005
3828.003

0.00 (302.05)
0.01 (438.19)
0.01 (173.06)
0.01 (441.15)
0.01 (195.18)
0.02 (260)
0.01 (268.1)
0.01 (894.24)
0.02 (591)
0.01 (394.11)
0.01 (512.18)
0.05 (829.32)
0.32 (903)
0.41 (1161)
0.10 (939.43)
28.03 (3652.0081)
3.31 (2238)
27.48 (2885)
63.87 (3993)
15.56 (5965)

LGP -td,TBL

TBL
TBL
TBL
LGP -td
LGP -td,TBL
TBL
LGP -td
TBL
TBL
TBL
LGP -td
LGP -td
TBL
LGP -s
LGP -td
LGP -td
LGP -td
LGP -td

LGP -td

TBL
LGP -td

TBL
LGP -td
LGP -s
LGP -td

TBL
Sapa
LGP -s
LGP -s
Sapa
LGP -s
LGP -s
LGP -s
LGP -td
TBL
LGP -s
LGP -s
Sapa
LGP -td

Sapa
Sapa
LGP -s
Sapa
LGP -td
TBL
Sapa
LGP -td
Sapa
Sapa
Sapa
Sapa
Sapa
COLIN
LGP -s
LGP -td

TBL
LGP -td
LGP -s

Table 10: Results Complex Domains: Best results show best time (corresponding quality) planner(s) achieved time best quality (corresponding time)
planner(s) achieving quality.

87

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
Quality
pipesnotankagetemporal
1
0.03
6.003
2
0.04
20.011
3
0.05
12.008
4
0.07
22.012
5
0.05
14.006
6
0.05
16.009
7
0.06
12.007
8
0.06
16.009
9
0.08
24.013
10
0.08
28.015
11
0.16
11.026
12
1.77
22.554
13
0.27
16.535
14
0.38
14.532
15
0.14
11.526
16
6.78
30.07
17
4.25
11.023
18
1.08
12.529
19
0.19
9.525
20
0.46
17.039
21
0.09
9.017
22
23
0.19
14.018
24
40.46
29.032
25
26
1.89
32.053
27
0.29
11.527
28
0.77
22.551
29
2.46
21.546
30
31
9.21
18.357
32
13.01
35.038
33
10.53
21.874
34
20.52
30.709
35
36
37
38
39
1.19
13.857
40
41
103.46
4.43
49
50

Average
Time
Quality
0.015
0.058
0.040
0.058
0.043
0.060
0.075
0.100
0.113
0.120
300.430
302.110
0.745
0.380
0.785
2.667
1.143
0.900
0.247
7.977
0.080
2.975
0.240
27.015
4.850
4.140
1.613
16.697
5.560
4.665
3.240
4.485
10.530
34.070
24.200
78.245
31.760
64.855
0.967
10.410
34.820
346.235
15.400

7.506
51.526
17.520
83.021
13.017
24.023
16.015
16.520
29.026
36.037
9.544
16.971
15.687
14.446
16.700
31.401
10.544
18.221
9.898
26.681
9.062
36.700
21.340
101.016
32.165
28.148
13.572
42.977
18.272
32.205
16.098
51.504
21.874
39.582
17.334
18.078
36.000
12.822
18.356
34.665
4.173
16.493
18.380

Time
0.00 (6.02)
0.01 (20.09)
0.01 (16.07)
0.01 (16.07)
0.01 (12.000)
0.01 (18.08)
0.01 (12.05)
0.03 (18.000)
0.02 (20.09)
0.02 (28.13)
0.05 (8.15)
0.28 (17.33)
0.05 (11.21)
0.15 (14.000)
0.12 (14.27)
0.48 (40.000)
0.09 (8.15)
0.20 (18.35)
0.11 (9.17)
0.46 (0.46)
0.02 (9.17)
2.05 (23.4)
0.19 (14.018)
13.57 (173.000)
1.12 (42.000)
1.46 (27.39)
0.29 (11.527)
0.77 (22.551)
0.34 (14.27)
1.39 (27.41)
0.17 (16.9367)
0.89 (17.31)
10.53 (21.874)
1.40 (23.370033)
48.40 (24.000)
6.49 (21.156633)
31.76 (36.000)
0.32 (13.6433)
0.17 (12.21)
10.41 (34.665)
0.10 (4.09)
2.15 (16.32)
15.40 (18.38)

Best
Planner
TBL
TBL
TBL
TBL
LGP -td,TBL
TBL
TBL
LGP -td
TBL
TBL
TBL
TBL
TBL
LGP -td
TBL
LGP -td
TBL
TBL
TBL
COLIN

TBL
TBL
COLIN
LGP -td
LGP -td

TBL
COLIN
COLIN

TBL
TBL
TBL
TBL
COLIN

TBL
LGP -td
TBL
LGP -td
TBL
TBL
LGP -td
TBL
TBL
TBL

Quality

Planner

6.000 (0.01)
20.011 (0.04)
12.008 (0.05)
16.07 (0.01)
12.000 (0.01)
16.009 (0.05)
12.007 (0.06)
16.001 (0.19)
20.09 (0.02)
28.015 (0.08)
8.15 (0.05)
11.002 (1200.92)
11.21 (0.05)
13.25 (0.99)
11.526 (0.14)
27.53 (3.41)
8.002 (11.023)
12.529 (1.08)
9.17 (0.11)
14.003 (17.039)
9.000 (0.13)
23.4 (2.05)
14.018 (0.19)
29.032 (40.46)
22.33 (8.58)
25.000 (9.07)
10.19 (0.48)
22.551 (0.77)
14.27 (0.34)
27.41 (1.39)
13.000 (0.34)
17.31 (0.89)
21.874 (10.53)
23.370033 (1.40)
10.669 ()
15.000 (150.00)
36.000 (31.76)
12.000 (129.39)
12.21 (0.17)
34.665 (10.41)
4.000 (0.90)
16.32 (2.15)
18.38 (15.40)

LGP -td
COLIN
COLIN

TBL
LGP -td
COLIN
COLIN
LGP -s

TBL
COLIN

TBL
LGP -s

TBL
TBL
COLIN

TBL
LGP -s
COLIN

TBL
LGP -s
LGP -td

TBL
COLIN
COLIN

TBL
LGP -td

TBL
COLIN

TBL
TBL
LGP -td
TBL
COLIN

TBL
LGP -s
LGP -td
LGP -td
LGP -td

TBL
LGP -td
LGP -td

TBL
TBL

Table 11: Results Complex Domains: Best results show best time (corresponding quality) planner(s) achieved time best quality (corresponding time)
planner(s) achieving quality.

88

fiC OLIN : P LANNING C ONTINUOUS C HANGE

COLIN

Time
Quality
pipestankagetemporal
1
0.04
6.003
2
0.12
24.013
3
0.23
12.008
4
0.52
18.009
5
0.09
14.007
6
0.09
16.01
7
0.26
16.008
8
0.30
18.012
9
10
4.40
36.02
11
0.40
13.031
12
13
1.51
13.53
14
53.09
22.052
15
59.61
17.541
17
18
33.06
11.527
19
20.29
16.537
20
2.54
12.029
21
22
23
24
23.25
31.564
25
983.78
28.558
26
32.55
33.053
27
2.30
10.024
29
191.49
23.548
30
58.98
28.555
31
187.22
32.713
32
33
34
160.42
25.038
37
39
9.14
15.191
40
51.82
21.877
41
269.57
4.93
49
50
82.82
22.378

Average
Time
Quality
0.020
0.147
0.180
0.275
0.153
0.160
1.175
1.275
238.057
26.135
316.585
12.480
6.420
334.625
64.690
1500.780
105.157
252.310
118.323
1.830
77.570
41.080
112.000
710.420
389.255
7.000
364.450
354.695
249.670
696.495
304.470
432.870
598.180
298.620
51.820
138.057
91.770
82.820

8.006
63.371
15.520
26.020
20.017
17.018
18.522
23.031
66.741
57.571
27.601
27.105
13.265
19.357
14.886
31.000
28.626
17.582
24.610
14.595
25.690
30.000
37.782
56.483
31.991
16.012
28.274
30.777
31.041
34.158
21.133
40.065
20.665
22.925
21.877
6.687
17.340
22.378

Time
0.00 (6.02)
0.02 (22.1)
0.06 (16.07)
0.04 (16.07)
0.02 (14.06)
0.02 (14.06)
0.07 (18.08)
0.30 (18.012)
0.95 (104.000)
0.32 (54.26)
0.40 (13.031)
5.08 (43.000)
1.51 (13.53)
9.17 (19.37)
59.61 (17.541)
1500.78 (31.000)
33.06 (11.527)
17.59 (11.21)
2.54 (12.029)
0.11 (10.19)
53.50 (30.000)
41.08 (30.000)
23.25 (31.564)
527.52 (116.500)
32.55 (33.053)
2.30 (10.024)
191.49 (23.548)
58.98 (28.555)
0.84 (31.7833)
179.24 (35.3167)
304.47 (21.133333)
31.22 (33.99)
598.18 (20.665)
9.14 (15.191)
51.82 (21.877)
32.63 (6.13)
91.77 (17.34)
82.82 (22.378)

Best
Planner
TBL
TBL
TBL
TBL
TBL
TBL
TBL
COLIN
LGP -td

TBL
COLIN
LGP -td
COLIN

TBL
COLIN
LGP -td
COLIN

TBL
COLIN

TBL
LGP -td
LGP -td
COLIN
LGP -td
COLIN
COLIN
COLIN
COLIN

TBL
TBL
TBL
TBL
LGP -td
COLIN
COLIN

TBL
TBL
COLIN

Quality

Planner

6.000 (0.03)
22.1 (0.02)
12.008 (0.23)
16.07 (0.04)
14.007 (0.09)
14.06 (0.02)
16.000 (0.31)
18.012 (0.30)
46.22 (6.34)
36.02 (4.40)
13.003 (1235.31)
11.21 (19.88)
13.000 (11.33)
18.000 (1276.24)
12.23 (69.77)
31.000 (1500.78)
11.527 (33.06)
11.21 (17.59)
12.029 (2.54)
10.19 (0.11)
21.38 (101.64)
30.000 (41.08)
31.564 (23.25)
24.39 (619.96)
30.93 (745.96)
10.024 (2.30)
23.548 (191.49)
28.555 (58.98)
29.833 (810.62)
33.000 (1213.75)
21.133333 (304.47)
25.038 (160.42)
20.665 (598.18)
15.191 (9.14)
21.877 (51.82)
4.93 (269.57)
17.34 (91.77)
22.378 (82.82)

LGP -s

TBL
COLIN

TBL
COLIN

TBL
LGP -td
COLIN

TBL
COLIN
LGP -s

TBL
LGP -td
LGP -td

TBL
LGP -td
COLIN

TBL
colin
TBL
TBL
LGP -td
COLIN

TBL
TBL
COLIN
COLIN
COLIN
LGP -td
LGP -td

TBL
COLIN
LGP -td
COLIN
COLIN
COLIN

TBL
COLIN

Table 12: Results Complex Domains: Best results show best time (corresponding quality) planner(s) achieved time best quality (corresponding time)
planner(s) achieving quality.

89

fiC OLES , C OLES , F OX & L ONG

COLIN

Time
roverstime
1
0.03
2
0.01
3
0.03
4
0.03
5
0.06
6
40.93
7
0.07
8
0.17
9
10
0.29
11
0.15
12
0.86
13
14
15
16
17
0.70
18
1.35
19
20
92.59
satellitetime
1
0.02
2
0.01
3
0.01
4
0.03
5
0.11
6
0.10
7
0.12
8
0.30
9
0.38
10
0.64
11
0.94
12
3.57
13
21.89
14
6.19
15
8.76
16
22.18
17
15.29
18
3.85
19
57.66
20

Quality
67.007
48.006
63.01
52.006
125.014
273.118
105.017
149.944
177.022
170.881
122.022

230.036
245.864
390.804
129.596
182.916
78.616
140.42
290.12
114.38
126.544
139.608
175.74
295.549
283.351
336.599
433.308
267.73
292.436
336.356
232.66
169.256
520.602

Average
Time
Quality

Best
Time

Planner

Quality

Planner

LGP -td

67.007 (67.007)
46.0007 (0.02)
63.01 (0.03)
52 (0.02)
107.12 (0.702)
273.118 (40.93)
90.538574 (0.411)
134 (0.04)
128.6895 (0.24)
154.48767 (1.448)
170.881 (0.15)
114.130005 (0.682)
237.8161 (0.86)
137.7917 (0.62)
205.3755 (0.10)
210 (0.46)
230.036 (0.70)
155.0909 (0.33)
394.5915 (0.61)
390.804 (92.59)

COLIN

0.048
0.027
0.062
0.040
0.258
14.010
0.138
0.494
0.150
0.534
0.170
0.476
0.560
0.865
0.500
0.460
2.223
1.817
0.610
49.107

73.524
56.269
70.525
52.733
129.069
299.794
107.121
160.906
137.345
192.855
195.395
134.818
292.200
206.147
239.333
210.000
341.230
220.290
394.591
505.667

0.02 (80)
0.01 (48.006)
0.02 (80)
0.02 (52)
0.02 (113.2)
0.08 (284.965)
0.03 (138.9286)
0.04 (134)
0.06 (146)
0.06 (190.3077)
0.07 (200.5)
0.04 (145.5294)
0.26 (346.5833)
0.35 (268.7368)
0.10 (205.3755)
0.46 (210)
0.34 (392.353)
0.33 (155.0909)
0.61 (394.5915)
3.38 (502.7423)

0.026
0.038
0.068
0.099
0.154
0.138
0.265
0.469
0.813
0.949
1.703
9.147
29.900
10.618
34.225
34.882
94.390
5.306
49.424
30.264

193.553
225.716
168.343
319.688
262.900
255.894
222.818
205.241
307.457
262.206
370.878
423.836
504.815
387.271
333.289
510.100
380.053
290.099
527.707
854.958

0.01 (205.28)
0.00 (235.12)
0.01 (78.616)
0.01 (359.28)
0.01 (254.563)
0.01 (264.51)
0.02 (296.16)
0.03 (226.503)
0.05 (351.8529)
0.04 (231.485)
0.07 (283.916)
0.13 (389.4588)
0.23 (464.408)
0.15 (461.855)
0.18 (267.4431)
0.23 (602.7849)
0.24 (378.459)
0.10 (324.406)
0.19 (352.355)
0.24 (584.663)

COLIN
LGP -td
LGP -s, LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -s, LGP -td,TBL
LGP -td
COLIN ,TBL

TBL
TBL
TBL
TBL
TBL
LGP -td,TBL
LGP -td
TBL
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
LGP -td
TBL
LGP -td
LGP -td

129.596 (0.02)
182.916 (0.01)
78.616 (0.01)
140.42 (0.03)
162.39699 (0.528)
114.38 (0.10)
126.544 (0.12)
139.608 (0.30)
175.74 (0.38)
231.485 (0.04)
283.351 (0.94)
336.599 (3.57)
433.308 (21.89)
267.73 (6.19)
264.6641 (2.48)
336.356 (22.18)
232.66 (15.29)
169.256 (3.85)
352.355 (0.19)
498.90106 (113.277)

LGP -s
COLIN
LGP -td

Sapa
COLIN

Sapa
LGP -td
LGP -s

Sapa
COLIN

Sapa
LGP -s
LGP -s
LGP -td
LGP -td
COLIN
LGP -td
LGP -td
COLIN
COLIN
COLIN
COLIN
COLIN

Sapa
COLIN
COLIN
COLIN
COLIN
LGP -td
COLIN
COLIN
COLIN
COLIN
LGP -s
COLIN
COLIN
COLIN
LGP -td

Table 13: Results Complex Domains: Best results show best time (corresponding quality) planner(s) achieved time best quality (corresponding time)
planner(s) achieving quality.

90

Sapa

fiC OLIN : P LANNING C ONTINUOUS C HANGE

COLIN

Time
zenotime
1
0.01
2
0.01
3
0.03
4
0.08
5
0.04
6
0.08
7
0.06
8
8.53
9
0.22
10
0.41
11
0.41
12
10.34
13
1.28
14
371.61
15
6.95
16
130.33
17
443.79
18
188.85
19
20

Quality
3.672
23.435
10.089
21.287
8.196
21.966
33.31
43.722
39.949
36.458
22.264
72.139
86.473
117.625
381.626
117.052
77.332
89.082

Average
Time
Quality
0.018
0.019
0.033
0.084
0.075
0.075
0.110
2.250
0.194
0.310
0.271
2.874
1.592
256.813
5.524
43.183
161.243
77.357
73.040
80.660

3.489
23.672
13.336
22.340
22.016
20.921
24.863
30.689
48.528
33.487
25.576
51.105
58.235
72.619
241.318
86.693
118.179
70.542
137.909
91.146

Best
Time

Planner

Quality

Planner

0.01 (0.01)
0.01 (0.01)
0.01 (14.4211)
0.01 (21.708)
0.02 (27.0419)
0.02 (20.8864)
0.01 (25.6744)
0.02 (24.2375)
0.03 (72.1579)
0.06 (46.1848)
0.05 (46.1576)
0.09 (42.1671)
0.07 (42.0593)
0.62 (58.8983)
0.87 (274.8496)
3.07 (67.554)
3.97 (117.1512)
4.48 (56.8345)
9.83 (168.0886)
28.69 (78.4703)

COLIN , LPG -td

3.424 (0.01)
23.431 (0.01)
10.089 (0.03)
21.287 (0.08)
8.196 (0.04)
16.578 (0.17)
18.283 (0.05)
24.238 (0.02)
23.238 (0.395)
20.864 (0.14)
13.666 (0.443)
38.992 (0.846)
42.059 (0.07)
39.064 (651.493)
117.171 (8.644)
54.717 (23.883)
77.332 (443.79)
56.835 (4.48)
107.729 (136.25)
78.470 (28.69)

LPG -td

COLIN , LPG -td
LPG -td
LPG -s
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td
LPG -td

LPG -td
COLIN
COLIN
COLIN

Sapa
LPG -s
LPG -td

Sapa
LPG -s

Sapa
Sapa
LPG -td
Sapa
Sapa
Sapa
COLIN
LPG -td
LPG -s
LPG -td

Table 14: Results Complex Domains: Best results show best time (corresponding quality) planner(s) achieved time best quality (corresponding time)
planner(s) achieving quality.

91

fiC OLES , C OLES , F OX & L ONG

References
Audemard, G., Bertoli, P., Cimatti, A., Kornilowicz, A., & Sebastiani, R. (2002). SAT-based approach solving formulas boolean linear mathematical propositions. Proceedings 18th International Conference Automated Deduction, Vol. 2392, pp. 193208.
Springer-Verlag, LNAI Series.
Blum, A., & Furst, M. (1995). Fast Planning Planning Graph Analysis. Proceedings
International Joint Conference Artificial Inteligence (IJCAI).
Boddy, M. S., & Johnson, D. P. (2002). New Method Global Solution Large Systems Continuous Constraints. Proceedings 1st International Workshop Global
Constraint Optimization Constraint Satisfaction (COCOS), Vol. 2861 Lecture Notes
Computer Science, pp. 142156. Springer.
Cesta, A., & Oddi, A. (1996). Gaining Efficiency Flexibility Simple Temporal Problem.
Proceedings 3rd International Workshop Temporal Representation Reasoning
(TIME).
Cesta, A., Cortellessa, G., Fratini, S., & Oddi, A. (2009). Developing End-to-End Planning
Application Timeline Representation Framework. Proceedings 21st Conference
Innovative Applications Artificial Intelligence (IA*AI).
Chien, S. A., Tran, D., Rabideau, G., Schaffer, S. R., Mandl, D., & Frye, S. (2010). Timeline-Based
Space Operations Scheduling External Constraints. Proceedings International
Conference AI Planning Scheduling (ICAPS), pp. 3441.
Cimatti, A., Giunchiglia, F., Giunchiglia, E., & Traverso, P. (1997). Planning via Model Checking:
Decision Procedure R. Recent Advances AI Planning, 4th European Conference
Planning, ECP, pp. 130142.
Coles, A. I., Fox, M., Halsey, K., Long, D., & Smith, A. J. (2008). Managing concurrency
temporal planning using planner-scheduler interaction. Artificial Intelligence, 173, 144.
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008a). Planning Problems Requiring Temporal
Coordination. Proceedings 23rd AAAI Conference Artificial Intelligence (AAAI
08).
Coles, A. I., Fox, M., Long, D., & Smith, A. J. (2008b). Hybrid Relaxed Planning GraphLP
Heuristic Numeric Planning Domains. Proceedings 18th International Conference Automated Planning Scheduling (ICAPS), pp. 5259.
Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2009a). Extending Use Inference Temporal Planning Forwards Search. Proceedings 19th International Conference
Automated Planning Scheduling (ICAPS 09).
Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2009b). Temporal Planning Domains Linear
Processes. Proceedings 21st International Joint Conference Artificial Intelligence
(IJCAI). AAAI Press.
Cushing, W., Kambhampati, S., Mausam, & Weld, D. (2007). temporal planning really
temporal planning?. Proceedings International Joint Conference AI (IJCAI), pp.
18521859.
92

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Dechter, R., Meiri, I., & Pearl, J. (1989). Temporal Constraint Networks. Proceedings Principles Knowledge Representation Reasoning (KR), pp. 8393. Toronto, Canada.
Dierks, H. (2005). Finding Optimal Plans Domains Restricted Continuous Effects
UPPAAL-Cora. ICAPS Workshop Verification Validation Model-Based Planning
Scheduling Systems.
Do, M. B., & Kambhampati, S. (2003). Sapa: Multi-objective Metric Temporal Planner. Journal
Artificial Intelligence Research (JAIR), 20, 155194.
Edelkamp, S. (2003). Taming numbers durations model-checking integrated planning
system. Journal Artificial Intelligence Research (JAIR), 20, 195238.
Edelkamp, S., & Jabbar, S. (2006). Cost-Optimal External Planning. Proceedings 21st
National (American) Conference Artificial Intelligence (AAAI). AAAI Press.
Eyerich, P., Mattmuller, R., & Roger, G. (2009). Using Context-enhanced Additive Heuristic
Temporal Numeric Planning. Proceedings 19th International Conference
Automated Planning Scheduling (ICAPS 2009). AAAI Press.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal planning
domains. Journal Artificial Intelligence Research (JAIR), 20, 61124.
Fox, M., & Long, D. (2006). Modelling Mixed Discrete-Continuous Domains Planning. Journal
Artificial Intelligence Research (JAIR), 27, 235297.
Fox, M., Howey, R., & Long, D. (2005). Validating Plans Context Processes Exogenous
Events. Proceedings 20th National Conference Artificial Intelligence 17th
Innovative Applications Artificial Intelligence Conference (AAAI), pp. 11511156.
Fox, M., Long, D., & Halsey, K. (2004). Investigation Expressive Power PDDL2.1.
Proceedings 16th European Conference Artificial Intelligence (ECAI).
Fox, M., Long, D., & Magazzeni, D. (2011). Automatic Construction Efficient Multiple Battery
Usage Policies. Proceedings 21st International Conference Automated Planning
Scheduling (ICAPS).
Frank, J., & Jonsson, A. K. (2003). Constraint-Based Attribute Interval Planning. Constraints,
8(4), 339364.
Garrido, A., Fox, M., & Long, D. (2002). Temporal Planning System Durative Actions
PDDL2.1. Proceedings 15th Eureopean Conference Artificial Intelligence
(ECAI), pp. 586590.
Garrido, A., Onainda, E., & Barber, F. (2001). Temporal Planning System Time-Optimal
Planning. Proceedings 10th Portuguese Conference Artificial Intelligence, pp.
379392. Springer.
Gerevini, A., Saetti, A., & Serina, I. (2006). Approach Temporal Planning Scheduling
Domains Predictable Exogenous Events. Journal Artificial Intelligence Research
(JAIR), 25, 187231.
Gerevini, A., Saetti, A., & Serina, I. (2010). Temporal Planning Problems Requiring Concurrency Action Graphs Local Search. Proceedings 20th International
Conference Automated Planning Scheduling (ICAPS).
93

fiC OLES , C OLES , F OX & L ONG

Gerevini, A., & Serina, I. (2000). Fast Plan Adaptation Planning Graphs: Local Systematic Search Techniques. Proceedings 5th International Conference Artificial
Intelligence Planning Systems (AIPS), pp. 112121.
Ghallab, M., & Laruelle, H. (1994). Representation Control IxTeT, Temporal Planner.
Proceedings 2nd International Conference Artificial Intelligence Planning Systems
(AIPS), pp. 6167.
Halsey, K. (2005). CRIKEY!: co-ordination temporal planning. Ph.D. thesis, University
Durham.
Haslum, P., & Geffner, H. (2001). Heuristic planning time resources. Proceedings
6th European Conference Planning (ECP01), pp. 121132.
Haslum, P. (2009). Admissible Makespan Estimates PDDL2.1 Temporal Planning. Proceedings ICAPS Workshop Heuristics Domain-Independent Planning.
Helmert, M. (2006). Fast Downward Planning System. Journal Artificial Intelligence (JAIR),
26, 191246.
Henzinger, T. (1996). Theory Hybrid Automata. Proceedings 11th Annual Symposium Logic Computer Science. Invited tutorial., pp. 278292. IEEE Computer Society
Press.
Henzinger, T., Ho, P.-H., & Wong-Toi, H. (1995). user guide HYTECH. E. Brinksma,
W.R. Cleaveland, K.G. Larsen, T. Margaria, B. Steffen, editors, Tool Algorithms
Construction Analysis Systems: (TACAS 95), volume 1019 Lecture Notes
Computer Science, pp. 4171.
Hoffmann, J. (2003). Metric-FF Planning System: Translating Ignoring Delete Lists Numeric State Variables. Journal Artificial Intelligence Research (JAIR), 20, 291341.
Hoffmann, J., & Edelkamp, S. (2005). Deterministic Part IPC-4: Overview. Journal
Artificial Intelligence Research (JAIR), 24, 519579.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research (JAIR), 14, 253302.
Huang, R., Chen, Y., & Zhang, W. (2009). Optimal Temporally Expressive Planner: Initial
Results Application P2P Network Optimization. Proceedings International
Conference Automated Planning Scheduling (ICAPS).
Knight, R., Schaffer, S., & B.Clement (2009). Power planning international space station
domain. Proceedings 6th International Workshop Planning Scheduling
Space (IWPSS).
Lamba, N., Dietz, M., Johnson, D. P., & Boddy, M. S. (2003). Method Global Optimization
Large Systems Quadratic Constraints. Proceedings 2nd International Workshop
Global Optimization Constraint Satisfaction (COCOS), Vol. 3478 Lecture Notes
Computer Science, pp. 6170. Springer.
Leaute, T., & Williams, B. (2005). Coordinating Agile Systems Model-based Execution
Temporal Plans. Proceedings 20th National Conference AI (AAAI).
Li, H., & Williams, B. (2008). Generative systems hybrid planning based flow tubes. Proc.
18th Int. Conf. Aut. Planning Scheduling (ICAPS).
94

fiC OLIN : P LANNING C ONTINUOUS C HANGE

Li, H., & Williams, B. (2011). Hybrid Planning Temporally Extended Goals Sustainable
Ocean Observing. Proceedings International Conference Association
Advancement AI (AAAI): Special Track Sustainability AI.
Long, D., & Fox, M. (2003a). Exploiting Graphplan Framework Temporal Planning.
Proceedings 13th International Conference Automated Planning Scheduling
(ICAPS), pp. 5261.
Long, D., & Fox, M. (2003b). 3rd International Planning Competition: Results Analysis.
Journal Artificial Intelligence Research (JAIR), 20, 159.
Lougee-Heimer, R. (2003). Common Optimization INterface Operations Research. IBM
Journal Research Development, 47(1), 5766.
McDermott, D. (2003). Reasoning Autonomous Processes Estimated Regression
Planner. Proceedings 13th International Conference Automated Planning
Scheduling (ICAPS).
McDermott, D. V. (2000). 1998 AI Planning Systems Competition. AI Magazine, 21(2), 3555.
Meuleau, N., Benazera, E., Brafman, R. I., Hansen, E. A., & Mausam (2009). Heuristic Search
Approach Planning Continuous Resources Stochastic Domains. Journal Artificial
Intelligence Research (JAIR), 34, 2759.
Palacios, H., & Geffner, H. (2009). Compiling Uncertainty Away Conformant Planning Problems
Bounded Width. Journal Artificial Intelligence Research (JAIR), 35, 623675.
Pednault, E. P. D. (1989). ADL: Exploring Middle Ground STRIPS Situation
Calculus. Proceedings International Conference Knowledge Representation (KR),
pp. 324332.
Pell, B., Gat, E., Keesing, R., Muscettola, N., & Smith, B. D. (1997). Robust Periodic Planning
Execution Autonomous Spacecraft. Proceedings International Joint Conference
AI (IJCAI), pp. 12341239.
Penberthy, S., & Weld, D. (1994). Temporal Planning Continuous Change. Proceedings
12th National Conference AI (AAAI), pp. 10101015. AAAI/MIT Press.
Penna, G. D., Intrigila, B., Magazzeni, D., & Mercorio, F. (2009). UPMurphi: Tool Universal Planning PDDL+ Problems. Proceedings 19th International Conference
Automated Planning Scheduling (ICAPS 2009), pp. 1923. AAAI Press.
Penna, G. D., Intrigila, B., Magazzeni, D., & Mercorio, F. (2010). PDDL+ Benchmark Problem:
Batch Chemical Plant. Proceedings International Conference AI Planning
Scheduling (ICAPS), pp. 222225.
Reddy, S. Y., Frank, J. D., Iatauro, M. J., Boyce, M. E., Kurklu, E., Ai-Chang, M., & Jonsson,
A. K. (2011). Planning Solar Array Operations International Space Station. ACM
Transactions Intelligent Systems Technology, 2, 124.
Richter, S., & Westphal, M. (2010). LAMA Planner: Guiding Cost-Based Anytime Planning
Landmarks. Journal Artificial Intelligence Research (JAIR), 39, 127177.
Shin, J., & Davis, E. (2005). Processes Continuous Change SAT-based Planner. Artificial
Intelligence, 166, 194253.
95

fiC OLES , C OLES , F OX & L ONG

Smith, D., & Weld, D. S. (1999). Temporal Planning Mutual Exclusion Reasoning. Proceedings 16th International Joint Conference AI (IJCAI), pp. 326337.
Veloso, M., Perez, M., & Carbonell, J. (1990). Nonlinear planning parallel resource allocation.
Proceedings DARPA Workshop Innovative Approaches Planning, Scheduling
Control, pp. 207212.
Vidal, V., & Geffner, H. (2006). Branching pruning: optimal temporal POCL planner based
constraint programming. Artificial Intelligence, 170(3), 298335.
Wolfman, S., & Weld, D. (1999). LPSAT System Application Resource Planning.
Proceedings 16th International Joint Conference Artificial Intelligence (IJCAI).
Yi, W., Larsen, K., & Pettersson, P. (1997). UPPAAL Nutshell. International Journal
Software Tools Technology Transfer, 1(1).
Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: Versatile heuristic partial order planner..
Journal Artificial Intelligence Research (JAIR), 20, 405430.

96

fiJournal Artificial Intelligence Research 44 (2012) 709-755

Submitted 04/12; published 08/12

Online Speedup Learning Optimal Planning
Carmel Domshlak
Erez Karpas

DCARMEL @ IE . TECHNION . AC . IL
KARPASE @ TECHNION . AC . IL

Faculty Industrial Engineering Management
Technion - Israel Institute Technology
Haifa, 32000, Israel

Shaul Markovitch

SHAULM @ CS . TECHNION . AC . IL

Faculty Computer Science
Technion - Israel Institute Technology
Haifa, 32000, Israel

Abstract
Domain-independent planning one foundational areas field Artificial Intelligence. description planning task consists initial world state, goal, set actions
modifying world state. objective find sequence actions, is, plan,
transforms initial world state goal state. optimal planning, interested finding plan, one cheapest plans. prominent approach optimal planning
days heuristic state-space search, guided admissible heuristic functions. Numerous admissible
heuristics developed, strengths weaknesses, well known
single best heuristic optimal planning general. Thus, heuristic
choose given planning task difficult question. difficulty avoided combining
several heuristics, requires computing numerous heuristic estimates state,
tradeoff time spent time saved combined advantages
different heuristics might high. present novel method reduces cost combining admissible heuristics optimal planning, maintaining benefits. Using idealized
search space model, formulate decision rule choosing best heuristic compute
state. present active online learning approach learning classifier decision
rule target concept, employ learned classifier decide heuristic compute
state. evaluate technique empirically, show substantially outperforms
standard method combining several heuristics via pointwise maximum.

1. Introduction
center problem intelligent autonomous behavior task selecting actions
take next. Planning AI best conceived model-based approach automated action
selection (Geffner, 2010). models represent current situation, goals, possible actions.
Planning-specific languages used describe models concisely. main challenge
planning computational, planning languages lead intractable problems worst
case. However, using rigorous search-guidance tools often allows efficient solving interesting
problem instances.
classical planning, concerned synthesis plans constituting goal-achieving
sequences deterministic actions, significant algorithmic progress achieved last
two decades. turn, progress classical planning translated advances involved
planning languages, allowing uncertainty feedback (Yoon, Fern, & Givan, 2007; Palacios
c
2012
AI Access Foundation. rights reserved.

fiD OMSHLAK , K ARPAS , & ARKOVITCH

& Geffner, 2009; Keyder & Geffner, 2009; Brafman & Shani, 2012). optimal planning,
objective find plan, find one cheapest plans.
prominent approach domain-independent planning, optimal planning particular,
state-space heuristic search. natural view planning task search problem,
use heuristic search algorithm solve it. Recent advances automatic construction heuristics
domain-independent planning established many heuristics choose from,
strengths weaknesses. However, wealth heuristics leads new question: given
specific planning task, heuristic choose?
paper, propose selective max online learning approach combines
strengths several heuristic functions, leading speedup optimal heuristic-search planning.
high level, selective max seen hyper-heuristic (Burke, Kendall, Newall, Hart, Ross,
& Schulenburg, 2003) heuristic choosing among heuristics. based seemingly trivial observation that, state, one heuristic best state.
principle, possible compute several heuristics state, choose one according values provide. However, heuristic computation domain-independent planning
typically expensive, thus computing several heuristic estimates state takes long time.
Selective max works predicting state heuristic yield best heuristic
estimate, computes heuristic.
always clear decide best heuristic state is, first
analyze idealized model search space describe choose best heuristic
state order minimize overall search time. describe online active learning
procedure uses decision rule formulated idealized model. procedure constitutes
essence selective max.
experimental evaluation, conducted using three state-of-the-art heuristics
domain-independent planning, shows selective max effective combining several
heuristics optimal search. Furthermore, results show using selective max results
speedup baseline heuristic combination method, selective max robust different parameter settings. claims supported selective max runnerup ex-aequo last International Planning Competition, IPC-2011 (Garca-Olaya, Jimenez, &
Linares Lopez, 2011).
paper expands conference version (Domshlak, Karpas, & Markovitch, 2010)
several ways. First, improve expand presentation selective max decision rule.
Second, explain handle non-uniform action costs principled way. Third, empirical
evaluation greatly extended, includes results IPC-2011, well controlled
experiments three different heuristics, exploration parameters selective
max affect performance.

2. Previous Work
Selective max speedup learning system. general, speedup learning concerned improving performance problem solving system experience. computational difficulty
domain-independent planning led many researchers use speedup learning techniques order
improve performance planning systems; survey many these, see work
Minton (1994), Zimmerman Kambhampati (2003), Fern, Khardon, Tadepalli (2011).
710

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Speedup learning systems divided along several dimensions (Zimmerman & Kambhampati, 2003; Fern, 2010). Arguably important dimension phase learning takes
place. offline, inter-problem, speedup learner analyzes problem solvers performance
different problem instances attempt formulate rule would improve
performance would also generalize well future problem instances. Offline learning
applied extensively domain-independent planning, varying degrees success (Fern et al.,
2011). However, one major drawback offline learning need training examples
case, planning tasks domains interest.
Learning also take place online, problem solving. online, intra-problem,
speedup learner invoked problem solver concrete problem instance solver
working on, attempts learn online, objective improving solvers performance
specific problem instance solved. general, online learners assumed pretrained other, previously seen problem instances; information rely
collected process solving concrete problem instance called for. Online
learning shown extremely helpful propositional satisfiability (SAT) general
constraint satisfaction (CSP) solving, nogood learning clause learning among
essential components state-of-the-art solver (Schiex & Verfaillie, 1993; Marques-Silva
& Sakallah, 1996; Bayardo Jr. & Schrag, 1997). Thus, indirectly, SAT- CSP-based domainindependent planners already benefit online learning techniques (Kautz & Selman, 1992;
Rintanen, Heljanko, & Niemela, 2006). However, best knowledge, work first
application online learning optimal heuristic-search planning.

3. Background
domain-independent planning task (or planning task, short) consists description
initial state, goal, set available operators. Several formalisms describing planning tasks
use, including STRIPS (Fikes & Nilsson, 1971), ADL (Pednault, 1989), SAS+ (Backstrom
& Klein, 1991; Backstrom & Nebel, 1995). describe SAS+ formalism, one used
Fast Downward planner (Helmert, 2006), top implemented evaluated
selective max. Nothing, however, precludes using selective max context formalisms.
SAS+ planning task given 4-tuple = hV, A, s0 , Gi. V = {v1 , . . . , vn } set state
variables, associated finite domain dom(vi ). complete assignment V called
state. s0 specified state called initial state, goal G partial assignment V .
finite set actions. action given pair hpre(a), eff(a)i partial assignments V
called preconditions effects, respectively. action also associated cost C(a) R0+ .
action applicable state iff |= pre(a). Applying changes value state
variable v eff(a)[v] eff(a)[v] specified. resulting state denoted sJaK. denote
state obtained sequential application (respectively applicable) actions a1 , . . . , ak
starting state sJha1 , . . . , ak iK. action sequence plan s0 Jha1 , . . . , ak iK |= G.
optimal planning, interested finding one
Pthe cheapest plans, cost plan
ha1 , . . . , ak sum constituent action costs ki=1 C(ai ).
SAS+ planning task = hV, A, s0 , Gi easily seen state-space search problem
whose states simply complete assignments variables V , transitions uniquely determined actions A. initial goal states also defined initial state goal .
optimal solution state-space search problem found using search algorithm
711

fiD OMSHLAK , K ARPAS , & ARKOVITCH

admissible heuristic h. heuristic evaluation function h assigns estimate distance
closest goal state state evaluates. length cheapest path state
goal denoted h (s), h called admissible never overestimates true goal distance
is, h(s) h (s) state s. works expanding states order increasing
f (s) := g(s) + h(s), g(s) cost cheapest path initial state known
far.

4. Selective Max Decision Rule
Many admissible heuristics proposed domain-independent planning; vary
cheap compute yet accurate, accurate yet expensive compute. general,
accurate heuristic is, fewer states would expanded using it.
accuracy heuristic functions varies different planning tasks, even different states
task, may able produce robust optimal planner combining several admissible heuristics. Presumably, heuristic accurate, is, provides higher estimates,
different regions search space. simplest best-known way using point-wise maximum heuristics use state. Given n admissible heuristics,
h1 , . . . , hn , new heuristic, maxh , defined maxh (s) := max1in hi (s). easy see
maxh (s) hi (s) state heuristic hi . Thus search using maxh expected
expand fewer states using individual heuristic.PHowever, denote time needed
compute hi ti , time needed compute maxh ni=1 ti .
mentioned previously, selective max form hyper-heuristic (Burke et al., 2003)
chooses heuristic compute state. view selective max decision rule dr,
given set heuristics h1 , . . . , hn state s, chooses heuristic compute
state. One natural candidate decision rule heuristic yields highest,
is, accurate, estimate:
drmax ({h1 , . . . , hn }, s) := hargmax1in hi (s) .
Using decision rule yields heuristic accurate maxh , still computing
one heuristic per state time targmax1in hi (s) .
analysis, however, take account different computation times different heuristics. instance, let h1 h2 pair admissible heuristics h2 h1 .
priori, seems using h2 always preferred using h1 former
cause expand fewer states. However, suppose given planning task, expands 1000
states guided h1 100 states guided h2 . computing h1 state
takes 10 ms, computing h2 state takes 1000 ms, switching h1 h2 increases
overall search time. Using maxh h1 h2 makes things worse, h2 h1 ,
thus computing maximum simply wastes time spent computing h1 . possible,
however, computing h2 carefully chosen states, computing h1 states,
would result expanding 100 states, reducing overall search time compared
running h2 .
example shows, even given knowledge heuristics estimates advance,
clear heuristic computed state objective minimize overall
search time. Therefore, begin formulating decision rule choosing one two
heuristics, respect idealized state-space model. Selective max operates online
712

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

s0


f2 = c

f1 = c
sg

Figure 1: illustration idealized search space model f -contours two admissible
heuristics

active learning procedure, attempting predict outcome decision rule choose
heuristic compute state.
4.1 Decision Rule Perfect Knowledge
formulate decision rule choosing two given admissible heuristics, h1 h2 ,
compute state idealized search space model. order formulate decision
rule, make following assumptions:
search space tree single goal, constant branching factor b, uniform cost
actions. idealized search space model used past analyze behavior
(Pearl, 1984).
time ti required computing heuristic hi independent state evaluated;
w.l.o.g. assume t2 t1 .
heuristics consistent. heuristic h said consistent obeys triangle
inequality: two states s, s0 , h(s) h(s0 ) + k(s, s0 ), k(s, s0 ) optimal cost
reaching s0 s.
have: (i) perfect knowledge structure search tree, particular
cost optimal solution c , (ii) perfect knowledge heuristic estimates
state, (iii) perfect tie-breaking mechanism.
Obviously, none assumptions holds typical search problems, later examine
individual influence framework.
Adopting standard notation, let g(s) cost cheapest path s0 s. Defining
maxh (s) = max(h1 (s), h2 (s)), use notation f1 (s) = g(s) + h1 (s), f2 (s) = g(s) +
h2 (s), maxf (s) = g(s) + maxh (s). algorithm consistent heuristic h expands
states increasing order f = g + h (Pearl, 1984). particular, every state f (s) <
h (I) = c surely expanded , every state f (s) > c surely
713

fiD OMSHLAK , K ARPAS , & ARKOVITCH

expanded . states f (s) = c might might expanded , depending
tie-breaking rule used. perfect tie-breaking assumption, states
f (s) = c expanded lie along optimal plan.
Let us consider states satisfying f1 (s) = c (the dotted line Fig. 1) satisfying
f2 (s) = c (the solid line Fig. 1). states f1 = c f2 = c contours
surely expanded h1 h2 , respectively. states contours
(the grid-marked region Fig. 1), is, states SE = {s | maxf (s) < c },
surely expanded using maxh (Pearl, 1984, Thm. 4, p. 79).
objective minimizing search time, note optimal decision state
SE compute heuristic all, since states surely expanded anyway.
Assuming still must choose one heuristics, would choose compute cheaper
heuristic h1 . Another easy case f1 (s) c . states, computing h1 (s) suffices
ensure surely expanded, using perfect tie-breaking rule, expanded
unless must be. h1 also cheaper compute h2 , h1 preferred, regardless
heuristic estimate h2 state s.
Let us consider optimal decision states, is, f1 (s) < c
f2 (s) c . fact, enough consider shallowest states; Figure 1,
states part f2 = c contour separates grid-marked line-marked
areas. Since f1 (s) f2 (s) based g(s), h2 (s) > h1 (s), is, h2
accurate state h1 . interested solely reducing state expansions, h2
would obviously right heuristic compute s. However, objective reducing
actual search time, h2 may actually wrong choice might much expensive
compute h1 .
Let us consider effects two alternatives. compute h2 (s),
surely expanded, f2 (s) = c , thus whether expands depends tiebreaking. before, assuming perfect tie-breaking, thus expanded unless
must be. Computing h2 would cost us t2 time.
contrast, compute h1 (s), surely expanded f1 (s) < c . Note
computing h2 computing h2 one descendants s0 clearly sub-optimal
strategy pay cost computing h2 , yet pruning limited search
sub-tree rooted s0 . Therefore, choices really either computing h2 s, computing h1
states sub-tree rooted lie f1 = c contour. Suppose need
expand l complete levels state space reach f1 = c contour. Thus, need
generate order bl states, invest bl t1 time calculating h1 states lie
f1 = c contour.
Considering two options, optimal decision state thus compute h2 iff t2 < bl t1 ,
express differently, l > logb ( tt12 ). special case, heuristics take time
compute, decision rule reduces l > 0, is, optimal choice simply accurate
heuristic state s.
Putting cases together yields decision rule dropt , below, ls
depth go f1 (s) = c :
714

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING



h1 , f1 (s) < c , f2 (s) < c



h , f (s) c
1
1
.
dropt ({h1 , h2 }, s) :=

h1 , f1 (s) < c , f2 (s) c , ls logb ( tt12 )



h , f (s) < c , f (s) c , l > log ( t2 )
2
1
2

b t1
4.2 Decision Rule without Perfect Knowledge
idealized model makes several assumptions, appear problematic
meet practice. examine assumptions closely, needed, suggest
pragmatic compromises.
First, model assumes search space forms tree single goal state,
heuristics question consistent, perfect tie-breaking rule. Although
first assumption hold planning tasks, second assumption satisfied
many state-of-the-art heuristics (Karpas & Domshlak, 2009; Helmert & Domshlak, 2009; Bonet
& Helmert, 2010), third assumption realistic, prevent us using
decision rule suggested model.
idealized model also assumes branching factor heuristic computation
times constant across search states. application decision rule planning
practice, deal assumption adopting average branching factor heuristic
computation times, estimated random sample search states.
Finally, decision rule dropt requires unrealistic knowledge heuristic estimates,
well optimal plan cost c depth ls go state f1 (s) = c .
obviously knowledge practice, must use approximation decision
rule.
first approximation make ignore trivial cases require knowledge c ;
cases either surely expanded, h1 enough prune s. Instead, apply
reasoning complicated case states, resulting following decision rule:
(
h1 , ls logb ( tt12 )
drapp1 ({h1 , h2 }, s) :=
.
h2 , ls > logb ( tt21 )
next step somehow estimate depth go ls number layers need
expand tree f1 reaches c . order derive useful decision rule, assume ls
positive correlation h (s) = h2 (s) h1 (s); is, h1 h2 close, ls low,
h1 yields much lower estimate h2 , implying h1 accurate s,
depth go f1 (s) = c large. approximation uses simplest correlation
linear one h (s) ls , hyper-parameter controlling slope.
Recall idealized model, actions unit cost, thus cost-to-go depthto-go same. However, planning tasks, notably, planning tasks 2008
International Planning Competition, feature non-uniform action costs. Therefore, decision rule
converts heuristic estimates cost-to-go heuristic estimates depth-to-go dividing
cost-to-go estimate average action cost. modifying estimate depthto-go, ls , average action cost, denote c. Plugging
715

fiD OMSHLAK , K ARPAS , & ARKOVITCH

decision rule yields:
(
h1 ,
drapp2 ({h1 , h2 }, s) :=
h2 ,

h (s) c logb ( tt12 )
.
h (s) > c logb ( tt21 )

Given b, t1 , t2 , c, quantity c logb (t2 /t1 ) becomes fixed, follows denote
simply threshold .
Note linear correlation h (s) ls occurs simple cases. first
case h1 value remains constant subtree rooted s, is, additive error
h1 increases 1 level s. case, f1 increases 1 expanded level
sub-tree (because h1 remains same, g increases 1), take expanding exactly
h (s) = h2 (s) h1 (s) levels reach f1 = c contour. second case
absolute error h1 remains constant, is, h1 increases 1 level expanded, f1
increases 2. case, need expand h (s)/2 levels. generalized
case estimate h1 increases constant additive factor c, results h (s)/(c+1)
levels expanded.
Furthermore, empirical evidence support conclusion exponential
growth search effort function heuristic error, even assumptions made
model hold. particular, experiments Helmert Roger (2008) IPC benchmarks
heuristics small constant additive errors show number expanded nodes
typically grows exponentially (still small additive) error increases.
Finally, remark decision rule always chooses admissible heuristic,
resulting heuristic estimate always admissible. Thus, even chosen heuristic
correct one according dropt , result loss optimality solution,
possible increase search time.

5. Online Learning Decision Rule
decision rule drapp2 still requires knowledge h1 h2 , use binary
label state. compute value decision rule paying computation
time heuristics, t1 + t2 , and, importantly, use binary classifier predict
value decision rule unknown state. Note use classifier online,
problem solving process, time spent learning classification counted time spent
problem solving. Furthermore, active learning, choose pay label
state, payment also computation time. Therefore refer setting active
online learning.
follows, provide general overview selective max procedure, describe
several alternatives components. decision rule states expensive
heuristic h2 computed search state h2 (s) h1 (s) > . decision rule
serves binary target concept, corresponds set states expensive
heuristic h2 significantly accurate cheaper heuristic h1 states where, according model, reduction expanded states computing h2 outweighs extra time
needed compute it. Selective max uses binary classifier predict value decision
rule. several steps building classifier:
716

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

evaluate(s)
hh, conf idencei := CLASSIFY(s, model)
(conf idence > )
return h(s)
else
label := h1
h2 (s) h1 (s) > c logb (t2 /t1 ) label := h2
update model hs, labeli
return max(h1 (s), h2 (s))
Figure 2: selective max state evaluation procedure
1. Training Example Collection: first need collect training examples,
representative entire search space. Several state-space sampling methods discussed
Section 5.1.
2. Labeling Training Examples: training examples collected, first used
estimate average branching factor b, average heuristic computation times t1 t2 ,
average action cost c. b, t1 , t2 , c estimated, use estimate
threshold = c logb (t2 /t1 ) decision rule.
generate label training example calculating h (s) = h2 (s) h1 (s),
comparing decision threshold: h (s) > , label h2 , otherwise
h1 . t1 > t2 simply switch heuristics decision always whether
compute expensive heuristic; default compute cheaper heuristic,
unless classifier says otherwise.
3. Feature Extraction: obtained set training examples, must decide
features characterize example. Since target concept based heuristic values,
features represent information heuristics derived typically
problem description current state.
several feature-construction techniques characterizing states planning tasks
proposed previous literature (Yoon, Fern, & Givan, 2008; de la Rosa, Jimenez, &
Borrajo, 2008), designed inter-problem learning, is, learning
different planning tasks already solved offline. However, approach,
concerned one problem, online setting, thus techniques
applicable. implementation, use simplest features possible, taking
state variable feature. empirical evaluation demonstrates, even elementary
features suffice selective max perform well.
4. Learning: set labeled training examples, represented vector
features, train binary classifier. Several different choices classifier discussed
Section 5.2.
completing steps described above, binary classifier used
predict value decision rule. However, classifier likely perfect accuracy,
717

fiD OMSHLAK , K ARPAS , & ARKOVITCH

consult confidence classifier associates classification. resulting state
evaluation procedure selective max depicted Figure 2. every state evaluated
search algorithm, use classifier decide heuristic compute. classification
confidence exceeds confidence threshold , parameter selective max, indicated
heuristic computed s. Otherwise, conclude enough information make
selective decision s, compute regular maximum h1 (s) h2 (s). However,
use opportunity improve quality prediction states similar s, update
classifier generating label based h2 (s)h1 (s) learning newly labeled example.
decisions dedicate computation time obtain label new example constitute
active part learning procedure. also possible update estimates b, t1 , t2 , c,
change threshold accordingly. However, would result concept trying
learn constantly changing phenomenon known concept drift usually affects
learning adversely. Therefore, update threshold .
5.1 State-Space Sampling
initial state-space sample serves two purposes. First, used estimate branching factor
b, heuristic computation times t1 t2 , average action cost c, compute
threshold = c logb (t2 /t1 ), used specify concept. concept specified,
state-space sample also provides us set examples classifier initially
trained. Therefore, important initial state-space sample representative
states evaluated search. number states initial sample controlled
parameter N .
One option use first N states search. However, method biased towards
states closer initial state, therefore likely represent search space well. Thus,
discuss three sophisticated state-space sampling procedures, based
performing random walks, probes, initial state. details sampling
procedures vary, probe terminates pre-set depth limit.
first sampling procedure, refer biased probes, uses inverse heuristic
selection bias choosing next state go probe. Specifically, probability
choosing state successor random walk continue proportional
1/ maxh (s). biases sample towards states lower heuristic estimates,
likely expanded search.
second sampling procedure similar first one, except chooses successor
uniformly, thus refer unbiased probes. sampling procedures add
generated states (that is, states along probe well siblings) statespace sample, terminate collecting N training examples. depth limit
random walks sampling schemes, set estimate goal depth;
discuss goal depth estimate later.
third state-space sampling procedure, referred PDB sampling, proposed
Haslum, Botea, Helmert, Bonet, Koenig (2007). procedure also uses unbiased probes,
adds last state reached probe state-space sample. depth
probe determined individually, drawing random depth binomial distribution around
estimated goal depth.
718

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Note three sampling procedures rely estimate minimum goal depth.
actions unit cost, minimum goal depth h (s0 ), thus use
heuristic estimate it. evaluation, used twice heuristic estimate initial state,
2 maxh (s0 ), goal depth estimate. However, non-uniform action costs, goal depth
cost longer measured units. seems could divide heuristicbased estimate average action cost c, recall use state-space sample order
obtain estimate estimate c, thus creating circular dependency. Although possible
estimate c taking average cost actions problem description, reason
assume actions equally likely used. Another option modify
state-space sampling procedures, place cost limit, rather depth limit, probe.
However, would pose problem presence 0-cost actions. case, probe
reaches cost limit yet possible 0-cost action apply, clear whether probe
terminate. Therefore, keep using depth-limited probes attempt estimate depth
cheapest goal. compute heuristic estimate initial state, use number
actions heuristic estimate based goal depth estimate.
possible every heuristic, use empirical evaluation monotonically-relaxed plan
heuristic. heuristic, also known FF heuristic (Hoffmann & Nebel, 2001), provide
information: first use heuristic find relaxed plan initial state, use
number actions relaxed plan goal depth estimate.
5.2 Classifier
last decision made choice classifier. Although many classifiers used here,
several requirements must met due particular setup. First, training classification must fast, performed time-constrained problem solving. Second,
classifier must incremental support active learning. achieved allowing online
updates learned model. Finally, classifier provide us meaningful measure
confidence predictions.
several classifiers meet requirements, found Naive Bayes classifier provide
good balance speed accuracy. One note Naive Bayes classifier
assumes strong conditional independence features. Although fully
realistic assumption planning tasks, using SAS+ task formulation contrast classical
STRIPS formulations helps lot: instead many highly dependent binary variables,
much smaller set less dependent ones.
Although, empirical evaluation demonstrate, Naive Bayes appears
suitable classifier use selective max, classifiers also used. obvious
choice replacement classifier would different Bayesian classifier. One classifier
AODE (Webb, Boughton, & Wang, 2005), extension Naive Bayes, somewhat relaxes
assumption independence features, typically accurate Naive
Bayes. However, added accuracy comes cost increased training classification time.
Decision trees another popular type classifier allows even faster classification.
decision tree induction algorithms incremental, Incremental Tree Inducer
(ITI) algorithm (Utgoff, Berkman, & Clouse, 1997) supports incremental updating decision trees
tree restructuring, also freely available implementation C. evaluation, used
ITI incremental mode, incorporated every example tree immediately,
719

fiD OMSHLAK , K ARPAS , & ARKOVITCH

tree likely used many classifications pairs consecutive updates training
examples active learning. classification confidence ITI classifier obtained
frequency examples leaf node classification came.
different family possible classifiers k-Nearest Neighbors (kNN) (Cover & Hart, 1967).
order use kNN, need distance metric examples, which, features,
simply states. choice features, opt simplicity use Euclidean distance
metric. kNN enjoys fast learning time suffers slow classification time.
classification confidence obtained simple (unweighted) vote k nearest neighbors.
Another question related choice classifier feature selection. planning tasks,
number variables, accordingly, features, 2000 (for example, task 35
AIRPORT domain 2558 variables). performance Naive Bayes kNN likely
improved using feature selection, poses problem initial sample considered.
Since feature selection done right initial sample obtained,
based initial sample. could cause problem since features might appear
irrelevant according initial sample, yet turn relevant active learning
used low-confidence states encountered. Therefore, use feature selection
empirical evaluation selective max.
5.3 Extension Multiple Heuristics
point, discussed choose heuristic compute state
two heuristics choose from. given two heuristics, decision
rule presented Section 4 inapplicable, extending handle two heuristics
straightforward. However, extending selective max use two heuristics straightforward simply compare heuristics pair-wise manner, use voting rule choose
heuristic compute.
many possible voting rules, go simplest one, compares
every pair heuristics, chooses winner vote, weighted confidence pairwise decision. overall winner simply heuristic highest total confidence
pairwise comparisons, ties broken favor cheaper-to-compute heuristic. Although
requires quadratic number classifiers, training classification time (at least Naive
Bayes) appear much lower overall time spent heuristic computations, thus
overhead induced learning classification likely remain relatively low reasonable
heuristic ensembles.

6. Experimental Evaluation
evaluate selective max empirically, implemented top open-source Fast Downward
planner (Helmert, 2006). empirical evaluation divided three parts. First, examine performance selective max using last International Planning Competition, IPC-2011,
benchmark. Selective max runner-up ex-aequo IPC-2011, tying 2nd place
version Fast Downward using abstraction merge-and-shrink heuristic (Nissim, Hoffmann, & Helmert, 2011), losing sequential portfolio combining heuristics used
runners-up (Helmert, Roger, & Karpas, 2011). Second, present series controlled parametric
experiments, examine behavior selective max different settings. Finally,
720

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Parameter


N
Sampling method
Classifier

Default value
1
0.6
1000
Biased probes
Naive Bayes

Meaning
heuristic difference bias
confidence threshold
initial sample size
state-space sampling method
classifier type

Table 1: Parameters selmax entry IPC-2011.
compare selective max simulated sequential portfolio, using heuristics selective
max.
6.1 Performance Evaluation: Results IPC-2011
IPC-2011 experiments (Garca-Olaya et al., 2011) run IPC organizers,
machines, time limit 30 minutes memory limit 6 GB per planning task.
competition included new domains, none participants seen before, thus
precluding participants using offline learning approaches.
Although many planners participated sequential optimal track IPC-2011, report
results relevant selective max. selective max entry IPC-2011 called selmax,
consisted selective max uniform action cost partitioning version hLA (Karpas &
Domshlak, 2009) hLM-CUT (Helmert & Domshlak, 2009) heuristics. parameters used
selective max IPC-2011 reported Table 1. Additionally, heuristics selmax used
entered individually BJOLP (hLA ) lmcut (hLM-CUT ), report results three
planners. comparison selective max regular maximum hLA hLM-CUT
would interesting, entry IPC-2011, thus report it.
controlled experiments, compare selective max regular maximum, well
baseline combination methods.
Figure 3 shows anytime profile three planners IPC-2011 tasks, plotting number tasks solved different timeouts, time limit 30 minutes. Additionally, Table
2 shows number tasks solved domain IPC-2011, 30 minutes, includes
number problems solved winner, Fast Downward Stone Soup 1 (FDSS-1), reference.
results show, selective max solves problems individual heuristics
uses. Furthermore, anytime profile selective max dominates heuristics,
range 214 seconds full 30 minute timeout. behavior anytime plot
shorter timeouts due overhead selective max, consists obtaining initial statespace sample, well learning classification. However, appears selective max quickly
compensates relatively slow start.
6.2 Controlled Experiments
series controlled experiments, attempted evaluate impact different parameters
selective max. controlled following independent variables:
Heuristics: used three state-of-the-art admissible heuristics: hLA (Karpas & Domshlak,
2009), hLM-CUT (Helmert & Domshlak, 2009), hLM-CUT+ (Bonet & Helmert, 2010). None
721

fiD OMSHLAK , K ARPAS , & ARKOVITCH

160

Solved Instances

140

120

100

80

BJOLP
lmcut
selmax

60
0

200

400

600

800
1000
Timeout (seconds)

1200

1400

1600

1800

Figure 3: IPC-2011 anytime performance. line shows number problems IPC-2011
solved BJOLP, lmcut, selmax planners, respectively, different timeouts.
Domain
barman
elevators
floortile
nomystery
openstacks
parcprinter
parking
pegsol
scanalyzer
sokoban
tidybot
transport
visitall
woodworking
TOTAL

BJOLP
4
14
2
20
14
11
3
17
6
20
14
7
10
9
151

lmcut
4
18
7
15
16
13
2
18
12
20
14
6
10
12
167

selmax
4
18
7
20
14
13
4
17
10
20
14
6
10
12
169

FDSS-1
4
18
7
20
16
14
7
19
14
20
14
7
13
12
185

Table 2: Number planning tasks solved IPC 2011 domain BJOLP, lmcut,
selmax planners. best result 3 planners bold. number problems
solved Fast Downward Stone Soup 1 (FDSS-1) domain also included
reference.

722

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

base heuristics yields better search performance others across planning
domains. heuristics, hLA typically fastest compute least accurate,
hLM-CUT expensive compute accurate, hLM-CUT+ expensive compute accurate.1 data gathered experiments,
hLM-CUT takes average 4.5 time per state hLA , hLM-CUT+ takes 53 time
per state hLA . evaluate selective max possible subsets two
three heuristics.
admissible heuristics SAS+ planning competitive
three (for example, Helmert, Haslum, & Hoffmann, 2007; Nissim et al., 2011; Katz &
Domshlak, 2010), based expensive offline preprocessing, followed fast
online per-state computation. contrast, hLA , hLM-CUT hLM-CUT+ perform
computation online, thus better exploited selective max.
Additionally, empirically examine effectiveness selective max deciding whether
compute heuristic value all. done combining accurate heuristic,
hLM-CUT+ , blind heuristic.
Heuristic difference bias : hyper-parameter controls tradeoff computation time heuristic accuracy. Setting = 0 sets threshold 0, forcing decision
rule always choose accurate heuristic. Increasing increases threshold, forcing decision rule choose accurate heuristic h2 value much higher
h1 . evaluate selective max values 0.1, 0.5, 1, 1.5, 2, 3, 4, 5.
Confidence threshold : confidence threshold controls active learning part selective max. Setting = 0.5 turns active learning completely, chosen heuristic
always comes confidence least 0.5. Setting = 1 would mean using active learning almost always, essentially reducing selective max regular point-wise maximization.
evaluate selective max values 0.51, 0.6, 0.7, 0.8, 0.9, 0.99.
Initial sample size N : initial sample size N important parameter,
used train initial classifier active learning done, also
source estimates branching factor, average action cost, heuristic computation
times. thus affects threshold : Increasing N increases accuracy initial
classifier various aforementioned estimates, also increases preprocessing
time. evaluate selective max values N 10, 100, 1000.
Sampling method: sampling method used obtain initial state-space sample important affects initial sample, thus accuracy threshold
initial classifier. evaluate selective max three different sampling methods,
P
described Section 5.1: biased probes (selPh ), unbiased probes (selU
h ), sampling
method Haslum et al. (2007) (selPDB
h ).
Classifier: choice classifier also important. Naive Bayes classifier comB
bines fast learning classification (selN
h ). sophisticated variant Naive
Bayes called AODE (Webb et al., 2005) also considered (selAODE
). AODE
h
1. course, three heuristics computable polynomial time SAS+ description planning task.

723

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Parameter
Heuristics


N
Sampling method
Classifier

Default value
hLA / hLM-CUT
1
0.6
100
PDB (Haslum et al., 2007)
Naive Bayes

Meaning
heuristics used
heuristic difference bias
confidence threshold
initial sample size
state-space sampling method
classifier type

Table 3: Default parameters selh .
accurate Naive Bayes, higher classification learning times, well increased memory overhead. Another possible choice using incremental decision trees (Utgoff et al., 1997), offer even faster classification, expensive learning

tree structure needs changed (selIT
h ). also consider kNN classifiers (Cover & Hart,
1967), offer faster learning Naive Bayes, usually expensive classificaN
tion, especially k grows larger (selkN
, k = 3, 5).
h
Table 3 describes default values independent variables.
subsequent experiments, vary one independent variables, keeping rest default
values. experiments, search planning task instance limited 30
minutes2 3 GB memory. search times include time needed translating
planning task PDDL SAS+ building Fast Downward data structures,
common planners, tangential issues considered study. search
times include learning classification time selective max.
Heuristics
begin varying set heuristics use. every possible choice two
heuristics uniform action cost partitioning version hLA (which simply refer
hLA ), hLM-CUT hLM-CUT+ , compare selective max methods heuristic
combination, well individual heuristics. compare selective max (selh )
regular maximum (maxh ), well planner chooses heuristic compute
state randomly (rndh ). clear whether random choice favor
expensive accurate heuristic cheaper less accurate one, simply use
uniform random choice.
experiment conducted 31 domains conditional effects axioms
(which none heuristics used support) International Planning Competitions
19982008. domains vary difficulty number tasks, normalize
score planner domain 0 1. Normalizing number
problems domain good idea, always possible generate number
effectively unsolvable problems domain, fraction solved problems
approach zero. Therefore, normalize number problems solved domain
number problems domain solved least one planners.
measure normalized coverage undesirable property introducing
2. search given single core 3GHz Intel E8400 CPU machine.

724

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Heuristic

hLA

hLM-CUT

hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost

0.89 (175)
0.98 (345)
0.80 (136)

0.83 (136)
0.96 (343)
0.94 (160)

0.81 (132)
0.94 (336)
0.86 (146)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

(a) Individual Heuristics
Domains
High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

maxh
0.90 (164)
0.97 (345)
0.92 (156)
0.94 (665)

rndh
0.74 (123)
0.95 (342)
0.79 (138)
0.85 (603)

selh
0.93 (174)
0.97 (346)
0.93 (157)
0.95 (677)

hLA / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.84 (149)
0.93 (335)
0.85 (144)
0.89 (628)

0.68 (115)
0.88 (327)
0.71 (122)
0.78 (564)

0.90 (164)
0.96 (342)
0.86 (145)
0.92 (651)

hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.80 (131)
0.94 (336)
0.87 (147)
0.89 (614)

0.75 (122)
0.93 (335)
0.86 (145)
0.87 (602)

0.80 (130)
0.97 (344)
0.93 (156)
0.91 (630)

hLA / hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

0.84 (149)
0.93 (335)
0.85 (144)
0.89 (628)

0.69 (116)
0.90 (332)
0.75 (130)
0.81 (578)

0.87 (154)
0.97 (345)
0.89 (150)
0.92 (649)

Heuristics
hLA / hLM-CUT

(b) Combinations two heuristics

Table 4: Average normalized coverage, total coverage parentheses, broken groups
domains unit cost actions high variance coverage, domains unit cost
actions low variance coverage, domains non-uniform action costs. Table
(a) shows results individual heuristics, table (b) shows results
maximum (maxh ), random choice (rndh ), selective max (selh ) combinations
set heuristics listed major row.

new planner could change normalized coverage planners, believe
best reflects performance nonetheless. overall performance measure, list
average normalized coverage score across domains. Using normalized coverage means
domains equal weight aggregate score. Additionally, list domain
number problems solved planner (in parentheses next domain
name), planner list number problems solved parentheses.
Tables 4 5 summarize results experiment. divided domains
experiment 3 sets: domains non-uniform action costs, domains unit action
costs exhibited high variance number problems solved different
725

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Heuristics

Domains

hLA

hLM-CUT

hLA / hLM-CUT

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

3.23
3.48
13.23
4.82

2.8
1.14
1.01
1.4

hLA / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

4.01
4.55
13.66
5.85

hLM-CUT / hLM-CUT+

High variance unit cost
Low variance unit cost
Non-uniform cost
TOTAL

hLA / hLM-CUT / hLM-CUT+

hLM-CUT+

maxh

rndh

selh

1.0
1.0
1.0
1.0

3.88
2.14
3.99
2.93

1.46
1.2
1.17
1.25

1.77
1.01
1.0
1.16

1.0
1.0
1.0
1.0

3.17
2.38
3.85
2.9

2.16
1.85
1.72
1.89

2.29
1.58
1.32
1.66

1.01
1.01
1.03
1.01

1.0
1.0
1.0
1.0

1.7
1.29
1.18
1.35

1.24
1.19
1.16
1.2

High variance unit cost
Low variance unit cost
Non-uniform cost

4.06
4.65
15.2

3.81
1.59
1.37

1.78
1.02
1.03

1.0
1.0
1.0

3.61
2.05
2.74

2.1
1.57
1.49

TOTAL

6.1

1.91

1.18

1.0

2.56

1.67

Table 5: Geometric mean ratio expansions relative maxh , broken groups domains unit cost actions high variance coverage, domains unit cost actions
low variance coverage, domains non-uniform action costs.

planners, domains unit action costs exhibited low variance number
problems solved different planners. make distinction conducted
following experiments, examine effects parameters selective
max, unit cost action domains exhibited high variance. Tables 4 5
summarize results three sets domains, well domains combined.
Detailed, per-domain results relegated Appendix A.
Table 4 lists normalized coverage score, averaged across domains, total number
problems solved parentheses. Table 4a lists individual heuristic,
Table 4b every combination method every set two heuristics. Table 5 shows
accurate heuristic combination methods is. Since, given set base
heuristics, maxh accurate heuristic possible, accuracy evaluated relative
maxh . evaluate heuristics accuracy task number states expanded
using heuristic, divided number states expanded using maxh .
compute geometric mean domain tasks solved planners
accuracy ratio, list geometric mean numbers. row lists
results combination two three heuristics; combinations two heuristics,
leave cell representing heuristic combination empty.
Looking results individual heuristics first, see accurate heuristic
(hLM-CUT+ ) well overall, least accurate heuristic (hLA ) solved
tasks total, hLM-CUT wins terms normalized coverage. However, looking
results individual domains, see best heuristic use varies, indicating
combining different heuristics could indeed practical value.
turn attention empirical results combinations possible subsets
two heuristics. results clearly demonstrate one heuristic
used, selective max always better regular maximum random choice, terms
normalized coverage absolute number problems solved. Furthermore, poor
performance rndh , coverage accuracy, demonstrates decision rule
726

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

700

650

Solved Instances

600

550

500

450

400
maxh

350

rndh
selh

300
200

400

600

800
1000
Timeout (seconds)

1200

1400

1600

1800

Figure 4: hLA / hLM-CUT / hLM-CUT+ anytime profile. line shows number problems
IPC 1998 2006 solved maximum (maxh ), random choice (rndh ), selective
max (selh ) combination methods hLA , hLM-CUT , hLM-CUT+ heuristics,
different timeouts.

classifier used selective max important success, computing one
heuristic state randomly insufficient, say least.
compared individual heuristics, selective max least well
individual heuristics uses, combinations except hLM-CUT hLM-CUT+ .
likely hLM-CUT hLM-CUT+ based similar procedure,
thus heuristic estimates highly correlated. see hinders selective max,
consider extreme case two heuristics correlation 1.0 (that is, yield
heuristic values), selective max offer benefit. Finally, remark
best planner experiment selective max combination hLA hLM-CUT .
results based 30 minute time limit, which, commonly used
IPC, arbitrary, number tasks solved 30 minutes tell complete
tale. Here, examine anytime profile different heuristic combination methods,
plotting number tasks solved different timeouts, timeout 30 minutes.
Figure 4 shows plot three combination methods three heuristics used.
figure shows, advantage selh baseline combination methods even
greater shorter timeouts. indicates advantage selh maxh even
727

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Heuristics
hLA / hLM-CUT

Overhead
12%

hLA / hLM-CUT+

15%

hLM-CUT / hLM-CUT+

9%

hLA / hLM-CUT / hLM-CUT+

10%

Table 6: Selective max overhead. row lists average percentage time spent learning
classification, total time taken selective max, set heuristics.

greater evident results 30 minutes, selh indeed effective
minimizing search time. Since anytime plots combinations pairs heuristics
similar, omit sake brevity.
Finally, present overhead statistics using selective max proportion time spent
learning classification, including time spent obtaining initial state-space sample, total solution time. Table 6 presents average overhead selective max
combinations two heuristics. Detailed, per-domain results
presented Table 18 Appendix A. results show, selective max incur noticeable overhead, still relatively low. also worth mentioning overhead
varies significantly different domains.
also performed empirical evaluation using selective max accurate heuristic
alongside blind heuristic. blind heuristic returns 0 goal states, cost
cheapest action non-goal states. experiment, chose accurate
heuristic, hLM-CUT+ . compare performance using hLM-CUT+ alone,
using selective max hLM-CUT+ blind heuristic. blind heuristic returns
constant value non-goal states, decision rule selective max uses combine
heuristic h blind heuristic hb simply h(s) + hb , is, compute h
predicted value h greater constant threshold. Recall that,
h(s) + g(s) < c , computing h simply waste time, pruned.
Therefore, makes sense compute h(s) h(s) c g(s). Note
threshold computing h depends g(s), thus constant. shows
constant threshold computing h(s) best possible decision rule. Unfortunately,
selective max decision rule based approximation fails capture subtleties
case.
Table 7 shows normalized coverage using hLM-CUT+ , using selective max
hLM-CUT+ blind heuristic. results show, selective max little effect
domains, though harm performance some, one domain OPENSTACKS
actually performs better single heuristic. Table 8 shows average expansions ratio,
using number states expanded hLM-CUT+ baseline; note using blind
heuristic never increases heuristic accuracy. results show, selective max chooses
use blind heuristic quite often, expanding average twice many states
hLM-CUT+ alone.
728

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

hLM-CUT+

selh

airport (31)
freecell (13)
logistics00 (17)
mprime (24)
mystery (17)
pipesworld-tankage (9)
satellite (9)
zenotravel (12)

1.00 (31)
1.00 (13)
1.00 (17)
1.00 (24)
1.00 (17)
1.00 (9)
1.00 (9)
1.00 (12)

1.00 (31)
1.00 (13)
1.00 (17)
1.00 (24)
1.00 (17)
1.00 (9)
1.00 (9)
1.00 (12)

blocks (27)
depot (7)
driverlog (14)
grid (2)
gripper (6)
logistics98 (6)
miconic (140)
pathways (5)
pipesworld-notankage (17)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

1.00 (27)
1.00 (7)
1.00 (14)
1.00 (2)
1.00 (6)
1.00 (6)
1.00 (140)
1.00 (5)
1.00 (17)
1.00 (48)
1.00 (7)
1.00 (27)
1.00 (15)
1.00 (6)
1.00 (9)

1.00 (27)
1.00 (7)
1.00 (14)
1.00 (2)
1.00 (6)
1.00 (6)
0.86 (121)
1.00 (5)
1.00 (17)
1.00 (48)
1.00 (7)
1.00 (27)
0.93 (14)
1.00 (6)
1.00 (9)

elevators-opt08-strips (18)
openstacks-opt08-strips (19)
parcprinter-08-strips (21)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (14)

1.00 (18)
0.89 (17)
1.00 (21)
1.00 (27)
1.00 (13)
1.00 (25)
1.00 (11)
1.00 (14)

0.83 (15)
1.00 (19)
1.00 (21)
1.00 (27)
0.77 (10)
1.00 (25)
1.00 (11)
0.93 (13)

TOTAL

1.00 (614)

0.98 (589)

Table 7: Normalized coverage hLM-CUT+ selective max combining hLM-CUT+ blind
heuristic. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

729

fiD OMSHLAK , K ARPAS , & ARKOVITCH

expansions

hLM-CUT+

selh

airport (31)
freecell (13)
logistics00 (17)
mprime (24)
mystery (18)
pipesworld-tankage (9)
satellite (9)
zenotravel (12)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.0
3.13
1.02
1.22
3.2
4.23
3.11
2.37

blocks (27)
depot (7)
driverlog (14)
grid (2)
gripper (6)
logistics98 (6)
miconic (121)
pathways (5)
pipesworld-notankage (17)
psr-small (48)
rovers (7)
schedule (27)
storage (14)
tpp (6)
trucks-strips (9)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.92
1.36
1.15
7.67
1.0
1.18
14.24
1.0
1.27
2.12
1.56
1.21
5.11
1.6
1.01

elevators-opt08-strips (15)
openstacks-opt08-strips (17)
parcprinter-08-strips (21)
pegsol-08-strips (27)
scanalyzer-08-strips (10)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (13)

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

13.41
1.08
1.24
1.01
4.87
1.0
5.86
46.97

GEOMETRIC MEAN

1.0

2.3

Table 8: Average ratio expanded states baseline hLM-CUT+ selective max
combining hLM-CUT+ blind heuristic. Domains grouped domains
unit cost actions high variance coverage, domains unit cost actions low
variance coverage, domains non-uniform action costs, respectively.

730

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

experiments varied heuristics selective max uses. following
experiments, fix set heuristics, examine impact parameters selective max performance. still need evaluate 20 different configurations selective
max, focus eight selected domains: AIRPORT, FREECELL, LOGISTICS 00, MPRIME, MYS TERY , PIPESWORLD - TANKAGE, SATELLITE , ZENOTRAVEL. eight domains
highest observed variance number tasks solved across different planners, unit
action cost domains used. domains chosen order reduce computation time
required experiments manageable quantity. excluded domains non-uniform
action costs, use different method estimating goal depth state-space
sampling method, one parameters examine. Below, focus one parameter
selective max time, present total number tasks solved eight chosen domains,
different values parameter. Detailed, per-domain results parameter appear
Appendix A.
hyper-parameter
Figure 5a plots total number problems solved, different values .
results show, selective max fairly robust respect value , unless large
value chosen, making difficult selective max choose accurate
heuristic.
Detailed, per-domain results appear Table 19 Appendix A, well Figure 6.
results show complex picture, seems cutoff value
domain, increasing past value impairs performance. one exception
PIPESWORLD - TANKAGE domain, setting = 5 helps.
confidence threshold
Figure 5b plots total number problems solved, different values , Detailed,
per-domain results appear Table 20 Appendix A. results indicate selective
max also robust values , unless set low value, causing selective max
behave like regular point-wise maximum.
initial sample size N
Figure 5c plots total number problems solved different values N .
x-axis logscale. Detailed, per-domain results appear Table 21 Appendix A.
results show, default value N = 100 best (of three values tried), although
selective max still fairly robust respect choice parameter.
sampling method
Figure 7 shows total number problems solved using different methods initial
state-space sampling. Detailed, per-domain results appear Table 22 Appendix A.
results demonstrate, choice sampling method notably affect performance
selective max. However, detailed results show, effect evident FREE CELL domain. also remark default sampling method, PDB, performs worse
others. Indeed using probe based sampling methods, selective max outperforms
using hLA alone. However, difference due FREECELL domain,
state certainty would generalize across domains.
731

fiSolved Instances

OMSHLAK , K ARPAS , & ARKOVITCH

174
172
170
168
166
0

0.5

1

1.5

2

2.5


3

3.5

4

4.5

5

0.8

0.85

0.9

0.95

1

Solved Instances

(a) Hyper-parameter

174
172
170
168
166
0.5

0.55

0.6

0.65

0.7

0.75


Solved Instances

(b) Confidence threshold

174
172
170
168
166
10

100


1000

(c) Initial Sample Size N
Figure 5: Number problems solved selective max different values (a) hyperparameter (b) confidence threshold , (c) initial sample size N .

732

fiSolved Instances

NLINE PEEDUP L EARNING PTIMAL P LANNING

50
45
40
35
30
25
20
15
10
5

airport
freecell
logistics00
mprime
mystery
pw-tankage
satellite
zenotravel
0

1

2

3

4

5



Figure 6: Number problems solved selective domain different values .

180
160

Solved Instances

140
120
100
80
60
40
20
0

PDB
174

Probe
178
Sampling Method

UnbiasedProbe
180

Figure 7: Number problems solved selective max different sampling methods.

733

fiD OMSHLAK , K ARPAS , & ARKOVITCH

180
160

Solved Instances

140
120
100
80
60
40
20
0
NB
174

AODE
168

ITI
156
Classifier

3NN
158

5NN
161

Figure 8: Number problems solved selective max different classifiers.
classifier
Figure 8 shows total number problems solved using different classifiers. Detailed,
per-domain results appear Table 23 Appendix A. Naive Bayes appears best
classifier use selective max, although AODE also performs quite well. Even though
kNN enjoys fast learning, classifier used mostly classification, expected,
kNN well. However, increased accuracy k = 5 seems pay
faster classification k = 3.
6.3 Comparison Sequential Portfolios
Sequential portfolio solvers optimal planning another approach exploiting merits
different heuristic functions, successful practice, Fast Downward
Stone Soup sequential portfolio (Helmert et al., 2011) winning sequential optimal track IPC2011. sequential portfolio utilizes different solvers running sequentially, prespecified time limit. one solver fails find solution allotted time limit, sequential
portfolio terminates it, moves next solver. However, sequential portfolio solver
needs know time allowance problem trying solve beforehand, setting known
contract anytime (Russell & Zilberstein, 1991). contrast, selective max used
interruptible anytime manner, time limit need known advance.
Here, compare selective max sequential portfolios heuristics.
exact time took search using heuristic alone solve problem,
determine whether sequential portfolio assigns heuristic time limit able
solve problem. Using data, simulate results two types sequential portfolio
planners. first setting, assume time limit known advance, simulate
results contract portfolio giving equal share time heuristics. second setting,
simulate interruptible anytime portfolio using binary exponential backoff time limits: starting
734

fi700

700

650

650
Solved Instances

Solved Instances

NLINE PEEDUP L EARNING PTIMAL P LANNING

600
550
500

selh
portctr

450

600
550
500

selh
portctr

450

portint

portint

400

400
200

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

200

700

700

650

650

600
550
500

selh
portctr

450

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

hLA / hLM-CUT+
(b)

Solved Instances

Solved Instances

hLA / hLM-CUT
(a)

400

600
550
500

selh
portctr

450

portint

portint

400

400
200

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

200

hLM-CUT / hLM-CUT+
(c)

400

600 800 1000 1200 1400 1600 1800
Timeout (seconds)

hLA / hLM-CUT / hLM-CUT+
(d)

Figure 9: Anytime profiles sequential portfolios selective max. plot shows number problems solved selective max (selh ), simulated contract anytime portfolio
(portctr ), simulated interruptible portfolio (portint ) using (a) hLA hLM-CUT (b)
hLA hLM-CUT+ (c) hLM-CUT hLM-CUT+ , (d) hLA , hLM-CUT , hLM-CUT+ .

time limit 1 second heuristic, increase time limit factor 2 none
heuristics able guide solve planning problem. several possible
orderings heuristics here, use de facto best ordering problem. denote
contract anytime portfolio portctr , interruptible anytime portfolio portint .
Figure 9 shows number problems solved different time limits selective max,
contract anytime sequential portfolio, interruptible anytime sequential portfolio.
results show, contract anytime sequential portfolio almost always outperforms selective
max. hand, sequential portfolio know time limit advance,
performance deteriorates significantly. best heuristic combination selective max, hLA
hLM-CUT , outperforms interruptible anytime portfolio using heuristics,
735

fiD OMSHLAK , K ARPAS , & ARKOVITCH

selective max combination hLM-CUT hLM-CUT+ . combinations heuristics,
interruptible anytime portfolio performs better selective max.

7. Discussion
Learning planning active field since early days planning (Fikes, Hart,
& Nilsson, 1972), recently receiving growing attention community. However, despite
early work (Rendell, 1983), relatively little work dealt learning state-space search
guided distance-estimating heuristics, one prominent approaches planning
days. works direction devoted learning macro-actions (see, example,
Finkelstein & Markovitch, 1998; Botea, Enzenberger, Muller, & Schaeffer, 2005; Coles & Smith,
2007). Recently, learning heuristic search planning received attention: Yoon et al.
(2008) suggested learning (inadmissible) heuristic functions based upon features extracted
relaxed plans. Arfaee, Zilles, Holte (2010) attempted learn almost admissible heuristic
estimate using neural network. Perhaps closely related work Thayer,
Dionne, Ruml (2011), learn correct errors heuristic estimates online. Thayer et al. attempt improve accuracy single given heuristic, selective max attempts choose one
several given heuristics state. two works differ technically point. importantly, however, none aforementioned approaches guarantee resulting heuristic
admissible, thus optimal solution found. contrast, focus optimal planning, aware previous work deals learning optimal
heuristic search.
experimental evaluation demonstrates selective max effective method
combining arbitrary admissible heuristics baseline point-wise maximization. Also advantageous selective maxs ability exploit pairs heuristics, one guaranteed always
least accurate other. example, hLA heuristic used two action
cost partitioning schemes: uniform optimal (Karpas & Domshlak, 2009). heuristic induced
optimal action cost partitioning least accurate one induced uniform action
cost partitioning, takes much longer compute. Selective max might used learn
worth spending extra time compute optimal cost partitioning, not.
contrast, max-based combination two heuristics would simply waste time spent
computing uniform action cost partitioning.
controlled parametric experiments demonstrate right choice classifier
sampling method initial state-space sample important. parameters
selective max appear affect performance much, long set reasonable
values. implies selective max could improved using faster, accurate, classifiers,
developing sampling methods represent state-space well.
Finally, remark Fast Downward Autotune entry sequential optimal track
2011 edition International Planning Competition, used ParamILS (Hutter, Hoos,
Leyton-Brown, & Stutzle, 2009) choose best configuration Fast Downward planner,
chose use selective-max combine hLM-CUT hmax (Bonet, Loerincs, & Geffner, 1997).
provides evidence selective max practically valuable method combining
heuristics optimal planning.
736

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

hLA

hLM-CUT

hLM-CUT+

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

Table 9: Detailed per-domain results individual heuristic. Normalized coverage
shown, number problems solved shown parentheses. Domains grouped
domains unit cost actions high variance coverage, domains unit
cost actions low variance coverage, domains non-uniform action costs,
respectively.

Acknowledgments
work partly supported Israel Science Foundation (ISF) grant 1045/12.

Appendix A. Detailed Results Empirical Evaluation
appendix, present detailed per-domain, results experiments described Section 6.
Table 9 shows normalized coverage number problems solved domain,
individual heuristics. normalized coverage score planner X domain number
problems domain solved planner X, divided number problems domain
solved least one planner. Tables 10 17 give results combinations two
heuristics. Tables 10, 12, 14, 16 list normalized coverage individual heuristics used,
combination using selective max (selh ), regular maximum (maxh ), random choice
heuristic state (rndh ) 30 minutes. Tables 11, 13, 15, 17 give geometric
mean ratio expanded states relative maxh domain, problems solved
configurations. number tasks solved planners listed parentheses next
domain. final row gives geometric mean geometric means domain.
737

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLA

hLM-CUT

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.91 (30)
0.71 (41)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.85 (28)
0.28 (16)
0.95 (20)
0.75 (18)
0.76 (13)
0.85 (11)
0.70 (7)
0.77 (10)

0.91 (30)
0.84 (49)
1.00 (21)
1.00 (24)
1.00 (17)
0.92 (12)
0.80 (8)
1.00 (13)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
0.80 (4)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.84 (16)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.44 (7)
1.00 (30)
0.92 (11)
0.68 (13)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.89 (17)

TOTAL

0.91 (656)

0.92 (639)

0.94 (665)

0.85 (603)

0.95 (677)

Table 10: Detailed per-domain normalized coverage using hLA hLM-CUT . line shows
normalized coverage domain, number problems solved shown
parentheses. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

738

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLA

hLM-CUT

maxh

rndh

selh

airport (28)
freecell (15)
logistics00 (20)
mprime (18)
mystery (14)
pipesworld-tankage (11)
satellite (7)
zenotravel (10)

2.88
1.01
1.0
6.34
7.9
1.61
6.27
7.98

1.12
529.61
1.0
1.89
1.15
2.35
1.26
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.61
116.96
1.0
4.2
5.19
1.62
2.32
3.3

2.2
2.14
1.0
1.52
1.17
1.12
1.09
2.02

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (7)
logistics98 (6)
miconic (141)
pathways (4)
pipesworld-notankage (17)
psr-small (49)
rovers (7)
schedule (30)
storage (15)
tpp (6)
trucks-strips (9)

7.4
3.45
7.2
2.15
1.0
7.74
1.0
39.65
2.01
1.27
2.18
1.15
2.16
1.74
46.11

1.0
1.32
1.09
1.73
1.04
1.0
1.0
1.0
2.16
1.0
1.31
1.0
1.0
1.0
1.02

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

2.2
1.91
2.89
1.57
1.02
2.69
1.0
17.91
1.97
1.11
1.77
1.03
1.45
1.42
12.12

1.61
1.3
1.24
1.83
1.0
1.08
1.0
1.0
1.36
1.15
1.09
1.15
1.56
1.0
1.01

elevators-opt08-strips (17)
openstacks-opt08-strips (18)
parcprinter-08-strips (15)
pegsol-08-strips (27)
scanalyzer-08-strips (7)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (12)

21.51
1.17
24.13
3.72
69.2
15.74
12.09
31.6

1.03
1.0
1.0
1.01
1.0
1.07
1.01
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

5.99
1.03
9.34
1.8
21.47
1.33
3.79
5.68

1.37
1.15
1.0
1.01
1.14
1.04
1.44
1.28

GEOMETRIC MEAN

4.82

1.4

1.0

2.93

1.25

Table 11: Detailed per-domain expansions relative maxh using hLA hLM-CUT . row
shows geometric mean ratio expanded nodes relative maxh . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

739

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLA

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.53 (31)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.85 (28)
0.26 (15)
0.95 (20)
0.67 (16)
0.71 (12)
0.62 (8)
0.70 (7)
0.69 (9)

0.91 (30)
0.71 (41)
1.00 (21)
1.00 (24)
1.00 (17)
0.69 (9)
1.00 (10)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.71 (5)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.93 (26)
0.86 (6)
0.93 (13)
0.67 (2)
0.86 (6)
0.83 (5)
0.99 (140)
0.80 (4)
0.83 (15)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.70 (7)

0.93 (26)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.80 (16)
0.95 (21)
0.96 (27)
0.81 (13)
0.77 (23)
0.92 (11)
0.79 (15)

0.59 (13)
0.85 (17)
0.55 (12)
0.96 (27)
0.38 (6)
0.83 (25)
0.92 (11)
0.58 (11)

0.73 (16)
0.85 (17)
1.00 (22)
0.96 (27)
0.81 (13)
0.80 (24)
0.92 (11)
0.79 (15)

TOTAL

0.91 (656)

0.89 (614)

0.89 (628)

0.78 (564)

0.92 (651)

Table 12: Detailed per-domain normalized coverage using hLA hLM-CUT+ . line shows
normalized coverage domain, number problems solved shown
parentheses. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

740

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLA

hLM-CUT+

maxh

rndh

selh

airport (28)
freecell (13)
logistics00 (16)
mprime (16)
mystery (13)
pipesworld-tankage (8)
satellite (7)
zenotravel (9)

3.05
1.22
1.0
8.45
7.76
2.17
19.26
6.62

1.0
47.57
1.0
1.23
1.11
1.42
1.03
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.43
10.54
1.0
5.2
4.77
1.48
5.94
3.09

2.81
2.05
1.0
1.57
1.7
1.86
4.12
4.04

blocks (26)
depot (6)
driverlog (13)
grid (2)
gripper (5)
logistics98 (5)
miconic (140)
pathways (4)
pipesworld-notankage (15)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (7)

6.97
21.8
11.11
5.04
1.0
6.1
1.0
40.56
3.08
1.31
2.75
1.09
2.29
2.72
46.09

1.0
1.0
1.01
1.01
1.0
1.0
1.0
1.0
1.12
1.0
1.01
1.0
1.0
1.0
1.01

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

2.15
5.46
3.71
2.14
1.0
2.14
1.0
18.03
1.75
1.14
1.81
1.0
1.53
1.88
12.02

4.28
3.96
2.56
4.74
1.0
3.79
1.0
1.0
2.46
1.27
1.45
1.09
2.16
1.17
1.01

elevators-opt08-strips (13)
openstacks-opt08-strips (16)
parcprinter-08-strips (12)
pegsol-08-strips (27)
scanalyzer-08-strips (6)
sokoban-opt08-strips (21)
transport-opt08-strips (11)
woodworking-opt08-strips (11)

28.6
1.17
24.87
4.92
23.07
15.66
15.34
53.27

1.01
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

7.1
1.03
9.23
2.15
6.88
1.33
4.26
8.53

7.46
1.09
1.19
1.0
1.43
1.01
2.84
1.91

GEOMETRIC MEAN

5.85

1.16

1.0

2.9

1.89

Table 13: Detailed per-domain expansions relative maxh using hLA hLM-CUT+ . row
shows geometric mean ratio expanded nodes relative maxh . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

741

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.22 (13)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.82 (27)
0.21 (12)
0.95 (20)
0.88 (21)
0.88 (15)
0.62 (8)
0.70 (7)
0.92 (12)

0.85 (28)
0.22 (13)
0.95 (20)
1.00 (24)
0.94 (16)
0.69 (9)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.89 (16)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.79 (15)

0.82 (18)
0.95 (19)
0.82 (18)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.95 (21)
0.95 (19)
0.91 (20)
0.96 (27)
0.94 (15)
0.83 (25)
0.92 (11)
0.95 (18)

TOTAL

0.92 (639)

0.89 (614)

0.89 (614)

0.87 (602)

0.91 (630)

Table 14: Detailed per-domain normalized coverage using hLM-CUT hLM-CUT+ . line shows
normalized coverage domain, number problems solved shown
parentheses. Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

742

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (26)
freecell (12)
logistics00 (16)
mprime (21)
mystery (16)
pipesworld-tankage (8)
satellite (7)
zenotravel (12)

1.16
9.55
1.0
2.2
1.69
3.09
3.66
1.61

1.0
1.0
1.0
1.01
1.01
1.01
0.98
1.09

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.04
4.37
1.0
1.84
1.52
1.75
2.39
1.3

1.16
1.26
1.0
1.0
1.32
1.61
1.51
1.22

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (6)
logistics98 (6)
miconic (140)
pathways (5)
pipesworld-notankage (16)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

1.02
7.53
1.71
4.03
1.05
1.08
1.0
1.22
3.49
1.03
1.66
1.0
1.07
1.56
1.32

1.0
1.0
1.02
1.0
1.0
1.05
1.0
1.02
1.01
1.0
1.01
1.0
1.0
1.0
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.01
4.07
1.36
1.9
1.03
1.06
1.0
1.13
1.9
1.02
1.28
1.0
1.03
1.16
1.14

1.02
1.25
1.49
1.28
1.05
1.06
1.0
1.22
1.4
1.03
1.3
1.0
1.07
1.56
1.26

elevators-opt08-strips (18)
openstacks-opt08-strips (17)
parcprinter-08-strips (17)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (25)
transport-opt08-strips (11)
woodworking-opt08-strips (13)

1.75
1.0
1.71
1.33
1.22
1.04
1.29
1.45

1.09
1.0
1.0
1.01
1.02
1.04
1.01
1.06

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.4
1.0
1.37
1.15
1.14
1.01
1.15
1.26

1.72
1.0
1.0
1.2
1.13
1.03
1.26
1.12

GEOMETRIC MEAN

1.66

1.01

1.0

1.35

1.2

Table 15: Detailed per-domain expansions relative maxh using hLM-CUT hLM-CUT+ .
row shows geometric mean ratio expanded nodes relative maxh . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

743

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

hLA

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
1.00 (58)
1.00 (21)
0.88 (21)
0.88 (15)
1.00 (13)
0.70 (7)
0.77 (10)

0.85 (28)
0.26 (15)
0.95 (20)
1.00 (24)
1.00 (17)
0.92 (12)
0.70 (7)
1.00 (13)

0.94 (31)
0.22 (13)
0.81 (17)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.94 (31)
0.53 (31)
0.76 (16)
1.00 (24)
1.00 (17)
0.69 (9)
0.90 (9)
0.92 (12)

0.79 (26)
0.26 (15)
0.95 (20)
0.75 (18)
0.71 (12)
0.69 (9)
0.70 (7)
0.69 (9)

0.91 (30)
0.57 (33)
0.95 (20)
0.96 (23)
1.00 (17)
0.85 (11)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.96 (27)
1.00 (7)
1.00 (14)
1.00 (3)
1.00 (7)
1.00 (6)
1.00 (142)
0.80 (4)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
0.71 (5)
1.00 (6)
0.99 (140)
1.00 (5)
0.94 (17)
0.98 (48)
0.88 (7)
0.90 (27)
1.00 (15)
1.00 (6)
0.90 (9)

0.96 (27)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
0.83 (5)
0.99 (140)
0.80 (4)
0.83 (15)
0.98 (48)
0.88 (7)
0.93 (28)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.77 (17)
0.90 (18)
0.68 (15)
0.96 (27)
0.56 (9)
0.83 (25)
1.00 (12)
0.68 (13)

1.00 (22)
1.00 (20)
0.82 (18)
1.00 (28)
0.94 (15)
1.00 (30)
0.92 (11)
0.84 (16)

0.82 (18)
0.85 (17)
0.95 (21)
0.96 (27)
0.81 (13)
0.83 (25)
0.92 (11)
0.74 (14)

0.82 (18)
0.80 (16)
0.95 (21)
0.96 (27)
0.81 (13)
0.77 (23)
0.92 (11)
0.79 (15)

0.64 (14)
0.90 (18)
0.59 (13)
0.96 (27)
0.38 (6)
0.90 (27)
0.92 (11)
0.74 (14)

0.95 (21)
0.80 (16)
0.86 (19)
0.96 (27)
0.94 (15)
0.87 (26)
0.92 (11)
0.79 (15)

TOTAL

0.91 (656)

0.92 (639)

0.89 (614)

0.89 (628)

0.81 (578)

0.92 (649)

Table 16: Detailed per-domain normalized coverage using hLA , hLM-CUT hLM-CUT+ . line
shows normalized coverage domain, number problems solved
shown parentheses. Domains grouped domains unit cost actions high
variance coverage, domains unit cost actions low variance coverage,
domains non-uniform action costs, respectively.

744

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

expansions

hLA

hLM-CUT

hLM-CUT+

maxh

rndh

selh

airport (26)
freecell (13)
logistics00 (16)
mprime (18)
mystery (13)
pipesworld-tankage (9)
satellite (7)
zenotravel (9)

2.29
1.22
1.0
9.21
7.85
2.68
18.81
7.26

1.16
417.8
1.0
2.74
1.41
5.08
3.78
1.23

1.0
47.65
1.0
1.21
1.13
1.38
1.01
1.1

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.04
45.83
1.0
4.26
4.48
2.27
4.53
3.07

1.71
6.73
1.0
1.99
1.43
1.93
2.45
2.45

blocks (27)
depot (7)
driverlog (13)
grid (2)
gripper (5)
logistics98 (5)
miconic (140)
pathways (4)
pipesworld-notankage (15)
psr-small (48)
rovers (7)
schedule (27)
storage (15)
tpp (6)
trucks-strips (9)

7.59
19.63
11.36
5.04
1.0
6.43
1.0
40.63
3.09
1.31
2.77
1.09
2.3
2.73
60.39

1.02
7.53
1.73
4.06
1.06
1.08
1.0
1.02
4.29
1.03
1.67
1.0
1.07
1.56
1.33

1.0
1.01
1.03
1.01
1.0
1.05
1.0
1.0
1.13
1.0
1.01
1.0
1.01
1.0
1.01

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

1.58
5.22
2.79
2.15
1.02
1.79
1.0
7.76
2.35
1.1
1.78
0.99
1.33
1.91
6.05

1.67
2.46
2.03
4.91
1.0
1.58
1.0
1.0
2.53
1.24
1.38
1.09
1.58
1.41
1.33

elevators-opt08-strips (14)
openstacks-opt08-strips (16)
parcprinter-08-strips (13)
pegsol-08-strips (27)
scanalyzer-08-strips (6)
sokoban-opt08-strips (21)
transport-opt08-strips (11)
woodworking-opt08-strips (11)

33.16
1.17
45.31
4.94
24.13
16.43
15.5
53.33

1.65
1.0
2.02
1.34
1.5
1.03
1.29
1.37

1.1
1.0
1.0
1.01
1.05
1.05
1.01
1.0

1.0
1.0
1.0
1.0
1.0
1.0
1.0
1.0

4.65
1.03
5.91
1.69
5.5
1.14
2.66
4.02

2.9
1.07
1.0
1.26
1.87
1.13
1.82
1.63

GEOMETRIC MEAN

6.1

1.91

1.18

1.0

2.56

1.67

Table 17: Detailed per-domain expansions relative maxh using hLA , hLM-CUT hLM-CUT+ .
row shows geometric mean ratio expanded nodes relative maxh .
Domains grouped domains unit cost actions high variance coverage,
domains unit cost actions low variance coverage, domains nonuniform action costs, respectively.

745

fiD OMSHLAK , K ARPAS , & ARKOVITCH

overhead

hLA /hLM-CUT

hLA /hLM-CUT+

hLM-CUT /hLM-CUT+

Three

airport (28)
freecell (13)
logistics00 (20)
mprime (23)
mystery (17)
pipesworld-tankage (9)
satellite (7)
zenotravel (12)
blocks (26)
depot (7)
driverlog (13)
grid (2)
gripper (7)
logistics98 (6)
miconic (141)
pathways (5)
pipesworld-notankage (17)
psr-small (49)
rovers (7)
schedule (30)
storage (15)
tpp (6)
trucks-strips (9)
elevators-opt08-strips (16)
openstacks-opt08-strips (16)
parcprinter-08-strips (18)
pegsol-08-strips (27)
scanalyzer-08-strips (13)
sokoban-opt08-strips (24)
transport-opt08-strips (11)
woodworking-opt08-strips (14)

4%
4%
8%
7%
3%
11%
14%
15%
21%
45%
29%
26%
13%
15%
1%
5%
22%
8%
15%
13%
18%
2%
3%
32%
15%
2%
9%
2%
5%
12%
5%

7%
8%
7%
7%
3%
11%
18%
35%
35%
29%
45%
17%
13%
31%
4%
1%
17%
11%
24%
13%
12%
1%
2%
75%
9%
6%
2%
4%
2%
23%
5%

1%
13%
2%
6%
8%
10%
10%
26%
2%
14%
26%
1%
5%
6%
3%
4%
20%
3%
26%
5%
2%
2%
12%
8%
10%
1%
28%
10%
14%
7%
2%

9%
1%
6%
3%
2%
5%
8%
21%
5%
10%
21%
6%
22%
5%
4%
7%
22%
12%
19%
24%
10%
3%
7%
9%
23%
5%
15%
1%
7%
3%
4%

AVERAGE

12%

15%

9%

10%

Table 18: Selective max overhead. row lists average percentage time spent learning
classification, total time taken selective max, domain,
set heuristics. Domains grouped domains unit cost actions high
variance coverage, domains unit cost actions low variance coverage,
domains non-uniform action costs, respectively.

746

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

sel=0.1
h
30
49
21
24
17
12
8
13
174

sel=0.5
h
30
49
21
24
17
12
8
13
174

sel=1
h
30
49
21
24
17
12
8
13
174

sel=1.5
h
30
49
21
24
17
12
8
13
174

sel=2
h
30
49
21
22
17
12
7
12
170

sel=3
h
30
49
21
23
16
12
7
11
169

sel=4
h
30
49
21
21
15
13
7
10
166

sel=5
h
30
49
21
21
15
13
7
10
166

Table 19: Number problems solved selective max domain varying values
hyper-parameter

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

sel=0.51
h
30
48
21
24
17
12
8
13
173

sel=0.6
h
30
49
21
24
17
12
8
13
174

sel=0.7
h
30
49
21
24
17
12
8
13
174

sel=0.8
h
30
49
21
24
17
12
8
13
174

sel=0.9
h
30
49
21
24
17
12
8
13
174

sel=0.99
h
30
49
21
24
17
12
8
13
174

Table 20: Number problems solved selective max domain varying values
confidence threshold

Table 18 lists average overhead selective max domain, combination
two heuristics.
Tables 19, 20, 21, 22 23 list number problems solved domain, various
values , , N , sampling method classifier, respectively.

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

=10
selN
h
30
47
21
24
17
12
8
13
172

=100
selN
h
30
49
21
24
17
12
8
13
174

=1000
selN
h
30
46
21
24
17
12
8
13
171

Table 21: Number problems solved selective max domain varying values
initial Sample Size N

747

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

selPDB
h
30
49
21
24
17
12
8
13
174

selP
h
30
53
21
24
17
12
8
13
178

P
selU
h
30
55
21
24
17
12
8
13
180

Table 22: Number problems solved selective max domain different sampling
methods. PDB sampling method Haslum et al. (2007), P biased probes
sampling method, U P unbiased probes sampling method.

coverage
airport (50)
freecell (80)
logistics00 (28)
mprime (35)
mystery (30)
pipesworld-tankage (50)
satellite (36)
zenotravel (20)
SUM

B
selN
h
30
49
21
24
17
12
8
13
174

selAODE
h
25
49
20
24
17
12
8
13
168


selIT
h
30
34
20
24
17
12
7
12
156

N
sel3N
h
30
35
20
24
17
12
7
13
158

N
sel5N
h
28
46
20
23
17
10
6
11
161

Table 23: Number problems solved selective max domain different classifiers

748

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.84 (49)
1.00 (21)
1.00 (24)
1.00 (17)
0.92 (12)
0.80 (8)
1.00 (13)

0.91 (30)
0.91 (53)
0.95 (20)
0.96 (23)
1.12 (19)
0.92 (12)
0.70 (7)
0.92 (12)

0.91 (30)
0.93 (54)
1.00 (21)
0.96 (23)
1.24 (21)
1.00 (13)
0.70 (7)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

1.00 (22)
0.90 (18)
0.82 (18)
0.96 (27)
0.94 (15)
0.97 (29)
0.92 (11)
0.89 (17)

0.82 (18)
0.90 (18)
0.82 (18)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.84 (16)

0.86 (19)
0.95 (19)
0.82 (18)
0.96 (27)
1.00 (16)
0.97 (29)
1.00 (12)
0.89 (17)

TOTAL

0.95 (677)

0.94 (672)

0.96 (685)

Table 24: Detailed coverage portfolio using hLA / hLM-CUT . Number problems solved selective max (selh ), simulated interruptible portfolio (portint ), simulated contract
anytime portfolio (portctr ) domain using heuristics hLA / hLM-CUT . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

749

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.71 (41)
1.00 (21)
1.00 (24)
1.00 (17)
0.69 (9)
1.00 (10)
0.92 (12)

0.91 (30)
0.91 (53)
0.95 (20)
1.00 (24)
1.12 (19)
0.92 (12)
0.80 (8)
0.85 (11)

0.91 (30)
0.93 (54)
1.00 (21)
1.00 (24)
1.18 (20)
1.00 (13)
0.80 (8)
0.85 (11)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

0.93 (26)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

0.93 (26)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.70 (7)

0.96 (27)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.80 (8)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.73 (16)
0.85 (17)
1.00 (22)
0.96 (27)
0.81 (13)
0.80 (24)
0.92 (11)
0.79 (15)

0.82 (18)
0.85 (17)
1.00 (22)
0.96 (27)
0.75 (12)
0.83 (25)
0.92 (11)
0.79 (15)

0.82 (18)
0.85 (17)
1.00 (22)
0.96 (27)
0.94 (15)
0.83 (25)
1.00 (12)
0.79 (15)

TOTAL

0.92 (651)

0.93 (666)

0.94 (676)

Table 25: Detailed coverage portfolio using hLA / hLM-CUT+ . Number problems solved selective max (selh ), simulated interruptible portfolio (portint ), simulated contract
anytime portfolio (portctr ) domain using heuristics hLA / hLM-CUT+ . Domains
grouped domains unit cost actions high variance coverage, domains
unit cost actions low variance coverage, domains non-uniform action
costs, respectively.

750

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.85 (28)
0.22 (13)
0.95 (20)
1.00 (24)
0.94 (16)
0.69 (9)
0.80 (8)
0.92 (12)

0.88 (29)
0.24 (14)
0.95 (20)
1.00 (24)
1.18 (20)
0.69 (9)
0.80 (8)
0.92 (12)

0.88 (29)
0.26 (15)
0.95 (20)
1.00 (24)
1.24 (21)
0.85 (11)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
0.86 (6)
1.00 (6)
0.99 (140)
1.00 (5)
0.89 (16)
1.00 (49)
0.88 (7)
0.93 (28)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
0.99 (141)
1.00 (5)
0.94 (17)
1.00 (49)
0.88 (7)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.95 (21)
0.95 (19)
0.91 (20)
0.96 (27)
0.94 (15)
0.83 (25)
0.92 (11)
0.95 (18)

0.82 (18)
0.90 (18)
1.00 (22)
0.96 (27)
0.81 (13)
0.93 (28)
0.92 (11)
0.79 (15)

0.86 (19)
0.95 (19)
1.00 (22)
0.96 (27)
0.94 (15)
0.93 (28)
0.92 (11)
0.84 (16)

TOTAL

0.91 (630)

0.90 (625)

0.93 (640)

Table 26: Detailed coverage portfolio using hLM-CUT / hLM-CUT+ . Number problems solved
selective max (selh ), simulated interruptible portfolio (portint ), simulated
contract anytime portfolio (portctr ) domain using heuristics hLM-CUT / hLM-CUT+ .
Domains grouped domains unit cost actions high variance coverage,
domains unit cost actions low variance coverage, domains nonuniform action costs, respectively.

751

fiD OMSHLAK , K ARPAS , & ARKOVITCH

coverage

selh

portint

portctr

airport (33)
freecell (58)
logistics00 (21)
mprime (24)
mystery (17)
pipesworld-tankage (13)
satellite (10)
zenotravel (13)

0.91 (30)
0.57 (33)
0.95 (20)
0.96 (23)
1.00 (17)
0.85 (11)
0.80 (8)
0.92 (12)

0.91 (30)
0.91 (53)
0.95 (20)
1.00 (24)
1.18 (20)
0.92 (12)
0.80 (8)
0.92 (12)

0.91 (30)
0.93 (54)
1.00 (21)
1.00 (24)
1.18 (20)
0.92 (12)
0.80 (8)
0.92 (12)

blocks (28)
depot (7)
driverlog (14)
grid (3)
gripper (7)
logistics98 (6)
miconic (142)
pathways (5)
pipesworld-notankage (18)
psr-small (49)
rovers (8)
schedule (30)
storage (15)
tpp (6)
trucks-strips (10)

1.00 (28)
1.00 (7)
0.93 (13)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
0.94 (17)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
1.00 (10)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

1.00 (28)
1.00 (7)
1.00 (14)
0.67 (2)
1.00 (7)
1.00 (6)
1.00 (142)
1.00 (5)
1.00 (18)
1.00 (49)
1.00 (8)
1.00 (30)
1.00 (15)
1.00 (6)
0.90 (9)

elevators-opt08-strips (22)
openstacks-opt08-strips (20)
parcprinter-08-strips (22)
pegsol-08-strips (28)
scanalyzer-08-strips (16)
sokoban-opt08-strips (30)
transport-opt08-strips (12)
woodworking-opt08-strips (19)

0.95 (21)
0.80 (16)
0.86 (19)
0.96 (27)
0.94 (15)
0.87 (26)
0.92 (11)
0.79 (15)

0.82 (18)
0.90 (18)
1.00 (22)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.84 (16)

0.86 (19)
0.95 (19)
1.00 (22)
0.96 (27)
0.81 (13)
0.97 (29)
0.92 (11)
0.89 (17)

TOTAL

0.92 (649)

0.95 (679)

0.95 (684)

Table 27: Detailed coverage portfolio using hLA / hLM-CUT / hLM-CUT+ . Number problems
solved selective max (selh ), simulated interruptible portfolio (portint ), simulated contract anytime portfolio (portctr ) domain using heuristics hLA / hLM-CUT
/ hLM-CUT+ . Domains grouped domains unit cost actions high variance
coverage, domains unit cost actions low variance coverage, domains
non-uniform action costs, respectively.

Tables 24, 25, 26 27 list normalized coverage domain selective max,
simulated contract interruptible sequential portfolios.

References
Arfaee, S. J., Zilles, S., & Holte, R. C. (2010). Bootstrap learning heuristic functions. Felner,
A., & Sturtevant, N. (Eds.), Proceedings Third Annual Symposium Combinatorial
Search (SoCS 2010), pp. 5260. AAAI Press.
Backstrom, C., & Klein, I. (1991). Planning polynomial time: SAS-PUBS class. Computational Intelligence, 7(3), 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational Intelligence, 11(4), 625655.
Bayardo Jr., R. J., & Schrag, R. (1997). Using CSP look-back techniques solve real-world SAT
instances. Kuipers, B., & Webber, B. L. (Eds.), Proceedings Fourteenth National
Conference Artificial Intelligence (AAAI 1997), pp. 203208. AAAI Press.
752

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets. Coelho,
H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th European Conference
Artificial Intelligence (ECAI 2010), pp. 329334. IOS Press.
Bonet, B., Loerincs, G., & Geffner, H. (1997). robust fast action selection mechanism
planning. Kuipers, B., & Webber, B. L. (Eds.), Proceedings Fourteenth National
Conference Artificial Intelligence (AAAI 1997), pp. 714719. AAAI Press.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI planning
automatically learned macro-operators. Journal Artificial Intelligence Research, 24,
581621.
Brafman, R., & Shani, G. (2012). multi-path compilation approach contingent planning.
Hoffmann, J., & Selman, B. (Eds.), Proceedings Twenty-Sixth AAAI Conference
Artificial Intelligence (AAAI 2012), pp. 915. AAAI Press.
Burke, E., Kendall, G., Newall, J., Hart, E., Ross, P., & Schulenburg, S. (2003). Hyper-Heuristics:
Emerging Direction Modern Search Technology. Handbook Metaheuristics, International Series Operations Research & Management Science, chap. 16, pp. 457474.
Coles, A., & Smith, A. (2007). Marvin: heuristic search planner online macro-action learning. Journal Artificial Intelligence Research, 28, 119156.
Cover, T. M., & Hart, P. E. (1967). Nearest neighbor pattern classification. IEEE Transactions
Information Theory, 13(1), 21 27.
de la Rosa, T., Jimenez, S., & Borrajo, D. (2008). Learning relational decision trees guiding
heuristic planning. Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings
Eighteenth International Conference Automated Planning Scheduling (ICAPS
2008), pp. 6067. AAAI Press.
Domshlak, C., Karpas, E., & Markovitch, S. (2010). max max: Online learning
speeding optimal planning. Fox, M., & Poole, D. (Eds.), Proceedings TwentyFourth AAAI Conference Artificial Intelligence (AAAI 2010), pp. 10711076. AAAI Press.
Fern, A. (2010). Speedup learning. Sammut, C., & Webb, G. I. (Eds.), Encyclopedia Machine
Learning, pp. 907911. Springer.
Fern, A., Khardon, R., & Tadepalli, P. (2011). first learning track international planning
competition. Machine Learning, 84(1-2), 81107.
Fikes, R. E., Hart, P. E., & Nilsson, N. J. (1972). Learning executing generalized robot plans.
Artificial Intelligence, 3, 251288.
Fikes, R. E., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2, 189208.
Finkelstein, L., & Markovitch, S. (1998). selective macro-learning algorithm application
NxN sliding-tile puzzle. Journal Artificial Intelligence Research, 8, 223263.
Garca-Olaya, A., Jimenez, S., & Linares Lopez, C. (2011). 2011 international planning competition. Tech. rep., Universidad Carlos III de Madrid. http://hdl.handle.net/10016/11710.
Geffner, H. (2010). model-based approach autonomous behavior: personal view. Fox,
M., & Poole, D. (Eds.), Proceedings Twenty-Fourth AAAI Conference Artificial
Intelligence (AAAI 2010), pp. 17091712. AAAI Press.
753

fiD OMSHLAK , K ARPAS , & ARKOVITCH

Haslum, P., Botea, A., Helmert, M., Bonet, B., & Koenig, S. (2007). Domain-independent construction pattern database heuristics cost-optimal planning. Holte, R. C., & Howe, A. E.
(Eds.), Proceedings Twenty-Second AAAI Conference Artificial Intelligence (AAAI
2007), pp. 10071012. AAAI Press.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats difference anyway?. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings
Nineteenth International Conference Automated Planning Scheduling (ICAPS
2009), pp. 162169. AAAI Press.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal sequential planning. Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings Seventeenth
International Conference Automated Planning Scheduling (ICAPS 2007), pp. 176
183. AAAI Press.
Helmert, M., & Roger, G. (2008). good almost perfect?. Fox, D., & Gomes, C. P. (Eds.),
Proceedings Twenty-Third AAAI Conference Artificial Intelligence (AAAI 2008), pp.
944949. AAAI Press.
Helmert, M., Roger, G., & Karpas, E. (2011). Fast Downward Stone Soup: baseline building
planner portfolios. ICAPS 2011 Workshop Planning Learning, pp. 2835.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation heuristic
search. Journal Artificial Intelligence Research, 14, 253302.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic algorithm
configuration framework. Journal Artificial Intelligence Research, 36, 267306.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C.
(Ed.), Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI 2009), pp. 17281733.
Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal Artificial Intelligence
Research, 39, 51126.
Kautz, H., & Selman, B. (1992). Planning satisfiability. Neumann, B. (Ed.), Proceedings
10th European Conference Artificial Intelligence (ECAI 1992), pp. 359363. John Wiley
Sons.
Keyder, E., & Geffner, H. (2009). Soft goals compiled away. Journal Artificial Intelligence
Research, 36, 547556.
Marques-Silva, J. P., & Sakallah, K. A. (1996). GRASP - new search algorithm satisfiability.
Proceedings 1996 IEEE/ACM International Conference Computer-Aided Design
(ICCAD 1996), pp. 220227.
Minton, S. (1994). Machine Learning Methods Planning. Morgan Kaufmann Publishers Inc.
Nissim, R., Hoffmann, J., & Helmert, M. (2011). Computing perfect heuristics polynomial time:
bisimulation merge-and-shrink abstraction optimal planning. Walsh, T. (Ed.),
Proceedings 22nd International Joint Conference Artificial Intelligence (IJCAI11),
pp. 19831990. AAAI Press/IJCAI.
754

fiO NLINE PEEDUP L EARNING PTIMAL P LANNING

Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planning problems
bounded width. Journal Artificial Intelligence Research, 35, 623675.
Pearl, J. (1984). Heuristics: Intelligent Search Strategies Computer Problem Solving. AddisonWesley.
Pednault, E. P. D. (1989). ADL: Exploring middle ground STRIPS situation
calculus. Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings First
International Conference Principles Knowledge Representation Reasoning (KR
1989), pp. 324332. Morgan Kaufmann.
Rendell, L. A. (1983). new basis state-space learning systems successful implementation. Artificial Intelligence, 20(4), 369392.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: Parallel plans algorithms plan search. Artificial Intelligence, 170(1213), 10311080.
Russell, S. J., & Zilberstein, S. (1991). Composing real-time systems. Mylopoulos, J., & Reiter,
R. (Eds.), Proceedings 12th International Joint Conference Artificial Intelligence
(IJCAI 1991), pp. 212217. Morgan Kaufmann.
Schiex, T., & Verfaillie, G. (1993). Nogood recording static dynamic constraint satisfaction
problems. Journal Artificial Intelligence Research, 3, 4855.
Thayer, J. T., Dionne, A. J., & Ruml, W. (2011). Learning inadmissible heuristics search.
Bacchus, F., Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.), Proceedings TwentyFirst International Conference Automated Planning Scheduling (ICAPS 2011), pp.
250257. AAAI Press.
Utgoff, P. E., Berkman, N. C., & Clouse, J. A. (1997). Decision tree induction based efficient
tree restructuring. Machine Learning, 29(1), 544.
Webb, G. I., Boughton, J. R., & Wang, Z. (2005). naive Bayes: Aggregating one-dependence
estimators. Machine Learning, 58(1), 524.
Yoon, S., Fern, A., & Givan, R. (2007). FF-Replan: baseline probabilistic planning. Boddy,
M., Fox, M., & Thiebaux, S. (Eds.), Proceedings Seventeenth International Conference
Automated Planning Scheduling (ICAPS 2007), pp. 352359. AAAI Press.
Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge forward search planning.
Journal Machine Learning Research, 9, 683718.
Zimmerman, T., & Kambhampati, S. (2003). Learning-assisted automated planning: looking back,
taking stock, going forward. AI Magazine, 24, 7396.

755

fiJournal Artificial Intelligence Research 44 (2012) 397-421

Submitted 01/12; published 06/12

Semantic Similarity Measures Applied Ontology
Human-Like Interaction
Esperanza Albacete
Javier Calle
Elena Castro
Dolores Cuadra

EALBACET@INF.UC3M.ES
FCALLE@INF.UC3M.ES
ECASTRO@INF.UC3M.ES
DCUADRA@INF.UC3M.ES

Computer Science Department, Carlos III University,
Madrid 28911, Spain

Abstract
focus paper calculation similarity two concepts ontology
Human-Like Interaction system. order facilitate calculation, similarity function
proposed based five dimensions (sort, compositional, essential, restrictive descriptive)
constituting structure ontological knowledge. paper includes proposal computing
similarity function dimension knowledge. Later on, similarity values obtained
weighted aggregated obtain global similarity measure. order calculate weights
associated dimension, four training methods proposed. training methods
differ element fit: user, concepts pairs concepts, hybrid approach.
evaluating proposal, knowledge base fed WordNet extended using
knowledge editing toolkit (Cognos). evaluation proposal carried
comparison system responses given human test subjects, providing
measure soundness procedure revealing ways proposal may
improved.

1. Introduction
main purpose ontology human-like interaction system unify representation
concept, relating appropriate terms, well concepts
shares semantic relation. Furthermore, ontological component also able
perform certain inferential processes, calculation semantic similarity
concepts. subject similarity continues widely studied fields
literature computer science, artificial intelligence, psychology linguistics. Good similarity
measures necessary several techniques fields including information retrieval,
clustering, data-mining, sense disambiguation, ontology translation automatic schema
matching. present paper focuses study semantic similarity concepts
ontology framework natural interaction.
principal benefit gained procedure ability substitute one concept
another based calculation similarity two, given specific circumstances.
users perspective, procedure allows use synonyms (terms related single
concept) concept case user familiar original concept itself.
Moreover, semantic similarity offers possibility build explanations clarifying concept
user based similar concepts, thereby enhancing communicative effectiveness.
2012 AI Access Foundation. rights reserved.

fiALBACETE, CALLE, CASTRO & CUADRA

hand, system may also able understand previously-unknown concept,
long user able relate similar concepts previously known system.
way, system learn new concepts automatically enrich ontology improve
future interactions.
first task study develop semantic similarity measure takes account
particular ontological dimensions described earlier study (Calle, Castro & Cuadra, 2008).
approach, conceptualization comprises seven ontological dimensions: semiotic, sort,
compositional, essential, restrictive, descriptive, comparative. first three dimensions
previously applied related works, stated Section 2. Essential, restrictive
descriptive dimensions part nature concept, influence human judgment
similarity detailed Section 3. seventh one, comparative dimension, derived
previous dimensions charge calculating degree similarity
ontological concepts.
second goal present article evaluate quality mechanism developed
calculation similarities two concepts ontology specially
designed human-like interaction system (Calle F., 2004). achieve this, several
experiments designed performed here. experiments
consequent evaluation semantic similarity measure carried out, however,
necessary implement similarity dimensions defined conceptual model feed
database large number concepts.
briefly outline content follows paper, Section 2 reviews literature
similarity measures ontologies methods available evaluation. Section 3,
approach similarity measures applied ontological model based several dimensions
proposed. Section 4, detailed explanation provided experiments designed test
proposal, well results obtained execution. Section 5 discusses limitations
encountered study. Finally, Section 6 presents conclusions future research.

2. Related Work
present section paper two main objectives. First, aims provide overview
different types approaches available comparison concepts ontologies and,
doing, identify foundations desired similarity measure may modeled,
taking account seven dimensions described previous study (Calle et al., 2008).
Secondly, aims select best way evaluate results yielded desired similarity
measure according studies regarding similarity metrics assessment.
Basically two types methods exist comparison terms graph-based ontology:
edge-based methods using graph edges types data source node-based methods
using graph nodes properties main data source. simplest intuitive
similarity measure, former method based mainly counting number edges
path two terms graph (Rada, Mili, Bicknell & Blettner, 1989). Within edgebased method, two general approaches exist: firstly, distance approach selects either
shortest path average paths (when one path exists) secondly common
398

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

path approach calculates similarity directly length path lowest common
ancestor two terms root node (Wu & Palmer, 1994). past years,
variety edge-based methods defined (Resnik, 1995; Leacock & Chodorow, 1998).
edge-based methods grounded two basic assumptions: firstly, nodes links
uniformly distributed ontology, is, terms depth
specificity (Budanitsky, 1999) and, secondly, edges level ontology indicate
semantic distance terms. However, suppositions rarely true
majority ontologies. reason, several strategies proposed response
fact. One example strategy weighting edges according hierarchical
depth use node density link type (Richardson, Smeaton & Murphy, 1994).
Nevertheless, strategies solve aforementioned problems due fact terms
depth necessarily specificity edges level
necessarily represent semantic distance.
second, node-based, method relies comparison properties terms
involved related terms themselves, ancestors descendants.
commonly used concept methods information content (IC), providing measure
specific informative term is. IC term c quantified negative
log-likelihood, IC = -log p(c), p(c) probability occurrence c specific
corpus, generally estimated annotation frequency. Another approach employed
obtain IC based number children term ontological structure (Seco,
Veale & Hayes, 2004). concept IC applied common ancestors two terms
order quantify information share and, thereby, measure semantic similarity.
way, two main approaches exist. first informative common ancestor (MICA)
technique common ancestor highest IC considered (Resnik, 1995).
second disjoint common ancestor (DCA) technique disjoint common
ancestors considered (the common ancestors subsume common
ancestor). one definition (Lin, 1998), similarity two concepts using node-based
method expressed ratio amount information needed state
commonality two concepts information needed fully describe them.
Moreover, similarity measure hierarchical ontologies called ontology structure-based
similarity (OSS) also defined (Schickel-Zuber, 2007) whose major ingredient
computation a-priori score concept c, (APS(c)), shares similarities IC
(i.e., calculated topology structure ontology reflecting
information contained within concepts).
Additionally, several hybrid methods also defined attempt improve
results techniques defined above. work Jiang Conrath, (1997), example,
combined model defined derived edge-based notion adding information
content decision factor. link strength two concepts defined difference
information content them.
aim collecting different methods approaches, SimPack, generic Java
library similarity measures use ontologies, created (Bernstein, Kaufmann,
399

fiALBACETE, CALLE, CASTRO & CUADRA

Kiefer & Brki, 2005) includes implementation ontology-based similarity methods
(including edge-based node-based measures). important note majority
techniques described define semantic similarity concepts applied
hierarchical ontologies whose structure takes account one two dimensions
graph. example, WordNet (Fellbaum, 1998) consists ontological graph
100,000 concepts whose edges model is_a part_of relationships. Perl module
(Pedersen, Patwardhan & Michelizzi, 2004) implemented lexical database
variety semantic similarity measures. Another example application Gene Ontology
(Department Genetics, Stanford University School Medicine, California, USA., 2000), one
important ontologies within bioinformatics community, 20,000 concepts
modeling is_a part_of relationships graph. Thus, none
techniques described section supposed appropriate dealing
two dimensions similarity, nevertheless useful attempt define
dimensions present studys ontological model.
second aim present section review assessment techniques ontological
similarity functions used earlier studies. gold standard established majority
experimental evaluations similarity (Resnik, 1999; Jiang & Conrath, 1997; Altintas, Karsligil,
& Coskun, 2005; Schickel-Zuber, 2007; Bernstein et al., 2005) based experiment
described Miller Charles study (1991) become benchmark determining
similarity words natural language processing research. experiment relies
similarity assessments made 38 university students provided 30 name pairs chosen
priori cover high, intermediate low levels similarity asked assess
similarity meaning scale 0 (no similarity) 4 (perfect synonymy). average
scored values represents good estimation degree similarity two terms.
certain evaluations based human judgment (Inkpen, 2007; Bernstein et al., 2005),
variations number participants way administer questionnaire
introduced. one studies (Bernstein et al., 2005), website containing survey tool
designed perform evaluation. Web experiment, subjects asked assess
similarity 73 pairs concepts scale 1 (no similarity) 5 (identical). Finally,
subjects also given possibility adding comments assessment. evaluate
quality similarity measures, results compared test subjects assessments
using corrected Spearman rank correlation coefficient.
concluded human reasoning one widely-used methods
comparison performing validation similarity measure. reason,
methodology also used experimentation section present study. Since
difficult run user-based evaluation complicated ontologies, example, Gene
Ontology (Lord, Stevens, Brass & Goble, 2003), deemed necessary find
model ontology elements test subjects could understand. Therefore,
ontological module implemented, must populated sufficiently good coverage
domain knowledge, is, enough knowledge meet system requirements.

400

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

3. Theoretical Approach
conceptual model grounding present study (Calle et al., 2008) distributes ontological
knowledge seven different dimensions. semiotic dimension represents relationship
concepts, terms language. example, shown Figure 1, concept
WordNets synset 3082979 corresponds machine able perform calculations
automatically, one terms associated concept computer. terms
related concept computing machine, computing device, data processor,
electronic computer information processing system, also linked concept
corresponds English language (synset 6947032).

Figure 1: Example semiotic dimension representation

sort dimension represents is_a relationship concepts, relates concept
concepts models polytree structure. instance, shown Figure 2, terms
node, server web site related concepts instances computer.

Figure 2: Sort dimension example

essential dimension represents general taxonomy concepts. taxonomy
located nodes top polytree represented sort dimension. Therefore,
relations included design already observed sort dimension. since
organize knowledge higher abstraction level (they discriminative)
taken account separately, adding extra value similarity measure.
design crucial attaining good similarity measures, determines usefulness
dimension. essential dimension WordNet (Princeton Univ., 2011), example,
classifies concepts four main linguistic categories (verb, noun, adjective, adverb).
approach adequate linguistic interaction domain, may weaker general
interaction domain. proposal includes essential design inspired previous (Calle et al.,
2008) related works (Gee, 1999; Miller, 1995) refined preliminary
experimentation. design departs three main categories (abstract, actions entities)
develops main classes concepts, shown Figure 3. Finally, added
proposal aimed general interaction domains, could improved suited specific
domains particular interaction systems.

401

fiALBACETE, CALLE, CASTRO & CUADRA

concept
[05835747]

.

.

abstract

action

entity

[05854150]

[06320569]

[00001740]

attribute

circumstance

sui generis

[00024264]

[14512817]

[90000001]

place

time

role

language

[08513718]

[00028270]

[00722061]

[06282651]

activity

environment

[00407535]

[08567235]

.

domain

.

interactive

static

active

[01946439]

[01564315]

[00524481]

[05999266]

unidirectional
comm. agent

communicative
agent

[90000002]

[02956371]

human

mechanical

[02743391]

[02891236]

user

Interaction
system

[10741590]

reactive

cyclic

[02105176]

[00675701]

[05661996]

Figure 3: Essential dimension taxonomy

compositional dimension represents part-whole relationship concepts.
way, concept relationships collection concepts part it.
Figure 4 shows concepts part computer, example hard disk,
RAM ALU.
computer
[03082979]

hard disk

RAM

ALU

[03492542]

[04052757]

[02995345]



Figure 4: Compositional dimension example

restrictive dimension shown Figure 5 describes compatibility concepts
related action rest. example, action compute related
concepts computer, calculator laptop, among others.

402

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

computer
[03082979]

Action concept:
compute

calculator
[02938886]

[00637259]

laptop
[03642806]

Figure 5: Restrictive dimension example

descriptive dimension shown Figure 6 charge relationships three
kinds concepts: generic concept (entity, abstract entity action), attribute likely
characterize concept, domain (of values) attribute defined. Notice
could several available domains given attribute, domain could
numeric (magnitudes regarding unit) enumerated (a concept composed set
named values also concepts). example, instance generic concept hard
disk value numeric domain information bytes attribute concept
storage capacity.
Generic concept:
hard disk

Attribute concept:
storage capacity

Domain concept:
Information bytes

[03492542]

[13562133]

[13626013]

Figure 6: Descriptive dimension example

Finally, comparative dimension derived previous dimensions responsible
calculating real time degree similarity ontological concepts. paper,
fact, focuses precisely similarity calculation. Finally, reasons efficiency,
frequently requested similarities buffered, is, stored calculated, periodically
updated retrieved necessary.

4. Proposal
paper proposes evaluates similarity measure based combination individual
similarity measures according dimensions explained (see Section 3).
combination produced training across numerous observations affect weight
dimension contributes final decision. Training performed according
different criteria. one hand, different human subjects support judgments different
combinations dimensions. hand, nature concept determines
relevant dimension comparison. example, comparing concept scanner
concept printer, sort dimension could influential, since types
computer peripherals; however restrictive dimension could influential
related different actions. opposite may happen concepts teacher tutorial

403

fiALBACETE, CALLE, CASTRO & CUADRA

related similar actions according restrictive dimension,
teaching, sort dimension little influence case.
following step describe similarity measure adapted described ontological
dimensions except semiotic dimension. Yet approach, similarity
semiotic dimension, similarity terms frequently described edit distance
Levenshtein distance (1966), is, number changes necessary turn one string
another string. decision leave dimension apart supported preliminary studies
measure yields average error rate 50% cases 80%.
Furthermore, every concept study, accuracy provided dimension lower
dimensions (the semiotic dimension never produced best
prediction), dimension never ranked first tested separately.
reason, estimated cannot contribute positively results (at least, cannot
properly adapted). Last least, preliminary experimentation training including
dimension, observed weight tended zero, drawback
slowing convergence weights rest dimensions. However, work,
evolution similarity measure (supported knowledge dimension)
incorporated global measure similarity.
4.1 Inference Mechanisms
sub-section describes method used calculate degree similarity two
given concepts ontology. Since ontological knowledge structured different
dimensions, similarity measure also based dimensions. Therefore, partial
similarity calculations made sort, essential, compositional, restrictive
description dimensions described previously. resulting overall similarity two
concepts obtained calculation weighted average five partial similarities

Ss, Sc, Se, Sr Sd similarity measures according sort, compositional,
essential, restrictive description dimensions, respectively. values w1, w2, w3, w4 w5
represent weights assigned dimension resulting total similarity
two concepts value 0 (completely different concepts) 1 (the two
concepts same).
following sections describe detail procedures developed calculation
partial similarities.
4.1.1 SIMILARITY ACCORDING SORT DIMENSION
sort dimension represents is_a relationship concepts. dimension
polytree structure, allowing concept descendant one concept. Similarity
dimension often calculated proportional intersection list predecessors
404

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

compared concepts regarding total size lists. define measure, variation
edge-counting technique concretely, conceptual similarity measure defined
work Wu Palmer (1994) employed. Given two concepts, C1 C2,
measure defined

N1 N2 number ancestors C1 C2, N3 number common
ancestors C1 C2 (in advantageous tree several found polytree).
4.1.2 SIMILARITY ACCORDING COMPOSITIONAL DIMENSION
compositional dimension represents part-whole relationship concepts.
reason, appropriate way calculate similarity two concepts based
dimension comparison parts (or ingredients) concepts. Furthermore,
calculation must also take account fact concept may consist required
optional concepts. detail important calculating similarity since greater weight must
given required ingredients appearing concepts, lower weight given
optional ingredients. resulting similarity two concepts, C1 C2, terms
compositional dimension obtained applying formula:

N1 number common components arising intersection
components concept C1 components concept C2 type required; N2
number common components arising intersection components C2
required components C1; N3 number required components C1 C2
common; N4 total number common components (both required optional)
two concepts; M1 M2 represent number required components concepts C1
C2, respectively. Finally, M3 M4 indicate total number components C1 C2 have.
4.1.3 SIMILARITY ACCORDING ESSENTIAL DIMENSION
essential dimension contains set abstract concepts define generic types
concepts (such action, entity, abstract, circumstance attribute). generic classification
frequently influences human speakers estimating similarity. works similarity
calculation posed concepts comparable included category
WordNets taxonomy (RiTa.WordNet, 2008). approach endows critical value
dimension, omitting rest classification. proposed
dimension contribute similarity estimation (albeit certain weight
could different rest), concepts observed design essential
dimension may influence similarity estimation.

405

fiALBACETE, CALLE, CASTRO & CUADRA

method calculating similarity two concepts C1 C2 essential
dimension based intersection essential ancestors (ancestors within subset
essential concepts). formalized follows:

Card(E1) Card(E2) are, respectively, total number essential ancestors
concepts C1 C2, Card(E1 E2) indicates number common essential ancestors.
4.1.4 SIMILARITY ACCORDING RESTRICTIVE DIMENSION
restrictive dimension defined concept representing action another
concept representing entity. Similarity dimension calculated different way
depending type concepts compared. reason, two different similarity
measures exist dimension: comparing two actions comparing two entities. Similarity
two concepts representing entity based action concepts
entities common. formula used calculation similarity comparing
two entities, C1 C2, defined

M1 M2 number common actions positive negative
restrictive relationship entities C1 C2, respectively. values N1, N2, N3 N4
represent, respectively, total number actions positive relationship entity
C1, negative relationship C1, positive relationship entity C2, negative
relationship C2.
regards similarity two concepts representing action, calculated based
set concepts defined actions, similar higher number
restricted concepts common. formula calculate similarity two action
concepts (C1, C2) particular sign (positive negative) defined

N3 number common entities shared two actions, N1 N2
total number entities restrictive relationship C1 C2, respectively.
4.1.5 SIMILARITY ACCORDING DESCRIPTIVE DIMENSION
description dimension represents relationship concept, attribute value
concrete domain. Similarity dimension calculated differently depending type
concepts compared, is, entities, attributes domains. pairs concepts (C1, C2)
representing entity, applicable formula defined

406

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

N1 number common attributes without default value assigned, N2
number common attributes whose value entities assigned
default, N3 number common attributes value one
assigned default. terms M1 M2 correspond total number attributes
related concepts C1 C2, respectively.
concepts (C1, C2) attributes, formula apply defined

N3 number common values attributes, N1, N2 total number
possible values attributes C1 C2, respectively.
Finally, concepts compared (C1, C2) represent domains, similarity according
dimension calculated based amount common attributes (for domains
apply) number values shared domains.

N3 number common attributes shared domains (C1, C2), N1, N2
total number attributes associated them. Finally, M3 number common values
defined domains, M1, M2 total number values two domains.
Finally, concepts compared (C1, C2) may values belonging domain, either
enumerated numeric type. operating domains, necessary define previously
correspondence them. Numeric domains related function (typically,
lineal proportion). Relating enumerated domain numeric domain achieved
assigning enumerated value fuzzy label numeric domain. Finally,
correspondence two enumerated domains always involves intermediate numeric
domain (with correspondence defined two domains). values
comparable, formula measure similarity defined follows:

Cinf Csup are, respectively, lower limit upper limit within range
values, C1 C2 correspondent numeric comparable values.
4.2 Preliminary Experimentation
testing proposal, preliminary experiments performed refine
obtain first perspective validity. experiments instructed set
similarity measures obtained total 20 pairs concepts evaluated 17 human subjects.
dataset described Section 5.1.
407

fiALBACETE, CALLE, CASTRO & CUADRA

Specifically, individual influence dimension similarity tested thorough set
experiments involving separately. Since combination them,
need training either. Figure 7 shows box plot represents error measures produced
individually dimension.
100

Error (%)

80
60
40
20
0
Sort

Compositional

Essential

Restrictive

Descriptive

Figure 7: Performance isolated dimensions Ontology

Figure 8 shows series twenty pairs, every dimension produced better prediction
others least once. fact, essential dimension provided best response almost half
cases, descriptive dimension best one case.
Restrictive
10%

Descriptive
5%

Sort
30%

Compositiona
l
15%

Essential
40%

Figure 8: Cases dimension ranked first

fact lead conclusion essential design appropriate,
descriptive dimension weak. analysis found latter lacked sufficient
knowledge, improved line evaluation (more knowledge added).
Despite improvement, since analysis introduction knowledge performed
manually (in contrast dimensions, knowledge obtained WordNet),
could still enhanced would improve individual results dimension. Besides,
result definitive, since weights may different interaction domains,
volume knowledge base important too. useful consequence one
408

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

five ontological dimensions contribute similarity function, supporting
hypothesis adequate combination may yield better results
individual approaches.
4.3 Weights Training Methods
Assigning proper weight dimension crucial achieving good results. Since
human test subject usually give relevance five dimensions similarity,
basic training program regarding weights associated dimension developed.
program based reinforcement learning technique (specifically variant Q learning
algorithm) implemented order determine, several iterations,
appropriate value weights applied dimension (previously defined Section 4.1)
minimize error formula result human judgment. Therefore, input
training algorithm set similarity judgments made human test subjects.
algorithm follows next steps:
a) initial step, five weights w1, w2, w3, w4 w5 applied dimension
(see formula Section 4.1) initialized 1.
b) iteration training algorithm, results dimension similarity
calculated according formulas described Sections 4.1.1 4.1.5.
Subsequently, five new weights calculated according next criteria:
1.
2.
3. Failure meet conditions 1) 2),
parameter ranged 1 5 (one dimension),
represents individual score represents similarity value 0 10 one
pair concepts scored one participant.
stands increase
weight (for dimension i) current iteration,
represents increase
previous iteration. max(Simi) min(Simi) represent maximum
minimum similarity individual values, respectively. Finally, stands learning rate.
training focused different points view, tested evaluated.
Firstly, pair-oriented training implemented order individually adjust weights
20 concept pairs, independently specific user. weights adjusted
individually pairs concepts, taking one user per iteration. way,
iteration, new array refined weights obtained used evaluating similarity.
test consists calculating similarity (with array weights) comparing
human assessment.
Since degree significance assigned dimension may depend subjectivity
testers, particular interest make adjustment weights based user.
409

fiALBACETE, CALLE, CASTRO & CUADRA

experiment, training weights performed user consisted
20 iterations (one pair concepts). iteration training algorithm, absolute
error committed relation corresponding pair calculated. running training
17 users, average absolute errors iterations calculated.
third method designed order address shortcomings pair-oriented
training. indicated storing array weights possible pair
concepts medium sized ontology requires unusually extensive physical resources. Besides,
significant coverage thus defined knowledge would require far much training. short,
realistic develop method high number combinations concepts.
However, preliminary experimentation checked weights applied pair
also likely applied combinations two concepts. Therefore,
new training method (feature-oriented) proposed slightly modifying pair-oriented one.
feature-oriented method, array weights stored concept instead
pair concepts (which solve problems storage extent training). time
one concept compared other, array weights reviewed refined.
similarity calculation given pair based aggregation arrays concepts.
Finally, observed method showed different behavior depending pair
concepts compared: method achieving worst results average also best
specific pairs. Subsequently, hybrid method proposed developed,
combining feature-oriented user-oriented trainings, aiming profit advantages
method. training similar focused user, iteration
array weights refined different degree, taking account array stored
particular concept. Therefore, particular dimension usually relevant concept,
adaptation user dimension strengthened.

5. Evaluation
conceptual model ontology defined, weights training methods
proposed, next step study evaluate proposal. present section describes
experiments run evaluating proposal, design results obtained
discussion. knowledge base supported relational database management system
Oracle 11g, logic ontology component (including inference mechanisms)
implemented Java. knowledge bases designed satisfy specific purposes within
research project. initial knowledge load obtained large lexical database
WordNet (Fellbaum, 1998) including existing concepts (synsets), terms relationships
(corresponding sort compositional dimensions). Since proposed ontological model
defines relationships concepts (essential, restrictive descriptive), necessary
add knowledge. Cognos.Onto tool enables knowledge edition management
specific model. tool belongs larger toolkit, Cognos (Calle et al., 2011) already used
several research projects. toolkit seeks ease interaction corpus analysis, annotation,
implementation management, diverse yet integrated tools aimed specific type
knowledge (pragmatic, NLP related, ontological etc.).
410

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

5.1 Experimental Design Preparation
First all, necessary choose Interaction Domain define entire
experiment. concepts involved subset whole knowledge base, restricted
specific domain. participants chosen order constitute good coverage
focused domain. Finally, additional knowledge fed experts interaction domain
related projects research framed (as test subjects
participant experiments).
methodology chosen evaluate proposed similarity measure based Millers
benchmark (Miller & Charles, 1991). Experiments designed determine whether
result attained application similarity function pair concepts reliable
or, words, result falls within acceptable range compared similarity
judgments made human test subjects.
begin experimental phase study, initial loading concepts must first made
proposed ontology. reason, WordNets synsets (Princeton Univ., 2011) taken
concepts, together corresponding semiotics, sort compositional relationships.
Knowledge domain experts responsible populating remaining dimensions
ontological model (i.e., essential, restrictive descriptive) subset 350 concepts,
selected relevance interaction domain.
chosen domain labeled computer science teaching interaction domain within
Spanish academic socio-cultural environment. area knowledge familiar test
subjects selected heterogeneous domain (different roles, ages,
genders). perform evaluation, test designed test subject rate
similarity pairs concepts. set pairs meet basic criterion: least two
pairs included explore proposed dimensions, one clear incidence
dimension another one without (or little impact).
total number twenty-one test subjects available, four outliers left
apart. discarded checking judgment responses
uniform rest sample. participant scores follow normal distribution
removing outliers. reason, sample size calculated test statistical
significance result least ten subjects ensure 99% confidence. Therefore,
sample size seventeen participants sufficient ensure data representative.The
seventeen subjects experts interaction domain (technical education), specifically
five technical students, seven researchers five lecturers. ages ranged 20 50
distributed follows: seven subjects 20-30 year-old range, six 30-40
year-old range remaining four 40-50 year-old range. regard gender,
slightly half female (9) rest male (8). chosen interaction
domain applied research project THUBAN (TIN2008-02711). participant
provided test containing set twenty pairs concepts domain. Since
observations follow normal distribution, determined minimum significant sample
size would sixteen 99% confidence. Therefore, set twenty pairs concepts provides
significant results. However, larger domain, size dataset may different attain
411

fiALBACETE, CALLE, CASTRO & CUADRA

statistically significant results. coherence components system
proposal integrated, similarity measures ranged zero (no similarity) ten
(absolutely identical, concept). addition, pairs, subjects asked
justify score, indicating specific parameters similarity took account
making decision.After obtaining individual survey results, average total human
assessments pair concepts calculated.Table 1 shows 20 pairs concepts
included test right pair, range (difference maximum
minimum scores), standard deviation average rating assigned users.
Pair ID

Pair concepts

Range

Standard
deviation

Average
similarity

0

Reading lamp Personal computer

6

1.76

2.71

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

Laptop Server computer
Teacher Tutorial
Meeting room Laboratory
Server computer Microwave
Office Laboratory
Screen Blackboard
Stapler Folder
Plug Power strip
Office Meeting room
Pencil CD marker
Associate professor Teaching Assistant
Associate professor Bachelor
write papers program
give lecture teach
Keyboard Mouse
Fridge Microwave
Hard disk drive Pendrive
Scanner Printer
Poster Blackboard

6
7
8
8
9
7
7
4
6
3
5
8
7
6
5
7
3
8
6

1.62
1.92
2.15
2.02
2.25
1.83
2.19
1.21
1.69
0.99
1.34
2.53
2.15
1.60
1.41
1.77
0.94
1.89
1.82

6.47
5.06
4.35
2.24
5.76
6.12
3.94
8.29
6.29
7.29
8.06
5.18
4.53
7.76
7.35
5.35
8.47
5.94
4.24

Table 1: Pairs concepts average similarity

methods subject iteration order (either analyzed pair human judge),
alter result training. order avoid effect endow significance
results, preliminary experiments minimum number repetitions (with different
order) determined reduce stochastic gain significance (close 275), consequently
decided program 300 repetitions different order method. graphs
tables, error rates pairs (identified pair_id) numbered 0 19, iterations
numbered 1 20.
5.2 Experiments
section presents results obtained execution experiments corresponding
four weight adjustment algorithms described Section 4.3. experiments
412

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

performed subset ontological knowledge stored acquired computer science
teaching domain. first experiment performed pair-oriented training and, order
evaluate results training, average absolute error calculated (for pair)
similarity based human judgment result obtained applying
similarity measure proposed according following formula:

corresponds index iterate human judge specific pair
concepts n number test subjects. Finally, errorpairId represents absolute error
human judgment pair result obtained training algorithm
iteration. Table 2 shows absolute errors calculated experiment pair
concepts, well average error which, 18.5% comes slightly closer scores
provided human subjects.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 15.2 14.8 38.3 18.6 19.4 18.1 17.6 18.8 20.2 15.4 13.4 18.0 22.5 19.6 15.2 13.0 15.3 20.9 17.1 19.0 18.5

Table 2: Pair-oriented training error rate

noted eleven cases, error rate less average, eight cases
error rate around average, one pair (#2) shows excessive error rate requires
analysis discussion (see subsection 5.3). Figure 9 shows comparison trend
lines regarding error rate accumulated pair-oriented training algorithm
accumulated error similarity function without weights training.

Figure 9: Accumulated average error pair-oriented training

second place, absolute error obtained pair feature-oriented training
shown Table 3. results, compared obtained pair-oriented training,
show slightly worse performance (with mean error rate 20,2%). However,
recalled method advantages (realistic storage training extent).
413

fiALBACETE, CALLE, CASTRO & CUADRA

Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 15.0 14.9 38.2 18.4 30.3 22.7 17.5 18.5 20.1 21.6 13.4 24.9 21.2 19.2 15.2 13.0 14.4 20.6 16.8 25.4 20.2

Table 3: Feature-oriented training error rate

third experiment executed user-oriented training. order evaluate results
experiment, average absolute error calculated (for human judge)
similarity based human judgment 20 pairs concepts result
obtained applying similarity measure proposed. way, error average
calculated follows:

corresponds index iterate pair concepts specific user, n
number pairs concepts errorpairId represents absolute error human
judgment pair result training algorithm iteration.
case, average error rate achieved 23.9%, even worse featureoriented training. absolute error rate obtained iteration shown Table 4.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 18.6 14.1 40.7 17.9 30.8 16.8 22.9 17.5 37.1 17.1 34.6 35.8 24.3 21.5 31.2 13.6 13.9 27.4 22.3 20.8 23.9

Table 4: User-oriented training error rate

Figure 10 shows comparison trend lines correspondent error rate accumulated
user-oriented training algorithm accumulated error without weight training.
observed, user-oriented training trend line follows downward curve 20
iterations reaches error rate 23.9%. Comparing trend lines, concluded
training decreases accumulated error adapts calculated similarities subjects
judgments, yet would desirable improve adaptation (since still far featureoriented training).

Figure 10: Accumulated average error user-oriented training

414

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

observed, user-oriented feature-oriented training methods able
improve similarities calculation, becoming noteworthy approaches. Consequently,
found interest explore method combines them. new hybrid method
departs user-oriented approach, takes account weights vector obtained
feature-oriented training described section 4.3. shown Table 5, user error rate
successfully reduced 21.2% respect user-oriented training. However,
method degrades performance achieved feature alone method.
Pair Id
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

AVG

error (%) 16.0 14.3 39.0 16.9 29.4 17.3 22.2 17.4 25.1 18.5 21.5 29.6 22.0 19.9 22.8 13.2 13.1 23.8 19.2 22.8 21.2

Table 5: User-feature hybrid training error rate

5.3 Discussion Results Obtained
Among results, concept pair 2 (teacher-tutorial) scored error rate 38%
average similarity assigned users (see Table 1) 5.06. latter value significantly high
considering fact first concept refers person second static entity.
Reviewing participant responses question, however, understood test subjects
gave higher score sole feature concepts common, activity teaching.
Analyzing results outlier, appears algorithm tendency gradually
increase weight restrictive dimension, longer training necessary adapt
weight vector relevant dimension restrictive one. Using training algorithm
faster convergence would ensure good result pair, could adversely affect
results. However, convergence guaranteed larger number users.
Figure 11 shows comparison absolute error obtained four experiments
performed work (pair-oriented, user-oriented, feature-oriented hybrid trainings)
pair, also average results method. first experiment performed, pairoriented training, achieves best average error rate, 18.5%, although pair
mentioned error exceeded 38%. However, experiment major limitation:
trained weight vector pair concepts possible cannot stored due large number
combinations existing concepts ontology. shortcoming mitigated
development feature-oriented training, achieving error rate 20.2%, figure
slightly worse pair-oriented training error. Nevertheless, result
fully reflect impact training test pairs include concepts appear
experiment. calculation average error restricted pairs
concepts repeated one pair, error amounts 22.8%.
case, experiment important advantage since implementation realistic
applied large ontologies.
user-oriented training aimed adapting weights subject order
confirm assumption every test subject assigns value dimensions.
Although error rate achieved (23.9%) satisfactory either pair feature415

fiALBACETE, CALLE, CASTRO & CUADRA

oriented trainings, figure included sub-section 5.2 training shows decreasing
trend line which, compared trend line without training, allows conclusion
user-oriented experiment able adapt individual judgment. reason,
improvement attempted user-training result combination
feature-oriented experiment.

Figure 11: Comparison experiment results

hybrid training detailed Section 5.2 achieved 21.2% error rate, reduces
user-oriented training, balances performance user-oriented method
(reduces standard deviation). Taking account feature-oriented training method depends
experience features knowledge base might lack experience,
response obtained could satisfactory cases. fact, calculating error
produced feature-oriented method dataset (not restricted repeated pairs)
result amounted 22.8%. sum, feature-oriented method provides better results
enough knowledge available. last results presented Figure 11 concern experiment
observing sort dimension (which frequent method calculating similarities).
average error rate 24.1%, higher four methods discussed.
addition, observed error rate experiment is, several cases, far
average error. Figure 12 shows boxplot comparing performance four training methods
proposed sort dimension formula.
416

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

100

Error (%)

80
60
40
20
0
Pair

Feature

User

Hybrid

Sort

Figure 12: Performance training method

seen, regarding error predictions, sort dimension obtains higher
maximum (although also lower minimum), higher median (except user training) higher
deviation rest. graph, concluded error rate achieved
sort dimension method (used previous studies similarity) greater error rate
achieved feature training method. order check statistically, null hypothesis
formulated (the average error methods) also alternative hypothesis, (the
average error feature-oriented method lower sort dimension method error).
measure discrepancy calculated sample twenty measures error (one per
pair) result (-1.78) found outside acceptance range (-1.64, +), therefore
null hypothesis rejected alternative accepted significance level 0.05.
Consequently, considered true error shown feature-oriented method lower
error produced sort dimension method.
Finally, Figure 13 shows average final weights four experiments. shows
relevance taken experiments dimension, yet cannot extrapolated
interaction domains. dependent set pairs chosen experiment, results
show five dimensions taken account, diverse weights.
Descriptive
14%

Sort 26%

Restrictive
12%

Compositional
22%

Essential 26%

Figure 13: Average weights ontological dimensions

417

fiALBACETE, CALLE, CASTRO & CUADRA

6. Conclusions Perspective Future Research
paper defines similarity measure multi-dimensional knowledge model ontology
type, specifically ontology aimed supporting Human-Like Interaction. proposed
measure based five dimensions ontological knowledge: sort, compositional, essential,
restrictive descriptive. five weighted aggregated order obtain
global similarity measure. equations applied dimension general used
ontologies observe dimensions, yet observing
aggregating similarity result proposed enhanced accuracy.
solution presents another challenge, form weights calculation. fact,
person decides similarity concepts unwittingly makes dimensions
prevail others. criteria may diverse, work focused studying
dependence weights nature concepts, either pairs (pair training method)
individually (feature training method), described Section 4.3. work also explores
influence past behavior users perform concept pair evaluations (and
ultimately, user owns device usually interacts it). Following line, userdependent training proposed, finally hybrid one (merging feature user benefits)
included too. evaluated compared order ascertain one
performs better, obtaining best results pair-oriented training.
order evaluate performance proposed similarity measure, results
recorded compared taken human test subjects. evaluation technique
applied several studies similarity measures considered gold standard.
experimental phase, four training algorithms developed according different
perspectives. Thus, phase included pair-oriented, feature-oriented, user-oriented
hybrid experiment. every case, error rate calculated respect human subject
assessments. best results corresponded pair-oriented method achieved error
rate 18.5%. Since implementation experiment realistic large ontologies,
feature-oriented experiment required despite slightly worsening results previous
experiment, concretely, producing error rate 20.2%. However, feature-oriented
experiment big advantage able applied easily large ontologies.
Moreover, user-oriented training aimed adapt weights subject order
confirm assumption every test subject assigns value dimensions.
experiment highest error rate algorithms (23.9%), demonstrated,
error rate follows decreasing trend line while, training done, error rate follows
asymptotic tendency. addition this, experiment shows slightly better results
taking account sort dimension (which average error rate 24.1%
maximum 60.4%). reason, concluded user-oriented experiment able
adapt individual judgment (although adaptation slow). Finally, hybrid
experiment combines feature-oriented user-oriented training and, error rate
21.2%, nevertheless manages reduce error user-oriented training, well
balancing error atypical cases common rest experiments.

418

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

Since hybrid experiment manages balance results experiments,
currently, improved hybrid algorithm developed. algorithm calculation
weights iteration affected depending error produced feature
experiment pair concepts corresponding iteration.
performance training methods proposed closely related available extent
knowledge. reason, authors also currently working mechanisms increasing
quality completeness ontological knowledge. manual acquisition new
knowledge expert requires great deal resources would desirable develop
advanced mechanism learn new concepts relations. challenge attain
knowledge acquisition human-like interaction human subjects. Therefore,
lifetime system, knowledge bases would enriched interacting users.
Finally, refinement similarities formulation also interesting line work, especially
semiotic dimension reintroducing influence global similarity calculation.

Acknowledgments
development approach construction part LaBDA-Interactor HumanLike Interaction System, part research projects SemAnts (TSI-020110-2009-419)
THUBAN (TIN2008-02711) CADOOH (TSI-020302-2011-21), supported Spanish
Ministry Industry, Tourism Commerce Spanish Ministry Education,
respectively. Besides, knowledge bases populated using COGNOS toolkit developed
research project MA2VICMR (S2009/TIC-1542) supported Regional
Government Madrid.

References
Altintas, E., Karsligil, E., & Coskun, V. (2005). new semantic similarity measure evaluated
word sense disambiguation. Procs. 15th NODALIDA conference. Joensuu.
Bernstein, A., Kaufmann, E., Kiefer, C., & Brki, C. (2005). SimPack: Generic Java Library
Similarity Measures Ontologies. Zurich: Technical report.
Budanitsky, A. (1999). Lexical semantic relatedness application natural language
processing. University Toronto. Technical report.
Calle, F. (2004). Interaccin Natural mediante procesamiento intencional: Modelo de Hilos en
dilogos. Thesis, (PhD). Politecnic University Madrid.
Calle, F. J., Albacete, E., Snchez, E., del Valle, D., Rivero, J., & Cuadra, D. (2009). Cognos:
Natural Interaction Knowledge Management Toolkit. International Conference
Applications Natural Language Information Systems (NLDB 2009) (pp. 303-304).
Saarbrken, Germany: Lecture Notes Computer Science.
Calle, F., Castro, E., & Cuadra, D. (2008). Ontological dimensions applied Natural Interaction.
Procs. First International Workshop Ontologies Interactive Systems , 91-96 .

419

fiALBACETE, CALLE, CASTRO & CUADRA

Department Genetics, Stanford University School Medicine, California, USA. (2000). Gene
ontology: tool unification biology. Gene Ontology Consortium. Nature
genetics Vol. 25, No. 1. , 25-29.
Fellbaum, C. (1998). WordNet: Electronic Lexical Database. Cambridge, UK: MIT Press.
Gee, J.P. (1999). Introduction Discourse Analysis. Routledge.
Inkpen, D. (2007). Semantic similarity knowledge applications. STUDIA UNIV. BABESBOLYAI, INFORMATICA, Volume LII, , 11-22.
Jiang, J. J., & Conrath, D. W. (1997). Semantic Similarity Based Corpus Statistics Lexical
Taxonomy. International Conference Research Computational Linguistics. Taiwan.
COGNOS Toolkit. (2011). Retrieved July 2011,
http://labda.inf.uc3m.es/doku.php?id=es:labda_lineas:cognos
RiTa.WordNet: WordNet library Java/Processing. (2008). [Online]. Available:
http://www.rednoise.org/rita/wordnet/documentation/
Leacock, C., & Chodorow, M. (1998). Combining Local Context WordNet Similarity
Word Sense Identification. Electronic Lexical Database , 265-283.
Levenshtein, V. I. (1966). Binary codes capable correcting deletions, insertions reversals.
Soviet Physics Doklady vol 10 , 707-710.
Lin, D. (1998). Information-Theoretic Definition Similarity. Proceedings 15th
International Conf. Machine Learning, (pp. 296-304). Madison, Wisconsin USA.
Lord, P. W., Stevens, R. D., Brass, A., & Goble, C. A. (2003). Investigating semantic similarity
measures across Gene Ontology: relationship sequence annotation.
Bioinformatics , 1275-1283.
Miller, G. A., & Charles, W. G. (1991). Contextual correlates semantic similarity. Language
Cognitive Processes , 1-28.
Miller, G. A. (1995). WordNet: Lexical Database English. Communications ACM vol
38 ,No. 11: 39-41.
Pedersen, T., Patwardhan, S., & Michelizzi, J. (2004). WordNet:: Similarity measuring
relatedness concepts. Demonstration Papers HLT-NAACL 2004 (pp. 38-41). Boston,
Massachusetts, USA: Association Computational Linguistics
Princeton Univ. (February 3, 2011). WordNet: lexical database English. Obtenido de
WordNet: lexical database English: http://wordnet.princeton.edu/
Rada, R., Mili, H., Bicknell, E., & Blettner, M. (1989). Development application metric
semantic nets. IEEE Trans. Systems, Man, Cybernetics. 19. , 17-30.
Resnik, P. (1999). Semantic Similarity Taxonomy: Information-Based Measure
Application Problems Ambiguity Natural Language. Journal Artificial
Intelligence Research , 95-130.
Resnik, P. (1995). Using information content evaluate semantic similarity taxonomy.
IJCAI'95 Proceedings 14th international joint conference Artificial intelligence
(pp 448-453). San Francisco, USA: Morgan Kaufmann Publishers Inc.
420

fiSEMANTIC SIMILARITY MEASURES APPLIED ONTOLOGY

Richardson, R., Smeaton, A. F., & Murphy, J. (1994). Using WordNet Knowledge Base
Measuring Semantic Similarity Words. Proceedings AICS Conference.
Dublin, Ireland: Technical Report.
Schickel-Zuber, V. (2007). OSS: semantic similarity function based hierarchical ontologies.
IJCAI'07 Proceedings 20th international joint conference Artifical intelligence
(pp. 551-556). San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.
Seco, N., Veale, T., & Hayes, J. (2004). Intrinsic Information Content Metric Semantic
Similarity WordNet. ECAI'2004, 16th European Conference Artificial
Intelligence, (pp. 1089-1090). Valencia, Spain .
Wu, Z., & Palmer, M. (1994). Verb semantics lexical selection. ACL'94 Proceedings
32nd annual meeting Association Computational Linguistics (pp. 133-138).
Stroudsburg, USA: Association Computational Linguistics.

421

fiJournal Artificial Intelligence Research 44 (2012) 141-177

Submitted 11/11; published 05/12

Algorithms Limits Compact Plan Representations
Christer Backstrom
Peter Jonsson

christer.backstrom@liu.se
peter.jonsson@liu.se

Department Computer Science
Linkoping University
SE-581 83 Linkoping, Sweden

Abstract
Compact representations objects common concept computer science. Automated planning viewed case concept: planning instance compact
implicit representation graph problem find path (a plan) graph.
graphs represented compactly planning instances, paths
usually represented explicitly sequences actions. cases known
plans always compact representations, example, using macros. show
results extend general case, proving number bounds compact
representations plans various criteria, like efficient sequential random access
actions. addition this, show results consequences
gained reformulating planning problem. contrast
also prove number positive results, demonstrating restricted cases plans
useful compact representations, well proving macro plans favourable access
properties. results finally discussed relation relevant contexts.

1. Introduction
usage study representations objects much smaller objects
commonplace computer science. us encounter representations
daily basis form zipped files, mp3 files etc. practical cases, usually
talk compressed objects, terms compact succinct common
theoretical studies. meaning terms vary common interesting case
size representation polylogarithmic size object.
Sometimes sufficient compute compact representation object, instance,
archiving file. cases representation must also support various operations
efficiently without first unpacking object explicit representation. Performing
operations compact representation often harder performing operation
explicit object, cases compact representation make easier
emphasising inherent structure object.
One archetypical case using compact representations automated planning, although
seldom viewed way. planning instance implicit representation graph
typically exponentially larger representation, instance,
solutions, plans, paths graph. Consider, example, Strips instance
n variables. variables implicitly define state space 2n states action
preconditions define 2nm arcs graph. Similarly, define instances
paths exponential length too. Although planning instances already
c
2012
AI Access Foundation. rights reserved.

fiBackstrom & Jonsson

compact representations, little attention paid compact representations
solutions, usually represented explicitly. paper introduces analyses
number compact representations.
first turn computer science general find compact representations
arbitrary strings intensively studied field. example, Charikar et al. (2005)
Rytter (2003) address problem approximating smallest string representation using
compressed grammar. Bille et al. (2011) show representations permit efficient
access matching operations, Jansson, Sadakane, Sung (2012) demonstrate
representations efficient edit operations. structured objects arbitrary strings
potentially compact representations. following examples,
displaying positive well negative results various areas. Galperin Wigderson
(1983) Wagner (1986) study complexity common graph operations
graphs implicitly represented circuits tell whether two vertices connected.
Balcazar (1996) uses variant approach study complexity search AI,
using circuit generates adjacency list vertex. Bulatov Dalmau (2006)
present efficient algorithm certain CSP problems relies using compact
representation set solutions. Liberatore Schaerf (2010) study preprocessing
model checking focus size preprocessed parts. Cadoli et al. (2000) study
various formalisms knowledge representation study problems modelled one
formalism transformed another formalism polynomially larger
representation.
One approach compact representations various areas use macros.
concept widely used long time also planning, although seldom
purpose providing compact representations. exception following case. 3S
class (Jonsson & Backstrom, 1998b) planning instances property optimal
plans exponential length always possible decide polynomial time
plan not. Gimenez Jonsson (2008) showed plans 3S class
always polynomial-size representation using macros, macro plans even
generated polynomial time. is, although plan may exponential length,
thus necessarily take exponential time generate, possible generate compact
representation polynomial time. Jonsson (2009) later demonstrated similar results
number classes. Although particular classes planning instances may
still restricted much practical use, principle compressing solution
using macros interesting tool planning plan explanation.
approaches compact plan representation appear sparingly literature.
notable exception Liberatore (2005a) studies two concepts plan representation
efficient random access efficient sequential access respectively. like macro
plans examples representing one long plan compactly. might also consider
representing large set plans compactly. instance, plan recognition may
simultaneously consider exponential number candidate plans (Geib, 2004). Although
seldom viewed way, also reactive plan representation large set plans,
one state goal reached. is, however, known reactive
plans cannot compact, efficient correct general case (Jonsson, Haslum,
& Backstrom, 2000), although properties important, instance, spaceship
applications (Williams & Pandurang Nayak, 1997). Pomdps may similarly thought
142

fiAlgorithms Limits Compact Plan Representations

probabilistic variant reactive plans compactness representations important
also case (Boutilier & Poole, 1996). Yet another case size plan
big plan necessarily long, occur various types branching
plans, contingent planning (Bonet & Geffner, 2000). three different concepts
isolated other. instance, Bonet (2010) casts contingent planning
problem conformant planning, is, branching plan represented one
long non-branching plan, branches appearing subplans. cases,
interesting know objects question compact representations. Although
compact representation save space, may secondary many cases.
important aspect object compact representation object
inherent structure may exploit also purposes. instance, represent
set many plans representation using recursive macros, similar, emphasize
differences similarities plans. make comparisons
operations plans efficient. Similarly, case branching plans might
want exploit structure clearly displays two branches common
differ.
positive results macro representations (Gimenez & Jonsson, 2008; Jonsson, 2009)
prompt obvious question whether long plans always compressed using macros
(or method). show paper unlikely, matter type
compact representation try use (macro plans, finite automata whatever).
remainder paper organized follows. Section 2 introduces basic notation
concepts well planning framework used paper, also contains
useful definitions complexity results. first ask, Section 3, whether
(optimal) plans instance compact representations. find answer
no; possible, neither macros method. However, results
exclude plans instance compact solutions. Section 4
thus restrict question whether uniform compact representation one plan
solvable instance. precisely, ask algorithm corresponds
one compact representation solvable instance. show algorithm
unlikely exist must also able access actions plan useful way.
Section 5 turn non-uniform case, asking solvable instance least
one plan compact representation. primarily consider representations
efficiently access actions plan sequentially randomly. show also
seems unlikely general case, interesting special cases
representations exist. section also investigate macro representations
extend results Gimenez Jonsson two ways. prove plans
polynomial-size macro representation random accessed polynomial
time without access full plan. However, also prove cannot always
represent plans compactly using macros. Section 6 analyse whether get around
problem long plans reformulating planning problem. Also
answered negatively. actually ask plan original problem, problem
inherently intractable also using reformulation. However, even considering
decision problem still seems possible make planning simpler reformulation.
Finally, Section 7 contains discussion results paper related
relevant various topics like adding information guide planners, causal graphs
143

fiBackstrom & Jonsson

plan explanation. paper ends summary results together list
open questions.
results paper appeared previous conference publication
(Backstrom & Jonsson, 2011b).

2. Preliminaries
section consists three parts. first part introduces general notation
terminology used paper. second part defines two planning frameworks used
paper, Finite Functional Planning propositional Strips, presents
constructions frequently used. third part briefly recapitulates concept
advice-taking Turing machines also defines 3SAT problem used
several occasions paper.
2.1 General Notation Terminology
sequence objects x1 , x2 , . . . , xn written hx1 , x2 , . . . , xn i, hi denoting empty
sequence. Given set X objects, set sequences X, including hi, denoted
X . set, sequence aggregation X objects, write |X| denote
cardinality (the number objects) x write ||X|| denote size (the number
bits representation) x. composition two functions f g denoted
f g defined (f g)(x) = f (g(x)).
negation propositional atom x denoted x. literal either atom
negation set L(X) literals set X atoms defined L(X) =
{x, x | x X}. Negation extended literals ` literal `. Negation
also extended sets X set literals X = {` | ` X}. Let
subset L(X) set X atoms. P os(Y ) = {x X | x } set
atoms appear positive , N eg(Y ) = {x X | x } set atoms
appear negated Atoms(Y ) = P os(Y )N eg(Y ). set consistent P os(Y )
N eg(Y ) empty set Z atoms satisfies P os(Y ) Z N eg(Y )Z = .
update operator n binary function given set X atoms set
literals, X n set atoms defined X n = (X N eg(Y )) P os(Y ).
2.2 Planning
positive results compact representations, want results apply general
powerful planning languages possible, results hold also languages
restricted. Hence, use Finite Functional Planning formalism (Backstrom &
Jonsson, 2011a), makes minimum assumption language, except
ground language state variables finite domains.
Definition 1. Finite Functional Planning (FFP) frame tuple hV, D, Ai V
implicitly ordered set variables, : V N domain function maps every variable
finite subset natural numbers set actions. frame implicitly
defines state space S(f ) = D(v1 ) . . . D(vn ), v1 , . . . , vn variables
V order. members S(f ) referred states. action two
associated total functions, precondition pre(a) : S(f ) {0, 1} postcondition
144

fiAlgorithms Limits Compact Plan Representations

post(a) : S(f ) S(f ). pairs states s, S(f ) actions A,

1) pre(a)(s) = 1
2) = post(a)(s).
sequence = ha1 , . . . , a` plan state s0 S(f ) state s` S(f )
either
1) = hi s0 = s`
2) states s1 , . . . , s`1 S(f ) ai si1 si (for 1 `).
FFP instance tuple p = hV, D, A, I, Gi f = hV, D, Ai FFP frame,
S(f ) state G : S(f ) {0, 1} total function. state S(f ) goal
state p G(s) = 1. goal G reachable state S(f ) plan
goal state p. solution p plan goal state S(f ).
solution p called plan p.
complexity computing pre- postconditions actions goal
function referred step complexity. paper, consider subclass
FFP([P]) consists FFP frames instances polynomial step complexity.
occasionally also consider restrictions FFP([P]) use notation FFP(p)
class FFP frames f (and instances p) action pre- postconditions
(and G) computed p(||f ||) time (and p(||p||) time), p polynomial.
furthermore say FFP([P]) instance p = hV, D, A, I, Gi deterministic
S(p) p plan s, one
pre(a)(s) = 1. is, instance deterministic planner never faced
choice two actions.
proving compact representation exist, result gets stronger
use weaker formalism. is, want use restricted formalism possible,
since results automatically apply formalisms expressive.
Hence, use propositional Strips results. number common
variants propositional Strips known equivalent
SAS+ formalism strong form polynomial reduction (Backstrom, 1995).
refer Strips paper variant called propositional Strips
negative goals (PSN) Backstrom. defined special case FFP([P])
uses binary variables, define traditional way, treating variables
propositional atoms.
Definition 2. Strips frame tuple f = hV, Ai V set propositional atoms
set actions. state space defined S(f ) = 2V states subsets
V . action precondition pre(a) postcondition post(a),
consistent sets literals V . pairs states s, S(f ) actions A,

1) satisfies pre(a)
2) = n post(a).
sequence = ha1 , . . . , a` plan state s0 S(f ) state s` S(f )
either
1) = hi s0 = s`
2) states s1 , . . . , s`1 S(f ) ai si1 si (for 1 `).
145

fiBackstrom & Jonsson

Strips instance tuple p = hV, A, I, Gi f = hV, Ai Strips frame,
state S(f ) G consistent set literals V . state S(f ) goal state
p satisfies G. goal G reachable state S(f ) plan
goal state p. solution p plan goal state S(f ).
solution p called plan p.
notation : X frequently used define action precondition X
postcondition .
negative results proven hold Strips. However, cases results
hold even many restricted subclasses Strips. would lead far survey
cases paper use restriction unary actions archetypical case
throughout paper.
Definition 3. Strips action unary |post(a)| = 1, set Strips actions unary
actions unary Strips frame instance unary action set unary.
Unary actions may seem like limiting restriction demonstrated
sufficient many cases use on-board controllers spacecrafts (Muscettola et al.,
1998; Brafman & Domshlak, 2003). surprising, though, since Strips planning
PSPACE-complete remains even restricted unary actions (Bylander, 1994).
Given Strips instance always possible construct corresponding Strips instance
unary. following reduction unary instances simplified Strips version
reduction used SAS + (Backstrom, 1992, proof Theorem 6.7).
Construction 4. Let p = hV, A, I, Gi Strips instance. Construct corresponding

instance p 0 = hV 0 , A0 , 0 , G0 follows. Define Vlock = {vlock
| A}. let V 0 =
0
0
0
V Vlock , = G = G Vlock . Define A, contains
following actions:
},
abegin : pre(a) Vlock {vlock

},
aend : post(a) {vlock } {vlock
} {` }, ` post(a).
ai : {vlock


leave without proof construction polynomial reduction class
Strips instances class unary Strips instances. furthermore worth noting
construction easily modified use padding redundant variables
make original actions correspond number actions unary instance.
Hence, possible make reduction plans unary instance
constant factor longer corresponding plans original instance.
also make frequent use Strips instances include encodings binary
counters based following construction, uses one action bit
increment non-negative integer encoded binary.
Construction 5. n-bit binary counter encoded Strips follows: let V =
{x1 , . . . , xn } let contain n actions
ai : {xi , xi1 , . . . , x1 } {xi , xi1 , . . . , x1 } (1 n).
146

fiAlgorithms Limits Compact Plan Representations

following plan counting 0 16 using 5-bit counter according Construction 5:
ha1 , a2 , a1 , a3 , a1 , a2 , a1 , a4 , a1 , a2 , a1 , a3 , a1 , a2 , a1 , a5 i.
could modify binary counter use unary actions described Construction 4, direct way get unary actions count Gray code.
Construction 6. (Backstrom & Klein, 1991) n-bit Gray-code counter encoded
Strips follows: let V = {x1 , . . . , xn } let contain 2n actions
si : {xi , xi1 , xi2 , . . . , x1 } {xi } (1 n),
ri : {xi , xi1 , xi2 , . . . , x1 } {xi } (1 n).
following plan counting 0 16 5-bit Gray-code counter according
Construction 6:
hs1 , s2 , r1 , s3 , s1 , r2 , r1 , s4 , s1 , s2 , r1 , r3 , s1 , r2 , r1 , s5 i.
2.3 Complexity Theory
use abbreviation DTM deterministic Turing machine NTM nondeterministic Turing machine. addition standard types, also use advice
taking Turing machines deterministic nondeterministic type.
advice-taking Turing machine associated sequence a1 , a2 , a3 , . . . advice
strings, special advice tape advice function a, natural numbers
advice sequence, a(n) = . input x advice tape immediately loaded
a(||x||). continues normal way, except also access
advice written advice tape. exists polynomial p ||a(n)|| p(n),
n > 0, said use polynomial advice. complexity class P/poly
set decision problems solved advice-taking DTM runs
polynomial time using polynomial advice. extended that, instance,
NP/poly defined NTMs run polynomial time using polynomial advice.
Note advice depends size input, content. Furthermore,
advice sequence must exist; need computable. following two
results literature used later paper.
Theorem 7. a) NP P/poly, polynomial hierarchy collapses (Karp & Lipton,
1980, Theorem 6.1). b) Let k > 0 integer. pk pk /poly, polynomial
hierarchy collapses level k + 2 (Yap, 1983, Lemma 7 combined Theorem 2).
3SAT problem consists instances form C = {c1 , . . . , cm } ci ,
1 m, called clause set exactly three literals universe
binary variables. instance C satisfiable exists assignment truth
values variables used C least one literal true ci C.
otherwise unsatisfiable. Deciding satisfiability 3SAT NP-complete, deciding
unsatisfiability coNP-complete. precisely, use following definition
3SAT paper.
147

fiBackstrom & Jonsson

Definition 8. integers n > 0, let Xn = {x1 , . . . , xn } set variables let
m(n)
m(n) number possible 3-literal clauses Xn . Let c1n , c2n , . . . , cn

m(n)
1
2
fixed systematic enumeration clauses let Cn = {cn , cn , . . . , cn }. clause
m(n) 1
cin defines three literals that1 cin = {`1i , `2i , `3i }. Further, let Cn0 , Cn1 , . . . , Cn2



fixed systematic enumeration subsets Cn , let n = hXn , Cn i, 0 <
m(n)
2m(n) . Also implicitly define set En = {e1n , e2n , . . . , en } atoms subsets
Eni = {ejn | cjn Cni }, 0 < 2m(n) .
m(n)

1 systematic enumeration possible 3SAT instances
sequence 0n , 1n , . . . , 2n
n variables, hence equivalent usual definition 3SAT. Technically speaking,
redundant encoding 3SAT since allows instances specify variables
used clauses. harmless, however; non-redundant instances remain,
still hard instances neither redundantly encoded instances
harder non-redundant counterpart. Since m(n) 8n3 , enumerations
Cn En chosen polynomial-time computable, assume
enumerations fixed on. also note set Eni uniquely
identifies clause set Cni .

3. Representing Arbitrary Plans Compactly
known cases planning instances exponential-size plans
plans always polynomial-size representation (Gimenez & Jonsson, 2008).
obvious question thus whether plans, including exponential length,
polynomial representations. one interpretation question answer trivially yes.
Observation 9. set plans arbitrary FFP([P]) instance p O(||p||)
size representation, since instance together deterministic planning algorithm
successively enumerates outputs plans representation.
Although trivial useful observation highlights fundamental issues representations. Liberatore (2005a) discusses similar representation, instead
specifying algorithm defines lexiographic ordering actions. Furthermore,
adds plan index able represent single plan rather whole set
plans. However, index unproblematic, see soon.
interesting interpretation question whether every single plan
particular instance polynomial representation. Even precisely,
polynomial p every plan every planning instance representation
size O(p(n)), n size planning instance? investigate question
consider simple compact notation possible, index number plan
particular instance. Since instances may infinitely many plans, due cycles
state-transition graph, consider optimal plans only. is, however, guarantee
even index small enougha polynomial number bits may sufficient
represent it.
1. sometimes omit index n, assumed obvious context, thus write `ki rather
`kn,i .

148

fiAlgorithms Limits Compact Plan Representations

Construction 10. Given arbitrary integer n > 0, construct Strips instance p n =
hVn , , , Gn Vn = {x1 , . . . , xn , y}, = , Gn = {x1 , . . . , xn } contains
actions
ai : {xi , xi1 , . . . , x1 } {xi , xi1 , . . . , x1 , y} (1 n)
bi : {xi , xi1 , . . . , x1 } {xi , xi1 , . . . , x1 , y} (1 n).
Lemma 11. every integer n > 0, instance pn according Construction 10 22
optimal plans.

n 1

Proof. Let n > 0 arbitrary integer p n corresponding Strips instance according
Construction 10. instance binary counter variables x1 , . . . , xn
Construction 5, except extra variable independently set
true false, depending whether action type ai bi chosen. Since variables
x1 , . . . , xn interpreted binary number, let notation hm, yi represent
state x1 , . . . , xn encodes number false, let hm, yi represent
corresponding state true. Whenever state hm, yi hm, yi (where < 2n 1)
possible go either hm + 1, yi hm + 1, yi using one action,
states. state transition graph instance appears Figure 1. initial state
h0, yi goal states h2n 1, yi h2n 1, yi. Hence, plan p n must
length 2n 1. every state goal state two different actions
choose lead different states. However, goal reachable
n
states choice action matter. Hence, 22 1 different
plans p n .

m=

0

1

2n 1
y=1

2

y=0
goal

init

Figure 1: State-transition graph proof Lemma 11.
Although atom redundant particular example whole construction could
part larger instance, purpose. also noted
instances used proof optimal plans; plans length.
set prove previous claim.
Theorem 12. every integer n > 0, takes 2n 1 bits index optimal plans
instance pn according Construction 10.
Proof. Since m-bit number distinguish 2m different objects,
follows Lemma 11 least 2n 1 bits necessary index plans p n
149

fiBackstrom & Jonsson

result immediately implies (optimal) plans Strips instance
polynomial-size representations. holds even restrictions, like unary actions.
basing Construction 10 Gray counter instead binary counter every action
two postconditions. Rewriting using Construction 4 yields equivalent instance
unary actions using block four actions action original instance.
Although plans get 4 times longer number plans remain same. Hence,
Theorem 12 still holds.
theorem leaves possibility open plans instance
polynomial representations, although can. interesting question thus
many plans instance polynomial representations? answer
question stray field information theory Kolmogorov complexity.
scope paper treat field detail, loosely speaking, Kolmogorov
complexity string size smallest DTM generate string
input. Let K(x) denote Kolmogorov complexity binary string x. following
lemma due Buhrman et al. (2000, Lm. 1).
Lemma 13. (Incompressibility lemma) Let c positive integer. Every set cardinality
least m(1 2c ) + 1 elements x K(x) blog mc c.
lemma used show fraction plans compactly represented
approaches zero size instances approaches infinity.
Theorem 14. Let p arbitrary polynomial. Consider instances pn according Construction 10 arbitrary integers n > 0. Let t(n) total number plans
pn let s(n) number plans represented p(n) bits.
limn s(n)
t(n) = 0.
n

Proof. Let p arbitrary polynomial. know Lemma 11 t(n) = 22 1 .
every n > 0, let c(n) = 2n p(n) 2. incompressibility lemma says
least t(n)(1 2c(n) ) + 1 plans K() blog t(n)c c(n).
is, 2c(n) t(n) 1 plans K() < blog t(n)c c(n). Using
values t(n) c(n) above, simplifies say 2p(n)+1 1
plans K() p(n). Hence, s(n) 2p(n)+1 1. theorem follows since
2p(n)+1 1
0 limn s(n)
= 0.
t(n) limn 22n 1
means even case plans every solvable instance
compact representations, probability particular plan compact representation
vanishingly low large instances. Although strictly necessary use
Kolmogorov complexity prove Theorem 14 makes information-theoretic
aspect compact representations clearer.

4. Uniform Compact Representations Plans
know cannot, general, compress arbitrary exponential plans subexponential size. choose plan use? previous
result still leaves open possibility small fraction solutions planning instance could compact representations. However, planner (or oracle whatever)
150

fiAlgorithms Limits Compact Plan Representations

would choose us plan present us compact representation
of. Suppose planner could actually this, would make use it? still need
actual plan cannot avoid exponential size. Hence, interesting case
seems could least access useful information plan efficiently.
term representation used loose sense here, need really precisely
defined moment. suffices note representation needs kind
data structure kind access algorithm, extreme cases either
vector data trivial access algorithm algorithm embeds data.
could mean access compact representation efficiently? investigate
two criteria. first one efficiently retrieve actions actual
plan sequentially. interpretation efficient actions retrieved
polynomial delay (Johnson, Papadimitriou, & Yannakakis, 1988). second criterion
action actual represented plan random accessed polynomial time,
size instance.
looking explicit representations plan take look uniform
case, single representation covers instances. precisely,
consider case single algorithm works compact representation
plan every solvable instance.
Theorem 15. algorithm solvable Strips instance p either
generate plan p sequentially polynomial delay random access action
plan p polynomial time, P = NP.
Note theorem follow fact Strips planning PSPACEcomplete since solvable instances considered. proving theorem need
introduce extra technical machinery. start encoding 3SAT instances according
Definition 8 Strips follows.
Construction 16. Let n > 0 i, 0 < 2m(n) , arbitrary integers. Construct
Strips instance p = hVn , , Eni , {goal}i Vn = Xn En {cts, ctu, goal, inc}
{v0 , . . . , vm(n) } actions specified Table 1.
previously noted, subset Eni En uniquely identifies 3SAT instance telling
clauses Cn enabled . is, initial state selects particular nvariable instance interested in. actions partitioned three groups. Group
contains two actions acs acu, set atoms cts ctu respectively.
actions block cts ctu initially false, one atoms
set true plan. is, cts ctu mutually exclusive. Group II consists
actions require cts true group III consists actions require ctu true.
two groups actions thus also mutually exclusive. Hence, every plan must start
exactly one action group rest plan consists actions
either group II group III, depending first action is. intention
following: plan starts action acs commits verifying
satisfiable plan starts action acu commits verifying
satisfiable. either case plan ends action satisfies goal plan
verified commitment made first action. interpreted viewing
151

fiBackstrom & Jonsson



acs : {ctu} {cts}
acu : {cts} {ctu}

Commit prove satisfiability
Commit prove unsatisfiability

II

aseti : {cts, v0 } {xi }
avt0 : {cts} {v0 }

Set xi
Start verification

avt0j : {cts, ejn , vj1 ,} {vj }
avtkj : {cts, ejn , vj1 , `kj } {vj }
ags : {cts, vm(n) } {goal}

Skip disabled clause cj
Verify cj true since `kj true
Conclude instance satisfiable

avf j : {ctu, inc, ejn , `1j , `2j , `3j } {inc}
aixi : {ctu, inc, xi , xi1 , . . . , x1 }
{inc, xi , xi1 , . . . , x1 }
agu : {ctu, inc, x1 , . . . , xn } {goal}

Verify clause cj false
Increment counter

III

Conclude instance unsatisfiable

Index ranges: 1 n, 1 j m(n) 1 k 3.

Table 1: Actions Construction 16.
planner theorem prover first outputs theorem (the first action plan)
proof theorem (the rest plan).
Lemma 17. every integer n > 0 integer 0 < 2m(n) , Strips
instance pin according Construction 16 following properties:
1. computed polynomial time n.
2. corresponds 3SAT instance sin every plan pin starts action
acs sin satisfiable otherwise action acu.
3. always least one plan.
Proof. Property 1 trivial prove. prove property 2, first note initial
state contains atoms En . previously noted, subset Eni En uniquely
identifies 3SAT instance telling clauses Cn enabled .
two cases: plan starts action acs commits verifying

n satisfiable plan starts action acu commits verifying
satisfiable. either case plan ends action satisfies goal
plan verified commitment made first action. details two cases
follows.
plan verifies satisfiability, must form
k

m(n)
hacs, aseti1 , . . . , asetih , avt0 , avtk11 , . . . , avtm(n)
, agsi.
{z
}
|
|
{z
}

assign

verify

assign block h actions set satisfying assignment x1 , . . . , xn . verify
k
block consists one action = avtj j clause cjn . cjn enabled (ejn true),
1 kj 3 verifies `kj cjn true assignment. Otherwise, cjn
152

fiAlgorithms Limits Compact Plan Representations

disabled kj = 0, = avt0j skips cjn without verifying anything.
planner thus
1. committed verify satisfiable,
2. chosen satisfying assignment x1 , . . . , xn
3. chosen one literal enabled clause witness clause true
assignment.
last action ags makes goal true three steps successful. Note
works also case clause enabled, corresponds trivially
satisfiable instance empty set clauses. Obviously, plan form
satisfiable.
plan instead verifies unsatisfiability, must form
hacu, b0 , a1 , b1 , a2 , b2 , . . . , ah , bh , agui,
h = 2n 1. Except first last actions, plan viewed two
interleaved sequences
= ha1 , . . . , ah = haix1 , aix2 , aix1 , aix3 , . . . , aix1

= hb0 , b1 , . . . , bh i.
aixi actions increment actions use x1 , . . . , xn form binary counter. Since
variables correspond number 0 initial state 2n 1 increment
actions, subplan enumerates possible truth assignments x1 , . . . , xn . Sequence
consists actions type avf j . avf j action verifies corresponding
clause cjn enabled false current assignment x1 , . . . , xn . aixi actions
require inc true set false, avf j actions instead require inc false
set true. Hence plan synchronised alternates actions
two sequences. Since first aixi action preceeded avf j action
avf j action last aixi action, follows must unsatisfied
enabled clause every possible truth assignment, since synchronization otherwise
get stuck counter cannot increment. is, plan type
unsatisfiable. last action agu makes goal true succeeded. Note
case need actions skip disabled clauses since sufficient
demonstrate one enabled clause false assignment.
follows plan first form satisfiable second form

n unsatisfiable. Furthermore, since first action commitment rest
plan whether verify satisfiability unsatisfiability, sufficient check action
decide satisfiable not.
Property 3 follows immediately property 2 since plan must either
two forms.
necessary tools prove theorem.
153

fiBackstrom & Jonsson

Proof Theorem 15. Suppose algorithm either sequential random access stated precondition theorem. solve 3SAT instance
polynomial time asking algorithm first action plan
corresponding instance p tell action whether satisfiable. However,
implies P = NP.
proof would still hold rewriting Construction 16 described Construction 4,
is, Theorem 15 holds even restricted set unary Strips instances only.

5. Non-Uniform Compact Representations Plans
Theorem 15 uses strong criterion: requires one single algorithm handle
instances. relaxed variant non-uniform case, allow different
representations different instances. is, consider compact representations
single plans different access criteria. order must first define
precisely mean representations.
5.1 Compact Representations Access Mechanisms
define concepts Csar Crar representations action sequences
characterised access properties2 .
Definition 18. Let f arbitrary function. Let f = hV, D, Ai FFP([P]) frame
let . representation DTM. Furthermore:
1. f -compact |||| f (||f ||) runs f (||f ||) space including input
output tapes.
2. f -compact sequential-access representation (f -Csar) f -compact,
takes input generates actions sequentially f (||f ||) time
successive action.
3. f -compact random-access representation (f -Crar) f -compact
arbitrary index (where 1 ||) input, outputs action
f (||f ||) time.
Note definition require representations computable.
could used two separate functions, one bound access time one bound
size, would allow better precision. However, choose use single function
since makes theory simpler clearer sufficient precision
purposes paper. consider output tape cleared actions
output single action, sequence . Also note space complexity
includes input output tapes, implies longest sequence f -Crar
2. Note definition differs slightly previous one (Backstrom & Jonsson, 2011b). First,
generalised definition allow compact representations arbitrary function f ,
arbitrary polynomial. Second, order improve precision longer use O() notation
exact functions. Finally, representations restriction space time. None
changes matter results previous publication, details proofs.

154

fiAlgorithms Limits Compact Plan Representations

represent less 2|||| actions since input limited |||| bits. Csar
corresponding limit since input. Furthermore, time restriction f -Csar
viewed generalisation polynomial delay concept restricted
polynomials. often apply definition instances rather frames. Although
makes slight difference technically, important principle ignoring
allows simpler theorems proofs. write Crar Csar referring
whole family representations particular type.
5.2 Sequential-Access Representations
sequential access non-uniform case would like ask solvable Strips
instances least one plan polynomial Csar. Unfortunately, still remains
open question. Hence, consider restricted case question also
require Csar must verifiable within resource constraint, define
follows.
Definition 19. every FFP([P]) plan representation type R, define following decision problem:
Plan Representation Verification
Instance: FFP([P]) instance p = hV, D, A, I, Gi string .
Question: R-representation plan p?
complexity verification measured ||p|| + ||||. state following
theorem polynomial Csars.
Theorem 20. Let C arbitrary complexity class p arbitrary polynomial.
p-Csar verification NP C every solvable Strips instance least one plan
corresponding p-Csar, PSPACE NP C .
Proof. Let p arbitrary polynomial. Suppose p-Csar verification NPC every
solvable Strips instance least one plan corresponding p-Csar. Let p
arbitrary Strips instance. decide p plan guessing string
length p(||p||) bits check string p-Csar plan p.
done polynomial time (in ||p||) using NTM oracle C since p-Csar
verification NPC . However, deciding Strips instance plan PSPACEcomplete (Bylander, 1994, Thm. 3.1) follows PSPACE NPC , since p
chosen arbitrarily.
is, Csar planning instance limited use must first verify
correct using it, since verification may difficult solving instance itself.
Also note C class polynomial hierarchy, PSPACE NPC implies
collapse hierarchy. preceding theorem holds restriction unary Strips
instances, since planning still PSPACE-complete restriction (Bylander, 1994,
Thm. 3.3). fact, holds restrictions planning still PSPACE-complete,
includes several cases Bylanders analysis well many subclasses
SAS+ planning (see Backstrom & Nebel, 1995; Jonsson & Backstrom, 1998a, overviews
results).
155

fiBackstrom & Jonsson

Although result may seem disapointing, holds condition
must check whether Csar correct. means, instance, theorem
irrelevant correctness Csar guaranteed design. One case following.
Theorem 21. Every Strips instance according Construction 16 plan
polynomial Csar.
Proof. Consider arbitrary instance p . Add n + 1 extra bits b0 , . . . , bn b0
tells satisfiable not. satisfiable remaining bits specify satisfying
assignment bi gives value vi , otherwise undefined. claim
simple deterministic algorithm uses p b0 , . . . , bn generates
plan p polynomial delay follows.
Suppose b0 says satisfiable h bits b1 , . . . , bn one.
plan p form
k

m(n)
, agsi.
hacs, aseti1 , . . . , asetih , avt0 , avtk11 , . . . , avtm(n)
{z
}
|
{z
}
|

assign

verify

actions assign block easily generated b1 , . . . , bn . avtkj actions,
output avt0j cjn enabled otherwise output avtkj smallest k `kj
true specified assignment. Clearly algorithm works polynomial delay.
Instead suppose satisfiable. plan second type must cycle
possible assignments. generating corresponding counting
actions trivial. assignment must also output avf j action. Determine
smallest j cjn enabled satisfied current assignment,
output avf j . done polynomial time since polynomial number
clauses.
Clearly construction polynomial Csar plan p .
following theorem demonstrates also general harder classes
instances even optimal plans polynomial Csars design.
Theorem 22. subclass X Strips polynomial p deciding
instances X plan PSPACE-complete solvable instances X
optimal plan p-Csar.
Proof. PSPACE characterised class polynomial-space bounded DTMs.
Bylander (1994, Thm. 3.1) used fact demonstrate polynomial reduction
PSPACE Strips planning. refer Bylander details brief: given
machine input x constructs deterministic Strips instance plan
(x) accepts. Hence, polynomial time problem check
valid state find action, any, applied state. follows
polynomial p every solvable Strips instance plan
p-Csar. Furthermore, since instance deterministic one plan,
must optimal.
156

fiAlgorithms Limits Compact Plan Representations

even general observation every deterministic FFP([P]) instance
solvable exactly one plan, thus optimal, plan polynomial
Csar. contrast next consider class instances solvable instances
always plans polynomial Csars optimality guarantee.
example thus illustrates Csar representation gives guarantees
actual data represents. precisely, example uses class reversible
FFP([P]) instances, state-transition graph symmetric.
Definition 23. FFP([P]) frame f = hV, D, Ai reversible pairs states
S(f ), whenever action also action a0
s.
Note reversible instances easy special case planning; deciding
plan still PSPACE-complete (Jonsson et al., 2000, Thm. 18). is, plans
still exponential length.
Theorem 24. polynomial q polynomials p, every solvable
reversible FFP(p) instance (q p)-Csar plan.
Proof. Let p = hV, D, A, I, Gi solvable FFP(p) instance f = hV, D, Ai
reversible. Consider algorithm Figure 2. Optplan assumed algorithm
optplan(s,G) returns length shortest plan G.
ignoring process B, clear algorithm outputs optimal plan p since
plan assumption. Process B finds two actions a1 a2 executing
ha1 , a2 state ends state s. choice actions must exist since
plan goal state f reversible. synchronisation processes
B make actions a1 , a2 appear adjacent order output
algorithm, thus interfere plan produced process A.
make plan longer. Choosing actions process B done double loop
pairs actions checking them.
obvious polynomial r process B runs r(||p||) time.
choose r also allow extra time run process parallel. Let p together
algorithm. |||| ||p|| + c constant c. Choose r also satisfies
n + c r(n) n > 0. Obviously, r-Csar plan p. Choose
polynomial q r(n) q(p(n)) n > 0.
Algorithm Optplan must obviously run polynomial space, complexity otherwise
important. parallel algorithm used proof theorem extent
nonsense algorithm. Process job consulting ordinary planning algorithm
(optplan) gives time guarantees. Process B, hand, contributes nothing
relevant plan satisfies access time requirement. is, process B buys time
process find plan generating irrelevant actions frequently enough satisfy
time requirements. wait statements strictly necessary illustrate
tune step complexity algorithm slowing process B desired.
Although example might, perhaps, considered somewhat pathological, clearly
demonstrates Csar (just like Crar) representation. like
data structures certain access properties guarantee particular
157

fiBackstrom & Jonsson

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20

:=
G(s) = 0
parallel
process A:
` = optplan(s, G)
a0 s.t. pre(a0 )(s) = 1
:= post(a0 )(s)
optplan(t, G) < `
:= a0 , ` := optplan(t, G)
process B:
process running
choose a1 s.t. pre(a1 )(s) = 1
u := post(a1 )(s)
choose a2 s.t. pre(a2 )(u) = 1 post(a2 )(u) =
output a1
wait
output a2
wait
output
:= post(a)(s)

Figure 2: Csar algorithm reversible instances.
properties actual data stored. uncommon plan representations either.
instance, reactive plan could constructed behaviour still
considered correct run polynomial time space. alternatively use
random walk algorithm, also output actions polynomial delay.
eventually reach goal plan, also output lot redundant
actions. algorithm Figure 2 may, sense, viewed derandomized variant
random walk.
5.3 Random-Access Representations
case non-uniform random access clearer case sequential access.
answer question existence Crars without qualifications
verifiability.
Theorem 25. polynomial p every solvable Strips instance
least one plan corresponding p-Crar, polynomial hierarchy collapses.
Since theorem conditioned verifiability representations stronger
result Theorem 20. proving theorem need introduce additional theory.

158

fiAlgorithms Limits Compact Plan Representations

Construction 26. Let n > 0 arbitrary integer. Construct Strips instance p n =
hVn , , , {goal}i
Vn = Xn En {v0 , . . . , vm(n) } {svi, sva, sia, sii, sti, t, f, goal}
actions specified Table 2.

abi : {svi, sva, sia, sii, sti} {svi, t}

Begin instance block

aba : {svi, sia} {sva, f , v0 , v1 , . . . , vm(n) }

Begin assignment block

avtkj : {sva, vj , vj1 , ejn , `kj } {vj }
avf j : {sva, vj , vj1 , ejn , `1j , `2j , `3j } {vj , f }

Verify `j true clause cj
Verify clause cj false

avsj : {sva, vj , vj1 , ejn } {vj }

Skip disabled clause cj

aaf : {sva, vm(n) , f } {sva, sia}
aat : {sva, vm(n) , f } {sva, sia, t}

Verify assignment satisfying
Verify assignment satisfying

aixi : {sia, xi , xi1 , . . . , x1 } {sia, xi , xi1 , . . . , x1 }
arx : {sia, xn , . . . , x1 } {sia, svi, sti, xn , . . . , x1 }

Increment assignment counter
Reset assignment counter

ais : {sti, t} {sti, sii}
aiu : {sti, t} {sti, sii}

Verify instance satisfiable
Verify instance unsatisfiable

1
aiij : {sii, ejn , enj1 , . . . , e1 } {sii, ejn , ej1
n , . . . , en }

Increment instance counter

ari :

m(n)
{sii, en , . . . , e1n }

{goal}

instances checked

Index ranges: 1 n, 1 j m(n) 1 k 3.

Table 2: Actions Construction 26.
previous Construction 16 allows plans two types, either choosing assignment
verifying clauses chaining, enumerating assignments demonstrate
one false clause each. Construction 26 mixes methods. check instance
satisfiable plan must enumerate variable assignments assignment
must walk clauses chaining. enabled clause demonstrates
either true literal none literals true, disabled clauses skipped
over. Atoms f keep track whether clauses true assignment,
m(n)
case instance satisfiable. extra counter uses variables e1n , . . . , en
enumerates possible subsets Eni En , thus implicitly enumerating 3SAT instances
m(n) 1
0n , . . . , 2n
. counter constitutes outer loop, Eni , possible
assignments x1 , . . . , xn tested described above. plan thought
implementing algorithm Figure 3.
Lemma 27. integers n > 0, instance pn according Construction 26
following properties:
1. computed polynomial time n.
159

fiBackstrom & Jonsson

1
3SAT instances size n
2
clear
3
assignments x1 , . . . , xn
4
clear f
5
clauses cj
6
cj disabled
7
nothing
8
elsif `kj cj satisfied
9
nothing
10
else (neither `1j , `2j `3j satisfied)
11
set f
12
f
13
set
14

15
report satisfiable
16
else
17
report unsatisfiable
Figure 3: Algorithmic description Construction 26.
2. always least one plan.
3. exist constants bn every i, 0 < 2m(n) , action
position bn + plan pn ais 3SAT instance sin satisfiable
aiu sin unsatisfiable.
Proof. addition previous explanation construction note instance
designed deterministic. Setting = 2n (m(n) + 3) + 2 bn = + 1 satisfies
claim, since action position bn + ais satisfiable aiu
unsatisfiable.
set prove theorem.
Proof Theorem 25. Suppose p polynomial solvable Strips instances
least one plan corresponding p-Crar. n > 0, let p n
corresponding instance according Construction 26 let n p-Crar plan
n p n . assumption, n n must exist every n.
Construct advice-taking DTM takes input form = hp n , ii,
n integers n > 0 0 < 2m(n) . Let represented binary
using exactly m(n) bits. Then, ||I || strictly increasing n depends n.
Let sn = ||I || (which well defined since ||I || depend i). Define advice
function a(sn ) = n . advice thus p-Crar plan Strips
instance p n according Construction 26. (Recall need know
advice exists, find it.) Let bn refer corresponding constants
must exist according Lemma 27. Since run whatever algorithm used access
n , follows assumptions find action bn + n polynomial
time sn . Let return yes action ais otherwise return no.
160

fiAlgorithms Limits Compact Plan Representations

Given arbitrary 3SAT instance , compute corresponding input
run instance. construction, answers yes satisfiable. input computed polynomial time ||s || runs polynomial time using polynomial advice. Since solves satisfiability 3SAT follows
NP P/poly, impossible unless polynomial hierarchy collapses level 2
according Theorem 7a.
worth noting plans instances according Construction 26
contains subplan every 3SAT instance particular size. Hence, alternatively
view plan representation set exponentially many plans, shows
representing one long plan representing large set plans fundamentally
different issues.
Also Crars restricted cases prove always exist.
One example is, again, Construction 16.
Theorem 28. Every Strips instance according Construction 16 plan
polynomial Crar.
Proof. Add n+1 extra bits b0 , . . . , bn explained proof Theorem 21 construct
polynomial-time random-access algorithm follows.
Suppose b0 says satisfiable h bits b1 , . . . , bn one.
plan p form
k

m(n)
hacs, aseti1 , . . . , asetih , avt0 , avtk11 , . . . , avtm(n)
, agsi.
|
{z
}
|
{z
}

assign

verify

Since h n construct whole assign sequence determine specific action
polynomial time. avtkj actions correspond specific clause cjn . Since
clauses ordered compute j index action ask for. cjn
enabled output avf 0j otherwise output avf kj smallest k `kj
true specified assignment b1 , . . . , bn .
Instead suppose satisfiable. first last actions interleaved aixi avf j actions. aixi actions function counter
variables x1 , . . . , xn . Let arbitrary index plan first
last action. odd, ai aixk action k easily computed i,
output aixk . even ai avf j action. value x1 , . . . , xn immediately
ai easily computed i. Use value check enabled clauses
order finding clause cjn satisfied output avf j .
Clearly construction polynomial Crar plan p .
Another much larger class instances plans Crars considered
next section.
5.4 Relationships Compact Representations
section investigate Crar Csar concepts relate other. Since
macro plan also viewed compact representation also investigate macro
161

fiBackstrom & Jonsson

plans relate concepts. start showing polynomial Crar
plan also polynomial Csar plan.
Theorem 29. polynomial q polynomials p, FFP([P]) frames
f = hV, D, Ai , p-Crar, also (q p)-Csar.
Proof. Let f arbitrary FFP([P]) instance let p-Crar plan f .
Use action counter initiated index first action plan. Generate
actions plan sequentially repeatedly asking action indexed counter
incrementing counter. Let 0 denote algorithm together . ||||-bit
counter sufficient since must shorter 2|||| actions. Suppose takes r(m) time
increment m-bit counter. constant c ||0 || |||| + c, 0 runs
2p(||f ||) + c space 0 runs p(||f ||) + r(p(||f ||)) + c time. Define polynomial q
q(n) = 2r(n)+c. Obviously, ||0 || ||||+c q(||||) q(p(||f ||)), 2p(||f ||)+c q(p(||f ||))
p(||f ||) + r(p(||f ||)) + c q(p(||f ||)) 0 (q p)-Csar .
opposite hold, however. particular, instances according
Construction 26 plan Crar plan Csar,
construction acts separation two concepts.
Theorem 30. Unless polynomial hierarchy collapses, polynomial q
every polynomial p, every Strips instance p every plan p, p-Csar
(q p)-Crar.
Proof. Let X denote class Strips instances used proof Theorem 25. Since
instances deterministic polynomial p every solvable instance
p-Csar plan. However, follows proof
polynomial r instances X plan r-Crar. Hence,
polynomial q instances plan (q p)-Crar.
Although previously defined paper, makes sense also look
macro plans context. macro sequence two actions. Macros
commonly used planning treated single action planner. Macros
useful planning certain subsequences actions occur frequently
plans (Korf, 1987). However, macros may also used purpose representing
plan compact structured way. especially true macros allowed
also contain macros, since allows hierarchies macros. instance, well
known shortest solution Towers-of-Hanoi problem arbitrary number
disks described recursive schema (Gill, 1976, Ex. 319) although plan
exponential number disks. 3S class planning instances (Jonsson &
Backstrom, 1998b) property always find polynomial time
instance plan, plan may exponential length thus cannot
generated subexponential time. Gimenez Jonsson (2008) showed plans 3S
instances always polynomial-size representation using macros. fact, macro
plan even generated polynomial time although actual non-macro plan would
take exponential time generate. result later generalised classes
162

fiAlgorithms Limits Compact Plan Representations

planning instances Jonsson (2009). show polynomial-size macro plans
immediate connection compact plan representations. However, contrast
Gimenez Jonsson discuss generate macro plans analyse
properties.
Macro plans powerful tools representing plans compactly. Hence,
interesting identify criteria compact macro-plan representations exist not.
problem scope paper, give partial answer
question following way. straightforward see macro plan viewed
context free grammar (CFG): let actions terminals, let macros
variables, let macro expansions production rules let root macro
start symbol. note use macros represent single plan, rather represent various possibilities planning, macro expansions must acyclic order
produce unique well-defined plan. Hence, macro plan defined acyclic CFG.
CFGs used represent single string compactly often referred
compressed grammars. Furthermore, compressed grammar permits efficient
random access string represents; access necessary preprocessing
polynomial time size grammar (Bille et al., 2011). precisely, consider
grammar size n represents string length N derivation tree maximum
height h. polynomial time preprocessing, size grammar, possible
random access symbol string index O(log N ) time or, alternatively,
O(h) time. algorithms typically work first computing length substrings
generated rule, preprocessing step, use information find
symbol certain index top-down search. Since grammar acyclic get h n.
Hence, following proposition immediate properties compressed grammars.
Proposition 31. polynomial r every FFP([P]) frame hV, D, Ai
every macro plan sequence , used random access action
r(||||) time.
thus get following relationship macro plans Crars.
Theorem 32. polynomial p polynomials q, FFP([P]) frames
f = hV, D, Ai action sequences , macro plan ||||
q(||f ||) (p q)-Crar.
Proof. Let r polynomial macro plans 0 random accessed r(||0 ||)
time. Let together random access algorithm. |||| |||| + c
constant c. Define p p(n) = r(n) + c. get |||| |||| + c q(||f ||) + c
r(q(||f ||)) + c = p(q(||f ||)). Furthermore, runs r(||||) r(q(||f ||)) + c = p(q(||f ||))
space time. follows (p q)-Crar .
follows Theorem 29 every plan polynomial macro plan also
polynomial Crar. is, class polynomial macro plans subclass class
polynomial Crars, know proper subclass. way, results
imply cannot always find polynomial macro plan instance.
Corollary 33. polynomial p every solvable Strips instance
least one plan corresponding macro plan size p(||p||) polynomial hierarchy collapses.
163

fiBackstrom & Jonsson

Proof. Immediate Theorems 25 32.

6. Problem Reformulation
concluded seems little hope plans compactly
represented general case, turn idea problem reformulation see
help. may seem place context is, contrary,
quite logical step take. far, analysed planning problems plans,
results hold for. obvious that, when, results hold also
planning instances solved reformulating instances problem.
thus hypothetically possible could get around problems approach.
However, say something useful relevant this, sufficient look
naive approaches, polynomial reductions, investigate stronger criterion.
basic idea reformulation transform planning instance another equivalent instance, either another planning instance instance problem.
reformulation useful, solution new instance must use solve
original instance, something must gained. Often, reformulation used intention overall process faster solving original instance directly. Common
variants reformulate planning SAT, CSP, model checking another planning
problem. Reformulation planning SAT first suggested Kautz Selman
(1992) still popular approach planning. Long, Fox, Hamdi (2002) discuss
reformulation planning general Edelkamp, Leue, Visser (2007) discuss
connections model checking planning.
reformulation process viewed shown Figure 4. planning instance p
solution find directly using ordinary planning. Solving p via reformulation
instead follows indirect path figure. First p reformulated new instance
R(p) (of problem). instance solved produces solution R(p).
Finally, transformed back solution p.

p
Direct

R(p)
Indirect




Figure 4: Reformulation generation problem.
Obviously, reformulation cannot help us plans exponential. Even first
two steps indirect path took polynomial time polynomial size, would
still necessarily take exponential time transform exponential.
164

fiAlgorithms Limits Compact Plan Representations

is, problem inherently intractable whichever method use solve it. Reformulation
could potentially speed things up, could somehow used directly solution
original problem, would happen rarely, all.
situation different, though, consider decision problem rather
generation problem, is, ask plan whether plan not.
case use solution R(p) directly, since decision problems two
possible answers, yes no. may thus escape inherent intractability. variant
reformulation shown Figure 5. Since exponential solution generated case,
reformulation could potentially efficient. know decision problem
Strips PSPACE-complete general case. reformulated problem easier
solve, could beneficial first reformulate p R(p) ask instance
solution not. would possible check solution
embarking generating possibly exponentially long plan. Consider, instance,
3S class (Jonsson & Backstrom, 1998b) plans may exponential size
always possible decide polynomial time plan. thus seems like case
reformulating decision problems interesting one look at,
give improvement, hardly improvement plan generation
via reformulation either.

p
Direct

R(p)
Indirect

Yes/No

Yes/No

Figure 5: Reformulation decision problem.
Let PE(Strips) denote decision problem (that is, plan existence) Strips.
following two results trivial, illustrative.
Theorem 34. a) exists decision problem X function R holds
p PE( Strips) R(p) X p R(p) answer. b)
complexity class C, decision problem X C polynomial-time computable
function R holds p PE( Strips) R(p) X p R(p)
answer, PSPACE C.
Proof. a) Let X = PE(Strips) R identity function. b) Immediate, since R
polynomial reduction PE(Strips) X.
cases reformulate PSPACE-complete problem PSPACE-complete problem, interesting. prove anything better, must obviously
look X R useful restrictions.
165

fiBackstrom & Jonsson

important note reformulating planning NP-complete problem, instance SAT, magically make planning NP-complete. reason
Strips planning PSPACE-complete allows exponential solutions. soon
restrict solutions bounded fixed polynomial, planning belongs
NP. Furthermore, encodings planning instances SAT typically use atoms encode
actions appear position plan, is, exponential number extra
atoms required general case. Hence, either original problem already
NP blow instance exponentially reformulating SAT.
latter case, complexity results longer comparable. Also note, deliberately restrict ask plan certain length shorter,
actually solving restricted version optimization problem, also case
planning would harder. fact, seems unlikely planning general
could reformulated problem NP. order avoid straightforward naive
approaches reformulation consider analyse reformulations defined follows.
Definition 35. Let p = hV, A, I, Gi Strips instance, let f = hV, Ai let = hI, Gi.
Let X decision problem. reformulation PE(Strips) X pair hR, ri
functions maps every instance p = hf , PE(Strips) corresponding instance
x = R(r(f ), ) X p x answer. hR, ri polynomial
reformulation also fixed polynomials p, q
1) ||r(f )|| O(p(||f ||))
2) R computable O(q(||r(f )|| + ||d ||)) time.
thus consider reformulation involves two functions, R r. Function r
main reformulation function, intended reformulate difficult part instance.
even require function computable, require exists. Function
R used transform initial goal descriptions something similar
new instance use, combine result delivered r proper instance
X. noted reformulation concept similar, although identical,
compilation concept used Nebel (2000).
Theorem 36. polynomial reformulation PE( Strips) X NP,
unless polynomial hierarchy collapses.
Proof. Suppose hR, ri reformulation. arbitrary integer n > 0, let f un = hVn ,
defined Construction 16, without action acs, let = hEni , {goal}i,
0 < 2m(n) . follows trivially proof Lemma 17 instance
p = hf un , solution unsatisfiable (note SAT part
instance disarmed).
Construct advice-taking NTM input = hf un , ii, n > 0 0
< 2m(n) , representing binary using m(n) bits. Clearly, ||I || strictly increasing
depends n, let sn = ||I || (for arbitrary i). Define advice function
a(sn ) = r(f un ). (Note need know advice exists, find it).
Let first compute , compute x = R(a(sn ), ) = R(r(f un ), ),
polynomial time since a(sn ) given free advice. assumption, x X
answer yes p solution. Also assumption, X NP
166

fiAlgorithms Limits Compact Plan Representations

solve x guessing solution verifying polynomial time. Hence, deciding
p solution NP/poly.
arbitrary 3SAT instance , compute polynomial time. answers yes

n unsatisfiable. However, unsatisfiability 3SAT coNP-complete
follows coNP NP/poly, impossible unless polynomial hierarchy
collapses level 3, according Theorem 7b.
result pushed arbitrarily high polynomial hierarchy, thus making
unlikely planning could reformulated anything simpler all.
Corollary 37. polynomial reformulation hR, ri PE( Strips) decision
problem X pk , k > 1, unless polynomial hierarchy collapses level k + 2.
Proof sketch. Construction 16 demonstrates encode existential quantification
(choosing truth assignment sat part) universal quantification (enumerating
truth assignments unsat part). Hence, straightforward modify
analogous construction QBF formulae k alternations. Given that, rest
proof analogous proof Theorem 36, must use oracle pk1 .
argument leads pk pk /poly, impossible unless polynomial hierarchy
collapses level k + 2, according Theorem 7b.
Since proofs build Construction 16 rely exact position
actions follows also Theorem Corollary hold restricted unary
Strips instances only.

7. Discussion
section consists five parts. first transfer reformulation theorem
general result adding information guide planners, discuss explain
various results literature. discuss potential relationship causal
graphs compact representations. followed discussion results
paper could relevant plan explanation. fourth part discusses related
work compact representations compilation. section ends summary
results list open questions.
7.1 Reformulation Additional Information
Theorem 36 broader consequences reformulation. fact, implies
way help planner adding information planning frame, matter
information get it, unless accept amount information
always polynomially bounded frame size. following theorem function g
assumed represent additional information, need even computable.
require result polynomially bounded.
Theorem 38. Let p arbitrary polynomial. Consider function g algorithm

1. g maps Strips frames {0, 1} ||g(f )|| O(p(||f ||)) frames f
167

fiBackstrom & Jonsson

2. Strips instances p = hf, i, algorithm answers yes input hp, g(f )i
p plan.
runs polynomial time, polynomial hierarchy collapses.
Proof. Assume function g algorithm properties described
theorem. Define function r r(f ) = hf , g(f )i every Strips frame f . Also
define function R R(hf , xi, ) = hhf , i, xi every Strips instance p = hf ,
every string x. R(r(f ), ) = hhf , i, g(f )i = hp, g(f )i, hR, ri polynomial
reformulation Strips planning equivalent problem algorithm solve
polynomial time. However, reformulation exist according Theorem 36,
unless polynomial hierarchy collapses.
result extended upwards polynomial hierarchy way Corollary 37 (no longer requiring polynomial algorithm). means cannot
make planning simpler adding polynomial amount additional information frame
use clever algorithm use information planning. Planning remain
hard without extra information. may sometimes help add information particular instance somehow guide planner, systematic way
add information frame level required polynomial size.
planning literature rich methods intended make planning
efficient adding information one way another, although methods perhaps
always thought so. non-exhaustive list methods, similar,
abstraction hierarchies, macros, case-based planning, annotated planning landmarks.
State space abstraction planning goes back least Abstrips planner (Sacerdoti, 1974). main idea form abstraction hierarchies variables, thus
implicitly actions, planner plan important goals
first get abstract plan refined detailed plan. Knoblock
(1994) proposed algorithm automatically computing abstraction hierarchies.
algorithm successful many examples demonstrated sometimes
fail produce exponential plans instances linear optimal plan (Backstrom
& Jonsson, 1995). surprising since use abstraction hierarchy
viewed adding information planning frame. Automatic generation abstraction
hierarchies systematic way add information thus treated special case
Theorem 38.
Adding set macros planning frame similar using abstraction hierarchies, Knoblock (1993, pp. 110111) noted. planner uses abstraction searches
plan abstract space tries refine action subplan lower
lever. planner uses macros search abstract space instead already
set macros available correspond subplan. Finding macro works
expanded thus similar refining abstract action. Also use
macros demonstrated speed planning considerably certain cases (Korf,
1987). Macros typically added frame level, learning suggested
one method create macros automatically (Korf, 1985). However, macros typically treated action planner expanded finding
plan. Hence, addition macros may also backfire make planning less efficient,
168

fiAlgorithms Limits Compact Plan Representations

adding redundant actions may (Haslum & Jonsson, 2000). again,
surprising since addition macros addition information thus also covered
Theorem 38.
Case based planning (see Spalazzi, 2001, survey) uses stored plans plan skeletons
planner tries reuse modifying and/or extending them. one sense,
similar macro planning, advanced macros macro expansion methods.
One also view similar abstraction, plan must refined order
work. difference abstraction planner finds plan skeleton planning
abstract space case-based planner set plans stored database.
plans may handcoded, usually result learning previous planning
situations. well known also case-based planning may fail improve efficiency
cases used must similar actual instance hand (Nebel & Koehler, 1995;
Liberatore, 2005b). Also explained special case Theorem 38.
term annotated planning sometimes used refer number similar techniques adding control information planner. Examples Prodigy planner
(Veloso et al., 1995) allows control information like rules goal ordering
Tlplan (Bacchus & Kabanza, 2000) allows adding temporal-logic axioms control
planner. techniques good using hand-tailored control rules/axioms
particular application domain, immediate Theorem 38 cannot help
us general case.
Planning landmarks (Hoffmann, Porteous, & Sebastia, 2004) idea adding
explicit subgoals (called landmarks) planning instance. intention tell
planner landmarks must achieved plan order achieve overall
goal. Landmarks may also ordered, guide planner. However,
authors point out, deciding variable value (or logic formula) necessary
subgoal PSPACE-complete problem. Hence, one usually considers incomplete
sets landmarks. interestingly, landmarks differ previous methods
important aspect; landmarks added instance level, frame level.
Although might quite rigid difference practice, seems fundamental
essence. Hence, adding landmarks non-uniform case adding information
thus immediately covered Theorem 38. meaningfully analyse non-uniform
case remains open question.
7.2 Causal Graphs
Knoblock (1994) defined ordering variables planning instance
used guidance finding abstraction hierarchies. ordering variables
fundamental also 3S class (Jonsson & Backstrom, 1998b) ordering implicitly
defined abstraction hierarchy. concept ordering variables
intention defining abstraction hierarchy, define tractable subclasses etc. nowadays
usually referred causal graph (see Chen & Gimenez, 2010, survey using
properties causal graph define tractable subclasses planning). Many papers still
use Knoblocks definition, follows:
every Strips action let Vpre(a) = Atoms(pre(a)) Vpost(a) = Atoms(post(a)). Let
169

fiBackstrom & Jonsson

f = hV, Ai Strips frame. causal graph f directed graph GCG = hV,
u, v V , u v u 6= v
u Vpre(a) Vpost(a) v Vpost(a) .
idea behind causal graphs strongly connected component graph
correspond abstraction level. applying definition examples
paper, find instance according Construction 16 causal graph containing
large strongly connected component. is, would possible form good
abstraction hierarchies based causal graphs. However, Theorem 25 says
plans instances seem likely useful compact representations anyway.
Plans binary counter Construction 5 polynomial Crars since
polynomial macro plans. Yet, whole causal graph instance also strongly
connected. hand, plans Gray counter Construction 6 exponential
polynomial Crars too, causal graph acyclic case. thus seems
causal graph type used Knoblock many others sufficient,
even necessarily useful, tool judging plans compact representations.
variants causal graphs, though. One example interaction networks (Chen &
Gimenez, 2010). Another Jonssons (2009) refined version Knoblocks causal graph,
defined follows:
Let f = hV, Ai Strips frame. refined causal graph f directed graph
GRCG = hV, u, v V , u v u 6= v either
1) u Vpre(a) Vpost(a) v Vpost(a)
2) u, v Vpost(a) either
a) a0 u Vpost(a0 ) v 6 Vpost(a0 )
b) a0 u 6 Vpost(a0 ) v Vpost(a0 ) .

major difference variant Knoblocks two variables
appear postcondition action, necessarily form cycle
graph. Hence, unary actions longer prerequisite acyclic graphs. using
refined causal graph, Gray counter binary counter acyclic
graphs, Construction 16 still large strongly connected component. is,
three examples acyclicity refined causal graph correlates whether plans
compact representations not. correlation seems hold general,
difference two types causal graphs suggests study variations
concept could lead insight topic compact representations.
turn fruitful, would likely carry also areas causal
graphs used, like model checking (Wehrle & Helmert, 2009).
7.3 Plan Explanation
results paper also important plan explanation. Bidot et al. (2010)
suggest important planning systems (and AI systems) able
170

fiAlgorithms Limits Compact Plan Representations

explain plans decisions user, else user may trust system.
Similarly, Southwick (1991) writes:
seems general agreement amongst involved KBS research
order useful, system must able explain reasoning user.
Although consider advanced explanation methods, do, results
implications possible explain meaningfully. plan explanation, results
necessarily bad planning. Consider example plan instance
Construction 16. case 3SAT instance unsatisfiable, almost whole plan
consists alternating sequence form ha, b, a, b, a, b, . . .i, denotes either
actions aix 1 , . . . , aix n b denotes either actions avf 1 , . . . , avf . first
group actions together implement increment function, thus serve
purpose. Similarly, second group consists actions serve purpose
verifying clause false. abstraction action sequence could
form hinc, vfy, inc, vfy, inc, vfy, . . .i, inc denotes counting actions vfy
verification actions. purpose explanation, seems useful replace
actual actions abstract explanations functions. abstract sequence
easier understand, also allows using macros compress it, might
enhance explaining power. However, particular case, would probably even
useful abstract whole sequence loop, similar. essentially
boils partitioning set actions equivalence classes
class consist actions meaningfully seen implementing concept.
seems interesting important investigate one partition
set actions equivalence classes useful abstractions.
Plan explanation could also mean trace explanation model checking, would
analogously make long trace shorter abstract order make easier understand. well known close ties planning model checking,
model-checking traces viewed plans vice versa (Edelkamp et al., 2007).
number steps (or clock cycles) exponential number state variables;
even system divided subsystems, individual subsystems may exponential behaviour blows combined subsystems. exponential-size
plan/trace much use engineerit almost impossible task analyse
understand plan. planning/verifying system could autonomously find
repetitive patterns, even recursive repetitive patterns, plan abstract these,
would considerably easier understand happens why. fact, may
interesting execute plan, even simulator, compact understandable
explanation plan may actual goal.
Furthermore, Geib (2004) discusses problem combinatorial explosion plan recognition, exponential number plans may share plan prefix recognized far.
could clearly useful structured compact representations plan candidates
save space allow intelligent operations plans. Although
problem slightly different representing single long plan, seen
two problems related.
cases, primary purpose compact representation would thus find
exploit inherent structure plan, set plans, rather save space.
171

fiBackstrom & Jonsson

7.4 Additional Related Work
Liberatore (2005a) also studied problem representing plans compactly
similarities well differences results ours. contrast us,
considers also plans represented sequences states, sequences actions.
cases, considers random access representation well sequential representation. random-access representation action sequences (TA) essentially
Crar concept, except specifies must implemented circuit.
sequential representation action sequences (SA), hand, different
Csar concept. function takes state input returns next state.
Hence, like restricted type reactive plan Csar, results
thus immediately comparable ours. instance, contrary Theorem 29
proves TA representation cannot polynomially converted SA representation,
clearly shows SA Csar quite different concepts. proof
planning instances plans SA representation thus obviously carry
also Csars. Furthermore, uses planning language actions modelled
polynomial-size circuits. coincides class FFP([P]). Hence, hardness
proofs weaker since use restricted Strips language cases.
finally noted Liberatores Theorem 17 case TA representations
result similar Theorem 25, use different methods different conditions.
Nebel (2000) defines concept compilation planning languages. Although
ways similar reformulation concept, also differences. compilation
function planning frame another frame different planning language.
compilation need resource bounded resulting frame must polynomially
bounded original frame. initial state goal must possible translate
polynomial time. is, first step corresponds function r second
step essentially corresponds function R. However, Nebel considers compilation
planning languages also requires concept modularity present
approach. Furthermore, focus complexity decision problem
question whether size solutions preserved compilations.
7.5 Conclusions Open Questions
current status knowledge non-uniform compact representations
visualized Figure 6. outer box represents set solvable Strips instances
inner boxes represent subsets least one plan instance
Csar, Crar polynomial macro plan. know classes least one plan
instance guaranteed polynomial macro plan, like Towers Hanoi 3S.
also know classes least one plan instance Crar know
plans also polynomial macro plan. Construction 16 example.
open question plan Crar polynomial macro plan.
know classes instance plan Csar know
also Crar, example, class reversible systems. However, Construction 26
class instances plan Csar plan Crar,
case provides strict separation Csar Crar concepts. Whether
classes Strips instances plan Csar remains open question, though.
172

fiAlgorithms Limits Compact Plan Representations

plans
Plans w. Csar
Plans w. Crar

3S
Towers
Hanoi

Plans w. poly.
macro plans
?

?

anything
here?

reversible
systems

?

Construction 16

Construction 26

Figure 6: Current status Csars Crars.

thus following chain inclusions
polynomial macro plans Crar Csar Strips,
know first last inclusions strict.
Theorem 15 may seem weak since conditioned P 6= NP. Using similar
techniques proofs Lemma 27 Corollary 37 could encode QBF
arbitrary number alternating quantifiers and, hence, push result polynomial
hierarchy. However, remains open question condition could strengthened
way P 6= PSPACE.
argued number results hold also restricted unary
instances, cases also restrictions, otherwise largely unexplored
area. Little currently known various structural restrictions affect
results paper. applies whether plans Csars Crars
whether polynomial-size macro plans.
consider non-uniform case compact representations single plans
single instances, might also interesting consider non-uniform case reformulation adding information. However, seems straightforward since could
always reformulate instance single bit telling whether instance solvable not.
reformulation clearly interesting additional criteria necessary.
previously (Backstrom & Jonsson, 2011a) defined complexity measure based
padding intended insensitive plan length. concept seems related
Nebels compilations, although two concepts identical directly comparable.
thus reasonable believe also compact representations padded complexity
somehow related, especially since padded complexity motivated instances
long plans. However, yet know relationship is. Furthermore, would
173

fiBackstrom & Jonsson

interesting consider compilations look size compact representations
plan rather size explicit plans.
Acknowledgments
Malte Helmert, Anders Jonsson anonymous reviewers paper earlier
conference version provided valuable comments suggestions.

References
Bacchus, F., & Kabanza, F. (2000). Using temporal logics express search control knowledge planning. Artificial Intelligence, 116 (1-2), 123191.
Backstrom, C., & Jonsson, P. (2011a). PSPACE-complete planning problems equal
equal others. Proceedings 4th International Symposium Combinatorial Search (SoCS11) Castell de Cardona, Barcelona, Spain, pp.
1017.
Backstrom, C., & Jonsson, P. (2011b). Limits compact representations plans. Proceedings 21st International Conference Automated Planning Scheduling,
(ICAPS11), Freiburg, Germany, pp. 1825.
Backstrom, C. (1992). Computational Complexity Reasoning Plans. PhD dissertation, Linkoping University, Linkoping, Sweden.
Backstrom, C. (1995). Expressive equivalence planning formalisms. Artificial Intelligence,
76 (1-2), 1734.
Backstrom, C., & Jonsson, P. (1995). Planning abstraction hierarchies exponentially less efficient. Proceedings 14th International Joint Conference
Artificial Intelligence (IJCAI95), Montreal, QC, Canada, pp. 15991605.
Backstrom, C., & Klein, I. (1991). Planning polynomial time: SAS-PUBS class.
Computational Intelligence, 7, 181197.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11, 625656.
Balcazar, J. (1996). complexity searching implicit graphs. Artificial Intelligence,
86 (1), 171188.
Bidot, J., Biundo, S., Heinroth, T., Minker, W., Nothdurft, F., & Schattenberg, B. (2010).
Verbal plan explanations hybrid planning. Proceedings 24th MKWI
related PuK-workshop: Planung/Scheduling und Konfigurieren/Entwurfen (PuK10),
pp. 23092320.
Bille, P., Landau, G., Raman, R., Sadakane, K., Satti, S., & Weimann, O. (2011). Random
access grammar-compressed strings. Proceedings 22nd ACM-SIAM Symposium Discrete Algorithms (SODA11), San Fransisco, CA, USA, pp. 373389.
Bonet, B. (2010). Conformant plans beyond: Principles complexity. Artificial
Intelligence, 174 (3-4), 245269.
174

fiAlgorithms Limits Compact Plan Representations

Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search
belief space. Proceedings 5th International Conference Artificial Intelligence Planning Systems (AIPS00), Breckenridge, CO, USA, pp. 5261.
Boutilier, C., & Poole, D. (1996). Computing optimal policies partially observable
decision processes using compact representations. Proceedings 13th National
Conference Artificial Intelligence (AAAI96), Portland, OR, USA, Vol. 2, pp. 1168
1175.
Brafman, R. I., & Domshlak, C. (2003). Structure complexity planning unary
operators. Journal Artificial Intelligence Research, 18, 315349.
Buhrman, H., Jiang, T., Li, M., & Vitanyi, P. M. B. (2000). New applications
incompressibility method: Part II. Theoretical Computer Science, 235 (1), 5970.
Bulatov, A., & Dalmau, V. (2006). simple algorithm Maltsev constraints. SIAM
Journal Computing, 36 (1), 1627.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (1-2), 165204.
Cadoli, M., Donini, F., Liberatore, P., & Schaerf, M. (2000). Space efficiency propositional
knowledge representation formalisms. Journal Artificial Intelligence Research, 13,
131.
Charikar, M., Lehman, E., Liu, D., Panigrahy, R., Prabhakaran, M., Sahai, A., & Shelat, A.
(2005). smallest grammar problem. IEEE Transactions Information Theory,
51 (7), 25542576.
Chen, H., & Gimenez, O. (2010). Causal graphs structurally restricted planning. Journal Computer System Sciences, 76 (7), 579592.
Edelkamp, S., Leue, S., & Visser, W. (2007). Summary Dagstuhl seminar 06172
directed model checking. Directed Model Checking, No. 06172 Dagstuhl Seminar
Proceedings. Dagstuhl, Germany.
Galperin, H., & Wigderson, A. (1983). Succinct representations graphs. Information
Control, 56 (3), 183198.
Geib, C. (2004). Assessing complexity plan recognition. Proceedings 19th
National Conference Artificial Intelligence (AAAI04), San Jose, CA, USA, pp.
507512.
Gill, A. (1976). Applied Algebra Computer Sciences. Prentice Hall. Englewood
Cliffs, NJ.
Gimenez, O., & Jonsson, A. (2008). complexity planning problems simple
causal graphs. Journal Artificial Intelligence Research, 31, 319351.
Haslum, P., & Jonsson, P. (2000). Planning reduced operator sets. Proceedings
5th International Conference Artificial Intelligence Planning Systems (AIPS00),
Breckenridge, CO, USA, pp. 150158.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. Journal
Artificial Intelligence Research, 22, 215278.
175

fiBackstrom & Jonsson

Jansson, J., Sadakane, K., & Sung, W.-K. (2012). Compressed random access memory.
ArXiv, abs/1011.1708v2.
Johnson, D. S., Papadimitriou, C. H., & Yannakakis, M. (1988). generating maximal
independent sets. Information Processing Letters, 27 (3), 119123.
Jonsson, A. (2009). role macros tractable planning. Journal Artificial Intelligence Research, 36, 471511.
Jonsson, P., & Backstrom, C. (1998a). State-variable planning structural restrictions:
Algorithms complexity. Artificial Intelligence, 100 (1-2), 125176.
Jonsson, P., & Backstrom, C. (1998b). Tractable plan existence imply tractable
plan generation. Annals Mathematics Artificial Intelligence, 22 (3-4), 281296.
Jonsson, P., Haslum, P., & Backstrom, C. (2000). Towards efficient universal planning:
randomized approach. Artificial Intelligence, 117 (1), 129.
Karp, R. M., & Lipton, R. J. (1980). connections nonuniform uniform complexity classes. Proceedings 12th ACM Symposium Theory
Computing (STOC80), Los Angeles, CA, USA, pp. 302309.
Kautz, H. A., & Selman, B. (1992). Planning satisfiability. Proceedings 10th
European Conference Artificial Intelligence (ECAI92), Vienna, Austria, pp. 359
363.
Knoblock, C. A. (1993). Generating Abstraction Hierarchies: Automated Approach
Reducing Search Planning. Kluwer Academic Publishers. Norwell, MA.
Knoblock, C. A. (1994). Automatically generating abstractions planning. Artificial
Intelligence, 68 (2), 243302.
Korf, R. E. (1985). Macro-operators: weak method learning. Artificial Intelligence,
26 (1), 3577.
Korf, R. E. (1987). Planning search: quantitative approach. Artificial Intelligence,
33 (1), 6588.
Liberatore, P., & Schaerf, M. (2010). size data structures used symbolic model
checking. ArXiv, abs/1012.3018.
Liberatore, P. (2005a). Complexity issues finding succinct solutions PSPACE-complete
problems. ArXiv, abs/cs/0503043.
Liberatore, P. (2005b). complexity case-based planning. Journal Experimental
Theoretical Artificial Intelligence, 17 (3), 283295.
Long, D., Fox, M., & Hamdi, M. (2002). Reformulation planning. Proceedings
5th International Symposium Abstraction, Reformulation Approximation
(SARA02), Kananaskis, AB, Canada, Vol. 2371 Lecture Notes Computer Science, pp. 1832. Springer.
Muscettola, N., Pandurang Nayak, P., Pell, B., & Williams, B. C. (1998). Remote agent:
boldly go AI system gone before. Artificial Intelligence, 103 (1-2),
547.
176

fiAlgorithms Limits Compact Plan Representations

Nebel, B. (2000). compilability expressive power propositional planning
formalisms. Journal Artificial Intelligence Research, 12, 271315.
Nebel, B., & Koehler, J. (1995). Plan reuse versus plan generation: theoretical
empirical analysis. Artificial Intelligence, 76 (1-2), 427454.
Rytter, W. (2003). Application Lempel-Ziv factorization approximation
grammar-based compression. Theoretical Computer Science, 302 (1-3), 211222.
Sacerdoti, E. D. (1974). Planning hierarchy abstraction spaces. Artificial Intelligence,
5 (2), 115135.
Southwick, R. W. (1991). Explaining reasoning: overview explanation knowledgebased systems. Knowledge Engineering Review, 6, 119.
Spalazzi, L. (2001). survey case-based planning. Artificial Intelligence Review, 16,
336.
Veloso, M. M., Carbonell, J. G., Perez, A., Borrajo, D., Fink, E., & Blythe, J. (1995). Integrating planning learning: PRODIGY architecture. Journal Experimental
Theoretical Artificial Intelligence Research, 7 (1), 81120.
Wagner, K. (1986). complexity combinatorial problems succinct input representation. Acta Informatica, 23 (3), 325356.
Wehrle, M., & Helmert, M. (2009). causal graph revisited directed model checking.
Proceedings 16th International Symposium Static Analysis (SAS09), Los
Angeles, CA, USA, Vol. 5673 Lecture Notes Computer Science, pp. 86101.
Springer.
Williams, B., & Pandurang Nayak, P. (1997). reactive planner model-based executive. Proceedings 15th International Joint Conference Artificial Intelligence (IJCAI97), Nagoya, Japan, pp. 11781185.
Yap, C.-K. (1983). consequences non-uniform conditions uniform classes. Theoretical Computer Science, 26, 287300.

177

fiJournal Artificial Intelligence Research 44 (2012) 275-333

Submitted 12/11; published 6/12

Algorithms Generating Ordered Solutions Explicit
AND/OR Structures
Priyankar Ghosh
Amit Sharma
P. P. Chakrabarti
Pallab Dasgupta

priyankar@cse.iitkgp.ernet.in
amit.ontop@gmail.com
ppchak@cse.iitkgp.ernet.in
pallab@cse.iitkgp.ernet.in

Department Computer Science Engineering
Indian Institute Technology Kharagpur
Kharagpur-721302, India

Abstract
present algorithms generating alternative solutions explicit acyclic AND/OR
structures non-decreasing order cost. proposed algorithms use best first search
technique report solutions using implicit representation ordered cost.
paper, present two versions search algorithm (a) initial version best first
search algorithm, ASG, may present one solution generating
ordered solutions, (b) another version, LASG, avoids construction
duplicate solutions. actual solutions reconstructed quickly implicit
compact representation used. applied methods test domains,
synthetic others based well known problems including search
space 5-peg Tower Hanoi problem, matrix-chain multiplication problem
problem finding secondary structure RNA. Experimental results show efficacy
proposed algorithms existing approach. proposed algorithms
potential use various domains ranging knowledge based frameworks service
composition, AND/OR structure widely used representing problems.

1. Introduction
use AND/OR structures modeling solving complex problems efficiently
attracted significant amount research effort last decades. Initially,
AND/OR search spaces mostly used problem reduction search solving complex
problems, logical reasoning theorem proving, etc., overall problem
hierarchically decomposed conjunction disjunction subproblems (Pearl, 1984;
Nilsson, 1980). Subsequently, AND/OR structures also applied variety domains, e.g., representing assembly plans (Homem de Mello & Sanderson, 1990), generating VLSI floor-plans (Dasgupta, Sur-Kolay, & Bhattacharya, 1995), puzzle solving (Fuxi,
Ming, & Yanxiang, 2003), etc. Traditionally algorithm AO* (Pearl, 1984; Nilsson, 1980;
Martelli & Montanari, 1978, 1973; Chang & Slagle, 1971) used searching implicitly defined AND/OR structures. empirical study AO* found Bonet
Geffners (2005) work.
recent past renewed research interest towards application
AND/OR structures. various planning problems, including conditional planning
handle uncertainty, AND/OR structure (Russell & Norvig, 2003) natural form

c
2012
AI Access Foundation. rights reserved.

fiGhosh, Sharma, Chakrabarti, & Dasgupta

representation. problem generating solutions representations
studied extensively (Hansen & Zilberstein, 2001; Jimenez & Torras, 2000; Chakrabarti,
1994). Dechter Mateescu (2007) presented explicit AND/OR search space
perspective graphical models. Different search strategies (best first, branch bound,
etc.) AND/OR search spaces graphical models discussed Marinescu
Dechter (2007b, 2006). AND/OR search spaces also used solving mixed integer
linear programming (Marinescu & Dechter, 2005), 0/1 integer Programming (Marinescu
& Dechter, 2007a), combinatorial optimization graphical models (Marinescu & Dechter,
2009a, 2009b). AND/OR Multivalued Decision Diagrams (AOMDD), combine
idea Multi-Valued Decision Diagrams(MDD) AND/OR structures, presented
Mateescu, Dechter, Marinescu (2008) research along direction
found work Mateescu Dechter (2008). AND/OR search spaces also
applied solution sampling counting (Gogate & Dechter, 2008). Smooth Deterministic Decomposable Negative Normal Forms (sd-DNNF) (Darwiche, 2001) exhibit explicit
AND/OR DAG structure used various applications including compiling
knowledge (Darwiche, 1999), estimating belief states (Elliott & Williams, 2006), etc.
Apart domains planning, constraint satisfaction, knowledge based reasoning,
etc., AND/OR structure based techniques also widely used various application based
domains, e.g., web service composition (Gu, Xu, & Li, 2010; Shin, Jeon, & Lee, 2010; Gu,
Li, & Xu, 2008; Ma, Dong, & He, 2008; Yan, Xu, & Gu, 2008; Lang & Su, 2005), vision
graphics tasks (Chen, Xu, Liu, & Zhu, 2006), etc. Lang Su (2005) described
AND/OR graph search algorithm composing web services user requirements.
et al. (2008) advocated use AND/OR trees capture dependencies
inputs outputs component web services propose top-down search algorithm
generate solutions AND/OR tree. research uses AND/OR structures
context web service composition found works Gu et al. (2010,
2008), Shin et al. (2010) Yan et al. (2008). Chen et al. (2006) applied explicit
AND/OR structures cloth modeling recognition important problem
vision graphics tasks.
recent adoption AND/OR search spaces wide variety AI problems
warrants research towards developing suitable algorithms searching AND/OR
structures different perspectives. general setting, fundamental problem
remains find minimum cost solution AND/OR structures. given explicit
AND/OR graph structure, minimum cost solution computed using either topdown bottom-up approach. approaches based principle dynamic
programming complexity linear respect size search
space. Finding minimum cost solution explicit AND/OR structure fundamental
step approaches use implicit representation systematically explore
search space. particularly case AO* (Nilsson, 1980) potential
solution graph (psg) recomputed every time current explicit graph node
expanded. view recent research AND/OR structures used leveraged
wide variety problems ranging planning domain web service composition,
need generating ordered set solutions given AND/OR structure becomes
imminent. briefly mention areas ordered solutions useful.

276

fiGenerating Ordered Solutions Explicit AND/OR Structures

Ordered set solutions explicit AND/OR DAG used develop useful
variants AO* algorithm. Currently AO*, minimum cost solution computed whereas several variants A* algorithm exist, solutions often sought
within factor cost optimal solution. approaches (Ebendt & Drechsler, 2009;
Pearl, 1984) developed adapt A* algorithm using inadmissible heuristics,
leveraging multiple heuristics (Chakrabarti, Ghose, Pandey, & DeSarkar, 1989), generating
solutions quickly within bounded sub-optimality, etc. Typically techniques order
Open list using one evaluation function, next element expansion selected
ordered subset Open using criterion. Similar techniques developed
AO* search ordered set potential solutions made available. set
used node selection expansion instead expanding nodes current
best psg. opens interesting area significant research potential
existing variations A* algorithm extended AND/OR search spaces.
context model based programming, problem finding ordered set
solutions significant importance. Elliott (2007) used valued sd-DNNFs represent
problem proposed approach generate k-best solutions. Since valued sd-DNNFs
AND/OR structure, proposed approach possibly earliest algorithm
generating ordered set solutions AND/OR structure. problem finding
ordered set solutions graphical models studied Flerova Dechter (2011, 2010).
However techniques use alternative representations algorithm, AND/OR
search spaces constructed (Dechter & Mateescu, 2007) graphical models. Recent
research involving AOMDD based representation weighted structures suggested future
extensions towards generalizing Algebraic Decision Diagrams introduces notion
cost AOMDDs. envisage ordered set solutions finds useful applications
context research around AND/OR decision diagram based representation.
domain service composition, primary motivation behind providing set
alternative solutions ordered cost offer choices, trading specified
cost criterion (to limited extent) favor unspecified criteria (primarily
standpoint quality). Shiaa, Fladmark, Thiell (2008) presented approach
generating ranked set solutions service composition problem. Typically
quality criteria subjective nature difficult express terms single scalar cost
function able combine cost/price quality aspects together.
aspects quality often encountered context serving custom user requirements
user prefers minimize cost/price solution preserving his/her
preferences. example, booking holiday package specific destination, travel
service portal typically offers list packages various combinations attractions,
hotel options meal plans ordered single cost criterion, namely, cost
package. general product/solution composed number components
compositional flavor similar service composition becomes important present
user set alternative solutions ordered cost he/she select best
alternative according his/her preferences.
Dynamic programming formulations typically underlying AND/OR DAG structure, formally studied past (Martelli & Montanari, 1973). Besides
classical problems like matrix chain multiplication, many real world optimization problems offer dynamic programming formulations, alternative solutions ordered cost
277

fiGhosh, Sharma, Chakrabarti, & Dasgupta

useful practice. One example problem finding secondary structure
RNA (Mathews & Zuker, 2004) important problem Bioinformatics. RNAs
may viewed sequences bases belonging set {Adenine(A), Cytocine(C), Guanine(G), Uracil(U)}. RNA molecules tend loop back form base pairs
resulting shape called secondary structure. primary factor influences
secondary structure RNA number base pairings (higher number base pairings generally implies stable secondary structure). well established rules
base pairings, problem maximizing number base pairings interesting dynamic programming formulation. However, apart number base pairings,
factors influence stability, factors typically evaluated
experimentally. Therefore, given RNA sequence, useful compute pool
candidate secondary structures (in decreasing order number base pairings)
may subjected experimental evaluation order determine stable
secondary structure.
problem generating ordered set solutions well studied domains.
discrete optimization problems, Lawler (1972) proposed general procedure
generating k-best solutions. similar problem finding k probable configurations
probabilistic expert systems addressed Nilsson (1998). Fromer Globerson (2009)
addressed problem finding k maximum probability assignments probabilistic modeling using LP relaxation. context ordinary graphs, Eppstein (1990)
studied problem finding k-smallest spanning trees. Subsequently, algorithm
finding k-best shortest paths proposed Eppsteins (1998) work. Hamacher
Queyranne (1985) suggested algorithm k-best solutions combinatorial optimization problems. Algorithms generating k-best perfect matching presented
Chegireddy Hamacher (1987). researchers applied k-shortest path problem
practical scenarios, as, routing transportation, developed specific solutions
(Takkala, Borndorfer, & Lobel, 2000; Subramanian, 1997; Topkis, 1988; Sugimoto & Katoh,
1985). However none approaches seems directly applicable AND/OR structures. Recently schemes related ordered solutions graphical models (Flerova &
Dechter, 2011, 2010) anytime AND/OR graph search (Otten & Dechter, 2011)
proposed. Anytime algorithms traditional search space (Hansen & Zhou, 2007)
well addressed research community.
paper, address problem generating ordered set solutions explicit
AND/OR DAG structure present new algorithms. existing method, proposed
Elliott (2007), works bottom-up computing k-best solutions current node
k-best solutions children nodes. present best first search algorithm,
named Alternative Solution Generation (ASG) generating ordered set solutions.
proposed algorithm maintains list candidate solutions, initially containing
optimal solution, iteratively generates next solution non-decreasing order cost
selecting minimum cost solution list. iteration, minimum cost
solution used construct another set candidate solutions, added
current list. present two versions algorithm
a. Basic ASG (will referred ASG henceforth) : version algorithm
may construct particular candidate solution once;

278

fiGenerating Ordered Solutions Explicit AND/OR Structures

b. Lazy ASG LASG : Another version ASG algorithm constructs every candidate solution once.
algorithms, use compact representation, named signature, storing
solutions. signature solution, actual explicit form solution
constructed top-down traversal given DAG. representation allows
proposed algorithms work top-down fashion starting initial optimal
solution. Another salient feature proposed algorithms algorithms work
incrementally unlike existing approach. proposed algorithms interrupted
point time execution set ordered solutions obtained far
observed subsequent solutions generated algorithms resumed
again. Moreover, upper limit estimate number solutions required known
priori, algorithms optimized using estimate.
rest paper organised follows. necessary formalisms definitions
presented Section 2. Section 3, address problem generating ordered set
solutions trees. Subsequently Section 4, address problem finding alternative
solutions explicit acyclic AND/OR DAGs non-decreasing order cost. present two
different solution semantics AND/OR DAGs discuss existing approach well
proposed approach, along comparative analysis. Detailed experimental results,
including comparison performance proposed algorithms existing
algorithm (Elliott, 2007), presented Section 5. used randomly constructed
trees DAGs well well-known problem domains including 5-peg Tower
Hanoi problem, matrix-chain multiplication problem problem finding
secondary structure RNA test domain. time required memory used
generating specific number ordered solutions different domains reported
detail. Section 6, outline briefly applying proposed algorithms implicitly
specified AND/OR structures. Finally present concluding remarks Section 7.

2. Definitions
section, describe terminology AND/OR trees DAGs followed
definitions used paper. G = hV, Ei AND/OR directed acyclic graph,
V set nodes E set edges. G refer
nodes nodes DAG respectively. direction edges G
parent node child node. nodes G successors called terminal
nodes. non-terminal nodes G two types i) nodes ii) nodes .
V V set nodes G respectively, n = |V |, n = |V |,
n = |V |. start (or root) node G denoted vR . edges edges
edges emanate nodes nodes respectively.
Definition 2.a [Solution Graph] solution graph, S(vq ), rooted node vq V ,
finite sub-graph G defined as:
a. vq S(vq );
b. vq node G vq S(vq ), exactly one immediate
successors G S(vq );
c. vq node G vq S(vq ), immediate successors
G S(vq );
279

fiGhosh, Sharma, Chakrabarti, & Dasgupta

d. Every maximal (directed) path S(vq ) ends terminal node;
e. node vq successors G S(vq ).
solution graph G mean solution graph root vR .




Definition 2.b [Cost Solution Graph] G , every edge eqr E node vq
node vr finite non-negative cost ce (hvq , vr i) ce (eqr ). Similarly every node vq
finite non-negative cost denoted cv (vq ). cost solution defined recursively
follows. every node vq S, cost C(S, vq ) is:


cv (vq ), vq terminal node;






cv (vq ) + C(S, vr ) + ce (hvq , vr i) , vq node,

C(S, vq ) =
vr successor vq S;


P


C(S, vj ) + ce (hvq , vj i) , 1 j k, vq node
cv (vq ) +




degree k, v1 , . . . , vk immediate successors vq S.
Therefore cost solution C(S, vR ) also denoted C(S). denote
optimal solution every node vq opt(vq ). Therefore, optimal solution
entire AND/OR DAG G , denoted Sopt , opt(vR ). cost optimal solution
rooted every node vq G Copt (vq ), defined recursively (for minimum cost
objective functions) follows:


cv (vq ), vq terminal node;







cv (vq ) + min Copt (vj ) + ce (hvq , vj i) , 1 j k, vq node
Copt (vq ) =
degree k, v1 , . . . , vk immediate successors vq G ;




cv (vq ) + P Copt (vj ) + ce (hvq , vj i) , 1 j k, vq node




degree k, v1 , . . . , vk immediate successors vq G .
cost optimal solution Sopt G denoted Copt (vR ) or, alternatively,
Copt (Sopt ). objective function needs maximized, instead min function,
max function used definition Copt (vq ).



may noted possible one solution node
vq qualify optimal one, i.e., cost, cost
minimum. Ties optimal solution node vq resolved arbitrarily
one among qualifying solutions (determined tie-breaking) marked
opt(vq ).
AND/OR tree, = hV, Ei, AND/OR DAG additionally satisfies
restrictions tree structure i.e., one parent node node vq
. context AND/OR trees, use eq denote edge points
vertex vq . alternating AND/OR tree, = hV, Ei, AND/OR tree
restriction alternation nodes nodes. Every
child node either node terminal node, every children
node either node terminal node. use term solution tree denote
solutions AND/OR trees.
also discuss different solution semantics, namely tree based semantics, AND/OR
DAGs. Every AND/OR DAG converted equivalent AND/OR tree traversing
280

fiGenerating Ordered Solutions Explicit AND/OR Structures

intermediate nodes reverse topological order replicating subtree rooted
every node whenever in-degree traversed node 1. details
shown Procedure ConvertDAG. Suppose AND/OR DAG G converted
equivalent AND/OR tree . define solutions solutions G
tree based semantics.
Procedure ConvertDAG(G )
input : AND/OR DAG G
output: equivalent AND/OR tree
1 Construct list , non-terminal nodes G , sorted reverse topological
order;
2 empty
3
vq Remove first element ;
/* Suppose Ein (vq ) list incoming edges vq
*/
4
InDegree(vq ) > 1
5
2 InDegree(vq )
6
et Ein (vq )[i];
Replicate
sub-tree rooted vq vq root;
7
Modify target node et vq vq ;
8
9
end
10
end
11 end
paper use solution semantics defined Definition 2.a default
semantics solutions AND/OR DAGs. tree based semantics used,
explicitly mentioned.
2.1 Example

2, 34

h3i
3, 29

v1

v1

v2

h1i

h1i

h2i

v3

2, 37

v2

v4

2, 8

h1i

v5

h3i

h4i

v6

3, 11

v7
h1i

h1i

h2i

h2i

v9

v10

v11

v12

v13

v14

v15

v9

v10

5

7

6

9

12

15

20

5

7

Figure 1: Alternating AND/OR Tree
281

v6

2, 35

v8

3, 9

h1i

h1i

h1i

h3i

h4i

v7
h3i

2, 41

h4i

v5

40

12
h2i

v3

3, 43

v4

v8

4, 17

h2i

h5i

h1i

35
h5i

2, 89

17

h2i

Figure 2: AND/OR DAG

52

fiGhosh, Sharma, Chakrabarti, & Dasgupta

present example alternating AND/OR tree Figure 1. figure,
terminal nodes represented circle thick outline. nodes shown
figures outgoing edges connected semi-circular curve examples.
edge costs shown side edge within angled bracket. cost
terminal nodes shown inside box. every non-terminal node vq , pair costs,
cv (vq ) Copt (vq ), shown inside rectangle.
Figure 1 optimal solution every node shown using thick dashed edges
arrow head. optimal solution AND/OR tree traced following
thick dashed edges node v1 . cost optimal solution tree 34. Also,
Figure 2 shows example DAG; cost optimal solution DAG 89.

3. Generating Ordered Solutions AND/OR Trees
section address problem generating ordered solutions trees. use
notion alternating AND/OR trees, defined Section 2, present algorithms.
alternating AND/OR tree presents succinct representation correctness
proofs much simpler alternating AND/OR trees. Appendix C show every
AND/OR tree converted equivalent alternating AND/OR tree respect
solution space.
worth noting search space problems (e.g. search space multipeg Tower Hanoi problem) exhibit alternating AND/OR tree structure. Moreover,
algorithms presented alternating AND/OR trees work without modification
general AND/OR trees. section, first present existing algorithm (Elliott,
2007) briefly, present proposed algorithms detail.
3.1 Existing Bottom-Up Evaluation Based Method Computing Alternative
Solutions
illustrate working existing method proposed Elliott (2007)
computing alternative solutions trees using example alternating AND/OR tree.
method (will referred BU henceforth) computes k-best solutions bottomup fashion. every node, vq , k-best solutions computed k-best solutions
children vq . overall idea follows.
a. node vq , solution rooted vq obtained selecting solution
child. Therefore k-best solutions vq computed selecting top k solutions
entire pool consisting solutions children.
b. case nodes, every child node vq k solutions.
solution rooted node vq obtained combining one solution every
child vq . Different combinations solutions children nodes vq generate
different solutions rooted vq . Among combinations, top k combinations
stored vq .
Figure 3 show working existing algorithm. every intermediate node
2-best solutions shown within rounded rectangle. every node vq , ith -best
cost.
solution rooted vq shown triplet form |{z}
: < child, solidx >, |{z}
{z
}
|
example, node v1 second best solution shown 2 : hv2 , 2i, 37; means
282

fiGenerating Ordered Solutions Explicit AND/OR Structures

2nd best solution rooted v1 obtained selecting 2nd best solution v2 .
Similarly, every node vq , ith solution rooted vq shown triplet
form : |sol vec|, cost triplets. sol vec comma separated list solution indices
every element sol vec corresponds child vq . j th element sol vec
shows index solution j th child. example, 2nd best solution rooted v2
shown 2 : |2, 1|, 32. means 2nd best solution rooted v2 computed using
2nd best solution 1st child (which v5 ) best solution (1st ) 2nd
child (which v6 ). index sol vec corresponds child shown placing
child node name every index position.

2, 34

h3i

3, 29

v2

h5i

2, 8

v5

1 : hv2 , 1i, 34
2 : hv2 , 2i, 37

v1

h1i

h2i

v5 v6
1 : |1, 1|, 29
2 : |2, 1|, 32

v3

2, 37

35

h1i

1 : hv9 , 1i, 8
2 : hv10 , 1i, 11

v7 v8
1 : |1, 1|, 37
1 : |1, 2|, 40

v4

h3i

h4i

v6

3, 11

v7

1 : hv11 , 1i, 11
2 : hv12 , 1i, 15

12

h3i

h2i

v8

4, 17

h1i

h1i

1 : hv13 , 1i, 17
2 : hv14 , 1i, 20
h2i

h1i

h2i

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 3: Example working existing algorithm
existing method works input parameter k, i.e., number solutions
generated known priori. Also method inherently incremental
nature, thus perform efficiently solutions needed demand, e.g.,
first, top 20 solutions needed, next 10 solutions needed. case
top 20 solutions recomputed computing next 10 solutions, i.e.,
21st solution 30th solution. Next present proposed top-down approach
suffer limitation.
3.2 Top-Down Evaluation Algorithms Generating Ordered Solutions
far discussed existing approaches primarily use bottom-up approach
computing ordered solutions. propose top-down approach generating alternative solutions non-decreasing order cost. may noted top-down
283

fiGhosh, Sharma, Chakrabarti, & Dasgupta

approach incremental nature. use edge marking based algorithm, Alternative
Solution Generation (ASG), generate next best solutions previously generated solutions. initial phase ASG algorithm, compute optimal solution
given alternating AND/OR tree perform initial marking edges.
following terminology notions used describe ASG algorithm.
context AND/OR trees, use eq denote edge points vertex vq .
use following definitions describing proposed top-down approaches.
Definition 3.c [Aggregated Cost] AND/OR DAG G , aggregated cost, ca ,
edge eij node vi node vj , defined : ca (eij ) = ce (eij ) + Copt (vj ).


v1

2, 34

[e2 : 5]

2,3 : 5

h3i

3, 29

3,4 : 1

v2

h1i

h2i

[e3 : 1]

v3

2, 37

v4

35
h5i

2, 8

h1i

v5

h4i

v6

3, 11

h3i

v7

v8

4, 17

12
[e11 : 4]

[e9 : 3]
h1i

9,10 : 3

h2i

h2i

[e13 : 3]
h3i

11,12 : 4

h1i

[e14 : 6] h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 4: Example OR-edge marking swap option
Marking edge : notion marking edge follows.
node vq , L(vq ) list edges vq sorted non-decreasing order aggregated
cost edges. define (i,i+1) difference cost edges, ei
ei+1 , ei ei+1 emanate node vq , ei+1 edge next
ei L(vq ). Procedure MarkOR describes marking process edges
node. Intuitively, mark represents cost increment incurred corresponding
edge replaced solution next best sibling. edge maximum
aggregated cost marked.
Consider solution, Scur , containing edge ei = (vq , vi ), ei Eopt (Scur ).
mark ei cost increment incurred construct next best solution
Scur choosing another child vq . Figure 4 marks corresponding edges
e2 , e3 , e9 , e11 , e13 , e14 [e2 : 5], [e3 : 1], [e9 : 3], [e11 : 4], [e13 : 3], [e14 : 6].
284

fiGenerating Ordered Solutions Explicit AND/OR Structures

Procedure MarkOR(vq )
1

2
3
4
5
6
7
8

Construct L(vq ) ; /* List edges vq sorted non-decreasing order ca
values */
count number elements L(vq ) ;
1 = count 1
ec L(vq )[i] ;
en L(vq )[i + 1] ;
tmp = (ca (en ) ca (ec )) ;
Mark ec pair [en : tmp ] ;
end

Definition 3.d [Swap Option] swap option ij defined three-tuple hei , ej , ij
ei ej emanate node vq , ej edge next ei L(vq ),
ij = ca (ej ) ca (ei ). Also, say swap option ij belongs node vq .


Consider node vq sorted list L(vq ). may observed L(vq )
every consecutive pair edges forms swap option. Therefore, k edges L(vq ),
k1 swap options formed. node vq , swap options ranked according
rank original edges L(vq ). Figure 4 swap options : (2,3) = he2 , e3 , 5i,
(3,4) = he3 , e4 , 1i, (9,10) = he9 , e10 , 3i, (11,12) = he11 , e12 , 4i, (13,14) = he13 , e14 , 3i,
(14,15) = he14 , e15 , 6i. Consider node v1 L(v1 ) = he2 , e3 , e4 i. Therefore, swap
options, (2,3) (3,4) , belong v1 . node v1 , rank (2,3) (3,4) 1 2
respectively.
Definition 3.e [Swap Operation] Swap operation defined application swap
option ij = hei , ej , ij solution Sm contains edge ei following way:
. Edge e
a. Remove subtree rooted vi Sm . Let modified tree Sm

original edge ij .
, constructed previous step. Let
b. Add subtree opt(vj ) Sm
. Edge e swapped edge .
newly constructed solution Sm
j
ij

Intuitively, swap operation ij = hei , ej , ij constructs new solution Sm


Sm contains edge ei . Moreover, cost Sm increased ij compared cost
Sm C(Sm , vi ) = Copt (vi ).



proposed algorithms use swap option based compact representation, named signature, storing solutions. Intuitively, alternative solution described
set swap operations performed optimal solution Sopt . interesting observe
applying ordered sequence swap options, h1 , , k i, application
swap operation creates intermediate alternative solution. example,
first swap option sequence, 1 , applied optimal solution, Sopt , new solution, say S1 , constructed. Then, 2nd swap option, 2 , applied S1 , yet
another solution S2 constructed. Let Si denote solution obtained applying
swap options, 1 , , , Sopt sequence. Although, ordered sequence swap
options, like h1 , , k i, used compact representation alternative
solution, following key points important observe.
A. Among possible sequences generate particular solution, need preclude
sequences contain redundant swap options (those swap options whose orig285

fiGhosh, Sharma, Chakrabarti, & Dasgupta

inal edge present solution applied). formally defined
later superfluous swap options. Also order applying swap options another important aspect. two swap options, j 1 < j k
source edge j belongs sub-tree included solution
Si applying Si1 . case, apply j place , i.e.,
apply j directly Si1 , effect source edge j present
Si1 , i.e., swapping location j sequence, j becomes
redundant swap option solution constructed would different swapped
sequence original sequence. formally define order relation pair
swap options based observation later part section formalize
compact representation solutions based order relation.
B. Suppose swap option j belongs node vpj . important observe
application j Sj1 construct Sj , invalidates application
swap options belong edge path root node vpj
solution Sj . Sj application swap option
belongs edge path root node vpj would make swap
vpj redundant. fact, swap option belonging node vpi , 1 j,
application swap options belong edge path
root node vpi invalidated solution Sj reason. condition
restricts set swap options applied particular solution.
C. Finally, two swap options j 1 < j k
j independent other, is, (a) applying Si1 subsequently
application j Sj1 , (b) applying j Si1 subsequently application
Sj1 , ultimately construct solution. happens
original edges j present Si1 , thus application one swap option
influence application other. However, desirable use one
way generate solution Sj . Section 3.3, propose variation top-down
approach (called LASG) resolves issue.
Definition 3.f [Order Relation R] define order relation, namely R, pair
swap options follows.
a. path vi vr , ei er edges, qi rj
swap options, (qi , rj ) R. example, Figure 4 ((3,4) , (13,14) ) R.
b. pq = hep , eq , pq rt = , et , rt two swap options vq = vr ,
(pq , rt ) R. Figure 4 ((2,3) , (3,4) ) R.


Implicit Representation Solutions : use implicit representation
storing every solution optimal one. solutions constructed
optimal solution applying set swap options optimal solution
following way. (i , j ) R, applied j . Therefore, every solution
represented sequence swap options, appears j (i , j ) R.
Intuitively application every swap option specifies swapped edge
part solution. Since swap options applied specific order R, may
happen edge become part solution due application
earlier swap option may get swapped due application later swap option.
286

fiGenerating Ordered Solutions Explicit AND/OR Structures

Definition 3.g [Superfluous Swap Option] Consider sequence swap options =
h1 , , corresponding solution Sm . Clearly possible swap option, ,
1 m, present sequence original edge
present solution Si1 constructed successive applications swap
options 1 , , i1 solution Sopt . application effect Si1 , i.e.,
solution Si identical solution Si1 . swap option superfluous swap
option respect sequence swap options corresponding solution Sm .


Property 3.1 sequence swap options corresponding solution minimal,
superfluous swap option.
property follows definition superfluous swap options notion
implicit representation solution.
Definition 3.h [Signature Solution] minimal sequence swap options corresponding solution, Sm , defined signature, Sig(Sm ), solution.
may noted optimal solution Sopt alternating AND/OR tree ,
Sig(Sopt ) = {}, i.e., empty sequence. possible construct one signature
solution, R partial order. important observe different signatures
particular solution equal length sets swap options corresponding
different signatures also equal. Therefore set swap options corresponding
signature canonical representation signature. Henceforth use set
notation describing signature solution.
v1

2, 39

2,3 : 5

h3i

3, 29

3,4 : 1
h2i

v3

v2

h1i

2, 37

v4

35
h5i

2, 8

h1i

v5

h3i

h4i

v6

3, 11

v7

v8

4, 17

12
h2i

h2i
h1i
9,10 : 3

h3i

11,12 : 4

h1i

h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 5: solution, S2 , AND/OR tree shown Figure 4
Figure 5 show solution, say S2 , AND/OR tree shown Figure 4.
solution highlighted using thick dashed lines arrow head. pair, cv (vq ), C(S2 , vq ),
287

fiGhosh, Sharma, Chakrabarti, & Dasgupta

shown within rectangles beside node vq solution S2 , used rectangles rounded corner whenever C(S2 , vq ) 6= Copt (vq ). Since S2 generated applying
swap option (2,3) solution Sopt , signature S2 , Sig(S2 ) = h(2,3) i. Consider
another sequence, 2 = h(2,3) , (9,10) i, swap options. worth noting 2 also
represents solution S2 . second swap option 2 , namely 9,10 ,
applied solution constructed applying (2,3) Sopt source edge (9,10) ,
e9 , present solution. Hence (9,10) superfluous swap option 2 .
Definition 3.i [Vopt Eopt ] solution graph Sm AND/OR DAG G ,
define set nodes,
fiVopt (Sm ), set edges, Eopt (Sm ), as:
a. Vopt (Sm ) = vq fi vq Sm solution graph Sm (vq ) identical solution graph
opt(vq )
fi


b. Eopt (Sm ) = epr fi edge epr Sm , vr Vopt (Sm )
Clearly, node vq Vopt (Sm ), vq present Sopt , (a) solution graph
Sm (vq ) identical solution graph Sopt (vq ), (b) C(Sm , vq ) = Copt (vq )


Definition 3.j [Swap List] swap list corresponding solution Sm , L(Sm ), list
swap options applicable Sm . Let Sig(Sm ) = {1 , , } i, 1 m,
swap option belongs node vpi . application swap options
belong edges path root node vpi invalidated solution
Sm . Hence, remaining swap options invalidated Sm applied
Sm constructing successor solutions Sm .
important observe swap option , source edge belongs
Eopt (Sm ), application invalidated Sm . Hence, solution Sm , construct L(Sm ) restricting swap operations edges belonging Eopt (Sm ).
Moreover, condition also ensures cost newly constructed solution
computed directly form cost parent solution value applied swap
constructed form
option. elaborate, suppose solution Sm
applying jk .

) = C(S ) +
cost Sm computed directly form C(Sm ) jk : C(Sm

jk
ej Eopt (Sm ). Procedure ComputeSwapList(Sm ) describes details computing swap
options given solution Sm .


Procedure ComputeSwapList(Sm)
1
2
3

4
5
6

L(Sm ) ; Compute Eopt (Sm );
foreach edge ec Eopt (Sm )
exists swap option edge ec
/* Suppose ec emanates node vq ec = L(vq )[i]. Also ec
marked pair htmp , en i, en = L(vq )[i + 1]
*/
cn hec , en , tmp i; Add cn L(Sm );
end
end

swap list optimal solution, L(Sopt ), Figure 4, {(2,3) , (9,10) }.
solution S1 , shown Figure 6, Vopt = {v6 , v10 }, except node v6 v10 ,
nodes vi S1 , opt(vi ) 6= S1 (vi ). also rectangles rounded corner used
C(S1 , vq ) 6= Copt (vq ). Therefore, Eopt = {e6 , e10 }. Since exists swap option
288

fiGenerating Ordered Solutions Explicit AND/OR Structures

v1

2, 37

2,3 : 5

h3i

3, 32

3,4 : 1
h2i

v2

v3

h1i

2, 37

v4

35
h5i

2, 11

h1i

v5

h4i

v6

3, 11

h3i

v7

v8

4, 17

12
h2i
h1i
9,10 : 3

h2i

h3i

11,12 : 4

h1i

h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 6: solution, S1 , AND/OR tree shown Figure 4
edges, e6 e10 , swap list solution S1 , L(S1 ) = . Hence, solution
Sm , L(Sm ) may empty, though Vopt (Sm ) never empty.
Although use notation ij denote swap option edge ei original
edge edge ej swapped edge, succinct representation, also use single
subscript, 3 , k , ij etc., represent swap option. alternative representation
swap options relate edge.
Definition 3.k [Successors Predecessors Solution] set successors
predecessors solution
fi Sm defined as:
fi constructed
a. Succ(Sm ) = {Sm
applying swap option

belongs swap
fi list Sm }
fi Succ(S )}


b. P red(Sm ) = {Sm



Property 3.2 solution Sm alternating AND/OR tree following state P red(S ), C(S ) C(S )
ment holds: Sm




property follows definitions. One special case requires attention. Consider
) = C(S ) P red(S ). case arise swap
case C(Sm



option cost 0 applied Sm . occurs case tie.
3.2.1 ASG Algorithm
present ASG, best first search algorithm, generating solutions alternating
AND/OR tree non-decreasing order costs. overall idea algorithm
follows. maintain list, Open, initially contains optimal solution Sopt .
point time Open contains set candidate solutions next best
289

fiGhosh, Sharma, Chakrabarti, & Dasgupta

solution non-decreasing order cost selected. iteration minimum cost
solution (Smin ) Open removed Open added another list, named, Closed.
Closed list contains set ordered solutions generated far. successor
set Smin constructed successor solution currently present
Open well already added Closed inserted Open. However
optimization, use sublist Closed, named TList, store relevant portion Closed
checking respect solutions TList sufficient figure whether
successor solution already added Closed. interesting observe
algorithm interrupted time set ordered solutions computed far
obtained. Also, algorithm resumed solutions needed.
details ASG algorithm presented Algorithm 4.
Algorithm 4: Alternative Solution Generation (ASG) Algorithm

1

2
3
4
5
6
7
8
9
10
11
12

13
14
15

16
17
18
19
20

input : alternating AND/OR tree
output: Alternative solutions non-decreasing order cost
Compute optimal solution Sopt , perform edge marking populate
swap options;
Create three lists, Open, Closed, TList, initially empty;
Put Sopt Open;
lastSolCost C(Sopt );
Open empty
Smin Remove minimum cost solution Open ;
lastSolCost < C(Smin )
Remove elements TList;
lastSolCost C(Smin );
end
Add Smin Closed TList;
Compute swap list, L(Smin ), Smin ;
/* Construct Succ(Smin ) using L(Smin ) add new solutions Open
*/
foreach ij L(Smin )
Construct Sm applying ij Smin ;
Construct signature Sm , Sig(Sm ), concatenating ij Sig(Smin );
/* Check whether Sm already present Open TList
*/
(Sm Open) (Sm TList)
Add Sm Open;
end
end
Report solutions Closed;

pseudo-code Line-1 Line-4 computes optimal solution Sopt , performs
marking edges, populates swap options, initializes Open, Closed TList.
loop Line-10 responsible generating new solution every time executed
long Open empty. Line-6 ASG algorithm, solution
current minimum cost solution Open (Smin ) selected removed Open.
TList populated maintained Line-7 Line-10. loop Line-13 generates

290

fiGenerating Ordered Solutions Explicit AND/OR Structures

successor solutions Smin one one adds newly constructed solutions
Open newly constructed solution already present Open well added
TList (Line-16 checking). proof correctness Algorithm 4 presented
Appendix A. discuss following issues related Algorithm 4.
Checking Duplication : order check whether particular solution Si already
present Open TList, signature Si matched signatures solutions
already present Open TList. sufficient check equality
set swap options respective signatures set unique particular
solution. may noted TList used optimization, avoids searching
entire Closed list.
Resolving Ties : removing minimum cost solution Open list, tie
may encountered among set solutions. Suppose tie among set Stie =
{S1 , , Sk }. ties resolved favor predecessor solutions, is,


Si , Sj Stie , (If Si predecessor Sj ) (Si removed Sj )
cases ties resolved arbitrarily favor solution
added Open first.
3.2.2 Working ASG Algorithm
illustrate working ASG algorithm example AND/OR tree shown
Figure 4. contents different lists obtained first iterations outermost
loop shown Table 1. use signature solution representation
purpose. solutions already present Open also constructed expanding
current Smin , highlighted under-braces.
It.
1
2
3
4

Smin
{}
{(9,10) }
{(2,3) }
{(2,3) , (3,4) }

L(Smin )
(2,3) , (9,10)

(3,4)
(11,12) , (13,14)

5

{(2,3) , (3,4) ,
(13,14) }

(11,12) , (14,15)

6

{(2,3) , (3,4) ,

(13,14)

(11,12) }

7

{(2,3) , (3,4) ,
(13,14) , (11,12) }

(14,15)

Open
{(2,3) }, {(9,10) }
{(2,3) }
{(2,3) , (3,4) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) , (11,12) }
{(2,3) , (3,4) , (13,14) , (14,15) }
{(2,3) , (3,4) , (13,14) , (11,12) },
|
{z
}
{(2,3) , (3,4) , (13,14) , (14,15) }

Closed
{}
{}, {(9,10) }
{}, {(9,10) }, {(2,3) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{(2,3) , (3,4) , (13,14) }
{}, {(9,10) }, {(2,3) },

TList
{}
{(9,10) }
{(2,3) }
{(2,3) , (3,4) }
{(2,3) , (3,4) ,
(13,14) }
{(2,3) , (3,4),

{(2,3) , (3,4) }
(11,12) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) , (14,15) }, {}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) ,
{(2,3) , (3,4) , (13,14) ,
{(2,3) , (3,4) }
(13,14) , (11,12) }
(11,12) , (14,15) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) ,
(11,12) }

Table 1: Working ASG Algorithm
291

fiGhosh, Sharma, Chakrabarti, & Dasgupta

entering outermost loop (Line 5), ASG computes optimal solution
Sopt , populates swap options, inserts Sopt Open. Thus, point time, Open
contains optimal solution Sopt ; Closed TList empty. first iteration
Sopt (the signature Sopt {}) selected removed Open. swap list
Sopt , L(Sopt ), computed. L(Sopt ), consists two swap options, namely (2,3) (9,10) .
ASG adds two new solutions {(2,3) } {(9,10) } Open. solution Sopt added
Closed TList.
next iteration, solution {(9,10) } minimum cost among solutions
currently Open, selected removed Open, swap list {(9,10) } computed
subsequently {(9,10) } added Open TList. happens, L({(9,10) }) = (owing
fact Eopt = {e6 , e10 } exists swap option edges, e6 e10 ),
thus nothing else happens iteration. next iteration, solution {(2,3) } removed
Open ultimately solution {(2,3) , (3,4) } added Open adding {(2,3) }
Closed well TList. Next two iterations proceed similar fashion. Now, consider
6th iteration. iteration, solution {(2,3) , (3,4) , (11,12) } removed Open,
successor set one solution, {(2,3) , (3,4) , (11,12) , (13,14) }, already present
Open (inserted Open Iteration-5). Therefore, solution {(2,3) , (3,4) , (11,12) , (13,14) }
inserted Open again. shown Iteration-7 Table 1.
3.3 Technique Avoiding Checking Duplicates Open
section, present technique avoid checking done adding newly
constructed solution Sm Open determine whether Sm already present Open.
first explain scenario example, portion previous example
shown Figure 4. Figure 7-10, solutions shown using thick dashed line
arrow head. Also rectangles rounded corner used highlight fact
corresponding node marked solution belong Vopt set solution.
v4

2, 37
h4i

3, 11
h2i

4, 17
h3i

11,12 : 4

h4i

h3i

v7
h1i

v4

2, 44

v8

3, 15

h1i

13,14 : 3

h3i

v7

4, 20
h3i

h2i

v8
h1i

h1i

v11

v12

v13

v14

v11

v12

v13

v14

6

9

12

15

6

9

12

15

Figure 8: Solution S3

Figure 7: Running Example

Consider solutions S1 , S2 S3 (shown Figure 9, Figure 10 Figure 8).
(a) L(Sopt ) = {(11,12) , (13,14) }, (b) Succ(Sopt ) = {S1 , S2 },
(c) Sig(S1 ) = {(13,14) }, (d) Sig(S2 ) = {(11,12) }, (e) Sig(S3 ) = {(13,14) , (11,12) }.
Algorithm 4 constructs solution S3 (shown Figure 8) adding Open twice
(i) part adding Succ(S1 ) Open, (ii) adding Succ(S2 ) Open.
292

fiGenerating Ordered Solutions Explicit AND/OR Structures

v4

2, 40

h4i

3, 11
h2i

4, 20
h3i

11,12 : 4

h4i

h3i

v7

v4

2, 41

v8

h1i

3, 15

h1i

h3i

v7

4, 17
h3i

h2i

h1i

v8
h1i

13,14 : 3

v11

v12

v13

v14

v11

v12

v13

v14

6

9

12

15

6

9

12

15

Figure 9: Solution S1

Figure 10: Solution S2

use following definitions describe another version ASG algorithm,
constructs solutions way check find whether solution already
added Open avoided.
Definition 3.l [Solution Space DAG(SSDAG)] solution space DAG alternating
AND/OR tree directed acyclic graph (DAG), G = hV, Ei, V set
possible solutions AND/OR tree , E set edges defined as:

fi

fi Sp , Sm V,


fi
E = espm fifi espm directed edge node Sp Sm ,


fi Sm Succ(Sp )

Clearly Sopt root node G .




Definition 3.m [Solution Space Tree Completeness] solution space tree
alternating AND/OR tree tree = hV , E V V, V set
possible solutions AND/OR tree , E set edges defined
as:
fi


fi Sp , Sm V ,


fi





fi
e


directed
edge

node



,

p

fi pm

E = epm fi

fi Sp P red(Sm ),




fi P red(Sm ), (Sp 6= ) edge Sm .
p
p
p
sibling set solution Sm , denoted using Sib(T , Sm ). solution space tree
AND/OR tree complete V = V.


may noted complete solution space tree alternating AND/OR tree
necessarily unique. possible alternating AND/OR tree
one complete solution space tree. However solution space DAG AND/OR tree
unique.
Definition 3.n [Native Swap Options Solution] Consider solution Sm alternating AND/OR tree . Suppose Sm constructed applying swap option ij
solution Sp . Since swap option ij = hei , ej , ij used construct Sm , node vj
present Sm . native swap options solution Sm respect swap option ij ,
N (Sm , ij ), subset L(Sm ), comprises following swap options :
293

fiGhosh, Sharma, Chakrabarti, & Dasgupta

v1

2, 49

2,3 : 5

h3i

3, 32

3,4 : 1
h2i

v2

v3

h1i

2, 43

v4

35
h5i

2, 11

h1i

v5

h3i

h4i

v6

3, 11

v7

v8

4, 23

12
h2i
h1i
9,10 : 3

h2i

h3i

11,12 : 4

h1i

h1i

h2i

13,14 : 3 14,15 : 6

v9

v10

v11

v12

v13

v14

v15

5

7

6

9

12

15

20

Figure 11: solution, S4 , AND/OR tree shown Figure 4
a. jk , jk swap option edge ej
b. , belongs node vq vq node Sm (vj )
use term N (Sm ) denote native swap options ij understood
context. Intuitively native swap options solution Sm swap options
become available immediately applying ij , available predecessor
solution Sm .



Consider solution S4 shown Figure 11 Sig(S4 ) = {(2,3) , (3,4) , (13,14) }.
solution highlighted using thick dashed lines arrow head. used rectangles rounded corner beside node vq solution S4 , C(S4 , vq ) 6= Copt (vq ).
Suppose S4 constructed form solution S3 (where Sig(S3 ) = {(2,3) , (3,4) }) using swap
option (13,14) . N (S4 , (13,14) ) = {(14,15) } whereas L(S4 ) = {(11,12) , (14,15) }.
consider solution S6 Sig(S6 ) = {(2,3) , (3,4) , (11,12) , (13,14) ). worth observing applying native swap options S4 instead swap options L(S4 )
prevents construction solution S6 solution S4 . S6 also constructed
applying (13,14) solution S5 , Sig(S5 ) = {(2,3) , (3,4) , (11,12) }. However, may
noted (13,14) native swap option solution S5 .
3.3.1 Lazy ASG Algorithm
intuition behind version ASG algorithm follows. newly
constructed solution Sm , need check whether Sm already present Open
Sm constructed part computing successor set multiple solutions.
Instead using entire swap list solution construct successors
add solutions Open, using native swap options constructing subset
successor set ensures following. subset constructed using native swap options
294

fiGenerating Ordered Solutions Explicit AND/OR Structures

consists solutions currently present Open thus
added Open without comparing existing entries Open. construction

remaining successor solution Sm
insertion Open delayed
added Closed.
every predecessor solution Sm
Algorithm 5: Lazy ASG (LASG) Algorithm

1

2
3
4
5
6
7
8
9
10
11

12

13

14
15
16

17
18

19
20
21
22
23
24
25
26
27
28

input : alternating AND/OR tree
output: Alternative solutions non-decreasing order cost
Compute optimal solution Sopt , perform edge marking populate
swap options;
Create two lists, Open Closed, initially empty;
Put Sopt Closed list;
Create solution space tree Sopt root;
Compute swap list, L(Sopt ), Sopt ;
Construct Succ(Sopt ) using L(Sopt );
forall Sm Succ(Sopt )
Add Sm Open;
end
Open empty
Smin Remove minimum cost solution Open ;
/* Suppose Smin constructed Sm applying swap option ij
*/
Add node corresponding Smin connect node using edge
Sm ;
Compute swap list L(Smin ) list native swap options N (Smin , ij );
/* Expansion using native swap options
*/
foreach tmp N (Smin , ij )
Construct Stmp Smin applying tmp ;
Construct signature Stmp , Sig(Stmp ), concatenating tmp
Sig(Smin );
Add Stmp Open;
end
/* Lazy Expansion
*/

forall Sp Sib(T , Smin )
ij L(Sp )
Construct Sp Sp using ij ;
Construct signature Sp , Sig(Sp ), concatenating ij Sig(Sp );
Add Sp Open;
end
end
Add Smin Closed;
end
Report solutions Closed;

solution space tree maintained throughout course algorithm
added Closed. Based idea
determine every predecessor Sm
295

fiGhosh, Sharma, Chakrabarti, & Dasgupta

present lazy version ASG algorithm, named LASG. selecting minimum cost
solution Open, algorithm explores successor set current minimum cost
solution lazy fashion. solution Sm , first subset Succ(Sm ) constructed
using native swap options Sm . solutions belong Succ(Sm )
explored late possible described above. resolving ties, LASG algorithm
uses strategy used ASG algorithm. details LASG algorithm
presented Algorithm 5. proof correctness algorithm presented
Appendix B.
Consider example tree shown Figure 7 solutions S1 S2 (shown Figure 9
Figure 10). Initially Open contain Sopt N (Sopt ) = {(11,12) , (13,14) }.
Sopt selected Open, S1 S2 added Open. Next S1 selected
followed S2 . Since, N (S1 ) = N (S2 ) = , selecting S1 S2 successor
solutions constructed using native swap list. Among predecessors S3 , S2
added last Closed. selecting removing S2 Open, solution S3 constructed
previously selected predecessor S1 using swap option (11,12) used
construct solution S2 Sopt .
3.3.2 Working LASG Algorithm (on AND/OR tree Figure 4)
entering outermost loop (Algorithm 5, Line 10), LASG computes
optimal solution Sopt constructs Succ(Sopt ).
solutions Succ(Sopt )
added Open contents Open becomes {(2,3) }, {(9,10) } . contents
different lists solution added Closed shown Table 2. solutions
represented using signatures. solutions added Open result
lazy expansion, highlighted using under-brace.
Iteration
1
2
3

Smin
{}
{(9,10) }
{(2,3) }
{(2,3) , (3,4) }

N (Smin )
(2,3) , (9,10)

(3,4)
(11,12) , (13,14)

4

{(2,3) , (3,4) , (13,14) }

(14,15)

5

{(2,3) , (3,4) , (11,12) }



6

{(2,3) , (3,4) , (13,14) ,
(11,12) }



Open
{(2,3) }, {(9,10) }
{(2,3) }
{(2,3) , (3,4) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) },
{(2,3) , (3,4) , (13,14) , (14,15) }

Closed
{}
{}, {(9,10) }
{}, {(9,10) }, {(2,3) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (13,14) , (14,15) }, {}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) , (13,14) , (11,12) }
{(2,3) , (3,4) }
|
{z
}
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) , (14,15) }, {}, {(9,10) }, {(2,3) },
{(2,3) , (3,4) }
{(2,3) , (3,4) , (13,14) }
{(2,3) , (3,4) , (11,12) }
{(2,3) , (3,4) , (13,14) ,
(11,12) }

Table 2: Working LASG Algorithm
generating first four solutions, contents different lists LASG
identical contents corresponding lists ASG (shown Table 1).
296

fiGenerating Ordered Solutions Explicit AND/OR Structures

soltuions, native swap list equal actual swap list solution. worth noting that, unlike ASG, LASG outermost loop starts
generating optimal solution Sopt , thus generating solution
iteration number LASG less ASG 1. 4th iteration, solution S4 = {(2,3) , (3,4) , (13,14) } native swap list equal swap list
described previously. holds true solution S5 = {(2,3) , (3,4) , (11,12) }
solution S6 = {(2,3) , (3,4) , (13,14) , (11,12) }. important observe LASG adds
solution S6 = {(2,3) , (3,4) , (13,14) , (11,12) } Open generation solution
S5 = {(2,3) , (3,4) , (11,12) } part lazy expansion (highlighted using under-brace
Table 2). Whereas, ASG algorithm adds S6 Open generating solution
S4 = {(2,3) , (3,4) , (13,14) }.
3.4 Complexity Analysis Comparison among ASG, LASG BU
section present complexity analysis ASG LASG compare
BU. use following parameters analysis.
a. n n denote total number nodes number nodes
alternating AND/OR tree.
b. denotes degree node maximum number children.
c. denotes maximum number edges solution.
d. denotes maximum size Open. present complexity analysis
generating c solutions. Therefore size Closed O(c).
3.4.1 Complexity ASG
Time Complexity : time complexity major steps Algorithm 4
follows.
a. Computing first solution done bottom-up fashion, thus requiring O(n )
steps. edges emanating node sorted non-decreasing order
aggregated cost compute marks edges, marking process takes
n .d. log . Since value
large general (can upper bounded
constant), n .d. log = O(n ).
b. number swap options available solution equal number
edges solution. Thus, swap list every solution built
O(m) time. c solutions, generating swap options take O(c.m).
c. Since size successor set solution most, size Open,
c.m. Also size TList equal c (the size
Closed).
d. Open list implemented using Fibonacci heap. Individual insert delete
operation Open take O(1)(amortized) O(lg o) time respectively. Hence,
inserting Open deleting Open altogether takes O(o. lg o) time
O(c.m. log(c.m)).
e. checking duplicates requires scanning entire Open TList. Since
length TList c, newly constructed solution checking takes
O(c + o) time O(c + o) solutions generated. Since O(c + o) actually
O(o), generating c solutions, step takes O(o)2 time. Also, maximum value
297

fiGhosh, Sharma, Chakrabarti, & Dasgupta

O(c.m). Thus, time complexity step O(c.m)2 . Clearly
step dominates O(o. lg o) total time taken insertions Open
deletions Open.
However, time bound improved maintain hash map
solutions Open TList, case checking duplicates
done O(o) time. case O(o. lg o) (total time taken insertions
Open deletions Open) becomes dominant time required checking
duplicates.
f. upper limit estimate could made estimating size solution tree

n regular complete alternating AND/OR trees. important
observe value independent average degree node
.
Combining
together get time complexity
ASG algorithm :

factors


2
2
2
2
n + = n + (c.m) = n + c .n = O(c .n )
Howeverif additional
hash
reduced :

map used time complexity



n + o. lg = n + c. n . lg(c.n ) = n + n .(c. lg c + c. lg n )
Space Complexity: following data-structures primarily contribute space complexity ASG algorithm.
a. Three lists, namely, Open, Closed, TList maintained throughout course
running ASG. contributes O(o + c) factor, O(o).
b. Since number swap options upper bounded total number edges,
constructing swap list contributes factor, O(n .d) space complexity.
Also marking solution requires putting mark every node AND/OR
tree, thus adding another O(n ) space clearly dominated previous
O(n .d) factor.
c. Since signature solution essentially set swap options, size
signature upper bounded total number swap options available. Combining
Open Closed list, altogether (c + o) solutions need stored.
Since (c + o)

O(o), total space required storing solutions o.n .d .
Combining
factors
together get space complexity ASG algorithm :
+ n .d + o.n .d = O(o.n .d)
additional
hash map used improve time complexity, another addi
tional o.n .d space required maintaining hash map. Although exact space
requirement doubled, asymptotically space complexity remains same.
3.4.2 Complexity LASG
Time Complexity : Compared Algorithm 4, Algorithm 5 check
duplicates adds solution Open required. Therefore
terms complexity remain except term corresponding checking
duplicates. However, created maintained course Algorithm 5.
Creating maintaining tree require O(c) time. Also lazy expansion
swap list previously generated sibling solutions searched (Line 19 Line 20
Algorithm 5). size swap list solution O(m), maximum
number edges solution. Also O(m) sibling solutions
298

fiGenerating Ordered Solutions Explicit AND/OR Structures

solution. Therefore complexity lazy expansion O(c.m2 ). Since O(c.m2 )
dominant factor, time complexity LASG O(c.m2 ) = O(c.n ).
Space Complexity : Compared ASG algorithm, LASG algorithm maintain
TList. However LASG maintains solution space tree whose size equal
Closed list, thus adding another O(c) factor space complexity incurred ASG
algorithm. interesting observe worst case space complexity remains O(o +
n .d + o.n .d) = O(o.n .d) equal space complexity ASG algorithm.
3.4.3 Comparison BU
time complexity generating c best solutions AND/OR tree O(n .c. log c)
space complexity O(n .c). detailed analysis found work
Elliott (2007). Since, n .d = O(n ), space complexity ASG LASG
algorithm reduces O(n .c) time complexity LASG log c factor better
BU whereas time complexity ASG quadratic respect c compared
(c. log c) factor BU. additional hash-map used reduce time overhead
duplicate checking, ASG beats LASG
BU terms time complexity,

O(n ) n .(c. lg c + c. lg n ) asymptotically lower O(n .c. log c).
However worst case complexity possible AND/OR trees duplicate solution generated. Empirical results show length Open, hardly reaches
O(c.m).

4. Ordered Solution Generation AND/OR DAGs
section, present problem generating solutions non-decreasing order
cost given AND/OR DAG. present working existing algorithm
generating solution tree based semantics default semantics. Next present
modifications ASG LASG handling DAG.
4.1 Existing Bottom-Up Algorithm
Figure 12 shows example working existing bottom-up approach, BU,
AND/OR DAG Figure 2. use notations used Figure 3 describe
different solutions Figure 12 generation top 2 solutions tree-based
semantics shown.
important notice although BU correctly generates alternative solutions
AND/OR DAGs tree based semantics, BU may generate solutions
invalid default semantics. Figure 13 present solution AND/OR DAG
Figure 2. solution example solution correct tree-based
semantics invalid default semantics. solution DAG (highlighted using
thick dashed lines arrow heads) Figure 13 generated 3rd solution
AND/OR DAG Figure 2 running BU. every non-terminal node, entry
(within rectangle) corresponding 3rd solution highlighted using bold face. may
noted terminal nodes, v9 v10 , included solution DAG though
emanate parent node. Therefore, solution valid one
default semantics.
299

fiGhosh, Sharma, Chakrabarti, & Dasgupta

2, 89

v1

v2 v3
1 : |1, 1|, 89
2 : |2, 1|, 90

h1i
3, 43

v2

1 : hv5 , 1i, 43
2 : hv4 , 1i, 44

v4
40

h1i

v7

1 : hv5 , 1i, 41
2 : hv5 , 2i, 44

3, 43

h1i

v7 v8
1 : |1, 1|, 35
2 : |2, 1|, 38

v2

1 : hv9 , 1i, 9
2 : hv10 , 1i, 12

v6

v4

52

40

1 : hv5 , 1i, 43
2 : hv4 , 1i, 44

v5

2, 35

v8

3, 9
h1i

v7

2, 41

v3

h4i

1 : hv5 , 1i, 41
2 : hv5 , 2i, 44
h1i

v7 v8
1 : |1, 1|, 35
2 : |2, 1|, 38

v6
52

h3i

h4i

17

h2i

h2i

h5i

h1i

h3i

h4i
3, 9

v3

h4i
v5

2, 35

2, 41

v1

h1i

h2i

h5i

h1i

2, 89

v2 v3
1 : |1, 1|, 89
2 : |2, 1|, 90
3 : |1, 2|, 92

1 : hv2 , 1i, 34
2 : hv2 , 2i, 37

v8
17

h2i

v9

v10

v9

v10

5

7

5

7

Figure 13: solution (tree based semantics)

Figure 12: BU approach AND/OR DAG

Proposed Extension BU Generate Alternative Solutions Default
Semantics : propose simple top-down traversal pruning based extension
BU generate alternative solutions default semantics. generating ordered
solutions node vq combining solutions children, following.
newly constructed solution rooted vq , top-down traversal solution
starting vq done check whether two edges node present
particular solution (a violation default semantics). violation
default semantics detected, solution pruned list alternative solutions
rooted vq . Therefore, every node, new solution constructed,
additional top-down traversal used detect semantics violation.
4.2 Top-Down Method DAGs
proposed top-down approaches (ASG LASG) also applicable AND/OR
DAGs generate alternative solution DAGs default semantics. method
computing cost increment application swap option needs modified
incorporate fact node may included solution DAG multiple
paths root node. use notion participation count computing cost
increment.
Participation Count : notion participation count applicable intermediate
nodes solution DAG follows. solution DAG, participation count
intermediate node, vq , total number distinct paths connecting root node, vR ,
vq . example, Figure 14, optimal solution DAG shown using thick dashed
lines arrow heads, participation count every intermediate nodes
shown within circle beside node.
300

fiGenerating Ordered Solutions Explicit AND/OR Structures

v1

h2i

h1i
1

h1i

v2

3, 43

1

h5i

2,5,4 : 1

v4

v1

2, 89

2

h4i

v5

2

h1i

v7

v3

2, 41

3,5,6 : 14

1

h1i

2, 35

v2

3, 44

v6

v4

52

40

1

h5i

h1i

h4i

v5

1

1

17
h2i

h1i

2, 41

3,5,6 : 14

h1i

v6

2, 35
h3i

h4i

v8

v3

52

h3i

3, 9

7,9,10 : 3

h2i

h1i

40
h4i

2, 90

v7

v8

3, 9

7,9,10 : 3

17

h2i

v9

v10

v9

v10

5

7

5

7

Figure 15: Solution DAG S1

Figure 14: AND/OR DAG

use notation ijk denote swap option context AND/OR DAGs,
swap option ijk belongs node vi , source edge swap option eij
node vi node vj , destination edge eik node vi node vk .
4.2.1 Modification Proposed Top-Down Approach
ASG algorithm modified handling AND/OR DAGs following way.
computation successor solution Line 14 Algorithm 4 modified incorporate
participation count node applied swap option belongs.
overall method shown Algorithm 6(in next page).
order apply LASG AND/OR DAGs, apart using mentioned
modification computing cost newly generated solution, another modification
needed computing native swap options given solution. modification
explained example. Consider solution, S1 , shown Figure 15. S1 highlighted
using thick dashed lines arrow heads. pair, cv (vq ), C(S1 , vq ), shown within
rectangles beside node vq ; rectangles rounded corner used C(S1 , vq ) 6=
Copt (vq ). Swap option (2,5,4) applied Sopt generate S1 . application
swap option (2,5,4) , participation count node v5 decremented 1. Therefore
S1 path root node node v5 node v5 still present S1 .
result, swap option (7,9,10) available S1 participation count equal
1 node v7 , whereas (7,9,10) available parent solution Sopt participation
count 2 node v7 . words, (7,9,10) available S1 parent solution
Sopt value participation count node v7 . Therefore (7,9,10) becomes
native swap option S1 . generalized definition native swap options solution
presented below.
Definition 4.o [Native Swap Options Solution] Consider solution Sm
AND/OR DAG G , Sm constructed applying swap option hij solution
Sp . Since swap option hij = hehi , ehj , hij used construct Sm , node vj belongs
301

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Sm . Similarly, participation count node vi remains greater zero applying hij Sm , node vi belongs Sm . native swap options solution Sm
respect swap option hij , N (Sm , hij ), subset L(Sm ), comprises following
swap options :
a. hjk , hjk swap option edge ehj
b. , belongs node vq vq node Sm (vj )
c. , node vi present Sm belongs node vq vq
node Sm (vi ).
use term N (Sm ) denote native swap options hij understood
context. Intuitively native swap options solution Sm swap options
become available immediately applying hij , available predecessor
solution Sm .


Algorithm 6: ASG Algorithm AND/OR DAGs
input : AND/OR DAG G
output: Alternative solutions G non-decreasing order cost
1 Compute optimal solution Sopt , perform edge marking populate
swap options;
2 Create three lists, Open, Closed, TList, initially empty;
3 Put Sopt Open;
4 lastSolCost C(Sopt );
5 Open empty
6
Smin Remove minimum cost solution Open;
7
lastSolCost < C(Smin )
8
Remove elements TList;
9
lastSolCost C(Smin );
10
end
11
Add Smin Closed TList;
12
Compute swap list, L(Smin ), Smin ;
/* Construct Succ(Smin ) using L(Smin ) add new solutions Open
*/
13
foreach ij L(Smin )
14
Construct Sm applying ij Smin ;
15
Construct signature Sm , Sig(Sm ), concatenating ij Sig(Smin );
16
Let ij belongs node vq , p participation count vq ,
cost increment ij ;
17
C(Sm ) = C(Sm ) + p ;
/* Check whether Sm already present Open TList
*/
18
(Sm Open) (Sm TList)
19
Add Sm Open;
20
end
21 end
22 Report solutions Closed;
worth noting Definition 4.o native swap option generalization
earlier definition native swap option (Definition 3.n), defined context trees.
302

fiGenerating Ordered Solutions Explicit AND/OR Structures

case trees, participation count node maximum 1. Therefore,
application swap option solution, participation count node,
original edge swap option points to, becomes 0. Therefore third
condition never applicable trees.
LASG (Algo. 5) applied AND/OR DAGs, mentioned modification
computing cost newly generated solution general definition native
swap option generate ordered solutions default semantics.
4.2.2 Working ASG LASG Algorithm AND/OR DAG
describe working ASG algorithm example DAG shown Figure 2.
entering outermost loop, TList Closed empty, Open contains
optimal solution Sopt . contents different lists obtained first cycles
outermost loop shown Table 3. solution represented signature.
solutions already present Open also constructed expanding
current Smin , highlighted under-braces. example, solution {(2,5,4) , (3,5,6) }
added Open Iteration 2 (while constructing successor solutions {(2,5,4) })
constructed Iteration 5 expanding solution {(3,5,6) }.
L(Smin )
Open
(2,5,4) , (3,5,6) , (7,9,10)
{(2,5,4) }, {(3,5,6) }, {(7,9,10) }
(3,5,6) , (7,9,10)
{(3,5,6) }, {(7,9,10) }, {(2,5,4) , (3,5,6) },
{(2,5,4) , (7,9,10) }
3 {(2,5,4) , (7,9,10) }

{(3,5,6) }, {(7,9,10) }, {(2,5,4) , (3,5,6) },

It.
1
2

Smin
{}
{(2,5,4) }

4

{(7,9,10) }



{(3,5,6) }, {(2,5,4) , (3,5,6) },

5

{(3,5,6) }

(2,5,4) , (7,9,10)

{(2,5,4) , (3,5,6) }, {(3,5,6) , (7,9,10) }
|
{z
}

Closed
{}
{}, {(2,5,4) }
{}, {(2,5,4) }
{(2,5,4) , (7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }, {(3,5,6) }

Table 3: Example Working ASG Algorithm DAG shown Figure 2
illustrate working LASG algorithm example DAG shown Figure 2. contents different lists solution added Closed shown
Table 4. worth noting solution S1 = {2,5,4 }, swap list L(S1 ) =
{(3,5,6) , (7,9,10) } whereas native swap list N (S1 ) = {(7,9,10) }. solutions
added Open result lazy expansion, highlighted using under-brace. example,
Iteration 7 LASG adds solution S5 = {(2,5,4) , (3,5,6) } Open generation
solution S4 = {3,5,6 } part lazy expansion, whereas ASG algorithm adds S5
Open generating solution S1 = {2,5,4 }.
4.2.3 Generating Solutions Tree Based Semantics
Unlike default semantics, ASG LASG straight forward extension
generating solutions tree based semantics. Figure 13 show example
solution valid tree based semantics, invalid default semantics,
edges emanating form node v7 , namely e(7,9) e(7,10) ,
303

fiGhosh, Sharma, Chakrabarti, & Dasgupta

N (Smin )
Open
(2,5,4) , (3,5,6) , (7,9,10) {(2,5,4) }, {(3,5,6) }, {(7,9,10) }
(7,9,10)
{(3,5,6) }, {(7,9,10) },
{(3,5,4) , (7,9,10) }
2 {(2,5,4) , (7,9,10) }

{(3,5,6) }, {(7,9,10) },

It.
1

Smin
{}
{(2,5,4) }

3

{(7,9,10) }



{(3,5,6) }

4

{(3,5,6) }

(7,9,10)

{(3,5,6) , (7,9,10) },
{(2,5,4) , (3,5,6) }
|
{z
}

Closed
{}
{}, {(2,5,4) }
{}, {(2,5,4) }
{(2,5,4) , (7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }
{}, {(2,5,4) },
{(2,5,4) , (7,9,10) },
{(7,9,10) }, {(3,5,6) }

Table 4: Example Working LASG Algorithm DAG shown Fugure 2

present solution. two edges included solution two
different paths emanating form root node, v1 . existing bottom-up approach
stores alternative solutions node terms solutions children
node, representation allows different paths stored explicitly, thus making
BU amenable generating alternative solutions tree-based semantics.
contrary, approach works top-down using compact representation (signature) storing solutions. signature based representation, currently
possible store fact particular node included solution two
different paths may select different child node. use equivalent
tree constructed form given graph, compact representation work correctly, case, node would reachable root node one
path. AND/OR DAG converted equivalent AND/OR tree representation
using procedure ConvertDAG (described Section 2) ASG LASG applied equivalent tree representation order generate alternative solutions
correctly tree-based semantics. However, worst case, procedure ConvertDAG
incurs space explosion blow worst case complexity ASG
LASG algorithms. Using compact representations generate ordered solutions
tree-based semantics given AND/OR DAG containing space explosion
worst case complexity algorithms remain comparable BU turns
interesting open problem.

5. Experimental Results Observations
obtain idea performance proposed algorithms compare
existing approach, implemented ASG, LASG BU (existing bottom-up
approach) tested following test domains.
a. set synthetically generated AND/OR trees;
b. Tower Hanoi (TOH) problem;
c. set synthetically generated AND/OR DAGs;
d. Matrix-chain multiplication problem;
e. problem determining secondary structure RNA sequences.
304

fiGenerating Ordered Solutions Explicit AND/OR Structures

may noted implementation ASG algorithm, implemented
space efficient version ASG algorithm (without separate hash-map storing
solutions Open Closed, thereby incurring extra overhead time duplication
checking). Another important point every test case reported running time
ASG LASG generating particular number solutions includes time required
constructing optimal solution graph. details different test domains
follows.
5.1 Complete Trees
generated set complete d-ary alternating AND/OR trees varying (a)
degree non-terminal nodes (denoted d), (b) height (denoted h).
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

100 solutions
ASG
LASG
BU
0.027
0.005
0.004
0.216
0.010
0.015
1.170
0.031
0.068
6.072
0.124
0.257
30.434
0.517
1.180
130.746 2.265
4.952
0.046
0.006
0.005
0.528
0.017
0.037
5.812
0.106
0.343
66.313
1.552
3.973
636.822 12.363 31.043
0.144
0.011
0.033
2.916
0.056
0.573
58.756
1.266
7.698
0.334
0.012
0.081
12.227
0.177
2.066
0.699
0.022
0.161
32.620
0.654
7.464
1.306
0.030
0.287
81.197
1.786 15.892

300 solutions
ASG
LASG
BU
0.086
0.014
0.009
1.448
0.035
0.046
10.098
0.094
0.184
57.757
0.348
0.777
278.453 1.433
3.917

6.443
13.277
0.196
0.015
0.018
4.764
0.060
0.153
55.170
0.290
1.733
620.996 3.712
14.323

34.150 128.314
1.041
0.025
0.092
25.341
0.181
1.561
544.989 3.327
27.063
2.792
0.036
0.400
102.577 0.443
11.717
5.384
0.071
1.418
288.257 1.566
37.758
12.006
0.092
1.833
785.160 4.284 102.431

500 solutions
ASG
LASG
BU
0.186
0.023
0.020
4.137
0.060
0.097
27.354
0.216
0.407
158.520 0.524
1.641
766.201 2.806
7.257

10.306 29.703
0.459
0.026
0.042
10.345
0.088
0.457
156.158 0.494
4.913

6.607
33.923

55.510 303.785
2.610
0.042
0.123
69.596
0.264
2.107

5.172
38.606
7.374
0.062
0.930
283.689 0.827
26.994
15.133
0.134
2.235
832.235 2.594
90.465
29.870
0.179
4.322

6.890 241.064

Table 5: Comparison running time (in seconds) generating 100, 300, 500 solutions
complete alternating AND/OR trees (T denotes timeout 15 minutes)
trees viewed search space gift packing problem,
(a) terminal nodes represent cost elementary items,
(b) nodes model choice among items (elementary composite nature)
represented children,
(c) nodes model repackaging items returned children.
Every packaging incurs cost modeled cost intermediate nodes.
objective find alternative gifts order non-decreasing cost.
Table 5 shows time required generating 100, 300, 500 solutions various
complete alternating AND/OR trees. implemented ASG, LASG
existing bottom-up algorithm corresponding running time shown column
heading ASG, LASG BU, respectively. used time limit 15 minutes
305

fiGhosh, Sharma, Chakrabarti, & Dasgupta

(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

ASG
12.633
52.770
116.582
287.898
664.789
1785.156
17.270
82.609
335.301
1474.477
9139.312
40.285
213.816
1563.770
64.879
529.738
97.703
1264.828
137.527
2628.461

100 solutions
LASG
BU
13.168
11.047
26.152
48.484
63.254
198.234
173.730
797.234
413.855
3193.234
1257.387 12777.234
17.258
11.688
48.086
111.438
184.375
1009.188
1071.352 9088.938
7872.055 81806.688
24.469
47.453
128.629
767.453
1158.582 12287.453
40.355
88.281
343.254
2217.188
58.191
151.047
862.332
5449.797
90.703
242.219
1995.195 11882.781

ASG
28.105
144.730
341.227
832.562
1767.867

47.531
235.855
926.004
3234.523

121.336
559.734
3209.145
182.270
1254.715
270.027
2747.238
369.086
4869.551

300 solutions
LASG
BU
32.293
14.266
75.355
69.953
165.824
292.703
399.445
1183.703
804.801
4747.703
2047.859 19003.703
49.230
14.812
134.102
152.062
376.766
1387.312
1656.844 12504.562
9565.598 112559.812
67.102
112.609
284.922
1826.359
1699.191 29246.359
110.480
225.781
596.957
5675.000
148.453
372.141
1273.641 13433.391
205.914
576.594
2627.211 28295.281

ASG
41.676
230.168
566.766
1396.758
2942.629

76.270
393.113
1507.973


199.254
917.824

305.891
2008.344
443.656
4203.957
606.133


500 solutions
LASG
BU
49.832
16.609
128.934
87.922
269.766
373.172
612.184
1514.172
1197.266
6078.172
2849.617
24334.172
80.980
17.938
219.555
192.688
577.766
1765.438
2238.152
15920.188
11251.035 143312.938
116.535
129.016
451.223
2105.266
2240.012
33725.266
179.801
363.281
858.852
9132.812
245.227
593.234
1695.684
21416.984
317.492
910.969
3273.703
44707.781

Table 6: Comparison space required (in KB) generating 100, 300, 500 solutions
complete alternating AND/OR trees

entries marked denotes time-out occurred test cases.
space required generating 100, 300, 500 solutions reported Table 6.
observed terms time space required, LASG outperforms ASG
BU. ASG BU, test cases BU performs better ASG
respect time required generating specific number solutions. space
requirement ASG BU generating specific number solutions interesting
correlation degree(d) height(h) parameter tree. low numerical values
h parameter, e.g., (d, h) combinations like (2, 7), (3, 5) etc., BU performs
better ASG. contrary, combinations, least one
h parameters high value, e.g., (d, h) combinations like (2, 17), (7, 5), (4, 9) etc.,
ASG outperforms BU.
5.1.1 Experimentation Queue Bounded Length
Since Open grow rapidly, ASG LASG incur significant overhead
terms time well space maintain Open list number solutions
generated known priori. fact, ASG checking duplicates Open
actually primary source time complexity storing solutions Open major
contributing factor space complexity. number solutions generated
known priori, proposed top-down approach leverage fact using bounded
length queue implementing Open. bounded length queue used, time
requirement along space requirement decreases significantly.
306

fiGenerating Ordered Solutions Explicit AND/OR Structures

(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

100 solutions
ASG
LASG
BU
0.011
0.008
0.004
0.030
0.011
0.015
0.051
0.031
0.068
0.125
0.103
0.257
0.473
0.421
1.180
2.129
2.199
4.952
0.012
0.009
0.005
0.031
0.018
0.037
0.133
0.102
0.343
1.246
1.143
3.973
10.713 10.313 31.043
0.019
0.008
0.033
0.071
0.055
0.573
1.099
0.998
7.698
0.025
0.013
0.081
0.201
0.161
2.066
0.036
0.018
0.161
0.543
0.460
7.464
0.042
0.029
0.287
1.940
1.705 15.892

300 solutions
ASG LASG
BU
0.003 0.002
0.009
0.008 0.006
0.046
0.020 0.011
0.184
0.043 0.059
0.777
0.168 0.164
3.917
0.766 1.005 13.277
0.003 0.002
0.018
0.012 0.006
0.153
0.048 0.043
1.733
0.477 0.636 14.323
4.160 5.555 128.314
0.006 0.004
0.092
0.026 0.023
1.561
0.443 0.552 27.063
0.009 0.031
0.400
0.083 0.078 11.717
0.014 0.011
1.418
0.240 0.325 37.758
0.020 0.013
1.833
0.807 0.843 102.431

500 solutions
ASG LASG
BU
0.005 0.004
0.020
0.014 0.008
0.097
0.023 0.017
0.407
0.065 0.058
1.641
0.254 0.346
7.257
1.146 1.492 29.703
0.005 0.004
0.042
0.019 0.010
0.457
0.071 0.061
4.913
0.693 0.905 33.923
6.013 7.890 303.785
0.010 0.006
0.123
0.038 0.033
2.107
0.641 0.808 38.606
0.015 0.008
0.930
0.116 0.153 26.994
0.021 0.010
2.235
0.326 0.431 90.465
0.025 0.022
4.322
0.870 1.125 241.064

Table 7: Comparison running time (in seconds) generating 100, 300, 500 solutions
complete alternating AND/OR trees bounded length Open queue ASG
LASG
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

ASG
10.109
23.875
54.609
135.477
361.859
1071.258
12.008
39.469
169.469
971.930
7075.109
20.664
116.609
1082.633
33.344
324.258
51.742
825.859
78.141
1919.805

100 solutions
LASG
BU
2.383
11.047
4.883
48.484
14.883
198.234
54.883
797.234
214.883
3193.234
854.883 12777.234
2.617
11.688
11.160
111.438
88.047
1009.188
780.027
9088.938
7007.852 81806.688
5.016
47.453
57.016
767.453
889.016 12287.453
10.195
88.281
217.715
2217.188
19.773
151.047
657.648
5449.797
35.742
242.219
1677.051 11882.781

ASG
27.781
64.430
141.203
317.445
738.992
1845.562
34.609
101.320
353.477
1529.031
8763.023
56.703
247.320
1607.859
84.422
565.531
121.031
1227.742
169.297
2542.047

300 solutions
LASG
BU
5.508
14.266
8.008
69.953
18.008
292.703
58.008
1183.703
218.008
4747.703
858.008
19003.703
5.742
14.812
14.285
152.062
91.172
1387.312
783.152
12504.562
7010.977 112559.812
8.141
112.609
60.141
1826.359
892.141
29246.359
13.320
225.781
220.840
5675.000
22.898
372.141
660.773
13433.391
38.867
576.594
1680.176 28295.281

ASG
45.789
104.117
225.969
497.508
1114.422
2615.656
57.617
163.102
537.328
2085.367
10457.797
93.031
377.922
2132.516
135.812
806.797
190.758
1628.797
260.406
3163.438

500 solutions
LASG
BU
8.633
16.609
11.133
87.922
21.133
373.172
61.133
1514.172
221.133
6078.172
861.133
24334.172
8.867
17.938
17.410
192.688
94.297
1765.438
786.277
15920.188
7014.102 143312.938
11.266
129.016
63.266
2105.266
895.266
33725.266
16.445
363.281
223.965
9132.812
26.023
593.234
663.898
21416.984
41.992
910.969
1683.301 44707.781

Table 8: Comparison space required (in KB) generating 100, 300, 500 solutions
complete alternating AND/OR trees bounded length Open queue ASG
LASG

307

fiGhosh, Sharma, Chakrabarti, & Dasgupta

show effect using bounded length queue implement Open Table 7 (reporting time requirement) Table 8 (reporting memory usage) generating
100, 300, 500 solutions, number solutions generated known beforehand. Table 7 Table 8 show case ASG LASG outperforms
BU terms time well space requirements. Particularly, ASG performs well
setting, outperforming LASG cases.
5.1.2 Experimentation Compare Incremental Nature
proposed top-down algorithms incremental nature whereas existing bottomup approach incremental. generating specified number ordered solutions,
methods generate next solution incrementally without needing restart itself,
whereas existing approach needs restarted. example, generating
first 10 ordered solutions, ASG LASG generate 11th solution directly data
structures maintained far algorithms perform necessary updates
data structures. Whereas, BU needs restarted input parameter 11 generating
11th solution. Table 9 compare time needed generate subsequent 11th
solution 12th solution incrementally generating first 10 solutions. order
clarity comparison among running times respective algorithms,
used higher precision (upto 6th decimal place) reporting running time
Table 9. Clearly, ASG LASG outperform BU generating 11th 12th
solution terms time requirement.
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

first 10
0.002403
0.009111
0.028519
0.097281
0.396460
1.561020
0.001692
0.012097
0.097356
0.934389
7.898530
0.005833
0.051598
0.813028
0.051530
0.172475
0.053422
0.502939
0.033831
1.198354

ASG
11th
0.000201
0.001957
0.003311
0.014776
0.063641
0.251839
0.000158
0.001542
0.013046
0.127943
1.082319
0.000650
0.006956
0.110205
0.001327
0.024262
0.002701
0.061417
0.003706
0.156145

12th
0.000201
0.001302
0.003533
0.015929
0.059229
0.277763
0.000151
0.001572
0.014405
0.156579
1.194090
0.000671
0.007196
0.124750
0.001641
0.024438
0.003092
0.069727
0.003846
0.166501

first 10
0.001003
0.003023
0.006700
0.025877
0.102493
0.446899
0.000683
0.004084
0.031159
0.311128
2.811539
0.002143
0.017046
0.294561
0.004638
0.059751
0.005282
0.184584
0.012862
0.466560

LASG
11th
0.000240
0.000714
0.001250
0.004113
0.014490
0.061422
0.000176
0.000583
0.003948
0.033169
0.282836
0.000303
0.002209
0.027612
0.000753
0.006116
0.000636
0.017116
0.001266
0.038792

12th
0.000123
0.000629
0.001346
0.004918
0.020031
0.082366
0.000112
0.000959
0.004604
0.047594
0.387715
0.000582
0.003115
0.037281
0.000652
0.007197
0.001087
0.024042
0.001282
0.061305

first 10
0.001344
0.003596
0.014628
0.059326
0.238418
0.962635
0.001055
0.009507
0.085610
0.778298
7.037050
0.004181
0.044913
0.727766
0.005963
0.152285
0.010895
0.406947
0.018185
0.929941

BU
11th
0.001359
0.003696
0.015046
0.061393
0.246042
0.989777
0.001101
0.009931
0.089379
0.811176
7.313715
0.004434
0.047867
0.775950
0.006358
0.162527
0.011604
0.435398
0.019567
0.989326

12th
0.001397
0.003895
0.015521
0.062717
0.251746
1.015848
0.001133
0.010336
0.093419
0.846578
7.608619
0.004725
0.050940
0.823442
0.006782
0.173191
0.012556
0.465301
0.020896
1.052566

Table 9: Comparison running time (in seconds) generating first 10 solutions
11th solution 12th solution incrementally complete alternating
AND/OR trees

308

fiGenerating Ordered Solutions Explicit AND/OR Structures

5.2 Multipeg Tower Hanoi Problem
Consider problem Multipeg Tower Hanoi (Majumdar, 1996; Gupta, Chakrabarti,
& Ghose, 1992). problem, pegs fastened stand. Initially disks rest
source peg small disk large disk ordering. objective transfer
disks destination peg B minimum legal moves. legal move,
topmost disk tower transferred peg larger disk
topmost disk. problem multi-peg tower Hanoi solved recursively follows.
a. Move recursively topmost k (k varies 1 1) disks
intermediate peg, I, using pegs.
b. Transfer remaining k disks B recursively, using ( 1) pegs
available.
c. Recursively move k disks transferred previously, intermediate
peg B, using pegs.
may noted choice value k, may take value 1
1. Solutions different values k may take different number moves,
solution incurs minimum number moves optimal solution. choice
value k modeled node, every choice, problem divided
three sub-problems. decomposition sub-problems modeled
node. Therefore, search spaces multi-peg Tower Hanoi problem correspond
alternating AND/OR trees.
#disks
8
9
10
11
12
13

100 solutions
ASG
LASG
BU
0.034
0.030
0.069
0.119
0.116
0.264
0.479
0.635
1.310
2.421
2.178
3.171
7.453
7.448 11.437
25.379 25.115 38.458

300 solutions
ASG
LASG
BU
0.104
0.084
0.252
0.314
0.289
0.942
1.706
1.658
3.305
6.573
6.161
12.998
21.232 21.081 43.358
68.574 67.170 140.392

500 solutions
ASG
LASG
BU
0.200
0.138
0.577
0.590
0.458
2.183
2.303
2.829
7.592
10.651
9.678
29.242
35.825
35.663
99.593
112.411 112.470 332.113

#Opt. No.
Moves
23
27
31
39
47
55

Table 10: Comparison running time (in seconds) alternating AND/OR trees corresponding search spaces 5-peg Tower Hanoi problem different
number disks
#disks
8
9
10
11
12
13

100 solutions
ASG
LASG
BU
ASG
36.664
43.008
416.312
64.516
96.211
111.320
1471.656
131.266
295.672
341.000
5074.219
326.352
957.336
1113.508 17197.312
999.602
3155.086 3664.117 57512.812
3198.156
10339.078 12022.883 190297.969 10412.242

300 solutions
LASG
BU
ASG
80.734
660.062
105.039
154.266
2359.156
166.789
383.453
8161.719
373.453
1158.797 27728.562
1039.367
3719.352 92906.562
3247.547
12078.914 307872.969 10483.570

500 solutions
LASG
BU
117.008
903.812
197.859
3246.656
427.766
11249.219
1204.719 38259.812
3767.617 128300.312
12137.242 425447.969

Table 11: Comparison space required (in KB) alternating AND/OR trees corresponding search spaces 5-peg Tower Hanoi problem different number
disks
used search space 5 peg Tower Hanoi problem different number
disks, , generated alternative solutions non-decreasing order cost using ASG
309

fiGhosh, Sharma, Chakrabarti, & Dasgupta

LASG algorithms. cost function expresses number legal moves. value
varied 8 13, Table 10 Table 11, report time required
space required, respectively, generating 100, 300, 500 solutions every test cases.
Experimental results show performance ASG similar performance
LASG respect space time. However ASG well LASG outperforms
BU respect time space requirements.
5.3 Randomly Constructed AND/OR DAGs
constructed set randomly generated AND/OR DAGs evaluated ASG,
LASG, BU algorithm generating solutions default semantics. used
proposed extension BU algorithm generating solutions default semantics.
n



60
220
920
33
404
2124
9624
144
744
8844
40884

2
2
2
3
3
3
3
4
4
4
4

100 solutions
ASG LASG
BU
0.027 0.006 0.039
0.060 0.009 0.096
0.363 0.020 0.106
0.020 0.006 0.019
0.203 0.018 0.067
3.550 0.045 0.730
26.659 0.201 14.620
0.065 0.008 0.034
0.877 0.025 0.400
7.422 0.160 26.683

1.972


300 solutions
ASG
LASG
BU
0.089
0.021 0.158
0.281
0.030 1.100
2.485
0.059 0.266
0.123
0.021 0.098
1.483
0.048 0.257
30.302 0.126 1.681
257.605 0.612 33.382
0.348
0.027 0.217
6.910
0.069 0.994
69.097 0.449 66.558

5.819


500 solutions
ASG
LASG
BU
0.172
0.033
0.282
0.594
0.051
3.665
6.163
0.100
0.528
0.280
0.032
0.245
4.043
0.083
0.541
85.863 0.215
2.766
710.708 1.194 52.406
0.817
0.049
2.251
18.823 0.118
1.365
194.452 0.927 109.076

9.426


Table 12: Comparison running time (in seconds) generating 100, 300, 500 solutions AND/OR DAGs (T denotes timeout 15 minutes)
n



60
220
920
33
404
2124
9624
144
744
8844
40884

2
2
2
3
3
3
3
4
4
4
4

ASG
11.609
23.141
74.082
13.914
48.867
229.820
772.441
30.648
121.535
471.625
2722.938

100 solutions
LASG
BU
8.875
8.125
16.219
31.312
39.000
106.875
10.492
8.172
35.445
66.938
118.707
389.844
339.676 1996.875
17.332
29.609
65.578
287.109
266.078 2729.297
1256.535


ASG
32.852
62.516
220.648
46.117
151.363
705.809
2245.938
85.781
381.133
1183.379


300 solutions
LASG
BU
30.797
10.906
46.711
49.562
105.852
172.562
32.539
11.297
101.168
98.188
312.246
621.094
825.984 3321.875
53.961
73.359
168.305
737.891
550.477 6945.703
2353.562


ASG
54.094
100.555
371.344
77.445
262.816
1200.336
3732.523
140.312
659.434
1927.961


500 solutions
LASG
BU
50.035
13.250
74.379
65.188
168.375
230.375
54.602
14.422
163.273
129.438
507.762
852.344
1327.406 4646.875
93.539
86.641
275.594
883.984
843.484 8419.922
3447.809


Table 13: Comparison space required (in KB) generating 100, 300, 500 solutions
AND/OR DAGs

Table 12 Table 13 compare time required space required running ASG,
LASG BU generating 100, 300, 500 solutions every test cases. first
second columns every row provide size (n ) average out-degree (d)
DAG. results obtained test domain similar results randomly
310

fiGenerating Ordered Solutions Explicit AND/OR Structures

constructed AND/OR trees. may noted terms time space required,
LASG outperforms ASG BU. ASG BU, test cases
BU performs better ASG respect time required generating specific
number solutions. Whereas, space requirement ASG BU generating
specific number solutions interesting co-relation average degree(d)
size (n ) parameter DAG. low numerical values n
parameter, e.g., (n , d) combinations like (60, 2), (33, 3) etc., BU performs better
ASG. contrary, combinations, least one n
parameter high value, e.g., (n , d) combinations like (920, 2), (9624, 3), (40884, 4)
etc., ASG outperforms BU.
5.4 Matrix-Chain Multiplication Problem
also used well-known matrix-chain multiplication (Cormen, Stein, Rivest, &
Leiserson, 2001) problem experimentation. search space popular dynamic
programming formulation problem correspond AND/OR DAG.
DAG
Cnstr.
#matrices
Time
(Sec)
20
0.033
30
0.200
40
0.898
50
3.033
60
8.335
70
19.591
80
41.960
90
82.578
100
151.814

Sopt
Cnstr.
Time
(Sec)
0.001
0.003
0.008
0.016
0.029
0.046
0.071
0.101
0.143

10 solutions

15 solutions

20 solutions

ASG

LASG

BU

ASG

LASG

BU

ASG

LASG

BU

0.003
0.009
0.019
0.047
0.088
0.140
0.209
0.296
0.409

0.002
0.008
0.018
0.048
0.090
0.142
0.212
0.300
0.412

0.206
2.785
15.580
93.267
342.212
862.387




0.004
0.012
0.024
0.062
0.118
0.187
0.280
0.396
0.546

0.003
0.010
0.024
0.065
0.120
0.190
0.282
0.398
0.548

0.288
4.087
23.414
140.513
509.906





0.005
0.015
0.030
0.079
0.148
0.235
0.351
0.496
0.688

0.004
0.012
0.030
0.081
0.151
0.238
0.354
0.499
0.683

0.373
5.406
31.112
187.227
678.718





Table 14: Comparison time required (in seconds) AND/OR DAGs corresponding
search spaces matrix-chain multiplication different number matrices, (T denotes timeout 15 minutes)
#matrices
20
30
40
50
60
70
80
90
100

ASG
19.641
66.367
156.559
308.984
537.383
859.844
1290.117
1843.828
2537.582

10 solutions
LASG
20.203
69.273
160.227
315.012
545.117
869.160
1301.406
1857.480
2556.883

BU
160.918
555.684
1317.637
2563.965
4411.855
6978.496




ASG
20.543
67.809
157.738
310.277
538.930
862.133
1293.148
1847.602
2542.746

15 solutions
LASG
21.227
70.695
161.785
316.543
546.512
870.867
1303.426
1859.812
2560.043

BU
234.305
821.902
1960.281
3825.223
6592.508





ASG
21.914
69.516
158.758
311.551
539.914
863.977
1295.852
1851.164
2549.352

20 solutions
LASG
22.773
72.523
162.852
318.145
547.551
872.219
1305.090
1861.789
2566.992

BU
303.973
1081.902
2594.207
5075.262
8759.441





Table 15: Comparison space required (in KB) AND/OR DAGs corresponding
search spaces matrix-chain multiplication different number matrices

Given sequence matrices, A1 , A2 , , , n matrices matrix Ai dimension pi1 pi , problem objective find efficient way multiply
311

fiGhosh, Sharma, Chakrabarti, & Dasgupta

matrices. classical dynamic programming approach works follows. Suppose
A[i,j] denotes matrix results evaluating product, Ai Ai+1 Aj , m[i, j]
minimum number scalar multiplications required computing matrix A[i,j] .
Therefore, cost optimal solution denoted m[i, j] recursively defined
:

m[i, j] =


0,

min

ik<j



= j;

m[i, k] + m[k + 1, j] + pi1 pk pj , < j.

choice value k modeled node every choice, problem
divided three sub-problems. decomposition sub-problems modeled
node. worth noting unlike search space 5-peg ToH problem,
search space matrix-chain multiplication problem corresponds AND/OR DAG.
used search space different matrix sequences varying length
generated alternative solutions order non-decreasing cost. Table 14, report
time required Table 15, report memory used generating 10, 15,
20 solutions every test cases.
Table 14, test case, also report time required constructing
explicit AND/OR DAG recursive formulation 2nd column, optimal
solution construction time 3rd column. interesting observe relative
performance ASG LASG search space similar obtained 5peg ToH search space though search space domain AND/OR DAG. ASG
LASG perform approximately respect time space requirement.
However, advantage ASG well LASG BU respect time
space requirement significant domain.
5.5 Generating Secondary Structure RNA
Another relevant problem alternative solutions play important role
computation secondary structure RNA. RNA molecules viewed strings
bases, base belongs set {Adenine, Cytocine, Guanine, U racil} (also
denoted {A, C, G, U }). RNA molecules tend loop back form base pairs
resulting shape called secondary structure (Mathews & Zuker, 2004). stability
secondary structure largely depends number base pairings (in general, larger
number base pairings implies stable secondary structure). Although
factors influence secondary structure, often possible express
factors using cost function typically evaluated empirically. Therefore,
useful generate set possible alternative secondary structures ordered decreasing
numbering base pairings given RNA subjected experimental
evaluation.
computation optimal secondary structure considering underlying principle maximizing number base-pairings nice dynamic programming formulation (Kleinberg & Tardos, 2005). Given RNA molecule B = hb1 b2 bn
bi {A, C, G, U }, secondary structure B set base pairings, = {(i, j)},
i, j {1, 2, n}, satisfies following conditions:
312

fiGenerating Ordered Solutions Explicit AND/OR Structures

Test Case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

Organism Name
Anaerorhabdus Furcosa
Archaeoglobus Fulgidus
Chlorobium Limicola
Desulfurococcus Mobilis
Haloarcula Japonica
Halobacterium Sp.
Mycoplasma Genitalium
Mycoplasma Hyopneumoniae
Mycoplasma Penetrans
Pyrobaculum Aerophilum
Pyrococcus Abyssi
Spiroplasma Melliferum
Sulfolobus Acidocaldarius
Symbiobacterium Thermophilum

# Bases
114
124
111
129
122
120
104
105
103
131
118
107
126
110

Table 16: Details RNA sequences used Experimentation
a. (i, j) D, + 4 < j : condition states ends pair
separated least four intermediate bases.
b. elements pair consists either {A, U } {C, G} (in either order).
c. base appears one pairings, i.e., matching.
d. (i, j) (k, l) two pairs D, possible < k < l < j, i.e.,
two pairings cross other.
Test
Case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

DAG Cnstr.
Time (Sec)
34.464
57.999
26.423
83.943
51.290
46.508
16.766
22.775
18.831
91.419
47.660
22.649
67.913
28.911

Sopt Cnstr.
Time (Sec)
0.042
0.057
0.038
0.065
0.051
0.047
0.029
0.033
0.031
0.073
0.047
0.034
0.061
0.038

ASG
0.094
0.126
0.084
0.144
0.114
0.107
0.068
0.077
0.068
0.167
0.111
0.078
0.140
0.087

5 solutions
LASG
BU
0.095 449.916
0.128 823.493
0.089 363.421
0.152 1089.462
0.116 681.429
0.108 598.419
0.069 210.806
0.078 284.455
0.072 233.999
0.170

0.109 627.744
0.079 288.520
0.141 962.641
0.085 366.693

ASG
0.145
0.193
0.135
0.230
0.176
0.166
0.101
0.120
0.109
0.249
0.173
0.116
0.206
0.134

10 solutions
LASG
BU
0.148 893.682
0.198

0.133 718.326
0.227

0.180 1349.181
0.175

0.103 410.817
0.122 559.318
0.111 458.290
0.263

0.171 1253.034
0.123 573.602
0.218

0.137 724.113

ASG
0.197
0.271
0.183
0.314
0.239
0.226
0.136
0.153
0.144
0.347
0.220
0.165
0.290
0.182

15 solutions
LASG
BU
0.202 1359.759
0.277

0.186 1077.094
0.317

0.245

0.238

0.144 621.792
0.165 836.359
0.148 683.411
0.355

0.240

0.167 849.134
0.288

0.186 1072.552

Table 17: Comparison time required (in seconds) AND/OR DAGs corresponding
search spaces RNA secondary structure different number bases (T
denotes timeout 30 minutes)

mentioned conditions dynamic programming formulation follows.
Suppose P (i, j) denotes maximum number base pairings secondary structure
bi bj . P (i, j) recursively defined :
P [i, j] =


0,

n


max P [i, j 1], max 1 + P [i, k 1] + P [k + 1, j 1] ,
ik<j

313

+ 4 j,

+ 4 < j.

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Here, choice value k modeled node every choice,
problem divided three sub-problems. decomposition sub-problems
modeled node. experimented search space problem
set RNA molecule sequences obtained test-cases developed Szymanski,
Barciszewska, Barciszewski, Erdmann (2005). details test cases shown
Table 16.
every test cases, report time required Table 17 generating 5, 10, 15
solutions. setting, space required reported Table 18. Table 17,
test case, also report time required constructing explicit AND/OR DAG
recursive formulation 2nd column, time required constructing
optimal solution time 3rd column. use high value time-out (1800 seconds)
order gather running time required BU. limit maximum solutions generated
15 generating higher number solutions, BU timed
test cases. worth noting result obtained domain similar
result obtained matrix-chain multiplication problem domain. space time
wise ASG LASG perform similarly outperform BU significantly respect
time well space requirement.
Test
Case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

ASG
1647.555
2254.531
1473.852
2606.242
2045.930
1912.227
1101.125
1293.812
1170.094
2984.773
1974.695
1295.141
2438.898
1475.477

5 solutions
LASG
1694.688
2310.008
1516.922
2665.820
2097.414
1963.367
1138.633
1333.336
1207.633
3047.539
2022.906
1335.883
2496.469
1517.828

BU
7409.336
9902.953
6629.891
11358.945
9021.273
8499.570
5087.680
5855.547
5352.477

8641.422
5924.664
10657.945
6627.844

ASG
1651.273
2258.773
1477.492
2610.875
2049.844
1916.422
1104.422
1297.750
1173.023
2990.211
1979.344
1297.273
2442.961
1478.555

10 solutions
LASG
1697.797
2315.258
1521.750
2671.711
2101.836
1968.305
1142.023
1338.070
1211.523
3053.977
2030.922
1339.516
2502.625
1521.352

BU
14656.469

13103.492

17875.430

10036.938
11560.203
10562.766

17119.820
11701.695

13099.055

ASG
1654.367
2262.492
1480.555
2615.719
2052.867
1921.117
1108.047
1302.242
1176.352
2994.773
1983.664
1299.805
2447.172
1482.234

15 solutions
LASG
1700.492
2318.008
1526.797
2675.633
2106.000
1972.172
1144.109
1342.484
1213.906
3059.781
2038.461
1341.914
2506.703
1525.344

BU
21846.156

19518.625



14924.820
17211.406
15718.617


17420.719

19519.742

Table 18: Comparison space required (in KB) AND/OR DAGs corresponding
search spaces RNA secondary structure different number bases

5.6 Observations
experimental data shows LASG algorithm generally outperforms ASG
algorithm existing bottom-up approach terms running time complete
alternating AND/OR trees AND/OR DAGs. Whereas, problem domains,
i.e., 5-peg Tower Hanoi problem, matrix-chain multiplication problem,
problem determining secondary structure RNA sequences, overall performance
ASG algorithm similar performance LASG algorithm. behavior
explained average maximum length statistics Open list, reported
Table 19 - Table 23, mentioned test domains.
314

fiGenerating Ordered Solutions Explicit AND/OR Structures

case complete trees random DAGs, ASG algorithm, average well
maximum size Open grows much faster LASG algorithm (Table 19
Table 20), increase size tree/DAG.
(d, h)
(2, 7)
(2, 9)
(2, 11)
(2, 13)
(2, 15)
(2, 17)
(3, 5)
(3, 7)
(3, 9)
(3, 11)
(3, 13)
(4, 5)
(4, 7)
(4, 9)
(5, 5)
(5, 7)
(6, 5)
(6, 7)
(7, 5)
(7, 7)

100 solutions
ASG
LASG
avg.
max.
avg. max.
235
383
75
159
994
1894
73
120
2427
4709
156
306
5546
10947
524
1149
11744
23291
384
523
24264
48333
655
841
304
549
120
242
1561
3015
172
346
5496
10899
191
289
17336
34542
486
691
53139 106155
1138 1216
734
1427
103
176
3748
7383
194
381
16282
32451
422
488
1216
2352
146
307
7261
14446
249
335
1781
3489
141
276
12362
24651
297
342
2433
4765
261
508
19311
38435
450
529

300 solutions
ASG
LASG
avg.
max.
avg. max.
435
629
179
289
2657
4931
220
528
6935
13537
483
1005
16266
32076
1550 2726
34836
69160
677
1121


1087 1611
740
1323
341
652
4359
8400
579
1260
16272
32244
387
661
51954 103549
956
1754


1267 1569
2062
4006
256
503
10928
21489
678
1467
48786
97196
687
1131
3407
6555
496
1053
21652
42972
470
888
5089
9911
507
1126
36868
73323
461
789
7072
13910
747
1483
57754 115116
687
961

500 solutions
ASG
LASG
avg.
max.
avg. max.
545
792
236
372
4103
7569
449
1069
11251
21843
851
1771
26748
52724
2261 3844
57673 114367
983
1824


1527 2819
1107
1972
539
1007
7026
13588
1012 2084
26904
53271
622
1368


1460 2672


1432 1776
3322
6375
452
1065
17932
35222
1265 2837


1025 1807
5508
10694
852
1742
35850
71054
832
1781
8250
16035
971
2164
61221 121958
749
1573
11595
22809
1204 2273


984
1922

Table 19: Average maximum length Open generating 100, 300, 500 solutions complete alternating AND/OR trees
n



60
220
920
33
404
2124
9624
144
744
8844
40884

2
2
2
3
3
3
3
4
4
4
4

100 solutions
ASG
LASG
avg.
max.
avg. max.
181
338
39
63
479
854
77
133
1530
2957
116
227
202
409
58
102
1001
1969
236
447
5008
9911
374
626
14422 28666
394
491
510
990
56
101
2407
4760
253
485
7522
14931
258
437


749
804

300 solutions
ASG
LASG
avg.
max.
avg. max.
428
768
131
282
1144
2058
210
417
4289
8278
332
639
604
1193
154
281
2958
5799
675 1256
14803 29314
851 1569
43087 85825
746 1339
1374
2563
187
458
7166
14204
590 1018
22254 44062
847 1831


852 1004

500 solutions
ASG
LASG
avg.
max.
avg. max.
643
1138
219
411
1721
3139
329
612
6902
13305
512
946
978
1875
234
422
4874
9781
1013 1810
24442
48357
1337 2527
71547 142327
1254 2756
2140
3996
376
868
11874
23558
885
1655
36743
72740
1565 3493


961
1215

Table 20: Average maximum length Open generating 100, 300, 500 solutions randomly constructed AND/OR DAGs

Since ASG algorithm checks presence duplicates expanding solution,
time required duplication checking grows rapidly test domains. Hence,
overall time required generating specific number solutions also increases rapidly
(faster BU LASG) increase size tree/DAG. result,
BU outperforms ASG respect time requirement trees DAGs. However
315

fiGhosh, Sharma, Chakrabarti, & Dasgupta

memory used generating specific number solutions increases moderately (slower
BU) increase size tree/DAG. Therefore respect space
requirement, ASG outperforms BU larger trees DAGs.
LASG BU, time well memory requirement BU increases
faster LASG degree AND/OR tree DAG increases.
happens because, BU, time taken merging sub-solutions nodes
memory required storing alternative solutions rooted different nodes
increases rapidly increase degree node.
contrary, test domains, 5-peg Tower Hanoi problem, matrix-chain
multiplication problem, probelm finding secondary structure RNA sequences,
average maximum size Open ASG LASG comparable (Table 21, Table 22 Table 23). Therefore, LASG algorithm, time saved
avoiding duplication checking compensated extra overhead maintaining
solution space tree checks required lazy expansion. Hence running time
well space requirement almost algorithms three
mentioned problem domains.
Moreover, due low values average maximum size Open, ASG
outperforms BU respect time requirement memory used three
test domains. three domains also, LASG BU, time well
memory requirement BU increases faster LASG size search
space (AND/OR tree DAG) increases.

6. Ramifications Implicitly Specified AND/OR Structures
section, briefly discuss use proposed algorithms generation alternative
solutions non-decreasing order cost implicit AND/OR search spaces. One
possible way extend standard AO generating given number solutions,
say k, follows. Instead keeping one potential solution graph(psg), stage k
psgs computed explicitly constructed search space instead expanding
one node, k nodes, (that is, one node psg), expanded once.
expanding nodes, k psgs recomputed again. Since cost nodes
often recomputed expanding nodes, swap options associated node
updated every recomputation.
Another possible approach could run AO generates optimal solution.
point time swap options computed explicit portion
graph swap option minimum cost applied optimal solution.
resulting psg expanded resulting expansion explicit graph.
swap options re-evaluated incorporate cost update. next best psg
computed. process continues till second best solution derived. among
remaining successor psgs first solution successor psgs second solution,
promising psg selected expanded. process continues till third solution
found. successor psgs also added already existing pool candidate
psgs. two broad steps, (a) selecting next best psg pool candidate
psgs, (b) keeping expanding explicit graph till next best solution
found, continued till k solutions found.
316

fiGenerating Ordered Solutions Explicit AND/OR Structures

# disks
8
9
10
11
12
13

100 solutions
ASG
LASG
avg. max. avg. max.
55
92
41
68
66
122
42
71
109
183
53
79
132
218
76
140
219
385
85
147
259
482
118
200

300 solutions
ASG
LASG
avg. max. avg. max.
111
186
91
174
163
331
119
252
216
367
142
283
296
611
177
373
473
776
234
492
675 1240
252
437

500 solutions
ASG
LASG
avg. max. avg. max.
174
375
135
235
265
484
198
382
345
693
234
447
486
882
291
558
668
1200
404
724
1016 1828
377
697

Table 21: Average maximum length Open generating 100, 300, 500 solutions 5-peg Tower Hanoi problem different number disks
# matrices
20
30
40
50
60
70
80
90
100

10 solutions
ASG
LASG
avg. max. avg. max.
46
87
25
39
84
162
71
126
73
123
58
90
86
151
75
126
91
144
76
112
136
234
85
122
181
324
94
132
226
414
103
142
307
576
167
259

15 solutions
ASG
LASG
avg. max. avg. max.
68
121
34
59
123
230
94
157
98
182
73
129
120
211
100
169
118
189
94
137
188
329
103
147
258
469
112
157
328
609
122
167
445
823
216
337

20 solutions
ASG
LASG
avg. max. avg. max.
90
176
46
95
160
293
116
192
125
226
90
152
151
266
123
205
151
267
108
160
243
437
117
170
335
607
127
180
427
777
136
190
583 1145
262
477

Table 22: Average maximum length Open generating 10, 15, 20 solutions
matrix-chain multiplication problems
Test case
TC1
TC2
TC3
TC4
TC5
TC6
TC7
TC8
TC9
TC10
TC11
TC12
TC13
TC14

5 solutions
ASG
LASG
avg. max. avg. max.
45
84
41
74
50
95
50
95
47
90
46
89
50
93
49
90
47
86
45
74
49
93
47
84
42
81
42
80
46
89
44
84
40
77
39
73
59
116
59
113
55
106
54
105
33
64
31
51
51
98
51
97
41
78
40
73

10 solutions
ASG
LASG
avg. max. avg. max.
93
176
75
125
100
192
94
170
90
168
82
142
101
194
87
155
98
186
87
149
105
200
95
168
83
157
73
119
97
188
86
159
80
147
70
119
128
251
116
212
115
225
110
211
67
116
55
98
103
193
100
185
82
154
69
112

15 solutions
ASG
LASG
avg. max. avg. max.
135
249
95
143
146
266
125
197
132
244
115
210
152
292
119
197
140
246
114
184
155
294
127
206
121
231
92
138
144
277
120
214
115
214
93
146
189
350
161
280
171
317
166
321
95
172
78
135
149
276
140
239
120
231
97
176

Table 23: Average maximum length Open generating 5, 10, 15 solutions
generating secondary structure RNA sequences

317

fiGhosh, Sharma, Chakrabarti, & Dasgupta

important observe methods heavily depend incorporating updates explicit DAG like adding nodes, increase cost, etc., recomputing
associated swap options along signatures use swap options. Handling
dynamic updates DAG efficiently use implicit AND/OR search spaces
remains interesting future direction.

7. Conclusion
work presented top-down algorithm generating solutions given
weighted AND/OR structure (DAG) non-decreasing order cost. Ordered solutions
AND/OR DAGs useful number areas including model based programming,
developing new variants AO*, service composition based user preferences, real life
problems dynamic programming formulation, etc. proposed algorithm two
advantages (a) works incrementally, i.e., generating specific number solutions,
next solution generated quickly, (b) number solutions generated
known priori, algorithm leverage generate solutions faster. Experimental
results show efficacy algorithm state-of-the-art. also opens
several interesting research problems development applications.

8. Acknowledgments
thank anonymous reviewers editor, Prof. Hector Geffner, valuable
comments enriched presentation paper significantly. also thank
Prof. Abhijit Mitra, International Institute Information Technology, Hyderabad, India,
valuable inputs regarding test domain involving secondary structure RNA.
thank Aritra Hazra Srobona Mitra, Research Scholar, Department Comp. Sc. &
Engg., Indian Institute Technology Kharagpur, India, proof reading paper.

Appendix A. Proof Correctness Algorithm 4
Lemma A.1 Every solution optimal solution Sopt constructed
Sopt applying sequence swap options according order R.
Proof: [Lemma A.1] Every solution Sopt alternating AND/ tree
constructed choosing non optimal edges nodes. Consider
solution Sm , corresponding set non-optimal edges suppose
|S | = m. apply relation R obtain ordered sequence edges
e1 , e2 , e1 appears e2 (e1 , e2 ) R. show exists
sequence swap options constructed . every edge eij
(here eij ith edge 1 m), append subsequence edges
ei1 , . . . , eij 1 eij , ei1 , . . . , eij edges emanate
parent vq , ei1 , . . . , eij 1 first ij 1 edges L(vq ).
get sequence edges aug mentioned augmentation.
aug basically concatenation subsequences 1 , . . . , , sequence edges
ei1 , . . . , eij ei1 , . . . , eij edges emanate parent vq ,
ei1 , . . . , eij first ij edges L(vq ). construct aug follows.
318

fiGenerating Ordered Solutions Explicit AND/OR Structures

every , construct = hi1 ,i2 , . . . , ij 1,ij i, ik ,ik +1 = heik , eik +1 , ik ,ik +1
i1 ik (ij 1). constructed concatenating every individual . Hence exists
sequence swap options corresponding every solution Sm .


Definition A.p [Default Path] Lemma A.1, every non-optimal solution Sm
constructed initial optimal solution applying sequence swap options,
(Sm ), according order R. sequence solutions formed following (Sm )
corresponds path Sopt Sm SSDAG G . path defined default
path, Pd (Sm ), Sm .
Lemma A.2 SSDAG alternating AND/OR tree contains every alternative
solution .
Proof: [Lemma A.2] prove induction length default path Pd
solutions.
[Basis (n = 1) :] Consider swap list Sopt . solutions whose default path length
equal 1 form Succ(Sopt ). Therefore solutions present G.
[Inductive Step :] Suppose solutions whose default path length less equal
n present G. prove solutions default path length equal
n + 1 also present G. Consider solution Sm Pd (Sm ) = n + 1. Let (Sm ) =
(S ) = h , , i. Since P (S ) =
h1 , , n , n+1 i. Consider solution Sm
1
n





V, swap option
n, Sm
n+1 L(Sm ), directed edge Sm Sm G .
Hence every solution default path length equal n + 1 also present G.


Lemma A.3 alternating AND/OR tree , Algorithm 4 adds solutions Closed
(at Line 11) non-decreasing order cost.
Proof: [Lemma A.3] Consider following invariants Algorithm 4 follow
description Algorithm 4.
a. minimum cost solution Open always removed Line 6 Algorithm 4.
b. cost solutions added Open, exploring successor set
solution Sm (at Line 13 Algorithm 4), greater equal C(Sm ).
two invariants follows Algorithm 4 adds solutions Closed (at Line 11)
non-decreasing order cost.
Lemma A.4 alternating AND/OR tree , every node SSDAG ,
Agorithm 4 generates solution corresponding node.
Proof: [Lemma A.4] Lemma A.3 follows Algorithm 4 generates solutions
non-decreasing order cost. generating solution Sm , mean adding Sm
Closed (at line 11 Algorithm 4). purpose proof contradiction, let us assume
Algorithm 4 generate solution Sm . Also let Sm first occurrence
319

fiGhosh, Sharma, Chakrabarti, & Dasgupta

scenario generating solutions mentioned order. According Lemma A.1,
exists sequence swap options = 1 , . . . , k corresponding Sm . Also consider
whose sequence swap options = , . . . ,
solution Sm
1
k1 . According Property 3.2,

C(Sm ) C(Sm ). Consider following two cases:
) < C(S ): Since
a. C(Sm

first instance incorrect scenario, Algo generated
rithm 4 generates solutions non-decreasing order cost, Sm
prior Sm .
) = C(S ): Since Algorithm 4 resolves tie favor parent solution,
b. C(Sm


Sm first instance incorrect scenario case also Sm
generated prior Sm .
. generated Algorithm 4,
swap option k belongs swap list Sm



is, Sm added Closed, Sm also expanded solutions
applying one swap option, added Open list. Since
constructed Sm

applying one swap option ,
constructed Sm

also
added


Open

k
. Therefore
exploring successors Sm
also eventually generated
Algorithm 4 - contradiction.



Lemma A.5 alternating AND/OR tree , Algorithm 4 add solution
Closed (at Line 11 Algorithm 4) once.
Proof: [Lemma A.5] purpose contradiction, let us assume Sm first
solution added Closed twice. Therefore Sm must added Open twice.
Consider following facts.
a. Sm added Closed first time, value lastSolCost C(Sm ),
Sm added TList.
b. description Algorithm 4 follows contents TList deleted
value lastSolCost increases.
c. Lemma A.3 follows Algorithm 4 generates solutions non-decreasing
order cost. Hence, Sm generated second time, value
lastSolCost change C(Sm ).
facts follow Sm present TList Sm added Open
second time. Since, adding solution Open, Algorithm 4 checks whether
present TList (at Line 16 Algorithm 4); Algorithm 4 must done
adding Sm Open second time. Therefore Sm could added Open
second time contradiction.


Theorem A.1 Sj V, Sj generated (at Line 11) Algorithm 4
non-decreasing order costs ties among solutions costs resolved
mentioned before.
Proof: [Theorem A.1] Follows Lemma A.2, Lemma A.3, Lemma A.4 Lemma A.5.


320

fiGenerating Ordered Solutions Explicit AND/OR Structures

Appendix B. Proof Correctness Algorithm 5
Definition B.q [Reconvergent Paths Solution Space DAG] Two paths, (i) p1 =
Si11 Si1n (ii) p2 = Si21 Si2m , SSDAG G alternating
AND/OR tree reconvergent following holds:
a. Si11 = Si21 , i.e. paths start node;
b. Si1n = Si1m , i.e. paths ends node;

c. (j [2, n 1])(k [2, 1]), Si1j 6= Si2k ; i.e. paths common
intermediate node.
Definition B.r [Order Generation Time] context Algorithm 5, define
order relation, V V, (Sp , Sq ) Sp generated Algorithm 5 Sq .
V set vertices SSDAG G alternating AND/OR tree .
Lemma B.1 Algorithm 5 adds solutions Closed list non-decreasing order
costs.
Proof: [Lemma B.1] Consider following invariants Algorithm 5 follow
description Algorithm 5.
a. minimum cost solution Open always removed line 11 Algorithm 4.
b. Algorithm 5 expands solution, say Sp , two phases. first phase Sp
expanded using native swap options Sp . solutions added Open
result application native swap options, cost greater
equal C(Sp ). second phase, i.e., lazy expansion, Sp expanded
using non native swap option. solution Sp may undergo second phase times
0 (|L(Sp )| |N (Sp , k )|) k used construct Sp . every lazy
expansion Sp , new solution added Open. Consider solution Sm
using Algorithm 5 P red(S ). Suppose swap
constructed Sm

j

option L(Sm ),
/ N (Sm , j ), i.e., native swap option Sm .
). Suppose successors respectively,
Clearly L(Sm

c

c



constructed application , i.e., Sm
Sc , Sm
Sc . Also let Sc
added Closed Sm .
Consider fact Algorithm 5 apply swap option Sm , is, Sc
) C(S ), C(S ) C(S ).
added Open Sc added Closed. Since C(Sm

c
c
According Algorithm 5, applied Sm (during lazy expansion), Sc
added Open right Sc added Closed. Consider time period
adding Sm adding Sc Closed. period, every solution added
Closed cost C(Sm ) C(Sc ), i.e., cost less equal C(Sc ).
general, application swap option add solution Open delayed
amount time, say , solutions, added Closed
time interval, cost less equal solution consideration.
321

fiGhosh, Sharma, Chakrabarti, & Dasgupta

facts follow Algorithm 5 adds solutions Closed list
non-decreasing order costs.


Lemma B.2 two reconvergent paths SSDAG G alternating AND/OR
tree equal length.
Proof: [Lemma B.2] Consider paths:












1
2
n
1
2
(i) p1 = S1
Sp

Sn , (ii) p2 = S1
Sp

Sn .

edges paths represent application swap option solution. p1
p2 start solution also end solution. Therefore sets
swap options used paths also same. Hence lengths paths
equal, is, context p1 p2 , n = m.
Lemma B.3 set reconvergent paths length n, Algorithm 5 generates
one path.
Proof: [Lemma B.3] following cases possible.
[Case 1 (n = 2) :] Consider following two paths:








1
2
1
2
(i) p1 = S1
S2
S3 , (ii) p2 = S1
S2
S3 .

obvious 1 = 2 2 = 1 . Suppose S2 S2 . Algorithm 5
apply swap option 1 S2 . Therefore p2 generated Algorithm 5.
[Case 2 (Any values n) :] case, path belonging set reconvergent paths, consists n different swap options, suppose 1 , , n . Also start
node end node paths consideration Sp Sm . Consider nodes
paths length 1 Sp . Clearly n nodes.
Among nodes, suppose Algorithm 5 adds Sp1 Closed first, Sp1 constructed
Sp applying swap option 1 . According Algorithm 5, 1 applied
node constructed Sp added Closed Sp1 . Therefore,
paths starting Sp , whose second node Sp1 , generated
Algorithm 5. use similar argument paths Sp1 Sm length n 1
determine paths generated Algorithm 5. stage, set
paths grown further, one path towards Sm continue grow.
applying previous argument n times, one path Sp Sm
constructed. Therefore Algorithm 5 generate one path Sp Sm .


Definition B.s [Connection Relation Rc Rc ] define connection relation, Rc ,
symmetric order relation pair nodes, vq vr , belonging alternating
AND/OR tree as:
(vq , vr ) Rc | exists node vp ,
exist two paths, (i) p1 = vp . . . vq ,

(ii) p2 = vp . . . vr
322

fiGenerating Ordered Solutions Explicit AND/OR Structures

Similarly connection relation, Rc , defined two swap options follows. Consider two swap options iq jr , iq = hei , eq , iq jr = hej , er , jr i. Suppose
edges ei eq emanate vp , edges ej er emanate vt .
(iq , jr ) Rc (vp , vt ) Rc .
Definition B.t [Mutually Connected Set] solution Sm , set Vm nodes
mutually connected,

v1 , v2 Vm , (v1 6= v2 ) {(v1 , v2 ) Rc }
Consider set nodes, Vm = {v1 , , vk }, swap option j belongs vj
1 j k. set swap options Vm = {1 , , k } mutually connected.
Lemma B.4 Suppose Sm solution alternating AND/OR tree , P red(Sm ) =
{S1 , , Sk }, swap option j used construct Sm Sj 1 j k.
swap options 1 , , k mutually connected.
Proof: [Lemma B.4] Since Sm constructed S1 , , Sk applying 1 , , k respectively, 1 , , k present signature Sm . Suppose set = {1 , , k }.
show

, b , (a , b ) Rc

purpose proof contradiction, let us assume (i1 , i2 )
/ Rc . Also Sm constructed applying i1 i2 Si1 Si2 respectively. Consider path p1 SSDAG
starts Sopt ends Sm , along p1 , Si1 parent Sm .
along path, i2 applied application swap option i1 . Similarly consider path p2 SSDAG starts Sopt ends Sm , along p2 ,
Si2 parent Sm . Along path, i1 applied application swap
option i2 .
Suppose i1 i2 belongs node v1 v2 respectively. Since along path p1 , i1
swap option applied last, Sm contains node v1 . Similarly along path p2 , i2
swap option applied last. Hence Sm contains node v2 . Therefore, must
node vr , exist paths node v1 v2 implies
(i1 , i2 ) Rc . arrive contradiction proves 1 , , k mutually connected.



Definition B.u [Subgraph SSDAG] Consider solution Sp alternating AND/OR
tree Tand mutually connected set Vm nodes Sp , vq Vm , C(Sp , vq ) =
(S , V ) = hV
Copt (vq ) . subgraph Gsub
p
sub , Esub SSDAG respect Sp
Vm defined follows. Vsub consists solutions constructed
Sp applying sequence swap options belonging Vm , Esub set edges
corresponding swap options belong Vm .
(S , V )
Lemma B.5 number total possible distinct solutions level Gsub
p

,

|V
|
=
n.
n+d2

n1

323

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Proof: [Lemma B.5] Consider swap options belong nodes Vm .
(S , V ) represented sequence
respect swap options, every solution Sr Gsub
p
numbers length n, Seq(Sr ), every number corresponds distinct node Vm .
numerical value number represent rank swap option chosen
node vq Vm . According representation, level:
i. sum numbers Seq(Sr ) solution, Sr , equal sum numbers
Seq(Sr ) solution, Sr , level;
ii. sum numbers Seq(Sr ) solution, Sr , increased 1 sum
numbers Seq(Sr ) solution, Sp , previous level.
Hence, dth level, n slots 1 increments need made
Seq(Sr ). instance well known combinatorial problem packing n + 1
objects n slots
restriction keeping least one object per slot.
n+d2
done n1 ways.


Theorem B.1 solution space tree constructed Algorithm 5 complete.
Proof: [Theorem B.1] purpose contradiction, suppose Sm first solution
generated Algorithm 5. Also P red(Sm ) = {Spi } Sm constructed
Spi applying qi , 1 k. Lemma B.4 follows set
swap options {qi | 1 k} mutually connected. Therefore set nodes Vm
swap options belong also mutually connected. Suppose |Vm | = n.
Consider solution Sq , Vm mutually connected, 1 k, every qi
belongs set native swap options Sq respect swap option used
construct Sq . Clearly

vt Vm , C(Sq , vt ) = Copt (vt )

argue Sq generated Algorithm 5 Sm first solution
rooted ,
generated Algorithm 5. Consider subtree Tsub
q
edges corresponding swap options belong Vm considered. prove
equal
number solutions generated Algorithm 5 every level Tsub

number solutions level Gsub (Sq , Vm ).
Consider solution Sq set Succ(Sq ). Suppose Succ(Sq , Vm ) set
successor solutions constructed Sq applying swap options belonging

minimum cost solution Succ(Sq , Vm ). According
nodes Vm , Smin

Algorithm 5 initially Succ(Smin ) partially explored using set native swap options

Smin
. non native swap option, b , belongs nodes Vm , used


explore Succ(Smin
), right sibling solution Smin
, constructed applying b Sq,
added Closed. Consider fact solution Sq , vt Vm , C(Sq , vt ) = Copt (vt )
holds. Therefore swap options belonging Vm also eventually used explore

successors Smin
. Similarly second best successor Sq able use

.
one swap option, c , used construct Smin


immediate children Smin Tsub consist solutions, obtained


application one swap option Vm Smin
. native swap list Smin
contains
swap option ranking next c . swap options, used construct
324

fiGenerating Ordered Solutions Explicit AND/OR Structures


n 1 sibling solutions Smin
, used lazy expansion, accounts


another n 1 children Smin
. Hence would n children Smin
.

Similarly, second best successor Sq Tsub n 1 immediate children.
n 2 children on. children
third best successor Sq Tsub
solutions children solutions own, increasing number
solutions level tree. way, increasing level, number
solutions present level keeps increasing. prove following proposition part
proving Theorem B.1.
) given
Proposition B.1 level d, number solutions N (d, n, Tsub


n
X
n+d2


N (d, n, Tsub ) =
N (d 1, k, Tsub ) =
n1
k=1

Proof: [Proposition B.1] second level, n solutions. give rise

k=1

k+

n1
X

k+

k=1

n2
X
k=1

k

k=1

solutions third level. Similarly fourth level
n
X

n
X



) + ... + 1
) + N (3, n 1, Tsub
k.... + 1 = N (3, n, Tsub

extend level result follows.

) = 1
N (1, n, Tsub


) = n
N (2, n, Tsub


n
X
n+1

N (3, n, Tsub ) =
k=
2
k=1


N (4, n, Tsub
)

=

n
X
k=1


N (3, k, Tsub
)

=




n+2
3

induction depth d.
determine number solutions level Tsub

[Basis (d = 1) :]

) = n.
Clearly, N (1, n, Tsub



[Inductive Step :] Suppose, dth level number solutions n+d2
= n+d2
n1
d1 .
Therefore + 1th level,





n
X
n+d2
n+d3
n+d1


N (d + 1, n, Tsub ) =
+
N (d, k, Tsub ) =
+ + 1 =
d1
d1
n1
k=1

Since Algorithm 5 generate duplicate node, Proposition B.1
(S , V ) level equal number solutions
number solutions Gsub
q

(S , V ) also generated

level Tsub , level set solutions Gsub
q
(S , V ),

Algorithm 5 Tsub . Therefore, level, Sm belongs Gsub
q
also generated Algorithm 5. Therefore Sm also generated Algorithm 5
contradiction establishes truth statement Theorem B.1.


325

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Appendix C. Conversion AND/OR Tree Alternating
AND/OR Tree
AND/OR tree generalization alternating AND/OR tree restriction
strict alternation nodes relaxed. words intermediate
node child another intermediate node similar parent child
relation also allowed node. present algorithm convert AND/OR
equivalent alternating AND/OR tree.
use two operations namely, folding unfolding conversions. Corresponding
every edge, stack, update-list, used conversions. AND/OR tree, consider
two nodes, vq vr , similar type (AND/OR) connected edge er .
Edges, e1 , , ek emanate er .
[Folding Node :] Suppose vq vr nodes. folding vr performed
follows.
source edges e1 , , ek changed vr vq costs updated
ce (ei ) ce (ei ) + ce (er ) + cv (vr ) 1 k, new cost sum
old cost cost edge points source ei . triplet
hvr , cv (vr ), ce (er )i pushed update-list ei , 1 k.
edge er along node vr removed vq .
[Folding Node :] Suppose vq vr nodes. folding vr performed follows.
source edges e1 , , ek changed vr vq . One edges among
e1 , , ek , suppose ei , selected arbitrarily cost updated ce (ei )
ce (ei ) + ce (er ) + cv (vr ) 1 k. triplet hvr , cv (vr ), ce (er )i pushed
update-list ei , whereas triplet hvr , 0, 0i pushed update-list ej ,
1 j k j 6= i.
edge er along node vr removed vq .
unfolding operation reverse folding operation
nodes. works node vq follows.
Procedure Unfold(node vq )
1
2
3
4
5
6
7
8
9
10
11

forall edge ei emanate vq
update list ei empty
hvt , c1 , c2 pop(update list ei );
exists edge et vq points node vt
Create node vt , connect vt using edge et vq ;
cv (vt ) c1 ;
ce (et ) c2 ;
else c2 6= 0
ce (et ) c2 ;
end
end

326

fiGenerating Ordered Solutions Explicit AND/OR Structures

Function Convert takes root node AND/OR tree transforms equivalent
alternating AND/OR tree recursively.
Function Convert(vq )
1
2
3
4
5
6

7

every child vq terminal node
vq parent vp type
Apply f old operation vq ;
end
else
foreach child vr vq , vr intermediate AND/OR node
Convert(vr );
end

Function Revert takes root node alternating AND/OR tree converts
original AND/OR tree recursively.
Function Revert(vq )
1
2
3
4
5
6

every child vq terminal node
return;
Perform unf old operation vq ;
foreach child vr vq
Revert(vr );
end

overall process generating alternative solutions AND/OR tree follows.
AND/OR tree converted alternating AND/OR tree using Convert function,
solutions generated using ASG algorithm. solutions transformed back
using Revert function. proof correctness presented below.
C.1 Proof Correctness
Suppose AND/OR tree two nodes, vq vr , similar type (AND/OR)
connected edge er . Edges e1 , , ek emanate er . fold operation
1 AND/OR tree generated application
applied vq vr . Let
f old operation.
Lemma C.1 context mentioned above, present claim following two
propositions.
Proposition C.1 set solutions node vq generated set
1 node v applying unfold operation v solutions
solutions
q
q
.
1 1 contains node v , exists soluProposition C.2 every solution Sm
q

1
tion Sm generated Sm applying unfold vq .

Proof: [Proposition C.1] present proof following cases. Consider
solution Sm contains node vq .
327

fiGhosh, Sharma, Chakrabarti, & Dasgupta

a. vq vr nodes: two cases possible.
1. vr absent Sm : Since fold operation modifies edge er only,
1 . Therefore
edges vq also present
also
1
present solution set remain unchanged
application unfold operation.
2. vr present Sm : Since k distinct edges emanating vr ,
let one edges, say ei , present Sm . prove
1 1 , application unfold operation 1
solution Sm


generate Sm . application fold operation node vr modifies source
1 .
cost edge ei vr vq ce (ei ) ce (ei ) + ce (er ) + cv (vr )
1 solution 1 , edge e present 1 . Also
Suppose Sm



1
subtree rooted vq , remaining parts Sm
identical
1
1
other. Clearly Sm exists solution application
1 generates .
unfold operation vq Sm

b. vq vr nodes: Since vq node Sm contain
edges emanate vq . Therefore edge er vr present
1 1 , following holds.
Sm . Consider solution Sm

1.
1. vq present Sm

2. subtrees rooted children vq vr Sm identical
1 .
subtrees rooted children vq Sm
1 identical
3. subtree rooted vq , remaining parts Sm

other.
1 exists solution 1 application unfold operation v
Clearly Sm
q

1
Sm generates Sm .

1
solution Sm
contain node vq , valid solution
well.



Proof: [Proposition C.2] present proof following cases. Consider
1 1 contains node v .
solution Sm
q

a. vq vr nodes: Since vq node, exactly one edge ei vq
1 . two cases possible.
belong Sm
1 : Since fold operation modifies
1. ei modified folding vr
edge er edges vr only, edges vq
1 . Since e modified folding, solution
also present

1
Sm also valid solution .
1 : Suppose e connects v v
2. ei modified folding vr

q

1 generate solution .
1
Sm . Apply unfold operation node vq Sm

edge ei replaced edge er connects vq vr ei
connect vr vi . argue Sm valid solution since

328

fiGenerating Ordered Solutions Explicit AND/OR Structures

subtree rooted vi modified sequence (a) folding vr
1 , (b) unfolding v construct 1 .
construct
q



1 contain
b. vq vr nodes: Since vq node, Sm
edges emanate vq . two types edges emanating
1 (a) Type-1 : edges v also present
vq
q

vq , (b) Type-2 : edges added vq folding edges
1 generate solution
vr . Apply unfold operation node vq Sm
Sm . Sm contain Type-1 edges, another edge er vq . Sm , vq vr
connected er Type-2 edges originated vr . argue Sm
valid solution since subtree rooted nodes pointed Type-2 edges
1 ,
modified sequence (a) folding vr construct

1.
(b) unfolding vq construct Sm Sm


1 1 contain node v valid solution
Clearly solution Sm
q


well.



Lemma C.2 function Convert applied root node AND/OR tree ,
alternating AND/OR tree generated.
Proof: [Lemma C.2] Function Convert traverses every intermediate node depth first
manner. Consider sequence nodes, vq1 , vq2 , , vqn type, vqi
parent vqi+1 1 < n. Obviously, fold operation applied vqi+1
vqi , 1 < n. words, fold operation applied sequence
nodes reverse order folding vqi+1 , edges vqi+1 modified
moved vqi , 1 < n. function call Convert(vq2 ) returns, edges
vq2 , , vqn already moved vq1 sequence nodes, vq1 , vq2 , , vqn
flattened. Therefore, every sequence nodes type flattened, function
call Convert(vR ) returns, vR root alternating AND/OR tree
generated.
Lemma C.3 function Revert applied alternating AND/OR tree , updatelist every edge becomes empty.
Proof: [Lemma C.3] Follows description Revert.
Theorem C.1 AND/OR tree , possible construct alternating AND/OR
tree using function Convert, set possible solutions generated
order increasing cost applying Algorithm 4 , converting
individual solutions using function Revert.
Proof: [Theorem C.1] According Lemma C.2, application function Convert
alternating AND/OR tree generated. Consider intermediate AND/OR
0 , 1 , , n
trees generated folding every node . Let


n . Since generated i+1
0 = ,
=

sequence AND/OR trees





329

fiGhosh, Sharma, Chakrabarti, & Dasgupta

, 0 < n, according
folding exactly one node
generated i+1 unfolding
solutions

Lemma C.3, solution , Revert unfolds every node vq
vq folded Convert transforming . Therefore
generated solutions .

Lemma C.1,
node. According
solution,
solutions

References
Bonet, B., & Geffner, H. (2005). algorithm better AO ?. Proceedings
20th national conference Artificial intelligence - Volume 3, pp. 13431347. AAAI
Press.
Chakrabarti, P. P. (1994). Algorithms searching explicit AND/OR graphs
applications problem reduction search. Artif. Intell., 65 (2), 329345.
Chakrabarti, P. P., Ghose, S., Pandey, A., & DeSarkar, S. C. (1989). Increasing search
efficiency using multiple heuristics. Inf. Process. Lett., 32 (5), 275275.
Chang, C. L., & Slagle, J. R. (1971). admissible optimal algorithm searching
AND/OR graphs. Artif. Intell., 2 (2), 117128.
Chegireddy, C. R., & Hamacher, H. W. (1987). Algorithms finding k-best perfect matchings. Discrete Applied Mathematics, 18 (2), 155165.
Chen, H., Xu, Z. J., Liu, Z. Q., & Zhu, S. C. (2006). Composite templates cloth modeling
sketching. Proceedings 2006 IEEE Computer Society Conference
Computer Vision Pattern Recognition - Volume 1, pp. 943950. IEEE Computer
Society.
Cormen, T. H., Stein, C., Rivest, R. L., & Leiserson, C. E. (2001). Introduction Algorithms
(2nd edition). McGraw-Hill Higher Education.
Darwiche, A. (1999). Compiling knowledge decomposable negation normal form.
Proceedings 16th international joint conference Artifical intelligence - Volume
1, pp. 284289. Morgan Kaufmann Publishers Inc.
Darwiche, A. (2001). Decomposable negation normal form. J. ACM, 48, 608647.
Dasgupta, P., Sur-Kolay, S., & Bhattacharya, B. (1995). VLSI floorplan generation
area optimization using and-or graph search. VLSI Design, 1995., Proceedings
8th International Conference on, pp. 370 375.
Dechter, R., & Mateescu, R. (2007). AND/OR search spaces graphical models. Artif.
Intell., 171 (2-3), 73106.
Ebendt, R., & Drechsler, R. (2009). Weighted search - unifying view application.
Artificial Intelligence, 173 (14), 1310 1342.
Elliott, P. (2007). Extracting k best solutions valued And-Or acyclic graph.
Masters thesis, Massachusetts Institute Technology.
Elliott, P., & Williams, B. (2006). DNNF-based belief state estimation. Proceedings
21st national conference Artificial intelligence - Volume 1, pp. 3641. AAAI
Press.
330

fiGenerating Ordered Solutions Explicit AND/OR Structures

Eppstein, D. (1990). Finding k smallest spanning trees. Proc. 2nd Scandinavian
Worksh. Algorithm Theory, No. 447 Lecture Notes Computer Science, pp. 38
47. Springer Verlag.
Eppstein, D. (1998). Finding k shortest paths. SIAM J. Comput., 28 (2), 652673.
Flerova, N., & Dechter, R. (2010). best solutions graphical models. 1st Workshop
Constraint Reasoning Graphical Structures.
Flerova, N., & Dechter, R. (2011). Bucket mini-bucket schemes best solutions
graphical models. GKR 2011(a workshop IJCAI 2011).
Fromer, M., & Globerson, A. (2009). LP view m-best MAP problem. Advances
Neural Information Processing Systems (NIPS) 22, pp. 567575.
Fuxi, Z., Ming, T., & Yanxiang, H. (2003). solution billiard balls puzzle using ao
algorithm application product development. Palade, V., Howlett, R., &
Jain, L. (Eds.), Knowledge-Based Intelligent Information Engineering Systems,
Vol. 2774 Lecture Notes Computer Science, pp. 10151022. Springer Berlin /
Heidelberg.
Gogate, V., & Dechter, R. (2008). Approximate solution sampling (and counting)
AND/OR spaces. CP, pp. 534538.
Gu, Z., Li, J., & Xu, B. (2008). Automatic service composition based enhanced service
dependency graph. Web Services, 2008. ICWS 08. IEEE International Conference
on, pp. 246 253.
Gu, Z., Xu, B., & Li, J. (2010). Service data correlation modeling application
data-driven service composition. Services Computing, IEEE Transactions on, 3 (4),
279291.
Gupta, P., Chakrabarti, P. P., & Ghose, S. (1992). Towers Hanoi: generalizations,
specializations algorithms. International Journal Computer Mathematics, 46,
149161.
Hamacher, H. W., & Queyranne, M. (1985). K best solutions combinatorial optimization
problems. Annals Operations Research, 4, 123143.
Hansen, E. A., & Zhou, R. (2007). Anytime heuristic search. J. Artif. Intell. Res. (JAIR),
28, 267297.
Hansen, E. A., & Zilberstein, S. (2001). LAO : heuristic search algorithm finds
solutions loops. Artificial Intelligence, 129 (1-2), 35 62.
Homem de Mello, L., & Sanderson, A. (1990). AND/OR graph representation assembly
plans. Robotics Automation, IEEE Transactions on, 6 (2), 188 199.
Jimenez, P., & Torras, C. (2000). efficient algorithm searching implicit AND/OR
graphs cycles. Artif. Intell., 124, 130.
Kleinberg, J., & Tardos, E. (2005). Algorithm Design. Addison-Wesley Longman Publishing
Co., Inc., Boston, MA, USA.
Lang, Q. A., & Su, Y. (2005). AND/OR graph search algorithm discovering composite web services. International Journal Web Services Research, 2 (4), 4664.
331

fiGhosh, Sharma, Chakrabarti, & Dasgupta

Lawler, E. L. (1972). procedure computing k best solutions discrete optimization
problems application shortest path problem. Management Science,
18 (7), pp. 401405.
Ma, X., Dong, B., & He, M. (2008). AND/OR tree search algorithm web service composition. PACIIA 08: Proceedings 2008 IEEE Pacific-Asia Workshop
Computational Intelligence Industrial Application, pp. 2327, Washington, DC,
USA. IEEE Computer Society.
Majumdar, A. A. K. (1996). Generalized multi-peg Tower Hanoi problem. Journal
Australian Mathematical Society. Series B. Applied Mathematics, 38, 201208.
Marinescu, R., & Dechter, R. (2005). AND/OR branch-and-bound solving mixed integer
linear programming problems. CP, p. 857.
Marinescu, R., & Dechter, R. (2006). Memory intensive branch-and-bound search graphical models. AAAI.
Marinescu, R., & Dechter, R. (2007a). Best-first AND/OR search 0/1 integer programming. CPAIOR, pp. 171185.
Marinescu, R., & Dechter, R. (2007b). Best-first AND/OR search graphical models.
AAAI, pp. 11711176.
Marinescu, R., & Dechter, R. (2009a). AND/OR branch-and-bound search combinatorial
optimization graphical models. Artif. Intell., 173 (16-17), 14571491.
Marinescu, R., & Dechter, R. (2009b). Memory intensive AND/OR search combinatorial
optimization graphical models. Artif. Intell., 173 (16-17), 14921524.
Martelli, A., & Montanari, U. (1973). Additive AND/OR graphs. Proceedings
3rd international joint conference Artificial intelligence, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.
Martelli, A., & Montanari, U. (1978). Optimizing decision trees heuristically guided
search. Commun. ACM, 21, 10251039.
Mateescu, R., & Dechter, R. (2008). AND/OR multi-valued decision diagrams constraint
networks. Concurrency, Graphs Models, pp. 238257.
Mateescu, R., Dechter, R., & Marinescu, R. (2008). AND/OR multi-valued decision diagrams (AOMDDs) graphical models. J. Artif. Intell. Res. (JAIR), 33, 465519.
Mathews, D. H., & Zuker, M. (2004). RNA secondary structure prediction. Encyclopedia
Genetics, Genomics, Proteomics Bioinformatics. John Wiley & Sons, Ltd.
Nilsson, D. (1998). efficient algorithm finding probable configurations
probabilistic expert systems. Statistics Computing, 8, 159173.
Nilsson, N. J. (1980). Principles artificial intelligence. Tioga Publishing Co.
Otten, L., & Dechter, R. (2011). Anytime AND/OR depth-first search combinatorial
optimization. SoCS.
Pearl, J. (1984). Heuristics: intelligent search strategies computer problem solving.
Addison-Wesley Longman Publishing Co., Inc., Boston, MA, USA.
332

fiGenerating Ordered Solutions Explicit AND/OR Structures

Russell, S., & Norvig, P. (2003). Artificial Intelligence: Modern Approach (2nd edition
edition)., chap. Planning, pp. 375461. Prentice-Hall, Englewood Cliffs, NJ.
Shiaa, M. M., Fladmark, J. O., & Thiell, B. (2008). incremental graph-based approach
automatic service composition. IEEE International Conference Services Computing, 4 (2), 4664.
Shin, D. H., Jeon, H. B., & Lee, K. H. (2010). sophisticated approach composing
services based action dominance relation. Services Computing Conference (APSCC), 2010 IEEE Asia-Pacific, pp. 164 170.
Subramanian, S. (1997). Routing algorithms dynamic, intelligent transportation networks. Masters thesis, Virginia Technical Univ., Dept. Civil Engineering.
Sugimoto, K., & Katoh, N. (1985). algorithm finding k shortest loopless paths
directed network. Trans. Information Processing Soc. Japan, 26, 356364.
Japanese.
Szymanski, M., Barciszewska, M. Z., Barciszewski, J., & Erdmann, V. A. (2005). 5S Ribosomal RNA Database. http://biobases.ibch.poznan.pl/5SData/. Online Database.
Takkala, T., Borndorfer, R., & Lobel, A. (2000). Dealing additional constraints
k-shortest path problem. Proc. WM 2000.
Topkis, D. M. (1988). k-shortest path algorithm adaptive routing communications
networks. Trans. Communications, 36 (7), 855859.
Yan, Y., Xu, B., & Gu, Z. (2008). Automatic service composition using AND/OR graph.
E-Commerce Technology Fifth IEEE Conference Enterprise Computing,
E-Commerce E-Services, 2008 10th IEEE Conference on, pp. 335338.

333

fiJournal Artificial Intelligence Research 44 (2012) 491-532

Submitted 11/11; published 07/12

Riffled Independence Efficient Inference
Partial Rankings
Jonathan Huang

jhuang11@stanford.edu

James H. Clark Center
Stanford University, Stanford CA 94305, USA

Ashish Kapoor

akapoor@microsoft.com

Microsoft Research
One Microsoft Way
Redmond WA 98052-6399, USA

Carlos Guestrin

guestrin@cs.cmu.edu

Gates Hillman Complex, Carnegie Mellon University,
5000 Forbes Avenue, Pittsburgh, PA 15213, USA

Abstract
Distributions rankings used model data multitude real world settings
preference analysis political elections. Modeling distributions presents
several computational challenges, however, due factorial size set rankings
item set. challenges quite familiar artificial intelligence
community, compactly represent distribution combinatorially large
space, efficiently perform probabilistic inference representations.
respect ranking, however, additional challenge refer
human task complexity users rarely willing provide full ranking long list
candidates, instead often preferring provide partial ranking information.
Simultaneously addressing challenges i.e., designing compactly representable model amenable efficient inference learned using partial
ranking data difficult task, necessary would like scale problems
nontrivial size. paper, show recently proposed riffled independence
assumptions cleanly efficiently address challenges. particular,
establish tight mathematical connection concepts riffled independence
partial rankings. correspondence allows us develop efficient
exact algorithms performing inference tasks using riffled independence based representations partial rankings, somewhat surprisingly, also shows efficient inference
possible riffle independent models (in certain sense) observations
take form partial rankings. Finally, using inference algorithm, introduce
first method learning riffled independence based models partially ranked data.

1. Probabilistic Modeling Ranking Data: Three Challenges
Rankings arise number machine learning application settings preference analysis movies books (Lebanon & Mao, 2008) political election analysis (Gormley
& Murphy, 2007; Huang & Guestrin, 2010). many problems, great interest
build statistical models ranking data order make predictions, form recommendations, discover latent trends structure construct human-comprehensible data
summaries.
c
2012
AI Access Foundation. rights reserved.

fiHuang, Kapoor & Guestrin

Modeling distributions rankings difficult problem, however, due fact
number items ranked increases, number possible rankings increases
factorially. combinatorial explosion forces us confront three central challenges
dealing rankings. First, need deal storage complexity compactly represent distribution space rankings?1 algorithmic complexity efficiently answer probabilistic inference queries given distribution?
Finally, must contend refer human task complexity,
challenge stemming fact difficult accurately elicit full ranking
large list candidates human user; choosing list n! options easy task
users typically prefer provide partial information. Take American Psychological
Association (APA) elections, example, allow voters rank order candidates
favorite least favorite. 1980 election, five candidates, therefore
5! = 120 ways rank five candidates. Despite small candidate list, voters
election preferred specify top-k favorite candidates rather writing
full rankings ballots (see Figure 1). example, roughly third voters
simply wrote single favorite candidate 1980 election.
three intertwined challenges storage, algorithmic, human task complexity
central issues probabilistic modeling rankings, models efficiently
handle three sources complexity limited applicability. paper, examine
flexible intuitive class models rankings based generalization probabilistic
independence called riffled independence, proposed recent work (Huang & Guestrin,
2009, 2010). previous papers focused primarily representational (storage
complexity) issues, concentrate inference incomplete observations (i.e., partial
rankings), showing addition storage complexity, riffle independence based models
efficiently address issues algorithmic human task complexity.
fact two issues algorithmic human task complexity intricately linked
riffle independent models. considering partial rankings, give users flexibility
provide much little information care give. context partial
ranking data, relevant inference queries also take form partial rankings.
example, might want predict voters second choice candidate given information
first choice. One main contributions paper show inference
partial ranking queries performed particularly efficiently riffle independent
models.
main contributions work follows:2
reveal natural fundamental connection riffle independent models
partial rankings. particular, show collection partial rankings
item set form complete characterization space observations upon
1. Note common wonder one would care represent distribution rankings
number sample rankings never nearly large. problem number samples always
much smaller n! however, means rankings never observed, limiting ability
estimate probability arbitrary ranking. way overcome paucity samples
exploit representational structure, much alignment solving storage complexity
issue.
2. paper extended presentation paper (Huang, Kapoor, & Guestrin, 2011) appeared
2011 Conference Uncertainty Artificial Intelligence (UAI) well results first
authors dissertation (Huang, 2011).

492

fiEfficient Inference Partial Rankings

First
Choice

Second
Choice

Third
Choice

Fourth
Choice

Fifth
Choice

#
votes

5

3

4

2

1

37

3

4

5

1

2

30

1

2

3

---

---

27

3

---

---

---

---

1198

4

1

3

---

---

15

1

3

---

---

---

302

3

1

2

5

4

186

Figure 1: Example partial ranking data (taken American Psychological Association
election dataset, 1980)

one efficiently condition riffle independent model. result, show
ranked items satisfy riffled independence relationship, conditioning
partial rankings done efficiently, running time O(n|H|), |H| denotes
number model parameters.
prove that, sense (which formalize), impossible efficiently condition
riffle independent models observations take form partial rankings.
propose first algorithm capable efficiently estimating structure
parameters riffle independent models heterogeneous collections partially
ranked data.
show results real voting preference data evidencing effectiveness
methods.

2. Riffled Independence Rankings
ranking, , items item set one-to-one mapping rank
set R = {1, . . . , n} denoted using vertical bar notation 1 (1)| 1 (2)| . . . | 1 (n).
say ranks item i1 (or over) item i2 rank i1 less
rank i2 . example, might {Corn, P eas, Apples, Oranges} ranking
Corn|P eas|Apples|Oranges encodes preference Corn Peas turn preferred Apples on. collection possible rankings item set denoted
(or Sn implicit).
Since n! rankings n items, intractable estimate even explicitly
represent arbitrary distributions Sn without making structural assumptions
underlying distribution. many possible simplifying assumptions one
make, focus approach proposed recent papers (Huang & Guestrin,
2009, 2010) ranks items assumed satisfy intuitive generalized notion
probabilistic independence known riffled independence. paper, argue
riffled independence assumptions particularly effective settings one would like
make queries taking form partial rankings. remainder section,
review riffled independence.
493

fiHuang, Kapoor & Guestrin

riffled independence assumption posits rankings item set generated independently generating rankings smaller disjoint item subsets (say,
B) partition , piecing together full ranking interleaving (or riffle shuffling)
smaller rankings together. example, rank item set foods, one might first
rank vegetables fruits separately, interleave two subset rankings form
full ranking. formally define riffled independence, use notions relative rankings
interleavings.
Definition 1 (Relative ranking map). Given ranking subset ,
relative ranking items A, (), ranking, SA , (i) < (j)
(i) < (j).
Definition 2 (Interleaving map). Given ranking partition disjoint
sets B, interleaving B (denoted, AB ()) (binary) mapping
rank set R = {1, . . . , n} {A, B} indicating whether rank occupied
B. rankings, denote interleaving ranking vertical bar notation:
[AB ()](1)|[AB ()](2)| . . . |[AB ()](n).
Example 3. Consider partitioning item set vegetables = {Corn, P eas}
fruits B = {Apples, Oranges}, well full ranking four items: =
Corn|Oranges|P eas|Apples. case, relative ranking vegetables () =
Corn|P eas relative ranking fruits B () = Oranges|Apples. interleaving vegetables fruits AB () = A|B|A|B.
Definition 4 (Riffled Independence). Let h distribution consider subset
items complement B. sets B said riffle independent
h decomposes (or factors) as:
h() = mAB (AB ()) fA (A ()) gB (B ()),
distributions mAB , fA gB , defined interleavings relative rankings
B respectively. words, B riffle independent relative rankings
B, well interleaving mutually independent. refer mAB
interleaving distribution fA gB relative ranking distributions.
Riffled independence found approximately hold number real datasets
(Huang & Guestrin, 2012). relationships identified data, instead
exhaustively representing n! ranking probabilities, one represent factors
mAB , fA gB , distributions smaller sets.
2.1 Hierarchical Riffle Independent Models
relative ranking factors fA gB distributions rankings.
reduce parameter space, natural consider hierarchical decompositions item sets
nested collections partitions (like hierarchical clustering). example, Figure 2.1
shows hierarchical decomposition vegetables riffle independent fruits among
healthy foods, healthy foods are, turn, riffle independent subset
desserts: {Doughnuts, &M s}.
494

fiEfficient Inference Partial Rankings

{C,P,A,O,D,M}

{D,M}

{C,P,A,O}

Doughnuts, M&Ms

{C,P}

{A,O}

Corn, Peas

Apples, Oranges

Figure 2: example hierarchy six food items.
simplicity, restrict consideration binary hierarchies, defined tuples
form H = (HA , HB ), HA HB either (1) null, case H called leaf,
(2) hierarchies item sets B respectively. second case, B
assumed form nontrivial partitioning item set.
Definition 5. say distribution h factors riffle independently respect
hierarchy H = (HA , HB ) item sets B riffle independent respect h,
fA gB factor riffle independently respect subhierarchies HA HB ,
respectively.
Like Bayesian networks, hierarchies represent families distributions obeying
certain set (riffled) independence constraints parameterized locally. draw
model, one generates full rankings recursively starting drawing rankings
leaf sets, working tree, sequentially interleaving rankings reaching
root. parameters hierarchical models simply interleaving relative
ranking distributions internal nodes leaves hierarchy, respectively.
general, number total parameters required represent hierarchical riffle
independent model (as Bayesian networks) still scale exponentially number

items. example, number interleavings p items n p items np .
often case however, much fewer parameters necessary. example, thin
models (Huang & Guestrin, 2012), number items factored model
stage hierarchy never small constant k, always represented
(degree k) polynomial number parameters. use |H| refer number
parameters necessary representing distribution factors according hierarchy
H.
decomposing distributions rankings small pieces (like Bayesian networks
done distributions), hierarchical models allow better interpretability,
efficient probabilistic representation, low sample complexity, efficient MAP optimization,
and, show paper, efficient inference.
Example 6. Figure 3(a), reproduce hierarchical structure learned using
fully ranked subset APA data consisting 5000 training examples Huang
Guestrin (2012). five candidates election: (1) William Bevan, (2) Ira
Iscoe, (3) Charles Kiesler, (4) Max Siegle, (5) Logan Wright (Marden, 1995). Strikingly,
structure learned using algorithm (maximum likelihood) knows nothing
underlying politics APA, leaf nodes correspond exactly
political coalitions dominated APA 1980 election research psychologists
495

fiHuang, Kapoor & Guestrin

A={12345}

B={1345}

C={2}
Community
psychologists

mB,C()
.14

B|C|B|B|B

.19

B|B|C|B|B

.25

B|B|B|C|B

.25

B|B|B|B|C

.18



mD,E()



fC()

D|D|E|E

.28

2

1.00

D|E|D|E

.12

D|E|E|D

.12

D={13}

E={45}

E|D|D|E

.14

Research
psychologists

Clinical
psychologists

E|D|E|D

.12

E|E|D|D

.22

(a) Hierarchical structure learned
via MLE using 5000 full rankings
APA dataset.


C|B|B|B|B



fD()



fE()

1|3

.50

4|5

.48

3|1

.50

5|4

.52

(b) Riffle independent model parameters learned via MLE using
5000 full rankings APA dataset.

Figure 3: Example hierarchical model APA election. Candidates enumerated
as: (1) William Bevan, (2) Ira Iscoe, (3) Charles Kiesler, (4) Max Siegle, (5)
Logan Wright (Marden, 1995).

(candidates 1 3), clinical psychologists (candidates 4 5), community
psychologists (candidate 2).
Figure 3(b), plot corresponding parameter distributions learned via
maximum likelihood. three relative ranking distributions, corresponding
political party, well two interleaving distributions (one interleaving research
clinical psychologists, one interleaving community psychologist
remaining candidates). Since parameter distribution constrained sum 1,
total 11 free parameters.
2.2 Model Estimation
paper estimate riffle independent models based methods introduced
earlier work. Given hierarchial structure model, maximum likelihood parameter
estimates hierarchical riffle independent model straightforward compute via frequency estimates. estimate correct structure model challenging
problem. key insight lies noticing two subsets B riffle independent,
j, k B, independence relation (i) ((j) < (k)) must hold.
structure learning algorithms operate hunting tripletwise independence
relations within data. defer interested readers details (Huang & Guestrin,
2012).
496

fiEfficient Inference Partial Rankings

Note earlier work, assumed algorithms access dataset
consisting i.i.d. full rankings provided users. current work, relax
assumptions allowing users provide partially ranked data. One assumption throughout, however, user full ranking mind items. particular,
current work address incomplete ranking problem, users might
seen items (we discuss possible extensions incomplete ranking setting
Section 9.

3. Decomposable Observations
Given prior distribution, h, rankings observation O, Bayes rule tells us
posterior distribution, h(|O), proportional L(O|) h(), L(O|)
likelihood function. operation conditioning h observation typically computationally intractable since requires multiplying two n! dimensional functions, unless
one exploit structural decompositions problem. section, describe decomposition certain class likelihood functions space rankings
observations factored simpler parts. observation decomposable
way, show one efficiently condition riffle independent prior distribution
O. simplicity paper, focus primarily subset observations whose likelihood
functions encode membership subset rankings Sn .
Definition 7 (Subset observations). subset observation binary observation whose
likelihood proportional indicator function subset Sn i.e.,

1
.
L(O|) =
0 otherwise
running example, consider class first place observations throughout
chapter (we consider far general observation models later sections). first
place observation =Corn ranked first, example, associated collection
rankings placing item Corn first place (O = { : (Corn) = 1}). interested
computing posterior h(| O). Thus first place scenario, given voters
top choice would like infer preferences remaining candidates.
Given partitioning item set two subsets B, sometimes possible
decompose (or factor ) subset observation involving items smaller subset observations involving A, B interleavings B independently. decompositions
often exploited efficient inference.
Example 8.
Consider first place observation
= Corn ranked first,
decomposed two independent observations observation
relative ranking Vegetables, observation interleaving Vegetables
Fruits:
497

fiHuang, Kapoor & Guestrin

OA = Corn ranked first among Vegetables,
OA,B = First place occupied Vegetable.
condition case, one updates relative ranking distribution
Vegetables (A) zeroing rankings vegetables place Corn first
place, updates interleaving distribution zeroing interleavings
place Vegetable first place, normalizes resulting distributions.
example nondecomposable observation observation
= Corn third place.
see decompose (with respect Vegetables Fruits), enough
notice interleaving Vegetables Fruits independent relative
ranking Vegetables. If, example, element interleaves (Vegetables)
B (Fruits) AB () = A|B|A|B, since (Corn) = 3, relative ranking
Vegetables constrained () = P eas|Corn. Since interleavings
relative rankings independent, see cannot decomposable.
Formally, use riffle independent factorizations define decomposability respect
hierarchy H item set.
Definition 9 (Decomposability). Given hierarchy H item set, subset observation decomposes respect H likelihood function L(O|) factors riffle
independently respect H.
subset observations prior decompose according hierarchy,
show (as Example 8) posterior also decomposes.
Proposition 10. Let H hierarchy item set. Given prior distribution h
subset observation decompose respect H, posterior distribution
h(|O) also factors riffle independently respect H.
Proof. Denote likelihood function corresponding L (in proof,
matter assumed subset observation result holds arbitrary
likelihoods).
use induction size item set n = ||. base case n = 1 trivially
true. Next consider general case n > 1. posterior distribution, Bayes rule,
written h(|O) L() h(). two cases. H leaf node,
posterior h0 trivially factors according H, done. Otherwise, L h
factor, assumption, according H = (HA , HB ) following way:
L() = mL (AB ())fL (A ())gL (B ()), h() = mh (AB ())fh (A ())gh (B ()).
Multiplying grouping terms, see posterior factors as:
h(|O) = [mL mh ](AB ()) [fL fh ](A ()) [gL gh ](B ()).
show h(|O) factors respect H, need demonstrate (by Definition 5)
distributions [fL fh ] [gL gh ] (after normalizing) factor respect HA
498

fiEfficient Inference Partial Rankings

HB , respectively. Since fL fh factor according hierarchy HA assumption
|A| < n since H leaf, invoke inductive hypothesis show
posterior distribution, proportional fL fh must also factor according HA .
Similarly, distribution proportional gL gh must factor according HB .

4. Complete Decomposability
condition Proposition 10, prior observation must decompose respect exactly hierarchy, sufficient one efficient inference, might
first glance seem restrictive render proposition useless practice. overcome
limitation hierarchy specific decomposability, explore special family observations (which call completely decomposable) property decomposability
depend specifically particular hierarchy, implying particular
observations, efficient inference always possible (provided efficient representation
prior distribution also possible).
illustrate observation decompose respect multiple hierarchies
item set, consider first place observation =Corn ranked first. argued
Example 8 decomposable observation. Notice however decomposability
particular observation depend items partitioned
hierarchy. Specifically, instead Vegetables Fruits, sets = {Corn, Apples}
B = {P eas, Oranges} riffle independent, similar decomposition would continue
hold, decomposing observation relative ranking items (Corn
first among items A), observation interleaving B (First place
occupied element A).
formally capture notion observation decompose respect
arbitrary underlying hierarchies, define complete decomposability:
Definition 11 (Complete decomposability). say subset observation completely decomposable decomposes respect every possible hierarchy item
set . denote collection possible completely decomposable (subset) observations C. See Figure 4 illustration set C.
Conceptually, completely decomposable observations correspond indicator functions
riffle independent possible. Complete decomposability guarantee
observation one always exploit available factorized structure prior
distribution order efficiently condition O.
Proposition 12. Let H binary hierarchy item set. Given prior h
factorizes respect H, completely decomposable observation O, posterior
h(|O) also decomposes respect H.
Proof. Proposition 12 follows simple corollary Proposition 10.
Example 13. simplest example completely decomposable observation uniform observation Ounif = , includes possible rankings corresponds
uniform indicator function unif rankings. Given hierarchy H, unif shown
decompose riffle independently respect H, factor also uniform,
hence Ounif completely decomposable.
499

fiHuang, Kapoor & Guestrin

H1

H6

H2

Completely
Decomposable
Observations

H5

H3

H4

Figure 4: diagram illustrating collection completely decomposable observations, C.
shaded region (labeled Hi ) represents family subset observations
Sn decompose respect hierarchy Hi . collection C
seen intersection shaded regions, subset observations
lie inside intersection ones conditioning performed
linear time (in number model parameters).

uniform observation course particularly interesting context Bayesian
inference, hand, given stringent conditions Definition 11,
obvious nontrivial completely decomposable observations even exist. Nonetheless,
exist nontrivial examples (such first place observations), next
section, exhibit rich general class completely decomposable observations.

5. Complete Decomposability Partial Ranking Observations
section discuss mathematical problem fully characterizing class
completely decomposable observations. main contribution section show
completely decomposable observations correspond precisely partial rankings
item set.
Partial rankings. begin discussion introducing partial rankings, allow
items tied respect ranking dropping verticals vertical bar
representation .
Definition 14 (Partial ranking observation). Let 1 , 2 ,. . . , r ordered collection
subsets partition (i.e., = j = 6= j). partial ranking
observation 3 corresponding partition collection rankings rank items
3. remarked Ailon (2007), note term partial ranking used confused
two standard objects: (1) Partial order, namely, reflexive, transitive anti-symmetric binary

500

fiEfficient Inference Partial Rankings

items j < j. denote partial ranking 1 |2 | . . . |r say
type = (|1 |, |2 |, . . . , |r |). denote collection partial rankings
(over n items) P.
partial ranking defined viewed coset subgroup =
S1 S2 Sr . Given type full ranking , one
partial ranking type containing , thus therefore equivalently denote partial
ranking 1 |2 | . . . |r , element 1 |2 | . . . |r . Note coset
notation allows multiple rankings refer partial ranking .
space partial rankings defined captures rich natural class
observations. particular, partial rankings encompass number commonly occurring
special cases, traditionally modeled isolation, work (as well
recent works Lebanon & Lafferty, 2003; Lebanon & Mao, 2008) used
unified setting.
Example 15. Partial ranking observations include:
(First place, Top-1 observations): First place observations correspond partial
rankings type = (1, n 1). observation Corn ranked first
written Corn|Peas,Apples,Oranges.
(Top-k observations): Top-k observations partial rankings type = (1, . . . , 1, n
k). generalize first place observations specifying items mapping
first k ranks, leaving n k remaining items implicitly ranked behind. example,
observation Corn ranked first Peas ranked second written
Corn|Peas|Apples,Oranges.
(Desired/less desired dichotomy): Partial rankings type = (k, n k) correspond
subset k items preferred desired remaining subset n k items.
example, partial rankings type (k, n k) might arise approval voting
voters mark subset approved candidates, implicitly indicating disapproval
remaining n k candidates.
(Ratings): Finally, partial rankings come form rating data where,
example, restaurants rated as, ?, ??, ? ? ?. corresponding partial ranking
would thus tie restaurants rated number stars, ranking
restaurants stars restaurants fewer stars.
(Trivial observations): Partial rankings type = (n) refer trivial observations
whose likelihood functions uniform entire space rankings, . trivial
observation rankings item set = {Corn, P eas, Apples}, example,
simply written simply Corn, P eas, Apples.
show partial ranking observations decompose, exhibit explicit factorization respect hierarchy H items. simplicity, begin considering
single layer case, items partitioned two leaf sets B. factorization depends following notions consistency relative rankings interleavings
partial ranking.
relation; (2) ranking subset [which discuss Section 9 incomplete rankings].
search engines, example, although top-k elements returned, remaining n k
implicitly assumed ranked behind [and therefore, search engines return partial rankings].

501

fiHuang, Kapoor & Guestrin

Definition 16 (Restriction consistency). Given partial ranking = 1 |2 | . . . |r
subset , define restriction partial ranking items
obtained intersecting A. Hence restriction is:
[S ]A = 1 A|2 A| . . . |r A.
Given ranking, items A, say consistent partial ranking
member restriction A, [S ]A .
Definition 17 (Interleaving consistency). Given interleaving AB two sets A, B
partition , say AB consistent partial ranking = 1 | . . . |r (with
type ) first 1 entries AB contain number Bs 1 ,
second 2 entries AB contain number Bs 2 , on. Given
partial ranking , denote collection consistent interleavings [S ]AB .
example, consider partial ranking
= Corn, Apples|P eas, Oranges,
places single vegetable single fruit first two ranks, single vegetable
single fruit last two ranks. Alternatively, partially specifies interleaving
AB|AB. full interleavings A|B|B|A B|A|B|A consistent (by dropping
vertical lines) A|A|B|B consistent (since places two vegetables first two
ranks).
Using notions consistency partial ranking, show partial ranking
observations decomposable respect binary partitioning (i.e., single layer
hierarchy) item set.
Proposition 18 (Single layer hierarchy). partial ranking observation
binary partitioning item set (A, B), indicator function , , factors riffle
independently as:
() = mAB (AB ()) fA (A ()) gB (B ()),

(5.1)

factors mAB , fA gB indicator functions consistent interleavings
relative rankings, [S ]AB , [S ]A [S ]B , respectively.
single layer decomposition Proposition 18 turned recursive decomposition partial ranking observations arbitrary binary hierarchies, establishes
main result. particular, given partial ranking prior distribution
factorizes according hierarchy H, first condition topmost interleaving distribution zeroing parameters corresponding interleavings consistent
, normalizing distribution. need condition subhierarchies
HA HB relative rankings B consistent , respectively.
Since consistent sets, [S ]A [S ]B , partial rankings themselves,
algorithm conditioning partial ranking applied recursively
subhierarchies HA HB . precise, show that:
Theorem 19. Every partial ranking completely decomposable (P C).
502

fiEfficient Inference Partial Rankings

prcondition (Prior hprior , Hierarchy H, Observation = 1 |2 | . . . |r )
isLeaf(H)
forall

hprior ()
hpost ()
;
0
otherwise
Normalize (hpost ) ;
return (hpost );
else
forall

mprior ( ) [S ]AB
mpost ( )
;
0
otherwise
Normalize (mpost ) ;
f (A ) prcondition (fprior , HA , [S ]A ) ;
g(B ) prcondition (gprior , HB , [S ]B ) ;
return (mpost , fpost , gpost );

Algorithm 1: Pseudocode prcondition, algorithm recursively conditioning hierarchical riffle independent prior distribution partial ranking observations. See Definitions 16
17 [S ]A , [S ]B , [S ]AB . runtime prcondition O(n |H|), |H|
number model parameters. Input: parameter distributions prior hprior represented explicit tabular form, observation form partial ranking. Output:
parameter distributions posterior hpost represented explicit tabular form.

Since proof Theorem 19 fairly straight forward given form factorization (Equation 5.1), deferred Appendix. consequence Theorem 19
Proposition 12, conditioning partial ranking observations performed efficiently.
See Algorithm 1 details recursive conditioning algorithm.
running time complexity conditioning partial ranking? recursion
Algorithm 1 operates parameter distribution once, setting probabilities
interleavings relative rankings distribution either zero not,
normalizing. decide whether zero probability not, one must check partial
ranking consistency either interleaving relative ranking, requires
O(n) time. Therefore, total, Algorithm 1 requires O(n |H|) time, |H|
total number model parameters. Notice complexity conditioning depends
linearly complexity prior whenever prior distribution compactly
represented, efficient inference partial ranking observations also possible.
stated Section 2, |H| general scale exponentially n, thin chain models,
number items factored model stage never
small constant k, verifying interleaving relative ranking consistency performed
constant time, implying conditioning operation linear number model
parameters, guaranteed polynomial n.
Example 20. example, consider conditioning APA distribution Example 6 observation Candidate 3 ranked first place, also
represented partial ranking = 3|1, 2, 4, 5. Recall candidate 3 Charles
Kiesler, research psychologist.
Figure 5(a) show structure parameters prior distribution
APA election data, highlighting particular interleavings relative rankings
503

fiHuang, Kapoor & Guestrin



mB,C()



C|B|B|B|B

.14

C|B|B|B|B

mB,C()
0

B|C|B|B|B

.19

B|C|B|B|B

.22

B|B|C|B|B

.25

B|B|C|B|B

.29

B|B|B|C|B

.25

B|B|B|C|B

.29

B|B|B|B|C

.18

B|B|B|B|C

.21



mD,E()



fC()



mD,E()



fC()

D|D|E|E

.28

2

1.00

D|D|E|E

.54

2

1.00

D|E|D|E

.12

D|E|D|E

.23

D|E|E|D

.12

D|E|E|D

.23

E|D|D|E

.14

E|D|D|E

0

E|D|E|D

.12

E|D|E|D

0

E|E|D|D

.22

E|E|D|D

0



fD()



fE()



fD()



fE()

1|3

.50

4|5

.48

1|3

0

4|5

.48

3|1

.50

5|4

.52

3|1

1.00

5|4

.52

(a) Structure parameters prior distribution (with consistent relative rankings interleavings highlighted).

(b) Structure parameters posterior distribution conditioning.

Figure 5: Example conditioning APA hierarchy (from Example 6) first place
observation Candidate 3 ranked first place.

consistent O. example, possible interleavings research psychologists
(D) clinical psychologists (E), interleavings consistent
rank research psychologist first among research clinical psychologists.
therefore three consistent interleavings: D|D|E|E, D|E|D|E, D|E|E|D.
Conditioning sets relative rankings interleavings consistent
zero normalizes resulting parameter distribution. resulting riffle
independent representation posterior distribution shown Figure 5(b).

5.1 Impossibility Result
interesting consider completely decomposable observations exist beyond partial
rankings. One main contributions show observations.
Theorem 21 (Converse Theorem 19). Every completely decomposable observation takes
form partial ranking (C P).
Together, Theorems 19 21 form significant insight nature rankings,
showing notions partial rankings riffled independence deeply connected.
fact, result shows even possible define partial rankings via complete
decomposability!
practical matter, Theorem 21 shows algorithm based simple
multiplicative updates parameters exactly condition observations
take form partial rankings. computational complexity conditioning
observations partial rankings remains open. conjecture approximate
inference approaches may necessary efficiently handling complex observations.
504

fiEfficient Inference Partial Rankings

5.2 Proof Impossiblity Result (Theorem 21)
turn proving Theorem 21. Since proof significantly longer less obvious
proof converse (Theorem 19), sketch main ideas drive proof
refer interested readers details Appendix.
Recall definition linear span set vectors vector space
intersection linear subspaces containing set vectors. prove Theorem 21,
introduce analogous concepts span set rankings.
Definition 22 (rspan pspan). Let X Sn collection rankings. define
pspan(X) intersection partial rankings containing X. Similarly, define
rspan(X) intersection completely decomposable observations containing X.
formally,
\
\
pspan(X) =
, rspan(X) =
O.
O:XO, OC

:XS

example, X = {Corn|P eas|Apples, Apples|P eas|Corn}, checked
partial ranking three items containing items X entire set itself.
Thus pspan(X) = Corn, P eas, Apples.
proof strategy establish two claims: (1) pspan set always
partial ranking, (2) fact, rspan pspan set X exactly
sets. Since claim (1) fact partial rankings involve riffled
independence, defer related proofs Appendix. Thus have:
Lemma 23. X Sn , pspan(X) partial ranking.
Proof. See Appendix.
following discussion instead sketch proof claim (2). first show, however,
Theorem 21 must hold indeed true claims (1) (2) hold.
Proof. (of Theorem 21): Given C, want show P. claim
(2), rspan(O) = pspan(O). Since element C, however, also
= rspan(O), thus = pspan(O). Finally Lemma 23 (claim (2)) guarantees
pspan(O) partial ranking, conclude P.
proceed establish claim rspan(X) = pspan(X). following
proposition lists several basic properties rspan use several
proofs. follow directly definition write proofs.
Proposition 24.
I. (Monotonicity) X, X rspan(X).
II. (Subset preservation) X, X 0 X X 0 , rspan(X) rspan(X 0 ).
III. (Idempotence) X, rspan(rspan(X)) = rspan(X).
One inclusion proof rspan(X) = pspan(X) follows directly fact
P C (Theorem 19):
505

fiHuang, Kapoor & Guestrin

formPspan(X)
X0 X; 0;
, 0 0 Xt disagree relative ordering items a1 , a2
Xt ;
foreach Xt
Add partial ranking obtained deleting vertical bar items
a1 a2 Xt ;
+ 1;
return (any element Xt ) ;

Algorithm 2: Pseudocode computing pspan(X). formPspan(X) takes set partial
rankings (or full rankings) X input outputs partial ranking. algorithm iteratively
deletes vertical bars elements X agreement. Note necessary
keep track t, ease notation proofs. algorithm
direct way computing pspan(X), again, simplifies proof main theorem.

Lemma 25. subset orderings, X, rspan(X) pspan(X).
Proof. Fix subset X Sn let element rspan(X). would like show
element pspan(X). Consider partial ranking P covers X
(i.e., 0 0 X). want see . Theorem 19, P C,
therefore, C. Since rspan(X), 0 0 X, conclude,
definition rspan, . Since holds partial ranking covering X,
pspan(X).
remains task establishing reverse inclusion:
Proposition 26. subset orderings, X, rspan(X) pspan(X).
prove Proposition 26, consider problem computing partial ranking span
(pspan) given set rankings X. Algorithm 2, show simple procedure based
iteratively finding rankings X disagree pairwise ranking two items,
replacing rankings partial ranking vertical bar two
elements removed. show algorithm provably outputs correct
result.
Proposition 27. Given set rankings X input, Algorithm 2 outputs pspan(X).
Proof. See Appendix.
final step able prove Proposition 26, prove following two
technical lemmas relate computation pspan Algorithm 2 riffled independence, really form heart argument. particular, completely
decomposable observation C, Lemma 28 shows ranking contained
force rankings also contained O.
Lemma 28. Let C suppose exist 1 , 2 disagree relative
ranking items i, j . ranking obtained swapping relative ranking
items i, j within 3 must also contained O.
506

fiEfficient Inference Partial Rankings

Proof. Let h indicator distribution corresponding observation O.
show swapping relative ranking items i, j 3 result ranking
assigned nonzero probability h, thus showing new ranking contained O.
Let = {i, j} B = \A. Since C, h must factor riffle independently according
partition (A, B). Thus,
h(1 ) = m(AB (1 )) f (A (1 )) g(B (1 )) > 0,
h(2 ) = m(AB (2 )) f (A (2 )) g(B (2 )) > 0.
Since 1 2 disagree relative ranking items A, factorization implies
particular f (A = i|j) > 0 f (A = j|i) > 0. Since h(3 ) > 0, must also
m(AB (3 )), f (A (3 )), g(B (3 )) positive probability.
therefore swap relative ranking A, , obtain new ranking positive
probability since terms decomposition new ranking positive
probability.
Lemma 29 provides conditions removing vertical bar one
rankings X change support completely riffle independent distribution. illustrate example, consider completely decomposable observation
contains partial ranking = Corn, P eas|Apples, Oranges subset.
Lemma 29 guarantees that, if, addition, exists element disagrees
relative ordering of, say, P eas Oranges, fact partial ranking
0 0 = Corn, P eas, Apples, Oranges (with bar removed ) must also
subset O. Formally,
Lemma 29. Let = 1 | . . . |i |i+1 | . . . |k partial ranking item set ,
0 0 = 1 | . . . |i i+1 | . . . |k , partial ranking sets i+1
merged. Let a1 ij=1 j a2 kj=i+1 j . element C
additionally exists ranking disagrees relative
ordering a1 , a2 , 0 0 O.
Proof. key strategy proof Lemma 29 argue large subsets rankings
must contained completely decomposable observation decomposing rankings
transpositions invoking technical lemma (Lemma 28) repeatedly.
See Appendix details.
use Lemma 29 show reverse inclusion Proposition 26 also
holds, establishing two sets rspan(X) pspan(X) fact equal thereby
proving desired result, C P.
Proof. (of Proposition 26) iteration t, Algorithm 2 producesS
set partial rankings,
Xt . denote union partial rankings time Xt Xt . Note
X0 = X XT = pspan(X). idea proof show iteration
t, following set inclusion holds: rspan(Xt ) rspan(Xt1 ). indeed holds,
507

fiHuang, Kapoor & Guestrin

final iteration , shown that:
pspan(X) = XT ,

(Proposition 27)

rspan(XT ),

(Monotonicity, Proposition 24)

rspan(X0 ),

(since rspan(Xt ) rspan(Xt1 ), shown below),

rspan(X)

(X0 = X, see Algorithm 2)

would prove Proposition.
remains show rspan(Xt ) rspan(Xt1 ). claim Xt rspan(Xt1 ).
Let Xt . Xt1 , since Xt1 rspan(Xt1 ), rspan(Xt1 )
proof done. Otherwise, Xt \Xt1 . second case, use fact
iteration t, vertical bar i+1 deleted partial ranking = 1 | . . . |i |i+1 | . . . |k (which subset Xt1 ) form partial ranking
0 0 = 1 | . . . |i i+1 | . . . |k . (which subset Xt ). Furthermore, order
vertical bar deleted algorithm, must existed partial
ranking (and therefore full ranking 0 ) disagreed relative ordering items a1 , a2 opposite sides bar. Since Xt \Xt1 assume
0 0 .
would like apply Lemma 29. Note C Xt1 O,
also O, since Xt1 . application Lemma 29 shows
0 0 therefore O.
shown fact holds observation C Xt1
O, therefore taking intersection supports C, see Xt
rspan(Xt1 ). Taking rspan sides yields:
rspan(Xt ) rspan(rspan(Xt1 )),
rspan(Xt1 ).

(Subset preservation, Proposition 24)

(Idempotence, Proposition 24)

5.3 Going Beyond Subset Observations
Though stated results far subset observations, comment
theory would look like considered general likelihood functions.
order avoid confusion, refer general class functions call completely decomposable functions, instead completely decomposable subset observations
Definition 11.
Definition 30. function h : Sn R called completely decomposable function
factors riffle independently respect every hierarchy item set . denote
e
collection possible completely decomposable functions C.
e nearly same. quite simple restate Theorem 19
discuss, C C
respect general case completely decomposable functions:
Theorem. Every partial ranking indicator function completely decomposable function.
508

fiEfficient Inference Partial Rankings

Unfortunately, proof converse (Theorem 21) easily generalize,
instead used show support ({ Sn : h() > 0}) every completely
decomposable function partial ranking. natural, however, suspect full
converse indeed exist every completely decomposable function proportional
indicator function partial ranking. fact, suspected converse almost
holds. have:
Theorem. h completely decomposable function supported partial ranking
= 1 | . . . |r |i | =
6 2 = 1, . . . , r, h proportional indicator
function .
Proof. See Appendix.
Example 31. completely decomposable functions, possible away
assumption |i | =
6 2 i. example, function defined as:

2/3 = Corn|P eas|Apples
1/3 = P eas|Corn|Apples ,
h() =

0
otherwise
supported partial ranking = Corn, P eas|Apples (where |1 | = 2),
proportional indicator function (i.e., uniform rankings
assigned positive probability).
However, still possible show h completely decomposable function.
prove so, necessary establish three things: {Corn, P eas} {Apples}
riffle independent, {Corn, Apples} {P eas} riffle independent,
{P eas, Apples} {Corn} riffle independent. example, respect partitioning sets = {Corn, Apples} B = {P eas}, see
h() = m(AB ()) f (A ()) g(B ()),
where:

2/3
1/3
m(AB ) =

0

AB = A|B|A
AB = B|A|A ,
AB = A|A|B


f (A ) =

1
0

{AC} = A|C
,
otherwise

g(B ) = 1.

Therefore, |i | = 2, possible completely decomposable functions
uniform supports.
5.4 Conditioning Noisy Observations
conclude section remark handling noise observations.
assumed paper observed partial rankings always consistent users
underlying full ranking, situations one may wish model noisier
setting, partial rankings may misreported small probability.
natural model accounts noise, example, might be:

1
L(O|) =
.
(5.2)

|O|1 otherwise
509

fiHuang, Kapoor & Guestrin

prior distribution factorizes respect hierarchy H, conditioning
noisy likelihood Equation 5.2 results posterior distribution written
weighted mixture prior distribution posterior would resulted
conditioning noise-free observation. component posterior
distribution factorizes respect H, mixture factor general (and
factor according theory). result, iteratively conditioning multiple
partial rankings according noisy likelihood function would quickly lead
unmanageable number mixture components. therefore believe approximate
inference methods conditioning multiple noisy partial ranking observations fruitful
area research.

6. Model Estimation Partially Ranked Data
many ranking based applications, datasets predominantly composed partial rankings rather full rankings due fact humans, partial rankings typically
easier faster specify. addition, many datasets heterogeneous, containing partial
ranking different types. example, American Psychological Assoication well
Irish House Parliament elections, voters allowed specify top-k candidate
choices value k (see Figures 7(a) 7(b)). section use efficient
inference algorithm proposed Section 5 estimating riffle independent model
partially ranked data. estimating model using partially ranked data typically
considered difficult estimating one using full rankings, common practice (e.g., see Huang & Guestrin, 2010) simply ignore partial rankings
dataset. ability method incorporate available data however, lead
significantly improved model accuracy well wider applicability method.
section, propose first efficient method estimating structure parameters
hierarchical riffle independent model heterogeneous datasets consisting arbitrary
partial ranking types. Central approach idea given someones partial preferences, use efficient algorithms developed previous section infer full
preferences consequently apply previously proposed algorithms designed
work full rankings.
6.1 Censoring Interpretations Partial Rankings
model estimation problem full rankings stated follows. Given i.i.d. training
examples (1) , . . . , (m) (consisting full rankings) drawn hierarchical riffle independent distribution h, recover structure parameters h.
partial ranking setting, assume i.i.d. draws, training
example (i) undergoes censoring process producing partial ranking consistent (i) .
example, censoring might allow ranking top-k items (i)
observed. allow arbitrary types partial rankings arise via censoring,
make common assumption partial ranking type resulting censoring (i)
depend (i) itself.
510

fiEfficient Inference Partial Rankings

6.2 Algorithm
treat model estimation partial rankings problem missing data problem.
many problems, could determine full ranking corresponding observation data, could apply algorithms work completely observed
data setting. Since full rankings given, utilize Expectation-Maximization (EM)
approach use inference compute posterior distribution full rankings
given observed partial ranking. case, apply algorithms Huang
Guestrin (2010, 2012) designed estimate hierarchical structure
model parameters dataset full rankings.
Given initial model h collection training examples {O(1) , O(2) , . . . , O(m) }
consisting partial rankings, EM-based approach alternates following two
steps convergence achieved.
(E-step): observation, O(i) = (i) (i) , training examples, use
inference compute posterior distribution full ranking could
generated O(i) via censoring, h(|O(i) = (i) (i) ). Since observations take
form partial rankings hence completely decomposable, use efficient
algorithms Section 5 perform E-step.
(M-step): M-step, one maximizes expected log-likelihood training
data respect model. hierarchical structure model
provided, known beforehand, M-step performed using standard methods optimizing parameters. structure unknown, use structural
EM approach, analogous methods graphical models literature
structure learning incomplete data (Friedman, 1997, 1998).
Unfortunately, (riffled independence) structure learning algorithm Huang
Guestrin (2010) unable directly use posterior distributions computed
E-step. Instead, observing sampling riffle independent models
done efficiently exactly (as opposed to, example, MCMC methods), simply
sample full rankings posterior distributions computed E-step
pass full rankings structure learning algorithm Huang Guestrin
(2010). number samples necessary, instead scaling factorially, scales
according number samples required detect riffled independence (which
mild assumptions polynomial n, Huang & Guestrin, 2010).

7. Related Work
Rankings permutations recently become active area research machine
learning due part hinge role play information retrieval preference
elicitation. Algorithms RankSVM (Joachims, 2002) RankBoost (Freund,
Iyer, Schapire, & Singer, 2003), example, successful large scale ranking
problems appear web search. main aims work differ web
scale settings however instead seeking single optimal ranking respect
objective function, seek understanding large collection rankings via density
estimation. following, outline two major lines research influenced
work.
511

fiHuang, Kapoor & Guestrin

7.1 Additive Multiplicative Decompositions
paper builds particular upon thread recent work tractable models permutation data based function decompositions. Kondor, Howard, Jebara (2007)
Huang, Guestrin, Guibas (2008, 2009) considered additive decompositions distribution weighted sum Fourier basis functions. papers show low-frequency
Fourier assumptions often effective coping representational complexity
working distributions permutations. show particular conditioning
prior distributions low frequency likelihood functions often arise multiobject
tracking problems performed especially efficiently.
Unfortunately, low frequency assumptions applicable distributions defined
rankings, address ranking problems specifically, Huang Guestrin (2009,
2010) introduced concept riffled independence useful generalization probabilistic independence rankings. Using multiplicative decompositions based riffled
independence, showed possible learn hierarchical structure model
given fully ranked dataset. previous papers topic riffled independence
focused problems related efficiently representing distributions, main focus
current paper lies efficient reasoning/inference tackling human task complexity
considering partial rankings.
interesting note natural efficient condition Fourier based
representation low-frequency observations (involving small number items)
=Alice third place, multiplicative decomposition based riffled independence
would able efficiently condition observation. hand,
multiplicative decompositions allow us condition top-k observations efficiently (independently size k), whereas top-k observations would difficult handle
Fourier theoretic setting (except small k).
7.2 Mallows Models
work also fits larger body research well known Mallows distribution
rankings, parameterized by:
h(; , 0 ) (,0 ) ,

(7.1)

function refers Kendalls tau distance metric rankings. Mallows
distribution (Equation 7.1) always shown special case hierarchical riffle independent model items sequentially factored model one
one (Huang, 2011) (see Figure 6).
Mallows models (as well similar distance based models) advantage
compactly represent distributions large n, admit conjugate prior
distributions (Meila, Phadnis, Patterson, & Bilmes, 2007). Estimating parameters
popular problem statisticians recovering optimal 0 data known
consensus ranking rank aggregation problem known N P -hard (Bartholdi,
Tovey, & Trick, 1989). Many authors focused approximation algorithms instead.
Like Gaussian distributions, Mallows models tend lack flexibility, Lebanon
Mao (2008) propose nonparametric model ranked (and partially ranked) data based
placing weighted Mallows kernels top training examples, which, show,
512

fiEfficient Inference Partial Rankings

{Corn,Peas,Apples,Oranges,Doughnuts}

{Corn}

{Peas,Apples,Oranges,Doughnuts}

{Peas}

{Apples,Oranges,Doughnuts}
{Apples}

{Oranges,Doughnuts}
{Oranges}

{Doughnuts}

Figure 6: Mallows model always factors according refer chain
structure items factored one one. Mallows distribution five items food item set mode (or central ranking)
0 = Corn|P eas|Apples|Oranges|Doughnuts, example, must factor according hierarchical structure.

realize far richer class distributions, learned efficiently. However,
address inference problem, immediately clear many Mallows models
papers whether one efficiently perform inference operations like marginalization
conditioning models. Riffle independent models, hand, encompass
class distributions rich well interpretable, additionally,
identified precise conditions efficient conditioning possible (the conditions
observations take form partial rankings).
several recent works model partial rankings using Mallows based models.
Busse, Orbanz, Buhmann (2007) learned finite mixtures Mallows models topk data (also using EM approach). Lebanon Mao (2008), mentioned,
developed nonparametric model based Mallows models handle arbitrary
types partial rankings. settings, central problem marginalize Mallows
model full rankings consistent particular partial ranking.
efficiently, papers rely fact (first shown Fligner & Verducci, 1986)
marginalization step performed closed form. closed form equation Fligner
Verducci (1986), however, seen special case setting since Mallows
models always shown factor riffle independently according chain structure.
Specifically, compute sum rankings consistent partial ranking
, necessary condition , compute normalization constant
resulting function. conditioning step performed using methods
described paper, normalization constant computed multiplying
normalization constant factor hierarchical decomposition. Thus, instead
resorting complicated mathematics inversion combinatorics, theory
complete decomposability offers simple conceptual way understand Mallows models
conditioned efficiently partial ranking observations.
513

fiHuang, Kapoor & Guestrin

Finally recent related work, Lu Boutilier (2011) considered even general
class observations based DAG (directed acyclic graph) based observations
probabilities rankings consistent DAG relative ranking relations
set zero. Lu Boutilier show particular conditioning problem
DAG-based class observations #P -hard. additionally propose efficient
rejection sampling method performing probabilistic inference within general class
DAG observations prove sampling method exact class partial
rankings discussed paper.

8. Experiments
section, demonstrate method learning hierarchical riffle independent models partial rankings simulated data well real datasets taken different
domains. experiments, initialize distributions uniform, use random restarts.
8.1 Datasets
addition roughly 5000 full rankings, APA dataset 10,000 top-k rankings
5 candidates. previous work, used full rankings APA data (Huang
& Guestrin, 2010, 2012), able use entire dataset. Figure 7(a) plots,
k {1, . . . , 5}, number ballots APA data length k.
Likewise, Meath dataset (Gormley & Murphy, 2007) taken 2002
Irish Parliament election 60,000 top-k rankings 14 candidates. APA
data, used full rankings Meath data previous work, use
entire dataset. Figure 7(b) plots, k {1, . . . , 14}, number ballots
Meath data length k. particular, note vast majority ballots dataset
consist partial rather full rankings, half electorate preferring list
favorite three four candidates. run inference (Algorithm 1)
5000 top-k examples Meath data 10 seconds dual 3.0 GHz Pentium machine
unoptimized Python implementation. Using brute force inference, estimate
job would require roughly one hundred years.
extracted third dataset database searchtrails collected White
Drucker (2007), browsing sessions roughly 2000 users logged 20082009. many cases, users unlikely read articles news story twice,
often possible think order user reads collection
articles top-k ranking articles concerning particular story/topic. ability
model visit orderings would allow us make long term predictions user browsing
behavior, even recommend curriculums articles users. ran algorithms
roughly 300 visit orderings eight popular posts www.huffingtonpost.com
concerning Sarah Palin, popular subject 2008 U.S. presidential election. Since
user visited every article, full rankings data thus
even exist option learning using subset full rankings.
514

fiEfficient Inference Partial Rankings

number votes

number votes

6000
5000

4000
3000
2000
1000

20,000

10,000

0

0

1

2

2
3
4
5
number candidates

4

6

8 10 12 14
k

(a) APA election data

(b) Irish election data

Figure 7: Histograms top-k ballot lengths APA Irish election datasets. Whereas
majority electorate provided full rankings APA election data
(probably due fact five candidates), vast majority
voters Irish election data provided top-3 top-4 choices.
{12345}

{12345}
{12345}

{2}

{2345}

{2}

{2345}
{1345}

{345}

{1}
{3}

{45}

(a) Structure learned using
subset full rankings
(out 300 given training
examples)

{345}

{1}
{5}

{34}

(b) Structure learned using
training examples 1 iteration EM

{13}
Research

{2}
Community
psychologists

{45}
Clinical

(c) Structure learned using
training examples structural convergence (3 iterations)

Figure 8: Structure learning subset APA dataset (300 rankings, randomly
sampled, including full partial rankings).

8.2 APA Structure Learning Results
Due unordinarily large number full rankings APA data, gains made
additionally using partially ranked data insignificant. better illustrate benefits
partial rankings, subsampled dataset 300 rankings (including full partial
rankings) present results smaller dataset. Performing structure learning using
full rankings 300 training examples (consisting roughly 100 examples),
one obtains structure Figure 8(a), seen match correct
structure Figure 3(a) learned using 5000 full rankings. Figures 8(b) 8(c)
515

fiHuang, Kapoor & Guestrin

training time (seconds)

test log-likelihood

x 10 4
-2
-3
-4
-5

-6
EM

Flat-EM

4

training time (seconds)

test log-likelihood

-5
-5.2
-5.4
-5.6
-5.8
-6
k>2

10
5

0
EM

Flat-EM Uniform
Fill-In

(b) Training time comparison
EM approach FlatEM
Uniform Fill-In methods.

x 10

k>1

15

Uniform
Fill-In

(a) Test set log-likelihood comparison
EM approach FlatEM
Uniform Fill-In methods.

k>0

20

2.5
2
1.5

1

k>3

(c) Test set log-likelihoods, training
top-t rankings larger
fixed k.

k>0

k>1

k>2

k>3

(d) Training times, training
top-t rankings larger fixed
k.

Figure 9: APA experimental results experiment repeated 200 bootstrapped
resamplings data

plot results EM algorithm former displaying resulting structure
single EM iteration latter result structural convergence, occurs
third iteration, showing method learn correct structure given
300 training examples.
compared EM algorithm two alternative baseline approaches
refer plots FlatEM Uniform Fill-in. FlatEM algorithm
EM algorithm except two details: (1) performs conditioning exhaustively
instead exploiting factorized model structure, (2) performs M-step without
sampling. Uniform Fill-in approach treats every top-k ranking training set
uniform collection votes full rankings consistent top-k ranking,
accomplished using one iteration EM algorithm.
Figure 9(a) plot test set loglikelihoods corresponding approach, EM
FlatEM almost identical results performing much better
Uniform Fill-in approach. hand, Figure 9(b), compares running times
three approaches, shows FlatEM far costly (for datasets,
cannot even run reasonable amount time).
516

fiEfficient Inference Partial Rankings

1st iteration

2nd iteration

{0,1,2,3,4,5,6,7}

3rd iteration

{0,1,2,3,4,5,6,7}
{0,1,2,3,4,5,6,7}

{5}

{0,1,2,3,4,6,7}

{5}

{0,1,2,3,4,6,7}
{5}

{0,1,2,3,4,7}

{6}

{0,1,2,3,4,7}

{0,1,2,3,4,6,7}

{7}
{0,1,2,3,4,7}

{0,1,2,3,4}

{7}

{0,1,2,3,4}

{6}
{0,2,3}

{0,2,3}

{1,4}

Log likelihood: -818.6579
(a)

{0,2,3}

{7}

{1,4,6}

{1,4}

Log likelihood: -769.2369
(b)

Log likelihood: -767.2760
(c)

Figure 10: Iterations Structure EM Sarah Palin data structural changes
iteration highlighted red. Structural convergence occurs three
iterations. Note structure discovered using visit orders,
text information pages incorporated learning process.
figure best viewed color.

verify partial rankings indeed make difference APA data, plot
results estimating model subsets APA training data consisting top-k
rankings length larger fixed k. Figures 9(c) 9(d) show log-likelihood
running times k = 0, 1, 2, 3 k = 0 entire training set k = 3
subset training data consisting full rankings. results show,
including partial rankings indeed help average improving test log-likelihood
(with diminishing returns).
8.3 Structure Discovery EM Larger n.
experiments led several observations using EM learning partial
rankings. First, observe typical runs converge fixed structure quickly,
three EM iterations. Figure 10 shows progress EM Sarah Palin
data, whose structure converges third iteration. expected, log-likelihood
increases iteration, remark structure becomes interpretable
example, leaf set {0, 2, 3} corresponds three posts Palins wardrobe
election, posts leaf set {1, 4, 6} related verbal gaffes
made Palin campaign. Notice structure discovered purely using
data visit orders text information used experiments.
517

fiHuang, Kapoor & Guestrin

-2.72

x 104

test log-likelihood

# EM iterations
convergence

30

25
20
15

10

EM
decomposable
conditioning

-2.8

[Lebanon & Mao, 08]

-2.84
-2.88

5
0

-2.76

0

0 1 2 3 4 5 6 7 8 9 10 11 12
k

250 1000 4000 16000 64000
# partial rankings training set
(in addition full rankings)

(a)

(b)

Figure 11: (a): Number EM iterations required convergence training set
contains rankings length longer k. (b): Density estimation synthetic
data. plot test loglikelihood learning 343 full rankings
0 64,000 additional partial rankings.

5000 training
examples

4

Test log-likelihood

x 10
-4.5



-4.6

25000 training
examples

5

x 10
-1.26

[LM08]

[LM08]

-1.28



-1.3

-4.7



-1.32

[LM08]


-4.8

[LM08]

-1.34

-4.9

Full

Mixed (Full+Partial)

Full

Mixed (Full+Partial)

Figure 12: Density estimation small (5000 examples) large subsets (25000 examples) Meath data. compare method work Lebanon
Mao (2008) two settings: (1) training available data (2) training
subset full rankings.

Secondly, number EM iterations required reach convergence log-likelihood
depends types partial rankings observed. ran algorithm subsets
Meath dataset, time training = 2000 rankings length larger
518

fiEfficient Inference Partial Rankings

fixed k. Figure 11(a) shows number iterations required convergence
function k (with 20 bootstrap trials k). observe fastest convergence
datasets consisting almost-full rankings slowest convergence consisting
almost-empty rankings, almost 25 iterations necessary one trains using rankings
types. Finally remark model obtained first iteration EM
interesting thought result pretending voter completely
ambivalent regarding n k unspecified candidates.
8.4 Value Partial Rankings
verify larger n using partial rankings addition full rankings
allows us achieve better density estimates. first learned models synthetic data
drawn hierarchy, training using 343 full rankings plus varying numbers partial
ranking examples (ranging 0-64,000). repeat setting 20 bootstrap
trials, evaluation, compute log-likelihood testset 5000 examples.
speed, learn structure H fix H learn parameters trial.
Figure 11(b), plots test log-likelihood function number partial
rankings made available training set, shows indeed able learn
accurate distributions data form partial rankings made
available.
8.5 Comparing Nonparametric Model
Comparing performance riffle independent models approaches possible previous work since able handle partial rankings. Using
methods developed current paper, however, compare riffle independent models
state-of-the-art nonparametric estimator Lebanon Mao (2008) (to
hereby refer LM08 estimator) data (setting regularization parameter C =1,2,5, 10 via validation set). Figure 11(b) shows (naturally)
data drawn synthetically riffle independent model, EM method significantly outperforms LM08 estimator. remark theory, LM08 guaranteed
catch performance (under appropriate conditions) given enough training examples.
Meath data, approximately riffle independent, trained subsets
size 5,000 25,000 (testing remaining data). subset, evaluated EM
algorithm learning riffle independent model LM08 estimator (1)
using full ranking data, (2) using data. before, methods better
partial rankings made available.
smaller training set, riffle independent model performs well better
LM08 estimator. larger training set 25,000, see nonparametric
method starts perform slightly better average, advantage nonparametric
model guaranteed consistent, converging correct model given
enough data. advantage riffle independent models, however, simple,
interpretable, highlight global structures hidden within data.
519

fiHuang, Kapoor & Guestrin

9. Future Directions
remain several possible extensions current work. list open
questions extensions following.
9.1 Inference Incomplete Rankings
shown paper one exploit riffled independence structure condition
observation takes form partial ranking. space
partial rankings rich useful many settings, cover important class
observations: incomplete rankings, defined ranking (or partial
ranking) subset itemset . example, Theorem 21 shows conditioning problem pairwise observations form Apples preferred Bananas
nondecomposable. Note top-k rankings considered complete rankings since
implicitly rank items last n k positions.
then, tractably condition incomplete rankings? One possible approach
convert Fourier representation using methods (Huang & Guestrin, 2012),
conditioning pairwise ranking observation using Fourier domain conditioning
algorithm proposed (Huang et al., 2008). Fourier domain approach would useful one particularly interested low-order marginal probabilities posterior
distributions.
Fourier approach viable, another option may assume
posterior distribution takes particular riffle independent structure (in way
mean field methods graphical models literature would assume factorized
posterior). research question interest is: hierarchical structure used
purposes approximating posterior?
9.2 Reexamining Data Independence Assumptions
paper, assumed throughout training examples independent
identically distributed. However practice always safe assumptions
number factors impact validity both. example, internet survey
user must perform series preference ranking tasks sequence, concern
users prior ranking tasks may bias results future rankings.
Another source bias lies reference ranking may displayed,
user asked rearrange items dragging dropping. one hand, showing
everyone reference ranking may bias resulting data. hand,
showing every user different reference ranking may mean training examples
exactly identically distributed.
Yet another form bias lies partial ranking types reported data.
formulate EM algorithm, assumed users preferences influence
whether chooses to, say, report full ranking instead top-3 ranking. practice,
however, partial ranking types user preferences often correlated. Irish elections, example, typically one Sinn Fein candidate, rank
Sinn Fein first typically likely reported top-1 choice.
520

fiEfficient Inference Partial Rankings

Understanding, identifying, finally, learning spite different types biases
may occur eliciting preference data remains fundamental problem ranking.
9.3 Probabilistic Modeling Strategic Voting
interesting consider differences actual vote distributions considered
paper approximate riffle independent distributions. Take APA dataset,
example, optimal approximation riffle independent hierarchy reflects
underlying political coalitions within organization. Upon comparison
approximation empirical distribution, however, marked differences arise.
example, riffle independent approximation underestimates number votes obtained
candidate 3 (a research psychologist) ultimately election.
One possible explanation discrepancy may lie idea voters tend vote
strategically APA elections, placing stronger candidates opposing political coalitions
lower ranking, rather revealing true preferences. interesting line
future work lies detecting studying presence strategic voting election
datasets. Open questions include (1) verifying mathematically whether strategic voting
indeed exist in, say, APA election data, (2) so, strategic voting effect
strong enough overwhelm riffled independence structure learning algorithms,
(3) strategic voting manifest partial ranking votes.

10. Conclusion
probabilistic reasoning problems, often case certain data types suggest
certain distribution representations. example, sparse dependency structure data
often suggests Markov random field (or graphical model) representation (Friedman,
1997, 1998). low-order permutation observations (depending items
time), recent work (Huang et al., 2009; Kondor, 2008) shown Fourier domain
representation appropriate. preference ranking scenarios, one must contend
human task complexity difficulty involved human rank long list items
often leads partially, instead fully ranked data. paper, shown
data takes form partial rankings, hierarchical riffle independent models
natural representation.
conjugate priors, showed riffle independent model guaranteed
retain factorization structure conditioning partial ranking (which performed efficiently). surprisingly, work shows observations
take form partial rankings amenable simple multiplicative update based
conditioning algorithms. Finally, showed possible learn hierarchical riffle
independent models partially ranked data, significantly extending applicability
previous work.

Acknowledgments
project formulated largely conducted internship Jonathan Huang
Microsoft Research. Additional work supported part ONR MURI
N000140710747, ARO MURI W911NF0810242. Carlos Guestrin funded
521

fiHuang, Kapoor & Guestrin

part NSF Career IIS-064422. thank Eric Horvitz, Ryen White, Dan Liebling,
Yi Mao discussions.

Appendix A. Proofs
appendix, provide supplementary proofs theoretical results
paper.
A.1 Proof Theorem 19
prove Theorem 19 (as well later results), refer rank sets.
Definition 32. Given partial ranking type , denote rank set occupied
Ri . Note Ri depends
written R1 = {1, . . . , 1 },
P
R2 = {1 + 1, . . . , 1 + 2 }, . . . , Rr = { r1
i=1 + 1, . . . , n}.
refer following basic fact regarding rank sets:
Proposition 33. = 1 | . . . |r i, (i ) = Ri .
Proof. (of Theorem 19) use induction size itemset. cases n = 1, 2
trivial since every distribution S1 S2 factors riffle independently. consider
general case n > 2.
Fix partial ranking = 1 |2 | . . . |r type binary partition item
set subsets B. show indicator function factors as:
() = m(AB ()) f (A ()) g(B ()),

(A.1)

factors m, f g indicator functions set consistent interleavings,
[S ]AB , sets consistent relative rankings, [S ]A [S ]B , respectively.
Equation A.1 true, shown must decompose respect
top layer H. show decomposes hierarchically, must also show
relative ranking factors fA gB decompose respect HA HB ,
subhierarchies item sets B. establish second step (assuming
Equation A.1 holds), note fA gB indicator functions restricted partial
rankings, [S ]A [S ]B , partial rankings smaller item sets
B. inductive hypothesis (and fact B assumed strictly
smaller sets ) shows functions fA gB factor according
respective subhierarchies.
turn establishing Equation A.1. suffices prove following two
statements equivalent:
I. ranking consistent partial ranking (i.e., ).
II. following three conditions hold:
(a) interleaving AB () consistent (i.e., AB () [S ]AB ),
(b) relative ranking () consistent (i.e., () [S ]A ),
(c) relative ranking B () consistent (i.e., B () [S ]B ).
522

fiEfficient Inference Partial Rankings

(I II): first show implies conditions (a), (b) (c).
(a) , i,
|j Ri : AB (j) = A| = |j Ri : 1 (j) A|,
= |k : k A|,

(by Definition 2)

(by Proposition 33)

= |i A|.
argument (replacing B) shows i, |j
Ri : AB (j) = B| = |i B|. two conditions (by Definition 17) show
AB consistent .
(b) , (by Definition 14) ranks items items j
< j. Intersecting A, also see ranks item
item j i, j. Definition 2, () also ranks item
item j i, j. finally Definition 16 again,
see () consistent partial ranking .
(c) (Same argument (b)).
(II I): assume conditions (a), (b), (c) hold, show .
Proposition 33 sufficient show item k , (k) Ri .
prove claim, show induction item k A, (k) Ri
(and similarly k B, (k) Ri ).
Base case. base case (i = 1), assume k 1 A, goal show
(k) R1 . condition (a), AB () [S ]AB . Definition 17,
means that: |1 A| = {j R1 : [AB ()](j) = A} = {j R1 : 1 (j) A}.
words, = |1 A| items lie rank set R1 = {1, . . . , 1 }.
show item k maps rank R1 , must show relative
ranking elements A, k among first m. condition (b), () [S ]A ,
implying item subset 1 occupies first positions relative
ranking A. Since k 1 A, item k among first items ranked ()
therefore (k) R1 . similar argument shows k 1 B implise
(k) R1 .
Inductive case. show k A, (k) Ri . condition (b),
() [S ]A , implying item subset (and hence, item k) occupies
first = |i A| positions relative ranking beyond items i1
j=1 (j
A). inductive hypothesis mutual exclusivity, items, together
i1
i1
j=1 (j B) occupy ranks j=1 Rj , therefore (k) R` ` i.
hand, condition (a) assures us |i A| = {j Ri : 1 (j) A}
words, ranks Ri occupied exactly items A. Therefore,
(k) Ri . Again, similar argument shows k B implies (k) Ri .

A.2 pspan Set Always Partial Ranking
reason pspan set rankings, first introduce basic concepts
regarding combinatorics partial rankings. collection partial rankings
523

fiHuang, Kapoor & Guestrin

forms partially ordered set (poset) 0 0 obtained 0 0
dropping vertical lines. example, S3 , 1|2|3 12|3. Hasse diagram
graph node corresponds partial ranking node x connected
node via edge x exists partial ranking z x z
(see Lebanon & Mao, 2008). top Hasse diagram partial ranking 1, 2, . . . , n
(i.e., ) bottom Hasse diagram lie full rankings. See Figure 13
example partial ranking lattice S3 .
Lemma 34. [Lebanon & Mao, 2008] Given two partial rankings , 0 0 ,
exists unique supremum 0 0 (a node Ssup sup Ssup sup
0 0 Ssup sup , node greater Ssup sup ). Similarly,
exists unique infimum 0 0 .
Lemma 35. Given two partial rankings , 0 0 , relation 0 0 holds
lies 0 0 Hasse diagram.
Proof. lies 0 0 Hasse diagram, 0 0 trivial since
obtained dropping vertical bars 0 0 . given lie
0 0 , would like show 0 0 6 . Let Sinf inf unique infimum
0 0 guaranteed Lemma 34. definition Hasse diagram,
obtained dropping verticals vertical bar representation
Sinf inf . Since lie 0 0 , must vertical bar
dropped 0 0 dropped (if exist bar,
0 0 ), hence must exist pair items i, j separated single vertical
bar unseparated 0 0 . Therefore exists 0 0 (j) < (i)
even though exists . conclude 0 0 6 .
Lemma 36 (Lemma 23 main body). X Sn , pspan(X) partial ranking.
Proof. Consider subset X Sn . partial ranking containing every element X
must upper bound every element X Hasse diagram Lemma 35.
Lemma 34, must exist unique least upper bound (supremum) X, Ssup sup ,
common upper bound X, must also ancestor Ssup sup
hence Ssup sup . therefore see partial ranking containing X must
superset Ssup sup . hand, Ssup sup partial ranking containing X.
Since pspan(X) intersection partial rankings containing X, pspan(X) =
Ssup sup therefore pspan(X) must partial ranking.
A.3 Proofs Claim rspan(X) = pspan(X)
simplify notation remaining proofs, introduce following definition.
Definition 37 (Ties). Given partial ranking = 1 | . . . |r , say items a1
a2 tied (written a1 a2 ) respect a1 , a2 i.
following basic properties tie relation straightforward.
Proposition 38.
524

fiEfficient Inference Partial Rankings

123
1|23

12|3

13|2

2|13

3|12

23|1

1|2|3

1|3|2

2|1|3

3|1|2

2|3|1

3|2|1

Figure 13: Hasse diagram lattice partial rankings S3 .
I. respect fixed partial ranking , tie relation, , equivalence relation
item set (i.e., reflexive, symmetric transitive).
II. exist , 0 disagree relative ranking items a1 a2 ,
a1 a2 respect .
III. 0 0 , a1 a2 respect , a1 a2 respect 0 0 .
IV. a1 a2 respect , (a1 ) < (a3 ) < (a2 ) item a3
, a1 a2 a3 .
Proposition 39. Given set rankings X input, Algorithm 2 outputs pspan(X).
Proof. prove three things, together prove proposition: (1) algorithm
terminates, (2) stage elements X contained pspan(X), (3)
upon termination, pspan(X) contained element X.
1. First note algorithm must terminate finitely many iterations
loop since stage least one vertical bar removed partial ranking,
vertical bars removed elements X,
disagreements relative ordering.
2. show stage algorithm, every element Xt subset
pspan(X). initialization, course, X0 , simply singleton
set consisting element X, therefore pspan(X).
Suppose pspan(X) every Xt . replaced
Xt+1 , want show pspan(X) well. Algorithm 2,
j, = 1 | . . . |j |j+1 | . . . |r , written 1 | . . . |j
j+1 | . . . |r , vertical bar j j+1 deleted due existence
partial ranking Xt , 0 0 Xt disagrees relative
ordering items a1 , a2 opposite sides bar. Since 0 0
subsets pspan(X) assumption, know a1 a2 respect pspan(X)
(Proposition 38, II). Suppose a1 a2 i0 . x
i0 , x a1 a2 respect pspan(X) (III)
Proposition 38. Moreover, (I, transitivity), see x respect
pspan(X). two elements i0 . (IV) Proposition 38,
items lying , i+1 , . . . , i0 thus tied respect pspan(X) therefore
removing bar items a1 a2 (producing, example, ) results
partial ranking subset pspan(X).
525

fiHuang, Kapoor & Guestrin

3. Finally, upon termination, ranking X contained element
Xt , would exist two items a1 , a2 whose relative ranking
disagree upon, contradiction. Therefore, every element Xt contains
every element X thus pspan(X) every Xt .

Lemma 40. Let = 1 | . . . |i |i+1 | . . . |k partial ranking item set ,
0 0 = 1 | . . . |i i+1 | . . . |k , partial ranking sets i+1
merged. Let a1 ij=1 j a2 kj=i+1 j . element C
additionally exists ranking disagrees relative
ordering a1 , a2 , 0 0 O.
Proof. fix completely decomposable work h, indicator
distribution corresponding O. Let 0 0 . prove lemma, need establish
h() > 0. Let 0 element 0 (k) = (k) k \(i i+1 ).
Since supp(h) assumption, h( 0 ) > 0.
Since 0 match items except i+1 , exists sequence
rankings 0 , 1 , 2 , . . . , = adjacent rankings sequence differ
pairwise exchange items b1 , b2 i+1 . show step
along sequence, h( ) > 0 implies h( t+1 ) > 0, prove h() > 0.
Suppose h( ) > 0 t+1 differ relative ranking
items b1 , b2 i+1 (without loss generality, assume (b2 ) < (b1 )
t+1 (b1 ) < t+1 (b2 )).
idea following paragraph use previous lemma (Lemma 28) prove
t+1 positive probability so, necessary argue
exists ranking 0 h( 0 ) > 0 0 (b1 ) < 0 (b2 ) (i.e., 0 disagrees
relative ranking b1 , b2 ). Let element . a1 , rearrange
a1 ranked first among elements . a2 i+1 , rearrange
a2 ranked last among elements i+1 . Note still element
possible rearrangements therefore h() > 0. assume (b2 ) < (b1 )
since otherwise shown wanted show. Thus relative ordering
a1 , a2 , b1 , b2 within a1 |b2 |b1 |a2 . Note treat case items a1 , a2 , b1 , b2
distinct, argument follows cases a1 = b2 a2 = b1 .
since disagrees relative ordering a1 , a2 assumption (and
hence disagrees ), apply Lemma 28 conclude swapping relative ordering
a1 , a2 within (obtaining a2 |b2 |b1 |a1 ) results ranking, 0 , h( 0 ) > 0.
Finally, observe 0 must disagree relative ranking a2 , b2 ,
invoking Lemma 28 shows swap relative ordering a2 , b2 within
(obtaining a1 |a2 |b1 |b2 ) result ranking 0 h( 0 ) > 0. element 0 ranks
b1 b2 , wanted show.
shown exist rankings disagree relative ordering b1
b2 positive probability h. applying Lemma 28 shows swap
relative ordering items b1 , b2 within obtain t+1 h( t+1 ) > 0,
concludes proof.
526

fiEfficient Inference Partial Rankings

A.4 Uniformity C Functions Partial Ranking
thus far shown element C must supported partial ranking.
following, show (up certain class exceptions), element must
assign uniform probability members partial ranking.
Theorem 41. h completely decomposable function supported partial ranking
= 1 | . . . |r |i | =
6 2 = 1, . . . , r, h uniform (i.e.,
1
Q
h() =
|i | ).


establish Theorem 41, must establish two supporting results: (1) Lemma 42
factors h r smaller completely decomposable functions, nonzero everywhere domain, (2) Theorem 43 establishes uniformity completely
decomposable function nonzero everywhere domain.
Lemma 42. completely decomposable Q
function, h, supported partial ranking
= 1 | . . . |r , must factor as: h() = ri=1 h((i )), factor distribution
h((i )) completely decomposable function Si .
Proof. Since h completely decomposable, (i ) riffle independent
(\i ) i. Since h supported partial ranking = )1 | . . . |r , however,
interleaving complement deterministic therefore conclude fact
(i ) fully independent
(\i ). Since (i ) (\i ) i,
Qr
factorization: h() = i=1 h((i )).
turn establishing factor h((i )) completely decomposable
observation. Fix = 1 (without loss generality) consider partition set 1
subsets B. would like see sets B riffle independent
respect h((1 )). Since h assumed completely decomposable, know
riffle independent complement, B(\1 ). words, B = B(\1 ),
variables (), AB , B (the relative ranking A, interleaving
remaining items, relative ranking remaining items, respectively) mutually
independent. observe (1) interleaving B, AB , deterministic
function interleaving AB (2) relative ranking B, B , deterministic
function B , thus proving , AB B mutually independent hence
B riffle independent.
Theorem 43. Let h completely decomposable function h() > 0 Sn
n > 2. two rankings 1 , 2 differ single transposition,
h(1 ) = h(2 ).
proof strategy Theorem 43 involve examining ratio two
probabilities h(1 ) h(2 ). define operation transforming 1 2 new
rankings 10 20 ratio rankings preserved (i.e., h(1 )/h(2 ) =
h(10 )/h(20 )). performing sequence ratio-preserving operations, show that:
h(1 )
h(2 )
=
,
h(2 )
h(1 )
Theorem 43 easily follows.
527

fiHuang, Kapoor & Guestrin

use two types operations transform ranking new ranking: (1)
changing interleaving two sets B within ranking , (2), changing
relative ranking set within ranking . precisely, given ranking
partitioning item set subsets B, uniquely index triplet
(, , B ), = A,B (), = (), B = B (). two operations
defined follows:
1. Changing interleaving A, B within 0 : yields new ranking 0
indexed ( 0 , , B ).
0 (or 0 ): yields new
2. Changing relative ranking (or B) within
B
0
0
0
ranking indexed (, , B ) [or (, , B )].

use operations obtain 10 20 , interested conditions
transformation ratio-preserving (i.e., h(1 )/h(2 ) = h(10 )/h(20 )).
following lemma provides sufficient conditions ratio-preservation.
Lemma 44. Let h completely decomposable function consider 1 , 2 Sn
h(2 ) > 0. partitioning item set subsets B, have:
1. 1 2 match interleaving B (i.e., A,B (1 ) = AB (2 )),
h(10 )
h(1 )
0
0
h(2 ) = h(20 ) , 1 2 formed changing interleaving sets
B within 1 2 new interleaving 0 .
2. 1 2 match relative ranking (or B) (i.e., (1 ) = (2 ) (or
h( 0 )
h(1 )
= h(10 ) , 10 20 formed changing
B (1 ) = B (2 ))), h(
2)
2
0
relative ranking set (or B) within 1 2 new relative ranking
0
(or B ).
Proof. Since proofs parts 1 2 nearly identical, prove part 1 here.
Since h C, sets B riffle independent assumption, hence
factorizations:
h(1 )
m(1 ) f (1A ) g(2B )
=
.
h(2 )
m(2 ) f (2A ) g(2B )

1 2 match interleaving sets B, = 1 = 2 ,
thus interleaving terms, m(1 ) m(2 ) numerator
denominator.
hand, examine ratio h(10 ) h(20 ), also see
interleaving terms must cancel:
h(1 )
m(10 ) f (1A ) g(2B )
=
.
h(2 )
m(20 ) f (2A ) g(2B )

therefore that:
f (1A ) g(piB
h(10 )
h(1 )
1 )
=
=
.

B
h(2 )
h(20 )
f (2 ) g(2 )

528

fiEfficient Inference Partial Rankings

established Lemma 44, turn establishing three short claims (using
lemma) allow us prove finally prove Theorem 43. interesting note
require n > 2 (strictly) claim III swap order j
numerator denominator. third item k proof thought
playing role dummy variable analogous temporary storage variables one
might use implementing swap function. necessity third item precisely
result hold special case n = 2.
Proposition 45. Let h : Sn R completely decomposable function n > 2
h() > 0 Sn . following equivalences (where
ratios, entries explicitly written assumed match identically
numerator denominator).
I.

II.

h(i|j| . . . |k| . . . )
h(i|j|k| . . . )
=
.
h(j|i| . . . |k| . . . )
h(j|i|k| . . . )
h(. . . |i| . . . |j| . . . )
h(i|j| . . . )
=
.
h(. . . |j| . . . |i| . . . )
h(j|i| . . . )

III.

h(j|i|k| . . . )
h(i|j|k| . . . )
=
.
h(j|i|k| . . . )
h(i|j|k| . . . )

Proof.
I. Equality holds since 1 2 match interleaving sets = {k}
B = \{k}. Thus change interleaving B 1 2
item k inserted rank 3 preserving ratio.
II. Equality holds II since 1 2 match interleaving sets = {i, j}
B = \{i, j}. Thus change interleaving B 1
2 items j occupy first two ranks preserving ratio
h(1 ) h(2 ).
III. following use 1 2 refer arguments numerator
denominator, respectively, preceding line.
h(i|j|k| . . . )
h(i|k|j| . . . )
=
,
h(j|i|k| . . . )
h(k|i|j| . . . )
h(j|i|k| . . . )
=
,
h(j|k|i| . . . )
h(i|j|k| . . . )
=
,
h(i|k|j| . . . )
h(k|j|i| . . . )
=
,
h(k|i|j| . . . )
h(j|i|k| . . . )
=
,
h(i|j|k| . . . )

(since 1 , 2 match relative ranking {j, k})
(since 1 , 2 match interleaving {j} \{j})
(since 1 , 2 match relative ranking {i, j})
(since 1 , 2 match relative ranking {i, k})
(since 1 , 2 match interleaving {k} \{k}).

529

fiHuang, Kapoor & Guestrin

Proof. (of Theorem 43) want show two rankings differ single transposition,
assigned equal probability h. Suppose 2 obtained
1 swapping ranks items j. Additionally, let k item besides j
(such item must exist since n > 2). following, use Proposition 45 show
h(1 )/h(2 ) = h(2 )/h(1 ). before, entries explicitly written
assumed match identically numerator denominator.
h(. . . |i| . . . |j| . . . )
h(i|j| . . . )
h(1 )
=
=
, (by Prop. 45, Part II)
h(2 )
h(. . . |j| . . . |i| . . . )
h(j|i| . . . )
h(i|j| . . . |k| . . . )
h(i|j|k| . . . )
=
=
, (by Prop. 45, Part I)
h(j|i| . . . |k| . . . )
h(j|i|k| . . . )
h(j|i|k| . . . )
, (by Prop. 45, Part III)
=
h(i|j|k| . . . )
h(j|i| . . . |k| . . . )
=
, (by Prop. 45, Part I)
h(i|j| . . . |k| . . . )
h(j|i| . . . )
h(. . . |j| . . . |i| . . . )
=
=
, (by Prop. 45, Part II)
h(i|j| . . . )
h(. . . |i| . . . |j| . . . )
h(2 )
=
.
h(1 )

Since assumed h(1 ) h(2 ) > 0, must conclude h(1 ) = h(2 ).
Finally, assemble supporting results prove Theorem 41.
Proof. (of Theorem 41) Lemma 42, completely decomposable function h must factor
as:
r

h() =
h((i )),
(A.2)
i=1

factor distribution h((i )) completely decomposable function Si .
assumption, |i | 6= 2. |i | = 1, corresponding factor h((i )) must trivially
uniform. Otherwise, |i | > 2. latter case, apply Theorem 43
h((i )) show must assign equal probability two rankings differ
single transposition. However, given rankings 1 , 2 Si , obtain sequence
transpositions transforms 1 2 , therefore, Theorem 43 fact implies
factor h((i )) constant inputs. proved factor Equation A.2
constant, conclude h must constant support.

References
Ailon, N. (2007). Aggregation partial rankings, p-ratings top-m lists. Proceedings
eighteenth annual ACM-SIAM symposium Discrete algorithms, SODA 07,
New Orleans, Louisiana.
Bartholdi, J. J., Tovey, C. A., & Trick, M. (1989). Voting schemes
difficult tell won. Social Choice Welfare, 6(2).
530

fiEfficient Inference Partial Rankings

Busse, L. M., Orbanz, P., & Buhmann, J. (2007). Cluster analysis heterogeneous rank
data. 24th Annual International Conference Machine Learning, Corvallis,
Oregon.
Fligner, M. A., & Verducci, J. S. (1986). Distance based ranking models. Journal
Royal Statistical Society, 48.
Freund, Y., Iyer, R., Schapire, R. E., & Singer, Y. (2003). efficient boosting algorithm
combining preferences. Journal Machine Learning Research (JMLR), 4, 933969.
Friedman, N. (1997). Learning belief networks presence missing values hidden variables. Proceedings Fourteenth International Conference Machine
Learning, ICML 97, pp. 125133, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.
Friedman, N. (1998). bayesian structural em algorithm. 14th Conference
Uncertainty Artificial Intelligence, UAI 98, Madison, Wisconsin.
Gormley, C., & Murphy, B. (2007). latent space model rank data. Proceedings
2006 conference Statistical network analysis, ICML06, pp. 90102, Berlin,
Heidelberg. Springer-Verlag.
Huang, J., Kapoor, A., & Guestrin, C. (2011). Efficient probabilistic inference partial
ranking queries. 27th Conference Uncertainty Artificial Intelligence, UAI
11, Barcelona, Spain.
Huang, J. (2011). Probabilistic Reasoning Learning Permutations: Exploiting Structural Decompositions Symmetric Group. Ph.D. thesis, Carnegie Mellon University.
Huang, J., & Guestrin, C. (2009). Riffled independence ranked data. Bengio, Y.,
Schuurmans, D., Lafferty, J., Williams, C. K. I., & Culotta, A. (Eds.), Advances
Neural Information Processing Systems 22, NIPS 08, pp. 799807. MIT Press.
Huang, J., & Guestrin, C. (2010). Learning hierarchical riffle independent groupings
rankings. Proceedings 27th Annual International Conference Machine
Learning, ICML 10, pp. 455462, Haifa, Israel.
Huang, J., & Guestrin, C. (2012). Uncovering riffled independence structure ranked
data. Electronic Journal Statistics, 6, 199230.
Huang, J., Guestrin, C., & Guibas, L. (2008). Efficient inference distributions permutations. Platt, J., Koller, D., Singer, Y., & Roweis, S. (Eds.), Advances Neural
Information Processing Systems 20, NIPS 07, pp. 697704. MIT Press, Cambridge,
MA.
Huang, J., Guestrin, C., & Guibas, L. J. (2009). Fourier theoretic probabilistic inference
permutations. Journal Machine Learning Research (JMLR), 10, 9971070.
Joachims, T. (2002). Optimizing search engines using clickthrough data. Proceedings
eighth ACM SIGKDD international conference Knowledge discovery data
mining, KDD 02, pp. 133142, New York, NY, USA. ACM.
Kondor, R., Howard, A., & Jebara, T. (2007). Multi-object tracking representations
symmetric group. Meila, M., & Shen, X. (Eds.), Proceedings Eleventh
531

fiHuang, Kapoor & Guestrin

International Conference Artificial Intelligence Statistics March 21-24, 2007,
San Juan, Puerto Rico, Vol. Volume 2 JMLR: W&CP.
Kondor, R. (2008). Group theoretical methods machine learning. Ph.D. thesis, Columbia
University.
Lebanon, G., & Lafferty, J. (2003). Conditional models ranking poset. S. Becker,
S. T., & Obermayer, K. (Eds.), Advances Neural Information Processing Systems
15, NIPS 02, pp. 415422, Cambridge, MA. MIT Press.
Lebanon, G., & Mao, Y. (2008). Non-parametric modeling partially ranked data. Platt,
J. C., Koller, D., Singer, Y., & Roweis, S. (Eds.), Advances Neural Information
Processing Systems 20, NIPS 07, pp. 857864, Cambridge, MA. MIT Press.
Lu, T., & Boutilier, C. (2011). Learning mallows models pairwise preferences.
28th Annual International Conference Machine Learning, ICML 11, Bellevue,
Washington.
Marden, J. I. (1995). Analyzing Modeling Rank Data. Chapman & Hall.
Meila, M., Phadnis, K., Patterson, A., & Bilmes, J. (2007). Consensus ranking
exponential model. Tech. rep. 515, University Washington, Statistics Department.
White, R., & Drucker, S. (2007). Investigating behavioral variability web search.
Proceedings 16th international conference World Wide Web, WWW 07,
Banff, Alberta, Canada. ACM.

532

fiJournal Artificial Intelligence Research 44 (2012) 383-395

Submitted 01/12; published 06/12

Research Note
Narrative Planning: Compilations Classical Planning
Patrik Haslum

PATRIK . HASLUM @ ANU . EDU . AU

Australian National University, Canberra
Optimisation Research Group, NICTA

Abstract
model story generation recently proposed Riedl Young casts planning,
additional condition story characters behave intentionally. means characters
perceivable motivation actions take. show condition compiled away (in
ways one) produce classical planning problem solved off-the-shelf
classical planner, efficiently Riedl Youngs specialised planner.

1. Introduction
classical AI planning model, assumes actions deterministic planner
complete knowledge control world, often thought restricted,
many potential applications problems appear requirements fit model. Recently, however, shown problems thought go beyond classical model
nevertheless solved classical planners means compilation, i.e., systematic remodelling
problem classical plan reformulated problem meets also non-classical
requirements. striking example work Palacios Geffner (2006), showed conformant planning (generating plans robust certain forms uncertainty) compiled
classical planning problem. Another example, closer topic paper, work
Porteous, Teutenberg, Pizzi Cavazza (2011), use planner generate variations
drama encoding constraints sequencing events within it.
paper another problem kind: planning fabula, meaning event structure,
plot, story.1 fabula planning problem considered formulated Riedl Young
(2010). main difference classical planning notion intentionality: actions story
taken different characters, story considered believable, characters
behave intentionally, i.e., (perceivable) motivations actions take. Riedl
Young argue [the fact classical planners take account character intentions]
limits applicability off-the-shelf planners techniques generating stories, develop
instead narrative planner, IPOCL, extends traditional partial-order causal link planner
mechanism enforce plans respect character intentionality. show fabula
planning, defined Riedl Young, compiled classical planning problem,
hence fact solved off-the-shelf classical planner. preclude using
extended formalism, like introduced Riedl Young, better suited purpose
modelling fabula planning problems, since compilation easily automated. advantage
obvious: allows bring bear narrative planning problem entirety existing,
1. telling story, discourse, distinct fabula (e.g., Gervas 2009). aforementioned work
Porteous et al. seen application planning generating different discourses given fabula.
c
2012
AI Access Foundation. rights reserved.

fiH ASLUM

future, work algorithms classical planning, dramatically reduced cost development
time effort. surprising find classical planners run compiled problem
far efficient IPOCL algorithm, well capable more, like finding set
diverse plans.
different theories distinguishes story arbitrary sequence
events, i.e., gives storiness (e.g., Gervas 2009; Mateas & Sengers, 1999). aim
criticise particular model narrative planning proposed Riedl Young merely
show criterion adopted character intentionality achieved classical
planner without modification, simply restating problem given planner solve.
Whether done also models narrative generation open question.

2. Narrative Planning Intentional Plans
story King Jafar becomes married Jasmine. magic genie.
also story genie dies.
(From textual representation story generated IPOCL; Riedl & Young 2010.)
Riedl Young observe many parallels plans narrative level
fabula. sequences events change state (story) world. story
perceived coherent plausible, event sequence must logically possible (i.e., preconditions achieved event takes place) connected causes effects (i.e., event
contributes something story, setting stage later events). goal story,
view, end state storys author mind; Riedl Young call story
outcome, distinguish character goals. story believable, characters
appear intentional agents: characters actions possible, contribute
outcome story, perceivable contributing goals character
(which necessarily authors goal). seen non-redundancy
requirement subsets plan: action done character story directly
indirectly contribute achieving goal character. course, goals character
change throughout course story, influenced characters, events
world around them. change characters goals must also cause.
illustrate narrative planning, evaluate believability plans generated IPOCL,
Riedl Young (appendix A.1, p. 254256) use following small example scenario. dramatis personae are:
King Jafar, lives Castle;
Aladdin, Knight loyal Jafar;
Jasmine, beautiful woman, also lives Castle;
Genie, imprisoned Magic Lamp;
Dragon, lives Mountain possesses Lamp start story.
Characters travel two locations. knight slay monster (only Dragon
Genie monsters). character take things dead character (pillage), give
things another character (the Lamp item interest). character Lamp
summon Genie, thereby gaining control it. Genie, magic, cause character
fall love another character. Two characters love, otherwise engaged,
marry. goals story (married Jafar Jasmine) (dead Genie). Note
goals represent story outcome; (initially) intended character.
384

fiNARRATIVE P LANNING : C OMPILATIONS C LASSICAL P LANNING

Riedl Young distinguish two types planning actions: intentional actions, correspond actions taken one story characters (actors action), happenings,
actors correspond accidental events, forces nature, etc. classifications actions intentional happenings, assignment role actor(s) parameters
intentional actions, part domain theory. Examples happenings scenario
character fall love another beautiful, scary monster frighten
another character.
Character intentions modelled modal literals form (intends f ), character f fact, i.e., normal literal. Intentions arise effect actions, either happenings
character actions. example, happening (fall-in-love ?man ?woman) effect (loves
?man ?woman) establishes intention (intends ?man (married ?man ?woman)). Similarly,
action (deliver-witty-insult ?speaker ?hearer ?victim), ?speaker actor, could
effect (amused ?hearer), also unintended (by speaker) effect (intends ?victim (dead
?speaker)). special category actions cause intentions delegating actions, one
character commands (or persuades, bribes, otherwise influences) another achieve something.
example, (order ?king ?knight ?goal) effect (intends ?knight ?goal).
Riedl Young define notion intentionality context partially ordered causal
link (POCL) plans.2 following definition summarises definitions 3, 5 6 (pp. 232234)
article:
Definition 1 intentional plan one every occurrence intentional action part
frame commitment. frame commitment subset steps (i.e., action occurrences)
plan, associated modal literal (intends g), satisfying four requirements: (1) Character actor every step . (2) final step sfin makes g true. (3)
motivating step sm plan, adds (intends g) precedes steps . Well
say motivational link sm every step frame commitment, . Note sm
part . (4) step sfin path causal motivational
links sfin . complete (fabula) plan one intentional valid classical sense.
Condition (4) departs slightly definitions stated Riedl Young: require
step temporally precedes sfin . would appear promiscuous, since
allows unrelated action incorporated frame commitment adding spurious
temporal constraints. IPOCL algorithm, however, incorporate step existing
frame commitment step causal link step already frame, serve
motivating step frame commitment whose final step causal link step already
frame (cf. items 1 2 page 235 article). Hence, frames algorithm
generates always satisfy condition (4).

3. Compilation 1: Explicit Justification Tracking
first compilation based explicit tracking justifications, form causal
motivating links, actions plan. inspired work Karpas Domshlak (2011)
pruning redundant action sequences search space, also relies notion
justification actions.
2. detailed account POCL planning found paper McAllester Rosenblitt (1991) AI
textbooks.

385

fiH ASLUM

use three kinds modal literals: (intends f ) (delegated f ),
character f fact, (justified f I), f fact intention, i.e., modal literal
first form. intends modality part narrative planning problem specification,
appear action effects initial state. modalities used describe
compilation. course, modal conditions cannot expressed directly classical planning
formalism like PDDL. PDDL model, replaced separate modal predicate
predicate (resp. combination two predicates) appear non-modal fact, whose arguments concatenation arguments modal literal. example, (intends Aladdin (has
Jafar Lamp)) replaced (intends-has Aladdin Jafar Lamp), (justified (at Aladdin Mountain)
(intends Aladdin (has Jafar Lamp))) replaced (justified-at-has Aladdin Mountain Aladdin Jafar
Lamp).
compiled problem, intentional action associated intention actions
actor(s). intention precondition action. action achieve
intention, creates outstanding obligation make use least one effects achieve
precondition action, done actor, contributes, directly indirectly,
achieving intention. modelled justified modality. explained earlier, actions
modal effects form (intends B f ), i.e., make character (different actor)
intend goal. modelled delegated modality.
intentional action, (a ~x), narrative planning problem, compiled problem
one distinct action combination intention (intends xA (p ~y )), xA
parameter represents actor (a ~x), effect (e ~z) (a ~x). name compiled
action (a-e-because-intends-p ~x ~y ), call (e ~z) chosen effect. Note parameters ~z
chosen effect composed subset parameters ~x action, possibly explicit
constants. Action (a-e-because-intends-p ~x ~y ) read character xA performs action (a ~x)
achieve effect (e ~z) step towards achieving characters intended goal (p ~y ). (e ~z)
unify (p ~y ), action must broken two cases: one forced
equal one forced distinct. intentional action one
actor, compiled problem must distinct action (possible relevant) choice
effect intention actor. happening (i.e., action without actor) one
corresponding action compiled problem.
justified delegated modalities combine track causal motivational links
compiled problem. (possible relevant) justified literals true initial state,
required true goal state. Action (a-e-because-intends-p ~x ~y ) makes chosen effect
unjustified, deleting (justified (e ~z) (intends xA (p ~y ))). Since goal requires justified literals
hold, plan must include action, actor intention, whose
precondition requires (e ~z); action make (justified (e ~z) (intends xA (p ~y ))) true again.
chosen effect modal literal (intends zA (q z~ )) subgoal (q z~ ) becomes unjustified,
also becomes delegated second character, zA . provides motivational link
action (a-e-because-intends-p ~x ~y ) action zA takes achieve (q z~ ). Delegation
ends character achieves goal. goal delegated, character may achieve
goal. ensures step created delegation eventually justified, character
performed making use achieved fact (q z~ ).
Let (a ~x) intentional action, xA parameter represents actor, (e ~z) chosen
effect (intends xA (p ~y )) intention actor. preconditions compiled action
(a-e-because-intends-p ~x ~y ) are:
386

fiNARRATIVE P LANNING : C OMPILATIONS C LASSICAL P LANNING

(1)
(2)
(3a)
(3b)
(3c)
(4)

preconditions (a ~x);
(intends xA (p ~y ));
w (delegated w (q z~ )), effect (a ~x) form (intends zA (q z~ ));
w 6= xA (delegated w (p ~y )), (p ~y ) effect (a ~x);
w (delegated w (q z~ )), effect (q z~ ) (a ~x) intends modal literal.
(intends zA (q z~ )), (e ~z) modal literal form (intends zA (q z~ )).

plan compiled problem, sets actions associated intention form frame
commitment. Precondition (2) ensures steps frame preceded motivating step.
Precondition (4) ensures one (intentional) motivating step. Preconditions (3ac)
ensure action taken delegates (a) achieves (bc) goal already delegated
another character.
effects compiled action are:
(1) effects (a ~x);
(2) (justified (q ~v ) (intends xA (p ~y ))), (non-static) precondition (q ~v ) (a ~x).
(3a) (justified (q z~ ) (intends xA (p ~y ))) (delegated zA (q z~ )), (e ~z) modal literal
form (intends zA (q z~ ));
(3b) (justified (e ~z) (intends xA (p ~y ))), (e ~z) intends literal (e ~z) equal
(p ~y );
(4) (delegated xA (e ~z)), (e ~z) equals (p ~y );
Effects (2) (3) make preconditions action justified, chosen effect unjustified,
explained above. chosen effect modal intends literal (case 3a), intended subgoal
becomes unjustified, also delegated character. Effect (4) ends delegation
goal action final step frame commitment. (Note, however, action
effect even goal delegated; matter.)
chosen effect (e ~z) unified (p ~y ), compiled action must split two:
one additional precondition ~z = ~y , ensuring equal, one additional
precondition ~z 6= ~y , ensuring not. necessary since effects compiled
action depend whether (e ~z) equals (p ~y ) not. Furthermore, mentioned above, original
action (a ~x) one actor, compiled problem one action every combination
intention chosen effect actor. case, conditions (p ~y ) (e ~z)
schema interpreted actor separately. is, (pi ~y ) (ei ~zi )
intention chosen effect actor xiA , compiled action effect (justified (ei ~zi ) (intends
xiA (pi ~y ))) (ei ~zi ) intends literal (ei ~zi ) equal (pi ~y ) (item 3b), regardless
whether (ei ~zi ) equals (pj ~y j ) j 6= i, vice versa.
illustrate compilation, consider following action example scenario Riedl
Young (appendix A.1, p. 255), written PDDL-like syntax:
(:action slay
:parameters (?knight - knight ?monster - monster ?where - place)
:actors (?knight)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where))
:effect (and (not (alive ?monster)) (dead ?monster)))

actor action knight. Consider intention (intends ?knight (dead ?who)).
action one relevant choice effect, (dead ?monster) (the negative literal appear
action precondition goal). However, since intention unifies chosen effect,
387

fiH ASLUM

compiled problem must still include two actions, one ?who = ?monster one ?who 6=
?monster:
(:action slay-1-because-intends-dead
:parameters (?knight - knight ?monster - monster ?where - place)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)
(intends ?knight (dead ?monster))
(not (exists (?c) (and (not (= ?c ?knight)) (delegated ?c (dead ?monster))))))
:effect (and (not (alive ?monster)) (dead ?monster)
(justified (at ?knight ?where) (intends ?knight (dead ?monster)))
(justified (at ?monster ?where) (intends ?knight (dead ?monster)))
(not (delegated ?knight (dead ?monster)))))
(:action slay-2-because-intends-dead
:parameters (?knight - knight ?monster - monster ?where - place ?who - monster)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)
(intends ?knight (dead ?who))
(not (exists (?c) (delegated ?c (dead ?monster))))
(not (= ?who ?monster)))
:effect (and (not (alive ?monster)) (dead ?monster)
(justified (at ?knight ?where) (intends ?knight (dead ?who)))
(justified (at ?monster ?where) (intends ?knight (dead ?who)))
(not (justified (dead ?monster) (intends ?knight (dead ?who))))))

(The alive literals dont need justification, way make true unless true
initially.) Corresponding intention (intends ?knight (has ?who ?what)) compiled problem
action:
(:action slay-because-intends-has
:parameters (?knight ?monster ?where ?who ?what)
:precondition (and (alive ?knight) (at ?knight ?where) (alive ?monster) (at ?monster ?where)
(intends ?knight (has ?who ?what))
(not (exists (?c) (delegated ?c (dead ?monster)))))
:effect (and (not (alive ?monster)) (dead ?monster)
(justified (at ?knight ?where) (intends ?knight (has ?who ?what)))
(justified (at ?monster ?where) (intends ?knight (has ?who ?what)))
(not (justified (dead ?monster) (intends ?knight (has ?who ?what))))))

prove correctness compilation general, need concept toggling
action (Hickmott & Sardina, 2009). action toggling w.r.t. effect action iff
actions precondition implies negation effect. is, action makes true fact f ,
precondition must include f , fact f mutex f , action makes f false,
must require f true. action toggling transformed equivalent set
actions are, though size set exponential number non-toggling effects
original action.
Theorem 2 Let P narrative planning problem, action toggling w.r.t. effects.
Let P compiled problem described above. Every plan P intentional.
Proof: Consider step S, instance action (a-e-because-intends-p ~x ~y ). Let
actor (i.e., constant bound actor parameter xA a) (e ~z) chosen effect
(a ~x). action part frame commitment goal (p ~y ). construction,
388

fiNARRATIVE P LANNING : C OMPILATIONS C LASSICAL P LANNING

precondition (a-e-because-intends-p ~x ~y ) includes (intends (p ~y )). must motivating
step establishes precondition, otherwise would classically valid.
(e ~z) equals (p ~y ), final step frame commitment.
(e ~z) equal (p ~y ) modal literal, (a-e-because-intends-p ~x ~y ) destroys
(justified (e ~z) (intends (p ~y )). Since literals goals P , must later step, ,
re-establishes it. construction, action actor, (intends (p ~y ))
associated intention, (e ~z) precondition. step adds
(e ~z), must causal link labelled (e ~z) (since actions toggling, (e ~z)
true s). cannot step sadd adds (e ~z), so,
action associated sadd would applied state one effects, (e ~z), already
true, thus toggling. Suppose steps sdel sadd taking place ,
sdel destroys (e ~z) sadd makes true again; several steps, let sdel first
sadd last, causal link sadd . Since actions toggling sdel requires
(e ~z), causal link sdel . chain causal links sdel sadd ,
subplan consisting steps including causal predecessors sadd (which
include sdel ) must executable, results execution action associated sadd
applied state one effects, (e ~z), already true, hence toggling.
Thus, must chain causal links sdel sadd , therefore . Since
part frame commitment (it motivating intention),
finite number steps frame commitment causally follow s, repeated application
reasoning leads conclusion must chain causal links final
step frame.
(e ~z) modal literal form (intends zA (q z~ )), (a-e-because-intends-p ~x ~y ) destroys
(justified (q z~ ) (intends (p ~y )), adds (delegated zA (q z~ )). above, must step
, frame commitment s, re-establishes (justified (q z~ ) (intends (p ~y )).
construction, (delegated w (q z~ )) true one character w time (any action
adds delegation requires character it), character currently holding
delegation (q z~ ) make true. Thus, (by argument above) causal
chain final step delegates frame commitment goal (q z~ ) .
actions compiled problem toggling w.r.t. intends literals, step must causal chain
precondition (intends zA (q z~ )) action frame commitment delegate,
thus serves motivating step frame. Thus, chain motivating causal
links , following argument above, therefore final step
frame commitment belongs to.
2
may noted apparently reasonable story plans disallowed. example, character
cannot delegate goal intends another character. This, however, consequence
Riedl Youngs definition intentional plans, compilation (and hence applies
also IPOCL planner): final step frame commitment must achieve intended
goal must action actor holds intention (conditions 1 & 2 Definition
1). rules delegating ones goals. desired, would difficult modify
compilation allow kind secondary delegation: requries adding exception w 6=
xA precondition (3a) effect like (4) case. plan also cannot character
trying failing multiple means achieve goals. Again, consequence Riedl
Youngs definition, compilation: every action taken character must chain
389

fiH ASLUM

causal motivational links final step (condition 4 Definition 1). rules characters
taking actions prove ultimately futile.
Theorem 2 shows compilation sound. question whether also complete, i.e.,
whether existence intentional plan narrative planning problem P always implies existence
plan compiled problem P , somewhat complicated. first glance, given intentional
plan P , appears plan compiled problem P could constructed selecting
action suitable representative a-. . .-because-. . ., intentions chosen effects
match frames commitment belongs S. Since intentional, frame
commitment preceded motivating step, ensuring intends preconditions compiled
action satisified, final step, causal link least one effects
another step, ensuring deleted justified literals restored. is, however, one point
correspondence fail, due restriction compiled problem delegated
goal achieved character delegated to: Suppose character delegates
goal g character B, i.e., character performs intentional action whose (relevant) effect
(intends B g). plan intentional, must frame commitment belonging
character B, associated intention (intends B g); frame must final step
achieves g, step must source causal link step performed character A,
belonging frame commitment step established motivation. Yet,
nothing prevents another character, C, achieving g purposes, long character
B also achieves g. compiled problem, however, allow character C achieve g long
delegated B, i.e., motivating step final step B. could
remedied elaborate justification tracking mechanism, distinguishes
fact achieved different characters.
practical perspective, combinations actions intentions, modal literals,
present compiled problem restricted possible relevant.
example, initial state goal needs include justified literals actually
negated possibly applicable action (which found standard relaxed reachability
analysis). example scenario, fact character Lamp never causally contribute to, e.g., goal character another item (there items have)
goal murdering another character. Thus, actions like pillage-because-intends-dead order-hasbecause-intends-has order-has-because-intends-dead never part valid plan.
information could found simple techniques like back-chaining relevance analysis.
Applying compilation Riedl Youngs example scenario, applying classical planner, using forward-chaining A* search LM-Cut heuristic (Helmert & Domshlak, 2009),
compiled problem, produces plan shown figure 1. planner outputs sequence
actions, transformed partially ordered plan polynomial time post-processing step
(Backstrom, 1998). Enumerating shortest plans reveals two variations: one Jafar travels
back Castle marry Jasmine, one Jafar orders Aladdin bring Lamp,
climactic events (the wedding Aladding slaying Genie) take place Castle.
(The latter one Riedl Young report found IPOCL, shown Figure 15, p. 259,
article.) Note possible Jafar command Aladdin make (loves Jasmine
Jafar) true, Aladdin means achieve goal delegating
Genie, which, explained above, permitted definition frame commitment.
Finding shortest plans end itself: rather, side effect fact planner
usually seek achieve story outcome simplest way. somewhat odds
390

fiNARRATIVE P LANNING : C OMPILATIONS C LASSICAL P LANNING

Figure 1: story plan generated example problem. Motivational links drawn gray.
dashed edge ordering constraint. outlines group actions form frame
commitment character. avoid clutter, causal links justified predicates
shown; instead, causal links chosen effect action drawn bold.
seen chosen effect, except final steps, links (directly indirectly)
precondition action frame commitment.

391

fiH ASLUM

making story interesting. Porteous Cavazza (2009) argue complexification, i.e.,
making story convoluted order make interesting, achieved posting
additional author goals form PDDL3 trajectory constraints, specifying fact must
achieved point plan; fact must never true point;
fact must achieved another. PDDL3 trajectory constraints also compiled away
(Gerevini, Haslum, Long, Saetti & Dimopoulos, 2008). Methods generating diverse set
plans (Srivastava, Kambhampati, Nguyen, Do, Gerevini & Serina, 2007) could also used
automate complexification.
total time generate plan around 45 seconds (and that, half actual search;
rest grounding preprocessing.) time required compilation less
second. stark contrast running time IPOCL planner problem, reported
12 hours even problem-specific search heuristic (Riedl & Young, 2010). However,
example represents small problem. contains actions objects necessary
form intended story plan, more. realistic scenario problem specification
contains many possible actions objects relevant story outcome,
allow construction materially different plans goal. size compiled problem
grow quite quickly size original narrative planning problem increases.
example, larger version problem, including three actions items,
none directly relevant achieving outcome, takes nearly 30 minutes solve.

4. Compilation 2: Meta-Planning
Magic Lamp, thought Jafar. could summon Genie gain control
it. controlled Genie, could command make Jasmine love me.
second compilation based simulating characters process forming intentions
making plans, using explicit character planning actions. similarity Wolfe Russells (2011) use explicit establishment intentions means guide plan search efficiently. Compared justification-tracking compilation, less complex also less stringent:
plans meta-planning compiled problem guaranteed intentional, according
definition Riedl Young, although time be.
meta-planning action allows character adopt intention achieving precondition
action achieves goal character already intends. avoid characters making plans
never act on, counter tracks number intentions character has, required
zero end plan.3 counter represented standard propositional
encoding (though limits depth intentions character hold), numeric fluent.
Let (a ~x) intentional action, xA parameter represents actor, (e ~z) chosen
effect. corresponding action compiled problem additional precondition (intends
xA (e ~z)) effects (intends xA (e ~z)) decreases xA intention count 1. words,
take action, actor must one effects current set intentions, performing
action releases actor intention. (e ~z) modal literal form (intends zA
(q z~ )), precondition effect refer instead (q z~ ), action also increases intention
count zA , i.e., effect move (q z~ ) intention set xA character zA .
Happenings add character intentions must also increase intention count.
3. exceptions must made: example, character dies, obviously cannot act outstanding intentions, invalidate plan.

392

fiNARRATIVE P LANNING : C OMPILATIONS C LASSICAL P LANNING

precondition (p ~y ) (a ~x), compiled problem also action (plan-to-a ~x),
precondition (intends xA (e ~z)) effects (intends xA (p ~y )) increasing xA intention
count. (a ~x) several preconditions, order achievement among enforced
adding subsets preconditions meta-planning actions. example, action (give
?who ?what ?to-who ?where) preconditions: (has ?who ?what); (at ?who ?where); (at
?to-who ?where). Adding (has ?who ?what) precondition meta-planning action
establishes (intends ?who (at ?who ?where)) forces character intends give something
plan acquire item, actually so, planning travel (if necessary)
place recipient gift is. necessary reasonable constraints order
achievement action preconditions may found landmark ordering analysis (Hoffmann,
Porteous, & Sebastia, 2004). Manually adding constraints meta-planning actions gives
flavour (a simulation of) methods HTN planning (Erol, Nau, & Hendler, 1994).
reason meta-planning compilation guarantee intentional plans
forces characters motivate action plan, force monitor
plans still valid action takes place. example, Aladdin plans slay Dragon
order pillage Lamp, thief steals Lamp Dragon Aladdin
way Mountain, Aladdin still license slay Dragon, even though longer
contributes getting Lamp (in fact, must slay Dragon avoid left
unfulfilled intention). part, could rectified encoding elaborate structure
character plans set outstanding goals. example, directed graph encoding
could track dependency relations intentions, dependence story world facts.
may also provide basis allowing characters revise plans face changed
circumstances.
Limited computational experiments meta-planning compilation suggest
produces much smaller (ground) problems justification-tracking compilation,
still harder current heuristic search-based planners solve.

5. Conclusion
Research classical planning problem developed wide array of, sometimes highly
effective, methods solving problems. compilations, capabilities existing
classical planners leveraged solve many problems surface
appear classical planning problems. Like loyal knight story, classical planner
committedly try solve whatever task set it, expressed planning domain
specification. trick setting right task.
noted, narrative planning model defined Riedl Young limitations.
example, allow create story character tries fails achieve goal.
Brenner (2010) describes approach story generation interleaves classical planning
individual characters goals, based characters state knowledge, plan execution, i.e.,
adding events story. permits system generate stories characters forced
abandon plans learning new facts, postpone planning crucial facts become known.
Brenner claims would quite difficult describe [such plot] single plan, let alone
generate single planner run. indeed appear quite difficult, whether
impossible remains open question.

393

fiH ASLUM

Acknowledgments
wish thank Alban Grastien, Malte Helmert, Robert Mattuller reviewers useful
comments drafts paper. work supported Australian Research Council discovery project DP0985532 Exploiting Structure AI Planning. NICTA funded
Australian Government represented Department Broadband, Communications
Digital Economy Australian Research Council ICT Centre Excellence program.

References
Backstrom, C. (1998). Computational aspects reordering plans. Journal AI Research, 9, 99
137.
Brenner, M. (2010). Creating dynamic story plots continual multiagent planning. Proc. 24th
AAAI Conference Artificial Intelligence, pp. 15171522.
Erol, K., Nau, D., & Hendler, J. (1994). HTN planning: Complexity expressivity. Proc.
National Conference Artificial Intelligence (AAAI94), pp. 11231128.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2008). Deterministic planning
fifth international planning competition: PDDL3 experimental evaluation
planners. Artificial Intelligence, 173(5-6), 619668.
Gervas, P. (2009). Computational approaches storytelling creativity. AI Magazine, 30(3),
4962.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats difference anyway?. Proc. 19th International Conference Automated Planning Scheduling (ICAPS09).
Hickmott, S., & Sardina, S. (2009). Optimality properties planning via Petri net unfolding: formal analysis. Proc. 19th International Conference Automated Planning Scheduling
(ICAPS09), pp. 170177.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. Journal AI
Research, 22, 215278.
Karpas, E., & Domshlak, C. (2011). Living edge: Safe search unsafe heuristics. Proc.
ICAPS11 Workshop Heuristics Domain-Independent Planning, pp. 5358.
Mateas, M., & Sengers, P. (1999). Narrative intelligence. Narrative Intelligence: Papers
AAAI Fall Symposium. AAAI Press.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. Proc. 9th National
Conference Artificial Intelligence.
Palacios, H., & Geffner, H. (2006). Compiling uncertainty away: Solving conformant planning
problems using classical planner (sometimes). Proc. 21st National Conference Artificial Intelligence (AAAI06).
Porteous, J., & Cavazza, M. (2009). Controlling narrative generation planning trajectories:
role constraints. Proc. 2nd International Conference Interactive Digital Storytelling,
pp. 234245.
394

fiNARRATIVE P LANNING : C OMPILATIONS C LASSICAL P LANNING

Porteous, J., Teutenberg, J., Pizzi, D., & Cavazza, M. (2011). Visual programming plan dynamics using constraints landmarks. Proc. 21st International Conference Automated
Planning Scheduling (ICAPS11), pp. 186193.
Riedl, M., & Young, R. (2010). Narrative planning: Balancing plot character. Journal AI
Research, 39, 217268.
Srivastava, B., Kambhampati, S., Nguyen, T., Do, M., Gerevini, A., & Serina, I. (2007). Domain
independent approaches finding diverse plans. Proc. 20th International Conference
Artificial Intelligence (IJCAI07), pp. 20162022.
Wolfe, J., & Russell, S. (2011). Bounded intention planning. Proc. 22nd International
Joint Conference AI (IJCAI11), pp. 20392045.

395

fiJournal Artificial Intelligence Research 44 (2012) 179-222

Submitted 10/10; published 05/12

Improving Statistical Machine Translation
Resource-Poor Language
Using Related Resource-Rich Languages
Preslav Nakov

pnakov@qf.org.qa

Qatar Computing Research Institute
Qatar Foundation
Tornado Tower, Floor 10, P.O. Box 5825
Doha, Qatar

Hwee Tou Ng

nght@comp.nus.edu.sg

Department Computer Science
National University Singapore
13 Computing Drive
Singapore 117417

Abstract
propose novel language-independent approach improving machine translation
resource-poor languages exploiting similarity resource-rich ones. precisely, improve translation resource-poor source language X1 resourcerich language given bi-text containing limited number parallel sentences X1 -Y
larger bi-text X2 -Y resource-rich language X2 closely related
X1 . achieved taking advantage opportunities vocabulary overlap
similarities languages X1 X2 spelling, word order, syntax offer:
(1) improve word alignments resource-poor language, (2) augment
additional translation options, (3) take care potential spelling differences
appropriate transliteration. evaluation IndonesianEnglish using Malay
SpanishEnglish using Portuguese pretending Spanish resource-poor shows
absolute gain 1.35 3.37 BLEU points, respectively, improvement best rivaling approaches, using much less additional data. Overall,
method cuts amount necessary real training data factor 25.

1. Introduction
Recent developments statistical machine translation (SMT), e.g., availability efficient implementations integrated open-source toolkits like Moses (Koehn, Hoang, Birch,
Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, &
Herbst, 2007), made possible build prototype system decent translation
quality language pair days even hours. theory. practice,
requires large set parallel sentence-aligned texts two languages (bitexts) language pair. large high-quality bi-texts rare; except Arabic,
Chinese, official languages European Union (EU), 6,500+ world
languages remain resource-poor SMT viewpoint.
c
2012
AI Access Foundation. rights reserved.

fiNakov & Ng

number resource poor languages becomes even striking consider language pairs instead individual languages. Moreover, even resource-rich language pairs
could poor bi-texts specific domain, e.g., biomedical.
manually creating small bi-text could relatively easy, building large one
hard time-consuming. Thus, publicly available bi-texts SMT come parliament debates legislation multi-lingual countries (e.g., French-English Canada,
Chinese-English Hong Kong), international organizations like United
Nations European Union. example, Europarl corpus parliament proceedings consists 1.3M parallel sentences (up 44M words) per language 11
languages (Koehn, 2005), JRC-Acquis corpus provides comparable amount European legislation 22 languages (Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis,
& Varga, 2006).
Due increasing volume EU parliament debates ever-growing European
legislation, official languages EU especially privileged SMT perspective. includes classic SMT languages English French (which
already resource-rich), important international ones like Spanish Portuguese,
many rest limited number speakers resource-poor years
ago. Thus, becoming official language EU turned easy recipe
getting resource-rich bi-texts quickly.
aim tap potential EU resources used nonEU languages closely related one official languages EU. Examples
EUnon-EU language pairs include SwedishNorwegian, BulgarianMacedonian1 ,
Romanian-Moldovan2 other. Croatia joins EU, Serbian, Bosnian,
Montenegrin3 also able benefit Croatian gradually turning resource-rich (all
four languages split Serbo-Croatian breakup Yugoslavia 90s
remain mutually intelligible). newly-made EU-official (and thus resourcerich) Czech Slovak languages another possible pair candidates. SpanishCatalan,
Irish-Gaelic Scottish, Standard GermanSwiss German, ItalianMaltese4 good
examples. see below, even resource-rich languages like Spanish Portuguese benefit proposed approach. course, many pairs closely related
languages could make use others bi-texts also found outside Europe:
one example MalayIndonesian, experimenting below.
non-EU language pairs could potentially benefit include Modern Standard Arabic
Dialectical Arabic (e.g., Egyptian, Levantine, Gulf, Iraqi Arabic), MandarinCantonese,
RussianUkrainian, TurkishAzerbaijani, HindiUrdu, many other.
1. heated linguistic debate whether Macedonian represents separate language
regional literary form Bulgarian. Since clear criteria distinguishing dialect
language, linguists divided issue. Politically, Macedonian language recognized
Bulgaria (which refers official language Republic Macedonia accordance
constitution) Greece (mostly dispute use name Macedonia).
2. Macedonian, debate existence Moldovan language. linguists
generally agree Moldovan one dialects Romanian, politically, national language
Moldova called Moldovan Romanian.
3. serious internal political division Montenegro whether national language
called Montenegrin Serbian.
4. Though, Maltese might benefit Arabic Italian.

180

fiImproving SMT Resource-Poor Language

propose using bi-texts resource-rich language pairs build better SMT
systems resource-poor pairs exploiting similarity resource-poor language resource-rich one. precisely, build phrase-based SMT systems
translate resource-poor language X1 resource-rich language given small
bi-text X1 -Y much larger bi-text X2 -Y , X1 X2 closely related.
motivated observation related languages tend (1) similar word
order syntax, and, importantly, (2) overlapping vocabulary, e.g., casa (house)
used Spanish Portuguese; also (3) similar spelling. vocabulary overlap means resource-rich auxiliary language used source
translation options words cannot translated resources available
resource-poor language. actual text, vocabulary overlap might extend individual words short phrases (especially resource-rich languages transliterated
look like resource-poor one), means translations whole phrases could
potentially reused related languages. Moreover, vocabulary overlap
similarity word order used improve word alignments resourcepoor language biasing word alignment process additional sentence pairs
resource-rich language. take advantage opportunities: (1) improve
word alignments resource-poor language, (2) augment additional translation options, (3) take care potential spelling differences
appropriate transliteration.
apply approach IndonesianEnglish using Malay SpanishEnglish
using Portuguese Italian (and pretending Spanish resource-poor), achieving
sizable performance gains (up 3.37 BLEU points) using additional bi-texts
related resource-rich language. show approach outperforms
best rivaling approaches, using less additional data. Overall, cut amount
necessary real training data factor 25.
approach based phrase-based SMT model (Koehn, Och, & Marcu, 2003),
commonly used state-of-the-art model today. However, general ideas
easily extended SMT models, e.g., hierarchical (Chiang, 2005), treelet
(Quirk, Menezes, & Cherry, 2005), syntactic (Galley, Hopkins, Knight, & Marcu, 2004).
remainder article organized follows: Section 2 provides overview
related work, Section 3 presents motivating example several languages, Section 4
introduces proposed approach discusses various alternatives, Section 5 describes
datasets use, Section 6 explains transliterate Portuguese Italian look
like Spanish automatically, Section 7 presents experiments discusses results,
Section 8 analyses results detail, and, finally, Section 9 concludes suggests
possible directions future work.

2. Related Work
general problem formulation special case domain adaptation. Moreover,
three basic concepts central work: (1) cognates related languages,
(2) machine translation closely related languages, (3) pivoting statistical
machine translation. review previous work topics below, also
mentioning related work whenever appropriate.
181

fiNakov & Ng

2.1 Domain Adaptation
Domain adaptation (or transfer learning) problem arises situations training test data come different distributions, thus violating fundamental
assumption statistical learning theory. problem instance special case
domain adaptation, in-domain data scarce, plenty out-of-domain
data. Many efficient techniques developed domain adaptation natural language processing; see work Daume Marcu (2006), Jiang Zhai (2007a, 2007b),
Chan Ng (2005, 2006, 2007), Dahlmeier Ng (2010) examples.
Unfortunately, techniques directly applicable machine translation,
much complicated, leaves lot space variety proposed solutions.
despite limited previous work domain adaptation SMT,
focused almost exclusively adapting European parliament debates news domain
part annual competition machine translation evaluation WMT workshop.
mention proposed approaches, Hildebrand, Eck, Vogel, Waibel
(2005) use information retrieval techniques choose training samples similar
test set way adapt translation model, Ueffing, Haffari, Sarkar
(2007) adapt translation model semi-supervised manner using monolingual data
source language. Snover, Dorr, Schwartz (2008) adapt translation
language model, using comparable monolingual data target language. Nakov
Ng (2009b) adapt translation model phrase-based SMT combining phrase
tables using extra features indicating source phrase; use combination
technique part proposed approach below. Finally, Daume Jagarlamudi (2011)
address domain shift problem mining appropriate translations unseen words.
2.2 Cognates
Cognates defined pairs source-target words similar spelling (and thus likely
similar meaning), example, developpement French vs. development English. Many
researchers used likely cognates co-occurring parallel sentences training bi-text
improve word alignments ultimately build better SMT systems.
Al-Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, Yarowsky
(1999) extracted likely cognates Czech-English, using one variations
longest common subsequence ratio LCSR (Melamed, 1995) described Tiedemann
(1999) similarity measure. used cognates improve word alignments
IBM models 14 three different ways: (1) seeding parameters IBM model
1, (2) constraining word co-occurrences training IBM models 14, (3)
adding cognate pairs bi-text additional sentence pairs. last approach
performed best later used Kondrak, Marcu, Knight (2003) demonstrated improved SMT nine European languages. extended Nakov,
Nakov, Paskaleva (2007), combined LCSR sentence-level co-occurrences
bi-text competitive linking (Melamed, 2000), language-specific weights, Web
n-gram frequencies.
Unlike approaches, extract cognates source target
language, use cognates source related language
different target. Moreover, implicitly rely existence cognates;
182

fiImproving SMT Resource-Poor Language

try extract all, leave original sentence contexts.5
Note approach orthogonal kind cognate extraction original
training bi-text, thus two combined (which Section 7.7).
Another relevant line research using cognates adapt resources one language
another one. example, Hana, Feldman, Brew, Amaral (2006) adapt Spanish
resources Brazilian Portuguese train part-of-speech tagger.
Cognates cognate extraction techniques used many applications,
e.g., automatic translation lexicon induction. example, Mann Yarowsky (2001)
induce translation lexicons resource-rich language (e.g., English) resourcepoor language (e.g., Portuguese) using resource-rich bridge language closely related
latter (e.g., Spanish). use pre-existing translation lexicons sourceto-bridge mapping step (e.g., English-Spanish), string distance measures finding
cognates bridge-to-target step (e.g., Spanish-Portuguese). work extended
Schafer Yarowsky (2002), later Scherrer (2007), relies graphemic
similarity inducing bilingual lexicons Swiss German Standard German.
Koehn Knight (2002) describe several techniques inducing translation lexicons
monolingual corpora. Starting unrelated German English corpora, look
(1) identical words, (2) cognates, (3) words similar frequencies, (4) words
similar meanings, (5) words similar contexts. bootstrapping process,
new translation pairs added lexicon iteration.
recent work automatic lexicon induction includes Haghighi, Liang,
Berg-Kirkpatrick, Klein (2008), Garera, Callison-Burch, Yarowsky (2009).
Finally, lot research string similarity applied cognate
identification: Ristad Yianilos (1998) Mann Yarowsky (2001) use minimum edit distance ratio MEDR weights learned automatically using
stochastic transducer. Tiedemann (1999) Mulloni Pekar (2006) learn automatically regular spelling changes two related languages, incorporate
similarity measures based LCSR MEDR, respectively. Kondrak (2005) proposes
formula measuring string similarity based LCSR correction addresses
general preference short words. Klementiev Roth (2006) Bergsma Kondrak (2007) propose discriminative frameworks measuring string similarity. Rappoport
Levent-Levi (2006) learn substring correspondences cognates, using string-level
substitutions framework Brill Moore (2000). Finally, Inkpen, Frunza, Kondrak
(2005) compare several orthographic similarity measures cognate extraction.
cognates typically extracted related languages, words
similar spelling unrelated languages well, e.g., Arabic, Chinese, Japanese,
Korean proper names transliterated English, uses different alphabet. See
work Oh, Choi, Isahara (2006) overview comparison different
transliteration models, well proceedings annual NEWS named entities workshop, features shared tasks transliteration mining generation (Li & Kumaran,
2010). Transliteration modeled using character-based machine translation techniques
(Matthews, 2007; Nakov & Ng, 2009a; Tiedemann & Nabende, 2009), related
character-based SMT model Vilar, Peter, Ney (2007), Tiedemann (2009).
5. However, experiments, extract cognates training transliteration system
resource-rich source language X2 resource-poor one X1 .

183

fiNakov & Ng

2.3 Machine Translation Closely Related Languages
Yet another relevant line research machine translation closely related languages, arguably simpler general SMT, thus handled using wordfor-word translation manual language-specific rules take care necessary morphological syntactic transformations. tried number language pairs
including CzechSlovak (Hajic, Hric, & Kubon, 2000), TurkishCrimean Tatar (Altintas &
Cicekli, 2002), IrishScottish Gaelic (Scannell, 2006), among others. recently,
Apertium open-source machine translation platform http://www.apertium.org/
developed, uses bilingual dictionaries manual rules translate
number related languages, including SpanishCatalan, SpanishGalician, Occitan
Catalan, Macedonian-Bulgarian. contrast, language-independent, statistical approach, different objective: translate third language X.
special case line research translation dialects
language, e.g., Cantonese Mandarin (Zhang, 1998), dialect
language standard version language, e.g., Arabic dialect
(e.g., Egyptian) Modern Standard Arabic (Bakr, Shaalan, & Ziedan, 2008; Sawaf,
2010; Salloum & Habash, 2011). again, manual rules and/or language-specific tools
typically used. case Arabic dialects, complication arises
informal status dialects, standardized used formal contexts
rather informal online communities6 social networks, chats, Twitter
SMS messages. causes mismatch domain genre.
Thus, translating Arabic dialects Modern Standard Arabic requires, among
things, normalizing informal text formal form. fact, general
problem, arises informal sources like SMS messages Tweets language
(Han & Baldwin, 2011). main focus coping spelling errors, abbreviations, slang, typically addressed using string edit distance, also taking
pronunciation account. different task, try reuse good,
formal text one language help improve SMT another language.
closely related relevant line research language adaptation normalization,
done specifically improving SMT another language. example, Marujo,
Grazina, Lus, Ling, Coheur, Trancoso (2011) described rule-based system adapting Brazilian Portuguese (BP) European Portuguese (EP), used adapt BP
English bi-texts EPEnglish. Unlike work, heavily relied language-specific
rules, approach statistical largely language-independent; importantly,
different objective: translate third language X.
2.4 Pivoting
Another relevant line research improving SMT using additional languages pivots.
Callison-Burch, Koehn, Osborne (2006) improved phrase-based SMT Spanish
French English using source-language phrase-level paraphrases extracted using
pivoting technique Bannard Callison-Burch (2005) eight additional languages
Europarl corpus (Koehn, 2005).
6. Egyptian Wikipedia one notable exception.

184

fiImproving SMT Resource-Poor Language

example, using German pivot, extracted English paraphrases parallel English-German bi-text looking English phrases aligned
German phrase: e.g., control check aligned unter controlle,
hypothesized paraphrases probability. Spanish/French paraphrases
added additional entries phrase table SpanishEnglish/FrenchEnglish
phrase-based SMT system paired English translation original Spanish/French phrase. system tuned minimum error rate training (MERT)
(Och, 2003), adding extra feature penalizing low-probability paraphrases; yielded
huge increase coverage (from 48% 90% test word types 10K training
sentence pairs used), 1.8 BLEU points absolute improvement.
Unlike kind pivoting, improve source-language lexical coverage,
augment source- target-language sides. Second, pivoting ignores
context extracting paraphrases, take account. Third, using
additional language one related source, able get increase BLEU
comparable even better pivoting achieves eight pivot languages.
negative side, approach limited requires auxiliary language
X2 related source language X1 , pivoting language Z
related X1 target language . However, need one additional parallel
corpus (for X2 -Y ), pivoting needs two: one X1 -Z one Z-Y . Finally, note
approach orthogonal pivoting, thus two combined (which
Section 7.8).
note pivoting general technique, widely used
statistical machine translation, e.g., triangulation, one wants build FrenchGerman machine translation system French-English English-German bi-text,
without access French-German bi-text. case, pivoting done
sentence-level, e.g., cascading translation systems, first translating French
English, translating English German (de Gispert & Mario, 2006; Utiyama
& Isahara, 2007) phrase-level, e.g., using phrase table composition,
done off-line (Cohn & Lapata, 2007; Wu & Wang, 2007), integrated
decoder (Bertoldi, Barbaiani, Federico, & Cattoni, 2008). also shown
pivoting outperform direct translation, e.g., translating Arabic Chinese could
work better using English pivot done directly (Habash & Hu, 2009). Moreover,
argued English might always optimal choice pivot language
(Paul, Yamamoto, Sumita, & Nakamura, 2009). Finally, pivoting techniques also
used word-level, e.g., translation lexicon induction Japanese German
using English (Tanaka, Murakami, & Ishida, 2009), improving word alignments (Filali
& Bilmes, 2005; Kumar, Och, & Macherey, 2007). Pivot languages also used
lexical adaptation (Crego, Max, & Yvon, 2010).
Overall, general pivoting techniques aim build machine translation
system new (resource-poor) language pair X-Y , assuming existence bi-texts X-Z
Z-Y auxiliary pivoting language Z, e.g., would useful translating
Malay Indonesian, pivoting English. contrast, interested
building better system translating X X Z, e.g.,
Indonesian English. assume bi-text X-Z small, one
Z-Y large, require X closely related languages.
185

fiNakov & Ng

Another related line research statistical multi-source translation, focuses
translating text given multiple source languages single target language (Och
& Ney, 2001; Schroeder, Cohn, & Koehn, 2009). situation arises small number
resource-rich languages context United Nations European Union,
could hardly expected resource-poor languages.

3. Motivating Example
Consider Article 1 Universal Declaration Human Rights:
human beings born free equal dignity rights. endowed
reason conscience act towards one another spirit
brotherhood.
let us see translated closely related Malay Indonesian
dissimilar Spanish Portuguese.
3.1 Malay Indonesian
Malay (aka Bahasa Malaysia) Indonesian (aka Bahasa Indonesia) closely related
Astronesian languages, 180 million speakers combined. Malay official
Malaysia, Singapore Brunei, Indonesian national language Indonesia.
two languages mutually intelligible great extent, differ orthography/pronunciation vocabulary.
Malay Indonesian use unified spelling system based Latin alphabet,
exhibit occasional differences orthography due diverging pronunciation, e.g.,
kerana vs. karena (because) Inggeris vs. Inggris (English) Malay Indonesian,
respectively. rarely, differences historical, e.g., wang vs. uang (money).
two languages differ substantially vocabulary, mostly loan words,
Malay typically follows English pronunciation, Indonesian tends follow
Dutch, e.g., televisyen vs. televisi, Julai vs. Juli, Jordan vs. Yordania. words
Latin origin end -y English, Malay uses -i, Indonesian uses -as, e.g.,
universiti vs. universitas, kualiti vs. kualitas.
many cognates two languages, also false
friends, words identically spelled different meanings two languages.
example, polisi means policy Malay police Indonesian. also many
partial cognates, e.g., nanti means (future tense marker) later Malay
later Indonesian. result, fluent Malay fluent Indonesian differ
substantially. Consider, example, Malay Indonesian versions Article 1
Universal Declaration Human Rights (from official website United Nations):
Malay: Semua manusia dilahirkan bebas dan samarata dari segi kemuliaan
dan hak-hak. Mereka mempunyai pemikiran dan perasaan hati dan hendaklah bertindak di antara satu sama lain dengan semangat persaudaraan.
Indonesian: Semua orang dilahirkan merdeka dan mempunyai martabat dan hak-hak yang sama. Mereka dikaruniai akal dan hati nurani dan
hendaknya bergaul satu sama lain dalam semangat persaudaraan.
186

fiImproving SMT Resource-Poor Language

Semantically, overlap substantial, native speaker Indonesian understand Malay version says, would find parts quite fluent.
example, 50% overlap individual word level (overlapping
words underlined). fact, actual vocabulary overlap much higher, e.g.,
one word Malay text exist Indonesian: samarata.
differences due use different morphological forms, e.g., hendaklah vs. hendaknya
(conscience), derivational variants hendak (want).
course, word choice translation often matter taste, thus differences necessarily required. test this, asked native speaker Indonesian
adapt Malay version Indonesian preserving many words possible.
yielded following, arguably somewhat less fluent, Indonesian version, six
words Malay version:
Indonesian (closer Malay): Semua manusia dilahirkan bebas dan mempunyai martabat dan hak-hak yang sama. Mereka mempunyai pemikiran dan
perasaan dan hendaklah bergaul satu sama lain dalam semangat persaudaraan.
Note increase average length matching phrases adapted version.
3.2 Spanish Portuguese
Spanish Portuguese also exhibit noticeable degree mutual intelligibility, differ
pronunciation, spelling, vocabulary. Unlike Malay Indonesian, however,
also differ syntactically exhibit high level spelling differences; seen
translation Article 1 Universal Declaration Human Rights:
Spanish: Todos los seres humanos nacen libres e iguales en dignidad
derechos y, dotados como estan de razon conciencia, deben comportarse fraternalmente los unos con los otros.
Portuguese: Todos os seres humanos nascem livres e iguais em dignidade
e em direitos. Dotados de razao e de consciencia, devem agir uns para com os
outros em esprito de fraternidade.
see exact word-level overlap Spanish Portuguese
quite low: 17% only. Still, see overlap level short phrases,
word level.
Spanish Portuguese share 90% vocabulary thus observed level
overlap may appear surprisingly low. reason many cognates two
languages exhibit minor spelling variations. variations stem different rules
orthography, e.g., senhor vs. senor Portuguese Spanish, also due
genuine phonological differences. example, Portuguese suffix -cao corresponds
Spanish suffix -cion, e.g., evolucao vs. evolucion. Similar systematic differences exist
verb endings like -ou vs. -o (for 3rd person singular, simple past tense), e.g., visitou vs.
visito, -ei vs. -e (for 1st person singular, simple past tense), e.g., visitei vs. visite.
also occasional differences apply particular word only, e.g., dizer vs. decir,
Mario vs. Mario, Maria vs. Mara.
187

fiNakov & Ng

Going back example, ignore spelling variations cognates
two languages, overlap jumps significantly:
Portuguese (cognates transliterated Spanish):
Todos los seres humanos nacen libres e iguales en dignidad en derechos.
Dotados de razon de conciencia, deben agir unos para con los otros en
esprito de fraternidad.
words sentence Spanish, differences official
Spanish version due different word choice translator; fact, sentence
become fluent Spanish agir unos par changed comportarse los unos con.

4. Method
examples suggest may feasible use bi-texts one language improve SMT related language, possibly suitable transliteration cognates
additional language match target spelling.
Thus, describe two general strategies improving phrase-based SMT
resource-poor language X1 target language , using bi-text X2 -Y
related resource-rich language X2 : (a) bi-text concatenation, possible repetitions
original bi-text balance, (b) phrase table combination, bi-text
used build separate phrase table, two phrase tables combined.
discuss advantages disadvantages general strategies, propose
hybrid approach combines strengths trying avoid limitations.
4.1 Concatenating Bi-texts
simply concatenate bi-texts X1 -Y X2 -Y one large bi-text use
train SMT system. offers several potential benefits.
First, yield improved word alignments sentences came X1 -Y
bi-text, e.g., since additional sentences provide new contexts rare words
bi-text, thus potentially improving alignments, turn could yield better
phrase pairs. Rare words known serve garbage collectors (Brown, Della Pietra,
Della Pietra, Goldsmith, Hajic, Mercer, & Mohanty, 1993) IBM word alignment
models. Namely, rare source word tends align many target language words rather
allowing stay unaligned align source words. problem
limited IBM word alignment models (Brown, Della Pietra, Della Pietra, & Mercer, 1993);
also exists HMM model Vogel, Ney, Tillmann (1996). See Graca, Ganchev,
Taskar (2010) detailed discussion examples garbage collector effect.
Moreover, concatenation provide new source-language side translation options, thus
increasing lexical coverage reducing number unknown words; also provide
new useful non-compositional phrases source-language side, thus yielding fluent
translation output. also offers new target-language side phrases known source phrases,
could improve fluency providing translation options language model
choose from. Finally, inappropriate phrases including words X2 exist
X1 match test-time input, inappropriate new target-language translations
still chance filtered language model.
188

fiImproving SMT Resource-Poor Language

However, simple concatenation problematic. First, concatenating small
bi-text X1 -Y much larger one X2 -Y , latter dominate word
alignment phrase extraction, thus hugely influencing lexical phrase translation
probabilities, yield poor performance. counter-acted repeating
small bi-text several times large one dominate. Second, since bitexts merged mechanically, way distinguish phrases extracted
bi-text X1 -Y coming bi-text X2 -Y . former
target language pair thus probably preferred, using latter
avoided since might contain inappropriate translations words X1 .
example, phrase pair Indonesian-English bi-text could (correctly) translate
polisi police, one Malay-English bi-text could (correctly Malay,
inappropriately Indonesian) translate policy. Malay word polisi
Indonesian word polisi false friends.
experiment combining original additional training bi-text
following three ways:
cat1: simply concatenate original additional training bi-text form
new training bi-text, use train phrase-based SMT system.
catk: concatenate k copies original one copy additional training
bi-text form new training bi-text. value k selected original
bi-text approximately matches size additional bi-text.
catk:align: concatenate k copies original one copy additional
training bi-text form new training bi-text. generate word alignments
concatenated bi-text. throw away sentence pairs alignments,
except one copy original bi-text. Thus, effectively induce word alignments
original bi-text only, using concatenated bi-text estimate
statistics them. use alignments build phrase table
original bi-text.
first second method represent simple balanced bi-text concatenation,
respectively. third method version second one, additional bi-text
used improve word alignments original bi-text, used
phrase extraction. Thus, isolates effect improved word alignments effect
improved vocabulary coverage additional training bi-text provide. cat1
catk:align basic building blocks sophisticated approach below.
4.2 Combining Phrase Tables
alternative way making use additional training bi-text resource-rich
language pair X2 -Y order train improved phrase-based SMT system X1
build separate phrase tables X1 -Y X2 -Y , (a) used together,
e.g., alternative decoding paths, (b) merged, e.g., using one extra features
indicate bi-text phrase pair came from, (c) interpolated, e.g., using simple linear
interpolation.
189

fiNakov & Ng

Building two separate phrase tables offers several advantages. First, preferable
phrase pairs extracted bi-text X1 -Y clearly distinguished (or given
higher weight linear interpolation compared to) potentially riskier ones
X2 -Y bi-text. Second, lexical phrase translation probabilities combined
principled manner. Third, using X2 -Y bi-text, much larger
X1 -Y problematic more: dominate case simple
concatenation above. Finally, bi-text merging, many additional sourceand target-language phrases, offer new translation options. negative side,
opportunity lost improve word alignments sentences X1 -Y bi-text.
experiment following three phrase table combination strategies:
Two-tables: build two separate phrase tables, one two bi-texts,
use alternative decoding paths (Birch, Osborne, & Koehn, 2007).
Interpolation: build two phrase tables, Torig Textra , original
additional bi-text, respectively, use linear interpolation combine
corresponding conditional probabilities: Pr(e|s) = Prorig (e|s) + (1 ) Prextra (e|s).
optimize value development dataset, i.e., run MERT merged
phrase tables generated using different values , choose value gives
rise phrase table achieves highest tuning BLEU score. order
reduce search space, try five values (.5, .6, .7, .8 .9), i.e.,
reduce tuning discrete set, use four conditional
probabilities phrase table.
Merge: build two separate phrase tables, Torig Textra , original
additional training bi-text, respectively. concatenate them, giving priority Torig follows: keep source-target phrase pairs Torig , adding
source-target phrase pairs Textra present Torig .
source-target phrase pair added, retain associated conditional probabilities (forward/reverse phrase translation probability, forward/reverse lexicalized
phrase translation probability) phrase penalty.7 add three
additional features entry new table: F1 , F2 , F3 . value F1
1 source-target phrase pair originated Torig , 0.5 otherwise. Similarly,
F2 =1 source-target phrase pair came Textra , F2 =0.5 otherwise.
value F3 1 source-target phrase pair Torig Textra ,
0.5 otherwise. Thus, three possible feature value combinations: (1;0.5;0.5),
(0.5;1;0.5) (1;1;1); last one used phrase pair Torig
Textra . experiment using (1) F1 only, (2) F1 F2 , (3) F1 , F2 , F3 .
set weights phrase table features, including standard five
additional three, using MERT. optimize number additional features
(one, two, three) development set, i.e., run MERT phrase tables
one, two, three extra features choose phrase table achieved
highest BLEU score tuning, suggested work Nakov (2008).
7. theory, also re-normalize probabilities since may sum one. practice,
important since log-linear phrase-based SMT model require features
probabilities all, e.g., F1 , F2 , F3 , phrase penalty probabilities.

190

fiImproving SMT Resource-Poor Language

4.3 Proposed Approach
Taking account potential advantages disadvantages two general
strategies, propose approach tries get best them, namely: (i )
improved word alignments X1 -Y , biasing word alignment process additional
sentence pairs X2 -Y , (ii ) increased lexical coverage, using additional phrase
pairs X2 -Y bi-text provide. achieved using Merge combine
phrase tables catk:align cat1. process described detail
follows:
1. Build balanced bi-text Brep , consists X1 -Y bi-text repeated k times
followed one copy X2 -Y bi-text. Generate word alignments Brep ,
truncate them, keeping word alignments one copy X1 -Y bi-text. Use
word alignments extract phrases, build phrase table Trep trunc .
2. Build bi-text Bcat simple concatenation bi-texts X1 -Y X2 -Y .
Generate word alignments Bcat , extract phrases, build phrase table Tcat .
3. Generate merged phrase table combining Trep trunc Tcat . merging gives
priority Trep trunc uses extra features indicating origin entry
combined phrase table.

5. Datasets
experiment following bi-texts monolingual English data:
Indonesian-English (in-en):
train: 28,383 sentence pairs (0.8M, 0.9M words);
dev: 2,000 sentence pairs (56.6K, 63.3K words);
test: 2,000 sentence pairs (58.2K, 65.0K words);
monolingual English en : 5.1M words.
Malay-English (ml-en):
train: 190,503 sentence pairs (5.4M, 5.8M words);
dev: 2,000 sentence pairs (59.7K, 64.5K words);
test: 2,000 sentence pairs (57.9K, 62.4K words);
monolingual English en ml : 27.9M words.
Spanish-English (es-en):
train: 1,240,518 sentence pairs (35.7M, 34.6M words);
dev: 2,000 sentence pairs (58.9K, 58.1K words);
test: 2,000 sentence pairs (56.2K, 55.5K words);
monolingual English en es:pt : 45.3M words (the pt-en it-en).
191

fiNakov & Ng

Portuguese-English (pt-en):





train: 1,230,038 sentence pairs (35.9M, 34.6M words).
dev: 2,000 sentence pairs (59.3K, 58.5K words);
test: 2,000 sentence pairs (56.5K, 55.7K words);
monolingual English en es:pt : 45.3M words (the es-en it-en).

Italian-English (it-en):





train: 1,565,885 sentence pairs (43.5M, 44.1M words);
dev: 2,000 sentence pairs (56.8K, 57.7K words);
test: 2,000 sentence pairs (57.4K, 60.3K words);
monolingual English en es:it : 45.3M words (the es-en pt-en).

lengths sentences bi-texts limited 100 tokens.
language pairs, development testing bi-text, 2,000 parallel
sentence pairs. made sure development testing bi-texts shared sentences training bi-texts; excluded monolingual English data
sentences English sides development testing bi-texts.
training bi-text datasets es-en, pt-en, it-en built v.3
Europarl corpus, excluding Q4/2000 portion data (2000-10 2000-12),
created testing development datasets.
built in-en bi-texts comparable texts downloaded Web.
translated Indonesian texts English using Google Translate, matched8
English texts using cosine similarity measure heuristic constraints
based document length words sentences, overlap numbers, words uppercase, words title. Next, extracted pairs sentences matched
document pairs using competitive linking (Melamed, 2000), retained ones whose
similarity pre-specified threshold. ml-en bi-text built similarly.
pairs languages, monolingual English text training language model
consists English side corresponding bi-text plus additional English text
source.
Note monolingual data training English language model
Spanish, Portuguese, Italian since es-en, pt-en, it-en
origin: fact, exceptions, sentences bi-texts aligned
English make es-en-pt-it four-text, since translations (from English
languages) original parliamentary debates. Thus, English side
es-en, pt-en, it-en, unaligned English sentences distribution.
case, however, Malay Indonesian, come different
sources different topics discuss issues Malaysia Indonesia, respectively. particular, differ lot use named entities: names persons,
locations, organizations talk about. separate monolingual texts train English language models ml-en in-en; see below,
indeed yield different performance SMT.
8. Note automatic translations used matching only; final bi-text contained automatic translations.

192

fiImproving SMT Resource-Poor Language

6. Transliteration
mentioned above, approach relies existence large number cognates related languages. linguists define cognates words derived
common root9 (Bickford & Tuggy, 2002), computational linguists typically ignore origin,
defining words different languages mutual translations similar orthography (Melamed, 1999; Mann & Yarowsky, 2001; Bergsma & Kondrak, 2007).
adopt latter definition.
seen Section 3, transliteration helpful languages like
Spanish Portuguese, many regular spelling differences. Thus, build
system automatic transliteration Portuguese Spanish, train list
automatically extracted pairs likely cognates. apply system Portuguese
side pt-en training bi-text.
Classic approaches automatic cognate extraction look non-stopwords similar
spelling appear parallel sentences bi-text (Kondrak et al., 2003). case,
however, need extract cognates Spanish Portuguese given pt-en
es-en bi-texts only, i.e., without pt-es bi-text. Although easy construct
pt-es bi-text Europarl corpus, chose since, general, synthesizing
bi-text X1 -X2 would impossible: e.g., cannot done ml-in given training
datasets in-en ml-en since English sides sentences common.
Thus, extracted list likely cognates Portuguese Spanish
training pt-en es-en bi-texts using English pivot follows: started
IBM model 4 word alignments, extracted four conditional lexical translation
probabilities: Pr(pj |ei ) Pr(ei |pj ) Portuguese-English, Pr(sk |ei ) Pr(ei |sk )
Spanish-English, pj , ei , sk stand Portuguese, English Spanish
word, respectively. Following Wu Wang (2007), induced conditional lexical
translation probabilities Pr(pj |sk ) Pr(sk |pj ) Portuguese-Spanish follows:
Pr(pj |sk ) =

Pr(pj |ei , sk ) Pr(ei |sk )

P

Assuming pj conditionally independent sk given ei , simplify this:
Pr(pj |sk ) =

Pr(pj |ei ) Pr(ei |sk )

P

Similarly, Pr(sk |pj ), obtain
Pr(sk |pj ) =

Pr(sk |ei ) Pr(ei |pj )

P

excluded stopwords, words length less three, containing digits.
calculated Prod(pj , sk ) = Pr(pj |sk ) Pr(sk |pj ), excluded PortugueseSpanish word pairs (pj , sk ) Prod(pj , sk ) < 0.01. value 0.01
previously suggested filtering phrase pairs obtained using pivoting (Callison-Burch, 2008,
2012; Denkowski & Lavie, 2010; Denkowski, 2012). remaining pairs, extracted
likely cognates based Prod(pj , sk ) orthographic similarity pj sk .
Following Melamed (1995), measured orthographic similarity using longest
common subsequence ratio (lcsr), defined follows:
9. E.g., Latin tu, Old English thou, Greek su, German du cognates meaning 2nd person singular.

193

fiNakov & Ng

lcsr(s1 , s2 ) =

|LCS(s1 ,s2 )|
max(|s1 |,|s2 |)

lcs(s1 , s2 ) longest common subsequence s1 s2 , |s| length s.
retained likely cognates pairs lcsr 0.58 higher; value
found Kondrak et al. (2003) optimal number language pairs
Europarl corpus.
Finally, performed competitive linking (Melamed, 2000), assuming Portuguese wordform one Spanish best cognate match. Thus, using values
Prod(pj , sk ), induced fully-connected weighted bipartite graph. Then, performed
greedy approximation maximum weighted bipartite matching graph, i.e.,
competitive linking, follows: First, accepted cognates cross-lingual pair (pj , sk )
highest Prod(pj , sk ) graph, discarded words pj sk consideration. Then, accepted next highest-scored pair, discarded
involved wordforms forth. process repeated matchable
word pairs left.
Note cognate extraction algorithm three components: (1) orthographic,
based lcsr, (2) semantic, based pivoting English, (3) competitive linking.
semantic component important makes extraction false friends
unlikely. Consider example Spanish-Portuguese word pairs largo largo
largo longo. latter pair true cognates, former pair false
friends since largo means long Spanish wide Portuguese. word largo appears
8,489 times es-en bi-text 432 times pt-en bi-text. However,
different meanings, get aligned English word high probability,
results low scores conditional probabilities: Pr(pj |sk ) = 0.000464
Pr(sk |pj ) = 0.009148; thus, Prod(pj , sk ) = 0.000004, 0.01 threshold.
result, false friend pair largo largo get extracted. contrast,
true cognate pair largo longo get extracted corresponding conditional
probabilities 0.151354 0.122656, respectively, product 0.018564,
0.01 (moreover, lcsr = 0.6, 0.58 threshold).
competitive linking component helps prevent issues related word inflection
cannot handled using pivoting alone. example, word green Spanish
Portuguese two forms: verde singular, verdes plural. Without competitive linking, would extract verde verde (Prod(pj , sk ) = 0.353662)
verdes verdes (Prod(pj , sk ) = 0.337979), also incorrect word pairs verde verdes
(Prod(pj , sk ) = 0.109792) verdes verde (Prod(pj , sk ) = 0.106088). Competitive linking, however, prevents asserting Portuguese Spanish word
one true cognate, effectively eliminates wrong pairs.
Thus, taken together, semantic component competitive linking make extraction false friends unlikely. Still, occasionally, get wrong alignments
intrusa intrusas, singular form matched plural form,
occurs mostly case rare words like intrusa (intruder, feminine) whose alignments
tend unreliable, inflected forms available competitive
linking choose from.
Note described transliteration system focusing precision less
recall. extracted likely cognate pairs going used train
194

fiImproving SMT Resource-Poor Language

SMT-based transliteration system. system translation component,
able generate many options, target language model component,
would help filter options. translation component tend generate
good options, thus needs trained primarily instances systematic, regular
differences, evolucao evolucion, suffix change -cao -cion
learned. Occasional differences dizer decir cannot generalized thus
less useful (they also less frequent, thus missing arguably
important), simply memorized model whole words still used.
also note focus precision cognate pair extraction mean
going extract primarily cognate pairs spelling differences.
explained above, spelling one component cognate pair extraction approach;
also semantic competitive linking component, could eliminate many
candidates close spelling prefer others dissimilarities (recall correct
choice largo longo wrong largo largo).
Note generality transliteration approach necessarily compromised
fact LCSR requires languages use writing system. example, Cyrillic-written Serbian Roman-written Croatian still compared using
LCSR, initial letter-by-letter mapping Cyrillic Roman alphabets, generally straightforward. course, even using alphabet,
languages different orthographical conventions, might make look
divergent actual phonetics would suggest, e.g., compare qui/chi, gui/ghi,
glio/llo Spanish Italian. Even though LCSR Italian-Spanish cognates
chi qui lower threshold 0.58, correspondence strings
still learned longer cognates, e.g., macchina maquina. would
allow transliteration system convert chi qui word.
Going back actual experiments, result cognate extraction procedure,
ended 28,725 Portuguese-Spanish cognate pairs, 9,201 (or 32.03%)
spelling differences. pair list cognate pairs, added spaces
two adjacent letters wordforms, appended start end
characters ^ $. example, cognate pair evolucao evolucion became
^ e v l u c $ ^ e v l u c n $
randomly split resulting list training (26,725 pairs) development
dataset (2,000 pairs), trained tuned character-level phrase-based monotone
SMT system similar Finch Sumita (2008) transliterate Portuguese wordform
Spanish wordform. used Spanish language model trained 14M word tokens
(obtained above-mentioned 45.3M-token monolingual English corpus excluding punctuation, stopwords, words length less three, containing digits):
one per line character-separated added start end characters
example. set maximum phrase length language model order ten;
found values tuning development dataset. tuned system using
MERT, saved feature weights. tuning BLEU 95.22%, baseline
BLEU, leaving Portuguese words intact, 87.63%.
195

fiNakov & Ng

Finally, merged training tuning datasets retrained. used
resulting system saved feature weights transliterate Portuguese side
training pt-en bi-text, yielded new ptes -en training bi-text.
repeated procedure Italian-English. extracted 25,107 ItalianSpanish cognate pairs, 14,651 (or 58.35%) spelling differences. Then,
split list training (23,107 pairs) development dataset (2,000 pairs),
trained character-level phrase-based monotone SMT system Spanish-English;
tuning BLEU 94.92%. used resulting system transliterate Italian
side training it-en bi-text, thus obtaining new ites -en training bi-text.
also applied transliteration Malay Indonesian, even though knew
spelling differences two languages rare. extracted 5,847 likely
cognate pairs, 844 (or 14.43%) spelling differences, used train
transliteration system. highest tuning BLEU 95.18% (for maximum phrase size
LM order 10), baseline 93.15%. re-trained system
combination training development datasets, transliterated Malay
side training ml-en bi-text, yielded new mlin -en training bi-text.

7. Experiments Evaluation
describe baseline system, perform various experiments assess
similarity original (Indonesian Spanish) auxiliary languages
(Malay Portuguese). improve IndonesianEnglish SpanishEnglish SMT
using Malay Portuguese, respectively, auxiliary languages.
also take closer look improving SpanishEnglish SMT, performing number
additional experiments. First, try using additional language dissimilar
Spanish, substituting Portuguese Italian. Second, experiment two auxiliary
languages simultaneously: Portuguese Italian. Finally, combine method
two orthogonal rivaling approaches: (1) using cognates source target
language (Kondrak et al., 2003), (2) source-language side paraphrasing pivot
language (Callison-Burch et al., 2006).
7.1 Baseline SMT System
baseline, used following setup: first tokenized lowercased sides
training bi-text. built separate directed word alignments EnglishX
XEnglish (X{Indonesian, Spanish}) using IBM model 4 (Brown, Della Pietra, Della
Pietra, & Mercer, 1993), combined using intersect+grow heuristic (Koehn
et al., 2007), extracted phrase pairs maximum length seven. thus obtained
phrase table phrase pair associated five standard parameters:
forward reverse phrase translation probabilities, forward reverse lexical translation probabilities, phrase penalty. trained log-linear model using standard
SMT feature functions: trigram language model probability, word penalty, distance-based10
distortion cost, parameters phrase table.
10. also tried lexicalized reordering (Koehn, Axelrod, Mayne, Callison-Burch, Osborne, & Talbot, 2005).
yielded higher absolute BLEU scores, relative improvement sample experiments
similar achieved distance-based re-ordering.

196

fiImproving SMT Resource-Poor Language

set weights optimizing BLEU (Papineni, Roukos, Ward, & Zhu, 2002) using
MERT separate development set 2,000 sentences (Indonesian Spanish),
used beam search decoder (Koehn et al., 2007) translate 2,000 test sentences
(Indonesian Spanish) English. Finally, detokenized output, evaluated
lowercased gold standard using BLEU.
7.2 Cross-lingual Translation Experiments
#
1
2
3
4
5
6

Train
ml-en
mlin -en
ml-en
ml-en
ml-en
mlin -en

Dev
ml-en
ml-en
ml-en
in-en
in-en
in-en

Test
ml-en
ml-en
in-en
in-en
in-en
in-en

LM
enml
enml
enml
enml
enin
enin

10K
44.93
38.99
13.69
13.98
15.56
16.44

20K
46.98
40.96
14.58
14.75
16.38
17.36

40K
47.15
41.02
14.76
14.91
16.52
17.62

80K
48.04
41.88
15.12
15.51
17.04
18.14

160K
49.01
42.81
15.84
16.27
17.90
19.15

Table 1: Malay-Indonesian cross-lingual SMT experiments: training Malay
testing Indonesian different number training ml-en sentence pairs. Columns 2-5 present bi-texts used training, development,
testing, monolingual data used train English language model.
following columns show resulting BLEU (in %) different numbers mlen training sentence pairs. Lines 1-2 show results training, tuning,
testing Malay, followed lines 3-6 results training Malay testing
Indonesian. mlin stands Malay transliterated Indonesian, enml
enin refer English side ml-en in-en bi-text, respectively.

Here, study similarity original auxiliary languages.
First, measured vocabulary overlap original auxiliary languages. Spanish Portuguese, feasible since training pt-en es-en
bi-texts time span Europarl corpus English sides largely
overlap. found 110,053 Portuguese 121,444 Spanish word types pt-en esen bi-texts, respectively, 44,461 identical, means 40.40%
Spanish word types present Portuguese side pt-en bi-text. Unfortunately,
could directly measure vocabulary overlap Malay Indonesian
way since English sides in-en ml-en bi-texts overlap content.
Second, following general experimental setup baseline system, performed
cross-lingual experiments, training one language pair testing another one,
order assess cross-lingual similarity Indonesian-Malay Spanish-Portuguese,
potential combining corresponding training bi-texts. results shown
Tables 1 2. see, cross-lingual evaluation training ml-en (pt-en)
instead in-en (es-en), testing (es) text yielded huge decrease BLEU
compared baseline: three times (for Malay) five times (for Spanish) even
large training datasets, even proper English LM development dataset
used: compare line 1 lines 3-5 Table 1, line 1 lines 3-4 Table 2.
197

fiNakov & Ng

#
1
2
3
4
5
6
7

Train
pt-en
ptes -en
pt-en
pt-en
ptes -en
es-en
es-en

Dev
pt-en
pt-en
pt-en
es-en
es-en
es-en
es-en

Test
pt-en
pt-en
es-en
es-en
es-en
es-en
pt-en

LM
enes:pt
enes:pt
enes:pt
enes:pt
enes:pt
enes:pt
enes:pt

10K
21.28
10.91
4.40
4.91
8.18
22.87
2.99

20K
23.11
11.56
4.77
5.12
9.03
24.71
3.14

40K 80K
24.43 25.72
12.16 12.50
4.57 5.02
5.64 5.82
9.97 10.66
25.80 27.08
3.33 3.54

160K
26.43
12.83
4.99
6.35
11.35
27.90
3.37

320K
27.10
13.27
5.32
6.87
12.26
28.46
3.94

640K 1.23M
27.78 27.96
13.48 13.71
5.08
5.34
6.44
7.10
12.69 13.79
29.51 29.90
4.18
3.99

Table 2: Portuguese-Spanish cross-lingual SMT experiments: training Portuguese testing Spanish different number training pt-en
sentence pairs. Lines 1-2 show results training, tuning, testing
Portuguese, lines 3-5 training Portuguese testing Spanish,
lines 6-7 training Spanish testing Spanish Portuguese.
Columns 2-5 present bi-texts used training, development, testing,
monolingual data used train English language model. following
columns show resulting BLEU (in %) different numbers training sentence pairs. ptes stands Portuguese transliterated Spanish. English
LMs pt-en es-en (marked enes:pt ).

Portuguese-Spanish, show results direction, training
Spanish testing Portuguese: compare line 6 line 7 Table 2. results show
comparable, slightly larger, drop BLEU direction. carry reverse
direction experiments Malay-Indonesian since enough parallel in-en data.
Third, experimented transliteration changing Malay look like Indonesian
Portuguese look like Spanish. caused BLEU score double Spanish
(compare line 5 lines 3-4 Table 2, improved far less Indonesian (compare line 6
lines 3-5 Table 1). Training transliterated data testing Malay/Portuguese
yielded 10% relative decrease Malay 50% Portuguese11 : compare line 1
line 2 Tables 1 2. Thus, unlike Spanish Portuguese, found far less systematic
spelling variations Malay Indonesian. closer inspection confirmed this: many
extracted likely Malay-Indonesian cognate pairs spelling differences fact forms
word existing languages, e.g., kata berkata (to say).
One interesting result Table 1 switching language model trained enml
one trained enin yields significant improvements (compare lines 4 5 Table 1).
may appear striking since former monolingual English text five times
bigger latter one, yet, smaller language model yields better results.
due partial domain shift, especially, respect named entities: even though
texts English domain, discuss events different countries,
involve country-specific cities, companies, political parties leaders; good
language model able prefer good English translations named entities.
11. Interestingly, lines 2 5 Table 2 show, system trained 1.23M transliterated ptes -en sentence
pairs performs equally well translating Portuguese Spanish input text: 13.71% vs. 13.79%.

198

fiImproving SMT Resource-Poor Language

7.3 Improving IndonesianEnglish SMT using Malay

Figure 1: Impact k BLEU catk different number extra ml-en
sentence pairs IndonesianEnglish SMT. Shown BLEU scores
different numbers k = 1,2,. . .,16 repetitions in-en concatenated
10000n pairs ml-en, n {1,2,4,8,16}.

First, study impact k catk. IndonesianEnglish SMT using Malay
additional language. tried values k 1k16 10000n extra
ml-en sentence pairs, n{1,2,4,8,16}. see Figure 1, highest BLEU scores
achieved (n; k){(1;2),(2;2),(4;4),(8;7),(16;16)}, i.e., k n. Thus, order
limit search space, used relationship k n experiments (also
Portuguese Spanish). note lot fluctuation results
Figure 1, probably due small sizes training corpora. Given
fluctuation, results over-interpreted, e.g., may chance
peaks different curves right places. Still, overall tendency
visible: need keep balance original auxiliary bi-texts.
Tables 3 4 show results experiments improving IndonesianEnglish SMT
using 10K, 20K, . . ., 160K additional pairs ml-en parallel sentences. Table 3 compares
performance approach baseline three concatenation methods described Section 4.1: cat1, catk, catk:align, Table 4 compares
performance approach various alternative ways combining two phrase tables, namely, using alternative decoding paths, phrase table interpolation, phrase table
merging, introduced Section 4.2.
199

fiNakov & Ng

in-en
28.4K
28.4K
28.4K
28.4K
28.4K

ml-en
10K
20K
40K
80K
160K

Baseline
23.80<
23.80<
23.80<
23.80<
23.80<

cat1
24.29<
24.37<
24.38
24.17<

24.43<

catk
24.29<
(1)

24.48(2)

24.54(4)

24.65<
(8)
<
25.00(16)

catk:align
24.01<
(1)
<
24.35<
(2)
<
24.39<
(4)
24.18<
(8)

24.27<
(16)

approach
24.51(2;1) (+0.72)
<
24.70(2;2) (+0.90)
<
24.73(4;2) (+0.93)
<
24.97(8;3) (+1.17)
<
25.15(16;3) (+1.35)
<

Table 3: Improving IndonesianEnglish SMT using different numbers additional Malay-English sentence pairs (varying amount additional
data): concatenations, repetitions, truncations, approach.
baseline 28,383 in-en sentence pairs only. Shown BLEU scores (in %)
different approaches. subscript shows best parameter value(s) found
development set used test set produce given result: first
value number repetitions original bi-text second value,
any, number extra features added phrase table. BLEU
scores statistically significantly better baseline/our approach
marked left/right side < (for p < 0.01) (for p < 0.05).

in-en
28.4K
28.4K
28.4K
28.4K
28.4K

ml-en
10K
20K
40K
80K
160K

Baseline
23.80<
23.80<
23.80<
23.80<
23.80<

Two Tables

23.79<
24.24<
24.27<
24.11<
<
24.58<

Interpolation
23.89<
(.9)
24.22<
(.8)
24.27<
(.8)

24.46<
(.8)
<
24.58<
(.8)

Merge
23.97<
(3)

24.46<
(3)
24.43
(3)
<
24.67(3)
<
24.79
(3)

approach
24.51(2;1) (+0.72)
<
24.70(2;2) (+0.90)
<
24.73(4;2) (+0.93)
<
24.97(8;3) (+1.17)
<
25.15(16;3) (+1.35)
<

Table 4: Improving IndonesianEnglish SMT using different numbers additional Malay-English sentence pairs (varying amount additional
data): comparing approach various alternatives. baseline
28,383 in-en sentence pairs only. Shown BLEU scores (in %) different approaches. subscript shows best parameter value(s) found
development set used test set produce given result: merging
methods, first value number repetitions original bi-text
second value, any, number extra features added phrase table;
interpolation, show weight phrase pairs in-en. BLEU
scores statistically significantly better baseline/our approach
marked left/right side < (for p < 0.01) (for p < 0.05).

Several interesting general observations Tables 3 4 made. First,
using additional Indonesian-English sentences yields better results. Second, one
exception, experiments yield improvements baseline. Third, improvements
always statistically significant approach, according Collins, Koehn,
Kucerovas (2005) sign test.
200

fiImproving SMT Resource-Poor Language

Overall, among different bi-text combination strategies, approach performs
best, followed catk, merge, interpolation, close performance;
three strategies ones consistently yield higher BLEU number
additional ml-en sentence pairs grows. Methods like cat1, catk:align, two-tables
somewhat inconsistent respect. latter method performs worst
one go baseline (for 10K ml-en sentence pairs).
One possible reason relatively bad performance two-tables could
tune weights compared models: phrase table
feature weights, means five additional features. well known MERT cannot
handle many features (Chiang, Knight, & Wang, 2009; Hopkins & May, 2011),
believe case takes 3035 iterations finish, methods
normally need 78 iterations. closer look MERT revealed two issues: (1)
n-best list many identical translations, i.e., spurious ambiguity became even
bigger problem. (2) MERT, identical translations different feature values,
could confused optimization. believe problems caused fact
often two identical translations would found use phrases
different tables thus different scores.
Note also high values interpolation parameter Table 4: 0.80.9.
indicate original bi-text needs weighted higher auxiliary one, thus
supporting need balanced concatenations repetitions original bi-text,
indirectly explaining catk performs better cat1 Table 3.
7.4 Improving SpanishEnglish SMT using Portuguese
Next, experiment using Portuguese improve SpanishEnglish SMT.
results shown Tables 5 6. Overall, consistent
IndonesianEnglish SMT using additional Malay-English bi-text (shown Tables 3
4 above). observe that, size original bi-text increases,
gain BLEU decreases, expected. Note also transliteration
important: doubles absolute gain BLEU achieved method.
Table 7 compares performance technique 160K vs. 1.23M additional
pt-en parallel sentence pairs, without transliteration training bi-texts
different numbers parallel es-en sentence pairs (10K, 20K, . . ., 320K). table shows
importance transliteration, responsible half improvement
baseline brought method. fact, small original es-en bi-texts (10K,
20K, 40K), using 160K transliterated additional pt-en sentence pairs works better
using 1.23M additional non-transliterated pt-en sentence pairs (which eight times bigger).
example, given 10K original training es-en sentence pairs, going 160K 1.23M
additional pt-en sentence pairs improves BLEU 0.25% (from 23.98% 24.23%),
using 160K transliterated pt-en data yields improvement 1.75% (from 23.98%
25.73%). impact transliteration surprising: already seen
Table 2, where, comparing lines 4 5, see transliterating Portuguese
look like Spanish effectively doubles BLEU score: 4.91% 8.18% 10K,
7.10% 13.79% 1.23M parallel training sentence pairs.
201

fiNakov & Ng

es-en pt-en Translit.
10K 160K

yes
20K 160K

yes
40K 160K

yes
80K 160K

yes
160K 160K

yes

Baseline
22.87<
22.87<
24.71<
24.71<
25.80<
25.80<
27.08
27.08<
27.90
27.90

cat1
23.54<
<
25.26
<
25.19<
<
26.16
26.24<
<
26.78
27.23
27.26<
27.83<

28.14
<

catk
23.83<
(16)
<
25.42(16)
<
25.29<
(8)
<
26.18
(8)
25.92<
(4)
<
26.93(4)
27.09<
(2)

27.53(2)
27.83<
(1)

28.14(1)
<

catk:align
22.93<
(16)
<
23.31<
(16)
24.91<
(8)
24.88<
(8)
25.99<
(4)
25.88<
(4)
27.01<
(2)
27.09<
(2)
27.94(1)
28.06(1)

method
23.98(16;3) (+1.11)
<
25.73(16;3) (+2.86)
<
25.65(8;2) (+0.94)
<
26.36(8;3) (+1.65)
<
26.49(4;2) (+0.69)
<
26.95(4;3) (+1.15)

27.30(2;2) (+0.22)
<
27.49(2;3) (+0.41)
28.05(1;3) (+0.15)
28.16(1;2) (+0.26)

<

Table 5: Improving SpanishEnglish SMT using 160K additional PortugueseEnglish sentence pairs (varying amount original data): concatenations, repetitions, truncations, method. first column contains
number original (es-en) sentence pairs. Column 3 shows whether transliteration used; following columns list BLEU scores (in %) different
methods. subscript shows best parameter value(s) found development set used test set produce given result: first value
number repetitions original bi-text second value, any,
number extra features added phrase table. BLEU scores
statistically significantly better baseline/our method marked
left/right side < (for p < 0.01) (for p < 0.05).

Note impact transliteration diminishes size es-en bi-text grows.
surprising: size good original es-en bi-text grows,
less less learned additional pt-en bi-text, regardless whether
without transliteration.
7.5 Improving SpanishEnglish SMT Using Italian
Here, experiment Italian auxiliary language improving SpanishEnglish
phrase-based SMT. Figure 2 shows results using Italian Portuguese auxiliary languages method transliteration. see major consistent drop
BLEU score using Italian instead Portuguese. example, 10K es-en sentence
pairs 160K additional pt-en/it-en sentence pairs, absolute drop BLEU
0.9%: 25.73% vs. 24.82%, respectively. Moreover, 160K original es-en
sentence pairs, method goes slightly baseline (by -0.05) using it-en
small improvement (by +0.26) pt-en.
Still, Figure 2 shows Italian, dissimilar Spanish Portuguese,
useful auxiliary language smaller sizes original es-en training bi-text. Thus,
conclude degree similarity auxiliary source
language matter, dissimilar languages still potentially useful auxiliary
languages.
202

fiImproving SMT Resource-Poor Language

es-en pt-en Translit.
10K 160K

yes
20K 160K
40K 160K
80K 160K
160K 160K


yes

yes

yes

yes

Baseline
22.87<
22.87<
24.71<
24.71<
25.80<
25.80<
27.08
27.08<
27.90
27.90

Two tables
<
23.81
<
25.29
<

25.22
<
26.07
25.96<
<
26.68

26.89<
27.20<
27.99
28.11

Interpol.
<
23.73(.5)
<
25.22<
(.5)


25.02<
(.5)
<
26.07(.7)
26.15<
(.6)
<
26.43(.7)
27.04<
(.8)
27.42(.5)
27.72(.5)

28.13(.6)

Merge
23.60(2)
<
25.16<
(2)

method
23.98(16;3) (+1.11)
<
25.73(16;3) (+2.86)

<

<

25.32
(3)
<
26.04<
(3)
25.99<
(3)
<
26.64(3)
27.02<
(3)
27.29
(3)
27.95(2)

28.17(2)

<

<

25.65(8;2) (+0.94)
26.36(8;3) (+1.65)
<
26.49(4;2) (+0.69)
<
26.95(4;3) (+1.15)

27.30(2;2) (+0.22)
<
27.49(2;3) (+0.41)
28.05(1;3) (+0.15)
28.16(1;2) (+0.26)
<

Table 6: Improving SpanishEnglish SMT using 160K additional PortugueseEnglish sentence pairs (varying amount original data): comparing
method various alternatives. first column contains number
original (es-en) sentence pairs. Column 3 shows whether transliteration
used; following columns list BLEU scores (in %) different methods.
subscript shows best parameter value(s) found development set
used test set produce given result: merging methods, first
value number repetitions original bi-text second value,
any, number extra features added phrase table; interpolation,
show weight phrase pairs in-en. BLEU scores
statistically significantly better baseline/our method marked
left/right side < (for p < 0.01) (for p < 0.05).

7.6 Improving SpanishEnglish SMT Using Portuguese Italian
seen Portuguese Italian useful auxiliary languages,
tried use together. experiments carried way
used single auxiliary language, except double usual number
repetitions k original bi-text auxiliary bi-texts dominate
catk:align. example, 10K original es-en training sentence pairs 160K
auxiliary pt-en 160K it-en sentence pairs, need include 32 copies original
bi-text instead 16, before.
results combination shown Figure 2. Comparing results
using pt-en data only, see small consistent improvement.
example, 10K original es-en sentence pairs, 160K additional pt-en 160K additional
it-en sentence pairs, absolute increase BLEU scores 0.18%: 25.73%
25.91%. size absolute improvement using 20K, 40K, 80K, 160K
additional pt-en it-en sentence pairs comparable: 0.10-0.20% average.
Thus, potential gains using multiple auxiliary languages simultaneously.
203

fiNakov & Ng

System
baseline
method: 160K pt-en pairs
improvement
method: 1.23M pt-en pairs
improvement
method: 160K pt-en, translit.
improvement
method: 1.23M pt-en, translit.
improvement

10K
22.87
23.98
+1.11
24.23
+1.36
25.73
+2.86
26.24
+3.37

20K
24.71
25.65
+0.94
25.70
+0.99
26.36
+1.65
26.82
+2.11

40K
25.80
26.49
+0.69
26.78
+0.98
26.95
+1.15
27.47
+1.67

80K
27.08
27.30
+0.22
27.49
+0.41
27.49
+0.41
27.85
+0.77

160K
27.90
28.05
+0.15
28.22
+0.32
28.16
+0.26
28.50
+0.60

320K
28.46
28.52
+0.06
28.58
+0.12
28.43
-0.03
28.70
+0.24

Table 7: SpanishEnglish: testing method using 160K vs. 1.23M additional
pt-en sentence pairs, without transliteration. Shown BLEU
scores (in %) absolute improvement baseline training bi-texts
different numbers parallel es-en sentence pairs (10K, 20K, . . ., 320K)
fixed number additional pt-en sentence pairs: 160K 1.23M. statistically
significant improvements baseline marked (for p < 0.01)
(for p < 0.05).

7.7 Combining Method Cognate Extraction Technique
Kondrak et al. (2003)
Next, combined method cognate extraction technique Kondrak et al.
(2003), pairs likely cognates extracted original training bi-text
added bi-text additional 1-word-to-1-word sentence pairs.
System
baseline
cognates
improvement (baseline)
(1.23M pt-en pt-en) + cognates
improvement (baseline)
improvement (our: 1.23M pt-en)
(1.23M pt-en, transl.) + cognates
improvement (baseline)
improvement (our: 1.23M, transl.)

10K
22.87
23.50
+0.63
24.55
+1.68
+0.32
26.35
+3.48
+0.11

20K
24.71
25.22
+0.51
25.98
+1.27
+0.28
26.78
+2.07
-0.04

40K
25.80
26.31
+0.51
26.73
+0.93
-0.05
27.34
+1.54
-0.13

80K
27.08
27.38
+0.30
27.67
+0.59
+0.18
27.79
+0.71
-0.06

160K
27.90
28.10
+0.20
28.33
+0.43
+0.11
28.50
+0.60
+0.00

320K
28.46
28.74
+0.28
28.90
+0.44
+0.32
28.68
+0.22
-0.02

Table 8: SpanishEnglish: combining method cognate extraction
technique Kondrak et al. (2003). Shown BLEU scores (in %)
absolute improvements (over baseline method) training bitexts different numbers parallel es-en sentence pairs (10K, 20K, . . ., 320K)
fixed number additional pt-en sentence pairs (1.23M), without
transliteration. statistically significant improvements marked (for
p < 0.01) (for p < 0.05).

204

fiImproving SMT Resource-Poor Language

28.5

27.5

26.5

25.5

baseline
+it-en
+pt-en
+it-en +pt-en

24.5

23.5

22.5
10K

20K

40K

80K

160K

Figure 2: Improving SpanishEnglish SMT using 160K Italian-English
160K Portuguese-English additional sentence pairs (varying
amount original data) transliteration.

results adding cognates training es-en bi-text, i.e., reimplementation algorithm, shown top lines Table 8. see
absolute improvement 0.5% BLEU es-en size 40K, improvement
statistically significant.
Next, combined method cognate extraction method follows: first,
augmented original es-en bi-text cognate pairs, used augmented
bi-text instead es-en method. Table 8 shows results combination
method cognate extraction (BLEU scores % absolute improvements
baseline method) training bi-texts different numbers parallel
es-en sentence pairs (10K, 20K, . . ., 320K) fixed number additional pt-en sentence
pairs (1.23M), without transliteration. see, worth combining
method cognate extraction technique Kondrak et al. (2003) small original
es-en datasets, e.g., 10K 20K (in cases statistically significant improvements occur
using method only), method use transliteration.
205

fiNakov & Ng

found interesting combining method cognate extraction technique Kondrak et al. (2003) help much used transliteration compared
use it. Thus, analyzed case 10K es-en sentence pairs
1.23M pt-en pairs. cognate extraction technique yielded 25,362 Spanish-English
likely cognate pairs, including 10,611 unique Spanish words. Portuguese side
1.23M pt-en data contained 14 0.13% 10,611 unique Spanish words. Thus,
information Spanish-English likely cognates provide word alignments
phrase pairs clearly complementary pt-en bi-text gives. However,
transliteration, source side 1.23M ptes -en bi-text contained 8,867 83.56%
10,611 unique Spanish words Spanish-English likely cognate pairs. drastic
jump means Spanish-English likely cognate pairs little add top
ptes -en already provides, explains lack improvement combined
method transliteration used.
7.8 Combining Method Phrase Table Pivoting Technique
Callison-Burch et al. (2006)
Finally, combined method phrase table pivoting technique Callison-Burch
et al. (2006) since orthogonal.
First, tried reproduce phrase table pivoting experiments Callison-Burch
et al. (2006), turned complicated (even though used original
code pivoting) various differences experimental setups: (1)
used Moses instead Pharaoh translation; (2) used IRSTLM instead SRILM
language modeling; (3) used different tokenization; (4) used maximum phrase
length seven instead ten; (5) created training/dev/test dataset
Europarl v.3, different version Europarl corpus available
2006 (which also implies different baseline, etc.).
results shown Table 9. bottom three lines show results reported
Callison-Burch et al. (2006), top three lines report BLEU scores
reproduction experiments, 1.3M pairs used eight
additional pivot languages: Danish, Dutch, Finnish, French, German, Italian, Portuguese,
Swedish. BLEU scores lower, good enough studying
potential combining two methods.
combination carried following way: built final merged
phrase table method, paraphrased source side pivoting using
method Callison-Burch et al. (2006). middle lines table show BLEU
scores (in %) combined method absolute improvements (over baseline
method) training bi-texts different numbers parallel es-en sentence pairs
(10K, 20K, . . ., 320K) fixed amount additional pt-en pairs (160K 1.23M pairs),
without transliteration.
results show worth combining method phrase table pivoting
small es-en datasets, e.g., 10K 20K (in cases, statistically significant improvements
occur using method only), method use transliteration,
case cognate extraction technique Kondrak et al. (2003).
206

fiImproving SMT Resource-Poor Language

Experiments
baseline
Pivoting (+8 pairs 1.3M)
improvement (baseline)
(160K pt-en) + pivoting
improvement (over baseline)
improvement (over method)
(1.23M pt-en) + pivoting
improvement (over baseline)
improvement (over method)
(160K pt-en, transl.) + pivoting
improvement (over baseline)
improvement (over method)
(1.23M pt-en, transl.) + pivoting
improvement (over baseline)
improvement (over method)
Callison-Burch et al. (2006)
baseline
Pivoting (+8 pairs 1.3M)
improvement (over baseline)

10K
22.87
23.33
+0.46
24.32
+1.45
+0.34
24.64
+1.77
+0.41
25.82
+2.95
+0.09
26.39
+3.52
+0.15

20K
24.71
24.88
+0.17
25.95
+1.24
+0.30
26.18
+1.47
+0.48
26.49
+1.78
+0.13
27.01
+2.30
+0.19

40K
25.80
26.10
+0.30
26.70
+0.90
+0.21
26.87
+1.07
+0.09
27.06
+1.26
+0.11
27.53
+1.73
+0.06

80K
27.08
27.06
-0.02
27.36
+0.28
+0.06
27.60
+0.52
+0.11
27.51
+0.43
+0.02
27.77
+0.69
-0.08

160K
27.90
28.09
+0.19
28.02
+0.12
-0.03
28.35
+0.45
+0.13
28.35
+0.45
+0.19
28.58
+0.68
+0.08

320K
28.46
28.49
+0.03
28.56
+0.10
+0.04
28.69
+0.23
+0.11
28.58
+0.12
+0.15
28.66
+0.20
-0.04

22.6
23.3
+0.7

25.0
26.0
+1.0

26.5
27.2
+0.7

26.5
28.0
+1.5

28.7
29.0
+0.3

30.0
30.0
+0.0

Table 9: SpanishEnglish: combining method phrase table pivoting
technique Callison-Burch et al. (2006). Shown BLEU scores (in %)
absolute improvements (over baseline method) training
bi-texts different numbers parallel es-en sentence pairs (10K, 20K, . . .,
320K) fixed amount additional pt-en pairs: (1) 1.3M pairs
eight additional languages pivoting, (2) 160K 1.23M pairs one
language (Portuguese) method (with without transliteration).
last three lines show results phrase table pivoting experiments reported
Callison-Burch et al. (2006) first three lines show reproduction
experiments. statistically significant improvements marked
(for p < 0.01) (for p < 0.05).

Again, found interesting pivoting help much transliteration
without it. Thus, closer look interaction pivoting transliteration
10K es-en sentence pairs 160K pt-en pairs. particular, looked number
usable phrase pairs respect test data, i.e., phrase pairs whose source side
matches test data, found without pivoting, using transliteration increases
number 657,541 1,863,950, i.e., 183.47%, using pivoting transliteration increases number 819,324 2,214,580, i.e., 170.29%. lower relative
increase number usable phrases one possible explanation corresponding
lower increase BLEU: +0.34 +0.09 absolute, respectively, without
transliteration.
207

fiNakov & Ng

8. Analysis Discussion
Below, perform deeper analysis method obtained results.
8.1 Merging Phrase Tables
compare merging catk:align cat1 (with 1-3 extra features, described
above), two simpler alternatives: (a) substituting cat1 ml-en, (b) merging
phrase tables derived original bi-texts, in-en ml-en.
implement evaluate following alternative method: (c) train
alignment models combined bi-text consists k copies in-en one
copy ml-en, truncate alignments appropriately, build two separate phrase
tables. first table catk:align method (built one copy in-en),
second one similar phrase table corresponds ml-en. Unlike (a) above, word
alignments second phrase table influenced k copies in-en. refer
second phrase table ml :catk:align. motivation trying alternative
(1) bit simpler implement, (2) somewhat symmetric phrase
tables. Yet, like method, alignment models benefit data,
phrase tables remain language-specific thus combined using extra features.
Table 10 compares method (line 3) above-described three alternatives, (a),
(b) (c), different numbers training ml-en sentence pairs. see, overall,
method (line 3) performs best, newly described alternative (c), shown line
4, ranked second. Merging phrase tables derived original bi-texts in-en
ml-en worst (line 1), explained fact cannot benefit
improved word alignments small in-en bi-text (unlike combinations,
notably one line 2). However, easy explain table alone
method better two alternatives.
Thus, looked phrase tables unknown words, case 160K
ml-en additional sentence pairs. results shown Table 11, offers good
insight: two good performing combinations lines 3-4 simply larger phrase tables
compared lines 1-2. importantly, translates higher number
phrase pairs potentially usable translating test sentences, i.e., match
input test time. Naturally, translation options mean larger search space
thus opportunities find better translations, explains better performance
combinations lines 3-4. table also compares number unknown word
types word tokens translating test data. see method
lowest number unknowns, explain good performance. hand,
numbers unknown words comparable three methods.
summary, Table 11 shows two important factors influencing BLEU: (i ) total used
number phrase pairs, (ii ) number unknown word types tokens translation
time. method ranks best criteria, second best method line 4 ranks
second first factor last second one (but close methods).
Thus, could conclude impact unknown words BLEU limited
differences small. phrase table size seems correlate somewhat better BLEU,
least two best performing methods. Finally, comparing line 2 lines 3-4,
conclude using in-en bi-text help align ml-en bi-text beneficial.
208

fiImproving SMT Resource-Poor Language

get even better insight, looked characteristics tables
combined: (1) phrase table sizes overlap, (2) number distinct source phrases
overlap, (3) average differences four standard scores merged tables
shared phrase pairs: inverse phrase translation probability (f |e), inverse lexical weighting
pw (f |e), direct phrase translation probability (e|f ), direct lexical weighting pw (e|f ).
results shown Table 12. table shows method combines phrase
tables much higher overlap (10-50 times higher!), terms number
phrase pairs number distinct source phrases. Moreover, absolute differences
scores shared phrase pairs halved (i.e., similar)
two phrase tables combined method, cat1 catk:align, compared
phrase tables combined three alternative approaches, last four
columns Table 12 show. high similarity scores cat1 catk:align
could one possible explanation similar performance shown Table 3.
Thus, method wins combining two tables already made
similar, thus appropriate combination. key element build
second table concatenation ml-en in-en bi-texts, in-en bitext minor influence word alignment (it simply much smaller), much
influence phrase extraction scoring. makes resulting phrase table much
similar first phrase table (which also made similar second table,
via word alignments only), also much bigger trained ml-en data
(14M vs. 11M phrase pairs); turn yields larger merged phrase table despite
higher overlap tables merged.
1
2
3
4

Merged Phrase Tables
in-en
ml-en
catk:align ml-en
catk:align cat1
catk:align ml :catk:align

10K
23.97
24.11
24.51
24.14

20K
24.46
24.56
24.70
24.54

40K
24.43
24.54
24.73
24.65

80K
24.67
24.62
24.97
24.72

160K
24.79
25.02
25.15
25.08

Table 10: Merging phrase tables Indonesian-English SMT: BLEU scores.
BLEU shown % different numbers training ml-en sentence pairs.

8.2 Transliteration
closer look transliteration: studying many words affects
impact number unknown words (also known OOVs, out-of-vocabulary words).
First, look number word types word tokens changed process
transliteration source side additional training bi-text. results shown
Table 13. see transliterating Malay Indonesian affects small
number words: 7.61% word types 5.78% word tokens.
surprising since spelling differences Malay Indonesian limited,
explained Section 3.1. contrast, transliterating Portuguese Spanish changes
44.71% word types 23.17% word tokens, agrees observations
Sections 3.2 6. Italian even affected transliteration Portuguese:
70.45% word types 34.37% word tokens changed.
209

fiNakov & Ng

1
2
3
4

Merged Phrase Tables
in-en
ml-en
catk:align ml-en
catk:align cat1
catk:align ml :catk:align

Phrase Pairs
Total
# Used % Used
14.23M
1.28M
9.02%
14.07M
1.25M
8.88%
15.83M
1.70M
10.71%
14.92M
1.37M
9.17%

Unknown
Types Tokens
1411
1917
1413
1906
1300
1743
1445
1933

BLEU
24.79
25.02
25.15
25.08

Table 11: Merging phrase tables derived in-en ml-en (160K): number
phrase pairs unknown words. Shown total number phrase
pairs merged phrase table number phrase pairs used decode
test data, followed number unknown word types tokens,
BLEU score (in %).

Merged Phrase Tables
1 in-en
ml-en
2 catk:align
3 catk:align
4 catk:align

ml-en
cat1
ml:catk:align

Phrase Pairs
PT1 PT2
3.2M 11.1M 72.1K

Source Phrases
PT1 PT2
1.1M 7.7M 10.3K

2.23%

0.91%

0.65%

1.2M 7.7M 11.1K

2.51%

0.95%

3.1M 14.0M 1.2M

1.2M 8.8M 0.6M
49.40%

0.21 0.05 0.13 0.05

6.54%

3.1M 11.9M 87.6K

1.2M 7.6M 11.6K

2.85%

0.99%

0.73%

0.40 0.18 0.19 0.10

0.14%

39.39%

8.67%

0.40 0.18 0.19 0.10

0.13%

3.1M 11.1M 77.1K
0.70%

Avg. Score Diff.
(f |e) pw (f |e) (e|f ) pw (e|f )

0.40 0.18 0.18 0.09

0.15%

Table 12: Comparison phrase tables merged Tables 10 11. Shown
number phrase pairs / source phrases phrase table
number/percent appear tables. last four columns
show average absolute differences four standard phrase table scores
phrase pairs appear tables; scores inverse phrase translation
probability (f |e), inverse lexical weighting pw (f |e), direct phrase translation
probability (e|f ), direct lexical weighting pw (e|f ).

One important reason higher number changes would that, unlike Spanish
Portuguese, Italian form plural nouns adjectives adding -s
vowel change. example, singular form adjective meaning green
verde three languages: Spanish, Portuguese, Italian. However, plural form
differs: verdes regardless gender Spanish Portuguese, verdi
(plural masculine) verde (plural feminine) Italian. Thus, transliterating Portuguese
Spanish would leave verdes intact, Italian, changes would needed. Given
frequency use plural nouns adjectives, expect many
differences ItalianSpanish PortugueseSpanish. Overall, small number
word types/tokens changed explains transliteration limited use Malay
important Spanish Italian.
210

fiImproving SMT Resource-Poor Language

1

Transliteration
MalayIndonesian

Word Types
Changed
Total
8,259
108,595

2

PortugueseSpanish

52,303

7.61%

5.78%

116,989

44.71%

3

ItalianSpanish

Word Tokens
Changed
Total
316,444
5,472,372
8,315,835

35,889,877

23.17%

88,767

126,005

70.45%

14,962,680

43,530,246

34.37%

Table 13: Transliteration: number words training data changed.
Shown number word types word tokens changed, compared
total number word types tokens source side different
training bi-texts.

1
2
3
4
5

Bi-text(s)
ml-en
mlin -en
in-en
in-en+ml-en
in-en+mlin -en

Sentences
160K
160K
28.4K
28.4K+160K
28.4K+160K

Unknown
Types Tokens
3,115
7,101
2,912
7,288
1,547
2,101
1,170
1,532
1,182
1,544

BLEU
17.90
19.15
23.80
24.43
24.72

Table 14: Unknown words Indonesian test dataset. Shown number
unknown word types word tokens, Bleu score % different training
bi-texts simple bi-text concatenations (cat1). counts respect
training bi-text; actual number unknown words translation time
differ. Indonesian bi-texts tuning testing enin monolingual
data used language modeling.

Next, studied impact transliteration number unknown words
test data. Table 14 shows results Indonesian, using Indonesian bi-texts
tuning testing enin monolingual data language modeling. Comparing lines 1
2, see transliteration limited impact reducing number
unknown word types training Malay data: number unknown word types
drops slightly 3,115 2,912, number unknown word tokens actually
grows, 7,101 7,288. Yet, improvement BLEU, 17.90 19.15.
improvement consistent n-gram scores included BLEU: 1-gram (48.46 vs.
50.12), 2-gram (22.09 vs. 23.46), 3-gram (12.49 vs. 13.54), 4-gram (7.67 vs. 8.44).
Thus, apparently, number unknown word types important number
unknown word tokens. Moving line 3, see number unknown
word types halved training Indonesian instead Malay, confirms
similarity Indonesian Malay. Comparing lines 4 5,
see concatenate Malay Indonesian training bi-texts, impact
transliteration minimal: terms word types/tokens BLEU.
211

fiNakov & Ng

1
2
3
4
5
6
7
8
9
10
11

Bi-text(s)
pt-en
ptes -en
it-en
ites -en
es-en
es-en+it-en
es-en+ites -en
es-en+pt-en
es-en+ptes -en
es-en+pt-en+it-en
es-en+ptes -en+ites -en

Sentences
160K
160K
160K
160K
160K
160K+160K
160K+160K
160K+160K
160K+160K
160K+160K+160K
160K+160K+160K

Unknown
Types Tokens
3,973
17,580
1,574
10,337
5,529
23,088
2,413
13,492
362
440
347
406
316
374
273
295
240
257
264
280
221
232

Bleu
6.35
11.35
4.06
9.38
27.90
27.65
27.69
27.83
28.14
27.89
28.02

Table 15: Unknown words Spanish test dataset. Shown number
unknown word types word tokens, Bleu score % different training
bi-texts simple bi-text concatenations (cat1). counts respect
training bi-text; actual number unknown words translation time
differ. Spanish bi-texts used tuning testing.

relative differences number unknown words much sizeable
transliterating Portuguese/Italian Spanish, Table 15 shows. Comparing lines 1-2
3-4, see number unknown word types/tokens halved, BLEU
doubles. confirms importance transliteration languages.
Going line 5, see 10-15 times drop number unknown word types
training Spanish bi-text. drop looks drastic compared Malay
Table 14, partly explained larger size training es-en bi-text,
contains 160K sentence pairs compared 28.4K pairs in-en. Since es-en bi-text
reduced number unknown word types 362, becomes hard reduce
number further. Still, lines 6-11 show, concatenating es-en pt-en it-en yields
sizable improvements using es-en only. Moreover, transliteration helps consistently
reducing number unknown words reductions bigger
Malay relative, also absolute terms. Still, reductions
number unknown words great absolute terms, thus corresponding
differences BLEU small. Yet, transliteration yields consistent improvement
concatenations: Spanish+Italian, Spanish+Portuguese, Spanish+Portuguese+Italian.
Overall, conclude large relative drops number unknown words
correspond sizable improvements BLEU; however, results small relative differences less conclusive: correspond small fluctuation BLEU Portuguese
Italian somewhat larger differences Malay. could feature much
lower token/type ratio Malay, agglutinative language, thus quite rich
wordforms: Table 13 shows, token/type ratio 50 Malay,
307 345 Portuguese Italian, respectively.
212

fiImproving SMT Resource-Poor Language

8.3 Relative Improvement
Finally, address important question much real data method saves.
Figure 3 compares graphically improvements baseline using method
160K vs. 1.23M pt-en sentence pairs transliteration different number original
training es-en sentence pairs. see figure that, 10K real training
es-en sentence pairs, using 160K additional pt-en method yields BLEU score
comparable achieved 40K real es-en sentence pairs, i.e., cut
necessary real data factor four. see using 1.23M pt-en
sentence pairs improves factor five. Similarly, 20K real es-en training sentence
pairs, method achieves BLEU score would require 33.5 times much real
training es-en data baseline system match.
Figure 4 summarizes statistics, showing many times real data would
needed baseline match performance method. see cut
factor 1.54 25, using 160K 1.23M additional pt-en sentences.

29

28

27

26

25

baseline
24

method: 160K
method: 1.23M

23

22
10K

20K

40K

80K

160K

320K

Figure 3: SpanishEnglish: improvements baseline using method
160K vs. 1.23M pt-en sentence pairs transliteration different
number original training es-en sentence pairs.

213

fiNakov & Ng

6

method: 160K
5

method: 1.23M
4

3

2

1

0
10K

20K

40K

80K

160K

Figure 4: Trade-off SpanishEnglish PortugueseEnglish data.
Shown number times need grow original es-en training data
order achieve BLEU score using method 160K/1.23M
additional pt-en sentence pairs transliteration.

9. Conclusion
proposed novel language-independent method improving statistical machine
translation resource-poor languages exploiting similarity related resource-rich
ones. achieved significant gains BLEU, improve best rivaling
approaches, using much less additional data.
studied impact using less closely related language auxiliary
language (Italian instead Portuguese improving SpanishEnglish SMT), tried
using Portuguese Italian together auxiliary languages, combined
method two orthogonal rivaling approaches: (1) using cognates source
target language, (2) source-language side paraphrasing pivot language.
experiments yielded statistically significant improvements small datasets.

214

fiImproving SMT Resource-Poor Language

Based experimental results, make several interesting conclusions:
1. shown using related languages help improve SMT: achieved
1.35 3.37 improvement BLEU in-en (+ml-en) es-en (+pt-en).
2. simple concatenation help, problematic additional sentences
out-number ones original bi-text.
3. Concatenation work well original bi-text repeated enough times
additional bi-text dominate.
4. Merging phrase tables giving priority original bi-text using additional
features good strategy.
5. Part improvement combining bi-texts due increased vocabulary
coverage another part comes improved word alignments. best results
achieved two sources first isolated combined (our method).
6. Transliteration help lot case systematic spelling variations
original additional source languages.
7. Overall, reduce amount necessary real training data factor 25.
future work, would like extend approach several interesting directions.
First, want make better use multi-lingual parallel corpora, e.g., access
Spanish-Portuguese-English corpus, used two separate bi-texts Spanish-English
Portuguese-English. Second, would like try using auxiliary languages
related target language. Finally, would like experiment sophisticated
ways get auxiliary language closer source go beyond simple transliteration.

Acknowledgments
would like thank anonymous reviewers constructive comments
suggestions, helped us improve quality manuscript. research
supported research grant POD0713875, Singapore National Research
Foundation International Research Centre @ Singapore Funding Initiative
administered IDM Programme Office.

References
Al-Onaizan, Y., Curin, J., Jahr, M., Knight, K., Lafferty, J., Melamed, D., Och, F. J.,
Purdy, D., Smith, N., & Yarowsky, D. (1999). Statistical machine translation. Tech.
rep., CLSP, Johns Hopkins University, Baltimore, MD.
Altintas, K., & Cicekli, I. (2002). machine translation system pair closely
related languages. Proceedings 17th International Symposium Computer
Information Sciences, ISCIS 02, pp. 192196, Orlando, FL.
Bakr, H. A., Shaalan, K., & Ziedan, I. (2008). hybrid approach converting written
Egyptian colloquial dialect diacritized Arabic. Proceedings 6th International Conference Informatics Systems, INFOS 08, Cairo, Egypt.
215

fiNakov & Ng

Bannard, C., & Callison-Burch, C. (2005). Paraphrasing bilingual parallel corpora.
Proceedings 43rd Annual Meeting Association Computational Linguistics,
ACL 05, pp. 597604, Ann Arbor, MI.
Bergsma, S., & Kondrak, G. (2007). Alignment-based discriminative string similarity.
Proceedings 45th Annual Meeting Association Computational Linguistics, ACL 07, pp. 656663, Prague, Czech Republic.
Bertoldi, N., Barbaiani, M., Federico, M., & Cattoni, R. (2008). Phrase-based statistical machine translation pivot languages. Proceedings International Workshop
Spoken Language Translation, IWSLT 08, pp. 143149, Honolulu, HI.
Bickford, A., & Tuggy, D. (2002).
Electronic glossary linguistic terms.
http://www.sil.org/mexico/ling/glosario/E005ai-Glossary.htm.
Birch, A., Osborne, M., & Koehn, P. (2007). CCG supertags factored statistical machine
translation. Proceedings Second Workshop Statistical Machine Translation, WMT 07, pp. 916, Prague, Czech Republic.
Brill, E., & Moore, R. C. (2000). improved error model noisy channel spelling correction. Proceedings 38th Annual Meeting Association Computational
Linguistics, ACL 00, pp. 286293, Hong Kong.
Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., Goldsmith, M. J., Hajic, J., Mercer,
R. L., & Mohanty, S. (1993). dictionaries data too. Proceedings
Workshop Human Language Technology, HLT 93, pp. 202205, Princeton, NJ.
Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L. (1993). mathematics statistical machine translation: parameter estimation. Computational Linguistics, 19 (2), 263311.
Callison-Burch, C. (2008). Syntactic constraints paraphrases extracted parallel
corpora. Proceedings 2008 Conference Empirical Methods Natural
Language Processing, pp. 196205.
Callison-Burch, C. (2012). How-to guide extracting syntactically constrained paraphrases.. http://www.cs.jhu.edu/ccb/howto-extract-paraphrases.html. Retrieved
2012-05-14.
Callison-Burch, C., Koehn, P., & Osborne, M. (2006). Improved statistical machine translation using paraphrases. Proceedings main conference Human Language
Technology Conference North American Chapter Association Computational Linguistics, HLT-NAACL 06, pp. 1724, New York, NY.
Chan, Y. S., & Ng, H. T. (2005). Word sense disambiguation distribution estimation.
Proceedings 19th International Joint Conference Artificial Intelligence,
IJCAI 05, pp. 10101015, Edinburgh, UK.
Chan, Y. S., & Ng, H. T. (2006). Estimating class priors domain adaptation word
sense disambiguation. Proceedings 21st International Conference Computational Linguistics 44th annual meeting Association Computational
Linguistics, COLING-ACL 06, pp. 8996, Sydney, Australia.
216

fiImproving SMT Resource-Poor Language

Chan, Y. S., & Ng, H. T. (2007). Domain adaptation active learning word sense
disambiguation. Proceedings 45th Annual Meeting Association
Computational Linguistics, ACL 07, pp. 4956, Prague, Czech Republic.
Chiang, D. (2005). hierarchical phrase-based model statistical machine translation.
Proceedings 43rd Annual Meeting Association Computational Linguistics, ACL 05, pp. 263270, Ann Arbor, MI.
Chiang, D., Knight, K., & Wang, W. (2009). 11,001 new features statistical machine
translation. Proceedings Human Language Technologies: Annual Conference
North American Chapter Association Computational Linguistics,
NAACL-HLT 09, pp. 218226, Boulder, CO.
Cohn, T., & Lapata, M. (2007). Machine translation triangulation: Making effective use
multi-parallel corpora. Proceedings 45th Annual Meeting Association
Computational Linguistics, ACL 07, pp. 728735, Prague, Czech Republic.
Collins, M., Koehn, P., & Kucerova, I. (2005). Clause restructuring statistical machine
translation. Proceedings 43rd Annual Meeting Association Computational Linguistics, ACL 05, pp. 531540, Ann Arbor, MI.
Crego, J. M., Max, A., & Yvon, F. (2010). Local lexical adaptation machine translation
triangulation: SMT helping SMT. Proceedings 23rd International
Conference Computational Linguistics, COLING 10, pp. 232240, Beijing, China.
Dahlmeier, D., & Ng, H. T. (2010). Domain adaptation semantic role labeling
biomedical domain. Bioinformatics, 26 (8), 10981104.
Daume, III, H., & Jagarlamudi, J. (2011). Domain adaptation machine translation
mining unseen words. Proceedings 49th Annual Meeting Association
Computational Linguistics: Human Language Technologies, ACL-HLT 11, pp. 407
412, Portland, OR.
Daume, III, H., & Marcu, D. (2006). Domain adaptation statistical classifiers. J. Artif.
Int. Res., 26, 101126.
de Gispert, A., & Mario, J. (2006). Catalan-English statistical machine translation without parallel corpus: Bridging Spanish. Proceedings 5th Workshop
Strategies developing Machine Translation Minority Languages LREC,
SALTMIL 06, pp. 6568, Genoa, Italy.
Denkowski,
M.
(2012).
README
file

Parex
paraphrase extractor.. https://github.com/mjdenkowski/parex/blob/master/README.
Retrieved 2012-05-14.
Denkowski, M., & Lavie, A. (2010). METEOR-NEXT METEOR paraphrase tables:
Improved evaluation support five target languages. Proceedings Joint 5th
Workshop Statistical Machine Translation MetricsMATR, pp. 339342.
Filali, K., & Bilmes, J. (2005). Leveraging multiple languages improve statistical MT
word alignments. Proceedings IEEE Automatic Speech Recognition Understanding Workshop, ASRU 05, Cancun, Mexico.
217

fiNakov & Ng

Finch, A., & Sumita, E. (2008). Phrase-based machine transliteration. Proceedings
Workshop Technologies Corpora Asia-Pacific Speech Translation, TCAST
08, pp. 1318, Hyderabad, India.
Galley, M., Hopkins, M., Knight, K., & Marcu, D. (2004). Whats translation rule?.
Proceedings Human Language Technology Conference North American
Chapter Association Computational Linguistics, HLT-NAACL 04, pp. 273
280, Boston, MA.
Garera, N., Callison-Burch, C., & Yarowsky, D. (2009). Improving translation lexicon induction monolingual corpora via dependency contexts part-of-speech equivalences. Proceedings Thirteenth Conference Computational Natural Language Learning, CoNLL 09, pp. 129137, Boulder, CO.
Graca, J., Ganchev, K., & Taskar, B. (2010). Learning tractable word alignment models
complex constraints. Comput. Linguist., 36, 481504.
Habash, N., & Hu, J. (2009). Improving Arabic-Chinese statistical machine translation
using English pivot language. Proceedings Fourth Workshop Statistical
Machine Translation, WMT 09, pp. 173181, Athens, Greece.
Haghighi, A., Liang, P., Berg-Kirkpatrick, T., & Klein, D. (2008). Learning bilingual lexicons monolingual corpora. Proceedings 46th Annual Meeting
Association Computational Linguistics, ACL 08, pp. 771779, Columbus, OH.
Hajic, J., Hric, J., & Kubon, V. (2000). Machine translation close languages.
Proceedings Sixth Conference Applied Natural Language Processing, ANLP
00, pp. 712, Seattle, WA.
Han, B., & Baldwin, T. (2011). Lexical normalisation short text messages: Makn sens
#twitter. Proceedings 49th Annual Meeting Association Computational Linguistics: Human Language Technologies, ACL-HLT 11, pp. 368378,
Portland, Oregon.
Hana, J., Feldman, A., Brew, C., & Amaral, L. (2006). Tagging Portuguese Spanish tagger using cognates. Proceedings International Workshop CrossLanguage Knowledge Induction, CrossLangInduction 06, pp. 3340, Trento, Italy.
Hildebrand, A. S., Eck, M., Vogel, S., & Waibel, A. (2005). Adaptation translation
model statistical machine translation based information retrieval. Proceedings
10th Annual Conference European Association Machine Translation,
EAMT 05, pp. 133142, Budapest, Hungary.
Hopkins, M., & May, J. (2011). Tuning ranking. Proceedings 2011 Conference
Empirical Methods Natural Language Processing, EMNLP 11, pp. 13521362,
Edinburgh, Scotland, UK.
Inkpen, D., Frunza, O., & Kondrak, G. (2005). Automatic identification cognates
false friends French English. Proceedings International Conference
Recent Advances Natural Language Processing, RANLP 05, pp. 251257, Borovets,
Bulgaria.
218

fiImproving SMT Resource-Poor Language

Jiang, J., & Zhai, C. (2007a). Instance weighting domain adaptation NLP. Proceedings 45th Annual Meeting Association Computational Linguistics,
ACL 07, pp. 264271, Prague, Czech Republic.
Jiang, J., & Zhai, C. (2007b). two-stage approach domain adaptation statistical
classifiers. Proceedings sixteenth ACM conference Conference information knowledge management, CIKM 07, pp. 401410, Lisbon, Portugal. ACM.
Klementiev, A., & Roth, D. (2006). Named entity transliteration discovery multilingual comparable corpora. Proceedings main conference Human Language Technology Conference North American Chapter Association
Computational Linguistics, HLT-NAACL 06, pp. 8288, New York, NY.
Koehn, P. (2005). Europarl: parallel corpus evaluation machine translation.
Proceedings Tenth Machine Translation Summit, MT Summit 05, pp. 7986,
Phuket, Thailand.
Koehn, P., Axelrod, A., Mayne, A. B., Callison-Burch, C., Osborne, M., & Talbot, D.
(2005). Edinburgh system description IWSLT speech translation evaluation.
Proceedings International Workshop Spoken Language Translation, IWSLT
05, Pittsburgh, PA.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bojar, O., Constantin, A., & Herbst, E.
(2007). Moses: Open source toolkit statistical machine translation. Proceedings 45th Annual Meeting Association Computational Linguistics.
Demonstration session, ACL 07, pp. 177180, Prague, Czech Republic.
Koehn, P., & Knight, K. (2002). Learning translation lexicon monolingual corpora.
Proceedings ACL-02 Workshop Unsupervised Lexical Acquisition, pp. 916,
Philadelphia, PA.
Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. Proceedings Conference North American Chapter Association
Computational Linguistics Human Language Technology, NAACL 03, pp. 4854,
Edmonton, Canada.
Kondrak, G. (2005). Cognates word alignment bitexts. Proceedings Tenth
Machine Translation Summit, MT Summit 05, pp. 305312, Phuket, Thailand.
Kondrak, G., Marcu, D., & Knight, K. (2003). Cognates improve statistical translation
models. Proceedings Conference North American Chapter
Association Computational Linguistics Human Language Technology, NAACL
03, pp. 4648, Edmonton, Canada.
Kumar, S., Och, F. J., & Macherey, W. (2007). Improving word alignment bridge
languages. Proceedings Joint Conference Empirical Methods Natural
Language Processing Computational Natural Language Learning, EMNLP-CoNLL
07, pp. 4250, Prague, Czech Republic.
Li, H., & Kumaran, A. (Eds.). (2010). NEWS 10: Proceedings 2010 Named Entities
Workshop, Uppsala, Sweden.
219

fiNakov & Ng

Mann, G. S., & Yarowsky, D. (2001). Multipath translation lexicon induction via bridge
languages. Proceedings second meeting North American Chapter
Association Computational Linguistics Language technologies, NAACL 01,
pp. 18, Pittsburgh, PA.
Marujo, L., Grazina, N., Lus, T., Ling, W., Coheur, L., & Trancoso, I. (2011). BP2EP
Adaptation Brazilian Portuguese texts European Portuguese. Proceedings
15th Conference European Association Machine Translation, EAMT
11, pp. 129136, Leuven, Belgium.
Matthews, D. (2007). Machine transliteration proper names. Masters thesis, School
Informatics, University Edinburgh.
Melamed, D. (1995). Automatic evaluation uniform filter cascades inducing N-best
translation lexicons. Proceedings Third Workshop Large Corpora,
VLC 95, pp. 184198, Cambridge, MA.
Melamed, D. (1999). Bitext maps alignment via pattern recognition. Computational
Linguistics, 25 (1), 107130.
Melamed, D. (2000). Models translational equivalence among words. Computational
Linguistics, 26 (2), 221249.
Mulloni, A., & Pekar, V. (2006). Automatic detection orthographic cues cognate
recognition. Proceedings 5th International Conference Language Resources
Evaluation, LREC 06, pp. 23872390, Genoa, Italy.
Nakov, P. (2008). Improved statistical machine translation using monolingual paraphrases.
Proceedings 18th European Conference Artificial Intelligence, ECAI 08,
pp. 338342, Patras, Greece.
Nakov, P., Nakov, S., & Paskaleva, E. (2007). Improved word alignments using Web
corpus. Proceedings International Conference Recent Advances
Natural Language Processing, RANLP 07, pp. 400405, Borovets, Bulgaria.
Nakov, P., & Ng, H. T. (2009a). Improved statistical machine translation resource-poor
languages using related resource-rich languages. Proceedings Conference
Empirical Methods Natural Language Processing, EMNLP 09, pp. 13581367,
Singapore.
Nakov, P., & Ng, H. T. (2009b). NUS WMT09: Domain adaptation experiments
English-Spanish machine translation news commentary text. Proceedings
Fourth Workshop Statistical Machine Translation, WMT 09, pp. 7579, Athens,
Greece.
Och, F. J. (2003). Minimum error rate training statistical machine translation.
Proceedings 41st Annual Meeting Association Computational Linguistics,
ACL 03, pp. 160167, Sapporo, Japan.
Och, F. J., & Ney, H. (2001). Statistical multi-source translation. Proceedings MT
Summit VIII. Machine Translation Information Age, MT Summit 01, pp. 253
258, Santiago de Compostela, Spain.
220

fiImproving SMT Resource-Poor Language

Oh, J.-H., Choi, K.-S., & Isahara, H. (2006). comparison different machine transliteration models. J. Artif. Int. Res., 27, 119151.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: method automatic
evaluation machine translation. Proceedings 40th Annual Meeting
Association Computational Linguistics, ACL 02, pp. 311318, Philadelphia, PA.
Paul, M., Yamamoto, H., Sumita, E., & Nakamura, S. (2009). importance pivot
language selection statistical machine translation. Proceedings Human Language Technologies: Annual Conference North American Chapter
Association Computational Linguistics, NAACL-HLT 09, pp. 221224, Boulder,
CO.
Quirk, C., Menezes, A., & Cherry, C. (2005). Dependency treelet translation: Syntactically
informed phrasal SMT. Proceedings 43rd Annual Meeting Association
Computational Linguistics, ACL 05, pp. 271279, Ann Arbor, MI.
Rappoport, A., & Levent-Levi, T. (2006). Induction cross-language affix letter
sequence correspondence. Proceedings International Workshop CrossLanguage Knowledge Induction, CrossLangInduction 06, pp. 1724, Trento, Italy.
Ristad, E., & Yianilos, P. (1998). Learning string-edit distance. IEEE Trans. Pattern Anal.
Mach. Intell., 20 (5), 522532.
Salloum, W., & Habash, N. (2011). Dialectal standard Arabic paraphrasing improve
Arabic-English statistical machine translation. Proceedings First Workshop
Algorithms Resources Modelling Dialects Language Varieties, pp.
1021, Edinburgh, Scotland, UK.
Sawaf, H. (2010). Arabic dialect handling hybrid machine translation. Proceedings
9th Conference Association Machine Translation Americas,
AMTA 10.
Scannell, K. (2006). Machine translation closely related language pairs. Proceedings
LREC2006 Workshop Strategies Developing Machine Translation
Minority Languages, Genoa, Italy.
Schafer, C., & Yarowsky, D. (2002). Inducing translation lexicons via diverse similarity
measures bridge languages. Proceedings 6th Conference Natural
Language Learning, COLING 02, pp. 17, Taipei, Taiwan.
Scherrer, Y. (2007). Adaptive string distance measures bilingual dialect lexicon induction. Proceedings 45th Annual Meeting ACL: Student Research
Workshop, ACL 07, pp. 5560, Prague, Czech Republic.
Schroeder, J., Cohn, T., & Koehn, P. (2009). Word lattices multi-source translation.
Proceedings 12th Conference European Chapter Association
Computational Linguistics, EACL 09, pp. 719727, Athens, Greece.
Snover, M., Dorr, B., & Schwartz, R. (2008). Language translation model adaptation
using comparable corpora. Proceedings Conference Empirical Methods
Natural Language Processing, EMNLP 08, pp. 857866, Honolulu, HI.
221

fiNakov & Ng

Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., Tufis, D., & Varga, D.
(2006). JRC-Acquis: multilingual aligned parallel corpus 20+ languages.
Proceedings 5th International Conference Language Resources Evaluation, LREC 06, pp. 21422147, Genoa, Italy.
Tanaka, R., Murakami, Y., & Ishida, T. (2009). Context-based approach pivot translation services. Proceedings 21st International Joint Conference Artifical
intelligence, IJCAI 09, pp. 15551561, Pasadena, CA.
Tiedemann, J. (1999). Automatic construction weighted string similarity measures.
Joint SIGDAT Conference Empirical Methods Natural Language Processing
Large Corpora, EMNLP-VLC 99, pp. 213219, College Park, MD.
Tiedemann, J. (2009). Character-based PSMT closely related languages. Proceedings
13th Annual Conference European Association Machine Translation,
EAMT 09, pp. 1219, Barcelona, Spain.
Tiedemann, J., & Nabende, P. (2009). Translating transliterations. International Journal
Computing ICT Research, 3 (1), 3341.
Ueffing, N., Haffari, G., & Sarkar, A. (2007). Semi-supervised model adaptation statistical machine translation. Machine Translation, 21, 7794.
Utiyama, M., & Isahara, H. (2007). comparison pivot methods phrase-based statistical machine translation. Human Language Technologies 2007: Conference
North American Chapter Association Computational Linguistics;
Proceedings Main Conference, NAACL-HLT 07, pp. 484491, Rochester, NY.
Vilar, D., Peter, J.-T., & Ney, H. (2007). translate letters?. Proceedings
Second Workshop Statistical Machine Translation, pp. 3339, Prague, Czech
Republic.
Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation. Proceedings 16th conference Computational linguistics, COLING
96, pp. 836841, Copenhagen, Denmark.
Wu, H., & Wang, H. (2007). Pivot language approach phrase-based statistical machine
translation. Machine Translation, 21 (3), 165181.
Zhang, X. (1998). Dialect MT: case study Cantonese Mandarin. Proceedings 36th Annual Meeting Association Computational Linguistics
17th International Conference Computational Linguistics, COLING-ACL 98, pp.
14601464, Montreal, Quebec, Canada.

222

fiJournal Artificial Intelligence Research 44 (2012) 97-140

Submitted 2/2012; published 5/2012

Solving Limited Memory Influence Diagrams
Denis Deratani Maua
Cassio Polpo de Campos
Marco Zaffalon

denis@idsia.ch
cassio@idsia.ch
zaffalon@idsia.ch

Istituto Dalle Molle di Studi sullIntelligenza Artificiale (IDSIA)
Galleria 2, Manno, 6928 Switzerland

Abstract
present new algorithm exactly solving decision making problems represented
influence diagrams. require usual assumptions forgetting regularity;
allows us solve problems simultaneous decisions limited information.
algorithm empirically shown outperform state-of-the-art algorithm randomly
generated problems 150 variables 1064 solutions. show problems
NP-hard even underlying graph structure problem low treewidth
variables take bounded number states, admit provably good
approximation variables take arbitrary number states.

1. Introduction
Influence diagrams (Howard & Matheson, 1984) graphical models aimed representation problems decision making uncertainty. Traditionally, designed
handle situations involving single, non-forgetful decision maker. Limited memory influence diagrams (hereafter LIMIDs) generalizations influence diagrams allow
decision making limited information, case simultaneous decisions, bounded
memory controllers non-communicating cooperative agents (Zhang, Qi, & Poole, 1994;
Lauritzen & Nilsson, 2001; Poupart & Boutilier, 2003; Detwarasiti & Shachter, 2005).
precisely, LIMIDs relax regularity forgetting assumptions influence diagrams,
namely, complete temporal ordering decision variables,
disclosed information (i.e., decisions observations made) remembered considered
future decisions. assumptions might hard meet applications, might lead exponential growth size policies, consequently
intractability.
Solving (limited memory) influence diagram refers finding optimal plan action,
is, combination decision rules, policies, associate possible observation
action. Optimality understood maximizing expected utility. task
empirically theoretically shown hard (de Campos & Ji, 2008). fact,
show solving LIMID NP-hard even admit singly connected diagrams
bounded number states per variable,1 devising algorithm produces
provably good approximate solutions within fixed factor unlike exist even
diagrams low treewidth.
1. diagram singly connected underlying (undirected) graph contains cycles.
2012 AI Access Foundation. rights reserved.

fiMaua, de Campos, & Zaffalon

Lauritzen Nilsson (2001) shown LIMIDS satisfy certain graphstructural conditions (which forgetting regularity imply) solved exactly
dynamic programming procedure complexity exponential treewidth. Hence,
solving LIMIDs computationally similar performing probabilistic inference
Bayesian networks (Koller & Friedman, 2009). fact, single policy updating (SPU)
algorithm Lauritzen Nilsson (2001) performs local search space policies
step performs probabilistic inference evaluate candidate solution.
However, many problems fail meet conditions necessary SPU achieving optimality, cases SPU might converge local optimum much inferior
actual (global) optimum. circumvent problem, de Campos Ji (2008) formulated
credal reformulation (CR) algorithm maps LIMID mixed integer linear
programming problem. showed CR algorithm able solve small problems exactly obtain good approximations medium-sized problems relaxing
integrality constraints.
show paper LIMIDs solved exactly variable elimination
scheme simultaneously propagates sets (partial) solutions. Although algorithm
runs exponential time worst case (which expected, problem
NP-hard), show many problem instances possible obtain optimal
solution efficiently pruning solutions Pareto-dominated others. heart
algorithms efficiency property moment variable elimination
local Pareto dominance implies global Pareto dominance, is, partial solution
Pareto-dominated another partial solution cannot part optimal solution,
hence safely discarded. show experimentally pruning Paretodominated local solutions enormously save computational resources, enable us
compute exact solutions much bigger problems previous algorithms. fact,
algorithm orders magnitude faster CR algorithm randomly generated
diagrams containing 150 variables 1064 strategies.
paper organized follows. Section 2 describes LIMID formalism presents
new results complexity solving LIMID. variable elimination algorithm
computing exact solutions presented Section 3, evaluated Section 4. last,
Sections 5 6 contain related work final discussion. improve readability,
proofs supporting results given appendix.

2. Limited Memory Influence Diagrams
section, describe LIMID formalism, state complexity solving LIMID
instance, show LIMID transformed equivalent (in terms
maximum expected utility) diagram whose utilities nonnegative decision variables
parents. LIMIDs input algorithm next section. start
example decision problem limited information, use throughout
rest paper illustrate motivate concepts. Although example (which
essentially team coordination problem) rather simple, easily extended
account realistic scenarios.
98

fiSolving LIMIDs

2.1 Fire Dispatching Problem
particular fire station contains group firefighters divided three units. fire
dispatcher decides units dispatch reported accident. dispatched
unit costs -1 utile, units dispatched cost utiles. case fire, higher
number dispatched teams higher chances minimum damage (which implies
saving lives preventing third-party financial losses). make things simple, consider
accident handled either appropriately, case say success,
inappropriately, case say failure. Ideally, dispatcher wants
maximize chance success minimizing number dispatched teams (and
hence cost operation). successful operation rewarded 7/2 utiles,
failure gets zero utiles.
2.2 Variables Domains
formalism (limited memory) influence diagrams, quantities events
interest represented three distinct types variables nodes.2 Chance variables
represent events decision maker control, outcomes tests
consequences actions. Decision variables represent options available decision
maker. Finally, value variables represent additive parcels utility associated state
world. set variables considered relevant problem denoted U.
variable X U associated domain X , finite non-empty set
values X assume. elements X called states. assume existence
empty domain , {}, contains single element
domain. Decision chance variables assumed domains different
empty domain, whereas value variables always associated empty domain.
fire dispatching problem, represent act dispatching
unit decision variable Ti ; hence three decision variables T1 , T2 , T3
domains T1 = T2 = T3 = {a, w}, stands act means unit
dispatched, w stands wait means unit dispatched. outcome
incident assignment units represented binary chance variable
domain = {s, f } (representing success failure, respectively), evaluated
value variable V (which associated ). also individual costs per unit
dispatched, modeled three value variables V1 , V2 V3 . set relevant
variables problem U = {T1 , V1 , T2 , V2 , T3 , V3 , O, V }.
domain x set variables x = {X1 , . . . , Xn } U given Cartesian
product X1 Xn variable domains. Thus, element u U defines
state world, is, realization actions events interest. x
sets variables x U, x element domain x , write
xy denote projection x onto smaller domain , is, xy contains
components x compatible variables y. convention,
x , . cylindrical extension x set x , {x x : xy = y}.
Often, write X1 Xn denote set {X1 , . . . , Xn } and, clear context,
X denote singleton {X}. instance, x = {T1 , O} = {T1 }, x =
2. make distinction node graphical representation decision problem
corresponding variable.

99

fiMaua, de Campos, & Zaffalon

{(a, s), (w, s), (a, f ), (w, f )}. Also, x = (w, s) x xy = w xO = s.
cylindrical extension x given sx = {(a, s), (w, s)}.
2.3 Operations Real-Valued Functions
operations real-valued functions need defined. Let f g functions
domains x , respectively. product f g defined function
domain xy (f g)(w) = f (wx )g(wy ) w domain. Sum functions
defined analogously: (f + g)(w) = f (wx ) + g(wy ). Notice product sum
functions associative commutative, product distributes sum, is,
f g = gf , f + g = gP+ f , f (g + h) = f g + f h. f function x , U,
sum-marginalP f returns
w
P function x\y element
P
domain ( f )(w) = xwx f (x). Notice x = , f = f . Also,
sum-marginal operation
inherits
commutativity
P
P P
P Pand associativity addition real
numbers, hence xy f = x\y f = y\x x f .
{fxy }yy set containing functions fxy domain x , one element ,

write fxy denote function w xy satisfies fxy (w) = fxw (wx ).
instance, X two binary-valued variables domains X = {x1 , x2 }



= {y 1 , 2 }, fX1 fX2 two functions X fX1 (x1 ) = 1/2,
y2
y2
y1

fX (x2 ) = 1/2, fX (x1 ) = 0 fX (x2 ) = 1, function fX





fX
(x2 , 1 ) = fX1 (x2 ) = 1/2 ,




fX
(x2 , 2 ) = fX2 (x2 ) = 1 .


fX
(x1 , 1 ) = fX1 (x1 ) , = 1/2




fX
(x1 , 2 ) = fX2 (x1 ) , = 0

clear context, write 1 denote function returns one
values domain 0 denote function returns always zero. x x ,
indicator function Ix returns one x = x zero otherwise.
f g functions domain x k real number, expressions f g
f = k denote f (x) g(x) f (x) = k, respectively, x x (e.g.,

previous example fX1 = 1/2). Finally, function domain containing
single element (e.g., empty domain) identified real number returns.
2.4 Definition
LIMID L consists direct acyclic graph (DAG) set variables U annotated
variable types (decision, chance value), together collection (conditional)
probability mass functions (one per chance variable) utility functions (one per value
variable). value nodes graph assumed children. precise
meaning arcs varies according type node point. Arcs entering
chance value nodes denote stochastic functional dependency, respectively; arcs
entering decision nodes describe information awareness time decision made.
variable X U, denote paX set parents X, is, set
nodes arc pointing X. Similarly, let chX denote set
children X (i.e., nodes arc X), faX , paX {X} denote
family. let C, V partition U sets chance, decision value
variables, respectively. chance variable C C associated set {p
C : paC }
100

fiSolving LIMIDs

V1

V2

V3

T1

T2

T3

uV1 (a) = uV2 (a) = uV3 (a) = 1
uV1 (w) = uV2 (w) = uV3 (w) = 0



pTO1 ,T2 ,T3 (s, t1 , t2 , t3 ) = I(a,a,a)
uV (s) = 7/2
uV (f ) = 0

V
Figure 1: LIMID representing fire dispatching problem.
(conditional) probability mass functions p
C quantifying decision makers beliefs
states x C conditional state parents (if C parents, single
probability mass function assigned). Using notation introduced previous section,
equivalently represent set probability mass functions associated variable C
pa
function pC C . assume chance variable X C stochastically independent
non-descendant non-parents given parents. value variable V V associated
real-valued utility function uV paV , quantifies (additive) contribution
states parents overall utility. Thus, thePoverall utility state x CD
given sum utility functions, is, u(x) = V V uV (xpaV ).
2.5 LIMID Fire Dispatching Problem
Figure 1 depicts LIMID fire dispatching problem. graph, chance, decision
value variables represented ovals, rectangles diamonds, respectively.
value variables V1 , V2 V3 associated utility functions uV1 , uV2 uV3 , respectively,
representing cost per unit dispatched. utility outcome quantified
function uV associated value variable V . chance variable associated
function pTO1 ,T2 ,T3 quantifies conditional probabilities P (O = o|T1 = tT1 , T2 =
tT2 , T3 = tT3 ) success (o = s) failure (o = f ) given joint decision T1 ,T2 ,T3 .
According model figure, dispatching three units results certain success,
whereas dispatching less three units leads failure.
2.6 Policies Strategies
decision variable least one parent, policy specifies action
possible state configuration parents, is, : paD .
parents, state . set policies variable denoted
. instance, policy T1 first unit running example state T1 .
space policies T1 given T1 = {a, w}.
Let , DD denote space possible combination policies. element
= (D )DD said strategy L. Given policy state paD , let

p
denote probability mass function conditional paD = pD = ID () .
parents, pD = ID unconditional probability mass function .
101

fiMaua, de Campos, & Zaffalon

pa

simplify notation, sometimes write pD irrespective whether parent.
pa
one-to-one correspondence functions pD policies
paD
specifying policy equivalent specifying pD vice-versa. denote
pa
set functions pD obtained way PD . So, instance, PT1 = {Ia , Iw }.
strategy induces joint probability mass function variables C
pa pa
ps ,
pC C
pD ,
(1)
CC

DD

associated expected utility
Es [L] ,

X

ps

CD

X

uV .

(2)

V V

Notice two sums Eq. (2) different semantics. outer (leftmost) sum
denotes sum-marginal
set variables C D, whereas inner (rightmost) denotes
overall utility function V V paV results sum functions uV .
fire dispatching problem, eight possible strategies consisting decision
act wait units, example, = (T1 , T2 , T3 ) = (a, w, a) possible
strategy. policy T1 = dispatches unit T1 induces probability mass function
pT1 = Ia T1 . Likewise, policy T2 = w induces function pT2 = Iw , policy
T3 = induces pT3 = Ia . strategy = (a, w, a) induces joint probability
mass function x O,T1 ,T2 ,T3
T1 ,T2 ,T3
ps (x) = pO
(x)pT1 (xT1 )pT2 (xT2 )pT3 (xT3 ) ,

expected utility
X
Es [L] =
ps [uV1 + uV2 + uV3 + uV ]
O,T1 ,T2 ,T3

=

X

h

ps (x) uV1 (xT1 ) + uV2 (xT2 ) + uV3 (xT3 ) + uV (xO ) = 2 .

xO,T1 ,T2 ,T3

optimal strategy = (a, a, a) dispatches units, hand,
expected utility Es [L] = 1/2.
2.7 Theoretical Complexity
treewidth graph measures resemblance tree given number
vertices largest clique corresponding triangulated moral graph minus one
(Bodlaender, 1996). Bayesian networks, complexity solving LIMID strongly
affected treewidth. Given LIMID L treewidth , evaluate expected
utility given strategy time space exponential (Koller & Friedman,
2009). Hence, bounded constant, computing Es [L] takes (at most) polynomial
time input size.
primary task LIMID find strategy maximal expected utility,
is, find
Es [L] Es [L]
102

s.

(3)

fiSolving LIMIDs

value Es [L] called maximum expected utility L denoted MEU[L].
real problems, enumerating strategies prohibitively costly. fact,
computing MEU bounded treewidth diagrams NP-hard (de Campos & Ji, 2008),
and, following result implies, remains NP-hard even simpler LIMIDs.
Theorem 1. Given singly connected LIMID treewidth equal two, variables three states, deciding whether strategy expected utility
greater given k NP-complete.
proof, based reduction partition problem (Garey & Johnson, 1979),
given appendix.
usual assumptions complexity theory, problem NP-hard solve
best available options (i) trying devise algorithm runs efficiently
many instances exponential worst-case complexity, (ii) trying develop
approximation algorithm instances provides polynomial time solution
provably within certain range optimal solution. Section 3, take option (i),
present algorithm efficiently computes optimal solutions many LIMIDs,
runs exponential time many others. following state result suggests
alternative (ii) likely unfeasible, even consider diagrams bounded
treewidth.
Given > 1, -approximation algorithm (for solving LIMID) obtains strategy

MEU[L]
Es [L] .
(4)

set = 1/(1 ), 0 < < 1, -approximation algorithm finds solution
whose induced relative error , is,
MEU[L] Es [L]
.
MEU[L]

(5)

following result indicates provably good approximation algorithms exist
unless P=NP.
Theorem 2. Given singly connected LIMID L bounded treewidth, (unless P=NP)
polynomial time -approximation algorithm, 1 < < 2 ,
number numerical parameters (i.e., probabilities utilities) required specify L.
defer proof appendix. result asserts algorithm finds
solutions LIMIDs polynomial time cannot guarantee relative error smaller
1 2 , even set inputs restricted LIMIDs bounded treewidth. Hence,
polynomial-time algorithm LIMIDs must eventually produce poor solutions,
relative error close one large models. exception treewidth
number states per variable bounded. cases, shown constructively
early work (Maua, de Campos, & Zaffalon, 2011) -approximation
algorithm runs polynomial time.
103

fiMaua, de Campos, & Zaffalon

2.8 Constraining LIMIDs Nonnegative Utilities
principle, utilities associated value variables LIMID take real
value. complicates ordering functions use algorithm
devise here. Fortunately, easily efficiently transform LIMID L
equivalent LIMID L0 utilities nonnegative whose optimal strategies
also optimal strategies L. Moreover, obtaining Es [L] Es [L0 ] strategy
straightforward.
Let L LIMID let k denote smallest utility value associated
value variables, is, V V follows k uV , V
uV (x) = k x paV . following transformation generates new LIMID L0
whose value variables associated nonnegative values.
Transformation 3. value variable V V, substitute associated utility function
uV new utility function u0V = uV k.
transformation shifts utility functions uV 0, makes uV (x) = 0
least one V x paV . Since affects value variables, strategy L (the
LIMID transformation) also valid strategy L0 (the transformed LIMID).
expected utilities strategy L L0 related according following
result.
Proposition 4. strategy s, Es [L] = Es [L0 ] + k|V|.
Proof. expected utility respect L0 given
Es [L0 ] =

X

=

X
x

V

=

X

X

ps (x)

x

X

u0V (xpaV )

V

X
ps (x)
[uV (xpaV ) k]
ps (x)

x

uV (xpaV ) k|V|

X

ps (x)

x

V

= Es [L] k|V| ,
last step follows

P

x ps (x)

= 1.

optimal strategy L satisfies Es [L] Es [L] s, hence Proposition 4
ensures Es [L] = Es [L0 ]+k|V| Es [L0 ]+k|V| = Es [L], implies also
optimal strategy L0 . Similarly, optimal strategy L0 ,
proposition Es [L0 ] = Es [L] k|V| Es [L] k|V| = Es [L0 ] s, therefore
also optimal L. following corollary summarizes results.
Corollary 5. strategy L0 optimal strategy also optimal
strategy L.
104

fiSolving LIMIDs

Consider running example more. smallest utility value k = 1.
utilities associated value variables transformed LIMID L0 given
u0V (s) = 9/2

u0V (f ) = 1

u0V1 (a) = 0

u0V1 (w) = 1

u0V2 (a) = 0

u0V2 (w) = 1

u0V3 (a) = 0

u0V3 (w) = 1 .

strategy = (a, w, a) expected utility Es [L0 ] = Es [L] k|V| = 2 (1)4 = 2.
optimal strategy = (a, a, a) obtains Es [L0 ] = 9/2.
rest paper, consider LIMIDs nonnegative utilities, due
Proposition 4 incur loss generality.
2.9 Decision Nodes Many Parents Versus Parentless Decision Nodes
policy decision variable parents corresponds choice one states.
Hence, space policies nodes contains number policies polynomial
input. hand, cardinality space policies decision nodes
many parents exponential number states parents. see this, consider
ten-state decision variable D. parents space policies contains 10
4
policies. However, four ternary parent nodes, space contains 103 = 1081
policies.
One might wonder whether LIMIDs whose decision nodes many parents
difficult solve LIMIDs parentless decision nodes. show that,
least theoretical perspective, case, LIMID
efficiently mapped MEU-equivalent LIMID decision nodes parents.
show optimal strategy original diagram produced
optimal strategy transformed diagram. particularly relevant algorithms
search space policies, case algorithm devise here, allow
us, without loss generality, focus LIMIDs whose decision nodes parents.
formally describing transformation showing produces diagram
equal MEU, let us first give idea works. end, consider
LIMID L decision node least one parent (e.g., diagram Figure 2(a)),
let 1 , . . . , denote configurations paD . policy maps configuration
pa
decision . function pD associated policy seen

set probability mass functions pT1 , . . . , pTm pTi = p
= ID ( ) , is,
function pTi represents choice state fixed configuration parents.
Recall policy associated parentless variable simply choice state.
transformation replaces decision variable decision variables T1 , . . . , Tm
chance variables X1 , . . . , Xm policy Ti corresponds decision (i )
original variables policy (see diagram Figure 2(b)). chain X1 Xm chance
variables responsible making policy Ti active parents assume
configuration , occurs , either blocking allowing information
flow according value parents D. Thus, parents act selector
105

fiMaua, de Campos, & Zaffalon

paD

paD


X1

X2

chD

T1

T2



(a)

Xm

chD

Tm
(b)

Figure 2: piece diagram (a) (b) Transformation 6.

decides probability mass functions pTi associated decision nodes T1 , . . . , Tm
going used, transformed diagram acts original one. probability
X
,Ti ,paD
mass functions pXi1
set ensure Xi = Ti paD = Xi = Xi1

otherwise.
Transformation 6. Consider LIMID L decision node least one parent,
let 1 , . . . , denote configurations paD . Remove add = |paD |
chance nodes X1 , . . . , Xm decision nodes T1 , . . . , Tm domains Xi = Ti =
(for = 1, . . . , m). Add arc every parent X1 , . . . , Xm , arc
every Xi Xi+1 , < m, arc every Ti Xi , = 1, . . . , m. Add arc
Xm child D. Associate X1 function


xpaD = 1 xX1 = xT1
1,
,pa
pX11 (x) = 0,
xpaD = 1 xX1 6= xT1


1/m xpaD 6= 1 .
node Xi , = 2, . . . , m, associate function


1, (xpaD 6=



0, (xpaD 6=
X
,Ti ,paD

pXi1
(x)
=

pa


1, (x
=



0, (xpaD =







xXi
xXi
xXi
xXi

= xXi1 )
6= xXi1 )
= xTi )
6= xTi ) .

pa

Finally, functions pX X child X substituted Xm domain,
without altering numerical values.
Figure 2 depicts decision node many parents (on left) new sub-diagram
generated Transformation 6 (on right). difficult see treewidth
transformed diagram increased three, subgraph containing
new nodes, parents children triangulated contains cliques
|paD {Xi , Xi1 , Di }| variables.3 Also, transformation two different
decision variables affect different parts, hence transforming diagram diagram
parentless decisions increase treewidth three. following
result states also optimality strategies preserved transformation.
3. Since treewidth given size largest clique triangulated moral graph minus one, |paD |
lower bound treewidth original graph.

106

fiSolving LIMIDs

Proposition 7. Let L0 result applying Transformation 6 decision variable
LIMID L, s0 denote strategy L0 , T1 , . . . , Tm denote corresponding
policies T1 , . . . , Tm s0 . Let also policy ( ) = Ti
paD . Finally, let strategy L obtained substituting T1 , . . . , Tm s0
(and keeping remaining policies). optimal strategy L
s0 optimal strategy L0 .
proof appendix. decision variable original LIMID,
transformed model contains chance variables specifying m|D |3 values, decision
nodes |D | states. treewidth original diagram bounded,
bounded transformation takes polynomial time.4 example ten-state
decision variable four ternary parents, transformation replaces decision variable
34 = 81 decision variables whose space policies contain 10 elements each, besides
81 chance variables. combined space policies, is, T1 T81 contains
also 1081 elements, total search space still (doubly) exponential input.
However, algorithms take advantage smaller local policy spaces reach better
solutions, particularly true algorithm devise later on.
rest paper assume without loss generality decision nodes
parents utilities nonnegative.

3. Solving LIMIDs
section, describe new algorithm solving LIMIDs exactly propagating
multiple non-dominated solutions. start defining basic algebraic structure
algorithm, given framework valuation algebra. show
framework alone, similar one used SPU, might lead poor accuracy. thus
extend framework sets valuations attempt improve accuracy increasing
complexity. Efficiency obtained pruning sets cardinality kept small
possible without affecting accuracy.
3.1 Valuation Algebra
basic ingredients algorithmic framework representing handling information LIMIDs called valuations, encode information (probabilities, utilities
policies) elements domain. valuation associated subset
variables U, called scope. concretely, valuation scope x pair (p, u)
nonnegative real-valued functions p u domain x ; refer p u
probability utility part, respectively, . Often, write x make explicit
scope x valuation . x U, denoted set possible
valuations
scope x x . set possible valuations thus given , xU x . set
closed two basic operations combination marginalization. Combination
represents aggregation information defined follows.
Definition 8. = (p, u) = (q, v) valuations scopes x y, respectively,
combination valuation (pq, pv + qu) scope x y.
4. treewidth bounded output algorithm, is, optimal strategy, might
take space exponential input.

107

fiMaua, de Campos, & Zaffalon

Marginalization, hand, acts coarsening information:
Definition 9. = (p, u) valuationP
scope
P x, set variables
x, marginal valuation ( x\y p, x\y u) scope y. case, say
z , x \ eliminated , denote z .
Notice definitions combination marginalization slightly differ previous works influence diagrams (e.g., Lauritzen & Nilsson, 2001), usually require
division utility part probability part. removal division operation
turns important feature discuss maximality valuations later on,
otherwise definition equivalent valuations division, sense one
could easily reformulate message-passing algorithms like SPU using definition.
terms computational complexity, combining two valuations scopes
x y, respectively, requires 3|xy | multiplications |xy | additions numbers;
computing , x, costs |xy | operations addition. words, cost
combining marginalizing valuation exponential cardinality scope (and
linear cardinality domain). Hence, wish work valuations whose
scope small possible. following result shows framework respects
necessary conditions computing efficiently valuations (in sense keeping
scope valuations obtained combinations marginalizations valuations
minimal).
Proposition 10. system (, U, , ) satisfies following three axioms (weak)
labeled valuation algebra (Shenoy & Shafer, 1990; Kohlas, 2003).
(A1) Combination commutative associative, is, 1 , 2 , 3

1 2 = 2 1 ,
1 (2 3 ) = (1 2 ) 3 .
(A2) Marginalization transitive, is, z z x z

(x
=
z )
z .

(A3) Marginalization distributes combination, is, x x ,
x z x
(x )z = x yyz .
Proof. (A1) follows directly commutativity, associativity distributivity product
sum real-valued functions, (A2) follows directly commutativity summarginal operation. show (A3), consider two valuations (p, u) (q, v) scopes
x y, respectively, set z x z x y. definition ,



X
X
[(p, u) (q, v)]z =
pq,
(pv + qu) .
xy\z

108

xy\z

fiSolving LIMIDs

Since x \ z = \ z, p u functions x , follows



X
X
X
X
X

q
v+u
q, p
(pv + qu) = p
pq,
xy\z

y\z

xy\z

y\z

y\z



X X
v ,
= (p, u)
q,
y\z

y\z

equals (p, y) (q, v)yz .
following result Kohlas (2003, Section 2.2) direct consequence (A3)
shall use prove correctness algorithm.
Lemma 11. x x , , z z x = , (x )z = x z
.
primary goal valuation algebra computation marginal valuations
form = (1 ) . Let {X1 , . . . , Xn } set variables appearing
scopes 1 , . . . , . marginal computed efficiently variable elimination
procedure5 receives set = {1 , . . . , } permutation variables
(1)
(k )
X1 , . . . , Xn , = 1, . . . , n replaces valuations , . . . , whose scope contains


(1)
(k ) (Xi )
variable (Xi ) marginal =
. Algorithm 1 describes
procedure. algorithm returns valuation j k , j , . . . , k n ,
equals Axioms (A1)(A3) (Kohlas, 2003, Section 4.1).
Algorithm 1 VariableElimination(x,,)
Input: permutation variables x = {X1 , . . . , Xn } set valuations =
{1 , . . . , } subsets x
Output: marginal valuation (1 )
1: Let 0
2: 1 n
(1)
(k)
3:
Let , . . . , denote valuations i1 whose scope contains (Xi )


(1)
(k) (Xi )
4:
Compute =
(1)

(k)

Let i1 {i } \ {i , . . . , }
6: end
7: return combination valuations n

5:

complexity variable elimination procedure given size largest
valuation generated loop. valuation might size exponential
size valuations 1 , . . . , given input, but, discuss later on, certain
conditions size bounded procedure takes time polynomial
input.
5. Variable elimination algorithms also known literature fusion algorithms (Shenoy & Shafer,
1990) bucket elimination (Dechter, 1999).

109

fiMaua, de Campos, & Zaffalon

3.2 Computing Expected Utilities
use valuation algebra framework introduced compute expected utility
given strategy using variable elimination. Let = (D )DD strategy LIMID
L whose expected utility want compute, permutation variables
C D. assume decision nodes L parents (otherwise need first
apply Transformation 6), strategy simply configuration .
procedure Algorithm 2 computes expected utility induced strategy s.
pa
procedure calls variable elimination set contains valuation C = (pC C , 0)
chance variable, valuation V = (1, uV ) value variable, valuation
= (ID , 0) decision variable. following result.
Algorithm 2 ExpectedUtility(L, , s)
Input: LIMID L whose decision nodes parents, permutation variables
C D, strategy = (D )DD
Output: expected utility
1: Let
2: C C
pa
3:
Add C = (pC C , 0)
4: end
5: V V
6:
Add V = (1, uV )
7: end
8:
9:
Add = (ID , 0)
10: end
11: Let VariableElimination(C D, , )
12: return utility part

Proposition 12. procedure described Algorithm (2) returns expected utility
strategy s.
Proof. Let output Variable Elimination Algorithm. According Axioms
(A1)(A3), = ,
"
# "
# "
#
pa



=
pC C , 0
(ID , 0)
(1, uV ) .
CC

DD

V V

Let p u denote probability
. definition
P utility part, respectively,
Q
pa
combination, = (ps , ps V V uV ), ps = PXCD pX X (1). Since
ps isP
probability
P distribution C D, follows p = xCD ps (x) = 1. Finally,
u = CD ps V V uV , equals Es [L] (2).
Consider LIMID fire dispatching problem (Figure 1) strategy =
(a, w, a) whose expected utility want compute using procedure above. assume
110

fiSolving LIMIDs

utilities nonnegative (i.e., already applied Transformation 3). According procedure Algorithm 2, first generate set = {O = (pTO1 ,T2 ,T3 , 0), V1 =
(1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 = (Ia , 0), T2 = (Iw , 0), T2 =
(Ia , 0)}. X1 = O, X2 = T1 , X3 = T2 , X4 = T3 , let permutation variables
(Xi ) = Xi = 1, . . . , 4. variable elimination algorithm
input produces valuations
1 = (V )O

2 = (V1 T1 1 )T1

3 = (V2 T2 2 )T2

4 = (V3 T3 3 )T3

loop, outputs valuation = 4 = (1, 2). Similarly, compute
expected utility optimal strategy = (a, a, a) run variable elimination
= {O = (pTO1 ,T2 ,T3 , 0), V1 = (1, u0V1 ), V2 = (1, u0V2 ), V3 = (1, u0V3 ), V = (1, u0v ), T1 =
(Ia , 0), T2 = (Ia , 0), T2 = (Ia , 0)}, outputs = (1, 9/2).
general, described procedure take time exponential input. However,
L bounded treewidth shown exists permutation
procedure takes time polynomial input. (e.g., Koller & Friedman, 2009,
Section 23.4.3). Hence, space strategies sufficiently small, find optimal
strategy simply ranking strategies according expected utilities. However,
expect feasible realistic diagram space strategies increases
exponentially number decision nodes (assuming parents), even
diagrams bounded treewidth bounded number states per variable.
3.3 Local Search Algorithms
first attempt design fast algorithm solve LIMIDs, one might suggest local
search scheme starts random solution repeatedly explores neighborhood
order find solution higher expected utility. treewidth diagram
bounded, expected utility neighbor solution efficiently computed,
complexity algorithm given size neighborhood. possible approach
define neighborhood solution strategies obtained changing
single policy, gives local search space polynomial input. Algorithm 3
describes greedy procedure step looks new policy improves
current best solution. algorithm guaranteed find strategy locally
optimal neighborhood, is, cannot improved changing one
policies. Lauritzen Nilsson (2001) stated sufficient conditions diagram
satisfy order guarantee solution produced local search procedure
(globally) optimal. Unfortunately, following example shows, conditions
violated even structurally simple chain diagrams, cases local search
procedure might output local optima poor accuracy.
Consider LIMID running example, suppose start strategy s0 =
(a, w, a), expected utility 2. first step might try improve policy
T1 , producing strategy = (w, w, a) whose expected utility 3. Since higher
expected utility initial solution, set sbest update highest
expected utility found. Next, try search better policy T2 , generate
strategy = (w, a, a). strategy expected utility 2, less
111

fiMaua, de Campos, & Zaffalon

Algorithm 3 GreedyPolicySearch(L, , s0 )
Input: LIMID L, permutation variables C D, initial strategy
s0 = (D )DD
Output: locally optimum strategy sbest
1: Let sbest s0 Esbest [L] ExpectedUtility(L, , s0 )
2: repeat
3:
Generate new candidate strategy replacing single policy sbest
4:
Compute Es [L] ExpectedUtility(L, , s)
5:
Es [L] > Esbest [L]
6:
Set sbest Esbest [L] Es [L]
7:
end
8: current solution cannot improved way
9: return sbest

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 3: chain structure diagram n decision variables.
expected utility best solution found far. Finally, look better policy T3 ,
leads us strategy = (w, w, w), whose expected utility 4. Since better
current best solution set sbest update associated expected utility.
Since change single policy improve strategy, algorithm halts
solution whose expected utility 4 maximum expected utility 9/2 achieved
strategy = (a, a, a) (more 10% relative error), or, terms original diagram
(by means Proposition 4), expected utility zero maximum expected utility
1/2.
procedure described similar SPU algorithm,
illustrates pitfalls local search. fact, SPU output local optimum
(but would start uniform policy every decision variable). Note solution
obtained greedy local search example degrades ratio utility
success (achieved strategy (a, a, a)) utility failure increases. instance,
utility success increased u0V (s) = 10 utility failure remained
same, is, u0V (f ) = 0, algorithm would reach solution whose expected utility
4, error 60% relative maximum expected utility 10. Moreover, cases
SPU performs poorly rare. instance, plots Figure 4 show SPUs relative
performance chain diagrams like one Figure 3. diagram generated
independently sampling conditional distribution associated chance node
symmetric Dirichlet distribution parameter 1/m, number variable
states. maximum expected utility diagram computed using algorithm
devise here, took less 3 seconds diagram experiment.
(blue) point plots Figure 4 depict relative error SPU given
diagram. (red) line indicates third quartile fixed configuration. di112

fiSolving LIMIDs

0.6

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Relative error

0.5
0.4
0.3
0.2
0.1
0
10
20
30
40
50
Number decision nodes

10
20
30
40
50
Number states per variable

Figure 4: Relative performance SPU randomly generated chain diagrams. (blue)
circle depicts experiment (red) line depicts third quartile.
agrams left hand-side plot obtained number states fixed 15,
diagrams right number decision variables fixed ten.
example, see third quartile line right-hand side plot 25%
chain diagrams 20 states ten decision variables, SPU returned strategy
(MEU[L] Es [L])/ MEU[L] 0.1. Also, cases SPU obtains 70%
relative error. hand, see majority cases solution
returned SPU achieved relative error less 10%. all, experiments
show local search effective many cases, may produce poor results.
3.4 Ordered Valuations
also exploit redundancy computation expected utility neighboring
strategies decide whether candidate solution improves current solution without
run variable elimination completely? instance, evaluating quality
new candidate strategy differs current best strategy policy
associated T1 , insight inspecting two valuations 2 produced
variable elimination example Section 3.2 using two different strategies? Fortunately,
answer yes, show need concept ordered valuations.
Let us define partial order (i.e., reflexive, antisymmetric transitive relation)
, set possible valuations, follows.
Definition 13. two valuations = (p, u) = (q, v) , say
dominates (conversely, say dominated ), write ,
equal scope, p q, u v.
scope x, deciding whether dominates costs 2|x | operations
comparison numbers. following result shows algebra valuations
monotonic respect dominance.
Proposition 14. system (, U, , , ) satisfies following two additional axioms
ordered valuation algebra (Haenni, 2004).
113

fiMaua, de Campos, & Zaffalon

(A4) Combination monotonic respect dominance, is,
x x (x ) (x ) .
(A5) Marginalization monotonic respect dominance, is,

x x
x x .

Proof. (A4). Consider two valuations (px , ux ) (qx , vx ) scope x (px , ux )
(qx , vx ), two valuations (py , uy ) (qy , vy ) scope satisfying (py , uy ) (qy , vy ).
definition , px qx , ux vx , py qy uy vy . Since
functions nonnegative, follows px py qx qy , px uy qx vy py ux qy vx .
Hence, (px , ux ) (py , uy ) = (px py , px uy + py ux ) (qx qy , qx vy + qy vx ) = (qx , vx ) (qy , vy ).
(A5). Let subset x. follows monotonicity respect addition
real numbers



X
X
X
X
(px , ux )y =
px ,
ux
qx ,
vx = (qx , vx )y .
x\y

x\y

x\y

x\y

Hence, result follows.
Axioms (A4) (A5) assert combination marginalization preserve partial
ordering valuations. allow us detect suboptimal strategies early
variable elimination procedure. Consider comparing strategies = (w, w, w) s0 =
(w, a, w) LIMID running example. third iteration loop (i.e.,
= 3), variable elimination procedure produces valuations s3 = (ps3 , us3 )
0
0
0
s3 = (ps3 , us3 ) strategies s0 , respectively,
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 3 ,

us3 (w) = 3 ,

0

ps3 (w) = 1 ,

0

0

us3 (w) = 2 .

ps3 (a) = 1 ,

0

us3 (a) = 2 ,
0

0

0

Thus, s3 s3 . Since s4 = (sT3 V3 s3 )T3 s4 = (sT3 V3 s3 )T3 , know
0
Axioms (A4) (A5) s4 s4 , hence Es0 [L] Es [L]. Therefore,
need continue execution variable elimination s0 , expected value cannot
higher s.
Unfortunately, suboptimal solutions always produce valuations dominated optimal one variable elimination. example, consider strategies
= (a, w, a) = (a, a, a). third step, variable elimination generates valuations



s3 = (ps3 , us3 ) s3 = (ps3 , us3 )
ps3 (a) = 1 ,

ps3 (w) = 1 ,

us3 (a) = 2 ,

us3 (w) = 2 ,




ps3 (w) = 1 ,



us3 (w) = 1 .

ps3 (a) = 1 ,



us3 (a) = 9/2 ,
114

fiSolving LIMIDs



Thus, even though optimal strategy, s3 6 s3 .
algorithm devise later exploits fact suboptimal solutions
early detected eliminated search space. suboptimal solutions
might eliminated variable elimination, algorithm runs exponential time
worst case, expected, problem NP-hard. Fortunately,
experiments random problems suggest situations like frequent.
3.5 Sets Valuations
multiple runs variable elimination different inputs elimination ordering (i.e., permutation variables) represented sets framework
algorithm devise later on. instance, might consider set 3 valuations
3 produced variable elimination third iteration loop every possible
strategy. Due monotonicity combination marginalization respect ,
immediately halt computation valuations 3 dominated
other, is, remove dominated valuations 3 . formalized
concept maximal valuations operator max:
Definition 15. Given finite set valuations , say maximal
holds . operator max returns set max()
maximal valuations .
x set valuations scope x, set maximal valuations max(x )
obtained m2 comparisons , (, ) x x .
valuations set x scope x, say x also scope
x. extend combination marginalization sets valuations follows.
Definition 16. x two sets valuations ,
x , {x : x x , }
denotes set obtained combinations valuation x valuation .
Definition 17. x x set valuations scope x x,


x , {x : x x }

denote set valuations obtained element-wise marginalization valuations y.
checked sets valuations combination marginalization defined
element-wise satisfy axioms (A1)(A3), therefore form valuation algebra. Hence,
Lemma 11 applies also sets valuations marginalization combination defined
above.
Lemma 18. x x two sets valuations scope x y,
respectively, z set variables z z x = , (x )z =
x yz .
Proof. result follows element-wise application Lemma 11 (x )z
(x )z .
115

fiMaua, de Campos, & Zaffalon

3.6 Solving LIMIDs Exactly
ready describe MultiplePolicyUpdating (MPU) algorithm,
solves arbitrary LIMIDs exactly. algorithm assumes decision nodes
variables, utilities nonnegative, hence Transformations 6 3
applied running algorithm case assumptions fail.
Consider LIMID L permutation variables C D, let n = |C D|.
pa
algorithm initialized generating set S0 contains singleton {(pC C , 0)}
chance variable C, singleton {(1, uV )} value variable V set
valuations {(pD , 0)}, contains one element (pD , 0) per policy , decision
variable D. set-valued variable elimination performed sets valuations
S0 , dominated valuations discarded set marginalization. Finally,
optimal solution obtained utility part single maximal valuation
set combination sets valuations Sn obtained variable elimination.
procedure detailed Algorithm 4.
Algorithm 4 MultiplePolicyUpdating(L, )
Input: LIMID L permutation variables C
Output: maximum expected utility
1: Let S0
2: C C
pa
3:
Add singleton {(pC C , 0)} S0
4: end
5: V V
6:
Add singleton {(1, uV )} S0
7: end
8:
9:
Add set {(Id , 0) : } S0
10: end
11: 1 n
(1)
(k)
12:
Let , . . . , denote
whose
h sets Si1
scope contains (Xi )

(1)
(k) (Xi )
13:
Compute = max
(1)

(k)

Let Si Si1 {i } \ {i , . . . , }
15: end
16: Let denote set combination sets Sn
17: return utility part u (p, u) max(S)

14:

Since variables eliminated end loop, valuations sets
empty scope probability utility parts identified
numbers. Hence, algorithm outputs expected utility (i.e., real number) line 17.
Let us illustrate algorithm example. more, consider LIMID L
fire dispatching problem applying Transformation 3 assume elimination
ordering variables used example Section 3.2. start empty set
116

fiSolving LIMIDs

S0 . chance variable, add set
= {(pTO1 ,T2 ,T3 , 0)}
S0 . add sets
V1 = {(1, u0V1 )} ,

V2 = {(1, u0V2 )} ,

V3 = {(1, u0V3 )} ,

V = {(1, u0V )}

S0 due value variables V1 , V2 , V3 V , respectively. decision variable T1
causes set
T1 = {(Ia , 0), (Iw , 0)}
scope T1 included S0 , similarly, variables T2 T3 , is, add
sets
T2 = {(Ia , 0), (Iw , 0)} ,

T3 = {(Ia , 0), (Iw , 0)} ,

scopes T2 T3 , respectively, S0 , obtaining S0 = {O , V1 , V2 , V3 , V , T1 , T2 , T3 }.
first iteration (i = 1) variable elimination loop (lines 1115),


1 = max [V ]O = {(p1 , u1 )} ,
p1 u1 functions T1 ,T2 ,T3 p1 = 1 u1 (a, a, a) = 9/2,
u1 (x) = 1 x 6= (a, a, a). Note 1 singleton since singletons
involved computation. second iteration


w
2 = max [V1 T1 1 ]T1 = {(pa2 , ua2 ), (pw
2 , u2 )} ,
w

w

pa2 , ua2 , pw
2 , u2 functions T2 ,T3 p2 = p2 = 1, u2 (a, a) = 9/2,

w
u2 (x) = 1 x 6= (a, a), u2 = 2. Note labeled functions
according policies T1 generated them. allows us easily extract
optimal strategy end algorithm.
third iteration need compute


3 = max [V2 T2 2 ]T2
(a,a)

= max({(p3
(a,a)

= {(p3
(a,a)

(a,a)

(a,w)

(a,a)

, u3

(a,a)

(a,w)

), (p3

(w,w)

(a,w)

, u3

(w,w)

, u3

), (p3

, u3

(a,w)

(w,w)

(w,w)

(w,w)

), (p3

(w,w)

, u3

)})

)} ,
(a,a)

p3 , u3 , p3
, u3
, p3
, u3
functions T3 p3
=
(a,w)
(w,w)
(a,a)
(a,a)
(a,w)
(w,w)
p3
= p3
= 1, u3 (a) = 9/2, u3 (w) = 1, u3
= 2, u3
= 3. Note
valuation associated policies T2 = w T2 = appear 3
(a,w) (a,w)
generate valuation equal (p3
, u3
). implies strategies (a, w, w)
(w, a, w) expected utility, also strategies (a, w, a) (w, a, a).
117

fiMaua, de Campos, & Zaffalon

last iteration, generate set


4 = max [V3 T3 3 ]T3
(a,a,a)

(a,a,a)

= max({(p4

, u4

(a,a,a)

(a,a,a)

= {(p4

, u4

(a,a,a)

(a,a,a)

(w,w,a)

), (p4

(w,w,a)

, u4

(a,a,w)

), (p4

(a,a,w)

, u4

(w,w,w)

), (p4

(w,w,w)

, u4

)})

)} ,
(w,w,a)

(w,w,a)

(a,a,w)

(a,a,w)

(w,w,w)

(w,w,w)

p4
, u4
, p4
, u4
, p4
, u4
, p4
, u4
functions
(a,a,a)
(w,w,a)
(a,a,w)
(w,w,w)
(a,a,a)
empty set p4
= p4
= p4
= p4
= 1, u4
= 9/2,
(w,w,a)
(a,a,w)
(w,w,w)
u4
= 3, u4
= 2, u4
= 4.
(a,a,a)
Finally, S4 = {4 }, algorithm returns u4
= 9/2,
expected utility optimal strategy (a, a, a). one see, optimal strategy
easily recovered labeling valuations corresponding policies.
Differently message-passing algorithms obtain approximate solutions
LIMIDs (repeatedly) propagating single valuation (e.g., SPU algorithm),
MPU algorithm computes exact solutions propagating several maximal valuations
correspond partial combinations local decision rules. efficiency algorithm
handling propagation many valuations derives early removal valuations
performed max operation propagation step.
Consider set L , {s : }, given
"

#


=

pa

pC C , 0



"


CC

#


DD

(Id , 0)

#!

"


(1, uV )

V V

functions Id consistent policies s. difficult see
#

"


L =


pa
pC C , 0

CC



#


{(Id , 0) : }

#!

"


{(1, uV )}

V V

DD




=

"



X

.

X S0

Hence, Proposition 12 L valuation probability part
one utility part equal expected utility strategy . Since relation
induces strict (linear) order L , MEU diagram equals utility part
(single) valuation max(L ).
N variable elimination procedure propagation
step responsible
Nfor obtaining max( Sn ) = max(L ) efficiently distributing
max X S0 X , allows significant reduction cardinalities
sets scopes valuations produced.
formally prove correctness algorithm. start showing max
distributes marginalization combination:
Lemma 19. (Distributivity maximality). x x two finite sets
ordered valuations z x, following holds.
118

fiSolving LIMIDs

(i) max(x max(y )) = max(x );
(ii) max(max(x )z ) = max(z
x ).
Proof. Part (i) shown Fargier, Rollon, Wilson (2010, Lemma 1(iv)).
use similar proof show part (ii) also holds. First, show max(z
x )
z
z
max(max(x ) ). Assume, show contradiction, element x max(z
x ),
x x , element max(max(x )z ). definition max(x ),
z
z
z
x max(x ) x x . Hence, (A5) implies z
x x , x x
z
z
z
z
follows z
/ max(max(x )z )
x = x , therefore x max(x ) . Since x
z max(max(x )z ) z
x z . contradicts initial assumpz
tion since z x .
Let us show max(xz ) max(max(x )z ). Assume contradiction
z
z
z max(max(x )z ) \ max(z
x ). Since z x , z max(x )
z
z z . shown max(x ) max(max(x )z ), hence z = z
z max(z
x ), contradiction.
iteration propagation step, combination sets current pool
sets Si produces set maximal valuations initial factorization marginalized
Xi+1 , . . . , Xn :
Lemma 20. {0, 1, . . . , n}, follows

{X1 ,...,Xi }






max

,
= max
S0

Si

i, Si collection sets valuations generated i-th iteration
propagation step MPU.
Proof. induction i. basis (i = 0) follows trivially.
Assume result holds i, is,



{X1 ,...,Xi }




max

.
= max
Si

S0

eliminating Xi+1 sides applying max operation get

{X1 ,...,Xi } Xi+1

Xi+1







max max



= max max
.




S0

Si

119

fiMaua, de Campos, & Zaffalon

Applying Lemma 19(ii) sides (A2) left-hand side yields


{X1 ,...,Xi+1 }
Xi+1




max


= max

S0

Si



= max

Xi+1











Bi+1

Si \Bi+1



= max



Xi+1


max






Bi+1

Si \Bi+1


= max








Si \Bi+1


= max




,

Si+1

passage first second identity follows element-wise application
(A1) Lemma 11, third follows second Lemma 19(i), last two
follow definitions Si+1 , respectively.
able show correctness algorithm solving LIMIDs exactly.
Theorem 21. Given LIMID L, MPU outputs MEU[L].

N
Proof. algorithm returns utility part valuation (p, u) max
, which,

n
N

Lemma 20 = n, equals max

. definition S0 , valuation
S0

N

S0 satisfies
"
=

#

CC


pa
pC C , 0

"


#


DD

(Id , 0)

"

#


(1, uV ) ,

V V

combination decisions (d)
N , corresponds strategy ,
exactly one valuation
S0 strategy . Hence, Propo
N
sition 12, set
contains pair (1, Es [L]) every strategy inducing
S0
distinct expected utility. Moreover, since functions empty scope correspond

N
numbers, relation specifies total ordering valuations
,
S0
strategy associated (p, u). Since
implies single maximal
element.
Let

N

(p, u) max

, follows maximality Es [L] Es [L] s,
S0
hence u = MEU[L].
120

fiSolving LIMIDs

3.7 Complexity Analysis
variable elimination, complexity algorithm depends permutation given input. time complexity algorithm given cost creating
sets valuations initialization step plus overall cost combination
marginalization operations performed propagation step. Regarding initialization step, loops chance value variables generate singletons, thus take time
linear input. Since decision nodes parents, set added due decision variable contains , |D | valuations. Let , maxDD cardinality
largest domain decision variable. initialization loop decision variables
takes O(|D|) time, polynomial input. Let us analyze propagation
step. running time propagating (sets of) valuations exponential maximum
number variables scope valuations generated loop step.
number depends permutation chosen best case equal treewidth
diagram plus one. Although finding optimal permutation (i.e., one leads
minimum maximum number variables per scope) NP-hard task, generate
permutations using standard heuristics variable elimination Bayesian networks,
minimizing number fill-ins cardinality domain neighbor
set, empirically shown produce good elimination orderings (Jensen &
Nielsen, 2007; Koller & Friedman, 2009).
Consider permutation induces maximum number variables per scope
, diagram bounded number states per variable . cost
combination marginalization bounded constant, complexity depends
number operations performed. Moreover, case .
Let denote cardinality largest set , = 1, . . . , n. Thus, computing
requires |U |1 operations combination (because
maximum number
N
sets might need combine compute Bi propagation step)
operations marginalization. worst case, equal |D| O(|D| ), is,
sets associated decision variables combined without discarding valuation.
Hence, worst-case complexity propagation step exponential number
decision variables, even width elimination ordering number states per
variable bounded. Note however pessimistic scenario and, average,
removal non-maximal elements greatly reduces complexity, experiments
Section 4 show.
3.8 Reverse Topological Ordering
valuations used MPU specify twice many numbers cardinality domain
associated scope. possible decrease number numerical parameters per
valuation algorithm needs handle factor two constraining elimination
variables follow reverse topological ordering according diagram, is,
requiring variable processed descendants processed.
following result shows, reverse topological ordering produces valuations whose
probability part equals one coordinates.

121

fiMaua, de Campos, & Zaffalon



B

V1



C

E

V2

F

Figure 5: LIMID reverse topological ordering increases treewidth.

Proposition 22. defines reverse topological ordering variables C D,
= 1, . . . , n valuations probability part p = 1, 1 function
always returns unity.
Proof. show result induction i. Regarding basis, reverse
topological ordering X1 variable containing value nodes children. Hence,
paX
B1 = {X1 } {{(1, uV )} : V chX1 }, definition X1 equals {(pX1 1 , 0)}
paX

paX

X1 chance node, {(pX1 1 , 0) : pX1 1 PX1 } decision node. follows
P
paX P
paX P
1 = max({( X1 pX1 1 , X1 pX1 1 V chX uV )}). Since paX , p
X1
1
1
P
paX
1
probability mass function X1 , p =
= 1. Assume
X1 pX1
N
inductive hypothesis


result
holds

1,
.
.
.
,


1,

let

,
x
Bi \S0 .
N
= max([ Bi S0 ] x ). inductive hypothesis valuations set Bi \ S0
probability part p = 1. Hence, definition combination, valuations x
contain also probability part equal one. reverse topological ordering implies
time variable Xi processed propagation step, children
paX
processed. Hence, element Bi S0 set Xi , equals {(pXi , 0)} Xi
paX

paX

chance node, {(pXi , 0) : pXi PXi } Xi decision node, {(1, uXi )}
value node. Thus, = max(Xi x ). case Xi value node
immediate, since valuation result combination two valuations
probability part equal one. Xi value node


X


paX X paX
paX
= max
pXi ,
pXi ux : (pXi , 0) faXi , (1, ux ) x
Xi

Xi



X


paX
paX
= max 1,
pXi ux : (pXi , 0) Xi , (1, ux ) x ,
Xi

since p
Xi probability mass function paX .


result states assume reverse topological elimination ordering, MPU
needs care utility part valuations. Unfortunately, constraining
elimination order might increase complexity algorithm, following example
shows.
Consider LIMID Figure 5, variables assumed binary (we omit
specification probabilities utilities relevant matter).
122

fiSolving LIMIDs

initialization, S0 = {A , B , C , , E , F , V1 , V2 }. Using reverse
topological elimination ordering implies first eliminate E, generates
set


1 = max [E , V1 V2 ]E = {(1, u1 )} ,

whose single element (1, u1 ) scope {A, C, D, F } size 24 = 16. Eliminating variables
ordering F, C, B, A, D, E, hand, generates following sets.


1 = max [F V2 C ]F = {(p1 , u1 )} ,


2 = max [C E 1 ]C = {(p2 , u2 )} ,

n

(d) (d)
3 = max [B ]B = (p3 , u3 ) : ,

n

(d) (d)
4 = max [A V1 3 ]A = (p4 , u4 ) : ,
n


(d) (d)
5 = max [2 4 ]D = (p5 , u5 ) : ,
n


(d)
=
(1,
u
)
:



.
6 = max E

5
6
scopes valuations 1 , 2 , 3 , 4 , 5 6 are, respectively, {E, C}, {D, E},
{D, A}, {E, D}, {E} {}. one see, largest valuation generated using ordering
F, C, B, A, D, E contains two variables scope therefore size 22 = 4.
four-fold decrease size compared size set 1 generated using reverse
topological ordering.
Notice however even though using reverse topological ordering might increase
size valuations generated variable elimination, necessarily results
higher complexity MPU. overall complexity algorithm
depends size largest valuation generated also cardinality
generated sets, possible reverse topological ordering induces significantly
smaller sets, produces valuations whose probability parts always equal one,
might increase number dominated elements.

4. Experiments
evaluate performance algorithm random LIMIDs generated following
way. LIMID parameterized number decision nodes , |D|, number
chance nodes c , |C|, maximum cardinality domain family chance
variable C , maxC |faC |, maximum cardinality domain family
decision variable , maxD |faD |. set number value nodes v + 2.
variable Xi , = 1, . . . , c + + v, sample Xi contain 2 4 states.
repeatedly add arc decision node children value node
parents (so decision node least one value node children).
step guarantees decisions relevant computation MEU. Finally,
repeatedly add arc neither makes domain variable greater given
bounds makes treewidth 10, arcs added without exceeding
123

fiMaua, de Campos, & Zaffalon

bounds.6 Note generates diagrams decision chance variables
log2 1 log2 C 1 parents, respectively. DAG obtained,
randomly sample probability mass functions utility functions associated chance
value variables, respectively.
compare MPU CR algorithm de Campos Ji (2008) 1620 LIMIDs
randomly generated described procedure parameters 5 50, 8 c 50,
8 64 16 C 64. MPU implemented C++ tested
computer CR.7 Table 1 contrasts running times algorithm (averages
standard deviation) different configurations randomly generated LIMIDs. row
contains percentage solved diagrams (SCR SMPU ) time performance (TCR
TMPU ) algorithms N diagrams randomly generated using parameters
d, c, v, , C . fixed parameter configuration, MPU outperforms CR
orders magnitude (line 12 contains case average running time
CR lower MPUs, note case CR solve one instance, whereas
MPU solved 86% instances). Also, CR unable solve diagrams
50 variables, whereas MPU could solve diagrams containing 150 variables
32. algorithms failed solve diagrams = 64. diagram
consider unsolved algorithm algorithm able reach exact solution
within limit 12 hours. all, MPU appears scale well number nodes
(i.e., d, c v) poorly domain cardinality family decision variables
(i.e., ).
good succinct measure hardness solving LIMID total number
strategies ||, represents size search space brute-force approach. ||
also loosely interpreted total number alternatives (over decision variables)
problem instance. Figure 6 depicts running time number strategies
log-log scale two algorithms test set random diagrams.
algorithm, solved instances shown, covers approximately 96% cases
MPU, 68% CR. note MPU solved cases CR solved (but
opposite). Again, see MPU orders magnitude faster CR. Within limit
12 hours, MPU able compute diagrams containing 1064 strategies, whereas
CR solved diagrams 1025 strategies.
reduction complexity obtained removal non-maximal valuations
propagation step checked Figure 7, shows maximum cardinality
set generated propagation step contrast number strategies.
diagram (a point figure) solved MPU, cardinality sets remains bounded
106 vary number strategies (which equals largest cardinality
propagated set worst case valuation discarded). shows
worst-case analysis Section 3.7 pessimistic.
6. Since current algorithms checking whether treewidth graph exceeds fixed k slow
k 5 (Bodlaender, 1996), resort greedy heuristic resulted diagrams whose actual
treewidth ranged 5 10.
7. used CR implementation available http://www.idsia.ch/~cassio/id2mip/ CPLEX
(http://www.ilog.com) mixed integer programming solver. implementation MPU
downloaded http://www.idsia.ch/~cassio/mpu/.

124

fiSolving LIMIDs

N



c

v



C

SCR (%)

TCR (s)

SMPU (%)

TMPU (s)

60
60
60
60
60
60
60
60
30
30
60
30
30
60
60
90
30
60
30
30
60
60
30
60
60
60
60
30
60
30
30
30
30

5
5
5
10
10
10
10
10
10
10
10
10
10
10
20
20
20
20
20
20
20
10
10
20
20
20
30
30
30
30
30
50
50

8
8
8
8
8
8
28
28
28
28
28
28
28
28
8
8
8
8
8
8
8
78
78
58
58
58
38
38
38
88
88
48
48

7
7
7
12
12
12
12
12
12
12
12
12
12
12
22
22
22
22
22
22
22
12
12
22
22
22
32
32
32
32
32
52
52

12
16
8
12
16
8
12
16
16
32
32
32
64
8
12
16
16
32
32
64
8
16
32
12
16
8
12
16
8
12
8
12
8

16
16
16
16
16
16
16
16
64
16
32
64
64
16
16
16
64
32
64
64
16
16
16
16
16
16
16
16
16
16
16
16
16

100
100
100
98
93
100
96
83
10
93
0
3
0
100
93
38
30
0
0
0
100
60
70
50
11
96
28
0
96
0
60
0
10

6 45
9 43
6 51
15 53
107 273
0.4 0.2
1175 6126
3340 8966
2838 1493
1070 2461

73 0

13
2687 7564
5443 10070
9660 10303



7 20
5944 9920
3820 8127
6455 9344
11895 12662
849 4098
3416 4827

2261 6572

3448 5837

5014 2974

100
100
100
100
100
100
100
100
96
100
93
86
0
100
100
98
100
78
76
0
100
100
100
100
100
100
98
100
100
100
100
96
100

0.006 0.01
0.02 0.05
0.002 0.01
0.02 0.02
103 786
0.007 0.01
0.05 0.08
0.2 0.2
47 142
0.2 0.4
905 2847
2440 7606

0.01 0.007
155 1196
270 1822
29 84
938 1417
1592 3402

0.02 0.008
0.5 0.5
0.6 1
522 4011
2 11
0.07 0.04
35 214
2 10
0.1 0.03
230 1027
0.2 0.1
1753 7405
0.5 0.09

Table 1: Performance MPU CR randomly generated LIMIDs (numbers
rounded down).

125

fiMaua, de Campos, & Zaffalon

105

MPU
CR

Running time (s)

104
103
102
101
100
101
102
101

1020
1040
1060
Number strategies (||)

Maximum set cardinality (maxi |i |)

Figure 6: Running time MPU CR randomly generated LIMIDs.
106
105
104
103
102
101
100
101

1020
1040
1060
Number strategies (||)

Figure 7: Maximum number valuations set propagation step MPU.

5. Related Work
Influence diagrams introduced Howard Matheson (1984) concise language
specification utility-based decision problems. substantial literature
formalizes influence diagrams develop algorithms premises forgetting
regularity (Cooper, 1988; Qi & Poole, 1995; Shachter & Peot, 1992). point
interested reader works Jensen Nielsen (2007) Koller Friedman (2009).
Zhang et al. (1994) studied families LIMIDs could solved dynamic programming, LIMIDs respecting forgetting regularity. SPU algorithm
Lauritzen Nilsson (2001) solves cases polynomial time diagram
126

fiSolving LIMIDs

bounded treewidth. best knowledge, attempt (globally) solve arbitrary LIMIDs exactly without recurring exhaustive search space strategies
CR algorithm de Campos Ji (2008) compare algorithm.
Shenoy Shafer (1990) introduced framework valuation algebras, states
basic algebraic requirements efficient computation valuations. recently,
Haenni (2004) incorporated partially ordered preferences algebra enable approximate computation. Fargier et al. (2010) extended framework preference
degree structure order capture common algebraic structure optimization problems based partial order. algebra develop Section 3 partly casted
framework.
PFU framework Pralet, Verfaillie, Schiex (2007) subsumes many formalisms
probabilistic reasoning, constraint satisfaction decision making. comes
decision problems framework geared towards sequential decision making
equivalent assumptions non-forgetting, although authors mention possibility
extending limited information decision scenarios.
variable elimination algorithm develop conceptually close message
passing algorithm Dubus, Gonzales, Perny (2009). algorithm, however,
handle uncertainty target primarily obtention Pareto-efficient solutions
specific class multi-objective optimization problems.
close relation maximum posteriori (MAP) inference Bayesian
networks LIMIDs whose decision variables parents. sense, algorithm de Campos (2011), solves MAP propagating Pareto efficient probability
potentials join tree, relates ours.

6. Conclusion
Solving limited memory influence diagrams hard task. complexity results
presented show problem NP-hard even diagrams bounded treewidth
number states per variable, obtaining provably good approximations
polynomial time unlikely number states small.
Despite theoretical hardness problem, developed algorithm
spite exponential worst-case complexity performed empirically well large set
randomly generated problems. algorithms efficiency based early removal
suboptimal solutions, helps algorithm drastically reduce search space.
Designing good heuristics elimination orderings algorithm seems
complex task standard variable elimination algorithms (e.g., belief
updating Bayesian networks), second component, cardinality
set, together domain cardinalities wish minimize. fact, preliminary
experimentation shown favoring set cardinality expense domain cardinality
might good approach. Unlike standard variable elimination, given elimination
ordering LIMID, seem possible determine true complexity
MPU advance (i.e., prior running algorithm). open question whether
MPUs complexity estimated beforehand, heuristics finding elimination
orderings perform better.
127

fiMaua, de Campos, & Zaffalon

Acknowledgments
work partially supported Swiss National Science Foundation (SNSF)
grants no. 200020 134759/1, 200020 137680/1 200020 132252, Hasler Foundation grant
no. 10030, Canton Ticino Computational Life Sciences Project. thank
reviewers pointing us related work making number comments helped
us improve readability paper. short version paper appeared NIPS
11 (Maua & de Campos, 2011).

Appendix A. Missing Proofs
section contains long proofs supporting results left main part
text improve readability.
following two lemmas used proof Theorem 1 later on.
Lemma 23. 2 real number nonnegative integer 2 + 2(i+3) <

2+2 .
Proof. Since 2 22 , 2 + 2(i+3) = 2 + 22 2i1 2 (1 + 2i1 ),

sufficient show 1 + 2i1 < 22 . Binomial Theorem


(1 + 2

i1 2i

)

=

2
X
2
k=0

k

(2i1 )k .

k = 0, . . . , 2i ,

2
2i (2i 1) (2i k + 1)
=
(2i )k .
k
k!
Hence,


(1 + 2

i1 2i

)



2
2

X
X
X
k i1 k
k

(2 ) (2
) =
2
2k = 2 ,
k=0

2i

therefore 1 + 2i1 < 2

k=0

k=0

.
4

Lemma 24. 0 x 1/2 2x1 + 2x1 2x .
Proof. obtain result approximating functions left- right-hand side
inequalities truncated Taylor expansions f (x) g(x), respectively,
4
showing 2x1 + 2x1 f (x) g(x) 2x . n-th order Taylor expansion
left-hand side around zero given
Tn (x) = 1 +

n/2
X
[ln(2)]2k
k=1

(2k)!

x2k .

Clearly, series converges hence 2x1 + 2x1 = limn Tn (x). Moreover,
n, residual Rn (x) = 2x1 + 2x1 Tn (x) positive terms sum
128

fiSolving LIMIDs

non negative. Thus,
f (x) = T2 (x) = 1 +

[ln(2)]2 2
x 2x1 + 2x1 .
2

similar fashion, apply variable change = x4 right-hand side
obtain Taylor expansion around zero, given
Tn0 (y) = 1 +
=1+

n
X
[ln(2)]k
k=1
n
X
k=1

k!

yk

[ln(2)]k 4k
x ,
k!

also converges positive residual. Hence,
4

2x = lim Tn0 (x)
n

= 1 + x4 ln(2) + x2 ln(2)


X
[ln(2)]k1
k=2

1 + x4 ln(2) + x2 ln(2)


X
k=2

= 1 + x4 ln(2) +

[ln(2)]2
32

1

k!
!

!
x4k2

24k1

x2 = g(x) .

inequality obtained noticing [ln(2)]k1 /k! < 1/2, x 1/2 ln(2)
geometric series

X
k=2

1
24k1




1 X 1 k
1
ln(2)
1 X 1 k
< 7
= 6 <
.
= 7
4
2
2
2
2
2
32
k=0

k=0

Finally, since x2 1/4 < 15 ln(2)/32


ln(2)
2
g(x) = 1 + x ln(2) x +
32


15
ln(2)
2
< 1 + x ln(2)
ln(2) +
32
32
2
[ln(2)] 2
=1+
x = f (x) .
2
2

4

Hence, 2x g(x) f (x) 2x1 + 2x1 result holds.
following result shows solving LIMIDs NP-hard even assume bounded
treewidth number states per variable.
129

fiMaua, de Campos, & Zaffalon

X0

D1

D2

X1

X2

Dn



Xn

R

Figure 8: LIMID used solve partition problem Proof Theorem 1.

Proof Theorem 1. Given strategy s, deciding whether Es [L] > k done polynomial time (Koller & Friedman, 2009), problem NP. Hardness shown using
reduction partition problem, NP-complete (Garey & Johnson, 1979)
stated follows. PGiven set
P n positive integers a1 , . . . , , set
= {1, . . . , n} iI ai = iA\I ai ? assume n > 3.
P
P
Let = 21 iA ai . even partition subset achieves iI ai = a.
solve partition, consider rescaled problem (dividing every element
a),
P
vP
= ai /a 2 elements look partition
iI vi = 1 (because
v
=
2).
iA
Consider following LIMID topology Figure 8. n binary decision
nodes labeled D1 , . . . , Dn . decision Di take states d1 d2 . chain
chance nodes n + 1 ternary variables X0 , X1 , . . . , Xn states x, y, z.
arc Xn single value node R. notational purposes, specify function
f domain {x, y, z} triple (f (x), f (y), f (z)). value node associated
utility function uR = (0, 0, 1). = 1, . . . , n, chance node Xi associated set
conditional probability mass functions given
d1 ,x
= (ti , 0, 1 ti ),
pX


d2 ,x
= (1, 0, 0),
pX


pdX1i,y = (0, 1, 0),

pdX2i,y = (0, ti , 1 ti ),

pdX1i,z = (0, 0, 1),

pdX2i,z = (0, 0, 1),
DX

ti [0, 1] (we specify variables later on). Note pXii i1 (w) = 0 every
w faXi wXi 6= wXi1 wXi 6= z. Finally, define pX0 = (1/3, 1/3, 1/3).
Given strategy = (D1 , . . . , Dn ), let , {i : Di = d1 } index set policies
Di () = d1 .
Es [L] =

X

pX0

CD

n


!
DX
pXii i1 pDi

i=1


=

X

X

pX0


Xn

uR

n



Xi1

pXii

i=1

CD\{Xn }

Let
ps , pX0

n


Xi1

pXii

i=1

130

pDi

pDi uR .

fiSolving LIMIDs


X

pXn ,

n


pX0

Xi1

pXii

i=1

CD\{Xn }

X

pDi =

ps .

CD\{Xn }
Xn1

w CD wXn = x (i.e., w xCD ) follows pXnn
0 wXn1 = x. wXn1

(wfaXn ) 6=


Xn2
= x pXn1
(wfaXn1 ) 6= 0
n1
DX
Also, {1, . . . , n}, pXii i1 (wfaXi )

wXn2 = x recursively.
equals ti 1 otherwise. Hence,
( Q
1
ti , wXi = x = 1, . . . , n 1
ps (w) = 3 iI
0,
otherwise,


n

1Y
ti .
ps (w) =
3
CD

X

pXn (x) =

iI

wx

Likewise, holds w CD
( Q
ps (w) =

1
3

iA\I ti ,

0,

wXi = = 1, . . . , n 1
otherwise,

therefore
pXn (x) =

n
1
ti .
3
iA\I

Since pXn probability mass function Xn , pXn (z) = 1 pXn (x) pXn (y),
X
pXn uR
Es [L] =
Xn

= 1 pXn (x) pXn (y)
1Y
1
=1
ti
ti .
3
3
iI

iA\I

Let us assume initially ti = 2vi . reduction original problem
way polynomial, use upper bound outcome
reduction obtain later. difficult
see
P
P Es [L] concave function
v1 , . . . , vn achieves maximum iI vi = iA\I vi = 1. Since strategy
defines partition vice-versa, even partition MEU[L] =
1 1/3(1/2 + 1/2) = 2/3.
show reduction encodes numbers ti time space polynomial
b, number bits used encode original problem. part close analogy
last part proof hardness MAP Bayesian networks de Campos
(2011, Theorem 10).
setting ti represent 2vi 6b + 3 bits precision (rounding necessary),
is, choosing ti 2vi ti < 2vi + , 0 < 2(6b+3) ,
131

fiMaua, de Campos, & Zaffalon

2vi ti < 2vi + 2(6b+3) , implies (by using Lemma 23 = vi 2
6b
= 6b) 2vi ti < 2vi +2 .
Assume even partition exists. Then8
P

6b
6b
5b
ti < 22 n iI vi = 21+2 n 21+2 ,
iI



6b n

< 22

P

iA\I

vi

6b n

= 21+2

5b

21+2

,

iA\I



5b


22
1 1+25b
5b
2
+ 21+2
=1
.
MEU[L] > 1
3
3

(6)

5b

Let r equal 22
encoded 5b + 3 bits precision (and rounded up), is,
5b
5b
2
2
(5b+3)
2
r<2
+2
, implies (by Lemma 24 = 25b 2 = 5b)

5b
5b
5b
15b
4b
22
r < 22 +2
= 22
< 22 .
(7)
reduction done verifying whether MEU[L] > 1 r/3. already know
even partition associated strategy obtains expected utility greater
1 r/3, Equality (6) fact r rounded up. Let us consider
case even partition exist. want show case MEU[L]
4b
1 22 /3, Inequality (7) implies MEU[L] < 1 r/3. Since even
partition, strategy induces
partition
P
P that, integer c different
zero, iI ai = ac iA\I ai = a+c, original numbers
ai positive integers add 2a. follows


ti +
ti = 2c/a1 + 2c/a1 .
iI

iA\I

right-hand side equality function c {a, . . . , a}\{0}, symmetric
respect y-axis (i.e., f (c) = f (c)) monotonically increasing c > 0.
Therefore, obtains minimum c = 1. Hence,


ti +
ti 21/a1 + 21/a1 .
iI

iA\I

Since n > 3 implies 2 (because numbers ai positive integers),
Lemma 24
4
21/a1 + 21/a1 21/a .
number ai encoded least log2 ai bits, therefore b log2 (a1 ) + +
log2 (an ) = log2 (a1 ). latter greater equal log2 (a1 + + ),
hence also greater log2 a. Thus, 2b , implies a4 24b
4
4b
therefore 1/a4 24b 21/a 22 . Hence,
4b

21/a1 + 21/a1 22

.

8. Since number bits used encode partition problem must greater equal n,
n/2b n/b 1, hence 2(j+1)b n < 2jb , j > 0.

132

fiSolving LIMIDs

Thus, even partition exist


4b

22
1
ti 1
MEU[L] = 1
ti +
< 1 r/3 .
3
3
iI

iA\I

summarize, built LIMID L polynomial time since ti specified
DX
using O(b) bits n functions pXii i1 , encoding 18 numbers (which
either 1, 0 ti ), 2n + 2 variables bounded number states. shown
one-to-one correspondence partitions original problem
strategies L, given rational r = f (b) encoded O(b) bits existence
even partition equivalent MEU[L] > 1 r/3.
following lemma used proof Theorem 2. similar result shown
Park Darwiche (2004, Lemma 9).
Lemma 25. x 1 follows x + 1/2 > 1/ ln(1 + 1/x).
Proof. Let f (x) = ln(1 + 1/x) 1/(x + 1/2).
f 0 (x) =

x2

1
1
+ 2
,
+ x x + x + 1/4

strictly negative x 1 since x2 +x < x2 +x+1/4. Hence, f (x) monotonically
decreasing function x 1. limx f (x) = 0, f (x) strictly positive [1, ).
Thus, result follows ln(1 + 1/x) > 1/(x + 1/2), since x 1.
show approximately solving LIMIDs bounded treewidth given
minimum performance NP-hard.
Proof Theorem 2. show fixed 0 < < 1 existence polynomial

time 2 -approximation algorithm solving LIMID would imply existence
polynomial time algorithm CNF-SAT problem, known impossible
unless P=NP (Garey & Johnson, 1979). similar reduction used Park
Darwiche (2004, Theorem 8) show analogous inapproximability result maximum
posteriori inference Bayesian networks. Notice 1 < < 2 0 < < 1

= 2 , hence existence -approximation algorithm implies existence

2 -approximation, suffices desired result show latter cannot
true (unless P=NP).
clause disjunction literals, literal either boolean variable
negation. say clause satisfied if, given assignment truth values
variables, least one literals evaluates 1. Thus, decide truth-value
assignment satisfies clause time linear number variables. CNF-SAT
problem defined follows. Given set clauses C1 , . . . , Cm (subsets ) boolean
variables X1 , . . . , Xn , assignment truth values variables satisfies
clauses?
positive integer q specify later on, consider LIMID obtained follows
(the topology depicted Figure 9). boolean variable Xi add q binary
133

fiMaua, de Campos, & Zaffalon

B1
Dn1

Sn1

Dn2

Bq
Dnq

Sn2

.
.
.
D11



B2

.
.
.

S11

D12

Snq

.
.
.
D1q

S12

S01

U

S1q
S0q

S02

Figure 9: Graph structure LIMID used proof Theorem 2.

decision variables Di1 , . . . , Diq q chance variables Si1 , . . . , Siq domain {0, 1, . . . , m}.
Additionally, q clause selector variables S01 , . . . , S0q taking values {1, 2, . . . , m},
q binary variables B 1 , . . . , B q , value node U B q parent. illustrated
Figure 9, LIMID consists q replicas polytree-shaped diagram variables
D1j , . . . , Dnj , S0j , . . . , Snj , B j , probability mass functions variables B 1 , . . . , B q
chosen make expected utility equal product expected utilities
replica. replicas (i.e., j {1, . . . , q}), variable Dij (i = 1, . . . , n)
represents assignment truth value Xi parents. selector variables
S0j represent choice clause process, is, S0j = k denotes clause Ck
processed, summing S0j process clauses. variable Sij , =
j
1, . . . , n j = 1, . . . , q, Dij Si1
parents. variables B j Snj and,
j > 1, B j1 parents. j, assign uniform probabilities S0j , is, pS j , 1/m.
0

j = 1, . . . , q, set probabilities associated variables S1j , . . . , Snj Ck
clause selected S0j Sij set zero Ck satisfied Di
j
D1 , . . . , Di1 , Sij = Si1
otherwise. Formally, x {S j ,Dj ,S j }




1,




j j

1,
p ji i1 (x) ,
Si
1,




0,



i1

j

j

xSi = xSi1 = 0 ;
j

j

xSi = 0 xSi1 = k 1 Xi = xDi satisfies Ck ;
j

j

xSi = xSi1 = k 1 Xi = xDi satisfy Ck ;
otherwise.

Notice S1j first case never occurs since S0j takes values {1, . . . , m}.
j
joint state configuration x S0j , . . . , Snj , D1j , . . . , Dnj xS0 = k {1, . . . , m} (i.e.,
j
clause Ck processed) xSn = 0, follows
!
n
j

Dij Si1
pS j
p j
pDj (x)
0

i=1

Si



equals 1/m 0 < n clause Ck satisfied Xi = xDi
j
X1 = xD1 , . . . , Xi1 = xDi1 , variables S1j , . . . , Si1
assume value k (i.e.,
134

fiSolving LIMIDs

j

j

j

j

xS1 = = xSi1 = k), xSi = = xSn = 0. Otherwise, equals 0. Hence,
(partial) strategy sj = (Dj , . . . , Dnj ) x = 0
1




j
psS j (x)
n

X

,

j ,...,S j

pS j

0

n1

0

n

i=1

j
Dij Si1

p

Sij



SAT (sj )
pD j
(x)
=
,




j
D1j ,...,Dn

SAT (sj ) denotes number clauses satisfied truth-value assignment
j

Sn B
X1 , . . . , Xn according sj . variable B j associated function pB
j
x faBj ,

j
B j = xB j1 xSn

= 0;
1, x
j j1
j
j
pSBnj B (x) = 1, xB = 0 xSn 6= 0 ;


0, otherwise;

j1



0

B 1 assume xB = 1. Hence, joint state configuration x
B 1 , . . . , B q , Sn1 , . . . , Snq

q
1
B 1 = = xB q = 1 xSn

= = xSn = 0;
1, x
j j1
1
q
1

pSBnj B (x) = 1, xB = = xB = 0 xSn 6= 0;


j=1
0, otherwise.




q


Finally, set utility functionu associated U return 1 B q = 1 0
j j1
Q
1
q
1
otherwise. way, u qj=1 pSBnj B
(x) equals 1 xB = = xB = 1 xSn =
q

= xSn = 0 zero otherwise. Thus, strategy = (s1 , . . . , sq ), sj =
Dj , . . . , Dnj , follows
1

Es [L] =

X

u

CD

=

q


u

B 1 ,...,B q
1 ,...,S q
Sn
n

=

=

j1

pS j

0

j=1

X

X

j

pSBnj B
q


j

pSBnj B

u

B 1 ,...,B q j=1
1 ,...,S q
Sn
n
q

j
psS j (0) =
n
j=1

i=1

j1

j=1

q


n


p

j
Dij Si1

Sij

X



pS j

j
S0j ,...,Sn1
j
j
D1 ,...,Dn
j

Sn B
pB
j

j1

pD j

0

n

i=1

p

j
Dij Si1

Sij

pD j


j

psS j

n

q
1
SAT (sj ) .
mq
j=1

instance CNF-SAT problem satisfiable optimum strategy
SAT (sj ) = j, MEU[L] = 1. hand, instance
135

fiMaua, de Campos, & Zaffalon

satisfiable, j strategy SAT (sj ) 1, hence
MEU[L] (m 1)q /mq . given 0 < < 1, let q positive integer chosen

1/2 > mq /(m + 1)q . show later q obtained polynomial

input. CNF-SAT instance satisfiable, 2 -approximation algorithm
MEU[L] returns value Es [L]
q


m1 q
MEU[L]

>
,
Es [L]
>
m+1

2
rightmost strict inequality follows m/(m + 1) > (m 1)/m.
hand, CNF-SAT instance satisfiable, approximation returns


m1 q
Es [L] MEU[L]
.



Hence, use 2 -approximation algorithm solve CNF-SAT checking whether
output E[L] > (m1)q /mq . Since q positive integers, test bound (m1)q /mq
obtained polynomnial time.
remains show reduction polynomial input. LIMID contains
q(2n + 2) + 1 variables, requiring specification 2(m + 1)2 numbers
{0, 1/m, 1}. , number numerical parameters L, polynomially bounded
q(m + 1)2 (4n + 4) + 2. Therefore, suffices show q polynomial n.
definition, q obeys


1 q
2

1+
> 2[q(m+1) (4n+4)+2] ,

equivalent


1
q ln 1 +




> q [(m + 1)2 (4n + 4) + 2] ln 2

[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 +
! 1
1
[(m + 1)2 (4n + 4) + 2]

ln 2
1
ln 1 +

q 1 >

q>

Since (by Lemma 25) + 1/2 > 1/ ln(1 + 1/m) 2 > ln(2), suffices choose q

1
q > (2m + 1)[(m + 1)2 (4n + 4) + 2] 1 .
2+1



words, q polynomially bounded 1 4n 1 . Therefore, MEU[L]

approximated polynomial time ratio greater 2 solve
CNF-SAT polynomial time.
next result show Transformation 6 preserves expected utility strategies,
strategies easily mapped back forward original transformed
diagrams.
136

fiSolving LIMIDs

paD = j

X1

X2

T1

T2



Xj1

Xj

Xj+1

Tj1

Tj

Tj+1



Xm

chD

Tm

Figure 10: Reasoning proof Transformation 6.

,pa

X

,T ,pa

Proof Proposition 7. looking definition functions pX11 pXii1 ,
= 2, . . . , m, see paD selects j , is, conditional paD = j ,
variable Xj independent Xj1 = 1, . . . , m, 6= j, variable Xi
independent Ti . words,


Pr(Xj |Xj1 , Tj , paD = j ) = Pr(Xj |Tj , paD = j ) , pXjj .
and, 6= j,
X

Pr(Xi |Xi1 , Ti , paD = j ) = Pr(Xi |Xi1 , paD = j ) , pXii1 .
visualize situation removing arc Xj1 Xj arcs
Ti Xi 6= j diagram Figure 2(b) (the arcs leaving paD also removed
conditioning value paD ), results diagram Figure 10. Note
principle case j = 1 deserves special attention, X1 depend
Xi variable, function associated X1 slightly differ others.
Nevertheless, similar reasoning applied. omit case j = 1
sake simplicity.
follows previous reasoning


pXjm , Pr(Xm |paD = j )

X
X


X
=
(pX1 pT1 )(pXjj pTj )
pXii1 pTi
T1 ,...,Tm X1 ,...,Xm1

=

X

pTj

Tj

X

i=2,i6=j


pXjj




X

i=j+1

Xj ,...,Xm1

X

pXi1


X1 ,...,Xj1

|
=

X
Tj

pTj

X
Xj ,...,Xm1



pXjj




X

pXii1 .

i=j+1

137

pX1

j1


X

pXi1


i=2

X




pTi

T1 ,...,Tm \Tj i=1,i6=j

{z

=1

}

fiMaua, de Campos, & Zaffalon

X

paD = j , function pXi1
6= j equals indicator function IXi =Xi1 ,



design, pXjj = IXj =Tj . thus

pXjm

=

X

X

pTj

Tj




IXj =Tj

IXi =Xi1 .

i=j+1

Xj ,...,Xm1

term outer sum Tj , inner sum Xj , . . . , Xm1 differs zero
Tj = Xj = Xj+1 = = Xm , case equals one. Hence,
X

pXjm =
pTj IXm =Tj
Tj

= pTj .
pa

consider strategy s0 = (T1 , . . . , Tm , . . . ) L0 , let pXmD function

equals pXjm every value j paD . Let also policy original decision
variable L ( j ) = Tj j, strategy L obtained
substituting policies T1 , . . . , Tm s0 . Finally, let pT1 , . . . , pTm distributions
pa
induced policies T1 , . . . , Tm s0 , pD distribution induced .
paD
Since value j paD pXm ( j ) = pTj , since design Xm = ,
pa
pa
follows pXmD = pD . Hence, combination policies T1 , . . . , Tm L0
derive corresponding policy L. converse also true: policy
pa
pa
generate T1 , . . . , Tm pXmD = pD (simply choose Ti = ( j ) i). Thus,
one-to-one correspondence policies T1 , . . . , Tm policies ,
pa
pa
one-to-one correspondence induced functions pXmD pD .
remains show combination policies T1 , . . . , Tm corresponding policy
induce expected utility. Let C 0 D0 denote, respectively, set chance
decision variables L0 , C set chance decision variables L.
Also, given strategy L, let

pa
p0s ,
pX X .
CD\{D}
pa

Note function independent choice policy , ps = p0s pD .
Given strategy s0 L0
X
X
Es0 [L0 ] =
ps0
uV
C 0 D0

=

X

V V

p0s

,pa
pX11

C 0 D0




X
,T ,pa
pXii1

i=2




!
pTi

=

p0s

X

uV

V V

CD\{D}

X X
C 0 \C D0 \D

X

X

CD\{D} Xm

pa

pXmD p0s

X




X

pXii1

i=2

{z

|
=

,paD

pX11

uV

V V

i=1

!
X

X

P
paD
= Xm pXm

uV

V V

138

,Ti ,paD




pTi

i=1

}

fiSolving LIMIDs

=

X

X

pa

pD p0s

X

ps

CD

X

uV

V V

CD\{D}

=

X

uV

V V

= Es [L] ,
strategy L obtained s0 substituting T1 , . . . , Tm corresponding policy .

References
Bodlaender, H. L. (1996). linear-time algorithm finding tree-decompositions small
treewidth. SIAM Journal Computing, 25 (6), 13051317.
Cooper, G. F. (1988). method using belief networks influence diagrams. Fourth
Workshop Uncertainty Artificial Intelligence.
de Campos, C. P. (2011). New results MAP problem Bayesian networks.
Proceedings 22nd International Joint Conference Artificial Intelligence, pp.
21002106.
de Campos, C. P., & Ji, Q. (2008). Strategy selection influence diagrams using imprecise probabilities. Proceedings 24th Conference Uncertainty Artificial
Intelligence, pp. 121128.
Dechter, R. (1999). Bucket elimination: unifying framework reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Detwarasiti, A., & Shachter, R. D. (2005). Influence diagrams team decision analysis.
Decision Analysis, 2, 207228.
Dubus, J.-P., Gonzales, C., & Perny, P. (2009). Multiobjective optimization using GAI
models. Proceedings 21st International Joint Conference Artificial Intelligence, pp. 19021907.
Fargier, H., Rollon, E., & Wilson, N. (2010). Enabling local computation partially
ordered preferences. Constraints, 15, 516539.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman.
Haenni, R. (2004). Ordered valuation algebras: generic framework approximating
inference. International Journal Approximate Reasoning, 37 (1), 141.
Howard, R. A., & Matheson, J. E. (1984). Influence diagrams. Readings Principles
Applications Decision Analysis, pp. 721762. Strategic Decisions Group.
Jensen, F. V., & Nielsen, T. D. (2007). Bayesian Networks Decision Graphs (2nd
edition). Information Science Statistics. Springer.
Kohlas, J. (2003). Information Algebras: Generic Structures Inference. Springer-Verlag,
New York, USA.
139

fiMaua, de Campos, & Zaffalon

Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.
Lauritzen, S. L., & Nilsson, D. (2001). Representing solving decision problems
limited information. Management Science, 47, 12351251.
Maua, D. D., & de Campos, C. P. (2011). Solving decision problems limited information. Advances Neural Information Processing Systems 24, pp. 603611.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2011). Solving limited memory influence
diagrams. ArXiv:1109.1754v2 [cs.AI].
Park, J. D., & Darwiche, A. (2004). Complexity results approximation strategies
MAP explanations. Journal Artificial Intelligence Research, 21, 101133.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. Advances Neural
Information Processing Systems 16 (NIPS).
Pralet, C., Verfaillie, G., & Schiex, T. (2007). algebraic graphical model decision
uncertainties, feasibilities, utilities. Journal Artificial Intelligence Research, 29,
421489.
Qi, R., & Poole, D. (1995). new method influence diagram evaluation. Computational
Intelligence, 11, 498528.
Shachter, R. D., & Peot, M. A. (1992). Decision making using probabilistic inference methods. Proceedings 8th Conference Uncertainty Artificial Intelligence,
pp. 276283.
Shenoy, P., & Shafer, G. (1990). Axioms probability belief-function propagation.
Proceedings 4th Conference Uncertainty Artificial Intelligence, pp.
169198.
Zhang, N. L., Qi, R., & Poole, D. (1994). computational theory decision networks.
International Journal Approximate Reasoning, 11 (2), 83158.

140

fi
