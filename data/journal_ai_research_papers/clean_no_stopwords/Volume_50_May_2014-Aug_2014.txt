Journal Artificial Intelligence Research 50 (2014) 535-572

Submitted 12/13; published 07/14

Integrating Queueing Theory Scheduling
Dynamic Scheduling Problems
Daria Terekhov
Tony T. Tran

dterekho@mie.utoronto.ca
tran@mie.utoronto.ca

Department Mechanical Industrial Engineering
University Toronto, Toronto, Ontario, Canada

Douglas G.

downd@mcmaster.ca

Department Computing Software
McMaster University, Hamilton, Ontario, Canada

J. Christopher Beck

jcb@mie.utoronto.ca

Department Mechanical Industrial Engineering
University Toronto, Toronto, Ontario, Canada

Abstract
Dynamic scheduling problems consist challenging combinatorics, found
classical scheduling problems, stochastics due uncertainty arrival times,
resource requirements, processing times jobs. address two challenges,
investigate integration queueing theory scheduling. former reasons
long-run stochastic system characteristics, whereas latter typically deals shortterm combinatorics. investigate two simple problems isolate core differences
potential synergies two approaches: two-machine dynamic flowshop
flexible queueing network. show first time stability, fundamental
characteristic queueing theory, applied approaches periodically solve combinatorial scheduling problems. empirically demonstrate dynamic flowshop,
use combinatorial reasoning little impact schedule quality beyond queueing approaches. contrast, complicated flexible queueing network, novel
algorithm combines long-term guidance queueing theory short-term combinatorial decision making outperforms tested approaches. knowledge,
first time hybrid queueing theory scheduling techniques
proposed evaluated.

1. Introduction
behave intelligently extended period time, situated agent must able
deal dynamic changes tasks goals. New tasks (e.g., targets surveillance, see Burns, Benton, Ruml, Yoon, & Do, 2012; deliveries, see Bent & Van Hentenryck,
2007; requests drink, see Petrick & Foster, 2013) arrive continuously must
incorporated ongoing problem-solving process.
Similarly, real-world scheduling problem, set jobs changes customer orders
arrive, processed, leave system. Different jobs different requirements
processing different resources, characteristics often become known
arrival job. Depending scheduling horizon, scheduler may number
possibly conflicting objectives. Examples short-term objectives include minimizing
c
2014
AI Access Foundation. rights reserved.

fiTerekhov, Tran, Down, & Beck

tardiness makespan, long term scheduler may want guarantee
facility handle expected pattern demand without catastrophic failures (e.g.,
without number jobs waiting processing becoming extremely large).
thesis long-term stochastic reasoning studied queueing theory
usefully combined, theoretically algorithmically, shorter-term combinatorial reasoning traditionally studied scheduling within artificial intelligence
(AI) operations research. combination challenging, queueing theory
scheduling developed independently many years and, consequence, different performance measures interest, standard problem settings, assumptions.
paper, take steps toward integration queueing scheduling studying
two dynamic scheduling problems making following contributions:

show fundamental queueing theory notion stability used
analyze periodic scheduling algorithms, standard approach dynamic scheduling
scheduling literature. show, problems studied,
periodic scheduling algorithms proved maximally stable: queueing
policy scheduling approach allow system operate higher load
achieve higher throughput.
show, context one dynamic scheduling problem, long-term,
stochastic reasoning queueing theory combined short-term combinatorial reasoning produce hybrid scheduling algorithm achieves better performance either queueing scheduling approaches alone.

paper organized follows. Section 2 provides necessary background
dynamic scheduling algorithms, queueing theory, stability. Next, discuss general
problem settings assumptions job arrivals time various problem
characteristics become known. Section 3 addresses first, simpler problem, scheduling
dynamic two-machine flowshop, presenting theoretical results stability
empirical results comparing algorithm performance. Section 4 turns second,
complex environment, flexible queueing network. problem scheduling
setting, addition theoretical numerical examination queueing
scheduling approaches, propose analyze queueing/scheduling hybrid. Section
5, discuss broader implications results scheduling AI problem solving.
conclude Section 6.

2. Preliminaries
section introduces background forms context study. review
general dynamic scheduling problem two solution approaches: combinatorial scheduling
queueing theory. provide detailed discussion stability, fundamental
analytical concept use theoretical contributions. Finally, discuss problem
settings assumptions.
536

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

2.1 Dynamic Scheduling Problems
dynamic scheduling problems interested characterized stream
jobs arriving stochastically time. job requires combination resources,
sequentially and/or parallel, different processing times. existence particular
job corresponding characteristics known arrival. However, make
assumption, queueing theory unlike typical scheduling settings,
stochastic information distribution job arrivals characteristics. Jobs may
require complex routing available resources, may heterogeneous
known deterministic capacities.
scheduling problem may short- long-term objectives. typical
scheduling contexts, goal construct schedule achieves optimal level
performance given optimization criterion (e.g., mean flow time) jobs
actually arrive. Often settle evaluating algorithm performance finite time
horizon; refer criteria short-term criteria. contrast, long-term objectives
focus system-level performance measures stability, establishes whether
instantaneous number jobs remain finite infinite horizon particular
system parameters.
solve dynamic scheduling problem, jobs must assigned appropriate resources start times, respecting resource temporal constraints. jobs arrive,
must online process make decisions: possible solve entire
problem offline.
Solving dynamic scheduling problems challenging due combinatorics
interaction jobs, resources, time, due stochastics: make decision,
one use information known certainty decision point
stochastic properties scenarios may occur future.
2.2 Combinatorial Scheduling
classical scheduling literature, common assume full information: jobs
characteristics known prior decision making. example, job shop
scheduling problem (JSP) consists |J| jobs |M | resources (French, 1982). job
consists set |M | completely ordered activities corresponding processing time
resource requirement: job must use specified resource full, uninterrupted
processing time. number objective functions defined, common minimize makespan: time start first activity
end last one. Many solution approaches proposed, ranging complete
techniques branch-and-bound (Carlier & Pinson, 1989; Brucker, Jurisch, & Sievers,
1994), mixed integer programming (Bowman, 1959; Manne, 1960), constraint programming (Fox, 1987; Baptiste, Le Pape, & Nuijten, 2001; Beck, 2007; Beck, Feng, & Watson,
2011), dispatch rules (Pinedo, 2003) meta-heuristics (Nowicki & Smutnicki, 1996,
2005).
scheduling literature also addressed problems uncertainty. Pinedo (2003)
refers stochastic scheduling problems random variables processing
times and/or release dates (i.e., arrival times) jobs. acknowledging similarity
dynamic problems studied queueing theory, Pinedo points primary
537

fiTerekhov, Tran, Down, & Beck

difference stochastic scheduling typically concerned optimizing schedule
finite number jobs rather long-term system behaviour potentially
infinite stream arriving jobs (Pinedo, 2003, ch. 11). Approaches solving stochastic
scheduling problems often involve formulation determinstic scheduling problem
optimize expected value probabilistic measure objective function
(Daniels & Carrillo, 1997; Pinedo, 2003; Beck & Wilson, 2007; Wu, Brown, & Beck, 2009),
insertion temporal resource redundancy cope realizations random variables
(Leon, Wu, & Storer, 1994; Davenport, Gefflot, & Beck, 2001), multi-stage stochastic
programming (Herroelen & Leus, 2005).
solving dynamic problems, scheduling community typically adopts periodic scheduling approach solving collection linked static sub-problems (Bidot, Vidal,
Laborie, & Beck, 2009; Ouelhadj & Petrovic, 2009). given time point, static
problem, consisting jobs currently present system, solved optimize
short-term objective function. schedule executed (wholly partially)
creation next sub-problem triggered. viewpoint means methods developed static scheduling problems become directly applicable dynamic ones.
methods effectively deal complex combinatorics optimize quality
schedules static sub-problem. However, tend overlook long-run performance
stochastic properties system.
examples work modifies short-term objective problemsolving process address fact static problem part long-term scheduling
problem. Branke Mattfeld (2002, 2005) address dynamic job shop problem
overall objective minimizing mean tardiness jobs. use periodic scheduling
approach based genetic algorithm solves sub-problem minimize combination tardiness preference place resource idle time toward end
sub-problem schedule. intuition later idle time allows jobs arrive
future slotted current schedule little disruption. Empirical results
demonstrate lower idle time long term compared simply minimizing tardiness.
Another example framework Online Stochastic Combinatorial Optimization
(OSCO) (Van Hentenryck & Bent, 2006; Mercier & Van Hentenryck, 2007),
set existing jobs plus sample future arrivals used create static scheduling
sub-problem. Multiple samples optimizations intricately combined arrive
set decisions existing jobs. Mercier Van Hentenryck (2007) show
algorithms scale better Markov Decision Processes (MDPs) result good
performance small expected difference best performance
clairvoyant non-clairvoyant decision makers. Similar approaches developed
AI planning (Yoon, Fern, Givan, & Kambhampati, 2008; Burns et al., 2012).
examples employ underlying approach dynamic scheduling problems:
adapt static technique incorporating intuitive (Branke & Mattfeld, 2002) sampled
(Van Hentenryck & Bent, 2006) information future. approaches serve
inspiration us develop formal general understanding long-term
objectives achieved solving series short-term, static scheduling problems.
538

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

2.3 Queueing Theory
Queueing theory mathematical study waiting lines (Gross & Harris, 1998).
models systems one servers (machines) one service stations
process arriving customer requests (jobs). Fundamentally, queueing theory focuses
formal analysis evolution queues related metrics time given particular system definition class systems. standard notation describe queueing
process, due mainly Kendall (1953), represented A/B/X/Y /Z. describes
inter-arrival process (distribution time two successive arrivals), B service
time distribution, X number parallel machines, buffer size (maximum job capacity system), Z queue discipline (scheduling order). Common distributions
found literature B deterministic1 (D), exponential (M) general
(G). Given defined arrival service time distribution, queueing discipline, number
machines buffer capacity, queueing literature commonly interested
determining steady-state system parameters stability conditions, expected waiting
time expected queue length. Although significant portion literature focuses
descriptive models steady-state performance metrics, transient behaviour
prescriptive models also studied, interest paper. Markov processes
(Down & Meyn, 1994; Dai & Meyn, 1995; Bolch, Greiner, de Meer, & Trivedi, 2006), fluid
models (Dai, 1995; Dai & Weiss, 1996), linear programming (LP) models (Andradottir,
Ayhan, & Down, 2003; & Karakostas, 2008) typical approaches analyzing
queueing systems.
area queueing theory deals prescriptive models frequently called
design control queueing systems (Tadj & Choudhury, 2005; Gross & Harris, 1998).
queueing design control problems, goal find optimal values
controllable parameters queue. parameters include number machines
available processing arriving jobs, buffer capacity, arrival rate jobs
queue(s), service rates machine(s), well combination these. Queueing
design problems static: optimal value controllable parameter determined,
becomes fixed characteristic queue. Queueing control problems, contrary,
dynamic: goal problems usually determine optimal action take
system particular state. example, consider retail facility workers
serve stochastically arriving customers also perform back-room tasks
independent customer arrival process (Terekhov, Beck, & Brown, 2009). order
optimize performance facility, one solve queueing design problem
finding optimal number cross-trained servers employ well related
queueing control problem determining switch workers two
task types. refer reader papers Tadj Choudhury (2005) Crabill,
Gross, Magazine (1977) overviews design control problems involving queues.
Queueing theory taken viewpoint that, since impossible create optimal
schedule every single sample path evolution system, one aim
achieve optimal performance probabilistic sense (e.g., expectation) infinite
time horizon. goal could attained construction policy based global
stochastic properties system. example, policy could specify start time
1. Deterministic refers inter-arrival service times value.

539

fiTerekhov, Tran, Down, & Beck

assignments made whenever new job arrives completes processing. However,
schedule resulting policy, good quality expectation, may
far optimal particular realization uncertainty occurs. Moreover,
queueing theory generally studies systems simple combinatorics, systems
amenable rigorous analysis stochastic properties.
2.4 Stability
Stability2 fundamental concept queueing theory forms main part
theoretical analysis. Informally, system stable queues remain bounded time.
stability system dependent scheduling policy employs: given set
problem parameters (e.g., arrival processing distributions), one policy may stabilize
system another might not. Knowledge whether system stable given job
arrival rate, processing rate scheduling policy considered precursor detailed
analysis essential practical applications (Kumar, 1994; Dai & Weiss, 1996).
Formally, system operating particular queueing discipline stable
Markov process describes dynamics system positive Harris recurrent (Dai,
1995). Positive Harris recurrence implies existence unique stationary distribution.
Due considerable notation required, formally define positive Harris recurrence here, instead refer reader work Dai (1995), Dai Meyn (1995)
Bramson (2008).
special case state space Markov process countable3 states
communicate, positive Harris recurrence equivalent widely-known concept
positive recurrence (Bramson, 2008). Markov chain positive recurrent every state
positive recurrent: probability process starting state return
1, expected time return state finite (Ross, 2003). particular,
property guarantees system empty.
2.5 Problem Settings
queueing theory combinatorial scheduling focus efficient use scarce
resources time. However, different emphases (i.e., stochastics vs. combinatorics)
indicate may possible combine order provide better understanding
of, stronger solution approaches to, dynamic scheduling problems.
first challenge study determine problem settings assumptions.
queueing scheduling sometimes make differing assumptions, guided
three heuristics choosing problems. First, sought simplest problem settings
queueing scheduling arrived solution. example, many single
machine dynamic scheduling problems, identical, optimal dispatch rules/queueing policies
exist literatures. Second, assumptions two areas consistent,
2. Unfortunately, stability multiple meanings closely related literature. scheduling literature,
predictive schedule called stable execution close planned (Bidot et al., 2009).
Similarly, work scheduling uncertainty, stability analysis concerns identification
range values processing times may take given schedule remains optimal (Sotskov,
Sotskova, Lai, & Werner, 2010). use meaning stability queueing theory.
3. process referred continuous-parameter Markov chain book Gross Harris
(1998).

540

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

adopted them. third, assumptions contradictory, attempted choose
realistic settings also result novel challenging problems.
consequence, make following assumptions two systems studied here.
queueing, assume know distribution job inter-arrival times.
assume job durations become known upon arrival realizations
corresponding known distributions. Queueing models typically assume
distribution job durations known, actual processing time job
available completion time.4 classical scheduling literature, exact
job durations known prior construction schedule jobs processed
machine have, general, different durations. knowledge distributions
actual durations upon arrival justified applications historical
data available similar activities repeatedly executed (e.g.,
serving static web page, cutting piece wood standardized
dimensions), adopt assumptions.
queue, sequences processing times machines sequence
inter-arrival times independent identically distributed sequences.
also mutually independent.
Mean processing times mean inter-arrival times finite.
inter-arrival times unbounded continuous.
final three assumptions standard queueing literature dealing
stability analysis (Dai, 1995) satisfied commonly used distributions (e.g., exponential distribution), combination first two assumptions typically received
much attention queueing scheduling literature. setting somewhat similar
online-time setting online scheduling (Pruhs, Sgall, & Torng, 2004) jobs arrive
system dynamically job processing times become known upon arrival. However,
setting makes assumption known inter-arrival duration distributional
information.

3. Two-Machine Dynamic Flowshop
first problem consider dynamic two-machine permutation flowshop. Within
setting, demonstrate stability periodic scheduling approach uses processing time information, provide numerical comparison queueing scheduling
approaches.
dynamic two-machine permutation flowshop, arriving jobs must processed first
machine 1 machine 2, order jobs processed two
machines must same. assume inter-arrival time distribution general
mean 1 , processing time distributions machine 1 2 general
means 11 12 , respectively. Thus, load machine 1 1 = 1 , load
4. One exception deterministic distribution, durations jobs assumed
identical (Gross & Harris, 1998).

541

fiTerekhov, Tran, Down, & Beck

machine 2 2 = 2 . 1 2 assumed less 1, known
necessary conditions stability (Gross & Harris, 1998). job arrives system,
processing times machines become known certainty. machines
unary capacity. Preemptions allowed. queues front machine 1
machine 2 assumed infinite size. goal problem sequence
jobs machine 1 machine 2 order minimize flow time: time
arrival job completion machine 2.
dynamic flowshop (Park, 1988; Sarper & Henry, 1996; El-Bouri, Balakrishnan,
& Popplewell, 2008) extension classical flowshop environment
extensively studied scheduling literature (Widmer & Hertz, 1989; Taillard, 1990).
queueing literature, system known tandem queue network queues
series also received significant attention (Burke, 1956; Reich, 1957; Jackson, 1957;
Gross & Harris, 1998; Andradottir & Ayhan, 2005).
3.1 Algorithms
consider four periodic scheduling approaches two-machine dynamic flowshop
problem. case, schedule formed optimizing value interest subproblem: set jobs present system particular time. dynamic flowshop,
start time every new sub-problem equal completion time last job
machine 1 previous sub-problem, Figure 1. Since jobs new sub-problem
begin execution scheduled jobs processed first machine,
time scheduling may still jobs previous schedule need processing
machine 2. previous scheduling decisions altered next sub-problem
solved.

Figure 1: Dynamic flowshop three sub-problems three jobs per sub-problem.
start sub-problem start set jobs machine 1, end sub-problem
end set jobs machine 2.
best knowledge, queueing policy proved optimal
flow time objective, even expected sense, dynamic two-machine flowshop
assumptions. first two approaches, however, chosen theoretical
results systems related ours, discussed below. dynamic flowshop, none
periodic scheduling methods make use distributional information.
542

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

3.1.1 FCFS
Jobs sub-problem sequenced non-decreasing order arrival times
system. FCFS achieves smallest expected flow time two-machine dynamic flowshop class work-conserving, non-preemptive policies use processing
time information (Towsley & Baccelli, 1991). Note periodic FCFS policy creates
identical schedules standard (non-periodic) first-come, first-served policy queueing
theory, jobs processed order arrive.
3.1.2 SPTsum
Jobs sub-problem processed non-decreasing order sum durations
machine 1 machine 2. policy choice motivated fact that, case
server single unary resource, shortest processing time first minimizes expected
flow time (Wierman, Winands, & Boxma, 2007).
3.1.3 CompletionTime
Since minimizing sub-problem flow time assumptions equivalent minimizing
sum job completion times sub-problem, natural sub-problem objective
sum completion times activities second machine. Optimizing total
completion time lead best short-run performance unclear
method perform respect long-run objectives. Minimizing sum completion
times two-machine flowshop NP-hard (Pinedo, 2003).
3.1.4 Makespan
fourth method employ motivated reasoning proxy measure
speculate may result strong long-run flow time performance. minimum makespan
schedule sub-problem, definition, allows subsequent sub-problem start
early possible machine 2, implying potentially lower flow times future subproblems system empties. Therefore, likely achieve optimal
flow time performance sub-problem, conjecture makespan minimization
may lead better long-run flow time performance.
optimal makespan schedule static two-machine flowshop found
polynomial-time using Johnsons rule (Conway, Maxwell, & Miller, 1967). Johnsons rule
divides jobs two sets: set consists jobs whose processing time machine 1
less equal processing time machine 2, set II consists
remaining jobs. Set processed set II. Note that, required, Johnsons rule
creates permutation schedules. Within set I, jobs sequenced non-decreasing order
processing time machine 1, within set II, jobs sequenced non-increasing
order processing times machine 2.
3.2 Stability
study compare stability one policies use
processing time information, i.e., FCFS, one policies does, i.e., makespan.
particular, show condition stability FCFS follows trivially known
543

fiTerekhov, Tran, Down, & Beck

results queueing literature. Using result, significantly, show
makespan approach stable condition. best knowledge,
first example stability analysis scheduling policies based observed processing
times.
leave study stability two remaining methods utilize processing
time information future work. Showing stability completionTime approach may
prove especially challenging since possesses neither specific structure
utilized proof property makes easily comparable FCFS.
Theorem 1. min{1 ,2 } < 1, periodic FCFS policy stable two-machine
dynamic flowshop.
Proof. assumptions, dynamic two-machine flowshop generalized Jackson
network, periodic FCFS policy equivalent standard, non-periodic implementation FCFS. Stability generalized Jackson networks condition
load machine strictly less 1 (in case, /1 < 1 /2 < 1) known
(Dai, 1995).
result extends |M | > 2 machines: fluid model methodology (Dai, 1995)
used show stability FCFS |M |-machine flowshop condition

minm{1,...,|M |} {m } < 1.
makespan policy, prove result holds every sample path
evolution system. Let sn tn time points sub-problem n starts
machine 1 completes machine 2, respectively, makespan approach. Let vn
vn total processing time jobs completed time tn makespan
policy arbitrary policy , respectively. Following queueing literature,
refer vn vn work completed time tn .
Lemma 1. amount work completed tn maximized makespan policy.
is, vn vn n non-idling .
Proof. arbitrary non-idling policy , vn written vn1, + vn2, , vn1,
amount work completed tn machine 1 vn2, amount work completed
tn machine 2. (In Figure 2, t0 5, v01, = 5 v02, = 3.) makespan approach,
use notation without superscript , i.e., vn = vn1 + vn2 . dynamic flowshop,
amount work completed tn machine 1 non-idling policy.
Thus, remains prove vn2 vn2, . prove induction.
Base Case: v02 v02, since policy makespan complete set initial
jobs time makespan (t0 ) later.
Inductive Hypothesis: Assume property true tn , is, vn2 vn2, .
2,
2
Inductive Step: need show property tn+1 , i.e., vn+1
vn+1
.
2
2
makespan approach, vn+1 = vn + ((sn , sn+1 ]), ((sn , sn+1 ]) total machine
2 workload arrives time period (sn , sn+1 ] and, therefore, workload
processed sub-problem starting sn+1 ending tn+1 .
induction hypothesis, know tn , vn2 vn2, . amount work
2,
processed machine 2 time tn+1 policy , vn+1
, equals amount work processed
time tn plus fraction difference amount work completed
544

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

makespan tn plus fraction amount machine 2 work arrives
2,
2 .
(sn , sn+1 ]. Thus, vn+1
vn2, + (vn2 vn2, ) + ((sn , sn+1 ]) = vn2 + ((sn , sn+1 ]) = vn+1

Figure 2: Schedule policy two-machine flowshop.

Figure 3: Schedule makespan problem instance Figure 2.
example, consider schedules Figures 2 3: s0 = 0, s1 = 4, s2 = 9, t0 = 5,
t1 = 11, t2 = 14, v22 = v12 + ((s1 , s2 ]) = 9 + 3 = 12, v22, = 7 + (9 7) + 1 12.5
lemma hold idling since idling policy may create better schedule
waiting taking jobs account.
Theorem 2. min{1 ,2 } < 1 periodic makespan policy stable twomachine dynamic flowshop.
Proof. know FCFS stable given condition. Lemma 1, every
sub-problem completion time, makespan approach finished least much work
FCFS. Therefore, two-machine dynamic flowshop periodic makespan policy
stable condition FCFS.
theorem provides sufficient condition stability. noted above,
literature (see e.g., Gross & Harris, 1998), know 1 < 1 2 < 1 necessary
conditions stability system. Since ensuring min{1 ,2 } < 1
ensuring 1 < 1 2 < 1, see min{1 ,2 } < 1 necessary sufficient condition
stability dynamic two-machine flowshop makespan policy.
5. assume J7, J8 J9 arrive time period (4, 9].

545

fiTerekhov, Tran, Down, & Beck

Figure 4: Schedule FCFS dynamic flowshop three machines.

Figure 5: Schedule makespan dynamic flowshop three machines.

Lemma 1 hold |M |-machine flowshop |M | > 2. illustrate
fact, consider problem instance Figures 4 5. example, sub-problem 0
consists jobs J0 J1, makespan policy FCFS construct
schedule, t0 = 7. second sub-problem consists J2 J3, two policies
result different schedules. t0 = 7, amount work completed makespan
v0 = 12, whereas amount work completed FCFS v0 = 13. Therefore,
case, v0 < v0 , shows possible amount work completed tn
maximized makespan policy. nonetheless conjecture Theorem 2 extends
case two machines proved using fluid model approach.
3.3 Numerical Results
present experiments comparing performance FCFS, SP Tsum , makespan completionTime models minimizing mean flow time long time horizon. completionTime model implemented via constraint programming ILOG Scheduler 6.5
546

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

uses completion global constraint (Kovacs & Beck, 2011). remaining methods
implemented using C++.
evaluate performance four methods dynamic flowshop, considered
system exponentially distributed inter-arrival times exponentially distributed
processing times means machines. Experiments uniformly
distributed processing times showed identical performance. parameters chosen
satisfy stability conditions Theorems 1 2. fixed mean inter-arrival time,
1/, 10, varied load system 0.1 0.95 changing means
processing time distributions 1 9.496. Note Theorems 1 2,
parameters guarantee stability FCFS makespan. results experiments
shown Figure 6. point figure represents mean flow time 100 problem
instances 55,000 jobs each.
experiments, completionTime model run time limit 1 second per sub-problem order ensure reasonable run-times. Moreover, since constraint
programming efficient integer, rather real-valued, durations, using
completionTime approach set durations ceiling actual durations
multiplied 100; resulting processing sequence used construct actual
sub-problem schedule. Note time limit, completionTime always find
optimal sub-problem schedule. run Dual Core AMD 270 CPU 1
MB cache, 4GB main memory, Red Hat Enterprise Linux 4, completionTime
model able solve 100% sub-problems optimality loads 0.1 0.3,
percentage decreases average 81.3% instances 0.95 load. change
performance due increase sub-problem size load increases: average
sub-problem size increases 1.009 0.1 load 5.452 0.95 load,
maximum sub-problem size encountered instances increases 5 0.1 load
172 0.95 load. Experiments time limit 5 seconds showed similar
performance, mean flow time 0.95 load decreasing 368.985 (from 371.434
completionTime model 1 second time limit) percentage instances
solved optimality 0.95 load increasing 83.8% machine 4 Intel Core
i7-2600 CPUs @ 3.40GHz 8 MB cache 9871 MB main memory, running Red Hat
Enterprise Linux 6.3.
Figure 6 shows little difference among methods. completionTime
slight advantage others loads 0.7 less. makespan model
better FCFS completionTime loads 0.8. SP Tsum best-performing
model loads 0.8, static sub-problems become large. last observation
supported results Xia, Shanthikumar, Glynn (2000), shown
SP Tsum asymptotically optimal static average completion time objective
number jobs two-machine flowshop increases. However, asymptotic result
imply applying SP Tsum sub-problem results best long-run behaviour
high loads. FCFS, hand, worst performer loads,
marginally so.
empirical results contradictory Theorem 1. particular, fact
makespan results largest amount workload completed particular time
point imply minimize mean flow time. example, consider
sub-problem 1 Figure 3: sequence displayed figure, J5 J6 J4,
547

fiTerekhov, Tran, Down, & Beck

200

FCFS
makespan
SPT_sum
completionTime

0

100

Mean Flow Time

300

Mean Flow Time Various Queue Loads

0.2

0.4

0.6

0.8

1.0

Loads

Figure 6: Mean flow times dynamic two-machine flowshop FCFS, SP Tsum , completionTime makespan models system load varies.
sequence J6 J5 J4 minimize makespan, latter sequence achieve
lower total completion time (26 opposed 28 first sequence) hence lower
mean flow time sub-problem.
3.4 Discussion
study dynamic two-machine flowshop provides partial support thesis
utility combining queueing scheduling. shown stability analysis
applied periodic scheduling algorithms algorithms reason
combinatorics achieve stability guarantees traditional queueing theory
approaches. However, system able empirically demonstrate
scheduling algorithms (completionTime makespan) result better mean flow time
performance queueing approaches.
low loads, methods perform equivalently due small sub-problems; high loads,
differences performance lead following observations. Firstly, performance
completionTime degrades due inability find good solutions large sub-problems
given time limit; able find better solution, completionTime defaults
FCFS schedule. Secondly, motivation using makespan approach
548

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

materialize: differences makespans makespan approach SPTsum
large enough offset differences total completion time (which favour
SPTsum ). Finally, conjecture implementation completionTime defaults
SPTsum schedule would outperform current approaches highest load.
improvement result finding, sub-problem, optimal total
completion time schedule lowest possible makespan.
Subsequent analytical work problem setting shows completionTime
approach results smaller long-run mean flow time time periods makespan if,
majority sub-problems, difference completionTime makespan
individual sub-problem total completion times larger difference makespans
prior start sub-problem. Furthermore, complex problem setting
(i.e., polling system two-machine flowshop server) shown, analytically
empirically, objective minimizing long-run flow time, algorithm
minimizes makespan sub-problems outperforms one minimizes sum
completion times (Terekhov, 2013, ch. 7). results directly address
combination queueing scheduling approaches, demonstrate impact
sub-problem optimization criteria long-term performance measures delicate
yet well understood.

4. Queueing Network Flexible Servers
deeply investigate combination queueing theory scheduling, examine
second system different combinatorial structure. first problem, provide
analysis stability numerical comparison queueing scheduling approaches.
However, unlike first problem, setting also propose evaluate hybrid
queueing/scheduling algorithm.
system interest queueing network heterogeneous servers required
serve jobs belonging specific classes. problem example classical queueing
system (Bramson & Williams, 2000; Andradottir et al., 2003). system differs
dynamic flowshop jobs may processed machine, assignment
job machine must made. Jobs arrive time via arrival process rate
generally distributed inter-arrival times. arriving job belongs class k
probability pk . assume preemptions: job begins execution
must processed full processing time. server assigned job class
k, jobs processing time generally distributed rate mk ; job j arrives
system, processing times server become known denoted dmj .
assume servers able serve jobs classes. multiple servers working
single class point time, work parallel job served
exactly one server.
equivalent static problem scheduling literature parallel machine
scheduling problem (Pinedo, 2003). However, scheduling literature either assumes machines related unrelated. related parallel machine scheduling problem,
machine inherent speed determines job processing times. machine twice
fast machine b, always require half time process job machine
b does. machines unrelated, correlation processing times job
549

fiTerekhov, Tran, Down, & Beck

different machines. queueing network problem, processing times given
job class stochastically related drawn distribution
given machine. However, class relationships across different machines
may ok < mk ol > ml 6= o, k 6= l. adopt queueing theory
assumption.
4.1 Algorithms
present five different approaches scheduling jobs queueing network flexible
servers: two queueing policies, two scheduling policies, hybrid queueing theory
scheduling method.
illustrate five approaches, present small example possible realization
system two servers two job classes. total five jobs: three
belonging class 1 two belonging class 2. job represented J{k,j},
k represents class job j job number. Table 1 provides arrival
processing times two machines (servers) job example. Notice
servers process class 2 jobs amount time, server 2 1.5 times
slower server 1 jobs class 1.
{Class, Job ID}
Arrival Time
Server 1 Processing Time
Server 2 Processing Time

J{1,1}
1
8
12

J{1,2}
3
6
9

J{1,3}
5
4
6

{2,1}
0
6
6

{2,2}
12
6
6

Table 1: Example job arrival processing times.

two queueing policies employ periodic scheduler. Instead, dispatch
rules used decide job processed server becomes available.
policies, linear program (LP), called allocation linear program, used determine
portion total capacity server allocate job class (Andradottir
et al., 2003). LP solved once, scheduling decisions made.
allocation LP derived fluid representation queueing network assumes
number jobs present system large exhibit properties
continuous fluid (Chen & Yao, 1992; Dai, 1995). allocation LP follows:
max
|M |
X
s.t.
mk mk pk , k K

(1)

m=1
|K|

X

mk 1,

mM

(2)

k K;

(3)

k=1

mk 0

550

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

: arrival rate jobs,
mk : fractional amount time server spend class k jobs,
K: set job classes,
: set servers.
decision variables problem mk . objective maximize
arrival rate jobs maintaining stability system. Stability achieved
constraint (1) ensures total capacity allocated job class greater
equal total amount work generated job class.
solution allocation LP provides tight upper bound maximum arrival
rate system stabilized, , values resource allocation
(Andradottir et al., 2003). However, provide method assign
proportions, mk
jobs servers decide sequence jobs. make decisions,
Round Robin policy (Andradottir et al., 2003) linear programming-based affinity
scheduling (LPAS ) heuristic (Al-Azzoni & Down, 2008) used.
4.1.1 Round Robin
Round Robin policy, server cyclically visits classes Vm , Vm

> 0. serving class k Vm , server
ordered list classes k mk mk
processes lmk jobs moving next class. server idle
point lmk jobs served, switches next class Vm . Given desired arrival

1
rate , let =
+ , mk = mk , let 1{mk > 0} function equal 1
values sufficiently
mk > 0 0 otherwise. Andradottir et al. (2003) show mk
tracked stabilize system lmk chosen
P

> 0})
(1 )( lK ml 1{mk
mk
lmk =
.
mk
Figure 7 shows schedule produced Round Robin policy five-job exam = 1, = 0, = 0.5, = 0.5.
ple. Assume allocation LP results 11
12
21
22
is, server 1 handles jobs class 1 only, server 2 handle classes. Further,
assume calculated lmk value greater three server class pairs.
situation, example three jobs per class, Round Robin policy
change classes server processing available tasks
class start immediately. time 0, J{2,1} present system. Since server 2
server handle class 2 jobs, job assigned begin immediately server 2.
J{1,1} arrives, server 1 able start job instantly. Server 2 completes J{2,1}
time 6, two jobs class 1 queue. Server 2 begins processing J{1,2}
since arrived first. Server 1 completes J{1,1} time 9 starts processing J{1,3}.
Server 1 completes J{1,3} server 2 completes J{1,2}. Although J{2,2} waiting
= 0. J{2,2} must wait
queue time 13, assigned server 1 12
server 2 available time 15. example schedule ends time 21 completion
J{2,2}.
4.1.2 LPAS
> 0 expected complete
LPAS assigns arriving job machine mk
job earliest time. LPAS heuristic similar Round Robin,

551

fiTerekhov, Tran, Down, & Beck

Figure 7: Example schedule produced Round Robin policy LPAS.

guarantee stability. Rather, heuristic uses
reason relative magnitudes mk

mk reason server-class pairs efficient assignments. stability
LPAS open question, though shown empirically perform well terms
number jobs system (Al-Azzoni & Down, 2008).
Figure 7 also presents schedule produced LPAS five-job example. Similar
Round Robin policy, assume allocation LP results server 1 processing class 1
only, server 2 handling classes. time 0, J{2,1} arrives assigned server
2. J{1,1} arrives time 1 processed either server. Starting immediately
server 1 would lead earlier completion time J{1,1}, make assignment.
J{1,2} arrives time 3 also considered servers. Starting J{1,2} server 2
time 6 leads earliest completion time, hence assignment made. J{1,3}
arrives time 5 complete earliest assigned server 1. Finally, J{2,2} must
assigned server 2 end schedule. Therefore, resulting schedule
particular example Round Robin policy LPAS.

two scheduling models study, one simple dispatch policy similar
queueing policies presented above, second makes use periodic scheduler.
4.1.3 MinFT
dispatch policy MinFT greedily minimizes flow time jobs without exploiting
solution allocationP
LP. setting, flow time job j, assigned
server m, fmj = + xm dmx + dmj , represents thePtotal remaining time
server busy job currently served, xm dmx sum
processing times jobs belonging , set jobs queued server m.
job arrives, assigned server results smallest flow time
job given jobs already scheduled. Ties broken arbitrarily. Jobs sequenced
first-come, first-served (FCFS) order server.
schedule produced MinFT five-job example shown Figure 8.
start schedule, J{2,1} considered servers, leads
completion time either, MinFT arbitrarily chooses one servers. case,
assume servers chosen lexicographically, job assigned server 1. time
1, assigning J{1,1} server 2 lead smaller flow time, hence assignment
made. process continues job, results schedule Figure 8.
552

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

Figure 8: Example schedule produced MinFT.

4.1.4 Makespan
flowshop studied above, makespan model periodically solves static makespan
minimization problems. period defined time scheduler evaluates
system server available. jobs belonging previous period
yet completed stay assigned before.
problem NP-hard, polynomial-time algorithms minimize
makespan two-machine dynamic flowshop problem. use mixed-integer
programming (MIP) solve minimum makespan scheduling problem. beginning
every period, following MIP model solved minimize makespan set
unscheduled jobs:
min Cmax
|J|
X
s.t.
xmj dmj + Cmax ,

mM

(4)

jJ

(5)

j J;

(6)

j=1
|M |

X

xmj = 1,

m=1

xmj {0, 1},

Cmax :
xmj :
:

makespan period,
1 job j assigned server m, 0 otherwise,
remaining time server busy serving jobs belonging schedules
made previous periods,
J: set jobs scheduled period.
model minimizes makespan, Cmax , constrained greater
equal maximum scheduled busy period server. amount time
P|J|
server busy able serve new jobs, j=1 xmj dmj total
processing time allotted new jobs server m. sum two terms equals
total time server busy following schedule. Constraint (5) ensures
job assigned exactly one server.
MIP model assigns jobs servers sequence jobs. order
achieve makespan since processing times jobs sequence independent.
553

fiTerekhov, Tran, Down, & Beck

allow direct comparison policies defined above, FCFS used jobs
assigned machines.
Figure 9 gives schedule produced makespan five-job example. time
0, 1 job available, makespan schedules J{2,1}. Assignment server 1
2 leads makespan, arbitrarily choose server 1. J{1,1} arrives,
new sub-problem created since server 2 idle begin processing jobs immediately.
Assigning arriving job server 2 leads minimizing makespan sub-problem 1.
time 6, server 1 becomes idle finds two jobs queue (J{1,2} J{1,3}). Minimizing
makespan sub-problem 2 requires J{1,2} J{1,3} assigned server 1.
final sub-problem starts time 13 server 2 finishes J{1,1}. point, one
job queue, assigned server 2 minimize makespan sub-problem 3.

Figure 9: Example schedule produced makespan model.

MinFT reason future jobs, makespan thought
indirectly saving resources future jobs minimizing makespan current period.
ability makespan model deal complex combinatorics allows take
advantage systems state information, Round Robin LPAS able use
knowledge processing arrival rates manage allocation servers. approach
able reason types information may improve overall performance.
Thus, integrate scheduling queueing theory algorithmic level create
hybrid model.
4.1.5 Hybrid Model
hybrid model periodic scheduler uses makespan model framework

employs mk
values allocation LP. Recall values indicate best
long-run proportional allocation servers job classes. MIP model solved
period is:
554

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

min Cmax + (1 )

|M | |K|
X
X

cmk

m=1 k=1

s.t.

Constraints (4) (6)
|J|
X
X

xmj dmj mk
xmj dmj cmk , k K;
jSk

(7)

j=1

cmk 0,

k K;

(8)


cmk : deviation realized assignment server class k
suggests,
mk

: input parameter used scale importance deviation mk
values versus makespan,
Sk : set jobs belong class k.
MIP model bi-criteria objective minimizing makespan deviation

values. trade-off makespan deviation expressed ,
mk
0 1. = 1, model makespan model.
Figure 10 illustrates schedule hybrid model might produce five-job
= 1, = 0, = 0.5,

values before, i.e., 11
example assuming mk
12
21

22 = 0.5, assuming chosen close 1. Using high value makes
illustration models behaviour simpler. Further, choice ensures minimizing
values used breaking ties
makespan important objective, mk
different schedules produce makespan. time 0, sub-problem 0 solved
J{2,1} system. Although makespan regardless
server responsible job, hybrid model chooses make assignment server
= 0 = 0.5. Sub-problem 1 starts time 1 J{1,1} arrives
2, 12
22
assigned server 1. time 6, J{1,2} J{1,3} queue, sub-problem 2 starts.
J{1,2} assigned server 1 J{1,3} assigned server 2 minimize makespan
sub-problem 2. time 12, sub-problem 3 begins J{2,2} scheduled server 2.

Figure 10: Example schedule produced hybrid model.

555

fiTerekhov, Tran, Down, & Beck

4.2 Stability
know work Andradottir et al. (2003) Round Robin policy stable
< , maximum stabilizable arrival rate. stability LPAS heuristic
yet established.
examine stability two scheduling policies hybrid model presented
above. stability conditions makespan hybrid model determined
comparison Round Robin policy. MinFT model shown guarantee
stability conditions Round Robin policy.
4.2.1 Stability Makespan
Given Round Robin achieve desired capacity < , following
theorem.
Theorem 3. Round Robin stable given arrival process rate ,
makespan model also guaranteed stable.
Proof. prove stability conditions makespan assuming makespan unstable
Round Robin stable, deriving contradiction. Let Jt set jobs
system time makespan policy. assumption makespan (denoted
notation) unstable means limt E(|Jt |) = .
time t0 , makespan model completes period schedules set Jt0 .
Denote earliest start time latest end time jobs Jt0 makespan policy S(Jt0 ) F (Jt0 ), respectively. makespan model minimize makespan,
C(Jt0 ) = F (Jt0 ) S(Jt0 ). However, work remaining previous periods servers,
represented , must accounted for. J 0 set jobs previous period,
left-over work bounded maxmM ;jJ 0 (dmj ) server residual
work greater largest processing times would job reassigned
free machine previous sub-problem reduce sub-problem makespan.
worst case, servers except one busy time next period one
server available immediately, delaying optimal schedule less time units.
define minimum makespan scheduling Jt0 residual work ignored
C (Jt0 ). easy show C(Jt0 ) C (Jt0 ) + . exists number jobs

|J|
1



C (J)
C(J)

=1


C(J)
C(J)

, 0. true number jobs increases, becomes
|J|
negligible compared actual makespan schedule. Therefore, number
jobs system increases without bound, makespan converges optimal. Since
throughput system exit rate jobs Round Robin best match

minimum makespan, system reached sufficiently large size J,
throughput makespan least large Round Robin policy. Therefore,
find contradiction: makespan cannot unstable Round Robin stable
throughput makespan least large Round Robin policy. Thus,
guaranteed stabilizable system stabilized makespan.
556

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

aspect proof technique,
Note dependence |J|
requirement stability. Stability property system depend
number jobs system. However, proof depends achieving minimum
makespan sub-problem, requires solving NP-hard problem. return
point Section 5.
4.2.2 Stability Hybrid
prove stability conditions hybrid model way makespan.
values
first show exists minimum makespan schedule tracks mk
number jobs period sufficiently large.
Proposition 1. number jobs scheduled period approaches , exists
values allocation LP.
schedule minimum makespan tracks mk
Proof. Denote set jobs schedule period J, set jobs assigned
, makespan
server class k Qmk , resulting makespan server Cm

system overPall machines set jobs J Cmax . time server spends
jobs class k jQmk dmj . proportion time server spends class k,
denoted mk ,
P
P
jQmk dmj
jQmk dmj
P
mk = P
.
=

Cm
kK
jQmk dmj
Using Law Large Numbers, know
X
1
(
dmj ) = 1
mk .
|Q
|
|Qmk |
mk
lim

iQmk

Taking limit number jobs system, |J|, goes , gives
(
|Qmk |
lim|J| |Qmk | = ,
lim|J| mk

Cmax
lim mk =
|J|
0
lim|J| |Qmk | < .

(1)

multiply mk mk sum machines, get
lim

|J|

|M |
X

mk mk = lim

m=1

1


|J| Cmax

|M |
X
m=1

pk |J|
,

C
|J| max

|Qmk | = lim

left-hand side constraint (1) allocation LP. Re-arranging terms leads

|M |
X
mk mk
pk |J|
|J|
= lim
= lim
.


pk
|J|
|J| pk Cmax
|J| Cmax

lim

m=1

Here, see since allocation LP aims maximize , equivalent minimizing

makespan Cmax
, therefore schedule exists minimum makespan also

tracks mk .
557

fiTerekhov, Tran, Down, & Beck

Theorem 4. Round Robin stable given arrival process rate ,
hybrid model also stable.
Proof. proof based proof Theorem 3. makespan replaced
hybrid model (denoted h used superscript) proof follows except
C h (Jth ) 6 C (Jth ). Due bi-criteria objective, model guarantee
minimum makespan schedules.
take |J| , Proposition 1 states minimum makespan schedule

track mk
values cmk goes 0. Therefore, sufficiently large
system size, cmk small enough ensure makespan schedule converges
makespan and, similarly Theorem 3, hybrid model guarantees stability
stabilizable system.
4.2.3 Instability MinFT
show MinFT model cannot handle < , provide counter-example.
Assume system two servers two job classes. arrival rate
system = 1 p1 = p2 = 0.5. 11 = 10, 21 = 9, 12 = 9, 22 = 10,
= 1, = 0, = 0, = 1 get = 20. order
allocation LP would assign 11
21
12
22
system stable particular , scheduling algorithm must adequately track
values. , available freedom algorithm deviate goes
mk
mk
0.
Assignments MinFT model made greedily server minimize
jobs flow time. Denoting completion time latest job server ,
know arriving job j served faster server rather slower
server l unless inequality + dmj > l + dlj true. inequality true,
MinFT model assign arriving job server l since completion time
earlier. define j = dlj dmj j << dmj since difference
processing rates order magnitude smaller processing rates themselves.
Consider two cases: (1) |1 2 | > j , (2) |1 2 | < j . case (1), arriving
job assigned server smaller regardless class
server busy. MinFT model follows efficient assignment use faster server
case (2). case (1) scheduler make efficient assignment 50%
time arriving job equal probability belonging either class. need
show P (|1 2 | > j ) > 0, MinFT model cannot guarantee stability like
Round Robin policy. Assume inequality false, i.e., P (|1 2 | > j ) = 0.
scenario, know system point time adheres |1 2 | < j . However,
job arrives, must scheduled onto one servers, making |1 2 | > minm1,2 (dmj )
j > j . inequality results contradiction since, certainty, next arriving
job force system case (1). Since case (1) occurs positive probability,
inefficient assignment occur non-zero probability. Denote probability
inefficient assignments b1 = P (1 2 > j )p1 b2 = P (1 2 < j )p2
b = b1 = b2 (0.5)(0.5) system symmetry. realized proportions time
server spends classes 11 = 1 b, 21 = b, 12 = b, 22 = 1 b. Therefore,
obtainable capacity
10(1 b) + 9b + 9b + 10(1 b) = 20 2b < 20,
558

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

b > 0. simple system, 2b < < , MinFT model cannot
guarantee stability.
4.3 Numerical Results
experimentally compare mean flow time performance proposed models. Two
different cases tested: two job classes two servers, four job classes four
servers. test case, five different loads 0.8 0.99 maximum
theoretical load simulated. load, 20 instances run 10,000 time units,
resulting total 100 simulations per model two systems.
Job arrivals follow Poisson process. order maintain relative processing times
single job server, amount work job, wj , generated using
exponential distribution rate 1; augmented linearly processing rate
wj
server, based jobs class, create processing time dmj = mk
. use
processing rates mk ranging one job per time unit ten jobs per time unit. test
cases asymmetric: processing rates classes different different servers.
Symmetric systems examined emphasize heterogeneity network.
simulation implemented C++. LP MIP models use IBM ILOG
CPLEX 12.1. experiments performed Dual Core AMD 270 CPU 1 MB
cache, 4GB main memory, running Red Hat Enterprise Linux 4. Preliminary results
showed = 0.6 provided best performance hybrid method (Tran, 2011).

Mean Flow Time

Round Robin
MinFT
LPAS
makespan
Hybrid

1

10

0

10

80

82

84

86
88
90
92
94
Percent Maximum Theoretical Load

96

98

100

Figure 11: Comparison mean flow times flexible queueing network two servers
two classes.

559

fiTerekhov, Tran, Down, & Beck

Mean Flow Time

Round Robin
MinFT
LPAS
makespan
Hybrid

1

10

0

10

80

82

84

86
88
90
92
94
Percent Maximum Theoretical Load

96

98

100

Figure 12: Comparison mean flow times flexible queueing network four servers
four classes.

Figures 11 12 present mean flow times averaged across problem instances
every load. Note log-scale y-axes. Figure 11, see two scheduling
models hybrid model create better schedules Round Robin.
Increasing system size produces substantially different results. Figure 12 shows
lower loads, LPAS obtains lowest mean flow time. contrast performing
worse makespan hybrid model loads smaller system.
load increases, makespan model performance becomes better Round Robin
still become good LPAS. hybrid model able obtain
performance comparable LPAS lower loads provide best performance
high loads. Thus, hybrid model maintains robust performance across varying
system loads. Even though performance hybrid falls short LPAS lower
loads, waiting times low loads almost negligible. heavy loads approaches
, hybrid model outperforms algorithms 17%.
good performance MinFT model lost larger system. loads
0.9 greater, MinFT model able process jobs quickly enough dissipate
build jobs. empirical confirmation MinFT stable parameters
algorithms stable, e.g., loads greater 90% Figure 12.
investigate whether strong performance hybrid model indeed due
values plot performance
guidance allocation LP values, alter mk
Figure 13. following queueing guidance beneficial, deviating values

.
lead worse schedules. Therefore, replace mk
values 1 mk
560

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

3

10

1

*

mk

*

mk

2

Mean Flow Time

10

1

10

0

10

80

82

84

86
88
90
92
94
Percent Maximum Theoretical Load

96

98

100

1
Figure 13: Comparison mean flow times hybrid model guided mk
mk
flexible queueing network four servers four classes.

resources allocation LP assigns
fewer assigned hybrid
P class,

model. Although method allows kK mk > 1, conceptual goal scheduling
avoid allocation LP solution still maintained, validity model
compromised since resource capacity limit essential solving fluid model.
find incorrectly guided hybrid performs poorly loads; loads 0.9,
system size grows rapidly behaves unstable. conclude using
proper guidance allocation LP crucial.
4.3.1 Performance Analysis
numerical results show makespan model improved incorporating
queueing analysis. understand result low loads considering system
two servers two classes. equal arrival rates processing rates 11 = 9, 12 =
= 0, = 1, = 0.5,
2, 21 = 5, 22 = 1, solving allocation LP gives 11
12
21

22 = 0.5. system lightly loaded two class 1 jobs present,
1
processing times equal expected value ( m1
: 19 server 1 15 server 2),
makespan schedule one job servers. hybrid model would consider
= 0 depending parameter chosen, could decide place jobs
fact 11
second server attempt perform well long run. Although hybrid
, guidance sufficient performance improvement
partially guided mk
makespan.
561

fiTerekhov, Tran, Down, & Beck

2

10

Round Robin
LPAS
makespan
Hybrid
1

Mean Variance

10

0

10

1

10

2

10

80

82

84

86
88
90
92
94
Percent Maximum Theoretical Load

96

98

100

Figure 14: Comparison class flow time variance flexible queueing network four
servers four classes.


so, contrary
heavy loads, Proposition 1 states makespan track mk
results, would expect makespan hybrid models perform similarly.
However, time server becomes busy idle, first
scheduling periods expected fewer jobs middle time
span, yet enough arrivals significant queues build up.
Therefore, first periods resemble lightly loaded system. necessarily
larger queue formed. early decisions
case makespan track mk
propagate subsequent periods affect later jobs within busy period.
hybrid model, start, able make better long-run decisions. Although
hybrid model guarantee always make best choice, speculate
increase probability better choices made.

instances four servers four job classes, LPAS better hybrid
low loads worse high loads. Deeper analysis shows performance pattern
largely due poor performance hybrid policy low loads. loads,
hybrid make assignments inefficient long term jobs
system. argued hybrid model making better assignments
makespan guided queueing analysis. However, policy maintains
values, LPAS Round Robin, reserves servers
strict adherence mk
job classes efficient long term. Even though hybrid model incorporates

mk
values decision-making process, guaranteed low loads
562

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

. especially
model always make globally optimal decisions adhere mk
true chosen high.
hybrid model outperforms LPAS heavy loads optimizing makespan
period long-run impact. heavy loads hybrid model able match
values minimize makespan, whereas Round Robin former
mk
LPAS cannot guarantee either. hybrid model reduces makespan time units
compared LPAS Round Robin, jobs next period able start time
units earlier thereby net effect reducing mean flow time approximately
subsequent set. reductions propagate subsequent periods server
idle.
propagation effect reducing makespan earlier period property
hybrid model inherited makespan model. such, expect
makespan exhibit behaviour well. numerical results show, expected,
performance makespan good heavy loads. makespan model lacks
queueing guidance ensure even higher quality schedules earlier busy period.
expected similar results makespan model dynamic flowshop problem
Section 3 well. However, experimental results Section 3 show assumption
incorrect. conjecture one reasons see better performance
makespan queueing network flexible servers dynamic flowshop
latter differences optimal sub-problem makespans
makespans found methods substantial. queueing network
flexible servers, makespan may change significantly using different policies.
Given complex nature systems, investigation performance trade-offs
resulting different system parameters necessary future work. hope
investigation lead derivations general dynamic scheduling principles.

4.3.2 Beyond Mean Flow Time
Though primary quantity interest mean flow time, variance also important
criterion. perspective customer submitted job processing,
high variance indicates actual flow time given job unlikely accurately
predicted mean flow time.
Figure 14 shows variance mean flow time job class four servers
four classes using Round Robin LPAS much larger makespan
hybrid policies.
see substantial difference (note log scale) among four algorithms.
larger variance observed queueing models occurs policies use less information state system. policies may overcompensate serve job
class immediately rather delaying service achieve fairer allocation. contrast,
scheduling models make use state information perform better load balancing
therefore exhibit lower variance.

5. Discussion
motivation studying integration scheduling queueing
two areas address similar problems different ways, combination terms problem
563

fiTerekhov, Tran, Down, & Beck

settings, performance measures algorithms provides richer set domains, goals
tools. Given nascent nature study, looked two simple problem settings
demonstrated following contributions.
1. problem settings, showed possible establish stability periodic
scheduling approaches, enhancing periodic scheduling framework guarantee
stability traditionally available queueing approaches only. far
aware, first time stability established algorithms use observed job characteristics instead of, addition to, stochastic
information. Similarly, far aware, concept stability appears
queueing theory examined combinatorial scheduling community.
believe oversight arising areas focus short-term combinatorics suggest that, queueing theory, stability important criterion
problem must deal stream arriving resource requests.
2. second problem setting, flexible queueing network, first,
dynamic flowshop, demonstrated solution approaches combine guidance
long-run stochastic reasoning short-term combinatorial reasoning perform better queueing scheduling approaches alone. However, differences
two problem settings, well work complex problem
domains (Tran, 2011), shows combination non-trivial work
needed place hybrid algorithms formal foundation.
see variety additional ways integrate ideas queueing theory scheduling future. example, would like to: extend analysis general
dynamic scheduling environments, job shops; compare methods discussed
paper complex queueing approaches alternative dynamic scheduling
approaches, OSCO; investigate stability dynamic scheduling approaches
OSCO based approximation algorithms (i.e., polynomial time approximation
schemes applied every sub-problem); develop sophisticated hybrid queueing
theory scheduling models.
broader direction future work fully investigate fact that,
number applications, reasonable assume data probability
distributions actual job characteristics (at arrival time) available. best way
integrate different data sources open question paper begun
investigate perspective hybridization existing tools.
5.1 Distributional Assumptions
work assumes that, queue, sequences processing times machines sequence inter-arrival times independent identically distributed sequences, sequences also mutually independent. many AI applications,
assumptions may justified, data may non-stationary (time-dependent)
and/or correlated. non-stationary models simple correlation structures also
considered queueuing theory literature (Prabhu & Zhu, 1989; Massey, 2002; Gupta,
Harchol-Balter, Scheller-Wolf, & Yechiali, 2006; Liu & Whitt, 2012).
564

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

Importantly, note proof Lemma 1 holds non-stationary setting
scheduling methods used dynamic flow shop distribution-independent.
flexible queueing network, majority analysis based allocation LP,
based fluid representation system. fluid analysis stability,
i.i.d. assumption required; instead, necessary Law Large Numbers
hold inter-arrival processing time sequences. Thus, analysis
extended including correlation structures long Law Large Numbers holds.
algorithmic side, Round Robin, LPAS hybrid methods adapted
non-stationary setting periodically re-solving allocation LP using updated
values. fact, approach special case general principle needs
considered dynamic scheduling problems: distributions may need updated
new data becomes available. surprisingly, queueing theory scheduling, nonstationary situations require periodic approaches.
5.2 Computational Complexity
substantial difference periodic scheduling approaches traditional queueing theory-based policies scheduling approaches may solve NP-hard
problems. indeed case completionTime algorithm two-machine
dynamic flowshop problem (Section 3) makespan hybrid algorithms
queueing network (Section 4). assumption work, consistent
related work OSCO (Van Hentenryck & Bent, 2006; Mercier & Van Hentenryck,
2007), dynamism system slow enough allow problem solving.
report run-times solving problems make look arbitrarily
good bad making assumptions time granularity. example, time
unit problem corresponds one hour, algorithm run-times 10 20 seconds
unlikely significant.
applications finer time granularity, may able solve problems
traditional queueing policies appropriate. However, work raise
interesting question stability polynomial-time algorithms provide approximation guarantees. proofs Theorems 2 4 depend finding optimal makespans,
seem easy generalization.
5.3 Online Scheduling
Online scheduling alternative approach dynamic scheduling problems (Pruhs et al.,
2004), different classical combinatorial scheduling queueing theory.
online scheduling literature focuses competitive analysis, proving worst-case bounds
much worse deterministic randomized online algorithms are, compared fullinformation algorithm. queueing theory, rigorous mathematical approach
online scheduling tends limit combinatorial structure addressed. However,
unlike queueing theory, uncommon assume knowledge stochastic distributions
job arrivals characteristics drawn. Indeed, often results showing
differences deterministic randomized online algorithms arise analysis
systems adversary full knowledge online algorithm manipulate
job characteristics arbitrarily.
565

fiTerekhov, Tran, Down, & Beck

chosen include online scheduling paper, believe
important understand results insights area integrated
work order obtain even deeper understanding dynamic scheduling problems.
5.4 Relevance AI
Dynamic scheduling requires series scheduling resource allocation decisions
made online future tasks arrive characteristics, any, known.
challenge sequential decision making uncertainty, problem received
significant amount attention AI. Indeed, requirement agent make decisions
take actions without full knowledge future states world would appear
central requirement embodied, intelligent agent. Investigation sequential
decision making applications interest AI include planning task allocation
uncertainty (Keller & Eyerich, 2012; Alighanbari & How, 2008), land purchases
conservation endangered species (Xue, Fern, & Sheldon, 2012), multi-player
strategy games (Sturtevant, 2008; Balla & Fern, 2009).
methodological approaches problems AI rely way Markov
Decision Processes (MDPs) (Puterman, 1994), notably area decision-theoretic
planning (Boutilier, Dearden, & Goldszmidt, 2000). challenge arising direct applications MDPs well-known curse dimensionality, state space
large problems cannot solved. Substantial work therefore focused approaches
factored MDPs (Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean, & Boutilier,
1998; Boutilier et al., 2000; Guestrin, Koller, & Parr, 2003), approximate dynamic programming (Powell, 2010), Monte Carlo Tree Search (Chaslot, 2011; Browne, Powley, Lucas,
Cowling, Rohlfshagen, Tavener, Perez, Samothrakis, & Colton, 2012; Bellemare, Naddaf,
Veness, & Bowling, 2013) Online Stochastic Combinatorial Optimization (Van Hentenryck & Bent, 2006).
Queueing theory another approach sequential decision making uncertainty,
one emphasizes time resources one that, knowledge,
considered solving problems studied AI. Given concern time resources,
dynamic scheduling natural problem choice investigation incorporation
queueing theory toolbox AI techniques. richness decision-making
problems AI extends questions time resources (e.g., temporal planning
problems, see Coles, Coles, Fox, & Long, 2012) and, fact, much underlying analysis
prescriptive queueing theory approaches founded MDPs (Stidham & Weber, 1993;
Sennott, 1999; Meyn, 2008), believe application queueing theory AI
hybridization queueing scheduling proposed paper, promising directions
fundamental applied research.

6. Conclusion
paper, considered combination long-run stochastic reasoning shortterm combinatorial reasoning solve dynamic scheduling problems. specifically,
investigated integration queueing theory scheduling two simple scheduling
problems: dynamic two-machine flowshop flexible queueing network. provided
analytical empirical results.
566

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

Analytically, demonstrated problem settings scheduling approaches make use observed job characteristics, opposed stochastic information job classes, proved stable. is, possible manage
system number jobs waiting processing remains finite, combinatorial scheduling algorithm so.
Empirically, demonstrated common scheduling criterion possible
create hybrid algorithm guided long-term stochastic reasoning short-term combinatorial reasoning. Furthermore, algorithm shown stable
empirically out-perform pure scheduling pure queueing approaches. However, result shown one two problem settings, suggesting currently
understanding allow us systematically design successful hybrids.
believe novel investigation integration problem settings, performance criteria, algorithms queueing theory combinatorial scheduling opens
number interesting research directions surrounding approaches dynamic scheduling
and, broadly, sequential decision making uncertainty.

Acknowledgements
authors would like thank reviewers associate editor comments,
helped improve paper.
Section 3 paper based previously published workshop conference papers
(Terekhov, Tran, & Beck, 2010; Terekhov, Tran, Down, & Beck, 2012). work Section
4 forms part Masters dissertation (Tran, 2011) appeared peerreviewed publication.
research supported Natural Sciences Engineering Research
Council Canada, Canadian Foundation Innovation, Ontario Research Fund,
Ontario Ministry Research Innovation, Ireland Industrial Development
Agency, Alcatel- Lucent, Microway Inc., IBM ILOG, University Toronto School Graduate Studies Doctoral Completion Award, Department Mechanical Industrial
Engineering University Toronto.

References
Al-Azzoni, I., & Down, D. G. (2008). Linear programming-based affinity scheduling
independent tasks heterogeneous computing systems. Parallel Distributed
Systems, IEEE Transactions on, 19 (12), 16711682.
Alighanbari, M., & How, J. P. (2008). robust approach UAV task assignment
problem. International Journal Robust Nonlinear Control, 18, 118134.
Andradottir, S., & Ayhan, H. (2005). Throughput maximization tandem lines two
stations flexible servers. Operations Research, 53 (3), 516531.
Andradottir, S., Ayhan, H., & Down, D. G. (2003). Dynamic server allocation queueing
networks flexible servers. Operations Research, 51 (6), 952968.
567

fiTerekhov, Tran, Down, & Beck

Balla, R.-K., & Fern, A. (2009). UCT tactical assault planning real-time strategy
games. Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI09), pp. 4045.
Baptiste, P., Le Pape, C., & Nuijten, W. (2001). Constraint-based Scheduling. Kluwer
Academic Publishers.
Beck, J. C. (2007). Solution-guided multi-point constructive search job shop scheduling.
Journal Artificial Intelligence Research, 29, 4977.
Beck, J. C., Feng, T., & Watson, J. P. (2011). Combining constraint programming local
search job-shop scheduling. INFORMS Journal Computing, 23 (1), 114.
Beck, J. C., & Wilson, N. (2007). Proactive algorithms job shop scheduling probabilistic durations. Journal Artificial Intelligence Research, 28, 183232.
Bellemare, M. G., Naddaf, Y., Veness, J., & Bowling, M. (2013). arcade learning environment: evaluation platform general agents. Journal Artificial Intelligence
Research, 47, 253279.
Bent, R., & Van Hentenryck, P. (2007). Waiting relocation strategies online stochastic
vehicle routing.. Proceedings 20th International Joint Conference Artificial
Intelligence (IJCAI07), pp. 18161821.
Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2009). theoretic practical framework
scheduling stochastic environment. Journal Scheduling, 12 (3), 315344.
Bolch, G., Greiner, S., de Meer, H., & Trivedi, K. S. (2006). Queueing networks
Markov chains: modeling performance evaluation computer science applications. Wiley-Interscience.
Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programming
factored representations. Artificial Intelligence, 121, 49107.
Bowman, E. (1959). schedule-sequencing problem. Operations Research, 7 (5), 621624.
Bramson, M. (2008). Stability queueing networks. Probability Surveys, 5, 169345.
Bramson, M., & Williams, R. J. (2000). dynamic scheduling stochastic networks
heavy traffic new results workload process. Proceedings
39th IEEE Conference Decision Control, Vol. 1, pp. 516521.
Branke, J., & Mattfeld, D. C. (2002). Anticipatory scheduling dynamic job shop problems. Proceedings ICAPS02 Workshop On-line Planning Scheduling,
pp. 310.
Branke, J., & Mattfeld, D. C. (2005). Anticipation flexibility dynamic scheduling.
International Journal Production Research, 43 (15), 31033129.
Browne, C., Powley, E., Lucas, S., Cowling, P. I., Rohlfshagen, P., Tavener, S., Perez, D.,
Samothrakis, S., & Colton, S. (2012). survey Monte Carlo tree search methods.
IEEE Transactions Computational Intelligence AI Games, 4 (1), 149.
Brucker, P., Jurisch, B., & Sievers, B. (1994). branch bound algorithm
job-shop scheduling problem. Discrete Applied Mathematics, 49 (1), 107127.
Burke, P. (1956). output queuing system. Operations Research, 4 (6), 699704.
568

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

Burns, E., Benton, J., Ruml, W., Yoon, S., & Do, M. B. (2012). Anticipatory on-line planning. Proceedings Twenty-Second International Conference Automated
Planning Scheduling (ICAPS12), pp. 333337.
Carlier, J., & Pinson, E. (1989). algorithm solving job-shop problem. Management Science, 35 (2), 164176.
Chaslot, G. M. J.-B. (2011). Monte-Carlo Tree Search. Ph.D. thesis, Universeteit Maastricht.
Chen, H., & Yao, D. D. (1992). fluid model systems random disruptions. Operations Research, 41 (2), 239247.
Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2012). COLIN: Planning continuous
linear numeric change. Journal Artificial Intelligence Research, 44, 196.
Conway, R. W., Maxwell, W. L., & Miller, L. W. (1967). Theory Scheduling. AddisonWesley.
Crabill, T., Gross, D., & Magazine, M. (1977). classified bibliography research
optimal design control queues. Operations Research, 25 (2), 219232.
Dai, J. G. (1995). positive Harris recurrence multiclass queueing networks: unified
approach via fluid limit models. Annals Applied Probability, 5 (1), 4977.
Dai, J. G., & Meyn, S. P. (1995). Stability convergence moments multiclass
queueing networks via fluid limit models. IEEE Transactions Automatic Control,
40 (11), 18891904.
Dai, J. G., & Weiss, G. (1996). Stability instability fluid models reentrant lines.
Mathematics Operations Research, 21 (1), 115134.
Daniels, R., & Carrillo, J. (1997). -robust scheduling single-machine systems
uncertain processing times. IIE Transactions, 29, 977985.
Davenport, A., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robust schedules.
Proceedings Sixth European Conference Planning (ECP-2001).
Down, D., & Meyn, S. (1994). survey Markovian methods stability networks.
11th International Conference Analysis Optimization Systems: Discrete
Event Systems, pp. 490504. Springer.
Down, D. G., & Karakostas, G. (2008). Maximizing throughput queueing networks
limited flexibility. European Journal Operational Research, 187 (1), 98112.
El-Bouri, A., Balakrishnan, S., & Popplewell, N. (2008). Cooperative dispatching minimizing mean flowtime dynamic flowshop. International Journal Production
Economics, 113 (2), 819833.
Fox, M. S. (1987). Constraint-directed Search: Case Study Job-Shop Scheduling.
Morgan-Kaufmann Publishers Inc.
French, S. (1982). Sequencing Scheduling: Introduction Mathematics
Job-shop. Ellis Horwood.
Gross, D., & Harris, C. (1998). Fundamentals Queueing Theory. John Wiley & Sons,
Inc.
569

fiTerekhov, Tran, Down, & Beck

Guestrin, C., Koller, D., & Parr, R. (2003). Efficient solution algorithms factored MDPs.
Journal Artificial Intelligence Research, 19, 399468.
Gupta, V., Harchol-Balter, M., Scheller-Wolf, A., & Yechiali, U. (2006). Fundamental characteristics queues fluctuating load. ACM SIGMETRICS Performance Evaluation Review, 34 (1), 203215.
Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey research
potentials. European Journal Operational Research, 165 (2), 289306.
Jackson, J. (1957). Networks waiting lines. Operations Research, 5 (4), 518521.
Keller, T., & Eyerich, P. (2012). PROST: Probabilistic planning based UCT. Proceedings 22nd International Conference Automated Planning Scheduling
(ICAPS12), pp. 119127.
Kendall, D. G. (1953). Stochastic processes occurring theory queues
analysis method imbedded Markov chain. Annals Mathematical
Statistics, 24 (3), 338354.
Kovacs, A., & Beck, J. C. (2011). global constraint total weighted completion time
unary resources. Constraints, 16 (1), 100123.
Kumar, P. R. (1994). Scheduling semiconductor manufacturing plants. IEEE Control Systems Magazine, 14 (6), 3340.
Leon, V. J., Wu, S. D., & Storer, R. H. (1994). Robustness measures robust scheduling
job shop. IIE Transactions, 26 (5), 3243.
Liu, Y., & Whitt, W. (2012). Gt /GI/st + GI many-server fluid queue. Queueing
Systems, 71 (4), 405444.
Manne, A. (1960). job-shop scheduling problem. Operations Research, 8 (2), 219223.
Massey, W. A. (2002). analysis queues time-varying rates telecommunication
models. Telecommunication Systems, 21 (24), 173204.
Mercier, L., & Van Hentenryck, P. (2007). Performance analysis online anticipatory
algorithms large multistage stochastic integer programs. Proceedings
20th International Joint Conference Artificial Intelligence, pp. 19791984. Morgan
Kaufmann Publishers Inc.
Meuleau, N., Hauskrecht, M., Kim, K. E., Peshkin, L., Kaelbling, L. P., Dean, T., &
Boutilier, C. (1998). Solving large weakly coupled Markov decision processes.
Proceedings 15th National Conference Artificial Intelligence (AAAI98).
Meyn, S. P. (2008). Control Techniques Complex Networks. Cambridge University Press.
Nowicki, E., & Smutnicki, C. (1996). fast taboo search algorithm job shop problem.
Management Science, 42 (6), 797813.
Nowicki, E., & Smutnicki, C. (2005). advanced tabu algorithm job shop problem.
Journal Scheduling, 8, 145159.
Ouelhadj, D., & Petrovic, S. (2009). survey dynamic scheduling manufacturing
systems. Journal Scheduling, 12 (4), 417431.
570

fiIntegrating Queueing Scheduling Dynamic Scheduling Problems

Park, B. Y. (1988). evaluation static flowshop scheduling heuristics dynamic
flowshop models via computer simulation. Computers & Industrial Engineering,
14 (2), 103112.
Petrick, R. P. A., & Foster, M. E. (2013). Planning social interaction robot bartender
domain. Proceedings 23rd International Conference Automated Planning
Scheduling, pp. 389397.
Pinedo, M. L. (2003). Scheduling: Theory, Algorithms, Systems (2nd edition). PrenticeHall.
Powell, W. (2010). Merging AI solve high-dimensional stochastic optimization
problems using approximate dynamic programming. INFORMS Journal Computing, 22 (1), 217.
Prabhu, N. U., & Zhu, Y. (1989). Markov-modulated queueing systems. Queueing Systems,
5 (13), 215245.
Pruhs, K., Sgall, J., & Torng, E. (2004). Online scheduling. Leung, J. Y.-T. (Ed.),
Handbook Scheduling: Algorithms, Models Performance Analysis, chap. 15.
CRC Press.
Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc.
Reich, E. (1957). Waiting times queues tandem. Annals Mathematical
Statistics, 28 (3), 768773.
Ross, S. M. (2003). Introduction Probability Models, chap. 6 Continuous-Time Markov
Chains, pp. 349399. Academic Press.
Sarper, H., & Henry, M. C. (1996). Combinatorial evaluation six dispatching rules
dynamic two-machine flow shop. Omega, 24 (1), 7381.
Sennott, L. I. (1999). Stochastic Dynamic Programming Control Queueing Systems. John Wiley & Sons, Inc.
Sotskov, Y. N., Sotskova, N. Y., Lai, T.-C., & Werner, F. (2010). Scheduling Uncertainty: Theory Algorithms. Belorussian Science.
Stidham, Jr., S., & Weber, R. (1993). survey Markov decision models control
networks queues. Queueing Systems, 13, 291314.
Sturtevant, N. (2008). analysis UCT multi-player games. Proceedings
Sixth International Conference Computers Games (CG2008), pp. 3749.
Tadj, L., & Choudhury, G. (2005). Optimal design control queues. Sociedad de
Estadstica e Investigacion Operativa, Top, 13 (2), 359412.
Taillard, E. (1990). efficient heuristic methods flow shop sequencing problem.
European Journal Operational Research, 47 (1), 6574.
Terekhov, D. (2013). Integrating Combinatorial Scheduling Inventory Management
Queueing Theory. Ph.D. thesis, Department Mechanical Industrial Engineering,
University Toronto.
571

fiTerekhov, Tran, Down, & Beck

Terekhov, D., Beck, J. C., & Brown, K. N. (2009). constraint programming approach
solving queueing design control problem. INFORMS Journal Computing,
21 (4), 549561.
Terekhov, D., Tran, T. T., & Beck, J. C. (2010). Investigating two-machine dynamic flow
shops based queueing scheduling. Proceedings ICAPS10 Workshop
Planning Scheduling Uncertainty.
Terekhov, D., Tran, T. T., Down, D. G., & Beck, J. C. (2012). Long-run stability dynamic scheduling. Proceedings 22nd International Conference Automated
Planning Scheduling (ICAPS12), pp. 261269.
Towsley, D., & Baccelli, F. (1991). Comparisons service disciplines tandem queueing
network real time constraints. Operations Research Letters, 10 (1), 4955.
Tran, T. T. (2011). Using queueing analysis guide combinatorial scheduling dynamic
environments. Masters thesis, Department Mechanical Industrial Engineering,
University Toronto.
Van Hentenryck, P., & Bent, R. (2006). Online Stochastic Combinatorial Optimization.
MIT Press.
Widmer, M., & Hertz, A. (1989). new heuristic method flow shop sequencing
problem. European Journal Operational Research, 41 (2), 186193.
Wierman, A., Winands, E., & Boxma, O. (2007). Scheduling polling systems. Performance Evaluation, 64, 10091028.
Wu, C. W., Brown, K. N., & Beck, J. C. (2009). Scheduling uncertain durations:
Modeling -robust scheduling constraints. Computers & Operations Research,
36 (8), 23482356.
Xia, C. H., Shanthikumar, J. G., & Glynn, P. W. (2000). asymptotic optimality
SPT rule flow shop average completion time problem. Operations Research,
48 (4), 615622.
Xue, S., Fern, A., & Sheldon, D. (2012). Scheduling conservation designs via network cascade
optimization. Proceedings 26th AAAI Conference Artificial Intelligence
(AAAI12), pp. 391397.
Yoon, S. W., Fern, A., Givan, R., & Kambhampati, S. (2008). Probabilistic planning via
determinization hindsight. Proceedings 23rd AAAI Conference Artificial
Intelligence (AAAI08), pp. 10101016.

572

fiJournal Artificial Intelligence Research 50 (2014) 639696

Submitted 02/14; published 07/14

Planning Automatic Portfolio Configuration:
PbP Approach
Alfonso Emilio Gerevini
Alessandro Saetti

alfonso.gerevini@unibs.it
alessandro.saetti@unibs.it

Dipartimento di Ingegneria dellInformazione
Universita degli Studi di Brescia
Via Branze 38, I-25123 Brescia, Italy

Mauro Vallati

m.vallati@hud.ac.uk

School Computing Engineering
University Huddersfield
Huddersfield, West Yorkshire, HD1 3DH, UK

Abstract
field domain-independent planning, several powerful planners implementing
different techniques developed. However, one systems outperforms
others every known benchmark domain. work, propose multi-planner
approach automatically configures portfolio planning techniques given
domain. configuration process given domain uses set training instances to:
(i) compute analyze alternative sets macro-actions planner
portfolio identifying (possibly empty) useful set, (ii) select cluster planners,
one identified useful set macro-actions, expected perform best,
(iii) derive additional information configuring execution scheduling
selected planners planning time. resulting planning system, called PbP (Portfoliobased Planner), two variants focusing speed plan quality. Different versions
PbP entered learning track sixth seventh International Planning
Competitions. paper, experimentally analyze PbP considering planning speed
plan quality depth. provide collection results help understand PbPs
behavior, demonstrate effectiveness approach configuring portfolio
planners macro-actions.

1. Introduction
last fifteen years, field automated plan generation achieved significant
advancements, several powerful domain-independent planners today available, e.g.,
propositional planning, FF (Hoffmann & Nebel, 2001), LPG (Gerevini, Saetti, & Serina,
2003), SGPlan (Chen, Hsu, & Wah, 2006), Fast Downward (Helmert, 2006), LAMA
(Richter & Westphal, 2010). Moreover, systems performs well
(more less large) class planning domains problems, well-known one
outperforms others every available benchmark domain (see, e.g., Roberts & Howe,
2009). would useful multi-planner system automatically selects
combines efficient planner(s) portfolio given domain.
c
2014
AI Access Foundation. rights reserved.

fiGerevini, Saetti, & Vallati

performance current planning systems typically affected structure
search space, depends considered planning domain. many domains,
planning performance improved exploiting knowledge domain
structure explicitly given part input formalization,
automatically derived it. particular, several approaches encoding additional knowledge form macro-actions proposed (e.g., Botea, Enzenberger, Muller,
& Schaeffer, 2005; Newton, Levine, Fox, & Long, 2007). macro-action (macro short)
sequence actions planned one time like single action. using
macros important tradeoff consider. use speedup planning
process, reduces number search steps required reach solution, also
increases search space size, could slow planning process. Moreover,
known effectiveness macros depend planning algorithm: set
macros increase performance planner, decrease it, irrelevant,
another.
paper, propose approach automatically configuring portfolio existing
planners, possibly using useful set macros them. configuration relies
statistical analysis performance planners portfolio usefulness
automatically generated sets macros, considering set training problem instances
given domain. configuration knowledge automatically generated
analysis consists cluster planners defined by: ordered subset planners
initial portfolio, planning time combined using round-robin strategy;
set useful macros planner; sets planning time slots. planning
time slots specify amount CPU time allocated planner cluster
planning. resulting planning system called PbP (Portfolio-based Planner).
current implementation PbP incorporates two systems generation
macros nine efficient planners, architecture open consider (current
future) planner additional alternative system. PbP used without configuration knowledge, planners portfolio scheduled (without macros) simple
round-robin strategy predefined CPU-time slots assigned (randomly
ordered) planners. PbP used configuration knowledge domain consideration, selected cluster planners (possibly using relative selected
sets macros) scheduled, ordering favors planners configuration
performed best, planning time slots defined computed configuration
knowledge. selection exploitation macros PbP, worth noting
planners portfolio configured PbP necessarily use macros learned
them. configuration process, system evaluates planner portfolio
set macros computed it, well empty macro set,
independent planning systems.
PbP two main variants: PbP.s, focusing speed, PbP.q, focusing plan
quality. preliminary implementation PbP.s (Gerevini, Saetti, & Vallati, 2009) entered
learning track sixth international planning competition (IPC6) overall
winner competition track (Fern, Khardon, & Tadepalli, 2011).1 recently,
1. observed IPC6 organizers, surprisingly, IPC6 problems use configuration
knowledge considerably speedup version PbP.s. reasons implementation bugs concerning configuration phase planning phase, inefficient use

640

fiPlanning Automatic Portfolio Configuration: PbP Approach

revised optimized version PbP speed quality variants entered
learning track seventh competition (IPC7), winner
competition track (Coles, Coles, Olaya, Celorrio, Lopez, Sanner, & Yoon, 2012).
large experimental analysis presented paper provides collection results
help understand performance behavior PbP effectiveness portfolio
configuration methods. particular, analysis (i) confirms good performance
PbP context IPC6-7 benchmarks, (ii) compares PbP existing
approaches configure planner portfolio, (iii) evaluates accuracy PbPs approach
identify effective cluster planners strength using (configured
unconfigured) multi-planner respect single planner, (iv) investigates usefulness
macros considered benchmarks, showing PbP selects useful macro sets,
(v) examines execution scheduling configuration PbP selected planners
configured portfolio, demonstrating default strategy works well compared
possible strategies considered analysis.
Several ideas techniques investigated context PbP use build previous
work. Besides presenting evaluating effective approach configuring planner
portfolio, research presented paper corroborates, validates evaluates
hunches empirical studies done researchers planning. particular,
experimental analysis confirms certain sets macros useful accelerate
planning speed improve plan quality (Botea et al., 2005; Coles & Smith, 2007; Newton
et al., 2007) others harmful, diversity planning techniques important
construction effective planner portfolio, observed by, e.g., Roberts Howe
(2009), round-robin scheduling planner execution times robust
strategy planner portfolio (Howe, Dahlman, Hansen, vonMayrhauser, & Scheetz, 1999;
Roberts & Howe, 2006).
remainder paper organized follows. Section 2 discusses related work;
Section 3 describes PbP approach; Section 4 presents results experimental
study; finally, Section 5 gives conclusions.

2. Related Work
section, brief presentation prominent work algorithm portfolio
design automated reasoning, describe related work others planner portfolio
design automated planning, pointing important differences PbP
related work. specific differences similarities indicated
following sections presenting technical results.
2.1 Algorithm Portfolio Design Automated Reasoning
field automated reasoning, idea using portfolio techniques
investigated several researchers. prominent example work Gomes Selman
(2001), conducted theoretical experimental study parallel run stochastic
algorithms solving computationally hard search problems. work shows
Linux shell scripts (evident especially small easy problems), corrected
competition obtaining much better results (Gerevini et al., 2009).

641

fiGerevini, Saetti, & Vallati

conditions running different stochastic algorithms parallel give computational gain
running multiple copies stochastic algorithm parallel.
Many papers algorithm portfolio design concern definition models select
best algorithm(s) instance certain problem according values
predetermined features instance (Rice, 1976). example, algorithm portfolios
designed aim solve instances SAT, MaxSAT, QBF (Matos, Planes,
Letombe, & Marques-Silva, 2008; Pulina & Tacchella, 2007; Xu, Hutter, Hoos, & LeytonBrown, 2008). SATzilla prominent example algorithm portfolio designed SAT
(Xu et al., 2008). SATzilla uses machine learning techniques build predictor
runtime class SAT solvers. SATzilla attempts solve instance SAT
problem, computes values features instance, predicts performance
SAT solvers incorporates, selects promising SAT solvers order
accordingly predicted performance, finally runs selected SAT solvers using
established ordering predicted required CPU times.
Matos et al. (2008) propose algorithm portfolio solving MaxSAT problem.
portfolio computes values several features given instance MaxSAT problem,
estimates runtime solver portfolio, solves instance
estimated fastest solver. estimation done using (linear) model configured
performing ridge regression (Marquardt & Snee, 1975). Similarly, Pulina Tacchella
(2007) study algorithm portfolio solving QBF problem. identify features
QBF problem, investigate usage four inductive models select best
solver use according values identified features.
2.2 Planner Portfolio Design Automated Planning
Regarding automated planning, prominent planners combining one algorithms
proposed. Blackbox (Kautz & Selman, 1999) use variety satisfiability engines (the initial version also included Graphplan algorithm), FF (Hoffmann & Nebel,
2001), LPG (Gerevini et al., 2003; Gerevini, Saetti, & Serina, 2006) SGPlan5 (Chen et al.,
2006) include backup strategy using alternative search technique run
default method fails. algorithm combination systems straightforward
use automatic portfolio configuration.
Previous work planner portfolios includes approach proposed Howe collaborators (Howe et al., 1999; Roberts & Howe, 2007, 2009; Roberts, Howe, Wilson, &
desJardins, 2008). rest paper, refer Howe collaborators approach using name first planner portfolio, BUS (Howe et al., 1999), although
analysis approach consider recent techniques planner
portfolio configuration. approach learns models performance set planners.
planning time, round-robin policy used schedule runs planners
set, learned models exploited determine order runs.
configuration-knowledge derived approach domain-independent: performance
models planners built using several predictive models WEKA data mining
package (Witten & Frank, 2005), set planners forming portfolio determined
set covering algorithm solved training problems across several different
planning domains.
642

fiPlanning Automatic Portfolio Configuration: PbP Approach

work BUS originally inspired approach. PbP similarities it,
computes uses different configuration knowledge, methods selecting
ordering portfolio planners considerably different. portfolio configuration
PbP generates domain-optimized clusters planners, selection ordering
PbP based statistical analysis planners performance set training
problems using Wilcoxon sign-rank test, also known Wilcoxon matched pairs
test (Wilcoxon & Wilcox, 1964).2 Finally, system compute, analyze use
macros, consider plan quality.
Similarly work Howe et al. (1999), Roberts Howe (2007), techniques used Cenamor, de la Rosa, Fernandez (2013), Fawcett, Vallati, Hutter,
Hoffmann, Hoos, Leyton-Brown (2014) learn models performance set planners
according predetermined features. work Cenamor et al. (2013), features derived SAS+ representation planning problem. approach,
learned models used determine planners run, order,
long. selected planners run sequentially either using amount CPU time
uniformly assigned determined predicted execution time. experimental results work Cenamor et al. (2013) show problems domains different
used learn models, configured portfolios perform worse running
unconfigured portfolio consisting incorporated planners uniform CPU time
assigned them.
work described Fawcett et al. (2014) focused generating models accurately predicting planners runtime. models exploit large set instance features,
derived PDDL SAS+ representations problem, SAT encoding
planning problem, (short) runs planners. experimental results work
Fawcett et al. (2014) indicate generated performance models able produce
accurate runtime predictions.
Fast Downward Stone Soup (here abbreviated FDSS) approach selecting combining set forward-state planning techniques (Helmert, Roger, & Karpas, 2011). Using
IPC6 scoring function, FDSS evaluates class candidate techniques basis
performance set training problem instances different domains,
builds domain-independent sequential portfolio forward planners hill-climbing algorithm searching space possible sequential combinations evaluated candidate
techniques. automatic portfolio configuration FDSS PbP aims building different types planning systems: single efficient domain-independent planner portfolio
FDSS; efficient domain-optimized portfolio planner given domain PbP.
configuration processes resulting configured portfolios FDSS PbP
significantly different. particular, PbP configures portfolio generic planners (using
different styles planning), one (possibly empty) set useful learned macros,
considered FDSS domain-independent purpose. Moreover,
execution scheduling strategy PbP runs selected planners round-robin rather
sequentially.
2. context planning, Wilcoxon sign-rank test previously used also work
Long Fox (2003), Gerevini, Haslum, Long, Saetti, Dimopoulos (2009), Gerevini et al. (2009),
Roberts Howe (2009).

643

fiGerevini, Saetti, & Vallati

ParLPG (Vallati, Fawcett, Gerevini, Hoos, & Saetti, 2013b) Fast Downward-autotune
(Fawcett, Helmert, Hoos, Karpas, Roger, & Seipp, 2011) configure parameters planners LPG Fast Downward (Helmert, 2006), respectively, using set training problems
given domain order obtain combinations parameters two planners
perform especially well given domain. frameworks uses stochastic local
search procedure ParamILS search high-performance configurations parameters
evaluating promising configurations (Hutter, Hoos, & Stutzle, 2007; Hutter, Hoos, LeytonBrown, & Stutzle, 2009). extended version FDSS (Seipp, Braun, Garimort, & Helmert,
2012) involves twenty one configurations Fast Downward, obtained configuring parameters Fast Downward-autotune twenty one different domains (Fawcett et al.,
2011), combined several alternative sequential strategies allocating CPU
times them.
ASAP (Vallati, Chrpa, & Kitchin, 2013a) recent system selecting promising planner set candidates planners derives much power use
entanglements (Chrpa & Bartak, 2009; Chrpa & McCluskey, 2012). Entanglements
relations planning operators predicates used reformulate domain model
removing unpromising operator instances restricting applicability actions
certain states. problem resulting modified domain become significantly
easier solve planner. hand, since ASAP uses approximate method
decide entanglements, PSPACE-complete (Chrpa, McCluskey, & Osborne, 2012),
problem solvable original domain become unsolvable reformulated domain. Given planning domain modified entanglements set planners,
ASAP identifies promising planners one highest IPC score
(Jimenez, Coles, & Coles, 2011) set training problems.

3. Automated Planner Portfolio Design PbP
section, introducing preliminaries defining problem configuring
planner portfolio execution solve planning problems, describe architecture
techniques approach configure execute planner portfolio.
3.1 Preliminaries Configuring Executing Planner Portfolio
Differently existing work algorithm portfolio design
aware, PbP design planner portfolio solving specific instance
planning problem according values predetermined features instance.
Instead, planning problems gathered according planning domains, planner portfolio designed whole domain. basis choice empirical
observation often exists single planner combination planners performs generally better problems domain. seems something
peculiar automated planning hold types reasoning problems,
makes PbP somewhat atypical general literature algorithm portfolio design.
Let planning domain, CPU-time limit, P set n planners (initial
portfolio), predefined parameter values. problem configuring
P consists computing set triples {hPi , Mi , Si | = 1 . . . m}, where: 1 n,
Pi P, Mi (possibly empty) set macro operators learned Pi domain D, Si
644

fiPlanning Automatic Portfolio Configuration: PbP Approach

sequence increasing CPU times. CPU times (real numbers) called planning
time slots, time lower equal .
output set triples identified portfolio configuration algorithm configured
(planner) portfolio P D, rest paper also called selected
planner cluster (or simply cluster). Depending planners, macros planning
time slots chosen, many candidate solutions portfolio configuration
problem. special case, call unconfigured (planner) portfolio, defined
{hPi , , Spre | = 1 . . . |P|}, Spre predefined h0.1, 1, 10, 100, 1000i (in seconds).
Like BUS, PbP uses round-robin policy scheduling runs planners
configured portfolio. Let = {hPi , Mi , Si | = 1 . . . m} planner portfolio configured
domain D. Portfolio executed solve planning problem roundrobin scheduling processes where: process corresponds running planner Pi
macros Mi (Pi + Mi short), according order time slices derived
sequences S1...m . precisely, circular order planners determined
considering values t1...m defined first planning time slot
sequences S1 . . . Sm . ti < tj , Pi ordered Pj ; ti = tj , relative order Pi
Pj arbitrarily decided (i.e., case Pi runs Pj iff < j), every i, j 1 . . .
6= j. planner Pi + Mi initially run total CPU time allocated
process ti , planner terminates earlier. planner Pi + Mi terminate
within assigned planning time slot ti , suspended, resumes next time
time slot assigned it. additional CPU time assigned processes
already terminated. When, according circularity order, planner Pi + Mi
resumes execution, total CPU time assigned (from start execution)
equal next unprocessed time slot Si (i.e., j-th value Si j-th time
Pi + Mi runs).
Figure 1 shows example round-robin scheduling portfolio {hP1 , M1 ,
h10, 40, 160, . . . ii, hP2 , M2 , h20, 60, 180, . . . ii}, assuming P1 + M1 terminates using
80 CPU time units, P2 + M2 using 120 CPU time units. P1 + M1 runs
planner P2 + M2 , first time slot P1 + M1 (i.e., 10) lower first
time slot P2 + M2 (i.e., 20). round-robin scheduler suspends P1 + M1 10 time
units, gives P2 + M2 20 time units CPU time. process repeated suspending
P1 + M1 total execution P1 + M1 consumed 40 time units, suspending
P2 + M2 total execution P2 + M2 consumed 60 time units. next
iteration, P1 + M1 suspended total execution time reaches 80 time units,
but, end third time slot, i.e., time 140, P1 + M1 terminates needs
CPU time. Then, P2 + M2 resumes run, terminates time 200.
example, planners portfolio use first three time slots.
Given set training problems domain D, propose approach configuring
initial planner portfolio statistical analysis performance
planners initial portfolio alternative sets computed macros.
effectiveness determined configured portfolios evaluated set test
problems D, experimental analysis disjoint training problem set
that, specified otherwise, always formed known benchmark problems.
proposed approach implemented planning system called PbP (Portfolio-based
Planner). following, depending context, PbP used indicate either
645

fiGerevini, Saetti, & Vallati

P1 M1
P2 M2
10

30

60

100

140

200

Time

Figure 1: example round-robin scheduling PbP running portfolio {hP1 , M1 , h10, 40, 160, . . . ii, {hP2 , M2 , h20, 60, 180, . . . ii} given planning
problem, assuming planner P1 using macros M1 takes total 80 CPUtime units terminate P2 M2 takes total 120 CPU-time units.

method configuring planner portfolio, generated configured portfolio.
experimental evaluation configured portfolios generated PbP, baseline
planner portfolio, use unconfigured planner portfolio, also called
unconfigured version PbP denoted PbP-nok (while PbP indicate
generated configured planner portfolio).
3.2 Architecture Components PbP
architecture PbP consists following five main components, combined
described Figure 2.
3.2.1 Macro-Actions Computation
integrated planner, PbP computes sets alternative macros using following two approaches.
Wizard, PhD thesis version (Newton et al., 2007). system implements three
learning techniques based offline evolutionary methods, use genetic operators
compute macros given planner plans solving set training problem
instances input domain. three learning techniques called chunking,
bunching, clumping: chunking learns individual macros original domain
operators; bunching learns bunches macros given pool macros (such
macros learned chunking process); clumping learns individual
macros sets macros simultaneously. learned macros filtered fitness
value. fitness value reflects filtering criteria including number solved
problems CPU time required solve training problems using domain
operators augmented learned macros. computed macros,
fitness value macro lower threshold, macro discarded. Therefore,
planner incorporated PbP (expect Macro-FF), PbP using Wizard
generate three sets macros planner. order determine sets
macros used configured portfolio, performance planner
evaluated PbP with/without using sets learned filtered macros
training problems. evaluation performed Planner cluster
646

fiPlanning

Planning Automatic Portfolio Configuration: PbP Approach

Incorporated Planners:

Domain
problem solve

Multi-planner
round-robin scheduling
Time limit

Fast-downward (Helmert, 2006)

Cluster planners macros

Planning time
Time slots
slots computation

LPG-td (Gerevini, Saetti & Serina, 2006)
Macro-FF (Botea et al., 2005)
Marvin (Coles & Smith, 2007)
Metric-FF (Hoffmann & Nebel, 2005)
SGPLAN5 (Chen, Wah & Hsu, 2006)

Portfolio configuration

LAMA (Richter & Westphal, 2010)

YAHSP (Vidal, 2004)

Solution plan
failure

Planner cluster
selection & ordering

Performance planners macros

Macro-actions
computation
Wizard

Planners macros

Performance
measurement

MacroFF

Planners

Domain
training probs

Time limit

ParLPG (Vallati et al., 2011)

Figure 2: sketch PbPs architecture.
selection ordering component. simplicity, sets learned macros
identified names techniques used derive them.
Macro-FF (Botea et al., 2005; Botea, Muller, & Schaeffer, 2007b). approach
implemented Macro-FF (Botea et al., 2005) computes macros analyzing solutions set training problem instances, macros appear frequently
significantly reduce required search effort preferred. particular,
first Macro-FF solves training problems using enhanced version FF;
generates macros considering frequency sequences actions forming
macros appear computed solutions.3 macro generation, Macro-FF
solves training problems using computed macros, ranks macros terms
obtained search effort gain, using ranking selects five sets
macros M1..5 , Mi = 1..5 set macros formed best learned
macros. version approach integrated PbP contains enhancements
described Botea et al. (2007b). Since macros learned Macro-FF coded
using ad-hoc language, PbP five learned sets macros M1..5 used
Macro-FF planner.

3.2.2 Planner Performance Measurement
expensive computation step configuration portfolio. PbP
runs integrated planner expect Macro-FF without three sets macros
3. experiments presented Section 4, observed Macro-FF computes macros
enhanced version FF solves training problem.

647

fiGerevini, Saetti, & Vallati

learned Wizard input training problem set, using input CPU time
limit planner run. Similarly, Macro-FF runs without five sets
macros learned itself. current implementation PbP incorporates eight well-known
successful planners, Fast Downward (Helmert, 2006), LAMA (Richter & Westphal, 2010),
LPG-td (Gerevini et al., 2006), Macro-FF (Botea et al., 2005, 2007b), Marvin (Coles & Smith,
2007), Metric-FF (Hoffmann, 2003), SGPlan5 (Chen et al., 2006), YAHSP (Vidal, 2004)
recent version LPG (ParLPG) using dedicated configuration phase automatically
optimize setting collection parameters governing behavior several parts
system (Vallati et al., 2013b). Basically, running ParLPG consists running LPG using
domain-specific parameter configuration. Every incorporated planner runs using
default parameter configuration. Marvin, implies planning learn
memorize macros escape plateaus. run, PbP measures planner
performance terms of: number problems solved within , CPU time required solving
training problems, quality computed solutions. incremental planners,
i.e., LPG, ParLPG LAMA, PbP measures quality solutions generated
problem corresponding CPU times. Finally, note macro-actions
computation Macro-FF Wizard already run incorporated planners hence,
principle, performance planners macros could measured Macro-FF
Wizard compute them. However, technical difficulties and, simplicity,
PbP duplicates runs (incorporated) planners.
3.2.3 Planning Time Slots Computation
method computing planning time slots PbP variant CPU-time allocation strategy proposed Roberts Howe (2007) round-robin planner scheduling. Let hp1 , . . . , pn sequence increasing percentages, tpi (i {1, . . . , n})
minimum CPU time required planner P set macros learned (P +
short) order solve percentage training problems equal pi . PbPs
configuration planner portfolio, planning time slots P + defined
= htp1 , . . . , tpn i.
difference planning time slots PbP approach Roberts
Howe explained following example. Assume computed planning
time slots planner using macros (A+MA ) h0.20, 1.40, 4.80, 22.50, . . .
planner B using macros MB (B + MB ) h14.5, 150.8, . . . i. Then, pair
planners, differently approach Roberts Howe, PbP extends first time
slot + (0.20) 4.80, i.e., greatest time slot + smaller
first time slot B + MB ; similarly subsequent time slots. first time slot
+ extended, slowest planner B + MB would initially run CPU
time much greater CPU time initially assigned fastest planner + ,
many problems planner + quickly solves (e.g., using one CPU second),
PbP would perform much slower. worth noting using time slot extension
observed high performance gain small easy problems.
rest paper, sequence increasing percentages hp1 , ..., pn used define
planning time slots called problem coverage percentage vector (PCPV). default
648

fiPlanning Automatic Portfolio Configuration: PbP Approach

PCPV PbP sequence h25, 50, 75, 80, 85, 90, 95, 97, 99i (n = 9),
used work Roberts Howe (2007).
3.2.4 Planner Cluster Selection Ordering
last step configuration process PbP. PbP selects cluster planners
initial portfolio (as described Section 3.3), one (possibly empty) set
useful macros, according measured performance computed planning time
slots.
macro selection, note PbP explicit independent mechanism
selecting macros used configured portfolio, macros shared
planners tools used learn (Wizard Macro-FF) generate
macro sets specific input planner. Planners macro sets selected together,
since planner cluster selection PbP considers candidate planner using two different
sets macros learned two different candidate planners.
execution order planners selected cluster implicitly defined
increasing first planning time slots associated planners. Section 3.3 describes
planner cluster selection detail.
3.2.5 Multi-Planner Round-Robin Scheduling
PbP configured planner portfolio domain consideration,
problem instance domain encountered, PbP runs selected ordered cluster
planners (each one using relative selected set macro-actions) round-robin
scheduling algorithm using computed planning time slots, similar one investigated many portfolio algorithms (see, e.g., Howe et al., 1999; Roberts & Howe, 2006,
2007). Alternative planner scheduling strategies possible, sequential execution
or/and using configured planning time slots. However, according experimental results
presented Section 4.8, default round-robin strategy planning
time slots derived default PCPV robust performs generally well. Concerning
termination resulting multi-planner, PbP.s terminates either given (execution)
CPU-time limit exceeded, returning failure, one among selected planners computes solution (output PbP.s); PbP.q terminates either time exceeded,
selected planners terminate. PbP.q generates solution within t, returns failure;
otherwise, returns best computed solution.
3.3 Selecting Planner Cluster
performance measurement time slot computation phases, PbP analyzes
obtained results identify best cluster planners macros domain
consideration given CPU-time limit . done simulating, every cluster
C k planners, (possibly empty) set macros, round-robin execution planners C solving training problems used performance
measurement phase.4 simulation done using data runs conducted
4. experiments parameter k set 3. k greater 3, experimentally observed
considered benchmark domains problems cluster selected PbP would same.
maximum number possible combinations planners currently incorporated PbP

649

fiGerevini, Saetti, & Vallati

performance measurement phase (the planners re-run), ignoring data
planners always perform worse another incorporated planner (i.e., planner
performs worse another one across training problems domain
discarded). CPU-time limit simulated execution cluster (the
time given run single planner performance measurement phase).
performances simulated cluster runs compared statistical analysis based
Wilcoxon sign-rank test (Wilcoxon & Wilcox, 1964). test applies set paired
observations (a sample larger population), tells us plausible assume
correlation pairwise observed quantities. case,
paired observations are, e.g., simulated runtimes two clusters training
problem instance, correlation means equally likely
see one cluster solving problem faster see opposite
sample problems.
purposes, Wilcoxon sign-rank test appropriate require
us know sample distribution, makes assumption distribution.
is, way know priori hard planning problem is, hence
distribution simulated performance clusters. Consequently, stated
Gibbons Chakraborti (2003), critical use non-parameterized test,
Wilcoxon sign-rank test. also investigated usage methods
compare performance simulated runs planner clusters, including IPC score
function also used Vallati et al. (2013a). However, experimentally observed
that, IPC7 domains, method less effective usage Wilcoxon
sign-rank test.
PbP, performance measure considers either CPU time (PbP.s) plan
quality (PbP.q). data carrying test PbP.s derived follows.
planning problem, system computes difference simulated execution
times compared clusters. planner cluster solve problem, corresponding simulated time twice CPU-time limit;5 cluster solves problem,
problem considered. difference simulated times normalized
value best simulated time comparison (e.g., cluster C1 requires 200
seconds cluster C2 220, difference 10% favor C1 ). absolute values
differences ranked increasing numbers, starting lowest value.
(The lowest value ranked 1, next lowest value ranked 2, on.) ranks
positive differences ranks negative differences summed, yielding
two values r+ r , respectively. performance two compared clusters
significantly different, number positive differences r+ approximately equal
number negative differences r , sum ranks set
positive differences approximately equal sum ranks set. Intuitively, test considers weighted sum number times cluster performs better
considered sets macros
hence, k = 3, maximum number clusters
P 38;
38
evaluated run simulation i=k
= 9177. number clusters 3 different
i=1

combinations planners macros 38 current implementation.
5. minimum value ensures performance gap problem solved one cluster
planners unsolved compared cluster bigger performance gap problem
solved compared clusters.

650

fiPlanning Automatic Portfolio Configuration: PbP Approach

compared one. sum weighted test uses performance
gap assign rank performance difference.
number samples sufficiently large, T-distribution used Wilcoxon
sign-rank test approximately normal distribution, characterized two parameters called z-value p-value. higher z-value, significant
difference performance is. p-value represents level significance
performance gap. p-value greater 0.05, null hypothesis
performance compared pair planners statistically similar refused, alternative hypothesis performance statistically different accepted. Otherwise,
statistically significant evidence perform differently, PbP considers
perform pretty much similarly.
results Wilcoxon sign-rank test used form directed graph
nodes compared clusters, edge cluster C1 another cluster C2
indicates C1 performs better C2 . graph already used Long
Fox present results 3rd International Planning Competition (Long & Fox,
2003). strongly connected component graph collapsed single node
representing elements clusters collapsed nodes. resulting DAG,
PbP considers nodes without incoming edges (the graph root nodes).
one root node, selected cluster, otherwise PbP uses secondary criteria
select promising cluster among root nodes. criteria number
solved problems, sums ratios (simulated) CPU times planners
compared clusters, first planning CPU-time slots involved planners.
Specifically, PbP selects cluster among root nodes simulation solves
highest number training problems. break ties, every pair selected clusters x
|sx sy |
PbP computes ratio max{s
, sx sy sums (simulated)
x ,sy }
CPU times clusters x y, respectively; ratio greater threshold 0.05,
compared cluster worst sum CPU times discarded. number
remaining clusters still greater one, PbP selects cluster lowest first
planning CPU-time slots involved planners. Finally, remaining ties broken
selecting cluster randomly, experiments cluster ever randomly
selected.
method used select cluster planners macros PbP.q similar,
applies plan qualities resulting cluster execution simulation, rather
CPU times done PbP.s. simulation, PbP.q considers also intermediate
solutions (i.e., generated last one, best quality)
relative CPU times computed basic incremental planners considered
clusters. solutions ignored, simulated plan quality clusters including
incremental planners could much worse actual quality. example, assume
CPU-time limit 900 seconds, FF computes solution quality 50 using 100
seconds, LAMA computes two solutions quality 20 19 using 120 880 seconds,
respectively. intermediate solutions LAMA ignored, estimated plan quality
cluster formed planners FF LAMA would equal quality plan
generated FF (the second solution generated LAMA could computed cluster
using 980 seconds, greater CPU time limit), although intermediate
(first) solution LAMA much better FFs solution.
651

fiGerevini, Saetti, & Vallati

Finally, note performance incorporated planners measured
CPU-time limit , portfolio PbP.s/q (re)configured time limit
simply ignoring solutions computed time simulation
planner cluster performance. , equally distributed among planners
selected cluster. planner terminates allocated time, remaining time
also equally distributed planners still running.
3.4 Integrated Basic Planners
subsection, give brief description nine basic planners
currently incorporated PbP. Much detailed information available
corresponding referred papers.
Metric-FF (Version 2.1; Hoffmann, 2003). Metric-FF inherits main ideas used FF
(Hoffmann & Nebel, 2001). FFs search strategy variation hill-climbing space
world states, FF goal distance estimated solving relaxed task
successor world state. Compared first version FF, Metric-FF enhanced
goal orderings pruning techniques ordering knowledge provided goal
agenda. Moreover, deals level 2 pddl2.1 (Fox & Long, 2003), i.e., numerical state
variables, numerical action preconditions effects.
YAHSP (Version 1.1; Vidal, 2004). YAHSP extends search procedure FF
information extracted FFs relaxed plan. evaluated world state, YAHSP
exploits look-ahead strategy complete best-first search employing actions
relaxed plans order find beginning valid plan lead reachable
world state.
MacroFF (Botea et al., 2005, 2007b). Macro-FF extends FF support using macrooperators search, engineering enhancements. One main features
planner version integrated PbP use iterative macros (Botea et al., 2007b),
i.e., runtime combinations macro operators, instantiated attempting use
many actions FFs relaxed plan possible. search procedure FF,
iterative macros successfully instantiated considered generation
next world states.
Marvin (Release 1; Coles & Smith, 2007). Marvin another planner based FF.
main improvement w.r.t. FF memorizing plateau-escaping action sequences discovered
(local) search FF. action sequences form macros, applied
later plateaus once-again encountered FFs search order escape
plateaus quickly.
SGPlan (Version 5.22; Chen et al., 2006) domain-modification script (Coles & Coles,
2011). SGPlan5 exploits partition-and-resolve strategy partition mutual-exclusion
constraints planning problem subgoals subproblems, solves subproblems individually using modified version Metric-FF planner, resolves
violated global constraints iteratively across subproblems. observed
performance SGPlan affected rules detecting domain name
number domain operators (Coles & Coles, 2011). work, intend consider
652

fiPlanning Automatic Portfolio Configuration: PbP Approach

available implemented systems chances perform well (possibly combination
others) least one domain range varied existing benchmark domains.
SGPlan definitely one systems. However, order prevent usage
domain-specific detection rules SGPlan that, differently planners incorporated PbP, would make SGPlan domain-specific domains, induced
SGPlan behave domain-independently domain modification script, proposed
Coles Coles (2011). script changes domain name, adds never-applicable
action domain, runs SGPlan obtained domain. addition,
domain-modification script also changes names domain operators.
Fast Downward (Version 1.0.1; Helmert, 2006). Fast Downward (abbreviated FD)
translates input pddl problem specification multi-valued state variable representation SAS+ (Backstrom & Nebel, 1995), searches plan space
world states using heuristic derived causal graph, particular graph representing
causal dependencies SAS+ variables. PbP integrates 2006 version planner.
main improvement compared earlier version planner 2004
propositional satisficing track IPC4 addition safe abstraction, form problem
simplification allows planner solve certain kinds simple problems without
search.
LAMA (Version 2008; Richter & Westphal, 2010). LAMA built Fast Downward, using
SAS+ state variables multi-heuristic search. core feature use pseudoheuristic derived landmarks, propositions must true every solution
planning task. Moreover, weighted A? search used iteratively decreasing weights,
planner continues search plans better quality.
LPG-td (Gerevini et al., 2006). LPG-td inherits main ideas used LPG (Gerevini et al.,
2003). LPG uses stochastic local search space partial plans represented action
graphs. search steps certain graph modifications transforming action graph
another one. LPG-td includes accurate heuristics selecting graph modifications
LPG.
ParLPG (Version IPC7; Vallati et al., 2013b). ParLPG recent system based
idea automatically configuring generic, parameterized planner using set training
planning problems order obtain speed-optimized planners perform especially well
domains problems. ParLPG uses FocusedILS variant off-the-shelf,
state-of-the-art automatic algorithm configuration procedure ParamILS (Hutter et al., 2007,
2009), planning system LPG (ver. 1.0), several components
configured flexibly via many exposed configurable parameters.

4. Experimental Analysis
section, present results large experimental study PbP
following main goals:
(G1) describing configured portfolios analyzing configuration process PbP
(Section 4.2);
653

fiGerevini, Saetti, & Vallati

(G2) analyzing efficiency PbP.s/q terms speed plan quality context
planning competitions IPC6-7 (Section 4.3);
(G3) comparing performance planner portfolio configured PbP.s/q versus
planning systems based planner portfolios (Section 4.4);
(G4) evaluating effectiveness using (automatically computed) domain-specific
configuration knowledge PbP.s/q (Section 4.5);
(G5) comparing performance planner portfolio configured PbP.s/q versus
single basic planners portfolio, evaluating accuracy planner
cluster selection PbP.s/q (Section 4.6);
(G6) analyzing kind macros selected PbP planners configured
portfolio, evaluating effectiveness using selected macro set, understanding PbP.s/qs accuracy selecting useful set (Section 4.7);
(G7) investigating possible alternative methods scheduling execution
planners selected cluster, understanding effectiveness default
round-robin strategy PbP.s/q (Section 4.8).
experimental study uses various versions PbP, important
listed Table 1. G1, show CPU time configuration step,
evaluate size training problem set important derive effective configured
portfolios. G2, PbP compared planners entered learning track
IPC6-7 winner deterministic track IPC7. G3, performance
PbP analyzed w.r.t. FDSS (Seipp et al., 2012) BUS, portfolio approach proposed
Roberts Howe (2007). Although BUS FDSS propose design domainindependent planner portfolios, principle also used, like PbP, generate
domain-optimized planning systems. experimentally investigate also use
approaches, comparing PbP. G4, show results three different
experimental comparisons: comparison PbP configured using learned domainspecific knowledge (DSK), unconfigured version PbP (PbP-nok) randomly
configured version PbP (PbP-rand); comparison performance gaps PbP
PbP-nok w.r.t. gaps IPC6-7 planners with/without learned knowledge;
comparison PbP using DSK, PbP configured single domain without using
macros, PbP configured across IPC7 domains (PbP-allD). G5, conducted
three experiments which: performance PbP incorporated planners
compared; performance PbP analyzed w.r.t. best incorporated planner (without
using macros) every IPC7 domain; and, finally, PbP compared best cluster
incorporated planners (possibly using macros) every IPC7 domain. G6, compare
performance planners forming clusters selected PbP using (i) macros,
(ii) set macros selected PbP, (iii) best performing set macros; moreover,
show comment features sets macros selected used PbP. Finally,
G7 perform two experimental analysis: comparison clusters selected PbP
using different scheduling strategies, comparison performance PbP using
different PCPVs (PbP R1-R2/S1-S2).
654

fiPlanning Automatic Portfolio Configuration: PbP Approach

PbP (default)
PbP-IPC6
PbP-IPC7
PbP-nok
PbP-rand
PbP-noM
PbP-allD
PbP S1
PbP S2
PbP R1 PbP
PbP R2
PbP 10/30/60

PbP versions
Last version PbP configured computing domain-specific knowledge (DSK)
Version PbP entered IPC6 configured using DSK
Version PbP entered IPC7 configured using DSK
Unconfigured portfolio
Randomly configured portfolio
Configuration without macros
Configuration without macros across IPC7 domains
Configuration using sequential scheduling planners uniform time slots
Configuration using sequential scheduling planners non-uniform time slots
Configuration using round-robin scheduling planners default PCPV
Configuration using round-robin scheduling planners different PCPVs
Configuration using 10/30/60 training problems

Table 1: Main variants PbP generating different types planner portfolio configurations
used experimental analysis.

presenting discussing results experimental analysis, describe
experimental settings.
4.1 Experimental Settings
experiment evaluating PbP.s/q respect IPC6-7 planners considers
IPC6-7 benchmark domains (Fern et al., 2011; Jimenez et al., 2011),
experiments focus recent IPC7 domains. Regarding training problems used
experiments, IPC6 domains IPC6; IPC7
domains, set 540 problems various sizes (60 problems IPC7 domain,
unless otherwise specified particular experiment consideration)
generated using problem generator made available organizers IPC7 (for IPC7,
explicit set training problems provided). training problems used
learning macros configuring portfolio. Since learning procedure Wizard
run planner training problems several times, order make training
much time consuming, half training problem set designed formed
problems took 30 seconds solve planner; half formed
problems took 450 seconds (half CPU time limit used testing
phase) solve.
Regarding test problems, used problems used IPC6-7:
IPC6 test problems used evaluating performance PbP.s/q respect
planners entered IPC6; IPC7 test problems, generally larger much
difficult IPC6 problems, used evaluating PbP.s/q respect
IPC7 planners, well experiments analysis.
experiments conducted using last version PbP.s/q,
exactly one entered IPC7 (PbP-IPC7 short) three reasons:6 (a) PbP-IPC7 properly compiled lack C-libraries
competition machine, discovered competition; (b) PbP-IPC7 contains
minor syntax bug format output plans IPC7 domains made
generated plans invalid program validating used competition (Howey,
6. code last version PbP available http://chronus.ing.unibs.it/pbp/.

655

fiGerevini, Saetti, & Vallati

Long, & Fox, 2004); (c) PbP-IPC7.s uses SGPlan5 without domain-modification
script induces SGPlan5 behave domain-independently. Point (a) negatively affected
performance PbP-IPC7.s/q, one incorporated planners (Macro-FF)
could run selected. (b), many valid plans generated PbP-IPC7.s/q
rejected plan validator IPC7. Point (c) changed composition clusters selected PbP-IPC7.q include SGPlan5, make performance
PbP.q PbP-IPC7.q substantially different. difference planner
clusters selected PbP-IPC7.s PbP.s concerns domain Blocksworld,
cluster PbP-IPC7.s consists ParLPG without macros, cluster selected PbP.s
ParLPG using Bunching set macros computed Wizard.
comparison IPC6 planners, results PbP.s/q obtained
running last version machine similar (same CPU frequency amount RAM)
one used obtain official IPC6 data (an Intel Core(tm) Quad-processor Q6600
3 Gbytes RAM). comparison PbP.s/q IPC7 planners, systems
run using machine IPC7 (a Quad-core Intel Xeon 2.93 GHz 4 Gbytes
RAM) IPC-organizers made available us experiment. Unless otherwise
specified, experiments conducted using Quad-core Intel Xeon(tm) 3.16
GHz 4 Gbytes RAM.
experimental analysis required many days CPU time. Unless otherwise indicated,
IPC6-7, CPU-time limit run PbP.s/q 15 minutes, PbP.s/q used
default configuration process (the CPU-time limit simulated execution planner
cluster 15 minutes), planners configured portfolio run roundrobin scheduling described Section 3.2. performance data planner PbP.s/q
incorporating randomized algorithm (i.e., LPG, ParLPG LAMA) obtained
single run considered problem instance.
experimental comparisons test instances generally use three alternative
methods: average performance data, IPC7 score function (Jimenez et al.,
2011), Wilcoxon sign-rank test used planner cluster selection
configuration. Given two compared planners problem set, average CPU time
planner computed problems set solved least one
compared planners, using CPU-time limit (900 seconds) CPU time
planner solve problem; average plan quality computed
problems solved compared planners.
IPC7 score function defined follows. Concerning planning speed, planner
P solves problem using CPU time, gets time score equal 1+log 1 (t/t ) ,
10
best time times required planners comparison solving
. Concerning plan quality, P generates plan l actions solving , gets quality

score equal , l number actions shortest plan computed
compared planners . P solve , gets zero score (both
speed quality). Given domain D, time (quality) score planner P
sum time (quality) scores assigned P considered test problems D.
IPC7 score function speed refinement IPC6 score function.
IPC6 IPC7 time scores defined according much slower planner performs
best performing one, IPC6 score penalizes slowdowns heavily
656

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7 score. experiments, observed using IPC6 function, instead
IPC7 function, gives similar general results slightly favorable PbP.s.
Wilcoxon sign-rank test, null hypothesis performance
compared pair planning systems statistically similar. level confidence used
p = 0.001. analysis involves comparison two planning systems,
then, order maintain confidence level used one hypothesis tested
(i.e., pair planners compared), confidence level modified
Bonferronis correction (Shaffer, 1995). analysis, usage Bonferronis
correction implies that, experimental result obtain Wilcoxon sign-rank test
derives comparison n planning systems, used confidence level 0.001
n1 .
Moreover, plan quality comparison using Wilcoxon sign-rank test, quality
plans computed two compared planners normalized length best plan
test problems solved planners. Since Wilcoxon sign-rank test uses
ranking differences values sample pair, compared absolute
plan length directly, without normalization, differences values domains
could result unintended bias, small relative differences benchmark domain
large solution plans weighted important larger relative differences
domain small plans.
4.2 Overview Configured Portfolios Generated PbP
section concerns experimental goal G1: give information configured portfolios (multi-planners) generated default version PbP.s/q (see Table 1),
relative CPU times used automated portfolio configuration, size
training problem set used configuring PbP. Table 2 shows planners clusters selected PbP every IPC6-7 domain. planner cluster, table
also indicates brackets sets macros selected PbP, available
http://chronus.ing.unibs.it/pbp (the computed planning time slots clusters
omitted brevity clarity). example, Depots, PbP.q selects cluster formed
(i) Macro-FF two learned macros frequently appear Macro-FFs
plans solving training problems, (ii) ParLPG without computed macros,
(iii) SGPlan5 set macros obtained chunking macro generation method
Wizard. configured portfolios Table 2 derive following observation:
Experimental result 4.2.1 planner clusters selected PbP often formed different sets planners macros: overall nine basic planners helpful (each
selected PbP.s/q least once), different sets macros considered helpful
others, including, cases, empty set.
Concerning planning speed, observe domains PbP.s relies single
planner possibly using set macros. particular, 7 15 considered domains
ParLPG outperforms incorporated planners, hence domains
selected cluster contains ParLPG. main reason better performance ParLPG
uses LPG parameter configuration (automatically) optimized
every considered domain, greatly speedup planner (Vallati et al., 2013b).
657

fiGerevini, Saetti, & Vallati

Domains
IPC6 domains
Gold-miner
Matching-BW
N-puzzle
Parking
Sokoban
Thoughtful
IPC7 domains
Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP

PbP.s

PbP.q

YAHSP (Cl)
ParLPG ()
ParLPG ()
Macro-FF (M2)
ParLPG ()
FF (), YAHSP ()

Macro-FF (M1), LAMA (B), LPG (0)
Marvin (0), LAMA (), LPG (B)
Fast Downward (), LAMA (), LPG (0)
FF (0), LAMA ()
Macro-FF (M2), LPG (B)
Macro-FF (M5), Marvin (), LAMA ()

SGPlan5 (B)
ParLPG (B)
Macro-FF (M2), ParLPG (0)
ParLPG ()
Macro-FF (M2)
ParLPG ()
ParLPG ()
ParLPG ()
Macro-FF (M1)

SGPlan5 (Cl), FF (), LAMA ()
ParLPG (), LPG (B)
Macro-FF (M2), ParLPG (0), SGPlan5 (Ch)
Marvin (), ParLPG ()
FF (0), LAMA ()
LAMA (), ParLPG ()
ParLPG (), Marvin (0)
LPG ()
LAMA (), SGPlan5 (Ch)

Table 2: Planners sets macros (in round brackets) cluster selected PbP
IPC6-7 domains. 0 indicate macros generated
selected, respectively; Ch, B Cl abbreviate three sets macros
Chunking, Bunching Clumping generated Wizard, respectively; M1M5
five sets macros generated Macro-FF. order planners listed
clusters corresponds order run.

observed that, previous version PbP entered IPC6 without ParLPG,
selected clusters even varied.
interesting observe PbP selects Macro-FF configured portfolio
planner always uses non-empty set macros. fact selected cluster Macro-FF always uses one among learned sets macros indicates macro
construction exploitation methods incorporated Macro-FF effective
planning system.
Table 3 gives CPU times used PbP.s different phases portfolio
configuration applied IPC7 domains, machine Quad-core Intel
Xeon(tm) 3.16 GHz 4 Gbytes RAM used.7 configuration times PbP.q
similar PbP.s macro extraction cluster simulation phases,
higher performance measurement, incorporated incremental
planners use whole CPU-time limit order find good quality plans. Although
configuring PbP specific domain requires considerable amount CPU time,
considered configuration needs done once, since generated
configured portfolio (selected planner cluster) used problems domain.
Finally, order understand small sets training problems sufficient
derive informative DSK test problems larger training ones,
7. every IPC7 domain, parameter configuration ParLPG required 1400 hours.

658

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7
Domains
Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP

Macro Extraction
Macro-FF Wizard
37.5
28.5
16.4
44.2
7.1
82.9
45.3
12.9
23.8
86.5
18.2
0.0
14.1
41.3
5.25
0.8
19.3
3.9

Performance
Measure
121.6
92.7
92.4
96.8
163.0
57.3
60.0
110.7
34.5

Simulation &
Selection
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02
0.02

Total
187.6
153.4
182.4
155.0
273.3
75.6
115.4
116.8
57.8

Table 3: CPU hours used configuration PbP.s IPC7 domains: extraction
macros Macro-FF Wizard (2nd 3rd columns), performance measurement phase (4th column), cluster run simulation best cluster selection (5th
column), total configuration time (6th column).

compared performance PbP configured using default number 60 training problems using half one-sixth training problems. (The range problem
size three sets training problems.) results analysis
Table 4. course, lower number training problems is, cheaper
training PbP is. hand, DSK computed using training problems
sometime much less effective informative DSK obtaining using larger sets.
Depots, PbP.s DSK derived 60 training problems performs much
better DSKs derived 30 10 training problems;
domains, performance PbP.s three compared DSKs similar same.
interesting observe Depots domain cluster PbP.s two
planners. domain, cluster PbP.s derived 60 training problems consists
Macro-FF ParLPG: 16 training problems ParLPG hands solution PbP.s,
44 training problems solution PbP.s obtained Macro-FF.
DSK derived 30 20 training problems, either Macro-FF ParLPG part
configured cluster PbP.s makes PbP.s performing worse.
Depots, Satellite TPP, PbP.q DSK derived 60 training problems
performs much better DSK derived 30 10 training problems.
domains, performance PbP.q similar same.
4.3 Performance PbP IPC6-7 Planners
section concerns experimental goal G2: experimentally evaluate performance
PbP context IPC6-7 aim showing competitive
recent planning systems using domain specific learned knowledge. Since time
writing several IPC6-7 planners relative domain specific knowledge available,
experiment used official competition data (CPU times, plan qualities
number solved problems) results obtained running last version PbP.
659

fiGerevini, Saetti, & Vallati

IPC7
Domains

Depots
Parking
domains
IPC7
Domains

Blocksworld
Depots
Parking
Satellite
TPP
domains

Time score
60
30
26.0
2.6
7.4
4.9
33.4
7.0

10
2.6
5.8
8.4

Mean CPU time
60
30
10
31.9
312.5 312.5
172.8 127.7 281.3
110.2 209.8 292.6

# solved problems
60
30
10
26
4
4
8
5
7
34
9
11

Quality score
60
30
10
29.9
29.6 29.6
24.7
8.6
9.2
4.8
2.8
2.0
29.6
0.0
27.8
14.8
7.7
0.0
133.8 78.7 98.6

Mean plan length
60
30
10
269.9 272.8 272.8
151.7 156.2 151.2
76.0
61.0
61.0






325.3 326.6 326.0

# solved problems
60
30
10
30
30
30
26
10
10
5
3
2
30
0
28
15
8
0
136
81
100

Table 4: Time/quality score, average CPU time/plan length number solved problems
PbP.s/q configured DSK computed using set either 60 (default
version PbP), 30 10 training problems. domains considered
IPC7 domains training phase PbP.s/q derives different DSKs
training problem sets different sizes.

learning track IPC6 IPC7, competing teams aware
domains used evaluation submitting systems. code submission,
contest two phases. first phase, domains released learning
parts planners run automatically derive, domain, additional
knowledge using set training problems domain. second phase, submitting learned knowledge IPC organizers, planners run relative
learned knowledge, resulting performance data compared using IPC score
function. interested reader find details IPC6-7 organization
well collection short papers describing IPC6-7 planners entered learning
track work Fern et al. (2011), Jimenez et al. (2011).
PbP, knowledge derived first phase competition portfolio configuration knowledge described previous section paper. knowledge learned IPC6 planner ObtuseWedge consists special patterns, extend
notion n-gram include argument relations, used aim
speeding enforced hill-climbing search (Yoon, Fern, & Givan, 2008). IPC6
planning systems Wizard+FF Wizard+SGPlan learn set macro actions planners FF SGPlan5, respectively. IPC7 planners, Bootstrap-Planner learns
domain-specific heuristic combining set existing heuristics weights obtained
evaluating performance heuristics training problems (Arfaee, Zilles, &
Holte, 2010). Finally, knowledge learned OALDAEYASHP (Brendel & Schoenauer,
2011), ParLPG, Fast Downward-autotune-speed Fast Downward-autotune-quality (Fawcett
et al., 2011) consists domain-specific parameter configurations.
Table 5 gives overall experimental evaluation best-performing planners
IPC6 (using IPC6 domains) best-performing planners IPC7 (using
660

fiPlanning Automatic Portfolio Configuration: PbP Approach

Best IPC6 planners
PbP.s
PbP.q
ObtuseWedge
PbP-IPC6.s
PbP-IPC6.q
RFA1
Wizard+FF
Wizard+SGPlan
Best IPC7 planners
PbP.s
PbP.q
Bootstrap-Planner
Fast Downward-autotune-speed
Fast Downward-autotune-quality
OALDAEYASHP
ParLPG
PbP-IPC7.s
PbP-IPC7.q
LAMA-2011

Problem Solved
(%)
97.0
95.0
65.0
95.6
92.8
47.2
56.7
51.1

Time score
(max = 180)
105.5
6.89
73.5
88.2
6.43
14.7
47.3
56.1

Quality score
(max = 180)
111.2
169.1
75.6
111.4
132.3
52.3
72.4
65.2

Problem Solved
(%)
87.4
83.7
4.07
77.0
32.2
7.41
57.04
71.48
70.37
37.67

Time score
(max = 270)
232.7
76.2
3.28
110.0
35.3
5.70
104.0
178.1
71.1
37.9 (1st sol.)

Quality score
(max = 270)
202.5
221.7
10.93
170.8
64.3
3.76
146.0
172.5
192.7
82.4 (last sol.)

Table 5: Percentage solved problems within 15 CPU minutes, time quality scores
PbP.s/q (best performing) planners took part learning track
IPC6-7 domains problems IPC6-7. Larger scores indicate better
performances. PbP-IPC6 PbP-IPC7 indicate versions PbP took part
IPC6 IPC7, respectively; LAMA-2011 winner deterministic track
IPC7.

IPC7 domains), terms percentage solved problems, planning speed plan quality.
compared planners run relative learned knowledge. data
Table 5, following general experimental result derived.
Experimental result 4.3.1 IPC6-7 domains problems, PbP.s generally
faster compared IPC6-7 planners, PbP.q performs generally better terms plan
quality, PbP.s/q solves many problems.8
Remarkably, PbP.s/q solves high percentage IPC6-7 benchmark problems
within 15 CPU minutes, PbP.q almost always computes plan better
plan computed competitor. contrast, time score PbP.q low, since
8. version PbP used comparison suffer technical problems indicated Section
4.1 affected performance PbP IPC7. IPC7 planners may suffered similar
problems, implementation might also improved versions considered.
However, note even version PbP.s/q entered IPC7 performs generally better
competing planners.

661

fiGerevini, Saetti, & Vallati

PbP.q usually runs one planner stops selected planners
terminate CPU-time limit exceeded.
analysis competition results (planner CPU times plan qualities) using
Wilcoxon sign-rank test instead IPC score functions performance comparison
confirms PbP.q generates significantly better quality plans (z = 3.920, p < 0.001
7 ).
p-value obtained analysis 0.004 (with z-value equal 2.846). Since p-value
adjusted critical value 0.001
7 , null hypothesis (the performance PbP
similar performance IPC6-7 planners terms speed) accepted,
thus research hypothesis (the performance PbP statistically different) rejected.
However, worth pointing critical value 0.001 quite hard reach,
especially given also apply experiment-wise error adjustment. set
less stringent critical value, say 0.05, adjusted critical value would 0.05
7 = 0.0071,
p-value 0.004 would significant.
Table 6 gives details performance comparison IPC7 domain.
terms speed, PbP.s best performance eight nine domains considered analysis; domain perform best Parking,
Fast Downward-Autotune-speed performs better. Similarly, terms quality, PbP.q
best performance seven nine domains, performs well ParLPG
PbP.q one domain (Spanner), performs worse Fast Downward-Autotune-speed
two domains (Parking TPP). worth noting principle portfolio approach
incorporate planners promising attempting problems domain.
current version PbP integrates planners established state-of-the-art
PbP developed, time Fast Downward-Autotune-speed available. results Table 6 indicate portfolio-based approach would reach better
performance, also incorporated planner. instance, likely PbP would
select planner domain Parking, greatly improving performance domain.
Finally, comment relative performance PbP winner deterministic satisficing track IPC7, 2011 version LAMA. course, cannot expect
domain-independent planner, LAMA, performs better planner exploiting
(learned) specific domain knowledge. hand, definitely desired property
way around holds: planning system uses form (automatically
acquired) domain specific knowledge effective performs better state-ofthe-art domain-independent planner use additional knowledge.
last lines Tables 5 6 indicate global domain-by-domain performance
LAMA-2011 respect planners learning track IPC7, considering
score functions competition track.9 comparison, CPU time limit used
run LAMA 15 minutes, time limit one used run PbP.s/q
planners took part learning track IPC7. worth noting
IPC7 domains learning track propositional, IPC7 problems require
optimization explicit specified plan metric; problems, LAMA
PbP minimize number actions. seen PbP.s/q performs substantially
9. Although experimental comparison considers planning time scores plan quality scores,
noted deterministic track IPC7 focused plan quality, hence LAMA-2011
presumably developed focusing quality rather speed. sense, results plan
quality comparison LAMA-2011 meaningful planning speed.

662

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7 Planners
Bootstrap-Planner
FDA-speed
FDA-quality
OALDAEYASHP
ParLPG
PbP-IPC7.s
PbP-IPC7.q
PbP.s
PbP.q
LAMA-11

Solved problems

Barman

BW

Depots

Gripper

Parking

Rovers

Sat

Spanner

TPP

0
30
0
0
0
29
30
30
30
2

11
29
27
20
30
29
30
30
30
29

0
20
0
0
17
26
10
26
26
0

0
30
1
0
30
30
30
30
30
0

0
20
9
0
0
0
5
8
5
5

0
30
30
0
27
27
30
27
30
30

0
19
7
0
30
30
30
30
30
13

0
0
0
0
30
30
30
30
30
0

0
30
14
0
15
0
0
25
15
20

Barman

BW

Depots

Gripper

Parking

Rovers

Sat

Spanner

TPP

0.0
14.3
0.0
0.0
0.0
28.8
22.9
28.8
22.9
0.52

3.28
12.1
9.31
5.70
16.3
17.3
8.27
30.0
8.27
10.6

0.0
10.9
0.0
0.0
9.18
25.1
3.05
25.1
7.95
0.0

0.0
9.84
0.55
0.0
15.3
30.0
8.47
30.0
8.47
0.0

0.0
18.7
5.67
0.0
0.0
0.0
2.62
7.14
2.62
2.8

0.0
13.5
11.4
0.0
17.5
27.0
8.21
27.0
8.21
10.0

0.0
6.39
1.92
0.0
17.7
30.0
10.2
30.0
10.2
3.5

0.0
0.81
0.51
0.0
16.2
30.0
7.34
30.0
7.34
0.0

0.0
23.5
5.96
0.0
11.9
0.0
0.0
24.8
7.37
10.5

Barman

BW

Depots

Gripper

Parking

Rovers

Sat

Spanner

TPP

0.0
26.9
0.0
0.0
0.0
28.4
30.0
28.4
30.0
1.86

3.76
13.2
13.3
10.9
21.7
24.1
29.8
21.1
29.8
21.8

0.0
20.0
0.0
0.0
8.31
16.8
9.01
16.8
23.0
0.0

0.0
28.8
0.0
0.0
28.6
27.5
29.9
27.5
29.9
0.0

0.0
17.2
9.00
0.0
0.0
0.0
4.09
9.08
4.09
3.8

0.0
24.2
22.8
0.0
21.4
19.3
30.0
19.3
30.0
24.7

0.0
15.7
6.67
0.0
28.5
26.5
30.0
26.5
30.0
11.0

0.0
0.0
0.0
0.0
30.0
30.0
30.0
30.0
30.0
0.0

0.0
24.8
12.6
0.0
7.54
0.0
0.0
23.9
14.9
19.3

IPC7 Planners
Bootstrap-Planner
FDA-speed
FDA-quality
OALDAEYASHP
ParLPG
PbP-IPC7.s
PbP-IPC7.q
PbP.s
PbP.q
LAMA-11 (1st sol.)

Time score

IPC7 Planners
Bootstrap-Planner
FDA-speed
FDA-quality
OALDAEYASHP
ParLPG
PbP-IPC7.s
PbP-IPC7.q
PbP.s
PbP.q
LAMA-11 (last sol.)

Quality score

Table 6: Number solved problems, time/quality scores (best performing)
IPC7 planners IPC7 domain. FDA, LAMA-11, BW Sat abbreviate
Fast Downward-Autotune, LAMA-2011, Blocksworld Satellite, respectively.

better LAMA-2011. results Table 5 show PbP.s/q solves many IPC7
problems, achieves considerably better overall time quality scores respect
LAMA-2011s first best quality solutions, respectively. results Table 6 show
that: PbP.s much higher speed performance every domain, much higher
quality performance domains; PbP.q much higher quality performance
seven domains, performs similarly two domains, much
higher speed performance domains.
Moreover, since deterministic track IPC7 CPU-time limit 30 minutes,
compared LAMA-2011 PbP.s/q problems learning track using
limit first planner, keeping 15 CPU minutes second. extra CPU
time LAMA-2011 considerably change results comparison: overall,
663

fiGerevini, Saetti, & Vallati

total time scores LAMA-2011 PbP.s/q 61.9 231.9/116.5, respectively;
total quality scores LAMA-2011 PbP.s/q 80.7 227.6/206.2, respectively;
LAMA-2011 solves 101 problems PbP.s/q solve 238/230 problems.
previous experimental analysis PbP.s/q LAMA-2011 summarized
following claim, suggesting portfolio-based planner (automatically) configured
given domain, perform much better state-of-the-art fully domain-independent
planner.
Experimental result 4.3.2 benchmark domains learning track IPC7,
configured versions PbP.s/q perform better IPC7 winner deterministic
track.
Since PbP without configuration knowledge (PbP-nok) fully domain-independent
planner, also interesting see well PbP-nok performs w.r.t. LAMA-2011.
experimental comparison, also used benchmark domains problems deterministic track IPC7, CPU-time limit IPC7 run (30 minutes).
Moreover, since deterministic track IPC7 focused plan quality, measured total
action cost, considered quality version PbP-nok. LAMA-2011 optimizes
total action cost, PbP-nok.q incorporated planners consider number actions
plan quality. Although analysis relies total action cost, hence somewhat
favor LAMA-2011, observed PbP-nok.q competitive LAMA-2011.
problems IPC7 deterministic track, total quality score number solved
problems slightly lower PbP-nok.q LAMA-2011 (214.8 232.2,
239 250, respectively). lower quality score PbP.q mainly two
fourteen IPC7 domains (Elevator Parcprinter), PbP-nok.q obtains much
lower scores (1.0 19.0 3.0 19.6, respectively). test problems
learning track IPC7, PbP-nok.q performs even better LAMA-2011 (IPC quality
score: 168.8 versus 97.5; solved problems: 181 versus 105).

Experimental result 4.3.3 benchmark domains deterministic learning
tracks IPC7, PbP.q without configuration knowledge (PbP-nok.q) competitive
winner IPC7 deterministic track.

Given PbP.q without configuration performs already well, performance improvement obtained exploiting computed configuration knowledge even notable.
Section 4.5 shows portfolio configuration PbP.s/q useful improve
performance.
4.4 Performance PbP Planner Portfolios
section concerns experimental goal G3: compare PbP two planner portfolio
approaches: FDSS (Helmert et al., 2011) BUS (Roberts & Howe, 2007).
664

fiPlanning Automatic Portfolio Configuration: PbP Approach

4.4.1 PbP versus FDSS
Table 7 shows performance PbP.s/q w.r.t. FDSS without using macros.10
results comparison summarized follows.
Experimental result 4.4.1 benchmark domains learning track IPC7,
terms number solved problems PbP.s/q performs always better FDSS, except
domains Rovers TPP, FDSS solves problems PbP.s PbP.q,
respectively. terms time score, PbP.s always performs better FDSS. terms
quality score, PbP.q performs always better except TPP.
think least four reasons experiments PbP performed generally
better FDSS. main reason that, PbP separately configured every
considered domain, FDSS always uses configuration determined problem
instances IPC16, designed using problem distributions quite different
learning track IPC7 (Seipp et al., 2012). reasons (a) diversity
planning methods implemented planners incorporated PbP FDSS, (b)
usage macros PbP.s/q, (c) different portfolio configuration techniques
two compared systems. Concerning (a), consider instance domain Spanner,
PbP.s/q outperforms FDSS PbPs configured portfolios use ParLPG/LPG (see Table
2). every planner incorporated FDSS uses heuristic forward search techniques,
ParLPG/LPG uses heuristic techniques searching space partial plans, seems
effective domain. (b), tried learn macros FDSS using Wizard,
unfortunately useful macro learned planning system. Therefore, tested
performance FDSS using macros learned Wizard selected PbP.s/q
planners configured portfolios (see Table 2). results Table 7 indicate
that, using macros sometimes greatly improves performance PbP,
really effective FDSS.
Finally, order better understand importance (c), also developed compared PbP new variant FDSS, called FDSSd , restricting differences
FDSS PbP configuration techniques. Specifically, FDSSd following similarities differences w.r.t. original FDSS. FDSSd uses configuration
techniques FDSS, configures planner portfolio separately input domain
(instead set domains altogether), uses macros, integrates planners
PbP (instead set forward-state planners). Then, important differences
PbP FDSSd method planner cluster selection scheduling
strategy used running planners forming clusters that, described Section 2,
substantially different.
Like PbP, computed two sets domain-optimized portfolio configurations
FDSSd : FDSS.sd focusing speed, FDSS.qd focusing plan quality. IPC7
domains except Depots, planner clusters selected FDSS.s
PbP.s. Depots, cluster FDSS.s consists Macro-FF using macro set M1
Macro-FF using macro set M2, cluster PbP.s consists ParLPG using macro
Macro-FF using macro set M2. domain FDSS.s PbP.s
10. version FDSS run experiment uses 15 38 variants Fast Downward analyzed
Helmert et al. (2011).

665

fiGerevini, Saetti, & Vallati

Planners
PbP.s
PbP.q
FDSS
FDSS+M
PbP-nok.s
PbP-nok.q

# solved problems

Barman

BW

Depots

Gripper

Parking

Rovers

Sat

Spanner

TPP

30
30
0
0
23
23

30
30
21
10
17
18

26
26
0
0
8
8

30
30
0
0
24
25

8
5
0
0
0
0

27
30
28
28
20
17

30
30
14
14
11
11

30
30
0
0
13
13

25
15
17
17
7
10

Barman

BW

Depots

Gripper

Parking

Rovers

Sat

Spanner

TPP

30.0
23.0
0.0
0.0
6.7
6.2

30.0
8.27
9.7
3.6
7.1
5.4

26.0
8.03
0.0
0.0
5.1
3.0

30.0
8.47
0.0
0.0
10.3
7.9

7.8
2.54
0.0
0.0
0.0
0.0

27.0
8.21
17.1
17.1
9.8
5.8

30.0
10.2
8.8
8.8
4.7
4.1

30.0
7.3
0.0
0.0
5.3
5.3

23.7
7.1
8.5
9.0
3.2
3.8

Barman

BW

Depots

Gripper

Parking

Rovers

Sat

Spanner

TPP

28.4
30.0
0.0
0.0
22.5
22.5

21.3
29.9
13.4
12.9
10.3
12.3

17.2
26.0
0.0
0.0
7.6
7.4

27.6
30.0
0.0
0.0
18.1
19.9

5.4
5.0
0.0
0.0
0.0
0.0

18.2
27.9
24.9
24.9
18.7
15.8

26.3
29.5
12.2
12.2
8.9
9.8

30.0
30.0
0.0
0.0
13.0
13.0

20.3
14.2
16.1
15.4
6.3
9.3

Planners
PbP.s
PbP.q
FDSS
FDSS+M
PbP-nok.s
PbP-nok.q

Time score

Planners
PbP.s
PbP.q
FDSS
FDSS+M
PbP-nok.s
PbP-nok.q

Total
236
226
80
69
123
125

Total
234.5
83.2
44.1
38.5
52.2
41.5

Quality score
Total
194.7
222.5
66.6
65.4
105.4
110.0

Table 7: Number solved problems, time/quality scores PbP, PbP-nok, FDSS
with/without using macros IPC7 domain. FDSS+M, BW Sat abbreviate FDSS using macros, Blocksworld Satellite, respectively.

cluster, cluster formed single planner. Hence, running sequential
scheduling round-robin scheduling thing, compared planner
portfolios performance.
planner clusters selected FDSS.q Table 8. domains Gripper, Satellite
TPP, PbP.q but, cases formed
one planner. domains Satellite Gripper observed FDSS.q performs
differently PbP.q different scheduling strategy. Table 9 shows results experimental comparison PbP FDSSd (results omitted
compared clusters formed single planner). Overall,
derive following observation.
Experimental result 4.4.2 almost benchmark problems domains
learning track IPC7, PbP.s fast FDSS.sd , Depots slightly faster;
PbP.q computes plans always good better computed FDSS.qd ,
solves problems.
performance gap PbP FDSSd lower gap PbP
FDSS, Depots PbP.s performs slightly better terms speed number
solved problems, IPC7 domains PbP.q performs considerably better
terms plan quality. rationale behavior that, show Section 4.6,
666

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7 Domain
Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP

FDSS.qd
(Cl), FF, L,
(B), FF (Ch), MFF (M1), FF (B),P, L, LPG (Ch), LPG (B)
LPG, M, FF (Ch), MFF (M1), FF (Cl), (Ch), (Cl), P, MFF (M2), L
M, P
FF (Ch), FF, L
FF, MFF (M1), L, LPG
P,
P
L (), (Ch)

Table 8: Planners sets macros (in round brackets) cluster selected FDSSd
IPC7 domains. S, L, M, MFF P abbreviate SGPlan5, LAMA, Marvin,
Macro-FF ParLPG, respectively; Ch, B Cl three sets
macros Chunking, Bunching Clumping generated Wizard; M1M5
five sets macros generated Macro-FF.

running planner clusters round-robin scheduling robust running
sequentially using possibly inadequate values planning time slots. Another explanation,
especially high performance difference terms plan quality, different way
PbP FDSSd explore portfolio configuration spaces. FDSSd searches
planner cluster use hill-climbing algorithm space possible clusters,
PbP explores whole space possible clusters (with bound number planners
clusters). selected clusters PbP.s FDSS.sd almost always
IPC7 domains considered training problems configuring planner portfolio
focusing speed quite easy, cases single planner (possibly using macros)
outperforms every planner. contrary, domains training
problems, configuring planner portfolio focusing plan quality difficult
FDSSd , search space contains local minima prevent FDSSd finding
best-performing configuration (planner cluster), complete exploration search
space allows PbP identify it.
worth noting space planner clusters PbP much smaller
spaces FDSS FDSSd , since space PbP cannot two different clusters
formed planners relative macros, different relative sequences
planning time slots (the sequence planning time slots planner relative
set macros derived according default PCPV). case, space
clusters PbP would orders magnitude greater, time required PbP
simulating cluster execution would negligible w.r.t. time
configuration phases (see Table 3).
performance comparison PbP.s FDSSd using Wilcoxon sign-rank test
gives statistical result compatible performance data Table 9
Experimental result 4.4.2: IPC7 domains, statistical difference
planning CPU times PbP.s FDSS.sd (z = 1.257, p = 0.209), while,
667

fiGerevini, Saetti, & Vallati

IPC7
Domains
Depots

Max
score
30

Time score
PbP.s
FDSS.sd
22.2
20.1

Mean CPU time
PbP.s
FDSS.sd
53.1
126.3

# solved problems
PbP.s
FDSS.sd
26
23

IPC7
Domains
Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains

Max
score
30
30
30
30
30
30
30
30
30
270

Quality score
PbP.q
FDSS.qd
30.0
30.0
30.0
14.4
24.2
19.2
30.0
23.7
4.8
2.8
29.8
17.3
30.0
25.0
30.0
30.0
15.0
15.0
223.8
177.4

Mean plan length
PbP.q
FDSS.qd
448.3
448.3
233.5
340.2
159.9
169.1
574.0
581.7
70.6
71.7
580.3
600.2
775.2
775.2
326.0
326.0
370.1
370.1
433.1
448.7

# solved problems
PbP.q
FDSS.qd
30
30
30
20
26
21
30
24
5
3
30
18
30
25
30
30
15
15
226
186

Table 9: Maximum score, time/quality score, average CPU time/plan length number
solved problems PbP FDSSd benchmark problems Depots
planning speed, IPC7 domains plan quality.

terms plan quality, PbP.q performs significantly better FDSS.qd (z = 5.767,
p < 0.001).
4.4.2 PbP versus BUS
Although BUS originally designed generate domain-independent configured planner portfolio, like FDSS, principle also used build domain-specific configured
portfolios. Domain specificity obtained simply training problems domain. fully-automated executable BUS available,
experimental results presented Roberts Howe (2007) derived simulation
(Roberts & Howe, 2012). Thereby, order compare PbP BUS, implemented
BUS approach using planners macros integrated PbP, generated
domain-specific configured portfolios using implementation BUS.
BUS selects planners configured portfolio greedy set covering
approximation algorithm sets problems solved incorporated planners,
planners forming clusters ordered according ranking algorithm
Simon Kadane (1975). greedy set covering approximation algorithm iteratively
selects planner reduces set covering problem smaller one, original
input set fully covered (Cormen, Stein, Rivest, & Leiserson, 2001). Let planning
domain, P set selected planners, set test problems cover. Initially, P
empty contains 60 training problems. iteration, algorithm chooses
planner largest set solved problems S, removes problems
S, adds selected planner P . number planners largest set
solved problems greater one, algorithm selects first evaluated planner
668

fiPlanning Automatic Portfolio Configuration: PbP Approach

(the planner evaluation order random). process terminates empty.
resulting set P contains planners configured portfolio.
experimentally observed almost every considered domain, since
one incorporated planner solves training problems domain, set planners
forming cluster selected BUS domain consists one planner (except
domain Parking two selected planners, LAMA FF using macro set Clumping). Moreover, choice planner among solve training problems
drastically affected random order greedy set covering approximation
algorithm evaluates coverage planners. Hence, derive indication
performance reached implementation BUS, ran portfolio configuration BUS nine times, tested obtained nine configured portfolios, analyzed
three sets experimental results CPU time three sets experimental results
plan quality. three sets derived using: median performing configured
portfolio nine generated considered domain, best/worst performing configured portfolio possible portfolios generated greedy
set covering approximation algorithm BUS. results experimental comparison
given Table 10 summarized following observation.
Experimental result 4.4.3 benchmark domains learning track IPC7,
terms time score average CPU time, PbP.s/q performs much better worst
median configured portfolios derived BUS; PbP.s performs slightly better
best configured portfolio oracle would select among derived
BUS, PbP.q performs slightly worse. terms problem coverage (the criterion used
BUS select planners cluster), PbP.s solves number problems
best configured portfolio derived BUS.
results Table 10 show performance obtained configured portfolios
generated BUS varies greatly, indicating planner-selection method BUS
accurate derive efficient domain-specific configured portfolios. think
main reason planner selection BUS considers problem
coverage ignores CPU time plan quality incorporated planners. However,
important note planner-selection method BUS originally proposed
different kinds data sets (problem instances set domains considered altogether
different used experiment) different purpose (generating
domain-independent planner portfolio), BUS prominent approach showed
good performance (Roberts & Howe, 2009).
4.5 Effectiveness Computed Configuration Knowledge
section concerns experimental goal G4. order understand effectiveness
automated portfolio configuration PbP, compare performance PbP
computed configuration knowledge (PbP.s/q), configuration (PbP-nok.s/q),
random configuration (PbP-rand.s/q). PbP-nok.s/q, planners initial
portfolio selected, macros used, planning time slots
planners, execution order random. PbP-rand.s/q, PbP-nok.s/q
except subset three randomly chosen planners (possibly empty)
669

fiGerevini, Saetti, & Vallati

IPC7
Domains

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP

PbP.s

domains

30.0
29.8
20.6
29.5
7.9
26.9
30.0
30.0
25.0
229.7

IPC7
Domains

PbP.q

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains

30.0
29.9
24.4
29.0
4.3
25.1
30.0
30.0
14.5
217.2

Time score
BUS
W.s
M.s
0.0
27.3
7.4
16.1
7.6
14.3
17.3
17.5
7.2
7.2
1.7
8.7
0.0
0.0
15.0
22.4
0.0
8.2
56.2
121.7
Quality score
BUS
W.q
M.q
0.0
29.5
9.4
29.7
6.0
13.5
15.2
15.2
7.8
7.8
4.4
16.9
0.0
0.0
30.0
30.0
0.0
14.7
72.8
157.9

Mean CPU time
BUS
W.s
M.s
B.s
2.0
900.0
2.7
2.0
9.9
603.2
135.1
19.7
191.4
590.9
205.0 132.5
18.2
183.8
87.3
18.3
364.1
428.1
428.1
428.1
50.5
840.4
411.5
50.5
28.3
900.0
900.0
70.2
16.9
208.1
151.1
16.9
121.2
900.0
508.6
175.3
63.2
627.0
299.6
70.3

# solved problems
PbP.s
BUS
W.s M.s B.s
30
0
30
30
30
10
30
30
26
11
22
26
30
25
30
30
8
8
8
8
27
5
18
27
30
0
0
30
30
30
30
30
25
0
15
25
236
89
183 236

Mean plan length
BUS
W.q
M.q


210.6
198.4
175.8
231.8
876.6
876.6
77.4
77.4
482.8
522.4


326.0
326.0


459.8
464.9

# solved problems
PbP.q
BUS
W.q M.q B.q
30
0
30
30
30
10
30
30
26
11
22
26
30
30
30
30
5
8
8
8
29
5
18
29
30
0
0
30
30
30
30
30
15
0
15
25
226
94
183 238

PbP.s

B.s
30.0
23.5
21.1
28.9
7.2
26.9
23.0
30.0
21.3
211.9

PbP.q
B.q
30.0
29.9
22.8
29.9
7.8
29.0
28.5
30.0
21.5
229.4


198.4
143.7
577.0
87.8
498.8

326.0

367.6

B.q

198.4
190.5
554.7
77.4
420.0

326.0

358.7

Table 10: Time/quality score, mean CPU time/plan length number solved problems
PbP.s/q, worst, median best portfolios derived
using BUS IPC7 domains. W.s, M.s B.s denote worst, median
best portfolios among BUS derive lowest, median,
highest time score considered IPC7 test problems, respectively; similarly
W.q, M.q B.q denote worst, median best portfolios lowest,
median, highest quality score, respectively.

randomly chosen set learned macros used, instead planners, different
random configuration PbP.s/q generated every IPC7 problem.
Figure 3 gives overall picture results problems IPC7 domains
considering different amounts CPU times portfolio configuration; specifically,
time x-axis CPU-time limit given run planner (with set
macros) performance measurement simulation phase, (simulated) run
candidate clusters planners planning cluster selection ordering phase,
run configured portfolio test phase. marked points
curves PbP.s/q correspond performance scores different configured portfolios
obtained different considered CPU-time limits. results indicate that, every
considered CPU-time limit configuration phase, PbP.s/q clearly performs better
PbP-nok PbP-rand. Moreover, refined analysis considering domain separately
shows PbP.s/q best performance also every single considered domain,
terms problem coverage every considered CPU-time limit gaps
670

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7 domains

Time score
240

PbP.s
PbP-nok.s
PbP-rand.s

200

IPC7 domains

Quality score
240

PbP.q
PbP-nok.q
PbP-rand.q

200

160

160

120

120

80

80

40

40

0

0
1

10

100

1000

1

10

100

1000

Figure 3: Time score (left plot) quality score (right plot) PbP, PbP-nok PbP-rand
respect increasing CPU-time limit (ranging 1 1000 seconds)
IPC7 domains.

PbP.s/q two compared version PbP similar gaps plots
Figure 3.
Experimental result 4.5.1 computed configuration knowledge considerably improve performance PbP.s/q w.r.t. unconfigured randomly configured versions
PbP (PbP-nok PbP-rand, respectively).
terms planning speed, performance comparison three considered versions PbP.s/q, using Wilcoxon sign-rank test gives similar general result: PbP.s
statistically faster versions (z = 12.578, p < 0.001
2 ). terms plan
quality, PbP.q performs statistically better unconfigured version (z = 13.205,
p < 0.001
2 ). comparison PbP.q PbP-rand.q, analyzed 47
230 problems solved PbP.q, PbP-rand.q solves problems plan
quality comparisons consider problems solved compared planners. results Wilcoxon test indicates PbP.q performs similarly PbP-rand.q
(z = 1.662, p = 0.096). However, noted low number considered
problems makes statistical comparison Wilcoxon sign-rank test
accurate informative deriving general conclusions relative performance
case.
also tested version PbP-nok incorporated planners run
using predetermined time slot sequence Spre planner runs ordered using
method used PbP, considers relative performance planners
set training problems instead random order. Overall performance
PbP-nok remains much worse performance (the planner cluster selected by)
configured version PbP.
Table 11 analyzes impact performance using DSK (i.e., PbP, computed
configuration knowledge) best-performing planners entered learning track
IPC6-7. results comparison confirm strong positive impact PbPs DSK.
671

fiGerevini, Saetti, & Vallati

Planner
Best IPC6 planners
ObtuseWedge
PbP-IPC6.s
PbP-IPC6.q
Wizard+FF
Wizard+SGPlan
PbP.s
PbP.q
Best IPC7 planners
BootstrapPlanner
Fast Downward-autotune-speed
Fast Downward-autotune-quality
OALDAEYASHP
ParLPG-speed
PbP-IPC7.s
PbP-IPC7.q
PbP.s
PbP.q

Solved (%)

Time

Quality

+17.3
+3.6
+0.9
6.6
1.7
+5.0
+3.3

+34.1
+ 65.2
+5.8
+21.0
+17.6
+82.5
+6.3

+23.7
3.0
+0.7
15.2
3.1
3.2
+37.5

+4.1
+43.3
+14.1
18.9
+9.3
+5.6
+7.4
+21.48
+20.74

+3.3
+65.3
+16.0
17.3
+42.1
+116.5
+24.3
+171.1
+29.4

+10.9
+99.1
+26.4
40.4
+15.6
+16.8
+40.9
+46.8
+69.8

Table 11: Performance gaps best-performing IPC6-7 planners with/without DSK
terms percentage solved problems, time quality scores IPC6-7
benchmark domains problems. Planner RFA1 omitted works
DSK.

Experimental result 4.5.2 IPC6 domains problems, DSK computed
PbP.s PbP.q strongest impact among DSK IPC6 planners terms
improved speed (time) plan quality (quality), respectively. DSK computed
ObtuseWedge strongest impact terms percentage additional solved IPC6
problems.
reason impact DSK computed PbP quite low terms additional
solved IPC6 problems PbP.s/q solves almost problems even without DSK.
Experimental result 4.5.3 IPC7 domains problems, DSK computed
PbP.s strongest impact terms improved speed (time) among DSK
IPC7 planners. use computed DSK Fast Downward-Autotune-speed
strongest impact terms percentage additional solved problems improved plan
quality.
Although terms percentage additional solved problems improved plan quality use DSK PbP.s/q highest impact, leads high improvements also PbP.s/q, allowing achieve performance generally better
Fast Downward-Autotune-speed (see Quality Score column Table 5).
Finally, conducted experiment understand configuring PbP specific domain generates DSK leads better performance w.r.t. configuring planner portfolio
672

fiPlanning Automatic Portfolio Configuration: PbP Approach

set domains altogether. Table 12 compares performance PbP.s/q
DSK, DSK obtained without using macros (PbP-noM.s/q), configuration knowledge computed across IPC7 domains (PbP-allD.s/q). planner cluster PbP-allD.s
formed LPG SGPlan5, planner cluster PbP-allD.q formed LAMA,
Marvin SGPlan5. results Table 12 indicate that, even without considering
usage macros, portfolio configuration considered domains together greatly
decreases performance PbP.
Experimental result 4.5.4 IPC7 domains, terms time score, average CPU
time number solved problems, PbP.s performs much better PbP-noM.s
PbP-allD.s. terms quality score number solved problems, PbP.q performs much
better PbP-noM.q PbP-allD.q. terms average plan length, PbP.q
PbP-noM.q perform usually better PbP-allD.q.
results Wilcoxon sign-rank test applied comparison PbP
PbP-noM confirm that, IPC7 domains, PbP.s significantly faster
PbP-noM.s (z = 7.699, p < 0.001) and, terms plan quality, PbP.q performs significantly better PbP-noM.q (z = 5.465, p < 0.001). high performance gap
PbP PbP-noM, favor PbP, clearly indicates usefulness using macros,
showing portfolio planners macros much efficient portfolio
planners.
4.6 Accuracy Planner Cluster Selection
section concerns experimental goal G5. order test accuracy planner
cluster selection PbP, carried three related experiments performance
PbP using computed configuration knowledge compared performance
(a) every basic planner incorporated initial portfolio, (b) best performing
incorporated planner (without using macros) considered domain, (c) best
performing planner cluster (possibly using macros) considered domain.
following, Section 4.6.1 presents experiments (a) (b), Section 4.6.2 experiment (c).
4.6.1 PbP Basic Portfolio Planners
Figure 4 gives overall picture performance PbP.s/q w.r.t. performance
basic planners (without macros) terms speed plan quality, using CPU-time limit
run ranging 1 1000 seconds. time/quality scores compared
system derived summing corresponding scores obtained system
IPC7 domain. analysis indicates that, every considered CPU-time limit, PbP.s
DSK generally much faster incorporated basic planners, PbP.q generates
better quality plans.
Experimental result 4.6.1 IPC7 domains, basic planner considered input portfolio PbP achieves overall performance better similar
performance PbP.s speed, PbP.q plan quality (except low
CPU-time limits, compared planners perform similarly terms plan quality).
673

fiGerevini, Saetti, & Vallati

IPC7
Domains

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains
IPC7
Domains

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains

Time score
PbP.s
noM
30.0
12.0
30.0
17.3
22.3
16.5
30.0
30.0
7.8
6.2
27.0
27.0
30.0
30.0
30.0
30.0
23.7
11.9
232.3 181.3

allD
10.9
8.3
8.7
15.0
0.0
13.6
18.3
11.3
0.0
86.1

Mean
PbP.s
2.0
5.9
28.3
18.2

16.9
28.3
13.5

25.8

CPU time
noM
allD
72.9
138.6
48.1
311.4
49.3
134.8
18.2
175.1


16.9
192.7
28.3
151.0
13.5
272.0


44.7
194.4

# solved problems
PbP.s noM allD
30
30
30
30
30
21
26
21
13
30
30
30
8
7
0
27
27
26
30
30
30
30
30
25
25
13
0
236
219
175

Quality score
PbP.q
noM
allD
29.9
29.8
0.0
29.9
18.5
13.4
25.8
7.2
2.8
30.0
30.0
21.4
4.8
4.8
2.0
29.6
29.6
22.1
29.9
29.9
8.8
30.0
30.0
8.0
14.8
14.8
12.3
224.7 194.5 91.2

Mean
PbP.q

222.6
153.0
578.9
76.0
634.9
715.1
284.8
370.1
484.5

plan length
noM
allD


307.0 340.8
163.5 171.0
578.9 675.9
76.0
61.0
634.9 650.6
715.1 731.9
284.8 284.8
370.1 374.5
498.8 535.4

# solved problems
PbP.q noM allD
30
30
0
30
26
16
26
9
3
30
30
25
5
5
2
30
30
23
30
30
9
30
30
8
15
15
13
226
205
99

Table 12: Time/quality score, average CPU time/plan length number solved problems speed quality versions PbP, PbP-noM (abbreviated noM)
PbP-allD (abbreviated allD) IPC7 domains.

results Wilcoxon sign-rank test applied experiment confirm PbP.s
significantly faster every incorporated planner (z = 5.773, p < 0.001
9 ),
terms plan quality PbP.q performs significantly better (z = 3.920,
p < 0.001
9 ) except ParLPG. According Wilcoxon sign-rank test, statistical
difference quality performances PbP.q ParLPG. discrepancy
results analysis Figure 4 generated different ways
unsolved problems handled quality score function Wilcoxon sign-rank
test comparing plan quality performance: first considers problems attempted
compared planners (explicitly penalizing planner zero score unsolved
problem), second considers subset test problems solved
compared planners; PbP.q solves many problems ParLPG (230 179),
reflected relative curves Figure 4 plan quality.
observed domains Rovers, Satellite Gripper solutions PbP.q
computed ParLPG; domains Blocksworld Depots, PbP.q using ParLPG solves
5 3 problems, respectively; considered domains, ParLPG part
selected cluster running planners. better understand importance ParLPG PbP,
analyzed performance version PbP incorporate ParLPG.
674

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7 domains

Time score
240

PbP.s
FD
LAMA (1st sol.)
LPG-td (1st sol.)
Macro-FF
Marvin
Metric-FF
SGPlan5
YAHSP
ParLPG

200
160
120
80

IPC7 domains

Quality score
210

PbP.q
FD
LAMA (last sol.)
LPG-td (last sol.)
Macro-FF
Marvin
Metric-FF
SGPlan5
YAHSP
ParLPG

180
150
120
90
60

40

30

0

0
1

10

100

1000

1

10

100

1000

Figure 4: Time (left plot) quality (right plot) scores PbP.s/q relative computed configuration knowledge compared time quality scores
basic incorporated planners IPC7 domains, using increasing CPU-time
limit. FD abbreviates Fast Downward.

IPC7 domains, PbP.s/q incorporate ParLPG, problems solved
PbP.s/q decrease 10/12%, and, terms time score, PbP.s without ParLPG
performs worse ParLPG (156.1 vs. 176.5). However, terms quality score, PbP.q
without ParLPG performs still much better ParLPG (183.1 vs. 144.5). results
analysis show performance PbP terms speed drastically affected
ParLPG. hand, importance ParLPG PbP.q limited
parameter configuration ParLPG focused speed.
two main reasons explaining observation derived Experimental result 4.6.1
globally best performance PbP.s/q basic incorporated planner
(even ParLPG) outperforms others every considered benchmark domain,
PbP effectively selects combines efficient planners domain
consideration (possibly using useful set macro-actions).
One may wonder picture different PbP.s/q compared basic
incorporated planners using (possibly empty) set macros. Figure 5 shows results
comparison, using CPU-time limit run ranging 1 1000 seconds.
sake readability, names 38 combinations basic incorporated planners
sets macros (learned Wizard Macro-FF) omitted. time/quality
scores compared system derived summing corresponding scores obtained compared system IPC7 domain. domain combination
planner P macro set empty, domain combination
restricted P .
results Figure 5 show that, terms CPU time, IPC7 domains
basic planner PbP that, using learned macro set, achieves overall performance
better similar performance PbP.s (except low CPU-time limits,
compared planners macros perform similarly). terms plan quality,
CPU-time limits lower 20 seconds, exist basic incorporated planners using
macros perform better PbP.q; high CPU-time limits, PbP.q performs much
better every compared planner macros. combinations basic incorporated
675

fiGerevini, Saetti, & Vallati

IPC7 domains

Time score
240

PbP.s
planner set macros

200

IPC7 domains

Quality score
240

PbP.q
planner set macros

200

160

160

120

120

80

80

40

40

0

0
1

10

100

1000

1

10

100

1000

Figure 5: Time (left plot) quality (right plot) scores PbP.s/q relative computed configuration knowledge compared time quality scores 38
combinations incorporated planners sets macros IPC7 domains.

planners sets macros low CPU-time limits perform better PbP.q
SGPlan5 using set learned macros, ParLPG using macro set bunching, YAHSP
using macro set clumping. low CPU-time limits, combinations planners
macros overall performance better PbP.q, essentially dominate
single domain: Barman SGPlan5, Blocksworld ParLPG YAHSP.
Since analysis Figure 4 considered test domains altogether, order verify
supposition also given single domain PbP performs better worse
every basic incorporated planner, compared PbP.s/q best-performing basic
planner (according test problems relative IPC scores) considered
domain. planner, indicated BestP.s/q, single planner (without macros)
would use oracle specifying best basic incorporated planner
test problems specific domain. results experiment shown Table 13.
domains Gripper, Rovers, Satellite Spanner planner cluster PbP.s
BestP.s. considered domains, time score average
CPU time PbP.s much better BestP.s. terms problem coverage, three
domains PbP.s solves much higher number problems; domains
problem coverage BestP.s. results show that, order achieve
higher planning speed, using cluster planners useful set macro-actions selected
PbP.s much better using single planner without macros. Sections 4.6.2
4.7 study usefulness using properly selected cluster planners
non-empty set macros, respectively.
Experimental result 4.6.2 IPC7 domain basic planner
considered input portfolio PbP.s faster, achieves better time score, solves
problems PbP.s.
Concerning plan quality, BestP.q contributes great deal success PbP.q, since
domains except Barman Spanner included cluster selected PbP.q
(see Table 2). Barman, Gripper, Parking, Rovers, Satellite, Spanner, TPP,
cases BestP.q provides solution PbP.q.
676

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7
Domains

BestP.s

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP

SGPlan5
ParLPG
ParLPG
ParLPG
FF
ParLPG
ParLPG
ParLPG
ParLPG


domains
IPC7
Domains

BestP.q

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP

SGPlan5
ParLPG
ParLPG
ParLPG
FF
ParLPG
ParLPG
ParLPG
LAMA


domains

Max
score
30
30
30
30
30
30
30
30
30
270

Time score
PbP.s
BestP.s
30.0
12.0
30.0
17.3
23.6
18.3
30.0
30.0
6.8
3.0
27.0
27.0
30.0
30.0
30.0
30.0
24.4
11.2
232.8
178.8

Mean CPU time
PbP.s
BestP.s
2.0
72.9
9.9
95.3
109.5
229.7
18.2
18.2
364.1
460.9
25.1
25.1
28.3
28.3
16.9
16.9
121.2
531.4
39.9
79.3

# solved problems
PbP.s
BestP.s
30
30
30
30
26
21
30
30
8
7
27
27
30
30
30
30
25
14
236
219

Max
score
30
30
30
30
30
30
30
30
30
270

Quality score
PbP.q
BestP.q
30.0
29.8
29.9
29.9
24.5
10.4
29.0
29.9
4.8
6.8
30.0
30.0
29.6
29.8
30.0
30.0
14.6
14.7
222.4
210.8

Mean plan length
PbP.q
BestP.q
449.3
452.9
269.9
272.8
160.1
163.1
577.3
570.1
79.0
80.6
694.7
694.7
785.2
782.8
326.0
326.0
370.1
366.3
472.6
481.8

# solved problems
PbP.q
BestP.q
30
30
30
30
26
11
30
30
5
7
30
30
30
30
30
30
15
15
226
213

Table 13: Maximum score, time/quality score, average CPU time/plan length, number
problems solved PbP.s/q best planner (BestP.s/q) IPC7
domains.

Experimental result 4.6.3 IPC7 domains, terms plan quality, relative
performance PbP.q best-performing basic planner (BestP.q) oracle would
choose generally slightly favor PbP.q: Blocksworld Depots PbP.q performs
better, Parking BestP.q performs slightly better, rest IPC7 domains
perform similarly.
Concerning Parking, Table 13 shows that, used benchmark problems,
BestP.q-planner FF, correctly contained cluster selected PbP.q
domain (see Table 2). However, cluster also includes additional planner (LAMA)
that, tested problems considered CPU-time limit, give useful
contribution PbP.q (no solution found LAMA), introducing noise
cluster selection. fact Parking useful set macros computed
PbP.q main reasons PbP.q performs slightly worse BestP.q-planners
considered test problems domain Parking.
Wilcoxon sign-rank test applied experiment confirms that, overall, PbP.s
significantly faster BestP.s-planner domain (z = 3.134, p 0.001);
terms plan quality, test results indicate performances PbP.q
677

fiGerevini, Saetti, & Vallati

BestP.q-planner significantly different (z = 1.157, p = 0.247); words,
test cannot derive one system performs statistically better other.
Finally, compared PbP.s/q best-performing combination P +
basic planner P non-empty set macros learned P IPC7 domain,
except Spanner macro computed. experiment, best macro set
P domain chosen considering performance P + training
problems D. Overall, terms speed score problem coverage, PbP.s performs
similarly P + five domains, performs much better three domains;
terms quality score, PbP.q performs similarly four domains much better
four domains. One reasons P + perform worse PbP.s/q
domains macros harmful, PbP.s/q correctly decides use them.
discussed also context experiment presented Section 4.7,
analyze usefulness macros accuracy selection PbP.s/q.
4.6.2 PbP Best-Performing Portfolio Configuration
order test accuracy planner cluster selection PbP.s/q, also
compared PbP computed configuration knowledge best-performing cluster
planners (with useful macros) considered test domain. (The worst-performing
cluster solves problem.) Table 14 shows results experiment considering two
best-performing clusters three planners: considered IPC7 domain,
BestC.s planner cluster highest time score among obtained
PbP.s using default PCPV; similarly, BestC.q planner cluster highest
quality score. Therefore data time/quality score columns BestC.s/q
maximum values time/quality score sums planner clusters set test
problems IPC7 domain.
every domain except Depots, time score PbP.s one
best cluster much greater zero (and thus much better score
worst cluster). Also terms average CPU time problem coverage performance
PbP.s best cluster almost always same. domain Depots PbP.s
BestC.s perform slightly differently; case, planners relative macros
cluster PbP.s different BestC.s. particular, Macro-FF selected
different set macros, makes PbP.s slightly slower.
Concerning PbP.q, overall, terms plan quality high performance gap
respect best cluster, although PbP.q performs worse domain TPP.
domain, training problems used PbP.q informative enough. observation
supported fact best cluster computed using training problems, instead
test problems, different one derived test problems.
hand, observed that, size training problems similar size test
problems, configured portfolios PbP.q BestC.q same.
Wilcoxon sign-rank test confirms that, overall, performance PbP.s/q
best cluster statistically significantly different (z = 0.422, p = 0.673, speed
analysis; z = 2.432, p = 0.015, quality analysis). Moreover, also observed
PbP.s/q without configuration (PbP-nok.s/q) performs generally much worse
678

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7
Domains

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains
IPC7
Domains

BestC.s
SGPlan5 (B)
ParLPG (B)
Macro-FF (M1)
ParLPG ()
Macro-FF (M2)
ParLPG ()
ParLPG ()
ParLPG ()
Macro-FF (M1)

BestC.q

Barman
SGPlan5 (Cl)
Blocksworld
ParLPG ()
Depots
MFF(M1),MFF(M2)
Gripper
ParLPG ()
Parking
FF (0)
Rovers
ParLPG ()
Satellite
ParLPG ()
Spanner
LPG ()
TPP
Macro-FF (M1)
domains

-

Max
score
30
30
30
30
30
30
30
30
30
270

Time score
PbP.s BestC.s
30.0
30.0
30.0
30.0
21.2
24.5
30.0
30.0
8.0
8.0
27.0
27.0
30.0
30.0
30.0
30.0
25.0
25.0
231.2
234.5

Mean CPU time
PbP.s
BestC.s
2.0
2.0
9.9
9.9
165.9
82.5
18.2
18.2
364.1
364.1
25.1
25.1
28.3
28.3
16.9
16.9
121.2
121.2
47.4
36.7

# solved probs
PbP.s BestC.s
30
30
30
30
26
28
30
30
8
8
27
27
30
30
30
30
25
25
236
238

Max
score
30
30
30
30
30
30
30
30
30
270

Quality score
PbP.q BestC.q
29.9
30.0
29.9
29.9
23.9
26.7
29.0
29.9
4.8
6.8
30.0
30.0
29.5
29.8
30.0
30.0
14.8
24.4
221.8
237.5

Mean plan length
PbP.q
BestC.q
449.3
448.3
269.9
272.8
160.1
165.1
577.3
570.1
79.0
80.6
694.7
694.7
785.2
782.8
326.0
326.0
370.1
379.5
461.2
487.6

# solved probs
PbP.q BestC.q
30
30
30
30
26
28
30
30
5
7
30
30
30
30
30
30
15
25
226
240

Table 14: Maximum score, time/quality score, average CPU time/plan length, number
problems solved PbP.s/q best cluster (BestC.s/q) IPC7
domains. MFF abbreviates Macro-FF. order planners listed
cluster Depots corresponds order run.

best cluster speed quality. Overall, experimental results derive
following observation.
Experimental result 4.6.4 IPC7 benchmarks, terms time score, average
CPU time problem coverage, PbP.s performs well or, Depots, similarly
BestC.s. terms quality score, average plan length problem coverage, PbP.q performs well similarly BestC.q, except TPP, plan quality score
problem coverage PbP.q worse.
Table 14 also shows often oracle would use single planner either quickly
solve IPC7 problems compute high-quality plans them. Hence, one may argue
using clusters formed one planner (possibly set useful macros)
useful. rationale best clusters Table 14 formed single planner
often incorporated planner (even using macros) requires almost CPU
time solve IPC7 test problem (except domain Depots); thus remaining time
usually enough improve coverage quality (first) computed plan
running one planner. purpose computing high-quality plans,
use set test problems smaller IPC7 problems, picture different.
679

fiGerevini, Saetti, & Vallati

Table 15 compares performance PbP best performing cluster planners
sets randomly generated medium-size problems IPC7 domains (i.e.,
size ranging largest training problems smallest testing problems).
table, BestC.s/q indicates clusters oracle would use solve sets
medium-size problems.
Experimental result 4.6.5 test problems IPC7 domains sizes ranging
training problem sizes IPC7 test problem sizes, IPC7
domains best planner clusters deriving high quality plans formed
one planner.
general, cluster planners containing certain planner performs worse
planner alone planning problems domain planner
portfolio configured efficiently solved planner alone, thus running also
planners cluster waste CPU time. cluster formed one
planner performs better single portfolio planner considered domain
planner dominating others terms either problem coverage CPU
time, problem coverage plan quality.
Interestingly, observed sometimes cluster selected PbP.q best
cluster intermediate-size test problems formed planner solves
problems, produces low-quality plans, planners produce higher-quality
plans, solve problems. case Barman TPP. domains,
although quality plans SGPlan5 low, SGPlan5 cluster
useful contributes greatly improve problem coverage cluster.
Finally, results Table 15 also indicate sometimes effectiveness
configured portfolio greatly affected difference size/hardness
training problems size/hardness test problems. particular, performance
gap PbP.q best cluster considered randomly generated intermediatesize problems domain TPP lower PbP.q best cluster IPC7
test problems TPP. indicates that, terms plan quality, effectiveness
planner portfolio configuration PbP.q computed using relatively small training problems
gradually decrease size/hardness test problems increased.
4.7 Macro Usefulness Selection Accuracy
section concerns experimental goal G6: analyze effectiveness using set
macros selected PbP planner, accuracy PbP selecting
useful set macros among computed Wizard Macro-FF planner
configured portfolio. shown Wizard Macro-FF often generate
useful sets macros speed planners (Botea et al., 2007b; Newton et al., 2007),
also known guarantee using macros always leads improving
speed planner, bad set macros could even make planner slower. Moreover,
usually degree usefulness set macros depends specific planner uses
them.
Concerning macros PbP.s, IPC7 domain least one non-empty set
computed macros planner selected cluster (see Table 2), compared
680

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7 domains

BestC.s

(medium probs)

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains
IPC7 domains

(B)
ParLPG (B)
MFF (M1), ParLPG (0)
ParLPG ()
MFF (M2)
ParLPG ()
ParLPG ()
ParLPG ()
Macro-FF (M1)

BestC.q

(medium probs)

Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains

(Cl), FF (), ()
P (), MFF (M1), LPG (B)
MFF (M1), P (), LPG ()
ParLPG ()
FF (), LAMA ()
ParLPG ()
ParLPG (), Marvin ()
LPG ()
MFF (M1), L (), (CH)


Time score
PbP.s BestC.s
30.0
30.0
30.0
30.0
28.9
29.7
30.0
30.0
22.0
22.0
30.0
30.0
30.0
30.0
30.0
30.0
30.0
30.0
260.9
261.7

Mean CPU time
PbP.s
BestC.s
1.5
1.5
7.3
7.3
57.4
52.5
13.2
13.2
308.7
308.7
17.6
17.6
14.3
14.3
13.6
13.6
93.6
93.6
50.9
50.4

# solved probs
PbP.s BestC.s
30
30
30
30
30
30
30
30
22
22
30
30
30
30
30
30
30
30
262
262

Quality score
PbP.q BestC.q
29.7
29.8
29.5
29.6
26.4
28.5
30.0
30.0
20.0
20.0
30.0
30.0
30.0
30.0
30.0
30.0
24.9
29.3
221.8
237.5

Mean plan length
PbP.q
BestC.q
327.2
327.1
174.7
173.2
143.1
145.4
472.3
472.3
63.1
63.1
694.7
694.7
524.6
524.6
257.2
257.2
219.4
220.3
462.6
463.2

# solved probs
PbP.q BestC.q
30
30
30
30
28
30
30
30
20
20
30
30
30
30
30
30
25
30
226
240

Table 15: Time/quality score, average CPU time/plan length, number problems
solved PbP.s/q best cluster (BestC.s/q) sets medium-size
problems IPC7 domains. S, M, MFF, P, L abbreviate SGPlan5, Marvin,
Macro-FF, ParLPG, LAMA, respectively. order planners listed
clusters corresponds order run.

number solved problems, number visited search nodes, average CPU time time
score using: (a) macros, (b) set macros identified PbP.s useful planner,
(c) set macros among computed planner terms time score
makes perform best test problems. results experiment,
given Table 16, following general observation derived.
Experimental result 4.7.1 IPC7 domains, often candidate set
macros planner (computed Wizard Macro-FF) greatly increases speed
performance configured portfolio, PbP.s correctly selects it.
Table 16 also indicates that, considered domains, performance
selected planners obtained using sets macros identified useful PbP.s
usually performance achieve using best sets macros.
gives strong positive evidence effectiveness PbP.ss approach selecting
useful set macros planner configured portfolio. particular, best
set macros set macros selected PbP.s (see Table 2).
exception sets macros identified PbP.s different best set
681

fiGerevini, Saetti, & Vallati

Domain &
Planner
Barman
SGPlan5
Blocksworld
ParLPG
Depots
Macro-FF
Parking
Macro-FF
TPP
Macro-FF

#S

macros
#N


TS

#S

PbP.s macros
#N

TS

#S

best macros
#N

TS

30



72.9

12.0

30



1.8

30.0

30



1.8

30.0

30

3361

95.3

17.3

30

218.0

9.9

30.0

30

218.0

9.9

30.0

0

242678



0.0

26

33654

203.3

22.2

28

21231

105.1

26.2

2

1739

406.9

0.6

8

880.9

92.3

8.0

8

880.9

92.3

8.0

0

71594

600.0

0.0

25

2990

121.2

25.0

25

2990

121.2

25.0

Table 16: Number solved problems (#S), number visited search nodes (#N), average
CPU time (T) time score (TS) planners forming cluster selected
PbP.s using macro, set macros selected PbP.s, best performing set computed macros. domains considered IPC7 domains
least one non-empty set computed macros. indicate
number nodes visited SGPlan5 could measured.

case Macro-FF domain Depots. However, shown Table 2, Depots PbP.s
selects cluster contains Macro-FF macro set M2 ParLPG, obtaining
overall performance experimentally observed similar performance
Macro-FF best set macros, M1. worth noting candidate sets
macros computed ParLPG Depots harmful (i.e., make speed performance
much worse) PbP.s correctly detects this, choosing run ParLPG zero macros
(denoted ParLPG (0) Table 2).
study computing using macros usually pursued main goal
speeding planning, possibly making quality computed plan lower
macros used. Interestingly, context PbP.q, several cases macros useful
also improving plan quality. Specifically, nine fifteen IPC6-7 domains,
configuration phase PbP.q selects clusters planners least one planner using
non-empty set macros (see Table 2). experimentally observed, training
problems test problems, two reasons macros useful PbP.q:
domains individual planners using macros leads better
quality plans. case, e.g., domains Barman Blocksworld using planners SGPlan5 LPG (first solution), respectively. behavior observed
also Botea et al. (2005), Coles Smith (2007), Newton et al. (2007).
selected cluster includes planner configured use set macros, usually
planner quickly computes solution. somewhat helpful also
test problems another planner cluster solve better solutions,
enough CPU time, quick termination planner macros
leaves CPU time run cluster planner(s). CPU time,
important especially incremental planner(s) included selected
682

fiPlanning Automatic Portfolio Configuration: PbP Approach

cluster, like LAMA ParLPG. many problem instances domains Depots,
Satellite TPP observed behavior.
Experimental result 4.7.2 IPC7 domains, use macros selected
PbP.q lead better quality solutions.
general, use macros make plan search effective because, e.g.,
planning multiple actions one search step size possible plateaus
depth local minima reduced. hand, large number macros
added domain, size search space drastically increase, making
problem harder solve. rest section, analyze kind number
macros selected used PbP. consider macro operators, i.e., parameterized
macros defined sequences (primitive) domain operators, macro actions, i.e., macros
derived instantiating parameters macro operators.
Table 17 describes macro operators sets selected PbP.s planner
configured portfolio (see Table 2) terms of: number aggregated operators,
number involved parameters, average numbers macro-actions primitive actions
augmented domain, average plan lengths obtained considered planners without
using macros, using counting planned macro actions single action.
data Table 17, derive interesting observations macros
used PbP considered domains. First, macro operators used PbP
planner three, often aggregate primitive operators. Secondly,
planners handle macros simply adding instantiated macro operators
domain definition (SGPlan5 ParLPG), average number macro actions
augmented domains much lower comparable number primitive domain
actions, even domain Barman SGPlan5 uses large macro operators involving
seven primitive operators six parameters. Hence, planners domains,
macro actions drastically increase search space. picture quite different
Macro-FF, macro operators selected PbP.s domains Depots, Parking
TPP, instantiated, generate number macro actions average one
orders magnitude greater number primitive domain actions. reason
Macro-FF successfully use macro operators even number domain macro actions
huge planner instantiates macro operators filters macro actions search
time, according relaxed-plan heuristic applied current search state, rather
simply adding macro actions original domain planning.
fact experiment PbP never generates configured portfolios large
sets macro actions added domain description seems indicate that, number
macro actions high w.r.t. number primitive actions, macro exploitation
method usually makes performance planner using much worse. observation confirmed additional experiment added PDDL description
macro operators learned Macro-FF domain Depots original description
Depots, run Macro-FF using resulting augmented domain. shown Table 17,
Depots number learned macro actions one order magnitude greater
number primitive actions. experimentally observed augmented
domain Macro-FF (without method using macros) solves Depots problem.
683

fiGerevini, Saetti, & Vallati

Domain &
Planner
Barman
SGPlan5+B
Blocksworld
ParLPG+B
Depots
Macro-FF+M2
Parking
Macro-FF+M2
TPP
Macro-FF+M1

#operators
every m.
7,4

#parameters
every m.
6,4

2,3,2

2,2,2

2,2

5,6

5,2

8,5

6

9

#grounded
macros
1645
(397)
17757
(5812)
224053
(114600)
billions
(billions)
billions
(billions)

#actions
15610
(3767)
11983
(5270)
16005
(8269)
243223
(151979)
133145
(78545)

Plan length
without m.
452
(57)
415
(107)

143
(23)


Plan length
m.
374
(45)
153
(42)
119
(26)
64
(11)
238
(51)

Table 17: Number (primitive) operators forming selected macro operators,
number parameters macro operator, average number instantiated
macro actions, average number domain (primitive) actions, average plan length
without using macros, average plan length using macros counting
planned macro action single action. number 2nd 3rd columns
refers different macro operator. Numbers brackets standard deviations. domains considered IPC7 domains least one non-empty
set learned macros selected PbP.s. B abbreviates Bunching macro
set learned Wizard; M1M2 two five sets macros generated
Macro-FF. indicate solution found within given
CPU-time limit.

Moreover, results average plan length Table 17, show plans
macro actions much shorter computed original domain, count
macro single action. Given planning application current
search state macro (or possibly combination macros Macro-FF) generates single
successor state, considered planners domains, average distance
initial search state goal state much shorter search space includes
macros, hence searching solution plan space much faster.
conclude, note usefulness macros also depend factors different
considered analysis, as, e.g., ratio number useful instantiations macro operator (providing shortcuts towards goal state)
number instantiations guides search towards wrong direction (Botea, Muller,
& Schaeffer, 2007a). factors might affect usefulness macro-operators
planning conjectured work McCluskey Porteous (1997).
4.8 Planner Cluster Scheduling
section concerns experimental goal G7: experimentally analyze possible alternative strategies scheduling execution planners portfolio configuration PbP planning time. first experiment, investigate use
PbP four sequential round-robin strategies predefined configured planning
time slots. second experiment, study importance choosing specific PCPV
684

fiPlanning Automatic Portfolio Configuration: PbP Approach

defining planning time slots (as described Section 3.1) particular PbPs
default PCPV.
Let input CPU-time limit, k maximum number planners cluster,
n number single planners, combined set macros, portfolio (in
experiment, = 900 seconds, k = 3, 9 n 38 depending number
computed macro sets). experimentally compare performance PbP using
following strategies planner cluster execution portfolio configuration:11
S1. Sequential execution tuple k planners Tk seconds run

P
every planner; number candidate configured portfolios ki=1 i! ni .
next (S2) strategies, planner terminates end time
slot, remaining time slot used (uniformly) increase slots
subsequently running planners.
S2. every combination time slots t1...k ti {0, 90, 180, 270, 360, 450,
540, 630, 720, 810, 900}, {1 k} t1 + + tk = , sequential execution
tuple k planners ti seconds runP
i-th
planner sequence;
number candidate configured portfolios ki=1 ni O(ui1 ), u
number non-zero planning time slots lower 900 (in experiment u = 9).
R1. Round-robin execution set k planners planning time slots
derived default PCPV defined Section 3.1 (this isPPbPs default
scheduling

strategy); number candidate configured portfolios ki=1 ni .
R2. every PCPV p = hp1 , ..., p9 set P (defined below), round-robin execution
set k planners planning
time uslots derived p;
Pk
n
number candidate configured portfolios i=1 O(s ), number
increments considered pi (in experiment = 4).
Set P R2 formed 100,000 PCPVs obtained setting percentage
PCPV value ranging li ui , with: l1 , ..., l9 equal 10, 15, 20, 25, 30, 35,
40, 45, 50; u1 , ..., u9 equal 70, 75, 80, 85, 90, 95, 98, 99, 100; increment step pi
equal ui 4li . instance, = 1, increment step p1 7010
= 15.
4
Consequently, values used first percentage p1 considered PCPVs 10,
25, 40, 55, 70.
Concerning execution order planners cluster, considered sequence
strategies S1 S2, order defined planner order sequence (two
sequences formed planners considered different clusters planners
differently ordered use different time slots); cluster planners strategies
R1 R2, execution order determined according increasing planning time slots
associated planners cluster (this default execution order strategy).
configuration phase PbP using four scheduling strategies generates four
alternative clusters planners, relative planning time slots, which, planning time,
run corresponding scheduling strategies used configuration
time. noted portfolio configuration using strategies S2 R2
11. planners candidate cluster executed simulation, described Section 3.2.

685

fiGerevini, Saetti, & Vallati

computationally much heavier configuration using S1 R1, respectively, since
many candidate configured portfolios considered. hand, since PbP
S2 R2 examines larger portfolio configuration spaces, principle, could obtain
accurate configured portfolios.
Tables 18 19 compare performance PbP configured using S1-S2 R1-R2
solving IPC7 domains problems. observed that, terms speed,
IPC7 benchmark domains except Depots, considered scheduling strategies
affect selection best cluster, since PbP.s always selects cluster formed
single planner (possibly using macros). Depots, shown Tables 18 19, PbP.s
round-robin scheduling strategies solves problems faster
sequential scheduling strategies.
Concerning plan quality, best cluster selected PbP.q contains one
planner every IPC7 domain. Overall, following observation derived:
Experimental result 4.8.1 IPC7 benchmark domains problems, PbP.q
R1-R2 solves problems PbP.q S1-S2 and, terms plan quality, overall
performs similarly PbP.q S1-S2.
think explanation PbP.q R1-R2 performs better terms number solved problems using round-robin strategy makes PbP.q robust
using sequential strategy respect possible incorrect ordering planner runs
inadequate values planning time slots decided configuration time.
training problems difficult used testing time (usually easier),
inaccurate estimation effectiveness learned configuration knowledge
arise. estimation time slot values incorrect planner execution
order damage severely sequential execution planners selected
cluster, since planners run once, using estimated time slot,
round-robin execution iteratively run (multiple) time
slots, total CPU-time limit reached planners terminate.
terms plan quality evaluated IPC quality scores, PbP.q R1-R2
tends perform better PbP.q S1-S2. main reason PbP.q R1R2 solves problems PbP.q S1-S2, quality score unsolved
problem zero. consider average plan quality (last four columns Tables 18
19), observe mixed results: two domains PbP.q R1-R2 performs best,
two worse, ones same. discrepancy evaluation results
using quality scores average plan qualities apparent, since quality score
average quality evaluations different assumptions way consider
unsolved problems. average plan quality, subset test problems solved
PbP using compared strategies considered; quality score, test
problems considered.
Seipp et al. (2012) show sequential portfolio 21 domain-independent statebased forward planners solve problems planning time slots uniform,
rather configured set training problems, because, considered planners
test problems, planner either quickly solves problem solve all.
context, observed sequentially run n planners PbP.q (i.e.,
38 combinations 9 basic planners with/without computed sets macros)
686

fiPlanning Automatic Portfolio Configuration: PbP Approach

IPC7
Domains
Depots

S1
20.8

Time Score PbP.s
S2
R1
R2
17.8
22.2
21.0

Problems Solved PbP.s
S1
S2
R1
R2
26
20
27
26

IPC7
Domains
Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains

Quality Score PbP.q
S1
S2
R1
R2
30.0
30.0
30.0
30.0
16.7
16.7
30.0
30.0
6.1
6.1
24.4
25.2
29.9
29.9
28.9
28.9
3.7
4.6
4.3
4.3
29.0
29.0
25.2
25.2
29.8
21.0
29.5
29.7
30.0
30.0
30.0
30.0
13.7
13.7
14.7
12.8
188.9 181.0 217.0 216.1

Problems Solved PbP.q
S1
S2
R1
R2
30
30
30
30
21
21
30
30
8
8
25
27
30
30
30
30
4
5
5
5
29
29
30
30
30
21
30
30
30
30
30
30
14
14
15
13
196
188
225
225

Table 18: Time/quality score number solved problems PbP.s/q using scheduling
strategies S1-S2 R1-R2 IPC7 benchmark domains problems.

using uniform time slots, 137 test problems solved (against 225 solved
PbP); n-planners uniform strategy performs well PbP.q CPU-time
limit increased several times (keeping 900 seconds PbP.q). Differently
observed work Seipp et al. (2012), experimental evaluation includes many
problems n planners PbP.q solve using considerable CPU time (e.g., number
problems solved planner incorporated PbP, even using macros,
within 10 seconds 80). Probably reason different behavior test
problems IPC7 learning track average difficult problems
IPC7 deterministic track, test problems used work Seipp et al.
(2012).
hand, PbP sequentially runs 3 planners, strategies S1S2, instead 38 possible combinations incorporated planners
learned macros, obtain behavior similar observed Seipp et al. (2012).
particular, results Tables 18 19 show terms number solved problems
speed, configuring planning time slots sequential scheduling cases
even degrade performance PbP w.r.t. using uniform distribution CPU time
(see results Tables 18 19 PbP.s using S1 S2 Depots PbP.q using
S1 S2 Satellite). However, context uniform distribution CPU time
planners cluster selected PbP best one, since experimentally
observed PbP S2 clearly outperforms PbP S1 configuration done
using test problems rather training problems. believe main reason
behavior experiment training problems much smaller
easier test problems, several cases makes PbP S2 (configured
training problems) underestimate CPU times required solve test problems.
687

fiGerevini, Saetti, & Vallati

IPC7
Domains
Depots

Average CPU Time PbP.s
S1
S2
R1
R2
256.2 360.8 185.2
185.0

Std. Dev. CPU Time PbP.s
S1
S2
R1
R2
122.3
250.4
206.1
78.2

IPC7
Domains
Barman
Blocksworld
Depots
Gripper
Parking
Rovers
Satellite
Spanner
TPP
domains

Average Plan Quality
S1
S2
R1
449.3 449.3 449.3
310.3 310.3 236.7
220.0 220.0 154.3
570.1 570.1 588.7
84.0
83.3
82.0
583.9 583.9 703.4
747.8 747.8 751.6
326.0 326.0 326.0
364.0 364.0 362.6
466.8 466.8 477.8

Std. Dev. plan
S1
S2
55.3
55.3
89.1
89.1
118.2
118.2
45.2
45.2
11.8
27.4
158.2
158.2
161.3
128.5
52.1
52.1
101.4
101.4
217.9
188.9

PbP.q
R2
449.3
236.7
159.5
588.7
82.0
703.4
751.6
326.0
362.6
477.6

quality PbP.q
R1
R2
55.3
55.3
68.6
68.6
32.5
32.8
38.0
38.0
24.8
24.8
194.9
194.9
183.8
183.8
52.1
52.1
99.1
99.1
238.4
238.8

Table 19: Average standard deviation CPU time/plan quality PbP.s/q using
scheduling strategies S1-S2 R1-R2 IPC7 benchmark domains
problems.

Contrary PbP S1-S2, PbP R1-R2 performs similarly according three
evaluation criteria (solved problems, speed plan quality). result indicates
configuring planning time slots considering many alternative PCPVs lead
high improvements respect using default predefined planning time slots,
PbP configuring values planning time slots less crucial using
round-robin strategy using sequential strategy, PbP R1-R2
less sensitive different size problems used configuration testing.
Experimental result 4.8.2 IPC7 benchmark domains problems, PbP.s/q
R1-R2 less sensitive definition planning time slots PbP.s/q
S1-S2.
rest section, study problem configuring PCPV used define
planning time slots round-robin planner scheduling PbP. particular,
address following questions focusing IPC7 benchmarks: important setting
PCPV particular value given domain? oracle specifying best
PCPV test problems specific domain, good would default PCPV
respect it?
data used analysis obtained follows. PCPV p set P
defined well scheduling strategy R2 previous experiment, PbP.s/q
run using cluster selected simulating round-robin scheduling planning
time slots derived p described Section 3.1. Thereby PbP.s/q configured
100,000 times different predefined PCPVs and, consequently, different predefined
planning time slots. resulting configured portfolios run (by simulation)
test problems learning track IPC7.
688

fiPlanning Automatic Portfolio Configuration: PbP Approach

Time score

Quality score

30

30

25

25

20

20

15

15

10

10

5

5

0

0
Barman

BW

Depots Grip. Parking Rovers

Sat. Spanner TPP

Barman

BW

Depots Grip. Parking Rovers

Sat. Spanner TPP

Figure 6: Distribution time (left plot) quality (right plot) scores PbP.s/q using
100,000 PCPVs IPC7 problems. BW, Grip. Sat. abbreviate
Blocksworld, Gripper Satellite, respectively.

Figure 6 analyzes time quality scores configured portfolios box
whisker plots. plot, bottom whisker worst score; bottom
box lower quartile score; band box median score; top
box upper quartile score; top whisker best score; finally, cross
score PbP.s/q domain using default predefined PCPV. following,
PCPV corresponding configured portfolio obtaining best time quality score
domain called best-performing PCPV domain. Since best performing
PCPV derived observed performance test problems, considered
best PCPV P oracle would give us. experimental data used
Figure 6, derive following observation.
Experimental result 4.8.3 Different IPC7 domains different best-performing PCPVs
PbP.
IPC7 domain length whisker Figure 6 zero, cluster
selected PbP.s/q PCPV formed single planner, hence
cases definition PCPV used derive planning time slots affect
performance PbP (all available CPU time assigned single selected planner).
plot speed happens domains except Depots, plot
plan quality, happens domain Spanner. domain Barman, clusters selected
PbP.q using configured PCPVs include SGPlan5 learned set macros,
planner cluster finding solutions test problems domain.
domains PbP.s/q always select singleton planner
cluster PCPVs considered, specific used PCPV high impact
PbPs performance, shown especially domains Depots, Gripper Satellite
quality-score plot Figure 6. Interestingly, observe default predefined
PCPV used PbP.s/q generally good choice, since often crosses plots
appear (or near to) top position corresponding whiskers.
689

fiGerevini, Saetti, & Vallati

Experimental result 4.8.4 every IPC7 domain, cluster selected PbP.s/q using
default PCPV h25, 50, 75, 80, 85, 90, 95, 97, 99i performs similarly PbP.s/q using
best-performing PCPV, except PbP.q domains Parking TPP.
Parking, best performance obtained running planners FF LAMA
PCPV equal h10, 15, 60, 65, 70, 75, 80, 95.5, 96.5i; TPP, obtained running planners LAMA, Macro-FF SGPlan5 PCPV equal h10, 15, 20, 25, 30, 35, 40, 45, 50i.
two domains, PbP.q default PCPV perform well
best-performing PCPV (but still better median-performing PCPV). main
reason domains IPC7 test problems much larger (and harder)
used training, which, also observed Section 4.6, affect accuracy
portfolio configuration test problems terms selected planner cluster
configured PCPVs.
Overall, results experiment configured default PCPVs PbP
indicate that, round-robin planner scheduling used, tuning PCPV (and consequently planning time slots) specific IPC7 domain greatly improve
performance resulting configured portfolio, since often default PCPV performs well best PCPV specified oracle. Consequently, given without
PCPV tuning portfolio configuration much simpler faster, PbP uses default
version.

5. Conclusions
existing automated-planning technology offers large, growing set powerful techniques efficient domain-independent planners, none outperforms
others every planning domain. practical perspective, useful consider
portfolio-based approach planning involves several techniques planners.
paper, proposed approach automatically configuring portfolio planners learned macros given domain, implemented portfolio-based
planner PbP. computed configuration knowledge consists promising combination
basic planners portfolio, one (possibly empty) set useful macros,
scheduling information specializing execution planning time.
configured portfolio obtained automated statistical analysis performance set candidate clusters planners relative candidate sets macros, using
collection training problems given domain. planner cluster performance
computed simulating cluster execution using performance data runs
individual basic planners (and relative sets macros) portfolio.
proposed approach portfolio planner configuration evaluated
large experimental analysis, focusing IPC6-7 domains, aim demonstrating high efficiency, understanding effectiveness automatic configuration,
investigating importance main design choices. Several results derived
various experiments analysis. important experimental results
indicate that:
configured planner portfolios generated PbP.s/q perform well compared
state-of-the-art planning systems using learning techniques, much better
690

fiPlanning Automatic Portfolio Configuration: PbP Approach








PbP-nok, i.e., unconfigured planner portfolio PbP (which competitive
LAMA, state-of-the-art domain independent planner);
PbP.s/q performs much better existing domain-independent portfoliobased planners, often better domain-optimized planner portfolio approaches;
computed configuration knowledge useful selection planner
cluster forming configured portfolio generally accurate given planning
domain;
macros planning domain always helpful planner improving
planning speed plan quality, PbP.s/q generally selects helpful sets macros;
context proposed approach, round-robin scheduling strategy
planner cluster execution robust strategy respect execution order
cluster planners planning time slots; moreover, configuring planning
time slots crucial given good default technique deriving currently
implemented PbP.s/q.

Besides evaluating approach PbP configuring planner portfolio macros,
experimental analysis corroborates validates results, observations empirical
studies previous work researchers planning. include usefulness
harmfulness macros set prominent existing planners, importance diversity
planning techniques construction effective planner portfolio,
robustness round-robin scheduling execution times multi-planner system.
current version PbP uses portfolio formed specific set selected
techniques plan synthesis, computation macros planner-parameter tuning,
architecture PbP open sense additional alternative (current future)
techniques integrated. Moreover, although chosen Wilcoxon sign-rank
test comparing candidate planner clusters macro sets, demonstrating effectiveness, methods could considered.
limit current approach, affects also systems relying knowledge
learned examples, training problem set representative
test problems (e.g., problems much smaller easier test problems),
computed portfolio configuration might accurate problems. Knowing
configuration time enough information characterizing test problems obviously
useful generating representative training problem sets. planning PbP,
experimentally observed that, minimum/maximum number objects involved
test problems known, randomly generated training problem sets object
bounds sufficiently representative effective configuration PbP.
think future work important study incorporate PbP
additional methods supporting problem-based configuration portfolio planner.
methods could refine current domain-based configuration problems
different size heuristically estimated hardness different, specialized configured
portfolios. Moreover, also important extend PbP.q plan quality
measured terms plan action costs rather number plan actions.
directions research investigating use PbP.s/q optimal
planning metric-temporal domains (Fox & Long, 2003), extending portfolios
691

fiGerevini, Saetti, & Vallati

additional automatically extracted domain-specific knowledge, entanglements
(Vallati et al., 2013a). Finally, intend investigate idea making PbP fully domainindependent computing many portfolio configurations (planner clusters) different
known domains, using classifier match new domain promising
stored configuration terms expected performance new domain. similar idea
successfully developed SAT (e.g., Xu et al., 2008).

Acknowledgments
Many ideas, techniques, systems investigated paper use build important
previous work planning portfolio design, without research would
possible. thank authors work, particular authors
planning systems macro generators incorporated PbP. special thank Mark
Roberts Adele Howe clarifications configuration planner portfolio,
Beniamino Galvani help implementation part preliminary version
PbP.s, IPC7 organizers letting us use competition machine one
experiments conducted competition. would also like thank
organizers IPC6 IPC7 developed made available large collection
useful benchmark domains, problems software tools used analysis.
Finally, thank anonymous Reviewers Associate Editor helpful
detailed comments.

References
Arfaee, S., J., Zilles, S., & Holte, R., C. (2010). Bootstrap learning heuristic functions.
Proceedings Third Annual Symposium Combinatorial Search (SOCS-10),
pp. 5260. AAAI Press.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11 (4), 134.
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI
planning automatically learned macro-operators. Journal Artificial Intelligence Research, 24, 581621.
Botea, A., Muller, M., & Schaeffer, J. (2007a). Fast planning iterative macros.
Proceedings Twentieth International Joint Conference Artificial Intelligence
IJCAI-07, pp. 18281833. AAAI Press.
Botea, A., Muller, M., & Schaeffer, J. (2007b). Learning partial-order macros solutions.
Proceedings Fifteenth International Conference Automated Planning
Scheduling (ICAPS-05), pp. 231240. AAAI Press.
Brendel, M., & Schoenauer, M. (2011). Instance-based parameter tuning evolutionary AI planning. Proceedings Thirteenth Annual Genetic Evolutionary
Computation Conference (GECCO-11), pp. 259260. ACM.
Cenamor, I., de la Rosa, T., & Fernandez, F. (2013). Learning predictive models configure planning portfolios. Proceedings ICAPS-13 Workshop Planning
Learning.
692

fiPlanning Automatic Portfolio Configuration: PbP Approach

Chen, Y., Hsu, C., & Wah, B. (2006). Temporal planning using subgoal partitioning
resolution SGPlan. Journal Artificial Intelligence Research, 26, 323369.
Chrpa, L., & Bartak, R. (2009). Reformulating planning problems eliminating unpromising actions. Proceedings Eighth Symposium Abstraction, Reformulation,
Approximation, (SARA-09), pp. 5057. AAAI press.
Chrpa, L., & McCluskey, T., L. (2012). exploiting structures classical planning problems: Generalizing entanglements. Proceedings Twentieth European Conference Artificial Intelligence (ECAI-12), pp. 240245. IOS Press.
Chrpa, L., McCluskey, T., & Osborne, H. (2012). Reformulating planning problems:
theoretical point view. Proceedings Twenty-Fifth International Florida
Artificial Intelligence Research Society Conference (FLAIRS-12), pp. 1419. AAAI
Press.
Coles, A., & Coles, A. (2011). LPRPG-P: Relaxed plan heuristics planning preferences. Proceedings Twenty-First International Conference Automated
Planning Scheduling (ICAPS-11), pp. 2633. AAAI Press.
Coles, A., Coles, A., Olaya, A., Celorrio, S., Lopez, C., Sanner, S., & Yoon, S. (2012).
survey seventh international planning competition. AI Magazine, 33 (1).
Coles, A., & Smith, K., A. (2007). Marvin: heuristic search planner online macroaction learning. Journal Artificial Intelligence Research, 28, 119156.
Cormen, T. H., Stein, C., Rivest, R. L., & Leiserson, C. E. (2001). Introduction Algorithms
(3rd edition). McGraw-Hill.
Fawcett, C., Helmert, M., Hoos, H., Karpas, E., Roger, G., & Seipp, J. (2011). FD-Autotune:
Domain-specific configuration using Fast Downward. Proceedings ICAPS-11
Workshop Planning Learning.
Fawcett, C., Vallati, M., Hutter, F., Hoffmann, J., Hoos, H., H., & Leyton-Brown, K. (2014).
Improved features runtime prediction domain-independent planners. Proceedings 24th International Conference Automated Planning Scheduling
(ICAPS), pp. 355359. AAAI Press.
Fern, A., Khardon, R., & Tadepalli, P. (2011). first learning track international
planning competition. Machine Learning, 84 (1), 81107.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. Journal Artificial Intelligence Research, 20, 61124.
Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministic
planning fifth international planning competition: PDDL3 experimental
evaluation planners. Artificial Intelligence, 173 (5-6), 619668.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs. Journal Artificial Intelligence Research, 20, 239290.
Gerevini, A., Saetti, A., & Serina, I. (2006). approach temporal planning scheduling domains predictable exogenous events. Journal Artificial Intelligence
Research, 25, 187231.
693

fiGerevini, Saetti, & Vallati

Gerevini, A., Saetti, A., & Vallati, M. (2009). automatically configurable portfolio-based
planner macro-actions: PbP. Proceedings Nineteenth International
Conference Automated Planning & Scheduling (ICAPS-09), pp. 350353. AAAI
Press.
Gibbons, J., & Chakraborti, S. (2003). Nonparametric Statistical Inference, Fourth Edition:
Revised Expanded. Statistics: Series Textbooks Monographs. CRC Press.
Gomes, C., P., & Selman, B. (2001). Algorithm portfolios. Artificial Intelligence, 126 (1-2),
4362.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M., Roger, G., & Karpas, E. (2011). Fast Downward Stone Soup: baseline
building planner portfolios. Proceedings ICAPS-11 Workshop Planning
Learning.
Hoffmann, J. (2003). Metric-FF planning system: Translating ignoring delete lists
numeric state variables. Journal Artificial Intelligence Research, 20, 291341.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Howe, A., Dahlman, E., Hansen, C., vonMayrhauser, A., & Scheetz, M. (1999). Exploiting
competitive planner performance. Proceedings Fifth European Conference
Planning (ECP-99), pp. 6272. Springer.
Howey, R., Long, D., & Fox, M. (2004). VAL: Automatic plan validation, continuous effects
mixed initiative planning using PDDL. Proceedings Sixteenth IEEE
International Conference Tools Artificial Intelligence (ICTAI-04), pp. 294
301. IEEE.
Hutter, F., Hoos, H., H., & Stutzle, T. (2007). Automatic algorithm configuration based
local search. Proceedings Twenty-second National Conference Artificial
Intelligence (AAAI-07), pp. 11521157. AAAI Press.
Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic
algorithm configuration framework. Journal Artificial Intelligence Research, 36,
267306.
Jimenez, S., C., Coles, A., & Coles, A. (2011). Seventh International Planning Competition
IPC7 learning part. http://www.plg.inf.uc3m.es/ipc2011-learning.
Kautz, H., A., & Selman, B. (1999). Unifying SAT-based graph-based planning.
Proceedings Sixteenth International Joint Conferences Artificial Intelligence
(IJCAI-99), pp. 318325. AAAI Press.
Long, D., & Fox, M. (2003). third International Planning Competition: Results
analysis. Journal Artificial Intelligence Research, 20, 159.
Marquardt, D., W., & Snee, D. (1975). Ridge regression practice. American Statistician, 29(1), 320.
694

fiPlanning Automatic Portfolio Configuration: PbP Approach

Matos, P., Planes, J., Letombe, F., & Marques-Silva, J. (2008). MAX-SAT algorithm
portfolio. Proceedings Eighteenth European Conference Artificial Intelligence (ECAI-08), pp. 911912. IOS Press.
McCluskey, T., L., & Porteous, J., M. (1997). Engineering compiling planning domain
models promote validity efficiency. Artificial Intelligence, 95 (1), 165.
Newton, M., Levine, J., Fox, M., & Long, D. (2007). Learning macro-actions arbitrary
planners domains. Proceedings Seventeenth International Conference
Automated Planning & Scheduling (ICAPS-07), pp. 256263. AAAI Press.
Pulina, L., & Tacchella, A. (2007). multi-engine solver quantified boolean formulas.
Proceedings Thirteenth International Conference Principles Practice
Constraint Programming (CP-07), pp. 574589. Springer.
Rice, J. R. (1976). algorithm selection problem. Advances Computers, 15, 65118.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. Journal Artificial Intelligence Research, 39, 127177.
Roberts, M., & Howe, A. (2006). Directing portfolio learning. Proceedings
AAAI 2006 Workshop Learning Search, pp. 129135.
Roberts, M., & Howe, A. (2007). Learned models performance many planners.
Proceedings ICAPS-07 Workshop AI Planning Learning.
Roberts, M., & Howe, A. (2009). Learning planner performance. Artificial Intelligence,
173 (5-6), 536561.
Roberts, M., & Howe, A. (2012). Personal communication. December 14.
Roberts, M., Howe, A., E., Wilson, B., & desJardins, M. (2008). makes planners
predictable?. Proceedings Eighteenth International Conference Automated
Planning Scheduling (ICAPS-08), pp. 288295. AAAI Press.
Seipp, J., Braun, M., Garimort, J., & Helmert, M. (2012). Learning portfolios automatically tuned planners. Proceedings Twenty-second International Conference
Automated Planning & Scheduling (ICAPS-12), pp. 368372. AAAI Press.
Shaffer, J., P. (1995). Multiple hypothesis testing. Annual Review Psych, 46, 561584.
Simon, H., & Kadane, J. (1975). Optimal problem-solving search: All-or-none solutions.
Artificial Intelligence, 6, 235247.
Vallati, M., Chrpa, L., & Kitchin, D. (2013a). automatic algorithm selection approach
planning. IEEE International Conference Tools Artificial Intelligence
(ICTAI), pp. 18. IEEE.
Vallati, M., Fawcett, C., Gerevini, A., Hoos, H., & Saetti, A. (2013b). Automatic generation efficient domain-optimized planners generic parametrized planners.
Proceedings 6th Annual Symposium Combinatorial Search (SOCS-13), pp.
184192. AAAI Press.
Vidal, V. (2004). lookahead strategy heuristic search planning. Proceedings
Fourteenth International Conference Automated Planning Scheduling (ICAPS04), pp. 150159. AAAI Press.
695

fiGerevini, Saetti, & Vallati

Wilcoxon, F., & Wilcox, R., A. (1964). Rapid Approximate Statistical Procedures.
American Cyanamid Co., Pearl River, N.Y.
Witten, I., H., & Frank, E. (2005). Data Mining: Practical machine learning tools
techniques. Morgan Kaufmann, San Francisco.
Xu, L., Hutter, F., Hoos, H., H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based
algorithm selection SAT. Journal Artificial Intelligence Research, 32, 565606.
Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge forward search
planning. Journal Machine Learning Research, 9, 683718.

696

fiJournal Artificial Intelligence Research 50 (2014) 141-187

Submitted 9/13; published 5/14

Enhanced Partial Expansion A*
Meir Goldenberg
Ariel Felner
Roni Stern
Guni Sharon

MGOLDENBE @ GMAIL . COM
FELNER @ BGU . AC . IL
RONI . STERN @ GMAIL . COM
GUNISHARON @ GMAIL . COM

Ben-Gurion University Negev
Beer-Sheva, Israel

Nathan Sturtevant

TURTEVANT @ CS . DU . EDU

University Denver,
Denver, USA

Robert C. Holte
Jonathan Schaeffer

HOLTE @ CS . UALBERTA . CA
JONATHAN @ CS . UALBERTA . CA

University Alberta
Edmonton, Canada

Abstract
solving instances problem domains feature large branching factor, A* may
generate large number nodes whose cost greater cost optimal solution.
designate nodes surplus. Generating surplus nodes adding OPEN list may
dominate time memory search. recently introduced variant A* called Partial
Expansion A* (PEA*) deals memory aspect problem. expanding node n,
PEA* generates children puts OPEN children f = f (n). n reinserted OPEN list f -cost best discarded child. guarantees surplus
nodes inserted OPEN.
paper, present novel variant A* called Enhanced Partial Expansion A* (EPEA*)
advances idea PEA* address time aspect. Given priori domain- heuristicspecific knowledge, EPEA* generates nodes f = f (n). Although EPEA*
always applicable practical, study several variants EPEA*, make applicable
large number domains heuristics. particular, ideas EPEA* applicable
IDA* domains pattern databases traditionally used. Experimental studies
show significant improvements run-time memory performance several standard benchmark applications. provide several theoretical studies facilitate understanding new
algorithm.

1. Introduction
A* derivatives IDA* (Korf, 1985) RBFS (Korf, 1993) general state-based
search solvers guided cost function f (n) = g(n) + h(n). Given admissible (i.e. nonoverestimating) heuristic function h, A* guaranteed find optimal solution. paper
Yoshizumi, Miura, Ishida (2000), performance studies A* mostly concentrated
number nodes A* expanded.1 Furthermore, general result optimality A*
1. Papers memory-bounded A* work Russell (1992) recent work Zhou Hansen
(2002) form one notable exception statement. However, saving time heap operations reducing size
OPEN list central focus papers.
c
2014
AI Access Foundation. rights reserved.

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

respect expanded nodes established (Dechter & Pearl, 1985). However, number
expanded nodes clearly represent performance A* accurately enough. Rather,
run-time performance A* determined net total many factors, number
generated nodes time updating data structures (the OPEN CLOSED lists).
Motivated need view performance A* general context, focus
number nodes A* expands number nodes A* generates.
Let C cost optimal solution particular problem instance. A* expand
nodes n f (n) < C guarantee optimality solution. nodes generated
well. However, A* generates many nodes f (n) = C nodes f (n) > C well.
call latter group nodes surplus (with f (n) > C ). Surplus nodes never expanded
A* thus contribute finding optimal solution. Non-surplus nodes called useful.
Many important problem domains feature large branching factor. solving problems, A* may generate large number surplus nodes. fact, execution time spent
generating nodes may much larger time spent generating expanding
useful nodes. solving instances domains, number generated nodes central
performance issue.
first step address problem general manner taken Yoshizumi et al. (2000).
introduced variant A* called Partial Expansion A* (PEA*), deals memory
aspect surplus nodes problem. Throughout paper, n denotes current node
expanded (unless different meaning explicitly specified), nc denotes child n.
PEA* expands n, generates ns children adds OPEN children f (nc ) =
f (n). guarantees surplus nodes inserted OPEN. rest children
discarded. n re-inserted OPEN f -cost best discarded child f (nc ) > f (n)
(the one minimal f -value). node n expanded way several times, time
different f (n). Note PEA* addresses problem high memory consumption
caused storing surplus nodes OPEN. time, PEA* incurs high price terms
run-time performance, since may generate children given node once.
preface presentation contributions following observation. know
A* optimal respect number expanded nodes, give optimality
guarantees respect number generated nodes. reason optimality A*
way consults heuristic decide node expand next (i.e. node minimal
g(n) + h(n) among nodes OPEN). However, A* take h(n) consideration
generates children n. A* could know, based h, nc surplus without
actually generating nc , could avoid generating surplus nodes altogether.
observation leads directly first important contribution paper: variant A* called Enhanced Partial Expansion A* (EPEA*) (Section 3). EPEA* generates
children f (nc ) = f (n). contrast PEA*, children even generated.
enabled using priori domain- heuristic-specific knowledge compute list operators lead children needed f -cost without actually generating children.
knowledge algorithm using (also domain- heuristic-specific) form Operator Selection Function (OSF). given node expansion, OSF returns set children
f (nc ) = f (n) smallest f -value among children f (nc ) > f (n).
following example gives preview EPEA*. Consider four-connected grid-based
single-agent pathfinding domain (SAPF) Manhattan distance heuristic. OSF represents
following piece domain- heuristic-specific knowledge: goal North-West
142

fiE NHANCED PARTIAL E XPANSION A*

N

G
W

+0
+0

n

E


+2

+2

Figure 1: EPEA* uses domain heuristic-specific knowledge obtain set children nc
node n expanded f (nc ) = f (n).

current location agent, moving North West result f -value,
moving South East increase f -value two. example knowledge shown
Figure 1. EPEA* expands node n first time, generates children nodes
f (nc ) = f (n). OSF tells EPEA* nodes result applying operators North
West. Also, OSF determines cost n increased 2, corresponding cost
best child generated. EPEA* keeps n new cost OPEN. n
re-expanded, children n corresponding remaining operators (i.e. South East)
generated.
OSFs domain heuristic-dependent. minimum prerequisite applying EPEA*
solve problem instances particular domain particular heuristic existence
full-checking OSF introduce Section 5 specific domain heuristic.
paper organized follows. PEA* described Section 2. note PEA*
described terms Collapsing Frontier Nodes (CFN) general technique
used number well known algorithms. Section 3 presents EPEA*. Section 4 extends
ideas IDA* resulting variant IDA* called Enhanced Partial Expansion IDA* (EPEIDA*).
Sections 5-8 describe study experimentally different kinds OSFs. Sections 9 10
presents analytical insights aspects EPEA*. Section 11 touches upon topic using PEA*
EPEA* inconsistent heuristic exposes trade-off exists situation.
paper introduces significant amount terminology. readers convenience,
provided glossary terms Appendix A.
preliminary version paper presented AAAI-2012 (Felner et al., 2012). current paper extends conference version deeper treatment EPEA* algorithm including
extended set experimental theoretical studies.

2. Background Knowledge
EPEA* advances idea Partial Expansion A* (PEA*) (Yoshizumi et al., 2000). describe
PEA* general context technique called Collapsing Frontier Nodes (CFN).
143

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Figure 2: subtree rooted node n collapsed n, receives new stored value
F (n) = 8.

2.1 Collapsing Frontier Nodes
Designate set leaf nodes search tree frontier search. Best-first search
algorithms choose frontier node lowest cost expansion. n expanded, n
removed frontier children added frontier. frontier maintained
either memory (OPEN A*) logically (IDA*, RBFS). example, frontier
IDA* given iteration nodes generated expanded
iteration (these nodes would stored OPEN A* used). either case, following
admissibility invariant maintained: every node n frontier, cost n exceed
cost possible solution passes n.
Let n non-leaf node search tree R subset frontier, that, r
R, path search tree root r passes n. is, n common ancestor
nodes R. Collapsing Frontier Nodes (CFN) technique relies observation
possible obtain smaller frontier replacing R n. Furthermore, cost n
increased, without violating admissibility invariant, minimum cost among nodes R.
illustrated Figure 2 part frontier corresponding entire left subtree
(i.e. R consists three nodes costs 9, 9 8) collapsed node n. cost n
modified minimum cost among collapsed leaves (8 case).
collapse actions used many algorithms. SMA* (Russell, 1992), example, OPEN large, areas highest f -values OPEN collapsed. another
example, consider IDA*. IDA* iteration ends, seen collapsing entire frontier start node, gets f -value least cost frontier node threshold
next iteration. (Ghosh, Mahanti, & Nau, 1994), IDA* allowed use given amount
memory. memory limit exceeded, collapsing used remove nodes
largest cost. Another important example RBFS. one branch tree plus children
nodes branch kept memory times. frontier nodes collapsed.
use terminology coined Korf (1993). regular f = g + h value node
designated static value denoted f (n). f -value leaves propagated
common ancestor n collapse action called stored value n denoted
F (n). static value n Figure 2 5, stored value collapse action 8.
reach node n OPEN stored value F (n) = x x > f (n), know
n expanded least-cost frontier node static f -value x.
144

fiE NHANCED PARTIAL E XPANSION A*

Figure 3: Example PEA* EPEA*. Two expansions node shown. Solid circles
denote generated children, non-solid circles denote discarded/collapsed
children.

important note time set nodes collapsed n, stored value n may grow.
stored value node never decreases.
2.2 Partial Expansion A*
Partial Expansion A* (PEA*) (Yoshizumi et al., 2000) variant A* reduces memory
overhead A* putting surplus nodes OPEN. PEA* preserves admissibility using
collapse actions. EPEA*, new variant A* introduced paper, works similarly PEA*.
Therefore, clear grasp PEA* essential understanding EPEA*. following,
(1) define PEA* (2) discuss performance overheads PEA* EPEA* addresses.
simplicity, assume consistent heuristic.2 touch upon case inconsistent
heuristic Section 11.
PEA* maintains static stored value node. stored value obtained
collapse actions describe below. PEA* expands nodes order least stored value.
avoid putting surplus nodes OPEN, PEA* distinguishes two kinds nc :
1. Provably useful, i.e. children f (nc ) F (n). Since n satisfies admissibility
invariant, F (n) C . infer f (nc ) C , means nc useful.
Thus, checking f (nc ) F (n) proves nc useful. words children
f (nc ) F (n) provably useful sense A* cannot optimal without putting
nodes OPEN list. node provably useful necessary imply
A* expand node.
2. Possibly surplus, i.e. children f (nc ) > F (n). node nc might useful,
cannot proven point search. Note possibly surplus nc become
provably useful n re-expanded higher stored value.
2. heuristic h called consistent if, every node n child nc inequality h(n) h(nc ) + cost(n, nc )
holds. Equivalently, heuristic h consistent results monotonically increasing f -values, i.e. every node
n child nc , inequality f (nc ) f (n) holds.

145

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

PEA* expands n, generates children n, inserts OPEN provably
useful children f (nc ) = F (n). Since F (n) grow, provably useful children
f (nc ) < F (n) known put OPEN previous expansions n. possibly
surplus children n collapsed n, re-inserted OPEN stored value
obtained collapse action. n possibly surplus children, re-inserted
OPEN, moved CLOSED instead.
refer provably useful children f (nc ) = F (n) currently needed. refer
children (i.e. possibly surplus children provably useful children f (nc ) <
F (n)) currently unneeded. words, currently needed children n ones
PEA* would insert OPEN current expansion n. designate operators result
currently needed children currently needed. operators designated currently
unneeded.
idea PEA* demonstrated Figure 3. top part, node expanded,
children (x, y, z, w) generated. However, children f -value 3 (x
y) currently needed. inserted OPEN. children possibly surplus.
collapsed back a, gets new stored value F (a) = 4 (since f (z) = 4 least
static value among possibly surplus children a). Following this, re-inserted OPEN
F (a) = 4. two cases.
re-expansion: Assume node g f (g) = 3 goal. case,
expanded children costs larger 3 (z w) never put
OPEN.
Re-expansion a: chosen re-expansion F (a) = 4 (Figure 3 (bottom)),
children generated. node z f (z) = 4 currently needed. placed
OPEN. possibly surplus node w collapsed gets new stored value
F (a) = 5. currently unneeded nodes (x y) discarded. Since possibly
surplus children, put back OPEN.
pseudo-code PEA* shown Procedure 1. clearly show differences
different variants A*, show A*, PEA* EPEA* pseudo-code. make
pseudo-code easier read, assign dummy stored value nodes A*, although A*
really ever use it. PEA* generates new node, sets new nodes stored value
equal static value (lines 2, 18).3 Nodes expanded order best stored value
(line 5). expanding n, PEA* generates children (line 7) inserts OPEN
children f (nc ) = F (n) (lines 11-18). nodes currently needed. children
f (nc ) > F (n) possibly surplus. collapsed n, whose stored value becomes
lowest static value among children (line 14). children f (nc ) < F (n) discarded
(line 15). n possibly surplus children (i.e. children n inserted OPEN),
n put CLOSED (line 20). Otherwise, n re-inserted OPEN new stored
value (line 22).
3. Although notion stored value defined context collapsing, view yet unexpanded node
frontier node collapsed itself.

146

fiE NHANCED PARTIAL E XPANSION A*

Procedure 1 A*, PEA* EPEA*.
1: Generate start node ns
2: Compute h(ns ) set F (ns ) f (ns ) h(ns )
3: Put ns OPEN
4: OPEN empty
5:
Get n lowest F (n) OPEN
6:
n goal exit
// optimal solution found!
7:
A* PEA*: set N set children n initialize Fnext (n)
8:
EPEA*: set (N, Fnext (n)) OSF (n).
9:
nc N
10:
Compute h(nc ), set g(nc ) g(n) + cost(n, nc ) f (nc ) g(nc ) + h(nc )
11:
PEA*:
12:
f (nc ) 6= F (n)
13:
f (nc ) > F (n)
14:
Set Fnext (n) min(Fnext (n), f (nc ))
15:
Discard nc
16:
continue
// next nc
17:
Check duplicates
18:
Set F (nc ) f (nc ) put nc OPEN
19:
Fnext (n) =
20:
Put n CLOSED
// A*, always done
21:
else
22:
Set F (n) Fnext (n) re-insert n OPEN
// Collapse
23: exit
// solution.

2.3 Parameter C Comparison EPEA* PEA*
PEA* saves memory putting surplus nodes OPEN, incurs large time performance
overhead, since, whenever re-expands node n, generates children nodes n
computes f -values, thus repeating work expanded n first time.
domains children n assume large number different static values, run-time
overhead large. make PEA* practicable domains, authors PEA* introduced
C-parameter, determines trade-off amount memory saved runtime overhead paid. node n expanded, children F (n) f (nc ) F (n) + C
added OPEN (the change made line 12 pseudo-code). C = 0 maximal
memory savings obtained. variant shown pseudo-code. C = , PEA*
becomes equivalent A*. best choice C domain-, heuristic- instance-dependent
policy selecting C reported.
EPEA* memory-time trade-off. saves amount memory
PEA* C = 0, saving run-time well. Therefore, experiments, always
compare EPEA* PEA* C = 0.
show Section 9 that, although PEA* motivated trying make OPEN smaller,
sometimes exactly opposite effect.
147

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

3. Enhanced Partial Expansion A*
section presents new variant A*, Enhanced Partial Expansion A* (EPEA*). start
important observation.
3.1 Three Phases Way OPEN
One key observations used EPEA* every node passes three phases inception
entry OPEN:
1. Discovering checking operator. search algorithm (a) discovers applicable
operator (b) checks whether operator applied. many commonly used
domains, list applicable operators (step (a) above) determined easily looking
current state. planning domains, discovering operator consists checking operators
preconditions. either case, A* PEA* generate children nodes corresponding
applicable operators. perform step (b) above. Checking operator refers
deciding whether apply available operator. now, step gone unnoticed.
Distinguishing step key idea EPEA*.
2. Applying operator. also refer phase generating node, since search
algorithm generates child node applying operator node expanded.
A*, generating node preceded making copy parent, IDA*
needed.
3. Inserting node OPEN. new node becomes part frontier nodes maintained
search algorithm.
3.2 Operator Selection Function (OSF)
difference EPEA* PEA* summarized follows. PEA* generates
children nc n two objectives:
1. put OPEN children f (nc ) = F (n)
2. update stored value F (n).
EPEA* achieves objectives without generating children. Instead, employs domainand heuristic-specific Operator Selection Function (OSF) generate children nc
n f (nc ) = F (n) compute next F (n). section, describe OSF. next
section, present EPEA* algorithm.
OSF consists two components:
1. Knowledge Component domain- heuristic-specific knowledge.
2. Algorithmic Component algorithm uses knowledge component attain
stated objectives OSF.
example OSF, consider single-agent pathfinding domain (SAPF) Figure 4 (left).
agent placed 4-connected grid (the shaded cell figure). agents arsenal
actions consists 4 cardinal moves Wait move (where agent stands still). Assume
148

fiE NHANCED PARTIAL E XPANSION A*

N

G

W

3
3 4 5
5

E


f (nc )
0
1
2

h(nc )
-1
0
1

Operators
North, West
Wait
South, East

Fnext (n)
1
2


Figure 4: knowledge component OSF single-agent pathfinding Manhattan
distance heuristic. part knowledge component case goal located
north-west current location shown.

moves cost 1 heuristic function Manhattan distance (MD). figure, numbers
inside cells corresponding h-values.
Consider case goal located north-west current location. knowledge component OSF example shown Figure 4 (right) form table.
table uses following convenient notation, continue use throughout paper.
Consider expansion n operator produces child nc . denote change
heuristic value resulting applying operator h(nc ) = h(nc ) h(n) change
f -value f (nc ) = f (nc ) f (n). current difference stored
static value n denoted F (n) = F (n) f (n). next stored value n denoted
Fnext (n), F (n) corresponds stored value denoted Fnext (n).
table groups operators according f (nc ) orders groups according increasing
order quantity. Note that, since quantities f (nc ) h(nc ) differ cost(n, nc ),
constant domain, ordering operators either f (nc ) h(nc ) produces
result.
EPEA* expands node n stored value F (n) needs generate children
nc f (nc ) = F (n), would invoke algorithmic component OSF to:
1. Find row correspond f (nc ) = F (n) f (n),
2. Generate currently needed children applying operators row,
3. Return next stored value n: Fnext (n) = f (n) + Fnext (n).
OSFs domain heuristic-dependent. Using EPEA* solve problem instances particular domain particular heuristic requires creation OSF specific domain
heuristic. provide classification OSFs Section 5. particular, minimum prerequisite applying EPEA* existence full-checking OSF described section
given domain heuristic. classification OSFs also serve general guideline OSF
construction.
OSF bears resemblance concept preferred operators, often used domain
independent planners FF (Hoffmann & Nebel, 2001) Fast Downward (Helmert, 2006;
Richter & Helmert, 2009).4 Preferred operators subset actions assumed
likely lead goal. expanding node, FF generates nodes using
4. FF, preferred operators called helpful actions.

149

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

preferred operators ignoring actions. often reduces search time cost
loss completeness. Fast Downward uses preferred operators conservative manner
preserves completeness. Nodes generated preferred operators prioritized
expanded often. done maintaining additional OPEN list containing nodes
generated preferred operators. Fast Downward alternates expanding node
additional OPEN list regular OPEN list containing generated nodes.
Preferred operators impose binary partition set operators: operator either preferred not. contrast, OSF provides finer grained operator partitioning, grouping operators
according f values. Moreover, neither FF Fast Downward able completely avoid
generating surplus nodes using preferred operators, EPEA* algorithm described
exactly using OSF.
Note Fast Downward uses preferred operators conjunction another technique called
deferred heuristic evaluation (Helmert, 2006; Richter & Helmert, 2009). Deferred heuristic evaluation saves heuristic computation time inserting generated nodes OPEN f -value
parent. heuristic node computed node reaches top
OPEN list. Thus, deferred heuristic evaluation trades memory time spent OPEN list
operations saving heuristic computation time. One view deferred heuristic evaluation
opposite collapse action (Section 2.1): collapse saves memory time needed
OPEN list operations.
ready describe EPEA* algorithm.
3.3 Definition EPEA*
flow EPEA* (Procedure 1) identical PEA*: (1) puts nodes OPEN
expands order PEA* (2) collapses possibly surplus children nodes.
Therefore, pseudo-code EPEA* similar PEA*. differences stem
fact EPEA* uses domain- heuristic-specific Operator Selection Function (OSF):
1. Instead generating children nodes discarding currently unneeded ones (PEA*,
lines 7 15), EPEA* uses OSF generate currently needed children nodes
start (line 8).
2. Instead looking children n compute next stored value (PEA*, line 14), EPEA*
receives value OSF (line 8).
already seen operation PEA* example Figure 3. Consider operation
EPEA* example. Figure 3 (top), EPEA* uses OSF generate
currently needed children x y. generate nodes z w, since possibly
surplus. OSF also determines next stored value (F (a) = 4) lowest cost among
nodes z w. Figure 3 (bottom), children x, z provably useful. However,
z currently needed generated OSF, since costs x (3) lower
F (a) (4). important clearly see distinction PEA* EPEA*: nodes
generated discarded PEA* nodes EPEA* generate.
example concrete OSF, consider operation EPEA* SAPF example
Figure 4 (left) OSF shown Figure 4 (right) described Section 3.2. Suppose
n (with agent shaded cell) expanded first time f (n) = F (n) = 10. EPEA*
uses OSF get children f (nc ) = F (n) = 10. is, interested children
150

fiE NHANCED PARTIAL E XPANSION A*

f (nc ) = 0. OSF uses information Figure 4 (right) produce children
correspond operators North West. children f (nc ) > F (n) collapsed n,
gets stored value determined f -value operator next row. case,
next row contains operator Wait f = 1, next stored value n Fnext (n) =
f (n) + 1 = 11. convenience, next value F (n), Fnext (n) = Fnext (n) f (n),
shown rightmost column table.
n re-expanded f (n) = 10 F (n) = 11, OSF returns nodes nc f (nc ) =
F (n) = 11 or, equivalently, f (nc ) = 1. corresponds applying Wait operator.
remaining children f (nc ) > F (n) collapsed n, get stored value
f (n) + Fnext (n) = 10 + 2 = 12.
Note table Figure 4 (right) expanding n located South-East
goal. complete knowledge component OSF domain contains seven tables
possible locations n relative goal.
3.4 High-Level Comparison A*, PEA* EPEA*
section, compare A*, PEA* EPEA* respect memory run-time
performance.
3.4.1 EMORY P ERFORMANCE
A* puts OPEN every node generates generated
lower cost. PEA* improves memory performance A* putting OPEN
currently unneeded nodes. actual memory saving determined parameter C (see
Section 2.2), greatest saving achieved setting C = 0. EPEA* puts OPEN
nodes PEA* C = 0. Therefore, EPEA* affords memory savings
memory-effective variant PEA*.
3.4.2 RUN -T IME P ERFORMANCE
First, compare node performance three algorithms:
A* known optimal respect number expanded nodes (Dechter & Pearl,
1985). give guarantees respect number generated nodes.
Consider first expansion node expanded PEA*. expansions
A* performs. Also, PEA* performs expansions order A*. Therefore,
PEA* optimal respect number unique node expansions.5 However, PEA* may
re-expand node many times. re-expansion, PEA* generates
nodes children. Therefore, PEA* may perform many node generations A*.
EPEA* expands nodes PEA* order. Therefore, like PEA*,
EPEA* optimal respect number unique node expansions. Unlike PEA*,
EPEA* generate currently unneeded nodes. Therefore, EPEA* may skip generating states A* would generate. fact, optimality results respect
5. Although number unique node expansions practical interest, interesting means understanding algorithm performance. Therefore, measure number unique node expansions
experiments.

151

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Variant

nodes generated

nodes put OPEN

A*
PEA*
EPEA*, full-checking OSF



Currently needed,
obtained checking operators
Currently needed,
obtained direct computation


Currently needed
Currently needed

EPEA*, direct-computation OSF

Currently needed

Table 1: High-level comparison A*, PEA* EPEA*.
number generated nodes recently proven variants EPEA* (Goldenberg, Felner, Stutervant, Holte, & Schaeffer, 2013).
consider run-time performance three algorithms:
Depending domain heuristic, A* may spend much time generating surplus
nodes. Also, A* may pay penalty related usage large amounts memory.
particular, OPEN list operations become expensive size search frontier
grows.
cases (see Section 9), PEA* uses smaller amount memory A*, pays
overhead possible re-expansions single node generating children node
re-expansion.
Similar PEA*, EPEA* pay price many possible re-expansions single node.
However, EPEA* avoids two run-time overheads PEA* suffers from: generating
useful node many times generating possibly surplus nodes. significance
savings depends size states domain amount computation
needs performed apply operator.
Depending kind OSF used (the different kinds OSFs considered
Section 5), EPEA* may able avoid generating currently unneeded nodes,
also checking operators result nodes (i.e. currently unneeded operators). differences A*, PEA* EPEA* respect phases described
Section 3.1 summarized Table 1. study time performance EPEA*
deeply Section 10.

4. Enhanced Partial Expansion IDA* (EPEIDA*)
begin noting IDA* viewed partial expansion built algorithm.
Namely, consider current iterations threshold stored value nodes iteration. IDA* completes iteration, collapses frontier nodes current iteration
root node, gets updated stored value next iterations threshold. Suppose
current iterations threshold . n expanded, children generated.
next level depth-first search, children nc n f (nc ) expanded,
children f (nc ) > discarded. partial expansion following one difference.
152

fiE NHANCED PARTIAL E XPANSION A*

PEA*, currently needed children children f (nc ) = F (n). children
f (nc ) < F (n) need put OPEN, since children put OPEN
previous expansions n. IDA* store information previous iterations
therefore needs search children f (nc ) < well. Therefore, context IDA*,
need re-define notion currently needed children n include children nc
f (nc ) .
describe EPEIDA*. clearly see distinctions IDA* EPEIDA*,
variants shown pseudo-code (Procedure 2). first difference EPEIDA* uses
OSF obtain list currently needed children (those f (nc ) ) lowest
cost among currently unneeded children (line 10). latter cost used update threshold
Tnext next iteration (line 11). threshold initialized infinity beginning
current iteration (not shown pseudo-code). contrast, IDA* generates children n
updates value threshold next iteration iterating list children
(IDA*, lines 5, 8). second difference EPEIDA* need check threshold
condition (IDA*, line 4). threshold condition equivalent condition
definition currently needed node IDA*. Since OSF generates currently needed
children, additional check needed.
number nodes EPEIDA* generates approximately b times smaller number
nodes generated IDA*, b average branching factor domain. verify
this, let X number nodes expanded last iteration IDA*. number nodes
generated iteration approximated bX. hand, EPEIDA* generates
X + (b 1)d nodes (more details given Section 10.1), depth search.
Since (b 1)d usually small compared X, ratio bX X + (b 1)d
approximately equal b. repeatedly point fact discussion experimental
results Sections 6-7.
experimental results compare performance EPEIDA* performance
IDA* several domains heuristics. studying results, important
mind IDA* viewed partial expansion built algorithm. Therefore,
compare EPEIDA* IDA*, really comparing EPEIDA* iterative deepening
version PEA*.

5. Classification OSFs
Recall high-level comparison A*, PEA* EPEA* Table 1. table, principle
distinctions EPEA* PEA* shown: EPEA* applies currently needed operators generate currently needed children, PEA* generates children node
n expanded. Furthermore, Table 1 shows two possibilities exist obtaining list
currently needed operators. possibilities correspond two classes OSFs:
1. full-checking OSF obtains list currently needed operators checking operators,
including currently unneeded ones.
2. direct-computation OSF obtains list currently needed operators means direct
computation.
two kinds OSF focus section. addition two pure classes,
encounter hybrid OSF. happen domains heuristics
153

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Procedure 2 IDA* EPEIDA*.
Variables:
current depth search tree
threshold current iteration
Tnext threshold next iteration, set infinity calling DFS().
1: DFS(n, i, )
2:
Compute h(n) set f (n) g(n) + h(n)
3:
IDA*:
4:
f (n) >
5:
Set Tnext = min(Tnext , f (n))
6:
return
// Threshold cut-off
7:
n goal halt
// optimal solution found!
8:
IDA*: Set N set children n
9:
EPEIDA*:
10:
Set N, f BestN otN eeded OSF (n)
11:
Set Tnext = min(Tnext , f BestN otN eeded)
12:
nc N
13:
Set g(nc ) g(n) + cost(n, nc )
14:
Call DF S(nc , + 1, )

able construct direct-computation OSF generate currently needed nodes certain
values f (nc ), values f (nc ). domains, construct
hybrid OSF, behave either direct-computation full-checking OSF different
(re-)expansions n depending required f (nc ).
show (Sections 6-8) OSF constructed well known domains heuristics. now, explain two pure classes OSFs using SAPF domain
running example.
5.1 Full-Checking OSFs
knowledge component full-checking OSF SAPF consists eight tables. table
corresponds one eight possible positions n relative goal. algorithmic component OSF determines tables must used given n based position
n relative goal. example, table case n located South-East goal (e.g.
shaded cell Figure 5 (left)) shown Figure 5 (right). on, use table
Figure 5 (right) running example.
operator applicable n, table records resulting changes h- f -values.
OSFs algorithmic component needs check operators decide children
nodes currently needed. generates children. Also, computes next stored
value n, Fnext (n), follows. Fnext (n) initialized infinity. Whenever OSF checks
operator results nc determines nc possibly surplus (i.e. f (nc ) > F (n)), updates
Fnext (n) Fnext (n) = min(Fnext (n), f (nc )).
154

fiE NHANCED PARTIAL E XPANSION A*

N

G

W

3
3 4 5
5

E


Operator
Wait
East
South
West
North

h(nc )
0
1
1
-1
-1

f (nc )
1
2
2
0
0

Figure 5: knowledge component full-checking OSF single-agent pathfinding
Manhattan distance heuristic. part knowledge component case
goal located north-west current location shown.

5.2 Direct-Computation OSFs
direct-computation OSF computes list currently needed operators directly, without
need check applicable operators. case SAPF, knowledge component
direct-computation OSF obtained described full-checking OSF ordering
rows eight tables order increasing f (nc ) merging rows corresponding f (nc ). table Figure 5 (right), corresponding knowledge
component direct-computation OSF shown Figure 4 (right). Given required f (nc ),
row currently needed operators found algorithmic component quickly
without checking operators.6 EPEA* apply operators generate corresponding currently needed children nodes.
general, direct-computation OSF constructed states domain
classified several classes, that, class C, one following holds:
table operators applicable states C ordered f (nc ) computed
stored main search begins. option used OSF
SAPF. case, class corresponded one eight possible locations n
respect goal.
set operators given f (nc ) computed on-the-fly search.
option use Section 6.2 pancake puzzle GAP heuristic (Helmert, 2010).
Even one conditions satisfied, may impossible impractical
construct direct-computation OSF given domain heuristic one
following reasons:
1. construct tables operators ordered f (nc ), large number state classes must
defined, resulting large time memory requirements pre-compute store
tables.
2. determine class given state belongs to, operators applicable state need
checked.
6. domain large number f (nc )-values, binary search hashing mechanism used.

155

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

reasons clarified Section 6.1, explain cannot construct
direct-computation OSF 15-Puzzle Manhattan distance heuristic.
Note even case direct-computation OSF available given domain
heuristic, still construct direct-computation OSF given search node. Namely,
n expanded first time, compute table operators applicable n ordered
f (nc ) store table together n OPEN. subsequent re-expansions
n, table used knowledge component direct-computation OSF. decision
whether construct direct-computation OSF individual search nodes depends following
time-memory trade-off:
Using technique eliminates need check operators re-expansion n.
amount saved execution time depends many times n re-expanded, turn
depends many different f -values taken children n.
Storing table applicable operators every node OPEN may prohibitively expensive (memory-wise) domains high average branching factor.

6. Experimental Study Different Kinds OSFs
two following sections, construct OSF show experimental results
several domains heuristics. start relatively simple OSFs section move
towards complicated PDBs-based OSFs Section 7. move yet
complicated additive PDBs-based OSFs Section 8. description OSF immediately
followed experimental study OSF.
start EPEIDA* two domains heuristics:
15-puzzle Manhattan distance heuristic. domain, construct
full-checking OSF explain constructing direct-computation OSF impractical.
pancake puzzle GAP heuristic. domain, construct hybrid OSF.
see that, practice, OSF behaves direct-computation OSF expansions.
One easily come interesting domains heuristics, pure direct-computation
OSF constructed. However, decided focus well known benchmark domains.
able show direct-computation OSFs domains context OSFs based
pattern databases (Culberson & Schaeffer, 1998; Felner, Korf, & Hanan, 2004) Sections 7 8.7
6.1 Full-Checking OSF 15-puzzle
15-puzzle consists 4 4 square frame containing 15 numbered square tiles, empty
position called blank. legal operators slide tile horizontally vertically
adjacent blank blank position. problem rearrange tiles random
initial configuration, e.g. Figure 6 (left), configuration Figure 6 (middle). Manhattan
distance (MD) classic heuristic function puzzle. computed counting
7. saw direct-computation OSF SAPF. However, searches state space SAPF feature small
number surplus nodes, makes uninteresting application EPEA*.

156

fiE NHANCED PARTIAL E XPANSION A*

6

1

5

8

13

3

9

4 14

7

1

2

3

4

5

6

7

8

9 10 11

2

12 10 15 11

Operator
13 moves East
6 moves South
3 moves West
14 moves North

12 13 14 15

h(nc )
1
-1
1
1

f (nc )
2
0
2
2

Figure 6: Left: possible state 15-Puzzle. Middle: goal state 15-Puzzle. Right: part
knowledge component OSF 15-Puzzle Manhattan distance
heuristic case set applicable operators state left.

number grid units tile displaced goal position, summing values
tiles.
6.1.1 OSF
15-puzzle, quantity f (nc ) operator applicable n completely determined by:
1. location blank,
2. identity tile moved operator,
3. position tile relative blank.
Therefore, construct knowledge component full-checking OSF 15-puzzle
three-dimensional array dimensions 16 15 4. dimensions stand 16 possible
locations blank, 15 possible identities tile moved 4 possible positions
tile moved relative blank. element array f (nc ) corresponding
operator.
Example. operators applicable node n Figure 6 (left), knowledge component OSF would store f (nc )-values shown Figure 6 (right). example,
operator moves 13 blank position, f (nc )-value (2) stored element
[6][13][0], 6 denotes position blank, 13 identity tile moved 0
denotes operator moves tile West blank blank position.
node n, algorithmic component OSF would (1) check operators Figure 6 (right)
looking corresponding entries three-dimensional array (i.e. knowledge component),
(2) generate currently needed nodes applying operators f (nc ) = F (n) f (n),
(3) compute next stored value n using minimal f (nc ) among possibly surplus
children: Fnext (n) = f (n) + f (nc ).
construct direct-computation OSF domain, need classify states two
states s1 s2 class (1) location blank s1 s2
(2) identities tiles surrounding blank positions relative blank
s1 s2 . Therefore, need define 16(15141312) classes. Pre-computing storing
table operators classes computation memory overhead. Furthermore,
decide class given state belongs to, OSF need look identities tiles
157

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Gen Nodes
Time (ms)

IDA*
363,028,079
17,537

EPEIDA*
184,336,705
14,020

Ratio
1.97
1.25

Table 2: Comparison generated nodes time performance IDA* EPEIDA* 15Puzzle.

surrounding blanks, equivalent checking operators. conclude constructing
direct-computation OSF 15-puzzle domain MD heuristic impractical.
provided experimental results obtained full-checking OSF.
6.1.2 E XPERIMENTAL R ESULTS
Optimal solutions random instances 15-puzzle first found Korf (1985) using IDA*
MD heuristic. Korf graciously made code available public. code
(known highly optimized), look-up table pre-computed give heuristic value based
current location tile, operator chosen tile currently occupying proposed
new location blank. Note information exactly knowledge component
full-checking OSF described above. However, Korfs code exploit information avoid
generating currently unneeded nodes. Instead, generates children nodes uses
look-up tables heuristic calculation.
Table 2 presents results running Korfs IDA* code EPEIDA* 100 random
instances. observe factor 1.97 reduction number generated nodes. number
close asymptotic branching factor domain reverse moves eliminated,
reported 2.13 (Edelkamp & Korf, 1998). reduction number generated
nodes translates 1.25-fold improvement run-time, significant given well known
efficiency Korfs code. timing results obtained Dell Optiplex 760.
6.2 Hybrid OSF Pancake Puzzle
pancake puzzle (Dweighter, 1975) analogous waiter navigating busy restaurant
stack N pancakes. waiter wants sort pancakes ordered size. one
free hand, available operation lift top portion stack reverse it. state
permutation values 1...N . state N 1 children, k th successor formed
reversing order first k + 1 elements permutation (1 k < N ). example,
N = 4 children state (1, 2, 3, 4) (2, 1, 3, 4), (3, 2, 1, 4) (4, 3, 2, 1). However,
may safely consider two successors parent position complete reverse
pancakes (the latter ignored search nodes GAP heuristic described
used). Therefore, branching factor domain approximately equal number
pancakes minus two. Since states reachable start state, size state space
N !. number heuristics based pattern databases used puzzle (Zahavi,
Felner, Holte, & Schaeffer, 2008; Felner, Zahavi, Holte, Schaeffer, Sturtevant, & Zhang, 2011;
Yang, Culberson, Holte, Zahavi, & Felner, 2008), GAP heuristic discussed Helmert
significantly outperforms (Helmert, 2010).
158

fiE NHANCED PARTIAL E XPANSION A*

6

1

3

4

5

7

2

Figure 7: state Pancake Puzzle seven pancakes. operator affect gap one
location only.

describe GAP heuristic. Two integers b consecutive |a b| = 1.
given state, gap location j occurs pancakes location j j + 1 consecutive.
goal defined pancake 1 location 1 gaps. GAP heuristic
iterates state counts number gaps. Since operator reduce number
gaps one, heuristic admissible.
gather insight necessary construct OSF, consider example Figure 7.
seven pancakes, pancake 6 occupying location 1. Consider operator reverses first
five pancakes. note operator affect number gaps pancakes
reversed (i.e. gaps locations 1-5 pancakes 6, 1, 3, 4, 5). Indeed,
gaps adjacent extreme pancakes reversed (i.e. pancakes 6 5) affected.
case, consecutive pancakes 6 7 become adjacent, gap pancakes 5 7
ceases exist. Thus, looking three pancakes (in case, 5, 6, 7), know
number gaps (and hence GAP heuristic) decreased one f (nc ) = 0.
generally, operator reverses j pancakes affects gaps formed three
pancakes locations 1 (pancake P ), j (pancake X), j + 1 (pancake ). Three cases
possible:
1. X consecutive P are. case, one gap removed
heuristic value decreases one. corresponds f (nc ) = 0.
2. pancakes X, pancakes P, form form gap. case
heuristic value change. corresponds f (nc ) = 1.
3. pancakes X, form gap, pancakes P, do. case, new gap
introduced heuristic grows one. corresponds f (nc ) = 2.
Suppose need generate children n f (nc ) = 0. note done
without checking currently unneeded operators (i.e. operators f (nc ) > 0). this,
classify states based identity pancake location 1. state shown Figure 7
belongs class pancake 6 location 1. enable OSF compute operators
f (nc ) = 0 class on-the-fly maintaining following additional information
node main search. pancake, keep current location pancakes
consecutive (note two pancakes; example, pancakes
consecutive pancake 6 5 7 locations 5 6, respectively). Now, suppose n
pancake P location 1. Then, use information stored P
locate pancakes P 1 P + 1 check pancakes directly left pancakes.
example, P + 1s left neighbor pancake P + 2, reversing pancakes
159

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

#

IDA*

20
30
40
50
60
70

18,592
241,947
1,928,771
13,671,072
92,816,534
754,845,658

Generated Nodes
EPEIDA*
Total
Full-checking OSF
1,042
8,655
50,777
284,838
1,600,315
11,101,091

12
25
49
131
121
1,118

ratio

IDA*

Time (ms)
EPEIDA*

ratio

17.84
27.95
37.98
47.99
57.99
67.99

1.5
24.9
247
2,058
16,268
155,037

0.1
1.2
8.5
57
359
2,821

11.23
20.00
30.75
36.15
45.32
54.90

Table 3: Comparison generated nodes time performance IDA* EPEIDA*
Pancake Puzzle.

left P + 1 decrease GAP heuristic result f (nc ) = 0. Thus, construct
direct-computation OSF case f (nc ) = 0.
cannot construct direct-computation OSF cases f (nc ), since check
operators find operators resulting f (nc ) = 1 f (nc ) = 2. cases,
full-checking OSF constructed. OSF knowledge component. algorithmic
component simply checks operators applicable n and, operator, computes
resulting f (nc ) looking three affected pancakes described above. operator
currently needed, corresponding child node generated.
experimental results 100 random instances 20 70 pancakes given Table 3.
table, compare performance EPEIDA* IDA*, using GAP heuristic.
70 pancakes, EPEIDA* generated (the column titled Total) 68 times fewer nodes IDA*.
reflected running time (54-fold). best knowledge,
state-of-the-art results puzzle. Note versions tested domain, reduction
number generated nodes almost branching factor domain.
better understand behavior hybrid OSF domain, compare numbers
two columns EPEIDA* generated nodes. column left shows total number
generated nodes, column right shows many nodes generated using
full-checking OSF. comparison two columns reveals that, vast majority
expansions, operators f (nc ) = 0 currently needed, whereby EPEIDA*
applied direct-computation OSF.

7. OSFs Based Pattern Databases
Pattern Databases (PDBs) (Culberson & Schaeffer, 1998; Felner et al., 2004) powerful method
automatically building admissible memory-based heuristics based domain abstractions.
short background section, explain PDB-based full-checking direct-computation OSFs
constructed provide experimental results Rubiks cube domain CornersPDB heuristic.
7.1 Background
View state domain assignment values number domain variables (hereafter
variables). main idea PDBs abstract state space considering subset
160

fiE NHANCED PARTIAL E XPANSION A*

variables. concrete choice variables, abstraction formalized abstraction
mapping, denote immediately define. state original state,
abstract state (or pattern) (s) projection onto variables participate (or,
short, projection onto ).
PDB given constructed performing full breadth-first search abstract state
space abstract goal, i.e. (g), g goal state. Distances abstract states
calculated stored lookup table (PDB). values used throughout search
admissible heuristics states original state space. Formally, state s, PDB
contains distance abstract space (s) (g). heuristic value required
n, one simply looks PDB[(n)].
interesting variation PDBs instance-dependent pattern databases (IDPDBs) (Felner
& Adler, 2005; Zhou & Hansen, 2004; Silver, 2005). IDPDBs built lazily search
particularly effective domains abstract space big stored completely
memory. first, directed search pattern space performed goal pattern
start pattern (unlike regular PDBs complete breadth-first search performed).
patterns seen search saved PDBs. Then, main search real state space
begins. nodes generated, search pattern space continued lazily
PDB values found stored. Hierarchical search algorithms, Hierarchical A* (Holte,
Perez, Zimmer, & MacDonald, 1996) Switchback (Larsen, Burns, Ruml, & Holte, 2010), use
hierarchy abstract spaces create hierarchy PDBs, also created lazily similar manner.
use IDPDBs experiments Section 8.4.
present method constructing PDB-based OSF.
7.2 PDB-Based OSF
Let abstraction mapping given domain. Note operator original space
projection onto abstract operator modifies variables (s) way
original operator modifies variables s.
given , construct either full-checking direct-computation OSF. Intuitively,
knowledge components OSFs similar tables constructed SAPF
Sections 5.1 5.2. Recall that, SAPF, knowledge component OSFs consisted
eight tables. table corresponded one eight possible positions n relative goal.
table recorded operators applicable n resulting f (nc ). Depending kind
OSF, tables sorted either operators f (nc )-values. adopt method
construct OSF based follows. knowledge component OSF contains:
table abstract state a. table records abstract operators applicable
well resulting change f -value. denote abstract operator ,
result applying ac (= (a)) resulting change f -value f (ac ).
Depending whether building full-checking direct-computation OSF,
table sorted either abstract operators f (ac ).
call data structure employed knowledge component -PDB distinguish
-PDB sorted operators (used knowledge component full-checking OSF)
-PDB sorted f (ac ) (used knowledge component direct-computation OSF).
important note that:
161

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

1. -PDB include regular PDB based on. Rather, -PDBs additional
data structures enable PDB-based OSF. domains, trade-off
(1) building -PDB, affords using EPEA* (2) building additional PDB,
affords accurate heuristic. explore trade-off.
2. entry -PDB different entry regular PDB. entry regular PDB
contains one value distance given abstract state abstract goal. entry
-PDB contains table abstract operators f (ac )-values given abstract state.
algorithmic component full-checking PDB-based OSF operates follows.
operator applicable n, OSF (1) locates table (n) -PDB ordered operators
(2) looks table f (ac )-value projection onto . value
required f (nc ), nc included set currently needed children.
algorithmic component direct-computation OSF operates follows. given n
required f (nc ), OSF (1) locates table (n) -PDB ordered f (ac )values (2) looks table abstract operators f (ac )-value equal
required f (nc ). abstract operator, OSF determines set operators
original space correspond abstract operators. Thus, direct-computation OSF
constructed every abstract operator efficiently mapped corresponding operator(s) original space.
clear that, unless branching factor abstract space large, improvement
run-time performance afforded using direct-computation OSF rather fullchecking OSF cannot large. algorithmic components kinds OSF
need perform one lookup -PDBs. difference full-checking OSF
needs scan array f (ac )-values corresponding abstract operators,
usually large overhead.
next section, consider OSF Rubiks Cube Corner PDBs heuristic
simple example PDB-based OSF. involved example OSF based additive
PDBs (Felner et al., 2004; Yang et al., 2008) Multi-Agent Pathfinding domain (MAPF) (Standley, 2010; Sharon, Stern, Goldenberg, & Felner, 2011, 2012) given Section 8.
7.3 OSF Rubiks Cube
Rubiks Cube invented 1974 Erno Rubik Hungary. standard version consists
3 3 3 cube different colored stickers exposed squares sub-cubes,
cubies. 20 movable cubies 6 stable cubies center face. movable
cubies divided eight corner cubies, three faces each, twelve edge cubies,
two faces each. Corner cubies move among corner positions, edge cubies
move among edge positions.
one 6 faces cube rotated 90, 180, 270 degrees relative rest
cube. results 18 possible moves state. Since twisting face twice
row redundant, branching factor first move reduced 15. addition,
movements opposite faces independent. example, twisting left face right
face leads state performing moves opposite order. Pruning redundant
moves results search tree asymptotic branching factor 13.34847 (Korf, 1997).
162

fiE NHANCED PARTIAL E XPANSION A*

#

12
13
14
15

IDA*

EPEIDA*
ratio
IDA* EPEIDA*
Corner PDB
Generated Nodes - Thousands
Time (mm:ss)
45,800
3,441 13.31
0:05
0.01
434,671
32,610 13.32
0:53
0:15
3,170,960
237,343 13.37
5:31
1:32
100,813,966 7,579,073 13.30 175:25
47:16

ratio

4
3.53
3.68
3.71

Table 4: Comparison generated nodes time performance IDA* EPEIDA*
Rubiks Cube.

goal state, squares side cube color. puzzle
scrambled making number random moves, task restore cube original
unscrambled state. 4 1019 different reachable states.
classic abstraction mapping Rubiks cube PDB based corner cubies (Korf,
1997). abstraction 88, 179, 840 abstract states. branching factor abstract space
branching factor original space. fact, operator abstract space
trivially one-to-one-mapped operator original space.
experimented full-checking direct-computation OSFs. expected,
branching factor 18 large enough achieve run-time advantage using directcomputation OSF. fact, full-checking OSF marginally faster experiments.
results full-checking OSF given Table 4. line average 100
instances depth 12-15. reduction (ratio column) number nodes generated factor
13.3 (again close known effective branching factor), time improvement
3.7-fold. reason discrepancy constant time per node EPEIDA*
larger IDA* since includes time retrieve values -PDB.

8. Additive PDBs-Based OSF
section motivated Multi-Agent Pathfinding domain (MAPF), recently attracted significant attention researchers (Standley, 2010; Sharon et al., 2011, 2012).
recent workshop dedicated problem, way use additive PDBs (Felner et al., 2004; Yang
et al., 2008) solve instances problem presented (Goldenberg, Felner, Stern, & Schaeffer, 2012). develop additive PDBs-based OSF, generation surplus nodes
avoided solving instances MAPF.
keep section simple possible, leave description technically complicated
background details implementation OSF Appendices C D. current section
organized follows:
1. brief description MAPF (Section 8.1). Standley (2010) introduced two MAPF-specific
algorithmic enhancements A* make problem instances MAPF solvable within reasonable time resources. mention enhancements describe Appendix C
purpose self-contained.
163

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

2. definition additive PDBs explanation PDBs built MAPF
(Section 8.2).
3. description basic additive PDBs-based OSF MAPF (Section 8.3).
number performance enhancements OSF, described Appendix D.
4. report experimental results (Section 8.4).
8.1 Multi-Agent Pathfinding Domain (MAPF)
Consider following commonly used variant MAPF (Standley, 2010; Sharon et al., 2011,
2012). input consists of: (1) graph G(V, E) (2) k agents labeled a1 , a2 . . . ak . Every
agent ai coupled start goal vertices: si gi . initial time point = 0 every
agent ai located location si . successive time points, agent perform
move action neighboring location wait (i.e. stay idle) current location. operator
consists action (which may Wait) every agent. Every legal operator respect two
constraints:
1. vertex occupied one agent given time
2. x neighboring vertices, two different agents cannot simultaneously traverse
connecting edge opposite directions (from x x). However, agents
allowed follow other, i.e., agent ai could move x time agent
aj moves z.
task find sequence legal operators bring agent goal position
minimizing global cost function. variant problem, cost function summation
(over agents) number time steps required reach goal location. Therefore,
Move Wait actions cost 1, except case Wait action applied agents goal
location, case costs 0. exception case agent waits times goal
location moves: cost move + 1.
A*-based optimal solvers MAPF use Sum Individual Costs (SIC) heuristic,
optimal cost solving problem legal operator constraints ignored. first
use PDBs MAPF recently reported (Goldenberg et al., 2012). explain
applying abstraction-based heuristics challenging MAPF. Two techniques become
standard A*-based optimal MAPF solvers (Standley, 2010):8
Independence Detection (ID) tries reduce part MAPF problem instances complexity due agents interactions (i.e. legal operator constraints).
Operator Decomposition (OD) reduces number surplus nodes generated A*.
call resulting variant A* Operator Decomposition A* (ODA*).
ID ODA* described detail Appendix C. appendix, also introduce
Partial Expansion ODA* (PEODA*), hybrid ODA* PEA*.
8. recent papers Roger Helmert (2012) Bouzy (2013) stand far solving MAPF non-optimally
concerned.

164

fiE NHANCED PARTIAL E XPANSION A*

8.2 Additive PDBs MAPF
section, define additive PDBs show constructing PDBs MAPF challenging.
8.2.1 EFINITION DDITIVE PDB
Consider set abstractions = {1 , 2 , . . . , k } given domain. abstraction
, PDB, denoted P DBi built. arbitrary state s, P DBi [i (s)] stores distance
goal abstract
X space . set called additive if, state
original state space, sum
P DBi [i (s)] greater distance goal


original space. PDBs based additive abstractions called additive PDBs (Felner et al.,
2004; Yang et al., 2008).
Suppose built stored -PDB ordered f (ac ) abstraction
additive set abstractions . denote -PDBs -PDB1 , -PDB2 , . . . , -PDBk .
make two assumptions motivated MAPF:
1. variable participates least one abstractions .
2. Given node n operator results nc , f (nc ) given by:
f (nc ) =

k
X

f (i (nc )),

(1)

i=1

Intuitively, means operator may affect variables
-PDBs looked determine f (nc ) particular operator.
8.2.2 DDITIVE PDB MAPF
given node n, say agents a1 , a2 , . . . , conflict SIC heuristic
agents (i.e. agents ignored) perfect. Intuitively definition means that,
whatever optimal plan chosen individual agent, plans cannot executed simultaneously without agents colliding other. PDBs MAPF provide useful heuristic
information built agents conflict many nodes main
search. However, information known priori. solve problem case
abstractions consist two variables (i.e. locations two agents). call PDBs based
abstractions pairwise PDBs.
Recall ID used top EPEA* (the reader unfamiliar ID refer Appendix C point). idea solution consider merge actions ID
indication agents merged conflict many nodes main search. Namely,
whenever ID merges two agents group, use information build pairwise PDBs
later stages ID. build additive PDBs consist pairwise PDBs built way.
Suppose, example, instance 10 agents. Consider execution ID, ignoring
operations except operation merging two groups single group. Suppose ID
merged agents {1, 5}, merged agents {2, 8} merged two groups together, forming
group consisting agents {1, 2, 5, 8}. looking optimal path group,
use two 2-agent PDBs: one states projected onto agents {1, 5} using projections
165

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

f ([1 (n)])



f ([2 (n)])



f ([3 (n)])



0
3
5

11 = {11 , 12 }
12 = {13 , 14 }
13 = {15 }

0
1
3

21 = {21 }
22 = {22 }
23 = {23 }

0
1
4

31 = {31 }
32 = {32 }
33 = {33 , 34 }

Figure 8: Entries -PDBs given node n.
onto agents {2, 8}. experiments, used instance dependent pattern databases described
above.
following section, describe direct-computation OSF constructed additive PDBs
built described above. important note that, MAPF, operator affects agents
Equation 1 holds.
Note SIC trivial case PDBs, since heuristic based single-agent additive PDBs
exactly SIC heuristic. Therefore, OSF based additive abstractions develop
applicable SIC well.
8.3 Constructing Direct-Computation OSF Additive PDBs
Recall Section 5.2 one way build direct-computation OSF defining classification states. particular, built direct-computation OSF single PDB
Section 7.2, defined classes putting abstract state class own. contrast, set abstractions define classification states. Therefore, use
classes (this equivalent putting states one class). Instead, algorithmic component
OSF compute set operators required value f (nc ) on-the-fly
describe below.
example, suppose three additive abstractions: 1 , 2 , 3 . Figure 8 shows entries
corresponding -PDBs ordered f (ac ) might contain particular node n expanded.
Let ij denote j th abstract operator applicable (n). Figure 8 groups abstract operators
result f (ac ). groups denoted , i.e. ij j th group abstract
operators applicable (n). example, group 11 contains two abstract operators: 11
12 . 5, 3 4 abstract operators available projections n onto three
abstractions, respectively. means could 5 3 4 = 60 operators n
original space. However, may every combination legal operator original
space. example, could changes variables performed 14 changes
variables performed 21 cannot applied time according rules
domain (e.g. two agents cannot occupy location MAPF).
Suppose need compute set operators applicable n f (nc ) = 8. According Equation 1, need find ways choose one abstract operator three
projections n, sum corresponding f (ac )-values would equal eight. One
choice 13 , 22 , 33 (these abstract operators f (ac )-values shown Figure 8
bold). Furthermore, could choose one operator groups 12 , 22 , 33 .
general, k abstractions, find operators required f (nc ) finding ways
choose one abstract operator abstraction, sum corresponding f (ac )values equal required f (nc ). note combinatorial problem exponential number abstractions. Since problem solved every expansion,
166

fiE NHANCED PARTIAL E XPANSION A*

Procedure 3 Algorithmic component additive PDBs-based OSF MAPF.
Variables:
k number abstractions
current abstraction
C sum f (ac )-values selected abstractions 1, 2, . . . , 1
sum sum f (ac )-values selected abstractions 1, 2, . . . ,
nOpsi number abstract operators applicable (n)
opi current choice abstract operator (n)
op current choice abstract operators abstractions 1, 2, . . . ,
OP set ops result required f (nc ). ops may illegal
N set currently needed nodes returned OSF
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

FindAbsOpSets(i, C, op)
j 1 nOpsi
Set opi ij
Set sum C + f (ij [i (n)])
sum > f (nc )
Set Fnext (n) min(Fnext (n), sum)
return
== k
sum == f (nc ) append op OP
continue
Call FindAbsOpSets(i + 1, sum, op)
OSF(f (nc ))
Set N , OP Fnext (n)
Call FindAbsOpSets(1, 0, )
op OP
op legal
Append nc corresponding op N
return N, Fnext (n)

critical problem solved efficiently. present simple basic algorithm solving
problem Procedure 3. Enhancements simple algorithm presented Appendix D.
addition finding operators required f (nc ), algorithm computes next stored
value n, Fnext (n). Thus, Procedure 3 full-fledged direct-computation OSF.
Procedure 3, main part OSF starts line 12. First, set currently needed
operators, N , initialized empty next stored value, Fnext (n) initialized infinity.
also initialize empty set OP , whose meaning explained below. call
FindAbsOpSets (which stands find abstract operator sets) procedure made. procedure
takes three parameters:
1. current abstraction,
2. C sum f (ac )s corresponding abstract operators chosen abstractions 1
though 1,
167

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

3. op current choice abstract operators abstractions 1, 2, . . . , i.
produces two results:
1. OP , set choices abstract operators, one per abstraction, result required
f (nc )
2. Fnext (n).
OSF computes N filtering illegal operators OP returns (lines 15-end).
walk FindAbsOpSets, implements simple recursive algorithm.
given level recursion begins, abstract operator chosen abstractions 1, 2, . . . ,
1. operators stored op. sum f (ac )s corresponding abstract operators
stored C. two cases:
1. current abstraction k (i.e. = k). base recursion. case,
look abstract operators current abstraction f (ac ) complements C
required f (nc ) (C + f (ac ) denoted sum Procedure 3). chosen
operator, tuple op appended operator stored OP (lines 8-10).
2. current abstraction k (i.e. < k). case, look abstract operators
current abstraction sum = C + f (ac ) would exceed required f (nc )
invoke next level recursion (line 11).
addition, whenever abstract operator results sum = C + f (ac ) exceeds
required f (nc ) encountered, update Fnext (n) look following abstractions (lines 5-7).
Appendix D, present four enhancements basic algorithm described.
8.4 Experimental Results
Tables 5 6 compare node time performance, respectively, six A*-variants optimally
solving MAPF. EPEA*, two variants shown: one using SIC heuristic using
additive PDBs-based OSF described above. -PDBs constructed on-the-fly.
is, node n expanded first time, entries -PDBs corresponding
abstractions n computed existed already.
total 1,000 instances. instances, agents placed onto four-connected
8x8 grid obstacles. varied number agents. algorithmic variants run
ID framework described footnote.9 variants given two minutes two
gigabytes memory per instance. results bucketed according number agents (k,
9. Since ID framework produce different results due reasons related performance properties different A* variants MAPF (see Appendix C), compared variants using following
approach (Sharon et al., 2011). given instance, first ran ODA* ID framework saved
largest group inter-dependent agents. Then, original instance substituted another instance,
agents largest group discarded. variants compared instances without use
ID.

168

fiE NHANCED PARTIAL E XPANSION A*

Unique Nodes Generated, 103
k Ins
A* ODA* PEA* PEODA* EPEA* EPEA* abstractions
Instances solved A* PEA* within two minutes 2GB memory
2-6 794
46.35
1.27 0.08
0.38
0.08
0.06
7-8 34 1,261.04
3.26 0.11
0.88
0.10
0.05
9-10
0
n/a
n/a
n/a
n/a
n/a
n/a
Instances solved neither A* PEA* within two minutes 2GB memory
2-6
1
n/a 335.34
n/a
105.14
9.94
9.31
7-8 25
n/a 219.11
n/a
67.04
7.82
4.41
9-10 13
n/a 705.76
n/a
211.54 17.57
10.01

Table 5: Comparison nodes performance six algorithms Multi-Agent Pathfinding.
Run-Time, ms
k Ins
A* ODA* PEA* PEODA* EPEA* EPEA* abstractions
Instances solved A* PEA* within two minutes 2GB memory
2-6 794
647
5
606
5
2
33
7-8 34 22,440
14 14,886
12
2
100
9-10
0
n/a
n/a
n/a
n/a
n/a
n/a
Instances solved neither A* PEA* within two minutes 2GB memory
2-6
1
n/a 2,153
n/a
1,803
278
354
7-8 25
n/a 1,637
n/a
1,312
335
232
9-10 13
n/a 16,660
n/a
8,846 3,062
1,089

Table 6: Comparison time performance six algorithms Multi-Agent Pathfinding.
shown first column Tables 5 6) results instances falling bucket
averaged.
Since basic A* PEA* perform much worse variants, split tables
two halves. upper part table shows results instances solved within
allowed resources A* PEA*. see EPEA* generates four orders magnitude
less nodes three orders magnitude faster A*. Also, generates order magnitude
less nodes seven times faster ODA*. EPEA* additive PDBs-based OSF
generates fewest number nodes among variants, fastest terms time.
because, simple instances, overhead building (-)PDBs pay off.
lower part table shows results instances solved either A*
PEA*, solved variants. following trends observed. Applying partial
expansion top ODA* results three-fold reduction number generated nodes
two times speed-up ODA*. However, EPEA* generates yet another order magnitude less
nodes four times faster. EPEA* additive PDBs-based OSF clear winner
hard instances, running three times faster EPEA* based SIC heuristic.
next two sections theoretical study PEA* EPEA*.

9. Size OPEN: Limitation PEA* EPEA*
section, show that, although purpose PEA* make OPEN smaller,
sometimes exactly opposite effect.
169

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

b s2

g2

s1

g1

Figure 9: instance MAPF, PEA*/EPEA* close even start node.

Figure 10: Open (checkerboard) closed (gray) nodes 16 node expansions A* (left)
PEA*/EPEA* (right).

PEA*/EPEA* expands node n, puts OPEN currently needed children
n. n possibly surplus children, n put back OPEN updated stored
value. contrast A*, always puts n CLOSED expansion. may
result PEA*/EPEA* maintaining much larger OPEN A*. Note OPEN frequently
implemented heap heap operations become slower number elements stored
heap grows. Therefore, time performance may suffer considerably size OPEN
increases.
Consider MAPF example Figure 9. instance, two agents start locations (s1 , s2 )
need get locations (g1 , g2 ). SIC heuristic start state 8, optimal
solution length 9 (namely, one agent wait agent pass). However,
highest-cost (i.e. agents (a, b)) child start node f -value 12. Therefore,
A* closes expanded nodes, PEA*/EPEA* never close nodes, even
start node.
Furthermore, possible node n closed PEA*/EPEA* even though
neighbors n surely surplus. Figure 10 (left) shows instance singleagent pathfinding problem four-connected grid, shortest path needed cell
cell G. Black cells obstacles. assume Manhattan distance heuristic. Note
shortest path length 10 16 gray cells f -value 8. Thus, A* starts expanding
states f = 8. 16 expansions states closed, 8 states around
(marked checkerboard) OPEN list, f = 10.
Consider operation PEA*/EPEA* example. PEA*/EPEA* expands
gray nodes close child f = 10. example,
expanding state 10, operators North West f (nc ) = 0, operators East South
170

fiE NHANCED PARTIAL E XPANSION A*

f (nc ) = 2. cell east 10 cell 1 already generated lower gvalue f = 8. However, PEA*/EPEA* perform duplicate detection currently
unneeded nodes. Thus, cell 10 re-inserted OPEN list F = 10, received cell 1.
Consequently, expanding gray cells first time, PEA*/EPEA* 16 OPEN nodes
shown Figure 10 (right) CLOSED nodes. case PEA*, problem fixed
expense run-time overhead performing hash look currently unneeded
children discarding (note fix address large OPEN problem shown
MAPF example above). case EPEA*, duplicate detection impossible, since
EPEA* actually generate currently unneeded children.
summarize, A* stores perimeter generated states OPEN list,
PEA*/EPEA*, worst case, stores OPEN list states ever generated search. polynomial domains (defined footnote10 ), considerably affects
time performance PEA*/EPEA*. exponential domains, factor lesser importance,
since, domains, A* stores nodes OPEN well.
observe EPEA* slower A* experiments besides experiments
SAPF (not shown), EPEA* slightly slower A*.

10. Performance analysis
purpose section analytically estimate time performance EPEA*/EPEIDA*
regular A*/IDA* compare. this, identify basic operations within
algorithms give notation time costs operations. use notation give
precise conditions obtaining time speed-up using enhanced partial expansion variant
A*/IDA*.
operations algorithms consideration listed Table 7. operation,
denote applicability given algorithm putting + respective column.
operation applicable full-checking OSF direct-computation OSF used,
denote fact +(FC) +(DC), respectively. operations appear order
appear Procedures 1 2.11 introduce little notation possible, group
operations together assign notation total time cost operations
group shown Table 8. Note time costs averages node expansions
generations, whichever applicable particular group operations. skip word
average text brevity. explain operations groups on-the-fly
used analysis. Analysis EPEIDA* simpler analysis EPEA*. Therefore
start analysis EPEIDA*.
10.1 Analysis EPEIDA*
simplicity, restrict analysis last iteration IDA*. Let X number nodes
expanded iteration. Let b average branching factor domain. approximate
10. Polynomial domains domains number distinct states depths breadth-first search tree
starting given state (dm ), domain-specific constant. SAPF classical example
polynomial domain. Exponential domains domains number distinct states depths
breadth-first search tree starting given state (bd ), b average branching factor domain.
15-puzzle, Rubiks cube pancake puzzle examples exponential domains.
11. Hence heuristic computation appears twice: operation 3 A*, operation 9 IDA*.

171

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

#
1
2
3
4
5
6
7
8
9
10

Operation

Applicability
A* PEA* EPEA* IDA* EPEIDA*
Remove OPEN
+
+
+
Recursive call IDA*
+
+
Compute nodes heuristic (IDA*) +
+
Check threshold condition IDA* +
+
Compute child nodes heuristic
+(FC)
+(FC)
node generated
Check one operator
+(FC)
+(FC)
using full-checking OSF
Check one operator
+(DC)
+(DC)
using direct-computation OSF
Apply operator
+
+
+
+
+
(in A*, includes copying parent)
Compute child nodes heuristic
+
+
node generated
Insert one child OPEN
+
+
+
-

Table 7: Summary operations performed five algorithms consideration. plus sign
stands operation performed given algorithm, minus sign stands
operation applicable context given algorithm.
Notation
te
tr
tof
tod
tm
t0m

Operations
1
8, 2, 3, 4
6
7
8, 9, 10
8, 10

Comments
different cost A* EPEA*,
so, EPEA*, use t0e
case EPEA*/EPEIDA*, also calls operation 5.
A*
EPEA*

Table 8: Notation time costs groups operations. operations denoted
numbers introduced Table 7.

number nodes generated IDA* bX. Since EPEIDA* generates currently needed
children (Section 4), expands nodes generates. exception rule
solution found. case, nodes generated upper levels
depth-first tree may remain unexpanded. Therefore, EPEIDA* generates X + (b 1)d nodes.
Since (b 1)d usually small compared X, ignore quantity following
analysis. allow us express ratio run-time costs IDA* EPEIDA*
terms parameters domain implementation without usage X.
operator available given node n, IDA* generates child nc applying
operator (operation 8), makes recursive call IDA* (operation 2), computes h(nc ) (operation
3) checks threshold condition (operation 4). denote total time cost operations
172

fiE NHANCED PARTIAL E XPANSION A*

tr . Since operations performed IDA* generated node, run-time cost
IDA* is:
bXtr .
(2)
10.1.1 NALYSIS EPEIDA* F ULL -C HECKING OSF
EPEIDA* full-checking OSF, node n expanded, cost tr spent
currently needed operators applicable n. operators checked (operation 6),
children generated. denoting time cost checking operator full-checking
OSF tof , run-time cost EPEIDA* given by:
bXtof + Xtr .

(3)

ratio run-time costs IDA* EPEIDA* expressed by:
btr
.
btof + tr

(4)

EPEIDA* faster IDA* ratio greater one, i.e.
tof < tr

b1
.
b

(5)

10.1.2 NALYSIS EPEIDA* IRECT-C OMPUTATION OSF
EPEIDA* direct-computation OSF checks operators leading X expanded
nodes. denoting time cost checking operator direct-computation OSF (operation
7) tod , run-time cost EPEIDA* is:
X(tod + tr ).

(6)

ratio run-time costs IDA* EPEIDA* expressed by:
b

tr
.
tod + tr

(7)

EPEIDA* faster IDA* ratio greater one, i.e.
tod < tr (b 1).

(8)

10.1.3 NALYSIS EPEIDA* H YBRID OSF
Recall hybrid OSF behave either direct-computation full-checking OSF
different expansions depending required f (nc ). example, OSF pancake
puzzle introduced Section 6.2 direct-computation-OSF nodes f (nc ) = 0
needed full-checking-OSF nodes f (nc ) = 1 f (nc ) = 2 needed.
Let G0 X number nodes whose generation direct-computation OSF used. Also,
let E 0 X number nodes whose expansion direct-computation OSF used. Note
cannot easily express G0 terms E 0 (i.e. would wrong state G0 = 0 ), since
direct-computation OSF generated currently needed children n. run-time cost
EPEIDA* given
G0 tod + b(X E 0 )tof + Xtr .
(9)
173

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

ratio run-time costs IDA* EPEIDA* expressed by:
G0 tod

bXtr
.
+ b(X E 0 )tof + Xtr

(10)

G0 E 0 known need use model allows detailed analysis
estimate them. Fortunately, suitable model reported (Zahavi, Felner, Burch, & Holte,
2010). Since using model estimate G0 E 0 technically involved provide
immediate insight efficiency EPEA*, defer analysis Appendix B.
10.2 Analysis EPEA*
analyze time performance EPEA*, need introduce two auxiliary parameters
characterize performance EPEA*. Let average number times given node
expanded (each time different stored value). Let average number currently
needed children given node expansion. particular, = 1 = b (b
average branching factor), EPEA* equivalent A*. Note parameters domain,
heuristic problem instance-dependent.
Suppose A* performs X expansions bX generations. Since EPEA* expands node
average times, perform total X expansions. Since EPEA* performs average
generations per expansion, perform total X generations.
Let te denote time cost getting least cost node OPEN (operation 1).
operator applicable n, A* generates child nc (operation 8), computes h(nc ) (operation 9)
inserts nc OPEN (operation 10). denote total cost three operations tm .
run-time cost regular A* given by:
Xte + bXtm .

(11)

10.2.1 NALYSIS EPEA* F ULL -C HECKING OSF
Recall Section 5.2 one trade memory speed imitating direct-computation OSF
even OSF available. following analysis pure version EPEA*
full-checking OSF trade-off used.
EPEA* performs X expansions, time checking b operators, followed generating
currently needed children nodes. Denote time cost expanding node EPEA* t0e . Note
te t0e may different problem instance, since size OPEN differs
expansions A* EPEA*. Similarly, denote total time cost generating child node
nc , computing h(nc ) putting nc OPEN EPEA* t0m , might differ tm .
run-time cost EPEA* given by:
Xt0e + bXtof + Xt0m .

(12)

ratio run-time costs regular A* EPEA* expressed by:


t0e

te + btm
.
+ btof + t0m

(13)

EPEA* faster regular A* ratio greater one, i.e.
tof <

te + btm (t0e + t0m )
.
b
174

(14)

fiE NHANCED PARTIAL E XPANSION A*

10.2.2 NALYSIS EPEA* IRECT-C OMPUTATION OSF
direct-computation OSF, EPEA* performs X expansions, time checking operators
generating currently needed children nodes. run-time cost EPEA* given by:
Xt0e + X(tod + t0m ).

(15)

ratio run-time costs regular A* EPEA* expressed by:


t0e

te + btm
.
+ (tod + t0m )

(16)

EPEA* faster regular A* ratio greater one, i.e.
tod <

btm t0e + te
t0m .


(17)

10.3 Conclusion Performance Analysis
analysis see whether EPEA*/EPEIDA* faster slower A*/IDA*
depends on:
1. average branching factor b domain,
2. efficiency implementation A*/IDA* (expressed te , tr tm ),
3. efficiency OSF used (expressed tof tod ),
4. EPEA*, domain heuristic-dependent parameters .
obtain experimental evidence analysis section, one would find way
reliably estimate quantities Table 8. However, estimation meets two challenges:
1. operations discussion fine granularity. time performance
operations cannot measured directly, measured sampling procedure.
2. EPEA*, estimating parameters presents additional challenge.
3. time performance operations discussion constant throughout
search. example, cost inserting node OPEN depends current size
OPEN. Also, domains nodes variable branching factors.
latter observation opens possibility algorithm that, depending current state
search, switches A*/IDA* EPEA*/EPEIDA*.

11. EPEA* Inconsistent Heuristics
heuristic h called consistent f -value decrease along path, i.e. f (nc ) f (n).
Otherwise, h called inconsistent. far, assumed consistent heuristic. section,
(1) show changes need made EPEA* (Procedure 1 Section 2.2)
inconsistent heuristic h used (2) point one make choice using EPEA*
175

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Procedure 4 A*, PEA* EPEA* inconsistent heuristic.
1: Generate start node ns
2: Compute h(ns ) set F (ns ) f (ns ) h(ns )
3: Put ns OPEN
4: OPEN empty
5:
Get n lowest F (n) OPEN
6:
n goal exit
// optimal solution found!
7:
A* PEA*: set N set children n initialize Fnext (n)
8:
EPEA*:
9:
f (n) = F (n)
10:
Set (N, Fnext (n)) OSFe (n).
11:
else
12:
Set (N, Fnext (n)) OSF (n).
13:
nc N
14:
Compute h(nc ), set g(nc ) g(n) + cost(n, nc ) f (nc ) g(nc ) + h(nc )
15:
PEA*:
16:
f (nc ) 6= F (n)
17:
f (nc ) > F (n)
18:
Set Fnext (n) min(Fnext (n), f (nc ))
19:
f (nc ) > F (n) F (n) 6= f (n)
20:
Discard nc
21:
continue
// next nc
22:
Check duplicates
23:
Set F (nc ) f (nc ) put nc OPEN
24:
Fnext (n) =
25:
Put n CLOSED
// A*, always done
26:
else
27:
Set F (n) Fnext (n) re-insert n OPEN
// Collapse
28: exit
// solution.
using heuristic value propagation techniques (such bidirectional pathmax (BPMX), Zahavi,
Felner, Schaeffer, & Sturtevant, 2007) inconsistent heuristics. deep experimental study
EPEA* inconsistent heuristics including trade-off due aforementioned choice
beyond scope paper.
11.1 Changes PEA* EPEA*
start discussing PEA*, since PEA* makes choice nodes insert OPEN
explicitly (line 12 Procedure 1).
heuristic inconsistent, possible children nc n f (nc ) <
f (n). children nodes surplus PEA* need insert OPEN
first expansion n. Thus, first expansion n definition currently needed
node changed include children f (nc ) F (n).
demonstrated Figure 11. node expanded, children (x, y, z, w)
generated. However, children f -values exceeding 3 (x y) currently
176

fiE NHANCED PARTIAL E XPANSION A*

Figure 11: Example PEA* inconsistent heuristic. first expansions node
shown. Even children nodes whose f -value less f (a) generated.

8
BPMX
6

10
4

BPMX

2

10

9
6

5
4
8
6

7

7
2

6

Figure 12: Two examples value propagation BPMX.

needed. inserted OPEN. children possibly surplus. collapsed
back a, gets new stored value F (a) = 4. Following this, re-inserted OPEN.
on, treated consistent heuristic case.
pseudo-code A*, PEA* EPEA* case inconsistent heuristic shown
Procedure 4. Compared Procedure 1 Section 2.2, PEA* handles inconsistent heuristic
performing check line 19 discarding nc .
EPEA*, case inconsistent heuristic also handled checking whether n
expanded first time (line 9). first expansion n, OSF returns set
children f (nc ) F (n) used. call extended OSF denote OSFe (line 10).
Note similar OSF used EPEIDA* (Section 4) well. expansions n,
change OSF needed (line 12).
11.2 Trade-Off
inconsistent heuristic used, heuristic value propagation techniques applied take
advantage regions state space high heuristic values. One effective
techniques bidirectional pathmax (BPMX) (Zahavi et al., 2007). example BPMXs
operation shown Figure 12 (right). Assuming unit edge costs, h-value left grandchild
(10) propagated search tree, increasing heuristic estimates states
neighborhood except gray node. general, two arbitrary states a, b V , heuristic
estimate h(a, g) updated max {h(a, g), h(b, g) d(a, b)} (shown Figure 12 (left))
BPMX uses rule directions search tree.
177

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

EPEA* used, possibly surplus children n generated and, therefore,
propagation values children n available. introduces interesting tradeoff:
EPEA* saves memory time generating surplus nodes,
opportunity increase quality heuristic estimates using non-monotonicity
f missed.
separate study might dedicated trade-off.12

12. Conclusions Future Work
presented Enhanced Partial Expansion A* (EPEA*), novel variant A*
avoids generating surplus nodes. enabled using priori domain- heuristic-specific
knowledge form Operator Selection Function (OSF) compute list operators
lead children needed f -cost without actually generating children
node expanded. studied several kinds OSF, including OSFs based (additive)
pattern databases. extended principles EPEA* IDA* resulting Enhanced Partial
Expansion IDA* (EPEIDA*). Experimental results 15-puzzle, pancake puzzle,
Rubiks cube multi-agent pathfinding show EPEA*/EPEIDA* achieves state-of-the-art
run-time performance. Furthermore, EPEA* fully maintains memory savings offered PEA*.
EPEA* effective domains heuristics meet following criteria:
1. domain possesses large branching factor. large branching factor indicator
A* may generate large number surplus nodes. EPEA* save overhead.
2. set possible f -values children given node small. means EPEA*
re-expand node many times.
3. operators classified according f (nc ) value, operators
needed class applied without need check operators node expanded. words, direct-computation OSF available.
conditions met specific domain heuristic interest,
thorough assessment, experimenting prototype implementation, needed.
addition, explained possibility poor performance EPEA* polynomial
domains.
Future work seek applications EPEA* domains heuristics. particular,
would interesting see whether EPEA* implemented best heuristics
used domain-independent planning. seems EPEA* easily implemented
12. Related trade-off following observation (Felner et al., 2011, p. 22). studied following trade-off
context applying BPMX IDA*. propagation children parent results cut-off, IDA*
either backtrack immediately (this option called lazy propagation) look children hopes obtain
even higher value parent obtain cut-offs future. concluded backtracking immediately
preferable domains studied. However, cannot conclude one always use
EPEA* forgo propagation values children parents, since IDA* lazy BPMX propagation
perform effective propagation backtracking.

178

fiE NHANCED PARTIAL E XPANSION A*

STRIPS (Fikes & Nilsson, 1971) variable abstraction heuristics (Edelkamp, 2001). However, remains see whether EPEA* applied merge-and-shrink abstractions (Helmert,
Haslum, & Hoffmann, 2007) landmarks (Karpas & Domshlak, 2009).
promising direction future work implement OSF using symbolic representation,
BDDs (Binary Decision Diagrams). Jensen, Bryant, Veloso (2002) proposed method
group state transitions effect f -value. grouping state transitions
referred improvement partitioning used avoid generating node f -values
larger given upper bound (Jensen, Hansen, Richards, & Zhou, 2006). Thus, believe
may possible create OSF similar method.
Another interesting direction see EPEA* used non-optimal searches.
searches, notion surplus node needs defined based required quality
solution.
Furthermore, touched upon topic EPEA* inconsistent heuristics pointed
trade-off exists using EPEA* leveraging full power value propagation
techniques. experimental study trade-off remains subject future work.

13. Acknowledgements
research supported Israeli Science Foundation (ISF) grant 305/09 Ariel Felner
Natural Sciences Engineering Research Council Canada grant Jonathan Schaeffer.
Acknowledgements due Kobi Shmerkovich, Tal Beja, Idan Morad Shaked Zimmermann performing experiments paper.

Appendix A. Glossary EPEA* Terms
Table 9 lists terms introduced paper alphabetical order. provides brief definition
term reference place term defined paper.

Term

Brief definition

Section(s)

Algorithmic component OSF

algorithm OSF employs generate currently
needed nodes compute next stored value node
expanded.

3.2

CFN

See collapsing frontier nodes.

2.1

Checking operator

Deciding whether apply available operator generate
child node.

3.1

Collapse action

operation substituting nodes search frontier
common ancestor n, increasing cost n. See
stored value.

2.1

Collapsing frontier nodes (CFN)

technique used number algorithms. See collapse
action.

2.1

179

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Currently needed
child node

node A*/IDA* generate current expansion guarantee optimality. definition differs A*
IDA*.

2.2 4

Currently needed
operator

operator results currently needed child node.

2.2 4

Currently
needed
node

child node currently needed.

2.2 4

Currently
unneeded operator

operator currently needed.

2.2 4

Directcomputation
OSF

OSF need check operators generate
currently needed nodes.

5

Full-checking
OSF

OSF needs check operators generate
currently needed nodes.

5

Hybrid OSF

OSF behaves either direct-computation fullchecking OSF depending needed change f -value
(f (nc )).

5

Knowledge component OSF

domain- heuristic-specific data structure OSF
stores. algorithmic component uses knowledge component generate currently needed nodes compute
next stored value node expanded.

3.2

Operator
selection
function (OSF)

function uses domain- heuristic-specific knowledge
generate currently needed nodes compute
next stored value node expanded.

3.2

OSF

See operator selection function.

3.2

Possibly surplus
child node

child node provably useful.

2.2

Provably useful
child node

child node proved useful. child node nc
provably useful f (nc ) F (n).

2.2

Pure OSF

Non-hybrid OSF.

5

SAPF

single-agent pathfinding domain.

3.2

Static value

regular g + h cost node, denoted f (n).

2.1

Stored value

cost node obtained collapse action denoted
F (n).

2.1

unchild

180

fiE NHANCED PARTIAL E XPANSION A*

Surplus node

node whose static value greater cost optimal
solution.

1

Useful node

node node surplus.

1

Table 9: terminology used paper.

Appendix B. Analysis Hybrid OSF
start describing model aims predict number nodes expanded IDA* (Zahavi
et al., 2010) (ZFBH).13 Later section, show model used
estimate quantities G0 E 0 introduced Section 10.1.3. model uses assumption
unit cost operators. analysis make assumption well.
start result puts study hybrid OSF general framework
pancake puzzle example.
Lemma 1. Let H natural number hybrid OSF direct nodes f (nc )
H needed. Then, whenever node n f (n) H expanded, threshold
current iteration, hybrid OSF direct.
Proof. Suppose n f (n) H expanded. Since IDA* nodes
f (nc ) needed, need generate nodes f (nc ) = f (nc ) f (n)
f (nc ) + H H. nodes OSF direct.
Remark 1. pancake puzzle, H zero.
Remark 2. chose focus simple model two ranges values f (nc ). results
section generalized model number ranges designated H1 , H2 , . . . , Hm .
B.1 Model ZFBH.
ZFBH define Ni (s, d, v) number nodes IDA* generate level heuristic
value equal v start state IDA*s iteration threshold. give recursive
formula approximate quantity follows:
d(i1)

Ni (s, d, v) =

X

Ni1 (s, d, vp ) bvp p(v|vp ).

(18)

vp =0

equation, p(v|vp ) probability child node heuristic value v given
parent heuristic value vp , bvp average branching factor nodes whose heuristic value
vp . quantities obtained sampling state space (we refer reader ZFBH
details sampling process). explain reasoning behind equation. Since
parent node located level 1 depth-search tree, could expanded
13. use basic one-step model ZFBH.

181

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

heuristic less equal (i 1) (otherwise, threshold condition would
failed). heuristic value vp , Ni1 (s, d, vp ) parent nodes, bvp
children. However, children heuristic value v interest. Since, parents
heuristic value fixed vp , multiply conditional probability.
total number nodes expanded iteration IDA* approximated by:
X

X
di
X

Ni (s, d, v).

(19)

i=0 v=0

first summation runs depths current iterations search tree. given depth i,
nodes heuristic value less equal satisfy threshold condition.
second summation runs heuristic values. depth heuristic
value v fixed, Ni (s, d, v), given Equation 18, approximates number nodes expanded
IDA*.
B.2 Estimating E 0 .
Lemma 1, hybrid OSF direct f (n) H. Subtracting level number
f (n), get equivalent condition:
v (d i) H.

(20)

Therefore, modify Equation 19 estimate E 0 :
E0


X

di
X

Ni (s, d, v).

(21)

i=0 v=(di)H

B.3 Estimating G0 .
Let G0i (s, d, v) denote number nodes EPEIDA* generate using direct-computation
OSF level heuristic value equal v start state IDA*s iteration
threshold. approximate G0i (s, d, v) restricting summation Equation 18
parent nodes expanded direct-computation OSF. Equation 20, condition is:
vp [d (i 1)] H. have:
d(i1)

G0

(s, d, v)

X

=

Ni1 (s, d, vp ) bvp p(v|vp ).

(22)

vp =[d(i1)]H

estimate G0 as:
0

G

X
di
X

G0 (s, d, v).

(23)

i=0 v=0

G0 E 0 estimated, Equation 10 gives time speed-up EPEIDA* IDA*.
interest note also estimate number nodes whose generation EPEIDA*
save compared IDA* particular level i:
+
X

Ni (s, d, v).

v=di+1

182

(24)

fiE NHANCED PARTIAL E XPANSION A*

summation, v starts + 1 nodes heuristic values range
[0 . . . i] expanded level i.

Appendix C. Algorithmic Enhancements Solving MAPF
section describe three MAPF-specific algorithmic enhancements A*. Two them,
Independence Detection (ID) Operator Decomposition A* (ODA*) due Standley
(2010). Partial Expansion ODA* (PEODA*) new hybrid ODA* PEA*.
C.1 Independence Detection (ID)
Two groups agents called independent optimal solution group
two solutions conflict. basic idea Independence Detection (ID) divide
agents independent groups. Initially agent placed group. Shortest paths
found group separately. resulting paths groups simultaneously performed
conflict occurs two (or more) groups. Then, agents conflicting groups
unified new group, i.e. two groups merged. Whenever new group k 1 agents
formed, new k-agent problem solved optimally A*-based search. process
repeated conflicts groups occur. Standley observed since problem
exponential k, A*-search largest group dominates running time solving
entire problem, searches involve smaller groups (for details ID, see Standley,
2010).
Note ID combined optimal MAPF solver. paper Standley (2010),
ID combined ODA*. approach combines ID EPEA* OSF based additive abstractions. fact, use feedback received ID determine variables
included additive abstractions explained below.
C.2 Operator Decomposition (OD)
Standley (2010) introduced Operator Decomposition (OD) reduces number surplus
nodes generated MAPF follows. OD introduces intermediate nodes regular states
A* search follows. Agents assigned arbitrary (but fixed) order. regular A*
state expanded, OD considers moves first agent, results generating
called intermediate nodes. nodes, moves second agent considered
intermediate nodes generated. operator applied last agent, regular node
generated. solution found, intermediate nodes OPEN developed
regular nodes, number surplus nodes significantly reduced. variant A*
referred ODA*. ODA* still generate surplus nodes, intermediate regular.
contrast, EPEA* never generates surplus nodes.
C.3 Partial Expansion ODA*
introduce Partial Expansion ODA* (PEODA*), hybrid ODA* PEA*. variant
operates similarly ODA* one exception. PEODA* generates intermediate children nc
n, puts nc OPEN f (nc ) = F (na ), na standard node ancestor nc .
particular, n standard node, na n.
183

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Appendix D. Enhancements OSF Based Additive PDBs
section, present four enhancements OSF described Section 8.3. enhancement presented separate subsection.
D.1 Avoiding Linear Search = k
obvious enhancement FindAbsOpSets that, last level recursion (i = k),
use fact -PDBk ordered f (ac ) quickly locate (e.g. binary search)
f (ac )-values complete sum required f (nc ).
D.2 Obtaining Cut-offs Line 5
note possible obtain stronger condition cut-off line 5 Procedure 3.
this, first expansion n, compute store n OPEN array k (the number
abstractions) elements:
smallSums[i] =

k
X

f (l1 [l (n)])

l=i+1

Intuitively, smallSums[i] sum smallest entries -PDBs n abstractions
+ 1 k. note cut-off performed whenever sum + smallSums[i] >
f (nc ) holds. Intuitively, means sum provably large, since even choosing smallest entries remaining abstractions would result exceeding required f (nc ). Whenever
cut-off occurs, Fnext (n) set minimum current value Fnext (n)
sum + smallSums[i].
D.3 Obtaining Additional Cut-off
obtain cut-off sum provably large, obtain cut-off sum
provably small. this, first expansion n, compute store n OPEN
array k (the number abstractions) elements:
largeSums[i] =

k
X

f (l,nOpsl [l (n)])

l=i+1

cut-off performed whenever sum + largeSums[i] < f (nc ) holds.
D.4 Per-Group Search
already observed that, choice f (ac )-value abstractions
results required f (nc ) found, take one abstract operator groups
resulting f (ac )-values. Therefore, change loop line 2 go
possible groups instead possible abstract operators. example, two choices groups
operators result f (nc ) = 8:
{(12 , 22 , 33 ), (13 , 23 , 31 )}.
184

fiE NHANCED PARTIAL E XPANSION A*

FindAbsOpSets returns choices groups, one per abstractions result required f (nc ) (line 14), post-processing step would compute corresponding choices abstract operators. example, post-processing step would take choice (12 , 22 , 33 )
compute four choices abstract operators:
{(13 , 22 , 33 ), (14 , 22 , 33 ), (13 , 22 , 34 ), (14 , 22 , 34 )}.
enhancement, domains MAPF, illegal operator pruning integrated
post-processing step. example, 22 cannot performed together 13 ,
need consider choice operator third abstraction. MAPF, results
significant time speed-up.

References
Bouzy, B. (2013). Monte-carlo fork search cooperative path-finding. IJCAI Workshop
Computer Games.
Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14(3),
318334.
Dechter, R., & Pearl, J. (1985). Generalized best-first search strategies optimality A*.
Journal Association Computing Machinery, 32(3), 505536.
Dweighter, H. (1975). Problem e2569. American Mathematical Monthly, 82, 1010.
Edelkamp, S. (2001). Planning pattern databases. European Conference Planning (ECP01), pp. 1324.
Edelkamp, S., & Korf, R. E. (1998). branching factor regular search spaces. AAAI, pp.
299304.
Felner, A., & Adler, A. (2005). Solving 24-puzzle instance dependent pattern databases.
SARA, pp. 248260.
Felner, A., Goldenberg, M., Sharon, G., Stutervant, N., Stern, R., Beja, T., Schaeffer, J., & Holte, R.
(2012). Partial-expansion A* selective node generation. AAAI.
Felner, A., Korf, R. E., & Hanan, S. (2004). Additive pattern database heuristics. Journal Artificial
Intelligence Research (JAIR), 22, 279318.
Felner, A., Zahavi, U., Holte, R., Schaeffer, J., Sturtevant, N., & Zhang, Z. (2011). Inconsistent
heuristics theory practice. Artificial Intelligence, 175(9-10), 15701603.
Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theorem proving
problem solving. Tech. rep. 43R, AI Center, SRI International.
Ghosh, S., Mahanti, A., & Nau, D. S. (1994). ITS: efficient limited-memory heuristic tree search
algorithm. AAAI, pp. 13531358.
Goldenberg, M., Felner, A., Stern, R., & Schaeffer, J. (2012). A* variants optimal multi-agent
pathfinding. Workshop Multiagent Pathfinding.
Goldenberg, M., Felner, A., Stutervant, N., Holte, R., & Schaeffer, J. (2013). Optimal-generation
variants EPEA*. International Symposium Combinatorial Search (SoCS).
185

fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER

Helmert, M. (2006). fast downward planning system.. Journal Artificial Intelligence Research (JAIR), 26, 191246.
Helmert, M. (2010). Landmark heuristics pancake problem. International Symposium
Combinatorial Search (SoCS), pp. 745750.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal sequential planning. ICAPS, pp. 176183.
Hoffmann, J., & Nebel, B. (2001). FF Planning System: Fast Plan Generation Heuristic Search. Journal Artificial Intelligence Research (JAIR), 14, 253302.
Holte, R. C., Perez, M. B., Zimmer, R. M., & MacDonald, A. J. (1996). Hierarchical A*: Searching
abstraction hierarchies efficiently. AAAI, pp. 530535.
Jensen, R. M., Hansen, E. A., Richards, S., & Zhou, R. (2006). Memory-efficient symbolic heuristic
search. ICAPS, pp. 304313.
Jensen, R. M., Bryant, R. E., & Veloso, M. M. (2002). SetA*: Efficient BDD-Based Heuristic
Search Algorithm. AAAI/IAAI, pp. 668673.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. IJCAI, pp. 1728
1733.
Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible treesearch. Artificial
Intelligence, 27(1), 97109.
Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62(1), 4178.
Korf, R. E. (1997). Finding optimal solutions Rubiks Cube using pattern databases. AAAI,
pp. 700705.
Larsen, B. J., Burns, E., Ruml, W., & Holte, R. (2010). Searching without heuristic: Efficient use
abstraction. AAAI.
Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing planning.. ICAPS, pp. 273280.
Roger, G., & Helmert, M. (2012). Non-optimal multi-agent pathfinding solved (since 1984).
International Symposium Combinatorial Search (SoCS), pp. 15.
Russell, S. J. (1992). Efficient memory-bounded search methods. ECAI-92.
Sharon, G., Stern, R., Goldenberg, M., & Felner, A. (2011). increasing cost tree search
optimal multi-agent pathfinding. IJCAI, pp. 662667.
Sharon, G., Stern, R., Goldenberg, M., & Felner, A. (2012). Meta-agent conflict-based search optimal multi-agent path finding. International Symposium Combinatorial Search (SoCS).
Silver, D. (2005). Cooperative pathfinding. AIIDE, pp. 117122.
Standley, T. (2010). Finding optimal solutions cooperative pathfinding problems. AAAI, pp.
173178.
Yang, F., Culberson, J., Holte, R. C., Zahavi, U., & Felner, A. (2008). general theory additive
state space abstractions. Journal Artificial Intelligence Research (JAIR), 32, 631662.
Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branching factor
problems. AAAI/IAAI, pp. 923929.
186

fiE NHANCED PARTIAL E XPANSION A*

Zahavi, U., Felner, A., Burch, N., & Holte, R. C. (2010). Predicting performance IDA* (with
BPMX) conditional distributions. Journal Artificial Intelligence Research (JAIR), 37,
4183.
Zahavi, U., Felner, A., Holte, R. C., & Schaeffer, J. (2008). Duality permutation state spaces
dual search algorithm. Artificial Intelligence, 172(45), 514540.
Zahavi, U., Felner, A., Schaeffer, J., & Sturtevant, N. R. (2007). Inconsistent heuristics. AAAI,
pp. 12111216.
Zhou, R., & Hansen, E. (2004). Space-efficient memory-based heuristics. AAAI, pp. 677682.
Zhou, R., & Hansen, E. A. (2002). Memory-bounded A* graph search. Florida Artificial Intelligence Research Society (FLAIRS-02), pp. 203209.

187

fiJournal Artificial Intelligence Research 50 (2014) 409-446

Submitted 12/13; published 6/14

Multivariate Complexity Analysis Lobbying
Multiple Referenda
Robert Bredereck
Jiehua Chen
Sepp Hartung
Stefan Kratsch
Rolf Niedermeier

robert.bredereck@tu-berlin.de
jiehua.chen@tu-berlin.de
sepp.hartung@tu-berlin.de
stefan.kratsch@tu-berlin.de
rolf.niedermeier@tu-berlin.de

TU Berlin, Germany

Ondrej Suchy

ondrej.suchy@fit.cvut.cz

Czech Technical University Prague, Czech Republic

Gerhard J. Woeginger

gwoegi@win.tue.nl

TU Eindhoven, Netherlands

Abstract
Assume n voters may may approve issues. agent (the
lobby) may influence k voters, central question NP-hard Lobbying
problem whether lobby choose voters influenced result
issue gets majority approvals. problem modeled simple matrix
modification problem: one replace k rows binary nm-matrix k all-1 rows
column resulting matrix majority 1s? Significantly extending
previous work showed parameterized intractability (W[2]-completeness) respect
number k modified rows, study natural parameters n, m, k,
maximum number 1s missing column majority 1s (referred
gap value g) govern computational complexity Lobbying. Among
results, prove Lobbying fixed-parameter tractable parameter provide
greedy logarithmic-factor approximation algorithm solves Lobbying even optimally
4. also show empirically greedy algorithm performs well general
instances. key result, prove Lobbying LOGSNP-complete
constant values g 1, thus providing first natural complete problem voting
complexity class limited nondeterminism.

1. Introduction
Campaign management comprises sorts activities influencing outcome
election, including well-known scenarios bribery (Faliszewski, Hemaspaandra, &
Hemaspaandra, 2009; Dorn & Schlotter, 2012; Schlotter, Elkind, & Faliszewski, 2011;
Elkind, Faliszewski, & Slinko, 2012) control (Bartholdi III, Tovey, & Trick, 1992; Elkind,
Faliszewski, & Slinko, 2011; Erdelyi, Piras, & Rothe, 2011). works relate
campaigning case classical voting scenarios one typically wants make specific
candidate win prevent winning, Christian, Fellows, Rosamond, Slinko
(2007) introduced scenario lobbying multiple referenda. Intuitively, point
n voters, providing yes- no-answer issues.
words, referendum issues voters decide on. Naturally,
c
2014
AI Access Foundation. rights reserved.

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

referendum held, campaigns run various parties interest groups
influence outcome referendum. Assuming complete knowledge current
voter opinions assuming extreme scenario external agentthe lobbygains
complete control specific voters, Christian et al. modeled basic scenario
0/1-matrix modification problem, rows represent voters, columns represent
issues vote yes (1) (0), lobby goal represented 0/1-vector.
Lobbying
Input:
matrix {0, 1}nm integer k 0.
Question: one modify entries k rows resulting
matrix every column 1s 0s?
context, modifying row means simply flip 0s 1s. Hence, modifying
minimum number rows interpreted lobby influencing minimum number
voters reach certain goal. difference Christian et al., assume
desired outcome column 1 instead providing goal vector lobby. is,
1 corresponds agreement lobby goal 0 corresponds disagreement. Clearly,
appropriately flipping entries column always ensured. Furthermore,
assume column majority 1s removed input matrix.
following example, extract real-world data Section 6.2, illustrates
model.
Example 1. Consider following four issues voting behavior five faction
leaders extracted recorded votes German parliament 2013. (See Section 6.2
details full data set.)
Selected issues:
1. Water access human right.
2. Forbid Nationalist Party.
3. Financial help Ireland.
4. Financial help Cyprus.

Bruderle
Gysi
Kauder
Kunast
Steinmeier

1

Yes

Yes


2

Yes

Yes
Yes

3
Yes

Yes
Yes
Yes

4
Yes

Yes
Yes
Yes

Assume lobby wants approve first two issues disapprove last two
issues. Then, matrix translates following binary matrix.
0
1
0
1
0

0
1
0
1
1

0
1
0
0
0

0
1
0
0
0

second column removed
majority voters already agree
lobby. Modifying first third row
yields solution.

Lobbying NP-complete (Christian et al., 2007). Moreover, setting parameterized complexity analysis (Downey & Fellows, 2013; Flum & Grohe, 2006; Niedermeier,
2006), Christian et al. showed W[2]-complete respect parameter number k rows modify, is, even small number voters shall influenced
problem computationally intractable. work, provide significantly
410

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

refined view parameterized multivariate computational complexity (Fellows,
Jansen, & Rosamond, 2013; Niedermeier, 2010) Lobbying. end, identify
following parameters naturally occurring Lobbying analyze influence
computational complexity. studied parameters are:
n: number rows;
m: number columns1 ;
k: number rows modify;
k 0 :=d(n + 1)/2e k: below-guarantee parameter;2
g:=maxm
j=1
Pngj : maximum gap value columns, gap value gj :=d(n +
1)/2e i=1 Ai,j number missing 1s make column j 1s
0s;
s: maximum number 1s per row;
t: maximum number 0s per row.
1.1 Parameter Choice
parameters n, m, k naturally occurring parameters measure input
size solution size, respectively. Scenarios voters issues clearly
interesting realistic restrictions. Furthermore, also restriction instances
small solutions natural limited budget lobby may allow (very)
small amount bribery or, positively, advertisement. Additionally, k 0 complements
parameter k seems promising measures distance trivial type
yes-instances. Moreover, observe maximum gap value g lower bound
number rows modified; precomputed linear time. Furthermore,
sets issues single issue needs small amount additional approvals
disapprovals bear good prospects lobby limited budget. Finally, measure
density input matrix. model density matrix seen
degree agreement voters lobby. Hence, worth investigate
whether high low density leads computational tractability.
1.2 Parameter Relations
various relations parameters values above. instance, columns
containing majority 1s safely removed (also implying positive gap values
columns). implies input matrix least many 0s 1s, follows
least one row least half entries 0s. Hence,
2t. addition, input matrix contains column consisting 0s,
one modify d(n + 1)/2e rows, implying corresponding Lobbying instance
1. Christian et al. (2007) argued seldom exceeds 20.
2. Clearly, lobbying d(n + 1)/2e voters, is, modifying d(n + 1)/2e rows input matrix yields always
desired solution, making d(n + 1)/2e trivial upper bound k.

411

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

(even constant parameter values)

LOGSNP-hard
maximum
gap value g

NP-hard

maximum number
1s per row

below-guarantee
parameter k 0

(s, k 0 )

W[2]-hard
number
k rows
modify

(s, k)

(s, g)

(m, g)

number
n rows

(m, k)

(k, k 0 )

ILP-FPT

(m, k 0 )

polynomial kernel
(s, n)

trivial FPT
(parameters provide upper bounds
input size)

maximum number
0s per row

number
columns

(m, n)

FPT
(fixed-parameter tractable)

(t, n)

Figure 1: Parameterized complexity Lobbying relations parameters
considered paper. arc x means function
f x f (y). omit combined parameters one component upperbounded function component, example (n, k) omitted,
k n. ILP-FPT means fixed-parameter tractability bases
formulation integer linear program.

yes-instance k d(n + 1)/2e. Also, assume n otherwise
column consisting 0s trivial input instance since would
check whether k d(n + 1)/2e. relations parameters
combinations considered paper illustrated Figure 1.
Finally, remark article focus plain lobbying multiple
referenda scenarios. leave considerations fine-grained aspects lobbying
process (such allowing different forms modifying input matrix) natural next
step future work.
412

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

1.3 Related Work
central point reference work Christian et al. (2007) whose key result
proof W[2]-completeness Lobbying respect number k. Erdelyi,
Hemaspaandra, Rothe, Spakowski (2007) generalized Lobbying weighted scenario showed efficient greedy algorithm achieves logarithmic approximation
factor (1 + ln(m d(n + 1)/2e)) weighted case. Moreover, showed essentially better approximation ratio proven algorithm. Later, models
lobbying probabilistic environment proposed Binkele-Raible, Erdelyi, Fernau,
Goldsmith, Mattei, Rothe (2014), providing (parameterized) hardness tractability
results; interpret lobbying form bribery.
special case combinatorial reverse auction problem (Sandholm, Suri, Gilpin,
& Levine, 2002), optimization version Lobbying relevant combinatorial markets
multi-agent systems. combinatorial reverse auctions, different items
buyer wants acquire lowest cost sellers. precisely, buyer wants
amount units item, U = (u1 , u2 , . . . , um ). seller submits
many goods item, (i1 , i2 , . . . , im ) price pi would
sell. goal minimize cost acquiring required amount units
item. easy see translate lobbying problem combinatorial reverse
auction problem: issue j corresponds item j. buyers requirement
item j gap value corresponding column, uj := gj , j {1, . . . , m}. row
corresponds seller offer ij := 1 Ai,j , j {1, . . . , m} price pi := 1.
Lobbying also closely related bribery judgment aggregation (Baumeister, Erdelyi,
& Rothe, 2011) judges submit binary opinions different propositions
goal bribe judges possible order obtain certain outcome. Lobbying
instance formulated equivalent instance bribery judgment aggregation
problem using premise-based procedure. precisely, given binary matrix A,
propositional variable vj corresponds column j, judge corresponds row
judgment set consisting variables vj satisfying Ai,j = 1, agenda consists
propositional variables premises conclusions. goal modifying
rows possible order 1s 0s column equivalent
bribing judges possible order possible variables approved
half judges.
Finally, refer survey articles discussion importance parameterized
complexity results context artificial intelligence (AI) (Gottlob, Scarcello, & Sideri,
2002; Gottlob & Szeider, 2008) voting (Betzler, Bredereck, Chen, & Niedermeier, 2012).
1.4 Contributions
initiate systematic parameterized multivariate complexity analysis Lobbying problem. contribute theoretical well empirical side. See
preliminaries Section 2 definitions parameterized complexity classes like.
complexity results summarized Table 1. Let us sketch highlights.
Section 3, show Lobbying remains NP-hard = 3 k 0 = 1. Thus,
hope fixed-parameter tractability respect parameters k 0 .
Moreover, special highlight work show even gap parameter g
413

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger





k0
g




k0
g
k
n
ILP-FPT (Thm. 9, Cor. 2)
FPT (Thm. 10)


(2m )2.52 +o(2 ) n
(g + 1)m n2
3: NP-c (Thm. 1)
FPT (Cor. 3)
2: P (Thm. 6)
NP-c
(g + 1)4s n2 + 16g
(Thm. 1) XP, FPT const. g
FPT (Prop. 2)
0
2g+1
2k

2 (Thm. 11)
2n

W[2]-h
LOGSNP-c (Thm. 2)
W[2]-ca

k
n
a. (Christian et al., 2007)

Table 1: Summary results. parameter combination (row column) entries
indicate whether Lobbying fixed-parameter tractable (FPT), fixed-parameter
tractable based formulation integer linear program (ILP-FPT), polynomialtime solvable constant parameter values (XP), W[2]-hard (W[2]-h), W[2]complete (W[2]-c), LOGSNP-complete, meaning completeness class limited
nondeterminism lying P NP constant parameter values (LOGSNPc), NP-complete even constant parameter values (NP-c). Entries main
diagonal represent results respect single parameters. Furthermore,
(m, n), (t, n), (s, n), problem kernels polynomial size
parameters naturally bound input size (see Figure 1). (m, k 0 )
aware kernel size bounds. parameter combinations above,
reasonable complexity-theoretic assumptions, cannot polynomialsize problem kernel (see Section 4).

equal one, Lobbying remains intractable sense complete
limited nondeterminism class LOGSNP (Papadimitriou & Yannakakis, 1996) (also see
survey Goldsmith, Levy, & Mundhenk, 1996). particular interest
least two reasons. First, provides first natural voting problem complete
LOGSNP. Second, one far rare examples complexity class
used context parameterized complexity analysis.
Section 4, reveal limitations effective polynomial-time preprocessing Lobbying, is, prove polynomial-size problem kernels unlikely exist.
Section 5, show Lobbying fixed-parameter tractable parameter
means describing ILP formulation 2m variables. provide
two efficient algorithms yielding provably optimal results input matrices
four columns. One two algorithms based simple greedy strategy
provides logarithmic approximation ratio cases four columns.
414

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

Furthermore, develop several fixed-parameter algorithms various parameter
combinations show Lobbying polynomial-time solvable 2.
Finally, Section 6, experimentally compare greedy heuristic, heuristic work Erdelyi et al. (2007), implementation ILP formulation
providing solutions guaranteed optimal. empirical results random data
real-world data indicate Lobbying solved efficiently.

2. Preliminaries
aim provide deeper understanding computational complexity NPcomplete Lobbying problem. end, employ classical complexity classes P
(polynomial time) NP (nondeterministic polynomial time) (Garey & Johnson, 1979)
well class LOGSNP limited nondeterminism (lying P NP) (Papadimitriou & Yannakakis, 1996; Goldsmith et al., 1996) parameterized complexity classes
FPT (fixed-parameter tractability), W[2] (second level weft hierarchy
presumable parameterized intractability), XP (Downey & Fellows, 2013; Flum & Grohe,
2006; Niedermeier, 2006). Throughout paper, denote log logarithm base
two.
2.1 LOGSNP
LOGSNP introduced Papadimitriou Yannakakis (1996) precisely characterize computational complexity certain problems NP neither known
NP-complete known solvable polynomial time. LOGSNP subclass
problems NP decided polynomial time initial phase O(log2 N )
nondeterministic steps, N overall input size. However, LOGSNP include problems decidable polynomial time nondeterministic phase since
puts additional restrictions computation. Roughly speaking, one allowed
use constant number elements guessed solution.
widely believed LOGSNP properly intermediate P NP. Problems complete LOGSNP polynomial-time reductions include Rich Hypergraph
Cover (see Section 3 definition) Log Adjustment (Papadimitriou & Yannakakis, 1996), latter particular importance artificial intelligence. Log
Adjustment, boolean expression conjunctive normal form r variables truth
assignment given, question whether satisfying truth assignment
whose Hamming distance log r.
Alternative characterizations LOGSNP exist (Cai, Chen, Downey, & Fellows, 1997;
Flum & Grohe, 2006, Sec. 15.2).
2.2 Fixed-Parameter Tractability XP
concept parameterized complexity pioneered Downey Fellows (2013) (see
also textbooks: Flum & Grohe, 2006; Niedermeier, 2006). fundamental goal
find whether seemingly unavoidable combinatorial explosion occurring algorithms
solve NP-hard problems confined certain problem-specific parameters.
parameter assumes small values applications, algorithm running
415

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

time exponential exclusively respect parameter may efficient.
Lobbying, suggest number (potentially small) parameters. combined parameter
(which vector parameters) can, sake convenience, simply seen
sum components.
Formally, problem fixed-parameter tractable (equivalently, contained parameterized complexity class FPT) respect parameter p (equivalently, parameterized p) instance (I, p) problem solved f (p) |I|O(1) time,
f solely depends p. problem solved polynomial running time
degree polynomial depends p (such |I|f (p) ), then, parameter p,
problem said lie thestrictly larger (Downey & Fellows, 2013)parameterized
complexity class XP. Note containment XP ensures polynomial-time solvability
constant parameter p whereas FPT additionally ensures degree corresponding
polynomial independent parameter p.
2.3 Kernelization
Another way showing fixed-parameter tractability kernelization. kernelization algorithm takes input problem instance together parameter p
transforms polynomial time instance 0 parameter p0 (I, p)
yes-instance (I 0 , p0 ) yes-instance function f
p0 f (p) |I 0 | f (p). function f measures size (problem) kernel (I 0 , p0 ).
problem kernel said polynomial kernel f polynomially bounded. Note
well-known decidable problem fixed-parameter tractable respect parameter kernelizable (Cai et al., 1997). corresponding kernels, however,
may exponential size particular interest determine problems,
respect parameter(s), allow polynomial-size problem kernels (Bodlaender, 2009;
Guo & Niedermeier, 2007) since total running time complexity may vary dependent
kernel size. Using techniques developed Bodlaender, Downey, Fellows, Hermelin
(2009) Fortnow Santhanam (2011), Szeider (2011) recently proposed examine
power kernelization several problems Artificial Intelligence. See Section 4
discussion.
2.4 Parameterized Intractability
Downey Fellows (2013) also introduced framework parameterized intractability.
framework, two basic complexity classes parameterized intractability W[1]
W[2], problem shown W[1]- W[2]-hard providing parameterized
reduction W[1]- W[2]-hard problem problem question. parameterized
reduction problem 1 another problem 2 function f computable FPT
time function g instance (I2 , p2 ) produced f instance
(I1 , p1 ) satisfies following:
(I1 , p1 ) yes-instance problem 1 (I2 , p2 ) yes-instance
problem 2 ,
p2 g(p1 ).
416

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

W[1]-complete problems include Clique parameterized solution size (Downey &
Fellows, 2013) W[2]-complete problems include Set Cover parameterized
solution size (see Section 3.1 formal definition).
problem shown NP-hard even parameter p constant, cannot
contained XP unless P = NP.

3. Intractable Cases
section, examine worst-case computational complexity Lobbying. Besides
NP-completeness one restricted case, also prove LOGSNP-completeness result
case column one 1-entry missing reach majority 1s.
3.1 NP-Completeness
hardness reductions presented work, NP-complete variants
following Set Cover (SC) problem used.
Set Cover (SC)
Input:
family sets = {S1 , . . . , S` } universe U = {u1 , . . . , ur } elements
integer h 0.
Question: size-h set cover, is, collection h sets whose union
U?
Note even 3-Set Cover (3-SC), set size three,
NP-complete (Karp, 1972). order make reduction work, need let h, |S|,
number occurrences every element sets fulfill following properties
whose correctness easy see:
1. add (multiple copies of) singletons family ensure |S| 2h + 1 0
ensure every element appears least h sets S.
2. also add new element u universe U, add h copies singleton {u }
family S, set h := h + 1 ensure element appears
|S| h sets S.
common starting point SC reductions transform (and U)
binary matrix similar way Christian et al. (2007) transformed Dominating Set
instances binary matrices. corresponding |S| |U|-matrix called SC-matrix
defined
(
1 uj Si ,
(S, U) = (xi,j ) xi,j :=
0 otherwise.
Observe column j {1, . . . , |U|} 1s (|S| h) rows. make
use SC-matrix Section 4 following theorem.
instance Lobbying k d(n + 1)/2e (that is, half rows
modified) yes-instance. Following general ideas Mahajan Raman (1999)
context guarantee parameterization, investigate complexity
Lobbying case maximum number 1s per row bounded constant k
slightly bound d(n + 1)/2e. parameterization called guarantee.
417

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

U = {1, 2, 3, 4, 5}
= { S1 = {2, 4}
S2 = {3, 5}
S3 = {1, 2, 5}
S4 = {1, 2, 3}
S5 = {4, 5} }

S1 :
S2 :
S3 :
S4 :
S5 :

1
0
0
1
1
0
0
0

2
1
0
1
1
0
0
0

3
0
1
0
1
0
0
0

4
1
0
0
0
1
0
0

5
0
1
1
0
1
0
0

6
0
0
0
0
0
1
0

7
0
0
0
0
0
0
1

k := |S| h = 3

h=2

Figure 2: Illustration reduction 3-SC Lobbying. Left: 3-SC instance;
Right: constructed Lobbying instance. SC-matrix together two
dummy rows two dummy columns (inside dashed polygon) ensure
set rows selected solution size three corresponds
set cover. 3-SC solution (S4 S5 ) highlighted boldface
left. Lobbying solution (modifying first three rows) highlighted
gray backgrounds.

Theorem 1. Lobbying remains NP-complete input matrices maximum number ones per row three k 0 = 1 guarantee parameter k 0 =
(d(n + 1)/2e k).
Proof. Obviously, given matrix k = d(n + 1)/2e 1 rows A, check
polynomial time whether row three 1s whether modifying
k given rows makes every column 1s 0s. Hence, Lobbying = 3
k 0 = 1 remains NP.
NP-hardness result, describe polynomial-time reduction 3-SC
Lobbying row contains three 1s. reduction illustrated
example Figure 2. Let (S, U, h) denote 3-SC instance. First, compute SC-matrix
(S, U), refer original rows original columns following. Second,
add |S|2h+1 additional dummy rows |S|2h+1 additional dummy columns containing
0s. Recall assume |S| 2h + 1 0. Finally, 1 |S| 2h + 1,
change entry ith dummy column ith dummy row 1. complete
construction set k := |S| h.
original row three 1s since set three elements.
dummy row exactly one 1. Further, guarantee parameter k 0 = d(n +
1)/2e k = d(2|S| 2h + 1)/2e (|S| h) = 1. quota column 1s
0s |S| h + 1. Since every original column 1s |S| h original rows
1s dummy rows, original column 1s 0s matrix.
precisely, jth original column gap value |S| h + 1 |{Si | uj Si }|. dummy
column gap value |S| h. Hence maximum gap value g |S| h.
418

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

Obviously, reduction runs polynomial time. Now, show (S, U, h)
yes-instance 3-SC constructed matrix modified 1s
0s every column changing k rows all-1-rows.
part, suppose (S, U, h) yes-instance 3-SC. Let 0
denote set cover size h. modifying original row corresponds set
Si
/ 0 , every column 1s 0s, is, least (|S| h + 1) 1s: jth
dummy column gains (|S| h) 1s modified original rows another 1
jth dummy row. original column gains (|S|h) 1s modified original rows
another 1 unmodified original row, since sets corresponding unmodified
original rows form set cover.
part, suppose constructed matrix 1s 0s every
column modifying k = |S| h rows. First, observe number modified
rows exactly |S| h since maximum gap value |S| h. Second, dummy row
modified: Assume towards contradiction i0 th dummy row modified. Since
i0 th dummy column one 1 matrix, namely, i0 th dummy row,
column cannot get majority (|S| h + 1) 1s modification |S| h rows
including i0 th dummy rowa contradiction. Third, show sets corresponding
unmodified original rows form size-h set cover (S, U, h). original column j 0
gets exactly (|S| h) 1s modified original rows 1 dummy row.
get majority (|S| h + 1) 1s, column j 0 must contain another 1 unmodified
original row. Hence, sets corresponding unmodified rows form set cover
size k. shows correctness construction.
Proposition 1. Lobbying remains NP-complete every constant integer value k 0 > 1
below-guarantee parameter k 0 = (d(n + 1)/2e k).
Proof. NP-containment follows analogously Theorem 1. show NP-hardness
constant k 0 > 1, take SC-matrix (S, U) add x additional dummy
columns xk 0 additional dummy rows x := (|S| 2h 1)/k 0 + 2. Note
add singletons family make sure k 0 divisor (|S| 2h 1). fill
added entries follows: j {1, . . . , |U|}, set entries k 0 1 arbitrary
dummy rows original column j 1. 1 j x, set entry jth dummy
column [(j 1)k 0 + 1]th, [(j 1)k 0 + 2]th, . . ., [(j 1)k 0 + k 0 ]th dummy rows 1.
Set k := |S| h.
total, constructed matrix 2|S| 2h + 2k 0 1 rows |U| + x columns.
quota column 1s 0s q = |S| h + k 0 . original column
gap value q (|{Si | uj Si }| + k 0 1) = |S| h + 1 (|{Si | uj Si }|) dummy
column gap value q k 0 = |S| h.
reduction runs polynomial time. Now, remains show correctness.
Suppose (S, U, h) set cover 0 size h. modifying original row
corresponds set Sj
/ 0 , every column 1s 0s.
Conversely, suppose constructed matrix 1s 0s modifying
k rows. Using analogous reasoning proof Theorem 1,
show exactly k original rows modified original rows modified
correspond sets form set cover (S, U, h).
419

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

3.2 LOGSNP-Completeness
section, show Lobbying instances constant maximum gap value g =
1 LOGSNP-complete (Papadimitriou & Yannakakis, 1996) (see also Section 2
discussion class). implies that,
unless LOGSNP = P, Lobbying restricted instances constant value g cannot
solved polynomial time, hence, Lobbying parameterized g XP,

unless LOGSNP = NP, Lobbying restricted instances constant value g
NP-hard.
Theorem 2. Lobbying instances constant maximum gap value g LOGSNP.
Proof. First all, show k g (blog mc + 1), Lobbying instance (A, k)
yes-instance. Recall row containing 0s least half columns
(see parameter discussion Section 1). Modify row continue columns
nothing modified far. Again, row containing 0s
least half columns, one modify. repeat column
touched least once, decreasing g least one. takes (blog mc + 1) steps.
Then, remove columns gap value zero. repeat procedure g times
end empty matrix, modifying altogether g (blog mc + 1) rows.
follows observations Lobbying instance (A, k) solved
modifying g (blog mc + 1) rows (independent value k). Since row
identified O(log n) bits, certificate yes-instances problem
uses O(log2 (n + m)) many bits. implies Lobbying problem belongs
problems decidable polynomial time O(log2 (n + m)) non-deterministic steps.
already indicates Lobbying constant maximum gap lies somewhere P
NP. show containment LOGSNP, reduce Lobbying constant maximum gap LOGSNP-complete Rich Hypergraph Cover problem (Papadimitriou
& Yannakakis, 1996) polynomial time.
Rich Hypergraph Cover (RHC)
Input:
family sets = {S1 , . . . , S` } universe U = {u1 , . . . , ur } even
number r elements, |Sj | r/2 Sj , integer h 0.
Question: subset U 0 U size h non-empty intersection
every set Sj S?
Let (A {0, 1}nm , k) input instance Lobbying constant maximum gap
value g. First, column j {1, . . . , m}, let Zj set rows 0s
column j let gj gap value column j, is, number missing 1s
make column j 1s 0s. assume (A, k) non-trivial, is,
column consists 0s gap values positive. Now, consider possible
size-(|Zj | gj + 1) subsets row set Zj . set X rows intersects
subsets, modifying rows X make column j 1s 0s.
exploit observation construct instance RHC (A {0, 1}nm , k).
420

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

row {1, . . . , n}, add element ui universe U. column j
{1, . . . , m}, add family possible size-(|Zj | gj + 1) subsets elements
set {ui | Zj }. say newly added subsets correspond column j. Let
solution size h equal k. completes reduction.
Since g constant ng different subsets added S, reduction
runs polynomial time. remains show correctness, is, (A, k) yes-instance
Lobbying constructed instance (S, U, h) yes-instance Rich
Hypergraph Cover.
part, assume (A, k) yes-instance. Let R0 set rows
size k modifying makes every column 1s 0s. Let
U 0 = {ui | R0 } set corresponding elements. show U 0 intersects
every set S. Suppose sake contradiction set
U 0 = . construction subsets S, let set correspond column j and,
hence, |S | = |Zj | gj + 1. R0 contain (gj 1) rows Zj makes
column j 1s 0sa contradiction.
part, assume (S, U, h) yes-instance. Let U 0 set elements
size h intersects every set S. Let R0 = {i | ui U 0 } set
corresponding rows. show modifying rows R0 results matrix
every column 1s 0s. Suppose sake contradiction
column j many 1s 0s modifying rows R0 . means
|Zj R0 | gj 1, hence Zj \ R0 contains least |Zj | gj + 1 rows. Thus,
possible find size-(|Zj | gj + 1) set elements {ui | Zj \ R0 } Zj
intersect U 0 contradiction.
consequence proof, assume non-trivial instance
Lobbying fulfills k < g (blog mc + 1). try combinations k rows
modify, check whether every column 1s 0s,
obtain algorithm solving Lobbying O(ng(dlog me+1) m) time. Now, suppose
Lobbying constant g NP-hard, implying polynomial-time reduction
NP-complete problem P Lobbying constant g. would
n = |I|O(1) = |I|O(1) constructed Lobbying instance |I| input
size problem P. Thus, P would decidable |I|O(log |I|) time, implying following
corollary.
Corollary 1. Lobbying instances constant maximum gap value g NP-hard
unless problems NP solved |I|O(log |I|) time, |I| size input.
Next, show Lobbying LOGSNP-hard even column needs one
additional 1 reach majority 1s, is, g = 1.
Theorem 3. Lobbying instances maximum gap value g = 1 LOGSNP-hard.
Proof. reduce polynomial time Rich Hypergraph Cover (RHC) Lobbying maximum gap value g = 1. definition RHC already given proof
Theorem 2.
Consider arbitrary RHC instance (S, U, h) |S| = ` |U| = r. already
mentioned Papadimitriou Yannakakis (1996), assume h blog `c + 1
421

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

otherwise (S, U, h) trivial yes-instance: Since set contains least half
elements U, one element appears least half sets
S. Add solution element appears least half subsets delete
sets contain element, repeat. Now, let w := max(dlog `e + 2, dlog re).
implies r/2 2w1 , h w 1 2w 8` + 2r, is, 2w upper-bounded
polynomial ` r. Furthermore, let ~vi 1 2w 1 enumeration
0/1-vectors length w exception all-zero vector. every vector ~vi ,
let V(i) denote set ~vi0 (1 i0 2w 1) inner product ~vi ~vi0 odd;
easily seen |V(i)| = 2w1 .
Now, ready construct instance (A, k) Lobbying. Add matrix
one element row element ui U one so-called dummy row i0 0/1vector ~vi0 (1 i0 2w 1) length w except all-zero vector. total number n
rows r + 2w 1, odd, r even. quota column
1s 0s q = r/2 + 2w1 . Let matrix total = ` (2w 1)
columns, one column c(j,z) pair (j, z) 1 j ` 1 z 2w 1. fill
entries follows: let column c(j,z) 0 element row corresponding
set Sj contains element ui , 1 otherwise. Further, let column c(j,z) 0s q |Sj |
arbitrarily chosen dummy rows i0 ~vi0 V(z) (that is, inner product ~vi0 ~vz odd),
1s remaining dummy rows. Note choice w implies |Sj | q
0 q |Sj | = r/2 + 2w1 |Sj | 2w1 enough dummy rows i0
~vi0 V(z). way, fix entries matrix column exactly
q 1 ones q zeros, means maximum gap value g equals one.
Finally, set parameter k h. completes reduction. Obviously, runs
polynomial time. remains show RHC instance (S, U, h) yes-instance
constructed Lobbying instance (A, k) yes-instance.
part, assume RHC instance (S, U, h) yes-instance,
certified subset U 0 size h = k. construction matrix A, modifying
element rows corresponding elements U 0 makes every column c(j,z) gain least
one additional 1.
part, assume modifying k rows matrix results matrix
column 1s 0s. Let R0 set modified element rows,
define = {d1 , d2 , . . . , dy } d1 , . . . , dy modified dummy rows. Thus,
k = h w 1. Let U 0 = {ui | R0 } set elements correspond
element rows R0 . sake contradiction, suppose set Sj
intersect U 0 . Then, every 1 z 2w 1, column c(j,z) 1s
element rows R0 . show even column c(j,z) 1s
every dummy row D. order find column, first observe standard
linear algebra exists vector ~vz (1 z 2w 1) simultaneously satisfies
equations ~vdi ~vz = 0 finite field size two 1 y. (The equation system
homogeneous, dimension underlying space w, w 1
constraining equations.) Then, definition, none vectors ~vd1 , . . . , ~vdy contained
set V(z). Thus, column c(j,z) 1s dummy rows d1 , . . . , dy contradiction
since c(j,z) gain additional 1 modifying rows R0 D.
422

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

4. Limits Preprocessing
Efficient preprocessing data reduction techniques key importance trying
(exactly) solve NP-hard problems (Guo & Niedermeier, 2007); also refer Szeider
(2011) general account showing limits preprocessing AI problems.
section, prove almost fixed-parameter tractability results stated Table 1,
Lobbying admit, reasonable complexity-theoretic assumption, efficient
preprocessing algorithm formalized polynomial kernelization parameterized algorithmics. sufficient assumption almost known lower bounds kernelization
NP * coNP/poly; known NP coNP/poly would imply collapse polynomial
hierarchy third level (Yap, 1983). One way showing non-existence polynomial kernels give so-called polynomial time parameter transformation
NP-hard problem already shown unlikely admit polynomial kernel (Bodlaender,
Thomasse, & Yeo, 2011). polynomial time parameter transformation parameterized reduction required computable polynomial time parameter
instance one reduces polynomially upper-bounded parameter
instance one reduces from.
prove Lobbying admits neither polynomial-size kernel respect
combined parameter (m, k) respect n. simple observations relations parameters, two results imply non-existence polynomial kernels
parameters parameter combinations listed Table 1. Recall Figure 1
parameter discussion Section 1 details parameter relations. cases
Lobbying NP-hard even parameters constants (see s, k 0 , (s, k 0 )),
cases parameters bounded functions depending n (see g, k, k 0 , n,
combinations them) parameters bounded functions depending
k (see t, m, g, k, combinations them). (m, n), (t, n), (s, n)
problem kernels linear ((m, n) (t, n)) polynomial ((s, n)) size,
parameters naturally bound input size. question whether polynomial kernels remains open parameters (m, k 0 ) (t, k 0 ), equivalent respect
question.
prove conditional non-existence result Lobbying parameterized (m, k),
employ incompressibility result Set Cover due work Dom, Lokshtanov,
Saurabh (2009).
Theorem 4. Unless NP coNP/poly, Lobbying admit polynomial-size problem kernel respect combined parameter (m, k), is, number columns
combined number rows modify .
Proof. Dom et al. (2009) showed that, unless NP coNP/poly, Set Cover (SC)
admit polynomial kernel respect combined parameter (|U|, h). show
result transfers Lobbying respect (m, k) describe polynomial time
parameter transformation SC respect (|U|, h).
Let (S, U, h) SC-instance. Recall adding multiple copies set
change answer instance, assume without loss generality
element occurs least h |S| h sets. First, compute SC-matrix
(S, U), refer original rows original columns following,
423

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

invert 0s 1s. Second, add |S| 2h + 1 dummy rows containing 0s. every original
column j, invert |S| |{Si : uj Si }| h + 1 0s arbitrary dummy rows 1s.
Add one dummy column containing 1s dummy rows, 0s elsewhere. Finally, let
k := h.
Note number 0s dummy column |S|, number 0s
column |S| h + 1, total number rows 2|S| 2h + 1. Thus, gap
original column exactly one gap dummy column h.
show (S, U, h) yes-instance Set Cover constructed
matrix modified 1s 0s every column changing k = h
rows all-1-rows.
part, assume (S, U, h) yes-instance. Let 0 size-h
set cover. Modifying (original) rows corresponding sets 0 results matrix
column 1s 0s: Since h modified original rows
0 dummy column, dummy column gains h additional 1s. Furthermore,
original row gets least one additional 1, 0 set cover.
part, suppose constructed instance yes-instance. means
modifying exactly k = h rows results matrix column 1s
0s since maximum gap value h. Since gap value dummy column h
dummy row contains 0 dummy column, solution cannot modify dummy
row. Since gap value original column exactly one, sets corresponding
modified rows Lobbying solution must form set cover.
reduction polynomial time parameter transformation SC parameterized |U| h Lobbying parameterized k: matrix resulting
Lobbying instance |U| + 1 columns ask modify k = h rows. Since
Lobbying contained NP since SC NP-hard, polynomial kernel Lobbying
respect (m, k) would imply polynomial kernel SC respect (|U|, h)
possible unless NP coNP/poly (Dom et al., 2009).
Lobbying trivially fixed-parameter tractable respect number n
rows, unlikely polynomial-size problem kernel parameterization.
Theorem 5. Unless NP coNP/poly, Lobbying admit polynomial-size problem
kernel respect number n rows (voters).
Proof. Observe polynomial time parameter transformation proof
Theorem 4 number rows constructed input matrix Lobbying
twice number sets SC instance. Hence, SC admit polynomial
kernel respect number sets (unless NP coNP/poly), Lobbying also
admit polynomial kernel respect n (unless NP coNP/poly). Next,
show that, indeed, SC admit polynomial kernel respect number
sets.
SC strongly related Hitting Set (HS) problem, which, given family
sets SH universe UH integer h 1, one asked choose set U 0 UH
size h set SH non-empty intersection U 0 . Dom et al.
(2009) showed that, unless NP coNP/poly, HS admit polynomial kernel
respect |UH |.
424

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

simple polynomial time parameter transformation HS parameterized
|UH | SC parameterized |S|: set Si SH HS instance add
element si universe set U SC instance. Finally, element e UH
HS instance add set set family SC instance contains element si
Si SH e Si . easy verify (SH , UH , h) yes-instance HS
(S, U, h) yes-instance SC.

5. Tractable Cases
section, contrasting intractability results previous sections, demonstrate Lobbying efficiently solvable practically relevant cases. end,
study numerous quantities (that is, parameters) influence computational
complexity Lobbying. instance, Section 3 seen Lobbying remains
NP-hard input matrices three 1s per row (Theorem 1)here show
becomes polynomial-time solvable matrices two 1s per row. Moreover,
show fixed-parameter tractability Lobbying respect number columns
(issues), four columns even linear-time solvable. Finally, shed light
several structural restrictions input matrix make solving Lobbying
feasible.
Note instances rows (voters) tractable, already
naive brute-force approach simply tries modify size-k subsets rows leads
algorithm FPT running time respect parameter number n rows.
Proposition 2. Lobbying solvable O(2n m) time.
5.1 Two Ones per Row
following result complements Theorem 1, altogether yielding complexity dichotomy
containment P NP-completeness respect maximum number
1s per row.
Theorem 6. Lobbying restricted input matrices two 1s per row, is,
2, solvable O(nm log m) time.
Proof. idea algorithm use special structure rows modified
fact row two 1s. may modify k d(n + 1)/2e rows
trivially answer yes; otherwise column requires b := d(n + 1)/2e k additional
1s outside k modified rows order reach d(n + 1)/2e 1s. algorithm seek
selection rows (1) column b 1s inside selected rows (2)
least k unselected rows left k modified. Modifying
k unselected rows gives total least b + k = d(n + 1)/2e 1s column. Note
solution k modified rows requires column initially contains least
b 1s; otherwise safely answer no.
see problem finding desired selection rows b 1s per column
comes certain matching problem auxiliary graph G, construct
next. graph G gets one vertex column, add G edge row
contains 1s corresponding two columns (a vertex pair may connected
425

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

multiple edges). b-matching graph subset edges vertex
endpoint b edges subset. final algorithm essentially come
computation maximum cardinality b-matching G. clarity, however, let us
first show b-matchings G solutions lobbying question interact.
First, assume exists solution Lobbying instance. Let R set
rows let R choice k rows modifying gives column
least d(n+1)/2e 1s. (Should R smaller k rows could added without
harm.) follows rows, say, R0 = R\R , contribute least b = d(n+1)/2ek
1s column. R0 get large b-matching G follows: column
arbitrarily mark b rows 1 column (so row marked
twice since 2). Let R0 denote set marked rows, let M2 denote
set rows marked twice. observe size b |M2 | since
marked b times used two marks row M2 . Considering edges G
correspond elements M2 easy see vertex incident
b (we marked b times per vertex, twice marked rows
considered). Thus edges corresponding M2 constitute b-matching G.
Second, consider set M2 rows correspond edges maximum
b-matching G, is, vertex incident b edges; clearly |M2 | |M2 |.
greedily add M2 rows column exactly b 1s created set
rows. (This possible since column contains least b 1s; otherwise answered
beginning.) let denote obtained set rows; i.e., M2
added ones. observe |M | = b |M2 |, since add b 2|M2 | rows
M2 : need b 1s total, M2 contributes 2|M2 | 1s, greedily added rows give
one 1 each. follows
|M | = b |M2 | b |M2 | = |M | |R0 | = |R| k.
Thus, least k rows left outside modified all-1 rows.
Together rows gives required number d(n + 1)/2e = k + b 1s
column.
Thus, solution gives rise b-matching maximum b-matching leads
solution (if one exists). algorithm therefore begins computing maximum bmatching G. Then, previous paragraph take corresponding rows
greedily extend set get b 1s column. Finally, leaves least k rows
unused modifying k must give solution (as argued). Crucially,
solution, showed gives sufficiently large b-matching G.
computation maximum b-matching costly part; according Gabow
(1983), maximum b-matching computed O(nm log m) time (see also Schrijver
(2003, Chapter 31) general notion b-matchings).
5.2 Columns
already mentioned introductory section, Christian et al. (2007) pointed
number issues multiple referenda rarely exceeds value 20. makes
well-motivated, practically relevant parameter leads question influences
computational complexity Lobbying. subsection, demonstrate
426

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

solve Lobbying efficiently 4 (by matching-based greedy algorithm).
Moreover, formulate Lobbying integer linear program number variables
bounded function deduce fixed-parameter tractability this.
findings complemented no-polynomial-kernel result Section 4 (Theorem 4)
experimental evaluations Section 6. start matching-based linear-time
algorithm Lobbying.
Theorem 7. input matrices four columns Lobbying solvable linear
time.
Proof. modify matching-based algorithm Theorem 6 cover cases
4. = 1 = 2, modification needed. cases = 3 = 4
observe first matching-based algorithm asked modify k rows
bi 1s column {1, . . . , m}.
Now, = 3 input matrix contains c all-1 rows, remove
execute matching-based algorithm Theorem 6 resulting matrix (where
every row contains two 1s) ask achieve d(n + 1)/2e c 1s column.
case = 4 claim optimal solution one
row three 1s modified. prove that, consider solution modifying minimum
number rows. assume rows last modified
consider situation row three 1s modified. suppose without
loss generality row vector 0111 modified. positive gap first
column whenever row 0 column, 0111 row. Hence,
number 0s column least d(n + 1)/2e yet satisfied. number
d(n + 1)/2e, otherwise would d(n + 1)/2e row vectors 0111
columns 2, 3, 4 would satisfied given matrixa contradiction. Thus,
gap first column 1 enough modify row vector 0111 satisfy
first column. another row three 1s modified, say row vector
1011, one together 0111 row vectors would make gap values
third fourth columns negativea contradiction.
summary, solve case = 4 branching five cases: One
0111 row modified, one 1011 row modified, one 1101 row modified, one 1110 row
modified, row three 1s modified. Then, modify appropriate row
remove rows containing least three 1s. count j number cj 1s
column j removed rows. Finally, ask matching-based algorithm modify
k 1 (or k, according chosen branch) remaining rows
column j contains d(n + 1)/2e cj 1-entries. running time follows Theorem 6.
attack matrices four columns, next develop simple greedy
strategy case. Indeed, provides optimal results input matrices
four columns. show logarithmic-factor approximation algorithm
unlimited number columns. Section 6, demonstrate excellent heuristic
properties.
Let {0, 1}nm input matrix. Recall gap gj column j {1, . . . , m}
number additional 1s column needs gain majority 1s. Let G := {gj |
j {1, . . . , m}} set different gap values, let hGi sequence elements
427

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

G decreasing order, let hGij denote jth element hGi. Further, let
gain(R) gain vector row vector R respect matrix A, defined
gain(R) := (z1 , z2 , . . . , z|G| ),
zj denotes number zeros row R columns gap value hGij . compare
two gain vectors, use lexicographic order . row R highest gain R
greatest element respect , is, every row R0 matrix holds
R0 R.
present algorithm MaxGapZeros employs greedy heuristic decide
rows modify. basic idea repeatedly choose row vector highest gain
set 1s columns satisfied. Note gap value
column may change one row modified. Hence, row vectors gain may also change.
Algorithm 1 MaxGapZeros (A {0, 1}nm )
compute gap values columns
column positive gap value exists
compute gain vector row vector
modify arbitrary row vector highest gain
update gap values columns
return modified rows

Theorem 8. Given input matrix n rows, columns, maximum gap g, MaxGapZeros finds solution size dlog g O(m n2 ) time; even finds
optimal solution Lobbying O(n2 ) time 4.
Proof. First, show running time bound. Computing gap values columns
takes O(mn) time MaxGapZeros performs d(n + 1)/2e iterations.
iteration computing gain vectors finding row maximum gain takes O(mn)
time, sort columns according gap values (positive integers
size n) O(m+n) time using counting sort, compute row-wise gain vectors
comparing current maximum gain vector O(mn) time. Updating gap
values takes O(m) time. Altogether, MaxGapZeros runs O(mn + n(m + n + mn + m)) =
O(m n2 ) time.
Second, show logarithmic approximation factor > 1. MaxGapZeros takes
iteration row maximum number 0s columns maximum gap value.
show that, this, MaxGapZeros reduces maximum gap value one
dlog iterations.
Let mg denote number columns gap value g, g maximum gap
value columns. g > 1, always row strictly (mg /2)
0s columns gap value g, otherwise matrix restricted columns
gap value g would contain many 0s 1s. MaxGapZeros select row
gain vector every row less (mg /2) 0s columns gap value g
smaller. Hence, maximum gap reduced one dlog(mg )e dlog
iterations.
428

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

g = 1, possible row strictly (mg /2) 0s,
matrix restricted columns gap one many 0s 1s. However, ith
iteration MaxGapZeros satisfies least mg 2i columns, since always row
contains least many 0s 1s columns gap one. Hence, dlog(mg )e iterations,
one column gap one survives. Thus, showing actually MaxGapZeros
satisfies mg /2 columns first iteration MaxGapZeros satisfies
mg /4 columns second iteration, show total MaxGapZeros needs dlog(mg )e
iterations satisfy columns gap one. Assume MaxGapZeros satisfies exactly
mg /2 columns first iteration. Without loss generality, let row selected
MaxGapZeros first iteration contain 1s first mg /2 columns gap one.
Since columns gap one, must 0s 1s remaining rows
matrix restricted columns. Thus, row (mg /4) 0s
columns gap one selected MaxGapZeros second iteration. Hence,
columns maximum gap one satisfied dlog(mg )e dlog iterations.
Summarizing, MaxGapZeros terminates dlog g iterations. Clearly, every
solution minimum size must contain least g rows.
Third, show MaxGapZeros finds optimal solution 4. input matrices one two columns, MaxGapZeros clearly finds solution minimum
size. remainder proof, show MaxGapZeros also finds minimum-size
solution input matrix contains three four columns. end, analyze
stepwise modification input matrix MaxGapZeros compare
stepwise modification input matrix following minimum-size solution.
multiset row vectors X, let A(X) denote matrix resulting
modification row vectors X A, is, replacing row vectors X
number all-1-rows. Furthermore, hXi denotes sequence row vectors
X hXii denotes ith element sequence.
analyze stepwise modification process follows: Let hRMGZ sequence
row vectors modified MaxGapZeros let hROPT arbitrary sequence
row vectors minimum size solution ROPT . Furthermore, let Ai matrix
ith row modification hRMGZ i, is, Ai := A({hRMGZ ii0 | i0 < i})
gj (Ai ) denotes gap value jth column matrix Ai . Now, = 1 |RMGZ |,
compare hRMGZ ii hROPT ii . Note hROPT ii run sequence
since show hRMGZ ii0 = hROPT ii0 , 1 i0 < i, clear hROPT
hRMGZ identical first 1 positions, either contain least elements
none. comparing hRMGZ ii hROPT ii , whenever hRMGZ ii 6= hROPT ii replace
reorder elements hROPT afterwards hRMGZ ii0 = hROPT ii0 , 1 i0 i, and,
invariant, hROPT still corresponds solution minimum size. implies
Ai = A({hRMGZ ii | i0 < i}) = A({hROPT ii | i0 < i}).
following, assume 0 hRMGZ ii0 = hROPT ii0 , i0 < i. two row
vectors r1 , r2 {0, 1}m write r1 r2 r1 [x] = 0 r2 [x] = 0, 1 x m.
easy see @i00 hRMGZ ii hROPT ii00 hRMGZ ii 6= hROPT ii00 ,
MaxGapZeros would selected hROPT ii00 instead hRMGZ ii already iteration i.
1 |hRMGZ i|, hRMGZ ii 6= hROPT ii , least one following four
cases occurs. Note case hRMGZ ii all-0s row subsumed Case 1.
429

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

Furthermore, three columns Case 2 also subsumed Case 1. Cases 2
4 implicitly assume Case 1 apply.
Case 1. i0 hROPT ii0 hRMGZ ii . i00 > hROPT ii00 = hRMGZ ii ,
swap ith i00 th element hROPT i. Otherwise, replace i0 th element
hROPT hRMGZ ii swap ith i0 th element hROPT i0 6= i.
Case 2. hRMGZ ii contains exactly three 0s. Without loss generality let hRMGZ ii
0s first three columns. implies last columns gap value
larger first three columns gap values, is, gx (Ai )
g4 (Ai ), x {1, 2, 3}. Since Case 1 apply, every position i0 holds
hROPT ii0 0 column 4, least one 1 column since
otherwise greedy algorithm would selected all-0-row hROPT ii0 step i.
Thus, g4 (Ai ) positions safely replace ith
element hROPT hRMGZ ii .
Case 3. hRMGZ ii contains exactly two 0s. Without loss generality, hRMGZ ii 0s
first two columns. Due design MaxGapZeros holds first two
columns gap values least large last two columns gap values, is,
gx (Ai ) gy (Ai ), x {1, 2}, {3, 4}. position i0 hROPT
hROPT ii0 also 0s first two columns, otherwise hRMGZ ii hROPT ii0 ,
possible since MaxGapZeros would selected hROPT ii0 instead
hRMGZ ii already iteration i. Thus, least g1 (Ai ) positions i1
hROPT ii1 containing 1 second column least g2 (Ai ) positions i2
hROPT ii2 containing 1 first column. Moreover, since Case 1
apply and, hence, hROPT ii0 6 hRMGZ ii every i0 > i, corresponding row
vectors least two 0s. g1 (Ai ) = g2 (Ai ), approximation guarantee
MaxGapZeros also needs dlog 4e g1 (Ai ) = g1 (Ai ) + g2 (Ai ) rows.
Thus, safely replace i0 th element hROPT hRMGZ ii0 i0 i.
g1 (Ai ) > g2 (Ai ), must position i0 hROPT ii0
contains 0 column {3, 4}, column already satisfied matrix
A({hROPT ii00 | i00 < i0 }). position hROPT ii containing two
0s: one 0 column one 0 column 1 2, replace th element
hROPT hRMGZ ii swap ith th element hROPT 6= i. Otherwise,
every position holds hROPT ii contains 0 column
hROPT ii contains exactly three 0: one 0 column 3, one 0 column 4, one 0
column 1 2. implies column 3 column 4 positive
gap matrix A({hROPT ii00 | i00 < i0 }). Thus, replace i0 element hROPT
hRMGZ ii swap ith i0 th element hROPT i0 6= i.
Case 4. hRMGZ ii contains exactly one 0. show case
two columns positive gap values Ai . Let j column hRMGZ ii
one 0. column j, let R0 (j) index set rows containing 0
column j. Consider column j 0 positive gap value. Ai contains rows
0s j j 0 , is, R0 (j ) R0 (j 0 ) = , otherwise greedy
algorithm would selected rows. Thus, gap values j j 0 must
one, implying maximum gap value one. matrix contains least
430

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

three columns maximum gap one, must row containing 0s
least two columns selected greedy algorithm.
Thus, two columns positive gap Ai . Since MaxGapZeros
optimal two columns, safely replace i0 th element hROPT
hRMGZ ii0 i0 i.
Finally, obtain minimum-size solution ROPT ROPT = RMGZ .
five-column input matrices algorithm may provide optimal
solution. example, optimal solution 5 6-matrix
0
0
0
0
1
1

0
0
1
1
0
1

0
1
0
1
0
1

1
0
1
1
0
0

1
1
0
1
0
0

contains two rows (row two three) algorithm may output three rows
possible solution since first three row vectors highest gain (1, 2). Note
first column gap 2 columns gap 1. MaxGapZeros decides
modify first row two rows, needs two rows satisfy
columns.
Theorems 7 8 show case four issues Lobbying solved
efficiently. contrary, parameterized number columns,
theoretical fixed-parameter tractability result; based famous theorem mathematical programming Lenstra (1983) improved Frank Tardos (1987)
Kannan (1987). Roughly speaking, says solving integer linear programs
number variables depending solely parameter p fixed-parameter tractable respect p. However, (worst-case) upper bound running time corresponding
algorithm impractical classification nature only. Nevertheless, experimented
practical usefulness subsequent ILP formulation (see Section 6).
Theorem 9. Lobbying fixed-parameter tractable respect parameter number
columns.
Proof. describe integer linear program (ILP) 2m variables solves
Lobbying.3 Then, Lobbying fixed-parameter tractable respect m,
ILP variables L input bits solved O(2.5+o() L) time (Kannan, 1987;
Frank & Tardos, 1987).
2m different rows binary matrix columns. Let r1 , . . . , rl
arbitrary ordering pairwise different rows A, 1 l let c(ri )
number occurrences ri . 1 l 1 j let Bj (ri ) = 1
jth column row ri value 0 and, otherwise, Bj (ri ) = 0. 1 l introduce
3. Dorn Schlotter (2012) already mentioned ILP Swap Bribery problem could
adapted Lobbying.

431

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

integer variable bi , 0 bi c(ri ); value bi indicates often one
modify row type ri . ILP formulated follows. Recall gj number
missing 1s make column j 1s 0s k number rows modify.
l
X

bi k,

(1)

i=1

0 bi c(ri )
gj

l
X

bi Bj (ri )

1 l,

(2)

1 j m.

(3)

i=1

Constraint (1) ensures k rows modified. Constraint (2) ensures
amount rows modified type ri available input matrix.
Constraint (3) ensures column j least gj rows 0-entry jth
position modified. Hence, ILP provides solution Lobbying k
modified rows.
Since 2t, fixed-parameter tractability (Theorem 9) implies following.
Corollary 2. Lobbying fixed-parameter tractable respect parameter maximum number zeros per row.
5.3 Dynamic Programming Columns Small Gap
use reduction proof Christian et al. (2007), immediately gain W[2]hardness result respect maximum gap value g Lobbying. Furthermore,
discussed Section 3.2, Lobbying LOGSNP-complete even g 1. So, reasonable
complexity-theoretic assumptions, neither NP-hard XP constant g.
section, prove tractability Lobbying respect parameter g combining
either number columns (Theorem 10) even maximum number
1s per row (Corollary 3).
Theorem 10. Lobbying solvable O((g + 1)m n2 m) time.
Proof. Let {0, 1}nm k N Lobbying input instance let g1 , g2 , . . . , gm
corresponding gap values A. solve problem via Dynamic Programming
employing boolean table [i, l, g1 , . . . , gm ], {0, . . . , n}, l {0, . . . , k},
gj {0, . . . , gj } j. entry [i, l, g1 , . . . , gm ] set True possible reduce
gap column j least gj modifying exactly l rows first rows A.
Otherwise set entry False. Clearly, (A, k) yes-instance Lobbying
[n, k, g1 , . . . , gm ] = True.
initialize table, set [0, 0, g1 , . . . , gm ] True gj = 0 j
False otherwise. compute entry [i, l, g1 , . . . , gm ] check two cases: First, set
[i, l, g1 , . . . , gm ] True [i 1, l, g1 , . . . , gm ] = True (treating case row
0 ]=
contained solution). Second, set [i, l, g1 , . . . , gm ] True [i1, l1, g10 , . . . , gm
True gj0 = gj row 1 column j gj0 = max{0, gj 1} row 0
column j. none two cases applies, set [i, l, g1 , . . . , gm ] = False.
432

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

Table (g + 1)m (k + 1) (n + 1) entries table entry computed
O(m) time, resulting overall running time O((g + 1)m k n m).
Finally, harvest fixed-parameter tractability result Lobbying
simply relating parameter values.
Corollary 3. Lobbying solvable O((g + 1)4s n2 + 16g m) time.
Proof. First, provide useful inequality (functions of) parameter values.
Count number 1s input matrix. Since row,
ns whole matrix. addition, least n/2 g
column and, hence, total number 1s least (n/2 g)m. follows
(n/2 g)m ns.
Now, employ derived inequality deduce fixed-parameter tractability
combined parameter (g, s). g n/4, nm/4 (n/2 g)m ns, hence 4s
use O((g + 1)m n2 ) = O((g + 1)4s n2 ) time algorithm Theorem 10.
Otherwise n < 4g solve problem brute force, testing possible subsets
rows modified O(2n m) = O(24g m) time.
5.4 Close Guarantee Small Gap
reasonable complexity-theoretic assumptions Lobbying neither XP
below-guarantee parameter k 0 :=d(n+1)/2ek (see Theorem 1) XP maximum
gap value g columns (see Theorem 3). However, using relations
parameters brute-force algorithm Proposition 2 show Lobbying
XP combined parameter (g, k 0 ). precisely, show Lobbying
fixed-parameter tractable respect k 0 g constant.
0

Theorem 11. Lobbying solvable O(m2g+1 22k ) time.
Proof. definition k 0 follows k + k 0 n/2. Furthermore,
logarithmic factor approximation (see Theorem 8) follows k g log m. Combining
gives n 2(g log + k 0 ). Thus, using brute-force algorithm Proposition 2,
0
0
Lobbying solvable O(2n m) = O(22glog 22k m) = O(m2g+1 22k ) time.
remains open whether Lobbying fixed-parameter tractable combined parameter (g, k 0 ) (not assuming g constant).

6. Experimental Evaluation Greedy ILP Algorithms
Recall consider number columns parameter currently
strongest support terms parameterized complexity analysis.
seldom exceeds 20 (Christian et al., 2007). Hence, section present experimental results obtained testing greedy heuristic (MaxGapZeros) ILP
formulation (ILP) Section 5.2 well slightly simpler greedy algorithm (MaxZeros) Erdelyi et al. (2007). Roughly speaking, whereas MaxZeros simply picks row
maximum number 0s, MaxGapZeros uses gain measure 0s columns higher
433

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

gap value given higher attention. Thus, comparing MaxGapZeros MaxZeros
evaluated effect refined gain measure.
evaluated efficiency solution quality greedy algorithms, comparing
exact solutions delivered ILP. Note heuristic Erdelyi et al. (2007)
designed solve general weighted variant Lobbying, hence,
expect MaxZeros outperform MaxGapZeros terms solution quality. However,
aware algorithm solving Lobbying compare with.
used Gurobi 5.0.1 (integer) linear program solver handle ILP formulation Lobbying given proof Theorem 9. Recall number variables
ILP formulation depends number different rows thus
upper-bounded 2m .
tested algorithms large set ( 3.3 105 matrices) random instances
instances generated actual voting records German parliament. used
two types random models controlled several density parameters,
determining fraction number 1s number 0s. row-oriented
model randomly chooses density row sets row entry random
equals 1 probability equal chosen density value. similar
way, column-oriented approach randomly chooses density column
generates entries column random using density value probability
generating 1. Section 6.1 contains detailed description random models.
Section 6.3 present experimental findings.
experiments performed Intel Xeon E5-1620 3.6GHz machine
64GB memory running Debian GNU/Linux 6.0 operating system. greedy
heuristics implemented C++. ILP implementation uses Gurobi4 5.0.1
Java API. source code including data generator freely available.5
6.1 Random Instance Generation
models, row-oriented column-oriented, process creating random
instance controlled two density parameters b 0 b 1. Subsequently,
describing two models detail, randomly choosing number always refers
random number generated using i.i.d. process uniform distribution.
6.1.1 Row-Oriented Model
certain values n, m, a, b b, row-oriented model creates binary
matrix {0, 1}nm follows. row i, chooses random number di
interval [a, b]. Then, 1 j m, entry Ai,j set 1 probability di . Using
row-oriented model, created instances combinations {0.1, 0.2, 0.3, 0.4}
b {0.5, 0.6, 0.65, 0.7, 0.8} + b < 1. Since expected fraction 1s row
di expected fraction 1s (a + b)/2, implying case + b 1
high fraction columns gaps zero, required + b < 1. Thus,
combination n m, created 13 instances according model. Herein,
started = 10 increased 10% step, rounding nearest
4. http://www.gurobi.com/
5. http://akt.tu-berlin.de/menue/software/

434

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

integer necessary (formally, dm 1.1e), larger 300. assigned n
110 equidistant values within [10, 991] (formally, n n + 9). Summarizing, 33
different values 110 different values n, obtaining total 47 190 instances
row-oriented model.
6.1.2 Column-Oriented Model
Here, create matrix {0, 1}nm fixed b, column columnoriented model chooses random number di [a, b]. Then, denoting maximum possible gap d(n+1)/2e gmax , model assigns 1s (1di )gmax many entries column i,
0 remaining entries. Observe ensures gap column di gmax
thus expected gap column ((a+b)/2)gmax . created instances combinations {0, 0.1, 0.2, 0.3, 0.4, 0.5} b {0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1}
b. Thus, combination n created 51 instances. Thereby,
started = 10 increased 10% step , rounding
nearest integer necessary (formally, dm 1.1e) long smaller
100. assigned n 110 equidistant values within [10, 991] (formally, n n + 9). Thus
21 different values 110 n, obtaining total 142 810 instances
column-oriented model.
discarded instances containing column gap zero. Furthermore,
discuss instances less 10 columns tested algorithms extremely
fast (less 0.01 seconds average) greedy heuristic computed optimal solutions
99% instances.
6.2 Real-World Data Generation
obtain data set representing realistic binary preferences politicians use welldocumented voting records German parliament, Bundestag. Votes issues
Bundestag anonymous recorded votes. Whenever party parliament
5% members request it, voters decision recorded together voters
name. generated instances recorded votes 2012 2013
freely available www.bundestag.de:
issue recorded vote became issue model.
several similar issues (for example similar amendments topic)
took last one.
member Bundestag became voter model. Bundestag
member show abstained voting assume opinion
consistent majority party. Bundestag member left
parliament period, collect votes. (This happened
twice.)
resulted matrix 67 columns 620 rows. Approximately half columns
small gap value (less 25) half gap values greater 90.
Roughly one third columns gap values greater 150. Even maximum
possible gap value 311 occurs twice.
435

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

6.2.1 Goal Lobby
Since lobby actions usually well-documented one cannot (easily) identify
voters bribed, decided guess goal lobby. Recall
model, 1 (resp. 0) column j row input matrix means voter agrees
(resp. disagrees) lobby respect issue j. Hence, get input matrices
model, need set issues lobby disagrees majority
voters. Issues goal lobby consistent majority voters
always ignored.
6.2.2 Test Series
performed three experiments, one randomly selected issues small gap values
(g < 30), one randomly selected issues high gap values (g > 90), one
randomly selected issues without restriction. number columns
{5, 10, . . . , 30} extracted 100 instances first two experiments.
{5, 10, . . . , 60} generated 100 instances last experiment. covers wide
range scenarios differ number issues lobby wants change well
amount changes issue needs reach majority approvals.
6.3 Results
evaluated experimental results concerning time efficiency and, greedy heuristics, additionally respect solution quality (closeness optimal solutions), is,
distance derived solutions optimal one.
evaluate efficiency fixed attribute values (e.g., number columns)
computed average running times corresponding instances. running times
greedy algorithms small (below 0.1 seconds average). get reliable
values ran greedy heuristics 20 times instance stored average value.
ILP algorithm solved 95% instances within five minutes. counted
running time remaining instances five minutes get lower bound
correct average running times ILP algorithm.
evaluate optimality computed percentage optimally solved instances
well average difference optimal number lobbied voters number
voters lobbied heuristic solution. following, denote distance
optimality.
6.3.1 Efficiency Row-Oriented Model
expected, heuristic algorithms much faster ILP algorithm. Whereas
heuristics needed less 0.1 seconds instances 300 columns
1000 rows, ILP needed ten seconds average instances
least 150 columns least 500 rows. See Figure 3 details. Somewhat surprisingly, MaxGapZeros turned faster MaxZeros instances
24 columns well instances least 100 rows. reason seems
MaxGapZeros produces smaller solutions MaxZeros allowing earlier termination
(see Figure 4).
436

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

101

running time seconds

101

100
100
101

101
102

102

103

0

50

100

150

200

250

0

300

100 200 300 400 500 600 700 800 900 1,000

number rows

number columns
MaxGapZeros

MaxZeros

ILP

Figure 3: Row-oriented model: Running time depending number columns
number rows, respectively.

10
100
9

distance optimality

%optimal solutions

90
80
70
60
50
40
30
20
10

8
7
6
5
4
3
2
1
0

0
0

50

100

150

200

250

300

0

50

100

150

200

250

300

number columns

number columns
MaxGapZeros

MaxZeros

Figure 4: Row-oriented model: Percentage optimal solutions average distance
optimal solution greedy algorithms, depending number
columns.

437

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

running time seconds

101
101
100

100

101

102

101

103

102

10

20

30

40

50

60

70

80

90

100

0

100 200 300 400 500 600 700 800 900 1,000

number columns
MaxGapZeros

number rows
MaxZeros

ILP

Figure 5: Column-oriented model: Running time depending number columns
number rows, respectively.

6.3.2 Optimality Row-Oriented Model
greedy algorithm (MaxGapZeros) performed well data set terms
solution size. 50% instances optimally solved, even
300 columns. contrast, simpler greedy algorithm (MaxZeros) could solve
instances optimally. distance optimality, MaxGapZeros results
average distance less one whereas average distance optimality
MaxZeros results exhibits logarithmic growth respect number issues
always greater two. See Figure 4 details.
6.3.3 Efficiency Column-Oriented Model
Similarly row-oriented model, heuristic algorithms extremely fast
tested instances. instances (which less 100 columns), MaxZeros
slightly faster MaxGapZeros difference average running time
MaxGapZeros MaxZeros decreased increasing number issues. See Figure 5
details.
6.3.4 Optimality Column-Oriented Model
Similarly row-oriented model, MaxGapZeros computed solutions relatively
close optimum. Whereas percentage instances 30 100
columns optimally solved MaxGapZeros slightly lower roworiented model, percentage instances optimally computed MaxZeros
twice high row-oriented model. contrast, distance optimality,
438

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

10
100
9

distance optimality

%optimal solutions

90
80
70
60
50
40
30
20
10

8
7
6
5
4
3
2
1
0

0
10

20

30

40

50

60

70

80

90

100

10

number columns

20

30

40

50

60

70

80

90

100

number columns

MaxGapZeros

MaxZeros

Figure 6: Column-oriented model: Percentage optimal solutions average distance
optimal solution greedy algorithms depending number
columns.

results column-oriented model behaved similarly results roworiented model. Again, average distance optimality MaxZeros results exhibits
logarithmic growth respect number issues always greater three,
average distance optimality MaxGapZeros results lower one
tested instances. See Figure 6 details.
6.3.5 Efficiency Real-World Data Set
Surprisingly, algorithms including ILP algorithm could solve every single instance
extremely fast. MaxZeros slightly faster MaxGapZeros even ILP algorithm
needed less 0.07 seconds instance. reason seems politicians
party often vote similarly different rows matrices and,
hence, ILP much less variables handle worst case (only 103
instead 620). expected, instances small maximum gap values could computed
(slightly) faster.
6.3.6 Optimality Real-World Data Set
Somewhat unexpectedly, MaxGapZeros could solve instances optimally. Recall
case random data instances similar sizes. contrast MaxGapZeros,
instances MaxZeros could find optimal solution. Especially instances
high gap values instances without restrictions gap values,
distance MaxZeross solution size optimal solution size quite large. See Figure 7
Figure 8 details. Interestingly, optimal solution size equals maximum gap
439

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

8
100

distance optimality

7

%optimal solutions

90

6

80

5

70

4

60

3

50
40

2

30

1

20
0
10
5

10

15

20

25

30

5

10

number columns

15

20

25

30

number columns

MaxGapZeros

MaxZeros

Figure 7: Real-world data, instances low gap values only: Percentage optimal solutions average distance optimal solution greedy algorithms
depending number columns.

100
100

distance optimality

90

%optimal solutions

90
80
70
60
50
40
30
20
10

80
70
60
50
40
30
20
10
0

0
0

10

20

30

40

50

0

60

10

20

30

40

50

60

number columns

number columns
MaxGapZeros

MaxZeros

Figure 8: Real-world data, instances low high gap values: Percentage optimal
solutions average distance optimal solution greedy algorithms depending number columns. results instances high
gap values similar.

440

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

value almost instances. Note cannot explanation tractability
since instances general still NP-hard compute; see reduction used
proof Theorem 1.
6.3.7 Conclusion
showed heuristics efficient synthetic random data reasonable
size, is, 300 columns 1000 rows. Whereas greedy heuristic
Erdelyi et al. (2007) computes solutions relatively far away optimum,
greedy algorithm computed optimal solutions instances. However, note
greedy algorithm directly designed solve Lobbying whereas algorithm Erdelyi
et al. (2007) designed general weighted variant Lobbying. Somewhat
unexpectedly, also exact ILP algorithm solved instances within five minutes.
Even instances 37 columns 100 rows optimally solved
ILP within five minutes.
data set based real-world data, algorithms behaved similar
synthetic case. greedy algorithm could solve instances optimally ILP algorithm could solve instances fast.

7. Conclusion
Lobbying studied fundamental matrix modification problem rich combinatorial structure.6 started exploiting structure terms number natural
parameterizations corresponding parameterized multivariate complexity analysis.
Table 1 Section 1 summarizes results. Indeed, space investigations could
extended introducing parameters also looking parameter combinations, time ultimate goal obtain (improved) fixed-parameter tractability
results (Komusiewicz & Niedermeier, 2012). far, results indicate making use
parameter number columns particularly promising albeit theoretical
fixed-parameter tractability result based integer linear programming could proven.
found well performing greedy algorithm turns deliver provably optimal results input matrices four columns. Based positive experimental
results, suggest algorithm current method choice solving also larger
Lobbying instances getting close optimal solutions.
methodological side, probably innovative contribution show
LOGSNP-completeness (Papadimitriou & Yannakakis, 1996) case input matrices
gap value 1 columns, is, situation lobby may hope
achieve goal low cost (meaning modified rows). result particular interest
since natural LOGSNP-complete problems known since seems
first use tool assessing parameterized complexity parameterized problems
XP class problems NP-hard even constant parameter values.
independent future interest studying parameterized complexity
problems.
6. recently, Lobbying useful assessing computational complexity matrix modification problem arising machine learning (Froese, van Bevern, Niedermeier, & Sorge, 2013).

441

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

future work, findings plain Lobbying problem may extended natural
variants generalizations. include
allow lobby partially influence voters (that is, rows may
changed all-1 rows),
head getting majority approvals certain (pre-specified) percentage
issues (columns),
consider modification operation adding voters (rows),
consider modification operation deleting voters (rows).
Moreover, interest extend multivariate studies scenarios probabilistic
weighted lobbying studied previous work (Binkele-Raible et al., 2014;
Erdelyi et al., 2007).
conclude concrete open questions future research Lobbying.
one replace integer linear program (see Theorem 9 Section 5.2) direct
(more efficient) combinatorial algorithm fixed-parameter tractability result
Lobbying parameterized number columns?
fixed-parameter tractability results parameter combinations (m, k), (m, g),
(m, s), (k, s), (g, s) theoretical nature onlycan made practical?
showed Lobbying fixed-parameter tractable respect k 0 g
constant. also fixed-parameter tractable combined parameter (g, k 0 )?
combined parameters (m, n), (t, n), (s, n) trivial polynomial-size
problem kernels Lobbying polynomials depending
respective parameters upper-bound input size. showed that, except
(m, k 0 ) remains open, fixed-parameter tractability results
polynomial-size problem kernels, unless NP coNP/poly.
possibility (provable) efficient effective preprocessing data reduction
Lobbying?
results adhere worst-case analysiswhat complexity Lobbying
average? findings greedy heuristic suggest reason
believe Lobbying computationally hard worst-case analysis suggests. situation similar recent studies concerning seemingly pathological NP-hardness manipulation good solvability experimental
results (Betzler, Niedermeier, & Woeginger, 2011; Davies, Katsirelos, Narodytska, &
Walsh, 2011; Davies, Narodytska, & Walsh, 2012; Walsh, 2011). thorough
investigation direction concerning Lobbying seems promising.

442

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

Acknowledgments
extended abstract work (without coauthor G.J. Woeginger) appeared
Proceedings 26th Conference Artificial Intelligence (AAAI 12) (Bredereck, Chen,
Hartung, Kratsch, Niedermeier, & Suchy, 2012). long version, exclusively
focusing plain Lobbying problem, provide numerous details
omitted extended abstract. Moreover, following new contributions:
prove LOGSNP-completeness case gap-1 instances. show greedy
algorithm already presented extended abstract logarithmic approximation
ratio. Finally, present experimental results greedy algorithms integer linear
program formulation Lobbying.
Robert Bredereck supported German Research Foundation (DFG), research
project PAWS (NI 369/10). Jiehua Chen supported Studienstiftung des Deutschen
Volkes. Main work done Stefan Kratsch Utrecht University supported Netherlands Organization Scientific Research (NWO), project KERNELS
(OND1336203), visiting TU Berlin, Germany. Ondrej Suchy supported DFG
Cluster Excellence Multimodal Computing Interaction (MMCI) DFG
project DARE (GU 1023/1-2). Main work done Universitat des
Saarlandes, Saarbrucken visiting TU Berlin, Germany. Gerhard J. Woeginger supported DIAMANT (a mathematics cluster Netherlands Organization Scientific
Research NWO). Main work done staying recipient Humboldt
Research Award TU Berlin.
grateful anonymous referees JAIR providing numerous insightful
remarks helped significantly improve paper. thank Kolja Stahl great
support extracting converting real-world data experiments.

References
Bartholdi III, J. J., Tovey, C. A., & Trick, M. A. (1992). hard control
election?. Mathematical Computer Modeling, 16 (8-9), 2740.
Baumeister, D., Erdelyi, G., & Rothe, J. (2011). hard bribe judges?
study complexity bribery judgment aggregation. Proceedings
2nd International Conference Algorithmic Decision Theory, Vol. 6992 LNCS,
pp. 115. Springer.
Betzler, N., Bredereck, R., Chen, J., & Niedermeier, R. (2012). Studies computational
aspects votinga parameterized complexity perspective. Multivariate Algorithmic Revolution Beyond, Vol. 7370 LNCS, pp. 318363. Springer.
Betzler, N., Niedermeier, R., & Woeginger, G. J. (2011). Unweighted coalitional manipulation Borda rule NP-hard. Proceedings 22nd International Joint
Conference Artificial Intelligence, pp. 5560. AAAI Press.
Binkele-Raible, D., Erdelyi, G., Fernau, H., Goldsmith, J., Mattei, N., & Rothe, J. (2014).
complexity probabilistic lobbying. Discrete Optimization, 11, 121.
443

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

Bodlaender, H. L. (2009). Kernelization: New upper lower bound techniques. Proceedings 4th International Workshop Parameterized Exact Computation,
Vol. 5917 LNCS, pp. 1737. Springer.
Bodlaender, H. L., Downey, R. G., Fellows, M. R., & Hermelin, D. (2009). problems
without polynomial kernels. Journal Computer System Sciences, 75 (8), 423434.
Bodlaender, H. L., Thomasse, S., & Yeo, A. (2011). Kernel bounds disjoint cycles
disjoint paths. Theoretical Computer Science, 412 (35), 45704578.
Bredereck, R., Chen, J., Hartung, S., Kratsch, S., Niedermeier, R., & Suchy, O. (2012).
multivariate complexity analysis lobbying multiple referenda. Proceedings
26th Conference Artificial Intelligence, pp. 12921298. AAAI Press.
Cai, L., Chen, J., Downey, R. G., & Fellows, M. R. (1997). Advice classes parameterized
tractability. Annals Pure Applied Logic, 84 (1), 119138.
Christian, R., Fellows, M., Rosamond, F., & Slinko, A. (2007). complexity lobbying
multiple referenda. Review Economic Design, 11 (3), 217224.
Davies, J., Katsirelos, G., Narodytska, N., & Walsh, T. (2011). Complexity algorithms
Borda manipulation. Proceedings 25th AAAI Conference Artificial
Intelligence, pp. 657662. AAAI Press.
Davies, J., Narodytska, N., & Walsh, T. (2012). Eliminating weakest link: Making
manipulation intractable?. Proceedings 26th AAAI Conference Artificial
Intelligence, pp. 13331339. AAAI Press.
Dom, M., Lokshtanov, D., & Saurabh, S. (2009). Incompressibility colors IDs.
Proceedings 36th International Colloquium Automata, Languages,
Programming, Vol. 5555 LNCS, pp. 378389. Springer.
Dorn, B., & Schlotter, I. (2012). Multivariate complexity analysis swap bribery. Algorithmica, 64 (1), 126151.
Downey, R. G., & Fellows, M. R. (2013). Fundamentals Parameterized Complexity. Texts
Computer Science. Springer.
Elkind, E., Faliszewski, P., & Slinko, A. (2011). Cloning elections: Finding possible
winners. Journal Artificial Intellligence Research, 42, 529573.
Elkind, E., Faliszewski, P., & Slinko, A. (2012). Clone structures voters preferences.
Proceedings 13th ACM Conference Electronic Commerce, pp. 496513.
ACM.
Erdelyi, G., Hemaspaandra, L. A., Rothe, J., & Spakowski, H. (2007). approximating
optimal weighted lobbying, frequency correctness versus average-case polynomial time. Proceedings 16th International Symposium Fundamentals
Computation Theory, Vol. 4639 LNCS, pp. 300311. Springer.
Erdelyi, G., Piras, L., & Rothe, J. (2011). complexity voter partition Bucklin
fallback voting: Solving three open problems. Proceedings 10th International Joint Conference Autonomous Agents Multiagent Systems, pp. 837844.
IFAAMAS.
444

fiA Multivariate Complexity Analysis Lobbying Multiple Referenda

Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. A. (2009). hard bribery
elections?. Journal Artificial Intelligence Research, 35, 485532.
Fellows, M. R., Jansen, B. M., & Rosamond, F. (2013). Towards fully multivariate algorithmics: Parameter ecology deconstruction computational complexity.
European Journal Combinatorics, 34 (3), 541566.
Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory. Springer.
Fortnow, L., & Santhanam, R. (2011). Infeasibility instance compression succinct
PCPs NP. Journal Computer System Sciences, 77 (1), 91106.
Frank, A., & Tardos, E. (1987). application simultaneous diophantine approximation
combinatorial optimization. Combinatorica, 7 (1), 4965.
Froese, V., van Bevern, R., Niedermeier, R., & Sorge, M. (2013). parameterized complexity analysis combinatorial feature selection problems. Proceedings
38th International Symposium Mathematical Foundations Computer Science,
Vol. 8087 LNCS, pp. 445456. Springer.
Gabow, H. N. (1983). efficient reduction technique degree-constrained subgraph
bidirected network flow problems. Proceedings 15th Annual ACM Symposium
Theory Computing, pp. 448456. ACM.
Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA Guide
Theory NP-Completeness. W. H. Freeman Company.
Goldsmith, J., Levy, M. A., & Mundhenk, M. (1996). Limited nondeterminism. SIGACT
News, 27 (2), 2029.
Gottlob, G., Scarcello, F., & Sideri, M. (2002). Fixed-parameter complexity AI
nonmonotonic reasoning. Artificial Intelligence, 138 (1-2), 5586.
Gottlob, G., & Szeider, S. (2008). Fixed-parameter algorithms artificial intelligence,
constraint satisfaction database problems. Computer Journal, 51 (3), 303
325.
Guo, J., & Niedermeier, R. (2007). Invitation data reduction problem kernelization.
SIGACT News, 38 (1), 3145.
Kannan, R. (1987). Minkowskis convex body theorem integer programming. Mathematics Operations Research, 12 (3), 415440.
Karp, R. M. (1972). Reducibility among combinatorial problems. Complexity Computer Computations, pp. 85103. Plenum Press.
Komusiewicz, C., & Niedermeier, R. (2012). New races parameterized algorithmics.
Proceedings 37th Mathematical Foundations Computer Science, Vol. 7464
LNCS, pp. 1930. Springer.
Lenstra, H. W. (1983). Integer programming fixed number variables. Mathematics
Operations Research, 8 (4), 538548.
Mahajan, M., & Raman, V. (1999). Parameterizing guaranteed values: MaxSat
MaxCut. Journal Algorithms, 31 (2), 335354.
Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.
445

fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger

Niedermeier, R. (2010). Reflections multivariate algorithmics problem parameterization. Proceedings 27th International Symposium Theoretical Aspects
Computer Science, Vol. 5 Leibniz International Proceedings Informatics, pp.
1732.
Papadimitriou, C. H., & Yannakakis, M. (1996). limited nondeterminism complexity V-C dimension. Journal Computer System Sciences, 53 (2),
161170.
Sandholm, T., Suri, S., Gilpin, A., & Levine, D. (2002). Winner determination combinatorial auction generalizations. Proceedings First International Conference
Autonomous Agents Multiagent Systems, pp. 6976. ACM.
Schlotter, I., Elkind, E., & Faliszewski, P. (2011). Campaign management approvaldriven voting rules. Proceedings 25th AAAI Conference Artificial Intelligence, pp. 726731. AAAI Press.
Schrijver, A. (2003).
Springer.

Combinatorial Optimization: Polyhedra Efficiency, Vol. A.

Szeider, S. (2011). Limits preprocessing. Proceedings 25th AAAI Conference
Artificial Intelligence, pp. 9398. AAAI Press.
Walsh, T. (2011). computational complexity barrier manipulation?. Annals
Mathematics Artificial Intelligence, 62 (1-2), 726.
Yap, C.-K. (1983). consequences non-uniform conditions uniform classes. Theoretical Computer Science, 26 (3), 287300.

446

fiJournal Artificial Intelligence Research 50 (2014) 573601

Submitted 12/13; published 07/14

False-Name Manipulation Weighted Voting Games Hard
Probabilistic Polynomial Time
Anja Rey
Jrg Rothe

REY @ CS . UNI - DUESSELDORF. DE
ROTHE @ CS . UNI - DUESSELDORF. DE

Institut fr Informatik
Heinrich-Heine-Universitt Dsseldorf
40225 Dsseldorf
Germany

Abstract
False-name manipulation refers question whether player weighted voting game
increase power splitting several players distributing weight among
false identities. Relatedly, beneficial merging problem asks whether coalition players
increase power weighted voting game merging weights. problems
whether merging splitting players weighted voting games beneficial terms
ShapleyShubik normalized Banzhaf index, merely NP-hardness lower bounds known,
leaving question exact complexity open. ShapleyShubik probabilistic Banzhaf index, raise lower bounds hardness PP, probabilistic polynomial
time, class considered far larger class NP. power indices, provide
matching upper bounds beneficial merging and, whenever new players weights given,
also beneficial splitting, thus resolving previous conjectures affirmative. Relatedly,
consider beneficial annexation problem, asking whether single player increase power
taking players weights. known annexation never disadvantageous
ShapleyShubik index, beneficial annexation NP-hard normalized Banzhaf
index. show annexation never disadvantageous probabilistic Banzhaf index either, ShapleyShubik index probabilistic Banzhaf index show
NP-complete decide whether annexing another player advantageous. Moreover, propose general framework merging splitting applied different classes
representations games.

1. Introduction
Algorithmic game theory studied intensely recent years (Nisan, Roughgarden, Tardos, &
Vazirani, 2007; Chalkiadakis, Elkind, & Wooldridge, 2011). paper focuses algorithmic
complexity-theoretic aspects problems cooperative game theory. central question
studied whether merging splitting players coalitional game (with transferable utilities)
raise power game. Power indices measure influential player forming winning
coalitions simple games. ShapleyShubik Banzhaf power indices prominent
among measures (Shapley & Shubik, 1954; Banzhaf III, 1965). Roughly speaking, simple
games indicate, respectively, many orders support probability
player swing outcome coalition joining leaving it.
Weighted voting games important class succinctly representable, simple games.
used model cooperation among players scenarios player assigned
weight, coalition players wins joint weight meets exceeds given
c
2014
AI Access Foundation. rights reserved.

fiR EY & ROTHE

quota. Typical real-world applications weighted voting games include decision-making legislative bodies (e.g., parliamentary voting) shareholder voting (for concrete applications literature pointers see Chalkiadakis et al., 2011). particular, algorithmic
complexity-theoretic properties problems related weighted voting studied depth
(for overview see, e.g., Elkind, Chalkiadakis, & Jennings, 2008; Elkind, Goldberg, Goldberg, &
Wooldridge, 2009; Bachrach, Elkind, Meir, Pasechnik, Zuckerman, Rothe, & Rosenschein, 2009;
Zuckerman, Faliszewski, Bachrach, & Elkind, 2012; Elkind, Pasechnik, & Zick, 2013; Chalkiadakis
et al., 2011).
weighted voting games, Bachrach Elkind (2008) first study complexity
false-name manipulation: possible player increase power splitting several
players distributing weight among them? player may incentive manipulate
game via introducing false names. Relatedly, also ask whether merging weights
help two players weighted voting game increase power.
PI-B ENEFICIAL ERGE
open question

PI-B ENEFICIAL PLIT
NP-hard (ShapleyShubik
index, = 2) *

PI-A NNEXATION
never disadv. (Shapley
Shubik index) #

NP-hard (ShapleyShubik
index)

never disadv. (probabilistic Banzhaf index)

PP (ShapleyShubik index, kSk = 2)

NP-complete (kSk = 1)

P (probabilistic Banzhaf
index, kSk = 2)

P (probabilistic Banzhaf
index, = 2)

PP-complete

PP-hard






#

NP-hard

(Bachrach & Elkind, 2008)
(Aziz & Paterson, 2009)
(Aziz, Bachrach, Elkind, & Paterson, 2011)
(Faliszewski & Hemaspaandra, 2009)
paper
(Felsenthal & Machover, 1995)

Table 1: Overview history complexity results beneficial merging, splitting, annexation probabilistic Banzhaf index ShapleyShubik index. Key: kSk denotes
size merging coalition number players given player splits into.

Table 1 gives overview development problems complexity results
power indices studied here, probabilistic Banzhaf index ShapleyShubik index,
briefly elaborate now. Merging extending results Bachrach Elkind
(2008) Aziz Paterson (2009), Aziz et al. (2011) particular study problem whether
574

fiFALSE -NAME ANIPULATION WVG H ARD PP

merging splitting players weighted voting games beneficial terms ShapleyShubik
index (Shapley, 1953; Shapley & Shubik, 1954) normalized Banzhaf index (Banzhaf III,
1965) (see Section 2 formal definitions). results, however, provide merely NP-hardness
lower bounds. Aziz et al. (2011, p. 72, Remark 13) note quite possible problems
NP (and thus NP-complete). Faliszewski Hemaspaandra (2009) provide
best known upper bound beneficial merging problem two players respect
ShapleyShubik index: contained class PP, probabilistic polynomial time,
considered far larger class NP, conjecture problem PP-complete.
observe arguments give PP upper bound beneficial merging also terms
probabilistic Banzhaf index.1 contrast normalized Banzhaf index Shapley
Shubik index, show probabilistic Banzhaf index problems raising power
merging splitting P coalitions size two split two players, respectively.
Furthermore, bridge gap NP-hardness lower bound PP upper bound
proving beneficial merging splitting (if new weights given problem instance) PP-complete problems ShapleyShubik probabilistic Banzhaf index.
Beneficial splitting general (i.e., number new false identities given, actual
weights) PP-hard two indices. Thus, none six problems NP, unless
polynomial hierarchy collapses first level, considered highly unlikely.
Felsenthal Machover (1995) distinguish two types merging, voluntarily involuntarily, show latter, bloc two players (a.k.a. annexation one player another),
never disadvantageous ShapleyShubik index, disadvantageous normalized Banzhaf index. latter index, Aziz et al. (2011) show NP-hard decide
whether player benefit annexing players. show NP-complete decide
whether annexing another player advantageous ShapleyShubik index, well
probabilistic Banzhaf index. also show annexation never disadvantageous
probabilistic Banzhaf index, thus behaves like ShapleyShubik index regard.
contribution paper propose general framework merging splitting applied various classes representations games. Introducing new properties
merging splitting functions, consistency independence, particular satisfied
standard merging splitting functions weighted voting games, generalize P
results probabilistic Banzhaf index. one hand, properties desirable
design merging splitting function; hand, approach axiomatic
evaluation functions. analysis properties interesting task future
work. example applying general framework concrete class games,
consider threshold network flow games hypergraphs, model adapted threshold
network flow games introduced Bachrach Rosenschein (2009). unanimity games
respect probabilistic Banzhaf index, show splitting always disadvantageous neutral, whereas merging neutral size-two coalitions, yet advantageous coalitions least
three players. strongly contrasts results Aziz et al. (2011) showing merging
always disadvantageous splitting always advantageous normalized Banzhaf index
unanimity weighted voting games. two examples different properties
game restrictions caused certain representation lead different behavior consid1. Note arguments cannot transferred immediately corresponding problem normalized
Banzhaf index.

575

fiR EY & ROTHE

ering merging splitting (for overview different classes representations games see,
example, Shoham & Leyton-Brown, 2009).

2. Preliminaries
start providing needed concepts notation cooperative game theory complexity theory.
2.1 Basic Notions Cooperative Game Theory
need following concepts cooperative game theory, see, e.g., textbooks
Chalkiadakis et al. (2011) Peleg Sudhlter (2003).
coalitional game transferable utilities, G = (N, v), consists set N = {1, . . . , n}
players (or, synonymously, agents) coalitional function v : P(N) R v(0)
/ = 0,
P(N) denotes power set N. consider different classes games certain properties.
example, coalitional game monotonic v(B) v(C) whenever B C coalitions B,C N,
simple monotonic v : P(N) {0, 1} maps coalition C N value
indicates whether C successful (i.e., C wins: v(C) = 1) (i.e., C loses: v(C) = 0),
require grand coalition N always winning (i.e., v(N) = 1).
Since number coalitions exponential number players, specifying coalitional
games listing values coalitional function would require exponential space. algorithmic purposes, however, important games represented succinctly. Weighted
voting games (a.k.a. weighted threshold games) important class simple games
compactly representable (Bilbao, Fernndez, Jimnez, & Lpez, 2002). games, player
given weight, coalition players successful sum weights
reaches exceeds given threshold, called quota. Formally, weighted voting game (WVG)
G = (w1 , . . . , wn ; q) consists quota q N nonnegative integer2 weights wi , 1 n,
wi ith players weight. coalition C N, letting w(C) denote iC wi , C wins
w(C) q, loses otherwise. Requiring quota satisfy 0 < q w(N) ensures
empty coalition loses grand coalition wins. Weighted voting games intensely
studied computational complexity point view, see, e.g., work Elkind et al. (2009)
book Chalkiadakis et al. (2011, ch. 4) overview.
weighted majority game (WMG) special case WVG quota set
q = bw(N)/2c + 1. WVGs compactly representable, although fully expressive (for simple
game cannot represented WVG see, e.g., Chalkiadakis et al., 2011, Example 4.17).
precisely, every simple game represented k-weighted voting game,
intersection k weighted voting games; smallest k dimension simple game;
weighted voting games fully expressive class one-dimensional simple games
(again, see book Chalkiadakis et al. (2011) details).
coalitional game G = (N, v), let dG (C, i) = v(C {i}) v(C) marginal contribution
player N coalition C N r {i}. simple game, player called pivotal (or
crucial critical) coalition C N r {i} C {i} successful, C not.
dG (C, i) = 1 player pivotal C, dG (C, i) = 0 otherwise. term generalized
nonsimple games, referring player pivotal C dG (C, i) > 0. power index measures
2. See work Chalkiadakis et al. (2011, Thm. 4.2) nonnegative integer weights quotas may assumed.

576

fiFALSE -NAME ANIPULATION WVG H ARD PP

players influence simple game. Banzhaf III (1965), rediscovered notion originally
introduced Penrose (1946), defined raw Banzhaf power index
Banzhaf (G , i) =



dG (C, i)

CNr{i}

game G = (N, v) player N. simple game, indicates number coalitions
player pivotal for. However, since ratios indices important
magnitudes, useful normalize them. fact, two different ways normalization
proposed Banzhaf index.
original definition normalized Banzhaf power index (Banzhaf III, 1965), raw
Banzhaf index given player divided sum players raw Banzhaf indices:
Banzhaf(G , i) =

Banzhaf (G , i)
,
nj=1 Banzhaf (G , j)

players normalized Banzhaf indices add one. index analyzed
detail Dubey Shapley (1979), introduce alternative normalization, divides
raw Banzhaf index given player total number coalitions without player
dub probabilistic Banzhaf power index:
Banzhaf(G , i) =

Banzhaf (G , i)
.
2n1

Intuitively, index measures probability player pivotal possible coalition.
Based comprehensive analysis comparing various mathematical properties two power
indices, Dubey Shapley (1979, p. 102) view probabilistic Banzhaf index many
respects natural normalized Banzhaf index. particular, probabilistic Banzhaf
index satisfies four fundamental axioms: (1) symmetry,3 (2) dummy player,4 (3) additivity,5
(4) property call valuation.6 Neither valuation additivity satisfied normalized
Banzhaf index. beyond purpose paper give full explanation axioms,
refer reader work Dubey Shapley (1979) careful, detailed discussion.
normalized Banzhaf index lacks fourth axiom, Dubey Shapley (1979, Footnote 21)
conclude: may taken initial sign trouble normalization [of normalized Banzhaf index]. also note probabilistic Banzhaf index better behaved
analyzing convergence (Dubey & Shapley, 1979, p. 116). Also, normalized Banzhaf index
subject so-called bloc paradox (see Felsenthal & Machover, 1995), is, player lose
power taking another players weight. probabilistic Banzhaf index paradox
doesnt hold. (See Sections 3 4 computational complexity annexation problem.)
hand, normalized Banzhaf power index advantages well, depending
setting one considers. Aziz et al. (2011, p. 61) argue that: Although probabilistic
3. game G , Banzhaf(G , i) = Banzhaf(G , j) whenever j symmetric, i.e., v(C {i}) = v(C { j})
coalitions C N r {i, j}.
4. game G , Banzhaf(G, i) = 0 whenever dummy player, i.e., v(C {i}) = v(C) coalition C N.
5. two games G1 = (N, v1 ) G2 = (N, v2 ), Banzhaf(G1 + G2 , i) = Banzhaf(G1 , i) + Banzhaf(G2 , i)
players N, G1 + G2 = (N, v1 + v2 ) defined via (v1 + v2 )(C) = v1 (C) + v2 (C) coalitions C N.
6. two simple games G1 = (N, v1 ) G2 = (N, v2 ), holds Banzhaf(Gv1 v2 , i) + Banzhaf(Gv1 v2 , i) =
Banzhaf(G1 , i) + Banzhaf(G2 , i) N, games Gv1 v2 = (N, v1 v2 ) Gv1 v2 = (N, v1 v2 )
defined (v1 v2 )(C) = max(v1 (C), v2 (C)) (v1 v2 )(C) = min(v1 (C), v2 (C)) coalitions C N.

577

fiR EY & ROTHE

Banzhaf index useful measuring actual probability influencing decision,
fit framework using power indices share resources power, probabilistic
Banzhaf index normalized. Here, normalization done respect number players/coalitions, makes games different numbers players better comparable. Due
normalization respect players game, monotonic games normalized Banzhaf
index yields imputation (i.e., payoff vector (Banzhaf(G , 1), Banzhaf(G , 2), . . . , Banzhaf(G , n))
satisfying efficiency, ni=1 Banzhaf(G , i) = v(N), individual rationality, Banzhaf(G , i) v({i})
N), whereas probabilistic Banzhaf index efficient.
unique imputation satisfying four axioms mentioned above, based Shapley
Shubik power index (Shapley & Shubik, 1954), describes marginal contributions
player possible coalitions respect order players enter coalitions:
ShapleyShubik (G , i) =

kCk! (n 1 kCk)! dG (C, i),


CNr{i}

normalized

ShapleyShubik (G , i)
.
n!
coalitional games, also known Shapley value (Shapley, 1953).
Felsenthal Machover (2005, 1995) carefully discuss differences power
indices, refer reader work.
ShapleyShubik(G , i) =

2.2 Basic Notions Computational Complexity Theory
assume reader familiar basic notions complexity theory complexity classes P (deterministic polynomial time) NP (nondeterministic polynomial time),
p
polynomial-time many-one reducibility, denoted , notions hardness comp
pleteness (of decision problems complexity classes) respect . background
details, see, e.g., textbooks Garey Johnson (1979), Papadimitriou (1995), Rothe
(2005).
Valiant (1979) introduces #P class functions give number solutions
instances NP problems. decision problem NP, denote function #A.
example, letting SAT denote satisfiability problem propositional logic, #SAT denotes
function mapping boolean formula number truth assignments satisfying .
several notions reducibility functional problems and, consequently, several notions
hardness completeness complexity classes functions #P. Let f g two
functions mapping N. say f many-one-reduces g exist two polynomialtime computable functions, , x , f (x) = (g((x))). notion
functional many-one reducibility due Zank (1991); analogue (polynomial-time)
many-one reducibility sets. special case identity yields parsimonious
reducibility, preserves number solutions: say f parsimoniously reduces g
exists polynomial-time computable function x , f (x) = g((x)).
Intuitively, parsimonious reductions preserve number solutions (for detailed discussion
functional reducibilities see Faliszewski & Hemaspaandra, 2009). say g #P-parsimonioushard every function f #P parsimoniously reduces g. g #P-parsimonious-hard g
#P, g #P-parsimonious-complete. notions #P-many-one-hardness #P-many-onecompleteness defined analogously. known that, given WVG G player i, computing
578

fiFALSE -NAME ANIPULATION WVG H ARD PP

raw Banzhaf index #P-parsimonious-complete (Prasad & Kelly, 1990), whereas computing
raw ShapleyShubik index (Faliszewski & Hemaspaandra, 2009), although #P-manyone-complete. recent #P-completeness results, refer work Aziz, Brandt,
Brill (2013).
Gill (1977) introduces class PP (probabilistic polynomial time) contains decision
problems X exist function f #P polynomial p instances x,
x X f (x) 2 p(|x|)1 . easy see NP PP; fact, PP considered
far larger class NP, due Todas theorem (1991): PP least hard (in terms
polynomial-time Turing reductions) problem polynomial hierarchy (i.e., PH PPP ).
NPPP , second level Wagners counting hierarchy (1986), class problems solvable
NP machine access PP oracle. Mundhenk, Goldsmith, Lusena, Allender (2000)
identify NPPP -complete problems related finite-horizon Markov decision processes. Littman,
Goldsmith, Mundhenk (1998) obtain NPPP -completeness results analyzing variant
satisfiability problem questions related probabilistic planning.

3. Definition Beneficial Merging, Splitting, Annexation
Aziz et al. (2011) introduce merging splitting operations WVGs. use following
notation. Given WVG G = (w1 , . . . , wn ; q) nonempty7 coalition {1, . . . , n}, let G&S =
(w(S), w j1 , . . . , w jnkSk ; q) { j1 , . . . , jnkSk } = N r denote new WVG players
merged one new player weight w(S).8 power index PI, beneficial
merging problem defined follows.
PI-B ENEFICIAL ERGE
Given:
Question:

WVG G = (w1 , . . . , wn ; q) nonempty coalition {1, . . . , n}.
true PI(G&S , 1) > PI(G , i)?

Similarly, given WVG G = (w1 , . . . , wn ; q), player i, integer 2, define set
WVGs Gim = (w1 , . . . , wi1 , wi+1 , . . . , wn , wn+1 , . . . , wn+m ; q) weight wi split
new players n + 1, . . . , n + weights wn+1 , . . . , wn+m mj=1 wn+ j = wi . (Note
set WVGs Gim , since might several possibilities distributing weight
wi new players n + 1, . . . , n + satisfying mj=1 wn+ j = wi .)
distinguish two different splitting problems.9 First, power index PI, consider
problem weighted voting game, player i, number false identities splits
given problem instance, weights new players:
PI-B ENEFICIAL PLIT
Given:
Question:

WVG G = (w1 , . . . , wn ; q), player i, integer 2.
possible split new players n + 1, . . . , n + weights wn+1 , . . . , wn+m
satisfying mj=1 wn+ j = wi new WVG, call Gim , holds
mj=1 PI(Gim , n + j) > PI(G , i)?

7. omit empty coalition, since would slightly change idea problem.
8. Note players order doesnt matter considering normalized probabilistic Banzhaf index.
9. distinction wouldnt make sense beneficial merging annexation.

579

fiR EY & ROTHE

mentioned above, instance (G , i, m) PI-B ENEFICIAL PLIT, might various
ways distributing weight false identities, giving rise various new games Gim .
second (more special) variant problem consider, new players weights given
explicitly problem instance (and thus number false identities given implicitly).
case, one unique new game Gim , splitting inverse function merging.
use PI-B ENEFICIAL PLIT denote general problem without explicitly given
weights, explicitly mention whenever speak restricted variant.
problems deal voluntary actions players, Felsenthal Machover (1995)
study question whether possible player change power taking another
players weight without players consent. introduce bloc paradox, stating
possible lose power annexing another players weight. instance, normalized Banzhaf
index subject paradox. ShapleyShubik index, Felsenthal Machover show
annexation never disadvantageous. Nevertheless, one still ask question whether
fact advantageous. following problem studied Aziz et al. (2011). Let PI
power index.
PI-B ENEFICIAL NNEXATION
Given:
Question:

WVG G = (w1 , . . . , wn ; q), player N, coalition {1, . . . , n} r {i}.
true PI(G&(S{i}) , 1) > PI(G , i)?

particular, Aziz et al. (2011) show NP-hard decide whether annexation beneficial
normalized Banzhaf index, respect power index always beneficial
player annex another player larger weight. also introduce annexation
nonmonotonicity paradox, says sometimes useful player annex
another player small weight annex another player large weight.
goal paper classify problems terms complexity
ShapleyShubik probabilistic Banzhaf index. First, since allow players zero weight,
analysis beneficial splitting problem requires another simple fact, use
upcoming proofs Theorems 4.7 4.12.
Lemma 3.1. probabilistic Banzhaf index ShapleyShubik index, given
weighted voting game, adding player weight zero change original players
power indices, new players power index zero.
proof Lemma 3.1 straightforward therefore omitted.

4. Complexity Beneficial Merging, Splitting, Annexation Weighted Voting
Games
Aziz et al. (2011) analyze problems ShapleyShubik-B ENEFICIAL ERGEand ShapleyShubikB ENEFICIAL PLIT well Banzhaf-B ENEFICIAL ERGE Banzhaf-B ENEFICIAL PLIT
terms complexity. provide NP-hardness lower bounds, leave open whether
problems NP. Indeed, Aziz et al. (2011, p. 72, Remark 13) note quite possible
problems NP, raises natural question: upper bounds?
Faliszewski Hemaspaandra (2009) establish upper bound restriction beneficial
merging problem weighted voting games originally proposed Bachrach Elkind
580

fiFALSE -NAME ANIPULATION WVG H ARD PP

(2008) (Can two players increase joint ShapleyShubik index via merging?): problem complexity class PP. paper, Faliszewski Hemaspaandra study problem
PI-P OWER C OMPARE weighted voting games, PI power index. prove PPcompleteness problem probabilistic Banzhaf ShapleyShubik index.
section prove beneficial merging splitting PP-hard, provide matching upper bounds beneficial merging splitting (the latter variant new players
weights given), ShapleyShubik probabilistic Banzhaf index.
4.1 Probabilistic Banzhaf Power Index
beneficial merging problem coalition size 2 beneficial splitting problem
= 2 false identities trivially decided polynomial time probabilistic Banzhaf
index, since sum power (in terms index) two players always equal power
player obtained merging them.
Proposition 4.1. Let G weighted voting game {1, . . . , n} coalition players.
1. Banzhaf-B ENEFICIAL ERGE P instances (G , S) kSk = 2.
2. Banzhaf-B ENEFICIAL PLIT P instances (G , i, 2).
Proof. Let G = (w1 , . . . , wn ; q) weighted voting game. Without loss generality (see Footnote 8), let = {1, n}. obtain new game G&S = (w1 + wn , w2 , . . . , wn1 ; q), first
player new player merging S. Letting vG vG&S denote corresponding coalitional functions, holds
Banzhaf(G&S , 1) (Banzhaf(G , 1) + Banzhaf(G , n))
!
1
= n2
(vG&S (C {1}) vG&S (C))
2
C{2,...,n1}


=

1
2n1
1

2n1

!



(vG (C {1}) vG (C)) +

C{2,...,n}





(vG (C {n}) vG (C))

C{1,...,n1}

(2(vG&S (C {1}) vG&S (C))

C{2,...,n1}

(vG (C {1}) vG (C)) (vG (C {1, n}) vG (C {n}))
!
(vG (C {n}) vG (C)) (vG (C {n, 1}) vG (C {1})))
=

1
2n1

!



(2vG&S (C {1}) 2vG (C {1, n}) + 2vG (C) 2vG&S (C))

C{2,...,n1}

case splitting, similarly holds
Banzhaf(Gn2 , n + 1) + Banzhaf(Gn2 , n + 2) Banzhaf(G , n) = 0
581

= 0.

fiR EY & ROTHE

weighted voting game G = (N, v), = 2, and, without loss generality, player n G splitting
players n + 1 n + 2 new game Gn2 .
q

Although may seem Proposition 4.1 implied merging (and splitting) never
beneficial regarding index, cannot generalized merging (or splitting into)
two players, repeatedly applying result pairs players step step. example,
soon two players merge, third players probabilistic Banzhaf index might already changed
new game, merging another player subsequent step. Suppose three players
{1, 2, 3} want merge game G . Let Bi = Banzhaf(G , i), 1 3, original probabilistic
Banzhaf indices. Let B common Banzhaf index merge. merging first two
players, let B01 B03 indices {1, 2} 3, respectively. Then, due Proposition 4.1, B =
B01 +B03 = B1 +B2 +B03 . Hence, B > B1 +B2 +B3 B03 > B3 . is, probabilistic
Banzhaf index, beneficial merging three players boils comparing index one player
two gamesthe original game one two players merged.
two arbitrary games, result PI-P OWER C OMPARE Faliszewski Hemaspaandra (2009)
would applied. Here, however, indices need compared two closely related games;
requires different proof. Indeed, next show far harder (unless polynomial
hierarchy collapses first level) decide whether merging three players beneficial terms
probabilistic Banzhaf index two players. use following result due
Faliszewski Hemaspaandra (2009, Lemma 2.3).

Lemma 4.2 (Faliszewski & Hemaspaandra, 2009). Let F #P-parsimonious-complete function. problem C OMPARE-F = {(x, y) | F(x) > F(y)} PP-complete.

well-known NP-complete problem UBSET UM (which special variant K NAP problem) asks, given sequence (a1 , . . . , ) positive integers positive integer q,
exist x1 , . . . , xn {0, 1} ni=1 xi ai = q? known #S UBSET UM #Pparsimonious-complete (for parsimonious reductions #3-SAT via #E XACT C B 3-S ETS
#S UBSET UM see, e.g., Hunt, Marathe, Radhakrishnan, & Stearns, 1998; Papadimitriou, 1995).
Hence, Lemma 4.2, following.
SACK

Corollary 4.3. C OMPARE-#S UBSET UM PP-complete.
p

goal provide -reduction C OMPARE-#S UBSET UM Banzhaf-B ENEFICIAL ERGE. However, make reduction work, useful consider two restricted variants C OMPARE-#S UBSET UM, denote C OMPARE-#S UBSET UM-R C OM PARE-#S UBSET UM -RR, show PP-hardness, reduce C OMPARE-#S UBSET UM -RR
Banzhaf-B ENEFICIAL ERGE. done Lemmas 4.4 4.5 Theorem 4.6.
restricted variants C OMPARE-#S UBSET UM may assume, without loss generality,
target value q related #S UBSET UM instance ((a1 , . . . , ), q) satisfies 1 q 1,
= ni=1 ai .
582

fiFALSE -NAME ANIPULATION WVG H ARD PP

C OMPARE -#S UBSET UM -R
Given:
Question:

sequence = (a1 , . . . , ) positive integers two positive integers q1 q2
1 q1 , q2 1, = ni=1 ai .
number subsequences summing q1 greater number
subsequences summing q2 , is, hold
#S UBSET UM((a1 , . . . , ), q1 ) > #S UBSET UM((a1 , . . . , ), q2 )?
p

Lemma 4.4. C OMPARE-#S UBSET UM C OMPARE-#S UBSET UM-R.
Proof. Given instance (X,Y ) C OMPARE-#S UBSET UM, X = ((x1 , . . . , xm ), qx ) =
((y1 , . . . , yn ), qy ), construct C OMPARE-#S UBSET UM-R instance (A, q1 , q2 ) follows. Let =

i=1 xi define = (x1 , . . . , xm , 2y1 , . . . , 2yn ), q1 = qx , q2 = 2qy . construction
obviously achieved polynomial time.
holds integers sum qx 1 contain multiples
2, thus #S UBSET UM(A, q1 ) = #S UBSET UM((x1 , . . . , xm ), qx ). hand, q2 cannot
obtained adding xi s, since would yield non-zero remainder modulo 2,

i=1 xi = small. Thus, holds #S UBSET UM (A, q2 ) = #S UBSET UM ((y1 , . . . , yn ), qy ).
follows (X,Y ) C OMPARE-#S UBSET UM (A, q1 , q2 ) C OMPARE #S UBSET UM -R.
q
order perform next step, need ensure integers C OMPARE-#S UBSETS UM-R instance divisible 8. easily achieved, multiplying integer
instance ((a1 , . . . , ), q1 , q2 ) 8, obtaining ((8a1 , . . . , 8an ), 8q1 , 8q2 ) without changing number
solutions related UBSET UM instances. Thus, on, without loss generality,
assume given C OMPARE-#S UBSET UM-R instance ((a1 , . . . , ), q1 , q2 ), holds
ai , q j 0 mod 8 1 n j {1, 2}.
Now, consider even restricted variant problem.
C OMPARE -#S UBSET UM -RR
Given:
Question:

sequence = (a1 , . . . , ) positive integers.
number subsequences summing (/2)2, = ni=1 ai , greater
number subsequences summing (/2) 1, i.e., true
#S UBSET UM((a1 , . . . , ), (/2) 2) > #S UBSET UM((a1 , . . . , ), (/2) 1)?
p

Lemma 4.5. C OMPARE-#S UBSET UM-R C OMPARE-#S UBSET UM-RR.
Proof. Given instance (A, q1 , q2 ) C OMPARE-#S UBSET UM-R, assume =
(a1 , . . . , ), q1 , q2 satisfy ai , q j 0 mod 8 1 n j {1, 2}, construct instance
B C OMPARE-#S UBSET UM-RR follows. (This reduction inspired standard reduction
UBSET UM PARTITION due Karp, 1972.)
Letting = ni=1 ai , define
B = (a1 , . . . , , 2 q1 , 2 + 1 q2 , 2 + 3 + q1 + q2 , 3).
583

fiR EY & ROTHE

instance obviously constructed polynomial time. Observe
!
n

T=

ai

+ (2 q1 ) + (2 + 1 q2 ) + (2 + 3 + q1 + q2 ) + 3 = 10 + 4,

i=1

therefore, (T/2)2 = 5 (T/2)1 = 5 +1. show (A, q1 , q2 ) C OMPARE-#S UB SET UM -R B C OMPARE-#S UBSET UM -RR.
First, examine subsequences B sum 5. Consider two cases.
Case 1: 3 added, 2 +3+q1 +q2 cannot added, would large. Also, 2 +1q2
cannot added, leading odd sum. So, 2 q1 added, remaining
small. Since 3 + 2 q1 = 5 q1 , 5 achieved adding ai
exists subset A0 {1, . . . , n} iA0 ai = q1 (i.e., A0 solution
UBSET UM instance (A, q1 )).
Case 2: 3 added, 2 + 3 + q1 + q2 , even number achieved adding
2 + 1 q2 , thus, 4 q1 remain. 2 q1 large, subsequence sums
4q1 , assumption divisibility 8. neither 3 2 +3+q1 +q2
added, remaining 5 + 1 q1 q2 small.
Thus, possibility obtain 5 find subsequence adding q1 . Thus,
#S UBSET UM(A, q1 ) = #S UBSET UM(B, 5).
Second, similar reasons, sum 5 + 1 achieved adding 3 + (2 +
1 q2 ) term iA0 ai , A0 subset {1, . . . , n} iA0 ai = q2 . Hence,
#S UBSET UM(A, q2 ) = #S UBSET UM(B, 5 + 1).
Thus, relation #S UBSET UM(A, q1 ) > #S UBSET UM(A, q2 ) holds #S UBSETS UM(B, 5) > #S UBSET UM(B, 5 + 1), completes proof.
q
ready prove main theorem section.
Theorem 4.6. Banzhaf-B ENEFICIAL ERGE PP-complete, even three players equal
weight merge.
Proof. Membership Banzhaf-B ENEFICIAL ERGE PP follows fact raw
Banzhaf index #P #P closed addition multiplication two,10 and, furthermore, since comparing values two #P functions two (possibly different) inputs reduces
PP-complete problem. technique (which proposed Faliszewski & Hemaspaandra,
p
2009, applies Lemma 2.10) works, since PP closed -reducibility.
p
show PP-hardness Banzhaf-B ENEFICIAL ERGE means -reduction C OM PARE-#S UBSET UM -RR, PP-hard Corollary 4.3 via Lemmas 4.4 4.5.
Given instance = (a1 , . . . , ) C OMPARE-#S UBSET UM-RR, construct following
instance Banzhaf-B ENEFICIAL ERGE. Let = ni=1 ai . Define WVG
G = (2a1 , . . . , 2an , 1, 1, 1, 1; )
10. Again, note idea cannot transferred straightforwardly normalized Banzhaf index, since different
games indices possibly different denominators, different factor power two,
case probabilistic Banzhaf index.

584

fiFALSE -NAME ANIPULATION WVG H ARD PP

n + 4 players, let merging coalition = {n + 2, n + 3, n + 4}.
Letting N = {1, . . . , n}, holds
(
fi
)
fi

1

fi

Banzhaf(G , n + 2) = n+3 C {1, . . . , n + 1, n + 3, n + 4} fi wi = 1

fi iC

2
(
fi
(
fi
)
)

fi


fi

1
0
fi

0
fi

= n+3 N fi 2ai = 1 + 3 N fi 1 + 2ai = 1

fi iA0


fi

2
iA0
fi
fi
(
) !
) (
fi
fi



fi
fi



+ 3 A0 N fi 2 + 2ai = 1 + A0 N fi 3 + 2ai = 1
fi
fi



iA0
iA0
(
fi
fi
) (
) !

fi

fi

1

fi

fi

= n+3 3 A0 N fi 2ai = 2 + A0 N fi 2ai = 4 ,

fi iA0

fi iA0

2

(1)
(2)

since 2ai add even number. first four sets (1) (2) refers
coalitions contain players n + 1, n + 3, n + 4; second, third,
fourth set (1) (2) refers coalitions containing either one, two, three them,
respectively. Since players weight, players n + 3 n + 4
probabilistic Banzhaf index player n + 2.
Furthermore, new game merging G&{n+2,n+3,n+4} = (3, 2a1 , . . . 2an , 1; ) n + 2
players, similarly Banzhaf index first player calculated follows:

Banzhaf G&{n+2,n+3,n+4} , 1
(
fi
)
fi

1

fi

C

{2,
.
.
.
,
n
+
2}
w

{

3,


2,


1}
=

fi


fi iC

2n+1
(
fi
)

fi

1
0
fi

=


N
2a

{

3,


2,


1}

fi

fi iA0

2n+1
(
fi
) !

fi

0
fi

+ N fi 1 + 2ai { 3, 2, 1}

fi

iA0
fi
fi
(
) !
) (

fi
fi


1
fi

0
fi
0


N
2a
=


4
+
2



N
2a
=


2
=
.


fi
fi





n+1

fi iA0
fi iA0


2
Altogether, holds
Banzhaf G&{n+2,n+3,n+4} , 1







Banzhaf(G , i)

i{n+2,n+3,n+4}

fi
(
fi
) (
) !
fi


fi

0
fi
0
fi

=


N
2a
=


2
+


N
2a
=


4
2


fi


fi





n+1

fi iA0

fi iA0

2
(
fi
fi
) (
) !

fi

fi

3

fi

fi

n+3 3 A0 N fi 2ai = 2 + A0 N fi 2ai = 4

fi iA0

fi iA0

2
1

585

fiR EY & ROTHE

fi
(
)


fi

0
fi


2


3


N
=
2a
=


2

fi



n+1
n+3

fi iA0

2
2
fi
(
)



fi

1
3

fi

+ n+1 n+3 A0 N fi 2ai = 4

fi iA0

2
2
(
fi
(
)
fi

1

1

fi


= n+3 A0 N fi ai = 1 + n+3 A0 N

fi iA0
2

2
2


1

3

greater zero
(
fi
) (

fi


0
fi
0


N

2

=

fi
> N

fi iA0

2

fi
fi
fi
fi
fi

fi
fi
fi
fi
fi

)




2

=
,
0 2

iA


0 ai = 2 1
iA

)


,


turn case original instance C OMPARE-#S UBSET UM-RR. q
Analogously proof Theorem 4.6, shown beneficial splitting problem
least three false identities given new weights PP-complete. However,
general beneficial splitting problem new players weights given, PP upper bound
cannot shown straightforwardly. Yet, shown problem PP-hard, even three
false identities.
Theorem 4.7. Banzhaf-B ENEFICIAL PLIT PP-hard (even given player split
three players equal weight).
Proof. order show PP-hardness Banzhaf-B ENEFICIAL PLIT, use techniques
Theorem 4.6, appropriately modified. fact, show PP-hardness = 3 false
identities. result expanded fixed 3 splitting additional players
weight 0. precisely, > 3, consider game G split three
players weight 1 3 players weight 0 each. Lemma 3.1, sum
new players Banzhaf power equal combined Banzhaf power three players. Thus,
PP-hardness hold splitting > 3 players essentially arguments given
splitting three players.
First, slightly change definition C OMPARE-#S UBSET UM-RR switching (/2)
2 (/2) 1. problem (call C OMPARE-#S UBSET UM-R R) whether number
subsequences given sequence positive integers summing (/2) 1 greater
number subsequences summing (/2) 2, PP-hard proof
Lemma 4.5 roles q1 q2 exchanged.
Now, reduce problem Banzhaf-B ENEFICIAL PLIT constructing following instance beneficial splitting problem instance = (a1 , . . . , ) C OMPARE-#S UBSETS UM-R R. Let G = (2a1 , . . . , 2an , 1, 3; ), = nj=1 j , let = n + 2 player
split. G (apart order players) equivalent game obtained merging proof
Theorem 4.6. Thus, letting N = {1, . . . , n}, Banzhaf(G , n + 2) equals
(
fi
fi
) (
) !

fi

fi

1
0
fi
0
fi

2



N
2a
=


2
+


N
2a
=


4

fi


fi
.
j
j
0
0

fi jA

fi jA

2n+1
586

fiFALSE -NAME ANIPULATION WVG H ARD PP

Allowing players weight zero, different possibilities split player n + 2 three
players. Lemma 3.1, splitting n + 2 one player weight 3 two others weight 0
beneficial. Likewise, splitting n + 2 two players weights 1 2 one player
weight 0 beneficial, Lemma 3.1 since splitting two players beneficial (by
Theorem 1). Thus, possibility left splitting n + 2 three players weight 1 each.
corresponds original game proof Theorem 4.6, Gi3 = (2a1 , . . . , 2an , 1, 1, 1, 1; ).
Therefore,
Banzhaf(Gi3 , n + 2) = Banzhaf(Gi3 , n + 3) = Banzhaf(Gi3 , n + 4)
fi
fi
(
) (
) !
fi
fi



1
fi
fi
0
0



N


N
2a
=


2
+
2a
=


4
=
3

fi

fi


.
0 j
0 j
fi jA
fi jA



2n+3
Altogether, proof Theorem 4.6, sum three new players probabilistic
Banzhaf indices minus probabilistic Banzhaf index original player greater zero

(
fi
fi
) (
)

fi

fi

0
fi


fi

0


N fi j = ( /2) 1 > N fi j = ( /2) 2 ,

fi jA0

fi jA0

true C OMPARE-#S UBSET UM-R R.

q

Remark 4.8. upper bound general beneficial splitting problem, show
membership NPPP , whenever number false identities given unary, conjecture
problem even complete class. number false identities
weights given unary, exponentially many possibilities distribute split players
weight among false identities. Nondeterministically guessing distribution then,
distribution guessed, asking appropriate PP oracle check polynomial time whether
combined Banzhaf power new game greater original players Banzhaf power
original game, shows Banzhaf-B ENEFICIAL PLIT NPPP .
Whenever number false identities given standard binary input format, even
upper bound might longer valid.
given weighted voting game G two players j G , Proposition 4.1 implies
Banzhaf(G&{i, j} , 1) Banzhaf(G , i) = Banzhaf(G , j) 0.

(3)

Therefore, never disadvantageous player annex player j. Furthermore,
following result complexity beneficial annexation probabilistic Banzhaf index.
Theorem 4.9. Banzhaf-B ENEFICIAL NNEXATION NP-complete instances (G , i, S)
kSk = 1.
Proof. Equation (3) above, question whether new players probabilistic Banzhaf
index greater original players probabilistic Banzhaf index equivalent question
whether annexed player positive value original game. property
decided nondeterministic polynomial time NP-hard result due Prasad Kelly
(1990).
q

587

fiR EY & ROTHE

Remark 4.10. Banzhaf-B ENEFICIAL NNEXATION immediately inherits NP-hardness
special case Theorem 4.9, problems NP upper bound generalize straightforwardly.
4.2 ShapleyShubik Power Index
order prove PP-hardness merging splitting problems respect Shapley
Shubik index, need take step back.
E XACT C 3-S ETS (X3C, short) another well-known NP-complete decision problem: Given set B size 3k family subsets B size three each,
exist subfamily 0 B exactly covered 0 ?
Theorem 4.11. ShapleyShubik-B ENEFICIAL ERGE PP-complete, even two players
equal weight merge.
Proof. PP upper bound, already observed two players Faliszewski
Hemaspaandra (2009), shown analogously proof Theorem 4.6.
proving lower bound, observe size coalition player pivotal crucial determining players ShapleyShubik index. Pursuing techniques Faliszewski
Hemaspaandra, examine problem COMPARE-#X3C, PP-complete Lemma 4.2.
apply following useful properties X3C instances shown Faliszewski Hemaspaandra (2009, Lemma 2.7): Every X3C instance (B0 , 0 ) transformed X3C instance
(B, ), kBk = 3k kS k = n, satisfies k/n = 2/3 without changing number solutions, i.e., #X3C(B, ) = #X3C(B0 , 0 ). Now, properties standard reduction
X3C UBSET UM (which particular preserves number solutions, i.e., #X3C parsimoniously reduces #S UBSET UM, well input size n solution size k, see, e.g.,
Papadimitriou, 1995), assume given C OMPARE -#S UBSET UM instance subsequence summing given integer q size 2n/3. Following track reductions
C OMPARE -#S UBSET UM via C OMPARE-#S UBSET UM-R C OMPARE-#S UBSET UM-RR
Lemmas 4.4 4.5, solution A0 {1, . . . , n} given instance = (a1 , . . . , ) latter problem (A0 satisfying either iA0 ai = (/2) 2 iA0 ai = (/2) 1, = ni=1 ai )
assumed satisfy kA0 k = k = (n+2)/3. assumption, show PP-hardness
ShapleyShubik-B ENEFICIAL ERGE via reduction C OMPARE -#S UBSET UM -RR. Given
instance, construct WVG G = (a1 , . . . , , 1, 1; /2) consider coalition = {n +
1, n + 2}. Let N = {1, . . . , n} define X = #S UBSET UM(A, (/2) 1) = #S UBSET UM(A,
(/2) 2). Then,
ShapleyShubik(G , n + 1) = ShapleyShubik(G , n + 2)


=




1



kCk!(n
+
1

kCk)!
+
(kCk
+
1)!(n

kCk)!






(n + 2)! CN

CN
ai =(/2)1

ai =(/2)2

iC

=



iC

1
(X k!(n + 1 k)! +Y (k + 1)!(n k)!) .
(n + 2)!
588

fiFALSE -NAME ANIPULATION WVG H ARD PP

Merging players S, obtain G&S = (2, a1 , . . . , ; /2). ShapleyShubik index
new player G&S
ShapleyShubik(G&S , 1) =

1
(n + 1)!



kCk!(n kCk)!

CN
ai {(/2)1,(/2)2}
iC

1
=
(X +Y ) (k + 1)!(n k)!.
(n + 1)!
all,
ShapleyShubik(G&S , 1) (ShapleyShubik(G , n + 1) + ShapleyShubik(G , n + 2))
(X +Y ) (k + 1)!(n k)! 2 (X k!(n + 1 k)! +Y (k + 1)!(n k)!)
=

(n + 1)!
(n + 2)!
k!(n k)!
=
(n 2k)(X +Y ).
(n + 2)!

(4)

Since assumed k = (n+2)/3 also assume n > 4 (because added four
integers construction proof Lemma 4.5), holds
n 2k =

n4
> 0.
3

Thus term (4) greater zero greater X, true
C OMPARE -#S UBSET UM -RR.
q
Analogously probabilistic Banzhaf index, show also ShapleyShubik
index PP-complete decide splitting player players given weights beneficial.
general case number false identities actual weights given,
raise previously known lower bound PP-hardness. However, upper bound PP
cannot transferred straightforwardly.
Theorem 4.12. ShapleyShubik-B ENEFICIAL PLIT PP-hard (even given player
split two players equal weight).
Proof. PP-hardness shown analogously proof Theorem 4.7, appropriately modified use arguments proof Theorem 4.11 instead proof Theorem 4.6.
q
upper bound NPPP holds due analogous arguments proof Theorem 4.7,
whenever given unary.
Felsenthal Machover (1995) shown annexation never disadvantageous
ShapleyShubik index. Still, question whether advantageous hard decide.
Theorem 4.13. ShapleyShubik-B ENEFICIAL NNEXATION NP-complete instances (G , i, S)
kSk = 1.
589

fiR EY & ROTHE

Proof. Let G = (w1 , . . . , wn ; q) weighted voting game and, without loss generality, let
player 1 annex player n. holds
ShapleyShubik(G&{1,n} , 1) ShapleyShubik(G , 1)
=

1
((v(C {1, n} v(C {1})) kCk!(n 1 kCk)!
n! C{2,...,n1}
+ (v(C {n} v(C)) (kCk + 1)!(n 2 kCk)!).

Unlike probabilistic Banzhaf index, term general equal ShapleyShubik(G , n),
greater zero player n pivotal least one coalition C {1, . . . , n 1}
original game. So, analogously Theorem 4.9, property decided nondeterministic
polynomial time NP-hard result due Prasad Kelly (1990) (see also Deng &
Papadimitriou, 1994).
q
Remark 4.14. Analogously annexation respect probabilistic Banzhaf index,
ShapleyShubik-B ENEFICIAL NNEXATION immediately inherits NP-hardness special case
Theorem 4.13, problems NP upper bound generalize straightforwardly.

5. Generalizing Merging Splitting Functions
extend definition merging splitting functions weighted voting games general
classes (or representations) G coalitional games; one may think G class simple
games family weighted voting games representation simple games
vector weighted voting games (Chalkiadakis et al., 2011), threshold network flow games due
Bachrach Rosenschein (2009), even class coalitional games.
merging function G,
G : {G = (N, v) | G G} (P(N) r 0)
/ G,
turns given coalitional game G = (N, v) suitable representation given nonempty coalition
N new game G (G , S) = (N 0 , v0 ), N 0 = {i&S } (N r S) contains new player i&S
merging S, v0 : P(N 0 ) R new coalitional function whose values specified
according type games class G. example, weighted voting games possible v0
specified Section 3.
Similarly, splitting function G,
G : {G = (N, v) | G G} N (N r {0, 1}) P(G),
turns given coalitional game G = (N, v), given player N, given integer 2
set new games form (N 0 , v0 ), player split players N 0 = {n +
1, . . . , n + m} (N r {i}) v0 : P(N 0 ) R new coalitional function whose values
specified according type games class G. Again, weighted voting games v0
specified Section 3, classes coalitional games, v0 needs suitably defined.
example, G class monotonic coalitional games, v0 must defined monotonicity
590

fiFALSE -NAME ANIPULATION WVG H ARD PP

maintained, since various possibilities so, various distinct splitting functions
defined class games.
example, let wvg wvg denote merging splitting functions weighted voting
games defined Section 3. is,
weighted voting game G = (w1 , . . . , wn ; q) coalition N = {1, . . . , n}, define
wvg (G , S) = G&S ,
given weighted voting game G = (w1 , . . . , wn ; q), player i, integer 2, define
wvg (G , i, m) set weighted voting games Gim .
define following properties merging splitting functions.
Definition 5.1. Let G class coalitional games let G merging function G
G splitting function G.
1. say G satisfies consistency G = (N, v) G coalition N,
G (G , S) = (N 0 , v0 ) v(C S) = v0 (C {i&S }) holds coalition C N r S.
2. say G satisfies independence G = (N, v) G coalition N,
G (G , S) = (N 0 , v0 ) v(C) = v0 (C) holds coalition C N r S.
3. say G satisfies consistency G = (N, v) G, player N,
integer 2, (N 0 , v0 ) G (G , i, m) v(C {i}) = v0 (C {n + 1, . . . , n + m})
coalition C N r {i}.
4. say G satisfies independence G = (N, v) G, player N,
integer 2, (N 0 , v0 ) G (G , i, m) v(C) = v0 (C) coalition C N r {i}.
Intuitively, consistency means value coalition subject merging splitting
operations. Independence means value coalition
affected merging splitting remain new game, i.e., depends
players coalition. weighted voting games, wvg wvg satisfy consistency
independence, since weight new player G (G , S) equals wi merging, since
mj=1 wn+ j = wi splitting.
following example presents merging function class weighted majority games
neither consistency independence satisfied.
Example 5.2. Let wmg merging function maps given weighted majority game G =
(w1 , . . . , wn ) given coalition N new weighted majority game, player
keeps weight, new player i&S merging receives weight wi&S = wi .
Consider game G = (2, 3, 4, 4) coalition = {1, 3}. Then, game wmg (G , S) =
(8, 3, 4) formed. value merged player new game v0 ({i&S }) = 1, whereas
value original game v(S) = 0. Thus, wmg consistent. hand,
value coalition players ({2, 4} G {2, 3} wmg (G , S)) decreases 1
0. Thus, wmg independent.
similar example obtained using, e.g., maximum minimum weight coalitions
players instead product weights, function additive.
591

fiR EY & ROTHE

general, merging function csg class constant-sum games (i.e., games G = (N, v)
v(C) + v(N r C) = v(N) holds coalition C N) neither consistent independent whenever G = (N, v), coalition N, csg (G , S) = (N 0 , v0 ),
v(S) 6= v0 ({i&S }) v(N) = v0 (N 0 ), since v(N r S) 6= v0 (N r {i&S }).
pointed anonymous reviewer, natural merging splitting functions may also
exist important classes coalitional games transferable utilities player
posesses certain amount divisible resource, fractional matching games, bankruptcy
games, market games (see, e.g., Shoham & Leyton-Brown, 2009). Moreover, one could consider
class path-disruption games (Bachrach & Porat, 2010; Rey & Rothe, 2011, 2012; Marple,
Rey, & Rothe, 2014), merging two unconnected vertices might influence value
coalition players. approach define merging splitting function
network flow games found Section 5.2.
5.1 Beneficial Merging Splitting Generalized: Case Two Players
define beneficial merging splitting problems general. Let G merging
function G splitting function class G coalitional games let PI power
index. Define following generalized problems.
G -PI-B ENEFICIAL ERGE
Given:
Question:

game G = (N, v) G nonempty coalition N.
true PI(G (G , S), i&S ) > PI(G , i), G (G , S) = (N 0 , v0 ) N 0 =
{i&S } (N r S)?
G -PI-B ENEFICIAL PLIT

Given:
Question:

game G = (N, v) G, N = {1, . . . , n}, player N, integer 2.
game G 0 = (N 0 , v0 ) G (G , i, m) N 0 = {n + 1, . . . , n + m} (N r {i})
mj=1 PI(G 0 , n + j) > PI(G , i)?

Intuitively, G -PI-B ENEFICIAL ERGE problem whether coalition players benefit merging via G raising power terms f . Similarly, G -PI-B ENEFICIAL PLIT
problem whether player benefit splitting number new players via G
raising power terms PI.
Generalizing Proposition 4.1, consistency independence satisfied merging function, coalition two players cannot benefit merging player benefit splitting
two players considering probabilistic Banzhaf index.
Theorem 5.3. Let G merging function let G splitting function, satisfying
consistency independence.
1. G -Banzhaf-B ENEFICIAL ERGE P instances (G , S) kSk = 2.
2. G -Banzhaf-B ENEFICIAL PLIT P instances (G , i, 2).
Proof. Let G = (N, v) coalitional game let G consistent independent merging
function. Without loss generality (see Footnote 8), let = {n 1, n}. obtain new game
592

fiFALSE -NAME ANIPULATION WVG H ARD PP

G (G , S) = ({1, . . . , n 1}, v0 ), n 1 new player merging G . holds
Banzhaf(G (G , S), n1) (Banzhaf(G , n1) + Banzhaf(G , n))

=

1

2(v0 (C {n1}) v0 (C))
2n1 C{1,...,n2}


(v(C {n1}) v(C))



CNr{n1,n}



(v(C {n1}) v(C))



CNr{n1},
nC




(v(C {n}) v(C))





CNr{n,n1}


=

1


2n1




(v(C {n}) v(C))

CNr{n},
n1C





0

0
2v (C {n1}) 2v(C {n1, n}) + 2v(C) 2v (C) = 0.
|
{z
}
|
{z
}
C{1,...,n2}



= 0 (by consistency)

= 0 (by independence)

case splitting, consider game G = (N, v) n players, consistent independent
splitting function G , and, without loss generality, player n G splitting players n + 1
n + 2, results new game G 0 G (G , n, 2). Now, similarly holds
Banzhaf(G 0 , n + 1) + Banzhaf(G 0 , n + 2) Banzhaf(G , n) = 0,
q

claimed.

particular, immediately implies Proposition 4.1 wvg wvg . another example,
next consider threshold network flow games hypergraphs, class compactly representable
simple coalitional games.
5.2 Example: Threshold Network Flow Games Hypergraphs
Bachrach Rosenschein (2009) analyze threshold network flow games graphs. threshold
network flow game (TNFG, short) defined edge-weighted graph n agents
control one edge, source vertex V target vertex V , threshold k R.
coalitional function success function, coalition agents successful
data flow size k sent edges represented agents coalition.
merging splitting defined setting? Since agents control single edges,11
merging two agents would yield one new agent controls one edge
would qualitively different remaining agents. Similarly, splitting agent several
subagents would mean split original agents edge, unclear that.
approach solving issue consider threshold network flow games hypergraphs rather
graphs. hyperedge hypergraph subset vertex set (so graph special
case hypergraph hyperedges size two only). course, agents hypergraph
control hyperedges different sizes, merely quantitative difference.
11. Kalai Zemel (1982a, 1982b) propose model agent controls set edges, single edge.
suggested anonymous reviewer, natural merging function would assign merging coalition
union sets edges controlled players coalition original game.

593

fiR EY & ROTHE

Definition 5.4. threshold hypergraph network flow game (THNFG, short) G = (N, v) set
weighted hypergraph H = (V, E) vertex set V set E = {e1 , . . . , en } n weighted
hyperedges (where agent represents hyperedge ei ), weight function w : E N (represented
list (w1 , . . . , wn ) wi = w(ei )), source vertex V target vertex V , threshold
k R. coalitional function v : P(N) {0, 1} defined v(C) = 1 data flow size k
possible H|C , subhypergraph H induced hyperedge set {ei | C},
v(C) = 0 otherwise.
Example 5.5. THNFG four agents Figure 1 may help visualize definitions
theorems given below. shows hypergraph (in standard bipartite graph representation
hypergraphs) related game G = ({1, . . . , 5}, v)
G = (H, s,t, w, k) = (({v1 , . . . , v5 }, {{v4 , v5 }, {v1 , v3 , v4 }, {v2 , v3 , v5 }, {v3 , v5 }}), v3 , v5 , (1, 2, 3, 4), 5).
| {z } | {z } | {z } | {z }
e1

v1

v2

e1

e2

e3

v3

v4

e3

e2

e4

v5

e4

Figure 1: THNFG Example 5.5
Possible applications THNFGs found grid computing manyoften thousands ofcomputers collaborate solve common task distributing various subtasks certain
clusters computers, represent agents (respectively, hyperedges). Connecting number computer clusters corresponds forming coalition agents. Modeled game,
coalition (i.e., set clusters) successful connects source target allows
sufficient network data flow within capacity computers clusters, case
clusters assigned desired subtask. another example possible application
THNFGs, propose use model smart power grids deliver electricity suppliers
consumers. Success coalition would mean certain threshold exceeded
according consumers current demands, thus allowing sufficiently large power flow.
TNFGs, determining raw Banzhaf index #P-complete, ShapleyShubik
index known least hard problems NP (Bachrach & Rosenschein, 2009).
However, THNFGs, following results consequences corresponding results
weighted voting games. easy hardness proof simply reduces problem WVGs
corresponding problem THNFGs mapping given WVG G = (w1 , . . . , wn , q) THNFG
H = (({v0 , v1 , . . . , vn+1 }, {e1 , . . . en }), v0 , vn+1 , (w1 , . . . , wn ), q),
ei = {v0 , vi , vn+1 } i, 1 n, weights threshold. Since value
coalition C G equals value C H , Banzhaf (G , i) = Banzhaf (H , i)
594

fiFALSE -NAME ANIPULATION WVG H ARD PP

ShapleyShubik (G , i) = ShapleyShubik (H , i) player i. Since reduction parsimonious, #P-parsimonious-hardness Banzhaf THNFGs inherited WVGs,
#P-many-one-hardness ShapleyShubik THNFGs inherited WVGs.
Proposition 5.6. Computing raw Banzhaf power index THNFGs #P-parsimonious-complete,
computing raw ShapleyShubik power index THNFGs #P-many-one-complete.
power compare problem weighted voting games respect power index PI
(originally introduced Faliszewski & Hemaspaandra, 2009) defined analogously
THNFGs:
PI-THNFG-P OWER C OMPARE
Given:
Question:

Two THNFGs, G G 0 , player occurring games.
true PI(G , i) > PI(G 0 , i)?

suitably extending reduction given right Proposition 5.6, following.
Corollary 5.7. PI-THNFG-P OWER C OMPARE PP-hard PI {ShapleyShubik, Banzhaf}.
use hyperedges makes possible that, THNFGs, coalition agents merged
single new agent controls hyperedge corresponds union vertices belonging hyperedges coalitions original agents. example grid computing, merge
two clusters allows new connections well sum computing power computers
clusters total weight. Similarly, possible agent setting split
several subagents partitioning agents hyperedge subsets controlled one
new subagents. define merging function splitting function THNFGs
follows:
merging function thnfg THNFGs maps given THNFG G = (H, s,t, w, k), hypergraph H = (V, E), given coalition agents new THNFG thnfg (G , S) =
(H&S , s,t, w&S , k), new hypergraph H&S = (V, E&S ) new set hyperS
edges E&S = (E r {ei | S}) {e&S }, new agent i&S controls hyperedge e&S = ei ,
new weight function w&S given w&S (ei ) = wi 6 S, w&S (e&S ) = wi .
splitting function thnfg THNFGs maps given THNFG G = (H, s,t, w, k),
hypergraph H = (V, E), given agent i, given integer 2 new THNFG
thnfg (G , i, m) = (Him , s,t, wim , k), new hypergraph = (V, Eim )
Eim = (E r {ei }) {en+1 , . . . , en+m }, agent split agents n + 1, . . . , n +

mj=1 en+ j = ei en+ j e` = 0/ ` {1, . . . , n} r {i}, new weight function
wim given wim (e` ) = w` ` 6= i, new agents weights wn+ j = wim (en+ j ),
1 j m, satisfy mj=1 wn+ j = wi .
contrast weighted voting games, consistency satisfied general THNFGs, neither
thnfg thnfg . one hand, merging two agents via thnfg create new connections
vertices thus allows new data flows emerge. hand, existing connections
get lost splitting agent via thnfg (i.e., splitting corresponding hyperedge). Therefore,
merging splitting thnfg thnfg might advantageous probabilistic Banzhaf index,
even size-two coalitions split two players.
595

fiR EY & ROTHE

Example 5.8 (continuing Example 5.5). Consider THNFG G Example 5.5. Merging
agents coalition = {1, 3} via thnfg , allows new connections, disadvantagous
probabilistic Banzhaf index new game
thnfg (G , {1, 3}) = (({v1 . . . , v5 }, {{v2 , v3 , v4 , v5 }, {v1 , v3 , v4 }, {v3 , v5 }}), v3 , v5 , (4, 2, 4), 5).
|
{z
} | {z } | {z }
e&{1,3}

e2

e4

However, merging agents coalition = {1, 2} via thnfg , beneficial probabilistic
Banzhaf index new game
thnfg (G , {1, 2}) = (({v1 . . . , v5 }, {{v1 , v3 , v4 , v5 }, {v2 , v3 , v5 }, {v3 , v5 }}), v1 , v5 , (3, 3, 4), 5).
|
{z
} | {z } | {z }
e&{1,2}

e3

e4

comparison, let G 0 corresponding weighted voting game G 0 = (1, 2, 3, 4; 5) (i.e.,
0
weights threshold). Merging agents = {1, 3} G 0 via wvg (G 0 , S) = G&{1,3}
=
0
0
0
(4, 2, 4; 5) well merging agents = {1, 2} G via wvg (G , S) = G&{1,2} = (3, 3, 4; 5)
neutral probabilistic Banzhaf index.
However, wvg wvg weighted voting games, thnfg thnfg satisfy independence THNFGs: value coalition depends hyperedges agents
within coalition, hyperedges might merged split.
5.3 Merging Splitting Unanimity Games
simple game G = (N, v) called unanimity game grand coalition wins, i.e., v(C) = 1
C = N, v(C) = 0 C ( N. example, weighted voting game G = (w1 , . . . , wn ; q)
unanimity weighted voting game ni=1 wi miniN wi < q ni=1 wi .
one possible merging function unanimity games. Let G unanimity game
let N coalition. Define ug (G , S) = (N 0 , v0 ) N 0 = {i&S } (N r S) v0 (C) = 1
C = N 0 , v0 (C) = 0 C ( N 0 . Obviously, ug satisfies consistency independence.
unanimity weighted voting games, Aziz et al. (2011) show normalized Banzhaf
index, merging always disadvantageous, whereas splitting always advantageous. (Thus one
decide polynomial time whether merging splitting beneficial.) strong contrast,
show unanimity games respect probabilistic Banzhaf index, splitting always
disadvantageous neutral, whereas merging neutral size-two coalitions, yet advantageous
coalitions least three players.
Theorem 5.9. Let G unanimity game player set N.
1. (G , S) 6 ug -Banzhaf-B ENEFICIAL ERGE N kSk = 2,
2. (G , S) ug -Banzhaf-B ENEFICIAL ERGE N kSk 3.
3. (G , i, m) 6 ug -Banzhaf-B ENEFICIAL PLIT N 2.
Proof. first statement follows immediately Theorem 5.3.
prove second statement, note unanimity game, player pivotal
coalition = N r {i}, always pivotal coalition. Thus raw Banzhaf
596

fiFALSE -NAME ANIPULATION WVG H ARD PP

index always equal one. follows Banzhaf(G , i) = 1/2n1 player N.
arbitrary coalition merges, Banzhaf index player new game ug (G , S)
Banzhaf(ug (G , S), i) = 1/2nkSk . Since kSk 3,
Banzhaf(ug (G , S), i&S ) Banzhaf(G , i) =


2kSk1 kSk
> 0.
2n1

third statement shown similar arguments. particular, possible split
players integer weights,


Banzhaf(ug (G , i, m), n + j) Banzhaf(G , i) =

j=1

2m1
0.
2n+m2
q

completes proof.

6. Conclusions Future Work
analyzed beneficial merging, splitting, annexation problems terms complexity. particular, results complementby considering probabilistic Banzhaf power
indexthose Aziz et al. (2011) normalized Banzhaf power index weighted voting
games. extent, results differ normalized Banzhaf power index:
probabilistic Banzhaf power index, beneficial merging splitting turns tractable
merger size-two coalitions split two players.
One main results that, solving previous conjectures affirmative, pinpointed precise complexity beneficial merging problem weighted voting games
ShapleyShubik probabilistic Banzhaf index showing PP-complete cases.
one hand, result interesting theoretical point view.
hand, provides PP-completeness result natural problem game theory,
far rarer NP-complete problems field. Since merging seen manipulative behavior, high complexity interpreted protection shield strategic interference.
several known methods circumvent NP-hardnesssuch approximation, fixedparameter tractability, typical case analyses (for discussion applying methods NP-hard
voting problems see, e.g., Rothe & Schend, 2013), recent algebraic approach (Berghammer &
Schnoor, 2014), methods less applicable circumvent hardness higher complexity
classes. Since PP considered much larger complexity class NP, PP-hardness
seen leading potentially higher degree protection mere NP-hardness. Still, hardness problems rests hardness compute related power indices. Note
good approximation schemes dynamic methods known computing ShapleyShubik
index (see, e.g., Bachrach, Markakis, Resnik, Procaccia, Rosenschein, & Saberi, 2010; Fatima,
Wooldridge, & Jennings, 2008; Bilbao, Fernndez, Jimnez, & Lpez, 2000; Matsui & Matsui,
2000; Shapley, 1953), though much known exact case.
obtained PP-completeness result beneficial splitting (a.k.a. false-name
manipulation) whenever new players weights given. given number false identities,
unknown weights, raised lower bound (known ShapleyShubik index) NPhardness PP-hardness showed contained NPPP whenever number false
597

fiR EY & ROTHE

identities given unary. problem, remains open whether shown complete
NPPP , huge complexity class thatby Todas theorem (1991)contains entire polynomial
hierarchy. NPPP interesting class, somewhat sparse natural complete problems.
(natural) NPPP -completeness results aware due Littman et al. (1998), analyze
variant satisfiability problem questions related probabilistic planning, due
Mundhenk et al. (2000), study problems related finite-horizon Markov decision processes.
Another interesting open question whether results transferred also beneficial
merging splitting problems normalized Banzhaf index power indices.
beneficial annexation problem takeover single player, showed NPcompleteness ShapleyShubik probabilistic Banzhaf index.
Finally, proposed general framework merging splitting applied
various classes coalitional games transferable utilities. interesting task future
research study useful properties merging splitting functions, consistency
independence, general applied particular classes games like network flow games
market games. Another interesting question, raised anonymous reviewer, naturally
extend idea merging classes games players control several resources.
properties want hold case? Also, merging function satisfies independence
consistence unique certain class games? unanimity games observed
one possible merging function guarantees unanimity. weighted voting games,
however, uniqueness result hold, since different ways distribute
players weights lead coalitional function. instance, games (1, 3, 4; 8)
(2, 3, 4; 8) semantically same, even players merge. Restricting classes requiring
properties might imply uniqueness. Although consistency seems essential property
merging splitting function, seen natural merging function threshold hypergraph
network flow games satisfy property, made similar observations
classes games.

Acknowledgments
Preliminary versions parts paper appear proceedings 19th European Conference Artificial Intelligence (ECAI10) (Rey & Rothe, 2010a), 5th European Starting AI
Researcher Symposium (STAIRS10) (Rey & Rothe, 2010b), 11th Latin American Theoretical Informatics Symposium (LATIN14) (Rey & Rothe, 2014). grateful anonymous
JAIR, ECAI10, STAIRS10, LATIN14, CoopMAS14 reviewers helpful comments
paper. work supported part DFG grants RO 1202/11-1, RO 1202/12-1 (within
ESF EUROCORES program LogICCC), RO 1202/14-1.

References
Aziz, H., Bachrach, Y., Elkind, E., & Paterson, M. (2011). False-name manipulations weighted
voting games. Journal Artificial Intelligence Research, 40, 5793.
Aziz, H., Brandt, F., & Brill, M. (2013). computational complexity random serial dictatorships. Economic Letters, 121(3), 341345.
598

fiFALSE -NAME ANIPULATION WVG H ARD PP

Aziz, H., & Paterson, M. (2009). False name manipulations weighted voting games: Splitting,
merging annexation. Proceedings 8th International Joint Conference Autonomous Agents Multiagent Systems, pp. 409416. IFAAMAS.
Bachrach, Y., & Elkind, E. (2008). Divide conquer: False-Name manipulations weighted voting games. Proceedings 7th International Joint Conference Autonomous Agents
Multiagent Systems, pp. 975982. IFAAMAS.
Bachrach, Y., Elkind, E., Meir, R., Pasechnik, D., Zuckerman, M., Rothe, J., & Rosenschein, J.
(2009). cost stability coalitional games. Proceedings 2nd International
Symposium Algorithmic Game Theory, pp. 122134. Springer-Verlag Lecture Notes
Computer Science #5814.
Bachrach, Y., Markakis, E., Resnik, E., Procaccia, A., Rosenschein, J., & Saberi, A. (2010). Approximating power indices: Theoretical empirical analysis. Journal Autonomous Agents
Multi-Agent Systems, 20(2), 105122.
Bachrach, Y., & Porat, E. (2010). Path disruption games. Proceedings 9th International
Joint Conference Autonomous Agents Multiagent Systems, pp. 11231130. IFAAMAS.
Bachrach, Y., & Rosenschein, J. (2009). Power threshold network flow games. Journal Autonomous Agents Multi-Agent Systems, 18(1), 106132.
Banzhaf III, J. (1965). Weighted voting doesnt work: mathematical analysis. Rutgers Law
Review, 19, 317343.
Berghammer, R., & Schnoor, H. (2014). Control condorcet voting: Complexity relationalgebraic approach (extended abstract). Proceedings 13th International Joint Conference Autonomous Agents Multiagent Systems, pp. 13651366. IFAAMAS.
Bilbao, J., Fernndez, J., Jimnez, N., & Lpez, J. (2000). Generating functions computing
power indices efficiently. Top, 8(2), 191213.
Bilbao, J., Fernndez, J., Jimnez, N., & Lpez, J. (2002). Voting power European Union
enlargement. European Journal Operational Research, 143(1), 181196.
Chalkiadakis, G., Elkind, E., & Wooldridge, M. (2011). Computational Aspects Cooperative
Game Theory. Synthesis Lectures Artificial Intelligence Machine Learning. Morgan
Claypool Publishers.
Deng, X., & Papadimitriou, C. (1994). complexity comparative solution concepts. Mathematics Operations Research, 4(2), 257266.
Dubey, P., & Shapley, L. (1979). Mathematical properties Banzhaf power index. Mathematics
Operations Research, 4(2), 99131.
Elkind, E., Chalkiadakis, G., & Jennings, N. (2008). Coalition structures weighted voting games.
Proceedings 18th European Conference Artificial Intelligence, pp. 393397. IOS
Press.
Elkind, E., Goldberg, L., Goldberg, P., & Wooldridge, M. (2009). computational complexity
weighted voting games. Annals Mathematics Artificial Intelligence, 56(2), 109131.
599

fiR EY & ROTHE

Elkind, E., Pasechnik, D., & Zick, Y. (2013). Dynamic weighted voting games. Proceedings
12th International Joint Conference Autonomous Agents Multiagent Systems, pp.
515522. IFAAMAS.
Faliszewski, P., & Hemaspaandra, L. (2009). complexity power-index comparison. Theoretical Computer Science, 410(1), 101107.
Fatima, S., Wooldridge, M., & Jennings, N. (2008). linear approximation method shapley
value. Artificial Intelligence, 172(14), 16731699.
Felsenthal, D., & Machover, M. (1995). Postulates paradoxes relative voting power
critical re-appraisal. Theory Decision, 38(2), 195229.
Felsenthal, D., & Machover, M. (2005). Voting power measurement: story misreinvention.
Social Choice Welfare, 25(2), 485506.
Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory NPCompleteness. W. H. Freeman Company.
Gill, J. (1977). Computational complexity probabilistic Turing machines. SIAM Journal
Computing, 6(4), 675695.
Hunt, H., Marathe, M., Radhakrishnan, V., & Stearns, R. (1998). complexity counting
problems. SIAM Journal Computing, 27(4), 11421167.
Kalai, E., & Zemel, E. (1982a). Generalized network problems yielding totally balanced games.
Operations Research, 30(5), 9981008.
Kalai, E., & Zemel, E. (1982b). Totally balanced games games flow. Mathematics Operations Research, 7(3), 476478.
Karp, R. (1972). Reducibility among combinatorial problems. Miller, R., & Thatcher, J. (Eds.),
Complexity Computer Computations, pp. 85103. Plenum Press.
Littman, M., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilistic
planning. Journal Artificial Intelligence Research, 9(1), 136.
Marple, A., Rey, A., & Rothe, J. (2014). Bribery multiple-adversary path-disruption games
hard second level polynomial hierarchy (extended abstract). Proceedings
13th International Joint Conference Autonomous Agents Multiagent Systems.
IFAAMAS. appear.
Matsui, T., & Matsui, Y. (2000). survey algorithms calculating power indices weighted
majority games. Journal Operation Research Society Japan, 43(1), 7186.
Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (2000). Complexity results finitehorizon Markov decision process problems. Journal ACM, 47(4), 681720.
Nisan, N., Roughgarden, T., Tardos, ., & Vazirani, V. (Eds.). (2007). Algorithmic Game Theory.
Cambridge University Press.
Papadimitriou, C. (1995). Computational Complexity (Second edition). Addison-Wesley.
Peleg, B., & Sudhlter, P. (2003). Introduction Theory Cooperative Games. Kluwer
Academic Publishers.
Penrose, L. (1946). elementary statistics majority voting. Journal Royal Statistical
Society, 109(1), 5357.
600

fiFALSE -NAME ANIPULATION WVG H ARD PP

Prasad, K., & Kelly, J. (1990). NP-completeness problems concerning voting games. International Journal Game Theory, 19(1), 19.
Rey, A., & Rothe, J. (2010a). Complexity merging splitting probabilistic Banzhaf
power index weighted voting games. Proceedings 19th European Conference
Artificial Intelligence, pp. 10211022. IOS Press.
Rey, A., & Rothe, J. (2010b). Merging splitting power indices weighted voting games
network flow games hypergraphs. Proceedings 5th European Starting AI
Researcher Symposium, pp. 277289. IOS Press.
Rey, A., & Rothe, J. (2011). Bribery path-disruption games. Proceedings 2nd International Conference Algorithmic Decision Theory, pp. 247261. Springer-Verlag Lecture
Notes Artificial Intelligence #6992.
Rey, A., & Rothe, J. (2012). Probabilistic path-disruption games. Proceedings 20th European Conference Artificial Intelligence, pp. 923924. IOS Press. extended version
appears proceedings 6th European Starting AI Researcher Symposium, IOS Press,
pages 264269, August 2012.
Rey, A., & Rothe, J. (2014). False-name manipulation weighted voting games hard probabilistic polynomial time. Proceedings 11th Latin American Theoretical Informatics
Symposium, pp. 6071. Springer-Verlag Lecture Notes Computer Science #8392.
Rothe, J. (2005). Complexity Theory Cryptology. Introduction Cryptocomplexity. EATCS
Texts Theoretical Computer Science. Springer-Verlag.
Rothe, J., & Schend, L. (2013). Challenges complexity shields supposed protect
elections manipulation control: survey. Annals Mathematics Artificial
Intelligence, 68(13), 161193.
Shapley, L. (1953). value n-person games. Kuhn, H., & Tucker, A. (Eds.), Contributions
Theory Games, Vol. II Annals Mathematics Studies 40. Princeton University
Press.
Shapley, L., & Shubik, M. (1954). method evaluating distribution power committee
system. American Political Science Review, 48(3), 787792.
Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems. Algorithmic, Game-Theoretic,
Logical Foundations. Cambridge University Press.
Toda, S. (1991). PP hard polynomial-time hierarchy. SIAM Journal Computing,
20(5), 865877.
Valiant, L. (1979). complexity computing permanent. Theoretical Computer Science,
8(2), 189201.
Wagner, K. (1986). complexity combinatorial problems succinct input representations.
Acta Informatica, 23, 325356.
Zank, V. (1991). #P-completeness via many-one reductions. International Journal Foundations
Computer Science, 2(1), 7682.
Zuckerman, M., Faliszewski, P., Bachrach, Y., & Elkind, E. (2012). Manipulating quota
weighted voting games. Artificial Intelligence, 180-181(0), 119.

601

fiJournal Artificial Intelligence Research 50 (2014) 369-407

Submitted 10/13; published 6/14

HC-Search: Learning Framework Search-based
Structured Prediction
Janardhan Rao Doppa

doppa@eecs.oregonstate.edu

School EECS, Oregon State University
Corvallis, 97331-5501, USA

Alan Fern

afern@eecs.oregonstate.edu

School EECS, Oregon State University
Corvallis, 97331-5501, USA

Prasad Tadepalli

tadepall@eecs.oregonstate.edu

School EECS, Oregon State University
Corvallis, 97331-5501, USA

Abstract
Structured prediction problem learning function maps structured inputs
structured outputs. Prototypical examples structured prediction include part-ofspeech tagging semantic segmentation images. Inspired recent successes
search-based structured prediction, introduce new framework structured prediction
called HC-Search. Given structured input, framework uses search procedure guided
learned heuristic H uncover high quality candidate outputs employs
separate learned cost function C select final prediction among outputs.
overall loss prediction architecture decomposes loss due H leading
high quality outputs, loss due C selecting best among generated
outputs. Guided decomposition, minimize overall loss greedy stage-wise
manner first training H quickly uncover high quality outputs via imitation learning,
training C correctly rank outputs generated via H according true
losses. Importantly, training procedure sensitive particular loss function
interest time-bound allowed predictions. Experiments several benchmark
domains show approach significantly outperforms several state-of-the-art methods.

1. Introduction
consider problem structured prediction, predictor must produce
structured output given structured input. example, Part-Of-Speech (POS) tagging, structured input sequence words structured output corresponds
POS tags words. Image scene labeling another example, structured
input image structured output semantic labeling image regions.
Structured prediction tasks arise several domains ranging natural
language processing (e.g., named entity recognition, coreference resolution, semantic
parsing) computer vision (e.g., multi-object tracking activity recognition videos)
speech (e.g., text-to-speech mapping speech recognition) compuational biology
(e.g., protein secondary structure prediction gene prediction).
Viewed traditional classification problem, set possible classes structured
prediction exponential size input. Thus, problem producing
c
2014
AI Access Foundation. rights reserved.

fiDoppa, Fern, & Tadepalli

output combinatorial nature, introduces non-trivial choice selecting
computational framework producing outputs. Importantly, framework needs
balance two conflicting criteria: 1) must flexible enough allow complex
accurate structured predictors learned, 2) must support inference outputs
within computational time constraints application. One core research
challenges structured prediction achieve balance criteria.
standard approach structured prediction learn cost function C(x, y)
scoring potential structured output given structured input x. Given cost
function new input x, output computation involves solving so-called Argmin
problem, find minimum cost output given input.
= arg minyY(x) C(x, y)

(1)

example, approaches Conditional Random Fields (CRFs) (Lafferty, McCallum,
& Pereira, 2001), Max-Margin Markov Networks (Taskar, Guestrin, & Koller, 2003)
Structured SVMs (Tsochantaridis, Hofmann, Joachims, & Altun, 2004) represent cost
function linear model template features x y. Unfortunately, exactly
solving Argmin problem often intractable. Efficient solutions exist limited
cases dependency structure among features forms tree. cases, one
forced simplify features allow tractable inference, detrimental
prediction accuracy. Alternatively, heuristic optimization method used
loopy belief propagation variational inference. methods shown
success practice, difficult characterize solutions predict
likely work well new problem.
inspired recent successes output-space search approaches (Doppa, Fern,
& Tadepalli, 2012; Wick, Rohanimanesh, Bellare, Culotta, & McCallum, 2011), place
restrictions form cost function. methods learn use cost
function conduct search space complete outputs via search procedure
(e.g., greedy search), return least cost output uncovered search
prediction. search procedure needs able efficiently evaluate cost
function specific input-output pairs, generally straightforward even
corresponding Argmin problem intractable. Thus, methods free increase
complexity cost function without considering impact inference complexity.
approaches achieved state-of-the-art performance number
benchmark problems, primary contribution paper highlight fundamental
deficiency share. particular, prior work uses single cost function serve
dual roles both: 1) guiding search toward good outputs, 2) scoring generated
outputs order select best one. Serving dual roles often means cost
function needs make unclear tradeoffs, increasing difficulty learning. Indeed,
traditional AI search literature, roles typically served different functions,
mainly heuristic function guiding search, cost/evaluation function (often part
problem definition) selecting final output.
paper, study new framework structured prediction called HC-Search
closely follows traditional search literature. key idea learn distinct functions
roles: 1) heuristic function H guide search generate set
high-quality candidate outputs, 2) cost function C score outputs generated
370

fiHC-Search: Learning Framework Search-based Structured Prediction

heuristic H. Given structured input, predictions made using H guide
search strategy (e.g., greedy search beam search) time bound generate set
candidate outputs returning generated output least cost according C.
move HC-Search might appear relatively small, significant
implications terms theory practice. First, regret HC-Search
approach decomposed loss due H leading high quality outputs,
loss due C selecting best among generated outputs. decomposition
helps us target training minimize losses individually greedy stagewise manner. Second, show, performance approaches single
function arbitrarily bad compared HC-Search worst case.
Finally, show practice HC-Search performs significantly better single
cost function search state-of-the-art approaches structured prediction.
effectiveness HC-Search approach particular problem depends critically
on: 1) quality search space complete outputs used, quality
defined expected depth target outputs (zero loss outputs) located, 2)
ability learn heuristic function effectively guiding search generate highquality candidate outputs, 3) accuracy learned cost function selecting
best output among candidate outputs generated heuristic function. work,
assume availability efficient search space complete outputs provide
effective training regime learning heuristic function cost function within
HC-Search framework.

1.1 Summary Contributions
main contributions work follows: 1) introduce HC-Search framework, two different functions learned serve purposes search heuristic
cost function search literature; 2) analyze representational power
computational complexity learning within HC-Search framework; 3) identify
novel decomposition overall regret HC-Search approach terms generation
loss, loss due heuristic generating high-quality candidate outputs, selection
loss, loss due cost function selecting best among generated outputs; 4)
Guided decomposition, propose stage-wise approach learning heuristic
cost functions based imitation learning; 5) empirically evaluate HC-Search
approach number benchmarks, comparing state-of-the-art methods analyzing different dimensions framework.
remainder paper proceeds follows. Section 2, introduce problem
setup, give high-level overview framework, analyze complexity HC-Search
learning problem. describe approaches heuristic cost function learning
Section 3. Section 4 presents experimental results followed engineering methodology applying framework new problems Section 5. Finally, Sections 6 7
discuss related work future directions.
371

fiDoppa, Fern, & Tadepalli

2. HC-Search Framework
section, first state formal problem setup describe specifics
search spaces search strategies investigate work. Next, give
high-level overview HC-Search framework along learning objective.
2.1 Problem Setup
structured prediction problem specifies space structured inputs X , space structured outputs Y, non-negative loss function L : X 7 <+ L(x, 0 , )
loss associated labeling particular input x output 0 true output . provided training set input-output pairs {(x, )} drawn
unknown target distribution D. goal return function/predictor structured inputs outputs whose predicted outputs low expected loss respect
distribution D. Since algorithms learning heuristic cost functions
input-output pairs, standard structured prediction, assume availability
feature function : X 7 <n computes n dimensional feature vector
pair. Importantly, employ two different feature functions H C heuristic
cost function noting serving two different roles: heuristic making
local decisions guide search towards high-quality outputs cost function
making global decisions scoring candidate outputs generated heuristic
framework.
2.2 Search Spaces Search Strategies
overview basic search concepts context search-based framework below.
2.2.1 Search Spaces
approach based search space complete outputs, assume
given. Every state search space complete outputs consists input-output
pair (x, y), representing possibility predicting output structured input
x. search space defined terms two functions: 1) initial state function
I(x) returns initial state input x, 2) successor function
search state (x, y), S((x, y)) returns set next states {(x, y1 ), , (x, yk )}
share input x parent. example, sequence labeling problem,
part-of-speech tagging, (x, y) sequence words corresponding part-of-speech
(POS) labels. successors (x, y) might correspond ways changing one
output labels y, so-called flipbit space. Figure 1 provides illustration
flipbit search space handwriting recognition task.
Search Space Quality. effectiveness HC-Search framework depends
quality search space used. quality search space turn
understood terms expected amount search needed uncover correct output
. search procedures, time required find target output grow
function depth target. Thus, one way quantify expected amount
search, independently specific search strategy, considering expected depth
target outputs . particular, given input-output pair (x, ), target depth
372

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 1: example Flipbit search space handwriting recognition problem.
search state consists complete input-output pair complete output
every state differs parent exactly one label. highlighted
state corresponds one true output smallest depth,
equal number errors initial state.

373

fiDoppa, Fern, & Tadepalli

defined minimum depth find state corresponding target
output (d = 5 example flipbit space shown Figure 1). Clearly according
definition, expected target depth flipbit space equal expected number
errors output corresponding initial state.
variety search spaces, flipbit space, Limited Discrepancy Search
(LDS) space (Doppa et al., 2012), defined based hand-designed proposal
distributions (Wick et al., 2011) used past research. work applies
space, focus LDS space experiment, shown
effectively uncover high-quality outputs relatively shallow search depths (Doppa et al.,
2012).
LDS space defined terms recurrent classifier h uses next input
token, e.g. word, output tokens small preceding window, e.g. POS labels,
predict next output token. initial state LDS space consists input
x paired output recurrent classifier h x. One problem recurrent
classifiers recurrent classifier makes mistake, effects get propagated
down-stream tokens. LDS space designed prevent error propagation
immediately correcting mistakes made continuing recurrent classifier.
Since know mistakes made correct them, possible
corrections, called discrepancies, considered. Hence successors state (x, y)
LDS space consist results running recurrent classifier changing exactly
one label, i.e., introducing single new discrepancy, somewhere current output
sequence preserving previously introduced discrepancies. previous work,
LDS space shown effective uncovering high-quality outputs relatively
shallow search depths, one would expect good recurrent classifier (Doppa et al.,
2012). Appendix contains details examples LDS space employ
work.
2.2.2 Search Strategies
Recall HC-Search framework, role search procedure uncover highquality outputs. consider uninformed informed search strategies. However,
uninformed search procedures like depth bounded breadth-first search practical
high-quality outputs exist small depths even feasible,
good choice dont use search time bound intelligent way
make predictions. structured prediction problems, informed search strategies
take heuristic functions account, greedy search best-first search better
choice, noting effectiveness depends quality search heuristic H. Prior
work (Doppa et al., 2012; Wick et al., 2011) shown greedy search (hill climbing
based heuristic value) works quite well number structured prediction tasks
used effective search space. Thus, work, focus empirical work
HC-Search framework using greedy search, though approach applies widely.
2.3 HC-Search Approach
approach parameterized search space complete outputs (e.g., LDS
space), heuristic search strategy (e.g., greedy search), learned heuristic function
374

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 2: high level overview HC-Search framework. Given structured input x
search space definition , first instantiate search space complete
outputs. search node space consists complete input-output pair.
Next, run search procedure (e.g., greedy search) guided heuristic
function H time bound . highlighted nodes correspond search
trajectory traversed search procedure, case greedy search.
scores nodes correspond cost values, different heuristic scores (not shown figure). return least cost output
uncovered search prediction input x.

H : X 7 <, learned cost function C : X 7 <. Given input x
prediction time bound , HC-Search makes predictions follows. traverses search
space starting I(x) using search procedure guided heuristic function H
time bound exceeded. cost function C applied find return least-cost
output generated search prediction input x. Figure 2 gives
high-level overview HC-Search framework.
formally, let YH (x) set candidate outputs generated using heuristic H
given input x. output returned HC-Search least cost output
set according C, i.e.,
= arg minyYH (x) C(x, y)
375

fiDoppa, Fern, & Tadepalli

Figure 3: example illustrates C-Search suffer arbitrarily large loss compared HC-Search.

expected loss HC-Search approach E(H, C) given heuristic H C
defined
E (H, C) = E(x,y )D L (x, y, )
(2)
goal learn heuristic function H corresponding cost function C minimize
expected loss respective spaces H C, i.e.,
(H , C ) = arg min(H,C)HC E (H, C)

(3)

contrast framework, existing approaches output space search (Doppa et al.,
2012; Wick et al., 2011) use single function (say C) serve dual purpose heuristic
cost function. raises question whether HC-Search, uses two different functions, strictly powerful terms achievable losses. following
proposition shows expected loss HC-Search arbitrarily smaller
restricting using single function C.
Proposition 1. Let H C functions function space.
learning problems, minC E(C, C) min(H,C) E(H, C). Moreover exist learning problems
minC E(C, C) arbitrarily larger (i.e. worse) min(H,C) E(H, C).
Proof. first part proposition follows fact first minimization
subset choices considered second.
see second part, consider problem single training instance search
space shown Figure 3. search procedure greedy search either guided
H HC-Search, C one function used. L(n) (n) represents
true loss feature vector node n respectively. cost heuristic functions
linear functions (n). Node 7 corresponds lowest-loss output greedy search
must follow trajectory highlighted nodes order reach output. First consider
HC-Search. highlighted path followed heuristic H needs satisfy
following constraints: H(3)<H(2), H(7)<H(6), weights wH = [1, 1, 1] result
376

fiHC-Search: Learning Framework Search-based Structured Prediction

heuristic satisfies constraints. Given heuristic function, order return node
7 final output, cost function must satisfy following constraints: C(7)<C(1),
C(7)<C(2), C(7)<C(3), C(7)<C(6), weights wC = [1, 1, 0] solve problem.
Thus see HC-Search achieve zero loss problem.
consider case single function C used heuristic cost
function. order generate loss zero, function C must satisfy combined
set constraints placed heuristic cost function. However,
verified set weights satisfies C(3)<C(2) C(7)<C(1),
hence, single function C space achieve loss zero.
scaling losses constant factors make loss suffered arbitrarily high.
Thus, see potential representational advantages following HCSearch framework. follows, consider implications added expressiveness
terms worst-case time complexity learning.
2.4 Learning Complexity
consider feasibility efficient, optimal learning simplest setting greedy
search using linear heuristic cost functions represented weight vectors wH
wC respectively. particular, consider HC-Search Consistency Problem,
input training set structured examples, must decide whether
exists wH wC HC-Search using greedy search achieve zero loss
training set. first note, problem shown NP-Hard appealing
results learning beam search (Xu, Fern, & Yoon, 2009a). particular, results
imply trivial cases, simply determining whether linear
heuristic wH uncovers zero loss search node NP-Hard. Since HC-Search
return zero loss outputs heuristic able uncover them, see problem
also hard.
prove stronger result provides insight HC-Search framework. particular, show even easy learn heuristic uncovers
zero loss outputs, consistency problem still hard. shows, worst case
hardness learning problem simply result hardness discovering
good outputs. Rather problem additionally complicated potential interaction
H C. Intuitively, learning H worst case ambiguity
many small loss outputs generate,
able find effective C return best one. formalized following
theorem, whose proof Appendix.
Theorem 1. HC-Search Consistency Problem greedy search linear heuristic
cost functions NP-Hard even restrict problems possible
heuristic functions uncover zero loss output.

3. Learning Approach
complexity result suggests that, general, learning optimal (H , C ) pair
impractical due potential interdependence. section, develop greedy
377

fiDoppa, Fern, & Tadepalli

stage-wise learning approach first learns H corresponding C. approach
motivated observing decomposition expected loss components due H
C. Below, first describe decomposition staged learning approach
motivates. Next describe approaches learning heuristic cost functions.
3.1 Loss Decomposition Staged Learning
heuristic H cost function C, expected loss E (H, C) decomposed
two parts: 1) generation loss H , due H generating high-quality outputs,
2) selection loss C|H , additional loss (conditional H) due C selecting
best loss output
best loss output generated heuristic. Formally, let yH
set YH (x), i.e.,

yH
= arg minyYH (x) L(x, y, )

express decomposition follows:


E (H, C) = E(x,y )D L (x, yH
, ) + E(x,y )D L (x, y, ) L (x, yH
, y)
|
{z
}
|
{z
}
H

(4)

C|H

Note given labeled data, straightforward estimate generation
selection loss, useful diagnosing HC-Search framework. example, one
observes system high generation loss, little payoff working
improve cost function. empirical evaluation illustrate
decomposition useful understanding results learning.
addition useful diagnosis, decomposition motivates learning approach targets minimizing errors separately. particular, optimize
overall error HC-Search approach greedy stage-wise manner. first train
heuristic H order optimize generation loss component H train cost
function C optimize selection loss C|H conditioned H.
H arg minHH H
C arg minCC C|H
Note approach greedy sense H learned without considering
proof Theorem 1 hinges coupling,
implications learning C.
found practice, learning H independently C effective strategy.
follows, first describe generic approach heuristic function learning
applicable wide range search spaces search strategies, explain
cost function learning algorithm.
3.2 Heuristic Function Learning
generally, learning heuristic viewed Reinforcement Learning (RL) problem heuristic viewed policy guiding search actions rewards
378

fiHC-Search: Learning Framework Search-based Structured Prediction

received uncovering high quality outputs (Zhang & Dietterich, 1995). fact,
approach explored structured prediction case greedy search (Wick,
Rohanimanesh, Singh, & McCallum, 2009) shown effective given carefully
designed reward function action space. viable approach, general purpose
RL quite sensitive algorithm parameters specific definition reward
function actions, make designing effective learner quite challenging. Indeed, recent work (Jiang, Teichert, Daume III, & Eisner, 2012), shown generic RL
algorithms struggle structured prediction problems, even significant effort
put forth designer. Hence, work, follow approach based imitation
learning, makes stronger assumptions, nevertheless effective
easy apply across variety problems.
Algorithm 1 Heuristic Function Learning via Exact Imitation
Input: = Training examples, (I, S) = Search space definition, L = Loss function, =
Rank-based search procedure, max = search time bound
Output: H, heuristic function
1: Initialize set ranking examples R =
2: training example (x, )
3:
s0 = I(x) // initial state search tree
4:
M0 = {s0 } // set open nodes internal memory search procedure
5:
search step = 1 max
6:
Select state(s) expand: Nt =Select(A, L, Mt1 )
7:
Expand every state Nt using successor function S: Ct =Expand(Nt , S)
8:
Prune states update internal memory state search procedure:
Mt =Prune(A, L, Mt1 Ct \ Nt )
9:
Generate ranking examples Rt imitate search step
10:
Add ranking examples Rt R: R = R Rt // aggregation training data
11:
end
12: end
13: H =Rank-Learner(R) // learn heuristic function ranking examples
14: return learned heuristic function H
heuristic learning approach based observation many structured
prediction problems, quickly generate high-quality outputs guiding
search procedure using true loss function L heuristic. Obviously
done training data know . suggests formulating heuristic
learning problem framework imitation learning attempting learn heuristic
mimics search decisions made true loss function training examples.
learned heuristic need approximate true loss function uniformly output
space, need make distinctions important guiding search.
main assumptions made approach are: 1) true loss function provide effective
heuristic guidance search procedure, worth imitating, 2)
learn imitate search decisions sufficiently well.
imitation learning approach similar prior work learning single cost functions
output-space search (Doppa et al., 2012). However, key distinction learning
379

fiDoppa, Fern, & Tadepalli

focused making distinctions necessary uncovering good outputs (the purpose
heuristic) hence requires different formulation. prior work, order
avoid need approximate loss function arbitrarily closely, restrict
rank-based search strategies. search strategy called rank-based makes
search decisions comparing relative values search nodes (their ranks) assigned
heuristic, rather sensitive absolute values heuristic. common
search procedures greedy search, beam search, best-first search fall
category.
3.2.1 Imitating Search Behavior
Given search space complete outputs S, rank-based search procedure A,
search time bound , learning procedure generates imitation training data
training example (x, ) follows. run search procedure time bound
input x using heuristic equal true loss function, i.e. H(x, y) = L(x, y, ).
search process observe pairwise ranking decisions made using
oracle heuristic record sufficient (see below) replicating search.
state (x, y1 ) smaller loss (x, y2 ), ranking example generated
form constraint H(x, y1 )<H(x, y2 ). Ties broken using fixed arbitrator1 .
aggregate set ranking examples collected training examples given
learning algorithm learn weights heuristic function.
learn function H hypothesis space H consistent
ranking examples, learned heuristic guaranteed replicate oracle-guided
search training data. Further, given assumptions base learning algorithm
(e.g. PAC), generic imitation learning results used give generalization guarantees
performance search new examples (Khardon, 1999; Fern, Yoon, & Givan, 2006;
Syed & Schapire, 2010; Ross & Bagnell, 2010). experiments show, simple
approach described above, performs extremely well problems.
Algorithm 1 describes approach heuristic function learning via exact imitation
search guided loss function. applicable wide-range search spaces, search
procedures loss functions. learning algorithm takes input: 1) = {(x, )},
set training examples structured prediction problem (e.g., handwriting recognition);
2) = (I, S), search space complete outputs (e.g., LDS space), initial
state function successor function; 3) L, task loss function defined
complete outputs (e.g., hamming loss); 4) A, rank-based search procedure (e.g., greedy
search); 5) max , search time bound (e.g., number search steps).
algorithmic description Algorithm 1 assumes search procedure
described terms three steps executed repeatedly open list search
nodes: 1) selection, 2) expansion 3) pruning. execution, search procedure
selects one open nodes internal memory expansion (step 6) based
heuristic value, expands selected nodes generate candidate set (step 7).
retains subset open nodes expansion internal memory
prunes away remaining ones (step 8) based heuristic value. example,
1. LDS Space employed work, implemented arbitrator breaks ties
based position discrepancy (prefers earlier discrepancies).

380

fiHC-Search: Learning Framework Search-based Structured Prediction

greedy search maintains best node, best-first beam search retains best b
nodes fixed beam-width b, pure best first search pruning.
Algorithm 1 loops training example collects set ranking constraints. Specifically, example (x, ), search procedure run time bound
max using true loss function L heuristic (steps 2-12). search step
set pairwise ranking examples generated sufficient allowing search step
imitated (step 9) described detail below. constraints
aggregated across search steps training examples, given rank-learning
algorithm (e.g., Perceptron SVM-Rank) learn weights heuristic function
(step 13).
important step heuristic function learning algorithm generation
ranking examples imitate step search procedure (step 9). follows,
give generic description sufficient pairwise decisions imitate search,
illustrate greedy search simple example.
3.2.2 Sufficient Pairwise Decisions
noted need collect learn imitate sufficient pairwise
decisions encountered search. say set constraints sufficient
structured training example (x, ), heuristic function consistent
constraints causes search follow trajectory open lists encountered
search. precise specification constraints depends actual search procedure
used. rank-based search procedures, sufficient constraints
categorized two types:
1. Selection constraints, ensure search node(s) internal memory
state expanded next search step (are) ranked better
nodes.
2. Pruning constraints, ensure internal memory state (set search nodes)
search procedure preserved every search step. specifically,
constraints involve ranking every search node internal memory state better
(lower H-value) pruned.
Below, illustrate constraints concretely greedy search noting similar
formulations rank-based search procedures straightforward (See (Doppa, Fern,
& Tadepalli, 2014a) beam search formulation).
3.2.3 Constraints Greedy Search
basic rank-based search procedure. given input x, traverses
search space selecting next state successor current state looks best
according heuristic function H. particular, si search state step i, greedy
search selects si+1 = arg minsS(si ) H(s), s0 = I(x). greedy search, internal
memory state search procedure step consists best open (unexpanded)
node si .
381

fiDoppa, Fern, & Tadepalli

Figure 4: example search tree illustrates greedy search loss function.
node represents complete input-output pair evaluated using loss
function. highlighted nodes correspond trajectory greedy search
guided loss function.

Let (x, yi ) correspond input-output pair associated state si . Since greedy
search maintains single open node si internal memory every search step i,
selection constraints. Let Ci+1 candidate set expanding state si ,
i.e., Ci+1 = S(si ). Let si+1 best node candidate set Ci+1 evaluated
loss function, i.e., si+1 = arg minsCi+1 L(s). greedy search prunes nodes
candidate set si+1 , pruning constraints need ensure si+1 ranked better
nodes Ci+1 . Therefore, include one ranking constraint every
node (x, y) Ci+1 \ (x, yi+1 ) H(x, yi+1 ) < H(x, y).
illustrate ranking constraints example. Figure 4 shows
example search tree depth two associated losses every search node.
highlighted nodes correspond trajectory greedy search loss function
learner imitate. first search step, {H(3) < H(2), H(3) < H(4)} pruning
constraints. Similarly, {H(10) < H(8), H(10) < H(9)} form pruning constraints
second search step. Therefore, aggregate set constraints needed imitate greedy
search behavior shown Figure 4 are:
{H(3) < H(2), H(3) < H(4), H(10) < H(8), H(10) < H(9)}.
3.3 Cost Function Learning
Given learned heuristic H, want learn cost function correctly ranks
potential outputs generated search procedure guided H. formally, let YH (x)
set candidate outputs generated search procedure guided heuristic H
given input x, lbest loss best output among outputs evaluated
true loss function L, i.e., lbest = minyYH (x) L(x, y, ). exact learning scenario,
goal find parameters cost function C every training example
382

fiHC-Search: Learning Framework Search-based Structured Prediction

(x, ), loss minimum cost output equals lbest , i.e., L(x, y, ) = lbest ,
= arg minyYH (x) C(x, y). practice, exact learning isnt possible, goal
find cost function average loss training data predicted output
using cost function minimized.
Algorithm 2 Cost Function Learning via Cross Validation
Input: = Training examples, = Search space definition, L = Loss function, =
Search procedure, max = search time bound
Output: C, cost function
1: Divide training set k folds D1 , D2 , , Dk
2: // Learn k different heuristics H1 , , Hk
3: = 1 k
4:
Ti = j6=i Dj // training data heuristic Hi
5:
Hi = Learn-Heuristic(Ti , , L, A, max ) // heuristic learning via Algorithm 1
6: end
7: // Generate ranking examples cost function training
8: Intialize set ranking examples R =
9: = 1 k
10:
training example (x, ) Di
11:
Generate outputs running search procedure heuristic Hi time
bound max : YHi (x) = Generate-Outputs(x, , A, Hi , max )
12:
Compute set best loss outputs: Ybest = {y YHi (x)|L(x, y, ) = lbest },
lbest = minyYH (x) L(x, y, )

13:
pair outputs (ybest , y) Ybest YHi (x) \ Ybest
14:
Add ranking example C(x, ybest ) < C(x, y) R
15:
end
16:
end
17: end
18: // Train cost function ranking examples
19: C = Rank-Learner(R)
20: return learned cost function C
formulate cost function training problem instance rank learning problem
(Agarwal & Roth, 2005). specifically, want best loss outputs YH (x)
ranked better non-best loss outputs according cost function,
bi-partite ranking problem. Let Ybest set best loss outputs YH (x), i.e.,
Ybest = {y YH (x)|L(x, y, ) = lbest }. generate one ranking example every pair
outputs (ybest , y) Ybest YH (x) \ Ybest , requiring C(x, ybest )<C(x, y). search
procedure able generate target output (i.e., lbest = 0), similar
standard learning CRFs SVM-Struct, results much simpler rank-learning
problem (cost function needs rank correct output incorrect outputs
generated search). set best loss outputs Ybest large, bi-partite
ranking may result highly over-constrained problem. cases, one could relax
problem attempting learn cost function ranks least one output Ybest higher
non-best loss outputs. easily implemented online-learning
383

fiDoppa, Fern, & Tadepalli

framework follows. error (i.e., best cost output according current
weights
/ Ybest ), weights updated ensure best cost output ybest Ybest
according current weights ranked better outputs YH (x) \ Ybest .
important note theory practice, distribution outputs
generated learned heuristic H testing data may slightly different
one training data. Thus, train C training examples used train H, C
necessarily optimized test distribution. mitigate effect, train
cost function via cross validation (see Algorithm 2) training cost function
data, used train heuristic. training methodology commonly
used Re-ranking style algorithms (Collins, 2000) among others.
Algorithm 2 describes approach cost function training via cross validation.
four main steps algorithm. First, divide training data k folds.
Second, learn k different heuristics, heuristic Hi learned using data
folds excluding ith fold (Steps 3-6). Third, generate ranking examples
cost function learning described using heuristic Hi data
trained (Steps 9-17). Finally, give aggregate set ranking examples R rank
learner (e.g., Perceptron, SVM-Rank) learn cost function C (Step 19).
3.4 Rank Learner
section, describe specifics rank learner used learn
heuristic cost functions aggregate sets ranking examples produced
algorithms. use off-the-shelf rank-learning algorithm (e.g., Perceptron,
SVM-Rank) base learner train heuristic function set ranking
examples R. specific implementation employed online Passive-Aggressive
(PA) algorithm (Crammer, Dekel, Keshet, Shalev-Shwartz, & Singer, 2006) base
learner. Training conducted 50 iterations experiments.
PA online large-margin algorithm, makes several passes training
examples R, updates weights whenever encounters ranking error. Recall
ranking example form H(x, y1 ) < H(x, y2 ) heuristic training C(x, y1 ) <
C(x, y2 ) cost function training, x structured input target output ,
y1 y2 potential outputs x L(x, y1 , ) < L(x, y2 , ). Let >0
difference losses two outputs involved ranking example.
experimented PA variants use margin scaling (margin scaled ) slack
scaling (errors weighted ) (Tsochantaridis, Joachims, Hofmann, & Altun, 2005). Since
margin scaling performed slightly better slack scaling, report results PA
variant employs margin scaling. give full details margin scaling
update.
Let wt current weights linear ranking function.
ranking error
cycling training data, i.e., wt (x, y2 ) wt (x, y1 ) < , new
weights wt+1 corrects error obtained using following equation.
wt+1 = wt + ((x, y2 ) (x, y1 ))
384

fiHC-Search: Learning Framework Search-based Structured Prediction

learning rate given
wt (x, y1 ) wt (x, y2 ) +
=
k(x, y2 ) (x, y1 )k2





specific update previously used cost-sensitive multiclass classification
(Crammer et al., 2006) (See Equation 51) structured output problems (Keshet,
Shalev-Shwartz, Singer, & Chazan, 2005) (See Equation 7).

4. Experiments Results
section empirically investigate HC-Search approach compare
state-of-the-art structured prediction.
4.1 Datasets
evaluate approach following four structured prediction problems including
three benchmark sequence labeling problems 2D image labeling problem.
Handwriting Recognition (HW). input sequence binary-segmented
handwritten letters output corresponding character sequence [a z]+ .
dataset contains roughly 6600 examples divided 10 folds (Taskar et al.,
2003). consider two different variants task work Hal Daume
III, Langford, Marcu (2009). HW-Small version, use one fold training
remaining 9 folds testing, vice-versa HW-Large.
NETtalk Stress. text-to-speech mapping problem, task
assign one 5 stress labels letter word. 1000 training
words 1000 test words standard dataset. use sliding window size
3 observational features.
NETtalk Phoneme. similar NETtalk Stress except task
assign one 51 phoneme labels letter word.
Scene labeling. data set contains 700 images outdoor scenes (Vogel &
Schiele, 2007). image divided patches placing regular grid size
1010 entire image, patch takes one 9 semantic labels (sky,
water, grass, trunks, foliage, field, rocks, flowers, sand ). Simple appearance features
including color, texture position used represent patch. Training
performed 600 images, remaining 100 images used testing.
4.2 Experimental Setup
HC-Search experiments, use Limited Discrepancy Space (LDS) exactly
described work Doppa et al. (2012) search space structured outputs.
Prior work HC-Search shown greedy search works quite well structured prediction tasks, particularly using LDS space (Doppa et al., 2012). Hence,
consider greedy search experiments. would like point experiments shown using beam search best first search produce similar results.
385

fiDoppa, Fern, & Tadepalli

training testing set search time bound 25 search steps domains
except scene labeling, much larger search space uses = 150.
found using values larger produce noticeable improvement.
extremely small values , performance tends worse, increases quickly
made larger. also show results full spectrum time bounds later.
domains, learn linear heuristic cost functions second order features unless otherwise noted. case, feature vector measures features neighboring label pairs
triples along features structured input. measure error Hamming
loss unless otherwise noted.
4.3 Comparison State-of-the-Art
compare results HC-Search approach structured prediction algorithms including CRFs (Lafferty et al., 2001), SVM-Struct (Tsochantaridis et al., 2004),
Searn (Hal Daume III et al., 2009), Cascades (Weiss & Taskar, 2010) C-Search,
identical HC-Search except uses single-function output space search
(Doppa et al., 2012). also show performance Recurrent, simple
recurrent classifier trained exactly work Doppa et al. (2012). top section
Table 1 shows error rates different algorithms. scene labeling
possible run CRFs, SVM-Struct, Cascades due complicated grid structure
outputs (hence - table). report best published results CRFs,
SVM-Struct, Searn. Cascades trained using implementation (Weiss, 2014) provided authors, used sequence labeling problems Hamming loss.
would like point results cascades differ appear
work Doppa, Fern, Tadepalli (2013) obtained using updated2 version
cascades training code. Across benchmarks, see results HC-Search comparable significantly better state-of-the-art including C-Search, uses single
function heuristic function cost function. results scene labeling
domain significant improving error rate 27.05 19.71. results
show HC-Search state-of-the-art approach across problems learning
separate heuristic cost functions significantly improve output-space search.
4.4 Higher-Order Features
One advantages approach compared many frameworks structured prediction ability use expressive feature spaces without paying huge computational
price. bottom part Table 1 shows results using third-order features (compared
second-order above) HC-Search, C-Search Cascades. Note practical
run methods using third-order features due substantial increase inference
time. overall error HC-Search higher-order features slightly improved compared
using second-order features across benchmarks still better error-rates
C-Search Cascades third-order features, exception Cascades
HW-Large. fact, HC-Search using second-order features still outperforming
third-order results methods three five domains.
2. Personal communication author

386

fiHC-Search: Learning Framework Search-based Structured Prediction

Algorithms
HW-Small

HW-Large

Datasets
Stress Phoneme

Scene labeling

HC-Search
C-Search
CRF
SVM-Struct
Recurrent
Searn
Cascades

a. Comparison state-of-the-art
12.81
03.23
17.58
16.91
17.03
07.16
21.07
20.81
19.97
13.11
21.48
21.09
19.64
12.49
22.01
21.70
34.33
25.13
27.18
26.42
17.88
09.42
23.85
22.74
13.02
03.22
20.41
17.56

19.71
27.05
43.36
37.69
-

HC-Search
C-Search
Cascades

b. Results Third-Order Features
10.04
02.21
16.32
14.29
14.15
04.76
19.36
18.19
10.82
02.16
19.51
17.41

18.25
25.79
-

Table 1: Error rates different structured prediction algorithms.
4.5 Loss Decomposition Analysis
examine HC-Search C-Search terms loss decomposition (see Equation 4) generation loss H selection loss C|H . quantities
easily measured HC-Search C-Search keeping track best loss output
generated search (guided either heuristic cost function C-Search)
across testing examples. Table 2 shows results, giving overall error HC
decomposition across benchmarks HC-Search C-Search.
first see generation loss H similar C-Search HC-Search across
benchmarks exception scene labeling, HC-Search generates slightly better
outputs. shows least LDS search space difference performance
C-Search HC-Search cannot explained C-Search generating lower quality
outputs. Rather, difference two methods reflected difference
selection loss C|H , meaning C-Search effective ranking outputs
generated search compared HC-Search. result clearly shows advantage
separating roles C H understandable light training mechanism
C-Search. approach, cost function trained satisfy constraints related
generation loss selection loss. turns many generation
loss constraints, hypothesize biases C-Search toward low generation loss
expense selection loss.
results also show methods selection loss C|H contributes significantly overall error compared H . shows approaches
able uncover high-quality outputs, unable correctly rank generated
outputs according losses. suggests first avenue improving results
HC-Search would improve cost function learning component, e.g. using
non-linear cost functions.
387

fiDoppa, Fern, & Tadepalli

4.6 Ablation Study
futher demonstrate two separate functions (heuristic cost function)
HC-Search lead accurate predictions compared using single function
C-Search, perform ablation experiments. study, take learned
heuristic function H cost function C HC-Search framwork, use one
make predictions. example, HH-Search corresponds configuration
use function H heuristic cost function. Similarly, CC-Search corresponds
configuration use function C heuristic cost function.
Table 2b shows results ablation experiments. make several interesting observations results. First, overall error HC-Search significantly
better HH-Search CC-Search. Second, selection loss HH-Search
increases compared HC-Search. understandable H trained
score candidate outputs generated search. Third, generation
loss CC-Search increases compared HC-Search behavior significant
(increases 11.24 compared 5.82) scene labeling task. results provide
evidence importance separating training heuristic cost
functions.
HW-Small
C|H
H

Stress
C|H
H

HC

03.2
07.1

a. HC-Search vs. C-Search
00.7 02.7 17.5 02.7 14.7
00.9 06.2 21.0 03.0 18.0

16.9
20.8

03.4
04.1

13.4
16.6

19.7
27.0

05.8
07.8

13.8
19.2

07.9
06.6

b. Results Ablation study
00.7 7.2
22.5 02.7 19.7
01.7 04.9 19.1 03.2 15.8

22.1
21.6

03.4
04.3

18.7
17.3

32.1
25.3

07.8
11.2

24.3
14.0

c. Results heuristic function training via DAgger
08.1 03.1 00.4 02.6 17.2 02.2 15.0 16.8 03.0
09.9 05.1 00.8 03.6 20.3 02.8 17.1 19.0 03.9

13.8
14.7

18.0
24.2

03.7
05.9

14.3
18.3

11.7

16.3

00.3

16.0

Datasets
Error

HC

HC-Search
C-Search

12.8
17.5

04.7
04.9

08.0
12.6

HH-Search
CC-Search

18.4
16.2

04.7
05.3

13.7
10.9

HC-Search
C-Search

12.0
15.1

03.9
04.6

HC

HW-Large
C|H
H

HC

Phoneme
C|H
H

HC

Scene
C|H
H

d. Results Oracle Heuristic
LC-Search
(Oracle H)

10.1

00.2

09.9

03.0

00.5

02.5

14.1

00.2

13.9

12.2

00.5

Table 2: HC-Search: Error decomposition heuristic cost function.
4.7 Results Heuristic Training via DAgger
heuristic learning approach follows simplest approach imitation learning, exact
imitation, learner attempts exactly imitate observed expert trajectories
(here imitate search oracle heuristic). experiments show exact
imitation performs quite well, known exact imitation certain deficiencies
general. particular, functions trained via exact imitation prone error propagation (Kaariainen, 2006; Ross & Bagnell, 2010), errors made test time change
distribution decisions encountered future compared training distribution.
address problem, sophisticated imitation learning algorithms developed, state-of-the-art approach DAgger (Ross, Gordon, & Bagnell, 2011).
388

fiHC-Search: Learning Framework Search-based Structured Prediction

consider whether DAgger improve heuristic learning turn overall
accuarcy.
DAgger iterative algorithm, iteration adds imitation data aggregated data set. first iteration follows exact imitation approach, data
collected observing expert trajectory (or number them). iteration
imitation function (here heuristic) learned current data. Successive iterations
generate trajectories following mixture expert suggestions (in case ranking decisions) suggestions recently learned imitation function. decision point
along trajectory added aggregate data set labeling expert decision.
way, later iterations allow DAgger learn states visited possibly erroneous learned functions correct mistakes using expert input. Ross et al. (2011)
show iterations DAgger using learned policy without mixing
expert policy performs well across diverse domains. Therefore, use
approach DAgger experiments. experiments run 5 iterations DAgger,
noting noticable improvement observed 5 iterations.
Table 2c shows results HC-Search C-Search obtained training DAgger. HC-Search, generation loss (H ) improved slightly sequence labeling
problems little room improvement, DAgger leads significant improvement generation loss challenging problem scene labeling. also
see overall error HC-Search scene labeling reduces due improvement
generation loss showing cost function able leverage better outputs produced
heuristic. Similarly, overall error C-Search also improved DAgger across
board see significant improvements handwiriting scene labeling
domains. interesting note unlike HC-Search, improvement C-Search
mostly due improvement selection loss (C|H ) except scene labeling task,
due improvement generation loss selection loss.
results show improving heuristic learning able improve overall
performance. clear whether improvement, perhaps due future
advances imitation learning, would yet lead overall improvement. is,
may possible improve generation loss, clear cost function
able exploit improvments. help evaluate ran experiment
gave HC-Search true loss function use heuristic (an oracle heuristic), i.e.,
H(x, y) = L(x, y, ), training cost function testing. provides
assessment much better might able could improve heuristic
learning. results Table 2, label LC-Search (Oracle H) show
using oracle heuristic, H negligible might expect smaller observed
HC-Search. shows may possible improve heuristic learning
via better imitation.
also see oracle results overall error HC better
HC-Search, HW-Small Scene labeling tasks, selection error C|H got slightly
worse.. indicates cost function learner able leverage, varying degrees, better outputs produced oracle heuristic. suggests improving
heuristic learner order reduce generation loss could viable way
reducing overall loss HC-Search, even without altering current cost learner. However, saw much less room improve heuristic learner
389

fiDoppa, Fern, & Tadepalli

data sets hence potential gains less directly trying improve cost
learner.
4.8 Results Training Different Time bounds

Train

also trained HC-Search different time bounds (i.e., number greedy search steps)
see overall loss, generation loss selection loss vary increase training
time bound. general, time bound increases, generation loss monotonically
decrease, since strictly outputs encountered. hand difficulty
cost function learning increase time bound grows since must learn distinguish larger set candidate outputs. Thus, degree overall
error decreases (or grows) time bound depends combination much
generation loss decreases whether cost function learner able accurately
distinguish improved outputs.
Figure 5 shows performance HC-Search full spectrum time bounds.
Qualitatively, see generation loss, due heuristic, decreases remarkably
fast benchmarks improves little initial decrease. also see
cost function learner achieves relatively stable selection loss short time, though
increase bit time cases. combined effect see overall
error HC improves quickly increase time bound improvement tends
small beyond certain time bound. Also, cases (e.g., phoneme prediction
scene labeling) performance tends get slightly worse large time bounds,
happens increase selection loss counteracted decreased generation
loss.
Loss Function
Hamming
VC

Test
Hamming
VC
1757
4658
1769
4620

Table 3: Results training non-hamming loss functions.

4.9 Results Training Non-Hamming Loss functions
One advantages HC-Search compared many approaches structured
prediction sensitive loss function used training. trained HCSearch different loss functions handwriting domain verify true
practice not. used hamming loss (uniform misclassification cost 1 characters)
Vowel-Consonant (VC) loss (different misclassification costs vowels consonants)
experiment. VC loss, used misclassification costs 4 2 vowels
consonants respectively. Training done 5 folds remaining 5 folds used
testing. Table 4.8 shows results training testing two loss functions.
report cumulative loss testing examples. see, testing
loss function, training loss function gives slightly better performance
training using different loss function. shows HC-Search learning approach
390

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 5: HC-Search results training different time bounds. training time
bound (i.e., no. greedy search steps) x-axis error y-axis.
three curves graph corresponding overall loss HC , generation loss H
selection loss C|H .

391

fiDoppa, Fern, & Tadepalli

sensitive loss function. However, result may hold generally much
depends problem structure, loss function ability cost function
capture loss.
4.10 Discussion Efficiency HC-Search Approach
HC-Search framework, basic computational elements include generating candidate
states given state; computing heuristic function features via H cost function
features via C candidate states; computing heuristic cost scores via
learned heuristic cost function pair (H, C). computational time generating
candidate states depends employed search space = (I, S), initial
state function successor function. example, generation candidates
efficient Flipbit space compared LDS space (involves running
recurrent classifier every action specified successor function S). Therefore,
efficiency overall approach depends size candidate set
greatly improved generating fewer candidate states (e.g., via pruning) parallelizing
computation. done preliminary work direction introducing sparse
versions LDS Flipbit search spaces pruning actions based recurrent
classifier scores (as specified prunining parameter k). simple pruning strategy
resulted 10-fold speedup little loss accuracy across several benchmark
problems (Doppa et al., 2014a). However, work needs done learning pruning
rules improve efficiency HC-Search approach.

5. Engineering Methodology Applying HC-Search
section, describe engineering methodology applying HC-Search framework new problems. high-level, methodology involves selecting effective
time-bounded search architecture (search space, search procedure, search time-bound),
leveraging loss decomposition terms generation selection loss training
debugging heuristic cost functions. describe steps detail.
5.1 Selection Time-bounded Search Architecture
time-bounded search architecture instantiated selecting search space, search
strategy, search time-bound. mentioned before, effectiveness HC-Search
depends critically quality search space (i.e., search depth target
outputs found) employed. fact, prior work empirically demonstrated performance gap search architectures Flipbit space LDS
space grows difference target depths increase (Doppa et al., 2014a).
Therefore, important select/design high-quality search space problem
hand.
exists greedy predictor structured prediction problem, one could leverage define appropriate variant LDS space. Fortunately, greedy
predictors several problems natural language processing, computer vision, relational
networks, planning preferences. example, transition-based parsers dependency parsing (Nivre, 2008; Goldberg & Elhadad, 2010); greedy classifiers co-reference
392

fiHC-Search: Learning Framework Search-based Structured Prediction

resolution (Chang, Samdani, & Roth, 2013; Stoyanov & Eisner, 2012) event extraction
(Li, Ji, & Huang, 2013); sequential labelers boundary detection objects images
(Payet & Todorovic, 2013); iterative classifiers collective inference relational networks
(Sen, Namata, Bilgic, Getoor, Gallagher, & Eliassi-Rad, 2008; Doppa, Yu, Tadepalli, &
Getoor, 2009, 2010); classifier chains multi-label prediction (Read, Pfahringer, Holmes,
& Frank, 2011); greedy planners planning preferences (Xu, Fern, & Yoon,
2010). general, designing high-quality search spaces key research topic
work needs done direction. Learning search operators (macro actions)
transformation rules Transformation-based Learning (TBL) (Brill, 1995) optimize
search space one many possibilities. Sometimes problem structure also help
designing effective search spaces. example, multi-label prediction problems,
outputs binary vectors small number active labels (highly sparse).
simple flipbit space initialized null vector effective (Doppa, Yu,
Ma, Fern, & Tadepalli, 2014b).
picking search space, need select appropriate search procedure
search time-bound. effectiveness search architecture measured performing
oracle search (true loss function used heuristic cost function) training
data. one could perform oracle search (LL-Search) different search procedures (e.g.,
greedy beam search) different time-bounds select search procedure
effective. see benefit beam search problems considered,
expect change harder problems non-Hamming loss functions (e.g.,
B-Cubed score co-reference resolution). search space redundant,
fix search time-bound value performance search architecture
stagnates. Otherwise, one allow slack search procedure recover
errors. experiments, found (size structured output)
reasonable value time-bound (Figure 5 provides justification choice).
5.2 Training Debugging
training procedure involves learning heuristic H cost function C optimize
performance selected time-bounded search architecture training data.
Following staged learning approach, one could start learning heuristic via exact
imitation oracle search. that, learned heuristic H evaluated
measuring generation loss (HL-Search configuration). performance HLSearch configuration acceptable respect performance LL-Search,
move cost function learning part. Otherwise, try improve heuristic either
employing sophisticated imitation learning algorithms (e.g., DAgger), enriching
feature function H , employing powerful rank learner. Similarly, learning
cost function C conditioned learned heuristic, measure selection loss.
selection loss high, try improve cost function either adding
expressive features C employing powerful rank learner.

6. Comparison Related Work
described earlier, majority structured prediction work focused use
exact inference computing outputs tractable, approximate inference
393

fiDoppa, Fern, & Tadepalli

techniques, loopy belief propagation relaxation methods, not. Learning focused tuning cost function parameters order optimize various
objective functions, differ among learning algorithms (Lafferty et al., 2001; Taskar
et al., 2003; Tsochantaridis et al., 2004; McAllester, Hazan, & Keshet, 2010). also
approximate cost function learning approaches employ inference routine
training. example, piece-wise training (Sutton & McCallum, 2009), Decomposed
Learning (Samdani & Roth, 2012) special case pseudo-max training (Sontag, Meshi,
Jaakkola, & Globerson, 2010) fall category. training approaches
efficient, still need inference algorithm make predictions testing.
cases, one could employ Constrained Conditional Models (CCM) framework
(Chang, Ratinov, & Roth, 2012) declarative (global) constraints make predictions using learned cost function. CCM framework relies Integer Linear
Programming (ILP) inference method (Roth & tau Yih, 2005). recent work attempted integrate (approximate) inference cost function learning principled
manner (Meshi, Sontag, Jaakkola, & Globerson, 2010; Stoyanov, Ropson, & Eisner, 2011;
Hazan & Urtasun, 2012; Domke, 2013). Researchers also worked using higher-order
features CRFs context sequence labeling pattern sparsity assumption
(Ye, Lee, Chieu, & Wu, 2009; Qian, Jiang, Zhang, Huang, & Wu, 2009). However,
approaches applicable graphical models sparsity assumption
hold.
alternative approach addressing inference complexity cascade training (Felzenszwalb & McAllester, 2007; Weiss & Taskar, 2010; Weiss, Sapp, & Taskar, 2010),
efficient inference achieved performing multiple runs inference coarse level
fine level abstraction. approaches shown good success, place
restrictions form cost functions facilitate cascading. Another potential drawback cascades approaches either ignore loss
function problem (e.g. assuming Hamming loss) require loss function
decomposable way supports loss augmented inference. approach sensitive
loss function makes minimal assumptions it, requiring
blackbox evaluate potential output.
Classifier-based structured prediction algorithms avoid directly solving Argmin problem assuming structured outputs generated making series discrete
decisions. approach attempts learn recurrent classifier given input
x iteratively applied order generate series decisions producing target
output y. Simple training methods (e.g. Dietterich, Hild, & Bakiri, 1995) shown
good success positive theoretical guarantees (Syed & Schapire, 2010;
Ross & Bagnell, 2010). However, recurrent classifiers prone error propagation
(Kaariainen, 2006; Ross & Bagnell, 2010). Recent work, e.g. SEARN (Hal Daume III
et al., 2009), SMiLe (Ross & Bagnell, 2010), DAgger (Ross et al., 2011), attempts
address issue using sophisticated training techniques shown state-of-theart structured-prediction results. However, approaches use classifiers produce
structured outputs single sequence greedy decisions. Unfortunately, many
problems, decisions difficult predict greedy classifier, crucial
good performance. contrast, approach leverages recurrent classifiers define good
394

fiHC-Search: Learning Framework Search-based Structured Prediction

quality search spaces complete outputs, allows decision making comparing
multiple complete outputs choosing best.
also non-greedy methods learn scoring function search space
partial structured outputs (DaumeIII & Marcu, 2005; Daume III, 2006; Xu, Fern, & Yoon,
2009b; Huang, Fayong, & Guo, 2012; Yu, Huang, Mi, & Zhao, 2013). methods
perform online training, differ way search errors defined
weights updated errors occur. Unfortunately, training scoring function
difficult hard evaluate states partial outputs theoretical
guarantees learned scoring function (e.g., convergence generalization results)
rely strong assumptions (Xu et al., 2009b).
work closely related output space search approaches (Doppa et al.,
2012; Wick et al., 2011), use single cost function serve search heuristic
also score candidate outputs. Serving dual roles often means cost
function needs make unclear tradeoffs, increasing difficulty learning. HCSearch approach overcomes deficiency learning two different functions, heuristic
function guide search generate high-quality candidate outputs, cost function
rank candidate outputs. Additionally, error decomposition HC-Search terms
heuristic error cost function error allows human designers learning system
diagnose failures take corrective measures.
approach also related Re-Ranking (Collins, 2002), uses generative
model propose k-best list outputs, ranked separate ranking
function. contrast, rather restricting generative model producing potential
outputs, approach leverages generic search efficient search spaces guided
learned heuristic function minimal representational restrictions, employs
learned cost function rank candidate outputs. Recent work generating multiple
diverse solutions probabilistic framework considered another way producing
candidate outputs. representative set approaches line work diverse Mbest (Batra, Yadollahpour, Guzman-Rivera, & Shakhnarovich, 2012), M-best modes (Park
& Ramanan, 2011; Chen, Kolmogorov, Zhu, Metaxas, & Lampert, 2013) Determinantal
Point Processes (Kulesza & Taskar, 2012).
general area speedup learning studied planning search community
also related work (Fern, 2010). problems, cost function typically known
objective learn control knowledge (i.e., heuristic function) directing search
algorithm low-cost terminal node search space. example, STAGE (Boyan &
Moore, 2000) learns evaluation function states improve performance
search, value state corresponds performance local search algorithm
starting state, (Zhang & Dietterich, 1995) use Reinforcement Learning (RL)
methods learn heuristics job shop scheduling goal minimizing duration
schedule. Unlike problems planning combinatorial optimization,
cost function given structured prediction problems. Therefore, HC-Search
approach learns cost function score structured outputs along heuristic
function guide search towards low cost outputs.
395

fiDoppa, Fern, & Tadepalli

7. Summary Future Work
introduced HC-Search framework structured prediction whose principal feature
separation cost function search heuristic. showed framework
yields significantly superior performance state-of-the-art results, allows informative error analysis diagnostics.
investigation showed main source error existing output-space approaches including approach (HC-Search) inability cost function correctly rank candidate outputs produced output generation process. analysis
suggests learning powerful cost functions, e.g., Regression trees (Mohan, Chen,
& Weinberger, 2011), eye towards anytime performance (Grubb & Bagnell, 2012;
Xu, Weinberger, & Chapelle, 2012) would productive. results also suggested
room improve overall performance better heuristic learning. Thus, another
direction pursue heuristic function learning speed process generating
high-quality outputs (Fern, 2010).
Future work includes applying framework challenging problems natural language processing (e.g., co-reference resolution, dependency parsing, semantic
parsing) computer vision (e.g., object detection biological images Lam, Doppa, Hu,
Todorovic, Dietterich, Reft, & Daly, 2013, multi-object tracking complex sports
videos Chen, Fern, & Todorovic, 2014). effectiveness HC-Search approach depends
quality search space, therefore, work needs done learning
optimize search spaces leveraging problem structure. Similarly, studying pruning
techniques improve efficiency learning inference another useful
direction.
Acknowledgements
authors would like thank anonymous reviewers Jason Eisner, associate
editor, comments feedback. first author would also like thank Tom
Dietterich encouragement support throughout work. work supported part NSF grants IIS 1219258, IIS 1018490 part Defense Advanced
Research Projects Agency (DARPA) Air Force Research Laboratory (AFRL)
Contract No. FA8750-13-2-0033. opinions, findings conclusions recommendations expressed material author(s) necessarily reflect
views NSF, DARPA, Air Force Research Laboratory (AFRL),
US government. preliminary version article published AAAI-2013 (Doppa
et al., 2013)

Appendix A. Limited Discrepancy Search (LDS) Space
Limited Discrepancy Search (LDS) space (Doppa et al., 2012, 2014a) defined terms
learned recurrent classifier h. Thus, start describing recurrent classifier
explain key idea behind LDS space. simplicity, explain main ideas using
sequence labeling problem (handwriting recognition task) noting generalize
non-sequence labeling problems (for full details see Doppa et al., 2012, 2014a).
396

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 6: Illustration recurrent classifier handwriting recognition problem. classifier predicts labels left-to-right order. makes labeling decision
position greedily based character image predicted label
previous position (shown dotted box). particular example,
classifier makes mistake first position error propagates
positions leading bad output.

A.1 Recurrent Classifier
sequence labeling problem, recurrent classifier produces label position
sequence, based input position predicted labels previous positions
(Dietterich et al., 1995). learned classifier accurate, number incorrect
labeling decisions relatively small. However, even small number errors
propagate cause poor outputs.
Figure 6 illustrates recurrent classifier handwriting recognition example.
classifier predicts labels left-to-right order. makes labeling decision
position greedily based character image predicted label previous
position (shown dotted box). particular example, classifier makes
mistake first position error propagates leading bad output (5
errors).
A.2 Limited Discrepancy Search (LDS)
LDS originally introduced context problem solving using heuristic search
(Harvey & Ginsberg, 1995). key idea behind LDS realize classifier
prediction corrected small number critical errors, much better output
397

fiDoppa, Fern, & Tadepalli

(a)

(b)

Figure 7: Illustration Limited Discrepancy Search (LDS) handwriting recognition
problem. given discrepancy set D, generate unique output
running recurrent classifier changes D. (a) LDS one
discrepancy. introduce discrepancy first position label (shown
red) run classifier, able correct two subsequent labels. (b)
LDS two discrepancies. introduce additional discrepancy fifth
position label c (shown red) run classifier, recover target
output struct.

would produced. LDS conducts (shallow) search space possible corrections
hope finding output better original.
Given classifier h sequence length , discrepancy pair (i, l)
{1, . . . , } index sequence position l label, generally different
prediction classifier position i. set discrepancies D,
generate unique output h[D](x) running classifier changes D.
discrepancies viewed overriding prediction h particular positions,
possibly correcting errors, introducing new errors. one extreme, empty,
get original output produced greedy classifier (see Figure 6).
extreme, specifies label position, output influenced h
completely specified discrepancy set. Figure 7 illustrates LDS
handwriting example. introduce discrepancy first position label
(shown red) run classifier, able correct two subsequent labels (see
Figure 7(a)). introduce additional discrepancy fifth position label c (shown
red) run classifier, recover target output struct (see Figure 7(b)).
398

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 8: example Limited Discrepancy Search (LDS) space handwriting recognition
problem. highlighted state corresponds one true output
smallest depth.

practice, h reasonably accurate, primarily interested small
discrepancy sets relative length sequence. problem know
corrections made thus LDS conducts search discrepancy
sets, usually small large sets.

A.3 LDS Space
Given recurrent classifier h, define corresponding limited-discrepancy search space
complete outputs follows. state search space represented (x, D)
x input sequence discrepancy set. view state (x, D) equivalent
input-output state (x, h[D](x)). initial state function simply returns (x, )
corresponds original output recurrent classifier. successor function
state (x, D) returns set states form (x, D0 ), D0 D,
additional discrepancy. way, path LDS search space starts
output generated recurrent classifier traverses sequence outputs
differ original number discrepancies. Given reasonably accurate h,
expect high-quality outputs generated relatively shallow depths
search space hence generated quickly.
399

fiDoppa, Fern, & Tadepalli

Figure 8 illustrates3 limited-discrepancy search space. state consists
input x, discrepancy set output produced running classifier
specified discrepancy set, i.e., h[D](x). root node empty discrepancy set. Nodes
level one contain discrepancy sets size one. highlighted state corresponds
smallest depth state containing target output.

Appendix B. Hardness Proof HC-Search Consistency Problem
Theorem 2. HC-Search Consistency Problem greedy search linear heuristic
cost functions NP-Hard even restrict problems possible
heuristic functions uncover zero loss output.
Proof. reduce Minimum Disagreement problem linear binary classifiers,
proven NP-complete work Hoffgen, Simon, Horn (1995).
one statement problem given input set N , p-dimensional vectors
= {x1 , . . . , xN } positive integer k. problem decide whether
p-dimensional real-valued weight vector w w xi < 0 k
vectors.
first sketch high-level idea proof. Given instance Minimum Disagreement, construct HC-Search consistency problem single structured
training example. search space corresponding training example designed
single node n loss zero nodes loss
1. linear heuristic functions greedy search paths terminate n ,
generating set nodes/outputs path there. search space designed
possible path initial node n corresponds selecting k fewer
vectors , denote . traversing path, set nodes
generated (and hence must scored C), say N , includes feature vectors corresponding
along negation feature vectors . define
n assigned zero vector, cost node 0 weight vector.
order achieve zero loss given path consideration, must weight
vector wC wC x 0 x N . construction equivalent
wC x < 0 x . possible found solution Minimum
Disagreement problem since |T | k. remaining details show construct
space setting heuristic weights generate paths corresponding
possible way paths end n . completeness describe
construction below.
search node space n tuple (i, m, t) 1 N ,
0 k, one 5 node types set {d, s+ , , x+ , x }.
viewed indexing example xi effectively codes many instances
selected mistakes hence put . Finally, encodes type
search node following meanings become clear
construction: (decision), s+ (positive selection), (negative selection), x+ (positive
instance), x (negative instance). search space constructed example xi
3. may clear example, allow over-riding discrepancies provide opportunity recover search errors.

400

fiHC-Search: Learning Framework Search-based Structured Prediction

Figure 9: example search space = {x1 , x2 , x3 } k = 1. greedy paths
terminate zero loss node n path selects one instance
include mistake set .

considered order choice made whether count mistake (put
) not. choice made decision nodes, form (i, m, d),
indicating decision made example already
examples selected . decision node < k two children (i, m, )
(i, m, s+ ), respectively correspond selecting xi mistake set not.
Later show features assigned nodes allow heuristic make
selection desired.
selection node single node child. particular, positive selection node
(i, m, s+ ) positive instance node (i, m, x+ ) child, negative selection nodes
(i, m, ) negative instance node (i, m, x ) child. instance node
effectively implements process putting xi become clear
feature vectors described below. arriving either positive negative instance
node, consideration xi complete must move decision next
example xi+1 . Thus, positive instance node (i, m, x+ ) single child decision node
401

fiDoppa, Fern, & Tadepalli

(i + 1, m, d), negative instance node single child decision node (i + 1, + 1, d),
noting number mistakes incremented negative nodes.
final details search space structure ensure k mistakes
allowed force search paths terminate n . particular, decision
node (i, m, d) = k, know mistakes allowed hence
decisions allowed. Thus, node form path n
goes positive instance nodes (i, m, x+ ), . . . , (N, m, x+ ), reflects none
{xi , . . . , xN } . Figure 9 shows example search space construction.
Given search space, polynomial size (since k N ), one verify
set k fewer instances path root n goes
negative instance nodes instances positive instance nodes
instances . Further, possible path goes either positive negative
instance node instance k negative nodes. Thus direct
correspondence paths mistake sets .
describe assign features node way allows
heuristic function select path effectively construct set . node
u feature vector (u) = (x, s, b). component x p-dimensional feature vector
correspond one xi . component N -dimensional vector
si {1, 1} implement selection instances. Finally b binary value
equal 1 non-instance nodes 0 positive negative instance nodes.
mapping nodes feature vectors follows. decision node (i, m, d),
zeros, except b = 1. positive selection node (i, m, s+ ) zeros except si = 1
b = 1. Negative selection nodes similar except si = 1. positive instance
node (i, m, x+ ) feature vector (xi , 0, 0) negative instance nodes (i, m, x )
feature vector (xi , 0, 0). Finally feature vector n zeros.
key idea note heuristic function effectively select positive
negative selection node setting weight si positive negative respectively.
particular, set negative selection nodes visited (and hence negative instance nodes)
correspond first k fewer negative weight values component feature
vector. Thus, heuristic select set negative nodes wants go through,
k. path three types nodes encountered
cost function must rank. First, control nodes (decision selection nodes)
b = 1. Next positive instance nodes feature
vector (xi , 0, 0) k negative instance nodes feature vectors (xi , 0, 0).
cost function easily rank n higher control nodes setting weight
b negative. find heuristic weights x component allows n
ranked highest solution original minimum disagreement problem.
solution disagreement problem easy see
also solution HC-Search consistency problem selecting heuristic spans
proper set .

References
Agarwal, S., & Roth, D. (2005). Learnability Bipartite Ranking Functions. Proceedings
International Conference Learning Theory (COLT), pp. 1631.
402

fiHC-Search: Learning Framework Search-based Structured Prediction

Batra, D., Yadollahpour, P., Guzman-Rivera, A., & Shakhnarovich, G. (2012). Diverse MBest Solutions Markov Random Fields. Proceedings European Conference
Computer Vision (ECCV), pp. 116.
Boyan, J. A., & Moore, A. W. (2000). Learning Evaluation Functions Improve Optimization Local Search. Journal Machine Learning Research (JMLR), 1, 77112.
Brill, E. (1995). Transformation-Based Error-Driven Learning Natural Language Processing: Case Study Part-of-Speech Tagging. Computational Linguistics, 21 (4),
543565.
Chang, K.-W., Samdani, R., & Roth, D. (2013). Constrained Latent Variable Model
Coreference Resolution. Proceedings Conference Empirical Methods
Natural Language Processing (EMNLP), pp. 601612.
Chang, M.-W., Ratinov, L.-A., & Roth, D. (2012). Structured Learning Constrained
Conditional Models. Machine Learning Journal (MLJ), 88 (3), 399431.
Chen, C., Kolmogorov, V., Zhu, Y., Metaxas, D., & Lampert, C. H. (2013). Computing
Probable Modes Graphical Model. Proceedings International
Conference Artificial Intelligence Statistics (AISTATS).
Chen, S., Fern, A., & Todorovic, S. (2014). Multi-Object Tracking via Constrained Sequential Labeling. appear Proceedings IEEE Conference Computer Vision
Pattern Recognition (CVPR).
Collins, M. (2000). Discriminative Reranking Natural Language Parsing. Proceedings
International Conference Machine Learning (ICML), pp. 175182.
Collins, M. (2002). Ranking Algorithms Named Entity Extraction: Boosting
Voted Perceptron. ACL.
Crammer, K., Dekel, O., Keshet, J., Shalev-Shwartz, S., & Singer, Y. (2006). Online PassiveAggressive Algorithms. Journal Machine Learning Research (JMLR), 7, 551585.
Daume III, H. (2006). Practical Structured Learning Techniques Natural Language
Processing. Ph.D. thesis, University Southern California, Los Angeles, CA.
DaumeIII, H., & Marcu, D. (2005). Learning Search Optimization: Approximate Large
margin methods Structured Prediction. ICML.
Dietterich, T. G., Hild, H., & Bakiri, G. (1995). Comparison ID3 Backpropagation
English Text-to-Speech Mapping. Machine Learning Journal (MLJ), 18 (1), 5180.
Domke, J. (2013). Structured Learning via Logistic Regression. Proceedings Advances
Neural Information Processing Systems (NIPS), pp. 647655.
Doppa, J. R., Fern, A., & Tadepalli, P. (2012). Output Space Search Structured Prediction. Proceedings International Conference Machine Learning (ICML).
Doppa, J. R., Fern, A., & Tadepalli, P. (2013). HC-Search: Learning Heuristics Cost
Functions Structured Prediction. Proceedings AAAI Conference Artificial
Intelligence (AAAI).
Doppa, J. R., Fern, A., & Tadepalli, P. (2014a). Structured Prediction via Output Space
Search. Journal Machine Learning Research (JMLR), 15, 13171350.
403

fiDoppa, Fern, & Tadepalli

Doppa, J. R., Yu, J., Ma, C., Fern, A., & Tadepalli, P. (2014b). HC-Search Multi-Label
Prediction: Empirical Study. appear Proceedings AAAI Conference
Artificial Intelligence (AAAI).
Doppa, J. R., Yu, J., Tadepalli, P., & Getoor, L. (2009). Chance-Constrained Programs
Link Prediction. Proceedings NIPS Workshop Analyzing Networks
Learning Graphs.
Doppa, J. R., Yu, J., Tadepalli, P., & Getoor, L. (2010). Learning Algorithms Link
Prediction based Chance Constraints. Proceedings European Conference
Machine Learning (ECML), pp. 344360.
Felzenszwalb, P. F., & McAllester, D. A. (2007). Generalized A* Architecture. Journal
Artificial Intelligence Research (JAIR), 29, 153190.
Fern, A. (2010). Speedup Learning. Encyclopedia Machine Learning, pp. 907911.
Fern, A., Yoon, S. W., & Givan, R. (2006). Approximate Policy Iteration Policy
Language Bias: Solving Relational Markov Decision Processes. Journal Artificial
Intelligence Research (JAIR), 25, 75118.
Goldberg, Y., & Elhadad, M. (2010). Efficient Algorithm Easy-First Non-Directional
Dependency Parsing. Proceedings Human Language Technologies: Conference
North American Chapter Association Computational Linguistic (HLTNAACL), pp. 742750.
Grubb, A., & Bagnell, D. (2012). SpeedBoost: Anytime Prediction Uniform NearOptimality. Journal Machine Learning Research - Proceedings Track, 22, 458466.
Hal Daume III, Langford, J., & Marcu, D. (2009). Search-based Structured Prediction.
Machine Learning Journal (MLJ), 75 (3), 297325.
Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 607615.
Hazan, T., & Urtasun, R. (2012). Efficient Learning Structured Predictors General
Graphical Models. CoRR, abs/1210.2346.
Hoffgen, K.-U., Simon, H.-U., & Horn, K. S. V. (1995). Robust Trainability Single
Neurons. Journal Computer System Sciences, 50 (1), 114125.
Huang, L., Fayong, S., & Guo, Y. (2012). Structured Perceptron Inexact Search.
Proceedings Human Language Technology Conference North American
Chapter Association Computational Linguistics (HLT-NAACL), pp. 142
151.
Jiang, J., Teichert, A., Daume III, H., & Eisner, J. (2012). Learned Prioritization
Trading Accuracy Speed. Proceedings Advances Neural Information
Processing (NIPS).
Kaariainen, M. (2006). Lower Bounds Reductions. Atomic Learning Workshop.
Keshet, J., Shalev-Shwartz, S., Singer, Y., & Chazan, D. (2005). Phoneme Alignment based
Discriminative Learning. Proceedings Annual Conference International
Speech Communication Association (Interspeech), pp. 29612964.
404

fiHC-Search: Learning Framework Search-based Structured Prediction

Khardon, R. (1999). Learning Take Actions. Machine Learning Journal (MLJ), 35 (1),
5790.
Kulesza, A., & Taskar, B. (2012). Determinantal Point Processes Machine Learning.
Foundations Trends Machine Learning, 5 (2-3), 123286.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional Random Fields: Probabilistic
Models Segmenting Labeling Sequence Data. Proceedings International
Conference Machine Learning (ICML), pp. 282289.
Lam, M., Doppa, J. R., Hu, X., Todorovic, S., Dietterich, T., Reft, A., & Daly, M. (2013).
Learning Detect Basal Tubules Nematocysts SEM Images. ICCV Workshop
Computer Vision Accelerated Biosciences (CVAB). IEEE.
Li, Q., Ji, H., & Huang, L. (2013). Joint Event Extraction via Structured Prediction
Global Features. Proceedings 51st Annual Meeting Association
Computational Linguistics (ACL), pp. 7382.
McAllester, D. A., Hazan, T., & Keshet, J. (2010). Direct Loss Minimization Structured
Prediction. Proceedings Advances Neural Information Processing Systems
(NIPS), pp. 15941602.
Meshi, O., Sontag, D., Jaakkola, T., & Globerson, A. (2010). Learning Efficiently
Approximate Inference via Dual Losses. Proceedings International Conference
Machine Learning (ICML), pp. 783790.
Mohan, A., Chen, Z., & Weinberger, K. Q. (2011). Web-Search Ranking Initialized
Gradient Boosted Regression trees. Journal Machine Learning Research - Proceedings Track, 14, 7789.
Nivre, J. (2008). Algorithms Deterministic Incremental Dependency Parsing. Computational Linguistics, 34 (4), 513553.
Park, D., & Ramanan, D. (2011). N-Best Maximal Decoders Part Models. Proccedings
IEEE International Conference Computer Vision (ICCV), pp. 26272634.
Payet, N., & Todorovic, S. (2013). SLEDGE: Sequential Labeling Image Edges
Boundary Detection. International Journal Computer Vision (IJCV), 104 (1), 15
37.
Qian, X., Jiang, X., Zhang, Q., Huang, X., & Wu, L. (2009). Sparse Higher Order Conditional Random Fields Improved Sequence Labeling. Proceedings International
Conference Machine Learning (ICML).
Read, J., Pfahringer, B., Holmes, G., & Frank, E. (2011). Classifier Chains Multi-Label
Classification. Machine Learning, 85 (3), 333359.
Ross, S., & Bagnell, D. (2010). Efficient Reductions Imitation Learning. Journal
Machine Learning Research - Proceedings Track, 9, 661668.
Ross, S., Gordon, G. J., & Bagnell, D. (2011). Reduction Imitation Learning
Structured Prediction No-Regret Online Learning. Journal Machine Learning
Research - Proceedings Track, 15, 627635.
405

fiDoppa, Fern, & Tadepalli

Roth, D., & tau Yih, W. (2005). Integer Linear Programming Inference Conditional
Random Fields. Proceedings International Conference Machine Learning
(ICML), pp. 736743.
Samdani, R., & Roth, D. (2012). Efficient Decomposed Learning Structured Prediction.
Proceedings International Conference Machine Learning (ICML).
Sen, P., Namata, G., Bilgic, M., Getoor, L., Gallagher, B., & Eliassi-Rad, T. (2008). Collective Classification Network Data. AI Magazine, 29 (3), 93106.
Sontag, D., Meshi, O., Jaakkola, T., & Globerson, A. (2010). data means less inference:
pseudo-max approach structured learning. Proceedings Advances Neural
Information Processing Systems (NIPS), pp. 21812189.
Stoyanov, V., & Eisner, J. (2012). Easy-first Coreference Resolution. Proceedings
International Conference Computational Linguistics (COLING), pp. 25192534.
Stoyanov, V., Ropson, A., & Eisner, J. (2011). Empirical Risk Minimization Graphical
Model Parameters Given Approximate Inference, Decoding, Model Structure.
Proceedings International Conference Artificial Intelligence Statistics
(AISTATS), pp. 725733.
Sutton, C. A., & McCallum, A. (2009). Piecewise Training Structured Prediction.
Machine Learning Journal (MLJ), 77 (2-3), 165194.
Syed, U., & Schapire, R. (2010). Reduction Apprenticeship Learning Classification. Proceedings Advances Neural Information Processing Systems (NIPS),
pp. 22532261.
Taskar, B., Guestrin, C., & Koller, D. (2003). Max-Margin Markov Networks. Proceedings
Advances Neural Information Processing Systems (NIPS).
Tsochantaridis, I., Hofmann, T., Joachims, T., & Altun, Y. (2004). Support Vector Machine Learning Interdependent Structured Output Spaces. Proceedings
International Conference Machine Learning (ICML).
Tsochantaridis, I., Joachims, T., Hofmann, T., & Altun, Y. (2005). Large Margin Methods
Structured Interdependent Output Variables. Journal Machine Learning
Research (JMLR), 6, 14531484.
Vogel, J., & Schiele, B. (2007). Semantic Modeling Natural Scenes Content-Based
Image Retrieval. International Journal Computer Vision (IJCV), 72 (2), 133157.
Weiss, D. (2014). Structured Prediction Cascades code. http://code.google.com/p/
structured-cascades/.
Weiss, D., Sapp, B., & Taskar, B. (2010). Sidestepping Intractable Inference Structured
Ensemble Cascades. Proceedings Advances Neural Information Processing
Systems (NIPS), pp. 24152423.
Weiss, D., & Taskar, B. (2010). Structured Prediction Cascades. Journal Machine
Learning Research - Proceedings Track, 9, 916923.
Wick, M. L., Rohanimanesh, K., Bellare, K., Culotta, A., & McCallum, A. (2011). SampleRank: Training Factor Graphs Atomic Gradients. Proceedings International
Conference Machine Learning (ICML).
406

fiHC-Search: Learning Framework Search-based Structured Prediction

Wick, M. L., Rohanimanesh, K., Singh, S., & McCallum, A. (2009). Training Factor Graphs
Reinforcement Learning Efficient MAP Inference. Proceedings Advances
Neural Information Processing Systems (NIPS), pp. 20442052.
Xu, Y., Fern, A., & Yoon, S. (2009a). Learning Linear Ranking Functions Beam Search
Application planning. Journal Machine Learning Research, 10, 1571
1610.
Xu, Y., Fern, A., & Yoon, S. W. (2009b). Learning Linear Ranking Functions Beam
Search Application Planning. Journal Machine Learning Research (JMLR),
10, 15711610.
Xu, Y., Fern, A., & Yoon, S. W. (2010). Iterative Learning Weighted Rule Sets
Greedy Search. Proceedings International Conference Automated Planning
Systems (ICAPS), pp. 201208.
Xu, Z., Weinberger, K., & Chapelle, O. (2012). Greedy Miser: Learning Test-time
Budgets. Proceedings International Conference Machine Learning (ICML).
Ye, N., Lee, W. S., Chieu, H. L., & Wu, D. (2009). Conditional Random Fields
High-Order Features Sequence Labeling. Proceedings Advances Neural
Information Processing Systems (NIPS), pp. 21962204.
Yu, H., Huang, L., Mi, H., & Zhao, K. (2013). Max-Violation Perceptron Forced
Decoding Scalable MT Training. Proceedings Empirical Methods Natural
Language Processing (EMNLP), pp. 11121123.
Zhang, W., & Dietterich, T. G. (1995). Reinforcement Learning Approach job-shop
Scheduling. Proceedings International Joint Conference Artificial Intelligence
(IJCAI), pp. 11141120.

407

fiJournal Artificial Intelligence Research 50 (2014) 235-264

Submitted 12/13; published 06/14

Reconnection Ideal Tree: New Approach
Real-Time Search
Nicolas Rivera

nicolas.rivera@kcl.ac.uk

Kings College London
London, WC2R 2LS, UK

Leon Illanes
Jorge A. Baier

lillanes@uc.cl
jabaier@ing.puc.cl

Departamento de Ciencia de la Computacion
Pontificia Universidad Catolica de Chile
Vicuna Mackenna 4860, Santiago, Chile

Carlos Hernandez

chernan@ucsc.cl

Departamento de Ingeniera Informatica
Universidad Catolica de la Santsima Concepcion
Caupolican 491, Concepcion, Chile

Abstract
Many applications, ranging video games dynamic robotics, require solving
single-agent, deterministic search problems partially known environments
tight time constraints. Real-Time Heuristic Search (RTHS) algorithms specifically
designed applications. subroutine, invoke standard,
bounded, search algorithm searches goal. paper present FRIT,
simple approach single-agent deterministic search problems tight constraints
partially known environments unlike traditional RTHS search goal
rather searches path connects current state so-called ideal tree .
agent observes arc tree cannot traversed actual environment, removes arc carries reconnection search whose
objective find path current state node . reconnection
search done using algorithm passed parameter FRIT. parameter
RTHS algorithm, resulting algorithm RTHS algorithm. show,
addition, FRIT may fed (bounded) complete blind-search algorithm.
evaluate approach grid pathfinding benchmarks including game maps mazes.
results show FRIT, used RTAA*, standard RTHS algorithm, outperforms
RTAA* significantly; one order magnitude tight time constraints. addition,
FRIT(daRTAA*) substantially outperforms daRTAA*, state-of-the-art RTHS algorithm,
usually obtaining solutions 50% cheaper average performing search effort.
Finally, FRIT(BFS), i.e., FRIT using breadth-first-search, obtains best-quality solutions
time limited compared Adaptive A* Repeated A*. Finally show
Bug2, pathfinding-specific navigation algorithm, outperforms FRIT(BFS) planning
time extremely limited, given time, situation reverses.

1. Introduction
Real-Time Heuristic Search (Korf, 1990) approach solving single-agent search problems limit imposed amount computation used deliberac
2014
AI Access Foundation. rights reserved.

fiRivera, Illanes, Baier, & Hernandez

tion. used solving problems agents start moving complete
search algorithm solve problem especially suitable problems
environment partially known advance.
application real-time heuristic search algorithms goal-directed navigation
video games (Bulitko, Bjornsson, Sturtevant, & Lawrence, 2011) computer characters expected find way partially known terrain. Game-developing companies
impose constant time limit amount computation per move close one millisecond simultaneously moving characters (Bulitko et al., 2011). such, real-time
search algorithms applicable since provide main loop quick moves
allow implementing continuous character moves.
standard real-time heuristic search algorithmse.g., LRTA* (Korf, 1990) LSSLRTA* (Koenig & Sun, 2009)are algorithms choice videogame developers, since
require characters re-visit many states order escape so-called heuristic
depressions, producing back-and-forth movements, also referred scrubbing (Bulitko
et al., 2011). underlying reason behavior heuristic used guide
search must updatedin process usually referred heuristic learningwhenever
new obstacles found. exit so-called heuristic depressions, agent may need
revisit group states many times (Ishida, 1992).
exploiting preprocessing (e.g., Bulitko, Bjornsson, Lustrek, Schaeffer, & Sigmundarson, 2007; Bulitko, Bjornsson, & Lawrence, 2010; Hernandez & Baier, 2011), one produce Real-Time Heuristic Search algorithms control agent way
sensible human observer. Give map terrain, algorithms compute information offline later utilized online Real-Time Search algorithm find
paths quickly.
Unfortunately, preprocessing applicable settings. example one wants
implement agent knowledge terrain, map
available prior search hence preprocessing carried out. hand,
knowledge terrain partial (i.e., agent may know location
obstacles them), using plain Real-Time Heuristic Search
along partial information map obtained preprocessing (i.e., perfect
heuristic computed partially known map) may still result performance
issues described above.
paper present FRIT, real-time search algorithm necessarily
rely heuristic learning control agent, produces high-quality solutions
partially known environments. easily motivated game applications, algorithm
designed general search problems. agent controlled algorithm always
follows branch tree containing family solutions. call tree ideal
tree paths contains solutions world currently known
agent, solutions may legal actual world. agent moves
states ideal tree usually encounter states accessible
block solution ideal tree. happens, secondary algorithmwhich
given parameteris used perform search reconnect current state
another state known ideal tree. reconnection succeeds agent
state updated ideal tree, continue following branch tree.
236

fiReconnection Ideal Tree: New Approach Real-Time Search

discuss two different ways algorithm given parameter FRIT
useful real-time scenarios. first alternative feed FRIT real-time
search algorithm. produces standard real-time search algorithm, so-called
agent-centered search algorithm (Koenig, 2001) since verify node connected
ideal tree may need consider states far away current position.
second option make FRIT amenable real-time scenarios consists feeding
FRIT bounded complete search algorithm; i.e., complete search algorithm
iteration expands bounded number states. performing limited number
expansions, search algorithm may found reconnecting path. case
agent may may perform action depending domain-specific considerations.
implementation chose perform move all.
evaluated algorithm standard game maze pathfinding benchmarks using
blind, breadth-first search algorithm two different real-time search algorithms
reconnection. Even though algorithm guarantee optimality, solutions returned, terms quality total time, significantly better returned
state-of-the-art real-time heuristic search algorithms compared to, search effort
comparable. Upon inspection route followed agent, observe
using blind-search algorithms reconnection contain back-and-forth, irrational movements, indeed look similar solutions returned so-called bug
algorithms (LaValle, 2006; Taylor & LaValle, 2009) developed robotics community.
such, usually detects states need visited againsometimes referred
dead-ends redundant states (Sturtevant & Bulitko, 2011; Sharon, Sturtevant, &
Felner, 2013)without implementing specific mechanism detect them.
also compared algorithm incremental heuristic search algorithms
modified behave like real-time search algorithm. find that, although FRIT
reach solution quality, obtain solutions significantly better
time deadline tight (under 40 sec).
algorithm extremely easy implement and, case sufficient time
pre-processing, utilize techniques already described literature, like so-called compressed path databases (Botea, 2011), compute initial ideal tree. Furthermore,
provide proofs termination algorithm using real-time search blind-search
reconnection, provide bound number moves required find solution
arbitrary graphs.
contributions presented article published conference
paper (Rivera, Illanes, Baier, & Hernandez, 2013b). articles extends work
includes new material. particular:
describe method use algorithm real-time search algorithm passed
parameter, evaluate results obtained using two different real-time
algorithms.
provide proofs termination algorithms obtained using aforementioned method, general proof convergence applicable algorithms
propose.
incorporate small optimization affects InTree[c] function described
Section 3.
237

fiRivera, Illanes, Baier, & Hernandez

extend previous empirical results including maze benchmarks,
previously considered, evaluating problem instances.
addition, compare algorithm Bug2 (Lumelsky & Stepanov, 1987)
pathfinding algorithm.
rest paper organized follows. Section 2 describe background
necessary rest paper. Section 3 describe simple version algorithm
real-time. Section 4 describe two alternative ways make algorithm
satisfy real-time property. Section 5 present theoretical analysis, followed
description experimental evaluation Section 6. describe related
work, finish summary.

2. Background
search problems deal paper described tuple P = (G, c, sstart , g),
G = (S, A) directed graph represents search space. set represents
states arcs represent available actions. State sstart initial
state state g goal state. assume finite, contain
elements form (s, s), G g reachable states reachable
sstart . addition, non-negative cost function c : R associates cost
available actions. Naturally, cost path graph sum
costs arcs path. Finally g goal state. Note even though
definition considers single goal state still model problems multiple goal
states since always transform multiple-goal problem single-goal problem
adding new state g graph connecting goals original problem g
zero-cost action.
define distance function dG : R dG (s, t) denotes cost
shortest path graph G. heuristic search graph G nonnegative function h : R h(s) estimates dG (s, g). say h admissible
h(s) dG (s, g), S. addition, say heuristic h consistent every
pair (s, t) holds h(s) c(s, t) + h(t), furthermore h(g) = 0. simple
prove consistency implies admissibility.
2.1 Real-Time Search
Given search problem P = (G, c, sstart , g), objective real-time search algorithm
move agent sstart g, low-cost path. algorithm satisfy
real-time property, means agent given bounded amount time
deliberating, independent size problem. deliberation, agent
expected move. move, time given deliberation loop
repeats.
Real-Time Heuristic Search algorithms rely execution bounded
standard state-space search algorithm (e.g., A*, Hart, Nilsson, & Raphael, 1968). order
apply algorithm partially known environments, carry search
graph may correspond graph describing actual environment.
particular, pathfinding grid worlds, assumed dimensions grid
238

fiReconnection Ideal Tree: New Approach Real-Time Search

known, enable search free-space assumption (Zelinsky, 1992) made, whereby grid
cells regarded obstacle-free unless known blocked.
define version free-space assumption use general search
problems. assume certain search graph GM given input agent.
graph reflects agent knows environment, kept memory
throughout execution. assume graph satisfies following generalized version
free-space assumption: actual search graph G = (S, A), GM spanning
supergraph G, i.e. GM = (S, A0 ), A0 . Note GM supergraph
G dGM (s, t) dG (s, t) s, S, h admissible GM
G.
moving environment, assume agent capable observing
whether arcs search graph GM = (S, A0 ) present actual
graph. Specifically, assume agent state s, able sense whether
(s, t) A0 traversable actual graph. arc (s, t) traversable,
inaccessible hence agent removes GM arcs lead t. Note
means GM satisfies free-space assumption initially, always satisfy
execution.
Note following fact implicit definitions: environment static.
G, unlike GM , never changes. free-space assumption also implies
agent cannot discover arcs environment present search graph GM .
Many standard real-time search algorithms structure Algorithm 1,
solves search problem iterating loop runs four procedures: lookahead,
heuristic learning, movement, observation. lookahead phase (Line 3) runs timebounded search algorithm returns path later determines agent moves.
heuristic learning procedure (Line 4) changes h-value states
search space make informed. Finally, movement observation phase
(Line 5), agent moves along path graph previously computed lookahead
search procedure. moving, agent observes environment, prunes away
GM arc perceived absent actual environment.
Algorithm 1: Generic Real-Time Search Algorithm
Input: search graph GM , heuristic function h, goal state g
Effect: agent moved initial state goal state trajectory exists
1 agent reached goal state
2
scurr current state.
3
path LookAhead(scurr , g).
4
Update heuristic function h.
5
Move agent path. moving, observe environment
update GM , removing non traversable arcs. Stop arc path removed
path traversed completely

RTAA* (Koenig & Likhachev, 2006) instance Algorithm 1. lookahead
phase, runs bounded A* scurr towards goal state, executes regular
A* execution stopped soon node lowest f -value Open goal
239

fiRivera, Illanes, Baier, & Hernandez

state soon k nodes expanded. path returned one connects
scurr best state Open (i.e., state lowest f-value Open).
hand, heuristic learning carried using Algorithm 2, resets heuristic
states expanded lookahead according f -value best state Open. Koenig
Likhachev (2006) prove Algorithm 2 maintains consistency h h initially
consistent.
Algorithm 2: RTAA*s heuristic learning.
1
2
3
4

procedure Update ()
f minsOpen g(s) + h(s)
Closed
h(s) f g(s)

LRTA* (Korf, 1990) also instance Algorithm 1; indeed, LRTA* instance
RTAA* k parameter set 1. nutshell, simple version LRTA*
decides move looking best scurr neighbors, updates
heuristic scurr also based heuristic neighbors.
easy see RTAA* LRTA* satisfy real-time property since
operations carried prior movement take constant time. algorithms
also completein sense always find solution one existswhen input
heuristic consistent. prove completeness, heuristic learning key. First,
learning guarantees state agent moves lower heuristic value compared
h(scurr ). Second, learning procedure guarantees heuristic always bounded (in case RTAA*, many algorithms, consistency, hence
admissibility preserved execution).
Finally, bounds number execution steps known algorithms.
LRTA*, example, solve search problem (|S|2 |S|)/2 iterations, |S|
number nodes search graph (Edelkamp & Schrodl, 2011, Ch. 11).

3. Searching via Tree Reconnection
algorithm propose moves agent towards goal state partially known
environment following arcs so-called ideal tree . Whenever arc
tree cannot traversed actual environment, carries search reconnect
current state node . section describe simple version algorithm
still satisfy real-time property. Prior that, describe built
initially.
3.1 Ideal Tree
ideal tree intuitively corresponds family paths connect states
search space goal state. tree ideal arcs tree may
exist actual search graph. Formally,

240

fiReconnection Ideal Tree: New Approach Real-Time Search

Definition 1 (Ideal Tree) Given search problem P = (G, c, sstart , g), graph GM
satisfies generalized free-space assumption respect G, ideal tree
P GM directed acyclic subgraph GM that:
1. goal state g parent (i.e., root),
2. child , (t, s) arc GM .
Note arcs ideal tree directed point children parent
(Figure 1 depicts ideal tree grid world). Properties 1 2 Definition 1 imply
given ideal tree node GM suffices follow arcs (which
also GM ) reach goal state g. Property 2 corresponds intuition
ideal : arcs may exist actual search graph correspond
arcs GM necessarily G.
note search problems search graph defined using successor
generator (as case standard planning problems) possible build ideal tree
first setting states represent leaves tree, computing path
goal states. way achieving relax successor generator
(perhaps removing preconditions), allows including arcs
original problem. such, Property 2 require user provide inverse
successor generator planning problems.
internal representation ideal tree straightforward. node
store pointer parent s, denote p(s). Formally p : {null}
{null}, p(null) = null p(g) = null. Notice representation actually
used describe forest. Below, sometimes refer forest F use concept
paths F, correspond paths connected component F might
.
outset search, algorithm present starts ideal tree
also spanning, i.e., contains states S. general case,
spanning ideal tree computed running Dijkstras algorithm goal node
graph like GM arcs inverted. Indeed, h(s) defined distance
g graph, ideal tree constructed using following rules:
every \ {g} define p(s) = arg minu:(s,u)A[GM ] c(s, u) + h(u), A[GM ]
arcs GM .
applications like real-time pathfinding video games, environment
partially known priori reasonable assume sufficient time preprocessing (Bulitko et al., 2010). preprocessing time, one could run Dijkstras algorithm
every possible goal state. memory problem, one could use so-called compressed path
databases (Botea, 2011), actually define spanning ideal trees every possible goal
state given grid.
Moreover, gridworld pathfinding unknown terrain, ideal tree obstaclefree GM quickly constructed using information given standard heuristic.
Manhattan distance octile distance correspond
value returned Dijkstra call goal state 4-connected 8-connected grids,
respectively. cases grid completely partially known initially
time preprocessing, one still feed algorithm obstacle-free initial
241

fiRivera, Illanes, Baier, & Hernandez

graph obstacles regarded accessible neighbor states. Thus, call
algorithm like Dijkstra need made insufficient time.
implementation algorithm gridworlds exploit fact
tree built fly. Indeed, need set p(s) every starting
search; instead, set p(s) needed first time. such, time
spent initializing ideal tree search. generally, depending problem
structure, specific implementations exploit fact need explicit tree.
3.2 Following Reconnecting
search algorithm, Follow Reconnect Ideal Tree (FRIT, Algorithm 3)
receives input search graph GM , initial state sstart , goal state g, graph
search algorithm A. GM search graph known agent initially, assume
satisfies generalized free-space assumption respect actual search graph.
algorithm used reconnecting ideal tree. require receive following
parameters: initial state, search graph, goal-checking boolean function,
receives state parameter.
Algorithm 3: FRIT: Follow Reconnect Ideal Tree
Input: search graph GM , initial state sstart , goal state g, search
algorithm
1 Initialization: Let ideal tree GM .
2 Set sstart .
3 Set c 0 color state GM 0.
4 Set hobstacle .
5 6= g
6
Observe environment around s.
7
newly discovered inaccesible state
8
h(o) < hobstacle
9
hobstacle h(o).
10
11
12
13
14

Prune GM arcs lead o.
p(s) = null
cc+1
Reconnect (A, s, GM , InTree[c]()).
Movement: Move agent p(s) set new position
agent.

Algorithm 4: Reconnect component FRIT
Input: search algorithm A, initial state s, search graph GM goal
function fGOAL ()
1 Let path returned call A(s, GM , fGOAL ()).
2 Assuming = s0 s1 , . . . sn make p(si ) = si+1 every {0, . . . , n 1}.

242

fiReconnection Ideal Tree: New Approach Real-Time Search

initialization (Lines 14), sets ideal tree graph GM . discussed
above, tree retrieved database, pre-processing carried out.
time pre-processing suitable heuristic available GM , computes
fly. addition sets value variable c color every state 0,
sets variable hobstacle . Note computed fly, state colors
also initialized fly. hobstacle used maintain record smallest heuristic
value observed inaccessible state. role state colors hobstacle become
clear below, describe reconnection InTree[c] function. initialization,
main loop (Lines 614), agent observes environment prunes GM
arcs exist actual graph. Additionally, updates hobstacle
needed. current state agent observes parent reachable
actual search graph, sets parent pointer s, p(s), null. agent
move immediately state p(s) unless p(s) = null. latter case, disconnected
ideal tree , reconnection search carried shown Algorithm 4.
procedure calls algorithm A. objective search reconnect state
: goal function InTree[c]() returns true invoked state false
otherwise. path returned, reconnect current state path
found move parent s. main loop Algorithm 3 finishes
agent reaches goal.
3.2.1 InTree[c] Function
key component reconnection search InTree[c] function determines whether
state . implementationshown Algorithm 5follows parent
pointers state queried returns true reaches goal state state
whose h-value smaller hobstacle . last condition exploits fact way
built (i.e.: free-space assumption) ensures states closer goal
observed obstacle must still . merely optimization technique,
removing incur small performance reduction, change actions
agent. addition, paints visited state color c, given parameter.
algorithm returns false state visited parent painted
c (i.e., visited previous call InTree[c]
reconnection search).
Algorithm 5: InTree[c] function
Input: vertex
1 6= g
2
h(s) < hobstacle
3
return true

6

Paint color c.
p(s) = null p(s) color c
return false

7

p(s)

4
5

8

return true

243

fiRivera, Illanes, Baier, & Hernandez

Figure 1 shows example execution algorithm priori unknown grid
pathfinding task. observed, agent moves wall encountered,
continues bordering wall solves problem. simple see that,
vertical longer, agent would traveled beside wall following similar
down-up pattern.
example reflects general behavior algorithm grid worlds: agent
usually moves around obstacles, way resembles bug algorithms (LaValle, 2006;
Taylor & LaValle, 2009). occurs agent believes path behind
wall currently known always tries move state unless another
state allows reconnection found first. closer look shows times
agent walk exactly besides wall moves close it, performing
sort zig-zag movement. occur search used consider cost
diagonals. Breadth-First Search (BFS) Depth-First Search (DFS) may sometimes prefer
using two diagonals instead two edges cost 1.
avoid problem use variant BFS, that, iterations, generates
first non-diagonal successors later diagonal ones. nodes deeper search
uses standard ordering (e.g., clockwise). version BFS achieves practice
behavior similar bug algorithm.1 approach explored previous
work (Rivera et al., 2013b), overall improvements shown small.
paper, use standard BFS. See Section 6.4 detailed comparison bug
algorithms.
Note algorithm perform kind update heuristic h.
contrasts traditional real-time heuristic search algorithms, rely increasing
heuristic value h exit heuristic depressions generated obstacles.
process may need revisit cell several times.

4. Satisfying Real-Time Property
FRIT, presented, satisfy real-time property. two reasons this:
R1. number states expanded call algorithm passed parameter, A,
depends search graph GM rather constant; and,
R2. execution A, time checks whether state connected
ideal tree , function InTree[c] may visit number states dependent
size search graph GM .
present two natural approaches making FRIT satisfy real-time property.
first approach use slightly modified, generic real-time heuristic search algorithm
parameter algorithm. resulting algorithm real-time search algorithm
satisfies real-time property time movements
bounded constant. second approach limits amount reconnection search
guarantee time movements limited constant.
1. Videos viewed http://web.ing.puc.cl/~jabaier/index.php?page=research.

244

fiReconnection Ideal Tree: New Approach Real-Time Search

1

2

3

4

5



6

7

8

1

2

3

4

5

6

7



8

1

2

3

4

5

6

7



8

1

B

B

B

B

C

C

C

C









E

E

E

F

F

(a)

g

g

F

(b)

2

3

4

5

6

7

8



E

g

F

(c)

(d)

Figure 1: illustration steps execution 4-connected grid
pathfinding task, initial state cell D3, goal E6. search algorithm
breadth-first search, which, expanding cell, generates successors clockwise
order starting node right. position agent shown black
dot. (a) shows true environment, known priori agent. (b) shows
p pointers define ideal tree built initially Manhattan heuristic. Following
p pointers, algorithm leads agent D4, new obstacle observed. D5
disconnected GM , reconnection search initiated. (c) shows status
reconnection search expands state D4, finding E4 . agent
moved E4, new reconnection search expands gray cells shown (d).
problem solved simply following p pointers.
4.1 FRIT Real-Time Heuristic Search Algorithms
natural way addressing R1 using real-time search algorithm parameter
FRIT. turns possible plug FRIT real-time search algorithm
directly without modifications. However, modifications need make Algorithm 1
simple. describe below.
following two observations justify changes need made pseudocode generic real-time search algorithm. First observe objective
lookahead search procedure real-time heuristic algorithms like Algorithm 1 search
towards goal thus heuristic h estimates distance goal. However,
FRIT carries search sole objective reconnecting ideal tree,
means goal condition heuristic changed. Second, one
main ideas underlying FRIT use maintain ideal tree ; is,
agent found reconnecting path, p function needs updated accordingly.
Algorithm 6 shows pseudocode modified generic real-time heuristic search
algorithm, two main differences respect Algorithm 1. First, goal
condition given function gT , returns true evaluated state
. Second, Line 5 Algorithm 6 connects states path found lookahead
search . implies also Reconnect procedure described Algorithm 4
needs changed described Algorithm 7.
turn attention guide search towards reconnection using
reconnecting heuristics. giving formal definition heuristics, introduce
little notation. Given graph GM = (S, A) ideal tree GM problem
P goal state g, denote ST set states . ready define
reconnecting heuristics formally.

245

fiRivera, Illanes, Baier, & Hernandez

Algorithm 6: Generic Real-Time Search Algorithm FRIT
Input: search graph GM , heuristic function h, goal function gT ()
receives state parameter.
Effect: agent moved initial state goal state trajectory
exists. ideal tree updated.
1 agent reached goal state
2
scurr current state
3
path LookAhead(scurr , gT ())
4
Update heuristic function h.
5
Given path = s0 s1 . . . sn , update p(si ) = si+1 every
{0, . . . , n 1}.
6
Move agent path. moving, observe environment
update GM , removing non traversable arcs updating hobstacle
needed. Stop current state parent .

Algorithm 7: Reconnect component FRIT real-time algorithm
Input: real-time search algorithm A, initial state s, search graph GM
goal function fGOAL ()
1 Call A(s, GM , fGOAL ).

Definition 2 (Admissible Reconnecting Heuristic) Given ideal tree graph
GM subset B ST , say function h : R+
0 admissible reconnecting
heuristic respect B iff every holds h(s) dGM (s, s0 ),
s0 B.
Intuitively, reconnecting heuristic respect B admissible heuristic
graph GM set goal states defined B. such, Algorithm 6
initialized reconnecting heuristic, search guided towards connected
states.
Depending choose B, may obtain different heuristic. first glance,
may seem sensible choose B ST . However, immediately obvious one would
maintain (i.e., learn) heuristic efficiently. ST change
new obstacles discovered. Initially ST contains states execution,
states cease belong ST arc removed become members
reconnection completed.
paper propose use easy-to-maintain reconnecting heuristic, which,
initialized zero updated standard way. Below, prove
update procedure standard properties, h corresponds reconnecting
heuristic subset B = V (E) ST , V (E) defined follows:
B = V (E) = {s ST : visited agent 6 E}.
addition, E must set set states whose heuristic value potentially
updated real-time search algorithm. reason that, definition,
246

fiReconnection Ideal Tree: New Approach Real-Time Search

states B h-value set zero thus want include B
states potentially modified.
prove simple heuristic initialized 0 states updated
standard way indeed reconnecting heuristic.
Proposition 1 Let FRIT modified initialize h null heuristic. Let E defined
set states update procedure potentially updated.2 Furthermore, assume
instance Algorithm 6 satisfying:
P1. gT (s) returns true iff ST .
P2. Heuristic learning maintains consistency; i.e., h consistent prior learning,
remains learning.
Then, along execution FRIT(A), h reconnecting heuristic respect
B = V (E).
Proof: First observe initially h reconnecting heuristic set
zero every state. Let state s0 state B. prove
h(s) d(s, s0 ). Indeed, let = s0 s1 . . . sn , s0 = sn = s, shortest path
s0 . Since h consistent, holds
h(si ) c(si , si+1 ) + h(si+1 ),

(1)

{0, . . . , n 1}. write
h(s) h(s0 ) =

n1
X

h(si ) h(si+1 )

i=0

n1
X

c(si , si+1 ) = d(s, s0 )

(2)

i=0

observe s0 B, h-value s0 could updated
algorithm therefore h(s0 ) = 0, substituted Inequality 2, proves desired
result.

4.1.1 Tie-Breaking
pathfinding, standard approach tie-breaking among states equal f-values
select state highest g-value. reconnection search, propose different
strategy based selecting state based user-given heuristic guide search
towards final goal state. example, experiments grids break ties
selecting state smallest octile distance goal. Intuitively, among two otherwise
equal states, prefer one seems closer final goal. seems like
reasonable way use information commonly used search algorithms,
unavailable reconnection search due initial use null heuristic.
2. Note practice, E natural set states. example RTAA* used, set states
potentially updated expanded A* lookahead search.

247

fiRivera, Illanes, Baier, & Hernandez

4.1.2 Making InTree[c] Real-Time
beginning Section 4 identified R1 R2 two reasons FRIT
satisfy real-time property, discussed address R1 using real-time
search algorithm. discuss address R2.
address R2, simply make InTree[c] bounded algorithm. real-time search
algorithms receive parameter allows bound computation carried per
search. Assume Algorithm 6 receives k parameter. Furthermore, assume without
loss generality lookahead search implemented algorithm constantly
expands states (such bounded A*). always choose implementation-specific
constants NE NT , associated respectively expansions performed lookahead
operation follows p pointer InTree[c] function. Given e
number expansions performed lookahead search f number times p
pointer followed run real-time search algorithm, modify stop
condition InTree[c] return false NE e + NT f > k. Also, modify lookahead
search stop condition holds true.
Henceforth call FRITRT algorithm addresses R1 R2 using real-time
search algorithm bounded version InTree[c]. Note computation per iteration FRITRT bounded, time agent moves bounded,
thus FRITRT considered standard real-time algorithm, originally defined
Korf (1990). Note however time reach state connected ideal tree
bounded, several calls real-time algorithm may required reaching
state.
4.2 FRIT Bounded Complete Search Algorithms
previous section proposed use standard real-time heuristic search algorithm
reconnect ideal tree. potential downside approach
algorithms usually find suboptimal solutions sometimes require re-visiting
state many timesa behavior usually referred scrubbing (Bulitko et al., 2011).
applications quality solution important, still
real-time constraints possible make FRIT satisfy real-time property different
way.
Imagine example, situation FRIT given sequence
time frames, short. time frame FRIT allowed return
movement performed agent. model real-time behavior
termed game time model (Hernandez, Baier, Uras, & Koenig, 2012b) since
clear application video games games main cycle reserve fixed
usually short amount time plan next move automated characters.
accommodate behavior FRIT apply simple idea already described Section 4.1.2, using complete search algorithm reconnection rather
real-time search algorithm. described simply involves choosing implementationspecific constants NE NT , associated respectively expansions performed
(now complete) search algorithm reconnection operation follows p
pointer InTree[c] function. before, given e number expansions
performed reconnection search f number times p pointer modify
248

fiReconnection Ideal Tree: New Approach Real-Time Search

Reconnect algorithm return empty path soon NE e + NT f > k save
local variables used InTree[c]. Reconnect called again, search
resumed point previous iteration e f set 0.
Note instead returning empty path implementations may choose
move agent fashion meaningful specific application. leave
thorough discussion implement movement strategy scope
paper since believe strategy usually application-specific. movement
ought carried time frame, agent could choose move back-andforth, choose moving strategy allows follow reconnection path
found. Later, experimental evaluation, choose move agent
computation exceeds parameter discuss seems good strategy
application chose.
Note non-empty path returned given time frame, FRIT,
modified way described above, also real-time search algorithm, originally
defined Korf (1990). Finally, note implementing stop-and-resume mechanism
described easy search algorithms.

5. Theoretical Analysis
results described section prove termination algorithms present
explicit bounds number agent moves performed FRIT FRITRT
reaching goal. Additionally, show algorithms converge second run
subsequent executions algorithm result identical paths. first theorem
correctness InTree[c] function.
5.1 Proofs InTree[c]
determine whether state belongs ideal tree, InTree[c] function
(Algorithm 5) follows p pointers goal reached state whose
h-value smaller hobstacle reached. prove InTree[c] correct
sense returns true iff state belongs ideal tree. start proving
following intermediate result.
Lemma 1 Let H = {s : h(s) < hobstacle }. Reconnection search never modifies parent
pointer state H.
Proof: Take state H. clear call InTree[c](s) immediately
return true (Algorithm 5, Lines 2 3). effectively ends search, path
ends selected. path change parent s.

Note property described Lemma holds FRIT FRITRT .
bounded version InTree[c] used FRITRT always answer true called
state H. Indeed, states H part reconnection target set B,
correctly identified execution.
Theorem 1 initialized described Section 3 color c set increment reconnection search, InTree[c], described Algorithm 5, returns true
state iff .
249

fiRivera, Illanes, Baier, & Hernandez

Proof: Note besides exit condition established Lines 2 3, algorithm
trivially correct. follows parent pointers, returns true reaches goal,
returns false reaches dead end state already checked.
Let H defined Lemma 1. need prove states H .
know states original parent pointers set construction
described Section 3. Note paths initial Ideal Tree monotonic;
every state different goal holds h(s) h(p(s)). this, know
state H, p(s) H true. proves ancestors H,
therefore represent path existed initial modified.
5.2 Termination Bound FRITRT
first result proves termination algorithm uses real-time search algorithm
parameter. provide explicit bound number agent moves reaching
goal.
Theorem 2 Consider conditions Proposition 1 let modified real-time
search algorithm described Algorithm 6, requires fA (x) agent moves
solve problem x states, never updates h-value goal state.
agent controlled FRITRT (A) reaches goal state performing O(|S|fA (|S|))
moves.
Proof: Let denote elements state space inaccessible
state connected component contains sstart . Furthermore, let ideal tree
computed initialization. Note that, Proposition 1, know use reconnecting
heuristic. definition, means heuristic always admissible subset
states always contain least g. Therefore, know reconnections
eventually successful reconnection takes fA (|S|) steps. Notice
agent moves |S| steps Ideal Tree reaches inaccessible state.
reconnection search invoked new inaccessible state detected,
invoked |M| times. definition , know |M| reconnections,
agent must able reach goal following . Therefore, total number
steps |S| + |M|(fA (|S|) + |S|) O(|S|fA (|S|)).

average length paths found FRITRT expected much lower. Indeed, number reconnections bounded number obstacles reachable
state GM , many cases much lower total number inaccessible
states.
5.3 Termination Bound FRIT
following result provides bound length solutions found FRIT.
Theorem 3 Given initial tree GM satisfies generalized free-space assumption,
2
FRIT solves P (|S|+1)
agent moves.
4
250

fiReconnection Ideal Tree: New Approach Real-Time Search

Proof: Let described proof Theorem 2. Note goal
state g always part , thus never become empty reconnection always
succeed. FRITRT , reconnection search invoked |M| times.
two consecutive calls reconnection search, agent moves tree thus cannot visit
state twice. Hence, number states visited two consecutive reconnection
searches |S| |M|. conclude number moves algorithm
terminates
(|M| + 1)(|S| |M|),
(3)
largest |M| =


|S|1
2 .

Substituting value (3) gives desired result.

Again, average complexity expected much lower bound.
5.4 Convergence
following results prove termination either FRIT FRITRT , agent
knows solution problem possibly shorter one found.
Lemma 2 Let F forest defined p pointers. Throughout execution either
FRIT FRITRT , path F goes sstart current position
agent.
Proof: proof done induction number steps taken agent. Let
represent current position agent. Initially, proposition trivial, sstart = s.
Let s0 position agent moving. induction hypothesis, know
path sstart s. s0 , know parent pointers
states different modified, therefore path extends
appending s0 valid satisfies property. s0 , know parent
pointers states appear s0 modified, therefore
valid subpath goes sstart s0 satisfies property.

Theorem 4 Running algorithm second time problem, without reinitializing ideal tree, results execution never runs reconnection search finds
potentially better solution one found first run.
Proof: proof straightforward Lemma 2. end execution,
path F, specifically , sstart g. Note states path
necessarily visited first execution, ensures new path
long one resulting first execution.

Note Theorem 4 implies algorithm return different path second
trial, viewed optimized solution contain loops
first solution had. second execution algorithm naturally fast,
reconnection search required.
interesting note approach could used real-time search
algorithm. storing visited state direction agent moved away
it, path loops goes sstart g immediately extracted
soon execution finishes.
251

fiRivera, Illanes, Baier, & Hernandez

6. Empirical Evaluation
objective experimental evaluation compare performance algorithm various state-of-the-art algorithms task pathfinding real-time
constraints. chose application since seems straightforward application real-time search algorithms.
compared three classes search algorithms. first class, considered stateof-the-art real-time heuristic search algorithms corresponding versions FRITRT
result fed these. Specifically, compare RTAA* (Koenig &
Likhachev, 2006) daRTAA* (Hernandez & Baier, 2012), variant RTAA*
may outperform significantly. versions algorithm, tree ideal tree
built outset search rather built on-the-fly, using heuristic function.
second class, compared FRIT fed breadth-first-search algorithm
incremental heuristic search algorithms Repeated A* (RA*) Adaptive A* (AA*).
chose one hand fairly obvious modify satisfy
real-time property following approach follow FRIT, hand
reasonable performance. Indeed, include D* Lite (Koenig &
Likhachev, 2002) since shown Repeated A* faster D* Lite
instances problems evaluate (Hernandez, Baier, Uras, & Koenig, 2012a).
incremental search algorithms included since focus paper
propose strategies make various algorithms satisfy real-time property.
Finally compare algorithm Bug2 (Lumelsky & Stepanov, 1987) so-called bug
algorithm, algorithm specifically designed path-planning. Bug algorithm
need limited computational requirements make decisions.
Repeated A* Adaptive A* run complete A* search currently known
search graph goal reached. path found followed. following
path, search graph updated newly found obstacles. agent stops
reaches goal reached path blocked obstacle.
happens, iterate running another A* goal. make algorithms satisfy
real-time property, follow approach similar employed design
algorithm Time-Bounded A* (Bjornsson, Bulitko, & Sturtevant, 2009). iteration,
allow algorithm expand k states. path goal found
agent move. Otherwise (the agent found path goal), agent makes
single move path.
case FRIT(BFS), satisfy real-time property discussed
setting constants, NE NT , 1. means iteration, current
state parent k states expanded/visited reconnection
search reconnection path found agent moved. Otherwise,
current state non-null parent pointer, agent follows pointer.
Therefore iteration FRIT(BFS), Repeated A* Adaptive A* two things
happen: either agent moved agent moved one step. moving strategy
sensible applications like video games where, although characters expected move
fluently, want force algorithm return arbitrary move path
found, since would introduce moves may perceived pointless
users. contrast, real-time search algorithms return move iteration.
252

fiReconnection Ideal Tree: New Approach Real-Time Search

4 mazes - 500 runs

4 mazes - 500 runs
10000000

FRIT_rt(RTAA)
FRIT_rt(daRTAA)
RTAA
daRTAA

1000000

Average Solution Cost (log-scale)

Average Solution Cost (log-scale)

10000000

100000

10000

1000

0

20

40

60

80

100

120

FRIT_rt(RTAA)
FRIT_rt(daRTAA)
RTAA
daRTAA
1000000

100000

10000

140

Average time per planning episode (us)

0

20

40

60

80

100

120

Average time per planning episode (us)

(a) Real-time algorithms games.

(b) Real-time algorithms mazes.

Figure 2: Real-time algorithms: Total Iterations versus Time per Episode
use eight-neighbor grids experiments since often preferred practice,
example video games (Bulitko et al., 2011). algorithms evaluated
context goal-directed navigation priori unknown grids. agent capable
detecting whether eight neighboring cells blocked move
one unblocked neighboring cells. user-given h-values octile distances
(Bulitko & Lee, 2006).
carry experiments, used twelve maps deployed video games four
different mazes. Six maps taken game Dragon Age, remaining
six taken game StarCraft. maps mazes retrieved
Nathan Sturtevants pathfinding repository (Sturtevant, 2012).3
averaged experimental results 500 test cases reachable goal cell
map. test case start goal cells chosen randomly. realtime algorithms run 10 different parameter values. incremental algorithms
run completion per test case, results processed show
behavior corresponding using 150,000 different values k parameter.
experiments run 2.00GHz QuadCore Intel Xeon machine running Linux.
6.1 Analysis Results Real-Time Search Algorithms
Figure 2 shows two plots average solution cost versus average time per planning
episode four real-time search algorithms games mazes benchmarks.
observe games benchmarks FRITRT outperforms RTAA* daRTAA*
substantially. FRITRT (daRTAA*) finds solutions half cost found
daRTAA* given time deadline. Moreover, average planning time per episode
needed FRITRT (daRTAA*) obtain particular solution quality one half
needed daRTAA*. improvements pronounced FRITRT (RTAA*),
3. Maps used Dragon Age: brc202d, orz702d, orz900d, ost000a, ost000t ost100d whose sizes
481 530, 939 718, 656 1491, 969 487, 971 487, 1025 1024 cells respectively. Maps
StarCraft: ArcticStation, Enigma, Inferno, JungleSiege, Ramparts WheelofWar sizes 768 768,
768 768, 768 768, 768 768, 512 512 768 768 cells respectively.
four mazes size, 512 512, different corridor widths: 4, 8, 16 32.

253

fiRivera, Illanes, Baier, & Hernandez

100000000
FRIT(BFS)
RA
AA
optimal

1000000

Average Solution Length (log-scale)

Average Solution Length (log-scale)

10000000

100000

10000

1000

0

100

200

300

400

500

600

Average time per planning episode (us)

FRIT(BFS)
RA
AA
optimal

10000000

1000000

100000

10000

1000

0

200

400

600

800

1000

Average time per planning episode (us)

(a) Incremental algorithms games.

(b) Incremental algorithms mazes.

Figure 3: Incremental algorithms: Total Iterations versus Time per Episode
solutions given time deadline least three times cheaper pure RTAA*
one order magnitude cheaper small time frames. interesting
note even though daRTAA* improves significantly RTAA*, FRITRT (daRTAA*)
marginally better FRITRT (RTAA*).
mazes, FRITRT variants seem slightly better daRTAA*, bigger improvements performance noticeable time deadlines increased.
best solutions found daRTAA* FRITRT (daRTAA*) comparable lengths,
FRITRT (daRTAA*) finds solutions requiring slightly half time per
planning episode daRTAA*.
6.2 Analysis Results Incremental Algorithms Modified Satisfy
Real-Time Property
Figure 3 shows two plots average number agent steps versus average time per
planning episode incremental search algorithms used real-time algorithms
described aboved games mazes benchmarks. Figure 4 shows regions
plots Figure 3 FRIT(BFS) appears.
observe FRIT(BFS) returns significantly better solutions time constraints
tight. Indeed, games benchmarks algorithm need 41 sec
per planning episode return best solution. Given time limit per episode,
AA* requires four times many iterations average. Furthermore, obtain
solution quality returned FRIT(BFS) 41 sec, AA* needs around 220 sec;
i.e., 5 times long FRIT(BFS). behavior extreme case
mazes, best solutions FRIT(BFS) obtained less 19 sec per
planning episode. time limit, number steps required average AA*
whole order magnitude larger number required FRIT(BFS).
Generally, FRIT(BFS) behaves much better RA* AA*, requiring fewer
iterations less time. Nevertheless, provided time, FRIT(BFS) take
advantage resulting solutions cease improve. seen
254

fiReconnection Ideal Tree: New Approach Real-Time Search

100000000
FRIT(BFS)
RA
AA
optimal

1000000

Average Solution Length (log-scale)

Average Solution Length (log-scale)

10000000

100000

10000

1000

0

10

20

30

40

50

FRIT(BFS)
RA
AA
optimal

10000000

1000000

100000

10000

1000

0

Average time per planning episode (us)

5

10

15

20

Average time per planning episode (us)

(a) Incremental algorithms games.

(b) Incremental algorithms mazes.

Figure 4: Incremental algorithms: Total Iterations versus Time per Episode (zoomed)
FRIT(BFS)
k Avg. Time/ep
( s)
1 1508631 0.0430
5 303483 0.2148
10 152858 0.4283
50 32401 2.0940
100 17370 4.0678
500
5449 16.115
1000
4035 24.840
5000
3073 39.316
10000
3026 40.487
50000
3011 40.851
100000
3011 40.869

RA*
moves Avg. Time/ep
(%)
( s)
99.80 3505076 0.3754
99.01 702029 1.8761
98.03 351648 3.7499
90.71 71343 18.655
82.67 36305 37.077
44.74
8304 175.89
25.38
4901 322.74
2.046
2261 915.66
0.501
1947 1171.9
0.030
1726 1458.9
0.007
1711 1484.7

AA*
moves Avg. Time/ep
(%)
( s)
99.95 1144680 0.4152
99.76 229967 2.0727
99.51 115628 4.1376
97.60 24156 20.378
95.29 12723 40.004
79.42
3607 172.41
65.13
2583 274.35
24.44
1854 474.29
12.26
1775 514.88
1.041
1728 524.55
0.133
1726 543.66

moves
(%)
99.84
99.25
98.51
92.86
86.44
52.15
33.20
6.904
2.764
0.117
0.014

Table 1: Relationship search expansions number iterations
agent move games maps. table shows parameter k algorithm.
case AA* Repeated A* parameter corresponds number expanded
states. case FRIT, parameter corresponds number visited states
iteration. addition, shows average time per search episode (Time/ep),
percentage iterations agent move respect total number
iterations (No moves).

Figure 3, across sets benchmarks, Table 1. example this, see
k = 5000 k = 100000 number iterations required solve problem
decreases 62 steps, time used per search episode increases 1.55 sec.
Effectively, means algorithm use extra time advantageous
way. contrast usually expected real-time search algorithms.
255

fiRivera, Illanes, Baier, & Hernandez

interesting variable study number algorithm iterations
agent return move algorithm exceeded amount computation
established parameter without finishing search. see Table 1, FRIT,
using BFS parameter algorithm, best relationship time spent per
episode percentage no-moves total number moves. comparable
real-time heuristic search algorithms, would preferrable reduce number
incomplete searches much possible. mind, focus time
amount incomplete searches reduced less 1%. Notice
FRIT(BFS) somewhere around 40 s, whereas AA* RA* requires times
514 1458 respectively.
6.3 Comparison Two Approaches
Figure 5 shows plot average time per planning episode versus average number
agent steps FRITRT (daRTAA*) FRIT(BFS) games benchmarks.
observe FRIT(BFS) obtains better resuts time limits. Indeed, given
time deadline 10 sec, FRIT(BFS) finds solution half long
found FRITRT (daRTAA*). smaller time deadlines results similar
algorithms. Furthermore, best solution obtained FRIT(BFS) is, average,
less 60% long best solution obtained FRITRT (daRTAA*). mentioned
above, particular solution requires time deadline less 41 sec per planning
episode. number no-moves incurred time limit experiments
465 iterations throughout experiments games benchmarks, corresponds
approximately one no-move every 40, 000 moves.
12 maps - 500 runs
Average Solution Length (log-scale)

10000000
FRIT_rt(daRTAA)
FRIT(BFS)
1000000

100000

10000

1000

0

10

20

30

40

50

60

Average time per planning episode (us)

Figure 5: Comparison FRIT using real-time algorithm versus FRIT incremental
algorithm games benchmarks.

256

fiReconnection Ideal Tree: New Approach Real-Time Search

1

2

3

4

5

6

7

8

9

10

11

12

13

1



2

3

4

5

6

7

8

9

10

11

12

13



B

B

C

C





E

E



F

F

G

G

H

H

(a)



(b)

Figure 6: Bug2 (a) FRIT (b) pathfinding scenario goal cell E10
initial cell E2. segmented line shows path followed agent
filled arrow m-line.

6.4 Comparison Bug2 Algorithm
Bug algorithms (LaValle, 2006; Taylor & LaValle, 2009) family pathfinding algorithms continuous 2D terrain. make decisions based sensory input, require
limited time memory resources, inspired behavior insects
finding way obstacles. Bug algorithms heuristic utilize
heuristic function make decisions (Rao, Kareti, Shi, & Iyengar, 1993).
Bug2 (Lumelsky & Stepanov, 1987) bug algorithm simple implement
guaranteed reach goal. agent controlled Bug2 follow straight line
connecting initial position final positionthe so-called m-line, encountering obstacle reaching goal. obstacle encountered, saves position
obstacle hit variable called hit point starts following
boundary obstacle (either clockwise counterclockwise) m-line encountered again. Then, current position closer goal hit point, agent
starts following m-line process repeats.
Figure 6 compares behaviors FRIT Bug2. particular situation, Bug2
make good decision FRIT solves problem fairly quickly. course
possible contrive families problems Bug2 always outperform FRIT.
implemented Bug2 8-connected grid worlds. forbid diagonal movements
two obstacles, essentially effect changing direction
obstacles boundary followed. make comparison fair, also ran FRIT(BFS)
additional restriction. used game maps, generated 500 solvable
random problems them.
Results FRIT(BFS) shown Table 2. average cost solutions obtained
Bug2 6546, requiring 5766 iterations. addition, average runtime 2317
s, yields, average, 0.4 spent per iteration. FRIT(BFS) spends around 0.4
per search episode k = 12, requires 20 times iterations solve
problem yielding 97% no-moves. obtain solution comparable Bug2,
FRIT(BFS) requires k set around 462, yields average time per search
episode close 12 s, returning no-move 47% iterations. Finally, time
257

fiRivera, Illanes, Baier, & Hernandez

k Avg. Time/ep ( s) moves (%)
1 1544087
0.0346
99.81
5 310579
0.1725
99.03
10 156411
0.3442
98.07
50 33314
1.6830
90.91
100 14715
3.2712
83.01
500
5521
13.009
45.45
1000
4070
20.132
26.02
5000
3079
32.162
2.207
10000
3027
33.193
0.542
50000
3012
33.520
0.026
100000
3011
33.532
0.006
Table 2: Performance Indicators FRIT(BFS) diagonal movements allowed
obstacles.
available, FRIT(BFS) returns solutions average 50% cheaper
obtained Bug2.
conclusion observe pathfinding applications Bug2 runs faster
search algorithm tried. disadvantage, Bug2 specific pathfinding
cannot exploit additional time per episode obtain better solution, yielding solutions
longer obtained FRIT(BFS) time available. Therefore
bug algorithms seem recommended real-time pathfinding applications
little time available per iteration. time available FRIT(BFS)
recommended algorithm, leaving AA* choice applications
significantly time available.
6.5 Usefulness Reconnecting Heuristics
Definition 2 introduced idea admissible reconnecting heuristics, argued
important guide search towards reconnection. natural question ask whether
heuristics key performance FRITRT . Indeed, admissible heuristic
problem formally admissible reconnecting heuristic since simply need
define B = {g} Definition 2. Nevertheless, intuitively problems heuristic
guide towards reconnection ideal tree.
evaluate usefulness reconnecting heuristics, implemented version
FRITRT (RTAA*) that:
1. uses problems heuristic guide A* search,
2. breaks ties favor states greater g-value,
3. learns h using RTAA*s learning rule.
compared standard FRITRT (RTAA*), uses admissible reconnection
h = 0 guide A* search, uses problem heuristic first tie breaker, uses
258

fiReconnection Ideal Tree: New Approach Real-Time Search

g-value second tie breaker, learns h using RTAA*s learning rule. ran
algorithms 12 game maps, using configuration described above.
Figure 7 shows relative performance algorithms, confirming indeed
pathfinding applications, using reconnection heuristics key performance. Using
goal heuristic guide reconnection performs similar baseline (RTAA*).
FRITRT , used problems heuristic, seen version RTAA*
stops A* search early expands state agent believes connected
goal (i.e., ideal tree). Although stopping search early saves time respect
RTAA*, expensive goal conditionwhich verifies state ideal
treeseems counter time savings unless lookahead parameter high.
12 game maps - 500 runs

Average Solution Cost (log-scale)

10000000
FRIT_rt(RTAA) [h0=0]
FRIT_rt(RTAA) [h0=octile]
RTAA

1000000

100000

10000

1000

0

20

40

60

80

100

120

Average time per planning episode (us)

Figure 7: Comparison FRITRT using reconnecting heuristic (h=0) guide search
versus FRITRT using problems heuristic.

7. Related Work
Incremental Heuristic Search Real-time Heuristic Search two heuristic search approaches solving search problems partially known environments using free-space
assumption related approach propose here. Incremental search algorithms based A*, D* Lite (Koenig & Likhachev, 2002), Adaptive A* (Koenig
& Likhachev, 2005) Tree Adaptive A* (Hernandez, Sun, Koenig, & Meseguer, 2011),
reuse information previous searches speed current search. algorithms
solve sequences similar search problems faster Repeated A*, performs
repeated A* searches scratch.
runtime, incremental search algorithms, like algorithm, store graph
memory reflecting current knowledge agent. first search, perform
complete A* (backward forward), subsequent searches perform less
intensive searches. contrast algorithm, searches return optimal paths connecting current state goal. FRIT similar incremental search algorithms
sense uses ideal tree, information that, cases, may
259

fiRivera, Illanes, Baier, & Hernandez

computed using search, differs objective search
compute optimal paths goal. algorithm leverages speed simple blind
search need deal priority queue, computationally expensive
handle.
Many state-of-the-art real-time heuristic search algorithms (e.g., Koenig & Sun, 2009;
Koenig & Likhachev, 2006; Sturtevant & Bulitko, 2011; Hernandez & Baier, 2012; Rivera,
Baier, & Hernandez, 2013a), satisfy real-time property, rely updating
heuristic guarantee important properties like termination. algorithm,
hand, need update heuristic guarantee termination. Like incremental
search algorithms, real-time heuristic search algorithms usually carry search path
current node goal state. Real-time heuristic search algorithms cannot
return likely better solution problem solved without performing search
(cf. Theorem 4). Instead, running multiple trials eventually converge
optimal solution offer guarantees solution quality. algorithm offer
guarantees solution quality, even though experimental results positive.
HCDPS (Lawrence & Bulitko, 2010) real-time heuristic algorithm
employ learning. algorithm tailored problems agent knows map
initially, time preprocessing.
idea reconnecting tree rooted goal state new traced
back bi-directional search (Pohl, 1971). recent Incremental Search algorithm, Tree
Adaptive A* (Hernandez et al., 2011), exploits idea make subsequent searches faster.
Real-Time D* (RTD*) (Bond, Widger, Ruml, & Sun, 2010) uses bi-directional search
perform searches dynamic environments. RTD* combines Incremental Backward Search
(D*Lite) Real-Time Forward Search (LSS-LRTA*).
Finally, notion generalized free-space assumption related proposed
Bonet Geffner (2011), case planning partially observable environments.
certain circumstances, propose set unobserved variables action preconditions convenient way planning time, indeed corresponds adding
arcs original search graph.

8. Summary Future Work
presented FRIT, search algorithm follows path treethe ideal tree
represents family solutions graph currently known agent.
algorithm simple describe implement, need update heuristic
guarantee termination. FRIT uses secondary search algorithm search state
ideal tree agent becomes disconnected it. show that, slight
modifications, real-time search algorithm search reconnection, obtain
real-time version FRIT, FRITRT . addition, propose different way using FRIT
applications use real-time search feeding bounded, complete search
algorithms.
provide theoretical results proving FRIT FRITRT always find solutions
exist. Furthermore, give explicit bounds length obtained solutions.
Finally, prove algorithms converge two trial runs.
260

fiReconnection Ideal Tree: New Approach Real-Time Search

experiments show proposed algorithms return solutions faster
state-of-the-art real-time search algorithms. particular FRIT(daRTAA*) substantially
improves performance daRTAA*, state-of-the-art Real-Time Search algorithm. Larger
performance improvements observed time constraints tighter. Additionally,
compare approaches show FRIT(BFS)that is, FRIT fed
breadth first search algorithmproduces similar better results tight time constraints.
comparison pathfinding-specific Bug2 algorithm, concluded
little time per search episode given Bug2 delivers best-quality solutions, followed
FRIT(BFS), eventually, significantly time available, followed state-ofthe-art incremental search algorithms.
disadvantage approach, note FRIT cannot exploit computational time algorithms do. Indeed, incremental heuristic search algorithms
return better quality solutions allowed large time constraints, FRIT generally converge asymptotically optimal path given arbitrary time.
left scope paper FRIT could used general
search spaces like ones described using planning language like STRIPS
(Fikes & Nilsson, 1971) PDDL (McDermott, 1998). planning domains, search graphs
implicitly defined actions defined terms preconditions effects. Computing
ideal trees using Dijkstras algorithm, suggested above, simple since requires
generation number states exponential size problem description.
Moreover, immediately obvious either build ideal tree standard
domain-independent heuristic, done pathfinding. Indeed, exist
domain-independent planning heuristics admissible (e.g., Haslum & Geffner, 2000),
easy show correspond perfect heuristic spanning supergraph original search space, implies possible use directly
construct ideal tree, loops may easily formed. Therefore, investigation
needed order adapt techniques presented planning applications.
Acknowledgments
Nicolas Rivera, Leon Illanes, Jorge Baier partly funded Fondecyt Project
Number 11110321. thank anonymous JAIR reviewers, valuable input,
SoCS2013 reviewers comments earlier version paper.

References
Bjornsson, Y., Bulitko, V., & Sturtevant, N. R. (2009). TBA*: Time-bounded A*. Proc.
21st Intl Joint Conf. Artificial Intelligence (IJCAI), pp. 431436.
Bond, D. M., Widger, N. A., Ruml, W., & Sun, X. (2010). Real-time search dynamic
worlds. Proc. 3rd Symposium Combinatorial Search (SoCS), Atlanta,
Georgia.
Bonet, B., & Geffner, H. (2011). Planning partial observability classical replanning: Theory experiments. Proc. 22nd Intl Joint Conf. Artificial
Intelligence (IJCAI), pp. 19361941, Barcelona, Spain.
261

fiRivera, Illanes, Baier, & Hernandez

Botea, A. (2011). Ultra-fast Optimal Pathfinding without Runtime Search. Proc.
7th Annual Intl AIIDE Conference (AIIDE), Palo Alto, California.
Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. Journal
Artificial Intelligence Research, 25, 119157.
Bulitko, V., Bjornsson, Y., & Lawrence, R. (2010). Case-based subgoaling real-time
heuristic search video game pathfinding. Journal Artificial Intelligence Research,
38, 268300.
Bulitko, V., Bjornsson, Y., Lustrek, M., Schaeffer, J., & Sigmundarson, S. (2007). Dynamic
control path-planning real-time heuristic search. Proc. 17th Intl
Conf. Automated Planning Scheduling (ICAPS), pp. 4956.
Bulitko, V., Bjornsson, Y., Sturtevant, N., & Lawrence, R. (2011). Real-time Heuristic
Search Game Pathfinding, pp. 130. Applied Research Artificial Intelligence
Computer Games. Springer Verlag.
Edelkamp, S., & Schrodl, S. (2011). Heuristic Search: Theory Applications. Morgan
Kaufmann.
Fikes, R., & Nilsson, N. J. (1971). STRIPS: new approach application theorem
proving problem solving. Artificial Intelligence, 2 (3/4), 189208.
Hart, P. E., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimal cost paths. IEEE Transactions Systems Science Cybernetics, 4 (2),
100107.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proc.
5th Intl Conf. Artificial Intelligence Planning Systems (AIPS), pp. 140149.
Hernandez, C., & Baier, J. A. (2011). Fast subgoaling pathfinding via real-time search.
Proc. 21th Intl Conf. Automated Planning Scheduling (ICAPS),
Freiburg, Germany.
Hernandez, C., & Baier, J. A. (2012). Avoiding escaping depressions real-time
heuristic search. Journal Artificial Intelligence Research, 43, 523570.
Hernandez, C., Baier, J. A., Uras, T., & Koenig, S. (2012a). Position paper: Incremental
search algorithms considered poorly understood. Proc. 5th Symposium
Combinatorial Search (SoCS).
Hernandez, C., Baier, J. A., Uras, T., & Koenig, S. (2012b). TBAA*: Time-Bounded
Adaptive A*. Proc. 10th Intl Joint Conf. Autonomous Agents Multi
Agent Systems (AAMAS).
Hernandez, C., Sun, X., Koenig, S., & Meseguer, P. (2011). Tree adaptive A*. Proc.
10th Intl Joint Conf. Autonomous Agents Multi Agent Systems (AAMAS),
Taipei, Taiwan.
Ishida, T. (1992). Moving target search intelligence. Proc. 10th National
Conf. Artificial Intelligence (AAAI), pp. 525532.
Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22 (4), 109131.
262

fiReconnection Ideal Tree: New Approach Real-Time Search

Koenig, S., & Likhachev, M. (2002). D* lite. Proc. 18th National Conf. Artificial
Intelligence (AAAI), pp. 476483.
Koenig, S., & Likhachev, M. (2005). Adaptive A*. Proc. 4th Intl Joint Conf.
Autonomous Agents Multi Agent Systems (AAMAS), pp. 13111312.
Koenig, S., & Likhachev, M. (2006). Real-time Adaptive A*. Proc. 5th Intl Joint
Conf. Autonomous Agents Multi Agent Systems (AAMAS), pp. 281288.
Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic search
real-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313
341.
Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2-3), 189211.
LaValle, S. M. (2006). Planning algorithms. Cambridge University Press.
Lawrence, R., & Bulitko, V. (2010). Taking learning real-time heuristic search
video-game pathfinding. Australasian Conf. Artificial Intelligence, pp. 405414.
Lumelsky, V. J., & Stepanov, A. A. (1987). Path-planning strategies point mobile
automaton moving amidst unknown obstacles arbitrary shape. Algorithmica, 2,
403430.
McDermott, D. V. (1998). PDDL Planning Domain Definition Language. Tech.
rep. TR-98-003/DCS TR-1165, Yale Center Computational Vision Control.
Pohl, I. (1971). Bi-directional heuristic search. Machine Intelligence 6, pp. 127140.
Edinburgh University Press, Edinburgh, Scotland.
Rao, N. S., Kareti, S., Shi, W., & Iyengar, S. S. (1993). Robot navigation unknown terrains: Introductory survey non-heuristic algorithms. Tech. rep. ORNL-TM-12410,
Oak Ridge National Laboratory.
Rivera, N., Baier, J. A., & Hernandez, C. (2013a). Weighted real-time heuristic search.
Proc. 11th Intl Joint Conf. Autonomous Agents Multi Agent Systems
(AAMAS).
Rivera, N., Illanes, L., Baier, J. A., & Hernandez, C. (2013b). Reconnecting ideal
tree: alternative heuristic learning real-time search. Proceedings 6th
Symposium Combinatorial Search (SoCS).
Sharon, G., Sturtevant, N., & Felner, A. (2013). Online detection dead states realtime agent-centered search. Proc. 6th Symposium Combinatorial Search
(SoCS), Leavenworth, WA, USA.
Sturtevant, N. R. (2012). Benchmarks grid-based pathfinding. IEEE Transactions
Computational Intelligence AI Games, 4 (2), 144148.
Sturtevant, N. R., & Bulitko, V. (2011). Learning going whence
came: h- g-cost learning real-time heuristic search. Proc. 22nd
Intl Joint Conf. Artificial Intelligence (IJCAI), pp. 365370, Barcelona, Spain.
Taylor, K., & LaValle, S. M. (2009). I-bug: intensity-based bug algorithm. Proc.
2009 IEEE Intl Conf. Robotics Automation (ICRA), pp. 39813986.
263

fiRivera, Illanes, Baier, & Hernandez

Zelinsky, A. (1992). mobile robot exploration algorithm. IEEE Transactions Robotics
Automation, 8 (6), 707717.

264

fiJournal Artificial Intelligence Research 50 (2014) 487-533

Submitted 12/13; published 06/14

Improving Delete Relaxation Heuristics Explicitly
Represented Conjunctions
Emil Keyder

emilkeyder@gmail.com

Jorg Hoffmann

hoffmann@cs.uni-saarland.de

Saarland University
66123 Saarbrucken, Germany

Patrik Haslum

patrik.haslum@anu.edu.au

Australian National University & NICTA
Canberra ACT 0200, Australia

Abstract
Heuristic functions based delete relaxation compute upper lower bounds
optimal delete-relaxation heuristic h+ , paramount importance
optimal satisficing planning. introduce principled flexible technique
improving h+ , augmenting delete-relaxed planning tasks limited amount
delete information. done introducing special fluents explicitly represent
conjunctions fluents original planning task, rendering h+ perfect heuristic h
limit. Previous work introduced method growth task
potentially exponential number conjunctions introduced. formulate alternative technique relying conditional effects, limiting growth task linear
number. show method still renders h+ perfect heuristic h
limit. propose techniques find informative set conjunctions introduced
different settings, analyze extend existing methods lower-bounding upperbounding h+ presence conditional effects. evaluate resulting heuristic
functions empirically set IPC benchmarks, show sometimes much
informative standard delete-relaxation heuristics.

1. Introduction
Planning heuristic search one successful approaches planning.
informative heuristic functions domain-independent planning obtained
estimated cost delete relaxation original planning task. delete
relaxation simplifies planning tasks assuming every variable value, achieved,
persists execution rest plan. cost optimal plan
resulting relaxed planning task, denoted h+ , NP-complete compute, however whether
plan delete-relaxed task exists checked polynomial time (Bylander,
1994). satisficing planning, heuristic admissible,
latter fact exploited upper-bound h+ , generating necessarily optimal
plan delete-relaxed task (Hoffmann & Nebel, 2001). optimal planning, lowerbounding methods devised based analysis landmarks, logical formulas
set actions state necessary properties delete-relaxed plans (Karpas &
c
2014
AI Access Foundation. rights reserved.

fiKeyder, Hoffmann, & Haslum

Domshlak, 2009; Helmert & Domshlak, 2009). cost estimates delete-relaxed
task used guide heuristic search state space original task.
Since delete relaxation heuristics first proposed (Bonet & Geffner, 2001), much
work done improve them. One approach focuses better approximation
schemes h+ , obtaining tighter upper bounds thus better non-admissible estimates
(Hoffmann & Nebel, 2001; Keyder & Geffner, 2008, 2009), tighter lower bounds
correspond informative admissible heuristics (Helmert & Domshlak, 2009; Bonet
& Helmert, 2010). many domains, however, important heuristic able
take account delete information (Hoffmann, 2005), indeed long tradition
works proposing heuristics so. Several extend delete relaxation
capture strictly information (Fox & Long, 2001; Helmert, 2006; Helmert & Geffner,
2008; Cai, Hoffmann, & Helmert, 2009; Katz, Hoffmann, & Domshlak, 2013),
consider delete relaxation attempt find low-conflict relaxed plans (Baier &
Botea, 2009), generate modified heuristic values based taking conflicts account
extent (Do & Kambhampati, 2001; Gerevini, Saetti, & Serina, 2003). Here,
approach problem taking inspiration admissible hm family heuristics
(Haslum & Geffner, 2000). important property heuristics introduce, shared
recent work direction, technique renders h+ perfect
heuristic h limit. words, technique offers trade-off amount
delete information considered computational overhead so. one end
continuum, delete-relaxed plans become plans original task.
hm heuristic function considers cost making true simultaneously sets fluents
size m. cost planning task estimated recursively taking cost
set fluents, goal set action preconditions, cost
costly subset size m, ignoring cost achieving remaining fluents
set. possible subset size fluents task must considered,
size representation required compute hm exponential m. hm heuristics
provide guarantee exists hm = h (trivially satisfied
total number fluents task). However, value required achieve
usually large make computing h method infeasible practice.
hm heuristic recently recast hmax = h1 cost planning task
deletes (Haslum, 2009). achieved representing conjunctions fluents c
size original task new fluents c , called -fluents, modifying
initial state, goal, operators planning task capture reasoning
performed hm sets within computation hmax . However, h+ (m )
admissible (since separate copy action may needed establish
-fluent), thus compilation useful obtaining admissible estimates
informative h+ . recent C construction (Haslum, 2012) fixes
issue (introducing action copy every subset -fluents may established),
cost growing task representation exponentially number -fluents rather
linearly representation. hand, C offers possibility
fine-grained tradeoff representation size heuristic accuracy, allowing
choice arbitrary set conjunctions C corresponding -fluents (which need
size). stands contrast hm heuristic compilation,
sets conjunctions size represented.
488

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Haslum (2012) proposed repeatedly solve C optimally, within iterative procedure
adds new conjunctions set C iteration. relaxed plans
computed therefore gradually become closer, sense, plans original
task. instead explore idea using kind construction obtaining heuristic
functions guiding search.
C
introduce related construction C
ce similar , makes use
conditional effects limit growth task worst case linear, rather
exponential, |C|. gain size comes price information loss relative
C . However, show, information loss affect fundamental property
tending towards perfect heuristic h enough conjunctions introduced: Like
C , C
ce perfect limit, i. e. always exists set conjunctions C

h+ (C
ce ) = h . Furthermore, information may lost, always case.
Indeed, possible construct families planning tasks C
ce represent
+
C
heuristic function C set conjunctions C, i. e., h+ (C
ce ) = h ( ),
C
representation ce occupies exponentially less space.
said that, theoretical advantage C
ce tend materialize practice
(or least commonly used benchmarks): without optimizations C
indeed grows quickly practical, turns mutex pruning techniques (eliminating compiled actions conflicting preconditions) extremely effective keeping
C
size C bay. therefore consider C
ce , evaluating usefulness
devising improved heuristic functions. focus two main questions:
(A) obtain upper lower bounds h+ compiled tasks?
(B) choose set conjunctions C maximize information gained
addition planning task?
response question (A), analyze extend three state-of-the-art methods
estimating h+ . satisficing setting (upper-bounding h+ ), consider problem
finding low-cost relaxed plans scheduled minimize cost
sequence actions required trigger given set conditional effects, avoiding unnecessary
repeated applications action. problem scantily addressed
previous work. show problem optimal action scheduling given
set effects NP-complete, generalize approximation technique used FF
planner (Hoffmann & Nebel, 2001).
optimal setting (lower-bounding h+ ), consider LM-cut heuristic (Helmert
& Domshlak, 2009) well admissible heuristics based fluent landmarks (Karpas
& Domshlak, 2009). former, findings mostly negative: First, show
even though introduction -fluents cannot decrease hmax h+ , lowerand upper-bound LM-cut, respectively, LM-cut heuristic value decrease. Second,
show neither two straightforward adaptations LM-cut algorithm
problems conditional effects maintains admissibility domination hmax .1
latter, show C
ce used generate informative fluent landmarks.
Recent work (Keyder, Richter, & Helmert, 2010) extracts landmarks task.
1. sophisticated adaptation LM-cut, based idea context splitting, recently
proposed ? (?). maintains properties.

489

fiKeyder, Hoffmann, & Haslum

allows discovery -fluent landmarks corresponding conjunctive landmarks
original task, suffers due large number -fluents must considered.
C
ce compilation offers possibility discovering interesting conjunctive landmarks
unbounded size, avoiding growing size compilation unnecessarily.
response question (B), devise range strategies depending purpose
C
C
ce compilation used. parameterized terms
allowed growth compiled task relative original task, thus allow
trade-off informativeness heuristic computational overhead.
evaluate resulting heuristics wide range benchmarks International Planning Competition, varying relevant algorithm parameters determine individual
effect performance. results show, several domains heuristics much
informative previous ones, leading significantly improved performance.
next define basic concepts (Section 2), moving formal definition

C
C
ce compilation previously introduced compilations (Section 3).
C

C
Section 4, analyze ce relation theoretical perspective.
Section 5 discusses practical issues arise using compilations purpose
satisficing planning, describes obtained experimental results, Section 6
case optimal planning. Finally, Section 7 summarizes main points
paper indicates possible future research directions.

2. Preliminaries
planning model based propositional STRIPS formalization, add
action costs conditional effects. States operators defined terms set F
propositional variables, fluents. state F given set fluents
true state. planning task described 4-tuple = hF, A, I, Gi, F
set variables, set actions, F initial state, G F
describes set goal states, given {s | G s}. action consists
4-tuple hpre(a), add(a), del(a), ce(a)i, pre(a), add(a), del(a) subsets F .
action cost cost(a) R+
0 . ce(a) = {ce(a)1 , . . . , ce(a)n }, denote set
conditional effects action a, triple hc(a)i , add(a)i , del(a)i subsets
F . simplify notations, require add(a) del(a) = ; need
impose restrictions deletes del(a)i conditional effects, conditional
effects used within delete relaxation. ce(a) = A,
conditional effects, say STRIPS planning task.
action applicable pre(a) s. result applying given
[
[
s[a] = (s \ (del(a)
del(a)i )) (add(a)
add(a)i )
{i|c(a)i s}

{i|c(a)i s}

plan sequence
Pn actions = a1 , . . . , whose application results goal
state. cost i=1 cost(ai ). optimal cost minimal among plans
s; often denote optimal plans . plan also called plan ,
simply plan.
heuristic function h mapping states R+
0 . perfect heuristic

h maps state cost optimal plan s. heuristic h admissible
490

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

h(s) h (s) s. h(0 ), denote heuristic function whose value
given estimating cost corresponding state s0 modified task 0 . specify
0 terms transformation = hF, A, I, Gi 0 = hF 0 , A0 , 0 , G0 i; s0 obtained
applying transformation used obtain 0 I. sometimes useful
make explicit h heuristic computed itself; denote h().
Note modified task 0 used computation heuristic function.
particular, actual search plan performed state space original
planning task .
delete relaxation + planning task obtained discarding delete
effects. Formally, + = hF, A+ , I, Gi, A+ = {hpre(a), add(a), , ce+ (a)i | A},
ce+ (a) = {hc(a)i , add(a)i , | ce(a)i ce(a)}. cost action a+ A+
cost corresponding action cost(a). optimal delete relaxation heuristic h+
defined cost h (+ ) optimal plan + .
denote power set F P(F ) = {c | c F }. context hm ,
C
, C
ce , refer fluent subsets c P(F ) sets conjunctions interchangeably.
Throughout paper, assume conjunctions non-unit, i. e., |c| > 1.
landmark planning task logical formula set fluents F
every valid plan makes true state (Hoffmann, Porteous, & Sebastia, 2004).
Orderings landmarks statements order states occur.
natural ordering 1 n 2 means state sj satisfies 2 , state si
occurring sj 1 satisfied. necessary ordering 1 nec 2 means 1
always true state immediately state 2 becomes true,
greedy necessary ordering 1 gn 2 means relationship holds first time
2 made true. Note necessary ordering 1 nec 2 implies greedy necessary
ordering 1 gn 2 , vice versa. landmark graph G directed graph whose
nodes landmarks, whose labelled edges correspond known orderings
landmarks.

3. , C C
ce Compilations
compilation (Haslum, 2009) first technique proposed made use
idea -fluents explicitly represent conjunctions original task. Given
conjunction c F , c new fluent c 6 F unique c, i. e., c 6= c0 c 6= c0 .
defining compilations discuss, use shorthand X C =
X {c | c C c X}, X F set fluents, C P(F ) set
conjunctions. words, X C consists set fluents X itself, together new
fluents c whose intention represent conjunctions c C contained X,
c X.
Definition 1 (The compilation) Given STRIPS planning task = hF, A, I, Gi
parameter Z+ , planning task hF C , AC , C , GC i, C = {c | c
F 1 < |c| m}, AC contains well action ac pair A, c C
del(a) c = add(a) c 6= , ac given del(ac ) = , ce(ac ) = ,
pre(ac ) = (pre(a) (c \ add(a)))C
add(ac ) = add(a) {c0 | c0 C c0 (add(a) c)}
491

fiKeyder, Hoffmann, & Haslum

parameter indicates maximum size conjunctions represented
explicitly resulting compiled task. -fluent inserted (by definition F C , cf.
above) c F 1 < |c| m. c added fluent sets
task (such initial state, action preconditions, goals) containing associated
set c. Furthermore, linear (in |C|) number representatives action added
task model situation elements c made true
already true applied, adds remaining fluents c deleting
none them, thereby making every fluent c, therefore c , true. compilation
allows admissible hm cost original task computed hmax cost
compiled task.
non-admissibility h (m ) = h+ (m ) due construction action representatives ac : Sets fluents simultaneously made true single application
action may require several representatives explicitly achieve
effect . Consider example action adding fluent p state q
r already true. makes fluents p, q, r true simultaneously, whereas
2 , two different representatives required: one c = {p, q} adding {p,q} ,
one c = {p, r} adding {p,r} .
C compilation solves problem instead creating number representatives exponential number -fluents may made true a.
representatives corresponds application makes set -fluents
true (Haslum, 2012). Following example, separate representatives would
introduced -fluent sets , {{p,q} }, {{p,r} }, {{p,q} , {p,r} },
representative resulting last could applied make two -fluents
true simultaneously. C also differs allows choice set C P(F ),
introduces fluents c c C, rather subsets size
m:2
Definition 2 (The C compilation) Given STRIPS planning task = hF, A, I, Gi
set non-unit conjunctions C P(F ), C planning task hF C , AC , C , GC i,
0
AC contains action aC pair A, C 0 C c0 C 0 ,
(1) del(a) c0 = add(a) c0 6= ,
(2) c C((c c0 add(a) c 6= ) = c C 0 ),
0

0

0

aC given del(aC ) = , ce(aC ) = ,
[
0
pre(aC ) = (pre(a)
(c0 \ add(a)))C
c0 C 0
C0

add(a ) = (add(a) (pre(a) \ del(a)))C {c0 | c0 C 0 }
2. three differences definition Haslums (2012) definition actions
C . First, Haslums definition features delete effects, ensuring real (non-relaxed) plans correspond
plans original task. Since consider delete relaxations compiled task, safely
omit these. Second, allow sets C 0 used construction actions contain conjunctions c
0
c add(a) (pre(a) \ del(a)); third, add(aC ) contains -fluents c c pre(a) \ del(a).
latter two differences keep definitions simpler. redundant action representatives
redundant add effects cause easily pruned practice.

492

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

0

representatives aC enforce, every c0 C 0 , part c0 deleted,
0
non-added part c0 true already aC executed. Constraint (2)
0
ensures form non-redundancy: aC adds -fluent c0 , also adds -fluents
c c c0 , fluents c necessarily become true application
action. Note that, differently , add effects C include -fluents representing
conjunctions fluents added action prevail fluents (non-deleted preconditions).
necessary admissibility h+ (the primary purpose C ), needed
computation h1 (the primary purpose ).
C enumerates possible subsets C constructing representatives
action therefore grows exponentially |C|. exponentiality reminiscent
canonical conditional effects compilation used convert planning tasks conditional
effects classical STRIPS planning tasks exponentially actions (Gazen &
Knoblock, 1997). C
ce compilation introduce result applying
roughly reverse transformation C , resulting closely related planning task
linear (in |C|) number conditional effects:
Definition 3 (The C
ce compilation) Given STRIPS planning task = hF, A, I, Gi
C
C
C
C
set non-unit conjunctions C P(F ), C
ce planning task hF , Ace , , G

C
C
C
C
AC
ce = {hpre(a ), add(a ), del(a ), ce(a )i | A},

aC given
pre(aC ) = pre(a)C
add(aC ) = (add(a) (pre(a) \ del(a)))C
del(aC ) =
ce(aC ) = {h(pre(a) (c \ add(a)))C , {c },
| c C c del(a) = c add(a) 6= }
Rather enumerating sets -fluents may made true action, C
ce
uses conditional effects implicitly describe conditions made true.
information lost information encoded cross-context -fluents
preconditions, appear action representatives C , preconditions
C 0
effect conditions corresponding actions C
ce . action representatives
0
C , -fluents pre(aC ) exists c C 0 s.t. (c \ add(a))
pre(a). situation discussed above, example, {q,r} precondition action
representative adds {p,q} {p,r} C , appear condition
conditional effects corresponding action C
ce . Since effect conditions
determined individually c , conditions never included. return
discussing theoretical relationship C C
ce .
Example 1 Consider STRIPS planning task (adapted Helmert & Geffner, 2008)
variables {x0 , . . . , xn , y}, initial state = {x0 , y}, goal G = {xn }, unit-cost actions
: h, {y}, ,

bi : h{xi , y}, {xi+1 }, {y},
493

fiKeyder, Hoffmann, & Haslum

= 0, . . . , n 1.
optimal solution planning task takes form b0 , a, b1 , a, . . . , bn1 ,
cost 2n1. delete relaxation task, fact deleted application
bi ignored, optimal plan cost n.
-fluent xi ,y introduced C
ce compilation, added precondition
action bi , new conditional effects ce(a)i form h{xi }, {{xi ,y} }, created
action a. conditional effects added b-actions, deletes
therefore cannot achiever -fluent. increases optimal delete relaxation
cost task 1, new instance must added relaxed plan achieve
newly introduced precondition bi . -fluents form {xi ,y} introduced,
delete relaxation cost C
ce becomes 2n 1, optimal cost.
set conjunctions renders delete relaxation cost C perfect (i. e.,
2n 1). However, size C given conjunction set exponential n: action
may principle achieve subset conjunctions, every subset C 0 induces
0
separate representative aC AC .
Regarding compilation, h2 = hmax (2 ) also gives optimal cost task.
However, computation requires consideration (n2 ) fluent pairs, rather
linear number -fluents need introduced C
ce . shall see (Theorem 6), example easily extended must scale n hm become
C

perfect, thus showing exponential separation C
ce .
important practical optimization C C
ce mutex pruning. mutex
information original planning task available, specifically given (some)
m-tuples fluents reachable conjunction, discard
compiled task action representatives conditional effects require
m-tuple, without losing admissibility compilation. Namely, value h+ (C )
(respectively h+ (C
ce )) mutex pruning bounded value
0
0
0
h+ (C ) (respectively h+ (C
ce )) larger set C C conjunctions: include

-fluents size m, h mutexes found, i. e., none respective fluents reachable compiled task. Exploiting available mutex information allows us
make compilation informed without add additional -fluents,
helping keep compilation small.
Another optimization use eliminate dominated preconditions. Whenever add
fluent c precondition action, condition conditional effect,
remove condition fluents p c -fluents {c0 | c0 c}.
achieving c implies achieving fluents well, methods count cost
separately (such as, example, hadd related heuristics) would incur overestimation.
Note, however, eliminate duplication caused -fluents representing different fluent sets non-empty intersection. Consider, example,
action pre(a) = {p, q, r}. C = {{p, q}, {q, r}}, pre(a) = {{p,q} , {q,r} },
cost achieving q implicitly counted twice hadd estimate cost
applying a. possible solution, considered replacing overlapping -fluents c , c0
cc0 . This, however, consistently improve heuristics compute
compiled tasks.
494

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

4. Theoretical Properties C
ce
+
C
discuss theoretical properties C
ce , considering cost h (ce )
optimal solutions instead practical approximations (note C
ce version
C considered here, h+ = h delete effects present). proof sketches
shown, full proofs found Appendix A. first show fundamental
expected property:

Theorem 1 (Consistency admissibility) h+ (C
ce ) consistent admissible.
Proof: Regarding consistency, given s, s[a] = s0 , need show
+
C
0
0C
0C C .
h+ (C
ce )(s) cost(a) + h (ce )(s ). Let (s ) optimal plan
ce
0C sC [aC ] C task
aC (s0C ) necessarily plan sC C
ce ,
ce
deletes. Admissibility follows consistency together fact h+ (C
ce )(s) = 0
goal states s.
Furthermore, (ideal) delete relaxation lower bound improve add -fluents:
Theorem 2 (h+ (C
ce ) grows monotonically C) Given planning task sets
0
+
C0
C C non-unit conjunctions, h+ (C
ce ) h (ce ).
C
C
0
Proof: follows fact given plan = aC
1 , . . . , an0 for0 ce , 0 =
0
0
0
C
C
C
C
C
C
a1 , . . . , constitutes plan ce . show induction [a1 ] . . . [ai ]
C
0
C0
C0 =
C [aC
1 ] . . . [ai ] \ {c | c C \ C }, shows result since goal ce G
GC \ {c | c C \ C 0 }, GC sC [] valid plan.
0
= 0, induction hypothesis holds since C = C \ {c | c C \ C 0 } definition.
0
0
0
0
C
C
C
C0
C
0
> 0, aC
applicable [a1 ] . . . [ai1 ] since pre(ai ) = pre(ai ) \ {c | c C \ C },
0
0
0
C
0
C
C C
C [aC
1 ] . . . [ai1 ] [a1 ] . . . [ai ] \ {c | c C \ C } induction hypothesis.
C
C
C
C
C
C
{c | c (I [a1 ] . . . [ai ] \ [a1 ] . . . [ai1 ]) c C 0 }, either c add(ai )C ,
0
C0
implies c add(aC
) due definition ce , exists conditional effect
C
0
cej (aC
) = h(pre(a) (c \0 add(a))) , {c }, i. Since c C , must exist 0corresponding
0
C
C0
conditional effect ce definition, condition must true C [aC
1 ] . . . [ai1 ]
induction hypothesis.

special case C 0 = , Theorem 2 gives us:
+
Corollary 1 (h+ (C
ce ) dominates h ()) Given planning task set non-unit
+
C
+
conjunctions C, h (ce ) h ().

domination strict, follows trivially convergence h (Theorem 5 below).
consider relationship C C
ce compilations. mentioned
above, information encoded cross-context preconditions lost moving
C
exponential C linear C
ce . Estimates obtained ce may therefore inferior
obtained C :
Theorem 3 (h+ (C ) dominates h+ (C
ce )) Given planning task set nonunit conjunctions C, h+ (C ) h+ (C
).
cases inequality strict.
ce
495

fiKeyder, Hoffmann, & Haslum

Proof sketch: standard conditional effects compilation STRIPS (Gazen & Knoblock,
C
1997), applied C
ce , equivalent except presence cross-context preconditions C . Given this, plan C also plan C
ce , yet inverse
C C
C
1
n
,
.
. . , aC
case. show first part, show induction C [aC
n ] [a1 , . . . , ]ce ,
1
I[. . . ]ce denotes result applying sequence actions initial state C
C
C
ce . Since goal tasks defined G , shows desired result.
strictness result follows fact possible construct tasks
cross-context preconditions discussed play role, leading situations
C
exist plans C
ce shorter minimum-length plans .
proof strictness (Appendix A), show planning task h+ (C )
value strictly larger h+ (C
ce ) value C chosen conjunctions
size 2. implies exist tasks necessary consider strictly
larger conjunctions C
ce obtain equally good heuristic estimates obtained
C
C . necessarily problematic however, differently hm , C
ce
introduce conjunctions given size, therefore exponential maximum
size conjunctions considered.
C
advantage C
ce potentially exponentially smaller |C|;
domination therefore must qualified reduction size. Furthermore,
C
ce preserves ability compute perfect heuristic given sufficiently large set C
conjunctions. first consider equivalent result C , already proved Haslum
(2012). provide alternative proof conveniently adapted show
C
property C
ce . key proof following equivalence
h1 (m ) h1 (C ):
Lemma 1 Given planning task , C = {c P(F ) | 1 < |c| m}, h1 (m ) = h1 (C ).
Proof sketch: C identical except action sets. h1 values computed
considering single add effect time. inequality h1 (m ) h1 (C )
0
easy see verifying that, every add effect c action aC C (unless
0
c pre(aC ) thus redundant), action ac dominates it, i. e., c add(ac )
0
pre(ac ) pre(aC ). proof similar inequality h1 (C ) h1 (m ), observing
action ac non-redundant add effect, exists dominating action
0
aC C .
Theorem 4 (h+ (C ) perfect limit) Given planning task , exists C
h+ (C ) = h ().
Proof: known h () = hm () sufficiently high values (Haslum &
Geffner, 2000), shown Haslum (2009), hm () = h1 (m ). Lemma 1,
C = {c P(F ) | 1 < |c| m}, h1 (m ) = h1 (C ). Choosing appropriate
corresponding C, thus h () = hm () = h1 (m ) = h1 (C ).
Together fact h1 (C ) h+ (C ), since h+ (C ) h () admissibility
h+ (C ), claim follows.
1
C
+
C
show claim C
ce , remains relate h ( ) h (ce ):

496

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Lemma 2 Given planning task set non-unit conjunctions C, h1 (C )
h+ (C
ce ).
C
Proof sketch: Consider planning task C
no-cc identical except drops cross1
context -fluents preconditions. show (A) h (C ) h1 (C
no-cc ), (B)
1
C
+
C
h (no-cc ) h (ce ).
Similarly proof Lemma 1, (A) easy see showing every add effect
0
C 00 C : simply set C 00
c action aC C
no-cc dominated action
minimal subset C 0 contains c satisfies condition (2) Definition 2 (in
words, reduce C 0 get rid cross-context -fluents).
+
C
(B), suffices show h+ (C
no-cc ) h (ce ). holds because, action
C
0
relaxed plan ce , C set conjunctions added conditional
0
effects applied plan, action representative aC C
no-cc
preconditions a, used achieve set fluents.

Theorem 5 (h+ (C
ce ) perfect limit) Given planning task , exists C
h+ (C
)
=
h ().
ce
Proof: Choosing appropriate C, h () = hm () = h1 (m ), and,
Lemma 1, h1 (m ) = h1 (C ). Lemma 2, get h1 (C ) h+ (C
ce ). Since,
(), shows claim.
Theorem 1, h+ (C
)

h
ce
Note that, Theorem 3, Theorem 4 actually corollary Theorem 5. presentation chosen make relation two results, role two lemmas,
clearer.
proofs Theorems 4 5 rely obtaining perfect hm , clearly unfeasible
general since involves enumerating subsets fluents (and hence possible states)
worst case. However, C C
ce offer flexibility allowing us choose set
C: selecting subsets guarantees perfect heuristic, may achieved
much less effort, especially beneficial using C
ce whose growth |C| linear.

Indeed, task families obtaining h takes exponential effort hm ,
requires exponentially-sized C , yet C
ce remains small:
C ) exist parameterized task
Theorem 6 (Expressive power C
ce vs. h
families k

1. hm (k ) = h (k ) k,

C
2. h+ (C
k ) = h (k ) implies number action representatives k exponential k,

3. k exists Ck |Ck | (and therefore number conditional effects
+
C

(k )C
ce ) polynomial k, (b) h ((k )ce ) = h (k ).
Proof: Members one family given combination k planning tasks
type shown Example 1, size k, share among action
fluent needs made true step. k k goals, hm = h iff
k.
497

fiKeyder, Hoffmann, & Haslum

C
C
k (k )ce perfect, k -fluents {xi1 , y}, . . . , {xik , y} must introduced individual subtasks i, leading total k 2 -fluents. one
-fluents present, precondition action bij (k )C
ce , similarly
representative C 0 = {} C
,



individual
fluent
preconditions
y, xij ,
k
consequence one actions reestablishing left plan.
number conditional effects created (k )C
ce linear number -fluents added.
However, number action representatives (k )C exponential k: action
adds fluent y, belongs -fluents, hence one representative
subset -fluents.

using h+ (C
ce ) practice, typically able choose C results
perfect heuristic. Instead, try pick set C yields informative heuristic
without making size representation impractical work with.

5. Heuristics Satisficing Planning
consider practical issues involved using C
ce satisficing planning. Section 5.1 deals extraction relaxed plans, Section 5.2 deals strategies
choosing set conjunctions C. Section 5.3 presents experiments resulting
setup.
5.1 Relaxed Planning Conditional Effects
Techniques extracting relaxed plans presence conditional effects long
known (Hoffmann & Nebel, 2001). Here, refine extend techniques.
particularly important context as, unlike IPC benchmarks, structure
conditional effects C
ce rather complex, involving multiple dependencies
different actions, even different executions action.3
Non-admissible delete-relaxation heuristics typically obtained relaxed plan
extraction algorithm (Keyder & Geffner, 2008). different variants algorithm
characterized best-supporter function bs : F 7 use. cases, bs(p)
action adding p minimizes estimate cost making p true.
conditional effects present, algorithms compute set actions
scheduled form relaxed plan planning task. Formally, algorithms construct
relaxed plan according following equations (Keyder & Geffner, 2008):
(
{}
p
(p) =
bs(p) (pre(bs(p))) otherwise
[
(P ) =
(p)
pP

Existing methods choosing best supporters, hadd hmax , easily
extended conditional effects treating conditional effect task separate
3. remark similar issues arise approaches compiling uncertainty classical planning
conditional effects (Palacios & Geffner, 2009; Bonet, Palacios, & Geffner, 2009), techniques may
turn useful well.

498

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

action. particular, method employed, using hmax , compute FF heuristic
function (Hoffmann & Nebel, 2001). precisely, relaxed conditional effect
ce(a)+
condition c(a)i add add(a)i , action ai add effect add(ai ) =
add(a) add(a)i precondition pre(ai ) = pre(a) c(a)i created. set effects (G)
defined rules forms relaxed plan. presence conditional effects,
however, implies problem schedule relaxed plan: different
schedules may require different numbers action applications, multiple applications
single action avoided making conditions multiple desired effects true
given application a.
illustration, consider planning task action move-briefcase n conditional effects, conditionally transports object location location
B inside briefcase. Using representation above, distinct moving action
generated conditional effect. one possible schedule relaxed plan repeatedly
puts object briefcase, applies move-briefcase, proceeds next object.
plan n 1 steps longer optimal relaxed plan, first places
objects briefcase applies move-briefcase once.
words, single action execution may trigger several conditional effects
once, may exist relaxed plan length less |(G)|. question arises
optimally schedule relaxed plan, minimizing number action applications
required. FF uses simple approximate solution problem, outline
improve upon below. first note problem scheduling conditional relaxed
plans (SCRP) actually NP-complete:
Theorem 7 (Scheduling conditional relaxed plans) Let + relaxed planning task
conditional effects (G) set effects that, viewed set independent actions,
constitutes plan + . Deciding whether exists sequence actions length k
conditional effects (G) triggered NP-complete.
Proof: Membership follows fact given sequence k actions, easily
checked polynomial time whether conditional effects (G) triggered. Hardness
follows reduction shortest common supersequence problem (SCS) (Garey &
Johnson, 1979). supersequence string x = d0 . . . dm alphabet string
alphabet belongs language L = d0 . . . dm . Given
instance SCS problem strings x0 , . . . , xn alphabet {0, 1} asks
whether exists supersequence strings length k, construct
planning task conditional effects = hF, A, I, Gi,

F = ni=0 {yij | 0 j |xi |}
= {a0 , a1 }, az = {, , , ce(az )}, ce(az ) given set conditional
effects
n |x[
|1
[
{hyij , yij+1 , | xij = z}
i=0 j=0

= {y00 , . . . , yn0 }
G = {y0|x0 | , . . . , yn|xn | }
499

fiKeyder, Hoffmann, & Haslum

two actions a0 a1 correspond addition symbols 0 1 respectively
supersequence implicitly constructed, fluent yij encodes fact
current string constitutes supersequence prefix xi0 , . . . , xij1 .
seen valid plan planning task must trigger conditional effects
task, yet sequence actions length k exists iff common
supersequence x0 , . . . , xn length k. transformation SCS problem
planning task conditional effects polynomial, shows claim.
Note Theorem 7 relate (known) hardness optimal relaxed planning:
wish schedule effects already selected know form
relaxed plan. source complexity has, yet, overlooked literature.
Given hardness result, employ greedy minimization technique call
conditional effect merging. Starting trivial schedule containing one action execution
effect (G), consider pairs effects e, e0 (G) conditional effects
action a. two effects merged single execution conditions
achieved without use either add effects. FFs approximation method
applies similar reasoning, captures special case condition holds:
e e0 appear layer relaxed planning graph, trivially
implies conditions effects independently achievable. However,
may also case effects different layers relaxed planning graph.
devise strictly general technique, capturing form independence
effects using call best supporter graph (BSG) representation relaxed plan
(for simplicity, assume task single goal fluent G0 , needed
achieved introducing new action end whose preconditions original goals,
adds G0 ):
Definition 4 (Best supporter graph) Given relaxed planning task + best supporter function bs, best supporter graph directed acyclic graph = hV, Ei,
V = (G), (G) above, E = {hv, v 0 | p pre(v 0 ) v = bs(p)}, vertex
labeled action whose conditional effect represents, edge labelled
set preconditions {p | p pre(v 0 ) v = bs(p)}.
nodes graph represent conditional effects appear relaxed plan,
exists edge hv, v 0 two nodes effect represented v best
supporter (pre)condition effect represented v 0 .4 bs valid best supporter
function (i. e., relaxed plan (G) generated bs sound) sufficient condition
acyclic, easily shown topological sort sound
relaxed plan. implies that, path two conditional effects
action, occur result action application, therefore
merged single occurrence action. nodes removed
BSG, new node added represents effects, combining incoming
outgoing edges. process repeated node merges possible.
algorithm runs polynomial time sound results BSG
topological sort constitutes relaxed plan . not, however, guarantee
optimal scheduling original plan.
4. edge labels used procedure choosing conjunction set C, described Section 5.2.

500

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

example, consider task move-briefcase n conditional effects
transporting object location location B inside briefcase. nodes
BSG n put-into-briefcase(oi ) actions (one object oi ), well n copies
move-briefcase(A, B) (one conditional effect regarding object oi ).
one edge put-into-briefcase(oi ) respective copy move-briefcase(A, B), labeled
in-briefcase(oi ). therefore path graph move-briefcase(A, B)
node another, merged single node conditional effect merging
algorithm. topological sorts merged BSG correspond optimal relaxed plans.
5.2 Choosing C Relaxed Planning
Algorithm 1 shows main procedure computing set conjunctions C used form
C
ce task. algorithm applied once, start search, initial
C
state planning task. resulting C
ce (or ) task used subsequent
heuristic evaluations. Conditional effect merging used conflict extraction
phase configuration discussed below, i. e., use original non-merged BSG
stated Definition 4.
Algorithm 1: Choosing C relaxed plan heuristics.
C=
= RelaxedPlan(C
ce )
plan size(C
ce ) < bound
C = C FindConflicts()
= RelaxedPlan(C
ce )
Algorithm 1 is, high level, similar procedure previously introduced
computing incremental cost lower bounds based C construction (Haslum, 2012).
algorithm repeatedly generates relaxed plans initial state current compiled
task. adds new conjunctions C based conflicts found current
plan, i. e., based current relaxed plan fails executed original planning
task . process stops either conflicts found, implying
current relaxed plan C
ce plan original planning task, user-specified
C
bound size ce reached. express bound terms size C
ce
compared (see below). also sometimes impose bound runtime
algorithm.
bound specified, FindConflicts() returns least one new conjunction
long plan , Algorithm 1 complete planning algorithm right.
report results usage algorithm experiments below. relaxed
plan generated iteration optimal, Algorithm 1 used compute sequence
admissible cost estimates converges optimal plan cost (Haslum, 2012).
focus, however, use C
ce generating inadmissible heuristic functions.
therefore use tractable, non-optimal, relaxed planning procedure, impose bound
typically stops Algorithm 1 plan original task found.
remains specify FindConflicts procedure: Given relaxed plan fails
execute original planning task , select set new conjunctions C? One
501

fiKeyder, Hoffmann, & Haslum

answer question provided previous use Algorithm 1 compute
plan cost lower bounds (Haslum, 2012). aim different computing heuristics
satisficing search-based planning make number changes previously
proposed version FindConflicts. Section 5.2.1 summarizes original procedure,
Section 5.2.2 describes changes make it.
5.2.1 Conflict Extraction Incremental Plan Cost Lower Bounds
Given optimal relaxed plan plan original planning task, Haslums
(2012) version FindConflicts returns set conjunctions C prevents relaxed
plan solution next iteration. ensures progress, sense
cost relaxed plan eventually increase, prove real plan cost.
describe conflict extraction procedure, need two definitions:
Definition 5 (Relaxed Plan Dependency Graph) Let non-redundant plan
relaxed planning task + . Construct directed graph G () one node va
action , plus node vG representing goal. Let pre(v) denote precondition
node v, pre(a) node va G node vG . G (S) directed edge
va v 0 iff pre(v 0 ) relaxed reachable using set actions minus {a}.
edge labelled subset pre(v 0 ) relaxed unreachable actions.
relaxed plan dependency graph, RPDG(), transitive reduction G ().
RPDG similar BSG (Definition 4), encodes necessary dependencies actions relaxed plan. path node va node vb
RPDG implies precedes b every valid sequencing ; case, vb said
ordered va . contrast, BSG encodes intentions relaxed plan
heuristic, form chosen best supporters, may impose orderings need
respected every valid sequencing plan (e. g. fluent p added another
action relaxed plan best supporter p). relaxed plan
non-redundant, meaning action removed without invalidating it,
path every action node RPDG goal node.
Definition 6 (Dependency Closure) Let non-redundant plan relaxed planning task + , let v v 0 nodes RPDG(), v 0 ordered v. simple
q1
q2
qm
dependency path path v v1 . . . v 0 v v 0 RPDG(), edge
labelled one fluent, chosen arbitrarily, edge label RPDG(). (Whenever
v 0 ordered v, simple dependency path v v 0 exists.) dependency closure
v v 0 minimal, w.r.t. subset, union paths, (1) contains simple
dependency path v v 0 , (2) q fluent labels edge node v 00
closure, action q add(a), action associated
v 00 , closure contains simple dependency path v node corresponding
a. (Such path guaranteed exist.)
Recall input FindConflicts plan, , valid delete relaxation +
original planning task delete effects considered.
valid + , preconditions actions , well goals, must made true
502

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

...
vd
p1
r
...
vf
q1

p
vd

q1

...

qn

vf

pn
vj
qm

(b)

(a)

Figure 1: Relaxed plan failure scenarios. Wavy edges show deletions precondition.
point. Thus, fails solve original task must case action
d, call deleter, deletes precondition action f , called
failed action. Note failed action also goal. Let p pre(f )
deleted fluent. procedure distinguishes two cases, based relation
nodes vd vf RPDG:
first case, illustrated Figure 1 (a), vf ordered vd . Choose dependency
closure vd vf , let L set fluents labelling edges closure:
set conflicts generated {{p, q} | q L}. (Note p 6 L, thus conflict
proper conjunction.)
first case hold, vd vf unordered. must nearest
common descendant node, vj , RPDG, situation illustrated Figure 1
(b). Choose dependency closure vd vj , let L1 set fluents labelling
edges closure. Likewise, choose dependency closure vf vj , let L2
set fluents labelling edges closure. set conflicts generated
{{q, q 0 } | q L1 , q 0 L2 {p}}.
Theorem 8 (Haslum, 2012, Theorem 6) Let = a1 , . . . , non-redundant plan
delete relaxed task + valid original task , let C set
conjunctions extracted procedure described above. action sequence 0 = a01 , . . . , a0n
a0i representative ai valid plan C .
5.2.2 Changes Conflict Extraction Satisficing Planning
number differences setting Haslum (2012).
particular, although -fluents collected initial state, resulting C
ce task
used heuristic evaluations states encountered search, growth
size C
ce task incur overhead heuristic evaluation. Thus,
objective find set C make heuristic accurate across states,
keeping size C limited. hand, computing non-optimal relaxed
plans computationally far cheaper optimal relaxed planning, afford
iterations Algorithm 1.
Therefore, make following modifications strategy: First, use BSG
instead RPDG. necessity orderings latter extend beyond
current (initial) state, therefore useful purpose. BSG
representative relaxed plans found non-optimal relaxed planning procedure.
Second, introduce single -fluent iteration Algorithm 1.
time, cause new relaxed plan found, allows algorithm focus
finding small number conflicts useful wide range states. chosen
conflict {p, qn } case depicted Figure 1 (a), {pn , qm } Figure 1 (b).
503

fiKeyder, Hoffmann, & Haslum

Intuitively, works better setting set conflicts generated
plan failure tends redundant, thus needlessly grows size task
leading slow evaluation times without much gain informativeness.
changes affect fundamental property Algorithm 1, converges
real plan. show convergence, property FindConflicts must
returns least one new conjunction whenever fails solve original task.
variant still gives guarantee:
Lemma 3 Assume eliminate dominated preconditions 5 C . Let = a1 , . . . ,
non-redundant plan C valid original task , let c
conjunction extracted procedure described above. c 6 C.
Proof: simply because, possible relaxed plan failure scenarios (Figure 1),
chosen conjunction c = {x, y} ({x, y} = {p, qn } respectively {x, y} = {pn , qm }) contained
precondition failed action f . Assuming c = {x, y} C, eliminate
dominated preconditions, action precondition C contains x y. Hence,
case, c cannot chosen conjunction.
Theorem 9 (Convergence conflict extraction) Assume eliminate dominated preconditions C , Algorithm 1 run without size bound. eventually
plan .
Proof: Follows Lemma 3 set possible conjunctions finite.
Contrasting Theorem 9 Haslums variant (Theorem 8), latter gives stronger
convergence guarantee (only) sense guarantees certain minimum progress
made iteration.
Lemma 3 (and thus Theorem 9) holds way C
ce , i. e., sequence
C
conditional effects ce , that, viewed set independent actions, constitutes nonredundant plan C
ce . rely eliminating dominated preconditions
makes proof simple, use technique practice anyway.
verify whether convergence holds also dominated preconditions eliminated;
conjecture does.
Since multiple conflicts BSG relaxed plan, experiments
choose (arbitrarily) one minimizes number conditional effects (or STRIPS
actions, case C ) created. place bound factor x C
ce exceeds
size original planning task . Precisely, x = 1, -fluents conditional
+
effects added, C
ce = , resulting standard relaxed plan heuristic. growth
bounds x > 1, -fluents added number conditional effects task reaches
(x 1) |A|. C , x limits total number actions task multiple |A|.

5. Recall eliminating dominated preconditions means that, whenever add fluent c precondition action, condition conditional effect, remove condition fluents
p c -fluents {c0 | c0 c}.

504

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Example 2 Consider STRIPS planning task Example 1, variables
{x0 , . . . , xn , y}, initial state = {x0 , y}, goal G = {xn }, unit-cost actions
: h, {y}, ,

bi : h{xi , y}, {xi+1 }, {y},

= 0, . . . , n 1.
previously discussed, setting C = {x1 ,y , . . . , xn1 ,y } renders delete relaxation
perfect, i. e., results relaxed plan re-establish every two bactions. Exactly set C iteratively selected procedure.
Assuming best supporter function based either hadd hmax , first iteration
Algorithm 1 BSG be:

b0

x1

b1

x2

...

b2

bn2

xn1

bn1

relaxed plan fails execute trying apply second action, b1 . corresponding failure scenario matches Figure 1 (a):


b0

b1

x1

chosen conflict thus {y, x0 }. non-empty set conjunctions C containing single conjunction, precondition b1 contains {x1 ,y} must
established using action a, BSG takes form (note dominated
preconditions xi b1 eliminated):

b0

x1



{x1 ,y}

b1

b2

x2

...

bn2

xn1

bn1

relaxed plan fails execute trying apply fourth action, b2 .
corresponding failure scenario is:


b1

x2

b2

chosen conflict {y, x2 }. Iterating procedure will, manner, select
exactly set C one-by-one, end relaxed plan solve original
planning task.
5.3 Experiments
evaluate impact using C
ce compilation relaxed plan heuristic context greedy search. expected impact using heuristic based improved
relaxation two-fold. one hand, make heuristic informative,
505

fiKeyder, Hoffmann, & Haslum

enabling search find plans fewer node evaluations. hand,
computational overhead associated growth problem, slowing heuristic
evaluations. examine effects individually, well combined influence coverage, set problems planner able solve within given time
memory bounds, take main measure performance.
study, consider objective producing plans high quality (as
measured plan length cost). plan quality unimportant. Rather,
rationale decision methodological: Seeking high quality plan
problem seeking find plan minimum search effort particularly
quality measured non-unit action costs requirements heuristics
two problems quite different. Here, chosen focus one, viz. search efficiency,
measured coverage node evaluations, rather conflate two. choice
plain greedy search algorithm also motivated decision. consequence,
treat actions unit cost 1. Previous experiments shown
context greedy search, distinguishing action costs heuristic calculation tends result
lower coverage (Richter & Westphal, 2010). However, least assess impact
heuristics plan quality, report data regarding plan length.
next describe experiment setup baseline. discuss heuristic informativeness, computational overhead, impact conditional effect merging, impact
plan length using C
ce heuristics, comparison state-of-the-art heuristics
problem, difference using C C
ce compilations, finding
plans search.
5.3.1 Experiment Setup Baseline
compilation associated heuristics implemented Fast Downward planner
(Helmert, 2006), used greedy best-first search, lazy evaluation second
open list (with boosting) states resulting preferred operators. planners
tested STRIPS domains 19982011 editions International
Planning Competition (IPC). domains last two IPCs, recent
sets instances used. experiments run Opteron 2384 processors
settings used competition: memory limit 2Gb time limit 30 minutes.
baseline planner configuration uses relaxed plan heuristic, best supporters
identified hadd , unmodified planning task (i. e., growth bound x = 1).
known fact greedy search, particular greedy search lazy evaluation
strong bias towards preferred operators, highly sensitive small changes
relaxed plan, even changes alter heuristic value rather
operators preferred. Unfortunately, fact rarely taken account
heuristics compared context greedy search. Since introduction -fluents
alters structure relaxed plan, believe particularly important determine
whether resulting differences planner performance really due relaxed plan
(or less) informative.
Therefore, first step towards accounting brittleness experiments
greedy heuristic search, introduce simple variance measure use decide
results experiments considered significant. Variance performance
506

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

baseline planner measured randomizing choice supporters equal
hadd values construction relaxed plan measuring maximum deviation
results baseline planner five repeated runs. results shown
columns labeled MaD (Tables 1 4). domain problem set
whole, deviation defined differences coverage median number
heuristic evaluations. Note interested whether randomization helps
hurts search, rather magnitude variation causes.
C
comparing results planner using heuristics based C
ce different
growth bounds results baseline planner, consider difference
significant greater magnitude maximum deviation observed
randomization baseline. interpreted significance
statistical sense (although, assumed randomization affects heuristics equally,
could estimate probability hypothesis difference), simply setting
reasonable threshold counts substantial difference search performance.

5.3.2 Heuristic Informativeness
comparison heuristic informativeness summarized right half Table 1,
shows ratio median (per domain, tasks solved planners)
number heuristic evaluations baseline planner planners using
C
ce -based heuristics. half domains, difference informativeness
C
ce -based heuristics compared baseline exceed threshold significance
set sensitivity study (shown MaD column). Among domains
significant difference, majority using C
ce -based heuristics reduces
number node evaluations, indicating augmented heuristics informative.
cases, ratio grows -fluents added, i.e., growth bound
x increased. drastic example seen Floortile domain,
C
ce -based heuristics evaluate four orders magnitude fewer nodes, compared
standard delete relaxation heuristic. allows easily solve instances
domain. comparison, planner IPC 2011 able solve 9
20 instances domain. Woodworking domain, C
ce heuristics
two orders magnitude informative, associated increase coverage
tasks solved configurations.
roughly third domains consistent (or nearly consistent) loss
informativeness, though significant. Note loss informativeness always correlate loss coverage. attributed different
factors, including small magnitudes loss, well fact ratio node
evaluations taken tasks solved planners compared. Another issue
dramatic coverage losses often due computational overhead incurred
C
ce compilation. particular, Openstacks Satellite domains, decrease
number tasks solved C
ce -based heuristics matches almost exactly number
tasks conflict selection compilation process fails complete within
1800 seconds allocated per task. get back next subsection.
507

fiKeyder, Hoffmann, & Haslum

worth noting quality C
ce -based heuristics highly sensitive
precise choice -fluents used compilation.6 Hence, may exist better policies
making choice relatively simple one used here.
HO PO colums Table 1 (coverage only) examine effect new
heuristic function, respectively new preferred operators returned function,
separation. PO corresponds configuration uses relaxed plan C
ce task
(built x = 1.5 timeout = 60s, discussed Section 5.3.3) identify
preferred operators, together heuristic value baseline (x = 1) heuristic.
HO, hand, uses heuristic values obtained x = 1.5 preferred
operators x = 1. Interestingly, either heuristic values preferred operators alone
sufficient greatly improve coverage Floortile, domain techniques
greatest impact. HO PO configurations able solve every instance
domain.7 effect domains mixed, configurations solving
sometimes more, sometimes fewer instances.
5.3.3 Computational Overhead
computational overhead C
ce -based heuristics, compared standard relaxed
plan heuristic, stems two sources: (1) time spent computing set -fluents
add problem, (2) greater overhead heuristic evaluation C
ce task.
Table 2 shows three measures impact.
first four columns (under Timeouts) show number instances
construction C
ce task finish within 1800 seconds, second set
four columns (under > 60 sec) shows number instances construction
time exceeds 60 seconds (inclusive instances first set columns). Note
behavior spending large amount time C
ce construction without reaching
growth bound partly due strategy selecting -fluents, since purposely
choose -fluents increase size compiled task least.
several domains construction time frequently exceeds 60 seconds,
happen domains C
ce -based heuristic informative,
Floortile Woodworking. suggests imposing time limit construction
C
ce task incur small loss informativeness. present coverage results
strategy (using 60 second time limit) Table 4 below. significantly better
baseline planner, compares favourably state art heuristics.
expected, domains evaluating heuristics C
ce task slower
standard delete relaxation, tends slow growth bound x increases,
due larger number fluents actions compiled planning task. median
slowdown per domain typically order x itself, exceeds one order
6. Indeed, results reported earlier paper (Keyder, Hoffmann, & Haslum, 2012) show increase
informativeness Barman Parcprinter domains.
7. plausible explanation behavior respect dead-end states (intuitively,
robot painted corner) unrecognized standard delete relaxation
heuristic, i. e., relaxed plan exists. appears C
ce highly effective fixing
issue: x = 1 search encounters millions states hFF () = , HO encounters
FF
states hFF (C
(C
ce ) = (suggesting h
ce ) prunes dead-ends early on), PO encounters
states (suggesting hFF (C
)
preferred
operators prevent search entering
ce
dead-end regions first place).

508

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Domain
x=1 MaD
Airport (50)
36
Barman (20)
13
Blocksworld (35)
35
Depots (22)
19
Driverlog (20)
20
Elevators (20)
19
Floortile (20)
6
FreeCell (80)
79
Grid (5)
5
Gripper (20)
20
Logistics00 (28)
28
Logistics98 (35)
34
Miconic (150)
150
Mprime (35)
35
Mystery (30)
16
Nomystery (20)
9
Openstacks (20)
20
Parcprinter (20)
16
Parking (20)
20
Pathways (30)
30
Pegsol (20)
20
Pipes-NoTk (50)
42
Pipes-Tank (50)
38
PSR (50)
50
Rovers (40)
40
Satellite (36)
35
Scanalyzer (20)
18
Sokoban (20)
19
Tidybot (20)
16
TPP (30)
30
Transport (20)
11
Trucks (30)
14
Visitall (20)
19
Woodwork (20)
20
Zenotravel (20)
20
Total (1126)
1002

+2

+5

+0

+1

+0

+3

+0

+2

+0

+0

+0

+1

+0

+0

+0

+2

+0

+7

+1

+2

+0

+1

+4

+0

+0

+1

+1

+1

+3

+0

+1

+0

+1

+0

+1

+19


Coverage
x =
PO HO
1.5 2 2.5 3 1.5 1.5
+0
+1 +3 +1 +2 +1
+6 +3 +1 3 3 +5
+0
+0
+0
+0
+0
+0

+0 1
+2 +2 +2 +2
+0
+0
+0
+0
+0
+0

+1 +1 +1 +1 +1 +1
+14 +14 +14 +14 +14 +14
+0 +1
+1 3 4 2
+0
+0
+0
+0
+0
+0

+0
+0
+0
+0
+0
+0

+0
+0
+0
+0
+0
+0

+0 1
+0 +1 +1
+1
+0
+0
+0
+0
+0
+0

+0
+0
+0
+0
+0
+0

+3 +3 +3 +3 +3 +1
2 3 3 3 1 2
9 9 9 9 1 1
11 8 7 7 4 10
+0 6
2 8 7 5
+0
1 2 5 1 1
+0
+0
+0
+0
+0
+0

+0 1
+0
+0 1
+0

+0 +2 1 +3
+3 +2
+0
+0
+0
+0
+0
+0

+0
+0
+0 1
+0
1
+0
2 5 6 8 +1
+2 +2 +2 +2 1 +2
+0 2
2 2 3 3
+0
+0 1 1
+0
2
+0
+0
+0
+0
+0
+0

+2 2 +1 +1 7 3
+0 +2
+1 +3 +4 +2
+1 +1 2 2 2 2
+0
+0
+0
+0
+0
+0

+0
+0
+0
+0
+0
+0

+6 9 17 14 3 +3

Median Node Evaluations Ratio
x =
1.5
2
2.5
3
4.32
1.36 : 1
1.34 : 1
1.40 : 1
1.50 : 1
9.91
1 : 1.63
1 : 2.22
1 : 8.33
1 : 25
5
2.84 : 1
2.90 : 1
2.90 : 1
3.02 : 1
12.13
2.84 : 1
3.26 : 1
3.65 : 1
8.55 : 1
1.16 2.17 : 1
2.64 : 1
2.65 : 1
2.31 : 1
1.31
1.25 : 1
1.47 : 1
1.34 : 1
1.22 : 1
6.42 15013 : 1
15110 : 1
14757 : 1
19674 : 1
1.28
1 : 1.11
1 : 1.28
1 : 1.17
1 : 1.29
1.21 1.27 : 1
2.83 : 1
1.27 : 1
1.27 : 1
1
1 : 1.05
1 : 1.51
1 : 1.49 1.23 : 1
1.64
1.47 : 1
1.47 : 1
1.53 : 1
1.60 : 1
1.45 2.53 : 1
2.57 : 1
2.83 : 1
2.70 : 1
1 1.16 : 1
1.22 : 1
1.29 : 1
1.36 : 1
1.09 2.33 : 1
2.33 : 1
2.33 : 1
2.33 : 1
1.07 1.21 : 1
1.27 : 1
1.29 : 1
1.29 : 1
13.93
1 : 1.44
2.58 : 1
9.95 : 1
10.13 : 1
1.08 2.52 : 1
1.31 : 1
1 : 1.23
1 : 1.11
1.58
1 : 1.04
1 : 1.04
1 : 1.08
1 : 1.09
7.06
1 : 1.12
3.02 : 1
1.61 : 1
1.18 : 1
1.21
1 : 1.03
1:1
1 : 1.05
1 : 1.11
3.42
1.44 : 1
1.09 : 1
1.66 : 1
1.41 : 1
16.47
1 : 1.07
1.08 : 1
1.14 : 1
1.29 : 1
2.46
1:1
1:1
1:1
1 : 1.05
1
1:1
1.02 : 1
1.12 : 1
1.12 : 1
1.33
1.12 : 1
1.15 : 1
1.12 : 1
1.20 : 1
1.36
1.15 : 1
1.36 : 1
1.30 : 1
1.29 : 1
1.85
1.17 : 1
1.80 : 1
3.43 : 1
3.25 : 1
1.46
1.17 : 1
1 : 1.09
1.01 : 1
1.06 : 1
1.22
1.15 : 1
1 : 1.25
1 : 1.38
1 : 1.08
2.29
1 : 1.20
1 : 1.13
1 : 1.19
1 : 1.01
2.73
1.20 : 1
1 : 1.11
1 : 1.29
1 : 1.01
1.66
1.16 : 1
1.97 : 1
7.27 : 1
4.57 : 1
1.34
1.01 : 1
1 : 1.08
1 : 1.09
1 : 1.49
52.78 245.72 : 1
263.3 : 1
245.72 : 1
245.72 : 1
1.28
1.22 : 1
1.24 : 1
1.36 : 1
1.42 : 1
MaD

Table 1: Planner coverage heuristic informativeness using C
ce varying growth bounds,
without conditional effect merging. Coverage shows number problems solved baseline
configuration (x = 1), difference (increase/decrease) relative baseline
configurations; PO uses preferred operators obtained C
ce compilation
x = 1.5 = 60s, returning x = 1 heuristic value, HO uses heuristic values
obtained x = 1.5 = 60s, preferred operators x = 1. Heuristic informativeness
measured ratio per-domain median number node evaluations, comparing
baseline configurations (across instances solved configurations), normalized
smaller value 1. is, entry : 1 means baseline planner requires times
many heuristic evaluations planner. Columns labeled MaD show magnitude
maximum deviation (in coverage ratio) baseline sensitivity study: values
bold exceed threshold, therefore consider significant.

magnitude Floortile domain x = 1.5. Somewhat surprisingly,
domains heuristic evaluations become faster -fluents added. possible
explanation eliminate dominated preconditions (cf. Section 3),
number action preconditions decreases delete-relaxation hypergraph
C
ce becomes graph-like result.
509

fiKeyder, Hoffmann, & Haslum

Domain
Airport (50)
Barman (20)
Blocksworld (35)
Depots (22)
Driverlog (20)
Elevators (20)
Floortile (20)
FreeCell (80)
Grid (5)
Gripper (20)
Logistics00 (28)
Logistics98 (35)
Miconic (150)
Mprime (35)
Mystery (30)
Nomystery (20)
Openstacks (20)
Parcprinter (20)
Parking (20)
Pathways (30)
Pegsol (20)
Pipes-NoTank (50)
Pipes-Tank (50)
PSR (50)
Rovers (40)
Satellite (36)
Scanalyzer (20)
Sokoban (20)
Tidybot (20)
TPP (30)
Transport (20)
Trucks (30)
Visitall (20)
Woodwork (20)
Zenotravel (20)
Total (1126)

Timeouts
x =
1.5 2 2.5 3
1
1
1
1

1.5
15

> 60 sec
x =
2
2.5
20
23

3
26

1

9

3

9

6

16

10

10

12

1

1

3

6

9

10

9

9

16

16

16

16

14

16
3

16
6

16
7

5
9
3

5
11
3

5
13
3

5
13
4

6

1
5
12
2
8

1
5
16
2
9

1
6
17
4
10

96

118

134

148

7

2

13

10

20

9

3

23

4
11

Ratio Median Evaluations/sec
x =
1.5
2
2.5
3
1.08 : 1
1.19 : 1
1.30 : 1
1.26 : 1
1.35 : 1
1.88 : 1
2.42 : 1
3.09 : 1
1.50 : 1
1.60 : 1
1.56 : 1
1.42 : 1
1.65 : 1
1.81 : 1
2.03 : 1
2.31 : 1
1.56 : 1
2.38 : 1
3.17 : 1
4.07 : 1
1.87 : 1
2.92 : 1
3.99 : 1
5.45 : 1
17.67 : 1
8.28 : 1
5.97 : 1
5.49 : 1
1.20 : 1
1.31 : 1
1.39 : 1
1.66 : 1
1.27 : 1
2.55 : 1
3.04 : 1
3.04 : 1
1 : 2.13
1 : 2.04
1 : 2.13
1 : 1.69
1.09 : 1
1 : 1.76
1 : 1.35
1 : 1.22
1.20 : 1
1.64 : 1
2.55 : 1
3.72 : 1
1.06 : 1
1.10 : 1
1.18 : 1
1.27 : 1
1.60 : 1
1.80 : 1
1.60 : 1
1.80 : 1
1.28 : 1
1.35 : 1
1.42 : 1
1.42 : 1
1.43 : 1
2.20 : 1
2.53 : 1
3.26 : 1
1.16 : 1
1.73 : 1
2.49 : 1
3.17 : 1
1 : 8.33
1 : 8.33
1 : 6.25
1 : 1.81
2.32 : 1
3.61 : 1
4.84 : 1
6.20 : 1
1.36 : 1
2.04 : 1
1.01 : 1
1.64 : 1
1.25 : 1
1.08 : 1
1.48 : 1
1.11 : 1
1.41 : 1
1.94 : 1
2.31 : 1
2.78 : 1
1.61 : 1
2.37 : 1
2.42 : 1
3.39 : 1
1:1
1:1
1.02 : 1
1 : 1.05
1.11 : 1
1.43 : 1
1.48 : 1
1.83 : 1
1.14 : 1
1.07 : 1
1 : 1.01 1.30 : 1
1.09 : 1
2.22 : 1
2.42 : 1
2.73 : 1
1.23 : 1
1.38 : 1
1.62 : 1
1.82 : 1
1.48 : 1
2.03 : 1
3.36 : 1
2.22 : 1
1.59 : 1
1.70 : 1
2.38 : 1
2.84 : 1
2.38 : 1
4.04 : 1
6.50 : 1
8.80 : 1
1.62 : 1
2.29 : 1
2.52 : 1
3.30 : 1
1 : 1.49
1 : 1.33
1 : 1.15
1 : 1.07
1 : 2.63
1 : 2.08 3.29 : 1
6.32 : 1
1.09 : 1
1:1
1.06 : 1
1.10 : 1

Table 2: Computational overhead C
ce . first set columns (Timeouts) shows number

tasks C
ce construction finish within 1800 second time limit,
second set (> 60 sec) shows number tasks construction time exceeds 60 seconds
(inclusive first set columns). improve readability, non-zero entries
shown (i.e., blank cells columns zeroes). last set columns shows median
(per domain, commonly solved tasks) ratio heuristic evaluations per second baseline
planner (x = 1) planner (x > 1). entry : 1 means baseline planner
performs times many heuristic evaluations per second planner.

5.3.4 Conditional Effect Merging
majority domains, conditional effect merging slightly increases change
informativeness C
ce -based heuristics. exceptions Logistics00
Gripper domains, merging results heuristic twice informative
(using ratio median number evaluations metric presented Table 1),
Nomystery domain order magnitude informative (for problems
solved heuristics), Barman domain four times less
informative. general, higher informativeness occurs domains tasks
510

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

solved planners, result increased coverage. Indeed, shown
Table 4 below, conditional effect merging proves detrimental overall coverage
C
planner using C
ce -based heuristic: best ce configuration conditional
effect merging solves, total, 4 tasks standard relaxed plan heuristic,
configuration without conditional effect merging solves 20 tasks.
runtime overhead merging procedure quite small, transitive closure
operation required check whether path two nodes BSG
implemented efficiently graph known directed acyclic, case
here. x = 1.5, comparing C
ce -based heuristic conditional effect merging
without, ratio median number heuristic evaluations per second (the
metric used right-hand side Table 2) shows maximal per-domain slow-down
2.04, across-domain average 1.11. Coverage decreases domains
Barman therefore appear due sensitivity search small changes
heuristic function (rather due time taken compute function).
5.3.5 Plan Length C
ce
determine effect using C
ce heuristics plan quality, compare length
plans found C
heuristics

found x = 1, standard delete relaxation
ce
heuristic. plan length measure equivalent plan quality unit-cost setting.
consider median ratio plan length found standard delete relaxation
heuristic found C
ce heuristic, set instances solved
configurations (Table 3). general, observe large differences,
median ratio staying close 1. One notable exception blocksworld domain,
heuristics based C
ce compilation consistently find significantly shorter plans.
C
results ce heuristics ability deduce implicit ordering constraints domain,
avoiding actions lead temporary improvements greedy search later
need reversed, adding plan length. C
ce also leads shorter plans Gripper,
Mprime, Woodworking domains, tends result longer plans Barman
Grid domains.
5.3.6 Comparison State Art
Table 4 shows coverage variety heuristics planners. best configurations
two compilations x > 1 achieve better overall coverage results
standard relaxed plan heuristic. best-performing heuristics obtained C
ce
compilation without conditional effect merging, C compilation, give coverages
1022 1023 respectively. difference coverage baseline
planner greater significance threshold. numbers also far exceed coverage obtained hcea heuristic, fall short 1039 instances solved
dual heuristic approach used LAMA. However, combining LAMA best C
ce -nm
configuration portfolio planner runs LAMA 1500 seconds search
C
ce -nm heuristic 300 seconds results coverage 1063 1115 solvable problems.
Almost difference results C
ce -based heuristics superior performance
Floortile, lesser extent, Airport domains.
511

fiKeyder, Hoffmann, & Haslum

Domain
Airport
Barman
Blocksworld
Depots
Driverlog
Elevators
Floortile
FreeCell
Grid
Gripper
Logistics00
Logistics98
Miconic
Mprime
Mystery
Nomystery
Openstacks
Parcprinter
Parking
Pathways
Pegsol
Pipesworld
Pipesworld
PSR
Rovers
Satellite
Scanalyzer
Sokoban
Tidybot
TPP
Transport
Trucks
Visitall
Woodwork
Zenotravel

x = 1.5
1 : 1.00
1 : 1.11
1.65 : 1
1.08 : 1
1.04 : 1
1 : 1.06
1 : 1.10
1 : 1.02
1 : 1.24
1.04 : 1
1 : 1.14
1.07 : 1
1 : 1.00
1.12 : 1
1 : 1.00
1 : 1.00
1 : 1.02
1 : 1.00
1.26 : 1
1 : 1.01
1 : 1.04
1 : 1.09
1 : 1.12
1 : 1.00
1 : 1.01
1 : 1.00
1 : 1.00
1 : 1.00
1 : 1.06
1 : 1.04
1 : 1.10
1 : 1.00
1.01 : 1
1.21 : 1
1 : 1.00

x
1
1
1.68
1.03
1
1
1
1
1
1.16
1
1.05
1
1.17
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1.21
1

=
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:

2
1.00
1.12
1
1
1.00
1.05
1.15
1.03
1.17
1
1.13
1
1.00
1
1.00
1.02
1.02
1.00
1.01
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.00
1.03
1.19
1.02
1.16
1.00
1.00
1
1.00

x = 2.5
1 : 1.00
1 : 1.23
1.69 : 1
1.04 : 1
1 : 1.00
1 : 1.05
1 : 1.05
1 : 1.04
1 : 1.17
1.31 : 1
1 : 1.13
1.05 : 1
1 : 1.00
1.12 : 1
1 : 1.00
1 : 1.02
1 : 1.02
1 : 1.00
1.04 : 1
1 : 1.01
1 : 1.03
1 : 1.17
1 : 1.04
1 : 1.00
1.01 : 1
1 : 1.00
1 : 1.00
1.01 : 1
1 : 1.16
1 : 1.00
1 : 1.06
1 : 1.00
1 : 1.04
1.21 : 1
1 : 1.00

x
1
1
1.64
1.06
1
1
1
1
1
1.31
1
1.06
1.01
1.17
1
1
1
1.04
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1.21
1

=
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:
:

3
1.00
1.32
1
1
1.00
1.12
1.03
1.06
1.17
1
1.12
1
1
1
1.00
1.02
1.01
1
1.00
1.02
1.02
1.14
1.06
1.00
1.00
1.01
1.00
1.03
1.13
1.00
1.13
1.00
1.08
1
1.00

Table 3: Median ratio length plans found x = 1, length plans found C
ce
different values x, instances solved planners. entry : 1 means
baselines plans times longer planner. conditional effect merging
used.

5.3.7 C vs. C
ce
Given fixed number -fluents, difference size C C
ce
compilations exponential worst case. Mutex pruning, however, mitigate much
growth C . Consider, example, action C
ce compilation n
different conditional effects. mutexes considered, one would expect number
action representatives generated set -fluents C 2n . If, however,
n -fluents generating conditional effects shown mutex
one another, number action representatives generated C also n.
found experiments effect leads much slower growth C
might expected. Consider Figure 2. point graph represents
512

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Domain
Airport (50)
Barman (20)
Blocksworld (35)
Depots (22)
Driverlog (20)
Elevators (20)
Floortile (20)
FreeCell (80)
Grid (5)
Gripper (20)
Logistics00 (28)
Logistics98 (35)
Miconic (150)
Mprime (35)
Mystery (30)
Nomystery (20)
Openstacks (20)
Parcprinter (20)
Parking (20)
Pathways (30)
Pegsol (20)
Pipes-NoTank (50)
Pipes-Tank (50)
PSR (50)
Rovers (40)
Satellite (36)
Scanalyzer (20)
Sokoban (20)
Tidybot (20)
TPP (30)
Transport (20)
Trucks (30)
Visitall (20)
Woodwork (20)
Zenotravel (20)
Total (1126)

x=1
36
13
35
19
20
19
6
79
5
20
28
34
150
35
16
9
20
16
20
30
20
42
38
50
40
35
18
19
16
30
11
14
19
20
20
1002

MaD
+2

+5

+0

+1

+0

+3

+0

+2

+0

+0

+0

+1

+0

+0

+0

+2

+0

+7

+1

+2

+0

+1

+4

+0

+0

+1

+1

+1

+3

+0

+1

+0

+1

+0

+1

+
19

C
ce
37
14
35
22
20
19
20
80
4
20
28
35
150
35
18
9
20
9
12
24
20
42
41
50
40
36
19
18
14
30
11
16
18
20
20
1006

Coverage
C
-nm
C
ce
36
38
19
18
35
35
21
21
20
20
20
19
20
20
80
79
5
5
20
20
28
28
35
35
150
150
35
35
19
19
7
11
20
20
5
10
18
15
29
29
20
20
42
42
41
40
50
50
40
40
36
36
20
20
17
17
14
16
30
30
15
11
15
16
20
18
20
20
20
20
1022
1023

hFF
34
20
35
18
20
19
6
79
5
20
28
33
150
35
16
10
20
20
20
30
20
43
39
50
40
36
18
19
14
30
11
19
3
20
20
1000

hcea
42
0
35
18
20
20
6
79
5
20
28
35
150
35
19
7
19
12
20
28
20
40
32
50
40
36
20
3
16
29
17
15
3
8
20
947

LAMA
31
20
35
21
20
20
5
79
5
20
28
35
150
35
19
13
20
20
20
30
20
44
43
50
40
36
20
19
17
30
19
15
20
20
20
1039

PF
36
20
35
22
20
20
20
79
5
20
28
35
150
35
19
13
20
20
20
30
20
44
44
50
40
36
20
19
17
30
19
16
20
20
20
1062

Table 4: Comparison state-of-the-art-heuristics satisficing planning. Columns x = 1
MaD Table 1. Column C
ce shows coverage best configuration (in terms overall
coverage) compilation using conditional effect merging (namely x = 1.5, = 60);
C
C
ce -nm best ce configuration without conditional effect merging (which happens use
C
x t); best C configuration x > 1 (which happens use
x t). Entries bold columns difference baseline planner
exceeds threshold significance (given MaD column). Column PF shows coverage
portfolio planner runs LAMA 1500 seconds C
ce 300 seconds.
single problem instance (from instance set before), paired value x.
C
C
ce (x-axis) (y-axis), measure ratio growth |A| growth
|F |, i. e., factor compilation increased size action set encoding
(measured number actions C number conditional effects C
ce ),
divided factor compilation increased number fluents.
513

fiKeyder, Hoffmann, & Haslum

1e+08
Action set growth/uent set growth, C

Action set growth/uent set growth, C

4.5
4
3.5
3
2.5
2
1.5
1
0.5
0

0

0.5

1

1.5

2

2.5

3

3.5

4

4.5

Action set growth/uent set growth, Cce

1e+07
1e+06
100000
10000
1000
100
10
1

0

50

100

150

200

250

300

350

Action set growth/uent set growth, Cce

(a)

(b)

Figure 2: Growth problem size ratio growth |A| growth |F |, (a) without
(b) mutex pruning. point corresponds single instance value x. f (x) = x also
shown reference.

words, assess growth encoding number conjunctions |C|,
theory worst-case exponential C linear C
ce .
mutex pruning used (Figure 2 (b)), growth C rapid
ratio quickly increases millions; mutex pruning (Figure 2 (a)), growth C
still faster C
ce , difference much smaller.
5.3.8 Finding Plans Search
growth time limit imposed construction C C
ce tasks,
Algorithm 1 used complete planning algorithm. competitive
heuristic search methods, nevertheless interesting observe performance details
algorithm various domains. coverage obtained algorithm using
C C
ce compilations, well statistics growth compiled
C
tasks, shown Table 5. difference C
ce much visible here,
since number -fluents added is, general, much larger growth-bounded
constructions used heuristic computation. C
ce able rapidly add much
larger number -fluents, therefore find relaxed plans solutions
C
original planning task well. Overall, C
ce solves 568 tasks compared 404 ,
solves equal greater number tasks except 4 domains.
Considering individual domains, seen C C
ce able solve
almost tasks certain domains Logistics00, Mprime, Mystery, Parcprinter,
PSR, Woodworking. domains, even addition small amount
information sufficient obtain relaxed plans plans original task,
maximum x values required solve tasks quite low. case Mprime,
Mystery, Woodworking domains, maximum required x values 4.07, 4.62,
1.35, respectively. others Elevators, Openstacks, Transport, Visitall,
even smallest tasks quite large many different plans possible,
possible introduce enough -fluents disqualify possible relaxed plans
constitute real plans, tasks solved.
514

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Domain
Airport (50)
Barman-sat (20)
Blocksworld (35)
Depots (22)
Driverlog (20)
Elevators-sat11 (20)
Floortile-sat11 (20)
FreeCell (80)
Grid (5)
Gripper (20)
Logistics00 (28)
Logistics98 (35)
Miconic (150)
Mprime (35)
Mystery (30)
Nomystery-sat11 (20)
Openstacks-sat11 (20)
Parcprinter-sat11 (20)
Parking-sat11 (20)
Pathways-noneg (30)
Pegsol-sat11 (20)
Pipes-NoTank (50)
Pipes-Tank (50)
PSR (50)
Rovers (40)
Satellite (36)
Scanalyzer-sat11 (20)
Sokoban-sat11 (20)
Tidybot-sat11 (20)
TPP (30)
Transport-sat11 (20)
Trucks (30)
Visitall-sat11 (20)
Woodwork-sat11 (20)
Zenotravel (20)
Total (1126)

Cov.
34
0
33
16
15
0
4
1
4
16
27
24
106
35
19
5
0
20
0
5
19
10
9
50
21
15
9
0
1
20
0
15
0
20
15
568

Min
1.00
1.21
1.82
1.00
31.47
91.41
1.29
5.37
1.27
1.22
1.20
1.02
1.02
16.72
3.66
1.77
69.36
3.51
2.69
1.03
1.35
4.22
1.90
22.42
1.17
5.54
1.00
1.00

C
ce
Max
44.50
141.79
90.93
37.11
216.18
91.41
22.53
208.75
91.10
41.16
175.11
4.07
4.62
59.80
76.04
51.72
707.06
187.41
94.33
77.38
459.66
43.61
47.75
22.42
43.12
21.36
1.35
92.26

C
Med
2.31
11.44
8.48
8.92
112.50
91.41
1.41
67.69
6.79
31.14
55.01
1.15
1.25
41.14
9.95
7.26
137.98
11.60
13.46
7.29
7.40
19.16
13.93
22.42
13.75
13.56
1.24
7.25

Cov.
31
0
30
14
14
0
9
2
4
6
27
21
36
35
19
3
0
9
0
3
0
5
8
49
14
7
10
1
0
7
0
8
0
20
12
404

Min
1.00
1.21
1.82
1.00
48.92
212.24
1.31
6.77
1.27
1.22
1.20
1.02
1.02
21.91
1.60
2.32
12.61
2.56
1.05
1.70
5.22
2.38
2.89
1.17
6.32
1.00
1.00

Max
168.45
400.94
221.41
74.97
633.11
272.12
41.22
501.28
585.53
149.91
2706.86
13.22
8.34
43.50
276.81
203.41
738.88
110.51
1052.26
645.00
399.10
161.42
2.89
560.95
100.15
1.40
191.54

Med
3.56
15.49
12.45
9.96
107.21
242.18
1.54
76.12
14.11
5.80
54.47
1.14
1.20
33.27
88.23
89.79
242.54
11.71
16.04
26.04
22.09
44.21
2.89
11.27
41.05
1.25
11.14

Table 5: Solving planning tasks search. Table shows Coverage C C
ce compilations, Minimum, Maximum, Median values x solved tasks.

6. Heuristics Optimal Planning
consider admissible heuristics, optimal planning. Section 6.1 considers
LM-cut heuristic, showing certain complications make difficult
obtain improved heuristic estimates C C
ce . Section 6.2, consider
alternative method lower-bound h+ , namely admissible cost-partitioning heuristics based
conjunctive landmarks obtained C
ce . detail choose C
setting, present experimental results Section 6.3.
515

fiKeyder, Hoffmann, & Haslum

a1


a2
a3

g2

aC
3

g1

g1


a1
a2
a3

g2

aC
2

0

g3

g3
(a)

0

{g1 ,g2 ,g3 }
aC
1

0

(b)

Figure 3: LM-cut , C compilation, Example 3.
6.1 LM-cut
state-of-the-art admissible approximation h+ computed LM-cut algorithm
(Helmert & Domshlak, 2009). logical approach obtaining admissible heuristics
C C
ce therefore apply LM-cut compilations. Unfortunately, turns
several serious obstacles this. discussing issues, first give
brief description LM-cut algorithm, present simpler case C
compilation, additional complication conditional effects present.
LM-cut computed planning task deletes, simple transformation first applied replaces goal set G single goal achieved
goal-achievement action whose precondition set G, adds dummy precondition actions whose precondition set empty. LM-cut initializes hLM-cut := 0
and, repeats following steps hmax (G) becomes 0: (1) Compute hmax ; (2) apply
precondition choice function (PCF) action precondition pre(a) removes
pre(a) one fluents p pre(a) hmax (p) maximal; (3) construct
justification graph whose vertices fluents whose arcs precondition/effect
pairs according PCF; (4) find cut L initial state goal
justification graph, given set actions enters goal zone, i. e., set
fluents goal reached 0 cost; (5) add costmin := minaL cost(a)
heuristic value hLM-cut , reduce cost L costmin . proved
Helmert Domshlak (2009), algorithm two fundamental properties, namely (i)
admissibility, hLM-cut h+ , (ii) domination hmax , hmax hLM-cut .
would expected heuristic obtained manner C would
strictly informative obtained original planning task ,
turns case. Indeed, heuristic become strictly less informative:
Example 3 Let = hF, A, I, Gi given F = {g1 , g2 , g3 }, = {a1 , a2 , a3 },
ai = h, {gi }, , i, = , G = {g1 , g2 , g3 } (Figure 3). words, three goals,
achievable single action. Valid plans apply action
order, make goals true. cuts found LM-cut algorithm task
{a1 }, {a2 }, {a3 }, regardless PCFs chosen, LM-cut algorithm therefore
always computes optimal cost 3. Consider C compilation results
set C = {{g1 , g2 , g3 }}. F C contains single -fluent {g1 ,g2 ,g3 } , representative
0
0
action aC
constructed sole non-empty subset C = {{g1 , g2 , g3 }} C.
first cut found LM-cut contains three representatives, adds
expensive goal {g1 ,g2 ,g3 } . possible PCFs, next cut last,
final heuristic estimate 2 two cuts found. If, example,
516

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

0

0

C
precondition choice function chooses g1 hmax justifier aC
2 a3 , g2
0
max
C
h
justifier a1 , cut {a1 , a2 }. cut, goal reached 0 cost
{{g ,g ,g }}
via a1 , a2 , a3 1 2 3 , hmax 0 LM-cut stops.

+
C
Note (similarly h+ (C
ce ), cf. Theorem 2) possible either h ( )
hmax (C ) decrease addition -fluents, example hmax
cost task actually increases (from 1 2) addition -fluent {g1 ,g2 ,g3 } .
However, type interactions introduced difficult LM-cut algorithm
reason about, resulting worse admissible bounds practice. LM-cut course continues dominate hmax , proving sufficient number -fluents added, LM-cut
eventually tend towards optimal cost task.

weakness pointed Example 3 inherited application LM-cut
algorithm C
ce compilation. Furthermore, application involves additional complication proves formidable: LM-cut defined conditional effects, therefore
cannot directly applied C
ce task. turns two straightforward
adaptations algorithm problems conditional effects, neither preserves
properties (i) admissibility (ii) domination hmax .
see (ii) stake, consider planning task single action
two conditional effects ce(a)1 = h{p}, {q}, ce(a)2 = h{q}, {r}, i, initial state
{p}, goal {r}. h+ () = hmax () = 2 due critical path ha, ai,
justification graph considered LM-cut consists sequence. first cut found
{a}. cost reduced, remaining task hmax cost 0, resulting
cost estimate hLM-cut = 1.
issue different conditional effects action may part
critical path. natural approach therefore reduce costs per individual conditional
effect, rather effects action once. Unfortunately, turns
preserve admissibility (i). Indeed, detail Example 4 (Appendix A),
exist STRIPS tasks whose C
ce compilations following property:
exists action reducing cost globally first encountered cut
leads heuristic estimate less hmax (C
ce ), treating effects
+
C
separately leads estimate greater h (ce ) = h ().
therefore simple strategy dealing conditional effects preserves
(i) (ii) planning tasks. Since admissibility cannot sacrificed, must
reduce costs globally give dominating hmax . particular implication
1
C

so, despite Theorem 5 shows hmax (C
ce ) = h (ce ) converges h (),
convergence guaranteed hLM-cut (C
ce ). could course fixed using
max(hmax , hLM-cut ) heuristic value, yet hmax typically informative,
strategy useful practice.
detail Section 6.3 below, IPC benchmarks, using LM-cut computed either C C
ce often results larger search spaces -fluents introduced. cases, overall performance worse hLM-cut (C ) hLM-cut (C
ce )
hLM-cut (). remains open question whether improved.
517

fiKeyder, Hoffmann, & Haslum

6.2 C
ce Landmarks
Landmarks planning tasks formulas set fluents F property made true state execution valid plan.
problem checking whether even single fluent landmark planning task
PSPACE-complete, approaches finding landmarks past focused
delete relaxation, setting whether fluent landmark checked
polynomial time. recently shown maximum fixpoint solution
set simple recursive equations defines complete set single fact delete-relaxation
landmarks, words landmark formulas consist single literal
= p (Keyder et al., 2010). solution computed algorithm repeatedly updates set landmarks fluent action planning task,
convergence. method naturally handle conditional effects treating
independent actions, described Section 5.1.
also shown equations applied AND/OR graph
structure, necessarily corresponding delete relaxation planning task.
insight used obtain landmarks task. Single -fluent landmarks
correspond conjunctive landmarks necessarily landmarks
delete relaxation + . approach suffers, however, large number -fluents
considered , rendering landmark generation impractical compilations larger tasks. aim take advantage flexibility C
ce compilation
obtain non-delete-relaxation landmarks original task, considering
focused set -fluents given size m. before, allow us
consider larger conjunctions keeping size delete relaxation task low.
using C
ce landmark finding, focus technique keep overhead
bay, choose set conjunctions C guarantee every -fluent landmark
C
ce (and therefore original planning task). accomplished extracting
landmark graph sets landmarks simultaneously achieved :
Definition 7 (Simultaneously achieved landmarks) set landmarks Ls = {1 ,
. . . , n } simultaneously achieved Lc = 1 ... n landmark .
Maximal sets simultanously achieved landmarks easily extracted set
landmarks orderings. Given initial set landmarks L set orderings,
following sets sets simultaneously achieved landmarks:
LG = {{ | G |= }}
Lnec = {{ | nec } | L}
Lgn = {{ | gn } | L}
LG contains single set made landmarks L entailed G. Since
valid plan must make goals true final state, necessarily simultaneously
achieved. Given landmark , Lnec contains set elements landmarks ordered necessarily . Due definition necessary orderings,
must simultaneously true every state immediately precedes state
becomes true. Lgn similar set, yet since greedy necessary orderings
518

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

weaker necessary orderings, sometimes contain sets appear Lnec ,
therefore result larger overall set conjunctive landmarks. Note necessary orderings also greedy necessary orderings, conjunctive landmark
results set necessary orderings therefore subset conjunctive landmark
results greedy necessary orderings. include conjunctive landmarks result
necessary orderings result stronger necessary orderings added
conjunctive landmark . Landmark heuristics sometimes infer
conjunctive landmarks must reachieved landmark ordered necessarily
reachieved. case conjunctive landmarks derived
greedy-necessary orderings, need achieved make landmarks
ordered true first time.
Algorithm 2: Choosing C landmark generation.
C=
L = FindLandmarks(C
ce )
repeat
C = C SimultaneouslyAchieved(L)
L = FindLandmarks(C
ce )
SimultaneouslyAchieved(L) C

strategy choosing C landmark generation shown Algorithm 2.
new conjunctive landmarks L = p1 pn discovered, corresponding fluents
{p1 ,...,pn } added C
ce landmark computation step repeated. Note
process may go several iterations, run fixpoint reached,
addition new -fluents C
ce task result discovery new landmarks.
process terminates new conjunctive landmarks discovered already
exist -fluents C
ce . note method choosing C desired
C
property mentioned above: -fluents introduced C
ce represent fact landmarks ce
conjunctive landmarks original task .
strategy works especially well domains many landmarks several landmarks necessarily greedy necessarily ordered them. One domain
occurs Blocksworld (see illustration Figure 4), method
able find extremely informative conjunctive landmarks allow optimally solve
tasks heuristic tested.
6.3 Experiments
consider performance LM-cut heuristic hLM-cut C C
ce compilations, admissible landmark cost-partitioning heuristic hLM introduced
Karpas Domshlak (2009) different landmark generation schemes, including
LM-cut used search algorithm, hLM
landmarks obtained C
ce . h

use LM-A , variant effective known fluent landmarks
(Karpas & Domshlak, 2009). benchmarks, computers, time/memory limits
used Section 5.3.
519

fiKeyder, Hoffmann, & Haslum

Informativeness
Coverage
Domain
C , 1.5
C
,
1.5
Orig.
x
=
1
C , 1.5 C
ce
ce , 1.5
Airport
1 : 49.02
1 : 52.91
28
28
19
18
Barman-opt
1 : 1.06
1 : 1.12
4
4
4
4
Blocksworld
4.22 : 1
1 : 1.71
28
28
28
27
Depots
1 : 1.96
1 : 6.49
7
5
4
4
Driverlog
1 : 23.7
1 : 48.31
13
13
10
10
Elevators-opt11
1.65 : 1
1 : 1.03
18
18
16
15
Floortile-opt11
19.23 : 1
13.93 : 1
7
6
12
12
FreeCell
1.07 : 1
1 : 2.12
15
15
13
9
Grid
3.47 : 1
1 : 1.35
2
2
2
1
Gripper
1:1
1:1
7
7
6
6
Logistics00
1 : 9.38
1 : 10.47
20
20
16
15
Logistics98
1 : 7.69
1 : 18.87
6
6
2
3
Miconic
1 : 232.55
1 : 769.23 141 141
50
45
Mprime
13.08 : 1
1 : 1.13
22
22
28
22
Mystery
1.03 : 1
1.07 : 1
16
16
17
17
Nomystery-opt11
1 : 126.58
1 : 588.24
14
14
8
8
Openstacks-opt11
1:1
1:1
14
14
14
14
Parcprinter-opt11
1 : 1.14
1 : 4.23
13
13
13
12
Parking-opt11
2
1
1
0
Pathways-noneg
1 : 15.72
1 : 51.81
5
5
4
4
Pegsol-opt11
1.08 : 1
1.08 : 1
17
17
17
17
Pipes-NoTank
1 : 1.48
1 : 2.09
17
17
15
14
Pipes-Tank
1 : 1.30
1 : 2.25
11
10
8
7
PSR
1.04 : 1
1 : 1.03
49
49
49
49
Rovers
1 : 1.72
1 : 3.56
7
7
7
6
Satellite
1 : 3.77
1 : 33.33
7
7
6
6
Scanalyzer-opt11
1 : 1.36
1 : 1.06
11
11
4
5
Sokoban-opt11
1 : 1.28
1 : 1.31
20
20
20
20
Tidybot-opt11
1 : 4.79
1 : 13.19
13
13
7
6
TPP
1 : 5.14
1 : 1.70
6
6
6
6
Transport-opt11
1 : 1.87
1.35 : 1
6
6
6
7
Trucks
1 : 5.94
1 : 10.26
10
10
7
6
Visitall-opt11
1 : 3.86
1 : 3.32
10
10
10
10
Woodwork-opt11
4.07 : 1
1 : 2.36
11
11
7
5
Zenotravel
1 : 39.37
1 : 153.85
12
12
8
8
Total
589 584
444
418
C
Table 6: LM-cut C
ce . two columns left show ratio summed

number heuristic evaluations tasks solved configurations, comparing standard
LM-cut results x = 1 LM-cut computed C C
ce x = 1.5. example,
first entry table, 1 : 49.02, shows LM-cut computed C growth bound
x = 1.5 evaluates, sum commonly solved tasks, nearly 50 times many states LM-cut
computed standard delete relaxation. last 4 columns show coverage. Column Original
shows results obtained Fast Downwards implementation LM-cut (which applies
standard delete relaxation), column x = 1 shows results implementation LMcut unmodified delete relaxation (with differences two purely due
implementation details). Entries bold indicate highest coverage domain, total.

520

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

clear(a)
gn
clear(b)
handempty
ontable(b)

clear(a)
holding(b)

nat

nat

clear(b)
handempty
on(b, a)
clear(c)
handempty
ontable(c)

clear(b)
clear(d)
gn
on(b, a)
holding(c)
nat ontable(d)
gn

on(b, a)
on(c, b)
on(d, c)

nec

clear(c)
clear(c)
clear(d)
on(b, a) gn handempty
on(c, b)
on(b, a)
holding(d)
on(c, b)
ontable(d)

Figure 4: Landmarks graph found C
ce compilation small Blocksworld task,
blocks initially table G = {on(b, a), on(c, b), on(d, c)}. smaller conjunctive
landmarks single fluent landmarks omitted.

6.3.1 LM-cut C C
ce
evaluate impact using C C
ce compilations LM-cut, constructed
C
C
ce tasks following procedure described Section 5.3, repeatedly
selecting conflicts increase size compiled task reached fixed growth
bound x. Conflict selection based hmax supporters rather hadd supporters,
hmax plays key role computation LM-cut, also resulted better performance.
that, procedure used generate C C
ce tasks same.
C
tested value x set {1.5, 2, 2.5, 3} C
ce . observed
x = 1.5 dominated larger values x domain-by-domain overall basis,
therefore report results two configurations. exception
Mystery domain, C x = 2.5 x = 3 solved 18 tasks compared 17
x = 1.5.
Overall, heuristic computed LM-cut algorithm standard delete relaxation + dominates computed C C
ce , terms informativeness
terms coverage. first two columns Table 6 show large majority
domains, search using LM-cut computed C C
ce performs many heuristic
evaluations tasks solved configurations. Airport domain,
instance, LM-cut standard delete relaxation requires approximately 50 times fewer
heuristic evaluations solve set tasks either C C
ce . domains, situation less extreme, standard delete relaxation continues give
better heuristic estimates. exceptions Blocksworld, Elevators, Floortile,
FreeCell, Grid, Mprime, Mystery, Pegsol, PSR, Transport Woodworking domains,
+
least one C C
ce yields informative heuristic estimates .
impressively, C C
ce give estimates respectively 19 14 times informative estimates obtained + Floortile domain, estimates using
C 13 times informative + Mprime domain. terms
coverage, translates 12 tasks solved C C
ce Floortile domain,
compared 7 standard version LM-cut, 28 tasks solved C
521

fiKeyder, Hoffmann, & Haslum

Mprime domain, compared 22. Mystery domain, coverage increased 1.
domains, coverage achieved C C
ce -based LM-cut less equal
coverage achieved standard LM-cut. Overall, standard version LM-cut
solves 589 planning tasks compared 445 C 418 C
ce . Though large part
difference (90 tasks) comes Miconic domain, difference remaining
domains still significant.
Comparing C C
ce , seen additional loss information resulting
treatment conditional effects LM-cut leads worse heuristic estimates
C
using C
ce . expected theoretical result ce grows linearly
number -fluents, number -fluents added task using
C
C
ce compilation almost always higher using . However treatment
conditional effects LM-cut (described above) turns greatly degrade performance,
C
LM-cut using C
ce informative LM-cut using 4 domains.
6.3.2 Admissible Landmark Heuristics C
ce Landmarks
admissible landmark heuristic, hLM , uses action cost partitioning derive heuristic
values collection (ordered) landmarks, distributing cost action
set landmarks achieves (Karpas & Domshlak, 2009). Cost partitioning done
different ways: optimal cost partitioning tractable, yields best possible heuristic
value given set landmarks, practice slow coverage suffers; uniform
partitioning generally achieves better time/informativeness trade-off, therefore better
coverage.
evaluate potential informativeness landmarks obtained C
ce using
iterative technique described Section 6.2, used landmarks optimal cost
partitioning setting, since setting makes best possible use information present
given landmarks. compared informativeness heuristic using
landmarks obtained compilation = 1 = 2 sound
complete landmark generation algorithm (Keyder et al., 2010). results shown
first two columns Table 7. show ratio total number heuristic evaluations,
per domain, tasks solved configurations, hLM using landmarks 1
heuristic using landmarks 2 C
ce , respectively. Note landmarks
2 compilations contain landmarks obtained 1
generated C


ce
subset, hLM optimal partitioning 2 C
ce landmarks therefore
dominates hLM optimal partitioning 1 landmarks. Hence ratio always
greater 1.
9 35 domains considered, neither addition 2 landmarks C
ce landmarks leads informative heuristic (cases columns show value 1).
remaining 26 domains, schemes improve 1 landmarks equal degree
7, 2 improves 1 greater degree C
ce 17. one case, Blocksworld,
C
landmarks

much

informative

landmarks
found methce
ods, improve informativeness baseline heuristic using 1 landmarks
factor 122.
Uniform cost partitioning divides cost action evenly set landmarks
achieves, rather searching partitioning maximizes heuristic value
522

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Domain

Airport
Barman-opt
Blocksworld
Depots
Driverlog
Elevators-opt11
Floortile-opt11
FreeCell
Grid
Gripper
Logistics00
Logistics98
Miconic
Mprime
Mystery
Nomystery-opt11
Openstacks-opt11
Parcprinter-opt11
Parking-opt11
Pathways-noneg
Pegsol-opt11
Pipes-NoTank
Pipes-Tank
PSR
Rovers
Satellite
Scanalyzer-opt11
Sokoban-opt11
Tidybot-opt11
TPP
Transport-opt11
Trucks
Visitall-opt11
Woodwork-opt11
Zenotravel
Total

Informativeness
Coverage
(optimal partitioning) (uniform partitioning)
2
C
1
2
C
ce
ce
1.03
1.03
27
11
27
4
4
4
25.65
122.31
26
28
32
4.28
1.11
7
7
7
1.02
1.01
10
9
9
1.54
1.54
12
12
12
3.28
1.02
2
2
2
1.32
1.01
60
38
39
1.12
1.12
2
2
2
1
1
7
6
7
13.65
13.65
20
22
22
1.25
1.25
3
3
3
3.91
3.91
142
142
143
1.39
1
20
20
20
2.17
1
15
15
15
3.08
1.69
20
20
18
1
1
12
7
11
4.09
1
10
8
10
9.84
1
3
0
0
1
1
4
4
4
1.25
1
17
15
17
1.37
1.27
16
16
16
1.64
1.13
13
10
11
2.68
1.23
49
49
49
1
1
6
6
5
1.06
1.06
6
6
6
1.54
1.01
6
3
6
1.02
1
20
14
18
1.18
1.05
14
9
14
1
1
6
6
6
1
1
6
6
6
1
1
8
6
7
1
1
16
9
9
3.04
1.16
7
4
5
1
1
8
8
8
604
527
570

Table 7: hLM landmarks generated delete relaxation (1 ), 2 (Keyder et al., 2010)
C
ce . two columns left show ratio summed number heuristic evaluations
tasks solved configurations, comparing 2 C
ce baseline using landmarks
1 . Using optimal cost partitioning hLM , landmarks yield better lower bounds,
indeed ratios 1 (which use : 1 presentation, differently
previous tables). right-most three columns show coverage, using uniform cost partitioning.
heuristic uniform partitioning solves tasks optimal cost partitioning
landmark generation schemes considered. Entries bold indicate best results, per domain
total.

523

fiKeyder, Hoffmann, & Haslum

state. make hLM heuristic weaker, though typically much,
also makes much faster compute, leading better coverage general. confirmed
uniform cost partitioning results higher coverage optimal cost partitioning
domains three landmark generation schemes considered.
three right-most columns Table 7 show coverage achieved hLM
three landmark generation schemes setting. seen using 1 landmarks results greater coverage combining either 2 C
ce landmarks.
2
C
Compared heuristic using landmarks, using ce landmarks solve many
tasks every domain except Nomystery Rovers domains. C
ce landmarks outperform 1 landmarks two domains: Blocksworld, using C
landmarks
planner
ce
finds optimal solutions 32 35 tasks, tested heuristic,
Miconic, 1 instance. domains, use C
ce landmarks either
1
effect worsens coverage compared . Interestingly, informativeness
LM-cut heuristic increases greatly C C
ce compilations Floortile domain, corresponding increase compilations used find landmarks.
conjunctive landmarks, besides goal, found.

7. Conclusions Open Questions
long tradition works attempting devise heuristics taking account
delete effects. However, techniques rendering h+ perfect limit thus allowing
smoothly interpolate h+ h proposed quite recently,
Haslum (2012) Katz et al. (2013) respectively. extended Haslums approach
introducing new compilation method linear (vs. worst-case exponential) growth,
demonstrated machinery needed using approach generate heuristics.
evaluation shows that, domains, informedness dramatically improved
small cost terms computational overhead.
main open issue lies use words domains here.
domains, gain informativeness small, domains overall performance
suffers dramatically. domain-independent planning technique work well
every domain, simple portfolio approach (cf. column PF Table 4) suffices
improve state art satisficing planning, extent per-domain performance variation technique dramatic. obtain understanding
causes phenomena, ultimately exploit understanding devise reliable/effective practical methods? unchanged worse performance many domains
due fundamental limitations technique, due particular instantiation
(especially selection -fluents) run experiments?
practical perspective, answering questions comes exploration
techniques predicting impact adding -fluents, making informed
decisions -fluents add. observed changes domain formulation, random reorderings, small changes heuristic criteria used -fluent
selection large impact heuristic informativeness coverage. research formulate new heuristic criteria improve existing ones therefore could,
potentially, provide better performance across wide range domains. might also in524

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

teresting systematically explore impact random/arbitrary changes, attempt
building complementary-strength compilations combined effective portfolios.
theoretical perspective, currently approaching questions
terms analyzing conditions small (polynomial-size) set -fluents
suffices render h+ perfect. Applied individual domains, analysis offers way
answering question whether lack performance improvement due
essential limitation due choosing wrong set -fluents. hope
eventually obtain syntactic criteria (e. g., based causal graph structure)
automatically applied arbitrary planning task descriptions, serving select -fluents
(or exclude subsets -fluents consideration) targeted manner. first
results direction already published HSDIP14 (Hoffmann, Steinmetz,
& Haslum, 2014).
observations optimal planning pose many questions future work. simple one
whether effective C
ce landmarks could extracted restricting techniques
adding -fluents guaranteed landmarks. daunting challenges regard
LM-cut. observations suggest methods use suffer greatly suboptimal
choices precondition choice functions (PCFs). would therefore worthwhile investigate new methods obtaining better PCFs. Another important direction develop
extensions LM-cut conditional effects guarantee admissibility domination hmax . simple yet impractical method multiply conditional effects
(enumerating subsets thereof). sophisticated method based context splitting, distinctions different occurences action introduced
targeted manner necessary, recently proposed (Roger, Pommerening,
& Helmert, 2014).
summary, explicitly represented conjunctions clearly exhibit potential dramatically improve delete relaxation heuristics. much remains done order
understand use effectively.

Acknowledgments
Part work leading publication carried Emil Keyder Jorg
Hoffmann working INRIA Grand Est, Nancy, France. NICTA funded
Australian Government Department Communications Australian
Research Council ICT Centre Excellence Program. thank University
Freiburg allowing us use computional resources.

Appendix A. Proofs
Theorem 3 (h+ (C ) dominates h+ (C
ce )) Given planning task set con+
C
+
C
junctions C, h ( ) h (ce ). cases inequality strict.
Proof: follows fact plan C also plan C
ce , yet
Cn plan C .
1
inverse case. show first part, let = haC
,
.
.
.
,

n
1
show sequence actions constitutes plan C
ce , showing
Cn ] C [aC , . . . , aC ] , I[. . . ]
1
induction C [aC
,
.
.
.
,

denotes
result
ce
n
n ce
1
1
525

fiKeyder, Hoffmann, & Haslum

applying sequence actions initial state C C
ce . Since goal tasks
defined GC , shows desired result. base case, initial state
C
C C
ce , subset relation holds. inductive case, assume
Ci1
C1
C
C
C
C
C
[a1 , . . . , ai1 ] [aC
1 , . . . , ai1 ]ce . Since precondition ai ce subset
C
C
C C
C

precondition aC
Ci , ai applied [a1 , . . . , ai1 ]ce
C

induction hypothesis. need show fluents added aC
also
Ci
C
C C
C
C
added aC
ce applied [a1 , . . . , ai1 ]ce . add effect ai consists
C
union two sets, (add(a) (pre(a) \ del(a))) , also add effect aC

Ci
C
0
C
0
ce therefore added, {c | c Ci }. Since ai applicable ,

Ci1
1
preconditions (pre(a) c0 Ci (c0 \add(a)))C must true C [aC
1 , . . . , ai1 ], therefore
C
0
C [aC
1 , . . . , ai1 ]ce , induction hypothesis. c C (and therefore c Ci , Ci
C
C
C), aC
ce conditional effect effect c condition (pre(a) (c \ add(a))) ,
Ci
C
applies condition subset precondition ai . shows
desired property.
strictness, consider planning task fluent set F = {p1 , p2 , r, g1 , g2 }, initial
state = {p1 }, goal G = {g1 , g2 }, actions
ap2 : h{p1 }, {p2 }, {r, p1 }, ar : h, {r}, ,
ag1 : h{p1 , r}, {g1 }, , ag2 : h{p2 , r}, {g2 }, ,
Let C = {c F | |c| = 2}. optimal plan C sequence
har , ag1 , ap2 , ar , ag2 i. case C follows fact plan must include
ag1 ag2 actions achieving two goals, therefore must achieve
precondition -fluents {p1 ,r} {p2 ,r} , respectively. -fluents
achieved ar , action achieves either p fluents without deleting
r. single representative ar achieves {p1 ,r} {p2 ,r} ,
representative would precondition {p1 ,p2 } , unreachable, since
action achieving p2 deletes p1 . plan C therefore must contain ag1 , ag2 , least two
instances ar , ap2 .
longer holds, however, considering C
ce , action sequence
hap2 , ar , ag1 , ag2 plan contains 4 actions. C
ce , two possible -fluents
added ar , {p1 ,r} {p2 ,r} , treated independently, separate conditional effect
created each, conditions p1 p2 respectively. p1 p2
achieved separately, single application action ar sufficient achieve
two -fluents, without making true (unreachable) cross-context -fluent {p1 ,p2 } .
similar cases, exist plans C
ce shorter minimum length plans
C .
Given STRIPS task = hF, A, I, G, costi, h1 heuristic set P fluents,
defined follows (Bonet & Geffner, 2001):

0
p
1
h (p) =
min{a|padd(a)} h1 (pre(a)) + cost(a) otherwise
h1 (P ) = max h1 (p)
pP

526

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

value heuristic given planning task taken h1 cost goal
G, h1 () = h1 (G).
Lemma 1 Given planning task C = {c P(F ) | 1 < |c| m}, h1 (C ) = h1 (m ).
Proof: Let = hF, A, I, Gi. C identical except action sets.
denote action set AC (m ) C AC (C ). deletes
conditional effects either AC (m ) AC (C ), ignore
follows.
first show h1 (C ) h1 (m ), h1 (m ) h1 (C ). direction
based following two observations. First, STRIPS planning task,
split actions singleton add effects, without affecting h1 . Precisely, given
action p add(a) \ pre(a), denote a[p] action pre(a[p]) = pre(a)
add(a[p]) = {p}. Replacing split-up actions a[p] (i. e. generating
split-up action a[p] every non-redundant add effect a), h1 remains same. Second,
say every split-up action a[p] action set dominated action a0 action set
A0 , i. e., pre(a0 ) pre(a[p]) add(a0 ) add(a[p]). h1 using A0 lower bound
h1 using A.
prove h1 (C ) h1 (m ). every c F 1 < |c| m,
del(a) c = , add(a) c 6= , AC (m ) contains action ac given pre(ac ) =
(pre(a) (c \ add(a)))C , add(ac ) = add(a) {c0 | c0 C c0 (add(a) c)}. Let
0
p add(ac ). p add(a), aC C 0 = dominates ac [p]. Say p = c0
c0 6 pre(ac ). obtain dominating action AC (C ), define:
C 0 := {c00 C | del(a) c00 = , add(a) c00 6= , c00 c0 }
C 0 C, c00 C 0 conditions (1) del(a) c00 = add(a) c00 6=
(2) c C : ((c c00 add(a) c 6= ) = c C 0 ) Definition 2
obviously satisfied.
0
0
Thus AC (C ) contains action aC given pre(aC ) = (pre(a) c00 C 0 (c00 \ add(a)))C
0
add(aC ) = (add(a) (pre(a) \ del(a)))C {c00 | c00 C 0 }. prove (a)
0
0
pre(aC ) pre(ac ) (b) p = c0 add(aC ).
Regarding (a), every c00 C 0

c00 \ add(a) c0 \ add(a) c \ add(a), thus c00 C 0 (c00 \ add(a)) c0 \ add(a) c \ add(a).
Regarding (b), need prove c0 C, del(a)c0 = , add(a)c0 6= , c0 c0 .
first last properties obvious, second one direct construction.
third one, add(a) c0 6= , true otherwise would c0
c \ add(a) implying contradiction construction c0 pre(ac ).
remains prove h1 (m ) h1 (C ). every C 0 C conditions
0
0
(1) (2) stated above, AC (C ) contains action aC . Let p add(aC ). p
-fluent, either p add(a) p pre(a) \ del(a). latter case irrelevant (and
0
split-up action generated); former case, setting c := add(a) get aC [p]
dominated ac AC (m ). Say p = c . least one following cases
must hold: (a) c C 0 (b) c (pre(a) \ del(a)) (c) c (add(a) (pre(a) \ del(a)))
c add(a) 6= . case (a), follows directly definition ac AC (m )
0
0
dominates aC [p]. case (b), p = c pre(aC ) case irrelevant. case (c),
0
c add(a) 6= c del(a) = ac AC (m ) dominates aC [p].
concludes proof.
527

fiKeyder, Hoffmann, & Haslum

Lemma 2 Given planning task set non-unit conjunctions C, h1 (C )
h+ (C
ce ).
C
Proof: Consider planning task C
no-cc identical except
include cross-context preconditions. is, precondition action representative
0
aC modified following:

0

pre(aC ) = pre(a)C

[

(pre(a) (c0 \ add(a)))C

c0 C 0

1
C
+
C
show (A) h1 (C ) h1 (C
no-cc ), (B) h (no-cc ) h (ce ).

first prove (A). proof Lemma 1, suffices prove that, every split0
C
action aC [p] C
no-cc , exists dominating action . p -fluent,
00
0
aC C C 00 = dominates aC [p]. Otherwise, say p = c0 . least one
following cases must hold: (a) c0 C 0 (b) c0 (add(a) (pre(a) \ del(a))). case (b),
00
0
aC C C 00 = dominates aC [p]. case (a), obtain dominating action
00
aC C , define
C 00 := {c00 C | del(a) c00 = , add(a) c00 6= , c00 c0 }
c00 C 00 satisfy conditions (1) del(a) c00 = add(a) c00 6= (2) c C :
00
((c c00 add(a) c 6= ) = c C 0 ) Definition 2, indeed aC action C .
00
00
obviously c0 C 00 thus p add(aC ). remains prove pre(aC )
0
pre(aC [p]). so, intuitively, C 00 corresponds single conjunction c0 (plus
subsumed conjunctions) hence cross-context fluents arise.S Specifically, every
00
c00 C 00 c00 \add(a) c0 \add(a). Thus pre(aC ) = (pre(a) c00 C 00 (c00 \add(a)))C =
0
(pre(a) (c0 \ add(a)))C . latter obviously contained pre(aC [p]), concluding
proof (A).
+
C
+
C
remains prove (B). Since h1 (C
no-cc ) h (no-cc ), suffices prove h (no-cc )
+
C
+
C
h (ce ). Consider state s, relaxed plan ce ce . action ace
+ , representing action original task , let C 0 set conjunctions c whose
ce
+ C . C 0 obviously qualifies
-fluents added ace execution ce
ce

constraint (1) Definition 2; qualifies constraint (2) conditional effect
c property triggered ace conditional effect suitable c0
C 0 a. Define action sequence +
triggered. Thus C
no-cc includes representative
C 0 + adds fluents ,
C0
C
ce
no-cc sequence . Obviously,
precondition union ace conditional effects fire. Thus
+
C
+
C
+ relaxed plan C
no-cc . follows h (no-cc ) h (ce ) desired.

Example 4 Consider STRIPS planning task variables {i, p, q, r, z, g1 , g2 , g3 },
initial state = {i}, goal G = {g1 , g2 , g3 }, actions follows:
528



fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Name
pre
add del ce cost
aqz
{i}
{q,
z}

4

ari
{i}
{r}

1
pz
{i, q}
{p} {z}
1
aiq
apz
{r}
{p}
{z}

4
r
g1
{p, z} {g1 }

1
apz
agiq2
{i, q} {g2 }

1
g3
ar
{r} {g3 }

1
set C = {{i, q}, {p, z}}. operator adding part {i, q} aqz
adds q.
qz
pz pz
operators adding part {p, z} ai adds z, aiq , ar add p;
pz
since aiq
apz
delete z, cannot used establish conjunction {p, z}.
r
Thus actions C
ce are:
Name
pre
add del
ce cost
qz
qz
ai
{i} {q, z}
ce(ai )
4
ari
{i}
{r}


1
{i,
q,

}
{p}


1
apz
i,q
iq
pz
ar
{r}
{p}


4
{p, z, p,z } {g1 }


1
agpz1
g2
aiq
{i, q, i,q } {g2 }


1
{r} {g3 }


1
agr3
ce(aqz
) contains two conditional effects:
Name
c
add del
i,q
ei
{i} {i,q }


ep p,z
{p} {p,z }

pz
Clearly, respect hmax , -fluents preconditions aiq
, agpz1 , agiq2 dominate respective preconditions actions (as pointed Section 5.1,
implementation actually remove preconditions). Thus LM-cuts justification
graph C
ce would structure shown Figure 5.
+
C
hmax (C
ce ) = 10 due cost achieving g1 . h (ce ), construct
qz pz
plan C
ce choice establish p. use ai , aiq ,
use ari , apz
r . latter case, make single application conditionalg2 g3
r pz qz g1
effects action aqz
, relaxed plan 1 = hai , ar , ai , apz , aiq , ar i, whose cost 12.
qz
former case, must use ai twice first i,q , p,z yielding relaxed
pz qz g1
g2 r g3
+
C
plan 2 = haqz
, aiq , ai , apz , aiq , ai , ar i, whose cost 13. Thus h (ce ) = 12. Since,
pz
execution 1 , delete ar , true anyhow state
execution, 1 also solves original task get h () = h+ (C
ce ) = 12.
consider LM-cut, say produced cut conditional-effects action
p,z
aqz
connects p p,z via conditional effect ep . two options discussed
Section 6.1 (A) reduce cost aqz
globally, sticking original definition


LM-cut; (B) reduce cost ep p,z , conditional effect ei i,q
p,z
part optimal-cost path ep thus serves justify hmax value.
options violates one essential properties LM-cut:

529

fiKeyder, Hoffmann, & Haslum



z

p



i,q
aqz
: ei

aqz




q

aqz


:


ei i,q

:

r

arg3

p,z

apz
iq


ei i,q

i,q

apz
r

ari

p,z
aqz
: ep

agiq2

agpz1

g1

g2

g3

Figure 5: Illustration LM-cut justification graphs C
ce Example 4. dashed
edges correspond preconditions critical (hmax -maximizing) start,
become critical point execution LM-cut.


p,z
(A) configuration, LM-cut produces cuts {agpz1 } [cost 1], {aqz
: ep } [cost 4],
pz pz
g2
[cost 1], {ar , aiq } [cost 1], {aiq } [cost 1], {ari } [cost 1]. Note that,
i,q
p,z
qz
qz
cut {aqz
: ep }, cost ai reduced 0 globally; particular, cut {ai : ei }
produced. get heuristic value hLM-cut = 9 < hmax (C
ce ) = 10, LM-cut
dominate hmax .
(B) configuration, LM-cut produce following cuts. start, every
p,z
possible precondition choice function (pcf ), get cuts {agpz1 } [cost 1] {aqz
: ep }
[cost 4]. hmax 5 g1 , g2 ; say pcf selects g2 , get cut {agiq2 }
pz
max 4
[cost 1]. Now, pcf select g1 , getting cut {apz
r , aiq } [cost 1]. Then, h
g1
g1 , g2 ; say pcf selects g1 . Say pcf selects p,z apz (another
choice would z), selects i,q apz
(another choice would q), thus remaining
iq
i,q pz
non-dashed part Figure 5. get cut {aqz
: ei , ar } [cost 3]
g1 reached 0 cost p i,q (we would get cut pcf
selecting g1 , point). Now, hmax 2 g3 1 g1 , g2 , get cut
{agr3 } [cost 1]. point, hmax 1 goal facts; say LM-cut selects g3 , thus
get cut {ari } [cost 1] way achieve r. finally hmax
i,q
1 g2 only, yielding cut {aqz
: ei } [cost 1]. Overall, get heuristic value
hLM-cut = 13 > h () = h+ (C
ce ) = 12, LM-cut admissible.

{agr3 }

Bibliography
Baier, J. A., & Botea, A. (2009). Improving planning performance using low-conflict relaxed
plans. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings
530

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

19th International Conference Automated Planning Scheduling (ICAPS09),
pp. 1017, Thessaloniki, Greece. AAAI Press.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets.
Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th European
Conference Artificial Intelligence (ECAI10), pp. 329334, Lisbon, Portugal. IOS
Press.
Bonet, B., Palacios, H., & Geffner, H. (2009). Automatic derivation memoryless policies
finite-state controllers using classical planners. Gerevini, A., Howe, A., Cesta,
A., & Refanidis, I. (Eds.), Proceedings 19th International Conference Automated Planning Scheduling (ICAPS09), pp. 3441, Thessaloniki, Greece. AAAI
Press.
Bylander, T. (1994). computational complexity propositional STRIPS planning.
Artificial Intelligence, 69 (12), 165204.
Cai, D., Hoffmann, J., & Helmert, M. (2009). Enhancing context-enhanced additive
heuristic precedence constraints. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings 19th International Conference Automated Planning
Scheduling (ICAPS09), pp. 5057, Thessaloniki, Greece. AAAI Press.
Do, M. B., & Kambhampati, S. (2001). Sapa: domain-independent heuristic metric temporal planner. Cesta, A., & Borrajo, D. (Eds.), Recent Advances AI Planning. 6th
European Conference Planning (ECP01), Lecture Notes Artificial Intelligence,
pp. 109120, Toledo, Spain. Springer-Verlag.
Fox, M., & Long, D. (2001). STAN4: hybrid planning strategy based subproblem
abstraction. AI Magazine, 22 (3), 8184.
Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA Guide
Theory NP-Completeness. Freeman, San Francisco, CA.
Gazen, B. C., & Knoblock, C. (1997). Combining expressiveness UCPOP
efficiency Graphplan. Steel, S., & Alami, R. (Eds.), Recent Advances AI
Planning. 4th European Conference Planning (ECP97), Lecture Notes Artificial
Intelligence, pp. 221233, Toulouse, France. Springer-Verlag.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local search
temporal action graphs. Journal Artificial Intelligence Research, 20, 239290.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Chien, S.,
Kambhampati, R., & Knoblock, C. (Eds.), Proceedings 5th International Conference Artificial Intelligence Planning Systems (AIPS00), pp. 140149, Breckenridge, CO. AAAI Press.
Haslum, P. (2009). hm (P ) = h1 (P ): Alternative characterisations generalisation
hmax hm . Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings 19th International Conference Automated Planning Scheduling
(ICAPS09), pp. 354357, Thessaloniki, Greece. AAAI Press.
531

fiKeyder, Hoffmann, & Haslum

Haslum, P. (2012). Incremental lower bounds additive cost planning problems.
Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd
International Conference Automated Planning Scheduling (ICAPS12), pp.
7482, Sao Paulo, Brasil. AAAI Press.
Helmert, M. (2006). Fast Downward planning system. Journal Artificial Intelligence
Research, 26, 191246.
Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whats
difference anyway?. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.),
Proceedings 19th International Conference Automated Planning Scheduling (ICAPS09), pp. 162169, Thessaloniki, Greece. AAAI Press.
Helmert, M., & Geffner, H. (2008). Unifying causal graph additive heuristics.
Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings 18th
International Conference Automated Planning Scheduling (ICAPS08), pp.
140147, Sydney, Australia. AAAI Press.
Hoffmann, J. (2005). ignoring delete lists works: Local search topology planning
benchmarks. Journal Artificial Intelligence Research, 24, 685758.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. Journal Artificial Intelligence Research, 14, 253302.
Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. Journal
Artificial Intelligence Research, 22, 215278.
Hoffmann, J., Steinmetz, M., & Haslum, P. (2014). take render h+ ( c )
perfect?. Proceedings 6th Workshop Heuristics Search Domain
Independent Planning, ICAPS14.
Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C.
(Ed.), Proceedings 21st International Joint Conference Artificial Intelligence
(IJCAI09), pp. 17281733, Pasadena, California, USA. Morgan Kaufmann.
Katz, M., Hoffmann, J., & Domshlak, C. (2013). said need relax variables?.
Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings
23rd International Conference Automated Planning Scheduling (ICAPS13),
pp. 126134, Rome, Italy. AAAI Press.
Keyder, E., & Geffner, H. (2008). Heuristics planning action costs revisited.
Ghallab, M. (Ed.), Proceedings 18th European Conference Artificial Intelligence (ECAI08), pp. 588592, Patras, Greece. Wiley.
Keyder, E., & Geffner, H. (2009). Trees shortest paths vs. Steiner trees: Understanding
improving delete relaxation heuristics. Boutilier, C. (Ed.), Proceedings
21st International Joint Conference Artificial Intelligence (IJCAI09), pp. 1734
1749, Pasadena, California, USA. Morgan Kaufmann.
Keyder, E., Hoffmann, J., & Haslum, P. (2012). Semi-relaxed plan heuristics. Bonet, B.,
McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd International Conference Automated Planning Scheduling (ICAPS12), pp. 128136,
Sao Paulo, Brasil. AAAI Press.
532

fiImproving Delete Relaxation Heuristics Explicit Conjunctions

Keyder, E., Richter, S., & Helmert, M. (2010). Sound complete landmarks And/Or
graphs. Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th
European Conference Artificial Intelligence (ECAI10), pp. 335340, Lisbon, Portugal. IOS Press.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planning
problems bounded width. Journal Artificial Intelligence Research, 35, 623
675.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. Journal Artificial Intelligence Research, 39, 127177.
Roger, G., Pommerening, F., & Helmert, M. (2014). Optimal planning presence
conditional effects: Extending LM-Cut context-splitting. Schaub, T. (Ed.),
Proceedings 21st European Conference Artificial Intelligence (ECAI14),
Prague, Czech Republic. IOS Press. appear.

533

fiJournal Artificial Intelligence Research 50 (2014) 1-30

Submitted 12/13; published 05/14

Topic-Based Dissimilarity Sensitivity Models
Translation Rule Selection
Min Zhang

MINZHANG @ SUDA . EDU . CN

Provincial Key Laboratory Computer Information Processing Technology,
Soochow University, Suzhou, China

Xinyan Xiao

XIAOXINYAN @ ICT. AC . CN

IIP Key Lab, Institute Computing Technology,
Chinese Academy Sciences, China

Deyi Xiong

DYXIONG @ SUDA . EDU . CN

Provincial Key Laboratory Computer Information Processing Technology,
Soochow University, Suzhou, China

Qun Liu

LIUQUN @ ICT. AC . CN

CNGL, School Computing, Dublin City University, Ireland
IIP Key Lab, Institute Computing Technology,
Chinese Academy Sciences, China

Abstract
Translation rule selection task selecting appropriate translation rules ambiguous
source-language segment. translation ambiguities pervasive statistical machine translation, introduce two topic-based models translation rule selection incorporates global
topic information translation disambiguation. associate synchronous translation rule
source- target-side topic distributions.With topic distributions, propose topic
dissimilarity model select desirable (less dissimilar) rules imposing penalties rules
large value dissimilarity topic distributions given documents. order encourage use non-topic specific translation rules, also present topic sensitivity model
balance translation rule selection generic rules topic-specific rules. Furthermore,
project target-side topic distributions onto source-side topic model space benefit
topic information source target language. integrate proposed topic dissimilarity sensitivity model hierarchical phrase-based machine translation synchronous
translation rule selection. Experiments show topic-based translation rule selection model
substantially improve translation quality.

1. Introduction
Translation rules bilingual segments1 establish translation equivalences source
target language. widely used statistical machine translation (SMT) various representations ranging word pairs bilingual phrases synchronous rules word-, phraseand syntax-based SMT respectively. Normally, large number translation rules learnt
bilingual training data single source segment occurs different contexts.
example, Xiong, Zhang, Li (2012) observe Chinese verb translated
1. segment defined string terminals and/or nonterminals.

c
2014
AI Access Foundation. rights reserved.

fiZ HANG , X IAO , X IONG , & L IU

140 different translation rules average. Therefore select appropriate translation
rule ambiguous source segment crucial issue SMT.
Traditionally appropriateness translation rule measured multiple probabilities
estimated word-aligned data, bidirectional translation probabilities (Koehn, Och, &
Marcu, 2003). probabilities fail capture local global contexts highly ambiguous
source segments, sufficient select correct translation rules segments. Therefore various approaches proposed capture rich contexts sentence level help
select proper translation rules phrase- (Carpuat & Wu, 2007a) syntax-based SMT (Chan, Ng,
& Chiang, 2007; He, Liu, & Lin, 2008; Liu, He, Liu, & Lin, 2008). studies show local
features, surrounding words, syntactic information on, helpful translation rule
selection.
Beyond contextual features sentence level, conjecture translation rules
also related high-level global information, topic (Hofmann, 1999; Blei, Ng, & Jordan,
2003) information document level. order visualize relatedness translation
rules document topics, show four hierarchical phrase-based translation rules topic
distributions Figure 1. figure, observe
First, translation rules divided two categories terms topic distributions:
topic-sensitive rules (i.e., topic-specific rules) topic-insensitive rules (i.e., non-topic specific generic rules). former rules, e.g., translation rule (a), (b) (d) Figure
1, much higher distribution probabilities specific topics topics.
latter rules, e.g., translation rule (c) Figure 1, even distribution topics.
Second, topic information used disambiguate ambiguous source segments. Figure
1, translation rule (b) (c) source segment. However topic distributions
quite different. Rule (b) distributes topic international relations
highest probability, suggests rule (b) much related topic
topics. contrast, rule (c) even distribution topics. Therefore document
international relations, rule (b) appropriate rule (c) source
X1 .
segment



two observations suggest different translation rules different topic distributions
document-level topic information used benefit translation rule selection.
article, propose framework translation rule selection exactly capitalizes
document-level topic information. proposed topic-based translation rule selection framework
associates translation rule topic distribution (rule-topic distribution) source
target side. source document also annotated corresponding topic distribution
(document-topic distribution). Dissimilarity document-topic distribution rule-topic
distribution calculated used help select translation rules related documents
terms topics. particular,
Given document translated, use topic dissimilarity model calculate dissimilarity translation rule document based topic distributions.
translation system penalize candidate translations high dissimilarities.2
2. Section 6 explains system penalizes candidate translations high dissimilarities.

2

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

0.6

0.6

0.4

0.4

0.2

0.2

0

U operational capability

1

(a)

5

10

15

20

25

0
30

1

0.6

0.6

0.4

0.4

0.2

0.2

0
1

5

(c)

X
10

1

0
15

20

25

5

(b)

30

1

give X1

(d) X1

X
10

15

1 ! X
5

20

25

30

25

30

grants X1

1

10

2

15

20

held talks X1 X2

Figure 1: Four synchronous rules topic distributions. sub-graph shows rule
topic distribution, X-axis shows topic index Y-axis topic probability. Notably, rule (b) rule (c) shares source Chinese string,
different topic distributions due different English translations.

dissimilarity topic-insensitive translation rule given source document
computed topic dissimilarity model often high documents normally
topic-sensitive. dont want penalize generic topic-insensitive rules. Therefore
propose topic sensitivity model rewards topic-insensitive rules
complement topic dissimilarity model.
associate translation rule rule-topic distribution source target side. order calculate dissimilarity target-side rule-topic distributions
translation rules source-side document-topic distributions given documents
decoding, project target-side rule-topic distributions translation rules onto space
source-side document topic model one-to-many mapping.
use hierarchical phrase-based SMT system (Chiang, 2007) validate effectiveness
topic-based models translation rule selection. Experiments Chinese-English translation
tasks (Section 7) show method outperforms baseline hierarchial phrase-based system
+1.2 B LEU points large-scale training data.
use topic-based dissimilarity sensitivity models improve SMT first presented
previous paper (Xiao, Xiong, Zhang, Liu, & Lin, 2012). article, provide
detailed comparison related work formulations two models well integration

3

fiZ HANG , X IAO , X IONG , & L IU

procedure. importantly, carry large-scale experiments bilingual monolingual training data incorporate detailed analysis output topic-based dissimilarity
sensitivity models document translation hypothesis level.
rest article organized follows. Section 2 introduces related work. Section 3
provides background knowledge statistical machine translation topic modeling. Section 4
elaborates topic-based translation rule selection framework, including topic dissimilarity
topic sensitivity model. Section 5 discusses estimate rule-topic document-topic distributions project target-side rule-topic distributions onto source-side topic space
one-to-many mapping fashion. Section 6 presents integration topic-based translation rule
selection models hierarchical phrase-based SMT. Section 7 describes series experiments
verify effectiveness approach. Section 8 provides detailed analysis output
models. Section 9 gives suggestions bilingual topic modeling perspective
machine translation. Finally, conclude Section 10 future directions.

2. Related Work
topic-based dissimilarity sensitivity models translation rule selection related three
categories work SMT: translation rule selection, topic models SMT document-level
translation. section, introduce related approaches three categories highlight
differences method previous work.
2.1 Translation Rule Selection
mentioned before, translation rule selection important task SMT. Several approaches proposed recently. Carpuat Wu explore word phrase sense
disambiguation (WSD PSD) translation rule selection phrase-based SMT (Carpuat & Wu,
2007a, 2007b). WSD PSD system integrate sentence-level local collocation features. Experiments show multi-word PSD improve phrase selection. Also following WSD line,
Chan et al. (2007) integrate WSD system hierarchical phrase-based SMT lexical selection
selection short phrases length 1 2. WSD system also adopts sentence-level
features local collocations, surrounding words on.
Different lexical phrasal selection using WSD/PSD, et al. (2008) propose maximum entropy (MaxEnt) based model context-dependent synchronous rule selection hierarchical phrase-based SMT. Local context features phrase boundary words part-of-speech
information incorporated model. Liu et al. (2008) extends selection method
et al. integrate similar MaxEnt-based rule selection model tree-to-string syntax-based
SMT system (Liu, Liu, & Lin, 2006). model uses syntactic information source parse
trees features.
significant difference topic-based rule selection framework previous approaches translation rule selection use global topic information help select translation rules ambiguous source segments rather sentence-level local context features.
2.2 Topic Models SMT
Topic modeling (Hofmann, 1999; Blei et al., 2003) popular technique discovering underlying
topic structures documents. Recent years witnessed topic models explored
4

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

SMT. Zhao Xing (2006, 2007) Tam, Lane, Schultz (2007) proposed topicspecific lexicon translation adaptation models improve translation quality. models focus
word-level translations. first estimate word translation probabilities conditioned topics,
adapt lexical translation probabilities phrases topic-conditioned probabilities. Since
modern SMT systems use synchronous rules bilingual phrases translate sentences, believe
reasonable incorporate topic models phrase synchronous rule selection
lexical selection.
Gong, Zhang, Zhou (2010) adopt topic model filter phrase pairs consistent source documents terms topics. assign topic document
translated. Similarly, phrase pair also assigned one topic. phrase pair
discarded topic mismatches document topic. differences work twofold.
First, calculate dissimilarities translation rules documents based topic distributions instead comparing best topics assigned translation rules documents.
Second, integrate topic information SMT soft-constraint manner via topic-based
models. explore topic information hard-constraint fashion discarding translation rules
unmatched topics.
Topic models also used domain adaptation translation language models SMT.
Foster Kuhn (2007) describe mixture model approach SMT adaptation. divide
training corpus different domains, used train domain-specific translation
model. decoding, combine general domain translation model specific domain
translation model selected according various text distances calculated topic model.
Tam et al. (2007) Ruiz Federico (2011) use bilingual topic model project latent topic
distributions across languages. Based bilingual topic model, apply source-side topic
weights onto target-side topic model adapt target-side n-gram language model.
2.3 Document-Level Machine Translation
Since incorporate document topic information SMT, work also related documentlevel machine translation. Tiedemann (2010) integrates cache-based language translation models built recently translated sentences SMT. Gong, Zhang, Zhou (2011)
extend cache-based approach introducing two additional caches: static cache stores
phrases extracted documents training data similar document question
topic cache target language topic words. Xiao, Zhu, Yao, Zhang (2011) try solve
translation consistency issue document-level translation introducing hard constraint
ambiguous source words required consistently translated frequent translation options. Ture, Oard, Resnik (2012) soften consistency constraint integrating three
counting features decoder. studies normally focus surface structure capture inter-sentence dependencies document-level machine translation explore topic
structure document document translation.

3. Preliminaries
establish section background knowledge statistical machine translation
topic modeling. Although introduction short, sufficient understanding

5

fiZ HANG , X IAO , X IONG , & L IU

Sub-models
PI
logP (ei |f )
P1I
logP (f |ei )
P1I
logPlex (ei |f )
P1I
logPlex (f |ei )
P1|e|
logP (ei |e1 ...ei1 )
PI1
1 log(ei , f )
|e|


Descriptions
direct translation probabilities
inverse translation probabilities
direct lexical translation probabilities
inverse lexical translation probabilities
language model
reordering model
word count
rule count

Table 1: widely-used sub-models statistical machine translation. number
translation rules used generate target sentence e given source sentence
f . ei f target source side translation rule ri .

topic-based dissimilarity sensitivity models try bridge gap topic modeling
statistical machine translation.
3.1 Statistical Machine Translation
Given source sentence f , SMT systems find best translation e among possible translations follows.
hP




exp

h
(f,
e)

1
hP

e = argmax P



e
e exp
1 hm (f, e )
#)
(
"
X
(1)
hm (f, e)
= argmax exp
e

= argmax
e

m=1

(


X

)

hm (f, e)

m=1

hm (f, e) feature function defined source sentence f corresponding
transla-i
hP
P


tion e, weight feature function. Since normalization e exp
1 hm (f, e )

constant possible translations e , need calculate decoding.
weighted model equation (1) log-linear model. feature functions hm (f, e)
also referred sub-models3 components log-linear model. Table 1,
show widely-used feature functions SMT. easily factored
translation rules, facilitates application dynamic programming decoding.
show proposed topic-based dissimilarity sensitivity models also easily factorized
Section 4.
3. notation used want emphasize sub-model component log-linear model. Otherwise
call models, language model, reordering model on.

6

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

log-linear model SMT, sub-models trained separately combined
assumption independent other. associated weights tuned
using minimum error rate training (MERT) (Och, 2003) Margin Infused Relaxed Algorithm
(MIRA) (Chiang, Marton, & Resnik, 2008). Note normalization factor equation (1)
calculated training algorithms. algorithms directly optimize
log-linear model SMT towards translation quality measure BLEU. Feature weights
optimized towards criteria Maximum Mutual Information (MMI) necessarily
optimal respect translation quality (Och, 2003).
integrate proposed two models log-linear model hierarchical phrasebased SMT system (Section 6) order validate effectiveness two models, provide
details hierarchical phrase-based SMT (Chiang, 2005) section. Translation rules
hierarchial phrase-based SMT synchronous context-free grammar rules, denoted
follows.
X h, ,
(2)
X undifferentiated nonterminal, strings terminals nonterminals4
source target side respectively, denotes one-to-one mapping nonterminals
nonterminals . rules automatically extracted word-aligned bilingual
training data. addition rules, two special rules also introduced hierarchical
phrase-based SMT.
hX1 , X1
hS0 X1 , S0 X1

(3)

two rules used serially concatenate nonterminal Xs monotonic manner form
initial symbol S, start symbol grammar hierarchical phrase-based SMT.
log-linear model hierarchical phrase-based SMT formulated follows.
!
X
log(t(r)) + lm logPlm (e) + wp |e| + rp
(4)
w(D) = exp
rD

derivation defined set triples (r, i, j), denotes application
translation rule spans words j source side. number translation rules
D. probability translation rule r defined
t(r) = P (|)1 P (|)2 Plex (|)3 Plex (|)4

(5)

lexical translation probabilities Plex (|) Plex (|) estimate probabilities
words translate words word-by-word fashion (Koehn et al., 2003).
3.2 Topic Modeling
Topic modeling used discover topics occur collection documents. Latent
Dirichlet Allocation (LDA) (Blei et al., 2003) Probabilistic Latent Semantic Analysis (PLSA)
4. order simplify decoder implementation, two nonterminals allowed hierarchical translation
rules.

7

fiZ HANG , X IAO , X IONG , & L IU

(Hofmann, 1999) topic models. LDA widely used topic model, exploit
mine topics translation rule selection.
LDA views document mixture various topics, probability distribution words. particularly, LDA works generative process follows.
document Dj , sample document-topic distribution (per-document topic distribution) j Dirichlet distribution Dir(): j Dir();
word wj,i Nj words document Dj ,
Sample topic assignment zj,i Multinomial(j );
Sample word wj,i Multinomial(zj,i ) zj,i per-topic word distribution topic zj,i drawn Dir().
Generally speaking, LDA contains two groups parameters. first group parameters
characterizes document-topic distributions (j ), record distribution document
topics. second group parameters used topic-word distributions (k ), represent
topic distribution words.
Given document collection observed words w = {wj,i }, goal LDA inference
compute values two sets parameters well latent topic assignments
z = {zj,i }. inference complicated due latent topic assignments z. efficient inference
algorithm proposed address problem Collapsed Gibbs Sampling (Griffiths
& Steyvers, 2004), two sets parameters integrated LDA model,
latent topic assignments z sampled P (z|w). obtain values z,
estimate recovering posterior distributions given z w. Section 4,
use two sets estimated parameters topic assignments words calculate
parameters models.

4. Topic-based Dissimilarity Sensitivity Models
section, elaborate topic-based models translation rule selection, including topic
dissimilarity model topic sensitivity model.
4.1 Topic Dissimilarity Model
Sentences translated accordance topics (Zhao & Xing, 2006, 2007; Tam
et al., 2007). Take translation rule (b) Figure 1 example. source side rule
(b) occurs document international relations, hope encourage application rule
(b) rather rule (c). achieved calculating dissimilarity probability
distributions translation rule document topics.
order calculate topic dissimilarity translation rule selection, associate
source target side translation rule rule-topic distribution P (z |r ),
placeholder source side f target side e, r source target side translation
rule r, z corresponding topic r . Therefore translation rule two rule-topic
distributions: P (zf |rf ) source side P (ze |re ) target side.
8

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

Supposing K topics, two distributions represented K-dimension vector. k-th component P (z = k|r ) denotes probability topic k given r . sourceand target-side rule-topic distributions separately estimated training data. estimation
method described Section 5, also discuss reason estimate
separate manner.
Analogously, represent topic information document translated documenttopic distribution P (z|d), also K-dimension vector. k-th dimension P (z = k|d)
topic proportion topic k document d. Different rule-topic distribution,
document-topic distribution directly inferred off-the-shelf LDA tool.
Based defined rule-topic document-topic distributions, measure dissimilarity translation rule document decide whether rule suitable document
translation. Traditionally, similarity two probability distributions calculated information measurements Jensen-Shannon divergence (Lin, 2006) Hellinger distance (Blei &
Lafferty, 2007).
adopt Hellinger distance (HD) measure topic dissimilarity, symmetric widely used comparing two probability distributions (Blei & Lafferty, 2007). Given
rule-topic distribution P (z |r ) document-topic distribution P (z|d), HD computed
follows.
K p
2
X
p
P (z = k|d) P (z = k|r )
(6)
HD(P (z|d), P (z |r )) =
k=1

Let derivation defined Section 3.1. Let P(z|r) represent corresponding rule-topic
distributions rules D. topic dissimilarity model Dsim(P (z|d), P(z|r)) derivation
defined HD equation (6) follows
X
Dsim(P (z|d), P(z|r)) =
HD(P (z|d), P (z |r ))
(7)
rD

Obviously, larger Hellinger distance candidate translation yielded derivation
document, larger dissimilarity them. topic dissimilarity model
defined above, aim select translation rules similar document translated
terms topics.
4.2 Topic Sensitivity Model
introduce topic sensitivity model, lets revisit Figure 1. easily find
probability rule (c) distributes evenly topics. indicates insensitive topics,
therefore applied topics. contrast, distributions three rules
peak topics. Generally speaking, topic-insensitive rule fairly flat distribution
topics, topic-sensitive rule sharp distribution topics.
document typically focuses topics, sharp distribution topics.
words, documents normally topic-sensitive. Since distribution topic-insensitive
rule fairly flat, dissimilarity topic-insensitive rule topic-sensitive document
low. Therefore, system proposed topic dissimilarity model punish
topic-insensitive rules.
9

fiZ HANG , X IAO , X IONG , & L IU

However, topic-insensitive rules may preferable topic-sensitive rules neither
similar given documents. document topic love, rule (b) (c)
Figure 1 dissimilar document rule (b) relates international relations topic
rule (c) topic-insensitive. Nevertheless, since rule (c) occurs frequently across various
topics, prefer rule (c) rule (b) translate document love.
address issue topic dissimilarity model, propose topic sensitivity
model. model employs entropy based metric measure topic sensitivity rule
follows
K
X
P (z = k|r ) log(P (z = k|r ))
(8)
H(P (z |r )) =
k=1

According equation, topic-insensitive rule normally large entropy topicsensitive rule smaller entropy.
Given derivation rule-topic distributions P(z|r) rules D, topic sensitivity
model defined follows.
X
H(P (z |r ))
(9)
Sen(P(z|r)) =
rD

Incorporating topic sensitivity model topic dissimilarity model, enable SMT
system balance selection topic-sensitive topic-insensitive rules. Given rules approximately equal values topic dissimilarity, prefer topic-insensitive rules.

5. Estimation
Unlike document-topic distributions directly learned LDA tools, need estimate
rule-topic distributions translation rules. want exploit topic information
source target language, separately train two monolingual topic models source
target side, learn correspondences two topic models via word alignments
bilingual training data.
Particularly, adopt two rule-topic distributions translation rule: 1) source-side
rule-topic distribution P (zf |rf ) 2) target-side rule-topic distribution P (ze |re ),
defined Section 4.1. two rule-topic distributions estimated using trained
topic models way (Section 5.1). Notably, source-language documents available
decoding. order compute dissimilarity target-side rule-topic distribution
translation rule source-side document-topic distribution given document need
project target-side rule-topic distribution translation rule onto space source-side
topic model (Section 5.2).
also establish alternative approaches estimation rule-topic distributions via
multilingual topic models (Mimno, Wallach, Naradowsky, Smith, & McCallum, 2009; Boyd-Graber
& Blei, 2009) bilingual topic models also infer word-to-word alignments document pairs
(Zhao & Xing, 2006, 2007). former multilingual topic models require documents
different languages comparable terms content similarity. contrast, latter bilingual
topic models require documents parallel, i.e., translations other, capture
word alignments.



10

fiT OPIC -BASED ISSIMILARITY

Z

N



ENSITIVITY ODELS

Z

W

N



Z

W
Z

topic
correspondence

N1

Z



k

k

target

source

(a)

W

NL

N



word
alignment

N



W




W

Z

Z

e

J

W
1

L

1

L

k



f

J





k

k

B



target

source

(a*)

(b)

(c)

Figure 2: Graphical model representations (a) bilingual topic model, (b) polylingual topic
model Mimno et al. (2009), (c) bilingual topic model Zhao Xing (2007)
number parallel sentence pairs document, word alignment
source target sentence. simplicity, display HMM transitions
among word alignments a. Subfigure (a*) shows build topic correspondences source target language source target topics separately learned
shown (a).

biggest difference method multilingual/bilingual topic models
use per-tuple topic distribution documents tuple. define
tuple set documents different languages. per-tuple topic distribution similar
per-document topic distribution. difference per-tuple topic
distribution shared documents tuple.
Topic assignments words languages naturally connected since sampled
topic distribution. contrast, assume document source/target
side sampled document-specific distribution topics. Topic correspondences source target document learned projection via word alignments. visualize
difference Figure 2.
Yet another difference models topic-specific lexicon translation model
Zhao Xing (2007) use bilingual topics improve SMT word level
instead rule level. Since synchronous rule rarely factorized individual words,
believe reasonable incorporate topic model directly rule level rather
word level. Section 7.2.3, empirically compare model topic-specific lexicon
translation model.
Tam et al. (2007) also construct two monolingual topic models parallel source target
documents. build topic correspondences source target documents enforcing one-to-one topic mapping constraint. project target-side topics onto space
source-side topic model one-to-many fashion. Section 7.3.1, compare two different
methods building topic correspondences.

11

fiZ HANG , X IAO , X IONG , & L IU

5.1 Rule-Topic Distribution Estimation
estimate rule-topic distributions word-aligned bilingual training corpus document
boundaries explicitly given. source- target-side rule-topic distributions estimated
way. Therefore, simplicity, describe estimation source-side rule-topic
distribution P (zf |rf ) translation rule section.
estimation rule-topic distributions analogous traditional estimation rule translation probabilities (Chiang, 2007). addition word-aligned corpus, input rule-topic
distribution estimation also contains source-side document-topic distributions inferred LDA tool.
first extract translation rules bilingual training data traditional way.
source side translation rule rf extracted source-language document df documenttopic distribution P (zf |df ), obtain instance (rf , P (zf |df ), ), fraction count
instance described Chiang (2007). way, collect set instances
= {(rf , P (zf |df ), )} different document-topic distributions translation rule. Using
instances, calculate probability P (zf = k|rf ) rf topic k follows:
P
P (zf = k|df )
(10)
P (zf = k|rf ) = PK II
P

k =1
II P (zf = k |df )

Based equation, obtain two rule-topic distributions P (zf |rf ) P (ze |re )
rule using source- target-side document-topic distributions P (zf |df ) P (ze |de ) respectively.
5.2 Target-Side Rule-Topic Distribution Projection

described previous section, also estimate target-side rule-topic distributions. However, directly use equation (6) calculate dissimilarity target-side
rule-topic distribution P (ze |re ) translation rule source-side document-topic distribution
P (zf |df ) source-language document translated. order measure dissimilarity, need project target-side topics onto source-side topic space. projection takes
following two steps.
First, calculate correspondence probability p(zf |ze ) pair target-side topic
ze source-side topic zf , inferred two separately trained monolingual
topic models respectively.
Second, project target-side rule-topic distribution translation rule onto sourceside topic space using correspondence probabilities learned first step.
first step, estimate topic-to-topic correspondence probabilities using co-occurrence
counts topic assignments source target words word-aligned corpus. topic assignments source/target words inferred two monolingual topic models. topic
assignments, characterize sentence pair (f, e) (zf , ze , a), zf ze two vectors
containing topic assignments words source target sentence f e respectively,
set word alignment links {(i, j)} source target sentence. Particularly, link
(i, j) represents source-side position aligns target-side position j.
12

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

notations, calculate co-occurrence count source-side topic kf
target-side topic ke follows.
X X
(zfi , kf ) (zej , ke )
(11)
(zf ,ze ,a) (i,j)a

zfi zej topic assignments words fi ej respectively, (x, y) Kronecker
function, 1 x = 0 otherwise.
compute topic-to-topic correspondence probability P (zf = kf |ze = ke )
normalizing co-occurrence count follows.
P
P
(zf ,ze ,a)
(i,j)a (zfi , kf ) (zej , ke )
P
P
(12)
P (zf = kf |ze = ke ) =
(zf ,ze ,a)
(i,j)a (zej , ke )

Overall, first step, obtain topic-to-topic correspondence matrix MKe Kf ,
item Mi,j represents probability P (zf = i|ze = j).
second step, given correspondence matrix MKe Kf , project target-side ruletopic distribution P (ze |re ) source-side topic space multiplication follows.
(P (ze |re )) = P (ze |re ) MKe Kf

(13)

way, get second distribution translation rule source-side topic space,
call projected target-side topic distribution (P (ze |re )).
Word alignment noises may introduced equation (11), turn may flatten
sharpness projected topic distributions calculated equation (13). order decrease
flattening effects word alignment noises, take following action practice:
topic-to-topic correspondence probability P (zf = kf |ze = ke ) calculated via word alignments
1
K predefined number topics, set 0 re-normalize
less K
correspondence probabilities target-side topic ke .
Obviously, projection method allows one target-side topic ze align multiple source-side
topics. different one-to-one correspondence used Tam et al. (2007). investigate correspondence matrix MKe Kf obtained training data. find topic
correspondence source target language necessarily one-to-one. Typically,
correspondence probability P (zf = kf |ze = ke ) target-side topic mainly distributes two
three source-side topics. Table 2 shows example target-side topic three mainly
aligned source-side topics.

6. Integration
incorporate topic dissimilarity sensitivity model two new features hierarchical
phrase-based system (Chiang, 2007) log-linear discriminative framework (Och & Ney,
2002). dissimilarity values positive Hellinger distances positive. weight
dissimilarity feature tuned MERT negative. Therefore log-linear model favor
candidate translations lower values dissimilarity feature (less dissimilar).
words, translation rules similar document translated terms topics
selected.
13

fiZ HANG , X IAO , X IONG , & L IU

e-topic
enterprises
rural
state
agricultural
market
reform
production
peasants
owned
enterprise
P (zf |ze )

(agricultural)
~(rural)
(peasant)
U(reform)
(finance)
(social)
(safety)
N(adjust)
(policy)
\(income)

f-topic 1

(enterprise)
|(market)
Ik(state)
i(company)
7K(finance)
1(bank)
(investment)
+n(manage)
U(reform)
E(operation)

f-topic 2

u(develop)
L(economic)
E(technology )
I(China)
E(technique)
(industry)
((structure)
M#(innovation)
\(accelerate)
U(reform)

f-topic 3

0.38

0.28

0.16

Table 2: example topic-to-topic correspondence. last line shows correspondence
probability. column shows topic represented top-10 topical words. first
column target-side topic, remaining three columns source-side topics.

One possible side-effect integration dissimilarity feature system
favour translations generated fewer translation rules generated translation
rules translation rules result higher dissimilarity (see equation (7)).
say, topic-based dissimilarity feature also acts translation rule count penalty derivations.
Fortunately, however, also use translation rule count feature (see last row Table 1)
normally favours translations yielded derivation large number translation rules.
feature balance mentioned side-effect topic-based dissimilarity feature.
translation rule associated source-side rule-topic distribution projected
target-side rule-topic distribution decoding, add four features follows.5
Dsim(P (zf |d), P(zf |rf )) (or DsimSrc): Topic dissimilarity feature source-side rule-topic
distributions.
Dsim(P (zf |d), (P(ze |re ))) (or DsimTrg): Topic dissimilarity feature projected targetside rule-topic distributions.
Sen(P(zf |rf )) (or SenSrc): Topic sensitivity feature source-side rule-topic distributions.
Sen(T (P(ze |re )) (or SenTrg): Topic sensitivity feature projected target-side rule-topic
distributions.
source-side projected target-side rule-topic distributions translation rules
calculated decoding described last section. decoding, first infer
topic distribution P (zf |d) given document source language. translation rule
adopted derivation, scores four features updated correspondingly according
equation (7) (9). Obviously, computational cost features rather small.
5. Since glue rule rules unknown words extracted training data, set values four
features rules zero.

14

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

topic-specific lexicon translation models (Zhao & Xing, 2007; Tam et al., 2007), first
calculate topic-specific translation probabilities normalizing entire lexicon translation table
adapt lexical weights translation rules correspondingly decoding. makes
decoder run slower. Therefore, comparing previous topic-specific lexicon translation methods, method provides efficient way incorporating topic models SMT.

7. Experiments
section, conducted two groups experiments validate effectiveness topicbased translation rule selection framework. first group experiments, use medium-scale
bilingual data train SMT system topic models. purpose group experiments
quickly answer following questions:
topic dissimilarity model able improve translation rule selection terms B LEU?
Furthermore, source-side target-side rule-topic distributions complementary
other?
helpful introduce topic sensitivity model distinguish topic-insensitive topicsensitive rules?
topic-based method better previous topic-specific lexicon translation method (Zhao
& Xing, 2007) terms B LEU decoding speed?
confirm efficacy topic-based dissimilarity sensitivity model mediumscale training data, conducted second group experiments large-scale training data
investigate following questions:
one-to-many target-side rule-topic projection method better previous methods
proposed Zhao Xing (2007) Tam et al. (2007)?
effects models various types rules, phrase rules rules
non-terminals?
else achieve use monolingual data train topic models?
7.1 Setup
carried experiments NIST Chinese-to-English translation. used NIST evaluation set 2005 (MT05) development set, sets MT06/MT08 test sets.
numbers documents MT05, MT06, MT08 100, 79, 109 respectively. Case-insensitive
NIST B LEU (Papineni, Roukos, Ward, & Zhu, 2002) used measure translation performance.
used minimum error rate training (Och, 2003) optimize feature weights.
medium-scale experiments, used FBIS corpus bilingual training data,
contains 10,947 documents, 239K sentence pairs 6.9M Chinese words 9.14M English
words. large-scale experiments, bilingual training data consists LDC2003E14, LDC2004T07, LDC2005T06, LDC2005T10 LDC2004T08 (Hong Kong Hansards/Laws/News).

15

fiZ HANG , X IAO , X IONG , & L IU

selected corpora contain 103,236 documents 2.80M sentences. average, document 28.4 sentences.
obtained symmetric word alignments training data first running GIZA++ (Och & Ney,
2003) directions applying refinement rule grow-diag-final-and (Koehn et al.,
2003). hierarchical phrase translation rules extracted word-aligned training data.
used SRILM toolkit (Stolcke, 2002) train language models Xinhua portion
GIGAWORD corpus, contains 238M English words. trained 4-gram language model
medium-scale experiments 5-gram language model large-scale experiments.
order train two monolingual topic models source target side bilingual
training data, used open source LDA tool GibbsLDA++.6 GibssLDA++ implementation
LDA using gibbs sampling parameter estimation inference. source- targetside topic models separately estimated Chinese English part bilingual
training data. set number topic K = 30 source- target-side topic models,
used default setting tool training inference.7 decoding, inferred
document-topic distribution document dev/test sets translation using
trained source-side topic model. Note topic inference dev/test sets performed
parameters two topic models estimated training data.
case-insensitive BLEU-4 used evaluation metric. performed statistical
significance BLEU differences using paired bootstrap re-sampling (Koehn, 2004). order
alleviate impact instability MERT, ran tuning process three times
large scale experiments presented average BLEU scores three runs following
suggestion Clark, Dyer, Lavie, Smith (2011)
7.2 Medium-Scale Experiments
section, conducted medium-scale experiments investigate effectiveness two
topic-based models translation rule selection.
7.2.1 E FFECT



OPIC ISSIMILARITY ODEL

quickly investigated effectiveness topic dissimilarity sensitivity model using
medium-scale training data. Results shown Table 3. table, observe
use topic dissimilarity model source-side projected target-side ruletopic distributions (DsimSrc/DsimTrg table, see descriptions Section 5),
obtain absolute improvement 0.48/0.38 B LEU points baseline.
combine two topic dissimilarity features together, achieve improvement 0.16 B LEU points DsimSrc.
two observations show topic dissimilarity model able improve translation quality
terms B LEU.
6. http://gibbslda.sourceforge.net/
7. determine K testing {15, 30, 50, 100, 200} preliminary experiments. find K = 30 produces
slightly better performance values. order improve stability topic estimation, run
tool multiple times use best model respect log-likelihood.

16

fiT OPIC -BASED ISSIMILARITY

System
Baseline
TopicLex
DsimSrc
DsimTrg
DsimSrc+DsimTrg
Dsim+Sen

MT06
30.20
30.65
30.41
30.51
30.73
30.95



ENSITIVITY ODELS

MT08
21.93
22.29
22.69
22.39
22.69
22.92

Avg
26.07
26.47
26.55
26.45
26.71
26.94

Speed
12.6
3.3
11.5
11.7
11.2
10.2

Table 3: Results topic dissimilarity sensitivity model terms B LEU speed (words
per second), comparing traditional hierarchical system (Baseline) system topic-specific lexicon translation model (TopicLex). DsimSrc DsimTrg topic dissimilarity features source-side projected target-side ruletopic distributions respectively. Dsim+Sen activates two dissimilarity features
two sensitivity features described Section 6. Avg denotes average B LEU
scores two test sets. Scores bold significantly better Baseline (p < 0.01).
Speed denotes number words translated per second.
Rule Type
Phrase
Monotone
Reordering


Count
3.9M
19.2M
5.7M
28.8M

Src-Sen(%)
83.4
85.3
85.9
85.1

Trg-Sen(%)
84.4
86.1
86.8
86.0

Table 4: Percentages topic-sensitive rules listed rule types according entropies
source-side (Src) target-side (Trg) rule-topic distributions. Phrase rules fully
lexicalized, monotone reordering rules contain nonterminals.

order gain insights topic dissimilarity model helpful translation rule
selection, investigate many rules topic-sensitive. described Section 4.2,
use entropy measure whether translation rule topic-sensitive based rule-topic distribution. entropy translation rule calculated equation (8) smaller certain
threshold, rule topic-sensitive. Since documents often focus topics, use average entropy document-topic distributions training documents threshold. compare
entropies source-side target-side rule-topic distributions threshold. findings
shown Table 4. 85.5% translation rules topic-sensitive rules compare entropies
source-side rule-topic distributions threshold. compare entropies targetside rule-topic distributions threshold, topic-sensitive rules account 86%.
strongly suggest rules occur documents specific topics topic information
used improve translation rule selection.
7.2.2 E FFECT



OPIC ENSITIVITY ODEL

see Table 4, still 15% translation rules generic, sensitive topics. rules also widely used documents. mentioned before,
17

fiZ HANG , X IAO , X IONG , & L IU

topic dissimilarity model always punishes rules documents normally topic-specific.
therefore introduce topic sensitivity model complement topic dissimilarity model. experiment result model show last line Table 3. obtain improvement
0.23 B LEU points incorporating topic sensitivity model. indicates necessary
distinguish topic-insensitive topic-sensitive rules.
7.2.3 C OMPARISON



OPIC -S PECIFIC L EXICON RANSLATION ODEL

also compared topic models topic-specific lexicon translation model proposed
Zhao Xing (2007). introduce framework combine Hidden Markov Model (HMM)
LDA topic model SMT, shown Figure 2. framework, bilingual sentence
pair single topic assignment sampled document-pair topic distribution .
words target language (e.g., English) sampled given sentence-pair topic assignment
monolingual per-topic word distribution . that, word alignments words
source language sampled first-order Markov process topic-specific translation
lexicon respectively.
Zhao Xing integrate topic-specific word-to-word translation lexicons estimated
bilingual topic model described topic-specific lexicon translation model,
formulated follows.
P (we |wf , df ) P (wf |we , df )P (we |df )
X
=
P (wf |we , z = k)P (we |z = k)P (z = k|df )

(14)

k

model, probability candidate translation source word wf source document df calculated marginalizing topics corresponding topic-specific translation
lexicons. simplify estimation p(wf |we , z = k) directly computing probabilities
word-aligned corpus associated target-side topic assignments inferred
target-side topic model. Despite simplification, improvement implementation comparable improvement obtained Zhao Xing (2007). Given new document, need
adapt lexical translation weights rules. adapted lexicon translation model integrated
new feature log-linear discriminative framework.
show comparison results Table 3. topic-specific lexicon translation model
better baseline 0.4 B LEU points. However, topic-based method (the combination
topic dissimilarity sensitivity models) outperforms baseline 0.87 B LEU points.
also compare two methods terms decoding speed (words/second). baseline translates 12.6 words per second, system topic-specific lexicon translation
model translates 3.3 words one second. overhead topic-specific lexicon translation model mainly comes adaptation lexical weights. takes 72.8% time
adaptation. contrast, method speed 10.2 words per second sentence
average, three times faster topic-specific lexicon translation method.
7.3 Large-Scale Experiments
section, investigated deeper models second group experiments
large-scale training data.
18

fiT OPIC -BASED ISSIMILARITY

7.3.1 E FFECT





ENSITIVITY ODELS

NE - -M P ROJECTION

discussed Section 5.2, need project target-side topics onto source-side topic space
calculate dissimilarity target-side rule-topic distribution source-side
document-topic distribution. propose one-to-many projection method issue. order
investigate effectiveness method, conducted experiments large-scale training
data compare following 3 methods.
One-to-One Mapping enforce one-to-one mapping source-side target-side
topics, similar method Tam et al. (2007). achieve aligning target-side
topic corresponding source-side topic largest correspondence probability
calculated Section 5.2.
Marginalization Word Alignments Following Zhao Xing (2007), first obtain
topics target side using LDA retrieve topics source language
marginalization word alignments follows.
X
P (wf |k) =
P (wf |we )P (we |z = k)
(15)


Combination source target language documents concatenate target document aligned source document one document. run LDA tool
combined documents train one topic model mixed-language words. decoding,
use trained topic model infer topics source documents.
order compare one-to-many projection method three methods described above,
add target-side topic dissimilarity feature (DsimTrg) log-linear translation model.
experiment results reported Table 5. Clearly, four methods achieve improvements
baseline. However, one-to-many projection method performs better three
methods. particular,
method outperforms one-to-one topic mapping method, indicates sourceside target-side topics exactly match one-to-one correspondence manner.
reason marginalization method performs worse among four methods may
topic model trained target documents.
Surprisingly, combination method performs quite well. shows LDA model
find hidden topics even mixed-language documents.

7.3.2 E FFECT
RULES



OPIC -BASED RULE ELECTION F RAMEWORK



VARIOUS YPES



conducted experiments investigate effect topic-based models various
types rules selection. Particularly, divide translation rules hierarchical phrase-based SMT
three types: 1) phrase rules, contain terminals bilingual phrase
pairs used phrase-based system; 2) monotone rules, contain non-terminals produce
19

fiZ HANG , X IAO , X IONG , & L IU

System
Baseline
One-to-One
Marginalization
Combination
One-to-Many

MT06
31.77
32.15
32.23
32.17
32.44

MT08
24.89
25.32
24.99
25.56
25.54

Avg
28.33
28.73
28.61
28.86
28.99

Table 5: Effect one-to-many topic projection method methods. Marginalization: Marginalization Word Alignments; Combination: Combination source
target language documents.
System
Baseline
Phrase rule
Monotone rule
Reordering rule


MT06
31.77
32.43
32.24
31.82
32.77

MT08
24.89
25.53
25.62
25.15
26.29

Avg
28.33
28.98
28.93
28.48
29.53

Table 6: Effect topic-based rule selection models three types rules. Phrase rules
fully lexicalized, monotone reordering rules contain nonterminals.

monotone translations; finally 3) reordering rules, also contain non-terminals change
order translations. define monotone reordering rules according Chiang et al.
(2008).
study impact topic-based models translation rule type A, activate
four features described Section 6 rules type A. Topic dissimilarity
sensitivity features two types translation rules deactivated.
Table 6 shows experiment results. table, observe
topic-based models achieve highest improvement 0.65 B LEU points baseline phrase rules among three types translation rules. reasonable phrase
rules consist topical words.
also obtain improvements 0.6 0.15 B LEU points baseline monotone
reordering rules respectively. shows models also able help select
appropriate translation rules non-terminals.
activate topic dissimilarity sensitivity models translation rules,
still achieve additional improvement 0.55 B LEU points. total, models outperform
baseline absolute improvement 1.2 B LEU points.
7.3.3 E FFECT



ORE ONOLINGUAL DATA

Comparing Table 6 Table 3, find topic-based dissimilarity sensitivity models
trained medium-scale data (about 10K documents) collectively achieve improvement 0.87
20

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

System
Baseline
DsimSrc + SenSrc + DsimTrg + SenTrg
DsimSrc + SenSrc + DsimTrg + SenTrg
DsimSrc + SenSrc + DsimTrg + SenTrg
DsimSrc + SenSrc + DsimTrg + SenTrg

MT06
31.77
32.77
32.70
32.37
32.61

MT08
24.89
26.29
25.91
25.80
25.66

Avg
28.33
29.53
29.31
29.09
29.13

Table 7: Effect using monolingual data train topic models. features bold
topic-based dissimilarity/sensitivity model LDA topic model trained using
combination source/target part large-scale bilingual data corresponding
monolingual corpus.

B LEU points baseline two models trained large-scale data (about 100K documents) obtain improvement 1.2 B LEU points. suggests performance gains
may obtained data. parallel bilingual data document boundaries provided easily accessible, try collect monolingual data source or/and target language.
interest study whether gain improvements using monolingual data
train topic models.
used Chinese monolingual corpus documents collected Chinese Sohu
weblog 2009.8 collected Chinese corpus contains 500K documents 273.8M Chinese
words. also used English monolingual corpus documents collected
English Blog Authorship corpus (Schler, Koppel, Argamon, & Pennebaker, 2006). English
monolingual corpus consists 371K documents 98M English words. combined new
Chinese corpus source part large-scale bilingual data train source-side LDA topic
model ST . English monolingual corpus also combined target part large-scale
bilingual data train target-side LDA topic model .
used two topic models ST infer topics test sets. Topic information source target part large-scale bilingual training data inferred ST
used estimate source-side rule-topic distributions projected target-side rule-topic distributions. way, obtain new topic-based dissimilarity sensitivity model
source/target side.
Experiment results shown Table 7. Unfortunately, obtain improvements training topic models larger data, combination Chinese monolingual
corpus source part bilingual training data. Instead, performance drops 29.53
29.31 use topic model ST build source-side dissimilarity sensitivity features
29.09 adopt topic model build target-side dissimilarity sensitivity
features.
One reason lower performance larger topic model training data may
use 30 topics. Using topics may improve models larger corpora. order
investigate this, conducted new experiments topics 30. trained sourceside topic model using combination source part large-scale bilingual data Sohu
weblog data. Based topic model, built source-side topic dissimilarity model
8. http://blog.sohu.com/.

21

fiZ HANG , X IAO , X IONG , & L IU

System
Baseline
K = 30
K = 50
K = 100
K = 200

MT06
31.77
32.32
31.96
32.26
32.16

MT08
24.89
25.41
25.73
25.53
25.28

Avg
28.33
28.86
28.85
28.90
28.72

Table 8: Experiment results different number topics (K). source-side topic dissimilarity model (DsimSrc) integrated SMT system.
Test Set
MT06
MT08

MonoSrc
0.359
0.232

BiSrc
0.238
0.136

MonoBiSrc
0.297
0.261

Table 9: Hellinger distances MT06/08 test sets Chinese monolingual corpus
(MonoSrc) source part bilingual training data (BiSrc) well combination (MonoBiSrc) terms average document-topic distributions.

integrated SMT system. Experiment results shown Table 8. table,
find using topics able improve model corpora.
Yet another reason may additional monolingual corpus similar test sets
terms topic distributions. order examine hypothesis, inferred document-topic
distributions documents test sets, Chinese monolingual corpus source part
bilingual corpus using topic model ST . average document-topic distributions
obtain four average document-topic distributions MT06, MT08, Chinese monolingual
corpus source part bilingual corpus respectively. average topic distributions approximated corpus-topic distributions four corpora. calculate
Hellinger distances corpus-topic distributions test sets Chinese
monolingual corpus source part bilingual training data, shown Table 9.
table, clearly find additional monolingual corpus much less similar
test sets comparing bilingual training corpus. Hellinger distance test
set MT08 MonoBiSrc corpus almost twice large bilingual training data
(0.261 vs. 0.136). topic model trained enlarged corpus make topic-based
models select translation rules similar documents test sets terms topic
distributions. suggests select additional monolingual data similar
test sets want obtain improvements.
conducted new group experiments empirically examine hypothesis
translating web-domain test set similar additional weblog corpus terms
topics. used web portion NIST MT06 set new development set web
portion NIST MT08 new test set. Results displayed Table 10, show
additional monolingual data improve performance time. suggests
select monolingual corpus similar test sets learn topics topic-based
dissimilarity sensitivity models.
22

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

System
Baseline
DsimSrc + SenSrc + DsimTrg + SenTrg
DsimSrc + SenSrc + DsimTrg + SenTrg

MT08-web
20.45
21.42
21.77

Table 10: Results translating web-domain test set topic-based models trained
data augmented monolingual weblog corpus. features bold topicbased dissimilarity/sensitivity model LDA topic model trained using
combination source/target part large-scale bilingual data corresponding
monolingual corpus. MT08-web web portion NIST MT08 test set.

8. Analysis
section, study details topic-based models translation rule selection
looking differences make target documents individual translation hypotheses.
differences help us gain insights presented models improve translation
quality. analysis, baseline system system enhanced proposed
topic-based models (all four features Section 6 activated) trained large-scale bilingual
data described Section 7.1. notational convenience, hereafter refer baseline
system BASE system enhanced topic-based dissimilarity sensitivity models
TOPSEL.
8.1 Differences Target Documents
order measure impact topic-based models target documents, calculate
Hellinger distances target documents generated BASE / TOPSEL system reference documents generated human terms topics inferred target-side LDA topic
model according following 4 steps. target-side LDA topic model trained target
part large-scale bilingual data described Section 7.1.
Use target-side LDA topic model infer document-topic distribution document
reference translations (called reference distribution).
Use target-side LDA topic model infer document-topic distribution target document generated BASE system (called BASE distribution).
Similarly, obtain
TOPSEL system.

TOPSEL

distribution target document generated

Calculate dissimilarity BASE reference distribution well TOPSEL reference distribution according equation (6). dissimilarities first averaged documents averaged four reference translations.
Table 11 shows calculated dissimilarities. According equation (6), smaller
Hellinger distance two items, similar are. average Hellinger distance
TOPSEL reference documents 0.123 distance BASE reference
23

fiZ HANG , X IAO , X IONG , & L IU

System
BASE
TOPSEL

MT06
0.119
0.116

MT08
0.137
0.129

Avg
0.128
0.123

Table 11: Dissimilarities (measured Hellinger distance) reference documents target
documents generated BASE TOPSEL system terms topics according
equation (6).

similar (+)
Less similar (-)
p<

MT06
49
30
0.05

Table 12: number target documents generated
erence documents BASE.

MT08
72
37
0.01
TOPSEL

more/less similar ref-

documents 0.128. Therefore, target documents generated TOPSEL system
MT06 MT08 similar documents reference translations
baseline system. calculate number target documents generated TOPSEL
more/less similar reference documents BASE based average Hellinger
distances. numbers shown Table 12. According sign test using numbers,
TOPSEL statistically significantly better baseline system terms similarity
translations generated two systems human-generated translations.
8.2 Differences Translation Hypotheses
look deeper translation hypotheses understand models select translation
rules. Table 13 shows three translation examples compare baseline system
enhanced topic-based models. order conduct quantitative comparison, calculate
dissimilarity values (measured Hellinger distance) underlined phrases Table 13 using
topic-based dissimilarity model. dissimilarity values computed projected
target-side rule-topic distributions underlined phrases source-side document-topic
distributions corresponding documents phrase used. values shown
Table 14.
two tables, easily observe system topic-based dissimilarity
model prefers target phrases smaller Hellinger distances documents
occur terms topic distributions. contrast, baseline able use document-level
topic information translation rule selection. Figure 3 shows topic distributions
source-side document, TOPSEL phrase allow BASE phrase permit Eg. 2.
major topics source-side document topic 12 36. TOPSEL phrase allow mainly
distributes 12 different topics9 including topic 12 36 BASE phrase permit
mainly 10 different topics include topic 12.
9. distribution probability topics larger 0.03.

24

fiT OPIC -BASED ISSIMILARITY

Source

ENSITIVITY ODELS

7 8 { "

described northern limit line unlawful .
referred northern limit line legitimate .
Reference pointed northern limit line legitimate .
Source
BASE
would permit love others also accepted people .
TOPSEL
allow love love others also accepted people
Reference would someone allow person loves accept peoples
love time
Source
BASE
present , internet entitled statutory right leave
TOPSEL
present internet enjoy statutory right leave
Reference present internet enjoy rights
BASE

Eg. 1



TOPSEL

#N gC < O<

Eg. 2

8 p k { N |

Eg. 3

Table 13: Translation examples NIST MT06/08 test sets, comparing baseline
system enhanced topic-based models. underlined words highlight
difference enhanced models baseline.
Phrase
unlawful
legitimate
permit
allow
entitled
enjoy

HD
3.08
2.27
3.75
3.47
3.45
3.24

Table 14: Dissimilarity values (measured Hellinger distance) underlined phrases Table 13 projected target-side rule-topic distributions corresponding
source-side document-topic distributions documents calculated topic-based dissimilarity model.

9. Discussion Bilingual Topic Modeling
Although topic models widely adopted monolingual text analysis, bilingual multilingual
topic models less explored, especially tailored multilingual tasks machine
translation. section try provide suggestions bilingual topic modeling
perspective statistical machine translation well practice integration topic models SMT. suggestions listed follows, also future
directions.
Investigation Topic divergences across different languages Cross-language divergences
pervasive become one big challenges machine translation (Dorr, 1994).
language-level divergences hint divergences topic concept level may also exist
across languages. may explain one-to-many topic projection target side
25

fiZ HANG , X IAO , X IONG , & L IU

Figure 3: Topic distributions source-side document (a),
BASE phrase permit shown Eg. 2 Table 13.

TOPSEL

phrase allow (b)

source side better one-to-one mapping. Although Mimno et al. (2009)
studied topic divergences using Wikipedia articles, believe deeper wider
investigation topic divergence needed shed new light build
better bilingual topic models.
Adding linguistic assumptions topic modeling Practices SMT show integrating linguistic knowledge machine translation normally generates better translations
(Chiang et al., 2008). believe adding linguistic assumptions beyond bag-ofwords also improve topic modeling. flexible topic modeling framework allows us
integrate rich linguistic knowledge form features definitely facilitate
application topic models natural language processing.
Joint modeling topic induction synchronous grammar induction Synchronous grammar induction machine translation task automatically learning translation rules
bilingual data (Blunsom, Cohn, Dyer, & Osborne, 2009; Xiao & Xiong, 2013). Bayesian
approaches successfully used topic modeling synchronous grammar induction, joint modeling interesting direction, also benefit grammar
adaptation one domain another domain machine translation.

10. Conclusions
article presented topic-based translation rule selection framework incorporates topic information source target language translation rule disambiguation. Particularly, use topic dissimilarity model select appropriate translation rules
documents according similarities translation rules documents. also adopt
26

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

topic sensitivity model complement topic dissimilarity model order balance translation
rule selection topic-sensitive topic-insensitive rules. order calculate dissimilarities source- target-side topic distributions, project topic distributions target
side onto source-side topic model space new efficient way.
integrated topic-based rule selection models hierarchical phrase-based SMT
system. Experiments medium/large-scale training data show
topic dissimilarity sensitivity model able substantially improve translation
quality terms B LEU improve translation rule selection various types rules (i.e.,
phrase/monotone/reordering rules).
method better previous topic-specific lexicon translation method translation quality decoding speed.
proposed one-to-many projection method also outperforms various methods
one-to-one mapping, marginalization via word alignments on.
want use additional monolingual corpus train topic models, first investigate whether new monolingual corpus similar test data terms topic
distributions.
Topic models provide global document-level information machine translation.
future, would like use topic models address document-level machine translation issues,
coherence cohesion (Barzilay & Lee, 2004; Hardmeier, Nivre, & Tiedemann, 2012).
also want integrate topic-based models linguistically syntax-based machine translation
syntactic translation rule selection (Liu et al., 2006).

Acknowledgments
work sponsored National Natural Science Foundation China projects
61373095 61333018. Qun Lius work partially supported Science Foundation Ireland
(Grant No. 07/CE/I1142) part CNGL Dublin City University. would like thank
three anonymous reviewers insightful comments. corresponding author article
Deyi Xiong.

References
Barzilay, R., & Lee, L. (2004). Catching drift: Probabilistic content models, applications
generation summarization. Susan Dumais, D. M., & Roukos, S. (Eds.), HLT-NAACL
2004: Main Proceedings, pp. 113120, Boston, Massachusetts, USA. Association Computational Linguistics.
Blei, D. M., & Lafferty, J. D. (2007). correlated topic model science. AAS, 1(1), 1735.
Blei, D. M., Ng, A., & Jordan, M. (2003). Latent dirichlet allocation. JMLR, 3, 9931022.

27

fiZ HANG , X IAO , X IONG , & L IU

Blunsom, P., Cohn, T., Dyer, C., & Osborne, M. (2009). gibbs sampler phrasal synchronous
grammar induction. Proceedings Joint Conference 47th Annual Meeting
ACL 4th International Joint Conference Natural Language Processing
AFNLP, pp. 782790, Suntec, Singapore. Association Computational Linguistics.
Boyd-Graber, J., & Blei, D. M. (2009). Multilingual topic models unaligned text. Proceedings
Twenty-Fifth Conference Uncertainty Artificial Intelligence, UAI 09, pp. 7582,
Arlington, Virginia, United States. AUAI Press.
Carpuat, M., & Wu, D. (2007a). phrase sense disambiguation outperforms word sense disambiguation statistical machine translation. Proceedings 11th Conference
Theoretical Methodological Issues Machine Translation, pp. 4352.
Carpuat, M., & Wu, D. (2007b). Improving statistical machine translation using word sense disambiguation. Proceedings 2007 Joint Conference Empirical Methods Natural
Language Processing Computational Natural Language Learning (EMNLP-CoNLL), pp.
6172, Prague, Czech Republic. Association Computational Linguistics.
Chan, Y. S., Ng, H. T., & Chiang, D. (2007). Word sense disambiguation improves statistical machine translation. Proceedings 45th Annual Meeting Association Computational Linguistics, pp. 3340, Prague, Czech Republic. Association Computational
Linguistics.
Chiang, D. (2005). hierarchical phrase-based model statistical machine translation. Proc.
ACL 2005.
Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33(2), 201
228.
Chiang, D., Marton, Y., & Resnik, P. (2008). Online large-margin training syntactic structural
translation features. Proceedings 2008 Conference Empirical Methods Natural Language Processing, pp. 224233, Honolulu, Hawaii. Association Computational
Linguistics.
Clark, J. H., Dyer, C., Lavie, A., & Smith, N. A. (2011). Better hypothesis testing statistical
machine translation: Controlling optimizer instability. Proceedings 49th Annual
Meeting Association Computational Linguistics: Human Language Technologies,
pp. 176181, Portland, Oregon, USA.
Dorr, B. J. (1994). Machine translation divergences: formal description proposed solution.
Computational Linguistics, 20(4), 597633.
Foster, G., & Kuhn, R. (2007). Mixture-model adaptation SMT. Proc. Second Workshop
Statistical Machine Translation, pp. 128135, Prague, Czech Republic.
Gong, Z., Zhang, M., & Zhou, G. (2011). Cache-based document-level statistical machine translation. Proc. EMNLP 2011.
Gong, Z., Zhang, Y., & Zhou, G. (2010). Statistical machine translation based LDA. Proc.
IUCS 2010, p. 286 290.



Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings National
Academy Sciences, 101(Suppl. 1), 52285235.

28

fiT OPIC -BASED ISSIMILARITY



ENSITIVITY ODELS

Hardmeier, C., Nivre, J., & Tiedemann, J. (2012). Document-wide decoding phrase-based statistical machine translation. Proceedings 2012 Joint Conference Empirical
Methods Natural Language Processing Computational Natural Language Learning,
pp. 11791190, Jeju Island, Korea. Association Computational Linguistics.
He, Z., Liu, Q., & Lin, S. (2008). Improving statistical machine translation using lexicalized rule
selection. Proceedings 22nd International Conference Computational Linguistics
(Coling 2008), pp. 321328, Manchester, UK. Coling 2008 Organizing Committee.
Hofmann, T. (1999). Probabilistic latent semantic analysis. Proc. UAI 1999, pp. 289296.
Koehn, P. (2004). Statistical significance tests machine translation evaluation. Proceedings
EMNLP 2004, pp. 388395, Barcelona, Spain.
Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. Proc. HLT-NAACL
2003.
Lin, J. (2006). Divergence measures based Shannon entropy. IEEE Trans. Inf. Theor., 37(1),
145151.
Liu, Q., He, Z., Liu, Y., & Lin, S. (2008). Maximum entropy based rule selection model syntaxbased statistical machine translation. Proceedings 2008 Conference Empirical Methods Natural Language Processing, pp. 8997, Honolulu, Hawaii. Association
Computational Linguistics.
Liu, Y., Liu, Q., & Lin, S. (2006). Tree-to-string alignment template statistical machine translation. Proc. ACL 2006.
Mimno, D., Wallach, H. M., Naradowsky, J., Smith, D. A., & McCallum, A. (2009). Polylingual
topic models. Proc. EMNLP 2009.
Och, F. J., & Ney, H. (2002). Discriminative training maximum entropy models statistical
machine translation. Proc. ACL 2002.
Och, F. J. (2003). Minimum error rate training statistical machine translation. Proc. ACL 2003.
Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignment models.
Computational Linguistics, 29(1), 1951.
Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: method automatic evaluation
machine translation. Proc. ACL 2002.
Ruiz, N., & Federico, M. (2011). Topic adaptation lecture translation bilingual latent
semantic models. Proceedings Sixth Workshop Statistical Machine Translation.
Schler, J., Koppel, M., Argamon, S., & Pennebaker, J. W. (2006). Effects age gender
blogging. AAAI Spring Symposium: Computational Approaches Analyzing Weblogs, pp.
199205.
Stolcke, A. (2002). SRILM extensible language modeling toolkit. Proc. ICSLP 2002.
Tam, Y.-C., Lane, I. R., & Schultz, T. (2007). Bilingual LSA-based adaptation statistical machine
translation. Machine Translation, 21(4), 187207.
Tiedemann, J. (2010). Context adaptation statistical machine translation using models exponentially decaying cache. Proceedings 2010 Workshop Domain Adaptation

29

fiZ HANG , X IAO , X IONG , & L IU

Natural Language Processing, pp. 815, Uppsala, Sweden. Association Computational
Linguistics.
Ture, F., Oard, D. W., & Resnik, P. (2012). Encouraging consistent translation choices. Proceedings 2012 Conference North American Chapter Association Computational Linguistics: Human Language Technologies, pp. 417426, Montreal, Canada. Association Computational Linguistics.
Xiao, T., Zhu, J., Yao, S., & Zhang, H. (2011). Document-level consistency verification machine
translation. Proceedings 2011 MT summit XIII, pp. 131138, Xiamen, China.
Xiao, X., & Xiong, D. (2013). Max-margin synchronous grammar induction machine translation. Proceedings 2013 Conference Empirical Methods Natural Language
Processing, pp. 255264, Seattle, Washington, USA. Association Computational Linguistics.
Xiao, X., Xiong, D., Zhang, M., Liu, Q., & Lin, S. (2012). topic similarity model hierarchical phrase-based translation. Proceedings 50th Annual Meeting Association
Computational Linguistics (Volume 1: Long Papers), pp. 750758, Jeju Island, Korea.
Association Computational Linguistics.
Xiong, D., Zhang, M., & Li, H. (2012). Modeling translation predicate-argument structure
SMT. Proceedings 50th Annual Meeting Association Computational
Linguistics (Volume 1: Long Papers), pp. 902911, Jeju Island, Korea. Association Computational Linguistics.
Zhao, B., & Xing, E. P. (2007). HM-BiTAM: Bilingual topic exploration, word alignment,
translation. Proc. NIPS 2007.
Zhao, B., & Xing, E. P. (2006). BiTAM: Bilingual topic admixture models word alignment.
Proc. ACL 2006.

30

fiJournal Artificial Intelligence Research 50 (2014) 723762

Submitted 12/13; published 08/14

Sentiment Analysis Short Informal Texts
Svetlana Kiritchenko
Xiaodan Zhu
Saif M. Mohammad

Svetlana.Kiritchenko@nrc-cnrc.gc.ca
Xiaodan.Zhu@nrc-cnrc.gc.ca
Saif.Mohammad@nrc-cnrc.gc.ca

National Research Council Canada
1200 Montreal Rd., Ottawa, ON, Canada

Abstract
describe state-of-the-art sentiment analysis system detects (a) sentiment
short informal textual messages tweets SMS (message-level task) (b)
sentiment word phrase within message (term-level task). system
based supervised statistical text classification approach leveraging variety surfaceform, semantic, sentiment features. sentiment features primarily derived
novel high-coverage tweet-specific sentiment lexicons. lexicons automatically
generated tweets sentiment-word hashtags tweets emoticons.
adequately capture sentiment words negated contexts, separate sentiment lexicon
generated negated words.
system ranked first SemEval-2013 shared task Sentiment Analysis Twitter (Task 2), obtaining F-score 69.02 message-level task 88.93
term-level task. Post-competition improvements boost performance F-score
70.45 (message-level task) 89.50 (term-level task). system also obtains state-ofthe-art performance two additional datasets: SemEval-2013 SMS test set
corpus movie review excerpts. ablation experiments demonstrate use
automatically generated lexicons results performance gains 6.5 absolute
percentage points.

1. Introduction
Sentiment Analysis involves determining evaluative nature piece text. example, product review express positive, negative, neutral sentiment (or polarity).
Automatically identifying sentiment expressed text number applications, including tracking sentiment towards products, movies, politicians, etc., improving customer
relation models, detecting happiness well-being, improving automatic dialogue systems. past decade, substantial growth use microblogging
services Twitter access mobile phones world-wide. Thus, tremendous
interest sentiment analysis short informal texts, tweets SMS messages,
across variety domains (e.g., commerce, health, military intelligence, disaster management).
Short informal textual messages bring new challenges sentiment analysis.
limited length, usually spanning one sentence less. tend many
misspellings, slang terms, shortened forms words. also special markers
hashtags used facilitate search, also indicate topic sentiment.
paper describes state-of-the-art sentiment analysis system addressing two tasks:
(a) detecting sentiment short informal textual messages (message-level task)
c
2014
National Research Council Canada. rights reserved.

fiKiritchenko, Zhu, & Mohammad

(b) detecting sentiment word phrase within message (term-level task).
system based supervised statistical text classification approach leveraging
variety surface-form, semantic, sentiment features. Given limited amounts
training data, statistical sentiment analysis systems often benefit use manually
automatically built sentiment lexicons. Sentiment lexicons lists words (and phrases)
prior associations positive negative sentiments. lexicons additionally
provide sentiment score term indicate strength evaluative intensity. Higher
scores indicate greater intensity. example, entry great (positive, 1.2) states
word great positive polarity sentiment score 1.2. entry acceptable
(positive, 0.1) specifies word acceptable positive polarity intensity
lower word great.
sentiment analysis system, utilize three freely available, manually created,
general-purpose sentiment lexicons. addition, generated two high-coverage tweetspecific sentiment lexicons 2.5 million tweets using sentiment markers within
them. lexicons automatically capture many peculiarities social media language
common intentional unintentional misspellings (e.g., gr8, lovin, coul, holys**t),
elongations (e.g., yesssss, mmmmmmm, uugghh), abbreviations (e.g., lmao, wtf ).
also include words usually considered expressing sentiment,
often associated positive/negative feelings (e.g., party, birthday, homework ).
Sentiment lexicons provide knowledge prior polarity (positive, negative, neutral)
word, i.e., polarity contexts. However, particular context prior
polarity change. One obvious contextual sentiment modifier negation.
negated context, many words change polarity least evaluative intensity.
example, word good often used express positive attitude whereas phrase
good clearly negative. conventional way addressing negation sentiment analysis
reverse polarity word, i.e. change words sentiment score
(Kennedy & Inkpen, 2005; Choi & Cardie, 2008). However, several studies pointed
inadequacy solution (Kennedy & Inkpen, 2006; Taboada, Brooke, Tofiloski,
Voll, & Stede, 2011). show experiments Section 4.3 many positive
terms, though all, tend reverse polarity negated, whereas negative
terms remain negative change evaluative intensity. example, word
terrible conveys strong negative sentiment whereas phrase wasnt terrible mildly
negative. Also, degree intensity shift varies term term positive negative terms. adequately capture effects negation different terms,
propose corpus-based statistical approach estimate sentiment scores individual
terms presence negation. build two lexicons: one words negated contexts
(Negated Context Lexicon) one words affirmative (non-negated) contexts (Affirmative Context Lexicon). word (or phrase) two scores, one Negated
Context Lexicon one Affirmative Context Lexicon. analyzing sentiment textual message, use scores Negated Context Lexicon words
appearing negated context scores Affirmative Context Lexicon words
appearing affirmative context.
Experiments carried asses both, performance overall sentiment
analysis system well quality value automatically created tweet-specific
lexicons. intrinsic evaluation lexicons, entries compared
724

fiSentiment Analysis Short Informal Texts

entries manually created lexicons. Also, human annotators asked rank
subset lexicon entries degree association positive negative sentiment
ranking compared ranking produced automatic lexicon.
experiments observe high agreement automatic manual sentiment
annotations.
extrinsic evaluation performed two tasks: unsupervised supervised sentiment analysis. supervised task, assess performance full sentiment
analysis system examine impact features derived automatic lexicons
overall performance. testbed, use datasets provided SemEval2013 competition Sentiment Analysis Twitter (Wilson, Kozareva, Nakov, Rosenthal,
Stoyanov, & Ritter, 2013).1 datasets provided two tasks, message-level task
term-level task, two domains, tweets SMS. However, training data
available tweets. Among 77 submissions 44 teams, system placed first
competition tasks tweet test set, obtaining macro-averaged F-score
69.02 message-level task 88.93 term-level task. Post-competition improvements system boost performance F-score 70.45 (message-level task)
89.50 (term-level task). also applied classifier SMS test set without
tuning. classifier obtained first position identifying sentiment
SMS messages (F-score 68.46) second position detecting sentiment
terms within SMS messages (F-score 88.00; 0.39 points behind first-ranked system). post-competition improvements, system achieves F-score 69.77
message-level task F-score 88.20 term-level task test set.
addition, evaluate performance sentiment analysis system domain
movie review excerpts (message-level task only). system re-trained collection
7,800 positive negative sentences extracted movie reviews. applied
test set unseen sentences, system able correctly classify 85.5% test
set. result exceeds best result obtained dataset recursive deep learning
approach requires access sentiment labels syntactic phrases trainingdata sentences (Socher, Perelygin, Wu, Chuang, Manning, Ng, & Potts, 2013).
message-level task, make use sentiment labels phrases training data,
often unavailable real-world applications.
ablation experiments reveal automatically built lexicons gave system
competitive advantage SemEval-2013. use new lexicons results gains
6.5 percentage points gains obtained use features.
Furthermore, show lexicons built specifically negated contexts better model
negation reversing polarity approach.
main contributions paper three-fold. First, present sentiment
analysis system achieves state-of-the-art performance three domains: tweets, SMS,
movie review excerpts. system replicated using freely available resources.
Second, describe process creating automatic, tweet-specific lexicons
demonstrate superior predictive power several manually automatically created general-purpose lexicons. Third, analyze impact negation sentiment
propose empirical method estimate sentiment words negated contexts
1. SemEval international forum natural-language shared tasks. competition refer
SemEval-2013 Task 2 (http://www.cs.york.ac.uk/semeval-2013/task2).

725

fiKiritchenko, Zhu, & Mohammad

creating separate sentiment lexicon negated words. automatic lexicons described
paper made available research community.2
paper organized follows. begin description related work Section 2. Next, describe sentiment analysis task data used research
(Section 3). Section 4 presents sentiment lexicons used system: existing manually
created, general-purpose lexicons (Section 4.1) automatic, tweet-specific lexicons
(Section 4.2). lexicons built affirmative negated contexts described Section 4.3. detailed description supervised sentiment analysis system, including
classification method feature sets, presented Section 5. Section 6 provides
results evaluation experiments. First, compare automatically created lexicons human annotations derived manual lexicons well collected
Amazons Mechanical Turk service3 (Section 6.1). Next, evaluate new lexicons
extrinsic task unsupervised sentiment analysis (Section 6.2.1). purpose
experiments compare predictive capacity individual lexicons without influence factors. Then, Section 6.2.2 assess performance entire
supervised sentiment analysis system examine contribution features derived
lexicons overall performance. Finally, conclude present directions
future work Section 7.

2. Related Work
last decade, explosion work exploring various aspects
sentiment analysis: detecting subjective objective sentences; classifying sentences
positive, negative, neutral; detecting person expressing sentiment target
sentiment; detecting emotions joy, fear, anger; visualizing sentiment
text; applying sentiment analysis health, commerce, disaster management.
Surveys Pang Lee (2008) Liu Zhang (2012) give summary many
approaches.
Sentiment analysis systems applied many different kinds texts including
customer reviews, news paper headlines (Bellegarda, 2010), novels (Boucouvalas, 2002;
John, Boucouvalas, & Xu, 2006; Francisco & Gervas, 2006; Mohammad & Yang, 2011),
emails (Liu, Lieberman, & Selker, 2003; Mohammad & Yang, 2011), blogs (Neviarouskaya,
Prendinger, & Ishizuka, 2011; Genereux & Evans, 2006; Mihalcea & Liu, 2006), tweets
(Mohammad, 2012). Often systems cater specific needs text
formality versus informality, length utterances, etc. Sentiment analysis systems
developed specifically tweets include Pak Paroubek (2010), Agarwal, Xie,
Vovsha, Rambow, Passonneau (2011), Thelwall, Buckley, Paltoglou (2011), Brody
Diakopoulos (2011), Aisopos, Papadakis, Tserpes, Varvarigou (2012), Bakliwal,
Arora, Madhappan, Kapre, Singh, Varma (2012). recent survey Martnez-Camara,
Martn-Valdivia, Urenalopez, Montejoraez (2012) provides overview research
sentiment analysis tweets.
Several manually created sentiment resources successfully applied sentiment
analysis. General Inquirer sentiment labels 3,600 terms (Stone, Dunphy,
2. www.purl.com/net/sentimentoftweets
3. https://www.mturk.com/mturk/welcome

726

fiSentiment Analysis Short Informal Texts

Smith, Ogilvie, & associates, 1966). Hu Liu (2004) manually labeled 6,800
words used detecting sentiment customer reviews. MPQA Subjectivity
Lexicon, draws General Inquirer sources, sentiment labels
8,000 words (Wilson, Wiebe, & Hoffmann, 2005). NRC Emotion Lexicon
sentiment emotion labels 14,000 words (Mohammad & Turney, 2010).
labels compiled Mechanical Turk annotations.
Semi-supervised automatic methods also proposed detect polarity
words. Hatzivassiloglou McKeown (1997) proposed algorithm determine
polarity adjectives. SentiWordNet (SWN) created using supervised classifiers well
manual annotation (Esuli & Sebastiani, 2006). Turney Littman (2003) proposed
minimally supervised algorithm calculate polarity word determining
tendency co-occur small set positive seed words greater tendency
co-occur small set negative seed words. Mohammad, Dunne, Dorr (2009)
automatically generated sentiment lexicon 60,000 words thesaurus.
use several lexicons system. addition, create two new sentiment
lexicons tweets using hashtags emoticons. Section 6, show tweetspecific lexicons higher coverage better predictive power lexicons
mentioned earlier.
Since manual annotation data costly, distant supervision techniques actively applied domain short informal texts. User-provided indications emotional
content, emoticons, emoji, hashtags, used noisy sentiment labels.
example, Go, Bhayani, Huang (2009) use tweets emoticons labeled data
supervised training. Emoticons :) considered positive labels tweets
emoticons :( used negative labels. Davidov, Tsur, Rappoport (2010)
Kouloumpis, Wilson, Moore (2011) use certain seed hashtag words #cute
#sucks labels positive negative sentiment. Mohammad (2012) developed classifier detect emotions using tweets emotion word hashtags (e.g., #anger, #surprise)
labeled data.
system too, make use emoticons hashtag words signals positive
negative sentiment. collected 775,000 sentiment-word hashtagged tweets used
1.6 million emoticon tweets collected Go et al. (2009). However, unlike previous research,
generate sentiment lexicons datasets use (along relatively
small hand-labeled training dataset) train supervised classifier. approach
following benefits. First, allows us incorporate large amounts noisily labeled data
quickly efficiently. Second, classification system robust introduced noise
noisy data incorporated directly training instances indirectly
features. Third, generated sentiment lexicons easily distributed among
research community employed applications domains (Kiritchenko,
Zhu, Cherry, & Mohammad, 2014).
Negation plays important role determining sentiment. Automatic negation handling involves identifying negation word not, determining scope negation
(which words affected negation word), finally appropriately capturing
impact negation. (See work Jia, Yu, Meng (2009), Wiegand, Balahur, Roth,
Klakow, Montoyo (2010), Lapponi, Read, Ovrelid (2012) detailed analyses
negation handling.) Traditionally, negation word determined small hand727

fiKiritchenko, Zhu, & Mohammad

crafted list (Taboada et al., 2011). scope negation often assumed begin
word following negation word next punctuation mark end
sentence (Polanyi & Zaenen, 2004; Kennedy & Inkpen, 2005). sophisticated methods
detect scope negation semantic parsing also proposed (Li, Zhou,
Wang, & Zhu, 2010).
common way capture impact negation reverse polarities
sentiment words scope negation. Taboada et al. (2011) proposed shift
sentiment score term negated context towards opposite polarity fixed
amount. However, experiments shift-score model agree human
judgment many cases, especially negated negative terms. complex approaches,
recursive deep models, address negation semantic composition (Socher,
Huval, Manning, & Ng, 2012; Socher et al., 2013). recursive deep models work
bottom-top fashion parse-tree structure sentence infer sentiment label
sentence composition sentiment expressed constituting parts: words
phrases. models require hand-crafted features semantic knowledge,
list negation words. However, computationally intensive need
substantial additional annotations (word phrase-level sentiment labeling) produce
competitive results (Socher et al., 2013). paper, propose simple corpus-based
statistical method estimate sentiment scores negated words. shown
Section 6.2.2, simple method able achieve level accuracy recursive
deep learning approach. Additionally, analyze impact negation sentiment scores
common sentiment terms.
promote research sentiment analysis short informal texts establish
common ground comparison different approaches, international competition
organized Conference Semantic Evaluation Exercises (SemEval-2013) (Wilson
et al., 2013). organizers created shared tweets training, development,
testing. also provided second test set consisting SMS messages. purpose
out-of-domain test set assess ability systems trained tweets
generalize types short informal texts. competition attracted 44 teams;
48 submissions 34 teams message-level task 29 submissions
23 teams term-level task. participants (including top 3 systems task)
chose supervised machine learning approach exploiting variety features derived
ngrams, stems, punctuation, POS tags, Twitter-specific encodings (e.g., emoticons,
hashtags, abbreviations). one top-performing systems entirely rule-based
hand-written rules (Reckman, Baird, Crawford, Crowell, Micciulla, Sethi, & Veress,
2013). Twitter-specific pre-processing (e.g., tokenization, normalization) well negation
handling commonly applied. Almost systems benefited sentiment lexicons:
MPQA Subjectivity Lexicon, SentiWordNet, others. Existing, low-coverage lexicons
sometimes extended distributionally similar words (Proisl, Greiner, Evert, &
Kabashi, 2013) sentiment-associated words collected noisily labeled data (Becker,
Erhart, Skiba, & Matula, 2013). extended lexicons, however, still order
magnitude smaller tweet-specific lexicons created. full results
competition details refer reader Wilson et al. (2013).
research approaches sentiment analysis two-tier problem: first piece text
marked either objective subjective, subjective text assessed
728

fiSentiment Analysis Short Informal Texts

determine whether positive, negative, neutral (Wiebe, Wilson, & Cardie, 2005;
Choi & Cardie, 2010; Johansson & Moschitti, 2013; Yang & Cardie, 2013). However,
lead propagation errors (for example, system may mark subjective text
objective). Further, one argue even objective statements express sentiment
(for example, sales Blackberries 0.002% used 5 years back).
model sentiment directly three-class problem: positive, negative, neutral.
Also, paper focuses sentiment analysis alone consider task
associating sentiment targets. interesting work studying
latter problem (e.g., Jiang, Yu, Zhou, Liu, & Zhao, 2011; Sauper & Barzilay, 2013).
(Kiritchenko et al., 2014) show approach adapted identify
sentiment specified target. system ranked first SemEval-2014 shared task
Aspect Based Sentiment Analysis.

3. Task Data Description
work, follow definition task use data provided SemEval2013 competition: Sentiment Analysis Twitter (Wilson et al., 2013). competition
two tasks: message-level task term-level task. objective messagelevel task detect whether whole message conveys positive, negative, neutral
sentiment. objective term-level task detect whether given target term (a
single word multi-word expression) conveys positive, negative, neutral sentiment
context message. Note term may express different sentiments
different contexts. example, word unpredictable expresses positive sentiment
sentence movie unpredictable ending; whereas, expresses negative sentiment
sentence car unpredictable steering.
Two test sets one tweets one SMS messages provided
participants task. Training development data available tweets.
briefly describe data collected annotated (for details see
task description paper (Wilson et al., 2013)). Tweets collected public
streaming Twitter API period one year: January 2012 January 2013.
reduce data skew towards neutral class, messages contain polarity
word listed SentiWordNet 3.0 discarded. remaining messages annotated
sentiment Mechanical Turk.4 annotator mark positive, negative,
neutral parts message well provide overall polarity label message.
Later, annotations combined intersection term-level task
majority voting message-level task. details data collection annotation
released participants competition.
data characteristics tasks shown Table 1. training set
distributed tweet ids download script. However, tweets accessible.
example, Twitter user could deleted messages, thus messages
would available. Table 1 shows number training examples able
download. development test sets provided full FTP.
4. Messages presented annotators polarity words marked way.

729

fiKiritchenko, Zhu, & Mohammad

Table 1: Data statistics SemEval-2013 training set, development set two testing
sets. # tokens per mess. denotes average number tokens per message
dataset. Vocab. size represents number unique tokens excluding
punctuation numerals.

Dataset
Positive
Message-level task:
Training set
3,045 (37%)
Development set
575 (35%)
Tweet test set
1,572 (41%)
SMS test set
492 (23%)
Term-level task:
Training set
4,831 (62%)
Development set
648 (57%)
Tweet test set
2,734 (62%)
SMS test set
1,071 (46%)

Number instances
Negative
Neutral
1,209
340
601
394

(15%)
(20%)
(16%)
(19%)

2,540
430
1,541
1,104

(33%)
(38%)
(35%)
(47%)

4,004
739
1,640
1,208

(48%)
(45%)
(43%)
(58%)

385
57
160
159

(5%)
(5%)
(3%)
(7%)

Total

# tokens
per mess.

Vocab.
size

8,258
1,654
3,813
2,094

22.09
22.19
22.15
18.05

21,848
6,543
12,977
3,513

7,756
1,135
4,435
2,334

22.55
22.93
22.63
19.95

15,238
3,909
10,383
2,979

tweets comprised regular English-language words well Twitter-specific
terms, emoticons, URLs, creative spellings. Using WordNet 3.05 (147,278
word types) supplemented large list stop words (571 words)6 repository
English-language words, found 45% vocabulary tweet datasets
out-of-dictionary terms. out-of-dictionary terms fall different categories, e.g.,
named entities (names people, places, companies, etc.) found WordNet, hashtags,
user mentions, etc. use Carnegie Mellon University (CMU) Twitter NLP tool
automatically identify categories. tool shown achieve 89% tagging accuracy
tweet data (Gimpel, Schneider, OConnor, Das, Mills, Eisenstein, Heilman, Yogatama,
Flanigan, & Smith, 2011). Table 2 shows distribution out-of-dictionary terms
category.7 One observe out-of-dictionary terms named entities
well user mentions, URLs, hashtags. also moderate amount creatively
spelled regular English words slang words used nouns, verbs, adjectives.
SMS test set, out-of-dictionary terms constitute smaller proportion vocabulary,
25%. mostly named entities, interjections, creative spellings, slang.
SemEval-2013 training development data used train supervised sentiment analysis system presented Section 5. performance system evaluated
test sets, tweets SMS (Section 6.2.2). test data also used
experiments comparing performance sentiment lexicons unsupervised settings
(Section 6.2.1).
5. http://wordnet.princeton.edu
6. SMART stopword list built Gerard Salton Chris Buckley SMART information retrieval
system Cornell University (http://www.lextek.com/manuals/onix/stopwords2.html) used.
7. percentages columns sum 100% terms used multiple
categories (e.g., noun verb).

730

fiSentiment Analysis Short Informal Texts

Table 2: distribution out-of-dictionary tokens category SemEval-2013
tweet SMS test sets.
Category tokens
named entities
user mentions
URLs
hashtags
interjections
emoticons
nouns
verbs
adjectives
adverbs
others

Tweet test set
31.84%
21.23%
16.92%
10.94%
2.56%
1.40%
8.52%
3.05%
1.43%
0.70%
4.00%

SMS test set
32.63%
0.11%
0.84%
0%
10.32%
1.89%
25.47%
18.95%
4.84%
6.21%
15.69%

addition SemEval-2013 datasets, evaluate system dataset movie
review excerpts (Socher et al., 2013). task predict sentiment label (positive
negative) given sentence, extracted longer movie review (message-level task).
dataset comprised 4,963 positive 4,650 negative sentences split training (6,920 sentences), development (872 sentences), test (1,821 sentences) sets. Since
detailed phrase-level annotations available real-world applications, use
sentence-level annotations ignore phrase-level annotations parse-tree
structures sentences provided data. train sentiment analysis system
training development subsets evaluate performance test subset.
results experiments reported Section 6.2.2.

4. Sentiment Lexicons Used System
4.1 Existing, General-Purpose, Manually Created Sentiment Lexicons
lexicons created manual annotation tend domain free
include thousand terms. lexicons use include NRC Emotion Lexicon
(Mohammad & Turney, 2010), Bing Lius Lexicon (Hu & Liu, 2004), MPQA Subjectivity Lexicon (Wilson et al., 2005). NRC Emotion Lexicon comprised frequent
English nouns, verbs, adjectives, adverbs annotated eight emotions (joy, sadness,
anger, fear, disgust, surprise, trust, anticipation) well positive negative
sentiment. Bing Lius Lexicon provides list positive negative words manually extracted customer reviews. MPQA Subjectivity Lexicon contains words marked
prior polarity (positive negative) discrete strength evaluative intensity
(strong weak). Entities lexicons come real-valued score indicating
fine-grained evaluative intensity.
731

fiKiritchenko, Zhu, & Mohammad

4.2 New, Tweet-Specific, Automatically Generated Sentiment Lexicons
4.2.1 Hashtag Sentiment Lexicon
Certain words tweets specially marked hashtag (#) indicate topic
sentiment. Mohammad (2012) showed hashtagged emotion words #joy,
#sad, #angry, #surprised good indicators tweet whole (even without
hashtagged emotion word) expressing emotion. adapted idea
create large corpus positive negative tweets. corpus automatically
generated high-coverage, tweet-specific sentiment lexicon described below.
polled Twitter API every four hours April December 2012 search
tweets either positive-word hashtag negative-word hashtag. collection
77 seed words closely associated positive negative sentiment #good,
#excellent, #bad, #terrible used (30 positive 47 negative). terms
chosen entries positive negative Rogets Thesaurus8 . 2 million tweets
collected total. used metadata tag iso language code identify English
tweets. Since tag always reliable, additionally discarded tweets
least two valid English content words Rogets Thesaurus.9 step also
helped discard short tweets tweets large proportion misspelled words.
set 775,000 remaining tweets, refer Hashtag Sentiment Corpus,
used generate large wordsentiment association lexicon. tweet considered
positive one 30 positive hashtagged seed words, negative one
47 negative hashtagged seed words. sentiment score term w calculated
pseudo-labeled tweets shown below:
Sentiment Score (w) = PMI (w , positive) PMI (w , negative)

(1)

PMI stands pointwise mutual information:
PMI (w , positive) = log2

freq (w , positive) N
freq (w ) freq (positive)

(2)

freq (w, positive) number times term w occurs positive tweets, freq (w)
total frequency term w corpus, freq (positive) total number tokens
positive tweets, N total number tokens corpus. PMI (w, negative)
calculated similar way. Thus, equation 1 simplified to:
Sentiment Score (w) = log2

freq (w , positive) freq (negative)
freq (w , negative) freq (positive)

(3)

Since PMI known poor estimator association low-frequency events,
ignore terms occurred less five times (positive negative) group
tweets.10
8. http://www.gutenberg.org/ebooks/10681
9. word thesaurus considered content word exception words
SMART stopword list.
10. threshold five occurrences least one class (positive negative) applied
automatic tweet-specific lexicons discussed paper. thresholding sentiment
score.

732

fiSentiment Analysis Short Informal Texts

positive sentiment score indicates greater overall association positive sentiment,
whereas negative score indicates greater association negative sentiment.
magnitude indicative degree association. Note exist numerous
methods estimate degree association term category (e.g., cross entropy,
Chi-squared, information gain). chosen PMI simple robust
successfully applied number NLP tasks (Turney, 2001; Turney &
Littman, 2003).
final lexicon, refer Hashtag Sentiment Base Lexicon (HS Base)
entries 39,413 unigrams 178,851 bigrams. Entries also generated
unigramunigram, unigrambigram, bigrambigram pairs necessarily
contiguous tweets corpus. Pairs least one terms punctuation (e.g.,
,, ?, .), user mention, URL, function word (e.g., a, the, and)
removed. lexicon entries 308,808 non-contiguous pairs.
4.2.2 Sentiment140 Lexicon
Sentiment140 Corpus (Go et al., 2009) collection 1.6 million tweets contain
emoticons. tweets labeled positive negative according emoticon.
generated Sentiment140 Base Lexicon (S140 Base) corpus manner
described hashtagged tweets using Equation 1. lexicon entries
65,361 unigrams, 266,510 bigrams, 480,010 non-contiguous pairs. following
section, build proposed approach create separate lexicons terms
affirmative contexts terms negated contexts.
4.3 Affirmative Context Negated Context Lexicons
word negated context different evaluative nature word
affirmative (non-negated) context. difference may include change polarity
category (positive becomes negative vice versa), evaluative intensity, both.
example, highly positive words (e.g., great) negated tend experience both, polarity
change intensity decrease, forming mildly negative phrases (e.g., great).
hand, many strong negative words (e.g., terrible) negated keep negative
polarity shift intensity. conventional approach reversing polarity
able handle cases properly.
propose empirical method determine sentiment words presence
negation. create separate lexicons affirmative negated contexts. way, two
sentiment scores term w computed: one affirmative contexts another
negated contexts. lexicons created follows. Hashtag Sentiment Corpus
split two parts: Affirmative Context Corpus Negated Context Corpus. Following
work Pang, Lee, Vaithyanathan (2002), define negated context segment
tweet starts negation word (e.g., no, shouldnt) ends one
punctuation marks: ,, ., :, ;, !, ?. list negation words adopted
Christopher Potts sentiment tutorial.11 Thus, part tweet marked negated
included Negated Context Corpus rest tweet becomes part
Affirmative Context Corpus. sentiment label tweet kept unchanged
11. http://sentiment.christopherpotts.net/lingstruc.html

733

fiKiritchenko, Zhu, & Mohammad

Table 3: Example sentiment scores Sentiment140 Base, Affirmative Context
(AffLex) Negated Context (NegLex) Lexicons.
Term

Sentiment140 Lexicons
Base AffLex NegLex

Positive terms
great
beautiful
nice
good
honest

1.177
1.049
0.974
0.825
0.391

1.273
1.112
1.149
1.167
0.431

-0.367
0.217
-0.912
-1.414
-0.123

Negative terms
terrible
shame
bad
ugly
negative

-1.766
-1.457
-1.297
-0.899
-0.090

-1.850
-1.548
-1.674
-0.964
-0.261

-0.890
-0.722
0.021
-0.772
0.389

corpora. Then, generate Affirmative Context Lexicon (HS AffLex)
Affirmative Context Corpus Negated Context Lexicon (HS NegLex)
Negated Context Corpus using technique described Section 4.2. refer
sentiment score calculated Affirmative Context Corpus score AffLex (w )
score calculated Negated Context Corpus score NegLex (w ). Similarly,
Sentiment140 Affirmative Context Lexicon (S140 AffLex) Sentiment140 Negated
Context Lexicon (S140 NegLex) built Affirmative Context Negated
Context parts Sentiment140 tweet corpus. employ lexicons separate
dataset, apply technique split message affirmative negated
contexts match words affirmative contexts Affirmative Context
Lexicons words negated contexts Negated Context Lexicons.
Computing sentiment score term w affirmative contexts makes
score AffLex (w ) precise since longer polluted negation. Positive terms get
stronger positive scores negative terms get stronger negative scores. Furthermore,
first time, create lexicons negated terms compute score NegLex (w ) reflects behaviour words presence negation. Table 3 shows examples
positive negative terms sentiment scores Sentiment140 Base, Affirmative Context (AffLex) Negated Context (NegLex) Lexicons. Fig. 1, visualize
relationship score AffLex (w ) score NegLex (w ) set words manually annotated sentiment MPQA Subjectivity Lexicon. x-axis score AffLex (w ),
sentiment score term w Sentiment140 Affirmative Context Lexicon; y-axis
score NegLex (w ), sentiment score term w Sentiment140 Negated Context
Lexicon. Dots plot correspond words occur MPQA Subjectivity Lexicon, Sentiment140 Affirmative Context Lexicon, Sentiment140 Negated
Context Lexicon. Furthermore, discard terms whose polarity category (positive
negative) Sentiment140 Affirmative Context Lexicon match polarity
MPQA Subjectivity Lexicon. observe negated, 76% positive terms
734

fiSentiment Analysis Short Informal Texts

3

scoreNegLex(w)

2

1

scoreAffLex(w)
0
-4.5

-3.5

-2.5

-1.5

-0.5

0.5

1.5

2.5

3.5

4.5

-1

-2

-3

Figure 1: sentiment scores Sentiment140 AffLex Sentiment140 NegLex
480 positive 486 negative terms MPQA Subjectivity Lexicon.
x-axis score AffLex (w ), sentiment score term w Sentiment140
Affirmative Context Lexicon; y-axis score NegLex (w ), sentiment score
term w Sentiment140 Negated Context Lexicon. dot corresponds
one (positive negative) term. graph shows positive negative terms
negated tend convey negative sentiment. Negation affects sentiment
differently term.

reverse polarity whereas 82% negative terms keep polarity orientation
shift sentiment scores. (This behaviour agrees well human judgments
study Taboada et al. (2011).) Changes evaluative intensity vary term
term. example, score NegLex (good ) < score AffLex (good ) whereas score NegLex (great) >
score AffLex (great).
also compiled list 596 antonym pairs WordNet compare scores
terms Sentiment140 Affirmative Context Lexicon scores terms
antonyms Sentiment140 Negated Context Lexicon. found 51% negated
positive terms less negative corresponding antonyms (e.g.,
score NegLex (good ) > score AffLex (bad )), 95% negated negative terms negative
positive antonyms (e.g., score NegLex (ugly) < score AffLex (beautiful )).
experiments reveal tendency positive terms negated convey
negative sentiment tendency negative terms negated still convey
negative sentiment. Moreover, degree change evaluative intensity appears
term-dependent. Capturing different behaviours terms negated contexts
means Negated Context Lexicons empower automatic sentiment analysis system
demonstrate experiments Section 6. Furthermore, believe
Affirmative Context Lexicons Negated Context Lexicons valuable
735

fiKiritchenko, Zhu, & Mohammad

applications textual entailment recognition, paraphrase detection, machine
translation. instance paraphrase detection task, given two sentences hotel
room wasnt terrible. hotel room excellent. automatic system
correctly infer sentences paraphrases looking score NegLex (terrible)
score AffLex (excellent) seeing polarities intensities terms
match (i.e., score AffLex (excellent) highly positive score NegLex (terrible) slightly
negative). time, mistake easily made conventional lexicons
polarity reversing strategy, according strong negative term terrible
assumed convey strong positive sentiment presence negation and, therefore,
polarities intensities two terms would match.
4.4 Negated Context (Positional) Lexicons
propose improve method constructing Negated Context Lexicons
splitting negated context two parts: immediate context consisting single token directly follows negation word, distant context consisting
rest tokens negated context. refer lexicons Negated Context
(Positional) Lexicons. token Negated Context (Positional) Lexicon two
scores: immediate-context score distant-context score. benefits approach
two-fold. Intuitively, negation affects words directly following negation word
strongly words farther away. Compare, example, immediate negation
good distant negation good, good, good idea. Second,
immediate-context scores less noisy. simple negation scope identification algorithm
occasionally fail include negated context parts tweet actually
negated (e.g., punctuation mark missing). errors less effect immediate
context. employing lexicons, use immediate-context score word
immediately preceded negation word use distant-context scores words
affected negation. before, non-negated parts message, sentiment scores
Affirmative Context Lexicon used. Assuming words occur distant contexts
often immediate contexts, approach introduce sparseness
lexicons. Thus, apply back-off strategy: immediate-context score available
token immediately following negation word, distant-context score used instead.
Section 6, experimentally show Negated Context (Positional) Lexicons provide additional benefits sentiment analysis system regular Negated Context
Lexicons described previous section.
4.5 Lexicon Coverage
Table 4 shows number positive negative entries sentiment lexicons
discussed above. automatically generated lexicons order magnitude larger
manually created lexicons. see manual lexicons contain
negative terms positive terms. automatically generated lexicons, imbalance
less pronounced (49% positive vs. 51% negative Hashtag Sentiment Base Lexicon)
even reversed (61% positive vs. 39% negative Sentiment140 Base Lexicon).
Sentiment140 Base Lexicon created equal number positive negative
tweets. Therefore, prevalence positive terms corresponds general trend
736

fiSentiment Analysis Short Informal Texts

Table 4: number positive negative entries sentiment lexicons.
Lexicon
NRC Emotion Lexicon
Bing Lius Lexicon
MPQA Subjectivity Lexicon
Hashtag Sentiment Lexicons (HS)
HS Base Lexicon
- unigrams
- bigrams
HS AffLex
- unigrams
- bigrams
HS NegLex
- unigrams
- bigrams
Sentiment140 Lexicons (S140)
S140 Base Lexicon
- unigrams
- bigrams
S140 AffLex
- unigrams
- bigrams
S140 NegLex
- unigrams
- bigrams

Positive
2,312 (41%)
2,006 (30%)
2,718 (36%)

Negative
3,324 (59%)
4,783 (70%)
4,911 (64%)

Total
5,636
6,789
7,629

19,121 (49%)
69,337 (39%)

20,292 (51%)
109,514 (61%)

39,413
178,851

19,344 (51%)
67,070 (42%)

18,905 (49%)
90,788 (58%)

38,249
157,858

936 (14%)
3,954 (15%)

5,536 (86%)
22,258 (85%)

6,472
26,212

39,979 (61%)
135,280 (51%)

25,382 (39%)
131,230 (49%)

65,361
266,510

40,422 (63%)
133,242 (55%)

23,382 (37%)
107,206 (45%)

63,804
240,448

1,038 (12%)
5,913 (16%)

7,315 (88%)
32,128 (84%)

8,353
38,041

language supports Polyanna Hypothesis (Boucher & Osgood, 1969), states
people tend use positive terms frequently diversely negative. Note,
however, negative terms dominant Negated Context Lexicons since
terms, positive negative, tend convey negative sentiment presence
negation. overall sizes Negated Context Lexicons rather small since negation
occurs 24% tweets Hashtag Sentiment140 corpora part
message negation actually negated.
Table 5 shows differences coverage lexicons. Specifically, gives
number additional terms lexicon row X comparison lexicon column
percentage tokens SemEval-2013 tweet test set covered extra
entries lexicon X (numbers brackets). instance, almost half Bing Lius Lexicon
(3,457 terms) found Sentiment140 Base Lexicon. However, additional
terms represent 0.05% tokens tweet test set. terms
rarely used short informal writing (e.g., acrimoniously, bestial, nepotism).
manually created lexicons covers extra 23% test data compared manual
lexicons. hand, automatically generated lexicons cover 60% tokens
test data. automatic lexicons provide number terms found other.
737

fiKiritchenko, Zhu, & Mohammad

Table 5: Lexicons supplemental coverage: row X column Y, number Lexicon
Xs entries found Lexicon (in brackets) percentage
tokens SemEval-2013 tweet test set covered extra entries Lexicon X. NRC stands NRC Emotion Lexicon, B.L. Bing Lius Lexicon,
MPQA MPQA Subjectivity Lexicon, HS Hashtag Sentiment Base
Lexicon, S140 Sentiment140 Base Lexicon.
Lexicon
NRC
B.L.
MPQA
HS
S140
NRC
3,179 (2.25%)
3,010 (2.00%)
2,480 (0.09%) 1,973 (0.05%)
B.L.
4,410 (1.72%)
1,383 (0.70%)
4,001 (0.07%) 3,457 (0.05%)
MPQA
3,905 (3.37%)
1,047 (2.60%)
3,719 (0.07%) 3,232 (0.04%)
HS
36,338 (64.23%) 36,628 (64.73%) 36,682 (62.84%)
15,185 (0.59%)
S140
61,779 (64.13%) 62,032 (64.65%) 62,143 (62.74%) 41,133 (0.53%)
-

5. System
5.1 Classifier
system, NRC-Canada Sentiment Analysis System, employs supervised statistical machine learning. tasks, message-level term-level, train linear-kernel Support Vector Machine (SVM) (Chang & Lin, 2011) classifier available training data.
SVM state-of-the-art learning algorithm proved effective text categorization
tasks robust large feature spaces. preliminary experiments, linear-kernel
SVM outperformed maximum-entropy classifier. Also, linear-kernel SVM showed better performance SVM another commonly used kernel, radial basis function
(RBF).
classification model leverages variety surface-form, semantic, sentiment
lexicon features described below. sentiment lexicon features derived three
existing, general-purpose, manual lexicons (NRC Emotion Lexicon, Bing Lius Lexicon,
MPQA Subjectivity Lexicon), four newly created, tweet-specific lexicons (Hashtag
Sentiment Affirmative Context, Hashtag Sentiment Negated Context (Positional), Sentiment140 Affirmative Context, Sentiment140 Negated Context (Positional)).
5.2 Features
5.2.1 Message-Level Task
message-level task, following pre-processing steps performed. URLs
user mentions normalized http://someurl @someuser, respectively. Tweets
tokenized part-of-speech tagged CMU Twitter NLP tool (Gimpel et al., 2011).
Then, tweet represented feature vector. employ commonly used text classification features ngrams part-of-speech tag counts, well common Twitterspecific features emoticon hashtag counts. addition, introduce several
lexicon features take advantage knowledge present manually automatically created lexicons. features designed explicitly handle negation. Table 6
738

fiSentiment Analysis Short Informal Texts

Table 6: Examples features system would generate message GRRREAT
show!!! Hope miss next one :). Numeric features presented
format: <feature name>:<feature value>. Binary features italicized;
features value 1 shown.
Feature group
word ngrams
character ngrams
all-caps
POS
automatic lexicon
features
manual lexicon
features
punctuation
emoticons
elongated words
clusters

Examples
grrreat, show, grrreat show, miss NEG, miss NEG
grr, grrr, grrre, rrr, rrre, rrrea
all-caps:1
POS N:1 (nouns), POS V:2 (verbs), POS E:1 (emoticons),
POS ,:1 (punctuation)
HS unigrams positive count:4, HS unigrams negative total score:1.51,
HS unigrams POS N combined total score:0.19,
HS bigrams positive total score:3.55, HS bigrams negative max score:1.98
MPQA positive affirmative score:2, MPQA negative negated score:1,
BINGLIU POS V negative negated score:1
punctuation !:1
emoticon positive:1, emoticon positive last
elongation:1
cluster 11111001110, cluster 10001111

provides example features tweet GRRREAT show!!! Hope miss next
one :).
features:
word ngrams: presence absence contiguous sequences 1, 2, 3, 4 tokens;
non-contiguous ngrams (ngrams one token replaced *);
character ngrams: presence absence contiguous sequences 3, 4, 5 characters;
all-caps: number tokens characters upper case;
POS: number occurrences part-of-speech tag;
hashtags: number hashtags;
negation: number negated contexts. Negation also affects ngram features:
word w becomes w NEG negated context;
sentiment lexicons:
Automatic lexicons following sets features generated separately
Hashtag Sentiment Lexicons (HS AffLex HS NegLex (Positional))
Sentiment140 Lexicons (S140 AffLex S140 NegLex (Positional)).
token w occurring tweet present lexicons, use sentiment
score (score AffLex (w ) w occurs affirmative context score NegLex (w )
w occurs negated context) compute:
number tokens score(w) 6= 0;
P
total score = wtweet score(w);
maximal score = max wtweet score(w);
739

fiKiritchenko, Zhu, & Mohammad

score last token tweet.
features calculated positive tokens (tokens sentiment scores
greater zero), negative tokens (tokens sentiment scores less
zero), tokens tweet. Similar feature sets also created
part-of-speech tag hashtags. Separate feature sets produced
unigrams, bigrams, non-contiguous pairs.
Manual lexicons three manual sentiment lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon), compute
following four features:










sum
sum
sum
sum






positive scores tweet tokens affirmative contexts;
negative scores tweet tokens affirmative contexts;
positive scores tweet tokens negated contexts;
negative scores tweet tokens negated contexts.

Negated contexts identified exactly described earlier Section 4.3 (the
method creating Negated Context Corpora). remaining parts
messages treated affirmative contexts. use score +1 positive
entries score -1 negative entries NRC Emotion Lexicon
Bing Lius Lexicon. MPQA Subjectivity Lexicon, provides two
grades association strength (strong weak), use scores +1/-1
weak associations +2/-2 strong associations. feature sets
also created part-of-speech tag, hashtags, all-caps tokens.
punctuation:
number contiguous sequences exclamation marks, question marks,
exclamation question marks;
whether last token contains exclamation question mark;
emoticons: polarity emoticon determined regular expression
adopted Christopher Potts tokenizing script:12
presence absence positive negative emoticons position
tweet;
whether last token positive negative emoticon;
elongated words: number words one character repeated two
times, example, soooo;
clusters: CMU Twitter NLP tool provides token clusters produced
Brown clustering algorithm 56 million English-language tweets. 1,000 clusters serve alternative representation tweet content, reducing sparcity
token space.
presence absence tokens 1000 clusters.
12. http://sentiment.christopherpotts.net/tokenizing.html

740

fiSentiment Analysis Short Informal Texts

5.2.2 Term-level Task
pre-processing steps term-level task include tokenization stemming
Porter stemmer (Porter, 1980).13 Then, tweet represented feature vector
following groups features:
word ngrams:
presence absence unigrams, bigrams, full word string target
term;
leading ending unigrams bigrams;
character ngrams: presence absence two- three-character prefixes suffixes
words target term (note target term may multi-word
sequence);
upper case:
whether words target start upper case letter followed
lower case letters;
whether target words uppercase (to capture potential named
entity);
stopwords: whether term contains stop-words. so, separate set features
indicates whether 1, 2, 3, stop-words;
negation: similar message-level task;
sentiment lexicons: manual sentiment lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon) automatic sentiment
lexicons (HS AffLex HS NegLex (Positional), S140 AffLex S140 NegLex
(Positional) Lexicons), compute following three features:
sum positive scores;
sum negative scores;
total score.
manual lexicons, polarity reversing strategy applied negation.14 Note
words stems matched sentiment lexicons.
punctuation: presence absence punctuation sequences ?! !!!;
emoticons: numbers categories emoticons term contains15 ;
elongated words: presence absence elongated words;
lengths:
length target term (number words);
13. differences implementation, use stemmer, simply result different team
members working two tasks.
14. experiments development dataset, manual lexicon features showed better performance
term-level task set four features used message-level task.
15. http://en.wikipedia.org/wiki/List emoticons

741

fiKiritchenko, Zhu, & Mohammad

average length words (number characters) term;
binary feature indicating whether term contains long words;
position: whether term beginning, end, another position
tweet;
term splitting: term contains hashtag made multiple words (e.g., #biggestdaythisyear ), split hashtag component words;
others:
whether term contains Twitter user name;
whether term contains URL.
features extracted target terms well rest
message (the context). unigrams bigrams, use four words either side
target context. window size chosen experiments development
set.

6. Experiments
section presents evaluation experiments demonstrate state-of-the-art performance sentiment analysis system three domains: tweets, SMS, movie
review excerpts. experiments also reveal superior predictive power new,
tweet-specific, automatically created lexicons existing, general-purpose lexicons. Furthermore, show Negated Context Lexicons bring additional gains
standard polarity reversing strategy handling negation.
begin intrinsic evaluation automatic lexicons comparing
manually created sentiment lexicons human annotated sentiment scores. Next,
assess value lexicons part sentiment analysis system both, supervised
unsupervised settings. goal experiments unsupervised sentiment analysis
(Section 6.2.1) compare predictive capacity lexicons simplest setup
reduce influence factors (such choice features) much possible.
Also, evaluate impact amount data used create automatic lexicon
quality lexicon. Then, Section 6.2.2 evaluate performance
supervised sentiment analysis system analyze contributions features derived
different sentiment lexicons.
6.1 Intrinsic Evaluation Lexicons
intrinsically evaluate tweet-specific, automatically created sentiment lexicons, first
compare existing manually created sentiment lexicons (Section 6.1.1). However,
existing manual lexicons tend discrete labels terms (positive, negative,
neutral) real-valued scores indicating intensity sentiment. Section 6.1.2,
show collected human annotated real-valued sentiment scores using MaxDiff
method annotation (Louviere, 1991). compare association scores
automatically generated lexicons human annotated scores.
742

fiSentiment Analysis Short Informal Texts

Table 7: Agreement polarity assignments Sentiment140 Affirmative Context
Lexicon manual lexicons. Agreement two lexicons measured
percentage shared terms given sentiment label (positive
negative) lexicons. agreement calculated three sets terms:
(1) shared terms; (2) shared terms whose sentiment score S140 AffLex
absolute value greater equal 1 (|score(w)| 1); (3) shared terms
whose sentiment score S140 AffLex absolute value greater equal
2 (|score(w)| 2). Sentiment scores S140 AffLex range -5.9 6.8.
Lexicon
NRC Emotion Lexicon
Bing Lius Lexicon
MPQA Subjectivity Lexicon

Number
shared terms
3,472
3,213
3,105

terms
73.96%
78.24%
75.91%

Agreement
|score(w)| 1 |score(w)| 2
89.96%
98.61%
92.32%
99.45%
90.26%
98.59%

6.1.1 Comparing Existing Manually Created Sentiment Lexicons
examine terms intersection manual lexicon automatic lexicon
measure agreement lexicons percentage shared terms
polarity label (positive negative) assigned lexicons. Table 7 shows
results Sentiment140 Affirmative Context Lexicon three manual lexicons: NRC
Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon. Similar figures (not
shown table) obtained automatic lexicons (HS Base Lexicon, HS AffLex,
S140 Base): agreement terms ranges 71% 78%. consider
terms whose sentiment scores automatic lexicon higher absolute values,
agreement numbers substantially increase. Thus, automatically generated entries
higher absolute sentiment values prove reliable.
6.1.2 Comparing Human Annotated Sentiment Association Scores
Apart polarity labels, automatic lexicons provide sentiment scores indicating
degree association term positive negative sentiment. noted
individual scores somewhat meaningless ability
indicate one word positive (or negative) another. However,
exists resource used determine real-valued scores match human
intuition. section, describe collected human annotations terms
sentiment association scores using crowdsourcing.
MaxDiff method annotation: people, assigning score indicating degree
sentiment natural. Different people may assign different scores target
item, hard even annotator remain consistent annotating
large number items. contrast, easier annotators determine whether one word
positive (or negative) other. However, latter requires much
larger number annotations former (in order N 2 , N number
items annotated). MaxDiff annotation scheme retains comparative
743

fiKiritchenko, Zhu, & Mohammad

aspect annotation still requiring small number annotations (Louviere,
1991).
annotator presented four words asked word positive
least positive. answering two questions five six
inequalities known. Consider set respondent evaluates: A, B, C D.
respondent says positive least positive, two responses
inform us that:
> B, > C, > D, B > D, C >
MaxDiff questions presented multiple annotators. responses
MaxDiff questions easily translated ranking terms
also real-valued score terms (Orme, 2009). two words different
degrees association (for example, >> D), chosen positive much
often chosen least positive much often A.
eventually lead ranked list significantly farther apart,
real-valued association scores also significantly different. hand,
two words similar degrees association positive sentiment (for example,
B), possible MaxDiff questions B, annotators
choose positive, choose B positive. Further,
B chosen positive (or negative) similar number times.
result list B ranked close real-valued
association scores also close value.
MaxDiff method widely used market survey questionnaires (Almquist & Lee,
2009). also used determining relation similarity pairs items Jurgens,
Mohammad, Turney, Holyoak (2012) SemEval-2012 shared task.
Term selection: evaluation automatic lexicons, selected 1,455 highfrequency terms Sentiment140 Corpus Hashtag Sentiment Corpus.
subset terms includes regular English words, Twitter-specific terms (e.g., emoticons, abbreviations, creative spellings), negated expressions. terms chosen follows.
terms corpora, excluding URLs, user mentions, stop words, terms
non-letter characters, ordered frequency. reduce subset skew towards
neutral class, terms selected different ranges sentiment values. this,
full range sentiment values automatic lexicons divided 10 equal-size
bins. bin, naff frequent affirmative terms nneg frequent negated
terms selected form initial list.16 . naff set 200 nneg 50
bins except two middle bins contain words weak association sentiment (i.e., neutral words). two middle bins, naff = 80 nneg = 20. Then,
initial list manually examined, ambiguous terms, rare abbreviations, extremely
obscene words (243 terms) removed. resulting list augmented
25 frequent emoticons. final list 1,455 terms contains 1,202 affirmative terms
253 negated terms; 946 words found WordNet 509 out-of-dictionary
terms. negated term presented annotators phrase negator + term,
16. bins may contain fewer naff affirmative fewer nneg negated terms. case,
available affirmative/negated terms selected.

744

fiSentiment Analysis Short Informal Texts

negator chosen frequent negator term (e.g., respect,
acceptable).
Annotation process: term list converted 3,000 MaxDiff
subsets 4 terms each. terms subsets chosen randomly term
list. duplicate terms allowed subset, subset unique.
MaxDiff subset, annotators asked identify term association
positive sentiment (i.e., positive term) term least association
positive sentiment (i.e., negative term). subset annotated 10
annotators. given question, refer option chosen often
majority answer. question answered randomly annotators, 25%
annotators expected select majority answer (as question four
options). task, observed majority answer selected 72%
annotators average.
answers converted scores using counting procedure (Orme, 2009).
term, score calculated percentage times term chosen
positive minus percentage times term chosen negative.
scores normalized range [0,1]. Even though annotators might disagree
answers individual questions, aggregated scores produced counting
procedure corresponding term ranking consistent. verified randomly
dividing sets answers question two groups comparing scores
rankings obtained two groups annotations. average, scores differed
0.04, Spearman rank correlation coefficient two sets rankings
0.97. rest paper, use scores term ranking produced full
set annotations. refer scores human annotated sentiment association
scores.
Comparing human annotated automatic sentiment scores: human
annotated scores used evaluate sentiment scores automatically generated,
tweet-specific lexicons. scores meaningful
ability rank terms order increasing (or decreasing) association positive (or
negative) sentiment. terms t1 t2 rank (t1 ) > rank (t2 ) per
rankings (human automatic), term pair (t1 , t2 ) considered
rank order.17 measure agreement human automatic sentiment rankings
percentage term pairs rank order same.18
two terms similar degree association sentiment,
likely humans disagree regarding order. Similarly, greater difference true sentiment scores, likely humans
agree regarding order. Thus, first create several sets term
pairs pertaining various minimal differences human sentiment scores, calculate
agreement sets. Every set pairsk term pairs (t1 , t2 )
Human Score (t1 ) 6= Human Score (t2 ) |Human Score (t1 ) Human Score (t2 )| k,
k varied 0 0.8 steps 0.1. Thus, pairs0 includes term pairs (t1 , t2 )
Human Score (t1 ) 6= Human Score (t2 ). Similarly, pairs0 .1 includes term pairs
|Human Score (t1 ) Human Score (t2 )| 0.1, on. agreement
17. One swap t2 t1 without loss generality.
18. measure agreement use similar Kendalls tau rank correlation coefficient.

745

fiKiritchenko, Zhu, & Mohammad

100

agreement

95

90

HS Base Lexicon
S140 Base Lexicon
HS AffLex HS NegLex
S140 AffLex S140 NegLex

85

80

75

min. abs. score difference

70

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

Figure 2: Agreement pair order ranking automatic lexicons human annotations. agreement (y-axis) measured percentage term pairs
rank order obtained lexicon human annotations.
x-axis represents minimal absolute difference human annotated scores
term pairs (k). results HS AffLex HS NegLex close results HS Base Lexicon, and, therefore, two curves indistinguishable
graph.

given set pairsk percentage term pairs set rank order
per human annotations automatically generated scores. expect higher
rank-order agreement sets pertaining higher ksets larger difference human
(or true) scores. plot agreement human annotations automatic
lexicon function k (x-axis) Figure 2.
agreement pairs0 used bottom-line overall agreement score
human annotations automatically generated scores. One observe overall
agreement automatic lexicons 7578%. agreement curves monotonically
increase difference human scores getting larger, eventually reaching 100%.
monotonic increase expected move farther right along x-axis, term pair
sets higher average difference human scores considered. demonstrates
automatic sentiment lexicons correspond well human intuition, especially
term pairs larger difference human scores.
6.2 Extrinsic Evaluation Lexicons
6.2.1 Lexicon Performance Unsupervised Sentiment Analysis
set experiments, evaluate performance individual lexicon
message-level sentiment analysis task unsupervised settings. training and/or tuning
performed. Since lexicons provide association scores positive
negative classes only, subsection, reduce problem two-way classification
task (positive negative). SemEval-2013 tweet test set SMS test set used
evaluation. neutral instances removed datasets.
746

fiSentiment Analysis Short Informal Texts

classify message positive negative, add scores matches
particular lexicon assign positive label cumulative score greater zero
negative label cumulative score less zero. Again, use scores +1/-1
NRC Emotion Lexicon Bing Lius Lexicon scores +1/-1 weak associations
+2/-2 strong associations MPQA Subjectivity Lexicon. message left
unclassified score equal zero matches found.
Table 8 presents results unsupervised sentiment analysis (1) manually created, general-purpose lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA
Subjectivity Lexicon), (2) automatically created, general-purpose lexicons (SentiWordNet
3.0 (Baccianella, Esuli, & Sebastiani, 2010), MSOL (Mohammad et al., 2009), Osgood
Evaluative Factor Ratings (Turney & Littman, 2003)), (3) automatically created,
tweet-specific lexicons (Hashtag Sentiment Sentiment140 Lexicons). unigram
entries used lexicon. automatic general-purpose lexicons large, opendomain lexicons providing automatically generated sentiment scores words taken
hand-built general thesauri WordNet Macquarie Thesaurus.19 predictive
performance assessed precision recall positive negative classes
well macro-averaged F-score two classes. Observe
lexicons, precision recall negative class lower positive class.
particular, holds manual lexicons (rows ac) despite fact
significantly negative terms positive terms. One possible explanation
phenomenon people express negative sentiment without using many
clearly negative words.
threshold zero seems natural separating positive negative classes
unsupervised polarity detection; however, better results possible thresholds.
example, predictions produced Osgood Evaluative Factor Ratings (rows f)
highly skewed towards positive class (recall 95.42 positive class 31.28
negative class), negatively affects macro-averaged F-score. avoid
problem setting optimal threshold unsupervised settings, report Area
ROC curve (AUC), takes account performance classifier
possible thresholds (see last column Table 8). calculate AUC, cumulative
scores assigned lexicon test messages ordered decreasing order. Then,
taking every score possible threshold, true positive ratio plotted false
positive ratio area curve calculated. shown AUC
classifier equivalent probability classifier rank randomly chosen
positive instance higher randomly chosen negative instance. also equivalent
Wilcoxon test ranks (Hanley & McNeil, 1982).
automatically generated lexicons match least one token test message
manual lexicons unable cover 1020% tweet test set. Paying attention
negation proves important general-purpose lexicons: macro-averaged Fscore AUC improved 14 percentage points. However, case
Hashtag Sentiment Base (rows g) Sentiment140 Base Lexicons (rows k).
polarity reversing strategy fails improve simple baseline disregarding negation
lexicons.
19. SentiWordNet 3.0 30,821 unigrams, MSOL Lexicon 55,141 unigrams, Osgood
Evaluative Factor Ratings Lexicon contains ratings 72,905 unigrams.

747

fiKiritchenko, Zhu, & Mohammad

Table 8: Prediction performance unigram lexicons unsupervised sentiment analysis
SemEval-2013 tweet test set. Cover. denotes coverage percentage
tweets test set least one match lexicon; P precision; R
recall; Favg macro-averaged F-score positive negative classes;
AUC area ROC curve.

Lexicon
Manual general-purpose lexicons
a. NRC Emotion Lexicon
- disregarding negation
- reversing polarity
b. Bing Lius Lexicon
- disregarding negation
- reversing polarity
c. MPQA Subjectivity Lexicon
- disregarding negation
- reversing polarity
Automatic general-purpose lexicons
d. SentiWordNet 3.0
- disregarding negation
- reversing polarity
e. MSOL
- disregarding negation
- reversing polarity
f. Osgood Evaluative Factor Ratings
- disregarding negation
- reversing polarity
Automatic tweet-specific lexicons
g. HS Base Lexicon
- disregarding negation
- reversing polarity
h. HS AffLex
- disregarding negation
- reversing polarity
i. HS AffLex HS NegLex
j. HS AffLex HS NegLex (Posit.)
k. S140 Base Lexicon
- disregarding negation
- reversing polarity
l. S140 AffLex
- disregarding negation
- reversing polarity
m. S140 AffLex S140 NegLex
n. S140 AffLex S140 NegLex (Posit.)
- tweet-specific entries

Cover.

Positive
P
R

Negative
P
R

Favg

AUC

76.30
76.30

84.77 58.78 56.83 34.61 56.22 70.66
86.20 59.61 59.02 35.94 57.58 72.83

77.59
77.59

90.73 61.64 65.94 45.42 63.60 79.08
92.02 61.64 66.74 48.75 65.09 80.20

88.36
88.36

82.90 71.56 58.57 38.10 61.49 73.01
84.56 71.06 60.09 43.09 63.71 75.33

100.00
100.00

82.40 71.76 44.93 59.73 64.00 71.51
85.08 71.12 47.42 67.22 66.54 75.15

100.00
100.00

77.18 74.43 38.66 27.79 54.06 63.44
77.35 74.30 41.70 30.95 55.66 63.80

100.00
100.00

75.65 97.65 74.31 17.80 56.99 75.30
78.41 95.42 72.31 31.28 64.88 80.11

100.00
100.00

89.15 72.65 51.79 76.87 70.97 82.52
88.03 72.07 50.45 74.38 69.69 80.21

100.00
100.00
100.00
100.00

87.53 80.41 57.75 70.05 73.56 83.06
87.04 79.07 55.84 69.22 72.34 82.21
89.44 77.04 55.92 76.21 73.64 84.61
89.60 77.29 56.30 76.54 73.94 84.62

100.00
100.00

88.60 77.61 55.78 73.88 73.15 84.47
87.78 77.23 54.68 71.88 72.14 83.21

100.00
100.00
100.00
100.00
100.00

85.96
87.19
89.65
89.79
87.26

748

86.45
85.31
83.21
83.33
86.26

64.02
63.56
63.03
63.31
65.11

63.06
67.05
74.88
75.21
67.05

74.87
75.75
77.37
77.59
76.41

84.94
86.04
86.88
87.14
86.55

fiSentiment Analysis Short Informal Texts

Compared Base Lexicons, lexicons created affirmative contexts
(rows h l) precise slightly improve predictive performance.
substantial improvements obtained adding Negated Context Lexicons (rows
m). Furthermore, Sentiment140 Negated Context (Positional) Lexicon (row n) offers
additional gain 0.26 percentage points AUC regular Sentiment140 Negated
Context Lexicon (row m). Overall, Affirmative Context Lexicons Negated
Context (Positional) Lexicons outperform Base Lexicons 2 percentage points
AUC.
automatically created general-purpose lexicons (rows df) substantially
higher coverage; however, show better performance manual lexicons.
hand, tweet-specific automatic lexicons demonstrate predictive power
superior both, manually automatically created, general-purpose lexicons.
differences especially pronounced Affirmative Context Lexicons
Negated Context Lexicons. keeping level precision close manual
lexicons, automatic tweet-specific lexicons able substantially improve recall
positive negative classes. increase recall particularly noticeable
negative class differences reach forty percentage points.
investigate impact tweet-specific subset vocabulary (e.g., emoticons,
hashtags, misspellings) performance automatic lexicons, conduct
experiments reduced lexicon. Terms punctuation, numerals, stop
words, found WordNet removed S140 AffLex
S140 NegLex (Positional) Lexicons. performance reduced lexicon (last row
table) drops 0.6 percentage points AUC demonstrating value tweetspecific terms. Nevertheless, results achieved subset S140 AffLex S140
NegLex (Positional) Lexicons still superior obtained automatic
manual lexicon. experiment suggests high-coverage automatic lexicons
also successfully employed general-purpose sentiment lexicons and, therefore, applied
other, non-tweet domains. next section, show features derived
lexicons extremely helpful automatic sentiment analysis tweets,
also SMS movie review data. Furthermore, (Kiritchenko et al., 2014)
demonstrate usefulness lexicons domains restaurant laptop customer
reviews.
unsupervised sentiment analysis experiments SMS test set (Table 9), one
see trends similar ones observed tweet test set above. automatic
lexicons built separately affirmative negated contexts (rows m) perform 36
percentage points better corresponding Base Lexicons combination polarity reversing strategy (rows g k). Moreover, use Sentiment140 Affirmative
Context Lexicon Negated Context (Positional) Lexicon (row n) results higher
performance obtained manually automatically created lexicon
used.
get better understanding impact amount data used create
automatic lexicon quality lexicon, compare performance automatic lexicons built subsets available data. split tweet corpus (Hashtag
Sentiment Corpus Sentiment140 Corpus) smaller chunks tweets time stamp.
Fig. 3 shows performance Hashtag Sentiment Base, Hashtag Sentiment Affirma749

fiKiritchenko, Zhu, & Mohammad

Table 9: Prediction performance unigram lexicons unsupervised sentiment analysis
SemEval-2013 SMS test set. polarity reversing strategy applied
negation lexicons except Negated Context Lexicons. Cover. denotes
coverage percentage SMS test set least one match
lexicon; P precision; R recall; Favg macro-averaged F-score
positive negative classes; AUC area ROC curve.
Positive
P
R

Negative
P
R

Lexicon

Cover.

Favg

AUC

Manual general-purpose lexicons
a. NRC Emotion Lexicon
b. Bing Lius Lexicon
c. MPQA Subjectivity Lexicon

70.88
69.75
83.86

85.11 56.91 80.17 47.21 63.82 79.66
87.90 61.99 86.36 48.22 67.30 83.24
81.69 72.56 77.95 52.03 69.63 82.42

Automatic general-purpose lexicons
d. SentiWordNet 3.0
e. MSOL
f. Osgood Evaluative Factor Ratings

100.00
100.00
100.00

77.36 79.88 73.87 70.30 75.32 81.34
69.88 73.58 69.14 44.92 63.07 72.49
66.15 95.33 87.01 39.09 66.02 84.01

Automatic tweet-specific lexicons
g. HS Base Lexicon
i. HS AffLex HS NegLex
j. HS AffLex HS NegLex (Posit.)

100.00
100.00
100.00

88.41 41.87 56.20 93.15 63.47 75.49
92.03 46.95 58.90 94.92 67.44 81.67
92.00 46.75 58.81 94.92 67.31 82.05

k. S140 Base Lexicon
m. S140 AffLex S140 NegLex
n. S140 AffLex S140 NegLex (Posit.)

100.00
100.00
100.00

85.71 73.17 71.67 84.77 78.31 86.07
88.38 78.86 76.73 87.06 82.46 89.34
88.69 79.67 77.48 87.31 83.02 89.60

tive Context Hashtag Sentiment Negated Context Lexicons, Sentiment140 Base,
Sentiment140 Affirmative Context Sentiment140 Negated Context Lexicons built
partial corpora function corpus size. above, performance
lexicons evaluated terms AUC unsupervised sentiment analysis SemEval2013 tweet test set. see Sentiment140 Lexicons generated half
available tweet set still higher predictive power full Hashtag Sentiment Lexicons. Interestingly, Hashtag Sentiment Lexicons seem stabilize corpus size
400,000500,000 tweets whereas Sentiment140 Lexicons stabilize 800,000
tweets. However, better results might still possible corpora orders
magnitude larger.
6.2.2 Lexicon Performance Supervised Sentiment Analysis
section, evaluate supervised sentiment analysis system (described Section 5) three-class problem (positive, negative, neutral) message-level
task term-level task. use data provided SemEval-2013 competition.
examine contribution various feature groups, including features derived
sentiment lexicons: manually created lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon) automatically created lexicons (Hashtag
750

fiSentiment Analysis Short Informal Texts

88

AUC

86
84
82

HS Base Lexicon
S140 Base Lexicon
HS AffLex HS NegLex
S140 AffLex S140 NegLex

80
78
76

# tweets (millions)

74

0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

Figure 3: Performance automatic tweet-specific lexicons unsupervised sentiment
analysis SemEval-2013 tweet test set different sizes tweet corpora.
AUC denotes Area ROC Curve.

Sentiment Sentiment140 Lexicons). Finally, compare performance different
strategies process negation.
tasks, train SVM classifier provided training data evaluate
performance learned models unseen tweet test set. models applied,
without change, test set SMS messages. evaluate performance
bottom-line evaluation measure used organizers SemEval-2013 competition
macro-averaged F-score positive negative classes:
Favg =

Fpos + Fneg
2

(4)

Note measure give credit correctly classifying neutral instances.
Nevertheless, system predict three classes (positive, negative, neutral)
avoid penalized misclassifying neutral instances positive negative. report
results obtained system training set (ten-fold cross-validation), development set (when trained training set), test sets (when trained combined
set tweets training development sets). Significance tests performed using
one-tailed paired t-test approximate randomization p < .05 level (Yeh, 2000).
order test system different domain, conduct experiments classifying
movie review sentences positive negative (message-level task only). use dataset
evaluation setup provided Socher et al. (2013). train system
training development subsets movie review excerpts dataset apply learned
model test subset. compare published results dataset, use accuracy
evaluation measure.
6.2.3 Results Message-Level Task
(a) SemEval-2013 data: results obtained system SemEval2013 message-level task presented Table 10. official submission task
751

fiKiritchenko, Zhu, & Mohammad

Table 10: Message-level task: macro-averaged F-scores SemEval-2013 datasets.
Classifier
a. Majority baseline
b. SVM-unigrams
c. system:
c.1. official SemEval-2013 submission
c.2. best result

Train.
Set
26.94
36.95

Dev.
Set
26.85
36.71

Test Sets
Tweets SMS
29.19
19.03
39.61
39.29

67.09
68.19

68.72
68.43

69.02
70.45

68.46
69.77

(row c.1) obtained macro-averaged F-score 69.02 tweet test set 68.46
SMS test set. 48 submissions 34 teams, system ranked first
datasets.20 replacing Base Lexicons Affirmative Context Lexicons
Negated Context (Positional) Lexicons improvements feature set,
achieved scores 70.45 tweet set 69.77 SMS set (row c.2).21
differences best scores official scores test sets statistically
significant. table also shows baseline results obtained majority classifier
always predicts frequent class (row a). bottom-line F-score based
F-scores positive negative classes (and neutral), majority
baseline chooses frequent class among positive negative, case
positive class.22 also include baseline results obtained using SVM
unigram features alone (row b).
Table 11 shows results ablation experiments repeat classification process remove one feature group time. influential features turn
sentiment lexicon features (row b): provide gains 810 percentage
points SemEval-2013 datasets. Note contribution automatic tweetspecific lexicons (row b.2) substantially exceeds contribution manual lexicons
(row b.1). especially noticeable tweet test set use automatic
lexicons results improvement 6.5 percentage points. Also, use bigrams
non-contiguous pairs (row b.5) bring additional gains using unigram lexicons.
second important feature group message-level task ngrams (row c):
word ngrams character ngrams. Part-of-speech tagging (row d) clustering (row
e) provide small improvements. Also, removing sentiment encoding features like
hashtags, emoticons, elongated words (row f) little impact performance,
probably discriminating information also captured
features character word ngrams.
Next, compare different strategies processing negation (Table 12). Observe
processing negation benefits overall sentiment analysis system: methods test
20. second-best results 65.27 tweet set 62.15 SMS set.
21. contributions different versions automatic lexicons overall systems performance
presented later subsection.
22. majority baseline calculated follows. Since instances predicted positive, Fneg = 0,
Rpos = 1, Ppos = Npos /N, Npos number positive instances N total number
instances dataset. Then, macro-averaged F-score positive negative classes Favg
= (Fpos + Fneg )/2 = Fpos /2 = (Ppos * Rpos )/(Ppos + Rpos ) = Ppos /(Ppos + 1) = Npos /(Npos + N).

752

fiSentiment Analysis Short Informal Texts

Table 11: Message-level task: macro-averaged F-scores obtained SemEval-2013
datasets one feature groups removed. Scores marked *
statistically significantly different (p < .05) corresponding scores row
a.
Experiment

Train.
Set
68.19

Dev.
Set
68.43

Test Sets
Tweets SMS
70.45
69.77

b. - lexicons
b.1. - manual lexicons
b.2. - automatic lexicons
b.3. - Sentiment140 Lexicons
b.4. - Hashtag Sentiment Lexicons
b.5. - automatic lexicons bigrams
& non-contiguous pairs

60.08*
66.59*
65.17*
66.84*
67.65*

58.98*
66.24*
64.15*
66.80*
67.82

60.51*
69.52*
63.89*
66.58*
67.64*

59.94*
67.26*
66.46*
67.61*
71.16*

67.65*

66.84

67.44*

69.42

c. - ngrams
c.1. - word ngrams
c.2. - character ngrams

64.07*
66.64*
67.64*

65.68*
66.70*
68.28

67.49*
68.29*
68.74*

66.93*
67.64*
69.11

d. - POS
e. - clusters
f. - encodings (elongated, emoticons,
punctuations, all-caps, hashtags)

67.54*
68.21*

67.64
68.33

70.47
70.00

68.42*
68.56*

67.99*

68.66

70.79

69.82

a. features

outperform baseline disregarding negation (row a.1). Employing Affirmative Context Lexicons Negated Context Lexicons (row b) provides substantial improvement
standard polarity reversing strategy Base Lexicons (row a.2). Replacing
Negated Context Lexicons Negated Context (Positional) Lexicons (row c) results
additional gains system.
(b) Movie Reviews data: results obtained using system
movie review excerpts dataset shown Table 13. system, trained sentencelevel annotations training development subsets, able correctly classify 85.5%
test subset. Note ignore annotations word phrase level
well parse tree structure used Socher et al. (2013). Even non-tweet domain,
employing automatically generated, tweet-specific lexicons significantly improves
overall performance: without use lexicons, performance drops 83.9%.
Furthermore, system demonstrates state-of-the-art performance surpassing previous best result obtained dataset (Socher et al., 2013).
6.2.4 Results Term-level Task
Table 14 shows performance sentiment analysis system SemEval-2013
term-level task. official submission (row c.1) obtained macro-averaged F-score
88.93 tweet set ranked first among 29 submissions 23 participating
753

fiKiritchenko, Zhu, & Mohammad

Table 12: Message-level task: macro-averaged F-scores Semeval-2013 datasets
different negation processing strategies. Scores marked * statistically
significantly different (p < .05) corresponding scores row c (our best
result).
Experiment
a. Base automatic lexicons
a.1. disregarding negation
a.2. reversing polarity
b. AffLex NegLex
c. AffLex NegLex (Positional)

Train.
Set

Dev.
Set

Test Sets
Tweets SMS

66.62*
67.61*
68.13*
68.19

67.36
68.04
68.41
68.43

67.99*
68.95*
69.95*
70.45

65.29*
66.96*
69.59
69.77

Table 13: Message-level task: results obtained movie review excerpts dataset.
System
a. Majority baseline
b. SVM-unigrams
c. Previous best result (Socher et al., 2013)
d. system

Accuracy
50.1
71.9
85.4
85.5

teams.23 Even tuning specific SMS data, system ranked second SMS
test set F-score 88.00. score first ranking system SMS set
88.39. post-competition bug-fix use Affirmative Context Lexicons
Negated Context (Positional) Lexicons resulted F-score 89.50 tweets set
88.20 SMS set (row c.2). difference best score official score
tweet test set statistically significant. table also shows baseline results
obtained majority classifier always predicts frequent class output (row
a), additional baseline result obtained using SVM unigram features alone
(row b).
Table 15 presents results ablation experiments feature groups alternately removed final model. Observe sentiment lexicon features (row
b) useful groupremoving leads drop F-score 45 percentage points datasets. manual (row b.1) automatic (row b.2) lexicons
contribute significantly overall sentiment analysis system, automatic lexicons
consistently showing larger gains.
ngram features (row c) next useful group term-level task. Note
removing word ngram features (row c.1) character ngram features
(row c.2) results small drop performance. indicates two feature
groups capture similar information.
last two rows Table 15 show results obtained features extracted
context target (and target itself) (row f)
extracted target (and context) (row g). Observe even
23. second-best system used additional labeled data obtained score 86.98 tweet
test set.

754

fiSentiment Analysis Short Informal Texts

Table 14: Term-level task: macro-averaged F-scores SemEval-2013 datasets.
Classifier
a. Majority baseline
b. SVM-unigrams
c. system:
c.1. official SemEval-2013 submission
c.2. best result

Train.
Set
38.38
78.04

Dev.
Set
36.34
79.76

Test Sets
Tweets SMS
38.13
32.11
80.28
78.71

86.80
87.03

86.49
87.07

88.93
89.50

88.00
88.20

Table 15: Term-level task: macro-averaged F-scores obtained SemEval-2013
datasets one feature groups removed. Scores marked *
statistically significantly different (p < .05) corresponding scores row
a.
Experiment
a. features

Train.
Set
87.03

Dev.
Set
87.07

Test Sets
Tweets SMS
89.50
88.20

b. - lexicons
b.1. - manual lexicons
b.2. - automatic lexicons

82.77*
86.16*
85.28*

81.75*
86.22
85.66*

85.56*
88.21*
88.02*

83.52*
87.27*
86.39*

c. - ngrams
c.1. - word ngrams
c.2. - char. ngrams

84.08*
86.65*
86.67*

84.94*
86.30
87.58

85.73*
88.51*
89.20

82.94*
87.02*
87.15*

d. - stopwords
e. - encodings (elongated words, emoticons,
punctuation, uppercase)

87.07*

87.08

89.42*

88.07*

87.11

87.08

89.44

88.17

f. - target
g. - context

72.65*
83.76*

71.72*
83.95*

74.12*
85.56*

69.37*
86.63*

though target features substantially useful context features, adding
context features system improves F-scores roughly 2 4 points.
performance sentiment analysis system significantly higher term-level
task message-level task. difference performance two tasks
also observed SVM-unigrams baseline. analyzed provided labeled data
determine unigrams performed strongly term-level task, found
test target tokens (85.1%) occur target tokens training data. Further,
distribution occurrences target term different polarities skewed towards one
polarity other. average, word appears target phrases polarity 80.8%
time. facts explain, least part, high overall result dominant
role unigrams term-level task. evaluate impact different feature groups
test data unseen target terms, split SemEval-2013 tweet test set
three subsets. Every instance first subset, targets fully seen training,
target X (X single word multi-word expression) following property:
exist instances training data exactly target. first subset
755

fiKiritchenko, Zhu, & Mohammad

Table 16: Term-level task: macro-averaged F-scores obtained different subsets
SemEval-2013 tweet test set one feature groups removed.
number brackets difference scores row a. Scores marked
* statistically significantly different (p < .05) corresponding scores
row a.
Classifier

a. features
b. - lexicons
b.1. - manual lexicons
b.2. - automatic lexicons
c. - ngrams

Targets
fully seen
training
93.31
92.96 (-0.35)
92.94 (-0.37)
92.98 (-0.33)
89.30 (-4.01)*

Targets
partially seen
training
85.42
81.26 (-4.16)*
84.51 (-0.91)
84.08 (-1.34)
81.61 (-3.81)*

Targets
unseen
training
84.09
69.55 (-14.54)*
79.33 (-4.76)*
79.41 (-4.68)*
80.62 (-3.47)*

Table 17: Term-level task: macro-averaged F-scores SemEval-2013 datasets
different negation processing strategies. Scores marked * statistically
significantly different (p < .05) corresponding scores row c (our best
result).
Experiment
a. Base automatic lexicons
a.1. disregarding negation
a.2. reversing polarity
b. AffLex NegLex
c. AffLex NegLex (Positional)

Train.
Set

Dev.
Set

Test Sets
Tweets SMS

85.88*
86.85
86.89
87.03

86.37*
86.48*
86.60*
87.07

88.38*
89.10*
89.33
89.50

86.77*
88.34
87.89
88.20

comprises 55% test set. Every instance second subset, targets partially seen
training, target X following property: exist instances training
data whose target expression includes one more, all, tokens X. second
subset comprises 31% test set. Every instance third subset, targets unseen
training, target X following property: instances
training data whose target includes tokens X. third subset comprises
14% test set. Table 16 shows results ablation experiments three
subsets. Observe instances unseen targets sentiment lexicons play
prominent role, providing substantial gain (14.54 percentage points).
next set experiments, compare performance different approaches
negation handling term-level task (Table 17). Similar message-level task,
processing negation proves beneficial term-level task well. tested negation
processing approaches show better results default strategy disregarding negation
(row a.1). use Affirmative Context Lexicons Negated Context Lexicons
(row b) especially Negated Context (Positional) Lexicons (row c) provides additional
gains results obtained use polarity reversing method (row a.2).
756

fiSentiment Analysis Short Informal Texts

7. Conclusions
created supervised statistical sentiment analysis system detects sentiment
short informal textual messages tweets SMS (message-level task) well
sentiment term (a word phrase) within message (term-level task). system
ranked first tasks SemEval-2013 competition Sentiment Analysis Twitter.
Moreover, demonstrated state-of-the-art performance two additional datasets:
SemEval-2013 SMS test set corpus movie review excerpts.
system, implemented variety features based surface form lexical
categories. also included features derived several sentiment lexicons: (1) existing,
manually created, general-purpose lexicons (2) high-coverage, tweet-specific lexicons
generated tweets sentiment-word hashtags tweets emoticons. experiments showed new tweet-specific lexicons superior sentiment
prediction tweets unsupervised supervised settings.
Processing negation plays important role sentiment analysis. Many previous studies adopted simple technique reverse polarity words scope negation.
work, demonstrated polarity reversing method may always appropriate. particular, showed positive terms negated, tend
convey negative sentiment. contrast, negative terms negated, tend
still convey negative sentiment. Furthermore, evaluative intensity positive
negative terms changes negated context, amount change varies
term term. adequately capture impact negation individual terms, proposed empirically estimate sentiment scores terms negated context large
tweet corpora, built two lexicons, one terms negated contexts one terms
affirmative (non-negated) contexts. using Affirmative Context Lexicons
Negated Context Lexicons able significantly improve performance
overall sentiment analysis system tasks. particular, features derived
lexicons provided gains 6.5 percentage points feature groups.
system process 100 tweets second. Thus, suitable small- bigdata versions applications listed introduction. recently annotated 135 million
tweets cluster 50 machines 11 hours. already employed sentiment analysis system within larger systems detecting intentions behind political tweets
(Mohammad, Kiritchenko, & Martin, 2013), detecting emotions text (Mohammad &
Kiritchenko, 2014), detecting sentiment towards particular aspects target entities
(Kiritchenko et al., 2014). also interested applying evaluating lexicons
generated tweets data kinds text blogs news articles.
addition, plan adapt sentiment analysis system languages English. Along way, continue improve sentiment lexicons generating
larger amounts data, different kinds data, tweets, blogs,
Facebook posts. especially interested algorithms gracefully handle kinds
sentiment modifiers including negations, also intensifiers (e.g., very, hardly),
discourse connectives (e.g., but, however).
757

fiKiritchenko, Zhu, & Mohammad

Acknowledgments
thank Colin Cherry providing SVM code helpful discussions.

References
Agarwal, A., Xie, B., Vovsha, I., Rambow, O., & Passonneau, R. (2011). Sentiment analysis
twitter data. Proceedings Workshop Languages Social Media, LSM
11, pp. 3038, Portland, Oregon.
Aisopos, F., Papadakis, G., Tserpes, K., & Varvarigou, T. (2012). Textual contextual
patterns sentiment analysis microblogs. Proceedings 21st International Conference World Wide Web Companion, WWW 12 Companion, pp.
453454, New York, NY, USA.
Almquist, E., & Lee, J. (2009). customers really want?. Harvard Business Review.
Baccianella, S., Esuli, A., & Sebastiani, F. (2010). SentiWordNet 3.0: enhanced lexical
resource sentiment analysis opinion mining. Proceeding 7th International Conference Language Resources Evaluation, Vol. 10 LREC 10, pp.
22002204.
Bakliwal, A., Arora, P., Madhappan, S., Kapre, N., Singh, M., & Varma, V. (2012). Mining sentiments tweets. Proceedings 3rd Workshop Computational
Approaches Subjectivity Sentiment Analysis, WASSA 12, pp. 1118, Jeju, Republic Korea.
Becker, L., Erhart, G., Skiba, D., & Matula, V. (2013). Avaya: Sentiment analysis
twitter self-training polarity lexicon expansion. Proceedings 7th International Workshop Semantic Evaluation (SemEval 2013), pp. 333340, Atlanta,
Georgia, USA.
Bellegarda, J. (2010). Emotion analysis using latent affective folding embedding.
Proceedings NAACL-HLT 2010 Workshop Computational Approaches
Analysis Generation Emotion Text, Los Angeles, California.
Boucher, J. D., & Osgood, C. E. (1969). Pollyanna Hypothesis. Journal Verbal
Learning Verbal Behaviour, 8, 18.
Boucouvalas, A. C. (2002). Real time text-to-emotion engine expressive internet communication. Emerging Communication: Studies New Technologies Practices
Communication, 5, 305318.
Brody, S., & Diakopoulos, N. (2011). Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!: using word
lengthening detect sentiment microblogs. Proceedings Conference
Empirical Methods Natural Language Processing, EMNLP 11, pp. 562570,
Stroudsburg, PA, USA.
Chang, C.-C., & Lin, C.-J. (2011). LIBSVM: library support vector machines. ACM
Transactions Intelligent Systems Technology, 2 (3), 27:127:27.
Choi, Y., & Cardie, C. (2008). Learning compositional semantics structural inference
subsentential sentiment analysis. Proceedings Conference Empirical
Methods Natural Language Processing, EMNLP 08, pp. 793801.
758

fiSentiment Analysis Short Informal Texts

Choi, Y., & Cardie, C. (2010). Hierarchical sequential learning extracting opinions
attributes. Proceedings Annual Meeting Association
Computational Linguistics, ACL 10, pp. 269274.
Davidov, D., Tsur, O., & Rappoport, A. (2010). Enhanced sentiment learning using Twitter hashtags smileys. Proceedings 23rd International Conference
Computational Linguistics: Posters, COLING 10, pp. 241249, Beijing, China.
Esuli, A., & Sebastiani, F. (2006). SENTIWORDNET: publicly available lexical resource
opinion mining. Proceedings 5th Conference Language Resources
Evaluation, LREC 06, pp. 417422.
Francisco, V., & Gervas, P. (2006). Automated mark affective information English
texts. Sojka, P., Kopecek, I., & Pala, K. (Eds.), Text, Speech Dialogue, Vol.
4188 Lecture Notes Computer Science, pp. 375382. Springer Berlin / Heidelberg.
Genereux, M., & Evans, R. P. (2006). Distinguishing affective states weblogs. Proceedings AAAI Spring Symposium Computational Approaches Analysing
Weblogs, pp. 2729, Stanford, California.
Gimpel, K., Schneider, N., OConnor, B., Das, D., Mills, D., Eisenstein, J., Heilman, M.,
Yogatama, D., Flanigan, J., & Smith, N. A. (2011). Part-of-speech tagging Twitter:
Annotation, features, experiments. Proceedings Annual Meeting
Association Computational Linguistics, ACL 11.
Go, A., Bhayani, R., & Huang, L. (2009). Twitter sentiment classification using distant
supervision. Tech. rep., Stanford University.
Hanley, J., & McNeil, B. (1982). meaning use area Receiver Operating Characteristic (ROC) curve. Radiology, 143, 2936.
Hatzivassiloglou, V., & McKeown, K. R. (1997). Predicting semantic orientation adjectives. Proceedings 8th Conference European Chapter Association
Computational Linguistics, EACL 97, pp. 174181, Madrid, Spain.
Hu, M., & Liu, B. (2004). Mining summarizing customer reviews. Proceedings
10th ACM SIGKDD International Conference Knowledge Discovery Data
Mining, KDD 04, pp. 168177, New York, NY, USA. ACM.
Jia, L., Yu, C., & Meng, W. (2009). effect negation sentiment analysis
retrieval effectiveness. Proceedings 18th ACM Conference Information
Knowledge Management, CIKM 09, pp. 18271830, New York, NY, USA. ACM.
Jiang, L., Yu, M., Zhou, M., Liu, X., & Zhao, T. (2011). Target-dependent Twitter sentiment classification. Proceedings 49th Annual Meeting Association
Computational Linguistics, ACL 11, pp. 151160.
Johansson, R., & Moschitti, A. (2013). Relational features fine-grained opinion analysis.
Computational Linguistics, 39 (3), 473509.
John, D., Boucouvalas, A. C., & Xu, Z. (2006). Representing emotional momentum within
expressive internet communication. Proceedings 24th International Conference Internet Multimedia Systems Applications, pp. 183188, Anaheim,
CA. ACTA Press.
759

fiKiritchenko, Zhu, & Mohammad

Jurgens, D., Mohammad, S. M., Turney, P., & Holyoak, K. (2012). Semeval-2012 task 2:
Measuring degrees relational similarity. Proceedings 6th International
Workshop Semantic Evaluation, SemEval 12, pp. 356364, Montreal, Canada.
Kennedy, A., & Inkpen, D. (2005). Sentiment classification movie product reviews
using contextual valence shifters. Proceedings Workshop Analysis
Informal Formal Information Exchange Negotiations, Ottawa, Ontario,
Canada.
Kennedy, A., & Inkpen, D. (2006). Sentiment classification movie reviews using contextual
valence shifters. Computational Intelligence, 22 (2), 110125.
Kiritchenko, S., Zhu, X., Cherry, C., & Mohammad, S. M. (2014). NRC-Canada-2014: Detecting aspects sentiment customer reviews. Proceedings International
Workshop Semantic Evaluation, SemEval 14, Dublin, Ireland.
Kouloumpis, E., Wilson, T., & Moore, J. (2011). Twitter sentiment analysis: Good
Bad OMG!. Proceedings 5th International AAAI Conference
Weblogs Social Media.
Lapponi, E., Read, J., & Ovrelid, L. (2012). Representing resolving negation sentiment analysis. Vreeken, J., Ling, C., Zaki, M. J., Siebes, A., Yu, J. X., Goethals,
B., Webb, G. I., & Wu, X. (Eds.), ICDM Workshops, pp. 687692. IEEE Computer
Society.
Li, J., Zhou, G., Wang, H., & Zhu, Q. (2010). Learning scope negation via shallow semantic parsing. Proceedings 23rd International Conference Computational
Linguistics, COLING 10, pp. 671679, Beijing, China.
Liu, B., & Zhang, L. (2012). survey opinion mining sentiment analysis.
Aggarwal, C. C., & Zhai, C. (Eds.), Mining Text Data, pp. 415463. Springer US.
Liu, H., Lieberman, H., & Selker, T. (2003). model textual affect sensing using realworld knowledge. Proceedings 8th International Conference Intelligent
User Interfaces, IUI 03, pp. 125132, New York, NY. ACM.
Louviere, J. J. (1991). Best-worst scaling: model largest difference judgments.
Working Paper.
Martnez-Camara, E., Martn-Valdivia, M. T., Urenalopez, L. A., & Montejoraez, A. R.
(2012). Sentiment analysis Twitter. Natural Language Engineering, 128.
Mihalcea, R., & Liu, H. (2006). corpus-based approach finding happiness. Proceedings AAAI Spring Symposium Computational Approaches Analysing
Weblogs, pp. 139144. AAAI Press.
Mohammad, S. M. (2012). #Emotional tweets. Proceedings First Joint Conference
Lexical Computational Semantics, *SEM 12, pp. 246255, Montreal, Canada.
Mohammad, S. M., Dunne, C., & Dorr, B. (2009). Generating high-coverage semantic
orientation lexicons overtly marked words thesaurus. Proceedings
Conference Empirical Methods Natural Language Processing: Volume 2, EMNLP
09, pp. 599608.
760

fiSentiment Analysis Short Informal Texts

Mohammad, S. M., & Kiritchenko, S. (2014). Using hashtags capture fine emotion
categories tweets. appear Computational Intelligence.
Mohammad, S. M., Kiritchenko, S., & Martin, J. (2013). Identifying purpose behind electoral tweets. Proceedings 2nd International Workshop Issues Sentiment
Discovery Opinion Mining, WISDOM 13, pp. 19.
Mohammad, S. M., & Turney, P. D. (2010). Emotions evoked common words
phrases: Using Mechanical Turk create emotion lexicon. Proceedings
NAACL-HLT Workshop Computational Approaches Analysis Generation
Emotion Text, LA, California.
Mohammad, S. M., & Yang, T. W. (2011). Tracking sentiment mail: genders differ
emotional axes. Proceedings ACL Workshop Computational Approaches
Subjectivity Sentiment Analysis, WASSA 11, Portland, OR, USA.
Neviarouskaya, A., Prendinger, H., & Ishizuka, M. (2011). Affect analysis model: novel
rule-based approach affect sensing text. Natural Language Engineering, 17,
95135.
Orme, B. (2009). Maxdiff analysis: Simple counting, individual-level logit, HB. Sawtooth Software, Inc.
Pak, A., & Paroubek, P. (2010). Twitter corpus sentiment analysis opinion
mining. Proceedings 7th Conference International Language Resources
Evaluation, LREC 10, Valletta, Malta.
Pang, B., & Lee, L. (2008). Opinion mining sentiment analysis. Foundations Trends
Information Retrieval, 2 (12), 1135.
Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up?: Sentiment classification using
machine learning techniques. Proceedings Conference Empirical Methods
Natural Language Processing, EMNLP 02, pp. 7986, Philadelphia, PA.
Polanyi, L., & Zaenen, A. (2004). Contextual valence shifters. Exploring Attitude
Affect Text: Theories Applications (AAAI Spring Symposium Series).
Porter, M. (1980). algorithm suffix stripping. Program, 3, 130137.
Proisl, T., Greiner, P., Evert, S., & Kabashi, B. (2013). Klue: Simple robust methods
polarity classification. Proceedings 7th International Workshop Semantic
Evaluation (SemEval 2013), pp. 395401, Atlanta, Georgia, USA.
Reckman, H., Baird, C., Crawford, J., Crowell, R., Micciulla, L., Sethi, S., & Veress, F.
(2013). teragram: Rule-based detection sentiment phrases using sas sentiment
analysis. Proceedings 7th International Workshop Semantic Evaluation
(SemEval 2013), pp. 513519, Atlanta, Georgia, USA.
Sauper, C., & Barzilay, R. (2013). Automatic aggregation joint modeling aspects
values. Journal Artificial Intelligence Research, 46, 89127.
Socher, R., Huval, B., Manning, C. D., & Ng, A. Y. (2012). Semantic compositionality
recursive matrix-vector spaces. Proceedings Conference Empirical
Methods Natural Language Processing, EMNLP 12, Jeju, Korea.
761

fiKiritchenko, Zhu, & Mohammad

Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., & Potts,
C. (2013). Recursive deep models semantic compositionality sentiment
treebank. Proceedings Conference Empirical Methods Natural Language
Processing, EMNLP 13, Seattle, USA.
Stone, P., Dunphy, D. C., Smith, M. S., Ogilvie, D. M., & associates (1966). General
Inquirer: Computer Approach Content Analysis. MIT Press.
Taboada, M., Brooke, J., Tofiloski, M., Voll, K., & Stede, M. (2011). Lexicon-based methods
sentiment analysis. Computational Linguistics, 37 (2), 267307.
Thelwall, M., Buckley, K., & Paltoglou, G. (2011). Sentiment Twitter events. Journal
American Society Information Science Technology, 62 (2), 406418.
Turney, P. (2001). Mining web synonyms: PMI-IR versus LSA TOEFL.
Proceedings Twelfth European Conference Machine Learning, pp. 491502,
Freiburg, Germany.
Turney, P., & Littman, M. L. (2003). Measuring praise criticism: Inference semantic
orientation association. ACM Transactions Information Systems, 21 (4).
Wiebe, J., Wilson, T., & Cardie, C. (2005). Annotating expressions opinions emotions
language. Language resources evaluation, 39 (2-3), 165210.
Wiegand, M., Balahur, A., Roth, B., Klakow, D., & Montoyo, A. (2010). survey
role negation sentiment analysis. Proceedings Workshop Negation
Speculation Natural Language Processing, NeSp-NLP 10, pp. 6068, Stroudsburg,
PA, USA.
Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S., Stoyanov, V., & Ritter, A. (2013).
SemEval-2013 Task 2: Sentiment analysis Twitter. Proceedings International Workshop Semantic Evaluation, SemEval 13, Atlanta, Georgia, USA.
Wilson, T., Wiebe, J., & Hoffmann, P. (2005). Recognizing contextual polarity phraselevel sentiment analysis. Proceedings Conference Human Language Technology Empirical Methods Natural Language Processing, HLT 05, pp. 347354,
Stroudsburg, PA, USA.
Yang, B., & Cardie, C. (2013). Joint inference fine-grained opinion extraction.
Proceedings Annual Meeting Association Computational Linguistics,
ACL 13.
Yeh, A. (2000). accurate tests statistical significance result differences.
Proceedings 18th conference Computational linguistics - Volume 2, COLING
00, pp. 947953, Stroudsburg, PA, USA.

762

fiJournal Artificial Intelligence Research 50 (2014) 603-637

Submitted 02/14; published 07/14

Probabilistic Inference Credal Networks:
New Complexity Results
Denis Deratani Maua

denis.maua@usp.br

Escola Politecnica, Universidade de Sao Paulo
Av. Prof. Luciano Gualberto, travessa 3, 380
Sao Paulo, 05508-010 Brazil

Cassio Polpo de Campos
Alessio Benavoli
Alessandro Antonucci

cassio@idsia.ch
alessio@idsia.ch
alessandro@idsia.ch

Istituto Dalle Molle di Studi sullIntelligenza Artificiale
Galleria 2
Manno, 6928 Switzerland

Abstract
Credal networks graph-based statistical models whose parameters take values
set, instead sharply specified traditional statistical models (e.g., Bayesian
networks). computational complexity inferences models depends
irrelevance/independence concept adopted. paper, study inferential complexity
concepts epistemic irrelevance strong independence. show inferences strong independence NP-hard even trees binary variables except
single ternary one. prove epistemic irrelevance polynomial-time
complexity inferences credal trees likely extend general models
(e.g., singly connected topologies). results clearly distinguish networks admit
efficient inferences inferences likely hard, settle several open
questions regarding computational complexity. show results remain
valid even disallow use zero probabilities. also show computation
bounds probability future state hidden Markov model
whether assume epistemic irrelevance strong independence, prove similar
result inference naive Bayes structures. inferential equivalences important
practitioners, hidden Markov models naive Bayes structures used real
applications imprecise probability.

1. Introduction
Bayesian networks multivariate probabilistic models stochastic independence assessments compactly represented acyclic directed graph whose nodes identified
variables (Pearl, 1988). addition acyclic directed graph, specification
Bayesian network requires specification conditional probability distribution
every variable every assignment parents. information costly acquire,
specifying conditional probabilities daunting task, whether estimated data elicited experts. causes inferences drawn model
contain imprecisions arbitrarinesses (Kwisthout & van der Gaag, 2008).
arguably principled approach coping imprecision numerical
parameters incorporating formalism. One way means
c
2014
AI Access Foundation. rights reserved.

fiMaua, de Campos, Benavoli & Antonucci

closed convex sets probability distributions, called credal sets (Levi, 1980).1
Bayesian networks whose numerical parameters specified conditional credal sets
known credal networks (Cano, Cano, & Moral, 1994; Cozman, 2000, 2005). Credal
networks successfully applied robust pattern recognition,2 knowledgebased systems, argued allowing parameters imprecisely specified
facilitates elicitation experts.3
Bayesian network provides concise representation (single) joint probability
distribution consistent network parameters satisfies (at least) set
stochastic independences encoded underlying graph. Analogously, credal network
provides concise representation credal set joint distributions consistent
local credal sets satisfy (at least) irrelevances encoded underlying
graph. precise characterization joint credal set depends however concept
irrelevance adopted.
two commonly used irrelevance concepts literature strong independence epistemic irrelevance. Two variables X strongly independent
joint credal set regarded originating number precise probability
distributions two variables stochastically independent. Strong
independence follows sensitivity analysis interpretation, regards imprecision
model arising partial ignorance ideal precise model. Epistemic irrelevance, hand, defined irrespective existence ideal precise model.
variable X epistemically irrelevant variable marginal credal set
coincides conditional credal set given X. Unlike strong independence, epistemic irrelevance asymmetric concept cannot general characterized
properties elements credal set alone (de Cooman et al., 2010).
one hand flexibility provided credal sets arguably facilitates model
building, other, imposes great burden computation inferences.
example, whereas posterior probability variable polynomial-time computable
polytree-shaped Bayesian networks, analogous task computing upper lower
bounds posterior probability given variable polytree-shaped credal networks
NP-hard task (de Campos & Cozman, 2005). however exceptional cases,
case inference polytree-shaped credal networks binary variables,
solved polynomial time strong independence (Fagiuoli & Zaffalon,
1998). Like Bayesian networks, theoretical practical tractability inferences
credal networks depends strongly network topology cardinality
variable domains. Credal networks however include another dimension parametrized
complexity inference, given type irrelevance concept adopted,
1. approaches include random sets (Kendall, 1974), evidence theory (Shafer, 1976; Shenoy & Shafer,
1988), possibility theory (Zadeh, 1978), conditional plausibility measures (Halpern, 2001), coherent
lower previsions (Walley, 1991; de Cooman & Miranda, 2012), last one largely equivalent
credal sets (there one-to-one correspondence credal sets coherent lower previsions).
2. example, see works Zaffalon, Wesnes, Petrini (2003), Zaffalon (2005), de Campos, Zhang,
Tong, Ji (2009), Antonucci, Bruhlmann, Piatti, Zaffalon (2009), Corani, Giusti, Migliore,
Schmidhuber (2010), Antonucci, de Rosa, Giusti (2011), de Campos Ji (2011).
3. example, see works Walley (2000), Antonucci, Piatti, Zaffalon (2007), Salvetti, Antonucci,
Zaffalon (2008), de Campos Ji (2008), Antonucci et al. (2009), Piatti, Antonucci, Zaffalon
(2010), Antonucci, Huber, Zaffalon, Luginbuhl, Chapman, Ladouceur (2013).

604

fiProbabilistic Inference Credal Networks: New Complexity Results

Bayesian case usually fixed. instance, computing probability bounds tree-shaped
credal networks concept epistemic irrelevance performed polynomial
time (de Cooman et al., 2010), whereas show task NP-hard
strong independence.
rest paper, properly define credal networks inference problem
address (sect. 2), investigate parametrized theoretical computational complexity
inferences credal networks (sect. 3), strong independence epistemic
irrelevance. show particular type inference imprecise hidden Markov models
(i.e., hidden Markov models uncertainty quantified local credal sets) invariant
choice either irrelevance concept, thus polynomial-time computable (as
known case epistemic irrelevance). obtain corollaries
result inferences strong independence epistemic irrelevance coincide also
tree-shaped networks evidence given, naive Bayes structures. also
show even tree-shaped credal networks inferences NP-hard assume strong
independence, complexity inference polytree-shaped credal
networks irrelevance concepts, even assume variables (at most)
ternary. prove so-called precise-vacuous models, is, credal networks
vacuous root nodes precise non-root nodes, lead inferences whether
assume epistemic irrelevance strong independence, true (apart
arbitrarily small error) vacuous nodes replaced near-vacuous ones,
avoiding problematic case zero probabilities. last fact proves hardness
results hold true even cases lower probability possible event strictly
positive.

2. Updating Credal Networks
section, review necessary concepts definitions, formalize problem
inference credal networks.
2.1 Bayesian Networks
Consider finite set X = {X1 , . . . , Xn } categorical variables, let Z X
set variables. probability distributionPp Z non-negative real-valued function
space assignments Z zZ p(z) = 1, notation z Z entails
z arbitrary (joint) assignment configuration variables Z. joint
probability distribution p induces probability measure Pp sigma-field subsets
assignments Z.
Let G acyclic directed graph (DAG) nodes N = {1, . . . , n}. denote
parents node G Pa(i). set non-descendants i, written Nd(i),
contains nodes reachable directed path. Note Pa(i) Nd(i).
Fix probability measure P sigma-field subsets X associate every node
variable Xi . DAG G represents following set stochastic independence
assessments known local Markov conditions:
P(Xi = xi |XNd(i) = xNd(i) ) = P(Xi = xi |XPa(i) = xPa(i) ) ,
605

(1)

fiMaua, de Campos, Benavoli & Antonucci

N , x X. words, every variable stochastically independent
non-descendant non-parents given parents suitable measure P.
Bayesian network triple (X, G, Q), Q set conditional probability
assessments
P(Xi = xi |XPa(i) = xPa(i) ) = q(xi |xPa(i) ) ,
(2)
N , xi Xi xPa(i) XPa(i) , q(Xi |xPa(i) ) probability distribution
Xi . assumption, Bayesian network defines joint probability distribution p X

p(x) =
q(xi |xPa(i) ) ,
(3)


x X. difficult see (1) (2) imply (3) Chain Rule using
topological ordering variables. (3) (2) imply (1) bit intricate see
also true (Cowell, Dawid, Lauritzen, & Spiegelhalter, 2007). Thus, two seemingly
different approaches specifying probability measure virtually equivalent.
explicit: given Bayesian network, probability measure satisfies (1)
(2) probability measure satisfies (3) (2), choose pair
assumptions define (single) measure network. shall see, analogous
equivalence observed probabilities imprecisely specified, leads
different definitions credal networks different computational complexity.
2.1.1 Probabilistic Inference Bayesian Networks
essential task many applications probabilistic modeling compute certain
probability value implied Bayesian network. call computational task
BN-INF problem, define follows.
BN-INF
Input: Bayesian network (X, G, Q), target node t, target value xt Xt ,
(possibly empty) set evidence nodes O, assignment xO XO .
Output: conditional probability P(Xt = xt |XO = xO ), P probability measure specified network.
problem assume P(XO = xO ) = 0 output special symbol
(e.g. ) indicating problem solution undefined.
Roth (1996) showed BN-INF #P-hard, defining lower bound complexity
problem. known (exact) algorithms take time least exponential treewidth
network worst case. treewidth measure resemblance network
tree; small treewidth suggests tree-like structure treewidth tree one
minimal (Koller & Friedman, 2009). Recently, Kwisthout, Bodlaender, van der
Gaag (2010) proved contingent hypothesis satisfiability Boolean formulas
takes exponential time worst-case (known ETH) best performance
algorithm BN-INF achieve. shall see next section, Bayesian networks
particular instances credal networks. such, complexity results set lower
bounds complexity inference credal networks.
DAG said singly connected one undirected path connecting
two nodes graph; tree additionally node one parent.
606

fiProbabilistic Inference Credal Networks: New Complexity Results

graph singly connected, say multiply connected. Singly connected directed
graphs also called polytrees. Pearls belief propagation algorithm (Pearl, 1988) computes
BN-INF polynomial time singly connected Bayesian networks. generally,
junction tree propagation algorithm (Cowell et al., 2007) solves BN-INF polynomial time
network bounded treewidth, includes singly connected networks bounded
in-degree (i.e., maximum number parents).
2.2 Credal Networks
section describe credal sets, irrelevance concepts, credal networks probabilistic
inference credal networks.
2.2.1 Credal Sets
Let Z X. credal set closed convex set joint probability distributions
domain, say z Z (Levi, 1980). vacuous credal set Z largest
credal set domain, denoted V (Z). extreme distribution credal set
element set cannot written convex combination elements
set. denote set extreme distributions credal set ext .
credal set finitely generated contains finite number extreme distributions.
finite representation finitely generated credal set means extreme distributions
called vertex-based. finitely generated credal set Z defines (bounded) polytope
probability simplex distributions Z, specified finite set
linear inequalities form
def

Ep (fl ) =

X

fl (z)p(z) 0 ,

(4)

zZ

{fl } finite collection real-valued functions Z (Cozman, 2000). converse
also true: finite set linear inequalities form determines (bounded)
polytope probability simplex (Boyd & Vandenberghe, 2004, ch. 2), hence
finitely generated credal set. Thus, alternative finite representation credal set
means finite set functions defining linear inequalities type above.
representation called constraint-based.
Example 1. Consider X = {X1 , X2 }, X1 takes values {0, 1, 2} X2 takes
values {0, 1}. vacuous set X1 probability simplex plane, drawn
triangle vertices (p(0), p(1), p(2)) = (0, 0, 1), (0, 1, 0) (1, 0, 0) Figure 1. Let
(X1 |X2 = 0) = {p V (X1 ) : p(k) 1/3, k = 1, 2}

(X1 |X2 = 1) = {p V (X1 ) : p(0) p(1) p(2)}
conditional credal sets X1 given X2 , (X2 ) singleton containing
distribution p X2 p(0) = p(1) = 1/2. first two sets depicted Figure 1.
607

fiMaua, de Campos, Benavoli & Antonucci

(0, 1, 0)

(0, 1, 0)

p5
p3

(0, 0, 1)

p2

p4

p3
p1
(1, 0, 0)

p1
(1, 0, 0)

(0, 0, 1)

(a) (X1 |X2 = 0)

(b) (X1 |X2 = 1)

Figure 1: Barycentric coordinate-system visualization conditional credal sets Example 1 (hatched regions) corresponding extreme distributions (black circles).
Let us represent generic function f {0, . . . , m} m-tuple (f (0), . . . , f (m)),
define
p1 = (1, 0, 0) ,

p2 = (2/3, 1/3, 0) ,

p3 = (1/3, 1/3, 1/3) ,

p4 = (2/3, 0, 1/3) ,

p5 = (1/2, 1/2, 0) ,

f1 = (1, 2, 1) ,

f2 = (1, 1, 2) ,

f3 = (1, 1, 0) ,

f4 = (0, 1, 1) ,

f5 = (1, 1) .

set (X1 |X2 = 0) represented vertex- constraint-based form, respectively, (X1 |X2 = 0) = co{p1 , p2 , p3 , p4 } (co denotes convex hull operator)
(X1 |X2 = 0) = {p V (X1 ) : Ep (f1 ) 0, Ep (f2 ) 0}, set (X1 |X2 = 1)
represented vertex- constraint-based forms (X1 |X2 = 1) = co{p1 , p3 , p5 }
(X1 |X2 = 1) = {p V (X1 ) : Ep (f3 ) 0, Ep (f4 ) 0}, respectively. Similarly, (X2 )
represented (X2 ) = {(1/2, 1/2)} vertex-based form, (X2 ) = {p
V (X2 ) : Ep (f5 ) 0, Ep (f5 ) 0} constraint-based form.
Vertex- constraint-based representations credal set different sizes. see this, consider single variable X taking values {0, . . . , m}, let
= {p V (X) : p(k) 1/(m + 1), k = 1, . . . , m}. set isomorphic mdimensional hypercube, therefore 2m extreme distributions,4 whereas set
represented constraint-based form degenerate functions X translated
1/(m + 1). Moving vertex-based constraint-based representation also result
exponential increase size ofP
input. Consider variable XPtaking values

{0, . . . , m} let = {f (X) 0 :
k=1 |f (k) 1/(2m)| 1/(2m),
k=0 f (k) = 1}.
set affinely equivalent m-dimensional cross-polytope, hence requires
2m inequalities described constraint-based form, represented
4. non-negative integer k greater (potentially empty) subset {1, . . . , m}
cardinality k, distribution assigns mass (m + 1 k)/(m + 1) p(0), mass 1/(m + 1) p(j)
j S, zero mass elsewhere, , since satisfies constraints valid
distribution. 2m distributions, one cannot written convex combination
distribution set.

608

fiProbabilistic Inference Credal Networks: New Complexity Results

vertex-based form 2m extreme distribution (Kalai & Ziegler, 2000, p. 11).5 Tessem
(1992) de Campos, Huete, Moral (1994) studied representation credal sets
defined linear constraints form lx p(x) ux , lx ux real numbers,
showed credal sets exponentially many extreme distributions
number constraints. Wallner (2007) proved attainable upper bound m! extreme
distributions credal sets generally defined coherent lower probability function
m-ary variable. recently, Miranda Destercke (2013) investigated number
extreme distributions credal sets defined linear constraints form p(x) p(x0 )
x 6= x0 , proved attainable upper bound 2m1 extreme distributions
case m-ary variable. Importantly, vacuous credal sets (of variables cardinality) credal sets binary variables succinctly represented either vertexor constraint-based form. complexity results obtain later use vacuous
credal sets and/or binary variables thus representation independent.
2.2.2 Graph-Based Representation
far considered explicit representation finitely generated credal set
finite number functions representing either vertices set set linear
inequalities. final goal however able specify credal sets large domains
x X. large set X, explicit representation difficult obtain
large manipulate computer. Thus, analogously efficient graph-based
representation large probability distribution given Bayesian network, large joint
credal set usually efficiently represented implicitly credal set satisfies
irrelevances encoded given graph agreeing projection local credal
sets, latter credal sets efficiently represented (either vertex-
constraint-based form) explicitly functions small subsets X.
(separately specified) credal network N triple (X, G, Q), G DAG
nodes N , Q set imprecise probability assessments
X
X
f :
f (xi )P(Xi = xi |XPa(i) = xPa(i) )
min
f (xi )q(xi ) ,
(5)
qQ(Xi |xPa(i) )

xi Xi

xi Xi

one every N xPa(i) XPa(i) , Q(Xi |xPa(i) ) credal set Xi
f arbitrary real-valued function Xi . Note left unspecified credal
sets represented.
Example 2. Consider credal network N variables X1 , X2 X3 take values
{0, 1}, graph structure shown Figure 2. local credal sets
Q(X1 ) = {p V (X1 ) : 0.5 p(1) 0.6} = co{(0.4, 0.6), (0.5, 0.5)} ,
Q(X2 ) = {p V (X2 ) : 0.5 p(1) 0.6} = co{(0.4, 0.6), (0.5, 0.5)} ,
Q(X3 |X1 = i, X2 = j) = {pij } j, pij probability distribution
{0, 1} pij (1) = 0 = j pij (1) = 1 otherwise.
P
5. m-dimensional cross-polytope set {f (X) : x |f (x)| 1}, whose extreme distributions
{e1 , . . . , em }, ek (k = 1, . . . , m) degenerate distribution placing mass X = k.
fact set cannot written less 2m inequalities follows dual
m-dimensional hypercube.

609

fiMaua, de Campos, Benavoli & Antonucci

1

2
3

Figure 2: DAG credal network Example 2.

node network associated variable Xi said precise (i.e., precisely specified) corresponding conditional credal sets Q(Xi |xPa(i) ) singletons,
otherwise said imprecise (i.e., imprecisely specified). Example 2 variable
X3 corresponding associated node precise, X1 X2 imprecise.
local credal sets vacuous, node corresponding variable said
vacuous. Bayesian network simply credal network nodes precise.
DAG G credal network specifies set conditional irrelevances sets
variables generalize Markov condition Bayesian networks. specifically,
node G, set XNd(i)\Pa(i) non-descendant non-parent variables Xi
assumed irrelevant Xi conditional parent variables XPa(i) . precise definition
statement requires definition irrelevance concept. instance, stochastic
independence adopted irrelevance concept, DAG G describes set Markov
conditions Bayesian network (stochastic irrelevance implies stochastic independence).
credal network formalism, two common irrelevance concepts used strong
independence epistemic irrelevance.
Fix joint credal set probability distributions X, consider subsets Y,
Z W X. say set variables strongly independent set
variables Z given variables W Z stochastically independent conditional
W every extreme distribution p ext (X), implies every y, z w
Pp (Y = y|Z = z, W = w) = Pp (Y = y|W = w). say set variables Z
epistemically irrelevant set variables conditional variables W every
function f assignments z w follows
min

pM

X

f (y)Pp (Y = y|Z = z, W = w) = min
pM

yY

X

f (y)Pp (Y = y|W = w) ,

(6)

yY

equivalent say projection conditioned W = w Z = z
equals projection conditioned W = w. immediate conclusion
strong independence implies epistemic irrelevance (and converse necessarily
true) (Cozman, 2000; de Cooman & Troffaes, 2004). Variables Z epistemically
independent conditional W if, given assignment w, Z epistemically
irrelevant (Walley, 1991, ch. 9).
strong extension credal network N = (X, G, Q) largest credal set KS
distributions X whose extreme distributions satisfy strong independence assessments
G (viz. every variable strongly independent non-descendant non-parents
given parents), whose projections local domains lie inside local credal sets
specified Q, is, KS convex hull set distributions X whose induced
measure satisfies (1) (5). One show strong extension equivalently
610

fiProbabilistic Inference Credal Networks: New Complexity Results

defined (Antonucci & Zaffalon, 2008; Antonucci, de Campos, & Zaffalon, 2014)
(
)
xPa(i)
xPa(i)
def
qi
KS = co p V (X) : p(x) =
(xi ), qi
ext Q(Xi |xPa(i) ) .

(7)



epistemic extension credal network largest joint credal set KE X
satisfies epistemic irrelevance assessments G (viz. non-descendant non-parents
irrelevant variable given parents), assessments Q. Equivalently,
epistemic extension credal set KE defined set probability distributions p
X
X
X
f (xi )Pp (xi |xNd(i) )
min
f (xi )q(xi ) ,
(8)
qQ(Xi |xPa(i) )

xi

xi

functions f Xi , assignment xNd(i) . Note inequalities turned
linear inequalities form (4) multiplying sides Pp (xNd(i) ) rearranging terms.
following example largely based Example 9.3.4 work Walley (1991).
Example 3. Consider network Example 2, represent function f binary
variable pair (f (0), f (1)). strong extension KS credal set whose extreme
distributions four joint probability distributions p V (X1 , X2 , X3 )
p(x1 , x2 , x3 ) = p1 (x1 )p2 (x2 )px3 1 x2 (x3 )

x1 , x2 , x3 {0, 1} ,


p1 {(0.4, 0.6), (0.5, 0.5)} ,

p2 {(0.4, 0.6), (0.5, 0.5)} ,

p00
3

10
p01
3 = p3 = (0, 1) .

=

p11
3

= (1, 0) ,

Note strong extension contains four extreme distributions. epistemic extension
KE set joint probability distributions p V (X1 , X2 , X3 ) satisfies system
linear inequalities
0.5 =

min q(1) Pp (X1 = 1|x2 ) max q(1) = 0.6

[x2 = 0, 1] ,

min q(1) Pp (X2 = 1|x1 ) max q(1) = 0.6

[x1 = 0, 1] ,

qQ(X1 )

0.5 =

qQ(X2 )

qQ(X1 )

qQ(X2 )

Pp (X3 = 1|X1 = x, X2 = x) = 0

[x = 0, 1] ,

Pp (X3 = 1|X1 = 0, X2 = 1) = Pp (X3 = 1|X1 = 1, X2 = 0) = 1 .
One verify set KE following six extreme distributions:
p1 = (0.25, 0, 0, 0.25, 0, 0.25, 0.25, 0) ,

p2 = (0.16, 0, 0, 0.36, 0, 0.24, 0.24, 0) ,

p3 = (0.2, 0, 0, 0.3, 0, 0.2, 0.3, 0) ,

p4 = (0.2, 0, 0, 0.3, 0, 0.3, 0.2, 0) ,

p5 = (2/9, 0, 0, 3/9, 0, 2/9, 2/9, 0) ,

p6 = (2/11, 0, 0, 3/11, 0, 3/11, 3/11, 0) ,

tuples right-hand side represent distributions p(x1 , x2 , x3 )
(p(0, 0, 0), p(1, 0, 0), p(0, 1, 0), p(1, 1, 0), p(0, 0, 1), p(1, 0, 1), p(0, 1, 1), p(1, 1, 1)) .
observe distributions p1 p4 extreme distributions strong extension,
whereas p5 p6 strong extension.
611

fiMaua, de Campos, Benavoli & Antonucci

example shows interesting well-known relation epistemic
strong extensions, namely, latter always contained former, thus
produces precise results (Walley, 1991, ch. 9.2).
already discussed choice representation credal sets affect
complexity. following result connects vertex- constraint-based credal networks
strong independence.
Proposition 1. vertex-based (separately specified) credal network efficiently
reduced constraint-based credal network larger set variables induces
strong extension projected original set variables.
Proof. Let Xi variable whose local credal set Q(Xi |xPa(i) ) specified extreme distributions p1 , . . . , pm , given assignment parents. Insert new vacuous
variable X taking values {1, . . . , m}, Xi child XPa(i) parents, redefine Q(Xi |xPa(i) ) singleton contains conditional distribution
q(xi |xPa(i) , x = k) = pk (xi ). One verify strong extension new network
marginalizing X coincides original strong extension.
result cannot applied derive complexity singly connected networks
since reduction used proof inserts (undirected) cycles network. Thus,
true hardness results obtained vertex-based singly connected networks
immediately extend constraint-based singly connected networks, even though
always case results present (for instance, use credal sets
easily translated one representation hardness results). Conversely,
tractability constraint-based singly connected networks immediately extend
vertex-based singly connected networks. unclear whether constraint-based networks
efficiently reduced vertex-based form inserting new variables, conjecture
true.
2.2.3 Probabilistic Inference
Similarly Bayesian networks, primary use credal networks deriving bounds
probabilities implied model. precise characterization depends choice
irrelevance concept. define inference problem strong independence follows.
STRONG-INF
Input: credal network (X, G, Q), target node t, assignment xt Xt ,
(possibly empty) set evidence nodes O, assignment xO XO .
Output: numbers
min Pp (Xt = xt |XO = xO ) max Pp (Xt = xt |XO = xO ) ,

pKS

pKS

KS strong extension network.
analogous inference problem defined epistemic irrelevance, simply
replacing strong extension output problem epistemic extension:
612

fiProbabilistic Inference Credal Networks: New Complexity Results

EPISTEMIC-INF
Input: credal network (X, G, Q), target node t, assignment xt Xt ,
(possibly empty) set evidence nodes O, assignment xO XO .
Output: numbers
min Pp (Xt = xt |XO = xO ) max Pp (Xt = xt |XO = xO ) ,

pKE

pKE

KE epistemic extension network.
assume problems lower probability evidence zero (i.e.,
minp Pp (XO = xO ) = 0), value solution (that is, minimization may achieve
zero maximization one).6 recent treatment zero probability case, see
work de Bock de Cooman (2013). emphasize complexity results hold
true regardless zero probabilities treated, take appropriate care
avoid conditioning event zero probability reductions (as become
clear later on).
Example 4. Consider network Example 2, assume target node
= 3, xt = 0 XO empty set. strong extension KS defined
Example 3. outcome STRONG-INF
X
min P(X3 = 0) = min
p1 (x1 )p2 (x2 )px3 1 x2 (0)
pKS

x1 ,x2

= 1 + min{2p1 (0)p2 (0) p1 (0) p2 (0)}
= 1 (2 1/2 1/2 1/2 1/2) = 1/2 ,
minimizations right performed p1 p2 ,
X
max P(X3 = 0) = max
p1 (x1 )p2 (x2 )px3 1 x2 (0)
pKS

x1 ,x2

= 1 + max{2p1 (0)p2 (0) p1 (0) p2 (0)}
= 1 (2 0.4 0.4 0.4 0.4) = 0.52 .
outcome EPISTEMIC-INF values solutions linear programs
min{p(0, 0, 0) + p(1, 1, 0) : p KE } = 5/11 < 1/2

max{p(0, 0, 0) + p(1, 1, 0) : p KE } = 5/9 > 0.52 ,
KE epistemic extension defined Example 3.
fact lower bound (resp., upper bound) EPISTEMIC-INF example
smaller (resp., greater) lower bound (upper bound) STRONG-INF
direct consequence fact strong extension contained epistemic
extension.
6. upper probability evidence positive, regular extension used compute nonvacuous inferences (see Walley, 1991, Appendix J).

613

fiMaua, de Campos, Benavoli & Antonucci

Let also z denote Kroneckers delta function z, returns one z zero
elsewhere. Since one-to-one mapping expectation probability,
state inference problems slightly different equivalent way.
STRONG-INF2
Input: credal network (X, G, Q), target node t, assignment xt Xt ,
(possibly empty) set evidence nodes O, assignment xO XO .
Output: solution optpKS Ep ([ xt ]xO ) = 0, KS strong
extension network, opt {min, max}.
EPISTEMIC-INF2
Input: credal network (X, G, Q), target node t, assignment xt Xt ,
(possibly empty) set evidence nodes O, assignment xO XO .
Output: solution optpKE Ep ([ xt ]xO ) = 0, KE
epistemic extension network, opt {min, max}.
main advantage reformulations linear-fractional programming
problem transformed linear programming problem, facilitates obtaining
results. refer reformulations interchangeably, mind
equivalence.

3. Complexity Results
section study complexity inference credal networks respect
irrelevance concept adopted, network topology variable domain cardinality.
3.1 Previously Known Results
Computing STRONG-INF notoriously hard task, whose complexity strongly depends
topology DAG cardinality variable domains. Cozman et al.
(2004) proved problem NPPP -hard. De Campos Cozman (2005) studied
parametrized complexity concluded problem NP-hard even singly
connected networks bounded treewidth. long-known positive result 2U algorithm Fagiuoli Zaffalon (1998), solves problem polynomial time
underlying graph polytree variables binary. networks assuming naive
Bayes topology (i.e., containing single root variable single parent remaining variables), Zaffalon (2002) showed STRONG-INF computed efficiently
query root variable. Zaffalon Fagiuoli (2003) showed problem
polynomial-time solvable tree-shaped networks evidence. De Campos
Cozman (2005) showed obtaining approximate solutions provably maximum error bound impossible unless P equals NP, even polytrees. hand,
Maua, de Campos, Zaffalon (2013) showed variable cardinalities
treewidth assumed bounded, fully polynomial-time approximation scheme
finds solutions withing given error time polynomial input 1/.
known positive result regarding complexity approximate inference
credal networks exact solution NP-hard.
614

fiProbabilistic Inference Credal Networks: New Complexity Results

Much fewer known complexity EPISTEMIC-INF. positive result
given de Cooman et al. (2010), developed polynomial-time algorithm computations credal trees.
3.2 Outline Contributions
first contribution (sect. 3.3) development credal networks polynomial-time
computable numbers. show networks allow us approximate arbitrarily well
network still inducing positive lower probabilities event. useful
extend subsequent complexity results (some involving events lower probability
zero) case lower probability event strictly positive.
proceed derive complexity results STRONG-INF EPISTEMICINF. first new complexity result concerns precise-vacuous networks, credal
networks comprised vacuous root nodes precise non-root nodes (sect. 3.4). credal
network transformed precise-vacuous network STRONG-INF provides
results original network; moreover, STRONG-INF known NPPP hard models. show solutions STRONG-INF EPISTEMIC-INF
coincide precise-vacuous networks, implies NPPP -hardness EPISTEMIC-INF.
hardness result holds even case binary variables (and multiply connected
networks).
next show problems remain NP-hard singly connected credal networks
even constraint variables take three values bound treewidth
two (sect. 3.5). show sequence STRONG-INF NP-hard already credal
trees (sect. 3.6); discussed, EPISTEMIC-INF polynomial-time computable case.
Imprecise hidden Markov models tree-shaped credal networks extend standard
(precise) Hidden Markov Models (HMMs) allow imprecisely specified parameters
form credal sets. HMMs commonly used represent time-dependent process wide applicability. Since imprecise HMMs particular instances credal
trees, EPISTEMIC-INF performed polynomial time models. show
Section 3.7 target node last node longest directed path
network inferences strong independence epistemic irrelevance coincide (in
context time-series prediction, inference known filtering). consequence,
STRONG-INF also polynomial-time computable queries. despite fact
strong epistemic extensions might disagree models, show
counter-example different type query. leave open complexity
general inferences imprecise HMMs strong independence.
corollaries equivalence certain type inference HMMs, obtain
STRONG-INF EPISTEMIC-INF also coincide marginal inference (i.e., evidence) tree-shaped networks, last-node inference imprecise Markov chains (sect. 3.8)
naive Bayes structures (sect. 3.9). results previously obtained independently irrelevance concept tractability thought coincidental.
organize presentation mentioned results according complexity
underlying DAG, listing results complex structures simplest
ones. reason proceed fashion allow obtaining results simpler
615

fiMaua, de Campos, Benavoli & Antonucci

models imprecise Markov chains naive Bayes structures corollaries results
complex models imprecise hidden Markov models.
3.3 Networks Specified Computable Numbers
presenting complexity results, need introduce concept polynomialtime computable numbers, discuss properties networks specified
numbers. used within later proofs essential way, including (but only)
showing hardness results hold true even assume possible event
positive probability.
number r polynomial-time computable exists transducer Turing machine
Mr that, integer input b (represented binary string), runs time
poly(b) (the notation poly(b) denotes arbitrary polynomial function b, might
indicate different polynomial time used) outputs rational number
r0 (represented numerator denominator binary strings) |r
r0 | < 2b . special relevance us numbers form (2v1 2v2 )/(1 + 2v3 ),
v1 , v2 v3 non-negative rationals greater two. rational v
zero two build machine outputs rational r0 approximates
2v precision b time poly(b) computing Taylor expansions 2v around
zero sufficiently many terms (depending value b) similar proof
Lemma 4 work Maua et al. (2013). desired numbers obtained
corresponding fractional expression. following lemmas ensure outcome
STRONG-INF networks specified polynomial-time computable numbers
approximated arbitrarily well using network specified positive rational numbers.
allows us specify desired precision nodes network numerical
parameters approximated positive rational numbers.
Lemma 1. Consider vertex-based credal network N whose numerical parameters
specified polynomial-time computable numbers encoded respective machines (or
directly given rational numbers), let b size encoding N . Given
subset nodes N 0 N N rational number 1 2poly(b) , construct
time poly(b) vertex-based credal network N 0 variables whose numerical
parameters specify credal sets nodes N 0 rational numbers greater
2poly(b) (numerical parameters related nodes N 0 kept unchanged),
polynomial-time computable surjection (p, p0 ) associates extreme p
strong extension N extreme p0 strong extension N 0 satisfying
max |Pp0 (XA = xA ) Pp (XA = xA )| ,
xA

subset XA X variables.
Proof. Take N 0 equal N except computable number r used specification N nodes N 0 replaced rational r0 |r0 r| < 2(n+1)(v+1)1 ,
n number variables, v maximum cardinality domain
variable N . 2poly(b) , run Turing machine Mr used represent r
input poly(b)+(n+1)(v+1)+1 obtain r0 time O(poly(poly(b) + (n + 1)(v + 1) + 1)),
O(poly(b)). obtaining r0 , add 2(n+1)(v+1)1 ensure r < r0 <
616

fiProbabilistic Inference Credal Networks: New Complexity Results

r + 2(n+1)(v+1) , is, approximation above. However, exactly one
probability values distribution used represent extreme local credal set
N 0 approximated way computed one minus sum
numbers ensure distribution adds exactly one; choose greatest
value (by trying (at most) v states, probability value least
1/v), error respect corresponding original computable number
(v 1) 2(n+1)(v+1) < 2n(v+1) . construction ensures every created
rational number greater 2(n+1)(v+1)1 > 2poly(b) error
2n(v+1) original corresponding number.
Let qi (xi |xPa(i) ) qi0 (xi |xPa(i) ) denote, respectively, parameters N N 0 (i.e.
corresponding extreme distributions local credal sets Q(Xi |xPa(i) ) two
networks) qi0 (xi |xPa(i) ) approximated version computed qi (xi |xPa(i) )
explained. Consider assignment x variables N (or NQ0 ). Let also p
extreme strong extension N . p factorizes p(x) = qi (xi |xPa(i) ),
combination extreme distributions qi (|xPa(i) ) Q(Xi |xPa(i) ), N . Finally,
let p0 extreme distribution strong extension N 0 satisfies p0 (x) =
Q
0
0
n(v+1) . follows
qi (xi |xPa(i) ). construction, |qi (xi |xPa(i) ) qi (xi |xPa(i) )| 2
binomial expansion factorization p0 (x) x



p0 (x) =
qi0 (xi |xPa(i) )
2n(v+1) + qi (xi |xPa(i) )




=

X

(2nvn )n|A|



qi (xi |xPa(i) )

iA



2n 2nvn +



qi (xi |xPa(i) )



= p(x) + 2nv .
second inequality follows fact one term p(x) expansion
2n 1 terms written product 2n(v+1) non-negative numbers
less equal one. similar reasoning, show


p0 (x)
qi (xi |xPa(i) ) 2n(v+1) p(x) 2nv .


Thus, maxx |p0 (x) p(x)| 2nv . consider subset variables XA
assignment xA XA . Since
X
Pp0 (XA = xA ) =
p0 (x0 ) ,
x0 :x0A =xA

term p0 (x0 ) sum satisfies p0 (x0 ) p(x0 ) + 2nv , less
v n 2vn terms summed, follows
X

Pp0 (XA = xA )
p(x) + 2vn Pp (XA = xA ) + .
x0 :x0A =xA

analogous argument used show Pp0 (XA = xA ) Pp (XA = xA ) . Note
obtained mapping (p, p0 ) surjection construction.
617

fiMaua, de Campos, Benavoli & Antonucci

lemma following direct consequence computation
STRONG-INF polynomial-time computable numbers. restriction application computable numbers must either zero greater
exponentially close zero.
Corollary 1. Consider vertex-based credal network N whose numerical parameters
specified polynomial-time computable numbers encoded respective machines (or
directly given rational numbers), number lies properly ]0, [,
0 1. Let b size encoding network. Given subset
nodes N 0 N N rational number 2poly(b) < , construct
time poly(b) vertex-based credal network N 0 variables whose numerical
parameters defining credal sets related nodes N 0 strictly positive rational numbers
greater 2poly(b) (numbers defining credal sets nodes N 0 kept unchanged),
7
|STRONG-INF(N 0 , t, xt , O, xO ) STRONG-INF(N , t, xt , O, xO )| ,
query t, xt , O, xO either = minp Pp (xO ) > 0 N .
Proof. According Lemma 1, polynomial-time computable network N 0 whose
numerical parameters specify credal sets related nodes N 0 positive rational numbers polynomial-time computable surjection (p, p0 ) p p0
are, respectively, extreme distributions strong extension N N 0 , satisfy
|Pp0 (xA ) Pp (xA )| n+1 /3 XA X xA XA . follows
Pp0 (xt |xO ) =

Pp0 (xt , xO )
Pp (xt , xO ) n+1 /3

,
Pp0 (xO )
Pp (xO ) + n+1 /3

p0 image p according surjection. Pp (xt , xO ) = 0, equation
useless vanishes. Otherwise, Lemma 7 work de Campos Cozman
(2013),
Pp (xt , xO ) n+1 /3
2n+1 /3

P
(x
|x
)

Pp (xt |xO ) .
p


Pp (xO ) + n+1 /3
n
side inequality obtained analogously (using Lemma 7
work de Campos & Cozman, 2013, except case Pp (xt , xO ) = 0,
following reasoning valid without need lemma):
Pp (xt , xO ) + n+1 /3
2n+1 /3

P
(x
|x
)
+
p


Pp (xO ) n+1 /3
n n+1 /3
2
Pp (xt |xO ) +
Pp (xt |xO ) + .
3

Pp0 (xt |xO )

Hence, |Pp0 (xt |xO )Pp (xt |xO )| . Let p extreme distribution strong extension
N Pp (xt |xO ) = minqKS Pq (xt |xO ), KS denotes strong extension
7. abuse notation STRONG-INF, defined opt {min, max}. intend mean
equation valid options opt.

618

fiProbabilistic Inference Credal Networks: New Complexity Results

N .
min Pq (xt |xO ) = Pp (xt |xO ) Pp0 (xt |xO ) min0 Pq0 (xt |xO ) ,
q 0 KS

qKS

p0 first inequality image p according surjection, KS0
last inequality strong extension N 0 . follows
min Pq0 (xt |xO ) min Pq (xt |xO ) .

q 0 KS0

qKS

side comes contradiction. Suppose
min Pq (xt |xO ) min0 Pq0 (xt |xO ) > min Pq (xt |xO ) > min0 Pq0 (xt |xO ) .

qKS

q 0 KS

q 0 KS

qKS

Hence would exist extreme q 0 KS0 |Pq0 (xt |xO ) Pq (xt |xO )| >
q KS , impossible mapping (q, q 0 ) surjection. analogous proof
works showing upper bounds according two networks differ
.
3.4 Precise-Vacuous Networks
show EPISTEMIC-INF NPPP -hard arbitrary networks, need following
result, shows inferences strong independence epistemic irrelevance
coincide precise-vacuous networks.
Proposition 2. Consider credal network whose root nodes vacuous non-root
nodes precise. Let non-root node, xt arbitrary value Xt = .
STRONG-INF equals EPISTEMIC-INF.
Proof. Let XR vacuous variables associated root nodes (hence vacuous
local credal sets), XI denote remaining variables (which precise). every
x
precise node I, let qi Pa(i) (xi ) single distribution associated credal set
Q(Xi |xPa(i) ). Consider arbitrary distribution p epistemic extension KE , let
< topological ordering nodes. assignment x X, write x<i denote
coordinates j < x according topological ordering. every node set
{j N : j < i} subset Nd(i), follows definition epistemic extension
x
Pp (xi |x<i ) = qi Pa(i) (xi ) every precise node assignments xi x<i .
Chain Rule
x X :

Pp (x) = Pp (xR )



Pp (xi |x<i ) = q(xR )

iI



x

qi Pa(i) (xi ) ,

iI

q distribution XR (since nodes vacuous, distribution satisfies
constraints KE them). stated, let xt value interest Xt . result
619

fiMaua, de Campos, Benavoli & Antonucci

EPISTEMIC-INF thus given
min Pp (Xt = xt ) =

pKE

=

min
qV (XR )

min
qV (XR )

=

min
qV (XR )

X

xt (xt ) q(xR )

x

X

q(xR )

xR

X

XY



x

qi Pa(i) (xi )

iI
xPa(i)
qi
(xi )xt (xt )

xI iI

q(xR ) g(xR ) ,

xR

xPa(i)
def P Q
g(xR ) =
(xi ). According last equality, lower
xI
iI xt (xt )qi
marginal probability Xt = xt convex combination g(xR ). Hence,
X xPa(i)
min Pp (Xt = xt ) min
qi
(xi ) .
pKE

xR

xI\{q} iI

rightmost minimization exactly value lower marginal probability returned
STRONG-INF, since strong extension contained epistemic extension,
inequality tight. analogous result obtained upper probability
substituting minimizations maximization inverting inequality above.
class networks considered result might seem restrictive first
sight. However, Antonucci Zaffalon (2008) showed STRONG-INF credal
network whose local credal sets represented vertex-based form reduced
linear time problem credal network containing vacuous precise
nodes. network transformed linear time precise-vacuous network
(i.e., one root nodes vacuous non-root nodes precise) applying
Transformation 6 work Maua, de Campos, Zaffalon (2012a),8 increases
treewidth network three. Hence, vertex-based credal network
reduced polynomial time precise-vacuous network STRONGINF provides result original network (and whose treewidth remains
bounded, originally were). hardness EPISTEMIC-INF precise-vacuous credal
networks follows immediately hardness inference strong independence
Proposition 2, following corollary shows.
Corollary 2. STRONG-INF EPISTEMIC-INF NPPP -hard even variables
binary numerical parameters strictly positive.
Proof. Cozman et al. (2004) used reduction E-MAJSAT STRONG-INF without
evidence binary credal network whose root nodes vacuous non-root nodes
precise show inference NPPP -hard. Since according Proposition 2 result
EPISTEMIC-INF same, EPISTEMIC-INF also NPPP -hard. order show
result valid also numerical parameters strictly positive, sketch
proof avoid repeating formulation E-MAJSAT problem. Using
Lemma 1 epsilon = 2poly(b) smaller precision number involved
8. Strictly speaking, work Maua et al. (2012a) deals influence diagrams; link
credal networks established Antonucci Zaffalon (2008) de Campos Ji (2008).

620

fiProbabilistic Inference Credal Networks: New Complexity Results

calculation, build new network numerical parameters strictly positive
variation result STRONG-INF negligible still decide
E-MAJSAT (further details small omitted simplicity,
2
gap instances large enough 2O((n+m) ) suffice, n,
number variables clauses specification E-MAJSAT, see Park & Darwiche,
2004, Thm. 2). EPISTEMIC-INF contains STRONG-INF, result applying
Lemma 1 results STRONG-INF new network old
network (the latter equals EPISTEMIC-INF). Hence, EPISTEMIC-INF new
network strictly positive numerical parameters also decides E-MAJSAT.
Note result holds irrespective local credal sets represented, since
vacuous precise nodes mapped constraint-based vertex-based form
vice-versa polynomial time.
3.5 Singly Connected Networks
turn attention singly connected networks. first result direct consequence Proposition 2 NP-hardness EPISTEMIC-INF singly connected credal
networks, since STRONG-INF NP-hard singly connected networks, even admit
imprecision root nodes:
Corollary 3. EPISTEMIC-INF NP-hard singly connected credal networks.
Proof. work de Campos Cozman (2005) shown STRONG-INF
NP-hard precise-vacuous singly connected networks. Since Proposition 2 shows
EPISTEMIC-INF reduced STRONG-INF input, result follows.
proof NP-hardness STRONG-INF provided de Campos Cozman (2005)
requires variable domain cardinalities unbounded. present stronger
result NP-hardness credal inference networks imprecise variables binary
precise ones ternary. show NP-hardness credal inference
singly connected networks bounded variable cardinality.
Theorem 1. STRONG-INF EPISTEMIC-INF NP-hard even network singly
connected treewidth two, imprecise variables binary, precise
variables (at most) ternary. Moreover, numerical parameters network
strictly positive.
Proof. defer treatment zero numerical parameters final part. build
singly connected credal network underlying graph Figure 3. variables
(associated nodes) upper row binary vacuous, namely X1 , . . . , Xk ,
remaining variables Xk+1 , , X2k+1 ternary precise. local credal
sets associated precise nodes singletons Q(Xk+1 ) contains uniform
distribution q(xk+1 ) = 1/3, and, = k + 2, . . . , 2k + 1, Q(Xi |xi1 , xik1 ) contains
conditional distribution q(Xi |xi1 , xik1 ) specified Table 1. rational numbers vi
table shall defined later on. Consider extreme distribution p(x) strong
621

fiMaua, de Campos, Benavoli & Antonucci

k+1

1

2

3

k+2

k+3

k+4

k



2k+1

Figure 3: Credal network structure used prove Theorem 1. shaded node
target.
q(xi |xi1 , xik1 )

xi = 1

xi = 2

xi = 3

xi1 = 1, xik1 = 1
xi1 = 2, xik1 = 1
xi1 = 3, xik1 = 1
xi1 = 1, xik1 = 0
xi1 = 2, xik1 = 0
xi1 = 3, xik1 = 0

2vi

0
1
0
0

1 2vi
0
1
0
1 2vi
1

0
0
1
0
0

2vi
0

Table 1: Local probability distributions used prove Theorem 1
extension network. follows x
p(x) = q(xk+1 )

2k+1


q(xi |xi1 , xik1 )


iA

i=k+2

1 (xi )



0 (xi ) ,

iA
/

{1, . . . , k}. extreme distributions local vacuous sets
binary variables 0 1 , choice local extreme root node
associated choice either including excluding corresponding node in/from
def

A. Let = {1, . . . , k} \ denote complement set respect {1, . . . , k}.

( Q
2k+1
1
q(xi |xi1 , xik1 ), xA = 1 xA = 0 ;
p(x) = 3 i=k+2
0,
otherwise.
follows
Pp (X2k+1 = 1) =

X

p(x)1 (x2k+1 ) =

x

2

P

iA

3

vi

Pp (X2k+1 = 2) =

2

P

iA

3

vi 2

.

show NP-hardness credal inference reducing NP-complete PARTITION
problem (Garey & Johnson, 1979) computation maxpKS Pp (X2n+1 = 3).
define PARTITION follows.
PARTITION
Input: List positive integers z1 , . . . , zk .
Output: subset {1, . . . , k}
X
X
zi =
zi ?
iA

iA

622

fiProbabilistic Inference Credal Networks: New Complexity Results

h(v)

1.2

1.1

1
0

0.5

1
v

1.5

2

Figure 4: Function used reduction proof Theorem 1.
Notice equality equivalent
k

X

zi /z = 1 ,

1X
z =
zi .
2
i=1

iA

def
def P
Define exponents

Table
1

v
=
z
/z,

let
v
= iA vi . follows



P
vA = 2 iA vi . instance PARTITION yes-instance (i.e., output
PARTITION yes), vA = 1, whereas no-instance (i.e.,
output no), A, follows |vA 1| 1/(2z) numbers
input integers hence sums two different sets either equal differ
least one. Consider function

h(vA ) =

2(vA 1) + 2vA 1
.
2

graph function depicted Figure 4. Seen function continuous variable
vA [0, 2], function strictly convex, symmetric around one, achieves
minimum value one vA = 1. Thus, PARTITION returns yes minA h(vA ) = 1,
returns
4

min h(vA ) 21/(2z)1 + 21/(2z)1 2(2z)


> 1 + (2z)4 /2 = 1 + 1/(32z 4 ) ,

second inequality due Lemma 24 work Maua et al. (2012a),
4

def

strict inequality follows first-order Taylor expansion 2(2z) . Let =
(1 + z 4 /64)/3. computing STRONG-INF query X2n+1 = 3 evidence,
decide PARTITION,
1 max Pp (X2k+1 = 3) = min (Pp (X2k+1 = 1) + Pp (X2k+1 = 2)) = min
p



h(vA )

3

result PARTITION yes. remains show polynomially
encode numbers 2zi /z . done applying Lemma 1 small enough
623

fiMaua, de Campos, Benavoli & Antonucci

0
1

2

3



k

k+1

k+2

k+3



2k

Figure 5: DAG credal tree used prove Theorem 2.
computable time polynomial size partition problem: = 1/(3 64z 4 )
suffices. Note apply Lemma 1 non-root nodes leave root
nodes untouched vacuous, according Proposition 2, outcome EPISTEMICINF same, proving also NP-hardness. Now, applying Lemma 1 root
vacuous nodes, ensure numerical parameters strictly positive still yield
result used decide PARTITION. EPISTEMIC-INF contains STRONGINF, result applying Lemma 1 results STRONG-INF
new network network vacuous root nodes. Hence, EPISTEMIC-INF
new network strictly positive numerical parameters also decides PARTITION.
3.6 Credal Trees
previous complexity results showed that, theoretical standpoint, computing
EPISTEMIC-INF difficult solving STRONG-INF. underlying graph
tree, de Cooman et al. (2010) showed EPISTEMIC-INF computed efficiently,
previously unknown whether similar result could obtained STRONG-INF.
next result shows case equivalence tractability two
different irrelevance concepts hold unless P equals NP.
Theorem 2. STRONG-INF tree-shaped credal networks NP-hard, even one variable ternary precise rest binary, even numerical parameters
strictly positive.
Proof. show hardness reduction PARTITION defined previously. before,
P
def
def P
define vi = zi /z, vA = iA vi , note vA = 2 iA vi . also let h(vA )
(thus h strictly convex [0, 2], symmetric around one, achieves
minimum value one vA = 1). Given instance PARTITION (i.e., list integers),
build credal tree N variables X0 , . . . , X2k DAG Figure 5. root
variable X0 takes values {1, 2, 3}, precise uniformly distributed (i.e., local
credal set contains distribution q0 (x0 ) = 1/3). remaining variables
binary take values {0, 1}. = 1, . . . , k, specify local conditional credal
sets Q(Xi |x0 ) singletons {qix0 }

vi
vi

2 /(1 + 2 ),
qix0 (1) = 1/(1 + 2vi ),


1/2,
624

x0 = 1,
x0 = 2,
x0 = 3.

fiProbabilistic Inference Credal Networks: New Complexity Results

= 1 + k, . . . , 2k specify local credal sets Q(Xi |xik ) = {p V (Xi ) : p(1)
1}, = 2k3 /(64z 4 ). local credal sets represented either
vertex-based form two extreme distributions couple constraints.
Let
Pp (X0 = 3, XO = xO )
def
= max Pp (X0 = 3|XO = xO ) = max
.
pKS
pKS
Pp (XO = xO )
Hence, solution
"
#
X
max
(3 (x0 ) )Pp (X0 = x0 , XO = xO ) = 0 .
pKS

x0

definition, extreme distribution p strong extension KS satisfies x X
xk+1 = xk+2 = = x2k = 1 equality
p(x) = q0 (x0 )

k


qix0 (xi )ixi ,

i=1

ixi


number [, 1]. Let = {k + 1, . . . , 2k} xO = (1, . . . , 1). follows
solution
max

X

(3 (x0 ) )q0 (x0 )

x0 ,...,xk

k


qix0 (xi )ixi = 0 ,

i=1

maximization performed i0 , i1 , = 1, . . . , k. Consider j {1, . . . , k}
let
x def
j j =

X

X

(3 (x0 )

) q0 (x0 )qjx0 (xj )

x0 ,...,xj1 xj+1 ,...,xk

k


[qix0 (xi )ixi ] .

i=1,i6=j

Then,
X

max

(3 (x0 ) ) q0 (x0 )

x0 ,...,xk

j0

k



[qix0 (xi )ixi ] = max j0 j0 + j1 j1 .

i=1

j1

Since

positive, maximization right-hand side equals
zero j0 j1 zero different signs. former case,
value j0 j1 maximizes expression, assume (j0 , j1 ) equals (, 1)
(1, ). latter case, j0 < j1 implies (j0 , j1 ) equals (, 1) order maximize
expression, (j0 , j1 ) = (1, ) would otherwise. Since selected j arbitrarily,
result holds j. Thus, maximization equivalent selecting, = 1, . . . , k,
value yi {0, 1} i0 = 1yi i1 = yi . follows
max

X
x0 ,...,xk

(3 (x0 ) ) q0 (x0 )

k


[qix0 (xi )ixi ] =

i=1

max

y{0,1}k

X

(3 (x0 ) ) q0 (x0 )

x0 ,...,xk

k

[qix0 (xi )(1xi )(1yi ) xi yi ] .
i=1

625

fiMaua, de Campos, Benavoli & Antonucci

rearranging terms, obtain
max

y{0,1}k

X

(3 (x0 ) ) q0 (x0 )

x0

k

x0

qi (0)1yi + qix0 (1)yi ,
i=1

construction equals
k

k

k

i=1

i=1

i=1

1yi
vi 1yi
1Y1+
max
[
+ 2vi yi ] +
[2
+ yi ] +
3
3
3
2
y{0,1}k

!
,

Q
= ki=1 qi2 (1) (recall qi2 (1) conditional probability value Xi = 1
given X0 = 2). binary vector seen characteristic vector subset
{1, . . . , k}. Define


def
(1 + 2vi )
(2vi + )
bA =
iA

iA

every subset A. optimization rewritten following optimization
subsets A: find
!


1 1+ k


+ max (bA + bA ) = 0 .

3
2
3
Solving expression , get

=

1+

2
1+

!1

k

min (bA + bA )


.

Define function g(a)


def

g(a) = 1 +

2
1+

k
(1 + a)

def

real number a, let aA = bA + bA 1 {1, . . . , k}. =
(minA g(aA ))1 . Note g(aA ) > 1 + (1 + aA )2k , > 2k (this used
later). follows Binomial Theorem value bA close value
2vA above.
2vA bA (2vA + 2k )(1 + )k
(2vA + 2k )(1 + 2k)
2vA + 2k+2 ,
used inequality (1 + r/c)c 1 + 2r valid r [0, 1] positive integer
c (Maua, de Campos, & Zaffalon, 2011, Lemma 37). Thus conclude value aA
close (again above) h(vA ) 1.
h(vA ) 1 aA h(vA ) 1 + 2k+3 = h(vA ) 1 + 1/(64z 4 ) .
626

fiProbabilistic Inference Credal Networks: New Complexity Results

Now, partition problem yes-instance, h(vA ) = 1 (recall behavior h
proof Theorem 3) thus aA 1/(64z 4 ), no-instance,
h(vA ) > 1 + 1/(32z 4 ) thus aA > 1/(32z 4 ). Hence, gap least 1/(64z 4 )
value aA yes- no-instances, decide partition problem
verifying whether g(3/(128z 4 ))1 . proof shall completed guarantee
approximate polynomial time irrational numbers used specify
credal tree g(a) well enough g(3/(128z 4 ))1 falls exactly middle
gap values yes- no-instances (because g linear a). First, note






k
1
1
1
2
g
g
=
,
32z 4
64z 4
64z 4 1 +
greater 2k /(64z 4 ) (since > 2k ). gap value least
1
1
g(1/(32z 4 )) g(1/(64z 4 ))

=
g(1/(64z 4 )) g(1/(32z 4 ))
g(1/(64z 4 ))g(1/(32z 4 ))
g(1/(32z 4 )) g(1/(64z 4 ))
>
g(1/(32z 4 ))2
k
2 /(64z 4 )
2k
>
.
>
1
k )2
4 64z 4
(1 + (1 + 32z
4 )2
k

2
0
apply Corollary 1 = 12 464z
4 obtain N network N made
positive rational numbers. guarantees separation yes-instances
no-instances PARTITION continue exist.

credal network used reduction proves previous result sense
simplest tree-shaped network solving STRONG-INF hard, since problem
would polynomial-time solvable root node replaced binary variable.
also interesting describes naive Bayes structure single layer latent variables,
useful topology robust classification problems non-linearly separable feature spaces.
3.7 Imprecise Hidden Markov Models
imprecise hidden Markov model (HMM) credal tree whose nodes partitioned
hidden manifest nodes hidden nodes form chain (i.e., sequence
nodes one node linking next sequence), manifest
nodes leaves graph. HMMs widely used represent discrete dynamic systems
whose output given time step stochastically determined current state
system, assumed partially observable.
Since HMM simply credal tree, algorithm de Cooman et al. (2010)
used efficiently compute EPISTEMIC-INF HMMs, 2U used solve
STRONG-INF variables binary. networks variables taking
two values, polynomial-time known STRONG-INF. section, show
evidence variables farther (in sense number nodes
path) root node target variable, outcomes STRONG-INF
EPISTEMIC-INF coincide. cases, run de Cooman et al.s (2010) algorithm
627

fiMaua, de Campos, Benavoli & Antonucci

1

2

4

3

Figure 6: Credal HMM Example 5.
compute STRONG-INF polynomial time. however always true, is,
types queries results STRONG-INF EPISTEMIC-INF differ,
following example shows.
Example 5. Consider HMM length two whose topology depicted Figure 6.
variables binary take values {0, 1}. Variables X1 X2 hidden,
variables X3 X4 manifest. local credal sets given Q(X1 ) = Q(X2 |0) =
Q(X4 |0) = {p V (X4 ) : p(1) = 1/4}, Q(X2 |1) = Q(X4 |1) = {p V (X4 ) : p(1) = 3/4},
Q(X3 |0) = {p V (X3 ) : 1/2 p(1) 3/4} Q(X3 |1) = {p V (X3 ) : 1/4 p(1)
1/2}. Thus, variable X3 imprecise, remaining variables precise. Consider
query target X4 = 0 evidence X3 = 0. lower bound STRONG-INF
value solves equation
X
X
min
q3x2 (0)g (x2 ) =
min q3x2 (0)g (x2 ) = 0 ,
x2

x2

minimizations performed q3x2 Q(X3 |x2 ), x2 = 0, 1,
def X
g (x2 ) =
(0 (x4 ) ) q1 (x1 )q2x1 (x2 )q4x1 (x4 ) ,
x1 ,x4

q1 = q20 = q40 = (3/4, 1/4) q21 = q41 = (1/4, 3/4). values q3x2 (0) depend
signs g (0) g (1), ought different expression vanish.
Solving four possibilities, taking minimum value , find
= 4/7 > 1/2.
lower bound EPISTEMIC-INF value solves
min

X

q1 (x1 )q2x1 (x2 )q4x1 (x4 )qx1 ,x2 ,x4 (0)h (x4 ) =

x1 ,x2 ,x4

(1 )

X

q1 (x1 )q2x1 (x2 )q4x1 (0) min qx1 ,x2 ,0 (0)

x1 ,x2



X

q1 (x1 )q2x1 (x2 )q4x1 (1) max qx1 ,x2 ,1 (0) = 0 ,

x1 ,x2

h (x4 ) = 0 (x4 ) , q1 , q2x1 q4x1 defined before, qx1 ,x2 ,x4 Q(X3 |x2 )
every x1 , x2 , x4 . Solving equation obtain = 13/28 < 1/2.
example shows STRONG-INF EPISTEMIC-INF might differ, even
simple case HMMs binary variables. currently unknown whether type
inference hard STRONG-INF. following result shows least particular
case, computations STRONG-INF EPISTEMIC-INF HMMs coincide.
628

fiProbabilistic Inference Credal Networks: New Complexity Results

0

2

n-2

1

3

n-1

n

Figure 7: DAG HMM considered Theorem 3.
Theorem 3. Consider separately specified HMM variables X0 , . . . , Xn . variables
associated odd numbers manifest, remaining variables hidden (see
Figure 7). Consider also target hidden node Xn = xn , evidence XO = xO
subset manifest nodes. outcomes STRONG-INF EPISTEMIC-INF
same.
def

Proof. Define f (xn ) = xn (xn ) given , consider distribution p
epistemic extension KE minimizes
X
f (xn )p(x) .
xX:xO =xO

Let < topological ordering
nodes. Chain Rule, x p
Qn
factorizes p(x) = Pp (x0 ) i=1 Pp (xi |x<i ), x<i denotes coordinates xj x
j < according topological ordering (we also write xi x>i denote analogous
projections). Assume non-negative integer less equal n holds

X
X

xPa(j)
f (xn )p(x)
f (xn )
Pp (xj |x<j )
pj
(xj ) ,
x:xO =xO
x
pj Pa(j)

j<i

x:xO =xO

ji


recursively defined extreme distribution local credal set
Q(Xj |xPa(j) ) minimizes either
X xPa(j)
X
xPa(k)
pj
(xj )
f (xn )
pk
(xk ) ,
xj

j O,

x>j
x

pj Pa(j) (xj )

X

k>j

f (xn )

x>j



x

pk Pa(k) (xk ) ,

k>j

j O, xj value Xj compatible xO . show induction
= n, . . . , 0 assumption true. 1
X

xPa(j)
f (xn )
Pp (xj |x<j )
pj
(xj ) =
j<i

x:xO =xO

X

ji



Pp (xj |x<j )

x<i1 :xO =xO j<i1

X



x<i1 :xO =xO j<i1

Pp (xj |x<j )

X

Pp (xi1 |x<i1 )

xi1

X

f (xn )

xi

X

min

qQ(Xi1 |xPa(i1) )

X
x:xO =xO

629

q(xi1 )

xi1

f (xn )

j<i1

x

pk Pa(k) (xk )

ki

X
xi





f (xn )



x

pk Pa(k) (xk ) =

k>i

Pp (xj |x<j )


ji1

x

pj Pa(j) (xj ) ,

fiMaua, de Campos, Benavoli & Antonucci


inequality follows definition
P
P epistemic extension, implies
h(x
)P
(x
|x
)

min

p Nd(i)
qQ(Xi |xPa(i) )
xi
xi h(xi )q(xi ) function h xi (note
Nd(i) {j < i}, minimization right constant w.r.t. values
xj<i:j Pa(i)
). case node analogous sum substituted single
/
term. = n, follows
X
X
X

f (xn )Pp (xt |x<n )
f (xn )p(x) =
Pp (xj |x<j )
xt

xj<n :xO =xO jn

x:xO =xO



X

f (xn )pnxn2 (xn )



Pp (xj |x<j ) ,

j<n

x:xO =xO

basis induction holds. = 0,
X
xPa(j)
X
f (xn )p(x)
f (xn )p0 (x0 )
pj
(xj ) ,
x:xO =xO



x:xO =xO

lower bound STRONG-INF. Thus, since epistemic extension contains
strong extension, inequality tight. particular, equality holds
lower bound EPISTEMIC-INF, follows
X
X
min
f (x)p(x) = min
f (x)p(x) = 0 ,
pKS

x:xO =xO

pKE

x:xO =xO

KS denotes strong extension. analogous proof shows also upper
bounds coincide.
previous result shows least particular case one seeks probability last variable, STRONG-INF computed polynomial time. Although
restrictive, type inference highly relevant, corresponds predicting future
state partially observable dynamic system whose future state depends level
current (unknown) state. also another type inference trees
insensitive irrelevance concept adopted, case marginal inferences:
Corollary 4. Consider tree-shaped network N target Xt = xt .
STRONG-INF(N , t, xt , , ) = EPISTEMIC-INF(N , t, xt , , ) .
Proof. say node barren ancestor target evidence node.
well-known removing barren nodes Bayesian network affect
outcome BN-INF (Koller & Friedman, 2009). Since inference strong independence
seen (exponentially many) inferences Bayesian networks, result STRONGINF also unaltered remove barren nodes. Moreover, since N tree, removing barren
nodes leaves chain ancestors t. According Theorem 15 work
Cozman (2000), epistemic extension N projected ancestors t, is,
set marginal distributions xA XA induced joint distributions epistemic
extension, denotes ancestors t, epistemic extension network
get removing nodes A. implies barren nodes discarded also
inferences epistemic irrelevance, result follows.
630

fiProbabilistic Inference Credal Networks: New Complexity Results

0

1

2

3

Figure 8: DAG naive Bayes 3 feature variables.
Zaffalon Fagiuoli (2003) developed linear-time algorithm compute marginal
inferences strong independence trees by-product work imprecise
tree-augmented naive Bayes classifiers. result shows algorithm
used compute marginal inferences trees epistemic irrelevance; conversely,
de Cooman et al.s (2010) algorithm epistemic trees used compute marginal
inferences strong trees.
3.8 Imprecise Markov Chains
simplest DAG structure forming connected graph chain, is,
network variable one parent one child. Credal chains
usually known (imprecise) Markov chains. chain also tree, computing
EPISTEMIC-INF done polynomial time; also case STRONG-INF
chains binary variables, subcase binary polytrees. chain seen
HMM values manifest variables deterministically determined
values hidden variables. such, equivalence types inference
certain types HMMs extends chains:
Corollary 5. Consider credal chain X0 Xn , target Xn = xn single leaf
variable separately specified (imprecise) Markov chain, evidence XO = xO
arbitrary non-leaf variables. outcomes STRONG-INF EPISTEMIC-INF
coincide.
Proof. proof Theorem 3 applies here, omit manifest nodes.
3.9 Imprecise Naive Bayes
widely used DAG structure naive Bayes, node (usually called class)
nodes (called features) children, arc present. Figure 8 depicts
naive Bayes structure class variable X0 features X1 , X2 X3 . DAG
constitutes structure behind Naive Bayes Naive Credal Classifiers (Zaffalon,
2002). tree, computing EPISTEMIC-INF done polynomial time;
also case STRONG-INF target node class variable (Zaffalon, 2002).
show next similar tractability coincidental: inferences yield
result, even target class node. achieve result building
HMM first hidden variable class hidden variables
state space class deterministically determined value,
manifest variables features naive Bayes structure. such, equivalence
inferences types irrelevance extends queries node naive Bayes
structure:
631

fiMaua, de Campos, Benavoli & Antonucci

MODEL

STRONG-INF

EPISTEMIC-INF

*Naive Bayes
*Imprecise HMM (query last node)
Imprecise HMMs
*Credal trees (no evidence)
Credal trees
Credal polytrees binary variables
Credal polytrees ternary variables
Bounded treewidth networks
Credal networks
*Precise-vacuous

P
P
Unknown
P
NP-hard
P
NP-hard
NP-hard
NPPP -hard
NPPP -hard

P
P
P
P
P
Unknown
NP-hard
NP-hard
NPPP -hard
NPPP -hard

Table 2: Parametrized complexity inference credal networks.

Corollary 6. Consider credal network N naive Bayes structure X0 X1 , X0
X2 , , X0 Xn , target Xt = xt node t, evidence XO = xO arbitrary
features (leaf variables). outcomes STRONG-INF EPISTEMIC-INF coincide.
Proof. Let X00 = X0 X10 , , Xn0 precise variables state space
class X00 probability distributions q(x0i |x0i1 ) = 1 x0i = x0i1 zero otherwise,
= 1, . . . , n. Define Q(Xi |Xi0 = x0i ) using credal set Q(Xi |X0 = x0 ) original
network N , whenever x0i = x0 , = 1, . . . , n. Without loss generality, assume
= n (if query X0 , use Xn0 query instead Xn ). procedure creates
imprecise HMM hidden nodes X00 , . . . , Xn0 , manifest nodes X1 , . . . , Xn1 , final
query = n Xt = xt . HMM clearly yields inferential result
naive Bayes network N STRONG-INF. Theorem 3, results STRONG-INF
EPISTEMIC-INF coincide HMM, hence result EPISTEMIC-INF HMM
equal result STRONG-INF N . construction, EPISTEMIC-INF HMM
contains result EPISTEMIC-INF N (that is, latter equal lies inside
former). EPISTEMIC-INF always contains STRONG-INF, particular
naive Bayes structure, must coincide.
3.10 Summary Complexity Results
complexity results obtained section suggest inference credal networks
computationally difficult wide variety model structures dimensionalities.
case, instance, precise-vacuous networks singly connected networks
ternary variables, according negative results shown. importation
exceptions obtained including last-node inference (filtering) imprecise HMMs
Markov chains inference naive Bayes structures. positive results
important structures applications pattern recognition tasks activity
recognition (Antonucci et al., 2011) robust classification (Zaffalon et al., 2003).
previously known new inferential complexity results summarized Table 2.
star indicates models inferences irrelevance concepts coincide.
632

fiProbabilistic Inference Credal Networks: New Complexity Results

Yet another irrelevance concept adopted imprecisely specified models Kuznetsov
independence. define Kuznetsov extension analogously definitions
strong epistemic extensions, define problem inference Kuznetsov independence accordingly. known Kuznetsov extension lies epistemic
strong extensions (Cozman & de Campos, 2014). implies outcomes
inferences Kuznetsov independence coincide strong independence epistemic irrelevance whenever last two coincide. hence get corollaries
results shown inference Kuznetsov independence NPPP -hard
precise-vacuous networks, NP-hard singly connected networks ternary variables,
polynomial-time computable HMMs Markov chains target variable lastnode, polynomial-time computable naive Bayes structures target variable
root node.

4. Conclusion
Credal networks generalize Bayesian networks allow representation uncertain
knowledge form credal sets, closed convex sets probability distributions.
use credal sets arguably facilitates constructions complex models, presents
challenge computation inferences model.
paper studied theoretical complexity inferences credal networks,
concerns topology network, semantics arcs (i.e., whether
epistemic irrelevance strong independence assumed), cardinality variable
domains. nutshell, computing credal networks NP-hard except cases
tree-shaped models epistemic irrelevance, binary polytree-shaped models
strong independence. notable exception computation probability bounds
value last variable imprecise hidden Markov models, case
shown inferences epistemic irrelevance strong independence coincide,
implies latter polynomial-time computable. leave open question
complexity generic inferences imprecise HMMs strong independence.
Another possible avenue future research investigating complexity approximate inference. De Campos Cozman (2005) showed approximating inference
strong independence NP-hard, even consider singly connected networks
bounded treewidth. however case variables binary, case
run 2U algorithm obtain exact value. Maua, de Campos, Zaffalon
(2012b) showed network bounded treewidth whose variables bounded
cardinality exists fully polynomial time approximation scheme performing inference strong independence, is, algorithm given rational > 0 finds
solutions within factor 1 + true value time polynomial input size 1/. Apart tractability credal trees, nothing known
complexity approximate inference epistemic irrelevance, unless case
precise-vacuous networks, showed provide inferences
strong independence epistemic irrelevance, results approximate inference
former extend latter.

633

fiMaua, de Campos, Benavoli & Antonucci

Acknowledgments
first author received financial support PNPD/CAPES Sao Paulo Research
Foundation (FAPESP) grant no. 2013/23197-4. second third authors received
financial support Swiss National Science Foundation grants no. 200021-146606/1
no. 200020-137680/1, respectively. shorter version paper appeared (Maua,
de Campos, Benavoli, & Antonucci, 2013).

References
Antonucci, A., Bruhlmann, R., Piatti, A., & Zaffalon, M. (2009). Credal networks
military identification problems. International Journal Approximate Reasoning,
50, 666679.
Antonucci, A., de Campos, C., & Zaffalon, M. (2014). Probabilistic graphical models.
Augustin, T., Coolen, F., de Cooman, G., & Troffaes, M. (Eds.), Introduction
Imprecise Probabilities, pp. 207229. John Wiley & Sons.
Antonucci, A., de Rosa, R., & Giusti, A. (2011). Action recognition imprecise hidden Markov models. Proceedings 2011 International Conference Image
Processing, Computer Vision Pattern Recognition (IPCV), pp. 474478.
Antonucci, A., Huber, D., Zaffalon, M., Luginbuhl, P., Chapman, I., & Ladouceur, R. (2013).
CREDO: military decision-support system based credal networks. Proceedings
16th Conference Information Fusion (FUSION 2013).
Antonucci, A., Piatti, A., & Zaffalon, M. (2007). Credal networks operational risk
measurement management. International Conference Knowledge-Based
Intelligent Information & Engineering Systems (KES), Vol. LNCS 4693, pp. 604611.
Antonucci, A., & Zaffalon, M. (2008). Decision-theoretic specification credal networks:
unified language uncertain modeling sets Bayesian networks. International
Journal Approximate Reasoning, 49 (2), 345361.
Boyd, S. P., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.
Cano, A., Cano, J. E., & Moral, S. (1994). Convex sets probabilities propagation simulated annealing. Proceedings Fith International Conference Information
Processing Management Uncertainty Knowledge Based Systems (IPMU),
pp. 48.
Corani, G., Giusti, A., Migliore, D., & Schmidhuber, J. (2010). Robust texture recognition
using credal classifiers. Proceedings British Machine Vision Conference
(BMVA), pp. 78.178.10.
Cowell, R., Dawid, P., Lauritzen, S., & Spiegelhalter, D. (2007). Probabilistic Networks
Expert Systems: Exact Computational Methods Bayesian Networks. Statistics
Engineering Information Science Series. Springer.
Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120 (2), 199233.
Cozman, F. G. (2005). Graphical models imprecise probabilities. International Journal
Approximate Reasoning, 39 (23), 167184.
634

fiProbabilistic Inference Credal Networks: New Complexity Results

Cozman, F. G., de Campos, C. P., Ide, J. S., & da Rocha, J. C. F. (2004). Propositional
relational Bayesian networks associated imprecise qualitative probabilistic assessments. Proceedings 20th Conference Uncertainty Artificial
Intelligence (UAI), pp. 104111.
Cozman, F., & de Campos, C. (2014). Kuznetsov independence interval-valued expectations sets probability distributions: Properties algorithms. International
Journal Approximate Reasoning, 55 (2), 666682.
de Bock, J., & de Cooman, G. (2013). Allowing probability zero credal networks
epistemic irrelevance. Proceedings 8th International Symposium
Imprecise Probabilty: Theories Applications (ISIPTA).
de Campos, C., & Ji, Q. (2011). Bayesian networks imprecise Dirichlet model applied
recognition problems. Liu, W. (Ed.), Symbolic Quantitative Approaches
Reasoning Uncertainty, Vol. 6717 Lecture Notes Computer Science, pp.
158169. Springer, Berlin / Heidelberg.
de Campos, C. P., & Cozman, F. G. (2005). inferential complexity Bayesian
credal networks. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), pp. 13131318.
de Campos, C. P., & Cozman, F. G. (2013). Complexity inferences polytree-shaped
semi-qualitative probabilistic networks. Proceedings 27th AAAI Conference
Advances Artificial Intelligence, pp. 217223.
de Campos, C. P., & Ji, Q. (2008). Strategy selection influence diagrams using imprecise probabilities. Proceedings 24th Conference Uncertainty Artificial
Intelligence (UAI), pp. 121128.
de Campos, C. P., Zhang, L., Tong, Y., & Ji, Q. (2009). Semi-qualitative probabilistic
networks computer vision problems. Journal Statistical Theory Practice,
3 (1), 197210.
de Campos, L., Huete, J., & Moral, S. (1994). Probability intervals: tool uncertain
reasoning. International Journal Uncertainty, Fuzziness Knowledge-Based Systems, 2, 167196.
de Cooman, G., Hermans, F., Antonucci, A., & Zaffalon, M. (2010). Epistemic irrelevance
credal nets: case imprecise Markov trees. International Journal Approximate
Reasoning, 51 (9), 10291052.
de Cooman, G., & Miranda, E. (2012). Irrelevant independent natural extension
sets desirable gambles. Journal Artificial Intelligence Research, 45, 601640.
de Cooman, G., & Troffaes, M. C. M. (2004). Coherent lower previsions systems modelling: Products aggregation rules. Reliability Engineering & System Safety, 85 (1
3), 113134.
Fagiuoli, E., & Zaffalon, M. (1998). 2U: exact interval propagation algorithm polytrees binary variables. Artificial Intelligence, 106 (1), 77107.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W.H. Freeman.
635

fiMaua, de Campos, Benavoli & Antonucci

Halpern, J. (2001). Conditional plausibility measures Bayesian networks. Journal
Artificial Intelligence Research, 14, 359389.
Kalai, G., & Ziegler, G. N. M. (2000). Polytopes: Combinatorics Computation. DMV
Seminar. Birkhauser Verlag.
Kendall, D. G. (1974). Foundations theory random sets. Harding, E., & Kendall,
D. G. (Eds.), Stochastic Geometry, pp. 322376. John Wiley & Sons.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models. MIT press.
Kwisthout, J., & van der Gaag, L. C. (2008). computational complexity sensitivity
analysis parameter tuning. Proceedings 24th Conference Uncertainty
Artificial Intelligence (UAI), pp. 349356.
Kwisthout, J. H. P., Bodlaender, H. L., & van der Gaag, L. C. (2010). necessity
bounded treewidth efficient inference Bayesian networks. Proceedings
19th European Conference Artificial Intelligence (ECAI), pp. 237242.
Levi, I. (1980). Enterprise Knowledge. MIT Press.
Maua, D. D., de Campos, C. P., Benavoli, A., & Antonucci, A. (2013). complexity
strong epistemic credal networks. Proceedings 29th Conference
Uncertainty Artificial Intelligence (UAI), pp. 391400.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2011). Solving limited memory influence
diagrams. CoRR, abs/1109.1754.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2012a). Solving limited memory influence
diagrams. Journal Artificial Intelligence Research, 44, 97140.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2012b). Updating credal networks
approximable polynomial time. International Journal Approximate Reasoning,
53 (8), 11831199.
Maua, D. D., de Campos, C. P., & Zaffalon, M. (2013). complexity solving
polytree-shaped limited memory influence diagrams binary variables. Artificial
Intelligence, 205, 3038.
Miranda, E., & Destercke, S. (2013). Extreme points credal sets generated elementary comparative probabilities. Proceedings 12th European Conference
Symbolic Quantitative Approaches Reasoning Uncertainty (ECSQARU),
Vol. 7958, pp. 424435.
Park, J. D., & Darwiche, A. (2004). Complexity results approximation strategies
MAP explanations. Journal Artificial Intelligence Research, 21, 101133.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann.
Piatti, A., Antonucci, A., & Zaffalon, M. (2010). Building Knowledge-Based Systems
Credal Networks: Tutorial. Nova Science.
Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (12),
273302.
636

fiProbabilistic Inference Credal Networks: New Complexity Results

Salvetti, A., Antonucci, A., & Zaffalon, M. (2008). Spatially distributed identification
debris flow source areas credal networks. Transactions 4th International
Congress Environmental Modelling Software Integrating Sciences Information Technology Environmental Assessment Decision Making (iEMSs), pp.
380387.
Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press.
Shenoy, P. P., & Shafer, G. (1988). Axioms probability belief-function propagation. Proceedings Fourth Annual Conference Uncertainty Artificial
Intelligence (UAI), pp. 169198.
Tessem, B. (1992). Interval probability propagation. International Journal Approximate
Reasoning, 7 (34), 95120.
Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall.
Walley, P. (2000). Towards unified theory imprecise probability. International Journal
Approximate Reasoning, 24 (23), 125148.
Wallner, A. (2007). Extreme points coherent probabilities finite spaces. International
Journal Approximate Reasoning, 44 (3), 339357.
Zadeh, L. A. (1978). Fuzzy sets basis theory possibility. Fuzzy Sets Systems,
1 (1), 328.
Zaffalon, M. (2002). naive credal classifier. Journal Statistical Planning Inference, 105 (1), 521.
Zaffalon, M. (2005). Credible classification environmental problems. Environmental
modelling software, 20 (8), 10031012.
Zaffalon, M., & Fagiuoli, E. (2003). Tree-based credal networks classification. Reliable
Computing, 9 (6), 487509.
Zaffalon, M., Wesnes, K., & Petrini, O. (2003). Reliable diagnoses dementia
naive credal classifier inferred incomplete cognitive data. Artificial Intelligence
Medicine, 29 (12), 6179.

637

fiJournal Artificial Intelligence Research 50 (2014) 885-922

Submitted 4/14; published 8/14

Demand Side Energy Management via Multiagent Coordination
Consumer Cooperatives
Andreas Veit

ANDREAS @ CS . CORNELL . EDU

Department Computer Science
Cornell University
Ithaca, NY 14853 USA

Ying Xu
Ronghuo Zheng

YINGX 1@ ANDREW. CMU . EDU
RONGHUOZ @ ANDREW. CMU . EDU

Tepper School Business
Carnegie Mellon University
5000 Forbes Avenue
Pittsburgh, PA 15213 USA

Nilanjan Chakraborty

NILANJAN . CHAKRABORTY @ STONYBROOK . EDU

Department Mechanical Engineering
Stony Brook University
Stony Brook, NY 11794 USA

Katia Sycara

KATIA @ CS . CMU . EDU

Robotics Institute, School Computer Science
Carnegie Mellon University
5000 Forbes Avenue
Pittsburgh, PA 15213 USA

Abstract

key challenge creating sustainable energy-efficient society make consumer
demand adaptive supply energy, especially renewable supply. article,
propose partially-centralized organization consumers (or agents), namely, consumer cooperative purchases electricity market. cooperative, central coordinator buys
electricity whole group. technical challenge consumers make demand
decisions, based private demand constraints preferences, share
coordinator agents. propose novel multiagent coordination algorithm, shape
energy demand cooperative. coordinate individual consumers incomplete information, coordinator determines virtual price signals sends consumers induce
shift demands required. prove algorithm converges central optimal solution minimizes electric energy cost cooperative. Additionally,
present results time complexity iterative algorithm implications agents
incentive compatibility. Furthermore, perform simulations based real world consumption
data (a) characterize convergence properties algorithm (b) understand effect
differing demand characteristics participants well different price functions cost
reduction. results show convergence time scales linearly agent population
size length optimization horizon. Finally, observe participants flexibility
shifting demands increases, cost reduction increases cost reduction sensitive
variation consumption patterns consumers.
2014 AI Access Foundation. rights reserved.

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

1. Introduction
Two key issues creating sustainable energy-efficient society increase penetration
renewable sources, manage supply demand reduce demand peaks
maintaining supply demand balance. One way, commonly used, achieve
demand supply balance supply requested demand whenever occurs. However,
attempting achieve demand supply balance adjusting supply side leads use
flexible (usually diesel operated) power plants expensive, inefficient, emit large
amount carbon. alternative adjusting supply side only, also adjust demand
consumers (Palensky & Dietrich, 2011) via demand response programs. Demand Response
defined changes electricity consumption end users normal consumption
patterns response changes price electricity time (Albadi & El-Saadany, 2007).
Several different forms demand response programs developed (for overview
see Albadi & El-Saadany, 2007). typical example incentive based program, customers receive payment participation, Direct Load Control programs, utilities
remotely control power consumption consumers appliances switching on/off.
small scale pilot studies, direct load control successful reducing peak energy consumption, however consumers uncomfortable yielding control appliances utility
companies (Rahimi & Ipakchi, 2010; Medina, Muller, & Roytelman, 2010). Another type demand management program price based, energy rates variable follow real cost
electricity. objective indirect method control overall demand incentivizing consumers flatten demand curve shifting energy peak off-peak times.
typical example programs Time Use pricing, price peak times
higher price off-peak times. Recent technological advances smart meters
smart appliances created potential enable direct real time participation individual
consumers energy market thus make real-time price based demand management programs
reality. However, two key problems realizing potential. First, despite presence
small pilot programs, utilities consider individual consumers insufficient size considered
demand response services. Second, consumers participate market directly, rather
utilities, stability system may compromised (e.g., herding) (Ramchurn,
Vytelingum, Rogers, & Jennings, 2012). Considering challenges, Mohsenian-Rad, Wong,
Jatskevich, Schober, Leon-Garcia (2010) argue good demand side management program
focus controlling aggregate demand (which also important economic load dispatching, Wood & Wollenberg, 1996) group consumers instead individual consumers.
paper, problem coordinating group consumers called consumer cooperative
introduced studied.
consumer cooperative, collective, allows partial centralization consumers represented
group coordinator (mediator) agent, purchases electricity utilities market
behalf. consumer configurations potentially increase energy efficiency via aggregation demand reduce peak power demand. coordinator neither market maker
traditional demand response aggregator (Jellings & Chamberlin, 1993), since set energy
prices aims incur profits selling market. Rather, role akin social planners,
sense manages demand associated consumer group (a) electricity cost
group minimized, (b) individual group members autonomously decentralized
manner decide shift demands, maintaining privacy individual demand preferences
constraints. members cooperative typically geographically co-located close
proximity one another, example small neighborhood households and/or enterprises.
practice, close proximity required due limitations distribution infrastructure, geograph886

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

ically separated system operators, markets, electricity suppliers. proposed coordination
algorithm could also benefit already existing structures universities, malls, industrial parks,
commercial estates, large residential complexes. Although organizations may already purchase electricity centralized manner, constituent members (e.g. firms industrial park)
currently coordinated keep constraints private.
Consumer cooperatives offer advantages energy utility companies consumers.
utility companys perspective, consumer groups large enough useful demand response programs predictable demand shifts compared individual consumers. Barbose, Goldman, Neenan (2004) give survey utility experience price based programs
conclude participants large industrial customers. individual consumers, participation energy groups allows retain control appliances. addition,
consumers obtain electricity better prices would have, purchased
electricity individually. price advantage due three reasons: First, groups size allows
group enter flexible purchase contracts, price paid consumers
reflects actual cost production accurately. case current long term fixed
contract structures (Kirschen, 2003). Second, buying collectively, group benefit
volume discounts analogous group insurance programs. Third, negotiated electricity contracts,
price usually consists two components, one reflecting actual energy production cost
premium volatility energy demand and/or supply. Buying group
help reduce premium volatility, provided demands group members
coordinated, making total demand stable.
aim paper design effective schemes coordinating electricity demand
agents purchasing electricity consumer cooperative. technical challenge
endeavor fact central coordinator know constraints individual
consumers, thus cannot compute optimal demand schedule own. Furthermore,
actual cost electricity consumption depends aggregate consumption profile agents.
However, agents may want share demand patterns constraints agents
coordinator. Therefore, present algorithm designed enable central agent coordinate consumers achieve optimal centralized load, individual agents decide
demand shifting autonomously retain private knowledge demand constraints.1
papers contributions follows. First, present iterative coordination algorithm
minimize energy cost consumer cooperative preserves privacy individual
demand constraints costs consumers. Second, prove algorithm converges
centralized optimal solution provide computational complexity results. Third, provide
formal arguments incentive compatibility coordination scheme. Fourth, present
discuss extensive simulation results based real world data. preliminary version work
appeared work Veit, Xu, Zheng, Chakraborty, Sycara (2013).
paper organized follows: Section 2 give overview related work
point differences approach paper. Section 3 formulate cost optimization problem consumer cooperative. Then, Section 4 introduce demand scheduling
algorithms consumer cooperative. particular, Section 4.1 introduce basic iterative algorithm Section 4.2 prove convergence optimal solution. Section 5,
introduce general iterative algorithm Section 5.3 prove convergence general
1. problem surface resemblance problems centralized coordinator determines resource allocations agents private preferences, coordinator tries elicit. problems typically addressed
via Vickrey-Clark-Groves mechanisms. problem differs fundamental ways discussed
Related Work section.

887

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

settings. Section 5.4, provide complexity analysis algorithms convergence Section 5.5 provide formal arguments incentive compatibility consumers. Section 6
evaluate coordination algorithms using simulations based real world consumption data.
Finally, Section 7, summarize main contributions paper offer perspective
future work.

2. Related Work
mentioned introduction, demand response programs vary classical direct load
control price based programs real time prices. paper, introduce algorithm
uses variable price signals coordinate energy consumption consumer cooperative.
Therefore, restrict discussion demand management using variable price signals.
Current literature price-based demand shaping mostly operates assumption
desirable automated autonomous system (e.g. smart meter) receives price
signals uses help consumer schedule demand minimize electricity cost,
satisfying demand preferences constraints. two types price signals
used: dynamic deterministic prices. literature price-based demand response
programs considers case deterministic prices, electricity prices time slots
known consumption. case applies long-term contracts day-ahead markets,
planning horizon sufficiently short (see Vytelingum, Ramchurn, Rogers, & Jennings, 2010;
Ramchurn, Vytelingum, Rogers, & Jennings, 2011). known electricity prices, consumers
compute consumption schedule ahead time, e.g., daily consumption plan, annual
production plan. paper falls category demand scheduling deterministic prices.
approaches demand scheduling proposed literature differ important characteristics. First, differ level problem studied secondly differ
objective demand scheduling. different levels problem studied include level single consumer, market maker, grid operator. different
objectives include minimizing cost single consumer, minimizing total cost power
generation, reducing peak-to-average ratio demand, optimizing grid stability.
papers studying demand scheduling problem level grid operators,
major concern grid stability. particular, objectives include minimization power
flow fluctuations (Tanaka et al., 2011), minimization power losses voltage deviations (Clement-Nyns, Haesen, & Driesen, 2010).
work demand scheduling done level consumers. important characteristic regime electricity prices often exogenously fixed influenced
demand scheduling; i.e., consumer price taker. Almost papers regime focus
(micro) demand scheduling one multiple appliances single residential household
commercial building, typical objective minimize incurred electricity cost. example, Chu Jong (2008) study air-conditioning load control; Pedrasa, Spooner, MacGill (2010)
optimize operation schedule various distributed energy resources including space heater
pool pump, etc. papers studying problem different perspectives. example, Philpott Pettersen (2006) Samadi, Mohsenian-Rad, Wong, Schober (2013) address
challenge uncertainty loads consumers energy consumption. stream
research close work, since well study demand management level
consumers. However, instead studying single consumer, consider group consumers
consumer cooperative, buys electricity utility company known price scheme.
work differs literature following aspects: size shift, system stability,
888

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

indirect control, and, crucially, information privacy. First, literature
considers control single consumer, practice, may difficult utility companies
grid operators deal individual consumers demand response programs. demand shift individual consumer might small magnitude compared aggregated
necessary shift. Thus, unclear whether scheme induce shift sufficient size.
contrast, utilitys perspective, consumer cooperative studied work large enough
useful demand response programs. Second, literature assumes
consumers participate markets directly. However, concerns voiced that,
without control utility companies, stability system may compromised
uncontrolled distributed interactions (Kirschen, 2003). contrast, demands consumers
consumer cooperative coordinated central coordinator minimize electricity procurement cost cooperative. Buying group helps reduce demand volatility,
coordinated demand management achieve higher stability demand reduce demand
peaks. Third, common assumption literature demand manager direct
control appliances household perfect knowledge loads operation
constraints. However, cooperative, coordinator lacks control demand scheduling
individual consumers. Moreover, demand constraints preferences private knowledge
individual consumer known either coordinator consumers.
Another stream research related work demand scheduling level market maker. contrast previous approaches, regime, coordinator (i.e., market
maker) set electricity prices consumers, often use price lever influence
demand number consumers. studies stream categorized two groups:
centralized decentralized. Dietrich, Latorre, Olmos, Ramos (2012) compare demand response programs electric system high wind penetration two different settings (i.e.,
centralized vs. decentralized) show centralized approach often reaches higher overall
cost savings, disadvantage central knowledge consumers constraints preferences necessary. partially decentralized approach avoids limitation keeps consumers
constraints preferences private also achieving proven optimality solution.
coordinator uses prices incentivize consumers shift demand, coordinator
needs pay close attention possibility herding phenomenon, whereby agents move
demand towards low price times simultaneously thus cause spike demand bring
instability system. address issue, addition price signal, papers adopt
auxiliary methods make agents gradually change loads. Voice, Vytelingum, Ramchurn,
Rogers, Jennings (2011) charge agents additional fee based much change
demand profile one period next. Ramchurn et al. (2011) introduce adaptive mechanism controlling rate frequency agents allowed adapt loads
readjust demand profile. Vytelingum et al. (2010) introduce compensation signal sent
agents, providing estimate much aim change behavior.
approaches may perform well, but, unlike work, provide formal guarantees
proposed algorithms converge optimal solution. Moreover, approaches require
coordinator market maker charge consumers arbitrarily, e.g., imposing additional fees, feature may implementable acceptable practice. contrast,
coordinator akin social planner must ensure total charge energy demand
agents equal actual amount paid energy supplier.
papers address decentralized demand-side management problem game theoretic perspective. mainly focus deriving charging mechanism make consumers
reach stable demand equilibrium, achieves central objective. papers often share
889

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

underlying assumption individual consumers unit electricity cost increases consumers aggregate consumption. assumption holds setting energy cost
period increases difference demand supply (Wu, Mohsenian-Rad, & Huang,
2012) Peak-To-Average ratio (Mohsenian-Rad et al., 2010; Nguyen, Song, & Han,
2012), unit market price per period increases aggregate demand (Vytelingum, Voice,
Ramchurn, Rogers, & Jennings, 2011; Atzeni, Ordonez, Scutari, Palomar, & Fonollosa, 2013).
work Mohsenian-Rad et al. (2010), Nash equilibrium demand achieves optimality via
designed billing strategy individual cost proportional total energy cost. However, billing strategy, consumer must estimate consumers demand
making decision. Therefore, implement proposed algorithms, consumers
needs coordinate iterative manner exchange demand profiles
iteration, may cause invasions consumers privacy. works Wu et al.
(2012), Nguyen et al. (2012), Vytelingum et al. (2011) Atzeni et al. (2013), individual consumers dont need interact other, communicate central coordinator.
papers, coordinator maintains equilibrium designing unit price, based
aggregate demand. algorithm often implemented distributed iterative scheme:
iteration agents report loads coordinator coordinator updates price
accordingly. Although papers ensure minimum information exchange, none
theoretically proven algorithms would converge centralized optimal solution.
contrast, paper safeguards privacy consumers, also proves algorithm
converges centralized optimal solution.
problem surface resemblance problems, central coordinator determines resource allocations agents private preferences, coordinator tries elicit.
problems typically addressed via Vickrey-Clark-Groves mechanisms. reason considering VCG-type mechanisms problem one key requirements application coordinator pay supplier groups electricity demand prices
given supplier. Thus, revenue, namely sum payments individual agents make
equal actual amount paid supplier. words, jargon mechanism design, budget balance key requirement problem. well-documented
literature VCG-type mechanisms guarantee budget balance (Green & Laffont, 1977;
Hurwicz, 1975)2 impossible design mechanism achieves three properties,
namely, efficiency, budget balance strategy-proofness. problem, addition budget
balance, allocation efficiency also desired social goal. algorithm achieves budget balance (Lemma 2) allocation efficiency (Theorem 3). Although algorithm cannot guarantee
strategy-proofness, due impossibility results, prove manipulation strategy exists
dominates truth reporting (Theorem 5).

3. Problem Formulation
model, consumer group consists N members planning period divided
discrete time slots. number discrete time slots depends market price structure,
differ depending utility companies. example, = 2 time-of-use pricing
different prices day night, whereas = 24 hourly time use pricing. Let
R N matrix row matrix, ri electricity demand agent i,
2. fact, shown Ausubel Milgrom (2006), context broadcast spectrum allocation,
revenue obtained VCG-type mechanisms even zero! case, would mean agents would
pay money coordinator, making impossible pay supplier.

890

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

20

Twolevel Threshold Rate

13
12

high load

11

9

low load

7
6
5
4
0

high load
(Price: 10.34 Cents/kWh)

16
14
12
10

threshold hj

Total Cost

Marginal price pM
(j)
j

10

8

Twolevel Threshold Rate

18

(Dollars)

(Cents/kWh)

14

8

low load
(Price: 6.9 Cents/kWh)

threshold hj

6
4
2

50

100

Aggregated demand j

150

0
0

200

(kWh)

(a) Marginal electricity prices.

50

100

Aggregated demand j

150

200

(kWh)

(b) Total electricity cost.

Figure 1: Sample two-level increasing threshold pricing model used BC Hydro
{1, 2, . . . , N }. call ri demand profile agent i. entry rij electricity demand
P
agent time slot j. total aggregated demand time slot j j = N
i=1 rij . average
market price unit electricity consumer group time slot j defined pj (j ).
assume typical market price function, prices different time slot
price threshold structure. means marginal electricity prices differ among different demand levels. time slot, every unit electricity consumed specified price
threshold charged lower price, additional unit exceeding threshold charged
higher price. Thus, marginal electricity price time slot, denoted pm
j (j ), nondecreasing function total demand. marginal price given demand level payment
increment (decrement) adding (reducing) one unit electricity. Figure 1a shows example
two-level increasing threshold pricing model adopted BC Hydro.3 The(marginal price
pH
j > hj
j
two-level threshold structure formally written follows: pm
(
)
=

j
j
L
p j j hj
L
+
pH
j > pj , hj price threshold time slot j. Let x denote positive value term
x, i.e., x+ = max {0, x}, x denote negative value respectively, i.e., x = min {0, x}.
total energy cost time slot j thus integral marginal prices. Figure 1b shows total
electricity cost aggregated demand based two-level threshold pricing model. total
electricity cost computed as:
+

L
L
pj (j ) j = pH
j (j hj ) + pj (j hj ) + pj hj

(1)

demand profile agent ri must satisfy individual constraints. overall demand
consists two types loads: shiftable loads non-shiftable loads. Mohsenian-Rad et al. (2010),
Mohsenian-Rad Leon-Garcia (2010) Wu et al. (2012) model demand constraints
shiftable non-shiftable loads. example non-shiftable loads typically refrigerator
3. BC Hydro Canadian utility company. pricing model obtained www.bchydro.com.

891

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

shiftable loads include dishwasher, electric vehicles, washer/dryer, etc. appliances modeled
total demand required course planning horizon, upper lower bounds
demand time slot well earliest start latest end times. constraints form
convex set. problem, P
also assume total demand agent whole
planning period fixed, i.e.,
j=1 rij = , total demand agent i. Further,
also consider loads, demand constraints form convex set denote Xi .
constraint set private knowledge agent share it, neither firms
coordinator. application scenarios, agent determines energy demand profile,
consider additional costs associated demand schedule. example, given
factory energy commonly used production. Changing energy demand schedule,
therefore, may mean changing production process and, thereby, production cost. agent i,
cost denoted gi (ri ). assume cost function convex. overall cost function
P
agent
j=1 pj (j ) rij + gi (ri ).
objective minimize sum agents costs, overall energy allocation problem written as:
P
PN PM
pj (j )rij + N
min C (R) :=
i=1 gi (ri )
i=1
j=1
PM
(2)
s.t. ri Xi , j=1 rij = .
energy allocations rij optimization variables R matrix demand
profiles agents. Note problem defined convex
Xi . Although
P setP

objective function non-linear, convex following. First, N
j=1 pj (j ) rij =
i=1
PM
j=1 pj (j ) j convex non-decreasing j indicated Equation 1. Together
PM
PN
j =
j=1 pj (j ) j convex rij , i, j, (Boyd & Vandeni=1 rij , conclude
berghe, 2004). Since gi (ri ) also convex, total cost function C (R) summation convex
functions also convex. Thus, Problem 2 convex minimization problem.

4. Solution Approach
Although Problem 2 convex optimization problem, since constraints preferences
agents private knowledge, optimal demand profiles cannot computed directly
central coordinator. objective function, although sum individual costs agent,
coupled, price electricity time slot j depends aggregated demand
agents j . However, since constraints Problem 2 agent-specific, naturally
separable. Therefore, primal decomposition approach (Bertsekas & Tsitsiklis, 1989) used
solve problem sub-problems correspond agent optimizing energy
cost subject individual constraints. central coordinator compute appropriate
information sent agents guide demand pattern towards time slots lower
prices (this corresponds master problem primal decomposition methods).
Since agents know electricity market prices, individually optimize demand
according prices. Let resulting demand profile called uncoordinated demand
profile. Figure 2a depicts aggregated uncoordinated demand profile setting three
time slots. seen aggregated demand time slot 2 threshold, 2 > h2 ,
aggregated demand time slots 1 3 below, 1 < h1 , 3 < h3 . Thus, shift
demand time slot 2 time slots would reduce total cost group. However,
since agents dont know demand agents, cannot shift demand.
intuitive solution approach, coordinator, coordinate demand would inform
892

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

2
1.5

Threshold
h2

High price
Low price
1

h1

3

1

1
0.5
0

h3
3

3

1

2.5

h1

2

High price

Threshold
3
h3

1.5

2

1
0.5

1

2

Time slot j

3

0

Aggregated demand

3.5

h2

Low price

(c) Coordinated Scenario

4

Aggregated demand

3.5

2

3
2.5

(b) Herding Scenario

4

2
Aggregated demand j

Aggregated demand j

Aggregated demand

Aggregated demand j

(a) Initial Scenario

4
3.5

Threshold

3

2

2.5
2
1.5

High price
h
Low price 1
1

h2
3

h3

1
0.5

1

2

Time slot j

3

0

1

2

Time slot j

3

Figure 2: comparison demand profiles Uncoordinated, Herding Coordinated scenarios.
agents aggregated demand time slot. Knowing market price, agents could
solve individual optimization problems. approach problematic, agents
dont know demand constraints preferences agents group, costs
strongly depend demand agents. example, agents knowing market
price current aggregated demand could shift much demand possible supposedly
cheap time slot. would lead load synchronization, herding phenomenon, agents
shift demand supposedly cheap time slot, resulting new demand peak time slot
thus increasing total cost. effect herding phenomenon shown Figure 2b,
much demand shifted time slot 2 resulting demand threshold
time slots 1 3. Thus, key challenge design information coordinator sends
agents, virtual price signal, enable system minimize overall cost.
virtual price signal final price agents pay, information
would pay, given current aggregated demand. virtual price signal enables
agents foresee possible price increment/reduction caused demand shifting. Therefore, virtual price signal agent time slot j, svij (rij |R), function variable rij ,
denoting new demand agent time slot j. price signal computed based previous aggregate demand profile R, therefore included price function. ease
readability, time made explicit notation used proofs. superscript v indicates virtual price, contrast real market prices pj (j ). design virtual
price signal, coordinator first computes amount demand ideally shifted
time slot. shown Figure (2a), amount, denoted j , j = 1, 2, 3, difference
total aggregated demand price threshold time slot. readability,
refer j delta increment, noting delta could negative values, i.e., could
decrement. avoid herding, delta increment needs divided among agents
threshold price signal needs designed agent, price threshold
lower price threshold. serves penalize total demand time slot going threshold. Thus, agents know maximum amount demand could shift
prices solve individual optimization problem. exact calculation price
signal svij (rij |R) shown Section 4.1.2. Given price signal, virtual cost optimization
problem agent solves
P
v
min Cvi (ri |R) := min
j=1 sij (rij |R) rij + gi (ri )
P
(3)

s.t. ri Xi , j=1 rij = .
Note problem, like overall problem, convex optimization problem thus solvable. However, individual constraints cost functions, agents might
able shift much demand assigned means virtual price signal.
893

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

implies aggregated demand shift less amount could achieved.
Figure 2c shows case, total demand second time slot remains threshold, whole 2 could shifted. order shift remaining demand, another
price signal, dividing remaining amount, would necessary. motivates us design
iterative algorithm coordinator update virtual price signal based consumers
feedback thus gradually adjust individual demands central optimal solution.
4.1 Basic Coordination Algorithm
present basic coordination algorithm details virtual price signal design
energy allocation setting planning horizon two time slots, = 2, cost
shifting demand, g() = 0. Although called basic setting paper, setting practical
relevance, represents commonly used Time Use pricing schemes divide
planning horizon two time slots (Albadi & El-Saadany, 2007). One time slot typically high
load high prices one time slot typically low load low prices electricity.
4.1.1 OVERVIEW LGORITHM
Recall ri denotes demand profile agent R matrix demand profiles
agents. Let r0i updated demand profile agent iteration R0 new
demand profile agents.
Initialization: agent computes initial uncoordinated electricity demand profile ri
solving Problem 3 based market prices sends coordinator.
1. coordinator adds individual demands determine aggregated demand j
time slot j calculates delta increment j demand shifted
time slot. Finally, coordinator divides demand among agents computes
virtual price signals svij (rij |R) agent time slot j.
2. coordinator sends virtual price signals agents.
3. receiving virtual price signal, agent individually calculate new demand
profiles r0i according optimization Problem 3.
4. agents send new demand profiles back coordinator.
5. coordinator compares new demand profiles old profiles. agent changed
demand profile, i.e., R = R0 , coordinator stops algorithm. Otherwise, sets R = R0
goes step (1).
4.1.2 C OORDINATION V IRTUAL P RICE IGNAL
virtual price signal one agent one time slot threshold price function demand
time slot. demand specified threshold charged low price demand
threshold charged higher price. virtual price signal therefore parameterized
H
low marginal price, pL
j , high marginal price, pj , price threshold, hij (R),
specifies demand levels prices apply. virtual price, svij , agent time slot j
computed based parameters follows
( pL h (R)+pH (r h (R))
ij
ij
j ij
j
rij > hij (R)
rij
svij (rij |R) =
(4)
L
pj
rij hij (R)
894

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

Aggregated demand iteration

1.75

Agent 1 demand r

1j

4

3.5

2
2

2.5

h2

2

2j

1

0.5

0

1

0.75
0.5
0.25

1.75

1

1

12

h12

1

r11

h11

11
1

2

Time slot j

h1

1.5

r12

1.5
1.25

0

Agent 2 demand r

Aggregated demand j

3

Agent 1 demand local optimization

r22

1.5
1.25
1

h21

0.75
0.5
0.25

22

h22

21
r21

0

2

Time slot j

Agent 2 demand local optimization

1

2

Time slot j

Figure 3: Division j among agents virtual price signal. yellow demand belongs
agent 1 red demand agent 2. 1 amount demand shifted
time slot 1, 2 indicates amount demand needs shifted time slot 2.

Agent 1 demand local optimization

1.5

r

1.25

h

1

3.5

12

12

0.75
0.5
0.25

3

h

11

r
11

0

1

2

Time slot j

Agent 2 demand local optimization


2j

1.75

Agent 2 demand r

Aggregated demand iteration

4

1.5
1.25
1
0.75
0.5

h21

r21

h22

Aggregated demand j

Agent 1 demand r


1j

1.75

r22

2.5

h2

2

1.5

2

h1
1

1

0.5

0.25
0

1

0

2

Time slot j

1

Time slot j

2

Figure 4: Demand agents local optimization. Agent 1 cannot reduce entire demand
time slot 2 (i.e., r12 > h12 ), demand constraints (left top plot). Thus,
aggregated demand time slot 1 still threshold (i.e., 01 < h1 ). Therefore, central
coordinator sends modified price signal agents algorithm continues
agents stop shifting demands.

895

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

L
v
Although prices pH
j pj derived market prices, sij called virtual price
signal, threshold hij (R) changes, agents change demand profiles.
coordinator chooses hij (R) < rij induce agents reduce demand hij (R) > rij
increase demand one time slot. ij amount coordinator wants agent change
demand time slot j, threshold hij (R) updated based demand profiles submitted
last iteration:
hij (R) = rij + ij
(5)

Thus, agents know that, current market price, change demand
time slot j ij . demand exceeding hij (R), need pay higher price.
demand, j , coordinator wants change time slot j calculated difference
current aggregated demand threshold market price:
j = hj j

(6)

Since coordinator
wants total demand change agents less j ,
P
ensure ij j . allowable shift agent proportional agents share
r
aggregated demand time slot, i.e., ij = Pj rijij . Figure 3 shows total demand

change divided among agents order create individual virtual price signals. left
side shows initial aggregated demand two agents. yellow demand belongs agent 1
red demand agent 2. Since aggregated demand threshold time slot 1 (i.e.,
1 < h1 ) threshold time slot 2 (i.e., 2 > h2 ), coordinator wants agents
shift demand time slot 2 time slot 1. amount demand shifted time
slot 1 1 , 2 amount demand shifted time slot 2. right
side shows individual thresholds agents determined central coordinator using
procedure described above. allocation demand change agents illustrated
dashed arrows. current demand agent 1 time slot 1 r11 threshold time slot
1 h11 (the notations interpreted similarly).
4.1.3 AGENT R ESPONSE V IRTUAL P RICE IGNAL
received virtual price signal, agents independently optimize demand profiles order minimize cost according Problem 3. agents objective function Cvi (ri |R)
P
v
=
j=1 sij (rij |R) rij + gi (ri ) written as:
Cvi

(ri |R) =


X



+

L
L
pH
j (rij hij (R)) + pj (rij hij (R)) + pj hij (R) + gi (ri )

(7)

j=1

Since agents pay high price pH
j demand exceeding individual threshold,
agent shift much demand, based false impression possible cost reduction. Figure 4 shows agents demand profiles individual optimization. left side shows
individual problems agents, optimized demand profile. comparison
right side Figure 3, seen agent 2 shifted whole allocated amount, agent 1
shifted part (e.g., due constraints). right side Figure 4 shows central
problem agents individual optimization. seen still demand left
shifted time slot 2 time slot 1. remaining demand would divided among
agents subsequent iteration.
896

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

4.1.4 PAYMENT RULE
algorithm converged, agents pay virtual unit price demand
time slot. last iteration virtual unit price equals average unit price aggregate demand whole cooperative, agent changed demand profile, Equation 9.
R final demand profiles whole cooperative ri final demand profile agent i,
payment agent given
paymenti =


X

svij (rij |R) rij

(8)

j=1

4.2 Convergence Basic Algorithm
section prove basic iterative procedure always converges optimal solution
L
basic setting = 2, gi () = 0 pH
j > pk , j, k. Lemma 1, show
algorithm strictly reduces cost every iteration. fact used Theorem 1 show
algorithm always converges. Then, Theorem 2 show that, = 2, gi () = 0
L
pH
j > pk , j, k, converged solution optimal solution. Subsequently, show
algorithm get stuck suboptimal solution general settings > 2 (Lemma 3)
gi () 6= 0 (Lemma 4).
Lemma 1. algorithm strictly reduces total cost every iteration: C (R0 ) < C (R).
Proof. Lets first introduce notation used throughout proof. Let R total
demand profile end iteration round R0 total demand profile end round
+ 1. Similarly, let C(R) total cost end iteration C(R0 ) total cost
end iteration + 1. virtual prices round + 1 computed central coordinator
using R. Let Cvi (ri |R) cost agent computed according virtual price signal
demands beginning round + 1 Cvi (r0i |R) end round + 1.
beginning iteration total cost consumer group based market prices
(given objective function Problem 2) equals sum individual cost agents
P
v
based virtual price signals (given Problem 3), i.e., N
i=1 Ci (ri |R) = C (R):
N X

X

svij

(rij |R) rij +

gi (ri )

i=1

i=1 j=1
N X

X

N
X

"



+
(hj j ) rij
P
=
rij rij +
rij
i=1 j=1



(hj j ) rij
P
+ pL
r

r
+
ij
ij
j
rij

# X
N
(hj j ) rij
L
P
+ pj rij +
+
gi (ri )
rij
i=1
=

pH
j

h
N
X
X
+

L
L
pH
(

h
)
+
p
(

h
)
+
p
h
+
gi (ri )
j
j
j
j
j
j
j
j
j=1

=

(9)

N X

X
i=1 j=1

i=1

pj (j ) rij +

N
X

gi (ri )

i=1

897

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

algorithm stopped, least one agent changed demand profile, i.e.,
r0i 6= ri . Agents change demand profile, reduces cost according Problem 3.
Thus, given virtual price, signal agent cost new demand profile r0i strictly lower
previous demand profile ri :

Cvi r0i |R < Cvi (ri |R)
(10)
agents
submitted new demand profile, new aggregated demand comPN
0
0
puted as: j = i=1 rij . Next, show sum agents individual cost according
virtual price signals upper bound total central cost market prices. Thus, total cost,
based new aggregated demand, lower equal sum agents individual cost,
based new demand. fact important, prevents herding behavior:
solution reduces cost agents individual problems lead worse solution
central problem. proved showing Equations 1 7 every time slot j
difference central cost aggregated demand sum agents individual
cost less equal 0. following sketch proof omitting algebraic steps
ease readability. Consult Appendix complete proof. time slot, j,
N
X

N
X
0
0
0
pj 0j rij

svij rij
|R rij

i=1

i=1

(PN
=


0
rij
hij (R) 0j
0

H
pL
rij hij (R) 0j
j pj
0

L
pH

p
r

h
(R)
0
ij
j
j
ij



+
H
0
pL
rij
hij (R)
0
j pj

i: r 0 h
PN ij ij
0 >h
i: rij
ij

hP
N

i=1
= hPN


i=1

L
pH
j pj



> hj
hj

(11)

0j > hj
0j hj



PN v 0
0 j, also holds sum time slots:
0
0
Since i=1 pj j rij i=1 sij rij |R rij
P
v
0
C (R0 ) N
i=1 Ci (ri |R).
Equations 9, 10 11 conclude that:
PN

N
N
X
X
C R0
Cvi r0i |R <
Cvi (ri |R) = C (R)
i=1

(12)

i=1

Thus, total cost strictly reduced iteration.
Theorem 1. basic iterative algorithm solving Problem 2 always converges.
Proof. definition Problem 2 convex lower bound total cost
obtained sum individual initial demand profile costs market prices. Lemma
1 algorithm reduces total cost iteration. Thus, concluded
algorithm converges.

P
PN v
N
Lemma 2. real market cost, N
i=1 pj i=1 rij rij , equals virtual cost
i=1 sij (rij |R) rij
time slot j, either i, rij hij (R) i, rij hij (R).
Proof. i, rij hij (R), j hj first case Equation 11 follows cost
equal. i, rij hij (R), j hj second case Equation 11 follows cost
equal.
898

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

Theorem 2. solution R basic algorithm optimal, either following cases
A) j, R satisfies j 6= hj restrictions gi ()
B) R satisfies j, s.t. j = hj = 2, gi () = 0 high price time slot
L
greater low price time slot, i.e., pH
j > pk , j, k
Proof. prove contradiction algorithm converged solution R
satisfies Case A, solution R0 lower cost. Suppose exists solution
R0 , i.e., C(R0 ) < C(R). show contradicts convergence conditions
algorithm i, ri solution agents individual problem, ri = arg minxi Xi Cvi (xi |R).
Denote R# () = R+(1 ) R0 , (0, 1), linear combination R R0 . Since central
cost function convex C(R0 ) < C(R), also C(R# ()) < C(R). j, R satisfies
j 6= hj , demand beginning iteration rij j either i, rij > hij (R)
i, rij < hij (R), j > 0 i, ij > 0 similarly j < 0 i, ij < 0.
#
#
follows, (0, 1), s.t. j, either i, rij
() hij (R) i, rij
(1 ) hij (R).


PN
#
v
= C(R# ()). Moreover,
Therefore, Lemma 2,
i=1 Ci ri () |R
P
v
C(R# ()) < C(R) Equation 9 also N
i=1 Ci (ri |R) = C(R). follows,
v
v
i, s.t. Cvi r#
() |R < Ci (ri |R), conflicts ri = arg minxi Xi Ci (xi |R), i.e., ri
solution agents individual Problem.
prove contradiction algorithm converged solution R satisfies
Case B, solution R0 lower cost. Assume exists solution R0
C(R0 ) < C(R). Let 2 time slots {j, k}, 0j < j 0k > k (without loss

generality). Note pm
j (j ) > pk (k ), otherwise new cost would lower.
H
L

j = hj , k = hk pm
j (j ) = pj (as j decreases) pk (k ) = pk (as k increases).
L


market price structure pH
k > pj . follows pj (j ) < pk (k ), leads

L
H
contradiction. j 6= hj , k = hk j < hj pj (j ) = pj pm
k (k ) = pk thus
H
H
H

H


pm
j (j ) < pk (k ). j > hj pj (j ) = pj pk (k ) = pk . pk > pj ,
otherwise shift j k would beneficial least one agent algorithm would

stopped. follows pm
j (j ) < pk (k ), leads contradiction. case
j = hj , k 6= hk works similarly.
follows R optimal solution, solution lower cost exists. Thus, proposed iterative algorithm converges optimal solution. Since problem convex solution also global optimal solution (Boyd & Vandenberghe, 2004).
Lemma 3. basic algorithm could converge suboptimal solution R settings, R
satisfies j, s.t. j = hj , > 2 gi () = 0.
Proof. prove presenting counterexample basic algorithm converge
suboptimal solution settings, R satisfies j, s.t. j = hj , > 2 gi () = 0. Consider
population 2 agents, N = 2, planning horizon 3 time slots, = 3. agents
constraints form converged solution aggregated demand
threshold one time slot, directly threshold another time slot one time slot
threshold.
Let price function three time slots given as:
H
L H
L H
(pL
1 , p1 ) = (3, 6), h1 = 10; (p2 , p2 ) = (2, 5), h2 = 10; (p3 , p3 ) = (1, 4), h3 = 10;

899

fi8
6

p1H=6

p2H=5

p3H=4

p1L=3

p2L=2

p3L=1

(KWh)

10

demand agent 1

demand agent 1

(KWh)

V EIT, X U , Z HENG , C HAKRABORTY, & YCARA

4
2
0

1

2

3

10
8
6
4
2
0

1

(KWh)

10
8
6
4
2
0

1

2

2

3

time slot

demand agent 2

demand agent 2

(KWh)

time slot

3

time slot

10
8
6
4
2
0

1

2

3

time slot

(b) Optimal Solution R0

(a) Converged Solution R(T )

Figure 5: Converged Optimal solution example Lemma 3. top row shows
demand agent 1 bottom row demand agent 2. dashed lines indicate upper
lower bounds demands agents time slot. solid black lines show price
thresholds time slot.
individual constraints agents demand are: (a) upper lower bounds demand
time slot (b) constant total demand time slots. Specifically,
r11 [1, 4], r12 [1, 9], r13 [1, 9], r11 + r12 + r13 = 1 = 17
r21 [1, 9], r22 [1, 9], r23 [8, 9], r21 + r22 + r23 = 2 = 17
Let R(t) denote demand profile agents tth iteration let = 1 initial
iteration = final iteration convergence. beginning agents compute
(1)
(1)
initial demand profiles based market
prices r1 = (1, 7, 9), r2 = (1, 7, 9). cost based

initial demand profiles C R(1) = 88. convergence, profiles two agents
(T )

(T )

r1 = (4, 5, 8), r2 = (4, 5, 8) (see Figure 5a graphical representation). cost based
demand profiles C R(T ) = 78. However, different demand profile agents exists
r01 = (4, 7, 6), r02 = (6, 3, 8) (see Figure 5b graphical representation). profile
feasible leads lower total cost, i.e., C (R0 ) = 76. follows algorithm stopped
suboptimal solution.

Lemma 4. basic algorithm could converge suboptimal solution R settings, R
satisfies j, s.t. j = hj , = 2 gi () 6= 0.
Proof. Appendix B counterexample presented, proving basic algorithm converge
suboptimal solution settings, R satisfies j, s.t. j = hj , = 2 gi () 6= 0.
900

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

5. General Coordination Algorithm
previous sections introduced basic iterative coordination algorithm optimal energy
allocation basic setting planning horizon two time slots, = 2, cost
shifting demand, g() = 0. Moreover, presented counter examples showing that, general
settings > 2 g() 6= 0, algorithm get stuck suboptimal solution.
section, present general coordination algorithm energy allocation general settings
two time slots non-zero individual costs shifting demand.
5.1 Additional Phase
reason convergence suboptimal solution coordinator cannot determine
agents marginal valuation demand, aggregated demand time slot
threshold. agents might different marginal valuations, shift agent
lower valuation agent higher valuation might beneficial. However, opportunity
improvement cannot realized, coordinator know marginal valuations
agents.
introduce additional phase algorithm address problem. basic
algorithm converged, coordinator checks whether aggregated demand threshold
least one time slot. case, algorithm stops solution optimal.
However, demand threshold time slot, coordinator initiates another phase.
basic idea that, besides virtual price signal, coordinator sends additional query
agents, requesting valuations -increase -decrease threshold time
slots, aggregated demand threshold. Then, coordinator uses information
adjust virtual price signals.
+
Let vij
denote value agent -increase threshold time slot j. Let
ij+
R
demand profile, resulting price signal agent
time slot
threshold

j+
v
ij+
ij+
virtual cost,
j increased , i.e., hij (R ) = hij (R) + . Moreover, let Ci ri |R
threshold time slot j increased .
Definition 1. Agent marginal valuation -increase threshold time slot j
difference virtual cost original virtual problem virtual problem
-increased threshold time slot j. valuation -decrease defined analogously.







j

+
ij+
0
v
ij
vij
(R) = Cvi rj+
|R

C
r
|R
;
v
(R)
=
C
r
|R
Ci r0i |R .




ij


(13)

agents receive virtual price signal query marginal valuations,
first compute optimal demand profile r0i , based price signal. Second, compute
+

marginal valuations vij
(R) vij
(R) every time slot, aggregated demand
+
threshold. Let vector vi consist valuations -increments vi decrements
respectively. Finally, agents send ri , vi+ vi back coordinator.
received agents information, coordinator computes virtual price signals
next iteration. aggregated demand thenthreshold,
finds agents lowest

+
cost -increase threshold: l = arg mini vij lowest cost -decrease
n


+
threshold: k = arg mini vij
. combined cost negative vkj
+ vlj
< 0, beneficial shift
901

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

agent l agent k exists. case, coordinator updates thresholds agents l, k
lj = , kj = .
algorithm stops, demand threshold time slot time slots

+
thresholds pair {l, k} exists vkj
+ vlj
< 0. follows, algorithm converges,
every time slot aggregated demand threshold, j = hj , agents, cost
reduction -increase threshold less additional cost -decrease
threshold agents, i.e.,
+

vlj
vkj
, l, k {1, ..., N } j s.t. j = hj .

(14)

Otherwise, coordinator would change price signals algorithm would stop.
5.2 General Algorithm
general algorithm designed iterative algorithm, coordinator updates virtual
price signals based consumers feedback thus gradually adjusts individual demands
central optimal solution. overall algorithm shown Algorithm 1. iteration
consists two steps: First, central coordinator aggregates demand submitted agents
computes virtual price signals agent. virtual price signals computed
subroutine CalculateVirtualPriceSignals (Algorithm 2). Second, individual agents use
virtual price signal solve individual cost optimization problem compute marginal
valuation electricity demand report coordinator. agents response
computed CalculateDemandProfileAndValuation (Algorithm 3).
general algorithm first runs basic algorithm convergence subsequently
performs additional phase, necessary. particular, additional phase performed, basic algorithm converged (Algorithm 1 line 8) least one time slot aggregated demand
threshold (Algorithm 1 line 9). algorithm reaches optimal solution R =
+

R0 either j 6= hj , j additional phase vlj
vkj
, l, k {1, ..., N }, j s.t. j = hj .
5.3 Convergence General Algorithm -optimal Solution
Please note Theorem 1 still holds general algorithm, algorithm still reduces
total cost iteration. Thus, extended algorithm converges. Theorem 3 prove
solution general algorithm lies within -neighborhood optimal solution.
Theorem 3. converged solution R general algorithm lies within neighborhood
optimal solution R , amount agents compute marginal valuations.
Proof. prove contradiction general algorithm converged solution R, solution R0 exists lower cost respect central Problem 2
outside -neighborhood around R. Suppose exists solution R0 lower total energy cost R, i.e., C(R0 ) < C(R). show contradicts convergence
conditions general algorithm i, ri solution agents individual problem,
+

ri = arg minxi Xi Cvi (xi |R), vlj
vkj
, l, k {1, ..., N } j s.t. j = hj .
case left Theorem 2 j, j = hj , implies i, rij = hij (R),

fi
fi
fi
0 > h (R) k K, r 0 < h (R), l, k s.t. r 0 r fi
L, K 6= , s.t. l L, rlj
fi lj
lj
kj
lj fi
kj
fi
fi
fi 0
fi
, firkj
rkj fi . show case conflicts convergence conditions, too.
902

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

Algorithm 1: Overall algorithm.
Data: Scenario electricity contract agent definitions.
Result: Optimal demand schedule R .
1
2
3
4

5
6

7
8
9
10
11
12
13
14
15
16
17
18
19
20
21

Initialization: agents compute initial energy demand profile ri solving Problem 3
based market prices send coordinator.;
addP hase = f alse;
demand schedule R optimal
Coordinator calculates price signals using Algorithm 2:
svij (rij |R) , i, j CalculateVirtualPriceSignals (ri , vi+ , vi , addP hase);
coordinator sends virtual price signals agents;
Agents calculate demand profiles valuations time slots, j, using Algorithm 3:
i: r0i , vi+ , vi CalculateDemandProfileAndValuation (svij (rij |R), addP hase);
agents send new demand profiles valuations back coordinator;
algorithm converged, i.e., R = R0
j 6= hj , j
demand schedule R0 optimal;
else
+

addP hase vlj
vkj
, l, k {1, ..., N }, j s.t. j = hj
demand schedule R0 optimal;
else
start additional phase, i.e., addP hase = true;
end
end
else
R R0 ;
end
end

fi
fi
fi
fi #
() rlj fi =
start case |L| = |K| = 1. (0, 1), s.t. firlj
fi
fi
fi #
fi
firkj () rkj fi = . Moreover, denote R## () s.t.,
##
rit


() =

#
rit
() L K, = j
rit
otherwise

demand profile reflecting changes demand time slot j resulting individ#
#
ual problems agents demand threshold, rlj
= hlj (R## ) rkj
=
##
hkj (R ). Thus, Lemma 2 get sum virtual cost equal central cost.
N
X







#
#
v
v
##
##
Cvi r#
()
|R
+
C
r
()
|R
()
+
C
r
()
|R
()
l
k

l
k

i=1,i6=l,k

=

C(R# ()) < C(R) =

N
X

Cvi (ri |R)

i=1

903

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

Algorithm 2: Calculation virtual price signal coordinator.
1

2
3
4

CalculateVirtualPriceSignals (ri , vi+ , vi , addP hase);
Data: demand profiles valuations agents, ri vi+ , vi , i.
Result: virtual price signals agents, svij (rij |R) , i, j.
P
Compute aggregated demand: j N
i=1 rij ;
Compute demand shifted time slot: j hj j ;
r
Divide demand among agents: ij Pj rijij ;


5
6
7
8
9
10
11

addP hase
n

+

Find time slot j agents l, k s.t. min vlj
vkj
;
+

vlj
+ vkj
< 0
Adapt demand shifted agent l: lj agent k: kj ;
end
end
Compute thresholds based demands shifted: hij rij + ij ;

Algorithm 3: Calculation individual demand profiles marginal valuation energy
agent i.
1 CalculateDemandProfileAndValuation (sv
ij (rij |R), addP hase);
Data: virtual price signal svij (rij |R), j = 1, . . . , .
Result: new demand profile r0i valuations vi+ , vi .
2
3
4
5
6
7
8

Compute new demand profile r0i according virtual price signal:
ri = arg minxi Xi Cvi (xi |R);
addP hase
foreach time slot j threshold, rij = hij



+
ij+ Cv (r0 |R);
Compute valuation increased threshold: vij
Cvi rj+
|R




ij Cv (r0 |R);
Compute valuation decreased threshold: vij
Cvi rj

|R

end
end

implies either
N
X



Cvi r#
() |R <

i=1,i6=l,k



N
X

Cvi (ri |R)

i=1,i6=l,k



v
i, s.t. Cvi r#
() |R < Ci (ri |R)

conflicts convergence condition ri = arg minxi Xi Cvi (xi |R);








#
v
##
##
Cvl r#
()
|R
()
+
C
r
()
|R
()
< Cvl (rl |R) + Cvk (rk |R)
k
l
k


h


##
##
Cvl r#
() Cvl (rl |R) < Cvk r#
() Cvk (rk |R)
l () |R
k () |R

904

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

fi
fi




fi #
fi
## () equal Cv rj+ |Rij+
firkj
() rkj fi = get Cvl r#
()
|R

l
l
l




## () equal Cv rj |Rij . Thus, Equation 13 follows
Cvk r#
k
k () |R
k
+

vlj
(R) < vkj
(R)

+

conflicts convergence condition, l, k {1, 2, , N }, vlj
(R) vkj
(R).
general case |L| , |K| 1, get
N
X




X
X

##
##
()
() +
Cvk r#
Cvl r#
Cvi r#
() |R +
k () |R
l () |R

i=1,iLK
/

=

kK



C(R# ()) < C(R) =

N
X

Cvi (ri |R)

i=1

implies either
N
X
i=1,iLK
/



i, s.t. Cvi

N
X



Cvi r#
()
|R
<


Cvi (ri |R)

i=1,iLK
/



r#




() |R <

Cvi

(ri |R)

conflicts convergence condition ri = arg minxi Xi Cvi (xi |R);

X


X

X
X
#
v
##
##
Cvk (rk |R)
Cvl r#
()
|R
()
+
C
r
()
|R
()
<
Cvl (rl |R) +
k
l
k





X


kK

Cvl





kK

"
#
X

X
X
##
##
r#
()
Cvl (rl |R) <
Cvk r#
()
Cvk (rk |R)
l () |R
k () |R


kK

kK

Since amount demand increased time slot j equal demand decreased, cost
decrease LHS greater increase cost RHS, exists pair agents,
l, k marginal cost decrease l larger marginal cost increase k
+

l L, k K, vlj
(R) < vkj
(R)

+

conflicts convergence condition, l, k {1, 2, , N }, vlj
(R) vkj
(R).

solution R lies within neighborhood optimal solution R , amount
agents compute marginal valuations. beneficial shift size greater
equal exists more, algorithm stops. However, beneficial shift smaller might
still exist.
5.4 Convergence Time Algorithm
section, give upper bound number steps algorithm needs converge.
First, give bound basic algorithm Lemma 5 extended phase Lemma 6.
Second, give bound general algorithm Theorem 4.
905

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

Lemma 5. basic algorithm converges within maximum log N e steps, N
number agents distance converged solution optimal solution basic
algorithm.
Proof. prove showing upper bound number iterations needed one time
slot, say, time slot j, get initial demand level neighborhood optimal
demand level basic algorithm. sufficient, demand last time
slot reached optimal level, demand time slots also reached optimal level.
proof consider time slot initial demand optimal demand.
sufficient, every shift consists demand decrease least one time slot also
increase least one time slot. Thus, time slots optimal demand
level, reached optimal level, remaining time slots also reached optimal levels.
Since variables proof time slot j, omit subscript j increased readability. Let Dt difference optimal aggregated demand aggregated demand
iteration t. Since demand assumed optimal demand, Dt > 0. Without
loss generality, assume initial value Dt 1 (D0 = 1) optimum 0;
agent i, initial demand rij = 1. worst case one agent (e.g., agent 1) increase
demand. case, agent 1 increase demand iteration, increment
equals amount demand shift assigned coordinator.
denote increment agent 1s demand iteration ct agent 1s demand
iteration (c0 = 1). N denoting total number agents, demand shift assigned
r
agent given based definition price signal ij = PNj ij . Then,
i=1 rij

agent 1s increment

ct1 Dt1
.
(15)
N 1 + ct1
Agent 1s demand iteration initial demand plus increments first iterations.
Similarly, difference Dt initial difference minus agent 1s increments.
=

ct = 1 +


X

al , Dt = 1

l=1


X

al = ct ct1 = Dt + Dt1 , ct = 2 Dt .

l=1

substituting Equation 15,
(2 Dt1 ) Dt1
N + 1 Dt1
2
= 2Dt1 Dt1
(N 1) Dt1
=
N + 1 Dt1

Dt + Dt1 =
2
(N + 1) (Dt + Dt1 ) + Dt Dt1 Dt1

Dt
Since n 1, Dt (0, 1), get



(N 1) Dt1
N 1 n
Dt <
Dt <
N
N


l

log

Thus, > 0, = loglogN1 = log N
log(N 1) , s.t., > , Dt < . Moreover,
N

since logarithm strictly increasing concave, log N log (N 1) >
> 0, = log N e, s.t., > , Dt < .
906

1
N.

Thus,

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

Lemma 6. extended phase converges maximum within number
0

l

(C0 C )
v



steps,



C total cost solution basic algorithm, C total cost optimal
solution v minimum value marginal valuations -increase decrease
threshold one time slot.
Proof. prove showing upper bound number iterations needed reduce
total cost solution basic algorithm, i.e., C0 , total cost optimal
solution, i.e., C . iteration extended phase, thresholds adapted two agents,

+
say k, j. Thus, total cost reduced vkj
+ vlj
(Equation 13). Let v minimum value

+
vkj + vlj . Then, long algorithm converge, iteration, total cost
l 0
reduced least v . Thus, algorithm stops within (C vC ) steps.
Theorem 4. time complexity general algorithm lies O(N + (C0 -C )), i.e., algorithm linear number agents pseudopolynomial (C 0 C ).
Proof. Lemma 5 get upper bound number iterations basic algorithm
dN log e. log constant, independent N , time complexity
basic algorithm O(N
l 0 ).
Lemma 6 get upper bound number iterations
(C C )
extended phase
. cost difference (C0 C ) depend N ,
v
specific characteristics agents. minimum valuation v proportional size
threshold increment/decrement . Thus v constant constant choice . Thus,
bound extended phase pseudopolynomial (C0 C ).
5.5 Incentive Compatibility
general, allocation problems, three key properties interest, namely, efficiency,
strategy-proofness, budget-balance. context problem, efficiency implies
overall electricity consumption cost minimized. Strategy-proofness implies telling truth
dominant strategy agents hence report truthfully. Budget-balance implies
total amount paid members cooperative equal actual electricity consumption cost. two well known facts three properties literature: First,
allocation efficient, way implement payments guarantee strategy-proofness
use VCG-type mechanisms, see work Green Laffont (1977), Hurwicz (1975). Second, Green Laffont (1977) Hurwicz (1975) also prove, payments obtained VCG-type
mechanisms cannot achieve budget balance. Thus, impossible design mechanism
achieves three properties, namely, efficiency, budget balance strategy-proofness.
stated discussion related work section, budget balance key requirement problem application point view. Furthermore, allocation efficiency desired social goal. algorithm achieves budget balance (Lemma 2) allocation efficiency
(Theorem 3). Therefore, impossibility results, cannot achieve strategy-proofness, i.e.,
truth telling cannot dominant strategy. However, believe agent may choose truthfully respond, agents cannot anticipate future development algorithm and,
prove below, manipulation strategy exists dominates truth reporting. Therefore, define
notion weak incentive compatibility.
Definition 2. algorithm satisfies weak incentive compatibility weakly incentive compatible,
strategy dominates telling truth algorithm.
907

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

Theorem 5. general algorithm weakly incentive compatible.
Proof. algorithm agents two possible ways deviate truthful reporting: First,
could report demand profile minimize individual cost according
current virtual price signals intent misreporting would benefit final
payment. Second, could report marginal valuations differ true marginal valuations. analysis assume rational agents, i.e., agents always prefer lower cost.
Note payment rule (Equation 8) agent pays electricity demand based
final price signal. iteration, truthful demand report minimizes agents cost given
price signal. Therefore, agent report truthfully final price signal (i.e., final
iteration) incur higher cost. Furthermore, agents know whether given price
signal final price signal not. is, agents limited knowledge
know demand profiles agents constraints preferences. Thus, manipulation
iteration may result higher cost truthful report. Therefore, manipulation strategy
involving misreported demand profiles dominates truthful reporting.
Regarding reporting marginal valuations (Definition 1), obvious deflating
valuation hurts agent. demonstrate extension example Lemma 3,
deviating truth revelation inflating reported marginal valuation also hurt
agent. aggregated demand threshold time slot 2 coordinator asks
agents valuations -increase threshold. Without loss generality assume = 1.
+
L
= pH
Agent 1s true valuation (reduce time slot 3 increase 2) v12
3 p2 = 2 agent 2s
+
L
(reduce time slot 1 increase 2) v22 = pH
1 p2 = 1. Lets assume agent 2 misreports
+
valuation v22 > 2. Then, coordinator increases threshold time slot 2 agent 2
decreases threshold agent 1. follows agent 1 shift demand time slot 2
time slot 3 agent 2 shift demand time slot 1 time slot 2. leads
demand profiles: rdeviate
= (4, 4, 9), rdeviate
= (3, 6, 8). However, profile
1
2
lead increase total cost, also increase individual cost deviating
agent 2. Table 1 shows individual cost.4 Since misreporting valuations may result higher
electricity cost truthful report misreporting agent, manipulation strategy involving
misreported marginal valuations dominates truthful reporting.
cost
truthful reports
agent 2 deviates

agent 1s cost
37.143
40.118

agent 2s cost
38,857
38.882

total cost
76
79

Table 1: Cost different demand profiles individual agents.

6. Simulation
perform simulations based real world consumption data (a) characterize convergence
properties algorithm (b) understand effect different parameters characterize
electricity demand profile cost reduction coordination algorithm.
results show algorithm scales linearly number agents time slots. Further,
observe participants flexibility shifting demands increases, cost reduction
4. Since Agent 2s deviation increases agent 1s well agent 2s cost, one might argue increasing
agents cost could also incentive deviation. However, note cost agent visible others.
Therefore, believe agent may choose report truthfully.

908

fielectricity price (Euro cents/kWh)

ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

dayahead
spot market
price

6

4

2

0

2

4

6

8

10

12

14

16

18

20

22

24

time slot

Figure 6: Day-ahead spot market prices EPEX Spot average Tuesday 2013
increases well cost reduction sensitive whether consumers use
electricity evening day.
6.1 Datasets
CER Electricity Consumption Data: use real electricity consumption data generate consumer demand profiles. data gathered Irish Commission Energy Regulation
(CER) context smart metering study. study, electricity consumption data
485 small medium enterprises 4, 225 private households collected period
1.5 years. observation period divided time intervals 30 minutes. One data
point represents average electricity consumption kilowatts one participant 30
minute interval. particular, used data 46 enterprises. participating enterprises
also answered questionnaires about, among others, number employees typical hours
operation. refer data set CER data set5 .
EEX Electricity Prices Market Data: generate cooperatives electricity prices using real
day-ahead market electricity prices, gathered European Energy Exchange (EEX),
leading energy exchange Europe. particular, use average hourly day-ahead
prices EPEX Spot market 20 Tuesdays January 1st 2013 May 14th 2013.
Figure 6 shows average day-ahead spot market prices observation period. refer
hourly market price data EEX data set6 .
6.2 Simulation Parameters
model work Mohsenian-Rad et al. (2010), weP
define agent predetermined total electricity demand planning horizon, =
r , upper lower
h j=1 iji
bounds electricity demand time slot, i.e., rij rij , rij . Regarding individual cost functions gi , assume gi = 0, data industry specific cost
functions.
5. data set available http://www.ucd.ie/issda/data/commissionforenergyregulation/.
6. data available http://www.eex.com/en/Market%20Data.

909

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

6.2.1 ODELING C OMPOSITION C OOPERATIVES :
Agents variety different demand characteristics. reflect diversity, use
CER data set identify two classes consumers similar characteristics. group
consumers similar characteristics, clustered participants study using k-means
clustering based information questionnaires electricity consumption data.
particular, used consumption profiles Tuesdays, Tuesday average
work day. Here, Class 1 represents consumers consuming electricity day,
whereas Class 2 represents consumers stable consumption day, higher
consumption night. Based classes, cooperatives varying compositions simulated. parameter p fracAgent defines composition cooperative specifying
fraction agents Class 1 (and Class 2 1 p f racAgent).
6.2.2 G ENERATING N OMINAL EMAND AGENTS :
agents nominal demand value around agent vary demand. simulate
scenarios {12, 24, 48} time slots use time intervals 30, 60 120 minutes,
generate interpolating averaging data points two data sets. Then, j = 1
represents first j = last time slot day. get different agents, nominal
demand agent time slot outcome xij random variable XCj . Let Cj

mean average demands participants class C time slot j let Cj
corrected sample standard deviationof average
demands. Thenominal demand drawn
uniform distribution XCj U Cj Cj , Cj + Cj . distributions XCj
two Classes
shown Figure 7. total demand agent whole day, computed
P
x
=
j=1 ij .
6.2.3 ODELING F LEXIBILITY C ONSUMERS :
Agents different flexibilities changing demand profiles. Here, ability expressed agents upper lower bound constraints electricity demand
time slot. parameter p flexShift defines flexibility agents specifying percentage, agents vary demands nominal demand. Thus,
larger p f lexShif t, apart upper lower bounds. parameter
agents fixed one scenario. Based flexibility nominal demand, upper
lower bounds computed
rij = xij (1 p f lexShif t)
rij = xij (1 + p f lexShif t)

(16)

6.2.4 ODELING E LECTRICITY P RICE :
cooperatives electricity price function time slot defined marginal price
H
low load, pL
j , high load, pj , price threshold, hj , specifying demand
levels marginal prices apply. use prices EEX data set exemplar prices
H
generate pL
j pj . Let mpj average spot market price EPEX Spot time slot j.
910

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

14

14
exemplary
nominal
demand

10

12

electricity demand (kW)

electricity demand (kW)

12

distribution
nominal
demand

8

6

4

10

2

0

8

6

4

2

0

2

4

6

8

10

12

14

16

18

20

22

0

24

0

2

4

6

time slot

8

10

12

14

16

18

20

22

24

time slot

(a) Class 1 - day consumer

(b) Class 2 - night consumer

Figure 7: Distributions nominal demand two different consumer classes.
compute marginal electricity prices
pL
j = mpj
pH
j = mpj +

max

x{1,...,M }

{mpx }

min

x{1,...,M }

(17)

{mpx }

keep marginal prices fixed across simulations. However, price thresholds may
vary across different simulation scenarios. example, price threshold could
aggregated nominal demand demand increased could
demand reduced. parameter p distThresh defines distance
aggregated nominal demand price thresholds specifying percentage thresholds
aggregated nominal demand. negative value p distT hresh,
thresholds lie positive value lie aggregated nominal demand.
scenario one fixed value time slots. Figure 8a illustrates scenarios
different values p distT hresh. addition, price thresholds could either different
time slot (e.g., following profile aggregated nominal demand) could
time slot (flat thresholds). Here, compute flat thresholds defining moving
average aggregated nominal demand. parameter p flatThresh defines flatness
threshold specifying width interval thresholds flattened
moving average. p f latT hresh = 0 thresholds follow exactly aggregated nominal
demand, whereas p f latT hresh = thresholds every time slot. Figure 8b
illustrates scenarios different values p f latT hresh. thresholds computed
1
hj =
1 + 2p f latT hresh

j+p f latT
X hresh
jp f latT hresh

!
(1 + p distT hresh)

X

xij

(18)



6.2.5 IMULATION CENARIOS :
create different scenarios, vary input parameters follows: p f racAgent {0, 0.25, 0.5,
0.75, 1}, p f lexShif {0.1, 0.2, 0.3}, p f latT hresh {0, 12, 24}, p distT hresh {0.2,
911

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

500

500
values
p_distThresh
0.2

400

0
0.1

300

0.2

200

100

0

0

400

0.1

aggregated demand (kW)

aggregated demand (kW)

values
p_flatThresh

6
24

300

200

100

0

2

4

6

8

10

12

14

16

18

20

22

0

24

time slot

0

2

4

6

8

10

12

14

16

18

20

22

24

time slot

(a) Price thresholds different values p distT hresh. (b) Price thresholds different values p f latT hresh.

Figure 8: Price thresholds different values parameters p distT hresh p f latT hresh.

0.1, 0, 0.1, 0.2}, #agents {20, 40, 60, 80, 100}, {12, 24, 48} {0.5, 1, 2}.
leads 3375 different scenarios. define algorithm converged, cost reduction
one iteration gets less 0.00001%, i.e., C (R) / C (R0 ) < 1.0000001.
6.3 Simulation Results
first present effects different parameters cost reduction algorithm
subsequently discuss convergence time.
Definition 3. cost reduction difference cost uncoordinated profile C0
(chosen agent optimizing cost according market price)
coordinated

profile C percentage cost uncoordinated profile, i.e., CR = C0C0C 100.
Figure 9 shows subset results p f racAgent {0, 0.5, 1}, = 24, #agents = 40
= 1. Figure 9a shows cost reduction cooperatives consisting consumers mainly
consuming electricity night. Figure 9b shows cost reductions cooperatives consist
consumer classes equal proportions. Finally, Figure 9c shows cost reductions cooperatives consisting consumers main demand day. x-axis represents
flexibility shifting demand, y-axis flatness thresholds z-axis height
thresholds. figures scenarios high cost reduction (white) scenarios
less cost reduction (dark red). scenarios, observed mean cost reduction 2.57%,
results varying 0% 7.44%. However, sampled cases represent combinations
input parameters cannot say realistic individual settings are. example,
many scenarios optimization possible put cost reduction 0%. optimization
possible, price threshold provided supplier higher sum agents upper
bound constraints price threshold lower sum lower bound constraints.
taking account scenarios, observe mean 2.96%. Moreover, looking cost
reduction initial nominal demand profile, get mean 3.7%, results 11.1%.
912

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

0.2

0.07

0.07

0.06

0.06

0.2

0.05

0.05

0.03
0.1

0.1
0.04

0
0.03
0.1

0.3

p_flexShift

0

12

0.01
0.1

24
0

p_flatThresh

0.02
0.2

0.01
0.2

0.03

0.02
0.2

0.1

0.04
0

0.1

0.02
0.2

p_distThresh

0.04

p_distThresh

0.1

0

0.06

0.2

0.05

0.1

p_distThresh

0.07

0.2
0.3

0

12

0

p_flatThresh

p_flexShift

0.01
0.1

24

0.2
0.3

p_flexShift

0

12

24
0

p_flatThresh

(a) consumers mainly con-(b) Consumers classes have(c) consumers mainly consume night, p f racAgent = 0.
equal fractions, p f racAgent = 0.5 sume day, p f racAgent = 1.

Figure 9: cost reduction algorithm function four input parameters:
p f racAgent, p f latT hresh, p distT hresh p f lexShif t. Scenarios high cost reduction white scenarios less cost reduction dark red.
6.3.1 ENSITIVITY NALYSIS
purpose sensitivity analysis understand effect different input parameters
cost reduction algorithm. sensitivity analysis perform multiple
linear regression. dependent variable (criterion) choose cost reduction (Definition 3).
independent variables (predictors) choose smallest interpretable model provides good
adjusted R-squared. resulting model shown Table 2. model explains 76.36%
variance adjusted R-squared 0.7571. remaining variance cannot explained
model, agents demand constraints generated randomly.
predictors
p f racAgent
p f latT hresh
p f lexShif
|p distT hresh|
p distT hresh p f lexShif
p f racAgent p f latT hresh

coefficient
0.0019
0.0077
0.0114
-0.0072
0.0018
-0.0016

stand. error
0.0011
0.0017
0.0010
0.0008
0.0002
0.0005

p-value
0.0910
1.66E-05
1.35E-25
2.08E-16
6.67E-17
0.0035

Table 2: Multiple linear regression model; adjusted R2 = 0.7571
Result 1: agents flexibility shifting demands increases, cost reduction increases, i.e.,
p f lexShif % G %.
multiple linear regression model summarized Table 2 shows effect p f lexShif
highly significant p < 0.01. positive value coefficient (0.0114) shows
increase flexibility leads increased cost reduction.
Intuitively, higher flexibility, demand time slots high prices shifted
lower prices. Consequently, higher cost reduction achieved. example,
p f lexShif = 0, demand shifted cost reduced. However, another reason
high cost reduction uncoordinated profile algorithm higher cost. Recall
uncoordinated demand profile agents optimize demand according hourly
913

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

550

550

500

500

450

aggregated
nominal demand

400

aggregated
optimal demand

aggregated demand (kW)

aggregated demand (kW)

price thresholds

350
300
250
200
150
100

450
400
350
300
250
200
150

0

2

4

6

8

10

12

14

16

18

20

22

100

24

time slot

0

2

4

6

8

10

12

14

16

18

20

22

24

time slot

(a) Lower flexibility, p f lexShif = 0.1.

(b) Higher flexibility, p f lexShif = 0.3.

Figure 10: Example scenarios different flexibilities agents shifting demands.

market prices. Consequently, higher agents flexibility, adapt demand
schedules hourly prices. However, since coordinated, agents shift much
demand possible cheap time slots. leads load synchronization, total demand
former cheap slots exceeds thresholds, leading higher costs (herding behavior). Thus,
high flexibility uncoordinated consumers leads highly synchronized demand. high initial
costs allow cost reduction algorithm. Figure 10 illustrates settings low
(p f lexShif = 0.1) high (p f lexShif = 0.3) flexibility. figure shows clearly
initial demand peak higher scenario flexibility. Recall Figure 6 slots
14, 15, 16 17 relatively low priced slots 17 lowest. area
red dashed curve uncoordinated demand profile coordinated demand profile gray
multiplied respective marginal prices shows cost reduction coordination.
increasing freedom Figure 10b seen area two curves increases.
reason height peak stays same, first agents shift much demand
possible time slots aggregated demands thresholds (peaks) time slots
demand levels thresholds. agents reach upper bounds time
slots, shift remaining demand time slots lowest prices threshold.
According hourly prices, cheapest remaining time slot 17. Since freedom allows
demanding remaining electricity time slot, height peak change.
Result 2: absolute distance demand thresholds aggregated load profile
decreases, cost reduction increases, i.e., |p distT hresh| & G %.
multiple linear regression model summarized Table 2 shows effect |p distT hresh|
highly significant p < 0.01. negative coefficient (-0.0072) shows away
thresholds aggregated load profile less cost reduction achieved.
Figure 11 illustrates settings low (p distT hresh = 0.2), normal (p distT hresh = 0)
high (p distT hresh = 0.2) thresholds. cost reduction limited much agents
decrease demand increase thresholds. demand thresholds
represented area initial demand profile (red dashed line) thresholds
(yellow flat line) thresholds, unused demand thresholds area
two lines thresholds. amounts also affected flatness
914

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

550

550

500

500

500

400

aggregated
nominal demand

350

aggregated
optimal demand

aggregated demand (kW)

aggregated demand (kW)

price thresholds

450

450

450

400

400

350

300

350

300

250

300

250

200

250

200

150
100

aggregated demand (kW)

550

200

150
0

2

4

6

8

10

12

14

time slot

16

18

20

22

24

100

150
0

2

4

6

8

10

12

14

time slot

16

18

20

22

24

100

0

2

4

6

8

10

12

14

16

18

20

22

24

time slot

(a) Thresholds average load,(b) Thresholds average load,(c) Thresholds average load,
p distT hresh = 0.2.
p distT hresh = 0.
p distT hresh = 0.2.

Figure 11: Example scenarios different heights price thresholds.

thresholds, i.e., flatter thresholds, larger two areas become. Thus, flatter
thresholds cost reduction increases well. regression model supports this,
parameter p f latT hresh positive coefficient (0.0077) highly significant p < 0.01.
However, cost reduction scenario high thresholds Figure 11c greater
case normal thresholds Figure 11b. happens, flexibility shifting
demand limiting factor. Since absolute distance upper lower bounds
smaller time slots low demand, demand hits upper bounds time slots
reaches lower bounds time slots high demand. situation, increment
thresholds leads time slots thresholds thus possibilities shift
demand. Consequently, flexibility limiting factor, cost reduction increases,
thresholds slightly increased. supported regression model, interaction
term p distT hresh p f lexShif highly significant p < 0.01.
Result 3: observe similar cost reductions groups mostly consumers one class
groups agents classes similar fractions.
multiple linear regression model Table 2 shows parameter p f racAgent
significant predictor cost reduction p > 0.05. supports observation
see cost reductions coordinated behavior two classes (day consumers
night consumers) well mixed groups. Figure 12 illustrates settings night consumers
(Figure 12a), mixed group (Figure 12b), day consumers (Figure 12c). However,
examples, increasing fraction day consumers, cost reduction decreases larger
extent indicated parameter p f racAgent regression model. effect due
interaction effect composition cooperative flatness thresholds.
multiple linear regression model shows interaction term p f racAgent p f latT hresh
significant predictor p < 0.01. negative value coefficient (-5.219e-04) shows
flatness thresholds increases fraction day consumers also increases,
cost reduction decreases. Figure 12 seen thresholds lying outside
agents demand bounds many time slots, thresholds time slot.
situation thresholds, demand bounds limit potential cost reduction
coordination. Consequently, thresholds get flatter, get reach agents demand
bounds. Since load profiles day consumers significant difference peak
low load, effect stronger groups larger fraction day consumers.
915

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

650

600

600

price thresholds

500

aggregated
nominal demand

aggregated demand (kW)

550

450

550

500

450

450

400

350

400

350

300

350

300

250

300

250

200

250

200

150
100

550

500

aggregated
optimal demand

400

aggregated demand (kW)

650

600

aggregated demand (kW)

650

200

150
0

2

4

6

8

10

12

14

time slot

16

18

20

22

24

100

150
0

2

4

6

8

10

12

14

16

18

20

time slot

22

24

100

0

2

4

6

8

10

12

14

16

18

20

22

24

time slot

(a) consumers mainly con-(b) Consumers classes have(c) consumers mainly consuming
sume night, p f racAgent = 0.
equal fractions, p f racAgent = 0.5. day, p f racAgent = 1.

Figure 12: Example scenarios different compositions consumer cooperative.
6.3.2 C ONVERGENCE P ROPERTIES LGORITHM
Let first iteration submission agents uncoordinated initial demand profiles. Then,
second iteration coordinator sends first virtual price signals agents. Recall
beginning basic algorithm performed basic algorithm converged,
additional phase started, necessary. Also recall defined algorithm converged,
cost reduction one iteration gets less 0.00001%, i.e., C (R) / C (R0 ) < 1.0000001.
simulations, basic algorithm converges average within 9.57 iterations. cases
need additional phase, general algorithm converges average additional 35.10 iterations.
experiment setup using one HP Pavilion dmt4-1000 Intel Core i5 520M
two cores operating 2.4GHz 8 Gigabyte DDR3 physical memory. Using setup, one
iteration basic algorithm took average 25.12 seconds one iteration extended
phase took average 52.13 seconds. Looking agents demand profiles convergence,
observe agent average 67.6% time slots demand bounds tight.
sampled scenarios, least one time slot, demand bound tight,
agents satisfy constant total demand whole planning horizon.
Definition 4. convergence accuracy difference cost converged solution
optimal solution percentage difference cost uncoordinated profile
)C(R )
optimal solution, i.e., C(R
100.
C(R1 )C(R )
Result 4: simulations, basic algorithm achieves optimal solution 44.9%
sampled scenarios.
found 44.9% sampled cases basic algorithm achieves optimal solution.
remaining scenarios basic algorithm comes average 1.06% close optimal solution.
indicates cases basic algorithm provide good results.
Result 5: simulations indicate larger step sizes, , lead faster convergence
cost small reductions accuracy.
parameter defines step size extended phase. Intuitively, larger steps lead faster
convergence, cost reduced accuracy. Table 3 shows convergence accuracy average
number iterations convergence varying {0.5, 1, 2}. number agents time
slots fixed N = 40 = 24. results indicate increases, number
iterations convergence well accuracy decreases. However, reduction accuracy
small algorithm achieves good results . results indicate order
916

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

achieve accurate solutions within iterations, step size adapted run-time.
particular, value reduced time.


Convergence accuracy

0.5
1
2

0.22%
0.33%
0.55%

Number iterations
convergence
36.5
26.1
17.9

Table 3: Convergence accuracy time varying step sizes
Result 6: simulations indicate convergence time scales linearly agent
population size number time slots.
analyze influence convergence time algorithm, vary number agents
20 100 time slots 12 48. Table 4a shows convergence accuracy Table 4b
number iterations convergence. step size fixed = 1. results indicate
number iterations convergence increases linearly number agents time
slots. accuracy change much, increase agent population time slots.
Ptime
P slots
agents PPPP

PP

20
40
60
80
100

12

24

48

0.21%
0.24%
0.23%
0.26%
0.25%

0.19%
0.29%
0.26%
0.26%
0.28%

0.18%
0.20%
0.28%
0.30%
0.38%

(a) Convergence accuracy

Ptime
P slots
agents PPPP
20
40
60
80
100

PP

12

24

48

9.8
12.4
13.5
15.2
16.9

16
20.1
23.7
27.1
28.2

22.4
30.2
35.4
40.3
43.2

(b) Number iterations convergece

Table 4: Convergence accuracy time varying number agents time slots

7. Conclusion Future Work
paper, presented iterative coordination algorithm minimize energy cost
consumer cooperative, given information agents individual demand constraints
preferences remains private. proved algorithm converges optimal demand schedule presented results time complexity iterative algorithm agents incentive
compatibility. Additionally, conducted evaluations algorithm using multiagent simulation based real world consumption data. simulations, characterized convergence
properties algorithm effect differing demand characteristics cooperative
price functions cost reduction algorithm. results show convergence
time scales linearly population size length optimization horizon. Finally, observe participants flexibility shifting demands increases, cost reduction increases
cost reduction sensitive variation consumption patterns consumers.
work extended several directions. Future work investigate settings
agents might able compute guaranteed optimal solution individual problem,
provably good approximation. could apply settings detailed load
917

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

models agents. overall demand come two types loads: shiftable loads
non-shiftable loads. loads divided interruptible non-interruptible
loads. addition, loads subject temporal constraints. lead situation
individual problems agents longer convex, thus agent solve
individual problem optimally. Luo, Chakraborty, Sycara (2013) present distributed iterative
algorithm generalized task assignment problem context multirobot system (MRGAP). Based (approximate) best responses agents, algorithm provable
approximate ratio. would interesting investigate distributed algorithm context
problem.
paper, demand cooperative time slot solely consists aggregated
demand agents. Future work consider problems generation and/ storage (that
centralized, i.e., owned cooperative, distributed, i.e., owned individual agent).
Another avenue future work consider problem formulation cooperative faces
uncertainty electricity prices. example, consider 24-hour planning horizon instead
long term contract electricity bought hourly spot market. Here, scheduling
demand, one knows price next hour prices future hourly time slots
uncertain. spot market electricity price depends many factors controlled
coordinator. Hence, planning purposes, prices assumed externally
specified stochastic process. assumption, goal would design algorithms (1)
determining policies (for generation, storage, price signals sent firms) central
coordinator (2) determine schedules individual firms, expected cost
buying electricity minimized.

Acknowledgements
work partially supported NSF award IIS-1218542.

Appendix A. Proof: Virtual Cost Upper Bound Total Cost
Proof. Here, give full proof showing sum agents individual cost according
virtual price signals upper bound total central cost market prices. prove this,
showing Equations 1 7 every time slot j difference total cost
aggregated demand sum agents individual cost lower equal 0. Since
true every time slot, also true sum time slots.
central cost aggregated demand given Equation 1
N
X

0
pj 0j rij
, j

i=1

+

0
= pH
0j hj + pL
+ pL
j
j j hj
j hj
(

H
0
L
0
pj j hj + pj hj j > hj

=
0
L
0j hj
pL
j j hj + pj hj
(P
PN

N
0
pH
rij
hij + i=1 pL
j
j hij

P
= Pi=1
N
N
L
0
+ i=1 pL
j hij
i=1 pj rij hij
918

0j > hj
0j hj

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

sum agents individual cost given Equation 7
N
X

0
0
sij rij
rij , j

i=1

=

N h
X

0
pH
rij
hij
j

+

0
+ pL
j rij hij



+ pL
j hij



i=1

difference two costs get:
N
X

N
X
0
0
0
pj 0j rij

sij rij
rij , j

i=1

i=1
P

h

+

N
L
0
L
0
H
L
0
H

h

h

p
r

h

p
r
h

p

h
+
p
r
p
ij
ij
ij
j ij
ij
j
ij
j
j ij
ij
j
i=1

= PN h

+

L
0
L
H
0
L
0
L

rij hij pj rij hij pj hij
i=1 pj rij hij + pj hij pj

Since

PN
i=1

0j hj


PN L
pL
h


ij
j
i=1 pj hij equal removed.

P
h



N pH r0 hij pH r0 hij + pL r0 hij
j
ij
j
ij
j
ij
i=1
= PN h

+

L
0
H
0
L
0

p
r

h

p
r

h

p
r
ij
ij
j
ij
j
ij
j
ij hij
i=1

Lets write
P
analog N
i: r0

0j > hj
0j hj



+


PN L 0
PN
H r0 h
H r0 h
p
r

h
p
p


0
ij
ij
ij
ij
ij
ij
i=1 j
i=1 j
i: rij >hij j


PN
PN
PN
H
0
rij hij . Lets also write i=1 i: r0 >hij + i: r0 hij .
hij pj

PN

ij

=

0j > hj

ij

ij

N
N


H 0


P H 0
P

H
0
L
0


i: r0 >h pj rij hij pj rij hij + i: r0 h pj rij hij pj rij hij
ij






i:

ij

N
P
0 >h
rij
ij

ij

i:

0j > hj terms

PN
i:

0 h
rij
pH
ij
j

=

i: r 0 h
PN ij ij
0 >h
i: rij
ij



0
L
0
pL
j rij hij pj rij hij



removed. 0j hj remove
(PN



0 h
rij
ij



0 >h
rij
ij

ij

N
P

L 0


0
pj rij hij pH
rij
hij +
j

0
i: rij

PN

0 >h
rij
ij

H 0


0
pj rij hij pL
j rij hij


L 0
0
pj rij hij pH
rij
hij
j

0j > hj
0j hj

0j > hj


H
0
pL
rij
hij
0j hj
j pj
(P
0

N
H
L
0j > hj
i=1 pj pj rij hij
= PN
+
L
H
0
rij
hij
0j hj
i=1 pj pj
h P




N
H
L
0

rij
hij
0 0j > hj
i=1 pj pj
h

=


P
+
N
L
H
0

rij
hij
0 0j hj
i=1 pj pj
=

i: r 0 h
PN ij ij
0 >h
i: rij
ij

L
pH
j pj



919

0j hj



H r0 h
p
ij equal
ij
j
i:


L
0
hij pj rij hij respectively.


PN





L pL pH out.
Factor pH

p
j
j
j
j
(PN

0j > hj

0
rij
hij



fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

Since inequality true every time slot, also holds sum time slots. follows
sum agents individual cost according virtual price signals upper bound
P
0
total central cost market prices, C (R0 ) N
i=1 Ci (ri ):
N X

X

N X

X
0
0
0
pj 0j rij
+ gi (r0i )
sij rij
rij + gi (r0i )

i=1 j=1

i=1 j=1

Appendix B. Proof Counterexample: Basic Algorithm Converge
Suboptimal Solution Case gi () 6= 0
present counterexample prove basic algorithm converge suboptimal solution
general settings gi () 6= 0. Consider population 2 agents, N = 2, planning
horizon 2 time slots, = 2. agents constraints converged solution,
aggregated demand equal threshold one time slot. Let price function given as:
H
L H
(pL
1 , p1 ) = (3, 8), h1 = 9 ; (p2 , p2 ) = (3, 8), h2 = 11

individual constraints agents demand are:
r11 [1, 3], r12 [4, 6], r11 + r12 = 1 = 7
r21 [4, 6], r22 [4, 6], r21 + r22 = 2 = 10

agents individual cost associated demand schedule given as:

g1 (r1 ) = r1

5
1




, g2 (r2 ) = r2

6
3



(1)

beginning, agents compute initial demand profiles based market prices r1 =

(1)
(1, 6), r2 = (4, 6). cost based demand profiles C R(1) = 109.
(T )

(T )

convergence, final profiles twoagents r1 = (1.5, 5.5), r2 = (4.5, 5.5).
cost based demand profiles C R(T ) = 107.5.
However different demand profile agents exists r01 = (1, 6), r02 = (5, 5).
profile feasible leads lower total cost, i.e., C (R0 ) = 107. follows algorithm
stopped suboptimal solution.

References
Albadi, M., & El-Saadany, E. (2007). Demand response electricity markets: overview.
Power Engineering Society General Meeting, 2007. IEEE, pp. 15. IEEE.
Atzeni, I., Ordonez, L., Scutari, G., Palomar, D., & Fonollosa, J. (2013). Demand-side management
via distributed energy generation storage optimization. IEEE Transactions Smart Grid,
4(2), 866876.
Ausubel, L. M., & Milgrom, P. (2006). lovely lonely vickrey auction. Combinatorial
auctions, 1740.
Barbose, G., Goldman, C., & Neenan, B. (2004). survey utility experience real time
pricing. Tech. rep., Ernest Orlando Lawrence Berkeley National Laboratory, Berkeley, CA,
USA.
920

fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT

Bertsekas, D. P., & Tsitsiklis, J. N. (1989). Parallel distributed computation: numerical methods. Prentice-Hall, Inc., Upper Saddle River, NJ, USA.
Boyd, S., & Vandenberghe, L. (2004). Convex optimization. Cambridge university press.
Chu, C., & Jong, T. (2008). novel direct air-conditioning load control method. IEEE Transactions
Power Systems, 23(3), 13561363.
Clement-Nyns, K., Haesen, E., & Driesen, J. (2010). impact charging plug-in hybrid electric
vehicles residential distribution grid. IEEE Transactions Power Systems, 25(1), 371
380.
Dietrich, K., Latorre, J., Olmos, L., & Ramos, A. (2012). Demand response isolated system
high wind integration. IEEE Transactions Power Systems, 27(1), 2029.
Green, J., & Laffont, J.-J. (1977). Characterization satisfactory mechanisms revelation
preferences public goods. Econometrica: Journal Econometric Society, 427438.
Hurwicz, L. (1975). existence allocation systems whose manipulative nash equilibria
pareto-optimal. 3rd World Congress Econometric Society.
Jellings, C. W., & Chamberlin, J. H. (1993). Demand Side Management: Concepts Methods.
PennWell Books, Tulsa, OK, USA.
Kirschen, D. (2003). Demand-side view electricity markets. IEEE Transactions Power Systems, 18(2), 520527.
Luo, L., Chakraborty, N., & Sycara, K. (2013). Distributed algorithm design multi-robot generalized task assignment. Proceedings IEEE International Conference Intelligent
Robots Systems.
Medina, J., Muller, N., & Roytelman, I. (2010). Demand response distribution grid operations:
Opportunities challenges. IEEE Transactions Smart Grid, 1(2), 193198.
Mohsenian-Rad, A., Wong, V., Jatskevich, J., Schober, R., & Leon-Garcia, A. (2010). Autonomous
demand-side management based game-theoretic energy consumption scheduling
future smart grid. IEEE Transactions Smart Grid, 1(3), 320331.
Mohsenian-Rad, A., & Leon-Garcia, A. (2010). Optimal residential load control price prediction real-time electricity pricing environments. IEEE Transactions Smart Grid, 1(2),
120133.
Nguyen, H. K., Song, J. B., & Han, Z. (2012). Demand side management reduce peak-to-average
ratio using game theory smart grid. IEEE Conference Computer Communications
Workshops (INFOCOM WKSHPS), pp. 9196. IEEE.
Palensky, P., & Dietrich, D. (2011). Demand side management: Demand response, intelligent energy
systems, smart loads. IEEE Transactions Industrial Informatics, 7(3), 381388.
Pedrasa, M., Spooner, T., & MacGill, I. (2010). Coordinated scheduling residential distributed
energy resources optimize smart home energy services. IEEE Transactions Smart Grid,
1(2), 134143.
Philpott, A., & Pettersen, E. (2006). Optimizing demand-side bids day-ahead electricity markets.
IEEE Transactions Power Systems, 21(2), 488498.
Rahimi, F., & Ipakchi, A. (2010). Demand response market resource smart grid
paradigm. IEEE Transactions Smart Grid, 1(1), 8288.
921

fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA

Ramchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. (2012). Putting smarts
smart grid: grand challenge artificial intelligence. Communications ACM, 55(4),
8697.
Ramchurn, S. D., Vytelingum, P., Rogers, A., & Jennings, N. (2011). Agent-based control decentralised demand side management smart grid. 10th International Conference
Autonomous Agents Multiagent Systems-Volume 1, pp. 512.
Samadi, P., Mohsenian-Rad, H., Wong, V., & Schober, R. (2013). Tackling load uncertainty
challenges energy consumption scheduling smart grid. IEEE Transactions Smart
Grid, 4(2), 10071016.
Tanaka, K., Uchida, K., Ogimi, K., Goya, T., Yona, A., Senjy, T., Funabashi, T., & Kim, C. (2011).
Optimal operation controllable loads based smart grid topology considering insolation
forecasted error. IEEE Transactions Smart Grid, 2(3), 438444.
Veit, A., Xu, Y., Zheng, R., Chakraborty, N., & Sycara, K. (2013). Multiagent coordination energy consumption scheduling consumer cooperatives. Proceedings 27th AAAI Conference Artificial Intelligence, pp. 13621368.
Voice, T., Vytelingum, P., Ramchurn, S., Rogers, A., & Jennings, N. (2011). Decentralised control
micro-storage smart grid. Proceedings 25th AAAI Conference Artificial
Intelligence, pp. 14211427.
Vytelingum, P., Ramchurn, S., Rogers, A., & Jennings, N. (2010). Agent-based homeostatic control
green energy smart grid. First International Workshop Agent Technologies
Energy Systems (ATES 2010).
Vytelingum, P., Voice, T., Ramchurn, S., Rogers, A., & Jennings, N. (2011). Theoretical practical foundations large-scale agent-based micro-storage smart grid. Journal Artificial Intelligence Research, 42(1), 765813.
Wood, A., & Wollenberg, B. (1996). Power Generation Operation Control. John Wiley & Sons.
Wu, C., Mohsenian-Rad, H., & Huang, J. (2012). Wind power integration via aggregator-consumer
coordination: game theoretic approach. Innovative Smart Grid Technologies (ISGT),
2012 IEEE PES, pp. 16. IEEE.

922

fiJournal Artificial Intelligence Research 50 (2014) 763-803

Submitted 1/14; published 8/14

Policy Iteration Based Stochastic Factorization
Andre M. S. Barreto

AMSB @ LNCC . BR

Laboratorio Nacional de Computacao Cientfica
Petropolis, Brazil

Joelle Pineau
Doina Precup

JPINEAU @ CS . MCGILL . CA
DPRECUP @ CS . MCGILL . CA

School Computer Science
McGill University
Montreal, Canada

Abstract
transition probability matrix represented product two stochastic matrices,
one swap factors multiplication obtain another transition matrix retains
fundamental characteristics original. Since derived matrix much smaller
precursor, property exploited create compact version Markov decision
process (MDP), hence reduce computational cost dynamic programming. Building
idea, paper presents approximate policy iteration algorithm called policy iteration
based stochastic factorization, PISF short. terms computational complexity, PISF
replaces standard policy iterations cubic dependence size MDP function
grows linearly number states model. proposed algorithm also enjoys
nice theoretical properties: always terminates finite number iterations returns
decision policy whose performance depends quality stochastic factorization.
particular, approximation error factorization sufficiently small, PISF computes
optimal value function MDP. paper also discusses practical ways factoring MDP
illustrates usefulness proposed algorithm application involving large-scale
decision problem real economical interest.

1. Introduction
Decisions rarely come alone real situations: usually, outcome decision effect
next one, turn impacts next, on. Thus, choice seems beneficial
short-sighted perspective may reveal disastrous long run. dealing
succession interrelated choices, one must weigh immediate effects decision
long-term consequences order achieve good overall performance. Formally, tasks involving
trade-off short- long-term benefits called sequential decision-making problems.
work focuses particular decision-making model known Markov decision process
(MDP, Puterman, 1994). MDP simple yet important mathematical model describes
sequential decision task terms transition probabilities rewards. transition probabilities
represent dynamics process, rewards provide evaluative feedback decisions made. Given MDP, one usually interested finding optimal decision policy,
maximizes expected total reward decision maker receive long run. natural
c
2014
AI Access Foundation. rights reserved.

fiBARRETO , P INEAU , & P RECUP

way perform search resort dynamic programming, class methods solving
sequential decision problems developed concomitantly MDP model (Bellman, 1957).
Since publication Bellmans (1957) seminal book, dynamic programming studied 50 years, supported strong well understood theoretical basis.
Besides, long ago transcended limits academia tested real situations (White,
1985, 1988, 1993). Despite success dynamic programming several applications,
serious obstacle hinders widespread use: computational cost dynamic programming
algorithms grows fast number states problem, precludes use many
domains. limitation noted Bellman (1961), also pointed number
states decision process grows exponentially number dimensions state spacea
problem came known dynamic programmings curse dimensionality.
Nowadays consensus that, order solve large-scale sequential decision problems,
one must exploit special structure corresponding model resort form approximation (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998; Powell, 2007). One way incorporating
approximation dynamic programming framework create compact version MDP
retains much possible information contained original model. approach
presented paper based idea. Specifically, builds following insight:
transition probability matrix approximated product two stochastic matrices, one
swap factors multiplication obtain another transition matrix, possibly much smaller
original, related precursor. property, called stochastic-factorization
trick, exploited create compact version MDP, hence reduce computational demands dynamic programming. main contribution paper approximate
policy iteration algorithm named policy iteration based stochastic factorization (PISF).
shown, performance decision policy computed PISF depends quality
stochastic factorization; particular, exact factorization leads optimal policy. Moreover, computational complexity iteration proposed algorithm linear
number states MDP.
stochastic factorization presented detail Section 2.4. Although simple,
presentation depends basic concepts, introduced Sections 2.2 2.3.
Section 3 discusses use stochastic factorization approximate MDP. section also introduces analyzes PISF algorithm, main contribution paper. Section 4 investigates
computational issues surrounding use PISF practice presents possible solutions
efficiently compute factorization MDP. Section 5 proposed solutions put
test large-scale decision problem involving maintenance asset components
deteriorate time. Section 6 outlines relationship stochastic factorization
approaches described literature. paper ends Section 7, brief summary
presented along suggestions future research.

2. Background
section introduces notation adopted briefly reviews concepts used
throughout paper.
764

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

2.1 Notation
Boldface letters used denote matrices vectors. Given matrix A, symbol ai used
represent ith row; ai j denotes jth element vector ai . Inequalities interpreted
element-wise; thus B means ai j bi j j. operators max argmax
applied row-by-row, is, given R pq , max vector b R p bi = max j ai j
i. Finally, symbols bmax bmin used shorthand maxi bi mini bi .
2.2 Markov Decision Processes
sequential decision-making model considered decisions made discrete time steps.
instant decision maker occupies state si must choose action set
A. sets called state action spaces, respectively. paper assumed
finite (though possibly large). execution action state si moves
decision maker new state j , new action must selected, on. transition

si
j certain probability occurrence associated reward r R. goal
decision maker find policy : 7 A, is, mapping states actions,
maximizes expected return associated every state S.1 return defined follows:


R (si ) = rt+1 + rt+2 + 2 rt+3 + ... + 1 rt+T = k=1 k1 rt+k ,

(1)

rt+k R reward received kth transition starting state si time step t.
parameter [0, 1) discount factor, determines relative importance individual
rewards depending far future received. sequential decision process may
last forever (T = ) decision maker reaches terminal state (T < ).
decision-making process described formalized Markov decision process,
MDP short. MDP tuple (S, A, P, R, ) (Puterman, 1994). element P
family transition probability functions, one action A. function Pa : 7 [0, 1]
gives transition probabilities associated action a; Pa (s j |si ) probability transition
|S|
state j action executed state si . Note j=1 Pa (s j |si ) = 1,
si (in paper | | used denote cardinality set absolute value
scalar; distinction clear context). remaining component MDP,

R, fidefined analogously
P: reward received transition si
j given Ra (si , j ),
fi
fiRa (si , j )fi Rmax < . Usually one interested expected reward resulting
|S|

execution action state si , is, ra (si ) = j=1 Ra (si , j )Pa (s j |si ). policy defined
MDP induces Markov process . dynamics given P (si ) (|si ), (si )
action selected state si . Likewise, expected reward collected state si
given r (si ) (si ).
state space action space finite, MDP represented
matrix form. function Pa becomes matrix Pa R|S||S| , paij = Pa (s j |si ). Since
elements row Pa nonnegative sum one, stochastic matrix (see
Definition 1). Stochastic matrices play important role rest paper. matrix

1. generally, decision policies rules associating states actions, range generality randomized
history-dependent stationary deterministic (Puterman, 1994, Section 2.1.5). Since discounted MDPs finite
state action spaces always exists stationary deterministic policy performs optimally, paper
focus class decision policies (Puterman, 1994, Thm. 6.2.7).

765

fiBARRETO , P INEAU , & P RECUP

form, function ra vector ra R|S| , ria = ra (si ). Thus, finite MDP
represented |A| matrices Pa number vectors ra : (S, A, Pa , ra , ). decision
policy defined finite MDP vector A|S| whose element action selected
si . Markov process induced represented matrix P R|S||S| vector
r R|S| . ith row P corresponds row index matrix Pi , is,
pi = pi . entries r given ri = rii .
paper assumed totally ordered set, symbol used refer
action index A. slight abuse notation simplifies presentation
considerably, distinction clear context.
2.3 Dynamic Programming
dynamic programming theory built upon concept value function. value state
si policy , denoted V (si ), expected return decision maker receive si
following . Using (1), one write V (si ) = E {R (si )}. case finite state space,
value function vector v R|S| . vector v makes possible impose partial ordering
decision policies. particular, policy considered least good another policy

v v . goal sequential decision problem find optimal policy
v v . well known always exists least one policy given
MDP (Bertsekas, 1987; Puterman, 1994). one optimal policy,
share value function v .
makes search optimal policy feasible Bellman equation, recursive relation state values lies core dynamic programming algorithms. Bellman
equation decision policy given v = r + P v . possible use equation
compute value function policy . One way simply convert socalled Bellman operator , v = r + P v. known (T )t v v
vector v R|S| (Bertsekas, 1987; Puterman, 1994). direct approach compute v
interpret Bellman equation system linear equations compute value function
v = (I P )1 r , identity matrix dimension |S|.
Given v , possible generate decision policy whose performance least good
original policy . Let : R|S| 7 R|S||A| mapping associated given MDP
v = Q, ath column Q
qa = ra + Pa v.

(2)

clear (T v)i = (v)ia , = . instead = argmax j (v)i j , one
Bellman operator MDPthat is, v = max v. Alternatively, v viewed single

application , = argmax v. driving force dynamic programming fact
derived v cannot perform worse . Therefore, dynamic programming
algorithms variations basic scheme: starting arbitrary v R|S| , compute
policy = argmax v apply update rule v (T )t v > 0. Then, based v ,

compute new decision policy , apply steps, on. shown that, regardless
value t, process eventually converge optimal policy (Bertsekas, 1987;
Puterman, 1994).
scheme described adopted = 1, process reduces successive
applications Bellman operator , resulting method popular value iteration
766

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

algorithm. paper focus extreme spectrum, = . case one
policy iteration method (Howard, 1960). Algorithm 1 shows step-by-step description
computations performed policy iteration (see also Appendix A.1).
Algorithm 1 Policy iteration
Require: MDP M: Pa R|S||S| ra R|S| A, [0, 1)
Ensure:
1: random vector A|S|
2: repeat

3:
4:
i1, 2, ..., |S| pi pii ri rii
v (I P )1 r
6:
argmax v
7: =

5:

Ties broken randomly

2.4 Stochastic-Factorization Trick
section presents stochastic-factorization trick, mathematical concept recently introduced
Barreto Fragoso (2011) serve cornerstone subsequent developments.
trick builds following definitions:
Definition 1. matrix P Rnz called stochastic pi j 0 i, j zj=1 pi j = 1
i. square stochastic matrix called transition matrix.
Definition 2. Given stochastic matrix P Rnz , relation P = DK called stochastic factorization P Rnm K Rmz also stochastic matrices. integer > 0 order
factorization.
relation P = DK fact stochastic imply every row P obtained
convex linear combination rows K. words, n stochastic vectors pi R1z
lie within convex hull defined set stochastic vectors ki R1z . Obviously,
n always possible find hull, is, always possible compute stochastic
factorization P. < n, however, exact factorization might possible. leads
following definition:
Definition 3. stochastic rank stochastic matrix P Rnz , denoted srk(P), smallest
possible order stochastic factorization P = DK.
matrix called nonnegative elements greater equal zero. said,
definitions nonnegative factorization nonnegative rank follow analogously
stochastic counterparts. Cohen Rothblum (1991) shown always possible
derive stochastic factorization nonnegative factorization stochastic matrix (see
Theorem 3.2). Since stochastic factorization also nonnegative factorization, follows
nonnegative stochastic ranks stochastic matrix coincide. easy show P
one nonzero element per row, stochastic rank matrix coincides conventional
rank, is, srk(P) = rk(P). general case, however, thing said
rk(P) srk(P) min(n, z) (Cohen & Rothblum, 1991).
767

fiBARRETO , P INEAU , & P RECUP




0.10 0.90 0.00
P = 0.28 0.63 0.09
0.70 0.00 0.30




1.0 0.0
= 0.7 0.3
0.0 1.0

K=



0.1 0.9 0.0
0.7 0.0 0.3



P =



0.73 0.27
0.70 0.30



Figure 1: Reducing dimension Markov process n = 3 states = 2 artificial states.
original states represented white circles; black circles depict artificial states.
figures appeared article Barreto Fragoso (2011).
stochastic factorization appeared literature, either defined (Cohen
& Rothblum, 1991; Ho & van Dooren, 2007) slightly modified versions (Cutler & Breiman,
1994; Ding et al., 2010). However, paper focus useful property type factorization recently noted (Barreto & Fragoso, 2011).
Let P transition matrix dimension n representing dynamics Markov process.
stochastic factorization P = DK admits interesting interpretation case. Suppose < n,
order factorization. elements row seen transition
probabilities states original Markov process set artificial states. Similarly,
rows K may interpreted probabilities transitions opposite direction.
interpretation mind, interesting ask product DK restitutes dynamics
original process. answer question, suffices see element pi j =
l=1 dil kl j sum
probabilities associated two-step transitions: si artificial state
back j . words, pi j accumulated probability possible paths si
j stopover one artificial states. Following similar reasoning, difficult see
swapping factors stochastic factorization, is, switching DK KD,
one obtains transition probabilities artificial states. makes possible define
new Markov process, composed artificial states, whose dynamics given P = KD.
Figure 1 illustrates idea case Markov process three states reduced
compact model containing two artificial states.
simply swapping factors stochastic factorization, possible derive new matrix P retains information dynamics original Markov process compact
way. stochasticity P follows immediately property K.
perhaps surprising fact matrix shares fundamental characteristics
original matrix P. Specifically, possible show that: (i) recurrent class P
corresponding class P period and, given simple assumptions
factorization, (ii) P irreducible P irreducible (iii) P regular P
regular (see Barreto & Fragoso, 2011, details formal definitions). property called
stochastic-factorization trick:

Given stochastic factorization square matrix, P = DK, swapping factors factorization yields another transition matrix P = KD, potentially much smaller original,
retains basic topology properties P.
768

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

3. Policy Iteration Based Stochastic Factorization
section introduces main contribution paper, approximate policy-iteration algorithm built upon stochastic-factorization trick. section starts description
stochastic-factorization trick used reduce computational cost evaluating Markov
process, generalizes idea MDP.
3.1 Approximating Markov Process
Suppose search optimal policy given MDP one determine value
function decision policy . Instead computing directly, one generate compact
version Markov process induced use value function recover value function
original process. following proposition provides mathematical foundation
implementation strategy above.
Proposition 1. Let (S, A, Pa , ra , ) MDP, 0 < 1. Given policy A|S| , let
P R|S||S| r R|S| transition probability matrix expected reward vector
Markov process induced policy M. Let R|S|m nonnegative matrix, let
K Rm|S| stochastic matrix, let r vector Rm
DK = P Dr = r .

(3)

Then,
(i) P = KD r define Markov process states.
Let v Rm value function computed discount factor . Then,
(ii) v = Dv value function .
Proof. Since K stochastic matrix nonnegative, equality DK = P implies
also stochastic: 1 = j pi j = j l dil kl j = l dil j kl j = l dil . fact K
nonnegative implies P nonnegative; since j pi j = j l kil dl j = l kil j dl j = l kil = 1,
P transition matrix (see Definition 1). proves (i). order prove (ii), recall v ,
value function , written
v = r + P v

(4)

(the existence uniqueness solution (4) guaranteed stochastic property P
fact 0 < 1see, example, Lemma 2.3.3 Golub & Loan, 1996 Proposition 2.6 Bertsekas & Tsitsiklis, 1996). Multiplying sides (4) D, one
Dv = Dr + DP v = r + DKDv = r + P Dv .

(5)

Expression (5) Bellman equation associated value function ; since equation
single fixed point, (ii) must true (Bertsekas, 1987; Puterman, 1994).
computation decision policys value function involves O(|S|3 ) arithmetic operations
(Littman et al., 1995). theory, Proposition 1 makes possible reduce computational complexity procedure O(m3 ) (also see Appendices A.1 A.2). Practically speaking,
769

fiBARRETO , P INEAU , & P RECUP

however, application Proposition 1 raises difficulties. First, one must determine reasonable value m, number artificial states compact model. Obviously, one wants
value small possible, trivial find smallest allows
application proposition. Even stochastic rank P known, might possible
simultaneously satisfy equalities (3) = srk(P ). Moreover, computation
D, K r requires number arithmetic operations easily exceed number operations involved original calculation v .2 reasons, one may resort
approximate factorization Markov process.
approximate version stochastic factorization problem, one interested finding
stochastic matrices K represent P well possible, i.e., minimize measure
dissimilarity DK P . order apply Proposition 1, one must also search
vector r Rm makes Dr similar possible r . D, K, r determined,
one swap factors stochastic factorization define Markov process artificial
states. described Proposition 1, value function resulting Markov process, v ,
used restore value function original model. Obviously, DK P Dr r ,
Dv be, too, approximation v . important issue case quantify
impact errors approximation P r might computation value
function. section provides analysis specific dissimilarity measure. particular,
presents upper bound k v Dv k based k P DK k k r Dr k . Here,
k k denotes maximum norm, induces following norm space matrices:
k k = maxi k ai k1 = maxi j |ai j |.
Proposition 2. Let P R|S||S| r R|S| transition probability matrix expectedreward vector describing Markov process induced decision policy . Let R|S|m
K Rm|S| stochastic matrices, let r vector Rm . Finally, let Markov
process described P = KD r. Then,



1






k P DK k ,
k v Dv k k r Dr k +
(6)

2(1 )
v v value functions , computed [0, 1),
, r

= 1 1 12 k P DK k , = max(rmax
max ) min(rmin , rmin ).

Proof. Let Markov process transition matrix DK reward vector Dr.
Proposition 1 follows value function given v = Dv . Recall Markov
process seen MDP |A| = 1. Then, applying Whitts (1978) Theorem 6.2 (b)
, mappings two models taken identities, one concludes
vi vi + i. Since mappings identity function, one
apply Theorem 6.2 (b) again, exchanging roles two models, obtain vi vi +
i. upper bound (6) results combination two inequalities above.
According Whitt (1978), possible construct examples showing (6) tight bound.
Proposition 2 makes clear approximation v depends characteristics
2. Vavasis (2009) shown determination nonnegative rank stochastic matrix NP-hard problem.
implies polynomial-time algorithm computing K currently known; case, one
could compute one factorization value = |S|, |S| 1, ..., 1, stopping exact factorization
longer possible, thus determining matrixs rank polynomial time.

770

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

quality stochastic factorization. First, right-hand side (6) increases 1
. expected, since magnitude individual rewards rate
accumulate time tend increase states values. important, difference
v Dv directly depends stochastic factorization, DK P Dr r
approximation Dv gets closer real value function v . limit, k r Dr k = 0
k P DK k = 0, one recovers Proposition 1.
interesting point intriguing property Proposition 2. Observe increase
approximation error k P DK k two opposite effects variables involved
derived bound: one hand increases coefficient multiplying , expected,
hand also decreases factor 1/ scaling entire right-hand (6). precisely
makes bound tight, since latter effect tends alleviate first. Needless say,
bound still monotonically increasing function k P DK k , one easily verify
computing appropriate partial derivative.
3.2 Approximating Markov Decision Process
straightforward way use stochastic-factorization trick search decision
policy factor one one Markov processes come search. specific,
let arbitrary decision policy defined finite MDP let P r describe
Markov process induced policy. Given approximations DK P Dr r , one
define new Markov process transition matrix P = KD reward vector r. auxiliary
model potentially many fewer states original Markov process. determining
value function compact model, v , one compute approximation original value
function making v = Dv . Finally, new policy = argmax v derived, restarting
usual dynamic programming loop. Notice DK = P Dr = r every policy
comes search, process eventually converge optimal decision policy.
direct consequence Proposition 1.
Although feasible, strategy presents obvious drawback: new factorization must
computed Markov process encountered search decision policy. Another possibility factor entire MDP once. case, possible approach find approximate
factorizations Markov process , Da Ka Pa Da ra ra , A, solve
reduced MDP whose transition matrices Ka Da whose expected reward vectors ra .
However, MDP directly solved, quality solution found depend
stochastic factorization only, even exact factorization MDP lead suboptimal
decision policies (for example, shown Barreto, Precup, & Pineau, 2011, Prop. 1, particular case single matrix used factor Markov processes, approximation
error also depends level stochasticity D, measured maxi (1 max j di j )). remaining section discusses alternative way factoring MDP performance
final decision policy depends exclusively quality stochastic factorization.
Let (S, A, Pa , ra , ) finite MDP. Let Da R|S|m K Rm|S| stochastic matrices
Da K Pa A, let r Rm vector Da r ra , A. Let
A|S| policy defined let corresponding Markov process. discussed
Section 2.3, ith row P R|S||S| , transition matrix , ith row Pi ,
action selected si (see line 4 Algorithm 1). approximations Da K Pa ,
one see ith row Pi approximated di K (recall di ith row Di ).
771

fiBARRETO , P INEAU , & P RECUP

Thus, order build approximation P , suffices construct matrix R|S|m whose
rows given di = di . determined, transition matrix associated
approximated P K. Analogously, vector r R|S| approximated
r r.
Using strategy above, straightforward extend ideas Proposition 1 factorization entire MDP. Given decision policy , one must first compute matrix described
define reduced Markov process transition matrix P = KD reward vector
r. corresponding value function v used compute approximation value
function , serve reference derivation new decision policy ,
on. Algorithm 2 shows ideas embedded policy iteration, giving rise
policy iteration based stochastic factorization algorithm, simply PISF.

Algorithm 2 Policy iteration based stochastic factorization (PISF)
Require: Da R|S|m A, K Rm|S| , r Rm , [0, 1)
Ensure:
1: random vector A|S|
2: repeat
3:

4:
i1, 2, ..., |S| di dii
5:
P KD
6:
v (I P )1 r
7:
Let Q R|S||A|
8:
a1, 2, ..., |A| q ,a Da v
q ,a ath column Q
9:
argmax Q
Ties broken randomly
10: =

standard policy iteration algorithm, computation decision policys value function
takes O(|S|3 ) arithmetic operations, derivation new policy O(|S|2 |A|) (Littman
et al., 1995). contrast, PISF needs O(|S|m|A|) operations derive new policyas shown
lines 8 9 Algorithm 2and breaks value function computation several steps
whose overall complexity O(|S|m2 ). process computing v follows. First, one
determine matrix , involves O(|S|) operations (line 4 Algorithm 2). Then,
necessary perform O(m2 |S|) operations compute transition matrix P (line 5). Finally,
one must calculate v , O(m3 ) (line 6). one see, computational complexity
one iteration PISF linear number states |S|. Thus, |S|, number
arithmetic operations performed per iteration PISF much smaller number operations
would executed conventional policy iteration algorithm.
Regarding space complexity PISF, storing Da , K r requires O(|S||A|m) bits. Note
though actual implementation matrices Da need stored main memory. Thus, one willing trade space timesince case would computed
loaded demand, actual memory usage algorithm drops O(|S|m) only.
772

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

3.3 Convergence Error Bound
PISF algorithm rests approximations Da K Pa Da r ra . approximations
happen exact, Proposition 1 directly applicable every decision policy generated algorithm, implies converge optimal policy . Nevertheless, order PISF
considered stable method, necessary show errors approximations
cause algorithm behave completely unpredictable way. following proposition
shows PISF well-behaved algorithm, sense always terminates finite number
iterations quality decision policy returned improves kDa KPa k 0
kDa rra k 0 A.
Proposition 3. Let (S, A, Pa , ra , ) MDP [0, 1). Let Da R|S|m K Rm|S|
stochastic matrices, A, let r R|S| . Then, PISF executed Da , K, r, ,
(i) terminate finite number iterations.
Let v value function policy returned PISF let ra = Da r A. Then,
(ii)
k

v v k

2

1



maxa k

ra ra





maxa k P K k ,
k +
2(1 )

(7)

min ra .
v optimal value function = maxa rmax
min

Proof. Let (S, A, Da K, Da r, ), is, MDP whose transition matrices Da K
whose expected reward vectors Da r, A. strategy proof show
executing PISF Da , K, r, equivalent running standard policy iteration M.
Let , v Q policy, value function, matrix computed PISF ith iteration
(lines 3, 6, 8 Algorithm 2, respectively). definition Q , one write
q ,a = Da v = Da (r + P v ) = Da (r + KD v ) = Da r + Da KD v ,

(8)

also matrix constructed PISF ith iteration (line 4 Algorithm 2). Comparing (2) (8), clear Q = v . Proposition 1, follows v value
function Markov process described K r. exactly Markov process
induced (see line 4 Algorithm 1). Therefore, policy computed one iteration
PISF starting , = argmax Q = argmax v , policy would computed
one iteration standard policy iteration applied also starting . implies
PISF converge optimal policy finite number iterations, hence (i) holds
(see, example, Puterman, 1994, Thm. 6.4.2).
order show (ii), suffices resort Whitts (1978) results comparing dynamic programs, generalization MDPs proposed Denardo (1967). Specifically, one applies
corollary Whitts Lemma 3.1 M, mappings two MDPs taken
identities, follows
2
maxi j |hi j |,
(9)
k v v k
1
hi j elements matrix H = v v v optimal value function (since
policy computed PISF optimal M, last term appearing Whitts bound vanishes).
773

fiBARRETO , P INEAU , & P RECUP

Based Corollary (b) Whitts Theorem 6.1, one write:
maxi j |hi j | maxa k ra ra k +


maxa k Pa Da K k .
2(1 )

(10)

Substituting right-hand side (10) (9) one gets desired bound.3
Proposition 3 states PISF converge decision policy finite number iterations. fact, proof proposition shows, solution returned PISF one
optimal policies MDP (S, A, Da K, Da r, ). Thus, one look PISF fast specialized method solve MDPs specific type structurenamely, MDPs allow
exact factorization single K single r. course, PISF converge decision policy even factorization exact; case algorithm becomes approximate policy
iteration method.
error bound provided Proposition 3 tight general. seen noting
|A| = 1 bound (7) may looser counterpart (6). Also, bound
pessimistic practical value many situations. Even so, Proposition 3 conceptual
importance establishes soundness PISF. particular, states performance
policy returned algorithm gets closer optimal error MDP approximation
decreases. fact, difficult show that, errors approximations Da K Pa
Da r ra certain threshold, policy returned PISF performs optimally M.
order that, first note ra = Da r implies rmin ria rmax a, thus one
, max ra ] still get exact factorization.
restrict elements r interval [mina rmin
max
Assuming case, term appearing right-hand side (7) replaced
min ra . means max k Pa Da K k max k ra Da r k
maxa rmax

min



terms (7) vary Da , K r, hence one make bound arbitrarily small
driving approximation errors zero. Let A|S| set non-optimal policies
let = min k v v k . Since v value function specific policy, follows that,
right-hand side (7) smaller , v = v . Therefore, exists scalar
maxa k Pa Da K k < maxa k ra Da r k < policy returned PISF optimal.

4. Computing Stochastic Factorization
shown previous section, PISFs performance depends crucially approximations
Da K Pa Da r ra , A. section discusses compute Da , K, r. starts
generic presentation problem gradually focuses specific formulations
solved much efficiently.
4.1 Optimization Problem
order facilitate exposition, assumed vectors ra matrices Pa
concatenated stacked obtain single matrix R|S||A||S|+1 representing entire MDP,
3. Ravindran Barto (2004) follow similar strategy bound approximation loss resulting approximate
homomorphism.

774

fiP OLICY TERATION BASED

follows:










M=







r11
..
.
1
r|S|
..
.
|A|
r1
..
.
|A|
r|S|



p111
..
.
p1|S|1
..
.
|A|
p11
..
.
|A|
p|S|1

TOCHASTIC FACTORIZATION

p112
..
.
p1|S|2
..
.
|A|
p12
..
.
|A|
p|S|2

p11|S|
..
.
p1|S||S|
..
.
|A|
p1|S|
..
.
|A|
p|S||S|


..
.

..
.

..
.











.







(11)

representation above, objective factorization problem reduces finding matrices
W DW M. formally, approximate factorization MDP
formulated constrained nonlinear optimization problem following way:
Problem 1. Given matrix R|S||A||S|+1 representing MDP, find R|S||A|m W
Rm|S|+1 order minimize dissimilarity measure (M, DW), subjected following constraints:
di j 0 = 1, 2, ...|S||A| j = 1, 2, ..., m,

(12)

wi j 0 = 1, 2, ...m j = 2, 3, ..., |S| + 1,

(13)


= 1 =
j=1 j
|S|+1
wi j = 1
j=2




1, 2, ...|S||A|,

(14)

= 1, 2, ...m.

(15)

Note problem formulation assumes first column reserved
rewards, (11). elements first column W subjected
stochasticity constraints (13) (15). |A| = 1 model Markov process. Also,
problem statement easily modified reflect case represents Markov chain
(that is, rewards Markov processsee Barreto & Fragoso, 2011).
modification major impact discussion follow.
hard see feasible region defined constraints optimization
problem convex set. Thus, continuously differentiable, one resort one several
methods presented Bertsekas (1999) solve constrained nonlinear optimization problem
convex feasible region. Among them, obvious choice probably gradient projection
method, candidate solution iteratively refined update rule keeps within
problems feasible region. Another approach seems promising context block
coordinate descent method (Bertsekas, 1999). case, subset variables updated
time remaining kept fixed. optimization problem hand, two
blocks variables corresponding elements matrices W. Thus, iteration
algorithm one applies following update rules:
argmin (M, DW)



DD

W argmin (M, W),
WW

(16)

R|S||A|m W Rm|S|+1 feasible regions W, respectively. Depending
characteristics dissimilarity measure adopted, repeated application
775

fiBARRETO , P INEAU , & P RECUP

update rules eventually converge stationary point (Grippo & Sciandrone, 2000).
true, example, (M, DW) =k DW kF , k kF Frobenius norm (Cutler &
Breiman, 1994; Lin, 2007b). k kF used, one compute W constrained
least-squares algorithm (Cutler, 1993).
solution two subproblems (16) may require large number arithmetic operations. Therefore, instead searching exact minima, one take small step per iteration
towards solution subproblem, much like conventional iterative descent methods (Lee
& Seung, 2000). case, relatively simple enforce stochasticity constraints projecting partial solutions onto feasible region incorporating penalty term
dissimilarity measure (Lee & Seung, 1997). noted, however, iterative
update rule used place (16), guarantee convergence solution may lost (Lin,
2007a).
ideas extensively exploited study related optimization problem
known nonnegative matrix factorization. name suggests, version problem
constraints (12) (13) normally imposed (Paatero & Tapper, 1994; Lee & Seung, 1999).
many works available discussing theoretical practical aspects nonnegative matrix
factorization (for survey, see Berry et al., 2007). ideas discussed works also
apply problem considered here. particular, since one derive stochastic factorization
nonnegative factorization stochastic matrix, algorithm designed latter
also used compute former (Cohen & Rothblum, 1991).
Instead addressing Problem 1 generic nonnegative factorization, one exploit
particular structure matrices W. discussed Section 2.4, fact stochastic
implies exact factorization DW = possible rows inside
convex hull defined rows W. So, one try solve problem (approximately)
computing convex hull contains rows determining coefficients
recover mi convex combination vertices hullwhich naturally give rise
stochastic D. approach closely related Cutler Breimans (1994) archetypal analysis
Ding et al.s (2010) convex nonnegative factorization. also interesting connection
problem known spectral unmixing field imaging spectroscopy,
determination matrix W usually referred task extracting end-members (Keshava
& Mustard, 2002; Keshava, 2003).
Yet another way approaching Problem 1 impose additional constraints resort
specialized methods. Consider example case one nonzero element
per row. case, factorization seen specific instance well-known dataclustering problem: vectors mi must grouped clusters C j whose centers
vectors wj common choice define centers wj = 1/|C j | {i|mi C j } mi =
1/|C j | {i|di j =1} mi (Hartigan, 1975). goal clustering problem determine assignment vectors mi clusters C j order minimize (M, DW). Since W automatically
defined given assignment, problem reduces computing matrix D. advantage interpreting factorization clustering problem availability large number algorithms
specifically designed solve type optimization (Kaufman & Rousseeuw, 1990; Gan et al.,
2007). Conveniently, depending defined, cluster centers wj naturally satisfy
stochasticity constraints (12), (13), (14), (15). case Frobenius norm
adopted objective function.
776

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

4.2 Reducing Computational Cost Factorization
work presents stochastic factorization general approach reduce number states
MDP. course, main reason one would interested reduction save
computational resources. One potential gain amount memory required represent
model. Nevertheless, paper mainly concerned use stochastic factorization
strategy reduce time complexity dynamic programming algorithms, is, number
arithmetic operations performed search decision policy. case, computational
cost factorization process concern. particular, makes sense resort
stochastic factorization number operations involved factorization process much
smaller number operations saved replacing original model compact one.
discussed, stochastic factorization problem equivalent nonnegative matrix factorization. Nonnegative matrix factorization popular research topic last years,
result efficiency algorithms increasing steadilyin fact, nowadays
possible compute nonnegative factorizations large matrices matter minutes (Esser
et al., 2012; Bittorf et al., 2012). Recently, Thurau et al. (2011, 2012) proposed efficient algorithms approximately compute convex hull contains rows M. show that,
exploiting extra structure Problem 1, one compute approximation DW much
faster algorithms treat problem conventional nonnegative factorization.
also methods spectral unmixing problem specifically designed computationally efficient (Nascimento & Dias, 2004; Chang et al., 2006). Finally, one interprets Problem 1
clustering task, possible approximate large matrices using recently
proposed methods (Boutsidis et al., 2010; Shindler et al., 2011).
principle, methods used compute approximation DW
required PISF. able solve problem time linear number rows
(Shindler et al., 2011; Thurau et al., 2012). Unfortunately, comes Problem 1,
mean factorization depend linearly |S|. problem vectors mi
live R|S|+1 . implies number states MDP defines number
vectors mi (the number rows M), also dimension (the number columns M).
consequence, even linear methods run O(|S|2 ) time.
Depending size MDP computational resources available, quadratic dependency |S| may acceptable. many algorithms available case. example,
Shindler et al.s (2011) clustering method deliver approximation DW O(|S|2 |A|m)
time, corresponds iterations value iteration algorithm (Littman et al., 1995).
also situations transition matrices Pa sparse, meaning execution action state si lead number states z |S|. case factorization problem
solved time linear |S|. remaining section focuses worst case scenario,
is, case sparse quadratic dependency |S| acceptable.
4.2.1 B REAKING



OUBLE EPENDENCY



IZE



MDP

order make stochastic factorization problem tractable large MDPs, one needs circumvent fact |S| defines number rows number columns M.
strategy proposed section rewrite problem terms dissimilarity measure whose
computation depend number states MDP.
777

fiBARRETO , P INEAU , & P RECUP

Let dissimilarity measure defined R|S|+1 R|S|+1 (such distance function,
example). section assume measure previously introduced induced .
examples, let B two arbitrary matrices dimension. one have,
instance,
(A, B) (ai , bi ) =k B kF ,

(ai , bi ) k ai bi kF
(ai , bi ) k ai bi k1

(A, B) maxi (ai , bi ) = k B k , (17)
q
(ai , bi ) k ai bi k2 (A, B) max [(ai bi )x]2 = max k (A B)x k2 , (18)
x,kxk2 =1

x,kxk2 =1

k k2 Euclidean norm. Based expressions above, clear order minimize (DW, M) one focus instead minimizing ( j di j wj , mi ) i. One way looking
j di j wj mi think rows wj set prototypical vectors representative
dynamics MDP M. Recalling row forms convex combination, element di j seen weight representative vector wj approximation mi (Cutler &
Breiman, 1994; Keshava & Mustard, 2002). core assumption section that, general,
di j decrease (mi , wj ). Although necessarily true exact factorization,
many approximation schemes rely implicitly explicitly premise (Hastie et al., 2002).
One example local kernel smoothing techniques Nadaraya-Watson kernel-weighted
estimator (Hastie et al., 2002, Chap. 6). case, elements would computed as:
di j =

exp( (mi , wj )/ )
,
k exp( (mi , wk )/ )

(19)

controls relative magnitude elements one row matrix. generally,
di j computed based function non-increasing respect (mi , wj ).
assumption di j decreases (mi , wj ) makes possible compute based exclusively , example given (19). also possible compute W using
dissimilarity measure. example, Thurau et al. (2012) argue that, one restricts rows W
subset rows M, minimization defined (18) accomplished
maximization volume simplex defined rows W. Based concepts distance geometry, authors show possible efficiently compute volume
simplex defined candidate W using only. also several clustering algorithms
require distance matrix work, never accessing vectors mi directly (Kaufman &
Rousseeuw, 1990). Finally, one derive simple heuristics use compute matrix W
covers well possible convex set defined M, ensuring every row mi close
least one representative vector wj . example, one adopt constructive method goes
vectors mi successively adds new rows matrix W order guarantee
min j (mi , wj ) < i, predefined threshold. Notice case number
representative rows wj automatically determined value . idea
explored Section 4.2.2.
obvious advantage computing DW based solely problem reducing
computational cost factorization comes finding efficient ways computing
. Specifically, one replace approximation whose computation requires fewer
arithmetic operations. One way define restrict computation (mi , j ) properly
defined subset elements mi j corresponds enforcing degree
778

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

sparsity (see Mahoney, 2011). section goes another direction, though: exploits
fact vector mi associated specific state-action pair often represented
feature vector whose dimension much smaller |S|.
dynamic programmings perspective, state sk nothing index k {1, 2, ..., |S|}.
However, MDP describing real decision problem, state clear semantic interpretation. general, given state MDP represented set features descriptive
real state problem. Based state features, usually easy define feature
vectors represent state-action pairs. Therefore, thought finite subset
vector space; slight abuse notation (si , a) used refer vectors representing
state-action pairs dim(S A) denote number components (si , a).
many cases, reasonable assume state-action features provide information
regarding dynamics MDP. precise, let dissimilarity measure defined
A. assumption that, state-action pair (sk , a) similar state-action pair (sl , b),
associated transition probabilities rewards also similarthat is, distance
corresponding vectors mi j small. Thus, one use surrogate .
Note direct relationship naturally happen MDP
result discretization model continuous state space, long functions defining
MDPs dynamics reasonably smooth resolution discretization sufficiently
fine. Moreover, often relative magnitude distance matters proper functioning
algorithms (Kaufman & Rousseeuw, 1990; Thurau et al., 2012). Therefore, approximation
((sk , a), (sl , b)) C (mi , j ), C > 0, suffice many cases.
strategy replacing dissimilarity measure defined state-action space
result significant computational savings dim(S A) |S| + 1. akin wellknown kernel trick, algorithm rewritten terms inner products
replaced appropriately defined kernel (Scholkopf & Smola, 2002). kernel trick allows
one work high-dimensional feature spaces without ever explicitly computing features.
Similarly, adopting algorithm based exclusively , replacing latter , one
compute approximation DW without ever manipulating vectors mi directly.
strategy used algorithm computes W based . illustration,
next section describes concrete algorithm that.
4.2.2 N LGORITHM



C OMPUTE



FACTORIZATION



MDP



L INEAR IME

previous sections discussed several ways address stochastic factorization problem (Problem 1). approach advantages drawbacks, decision method
adopt take account factors like size problem, level accuracy required
solution, computational resources available. section describes detail
specific algorithm compute approximation DW M. objective provide illustration ideas described implemented, also make discussion
regarding computational theoretical aspects factorization problem concrete.
proposed method, described Algorithm 3, builds ideas discussed Section 4.2.1.
strategy select subset rows form matrix W, row mi
representative vector wj within predefined neighborhood. neighborhood induced
dissimilarity measure defined A. mechanics method simple. goes
state-action pair MDP computes distance -closest neighbors
779

fiBARRETO , P INEAU , & P RECUP

set E state-action pairs already selected part model (line 7 Algorithm 3).
distance closest neighbor predefined threshold , corresponding row
added W (lines 9 11). not, number representative state-action pairs remains same.
Regardless whether model grown not, -closest neighbors used compute
elements zth row D, z index current state-action pair (lines 13
14). elements di j computed function increase (see
discussion Section 4.2.1 equation (19) example).
Algorithm 3 Stochastic-factorization computation
MDP
R|S||A||S|+1 corresponding features (si , a)
: (S A) (S A) 7 R similarity function
Require: : R 7 R
non-decreasing function
R+
neighborhood radius
N
number neighbors approximation
Ensure: Factorization DW
1: E{(s1 , 0)}
E representative state-action pairs (|E| = m)
2: D0 R|S||A|1 ; Wm1 R1|S|+1
3: 1, 2, ..., |S|
4:
1, 2, ..., |A|
5:
z(a 1) |S| +
z row index (si , a) (see (11))
6:
h min( , |E|)
7:
find h nearest elements (si , a) E according ; call jth closest pair (s, b) j
8:
((s, b)1 , (si , a)) >
new representative state-action pair must added
9:
EE+ {(s
,
a)}


W
10:
W
Add one row W
z
11:
D[ 0 ]
Add one column
12:
j1, 2, ..., h
13:
k index (s, b) j W
14:
dzk ( ((s, b) j , (si , a)))
15:

|E|

j1, 2, ..., |E| dz j dz j / l=1 dzl

Make sure stochastic

parameter strong effect output Algorithm 3: decreasing value usually
leads accurate approximation DW M, also increases number representative state-action pairs (or, equivalently, representative vectors wj ). algorithm go
state-action pairs MDP order, end every pair least one representative counterpart within distance space (S A, ). However, since Algorithm 3
greedy method, set state-action pairs selected part model may change depending order pairs visited. parameter determines number
representative vectors wj used approximate mi , seen device control
local approximation (this akin setting parameter k k-nearest neighbor
approximation; see Hastie et al., 2002, Chap. 2, intuitive discussion). parameter also
direct effect computational cost algorithm, discussed next.
demanding operation iteration Algorithm 3 computation nearest neighbors current state-action pair. several efficient algorithms available
780

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

perform search, either exactly approximately (Liu et al., 2005). popular exact
method use KD-tree, takes O(dim(S A)m log m) operations constructed
allows search performed O( log m) time, average (Friedman et al., 1977). Since
Algorithm 3 performs |S||A| iterations, overall complexity linear |S|. Therefore, using
algorithm build approximation DW M, assuming number iterations
performed PISF much smaller |S|, cost entire process computing decision
policy depends linearly number states MDP. best one without
assuming extra structure model.
space complexity Algorithm 3, note actual implementation matrix
really necessary, neither W must explicitly stored: W represented
m-dimensional vector containing indices representative state-action pairs
data structure |S||A| nonzero elements di j .
mentioned, Algorithm 3 terminates state-action pairs MDP least one
representative state-action pair within neighborhood radius defined space (S A, ).
order extrapolate guarantee performance PISF, necessary relate . Let
(sk , a) (sl , b) two state-action pairs associated vectors mi j , respectively. Then,

((sk , a), (sl , b)) < = (mi , j ) < ,

(20)

relatively straightforward provide guarantees regarding PISFs solution. example,
(17) adopted = 1, one resort Proposition 3 obtain guarantees.
specific scenarios easy ensure assumptions like (20) hold,
example MDP results discretization continuous model. may also
possible derive guarantees similar (20) based knowledge problem, example
looking transition equations describing dynamics MDP. general, though, may
difficult relate . Note trivial modify Algorithm 3 reflect case
computed based subset elements mi j . case deriving guarantees
analogous (20) considerably easier (see example Mahoney, 2011).
Algorithm 3 relies two premises: (i) given W, making elements di j inversely
proportional (mi , wj ) results good approximation DW M; (ii) possible define
dissimilarity measure : (S A) (S A) 7 R ((sk , a), (sl , b)) C (mi , j ),
C > 0, mi j rows associated (sk , a) (sl , b), respectively.
important point building algorithm based assumptions one possible
artifice circumvent computational cost factoring MDP. strategies may possible,
resorting domain knowledge developing methods exploit structural regularity
MDP (see Section 5.3.3). fact, scenarios exact factorization readily
available without need computation (see Barreto, 2014, example). case,
next section shows empirically Algorithm 3 generate good decision policies
problems.

5. Computational Experiment
section illustrates PISF useful practice real-world application significant
economical interest.
781

fiBARRETO , P INEAU , & P RECUP

5.1 Multicomponent-Replacement Decision Task
One big challenges faced industry maintenance assets long period time.
example, commercial airline cargo company must operational fleet, power
company needs maintain electric power grid functioning times (Powell, 2007). many
cases, maintenance expensive equipments involves sums money counted millions
dollars. situations, decisions made maintenance activities may
enormous economical impact.
Usually, equipment jet engine electric generator composed several components degrade time. critical component breaks, replaced immediately.
often case maintenance operation associated setup cost independent number components replaced. may financial losses caused
time costs associated activities disassembling equipment, delivery new
components, displacement specialists. Thus, circumstances, may advantageous
perform opportunistic replacements functioning components avoid future setup costs.
discussed, trade-off immediate future costs typical decision making tasks.
importance decision problem described attested huge body literature
originated 1960s spanning subsequent four decades (Barlow & Proschan, 1965;
McCall, 1965; Pierskalla & Voelker, 1976; Sherif & Smith, 1981; Cho & Parlar, 1991; Dekker
et al., 1997; Wang, 2002). problem formalized follows. Suppose asset
interest nc components let l j N+ denote expected lifetime component c j measured
discrete time unit. Then, state si vector si Nnc whose jth entry si j represents
remaining lifetime component c j . time step remaining lifetime c j decreased
one, si j = 0 indicates component longer operational. Even c j reached
end useful life, may fail given probability, function si j possibly
components remaining lifetimes siu . inactive component c j causes entire asset
stop working, c j replaced immediately penalty takes place next
transition. avoid that, one must replace c j , incurs cost r j dollars. top that,
every replacement activityjoint nothas associated setup cost. setup cost composed
two terms, fixed amount Rs dollars plus extra fee R f dollars charged
component failed reaching expected lifetime. extra fee covers expenses
last-minute measures required unexpected failures. Let action represented binary
vector ah {0, 1}nc ah j = 1 indicates component c j replaced. goal
decision maker select action ah time step order minimize expected
discounted future cost.
one see, problem suffers particularly severe version curse dimensionality: state space grow fast nc , |S| = (li + 1), also cardinality
action space exponential function variable, since |A| = 2nc . Thus, even instances
problem small number components already represent difficult challenge
dynamic programming.
Given scalability issue, researchers usually focus particular cases multicomponentreplacement task whose structure exploited somehow. example, noted
literature failure cost R f considered state space multicomponentreplacement problem reduced 50% simply eliminating states
components functional (i.e., si j > 0 j). Since one knows optimal action
782

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

excluded states replace zero components, modification change optimal
policy problem (see Sun et al., 2007; Arruda & Fragoso, 2011). Note though
R f > 0 may advantageous carry replacements even components expired;
seen, case reduction strategies cited may fail.
Researchers practitioners also explored constrained versions multicomponent-replacement task. example, replacement costs r j lifetimes l j
components c j , permutations given vector si considered state,
reduces state space considerably (Haurie & LEcuyer, 1982). Another simplification
problem assume probability component c j failing independent
components remaining lifetimes siu . case, components related
economical dependence represented setup cost (Cho & Parlar, 1991). resulting
model, factored MDP, solved orders magnitude faster conventional MDP (see
Section 5.3.3). also possible reduce action space multicomponent maintenance
task making assumptions regarding problems dynamics (Xia et al., 2008).
Although methods effective particular instances maintenance
task, directly applicable general version problem, components different characteristics depend economically structurally.
Hence, practice industry often relies simple threshold policies replace components
remaining lifetime given value (Haurie & LEcuyer, 1982; van der Duyn Schouten
& Vanneste, 1990). Unfortunately, known that, general, optimal policy multicomponent-replacement problem lie space threshold decision policies (Ozekici,
1988; Xia et al., 2008).
5.2 Experimental Setup
experiments described section carried assuming general version maintenance task components interact other. failure probability component c j
modeled linear function assets general condition. Suppose asset state si
decision maker decides perform action ah . Then, denoting next state sk , probability
component c j failing is:
P(sk j = 0 | si j > 1, ah j = 0) = f

( f fmin )(si j 1) u6= j (lu siu )
,
+f
lj 1
u6= j lu

(21)

f , fmin f parameters model assumed l j > 1 j. motivation
equation (21) probability given component failing depend
condition component itself, also condition components asset.
fact generalization commonly used model problem; f = fmin f = 0,
equation (21) reduces fixed failure probability often assumed literature (Sun et al.,
2007; Arruda & Fragoso, 2011). experiments, equation (21) considered f = 0.1,
fmin = 0.01, f = 0.1. Thus, many components asset expire, probability
component c j failing double.
formulation problem considered also general respect characteristics individual components asset. Instead assuming components
lifetime cost, seems unrealistic, variables l j r j drawn normal
distributions means l = 10 r = 10 common standard deviation lr = 3 (the values
783

fiBARRETO , P INEAU , & P RECUP

sampled l j rounded closest natural number sampled case result
smaller 2). configuration, expected value models parameters coincide
ones adopted Sun et al. (2007). constant term setup cost fixed Rs = 10
failure cost set R f = 5nc . discussed above, R f > 0 might happen
(si ) 6= 0 even si j > 0 j. increases effective size state space, since one
cannot simply discard states without expired components.
multicomponent-replacement task modeled discounted problem = 0.999
(as discussed Puterman, 1994, case seen way emulating devaluation
money). value nc {2, 3, ..., 7}, 100 instances problem randomly generated.
policy iteration algorithm used find optimal policy resulting MDPs (see
Appendix A.3). means comparison, policy iteration also applied reduced version
problem, state si removed MDP si j > 0 j. Note
modification requires recalculation transition probabilities states
remain model (Arruda & Fragoso, 2011). Here, order accomplish reduction, actions
replaced temporally extended counterparts, options, giving rise semi-MDP
(options closed-loop policies well-defined termination condition initiation set; see
Sutton et al., 1999, details) .
order evaluate heuristics usually adopted industry, threshold policies using values
ranging 1 10 considered. value nc , policies compared
one providing lowest expected cost used comparisons algorithms.
Notice threshold policy using value 0 corresponds naive strategy replacing non-operational components. performance policy used baseline
comparisons.
discussed Section 4, PISFs configuration comes definition matrices
R|S||A|m W Rm|S|+1 . experiments section matrices computed
Algorithm 3. following function used similarity measure state-action pairs:

((si , ah ), (sk , ag )) =



ah 6= ag ,
nc
(1 ah j )|r j |(si j sk j )2 otherwise.
j=1

(22)

intuition behind (22) straightforward: two state-action pairs considered similar
if, application actions corresponding states, remaining lifetimes
components approximately (except eventual failures). Note difference
remaining lifetimes si j sk j weighed magnitude cost r j replacing
jth component. parameters Algorithm 3 defined follows. number
neighbors used approximation set nc , function defined constant
1/ , neighborhood radius varied {200, 400, 600}. Since parameter
varied across experiments, specific instances PISF referred PISF- (see
Appendix A.3 details regarding implementation PISF).
5.3 Results
Throughout section, following measure used evaluate algorithms:

(v , v | S) =

vi vi
1
,

|S| {i | S} |vi |


784

(23)

fiP OLICY TERATION BASED

TOCHASTIC FACTORIZATION

0.15

0.16

0.17

PI
PIRED
BEST THR
PISF200
PISF400
PISF600

0.12

0.13

0.14

(v, vN)



2

3

4
5
6
Number components (nc)

7

Figure 2: Expected gain multicomponent-replacement problem respect naive
decision policy. Error bars represent one standard error 100 runs.
v value function policy returned algorithm evaluation, v
reference value function, set test states used evaluation (note
take negative values).
5.3.1 TANDARD OLUTIONS
two natural ways addressing multicomponent-replacement problem use dynamic programming resort threshold policies normally adopted practice. section
compares methods PISF. performance measure used evaluate algorithms
relative gain one expect using instead naively replacing component
fails. Hence, reference function v (23) value function naive policy, vN .
nc 5, possible compute value functions v vN exactly, thus
case set appearing (23) entire state space S. However, nc > 5 computing v
vN becomes infeasible computers used experiments. case composed
10, 000 test states si sampled uniformly random S, corresponding values vi vi N
approximated Monte Carlo roll-outs length 5, 000.4
Figure 2 compares results policy iteration (PI), policy iteration applied reduced
version problem (PI-RED), best threshold policy (BEST THR), PISF using = 200,
= 400, = 600. One thing immediately stands figure fact performance optimal policies improves number components nc increases. indicates
financial losses company make opportunistic replacements increase
number components asset.
4. roll-outs truncated point value rewards (in case current application,
dollars) already decreased 99% (that is, 5000 < 0.01).

785

fiBARRETO , P INEAU , & P RECUP

THR policies perform better naive policy general. Notice though results
shown Figure 2 correspond performance best THR policy selected independently
value nc . So, example, average gain provided best THR policy
nc = 5 13.36%, average gain worst policy type 3.77%. means that,
order achieve level performance shown Figure 2 real application, one cannot
arbitrarily pick one specific THR policy. Rather, necessary model problem
willing systematically compare possible threshold values. Even case, resulting policy suboptimal. example, nc = 5, making optimal decisions increases
expected profit best THR policy 27.8%, average (see Figure 2). Considering
amounts money often involved maintenance activities, difference represent significant monetary gains. good illustration impact dynamic programming may
practice.
Unfortunately, dynamic programming scale well number components
multicomponent-replacement task. mentioned above, experiments described
optimal policy could computed instances problem nc > 5. Since
standard dynamic programming algorithms easy way control amount memory
used, one left alternatives. case multicomponent-replacement task, one
possibility eliminate states si > 0 apply dynamic programing reduced MDP.
strategy reduces state space considerably, makes possible solve MDPs one order
magnitude bigger (see Figure 2). Although technique works well version problem
considered Arruda Fragoso (2011), may fail version problem considered here,
optimal policy may carry opportunistic replacements states without expired
components. illustrated PI-RED curve Figure 2, clearly shows
optimal policies reduced MDPs perform optimally original models.
PISF represents alternative two extremes computing optimal policy
resorting simple heuristics threshold policies. contrast conventional dynamic
programming algorithms, PISF provides practical mechanism control trade-off
computational resources used quality resulting decision policy (the order
stochastic factorization, indirectly defined neighborhood radius ). point better
illustrated Figure 2 analyzed conjunction Figure 3, shows size
models generated algorithm associated time needed solve them.
dimension matrices processed algorithms value function computation defined number states corresponding Markov process. Thus, number
good measure algorithms time space complexities. case policy iteration,
defines size Markov processes number states MDP; PISF, number m, order stochastic factorization. size Markov processes generated
method shown Figure 3a. figure makes clear amount memory required
methods restricts application. example, PI-RED run MDPs
nc = 7 components, resulting Markov processes would bigger largest
model shown.
expected, size Markov processes generated PISF decreases . Take
MDPs nc = 5, instance. case average reduction original models provided
PISF 60% = 200, 88% = 400, 95% = 600. analyzing
numbers, one keep mind computational cost evaluating decision policy
cubic size Markov process. Thus, value functions computed exactly,
786

fi1e+06

P OLICY TERATION BASED



TOCHASTIC FACTORIZATION

15
5
0

2e+05
0e+00

PI
PIRED
PISF200
PISF400
PISF600

Hours
10

Size
4e+05 6e+05

8e+05

PI
PIRED
PISF200
PISF400
PISF600

2

3
4
5
6
Number components (nc)

7

2

(a) Size Markov processes

3
4
5
6
Number components (nc)

7

(b) Run time (PISFs values include time compute MDP factorization Algorithm 3)

Figure 3: Size models generated algorithms associated time needed compute
solution. Error bars represent one standard error 100 runs.
reduction 88% models size translates decrease 99, 82% number arithmetic
operations performed value-function computation.
course, real application value function seldom computed exactly. Besides,
order use PISF one compute factorization MDP. Even considering factors,
replacing PI PISF result significant time savings. illustrated Figure 3b,
shows actual run times algorithms. concrete example, take MDPs
nc = 5 components. case, adopting PISF-600 instead PI results 97% reduction
computing timewhich equivalent saying former algorithm 37 times faster
latter. put number perspective, possible run PI MDPs nc = 7
components, finding decision policy would take 8 days. PISF-600 able compute
approximation less 5 hours.
reduction computational cost memory usage provided PISF meaningless resulting decision policies perform poorly. Comparing Figures 2 3, one clearly
see case multicomponent-replacement problem. example, replacing PI PISF-400, average reduction computing time 90% values nc .
contrast, expected decrease profit 6.2%. one adopts PISF-600 instead
PISF-400, reduction computational cost least 94%, values nc ,
associated losses 9.5%. illustrates PISFs performance degrades gracefully quality MDPs factorization, indicated theoretical results presented
Section 3.3.
however clear decrease expected gain provided PISF nc increases
6 7, shown Figure 2. One possible explanation fact multicomponentreplacement task increasing number components asset increases size
state space S, also number actions A. means dimension
787

fiBARRETO , P INEAU , & P RECUP

number matrices Pa increase exponentially nc , making harder summarize
information single matrix K. top that, perhaps important, keeping
neighborhood radius fixed, relative size models generated PISF actually decreases.
example, PISF-400, average ratio m/|S| equal 0.23 nc = 3, 0.12 nc = 5,
0.06 nc = 7. Thus, order keep relative size fixed, must increase
nc . case, even MDPs nc = 7 components PISF clearly outperforms best THR
policy, feasible alternative among methods considered section. next
sections investigate approximate solutions multicomponent-replacement problem.
5.3.2 U PPER C ONFIDENCE B OUNDS



REES (UCT)

possible compute optimal policy multicomponent-replacement problem
number components asset certain threshold defined computational
resources available. threshold, standard solution adopted industry resort
simple heuristics. previous section presented PISF alternative solution allows
control trade-off computational resources used quality resulting policy. natural ask whether approximate methods would also applicable
case.
Two popular approaches approximately solving MDP value-function approximation
state aggregation. techniques closely related stochastic-factorization trick,
discussed Section 6. section focus set methods collectively known
Monte-Carlo tree search (MCTS). MCTS methods capable computing approximate solutions
large MDPs combining tree search random sampling (Browne et al., 2012).
methods receiving lot attention recently due enormous success several
applications, notably game Go (Bouzy & Helmstetter, 2003). MCTS algorithms use
Monte Carlo roll-outs estimate return associated actions available current state.
order so, build tree, rooted current state, whose structure reflects transitions
performed roll-outs.
main feature distinguishes different MCTS algorithms strategy used select
actions roll-outs. popular MCTS algorithm Kocsis Szepesvaris (2006)
upper confidence bounds trees (UCT). UCT action selection process interpreted
multi-armed bandit problem arm corresponds action (Auer et al., 2002).
Intuitively, UCT works adding exploration bonus values actions
tried less often. One main parameters algorithm exploration constant C p used
weigh bonus value actions (Kocsis & Szepesvari, 2006).
UCT nice theoretical properties: given > 0, guaranteed return -optimal
action depth tree number roll-outs large enough (Kocsis & Szepesvari,
2006). Therefore, given enough computation, UCT always able perform level
PISF (and eventually better, PISFs policy optimal). interesting question case
much computation needed practice happen.
order answer question, experiment carried UCT PISF
compared multicomponent-replacement problem. algorithms evaluated 100
MDPs nc = 5 components described Section 5.2. before, performance resulting
policies contrasted naive policy N . comparisons based single
roll-out starting state selected uniformly random independently MDP.
788

fiON

TOCHASTIC FACTORIZATION

0.2

P OLICY TERATION BASED

0.2
0.4

UCT

0.6

(v, vN)

0.0

PISF600

1

3

5
7
9
11
Seconds per step (tmax)

13

15

Figure 4: Expected performance multicomponent-replacement problem respect
naive decision policy. Error bars shadow represent three standard errors 100 runs.
specifically, set test states appearing (23) composed single state si , and,
before, corresponding values vi viN approximated Monte Carlo roll-out
length 5, 000.5
described above, action selection UCT builds tree based Monte-Carlo rollouts. number roll-outs grows, quality value function approximation increases,
computational cost algorithm. Thus, one way evaluating UCT impose
time limit tmax iteration algorithm check performance resulting policy
function tmax . Note that, given fixed time budget tmax , trade-off
number roll-outs carried length, finding right compromise
two corresponds finding right balance bias variance value function
approximation (Hastie et al., 2002). issue resolved changing maximum depth
tree, hmax , set {5, 50, 500, 5000}.6 Also, UCTs exploration parameter C p varied
{100 , 101 , 102 , 103 }. Therefore, MDP value tmax , UCT run 16 times
corresponding possible combinations values hmax C p , best result
selected compared naive policy (23). Figure 4 shows average value
(v , vN ) function tmax . reference comparison, average result PISF-600
MDPs also shown.
shown Figure 4, UCT performs worse naive policy N tmax 15. Assuming
logarithmic trend shown figure persist tmax > 15, UCT would need 46 seconds
per step reach level performance N . order find solutions comparable
found PISF-600, UCT would require around 115 seconds per step, approximately 1.74 times
time needed former algorithm compute decision policy entire state space.
5. policies evaluated single test state nature UCT algorithm makes computationally impractical carry many roll-outs length 5, 000. case, small variance (23) across
MDPs indicates decision strong effect comparisons.
|S|
6. Since |(vmax vmin )/v | < 0.002 MDPs, v = 1/|S| i=1 vi , value leaf nodes set zero.

789

fiBARRETO , P INEAU , & P RECUP

Note that, even though time limit tmax = 15 seconds per step may seem like much first,
run time UCT quickly escalates horizon problem. becomes clear
one observes trajectory 5, 000 steps UCT using tmax = 15 takes 20 hours,
computing optimal decision policy problem takes average 34 minutes.
mentioned basic version UCT used experiments
section. Nowadays several extensions available literature (see example Chaslot
et al., 2008; Gelly et al., 2012; Keller & Eyerich, 2012). strategies, built top
UCT, tend improve performance. said, fact UCT needs orders magnitude
computation PISF reach level performance surprising, since
former uses MDP generative modelthat is, algorithm samples
conditional distributions represented transition matriceswhile latter fully exploits
information available model.
5.3.3 FACTORED MDP
previous section illustrated exploiting information available problem
important computational efficiency. section shifts focus discussion another
issue, namely structure model. particular, describes specific structured model
known factored MDPs.
factored MDP transition dynamics described dynamic Bayesian network
(DBN, Dean & Kanazawa, 1989; Boutilier et al., 1995). Let s(t) s(t+1) denote, respectively,
state current time next step. transition graph DBN two-layer directed
(t+1)
(t+1)
(t)
(t+1)
(t)
acyclic graph whose nodes variables set = {s(t)
1 , s2 , ..., sn , s1 , s2 , ..., sn }.
(t)
(t+1)
arc j si indicates value ith variable time + 1 depends value
jth variable time t. Let (si(t+1) ) denote set nodes arc si(t+1) . transition
model factored MDP given P(s(t+1) |s(t) ) = P(si(t+1) | (si(t+1) )). allows compact
representationand efficient solutionof factored MDP assumption DBN sparse,
is, (si(t+1) ) restricted small subset i. addition, assumed reward
given summation functions depend status variables.
assumptions hold, is, MDP truly factored, possible represent models dynamics compactly using structures like decision trees algebraic decision diagrams (Boutilier
et al., 1995; Hoey et al., 1999). Therefore, number states MDP remains same;
computational gain comes fact state space never explicitly enumerated.
first, one might expect structure factored MDP would induce value function
similar structure. indeed case, would possible compute optimal policy
factored MDP much faster dynamic programming algorithms ignore models
special structure. Unfortunately, Koller Parr (1999) shown that, general, value
function factored MDP factored. Therefore, practical algorithms developed factored
MDPs compute approximate solution (see Guestrin et al., 2003, references therein).
factored MDP model captures dynamics many real-world decision-making tasks (Powell, 2007). fact, safe say MDPs solved using technique among largest
solved date (Guestrin et al., 2003, see also Section 5.4). However, decision problems
great interest whose dynamics satisfy assumptions models. version
multicomponent-maintenance problem addressed good example: since probability
given component failing depends condition components, resulting DBN
790

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

sparse (cf. equation (21)). happens one ignores fact MDP truly
factored applies algorithms developed assumption anyway?
help answering question, experiment performed following way. Let
one MDPs nc = 5 components described Section 5.2. component c j
value z {1, 2, 3, 4}, set z (c j ) {1, 2, 3, 4, 5} { j} containing z distinct elements
generated uniformly random. Then, value z, transition matrices
regenerated (21) replaced
( f fmin )(si j 1) u/ z (c j ) (lu siu ) + uz (c j ) (lu lu /2)
,
+f
lj 1
u6= j lu
(24)
giving rise MDP Mz . Using (24) corresponds enforcing sparsity DBN describing
components failure probabilities. Note that, instead completely ignoring influence
components cu u z (c j ), remaining lifetimes replaced lu /2, middle point
range possible values. way making factored model closer original
one without incurring denser DBN. transition matrices Mz generated, policy
iteration used compute optimal policy, z (note computation exact). Finally,
performance z original MDP compared , optimal policy
(thus, experiment reference value function v appearing (23) v , = S).
entire process repeated one 100 MDPs nc = 5 components.
Figure 5a compares performance z , policies returned policy iteration
artificially-factored MDPs (PI-FAC), PISF-200, PISF-400, PISF-600. Observe
performance PI-FAC degenerates level sparsity z artificially-factored MDPs
increases. expected, since derived models deviate original ones z approaches
nc . Since computational cost algorithms developed factored MDPs decreases
z, one trade performance speed choosing interactions variables
ignore. important point note fact PI-FAC outperformed instances
PISF z > 1. Since z optimal policy factored MDPs, performance
best one reasonably hope using algorithms approximate it. words,
factored MDP algorithm using (24) outperform PISF multicomponent-replacement task
approximation computes luckily induces policy performs better z
original, non-factored, MDP.
experiment shows that, pretending non-factored MDP factored, one may
severely restrict quality resulting policy, regardless specific algorithm chosen
solve factored MDP. reason believe phenomenon restricted
multicomponent-replacement domain. Thus, niche problems big
solved standard dynamic programming cannot reliably solved algorithms developed
factored MDPs. problems, might good alternative resort algorithms
exploit types structure, PISF.
say stochastic-factorization trick seen alternative factored MDPs. principle, properties MDP factored factorizable orthogonal other, therefore structures potentially exploited conjunction.
illustrate point, experiment carried PISF THR policies run
factored MDPs Mz . Note difference respect previous experiment:
models Mz considered approximations MDPs M, assumed
true models. Thus, PISF THR policies compared optimal policies z .
P(sk j = 0|si j > 1, ah j = 0) = f

791

fiBARRETO , P INEAU , & P RECUP

PISF400

2
3
Level sparsity (z)

0.14

0.05

PIFAC

1

0.06
0.10

0.03

(v, vz*)

0.02

PISF600

0.04

(v, v*)

0.02

0.01

PISF200

4

(a) Artificially-factored MDPs

BEST THR

PISF 200
PISF 400
PISF 600
1

2
3
Level sparsity (z)

4

(b) Truly-factored MDPs

Figure 5: Expected loss multicomponent-replacement problem respect optimal
decision policy. Error bars shadows represent one standard error 100 runs.

idea investigate structure transition matrix induced sparse DBN affects PISFs
performance. Figure 5b shows performance PISF best THR policy factored
MDPs Mz function level sparsity z (cf. equation (24)). Although performance
PISF degenerates slightly z increases, relative performance respect best THR
policy generally improves model gets sparse.
experiment illustrates stochastic-factorization trick potentially useful
computation policy factored MDP, may lead solution large
sequential decision problems. course, order simultaneously exploit factored
factorizable structures model, one apply trick without explicitly manipulating
matrices involved. constitutes interesting extension current research, left
suggestion future work.
5.4 Discussion
section described application PISF large problem real interest. shown that,
using Algorithm 3 compute W, possible handle MDPs whose exponentially large
state action spaces preclude use standard dynamic programming. largest instance
problem solved PISF 39, 916, 800 states 128 actions, 359 times size
largest MDP solved policy iteration. Note maintenance problem studied
trivial define heuristics perform reasonably well, applications may
true. example, Dekker et al. (1996) point multicomponent-replacement problem
structure similar important decision-making tasks arising production
inventory control. scenarios PISF even valuable tool.
792

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

mentioned experiments section considered classical scenario
dynamic programming, one seeks decision policy defined entire state space S.
formulations decision problem possible. example, field automated
planning often assumed decision maker must perform well small number
initial states only, state si small set actions A(s) available (Ghallab
et al., 2004; Geffner & Bonet, 2013). top that, sometimes assumed dynamics
MDP truly factored (Sanner, 2010). assumptions hold, possible
decision maker perform well visiting small fraction state space, and, since
MDPs dynamics factored, sometimes even small subset must explicitly enumerated.
Therefore, algorithms developed scenario applied large MDPs (Keller &
Eyerich, 2012; Kolobov et al., 2012).
PISF direct competitor planning algorithms developed scenario
designed assumptions mind. Since PISF offline method computes
policy entire state space, never scale MDPs large handled on-line
methods compute policy demand, UCT. Similarly, MDP truly factored
dynamics favor methods exploit structure. hand, experiments
section show, assumptions underlie planning algorithms hold,
largely outperformed PISF.
end, determines success given algorithm suitability underlying
assumptions scenario interest. PISF developed MDPs factorizable
nearly soa structural regularity exploited dynamic programming algorithm.
often structure arises problems interest well exploited together
assumptions, usually considered automated planning, interesting questions
addressed future research.

6. Related Work
section reviews approaches proposed circumvent dynamic programmings curse dimensionality, discusses methods relate stochasticfactorization trick.
6.1 Value-Function Approximation
Perhaps straightforward approach deal large MDP use compact parametric
representation value function. new idea; fact, Bellman Dreyfus explored
use polynomials approximate value function early 1959. Since theory
evolved lot, nowadays possible find books cover subject detail (Bertsekas
& Tsitsiklis, 1996; Powell, 2007).
main issue regarding use parametric representation value function damaging effect may dynamic programming algorithms. particular, well known
use general approximators may cause instabilities even divergence algorithms (Boyan
& Moore, 1995; Baird, 1995; Tsitsiklis & Roy, 1996, 1997). common strategy deal
problem restrict structure approximator compact representations
linear dependence parameters (Tsitsiklis & Roy, 1997; Tadic, 2001; Schoknecht & Merke,
2003). Indeed, use linear approximators led number successful algorithms
793

fiBARRETO , P INEAU , & P RECUP

good convergence properties (Tsitsiklis & Roy, 1996; Bradtke & Barto, 1996; Perkins & Precup,
2003; Lagoudakis & Parr, 2003; Sutton et al., 2008).
evidence literature instability caused function approximators related tendency exaggerate difference two successive estimates
value function (Thrun & Schwartz, 1993; Gordon, 1995; Ormoneit & Sen, 2002). reason,
many researches advocated use conservative function approximators compute
value state weighted average states values (Gordon, 1995; Tsitsiklis & Roy, 1996;
Rust, 1997; Munos & Moore, 1999; Ormoneit & Sen, 2002; Szepesvari & Smart, 2004). Examples
approximators include kernel averaging, linear interpolation, k-nearest neighbor,
types splines. general, combination approximators dynamic programming
leads convergent algorithms (Gordon, 1995; Tsitsiklis & Roy, 1996).
Conservative function approximators similar nature stochastic-factorization trick.
see so, consider class function approximators Gordon (1995) called
averagers. averager approximates value state convex combination states
values possibly predetermined constants. Given MDP (S, A, P, R, ), let
subset state space S, |S| = m, let v Rm represent values states
subset. averager would compute approximation value function


vi = di0 ci + j=1 di j v j ,

(25)

ci R, di j R+ mj=0 di j = 1. Since approximation scheme values
states determined values states S, latter must updated
dynamic programmings iterative process.
sake simplicity, suppose averager dio = 0
{1, 2, ..., |S|}. case, approximate dynamic programming using (25) corresponds exact
|S|
version reduced MDP (S, A, P, R, ) Pa (s j |si ) = k=1 paik dk j ra (si ) = ra (si ) (Gordon, 1995, Thm. 4.1). model represents particular case stochastic-factorization trick
single matrix R|S|m one matrix Ka Rm|S| (Barreto
et al., 2011). dynamics reduced model given Pa = Ka D, Ka matrix
composed rows original transition matrix Pa R|S||S| associated states si S.
interpreting conservative approximators particular case stochastic-factorization trick,
schemes similar (25) thought approximating MDP itself. Thus, definition
approximators architecture configuration parameters converted well
defined optimization problem, objective find matrices Wa minimize
(Ma , DWa ) A.
6.2 Model Reduction
Another way handling large-scale decision-making problems find compact representation
associated MDP. case, simplest idea aggregate states share common
characteristic. many proposals type literature, distinguishes
criterion used group states. detailed account model approximation techniques,
reader referred review provided Li et al. (2006).
One earliest works model approximation Bertsekas Castanon (1989),
propose aggregating disaggregating states dynamically, value function computation, according residual left applications Bellman operator. alternative
794

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

approach group states based associated transition probabilities rewards. Following
line, Givan et al. (2003) suggest notion stochastic bisimulation criterion aggregate
states. Roughly speaking, two states bisimilar expected reward associated
action, transition probabilities groups bisimilar states. notion
closely related Ravindrans (2004) concept homomorphism MDPs. bisimulation homomorphism principled criteria state aggregation, guarantee
optimality decision policy lifted compact model. However, restrictive
applied many real situations. Realizing that, several authors proposed relaxed versions
criteria (Dean et al., 1997; Ferns et al., 2006; Ravindran, 2004; Sorg & Singh, 2009).
Regardless specific criterion used group states, state aggregation naturally
represented stochastic factorization. case, rows matrix W represent dynamics
associated group matrix one nonzero element per row indicating group
state-action pair belongs (note flexibility aggregating state-action pairs instead
states only). context, applying stochastic-factorization trick corresponds computing
probabilities transitions groups. slightly general approach model reduction assume soft aggregation states, state belongs group given
probability (Singh et al., 1995; Sorg & Singh, 2009). Soft aggregation also naturally represented
stochastic factorization letting one nonzero element per row. fact,
shown Sorg Singhs (2009) concept soft homomorphism equivalent particular
case stochastic-factorization trick discussed Section 6.1 (Barreto et al., 2011).
one see, stochastic-factorization trick serve useful formalism thinking
state aggregation. example, hard aggregation states corresponds matrix
row contains single 1 rows associated given state nonzero element column. soft aggregation state-action pairs restrictions removed.
Also, single application trick leads (soft) homomorphism, successive applications
lead aggregation/disaggregation scheme similar Bertsekas Castanons (1989) approach.
Perhaps important, conservative approximators, stochastic factorization turns
aggregation problem well defined optimization problem. provide unifying framework analysis, comparison, solution different versions aggregation problem.

7. Conclusion
approach presented paper builds simple idea, called stochastic-factorization
trick: given stochastic factorization transition probability matrix, one swap factors
multiplication obtain another transition matrix, possibly much smaller original.
property exploited reduce number states Markov process. Intuitively,
stochastic-factorization trick corresponds creating small number representative states (or
state-action pairs) redirecting transitions original model according similarity
measure. Formally, process posed well defined optimization problem.
stochastic-factorization trick extended MDP least two ways: one
factor Markov process comes search decision policy factor Markov
processes associated actions problem search begins. single matrix K
single vector r used latter, PISF algorithm used compute decision
policy problem hand. PISF reduces computational complexity standard policy
iteration cubic dependence |S| function grows linearly size
795

fiBARRETO , P INEAU , & P RECUP

MDP. PISF also enjoys nice theoretical guarantees, since always converges decision
policy whose performance improves quality MDPs factorization. general
factorization improves order, m, one use parameter control trade-off
use computational resources performance resulting policy.
order apply PISF decision-making problem, one must find approximate factorization
corresponding MDP, DW. One way compute factorization see rows
W prototypical vectors represent dynamics interpret elements
similarity measure vectors rows M. way, W
computed based dissimilarity measure defined problems state-action space A.
technique allows approximation DW computed time linear |S|. Therefore,
entire process computing decision policy PISF depend linearly number
states MDP. Exploiting fact, PISF able find approximate solutions instances
important decision task 5 billion state-action pairs. solutions found
considerably better found heuristic commonly adopted practice.
Evidently, paper exhaust discussion stochastic-factorization trick
PISF. One subject calls investigation development alternative methods
efficiently compute matrices W (or identification scenarios factorization
available easy compute). Another promising research topic application stochasticfactorization trick factored MDPs types structured models. Finally, PISF may also
useful context model-based reinforcement learning. case, instead collecting
sample transitions order estimate parameters MDP M, one leverage use data
focusing prototypical state-action pairs represented W. W determined,
elements computed based measure similarity defined A, done
experiment presented paper. topics constitute interesting directions future
research.

Appendix A. Modified Policy Iteration Modified PISF
Throughout paper, assumed value function v computed exactly step
policy iteration. facilitates analysis theoretical properties computational
complexity algorithms. However, ideas discussed extend naturally case
v approximated.
A.1 Modified Policy Iteration
Puterman Shins (1978) modified policy iteration, v estimated applications
. Thus, case value function computation involves O(|S|2 t) operations. Decreasing
reduces computational cost evaluating decision policy, general also increases
number policies must evaluated convergence (Puterman, 1994). Note
= 1 one recovers value iteration algorithm. Similarly, |S| one simply compute v
exactly solving associated linear system, comes conventional policy iteration.
Therefore, value iteration policy iteration seen special cases modified policy
iteration.
amount memory used modified policy iteration depends specific implementation adopted. general, memory usage inversely proportional algorithms effective run
time. One extreme implementation strategy store one vector corresponding current
796

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

estimate value function, v . Note though case multiplication P v requires
loading rows P secondary memory (or computing demand), thus significantly
increasing algorithms run time. One speed algorithm keeping entire MDP
loaded memory times, therefore increasing use memory O(|S|) O(|S|2 |A|).
intermediate solution two extremes load (or compute) P value
function computation, leads O(|S|2 ) memory usage.
A.2 Modified PISF
definition modified PISF straightforward: change needed replace exact
computation v line 6 Algorithm 2 applications v = r + P v. case, using
PISF instead modified policy iteration reduces computational cost value function
computation O(|S|2 t) O(m2t). reduction memory usage depends strategy
used represent models, discussed Appendix A.1.
clear using modified PISF = 1 corresponds combining stochasticfactorization trick value iteration. Note though that, terms computational cost, may
best alternative. discussed Appendix A.1, decreasing tends increase number
iterations performed PISF. iteration PISF involves building matrix computing
multiplication KD (lines 4 5 Algorithm 2, respectively), seen constructing operator current . Since construction takes O(|S|2 m) operations
application O(m2 ), one may wasting computational effort applying
operator once.
A.3 Implementation Details
experiments Section 5 performed using modified policy iteration modified PISF
(Appendices A.1 A.2, respectively). Instead fixing value t, iterative value function
computation interrupted according stop criterion described Putermans (1994) Proposition 6.6.5, = 106 . Policy iteration PISF run two successive policies
identical, shown Algorithms 1 2. matrices P modified policy iteration loaded
value function computation, since represents compromise memory usage
computational cost (see Appendix A.1). case PISF matrix K kept memory
times; matrices computed demand iteration algorithm.
statements Section 5 regarding algorithms computational requirements refer specific
implementation.

Acknowledgements
Part work done Andre Barreto postdoctoral fellow School Computer
Science McGill University. authors would like thank Amir-massoud Farahmand valid
discussions, also anonymous reviewers suggestions improve paper.
experiments run using computational resources made available Compute Canada Calcul
Quebec. Funding research provided Coordenacao de Aperfeicoamento de Pessoal
de Nvel Superior (CAPES), National Institutes Health (grant R21 DA019800), NSERC
Discovery Grant program, Projets de Recherche en Equipe (FQRNT).
797

fiBARRETO , P INEAU , & P RECUP

References
Arruda, E., & Fragoso, M. D. (2011). Time aggregated Markov decision processes via standard
dynamic programming. Operations Research Letters, 39(3), 25762580.
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multiarmed bandit
problem. Machine Learning, 47(2-3), 235256.
Baird, L. C. (1995). Residual algorithms: Reinforcement learning function approximation.
Proceedings International Conference Machine Learning (ICML), pp. 3037.
Barlow, R. E., & Proschan, F. (1965). Mathematical Theory Reliability. Wiley.
Barreto, A. M. S. (2014). Tree-based on-line reinforcement learning. Proceedings AAAI
Conference Artificial Intelligence.
Barreto, A. M. S., & Fragoso, M. D. (2011). Computing stationary distribution finite Markov
chain stochastic factorization. SIAM Journal Matrix Analysis Applications,
32, 15131523.
Barreto, A. M. S., Precup, D., & Pineau, J. (2011). Reinforcement learning using kernel-based
stochastic factorization. Advances Neural Information Processing Systems (NIPS), pp.
720728.
Bellman, R. E. (1957). Dynamic Programming. Princeton University Press.
Bellman, R. E. (1961). Adaptive Control Processes. Princeton University Press.
Bellman, R. E., & Dreyfus, S. (1959). Functional approximations dynamic programming. Mathematical Tables Aids Computation, 13(68), 247251.
Berry, M. W., Browne, M., Langville, A. N., Pauca, V. P., & Plemmons, R. J. (2007). Algorithms
applications approximate nonnegative matrix factorization. Computational Statistics
Data Analysis, 52(1), 155173.
Bertsekas, D. P. (1987). Dynamic programming: deterministic stochastic models. Prentice-Hall.
Bertsekas, D. P. (1999). Nonlinear Programming (2nd edition). Athena Scientific.
Bertsekas, D. P., & Castanon, D. A. (1989). Adaptive aggregation methods infinite horizon
dynamic programming. IEEE Transactions Automatic Control, 34(6), 589598.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.
Bittorf, V., Recht, B., Re, C., & Tropp, J. A. (2012). Factoring nonnegative matrices linear
programs. Advances Neural Information Processing Systems (NIPS), pp. 12141222.
Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction.
Proceedings International Joint Conferences Artificial Intelligence (IJCAI), pp.
11041113.
Boutsidis, C., Zouzias, A., & Drineas, P. (2010). Random projections k-means clustering.
Advances Neural Information Processing Systems (NIPS), pp. 298306.
Bouzy, B., & Helmstetter, B. (2003). Monte-Carlo Go developments. Advances Computer
Games, pp. 159174.
798

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

Boyan, J. A., & Moore, A. W. (1995). Generalization reinforcement learning: Safely approximating value function. Advances Neural Information Processing Systems (NIPS),
pp. 369376.
Bradtke, S. J., & Barto, A. G. (1996). Linear least-squares algorithms temporal difference
learning. Machine Learning, 22(1/2/3), 3357.
Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P. I., Rohlfshagen, P., Tavener, S.,
Perez, D., Samothrakis, S., & Colton, S. (2012). survey Monte Carlo tree search methods.
IEEE Transactions Computational Intelligence AI Games, 4, 143.
Chang, C.-I., Wu, C.-C., Liu, W., & Ouyang, Y. C. (2006). new growing method simplex-based
endmember extraction algorithm. IEEE Transactions Geoscience Remote Sensing,
44(10), 28042819.
Chaslot, G. M. J.-B., Winands, M. H. M., van den Herik, H. J., Uiterwijk, J. W. H. M., & Bouzy, B.
(2008). Progressive strategies Monte-Carlo tree search. New Mathematics Natural
Computation, 4, 343357.
Cho, D. I., & Parlar, M. (1991). survey maintenance models multi-unit systems. European
Journal Operational Research, 51(1), 123.
Cohen, J. E., & Rothblum, U. G. (1991). Nonnegative ranks, decompositions factorizations
nonnegative matrices. Linear Algebra Applications, 190, 149168.
Cutler, A. (1993). branch bound algorithm constrained least squares. Communications
StatisticsSimulation Computation, 22(2), 395321.
Cutler, A., & Breiman, L. (1994). Archetypal analysis. Technometrics, 36(4), 338347.
Dean, T., Givan, R., & Leach, S. (1997). Model reduction techniques computing approximately
optimal solutions Markov decision processes. Proceedings Conference Uncertainty Artificial Intelligence (UAI), pp. 124131.
Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation. Computational Intelligence, 5(2), 142150.
Dekker, R., Wildeman, R. E., & van Egmond, R. (1996). Joint replacement operational planning phase. European Journal Operational Research, 91(1), 7488.
Dekker, R., Wildeman, R. E., & van der Duyn Schouten, F. A. (1997). review multi-component
maintenance models economic dependence. Mathematical Methods Operations Research, 45, 411435.
Denardo, E. V. (1967). Contraction mappings theory underlying dynamic programming.
SIAM Review, 9(2), 165177.
Ding, C. H. Q., Li, T., & Jordan, M. I. (2010). Convex semi-nonnegative matrix factorizations.
IEEE Transactions Pattern Analysis Machine Intelligence, 32(1), 4555.
Esser, E., Mller, M., Osher, S., Sapiro, G., & Xin, J. (2012). convex model nonnegative matrix
factorization dimensionality reduction physical space. IEEE Transactions Image
Processing, 21(7), 32393252.
Ferns, N., Castro, P. S., Precup, D., & Panangaden, P. (2006). Methods computing state similarity
Markov decision processes. Proceedings Conference Uncertainty Artificial
Intelligence (UAI), pp. 174181.
799

fiBARRETO , P INEAU , & P RECUP

Friedman, J. H., Bentley, J. L., & Finkel, R. A. (1977). algorithm finding best matches
logarithmic expected time. ACM Transactions Mathematical Software, 3(3), 209226.
Gan, G., Ma, C., & Wu, J. (2007). Data Clustering: Theory, Algorithms, Applications. ASASIAM Series Statistics Applied Probability. SIAM.
Geffner, H., & Bonet, B. (2013). Concise Introduction Models Methods Automated
Planning. Synthesis Lectures Artificial Intelligence Machine Learning. Morgan &
Claypool Publishers.
Gelly, S., Kocsis, L., Schoenauer, M., Sebag, M., Silver, D., Szepesvari, C., & Teytaud, O. (2012).
grand challenge computer Go: Monte Carlo tree search extensions. Communications ACM, 55(3), 106113.
Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory & Practice. Morgan
Kaufmann Publishers Inc.
Givan, R., Dean, T., & Greig, M. (2003). Equivalence notions model minimization Markov
decision processes. Artificial Intelligence, 147(1-2), 163223.
Golub, G. H., & Loan, C. F. V. (1996). Matrix Computations (3rd edition). Johns Hopkins
University Press.
Gordon, G. J. (1995). Stable function approximation dynamic programming. Proceedings
International Conference Machine Learning (ICML), pp. 261268.
Grippo, L., & Sciandrone, M. (2000). convergence block nonlinear Gauss-Seidel
method convex constraints. Operations Research Letters, 26, 127136.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.
Hartigan, J. A. (1975). Clustering Algorithms. John Wiley Sons.
Hastie, T., Tibshirani, R., & Friedman, J. (2002). Elements Statistical Learning: Data Mining,
Inference, Prediction. Springer.
Haurie, A., & LEcuyer, P. (1982). stochastic control approach group preventive replacement
multicomponent system. IEEE Transactions Automatic Control, 27, 387393.
Ho, N.-D., & van Dooren, P. (2007). Non-negative matrix factorization fixed row column
sums. Linear Algebra Applications, 429(56), 10201025.
Hoey, J., St-Aubin, R., Hu, A. J., & Boutilier, C. (1999). SPUDD: Stochastic planning using decision
diagrams. Proceedings Conference Uncertainty Artificial Intelligence (UAI),
pp. 279288.
Howard, R. (1960). Dynamic Programming Markov Processes. MIT Press.
Kaufman, L., & Rousseeuw, P. J. (1990). Finding Groups Data: Introduction Cluster
Analysis. John Wiley Sons.
Keller, T., & Eyerich, P. (2012). PROST: Probabilistic planning based UCT. Proceedings
International Conference Automated Planning Scheduling.
Keshava, N. (2003). Survey Spectral Unmixing Algorithms. Lincoln Laboratory Journal,
14(1), 5578.
800

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

Keshava, N., & Mustard, J. (2002). Spectral unmixing. Signal Processing Magazine, 19, 4457.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. Proceedings
European Conference Machine Learning (ECML), pp. 282293.
Koller, D., & Parr, R. (1999). Computing factored value functions policies structured MDPs.
Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp.
13321339.
Kolobov, A., Mausam, & Weld, D. S. (2012). LRTDP versus UCT online probabilistic planning.
Proceedings AAAI Conference Artificial Intelligence.
Lagoudakis, M. G., & Parr, R. (2003). Least-squares policy iteration. Journal Machine Learning
Research, 4, 11071149.
Lee, D. D., & Seung, H. S. (1997). Unsupervised learning convex conic coding. Advances
Neural Information Processing Systems (NIPS), pp. 515521.
Lee, D. D., & Seung, H. S. (1999). Learning parts objects non-negative matrix factorization. Nature, 401, 788791.
Lee, D. D., & Seung, H. S. (2000). Algorithms nonnegative matrix factorization. Advances
Neural Information Processing Systems (NIPS), pp. 556562.
Li, L., Walsh, T. J., & Littman, M. L. (2006). Towards unified theory state abstraction MDPs.
Proceedings International Symposium Artificial Intelligence Mathematics,
pp. 531539.
Lin, C.-J. (2007a). convergence multiplicative update algorithms nonnegative matrix
factorization. IEEE Transactions Neural Networks, 18, 1589 1596.
Lin, C.-J. (2007b). Projected gradient methods nonnegative matrix factorization. Neural Computation, 19(10), 27562779.
Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solving Markov
decision problems. Proceedings Conference Uncertainty Artificial Intelligence
(UAI), pp. 394402.
Liu, T., Moore, A. W., Gray, A., & Yang, K. (2005). investigation practical approximate
nearest neighbor algorithms. Advances Neural Information Processing Systems (NIPS),
pp. 825832.
Mahoney, M. W. (2011). Randomized algorithms matrices data. Foundations Trends
Machine Learning, 3(2), 123224.
McCall, J. J. (1965). Maintenance policies stochastically failing equipment: survey. Management Science, 11, 493524.
Munos, R., & Moore, A. (1999). Barycentric interpolators continuous space & time reinforcement learning. Advances Neural Information Processing Systems (NIPS), pp. 1024
1030.
Nascimento, J. M. P., & Dias, J. M. B. (2004). Vertex component analysis: fast algorithm unmix
hyperspectral data. IEEE Transactions Geoscience Remote Sensing, 43, 898910.
Ormoneit, D., & Sen, S. (2002). Kernel-based reinforcement learning. Machine Learning, 49 (23),
161178.
801

fiBARRETO , P INEAU , & P RECUP

Ozekici, S. (1988). Optimal periodic replacement multicomponent reliability systems. Operations Research, 36, 542552.
Paatero, P., & Tapper, U. (1994). Positive matrix factorization: non-negative factor model
optimal utilization error estimates data values. Environmetrics, 5, 111126.
Perkins, T. J., & Precup, D. (2003). convergent form approximate policy iteration. Advances
Neural Information Processing Systems (NIPS), pp. 15951602.
Pierskalla, W. P., & Voelker, J. A. (1976). survey maintenance models: control surveillance deteriorating systems. Naval Research Logistics Quarterly, 23(3), 353388.
Powell, W. B. (2007). Approximate Dynamic ProgrammingSolving Curses Dimensionality.
John Wiley & Sons, Inc.
Puterman, M. L. (1994). Markov Decision ProcessesDiscrete Stochastic Dynamic Programming.
John Wiley & Sons, Inc.
Puterman, M. L., & Shin, M. (1978). Modified policy iteration algorithms discounted Markov
decision problems. Management Science, 24(11), 11271137.
Ravindran, B. (2004). Algebraic Approach Abstraction Reinforcement Learning. Ph.D.
thesis, University Massachusetts, Amherst, MA.
Ravindran, B., & Barto, A. G. (2004). Approximate homomorphisms: framework non-exact
minimization Markov decision processes. Proceedings International Conference
Knowledge Based Computer Systems.
Rust, J. (1997). Using randomization break curse dimensionality. Econometrica, 65(3),
487516.
Sanner, S. (2010). Relational dynamic influence diagram language (RDDL): Language description.
Schoknecht, R., & Merke, A. (2003). Convergent combinations reinforcement learning linear function approximation. Advances Neural Information Processing Systems (NIPS),
pp. 15791586.
Scholkopf, B., & Smola, A. (2002). Learning Kernels. MIT Press.
Sherif, Y. S., & Smith, M. L. (1981). Optimal maintenance models systems subject failurea
review. Naval Research Logistics Quarterly, 28(1), 4774.
Shindler, M., Wong, A., & Meyerson, A. W. (2011). Fast accurate k-means large datasets.
Advances Neural Information Processing Systems (NIPS), pp. 23752383.
Singh, S. P., Jaakkola, T., & Jordan, M. I. (1995). Reinforcement learning soft state aggregation. Advances Neural Information Processing Systems (NIPS), pp. 361368.
Sorg, J., & Singh, S. (2009). Transfer via soft homomorphisms. Autonomous Agents & Multiagent
Systems/Agent Theories, Architectures, Languages, pp. 741748.
Sun, T., Zhao, Q., & Luh, P. (2007). Incremental value iteration time-aggregated Markovdecision processes. IEEE Transactions Automatic Control, 52, 21772182.
Sutton, R. S., Szepesvari, C., & Maei, H. R. (2008). convergent O(n) algorithm off-policy
temporal-difference learning linear function approximation. Advances Neural Information Processing Systems (NIPS), pp. 16091616.
802

fiP OLICY TERATION BASED



TOCHASTIC FACTORIZATION

Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.
Sutton, R. S., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: framework
temporal abstraction reinforcement learning. Artificial Intelligence, 112, 181211.
Szepesvari, C., & Smart, W. D. (2004). Interpolation-based Q-learning. Proceedings
International Conference Machine Learning (ICML), pp. 791798.
Tadic, V. (2001). convergence temporal-difference learning linear function approximation. Machine Learning, 42(3), 241267.
Thrun, S., & Schwartz, A. (1993). Issues using function approximation reinforcement learning. Proceedings Fourth Connectionist Models Summer School, pp. 255263.
Thurau, C., Kersting, K., Wahabzada, M., & Bauckhage, C. (2011). Convex non-negative matrix
factorization massive datasets. Knowledge Information Systems, 29, 457478.
Thurau, C., Kersting, K., Wahabzada, M., & Bauckhage, C. (2012). Descriptive matrix factorization
sustainability adopting principle opposites. Data Mining Knowledge Discovery,
24(2), 325354.
Tsitsiklis, J. N., & Roy, B. V. (1996). Feature-based methods large scale dynamic programming.
Machine Learning, 22, 5994.
Tsitsiklis, J. N., & Roy, B. V. (1997). analysis temporal-difference learning function
approximation. IEEE Transactions Automatic Control, 42, 674690.
van der Duyn Schouten, F. A., & Vanneste, S. G. (1990). Analysis computation (n, n)strategies maintenance two-component system. European Journal Operational
Research, 48(2), 260274.
Vavasis, S. A. (2009). complexity nonnegative matrix factorization. SIAM Journal
Optimization, 20, 13641377.
Wang, H. (2002). survey maintenance policies deteriorating systems. European Journal
Operational Research, 139(3), 469 489.
White, D. J. (1985). Real applications Markov decision processes. Interfaces, 15, 7383.
White, D. J. (1988). real applications Markov decision processes. Interfaces, 18, 5561.
White, D. J. (1993). survey applications Markov decision processes. Journal
Operational Research Society, 44(11), 10731096.
Whitt, W. (1978). Approximations dynamic programs, I. Mathematics Operations Research,
3(3), 231243.
Xia, L., Zhao, Q., & Jia, Q.-S. (2008). structure property optimal policies maintenance
problems safety-critical components. IEEE Transactions Automation Science Engineering, 5(3), 519531.

803

fiJournal Artificial Intelligence Research 50 (2014) 697-722

Submitted 10/13; published 07/14

MDD Propagation Sequence Constraints
David Bergman

david.bergman@business.uconn.edu

School Business, University Connecticut
2100 Hillside Road, Unit 1041, Storrs, CT 06260

Andre A. Cire
Willem-Jan van Hoeve

acire@andrew.cmu.edu
vanhoeve@andrew.cmu.edu

Tepper School Business, Carnegie Mellon University
5000 Forbes Avenue, Pittsburgh, PA 15213 USA

Abstract
study propagation Sequence constraint context constraint programming based limited-width MDDs. first contribution proving establishing
MDD-consistency Sequence NP-hard. Yet, also show task fixed parameter tractable respect length sub-sequences. addition, propose
partial filtering algorithm relies specific decomposition constraint
novel extension MDD filtering node domains. experimentally evaluate performance proposed filtering algorithm, demonstrate strength
MDD propagation increases maximum width increased. particular, MDD propagation outperform conventional domain propagation Sequence reducing
search tree size solving time several orders magnitude. Similar improvements
observed respect current best MDD approach applies decomposition
Sequence Among constraints.

1. Introduction
central inference process constraint programming constraint propagation (Rossi,
van Beek, & Walsh, 2006; Dechter, 2003; Apt, 2003). traditional constraint processing
techniques designed explicitly defined relations small arity, state-of-the-art constraint programming solvers apply specialized constraint propagation algorithms global
constraints arity, often based efficient combinatorial methods network
flows (van Hoeve & Katriel, 2006; Regin, 2011).
Conventional constraint propagation algorithms (or domain filtering algorithms) operate individual constraints given problem. role identify remove
values variable domains inconsistent respect constraint
consideration. Whenever domain variable updated (i.e., value removed),
constraints variable appears reconsidered inspection.
cascading process propagating changes variable domains constraints
continues fixed point reached. constraint programming solvers assume
variable domains finite, ensures termination constraint propagation
process. Note constraint propagation may sufficient determine
resolution given problem. Therefore, constraint propagation normally applied
search state systematic search process.
c
2014
AI Access Foundation. rights reserved.

fiBergman, Cire & van Hoeve

major benefit propagating variable domains implemented efficiently
many cases. However, inherent weakness domain propagation implicitly
represents Cartesian product variable domains potential solution space.
communicating domain changes, limits amount information shared
constraints.
address shortcoming domain propagation, Andersen, Hadzic, Hooker,
Tiedemann (2007) proposed use multi-valued decision diagrams (MDDs) alternative variable domains context constraint propagation. MDDs directed
acyclic layered graphs can, principle, compactly represent solutions combinatorial problem (Wegener, 2000). Andersen et al. (2007) showed MDDs limited
width provide much stronger relaxation solution space traditional
Cartesian product variable domains, consequence MDDs allow represent
communicate refined information constraints. propagating MDDs
rather variable domains, huge reductions search tree size computation time
realized (Andersen et al., 2007; Hadzic, Hooker, OSullivan, & Tiedemann, 2008a;
Hadzic, Hooker, & Tiedemann, 2008b; Hadzic, OMahony, OSullivan, & Sellmann, 2009;
Hoda, van Hoeve, & Hooker, 2010; Cire & van Hoeve, 2012, 2013).
MDDs used represent individual (global) constraints, subsets constraints,
constraints given problem. representing individual constraints,
work Hawkins, Lagoon, Stuckey (2005) Cheng Yap (2008), higher-level
information carried MDD lost projecting variable domains
traditional domain propagation. highest potential MDD propagation instead
appears representing specific subsets constraints within MDD. is,
given set constraints, create maintain one single limited-width MDD,
propagated constraint set. Since MDD defined respect
fixed variable ordering, useful select subset constraints compatible
ordering. applied way, MDD propagation implemented parallel
existing domain propagation constraint programming systems, thus complementing
potentially strengthening domain propagation process. example, Cire van Hoeve
(2013) introduced MDD propagation subset constraints representing disjunctive
scheduling problems. embedded custom global constraint ILOG CP
Optimizer constraint programming solver, greatly improved performance.
1.1 Methodology
Constraint propagation based limited-width MDDs amounts MDD filtering MDD
refinement. role MDD filtering algorithm remove provably inconsistent arcs
MDD (Hadzic et al., 2008b; Hoda et al., 2010). MDD refinement algorithm
hand, aims splitting nodes MDD accurately reflect solution
space (Hadzic et al., 2008a). order make approach scalable efficient, refinement
algorithms must ensure MDD remains within given maximum size (typically
restricting maximum widththe number nodes layer). increasing
maximum width, MDD relaxation strengthened desired level.
is, maximum width 1 would correspond traditional Cartesian product
variable domains, infinite maximum width would correspond exact MDD
698

fiMDD Propagation Sequence Constraints

representing solutions. However, increasing size MDD immediately impacts
computation time, one typically needs balance trade-off strength
MDD associated computation time.
order characterize outcome MDD filtering algorithm, notion MDD
consistency introduced Andersen et al. (2007), similar domain consistency
finite-domain constraint programming: Given MDD, constraint MDD consistent
arcs MDD belong least one solution constraint. consequence
richer data structure MDD represents, establishing MDD consistency may
difficult establishing domain consistency. example, Andersen et al. show
establishing MDD consistency Alldifferent constraint NP-hard,
establishing traditional domain consistency done polynomial time (Regin, 1994).
1.2 Contributions
main focus paper Sequence constraint, defined specific conjunction Among constraints, Among constraint restricts occurrence
set values sequence variables within lower upper bound (Beldiceanu
& Contejean, 1994). Sequence constraint finds applications in, e.g., car sequencing
employee scheduling problems (Regin & Puget, 1997; van Hoeve, Pesant, Rousseau, &
Sabharwal, 2009). known classical domain consistency established Sequence polynomial time (van Hoeve, Pesant, Rousseau, & Sabharwal, 2006; van Hoeve
et al., 2009; Brand, Narodytska, Quimper, Stuckey, & Walsh, 2007; Maher, Narodytska,
Quimper, & Walsh, 2008; Downing, Feydy, & Stuckey, 2012). Furthermore, Hoda et al.
(2010) present MDD filtering algorithm Among constraints establishing MDD consistency polynomial time. However, remained open question whether MDD
consistency Sequence established polynomial time well.
work, answer question negatively first contribution showing
establishing MDD consistency Sequence constraint NP-hard.
important result perspective MDD-based constraint programming. Namely,
global constraints, Sequence constraint perhaps suitable combinatorial
structure MDD approach; prescribed variable ordering, combines subconstraints contiguous variables, existing approaches handle constraint
fully using bounds reasoning only.
second contribution, show establishing MDD consistency Sequence constraint fixed parameter tractable respect lengths subsequences (the Among constraints), provided MDD follows order Sequence constraint. proof constructive, follows generic algorithm filter
one MDD another.
third contribution partial MDD propagation algorithm Sequence,
necessarily establish MDD consistency. relies decomposition Sequence
cumulative sums, new extension MDD filtering information
stored nodes.
last contribution experimental evaluation proposed partial MDD propagation algorithm. evaluate strength algorithm MDDs various maximum
widths, compare performance existing domain propagators Sequence.
699

fiBergman, Cire & van Hoeve

also compare algorithm currently best known MDD approach uses
natural decomposition Sequence Among constraints (Hoda et al., 2010).
experiments demonstrate MDD propagation outperform domain propagation
Sequence reducing search tree size, solving time, several orders magnitude. Similar results observed respect MDD propagation Among constraints.
results thus provide evidence power MDD propagation context
constraint programming.
remainder paper structured follows. Section 2, provide necessary definitions MDD-based constraint programming Sequence constraint.
Section 3, present proof establishing MDD consistency Sequence NPhard. Section 4 describes establishing MDD consistency fixed parameter tractable.
Section 5, partial MDD filtering algorithm presented. Section 6 shows experimental results. present final conclusions Section 7.

2. Definitions
first recall basic definitions MDD-based constraint programming, following
work Andersen et al. (2007) Hoda et al. (2010). work, ordered Multivalued
Decision Diagram (MDD) directed acyclic graph whose nodes partitioned n + 1
(possibly empty) subsets layers L1 , . . . , Ln+1 , layers L1 , . . . , Ln correspond
respectively variables x1 , . . . , xn . L1 contains single root node r, Ln+1 contains
single terminal node t. node u MDD, let L (u) denote index
layer. MDD , width w(M ) maximum number nodes layer,
maxni=1 {|Li |}. MDD-based CP, MDDs typically given fixed maximum width.
arcs MDD directed upper lower layer; is, node
Li node Lj < j. purposes convenient assume
(without loss generality) arc connects two adjacent layers. arc
layer Li labeled element domain D(xi ) xi . arc a, refer
label represents `(a). notational convenience, also write `(u, v) instead
`((u, v)) arc (u, v). element D(xi ) appears label
arcs given node u Li . set A(u, v) arcs node u node v may
contain multiple arcs, denote label. Let (u) denote set arcs
comingfi node u. define size anfi MDD number arcs, i.e.,
|M | = fi{a | (u), u Li , = 2, . . . , n + 1}fi.
arc label v leaving node layer represents assignment xi = v.
path MDD r denoted arc labels v1 , . . . , vn path
identified solution (x1 , . . . , xn ) = (v1 , . . . , vn ). path v1 , . . . , vn feasible
given constraint C setting (x1 , . . . , xn ) = (v1 , . . . , vn ) satisfies C. Constraint C feasible
MDD MDD contains feasible path C.
constraint C called MDD consistent given MDD every arc MDD
lies feasible path. Thus MDD consistency achieved redundant arcs
(i.e., arcs feasible path) removed. also say MDD MDD
consistent respect C. Domain consistency C equivalent MDD consistency
MDD width one represents variable domains. is, equivalent
700

fiMDD Propagation Sequence Constraints

MDD consistency MDD layer Li contains single node si ,
A(si , si+1 ) = D(xi ) = 1, . . . , n.
Lastly, formally recall definitions Among (Beldiceanu & Contejean, 1994),
Sequence (Beldiceanu & Contejean, 1994), Gen-Sequence (van Hoeve et al., 2009)
constraints. Among constraint counts number variables assigned
value given set S, ensures number given lower upper
bound:
Definition 1 Let X set variables, l, u integer numbers 0 l u |X|,
xX D(x) subset domain values. define Among(X, l, u, S)
X
l
(x S) u.
xX

Note expression (x S) evaluated binary value, i.e., resulting 1 x
0 x
/ S. Sequence constraint conjunction given Among constraint
applied every sub-sequence length q sequence n variables:
Definition 2 Let X ordered set n variables, q, l, u integer numbers
0 q n, 0 l u q, xX D(x) subset domain values.
Sequence(X, q, l, u, S) =

nq+1
^

Among(si , l, u, S),

i=1

si represents sub-sequence xi , . . . , xi+q1 .
Finally, generalized Sequence constraint extends Sequence constraint allowing
Among constraints specified different lower upper bounds, subsequence length:
Definition 3 Let X ordered set n variables, k natural number, ~s, ~l, ~u vectors
length k si sub-sequence X, li , ui N, 0 li ui n = 1, 2, . . . , k,
xX D(x) subset domain values.
Gen-Sequence(X, ~s, ~l, ~u, S) =

k
^

Among(si , li , ui , S).

i=1

3. MDD Consistency Sequence NP-Hard
stated before, known non-trivial NP-hardness result global constraint
context MDD-based constraint programming Andersen et al. (2007)
Alldifferent constraint. challenge determining whether global constraint
made MDD consistent polynomial time must guaranteed
given MDD. is, addition combinatorics global constraint itself,
shape MDD adds another layer complexity establishing MDD consistency.
proving NP-hardness, particular difficulty making sure reduction, MDD
remains polynomial size. Sequence constraints, far unknown whether
polynomial-time MDD consistency algorithm exists. section answer question
negatively prove following result.
701

fiBergman, Cire & van Hoeve

Theorem 1 Establishing MDD consistency Sequence arbitrary MDD NPhard even MDD follows variable ordering Sequence constraint.
Proof. proof reduction 3-SAT, classical NP-complete problem (Garey
& Johnson, 1979). show instance 3-SAT satisfied
particular Sequence constraint particular MDD polynomial size solution.
Therefore, establishing MDD consistency Sequence arbitrary MDD least
hard 3-SAT.
Consider 3-SAT instance n variables x1 , . . . , xn , consisting clauses c1 , . . . , cm .
first construct MDD represents basic structure 3-SAT formula (see
Example 1 proof illustration). introduce binary variables yi,j i,j
representing literals xj xj per clause ci , = 1, . . . , j = 1, . . . , n (xj xj
may may exist ci ). order variables sequence , first index
clauses, index variables, yi,j , i,j clause ci variable
xj . is, = y1,1 , 1,1 , y1,2 , 1,2 ,. . . ,y1,n , 1,n , . . . , ym,1 , m,1 , . . . ,ym,n , m,n .
construct MDD layered graph, k-th layer corresponds k-th
variable sequence .
clause ci represented 2n consecutive layers corresponding yi,1 , . . . , i,n .
part MDD, identify precisely paths lead solution satisfying
clause. basis diamond structure pair literals (yi,j , i,j ),
assigns either (0, 1) (1, 0) pair. variable appear clause,
represent using diamond part MDD representing clause, thus
ensuring variable take assignment respect clause.
variables appear clause, explicitly list allowed combinations.
precisely, clause ci , first define local root node ri representing layer L (yi,1 ),
set tag(ri ) = unsat. node u layer L (yi,j ) (for j = 1, . . . , n),
following. variable xj appear ci , tag(u) sat, create two nodes v, v 0
L i,j , one single node w L (yi,j+1 ), arcs (u, v) label 1, (u, v 0 ) label 0,
(v, w) label 0, (v 0 , w) label 1. corresponds diamond structure.
set tag(w) = tag(u). Otherwise (i.e., tag(u) unsat yi,j appears ci ), create
two nodes v, v 0 L i,j , two nodes w, w0 L (yi,j+1 ), arcs (u, v) label 1, (u, v 0 )
label 0, (v, w) label 0, (v 0 , w0 ) label 1. ci contains literal yi,j , set
tag(w) = sat tag(w0 ) = unsat. Otherwise (ci contains i,j ), set tag(w) = unsat
tag(w0 ) = sat.
procedure initialized single root node r representing L (y11 ).
iteratively append MDDs two consecutive clauses ci ci+1 merging nodes
last layer ci marked sat single node, let node
local root ci+1 . finalize procedure merging nodes last layer
marked sat single terminal node t. construction, ensure one
yij ij set 1. Furthermore, variable assignment corresponding
path layers L (yi,1 ) L (yi+1,1 ) satisfy clause ci , exactly n literals
chosen accordingly path.
next need ensure feasible path MDD, variable xj
correspond literal yi,j i,j clause ci . end, impose
702

fiMDD Propagation Sequence Constraints

r
c1

:0
:1

y1,1

y1,1
y1,2
y1,2
y1,3
y1,3
y1,4
y1,4
c2

y2,1

y2,1
y2,2
y2,2
y2,3
y2,3
y2,4
y2,4


Figure 1: MDD corresponding Example 1.
constraint
Sequence(Y, q = 2n, l = n, u = n, = {1})

(1)

MDD described above. sub-sequence length 2n starts positive
literal yi,j , definition exactly n variables take value 1. sub-sequence
starts negative literal i,j instead, last variable sequence corresponds
value xj next clause ci+1 , i.e., yi+1,j . Observe variables except
first last sequence take value 1 already n 1 times. Therefore,
first last variable sequence (which represent xj complement xj
order), one take value 1. is, xj must take value clause ci
ci+1 . Since holds sub-sequences, variables xj must take value
clauses.
MDD contains 2mn + 1 layers, layer contains six nodes.
Therefore, polynomial size (in size 3-SAT instance), overall construction needs polynomial time.

703

fiBergman, Cire & van Hoeve

:0
:1

x1
0

1

x2
00

01

10

11

00

01

10

11

00

01

10

11

00

01

10

11

x3

x4

x5

x6

Figure 2: exact MDD Sequence constraint Example 2.

Example 1 Consider 3-SAT instance four Boolean variables x1 , x2 , x3 , x4 clauses
c1 = (x1 x3 x4 ) c2 = (x2 x3 x4 ). corresponding MDD used reduction
given Figure 1.

4. MDD Consistency Sequence Fixed Parameter Tractable
section show establishing MDD consistency Sequence arbitrary
MDD fixed parameter tractable, respect length sub-sequences q.
already shown van Hoeve et al. (2006, 2009) exact MDD Sequence
constraint exists O(n2q ) nodes (i.e., unfolded automaton Regular constraint), illustrated next example.
Example 2 Consider constraint Sequence(X, q = 3, l = 1, u = 2, = {1})
X = {x1 , x2 , . . . , x6 } ordered set binary variables. corresponding exact MDD,
following order X, presented Figure 2. convenience, node MDD
labeled last q 1 labels represent sub-sequence node (starting
q 1 layers up). example, second node third layer represents decisions x1 = 0
x2 = 1, corresponding sub-sequence 01. construct next layer, either append
0 1 sub-sequence (and remove first symbol), leading nodes labeled 10
11, respectively. Note nodes labeled 00 must take arc label 1,
l = 1. Similarly nodes labeled 11 must take arc label 0, u = 2. q
704

fiMDD Propagation Sequence Constraints

layers, possible sub-sequences created (maximally O(2q1 )), thus defines
width subsequent layers.
However, since given arbitrary MDD, necessarily exact MDD, need
additional steps exploit connection. apply generic approach
show fixed parameter tractability Sequence, fact applied
determine whether MDD consistency tractable constraint.
goal establish MDD consistency given MDD respect another
MDD 0 set variables. compatible earlier definitions since
0 interpreted define constraint. is, MDD consistent respect
0 every arc belongs path (solution) also exists 0 . purposes,
assume 0 follow variable ordering.
establish MDD consistency first taking intersection 0 ,
removing arcs compatible intersection. Computing
intersection two MDDs well-studied, present top-down intersection algorithm
follows definitions Algorithm 1. description adapted melding
procedure presented Knuth (2009).
intersection MDD, denoted I, represents possible paths (solutions)
present 0 . partial path root rI node u thus
exist 0 , respective endpoints v, v 0 . information captured
associating node u state s(u) = (v, v 0 ) representing nodes v
v 0 0 . root initialized rI s(rI ) := (r, r0 ) r r0
respective roots 0 (lines 1-2). algorithm then, top-down traversal,
considers layer LIi I, augments node u LIi s(u) = (v, v 0 ) arc
0 arc label v v 0 respectively (lines
5-7). next layer already contains node u state re-use node.
Otherwise add new node u LIi+1 add arc (u, u) I. Note last layer
contains single terminal tI state s(tI ) = (t, t0 ), provided empty.
last step (line 14) clean removing arcs nodes belong
feasible path. done bottom-up traversal I. Observe algorithm
necessarily create reduced MDD.
Algorithm 2 presents algorithm establish MDD-consistency respect
0
. first compute intersection 0 (line 1). traverse
top-down traversal, layer LM
identify remove infeasible arcs. this,
define Boolean array Support[u, l] (initialized 0) represents whether arc
node u label l support (line 3). line 4, consider arcs
layer LIi I. arc = (v, v) exists LIi label l s(v) = (u, u0 ), mark
associated arc u supported setting Support[u, l] := 1 (lines 4-6).
remove arcs LM
support (lines 7-9). Lastly, clean
removing arcs nodes belong feasible path (line 11).
Theorem 2 Algorithm 2 establishes MDD-consistency respect 0 O(|M |
w(M 0 ) time space.
Proof. correctness Algorithm 1 follows induction number layers.
prove Algorithm 2 establishes MDD-consistency, consider arc = (u, u)
705

fiBergman, Cire & van Hoeve

Algorithm 1 Intersection(M ,M 0 )
Input: MDD root r, MDD 0 root r0 . 0 defined
ordered sequence n variables.
Output: MDD layers LI1 , . . . , LIn+1 arc set AI . node u
associated state s(u).
1: create node r state s(r ) := (r, r 0 )
2: LI1 := {r }
3: = 1 n
4:
LIi+1 := {}
5:
u LIi s(u) = (v, v 0 )
6:
= (v, v) a0 = (v 0 , v 0 ) 0 `(a) = `(a0 )
7:
create node u state s(u) := (v, v 0 )
8:
w LIj+1 s(w) = s(u) u := w
9:
else LIi+1 += u end
10:
add arc (u, u) label `(a) arc set AI
11:
end
12:
end
13: end
14: remove arcs nodes path r tI LIn+1
15: return

Algorithm 2 MDD-Consistency(M ,M 0 )
Input: MDD root r, MDD 0 root r0 . 0 defined
ordered sequence n variables.
Output: MDD-consistent respect 0
1: create := Intersection(M ,M 0 )
2: = 1 n
3:
create array Support[u, l] := 0 u LM
arcs u label l
4:
arcs = (v, v) AI s(v) = (u, u0 ) v LIi
5:
Support[u, `(a)] := 1
6:
end
7:
arcs = (u, u) u LM

8:
Support[u, `(a)] = 0 remove end
9:
end
10: end
11: remove arcs nodes path r LM
n+1
12: return

706

fiMDD Propagation Sequence Constraints

applying algorithm. exists node v s(v) = (u, u0 ) solutions
represented paths r u r0 u0 0 equivalent.
also exists arc aI = (v, v) AI label a. Consider s(v) = (w, w0 ). Since
decision diagrams, label appears arc node.
Therefore, w = u. Since aI belongs I, exist paths w (or u)
w0 t0 0 equivalent. Hence, belongs feasible path (from r
u, along u terminating t) equivalent path exists 0
(from r0 u0 , w0 terminating t0 ).
Regarding time complexity computing intersection, coarse upper bound
multiplies n (line 3), w(M ) w(M 0 ) (line 5), d2max (line 6), dmax represents
maximum degree node, maxxX |D(x)|. amortize steps since forloops lines 3 6 consider arc comparison arcs 0 . arc
compared w(M 0 ) arcs (line 6); assume check constant
time whether node outgoing arc given label (using arc-label list).
gives total time complexity O(|M | w(M 0 )). memory requirements bounded
size intersection, O(n w(M ) w(M 0 ) dmax ) = O(|M | w(M 0 )).
dominates complexity Algorithm 2, since lines 2-12 performed linear
time space (in size ).

Observe Algorithm 2 longer ensures solution represented
path 0 , case intersection. MDD-consistency merely establishes
arc belongs solution also 0 . Although MDD intersections
stronger MDD consistency, limitation width intersection
MDD may large product widths 0 . Therefore intersecting
multiple MDDs will, general, increase size resulting MDD exponentially.
next apply Theorem 2 Sequence constraint.
Corollary 1 Let X ordered sequence variables, C = Sequence(X, q, l, u, S)
sequence constraint, arbitrary MDD following variable ordering X. Establishing MDD consistency C fixed parameter tractable respect parameter q.
Proof. know exists exact MDD 0 size O(n2q1 ) represents C
(van Hoeve et al., 2006, 2009). Applying Theorem 2 gives MDD-consistency algorithm
time space complexity O(|M | 2q1 ), result follows.

note Theorem 2 also applied obtain tractability establishing
MDD consistency constraints. Consider example constraint Among(x1 , x2 ,
. . . , xn , l, u, S). variable ordering, construct exact MDD top-down
procedure associating node v number variables taking value along
path r v, representing length path. Nodes length
equivalent merged. largest layer u + 1 different path
lengths, exact MDD size O(nu), Theorem 2 establishing MDD consistency
tractable Among. Indeed, Hoda et al. (2010) also showed MDD consistency
established constraint, quadratic time complexity.
707

fiBergman, Cire & van Hoeve

converse Theorem 2 hold: exist constraints MDD
consistency established polynomial time given MDD, minimal
reduced exact MDD hasP
exponential size. specific example, consider linear inequality
constraints form ni=1 ai xi b xi integer variable, ai constant,
= 1, . . . , n, b constant. MDD consistency established constraints
linear time, given MDD, computing arc longest r-t path (relative
coefficients ai ) uses arc (Andersen et al., 2007). However, Hosaka, Takenaga,
Kaneda, Yajima (1997)
provide following explicit linear inequality. k even
P
n = k 2 , consider 1i,jk aij xij k(22k 1)/2, xij binary variable,
aij = 2i1 + 2k+j1 , 1 i, j k. show that, variable order,
size

n/2
reduced ordered BDD inequality bounded (2
).

5. Partial MDD Filtering Sequence
many practical situations value q lead prohibitively large exact MDDs
establishing MDD consistency, limits applicability Corollary 1. Therefore
next explore practical partial filtering algorithm polynomial also q.
One immediate approach propagate Sequence constraint MDDs
natural decomposition Among constraints, apply MDD filtering algorithms
Among proposed Hoda et al. (2010). However, well-known classical
constraint propagation based variable domains, Among decomposition substantially improved dedicated domain filtering algorithm Sequence (van Hoeve
et al., 2006, 2009; Brand et al., 2007; Maher et al., 2008). Therefore, goal section provide MDD filtering Sequence stronger practice MDD
filtering Among decomposition, stronger domain filtering Sequence.
follows, assume MDD hand respects ordering variables
Sequence constraint.
5.1 Cumulative Sums Encoding
proposed algorithm extends original domain consistency filtering algorithm
Sequence van Hoeve et al. (2006) MDDs, following cumulative sums encoding proposed Brand et al. (2007). representation takes following form.
sequence variables X = x1 , x2 , . . . , xn , constraint Sequence(X, q, l, u, S),
first introduce variables y0 , y1 , . . . , yn , respective initial domains D(yi ) = [0, i]

Pi = 1, . . . , n. variables represent cumulative sums X, i.e., yi represents
j=1 (xj S) = 1, . . . , n. rewrite Sequence constraint following
system constraints:
{1, . . . , n},

(2)

yi+q yi l

{0, . . . , n q},

(3)

yi+q yi u

{0, . . . , n q},

(4)

yi = yi1 + (xi )

: X {0, 1} indicator function set S, i.e., (x) = 1 x
(x) = 0 x
/ S. Brand et al. show establishing singleton bounds consistency
system suffices establish domain consistency original Sequence constraint.
708

fiMDD Propagation Sequence Constraints

order apply similar reasoning context MDDs, crucial observation
domains variables y0 , . . . , yn naturally represented nodes
MDD. words, node v layer Li represents domain yi1 , restricted
solution space formed r-t paths containing v. Let us denote information
node v explicitly interval [lb(v), ub(v)], refer node domain
v. Following approach Hoda et al. (2010), compute information linear
time one top-down pass, using equation (2), follows:
lb(v) = min(u,v)Ain (v) {lb(u) + (`(u, v))} ,
ub(v) = max(u,v)Ain (v) {ub(u) + (`(u, v))} ,

(5)

nodes v 6= r, [lb(r), ub(r)] = [0, 0].
individual Among constraints posted yi+q yi l yi+q yi u,
also need compute node v layer Li+1 ancestors layer Li .
done maintaining vector Av length q + 1 node v, Av [i] represents
set ancestor nodes v i-th layer v, = 0, . . . , q. initialize
Ar = [{r}, , . . . , ], apply recursion
Av [i] = (u,v)Ain (v) Au [i 1]

= 1, 2, . . . , q,

Av [0] = {v}.
resulting top-down pass takes linear time (in size MDD), direct
implementation recursive step node takes O(q (w(M ))2 ) operations
MDD . Now, relevant ancestor nodes node v layer Li+q stored Av [q],
subset layer Li . similarly compute descendant nodes v vector Dv
length q + 1, Dv [i] contains descendants v i-th layer v,
= 0, 1, . . . , q. initialize Dt = [{t}, , . . . , ].
However, purposes need maintain minimum maximum value
union domains Av , resp., Dv , constraints (3) (4) inequalities;
see application Av Dv rules (8) below. makes recursive step
efficient, taking O(qw(M )) operations per node.
Alternatively, approximate information maintaining minimum
maximum node domain value layer, instead list ancestor layers.
compromise filtering, may efficient practice, requires
maintain two integers per layer.
5.2 Processing Constraints
next process constraints (2), (3), (4) turn remove provably inconsistent arcs, time filter node information.
Starting ternary constraints type (2), remove arc (u, v) lb(u) +
(`(u, v)) > ub(v). Updating [lb(v), ub(v)] node v done similar rules (5)
above:


lb(v) = max lb(v), min(u,v)Ain (v) {lb(u) + (`(u, v))} ,
(6)


ub(v) = min ub(v), min(u,v)Ain (v) {ub(u) + (`(u, v))} ,
709

fiBergman, Cire & van Hoeve

:0
:1

y0

[0,0

[0,0]

x1

x1
[0,0]

[0,0]

[1,1]

y1

[1,1]

x2

x2
[0,0]

[2,2]

[1,1]

[0,0]

[2,2]

[1,1]

y2
x3

x3
[1,1]

[0,2]

[2,3]

[1,1]

[2,2]

[2,2]

y3
x4

x4
[1,1]

[0,2]

[1,4]

[1,1]

[2,2]

[3,3]

y4
x5

x5
[2,4]

[0,5]

a. Initial MDD

b. Node domains

y5

c. MDD filtering

Figure 3: MDD propagation constraint Sequence(X, q = 3, l = 1, u = 2, = {1})
Example 3.

fact, resulting algorithm special case MDD consistency equality propagator Hadzic et al. (2008a), thus inherit MDD consistency ternary
constraints.
Next, process constraints (3) (4) node v layer Li+1 (i = 0, . . . , n).
Recall relevant ancestors Li+1q Av [q], relevant descendants
Li+1+q Dv [q]. variable corresponding node v yi , participates
four constraints:
yi l + yiq ,
yi u + yiq ,
(7)
yi yi+q l,
yi yi+q u.
Observe apply constraints filter node domain [lb(v), ub(v)]
corresponding yi . Namely, node domains corresponding variables yiq
yi+q may find support nodes layer Li+1 v. update lb(v)
ub(v) according equations (7):
lb(v) = max{ lb(v),

l + min lb(u),
uAv [q]

ub(v) = min{ ub(v), u + max ub(u),
uAv [q]

min lb(w) u },
wDv [q]

max ub(w) l }.

(8)

wDv [q]

resulting algorithm specific instance generic MDD consistent binary
constraint propagator presented Hoda et al. (2010), inherit MDD
consistency constraints. process constraints linear time (in size
MDD) top-down bottom-up pass MDD.
710

fiMDD Propagation Sequence Constraints

Example 3 Consider constraint Sequence(X, q = 3, l = 1, u = 2, = {1})
ordered sequence binary variables X = {x1 , x2 , x3 , x4 , x5 }. Assume given
MDD Figure 3.a. Figure 3.b. show node domains result processing
rules (5). Figure 3.c. shows resulting MDD processing constraints via
rules (6) (8). example, consider middle node fourth layer, corresponding
variable y3 . Let node v. initial domain [0, 2], Av [q] contains
root node, domain [0, 0]. Since l = 1, reduce domain v [1, 2].
next consider arcs v, conclude value 1 domain supported.
reduces domain v [2, 2], allows us eliminate one incoming arc
(from first node previous layer).
resulting MDD Figure 3.c. reflects possible deductions made
partial algorithm. established MDD consistency however, witnessed
infeasible path (1, 1, 0, 0, 0).
Observe proposed algorithm applied immediately general
Gen-Sequence constraints Among constraint individual l, u q.
cumulative sums encoding adjusted straightforward manner represent
different values.
5.3 Formal Analysis
next formally compare outcome partial MDD filtering algorithm MDD
propagation Among encoding domain propagation Sequence. First,
recall following theorem.
Theorem 3 (Brand et al., 2007, Thm. 4) Bounds consistency cumulative sums
encoding incomparable bounds consistency Among encoding Sequence.
Note since variable domains Among cumulative sums encoding
ranges (intervals integer values), bounds consistency equivalent domain consistency.
Corollary 2 MDD consistency cumulative sums encoding incomparable MDD
consistency Among encoding Sequence.
Proof. apply examples proof Theorem 4 work Brand et al..
Consider constraint Sequence(X, q = 2, l = 1, u = 2, = {1}) ordered
sequence binary variables X = {x1 , x2 , x3 , x4 } domains D(xi ) = {0, 1} =
1, 2, 4, D(x3 ) = {0}. apply trivial MDD width 1 representing Cartesian
product variable domains. Establishing MDD consistency cumulative sums
encoding yields
y0 [0, 0], y1 [0, 1], y2 [1, 2], y3 [1, 2], y4 [2, 3],
x1 {0, 1}, x2 {0, 1}, x3 {0}, x4 {0, 1}.
Establishing MDD consistency Among encoding, however, yields
x1 {0, 1}, x2 {1}, x3 {0}, x4 {1}.
711

fiBergman, Cire & van Hoeve

Consider constraint Sequence(X, q = 3, l = 1, u = 1, = {1}) ordered
sequence binary variables X = {x1 , x2 , x3 , x4 } domains D(xi ) = {0, 1} =
2, 3, 4, D(x1 ) = {0}. Again, apply MDD width 1 representing Cartesian
product variable domains. Establishing MDD consistency cumulative sums
encoding yields
y0 [0, 0], y1 [0, 0], y2 [0, 1], y3 [1, 1], y4 [1, 1],
x1 {0}, x2 {0, 1}, x3 {0, 1}, x4 {0},
establishing MDD consistency Among encoding prune value.
additional illustration Corollary 2, consider Example 3 Figure 3. MDD
propagation Among encoding eliminate value x4 = 0 infeasible
path (1, 1, 0, 0, 0), whereas example showed MDD propagation cumulative sums
detect this.
Theorem 4 MDD consistency cumulative sums encoding Sequence incomparable domain consistency Sequence.
Proof. first example proof Corollary 2 also shows domain consistency
Sequence stronger MDD consistency cumulative sums encoding.
show opposite, consider constraint Sequence(X, q, l, u, = {1}) set
binary variables arbitrary size, arbitrary values q, l, u = |X| 1. Let
MDD defined X consisting two disjoint paths r t: arcs one path
label 0, arcs value 1. Since projection onto
variable domains gives x {0, 1} x X, domain consistency deduce
infeasibility. However, establishing MDD consistency respect cumulative
sums encoding detect this.

Even though formally MDD propagation based cumulative sums incomparable
domain propagation Sequence MDD propagation Among constraints,
next section show practice algorithm reduce search space
orders magnitude compared methods.

6. Computational Results
purpose computational results evaluate empirically strength partial MDD propagator described Section 5. perform three main comparisons. First,
want assess impact increasing maximum width MDD filtering.
Second, want compare MDD propagation classical domain propagation
Sequence. particular, wish evaluate computational overhead MDD
propagation relative domain propagation, extent MDD propagation
outperform domain propagation. Third, compare filtering strength MDD
propagator Sequence filtering strength MDD propagators individual Among constraints, best MDD approach Sequence far (Hoda et al.,
2010).
712

fiMDD Propagation Sequence Constraints

implemented MDD propagator Sequence custom global constraint
IBM ILOG CPLEX CP Optimizer 12.4, using C++ interface. Recall Section 5
applying rules (8) either maintain minimum maximum value q
previous ancestors descendants node, approximate maintaining
values simply layer. evaluated strategies found latter
reduce amount filtering, nonetheless resulted much efficient performance
(about twice fast average). Hence, reported results use implementation.
MDD propagator Among, apply code (Hoda et al., 2010).
domain propagation, applied three models. first uses domain consistent propagator Sequence van Hoeve et al. (2009), running O(n3 ) time. second uses
domain consistent propagator Sequence based network flow representation
Maher et al. (2008), runs O(n2 ) time.1 third model, applied decomposition cumulative sums, uses explicit global constraint Sequence.
Propagating decomposition also takes O(n2 ) worst case, considers O(n) variables constraints variable domains contain n elements. note
almost test instances, cumulative sums encoding established domain consistency
Sequence. additional advantage, cumulative sums encoding permits
insightful comparison MDD propagator, since based cumulative
sums decomposition.
note Brand et al. (2007) introduce multiple-Sequence constraint
represents conjunction multiple Sequence constraints set ordered
variables (as experimental setup). Narodytska (2011) shows establishing bounds
consistency system already NP-hard, presents domain consistent propagator
encodes system automaton Regular constraint. algorithm runs
O(nmq ) time, n represents number variables, number Sequence
constraints, q length largest subsequence.
order compare algorithms multiple-Sequence constraint, conducted experiments identify suitable testbed. found instances
multiple-Sequence constraint would run memory could solved instantly
using domain propagator individual Sequence constraints, creating
data structures multiple-Sequence constraint took substantially time average. instances challenging (as described next sections),
multiple-Sequence constraint could applied due memory issues. therefore
excluded algorithm comparisons sections below.
single Sequence constraints solved polynomial time, consider
instances multiple Sequence constraints experiments. assume
defined ordered set variables. measure impact different
propagation methods correctly, approaches apply fixed search strategy, i.e.,
following given ordering variables, lexicographic value ordering heuristic.
method, measure number backtracks failed search state well
solving time. experiments performed using 2.33GHz Intel Xeon machine.
1. thank Nina Narodytska sharing implementation us.

713

fiBergman, Cire & van Hoeve

6.1 Systems Sequence Constraints
first consider systems multiple Sequence constraints defined set
variables. generate instances n = 50 variables domain {0, 1, . . . , 10},
5 Sequence constraints. Sequence constraint, set length subsequence uniform randomly [5, n/2)
q = (rand()%((n/2) 5)) + 5.
Here, rand() refers standard C++ random number generator, i.e., rand()%k selects
number range [0, k 1]. Without minimum length 5, many instances
would easy solve either method. next define difference l
u := (rand()%q), set
l := (rand()%(q )),
u := l + .
Lastly, define set values first defining cardinality (rand()%11) + 1,
selecting many values uniformly random {0, 1, . . . , 10}. generated 250
instances total.2
solve instance using domain consistency propagator Sequence,
cumulative sums encoding (domain propagation), MDD propagator maximum
widths 2, 4, 8, 16, 32, 64, 128. method given maximum time limit 1,800 seconds
per instance.
compare performance domain propagation MDD propagation Figure 4. figure, report given time point many instances could
solved within time specific method. three domain propagation methods
represented Cumulative Sums (the cumulative sums decomposition), Sequence - HPRS
(the Sequence propagator van Hoeve et al., 2006, 2009), Sequence - Flow (the
flow-based propagator Maher et al., 2008). Observe cumulative sums domain
propagation, although guaranteed establish domain consistency, outperforms
domain consistent Sequence propagators. Also, MDD propagation maximum width
2 already substantially outperform domain propagation. observe
larger maximum widths require time MDDs processed, end
allow solve instances: maximum MDD width 128 permits solve 250
instances within given time limit, whereas domain propagation respectively solve
220 (Sequence - Flow), 230 (Sequence - HPRS), 232 (Cumulative Sums) instances.
illustrate difference domain MDD propagation detail, Figure 5 presents scatter plots comparing domain propagation (cumulative sums) MDD
propagation (maximum width 32). comparison particularly meaningful
propagation methods rely cumulative sums representation. instance,
Figure 5.a depicts number backtracks Figure 5.b depicts solving time
methods. instances solved within time limit collected
(time out) method. Figure 5.a demonstrates MDD propagation lead
dramatic search tree reductions, several orders magnitude. Naturally, MDD
2. instances available http://www.andrew.cmu.edu/user/vanhoeve/mdd/.

714

fi200
150
100

MDD Width 128
MDD Width 32
MDD Width 2
Domain (Cumulative Sums)
Domain (Sequence HPRS)
Domain (Sequence Flow)

0

50

Number instances solved

250

MDD Propagation Sequence Constraints

102

101

100

101

102

103

Time(s)

Figure 4: Performance comparison domain MDD propagators Sequence
constraint. data point reflects total number instances solved
particular method within corresponding time limit.

propagation comes computational cost, Figure 5.b shows almost instances (especially harder ones), search tree reductions correspond faster solving
times, often several orders magnitude.
next evaluate impact increasing maximum widths MDD propagator.
Figure 6, present method survival function respect number
backtracks (a.) solving time (b.). Formally, applied combinatorial backtrack search algorithms, survival function represents probability run taking
x backtracks (Gomes, Fernandez, Selman, & Bessiere, 2005). case,
approximate function taking proportion instances need least x backtracks (Figure 6.a), respectively seconds (Figure 6.b). Observe log-log plots.
respect search tree size, Figure 6.a clearly shows strengthening MDD
propagation maximum width increased. particular, domain propagation
reflects linear behavior several orders magnitude typical heavy-tailed
runtime distributions. Naturally, similar behavior present MDD propagation,
much weaker form increasing maximum MDD widths. associated solving times
presented Figure 6.b. reflects similar behavior, also takes account
initial computational overhead MDD propagation.
715

fi102
101
100
102

101

MDD Propagator (Width 32) Time (s)

106
104
102
100

MDD Propagator (Width 32) Backtracks



103

Bergman, Cire & van Hoeve

100

102

104

106

102



101

100

101

102

103

Domain Propagator (Cumulative Sums) Time (s)

Domain Propagator (Cumulative Sums) Backtracks

b. Solving time

a. Number backtracks

Figure 5: Comparing domain MDD propagation Sequence constraints. data
point reflects number backtracks (a.) resp. solving time seconds (b.)
specific instance, solved best domain propagator (cumulative
sums encoding) MDD propagator maximum width 32. Instances
either method needed 0 backtracks (a.) less 0.01 seconds (b.)
excluded. Here, stands timeout represents specific instance
could solved within 1,800s (Fig. b.). Figure a., instances
labeled separately (at tick-mark 108 ); note reported number
backtracks 1,800 seconds may much less 108 instances.
reported instances fewer 108 backtracks solved within time
limit.

6.2 Nurse Rostering Instances
next consider structured problem class inspired nurse rostering problems.
problem design work schedule nurse given horizon n days.
day, nurse either work day shift (D), evening shift (E), night shift (N),
day (O). introduce variable xi day = 1, . . . , n, domain
D(xi ) = {O, D, E, N } representing shift. impose eight Sequence constraints
modeling requirements listed Table 1.
combinatorial nature problem, size CP search tree turns
largely independent length time horizon, lexicographic search (by
increasing day i) applied. however consider instances various time horizons
(n = 40, 60, 80, 100), address potential scaling issues.
results presented Table 2. columns Domain Sequence show total
number backtracks (BT) solving time seconds (CPU) domain consistent
Sequence propagator. Similarly, columns Domain Cumul. Sums show infor716

fiMDD Propagation Sequence Constraints

1.0
0.5
0.1
0.05

Survival function

0.1

Domain Consistency
MDD Width 2
MDD Width 4
MDD Width 8
MDD Width 16
MDD Width 32
MDD Width 64
MDD Width 128

0.005 0.01

0.05
0.005 0.01

Survival function

0.5

1.0

Domain Consistency
MDD Width 2
MDD Width 4
MDD Width 8
MDD Width 16
MDD Width 32
MDD Width 64
MDD Width 128

100

101

102

103

104

105

106

107

102

Backtracks

101

100

101

102

103

Time (s)

a. Survival function respect backtracks

b. Survival function respect solving time

Figure 6: Evaluating impact increased width MDD propagation via survival function plots respect search backtracks (a.) solving time (b.). plots
log-log scale. data point reflects percentage instances require least many backtracks (a.) resp. seconds (b.) solved
particular method.

Requirement

Sequence(X, q, l, u, S)

least 20 work shifts every 28 days:
least 4 off-days every 14 days:
1 4 night shifts every 14 days:
4 8 evening shifts every 14 days:
Nights shifts cannot appear consecutive days:
2 4 evening/night shifts every 7 days:
6 work shifts every 7 days:

Sequence(X, 28, 20, 28, {D, E, N })
Sequence(X, 14, 4, 14, {O})
Sequence(X, 14, 1, 4, {N })
Sequence(X, 14, 4, 8, {E})
Sequence(X, 2, 0, 1, {N })
Sequence(X, 7, 2, 4, {E, N })
Sequence(X, 7, 0, 6, {D, E, N })

Table 1: Nurse rostering problem specification. Variable set X represents shifts
assigned sequence days. possible shifts day (D), evening (E),
night (N), day (O).

mation cumulative sums domain propagation. subsequent columns show
numbers MDD propagator, MDDs maximum width 1, 2, 4, 8. Note
propagating MDD width 1 corresponds domain propagation, indeed associated number backtracks equivalent domain propagator cumulative sums.
first observation, maximum width 2 already reduces number backtracks
factor 8.3. maximum width 8 MDD propagation even allows solve
717

fiBergman, Cire & van Hoeve

n
40
60
80
100

Domain
Sequence
BT
CPU
438,059 43.83
438,059 78.26
438,059 124.81
438,059 157.75

Domain
Cumul. Sums
BT
CPU
438,059
438,059
438,059
438,059

32.26
53.40
71.33
96.27

MDD
Width 1
BT
CPU
438,059 54.27
438,059 80.36
438,059 106.81
438,059 135.37

MDD
Width 2
BT
CPU
52,443
52,443
52,443
52,443

12.92
18.36
28.58
37.76

MDD
Width 4
BT CPU
439
439
439
439

0.44
0.68
0.94
1.22

MDD
Width 8
BT CPU
0
0
0
0

0.02
0.04
0.06
0.10

Table 2: Comparing domain propagation MDD propagation Sequence nurse
rostering instances. Here, n stands number variables, BT number
backtracks, CPU solving time seconds.

problem without search. computation times correspondingly reduced, e.g.,
157s (resp. 96s) domain propagators 0.10s MDD propagator (width 8)
instance n = 100. Lastly, observe case MDD propagation
suffer scaling issues compared domain propagation.
final remark, also attempted solve nurse rostering instances using
Sequence domain propagator CP Optimizer (IloSequence). able solve
instance n = 40 1,150 seconds, none others instances solved within
time limit 1,800 seconds.
6.3 Comparing MDD Filtering Sequence Among
last experiment, compare Sequence MDD propagator MDD propagator Among constraints Hoda et al. (2010). main goal determine whether
large MDD sufficient solve problem (irrespective propagating Among
cumulative sums decomposition), whether additional information obtained
Sequence propagator makes difference.
apply methods, MDD propagation Sequence MDD propagation
Among, data set Section 6.1 containing 250 instances. time limit
1,800 seconds, run propagators maximum MDD widths 2, 8, 32, 128.
first compare performance MDD propagators Among Sequence
Figure 7. figure depicts number instances solved within given
time limit various methods. plot indicates Among propagators
much weaker Sequence propagator, moreover larger maximum widths
alone suffice: using Sequence propagator maximum width 2 outperforms
Among propagators maximum widths 128.
scatter plot Figure 8 compares MDD propagators Among Sequence
detail, widths 2, 8, 32, 128 (instances take 0 backtracks, resp. less
0.01 seconds, either method discarded Figure 8.a, resp. 8.b). smaller
widths, several instances Among propagator solve faster,
relative strength Sequence propagator increases larger widths. width
128, Sequence propagator achieve orders magnitude smaller search trees
718

fi200
150
100

Sequence Width 128
Sequence Width 32
Sequence Width 8
Sequence Width 2
Among Width 128
Among Width 32
Among Width 8
Among Width 2

0

50

Number instances solved

250

MDD Propagation Sequence Constraints

102

101

100

101

102

103

Time(s)

103
102
101
100
101

Sequence MDD Propagator Time (s)

Width 2
Width 8
Width 32
Width 128

102

102

104

106

Width 2
Width 8
Width 32
Width 128

100

Sequence MDD Propagator Backtracks



Figure 7: Performance comparison MDD propagation Sequence Among
various maximum widths. data point reflects total number instances
solved particular method within corresponding time limit.

100

102

104

106

102



101

100

101

102

103

Among MDD Propagator Time (s)

Among MDD Propagator Backtracks

b. Solving time

a. Number backtracks

Figure 8: Evaluating MDD propagation Sequence Among various maximum
widths via scatter plots respect search backtracks (a.) solving time
(b.). plots log-log scale follow format Figure 5.

719

fiBergman, Cire & van Hoeve

solving time Among propagators, demonstrates advantage
MDD propagation Sequence compared Among decomposition.

7. Conclusion
Constraint propagation limited-width MDDs recently shown powerful
alternative conventional propagation variable domains constraint programming.
work, studied MDD propagation Sequence constraint, appears in, e.g., rostering scheduling applications. first proved establishing
MDD consistency Sequence NP-hard. However, also shown task
fixed parameter tractable respect length sub-sequences defined
constraint, provided MDD follows variable ordering specified constraint.
proposed practical MDD propagation algorithm Sequence also polynomial length sub-sequences, based cumulative decomposition.
provided extensive experimental results comparing MDD propagator Sequence
domain propagators Sequence well existing MDD propagator Among.
computational experiments shown MDD propagator Sequence
outperform domain propagators orders magnitude terms search tree size
solving time. Similar results obtained compared existing MDD propagator Among, demonstrates practice large MDD alone sufficient
solve problems; specific MDD propagators global constraints Sequence
lead orders magnitude speedups.

Acknowledgments
material based upon work supported National Science Foundation
Grant No. CMMI-1130012, Google Research Award. also thank reviewers
whose comments helped improve paper.

References
Andersen, H. R., Hadzic, T., Hooker, J. N., & Tiedemann, P. (2007). Constraint Store
Based Multivalued Decision Diagrams. Proceedings CP, Vol. 4741 LNCS,
pp. 118132. Springer.
Apt, K. R. (2003). Principles Constraint Programming. Cambridge University Press.
Beldiceanu, N., & Contejean, E. (1994). Introducing global constraints CHIP. Journal
Mathematical Computer Modelling, 20 (12), 97123.
Brand, S., Narodytska, N., Quimper, C., Stuckey, P., & Walsh, T. (2007). Encodings
Sequence Constraint. Proceedings CP, Vol. 4741 LNCS, pp. 210224. Springer.
Cheng, K., & Yap, R. (2008). Maintaining Generalized Arc Consistency Ad Hoc r-Ary
Constraints. Proceedings CP, Vol. 5202 LNCS, pp. 509523. Springer.
Cire, A. A., & van Hoeve, W.-J. (2012). MDD Propagation Disjunctive Scheduling.
Proceedings ICAPS, pp. 1119. AAAI Press.
720

fiMDD Propagation Sequence Constraints

Cire, A. A., & van Hoeve, W.-J. (2013). Multivalued Decision Diagrams Sequencing
Problems. Operations Research, 61 (6), 14111428.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Downing, N., Feydy, T., & Stuckey, P. (2012). Explaining Flow-Based Propagation.
Proceedings CPAIOR, Vol. 7298 LNCS, pp. 146162. Springer.
Garey, M., & Johnson, D. (1979). Computers Intractability - Guide Theory
NP-Completeness. Freeman.
Gomes, C. P., Fernandez, C., Selman, B., & Bessiere, C. (2005). Statistical Regimes Across
Constrainedness Regions. Constraints, 10 (4), 317337.
Hadzic, T., Hooker, J. N., OSullivan, B., & Tiedemann, P. (2008a). Approximate Compilation Constraints Multivalued Decision Diagrams. Proceedings CP, Vol.
5202 LNCS, pp. 448462. Springer.
Hadzic, T., Hooker, J. N., & Tiedemann, P. (2008b). Propagating Separable Equalities
MDD Store. Proceedings CPAIOR, Vol. 5015 LNCS, pp. 318322. Springer.
Hadzic, T., OMahony, E., OSullivan, B., & Sellmann, M. (2009). Enhanced Inference
Market Split Problem. Proceedings ICTAI, pp. 716723. IEEE.
Hawkins, P., Lagoon, V., & Stuckey, P. (2005). Solving Set Constraint Satisfaction Problems
Using ROBDDs. JAIR, 24 (1), 109156.
Hoda, S., van Hoeve, W.-J., & Hooker, J. N. (2010). Systematic Approach MDD-Based
Constraint Programming. Proceedings CP, Vol. 6308 LNCS, pp. 266280.
Springer.
Hosaka, K., Takenaga, Y., Kaneda, T., & Yajima, S. (1997). Size ordered binary decision
diagrams representing threshold functions. Theoretical Computer Science, 180, 4760.
Knuth, D. E. (2009). Art Computer Programming, Volume 4, Fascicle 1: Bitwise
Tricks & Techniques; Binary Decision Diagrams. Addison-Wesley Professional.
Maher, M., Narodytska, N., Quimper, C.-G., & Walsh, T. (2008). Flow-Based Propagators
SEQUENCE Related Global Constraints. Proceedings CP, Vol. 5202
LNCS, pp. 159174. Springer.
Narodytska, N. (2011). Reformulation Global Constraints. Ph.D. thesis, University
New South Wales.
Regin, J.-C. (1994). Filtering Algorithm Constraints Difference CSPs.
Proceedings AAAI, Vol. 1, pp. 362367. AAAI Press.
Regin, J.-C. (2011). Global Constraints: Survey. Van Hentenryck, P., & Milano, M.
(Eds.), Hybrid Optimization, pp. 63134. Springer.
Regin, J.-C., & Puget, J.-F. (1997). Filtering Algorithm Global Sequencing Constraints. Proceedings CP, Vol. 1330 LNCS, pp. 3246. Springer.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). Handbook Constraint Programming.
Elsevier.
van Hoeve, W.-J., & Katriel, I. (2006). Global Constraints. Rossi, F. van Beek, P., &
Walsh, T. (Eds.), Handbook Constraint Programming, chap. 6. Elsevier.
721

fiBergman, Cire & van Hoeve

van Hoeve, W.-J., Pesant, G., Rousseau, L.-M., & Sabharwal, A. (2006). Revisiting
Sequence Constraint. Proceedings CP, Vol. 4204 LNCS, pp. 620634. Springer.
van Hoeve, W.-J., Pesant, G., Rousseau, L.-M., & Sabharwal, A. (2009). New Filtering
Algorithms Combinations Among Constraints. Constraints, 14, 273292.
Wegener, I. (2000). Branching Programs Binary Decision Diagrams: Theory Applications. SIAM monographs discrete mathematics applications. Society
Industrial Applied Mathematics.

722

fiJournal Artificial Intelligence Research 50 (2014) 847-884

Submitted 11/13; published 8/14

Arbitration Stability
Cooperative Games Overlapping Coalitions
Yair Zick

YAIRZICK @ CMU . EDU

School Computer Science
Carnegie Mellon University, United States

Evangelos Markakis

MARKAKIS @ GMAIL . COM

Department Informatics
Athens University Economics Business, Greece

Edith Elkind

ELKIND @ CS . OX . AC . UK

Department Computer Science
University Oxford, United Kingdom

Abstract
Overlapping Coalition Formation (OCF) games, introduced Chalkiadakis, Elkind, Markakis,
Polukarov Jennings 2010, cooperative games players simultaneously participate several coalitions. Capturing notion stability OCF games difficult task: deviating players may continue contribute resources joint projects non-deviators,
crucial question payoffs deviators expect receive projects. Chalkiadakis
et al. introduce three stability concepts OCF gamesthe conservative core, refined core,
optimistic corethat based different answers question. paper,
propose unified framework study stability OCF setting, encompasses
stability concepts considered Chalkiadakis et al. well wide variety alternative stability
concepts. approach based notion arbitration functions, determine payoff
obtained deviators, given deviation current allocation resources. provide
characterization stable outcomes arbitration. conduct in-depth study four
types arbitration functions, correspond four notions core; include three
notions core considered Chalkiadakis et al. results complement Chalkiadakis
et al. answer questions left open work. particular, show OCF games
conservative arbitration function essentially equivalent non-OCF games, relating
conservative core OCF game core non-overlapping cooperative game, use
result obtain strictly weaker sufficient condition conservative core non-emptiness
one given Chalkiadakis et al.

1. Introduction
Consider market exchange involving several agents, owning certain amount goods
(say, oil, sugar flour). agents trade other, vendor may offer different
prices different buyers. Suppose one vendors 3 tons sugar agreed sell
buyers 1 2 buyer 1 receives 1 ton sugar pays 500 dollars, whereas buyer 2
receives 2 tons sugar pays 900 dollars. vendor discovers sell one ton
sugar third buyer 700 dollars. may decide unhappy amount money
receives transaction buyer 1, cancel deal favor buyer 3. However,
buyer 2, upon hearing transaction buyer 1 canceled, may longer wish
work vendor, cancel agreement well. Therefore, deciding
c
2014
AI Access Foundation. rights reserved.

fiZ ICK , ARKAKIS , & E LKIND

whether deviation agreement profitable, vendor needs predict parties
trading would react actions. safe assume buyer 2 willing upkeep
interaction, deviation profitable; true, seller forgo
better deal buyer 3, lose deviation worth.
setting possesses several interesting characteristics. First, vendor may allocate goods
several buyers, buyer may also purchase goods several vendors. words,
agents may allocate fractions resources several profit-generating tasks. Second, agents
may withdraw resources agreements, keeping others unchanged.
example, oil vendor may wish sell less oil customer, change interactions
parties; similarly, buyer may want pay less vendors, maintain
payments others. Finally, trying strategically change agreement, agents must take
account impact actions contracts still maintain (possibly
unaffected) parties.
features typical many multi-agent settings, agents collaborate allocating
parts resources working together order generate revenue, share resulting
profits. Profit sharing done directly, exchange goods results profit, e.g.,
agents make new good using resources sell it; profit sharing also indirect,
e.g., via setting price good sold. settings, even external constraints
profits distributed, agents account individuals groups agents
underpaid. group agents get money deviating proposed deal
may destabilize entire agreement, causing cascade deviations results less desirable
state. However, constitutes profitable deviation greatly depends non-deviators
respond deviating set.
Modeling system incentives reactions challenge itself. Recently challenge
addressed Chalkiadakis, Elkind, Markakis, Polukarov, Jennings (2010), propose
novel approach modeling scenarios agents divide resources among several coalitions.
introduce overlapping coalition formation (OCF) games, generalize classic model
cooperative games (Peleg & Sudholter, 2007).
classic cooperative game theory model, set agents N ; subset N
form team generate profit members. transferable utility (TU) games, subset
agents N identified value v(S). value thought monetary
payoff set members agree work together, freely divided among
members S. argued above, desirable property payoff distribution scheme stability
individual group deviations, captured notion core (Gillies, 1953):
payoff division said core every subset agents N receives total payoff
least value v(S).
Classic cooperative game theory assumes agent may belong one coalition
given time. is, agents form coalition structures splitting disjoint groups,
group working individual task. Consequently, classic approach well-suited handle
overlapping coalitions, intricacies deviation settings agent participates
several agreements. Indeed, classic cooperative game setting, set agents assesses
desirability payoff division make own: total payoff allotted
least v(S)? deviating agents break ties non-deviators,
cannot expect non-deviators collaborate way. contrast,
agents allowed split resources among multiple coalitions, notion profitable
848

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

deviation must reexamined, since partial coalitions allow partial deviations, means
even though set agents decides deviate group agreement, remains involved
collaborative projects non-deviators. non-deviators decide much deviators
receive projects. Hence, deviators decision whether withdraw
tasks (and extent) depends expect receive collaboration
non-deviators.
Chalkiadakis et al. (2010) propose model agents split resources among several
coalitions, study effect joint projects non-deviators desirability deviation
overlapping coalition setting. propose discuss three notions reaction deviation.
first reaction, term conservative, gives deviators share profits
coalitions maintain non-deviators. second reaction, termed refined, allows deviators keep payoffs coalitions unaffected deviation. Finally,
optimistic reaction deviators may able receive revenue coalition
involved in, long non-deviators coalition guaranteed pre-deviation payoffs.
reactions deviation correspond three notions stability OCF games, namely,
conservative core, refined core, optimistic core.
non-deviators reaction deviation extend beyond three notions. Many legal
contracts (e.g., ones involving service provider clients, vendors suppliers, several
companies working joint venture) designed explicit aim detailing consequences deviation parties. Typically, contracts impose fines parties break
agreement. However, also forms punishment: instance, company fails
uphold contractual obligations may blacklisted clients, reputation
tarnished bad press. Alternatively, one may actively rewarded deviating, e.g.,
external party wishes break certain status-quo, encourage project diversification.
adopting notion partial deviation possible reactions deviation, capture far
nuanced scenarios described classic TU games.
1.1 Contribution
main contribution broad generalization overlapping coalition formation (OCF) model
proposed Chalkiadakis et al. (2010). Chalkiadakis et al. describe three ways nondeviators may react deviation, propose general framework modeling reactions.
framework based notion arbitration function (Section 3). function that,
given deviating group players deviation, outputs, every coalition containing
deviators, amount deviators expect receive coalition post-deviation.
Using arbitration functions, present class solution concepts OCF games call
arbitrated cores (Section 4). show three concepts core described Chalkiadakis
et al. (2010) special cases model, propose new concept core, call
sensitive core. propose criterion checking whether outcome arbitrated
core, characterize core outcomes important arbitration functions. focus
identifying sufficient necessary conditions arbitrated core non-empty (Section 5). Building work Chalkiadakis et al., provide LP-based criterion
non-emptiness conservative core, derive criteria sensitive refined core
non-empty. use result identify interesting class OCF games whose refined core
guaranteed non-empty. Finally, show OCF games conservative arbitration
849

fiZ ICK , ARKAKIS , & E LKIND

function essentially equivalent non-OCF games, relating conservative core OCF
game G core discrete superadditive cover, non-OCF game constructed
G natural way. particular, means conservative core OCF game G
non-empty discrete superadditive cover G supermodular. demonstrate
condition strictly weaker convexity-based condition conservative core non-emptiness
given Chalkiadakis et al.
1.2 Related Work
direct precursor work work Chalkiadakis et al. (2010): generalize
model capture broader class possible reactions deviation, solve problem
left open work.
Incentives optimization collaborative multi-agent environments received plenty
attention multiagent research community (Sims, Corkill, & Lesser, 2008; Airiau & Sen,
2009; Rahwan & Jennings, 2008; Dang, Dash, Rogers, & Jennings, 2006; Shehory & Kraus, 1996;
Lin & Hu, 2007; Zhang, Jiang, Su, Qi, & Fang, 2010); see also PhD thesis Rahwan (2007)
recent book Chalkiadakis, Elkind, Wooldridge (2011) overview. studies
often use cooperative game theory modeling framework.
Several authors considered problem optimal coalition structure generation cooperative settings overlapping coalitions. Shehory Kraus (1996) initiated line
research; work, describe distributed coalition formation algorithm agents may
split resources among several tasks order achieve better outcomes. Dang et al. (2006)
consider overlapping coalitions sensor networks, agents sensors tasked
tracking objects. Lin Hu (2007) provide parallel algorithm overlapping coalition formation. papers, underlying assumption agents fully cooperative, i.e.,
seek maximize social welfare rather gains. contrast, work focus
game-theoretic aspects strategic behavior cooperative settings, taking agent incentives
account.
model applies settings rational agents distribute resources among several
projects, receiving profits each. scenario occurs variety applications. example,
multi-commodity network flows easily modeled within overlapping coalition formation
framework (for analysis underlying non-OCF game, see Markakis & Saberi, 2005).
also case several fractional optimization problems (Deng, Ibaraki, & Nagamochi,
1999). example, fractional matching problem thought OCF game,
partial coalition pair agents describes amount resources agents
assigns respective task.
Another class settings overlapping coalitions arise collaboration networks. Consider social network agent associated weighted node derives value
assigning certain portion weight collaborating neighbors. settings
received much attention recent years (for survey, see Jackson, 2003). instance, Anshelevich Hoefer (2010) discuss strategic aspects network formation settings agents
may participate one coalition; however, contrast work, main focus
analysis individual rationality pairwise equilibria networks, rather group
stability. Fractional stable matchings discussed Aharoni Fleiner (2003), nontransferable utility model. recently, Ackerman Branzei (2014) analyzed research
850

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

collaboration using graphical model, authors devote efforts collaborative
projects, receive credit work based authorship order model. Ackerman
Branzei mainly interested individually rational pairwise stable outcomes, much like Anshelevich Hoefer. OCF framework recently used model collaborative wireless
networks (Wang, Song, Han, & Saad, 2013; Zhang, Song, Han, Saad, & Lu, 2013).
Overlapping coalition formation games, proposed Chalkiadakis et al. (2010), share
features fuzzy games (Aubin, 1981). However, fundamental differences
two models. Arguably, important difference Chalkiadakis et al. assume several
partial coalitions may form, whereas Aubin assumes agents pool resources work
single task, considers partial coalitions context potential deviations. Assuming
formation single coalition eliminates many subtleties games overlapping
coalitions capture, emphasized Chalkiadakis et al.
work presented paper computational nature, algorithmic issues
arise cooperative games overlapping coalitions discussed Chalkiadakis et al.
(2010) subsequently Zick, Chalkiadakis, Elkind (2012); refer reader companion paper (Zick, Chalkiadakis, Elkind, & Markakis, 2014) in-depth analysis.

2. Preliminaries
Throughout paper, consider games finite set players N = {1, . . . , n}. use
boldface lowercase letters denote vectors uppercase letters denote sets. Given set N ,
write eS denote indicator vector
Furthermore, given vector x = (x1 , . . . , xn ) Rn
P S.
subset N , set x(S) = xi .
2.1 Classic TU Cooperative Games
transferable utility (TU) cooperative game given set players, agents, N = {1, . . . , n}
characteristic function u : 2N R u() = 0; write G = hN, ui. payoff vector
game G = hN, ui vector x Rn x(N ) = u(N ). payoff vector x game
G = hN, ui said stable x(S) u(S) N . set stable payoff vectors
G called core G.
sometimes assumed agents allowed form coalition structures; coalition structure CS simply partition N , value u(CS ) sum values constituent
coalitions. coalition part coalition structure CS , value S, u(S),
freely divided among members S, transfers agents members
allowed, i.e., x payoff vector coalition structure CS x(S) = u(S)
CS . core game G = hN, ui coalition structures set pairs (CS , x),
CS coalition structure, x payoff vector CS , x(S) u(S) N .
Cooperative games coalition structures first studied Aumann Dreze (1974),
focus number recent papers multiagent research community (see
Chalkiadakis et al., 2011).
2.2 OCF Games
Given set agents N = {1 . . . n}, partial coalition players N vector c = (c1 , . . . , cn )
[0, 1]n . i-th coordinate c indicates fraction player resources contributed c.
851

fiZ ICK , ARKAKIS , & E LKIND

follows, omit word partial, refer vectors [0, 1]n coalitions.
particular interest players actively participate c. players may rightfully claim
share cs profits, ones may potentially get hurt agent changes
contribution c. Formally, support coalition c set supp(c) = {i N | ci > 0}.
recall formal definition OCF games, given Chalkiadakis et al. (2010).
Definition 2.1. OCF game G = hN, vi given set players N = {1, . . . , n}
characteristic function v : [0, 1]n R+ , assigns non-negative real value partial
coalition; require v(0n ) = 0.
characteristic function OCF game quite general; even require v
monotone. reasoning behind apparent leniency that, given v, agents N may form
several coalitions order optimize revenue, process results coalition structure.
is, however, one additional assumption v would like impose; introduce it,
first need formally define concept coalition structure OCF game.
P
coalition structure N finite list coalitions CS = (c1 , . . . , cm )
j=1 cj
1n . coalition structure CS thought n matrix whose rows sum 1.
requirement rows sum 1 means CS valid division players
resources, i.e., player gives 100% resources CS . readability, use set
notation referring coalition structures: e.g., referring coalition c appears
CS , write c CS , referring coalition structure CS 0 sublist CS ,
write CS 0 CS .
Recall coalition structure classic cooperative game partition agent set, i.e.,
collection disjoint subsets N whose union N . particular, set agents appear twice
coalition structure. contrast, OCF games, possible coalition structure CS
coalition appearing once. simply means respective agents
completing two separate tasks, require resources generate revenue.
Example 2.2. Consider setting two researchers collaborate. write single long
research paper, require time, generate revenue $100000 (in, say,
grant money performance payment). Alternatively, split time equally two
research projects, produce two shorter papers, generate $70000 each. setting,
agents best interest split two identical coalitions form ( .5
.5 ) rather form
single coalition.
P
total revenue generated coalition structure CS simply cCS v(c), denoted
v(CS ).
Given set agents N , say coalition structure CS supp(c)
c CS . denote set coalition
structures CS(S). weight vector
P
coalition structure CS w(CS ) = cCS c. vector w(CS ) indicates total amount
resources player N invests coalition structure CS . Note w(CS ) [0, 1]n ,
CS CS(S), w(CS ) eS ; say coalition structure CS efficient
w(CS ) = eS . also write wS (CS ) denote total weight CS ; namely, i-th
coordinate wS (CS ) equals i-th coordinate w(CS ) S, 0 otherwise.
shown Example 2.2, agents may form coalition structures order increase revenue. considerations naturally give rise following definition. superadditive cover
852

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

v defined
v (c) = sup{v(CS ) | CS CS(N ), w(CS ) c}.
value v (c) players make using resources c. Note similar
notion superadditive cover exists classic coalitional games (Aumann & Dreze, 1974): given
function u : 2N R, superadditive cover function u : 2N R defined
X
u (S) = max{
v(T ) | P partition S}.
P

Recall function f : Rn R called superadditive c, Rn
f (c) + f (d) f (c + d);

(1)

f defined subdomain U Rn , condition (1) imposed vectors c,
c + still U . definition following discrete analogue: function u : 2N R
called superadditive sets S, N =
u(S) + u(T ) u(S ).

(2)

definitions explain term superadditive cover: easy see v minimal
superadditive function [0, 1]n R v (c) v(c) every c [0, 1]n , and, similarly,
u minimal superadditive function 2N R u (S) u(S) every N .
ready formulate additional requirement wish impose v.
Definition 2.3. characteristic function v efficient coalition structure property every
c [0, 1]n exists CS CS(N ) w(CS ) = c v (c) = v(CS ).
characteristic functions efficient coalition structure property, sup definition v replaced max. follows, limit attention OCF games whose
characteristic functions enjoy property. see efficient coalition structure property
desirable OCF setting, consider function f given f (x) = x [0, 1]n \ {0n },
positive constant. function efficient coalition structure
property superadditive cover f (x) = x [0, 1]n \ {0n }. particular,
means coalition structure optimal f : always possible increase social welfare
splitting coalition two non-zero coalitions. remark Chalkiadakis et al. (2010)
impose number conditions characteristic function OCF game that, taken together,
imply efficient coalition structure property; find convenient state property
directly.
provide intuition concepts introduced far, describe simple class
OCF games. often useful think agents using resources complete
given set tasks. Chalkiadakis et al. (2010) describe class OCF games, call
Threshold Task Games (TTGs), based idea. TTG specified finite list
tasks, = {t1 , ..., tk }, task t` requires weight (t` ) 0 completion
gives certain payoff p(t` ) 0, list players weights, denoted (w1 , . . . , wn ). player
allocate fraction weight completion task. worth coalition
v(c) = max{p(t` ) | (t` )

n
X
i=1

853

ci wi };

fiZ ICK , ARKAKIS , & E LKIND

is, value coalition simply value highest-paying task agents
complete using combined weight. Threshold Task Games natural extension Weighted
Voting Games (WVGs) (Chalkiadakis et al., 2011). Indeed, weighted voting game, agent
N non-negative weight wi , value set players N 1 combined
weight members least given non-negative quota q, 0 otherwise. Thus,
weighted voting games simply threshold task games single task weight q
payoff 1, overlapping coalitions allowed.
2.3 Payoff Division
split coalitions generated revenue, agents decide divide
revenue amongst agreeable manner. formally describe payoff division
OCF games.
imputation coalition structure CS = (c1 , ..., cm ) CS(N ) list vectors x =
(x1 , ..., xm ); j = 1, . . . , m, xj vector Rn describes much agent N
receives cj . Given coalition c CS imputation x CS , refer way
value c divided x(c); thus, payoff agent coalition c CS x x(c)i .
order x valid division payoffs among agents, satisfy following
conditions.
P

{i}
Individual Rationality:
cCS x(c) v (e ) N .
P
Payoff Distribution: c CS holds x(c)i v(c), ci = 0 x(c)i = 0.
denote set imputations CS I(CS ). Observe definition allow
inter-coalitional transfers. is, agent N support c, cannot
expect receive payoff c. call tuple (CS , x), CS coalition structure
x I(CS ), feasible outcome. Given set N , denote F(S) set feasible
outcomes (CS , x) CS CS(S). Thus, F(N ) refers possible ways agents form
coalition structures divide payoffs.
Given feasible
outcome (CS , x) F(N ), define payoff agent N
P

p (CS , x) = cCS x(c)i . total payoff coalitions CS . Observe
pi (CS , x) uniquely defined: given outcome (CS , x), total payoff player depends
solely amount payoff received coalitions CS ,
x,
P determined


x alone. Similarly, total payoff set given p (CS , x) = p (CS , x).
Definition 2.4. Given set N coalition structure CS CS (N ), coalition structure
CS reduced defined
CS |S = (c CS | supp(c) S) .
coalitions comprised solely members S.
coalitions CS |S fully controlled S. Hence, deviation members would
affect non-deviators changes contribution coalitions outside CS |S .
ready formally define deviations OCF games. Loosely speaking, deviation
set N coalition structure CS CS(N ) specifies amount resources
withdraw coalitions CS |S .
854

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

Definition 2.5. Suppose CS \CS |S = (cj1 , . . . , cjk ). coalition structure CS 0 = (d1 , . . . , dk )
deviation CS ` = 1, . . . , k holds d` cj` d` eS .
deviation CS 0 describes set withdraws resources coalitions CS \ CS |S .
requirement d` cj` captures fact cannot withdraw resources
coalition cj` invested it. also require d` eS since deviation CS 0
involve members only.
sometimes convenient think deviation function that, coalition c
CS \ CS |S , outputs much agents withdraw c. is, given coalition structure
CS CS(N ), set N , deviation CS 0 CS , coalition cj` CS \ CS |S ,
write dCS 0 (cj` ) refer coalition d` CS 0 corresponds deviation
cj` . notation, (dCS 0 (cj` ))i specifies amount resources agent withdraws
coalition cj` CS 0 . deviation CS 0 understood context, omit
subscript CS 0 dCS 0 (c) refer deviation c d(c).
Note withdraws resources CS \ CS |S , total weight available
w(CS |S ) + wS (CS \ CS |S ) = wS (CS ).
Example 2.6. Consider three-player game described follows. several types tasks:
t12 requires 50% player 1s resources player 2s resources, payoff 16;
t012 requires 40% player 1s resources player 2s resources, payoff 10;
t13 requires 50% player 1s resources player 3s resources, payoff 20;
t1 requires 10% player 1s resources payoff 3.
optimal coalition structure case

0.5
0.5
CS = c1 = 1 , c2 = 0
.
0

1

coalitions c1 c2 complete tasks t12 t13 , respectively; thus, v(c1 ) = 16 v(c2 ) = 20.
deviation player 1 CS would coalition structure

CS 1 =
0 , 0
0

0

0.5 0.5. = 0, player 2 unaffected deviation; = 0
player 3 unaffected deviation.
possible player 1 deviates c1 changing contribution c2 , vice
versa. Moreover, possible coalition resources withdrawn still
generate revenue. instance, player 1 withdraws 10% resources c1 ,
remains c1 still generates revenue 10. opens opportunities nuanced postdeviation behavior: player 3 may decide break agreement player 1 = 0,
= .1 player 2s payment original coalition structure less 10, player 1 hope
get payment reduced collaboration player 2.
Example 2.6 illustrates, deviations OCF games may leave non-deviators unaffected deviation. Moreover, may possible deviators ensure non-deviators
still receive payoff allocated prior deviation. deviators agree assume
marginal loss deviation, possible non-deviators agree maintain coalitions
them. notions formalized Section 3.
855

fiZ ICK , ARKAKIS , & E LKIND

3. Arbitration Function
classic cooperative game theory, set unhappy payoffs wants deviate
compares current payoff earn own. However, Example 2.6 shows,
complex structure deviations OCF games lead variety ways agents
may react deviation. deviating set still keeps resources invested coalitions
non-deviators, may case continue receive payments coalitions.
discuss stability OCF games, need describe agents react set N
deviates (CS , x). One think process following manner: given outcome
(CS , x) deviation CS 0 N CS , set may use available resources CS |S
CS 0 order generate revenue itself. Moreover, coalition c CS \ CS |S needs
decide much payoff gives deviators; behavior specified arbitration
function.
Definition 3.1. Given outcome (CS , x), set N deviation CS 0 CS ,
arbitration function mapping assigns real value c (CS , x, S, CS 0 ) c
CS \ CS |S .
value c (CS , x, S, CS 0 ) represents amount coalition c pay S, given
current outcome (CS , x), identity deviators, nature deviation.
3.1 Properties Arbitration Functions
Clearly, need impose restrictions amount deviators may expect get
non-deviators. example, would unreasonable deviating set expect payoff
exceeds post-deviation value respective coalition. Another natural restriction that,
deviators get payoff given coalition, every non-deviator coalition
receive payoff deviation, i.e., non-deviators never agree pay
deviating set expense non-deviating members.
Formally, given outcome (CS , x), set N , deviation CS 0 CS , arbitration function whose output (CS , x, S, CS 0 ) described list values (c )cCS \CS |S ,
require following properties:
P
Accountability: c (CS , x, S, CS 0 ) max{v(c d(c)) \S x(c)i , 0}.
Deviation-Monotonicity: every pair subsets S, N respective
deviations CS 0 CS 00 CS dCS 0 (c) dCS 00 (c) c CS \ CS |S ,
holds c (CS , x, S, CS 0 ) c (CS , x, T, CS 00 ).
first condition states general upper bound amount deviating set expect
receive coalition: deviation, coalition c generate profit v(c d(c)),
deviating set expect receive v(c d(c)), minus original payments given
non-deviators (CS , x). second condition simply states punishment imposed
arbitration function monotone size violation: deviators withdraw
smaller amount resources coalition, receive least much payoff
received original deviation. rationale behind first condition strategic
nature; stems assumption set agents engaged task agree pay
deviating members deviators cannot ensure non-deviator paid amount
856

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

prior deviation. stress however, accountability necessary component
proofs: results still hold even one assume accountability. second condition,
sensible well, instrumental proving Theorem 3.4, necessary assumption. Finally,
note possible coalition imposes fine deviating members, is, value c
need positive.
total revenue deviating set given deviation CS 0 CS written
A(CS , x, S, CS 0 ) = v (w(CS |S ) + w(CS 0 )) +

X

c (CS , x, S, CS ).

cCS \CS |S

Given outcome (CS , x) set N , get deviating (CS , x)
(CS , x, S) = sup{A(CS , x, S, CS 0 ) | CS 0 deviation CS }.
Now, order deem deviation profitable, members stand gain
it. formal definition captures idea somewhat complicated, describe
deviators share profit/loss allocated arbitration function.
Definition 3.2. Given outcome (CS , x) deviation CS 0 N CS , say
CS 0 A-profitable deviation construct
1. coalition structure CS w(CS ) = w(CS |S ) + w(CS 0 ) together imputation xd I(CS ),
2. collection vectors = (yc )cCS \CS |S , every c CS \ CS |S holds
(a) yc (R+ )n c (CS , x, S, CS 0 ) 0 yc (R )n otherwise,
(b) (yc )i = 0 6 supp(c d(c)),
Pn
0

(c)
i=1 (yc ) = c (CS , x, S, CS ),
P
every holds pi (CS , xd ) + cCS \CS |S (yc )i > pi (CS , x).
Simply put, given Ss deviation (CS , x) arbitration function A, agents
agree three things. First, decide coalition structure form
post-deviation resources. Second, come way dividing profits
coalition structure. Third, agree way dividing payoffs (or fines) assigned
arbitration function. deviation profitable, agreements
agents receive strictly received (CS , x).
agreement exists, cannot A-profitably deviate. Given (CS , xd ) y, total payoff
agent deviating denoted q (xd , y).
priori, seems possible that, even total payoff deviating set

p (CS , x), members may unable divide revenue deviation way
benefits due coalitional restrictions. Chalkiadakis et al. (2010) show
conservative arbitration function (see Section 3.2) case: way agents
jointly gain deviating, divide profits way benefits all.
Theorem 3.4, show extend result general arbitration functions.
857

fiZ ICK , ARKAKIS , & E LKIND

Remark 3.3. possible incorporate freely divisible value arbitration function.
value payoff (or fine) assigned deviators external entity. payments
coalitions CS \ CS |S , payment may depend original outcome, identity
deviating set, nature deviation. results paper carry
addition freely divisible value. Intuitively, value allows us extend notions
-core (Maschler, Peleg, & Shapley, 1979) OCF games.
3.2 Arbitration Functions
present arbitration functions briefly discuss properties. Three
arbitration functions correspond three notions core introduced Chalkiadakis et al.
(2010) (the conservative core, refined core optimistic core), names use
arbitration functions reflect this; contrast, sensitive arbitration function based
new idea.
3.2.1 C ONSERVATIVE RBITRATION F UNCTION
simplest assumption one make respect reaction deviation nondeviators react voiding agreements deviators; is, deviators expect
payment coalitions non-deviators, regardless contribution.
reasoning gives rise conservative arbitration function; formally, defined setting
c 0 given input. conservative arbitration function, deviating set
rewarded way continued interaction non-deviators; thus, profit hope
gain deviating exactly make own. Therefore, conservative
arbitration function, denoted Ac , Ac (CS , x, S) = v (eS ) every outcome (CS , x).
3.2.2 ENSITIVE RBITRATION F UNCTION
reasoning agents reaction deviation, natural assumption make nondeviators care deviating set does, long deviation affect them.
approach captured sensitive arbitration function. function payment
deviators obtain coalition c CS \ CS |S 0 c0 CS \ CS |S
d(c0 ) 6= 0 supp(c) supp(c0 ) N \ 6= ; otherwise, payment total payoff
members receiving c prior deviation.
sensitive arbitration function, denoted , deviating set get
computed follows. First, clear benefit investing resources
joint projects non-deviating agents hurt way deviation. Thus,
needs decide agents keep collaborating with; agents, break
agreements them. order describe payments sensitive arbitration function,
employ following notation. Given set N , let CS set coalitions
CS involve members ;
CS = (c CS | supp(c) 6= ).
Now, set N chooses break agreements involve members , forgoes payments
coalitions CS , use resources invested CS order maximize
profits. is, obtain



(CS , x, S) = max v w(CS |S ) + wS (CS ) + pS (CS \ (CS |S CS ), x) | N \ .
858

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

definition extended follows: instead completely self-interested,
agent N set players Si N cares about. agents Si hurt
deviation, agent allow deviating set payoff coalitions
involved in.
3.2.3 R EFINED RBITRATION F UNCTION
sensitive arbitration function focuses impact deviation individual agents;
contrast, refined arbitration function makes decisions based deviations impact
coalition. Specifically, arbitration function coalition c allows deviators keep
payoffs c withdrawn resources c. Formally, given
deviation CS 0 N CS outcome (CS , x), refined arbitration function, denoted
Ar , let keep payoff coalition c CS \ CS |S d(c) = 0, allocate payoff
c otherwise. Note refined arbitration function generous deviators
sensitive arbitration function: deviator non-deviator j involved coalitions
c c0 , c0 affected deviation c not, refined arbitration function
receive share cs payoffs, whereas sensitive arbitration function not.
set expect gain deviating refined arbitration function
computed follows. First, note given coalition c CS \ CS |S , either withdraw
resources c none all. Thus, needs find best set coalitions CS
fully withdraw resources. Formally,
c )) + pS (CS \ CS
c , x) | CS |S CS
c CS }.
Ar (CS , x, S) = max{v (wS (CS
3.2.4 PTIMISTIC RBITRATION F UNCTION
yet lenient reaction deviation captured optimistic arbitration function, denoted
Ao . arbitration function coalition willing pay deviating set long
non-deviators receive pre-deviation payoffs. Since require arbitration functions
accountability property, means optimistic arbitration function gives deviating set
highest possible payoff receive arbitration function. Formally, given set S,
outcome (CS , x) aP
deviation CS 0 CS , payoff gets coalition c

max{0, v(c d(c))
/ x(c) }.
order compute set get deviating optimistic arbitration
function, need determine amount resources going withdraw every
coalition involved in. obtain
X
c ) + w(CS 0 )) +
c , x)},
Ao (CS , x, S) = sup{v (wS (CS
v(c d(c)) pN \S (CS \ CS
c
cCS \CS

c CS |S CS
c CS (intuwhere supremum taken coalition structures CS
itively, coalitions CS members withdraw resources)
c.
deviations CS 0 CS \ CS
3.3 Redefining A-Profitable Deviations
definition A-profitable deviation somewhat difficult work with. remedy this,
provide simple sufficient condition existence A-profitable deviation.
859

fiZ ICK , ARKAKIS , & E LKIND

Chalkiadakis et al. (2010) prove similar result conservative arbitration function,
use techniques (most notably, coloring argument) proof.
Theorem 3.4. Consider OCF game G = hN, vi, outcome (CS , x) G arbitration
function A. (CS , x, S) > pS (CS , x) N , subset
A-profitably deviate (CS , x).
Proof. Consider set N (CS , x, S) > pS (CS , x). First, note space
possible deviations coalition structure CS viewed subset RD (for
appropriate value D) bounded described finitely many non-strict linear
inequalities. Therefore space compact. Thus, exists deviation (CS , x)
maximizing total payoff derive deviating; let CS 0 deviation.
Since v efficient coalition structure property, exists coalition structure CS
v(CS ) = v (w(CS |S ) + w(CS 0 )). every c CS \ CS |S , let c amount
supp(c d(c)) receives c deviation. objective find imputation
xd I(CS ) along payoff divisions (c )cCS \CS |S would witness subset
A-profitable deviation (CS , x).
Given coalition c CS \ CS |S , let Ic set possible ways c divided
among members supp(c d(c)). Formally, c 0,
Ic = {yc (R+ )n | supp(yc ) supp(c d(c))

n
X

(yc )i = c };

i=1
n
c < 0, IQ
c defined similarly, yc Ic vectors (R ) . Given xd
I(CS ) cCS \CS |S Ic , recall q (xd , y) payoff agent deviation
payoffs CS arbitration functionQ
payoffs divided according xd y,
respectively. define function TL : I(CS ) cCS \CS |S Ic R follows:

TL(xd , y) =

X



min pi (CS , x) q (xd , y), 0 .



function TL measures total loss incurred members hurt deviation;
members who, despite joining deviators,
Q enjoy profit deviating.
Observe TL continuous, I(CS ) cCS \CS |S Ic compact sets; thus,
TL attains minimum value domain. Among minimizers function, pick one
number agents pi (CS , x) < q (xd , y) largest; denote point
(x0 , y0 ).
Now, let us color agents follows: agent green pi (CS , x) < q (x0 , y0 );
red pi (CS , x) > q (x0 , y0 ) white pi (CS , x) = q (x0 , y0 ). Green agents derive strictly
positive benefit proposed deviation, red agents suffer loss, white agents break even.
Now, consider green agent g, suppose g legally transfer payoff agent
x0 y0 , i.e., (a) g support coalition c CS g receives
positive payoff c, (b) g support coalition c d(c)
c CS \ CS |S , c > 0, g receives positive payoff c, (c) g
support coalition c d(c) c CS \ CS |S , c < 0, receives negative payoff
c. red, g transfer small positive payoff remaining green, resulting
payoff division would strictly lower value TL (x0 , y0 ), contradiction. Similarly,
860

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

white, g transfer small amount i, making green well, without changing
value L; contradiction, since chose (x0 , y0 ) maximize number green
agents. Thus, g support coalition deviation (i.e., either
coalition CS surviving coalition CS \ CS |S ), g cannot receive positive payoff
coalition. argument, coalition CS \ CS |S assigns negative payoff
deviating agents A, green agents incur loss coalition.
Let Sg set green agents S. argued agents Sg receive payoff
coalitions form non-green agents S. follows Sg A-profitably deviate
(CS , x). Indeed, suppose agents \ Sg deviate, agents Sg deviate
withdrawing resources need forming coalitions among CS ;
resources Sg withdrew CS deviation CS 0 order invest coalitions
members \ Sg CS kept is. Since deviation-monotone, payment Sg
receives arbitration function new deviation weakly higher CS 0 .
Furthermore, suppose Sg forms coalitions CS |Sg , divides payoffs
coalitions according x0 , distributes arbitration function payoffs according y0 ,
surplus payments arbitration function shared arbitrarily. payoffs members
Sg least high CS 0 , x0 y0 ; since agents green,
benefits new deviation. Finally, note Sg 6= , since pS (CS , x) < (CS , x, S).
concludes proof.
Simply put, Theorem 3.4 states set get deviating (CS , x)
strictly greater payoff (CS , x), non-empty subset
A-profitably deviate. Note distinction coalitional value profitability
deviating exists cooperative games coalition structures well.
Example 3.5. Consider modified version three player 2-majority game: agent set
N = {1, 2, 3}, value coalition N size least 2 6, value
singleton 1. Suppose agents form coalition N , divide payoffs agent
receives 2. set N earn forming coalition structure ({1, 2}, {3}), whose value
7. However, way divide payoffs coalition structure every agent
receives 2: agent 3 receive 1, better off. Thus, N cannot deviate
whole, coalition {1, 2} singleton {3} (or both, depending value
grand coalition distributed) profitable deviation.
Theorem 3.4 provides us justification using (CS , x, S) measure deviators satisfaction outcome. Indeed, A-profitably deviate (CS , x) via
deviation CS 0 , clearly (CS , x, S) > pS (CS , x). hand, (CS , x, S) >
pS (CS , x), A-profitably deviate (CS , x).

4. Arbitrated Core
Given OCF game G = hN, vi arbitration function A, say outcome (CS , x)
A-stable set N A-profitably deviate (CS , x). arbitrated
core G respect arbitration function A, A-core G (denoted Core(G, A)),
set A-stable outcomes G. Using Theorem 3.4, obtain following characterization
A-stable outcomes.
861

fiZ ICK , ARKAKIS , & E LKIND

Theorem 4.1. Let G = hN, vi OCF game. outcome (CS , x) A-core G
every N pS (CS , x) (CS , x, S).
Proof. First, suppose every N pS (CS , x) (CS , x, S). Let CS 0
arbitrary deviation CS . pS (CS , x) A(CS , x, S, CS 0 ). Thus, matter
divides deviation payoffs, would least one agent gets
pi (CS , x). true arbitrary deviation CS 0 , follows cannot A-profitably
deviate.
Conversely, suppose pS (CS , x) < (CS , x, S). Theorem 3.4, subset
A-profitably deviate (CS , x), thus (CS , x) A-stable.
Let two arbitration functions. Intuitively, clear lenient
A, A-core contained A-core. Indeed, outcome (CS , x) stable respect
always pays deviators (thus making deviation tempting),
(CS , x) A-stable well. formalize intuition, use following notation.
Given two arbitration functions A, write every set N every
outcome (CS , x) holds (CS , x, S) (CS , x, S). state observation
follows.
Corollary 4.2. Core(G, A) Core(G, A).
Proof. Suppose (CS , x) Core(G, A). means N pS (CS , x)
(CS , x, S). Since A, follows pS (CS , x) (CS , x) N well,
implies (CS , x) Core(G, A).
conservative, sensitive, refined optimistic arbitration functions described Section 3.2,
denoted Ac , , Ar Ao , respectively, satisfy Ao Ar Ac . Thus, Corollary 4.2
implies conservative core contains sensitive core, contains refined core,
contains optimistic core. observations (with respect conservative, refined,
optimistic core only) made Chalkiadakis et al. (2010) well; fact, Chalkiadakis
et al. show containments strict, i.e., games conservative core
strictly contains refined core, games refined core strictly contains
optimistic core. similar separation shown sensitive core.
4.1 Arbitrated Cores
Using characterization result Theorem 4.1, proceed describe arbitrated cores,
namely, corresponding arbitration functions introduced Section 3.2.
4.1.1 C ONSERVATIVE C ORE
argued Section 3.2, every outcome (CS , x) every set N , get
conservative arbitration function v (eS ). Thus, conservative core set
outcomes (CS , x) every set N holds
pS (CS , x) v (eS ).
862

(3)

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

4.1.2 ENSITIVE C ORE
order outcome (CS , x) stable sensitive arbitration function, every set
N every N \ hold
pS (CS , x) v (w(CS |S ) + wS (CS )) + pS (CS \ (CS |S CS ), x);
recall CS set coalitions CS involve members . Subtracting payments
associated coalitions CS \ (CS |S CS ) sides inequality, get
pS (CS |S , x) + pS (CS , x) v (w(CS |S ) + wS (CS )).
Chalkiadakis et al. (2010) show CS optimal coalition structure (CS , x)
conservative core consequently sensitive core either. Thus,
assume CS optimal coalition structure, hence CS |S optimal N , i.e.,
v(CS |S ) = v (w(CS |S )). also pS (CS |S , x) = v(CS |S ). implies that, order
(CS , x) sensitive core, must case CS optimal coalition structure
every N every N \ holds
pS (CS , x) v (w(CS |S ) + wS (CS )) v (w(CS |S )),

(4)

i.e., total payoff CS must least marginal benefit using resources
invested CS . Note take = N \ S, obtain conservative core condition.
4.1.3 R EFINED C ORE
refined core,
c )) + pS (CS \ CS
c , x) | CS |S CS
c CS }.
Ar (CS , x, S) = max{v (wS (CS
Thus, outcome (CS , x) refined core every N every
c containing CS |S holds
coalition structure CS
c )) + pS (CS \ CS
c , x).
pS (CS , x) v (wS (CS
c holds
Consequently, (CS , x) refined core every CS
c , x) v (wS (CS
c )).
pS (CS

(5)

c containing CS |S
words, payoff every coalition structure CS
c . Note
least large get resources invested CS
c
c
limit coalition structures CS CS = CS |S CS N \ S,
obtain sensitive core condition.
4.1.4 PTIMISTIC C ORE
optimistic arbitration function, Ao , shown
X
c ) + w(CS 0 )) +
c , x)},
Ao (CS , x, S) = sup{v (wS (CS
v(c d(c)) pN \S (CS \ CS
c
cCS \CS

863

fiZ ICK , ARKAKIS , & E LKIND

c CS |S CS
c CS
supremum taken coalition structures CS
c . Thus, order outcome (CS , x) optimistic
deviations CS 0 CS \ CS
c CS containing
core, must case every set N , every coalition structure CS
0
c
CS |S every deviation CS CS \ CS holds
X
c , x). (6)
c ) + w(CS 0 )) +
v(c d(c)) pN \S (CS \ CS
pS (CS , x) v (wS (CS
c
cCS \CS

c , CS 0 ) denote coalition structure formed remains CS \ CS
c
Let (CS \ CS
P
0
withdrawn resources CS according CS . obtain cCS \CS
c v(c d(c)) =
0

c , CS )). Thus, subtracting p (CS \ CS
c , x) sides inequality (6)
v((CS \ CS
N
c
c
using fact p (CS \ CS , x) = v(CS \ CS ), rewrite inequality (6)


c , x) v (wS (CS
c ) + w(CS 0 )) v(CS \ CS
c ) v((CS \ CS
c , CS 0 )) .
pS (CS

(7)

optimistic core stability condition thus similar refined core stability condition; however,
c willing assume
also allowed withdraw resources coalitions outside CS
marginal costs withdrawal.
Example 4.3. Consider following example. three players, N = {1, 2, 3},
following characteristic function:


0
0
1
1
1
1
v 4 = 1,
v 2 = 40,
v 41 = 20,
0

0

2

v(c) = 0 every coalition c [0, 1]3 . First, observe optimal coalition
structure (up order coalitions) CS = (c1 , c2 , c3 ),
0
0

1
1
1
1
c2 = 41 ,
c3 = 41 .
c1 = 2 ,
0

2

2

words, players 1 2 collaborate one project (which requires 100% player 1s resources,
50% player 2s resources), generate revenue 40; players 2 3 work two
identical projects (each requiring 25% player 2s resources 50% player 3s resources),
generating revenue 40 total well. Now, suppose payoffs divided according
x = (x1 , x2 , x3 ),
0
0
40
x2 = 0 ,
x3 = 4 .
x1 = 0 ,
0

20

16

conservative arbitration function, payoff division stable: subset players
receives less make own. However, sensitive arbitration function,
longer case: player 2 must receive payoff least 2 c1 , combined payoff
least 2 c2 c3 .
Now, let us suppose following payoff division proposed instead: = (y1 , y2 , y3 ),

38
0
0
y2 = 0 ,
y3 = 2 .
y1 = 2 ,
0

20

864

18

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

outcome (CS , y) stable respect sensitive arbitration function; however,
stable respect refined arbitration function: player 2 withdraw contribution c2
earn strictly more. Thus, order imputation r-stable, player 2 must receive least
2 c1 , least 1 c2 c3 .
Example 4.3 illustrates interesting phenomenon: lenient arbitration functions force
payments spread out: player 2 receives payoff, payoff must received
distributed manner lenient reactions deviations assumed.

5. Non-emptiness Arbitrated Cores
Core outcomes highly desirable classic cooperative games OCF games. Thus,
important find conditions characteristic function OCF game would guarantee
non-emptiness arbitrated core, well identify classes OCF games whose arbitrated
core always non-empty, natural arbitration functions. note questions
beand beenlooked lens computational complexity. is, one ask
whether exist polynomial-time algorithms decide whether arbitrated core non-empty
find outcome arbitrated core, either general model specific classes OCF
games. question explored Chalkiadakis et al. (2010) Zick et al. (2012),
paper consider computational complexity issues focus instead characterization
results (see, however, companion paper Zick et al., 2014).
characterization results similar spirit celebrated BondarevaShapley condition
core non-emptiness classic cooperative games (Bondareva, 1963; Shapley, 1967).
briefly state condition. Given set P
N = {1, . . . , n}, collection weights (S )SN
called balanced 0 N S:iS = 1 N . view balanced
collection weights way agent partially participate sets contain i,
contribution specified respective weight.
Given cooperative game G = hN, ui u : 2N
PR+ , say G balanced
every balanced collection weights (S )SN holds SN u(S) u(N ).
Theorem 5.1 (BondarevaShapley Theorem). cooperative game G = hN, ui u : 2N R+
non-empty core balanced.
important feature characterization stated terms characteristic
function itself, explicitly refer outcomes game. follows, describe
similar characterizations OCF games, conservative, sensitive refined arbitration functions.1 Specifically, arbitration functions, given OCF game G = hN, vi
coalition structure CS CS(N ), characterize set imputations x I(CS )
(CS , x) respective arbitrated core G. limit attention optimal coalition structures, i.e., assume v(CS ) = v (eN ): CS optimal, outcome form
(CS , x) arbitrated core G arbitration functions, since grand
coalition profitably deviate (CS , x) (Chalkiadakis et al., 2010).
1. case conservative arbitration function considered Chalkiadakis et al. (2010); reproduce
results completeness facilitate comparison two cases.

865

fiZ ICK , ARKAKIS , & E LKIND

5.1 Conservative Core
Given OCF game G = hN, vi coalition structure CS = (c1 , . . . , cm ), say
collection non-negative weights {(rj )m
j=1 ; (S )SN } c-balanced
P respect CS every
N every coalition cj supp(cj ) holds rj + S:iS = 1. Chalkiadakis
et al. (2010) show following result.
Theorem 5.2 (Chalkiadakis et al., 2010, Thm. 2). Given OCF game G = hN, vi optimal coalition structure CS CS(N ), exists outcome x I(CS ) (CS , x)
conservative core G every collection non-negative weights {(rj )m
j=1 ; (S )SN }
c-balanced respect CS holds

X

rj v(cj ) +

j=1

X

v (eS ) v (eN ).

SN

first observation proof Theorem 5.2, given work Chalkiadakis et al.
(2010), gap. Appendix contains correction proof.
provide alternative characterization OCF games non-empty conservative
core, establishing connection conservative core OCF game core
related classic cooperative game.
Given OCF game G = hN, vi, discrete superadditive cover classic cooperative game
G = hN, Uv i, Uv (S) = v (eS ). Simply put, value set N G
make function v forming coalition structure. show
conservative core G non-empty core G non-empty.
Theorem 5.3. conservative core OCF-game G = hN, vi non-empty
core discrete superadditive cover G = hN, Uv non-empty.
Proof. argued conservative core G non-empty, exists outcome
(CS , x) N pS (CS , x) v (eS ). Note CS optimal coalition
structure G, since v(CS ) = pN (CS , x) v (eN ). Consider payoff vector p = (p1 , . . . , pn )
pi = pi (CS , x)
P N . follows p core G. Indeed, since CS
optimal, ni=1 pi = v(CS ) = v (eN ) = Uv (N ), every N
p(S) = pS (CS , x) v (eS ) = Uv (S).
Conversely, let p = (p1 , . . . , pn ) payoff vector core G. Fix coalition structure
CS = (c1 , . . . , cm ) v(CS ) = v (eN ). use p construct imputation
x I(CS ) (CS , x) conservative core G.
Given imputation z I(CS ), color agents N follows: green pi (CS , z) >

p ; red pi (CS , z) < pi white pi (CS , z) = pi . Green agents better (CS , z)
p, red agents worse (CS , z) p, white agents indifferent.
Now, suppose z I(CS ) agent respective coloring
green. Since CS optimal, means agent red either. Thus, agents white.
turn implies N pS (CS , z) = p(S) Uv (S) = v (eS ), (CS , z)
conservative core. Thus, need show exists z I(CS )
agent respective coloring green.
Let F : I(CS ) R defined follows:
F (z) =

n
X

max{0, pi pi (CS , z)}.

i=1

866

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

function F measures agents total unhappiness outcome (CS , z) compared
p. F continuous function (it sum maxima functions continuous z),
I(CS ) compact set. Thus, exists imputation x I(CS ) minimizes value
F . pick x arg min F (z) minimize number white agents respective
coloring N .
suppose exist green agent g, non-green agent coalition c CS
g, supp(c) x(c)g > 0. > 0 setting x(c)g = x(c)g
x(c)i = x(c)i + (i.e., transferring amount g within coalition c) results
valid payoff division CS keeps g green. white prior transfer,
becomes green (and value F change). contradiction fact x
minimizes number white agents. hand, red, transfer decreases
contribution F (while gs contribution F remains 0), contradiction fact
x arg min F (z). means green agents get zero payoff coalitions non-green
agents. Let us denote set green agents Sg .
pSg (CS , x) = pSg (CS |Sg , x) v (eSg ).
hand, Sg 6= , since Sg pi (CS , x) > pi , obtain
pSg (CS , x) > p(Sg ) Uv (Sg ) = v (eSg ).
contradiction shows Sg = , argued case agents white.
completes proof.
following corollary immediately implied proof Theorem 5.3.
Corollary 5.4. Consider OCF game G = hN, vi. every payoff vector p = (p1 , . . . , pn )
core G every optimal coalition structure CS CS(N ), exists x I(CS )
pi = pi (CS , x) N .
Corollary 5.4 enables us generalize following well-known result classic cooperative
games. Aumann Dreze (1974) show CS CS 0 optimal (non-overlapping) coalition
structures G = hN, ui (CS , p) core G (CS 0 , p) also core G.
words, CS opt set optimal coalition structures G, Istab set
stable payoff divisions G, set core outcomes G CS opt Istab . Using
Corollary 5.4, extend result OCF games conservative arbitration function.
Corollary 5.5. Consider OCF game G = hN, vi. every pair optimal coalition structures
CS , CS 0 CS(N ) every imputation x I(CS ) (CS , x) conservative core,
exists imputation x0 I(CS 0 ) (CS 0 , x0 ) conservative core G
pi (CS , x) = pi (CS 0 , x0 ) N .
5.1.1 C ONVEXITY OCF G AMES R EVISITED
classic cooperative games, convexity, supermodularity, characteristic function wellknown sufficient condition non-emptiness core (Shapley, 1971). detail,
recall cooperative game G = hN, vi said supermodular every pair sets S,
N every R N \ holds
v(T R) v(T ) v(S R) v(S).
867

fiZ ICK , ARKAKIS , & E LKIND

Supermodular games often referred convex games literature; however, avoid confusion notions convexity considered paper, use term supermodularity.
Shapley (1971) proves following result.
Theorem 5.6. cooperative game G supermodular, core non-empty.
order extend Theorem 5.6 OCF games, Chalkiadakis et al. (2010) propose following
notion convexity OCF games.
Definition 5.7 (OCF convexity, Chalkiadakis et al., 2010). OCF game OCF-convex
every pair sets S, N , every R N \ , every outcome (CS , xS ) F(S),
every outcome (CS , xT ) F(T ), every outcome (CS SR , xSR ) F(S R) following
condition holds: pi (CS , xS ) pi (CS SR , xSR ) outcome
(CS R , xT R ) F(T R)
(1) pi (CS , xT ) pi (CS R , xT R ) ;
(2) pi (CS SR , xSR ) pi (CS R , xT R ) R.
Intuitively, Definition 5.7 simply means larger coalitions offer lucrative options
players join them, compared smaller coalitions.
Chalkiadakis et al. (2010) show OCF convexity sufficient condition nonemptiness conservative core.
Theorem 5.8 (Chalkiadakis et al., 2010, Thm. 3). OCF game G OCF-convex,
conservative core non-empty.
hand, combining Theorem 5.3 Theorem 5.6, obtain following sufficient
condition conservative core non-emptiness.
Proposition 5.9. Consider OCF game G. G = hN, Uv supermodular, conservative
core G non-empty.
argue Proposition 5.9 strictly stronger Theorem 5.8, showing
supermodularity G strictly weaker condition OCF-convexity G. first show
OCF-convexity G implies supermodularity G. present example game
G = hN, vi G supermodular, G OCF-convex (Example 5.13).
implement first step plan, first establish following crucial proposition,
may seem counterintuitive first sight. proof based coloring arguments similar
ones used proofs Theorems 3.4 5.3.
Proposition 5.10. every pair sets S, N every pair optimal
coalition structures CS CS(S), CS CS(T ), exist imputations x I(CS )
I(CS ) pi (CS , x) = pi (CS , y) S.
Proof. Fix sets optimal coalition structures CS CS(S), CS CS(T ).
first establish find imputations x0 I(CS ) y0 I(CS ) pi (CS , x0 )
pi (CS , y0 ) S. show use fact prove original claim.
Lemma 5.11. exist imputations x0 I(CS ) y0 I(CS ) pi (CS , x0 )
pi (CS , y0 ) S.
868

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

Proof. Given pair imputations x I(CS ), I(CS ), color agents follows:
agent green pi (CS , y) > pi (CS , x) \ pi (CS , y) > 0; red
pi (CS , y) < pi (CS , x); white otherwise.
define mapping : I(CS ) I(CS ) R setting
X
D(x, y) =
max{0, pi (CS , x) pi (CS , y)}.


function continuous compact set, thus attains minimum value point
(x, y) I(CS ) I(CS ). Among points, pick one smallest number white
agents denote (x0 , y0 ). Let q = pi (CS , y0 ) , pi = pi (CS , x0 ) S.
show q pi S.
Assume sake contradiction case. D(x0 , y0 ) > 0
least one red agent . Since v (T ) v (S), also green agent .
Now, consider green agent g non-green agent i. Suppose
(a) exists coalition c CS g, supp(c) y0 (c)g > 0,
(b) exists coalition c CS g, supp(c) x0 (c)i > 0.
case (a) modify y0 making g transfer small amount payoff i, case (b)
modify x0 making transfer small amount payoff g; choose transfer
small enough g remains green. white, becomes green, red,
lowers contribution D. cases, get contradiction choice (x0 , y0 ). Thus,
coalition c exists.
Let Sg denote set green agents S, let Sng = \ Sg . x0 , every Sng
gets payoff coalitions CS whose support contains members Sg . Similarly, y0
green agents get payoff coalitions CS contain members Sng .
Now, suppose modify CS agents Sng abandon existing coalitions
form coalitions form among CS instead. Denote resulting coalition
structure CS 0 . define imputation z0 CS 0 follows. imputation z0 coincides
y0 c supp(c) Sng = , coincides x0 coalition c0 formed
members Sng . remaining coalitions CS 0 involve agents Sng agents
\ Sng , may suffered reduction value relative CS Sng withdrew
resources them; coalitions z0 distributes value arbitrarily among members
Sng .
argued above, (CS , x0 ) members Sng receive payoffs coalitions
fully control, pi (CS 0 , z0 ) pi (CS , x0 ) Sng . Further, since least one
agent red, pSng (CS , x0 ) > pSng (CS , y0 ). hand, (CS , y0 )
members \ Sng receive payoff coalitions members Sng , letting Sng
receive payoffs coalitions affect payoff members
\ Sng receive, relative received (CS , y0 ). Thus, \ Sng holds
pi (CS 0 , z0 ) = pi (CS , y0 ). Hence, obtain
v(CS 0 ) = pT (CS 0 , z0 )
\Sng

= p
> p

\Sng

(8)

0

(CS , z0 ) + p

Sng

(CS , y0 ) + p




= v(CS ) = v (e ).
869

0

(CS , z0 )

Sng

(CS , y0 )

fiZ ICK , ARKAKIS , & E LKIND

contradiction shows set red agents empty hence pi (CS , y0 ) pi (CS , x0 )
S.
use Lemma 5.11 complete proof Proposition 5.10. Define
P (CS , CS ) = {(x, y) I(CS ) I(CS ) | pi (CS , y) pi (CS , x) S}.
Lemma 5.11 implies P (CS , CS ) empty. Moreover, P (CS , CS ) compact; thus,
contains point (x, y) minimizes value pS (CS , y) P (CS , CS ).
Let (CS , CS ) set points (x, y) P (CS , CS ) minimize pS (CS , y);
complete proof, identify point (x1 , y1 ) (CS , CS ) pS (CS , y1 ) =
pS (CS , x1 ) = v (eS ).
Given point (x, y) (CS , CS ), color agents follows: green
pi (CS , y) > pi (CS , x), white otherwise. Note that, since (x, y) P (CS , CS ),
contains white agent i, pi (CS , y) = pi (CS , x). Let (x1 , y1 ) point
(CS , CS ) maximizes number green agents .
Now, consider green agent g white agent i. Suppose
(a) g S, , coalition c CS g, supp(c) y(c)g > 0,
(b) g, S, coalition c CS g, supp(c) x(c)i > 0.
case (a) could transfer small amount payoff g CS either make
green thereby increase number green vertices (if S) lower total payoff
CS (if \ S), case (b) could transfer small amount payoff g CS
make green (again, choose transfer small enough g remains green).
cases, get contradiction choice (x1 , y1 ).
Let Sg set green agents S, let Sw = \ Sg set white agents
S. shown (CS , x1 ) members Sw receive payoffs
joint coalitions members Sg , (CS , y1 ) members Sg receive payoffs joint coalitions members Sw , pSw (CS , x1 ) v (eSw )
pSg (CS , y1 ) v (eSg ). Thus, Sg 6= ,
v (eS ) = pS (CS , x1 )

(9)

Sg

Sw

Sg



= p (CS , x1 ) + p

(CS , x1 )

< p (CS , y1 ) + v (eSw )
v (eSg ) + v (eSw ).
Thus, Sg 6= , v (eS ) < v (eSg ) + v (eSw ), contradiction superadditivity v .
conclude Sg = , implies pi (CS , x1 ) = pi (CS , y1 ) S.
Armed Proposition 5.10, ready prove following theorem.
Theorem 5.12. G = hN, vi OCF-convex G = hN, Uv supermodular.
Proof. Consider sets S, T, R N R N \ ; demonstrate
Uv (S R) Uv (S) Uv (T R) Uv (T ). Set 0 = R, 0 = R, consider coalition
0
structures CS CS(S), CS 0 CS(S 0 ) v(CS ) = v (eS ), v(CS 0 ) = v (eS ).
870

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

Proposition 5.10, exist imputations xS xS 0 pi (CS , xS ) = pi (CS 0 , xS 0 )
S; thus, total payoff R (CS 0 , xS 0 ) v (eSR ) v (eS ).
Consider outcome (CS , xT ) FT v(CS ) = v (eT ); since G OCF-convex,
outcome (CS 0 , xT 0 ) better members 0 (CS 0 , xS 0 ), also pays
total least v (eT ). payoff R (CS 0 , xT 0 ) v(CS 0 ) pT (CS 0 , xT 0 ).
v(CS 0 ) v (eT R ) pT (CS 0 , xT 0 ) v (eT ), payoff R (CS 0 , xT 0 )
v (eT R ) v (eT ). Finally, OCF convexity G implies payoff R (CS 0 , xT 0 )
least large payoff (CS 0 , xS 0 ). Combining inequalities, get
Uv (S R) Uv (S) = v (eSR ) v (eS )
= pR (CS 0 , xS 0 )
pR (CS 0 , xT 0 )
v (eT R ) v (eT )
= Uv (T R) Uv (T ),
concludes proof.
Theorem 5.12 shows OCF game OCF-convex, discrete superadditive cover
supermodular. show converse always hold, i.e., supermodularity
strictly weaker property OCF convexity.
Example 5.13. Consider game G = hN, vi N = {1, 2, 3} v defined follows:
1
0
v 0 = 1, v 1 = 1;
0

0

v

1

= 6, v

v

1

= 4, v

.5
0
0
1

0
.5
1

0
1
1

= 3;

= 4;

v(c) = 0 partial coalition c [0, 1]3 .

Uv ({1}) = Uv ({2}) = 1, Uv ({3}) = 0;
Uv ({1, 2}) = 6, Uv ({1, 3}) = Uv ({2, 3}) = 4;
Uv (N ) = 9.
One check Uv indeed supermodular.
However, G

Indeed,
OCF-convex.
set =
0
0
1
0
0
1
{3}, = {1, 3}, R = {2}, CS =
, CS =
, CS SR =
. Assume
1
1
1
players R share payoffs according xT = ((0, 0, 4)) xSR =
((0, 4, 0)), respectively. G OCF-convex, exist coalition structure CS
player 3 earns least 4 player 2 earns
least 4. However,
impossible: player 3 earns
1
0
0
least 4, CS contains either c = 0 c = 1 . c formed, player 2 get
1

1

1; c0 formed, players 2 3 together get 4. Thus, way
satisfy agents demands.
871

fiZ ICK , ARKAKIS , & E LKIND

5.2 Sensitive Core
Recall sensitive arbitration function, agent withhold payments deviators coalitions participates hurt deviation. Section 4.1, obtained
following characterization sensitive core: outcome (CS , x) sensitive core
CS optimal coalition structure, set N holds
N \ total payoff receives investing resources coalitions involving
least large marginal returns investing resources working (see
formula (4)).
Let CS = (c1 , . . . , cm ) optimal coalition structure. Using characterization above,
conclude deciding whether sensitive core contains outcome form (CS , x)
equivalent determining whether value following linear program equals v (eN ).

P

min

P

j=1 isupp(cj )

(10)

xij v(cj )

P

s.t.

xij
cj CS

isupp(cj )

pS (CS , x) v (wS (CS |S ) + wS (CS )) v (wS (CS |S )) N, N \
note linear program (10) require xij 0 cj CS
supp(cj ). argument presented Appendix shows constraints
safely omitted. revisit point proof Theorem 5.15 context
refined core.
Consider dual linear program.
max


P

rj v(cj ) +

j=1

s.t.

P

P

S,T (v (wS (CS |S ) +wS (CS )) v (wS (CS |S ))) (11)

SN N \S

rj +

P

P

S:iS

N \S:
supp(cj )T 6=

S,T = 1
rj 0
S,T 0

cj CS , supp(cj )
cj CS
N, N \


say collection non-negative
P weights
P {(rj )j=1 ; (S,T )SN ;T N \S } s-balanced
respect CS = (c1 , . . . , cm ) rj + S:iS N \S:supp(cj )T 6= S,T = 1 cj CS
supp(cj ). Applying linear programming duality linear programs (10) (11), obtain
following theorem.

Theorem 5.14. sensitive core game G = hN, vi empty exists
coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ) every collection
non-negative weights {(rj )m
j=1 ; (S,T )SN ;T N \S } s-balanced respect CS holds


X
j=1

rj v(cj ) +

X

X

S,T (v (wS (CS |S ) + wS (CS )) v (wS (CS |S ))) v (eN ).

SN N \S

872

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

Theorem 5.14 similar Theorem 5.2, presents criterion non-emptiness
conservative core. main difference Theorem 5.2 considers collections weights
contain single weight set N , whereas sensitive core consider collections
weights contain weight S,T pair disjoint sets S, N .
5.3 Refined Core
sensitive arbitration function, deviating players need decide nondeviating players wish work more. contrast, refined arbitration
function, deviators look coalitions non-deviators one one, decide
worth keeping. provide characterization games nonempty refined core similar characterizations games non-empty conservative
sensitive cores (Theorem 5.2 Theorem 5.14, respectively). Employing characterization,
describe class OCF games non-empty refined core.
Section 4.1, obtained following characterization outcomes refined core: given
coalition structure CS , imputation x I(CS ) (CS , x) refined core
pS (CS 0 , x) v (wS (CS 0 )) every N every coalition structure CS 0 CS
containing CS |S .
follows, given subset agents N coalition structure CS , write [CS ]S =
{CS 0 CS | CS |S CS 0 }. Also, given coalition structure CS = (c1 , . . . , cm ), say
collection non-negative weights {(rj )m
j=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respect
CS cj CS supp(cj ) holds
X
X
rj +
S,CS 0 = 1.
S:iS CS 0 [CS ]S :
cj CS 0

ready present characterization.
Theorem 5.15. refined core OCF game G = hN, vi non-empty
exists coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ) every collection
weights {(rj )m
j=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respect CS holds

X

rj v(cj ) +

X

X

S,CS 0 v (wS (CS 0 )) v (eN ).

SN CS 0 [CS ]S

j=1

Proof. Fix coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ), consider following linear program.

P

min

P

j=1 isupp(cj )

s.t.

P

xij

(12)

xij v(cj )

cj CS

isupp(cj )

pS (CS 0 , x) v (wS (CS 0 )) N, CS 0 [CS ]S
claim refined core G contains outcome form (CS , x) value
linear program v (eN ).
873

fiZ ICK , ARKAKIS , & E LKIND

see case, suffices observe that, argument Appendix A,
omit constraints form xij 0 cj CS supp(cj ). fact, turns
refined core, much simpler explanation holds: Non-negativity xij implied
stability constraints. see this, consider coalition cj supp(cj ). supp(cj ) = {i},
xij = v(cj ) 0 done. Otherwise, consider coalition structure CS 0 = (CS |{i} , cj ).
total payoff CS 0 pi (CS 0 , x) = pi (CS |{i} , x)+xij = v(CS |{i} )+xij . constraint
corresponds = {i} CS 0 states payoff must least v (w{i} (CS 0 )),
least v(CS |{i} ), hence xij 0.
Consider dual linear program (12).
max


P

P

rj v(cj ) +

j=1

P

rj +

s.t.

S,CS 0 v (wS (CS 0 ))

(13)

SN
CS 0 [CS ]S

S,CS 0 = 1

cj CS , supp(cj )

S,CS 0 0

N, CS 0 [CS ]S

S:iS
CS 0 [CS ]S :cj CS 0

rj 0

cj CS

Observe dual constraints (13) equalities since xij unconstrained (12). Note
also every feasible solution (13) corresponds collection non-negative weights
r-balanced respect CS . claim follows standard linear programming duality
argument.
Theorem 5.15 enables us identify interesting class OCF games non-empty refined
core. Recall function f : Rn R homogeneous degree k, k-homogeneous,
f (x) = k f (x) R+ . Intuitively, means f scales consistent manner:
players invest twice much resources coalition, get 2k times profit. returns
scale positive k 1 negative k < 1.
Corollary 5.16. Consider OCF game G = hN, vi. v homogeneous degree k 1,
refined core G non-empty.
Proof. Consider coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ) collection
non-negative weights {(rj )m
j=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respect CS .
According Theorem 5.15, suffices show

X
j=1

rj v(cj ) +

X

S,CS 0 v (wS (CS 0 )) v (eN ).

(14)

SN
CS 0 [CS ]S

First, since v k-homogeneous,

X
SN
CS 0 [CS ]S


S,CS 0 v (wS (CS 0 )) v


874


X
SN
CS 0 [CS ]S


S,CS 0 wS (CS 0 )
.

(15)

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

S,CS 0 wS (CS 0 ) .

P

Denote i-th coordinate

SN
CS 0 [CS ]S

=

X

X

S:iS CS 0 [CS ]S

=


X

cij

j=1

X
S:iS

=

cij

cj CS 0

X

S,CS 0

CS 0 [CS ]
cj CS 0


X

X

S,CS 0

S:

cij (1 rj ),

j=1

P
first transition derived fact wi (CS 0 ) = cj CS 0 cij S,
second transition uses fact {(rj )m
j=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respect
CS . conclude right-hand side equation (15) upper-bounded
v(


X
(1 rj )cj ).
j=1

consider first summand left-hand side (14). k-homogeneity v ,

X

rj v(cj )

j=1


X


X
rj v (cj ) v (
rj cj ).

j=1

j=1

Using superadditivity v , obtain left-hand side (14) upper-bounded



X
X
X
v(
rj cj +
(1 rj )cj ) = v (
cj ) = v (eN ).
j=1

j=1

j=1

concludes proof.
fact, proof Corollary 5.16 shows stronger claim: v k-homogeneous, every
optimal coalition structure CS admits imputation x I(CS ) (CS , x) refined
core. case general; exist games optimal coalition structures
cannot stabilized refined arbitration function, others can. illustrated
following example.
Example 5.17. Consider following three-player game. four types tasks: task
type t1 completed player 1 alone, requires resources, worth 5. task
type t12 requires 50% player 2 player 1s resources worth 10. task type T12
requires resources players 1 2 worth 20. Finally, task type t23 requires
player 3s resources 50% player 2s resources, worth 9. Consider coalition
structures CS = (c1 , c2 ) CS 0 = (c01 ),
.5
.5
1
c1 = .5 , c2 = .5 , c01 = 1 .
0

0

875

0

fiZ ICK , ARKAKIS , & E LKIND

easy see CS CS 0 optimal game. Simply put, best players 1
2 work together earn total 20 (by completing t12 twice T12 once), player 3
makes profit.
First, claim CS cannot stabilized respect refined arbitration function.
reason outcome (CS , x) refined core, must case player 2 gets
least 9 coalitions c1 c2 . However, means player 1 gets 2
working player 2, get 5 working alone. hand, let
imputation CS 0 splits payoff T12 evenly players 1 2. (CS 0 , y)
refined core.
Finally, note one cannot immediately employ LP duality argument characterizing
OCF games non-empty optimistic core. difficulty optimistic arbitration
function number possible deviations infinite: deviating set needs specify amount
resources withdraws coalition non-deviators. words, linear program
describes optimistic core infinitely many constraints, dual infinitely many
variables.

6. Conclusions Future Work
main contribution work concept arbitration functions, analysis
impact arbitration stability cooperative games overlapping coalitions. concept
allows us put three notions stability proposed Chalkiadakis et al. (2010) broader
context derive new notions stability sensitive core.
Perhaps interesting results connection OCF games conservative arbitration function discrete superadditive covers. sense, shows
players pessimistic assume post-deviation payoffs given
conservative arbitration function, little benefit employing OCF framework.
words, main value OCF approach lies ability model non-trivial post-deviation
interactions. Thus, OCF framework eminently suitable settings agents reason expect deviating collaborative projects cause agents
boycott them. believe settings becoming increasingly common modern
interconnected society, multitasking norm collaboration necessary succeed.
reaction non-deviators deviation plays decisive role analysis many strategic
interactions. example, Ackerman Branzei (2014) use concept arbitration function
analysis Nash equilibrium pairwise equilibrium. Also, Branzei, Michalak, Rahwan,
Larson, Jennings (2013) study matchings externalities; model viewed
application idea arbitration functions matching problems. fact, strategic setting
deviating set must still interact non-deviators one reason nondeviators behavior deviation occurs. common make worst-case assumption,
always appropriate realistic. Thus, notion similar arbitration functions may
useful beyond setting cooperative games. instance, players interact market,
behavior governed contracts (think wireless service provider consumer buying
new data plan), clearly specify penalties failing fulfill ones obligations (in case
wireless service providers, typically case withdrawal agreed-upon contract
entails monetary penalty, i.e. worse-than-conservative reaction deviation). contracts
876

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

viewed arbitration functions. Thus, concept arbitration function may useful
modeling market interactions contracts.
6.1 Future Work
Section 5, provided criteria core non-emptiness several arbitration functions.
conservative refined core, also identified simple sufficient conditions
core non-empty (supermodularity discrete superadditive cover first-order homogeneity v , respectively). would useful obtain similar results natural notions
arbitration, sensitive arbitration function optimistic arbitration function.
Another interesting research direction consider inverse problem: given
OCF game, generous arbitration function arbitrated core
game empty? formally, given game G, let us call arbitration function maxstable G Core(G, A) 6= , A0 A0 Core(G, A0 ) = .
Simply put, arbitration function max-stable provides largest possible payoffs
deviators without destabilizing G. would interesting prove arbitration function
max-stable class OCF games, or, ambitiously, completely characterize set
max-stable arbitration functions. line enquiry similar spirit concepts least
core (Maschler et al., 1979), cost stability (Bejan & Gomez, 2009; Bachrach, Elkind, Meir,
Pasechnik, Zuckerman, Rothe, & Rosenschein, 2009), taxation (Zick, Polukarov, & Jennings,
2013).
note model deviators allowed withdraw resources coalitions nondeviators, add resources coalitions. implications general definition,
deviators add withdraw resources coalitions non-deviators,
worth exploring well.
analysis focuses core cooperative games overlapping coalitions. is,
extent, reflection state art study classic cooperative games: core
related notions (i.e., -core least core) studied greater detail
cooperative solution concepts (barring, perhaps, Shapley value). analysis various
solution concepts OCF games, nucleolus, kernel, bargaining set,
relations one another, would greatly improve understanding overlapping coalition
formation. solution concepts OCF games briefly discussed
Zick Elkind (2011), analysis far complete.
Finally, would interesting study models dynamic coalition formation cooperative
games overlapping coalitions. models explored classic cooperative
games (see, e.g., Arnold & Schwalbe, 2002; Lehrer & Scarsini, 2013), games overlapping coalitions fully cooperative agents (Shehory & Kraus, 1996), immediately clear
extend prior work arbitrated OCF games. settings, arbitration functions
used method controlling coalition formation process: outcome stage
coalition formation process stable respect currently used arbitration function,
permissive reaction deviation allowed future rounds; outcome unstable, players
assumed less tolerant towards deviators. Thus, controlling extent players
allowed deviate, one trade speed coalition formation process quality
resulting outcome.
877

fiZ ICK , ARKAKIS , & E LKIND

Acknowledgments
Part work done Y. Zick E. Elkind affiliated Nanyang Technological University, Singapore. Y. Zick supported Singapore International Graduate Award
(SINGA), provided Agency Science, Technology Research (A*STAR). E. Markakis
supported European Union (European Social Fund--ESF) Greek national funds
Operational Program Education Lifelong Learning National Strategic Reference Framework (NSRF)Research Funding Program: THALES. Investing knowledge society
European Social Fund. E. Elkind supported National Research Foundation
(Singapore) grant NRF RF2009-08. authors would like thank anonymous JAIR
reviewers well anonymous reviewers earlier versions work (Zick & Elkind, 2011;
Zick, Markakis, & Elkind, 2012). Y. Zick would also like thank anonymous reviewers
Ph.D thesis (Zick, 2014), parts incorporated paper.

Appendix A. Note Characterization Conservative Core
purpose appendix fill gap proof characterization conservative core given Chalkiadakis et al. (2010) (see Theorem 5.2). argument also
implications characterization sensitive core (Section 5.2).
proof Theorem 5.2 proceeds follows. Given optimal coalition structure CS =
(c1 , . . . , cm ), consider following linear program:
Pm P

min


isupp(cj ) xj

isupp(cj ) xj v(cj )
j=1

P

s.t.

P



Pm

j {1, . . . , m}

(16)

v (eS ) N


j=1 xj

dual LP (16)
max
s.t.

Pm

j=1 rj v(cj )

rj +

+
P

P

SN

S:iS

v (eS )

=1

j, supp(cj )

rj 0

j {1, . . . , m}

0

N

(17)

Chalkiadakis et al. (2010)
P argue LP (16) describes constraints conservative core,
exception isupp(cj ) xij required least v(cj ) rather equal v(cj ).
Thus,
solution LP (16), (CS , x) conservative core
P x
Pis optimal
= v(CS ) = v (eN ). LP duality implies value LP (17)

x
j=1
isupp(cj ) j
v (eN ) CS stabilized respect conservative arbitration
function.

problem argument
PLP (16) require variables
P xj nonnegative, allows us rj + S:iS = 1 rather rj + S:iS 1
dual LP. However, allow variables xij take negative values, effectively
breaking payoff distribution requirement imputations. mention that, contrast,
BondarevaShapley theorem acceptable impose non-negativity constraints explicitly,
since stability constraints imply pi u({i}) 0. However, conservative core get
878

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

v (e{i} ) N , imply individual xij non-negative.
words, Chalkiadakis et al. (2010) show every c-balanced OCF game every optimal
coalition structure CS = (c1 , . . . , cm ) game admit pre-imputation x (CS , x)
conservative core (recall x = (x1 , . . . , xm ) pre-imputation
CS = (c1 , . . . , cm )
Pfor
n
n
j = 1, . . . , holds xj vector R i=1 xij = v(cj )
cij = 0 xij = 0, i.e., preimputation satisfies conditions imputation, except
non-negativity). argue one transform pre-imputation imputation.

j:isupp(cj ) xj

P

Theorem A.1. exists pre-imputation x satisfies constraints LP (16),
exists imputation x I(CS ) pi (CS , x) = pi (CS , x) N .
Proof. Let Ipre (CS ) denote set pre-imputations coalition structure CS . Given
point x Ipre (CS ), define graph (x) = hV, Ei follows: vertices (x)
V = {(i, j) | cj CS , supp(cj )} ,
set edges E = E1 E2 ,



E1 = (i, j), (i, j 0 ) | supp(cj ) supp(cj 0 ), j 6= j 0 ,

E2 =





(i, j), (i0 , j) | i, i0 supp(cj ), xij > 0 .

is, E1 consists pairs (i, j), (i, j 0 ) supp(cj ) supp(cj 0 ), E2
consists pairs (i, j), (i0 , j) i, i0 supp(cj ) cj CS xij > 0. edge
E2 means transfer small amount payoff i0 coalition cj , still maintain
positive payoff cj .
Further, given point x Ipre (CS ), set
TN (x) =

X
n
X

min{0, xij }.

j=1 i=1

Fix arbitrary point x Ipre (CS ), consider set
Ipre (CS , x) = {y Ipre (CS ) | pi (CS , y) = pi (CS , x) N TN (y) TN (x)}.
set Ipre (CS , x) compact TN continuous, exists point x Ipre (CS , x)
maximizes TN Ipre (CS , x).

Suppose exists coalition cj agent supp(cj ) xij < 0. Note
(x) must edge E1 leaves (i , j ): otherwise, paid cj ,
case would
p (CS , x) =



X







xij = xij < 0 v (e{i } ),

j=1

violating respective constraint LP (16).
Let C minimum-length directed cycle (x) contains edge ((i , j ), (i , j0 ))
cj0 CS well edges E2 . Note C contains path form
(i, j1 ) (i, j2 ) (i, j3 );
879

fiZ ICK , ARKAKIS , & E LKIND

edge ((i, j1 ), (i, j3 )) E1 , contradiction C minimum length.
Moreover, C cannot contain path form
(i1 , j) (i2 , j) (i3 , j);
indeed, ((i1 , j), (i2 , j)) E2 , agent i1 receives positive payoff cj , hence
edge ((i1 , j), (i3 , j)) also E2 , contradiction choice C.
conclude minimum-length cycle passes (i , j ) intersects E2 must
form
(i , j ) (i , j0 ) (i1 , j0 ) (i1 , j1 ) (i2 , j1 ) (it , j ) (i , j ).
means receives positive payoff cj0 , i1 receives positive payoff cj1 , i2
receives positive payoff cj2 and, general, i` receives positive payoff coalition
cj` 1 ` 1. Finally, player receives positive payoff cj .
Now, pick satsifying




0 < < min{xij0 , xij11 , . . . , xjt1
, xijt },
t1
let = (y1 , . . . , ym ) pre-imputation obtained x transferring payoff


i1 cj0 , i` i`+1 cj` ` =
Pfrom ii cj .
P1, . . . , i1,
x


cj CS .
pi (CS , y) = pi (CS , x) N , isupp(cj ) yj =
isupp(cj ) j
Therefore, optimal solution LP (16). However, TN (y) > TN (x), contradiction
choice x. conclude (x) contains cycles pass (i , j ) intersect E2 .
Let us define
Np = {i N | path (i , j ) (i, j) cj }.
every Np every i0 N \Np , graph contains edge form ((i, j), (i0 , j)).
Hence, i, i0 supp(cj ) xij 0. is, every coalition involves agents Np
agents N \ Np payoffs split share agent Np non-positive.
Hence, pNp (CS , x) pNp (CS |Np , x).
Moreover, argue cj total share agents Np is, fact, negative,

therefore pNp (CS , x) < pNp (CS |Np , x). Indeed, recall xij < 0. Suppose xij > 0
Np ; note implies edge e = ((i, j ), (i , j )) E2 . Consider coalition
cj graph contains path P (i , j ) (i, j). j = j , adding e P obtain
cycle passes (i , j ) intersects E2 . Otherwise, edge e0 = ((i, j), (i, j ))
E1 , adding e0 e P results cycle passes (i , j ) intersects E2 .
cases, get contradiction, argued cycle exists. Thus, players
Np get non-positive payoff cj , gets strictly negative payoff coalition.
Consequently, pNp (CS , x) < pNp (CS |Np , x). hand,
pNp (CS |Np , x) = v(CS |Np ) v (eNp );
combining inequalities obtain pNp (CS , x) < v (eNp ), contradiction
(CS , x) satisfying inequalities LP (16).
conclude x imputation CS pi (CS , x) = pi (CS , x) N
xij 0 cj CS supp(cj ), concludes proof.
880

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

1,1

1,2

1,3

2,1

2,2

2,3

3,1

3,3

Figure 1: graph (x) formed coalition structure imputation described Example A.2.

Example A.2. Suppose players form coalition structure CS = (c1 , c2 , c3 ) given
0.6
0.3
0.1
c1 = 0.3 ,
c2 = 0.6 ,
c3 = 0.1 ,
0.3

0

use imputation x = (x1 , x2 , x3 ),
0
2
x1 = 2 ,
x2 = 2 ,
3

0

0.7

x3 =



3
0
1



.

resulting graph shown Figure 1, shortest cycle starting (3, 3) including edges
E2
(3, 3) (3, 1) (1, 1) (1, 3) (3, 3).
is, negative payoff player 3 c3 reduced player 3 transfers small amount
payoff player 1 c1 , player 1 transfers amount payoff player 3
c3 ; instance, moving 1 unit payoff manner would result valid imputation.
Theorem A.1 implies even assume xij unconstrained, solution
LP (16) value v (eN ), solution negative payoffs coalitions
value, i.e., optimal solution I(CS ). particular, means
loss generality assuming variables xij LP (16) unconstrained, therefore
Theorem 5.2 holds.

References
Ackerman, M., & Branzei, S. (2014). Research quality, fairness, authorship order. Proceedings 13th International Conference Autonomous Agents Multiagent Systems
(AAMAS-14), pp. 14871488.
881

fiZ ICK , ARKAKIS , & E LKIND

Aharoni, R., & Fleiner, T. (2003). lemma Scarf. Journal Combinatorial Theory, Series
B, 87, 7280.
Airiau, S., & Sen, S. (2009). fair payoff distribution myopic rational agents. Proceedings
8th International Conference Autonomous Agents Multiagent Systems (AAMAS09), pp. 13051306.
Anshelevich, E., & Hoefer, M. (2010). Contribution games social networks. Proceedings
18th European Symposium Algorithms (ESA-10), pp. 158169.
Arnold, T., & Schwalbe, U. (2002). Dynamic coalition formation core. Journal Economic
Behavior & Organization, 49(3), 363380.
Aubin, J. (1981). Cooperative fuzzy games. Mathematics Operations Research, 6(1), 113.
Aumann, R., & Dreze, J. (1974). Cooperative games coalition structures. International Journal
Game Theory, 3, 217237.
Bachrach, Y., Elkind, E., Meir, R., Pasechnik, D., Zuckerman, M., Rothe, J., & Rosenschein, J.
(2009). cost stability coalitional games. Proceedings 2nd International
Symposium Algorithmic Game Theory (SAGT-09), pp. 122134.
Bejan, C., & Gomez, J. C. (2009). Core extensions non-balanced TU-games. International
Journal Game Theory, 38(1), 316.
Bondareva, O. (1963). applications linear programming methods theory cooperative games. Problemy kibernetiki, 10, 119139.
Branzei, S., Michalak, T., Rahwan, T., Larson, K., & Jennings, N. R. (2013). Matchings externalities attitudes. Proceedings 12th International Conference Autonomous
Agents Multi-Agent Systems (AAMAS-13), pp. 295302.
Chalkiadakis, G., Elkind, E., Markakis, E., Polukarov, M., & Jennings, N. (2010). Cooperative
games overlapping coalitions. Journal Artificial Intelligence Research, 39, 179216.
Chalkiadakis, G., Elkind, E., & Wooldridge, M. (2011). Computational Aspects Cooperative
Game Theory. Morgan Claypool.
Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition formation
efficient data fusion multi-sensor networks. Proceedings 21st AAAI Conference
AI (AAAI-06), pp. 635640.
Deng, X., Ibaraki, T., & Nagamochi, H. (1999). Algorithmic aspects core combinatorial
optimization games. Mathematics Operations Research, 24(3), 751766.
Gillies, D. (1953). Theorems n-Person Games. Ph.D. thesis, Princeton University.
Jackson, M. O. (2003). survey models network formationstability efficiency.
Demange, G., & Wooders, M. (Eds.), Group Formation Economics: Networks, Clubs
Coalitions, chap. 1. Cambridge University Press.
Lehrer, E., & Scarsini, M. (2013). core dynamic cooperative games. Dynamic Games
Applications, 3(3), 359373.
Lin, C., & Hu, S. (2007). Multi-task overlapping coalition parallel formation algorithm. Proceedings 6th International Conference Autonomous Agents Multiagent Systems
(AAMAS-07), p. 211.
882

fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS

Markakis, E., & Saberi, A. (2005). core multicommodity flow game. Decision Support
Systems, 39(1), 310.
Maschler, M., Peleg, B., & Shapley, L. S. (1979). Geometric properties kernel, nucleolus,
related solution concepts. Mathematics Operations Research, 4(4), 303338.
Peleg, B., & Sudholter, P. (2007). Introduction Theory Cooperative Games (Second edition)., Vol. 34 Theory Decision Library. Series C: Game Theory, Mathematical Programming Operations Research. Springer, Berlin.
Rahwan, T. (2007). Algorithms Coalition Formation Multi-Agent Systems. Ph.D. thesis,
University Southampton.
Rahwan, T., & Jennings, N. (2008). improved dynamic programming algorithm coalition
structure generation. Proceedings 7th International Conference Autonomous
Agents Multiagent Systems (AAMAS-08), pp. 14171420.
Shapley, L. S. (1967). balanced sets cores. Naval Research Logistics Quarterly, 14(4),
453460.
Shapley, L. S. (1971). Cores convex games. International Journal Game Theory, 1, 1126.
Shehory, O., & Kraus, S. (1996). Formation overlapping coalitions precedence-ordered taskexecution among autonomous agents. Proceedings 2nd International Conference
Multi-Agent Systems (ICMAS-96), pp. 330337.
Sims, M., Corkill, D., & Lesser, V. (2008). Automated organization design multi-agent systems.
Autonomous Agents Multi-Agent Systems, 16, 151185.
Wang, T., Song, L., Han, Z., & Saad, W. (2013). Overlapping coalitional games collaborative
sensing cognitive radio networks. Proceedings 2013 Wireless Communications
Networking Conference (WCNC-13), pp. 41184123.
Zhang, G., Jiang, J., Su, Z., Qi, M., & Fang, H. (2010). Searching overlapping coalitions
multiple virtual organizations. Information Sciences, 180, 31403156.
Zhang, Z., Song, L., Han, Z., Saad, W., & Lu, Z. (2013). Overlapping coalition formation games
cooperative interference management small cell networks. Proceedings 2013 Wireless
Communications Networking Conference (WCNC-13), pp. 643648.
Zick, Y. (2014). Arbitration, Fairness Stability: Revenue Division Collaborative Settings.
Ph.D. thesis, Nanyang Technological University.
Zick, Y., Chalkiadakis, G., & Elkind, E. (2012). Overlapping coalition formation games: Charting
tractability frontier. Proceedings 11th International Conference Autonomous
Agents Multiagent Systems (AAMAS-12), pp. 787794.
Zick, Y., Chalkiadakis, G., Elkind, E., & Markakis, E. (2014). Cooperative games overlapping
coalitions: Charting tractability frontier. arXiv 1407:0420.
Zick, Y., & Elkind, E. (2011). Arbitrators overlapping coalition formation games. Proceedings 10th International Conference Autonomous Agents Multiagent Systems
(AAMAS-11), pp. 5562.
Zick, Y., Markakis, E., & Elkind, E. (2012). Stability via convexity LP-duality OCF games.
Proceedings 26th AAAI Conference AI (AAAI-12).
883

fiZ ICK , ARKAKIS , & E LKIND

Zick, Y., Polukarov, M., & Jennings, N. R. (2013). Taxation stability cooperative games.
Proceedings 12th International Conference Autonomous Agents Multiagent
Systems (AAMAS-13), pp. 523530.

884

fiJournal Artificial Intelligence Research 50 (2014) 805-845

Submitted 02/14; published 08/14

Speeding Iterative Ontology Alignment using
Block-Coordinate Descent
Uthayasanker Thayasivam
Prashant Doshi

UTHAYASA @ CS . UGA . EDU
PDOSHI @ CS . UGA . EDU

THINC Lab, Department Computer Science,
University Georgia, Athens, GA 30602, USA

Abstract
domains biomedicine, ontologies prominently utilized annotating data. Consequently, aligning ontologies facilitates integrating data. Several algorithms exist automatically aligning ontologies diverse levels performance. alignment applications evolve
exhibit online run time constraints, performing alignment reasonable amount time without compromising quality alignment crucial challenge. large class alignment
algorithms iterative often consumes time others delivering solutions high
quality. present novel general approach speeding multivariable optimization
process utilized algorithms. Specifically, use technique block-coordinate descent
(BCD), exploits subdimensions alignment problem identified using partitioning
scheme. integrate approach multiple well-known alignment algorithms show
enhanced algorithms generate similar improved alignments significantly less time
comprehensive testbed ontology pairs. BCD overly constrain partition
order parts, vary partitioning ordering schemes order empirically determine
best schemes selected algorithms. biomedicine represents key application
domain ontologies, introduce comprehensive biomedical ontology testbed community order evaluate alignment algorithms. biomedical ontologies tend large,
default iterative techniques find difficult produce good quality alignment within reasonable
amount time. align significant number ontology pairs testbed using BCDenhanced algorithms. contributions represent important step toward making significant
class alignment techniques computationally feasible.

1. Introduction
Recent advances Web-based ontologies provide needed alternative conventional schemas
allowing descriptive annotations data sets. example, National Center Biomedical
Ontology (NCBO) hosts 370 curated biomedical ontologies BioPortal including
high use SNOMED-CT, whose concepts participate 2 billion data
annotations (Musen et al., 2012). Therefore, present day challenge toward data integration
manage multitude ontologies build bridges ontologies overlapping
scope problem often referred ontology matching produces alignment (Euzenat & Shvaiko, 2007). illustrate partial alignment biomedical ontologies Fig. 1.
Consequently, several algorithms exist automatically aligning ontologies using various techniques (Euzenat, Loup, Touzani, & Valtchev, 2004; Jian, Hu, Cheng, & Qu, 2005; Li, Li, & Tang,
2007; Jean-Mary, Shironoshita, & Kabuka, 2009; Doshi, Kolli, & Thomas, 2009; Wang & Xu,
2009; Hanif & Aono, 2009; Bock & Hettenhausen, 2010; Jimenez-Ruiz & Grau, 2011; Shvaiko &
c
2014
AI Access Foundation. rights reserved.

fiT HAYASIVAM & OSHI

data
starting material,
intermediate material, end
products scientific
experiment parameters

process
occurrent entities
affect individuals

sample
specimen

agent

researcher

individual involved
experimental processes

role

Entity

continuant entities
causally affect
individuals process

role person,
chemical compund,etc...

worker_role
Processual_Entity Public
sector workers
exists time occurring
happening, temporal parts
always involves depends
entity.

reagent_role

states

drug

Buffer, dye, catalyst,
solvating agent.

drug_role

chemical substance that,
absorbed cell,
alters normal cell function

drug

region

region

Specimen

region

sample

region

(a)

(b)

Figure 1: Biomedicine important application domain ontologies. Alignment (shown
dashed red) portions of, (a) Parasite Experiment Ontology (PEO) and, (b)
Ontology Biomedical Investigations (OBI) discovered automated algorithm
called AgreementMaker (Cruz et al., 2012). ontologies available NCBO.
identified map alignment signifies equivalence concepts.

Euzenat, 2013), mixed levels performance. Crucial challenges algorithms involve
scaling large ontologies performing alignment reasonable amount time without
compromising quality alignment. case point, 6 alignment algorithms (not
including variants) 21 participated 2012 2013 instances annual
ontology alignment evaluation initiative (OAEI) competition (Shvaiko et al., 2012, 2013) generated
results acceptable amount time aligning large biomedical ontologies.
Although ontology alignment traditionally perceived offline one-time task, second challenge gaining importance. particular, Hughes Ashpole (2004) note, continuously evolving ontologies applications involving real-time ontology alignment semantic
search Web service composition stress importance computational complexity considerations. Recently, established competitions OAEI (Shvaiko et al., 2011) began reporting
execution times participating alignment algorithms well. ontologies become larger,
efficiency scalability become key properties alignment algorithms.
large class algorithms performs automated alignment iterative nature (Melnik,
Garcia-molina, & Rahm, 2002; Euzenat et al., 2004; Jian et al., 2005; Li et al., 2007; Doshi et al.,
2009; Wang & Xu, 2009; Hanif & Aono, 2009; Bock & Hettenhausen, 2010). algorithms
repeatedly improve previous preliminary solution optimizing measure solution
quality. Often, carried guided search alignment space using techniques
gradient descent expectation-maximization. algorithms may run convergence,
means solution cannot improved a, possibly local, optimum.
However, practice, runs often terminated ad hoc number iterations.
repeated improvements, computed alignment usually high quality approaches
also consume time general non-iterative counterparts. example, algorithms
performing among top three OAEI 2012 terms alignment quality YAM++ (Ngo
& Bellahsene, 2012), ranked first conference track, Optima+, ranked third conference track, GOMMA (Kirsten et al., 2011), ranked first anatomy library tracks,
806

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

iterative. 1 hand, YAM++ consumed excessive amount time completing
conference track (greater 5 hours) Optima+ consumed comparatively time well.
Furthermore, iterative techniques tend anytime algorithms, deliver alignment
even algorithm interrupted convergence. considerations computational
complexity delivered ways scaling algorithms larger ontologies,
ontology partitioning (Hu, Zhao, & Qu, 2006; Seddiqui & Aono, 2009; Stoutenburg, Kalita, Ewing,
& Hines, 2010; Rahm, 2011) use inverted indices (Jimenez-Ruiz & Grau, 2011), seek
speed alignment process multiple algorithms. think considerations space
time go hand hand context usability.
primary contribution article general approach comprehensive evaluation
significantly speeding convergence iterative ontology alignment techniques. Thayasivam Doshi (2012a) provide preliminary introduction approach. Objective functions
measure solution quality typically multidimensional. Instead traditional approach
modifying values large number variables iteration, decompose problem optimization subproblems objective optimized respect single
small subset, also called block, variables holding variables fixed. approach
block-coordinate descent (BCD) theoretically shown converge faster considerably
relaxed conditions objective function pseudoconvexity even lack
certain cases existence optima variable (coordinate) block (Tseng, 2001).
forms standard candidate tool multidimensional optimization statistics, applied
contexts image reconstruction (Pinter, 2000; Fessler & Kim, 2011) channel capacity
computation (Blahut, 1972; Arimoto, 1972), article presents use ontology alignment.
extensively evaluate approach integrating multiple ontology alignment algorithms. selected Falcon-AO (Jian et al., 2005), MapPSO (Bock & Hettenhausen, 2010),
OLA (Euzenat & Valtchev, 2004) Optima (Doshi et al., 2009) representative algorithms.
algorithms participated OAEI competitions past, ranked
top tier. Consequently, algorithms default forms exhibit favorable alignment performance. Furthermore, implementations source codes needed approach
freely accessible.
Using comprehensive testbed several ontology pairs large spanning
multiple domains, show significant reduction execution times alignment processes
thereby converging faster. Corresponding alignment quality continues remain
improved small amount cases. enables application algorithms
toward aligning ontology pairs given amount time, subsets large ontology
partitions. Also, allows techniques run convergence possible contrast
predefined ad hoc number iterations, possibly leads similar improved alignments.
useful context techniques guaranteed converge.
BCD constrain alignment variables divided blocks except rule
block chosen least cycle blocks. Furthermore, may order
blocks consideration manner within cycle. Consequently, second contribution
empirical study impact different ordering partitioning schemes improvement
BCD brings alignment. addition default ordering scheme based increasing height
grouped entities, consider reversing ordering, third approach sample
1. GOMMA utilizes multiple matching strategies may iterative, partly contributed
toward performance OAEI well.

807

fiT HAYASIVAM & OSHI

blocks based probability distribution represents estimated likelihood finding large
alignment block. context partitioning, additionally consider grouping alignment
variables entities divided breadth-first search based partition. default
approach partitions one ontologies pair, also consider impact partitioning both.
Performances iterative algorithms impacted differently various ways formulating
blocks ordering them. Notably, quality alignment may adversely impacted.
Surprisingly, algorithms differ ordering partitioning scheme optimizes
alignment performance. order comprehensively evaluate efficiency BCD-enhanced
optimized algorithms, contribute novel biomedical ontology alignment testbed. addition
important application domain, aligning biomedical ontologies unique challenges. selected biomedical ontologies published NCBO testbed, also provides
primarily UMLS-sourced incomplete reference alignment. Thirty-two different biomedical
ontologies form 50 pairs testbed half 3,000+ named classes.
rest article organized follows. next section, briefly explain iterative ontology alignment introduce four representative iterative algorithms. Additionally,
briefly review technical approach BCD. show BCD may integrated iterative
ontology alignment algorithms Section 3. Section 4, empirically evaluate performances
BCD enhanced algorithms using comprehensive data set. Then, Section 5, explore
ways ordering blocks partitioning alignment variables. Thereafter, Section 6,
detail new biomedical ontology benchmark report performances BCD enhanced
optimized iterative techniques benchmark. discuss impact BCD along
limitations Section 7, conclude article Section 8. Appendix outlines representative algorithms modifications utilize BCD, followed details biomedical
ontology alignment testbed Appendix B.

2. Background
provide brief overview ontology alignment problem next subsection.
followed brief descriptions four algorithms representative iterative alignment
approaches. Finally, describe technique BCD general.
2.1 Overview Ontology Alignment
ontology specification knowledge pertaining domain interest formalized
entities relationships entities. Contemporary ontologies utilize description logics (Baader, Horrocks, & Sattler, 2003) Web Ontology Language (OWL) (McGuinness
& Harmelen, 2004) order facilitate publication Web. OWL allows use classes
represent entities, different types properties represent relationships, individuals include
instances.
ontology alignment problem find set correspondences two ontologies, O1
O2 . Though OWL based description logic, several alignment algorithms model ontologies
labeled graphs (with possible loss information) due presence class hierarchy
properties relate classes, order facilitate alignment. example, Falcon-AO
Optima transform OWL ontologies bipartite graph (Hayes & Gutierrez, 2004) OLA
utilizes OL-graph (Euzenat et al., 2004). Consequently, alignment problem often cast
matching problem graphs. ontology graph, O, defined as, = hV, E, Li where,
808

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

V set uniquely labeled vertices representing entities, E set edges representing
relations, set ordered 2-subsets V , L mapping edge
label. correspondence, , two entities, xa O1 O2 , consists relation,
r {=, , }, confidence, c R. However, alignment algorithms use focus
possible presence = relation (also called equivalentClass OWL) entities only.
case, alignment may represented |V1 | |V2 | matrix represents correspondence
two ontologies, O1 = hV1 , E1 , L1 O2 = hV2 , E2 , L2 i:


m11
m12 m1|V2 |
m21
m22 m2|V2 |




.
.



.

=


.
.

.




.
.

.
m|V1 |1 m|V1 |2 m|V1 ||V2 |

Note ontologies modeled graphs, rows columns concepts
O1 O2 defined description logic. assignment variable, , confidence
correspondence entities, xa V1 V2 . Consequently, could realvalued matrix, commonly known similarity matrix two ontologies. However,
confidence may also binary 1 indicating correspondence, otherwise 0, due
match matrix becomes binary matrix representing alignment. Two algorithms
use maintain binary others use real .
alignment limited correspondences entities alone, may include correspondences relationship labels well. order facilitate matching relationships,
alignment techniques, including use transform edge-labeled graphs unlabeled
bipartite ones elevating edge labels first-class citizens graph. process involves
treating relationships resources thereby adding nodes graph.
2.2 Iterative Ontology Alignment
large class alignment algorithms iterative nature (Melnik et al., 2002; Euzenat et al., 2004;
Jian et al., 2005; Li et al., 2007; Doshi et al., 2009; Wang & Xu, 2009; Hanif & Aono, 2009;
Bock & Hettenhausen, 2010; Ngo & Bellahsene, 2012). Iterative algorithms utilize seed matrix,
0 , iteratively improved converges. seed matrix either input user
generated automatically often using fast string matching lexical matching.
Two types iterative techniques predominant. differ next match matrix,
, obtained previous iterations match matrix step. first type iterative
algorithms improve real-valued similarity matrix previous iteration, i1 , directly
updating it:
= U (M i1 )
(1)
where, U function updates similarities. type algorithms often converges
fixed point, , that, = U (M ). 2
second type iterative algorithms repeatedly explicitly search space match
matrices, denoted M. goal find alignment optimizes objective function,
2. Convergence predicated U , fixed point may exist techniques. However, convergence
desirable property iterative alignment algorithms; absence stop criteria often ad hoc.

809

fiAlignment Quality

HAYASIVAM & OSHI



Space Alignments

Figure 2: iterative update search jump one alignment another improving
previous one. two differ obtain next alignment iteration
qualitative metric used assessing it. alignment cannot improved
signifies convergence.

gives measure quality alignment context alignment
previous iteration. approach appropriate search space bounded
match matrix binary. Nevertheless, cardinality 2|V1 ||V2 | space could get
large. algorithms sample space reduce effective search space though scaling
large ontologies continues remain challenging. Formally,
Mi = arg max Q(M, Mi1 )

(2)



where, Mi alignment optimizes Q function iteration given best alignment
previous iteration, Mi1 . Convergence algorithms occurs iterations reach
point, , cannot improved searching alignment matrix, M,
Q(M, ) > Q(M , ). Equations 1 2 help solve multidimensional optimization problem
iteratively variables. abstractly illustrate iterative approaches Fig. 2.
Fig. 3, show abstract algorithms two types iterative approaches.
iterative update Fig. 3(a), may settle near fixed point calculating distance
pair alignment matrices (line 8) terminating iterations distance within
parameter, . 0 get closer fixed point obtain fixed point limit.
Iterative search Fig. 3(b) often requires seed map (line 3) obtain 0 , typically
generated using fast lexical matching.
Next, briefly review four ontology alignment algorithms optimize iteratively. selection algorithms based accessibility competitive performance previous
OAEI competitions, meant representative iteration-based alignment algorithms. 3
2.2.1 FALCON -AO
Falcon-AO (Jian et al., 2005) well-known automated ontology alignment system combining
output multiple components including linguistic matcher, iterative structural graph matching algorithm called GMO (Hu, Jian, Qu, & Wang, 2005), method partitioning large
ontologies focusing parts.
3. sought include YAM++ well evaluation, top performer conference track OAEI
2012 2013. However, source code freely available could access it.

810

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

TERATIVE U PDATE (O1 , O2 , )

TERATIVE EARCH (O1 , O2 )

Initialize:
1. Iteration counter 0
2. Calculate similarity
entities O1 O2 using measure
3. Populate real-valued matrix, 0 ,
initial similarity values
4. 0

Initialize:
1. Iteration counter 0
2. Generate seed map
O1 O2
3. Populate binary matrix, 0 ,
seed correspondences
4. 0

Iterate:
5.
6.
ii+1
7.
= U (M i1 )
8.
Dist(M , )
9.

10.
11. Extract alignment

Iterate:
5.
6.
ii+1
7.
Search arg max Q(M, i1 )


8.

9. 6= i1
10. Extract alignment

(a)

(b)

Figure 3: General algorithms iterative (a) update, (b) search approaches toward aligning
ontologies. distance function, Dist, line 8 (a) measure difference
two real-valued matrices.

GMO measures structural similarity ontologies modeled bipartite
graphs (Hayes & Gutierrez, 2004). Matrix GMO real-valued similarity matrix
iteratively updated (Eq. 1) updating variable, , average neighborhood
similarities stops changing significantly. GMO takes external input, typically obtained
lexical matching, seed. Equation 1 manifests GMO series matrix operations:
= G1 i1 GT2 + GT1 i1 G2

(3)

Here, G1 G2 adjacency matrices bipartite models two ontologies O1 O2 ,
respectively. first term summation, outbound neighborhood entities O1
O2 considered, second term considers inbound neighborhood. Iterations terminate
cosine similarity successive matrices, i1 , less parameter, .
iterative update algorithm manifests Falcon-AO shown Fig. 17(a) Appendix A.
2.2.2 AP PSO
MapPSO (Bock & Hettenhausen, 2010) utilizes discrete particle swarms perform optimization. K particles swarm represents valid candidate alignment, updated
iteratively. iteration, given particle(s) representing best alignment(s) swarm,
alignments particles adjusted influenced best particle.
Equation 2 manifests MapPSO two-step process consisting retaining best particle(s) (alignment(s)) replacing others improved ones influenced best alignment
previous iteration. measure quality alignment k th particle determined
811

fiT HAYASIVAM & OSHI

mean measures correspondences shown below:

Q(Mki )

=

|V
P1 | |V
P2 |

f (xa , )

a=1 =1

|V1 ||V2 |

(4)

where, correspondence Mki f represents weighted combination multiple syntactic possibly semantic similarity measures entities two ontologies. Improved
particles generated keeping aside random number best correspondences according f
particle, replacing others based correspondences previous best particle. Iterations terminate increment Q due new alignment matrix lower parameter,
. Iterative search Eq. 2 manifests MapPSO shown algorithm Fig. 18(a).
2.2.3 OWL-L ITE LIGNMENT
OWL-Lite alignment (OLA) (Euzenat et al., 2004) limited aligning ontologies expressed
OWL emphasis restricted dialect called OWL-Lite. OLA adopts bipartite
graph model ontology, distinguishes 8 types nodes classes, objects,
properties, restrictions others; 5 types edges: rdfs:subClassOf, rdf:type,
classes properties, objects property instances, owl:Restriction, properties individuals.
OLA computes similarity pair entities two ontologies weighted
aggregation similarities respective neighborhood entities. Due consideration
multiple types edges, cycles common. Consequently, computes similarities
entities solution large system linear equations, solved iteratively fixed point.
Let F(xa ) set nodes O1 , connected node xa via edge type,
F. Formally, similarity Sim(xa , ), vertex, xa O1 , vertex, O2 , defined as,
X

Sim(xa , ) =
wF
SetSim(F(xa ), F(y ))
(5)
F N (xa ,y )

,
where, N (xa , ) set edge types xa , P
participate. Weight, wF

wF = 1. Function, SetSim,
entity pair, xa , , edge type, F, normalized, i.e.,
F N (xa ,y )

evaluates similarity sets, F(xa ) F(y ), average maximal pairing.
OLA initializes real-valued similarity matrix, 0 , values based lexical attributes
only, iterations update variable, , matrix using structure two
ontologies. particular, two entities, xa type, updated using
Eq. 5, otherwise value 0. Iterative update Eq. 1 realized OLA Fig. 19(a)
Appendix A.
2.2.4 PTIMA
Optima (Doshi et al., 2009) formulates ontology alignment maximum likelihood problem,
searches match matrix, , gives maximum conditional probability observing
ontology O1 , given ontology, O2 , match matrix .
employs generalized expectation-maximization solve optimization problem which,
iteratively evaluates expected log likelihood candidate alignment picks one
maximizes it. implements Eq. 2 two-step process computing expectation followed
812

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

maximization, iterated convergence. expectation step consists evaluating
expected log likelihood candidate alignment given previous iterations alignment:
Q(M |M i1 ) =

|V1 | |V2 |
X
X

P r(y |xa , i1 ) logP r(xa |y , )i

(6)

a=1 =1

where, xa entities ontologies O1 O2 respectively, prior probability
. P r(xa |y , ) probability node xa correspondence node given
match matrix . prior probability computed as,
|V1 |

=

1 X
P r(y |xa , i1 )
|V1 |
a=1

generalized maximization involves finding matrix, Mi , improves previous one:
Mi = : Q(M |Mi1 ) Q(Mi1 |Mi1 )

(7)

show iterative alignment algorithm Optima Fig. 20(a).
Altogether, four alignment algorithms describe subsection represent broad
variety iterative update search techniques, realized different ways. facilitates broad
evaluation usefulness BCD. years, algorithms Falcon-AO, OLA Optima performed satisfactorily annual OAEI competitions, Falcon-AO Optima
demonstrating strong performances respect comparative quality generated alignment. example, Falcon-AO often ranked top 3 systems participated OAEI
competitions 2005 2010, performance continues remain benchmark
algorithms. Optima enhanced BCD (called Optima+) ranked second conference
track (F2-measure recall) 2012 edition OAEI competition (Thayasivam & Doshi,
2012b). Consequently, representative algorithms exhibit strong alignment performances.
hand, MapPSOs performance comparatively poor particle-swarm based iterative approach motivates selection representative set.
2.3 Block-Coordinate Descent
Large-scale multidimensional optimization problems maximize minimize real-valued continuously differentiable objective function, Q, N real variables. Block-coordinate descent (BCD)
(Tseng, 2001) established iterative technique gain faster convergence context
large-scale N -dimensional optimization problems. technique, within iteration, set
variables referred coordinates chosen objective function, Q, optimized
respect one coordinate blocks coordinates held fixed. application
setting, recall coordinates alignment variables match matrix, .
Let denote block coordinates, non-empty subset {1, 2, . . . , N }. Define set
blocks as, B = {S0 , S1 , . . . , SC }, set subsets representing coordinate
block constraint that, S0 S1 . . . SC = {1, 2, . . . , N }. B could single block
partition coordinates although required blocks may intersect. also
define complement coordinate block, Sc , c {0, 1, . . . , C}, as, Sc = B Sc .
813

fiT HAYASIVAM & OSHI

illustrate, let domain real-valued, continuously differentiable, multidimensional function, Q,
N = 10 be, = {m1 , m2 , m3 , . . . , m10 }, element variable. may partition
set coordinates two blocks, C = 2, that, B = {S0 , S1 }. Let S0 = {m2 , m5 , m8 }
S1 = {m1 , m3 , m4 , m6 , m7 , m9 , m10 }. Finally, S0 denotes block, S1 .
BCD converges fixed point local global optimum objective function
relaxed conditions pseudoconvexity function requires function
bounded level sets (Tseng, 2001). pseudoconvex functions continue fixed points,
may non-unique optima along different coordinate directions. absence pseudoconvexity, BCD may oscillate without approaching fixed point function. Nevertheless, BCD
still converges function unique optima coordinate blocks.
order converge using BCD, must satisfy following rule, ensures
coordinate chosen sufficiently often (Tseng, 2001).
Definition 1 (Cyclic rule) exists constant, C C > 0, every block, Sc ,
chosen least ith iteration (i + 1)th iteration, i.
context cyclic rule, BCD mandate specific partitioning ordering scheme
blocks. simple way meet rule sequentially iterating block
although must continue iterating block converges fixed point.
Recently, Saha Tewari (2013) show nonasymptotic convergence rate 4 BCD
cyclic rule faster gradient descent (GC) start
point, conditions objective function, Q, Lipschitz continuous gradient (it
differentiable everywhere bounded derivative) strongly convex, Q
L
isotonic, identity function L Lipschitz constant. Starting
0
0 , let

initial map, MBCD
= MGC
BCD MGC denote alignment iteration BCD
cyclic rule GC, respectively. condition objective function, Q, must

). nonasymptotic
say, minimized, continuous isotonic, 1, Q(MBCD
) Q(MGC
convergence rate BCD cyclic rule objective functions previous properties
is, O(1/i), iteration count.

3. Integrating BCD Iterative Alignment
mentioned previously, ontology alignment may approached principled multivariable
optimization objective function, variables correspondences
entities two ontologies. Different algorithms formulate objective function differently.
objective functions often complex difficult differentiate, numerical iterative techniques
appropriate tend progress slowly. context, may speed convergence
rate using BCD describe below.
3.1 General Approach
Section 2.2, identified two types iterative ontology alignment algorithms. BCD may
integrated types. order integrate BCD iterations, match matrix,
, must first suitably partitioned blocks. course, existing algorithms may viewed
single block variables therefore trivially utilizing BCD.
4. rate convergence effective first iteration itself.

814

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

Though matrix may partitioned using one several ways, adopt approach
well supported context ontology alignment. important heuristic, proved
highly successful ontology schema alignment, matches parent entities two ontologies
respective child entities previously matched (Doan, Madhavan, Domingos, & Halevy,
2003). motivates grouping together variables, , coordinate block
xa participating correspondence belong height leading partition
. height ontology node length shortest path leaf node. Subsequently,
alignment blocks less height (containing child entities) optimized first followed
increasing height (containing parent entities). determining height, utilize
tree graph model ontology built internally respective ontology alignment
algorithm. include property nodes may differ algorithms.
Let partition coordinate blocks {MS0 , MS1 , . . . , MSC }, C height
largest class hierarchy ontology O1 . Thus, block submatrix many rows
number entities O1 height number columns equal number entities
O2 . example, correspondences leaf entities O1 entities O2 form
block, MS0 . context bipartite graph model utilized Falcon-AO Optima,
represents properties ontology vertices well therefore part ,
would included coordinate blocks.
Iterative ontology alignment integrated BCD optimizes respect single block, MSc ,
iteration keeping remaining blocks fixed. order meet cyclic rule, choose
block, MSc , iterations, = c + qC q {0, 1, 2, . . .}. point BCD applicable
types iterative alignment techniques outlined Section 2.2. Alignment algorithms
update similarity matrix iteratively Eq. 1 update current block interest,
MSc , remaining blocks carried forward is, shown below:
MSi c = USc (M i1 )
MSi = MSi1
Sc

(8)

Sc complement Sc B. Note MSi c combined MSi Sc forms
. Update function, USc , modifies U Eq. 1 update block coordinates.
Analogously, iterative alignment searches candidate alignment maximizes
objective function Eq. 2, choose block, MSc , iteration. search
reduced search space pertaining subset variables included MSc , best
candidate coordinate block. Formally,

MSi c , = arg max QS MSc , Mi1
MSc MSc
(9)
= i1
MS,




c
S,
where, MSc space alignments limited block, Sc . original objective function, Q,
modified QS provides measure quality block, MSc , given previous
best match matrix. Note previous iterations matrix, Mi1 , contains best block
interest iteration.
Performing update, USc , evaluating objective function, QS , focusing coordinate block may performed significantly reduced time compared performing
operations entire alignment matrix. may perform iterations cycle
815

fiT HAYASIVAM & OSHI

2.2e+07

Q-Value

2.1e+07
2e+07
1.9e+07
1.8e+07
1.7e+07

Optima BCD
Optima

1.6e+07
0

10

20

30

40

50

60

time (s)

Figure 4: BCD facilitates faster convergence aligning ontologies iasted sigkdd related
conference organization.

blocks, use partially updated matrices previous iteration evaluating
next block facilitates faster convergence. illustrate impact BCD iterative search
performed Optima example ontology pair Fig. 4. Alignment using BCD shows
faster convergence rate.
TERATIVE U PDATE BCD (O1 , O2 , )

TERATIVE EARCH BCD (O1 , O2 )

Initialize:
1. Iteration counter 0
2. Calculate similarity
entities O1 O2 using measure
3. Populate real-valued matrix, 0 ,
initial similarity values
4. Create partition :
{MS0 , MS1 , . . . , MSC }
5. 0

Initialize:
1. Iteration counter 0
2. Generate seed map
O1 O2
3. Populate binary matrix, 0 ,
seed correspondences
4. Create partition :
{MS0 , MS1 , . . . , MSC }
5. 0

Iterate:
6.
7.
c % (C + 1), + 1
8.
MSi c USc (M i1 )
9.
MSi MSi1 Sc
10. c = C
11.
Dist(M , )
else
12.
high value
13.
14.
15. Extract alignment

Iterate:
6.
7.
c % (C + 1), + 1

8.
Search MSi c , arg max QS MSc , Mi1
MSc MSc

i1

MS,
MS,
Sc
c = C
changed Mi 6= Mi1 ?
else
12.
changed true
13. changed
14. Extract alignment Mi

9.
10.
11.

(a)

(b)

Figure 5: General iterative algorithms Fig. 3 modified obtain, (a) iterative update enhanced
BCD, (b) iterative search enhanced BCD. update search steps line
numbers 8 9 modified update current block interest.

816

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

Algorithms Fig. 5 revise iterative update search algorithms Fig. 3 order
integrate BCD. primary differences involve creating partition alignment matrix,
(line 4), iterations sequentially process coordinate block keeping
others fixed (lines 7-9). completing cycle coordinate blocks determined
check line 10, evaluate whether new alignment matrix differs one previous
iteration, continue iterations (lines 11-13). Observe regular iterations
improving full match matrix replaced mini-iterations updating blocks.
Given general modifications brought BCD, describe manifest
four iterative alignment systems form representative set. modifications based
type iterative technique uniform within group. change core
alignment approach algorithm given input see next.
3.2 BCD Enhanced Falcon-AO
enhance Falcon-AO modifying GMO utilize BCD iterates. depicted Fig. 17(b),
begin partitioning similarity matrix used GMO C + 1 blocks based height
entities O1 part correspondences, mentioned previously. GMO
modified iteration, block similarity matrix updated blocks
remain unchanged. block, Sc , updated iteration i, Eq. 3 becomes:
MSi c = G1,Sc i1 GT2 + GT1,Sc i1 G2
MSi = MSi1 Sc

(10)

Here, G1,Sc focuses portion adjacency matrix O1 corresponds outbound
neighborhood entities participating correspondences block Sc , GT1,Sc focuses
inbound neighborhood entities Sc . Adjacency matrix, G2 , utilized before. outcome
matrix operations similarity matrix, many rows variables Sc columns
corresponding entities O2 . complete similarity matrix obtained iteration, i,
carrying forward remaining blocks unchanged, utilized next iteration.
general iterative update modified perform BCD Fig. 5(a) may realized Falcon-AO
algorithm Fig. 17(b) Appendix A.
3.3 BCD Enhanced MapPSO
may integrate BCD MapPSO ordering particles swarm based measure
quality coordinate block, Sc , particle iteration. Equation 4 modified
measure quality correspondences coordinate block Sc , k th particle
taking average:
|VP
1,c | |V
P2 |
f (xa , )
a=1 =1

QS (Mk ) =
(11)
|V1,c ||V2 |
where, V1,c denotes set entities ontology, O1 , identical height participating correspondences included block Sc . before, retain best particle(s) based measure

, remaining particles using best
improve alignment coordinate block, Mk,S
c
particle previous iteration. remaining coordinates held unchanged. Iterative search
MapPSO modified using BCD shown algorithm Fig. 18(b).
817

fiT HAYASIVAM & OSHI

3.4 BCD Enhanced OLA
explained earlier, OLA evolves similarity matrix similarity exchange pairs
neighboring entities. iteration, performs element-wise matrix update operation. OLA
enhanced BCD adopting Eq. 8. Specifically, similarity values coordinates
chosen block, Sc , updated using similarity computations (Eq. 5). remaining blocks,
MSi , kept unchanged.
c

mia

=



Sim(xa , ) types xa
, mia
Sc
0
otherwise

(12)

MSi = MSi1 Sc
3.5 BCD Enhanced Optima
mentioned previously, Optima utilizes generalized expectation-maximization iteratively
improve likelihood candidate alignments. Jeffery Alfred (1994) discuss BCD inspired expectation-maximization scheme call space alternating generalized expectationmaximization (SAGE). Intuitively, SAGE maximizes expected log likelihood block coordinates thereby limiting hidden space, instead maximizing likelihood complete
alignment. sequence block updates SAGE monotonically improves objective likelihood. regular objective function, monotonicity property ensures sequence
diverge, guarantee convergence. However, proper initialization lets SAGE converge
locally. 5 iteration, Optima enhanced using SAGE chooses block match matrix,
MSi c , expected log likelihood estimated. previous techniques, choose blocks
sequential manner blocks iterated order.
Equation 6 changes estimate expected log likelihood block candidate alignment:
|V1,c | |V2 |

QS (MSi c |M i1 ) =

XX


P r(y |xa , i1 ) logP r(xa |y , MSi c ) ,c

(13)

a=1 =1

Recall V1,c denotes set entities ontology, O1 , participating correspondences
, modified well utilize V
included Sc . Notice prior probability, ,c
1,c
calculations.
generalized maximization step involves finding match matrix block, MSi c , ,
improves previous one:
|Mi1 )
MSi c , = MSi c MSc : QS (MSi c , |Mi1 ) QS (MSi1
c ,

(14)

Here, MSi1
part Mi1 .
c ,
iteration i, best alignment matrix Mi , formed combining block MSi c , ,
i1
improves QS defined Eq. 14 remaining blocks previous iteration, MS,
,
complement Sc , unchanged.
5. Furthermore, convergence rate may improved choosing hidden space less Fisher information (Hero
& Fessler, 1993).

818

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

algorithm Fig. 20(b) shows Optima may enhanced BCD. expect significant savings time search reduced space alignments focused block,
MSc , iteration. Additionally, objective function, QS , prior operate
single coordinate block reduced time. Finally, using aligned blocks next iteration improves
convergence rate.

4. Empirical Analysis
use BCD expected make iterative approaches exhibit greater rate improvement, approach converges, reach fixed point faster, seek empirically determine:
1. amount speed obtained various alignment algorithms integrating BCD;

2. Changes quality final alignment, any, due BCD. may happen
iterations converge different local optimum.
Ontology

Named Classes
Conference domain
ekaw
74
sigkdd
49
iasted
150
cmt
36
edas
104
confOf
38
conference
60
Life Sciences
mouse anatomy
2,744
human anatomy
3,304

Properties
33
28
41
59
50
36
64
2
3

Table 1: Ontologies OAEI 2012 used evaluation. show number named classes
properties estimate size. Notice evaluation includes
large ontologies different domains well. Additionally, Thayasivam
Doshi (2012a) present evaluations four pairs 300 range bibliography
benchmark competition.
use comprehensive testbed several ontology pairs large spanning
two domains. used ontology pairs OAEI competition 2012 version testbed
evaluation (Shvaiko et al., 2012). Among OAEI tracks, focus test cases
involve real-world ontologies reference (true) alignment provided OAEI.
ontologies either acquired Web created independently
based real-world resources. includes pairs expressive ontologies conference
track structure knowledge related conference organization, anatomy track,
consists pair mid-sized ontologies life sciences describing anatomy
adult mouse human. list ontologies OAEI participating evaluation
Table 1 provide indication sizes. Additionally, Thayasivam Doshi (2012a)
evaluate Falcon-AO, MapPSO Optima BCD four pairs 300 range
819

fiT HAYASIVAM & OSHI

bibliography benchmark competition. Ontology pairs 100 200 ranges bibliography
benchmark utilized participating ontologies small 33 classes
64 properties. Subsequently, representative iterative techniques align quickly
order milliseconds leaving significant room improvement.
align ontology pairs using four representative algorithms, original forms
BCD using seed alignment, 0 , applicable. iterations run algorithm
converged measured total execution time, final recall, precision F-measure,
number iterations performed convergence. Recall measures fraction correspondences
reference alignment found algorithm precision measures fraction
found correspondences reference alignment thereby indicating fraction
false positives. F-measure represents harmonic mean recall precision.
averaged results 5 runs every ontology pair using original BCD
enhanced version algorithm. large number total runs, ran tests
two different computing platforms ensuring comparability. One Red Hat machine
Intel Xeon Core 2, processor speed 3 GHz 8GB memory (anatomy ontology
pair) one Windows 7 machine Intel Core i7, 1.6 GHz processor 4GB
memory (benchmark conference ontology pairs). comparing performance metrics
statistical significance, tested data normality used Students paired t-test exhibits
normality. Otherwise, employed Wilcoxon signed-rank test. utilized 1% level (p
0.01) deem significance.
Thayasivam Doshi (2012a) previously evaluate OLA bibliography domain
ontology pairs, discuss performance article completeness. Similar algorithms, introduction BCD OLA reduced execution time four pairs total 1.3
seconds compared original time 27.3 seconds. OLAs precision recall reduced slightly
causing F-measure reduce 1% ontology pair (302,101), alignments
pairs remained same.
ontologies conference domain vary widely size structure. shown
Fig. 6, introduction BCD four iterative techniques clearly improves speed
convergence differences algorithm significant (Students paired t-test, p
0.01). particular, observed order magnitude reduction time aligning relatively
larger ontologies iasted edas. example, pairs (conference, iasted) MapPSO
(edas, iasted) Optima showed reductions. Overall, observed total reduction 50
seconds Falcon-AO 3 minutes, 1 minute 37 seconds MapPSO, 31 seconds OLA
total 1 minute 37 seconds, 29 minutes 20 seconds Optima 4 minutes
53 seconds.
Falcon-AO shows change due BCD alignment, holding precision 25%
recall 66%. Optima shows 4% improvement average precision 56% 60% average
recall reduced 70% 68%. Nevertheless, causes 2% improvement average F-measure
64%. MapPSO BCD resulted significant improvement final precision 9%
43% average, although difference recall significant. precision recall
OLA remained unchanged.
mid-sized anatomy ontologies mouse human successfully aligned
MapPSO OLA despite use BCD. However, BCD reduced Falcon-AOs average execution time aligning single ontology pair 6.2 seconds 2.6 minutes, drastically
reduced Optimas average execution time 4.4 minutes 62.7 minutes. alignment gen820

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

60

20
Falcon-AO
Falcon-AO BCD

16
14

Time (sec)

40

Time (sec)

MapPSO
MapPSO BCD

18

50

30
20

12
10
8
6

10

4
2

0
e

er

f




(c

t,C


da

e
nc



fe



(C

(c

,i


(e

)

f)

aw

fO

,ek



t,c







n



fe



(C


nf


te



f,e

sig

ce

)

)


da


kd

,e

ig



(c


kd

t,s

)

)

)

)

e
nc

(c



fe



(a)

,i
ce

d)

,s
ce

(c

(c

w)

ka

f,e

f,e


nf



n



fe



(c

s)

da

kd

ig

n



fe



(c

d)

te



e
nc


nf



(c

(b)

10
OLA
OLA BCD

Optima
Optima BCD

1000

8

Time (sec)

Time (sec)

100
6

4

10

1

2

0

0.1
s)

d)

da

kd





(c

g
,si


e,i

nc

en

r
fe



(C

f

e
er



(C

)

ed

st

,e
ce

d)

te


-ia



da

(e

ka

(e

)

d)

ed

st

ia
w,

e)

kd

g
,si

t,



(c

(c)

n
Co

nc



fe

aw

k
(e





(c

d)

f)

fO

kd

n
,co





(c


s,i

da

(e

(d)

)

ed

st

g
,si

ka

(e

d)

)

kd

ed

st

ia
w,

sig

,
ed

st

(ia

Figure 6: Average execution time consumed by, (a) Falcon-AO, (b) MapPSO, (c) OLA, (d)
Optima original form BCD, 6 21 ontology pairs conference domain. ran algorithms pairs, selected ontology pairs
exhibited three highest three lowest differences average execution times
clarity. Note time axis (d) log scale. Notice improvements
execution time larger pairs. Specifically, 50% reduction average execution time ontology pair (edas, iasted) Falcon-AO order magnitude
reductions average run time ontology pairs (conference, iasted) MapPSO
(edas, iasted) Optima, observed.

erated Falcon-AO BCD remained unchanged 76.1% precision 80% recall
alignment Optima BCD improved precision 96% recall 74.2%.
Falcon-AO Optima automatically utilized ontology partitioning methods order align
mid-sized pairs.
summary, introduction BCD led significant reductions convergence time
four iterative algorithms several ontology pairs, extending order magnitude. Simultaneously, quality final alignments indicated F-measure improved pairs,
one pair showing reduction context Optima. However, observe change
F-measure many pairs. Therefore, empirical observations indicate BCD
significant adverse impact quality alignment.
821

fiT HAYASIVAM & OSHI

5. Optimizing BCD using Ordering Partitioning Schemes
mentioned previously, BCD overly constrain formation coordinate blocks
neither impose ordering consideration blocks, satisfying
cyclic rule. Consequently, explore ways ordering blocks partitioning
alignment variables context representative algorithms. include:
1. Ordered roots leaves: Cycle blocks decreasing height starting block
containing entities largest height.
2. Ordered similarity distribution: Obtain aggregate measure lexical similarity ontology entities participating block. normalized distribution similarities provides likelihood picking next block.
3. ontologies partitioned: block contains participating entities ontology
height.
4. Subtree-based partitioning: Transform ontology tree form block variables
participating entities part subtree predefined size.
5. Random partitioning: Form block randomly selecting alignment variables inclusion.
partitioning ordering utilized previous section intuitive, objective
discover ways may improve run time performances algorithms. subsequent experimentation, exclude MapPSO representative set due randomness
algorithm, leads comparatively high variability run times.
5.1 Ordering Blocks
order blocks processed may affect performance. updated
correspondences previous blocks used generating alignment current block.
Initially, blocks participating entities increasing height beginning leaves used
illustrated Fig. 7. ordering schemes could improve performance:
may reverse previous ordering cycling blocks decreasing height, beginning
block contains entities largest height. leads processing parent
entities first followed children.
may obtain quick approximate estimate amount alignment block
variables. One way compute aggregate measure lexical similarity
entities two ontologies participating block. Assuming similarity estimate amount alignment block, may convert estimates
probability distribution gives likelihood finding multiple correspondences
block. block process next sampled distribution. approach
requires relaxation cyclic rule particular block guaranteed selected. regard, expectation selecting block sufficient obtain asymptotic
convergence BCD (Nesterov, 2012).
822

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

role
agent

data

worker_role
sample

reagent_role

researcher

drug

drug_role
Specimen
O2
drug

m11

m12

m13

m14

m15

agent

m21

m22

m23

m24

m25

sample

m31

m32

m33

m34

m35

researcher

m41

m42

m43

m44

m45

m51

m52

m53

m54

m55

O1

data

Figure 7: Presence absence correspondences entities two ontologies represented
match matrix. Concepts drug, sample, researcher leaves correspondences may grouped block (highlighted). may process block
first followed block containing data agent. Alternately, may reverse
ordering optimizing blocks.

compare performances alternate ordering schemes initial 21 ontology pairs conference domain. results reversing order original scheme
shown Fig. 8. Clearly, original ordering allows three BCD-enhanced approaches
converge faster general. Optimas average recall across pairs improved slightly
68% 70%, average precision reduced 4% final 56%. Falcon-AOs average F-measure
improved insignificantly overall expense 40 seconds run time. Reversing order
impact precision recall OLA. results insightful reinforce
usefulness alignment heuristic motivating original ordering scheme.
second alternate ordering scheme involves determining aggregate lexical similarity entities participating block. distribution similarities normalized next
block consider sampled distribution. Notice Fig. 9 Falcon-AO OLA
demonstrate significant increases convergence time (p 0.01) compared utilizing BCD
initial ordering scheme; hand, overall time reduces Optima orders
magnitude pairs containing larger ontologies edas iasted.
select 6 pairs, exhibit highest lowest differences average execution times show
Fig. 9. Falcon-AOs precision recall show significant change F-measure remains
unchanged. OLA loses precision recall similarity distribution scheme. precision across pairs went 13% 37% along 24% drop recall 58% leading
drop F-measure 19%. However, Optimas F-measure remains largely unaffected.
Recall Falcon-AO OLA perform iterative updates Optima conducts
iterative search. sampled blocks undergo updates iterative update algorithms, search
algorithms may improve blocks low similarity. Consequently, blocks high
similarity sampled often repeatedly improved. results quicker convergence
823

fiT HAYASIVAM & OSHI

Falcon-AO BCD
Falcon-AO BCD (ordered roots leaves)

50

OLA BCD
OLA BCD (ordered roots leaves)

14
12

40

Time (sec)

Time (sec)

10
30

20

8
6
4

10
2
0

0

)

(

e
nc



fe



(C

f




e
nc




,ia

nc

(c

(

n
Co

t,



(c

(a)
1000

e
er

f




ed

s)

e)

d)

te


f,e

f




fe



(C

k
sig

,

c

n


)



dd


e,e

fe

(C

)

)



,c

t,

cm

)



dd

k
sig

da

)


f

n
,co





(c

,e
ce

en



r
fe

(C



(C

(b)

d)

kd

ig

en

r
fe

d)

te



,i
ce

(c

f


,s


)

ed

st

,ia


da

(e

Optima BCD
Optima BCD (ordered roots leaves)

Time (sec)

100

10

1

)

aw

,ek



fe



(C

e
nc

n



fe

n
Co

d)

te



,i
ce

f



(c

(

d)

te



,i


ka

(e

)

dd

si
d,

e

st

(ia

dd

gk

gk

si
w,

ka

(e

)

)

ed

st

ia
w,

(c)

Figure 8: Average execution times of, (a) Falcon-AO, (b) OLA, (c) Optima, BCD
uses initial ordering scheme BCD ordering blocks root(s) leaves,
6 21 ontology pairs conference domain. ran algorithms
pairs, selected ontology pairs exhibited highest lowest differences average execution times. alternate ordering increases run times
convergence observe significant improvements F-measures.

different peculiar local optima blocks high similarity converged
others predominantly remain unchanged. Thus, alignment quality remains largely unaffected
convergence time reduced, see context Optima.
5.2 Partitioning Alignment Variables
BCD impose particular way grouping variables, well-founded partitioning schemes may yield significant improvements:
extension initial scheme (Fig. 10(a)) would group variables representing
correspondences participating entities O1 O2
height relation leaf entity ontology, illustrate Fig. 10(b). Note
824

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

20

Falcon-AO BCD
Falcon-AO BCD (ordered similarity distribution)

60
50

15

Time (sec)

40

Time (sec)

OLA BCD
OLA BCD (ordered similarity distribution)

30

10

20
5
10
0

0

)

)


fe



(C

fO



(c

aw

k
sig

f,

nc

)

dd


e,e

t,



(c

)



dd

k
sig

da

(e

d)


,ia



k
sig

(e

e
nf



t,C

(a)
1000





nf


t,c



(c



(c

)

)

nc



w,

ka



(e

e)

)

dd

te

k
s,e

,ed

e
nc



fe



(

(b)

)

fO



(c

dd

gk


f,s

n



fe

n
Co

(C

d)

te



,i
ce

d)

te



,i




(e

Optima BCD
Optima BCD (ordered similarity distribution)

Time (sec)

100

10

1

0.1

(C



r
fe

d)

,e
ce

kd

ig
f,s

en

gk

,si





(c

s)

da

)
dd



(c

da

(e

(c)

)

)

)

ed

st


s,i

fO

aw

da

(e

dd

gk

k
s,e

si
w,

ka

(e

Figure 9: Average execution time consumed by, (a) Falcon-AO, (b) OLA (c) Optima
BCD utilizing previous ordering scheme BCD ordering blocks similarity distribution, 6 21 ontology pairs conference domain. Although
ran algorithms pairs, show ontology pairs exhibited highest lowest differences average execution times. new ordering helped Optima
cut total execution time 262 seconds finding 1 correct
correspondence 6 false positives across pairs.

entity heights may differ two ontologies. based observation
generalization-specialization hierarchy concepts pertaining subtopic usually
invariant across ontologies.
sophisticated scheme founded observation temporarily transform
ontology, modeled labeled graph, tree. may utilize graph
search technique handles repeated nodes, breadth-first search graphs (Russell
& Norvig, 2010), obtain tree. ontology isolated graphs leading separate
trees, use owl:thing node combine single tree. Subsequently, group
variables participating entities ontology part subtree
825

fiT HAYASIVAM & OSHI






mff mfi


mff mfi











ff

fi











ff

fi

mff mff
mffff mff mfffi

mff mff
mffff mff mfffi


ff fi


ff fi














mff mfi




ff

fi
mff mff
mffff mff mfffi

ff fi


Figure 10: Matrices representing intermediate alignment entities O1 O2 . (a)
Identically shaded rows form block variables corresponding entities
O1 height. (b) Identically shaded rows columns correspond
entities heights O1 O2 , respectively. Variables overlapping regions
form block. (c) Entities corresponding identically shaded rows columns form
subtrees. fourth approach randomly select variables inclusion block.

predefined size (Fig. 10(c)). may discard ontology trees forming blocks.
previous schemes form blocks differing numbers variables, scheme forms
one block number variables limiting subtree size.
simple point comparison would scheme randomly selects alignment variables
inclusion block. clear way determine many variables include
block, randomly inserted variables 5 blocks.
Based findings previous subsection, blocks ordered based height
participating entities subtrees root nodes Falcon-AO OLA. begin blocks
smaller height proceed increasing height. Optima, sample blocks
using distribution based lexical similarity participating entities.
illustrated Fig. 11, partitioning ontologies helped Optima significantly saves execution times (p 0.01). pairs involving larger ontologies,
reduced order magnitude. Furthermore, Optima gains precision
pairs 6% 1% reduction recall resulting 3% gain F-measure 67%. OLA saves
execution time well relatively less Optima slight improvement alignment
quality. hand, Falcon-AO experienced increase total execution time
pairs. Optimas improved performance attributed blocks smaller allowing
comprehensive coverage search space less time. hand, iterative update
techniques Falcon-AO show improvement smaller blocks may
sign overpartitioning.
Figure 12 illustrates impact subtree-based partitioning three algorithms. Falcon-AO
exhibited significant reduction execution times (p < 0.01) simultaneously improvement
precision F-measure pairs 3%. Similar previous optimization, OLAs
execution time reduces significantly well (p < 0.01) keeping output unchanged.
826

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

12

Falcon-AO BCD
Falcon-AO BCD (both ontologies partitioned)

50

OLA BCD
OLA BCD (both ontologies partitioned)

10
40

Time (sec)

Time (sec)

8
30

20

6

4

10

2

0

0




e,e



t,s

cm

(

c
en

r

fe



(C

d)

)

d)


gk

,si

f
fO



(c

w)


gk

(


ias

d)


da

e)


gk

si

,




ed

)

ed


,ek

,
aw

k

(e

(e

1000

kd

e,s

c
en

r

fe



(C

kd

ig

ig

t,s


(c

(a)

d)

d)

da

t,e



(c

t,



(c

s)

nc



fe

n
Co

(

d)

d)

te



s,i


ed

kd

sig

w,


ek

(

(b)

Optima BCD
Optima BCD (both ontologies partitioned)

Time (sec)

100

10

1

0.1
f)

)

(

aw

,ed

fe

n


,ek

(c

f



ed

d)

te



s,i



ce



(C

)



fO



t,c

cm

(

(

d)

d)

te

ias

w,


ek

kd

ig

,s


te



(ia

(c)

Figure 11: Execution times consumed by, (a) Falcon-AO, (b) OLA, (c) Optima BCD
uses blocks obtained partitioning single ontology BCD utilizes
partitions ontologies, 6 21 ontology pairs conference domain.
Although ran algorithms pairs, selected ontology pairs exhibited highest lowest differences execution times. Optimas total execution
time pairs reduced 274 seconds. False positive correspondences reduced
37 expense 3 correct correspondences. OLA cut 10 seconds total
execution time 2 incorrect correspondences.

hand, partitioning technique reduces efficiency Optima small reduction
alignment quality well. Falcon-AOs GMO employs approach relies inbound
outbound neighbors, benefited using blocks whose participating entities form subtrees.
structure-based matching Optima limited looking correspondences
immediate children, including larger subtrees blocks may benefit Optima.
Finally, Fig. 13 explore impact randomly partitioning variables blocks
three alignment algorithms. Falcon-AO OLA showed significant increases execution time (p < 0.01) conference pairs. Falcon-AOs precision improved less
1%, recall dropped 2% overall reduction F-measure 1%. OLA exhibited minor increase precision 0.2% recall remained unchanged resulting increase
F-measure 0.2%. Optima demonstrated mixed results shown Fig. 13(c) execution
827

fiT HAYASIVAM & OSHI

35

12

Falcon-AO BCD
Falcon-AO BCD (subtree based partitioning)

30

OLA BCD
OLA BCD (subtree based partitioning)

10

25

Time (sec)

Time (sec)

8
20
15

6

4
10
2

5
0

0
f)

f)

fO

fO





(c


e,i

ce

n



fe



(C

nc



fe



(C

d)

)

aw

te

n
,co

n
,co

da

(e

d)

te

k
s,e


s,i

da

F)

d)

te


,ia

(e

f,e

t,c



k

(e

(c

d)

w)

ka

fO



aw


nf

f



(c



(c

(a)

)

aw

kd

,ek

ig

,s



da

(e

(e

)

d)

ed

st

,ia


da

kd

ig

,s




(e

(b)
1000

Optima BCD
Optima BCD (subtree based partitioning)

Time (sec)

100

10

1



(c

f)

d)

fO

te



t,i

n



fe



(C



n



fe



(C

,i
ce

d)

te



,c
ce



(e

d)

d)

te



,i


kd



(e

,
aw

d)

te

ias

ig

,s


k

(e

(c)

Figure 12: Execution times consumed by, (a) Falcon-AO, (b) OLA, (c) Optima, BCD
uses default partitioning approach BCD uses subtree-based partitioning, 6 21 ontology pairs conference domain. ran algorithms
pairs selected ontology pairs exhibited highest lowest
differences execution times. total execution time Falcon-AO complete
conference track reduces 8 sec along reduction 71 false positives. OLA
saves 1.5 sec total execution time keeping output alignments unchanged.
However, Optima consumes 192 seconds more.

time increasing pairs reducing others. whole, observe statistically significant difference execution times. Furthermore, BCD due random partitioning
improve beyond seed alignment many pairs, overall decrease F-measure
1% across pairs.
summary, side-by-side comparison various block ordering partitioning techniques
discussed previously presented Fig. 14 three alignment algorithms single ontology
pair, (edas, iasted). include random partitioning alignment performance terms
recall precision poor many ontology pairs making illsuited candidate.
Differences run time performance algorithms (edas, iasted) representative
828

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

40

30
Falcon-AO BCD
Falcon-AO BCD (randomly partitioned)

35

OLA BCD
OLA BCD (randomly partitioned)
25
20

Time (sec)

Time (sec)

30
25
20
15

15
10

10
5

5
0
nc



fe



(C

0

)



nf


e,c

)




e,e



fe



(C

)

w)

nc


,ek

da

g
,si



da

(e

(e

n
,co





(c

w

ka

(e

(a)

g
,si

d)

w)

fO

kd

kd

ias

s,



da

(e


te

f)

d)

d)





(c

kd

ig


,ek

nf

,s




(c



(e

d)

d)

te



,i


kd



(e

,
aw

d)

te

ias

ig

,s


k

(e

(b)

10

Time (sec)

Optima BCD
Optima BCD (randomly partitioned)

1

0.1

f)

en

r
fe



(C

da

,e
ce

en

r
fe

(C



d)

s)

fO



,c
ce

kd

ig

,s
ce

en

r
fe



(C



(c

(c)

)

ed

st

,ia

f
fO

(e

)

ed

st

,ia


da

)

ed

st

,ia

w
ka

(e

Figure 13: Execution times consumed by, (a) Falcon-AO, (b) OLA, (c) Optima, BCD
uses default partitioning approach BCD uses random partitioning.
show 6 21 ontology pairs conference domain. ran algorithms
pairs selected ontology pairs exhibited highest lowest
differences execution times. total execution time Falcon-AO complete
conference track increases 19.5 secs due random partitioning. OLA takes
additional 28 secs total execution time Optima saves 8.5 seconds
pairs expense alignment quality.

performances larger data set general. particular, Falcon-AOs run time reduces
using subtree-based partitioning obtain blocks. OLAs run time reduces
ontologies pair partitioned using entity height, Optima benefits ordering
blocks based preliminary measure similarity participating entities forming
blocks partitioning ontologies.

6. Aligning Large Biomedical Ontologies
Ontologies becoming increasingly critical life sciences (Bodenreider & Stevens, 2006;
Lambrix, Tan, Jakoniene, & Stromback, 2007) multiple repositories Bio2RDF (Belleau et al., 2008), OBO Foundry (Smith et al., 2007) NCBOs BioPortal (Musen et al., 2012)
829

fiT HAYASIVAM & OSHI

Time (sec)

100

default
ordered roots leaves
ordered similarity distribution
ontologies partitioned
subtree based partitioning

10

1

Falcon-AO BCD

OLA BCD

Optima BCD

Figure 14: side-by-side comparison performances three iterative algorithms using
various block ordering formation techniques. single moderately large ontology
pair, (edas, iasted), aligned. default represents iterative alignment algorithm BCD blocks ordered based height participating
entities leaves root single ontology partitioned form blocks.
Differences run times indicative performance general.

publishing growing number biomedical ontologies different domains anatomy
molecular biology. example, BioPortal hosts 370 ontologies whose domains fall
within life sciences. ontologies primarily used annotate biomedical data
literature order facilitate improved information exchange. growth ontology usage,
reconciliation overlap scope gains importance.
Evaluation general ontology alignment algorithms benefited immensely standardsetting benchmark OAEI (Shvaiko et al., 2012). addition multiple tracks real-world test
cases, competition emphasizes benchmark comparison tracks use test pairs modifications single ontology pair order systematically identify strengths weaknesses
alignment algorithms. One tracks real-world ontology pairs involves aligning
ontology adult mouse anatomy human anatomy portion NCI thesaurus (Golbeck
et al., 2003), another seeks align foundational model anatomy (FMA), SNOMED CT
national cancer institute thesaurus (NCI). However, aligning biomedical ontologies poses
unique challenges. particular,
1. Entity names often identification numbers instead descriptive names. Hence, alignment algorithm must rely labels descriptions associated entities,
expressed differently using different formats.
2. Although annotations using entities ontologies gene ontology (Ashburner
et al., 2000) growing rapidly, ontologies continue remain sparse. Consequently, may overly rely entity instances aligning biomedical ontologies.
3. Finally, biomedical ontologies tend large many including thousand entities.
motivates alignment approaches depend less brute-force steps, compels
assigning high importance issues related efficiency scalability.
Given specific challenges, combed 370 ontologies hosted NCBO
(Musen et al., 2012) OBO Foundry (Smith et al., 2007), isolated community benchmark
830

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

50 different biomedical ontology pairs. Thirty-two ontologies sizes ranging hundred
tens thousands entities constitute pairs. provide list ontologies participating
benchmark ontology pairs Appendix B. new benchmark guides comparative
evaluation alignment algorithms context key application domain biomedicine.
primary criteria including pair benchmark expectation sufficient
amount correspondences ontologies pair, determined NCBOs BioPortal. particular, calculated ratio correspondences posted BioPortal
ontology pair largest number possible correspondences could exist. selected
50 pairs largest ratio. Existing correspondences serve reference alignment.
include maps UMLS Metathesaurus crowd sourced. Nevertheless, analysis reveals existing correspondences constitute small fraction
total alignment possible two ontologies.
sought align pairs new biomedical ontology alignment testbed using BCDenhanced representative algorithms. obtained alignments evaluated using existing correspondences previously present BioPortal; reference alignments pairs likely
incomplete. secondary objective discover new correspondences ontologies
submit NCBOs BioPortal curation.
Informed experimentation described Section 5, blocks BCD Falcon-AO
formed using subtree-based partitioning one ontology ordered created. Blocks
OLA formed similarly though ontologies partitioned blocks Optima
formed partitioning ontologies basis height entities ordered
leaves root. execution times F-measure pairs successfully aligned within
arbitrary window 5 hours per pair BCD-enhanced algorithms shown Figs. 15
16. point BCD speeds algorithms explicitly promote scalability.
words, reduces time convergence provide way manage
memory order align large ontologies.
OLA BCD failed align single pair within time window. Falcon-AO enhanced
BCD without aligned 47 pairs within time window. Falcon-AO unable parse
one ontologies remaining 3 pairs due results available these.
Falcon-AO BCD aligned pairs taking 3.7 hours less time total original
consumed 7.5 hours pairs. show time pair Fig. 15(a). closer
look reveals Falcon-AO BCD exhibited time greater default 9 47 pairs.
Time pairs exceed 16 seconds due performing
subtree-based partitioning variables forming blocks BCD. corresponding Fmeasure change significantly due use BCD pairs F-measure
pairs 54.7%.
Optima enhanced BCD aligned 42 pairs within time window compared 30 pairs
without BCD. Optima unable parse one ontologies remaining 8 pairs due
results available these. Focusing 30 pairs aligned within
time window (Fig. 16), Optima BCD aligned pairs 2.3 hours taking 11.4 hours
less time compared original algorithm. Simultaneously, found additional 269 correct
correspondences across pairs increase F-measure 2%.
LogMap, fast non-iterative algorithm targets biomedical ontologies returned alignments
50 pairs 20 minutes total time. produced precision recall 23.5% 39.5%
(F-measure = 29.5%), respectively pairs. significantly less
831

fiT HAYASIVAM & OSHI

10000

Falcon-AO
Falcon-AO BCD

Time (sec)

1000

100

10

1

)
N)
)
N)
N) )
L) )
N) )
)

A) GA
N) )
)
)
) AA A)
)
T) A) A) O) RO A)
I) DA EL DA
)
)
)
BI DA P )
)
)
DA ER
)
A) )
)
RO
)
A) )
)
RO DA
G
A)
RO
)
DA O) ,OB EH IFC ,EH V) HD FA AO AO V) HD FA AO EH O) HO HD HD B-B HD GM AR N, HD ,MA ,EV ,EH ,UB E) V) ,BT ,EV ,PO ,PO VM ,EH O-C DS EV HD
EH ,TA SP S,
,N O,E O,E O,Z O,X O,T O,U ,E ,E ,Z
,T
,U O, ,BT ,V A,E A,E O,F O,E O,T O,C O,U ERO ,E G
G
G
G ,PA ,E ,U BT BT CV CV O,E D,C RO ,GR ,PS A, A,E
,

P
















F

F







IL
IL





B
E











H
H
H
H



H
FA FA B


B
B
B
B
(Z (Z (F (T (S (B (A (A (A (A (A (A (X (X (X (X (X (P (P (T (B (B (H (H (H (H (H (U (A (V (V (V (V (P (B (B (F (F (F (F (M (M (C (P (P (E (M

Ontology pair

(a)
1

Falcon-AO
Falcon-AO BCD

F-measure

0.8

0.6

0.4

0.2

0

)
N)
) )
)
N)
L) )
N) )
)

A) GA
N) )
)
)
) AA A) T) A) A) O) RON ) )
)
I) DA EL DA
)
)
BI DA P )
)
)
DA ER
A) )
)
RO
)
A) )
)
RO DA
G

A)
RO )
)
DA O) ,OB EH IFC EH V) HD FA AO AO V) HD FA AO EH O) HO HD HD B-B HD GM AR N, HD EV EH UB E) V) BT EV ,PO ,PO VM EH O-C DS EV HD
EH ,TA SP S, ,N O, ,E ,E ,Z ,X ,T ,U ,E ,E ,Z ,T ,U O, ,BT ,V A,E A,E ,F ,E ,T ,C ,U RO ,E G, G, G, G, ,PA ,E ,U BT, BT, CV CV ,E D,C O, ,GR ,PS A, ,E
,
FA B- AD AO SP AO AO AO AO AO AO AO AO AO AO AO AO IL IL AO AO AO AO AO EO HO HO HO HO B- B- B- B- FO AR HD FA
F
(Z (Z (F (T (S (B (A (A (A (A (A (A (X (X (X (X (X (P (P (T (B (B (H (H (H (H (H (U (A (V (V (V (V (P (B (B (F (F (F (F (M (M (C (P (P (E (M

Ontology pair

(b)

Figure 15: (a) Time consumed, (b) F-measure attained original Falcon-AO
optimized BCD 47 pairs large biomedical ontology testbed, respectively.
Note time axis log scale. Ontology names NCBO abbreviations.
alignment performed Red Hat machine Intel Xeon Core 2, processor speed
3 GHz 8GB memory.

Falcon-AO, exhibited precision recall 80.9% 41.3% respectively, pairs
aligned. Optima BCD exhibited precision 76.1% recall 35.8% overall
F-measure 48.7%. recall less LogMap, F-measure significantly better
due improved precision.
Finally, submitted 15 new correspondences entities pairs testbed
NCBO curation publication. nontrivial correspondences identified algorithms, present reference alignments appropriately validated us.
832

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

100000

Optima
Optima BCD

Time (sec)

10000

1000

100

10

N)
N)
N) A)
L)
N) )
N) )
)
)
)
A)
)
)
)
I)
)
A)
RO
)
I)
EL DA
)
)
)
)
A) )
)
RO
A) )
)
RO DA
G DA DA -BT DA) RO ERO ,M DA) A) V)
RO V)
DA
EB
PO
HD UBE )
DA O) ,OB EH IFC ,EH V)
N H
H

B
HD FA AO AO V)
H
VM H
HD FA AO EH O)
E
B
G
,B
HO H
V)
,P
,
,E
,M
,E
,E
,

EH ,TA SP
S, O,N PO O,E O,E O,Z O,X O,T O,U O,E O,E O,Z O,T O,U TO, ,BT O,V A,E A,E O,F O,E O,T O,C O,U ER O,E OG OG OG OG ,PA O,E O,U -BT -BT -CV -CV O,E D,C
,

FA ZFA FB TA SA BS AA AA AA AA AA AA XA XA XA XA XA PA PO TA BIL BIL HA HA HA HA HA UB AE VH VH VH VH PO BT BT FB FB FB FB MF MO
(Z
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(
(

Ontology pair

(a)
Optima
Optima BCD

1

F-measure

0.8

0.6

0.4

0.2

0

N)
) )
)
N)
)

L) )
N) )
N) )
)
)
) AA A) T) A) A) O) RON ) )
)
I) DA EL DA
)
)
BI
)
)
DA ER
A) )
RO
)
)
A) )
RO DA

)
G
RO )
DA O) ,OB EH IFC ,EH V) HD FA AO AO V) HD FA AO EH O) HO HD HD B-B HD GM AR N, HD ,MA ,EV ,EH ,UB E) V) ,BT ,EV ,PO ,PO VM
H


,
,
E
E
E
E
Z
X

U
F
E

C
U
N
E
E
Z

U

E

V
,E A,T -SP DS O, PO O, O, O, O, O, O, O, O, O, O, O, ,B O, A, A, O, O, O, O, O, ER O, OG OG OG OG ,P O,E O,U -BT -BT -CV -CV O,E D,C

L
L
F





B E H H H H
B B B B

F
F
B
(Z (Z (F (T (S (B (A (A (A (A (A (A (X (X (X (X (X (P (P (T (B (B (H (H (H (H (H (U (A (V (V (V (V (P (B (B (F (F (F (F (M (M

Ontology pair

(b)

Figure 16: (a) Time consumed, (b) F-measure attained original Optima
optimized BCD, 42 pairs biomedical ontology testbed, respectively. Note
time axis log scale.

7. Discussion
Performances iterative update search techniques impacted differently various ways
formulating blocks order processing them. Importantly, quality alignment
may adversely impacted. Nevertheless, approach grouping alignment variables blocks
based height participating entities ontologies motivated recognized
heuristic leads competitive performance observed negative impact precision
recall alignments. However, different ontology pairs may lead differing number
blocks various sizes: particular, tall ontologies exhibit deep class hierarchy result
blocks short ontologies.
833

fiT HAYASIVAM & OSHI

Given BCD-based enhancement optimization, well algorithms compare
terms execution time alignment quality state art? order answer
question, compare performances 18 algorithms participated conference
track OAEI 2012 (Shvaiko et al., 2012). Among these, iterative alignment algorithm, YAM++,
produced best F-measure 21 pairs followed LogMap utilize optimization CODI, Optima+, Optima augmented BCD. latter approaches
produced F-measures tied within 2% other. Optima+ ranked second
YAM++ alignment evaluated using F2 measure due comparatively high recall.
OAEI reports run time larger task aligning 120 conference ontology pairs. task,
YAM++ consumed 5 hours pairs, LogMap took slightly less 4
minutes Optima+ consumed 22 minutes. Falcon-AO OLA participate
OAEI 2012, ran separately 120 pairs machines, whose configurations
comparable utilized OAEI. Falcon-AO OLA enhanced BCD consumed 11
5 minutes respectively although alignment quality lower Optima+. would
place three representative algorithms top two-thirds among 18 participated
conference track OAEI terms run time OLA top half, Optima+ OLA
group 1 respect alignment quality. 6 7 competing algorithms completed evaluation
faster, 5 exhibit alignment quality substantially worse representative
algorithms. absence BCD, representative algorithms would ranked among
bottom third exceeded 5 hour cut off. Performance anatomy pair due BCD would
place Falcon-AO Optima+ top half 14 algorithms participated terms
run time F-measure. Previously, Optima without BCD ranked bottom quarter.
reductions convergence time observed increases precision alignment
due BCD is, part, optimized correspondences found previous coordinate block, influence selection correspondences current coordinate block.
Furthermore, mentioned previously, limiting randomly generated correspondences
MapPSO block instead whole ontology makes search guided. representative effect BCD iterative search general. Focusing single block
significantly reduces space alignments iterative techniques must search thereby
arriving optimum quicker. However, greater number smaller optimization subproblems must solved results imply smaller optimization problem offsets expense.
Given integrating BCD iterative algorithms converged different values Q
function iterative search different match matrices, , iterative update,
often produced better quality alignments, infer original algorithms converging
local optima instead global optima, using BCD likely resulted convergence
(better) local optima well. insight new (Euzenat et al., 2004), significant
reinforces presence local optima alignment space algorithms.
may limit efficacy iterative alignment techniques.
Falcon-AO Optima+s comparatively better performance measured using F-measure
fast, non-iterative algorithm, LogMap, biomedical ontology alignment testbed indicates
iterative techniques continue among best quality obtained alignment including large ontology pairs. motivates ways making efficient, BCD,
scalable.
6. Note MapPSO BCD would placed bottom third.

834

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

8. Conclusion Future Work
techniques scaling automated alignment large ontologies previously proposed, presented novel approach based BCD speed alignment process
important class algorithms. algorithms iterative anytime demonstrating high quality alignments often consuming time non-iterative algorithms. demonstrated
technique context four different iterative algorithms evaluated impact
total time execution final alignments precision recall. reported significant
reductions total execution times algorithms enhanced using BCD. reductions
noticeable larger ontology pairs. Often algorithms converged lesser number
iterations. Simultaneously, utilizing default scheme grouping alignment variables
participating entities one ontology block height optimizing blocks order increasing height, observe improvement precision
alignments generated algorithms significant change recall.
possible improve run time performance default partitioning
ordering scheme utilizing schemes, note may negatively impact
alignment quality. Subsequently, default scheme generally recommended existing new
iterative alignment techniques seek utilize BCD.
ability improve quickly allows iterative alignment algorithm run convergence
possible, contrast common practice terminating alignment process arbitrary
number iterations. predefining common bound number iterations difficult,
speeding convergence becomes vital. observe BCD promote scalability
large ontologies.
Finally, demonstrated benefits BCD toward aligning pairs new biomedical ontology testbed. Due large number ontologies biomedicine, critical need
ontology alignment vast domain. future work continue focus methods
would allow general principled alignment approaches Falcon-AO Optima perform better testbed producing better quality alignment pairs less time,
aligning large biomedical ontologies popular use SNOMED-CT NCI.
Consequently, believe community benchmark could potentially drive future research
toward pragmatic ontology alignment.

9. Acknowledgment
research supported part grant number R01HL087795 National Heart, Lung,
Blood Institute. content solely responsibility authors necessarily
represent official views National Heart, Lung, Blood Institute National Institutes Health. authors thank Todd Minning Rick Tarleton Center Tropical
Emerging Diseases University Georgia Amit Sheth Wright State University
useful discussions. authors also thank anonymous reviewers feedback benefited
article greatly.

835

fiT HAYASIVAM & OSHI

Appendix A. Representative Iterative Algorithms Enhanced BCD
chose four representative iterative alignment algorithms, Falcon-AO, MapPSO, OLA Optima order illustrate iterative algorithms could enhanced BCD. section,
present alignment algorithm original form enhanced BCD, facilitate direct
comparison quick identification needed modifications.
FALCON -AO/GMO-BCD (O1 , O2 , )

FALCON -AO/GMO (O1 , O2 , )
Initialize:
1. Iteration counter 0
2. G1 AdjacencyMatrix (O1 )
3. G2 AdjacencyMatrix (O2 )
4. 0
5.
1
6. 0
Iterate:
7.
8.
ii+1
9.
G1 i1 GT2 + GT1 i1 G2
10. CosineSim(M , )
11.
12.
13. Extract alignment

Initialize:
1. Iteration counter 0
2. G1 AdjacencyMatrix (O1 )
3. G2 AdjacencyMatrix (O2 )
4. 0
5.
1
6. Create partition :
{MS0 , MS1 , . . . , MSC }
7. 0
Iterate:
8.
9.
c % (C + 1), + 1
10. MSi c G1,Sc i1 GT2 + GT1,Sc i1 G2
11. MSi MSi1 Sc
12. c = C
13.
CosineSim(M , )
else
14.
high value
15.
16.
17. Extract alignment

Figure 17: (a) Iterative update structural matcher, GMO, Falcon-AO. (b) Iterative update
GMO modified perform BCD.

Fig. 17, show iterative algorithm GMO component Falcon-AO
enhancement due use BCD. AdjacencyMatrix (O1 ) (line 2 Fig. 17(a)) produces binary
matrix, G1 , size |V1 | |V1 |, value 1 ith row j th column represents
edge vertex indexed vertex indexed j bipartite graph model O1 ;
analogously AdjacencyMatrix (O2 ). update distance functions implemented
shown lines 9 10, respectively, algorithm. particular, cosine similarity computes
cosine two matrices consecutive iterations serialized vectors. Notice
iteration Fig. 17(b), block variables, MSi c , updated using Eq. 10 holding
remaining blocks fixed (lines 10 11). yields partially updated complete alignment
matrix reduced time, utilized next iteration.
MapPSOs iterative search algorithm performs particle swarm optimization modification due BCD shown Fig. 18. algorithm takes input number particles, K,
836

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

AP PSO-BCD (O1 , O2 , K, )
Initialize:
1. Iteration counter 0
2. Generate seed map
O1 O2
3. Populate binary matrix, 0 ,
seed correspondences
4. Generate K particles using
0
seed 0 : P = {M10 , M20 , . . . , MK
}
5. Create partition :
{MS0 , MS1 , . . . , MSC }
6. Search M0 arg max Q(Mk0 )

AP PSO (O1 , O2 , K, )
Initialize:
1. Iteration counter 0
2. Generate seed map O1 O2
3. Populate binary matrix, 0 ,
seed correspondences
4. Generate K particles using
0
seed 0 : P = {M10 , M20 , . . . , MK
}
0
0
5. Search arg max Q(Mk )

Mk0 P

Mk0 P

Iterate:
7.
8.
c % (C + 1), + 1
9.
k 1, 2, . . . , K


, Mi1 )
U pdateBlock(Mk,S
10.
Mk,S
c
c
i1

11.
Mk,
Mk,S Sc

12. Search Mi arg max QS (Mki )

Iterate:
6.
7.
ii+1
8.
k 1, 2, . . . , K
9.
Mki U pdateP article(Mki , Mi1 )
10. Search Mi arg max Q(Mki )
Mki P

Mki P

11. |Q(Mi ) Q(Mi1 )|
12. Extract alignment Mi

c = C
changed |Q(Mi ) Q(Mi1 )| ?
else
15.
changed true
16. changed
17. Extract alignment Mi

13.
14.

(a)

(b)

Figure 18: (a) Iterative search MapPSO. Objective function, Q, given Eq. 4. (b)
MapPSOs particle swarm based iterative algorithm enhanced BCD.

threshold, , addition two ontologies aligned. iteratively searches
alignment unable find one improves previous best alignment
equal . objective function, Q, modified QS Fig. 18(b), calculated
coordinate block interest. coordinate block particle, k, updated keeping
remaining blocks unchanged (lines 10 11), followed searching best particle based
measure alignment block (line 12). steps may performed reduced
time. Additionally, randomly generated mappings MapPSO limited block instead
whole ontology, due search becomes guided.
OLAs iterative algorithm shown Fig. 19 (a), enhancement due use BCD
Fig. 19(b). distance function line 11 measures similarity updated alignment
matrix previous iteration. iterations terminate distance falls
parameter, . Observe cycle blocks BCD enhanced algorithm
Fig. 19 (b) coordinates belonging current block, MSi c , updated lines 8-11.
837

fiT HAYASIVAM & OSHI

OLA-BCD (O1 , O2 , )

OLA (O1 , O2 , )
Initialize:
1. Iteration counter 0
2. Fill real-valued matrix, 0 , lexical similarity
3. 0
Iterate:
4.
5. + 1
6.
7. types x

P

wF
SetSim(F(xa ), F(y ))
8.

F N (xa ,y )

9.
10.
11.
12.
13.
14.

else
0
Dist(M , )


Extract alignment

Initialize:
1. Iteration counter 0
2. Populate real-valued matrix 0
lexical similarity values
3. Create partition :
{MS0 , MS1 , . . . , MSC }
4. 0
Iterate:
5.
6. c % (C + 1), + 1
7. MSi c
8. types xa

P

wF
SetSim(F(a), F())
9.

F N (a,)

10. else
11. 0
12. MSi = MSi1 Sc
13. c = C
14.
Dist(M , )
else
15.
high value
16.
17.
18. Extract alignment

(a)

(b)

Figure 19: (a) OLA iteratively updates alignment matrix using combination neighboring
similarity values. (b) OLAs BCD-integrated iterative ontology alignment algorithm.

Finally, Fig. 20, outline iterative search undertaken Optima modification
due BCD. Optimas expectation-maximization based iterative search uses binary matrix, ,
represent alignment. Objective function, Q, defined Eq. 6. search improved
alignment line 8 implemented using two steps expectation maximization. Iterations
terminate sample M, improves objective function, Q further, available.
search modified Fig. 20 (b) explore reduced search space, MSc , cycle
blocks. objective function, QS , prior operate single coordinate block.

Appendix B. Biomedical Ontology Alignment Benchmark
Biomedical ontologies bring unique challenges ontology alignment problem. Moreover,
explicit interest ontologies ontology alignment domain biomedicine. Consequently, present new biomedical ontology alignment testbed, provides important
application context alignment research community. Due large sizes biomedical
838

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

PTIMA -BCD (O1 , O2 )
Initialize:
1. Iteration counter 0
2. {1, 2, . . . , |V2 |}
3.
0 |V12 |
4. Generate seed map
O1 O2
5. Populate binary matrix, M0 ,
seed correspondences
6. Create partition :
{MS0 , MS1 , . . . , MSC }

PTIMA (O1 , O2 )
Initialize:
1. Iteration counter 0
2. {1, 2, . . . , |V2 |}
3.
0 |V12 |
4. Generate seed map
O1 O2
5. Populate binary matrix, M0 ,
seed correspondences

Iterate:
7.
8.
c % (C + 1), + 1
9.
Search MSi c , arg max QS (MSi c |Mi1 )

Iterate:
6.
7.
ii+1
8.
Search Mi arg max Q(M |Mi1 )

P|V1M
|
P r(y |xa , Mi1 )
9.
|V11 | a=1
10. Mi 6= Mi1
11. Extract alignment Mi

10.
11.
12.
13.

MSc MSc
i1

MS, MS, Sc
P|V1,c |
1
i1

)
,c
|V1,c
a=1 P r(y |xa ,
|

c = C
changed Mi 6= Mi1 ?
else
14.
changed true
15. changed
16. Extract alignment Mi

(a)

(b)

Figure 20: (a) Optimas expectation-maximization based iterative search algorithm.
(b)
Expectation-maximization based iterative ontology alignment Optima BCD.

ontologies, testbed could serve comprehensive large ontology benchmark. Existing correspondences NCBO may serve reference alignments pairs, although analysis
reveals maps represent small fraction total alignment possible
two ontologies. Consequently, new correspondences discovered benchmarking may
submitted NCBO curation publication.
order create testbed, combed 370 ontologies hosted NCBO
OBO Foundry, isolated benchmark 50 different biomedical ontology pairs. Thirty-two
ontologies sizes ranging hundred tens thousands entities constitute
pairs, listed Table 2. provide snapshot full benchmark Table 3. testbed
reference alignments available download http://tinyurl.com/n4t2ns3.
primary criteria including pair benchmark presence sufficient amount
correspondences ontologies pair, determined NCBOs BioPortal.
briefly describe steps creating testbed:
1. selected ontologies, exist either OWL RDF models.
839

fiT HAYASIVAM & OSHI

2. paired ontologies ordered pairs percentage available correspondences. ratio correspondences exist BioPortal pair ontologies
consideration divided product number entities ontologies.
3. Top 100 ontology pairs based ratio selected, followed ordering pairs
based joint sizes.
4. created 5 bins equal sizes randomly sampled bin uniform distribution
obtain final 50 pairs.
Named
Data
Classes
Properties
114
0
Bilateria anatomy (BILA)
50
0
Common Anatomy Reference Ontology (CARO)
282
2
Plant Growth Development Stage (PO PSDA)
821
0
FlyBase Controlled Vocabulary (FBcv)
129
0
Spatial Ontology (BSPO)
1603
0
Amphibian gross anatomy (AAO)
238
0
Anatomical Entity Ontology (AEO)
1270
7
Cereal plant gross anatomy (GR CPGA)
1,270
6
Plant Anatomy (PO PAE)
821
0
Subcellular Anatomy Ontology (SAO)
1,041
0
Xenopus anatomy development (XAO)
1,184
0
vertebrate Homologous Organ Groups (sHOG)
1,930
4
Hymenoptera Anatomy Ontology (HAO)
3,039
0
Teleost Anatomy Ontology (TAO)
628
0
Tick gross anatomy (TADS)
2,788
5
Zebrafish anatomy development (ZFA)
4,358
0
Medaka fish anatomy development (MFO)
5,139
4
BRENDA tissue / enzyme source (BTO)
2274
0
Expressed Sequence Annotation Humans (eVOC)
7,797
0
Drosophila gross anatomy (FBbt)
2,281
24
Phenotypic quality (PATO)
7,294
112
Uber anatomy ontology (UBERON)
6,599
0
Fly taxonomy (FBsp)
1,338
4
Protein modification (MOD)
2,314
0
Human developmental anatomy (EHDAA)
8,340
0
Human developmental anatomy timed version (EHDA)
1,585
7
Plant Ontology (PO)
2,703
73
NIF Cell (NIF Cell)
2,982
1
Mouse adult gross anatomy (MA)
1,864
3
Mosquito gross anatomy (TGMA)
3,537
102
Ontology Biomedical Investigations (OBI)
31,470
9
Chemical entities biological interest (CHEBI)
Table 2: Selected ontologies NCBO biomedical ontology
alignment testbed number named classes properties
each. Notice data set includes large ontologies. NCBO abbreviations ontologies also provided.
Ontology

840

Object
Properties
9
9
0
10
9
9
6
0
0
85
10
7
4
9
0
0
6
9
7
10
0
0
0
0
7
7
0
5
6
0
6
0

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

Biomedical ontology alignment testbed
Ontology O1
Ontology O2
|V1 | |V2 |
Common Anatomy Reference Ontology
Human developmental anatomy (EHDAA)
115,700
(CARO)
Bilateria anatomy (BILA)
Human developmental anatomy (EHDAA)
263,796
Bilateria anatomy (BILA)
Human developmental anatomy (EHDAA)
263,796
Spatial Ontology (BSPO)
Human developmental anatomy (EHDAA)
298,506
Plant Growth Development Stage
Plant Ontology (PO)
446,970
(PO PSDA)
Anatomical Entity Ontology (AEO)
Human developmental anatomy (EHDAA)
550,732
FlyBase Controlled Vocabulary (FBcv)
Cereal plant gross anatomy (GR CPGA)
1,042,670
FlyBase Controlled Vocabulary (FBcv)
Plant Ontology (PO)
1,301,285
Tick gross anatomy (TADS)
Human developmental anatomy (EHDAA)
1,453,192
Amphibian gross anatomy (AAO)
Xenopus anatomy development (XAO)
1,668,723
Cereal plant gross anatomy (GR CPGA)
Plant Ontology (PO)
2,012,950
Plant Anatomy (PO PAE)
Plant Ontology (PO)
2,012,950
Subcellular Anatomy Ontology (SAO)
NIF Cell (NIF Cell)
2,219,163
Expressed Sequence Annotation Humans
Xenopus anatomy development (XAO)
2,367,234
(eVOC)
Xenopus anatomy development (XAO)
Human developmental anatomy (EHDAA)
2,408,874
vertebrate Homologous Organ Groups Expressed Sequence Annotation Humans
2,692,416
(sHOG)
(eVOC)
vertebrate Homologous Organ Groups
Human developmental anatomy (EHDAA)
2,739,776
(sHOG)
Xenopus anatomy development (XAO)
Zebrafish anatomy development (ZFA)
2,902,308
Xenopus anatomy development (XAO)
Teleost Anatomy Ontology (TAO)
3,163,599
vertebrate Homologous Organ Groups
Mouse adult gross anatomy (MA)
3,530,688
(sHOG)
Hymenoptera Anatomy Ontology (HAO)
Mosquito gross anatomy (TGMA)
3,597,520
vertebrate Homologous Organ Groups
Teleost Anatomy Ontology (TAO)
3,598,176
(sHOG)
Expressed Sequence Annotation Humans
Amphibian gross anatomy (AAO)
3,645,222
(eVOC)
Amphibian gross anatomy (AAO)
Human developmental anatomy (EHDAA)
3,709,342
Hymenoptera Anatomy Ontology (HAO)
Human developmental anatomy (EHDAA)
4,466,020
Amphibian gross anatomy (AAO)
Zebrafish anatomy development (ZFA)
4,469,164
Amphibian gross anatomy (AAO)
Teleost Anatomy Ontology (TAO)
4,871,517
Expressed Sequence Annotation Humans
Human developmental anatomy (EHDAA)
5,262,036
(eVOC)
Phenotypic quality (PATO)
Human developmental anatomy (EHDAA)
5,278,234
Zebrafish anatomy development (ZFA)
Human developmental anatomy (EHDAA)
6,451,432
Plant Anatomy (PO PAE)
BRENDA tissue / enzyme source (BTO)
6,526,530
Teleost Anatomy Ontology (TAO)
Human developmental anatomy (EHDAA)
7,032,246
Xenopus anatomy development (XAO)
Uber anatomy ontology (UBERON)
7,593,054
Zebrafish anatomy development (ZFA)
Teleost Anatomy Ontology (TAO)
8,472,732
Continued next page

841

fiT HAYASIVAM & OSHI

Ontology 1
vertebrate Homologous Organ Groups
(sHOG)
Medaka fish anatomy development
(MFO)
Medaka fish anatomy development
(MFO)
BRENDA tissue / enzyme source (BTO)
Amphibian gross anatomy (AAO)
BRENDA tissue / enzyme source (BTO)
Hymenoptera Anatomy Ontology (HAO)
Hymenoptera Anatomy Ontology (HAO)
Expressed Sequence Annotation Humans
(eVOC)

Ontology 2

|V1 | |V2 |

Uber anatomy ontology (UBERON)

8,636,096

Expressed Sequence Annotation Humans
(eVOC)

9,910,092

Human developmental anatomy (EHDAA)
Expressed Sequence Annotation Humans
(eVOC)
Uber anatomy ontology (UBERON)
Human developmental anatomy (EHDAA)
Uber anatomy ontology (UBERON)
Drosophila gross anatomy (FBbt)
Uber anatomy ontology (UBERON)

Expressed Sequence Annotation Humans
(eVOC)
Zebrafish anatomy development (ZFA)
Uber anatomy ontology (UBERON)
Uber anatomy ontology (UBERON)
Mouse adult gross anatomy (MA)
Ontology Biomedical Investigations
Fly taxonomy (FBsp)
(OBI)
BRENDA tissue / enzyme source (BTO)
Uber anatomy ontology (UBERON)
Drosophila gross anatomy (FBbt)
BRENDA tissue / enzyme source (BTO)
Chemical entities biological interest
Protein modification (MOD)
(CHEBI)
Table 3: biomedical ontology pairs testbed sorted terms
|V1 | |V2 |. metric illustrative complexity aligning
pair.
Drosophila gross anatomy (FBbt)

10,084,412
11,686,086
11,692,282
11,891,646
14,077,420
15,048,210
16,586,556
17,730,378
20,335,672
21,750,708
23,340,663
37,483,866
40,068,783
42,106,860

References
Arimoto, S. (1972). algorithm computing capacity arbitrary discrete memoryless
channels. IEEE Transactions Information Theory, 18(1), 1420.
Ashburner, M., Ball, C. A., Blake, J. A., Botstein, D., Butler, H., Cherry, J. M., Davis, A. P., Dolinski, K., Dwight, S. S., Eppig, J. T., Harris, M. A., Hill, D. P., Issel-Tarver, L., Kasarskis,
A., Lewis, S., Matese, J. C., Richardson, J. E., Ringwald, M., Rubin, G. M., & Sherlock, G.
(2000). Gene ontology: tool unification biology. gene ontology consortium..
Nature genetics, 25(1), 2529.
Baader, F., Horrocks, I., & Sattler, U. (2003). Description logics ontology languages
semantic web. Lecture Notes Artificial Intelligence, pp. 228248. Springer-Verlag.
Belleau, F., Nolin, M.-A., Tourigny, N., Rigault, P., & Morissette, J. (2008). (bio2rdf): Towards
mashup build bioinformatics knowledge systems. Journal Biomedical Informatics,
41(5), 706716.
842

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

Blahut, R. E. (1972). Computation channel capacity rate-distortion functions. IEEE Transactions Information Theory, 18, 460473.
Bock, J., & Hettenhausen, J. (2010). Discrete particle swarm optimisation ontology alignment.
Information Sciences, 192, 122.
Bodenreider, O., & Stevens, R. (2006). Bio-ontologies: current trends future directions. Brief
Bioinform, 7, 256274.
Cruz, I. F., Stroe, C., & Palmonari, M. (2012). Interactive user feedback ontology matching
using signature vectors. IEEE 28th International Conference Data Engineering, pp.
13211324. IEEE Computer Society.
Doan, A., Madhavan, J., Domingos, P., & Halevy, A. (2003). Ontology matching: machine learning approach. Handbook Ontologies Information Systems, pp. 397416. Springer.
Doshi, P., Kolli, R., & Thomas, C. (2009). Inexact matching ontology graphs using expectationmaximization. Web Semantics: Science, Services Agents World Wide Web, 7(2),
90106.
Euzenat, J., Loup, D., Touzani, M., & Valtchev, P. (2004). Ontology alignment OLA.
Proceedings 3rd EON Workshop, 3rd International Semantic Web Conference, pp.
5968. CEUR-WS.
Euzenat, J., & Valtchev, P. (2004). Similarity-based ontology alignment OWL-lite. European
Conference Artificial Intelligence (ECAI), pp. 333337.
Euzenat, J., & Shvaiko, P. (2007). Ontology Matching. Springer.
Fessler, J. A., & Hero, A. O. (1994). Space-alternating generalized expectation-maximization algorithm. IEEE Transactions Signal Processing, 42, 26642677.
Fessler, J. A., & Kim, D. (2011). Axial block coordinate descent (abcd) algorithm X-ray CT
image reconstruction. Proceedings Fully 3D Image Reconstruction Radiology
Nuclear Medicine, pp. 262265.
Golbeck, J., Fragoso, G., Hartel, F., Hendler, J., Oberthaler, J., & Parsia, B. (2003). national
cancer institutes thesaurus ontology. Journal web semantics, 1(1), 7580.
Hanif, M. S., & Aono, M. (2009). Anchor-flood: results OAEI 2009. Proceedings
Workshop Ontology Matching 8th International Semantic Web Conference, pp. 127
134.
Hayes, J., & Gutierrez, C. (2004). Bipartite graphs intermediate model RDF. Proceedings 3rd International Semantic Web Conference (ISWC), Lecture Notes Computer
Science, pp. 4761. Springer Berlin / Heidelberg.
Hero, A. O., & Fessler, J. A. (1993). Asymptotic convergence properties (em)-type algorithms.
Tech. rep., Department EECS, Univ. Michigan, Ann Arbor, MI.
Hu, W., Jian, N., Qu, Y., & Wang, Y. (2005). GMO: graph matching ontologies. K-Cap
Workshop Integrating Ontologies, pp. 4350.
Hu, W., Zhao, Y., & Qu, Y. (2006). Partition-based block matching large class hierarchies.
Proceedings 1st Asian Semantic Web Conference (ASWC), pp. 7283.
843

fiT HAYASIVAM & OSHI

Hughes, T. C., & Ashpole, B. C. (2004). semantics ontology alignment. Information
Interpretation Integration Conference (I3CON).
Jean-Mary, Y. R., Shironoshita, E. P., & Kabuka, M. R. (2009). Ontology matching semantic
verification. Web Semantics: Science, Services Agents World Wide Web, 7(3),
235251.
Jian, N., Hu, W., Cheng, G., & Qu, Y. (2005). Falcon-AO: Aligning ontologies Falcon.
K-Cap Workshop Integrating Ontologies, pp. 8793.
Jimenez-Ruiz, E., & Grau, B. C. (2011). LogMap: Logic-based scalable ontology matching.
International Semantic Web Conference, pp. 273288.
Kirsten, T., Gross, A., Hartung, M., & Rahm, E. (2011). GOMMA: component-based infrastructure managing analyzing life science ontologies evolution. Journal
Biomedical Semantics, 2, 6.
Lambrix, P., Tan, H., Jakoniene, V., & Stromback, L. (2007). Biological ontologies In: Semantic
Web: Revolutionizing Knowledge Discovery Life Sciences, pp. 8599. Springer.
Li, Y., Li, J., & Tang, J. (2007).
RiMOM: Ontology alignment strategy selection. Proceedings 6th International 2nd Asian Semantic Web Conference
(ISWC2007+ASWC2007), pp. 5152.
McGuinness, D., & Harmelen, F. (2004). Owl web ontology language overview. Tech. rep., W3C.
Melnik, S., Garcia-molina, H., & Rahm, E. (2002). Similarity flooding: versatile graph matching
algorithm. ICDE: Int. Conference Data Engineering, pp. 117128.
Musen, M. A., Noy, N. F., Shah, N. H., Whetzel, P. L., Chute, C. G., Storey, M.-A. D., & Smith, B.
(2012). national center biomedical ontology. JAMIA, 19(2), 190195.
Nesterov, Y. (2012). Efficiency coordinate descent methods huge-scale optimization problems.
SIAM Journal Optimization, 22(2), 341362.
Ngo, D., & Bellahsene, Z. (2012). YAM++ : multi-strategy based approach ontology matching
task. International Conference Knowledge Engineering Knowledge Management,
pp. 421425.
Pinter, J. D. (2000). Yair censor stavros a. zenios, parallel optimization theory, algorithms,
applications. Journal Global Optimization, 16, 107108.
Rahm, E. (2011). Towards large-scale schema ontology matching. Bellahsene, Z., Bonifati,
A., & Rahm, E. (Eds.), Schema Matching Mapping, pp. 327. Springer.
Russell, S. J., & Norvig, P. (2010). Artificial Intelligence - Modern Approach (3rd edition).
Pearson Education.
Saha, A., & Tewari, A. (2013). non-asymptotic convergence cyclic coordinate descent
methods. SIAM Journal Optimization, 23(1), 576601.
Seddiqui, M. H., & Aono, M. (2009). efficient scalable algorithm segmented alignment
ontologies arbitrary size. Web Semantics: Science, Services Agents World
Wide Web, 7, 344356.
Shvaiko, P., & Euzenat, J. (2013). Ontology matching: State art future challenges. IEEE
Transactions Knowledge Data Engineering, 25(1), 158176.
844

fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD

Shvaiko, P., Euzenat, J., Heath, T., Quix, C., Mao, M., & Cruz, I. F. (Eds.). (2011). Proceedings
6th International Workshop Ontology Matching, Vol. 814 CEUR Workshop Proceedings. CEUR-WS.org.
Shvaiko, P., Euzenat, J., Kementsietsidis, A., Mao, M., Noy, N., & Stuckenschmidt, H. (Eds.).
(2012). Results Ontology Alignment Evaluation Initiative (OAEI) 2012, Vol. 946
CEUR Workshop Proceedings. CEUR-WS.org.
Shvaiko, P., Euzenat, J., Srinivas, K., Mao, M., & Jimenez-Ruiz, E. (Eds.). (2013). Preliminary
Results Ontology Alignment Evaluation Initiative (OAEI) 2013, Vol. 1111 CEUR
Workshop Proceedings. CEUR-WS.org.
Smith, B., Ashburner, M., Rosse, C., Bard, J., Bug, W., Ceusters, W., Goldberg, L. J., Eilbeck,
K., Ireland, A., Mungall, C. J., Leontis, N., Rocca-Serra, P., Ruttenberg, A., Sansone, S.-A.,
Scheuermann, R. H., Shah, N., Whetzel, P. L., & Lewis, S. (2007). OBO foundry: coordinated evolution ontologies support biomedical data integration. Nature Biotechnology,
25(11), 12511255.
Stoutenburg, S. K., Kalita, J., Ewing, K., & Hines, L. M. (2010). Scaling alignment large ontologies. International Journal Bioinformatics Research Applications, 6, 384401.
Thayasivam, U., & Doshi, P. (2012a). Improved convergence iterative ontology alignment using
block-coordinate descent. Twenty-Sixth Conference Artificial Intelligence (AAAI), pp.
150156.
Thayasivam, U., & Doshi, P. (2012b). Optima+ results OAEI 2012. Workshop Ontology Matching 11th International Semantic Web Conference (ISWC). Vol. 946 CEURWS.org.
Tseng, P. (2001). Convergence block coordinate descent method nondifferentiable minimization. Journal Optimization Theory Applications, 109, 475494.
Wang, P., & Xu, B. (2009). Lily: Ontology alignment results OAEI 2008. Proceedings
Workshop Ontology Matching 7th International Semantic Web Conference (ISWC).

845

fiJournal Artificial Intelligence Research 50 (2014) 321-367

Submitted 1/14; published 6/14

Game-Theoretic Security Patrolling Dynamic Execution
Uncertainty Case Study Real Transit System
Francesco M. Delle Fave
Albert Xin Jiang
Zhengyu Yin
Chao Zhang
Milind Tambe

dellefav@usc.edu
jiangx@usc.edu
zhengyuy@usc.edu
zhan661@usc.edu
tambe@usc.edu

University Southern California,
Los Angeles, CA 90089 USA

Sarit Kraus

sarit@cs.biu.ac.il

Bar Ilan University,
Ramat Gan 52900, Israel

John P. Sullivan

jpsulliv@lasd.org

Los Angeles County Sheriff Department
Los Angeles, CA 90059

Abstract
Attacker-Defender Stackelberg security games (SSGs) emerged important
research area multi-agent systems. However, existing SSGs models yield fixed, static,
schedules fail dynamic domains defenders face execution uncertainty, i.e.,
domains defenders may face unanticipated disruptions schedules. concrete
example application involving checking fares trains, defenders schedule
frequently interrupted fare evaders, making static schedules useless.
address shortcoming, paper provides four main contributions. First,
present novel general Bayesian Stackelberg game model security resource allocation
dynamic uncertain domains. new model, execution uncertainty handled
using Markov decision process (MDP) generating defender policies. Second, study
problem computing Stackelberg equilibrium game exploit problem
structure reduce polynomial-sized optimization problem. Shifting evaluation,
third contribution shows, simulation, MDP-based policies overcome
failures previous SSG algorithms. doing, build complete system,
enables handling schedule interruptions and, consequently, conduct first
controlled experiments SSGs field. Hence, final contribution, present
results real-world experiment Metro trains Los Angeles validating MDPbased model, importantly, concretely measuring benefits SSGs security
resource allocation.

1. Introduction
recent years, research algorithmic game theory started show significant interest
security resource optimization problems. research led decision aids realworld security agencies need deploy patrols checkpoints protect targets
terrorists criminals (Tambe, 2011). Stackelberg security games (SSGs)
advocated powerful tool model problems (Gatti, 2008; Conitzer, 2012; Basilico,
c
2014
AI Access Foundation. rights reserved.

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

Gatti, & Amigoni, 2009a; Vorobeychik & Singh, 2012; Vanek, Jakob, Lisy, Bosansky, &
Pechoucek, 2011; Pita, Jain, Western, Portway, Tambe, Ordonez, Kraus, & Paruchuri, 2008;
Tambe, 2011). SSG two-player game defender (the security agency)
adversary (a terrorist criminal). defender commits mixed strategy
randomized resource allocation specified probability distribution deterministic
schedules takes account adversarys best response observation
mixed strategy1 . Several decision-support systems based SSGs successfully
deployed real world domains assisting security ports, airports, ferries
transit systems. Examples include ARMOR GUARDS airport security (Pita et al.,
2008; Pita, Tambe, Kiekintveld, Cullen, & Steigerwald, 2011), IRIS allocating security
personnel international flights US Carriers (Tsai, Rathi, Kiekintveld, Ordonez, &
Tambe, 2009), PROTECT randomized patrols security ports passenger ferries
ports New York, Boston Los Angeles (Shieh, An, Yang, Tambe, Baldwin,
DiRenzo, Maule, & Meyer, 2012; Fang, Jiang, & Tambe, 2013) TRUSTS patrolling
Metro trains Los Angeles (Yin, Jiang, Johnson, Tambe, Kiekintveld, Leyton-Brown,
Sandholm, & Sullivan, 2012).
domains discussed involve patrolling transportation system
train-line, ferry flight system. settings, schedules typically timecritical depend time table vehicles (trains, ferries flights).
However, interruptions frequent patrolling key transportation systems
officer might respond emergency, provide assistance passenger
need arrest someone. example, patrolling trains, whenever officer delayed
midway, might become impossible officer complete patrol schedule. Hence,
fixed schedules cannot updated interruption hard follow
officer delayed. Unfortunately, previous work often provided static fixed patrolling
schedules face problems presence unanticipated disruptions.
general, execution uncertainty endemic transportation domains
affect defender units ability carry planned schedules later time steps. One
motivating example, used throughout work, TRUSTS system
scheduling fare inspections Los Angeles metro rail system (LA Metro). TRUSTS (Yin
et al., 2012), currently evaluated Los Angeles sheriffs department (LASD),
provides game-theoretic solution scheduling randomized patrols fare inspections
trains stations. see later paper, real world trials carried
LASD, significant fraction executions pre-generated schedules got
interrupted variety reasons writing citations, felony arrests, handling
emergencies. interruptions caused officers miss train supposed
take part patrol schedule. occasions, solution TRUSTS
provide instructions interruption making schedules useless
officers.
Previous work addressed aspects execution uncertainty. particular, Yin,
Jain, Tambe, Ordonez (2011), Yin Tambe (2012) present two different approaches,
one based robust optimization another Bayesian method, whereby defender
optimizes mixed strategy taking account (small) fraction
1. convention security games literature, defender referred adversary
he.

322

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

incorrectly executed. Unfortunately, discussed above, domains interest
work, including TRUSTS, significant fraction schedules interrupted.
importantly, cases, previous work suggest alternatives whenever
defenders patrol interruptedthus fails optimally use patrol time.
clearly indicates key challenge still needs addressed SSGs: new framework
needed, generate patrol schedules robust execution uncertainty
provide contingency plans whenever disruptions occur.
provide framework, paper presents four main contributions. first
contribution consists general Bayesian Stackelberg game model security patrolling
execution uncertainty. model, execution uncertainty handled via Markov
decision process (MDP). second contribution detailed study problem
computing Stackelberg equilibrium (SSE) game. Computing SSE timely
fashion presents significant computational challenges defenders strategy space,
already exponential real-world applications (Jain, Kardes, Kiekintveld, Tambe, &
Ordonez, 2010; Conitzer, 2012), grows complexity given must address
contingencies execution. address shortcoming, show
games utility functions specific separable structure, defenders strategy space
compactly represented. using structure, reduce problem
polynomial-sized optimization problem, solved existing approaches
solving Bayesian Stackelberg games without execution uncertainty, e.g., DOBSS (Paruchuri,
Pearce, Marecki, Tambe, Ordonez, & Kraus., 2008b). However, randomized patrol
schedules obtain, well-defined MDP-policies, i.e., plans, take
account contingencies unexpected events. show remainder work,
policies always generated polynomially-sized support. addition,
policies loaded smart-phone application carried patrol units shift.
next two contributions focus application former approach generate
patrol schedules fare inspection LA Metro. detail, third contribution
shows simulation that, modeling execution uncertainty MDP, able
generate policies overcome failures existing SSG algorithms take
uncertainty account. addition, results numerical experiments show
execution uncertainty significant impact defenders expected utility.
key question raised deployed applications SSGs evaluation performance field. Whereas many different evaluation metrics offered,
difficult evaluate SSGs approaches resource allocation generate
actual domains airport port security (Tambe, 2011). Fortunately, MDP policies
new game model, loaded onto smartphonesan application discuss later
paperenables us test use SSGs field alternatives.
fundamentally new test real world validate new game model,
generally, algorithmic game theory field. Therefore, fourth contribution
real-world experiment aims evaluate comprehensive game-theoretic system
field. Specifically, ran 21-day experiment, compared schedules generated using approach competing schedules comprised random scheduler
augmented officers providing real-time knowledge current situation. results
provided evidence support MDP-based modelthe contingency plans provided
MDP actually used significant frequency real world. importantly,
323

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

results showed game-theoretic schedules led statistically significant improvements competing schedules, despite fact latter improved
real-time knowledge. results constitute first example head-to-head comparison
SSGs competing approaches field. fact, constitute first
data obtained deploying algorithmic game theory real-world.
summary, paper makes following contributions:
present novel Bayesian Stackelberg game model accounts execution
uncertainty security patrolling using MDP.
study problem computing Stackelberg equilibrium (SSE) game.
Specifically, derive conditions game represented compact form, solved polynomial time. resulting strategies are,
however, MDP-policies, i.e., plans, take account contingencies unexpected events.
present extensive empirical evaluation whereby analyze impact execution uncertainty new game model expected utility defender.
present real-world experiment compared schedules generated using
approach competing schedules comprised random scheduler. results
showed game-theoretic schedules outperformed competing schedules terms
number fare evaders captured. doing, provide evidence
benefits deploying algorithmic game theory real-world.
remainder paper organized follows: Section 2 presents related work
SSGs handle uncertainty. Section 3 discusses motivating problem
patrolling LA Metro system presents formal model problem Bayesian
Stackelberg game. Section 4 discusses solution method. Section 5 discusses way
apply model defined Section 4 LA Metro problem. Section 6 discusses
evaluation consisting simulations real world experiments and, finally Section 7
concludes discusses future work.

2. Related Work
Stackelberg security games (SSGs) gathered significant attention literature (Basilico
et al., 2009a; Dickerson, Simari, Subrahmanian, & Kraus, 2010; Letchford, MacDermed,
Conitzer, Parr, & Isbell, 2012; Letchford & Conitzer, 2013; Letchford & Vorobeychik, 2013;
Korzhyk, Conitzer, & Parr, 2011a, 2011b). Indeed, stated earlier, SSGs models
algorithms used build decision aids including ARMOR (Pita et al., 2008), IRIS
(Tsai et al., 2009), GUARDS (Pita et al., 2011) PROTECT (Shieh et al., 2012).
importantly, two systems, namely TRUSTS (Yin et al., 2012) RaPtoR (Varakantham,
Lau, & Yuan, 2013), used generate schedules patrolling public transit
systems LA Metro Singapore Metro system. Unfortunately,
deployed applications take execution uncertainty account. consequence,
useful settings interest paper, ones involving patrolling
transportation system disruptions may occur frequently.
324

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

Nonetheless, tackling uncertainty become one principal challenges SSGs
research. particular, previous work focused different types uncertainties: uncertainty adversary response due bounded rationality (Yang, Kiekintveld, Ordonez,
Tambe, & John, 2011; Nguyen, Yang, Azaria, Kraus, & Tambe, 2013), uncertainty adversary surveillance (An, Tambe, Ordonez, Shieh, & Kiekintveld, 2011), uncertainty adversary capability uncertainty defender execution strategies (Yin et al., 2011; Yin &
Tambe, 2012)2 . respect bounded rationality, previous approaches focused
different models bounded rationality, logit quantal response subjective utility
quantal response (Yang et al., 2011; Nguyen et al., 2013). However, frameworks
address execution uncertainty and, consequence, address challenge
studied work. respect adversary surveillance, previous approaches focused modeling fact many domains adversary partially observe
defenders mixed strategy (An, Kempe, Kiekintveld, Shieh, Singh, & Tambe, 2012).
Similarly, respect uncertainty adversarys surveillance capability
defenders execution strategy, previous approaches focused modeling uncertainty
using Bayesian game (Yin & Tambe, 2012) using robust strategy computation,
including robust optimization, provide safe quality guarantees obtained defenders
strategy (Yin et al., 2011). Unfortunately, discussed Section 1, approaches
suggest alternative whenever defenders patrol interrupted. Thus
address challenge setting, would generate schedules would
become useless anytime defender interrupted.
game theoretic perspective then, game model paper considered
extensive-form Stackelberg games chance nodes (Letchford & Conitzer, 2010),
special case stochastic Stackelberg game follower choose
one action initial state stick action future states (Letchford et al.,
2012). general cases games shown NP-hard. Vorobeychik
Singh provided mixed integer linear programs finding optimal approximate Markov
stationary strategy general-sum stochastic Stackelberg games (Vorobeychik & Singh,
2012). However, approach handle multiple adversary types MILP
formulation lacks scalability large number states LA Metro problems.
Another related line research equilibrium refinement dynamic games,
trembling hand perfect equilibrium (Aoyagi, 1996), considers possibility
strategy imperfectly executed. However research mainly interested
limit uncertainty goes zero, real world settings probability imperfect
execution really non-zero.
types SSGs include multi-robot adversarial patrolling games (MAPG).
MAPG special restricted type SSG considers problem multi-robot
patrol around closed area existence adversary attempting penetrate
area (Agmon, Kraus, & Kaminka, 2008a; Agmon, Kaminka, & Kraus, 2011).
penetration requires time defender identify attacker attempt.
literature uncertainty MAPGs studied uncertainty related type
2. Execution uncertainty also studied context finding Nash-equilibrium standard
multi-player simultaneous move games (Bowling & Veloso, 2004; Archibald & Shoham, 2011). Despite
addressing similar topic, however, literature scope work, centered
modeling execution uncertainty SSGs.

325

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

knowledge attacker (Agmon, Sadov, Kaminka, & Kraus, 2008b; Basilico, Gatti,
Rossi, Ceppi, & Amigoni, 2009b; Basilico, Gatti, & Villa, 2010). Furthermore, assumed
adversary detected robots continue patrol around area looking
additional attackers without need modify strategy. Thus, execution uncertainty,
discussed work, addressed.
One exception, closer work, work Sless, Agmon, Kraus
(2014) requires robots physically inspect penetration attempts given time
period. This, work, far reaching consequences performance
patrol algorithm. Specifically, creates vulnerability points along patrol path
taken advantage knowledgeable adversary. particular, Sless et al. (2014)
investigate problem coordinated attacks, adversary initiates two attacks
order maximize chances successful penetration, assuming robot team
sent examine penetration attempt. suggest algorithm computing
robots strategy handling coordinated attacks, show despite exponential
time complexity, practical run time algorithm significantly reduced without
harming optimality strategy. Unfortunately, whereas work assumes
contribution multiple patrol units covering edge additive, thus enabling
formulate problem linear programming problem, Sless et al. settings
hold multiple robot covering segment contribute single
robot.
Finally, since significant portion work deals deploying game-theoretic
schedules field, relevant discuss existing literature addressed similar
challenge. discussed Section 6, deploy game-theoretic schedules deter
fare evasion LA metro system. doing, work similar number studies
fare-evasion prevention conducted systems London Alberta (Clarke, 1993;
Weidner, 1996; Clarke, Contre, & Petrossian, 2010). studies focused understanding
impact introducing automatic gates, turn-styles ticket prices, fare evasion
rate. work, interested different aspect: understanding game-theoretic
scheduling affect performance security resources responsible patrolling
transit system every day.
Given focus validating game-theoretic scheduling real world, work
shares many ideas literature game theory field. line research
focused showing equilibrium concepts human animal activities (Ostling, Wang,
Tao-yi, Chou, & Camerer, 2011; Brown, Camerer, & Lovallo, 2012). work shares
enthusiasm taking game theory field, fundamentally focuses algorithmic
deployments impact algorithms.

3. Problem Statement
section discusses, first, Los Angeles Metro domain, key domain used
motivation work. Second, presents Stackelberg game model
define formalize problem.
326

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

3.1 Motivating Example: LA Metro System
model quite general modeling time-sensitive patrols security domains
execution uncertainty, study paper substantially motivated TRUSTS,
application scheduling fare inspections Los Angeles Metro Rail system (Yin
et al., 2012). LA Metro Rail system, similar proof-of-payment transit systems
worldwide, barrier-free transit system passengers legally required purchase tickets boarding, physically blocked gates turnstiles. Instead,
security personnel dynamically deployed throughout transit system, randomly inspecting passenger tickets. approximately 300,000 daily riders, revenue loss due
fare evasion significantthis cost estimated $5.6 million (Booz Allen
Report, 2007). Los Angeles Sheriffs Department (LASD) deploys uniformed patrols
onboard trains stations fare-checking (and purposes crime suppression), order discourage fare evasion. limited resources devote patrols,
impossible cover locations times.
TRUSTS, currently evaluated LASD, provides game-theoretic solution
scheduling randomized patrols fare evasion deterrence. given day, TRUSTS generates one patrol schedule fare inspection team according pre-computed probability distribution large set possible patrol candidates. patrol schedule generated
sequence fare-check operations, alternating in-station on-train operations. operation indicates specifically patrol unit check fares.
Unfortunately, security personnel may deviate given schedule variety
reasons, writing citations, felony arrests, handling emergencies, etc. Indeed, 5 real
world trials carried LASD, 4 times pre-generated schedules got interrupted.
Often entire schedule got abandoned interruption operations specified
afterwards became irrelevant. example, officer following pre-generated schedule
write citation rider carrying valid ticket, preventing carrying
rest schedule.
3.2 Formal Model

Figure 1: Example schedule.
first contribution work, present formal game-theoretic model
patrolling dynamic execution uncertainty. patrolling game execution uncertainty
two-player Bayesian Stackelberg game, leader (the defender) follower
(the adversary). leader patrol units, commits randomized daily patrol
schedule unit. patrol schedule consists list commands carried
sequence. command form: time , unit location l,
327

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

execute patrol task a. patrol action current command, executed
successfully, take unit location time next command. graphical
representation schedule shown Figure 1. unit faces uncertainty
execution command: delays, called deal emergencies (possibly
another location). result unit may end location time different
intended outcome action, thus rest naive patrol schedule
cannot executed.
use Markov Decision Processes (MDPs) compact representation model
individual defender units patrol actions. emphasize MDPs whole
game: model defenders patrol actions environment executing
patrols; later describe interaction defender adversary.
Formally, defender unit {1, . . . , } define MDP (Si , Ai , Ti , Ri ),
Si finite set states. state si Si tuple (l, ) current location
unit current discretized time. denote l(si ) (si ) location
time si , respectively.
Ai finite set actions. Let Ai (si ) Ai set actions available state si .
si Si action ai Ai (s), default next state n(si , ai ) Si
intended next state executing action ai si . call transition (si , ai , si ) default
transition si = n(si , ai ) non-default transition otherwise.
Ti (si , ai , si ) probability next state si current state si
action taken ai .
Ri (si , ai , si ) immediate reward defender transition (si , ai , si ).
example, available emergencies (such helping lost child) important
function police, take account optimization formulation
using Ri give positive rewards events.
assume MDP acyclic: Ti (si , ai , si ) positive (si ) > (si ),
i.e., transitions go forward time. Si+ Si subset states patrol
could start. patrol could end state. convenience, add dummy source
state s+
Si actions deterministic transitions going states
+
Si , analogously dummy sink state
Si . Thus patrol defender

starts s+

ends


.

patrol
execution
specified complete trajectory


+ 1 1 2

ti = (s+
,

,

,

,

,
.
.
.
,

),

records

sequence states visited actions





performed. joint complete trajectory, denoted = (t1 , . . . , ), tuple complete
trajectories units. Let X finite space joint complete trajectories.
immediate rewards Ri utility received defender. defender
also receives rewards interactions adversary. adversary set
possible types finite set actions A. types drawn known
distribution, p probability type . defender know
instantiated type adversary, adversary condition decision
type.
general game model, utilities resulting defender-adversary interaction
could depend arbitrarily complete trajectories defender units. Formally,
joint complete trajectory t, realized adversary type , action adversary
A, defender receives utility ud (t, , ), adversary receives ua (t, , ).
328

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

interested finding Strong Stackelberg Equilibrium (SSE) game,
defender commits randomized policy define next, adversary
plays best response randomized policy. sufficient consider pure
strategies adversary (Conitzer & Sandholm, 2006). Finding one SSE equivalent
following optimization problem:
max


X

p Et [ud (t, , ) +

X

Ri (ti )]

(1)





s.t. arg max Et [ua (t, , )],


(2)

Ri (ti ) total immediate reward trajectory ti , Et [] denotes
expectation joint complete trajectories induced defenders randomized policy .
Whereas MDPs always Markovian deterministic optimal policies, game
defenders optimal strategy may non-Markovian utilities depend
trajectories, may randomized interactions adversary. consider
two cases: coupled execution decoupled execution. coupled execution, patrol units
coordinate other; is, behavior unit si could depend
earlier joint trajectory units. Formally, let Ti set unit isQpartial Q
trajectories
+ 1 1
). coupled randomized policy function :


(s+
,

,

,

,
.
.
.
,




Ai R



specifies probability distribution joint actions units joint partial
trajectory. Let (t; ) R probability joint complete trajectory X
instantiated policy . decoupled execution, patrol units communicate
other. Formally, decoupled randomized policy = (1 , . . . , ) unit
i, : Ti Ai R specifies probability distribution actions given partial
trajectory i. Thus decoupled randomized policy (1Q
, . . . , ) thought
coupled randomized policy (t, (a1 , . . . , )) = (ti , ai ).
Coupled execution potentially yields higher expected utility decoupled execution.
Suppose defender wants protect important target least one unit, unit
1 assigned task. knows unit 1 dealing emergency unable
reach target, reroute unit 2 cover target. However, coordinating among
units presents significant logistical (as see paper) computational burden.

4. Approach
defenders optimal strategy may coupled non-Markovian, i.e., policy
could depend entire earlier trajectories units rather current state
s. makes solving game computationally difficultthe dimension space
mixed strategies exponential number states.
Nevertheless, many domains, utilities additional structure.
extensive research efficient computation SSE massive games structured utility
functions (Tambe, 2011), including LA Metro domain (Yin et al., 2012),
works cannot deal type execution uncertainty studied paper. Section 4.1 show assumption utilities separable structure,
possible efficiently compute SSE patrolling games execution uncertainty.
Section 4.2 discuss generating patrol schedules solutions described Section 4.1.
329

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

Section 4.3 present procedure extract optimal mixed strategy
polynomial-sized support. Section 4.4 consider general case partially
separable utilities.
4.1 Efficient Computation via Compact Representation Strategies
Consider coupled strategy . Denote xi (si , ai , si ) marginal probability defender
unit reaching state si , executing action ai , ending next state si . Formally,
xi (si , ai , si ) =

X

(t; )(ti , si , ai , si ),

(3)

tX

value membership function (ti , si , ai , si ) equal 1 trajectory ti
contains transition (si , ai , si ) equal 0 otherwise. defined Section 3.2,
state tuple (l, ) current location unit current discretized time.
Hence, marginal probability xi (si , ai , si ) takes account location,
also time specific patrol action taken. see remainder
section, time location affect expected utility players. Hence,
design choice improves accuracy model compared real
P world problem. Let
x RM vector marginal probabilities, = |Si |2 |Ai |. Similarly,
let wi (s
Pi , ai ) marginal probability unit reaching si taking action ai . Let
w R |Si ||Ai | vector marginal probabilities.
goal compactly represent SSE problem terms w x,
dimensions polynomial sizes MDPs. first show w x satisfy
linear constraints:
xi (si , ai , si ) = wi (si , ai )Ti (si , ai , si ), si , ai , si
X
X
xi (si , ai , si ) =
wi (si , ai ), si

ai

(5)

ai

si ,ai

X

(4)

wi (s+
, ai ) =

X

xi (si , ai ,
) = 1,

(6)

si ,ai

wi (si , ai ) 0, si , ai

(7)

Lemma 1. coupled randomized policy , resulting marginal probabilities wi (si , ai )
xi (si , ai , si ) satisfy constraints (4), (5), (6), (7).
Proof. Constraint (4) holds definition transition probabilities MDPs. Constraint
(5) holds lhs rhs equal marginal probability reaching state s.
Constraint (6) holds construction, marginal probability reaching s+
1,

marginal probability reaching si . Constraint (7) holds wi (si , ai )
probability.
Similar formulations marginal probabilities MDPs known (e.g., Filar & Vrieze,
1996). However, unlike MDPs, general utility functions depend defenders complete trajectory adversarys type action, result w x
sufficient determine expected utilities game. Thus, order make
330

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

use compact representation, need make restrictions structure
utility functions. turns formulate expected utilities terms
w x games utilities separable, intuitively means given adversarys strategy, utilities players sums contributions individual units
individual transitions:
Definition 1. patrolling game execution uncertainty defined Section 3.2
separable utilities exist utilities Ud (si , ai , si , ) Ua (si , ai , si , ) unit
i, transition (si , ai , si ), , A, X , , A, defenders
adversarys utilities expressed
X X
ud (t, , ) =
(ti , si , ai , si )Ud (si , ai , si , )



ua (t, , ) =

si ,ai ,si

X X


(ti , si , ai , si )Ua (si , ai , si , ),

si ,ai ,si

respectively.
Let Ud , Ua RM |A| corresponding matrices. Ud , Ua completely specifies
utility functions ud ua .
Recall (ti , si , ai , si ) equal 1 trajectory ti contains transition (si , ai , si )
equal 0 otherwise. definition saying separable game, players
utility trajectory decomposed contributions transition
units trajectory ti . natural extension additive reward model
MDPs multi-player setting. Separable games represent common attacker-defender
patrolling scenarios, illustrated following example.
0
L1

L1, 0

1
1.0

Stay

L1, 1

2

L2

0.9

L1

L1
0.1

0.1
L2, 0

Stay

0.9
0.9

0.9

L2

L1, 2

0.1

0.1
L2

1.0

Stay

1.0

L2, 1

Stay

1.0

L2, 2

Figure 2: Example game separable utilities.
Example 1. Consider simple example game one defender unit, whose MDP
illustrated Figure 2. six states, shown circles figure, two locations L1 , L2 three time points 0 , 1 , 2 . states 0 1 , unit
two actions: stay current location, always succeeds, try go
331

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

location, probability 0.9 succeeds probability 0.1 fails (in
case stays current location). 12 transitions total,
fewer number complete trajectories (18). single type adversary chooses one location L1 L2 one time point 1 2
attack (0 cannot chosen). defender location time, attack fails players get zero utility. Otherwise, attack succeeds, adversary gets utility 1 defender gets 1. words, attack succeeds
avoids defender units trajectory. game separable utilities:
transition (si , ai , si ) MDP, let Ua (si , ai , si , ) 0 coincides si
1 otherwise. players utility given trajectory expressed sum
contributions transitions, exactly Definition 1. example, utility expression adversary given trajectory ((L1 , 0 ), L2 , (L1 , 1 ), L2 , (L2 , 2 ))
Ua ((L1 , 0 ), L2 , (L1 , 1 ), ) + Ua ((L1 , 1 ), L2 , (L2 , 2 ), ), gives correct
utility value adversary: 0 equals (L1 , 1 ) (L2 , 2 ) 1 otherwise.
straightforward show following.
Lemma 2. Consider game separable utilities. Suppose x vector marginal
probabilities induced defenders randomized policy . Let R|A| vector
describing mixed strategy adversary type , () denoting probability
choosing action
adversarys expected utilities
P
P . defenders
interactions p xT Ud p xT Ua , respectively.
words, given adversarys strategy, expected utilities players
linear marginal probabilities xi (si , ai , si ). Lemma 2 also applies (as
SSE) adversary playing pure strategy, case 0-1 integer vector
() = 1 action chosen. thus use compact representation
defender strategies rewrite formulation SSE (1) polynomial-sized optimization
problem.
max

w,x,y

X

p xT Ud +

X
X

xi (si , ai , si )Ri (si , ai , si )

(8)

i=1si ,ai ,si



s.t. constraints (4), (5), (6), (7)
X
() = 1,

(9)



() {0, 1},
x
arg max



,


Ua

(10)
(11)

show Section 4.2, given solution w, x (8), calculate decoupled
policy matches marginals w, x. Compared (1), optimization problem (8)
exponentially fewer dimensions; particular numbers variables constraints
polynomial sizes MDPs. Furthermore, existing methods solving Bayesian
Stackelberg games, mixed-integer linear program formulation (Paruchuri, Pearce,
Marecki, Tambe, Ordonez, & Kraus, 2008a) branch-and-bound approach (Yin & Tambe,
2012), adapted solve (8). example, Paruchuri et al. (2008a) formulated
332

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

problem mixed-integer quadratic program, transformed equivalent
mixed-integer linear program, solved using standard optimization solvers like
CPLEX. Paruchuri et al. (2008a) assumed defenders strategy space
standard simplex, replace simplex constraints flow constraints (4), (5),
(6), (7), apply techniques described Paruchuri et al. (2008a) derive
mixed-integer linear program.
special case Ud + Ua = 0 , i.e., interaction defender
adversary zero-sum, SSE problem formulated following linear
program (LP):
X
X X
max
p u +
xi (si , ai , si )Ri (si , ai , si )
(12)
w,x,u





si ,ai ,si

s.t. constraints (4), (5), (6), (7)
u xT Ud e ,

, A,

(13)

e basis vector corresponding adversary action . LP similar
maximin LP
zero-sum game utilities given Ud Ua , except adP aP
ditional term si ,ai ,s xi (si , ai , si )Ri (si , ai , si ) representing defenders expected utilities

immediate rewards added objective. One potential issue arises:
extra defender utilities immediate rewards, entire game longer zero-sum.
still valid use maximin LP formulation? turns LP indeed
valid, immediate rewards depend adversarys strategy.
Proposition 1. game separable utilities Ud + Ua = 0 ,
solution LP (12) SSE.
Proof. transform game equivalent zero-sum Bayesian game whose LP
formulation equivalent (12). Specifically, given non-zero-sum Bayesian game
specified above, consider Bayesian game following meta type distribution
second player: corresponding type ,
probability p = 0.5p , familiar utility functions; special type
probability p = 0.5, whose action affect
P either
P players utility. Specifically
utilities special type ud (t, , ) = si ,ai ,s (ti , si , ai , si )Ri (si , ai , si )

P P
ua (t, , ) = si ,ai ,s (ti , si , ai , si )Ri (si , ai , si ). resulting game zeroi
sum, defenders utility exactly half objective (12). Since zero-sum games
maximin strategies SSE coincide, solution LP (12) optimal SSE marginal
vector defender . hand, compare induced
P normal forms

, difference adversary utility 0.5 eE Ue xe added,
depend adversarys strategy. Therefore set
SSE, implies solution LP SSE .
4.2 Generating Patrol Schedules
solution (8) yet provide complete specification do. ultimately want explicit procedure generating patrol schedules. define Markov
strategy decoupled strategy (1 , . . . , ), : Si Ai R, distribution
333

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

next actions depends current state. Proposition 2 shows given
w, x, simple procedure calculate Markov strategy matches marginal
probabilities. implies w, x optimal solution (8), corresponding
Markov strategy achieves expected utility. thus shown games
separable utilities sufficient consider Markov strategies.
Proposition 2. Given w, x satisfying constraints (4) (7), construct Markov strategy
P
(si ,ai )

follows: si Si , ai Ai (si ), (si , ai ) = Pwiw
) .
wi (si , ai ) =
(s
,a









0 set (si , ) arbitrary distribution. Suppose defender plays ,
unit transition (si , ai , si ), probability (si , ai , si ) reached equals
xi (si , ai , si ).
Proof. Markov strategy induces Markov chain states Si unit
i. claim resulting marginal probability vector Markov chain matches x.
show induction starting state s+
successor states. marginal
+
probability Pr(s+
,

)

reaching
state


taking
action
ai equal (s+



, ai ), since
+
s+
1 always reached. (si , ai ) =

P

wi (s+
,ai )

w
(s+



,ai )

= wi (s+
, ai ) constraint (6),



marginals matched s+
. inductive step, marginal probability Pr(si , ai )
reaching si taking action ai equal Pr(si )i (si , ai ), Pr(si ) probability
reaching si . induction hypothesis,
P Pr(si ) computed marginals
x, w previous states, Pr(si ) = ,a xi (si , ai , si ).


Pr(si , ai ) = (si , ai )



X

wi (si , ai ) X
xi (si , ai , si ) = P
xi (si , ai , si ) = wi (si , ai )
)
w
(s
,








si ,ai



si ,ai

constraint (5). Thus marginals matched states.
practice, directly implementing Markov strategy requires unit draw
action according probability distribution (si , ) state si . possible
unit consult random-number generator, communicate central
command. However, certain domains requirement computation communication
time step places additional logistical burden patrol unit. avoid unnecessary
computation communication every time step, desirable let unit execute
deterministic schedule (i.e., pure strategy). guarantee optimal expected utility,
want deterministic schedule drawn distribution marginals
optimal solution (8). say procedure generates patrols correct
property. execution uncertainty, pure strategy specified
complete trajectory unit. However, longer works case execution
uncertainty, interruptions lead states outside trajectory.
thus begin defining Markov pure strategy, specifies deterministic choice
state.
Definition 2. Markov pure strategy q tuple (q1 , . . . , q ) unit i,
qi : Si Ai .
334

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

note set Markov pure strategies subset pure strategies,
generally condition choices earlier histories addition current states.
Nevertheless, show Markov pure strategies useful part efficient
procedure sampling solution (8).
Given Markov strategy , sample Markov pure strategy q follows:
Procedure 1. Given , unit state si Si , sample action ai according
, set qi (si ) ai . Output Markov pure strategy q.
procedure correct since state MDP visited thus
qi exactly simulates walk s+
Markov chain induced .
directly implement Markov pure strategy, unit needs either remember
entire mapping q receive action central command time step.
alternative scheme requires small amount storage minimal amount communication following: central command sends unit trajectory assuming
perfect execution, non-default transition happened unit communicates central command get new trajectory starting current state.
Formally, given si Si qi , define optimistic trajectory si induced qi
(si , qi (si ), n(si , qi (si )), . . . ), i.e, trajectory assuming always reaches default
next state. Given Markov pure strategy q, following procedure exactly simulates q:
Procedure 2. unit i: (i) central command gives unit optimistic trajectory
s+ induced qi ; (ii) unit follows trajectory terminal state reached
unexpected event happens takes state si ; (iii) latter case, central
command sends unit new optimistic trajectory si induced qi repeat
step (ii).
4.3 Extracting Mixed Strategy Small Support
far procedures generating patrol schedules described different implementations Markov strategy Proposition 2. corresponds mixed strategy
set Markov pure strategies: Markov pure strategy q played probability equal probability sampled sampling procedure. support
mixed strategy, i.e., set pure strategies non-zero probability, general
exponential-sized set.
practice, sometimes desirable mixed strategy polynomial-sized
support. example, security agency may need carry training exercises
pure strategies support (e.g., Fang et al., 2013). cases, would like
polynomial-support mixed strategy achieves expected utility optimal
solution (8). following proposition shows always exists polynomialsupport mixed strategy matches given marginals w, x, therefore achieves
optimal expected utility w, x solution (8).
Proposition 3. Given w, x satisfying constraints (4) (7), exists mixed strategy
polynomial-sized support matches marginals.
Proof. Since (w, x) polytope defined constraints (4) (7), extreme points
polytope correspond pure strategies, Caratheodorys Theorem3 implies (w, x)
3. See Chapter 3 (Gruber, 2007)

335

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

written convex combination dim(w)+dim(x)+1 = O(
pure strategies.

P

|Si |

2 |A |)


However, proof constructive. Grotschel, Lovasz, Schrijver (1981)
provided polynomial-time procedure given point inside polytope, decomposes
convex combination polynomial number extreme points polytope;
however method requires application ellipsoid method, tends slow
practice. section, provide efficient procedure generating mixed strategy
polynomial-sized support matches marginals w, x.
Procedure 3. Given (w, x), optimal solution (8), initialize mixed strategy
empty support set.
1. Compute Markov strategy (si , ai ) =

Pwi (si ,ai ) .
wi (si ,ai )




P

ai

wi (si , ai ) = 0

set (si , ) arbitrary distribution.
2. Select Markov pure strategy q played positive probability . One
possible way construct q follows: state si , set qi (si ) action
ai played positive probability si .
3. Compute marginals wq , xq corresponding pure strategy q. done
s+
successor states.
4. Let q maximum w wq 0 x xq 0.
5. Set w := w q wq , x := x q xq . Add pure strategy q support, played
probability q .
6. w = 0, Stop. Otherwise, go Step 1.
Proposition 4. Procedure 3 outputs polynomial time mixed strategy polynomialsized support, matching marginals.
Proof. Since wq , xq valid marginal vectors satisfying constraints (4) (7), updated
marginals (w, x) Step 5 still satisfies flow conservation constraints (4), (5),
nonnegativity constraint (7), total flow (corresponding (6)) reduced
q . implies steps procedure well-defined; furthermore
procedure stops, output sum 1, corresponding mixed strategy matches
marginals wq , xq .
remains show procedure stops polynomial number iterations.
see this, note construction, execution Step 5 reduce least one
component (w, x) zero. otherwise could increase qP
, contradicting
Step 4. Therefore procedure stops dim(w) + dim(x) = O( |Si |2 |Ai |)
iterations; since iteration adds one pure strategy support, resulting
mixed strategy polynomial-sized support.
336

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

4.4 Coupled Execution: Cartesian Product MDP
Without assumption separable utilities, longer sufficient consider decoupled
Markov strategies individual units MDPs. create new MDP captures joint
execution patrols units. simplicity exposition look case two
defender units. state new MDP corresponds tuple (location unit 1,
location unit 2, time). action new MDP corresponds tuple (action unit
1, action unit 2). Formally, unit 1 action a1 state s1 = (l1 , ) takes
s1 = (l1 , ) probability T1 (s1 , a1 , s1 ), unit 2 action a2 state s2 = (l2 , )
takes s2 = (l2 , ) probability T2 (s2 , a2 , s2 ), create new MDP
action = (a1 , a2 ) state = (l1 , l2 , ) transitions = (l1 , l2 , )
probability (s , , ) = T1 (s1 , a1 , s1 )T2 (s2 , a2 , s2 ). immediate rewards R
MDP defined analogously. call resulting MDP (S , , , R ) Cartesian
Product MDP.
issue arises state individual units transitions different time
durations. example, unit 1 rides train takes 2 time steps reach next station
unit 2 stays station 1 time step. intermediate time steps
unit 2 free choice. model Cartesian Product MDP? One
approach create new states intermediate time steps. example, suppose
location LA time 1 non-default transition takes unit 1 location LA time 3.
modify unit 1s MDP transition ends new state (L1A , 2) S1 , L1A
special location specifying unit become alive location LA
one time step. one action (L1A , 2), one possible next
state (LA , 3). modified individual units MDPs transitions
take exactly one time step, create Cartesian Product MDP described
previous paragraph.
Like units MDPs, Cartesian Product MDP also acyclic. Therefore
analogously define marginal probabilities w (s , ) x (s , , ) Cartesian
2
Product MDP. Let w R|S ||A | x R|S | |A | corresponding vectors.
Utilities generally cannot expressed terms w x . consider special case
utilities partially separable:
Definition 3. patrolling game execution uncertainty partially separable utilities exist Ud (s , , , ) Ua (s , , , ) transition (s , , ),
, A, X , P
, A, defenders adversarys
utilities expressed ud (t, , ) = ,a ,s (t, , , )Ud (s , , , )

P
ua (t, , ) = ,a ,s (t, , , )Ua (s , , , ), respectively.


Partially separable utilities weaker condition separable utilities,
expected utilities may sums contributions individual units. utilities
partially separable, express expected utilities terms w x find
,
SSE solving optimization problem analogous (8). optimal w
(s , ) =
get Markov strategy


w (s ,a )
P

,
w (s,a )

provably optimal coupled



strategy.
approach cannot scale large number defender units, size
grow exponentially number units. particular dimension Markov
337

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

policy already exponential number units. overcome need
compact representation defender strategies. One approach use decoupled
strategies. resulting defender strategy model resembles transition independent DECMDP (Becker, Zilberstein, Lesser, & Goldman, 2004). However, due strategic interaction
adversaries, existing methods DEC-MDPwhich compute pure strategies
cannot directly applied. Efficient computation settings remains open problem.

5. Case Study LA Metro System
section discusses apply model presented Section 3.2 approach
presented Section 4 problem patrolling LA Metro system fare evasion.
particular, Section 5.1 discusses game model adapted LA metro patrolling
problem Section 5.2 discusses use framework build scheduling system
whereby schedules generated central planner visualized smartphone
application running android phones.
5.1 Application LA Metro Domain
explain proposed techniques used LA Metro domain.
involves defining number parameters specific LA Metro domain
initialized real-world experiment Section 6. addition, see, although
utilities domain separable, able provide upper bound
defender utilities separable utilities, allowing efficient computation.
Similar work Yin et al. (2012), state comprises current station
time unit, well necessary history information starting time4 . state,
unit may stay current station conduct in-station operation time
ride train conduct on-train operation current time coincides
train schedule. Due execution uncertainty, unit may end state
intended outcome action. ease analysis, assume throughout rest
paper single type unexpected event delays patrol unit time beyond
intended execution time. Specifically, assume fare check operation taken,
probability operation delayed, i.e., staying station
(for in-station operations) train (for on-train operations) involuntarily
time. Furthermore, assume units involved events unrelated
fare enforcement thus check fares delayed period operation.
Intuitively, higher chance delay leads less time spent fare inspection.
see Section 6, initializing probability conducting real-world experiments required
adopting robust approach based cross-validation (Kohavi, 1995; Jaulmes, Pineau, &
Precup, 2007) address uncertainty related duration delay.
adversary faced riders system. Specifically, model
common type riders use metro line every day go work come
back home. takes fixed route: starts specific station (at specific
time) ends new station B (at new time). Since exists multiple stations
time units, also exist multiple routes considered. address issue, define
4. Interested readers encouraged read work Yin et al. (2012) details

338

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

multiple riders representing specific route. rider observes likelihood
checked makes binary decision buying buying ticket. rider
type buys ticket, pays fixed ticket price . Otherwise, rides train
free risks chance caught paying fine > . LASDs objective
set maximize overall revenue whole system including ticket sales fine
collected, essentially forming zero-sum game. revenue depends number
resources available LASD, i.e., ones deployed patrol5 . Given
number available officers then, costs associated deployment (e.g., number
officers working hours) incorporated objective function defining
negative rewards Equation 8.
Since fare check operation performed determined actual transition rather
action taken, define effectiveness transition (s, a, ) rider type
, f (s, a, ), percentage riders type checked transition (s, a, ). Following
argument Yin et al. (2012), assume probability joint complete
trajectory detects evader sum f transitions = (t1 , . . . , ) capped
one:
X
X
Pr(t, ) = min{
f (si , ai , si )(ti , si , ai , si ), 1}.
(14)
i=1 si ,ai ,si

type joint trajectory t, LASD receives rider buys ticket
Pr(t, ) otherwise. utilities domain indeed separable even though
multiple units (or even single unit) may detect fare evader multiple times, evader
fined once. result, neither players utilities computed directly using
marginal probabilities x w. Instead, provide upper bound defender utility
overestimating detection probability following:
\) =
Pr(t,

X
X

f (si , ai , si )(ti , si , ai , si ) Pr(t, ).

(15)

i=1 si ,ai ,si

\),
defender utility rider buy ticket upper-bounded Pr(t,
separable. Given marginal vector x, detection probability upperbounded

X
X
\
Pr(x, ) =
f (si , ai , si )xi (si , ai , si ).
(16)
i=1 si ,ai ,si

Equation (16) leads following upper bound LP LA Metro problem:
max

x,w,u

s.t.

X


p u +


X
X

Ri (si , ai , si )

(17)

i=1 si ,ai ,si

constraints (4), (5), (6), (7)
\)},
u min{ , Pr(x,

(18)

5. number resources required maximize revenue LASD equal number number
edges MDP defined Section 4. Unfortunately, real world available resources
much less number. Therefore, idea maximize revenue LASD given
resources available.

339

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

prove claims following two propositions.
\) upper bound true detection probability coupled
Proposition 5. Pr(x,
strategy marginals x.
Proof. Consider coupled strategy . Recall (t; ) R probability
joint trajectory
P X instantiated. rider type , true detection probability
Pr(, ) = tX (t; )Pr(t, ). Applying Equations (14) (3) have,
Pr(, )

X

(t; )


X
X

f (si , ai , si )

i=1 si ,ai ,si

=


X

f (si , ai , si )(ti , si , ai , si )

i=1 si ,ai ,si

tX

=


X
X

X

X

(t; )(ti , si , ai , si )

tX

\).
f (si , ai , si )xi (si , ai , si ) = Pr(x,

i=1 si ,ai ,si

Proposition 6. LP (17) provides upper bound optimal coupled strategy.
Sketch. Let x w marginal coverage u value patroller
rider type optimal coupled strategy . suffices show (x , w ,
u ) feasible point LP. Lemma 1, already know x w must satisfy
constraints (4) (7). Furthermore, u since rider pays ticket
\) since Pr(x,
\) overestimate true detection
price. Finally, u Pr(x,


probability.
Intuitively, LP (17) relaxes utility functions allowing evader fined multiple times single trip. relaxed utilities separable thus relaxed
problem efficiently solved. Since solution returned x w satisfy constraints
(4) (7), construct Markov strategy w described Section 4.2.
Markov strategy provides approximate solution original problem, whose actual
value evaluated using Monte Carlo simulation. strategy also sampled
produce patrol schedule uploaded smartphone application
discussed next.
5.2 Smartphone Application
smartphone app software agent carried patrol officer visualizes
patrol schedules generates using approach discussed previous section. Shown
Figure 3, app provides three principal features: (i) patrol schedule current
shift; (ii) system reporting passenger violations (iii) shift statistics summary
report. beginning shift, patrol schedule loaded app either
hand using database. app displays schedule current upcoming
patrol actions schedule view, shown Figure 3(a). Implementing recovery
340

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

(a) Schedule View

(b) Reporting View

(c) Summary View

Figure 3: smartphone user interface

real-world unexpected events interrupt officers schedule, schedule view also
allows officer manually set current location, triggering app select new
patrol schedule based officers current location time. so, number
patrol schedules sampled Markov strategy (see Section 4.2) uploaded
app deployment. remainder work, refer action
requesting update. app also allows patrol officers record passenger violations,
fare evasion, current patrol action using Reporting View, shown Figure
3(b). Officers also view edit passenger violations reported past actions
Summary View, shown Figure 3(c). Upon shift completion, officer also use
Summary View submit app-generated shift statistics summary report, including
unexpected events violations reported throughout shift, database.
app presents two key advantages security agencies. First, allows
collection patrol data, could used analyze behavior adversaries
fare evaders criminals. Second, app-collected data could also benefit transit
system security departments manually record violations data conduct
analysis patrol strategy performance.

6. Evaluation
section describes experiments. Section 6.1, describe datasets
instantiated model parameters experiments. Section 6.2, discusses
simulations studied key properties approach discussed Section
5.1. Finally, Section 6.3 discusses real-world experiment ran head-to-head
comparison approach uniform random approach, automated approach
security agencies use using game-theoretic approach (Tambe, 2011).
341

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

6.1 Data Sets
experiments presented work, either simulation real-world, based
four data sets, based different Los Angeles Metro Rail line: Red (including
Purple), Blue, Gold, Green. data sets, train schedules obtained
http://www.metro.net ridership distributions line estimated
hourly boarding alighting counts provided LASD. allowed ontrain operation, i.e., train checks could two stations defined instation operations, i.e., station-checks, fixed intervals 10 20 minutes.
recommended LASD, duration one security officers typically adopt
conduct fare inspections train station. effectiveness fare check operation
adjusted based volume riders period assumption
unit would check three riders per minute. ticket fare set $1.5 (the actual
current value), fine set $100 (fare evaders Los Angeles fined $200,
however, also may issed warnings). rider always pay ticket price $1.5
evade ticket expected fine lower. immediate rewards Ri
set zero. Table 1 summarizes detailed statistics four Metro lines.
Line
Red
Blue
Gold
Green

Stops

Trains

Daily Riders

Types

16
22
19
14

433
287
280
217

149991.5
76906.2
30940.0
38442.6

26033
46630
41910
19559

Table 1: Statistics Los Angeles Metro lines.

6.2 Simulations
simulations aimed analyze performance Markov strategies calculated
solving LP defined Section 5.1. specifically, aim analyze key features
approach systematically manipulating parameters likely
vary significantly real world and, consequence, affect revenue defender
rate fare evaders captured. parameters include delay length, train
lines, levels execution uncertainty number available resources. also
tested runtime LP algorithm verify whether capable generating
output timely manner. result presented Red line only. Results
Blue, Gold Green line presented Appendix A.
simulations, found Markov strategy close optimal
revenue always 99% LP upper bound. Figure 4 shows result, assuming
6 resources patrolling Red line 3 hours varying uncertainty probability (from 0%
25%). Similar results found Blue, Green Gold lines reported
Figure 14 Appendix A. result indicated relaxed detection probability
given Equation (16) provided good estimation true probability, implying
riders unlikely checked joint execution trajectories produced
Markov strategy data sets. reason, remainder
342

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

Figure 4: Markov Strategy (Equation (17)) vs. true LP (Equation (8)).

section report values Markov strategy without mentioning LP upper
bound.
experiments, compared, execution uncertainty, performance
Markov strategy (obtained solving LP (17)) two types benchmarks: gametheoretic, deterministic, policies assuming execution uncertainty Markov policies
take execution uncertainty account, assign actions based uniform
random probability. pre-generated schedules calculated using TRUSTS (Yin et al.,
2012), original system developed patrolling train lines, based deterministic
model assuming execution uncertainty. However, since actions take deviations
original plan well-defined TRUSTS schedules, augmented pregenerated schedules two naive contingency plans indicating actions follow
unit deviates original plan. first plan, Abort, simply abandon
entire schedule return base. second plan, Arbitrary, pick action
randomly available actions decision point deviation. uniform
random Markov strategy (Markov UR) assigns, given state Si MDP defined
Section 3.2, uniform probability actions taken leading another state
Si . essence, strategy similar Arbitrary policy assumes
resources always pick random action deviated. chosen
approach security agencies adopt using game-theoretic
approach randomization6 .
strategies generated using CPLEX 12.2 barrier method
standard 2.8GHz machines 4GB memory. Then, generate significant datapoints,
strategy evaluated using Monte Carlo simulations 100000 samples.
simulations, riders assumed choose best response based frequency
checked samples. discussion results follows.

6. See work Tambe (2011) detail.

343

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

(a) Varying uncertainty

(b) Varying delay

Figure 5: Defenders revenue per rider Red line: Markov vs. TRUSTS pre-generated
strategies Markov UR

6.2.1 Expected Revenue Varying Delay Probability Time
run experiment, fixed number units 6 patrol length 3 hours
varied delay probability delay time. results presented based
simulations Red line. Figure 15 Appendix shows results Blue,
Green Gold lines.
First, fixed delay time 10 minutes varied delay probability 0%
25%. see Figure 5(a), Abort, Arbitrary Markov-UR performed
poorly presence execution uncertainty. increasing values , revenue
Abort Arbitrary decayed much faster Markov strategy. fact,
increasing delay probability, number interruptions also increased.
situations, Abort Arbitrary strategies perform sub-optimal actions
(dropping schedule selecting random action) yield poor performance.
344

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

example, increased 0% 25%, revenue Abort Arbitrary
decreased 75.4% 37.0% respectively Markov strategy decreased
3.6%. contrast, performance ofMarkov-UR remained constantly around
value of, approximately 0.4. expected, since strategy constantly performs random
actions, therefore performance independent delay probability.
important observation revenue Abort decayed extremely fast
increasing even 5% probability delay, revenue Abort
73.5% Markov strategy. conservative estimate 6% potential fare
evaders (?) 300, 000 daily riders LA Metro Rail system, 26.5% difference
implies daily revenue loss $6, 500 $2.4 million annually.
Second, fixed 10% varied delay time 5 25 minutes. results,
Figure 5(b), present similar trends ones Figure 5(a). three strategies Abort,
Arbitrary Markov-UR performed worse Markov strategy. increasing
delay time, revenue Arbitrary, decayed faster rate Markov strategy.
Similar discussed earlier, delay, strategy would start generate suboptimal actions would result low expected revenue. contrast, revenue
Abort Markov-UR remained approximately same. time
delay matter Abort strategy resource abandon schedule
first unexpected event. Similarly, time delay matter Markov-UR
resource performs random actions. delay time increased 5
25 minutes, revenue Abort Markov UR remained same, 0.4 0.75
respectively, Arbitrary Markov strategy decreased 14.4% 3.6%
respectively.

Figure 6: Markov vs. deterministic strategies: evasion rate

6.2.2 Fare Evasion Rate Varying Delay Probability Time
settings experiment ones experiment discussed
above. Here, present results Red line only. results Blue,
Green Gold line, present similar trends shown Figure 16 Appendix
A. discussed Section 6.1, considered rider prefer fare evasion
345

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

expected penalty fare evasion lower $1.5, ticket price. results
shown Figure 6, shows fare evasion rate four policies increasing .
see, Abort, Arbitrary Markov UR showed extremely poor performance
evasion deterrence even tiny probability execution error. Similar first
experiment, increasing number interruptions led two deterministic strategies
produce sub-optimal actions yielding fewer number fare evaders captured. particular,
delay probability increased 0% 5%, evasion rate Markov
strategy barely increased Abort Arbitrary increased 11.2%
74.3% 43.9% respectively. contrast, Markov UR strategy remained stable
around fare evasion rate 80%. result confirms trend Markov UR
strategy depicted Figure 5(a). delay probability affect performance
strategy consists computing random actions.

20%
Fare evasion rate

Revenue per rider

1.5
1.45
1.4
1.35
Blue

Gold

Green

Red

1.3
0 0.05 0.1 0.15 0.2 0.25
Probability unexpected event

Blue

Gold

Green

Red

15%
10%
5%
0%
0 0.05 0.1 0.15 0.2 0.25
Probability unexpected event

(a) Revenue per rider Markov strategy

(b) Evasion rate Markov strategy

Figure 7: Markov strategy different lines.

6.2.3 Robustness Approach increasing Delay Probability
run experiment, fixed number units 6 patrol length 3 hours,
varied delay probability 0% 25%. Figure 7(a) Figure 7(b) show
expected revenue per rider evasion rate four lines respectively7 .
see, revenue decreased evasion rate increased increasing . However,
Markov strategy able effectively allocate resources counter effect increasing
terms revenue maximization evasion deterrence. example, ratio
revenue = 25% = 0% 97.2%, 99.1%, 99.9%, 95.3% Blue,
Gold, Green Red line respectively. Similarly, increased 0% 25%,
evasion rate Blue, Gold, Green Red line increased 4.6, 1.9, 0.1, 5.2
percentage points respectively. Thus, Markov strategy performance degraded gracefully
uncertainty increased four lines.
7. revenue Red line significantly lower lines fare check effectiveness
f defined Section 5.1 set inversely proportional ridership volume.

346

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

Revenue per rider

1.5
1.3
Low

Medium

High

1.1
0.9
0.7
0 0.05 0.1 0.15 0.2 0.25
Probability unexpected event

Figure 8: Revenue decay varying coverage levels

6.2.4 Revenue per Rider Increasing Delay Probability
experiment, considered 3, 6 9 patrol units, representing three levels fare
enforcement: low, medium high, respectively, evaluated revenue per rider
increasing . results red line depicted Figure 8. Results blue,
green gold line present similar trends depicted Figure 17
Appendix A. shown Figure 8, rate revenue decay respect decreased
increased level fare enforcement low high. Intuitively,
resources, defender could better afford time spent handling unexpected events
without sacrificing overall revenue. example, increased 0% 25%,
revenue drop low, medium high enforcement setting 13.2%, 4.7%,
0.4% respectively.

Revenue per rider

1.4
1.2
1

= 0%
= 10%
= 20%

0.8
0.6
2

3
4
5
Number patrol units

6

Figure 9: Revenue per rider increasing coverage

347

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

6.2.5 Revenue per Rider Increasing Number Resources

Runtime(in minutes)

experiment, fixed patrol length 3 hours, considered three delay
probabilities = 0%, 10%, 20%, representing increasing level uncertainty.
measure impact number units, increased number units 2
6. results Red line shown Figure 9, Figure 18 Appendix shows
results Blue, Green Gold lines. figures show revenue per rider
defender increasing number units. depicted figure, increased
number, revenue increased towards maximal achievable value $1.5 (ticket
price). number resources increases, algorithm produces Markov strategies
distribute resources check rider types. example, shown
figure, = 10%, revenue per rider $0.65, $1.12, $1.37 2, 4, 6
patrol units respectively. addition, figure shows uncertainty increases,
revenue per rider slightly decays. example, considering 4 units, revenue per rider
1.09, 1.13 1.18 = 0%, 10% 20% respectively.

60
Blue
54
48
Gold
42
Green
36
Red
30
24
18
12
6
0
0 0.05 0.1 0.15 0.2 0.25
Probability unexpected event
Figure 10: Worst-case LP runtime

6.2.6 Runtime LP Algorithm
confirm hypothesis, ran experiment considering worst-case runtime (over
10 runs) LP increasing four metro lines. number units
fixed 3 patrol length per unit fixed 3 hours. verify whether delay
probability impact runtime, ran simulations varying 0% 25%.
results depicted Figure 10. see, algorithm could solve
problems within hour. example, = 10%, runtime Blue, Gold,
Green, Red line 14.0, 24.3, 2.4, 4.3 minutes respectively.
addition, results present number additional features analyzed.
runtime varied among four Metro lines, related number states
types. words, number stations daily trains (i.e. density train
schedule) affected runtime algorithm. example, since Green line
significantly fewer types states, solving LP easier three lines.
348

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

surprising result fact found correlation runtime
delay probability . results showed that, four lines, stochastic models
> 0% took less time solve deterministic models ( = 0%). precisely,
increasing beyond 0%, runtime four lines fluctuated showed upwards trend, yet correlation runtime delay probability statistically
significant.
6.3 Real-World Experiment
results simulations presented showed deterministic approaches
take execution uncertainty account perform poorly. Given large number
interruptions, officers rarely able complete schedule provided deterministic
strategies. discussed Section 1, results motivated work led new
solution concept based MDP. addition, considering limited time
given LASD run experiment, decided use Markov UR strategy
benchmark real world experiment. Real-world failure acceptable
LASD. Therefore, recommended testing deterministic schedules further.
addition, despite performing poorly simulation, Markov UR strategy
used security agencies automatically allocate resources, schedules
updated whenever interruption occurs.
real world experiment took place 21 days months July
August 2013. organization experiment (e.g., train security officers, design
organize experiment collaboration LASD) required approximately two
weeks. experiment two key purposes. first validate MDP model
real world. second run head-to-head comparison gametheoretic approach Markov-UR approach. section discusses setup
experiment results obtained.
6.3.1 Experiment Setup
fare evasion experiment took place Blue line LA Metro system (see Figure
11 map metro line). lines could tested, LASD
allowed us use strategies Blue line real-world test. line
consists 22 different stations one biggest lines LA Metro system.
selected LASD, helped organize experiment (e.g., assign security
officers patrol times).
day, team two security officers (see Figure 12), randomly selected
LASD, patrol line duration 120 minutes. Patrols run
morning afternoon. days tests ended early due officers
reassigned. One two officers acted leader team: given
smartphone, read schedule officers, collect data
eventually update whenever delay occurred. update could made either
station-check described Section 6.1) train-check. latter case,
officers required leave train next station request update.
required because, discussed Section 5.1, Markov strategy defined
349

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

Figure 11: map blue line LA Metro

Figure 12: Two security officers performing fare checks train.
state MDP (i.e., station, time). Thus new strategy sampled
specific state. Every week team provided one two types schedules:
Game-theoretic schedules (GT): type schedule generated according
LP Equation (17) presented Section 5.1.
Markov UR schedules (UR): type schedule generated modeling
problem MDP, discussed Section 3.2. However, corresponding Markov
strategy si ,ai , state si action ai calculated assuming uniform
probability distribution.
officers told schedule using bias performance. experiment, anticipated officers might view
350

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

schedules leading low performance terms catching fare evaders.
situation, officers, order avoid poor performance, might end voluntarily deviating given schedules reach better location unsatisfied
current one. anticipation voluntary deviations, augmented
game-theoretic UR schedules ability perform updates. specifically,
allowed officers request VOLUNTARY INVOLUNTARY updates. VOLUNTARY
updates consisted officers updating current schedule opinion,
current specified action fruitful venue check fares. Officers allowed
choose new location considered fruitful catching fare evaders
request new schedule there. INVOLUNTARY updates consisted officers requesting new schedule delayed (e.g., issuing citations arresting
suspect) unable perform next action schedule. type
update could requested anytime officer delayed. see officers
used VOLUNTARY updates almost every day UR schedules, never GT
schedules.
Finally, important notice given duration experiment, gametheoretic schedules essentially testing maximin strategy. discussed Section
5.1, LP computes Stackelberg strategy, strategy based assumption
riders conduct surveillance observe defenders mixed strategy. However,
considering 21 days patrol whereby officers could patrol less
hours per day, either morning afternoon, cannot assume riders
sufficient time conduct accurate surveillance, observe mixed strategy best
respond it. Nonetheless, LP Section 5.1 solves zero-sum game
Stackelberg equilibrium maximin strategy known equivalent (Yin et al.,
2012). Thus, since maximin strategy provides guaranteed level defender utility
without making assumption adversarys surveillance defenders mixed
strategy, experiments compare benefit using maximin strategy
(non-game-theoretic) approaches generating patrol schedules.
6.3.2 Estimating Uncertainty Parameter
Given unpredictability real-world, two key parameters instantiating
MDPthe length delay and, importantly, probability delay
could happen could defined before-hand, done Section 6.1 remaining problem parameters. setting, adopting continuous-time MDP could
possible alternative. However, continuous time MDP algorithms, involve techniques
forward search (Marecki & Tambe, 2008; Mausam, Benazera, Brafman, Meuleau,
& Hansen, 2005), would appear difficult implement would add significant computational complexity. Another alternative, one adopted work, adopt cross
validation approach, well-known technique used machine learning (Jaulmes et al., 2007)
statistics (Kohavi, 1995). idea select policy robust uncertainty, i.e.,
policy guarantees highest expected revenue worst case setting,
uncertainty minimize defenders expected utility. achieve this, discretized
delays defined MDP model assumed multiple delays, specific
probability. divided approach two steps. First, randomly generated N
351

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

GT
UR

D1
60
60

D2
60
60

D3
90
60

D4
60
60

D5
90
60

D6
10
75

D7
90
100

D8
110
100

D9
90
100

D10
90
90

D11
105

total
855
765

Table 2: Patrol duration 21 days.
MDPs. MDP generated assuming delay happen within time window
30 minutes. words, assume resource experience delays 30
minutes (any delay longer 30 minutes considered beyond repair new
schedule generated). time window divided five different time intervals:
[0, 6], [6, 12], [12, 18], [18, 24] [24, 30] minutes one delay sampled interval. essence, process discretizes unknown delay length 5 possible delays
distributed within 30 minutes time window.
Second, solve MDP-based patrolling game using LP Section 5.1.
doing, obtain N Markov policies ik corresponding DP k . Next, crossvalidate policy ik DPk k 6= k , i.e., calculate expected

revenue policy ik generates evaluated DP k . expected
revenue calculated running 100000 Monte Carlo simulations. simulation consists
sampling one policy defender calculate resulting expected utility
N MDPs. end simulations, obtain N N matrix rows
represented policies ik columns represent N MDPs. cell (k, k )

matrix contains expected revenue obtained evaluating policy ik DP k .
Then, policy deploy selected using maximin strategy. detail,
chose policy maximizing expected utility worst case scenario, i.e.
considering MDP yielding lowest expected utility among different MDPs.
practical perspective, policy obtained earlier might yield schedule
represent exactly delays might happen patrol. However,
modelling five different delays, schedules able cover larger range
delays. Hence, whenever officer interrupted requests update, smartphone
application simply search schedule state best matches officer current
location time present new list actions starting there.
6.3.3 Results
21 weekdays experiments, able run GT schedules 11 days
testing UR schedules deployed 10 days, resulting 855 765 patrol
minutes, respectively. schedules compared using two different metrics. First,
counted number passengers checked number captures end
patrol. captures defined sum number warnings, citations,
arrests. Passengers without valid ticket could given warning cited violation
discretion officer. metric chosen would allow us measure
performance schedule real world. Second, counted number times
update function used voluntarily involuntarily. involuntary updates
helped determine value using MDPs discussed below, voluntary updates measured
352

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

GT
UR

D1
0
0

D2
1
2

D3
3
1

D4
1
1

D5
1
1

D6
0
2

D7
2
2

D8
2
2

D9
4
3

D10
2
2

D11
1

total
18
16

Table 3: Number INVOLUNTARY (delays) deviations day patrol

GT
UR

D1
0
1

D2
0
0

D3
0
1

D4
0
1

D5
0
1

D6
0
0

D7
0
1

D8
0
1

D9
0
1

D10
0
1

D11
0

total
0
8

Table 4: Number VOLUNTARY (updates) deviations day patrol
human (officer) perception quality schedules voluntary updates,
officers dissatisfied given action. Table 2 shows duration
day patrol GT UR schedules8 .
shown table, actual duration daily patrol often different
21 days experiment, GT UR schedules. reason, providing
comparison normalized days experiment impossible. However,
days, able collect data multiples 30 minutes (e.g., 60, 90 minutes).
Hence, properly compare results, divided data 30 minutes segments.
specifically, considered train station checks within time window 30
minutes collected data resulting actions9 . defined data
points, proceed analyze results.
Validation MDP model: discussed beginning section GT
UR schedules calculated solving MDP. reason schedules could
updated request new schedule. Tables 3 4 show, day patrol,
number VOLUNTARY INVOLUNTARY deviations requested officers.
total, GT schedules updated 18 times, involuntary deviations,
i.e., delays. update requests confirm MDP model able provide
schedules could updated whenever necessary.
INVOLUNTARY deviations due officers writing citations helping
people. average delay length 12 minutes (the largest delay 20 minutes).
case, discussed beginning section, new schedule provided
starting officers current location closest time. Finally, Table 4 shows
voluntary deviations used UR schedules. result strongly suggests
officers mostly satisfied GT schedules. addition, means GT schedules
8. shown Table 2, day patrol correspond 2-day test GT schedules tested
first day UR schedules tested second, identical times.
9. doing, segments also statistically independent. Within segment officers check
different people unable affect other. segment corresponds sample different
train riders taken different times locations. officers never check rider
twice importantly, 30 minutes, visit different locations riding trains
(roughly, one train every 6 minutes blue line) inspecting stations (on-station operations
last longer 20 minutes).

353

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

(a) Captures

(b) Warnings

(c) Violations

(d) Passengers

Figure 13: Results Fare Evasion tests
really compete UR schedules only. Rather, comparison UR
schedules augmented real-time human intelligence time (8
10 days). discuss results comparison next.
Game-Theory vs. Uniform Random: results obtained shown
Figure 13 Table 5. Figure 13 shows eight boxplots depicting data
collected patrol, using GT UR schedules. Respectively, four
figures present data collected captures (Figure 13(a)), warnings (Figure 13(b)), violations
(Figure 13(c)), passengers checked (Figure 13(d)) per 30 minutes patrolling10 .
boxplot, top bottom box represent 75th 25th percentiles,
respectively, middle line indicates median collected data. +
data points indicate statistical outliers, whiskers show extreme nonoutlier data points. four figures (captures, warnings, violations passengers
checked) shows data collected using GT schedules higher values
data collected using UR schedules. shown Table 5, average, GT schedules led
to, respectively 15.52 captures, 10.42 warnings 5.03 violations issued every 30 minutes
against, respectively 9.55 captures, 6.48 warnings 3.07 violations obtained using
UR schedules. confirm statistical significance results, ran number
weighted unpaired student t-tests (p = 0.05) (Goldberg, Kercheval, & Lee, 2005; Bland &
Kerry, 1998) verified, metric, difference results statistically
significant. used weighted t-test data segments duration shorter
30 minutes wanted use available data analysis. shown
Table 2, patrol durations could properly divided finite number
30 minutes segments (e.g., UR: D6, D7, D8, D9 GT: D6, D8, D11). Therefore,
10. GT schedules also led two arrests day 6. patrol lasted 10 minutes.

354

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

GT
UR

Days
11
10

avg. C
15.52
9.55

avg. W
10.42
6.48

avg. V
5.03
3.07

avg. P
96.77
60.85

Table 5: Average captures (C), warnings (W), violations (V) passengers (P) based
results obtained Figure 13

calculated weighted average metric defined above, whereby segment
given weight defined based segments duration (longer segments
corresponded higher weights).
practical perspective, magnitude difference two approaches significant: cumulatively period 21 days GT would capture much
larger total number fare evaders. result emphasized even correlate results shown Tables 4 3. running UR schedules officers
requesting INVOLUNTARY deviations essentially every day, whereas deviations requested running GT schedules. words, using real-time
situation awareness augment quality schedules, thus making UR schedule
compelling.
results Table 5 also indicate GT schedules led 96.77 passengers checked
every 30 minutes 60.85 passengers checked using UR schedules. discussed
Section 5.1, GT schedules generated leveraging possible sequences train
station checks taking account key dimensions discussed Section
6.1, including train schedules, officers effectiveness and, importantly daily
ridership statistics. means stations trains higher presence riders
given higher coverage probability since likely contain fare evaders.
Hence, results confirm accuracy model Figure 13(d) Table 5
show GT schedules led officers check passengers UR schedules.
raises question whether static type schedule, deploys
officers crowded locations, would lead similar even better results
obtained GT. Given limited amount time conduct
experiments, unable compare GT schedules static deployment
key weakness predictability longer term. Indeed, effective randomization
one main reasons LASD collaborate experiments security agencies
know static schedules become predictable long term11 . certain amount
time, passengers would know officers located could exploit
information avoid paying fare.

7. Summary Future Work
paper addressed dynamic execution uncertainty security resources allocation.
specifically, paper presented four main contributions. First, proposed general
Bayesian Stackelberg game model security patrolling whereby execution uncertainty
11. Tambe (2011) discusses benefits randomization detail.

355

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

handled via Markov decision process (MDP). Second, studied problem computing
Stackelberg equilibrium (SSE) game showed exploiting structure
games utility functions, could represent defenders strategy space compact
form could efficiently solved using canonical algorithms solving Bayesian SSGs.
addition, showed always possible generate mixed strategy
polynomially-sized support. Third, ran number simulations whereby tested
framework within various different settings. key result modeling execution
uncertainty MDP, able generate policies overcame failures
existing SSG algorithms take uncertainty account. Finally,
fourth contribution, ran real-world experiment whereby compared schedules
generated using approach competing schedules comprised random scheduler
augmented officers providing real-time knowledge current situation. results
supported MDP-based model actually able show use
contingency plans provided MDP real-world. addition, results showed
game-theoretic schedules outperformed competing schedules, despite fact
latter improved real-time knowledge. doing, results constitute
one first examples potential employing algorithmic game theory solve
real-world security allocation problems.
terms future work, exist number challenges left address. One interesting technical challenge addressing adjustable autonomy (Huber, 1999; Scerri,
Pynadath, & Tambe, 2002) mixed initiative planning (Ferguson, Allen, & Miller, 1996)
context game theoretic scheduling. experiments showed officers might
deviate schedule perceive might lead poor performance terms
fare evaders captured. Hence, would interesting augment schedules take
possibility account. specifically, could extend game theoretic model described Section 3 account possibility officers would eventually deviate
schedules execute action based real-time situational awareness.
One interesting empirical challenge would run long-term controlled experiment
(e.g., one year) complementary one present paper. idea would
measure riders react game-theoretic scheduling. discussed Section 6.3,
given practical difficulties related running real-world security experiments, security
agencies LASD typically prefer avoid running long term experiments
would interfere every-day security transit system. Nonetheless,
could done, experiment would provide valuable insight effects
SSGs real-world.

Acknowledgements
article product joint work Francesco M. Delle Fave Albert X. Jiang.
first authors work.
terms contributions, article extends paper Jiang, Yin, Zhang, Tambe,
Kraus (2013). work, extend initial version following contributions: (i) present new theoretical result, whereby show always calculate
optimal mixed strategy defender polynomially-sized support; (ii) extend simulations presented Jiang et al. (2013) evaluating approach
356

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

uniform random scheduler; (iii) present results large scale real-world experiment
whereby validate MDP-based approach defined Jiang et al. (2013) field; (iv)
experiment, compare actual outcome executing schedules generated
MDP-based approach ones generated using competing uniform random
scheduler presenting first results algorithmic game theory field; (v)
run real-world experiments, describe development smartphone application load visualize game-theoretic schedules sampling technique instantiate
key parameters MDP; (vi) discuss significant new related work future work.
thank Los Angeles Sheriffs Department exceptional collaboration.
research supported TSA grant HSHQDC-10-A-BOA19, MURI grant W911NF-11-10332 3-6797.

Appendix
appendix complements simulations results discussed Section 6.2, presenting
results obtained Blue, Green Gold line. Figure 14 compares,
former three lines, defenders revenue per rider obtained LP (Equation (8)), i.e.,
upper bound, true value obtained running 100000 Monte Carlo simulations
Markov strategy. experiment run assuming setting discussed
beginning Section 6.2: 3 hours patrolling 6 resources.
Figure 15 shows simulation results complementing ones presented Section 6.2
Hypothesis 1. setting described Section 6.2: 6 resources patrolling
Blue, Green Gold lines 3 hours varying 0% 25%
delay time 5 25 minutes.
Figure 16 shows results complementing ones presented Section 6.2 validating hypothesis 2. simulation, considered 6 resources patrolling 3 hours
four lines varied uncertainty 0% 25%.
Figure 17 shows results complementing ones presented Section 6.2 validating hypothesis 4. simulation, considered 3, 6 9 resources representing 3
levels coverage, low, medium high respectively. evaluated revenue per
rider varying delay probability 0% 25%.
Figure 18 shows results complementing ones presented Section 6.2 validating hypothesis 5. simulation, considered different delay probabilities (0%, 10%
20%) evaluated revenue per rider varying number patrol units 2
6.

357

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

(a) Blue line

(b) Green line

(c) Gold line

Figure 14: Markov Strategy (Equation (17)) vs. true LP (Equation (8))
Blue, Green Gold lines

358

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

(a) Blue line

(b) Green line

(c) Gold line

Figure 15: Defenders revenue per rider Blue, Green Gold line, varying
uncertainty delay time.

359

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

(a) Blue line

(b) Green line

(c) Gold line

Figure 16: Fare evasion rate Blue, Green Gold lines varying delay probability

360

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

(a) Blue line

(b) Green line

(c) Gold line

Figure 17: Revenue per rider Blue, Green Gold lines different allocation
resources

361

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

(a) Blue line

(b) Green line

(c) Gold line

Figure 18: Revenue per rider Blue, Green Gold lines three levels delay
probability

362

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

References
Agmon, N., Kaminka, G. A., & Kraus, S. (2011). Multi-robot adversarial patrolling: facing
full-knowledge opponent. Journal Artificial Intelligence Research (JAIR), 42 (1),
887916.
Agmon, N., Kraus, S., & Kaminka, G. A. (2008a). Multi-robot perimeter patrol adversarial settings. Proceedings International Conference Robotics
Automation (ICRA), pp. 23392345. IEEE.
Agmon, N., Sadov, V., Kaminka, G., & Kraus, S. (2008b). impact adversarial
knowledge adversarial planning perimeter patrol. Proceedings Seventh International Joint Conference Autonomous Agents Multiagent Systems
(AAMAS), pp. 5562.
An, B., Kempe, D., Kiekintveld, C., Shieh, E., Singh, S., & Tambe, M. (2012). Security
games limited surveillance. Proceedings AAAI Conference Artificial
Intelligence (AAAI), pp. 12411247.
An, B., Tambe, M., Ordonez, F., Shieh, E., & Kiekintveld, C. (2011). Refinement strong
Stackelberg equilibria security games. Proceedings Twenty-Fifth Conference Advancement Artificial Intelligence (AAAI), pp. 587593.
Aoyagi, M. (1996). Reputation dynamic Stackelberg leadership infinitely repeated
games. Journal Economic Theory, 71 (2), 378 393.
Archibald, C., & Shoham, Y. (2011). Hustling repeated zero-sum games imperfect
execution. Proceedings Twenty-second International Joint Conference
Artificial Intelligence (IJCAI), pp. 3136.
Basilico, N., Gatti, N., & Amigoni, F. (2009a). Leader-follower strategies robotic patrolling environments arbitrary topologies. Proceedings Eight International Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp.
5764.
Basilico, N., Gatti, N., Rossi, T., Ceppi, S., & Amigoni, F. (2009b). Extending algorithms
mobile robot patrolling presence adversaries realistic settings.
Proceeding Conference Intelligence Agent Technology (IAT), pp. 557564.
Basilico, N., Gatti, N., & Villa, F. (2010). Asynchronous multi-robot patrolling intrusions arbitrary topologies. Proceeding Conference Advancement
Artificial Intelligence (AAAI), pp. 345350.
Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2004). Solving Transition Independent Decentralized Markov Decision Processes. JAIR.
Bland, M. J., & Kerry, S. M. (1998). Weighted comparison means. BMJ: British Medical
Journal, 316, 125129.
Booz Allen Report (2007). Faregating analysis. Tech. rep., Booz Allen Hamilton Company. Report commissioned LA Metro, http://boardarchives.metro.net/
Items/2007/11_November/20071115EMACItem27.pdf.
Bowling, M., & Veloso, M. (2004). Existence multiagent equilibria limited agents.
Journal Artificial Intelligence Research (JAIR), 22, 353384.
363

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

Brown, A., Camerer, C. F., & Lovallo, D. (2012). review review? limited strategic thinking movie box office. American Economic Journal: Microeconomics,
4 (2), 126.
Clarke, R. V. (1993). Fare evadion automatic ticket collection london underground. Crime Prevention Studies, 1, 135146.
Clarke, R. V., Contre, S., & Petrossian, G. (2010). Deterrence Fare Evasion: Results
Natural Experiment. Security Journal.
Conitzer, V. (2012). Computing game-theoretic solutions applications security.
Proceedings AAAI Conference Artificial Intelligence (AAAI), pp. 21062112.
Conitzer, V., & Sandholm, T. (2006). Computing optimal strategy commit to.
EC: Proceedings ACM Conference Electronic Commerce.
Dickerson, J. P., Simari, G. I., Subrahmanian, V. S., & Kraus, S. (2010). graph-theoretic
approach protect static moving targets adversaries. Proceedings
Ninth International Joint Conference Autonomous Agents Multiagent Systems,
pp. 299306.
Fang, F., Jiang, A., & Tambe, M. (2013). Protecting moving targets multiple mobile
resources. Journal Artificial Intelligence Research (JAIR), 48, 583634.
Ferguson, G., Allen, J., & Miller, B. (1996). Trains-95: Towards mixed-initiative planning
assistant. Proceedings 3rd Conference Artificial Intelligence Planning
Systems (AIPS), pp. 7077.
Filar, J., & Vrieze, K. (1996). Competitive Markov Decision Processes. Springer.
Gatti, N. (2008). Game theoretical insights strategic patrolling: Model algorithm
normal form. Proceedings European Conference Artificial Intelligence
(ECAI), pp. 403407.
Goldberg, L. R., Kercheval, A. N., & Lee, K. (2005). t-statistics weighted means
credit risk modeling. Journal Risk Finance, 6 (4), 349365.
Grotschel, M., Lovasz, L., & Schrijver, A. (1981). ellipsoid method consequences
combinatorial optimization. Combinatorica, 1 (2), 169197.
Gruber, P. M. (2007). Convex Discrete Geometry. Springer.
Huber, M. J. (1999). Considerations flexible autonomy within bdi intelligent agent architectures. Proceedings AAAI Conference Artificial Intelligence (AAAI),
pp. 431438.
Jain, M., Kardes, E., Kiekintveld, C., Tambe, M., & Ordonez, F. (2010). Security games
arbitrary schedules: branch price approach. AAAI.
Jaulmes, R., Pineau, J., & Precup, D. (2007). formal framework robot learning
control model uncertainty. Proceedings International Conference
Robotics Automation (ICRA), pp. 21042110. IEEE.
Jiang, A. X., Yin, Z., Zhang, C., Tambe, M., & Kraus, S. (2013). Game-theoretic randomization security patrolling dynamic execution uncertainty. Proceedings
Twelfth International Conference Autonomous Agents Multiagent Systems,
pp. 207214.
364

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

Kohavi, R. (1995). study cross-validation bootstrap accuracy estimation
model selection. Proceedings Fourteenth International Joint Conference
Artificial Intelligence (IJCAI), pp. 11371143.
Korzhyk, D., Conitzer, V., & Parr, R. (2011a). Security games multiple attacker
resources. Proceedings Twenty-second International Joint Conference
Artificial Intelligence (IJCAI), pp. 273279.
Korzhyk, D., Conitzer, V., & Parr, R. (2011b). Solving stackelberg games uncertain
observability. Proceedings Tenth International Conference Agents
Multi-agent Systems (AAMAS), pp. 10131020.
Letchford, J., & Conitzer, V. (2013). Solving security games graphs via marginal probabilities. Proceedings AAAI Conference Artificial Intelligence (AAAI),
pp. 591597.
Letchford, J., & Vorobeychik (2013). Optimal interdiction attack plans. Proceedings
Twelfth International Conference Autonomous Agents Multi-agent Systems
(AAMAS)., pp. 199206.
Letchford, J., & Conitzer, V. (2010). Computing optimal strategies commit
extensive-form games. Proceedings ACM Conference Electronic Commerce (EC), pp. 8392.
Letchford, J., MacDermed, L., Conitzer, V., Parr, R., & Isbell, C. L. (2012). Computing
optimal strategies commit stochastic games. Proceedings AAAI
Conference Artificial Intelligence.
Marecki, J., & Tambe, M. (2008). Towards faster planning continuous resources
stochastic domains. Proceedings AAAI Conference Artificial Intelligence
(AAAI), No. 10491055.
Mausam, Benazera, E., Brafman, R. I., Meuleau, N., & Hansen, E. A. (2005). Planning
continuous resources stochastic domains. Proceedings Nineteenth
International Joint Conference Artificial Intelligence, pp. 12441250.
Nguyen, T. H., Yang, R., Azaria, A., Kraus, S., & Tambe, M. (2013). Analyzing
effectiveness adversary modeling security games. Proceedings AAAI
Conference Artificial Intelligence (AAAI), pp. 718724.
Ostling, R., Wang, J., Tao-yi, J., Chou, E. Y., & Camerer, C. F. (2011). Testing game theory
field: Swedish lupi lottery games. American Economic Journal: Microeconomics,
3 (3), 133.
Paruchuri, P., Pearce, J. P., Marecki, J., Tambe, M., Ordonez, F., & Kraus, S. (2008a).
Playing games security: efficient exact algorithm Bayesian Stackelberg
games. AAMAS.
Paruchuri, P., Pearce, J. P., Marecki, J., Tambe, M., Ordonez, F., & Kraus., S. (2008b).
Playing games security: efficient exact algorithm solving bayesian stackelberg games. Proceedings Seventh International Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 539547.
365

fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe

Pita, J., Jain, M., Western, C., Portway, C., Tambe, M., Ordonez, F., Kraus, S., & Paruchuri,
P. (2008). Deployed ARMOR protection: application game theroetic model
security los angeles international airport. Proceedings Seventh
Internation Conference Autonomous Agents Multi-Agent Systems (AAMAS).
Pita, J., Tambe, M., Kiekintveld, C., Cullen, S., & Steigerwald, E. (2011). GUARDS game theoretic security allocation national scale. Proceedings Tenth
International Conference Autonomous Agents Multi-Agent Systems (AAMAS),
pp. 3744.
Scerri, P., Pynadath, D. V., & Tambe, M. (2002). Towards adjustable autonomy
real-world. Journal Artificial Intelligence Research (JAIR), 17, 171228.
Shieh, E., An, B., Yang, R., Tambe, M., Baldwin, C., DiRenzo, J., Maule, B., & Meyer, G.
(2012). Protect: deployed game theoretic system protect ports united
states. AAMAS.
Sless, E., Agmon, N., & Kraus, S. (2014). impact adversarial knowledge adversarial planning perimeter patrol. Proceedings Thirteenth International
Conference Autonomous Agents Multi-Agent Systems (AAMAS), p. press.
Tambe, M. (2011). Security Game Theory: Algorithms, Deployed Systems, Lessons
Learned. Cambridge University Press.
Tsai, J., Rathi, S., Kiekintveld, C., Ordonez, F., & Tambe, M. (2009). IRIS - tool
strategic security allocation transportation networks. Proceedings Eight
International Conference Autonomous Agents Multi-Agent Systems (AAMAS),
pp. 831839.
Vanek, O., Jakob, M., Lisy, V., Bosansky, B., & Pechoucek, M. (2011). Iterative gametheoretic route selection hostile area transit patrolling. Proceedings
Tenth International Conference Autonomous Agents Multi-Agent Systems
(AAMAS), pp. 12731274.
Varakantham, P., Lau, H. C., & Yuan, Z. (2013). Scalable randomized patrolling securing
rapid transit networks. Proceedings Conference Innovative Applications
Artificial Intelligence (IAAI), pp. 15631568.
Vorobeychik, Y., & Singh, S. (2012). Computing stackelberg equilibria discounted
stochastic games. Proceedings AAAI Conference Artificial Intelligence
(AAAI), pp. 14781484.
Weidner, R. R. (1996). Target-hardening new york city subway station: Decreased fare
evasion price?. Crime Prevention Studies, 6, 117132.
Yang, R., Kiekintveld, C., Ordonez, F., Tambe, M., & John, R. (2011). Improving resource
allocation strategy human adversaries security games. Proceedings
International Joint Conference Artificial Intelligence (IJCAI), pp. 458464.
Yin, Z., Jiang, A., Johnson, M., Tambe, M., Kiekintveld, C., Leyton-Brown, K., Sandholm,
T., & Sullivan, J. (2012). Trusts: Scheduling randomized patrols fare inspection
transit systems. Proceedings Conference Innovative Applications
Artificial Intelligence (IAAI), pp. 5972.
366

fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty

Yin, Z., Jain, M., Tambe, M., & Ordonez, F. (2011). Risk-averse strategies security
games execution observational uncertainty. Proceedings AAAI
Conference Artificial Intelligence (AAAI), pp. 758763.
Yin, Z., & Tambe, M. (2012). unified method handling discrete continuous uncertainty Bayesian stackelberg games. Proceedings Eleventh International
Conference Autonomous Agents Multiagent Systems (AAMAS), pp. 234242.

367

fiJournal Artificial Intelligence Research 50 (2014)

Submitted 10/13; published 05/14

Decision-Theoretic Model Assistance
Alan Fern

AFERN @ EECS . OREGONSTATE . EDU

School EECS, Oregon State University, Corvallis, USA

Sriraam Natarajan

NATARASR @ INDIANA . EDU

SoIC, Indiana University, Bloomington, USA

Kshitij Judah

JUDAHK @ EECS . OREGONSTATE . EDU

School EECS, Oregon State University, Corvallis, USA

Prasad Tadepalli

TADEPALL @ EECS . OREGONSTATE . EDU

School EECS, Oregon State University, Corvallis, USA

Abstract
growing interest intelligent assistants variety applications sorting
email helping people disabilities daily chores. paper, formulate
problem intelligent assistance decision-theoretic framework, present theoretical
empirical results. first introduce class POMDPs called hidden-goal MDPs (HGMDPs),
formalizes problem interactively assisting agent whose goal hidden whose
actions observable. spite restricted nature, show optimal action selection
HGMDPs PSPACE-complete even deterministic dynamics. introduce
restricted model called helper action MDPs (HAMDPs), sufficient modeling many
real-world problems. show classes HAMDPs efficient algorithms possible.
interestingly, general HAMDPs show simple myopic policy achieves near
optimal regret, compared oracle assistant knows agents goal. introduce
sophisticated versions policy general case HGMDPs combine
novel approach quickly learning agent assisted. evaluate approach
two game-like computer environments human subjects perform tasks, real-world
domain providing assistance folder navigation computer desktop environment.
results show three domains framework results assistant substantially reduces
user effort modest computation.

1. Introduction
Personalized AI systems interactively assist human users received significant attention recent years (Yorke-Smith, Saadati, Myers, & Morley, 2012; Lieberman, 2009; Myers, Berry,
Blythe, Conleyn, Gervasio, McGuinness, Morley, Pfeffer, Pollack, & Tambe, 2007). However,
overarching formal framework interactive assistance captures different systems
provides theoretical foundation largely missing. paper address lacuna introducing general framework decision-theoretic assistance, analyzing problem complexity
different assumptons, proposing different heuristic solutions, evaluating effectiveness.
consider model assistant observes goal-oriented agent must select assistive
actions order best help agent achieve goals. real applications, requires
assistant able handle uncertainty environment agent, reason varying
c
2014
AI Access Foundation. rights reserved.

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

action costs, handle unforeseen situations, adapt agent time. consider
decision-theoretic model, based partially observable Markov decision processes (POMDPs),
naturally handles features, providing formal basis designing intelligent assistants.
first contribution work formulate problem selecting assistive actions
class partially observable Markov decision processes (POMDPs) called Hidden Goal MDPs
(HGMDPs), jointly models application environment along agents policy
hidden goals. key feature approach explicitly reasons environment
agent, provides potential flexibility assisting ways unforeseen developer
new situations encountered. Thus, developer need design hand-coded assistive
policy preconceived application scenario. Instead, using framework, burden
developer provide model application domain agent, alternatively
mechanism learning one models experience. framework uses
models attempt compute, situation, whether assistance could beneficial
assistive action select.
second contribution work analyze properties formulation. Despite
restricted nature HGMDPs, complexity determining HGMDP finite-horizon
policy given value PSPACE-complete even deterministic environments. motivates
restricted model called Helper Action MDP (HAMDP), assistant executes helper
action step. agent obliged accept helper action helpful goal
receives reward bonus (or cost reduction) so. Otherwise, agent continue
preferred action without reward penalty assistant. show classes
problem complete PSPACE NP. also show class HAMDPs
deterministic agents polynomial time algorithms minimizing expected worstcase regret relative oracle assistant knows goal agent. Further, show
optimal worst case regret characterized graph theoretic property called tree rank
corresponding all-goals policy tree computed linear time.
principle, given HGMDP, one could apply POMDP solver order arrive optimal
assistant policy. Unfortunately, relatively poor scalability POMDP solvers often force us
utilize approximate/heuristic solutions. particularly true assistant continually
learning updated models agent and/or environment, results sequence
accurate HGMDPs, needs solved. third contribution work set
myopic action selection mecahnisms approximate optimal policy. HAMDPs,
analyze myopic heuristic show regret upper bounded entropy
goal distribution HAMDPs. Furthermore give variant policy able
achieve worst-case expected regret logarithmic number goals without
prior knowledge goal distribution. also describe two approaches based
combination explicit goal estimation, myopic heuristics, bounded search
generally applicable HGMDPs.
order approach useful, HGMDP must incorporate reasonably accurate model agent assisted. fourth contribution work describe novel
model-based bootstrapping mechanism quickly learning agent policy, important
usability assistant early lifetime. main idea assume agent
close rational decision-theoretic sense, motivates defining prior agent policies
places higher probability policies closer optimal. prior combination

72

fiA ECISION -T HEORETIC ODEL SSISTANCE

Bayesian updates allows agent model learned quickly rationality assumption
approximately satisfied.
final contribution work evaluate framework three domains. First
consider two game-like computer environments human subjects. results domains
show assistants resulting framework substantially reduce amount work
performed human subjects. also consider realistic domain, folder navigator
(Bao, Herlocker, & Dietterich, 2006) Task Tracer project. domain, user navigates
directory structure searching particular location open save file, unknown
assistant. job assistant predict users destination folder take actions
provide short cuts reach it. results show generic assistant framework compares
favorably hand-coded solution Bao et al.
remainder paper organized follows. next section, introduce formal problem setup terms HGMDPs, followed analysis computational complexity
guarantees myopic heuristics case HAMDPs. Next, present approximate solution approach general HGMDPs based goal estimation online action selection. Finally
give empirical evaluation approach three domains conclude discussion
related future work.

2. Hidden Goal Markov Decision Processes
Throughout paper refer entity attempting assist agent
assisting entity assistant. consider episodic problem setting beginning
episode agent begins world state selects goal finite set possible
goals. goal set, example, might contain possible dishes agent might interested
cooking, possible destination folders agent may possibly navigate to. Importantly, assistant fully observe world state agents actions, cannot observe
goal agent. model interaction agent assistant sequential
agent assistant alternate turns, taking single action per turn (possibly noop).1 episode
ends either agents assistants action leads goal state. immediate reward
accumulated action episode. total reward episode equal
sum rewards obtained episode. Note available actions agent
assistant need may varying rewards. Since assistant agent
share objective, rewards viewed perspective agent. objective
assistant behave way maximizes expected total reward episode.
formally, model interaction via Hidden Goal Markov Decision Processes
(HGMDPs). HGMDP MDP goal user observed rest
environment completely observed. HGMDP tuple hS, G, A, A0 , T, R, , , IG
set states, G finite set possible agent goals, set agent actions,
A0 set assistant actions. Typically A0 include noop action, allows assistant
decide provide assistance particular decision epoch. transition function
(s, g, a, s0 ) probability transition state s0 taking action A0
agents goal g. R reward function maps G (A A0 ) real values.
1. consider strictly alternating turn model simplicity. However, straightforward use model
capture interactions strictly alternating, e.g. allowing assistant agent take multiple actions
row.

73

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

agents policy maps G distributions need optimal sense.
(IG ) initial state (goal) distribution.
assistant policy HGMDP defines distribution actions given sequence
preceding observations, i.e., sequence state action pairs. important assistant policy depends history rather current state since entire history potentially
provide evidence goal agent, may necessary selecting appropriate
action. must define objective function used evaluate value particular assistant policy. consider finite-horizon episodic problem setting, HGMDP
episode begins drawing initial state goal g IG . process alternates
agent assistant executing actions (including noops) environment
horizon terminal state reached. agent assumed select actions according .
many domains, terminal goal state reached within horizon, though general, goals
arbitrary impact reward function. reward episode equal sum
rewards actions executed agent assistant episode. objective
assistant reason HGMDP observed state-action history order select
actions maximize expected (or worst-case) total reward episode.
proceeding worth reviewing assumptions formulation potential implications.
Partial Observability: definition HGMDP similar definition
Partially Observable Markov Decision Process (POMDP). fact, HGMDP special
case POMDP unobserved part state space consists single component corresponds goal user. simplicity assumed
world state fully observable. choice fundamental framework one
imagine relatively straightforward extensions techniques model environment
partially observable MDP (POMDP) world states fully observable.
Section 3, shed light hardness HGMDPs describe specialized
heuristic solutions performance guarantees.
Agent Policy: also assumed agent modeled memoryless/reactive
policy gives distribution actions conditioned current world state
goal. assumption also fundamental framework one also extend
include complex models user, example, include hierarchical goal
structures. extension explored previously (Natarajan, Tadepalli, & Fern,
2007).
Sequential Interaction: also assumed simplicity interaction model
assistant agent involves interleaved, sequential actions rather parallel actions.
This, example, precludes assistant taking actions parallel agent.
parallel assistive actions useful many cases, many domains sequential
actions norm. especially motivated domains intelligent desktop
assistants help store retrieve files, filter spam, sort email, etc., smart homes
open doors, switch appliances, on. Many opportunities assistance
domains sequential variety. many cases, tasks appear require parallel
activity often formulated set threads thread sequential hence

74

fiA ECISION -T HEORETIC ODEL SSISTANCE

formulated separate assistant. Extending framework handle general parallel
assistance interesting future direction.
Goal-Dependent Transitions: dependence reward policy goal allows
model capture agents desires behavior goal. dependence
goal less intuitive many cases dependence used
model dynamics environment. However, allow goal dependence
generality modeling. example, convenient model basic communication
actions agent changing aspects state, result actions often
goal dependent.
two main obstacles solving problem intelligent assistance framework.
First, many scenarios, initially HGMDP directly disposal since lack
accurate information agent policy and/or goal distribution IG . often due
fact assistant deployed variety initially unknown agents. Rather, assistant find environment given possible set goals. described
Section 5, approach difficulty learn approximate HGMDP estimating agent
policy goal distribution IG . Furthermore, also describe bootstrapping mechanism learning approximations quickly. second obstacle solving HGMDP
generally high computational complexity solving HGMDPs. deal issue Section 4
considers various approximate techniques efficiently solving HGMDPs.
mentioned possible provide assistance using simpler domain-specific
engineered solutions. particular, domains consider later could solved using several less
expensive solutions require machinery HGMDPs. fact, one domains,
compare model existing supervised learning method. goal work
provide domain-independent framework potentially encapsulate several assistant
systems hope gives rise robust understanding methodology building
systems much less human effort future.

3. Theoretical Analysis
section, analyze hardness solving HGMDPs, show despite
special case POMDPs, hard. motivates new model called Helper-Action
MDP (HAMDP) restricted amenable approximate solutions.
introduce myopic heuristic solve HAMDPs analyze performance. also
analyze special cases HAMDPs permit efficient solutions.
3.1 Complexity Results Hidden Goal MDPs
Given knowledge agents goal g HGMDP, assistants problem reduces solving
MDP assistant actions. MDP transition function captures state change due
assistant action also ensuing state change due agent action selected according
given g. Likewise reward function transition captures reward due assistant action
ensuing agent action conditioned g. optimal policy MDP corresponds
optimal assistant policy g. However, since real assistant often uncertainty
agents goal, unlikely optimal performance achieved.

75

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

view HGMDP collection |G| MDPs share state space,
assistant placed one MDPs beginning episode, cannot observe
one. MDP result fixing goal component HGMDP definition one
goals. collection easily modeled restricted type partially observable MDP
(POMDP) state space G. component completely observable, G component unobservable changes beginning episode (according IG )
remains constant throughout episode. Furthermore, POMDP transition provides observations agent action, gives direct evidence unchanging G component.
perspective HGMDPs appear significant restriction general POMDPs. However,
first result shows despite restriction worst-case complexity reduced even
deterministic dynamics.
Given HGMDP , horizon = O(|M |), reward target r , short-term reward
maximization problem asks whether exists history-dependent assistant policy achieves
expected finite horizon reward least r . general POMDPs problem PSPACEcomplete (Papadimitriou & Tsitsiklis, 1987; Mundhenk, 2001), POMDPs deterministic
dynamics, NP-complete (Littman, 1996). However, following result.
Theorem 1. Short-term reward maximization HGMDPs deterministic dynamics PSPACEcomplete.
Proof. Membership PSPACE follows fact HGMDP polynomially encoded POMDP policy existence PSPACE. show PSPACE-hardness,
reduce PSPACE-complete problem TQBF (truth quantified Boolean formula) problem
existence history-dependent assistant policy expected reward r.
Let quantified Boolean formula form x1 x2 x3 . . . xn {C1 (x1 , . . . , xn ) . . .
Cm (x1 , . . . , xn )}, Ci disjunctive clause. us, goal gi clause,
agent chooses goal uniformly randomly set goals formed hides
assistant. states consist pairs form (v, i), v {0, 1} current value
goal clause, next variable set. actions assistant set existentially
quantified variables. agent simulates setting universally quantified variables choosing
actions set {0, 1} equal probability. episode terminates variables
set, assistant gets reward 1 value clause 1 end reward 0
otherwise.
Note assistant get useful informtion goal termination
episode. satisfiable, assistant policy leads reward 1
goals choices agent actions, hence expected value 1 goal
distribution. not, least one goals satisfied setting universal
quantifiers, leading expected value < 1. Hence TQBF problem reduces deciding
HGMDP policy expected reward 1.
result shows POMDP encoded HGMDP deterministic dynamics, stochastic dynamics POMDP captured via stochastic agent policy
HGMDP. However, HGMDPs resulting PSPACE-hardness reduction quite pathological compared likely arise realistic assistant domains. importantly,
agents actions provide practically information agents goal end episode,
late exploit knowledge. suggests search restricted classes
HGMDPs allow efficient solutions performance guarantees.
76

fiA ECISION -T HEORETIC ODEL SSISTANCE

3.2 Helper Action MDPs
motivation Helper Action MDPs (HAMDPs) place restrictions agent assistant avoid following three complexities arise general HGMDPs: 1) agent
behave arbitrarily poorly left unassisted agent actions may provide significant evidence goal; 2) agent free effectively ignore assistants help
exploit results assistive action, even would beneficial; 3) assistant
actions possibility negatively impacting agent compared assistant.
HAMDPs address first issue assuming agent competent (approximately)
maximizing reward without assistant. second third issues addressed assuming agent always detect exploit helpful actions assistant actions
never hurt agent even unhelpful.
Informally, HAMDP provides assistant helper action agents actions. Whenever helper action h executed directly corresponding agent action a,
agent receives bonus reward 1. However, agent accept helper action h
(by taking a) hence receive bonus, action agent considers good
achieving goal without assistant. Thus, primary objective assistant HAMDP
maximize number helper actions get accepted agent.2
simple, model captures much essence assistive domains assistant
actions cause minimal harm agent able detect accept good assistance
arises.
HAMDP HGMDP hS, G, A, A0 , T, R, , , IG following constraints:
agent assistant actions sets = {a1 , . . . , } A0 = {h1 , . . . , hn },
ai corresponding helper action hi .
state space = W (W A0 ), W set world states. States W A0
encode current world state previous assistant action.
reward function R 0 assistant actions. agent actions reward zero
unless agent selects action ai state (s, hi ) gives reward 1. is,
agent receives bonus 1 whenever takes action directly corresponding helper
action.
assistant always acts states W , taking hi deterministically
transitions (s, hi ).
agent always acts states A0 , resulting states according transition function depend hi , i.e. ((s, hi ), g, ai , s0 ) = 0 (s, g, ai , s0 )
transition function 0 .
Finally, agent policy, let (s, g) function returns set actions P (s, g)
distribution actions. view (s, g) set actions agent
2. Note assumed bonus rewards 1 simplicity. results easily extended
non-uniform positive bonus rewards. particular main result concerning bounding regret
myopic policy, analogous result simply includes constant factor equal maximum possible reward bonus.
exceptions Theorems 7 8, currently analogous results non-uniform reward
bonuses.

77

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

considers acceptable (or equally good) state goal g. agent policy always selects
ai helper action hi whenever ai acceptable. is, ((s, hi ), g) = ai whenever
ai (s, g). Otherwise agent draws action P (s, g).
HAMDP, primary impact assistant action influence reward following
agent action. Also notice HAMDPs rewards inherent underlying
environment. Rather, rewards bonuses received whenever agent accepts helper
action. could defined model include environmental reward addition
helper bonuses, unnecessarily complicates model (as following hardness result shows).
Instead, assume inherent environmental reward already captured agent policy
via (s, g), considered contain actions approximately optimize reward.
example, HAMDP model captures doorman domain, desktop domain experiments. doorman domain, helper actions correspond opening doors
agent, reduces cost navigating one room another. desktop domain, helper actions correspond offering shortcuts users destination folders. Importantly
opening incorrect door offering incorrect shortcut increase (physical) cost
agent assistant all, key property HAMDPs.
Despite apparent simplification HAMDPs HGMDPs, turns somewhat
surprisingly worst case computational complexity reduced.
Theorem 2. Short-term reward maximization HAMDPs PSPACE-complete.
Proof. Membership PSPACE follows easily since HAMDPs specialization HGMDPs.
proof PSPACE-hardness identical Theorem 1 except here, instead
agents actions, stochastic environment models universal quantifiers. agent accepts
actions last one sets variable suggested assistant.
assistants actions, environment chooses value universally quantified variable equal
probability. last action accepted agent goal clause evaluates 1, otherwise not.
history-dependent policy whose expected reward greater equal number
existential variables quantified Boolean formula satisfiable.
Unlike case HGMDPs, stochastic dynamics essential PSPACE-hardness
shown later section. Despite negative result, following sections demonstrate utility HAMDP restriction giving performance guarantees simple policies improved
complexity results. far, analogous results general HGMDPs.
3.3 Myopic Heuristic Analysis
HAMDPs closely related sequential prediction framework Littlestone (1988).
framework, round learner shown new instance predicts binary label.
prediction incorrect, mistake made, learner given true label. realizable
setting, true labels determined hypothesis target class. optimal prediction
algorithm minimizes upper bound number mistakes possible hypotheses.
view helper action HAMDP prediction user action. Maximizing bonus
reward HAMDP equivalent minimizing number mistakes sequential prediction.
Unlike sequential prediction, predictions (actions) need binary. sequential
prediction sequence states arbitrarily chosen, assume generated
78

fiA ECISION -T HEORETIC ODEL SSISTANCE

Markov process. spite differences, results sequential prediction
adapted HAMDPs albeit using different terminology. However, derive results
first principles consistency.
Given assistant policy 0 , regret particular episode extra reward oracle
assistant knowledge goal would achieve 0 . HAMDPs oracle assistant
always achieve reward equal finite horizon m, always select helper action
accepted agent. Thus, regret execution 0 HAMDP equal
number helper actions accepted agent, call mispredictions.
know optimizing regret PSPACE-hard thus focus bounding
expected worst-case regret assistant. introduce first myopic heuristic
show able achieve regret bounds logarithmic number goals.
Coarsened Posterior Heuristic. Intuitively, myopic heuristic select action
highest probability accepted respect coarsened version posterior
distribution goals. myopic policy state given history H based consistent goal
set C(H), set goals non-zero probability respect history H.
straightforward maintain C(H) observation (observations include world state
agents actions). myopic policy defined as:
(s, H) = arg max IG (C(H) G(s, a))


G(s, a) = {g | (s, g)} set goals agent considers
acceptable action state s. expression IG (C(H) G(s, a)) viewed probability
mass G(s, a) coarsened goal posterior assigns goals outside C(H) probability
zero otherwise weighs proportional prior.
Theorem 3. HAMDP expected regret coarsened posterior heuristic bounded
entropy goal distribution H(IG ).
Proof. main idea proof show misprediction myopic policy (i.e.
selected helper action accepted agent) uncertainty goal reduced
constant factor, allow us bound total number mispredictions trajectory.
Consider misprediction step coarsened posterior heuristic selects helper action hi
state given history H, agent accept action instead selects 6= ai .
definition myopic policy know IG (C(H) G(s, ai )) IG (C(H) G(s, )), since
otherwise assistant would chosen hi . fact argue IG (C(H 0 ))
IG (C(H))/2 H 0 history misprediction. is, probability mass
IG consistent goal set misprediction less half consistent goal set
misprediction. show consider two cases: 1) IG (C(H) G(s, ai )) <
IG (C(H))/2, 2) IG (C(H) G(s, ai )) IG (C(H))/2. first case, immediately get
IG (C(H) G(s, )) < IG (C(H))/2. Combining fact C(H 0 ) C(H)
G(s, ) get desired result IG (C(H 0 )) IG (C(H))/2. second case, note
C(H 0 ) C(H) (G(s, ) G(s, ai ))
C(H) (C(H) G(s, ai ))
Combining assumption second case immediately implies IG (C(H 0 ))
IG (C(H))/2.
79

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

shows misprediction made histories H H 0 IG (C(H 0 ))
IG (C(H))/2. implies episode, n mispredictions resulting history Hn ,
IG (C(Hn )) 2n . consider arbitrary episode true goal g. know
IG (g) lower bound IG (C(Hn )), implies IG (g) 2n equivalently n
log(IG (g)). Thus episode goal g maximum number mistakes bounded
log(IG (g)). Using fact get thePexpected number mispredictions episode
respect IG bounded g IG (g) log(IG (g)) = H(IG ), completes
proof.
Since H(IG ) log(|G|), result implies HAMDPs expected regret myopic
policy logarithmic number goals. Furthermore, uncertainty
goal decreases (decreasing H(IG )) regret bound improves get regret 0 IG
puts mass single goal. turns logarithmic bound asymptotically tight
worst case.
Theorem 4. exists HAMDP assistant policy expected regret least
log(|G|)/2.
Proof. Consider deterministic HAMDP environment structured binary tree
depth log(|G|), leaf corresponds one |G| goals. considering uniform
goal distribution easy verify node tree equal chance true
goal left right sub-tree episode. Thus, policy 0.5 chance
committing misprediction step episode. Since episode length log(|G|),
expected regret episode policy log(|G|)/2.
Resolving gap myopic policy bound regret lower bound open problem.
3.3.1 PPROXIMATE G OAL ISTRIBUTIONS .
0 instead true underlying
Suppose assistant uses approximate goal distribution IG
goal distribution IG computing myopic policy. is, assistant selects actions
0 (C(H) G(s, a)), refer myopic policy relative 0 .
maximize IG
G
0 instead bounded terms KullbackLeibler (KL) diverextra regret using IG
G
0 ), zero 0
gence (Kullback & Leibler, 1951) distributions KL(IG k IG
G
equals IG .

Theorem 5. HAMDP goal distribution IG , expected regret myopic policy
0 bounded H(I ) + KL(I k 0 ).
respect distribution IG
G
G
G
Proof. proof similar Theorem 3, except since myopic policy respect
0 rather , derive that, episode, maximum number mispredictions n
IG
G

80

fiA ECISION -T HEORETIC ODEL SSISTANCE

0 (g)). Using fact, average number mispredictions given by:
bounded log(IG

P

g

P

g

P

g

=

1
)=
IG (g) log( 0
IG (g)


1
IG (g) log( 0
) + log(IG (g)) log(IG (g)) =
IG (g)
X
IG (g)
IG (g) log(IG (g))
IG (g) log( 0
)
IG (g)
g
0
H(IG ) + KL(IG k IG
).

Note random variable X distribution P finite domain size N ,
KL(P k U ) = log(N ) H(P ), U uniform distribution. Thus, consequence
Theorem 5 myopic policy respect uniform goal distribution expected regret
bounded log(|G|) HAMDP, showing logarithmic regret achieved without
knowledge IG . strengthened hold worst case regret.
Theorem 6. HAMDP, worst case hence expected regret myopic policy
respect uniform goal distribution bounded log(|G|).
Proof. proof Theorem 5 shows number mispredictions episode bounded
0 ). case 0 = 1/|G| shows worst case regret bound log(|G|).
log(IG
G
immediately implies expected regret bound uniform myopic policy bounded
log(|G|).
3.4 Deterministic Agent Policies
consider several special cases HAMDPs. First, restrict agents policy
deterministic goal, i.e. (s, g) single action state-goal pair (s, g).
Theorem 7. myopic policy achieves optimal expected reward HAMDPs deterministic agent policies.
proof given Appendix. sometimes desirable minimize worst possible regret
compared oracle assistant knows agents goal. show below, captured
graph-theoretic notion tree rank generalizes rank decision trees (Ehrenfeucht &
Haussler, 1989).
Definition 1. rank rooted tree rank root node. node leaf node
rank(node) = 0, else node least two distinct children c1 c2 equal highest ranks
among children, rank(node) = 1+ rank(c1 ). Otherwise rank(node) = rank highest
ranked child.
optimal trajectory tree (OTT) HAMDP deterministic environments tree
nodes represent states HAMDP reached prefixes optimal action sequences
different goals starting initial state.3 node tree represents state set
3. multiple initial states, build OTT initial state. rank would maximum
ranks trees.

81

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

goals optimal path initial state. Since agent policy deterministic,
one trajectory per goal tree. Hence size optimal trajectory tree
bounded number goals times maximum length trajectory,
size state space deterministic domains. following Lemma follows induction
depth optimal trajectory tree. proof Appendix.
Lemma 1. minimum worst-case regret policy HAMDP deterministic environments deterministic agent policies equal tree rank optimal trajectory tree.
leads following.
Theorem 8. agent policy deterministic, problem minimizing maximum regret
HAMDPs deterministic environments P.
Proof. first construct optimal trajectory tree. compute rank linear time
simultaneously computing optimal minimax policy using recursive definition tree rank.
result follows Lemma 1.
3.5 Bounded Branching Factor Policies
assumption deterministic agent policy may restrictive many domains.
consider agent policies may constant number possible actions (s, g)
state-goal pair defined below.
Definition 2. branching factor HAMDP largest number possible actions (s, g)
agent state goal assistants action.
Doorman domain Section 6.1 branching factor 2 since two optimal
actions reach goal state.
Theorem 9. Minimizing worst-case regret finite horizon HAMDPS deterministic environments constant branching factor k NP-complete.
proof appendix. also show minimizing expected regret bounded
k NP-hard. conjecture problem also NP, question remains open.

4. Solving Practical HGMDPs
Although HAMDPs offer theoretically elegant framework, requirements practical assistant
systems easily satisfed assumptions. section, consider general
problem solving HGMDPs offer practical heuristic solutions inspired
theoretical analysis.
principle could use general purpose POMDP solver solve HGMDPs.
POMDP solvers based point-based methods search-based methods become efficient years, still inefficient used interactive setting,
parameters POMDP continually updated. Moreover, analysis previous
section suggests, simple myopic heuristics based knowledge goal distribution
optimal policies given goals appear promising yield respectable performance. reason,
adopt approach based Bayesian goal estimation followed heuristic action selection,
evaluate three different domains. Below, first give overview solution algorithm
describe components detail.
82

fiA ECISION -T HEORETIC ODEL SSISTANCE

4.1 Overview
section, assume given HGMDP , delegating problem learning
Section 5. Let Ot = o1 , ..., ot observation sequence observed assistant
beginning current trajectory time t. observation tuple world state
previously selected action (by either assistant agent). Given Ot goal compute
assistant action whose value (close to) optimal.
motivate approach, useful consider special characteristics HGMDP.
importantly, belief state corresponds distribution agents goal. Since agent
assumed goal directed, observed agent actions provide substantial evidence
goal might might be. fact, even assistant nothing, agents goals
often rapidly revealed analyzing relevance agents initial actions possible
goals. cases, suggests state/goal estimation problem HGMDP may
solved quite effectively observing agents actions relate various possible goals,
rather requiring assistant select actions explicitly purpose information gathering
agents goals. words, cases, expect purely (or nearly) myopic
action selection strategies, avoid reasoning information gathering, effective.
Reasoning information gathering one key complexities involved solving POMDPs
compared MDPs. leverage intuitive properties HGMDP gain tractability
limiting completely avoiding reasoning. course, shown PSPACE-hardness
results, goals always rapidly revealed non-myopic reasoning essential.
note cases, assistant pure information-gathering actions
disposal, e.g. asking agent question. consider actions experiments,
believe actions handled naturally framework incorporating
small amount look-ahead search.
motivation, assistant architecture, depicted Figure 1, alternates
goal estimation action selection follows:
1. observing agents next action, update goal distribution based HGMDP
model.
2. Based updated distribution evaluate effectiveness assistant actions (including
noop) building sparse-sampling look-ahead tree bounded depth (perhaps depth
one), leaves evaluated via myopic heuristic.
key element architecture computation myopic heuristics. top
heuristic, optionally obtain non-myopic behavior via search building look-ahead sparsesampling tree. experiments show search improve performance small margin
significant computational cost. note idea utilizing myopic heuristics select
actions POMDPs new, see example (Cassandra, 1998; Geffner & Bonet, 1998),
similar methods used previously success applications computer bridge
(Ginsberg, 1999). main contribution show approach particularly well
suited setting evaluate efficiently computable heuristics specifically designed
solving HGMDPs. describe goal estimation action selection operations
detail.

83

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Goal Estimation

P(G)

Action Selection

Assistant
Ot



Wt
Environment

User
Ut

Figure 1: Depiction assistant architecture. agent hidden goal selects actions
Ut cause environment change world state Wt , typically moving closer
goal. assistant (upper rectangle) able observe world state along
observations generated environment, setting contain user/agent
actions along world state. assistant divided two components. First,
goal estimation component computes posterior agent goals P (G) given observations. Second, action selection component uses goal distribution compute
best assistive action via combination bounded search myopic heuristic
computation. best action might noop cases none assistive
actions higher utility user.

84

fiA ECISION -T HEORETIC ODEL SSISTANCE

4.2 Goal Estimation
Given HGMDP agent policy initial goal distribution IG , objective maintain
posterior goal distribution P (g|Ot ), gives probability agent goal g
conditioned observation sequence Ot . Note since assumed assistant cannot
affect agents goal, observations related agents actions relevant posterior.
Given agent policy , straightforward incrementally update posterior P (g|Ot ) upon
agents actions.
beginning episode initialize goal distribution P (g|O0 ) IG . timestep
episode, Ot involve agent action, leave distribution unchanged. Otherwise, agent selects action state s, update posterior according P (g|Ot ) =
(1/Z) P (g|Ot1 ) (a|s, g), Z normalizing constant. is, distribution adjusted place weight goals likely cause agent execute action s.
accuracy goal estimation relies well policy learned assistant reflects
true agent policy. described Section 5.2, use model-based bootstrapping approach
estimating update estimate end episode. Provided agent close
optimal, experimental domains, approach lead rapid goal estimation, even early
lifetime assistant.
assumed simplicity actions agent directly observable.
domains, natural assume state world observable, rather
actual action identities. cases, observing agent transitioning s0
use MDP transition function marginalize possible agent actions yielding update,
P (g|Ot ) = (1/Z) P (g|Ot1 )

X

(a|s, g)T (s, a, s0 ).

aA

4.3 Action Selection
Given HGMDP distribution goals P (g|Ot ), address problem
selecting assistive action. mechanisms utilize combination bounded look-ahead search
myopic heuristic computations. increasing amount look-ahead search actions
returned closer optimal cost computation. Fortunately, many HGMDPs,
useful assistant actions computed relatively little search. first describe several
myopic heuristics used either greedy action selection combination search.
Next, review utilize sparse sampling obtain non-myopic action selection.
4.3.1 ACTION ELECTION H EURISTICS
explain action selection procedure, introduce idea assistant MDP relative
goal g , denote (g). MDP (g) identical except
change initial goal distribution P (G0 = g) = 1. is, goal always fixed g
episode. Since hidden component state space goal, fixing goal
(g) makes state fully observable, yielding MDP. episode (g) evolves drawing
initial world state selecting assistant actions goal g achieved. Note
state transition assistant action a0 state result successive state transitions, first
due assistant action due ensuing agent action, selected based
agent policy goal g. optimal policy (g) gives optimal assistive action assuming
85

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

agent acting achieve goal g. denote Q-function (g) Qg (s, a),
expected cost executing action state following optimal policy.
consider second heuristic action selection, accounts non-uniform rewards true goal posterior, unlike coarsened posterior heuristic introduced Section 3.3.
simply expected Q-value action assistant MDPs, also called QMDP
method Cassandra (1998). heuristic value assistant action state given observations
Ot
X
Qg (s, a) P (g|Ot ).
H(s, a, Ot ) =
g

Intuitively H(s, a, Ot ) measures utility taking action assumption
goal ambiguity resolved one step. Thus, heuristic value information-gathering
utility action. Rather, heuristic favor assistant actions make progress toward goals
high posterior probability. goal posterior highly ambiguous often lead
assistant prefer noop, least hurt progress toward goal. Note
heuristic, well others below, used evaluate utility state s, rather
state-action pair, maximizing actions maxa H(s, a, Ot ).
primary computational complexity computing H solve assistant MDPs
goal order obtain Q-functions. Technically, since transition functions assistant
MDPs depend approximate agent policy , must re-solve MDP updating
estimate end episode (see Section 5.2 policy learning). However, using incremental dynamic programming methods prioritized sweeping (Moore & Atkeson, 1993)
alleviate much computational cost. particular, deploying assistant solve
MDP offline based default agent policy given Boltzmann bootstrapping distribution describe Section 5.2. deployment, prioritized sweeping used incrementally
update Q-values based learned refinements make .
practical exactly solve assistant MDPs, may resort various approximations. consider two approximations experiments. One replace users policy
used computing assistant MDP fixed default user policy, eliminating need
compute assistant MDP every step. denote approximation Hd . Another approximation uses simulation technique policy rollout (Bertsekas & Tsitsiklis, 1996) approximate
Qg (s, a) expression H. done first simulating effect taking action
state using estimate expected cost agent achieve g resulting
state. is, approximate Qg (s, a) assuming assistant select single
initial action followed agent actions. formally, let Cn (, s, g) function simulates n trajectories achieving goal state averaging trajectory costs.

H(s, a, Ot ) except replace Qg (s, a) expectation
P heuristic H0r identical
0
s0 (s, a, ) C(, , g). also combine heuristics, using fixed default
user policy policy rollouts, denote Hd,r .
4.3.2 PARSE AMPLING
heuristics somewhat myopic sense take account
potentially persistent ambiguity agents goal consider use information
gathering actions resolve ambiguity. cases beneficial consider nonmyopic reasoning, one combine heuristics shallow search belief space

86

fiA ECISION -T HEORETIC ODEL SSISTANCE

assistant MDP. purpose utilize depth bounded sparse sampling trees (Kearns,
Mansour, & Ng, 1999) compute approximation Q-function given belief state
(st , Ot ), denoted Qd (st , a, Ot ). Given particular belief state, assistant select
action maximizes Qd . Note convenience represent belief state pair
current state st observation history Ot . lossless representation belief state since
posterior goal distribution computed exactly Ot goal hidden
portion POMDP state.
base case Q0 (st , a, Ot ) equal one myopic heuristics described above.
Increasing depth result looking ahead state transitions evaluating one
heuristics. looking ahead possible track potential changes belief state
taking certain actions determine whether changes belief would beneficial
respect providing better assistance. Sparse sampling look-ahead approximately
computing:
Qd (s, a, O) = E[R(s, g, a) + V d1 (s0 , O0 )]




V (s, O) = max Q (s, a, O)


(1)
(2)

g random variable distributed according goal posterior P (g|O) (s0 , O0 )
random variable represents belief state taking action belief state (s, O).
particular, s0 world state arrived O0 simply observation sequence extended
observation obtained state transition. first term expectation
represents immediate reward assistant action goal g.
Sparse sampling approximates expectation averaging set b samples successor belief states. sparse-sampling pseudo-code presented Table 4.3.2. Given input belief
state (s, O), assistant action a, heuristic H, depth bound d, sampling width b algorithm returns (an approximation of) Qd (s, a, O). First, depth bound equal zero heuristic
value returned. Otherwise b samples observations resulting taking action belief state
(s, O) generated. observations form oi = (s0i , ai , si ), s0i state
resulting taking action state s, ai ensuing agent action selected s0i based goal
drawn goal posterior, si result taking action ai state s0i . observation oi
corresponds new belief state (si , [O; oi ]) [O; oi ] simply concatenation oi O.
code recursively computes value belief states maximizing Qd
actions averages results.
b become large, sparse sampling produce arbitrarily close approximation
true Q-function belief state MDP. computational complexity sparse sampling linear
b exponential d. Thus depth must kept small real-time operation.

5. Learning HGMDPs
section, tackle problem learning HGMDP interacting environment assist agent. assume set goals G known agent. primary
role learning acquire agents policy goal distribution. assumption natural
situations assistant applied many times environment, possibly
different agents. example, desktop environment, environment MDP corresponds
description various desktop functionalities, remains fixed across users. one
87

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Given: heuristic function H, belief state (s, O), action a, depth bound d, sampling width b
Return: approximation Qd (s, a, O) value belief state (s, O)
1. = 0 return H(s, a, O)
2. Sample set b observations {o1 , . . . , ob } resulting taking action
belief state (s, O) follows:
(a) Sample s0i environment MDP transition function (s, a, )
(b) Sample goal gi P (gi |O)
(c) Sample agent action ai agent policy (|s0i , gi )
(d) oi = (s0i , ai , si ), si sample environment MDP transition
function (s0i , ai , )
3. oi = (s0i , gi , ai , si ) compute Vi = maxa0 Qd1 (si , a0 , [O; oi ])
P
4. Return Qd (s, a, O) = 1b R(s, gi , a) + Vi

Table 1: Pseudo-code Sparse Sampling HGMDP
provided description MDP typically straightforward learn model
primary cost longer warming period assistant.
Relaxing assumption provided set possible goals problematic
current framework. saw Section 4, solution methods depend knowing set
goals clear learn observations, since goals, unlike states
actions, directly observable assistant. Extending framework assistant
automatically infer set possible user goals, allow user define goals,
interesting future direction. note, however, often possible designer enumerate
set user goals deployment perhaps complete, allows useful assistance
provided.
5.1 Maximum Likelihood Estimates
straightforward estimate goal distribution G0 agent policy simply observing
agents actions, possibly assisted, compute empirical estimates relevant
quantities. done storing goal achieved end episode along
set world state-action pairs observed agent episode. estimate IG
based observed frequency goal (usually Laplace correction avoid
extreme values probabilities). Likewise, estimate (a|s, g) simply frequency
action taken agent state goal g. limit
maximum likelihood estimates converge correct values true HGMDP, practice
convergence slow. slow convergence lead poor performance early stages
assistants lifetime. alleviate problem propose approach bootstrapping
learning agent policy .
88

fiA ECISION -T HEORETIC ODEL SSISTANCE

5.2 Model-Based Bootstrapping
leverage environment MDP model order bootstrap learning agent policy.
particular, assume agent near optimal sense that, particular goal
world state, likely select actions close optimal. unrealistic
many application domains might benefit intelligent assistants. particular,
many tasks, conceptually simple humans, yet quite tedious, e.g., navigating
directory structure computer desktop. Performing optimally tasks difficult
humans.
Given near rationality assumption, initialize estimate agents policy
prior biased toward optimal agent actions. consider environment MDP
assistant actions removed solve Q-function Q(a, s, g) using MDP planning
techniques. Q-function gives expected cost executing agent action world state
acting optimally achieve goal g using agent actions. world without assistant,
rational agent would always select actions maximize Q-function state goal.
Furthermore, close-to-rational agent would prefer actions achieve higher Q-values highly
suboptimal actions. first define Boltzmann distribution, used define
prior,
1
(a|s, g) =
exp(K Q(a, s, g))
(3)
Z(s, g)
Z(s, g) normalizing constant, K temperature constant. Using larger values
K skews distribution heavily toward optimal actions. Given definition, prior
distribution (|w, g) taken Dirichlet parameters (1 , . . . , |A| ), =
0 (ai |s, g). 0 parameter controls strength prior. Intuitively 0
thought number pseudo-actions represented prior, representing
number pseudo-actions involved agent action ai . Since Dirichlet conjugate
multinomial distribution, form (|s, g), easy update posterior
(|s, g) observation. One take mode mean posterior point
estimate agent policy used define HGMDP.
experiments, found prior provides good initial proxy actual agent
policy, allowing assistant immediately useful. updating posterior tunes
assistant better peculiarities given agent. example, many cases
multiple optimal actions posterior come reflect systematic bias among equally
good actions agent has. Computationally main obstacle approach computing
Q-function, needs done given application domain since environment
MDP constant. Using dynamic programming accomplished polynomial time
number states goals. practical, number alternatives exist including
use factored MDP algorithms (Boutilier et al., 1999), approximate solution methods (Boutilier
et al., 1999; Guestrin et al., 2003), developing domain specific solutions.
Finally, work, utilize uninformative prior goal distribution. interesting
future direction would bootstrap goal distribution estimate based observations
population agents.

89

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

6. Experimental Results
section, present results conducting user studies simulations three domains:
two game-like environments folder predictor domain intelligent desktop assistant.
user studies two game-like domains, episode, users assistants actions
recorded. user studies performed using 12 human subjects (graduate students CS
department Oregon State University) single session. ratio cost achieving
goal assistants help optimal cost without assistant calculated averaged
multiple trials user. present similar results simulations well. third
domain folder predictor domain, simulated user used one heuristics
generate top 3 recommended folders user. present number clicks required
average user reach desired folder. Two three domains, namely, doorman
domain folder predictor domain, fall category HAMDPs since assistive
actions merely viewed helper actions agent ignore. kitchen domain
hand needs slightly general formulation since agent assistant
strictly alternate, assistants actions cannot ignored agent.
6.1 Doorman Domain
doorman domain, agent set possible goals collect wood, food
gold. grid cells blocked. cell four doors agent open
door move next cell (see Figure 2). door closes one time-step time
one door open. goal assistant help user reach goal faster opening
correct doors.
state tuple hs, di, stands agents cell door open.
total number states 245 (49 squares 5 possibilities door). actions agent
open door move 4 directions pickup whatever cell,
total 9 actions. assistant open doors perform noop (5 actions. agents
assistants actions strictly alternate domain, satisfying definition HAMDPs.
reward 1 (or cost 1) user open door reward assistants
action. trial ends agent picks desired object. Note included
noop action assistant, domain action never selected, since cost opening
wrong door noop same, potential benefit selecting noop.
experiment, evaluated two heuristics: one fixed user policy default
policy HGMDP creation (Hd ) avoiding need repeated computation HGMDP
every step second use policy rollout calculate Q-values (Hr ).
trial, system chooses goal one two heuristics random. user shown
goal tries achieve it, always starting center square. every users action,
assistant opens door nothing. user may pass door open different door.
user achieves goal, trial ends, new one begins. assistant uses
users trajectory update agents policy.
results user studies doorman domain presented Tabe 2. first two
rows give cumulative results user study actions selected greedily according Hr
Hd respectively. Rather reporting negtive rewards, table shows total number

90

fiA ECISION -T HEORETIC ODEL SSISTANCE

Figure 2: Doorman Domain. agents goal fetch resource. grid cells separated
doors must opened passing through.

actions trials across users without assistant N, total number actions
assistant U, average percentage savings (1-(U/N)) trials users.4
seen, methods reduce number actions 50%. Note
assistant selects among four doors random would reduce number actions
25% comparison. omniscient assistant knows users goal reduces number
actions 78%. 100% first door always opened user.
experiments, count users first action, number actions reduces 65%.5
observed Hr appears slight edge Hd . One possible reason
using Hd , re-solve MDP updating user policy, Hr always
using updated user policy. Thus, rollout reasoning accurate model user.
Heuristic
Hr
Hd
Hr
= 2, b = 1
= 2, b = 2
= 3, b = 1
= 3, b = 2

Total
Actions
N
750
882
1550
1337
1304
1167
1113

User
Actions
U
339
435
751
570
521
467
422

Fractional Savings
1 (U/N )
0.55 0.055
0.51 0.05
0.543 0.17
0.588 0.17
0.597 0.17
0.6 0.15
0.623 0.15

Time
per
action (in secs
0.0562
0.0021
0.031
0.097
0.35
0.384
2.61

Table 2: Results experiments Doorman Domain. first two rows table present
results user studies rest table presents results simulation.

4. gives pessimistic estimate usefulness assistant assuming optimal user measure utility
normalized optimal utility without aid assistant.
5. Note first action requirement easily aviodable. simply equivalent switch indicate
user ready move grid. also replace requirement explicitly adding button
interface start new episode.

91

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Another interesting observation individual differences among users.
users always prefer fixed path goal regardless assistants actions. users
flexible. survey conducted end experiment, learned one
features users liked system tolerant choice suboptimal paths.
data reveals system able reduce costs approximately 50% even
users chose suboptimal trajectories.
also conducted experiments using sparse sampling non-zero depths. considered
depths = 1 = 2 using sampling widths b = 1 b = 2. leaves sparse
sampling tree evaluated using Hr simply applies rollout user policy. Hence sparse
sampling = 0 b = 1, would correspond heuristic Hr . experiments,
conduct user studies, due high cost effort required humans studies,
simulated human users choosing actions according policies learned observed
actions previous user study. results presented last 5 rows Table 2. Note
absolute numbers actions user studies simulations comparable
based different numbers trajectories. human users tested fewer trajectories
minimize fatigue. see sparse sampling increased average run time (last column)
order magnitude, able produce reduction average cost user. result
surprising hindsight, simulated experiments, sparse sampling able sample
exact user policy (i.e. sampling learned policy, also used
simulations). results suggest small amount non-myopic reasoning
positive benefit substantial computation cost. Note, however, bulk benefit
realized assistant obtained without reasoning, showing myopic heuristics
well-suited domain.
6.2 Kitchen Domain
kitchen domain, goals agent cook various dishes. 2 shelves
3 ingredients each. dish recipe, represented partially ordered plan. ingredients
fetched order, mixed heated. shelves doors
must opened fetching ingredients one door open time.
8 different recipes. state consists location ingredients
(bowl/shelf/table), mixing state temperature state ingredient (if bowl)
door open. state also includes action history preserve ordering
plans recipes. users actions are: open doors, fetch ingredients, pour
bowl, mix, heat bake contents bowl, replace ingredient back shelf.
assistant perform user actions except pouring ingredients replacing ingredient
back shelf. restricted assistant pouring ingredients irreversible action. reward non-pour actions -1. Experiments conducted 12 human subjects
computer science graduate students. Unlike doorman domain, allowed
assistant take multiple consecutive actions. turn switches user assistant
executes noop action.
domain large state space hence possible update user policy
every trajectory. Hence, two heuristics compare use default user policy.
second heuristic addition uses policy rollout compare actions. words, compare
Hd Hd,r . results user studies shown top part Table 3. doorman

92

fiA ECISION -T HEORETIC ODEL SSISTANCE

Figure 3: kitchen domain. user prepare dishes described recipes
right. assistants actions shown bottom frame.

domain, total number agent actions without assistant, percentage reduction due assistant presented. number user actions summed 12 users
cumulative results presented. observed Hd,r performs better Hd .
observed experiments Hd,r technique aggressive choosing non-noop
actions Hd , would wait goal distribution highly skewed toward particular
goal.
Heuristic
Hd,r
Hd
Hd,r
= 2, b = 1
= 2, b = 2
= 3, b = 1
= 3, b = 2

Total
Actions
N
3188
3175
6498
6532
6477
6536
6585

User
Actions
U
1175
1458
2332
2427
2293
2458
2408

Fractional Savings
1 (U/N )
0.6361 0.15
0.5371 0.10
0.6379 0.14
0.6277 0.14
0.646 0.14
0.6263 0.15
0.645 0.14

Time
per
action (secs)
0.013
0.013
0.013
0.054
0.190
0.170
0.995

Table 3: Results experiments Kitchen Domain. first two rows table present
results user studies last 5 rows present results simulation.

compared use sparse sampling heuristic simulated user trajectories
domain well (see last 5 rows Table 3). Again, absolute numbers actions
user studies comparable simuations due different numbers trajectories
case. Since sparse sampling considers larger number trajectories methods,
policies learned sometimes better learned heuristics, although took
time execute. However, significant difference solution quality
rollouts sparse sampling simulations, showing myopic heuristics performing
93

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

well sparse sampling much less computation. Sparse sampling higher depths requires
order magnitude computation time compared rollout.
6.3 Folder Predictor
section, present evaluation framework real-world domain. part
Task Tracer project (Dragunov, Dietterich, Johnsrude, McLaughlin, Li, & Herlocker, 2005),
researchers developed file location system called folder predictor (Bao et al., 2006). idea
behind folder predictor learning users file access patterns, assistant
help user file accesses predicting folder file accessed
saved.
setting, goal folder predictor minimize number clicks user.
predictor would choose top three folders would minimize cost append
UI (shown ovals Figure 4). Also, user taken first recommended folder.
users target folder first recommended folder, user would reach folder zero clicks
reach second third recommended folder one click. user either choose one
recommendations navigate windows folder hierarchy recommendations
relevant.

Figure 4: Folder predictor (Bao et al., 2006).
Bao et al. considered problem supervised learning problem implemented costsensitive algorithm predictions cost number clicks user (Bao
et al., 2006). But, algorithm take account response user
predictions. instance, user chooses ignore recommended folders navigates
folder hierarchy, make re-predictions. due fact model
one-time prediction consider user responses. Also, algorithm considers
restricted set previously accessed folders ancestors possible destinations.
precludes handling possibility user accessing new folder.
decision-theoretic model naturally handles case re-predictions changing recommendations response user actions. first step, used data collected
user interface used model make predictions. use users response predic94

fiA ECISION -T HEORETIC ODEL SSISTANCE

tions make predictions. Also, handle possibility new folder, consider
folders folder hierarchies prediction. used mixture density obtain
probability distribution folders.
P (f ) = 0 P0 (f ) + (1 0 )Pl (f )
P0 probability according Bao et.als algorithm (2006), Pl uniform probability distribution set folders 0 ratio number times previously accessed
folder accessed total number folder accesses.
idea behind using density function early stages task, user
accessing new folders later stages user access folders particular task
hierarchy. Hence number folder accesses increases value 0 increases would
eventually converge 1, hence resulting distribution would converge P0 . data set
consists collection requests open file (Open) save file (saveAs), ordered time.
request contains information as, type request (open saveAs), current task,
destination folder, etc. data set consists total 810 open/saveAs requests. folder
hierarchy consists 226 folders.
state space consists 4 parts: current folder user accessing three
recommendations two unordered. would correspond state space size
226 225 224
2 . action user either choose recommended folder select
different folder. action assistant corresponds choosing top 3 folders
action space size 225 224
2 . reward case negative number user
clicks. domain, assistant users actions strictly alternate assistant revises
predictions every user action. prior distribution initialized using rewards computed
model developed Bao et al. (2006).
applied decision theoretic model data set. request, assistant would
make prediction using Hd,r heuristic (which uses default user policy rollout
method) user simulated. user would accept recommendation shortens
path goal, otherwise would act according optimal policy. user
considered close optimal, unrealistic real world. compare results,
also used model developed Bao et al. data set present results Table 4.
Restricted folder set
Folders

One-time Prediction
1.3724
1.319

Repredictions
1.34
1.2344

Table 4: Results experiments folder predictor domain. numbers indicate average number clicks required agent reach his/her correct folder. entry
top left hand cell performance current Task Tracer, one
bottom right hand cell performance decision-theoretic assistant.

table shows average cost folder navigation 4 different cases: Bao et.als original
algorithm, algorithm modified include mixture distributions model without
mixture distributions. seen model use mixture distributions
least user cost navigation hence effective. Bao et. al shown
95

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

algorithm performs significantly better windows default prediction average
2.6 clicks per folder navigation. improvement attributed two modifications
mentioned earlier. First, use re-predictions model natural decisiontheoretic framework model makes one-time prediction hence cannot make use
users response recommendations. Secondly, considering folders hierarchy
prediction including possibility user accessing new folder found useful.
observed either modifications yields lower cost original algorithm,
combining two changes significantly effective.

7. Discussion Related Work
work inspired growing interest success building useful software assistants
(Yorke-Smith et al., 2012; Lieberman, 2009; Myers et al., 2007). effort focused
building desktop assistants help tasks calendar scheduling (Refanidis, Alexiadis, & Yorke-Smith, 2011), email filtering (Cohen, Carvalho, & Mitchell, 2004), on-line diagnostics (Skaanning, Jensen, & Kjaerulff, 2000), travel planning (Ambite, Barish, Knoblock,
Muslea, Oh, & Minton, 2002). tasks typically requires designing software system
around specialized technologies algorithms. example, email filtering typically posed
supervised learning problem (Cohen et al., 2004), travel planning combines information gathering
search constraint propagation (Ambite et al., 2002), printer diagnostics formulated
Bayesian network inference (Skaanning et al., 2000). approaches focus socially assistive robots setting robot designed aid human agents achieving goals (Johnson,
Cuijpers, Juol, Torta, Simonov, Frisiello, Bazzani, Yan, Weber, Wermter, et al., 2013). Unfortunately plethora systems approaches lacks overarching conceptual framework,
makes difficult build others work. paper, argue decision-theoretic
approach provides common framework allows design systems respond
novel situations flexible manner reducing need pre-programmed behaviors. formulate general version assistantship problem involves inferring users goals taking
actions minimize expected costs.
Earlier work learning apprentice systems focused learning users observation (Mahadevan, Mitchell, Mostow, Steinberg, & Tadepalli, 1993; Mitchell, Caruana, Freitag,
J.McDermott, & Zabowski, 1994). work also closely related learning demonstration
programming demonstration (Johnson, 2014; Konidaris, Kuindersma, Grupen, & Barto, 2012;
Atkeson & Schaal, 1997; Cypher, 1993; Lau, Wolfman, Domingos, & Weld, 2003). emphasis
systems provide interface computer system unobtrusively observe
human user task learn itself. human acts user teacher.
performance system measured quickly system learns imitate user,
i.e., supervised learning setting. Note imitation assistance two different things
general. expect secretaries learn us, typically expected replace
us. setting, assistants goal reduce expected cost users problem solving.
user assistant capable exactly set actions, assistants actions cost
nothing compared users, makes sense assistant try completely replace
human. Even case, assistantship framework different learning demonstration
still requires assistant infer users goal actions trying achieve
it. Moreover, assistant might learn solve goal reasoning action set

96

fiA ECISION -T HEORETIC ODEL SSISTANCE

rather shown examples user. general, however, action
set user assistant may different, supervised learning appropriate.
example, case folder predictor. system needs decide set folders
present user, user needs decide choose. awkward
impossible formulate problem supervised learning programming demonstration.
Taking decision-theoretic view helps us approach assistantship problem principled
manner taking account uncertainty users goals costs taking different
actions. assistant chooses action whose expected cost lowest. framework naturally
prevents assistant taking actions (other noop) assistive action
expected reduce overall cost user. Rather learning user behave,
framework assistant learns users policy. similar secretary learns
habits boss, much imitate her, help effective way. work
assumed user MDP small enough solved exactly given users goals.
assumption may always valid, makes sense cases learn user
behave. natural treat case users actions provide exploratory
guidance system (Clouse & Utgoff, 1992; Driessens, 2002). gives opportunity
system imitate user knows nothing better improve upon users policy
can.
personal assistant systems based POMDP models. However,
systems formulated domain-specific POMDPs solved offline. instance,
COACH system helped people suffering dementia giving appropriate prompts
needed daily activities (Boger, Poupart, Hoey, Boutilier, Fernie, & Mihailidis, 2005).
use plan graph keep track users progress estimate users responsiveness
determine best prompting strategy. distinct difference approach
single fixed goal washing hands, hidden variable user responsiveness
either low high. Rather, formulation goal random variable hidden
assistant. Since state-action space significantly smaller (1280 2 108 states
folder predictor domain), possible solve POMDP exactly. Given need
re-solve POMDP every user action, becomes prohibitively expensive. Yet another
difference length trajectory goal small case hence plan graph
would suffice capture user policy. model, restrict plan graph instead
solve user MDP bootstrap policy. mentioned learning user policy
future direction. work, even though start initial estimate user policy,
update every goal achieved. considered online learning user policy
reasonably good prior. note combination two frameworks (one modeling
users responsiveness modeling users goal) would useful, assistant
infers agent goals relevant hidden properties user, responsiveness.
Electric Elves, assistant takes many mundane responsibilities human
agent including rescheduling meeting appear user likely miss it.
domain-specific POMDP formulated solved offline using variety techniques. one
approach, since system monitors users short regular intervals, radical changes belief
states usually possible pruned search space (Varakantham, Maheswaran,
& Tambe, 2005). Neither exact approximate POMDP solvers feasible online setting,
POMDP changing learn user, must repeatedly solved.
either costly run (Boger et al., 2005), complex implement baseline, e.g., Electric
97

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Elves (Varakantham et al., 2005). experiments demonstrate simple methods onestep look-ahead followed rollouts would work well many domains POMDPs
solved online. distinct related work (Doshi & Gmytrasiewicz, 2004), authors introduce
setting interactive POMDPs, agent models agents beliefs. Clearly,
general complex ordinary POMDPs. model simpler assumes
agent oblivious presence beliefs assistant. simplified model suffices
many domains, relaxing assumption without sacrificing tractability would interesting.
several dialogue systems proposed many based decisiontheoretic principles (Walker, 2000; Singh, Litman, Kearns, & Walker, 2002). instance,
NJFun system designed MDP provide assistance user interacting user
providing answer users questions. uses automatic speech recognizer (ASR)
interpret human dialogues uses dialogue policy choose best action (the response).
goals user could set standard queries locations restaurants, wineries,
shopping centers etc. state space would dialogue states, i.e., current state
dialogue user assistant (such greeting, choice state etc). observations
interpretations dialogues human ASR. NJFun system usefully
modeled HGMDP, goal assistant infer users query given observations provide appropriate response. initial assistant policy learned training
data, manner similar dialogue policy NJFun system.
work also related on-line plan recognition naturally extended include
hierarchies hierarchical versions HMMs (Bui, Venkatesh, & West, 2002) PCFGs
(Pynadath & Wellman, 2000). Blaylock Allen describe statistical approach goal recognition
uses maximum likelihood estimates goal schemas parameters (Blaylock & Allen, 2004).
approaches notion cost reward. incorporating plan recognition
decision-theoretic context, obtain natural notion optimal assistance, namely maximizing
expected utility.
substantial research area user modeling. Horvitz et al. took Bayesian
approach model whether user needs assistance based actions attributes provided
assistance needed spreadsheet application (Horvitz et al., 1998). Hui Boutilier used
similar idea assistance text editing (Hui & Boutilier, 2006). use DBNs handcoded
parameters infer type user compute expected utility assisting user.
would interesting explore use ideas plan recognition (Charniak & Goldman, 2013;
Gal, Reddy, Shieber, Rubin, & Grosz, 2012; Chu, Song, Kautz, & Levinson, 2011) system
take account users intentions attitudes computing optimal policy
assistant.
Recently, methods proposed solving POMDPs called point based methods (Pineau, Gordon, & Thrun, 2003; Porta, Vlassis, Spaan, & Poupart, 2006; Kurniawati, Hsu,
& Lee, 2008; Shani, Pineau, & Kaplow, 2013). example method point based value
iteration (PBVI) (Pineau et al., 2003; Porta et al., 2006) takes set belief points B input
maintains set POMDP -vectors iteration. iteration produces new set vectors optimal belief point respect -vectors previous iteration.
approximation made PBVI compared value iteration guarantee
set -vectors optimal entire belief space. omitting -vectors, PBVI
maintains constant run time per iteration. Application efficient point based methods

98

fiA ECISION -T HEORETIC ODEL SSISTANCE

PBVI decision-theoretic assistance problem evaluation performance compared
policy rollout sparse sampling methods remains promising research direction.

8. Summary Future Work
introduced decision-theoretic framework assistant systems described HGMDP
appropriate model selecting assistive actions. computational complexity HGMDPs
motivated definition simpler model called HAMDP, allows efficient myopic heurstics
tractable special cases.
also described approximate solution approach based iteratively estimating agents
goal selecting actions using myopic heuristics. evaluation using human subjects two
game-like domains show approach significantly help user. also demonstrated
real world folder predictor decision-theoretic framework effective state
art techniques folder prediction.
One future direction consider complex domains assistant able series activities parallel agent. Another possible direction assume hierarchical goal
structure user goal estimation context. Recently, assistantship model
extended hierarchical relational settings (Natarajan et al., 2007) including parameterized
task hierarchies conditional relational influences prior knowledge assistant. prior
knowledge would relax assumption user MDP solved tractably. knowledge
compiled underlying Dynamic Bayesian network, Bayesian network inference algorithms used infer distribution users goals given sequence atomic actions.
parameters users policy estimated observing users actions.
framework naturally extended case environment partially observable agent and/or assistant. requires recognizing actions taken gather
information, e.g., opening fridge decide make based available. Incorporating sophisticated user modeling includes users forgetting goals, paying attention
important detail, and/or changing intentions would extremely important building
practical systems. assistive technology also useful assistant quickly learn
new tasks expert users transfer knowledge novice users training.

Acknowledgements
material based upon work supported Defense Advanced Research Projects Agency
(DARPA), Department Interior, NBC, Acquisition Services Division, Contract No. NBCHD030010. opinions, findings, conclusions recommendations expressed
material authors necessarily reflect views DARPA. Alan
Fern Prasad Tadepalli gratefully acknowledge following grants: NSF IIS-0964705 ONR
N00014-11-1-0106. Sriraam Natarajan thanks Army Research Office grant number W911NF-13-10432 Young Investigator Program.

Appendix A. Proof Theorem 7
According theory POMDPs, optimal action POMDP maximizes sum
immediate expected reward value resulting belief state (of assistant) (Kaelbling,

99

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Littman, & Cassandra, 1998). agent policy deterministic, initial goal distribution
IG history agent actions states H fully captures belief state agent. Let
V (IG , H) represent value current belief state. value function belief state
given following Bellman equation, H 0 stands history assistants
action hi agents action aj .
V (IG , H) = max E(R((s, hi ), g, aj )) + V (IG , H 0 )
hi

H0

(4)

Since one agents action (s, g), agent action aj , subsequent state s0
value depend hi . Hence best helper action h assistant given by:
h (IG , H) = arg max E(R((s, hi ), g, (s, g)))
hi
X
= arg max
IG (g)I(ai (s, g))
hi

gC(H)

= arg max IG (C(H) G(s, ai ))
hi

C(H) set goals consistent current history H, G(s, ai ) set goals
ai good state s. I(ai (s, g)) indicator function = 1 ai (s, g).
Note h exactly myopic policy. 2

Appendix B. Proof Lemma 1
worst-case regret pair (s, G) HAMDP given following Bellman equation.
assuming G set possible goals agent current state s. Regret(s, G) = 0
terminal state goals G satisfied s. Otherwise, Regret(s, G) = mini maxj6=i
{Regret(si , Gi ), 1 + Regret(sj , Gj ))} (si , Gi ) (sj , Gj ) Children((s, G)).
outer min due assistant picking helper action goal Gi maximize
reward inner max due agent either accepting it, picking different goal
minimize reward. proof induction. node trajectory tree represents state
set goals G state optimal path.
Basis: (s, G) leaf node, either terminal state goals G satisfied s. Hence
rank equals reward 0.
Inductive step: Suppose induction true children (s, G). consider two
cases.
Case 1. unique child (s, G) representing (s1 , G1 ) highest regret among
children. inductive hypothesis, rank((s1 , G1 )) = regret(s1 , G1 ). assistant chooses
helper action corresponds (s1 , G1 ), agent choose actions yield lower
regret worst case. Choosing helper action would increase regret, since
agent could choose a1 add 1 regret. have, regret(s, G)= regret(s1 , G1 ) =
rank((s1 , G1 )) = rank((s, G)).
Case 2. least two children (s1 , G1 ) (s2 , G2 ) (s, G) highest rank
among children. inductive hypothesis, rank((s1 , G1 )) = rank((s2 , G2 )) = regret(s1 , G1 )
= regret(s2 , G2 ). agent increase regret 1 choosing goal G2
assistant chooses G1 vice versa. Hence, regret(s, G)= 1+regret(s1 , G1 ) = 1+rank((s1 , G1 )) =
100

fiA ECISION -T HEORETIC ODEL SSISTANCE

rank((s, G)).
Hence cases, shown regret(s, G) rank((s, G)). 2

Appendix C. Proof Theorem 9
first show problem NP. build tree representation history-dependent policy
initial state. Every node tree represeted triple (s, i, G), state,
G set goals good path, index helper action chosen
policy node. root node corresponds possible initial state initial goal
set IG . children node tree represent possible successor nodes (sj , j, Gj ) reached
agents response hi , whether accepting hi executing ai executing actions.
children resulting ai called accepted, latter called rejected. Note
multiple children result action dynamics function agents
goal.
guess policy tree check maximum regret, i.e. maximum number
rejected children path root leaf, within bounds. verify optimal
policy tree polynomial size note number leaf nodes upper bounded |G|
maxg N (g), N (g) number leaf nodes generated goal g. estimate N (g),
start root navigate downwards. node contains g goal set,
accepted child contains g, child reached g. not,
misprediction k children reached. Hence, number nodes reached g
grows geometrically number mispredictions. Theorem 6, since
log |G| mispredictions path, N (g) k log2 |G| = k logk |G| log2 k = |G|log2 k . Hence
total number leaf nodes tree bounded |G|1+log k , total number nodes
tree bounded m|G|1+log k , number steps horizon. Since
polynomial problem parameters, problem NP.
show NP-hardness, reduce 3-SAT given problem. consider 3-literal clause
Ci propositional formula possible goal. rest proof identical
Theorem 1 except variables set assistant since universal quantifiers.
agent rejects setting last variable clause clause evaluates 0.
worst regret goal 0 iff 3-SAT problem satisfying assignment. 2

References
Ambite, J. L., Barish, G., Knoblock, C. A., Muslea, M., Oh, J., & Minton, S. (2002). Getting
there: Interactive planning agent execution optimizing travel. Proceedings
Fourteenth Conference Innovative Applications Artificial Intelligence, pp. 862
869.
Atkeson, C. G., & Schaal, S. (1997). Learning tasks single demonstration. Proceedings
IEEE International Conference Robotics Automation, pp. 17061712.
Bao, X., Herlocker, J. L., & Dietterich, T. G. (2006). Fewer clicks less frustration: reducing
cost reaching right folder. Proceedings Eleventh International Conference
Intelligent User Interfaces, pp. 178185.
Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.

101

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Blaylock, N., & Allen, J. F. (2004). Statistical goal parameter recognition. Proceedings
Fourteenth International Conference Automated Planning Scheduling, pp. 297305.
Boger, J., Poupart, P., Hoey, J., Boutilier, C., Fernie, G., & Mihailidis, A. (2005). decisiontheoretic approach task assistance persons dementia. Proceedings Nineteenth International Joint Conference Artificial Intelligence, pp. 12931299.
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions
computational leverage. Journal Artificial Intelligence Research, 11, 194.
Bui, H., Venkatesh, S., & West, G. (2002). Policy recognition abstract hidden markov models.
Journal Artificial Intelligence Research, 17, 451499.
Cassandra, A. R. (1998). Exact approximate algorithms partially observable Markov decision processes. Ph.D. thesis, Brown University.
Charniak, E., & Goldman, R. (2013). Plan recognition stories life. CoRR, abs/1304.1497.
Chu, Y., Song, Y., Kautz, H., & Levinson, R. (2011). start thing
do? interactive activity recognition prompting. Proceedings Twenty-Fifth AAAI
Conference Workshop Artificial Intelligence Smarter Living, pp. 1521.
Clouse, J. A., & Utgoff, P. E. (1992). teaching method reinforcement learning. Proceedings
Ninth International Workshop Machine Learning, pp. 92110.
Cohen, W. W., Carvalho, V. R., & Mitchell, T. M. (2004). Learning classify email speech acts.
Proceedings Conference Empirical Methods Natural Language Processing, pp.
309316.
Cypher, A. (1993). Watch Do: Programming Demonstration. MIT Press.
Doshi, P., & Gmytrasiewicz, P. (2004). particle filtering algorithm interactive POMDPs.
Proceedings Workshop Modeling Agents Observations, pp. 8793.
Dragunov, A. N., Dietterich, T. G., Johnsrude, K., McLaughlin, M., Li, L., & Herlocker, J. L. (2005).
Tasktracer: desktop environment support multi-tasking knowledge workers. Proceedings Tenth International Conference Intelligent User Interfaces, pp. 7582.
Driessens, K. (2002). Adding guidance relational reinforcement learning. Third FreiburgLeuven Workshop Machine Learning.
Ehrenfeucht, A., & Haussler, D. (1989). Learning decision trees random examples. Information Computation, 82(3), 231246.
Gal, Y., Reddy, S., Shieber, S., Rubin, A., & Grosz, B. (2012). Plan recognition exploratory
domains. Artificial Intelligence, 176(1), 22702290.
Geffner, H., & Bonet, B. (1998). Solving large POMDPs using real time dynamic programming.
Proceedings AAAI Fall Symposium POMPDs.
Ginsberg, M. L. (1999). GIB: Steps Toward Expert-Level Bridge-Playing Program. Proceedings Sixteenth International Joint Conference Artificial Intelligence, pp. 584589.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
factored MDPs. Journal Artificial Intelligence Research, 19, 399468.

102

fiA ECISION -T HEORETIC ODEL SSISTANCE

Horvitz, E., Breese, J., Heckerman, D., Hovel, D., & Rommelse, K. (1998). lumiere project:
Bayesian user modeling inferring goals needs software users. Proceedings
Fourteenth Conference Uncertainty Artificial Intelligence, pp. 256265.
Hui, B., & Boutilier, C. (2006). Whos asking help?: Bayesian approach intelligent assistance. Proceedings Eleventh International Conference Intelligent User Interfaces,
pp. 186193.
Johnson, D., Cuijpers, R., Juol, J., Torta, E., Simonov, M., Frisiello, A., Bazzani, M., Yan, W.,
Weber, C., Wermter, S., et al. (2013). Socially assistive robots: comprehensive approach
extending independent living. International Journal Social Robotics, 6(2), 195211.
Johnson, M. (2014). Inverse optimal control deterministic continuous-time nonlinear systems.
Ph.D. thesis, University Illinois Urbana-Champaign.
Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially bservable
stochastic domains. Artificial Intelligence, 101(1-2), 99134.
Kearns, M. J., Mansour, Y., & Ng, A. Y. (1999). sparse sampling algorithm near-optimal
planning large markov decision processes. Proceedings Sixteenth International
Joint Conference Artificial Intelligence, pp. 13241331.
Konidaris, G., Kuindersma, S., Grupen, R., & Barto, A. (2012). Robot learning demonstration
constructing skill trees. International Journal Robotics Research, 31(3), 360375.
Kullback, S., & Leibler, R. (1951). information sufficiency. Annals Mathematical
Statistics, 22(1), 7986.
Kurniawati, H., Hsu, D., & Lee, W. (2008). Sarsop: Efficient point-based POMDP planning
approximating optimally reachable belief spaces. Proceedings Robotics: Science
Systems IV.
Lau, T., Wolfman, S., Domingos, P., & Weld, D. (2003). Programming demonstration using
version space algebra. Machine Learning, 53(1-2), 111156.
Lieberman, H. (2009). User interface goals, AI opportunities. AI Magazine, 30(3), 1622.
Littlestone, N. (1988). Learning quickly irrelevant attributes abound: new linear-threshold
algorithm. Machine Learning, 2(4), 285318.
Littman, M. L. . (1996). Algorithms Sequential Decision Making. Ph.D. thesis, Brown University.
Mahadevan, S., Mitchell, T. M., Mostow, J., Steinberg, L. I., & Tadepalli, P. (1993). apprenticebased approach knowledge acquisition.. Artificial Intelligence, 64(1), 152.
Mitchell, T. M., Caruana, R., Freitag, D., J.McDermott, & Zabowski, D. (1994). Experience
learning personal assistant. Communications ACM, 37(7), 8091.
Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning less
data less time. Machine Learning, 13, 103130.
Mundhenk, M. (2001). complexity planning partially-observable Markov Decision
Processes. Ph.D. thesis, Friedrich-Schiller-Universitdt.

103

fiF ERN , NATARAJAN , J UDAH , & TADEPALLI

Myers, K., Berry, P., Blythe, J., Conleyn, K., Gervasio, M., McGuinness, D., Morley, D., Pfeffer,
A., Pollack, M., & Tambe, M. (2007). intelligent personal assistant task time
management. AI Magazine, Vol. 28, pp. 4761.
Natarajan, S., Tadepalli, P., & Fern, A. (2007). relational hierarchical model decision-theoretic
assistance. Proceedings Seventeenth Annual International Conference Inductive
Logic Programming, pp. 175190.
Papadimitriou, C., & Tsitsiklis, J. (1987). complexity Markov Decision Processes. Mathematics Operations Research, 12(3), 441450.
Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: anytime algorithm
POMDPs. Proceedings Eighteenth International Joint Conference Artificial
Intelligence, pp. 1025 1030.
Porta, J., Vlassis, N., Spaan, M., & Poupart, P. (2006). Point-based value iteration continuous
POMDPs. Journal Machine Learning Research, 7, 23292367.
Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars plan recognition. Proceedings Sixteenth Conference Uncertainty Artificial Intelligence,
pp. 507514.
Refanidis, I., Alexiadis, A., & Yorke-Smith, N. (2011). Beyond calendar mashups: Intelligent calendaring. Proceedings Twenty-First International Conference Automated Planning
Scheduling System Demonstrations.
Shani, G., Pineau, J., & Kaplow, R. (2013). survey point-based POMDP solvers. Autonomous
Agents Multi-Agent Systems, 27(1), 151.
Singh, S. P., Litman, D. J., Kearns, M. J., & Walker, M. A. (2002). Optimizing dialogue management reinforcement learning: Experiments njfun system.. Journal Artificial
Intelligence Research, 16, 105133.
Skaanning, C., Jensen, F. V., & Kjaerulff, U. (2000). Printer troubleshooting using bayesian networks. Proceedings Thirteenth International Conference Industrial Engineering Applications Artificial Intelligence Expert Systems, pp. 367379.
Varakantham, P., Maheswaran, R. T., & Tambe, M. (2005). Exploiting belief bounds: practical
POMDPs personal assistant agents. Proceedings Fourth Internation Conference
Autonomous Agents Multiagent Systems, pp. 978985.
Walker, M. A. (2000). application reinforcement learning dialogue strategy selection
spoken dialogue system email. Journal Artificial Intelligence Research, 12, 387416.
Yorke-Smith, N., Saadati, S., Myers, K., & Morley, D. (2012). design proactive personal
agent task management. International Journal Artificial Intelligence Tools, 21(1), 90
119.

104

fiJournal Artificial Intelligence Research 50 (2014) 923970

Submitted 06/14; published 08/14

Belief Tracking Planning Sensing: Width,
Complexity Approximations
Blai Bonet

bonet@ldc.usb.ve

Departamento de Computacion
Universidad Simon Bolvar
Caracas, Venezuela

Hector Geffner

hector.geffner@upf.edu

ICREA & Universitat Pompeu Fabra
Roc Boronat 138
08018 Barcelona, Spain

Abstract
consider problem belief tracking planning setting states valuations set variables partially observable, beliefs stand sets
states possible. problem intractable worst case,
recently shown deterministic conformant contingent problems, belief tracking exponential width parameter often bounded small. work,
extend results two ways. First, introduce width notion applies
non-deterministic problems well, develop factored belief tracking algorithm exponential problem width, show applies existing benchmarks. Second,
introduce meaningful, powerful, sound approximation scheme, beam tracking,
exponential smaller parameter, problem causal width, much broader applicability. illustrate value algorithm large instances problems
Battleship, Minesweeper, Wumpus, yields state-of-the-art performance
real-time.

1. Introduction
Planning incomplete information formulated search problem belief space
two issues need addressed: keeping track beliefs, searching goal
belief (Bonet & Geffner, 2000). two tasks intractable worst case
compact representations, approach adopted recent conformant
contingent planners beliefs handled using SAT, regression techniques, logical
normal forms CNF, DNF, OBDDs, search goal beliefs guided
domain-independent heuristics (Bertoli, Cimatti, Roveri, & Traverso, 2001; Hoffmann &
Brafman, 2006; Bryce, Kambhampati, & Smith, 2006; To, Pontelli, & Son, 2011; Shani &
Brafman, 2011; Brafman & Shani, 2012).
Recently, complexity belief tracking deterministic conformant contingent
planning shown exponential problem width parameter often
bounded small (Palacios & Geffner, 2009; Albore, Palacios, & Geffner, 2009).
bound follows family translations developed compiling planning problems
beliefs planning problems states. translations exponential problem
c
2014
AI Access Foundation. rights reserved.

fiBonet & Geffner

width, deterministic conformant problems result problems solved
classical planners.
difficulty extending results Palacios, Albore, Geffner nondeterministic setting consequence special role played initial situation
deterministic problems. case, uncertainty, particular, uncertainty
observations, action preconditions, goals, one matters
complete planner, result uncertainty initial situation. nondeterministic setting, hand, uncertainty produced dynamically result
application non-deterministic actions. Moreover, uncertain initial situation
always modeled fully known initial situation dummy non-deterministic
action, opposite transformation simple. Indeed, non-deterministic effects
compiled deterministic effects conditional value hidden variables,
number hidden variables required must grow planning horizon
(Weld, Anderson, & Smith, 1998; Albore, Ramirez, & Geffner, 2010).
aim work study computational complexity belief tracking
terms novel width parameters apply deterministic non-deterministic
planning problems, formulation practical approximate belief tracking algorithms
efficient effective even problems large width. achieve
considering two decomposition schemes belief tracking, three algorithms based
decompositions. precisely, introduce:
1. width notion planning close correspondence notion introduced
Palacios, Albore, Geffner applies non-deterministic problems
well.
2. first belief tracking algorithm, factored belief tracking, sound complete
deterministic non-deterministic problems P , runs time space
exponential problem width w(P ). algorithm based decomposition
problem P projected subproblems PX , one every goal precondition
variable X, one including variables relevant X.
3. second belief tracking algorithm, causal belief tracking, based alternative
decomposition scheme, subproblems PX defined every goal, precondition,
observable variable X, one including variables causally relevant
X. algorithm sound complete large meaningful class problems,
still time exponential problem width, space exponential
causal width problem often much smaller.
4. final belief tracking algorithm, beam tracking sound incomplete approximation causal belief tracking, often practical enough, even problems
large widths, runs time space exponential problem causal
width.
power last algorithm, beam tracking, shown empirically large
instances problems Minesweeper, Battleship, Wumpus, state-of-the924

fiBelief Tracking Planning Sensing

art performance obtained real-time combining belief tracking algorithm
simple heuristics action selection.1
organization paper follows structure, preceded overview
relevant notation background, followed description experiments,
discussion related work, summary. paper integrates results two conference
papers (Bonet & Geffner, 2012b, 2013), providing proofs additional details. work
related proposals tractable forms belief tracking logical probabilistic
frameworks (Doucet, Freitas, Murphy, & Russell, 2000; Amir & Russell, 2003), yet
two key differences. One start exact account used determine
certainty whether goal achieved action applicable. second
belief tracking accounts planning complete formulas. order
sound complete planner, beliefs observations, action preconditions,
goals required. important observations, action preconditions,
goals given, structure actions, sensors, goals exploited
track beliefs efficiently. observation implicit lazy belief tracking
schemes planning incomplete information appeal SAT-solvers (Hoffmann &
Brafman, 2006) regression (Shani & Brafman, 2011). Well say related work
Section 12.

2. Model
model planning sensing simple extension model conformant
planning goal achieved certainty spite uncertainty initial
situation action effects (Goldman & Boddy, 1996; Smith & Weld, 1998). model
conformant planning characterized tuple = hS, S0 , SG , A, F
finite state space,
S0 non-empty set possible initial states, S0 S,
SG non-empty set goal states, SG S,
set actions A(s) denoting sets actions applicable S,
F non-deterministic state-transition function F (a, s) denotes nonempty set possible successor states follow action s, A(s).
solution conformant model action sequence maps possible initial state
goal state. precisely, = ha0 , . . . , an1 conformant plan possible
sequence states s0 , s1 , . . . , sn s0 S0 si+1 F (ai , si ), = 0, . . . , n 1,
action ai applicable si sn goal state.
Conformant planning cast path finding problem beliefs, defined
sets states deemed possible time point (Bonet & Geffner, 2000).
initial belief b0 S0 , belief ba results action belief state b is:
ba = {s0 | b s0 F (a, s)} ,

(1)

1. real-time animation algorithm several instances Minesweeper seen https:
//www.youtube.com/watch?v=U98ow4n87RA, source code graphical interfaces
obtained http://code.google.com/p/belief-tracking.

925

fiBonet & Geffner

action applicable b applicable state b. formulation,
conformant plan action sequence maps initial belief b0 goal belief bG ;
i.e., set goal states.
Contingent planning planning sensing planning uncertainty
feedback. model contingent planning model conformant planning extended
sensor model. sensor model function O(s, a) mapping state-action pairs
observations tokens o. expression O(s, a) means token possible
observation true state system last action done.
observed token provides partial information true possibly hidden system
state token may possible different states. two different tokens o1
o2 belong O(s, a), means either one observed
last action. Sensing deterministic noiseless O(s, a) contains one token, else
non-deterministic noisy. contingent model similar POMDPs (Kaelbling,
Littman, & Cassandra, 1999) uncertainty encoded sets states rather
probability distributions.
Executions contingent setting sequences ha0 , o0 , a1 , o1 , . . .i pairs actions
ai observations oi . b = bi belief state action ai applied oi
token observed, belief ba action = ai given (1),
belief bi+1 = boa follows observing token is:
boa = {s | ba O(s, a)} .

(2)

execution ha0 , o0 , a1 , o1 , . . .i possible starting initial belief b0 , action
ai applicable belief bi (i.e., ai A(s) bi ), 0, belief bi
empty.
off-line contingent planning, action selection strategy sought ensures
possible executions end goal belief. on-line contingent planning, action
selection strategy sought ensures single execution results
interaction real system simulator, ends goal belief. cases,
action selection strategy expressed partial function beliefs, called policy,
(b) action belief b. function partial
defined initial belief b0 non-goal beliefs b; namely,
reached b0 off-line planning, reached
b0 on-line planning.

3. Language
Syntactically, conformant problems expressed compact form set
state variables, convenience assume multi-valued.2 precisely,
conformant planning problem tuple P = hV, I, A, Gi V stands problem
variables X, one finite discrete domain DX , set clauses
V -literals defining initial situation, set actions, G set V -literals
defining goal. Every action precondition P re(a) given set V -literals,
2. Multi-valued variables compiled boolean variables compilation affects syntactic
structure problem. principle, structure could recovered boolean encodings
would result complex formulation.

926

fiBelief Tracking Planning Sensing

set conditional effects C E1 | . . . |En C Ei sets (conjunctions)
V -literals. conditional effect non-deterministic n > 1; else n = 1 effect
deterministic.
problem P = hV, I, A, Gi defines conformant model S(P ) = hS, S0 , SG , A, F i,
set possible valuations variables V , S0 SG sets valuations
satisfy G respectively, A(s) set operators whose preconditions true
s, F (a, s) non-deterministic transition function results collecting
successor states may follow selecting one head Ei conditional
effect C E1 | . . . |En whose body C true s.3
Contingent problems described extending syntactic description conformant problems compact encoding sensor model. this, assume set
V 0 observable multi-valued variables , necessarily disjoint state variables
V (i.e., state variables may observable), formulas Wa (Y = y) state
variables, action possible value observable variable .
formula Wa (Y = y) implicitly encodes states observation literal =
possible last action executed. formulas Wa (Y = y) different
values DY must logically exhaustive, every state-action pair must give rise
observation = y. addition, formulas Wa (Y = y) different values
logically exclusive, every state-action pair gives rise single observation =
sensing deterministic. state variable X observable, Wa (X = x)
formula X = x.
contingent problem P tuple P = hV, I, A, G, V 0 , W defines contingent
model made conformant model hS, S0 , SG , A, F determined first four
components P , sensor model O(a, s) determined last two components,
O(a, s) iff valuation observable variables V 0 =
true formula Wa (Y = y) W true DY .
standard language representing contingent problems compact form featuring incomplete information, non-deterministic actions sensors. two
distinctive features relation similar languages use multi-valued variables,
distinction state observable variables.
illustration, X encodes position agent, encodes position
object seen agent X = , observable variable
Z {Y es, N o} encoding whether
object seen agent
W
W not, defined
formulas Wa (Z = es) = lD (X = lY = l), Wa (Z = N o) = lD (X = lY = l),
set possible locations action. deterministic
sensor. non-deterministic sensor could used if, example, agent cannot detect
0
presence
W object certain locations l . this, suffices push
disjunct lD0 (X = l) formulas characterizing Wa (Z = es) Wa (Z = N o),
two observations Z = es Z = N would possible agent
position l D0 .
Since conformant problem hV, I, A, Gi expressed contingent problem
hV, I, A, G, V 0 , W one (dummy) observable variable Z, Z
/ V domain
3. conditional effects must consistent sense explained below.

927

fiBonet & Geffner

DZ = {>}, observation model Wa (Z = >) = true every action a, focus
general contingent problem.
Likewise, convenience, variable boolean, often represent literals
= true = f alse . Similarly, variable observable, unless stated
otherwise, assume observation model deterministic formula
Wa (Y = f alse) becomes complement formula Wa (Y = true).

4. Belief Tracking Problem Flat Belief Tracking Algorithm
execution problem P = hV, I, A, G, V 0 , W sequence ha0 , o0 , a1 , o1 , . . .i
actions ai observations oi ai observation oi full
valuation observation variables V 0 . execution ha0 , o0 , . . . , , possible
problem P non-empty belief state b0 , generates sequence beliefs b0 , . . . , bn
preconditions action ai true belief bi , belief states
bi empty. problem belief tracking contingent planning problem
determining execution possible final belief state achieves goal:
Definition 1. Belief tracking planning (BTP) problem determining whether
execution ha0 , o0 , a1 , o1 , . . .i planning problem P = hV, I, A, G, V 0 , W possible,
so, whether resulting belief state makes goal G true.
complete planner needs solve problem determining actions applicable given execution, observations may result, whether goal
achieved. machinery develop aimed slightly general
belief tracking problem generalized executions: executions ha0 , o0 , a1 , o1 , . . .i
observations oi partial rather full valuations observable variables. Moreover, suffices consider generalized executions observations
valuations single observable variable. observations oi represented
observation literals `i :
Definition 2. Generalized belief tracking planning (GBTP) problem determining whether generalized execution ha0 , `0 , a1 , `1 , . . .i planning problem P =
hV, I, A, G, V 0 , W possible, so, whether achieves given goal, precondition,
observation literal.
Given procedure deciding GBTP, simple decide BTP execution
calling procedure deciding GBTP generalized execution 0 replaces
observation oi sequence observation literals true oi separated
NO-OP actions (actions effects).
Proposition 3. BTP polynomial-time reducible GBTP.
interest belief tracking planning, find convenient focus
generalized problem, none belief update equations algorithms sensitive
distinction. simplicity, however, talk belief tracking, make
explicit distinctions BTP GBTP, normal generalized
executions, needed.
928

fiBelief Tracking Planning Sensing

plain solution belief tracking problem given updates expressed
Eqs. 1 2, belief states explicitly represented sets states, states full
valuations state variables, actions, transition function, observations
obtained syntactic representation problem:
Definition 4. flat belief tracking algorithm execution ha0 , o0 , a1 , o1 , . . .i
problem P , starts belief b0 contains states satisfy initial situation,
setting next belief state bi+1 boa using (1) (2) b = bi , = ai , = oi .
complexity flat belief tracking exponential number state variables. Yet,
often state variables add complexity tracking beliefs. Syntactically,
happens state variable X initially known, variables causally
relevant X (see below) initially known well, neither X variable
causally relevant X appears head non-deterministic effect. say
variables determined value every reachable belief known, fully
predicted preceding actions preceding values. example, variable
encodes position agent Wumpus game determined, initial
value known effect actions variable deterministic depends
previous value.
Formally, define set variables determined problem
largest set state variables X problem initially known every
state variable X 0 causally relevant X belongs set. set variables
easily identifiable low polynomial time. complexity flat belief tracking
expressed follows:
Theorem 5. Flat belief tracking exponential |VU |, VU = V \ VK VK
set state variables determined problem.
Given result, first question arises bad naive approach flat belief
tracking. Interestingly, following result decision problem shows flat belief
tracking bad worst case:
Theorem 6. BTP GBTP Turing complete class PNP .
is, BTP GBTP decided polynomial time using oracle NP (SAT,
example), every decision problem decided polynomial time
oracle, decided polynomial time oracle BTP GBTP.
complexity class PNP includes classes NP coNP, contained PSPACE
(Sipser, 2006).

5. Structure Width
possible improve complexity flat belief tracking specific problem
exploiting structure problem. introducing graph captures
structure, convenient make explicit assumptions restrict
generality approach make definitions simpler. First, assume
formula encoding initial situation contains positive negative literals; i.e., unit
clauses only. restrictive assumption since set clauses encoded
929

fiBonet & Geffner

help dummy observations. Second, assume non-deterministic effects
involve one variable heads. Again, always achieved adding extra
variables effects. example, non-deterministic effect X Z | Z
action replaced deterministic effects X W Z X W Z,
along non-deterministic effect true W | W , W new random boolean
variable initially unknown changes randomly. Third, assume problem
consistent, meaning initial situation logically consistent initial
belief state b0 empty, effects action consistent
heads deterministic conditional effects applicable reachable state s, along
choice heads non-deterministic conditional effects applicable
s, jointly consistent.4 Last, assume every observable variable relevant
variable appearing precondition goal, notion relevance spelled
below. Observable variables dont comply condition eliminated
problem relevant information loss.
5.1 Relevance Width
variable X, whether state variable, observable variable, both, immediate
causes X defined follows:
Definition 7. variable X immediate cause variable problem P , written
X Ca(Y ), iff X 6= , either X occurs body C conditional effect C
E1 | |En occurs head Ei , 1 n, observable variable X
occurs formula Wa (Y = y) DY action a.
Basically, X immediate cause uncertainty X may affect
uncertainty directly, variables. X necessarily immediate
cause X appears precondition action affects , preconditions
must known certainty, hence, propagate uncertainty. notion
causal relevance given transitive closure immediate cause relation:
Definition 8. X causally relevant P X = , X Ca(Y ), X causally
relevant variable Z causally relevant .
order test whether given literal Z = z known certain execution
ha0 , a1 , . . . , ai actions conformant setting, possible show one
progress state variables X causally relevant Z:
Proposition 9. Belief tracking deterministic non-deterministic conformant setting exponential maximum number non-determined variables causally
relevant variable appearing action precondition goal.
bound closely related bound obtained Palacios Geffner
deterministic setting. Indeed, refer number non-determined state variables
4. semantic point view, means state s0 possible successor state
action applicable s, i.e. s0 F (a, s), iff every literal X = x true s0 , X = x head
deterministic non-deterministic conditional effect action whose body true s, X = x
true s, effect action X = x0 head, x0 6= x, whose body
true s.

930

fiBelief Tracking Planning Sensing

causally relevant X, conformant width X, set width P
maximum conformant width variables X appear action preconditions
goals, Proposition 9 simply says belief tracking non-deterministic conformant
problem exponential problem width. width notion, however, exactly
equivalent notion Palacios Geffner used deterministic setting
defined variables rather literals. say distinction
below. general, however, two accounts yield similar widths deterministic
benchmarks.
contingent setting, variables whose uncertainty may affect variable
Z causally relevant Z. situation similar one arising
Bayesian networks (Pearl, 1988), relevance flows causally, direction
arrows, evidentially, observations direction arrows.
Definition 10. X evidentially relevant P X observable variable
causally relevant X.
notion relevance captures transitive closure (directional) causal evidential relations:
Definition 11. X relevant X causally evidentially relevant , X
relevant variable Z relevant .
Thus, variable X = W1 relevant variable = Wn iff chain variables
Wi , 1 n 1, variable Wi causally evidentially relevant next
variable Wi+1 chain. example, X causally relevant Z,
observable variable, relevant Z evidentially relevant X X
causally relevant Z.
Like Bayesian networks, relevance relations understood graph-theoretically.
Thus, directed edge Z stands Z immediate cause , X
causally relevant X 0 directed path X X 0 , X evidentially
relevant X 0 X observable variable, directed path X 0
X. terms Bayesian networks, relevance relation takes transitive closure
causal evidential relationships, encodes potential dependency given
may observed, using information certain variables observed (are
observable). Unlike Bayesian networks, means however relevance relation
symmetric. Namely, cause X relevant , automatically
relevant X causally relevant observable variable Z, may
itself. context variable set variables problem relevant
X:
Definition 12. context variable X, Ctx(X), denotes set state variables
problem relevant X.
width variable defined number state variables context
determined:
Definition 13. width variable X, w(X), |Ctx(X) VU |, VU = V \ VK
VK set state variables determined.
931

fiBonet & Geffner

width problem then:
Definition 14. width w(P ) conformant contingent problem P , whether deterministic not, maxX w(X) X ranges variables appear goal
action precondition P .
relation width complexity expressed as:
Theorem 15. Belief tracking P exponential w(P ).
proof theorem follows results algorithm
achieves complexity bound presented. significance theorem belief
tracking planning domains width bounded constant becomes polynomial
number problem variables. see examples below. complexity bound
similar ones obtained deterministic conformant contingent problems (Palacios
& Geffner, 2009; Albore et al., 2009). main difference new account applies
non-deterministic problems well. new account simpler general,
see, also slightly less tight deterministic domains.

6. Examples
illustrate definitions benchmark domains, starting DET-Ring
(Cimatti, Roveri, & Bertoli, 2004). domain, ring n rooms
agent move forward backward along ring. room window
opened, closed, locked closed. Initially, status windows
known agent know initial location. domain agent
means obtaining information status windows position,
goal windows locked. plan deterministic conformant problem
repeat n times actions (close, lock, f wd), skipping last f wd action. Alternatively,
action f wd replaced action bwd throughout plan. state variables
problem encode agent location Loc {1, . . . , n}, status window,
W (i) {open, closed, locked}, = 1, . . . , n. location variable Loc (causally) relevant
window variable W (i), window variable W (i) relevant Loc W (k)
k 6= i, W (i) causally relevant observable variable. None variables
determined largest contexts window variables W (i) include two
variables, W (i) Loc. result width domain 2, independent
number state variables W (i) grows number rooms n. causal
graph problem, directed edge X means X immediate cause
shown Figure 1a.
NON-DET-Ring variation domain actions f wd bwd
agent non-deterministic effect status windows locked,
capturing possibility external events open close unlocked windows.
non-determinism effect causal graph variables. result,
change effect contexts domain width remains bounded equal
2 number rooms n.
last version domain considered Cimatti et al. NON-DET-Ring-Key,
key required lock windows. initial position key known,
932

fiBelief Tracking Planning Sensing

Loc

Loc

W (1)

W (2)



W (n)

W (1)

(a) DET-Ring

W (2)

KLoc



W (n)

H

(b) CONT-NON-DET-Ring-Key

Figure 1: Causal graphs problems DET-Ring (left) CONT-NON-DET-Ring-Key
(right). latter, variable H observable tells us whether key held
not. arc X denotes X immediate cause . graphs, variables
preconditions goals underlined yellow colored, observable variables
enclosed blue circle.
yet agent tries collect key room key there, agent
key. conformant plan problem repeat actions pick f wd, n
times, skipping last f wd action, following plan DET-Ring. NON-DETRing-Key, additional state variable, KLoc {1, . . . , n, hand}, represents
key location. agent location Loc relevant KLoc relevant window
variable W (i). result, size contexts Ctx(W (i)) problem width
increase 1. width however remains bounded value 3 independently
number rooms n.5
presence partial observability, analysis similar necessary
consider relevance relationships arise due presence observable variables.
example, one express agent always observe whether holding
key not, boolean observable variable H (deterministic) observation
model Wa (H = true) given KLoc = hand, actions a. new relevance
relation among state variables arises adding observable variable
Loc KLoc, causally relevant H. Before, Loc relevant KLoc
way around. Yet affect domain width remains 3
n. causal graph resulting domain shown Figure 1b.

7. Factored Belief Tracking
Belief tracking problem P exponential width w(P ) P . algorithm
achieves bound exploits relevance relations encoded variable contexts
decomposing beliefs. particular, variable relevant variable,
problem width 1, beliefs variable maintained separately.
belief decomposition obtained projecting problem P smaller problems PS
set state variables P . Semantically, projected problems PS capture
dynamics problem P expressed subset state variables. Syntactically,
projected problems PS defined means logical notion projection.
5. problem also encoded making holding key precondition rather condition
locking windows. encoding, variable KLoc longer relevant window
variables W (i) according definitions, KLoc = hand must known certainty,
hence uncertainty windows variables W (i) affected uncertainty KLoc.
result encoding, domain width reduces 2.

933

fiBonet & Geffner

logical projection formula F subset variables refers formula F 0
defined variables S, valuations satisfy F 0 exactly
extended valuations satisfy F (Darwiche & Marquis, 2002). Likewise,
projection conditional effect C E 1 | |E n conditional effect CS ES1 | |ESn
body C effects E replaced logical projections CS ESi
respectively.
Definition 16. projection problem P = hV, I, A, G, V 0 , W set variables
V problem PS = hVS , , , GS , VS0 , WS VS S, GS
initial goal formulas G logically projected variables S,
preconditions conditional effects projected S, VS0 V 0 , WS set
formulas Wa (Y = y) W logically projected variables S.
notion projected planning problem used setting
classical planning introducing class admissible heuristics known pattern databases
(Edelkamp, 2001). use richer contingent setting decomposing belief
tracking problem P belief tracking problem smaller problems PS obtained
P projecting away state variables P .
defining target subproblems PS decomposition, notice variables
state observable variables P S, belong VS0
VS , meaning observable variables projected problem PS .
Moreover, formulas variables WS become Wa (Y = y) = true
DY , meaning problem PS , observations = possible
y, regardless state last action done. observations thus completely
irrelevant PS effect. case, P PS share set actions
set observations even actions observations PS may
defined smaller set state variables.
target subproblems PS defined terms set state variables
relevant precondition goal variables. Recall assume observable
variable problem relevant action precondition goal, else variable
could safely removed.
Definition 17. projection problem P variable X, denoted PX ,
projection PS P set variables = Ctx(X), Ctx(X) context
X P ; i.e., set state variables P relevant X.
Two basic properties projected problems PX are:
Proposition 18. variable X appears goal precondition, number state
variables PX determined bounded w(P ).
Proposition 19. execution ha0 , o0 , a1 , o1 , . . .i possible P , also possible
PX state variable X P .
b belief results execution P , call bX belief
results execution projected problem PX . completeness
decomposition global belief b P expressed terms local beliefs bX
subproblems PX . treat beliefs b bX relations database
934

fiBelief Tracking Planning Sensing

state variables beliefs columns possible combination values
(states local states) rows. projection b, set variables thus
represents combination values variables possible b,
join bX
nbY represents combination values x sets variables
two beliefs bX x coincide variables X
. example, b contains valuations (states) X = 1, = 1 X = 2, = 2,
projection {X} b contain valuations X = 1 X = 2. Likewise, b0 contains
= 1, Z = 1 = 1, Z = 2, join b
n b0 contain X = 1, = 1, Z = 1
X = 1, = 1, Z = 2.
Theorem 20. state variable X, let b bX beliefs result execution
possible P PX . Then,
X bX = X b .

(3)

Equation 3 states literal X = x possible true global belief b iff
possible belief bX results execution projected problem
PX . exactly type completeness needed planning variable
X involved action precondition goal. stronger form completeness
formulas, expressed


nX bX = b ,

(4)


n stands join operation X ranges precondition goal variables
problem, needed, actually necessarily true, even state
variables appear context Ctx(X). example, value boolean variable
Z initially unknown, variables X initially false, action conditional
effects Z X Z Z results belief b two states, corresponding
terms Z X Z X . X precondition goal variables
relevant other, projected problem PX contain variables
X Z, projected problem PY contain variables Z. belief
bX resulting execution action PX include local states
corresponding terms Z X Z X, belief PY include
local states corresponding terms Z Z . Clearly, projection b
bX (bY ) variable X (Y ) coincide dictated (3), join two local
beliefs bX yield global belief b would correspond (4); indeed,
formula like X false latter former. (3), prove
inductively size execution that:
Theorem 21. 1) execution possible P iff possible subproblems
PX X precondition goal variable P . 2) execution precondition
goal variable X, X = x (resp. X 6= x) true b iff X = x (resp. X 6= x) true
bX , b bX beliefs result executing P PX respectively.
Since plain belief tracking projected problem PX exponential size
PX , bounded w(P ) determined variables excluded, follows that:
935

fiBonet & Geffner

Theorem 22. Flat belief tracking projected problems PX X
precondition goal variable P , provides sound complete factored algorithm
belief tracking P time space exponential width P .
call algorithm, factored belief tracking. order check whether precondition
goal literal X = x true execution, factored belief tracking checks whether
X = x true belief bX results execution subproblem PX .
execution possible action precondition X = x true bX results
empty belief subproblem. Theorem 22 thus says factored belief tracking
sound complete algorithm BTP time space complexity exponential
problem width. Indeed, since every observable variable relevant precondition
goal variable X assumption, every direct cause Z relevant X
evidentially relevant X. Thus, formula Wa (Y = y) evaluated bX
determine whether observation = necessary, possible impossible applying
action a. Thus, factored belief tracking also solves generalized BTP problem.
illustration Theorem 22, let us go back DET-Ring problems P whose
structure analyzed before. theorem implies order check whether given
possible execution achieves goal P , sufficient check whether goal literal
W (i) = locked, 1 n, achieved execution subproblem PW (i) . Thus,
factored belief tracking P done O(n2 ) time since n subproblems
PW (i) , one involving 2 variables: W (i) constant-size domain Loc
domain size n.
exact situation arises non-deterministic conformant problem NON-DET
Ring whose causal graph one DET-Ring. hand, NONDET-Ring-Key, subproblems must keep track KLoc variable encoding key
location, thus belief update operation requires O(n3 ) time, still much better
flat belief tracking P requires time exponential n. complexity
results applies problem longer conformant agent observe whether
holding key not.
experimental figures domains shown Table 1, factored belief
tracking used combination simple heuristics. experiments run
Xeon Woodcrest 5140 CPU running 2.33 GHz 8 GB RAM. planner
KACMBP Cimatti et al. uses OBDD-based belief representation cardinality
heuristics, solve problems n = 20 rooms, producing plans 206
steps slightly 1,000 seconds NON-DET-Ring-Key. Conformant planners
T0 (Palacios & Geffner, 2009) cannot used problem non-deterministic.
Tables 1a 1b show scalability factored belief tracking algorithm context
greedy best-first search P
heuristic h(b), similar one used Albore, Ramirez,
Geffner (2011), h(b) = ni=1 h(bi ), bi belief factor projected
problem goal variable W (i) representing status ith window, h(bi )
representing fraction states bi goal W (i) = locked false. displayed
tables, resulting planner scales polynomially, NON-DET-Ring-Key
100 rooms, produces plan 1, 111 actions 783.1 seconds. contingent
version problem agent detects key room, CONT-DETRing-Key, policy greedy cardinality heuristic h(b) = maxni=1 |bi | used instead,
936

fiBelief Tracking Planning Sensing

n

steps

exp.

time

n

steps

exp.

time

n

avg. steps

avg. time

10
20
30
40
50
60
70
80
90
100

68
138
208
277
345
415
476
545
610
679

355
705
1,055
1,400
1,740
2,090
2,395
2,740
3,065
3,410

< 0.1
0.1
0.9
3.1
8.3
18.6
34.5
62.8
106.4
171.0

10
20
30
40
50
60
70
80
90
100

118
198
278
488
438
468
543
616
682
1,111

770
1,220
1,670
3,210
2,570
2,660
3,080
3,480
3,880
7,220

< 0.1
0.8
4.2
15.2
34.4
52.2
100.6
172.9
285.6
783.1

10
20
30
40
50
60
70
80
90
100

326.8 4.3
1, 036.0 13.5
2, 068.0 26.5
3, 462.9 47.2
5, 130.7 71.0
7, 070.9 100.9
9, 334.1 127.6
11, 724.0 162.2
14, 617.4 204.6
17, 891.2 252.3

0.0
0.1
0.5
1.8
4.4
9.3
17.5
30.6
50.0
79.0

(a) DET-Ring-Key

(b) NON-DET-Ring-Key

(c) CONT-DET-Ring-Key

Table 1: Results conformant contingent Ring problems obtained combining factored belief tracking simple heuristics. data point panel (c) contingent
problem average (and sample standard deviation) 1,000 random instances. Times
seconds. column exp. contains number expansions.

ties broken randomly, bi belief factor goal variable W (i).
seen Table 1c, resulting planner runs polynomial time solve problems
100 rooms. Thus, heuristic policy weak, long executions result,
belief tracking problem efficient scales well.

8. Causal Belief Tracking
Factored belief tracking exponential problem width. many problems, however,
width may high method usable practice. illustration,
consider problem P state variables X1 , . . . , Xn+1 , observable variables O1 , . . . ,
Oi true iff Xi = Xi+1 . sensors thus Wa (Oi = true) = (Xi = Xi+1 )
Wa (Oi = f alse) = (Xi 6= Xi+1 ) actions 1 n. Let us also assume
actions problem may affect Xi variables introduce
causal relations among them, state variables appear preconditions
goals. causal graph problem shown Figure 2. width n + 1
state variables interact. Indeed, variable Xi relevant variable Xk ,
relevance flowing Xi Xi+1 , vice versa, variables causally relevant
observable variable Oi evidentially relevant both. result
problem P projected problems PXi coincide denote problem,
contexts state variables include state variables.
focus different decomposition belief tracking maps problem P
smaller subproblems PXc whose size bounded number state variables
causally relevant given precondition, goal, observation variable. new width
measure called causal width problem. problem shown Figure 2
width n + 1 causal width 2. explore belief tracking algorithms
exponential problem causal width analyze conditions
937

fiBonet & Geffner

X1

X2

X3



Xn

O1

O2

O3





Xn+1

Figure 2: Causal graph 2-layer network example state variables X1 , . . . , Xn+1
observable variables O1 , . . . , On+1 . immediate causes observable Oi
variables Xi Xi+1 . Precondition goal variables appear underlined
yellow box, observable variables appear within blue circle. Since Xi variables
relevant other, width problem n + 1. hand, since
two variables causally relevant precondition, goal, observable variable,
causal width problem 2.
complete. this, first generalize make explicit decomposition underlying
factored belief tracking algorithm:
Definition 23. decomposition problem P pair = hT, Bi, set
variables X appearing P , called target variables decomposition, B
collection beams B(X) associated target variable made
state variables P .
decomposition = hT, Bi maps P set subproblems PXD , one variable
X , corresponds projections P state variables beam B(X).
decomposition underlies factored belief tracking is:
Definition 24. factored decomposition F = hTF , BF P decomposition
target variables TF given state variables X appearing action preconditions goals,
beams BF (X) given state variables relevant X.
Factored belief tracking flat belief tracking applied subproblems determined
factored decomposition. algorithms introduce next based different
decomposition:
Definition 25. causal decomposition C = hTC , BC P decomposition
target variables TC given observable variables state variables appearing
action precondition goals, beams BC (X) given state variables
causally relevant X.
causal decomposition determines larger number subproblems, subproblems
also generated observable variables, subproblems smaller beams
BC (X), contain state variables causally relevant X opposed
variables relevant X. causal width problem given size
largest beam causal decomposition, discounting variables determined
problem:
Definition 26. causal width variable X problem P , wc (X), number
state variables causally relevant X determined. causal width
938

fiBelief Tracking Planning Sensing

P maxX wc (X), X ranges target variables causal decomposition
P .
first simplest belief tracking algorithm defined causal decomposition
call Decoupled Causal Belief Tracking, runs time space
exponential problem causal width:
Definition 27. Decoupled causal belief tracking (Decoupled CBT) flat belief tracking
applied independently problems PXC determined causal decomposition
C = hTC , BC P . subproblem PXC problem P projected variables
BC (X) X TC ; i.e., PXC = PBC (X) .
Since causal width never greater width often much smaller, Decoupled
CBT runs much faster factored belief tracking general. This, however, comes
price express using expression b denoting projection (the states
the) belief b variables S.
Theorem 28. Decoupled CBT runs time space exponential wc (P ),
sound complete. is, target variable X causal decomposition,
b bX beliefs resulting execution P PXC respectively,
bX BC (X) b necessarily true, bX BC (X) b not.
One reason incompleteness beliefs bX associated different target
variables X assumed independent Decoupled CBT may
true. Indeed, causal decomposition problem may give rise beam BC (Y )
involving variable X, second beam BC (Z) involving variable X another
variable X 0 . variable observed, X = x may become false,
observation Z may lead X 0 = x0 becoming false well. Yet, Decoupled CBT,
inference cannot captured information flow across beams. factored
decomposition situation like cannot happen variable X 0 relevant variable
X hence beams contain X necessarily contain X 0 (X 0 relevant X
causally relevant Z evidentially relevant X).
causal decomposition, beams kept small closing relevance
relation, result, beliefs beams longer independent. However,
regarding beliefs tables relations, consistency relation among local beliefs
causal decomposition enforced means join operation. resulting
algorithm Coupled Causal Belief Tracking, abbreviated simply Causal Belief Tracking:
Definition 29. Causal Belief Tracking (CBT) belief tracking algorithm operates
causal decomposition C = hTC , BC setting beliefs b0X time 0 beam
BC (X) projection BC (X) initial belief, X TC , successive beliefs
bi+1
X as:
bi+1
n{(biY )oa : TC relevant X}
(5)
X = BC (X)
= ai = oi action observation time execution,
(biY )oa boa Eqs. 1-2 b = biY .
CBT, beliefs tracked independently subproblems PXC
causal decomposition; rather, beliefs first progressed filtered independently,
939

fiBonet & Geffner

merged projected back onto beams, making consistent
other. progression filtering local beliefs causal decomposition performed time space exponential problem causal width, full consistency
operation captured join-project operation (5) requires time worst case
exponential problem width:
Theorem 30. CBT space exponential causal width problem, time
exponential width.
CBT sound incomplete. However, range problem CBT complete,
unlike Decoupled CBT, large meaningful enough, includes example three
domains considered experiments below: Battleship, Minesweeper
Wumpus. express completeness conditions CBT introducing notion
memory variables:
Definition 31. state variable X memory variable problem P value X k
variable X time point k execution determined uniquely observation
value X X time point i, k, actions execution, initial
belief state problem.
example, static variables memory variables change thus
knowing value time point determines value point. Determined
variables (Section 4) also memory variables since value X k variables
determined initial belief actions done time k. Likewise, variables
permutation domains actions permute values variables (Amir & Russell,
2003), also memory variables. three sufficient conditions state variable
memory variable easy check. problem said causally
decomposable following condition holds:
Definition 32. problem P causally decomposable every pair beams BC (X)
BC (X 0 ) causal decomposition P non-empty intersection, X 0
observation variable, either 1) variables intersection memory variables,
2) variable W causal decomposition relevant X X 0
whose causal beam BC (W ) contains BC (X) BC (X 0 ).
problem causally decomposable, filtering implemented updates
CBT using Equation 5 suffices completeness:
Theorem 33. Causal belief tracking always sound complete causally decomposable problems.
importance result many meaningful domains whose problem
instances causally decomposable; particular, domains variables appear
two different beams static (this include Minesweeper), domains variables
appear two different beams either static determined (this includes Wumpus,
non-static variable agent location determined), domains
hidden non-static state variables appear one beam (this includes Battleship
hidden non-static variables appear intersection beams), cases
well. Sect. 11.4, present variation Wumpus monster moves
non-deterministically grid also instance causally-decomposable
problem.
940

fiBelief Tracking Planning Sensing

9. Approximation: Beam Tracking
causal belief tracking algorithm shows possible track beliefs planning
sound complete manner large meaningful class problems, considering
beliefs subproblems smaller factored decomposition.
algorithm, however, space exponential causal width problem,
time exponential problem width. global consistency operation
enforced (5). Beam tracking final belief tracking algorithm consider:
replaces global consistency operation local consistency operation
performed polynomial time. Beam tracking thus approximation causal belief
tracking aimed efficient effective rather complete.
Definition 34. Beam tracking belief tracking algorithm operates causal
decomposition C = hTC , BC i, setting beliefs b0X time 0 projection initial
belief beam X TC , setting successive beliefs bi+1
X two steps. First,


set progressed filtered belief ba b = bX , = ai = oi ,
ai oi action observation time execution. Then, local form
consistency enforced upon beliefs means following updates fixed
point reached:
i+1
(6)
bi+1
nbi+1
)
X = BC (X) (bX
refers target variable causal decomposition BC (Y )
BC (X) non-empty.
filtering represented iterative update Eq. 6 defines form relational
arc consistency (Dechter & Beek, 1997) equality constraints among beams sharing
common variables enforced polynomial time space size beams. Beam
tracking remains sound complete. causally decomposable problems, however,
incompleteness sole result replacing global local consistency.

10. Extensions, Modeling, Width
testing beam tracking algorithm empirically, present two simple extensions
language contingent planning useful modeling, briefly discuss
modeling choices affect causal width problem. first extension allows
use defined variables preconditions goals; second extension allows use
state constraints restricting possible value combination subsets variables.
10.1 Defined Variables
variable Z domain DZ defined function subset state variables
problem, function belief variables. example, boolean variable
Z defined true two variables X equal, third variable W
known true. Defined variables Z function set SZ state variables
function belief variables, handled action preconditions
goals introducing beam decomposition includes variables SZ
along variables relevant causally relevant them, according whether
decomposition factored causal. width causal width problem follow
941

fiBonet & Geffner

then, before, size largest beam factored causal decompositions
determined variables excluded.
10.2 State Constraints
State constraints used restrict value combinations given subsets state variables. game Battleship, example, modeled state variables associated
cells grid representing whether cell part ship, size
ship cell belongs (if any), relative position cell within ship
cell belongs (if any), whether ship placed vertically horizontally. state variables, however, independent, indeed, ship size 10
horizontally placed cell (0, 0), cells (0, i), {0, 1, . . . , 9} must belong (the
same) ship.
Formally, state constraint represented formula C state variables
encoded means dummy observable variable always observed
true, observed true states C holds; i.e., model
Wa (Y = true) = C every action a. implementation, however, pays treat
constraints C relations (the set valuations satisfy C), include
joins beliefs include variables C. causal belief tracking
effect completeness complexity algorithm, beam tracking,
changing update (6)
i+1
n C1
n
n Cn )
n bi+1
bi+1

X = BC (X) (bX

(7)

C1 , . . . , Cn state constraints whose variables included BC (X) BC (Y ),
makes local consistency stronger effect complexity algorithm. Moreover, one pair beams state constraint, state constraints
increase causal width problem constant factor 2 most, yet
effective causal width problem change, beams associated
dummy observables introduced constraints redundant ignored.
later case, using beam tracking, constraints Ci need stored
extensional form relations handled intentionally boolean functions
test whether assignment join two beams satisfies constraint.
10.3 Modeling Width
complexity belief tracking algorithms function width causal width
problem, turns depends way problem encoded. Often small
changes encoding drastic effect resulting widths. example,
Wumpus problem (Russell & Norvig, 2009), natural define conditions
stench signal received setting observation model to:

W
W
Wa (stench = true) = c (pos = c) c0 wumpc0
pos encodes agent position, c ranges possible cells, c0 ranges cells
adjacent c, wumpc0 denotes presence wumpus c0 . encoding,
however, results beam observable variable stench includes wumpc
942

fiBelief Tracking Planning Sensing

szx,y

hitx,y

waterx,y

nhitsx,y

ancx,y

hzx,y

Figure 3: Causal graph fragment Battleship. Circled variables observable
others state variables. problem one type variable cell (x, y)
grid. Causal width problem 5.
variables, hence whose size grows grid size. better alternative results
beams bounded causal width exploit fact position agent pos
determined. Taking advantage this, observable variable stench replaced
observable variables stenchc , one cell grid, sensors characterized
model:
Wa (stenchc = true) = (pos = c)

W

c0

wumpc0 .

beams stenchc variables contain four wumpc0 variables, one cell
c0 adjacent c. way, causal width Wumpus problem becomes bounded
independent grid size, number wumpus pits (see below).
idea
W generalized automated. observation model form Wa (Z =
z) = x (x) (x), (x) formula constructed determined variables,
replaced observation models Wa (Zx = z) = (x) (x) expanding
number observable variables. Likewise, multiple observation models Wai (Z = z) =
one observable variable Z different actions {ai }iR conveniently replaced
observation models Wai (Zi = z) = , R different observable variables Zi ,
different formulas involve different variables. alternatives domain encoding
difference bounded unbounded causal width, hence, whether
complexity beam tracking grow polynomially exponentially.

11. Experiments
tested beam tracking large instances Battleship, Minesweeper, Wumpus, combination simple heuristics action selection make use computed beliefs. width problems bounded, hence, neither factored
causal belief tracking used except small instances. hand,
domains small bounded causal widths encodings provided, hence
beam tracking runs efficiently time space. Exact belief tracking
domains difficult (Kaye, 2000; Scott, Stege, & Rooij, 2011), sizes
instances considered much larger used contingent planning. Moreover,
domains full contingent solutions. thus compare on-line
planner relies handcrafted heuristics two reported solvers rely belief
tracking algorithms tailored domains. also consider non-deterministic version
Wumpus domain. results obtained Xeon Woodcrest 5140 CPU
running 2.33 GHz 8GB RAM.
943

fiBonet & Geffner

11.1 Battleship
Battleship popular two-player guessing game. standard version consists four
ships length 2, 3, 4 5 units secretly placed 10-by-10 grid, ship
adjacent diagonally adjacent another. task sink ships firing torpedos
specific cells. fired torpedo, told whether torpedo hits water ship.
ship sunk cells hit. problem encoded 6 state variables
per cell (x, y):6 hitx,y tells torpedo fired cell, szx,y tells size
ship occupying cell (0 ship), hzx,y tells ship placed horizontally
vertically (true ship), nhitsx,y tells number hits ship (0
ship), ancx,y tells relative position ship cell (0 ship).
single observable boolean variable water deterministic sensor model given
Wf ire(x,y) (waterx,y = true) = (szx,y = 0). action model complex firing
torpedo (x, y) may cause change variables associated cells (x0 , 0 ).
Indeed, denotes maximum size ship (5 standard game), f ire(x, y)
includes conditional effects variables referring cells (x0 , 0 ) vertical
horizontal distance units. goal problem achieve equality
nhitsx,y = szx,y cells may contain ship. State constraints used
constraining sets state variables described above. encoding, causal beams
never contain 5 variables, even though problem width bounded
grows grid size. Figure 3 shows fragment causal graph Battleship.
Table 2 shows results two policies: random policy fires non-fired cell
random, greedy policy fires non-fired cell likely contain ship.
Approximations probabilities obtained beliefs maintained beam
tracking.7 difference performance two policies shows beliefs
informative. Moreover, 10 10 game, agent fires 40.0 6.9 torpedos
average, matching quite closely average results Silver Veness (2010)
obtained combination UCT (Kocsis & Szepesvari, 2006) action selection,
particle filter (Doucet et al., 2000) hand-tuned domain belief tracking.
approach, however, involves 65,000 simulation per action result order 2 seconds
per game 10 10 instances, greedy approach takes 0.0096 seconds per game.
11.2 Minesweeper
objective Minesweeper clear rectangular minefield without detonating mine.
play either opens flags cell. first case, cell contains mine, game
terminated; otherwise integer counting number mines surrounding cell
revealed. initial configuration minesweeper consists n minefield k
randomly-placed mines. three standard difficulty levels game
made 8 8, 16 16 16 30 boards 10, 40 99 mines respectively.
6. rich encoding allows accommodate observation ship fully sunk.
experiments, however, observation used order compare results reported
Silver Veness (2010).
7. Probabilities events defined variables beam obtained ratio number states
beam satisfy event total number states beam.

944

fiBelief Tracking Planning Sensing

avg. time per
dim

policy

#ships

#torpedos

decision

game

10 10
20 20
30 30
40 40

greedy
greedy
greedy
greedy

4
8
12
16

40.0 6.9
163.1 32.1
389.4 73.4
723.8 129.2

2.4e-4
6.6e-4
1.2e-3
2.1e-3

9.6e-3
1.0e-1
4.9e-1
1.5

10 10
20 20
30 30
40 40

random
random
random
random

4
8
12
16

94.2 5.9
387.1 13.6
879.5 22.3
1,572.8 31.3

5.7e-5
7.4e-5
8.5e-5
9.5e-5

5.3e-3
2.8e-2
7.4e-2
1.4e-1

Table 2: Results Battleship. table contains results greedy random
policies described text. 10 10 board, 4 ships sizes 2, 3, 4 5.
size board increased n, number ships size gets multiplied
n. Average sample standard deviation number torpedos required sunk
ships, calculated 10,000 random instances board, shown. Average times
seconds.

problem encoded 3mn boolean state variables minex,y , openedx,y
f laggedx,y denote presence/absence mine cell (x, y) whether cell
opened flagged, mn observable variables obsx,y domain = {0, . . . , 9}.
two type actions open(x, y) f lag(x, y) first precondition effect f laggedx,y openedx,y , second precondition minex,y
effect f laggedx,y . sensor model given formulas specify integer
agent receives opening cell terms status minex0 ,y0 variables
surrounding cells. formulas are:
Wopen(x,y) (obsx,y = 9) = minex,y ,
Wopen(x,y) (obsx,y = k) = minex,y

W

tN (x,y,k) ,

0 k < 9 ,

Wopen(x,y) (obsx0 ,y0 = k) = true ,

(x0 , 0 ) 6= (x, y) 0 k 9 ,

Wf lag(x,y) (obsx0 ,y0 = k) = true ,

(x0 , 0 ) 0 k 9 ,

N (x, y, k) terms 8 cell variables minex0 ,y0 surrounding cell (x, y)
make exactly k literals true. initial situation, variables openedx,y
f laggedx,y false minex,y unknown. goal problem get disjunction f laggedx,y openedx,y cell (x, y) without triggering explosion.
beams result factored decomposition contain 3mn state variables, making beams identical resulting unbounded width 3mn. causal
width, hand, 9 causal beams openedx,y f laggedx,y identical
contain 3 variables, beams obsx,y contain 9 minex0 ,y0 variables
cells (x0 , 0 ) surround cell (x, y) along variable minex,y . Figure 4
contains fragment causal graph Minesweeper.
945

fiBonet & Geffner

minex0 ,y0

minex,y

f laggedx,y

openedx,y

obsx,y
Figure 4: Sketch causal graph Minesweeper. observable variables obsx,y
state variables minex,y , f laggedx,y openedx,y cell (x, y). cell (x0 , 0 )
represents one adjacent cells (x, y). Since 8 cells, causal width
problem 9.
avg. time per
dim

#mines

density

%win

#guess

decision

game

88
16 16
16 30
32 64

10
40
99
320

15.6%
15.6%
20.6%
15.6%

83.4
79.8
35.9
80.3

606
670
2,476
672

8.3e-3
1.2e-2
1.1e-2
1.3e-2

0.21
1.42
2.86
2.89

Table 3: Results Minesweeper. table contains results three standard levels
game plus larger instance. Average results 1,000 runs shown. Average
times seconds.

Table 3 shows results three standard levels game much larger
instance. Battleship, greedy policy used action selection makes use beliefs
computed beam tracking, flagging opening cell certain content, else
selecting cell lowest probability containing mine opening it,
probabilities approximated beliefs beams indicated before. Despite
complexity game, NP-complete checking consistency (Kaye, 2000) coNPcomplete inference (Scott et al., 2011), beam tracking scales well solves difficult
games quickly. Moreover, results shown table competitive recently
reported Lin, Buffet, Lee, Teytaud (2012), obtained combination
UCT action selection, domain-specific CSP solver tracking beliefs. success
ratios report are: 80.2 0.48% 8 8 instances 10 mines, 74.4 0.5%
16 16 instances 40 mines, 38.7 1.8% 16 30 instances 99
mines. authors report times.
11.3 Wumpus
Wumpus game (Russell & Norvig, 2009) consists maze agent
moves around looking gold avoiding hidden pits wumpus monsters.
Initially, agent know positions gold, pits wumpuses, senses
glitter cell gold, senses stench breeze adjacent
cell wumpus pit respectively. n instance described known state
variables position orientation agent, hidden boolean variables
cell tell whether pit, wumpus, nothing cell. One
946

fiBelief Tracking Planning Sensing

heading
gold-pos

pos

pitx0 ,y0

wumpx0 ,y0

glitter

deadx0 ,y0

breezex,y

stenchx,y

Figure 5: Fragment causal graph Wumpus. observable variables
breezex,y , stenchx,y deadx,y , state variables heading, pos, pitx,y wumpx,y ,
(x, y) ranging grid cells. Cells (x0 , 0 ) stand cells adjacent (x, y).
causal width problem 4 4 cells, state variables heading
pos determined.
hidden state variable stores position gold. observable variables boolean:
glitter, breezex,y , stenchx,y deadx,y , (x, y) ranging different cells.
actions move forward, rotate right left, grab gold. causal width
encoding 4 problem width grows n. Figure 5 shows fragment
causal graph Wumpus. size causal beams breeze stench
variables bounded 4 cell 4 neighbors heading
position variables agent determined.
Table 4 shows results different grid sizes number pits wumpus,
agent selects actions greedy policy based heuristic returns length
minimum-length safe path nearest cell may contain gold. beliefs
computed beam tracking used determine cells safe (known contain
wumpus pit) may contain gold. aware tested
scalable solver Wumpus making comparison, exception recent
LW1 planner built work (Bonet & Geffner, 2014). figures table
show clearly beam tracking computes beliefs effectively efficiently domain.
instance, 30 30 instances 32 pits 32 wumpus solved successfully 89%
time, less 4.4 seconds average. Moreover, unsolved instances
actually shown unsolvable sense agent could reach unvisited
cell safe manner. proved unsolved instance calling SAT solver
propositional theory encodes game literals learned agent
execution.
11.4 Non-Deterministic Moving Wumpus
order evaluate beam tracking complex non-deterministic domain (the NONDET-Ring-Key domain Section 7 small width), designed non-deterministic
variant Wumpus domain. Moving Wumpus one wumpus grid
wumpus moves around non-deterministically everytime agent moves.
grid still contains hidden pits hidden gold, order make game safer
agent, wumpus sensor enhanced detect position wumpus
(euclidean) distance less 3 agent (else safe strategy escaping
death general).
947

fiBonet & Geffner

avg. time per
dim

#pits/#wumpus

%density

#decisions

%win

decision

game

55
10 10
15 15
20 20
25 25
30 30
35 35
40 40
45 45
50 50

1/1
2/2
4/4
8/8
16 / 16
32 / 32
64 / 64
128 / 128
256 / 256
512 / 512

8.0
4.0
3.5
4.0
5.1
7.1
10.4
16.0
25.2
40.9

22,863
75,507
165,263
295,305
559,595
937,674
2,206,905
4,471,168
6,026,625
7,492,503

93.6
98.3
97.9
97.8
94.0
89.0
54.3
7.3
0.8
0.1

3.8e-4
9.6e-4
1.6e-3
2.4e-3
3.8e-3
4.7e-3
3.7e-3
2.8e-3
8.6e-3
1.3e-2

8.7e-3
7.2e-2
2.6e-1
7.2e-1
2.1
4.4
8.2
12.7
51.8
100.4

Table 4: Results Wumpus. size, performed 1,000 runs. table shows
total number density pits wumpus grid, total number decisions
across runs, percentage runs agent found gold, average
time seconds per decision game.

Moving Wumpus causally decomposable thus incompleteness beam tracking
domain due replacement full consistency among beams done
CBT weaker efficient (relational) arc consistency done beam tracking.
see this, observe variable memory variable position
wumpus WLoc. However, two beams causal decomposition
contain variable: beam WLoc beam observable variable
tells position wumpus, former beam contained latter beam.8
Experimental results beam tracking domain presented Table 5
policy obtained using AOT lookahead algorithm based AO* (Bonet & Geffner, 2012a)
builds lookahead tree depth 10 using 50 expansions, heuristic function
measures distance agent position closest unvisited cell.
algorithm evaluated different instances grids nn n = 4, 6, 8, . . . , 20,
number pits equal (n 4)/2. grid size, performed 1,000
evaluations different initial configurations wumpus, pits gold randomly
placed. instance game may turn unsolvable gold isolated
agent pits, agent finds position safe movement,
agent exceeded maximum number actions (set 3 times number
cells grid).

8. Indeed, general version problem involves wumpuses move non-deterministically
grid. version also causally decomposable beams positions wumpuses
(one wumpus) contained beam observable variable. general case,
problem would causal width equal m.

948

fiBelief Tracking Planning Sensing

avg. time per
dim

#pits

%density

#decisions

%win

decision

game

44
66
88
10 10
12 12
14 14
16 16
18 18
20 20

0
1
2
3
4
5
6
7
8

0.0
2.7
3.1
3.0
2.7
2.5
2.3
2.1
2.0

13,770
30,666
54,528
85,635
123,921
159,977
231,307
309,919
362,816

97.6
95.0
94.8
93.0
93.6
93.4
91.7
90.0
90.8

3.5e-2
1.6e-1
4.1e-1
8.5e-1
1.3
2.2
3.1
4.1
5.3

4.9e-1
5.1
22.7
73.5
173.4
352.4
722.0
1,282.3
1,942.8

Table 5: Results Non-Deterministic Moving Wumpus domain. grid size,
averages 1,000 runs shown. table shows total number density pits
grid, total number decisions across runs, percentage runs
agent found gold, average time seconds per decision game.

12. Related Work
formulation paper closely related recent translation-based approaches
conformant contingent planning compile beliefs away (Palacios & Geffner, 2009;
Albore et al., 2009). translations, however, assume problems deterministic.
account yields similar widths deterministic benchmarks,
simpler, defined multi-valued variables, general,
handles non-deterministic actions. Yet account also less tight deterministic problems. illustration, = {x1 xn } actions ai ,
conditional effect xi G, = 1, . . . , n, conformant problem goal G width
1 Palacios Geffners account, width n ours. relevance account based
literals indeed finer one based variables also difficult
generalize non-deterministic settings. difference seem practical
effects benchmarks disjunctions initial situation exclusive
implicitly encode possible values set multi-valued variables. Another important
difference approaches complete translations always exponential
problem width, complexity bound worst case; i.e., variables contexts
highly correlated, actual complexity factored belief tracking much lower.
notion width appears also Bayesian networks inference exponential
width network (Pearl, 1988). Three differences pointed
relation notion width 1) exploit knowledge certain variables
observable, 2) determine use knowledge certain variables
determined, 3) make use distinction action conditions preconditions planning. example, problem agent go n doors
whose status, open closed, observed agent near door,
width smaller n modeled dynamic Bayesian network, door
variables affect agent location variable. setting, however, problem width
949

fiBonet & Geffner

1 status door need known agent open, close
walk door.
causal decomposition resulting causal belief tracking algorithms similarly related ideas variable splitting renaming graphical models,
variable X appearing different factors fi replaced different variables Xi , one per
factor fi (Choi & Darwiche, 2006; Ramirez & Geffner, 2007), problem width
reduced. Then, equality constraints relating Xi variables must enforced.
Approximate belief tracking algorithms dynamic bayesian networks POMDPs
also appealed idea decomposing global beliefs variables local beliefs subsets variables (Boyen & Koller, 1998; Shani, Poupart, Brafman, & Shimony,
2008). key difference causal belief tracking algorithm provide
conditions type decomposition remains sound complete.
hand, deal uncertainty represented sets states, probability
distributions.
number logical schemes representing tracking beliefs used
developed contingent planning, appealing OBDDs, CNF, DNF representations
(Bertoli et al., 2001; Bryce et al., 2006; et al., 2011), relevance considerations (Tran,
Nguyen, Son, & Pontelli, 2013), lazy SAT regression techniques (Hoffmann & Brafman, 2005; Rintanen, 2008; Shani & Brafman, 2011). None approaches, however,
tried domains considered paper instances similar size.
Indeed, causal width domains bounds complexity beam tracking, similar bound known schemes unlike beam tracking complete.
Moreover, principle schemes handle non-determinism naturally,
methods like based SAT not. K-replanner (Bonet & Geffner, 2011) also
based efficient effective belief tracking method polynomial
fully general cannot deal non-deterministic actions. follow LW1 planner
(Bonet & Geffner, 2014) shares features K-replanner complete width-1
problems.
experimental perspective, several comments questions order
relation beam tracking algorithms used belief tracking contingent
planners existing benchmarks. First all, practically benchmarks used
far contingent planning easy belief tracking point view. Indeed,
quadratic linear time representation beliefs CLG LW1 respectively,
shown adequate problems, including Wumpus problems above.
exception Minesweeper, belief tracking provably NP-hard
linear approximation LW1 turns much weaker beam tracking, failing
solve without guessing instances beam tracking solve
way (Bonet & Geffner, 2014). means that, whether width problems
low high, effective width 1, cases, beam tracking cannot help
computationally, actually, may degrade performance (except Minesweeper), beam
tracking exponential problem causal width, lower width general
usually higher 1. effective width problem P minimum non-negative
integer value contingent translation Xi (P ) (Palacios & Geffner, 2009; Albore
et al., 2009) solution. effective width problem never greater width
much smaller width causal width. example,
950

fiBelief Tracking Planning Sensing

avg. time per
dim

#mines

%density

%succ

%failure

%aborted

decision

game

88
16 16
30 16

10
40
99

15.6
15.6
20.6

93.0
94.0
65.0

7.0
6.0
6.0

0.0
0.0
29.0

0.8
4.9
12.4

56.3
1,268.4
5,998.6

Table 6: Comparison SDR on-line planner Minesweeper instances. SDR fed
random hidden states solutions (action sequences) computed beam tracking
guessing. planner task check applicability actions given
solution whether goal holds. instance size, SDR tested 100 different
random problems. column failure indicates number times SDR able
verify correct solution, column aborted indicates number times
SDR terminated early due bug. Times seconds. Beam tracking takes
seconds solving instances (see Table 3).

problem actions ai conditional effects map valuations vi set variables
X1 , . . . , Xn goal literal = y, width causal width smaller
n variables Xi causally relevant . Yet effective width
problem may 1 values Xi variables observed directly
inferred observations, also, goal achieved without using
actions all. sense, notion effective width provides lower bound
number state variables whose uncertainty must tracked jointly order make
problem solvable, notions width, characterized syntactically, provides upper
bound number state variables whose uncertainty must tracked jointly
solution would missed. gap two bounds large indeed,
obtaining syntactic characterizations former open problem.
related question various belief tracking algorithms used contingent planning regression, OBDDs, CNF, DNF, scale domains.
general comparison complete exponential algorithms incomplete polynomial algorithms like beam tracking (over domains bounded causal width) would
fair, would still interesting find easy cases algorithms scale polynomially exponentially. Performing tests, however,
simple, requires getting code planners would
follow fixed common policy instance, thus leaving planning component aside.
Moreover, even fixing policy instance, enough, planners
off-line hence track beliefs many possible executions one,
case on-line planners.
purpose illustration performed test one difficult
domains, Minesweeper, supplying on-line planner SDR (Shani & Brafman, 2011)
execution computed beam tracking along hidden initial state
execution. setting, on-line planner SDR planning, rather
tracking beliefs problem verify goal achievement preconditions
given applicable action time point. Minesweeper instances solved
951

fiBonet & Geffner

beam tracking without guessing; i.e., pure inference first fixed choice. Table 6
shows results SDR tracks beliefs using form regression (Rintanen, 2008;
Shani & Brafman, 2011). Two observations made comparing results
table Table 3 beam tracking. First, SDR takes 56.3, 1,268.4
5,998.6 seconds average verifying solutions 8 8, 16 16 30 16 instances
respectively, beam tracking takes 0.21, 1.42 2.86 seconds finding solutions
following greedy policy. Since finding solutions expensive verifying
one must least identify applicable actions time point difference
performance turns several orders magnitude, growing grid size.
addition, regression mechanism SDR fails verify correct solutions several cases
aborts failure large number cases large instances. case,
performance gap surprising: belief tracking Minesweeper NP-hard, thus
complete algorithms like regression run exponential time worst case,
beam tracking remains polynomial causal width domain bounded.
challenging problems, gap performance beam tracking complete belief
tracking algorithms similar. Beam tracking useful causal width
problem bounded large, trading principled way completeness
tractability.

13. Summary
Effective belief tracking crucial planning incomplete information sensing.
problem intractable general, shown elsewhere belief tracking deterministic problems exponential width parameter often bounded
small. work, introduced related formulation applies nondeterministic problems well. factored belief tracking algorithm results set
projected problems whose size bounded problem width. beliefs goals
preconditions obtained directly beliefs projected problems
maintained independently. developed different decomposition
scheme belief tracking algorithm maintains beliefs smaller projections,
provided conditions algorithm complete. Causal belief tracking
space exponential problem causal width remains time exponential problem width, global consistency beliefs smaller projections need
enforced. Finally, beam tracking sound incomplete approximation causal belief
tracking global consistency replaced local powerful form consistency.
Beam tracking runs time space exponential problem causal width
often much smaller problem width. tested beam tracking large
instances Battleship, Minesweeper, Wumpus, combination simple heuristics
action selection, performance compares well state-of-the-art solvers
using orders-of-magnitude less time. future, would like explore extensions
proposed framework belief tracking POMDPs, belief states sets
states probability distributions, particle-based algorithms provide common
approximation (Doucet et al., 2000).
952

fiBelief Tracking Planning Sensing

Acknowledgments
thank Gabriel Detoni Java Tewnta framework (http://code.google.com/p/
tewnta) implementing client/server games graphical interface developed graphical interfaces Battleship, Minesweeper Wumpus. Thanks also
James Biagioni wumpuslite JAVA simulator (http://www.cs.uic.edu/~jbiagion/
wumpuslite.html) adapted run experiments Wumpus, Guy Shani
help running SDR. Hector Geffner partially supported EU FP7 Grant# 270019
(Spacebook) MICINN CSD2010-00034 (Simulpast).

Appendix A. Proofs
Formal results needed stated propositions theorems
main text article appear form lemmas.
A.1 Complexity Flat Belief Tracking
Let us first formally define decision problems BTP GBTP. BTP language
BTP = {hP, : P contingent problem, possible execution, b |= G}
P = hV, I, A, G, V 0 , W i, = ha0 , o0 , . . . , , execution, b belief
results execution initial belief state. GBTP like BTP except
consists triplets hP, , `i P contingent problem, possible generalized
execution, ` goal, precondition observation literal, b |= `.
Observe BTP GBTP respectively include tuples hP, hP, , `i
problem empty initial belief state, due two complementary literals appearing unit clauses I, since case every execution trivially possible b
trivially entails literal `.
Proposition 3. BTP polynomial-time reducible GBTP.
Proof. idea map normal execution generalized execution results
replacing pair ha, oi sequence ha, `1 , noopa , `2 , . . . , noopa , `|V 0 |
`1 , . . . , `|V 0 | observation literals made true o, one observable variable
V 0 , noopa action requires nothing nothing whose sensor
model Wnoopa (`) = Wa (`) observation literal `.
Formally, given instance hP, BTP, reduction must generate polynomial
time instance hP 0 , 0 , `i GBTP hP, BTP iff hP 0 , 0 , `i GBTP.
problem P 0 problem P extended actions noopa , new boolean
variable Xgoal denotes achievement goal G P , new action agoal
precondition G effect Xgoal , new dummy observable variable domain
{>} models Wa (Y = >) = true actions a. hand, generalized
execution 0 hm , agoal , = >i ` = Xgoal . Clearly, reduction works polynomial
time hP, BTP iff hP 0 , 0 , `i GBTP.
Theorem 5. Flat belief tracking exponential |VU |, VU = V \ VK VK
set state variables V determined.
953

fiBonet & Geffner

Proof. described Definition 4, flat belief tracking consists explicit representation
beliefs set states, savings space time obtained noting
variables VK determined.
explicit representation beliefs, belief tracking problem gets trivially solved
checking whether execution = ha0 , o0 , . . . , , possible literal `
true reduces computing belief bn+1 results checking whether
bn+1 empty whether every state satisfies `. time complexity algorithm
time needed compute initial belief b0 plus (n + 1) multiplied time needed
compute bi+1 bi plus time needed check validity `. Among times,
last easiest calculate linear size bn+1 . thus need bound
first two times. begin proof showing flat belief tracking done
time exponential |V | reduce exponential dependency |V | |VU |.
computing b0 enough generate possible states (valuations variables)
filter satisfy clauses I. total time thus spent
|V | |I| 2O(|V |) since 2O(|V |) valuations, |I| clauses, clause
|V | literals.9
time compute bi+1 bi consists time check preconditions
hold b, times compute ba b boa ba b = bi , = ai
= oi . preconditions easily verified iterating states b. time
bounded |V | 2O(|V |) since contains |V | preconditions b contains
2O(|V |) states. precondition satisfied state b, execution
possible.
belief ba computed b iterating state b,
possible state s0 ba , checking whether s0 F (a, s). two nested
iterations require time 2O(|V |) 2O(|V |) = 2O(|V |) . test s0 F (a, s) performed
time exponential |V | follows. Let Ci E1i | |Eni , 1 m,
collection conditional effects action trigger state s. s0 F (a, s),
s0 result applying one head conditional effect s. Since
problem |V | variables, among heads |V | heads map
s0 rest (if any) subsumed first. subsets heads size
|V | enumerated 2O(|V |) time, subset checking whether gets
mapped s0 requires O(|V |) time. Therefore, checking s0 F (a, s) requires 2O(|V |) time
well computing ba b.
ba obtained, boa calculated removing (filtering) ba states
comply observation o. state ba observation literal
` compatible o, state belongs boa iff |= Wa (`). latter test
performed time linear |Wa (`)|, size formula Wa (`). Hence, since
|V 0 | observation literals compatible o, boa computed ba time O(|ba |
|V 0 | |Wa |) |Wa | = max` |Wa (`)| max ranges observation literals `.
boa empty ba non-empty, execution possible.
9. calculation, implicitly assume variable domains constant size. Otherwise,
domains size n linear input size, number valuations bounded 2O(|V | log n)
instead 2O(|V |) . either case, number valuations still exponential number variables
well resulting complexity flat belief tracking.

954

fiBelief Tracking Planning Sensing

times weighed in, see flat belief tracking done time
exponential |V |.
reduce exponent |V | |VU |. direct since determined
variable valuation across states reachable belief. Hence, variables
contribute increase number states reachable beliefs. Likewise,
subsets heads size |VU | need considered computing belief ba b.
Hence, computations done time space exponential |VU |.
Theorem 6. BTP GBTP Turing complete class PNP .
Proof. Proposition 3, BTP polynomial-time reducible GBTP, thus enough
show hardness BTP inclusion GBTP.
class PNP set decisions problems decided (deterministic)
polynomial time using oracle SAT. show BTP hard class,
enough show UNSAT reduced polynomial time BTP since every
call NP oracle replaced call BTP oracle. hand,
show GBTP belongs PNP , enough show algorithm
complement GBTP (since PNP closed complementation) runs polynomial
time makes calls oracle SAT.
Hardness. Let = {C1 , . . . , Cm } CNF theory boolean variables X1 , . . . , Xn .
need construct polynomial time contingent problem P = hV, I, A, G, V 0 , W
execution hP, BTP iff unsatisfiable. variables
problem P boolean given V = {X1 , . . . , Xn , Q} V 0 = {Z1 , . . . , Zm }.
empty set clauses G = {Q = true}. actions a1 , . . . , , empty
preconditions conditional effects, sensor model Wai (Zi = true) = Ci Q
Wai (Zj = true) = f alse j 6= i. Finally, execution = ha1 , o1 , . . . , , om
oi V 0 -valuation makes Zi true Zj false j 6= i.
Note initial belief contains 2n+1 V -valuations, half satisfying
Q half Q. first observation o1 received, valuations
satisfy clause C1 Q preserved. Thus, inductively, observation oi
received, valuations satisfy clauses {C1 , C2 , . . . , Ci } Q preserved.
Therefore, b set valuations satisfy Q hence non-empty (i.e.,
possible execution). Thus, b |= G iff valuations Q gone iff unsatisfiable.
Inclusion. complement GBTP consists tuples hP, , `i b0 non-empty
either non-executable b 6|= `. Since consists unit clauses, b0 6= iff
contains pair complementary literals. Assume = ha0 , `0 , a1 , `1 , . . . , , `n i,
literals `i observation literals, let bi belief action ai
applied; i.e., bi = boa b = bi1 , = ai1 = `i1 . Then, possible iff
bi non-empty action ai applicable bi . Assume established
prefix = ha0 , `0 , . . . , ai1 , `i1 possible, checking whether i+1 possible
involves two operations: 1) checking precondition literal ai holds bi1
2) checking whether least one state bai complies `i , b = bi1 .
first check done calling SAT oracle CNF theory i1 ,
time-indexed propositions state-variable literals actions, encodes possible
state trajectories fixed valuation actions. time horizon theory
955

fiBonet & Geffner

= 0, . . . , 1, theory built way satisfiable iff state
time (i.e., bi1 ) satisfy least one precondition ai . theory
polynomial size built polynomial time. Likewise, second check
performed calling SAT oracle CNF theory i1 property
satisfiable iff state bi1 complies observation `i .
Hence, algorithm decides complement GBTP works building theories
= 0, . . . , n. stage t, ACCEPTs input satisfiable
unsatisfiable. If, end, algorithm accepted yet, builds another theory
n+1 , like instead checking whether precondition action ai doesnt
hold, checks whether input literal ` doesnt hold. n+1 satisfiable, ACCEPTs
since belief b satisfy `, else REJECTs hP, , `i GBTP.
A.2 Factored Belief Tracking
following, state (valuation variables) subset variables, write
s|S denote valuation restricted variables S, also called projection
S. general, use symbols s, primed versions denote states,
symbols u, v primed versions denote projected states (restrictions
partial valuations).
Proposition 9. Belief tracking deterministic non-deterministic conformant setting exponential maximum number non-determined variables causally
relevant variable appearing action precondition goal.
Proof. proposition special case Theorem 15 (and also Theorem 33).
Theorem 15. Belief tracking P exponential w(P ).
Proof. conformant setting, observable variables hence evidential
relevance relation empty relevant relation equals causally relevant relation.
Therefore, context variable X equals set variables causally relevant
X, theorem establish Proposition 9 conformant setting.
general setting, theorem shown constructing algorithm belief
tracking whose time complexity exponential w(P ). definition analysis
algorithm done series claims terminate Theorem 22 below.
Proposition 18. variable X appears goal precondition, number state
variables PX determined bounded w(P ).
Proof. number state variables PX |Ctx(X)| number state variables
determined PX |Ctx(X) VU |. definition width, quantity
less equal w(P ) X goal precondition variable.
establish two fundamental lemmas progression actions projection observable models. following, say subset variable causally
closed variable X variable causally relevant X, S.
Likewise, causal closure variable Z minimum (with respect set inclusion)
subset variables causally closed includes Z.
956

fiBelief Tracking Planning Sensing

Lemma 1 (Factored Progression). Consider consistent problem P . Let state,
action applicable s. Then, causally-closed subset variables:
1) every u0 , u0 FS (a, s|S ) s0 F (a, s) u0 = s0 |S ,
2) every s0 , s0 F (a, s) s0 |S FS (a, s|S )
FS transition function projected problem PS . Therefore, F (a, s) =
FS (a, s|S ) every state applicable, F (a, U ) = FS (a, U ) every
set U valuations applicable.
Proof. Part 1. Let u0 element FS (a, s|S ) let HS = {ESi }m
i=1 collection
heads conditional effects CSi ESi trigger s|S result u0 .
fixed {1, . . . , m}, know s|S |= CSi . ESi 6= then, definition causally
relevant relation, V ars(C ) thus CSi = C . Therefore, |= C effect also
triggers applied s. show effect affects variable
triggers applied s. Indeed, conditional effect C F affects
variable triggers, |= C thus s|S |= CS FS HS . Finally, effects
trigger affect variables problems P PS . Since P
consistent, set effects {E }m
i=1 contained set H heads effects
trigger applied s. Therefore, u0 projection state s0
results applying effects H s; i.e., u0 = s0 |S .
Part 2. Let s0 element F (a, s) let H = {E }m
i=1 collection heads
conditional effects C E trigger result s0 . fixed {1, . . . , m},
know |= C thus s|S |= C |S . Therefore, effects CSi ESi also trigger
applied s|S PS . show effect affects variable
triggers applied s|S PS . Indeed, let us suppose projected conditional
effect CS FS affects variable triggers s|S . Then, V ars(F ) thus
V ars(C) S, since causally closed, CS = C. Therefore, |= C effect
also triggers applied s. Finally, since effects trigger affect
variables problems P PS , s0 |S result applying
0
projected effects {ESi }m
i=1 s|S ; i.e., |S FS (a, s|S ).
Lemma 2 (Observational Closure). every variable X, action a, observation literal
` = Z = z, Wa (`)S either Wa (`) true, = Ctx(X).
Proof. Let {X1 , . . . , Xn } variables Wa (`). definition relevant relation,
Z relevant Xi vice versa. Hence, Z Xi belongs S, Z
Xi belongs well. Therefore, Wa (`)S either Wa (`) true.
following results obtained induction length executions.
noted before, loss generality consider generalized executions instead
executions. However, easier consider even general executions correspond
finite sequences alphabet {ha, `i : A, ` Lits(V 0 )}
set actions Lits(V 0 ) set observation literals. type executions
general require interleaving actions observations; i.e.,
execution may contain multiple actions observations sequence. example,
957

fiBonet & Geffner

execution like ha0 , a1 , ha2 , `2 i, ha3 , `3 i, . . .i indicates initial belief needs
progressed actions a0 a1 , filtered formula Wa2 (`2 ), filtered
formula Wa3 (`3 ), on. case normal generalized executions,
direct mapping generalized executions new type executions.
one execution, b denotes belief results applying initial
belief, b = b , ba ba,` denote beliefs result executions
0 = h, ai 0 = h, ha, `ii respectively. Therefore, making induction
length executions prove claim, need show claim initial belief
corresponds empty execution, beliefs form ba ba,` b = b .
next definition lemma make precise notion decomposable belief
plays fundamental role results. Intuitively, belief b decomposable
every pair states s, b, state w b agrees variables
subset agrees variables subset (where certain
subsets variables); symbols, w b w|S = s|S w|T = t|T .
Definition Lemma 3 (Decomposability). belief state b decomposable iff
every variable X, observation literal ` = Z = z, action a, subset V ars(Wa (`))
causally closed Ctx(X) = , holds:


s, s, b = w w b w|Ctx(X) = s|Ctx(X) w|T = t|T .
turns every reachable belief decomposable.
Proof. Let b reachable belief. Then, execution b = b .
proof induction length . empty, claim holds since contains
unit clauses Ctx(X) = .
Assume beliefs reachable executions length less equal
n decomposable, consider execution 0 length n + 1 augments
execution length n. following, b denotes belief b , res(a, s) denotes
state results applying deterministic action state s.
Case: 0 = h, a0 i. Let X, `, statement lemma, = Ctx(X),
let s0 , t0 two states ba0 . Therefore, two determinizations a1 a2
a0 s0 = res(a1 , s) t0 = res(a2 , t) s, b. Apply inductive hypothesis
obtain w b w|S = s|S w|T = t|T . Since disjoint
causally closed, determinization10 a3 a0 res(a1 , s)|S = res(a3 , w)|S
res(a2 , t)|T = res(a3 , w)|T . sought w0 ba0 thus w0 = res(a3 , w).
Case: 0 = h, ha0 , `0 ii. before, let X, `, statement lemma,
0 0
let `0 = Z 0 = z 0 , let s0 , t0 two states ba ,` . consider two subcases whether
V ars(Wa0 (`0 )) not, = Ctx(X):
Subcase: V ars(Wa0 (`0 )) S. Since, s0 , t0 b, apply inductive hypothesis get w0 b
0 0
w0 |S = s0 |S w0 |T = t0 |T . Then, w0 ba ,` w0 |S = s0 |S |= Wa0 (`0 )S =
Wa0 (`0 ).
10. existence determinization granted second assumption planning problem
fact sets variables disjoint.

958

fiBelief Tracking Planning Sensing

Subcase: V ars(Wa0 (`0 )) * S. Lemma 2, V ars(Wa0 (`0 )) = . Let 0 minimal
causally-closed subset variables includes V ars(Wa0 (`0 )). Observe 0 =
since belongs intersection, Z 0 relevant , relevant X, thus
Z 0 relevant X contradicting V ars(Wa0 (`0 )) = . Apply inductive hypothesis
using 0 get w0 b w0 |S = s0 |S w0 |T 0 = t0 |T 0 . w0
0 0
looking 0 thus w0 |T = t0 |T , w0 ba ,` since
w0 |T 0 = t0 |T 0 |= Wa0 (`0 )T 0 = Wa0 (`0 ).
last technical lemma, giving proofs Theorems 20 22, establish
existence partial valuations projection filtered beliefs following:
Lemma 4 (Factored Filtering). Let X variable, = Ctx(X), b reachable belief,
action, ` = Z=z observation literal. ba,` non-empty u
u b u |= Wa (`)S , u ba,` .
Proof. Assume ba,` non-empty let u S-valuation satisfies antecedent lemma. Wa (`)S = Wa (`), u |= Wa (`) u ba,` .
Wa (`)S 6= Wa (`) Lemma 2, V ars(Wa (`)) = . Let minimal
causally-closed subset variables includes V ars(Wa (`)). Note
Z evidentially relevant relevant X, thus Z relevant X
V ars(Wa (`)) S. Therefore, = . Let ba,` b apply Lemma 3 get
w b w|S = u w|T = t|T . Hence, w|T |= Wa (`)T = Wa (`), w ba,`
u ba,` .
Theorem 20. state variable X, let b bX beliefs result execution
possible P PX . Then, X bX = X b.
Proof. Let execution possible P PX . prove
general result bX = b = Ctx(X); general X
X bX = X b = X b. proof induction length . empty
execution, result follows readily since contains unit clauses. Assume
claim holds executions length n, let 0 execution length n + 1
augments execution length n possible P PX . Further, let b
bX beliefs result P PX respectively. Then, inductive
hypothesis bX = b.
Case: 0 = h, ai. need show bX,a = ba . following, FS denotes
transition function PX . forward inclusion given


1
u0 bX,a = u u bX u0 FS (a, u)


2
= us u bX u0 FS (a, u) b s|S = u


3
= uss0 u bX u0 FS (a, u) b s|S = u s0 F (a, s) s0 |S = u0


4
= ss0 b s0 F (a, s) s0 |S = u0

6
5
= s0 s0 ba s0 |S = u0 = u0 ba
959

fiBonet & Geffner

1 definition bX,a , 2 inductive hypothesis, 3 Lemma 1, 5
6 definitions ba ba respectively. backward inclusion

2


1
s0 |S ba = b s0 F (a, s) = b s0 F (a, s) s0 |S FS (a, s|S )

4
3
= s|S bX s0 |S FS (a, s|S ) = s0 |S bX,a
1 definition ba , 2 Lemma 1, 3 inductive hypothesis, 4
definition bX,a . Therefore, bX,a = ba .
a,`
Case: 0 = h, ha, `ii. need show ba,`
X = b . forward inclusion
1

2

3

a,`
u ba,`
X = u bX u |= Wa (`)S = u b u |= Wa (`)S = u b

1 definition ba,`
X , 2 inductive hypothesis, 3 Lemma 4.
backward inclusion
1

2

3

s|S ba,` = b |= Wa (`) = s|S bX s|S |= Wa (`)S = s|S ba,`
X .
1 definition ba,` , 2 inductive hypothesis, 3 definition
a,`
a,`
ba,`
X . Therefore, bX = b .
Theorem 21. 1) execution possible P iff possible subproblems
PX X precondition goal variable P . 2) execution precondition
goal variable X, X = x (resp. X 6= x) true b iff X = x (resp. X 6= x) true
bX , b bX beliefs result executing P PX respectively.
Proof. Part 1. proof induction length executions. base case
induction empty execution possible P PX . Assume
claim holds executions length n, let b bX beliefs result
P subproblem PX respectively. Let 0 execution length
n + 1 augments . following, F denotes collection precondition goal
variables P , = Ctx(X) X F.
Case: 0 = h, ai. First, assume 0 possible P . need show 0 possible
PX X F. assumption, literal ` P re(a) b, |= `.
Let ` literal P re(a)S u bX X F. Then, V ars(`) and, inductive
hypothesis Theorem 20 (since applicable P PX ) applied , u = s|S
b. Therefore, u |= ` applicable bX .
Now, assume 0 possible PX X F. need show 0
possible P . ` = X = x precondition a, ` P re(a)S ` holds
state u bX . b then, inductive hypothesis Theorem 20 applied ,
u bX s|S = u. Thus, |= ` applicable b.
Case: 0 = h, ha, `ii. First, assume 0 possible P ; i.e., ba,` non-empty. need
show ba,`
X non-empty well X F.
1

2

3

ba,` = b |= Wa (`) = s|S bX s|S |= Wa (`)S = s|S ba,`
X
960

fiBelief Tracking Planning Sensing

1 definition ba,` , 2 inductive hypothesis Theorem 20, 3
a,`
definition ba,`
X . Hence, bX non-empty.
Finally, assume 0 possible PX ; i.e., ba,`
X non-empty X F.
a,`
need show b non-empty. Let X F Wa (`)S = Wa (`)
= Ctx(X); exists fourth assumption problem P Lemma 2.



1
2
u ba,`
X = u bX u |= Wa (`)S = u bX u |= Wa (`)S b u = s|S


3
= u bX |= Wa (`) b u = s|S

5


4
= |= Wa (`) b = ba,`
1 definition ba,`
X , 2 inductive hypothesis Theorem 20, 3
Wa (`)S = Wa (`), 5 definition ba,` . Hence, ba,` non-empty.
Part 2. Let possible execution P , hence, part 1, also possible PX .
Let b bX beliefs result P PX respectively. Theorem 20,
X bX = X b. Therefore, X = x (or X 6= x) holds bX iff holds b.
Theorem 22. Flat belief tracking projected problems PX X
precondition goal variable P , provides sound complete factored algorithm
belief tracking P time space exponential width P .
Proof. direct Theorem 21. Let execution b bX,
beliefs result executing P PX respectively. Then, possible P iff
possible PX . Therefore, flat belief tracking subproblems PX tells whether
possible P . Furthermore, precondition goal variable X, X = x holds
b iff holds bX, . Thus, flat belief tracking subproblems PX sufficient
determine action applicable goal belief reached.
Theorem 5, flat belief tracking subproblem PX exponential |Ctx(X) VU |.
Therefore, flat belief tracking subproblems PX (simultaneously) exponential
maxX |Ctx(X) VU | max ranges precondition goal variables X.
latter expression one defines w(P ).
Proposition 19. execution ha0 , o0 , a1 , o1 , . . .i possible P , also possible
PX state variable X P .
Proof. X precondition goal variable, claim follows Theorem 21. So,
assume X state variable appear precondition goal. show
using induction length (generalized) execution possible P
also possible PX . base case empty executions direct. Consider
execution 0 length n + 1 extends execution length n. Let b bX
result applying execution P PX respectively, let = Ctx(X).
Case: 0 = h, ai. Let ` = = precondition P re(a)S = Ctx(Y ). Then,
Ctx(Y ) Ctx(X) relevant X. Lemma 5 (below), bX .
961

fiBonet & Geffner

hand, Theorem 21, |= ` every . Therefore, ` holds state
bX , applicable bX , 0 possible PX .
Case: 0 = h, ha, `ii. Wa (`)S = true, ba,`
X = bX non-empty inductive
hypothesis thus 0 possible PX . Wa (`)S 6= true ` = Z = z, Z
relevant X. Since assumption precondition goal variable Z
relevant , difficult show X relevant . Thus, Ctx(X) Ctx(Y )
bX Lemma 5. Since 0 possible P ba,`
non-empty Theorem 21,
0 possible P .
ba,`

non-empty


X
X
A.3 Causal Belief Tracking
Lemma 5 (Soundness Causally-Closed Decompositions). Let = hT, Bi decomposition whose beams causally closed, let PXD subproblem corresponding
projection P variables B(X) X . target variable X , b
bX beliefs resulting execution P PXD respectively, bX B(X) b.
Proof. proof induction length executions. empty execution,
claims holds since contains unit clauses. Let 0 execution length 0
augments . following, b bX denote beliefs P PXD resulting
execution , denotes B(X).
Case: 0 = h, ai. Let u0 ba . Then, b u0 F (a, s).
Lemma 1, u0 FS (a, s|S ). Thus, since s|S bX inductive hypothesis, u0 bX,a .
Case: 0 = h, ha, `ii. Let s|S ba,` . b |= Wa (`). inductive
hypothesis, s|S |= Wa (`)S s|S bX . Thus, s|S ba,`
X .
Theorem 28. Decoupled CBT runs time space exponential wc (P ),
sound complete. is, target variable X causal decomposition,
b bX beliefs resulting execution P PXC respectively,
bX BC (X) b necessarily true, bX BC (X) b not.
Proof. Soundness follows directly Lemma 5. bounds time space also
direct size beam BC (X) bounded causal width wc (P ).
Theorem 30. CBT space exponential causal width problem, time
exponential width.
Proof. CBT maintains beliefs beams causal decomposition whose size
bounded causal width problem. join-project operation CBT
performed across time, considering one valuation time, without need first
compute store full joint. done recursively iterating beliefs
(bY )oa participate join (5), combining partial valuations belief,
storing projection resulting belief bi+1
X . number valuations join
O(w(P
))
(5) bounded 2
variable Z BC (Y ), relevant X, relevant
X thus Z Ctx(X).
962

fiBelief Tracking Planning Sensing

remains show Theorem 33 (stated below). proof straightforward
split two parts. first part reformulates CBT algorithm called Wide
(Causal) Belief Tracking (WBT), like CBT performs join operation
beliefs variables problem variables relevant
X, shows soundness completeness WBT. second part, show
CBT simply WBT applied subproblem PCtx(X) associated variable X
factored decomposition F , use soundness completeness factored
decomposition finish proof. first part proof consists Lemmas 68,
second part consists Lemma 9 Theorem 33.
WBT works causal decomposition C = hTC , BC like CBT. beliefs time
0 WBT CBT: initial belief projected causal
beams BC (X) X TC . Beliefs later times associated executions 0
augment executions . denote belief variable X TC execution
bX, , update equations WBT are:
bX,h,ai = BC (X)
n{FT (a, bY, ) : TC } ,
bX,h,ha,`ii = BC (X)
n{F ilter(Wa(`)T , bY, ) : TC }

(8)
(9)

= BC (Y ) beam , FT (a, U ) set uU FT (a, u), F ilter(, U )
set {u U : u |= }. equations essentially equation (5) CBT,
progression filtering separated, except join performed
target variables instead joining target variables relevant X.
following basic facts joins, projections filtering easily shown
used proofs. (We include proofs here.) statements, sets
U Ui refer sets valuations, refers collection subset variables, refers
subset variables Si = V ars(Ui ), refers logical formula. facts are:
BF1. U
n{S U : S},
BF2. collection {Ui }iI ,


n{Si
n{Ui : I} : I} =
n{Ui : I},

BF3. F ilter(, U ) F ilter(S , U ).
Definition Lemma 6. decomposition = hT, Bi factors set U V -valuations
iff U =
n{B(X) U : X }.
decomposition = hT, Bi preserves transitions set U V -valuations iff
pair variables X, , Z B(X) B(Y ), either i) Z known U (i.e.,
u[Z] = u0 [Z] u, u0 U ), ii) B(X) B(Y ) B(W ) variable W ,
iii) every action a, transition function FS (a, ) 1-1 variable Z U ,
causal closure Z.
Let = hT, Bi decomposition V = XT B(X) B(X) causally
closed X , U set V -valuations, V -formula. following
claims hold:
1. factors U ,
F (a, U )
n{B(X)F (a, U ) : X } =
n{FB(X)(a, B(X)U ) : X } .
963

fiBonet & Geffner

2. factors preserves transitions U ,
F (a, U ) =
n{B(X)F (a, U ) : X } =
n{FB(X)(a, B(X)U ) : X } .
3. factors U X B(X) = ,
F ilter(, U ) =
n{B(X)F ilter(, U ) : X } =
n{F ilter(B(X), B(X)U ) : X } .
Proof. Part 1. containment direct BF1, equality follows directly
B(X) F (a, U ) = FB(X) (a, B(X) U ) Lemma 1.
Part 2. second equality forward inclusion first equality
Part 1. thus need show F (a, U )
n{B(X) F (a, U ) : X }. Let
u0 element right-hand side expression X . Then, u0 |B(X)
B(X) F (a, U ) (by Lemma 1) uX B(X) U u0 |B(X) FB(X) (a, uX ).
claim {uX }XT consistent collection valuations. Indeed, not,
valuations uX , uY variable Z uX [Z] 6= uY [Z]. Clearly, Z known
U . B(X) B(Y ) B(W ) W , exchange uX uY
uW |B(X) uW |B(Y ) respectively. Otherwise, see function FS (a, ),
causal closure Z, 1-1 Z, contradicting assumptions. Therefore,
valuation u u|B(X) = uX X (i.e., u
n{B(X) U : X }) thus,
assumption, u U . Finally, since B(X) F (a, u) = FB(X) (a, u|B(X) ) = FB(X) (a, uX )
Lemma 1, u0 |B(X) B(X) F (a, u) u0 F (a, U ).
Part 3. First, observe BF1 BF3 imply chain containments
F ilter(, U )
n{B(X)F ilter(, U ) : X }
n{F ilter(B(X), B(X)U ) : X } .
finish showing equality holds proving last subset contained
first. Let u0 element last subset. u0 belongs
n{B(X) U : X }
also U since factors U . thus need show u0 |= . direct
since assumption X B(X) = , thus u0 |B(X) |= B(X) = .
Lemma 7 (Soundness WBT). WBT sound. is, C = hTC , BC causal
decomposition problem P , {bX }XTC local beliefs time i, b global
belief time i, b
n{bX : X TC } BC (X) b bX X TC .
Proof. really need proof first claim b
n{bX : X TC } second
follows directly observing bX belief variables BC (X).
proof first claim induction length executions. base
case empty execution easily verified. Assume claims hold executions
length n let 0 execution length n + 1 augments execution
length n. Observe C factors U =
n{bY, : TC } BF2, b U inductive
hypothesis.
Case: 0 = h, ai.


n{bX,

1

0

: X TC } =
n{BC (X)
n{FBC (Y )(a, bY, ) : TC } : X TC }
964

fiBelief Tracking Planning Sensing

2


n{BC (X)
n{FBC (Y )(a, BC (Y )U ) : TC } : X TC }
3

4

F (a, U ) F (a, b ) = b 0
1 Eq. 8, 2 bY, BC (Y ) U , 3 part 1 Lemma 6, 4
inductive hypothesis.
Case: 0 = h, ha, `ii.


n{bX,

9

0

: X TC } =
n{BC (X)
n{F ilter(Wa(`)BC (Y ), bY, ) : TC } : X TC }
10




n{B

C (X)


n{F ilter(Wa(`)B

C (Y

) , BC (Y ) U )

: TC } : X TC }

12

11

= F ilter(Wa (`), U ) F ilter(Wa (`), b ) = b 0
9 Eq. 9,
inductive hypothesis.

10

bY, BC (Y ) U ,

11

part 3 Lemma 6,

12



Lemma 8 (Completeness WBT). Let C = hTC , BC causal decomposition
problem P . C preserves transitions every reachable belief state, WBT complete.
is, {bX }XTC local beliefs time i, b global belief time i,
b=o
n{bX : X TC } BC (X) b = bX X TC .
Proof. proof induction length executions. base case
empty execution easily verified since contains unit clauses. Assume claims
hold executions length n let 0 execution length n + 1 augments
execution length n. Observe C factors U =
n{bY, : TC } BF2,
inductive hypothesis implies b = U bY, = BC (Y ) U . proof first claim
b=o
n{bX : X TC } exactly like proof Lemma 7 except containments
replaced equalities, either using part 2 Lemma 6 inductive hypothesis.
second claim, make similar induction (in tandem first induction).
Again, base case induction easily verified. inductive step,
Case: 0 = h, ai.
1

2

bX, 0 = BC (X)
n{FBC (Y )(a, bY, ) : TC } = BC (X)
n{FBC (Y )(a, BC (Y )U ) : TC }
3

4

= BC (X) F (a, U ) = BC (X) F (a, b ) = BC (X) b 0
1 Eq. 8, 2 4 inductive hypothesis, 3 part 2 Lemma 6.
Case: 0 = h, ha, `ii.
5

bX, 0 = BC (X)
n{F ilter(Wa(`)BC (Y ), bY, ) : TC }
6

= BC (X)
n{F ilter(Wa(`)BC (Y ), BC (Y )U ) : TC }
7

8

= BC (X) F ilter(Wa (`), U ) = BC (X) F ilter(Wa (`), b ) = BC (X) b 0
5 Eq. 9, 6 8 inductive hypothesis, 7 part 3 Lemma 6.
965

fiBonet & Geffner

following lemma shows tracking CBT variable X equivalent
tracking WBT subproblem PX factored decomposition (i.e.,
PX = PBF (X) factored decomposition F = hTF , BF i).
Lemma 9. Let F = hTF , BF C = hTC , BC factored causal decompositions
W
problem P . execution X TC state variable, bC
X = bX
C
bX denotes local belief variable X computed CBT problem
P , bW
X denotes local belief variable X computed WBT
subproblem PBF (X) .
Proof sketch. simple tedious proof, provide sketch. Let CX =
hTX , BX causal decomposition subproblem PBF (X) X TF (i.e.,
causal decomposition subproblem associated variable X TF factored
decomposition). beams participate join CBT beams
variables TC relevant X; variables appear TX well. TX
variables however: observable variables relevant X. Yet, since
state variables PBF (X) relevant X, projected formulas Wa (Y = y)BF (X)
variables equal true. Hence, beams variables
empty set variables contain empty valuation. Therefore, beams
removed join defines WBT problem PBF (X) without altering value.
resulting join WBT PBF (X) contain beams variables TC
relevant X.
fact observed, proof consists simple induction length
executions. induction left exercise.
Theorem 33. Causal belief tracking always sound. complete causally decomposable problems.
Proof. Let F = hTF , BF C = hTC , BC factored causal decompositions
problem P , CX = hTX , BX causal decomposition subproblem PBF (X)
X TF (notice X state variable TF comprised such). Further, let
W
execution, let bC
X bX local beliefs variable X computed
CBT problem P WBT problem PBF (X) respectively, let bFX local belief
variable X computed factored belief tracking problem P , let b
(global) belief problem P .
observable variable relevant X, BC (X) = BF (X) CBT X equal
factored belief tracking X sound complete Theorem 20.
observable variables relevant X, first notice
W
F
bC
X = bX BC (X) bX = BC (X) b

(10)

Lemma 9, soundness WBT (cf. Lemma 7), soundness completeness FBT (cf. Theorem 20). Therefore, CBT sound.
causal decomposition CX preserves transitions every reachable belief state
problem PBF (X) , containment (10) equality CBT complete well.
thus finish proof showing decomposition CX causally-decomposable
problems decomposition preserves transitions reachable belief PBF (X) .
966

fiBelief Tracking Planning Sensing

Let X TC variable, let bX reachable belief problem PBF (X) , let X 0
two variables TX (the target variables causal decomposition problem
PBF (X) ), let Z variable BC (X 0 ) BC (X 00 ). show either 1) Z
known bX , 2) BC (X 0 ) BC (X 00 ) BC (W ) variable W TX , 3) every
action a, transition function FS (a, ) 1-1 variable Z bX causal
closure Z. case, causal decomposition CX preserves transitions every
reachable belief problem PBF (X) .
X 00

consider two cases:
Case: X 0 X 00 observable. First, apply causal-decomposability P conclude
either variable W TC relevant X 0 X 00 BC (W ) BC (X 0 )
BC (X 00 ), Z memory variable. former case, W relevant X thus
belongs TX . latter case, show either Z known bX transition
function FS (a, ) 1-1 Z bX , causal closure Z action
applicable bX .
Indeed, proof contradiction let us suppose Z known bX
transition function 1-1. Then, two valuations s1 , s2 bX two
progressions s01 FX (a, s1 ) s02 FX (a, s2 ) s1 [Z] 6= s2 [Z] s01 [Z] = s02 [Z].
Therefore, observing value Z state s01 knowing initial belief
actions execution h, ai (where execution leads bX ), one cannot infer
value Z bX two different values compatible
observation, namely s1 [Z] s2 [Z]. Hence, Z memory variable contradicting
assumed causal-decomposability P .
Case: X 0 X 00 observables. divide case two subcases
whether variables X 0 X 00 causal ancestors X not. affirmative
subcase, BC (X 0 ) BC (X 00 ) BC (X). negative subcase, assume without loss
generality X 0 causal ancestor X. Then, observable variable
X 0 causal ancestor relevant X. Hence, BC (Y ) BC (X 0 )
implies Z BC (Y ) BC (X 00 ) case reduced previous case.

References
Albore, A., Palacios, H., & Geffner, H. (2009). translation-based approach contingent
planning. Proc. 21st Int. Joint Conf. Artificial Intelligence, pp. 16231628,
Pasadena, California.
Albore, A., Ramirez, M., & Geffner, H. (2010). Compiling uncertainty away nondeterministic conformant planning. Proc. 19th European Conf. Artificial Intelligence, pp. 465470, Lisbon, Portugal.
Albore, A., Ramirez, M., & Geffner, H. (2011). Effective heuristics belief tracking
planning incomplete information. Proc. 21st Int. Conf. Automated
Planning Scheduling, pp. 29, Freiburg, Germany.
Amir, E., & Russell, S. (2003). Logical filtering. Proc. 18th Int. Joint Conf. Artificial
Intelligence, pp. 7582, Acapulco, Mexico.
967

fiBonet & Geffner

Bertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001). Planning nondeterministic domains partial observability via symbolic model checking. Nebel, B.
(Ed.), Proc. 17th Int. Joint Conf. Artificial Intelligence, pp. 473478, Seattle, WA.
Morgan Kaufmann.
Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic search
belief space. Chien, S., Kambhampati, S., & Knoblock, C. (Eds.), Proc. 5th
Int. Conf. Artificial Intelligence Planning Systems, pp. 5261, Breckenridge, CO.
AAAI Press.
Bonet, B., & Geffner, H. (2011). Planning partial observability classical replanning:
Theory experiments. Proc. 22nd Int. Joint Conf. Artificial Intelligence, pp.
19361941, Barcelona, Spain.
Bonet, B., & Geffner, H. (2012a). Action selection MDPs: Anytime AO* vs. UCT.
Proc. 26th AAAI Conf. Artificial Intelligence, pp. 17491755, Toronto, Canada.
Bonet, B., & Geffner, H. (2012b). Width complexity belief tracking nondeterministic conformant contingent planning. Proc. 26th AAAI Conf.
Artificial Intelligence, pp. 17561762, Toronto, Canada.
Bonet, B., & Geffner, H. (2013). Causal belief decomposition planning sensing:
Completeness results practical approximation. Proc. 23rd Int. Joint Conf.
Artificial Intelligence, pp. 22752281, Beijing, China.
Bonet, B., & Geffner, H. (2014). Flexible scalable partially observable planning
linear translations. Proc. 28th AAAI Conf. Artificial Intelligence, pp. 22352241,
Quebec City, Canada.
Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.
Cooper, G., & Moral, S. (Eds.), Proc. 14th Conf. Uncertainty Artificial Intelligence, pp. 3342, Madison, WI. Morgan Kaufmann.
Brafman, R. I., & Shani, G. (2012). Replanning domains partial information
sensing actions. Journal Artificial Intelligence Research, 1 (45), 565600.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics belief
space search. Journal Artificial Intelligence Research, 26, 3599.
Choi, A., & Darwiche, A. (2006). edge deletion semantics belief propagation
practical impact approximation quality. Proc. 21st Nat. Conf. Artificial
Intelligence, pp. 11071114.
Cimatti, A., Roveri, M., & Bertoli, P. (2004). Conformant planning via symbolic model
checking heuristic search. Artificial Intelligence, 159, 127206.
Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal Artificial
Intelligence Research, 17, 229264.
Dechter, R., & Beek, P. V. (1997). Local global relational consistency. Theoretical
Computer Science, 173 (1), 283308.
Doucet, A., Freitas, N. D., Murphy, K., & Russell, S. (2000). Rao-blackwellised particle filtering dynamic bayesian networks. Proc. 16th Conf. Uncertainty Artificial
Intelligence, pp. 176183.
968

fiBelief Tracking Planning Sensing

Edelkamp, S. (2001). Planning pattern databases. Cesta, A. (Ed.), Proc. 6th
European Conf. Planning, pp. 1324, Toledo, Spain. Springer: LNCS.
Goldman, R. P., & Boddy, M. S. (1996). Expressive planning explicit knowledge.
Drabble, B. (Ed.), Proc. 3rd Int. Conf. Artificial Intelligence Planning Systems,
pp. 110117, Edinburgh, Scotland. AAAI Press.
Hoffmann, J., & Brafman, R. I. (2005). Contingent planning via heuristic forward search
implicit belief states. Biundo, S., Myers, K., & Rajan, K. (Eds.), Proc. 15th
Int. Conf. Automated Planning Scheduling, pp. 7180, Monterey, CA. Morgan
Kaufmann.
Hoffmann, J., & Brafman, R. I. (2006). Conformant planning via heuristic forward search:
new approach. Artificial Intelligence, 170, 507541.
Kaelbling, L. P., Littman, M., & Cassandra, A. R. (1999). Planning acting partially
observable stochastic domains. Artificial Intelligence, 101, 99134.
Kaye, R. (2000). Minesweeper NP-Complete. Mathematical Intelligencer, 22 (2), 915.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. Proc. 17th
European Conf. Machine Learning, pp. 282293. Springer.
Lin, W., Buffet, O., Lee, C., & Teytaud, O. (2012). Optimistic heuristics Minesweeper.
Proc. Int. Computer Symposium (ICS-12). http://hal.inria.fr/docs/
00/75/05/77/PDF/mines3.pdf.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planning
problems bounded width. Journal Artificial Intelligence Research, 35, 623
675.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.
Ramirez, M., & Geffner, H. (2007). Structural relaxations variable renaming
compilation solving MinCostSAT. Proc. 13th Int. Conf. Principles
Practice Constraint Programming, pp. 605619. Springer.
Rintanen, J. (2008). Regression classical nondeterministic planning. Ghallab,
M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), Proc. 18th European
Conf. Artificial Intelligence, pp. 568572, Patras, Greece.
Russell, S., & Norvig, P. (2009). Artificial Intelligence: Modern Approach (3rd edition).
Prentice Hall.
Scott, A., Stege, U., & Rooij, I. V. (2011). Minesweeper may NP-Complete
Hard nonetheless. Science+Business Media, LLC, 33 (4), 517.
Shani, G., & Brafman, R. I. (2011). Replanning domains partial information
sensing actions. Proc. 22nd Int. Joint Conf. Artificial Intelligence, pp. 2021
2026, Barcelona, Spain.
Shani, G., Poupart, P., Brafman, R. I., & Shimony, S. (2008). Efficient ADD operations
point-based algorithms. Rintanen, J., Nebel, B., & J. C. Beck, E. A. H. (Eds.),
Proc. 18th Int. Conf. Automated Planning Scheduling, pp. 330337, Sydney,
Australia.
969

fiBonet & Geffner

Silver, D., & Veness, J. (2010). Monte-Carlo planning large POMDPs. Proc. 24th
Annual Conf. Advances Neural Information Processing Systems, pp. 21642172.
Sipser, M. (2006). Introduction Theory Computation (2nd edition). Thomson Course
Technology, Boston, MA.
Smith, D., & Weld, D. (1998). Conformant graphplan. Mostow, J., & Rich, C. (Eds.),
Proc. 15th Nat. Conf. Artificial Intelligence, pp. 889896, Madison, WI. AAAI
Press / MIT Press.
To, S. T., Pontelli, E., & Son, T. C. (2011). effectiveness CNF DNF representations contingent planning. Proc. 22nd Int. Joint Conf. Artificial Intelligence,
pp. 20332038, Barcelona, Spain.
Tran, V., Nguyen, K., Son, T. C., & Pontelli, E. (2013). conformant planner based
approximation: CpA(H). ACM Trans. Intelligent Systems Technology, 4 (2),
36.
Weld, D., Anderson, C., & Smith, D. (1998). Extending Graphplan handle uncertainty
sensing actions. Proc. 15th Nat. Conf. Artificial Intelligence, pp. 897904.
AAAI Press.

970

fiJournal Artificial Intelligence Research 50 (2014) 189-233

Submitted 03/14; published 05/14

Efficient Algorithm Estimating State Sequences
Imprecise Hidden Markov Models
Jasper De Bock
Gert de Cooman

JASPER . DEBOCK @ UGENT.
GERT. DECOOMAN @ UGENT.

Ghent University, SYSTeMS Research Group
TechnologieparkZwijnaarde 914
9052 Zwijnaarde, Belgium

Abstract
present efficient exact algorithm estimating state sequences outputs observations imprecise hidden Markov models (iHMMs). uncertainty linking one state next,
linking state output, represented set probability mass functions instead
single mass function. consider best estimates state sequences maximal sequences posterior joint state model conditioned observed output sequence, associated
gain function indicator state sequence. corresponds generalises
finding state sequence highest posterior probability (precise-probabilistic) HMMs,
thereby making algorithm generalisation one Viterbi. argue computational complexity algorithm worst quadratic length iHMM, cubic
number states, essentially linear number maximal state sequences. important
feature imprecise approach may one maximal sequence, typically
instances precise-probabilistic counterpart sensitive choice prior.
binary iHMMs, investigate experimentally number maximal state sequences depends model parameters. also present application optical character recognition,
demonstrating algorithm usefully applied robustify inferences made
precise-probabilistic counterpart.

1. Introduction
field Artificial Intelligence, probabilistic graphical models become powerful tool,
especially domains reasoning uncertainty needed (Koller & Friedman, 2009;
Pearl, 1988). Usually, uncertainty expressed probabilities, estimated data
elicited domain experts. However, assumption probabilities obtained,
matter, exist, always realistic. example happen multiple
experts disagree, rounding errors occur, available data limited; latter
either inherent problem consequence economic temporal constraints.
order relax assumption, one use theory imprecise probabilities. basic
idea allow sets probability distributions rather requiring specification single
one. way, partial probabilistic information expressed easily, example, means
linear constraints probability distributions. theory imprecise probability encompasses
number different, closely related frameworks; coherent lower previsions (Walley, 1991),
interval probabilities (Weichselberger, 2000) belief functions (Dempster, 1967; Shafer, 1976)
well-known examples.
c
2014
AI Access Foundation. rights reserved.

fiD E B OCK & E C OOMAN

context graphical models, imprecise-probabilistic ideas used develop
notion credal network (Cozman, 2000, 2005). similar Bayesian network,
general sense allows local uncertainty models imprecisely specified,
sets probability distributions. gain generality, however, comes price added
computational complexity existing algorithms either approximative cannot handle
large networks. fact, inferences credal networks proven NP-hard even singly
connected networks ternary variables (Mau, de Campos, Benavoli, & Antonucci, 2013).
notable exception intractability inference problems credal networks occurs
drop so-called strong independence assumption usually associated credal networks replace assessment epistemic irrelevance. Strong independence requires
credal network convex hull (precise) Bayesian networks, whereas epistemic irrelevance
less restrictive property, imposed imprecise model instead individual precise models consists of; information difference two
approaches, see example pioneering work Cozman (2000). Recent work (De Cooman,
Hermans, Antonucci, & Zaffalon, 2010) shown use epistemic irrelevance guarantees efficient algorithm updating beliefs single target node credal
tree, essentially linear number nodes tree. imprecise-probabilistic hidden Markov models (iHMMs), credal network equivalent hidden Markov models
(HMMs), efficiency single target node inferences succesfully exploited develop
imprecise-probabilistic counterpart Kalman filter (Benavoli, Zaffalon, & Miranda, 2011).
paper, tackle imprecise-probabilistic counterpart another important application
HMMs: finding sequence hidden states highest posterior probability conditional observed sequence outputs (Rabiner, 1989). HMMs precise local transition
emission probabilities, efficient dynamic programming algorithm performing task
developed Viterbi (1967). imprecise-probabilistic HMMs however, know algorithm literature computational complexity comes even close Viterbis.
remedy situation developing efficient exact algorithm, called EstiHMM1 , solves
following imprecise-probabilistic generalisation state estimation problem: given observed sequence outputs, maximal (Troffaes, 2007; Walley, 1991) state sequences
posterior joint model?
important difference imprecise approach conventional preciseprobabilistic approach EstiHMM algorithm may sometimes return one solution,
whereas Viterbi algorithm always produce single one. imprecise iHMM
is, maximal state sequences be. precise HMMs, EstiHMM Viterbi
algorithms produce identical results. advantage behaviour EstiHMM algorithm
typically return one maximal sequence instances precise
approach sensitive choice prior. cases, set-valued solution EstiHMM
algorithm likely contain correct hidden sequence. application optical character
recognition (see Section 9) illustrates advantage convincingly.
credal network point view, main contribution paper EstiHMM algorithm itself. especially surprising algorithm, provides efficient
solution inference problem deals multiple target nodes once, situation which,
general, difficult handle current state art algorithms field. think
1. EstiHMM: Estimation imprecise Hidden Markov Models

190

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

promising results paper motivate study similar problems network topologies
go beyond HMMs.
importance results HMM community and, extension, field AI
general, illustrate model uncertaintynot confused probabilistic
uncertainty intrinsic model itselfcan dealt efficiently can,
time, lead informative, set-valued estimates (sets maximal state sequences) usefully
applied real-life problems. believe model uncertainty relevant subfields AI
difficultif impossibleto accurately pinpoint single probability distribution.
model uncertainty might severe impact resulting inferences and, so,
taken account basing decisions inferences.
start Section 3 describing imprecise hidden Markov models special case
credal trees epistemic irrelevance. show particular use ideas underlying
MePiCTIr2 algorithm (De Cooman et al., 2010) construct conservative joint model
imprecise local transition emission models. also derive number interesting
useful formulas construction. results section assume basic knowledge
theory coherent lower previsions. include short introduction theory Section 2.
Section 4, explain maximality criterion show leads set optimal
estimates hidden state sequence. Finding maximal state sequences seems daunting
task first: search space grows exponentially length Markov chain.
However, shown Section 5, use basic formulas Section 3 derive appropriate
version Bellmans Principle Optimality (Bellman, 1957), resulting exponential reduction
search space. using number additional tricks, including clever reformulation
maximality criterion, enables us Section 6 devise EstiHMM algorithm,
efficiently constructs set maximal state sequences.
Section 7 discusses computational complexity EstiHMM algorithm. show
essentially linear number maximal sequences, quadratic length chain,
cubic number states. perceive complexity comparable Viterbi
algorithm, especially realising latter makes simplifying step resolving ties
less arbitrarily order produce single optimal state sequence.
Section 8, consider special case binary iHMMs, investigate experimentally
number maximal state sequences depends model parameters. comment interesting structures emerge, provide heuristic explanation them. also demonstrate
algorithms efficiency calculating maximal sequences iHMM length 100.
Finally, Section 9, present application optical character recognition. clearly
demonstrates advantages algorithm gives clear indication EstiHMM algorithm able robustify results existing Viterbi algorithm intelligent manner.
conclude paper Section 10 discuss number possible avenues future research. order make main argumentation readable possible, technical proofs
relegated appendix.

2. Freshening Coherent Lower Previsions
begin basic theory coherent lower previsions; information, refer
Walleys book (1991) recent survey Miranda (2008).
2. MePiCTIr: Message Passing Credal Trees Irrelevance.

191

fiD E B OCK & E C OOMAN

Coherent lower previsions special type imprecise probability model. Roughly speaking,
whereas classical probability theory assumes subjects uncertainty represented
single probability mass function, theory imprecise probabilities effectively works sets
possible probability mass functions, thereby allows imprecision well indecision
modelled represented. people unfamiliar theory, looking way
robustifying classical theory perhaps easiest way understand interpret it,
use approach here.
2.1 Unconditional Lower Previsions
Let X non-empty, finite3 set possible states. call real-valued function f X
gamble denote set gambles X G (X). Consider set probability mass
functions X. mass function p , associate linear previsionor expectation functionalPp , defined G (X). every gamble f G (X) , Pp ( f ) := xX p(x) f (x)
expected value f , associated probability mass function p. define lower
previsionor lower expectation functionalPM corresponds set following
lower envelope linear previsions:
PM ( f ) := inf {Pp ( f ) : p } f G (X).

(1)

Similarly, define upper previsionor upper expectation functionalPM
PM ( f ) := sup {Pp ( f ) : p } = inf {Pp ( f ) : p } = PM ( f ) f G (X). (2)
mostly talk lower previsions, since follows conjugacy relation (2)
two models mathematically equivalent.
event subset set possible values X: X. event,
associate indicator IA , gamble X assumes value 1 A, 0 outside A.
call


PM (A) := PM (IA ) = inf p(x) : p
xA

lower probability event A, similarly PM (A) := PM (IA ) upper probability.
shown (Walley, 1991) functional PM satisfies following set interesting
mathematical properties, define coherent lower prevision:
C1. PM ( f ) min f f G (X),
C2. PM ( f ) = PM ( f ) f G (X) real 0,
C3. PM ( f + g) PM ( f ) + PM (g) f , g G (X).

[non-negative homogeneity]
[superadditivity]

Every set mass functions uniquely defines coherent lower prevision PM , general
converse hold. However, limit sets mass functions
closed convexwhich makes credal setsthey one-to-one correspondence
coherent lower previsions (Walley, 1991). implies use theory coherent
3. theory coherent lower previsions applicable non-finite sets well, expense complications.
However, present purposes, suffices consider finitary case only.

192

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

lower previsions tool reasoning closed convex sets probability mass functions.
on, longer explicitly refer credal sets , simply talk
coherent lower previsions P. useful keep mind always unique credal set
corresponds coherent lower prevision: P = PM unique credal set , given
= {p : ( f G (X))Pp ( f ) P( f )}.
special kind imprecise model X vacuous lower prevision. model
represents complete ignorance therefore set possible mass functions X
credal set . shown easily every f G (X), corresponding lower prevision
given P( f ) = min f .
2.2 Conditional Lower Previsions
Conditional lower upper previsions, extensions classical conditional expectation functionals, defined similar, intuitively obvious way: lower envelopes associated
sets conditional mass functions.
Consider variable X X variable . conditional lower prevision P(|Y )
set G (X) gambles X two-place real-valued function. gamble f X, P( f |Y )
gamble , whose value P( f |y) lower prevision f , conditional event
= y. , lower prevision P(|y) coherentsatisfies conditions C1C3then
call conditional lower prevision P(|Y ) separately coherent. sometimes useful
extend domain conditional lower prevision P(|y) G (X) G (X ) letting
P( f |y) := P( f (, y)|y) gambles f X .
number conditional lower previsions involving number variables,
must separately coherent, also make sure satisfy stringent
joint coherence requirement. Explaining detail would take us far; Walley (1991) provides
detailed discussion motivation. present purposes, suffices say joint coherence
closely related making sure conditional lower previsions lower envelopes
associated conditional mass functions satisfy Bayess Rule.
given lower prevision P G (X ), may one corresponding conditional lower prevision P(|Y ) jointly coherent P. Depending updating method
used, one obtains different model.
use natural
coherent lower prevision P(|Y ) defined
extension, conditional

P( f |y) := max R : P(I{y} [ f ]) 0 P({y}) > 0 vacuous thus given
P( f |y) := min f P({y}) = 0. smallest, conservative coherent way conditioning
lower prevision. P({y}) > 0, corresponds conditioning every probability mass function
credal set P observation = taking lower envelope
conditioned mass functions.
use regular extension, P(|Y ) defined P( f |y) := max { R : P(Iy [ f ]) 0}
P({y}) > 0 vacuous P({y}) = 0. P({y}) > 0, regular extension (a) gives us
greatestmost informativeconditional lower prevision jointly coherent original
unconditional lower prevision (b) corresponds taking mass functions p credal set
P p(y) 6= 0, conditioning observation = taking lower
envelope.
Natural regular extension coincide P({y}) > 0 P({y}) = 0 may differ
P({y}) > P({y}) = 0. latter case, natural extension vacuous, regular extension usu193

fiD E B OCK & E C OOMAN

ally remains informative. Furthermore, P({y}) > 0, every coherent updating method
yields conditional lower prevision lies obtained natural regular extension (Walley, 1991; Miranda, 2009).
2.3 Different Interpretations Lower Previsions
seen, coherent lower prevision P serves alternative representation
closed convex set probability mass functions. Often, credal set interpreted
set candidates one true unknown probability mass function. interpretation particularly intuitive people used working classical probability theory.
Walley (1991, Section 2.10.4) calls sensitivity analysis interpretation. sake completeness, mention coherent lower previsions also given behavioural interpretation, without using notion probability mass function. lower prevision P( f )
gamble f G (X) interpreted supremum acceptable buying price subject
willing pay order gain thepossibly negativereward f (x) outcome x X
experiment determined. Walley discusses alternative interpretation extensively.

3. Basic Notions
imprecise hidden Markov model depicted using following probabilistic graphical
model:
Q1 ()

Q2 (|X1 )

Qk (|Xk1 )

Qn (|Xn1 )

State sequence:

X1

X2

Xk

Xn

Output sequence:

O1

O2

Ok



S1 (|X1 )

S2 (|X2 )

Sk (|Xk )

Sn (|Xn )

Figure 1: Tree representation hidden Markov model
n natural number. state variables X1 , . . . , Xn assume values respective finite
sets X1 , . . . , Xn , output variables O1 , . . . , assume values respective finite sets O1 ,
. . . , . denote generic values Xk xk , xk zk , generic values Ok ok .
3.1 Local Uncertainty Models
assume following local uncertainty models variables. X1 ,
marginal lower prevision Q1 , defined set G (X1 ) real-valued mapsor gambles
X1 . subsequent states Xk , k {2, . . . , n}, conditional lower prevision
Qk (|Xk1 ) defined G (Xk ), called transition model. order maintain uniformity notation,
also denote marginal lower prevision Q1 conditional lower prevision Q1 (|X0 ),
X0 denotes variable may assume single value x0 X0 := {x0 }, whose
194

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

value therefore certain. gamble fk G (Xk ), Qk ( fk |Xk1 ) interpreted gamble
Xk1 , whose value Qk ( fk |xk1 ) xk1 Xk1 lower prevision gamble fk (Xk ),
conditional Xk1 = xk1 .
addition, output Ok , k {1, . . . , n}, conditional lower prevision
Sk (|Xk ) defined G (Ok ), called emission model. gamble gk G (Ok ), Sk (gk |Xk )
interpreted gamble Xk , whose value Sk (gk |xk ) xk Xk lower prevision
gamble gk (Ok ), conditional Xk = xk .
take localmarginal, transition emissionuncertainty models separately
coherent. Recall simply means k {1, . . . , n}, lower prevision Qk (|xk1 )
coherentas unconditional lower previsionfor xk1 Xk1 Sk (|xk )
coherent xk Xk .
3.2 Interpretation Graphical Structure
assume graphical representation Figure 1 represents following irrelevance
assessments: conditional mother variable, non-parent non-descendants variable
tree epistemically irrelevant variable descendants. say variable
X epistemically irrelevant variable observing X affect beliefs .
Mathematically stated terms lower previsions: P( f (Y )) = P( f (Y )|x) f G (Y )
x X.
go on, useful introduce mathematical short-hand notation
describing joint variables tree Figure 1. 1 k ` n, denote tuple
(Xk , Xk+1 , . . . , X` ) Xk:` , tuple (Ok , Ok+1 , . . . , O` ) Ok:` . Xk:` variable assume
values set Xk:` := `r=k Xr , Ok:` variable assume values set
Ok:` := `r=k . Generic values Xk:` denoted xk:` , xk:` zk:` , generic values Ok:`
ok:` .
Example 1. Consider variable Xk mother variable Xk1 Figure 1. variables X1:k2
O1:k1 non-parent non-descendants, variables Xk+1:n Ok:n descendants.
interpretation graphical structure Figure 1 implies knowconditional
onthe value xk1 Xk1 , additionally learning values variables X1 , . . . , Xk2
O1 , . . . , Ok1 change beliefs Xk:n Ok:n .

3.3 Constructing Global Uncertainty Model
Using local uncertainty models, want construct global model: joint lower prevision
P G (X1:n O1:n ) variables (X1:n , O1:n ) tree. joint lower prevision
(i) jointly coherent local models; (ii) encode epistemic irrelevance assessments
encoded tree; (iii) small, conservative,4 possible. special case
general problem credal trees, discussed solved great detail De Cooman et
al. (2010). section, summarise solution iHMMs give heuristic justification
it; De Cooman et al. prove joint model presented indeed
conservative lower prevision coherent local models captures epistemic
irrelevance assessments encoded tree.
4. Recall pointwise smaller lower previsions correspond larger credal sets.

195

fiD E B OCK & E C OOMAN

proceed recursive manner. k {1, . . . , n} xk1 Xk1 , consider
smallest coherent joint lower prevision Pk (|xk1 ) G (Xk:n Ok:n ) variables (Xk:n , Ok:n )
iHMM depicted Figure 2, representing subtree tree represented Figure 1,
lower prevision Qk (|xk1 ) acting marginal model first state variable Xk . Note that,
due notational trick introduced Section 3.1, global model P identified
conditional lower prevision P1 (|x0 ).

Qk (|xk1 )

Qk+1 (|Xk )

Xk

Xk+1

Pk (|Xk1 )
E k (|Xk )

Ok

Ok+1

Sk (|Xk )

Sk+1 (|Xk+1 )

Pk+1 (|Xk )

Figure 2: Subtree iHMM involving variables (Xk:n , Ok:n )
aim develop recursive expressions enable us construct Pk (|xk1 )
Pk+1 (|Xk ), Sk (|Xk ) Qk (|xk1 ). Using expressions eventually
yield global model P = P1 (|x0 ).
first step, consider xk Xk combine joint model Pk+1 (|xk ) variables
(Xk+1:n , Ok+1:n ), defined G (Xk+1:n Ok+1:n )see thick dotted lines Figure 2,with
local model Sk (|xk ) variable Ok , defined G (Ok ). lead joint model E k (|xk )
variables (Xk+1:n , Ok:n ), defined G (Xk+1:n Ok:n )see semi-thick dotted lines
Figure 2. trivial k = n, since must E n (|xn ) = Sn (|xn ).
k 6= n, solution less obvious. joint model constructed many different ways,
impose conditions. first condition E k (|xk ) coherent
lower prevision jointly coherent marginal models Pk+1 (|xk ) Sk (|xk ). second, rather obvious, condition E k (|xk ) coincide Pk+1 (|xk ) Sk (|xk )
respective domains. third condition model capture epistemic irrelevance
assessments encoded tree. particular state that, conditional Xk = xk , two variables (Xk+1:n , Ok+1:n ) Ok epistemically independent, words, epistemically
irrelevant one another.
model meets conditions called independent product (De Cooman, Miranda, & Zaffalon, 2011) Pk+1 (|xk ) Sk (|xk ). Generally speaking, independent product unique. call pointwise smallest, conservative, possible independent
196

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

products, always exists, independent natural extension (Walley, 1991; De Cooman et al.,
2011) Pk+1 (|xk ) Sk (|xk ), denote Pk+1 (|xk ) Sk (|xk ).
Summarising, E k (|xk ) given
(
Sn (|xn )
k = n
E k (|xk ) :=
Sk (|xk ) Pk+1 (|xk ) k = n 1, . . . , 1.

(3)

conditionally independent natural extension properties studied great detail
De Cooman et al. (2011). purposes paper, suffice recall
study thatvery much like independent products precise probability modelssuch independent
natural extensions factorising, implies particular
E k ( f g|xk ) = E k (gE k ( f |xk )|xk ) = Sk (gPk+1 ( f |xk )|xk )
(
Sk (g|xk )Pk+1 ( f |xk )
=
Sk (g|xk )Pk+1 ( f |xk )

Pk+1 ( f |xk ) 0
Pk+1 ( f |xk ) 0

= Sk (g|xk ) fi Pk+1 ( f |xk ),

(4)

f G (Xk+1:n Ok+1:n ) non-negative g G (Ok )we call gamble non-negative
values are. expression, first equality actual factorisation property. second
equality holds E k (|xk ) coincides Pk+1 (|xk ) Sk (|xk ) respective domains.
third equality follows conjugacy relationEquation (2)and coherence condition
C2, fourth used shorthand notation fi x := max{0, x} + min{0, x}.
on, also use analogous notation n fi x := n max{0, x} + n min{0, x}.
second final step, combine joint model E k (|Xk ) variables (Xk+1:n , Ok:n ),
defined G (Xk+1:n Ok:n ), local model Qk (|xk1 ) variable Xk , defined G (Xk ),
joint model Pk (|xk1 ) variables (Xk:n , Ok:n ), defined G (Xk:n Ok:n ).
shown elsewhere (Miranda & de Cooman, 2007; Walley, 1991) conservative coherent
way this, means marginal extension, also known law iterated lower
expectations. leads Pk (|xk1 ) := Qk (E k (|Xk )|xk1 ), or, allow xk1 range
Xk1 :
Pk (|Xk1 ) := Qk (E k (|Xk )|Xk1 ).

(5)

practical purposes, useful see equivalent

Pk ( f |Xk1 ) = Qk



xk Xk


fi
fi
I{xk } E k ( f (xk , Xk+1:n , Ok:n )|xk )fiXk1

f G (Xk:n Ok:n ). Recall expression, indicator I{xk } gamble Xk
assumes value 1 Xk = xk 0 Xk 6= xk .
197

fiD E B OCK & E C OOMAN

3.4 Interesting Lower Upper Probabilities
Without much trouble,5 use Equations (3)(5) derive following expressions
number interesting lower upper probabilities:
n

Pk ({ok:n } {xk:n }|xk1 ) = Si ({oi }|xi )Qi ({xi }|xi1 )

(6)

Pk ({ok:n } {xk:n }|xk1 ) = Si ({oi }|xi )Qi ({xi }|xi1 )

(7)

i=k
n
i=k

xk1 Xk1 , xk:n Xk:n , ok:n Ok:n k {1, . . . , n},
n

E k ({ok:n } {xk+1:n }|xk ) = Sk ({ok }|xk )



Si ({oi }|xi )Qi ({xi }|xi1 )

(8)



Si ({oi }|xi )Qi ({xi }|xi1 ).

(9)

i=k+1
n

E k ({ok:n } {xk+1:n }|xk ) = Sk ({ok }|xk )

i=k+1

xk Xk , xk+1:n Xk+1:n , ok:n Ok:n k {1, . . . , n}. Recall equate events
indicators, lower upper prevision indicators correspond lower
upper probability event; see Section 2. example, Equation (6), Pk ({ok:n }
{xk:n }|xk1 ) := Pk (I{ok:n } I{xk:n } |xk1 ) lower probability that, conditional Xk1 = xk1 ,
rest hidden sequence value xk:n , corresponding observations ok:n . joint lower
probablity obtained simply multiplying relevant local lower (transition emission) probabilities.
assume throughout
P({x1:n } {o1:n }) > 0 x1:n X1:n o1:n O1:n
or, equivalentlyby Equation (7), k = 1, local upper probabilities positive,
sense (De Cooman et al., 2010):
Qk ({xk }|xk1 ) > 0 Sk ({ok }|xk ) > 0
k {1, . . . , n}, xk1 Xk1 , xk Xk ok Ok . (10)
assumption weak restrictive practical purposes. impreciseprobabilistic local models often constructed adding margin error around precise
model, thereby making upper transition probabilities positive construction. however allow lower transition probabilities zero, something happen often
practical problems.
Proposition 1. local upper probabilities positiveEquation (10),
k {1, . . . , n}, xk Xk , xk1 Xk1 ok:n Ok:n Pk ({ok:n }|xk1 ) > 0 E k ({ok:n }|xk ) > 0.
5. example, derive Equations (6) (7) Appendix A.

198

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

4. Estimating States Outputs
hidden Markov model, states directly observable, outputs are, general
aim use outputs estimate states. concentrate following problem: Suppose
observed output sequence o1:n , estimate state sequence x1:n . use essentially Bayesian approach so, need allow fact working imprecise
rather precise probability models. consider optimal estimates state sequences
maximal, criterion introduce Section 4.2; see Section 4.3 two alternative criteria,
consider context paper. main contribution section
formulation maximality stated directly terms unconditional global model P,
instead conditional model P(|o1:n ) conventionally used purpose. Furthermore,
rather surprisingly, alternative formulation valid regardless whether use regular
natural extension derive P(|o1:n ) P.
4.1 Updating iHMM
first step approach consists updating (or conditioning) joint model P := P1 (|x0 )
observed outputs O1:n = o1:n . mentioned Section 2, unique coherent way
perform updating. However, particular problem solving paper,
happens makes difference updating method used, long coherent.
time being, use regular extension, later Section 4.2, show
coherent updating method yields results.
Since follows positivity assumption (10) Proposition 1 P({o1:n }) > 0, regular
extension leads us consider updated lower prevision P(|o1:n ) G (X1:n ), given by:


P( f |o1:n ) := max R : P(I{o1:n } [ f ]) 0 gambles f X1:n .
(11)
Using coherence joint lower prevision P, hard prove P({o1:n }) > 0,
P(I{o1:n } [ f ]) strictly decreasing continuous function , therefore unique
zerosee Lemma 7(i)&(iii) Appendix A. consequence, f G (X1:n )
P( f |o1:n ) 0 ( > 0)P(I{o1:n } [ f ]) < 0 P(I{o1:n } f ) 0.

(12)

fact, hard infer strictly decreasing continuous character P(I{o1:n } [ f ])
P( f |o1:n ) P(I{o1:n } f ) sign. either negative, positive
equal zero; see also Figure 3.

P(I{o1:n } f )

P(I{o1:n } [ f ])
P( f |o1:n )
Figure 3: Conditional versus unconditional lower prevision
199

fiD E B OCK & E C OOMAN

Equation (12) crucial importance on. However, general, want allow
P({o1:n }) zerosince may happen allow lower transition probabilities zero,
requiring P({o1:n }) > 0because follows positivity assumption (10)
Proposition 1. will, generally speaking, invalidate second equivalence Equation (12):
turns implication only. But, limit specific type gambles X1:n
form f = I{x1:n } I{x1:n } , still prove following important theorem.
Theorem 2. local upper probabilities positiveEquation (10), fixed values
x1:n , x1:n X1:n o1:n O1:n , P(I{o1:n } [I{x1:n } I{x1:n } ]) P(I{x1:n } I{x1:n } |o1:n )
sign. positive, negative zero.
4.2 Maximal State Sequences
next step consists using posterior model P(|o1:n ) find best estimates state
sequence x1:n . Bayesian approach, usually done solving decision-making,
optimisation problem: associate gain function I{x1:n } every candidate state sequence x1:n ,
select best estimates state sequences x1:n maximise posterior expected gain,
resulting state sequences maximal posterior probability.
generalise decision-making approach towards working imprecise probability
models. criterion use decide estimates optimal given gain functions
(WalleySen) maximality (Troffaes, 2007; Walley, 1991). Maximality number
desirable properties make sure works well optimisation contexts (De Cooman & Troffaes,
2005; Huntley & Troffaes, 2010), well-justified behavioural point view, well
robustness approach, shall see presently.
express strict preference two state sequence estimates x1:n x1:n
follows:
x1:n x1:n P(I{x1:n } I{x1:n } |o1:n ) > 0.
behavioural interpretation, expresses subject lower prevision P(|o1:n ) disposed pay strictly positive amount utility replace gain associated estimate
x1:n gain associated estimate x1:n ; Walley (1991, Section 3.9) provides additional
information. Alternatively, robustness point view, expresses conditional
mass function p(|o1:n ) credal set associated updated lower prevision P(|o1:n ),
state sequence x1:n posterior probability p(x1:n |o1:n ) strictly higher posterior
probability p(x1:n |o1:n ) state sequence x1:n .
binary relation thus defined strict partial orderan irreflexive transitive binary
relationon set state sequences X1:n , consider estimate x1:n optimal
undominated, maximal, strict partial order:
x1:n opt (X1:n |o1:n ) (x1:n X1:n )x1:n 6 x1:n
(x1:n X1:n )P(I{x1:n } I{x1:n } |o1:n ) 0
(x1:n X1:n )P(I{o1:n } [I{x1:n } I{x1:n } ]) 0,

(13)

useful last equivalence follows Theorem 2. summary then, aim
paper develop efficient algorithm finding set maximal estimates opt (X1:n |o1:n ).
statement Section 4.1, coherent updating method would yield results
regular extension, justified. Since coherent updating unique P({o1:n }) > 0,
200

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

since case P({o1:n }) = 0 excluded Proposition 1 positivity assumption (10),
need motivate statement special case P({o1:n }) = 0 P({o1:n }) > 0.
use regular extension update model, optimal estimates given Equation (13). special case P({o1:n }) = 0, find x1:n X1:n x1:n X1:n
P(I{o1:n } [I{x1:n } I{x1:n } ]) P(I{o1:n } ) = P({o1:n }) = 0,
first inequality follows monotonicity coherent lower previsions (as consequence C1 C2). Therefore, find P({o1:n }) = 0, sequences optimal,
resulting opt (X1:n |o1:n ) = X1:n .
use natural extension update joint model, optimal state sequences
still given Equation (13), final equivalence longer holds uses Theorem 2,
assumes use regular extension perform updating joint model. However,
special case P({o1:n }) = 0, natural extension definition leads updated model
equal vacuous one. Therefore, find x1:n X1:n x1:n X1:n
P(I{x1:n } I{x1:n } |o1:n ) = min(I{x1:n } I{x1:n } ) 0.
implies special case P({o1:n }) = 0 P({o1:n }) > 0identical
found regular extensionnatural extension also results sequences optimal, meaning
opt (X1:n |o1:n ) = X1:n .
thus shown that, even special case P({o1:n }) = 0 P({o1:n }) > 0,
set optimal sequences same, regardless whether use natural regular extension
update joint model. Since special case, every coherent updating method lies
two methods, bound yield opt (X1:n |o1:n ).
therefore conclude results paper depend particular updating method
chosen, long coherent.
4.3 Decision Criteria
Instead looking maximal state sequences, one could use decision criteria well (Troffaes, 2007), two discuss present section.
first approach consider on, consists trying find so-called
-maximin state sequences x1:n , maximise posterior lower probability:
x1:n argmax P({x1:n }|o1:n ).
x1:n X1:n

approach basically optimises worst-case scenariothe lower probabilityand therefore regarded risk averse choice. computational point view, finding maximin sequences rather complicated affair. need optimise exponential number sequences, top that, every single lower probability P({x1:n }|o1:n )
optimisation problem hard compute. positive side, recently discovered thatin
case epistemic irrelevanceit possible calculate lower probabilities efficiently
recursive manner. However, results published yet fall beyond scope
current paper. know algorithm calculate lower probabilities efficiently.
case, issue still remains need optimise exponentially large set X1:n .
201

fiD E B OCK & E C OOMAN

second approach considered consists working so-called
E-admissible sequences, sequences maximise expected gain least one
conditional mass function p(|o1:n ) credal set associated updated lower prevision
P(|o1:n ). one interprets imprecise model collectiona credal setof precise models,
one unknown true model, one E-admissible solutions unknown
true solution. E-admissible state sequences difficult compute. intuitive reason
need solve precise problem every p(|o1:n ) credal set associated
P(|o1:n ), infinitely many. State art algorithms (Kikuti, Cozman, & de Campos, 2005; Utkin & Augustin, 2005) avoid issue, still quadratic search space.
makes intractable present problem search space X1:n exponential
length iHMM.
Besides computational difficulties approaches, number additional reasons why, paper, focus maximal state sequences rather -maximin
E-admissible ones. first important reason able develop algorithm
determine efficiently; see Sections 6 7. Secondly, common advantage
maximality E-admissibility: higher imprecision model, solutions
returned. contrast, even high imprecision, cases, one -maximin
sequence (except two sequences highest conditional lower probability).
application Section 9 clearly illustrates emitting single solution indeed
useful. Thirdly, cases decision criteria preferred, maximal state sequences still use every -maximin E-admissible state sequence guaranteed
maximal well (Troffaes, 2007). algorithm yields single maximal solution,
also unique -maximin E-admissible solution. one maximal sequence
returned, regarded preprocessing step. example, know maximal
solutions, finding -maximin solutions amounts comparing posterior lower probabilities
maximal sequences only, instead sequences X1:n .
4.4 Maximal Subsequences
shall see order find set maximal estimates, useful consider
general sets so-called maximal subsequences: k {1, . . . , n} xk1 Xk1 , define
opt (Xk:n |xk1 , ok:n ):
xk:n opt (Xk:n |xk1 , ok:n ) (xk:n Xk:n ) Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) 0.

(14)

interpretation sets immediate consider part original iHMM
depicted Figure 4, take Qk (|xk1 ) marginal model first state Xk . Then,
explained Section 3.3, corresponding joint lower prevision G (Xk:n Ok:n ) precisely
Pk (|xk1 ), sequence outputs ok:n , opt (Xk:n |xk1 , ok:n ) set state
sequence estimates undominated estimate Xk:n . clear
set opt (X1:n |o1:n ) eventually looking for, also written opt (X1:n |x0 , o1:n ).
4.5 Useful Recursion Equations
Fix k {1, . . . , n}. look Equation (14), see useful derive manageable expression lower prevision Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ). easily donesee
202

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

Qk (|xk1 )

Qr (|Xr1 )

Qn (|Xn1 )

State subsequence:

Xk

Xr

Xn

Output subsequence:

Ok





Sk (|Xk )

Sr (|Xr )

Sn (|Xn )

Figure 4: Tree representation part original iHMM

Appendix Aby using Equations (3)(7) algebraic manipulations. consider three different cases. xk = xk k {1, . . . , n 1} then, using notation introduced Section 3.3:
Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 )
= Qk ({xk }|xk1 )Sk ({ok }|xk ) fi Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } ]|xk ). (15)
xn = xn
Pn (I{on } [I{xn } I{xn } ]|xn1 ) = 0.

(16)

Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) = Qk (I{xk } (xk:n ) I{xk } (xk:n )|xk1 ),

(17)

xk 6= xk k {1, . . . , n}

define, xk:n Xk:n :
n

(xk:n ) := E k (I{ok:n } I{xk+1:n } |xk ) = Sk ({ok }|xk )



Si ({oi }|xi )Qi ({xi }|xi1 )

(18)



Si ({oi }|xi )Qi ({xi }|xi1 ).

(19)

i=k+1
n

(xk:n ) := E k (I{ok:n } I{xk+1:n } |xk ) = Sk ({ok }|xk )

i=k+1

useful realise (xk:n ) (xk:n ) shorthand notations lower upper
probabilities Equations (8) (9), fixed sequence observations. given sequence
states xk:n Xk:n , (xk:n ) (xk:n ) found simple backward recursion:
(xk:n ) := (xk+1:n )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk )
(xk:n ) := (xk+1:n )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk ),

(20)
(21)

k {1, . . . , n 1}, starting from:
(xn:n ) = (xn ) := Sn ({on }|xn ) (xn:n ) = (xn ) := Sn ({on }|xn ).
203

(22)

fiD E B OCK & E C OOMAN

5. Principle Optimality
Determining state sequences opt (X1:n |o1:n ) directly using Equation (13) clearly complexity exponential length chain. going take dynamic programming approach (Bellman, 1957) reducing complexity deriving recursion equation
sets optimal (sub)sequences opt (Xk:n |xk1 , ok:n ).
Theorem 3 (Principle Optimality). k {1, . . . , n 1}, xk1 Xk1 xk:n Xk:n :
Qk ({xk }|xk1 ) > 0 Sk ({ok }|xk ) > 0,
xk:n opt (Xk:n |xk1 , ok:n ) xk+1:n opt (Xk+1:n |xk , ok+1:n ) .
immediate consequence, find
opt (Xk:n |xk1 , ok:n ) cand (Xk:n |xk1 , ok:n ) ,

(23)

set cand (Xk:n |xk1 , ok:n ) consists sequences Xk:n still element
opt (Xk:n |xk1 , ok:n ) according Theorem 3:
cand (Xk:n |xk1 , ok:n )

:=

[


xk opt (Xk+1:n |xk , ok+1:n )

[


xk Xk+1:n . (24)

xk Pos
/
k (xk1 )

xk Posk (xk1 )

denotes concatenation state sequences set states Posk (xk1 ) Xk defined
xk Posk (xk1 ) Qk ({xk }|xk1 ) > 0 Sk ({ok }|xk ) > 0.

(25)

Equation (24) simplifies
cand (Xk:n |xk1 , ok:n ) =

[

xk opt (Xk+1:n |xk , ok+1:n )

(26)

xk Xk

local lower probabilities positive, generally true general case
considering here, upper probabilities required positive.

6. Algorithm Finding Maximal State Sequences
use Equation (23) devise algorithm constructing set opt (X1:n |o1:n ) maximal
state sequences recursive manner.
6.1 Initial Set-up Using Backward Recursion
begin defining auxiliary notions. First all, consider following thresholds:
n

k (xk , xk |xk1 ) := min 0 : Qk (I{xk } aI{xk } |xk1 ) 0
(27)
k {1, . . . , n}, xk1 Xk1 x1 , x1 X1 x1 6= x1 .
204

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

Next, define
kmax (xk ) := max (zk:n ) kmax (xk ) := max (zk:n )
zk:n Xk:n
zk =xk

zk:n Xk:n
zk =xk

(28)

k {1, . . . , n} xk Xk . Using Equations (20)(21), calculated efficiently
using following backward recursive (dynamic programming) procedure:
kmax (xk ) =

max
max k+1
(xk+1 )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk )

xk+1 Xk+1

max
= Sk ({ok }|xk ) max k+1
(xk+1 )Qk+1 ({xk+1 }|xk ),
xk+1 Xk+1

(29)


kmax (xk ) =

max
max k+1
(xk+1 )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk )

xk+1 Xk+1

max
= Sk ({ok }|xk ) max k+1
(xk+1 )Qk+1 ({xk+1 }|xk ),
xk+1 Xk+1

(30)

k {1, . . . , n 1}, starting
nmax (xn ) = (xn ) = Sn ({on }|xn ) nmax (xn ) = (xn ) = Sn ({on }|xn ).

(31)

Finally, let
opt

k (xk |xk1 ) := max kmax (xk )k (xk , xk |xk1 ),
xk Xk
xk 6=xk

(32)

k {1, . . . , n}, xk1 Xk1 xk Xk .
6.2 Recursive Solution Method
opt

turns k (xk |xk1 ), calculated Equation (32), extremely useful. proved
Appendix A, allow us significantly simplify Equation (14) follows:
n

opt
opt (Xk:n |xk1 , ok:n ) = xk:n cand (Xk:n |xk1 , ok:n ) : (xk:n ) k (xk |xk1 ) ,

(33)

which, k = n, reduces


opt (Xn |xn1 , ) = xn Xn : (xn ) nopt (xn |xn1 ) .

(34)

Since opt (X1:n |x0 , o1:n ) = opt (X1:n |o1:n ), suggest following algorithm constructing
set maximal state sequences.
205

fiD E B OCK & E C OOMAN

Algorithm 1: ConstructMaximals
opt

Data: local lower upper probabilities parameters kmax k
(calculated Section 6.1)
Result: set maximal state sequences: opt (X1:n |o1:n )
1
2
3
4
5
6
7
8
9
10

xn1 Xn1
opt (Xn |xn1 , ) 0/
xn Xn
opt
(xn ) n (xn |xn1 ) add xn opt (Xn |xn1 , )
k n 1 1
xk1 Xk1
opt (Xk:n |xk1 , ok:n ) 0/
xk:n cand (Xk:n |xk1 , ok:n )
opt
(xk:n ) k (xk |xk1 ) add xk:n opt (Xk:n |xk1 , ok:n )
return opt (X1:n |x0 , o1:n )

Algorithm 1 already much efficient straightforward implementation
Equation (13), still room improvement. Posk (xk1 ) 6= Xk , Equation (24),
know cand (Xk:n |xk1 , ok:n ) number elements exponential length
considered sequences, making inefficient execute steps Lines 8 9 Algorithm 1.
order circumvent problem, propose method require explicit check
inequality Criterion (33) elements cand (Xk:n |xk1 , ok:n ). approach identical
Algorithm 1, except Lines 8 9, replaced Lines 8 9, given
Algorithm 2.
Algorithm 2: efficient alternative Lines 8 9 Algorithm 1
...
...
...
xk Xk
opt
kmax (xk ) k (xk |xk1 ) Recur(xk , k)

8
9

...

order able define recursive procedure Recur used Line 9 Algorithm 2,
need additional notation. First all, k {1, . . . , n}, {k, . . . , n}, xk1 Xk1 ,
xk:s Xk:s ok:n Ok:n , define
candxk:s (Xk:n |xk1 , ok:n ) := {xk:n cand (Xk:n |xk1 , ok:n ) : xk:s = xk:s } .

(35)
opt

Secondly, k {1, . . . , n}, {k, . . . , n}, xk1 Xk1 xk:s Xk:s , define k (xk:s |xk1 )
opt
opt
follows. = k, let k (xk:k |xk1 ) := k (xk |xk1 ), given Equation (32).
206

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

opt

{k + 1, . . . , n}, k (xk:s |xk1 ) recursively defined
opt

opt
k (xk:s |xk1 )

k (xk:s1 |xk1 )
=
.
Ss1 ({os1 }|xs1 )Qs ({xs }|xs1 )

(36)

Procedure Recur(xk:s , s)
1
2
3
4
5
6

= n
add xk:n opt (Xk:n |xk1 , ok:n )
else
xs+1 Xs+1
candxk:s xs+1 (Xk:n |xk1 , ok:n ) 6= 0/
opt
max (x
s+1
s+1 ) k (xk:s xs+1 |xk1 ) Recur(xk:s xs+1 , + 1)

following result establishes Lines 8 9 Algorithm 2 indeed valid alternative
Lines 8 9 Algorithm 1.
Theorem 4. set opt (Xk:n |xk1 , ok:n ) obtained executing Algorithm 2 correct,
sense satisfies Equation (33).
show Section 7, Algorithm 2 surprisingly efficient. One reasons
efficiency checking if-conditions Lines 5 6 Procedure Recur really easy,
perhaps contrast one might think first sight. condition Line 6,
opt
opt
one use Equation (36) derive k (xk:s xs+1 |xk1 ) k (xk:s |xk1 ), latter
opt
either available previous call Procedure Recur or, = k, equal k (xk |xk1 ),
already calculated initial set-up phase (see Section 6.1).
explain checking condition Line 5 easy well, first need introduce data
structure use store sets opt (Xk:n |xk1 , ok:n ) optimal sequences.
k = n, opt (Xn |xn1 , ) simply list states xn Xn . k < n, could also store
optimal sequences xk:n opt (Xk:n |xk1 , ok:n ) simple list, would imply storing
information multiple times, since initial part sequences identical.
Furthermore, would make checking condition Line 5 Procedure Recur elaborate.
therefore choose represent set opt (Xk:n |xk1 , ok:n ) collection trees. xk Xk
satisfies inequality Line 9 corresponds root tree. paths trees
correspond elements opt (Xk:n |xk1 , ok:n ).
Example 2. consider simple binary HMM with, {1, . . . , n}, Xi = {0, 1}.
k = n 7, could example find
opt (Xk:n | 0, ok:n ) = {00001000, 00001010, 00001110, 00011110, 10001010, 10001110}.
set optimal sequences also represented collection trees, depicted
Figure 5.

Representing opt (Xk:n |xk1 , ok:n ) collection trees two important advantages.
first advantage collection trees constructed step step running Algorithm 2. Line 9 algorithm, every call Procedure Recur, add current
207

fiD E B OCK & E C OOMAN

0

0

0

1

0

0

1

1

1

0

0

0

0

1

1

1

1

0

1

0

0

0

1

0

1

0

1

1

0

Figure 5: Tree representation opt (Xk:n | 0, ok:n ), k = n 7
state xk root node new tree. every subsequent recursive call Procedure Recur
(in Line 6 procedure), add new child xs+1 already existing node xs , xs
last state presently considered sequence xk:s .
order step step construction lead representation opt (Xk:n |xk1 , ok:n ),
path resulting set trees must length n k + 1. words, necessary
every node representation least one child, except nodes form end
path length n k + 1. Equivalently, technically, necessary every
execution Line 4 Procedure Recur, least one xs+1 Xs+1 satisfies subsequent
if-conditions (in Lines 5 6). following result establishes condition always met.
Theorem 5. Fix k {1, ..., n 1} {k, ..., n 1} consider execution Procedure Recur(xk:s , s) running Algorithm 2. least one xs+1 Xs+1
obtain candxk:s xs+1 (Xk:n |xk1 , ok:n ) 6= 0/ [the if-condition Line 5]
opt
max (x
s+1
s+1 ) k (xk:s xs+1 |xk1 ) [the if-condition Line 6].
left explain if-condition Line 5 Procedure Recur
checked efficiently. consider two distinct cases: xk Posk (xk1 ) xk
/ Posk (xk1 ).
xk
/ Posk (xk1 ), Equations (24) (35), find
candxk:s xs+1 (Xk:n |xk1 , ok:n ) = xk:s xs+1 Xs+2:n 6= 0,
/
makes if-condition Line 5 trivially true. xk Posk (xk1 ), Equations (24) (35), candxk:s xs+1 (Xk:n |xk1 , ok:n ) 6= 0/ opt (Xk+1:n |xk , ok+1:n ) contains
sequence starts xk+1:s xs+1 . represent opt (Xk+1:n |xk , ok+1:n ) collection
trees, equivalent checking whether xs+1 child node corresponds last
state sequence xk:s .
brings us second advantage representing sets optimal sequences collection trees: makes checking if-condition Line 5 Procedure Recur elegant
efficient. Line 8 Algorithm 2, xk
/ Posk (xk1 ), subsequent calls
Procedure Recur, Line 5 simply ignored. xk Posk (xk1 ), subsequent calls Procedure Recur, Lines 5 6 condensed single for-loop
runs children node corresponds xs . Hence, xk Posk (xk1 ), executing
Line 8 Algorithm 2including subsequent recursive calls Procedure Recurcan
208

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

done efficiently traversing depth-first trees make representation
opt (Xk+1:n |xk , ok+1:n ), copying go, except nodes condition
Line 6 Procedure Recur satisfied.
Example 3. continue Example 2. time, let k = n 8, implies Figure 5
representation opt (Xk+1:n | 0, ok+1:n ). sake example, let us assume
0 Posk (0) 1
/ Posk (0). know Equations (23) (24) every sequence
xk:n opt (Xk:n | 0, ok:n ) element either 0 opt (Xk+1:n | 0, ok+1:n ) 1 Xk+1:n . Hence,
opt (Xk:n | 0, ok:n ) might example representation looks like one depicted Figure 6.
0

1

0

0

0

0

0

0

1

1

1

0

1

1

0

0

1

1

1

1

0

1

1

1

1

1

0
1

Figure 6: Tree representation opt (Xk:n |0, ok:n ), k = n 8
Figure 7 clarify Algorithm 2 constructs representation. two sequences
opt (Xk:n | 0, ok:n ) start 0 correspond greengrey monochrome versions
paperbranches topmost part Figure 7. first node two sequences added
Line 9 Algorithm 2 (in case, if-condition line turned true).
green nodes topmost part Figure 7 added subsequent calls
Procedure Recur. Checking if-condition Line 5 procedures done traversing
depth-first nodes representation opt (Xk+1:n | 0, ok+1:n ). redgrey
thicker outline monochrome versions papernodes correspond states
if-condition Line 6 satisfied. (white) descendants red nodes never
visited algorithm; depict allow easy comparison Figure 5.
tree representation three sequences opt (Xk:n | 0, ok:n ) start 1 constructed
similar manner, illustrated bottommost part Figure 7. main difference
sequences, since 1
/ Posk (0), if-condition Line 5 Procedure Recur
trivially true, implying algorithm need traverse tree representation
opt (Xk+1:n | 1, ok+1:n ), rather trough complete set Xk+1:n . Again, stop whenever
if-condition Line 6 satisfied, symbolised red nodes.

6.3 Additional Comment
might happen available information consists assessments lower upper
transition emission probabilities only:
Qk ({xk }|xk1 ), Qk ({xk }|xk1 ), Sk ({ok }|xk ) Sk ({ok }|xk )
209

fiD E B OCK & E C OOMAN

opt (Xk+1:n | 0, ok+1:n )

0

0

0

1

0

0

1

1

1

0

0

0

0

1

1

1

1

0

1

0

0

0

1

0

1

0

1

1

0

0

0

0

0

0

0

1
1

0

0

1

1

1

1

0

1

1

0

0

0

0

1

1

1

1

1

0
1

Figure 7: Clarification construction opt (Xk:n |0, ok:n ), k = n 8

k {1, . . . , n}, xk1 Xk1 , xk Xk ok Ok . case, one use following method construct, k {1, . . . , n}, xk1 Xk1 xk , xk Xk xk 6= xk ,
conservative value threshold k (xk , xk |xk1 ).
conservative coherent models Qk (|Xk1 ) correspond assessments lower
upper probabilities singletons 2-monotone (de Campos, Huete, & Moral, 1994). Due
comonotone additivity (De Cooman, Troffaes, & Miranda, 2008), implies that:
Qk (I{xk } aI{xk } |xk1 ) = Qk ({xk }|xk1 ) aQk ({xk }|xk1 )
0, therefore Equation (27) leads

k (xk , xk |xk1 ) =

Qk ({xk }|xk1 )
Qk ({xk }|xk1 )

.

right-hand side smallest possible value threshold k (xk , xk |xk1 ) corresponding
assessments Qk ({xk }|xk1 ) Qk ({xk }|xk1 ), leading conservative inferences
therefore largest possible sets maximal sequences correspond assessments.
210

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

7. Discussion Algorithms Complexity
section discusses computational compexity different steps EstiHMM algorithm, developed previous section. end, find total complexity
EstiHMM algorithm polynomial size inputquadratic length iHMM
cubic number states, well linear size outputthe number maximal sequences opt (X1:n |o1:n ). linearity size output especially interesting;
discuss Section 7.4.
7.1 Preparatory Calculations
begin preparatory calculations quantities Equations (27)(32). thresholds k (xk , xk |zk1 ) Equation (27), computational complexity clearly cubic number
states, andexcept stationary iHMMslinear length iHMM. Calculating
kmax (xk ) kmax (xk ) Equations (29) (30) linear length iHMMeven staopt
tionary iHMMsand quadratic number states. complexity finding k (xk |xk1 )
Equation (32) thereforein worst, non-stationary caselinear lenght iHMM
cubic number states.
7.2 Algorithm 2
computational complexity Algorithm 2 less trivial. Let us start noting construction essentially consists repeating small step again, namely executing
Procedure Recur. explained previous section, data structurea collection
treesenables us efficiently. three if-conditions Procedure Recur
checked constant time. Therefore, taking account for-loop Line 4, find
computational complexity single execution Procedure Recur linear number
states.
Next, notice every optimal sequence xk:n obtained running Algorithm 2 constructed adding extra states xs+1 already constructed sequence xk:s , repeating going
k n 1. Adding state means executing Procedure Recur once, therefore
linear number states. Similarly, creating first state xk linear number
states welldue for-loop Line 8 Algorithm 2. Hence, constructing single optimal
sequence xk:n linear length sequence, well linear number states.
Theorem 5, also know every execution Procedure Recur guaranteed part
construction least one optimal sequence. Therefore, find constructing single
set opt (Xk:n |xk1 , ok:n )executing Algorithm 2is linear number optimal sequences
consists of, linear length sequences linear number states.
7.3 Algorithm 1
Algorithm 1 basically obtain set opt (X1:n |o1:n ) construct sets
opt (Xk:n |xk1 , ok:n ), every xk1 Xk1 , letting k run n 1. k = n fixed
xn1 Xn1 , linear number statessee Lines 3 4 Algorithm 1. k < n
fixed xk1 Xk1 , comes executing Algorithm 2. shown previous
section, Algorithm 2 linear number optimal sequences opt (Xk:n |xk1 , ok:n ), linear
length sequences (n k + 1) linear number states. Hence, conclude
211

fiD E B OCK & E C OOMAN

complexity Algorithm 1 quadratic length iHMM, quadratic number
states roughly speaking6 linear number maximal sequences.
7.4 Total Complexity
complete EstiHMM algorithm consists preparatory calculations Section 6.1 single execution Algorithm 1, where, latter, Lines 8 9 replaced efficient
versions Algorithm 2. conclude previous sections total computational complexity isat worstquadratic length iHMM, cubic number
states, roughly speaking linear number maximal sequences.
linearity number maximal sequences clearly remaining bottleneck
algorithm, since may exponentially many sequences. However, lead
reader conclude EstiHMM algorithm exponential complexity, meaning
exponential size inputthe length iHMM number states. crucial
realise complexity linear size outputthe number maximal sequences,
turn may exponential input. However, long size output bounded,
algorithm guaranteed computational complexity polynomial size
input. guarantee given algorithms whose complexity linear size
inputfor example naive implementation Algorithm 1 replace Lines 8 9
efficient counterparts Algorithm 2.
Although linearity size output might seem rather bad, fact hope for.
Even simply printing outputall maximal sequencesalready computational complexity
linear size well linear length iHMM. Linearity size output
inherent problems necessarily lead single solution, allow set-valued
solutions well. size output large, algorithm, however cleverly designed,
overcome hurdle.
order EstiHMM algorithm choke number maximal sequences
large, one keep trackfor every set opt (Xk:n |xk1 , ok:n )of many times Line 2
Procedure Recur executed far, aborting algorithm whenever preset treshold
exceeded. however possible return k best solutions, simply
thing better worse maximal sequence; incomparable.
way number maximal sequences reduced decreasing imprecision
model: gather extra data expert knowledge, leading smaller local credal sets, pointwise
larger local lower previsions therefore fewer maximal sequences. Alternatively, one could also
consider using E-admissable sequencesof may multiple well, many
maximal onesor -maximin sequencesof which, instances, one. However,
know algorithm calculate E-admissable -maximin sequences efficient
manner, let alone one linear output; see Section 4.3.
7.5 Comparison Viterbis Algorithm
precise HMMs, state sequence estimation problem solved efficiently
Viterbi algorithm (Rabiner, 1989; Viterbi, 1967), whose complexity linear length
HMM, quadratic number states. However, algorithm emits single optimal
6. every k xk1 Xk1 , constructing set opt (Xk:n |xk1 , ok:n ) linear complexity number optimal
sequences stage.

212

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

probablestate sequence, even cases multipleequally probableoptimal
solutions: course simplifies problem. would content giving
single maximal solution, ensuing version algorithm would complexity
similar Viterbis.
So, allow fair comparison Viterbis algorithm ours, would need alter
Viterbis algorithm way longer resolves ties arbitrarily, emits allequally
probableoptimal state sequences. new version remain linear length HMM,
quadratic number states, also added complexity. discussed
previous section, even printing optimal sequences linear number therefore
possibly exponential, example possible solutions equally probableimagine precise
HMM local probability mass functions uniform.
complexity time-consuming part algorithmAlgorithm 1,
difference this: Viterbis approach linear quadratic length HMM.
difference come from? imprecise HMMs mutually incomparable solutions,
whereas precise HMMs optimal solutions indifferent, equally probable. makes
sure algorithm precise HMMs requires forward loops, case EstiHMM
algorithm, every time run Algorithm 2. believe added complexity reasonable
price pay robustness working imprecise-probabilistic models offers.

8. Experiments
Since complexity EstiHMM algorithm depends crucially number maximal
sequences emits, present section study number detail. taking
closer look depends transition probabilities model, evolves
let imprecision local models grow. shall see number maximal
sequences displays interesting behaviour explained, even predicted
extent. allow easy visualisation, limit discussion stationary binary iHMMs,
state output variables assume two possible values, say 0 1.
8.1 Describing Stationary Binary iHMM
precise transition probabilities going one state next completely determined
numbers unit interval: probability p go state 0 state 0, probability
q go state 1 state 0. pin HMM also need specify marginal
probability first state 0, two emission probabilities: probability r
emitting output 0 state 0 probability emitting output 0 state 1.
binary case, coherent imprecise-probabilistic models found contamination:
taking convex mixtures precise models, mixture coefficient 1 , vacuous model,
mixture coefficient , leading so-called linear-vacuous model (Walley, 1991), often referred
-contaminated model well. simplify analysis, let emission model remain
precise, use mixture coefficient marginal transition models.
ranges zero one, evolve precise HMM towards iHMM vacuous
marginal transition models (and precise emission models).
213

fiD E B OCK & E C OOMAN

8.2 iHMM Length Two
examine behaviour iHMM length two, following precise probabilities
fixed:
= 0.1, r = 0.8 = 0.3.
Fixing output sequence value , use algorithm calculate corresponding
numbers maximal state sequences p q range unit interval. results
represented conveniently form heat plot. plots Figure 8 correspond output
sequence o1:2 = 01.
1

1

q

q

= 2%
0

0

p

= 5%
1

1

0

0

1

1

q

q

= 10%
0

p

0

p

= 15%
1

0

0

p

1

Figure 8: Heat plots o1:2 = 01
number maximal state sequences clearly depends transition probabilities p
q. rather large parts probability space coloured white, get single maximal
sequenceas would HMMs, continuous regions see higher number appear. present examplea binary chain length two, highest possible number
maximal sequences course four. dark grey area, three maximal sequences,
two light grey regions. plots show happens let increase: grey
areas expand number maximal sequences increases. = 15%, even find small
areacoloured blackwhere four possible state sequences maximal: locally, due relatively high imprecision local models, cannot provide useful robust estimate
state sequence producing output sequence o1:2 = 01.
214

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

small , areas one maximal state sequence quite small seem
resemble strips narrow lines tends zero. suggests able
explain least qualitatively areas come looking compatible precise models:
regions iHMM produces different maximal (mutually incomparable) sequences,
widened versions loci indifference precise HMMs.
locus indifference, mean set (p, q) correspond two given state sequences
x1:2 x1:2 equal posterior probability:
p(x1:2 |o1:2 ) = p(x1:2 |o1:2 ),
or, provided p(o1:2 ) > 0,
p(x1:2 , o1:2 ) = p(x1:2 , o1:2 ).
example, o1:2 = 01, find following expressions four possible
state sequences:
p(00, 01) = mr(1 r)p;

p(10, 01) = (1 m)s(1 r)q;

p(01, 01) = mr(1 s)(1 p);

p(11, 01) = (1 m)s(1 s)(1 q).

1
00 11

01

10
01

11

10 11


10

00 01

01

q

11

00

0

0

10

p

1

Figure 9: Loci indifference o1:2 = 01
equating two expressions, express corresponding two state sequences
equal posterior probability. Since resulting equations function p q only,
six possible combinations defines locus indifference. depicted lines
Figure 9.
215

fiD E B OCK & E C OOMAN

111000001101000010001000011111111110111101000010110110110000 . . .
111000001101000010001000011111111110111101000010110110110000
110000001101000010001000011111111110111101000010110110110000
111000000101000010001000011111111110111101000010110110110000
111000001100000010001000011111111110111101000010110110110000
111000001101000000001000011111111110111101000010110110110000

...
...
...
...
...

Figure 10: Maximal sequences iHMM length 100
Parts loci, depicted bluedarker bolder monochrome versions paper,
demarcate three regions state sequences 01, 10 11 optimalhave highest
posterior probability.
happens transition models become imprecise? Roughly speaking, nearby values
original p q enter picture, effectively turning locilinesof indifference
bands incomparability: emergence regions two maximal sequences
seen originate loci indifference; compare Figure 9 Figure 8.
8.3 iHMM Length 100
order demonstrate algorithm indeed efficient, let determine maximal
sequences random output sequence length 100.
consider stationary binary HMM before, following precise marginal
emission probabilities:
= 0.1, r = 0.98, = 0.01.
practical applications, probability output variable value corresponding hidden state variable usually quite high, explains chosen r
close 1 0, respectively. contrast previous experiments, let
transition probabilities vary, fix following values:
p = 0.6 q = 0.5.
local models iHMM use determine maximal sequences generated -contaminating precise local models. use mixture coefficient
marginal, transition emission models. Figure 10, show five maximal sequences
correspond highlighted output sequence, = 2%. Due space constraints,
display first 60 digits sequences. Since emission probabilities chosen
quite accurate, surprise output sequence one maximal sequences.
addition, indicated bold face state values differ outputs output
sequence; 40 digits displayed, differences occured. see model
represents indecision values state variables move away
end sequence. result phenomenon called dilation, whichas noted
another paper (De Cooman et al., 2010)tends occur inferences credal tree proceed
leaves towards root.
efficiency algorithm: took 0.2 seconds calculate 5 maximal
sequences.7 reason could done fast algorithm less linear
7. Running Python program 2012 MacBook Pro.

216

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

number solutions (see Section 7), case 5. let grow
example 5%, number maximal sequences output sequence 764
determined 32 seconds. demonstrates complexity indeed
less proportional toand therefore linear inthe number solutions algorithm
efficiently calculate set maximal sequences, even long output sequences. larger values
, say 10%, took 30 minutes determine maximal sequences, leading us abort
algorithm. lead reader conclude large , EstiHMM algorithm
longer linear number maximal sequences. No, simply means thatat least long
iHMMsthis number maximal sequences increase quickly soon passes critical
boundary.

9. Application Optical Character Recognition
first application, use EstiHMM algorithm detect correct mistakes words.
hidden sequence x1:n corresponds original, correct version word, output
sequence o1:n artificially corrupted version. way, simulate observational processes
perfectly reliable, output Optical Character Recognition (OCR) device.
leads observed output sequences may contain errors, try detect
correct. original words taken Dantes Divina Commedia, 1018 words
second canto used training set initial 200 words first canto test
set. comparing results EstiHMM algorithm Viterbi algorithm,
able illustrate advantages former.
9.1 Learning Local Models
order apply algorithm, must identify local uncertainty model original
observed letter: marginal model Q1 first letter X1 original word, transition model
Qk (|Xk1 ) subsequent letters Xk , k {2, . . . , n}, emission model Sk (|Xk )
observed letters Ok , k {1, . . . , n}. use state space X = variables,
consisting 21 letters Italian alphabet. sake simplicity, assume stationarity,
making transition emission models independent k.
identification local models iHMM, use imprecise Dirichlet model
(IDM) (Walley, 1996). corresponds considering set Dirichlet priors fixed
strength > 0, using lower upper bounds inferences obtained priors
model. example, marginal model Q1 , applying IDM leads following
lower upper probabilities:
Q1 ({x}) =

nx
+ nx
Q1 ({x}) =
x X,
+ zX nz
+ zX nz

where, z X, nz number words training text first letter X1
equal z. hyperparameter regarded degree caution taken account
inferences. use = 2; Walley (1996, Section 2.5) provides number arguments
favour choice. transition emission models, proceed similarly, counting
transitions one letter another, respectively original word observation
process. way, obtain lower upper transition emission probabilities singletons,
which, pointed Section 6.3, suffice run algorithm. fact, since IDM leads
217

fiD E B OCK & E C OOMAN

local models linear-vacuous hence completely therefore also 2-monotone,
approach described Section 6.3 actually leads exact values parameters k (xk , xk |xk1 )
instead conservative approximation.
identification local models precise HMM, use similar precise
Dirichlet model approach, Perkss prior prior strength = 2. example,
precise marginal model Q1 , leads following simple identification:
Q1 ({x}) =

s/|X | + nx

+ zX nz

,

|X | number states.
difference precise imprecise models constructed way described relatively small. example, using training set 1018 words, 67
start letter A, obtained following (lower, upper precise) probability first
letter word A:
Q1 ({A}) = 0.06569, Q1 ({A}) = 0.06578 Q1 ({A}) = 0.06765.
Nevertheless, illustrated next section, imprecise model lead results rather
diferent obtained precise model.
9.2 Results
Let us first discuss example difference results obtained Viterbi
EstiHMM algorithm, order illustrate important advantage latter. OCR software
mistakenly read Italian word QUANTO OUANTO. Using precise model, Viterbi algorithm correct mistake, suggests original correct word DUANTO.
EstiHMM algorithm hand, using imprecise model, returns CUANTO, DUANTO,
FUANTO QUANTO maximal, undominated solutions, including correct one. course
would still pick correct solution set suggestionsfor example using dictionary human opinion, using EstiHMM algorithm, managed
reduce search space possible five letter words much smaller set four words
given above. Notice solution Viterbi algorithm included maximal solutions
EstiHMM returns. One easily prove always case.
applied method first 200 words first canto Dantes Divina Commedia,
137 correctly read artifical OCR device 63 contained errors.
tried correct errors using EstiHMM Viterbi algorithm, compare
approaches. results summarised Table 1.
Viterbi algorithm, main conclusion applying output OCR device
results decreased number incorrect words. number correct words rises 68.5%
78.5%. However, Viterbi algorithm also introduces new errors 5 correctly read words.
EstiHMM algorithm manages suggest original correct word one solutions
86% cases. Assuming able detect correct word, percentage correct
words rises 68.5% 86% applying EstiHMM algorithm, thereby outperforming
Viterbi algorithm almost 10%. Secondly, also notice EstiHMM algorithm never
introduced new errors words already correct.
218

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

total number
Viterbi
correct solution
wrong solution
EstiHMM
correct solution included
correct solution included

total number
200 (100%)

correct OCR
137 (68.5%)

wrong OCR
63 (31.5%)

157 (78.5%)
43 (21.5%)

132
5

25
38

172 (86%)
28 (14%)

137
0

35
28

Table 1: Summary results EstiHMM Viterbi algorithm

course, since EstiHMM algorithm allows multiple solutions, instead single one,
surprise manage increase amount times suggest correct solution.
would happen even added random extra solutions solution Viterbi algorithm.
Giving extra solutions seen improvement done smartly. investigate
this, distinguish cases EstiHMM algorithm returns single solution,
returns multiple solutions; look Viterbi EstiHMM algorithms
compare two cases.
EstiHMM algorithm returned single solution 155 200 words.
already mentioned above, single solution always coincide one given Viterbi
algorithm. results EstiHMM Viterbi algorithms summarised Table 2.
EstiHMM (single solutions)
total number
single correct solution
single wrong solution

total number
155 (100%)
134 (86.5%)
21 (13.5%)

correct OCR
129 (83.2%)
129
0

wrong OCR
26 (16.8%)
5
21

Table 2: instances EstiHMM produces single estimate
percentage words correctly read OCR software 83.2% instead global
68.5%. result EstiHMM algorithm single solution, serves indication
word trying correct fairly high probability already correct. also
see eventual percentage correct words 86.5%, slight improvement
83.2% already correct applying algorithms.
Next, look remaining 45 words, EstiHMM algorithm returns
one maximal element. case, see significant difference results
Viterbi EstiHMM algorithm Viterbi algorithm always returns single
solution. results algorithms listed Table 3.
first important conclusion drawn table EstiHMM algorithm indecisive, serves rather strong indication word applying
algorithm indeed contain errors: EstiHMM algorithm returns multiple solutions,
original word incorrectly read OCR software 82.2% cases.
219

fiD E B OCK & E C OOMAN

total number
EstiHMM (multiple solutions)
correct solution included
correct solution included
Viterbi
correct solution
wrong solution

total number
45 (100%)

correct OCR
8 (17.8%)

wrong OCR
37 (82.2%)

38 (84.4%)
7 (15.6%)

8
0

30
7

23 (51.1%)
22 (48.9%)

3
5

20
17

Table 3: instances EstiHMM produces set-valued estimate

second conclusion, related first, EstiHMM algorithm indecisive,
also serves indication result returned Viterbi algorithm less reliable:
percentage correct words applying Viterbi algorithm dropped 51.1%, contrast
global percentage 78.5%. EstiHMM algorithm, however, still gives correct
word one solutions 84.4% cases, almost high global percentage
86%. set given EstiHMM algorithm contains correct solution, Viterbi algorithm
manages pick correct solution set 60.5% cases. see EstiHMM
algorithm seems notice dealing difficult words therefore gives us
multiple solutions, cannot decide.
9.3 Advantages Imprecise Approach
learn experiments EstiHMM algorithm usefully applied make
results Viterbi algorithm robust, gain appreciation likely go
wrong. EstiHMM algorithm indeterminate, serves indication robustness issues
would occur solved problem Viterbi algorithm. instances,
EstiHMM algorithm returns multiple solutions, cannot decide, whereas
Viterbi algorithm pick one set fairly arbitrary waydepending choice
prior, thereby increasing amount errors made.
leads us conclude imprecise approach EstiHMM algorithm two main
advantages. first advantage easily detect precise approach becomes
sensitive adopted prior: kind sensitivity occurs exactly instances
EstiHMM algorithm returns indeterminate result. second advantage that, instead simply
detecting sensitivity choice prior, EstiHMM algorithm also offers alternative
solution suffer issues, form set maximal sequencesa set
suggestions correct hidden word. illustrated experiments, set often
contain actual correct word.
Future work could try exploit set-valued solutions trying pick correct word
given set options non-arbitrary way. could example done
comparing options entries dictionary. Alternatively, one could consider asking
user feedback, asking choose among options. way, additional data gathered
used build better model less sensitive choice prior.
220

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

10. Conclusions
Interpreting graphical structure imprecise hidden Markov model credal network
epistemic irrelevance leads efficient algorithm finding maximal, undominated hidden
state sequences given observed sequence. interesting feature algorithm
computational complexity linear size outputthe number maximal state
sequences. Preliminary simulations show that, even long iHMMs transition models
non-negligible imprecision, number maximal state sequences often reasonably low.
remains seen whether observation corroborated deeper theoretical analysis.
application OCR clearly shows EstiHMM algorithm able robustify
results Viterbi algorithm. reduce amount wrong conclusions
providing extra possible solutions, intelligent manner. adds extra solutions
specific cases Viterbi algorithm likely wrong, thereby also serving indicator
reliability result given Viterbi algorithm. Since set-valued solutions often
contain correct hidden state sequence, usefully applied postprocessing phase,
example offering set user, asking feedback.
first important avenue future research would compare EstiHMM algorithm
methods also try robustify Viterbi algorithm producing set-valued solutions.
distinguish two different approaches.
one hand, imprecise methods one adopted us. combine
imprecise model imprecise-probabilistic decision criterion. paper, chosen
use maximality decision criterion. However, decision criteria adopted well; see
Section 4.3. criteria, E-admissibility, also lead set-valued estimates.
common feature methods take account model uncertainty:
happens inferences model imperfect? happens instead single probability mass function, set possible candidates? many instances, resulting inferences
still determinate. Set-valued solutions typically obtained instances
precise-probabilistic approach likely wrong.
hand, precise models may lead set-valued solutions well. context
HMMs, important example seems k-best Viterbi algorithm (Brown & Golod,
2010). Instead returning posteriori probable hidden state sequence, k-best
Viterbi algorithm returns k probable hidden state sequences. two important
differences imprecise approaches described above. First all, k-best approach
nothing model uncertainty. Instead, deals probabilistic uncertainty
inherent model itself, assuming model perfectly known. model
indeed correct, returning k probable sequences, probability correct
estimate included set-valued solution increases, expense losing determinacy.
Secondly, related previous difference, k-best method always return k sequences,
regardless accuracy 1-best approach. contrast, imprecise approaches typically
able distinguish easy hard cases, producing determinate answers former
set-valued answers latter. Nevertheless, despite differences, one gets impression
k-best method used tackle similar applications EstiHMM algorithm. would
interesting check whether indeed case, compare respective results.
leave topic future research.
221

fiD E B OCK & E C OOMAN

Another, theoretical avenue future research investigate extent
ideas presented paper applied credal networks iHMMs epistemic
irrelevance. two specific instances concrete ideas proceed. First
all, strong reasons believe possible derive similarly efficient algorithm
iHMMs whose graphical structure interpreted credal network strong independence
rather epistemic irrelevance. could interesting relevant, stringent
independence condition leads joint models less imprecise, therefore produce fewer
maximal state sequencesalthough included solutions. Secondly, EstiHMM
algorithm demonstrates efficient inference credal trees epistemic irrelevance
necessarily limited queries single target node only. fact, believe possible
develop polyonomial time algorithms, capable solving wide classes inference problems
credal trees epistemic irrelevance, thereby extending results De Cooman et al. (2010).

Acknowledgments
Jasper De Bock Ph.D. Fellow Research Foundation - Flanders (FWO) Ghent University, developed algorithm described context Masters thesis,
close cooperation Gert de Cooman, acted thesis supervisor. present article
describes main results Masters thesis. Research De Cooman supported
SBO project 060043 IWT-Vlaanderen.
authors would like thank anonimous referees paper previous conference version useful, constructive comments. led significant improvement
current version, notably regarding presentation. paper also benefitted discussions Marco Zaffalon, Alessandro Antonucci, Alessio Benavoli, Cassio de Campos, Erik
Quaeghebeur Filip Hermans. grateful Marco Zaffalon providing travel funds,
allowed us visit IDSIA discuss practical applications.

Appendix A. Proofs Main Results
appendix, justify formulas (6), (7), (15), (16), (17), (33) (34) give proofs
Proposition 1 Theorems 25. frequently use terms positive, negative,
decreasing increasing. therefore start clarifying mean them. x R,
say x positive x > 0, negative x < 0, non-negative x 0 non-positive x 0.
call real-valued function f defined R:
(i) increasing (x, R)(x > f (x) > f (y));
(ii) decreasing (x, R)(x > f (x) < f (y));
(iii) non-decreasing (x, R)(x > f (x) f (y));
(iv) non-increasing (x, R)(x > f (x) f (y)).
222

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

Proof Equation (6). k {1, . . . , n}, xk1 Xk1 , xk:n Xk:n ok:n Ok:n infer
Equation (5)
Pk (I{xk:n } I{ok:n } |xk1 ) = Qk (E k (I{xk:n } I{ok:n } |Xk )|xk1 )


fi
fi
= Qk I{zk } E k (I{xk } (zk )I{xk+1:n } I{ok:n } |zk )fixk1
zk Xk

= Qk (I{xk } E k (I{xk+1:n } I{ok:n } |xk )|xk1 ).
Since E k (I{xk+1:n } I{ok:n } |xk ) 0 C1, see C2 transforms
= Qk (I{xk } |xk1 )E k (I{xk+1:n } I{ok:n } |xk ),
reformulated
= Qk (I{xk } |xk1 )Sk (I{ok } |xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk )
= Qk ({xk }|xk1 )Sk ({ok }|xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk ),
take account Equation (4), since Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) 0 C1.
Repeating steps eventually yields Equation (6):
n

Pk (I{xk:n } I{ok:n } |xk1 ) = Qi ({xi }|xi1 )Si ({oi }|xi ).
i=k

last step, k = n, used equality E n ({on }|xn ) = Sn ({on }|xn ), follows
Equation (3).
Proof Equation (7). k {1, . . . , n}, xk1 Xk1 , xk:n Xk:n ok:n Ok:n infer
conjugacy Equation (5)
Pk (I{xk:n } I{ok:n } |xk1 ) = Pk (I{xk:n } I{ok:n } |xk1 )
= Qk (E k (I{xk:n } I{ok:n } |Xk )|xk1 )


fi
fi
= Qk I{zk } E k (I{xk } (zk )I{xk+1:n } I{ok:n } |zk )fixk1
zk Xk

= Qk (I{xk } E k (I{xk+1:n } I{ok:n } |xk )|xk1 )
= Qk (I{xk } (E k (I{xk+1:n } I{ok:n } |xk )))|xk1 ).
Since E k (I{xk+1:n } I{ok:n } |xk ) = E k (I{xk+1:n } I{ok:n } |xk ) 0 conjugacy Lemma 6, see
C2 Equation (2) transform

= E k (I{xk+1:n } I{ok:n } |xk ) Qk (I{xk } |xk1 )
= Qk (I{xk } |xk1 )E k (I{xk+1:n } I{ok:n } |xk ),
reformulated
= Qk (I{xk } |xk1 )Sk (I{ok } |xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk )
= Qk (I{xk } |xk1 )Sk (I{ok } |xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk )
= Qk ({xk }|xk1 )Sk ({ok }|xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk ),
223

fiD E B OCK & E C OOMAN

using conjugacy Equation (4), since Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) 0. last inequality true
know Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) = Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) conjugacy
Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) 0 Lemma 6.
Repeating steps again, eventually yields Equation (7):
n

Pk (I{xk:n } I{ok:n } |xk1 ) = Qi ({xi }|xi1 )Si ({oi }|xi ).
i=k

last step, k = n, used equality E n ({on }|xn ) = Sn ({on }|xn ), follows
Equation (3) conjugacy.
Lemma 6. Consider coherent lower prevision P G (X). Then, f G (X),
min f P( f ) P( f ) max f and, R, P( f ) = P() = .
Proof. prove inequalities min f P( f ) P( f ) max f one one. first one
C1. follows C3 P( f f ) P( f ) + P( f ) therefore, since know
C2 P(0) = 0P(0) = 0, implies P( f ) P( f ) = P( f ), using conjugacy last
equality. gamble f , C1 yields min f P( f ) turn implies max f =
min f P( f ) = P( f ).
conclude, P( f ) = P() = follows applying inequalities f = .
Proof Proposition 1. Observe

Pk (I{ok:n } |xk1 ) = Pk I{ok:n }



zk:n Xk:n




fi
fi
fi
fi
I{zk:n } fixk1 Pk I{ok:n } I{zk:n } fixk1 > 0,

zk:n element Xk:n . equality follows zk:n Xk:n I{zk:n } = 1, first inequality
Lemma 8(ii), second one positivity assumption (10) Equation (7).
way, easily prove


fi
fi
fi
fi

E k ({ok:n }|xk ) = E k I{ok:n }
I{zk+1:n } fixk E k I{ok:n } I{zk+1:n } fixk > 0.
zk+1:n Xk+1:n

time, used positivity assumption (10) Equation (9) last inequality.
Proof Theorem 2. Consider real-valued function , defined
() := P(I{o1:n } [I{x1:n } I{x1:n } ]) R.
follows Equation (11) P(I{x1:n } I{x1:n } |o1:n ) rightmost zero, also know
(0) = P(I{o1:n } [I{x1:n } I{x1:n } ]). Furthermore, non-increasing continuous Lemma
7(i), least one zero Lemma 7(ii). Hence, (0) > 0, least one positive
zero P(I{x1:n } I{x1:n } |o1:n ) > 0. (0) < 0, negative zeroes find
P(I{x1:n } I{x1:n } |o1:n ) < 0. Hence, proving theorem comes proving (0) = 0
implies () < 0 > 0, since turn implies P(I{x1:n } I{x1:n } |o1:n ) = 0.
prove implication. consider two different cases.
224

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

case x1 = x1 . real > 0:
() = P(I{o1:n } [I{x1:n } I{x1:n } ])
= Q1 (E 1 (I{o1:n } [I{x1:n } I{x1:n } ]|X1 ))

= Q1 I{x1 } E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) +




I{z1 } E 1 (I{o1:n } |z1 ) .

(37)

z1 6=x1

coefficients E 1 (I{o1:n } |z1 ) written E 1 ({o1:n }|z1 ) conjugacy C2,
makes negative, decreasing functions , since E 1 ({o1:n }|z1 ) > 0 positivity assumption (10) Proposition 1.
coefficient E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ), consider two possible cases.
E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) > 0, know E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) decreasing function Lemma 7(vi). Therefore, argument Q1 Equation (37) decreases
pointwise , Lemma 8(i) implies () decreasing function therefore
() < (0) = 0.
If, hand, E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) 0, know Lemma 8(ii)
E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) 0, implying

() Q1




I{z1 } E 1 (I{o1:n } |z1 )

z1 6=x1


Q1 I{z1 } E 1 (I{o1:n } |z1 ) = E 1 ({o1:n }|z1 )Q1 {z1 } < 0.
expression, z1 arbitrary z1 6= x1 . first two inequalities due Lemma 8(ii).
Conjugacy C2 yield equality last inequality consequence positivity assumption (10) Proposition 1. Also case, therefore, find () < 0.
case x1 6= x1 . real > 0:
() = P(I{o1:n } [I{x1:n } I{x1:n } ])
= Q1 (E 1 (I{o1:n } [I{x1:n } I{x1:n } ]|X1 ))

= Q1 I{x1 } E 1 (I{o1:n } [I{x2:n } ]|x1 ) + I{x1 } E 1 (I{o1:n } [I{x2:n } ]|x1 )
+




I{z1 } E 1 (I{o1:n } |z1 )

(38)

z1 6=x1 ,x1

proof case x1 = x1 , already shown coefficients E 1 (I{o1:n } |z1 )
negative, decreasing functions . Together Lemma 8(ii), allows us infer
E 1 (I{o1:n } [I{x2:n } ]|x1 ) E 1 (I{o1:n } |x1 ) < 0, turn Lemma 7(vii) implies
E 1 (I{o1:n } [I{x2:n } ]|x1 ) decreasing function . left consider coefficient E 1 (I{o1:n } [I{x2:n } ]|x1 ). two possibilities.
E 1 (I{o1:n } I{x2:n } |x1 ) > 0, Lemma 7(vi) implies E 1 (I{o1:n } [I{x2:n } ]|x1 ) decreasing
function . Therefore, argument Q1 Equation (38) decreases pointwise ,
Lemma 8(i) implies () decreasing function therefore () < (0) = 0.
225

fiD E B OCK & E C OOMAN

If, hand, E 1 (I{o1:n } I{x2:n } |x1 ) = 0, Lemma 8(ii), E 1 (I{o1:n } [I{x2:n } ]|x1 ) 0,
implying
() Q1 (I{x1 } E 1 (I{o1:n } [I{x2:n } ]|x1 ))
Q1 (I{x1 } E 1 (I{o1:n } |x1 )) = E 1 ({o1:n }|x1 )Q1 ({x1 }) < 0.
first two inequalities follow Lemma 8(ii). Conjugacy C2 yield equality,
last inequality consequence positivity assumption (10) Proposition 1. Also
case, then, find () < 0.
Lemma 7. Let P coherent lower prevision G (X). f G (X) , consider
real-valued map defined R () := P(I{y} [ f ]) real . following
statements hold:
(i) non-increasing, concave continuous.
(ii) least one zero.
(iii) P({y}) > 0, decreasing unique zero.
(iv) P({y}) = 0, identically zero.
(v) P({y}) = 0 P({y}) > 0, zero (, P( f |y)], negative decreasing
(P( f |y), +).
(vi) (a) > 0 a, decreasing unique zero.
(vii) negative interval (a, b), also decreasing (a, b).
Proof. start proving (i). follows directly Lemma 8(ii) non-increasing .
consider 1 2 R 0 1. concave
( 1 + (1 )2 ) = P(I{y} [ f ( 1 + (1 )2 )])
= P( I{y} [ f 1 ] + (1 )I{y} [ f 2 ])
P( I{y} [ f 1 ]) + P((1 )I{y} [ f 2 ])
= P(I{y} [ f 1 ]) + (1 )P(I{y} [ f 2 ])
= (1 ) + (1 )(2 ),
inequality follows C3 subsequent step due C2. prove ()
continuous, consider 1 2 R, see
(2 ) = P(I{y} [ f 2 ]) = P(I{y} [ f 1 + (1 2 )])
= P(I{y} [ f 1 ] + I{y} (1 2 )) P(I{y} [ f 1 ]) + P(I{y} (1 2 ))
= (1 ) P({y}) fi (2 1 ),
inequality follows C3, last equality due conjugacy C2. Hence
|(1 ) (2 )| |2 1 |P({y}), proves Lipschitz continuous, therefore also
continuous.
226

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

prove (ii), first notice (min f ) = P(I{y} [ f min f ]) P(I{y} [min f min f ]) = 0
(max f ) = P(I{y} [ f max f ])E P(I{y} [max f max f ]) = 0. inequalities consequence
Lemma 8(ii), last equalities follow Lemma 6. Since () continuous, implies
existence zero min f max f .
Property (iii) proved considering 1 2 R 2 > 1 . P({y}) > 0, see
decreasing, since
(1 ) = P(I{y} [ f 1 ]) = P(I{y} [ f 2 + (2 1 )])
= P(I{y} [ f 2 ] + I{y} (2 1 )) P(I{y} [ f 2 ]) + P(I{y} (2 1 ))
= (2 ) + (2 1 )P({y}) > (2 ),
first inequality follows C3 last equality C2. know (ii)
least one zero, must unique decreasing.
prove (iv), first note P({y}) = 0 also implies P({y}) = 0, Lemma 6. fix
R choose b R
< min{0, min{ f }} max{0, max{ f }} < b.
find () = P(I{y} [ f ]) P(I{y} a) = aP({y}) = 0 () = P(I{y} [ f ])
P(I{y} b) = bP({y}) = 0, using Lemma 8(ii), C2 conjugacy. conclude () = 0
R.
proof (v) starts noticing () 0 (, P( f |y)] () < 0
(P( f |y), +), due definition P( f |y) (see Equation (11)), fact nonincreasing (i). proof (iv), already shown non-positive P({y}) = 0,
allows us conclude () = 0 (, P( f |y)]. left prove
decreasing interval (P( f |y), +). contradiction. Suppose
decreasing interval, 1 2 interval, 2 > 1
0 > (2 ) (1 ). Since zero (, P( f |y)), also choose 0 < 1
(0 ) = 0. existence 0 , 1 2 contradicts concavity , established (i).
prove (vi), observe P({y}) P({y}) 0 Lemma 6. implies three cases
considered (iii), (iv) (v) exhaustive mutually exclusive.
(a) > 0, case considered (iii), implies decreasing
unique zero.
remains prove (vii). repeating argument proof (vi), see
negative interval (a, b), cases considered (iii) (v) obtain. (iii),
decreasing entire domain. (v), definitely decreasing (a, b).
Lemma 8. Consider coherent lower prevision P G (X) two gambles f , g G (X).
(i) f (x) > g(x) x X, P( f ) > P(g).
(ii) f (x) g(x) x X, P( f ) P(g).
Proof. start (i). Since f g pointwise positive, min( f g) > 0 therefore
P( f g) min ( f g) > 0, using C1 first inequality. follows C3
P( f ) = P(( f g) + g) P( f g) + P(g), therefore P( f ) P(g) P( f g) > 0, whence
indeed P( f ) > P(g). proof (ii) analogous; time, min( f g) 0
therefore P( f ) P(g) P( f g) min ( f g) 0.
227

fiD E B OCK & E C OOMAN

Proof Equation (15). Let [xk:n , xk:n ] := I{ok:n } [I{xk:n } I{xk:n } ]. Since considering case
k {1, . . . , n 1} xk = xk , find
[xk:n , xk:n ] = I{ok:n } [I{xk:n } I{xk:n } ] = I{ok } I{xk } I{ok+1:n } [I{xk+1:n } I{xk+1:n } ]
= I{ok } I{xk } [xk+1:n , xk+1:n ],
turn implies
Pk ([xk:n , xk:n ]|xk1 ) = Qk (E k (I{ok } I{xk } [xk+1:n , xk+1:n ]|Xk )|xk1 )
= Qk (I{xk } E k (I{ok } [xk+1:n , xk+1:n ]|xk )|xk1 )
= Qk ({xk }|xk1 ) fi E k (I{ok } [xk+1:n , xk+1:n ]|xk )
= Qk ({xk }|xk1 )Sk ({ok }|xk ) fi Pk+1 ([xk+1:n , xk+1:n ]|xk ),
proving Equation (15). first equality follows Equation (5). second equality holds
I{xk } (zk ) = 0 zk 6= xk , implying
E k (I{ok } I{xk } [xk+1:n , xk+1:n ]|Xk ) = I{xk } E k (I{ok } [xk+1:n , xk+1:n ]|xk ).
third equality follows conjugacy C2, last one follows Equation (4).
Proof Equation (16). Since xn = xn , Lemma 6 yields:
Pn (I{on } [I{xn } I{xn } |xn1 ) = Pn (I{on } [I{xn } I{xn } |xn1 ) = Pn (0|xn1 ) = 0.
Proof Equation (17). k {1, . . . , n} xk 6= xk ,
Pk (I{ok:n } [I{xk:n } I{xk:n } |xk1 ) = Qk (E k (I{ok:n } [I{xk:n } I{xk:n } ]|Xk )|xk1 )
= Qk (I{xk } E k (I{ok:n } I{xk+1:n } |xk ) + I{xk } E k (I{ok:n } I{xk+1:n } |xk )|xk1 )
= Qk (I{xk } E k (I{ok:n } I{xk+1:n } |xk ) I{xk } E k (I{ok:n } I{xk+1:n } |xk )|xk1 )
= Qk (I{xk } (xk:n ) I{xk } (xk:n )|xk1 ),
proving Equation (17). reasons equalities hold, analogous ones given
proof Equation (15).
Proof Theorem 3. Fix k {1, . . . , n 1}, xk1 Xk1 xk:n Xk:n . assume
xk+1:n
/ opt (Xk+1:n |xk , ok+1:n ) show xk:n
/ opt (Xk:n |xk1 , ok:n ). follows assumption Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } |xk ) > 0 xk+1:n Xk+1 . prefix state
sequence xk+1:n state xk form state sequence xk:n , implying xk = xk .
infer Equation (15)
Pk (I{ok:n } [I{xk:n } I{xk:n } |xk1 ) = Qk ({xk }|xk1 )Sk ({ok }|xk )Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } |xk ) > 0,
tells us indeed xk:n
/ opt (Xk:n |xk1 , ok:n ).
228

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

Proof Equations (33) (34). First, consider k = n. every xn1 Xn1 , determine
opt (Xn |xn1 , ) set elements xn Xn
(xn Xn \ {xn })Qn (I{xn } nmax (xn ) I{xn } (xn )|xn1 ) 0,
condition equivalent optimality condition (14) k = n, taking account Equations (16), (17) (31). show condition also equivalent
(xn Xn \ {xn })(xn ) nmax (xn )n (xn , xn |xn1 ),

(39)

see this, consider two different cases. xn nmax (xn ) = 0, inequalities Qn (I{xn } nmax (xn ) I{xn } (xn )|xn1 ) 0 (xn ) nmax (xn )n (xn , xn |xn1 ) trivially
satisfied since (xn ) = Sn ({on }|xn ) > 0 positivity assumption (10). nmax (xn ) > 0,
inequalities equivalent C2 Equation (27):


(xn ) fifi
max
Qn (I{xn } n (xn ) I{xn } (xn )|xn1 ) 0 Qn I{xn } I{xn } max
fixn1 0
n (xn )
(xn )
n (xn , xn |xn1 )
max
n (xn )
(xn ) nmax (xn )n (xn , xn |xn1 ).
opt

Using Equation (32), Equation (39) reformulated (xn ) n (xn |xn1 ), completes proof equivalence.
Next, consider k {1, . . . , n1} xk1 Xk1 . must determine opt (Xk:n |xk1 , ok:n ).
know Principle Optimality (23) limit candidate optimal sequences
xk:n set cand (Xk:n |xk1 , ok:n ). Consider xk:n , must check xk:n Xk:n
whether Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) 0; see Equation (14).
xk:n xk = xk , inequality always satisfied. Indeed, xk
/ Posk (xk1 ),
infer Equation (25) Qk ({xk }|xk1 ) = 0 Sk ({ok }|xk ) = 0, Equation (15) tells
us Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) = 0. xk Posk (xk1 ), know Equation (24)
xk+1:n opt (Xk+1:n |xk , ok+1:n ), turn implies Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } ]|xk ) 0.
Hence Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) 0, Equation (15).
means limit checking inequality xk:n xk 6= xk .
fix xk 6= xk , must check whether
(xk+1:n Xk+1:n )Qk (I{xk } (xk:n ) I{xk } (xk:n )|xk1 ) 0;
see Equation (17). Equation (28) Lemma 8, equivalent
Qk (I{xk } kmax (xk ) I{xk } (xk:n )|xk1 ) 0,
turn seen equivalent (xk:n ) kmax (xk )k (xk , xk |xk1 ), using course
reasoning completely analogous one used case k = n. Since inequality must
opt
hold every xk 6= xk , infer Equation (32) must (xk:n ) k (xk |xk1 ).
must check condition candidate sequences xk:n cand (Xk:n |xk1 , ok:n ),
proves Equation (33).
229

fiD E B OCK & E C OOMAN

Proof Theorem 4. start proving every sequence xk:n added Line 2
Procedure Recur(xk:n , n) indeed element opt (Xk:n |xk1 , ok:n ). Line 2 Procedure Recur(xk:n , n) executed, means Procedure Recur(xk:n1 , n 1) executed
previous step, point, if-conditions Lines 5 6 satisfied. Due
first if-condition, know xk:n candxk:n (Xk:n |xk1 , ok:n ) therefore, Equation (35),
also xk:n cand (Xk:n |xk1 , ok:n ). second if-condition, infer nmax (xn )
opt
opt
k (xk:n |xk1 ), seen equivalent (xk:n ) k (xk |xk1 ), Equation (31)
repeated use Equations (36) (20). follows Equation (33) xk:n
element opt (Xk:n |xk1 , ok:n ).
conclude proof, show sequence xk:n added course
algorithm cannot element opt (Xk:n |xk1 , ok:n ). sequence xk:n added,
either implies element cand (Xk:n |xk1 , ok:n ) [the if-condition Line 5
Procedure Recur satisfied], {k, . . . , n} imax (xi ) <
opt
k (xk:i |xk1 ) [the if-condition Line 9 Algorithm 2 Line 5 Procedure Recur
satisfied]. first case, follows directly Equation (33) xk:n cannot element
opt
opt (Xk:n |xk1 , ok:n ). second case, find imax (xi ) < k (xk:i |xk1 ) implies
opt
opt
(xk:n ) < k (xk |xk1 ), seen equivalent (xk:n ) < k (xk |xk1 )
repeated use Equations (36) (20). follows Equation (33) xk:n cannot
element opt (Xk:n |xk1 , ok:n ).

Proof Theorem 5. Equation (28) implies least one sequence xs+1:n
Xs+1:n

max

(xs xs+1:n ) = (xs ). prove first state xs+1 sequence meets
criteria theorem.
opt
know candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ smax (xs ) k (xk:s |xk1 ) conditions necessary order Procedure Recur(xk:s , s) executed running Algorithm 2. = k, condition candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ explicitely checked Algorithm 2, nevertheless also true Equations (24) (35) know
opt (Xk+1:n |xk , ok+1:n ) 6= 0/ [because every finite partially ordered set least one maximal
element].
opt

Since (xs xs+1:n
) = smax (xs ) k (xk:s |xk1 ), know Equations (20) (36)
opt

|x
max
(xs+1:n
) k (xk:s xs+1
k1 ). combining Equation (28), find s+1 (xs+1 )
opt


k (xk:s xs+1 |xk1 ), meaning xs+1 satisfies if-condition Line 6.

Due Lemma 9, infer candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ (xs xs+1:n
) = smax (xs )


candxk:s xs+1
(Xk:n |xk1 , ok:n ) 6= 0,
/ meaning xs+1 satisfies if-condition Line 5 well.


Lemma 9. Consider k {1, . . . , n 1}, {k, . . . , n 1}, xk1 Xk1 , xk:s Xk:s xs+1:n


max
Xs+1:n . candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ (xs xs+1:n ) = (xs ), also

candxk:s xs+1
(Xk:n |xk1 , ok:n ) 6= 0.
/

Proof. Let zs+1:n sequence Xs+1:n xk:s zs+1:n cand (Xk:n |xk1 , ok:n );
possible because, assumption, candxk:s (Xk:n |xk1 , ok:n ) 6= 0.
/
q {k, . . . , 1} xq
/ Posq (xq1 ), denote smallest q

q . case, Equation (24), find xq :s xs+1:n
xq :s zs+1:n elements

cand (Xq :n |xq 1 , oq :n ). q exists, let q := s. case, since xq Posq (xq1 )
230

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

q {k, . . . , 1}, follows xk:s zs+1:n cand (Xk:n |xk1 , ok:n ) repeated use Equa
tions (24) (23) xs zs+1:n belongs cand (Xs:n |xs1 , os:n ). Since (xs xs+1:n
) = smax (xs ),

infer Lemma 10 xs+1:n
opt (Xs+1:n |xs , os+1:n ) therefore, Equation (24),

xs xs+1:n cand (Xs:n |xs1 , os:n ).

case, q {k, . . . , s} xq :s xs+1:n
xq :s zs+1:n belong

cand (Xq :n |xq 1 , oq :n ) which, q {k, . . . , q 1}, xq Posq (xq1 ). q = k,
concludes proof. Therefore, consider case q {k + 1, . . . , s}.
first recall cand (Xk:n |xk1 , ok:n ) constructed applying Equations (33) (24)
repeatedly. Therefore, since know xq :s zs+1:n cand (Xq :n |xq 1 , oq :n ) xk:s zs+1:n
cand (Xk:n |xk1 , ok:n ), must
(xq:s zs+1:n ) qopt (xq |xq1 ) q {k + 1, . . . , q }.

(40)



Furthermore, since (xs xs+1:n
) = smax (xs ), infer Equation (28) (xs xs+1:n
)
(xs zs+1:n ) therefore, Equation (20), find hat

(xq:s xs+1:n
) (xq:s zs+1:n ) q {k + 1, . . . , s}.

Hence, Equation (40):

(xq:s xs+1:n
) qopt (xq |xq1 ) q {k + 1, . . . , q }.

(41)

Since cand (Xk:n |xk1 , ok:n ) constructed repeatedly applying Equations (33) (24)


xq :s xs+1:n
cand (Xq :n |xq 1 , oq :n ), infer Equation (41) xk:s xs+1:n

cand (Xk:n |xk1 , ok:n ).

Lemma 10. Consider {1, . . . , n 1}, xs Xs xs+1:n
Xs+1:n .


(xs xs+1:n
) = smax (xs ) = xs+1:n
opt (Xs+1:n |xs , os+1:n ) .

Proof. Assume (xs xs+1:n
) = smax (xs ) consider zs+1:n Xs+1:n . know

Equation (28) (xs xs+1:n
) (xs zs+1:n ) therefore, Equation (19) (7),

Ss ({os }|xs )Ps+1 (I{xs+1:n
} I{os+1:n } |xs ) Ss ({os }|xs )Ps+1 (I{zs+1:n } I{os+1:n } |xs ).

Together positivity assumption (10), implies

Ps+1 (I{xs+1:n
} I{os+1:n } |xs ) Ps+1 (I{zs+1:n } I{os+1:n } |xs ).

(42)

C3, also know


Ps+1 (I{xs+1:n
} I{os+1:n } |xs ) Ps+1 (I{os+1:n } (I{zs+1:n } I{xs+1:n
} )|xs ) + Ps+1 (I{zs+1:n } I{os+1:n } |xs )

which, conjugacy, implies


Ps+1 (I{os+1:n } (I{zs+1:n } I{xs+1:n
} )|xs ) Ps+1 (I{zs+1:n } I{os+1:n } |xs ) Ps+1 (I{xs+1:n
} I{os+1:n } |xs ).

Using Equation (42), see Ps+1 (I{os+1:n } (I{zs+1:n } I{xs+1:n
} )|xs ) 0. Since holds

zs+1:n Xs+1:n , infer Equation (14) xs+1:n
opt (Xs+1:n |xs , os+1:n ).

231

fiD E B OCK & E C OOMAN

References
Bellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton.
Benavoli, A., Zaffalon, M., & Miranda, E. (2011). Robust filtering coherent lower previsions. Automatic Control, IEEE Transactions on, 56(7), 15671581.
Brown, D. G., & Golod, D. (2010). Decoding HMMs using k best paths: algorithms applications.. BMC Bioinformatics, 11(S-1), 28.
Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120, 199233.
Cozman, F. G. (2005). Graphical models imprecise probabilities. International Journal
Approximate Reasoning, 39(2-3), 167184.
de Campos, L. M., Huete, J. F., & Moral, S. (1994). Probability intervals: tool uncertain
reasoning. International Journal Uncertainty, Fuzziness Knowledge-Based Systems,
2, 167196.
De Cooman, G., Miranda, E., & Zaffalon, M. (2011). Independent natural extension. Artificial
Intelligence, 175, 19111950.
De Cooman, G., Hermans, F., Antonucci, A., & Zaffalon, M. (2010). Epistemic irrelevance credal
nets: case imprecise Markov trees. International Journal Approximate Reasoning,
51, 10291052.
De Cooman, G., & Troffaes, M. C. M. (2005). Dynamic programming deterministic discretetime systems uncertain gain. International Journal Approximate Reasoning, 39, 257
278.
De Cooman, G., Troffaes, M. C. M., & Miranda, E. (2008). n-Monotone exact functionals. Journal
Mathematical Analysis Applications, 347, 143156.
Dempster, A. P. (1967). Upper lower probabilities induced multivalued mapping. Annals
Mathematical Statistics, 38, 325339.
Huntley, N., & Troffaes, M. C. M. (2010). Normal form backward induction decision trees
coherent lower previsions. Annals Operations Research. Submitted publication.
Kikuti, D., Cozman, F., & de Campos, C. (2005). Partially ordered preferences decision trees:
computing strategies imprecision probabilities. IJCAI Workshop Advances
Preference Handling, pp. 13131318.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques Adaptive Computation Machine Learning. MIT Press.
Mau, D., de Campos, C., Benavoli, A., & Antonucci, A. (2013). complexity strong
epistemic credal networks. Proceedings 29th Conference Uncertainty Artificial
Intelligence, pp. 391400. AUAI Press.
Miranda, E. (2008). survey theory coherent lower previsions. International Journal
Approximate Reasoning, 48(2), 628658.
Miranda, E. (2009). Updating coherent lower previsions finite spaces. Fuzzy Sets Systems,
160(9), 12861307.
232

fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS

Miranda, E., & de Cooman, G. (2007). Marginal extension theory coherent lower previsions. International Journal Approximate Reasoning, 46(1), 188225.
Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.
Morgan Kaufmann, San Mateo, CA.
Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speech
recognition. Proceedings IEEE, 77(2), 257286.
Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press, Princeton, NJ.
Troffaes, M. C. M. (2007). Decision making uncertainty using imprecise probabilities. International Journal Approximate Reasoning, 45(1), 1729.
Utkin, L. V., & Augustin, T. (2005). Powerful algorithms decision making partial prior information general ambiguity attitudes. in: Proceedings 3th International Symposium Imprecise Probability: Theories Applications (ISIPTA), Prague,Czech Republic,
pp. 349358.
Viterbi, A. J. (1967). Error bounds convolutional codes asymptotically optimum decoding
algorithm. IEEE Transactions Information Theory, 13(2), 260269.
Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall, London.
Walley, P. (1996). Inferences multinomial data: learning bag marbles. Journal
Royal Statistical Society, Series B, 58, 357. discussion.
Weichselberger, K. (2000). theory interval probability unifying concept uncertainty.
International Journal Approximate Reasoning, 24(23), 149170.

233

fiJournal Artificial Intelligence Research 50 (2014) 447-485

Submitted 2/14; published 6/14

Monotone Temporal Planning:
Tractability, Extensions Applications
Martin C. Cooper
Frdric Maris
Pierre Rgnier

COOPER@IRIT.FR
MARIS@IRIT.FR
REGNIER@IRIT.FR

IRIT, Paul Sabatier University
118 Route de Narbonne
31062 Toulouse, France

Abstract
paper describes polynomially-solvable class temporal planning problems. Polynomiality follows two assumptions. Firstly, supposing sub-goal fluent established
one action, quickly determine actions necessary plan. Secondly,
monotonicity sub-goal fluents allows us express planning instance STP (Simple
Temporal Problem difference constraints). class includes temporally-expressive problems
requiring concurrent execution actions, potential applications chemical, pharmaceutical construction industries.
also show (temporal) planning problem monotone relaxation lead
polynomial-time detection unsolvability certain cases. Indeed show relaxation orthogonal relaxations based ignore-deletes approach used classical planning
since preserves deletes also exploit temporal information.

1. Introduction
Planning field AI intractable general case (Erol, Nau & Subrahmanian,
1995). particular, propositional planning PSPACE-Complete (Bylander, 1994). Identifying tractable classes planning important least two reasons. Firstly, real-world applications may fall
classes. Secondly, relaxing arbitrary instance falls tractable class
provide useful information concerning polynomial time.
Temporal planning important extension classical planning actions durative
may overlap. important aspect temporal planning that, unlike classical planning, permits us model problems execution two actions parallel essential order solve problem (Cushing, Kambhampati, Mausam & Weld, 2007). Although planning
studied since beginnings research Artificial Intelligence, temporal planning relatively new field research. tractable classes specifically defined temporal framework
research described paper. present class temporal planning problems
solved polynomial time. particular, considerably extend theoretical results given
conference papers (Cooper, Maris & Rgnier, 2012, 2013b) considering plans optimal
makespan, relaxing assumption two instances action overlap
introducing notion unitary actions. also give previously unpublished results experimental
trials benchmark problems. first, review previous work identification tractable
classes classical planning problems.
2014 AI Access Foundation. rights reserved.

fiCOOPER, MARIS, & REGNIER

lot work done computational complexity non-optimal optimal planning
classical benchmark domains. non-optimal case, Helmert (2003, 2006) proved
benchmarks solved simple procedures running low-order polynomial time.
optimal case, finding optimal plan famous blocksworld domain NP-hard (Gupta & Nau,
1992) Slaney Thibaux (2001) proved domain tractable searching nonoptimal plan.
Moreover, planners empirically showed number benchmark problems
solved without search may even larger number tractable problems identified theoretically. FF planner (Hoffmann, 2005) demonstrated domains constantbounded heuristic plateaus theoretically solved polynomial time using h+ heuristic.
eCPT planner (Vidal & Geffner, 2005) solve, use inference, many instances benchmark
domains without backtrack.
Since work Bckstrm Klein (1991a) SAS formulation planning, several studies also performed define tractable classes planning problems. Many results
(Bylander, 1994; Bckstrm & Nebel, 1995; Erol, Nau & Subrahmanian, 1995; Jonsson & Bckstrm, 1998) based syntactic restrictions set operators. example, operators
single effect, two operators effect, etc.
Another important body work focused underlying structure planning problems
highlighted using causal graph, directed graph describes variable dependencies
(Knoblock, 1994). Jonsson Bckstrm (1995) presented class planning problems acyclic causal graph unary operators. "3S" class, variables either Static, Symmetrically
reversible, Splitting; plan existence determined polynomial time plan generation
provably intractable. Gimnez Jonsson (2008) designed algorithm solves problems
polynomial time producing compact macro plan place explicit exponential solution. also proved problem plan existence planning problems multi-valued
variables chain causal graphs NP-hard. Plan existence planning problems binary state
variables polytree causal graphs also proven NP-complete.
Jonsson Bckstrm (1994, 1998) considered optimal non-optimal plan generation presented exhaustive map complexity results based syntactic restrictions (using SAS+ formulation planning) together restrictions causal graph structure (interference-safe, acyclic, prevail-order-preserving). present planning algorithm correct runs polynomial time restrictions. Williams Nayak (1997) designed polynomial-time algorithm solving planning problems acyclic causal graphs reversible actions. Domshlak
Dinitz (2001) investigated connections structure causal graph complexity
corresponding problems case coordination problems dependent agents independent goals acting environment. general problem shown intractable,
significant subclasses NP even polynomial.
Brafman Domshlak (2003, 2006) studied complexity planning propositional
STRIPS formalism restrictions unary operators acyclic graphs. give polynomial planning algorithm domains whose causal graph induces polytree bounded indegree.
However, also demonstrated singly connected causal graphs problem NP-complete.
Gimnez Jonsson (2012) gave polynomial algorithm class P(k) k-dependent planning
problems binary variables polytree causal graphs fixed value k. also showed
448

fiMONOTONE TEMPORAL PLANNING

if, addition, causal graph bounded depth, plan generation linear size input. Haslum (2008) defines planning problems terms graph grammars. method reduces
original problem graph parsing, solved polynomial time certain restrictions grammar. Haslum thus explores novel classes restrictions distinct
previously known tractable classes. Katz Domshlak (2008) showed planning problems whose
causal graphs inverted forks tractable root variable domain fixed size. Jonsson
(2007, 2009) introduced class IR inverted tree reducible planning problems gave algorithm uses macros solve problems class. complexity depends size
domain transition graph runs polynomial time several subclasses IR. Chen Gimnez (2008) gave unified framework classify complexity planning causal graph restrictions. give complete complexity classification sets causal graphs reversible
planning problems. graph property determines tractability existence constant bound
size strongly connected components.
However, real application domains, sequential nature classical plans often restrictive
temporal plan required consisting set instances durative actions may overlap.
Whereas classical planning consists scheduling action-instances, temporal planning seen
scheduling events (such establishment destruction fluents) action-instances subject
temporal constraints capturing internal structure actions. temporal planning framework
must therefore used formalize temporal relations events within different
actions-instances. PDDL 2.1 temporal framework (McDermott, 1998; Fox & Long, 2003),
PSPACE-complete complexity classical planning preserved different instances
action cannot overlap. overlap, testing existence valid plan becomes
EXPSPACE-complete problem (Rintanen, 2007).
paper present polynomially-solvable sub-problem temporal planning.
knowledge previous work specifically addressed issue. Polynomiality follows
double assumption sub-goal fluent established one action also satisfies monotonicity condition. allows us express temporal planning instance
polynomial-time solvable problem STP (Simple Temporal Problem difference constraints).
STP instance consists set real-valued variables set constraints three following forms xy < c, xy c xy c, x,y variables c constant.
tractable class includes temporally-expressive problems requiring concurrent execution actions, potential industrial applications. also show derive, arbitrary (temporal) planning problem, relaxed version belonging tractable class. lead
polynomial-time detection unsolvability certain cases. also provides polynomial-time heuristic detecting actions fluents satisfying certain properties.
article organized follows: Section 2 reviews existing temporal planners use
temporal constraints. Section 3 presents temporal framework. Section 4 introduces notion
monotonicity fluents. Section 5 shows notion monotonicity extended monotonicity* order define larger tractable class presents main theorem. Section 6 demonstrates build tractable relaxation temporal planning problem (or classical planning
problem) based simple temporal problems. Section 7 shows determine whether fluents
monotone* using relaxation describes tractable class temporal planning problems. Section 8 describes experimental trials validate identify limits temporal relaxation. Section 9 gives examples temporal planning problems solved polynomial time, including
449

fiCOOPER, MARIS, & REGNIER

detailed example involving concrete mixing, delivery use. worth noting solutions
examples discussed Section 9 require concurrent actions. Sections 10 11 conclude discuss avenues future research.
2. Temporal Constraint Solving Temporal Planning
first temporal planner DEVISER (Vere, 1983), planners FORBIN (Dean, Firby &
Miller, 1988) quite rapidly used independent module, called Time-Map Manager (Dean &
McDermott, 1987), handle temporal constraints. HTN (Hierarchical Tasks Network) planners
IxTeT (Ghallab & Alaoui, 1989; Laborie & Ghallab, 1995), TRIPTIC (Rutten & Hertzberg, 1993)
TEST (Reichgelt & Shadbolt, 1990) kept idea Independent module manage temporal
data.
Todays temporal planners essentially based one three types algorithms: plan-space
search, state-space search GRAPHPLAN (Blum & Furst, 1995).
plan-space planners HTN POP (Partially Ordered Planning) first extended
temporal framework. general, use temporal intervals representation actions
propositions, causality relation actions replaced temporal order partial
plans. Conflict handling performed system inspired Time-Map Manager. example,
VHPOP planner (Younes & Simmons, 2003) uses system simple temporal constraints (STP:
Simple Temporal Problem) (Dechter, Meiri & Pearl, 1991), whereas DT-POP (Schwartz & Pollack,
2004) based system disjunctive temporal constraints (DTP: Disjunctive Temporal Problem)
(Stergiou & Koubarakis, 2000). advantage STPs solved polynomial time.
DTPs cannot solved polynomial time, allow user express temporal constraints
"A appears B", lightens work planner.
State-space search planners associate start instant world state. Search based first
instants event occur: decision form "when perform action"
taken decisions form "which action performed". approach called Decision Epoch Planning. Search also based first finding actions use scheduling
actions time: decisions form "when perform action" taken
decisions form "which action performed" taken. approach called
Temporally Lifted Progression Planning.
GRAPHPLAN also extended temporal domains use solvers, planners LPGP (Long & Fox, 2003), TM-LPSAT (Shin & Davis, 2004) TLP-GP (Maris & Rgnier,
2008).
seen, many temporal planners use resolution system temporal constraints.
However, even system constraints solved polynomial time, case
simple temporal constraints, PSPACE complexity classical planning remains. Indeed, certain
planners even solve system disjunctive temporal constraints, known NP-hard.
tractable classes classical planning (discussed Section 1) explicitly extended
temporal planning. paper present knowledge first tractable class temporal planning problems. solution algorithm based solving system simple temporal constraints.
450

fiMONOTONE TEMPORAL PLANNING

3. Definitions
study temporal propositional planning language based temporal aspects
PDDL2.1 (Fox & Long, 2003). fluent positive negative atomic proposition. PDDL2.1,
consider changes values fluents instantaneous conditions value
fluents may imposed interval. action quadruple <Cond(a), Add(a), Del(a), Constr(a)>, set conditions Cond(a) set fluents required true
executed, set additions Add(a) set fluents established a, set deletions Del(a) set fluents destroyed a, set constraints Constr(a) set
constraints relative times events occur execution a. event
corresponds one four possibilities: establishment destruction fluent action a,
beginning end interval fluent required action a. PDDL2.1, events
occur beginning end actions, relax assumption events occur time provided constraints Constr(a) satisfied. Note Add(a) Del(a) may
non-empty. Indeed, unusual durative action establish fluent beginning
action destroy end. also observe duration action, time
first last events action, need explicitly stored.
represent non-instantaneous actions rectangle. duration action given square
brackets name action. Conditions written action, effects below.
action LOAD(m,c) shown Figure 1 represents loading batch concrete c mixer m.
Cond(LOAD(m,c)) = {Fluid(c), Empty(m), At-factory(m)}. see figure mixer
must empty start loading, whereas concrete must fluid mixer factory whole duration loading. Del(LOAD(m,c)) = {Empty(m)}
Add(LOAD(m,c) = {On(m,c)}. see figure soon loading starts, mixer
longer empty end loading mixer contains concrete.
Fluid(c)
Empty(m)

At-factory(m)
LOAD(m,c)[5]
On(m,c)

Empty(m)

Figure 1: example representation durative action

use notation f denote event action establishes fluent f, f denote
event destroys f, f | f | a, respectively, denote beginning end
interval requires condition f. f already true (respectively, false) event
f (a f ) occurs, still consider establishes (destroys) f. temporal plan may contain
several instances action, since temporal plans studied paper contain
one instance action, notational simplicity, make distinction
actions action-instances absolutely necessary. use notation (e) represent
time plan event e occurs.
451

fiCOOPER, MARIS, & REGNIER

given action (or action-instance) a, let Events(a) represent different events constitute definition, namely (a f ) f Add(a), (a f ) f Del(a), ( f | a)
( f | a) f Cond(a). definition action includes constraints Constr(a) relative times events Events(a). example, internal structure fixed-length action
LOAD(m,c) shown Figure 1 defined constraints
(Fluid(c) | LOAD(m,c)) (Fluid(c) | LOAD(m,c)) = 5
(LOAD(m,c) On(m,c)) (Fluid(c) | LOAD(m,c)) = 0
PDDL2.1, consider length time events Events(a) necessarily
fixed Constr(a) set interval constraints pairs events,
( f | a) ( f | a) [, ] constants ,. use [a(e1, e2), a(e1, e2)] denote interval possible values relative distance events e1, e2 action a. fixed length time
events e1, e2 Events(a) can, course, modelled setting a(e1, e2) = a(e1, e2). Similarly, absence constraint modelled interval [, +]. introduce two
basic constraints temporal plans must satisfy.
inherent constraints set action-instances A: aA, satisfies Constr(a), i.e.
pairs events e1, e2 Events(a), (e1) (e2) [a(e1, e2), a(e1, e2)].
contradictory-effects constraints set action-instances A: ai, aj A, positive
fluents f Del(ai) Add(aj), (ai f ) (aj f ).
inherent constraints define internal structure action-instance, whereas contradictory-effects constraints ensure truth-value fluent never becomes undefined
execution temporal plan. example, plan contains instance action LOAD(m,c)
shown Figure 1 instance b another action CLEAN(m) Empty(m)
Add(CLEAN(m)), temporal plan must satisfy contradictory-effects constraint
(a EMPTY(m)) (b EMPTY(m)).
Definition 3.1. temporal planning problem <I,A,G> consists set actions A, initial state
goal G, G sets fluents.
Notation: set action-instances, Events(A) union sets Events(a) (for
action-instances A).
Definition 3.2. P = <A,>, finite set action-instances {a1,..., an} real-valued
function Events(A), temporal plan problem <I, A, G>
(1) A,
(2) P satisfies inherent contradictory-effect constraints A;
P executed (i.e. fluents established destroyed times given ) starting
initial state I:
(3) ai A, f Cond(ai) true required,
(4) goal fluents g G true end execution P.
(5) P robust infinitesimal shifts starting times actions.
452

fiMONOTONE TEMPORAL PLANNING

Events instantaneous, whereas actions durative may also variable length.
Thus temporal plan P schedule action-instances directly schedules events
action-instances.
Condition (5) Definition 3.2 means disallow plans require perfect synchronisation
different actions. Fox, Long Halsey (2004) show condition imposed
within PDDL2.1. require plans fluents established strictly beginning
interval required. exception rule fluent f established required action a. allow possibility perfect synchronization within
action, means (a f ) = ( f | a). Similarly, fluents destroyed
strictly end interval required. exception rule
fluent f required destroyed action a, case ( f | a) =
(a f ). example, fluent Empty(m) simultaneously required destroyed action
LOAD(m,c) shown Figure 1.
Since set actions viewed set action-instances action occurs exactly
once, apply constraints, inherent contradictory-effects constraints, set
actions rather set action-instances. look detail type constraints
impose relative times events within action-instance.
Definition 3.3. interval constraint C(x,y) real-valued variables x,y binary constraint
form xy [a,b] a,b real constants.
Definition 3.4. (Jeavons & Cooper, 1995) binary constraint C(x,y) min-closed pairs
values (x1,y1), (x2,y2) satisfy C, (min(x1,x2),min(y1,y2)) also satisfies C. binary constraint
C(x,y) max-closed pairs values (x1,y1), (x2,y2) satisfy C, (max(x1,x2),max(y1,y2))
also satisfies C.
Lemma 3.5. Let = {a1,..., an} set actions set action-instances action
ai (i =1,..., n) occurs ti1 times. Let real-valued function set events A.
e Events(ai), let e[ j] ( j =1,...,ti) represent occurrence event e within instance number j ai.
{1,...,n}, define real-valued functions min, max set events set actions
min(e) = min{(e[ j]) | j =1,..., ti} max(e) = max{(e[ j]) | j =1,..., ti}. satisfies inherent constraints A, min max satisfy inherent constraints A.
Proof: interval constraints min-closed max-closed (Jeavons & Cooper, 1995).
applying definition min-closedness (respectively, max-closedness) ti 1 times, action ai,
deduce satisfies interval constraint ti instances ai, min (max)
satisfies constraint action ai. words, pairs events e1, e2 Events(ai),
(e1[ j]) (e2[ j]) [a(e1, e2), a(e1, e2)] j=1,...,ti, min(e1) min(e2) [a(e1, e2), a(e1, e2)]
max(e1) max(e2) [a(e1, e2), a(e1, e2)]. Hence satisfies inherent constraints A, min
max satisfy inherent constraints A.

Definition 3.6. temporal planning problem <I,A,G> positive negative fluents
conditions actions goal G.
453

fiCOOPER, MARIS, & REGNIER

paper, consider positive temporal planning problems <I,A,G>. well known
planning problem transformed equivalent positive problem linear time
introduction, positive fluent f, new fluent notf replace occurrences f conditions actions (Ghallab, Nau & Traverso, 2004). important note, however, transformation may conserve properties instance. assumption problems positive, G Cond(a) (for action a) composed positive fluents. convention, Add(a)
Del(a) also composed exclusively positive fluents. initial state I, however, may contain
negative fluents.
simplicity presentation, assume throughout paper set actions undergone filtering operation consisting eliminating actions cannot possibly
executed since Cond(a) subset Add(A).
need following notion establisher-uniqueness order define tractable class
temporal planning problems. equivalent post-uniqueness SAS+ planning (Jonsson &
Bckstrm, 1998) restricted Boolean variables specialised applies specific subset
positive fluents. next section, apply subset positive fluents may
required realisation goal.
Definition 3.7. set actions = {a1,...,an} establisher-unique (EU) relative set positive
fluents j, Add(ai) Add(aj) = , i.e. fluent established two distinct actions A.
set actions establisher-unique relative set sub-goals problem, determine polynomial time set actions necessarily present temporal plan.
remains problem determining many times action must occur scheduling action-instances order produce valid temporal plan. Establisher-uniqueness alone cannot
prevent minimal plans exponential size (Bckstrm & Klein, 1991b).
4. Monotone Planning
section, introduce notion monotonicity fluents. Together establisheruniqueness, monotonicity fluents sufficient condition existence polynomial-time
algorithm temporal planning.
Definition 4.1. fluent f monotone (relative positive temporal planning problem <I,A,G>) if,
destroyed f never re-established temporal plan <I,A,G>. fluent f
+monotone (relative <I,A,G>) if, established f never destroyed temporal
plan <I,A,G>. fluent monotone (relative <I,A,G>) either + monotone (relative
<I,A,G>).
Example 4.2: Consider two actions shown Figure 2: LIGHT-MATCH LIGHT-CANDLE.
action LIGHT-MATCH requires match live, order light it. match remains lit
blown end action. constraint Constr(LIGHT-MATCH) imposes
duration action, i.e. (LIGHT-MATCH Match-lit) (LIGHT-MATCH Match-lit),
1 10 time units. second action LIGHT-CANDLE requires match lit dur454

fiMONOTONE TEMPORAL PLANNING

ing two time units candle lit. initial state = {live, Match-lit} set goals
G = {Candle-lit}, clear temporal plans problem involve executing two actions
parallel start (respectively, end) LIGHT-MATCH strictly (after) start
(end) LIGHT-CANDLE. one match available, means LIGHT-MATCH
executed once. means fluent Match-lit monotone since cannot
established destroyed. fluent Match-lit +monotone since destroyed
established.
Live

Match-lit
LIGHT-MATCH

Live

LIGHT-CANDLE[2]
Candle-lit

Match-lit

Match-lit

Figure 2: example set actions allows us light candle using single match.

Notation: set actions, use notation Del(A) represent union sets Del(a)
(for actions A). Add(A), Cond(A), Constr(A) defined similarly.
following lemma follows trivially Definition 4.1.
Lemma 4.3. f Add(A) Del(A), f monotone +monotone relative positive
temporal planning problem <I,A,G>.
Certain physical actions chemical reactions irreversible. Examples include bursting balloon, killing fly, adding milk cup coffee burning fuel. Since action destroy corresponding fluents Burst, Fly-dead, Milk-added, Fuel-burnt, fluents necessarily
monotone +monotone Lemma 4.3. similar remark holds fluents may true
initial state action establishes them, Fly-alive, example.
Example 4.2, fluent Live monotone +monotone since action establish it, fluent Candle-lit monotone +monotone since action destroy it.
introduce three sets constraints, authorisation constraints applied
monotone fluents f +authorisation constraints +monotone fluents. causality constraints
fluent f valid unique action-instance establishes f.

authorisation constraints positive fluent f set action-instances A:
ai aj A, f Del(aj) Cond(ai), ( f | ai) < (aj f ); ai A, f Del(ai)
Cond(ai), ( f | ai) (ai f ).
+authorisation constraints positive fluent f set action-instances A: ai,aj A,
f Del(aj) Add(ai) (Cond(A) G), (aj f ) < (ai f ).
causality constraints positive fluent f set action-instances A: ai aj A,
f(Cond(aj) Add(ai))\I, (ai f ) < ( f | aj); ai A, f (Cond(ai) Add(ai))\
(ai f ) ( f | ai).
455

fiCOOPER, MARIS, & REGNIER

Within action-instance ai, perfect synchronisation possible events f | ai
ai f. Indeed, one way ensuring action executed temporal
plan create fluent fa Cond(a) Del(a) simultaneously required deleted
start established action. example, action LIGHTMATCH Example 4.2, fa fluent live. hand, condition (5) Definition 3.2
temporal plan, cannot perfect synchronisation events distinct action-instances.
explains authorisation constraints impose strict inequality ( f | ai) < (aj f )
ai aj non-strict inequality ( f | ai) (aj f ) ai = aj. similar remark
holds perfect synchronisation events ai f f | aj permitted
causality constraints ai = aj.
Definition 4.4. temporal plan <A,> positive temporal planning problem <I,A,G> monotone
pair action-instances (in A) satisfies +authorisation constraints +monotone fluents
satisfies authorisation constraints monotone fluents.
Definition 4.5. Given temporal planning problem <I,A,G>, set sub-goals minimum subset SG Cond(A) G satisfying
1. G SG
2. A, Add(a) (SG \ I) , Cond(a) SG.
reduced set actions Ar = {a | Add(a) (SG \ I) }.
determine SG Ar polynomial time result unique. see consider
simple algorithm initialises SG G repeatedly adds SG set fluents F
union (Cond(a) \ SG) actions Add(a) (SG \ I) ,
F=. simple algorithm worst-case time complexity O(n3), n total number
events actions A, produces unique result clearly minimum set fluents
satisfying two conditions Definition 4.5. Note algorithm similar standard
method relevance detection used GRAPHPLAN (Blum & Furst, 1995).
order state theorem, require relaxed definition set sub-goals
reduced set actions take account case fluents initial state destroyed
re-established. Let SG p (the set possible sub-goals) denote minimal set fluents satisfying
1. G SG p
2. actions A, Add(a) SG p Cond(a) SG p.
Let Ap set actions { | Add(a) SG p }. difference Ar Ap
set actions could occur minimal temporal plan fluents initial
state destroyed re-established. SG Ar, SG p Ap unique determined O(n3) time.
p

fluent Cond(Ar) G monotone, say plan P temporal planning problem <I,A,G> satisfies authorisation constraints monotone fluent satisfies authorisation constraints +monotone fluent satisfies +authorisation constraints (it assumed
know, fluent f Cond(Ar) G, whether f + monotone).
456

fiMONOTONE TEMPORAL PLANNING

following theorem contains minor improvements corrections compared conference
version present paper (Cooper, Maris & Rgnier, 2012). Since corollary Theorem 5.6
(proved following section), omit proof.
Theorem 4.6. Given positive temporal planning problem <I,A,G>, let SG Ar be, respectively,
set sub-goals reduced set actions, Ap defined above. Suppose Constr(Ar)
interval constraints, set actions Ar establisher-unique relative SG \ I, fluent
Cond(Ar) G monotone relative <I,Ar,G> fluent (Cond(Ar) G) monotone
relative <I,Ap,G>. <I,A,G> temporal plan P
(1) G (I \ Del(Ar)) Add(Ar)
(2) Cond(Ar) Add(Ar)
(3) fluents g G Del(Ar) Add(Ar) +monotone relative <I,Ar,G>
(4) set authorisation, inherent, contradictory-effects causality constraints solution
set actions Ar.
5. Extending Monotonicity Fluents
section introduce notion monotonicity*, thus allowing us define larger tractable class temporal planning problems.
Definition 5.1. plan minimal removing non-empty subset action-instances produces
invalid plan. fluent f monotone* (relative positive temporal planning problem <I,A,G>) if,
destroyed f never re-established minimal temporal plan <I,A,G>. fluent f
+monotone* (relative <I,A,G>) if, established f never destroyed minimal
temporal plan <I,A,G>. fluent monotone* (relative <I,A,G>) either + monotone*
(relative <I,A,G>).
Example 5.2. give example monotone* fluent monotone, consider following planning problem actions instantaneous:
Start_vehicle: k
Drive: d,
Unload: p
= {k}, G = {p}. fluents represent ignition key (k), engine (o),
destination reached (d) package delivered (p). one minimal plan, namely Start_vehicle, Drive, Unload, also non-minimal plan Start_vehicle,
Drive, Start_vehicle, Unload fluent established, destroyed re-established.
Hence monotone* monotone.
+monotone (monotone) fluent clearly +monotone* (monotone*) since plan, including minimal plans, established (destroyed) never destroyed (re-established).
order prove equivalent Theorem 4.6 monotone* fluents, first require another definition
two minor technical results.
457

fiCOOPER, MARIS, & REGNIER

Definition 5.3. minimal temporal plan <A,> positive temporal planning problem <I,A,G>
monotone* pair action-instances satisfies +authorisation constraints
+monotone* fluents satisfies authorisation constraints monotone* fluents.
following lemma follows directly Definition 5.1 monotonicity* fluent along
fact fluent cannot simultaneously established destroyed temporal plan.
Lemma 5.4. Suppose positive fluent f monotone* relative positive temporal planning
problem <I,A,G>. Let <A,> minimal temporal plan <I,A,G> actions ai, aj
f Add(ai) Del(aj). f +monotone* relative problem, (aj f ) < (ai f ). f
monotone* relative problem, (ai f ) < (aj f ).
Proposition 5.5. fluent Cond(A) monotone* relative positive temporal planning problem <I,A,G>, minimal temporal plans <I,A,G> monotone*.
Proof: Let P minimal temporal plan. Consider firstly positive monotone* fluent f.
show authorisation constraints satisfied f P, i.e. f destroyed (or
time as) required P. must case since P plan f cannot reestablished destroyed. Consider secondly positive +monotone* fluent f. Lemma 5.4,
+authorisation constraint satisfied f P.

give main theorem generalizes Theorem 4.6 monotone* fluents.
Theorem 5.6. Given positive temporal planning problem <I,A,G>, let SG Ar be, respectively,
set sub-goals reduced set actions. Suppose constraints Constr(Ar) interval constraints, set actions Ar establisher-unique relative SG \ I, fluent Cond(Ar) G
monotone* relative <I,Ar,G> fluent (Cond(Ar) G) monotone* relative
<I,Ap,G>. <I,A,G> temporal plan P
(1) G (I \ Del(Ar)) Add(Ar)
(2) Cond(Ar) Add(Ar)
(3) fluents g G Del(Ar) Add(Ar) +monotone* relative <I,Ar,G>
(4) set authorisation, inherent, contradictory-effects causality constraints (given Sections 3 4) solution set actions Ar (where +authorisation constraints apply
+monotone* fluent authorisation constraints apply monotone* fluent).
Proof: () <I,A,G> temporal plan, clearly minimal plan P. Ar set
actions establish sub-goals f SG \ I. definition, SG = Cond(Ar) G. Since Ar establisherunique relative SG \ I, sub-goal f SG \ unique action establishes it. Hence
action Ar must occur plan P. Furthermore, (Add(A) \ Add(Ar)) (Cond(Ar) \ I) = Definition 4.5. follows (2) necessary condition temporal plan P exist.
Let P p version P keep actions Ap. P p valid temporal plan since,
definition Ap, fluent (Cond(Ap) G) established actions \ Ap. Indeed, since P
assumed minimal, must P p =P. let P version P keep
actions Ar. Definition 4.5, conditions actions P goals G established
458

fiMONOTONE TEMPORAL PLANNING

actions eliminated P, except possibly also I. Thus show P also
valid temporal plan need show establishment fluent f (Cond(Ar) G)
P action Ap \ Ar unnecessary. hypothesis, f monotone* relative <I,Ap,G>
hence f cannot established P destroyed. Since f I, means establishment f P unnecessary. Hence P valid temporal plan. Indeed, since P assumed
minimal, must P=P.
seen P contains exactly actions Ar. Hence, fluents gG (which necessarily positive hypothesis positive planning problem) either present initial state deleted action Ar must established action Ar. follows (1)
necessary condition P valid temporal plan. Consider g G Del(Ar) Add(Ar).
Lemma 5.4, deduce g cannot monotone*, since g true end execution
P. Thus (3) holds. Let Pmin=<Ar,min> version temporal plan P=<Ar,>
keep one instance action ai Ar (and instances actions \ Ar) min defined
taking first instance event Events(ai), action ai Ar, described
statement Lemma 3.5. show Pmin satisfies authorisation, inherent, contradictory-effects causality constraints.
know P temporal plan problem <I,A,G>. Hence also temporal plan
problem <I,Ar,G>, since uses actions Ar. hypothesis, fluents Cond(Ar)
monotone relative <I,Ar,G>. Therefore, Proposition 5.5, temporal plan P monotone*. Since
P monotone* definition temporal plan, authorisation constraints satisfied.
P must also, definition temporal plan, satisfy inherent contradictory-effects constraints.
follows Lemma 3.5 Pmin also satisfies inherent constraints. Since events Pmin
simply subset events P, Pmin necessarily satisfies authorisation constraints
contradictory-effects constraints.
Consider positive fluent f (Cond(aj) Add(ai)) \ I, ai, aj Ar. Since aj Ar, know
Add(aj) (SG \ I) hence Cond(aj) SG, definition set sub-goals SG.
Since f Cond(aj) deduce f SG. fact, f SG \ since assume f I. follows
f Add(a) A, Ar. know Ar establisher-unique (relative
SG). Hence, since f Cond(aj) Cond(Ar) f Add(ai), f established single action
a=ai A. Since f I, first establishment f instance ai must occur P f first
required instance aj. follows causality constraint must satisfied f Pmin.
() Suppose conditions (1)-(4) satisfied Ar. Let P solution set authorisation,
inherent, contradictory-effects causality constraints Ar. solution constraints uses
action Ar (in fact, uses action exactly since assigns one start time action
Ar). Consider g G. (1), g (I \ Del(Ar)) Add(Ar). g Del(Ar), g necessarily
true end execution P. hand, g Del(aj) action aj Ar,
(1) necessarily action ai Ar establishes g. Then, (3) g +monotone*. Since P
satisfies +authorisation constraint g, ai establishes g deletions g. follows g
true end execution P.
Consider monotone* f Cond(aj) aj Ar. Since authorisation constraint
satisfied f P, f deleted P required aj. Therefore, remains
459

fiCOOPER, MARIS, & REGNIER

show f either true initial state established time required
aj. (2), f Add(Ar), need consider case f f Add(ai)
action ai Ar. Since P satisfies causality constraint, (ai f ) < ( f | aj) hence,
execution P, f true required action aj.
Consider f Cond(aj), aj Ar, f monotone*. assumptions theorem, f necessarily +monotone* f I. First, consider case f Del(Ar)
Add(Ar). Lemma 4.3, f monotone (and hence monotone*) contradicts assumption.
Therefore f Del(ak) Add(ai), ai, ak Ar, recall f I. Since +authorisation
constraint satisfied f P, destruction f occurs f established ai. follows
causality constraint condition f true required aj execution
P.


makespan temporal plan P = <A,> time interval first last events
P, i.e. max{(e) | eEvents(A)} min{(e) | eEvents(A)}. problem finding plan minimum makespan polytime approximable polynomial-time algorithm which, given
temporal planning problem <I,A,G> > 0, finds temporal plan whose makespan
Mopt + , Mopt minimum makespan temporal plans <I,A,G>.
constraints Constr(a) impose time interval pair events
Events(a) fixed, say action rigid.
express complexities terms total number n events actions A. Without loss
generality, assume actions contain least one event fluents occur least
one event. Hence number actions fluents bounded n.
Theorem 5.7: Let EUM* class positive temporal planning problems <I,A,G>
establisher-unique relative Cond(A) G, fluents Cond(A) G monotone* relative
<I,A,G> fluents (Cond(A) G) monotone* relative <I,A,G>. EUM*
solved time O(n3) space O(n2), n total number events actions A. Indeed,
even find temporal plan minimum number action-instances minimal cost,
action associated non-negative cost, complexity. Furthermore, actions
rigid problem finding plan minimum makespan polytime approximable.
Proof: fact EUM* solved time O(n3) space O(n2) follows almost directly
Theorem 5.6 fact set authorisation, inherent, contradictory-effects causality
constraints form STP, simple temporal problem difference constraints (Koubarakis, 1992).
instance STP solved O(n3+k) time O(n2+k) space (Gerevini & Cristani, 1997),
n number variables k number difference constraints (i.e. constraints
form xj xi d). Here, difference constraints contradictory-effects constraints
n2, k=O(n2). Furthermore, pointed Section 4, calculation SG
Ar O(n3).
Establisher-uniqueness tells us exactly actions must belong minimal temporal plans. Then,
seen proof Theorem 5.6, monotonicity* assumptions imply need
one instance actions. trivially follows solve optimal version
temporal planning problem, aim find temporal plan minimum number
460

fiMONOTONE TEMPORAL PLANNING

action-instances minimal cost, action associated cost, solving set authorisation, inherent, contradictory-effects causality constraints.
suppose actions rigid. express problem minimising makespan
ignoring contradictory-effects constraints linear program. show
always possible satisfy contradictory-effects constraints (without violating constraints)
making arbitrarily small perturbations start times actions. assume events
single action-instance satisfy contradictory-effects authorisation constraints; since actions
rigid checked independently action polynomial time. Let P temporal
plan <I,A,G> minimum makespan. showed proof Theorem 5.6 Pmin,
obtained P keeping one instance action P, also valid temporal plan. Since
makespan cannot increased eliminating action-instances temporal plan, Pmin also minimises makespan. Let C set inherent, authorisation causality constraints Pmin must
satisfy. C contains equality constraints form xj xi = d, constant xj, xi times
events action, constraints form xj xi < d, constant xj, xi
times events different actions. introduce two variables begin, end denote Copt
set constraints C together constraints begin (e) (e) end eEvents(Ar).
linear program minimises end begin subject constraints Copt minimises makespan
take account contradictory-effects constraints C must satisfied valid
temporal plan. Let PLP solution linear program. makespan clearly greater
Mopt, minimum makespan temporal plans (since valid temporal plans must satisfy constraints C C ). Let minimum difference (xj xi) PLP constraints form
xj xi < C. Let minimum non-zero difference | (xj xi) | PLP contradictoryeffects constraints xj xi C . Suppose Ar = {a1,...,am}. Let P identical PLP except
add = min{,,}(i1)/m (e) eEvents(ai). construction, contradictory-effects
constraints violated PLP satisfied P, contradictory-effects constraints
satisfied PLP still satisfied P, strict inequalities satisfied PLP
still satisfied P. inequalities begin (e) still satisfied P. Finally, order guarantee
satisfying inequalities (e) end, suffices add end. resulting solution P corresponds
valid temporal plan whose makespan Mopt + . result follows fact
linear programming solvable O(n3.5L) time Karmarkars interior-point algorithm, n
number variables L number bits required encode problem (Karmarkar,
1984).







f

f

a1

a1

a1
g

a2

g

h

h

a2

f

a2

f

(a)

g

f

f

(b)

g

(c)

Figure 3: (a) instances action a1 occur strictly instances action a2, (b) instances
a2 contained instances a1 (c) instances a1 overlap instances a2.
461

fiCOOPER, MARIS, & REGNIER

class EUM*, sub-goal fluents f SG true single interval Int(f, P) execution temporal plan P. f +monotone*, Int(f, P) necessarily form [t1,) t1
moment f first established. f monotone*, Int(f, P) necessarily form
[t1, t2] t1 moment f first established (or 0 f I) t2 first moment
t1 f destroyed (or [t1,) f never destroyed). class EUM* solvable polynomial
time due fact establisher-uniqueness ensures choice concerning actions include plan monotonicity* ensures choice concerning time
events within interval. Given two restrictions quite surprising large range industrial planning problems fall class (Cooper, Maris & Rgnier, 2012, 2013b). EU monotone
planning sufficiently powerful modelling language allow us impose constraints
action occurs plan instances event e1 occur instances event
e2. illustrate this, Figure 3 shows impose precedence, containment overlapping constraints actions a1 a2 introduction of, respectively, one, two three fluents
f, g, h occur events shown Figure 3. Lemma 4.3, fluents f, g, h
necessarily monotone +monotone temporal plans.
6. Temporal Relaxation
Relaxation ubiquitous Artificial Intelligence. valid relaxation instance solution
solution. Hence relaxation solution, implies unsolvability
original instance I. tractable relaxation built solved polynomial time.
traditional relaxation propositional non-temporal planning problems consisting ignoring
deletes two drawbacks. Firstly, traditionally used forward search, valid
temporal planning unless specific transformation applied beforehand set actions (Cooper, Maris & Rgnier, 2013a). Secondly, use information may essential
detection unsolvability original instance, namely destruction fluents temporal information relative duration actions. section present valid tractable
relaxation inspired EU monotone temporal planning. following section show use
temporal relaxation detect monotonicity* fluents. possible applications,
detection action landmarks (actions occur solution plan) (Karpas & Domshlak,
2009), immediately leads lower bound cost plan action associated cost (Cooper, de Roquemaurel & Rgnier, 2011).
traditional relaxation classical non-temporal planning problems consists ignoring deletes
actions. finding cost optimal relaxed plan, relaxation used calculate
admissible h+ heuristic. shown Betz Helmert (2009), h+ informative unfortunately NP-hard compute (Bylander, 1994) also hard approximate (Betz & Helmert, 2009).
relaxation use information may essential detection un-solvability
original instance (namely destruction fluents), lot research carried
take deletes account (Fox & Long, 2001; Gerevini, Saetti & Serina, 2003; Helmert, 2004;
Helmert & Geffner, 2008; Keyder & Geffner, 2008; Cai, Hoffmann & Helmert, 2009). Another recent
approach (Haslum, Slaney & Thibaux, 2012; Keyder, Hoffmann & Haslum, 2012) consists enriching classical relaxation set fact conjunctions. Finally red-black relaxation (Katz,
Hoffmann & Domshlak, 2013a, 2013b) generalizes delete-relaxed planning relaxing subset
state variables.
462

fiMONOTONE TEMPORAL PLANNING

Unfortunately, relaxations directly generalize temporal planning, since techniques
based combination ignoring deletes forward search valid temporal planning unless specific transformation applied beforehand set actions. important aspect temporal planning, absent non-temporal planning, certain temporal planning problems, known temporally-expressive problems, require concurrency actions order
solved (Cushing, Kambhampati, Mausam & Weld, 2007). typical example temporallyexpressive problem cooking: several ingredients must cooked simultaneously order
ready moment. previous paper (Cooper, Maris & Rgnier, 2010), identified subclass temporally expressive problems, known temporally-cyclic, require cyclicallydependent sets actions order solved.
Wages-paid

PAY(1)

WORK(10)
Job-started

Job-started

Job-finished

Wages-paid

Figure 4: example temporally cyclic temporal planning problem.
simple temporally-cyclic problem shown Figure 4, = G = {Job-finished}.
condition workman start work paid (at end job) whereas employer
pay started work. valid temporal plan problem actions PAY
WORK must executed parallel execution action PAY contained within interval action WORK executed. applying traditional ignore-deletes relaxation,
forward chaining initial state would able start either two actions since
missing condition. Thus, certain proposed techniques, although useful guiding
heuristic search (Eyerich, Mattmller & Rger, 2009; & Kambhampati, 2003), valid
temporally cyclic problems. Different solutions exist get round problem temporal cycles.
example, gave polynomial-time algorithm transform temporally-cyclic problem
equivalent acyclic one (Cooper, Maris & Rgnier, 2013a). transformations proposed
literature (Long & Fox, 2003; Coles, Fox, Long & Smith, 2008) also eliminate possibility temporal cycles, although explicitly-stated aim descriptions
transformations: temporal cycles avoided decomposing durative actions instantaneous actions denoting start end action. Intermediate conditions also managed splitting
actions component actions enclosed within envelope action (Smith, 2003). case, ignoring deletes transformed problem followed forward search provides valid relaxation.
original problem temporarily cyclic, ignoring deletes followed forward search
valid relaxation.
section, present alternative form relaxation, call TR (for Temporal Relaxation), inspired EU monotone planning, comprising STP instance solution
original temporal planning instance solution. incomparable relaxation based
ignoring deletes, show temporal non-temporal examples, sense
instances detected unsolvable using EU monotone relaxation ignoring deletes (and vice versa).
463

fiCOOPER, MARIS, & REGNIER

applying following simple rule convergence transform (in polynomial time)
temporal planning problem P relaxed version P EU relative set sub-goals
SG: sub-goal fluent f established two distinct actions, delete f goal G
Cond(a) actions a. consequence, f longer sub-goal SG recalculated.
Clearly, P valid relaxation P. assume temporal planning problem EU
relative SG.
denote ALM set action landmarks detected (Karpas & Domshlak,
2009). Action landmarks also known indispensable actions (Cooper, de Roquemaurel & Rgnier, 2011). Establisher-uniqueness implies easily identify many actions, particular set actions Ar establish sub-goals present initial state I.
cannot assume STP single instance action sufficient. action landmark event e Events(a), introduce two variables first(e), last(e) representing times first last occurrences event e plan. constraints temporal
relaxation TR include versions internal, contradictory-effects, authorization causality constraints (which give below) together following obvious constraint:
intrinsic TR-constraints: aALM, events e Events(a), first(e) last(e).
conference version paper described preliminary version TR (Cooper,
Maris & Rgnier 2013b), made assumption two instances action overlap. assumption, e1, e2 Events(a), first occurrences e1, e2 plan correspond
instance action a. similar remark holds last occurrences e1, e2. turns
need make assumption order apply TR inherent constraint Constr(a)
independently values first(e) last(e) (for e Events(a)). Indeed, according Lemma 3.5, assuming Constr(Ar) interval constraints, instance action satisfies inherent constraints, first last satisfy inherent constraints events action a:
inherent TR-constraints: aALM, e1,e2 Events(a), first(e1) first(e2) [a(e1,e2), a(e1,e2)]
last(e1) last(e2) [a(e1,e2), a(e1,e2)].
contradictory-effects constraints TR follows:
contradictory-effects TR-constraints: ai, aj ALM, positive fluents f Del(ai) Add(aj),
L1,L2 {first,last}, L1(ai f ) L2(aj f ).
positive fluent f known monotone*, apply TR following modified version authorisation constraints f:

authorisation TR-constraints: ai aj ALM, f Del(aj) Cond(ai), last( f | ai) <
first(aj f ); ai ALM, f Del(ai) Cond(ai), last( f | ai) first(ai f ).
positive fluent f known +monotone*, apply TR following modified
version +authorisation constraints f:
+authorisation TR-constraints: ai, aj ALM, f Del(aj) Add(ai), last(aj f ) <
first(ai f).
check every condition every goal established, i.e. Cond(ALM) Add(A)
G (I \ Del(ALM)) Add(A). not, consider relaxation TR solution.
464

fiMONOTONE TEMPORAL PLANNING

also apply TR following causality constraints positive fluent f:
causality TR-constraints: ai aj ALM, f (Cond(aj) Add(ai)) \ first(ai f ) <
first(f | aj); ai ALM, f (Cond(ai) Add(ai)) \ first(ai f ) first( f | ai).
also apply following goal constraints g G:
goal TR-constraints: ai, aj ALM, g Del(aj) Add(ai), last(aj g) < last(ai g).
course, causality goal constraints necessary conditions existence plan ALM EU relative (Cond(ALM) \ I) (G Del(A)).
Definition 6.1: action aA unitary temporal planning problem <I,A,G> minimal
temporal plan <I,A,G> contains one instance a.
action aALM known unitary, TR, event e Events(a), replace
two variables first(e), last(e) constraints unique variable (e).
Thus TR consists first eliminating G Cond(a) (for A) fluents established
two distinct actions, then, checking Cond(ALM) Add(A) G (I \ Del(ALM))
Add(A), solving STP consisting intrinsic, inherent, contradictory-effects, authorisation,
+authorisation, causality goal TR-constraints, given above.
TR valid relaxation since constraints TR must clearly satisfied temporal plan.
Furthermore, plan exists minimal plan necessarily exists minimal plans
one instance unitary action. assumptions establisher-uniqueness monotonicity*, TR fact solution procedure tractable class described Theorem 5.7.
temporal relaxation TR significantly strengthened prior identification unitary
actions. therefore present lemmas cover several simple common cases
actions identified unitary. first give lemma allows us simplify certain actions.
Lemma 6.2: Suppose f f monotone* positive temporal planning problem
<I,A,G>. Let identical set actions except f deleted Add(a)
action a. minimal temporal plans <I,A,G> minimal temporal plans <I,A,G>
vice versa.
Proof: P minimal temporal plan <I,A,G>, then, since f monotone*, cannot established destroyed P. follows establishments f P unnecessary
since occur f already true. Hence, P also plan <I,A,G>. also
minimal <I,A,G> since conditions goals identical problems. minimal temporal plan <I,A,G> necessarily temporal plan <I,A,G>, since conditions goals
positive, necessarily minimal since conditions goals identical problems.


assume rest paper TR set actions simplified indicated
Lemma 6.2.

465

fiCOOPER, MARIS, & REGNIER

Lemma 6.3: f monotone*, f Cond(a), f Del(a) simultaneously requires destroys f
(i.e. Constr(a) contains constraints ( f | a) = ( f | a) = (a f )), unitary.
Proof: Let P minimal temporal plan containing consider instance P
first destroys f. condition (5) Definition 3.2 temporal plan, two instances
synchronised destroy f simultaneously, instance unique. monotonicity*,
f cannot later established P. Hence instance require (and destroy) f
instant. follows minimal temporal plan P contain one instance a.
Hence unitary.

Lemma 6.4: Let <I,A,G> positive temporal planning problem aA action
rigid two instances overlap temporal plan <I,A,G>. three
following cases unitary <I,A,G>: (1) fluents Add(a) monotone*, (2) Add(a)
G\Cond(A), (3) Add(a) = {h} fluent hG, unique action b h
Cond(b), furthermore b unitary.
Proof: Let P minimal temporal plan <I,A,G> containing action a. First, consider case (1)
fluents Add(a) monotone*. Monotone* fluents never need established
minimal plan. minimal plans, +monotone* fluent
established, cannot destroyed and, monotone* fluent established,
destroyed established again. follows first establishment
fluent Add(a) unnecessary P. Whether rigid two instances overlap
P, first establishments fluents Add(a) correspond instance
a. instances thus deleted P without destroying validity. Hence
unitary.
consider case (2), i.e. Add(a) G\Cond(A). last establishment fluent
Add(a) unnecessary P, since fluents Add(a) conditions actions A.
Whether rigid two instances overlap P, last establishments
fluents Add(a) correspond instance a. instances thus
deleted P without destroying validity. Hence unitary.
consider case (3). Since b unitary, minimal plan P contains one instance
b. instance last establishes h required unique instance b
actually necessary. instances deleted P without destroying
validity. Hence unitary.


often case two instances action executed parallel, example due
limited resources. therefore quite common modelling temporal planning problem
forbid two instances action overlap. achieved introducing fluent
f Cond(A\{a}) Add(A\{a}) Del(A\{a}) G, adding f placing events f | a,
f | f beginning event f end a. Alternatively,
place event f beginning events f | a, f | f end a,
case need fI. either case, say f non-overlap fluent a.
state general version Lemma 6.4.
466

fiMONOTONE TEMPORAL PLANNING

Lemma 6.5: Let <I,A,G> positive temporal planning problem aA action f
non-overlap fluent a. three following cases unitary <I,A,G>: (1)
fluents Add(a)\{f} monotone*, (2) Add(a)\{f} G\Cond(A), (3) Add(a)\{f} = {h}
fluent hG, unique action b h Cond(b), furthermore b
unitary.
Proof: Let P minimal temporal plan <I,A,G> containing action a. two instances
overlap P. proof Lemma 6.4, need keep single instance a: case (1)
first instance a, case (2) last instance a, case (3) last instance h required b. Hence unitary.

temporal relaxation TR uses two types information used ignore-deletes relaxation:
destruction fluents temporal information. give two simple examples illustrate
this.
Example 6.6: simplest possible example showing TR detect unsolvability planning problem cannot detected ignore-deletes relaxation consists initial state
= {f}, goal G = {f, g} single action simultaneously establishes g destroys f. Unsolvability detected TR since condition G \ Del(ALM) Add(A) satisfied.
Example 6.7: Consider problem lighting candle using single match described Example 4.2. Suppose match short burn two time units.
problem clearly establisher-unique. Furthermore, actions belong Ar hence landmarks. deduce LIGHT-MATCH unitary Lemma 6.3 LIGHT-CANDLE
unitary Lemma 6.4 (case (2)). Thus, TR single variable (e) event
eEvents(A). already seen, Match-lit monotone, TR contains authorisation
constraint (match-lit | LIGHT-CANDLE) < (LIGHT-MATCH match-lit). also contains
causality constraint (LIGHT-MATCH match-lit) < (match-lit | LIGHT-CANDLE).
two inherent constraints (LIGHT-MATCH match-lit) (LIGHT-MATCH match-lit) 2
(match-lit | LIGHT-CANDLE) (match-lit | LIGHT-CANDLE) = 2 provide contradiction. form relaxation take account duration actions detect
unsolvability problem, since identical problem different durations given Example 4.2 solution.
Example 6.8: give generic example involving choice two alternatives
temporal relaxation TR detect unsolvable problems cannot detected ignoring
deletes. illustrate generic example simple non-temporal planning problem P
initial state = {f}, goal G = {g,h} following two actions:
B: f f, g
C: f f, h
fluents many possible interpretations, including: f = packet, g = sent
packet Destination1, h = sent packet Destination2. Clearly problem solution, discovered ignore-deletes relaxation (which cannot take account fact
longer packet sent somewhere).
467

fiCOOPER, MARIS, & REGNIER

show TR solution give proof general case ALM EU, actions
B,C ALM instantaneous, f (Cond(B) Del(B) Cond(C) Del(C) I)\Add(A), g Add(B)
(G\I) h Add(C) (G\I). fluent f monotone Lemma 4.3 since action
establish it. TR solution since obtain following contradiction sequence authorisation, inherent, intrinsic, authorisation, inherent intrinsic (respectively) constraints: last(f | B)
< first(C f) = first(f | C) last(f | C) < first(B f) = first(f | B) last(f | B).
point improved versions ignore-deletes relaxation retain information concerning deletes would also able detect unsolvability simple problem.
example, transformation Keyder, Hoffmann Haslum (2012) detect unsolvability
introducing special fluent representing conjunction g h .
Example 6.9: show temporal relaxation TR detect unsolvable problems
necessarily establisher-unique. example, actions instantaneous hence present form non-temporal planning problem P initial state = {j,m,d}, goal G = {g}
following three actions:
Buy: j, h, d,
Sell: h m, h
Mort2: d, h m, d, g
interpret fluents follows: j = job, = money, = debt-free, h =
house, g = taken second mortgage. example, action Buy possible
job money put deposit house; result house
debt longer money. goal take second mortgage via action Mort2.
problem solution, fact detected standard relaxation consisting
ignoring destructions fluents. set TR, first determine action landmarks ALM = {Buy,
Mort2} easily identified landmarks rules given Cooper, de Roquemaurel Rgnier
(2011) since establish sub-goals h g, respectively, present initial state. Observe
ALM EU relative set sub-goals {g,h} retains destructions fluents. applying Lemma 6.3 fluent (which monotone Lemma 4.3), deduce Mort2
unitary. deduce Lemma 6.4 (case (3)) Buy unitary, since Add(Buy) = {h}
Mort2 action requiring h. Thus, TR single variable (e) event
eEvents(ALM). TR contains following constraints: (d | Mort2) = (h | Mort2) internal
TR-constraint Mort2; (Buy h) = (Buy d) internal TR-constraint Buy; (Buy h)
< (h | Mort2) causality TR-constraint h; (d | Mort2) < (Buy d)
authorisation TR-constraint, since monotone. set four constraints solution,
deduce P solution. example shows temporal relaxation useful even non-temporal planning problems establisher-unique.
examples show EU monotone relaxation TR stronger relaxation
based ignoring deletes two reasons: TR uses temporal information, example concerning
duration actions, retains destructions fluents. see ignoring deletes stronger
EU monotone relaxation, consider problem unique goal g produced unique
action Cond(a) = {f} fluent f produced two distinct actions b c.
EU monotone relaxation, fluent f deleted Cond(a), since established two distinct
actions, relaxed version problem immediately solvable plan containing single
468

fiMONOTONE TEMPORAL PLANNING

action a. Ignoring deletes, hand, detect unsolvability original problem
certain cases, example, actions b c instantaneous, b action establishes
fluent p Cond(c) \ c action establishes fluent q Cond(b) \ I.
obvious application temporal relaxation detection action landmarks following
classic technique applies valid relaxation (Hoffmann, Porteous & Sebastia, 2004;
Cooper, de Roquemaurel & Rgnier, 2011). Let P [-a] represent planning problem P without
particular action a. temporal relaxation P [-a] solution, conclude
action landmark P.
following sections investigate applications temporal relaxation concerning
detection different forms monotonicity. basic idea H hypothesis tested
H expressed conjunction STP constraints, add H constraints
temporal relaxation TR. thus obtain STP instance denote TR[H]: TR[H]
solution H cannot true solution planning problem. case, complexity
solving TR[H] O(n3) time O(n2) space, n total number events actions
(as already seen proof Theorem 5.7).
7. Detecting Monotonicity* Using Temporal Relaxation
subclass instances NP-hard problem generally considered tractable satisfies two
conditions: (1) polynomial-time algorithm solve , (2) polynomial-time
algorithm recognize . clearly polynomial-time detect whether actions establisherunique. hand, general definition monotonicity fluents implies
case determining whether fluents monotone. section show temporal
relaxation used detect monotonicity* certain fluents. Unfortunately, following theorem shows that, general, detection monotonicity* difficult temporal planning.
Theorem 7.1. Determining whether fluent temporal planning problem <I,A,G> monotone (or
monotone*) PSPACE-hard overlapping instances action allowed plans
EXPSPACE-complete overlapping instances action allowed.
Proof: Notice <I,A,G> solution, fluents trivially monotone (and hence monotone*) Definition 4.1, since neither established destroyed plan. sufficient
add two new goal fluents f1, f2 two new instantaneous actions A, a1 simply adds f1 a2
f1 condition, adds f2 deletes f1 (a1 a2 independent fluents)
problem <I,A,G>: f1 monotone (monotone*) resulting problem temporal plan. theorem follows fact testing existence temporal plan
temporal planning problem <I,A,G> PSPACE-hard overlapping instances action
allowed plans EXPSPACE-complete overlapping instances action allowed (Rintanen, 2007).

nevertheless detect monotonicity* certain fluents polynomial time. section
give rules applied polynomial time. Given Theorem 7.1, clearly claim
able detect monotone* fluents rules. set temporal planning problems
whose fluents proved +monotone* monotone* rules given section, re469

fiCOOPER, MARIS, & REGNIER

quired conditions Theorem 5.7, represents tractable class, since recognized
solved polynomial time.
detect +monotonicity (+monotonicity*) fluent f suffices give proof f cannot
destroyed (minimal) plan established. conference version paper
gave rules provide proof, based knowledge monotonicity fluents (Cooper,
Maris & Rgnier, 2012). turns simpler general proof rule (although
computationally expensive) involves solving STP pair actions a, b
f Add(a) Del(b). set actions establisher-unique, one action a. try prove b cannot destroy f establishes f, set relaxation TR[Before(a,
f, b)] consisting temporal relaxation TR planning problem together single hypothesis constraint: Before(a, f, b) = { first(a f ) < last(b f )}. consider case
pair actions a,b exist (see Lemma 4.3) simply special case rule. Note, however, fact TR[Before(a, f, b)] solution necessary sufficient condition
existence valid temporal plan b destroys f establishes f. Indeed, Theorem 7.1
tells us highly unlikely polynomial-time algorithm exists determining whether
fluent monotone*.
detect monotonicity* fluent f need prove f cannot established minimal plan destroyed. corresponding STP TR[After(a, f, b)], hypothesis is: After(a, f, b) = {first(b f ) < last(a f )}. assume setting temporal relaxation
TR[Before(a, f, b)] TR[After(a, f, b)] apply rules given previous section identification unitary actions. implies implicitly considering minimal plans
hence detect monotonicity* rather monotonicity.
Lemma 7.2. Suppose set actions EU. TR[Before(a, f, b)] solution pair
actions a,b f Add(a) Del(b), f +monotone* relative <I,A,G>.
TR[After(a, f, b)] solution pair actions a, b f Add(a) Del(b), f
monotone* relative <I,A,G>.
order apply Theorem 5.6, also prove fluents (Cond(Ar) G)
monotone* relative <I,Ap,G>. plan problem <I,Ap,G> necessarily includes actions
ALM, may may include actions Ap \ ALM. consequence this,
impose constraints actions ALM. Indeed, extra hypothesis set actions Ap
establisher-unique, corresponding STP identical TR[After(a, f, b)].
Lemma 7.3. set actions Ap establisher-unique temporal relaxation TR[After(a, f, b)]
solution pair actions a, b Ap f Add(a) Del(b), f monotone*
relative <I,Ap,G>.
give simple lemma detect certain +monotone* fluents based notion unitary
action. assume Lemmas 6.3, 6.4 6.5 used detect unitary actions.
Lemma 7.4. establisher-unique action aA unitary, fluents f Add(a)
(G \(I \Del(ALM))) +monotone* relative temporal planning problem <I,A,G>.

470

fiMONOTONE TEMPORAL PLANNING

Proof: Let f Add(a) (G \ (I \ Del(ALM))) let P minimal plan <I,A,G>. fluents
G\(I \ Del(ALM)) must established P. Thus P must contain instance action a, since establisher-unique. Indeed, since unitary, P contains exactly one instance a. Therefore, f established exactly P, furthermore cannot later destroyed P since f goal fluent. follows f +monotone*.

Example 7.5. Consider following simple example planning problem instantaneous actions:
Wash_hair: d, c
Dry_clean_hair: c
means dry hair c means clean hair, = G = {d,c}. Note impose condition hair must clean dried. fluent monotone since solution plan Wash_hair, Dry_clean_hair, Wash_hair, Dry_clean_hair (in last two actions
clearly redundant) destroys, establishes, destroys re-establishes d, plan clearly
minimal. deduce Lemma 6.4 (case(2)) Dry_clean_hair unitary. Lemma 7.4
tells us +monotone* since Add(Dry_clean_hair) (G \(I \ Del(ALM))) = {d}.
following theorem follows Theorem 5.7 together fact STP
solved polynomial time. Recall class tractable recognised solved polynomial time.
Theorem 7.6. Let 1 class positive temporal planning problems <I,A,G> Constr(Ar) interval constraints, Ar establisher-unique relative SG, fluents Cond(Ar) G
monotone* relative <I,Ar,G> fluents (Cond(Ar) G) monotone* relative
<I,Ap,G>, monotonicity* fluents detected applying Lemmas 7.3 7.4.
1 tractable.
already seen proof Theorem 5.7 temporal relaxation solved
O(n3) time O(n2) space, n total number events actions A. number
temporal relaxations solve, order prove temporal planning problem belongs 1,
proportional number triples (a, f, b) a, b Ap f Add(a) Del(b). number
pairs ( f, b) b Ap f Del(b) bounded n. Ap establisher-unique,
one action Ap f Add(a). Therefore, complexity recognizing
1 O(n4) time O(n2) space. conference version paper (Cooper, Maris & Rgnier,
2012) gave simple rules used recognize subclass 1 O(n2) time O(n)
space.
discuss rules detection monotone* fluents. show monotone* fluents detected polynomial time cost greater computational complexity.
say action-instance usefully produces fluent h execution plan h
false established a. say usefully produces required fluent h usefully produces h either h G fluent h condition action c plan
(a h) < (h | c). state following general proposition.
471

fiCOOPER, MARIS, & REGNIER

Proposition 7.7. Suppose set actions EU relative set sub-goals let
unique action establishes sub-goal f. (a) b f Del(b), minimal
plan instance b destroys f instance establishes f,
instance first establishes f last instance b last destroys f usefully produce required fluents, f +monotone*. (b) b f Del(b), minimal
plan instance establishes f instance b destroys f,
instance last establishes f instance b first destroys f usefully produce
required fluents, f monotone*.
Proof: (a) Let P minimal plan instance b destroys f instance
establishes f. Then, hypothesis proposition, either instance first establishes
f P last instance b last destroys f P usefully produce required fluent.
Hence P cannot minimal, since could delete either instance b instance P
leave another valid plan. contradiction shows f +monotone*. proof case (b)
similar.

give lemma allows us deduce one hypotheses Proposition 7.7
hence deduce fluent f +monotone* monotone*. simplify expression
lemma, suppose goal-achieving action aG must executed end
plans Cond(aG) = G. simply means goal fluents h need treated
special cases.
Lemma 7.8. Suppose EU relative set sub-goals SG let unique action establishes fluent f SG. Let b f Del(b).
(a) Let h SG Add(a) h SG Add(b). following conditions hold,
minimal plan P last destruction f instance b occurs first establishment f instance a, instance b usefully produces required fluent h
instance usefully produces required fluent h:
(1) actions c,c h Cond(c), h Cond(c), TR[Before(a,f,b) For(a,first,h,c)
For(b,last,h,c)] solution, For(x,L,h,c) = {L(x h) < last(h | c)}.
(2) Constr(b) imposes fixed interval destruction f establishment h b,
h monotone* actions c,c h Cond(c) h Cond(c), TR[Before(a,f,b)
Once(b) For(a,first,h,c) For(b,last,h,c)] solution, Once(x) = {first(E) = last(E)
| E Events(x)}.
(b) Let h SG Add(a) h SG Add(b). following conditions hold,
minimal plan P last establishment f instance occurs first destruction f instance b, instance usefully produces required fluent h
instance b usefully produces required fluent h:
(1) actions c,c h Cond(c), h Cond(c), TR[After(a,f,b) For(a,last,h,c)
For(b,first,h,c)] solution.
(2) Constr(b) imposes fixed interval destruction f establishment h b,
h monotone* actions c,c h Cond(c) h Cond(c), TR[After(a,f,b)
Once(a) For(a,last,h,c) For(b,first,h,c)] solution.
472

fiMONOTONE TEMPORAL PLANNING

Proof: (a) suppose EU relative SG, f SG Add(a) Del(b), h SG Add(a)
h SG Add(b).
(1) TR[Before(a,f,b) For(a,first,h,c) For(b,last,h,c)] solution actions c,c
h Cond(c), h Cond(c), cannot case minimal plan P first establishment f occurs last destruction f instance b, instance
first establishes f usefully produces required fluent h P, instance b
last destroys f usefully produces required fluent h P.
(2) h monotone*, instance b first establishes h usefully produce h
P. Since fixed interval destruction f establishment h b,
necessarily instance b first destroys f. Since instance b last
destroys f assumed usefully produce h, deduce instances b synchronised destroy f exactly moment. contradicts Condition (5)
Definition 3.2 temporal plan, unless one instance b P. result follows
argument case (2) extra constraint Once(b) one instance b P.

proof part (b) lemma similar.



Example 7.9. Consider following EU temporal planning problem actions instantaneous:
Check: p g,
Drive: p, a, g
Take: g p
= {g} G = {a}. One interpretation actions fluents is: Have_Engine_checked
(Check), Drive_to_destination (Drive), Take_Petrol (Take), Have_petrol (p), At_garage (g), Engine_OK (o), Arrived (a). fluent g monotone since plan Take, Check, Drive,
Check (in last action clearly redundant) establishes, destroys, establishes g.
However, g monotone* since minimal plan action Check cannot usefully produce fluent
h Add(Check) = {g, o} action Drive destroyed g. case h=g, Lemma
7.8(b)(1): Take action g Cond(Take), TR[After(Check,g,Drive)
For(Check,last,g, Take)] solution. case h = o, Lemma 7.8(b)(2) since
monotone* (by Lemma 4.3) TR[After(Check,g,Drive) Once(Check)] solution. Note
since a, p monotone Lemma 4.3, deduce Lemma 6.4 (case (1)) actions Drive
Take unitary. follows Lemma 6.4 (case (3)) action Check also unitary.
therefore impose TR actions Check, Drive Take occur once; follows
could deduced g monotone* directly Lemma 7.2 without use Lemma 7.8.
Combining Proposition 7.7 Lemma 7.8 allows us define tractable class temporal planning problems larger class described Theorem 7.6.
Theorem 7.10. Let 2 class positive temporal planning problems <I,A,G> Constr(Ar) interval constraints, Ar establisher-unique relative SG, fluents Cond(Ar) G
monotone* relative <I,Ar,G> fluents (Cond(Ar) G) monotone* relative
473

fiCOOPER, MARIS, & REGNIER

<I,Ap,G>, monotonicity* fluents deduced Proposition 7.7, Lemmas 7.4
7.8. 2 tractable.
number temporal relaxations solve, order prove temporal planning problem
belongs 2, proportional number septuples (a,f,b,c,h,c,h) a,b,c,c Ap,
f Add(a) Del(b), h Add(a) Cond(c) h Add(b) Cond(c). seen Section 5
that, assuming establisher-unique, number triples (a,f,b) satisfying a,b Ap
f Add(a) Del(b) bounded n, total number events actions A. number pairs (c,h) c Ap h Cond(c) bounded n. Therefore, number relaxations solved O(n3). seen proof Lemma 4.3 temporal
relaxation solved O(n3) time O(n2) space. follows complexity recognizing
2 O(n6) time O(n2) space.
8. Experiments IPC-2011 Benchmarks
conducted experiments benchmark problems temporal deterministic track
7th international planning competition IPC-2011, order test applicability proposed
temporal relaxation TR well relative utility various lemmas detection monotonicity*. main drawback temporal relaxation concerns EU fluents (i.e. fluents f single action f Add(a)). Indeed, first step setting TR
remove fluents EU goal. goal fluents removed problems
following domains: floortile, matchcellar, parking, pegsol, openstacks, sokoban, storage,
turnandopen. therefore concentrated experiments three domains crewplanning,
parcprinter, tms. problem domain, let SGp denote set possible sub-goals
original unrelaxed problem. 20 problems domains, determined
set EUSGp possible sub-goals SGp EU. EU possible sub-goals
unrelaxed problem remain possible sub-goals TR, since TR remove fluents
EU conditions actions. calculated set possible sub-goals relaxed problem,
call SGp(rel) distinguish set set possible sub-goals SGp unrelaxed
problem. Moreover, calculated set actions produce possible sub-goals relaxed
problem, call Ap(rel) distinguish set Ap unrelaxed problem. first three
columns Table 8.1 show minimum, mean maximum percentages possible sub-goals
remain possible sub-goals TR (i.e. ratio | SGp(rel) | / | SGp | ) 20 problems.
used fluents EUSGp and, particular, ones SGp(rel) test relative frequency
monotonicity*. results SGp(rel) shown next three columns Table 8.1.
parcprinter domain, EUSGp fluents detected monotone*. problem
crewplanning domain, almost fluents EUSGp detected monotone*. problem
tms domain, 37% fluents EUSGp detected monotone*, 50% SGp(rel).
results indicate certain temporal planning problems EU monotone* fluents quite
common, others TR provide useful information since goals EU.

474

fiMONOTONE TEMPORAL PLANNING

IPC 2011
Domain

SGp(rel)

Monotone* SGp(rel)

Unitary Ap(rel)

MIN MEAN MAX MIN MEAN MAX MIN MEAN MAX

Crewplanning

21%

36%

94%

87%

98% 39%

56%

71%

Parcprinter

4%

8%

15% 100% 100% 100% 56%

72%

94%

Tms

60%

60%

60%

54%

54%

50%

95%
50%

50% 54%

Table 8.1. Results experiments three domains IPC 2011.
last three columns Table 8.1 give number actions Ap(rel) detected unitary TR. identification unitary actions Lemmas 6.3, 6.4 6.5 achieved linear
time provides useful information used TR detection monotonicity*. average, half actions Ap(rel) found unitary.
detected monotonicity* applying lemmas increasing order computational complexity: Lemma 4.3, Lemma 7.4, Lemma 7.2, Lemma 7.8. domains, majority
fluents recognised monotone* recognised applying Lemma 4.3, fluents recognised monotone* applying Lemma 7.4 monotone* fluents recognised Lemma 7.2 (which uses temporal relaxation TR). found monotone* fluents
required Lemma 7.8 detected. significantly greater complexity applying Lemma 7.8
compared Lemma 7.2 means worth applying systematically problems.
hand, experiments confirmed Lemmas 4.3, 7.4 7.2 effective detection monotonicity*. Table 8.2 shows three domains, minimum, mean
maximum percentage fluents SGp detected three lemmas.

IPC 2011
Domain
MIN
Crewplanning MEAN
MAX
MIN
Parcprinter
MEAN
MAX
MIN
Tms
MEAN
MAX

Lemma 4.3
80%
87%
95%
88%
95%
100%
29%
29%
29%

Monotone* SGp(rel)
Lemma 7.4 Lemma 7.2
0%
0%
0%
7%
0%
13%
0%
0%
0%
5%
0%
12%
21%
0%
21%
0%
21%
0%


87%
95%
98%
100%
100%
100%
50%
50%
50%

Table 8.2. Percentages fluents detected monotone* three different lemmas.
illustrate degree variation different problems within domain, Figures
8.3, 8.4 8.5 show details 20 problems three different domains.
problem show number monotone* fluents SGp(rel) detected different lemmas.
475

fiCOOPER, MARIS, & REGNIER

Figure 8.3. number fluents SGp(rel) detected monotone* different lemmas
crewplanning domain.

Figure 8.4. number fluents SGp(rel) detected monotone* different lemmas
parcprinter domain.

476

fiMONOTONE TEMPORAL PLANNING

Figure 8.5. number fluents SGp(rel) detected monotone* different lemmas
tms domain.
general conclusion experimental trials, seen many problems TR provides useful information since goal fluents removed. Nevertheless, identified various benchmark domains applied. fact large percentage fluents
found monotone* large percentage actions found unitary demonstrates
potential importance notions beyond use temporal relaxation TR. experimental trials together investigation specific examples (such Example 7.9 Temporal Cement Factory domain described following section) seem indicate integrating
detection unitary actions TR provides much information computationally expensive approach Lemma 7.8.
9. Examples Applications EU Monotone Planning
previously shown EU monotone planning potential applications various industrial settings, construction chemical pharmaceutical industries (Cooper, Maris &
Rgnier, 2012, 2013b). example, Temporal Chemical Process domain, described detail
Cooper, Maris Rgnier (2013b), involves different kinds operations chemicals performed industrial production compounds. raw material, operator
activate source. Then, raw material catalysed different ways synthesize different
products. products mixed reacted using raw material produce
desired compound. example, acetylene raw material derived calcium carbide using water. Then, vinyl chloride monomer produced acetylene hydrogen chloride using mercuric
chloride catalyst. PVC produced polymerization. examples occur pharmaceutical industry production drugs (such paracetamol ibuprofen) and, general,
many processes requiring production combination several molecules, given
unique way obtain (which often case due industrial constraints).
477

fiCOOPER, MARIS, & REGNIER

give detail example construction industry show detection unitary actions greatly speed recognition problems. Temporal Cement Factory
planning domain (Cooper, Maris & Rgnier, 2013b) allows us plan concrete mixing, delivery
use. action duration 30 time units makes times batch concrete fluid time
unit 3 30 (after sets). time, concrete-mixer must cleaned, order
concrete loaded, driven building site, unloaded. concrete must
used still fluid. process illustrated temporal plan given Figure 5. set
actions (illustrated temporal plan shown Figure 5) landmarks. initial state
goal G given
= {At-factory(m), Available(c)}
G = {Delivered(m,c,s), Used(c)}
Given temporal planning problem <I,A,G>, set actions Temporal
Cement Factory domain, set sub-goals SG reduced set actions Ar are:
SG = {Delivered(m,c,s), Used(c), Fluid(c), At(m,s), Available(c),
On(m,c), At-factory(m), Empty(m)}

Ar = {USE(c), UNLOAD(m,c,s), DRIVE(m,s), LOAD(m,c), CLEAN(m), MAKEAND-TIME-CONCRETE(c)}

ai aj A, Add(ai) Add(aj) SG = . Hence, Definition 3.3, set actions EU relative SG. immediately remark actions delete fluents Used(c),
Delivered(m,c,s) At(m,s), actions add fluents Available(c) Atfactory(m). Thus, Lemma 4.3, fluents monotone +monotone relative <I,A,G>. Lemma 7.2, deduce On(m,c) monotone since temporal relaxation TR[After(LOAD(m,c),On(m,c),UNLOAD(m,c,s))] solution. similar argument,
Fluid(c) also monotone Lemma 7.2.
Available(c)
MAKE-AND-TIME-CONCRETE(c)[30]
Available(c)

Fluid(c)

Fluid(c)
At-factory(m)

At-factory(m)

DRIVE(m,s)[6]

CLEAN(m)[4]

At(m,s)

At-factory(m)

Empty(m)

Fluid(c)

Empty(m)

At-factory(m)

At(m,s)
On(m,c)

LOAD(m,c)[5]
Empty(m)

Delivered(m,c,s)
Fluid(c)

Fluid(c)

USE(c)[4]

UNLOAD(m,c,s)[7]

On(m,c)
On(m,c)

Used(c)

Delivered(m,c,s)

Figure 5: Ready-mix Concrete Delivery Temporal Plan
detect unitary actions. Lemma 6.4 (case (1)), deduce
UNLOAD(m,c,s) unitary. Then, applying Lemma 6.4 (case (3)), h = On(m,c) b =
478

fiMONOTONE TEMPORAL PLANNING

UNLOAD(m,c,s), tells us LOAD(m,c) unitary. Finally, applying Lemma 6.4 (case (3)), h
= Empty(m) b = LOAD(m,c), tells us CLEAN(m) unitary. Since CLEAN(m) unitary,
effectively add constraint Once(CLEAN(m)) TR constraint Lemma 7.2 sufficient detect Empty(m) monotone*. Thus, using new notion unitary action

linear-time rules detect actions given Section 6, prove monotonicity* fluents
without needing use computationally expensive Lemma 7.8 previously proposed (Cooper,
Maris & Rgnier, 2013b).
possible apply Theorem 5.6, since EU, fluents monotone* fluents
monotone*. follows TR solution procedure problem. problem <I,A,G>
solution-plan, found TR, shown Figure 5. represent non-instantaneous actions
rectangle. Conditions written action, effects below; causality constraints represented bold arrows, authorisation constraints dotted arrows.
example extended generic case several sites, several batches
concrete several mixers. monotone remains EU provided goals (via fluents
Delivered(m,c,s)) specify mixer deliver batch c building site s.
instances solved polynomial time Theorem 7.10.
10. Discussion
results paper also applied non-temporal planning since, example, classical STRIPS planning problem modelled temporal planning problem actions
instantaneous. worth pointing tractable class classical planning problems
actions establisher-unique fluents detectable (both + ) monotone
applying Lemma 4.3, covered PA tractable class Jonsson Bckstrm (1998).
obvious question whether establisher-uniqueness monotonicity necessary obtain tractability. affirmative answer question follows intractability results nontemporal planning: Bckstrm Klein (1991b) showed establisher-uniqueness alone cannot
prevent minimal plans exponential size, Jonsson Bckstrm (1998) showed conditions implying monotonicity fluents (the class BA terminology), planning
NP-hard.
+

simplicity presentation conformity PDDL2.1, considered inherent
constraints times events within action-instance interval constraints.
can, however, remark Theorem 5.6 still holds inherent constraints arbitrary minclosed constraints, since property required constraints proof Theorem
5.6. example constraint C(x,y) binary interval constraint variable bounds:
yx [f(x,y),g(x,y)], min-closed provided f(x,y) monotone increasing function x
g(x,y) monotone decreasing function y. shift-monotonic constraints used Pralet
Verfaillie (2012) scheduling agile satellites subclass constraints since shiftmonotonic constraints f(x,y) g(x,y) monotone increasing functions x monotone
decreasing functions y. consistency set shift-monotonic constraints tested time
O(n3).

479

fiCOOPER, MARIS, & REGNIER

important aspect temporal planning, absent non-temporal planning, certain temporal planning problems, known temporally-expressive problems, require concurrency
actions order solved (Cushing, Kambhampati, Mausam & Weld, 2007). cement factory
planning problem given Section 9 example temporally-expressive problem, since concurrency actions required solution. Indeed, industrial environments, concurrency actions
often used keep storage space turn-around times within given limits. previous paper
(Cooper, Maris & Rgnier, 2013a), identified subclass temporally expressive problems,
known temporally-cyclic, require cyclically-dependent sets actions order solved.
simple commonly occurring example given Figure 4, concerning agreement
employer employee. tractable class temporal planning problems described Theorem
7.6 contains temporally-expressive temporally-cyclic problems. example, temporally-cyclic problem given Figure 4 establisher-unique fluents + monotone
(this follows Lemma 4.3 since fluents destroyed either action).
temporal planning problems fall tractable class EU monotone problems.
Even so, may certain sub-problems fall class. Given temporal planning problem
<I,A,G>, test polynomial time, fluent f, whether sub-problem <I,A,{f}> satisfies
conditions Theorem 7.6 (i.e. EU monotone, monotonicity detectable using temporal
relaxation TR). case, find polynomial time plan Pf establishes
fluent f. plan Pf considered action could added set actions
order facilitate solution original problem <I,A,G>.
work related literature regarding landmarks. Porteous, Sebastia Hoffmann (2001)
Keyder, Richter Helmert (2010) define landmark fact must true point
every valid solution-plan. Landmarks used planning two main ways. first one
conception heuristic functions guide search algorithms (Richter, Helmert & Westphal, 2008;
Richter & Westphal, 2010; Helmert & Domshlak, 2009). Another use landmarks partition
problem easier subproblems whose goals disjunctions landmarks (Hoffmann, Porteous &
Sebastia, 2004; Sebastia, Onaindia & Marzal, 2006). recently, Vernhes, Infantes Vidal
(2013) define landmark-based meta best-first search algorithm.
Landmarks also used detection unsolvable temporal planning problems (Marzal, Sebastia & Onaindia, 2008). graph built adding causal relationships extracted
landmarks. temporal intervals associated landmark intervals, together
causal relationships, define set constraints. Finally, CSP solver checks consistency
set indicates problem solution inconsistency found. Unlike
set constraints temporal relaxation TR, set constraints fall tractable
class. research required determine whether certain constraints could usefully
combined STP constraints temporal relaxation TR obtain even stronger tractable
relaxation.
general case, verifying fact landmark PSPACE-complete (Hoffmann, Porteous
& Sebastia, 2004). However, landmarks found efficiently using various techniques: Porteous Cresswell (2002) Hoffmann, Porteous Sebastia (2004) present methods
detecting landmarks relations landmarks based backchaining goals
relaxed planning graph, whereas Zhu Givan (2003) use forward propagation graph
Richter, Helmert Westphal (2008) use domain transition graph, graph whose nodes
480

fiMONOTONE TEMPORAL PLANNING

represent possible values variable edges represent possible transitions values induced actions.
notion monotonicity* introduced paper depends relative order establishment destruction fluent within minimal plan. experiments demonstrated many fluents benchmark problems indeed monotone*. interesting avenue future research would investigate, theoretically empirically, relative order establishment destruction different fluents within minimal temporal plan.
closely related research landmarks. Different orderings landmarks studied
non-temporal planning. orderings guaranteed hold every solution-plan
prune solution space (they sound): "Natural" (Koehler & Hoffmann, 2000), "Necessary"
"Greedy-necessary" (Hoffmann, Porteous & Sebastia, 2004). natural ordering
general greedy-necessary ordering necessary ordering. Others orderings "Reasonable", "Obedient-Reasonable" (Koehler & Hoffmann, 2000) sound (it possible
solution-plan respects orderings) may prune solution space. orderings landmarks defined assuming instantaneous actions would need redefined
temporal framework. research required determine whether landmark orderings could usefully extended incorporate orderings types events temporal plans (the establishment destruction fluent action landmark, beginning end interval
fluent required action landmark).
11. Conclusion
presented class temporal planning problems solved polynomial time
number possible applications, notably chemical, pharmaceutical construction industries. notion monotonicity temporal planning essential part definition class. extended basic notion monotonicity monotonicity* considering
minimal plans.
also shown planning problems relaxation based EU monotone planning
interesting alternative standard relaxation produced ignoring deletes. also provides means detecting action landmarks monotone* fluents.
research required discover possible application areas and, practical level,
develop tools help users find model problem involving monotone* fluents
model exists. theoretical level, interesting avenue future research extension
tractable classes presented paper relaxing condition establisher-uniqueness
fluent established one action provided one action establish given moment.
Acknowledgements
research supported ANR Project ANR-10-BLAN-0210. gratefully acknowledge
help reviewers whose constructive suggestions led significant improvements
presentation paper.
481

fiCOOPER, MARIS, & REGNIER

References
Bckstrm C. & Klein I. (1991a) Parallel non-binary planning polynomial time. Proceedings
IJCAI1991, 268-273.
Bckstrm C. & Klein I. (1991b) Planning polynomial time: SAS-PUBS class,
Computational Intelligence 7 (3), 181-197.
Bckstrm C. & Nebel B. (1995) Complexity results SAS+ planning. Computational
Intelligence 11(4), 625-655.
Baier J. A. & Botea A. (2009). Improving planning performance using low-conflict relaxed plans.
Proc. 19th International Conference Automated Planning Scheduling (ICAPS2009).
Betz C. & Helmert M. (2009). Planning h+ Theory Practice. KI 2009: Advances
Artificial Intelligence, LNCS Vol. 5803, 9-16.
Blum A.L. & Furst M.L. (1995) A.L. Blum, M.L. Furst, Fast planning planning-graphs
analysis, in: Proceedings 14th International Joint Conference Artificial Intelligence
(IJCAI-95), Montral, Qubec, Canada, 1636-1642.
Bonet B., Loerincs G. & Geffner H. (1997) Robust Fast Action Selection Mechanism
Planning, Proceedings AAAI-97/IAAI-97, 714-719.
Brafman R.I. & Domshlak C. (2003) Structure Complexity Planning Unary
Operators. Journal Artificial Intelligence Research 18, 315-349.
Brafman R.I. & Domshlak C. (2006) Factored Planning: How, When, Not. Proc. 21st
National Conference Artificial Intelligence, 809-814.
Bylander T. (1994) Computational Complexity Propositional STRIPS Planning. Artificial
Intelligence 69(1-2), 165-204.
Cai D., Hoffmann J. & Helmert M. (2009). Enhancing context-enhanced additive heuristic
precedence constraints. Proc. 19th International Conference Automated Planning
Scheduling (ICAPS2009), 5057.
Chen H. & Gimnez O. (2008) Causal Graphs Structurally Restricted Planning. Proc. 18th
International Conference Automated Planning Scheduling (ICAPS2008), 36-43.
Coles A., Fox M., Long D. & Smith A. (2008) Planning Problems Requiring Temporal
Coordination, Proc. AAAI 2008, 892-897.
Cooper M.C., de Roquemaurel M. & Rgnier, P. (2011) weighted CSP approach costoptimal planning, Artificial Intelligence Communications 24(1), 1-29.
Cooper M.C., Maris F. & Rgnier P. (2010) Solving temporally cyclic planning problems,
International Symposium Temporal Representation Reasoning (TIME), 113-120.
Cooper M.C., Maris F. & Rgnier, P. (2012) Tractable monotone temporal planning, Proceedings
ICAPS 2012, 20-28.
Cooper M.C., Maris F. & Rgnier, P. (2013a) Managing Temporal Cycles Planning Problems
Requiring Concurrency, Computational Intelligence 29(1), 111-128.
Cooper M.C., Maris F. & Rgnier P. (2013b) Relaxation Temporal Planning Problems,
International Symposium Temporal Representation Reasoning (TIME), 37-44.
Cushing W., Kambhampati S., Mausam & Weld D.S. (2007) Temporal Planning Really
Temporal? Proceedings 20th International Joint Conference Artificial Intelligence,
IJCAI2007, 1852-1859.
Dean T., Firby J. & Miller D. (1988) Hierarchical Planning involving deadlines, travel time
ressources. Computational Intelligence 6(1), 381-398.
482

fiMONOTONE TEMPORAL PLANNING

Dean T. & McDermott D.V. (1987) Temporal Data Base Management. Artificial Intelligence
32(1), 1-55.
Dechter R., Meiri I. & Pearl J. (1991) Temporal Constraint Networks, Artificial Intelligence 49(13), 61-95.
M.B. & Kambhampati S. (2003) Sapa: Multi-objective Metric Temporal Planner, Journal
Artificial Intelligence Research 20, 155-194.
Domshlak C. & Dinitz Y. (2001) Multi-agent off-line coordination: Structure complexity.
Proceedings 6th European Conference Planning, ECP2001, 277-288.
Erol K., Nau D.S. & Subrahmanian V.S. (1995) Complexity, decidability undecidability
results domain-independent planning. Artificial Intelligence 76(1-2), 75-88.
Eyerich P., Mattmller R. & Rger G. (2009) Using Context-enhanced Additive Heuristic
Temporal Numeric Planning, Proceedings ICAPS 2009, 130-137.
Fox, M. & Long, D. (2001). Stan4: hybrid planning strategy based subproblem abstraction.
AI Magazine 22(3), 8184.
Fox M. & Long D. (2003) PDDL2.1: Extension PDDL Expressing Temporal Planning
Domains, Journal Artificial Intelligence Research 20, 61-124.
Fox M., Long D. & Halsey K. (2004). Investigation Expressive Power PDDL2.1,
Proc. 16th European Conference Artificial Intelligence, 328-342.
Gerevini A. & Cristani M. (1997) Finding Solution Temporal Constraint Satisfaction
Problems. Proc. 15th International Joint Conference Artificial Intelligence, 1460-1465.
Gerevini, A., Saetti, A. & Serina, I. (2003). Planning stochastic local search temporal
action graphs. Journal Artificial Intelligence Research 20, 239290.
Ghallab M. & Alaoui A.M. (1989) Managing Efficiently Temporal Relations Indexed
Spanning Trees. Proc. 11th Int. Joint Conference Artificial Intelligence, 1297-1303.
Ghallab M., Nau D.S. & Traverso P. (2004) Automated Planning: Theory Practice, Morgan
Kaufmann.
Gimnez O. & Jonsson A. (2008) complexity planning problems simple causal
graphs. Journal Artificial Intelligence Research 31, 319-351.
Gimnez O. & Jonsson A. (2012). influence k-dependence complexity planning.
Artificial Intelligence 177-179, 25-45.
Haslum P. (2008) New Approach Tractable Planning. Proceedings ICAPS2008, 132139.
Haslum P., Slaney J. & Thibaux S. (2012). Incremental lower bounds additive cost planning
problems. Proc. 22nd International Conference Automated Planning Scheduling
(ICAPS2012), 7482.
Helmert M. (2003) Complexity results standard benchmark domains planning. Artificial
Intelligence 143 (2), 219-262.
Helmert M. (2004). planning heuristic based causal graph analysis. Proc. 14th International
Conference Automated Planning Scheduling (ICAPS2004), 161170.
Helmert M. (2006) New Complexity Results Classical Planning Benchmarks. Proc. 16th
International Conference Automated Planning Scheduling (ICAPS2006), 52-61.
Helmert M. & Geffner H. (2008). Unifying causal graph additive heuristics. Proc. 18th
International Conference Automated Planning Scheduling (ICAPS2008), 140147.
Helmert M. & Domshlak C. (2009) Landmarks, Critical Paths Abstractions: Whats
Difference Anyway? Proc. International Conference Automated Planning Scheduling
(ICAPS 2009), 162-169.
483

fiCOOPER, MARIS, & REGNIER

Hoffmann J. (2005) Ignoring Delete Lists Works, Local Search Topology Planning
Benchmarks. Journal Artificial Intelligence Research 24, 685-758.
Hoffmann J., Porteous J. & Sebastia L. (2004) Ordered Landmarks Planning. Journal
Artificial Intelligence Research 22, 215278.
Jeavons P. & Cooper M.C. (1995) Tractable constraints ordered domains, Artificial
Intelligence 79, 327-339.
Jonsson A. (2007) Role Macros Tractable Planning Causal Graphs. Proc. 20th
International Joint Conference Artificial Intelligence (IJCAI2007), 1936-1941.
Jonsson A. (2009) Role Macros Tractable Planning. Journal Artificial Intelligence
Research 36, 471-511.
Jonsson P. & Bckstrm C. (1994) Tractable planning state variables exploiting structural
restrictions. Proc. AAAI1994, 998-1003.
Jonsson P. & Bckstrm C. (1995) Incremental Planning. New Directions AI Planning: 3rd
European Workshop Planning, EWSP1995, 79-90.
Jonsson P. & Bckstrm C. (1998) State-variable planning structural restrictions:
Algorithms complexity. Artificial Intelligence 100(1-2), 125-176.
Karmarkar N. (1984) new polynomial time algorithm linear programming. Combinatorica 4
(4) 373395.
Karpas E. & Domshlak C. (2009) Cost-optimal planning landmarks, International Joint
Conference Artificial Intelligence (IJCAI2009), 17281733.
Katz M. & Domshlak C. (2008) New Islands Tractability Cost-Optimal Planning. Journal
Artificial Intelligence Research 32, 203-288.
Katz M., Hoffmann J. & Domshlak C. (2013a). said need relax variables? Proc.
23rd International Conference Automated Planning Scheduling, (ICAPS2013).
Katz M., Hoffmann J. & Domshlak C. (2013b). Red-Black Relaxed Plan Heuristics. Proc. 27th
AAAI Conference Artificial Intelligence (AAAI2013).
Keyder E. & Geffner H. (2008). Heuristics planning action costs revisited. Proc. 18th
European Conference Artificial Intelligence (ECAI2008), 588592.
Keyder E., Hoffmann J. & Haslum P. (2012) Semi-Relaxed Plan Heuristics, Proc. 22nd
International Conference Automated Planning Scheduling, ICAPS2012, 128-136.
Keyder E., Richter S. & Helmert M. (2010) Sound Complete Landmarks And/Or Graphs.
Proceedings European Conference Artificial Intelligence (ECAI), 335-340.
Knoblock C.A. (1994) Automatically Generating Abstractions Planning. Artificial Intelligence
68(2), 243-302.
Koehler J. & Hoffmann J. (2000) reasonable forced goal orderings use
agenda-driven planning algorithm. Journal Artificial Intelligence Research 12, 338386.
Koubarakis M. (1992) Dense Time Temporal Constraints . Proc. 3rd International
Conference Principles Knowledge Representation Reasoning (KR1992), 24-35.
Laborie P. & Ghallab M. (1995) Planning Sharable Resource Constraints. Proc. 14th
International Joint Conference Artificial Intelligence, 1643-1651.
Long D. & Fox M. (2003) Exploiting graphplan framework temporal planning, Proc. 13th
International Conference Automatic Planning Scheduling, 52-61.
Maris F. & Rgnier P. (2008) TLP-GP: Solving Temporally-Expressive Planning Problems,
TIME 2008, 137-144.

484

fiMONOTONE TEMPORAL PLANNING

Marzal E., Sebastia L. & Onaindia E. (2008) Detection unsolvable temporal planning problems
use landmarks. Proceedings ECAI2008. 919-920.
McDermott D. (1998) PDDL, Planning Domain Definition Language. Technical Report,
http://cs-www.cs.yale.edu/ homes/dvm/.
Porteous J. & Cresswell S. (2002) Extending landmarks analysis reason resources
repetition. Proceedings PLANSIG2002, 4554.
Porteous J., Sebastia L. & Hoffmann J. (2001) Extraction, Ordering, Usage
Landmarks Planning. Recent Advances AI Planning. European Conference Planning
(ECP 2001), 3748.
Pralet C. & Verfaillie G (2012) Time-Dependent Simple Temporal Networks, Proc. 18th
International Conference Principles Practice Constraint Programming, 608-623.
Reichgelt H. & Shadbolt N. (1990). Specification Tool Planning Systems. Proc. 9th
European Conference Artificial Intelligence, 541-546.
Richter S., Helmert M. & Westphal M. (2008) Landmarks revisited. Proc. 23rd AAAI Conference
Artificial Intelligence (AAAI'08). 975-982.
Richter S. & Westphal M. (2010) LAMA Planner: Guiding Cost-Based Anytime Planning
Landmarks. Journal Artificial Intelligence Research (JAIR) 39: 127-177.
Rintanen J. (2007) Complexity Concurrent Temporal Planning. Proc. 17th International
Conference Automated Planning Scheduling (ICAPS2007), 280-287.
Rutten E. & Hertzberg J. (1993) Temporal Planner = Nonlinear Planner + Time Map Manager.
Artificial Intelligence Communications 6(1), 18-26.
Schwartz P. & Pollack M.E. (2004) Planning Disjunctive Temporal Constraints. Proc.
ICAPS'04 Workshop Integrating Planning Scheduling, 67-74.
Sebastia L., Onaindia E. & Marzal E., (2006) Decomposition planning problems. AI
Communications 19:4981.
Shin J. & Davis E. (2004) Continuous Time SAT-Based Planner. Proc. 19th National
Conference Artificial Intelligence (AAAI'04), 531-536.
Slaney J. & Thibaux S. (2001) Blocks World revisited. Artificial Intelligence 125, 119-153.
Smith D.E. (2003) Case Durative Actions: Commentary PDDL2.1, Journal
Artificial Intelligence Research 20, 149-154.
Stergiou K. & Koubarakis M. (2000) Backtracking algorithms disjunctions temporal
constraints. Artificial Intelligence 120(1):81117.
Vere S. (1983) Planning Time: Windows Durations Activities Goals. IEEE Trans.
Pattern Analysis Machine Intelligence 5, 246-267.
Vernhes S., Infantes G. & V. Vidal V. (2013) Problem Splitting using Heuristic Search
Landmark Orderings. Proc. 23rd International Joint Conference Artificial Intelligence
(IJCAI2013), 2401-2407.
Vidal V. & Geffner H. (2005) Solving Simple Planning Problems Inference
Search. Proc. 11th International Conference Principles Practice Constraint
Programming, CP'05, 682-696.
Williams B.C. & Nayak P. (1997) reactive planner model-based executive. Proc. 15th
International Joint Conference Artificial Intelligence, 1178-1185.
Younes H.L.S. & Simmons R.G. (2003) VHPOP: Versatile Heuristic Partial Order Planner.
Journal Artificial Intelligence Research 20, 405-430.
Zhu L. & Givan R. (2003) Landmark extraction via planning graph propagation. ICAPS2003
Doctoral Consortium, 156160.
485

fiJournal Artificial Intelligence Research 50 (2014) 265-319

Submitted 10/13; published 06/14

Property Directed Reachability Automated Planning
Martin Suda

suda@mpi-inf.mpg.de

Max-Planck-Institut fur Informatik,
Saarbrucken, Germany
Charles University, Prague, Czech Republic

Abstract
Property Directed Reachability (PDR) promising recent method deciding
reachability symbolically represented transition systems. originally conceived
model checking algorithm hardware circuits, already successfully applied
several areas. paper first investigation PDR perspective
automated planning.
Similarly planning satisfiability paradigm, PDR draws strength internally employing efficient SAT-solver. show standard encoding schemes
planning SAT directly used turn PDR planning algorithm.
non-obvious alternative, propose replace SAT-solver inside PDR planningspecific procedure implementing interface. SAT-solver free variant
efficient, offers additional insights opportunities improvements.
experimental comparison state art planners finds highly competitive,
solving problems several domains.

1. Introduction
Property Directed Reachability (PDR), also known IC3, recently proposed algorithm
deciding reachability symbolically represented transition systems (Bradley, 2011; Een,
Mishchenko, & Brayton, 2011).1 Since discovery 2010, already established
one strongest model checking algorithms used hardware verification.
original inspiring way PDR harnesses power modern SAT-solver
gives algorithm unique ability discover long counterexample paths combined
remarkable performance proving unreachability. interesting traits include
typically small memory footprint good potential parallelization.
awareness well-known equivalence model checking automated
planning, aim work investigate PDR planning perspective.
main goal establish whether practical success algorithm repeated
planning benchmarks. Moreover, also interested relation PDR
currently used planning techniques. illustrative highlighting interesting
features algorithm start preliminary comparison right away.
fact PDR builds upon SAT-solving technology makes obviously related
planning satisfiability approach (Kautz & Selman, 1996). planning
satisfiability underlying SAT-solver receives formulas increasing size method
progresses check existence increasingly longer plans, PDR SAT-solver call
1. IC3 name Aaron Bradley, originator algorithm, gave first implementation (Bradley,
2011). descriptive name Property Directed Reachability coined Een et al. (2011).
c
2014
AI Access Foundation. rights reserved.

fiSuda

corresponds single step transition system. algorithm
sometimes said operate without unrolling. Dealing formulas fixed signature
lifts computational burden SAT-solver, making respond
reliable way.
Similarly planning satisfiability, PDR proceeds iteratively, gradually disproving
existence plans length 0, 1, 2,. . . . Due so-called obligation rescheduling technique,
however, PDR discover plan length l already iteration k < l, is,
existence shorter plans necessarily ruled yet. typically leads
improved performance, allows algorithm avoid completing potentially
expensive non-existence proofs. similar effect achieved planning satisfiability approach running several SAT-solvers parallel interleaved (Rintanen, 2004).
modification, however, requires non-trivial engineering effort resulting
system contains parameters need tuned problem hand. contrast,
rescheduling PDR amounts literally one-line change algorithm.
line disabled, PDR resorts expensive search optimal length plan.
Surprisingly, PDR also naturally compared explicit heuristic search planning (Bonet & Geffner, 2001). Indeed, PDR probably best understood hybrid
explicit symbolic approaches. satisfying assignment PDR
built systematically, one transition time, finished part corresponds explicit path transition system last piece state expanded next.
time, PDR maintains symbolic reachability information form sequence
sets clauses. k-th set sequence over-approximates k-fold preimage
set goal states. clause sets play role similar admissible heuristic.
represent lower bound estimate distance state goal thus provide
means guide search towards it. However, heuristic value particular state
normally computed remains constant search plan,
clause sets PDR refined continually. refinement happens demand, driven
states encountered search.
1.1 Paper Overview
order apply PDR planning problem, problem processed
suitable form. Section 2 introduce symbolic transition system, description
reachability task based clausal language propositional logic, serves
generic input PDR. observe standard encoding schemes planning
SAT provide us description. means general implementation
algorithm, describe detail Section 3, combined encoding
already yields stand-alone planner. is, however, efficient path take.
main contribution paper presented Section 4. show instead
relying encoding general purpose SAT-solver, can, least case
sequential plan semantics, delegate single step reachability queries planning-specific
procedure. gain polynomial time guarantee answering individual
queries, decoupling PDR underlying SAT-solver also gain additional
insights ideas improvements.
266

fiProperty Directed Reachability Automated Planning

implemented proposed idea new planner PDRplan. Section 5 experimentally confirm efficient standard PDR combined encodings.
also evaluate practical impact various improvements, compare successful configuration PDRplan state art planners encouraging results.
Section 6 returns related work uncovers perhaps surprising connection
PDR Graphplan algorithm Blum Furst (1997). Finally, Section 7 uses
examples behavior PDR two classical planning domains discuss possibilities
future extensions algorithm Section 8 concludes.

2. Preliminaries
section build necessary background explaining PDR. recalling
basic notions propositional logic fixing notation, introduce symbolic transition
systems, serve canonical input algorithm. observe encoding
part well-known planning satisfiability paradigm seen translate given
planning problem symbolic transition system. means combining
encoding PDR one already obtains standalone planner.
2.1 Propositional Logic
signature finite set propositional variables. Formulas built variables
using propositional connectives negation , conjunction , disjunction , implication . Given formula F denote Vars(F ) set variables actually
occurring F (i.e. Vars(F ) ). literal l either variable p negation p.
first case, literal called positive. define complement l literal l
p l = p, p l = p. Also contexts, double negations silently
reduced away.
consistent conjunction literals referred cube disjunction clause.
cube r full Vars(r) = . describing algorithms, advantageous treat
cubes clauses simply sets literals leave interpretation follow
context. Then, complementing cube r obtain clause r = {l | l r}
also vice versa. call clause positive literals positive. clause c said
subsume another clause c d. usual, sets clauses stand conjunction.
semantics propositional logic built around notion assignment,
mapping : {0, 1} signature truth values {0, 1}. write
|= F assignment satisfies formula F . formula F called satisfiable
assignment satisfies it, called valid F satisfiable. Assignments
naturally correspond full cubes: Given assignment define full cube
Lits(s) = {p | p s(p) = 1} {p | p s(p) = 0}.
exactly one assignment, namely s, satisfies Lits(s).
2.2 Encoding Discrete Time
reasoning systems evolve time, use basic signature =
{p, q, . . .} describe current state system introduce disjoint copy
267

fiSuda

denoted 0 = {p0 , q 0 , . . .} represent state system one step. Similarly,
copies 00 , 000 , . . . (also written (2) , (3) , . . .) stand states
future. priming notation extended formulas assignments following way.
F 0 denote formula obtained formula F priming every variable occurring
F . assignment : {0, 1}, denote s0 : 0 {0, 1} assignment
behaves primed symbols unprimed ones, i.e., s0 (p0 ) = s(p) every
p . two assignments , let (s, t0 ) denote joint assignment
(s t0 ) : 0 {0, 1}. means
(
s(p)
(s, t0 )(x) =
t(p)

x = p ,
x = p0 0 .

assignment gives truth value formulas joint signature 0 .
2.3 Symbolic Transition Systems
symbolic transition system (STS) tuple = (, I, G, ), signature, I,
called initial formula, G, goal formula, sets clauses , ,
transition formula, set clauses 0 . STS symbolically represents
explicit transition system TS = (S, SI , SG , RT ), describe next. Notice
symbolic representation exponentially succinct explicit system.
explicit transition system TS consists
set states S, identified set assignments :
= {s | : {0, 1}},
subset SI initial states, states satisfy initial formula:
SI = {s | |= I},
subset SG goal states, states satisfy goal formula:
SG = {s | |= G},
transition relation RT pairs states (also called transitions)
jointly satisfy transition formula:
RT = {(s, t) | s, (s, t0 ) |= }.
path TS finite sequence s0 , . . . , sk states (sj , sj+1 ) RT every
j = 0, . . . k 1. interested existence paths connecting initial state
goal state. say STS satisfiable path s0 , . . . , sk TS
s0 SI sk SG . simplicity, call path witnessing path S.
268

fiProperty Directed Reachability Automated Planning

SI

SG
b

b

b

b

s01 = {p 7 0, q 7 1}

s00 = {p 7 0, q 7 0}

s11 = {p 7 1, q 7 1}
s10 = {p 7 1, q 7 0}

Figure 1: explicit transition system TS represented STS Example 1.
four states correspond four assignments signature = {p, q}.
Example 1. Consider STS = (, I, G, ), = {p, q}, = {p}, G = {p, q},
= {p p0 q 0 , p q p0 , p q q 0 , p q p0 , q p0 q 0 }.

Notice prefer formula notation (as opposed set notation) concrete
clauses. means consist one G two unit clauses, i.e. clauses
single literal. corresponding explicit transition system TS shown Figure 1.
path s00 , s01 , s10 , s11 example witnessing path S. STS satisfiable.
useful notice definition STS symmetrical following sense.
Given STS = (, I, G, ) inverted STS defined 1 = (, G, I, 1 ),
1 obtained simultaneously removing primes occurrences
primed variables adding primes occurrences originally unprimed variables.
corresponds, explicit side, exchanging initial goal states inverting
direction transitions. Therefore, STS satisfiable 1 is.
Moreover, witnessing path recovered witnessing path 1 (also
vice versa) reading respective sequence backwards.
2.4 Propositional STRIPS Planning
paper work planning problems described STRIPS planning formalism. Similarly states transition systems, states world STRIPS planning
identified propositional assignments. propositional variables encoding state
context called state variables denote set X.
action determined tuple = (pre , eff ), pre , called precondition
list, eff , effect list, cubes X, i.e. consistent conjunctive sets literals.
action applicable state |= pre . case applying action
results successor state = apply(s, a), unique state satisfies
eff every p X occurring eff t(p) = s(p). degenerate action
empty precondition effect lists called noop action. applicable state
corresponding successor identical original state: apply(s, noop) = s.
STRIPS planning problem tuple P = (X, sI , g, A), X set state
variables, sI initial state, g goal condition form cube X,
set actions. plan P finite sequence a1 , . . . , ak actions
states s0 , . . . , sk satisfying following conditions:
269

fiSuda

s0 = sI ,
aj applicable sj1 j = 1, . . . , k,
sj = apply(sj1 , aj ) j = 1, . . . , k,
sk |= g.

Notice empty sequence plan P sI |= g.
2.5 Planning Satisfiability
basic idea behind planning satisfiability paradigm (Kautz & Selman, 1992, 1996)
follows. Given planning problem P define sequence propositional formulas
F0 , F1 , . . . plan P formula Fi satisfiable
i. individual formulas Fi iteratively checked using SAT-solver
satisfiable Fi found, plan recovered corresponding satisfying assignment.
concrete form formulas sequence dictated encoding scheme
(see, e.g., Kautz, McAllester, & Selman, 1996; Rintanen, Heljanko, & Niemela, 2006; Huang,
Chen, & Zhang, 2012). encoding schemes simple structure captured
STS = (, I, G, ), individual formulas Fi obtained
Fi = (0) (1) . . . (i1) G(i) .

(1)

Note use priming notation described Section 2.2 thus (0) stands
formula , (1)
formula 0 , etc. resulting formula (1)
Fi , signature j=0,...,i (i) , expresses existence witnessing path
length i. encoding scheme uses called sequential plan semantics,
witnessing path also directly corresponds plan length i. equivalent saying
transition relation encoded allows application single action one
step. Parallel plan semantics allow multiple actions applied one time step.
leads compact representation potentially faster discovery plans. Additional
conditions parallel actions need imposed, however, guarantee true
sequential plan recovered end (see Rintanen et al., 2006, details).
2.6 Two Simple Encodings
close section introducing two example encodings STRIPS planning problem
P = (X, sI , g, A) STS. perhaps simplest representatives encoding
schemes sequential parallel plan semantics, respectively. later refer
theoretical considerations.
transition systems SPseq SPpar corresponding two encodings share several
building blocks. Let signature consist state variables X union set
fresh auxiliary variables = {pa | A} used encoding applied actions. Further,
let us identify initial formula cube Lits(sI ) define goal formula G
reinterpreting goal condition g, formally cube, set unit clauses
G = {{l} | l g}. action mechanics encodings captured following
action precondition axioms AP action effect axioms AE :
AE = {pa l0 | A, l eff }.

AP = {pa l | A, l pre },
270

fiProperty Directed Reachability Automated Planning

encodings differ formalize preserving part actions semantics.
sequential encoding SPseq relies called classical frame axioms
CF (McCarthy
W
& Hayes, 1969) complemented single at-least-one axiom alo = aA pa :
CF = {pa l l0 | A, l literal X l 6 eff l 6 eff }.
Putting together, obtain SPseq = (, I, G, seq ), seq = AP AE CF alo.
Note at-least-one axiom needed, without transition arbitrary
state would possible state action applied, i.e. state pa
false every A. hand, classical frame axioms ensure two
actions applied together state effects must identical. Thus extracting
(sequential) plan witnessing path SPseq arbitrarily choose step
action pa true corresponding state.
parallel encoding SPpar uses following explanatory frame axioms EF (Haas, 1987)
EF = {l l0

W

aA leff pa

| l literal X},

combination called conflict exclusion axioms CE
CE = {pa pb | a, b A, 6= b, actions b conflicting},
two actions considered conflicting ones precondition inconsistent
others effect, i.e. literal l X
either l pre l eff b , l pre b l eff .
sum, define SPpar = (, I, G, par ) par = AP AE EF CE . encoding
two actions applied parallel consistent effects (action effect axioms)
one destroy precondition (conflict exclusion axioms).
recovering sequential plan, parallel actions serialized order.
Please consult work Ghallab, Nau, Traverso (2004, ch. 7.4) details.

3. Property Directed Reachability
section present PDR algorithm deciding satisfiability symbolic transition systems. algorithm probably best understood explicit search
given transition system complemented symbolic reachability analysis. explicit
side, constructs path starting initial state extending step step towards
goal.2 time, maintains symbolic stepwise approximating reachability information, locally refined whenever current path cannot extended further.
reachability information guides path construction also bound eventually
converge certificate non-reachability, witnessing path exists.
2. standard formulation, PDR actually builds path way round, goal state
backwards towards initial state. small detail theory point view, since
definition STS symmetrical. hand, later show, direction adopt
gives rise much successful algorithm typical planning benchmarks.

271

fiSuda

3.1 Extension Query Reason Computation
Let us assume STS = (, I, G, ) given. basic building block
constructed path state, reachability information composed sets clauses.
core operation, around algorithm built, extending current path one
step. Given state set clauses L, ask whether state t, successor
respect , satisfying clauses L. question delegated
SAT-solver posing following query:
SAT ?[ Lits(s) (L)0 ].

(2)

answer positive, extract successor state satisfying assignment,
necessarily form (s, t0 ), extend current path. unsatisfiable
case, compute reason successor property L.
reason cube r Lits(s) already formula r (L)0 unsatisfiable. PDR
removes path learns clause c = r prevent situation
happening future. clause c property preimage L respect
state fails satisfy.
important efficiency algorithm always compute reason
small possible. reason fewer literals gives rise shorter clause,
better generalizes current situation. clause learned
state also many similar states known successor satisfying L.
several techniques computing small reasons. describe two
them: SAT-solving assumptions explicit minimization. postpone discussing
third one, inductive minimization, till Section 3.5. important correctness
PDR final reason consistent goal formula G. close section
explaining property achieved.
3.1.1 SAT-solving Assumptions
Many modern SAT-solvers simply return UNSAT, able identify
input clauses actually used derivation unsatisfiability. Solving
assumptions particular, simple efficient form unsatisfiable core extraction
technique, first introduced Een Sorensson (2003) SAT-solver Minisat.
assumptions technique understand designated unit (single literal) clauses passed
along rest input solver. case input unsatisfiable, solver
able report units actually used proof.
Solving assumptions provides us essentially free mechanism computing
small reasons. simply designate literals Lits(s) treated unit assumptions
query (2) above. unsatisfiable case, obtain reason r Lits(s) required.
3.1.2 Explicit Minimization
subset r assumption literals Lits(s) returned solver typically
reduced. explicitly minimize trying remove literals one one.
respective query remains unsatisfiable leave literal out. Otherwise put
back. number steps proportional |r| obtain final reason set r r minimal
272

fiProperty Directed Reachability Automated Planning

respect subset relation query
SAT ?[ r (L)0 ],
unsatisfiable. Note order literals tried influences final
result may subject heuristical tuning. Although reason minimization expensive operation (we need one extra SAT-solver call per literal), experiments show
important ingredient solving hard problems.
3.1.3 Keeping Reason Disjoint G
become clear later, ensure correctness PDR require computed
reason r consistent goal formula G. words, formula r G must
unsatisfiable. always achieved, algorithm never attempts
extend goal state thus start minimizing unsatisfiable Lits(s) G.
particularly simple strategy, works whenever goal formula G form
set unit clauses (as case planning), minimizes reason much possible,
afterwards puts single literal back r provided required unsatisfiability condition
would otherwise compromised. look literal l added r (unless found
already present) {l} G. condition is, assumptions,
sufficient necessary ensure r G unsatisfiable established without
additional calls SAT-solver.
Another option make sure beforehand set goal states included
preimage respect transition relation . instance, making transition
relation reflexive adding self-loops every state achieves without actually affecting
existence length shortest witnessing path. planning, simply
include noop action action set.
3.2 Data Structures Main Invariants
continue exposition PDR describing main data structures. clause sets
representing reachability information organized sequence3 L0 , L1 , . . .
refer layers. moment run algorithm layers satisfy
following three invariants:
1) L0 equivalent G,
2) Lj+1 Lj thus Lj Lj+1 j 0,
3) (Lj )0 Lj+1 j 0, i.e., Lj+1 over-approximates preimage Lj .

algorithm starts, layer L0 initialized equal set G
remaining layers empty. Thus, initially, invariants 1), 2), 3) trivially
satisfied. return invariants appropriate place argue
indeed maintained algorithm.
constructed paths actually one represented via
called obligations.4 Formally, obligation pair (s, i) consisting state
3. point time finitely many layers non-empty need represented memory.
4. full term proof obligation. comes verification perspective, obligation must
proven unreachable, otherwise property system hold counter-example found.

273

fiSuda

index i. index natural number denoting position respect
layers. may seen stand lower bound estimate distance towards
goal. practical implementation obligation also stores link parent, i.e.
obligation derived, use links recover full witnessing
path goal reached.
3.3 Algorithm
ready look overall structure PDR (see Pseudocode 1).
initializing layers (line 1), algorithm proceeds iterations, counted variable
k. main part iteration path construction phase algorithm
attempts build path step step terminates full witnessing path actually
discovered. iteration k finishes without completing path, PDR established
witnessing path transition system length k less.
describe detail below, path construction enhanced obligation
rescheduling technique, allows algorithm iteration k consider paths
potentially longer k. Path construction iteration complemented clause
propagation phase, attempts push clauses low index layers high index
ones checks global convergence within layers, occurrence implies
witnessing path (of length) possible. Neither obligation rescheduling
clause pushing needed ensuring correctness algorithm, typically greatly
improve performance.
3.3.1 Path Construction
path construction phase iteration k starts using SAT-solver pick initial
state satisfying Lk (lines 4 5). manipulates set Q, working priority queue,
storing obligations. set Q initialized (line 6) obligation (s, k).
inner loop (starting line 7) processes individual obligations, selecting first
estimated closer goal (line 8). Let (s, i) selected obligation. = 0,
means full witnessing path constructed algorithm terminates
(line 10). path extension query described previously executed next (line 11). look
successor would satisfy clauses Li1 . Since originally obtained
satisfying Li , represents attempt extend current path one step closer towards
goal. extension successful new obligation (t, i1) worked next
current (s, i) stored Q (lines 12, 13). opposite case, new clause
derived reason failure used strengthen layers L0 , . . . , Li (lines 15,
16). Notice strengthening state longer satisfies Li . means
approximation become strictly precise, ensures progress.
3.3.2 Obligation Rescheduling
unsatisfiable branch extension attempt continues two lines (19, 20),
necessary correctness PDR. Without obligation rescheduling technique, algorithm would forget obligation (s, i) would return work
parent. would correspond strict backtracking behavior, set Q functioning
stack. Instead, try reuse obligation reschedule one step
274

fiProperty Directed Reachability Automated Planning

Pseudocode 1 Algorithm PDR(, I, G, ):
Input:
symbolic transition system = (, I, G, )
Output:
witnessing path guarantee path exists
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:

L0 G; foreach j > 0 : Lj /* Initialize layers */
k = 0, 1, . . .
/* Path construction: */
SAT ?[ Lk ]
extract state model
Q {(s, k)}
Q empty
pop (s, i) Q minimal
= 0
return WITNESSING PATH FOUND
SAT ?[ Lits(s) (Li1 )0 ]
extract successor state model
Q Q {(s, i), (t, 1)}
else
compute reason r Lits(s) r G unsatisfiable
foreach 0 j : Lj Lj {r}
/* Obligation rescheduling: */
< k
Q Q {(s, + 1)}
/* Clause propagation: */
= 1, . . . , k + 1
foreach c Li1 \ Li
/* Clause push check */
SAT ?[ c (Li1 )0 ]
Li Li {c}
/* Convergence check */
Li1 = Li
return PATH POSSIBLE

275

fiSuda

b

(t, 1)

b

(s, 2)


L2

G
?
L0

G
b

r
b

(s, 2)


L1

b

b

(t, 2)

L2

L0
L1

Figure 2: Layers, obligations rescheduling.
goal. typically boosts performance allows PDR discover paths longer
current iteration number k, existence paths length k ruled out.
Without obligation rescheduling, PDR looks optimal length paths.
obligation rescheduling technique well general interaction layers,
obligations, reasons illustrated Figure 2. There, PDR middle path
construction phase iteration 2. algorithm attempting extend obligation (t, 1)
reach goal state one step (left). attempt fails (right), PDR generalizes
t, obtains reason r, learns new clause c = r strengthen layers L1
L0 . Notice obligation rescheduled (t, 2) PDR attempt extend
satisfy new L1 one step. Without rescheduling, PDR would forget would
go back extending (s, 2) instead.
3.3.3 Clause Propagation
Let us proceed clause propagation phase. checks every clause c lying layer
Li1 Li (line 24) whether could pushed forward added strengthen
layer Li . done query line 26 returns UNSAT, means
(Li1 )0 c,
adding clause Li preserve invariant 3). motivation clause propagation
stronger layers provide better guidance following path construction
phase. Indeed, notice clauses may even enter till empty layer Lk+1 .
importantly, however, clause propagation opportunity check equality
two neighboring layers (line 29).5 explain later, equality implies
witnessing path transition system length PDR terminates (line 30).
3.3.4 Example Execution
Let us recall STS = (, I, G, ) Example 1, defined two variable signature
= {p, q} initial, goal, transition formulas = {p}, G = {p, q},
= {p p0 q 0 , p q p0 , p q q 0 , p q p0 , q p0 q 0 },
5. necessary perform relatively expensive clause pushing (which requires one SAT-solver call
per clause) checking layer equivalence. Experience model-checking suggests, however,
pushing substantially helps speed convergence clause propagation one key
ingredients efficiently detecting unsatisfiable problems.

276

fiProperty Directed Reachability Automated Planning

step
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25

event / query

effect / explanation

Initialization
Path construction (iteration 0)
SAT ?[ L0 ] false
Clause propagation
SAT ?[ p (L0 )0 ] false
push p add L1
SAT ?[ q (L0 )0 ] true
Path construction (iteration 1)
SAT ?[ L1 ] false
Clause propagation
SAT ?[ q (L0 )0 ] true
SAT ?[ p (L1 )0 ] true
Path construction (iteration 2)
SAT ?[ L2 ] true
extract state initialize Q
SAT ?[ Lits(s) (L1 )0 ] false
compute reason learn clause
SAT ?[ L2 ] true
extract state initialize Q
SAT ?[ Lits(t) (L1 )0 ] true
extract state store Q
SAT ?[ Lits(u) (L0 )0 ] true
extract state . . .
. . . store Q
witnessing path found

L0 = {p, q}; Li = > 0
k=0
p p unsat.
p (p p0 q 0 ) (p q)0 unsat.
L1 = {p}
q (p q)0 sat.
k=1
p p unsat.
q (p q)0 sat.
p p0 sat.
k=2
p sat.
= {p 7 0, q 7 0}; Q = {(s, 2)}
p q (p q p0 ) (p)0 unsat.
r = p q; L2 = {p q}, L1 = . . .
p (p q) sat.
= {p 7 0, q 7 1}; Q = {(t, 2)}
p q (p)0 sat.
u = {p 7 1, q 7 0}; Q = {(t, 2), (u, 1)}
p q (p q)0 sat.
v = {p 7 1, q 7 1};
Q = {(t, 2), (u, 1), (v, 0)}
return t, u, v

Table 1: Execution trace PDR STS Example 1.

respectively. Table 1 showcases execution trace PDR STS. lists
SAT-solver queries order execution, provides explanation results form
unsatisfiable cores, tracks changes global variables. Notice step 6
clause p successfully pushed layer L0 L1 . step 17 new clause p q
formally added L2 , L1 , L0 . However, properly strengthens layer L2 .

3.4 Correctness
show correctness PDR first review invariants 1)3) demonstrate
indeed preserved run algorithm. add fourth observation,
invariant 4), important showing correctness unsatisfiable case. invariants
used prove independent lemma and, finally, also main correctness theorem.
277

fiSuda

3.4.1 Four Invariants
Invariant 1) states layer L0 equivalent G. could violated
new clause c added L0 (line 16). since c = r reason r assume
r G unsatisfiable (recall Section 3.1.3), G c invariant 1) preserved.
Invariant 2) asserts Lj+1 Lj index j 0. trivially maintained
new clause added layers (line 16) clause pushing (line 27).
Invariant 3) statement (Lj )0 Lj+1 j 0. new clause c
added layers L0 , . . . , Li (line 16) unsuccessful extension obligation
(s, i), means c = r reason r Lits(s). definition reason
formula r (Li1 )0 unsatisfiable and, therefore, (Li1 )0 c.
guarantees invariant 3) hold j = 1 clause c added Li . However,
layers index j < 1 even stronger Li1 invariant 2), invariant
3) also hold j < 1. Finally, case j > 1 trivial. already discussed
(recall Section 3.3.3) invariant 3) also preserved clause propagation.
one observation need order show correctness PDR.
Let us call invariant 4). Invariant 4) states path construction iteration
k finishes initial state satisfying Lk . follows fact query
line 4 must unsatisfiable path construction finish.
3.4.2 Correctness Termination
Lemma 1. PDR creates (either line 6 line 13) new obligation (s, i)
|= Li . Moreover, 6|= Lj j < i. latter property maintained throughout
run algorithm and, particular, holds also rescheduling (line 20).
Proof. First note sufficient show second part j = 1
use invariant 2). Also note run PDR clauses added never
removed layers. means sufficient focus moments new
obligation created: 6|= Lj obligation (s, i) created, must also hold
later, layer Lj strengthened addition new clauses.
Let us consider iteration k. creating new obligation (s, k) line 6,
|= Lk construction 6|= Lk1 invariant 4). creating new obligation
(t, 1) line 13, assume parent (s, i) already satisfies lemma and,
particular, 6|= Li1 . |= Li1 , construction, > 1
infer 6|= Li2 assumption invariant 3). Finally, obligation
(s, i) rescheduled (s, + 1) addition clause c = r Li
r Lits(s). means 6|= Li time rescheduling.
Lemma 1 captures intuition state obligation (s, i) always least
steps reaching goal. follows lemma PDR never attempts
extend goal state, assumption relied Section 3.1.3 show
always keep reasons disjoint goal formula G.
Theorem 1 (Bradley, 2011). Given STS = (, I, G, ) algorithm terminates
returns witnessing path satisfiable.
278

fiProperty Directed Reachability Automated Planning

Proof. easy see PDR returns path (line 10)6 witnessing path S.
Indeed, every considered obligation (s, i) state reachable initial state
= 0 state satisfies L0 , equivalent G invariant 1).
PDR terminates claiming witnessing path exists (line 30) path construction
phase iteration k finished index 0 j k Lj = Lj+1 .
combining invariants 1)3) detected equality obtain G Lj (Lj )0 Lj .
together invariant 4) rules existence witnessing path length.7
address termination first show path construction phase iteration k
cannot run indefinitely. Recall PDR always selects extension obligation
minimal index (line 8). Thus follows Lemma 1 successful extension
obligation (s, i) new extracted state equal state previously
considered iteration k (t currently state satisfies Li1 ).
hand, unsuccessful extension obligation (s, i) addition new clause c
layer Li ensures 6|= Li anymore (recall c = r r Lits(s)).
means cannot k 2|| repetitions Q-processing while-loop
(line 7) 2|| repetitions outer while-loop path construction (line 4).
left bound maximal number iterations PDR. invariant 2) sets
states represented individual layers ordered inclusion clause
propagation phase iteration k finishes first k + 1 sets necessarily distinct.
Thus cannot 2|| iterations PDR terminates.
3.5 Inductive Reason Minimization
Inductive reason minimization technique obtaining small reasons unsuccessful
extensions. postponed discussing technique presentation PDR,
relies non-obvious way overall architecture algorithm. Moreover,
although inductiveness one main initial ideas behind PDR (Bradley, 2011),
experiments suggest practical value relatively advanced technique
automated planning may limited.
demonstrate inductive minimization let us recall situation unsuccessful extension obligation (s, i). want compute reason r, subset
Lits(s), ideally small possible, formula
r (Li1 )0

(3)

unsatisfiable. Now, crucial observation since next step going
strengthen layers L0 , . . . , Li (and, particular, layer Li1 ) clause c = r,
may already assume c primed side (3) minimizing r. means,
use stronger query
r (Li1 r)0 .
r sides transition breaks monotonicity: r gets weaker, r gets
stronger. Satisfiable query may become unsatisfiable literals removed
6. Line 10 Pseudocode 1 reports existence path. true witnessing path can, however,
easily recovered following parent pointers (see Section 3.2) last obligation (s, 0).
7. layer Lj understood promised certificate non-reachability. property
goal states incompatible initial formula preserved traversing transitions backwards.

279

fiSuda

r. makes task finding subset-minimal inductive reason computationally
difficult (Bradley & Manna, 2007).
Pseudocode 2 Inductive Reason Minimization:
Input:
set clauses L cube r
formulas r (L)0 r G unsatisfiable
Output:
Minimized inductive reason r r, i.e.,
formulas r (L r )0 r G unsatisfiable
1:
2:
3:
4:
5:
6:
7:
8:

repeat
r0 r
foreach l r /* Check literal r0 */
l0 (r0 \ {l}) {l0 } G /* try removing l */
r0 (r0 \ {l})
SAT ?[ r0 (Li1 r0 )0 ]
r0 (r0 {l}) /* Put literal back */
r = r0 /* removal last iteration */

9:
10:

return r

Pseudocode 2 present simple version inductive reason minimization
minimality guarantee, was, however, successfully applied hardware model checking
(Een et al., 2011). procedure meant improve replace explicit reason
minimization described Section 3.1.2. assumes goal formula G form
set unit clauses keep reason disjoint G (see Section 3.1.3). Notice
non-monotone setting inductive minimization makes sense retry literals
single literal successfully removed. procedure employes
outer loop continue minimizing till true fixed point reached.
3.6 Notes Implementation
several important points relevant practical implementation PDR
fit level detail presented pseudocode. moved section.
3.6.1 Representation Layers
individual clause sets Li ordered inclusion advantageous store
clause once, namely position appears last. convention
named delta encoding Een et al. (2011). defined setting
= Li \ Li+1



Li =



ji j .

delta encoded layers clause propagation moves clauses around instead copying
equality check neighboring layers becomes emptiness check
respective delta.
280

fiProperty Directed Reachability Automated Planning

3.6.2 Clause Subsumption
observed PDR often derives clause c layer Li weaker clause
already present. pays remove (so effectively L0 , . . . , Li )
clauses subsumed new clause c. Keeping layers small way (while
preserving semantic strength) helps speed algorithm several places.
reduces load SAT-solver (provided retract subsumed clause it)
also means fewer clauses need checked pushing.
3.6.3 Obligation Subsumption
Another place subsumption (and should) employed dealing
obligations. may happen obligation (s, i) handled, layer Li ,
obligation belongs, gets meantime strengthened way longer
satisfies Li . point already know obligation cannot extended,
save one SAT-solver call directly reschedule obligation. situation
detected subsumption: state satisfy clause set L
clause c L c Lits(s). insert test point algorithm
new clause c derived Li . check subsumption obligations
form (s, i) currently set Q.
3.6.4 Breaking Ties Popping Q
popping obligations set Q (line 8) make sure select among
estimated closest goal. necessary ensuring termination algorithm.
Otherwise, however, free choose obligation minimal index i. Two
prominent strategies resolving dont-care non-determinism
select recently added obligation first, call stack strategy,
select least recently added obligation first, queue strategy.
stack strategy prefers exploring longer paths short ones, queue strategy
opposite. Een et al. (2011) report small performance gain stack strategy
hardware model checking benchmarks. used stack strategy default
experiments observed superiority queue strategy satisficing planning,
also slightly unfavorable effect plan quality (see Section 5.3.3).

4. PDR without SAT-solver
Although possible encode STRIPS planning problem STS use general
implementation PDR solve it, efficient approach adopted. approach
relies observation work normally delegated PDR SAT-solver
case planning sequential plan semantics instead implemented directly
planning-specific procedure. gain procedure polynomial
time guarantee response extension query, ensuing perspective also
enables us devise new improvements overall algorithm.
SAT-solver employed several places within PDR. start focusing
primary role lies extending current path one step. Section 4.1
281

fiSuda

develop procedure extend replace SAT-solver path extension queries. separate
section devoted discussing inductive reason minimization planning context.
Section 4.3 deal replacing remaining SAT-solver calls. show
efficiently implement clause pushing positive STRIPS planning problems, subclass
STRIPS problems typically used practice. discuss possibility
reversing default search direction PDR Section 4.4 and, finally, propose several
improvements algorithm Section 4.5.
4.1 Planning-Specific Path Extensions
Let us recall interface path extensions, normally implemented PDR
call SAT-solver (Section 3.1). Given state set clauses L decide whether
exists state t, successor respect transition relation ,
satisfies L. positive case, refer successful extension, return t.
negative case, successor exists, compute reason r failure
form preferably small subset literals defining s, state satisfying
r successor would satisfy L.
Let us assume STRIPS planning problem P = (X, sI , g, A) given. gradually
work towards planning-specific implementation interface within procedure
extend(s, L). central idea emulate mechanics sequential encoding SPseq
(see Section 2.6). makes implementation particularly straightforward
perspective positive part interface. Given state s, simply iterate
actions A, generate successor ta = apply(s, a) whenever applicable s,
check ta whether satisfies clauses L. successor found,
returned procedure terminates. iteration clearly affordable
complexity point view. fact, similar spirit explicit state
planners need do: enumerate successor states evaluate heuristic value.
non-trivial part extend procedure deals computing small reason
case unsuccessful extension. conceptually simplify problem first separately
collecting set reasons Ra every action computing overall reason
r union
[
r=
ra
(4)
aA

reason contributions ra Ra selected way minimizes size union.
idea ra Ra distinct reason action cannot applied
produce successor state would satisfy clauses L. union (4)
justifies successor state via action whatsoever.
rest section, first explain individual reasons ra Ra
action derived actions failed preconditions clauses L
respective successor state fails satisfy. show reason collecting
process practice sped employing certain subsumption concepts. Finally,
present approach obtaining small overall reason r, along detailed pseudocode
extend procedure proof correctness. satisfy requirement PDR
final reason disjoint set goal states, adopt solution
formally adding noop action action set (see Section 3.1.3).
282

fiProperty Directed Reachability Automated Planning

4.1.1 Reasons Individual Actions
construct set reasons Ra particular action follows. First check
whether action applicable given state s. precondition
literal l pre false s. negation literal represents singleton reason
{l} Lits(s) add Ra . Clearly, long state satisfies l way
used produce successor state, let alone one would satisfy L.
Next, compute successor state ta = apply(s, a). Strictly speaking, ta cannot
regarded true successor applicable s. Nevertheless, ta useful even
computing reasons, namely reasons corresponding clauses L false
ta . either clauses already false failed make true
clauses became false due effect a. clause c add Ra
reason rc consisting negations literals l c. optimization, include
negated literals made false effect a. Since literals
always false applied due effects, long satisfies rc , successor ta
cannot satisfy c. Summarizing formally, final set reasons obtain:
Ra = {{l} | l pre 6|= l} {rc | c L ta 6|= c},
rc = {l | l c l 6 eff }. easy check rc Lits(s) required.
Notice set Ra empty action applicable successor
ta satisfies clauses L.
Example 2. Starting state = {o 7 0, p 7 0, q 7 0, r 7 0}, let us compute
reasons action = (pre , eff ) pre = {p, q} eff = {o, r} respect
clause set L = {o q, p r}. precondition q satisfied s, one
reason {q}. Next compute ta = apply(s, a) = {o 7 1, p 7 0, q 7 0, r 7 0}.
first clause, q satisfied ta give rise reason. second clause,
p r, however, false ta . reason corresponding second clause {p}.
negated literal, r, part reason, explicitly set false
effect a. final reason set Ra obtain thus {{p}, {q}}. Notice
computed reasons subsets Lits(s) = {o, p, q, r}.
Correctness reason set construction captured following lemma.

Lemma 2. Let ra Ra reason action {noop} defined above.
ra AP AE CF (L)0 |= pa ,
AP , AE CF are, respectively, action precondition, action effect
classical frame axioms used transition formula seq sequential encoding SPseq .
Proof. Let us first assume ra = {l} reason derived failed precondition
literal l pre . action precondition axiom pa l AP
conclusion pa follows single resolution inference unit assumption l.
possibility ra = {l | l c l 6 eff } clause c L false
successor state ta . must action effect axiom pa l0 AE every
literal l c l eff also classical frame axiom pa l l0 CF every
literal l c l 6 eff (if literal l eff clause c would satisfied
283

fiSuda

ta ). resolving axioms respective primed
literals l0 primed version
W
0
0
(c) (L) clause c obtain clause pa lra l final unit clause
pa derived resolution available assumptions ra .
4.1.2 Reason Subsumption
describe compute overall reason r actions contributions
Ra , let us note two useful notions subsumption individual
reasons reason sets, used simplify reason sets
computation started. subsumption individual reasons inside one particular
Ra simply subset relation. make sense keep r1 r2 inside Ra
r1 r2 . Keeping smaller r1 sufficient, whenever would decide pick r2
reason inside union (4), switching r1 instead could make result
smaller. practice, check kind subsumption unit reasons
failed preconditions reasons false clauses.8 implemented
simply ignoring false clauses would true action applicable.
Dually above, discard whole reason set Ra action
another action b reason set Rb
rb Rb ra Ra ra rb .
remove reason set Ra , sense lean,
contribution rb Rb choice ra Ra would dominated rb
final union r. efficiency reasons, exploit trick implementation
respect one particular action role subsuming action b, namely
noop action. mentioned before, include noop action action set ensure
PDRs correctness. reason set Rnoop consists reasons corresponding clauses
L false s.9 action make clauses true
corresponding successor state, reason set Ra subsumed described sense
Rnoop skipped.
4.1.3 Computing Overall Reason
Computing overall reason r amounts selecting every particular reason ra Ra
union (4) small possible. Stated general form facing
optimization version NP-complete problem. fact, easily seen dual
Maximum Subset Intersection problem shown NP-complete Clifford Popa (2011).
therefore attempt find optimal solution contend
reasonable approximation instead.
sort reason sets Ra according size |Ra | traverse smaller
larger ones. idea deal constrained cases first moving
freedom. traversal, maintain unfinished
union r0 initialized empty set . reason set Ra considered
turn pick reason ra Ra minimizes size r0 ra update
8. sufficient, PDR keeps layers L subsumption reduced reasons false clauses
subsumption reduced free.
9. PDR calls extend(s, L) 6|= L, always least one clause.

284

fiProperty Directed Reachability Automated Planning

set r0 accordingly describe union reasons selected far. Although
greedy pass action sets guarantee final value r0 minimal,
already gives satisfactory results.
improve quality reason set even further, minimize r0 respect
subset relation explicitly trying remove individual literals checking whether
result still valid overall reason. direct adaptation explicit reason
minimization procedure employed original PDR (recall Section 3.1.2). detail,
iteratively pick literal l r0 check every action whether reason ra Ra
ra (r0 \ {l}). indeed case, r0 shrunk (r0 \ {l}), otherwise
continue old r0 try another literal instead. literals
tried out, obtain final result r.
4.1.4 Pseudocode Correctness
code procedure extend(s, L) detailed Pseudocode 3. corresponding
reason construction proceeds three stages. first stage collect reasons
individual actions, constructing sets Ra . performed iteration
action set establishes whether successor state satisfying L exists.
either terminates discovering computes non-empty set Ra every action
a. first stage also includes subsumption-based filtering reasons, within
particular actions reason set reason sets noop action one
action. second stage, described simple greedy pass sets Ra
computes initial overall reason, explicitly minimized stage three.
Correctness extend procedure positive case well fact
returned reason r r Lits(s) easy establish. remaining argument
captured following lemma.
Lemma 3. Let r cube returned procedure extend(s, L). formula
r seq (L)0

(5)

unsatisfiable, seq transition formula sequential encoding SPseq .
Proof. WeSfirst observe every action {noop} reason ra
r = aA{noop} ra . actions Ra R reason initially
picked stage two (line 22) possibly later changed reason ra
ra (r \ {l}) stage three (line 26). actions whose reason set subsumed
Rnoop (line 14) formally pick reason noop.
Since ra r every action {noop}, use Lemma 2 infer formula
(5) entails unit clause pa every WA {noop}. formula (5) also
trivially entails at-least-one axiom alo = aA{noop} pa , must unsatisfiable.
easy see procedure extend(s, L) runs time polynomial |X|,
number state variables, |A|, number actions planning problem, |L|,
size given clause set. mainly enabled fact extend emulates
285

fiSuda

Pseudocode 3 Procedure extend(s, L):
Input:
State s; set clauses L 6|= L
Output:
Either state t, successor |= L
reason r Lits(s) state satisfying r successor satisfying L
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

/* Stage one: look successor state prepare reason sets */
Ls {c L | 6|= c} /* Clauses false */
Rnoop {c | c Ls } /* reasons noop action */
assert Rnoop 6= /* Follows contract caller */
R {Rnoop } /* set reason sets collected far */
foreach
pre sa {l pre | 6|= l} /* Preconditions false */
apply(s, (, eff )) /* Ignore preconditions apply effects */
Lt {c L | 6|= c} /* Clauses false */
pre sa = Lt =
return /* positive part: returning successor */
else Ls Lt
pass /* nothing: reason set would subsumed Rnoop */
else
Lt0 {c Lt | c pre sa = } /* False clauses non-subsumed reason */
Ra {{l} | l pre sa } {{l | l c l 6 eff } | c Lt0 }
R R {Ra } /* Record reason set */

/* Stage two: compute overall reason */
r
21: foreach Ra R ordered |Ra | small large
22:
pick ra Ra |r ra | minimal
23:
r r ra
19:
20:

/* Stage three (optional): minimize reason */
foreach l r
26:
every Ra R ra Ra ra (r \ {l})
27:
r (r \ {l})
24:
25:

28:
29:

return r /* negative part: returning (subset minimal) reason cube */

286

fiProperty Directed Reachability Automated Planning

sequential encoding SPseq individual actions first stage considered
independently.10
similar complexity guarantee seems achievable within general-purpose SATsolver supplied encoding configured prefer branching
action variables setting first true. However, inherent overhead connected
explicitly generating corresponding axioms storing memory
probably noticeable practice. Moreover, reason set subsumption optimization
counterpart general-purpose solver.
4.2 Inductive Reason Minimization Procedure extend
Inductive minimization based idea checking whether particular literal l
removed final reason r assume clause c = r0 corresponding
reduced reason r0 = (r\{l}) already present set clauses L (see Section 3.5).
perform inductive minimization within extend procedure speculating
action whether would able satisfy additional clause c applying a.
answer positive need look proper reason ra Ra .
Pseudocode 4 Stage three extend(s, L); inductive version:
1: repeat
2:
r0 r
3:
foreach l r /* Check literal r0 */
4:
l0 (r0 \ {l}) l0 g /* attempt remove l */
5:
r0 (r0 \ {l})
6:
foreach
7:
every l0 eff : l0 6 r0
8:
continue /* passed inductive argument */
9:
Ra R ra R ra r0
10:
continue /* passed; small reason */
11:
Ra 6 R ra Rnoop ra r0
12:
continue /* Ra subsumed Rnoop contains small reason */
13:

/* Action says: Literal l cannot removed */
15:
r0 (r0 {l}) /* Put literal back */
16:
break
17: r = r0 /* removal last iteration */
14:

18:
19:

return r

idea demonstrated Pseudocode 4, regarded replacement
stage three original extend procedure. Notice longer consider
noop action part action set11 thus need explicitly check
10. devising analogous procedure parallel plan semantics, one would general need
consider every subset actions applied together. seems make polynomial time
solution much difficult, hopeless. However, see Section 6 interesting connection.
11. noop action trivially passes inductiveness check, never make clause true.

287

fiSuda

remains least one literal incompatible goal condition g (line 4). still
actions, however, whose reason set subsumed Rnoop look
reason Rnoop (line 11) whenever fail pass inductiveness check (line 7).
avoid confusion remark continue break commands refer innermost cycle, iterates actions (line 6). Finally, note presence small
reason Rnoop depends current value r0 corresponding check
could precomputed outside inner cycle.
Example 3. Recall Example 2, action = ({p, q}, {o, r}) failed state
= {o 7 0, p 7 0, q 7 0, r 7 0} provide successor state would satisfy clauses
L = {o q, p r} computed reason set Ra = {{p}, {q}}. Assume
apart action set contains one action, namely b = ({r}, {p}),
obtain reason set Rb = {{o, q}}. overall reason stage two
thus necessarily r = {o, q}. Assuming goal condition given problem
g = {o, p, q, r}, inductive minimization reason r could proceed follows.
First try reason r0 = {o}. Since eff cannot use inductive argument
action also proper reason ra Ra property ra r0 . Thus
literal q cannot removed r. Next try reason r0 = {q}. Since neither
action b contain literal q effect lists, smaller reason justified
inductively actions overall reason r reduced {q}. cannot minimize
r further, remain least one literal l0 r l g.
Looking perspective final learned clause c = r observe inductive
minimization allows us (as example above) remove c every literal cannot
made true action action set A. Although may seem like powerful
(global) criterion, effectively made redundant practice called relaxed reachability analysis (see Hoffmann & Nebel, 2001, Section 4.3), standard preprocessing step
which, actual search started, removes problem unattainable
variables well actions mention precondition lists. Non-trivial
invocations inductive minimization actually quite rare experiments.
4.3 Replacing Remaining SAT-solver Calls
Beside query extending states, two points formulation PDR
(recall Pseudocode 1 page 275) SAT-solver call employed. used pick
initial states beginning path construction phase (line 4) also central
verifying condition pushing clauses clause propagation phase (line 26).
planning, easily without SAT-solver first case, one
initial state picked, namely state sI , need verify sI satisfies
clauses Lk path construction phase iteration k started.
basically two options deal second case. Since clause pushing
need ensuring correctness PDR, simply leave operation out.
later show experiments, significantly affect performance planning
benchmarks, typically satisfiable. second option, propose restrict
planning formalism query corresponding push check clause c, i.e.,
SAT ?[ c (L)0 ],
288

(6)

fiProperty Directed Reachability Automated Planning

decided polynomial time.12 say STRIPS planning problem positive
precondition list every action goal condition problem consist
positive literals only.13 easy see running positive STRIPS problem,
PDR deals positive clauses. unit clauses layer L0 , describe goal,
positive assumption learned clauses transitively built
goal literals action precondition literals. observation allows us reduce
query (6) evaluation positive part interface path extensions.
Lemma 4. Let P = (X, sI , g, A) positive STRIPS planning problem seq
transition formula sequential encoding SPseq . Further, let L set positive clauses
X, c positive clause X, sc : X {0, 1} state defined every p X
(
0 p c,
sc (p) =
1 otherwise.
following formula
Fc = c seq (L)0
satisfiable action sc |= pre apply(sc , a) |= L.
Proof. Let us first assume action applicable sc
successor state = apply(sc , a) satisfies clauses L. Notice Vars(Fc ) = X
X 0 , = {pa | A} set variables used encoding applied actions.
define following assignment : {0, 1}:
= {pa 7 1} {pb 7 0 | b A, b 6= a}.
easy verify joint assignment (sc t0 ) satisfies Fc .
opposite direction, let us assume assignment V : X X 0 {0, 1}
satisfies formula Fc . fix action
must
W V (pa ) = 1. action
seq
exist, V satisfies at-least-one axiom alo = aA pa , part .
restricting V , first, state variables X, and, second, primed variables X 0 ,
extract, respectively, state = V X state t0 = V X 0 . axioms
seq ensure action applicable = apply(s, a).
notice |= c, means s(p) = 0 every p c. Thus
difference states sc variables p 6 c s(p) = 0
sc (p) = 1. means, one thing, since action applicable s,
must also applicable sc (preconditions positive) and, other, since |= L,
successor state tc = apply(sc , a) corresponding sc must also satisfy clauses L
(the implication p X : s(p) = 1 sc (p) = 1 preserved transition becomes
p X : t(p) = 1 tc (p) = 1 clauses L positive assumption).
12. current setting, seem general polynomial solution. fact, even
degenerate case encoding transition single noop action c empty clause,
query (6) boils satisfiability L evaluation thus NP-complete problem.
13. standard planning benchmarks positive STRIPS. Moreover, well-known reduction (Gazen & Knoblock, 1997) turns general STRIPS problem positive one. reduction
introduces new variable p every variable p occurs negatively precondition goal
updates actions always force p opposite value p.

289

fiSuda

Pseudocode 5 Algorithm PDRplan(X, sI , g, A):
Input:
positive STRIPS planning problem P = (X, sI , g, A)
Output:
plan P guarantee plan exists
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:

L0 {{p} | p g} /* goal cube treated set unit clauses */
foreach j > 0 : Lj
k = 0, 1, . . .
/* Path construction: */
sI |= Lk
Q {(sI , k)}
Q empty
pop (s, i) Q minimal
= 0
return PLAN FOUND
extend(s, Li1 ) returns successor state
Q Q {(t, 1), (s, i)}
else
extend returned reason r Lits(s)
foreach 0 j : Lj Lj {r}
/* Obligation rescheduling: */
< k
Q Q {(s, + 1)}
/* Clause propagation: */
= 1, . . . , k + 1
foreach c Li1 \ Li
/* Clause push check */
sc {p 7 0 | p c} {p 7 1 | p (X \ c)}
every : sc 6|= pre apply(sc , a) 6|= Li1
Li Li {c}
/* Convergence check */
Li1 = Li
return PLAN POSSIBLE

290

fiProperty Directed Reachability Automated Planning

version PDR specialized positive STRIPS planning shown Pseudocode 5.
calls SAT-solver original formulation replaced, respectively, simple
entailment check (line 5), call extend procedure (line 11), enumeration
successor states state sc defined Lemma 4 (line 26).
4.4 Reversing Search Direction
mentioned original formulation PDR based opposite search
direction one described paper extends paths goal state
backwards towards initial state. would like test algorithm directions
see one favorable practice.
One possibility achieve provide PDR inverted version input,
initial goal states swapped transition relation turned
around. straightforward input STS (recall Section 2.3),
case general version PDR. situation complicated SATsolver free version, directly takes STRIPS planning problem input. Indeed,
seems extend procedure substantially relies forward direction.
Interestingly, exists transformation inverting STRIPS planning problems.
first described Massey (1999) dissertation. present streamlined version due Pettersson (2005) relies problem positive. Let us
start introducing alternative representation positive STRIPS planning problems,
makes description transformation particularly straightforward. positive
STRIPS planning problem subset representation given tuple P = (X, i, g, A),
i, g X initial goal conditions, respectively, every action
encoded triple = (pre , add , del ), consisting precondition list, add list
delete list, subsets X pre add = add del = .
subset representation differs one presented Section 2 encoding initial
state set variables true it:
sI (p) = 1 p i,
splitting actions effects positive negative ones:
eff = add {p | p del }.
goal condition g precondition lists pre remain intact, may understood subsets X since problem positive. clear subset
representation one Section 2 equivalent.
Now, action = (pre , add , del ) inverted action a1 formed exchanging
precondition delete list: a1 = (del , add , pre ). set actions set
inverted actions A1 = {a1 | A}. Given planning problem P = (X, i, g, A)
subset representation, inverted problem P 1 obtained exchanging initial
goal conditions taking complements respect X using inverted
action set:
P 1 = (X, (X \ g), (X \ i), A1 ).
original problem inverted version related following sense:
291

fiSuda

Theorem 2. sequence actions a0 , a1 , . . . , ak plan planning problem P
1
1
1 .
sequence a1
k , ak1 , . . . , a0 plan P
means performing forward search (also called progression) P equivalent
performing backward search (regression) P 1 vice versa. Notice that, priori,
computational overhead incurred transformation: inverted problem
number actions well set state variables X representation
states size. proof Theorem 2 along intuition behind
transformation theoretical practical implications described Suda (2013b).
4.5 Improvements
describe three additional modifications PDR aim make algorithm efficient practice. first planning-specific improvement extend procedure,
two focus obligations handled overall algorithm. Section 5
experimentally evaluate effect modifications solving planning problems.
interested reader find pseudocode modifications Appendix A.
4.5.1 Lazy False Clause Computation
One way speed extend procedure practice technique named lazy false
clause computation. based following two observations:
Ls , set clauses false state s, typically small subset L, set
clauses successor state satisfy,
small fraction available actions makes clauses Ls true
respective successor.
idea avoid relatively expensive computation set clauses false
successor t, i.e. computation set Lt line 10 (Pseudocode 3), instead
first look truth value clauses Ls . (Notice Ls precomputed
start iterating actions.) find action
preconditions satisfied makes clauses Ls true respective
successor t, classify action promising go back computing full Lt . Thus,
non-promising actions save computational time. may pay little
side quality reason set, use Ls,t = {c Ls | 6|= c}
instead full Lt computing reasons. hand, promising actions
complete test necessary distinguish true successor satisfying L
action repairs everything false s, breaks something else instead.
4.5.2 Sidestepping
Sidestepping technique propose make PDR active early exploration
promising paths. partially circumvents limitation stemming fact extend
procedure emulates sequential encoding SPseq .
Imagine want extend obligation (s, i), i.e. find successor would
satisfy Li1 , two clauses c1 , c2 Li1 false s. Let us think two clauses
292

fiProperty Directed Reachability Automated Planning

two independent subgoals achieved. two actions a1 a2 applicable
s. Action a1 makes c1 true successor state a2 makes c2 true, action
make clauses true one step. means extension cannot successful
PDR learn new clause c = c1 c2 (or superset thereof). clause c expresses
fact order reach state satisfying Li1 one step, least one two clauses
c1 , c2 must satisfied beforehand. could important ingredient showing
path length k reach goal, helping algorithm eventually advance next
iteration. However, planning usually interested actually finding
plans showing non-existence, deriving clause c could represent unnecessary
extra work. idea behind sidestepping make extend procedure succeed
often, even mean directly advancing next layer. example,
return successor state = apply(s, a1 ) additional flag informing caller
new obligation index usual 1. effectively
sidestepping (s, i) (t, i). next round obligation (t, i) picked
successfully (provided actions a1 a2 interfere) extended (u, 1) via
action a2 . way end state satisfying Li1 almost executed
two actions a1 a2 parallel.
Let us present sidestepping technique detail. order action
respective successor ta = apply(s, a) qualify sidestep extension
obligation (s, i) following conditions must met:
1) applicable s,
2) ta improves respect set satisfied Li1 clauses:

Lti1
= {c Li1 | ta 6|= c} Lsi1 = {c Li1 | 6|= c},

3) ta satisfies Li clauses.
Notice require improvement strict (condition 2). ensures
sidestepping compromise termination. also make sure new state
stays within Li (condition 3) improvement one respect payed
overall deterioration.
action qualifies sidestep, compute return reason set

usual. Otherwise, choose among action size Lti1

ta
smallest. case |Li1 | = 0 corresponds regular successful extension new

obligation (ta , 1) stored set Q. |Lti1
| > 0, store (ta , i) instead,
means perform sidestep.
sidestepping old obligation (s, i) new (ta , i) occupy
index Q. important prioritize latter former picking (e.g.,
even otherwise want use queue tie-breaking strategy; see Section 3.6.4),
prevent algorithm sidestepping way once.14
Notice sidestepping extension PDR relies modification
planning-specific extend procedure. immediate counterpart
original algorithm, path extensions delegated SAT-solver.
14. time (s, i) reconsidered must unsuccessful extension (ta , i), means Li
got meantime strengthened ta longer satisfies it.

293

fiSuda

4.5.3 Keeping Obligations Iterations
Let us return obligation rescheduling (lines 18 19 Pseudocode 5) discuss one
additional aspect feature. Notice reschedule obligation (s, i) < k
new obligation (s, + 1) never positioned goal k steps
iteration k. Obligations form (s, k) simply forgotten ensures
path construction phase eventually terminates. viable alternative strategy
reschedule obligations queue Q index k + 1, set dormant
state return next iteration. understood
effectively enlarging set initial states next iteration includes
states reached far.
Although modification quite simple implement seems go well
spirit obligation rescheduling itself, publicly described yet. potential
disadvantage could increased memory consumption, since states ever encountered run must stored algorithm. utility modification may,
therefore, depend application domain.

5. Experiments
section report series experiments aimed establish practical relevance
PDR automated planning. first compare standard version algorithm
combined encodings SAT-solver free variant PDR proposed paper.
latter implemented new planner PDRplan. Next, measure influence
several design choices mentioned Section 3 well various improvements
proposed Section 4.5 performance PDRplan. successful configuration
PDRplan compared planners, including state art representatives
heuristic search planning planning satisfiability paradigms. Finally, also assess
PDRplan perspective plan quality, finding optimal length plans detecting
unsatisfiable problems.
5.1 Setup
performed experiments machines 3.16 GHz Intel Xeon CPU, 16 GB RAM,
running Debian 6.0. Although multiple cores available machine, planners
used one core made sure busy process running concurrently would compete planner memory, etc. main measured resource
computation time. used time limit 180 seconds per problem instance
runs, increased 1800 seconds main comparison.
increase level confidence towards correctness implementation
generated plans subsequently checked latest version plan validator VAL
(Howey, Long, & Fox, 2004). discrepancies found experiments reported
paper.
tested planners STRIPS15 benchmarks International Planning
Competition (IPC, 2014). far, altogether seven repetitions competition
happening biennially 1998 2008 2011. time planners competed
15. richer ADL formalism currently supported PDRplan.

294

fiProperty Directed Reachability Automated Planning

several benchmark domains various planning scenarios. used available
STRIPS domains except following:
1998-MOVIE, turned technically difficult validate plans.16
Note domain is, fact, trivial solve.
2000-SCHEDULE, originally ADL domain. competition archive contains also STRIPS version, accompanied note saying version later
proved problematic dropped competition.
2002-ROVERS, problems included set 2006-ROVERS.
2002-SATELLITE 2011-TIDYBOT, make use actions negative preconditions, feature supported parser.
Altogether, collected 1561 problems 49 domains (see Table 3 page 304 detailed
list). 2008 2011 competition benchmarks specify action costs. modified
respective files remove feature, supported PDRplan.
implemented PDR extend procedure described Section 4
PDRplan system. code PDRplan (approximately 2K lines C++) built top
PDDL parser grounder adopted SatPlan 2006 (Kautz, Selman, & Hoffmann,
2006). modified parser successfully process large problems recent
IPC domains. source code PDRplan publicly available web page (Suda,
2014), also contains material relevant reproducing experiments.
5.2 PDRplan v.s. Standard PDR plus Encodings
main purpose first experiment compare PDRplan planning-specific
implementation extend procedure composition general PDR, uses
SAT-solver answer one-step reachability queries, various encodings planning
STS. also wanted establish two possible search directions
PDR favorable discovering plans.
took implementation PDR called minireachIC3, originally developed
model checking tool hardware circuits. internally relies SAT-solver Minisat
(Een & Sorensson, 2003) version 2.2. extended minireachIC3 able read
description STS. designed new input format purpose, call
DIMSPEC (Suda, 2013a). simple modification well-known DIMACS CNF
format used SAT-solvers extended define individual clause sets STS.
coupled minireachIC3 four encoders planning STS. first two
encoders, seq par, implementations two simple encoding SPseq SPpar ,
respectively (recall Section 2.6). third encoder version planner Mp (Rintanen,
2012) modified output encoded instance form STS quit starting
actual solving process. Mp uses -step parallel encoding scheme Rintanen et al.
(2006). Finally, fourth encoder implements SASE encoding scheme introduced
16. parser adopted PDRplan removes vacuous arguments operators resulting actions
names. validator VAL complains resulting plans.

295

fiSuda

Huang et al. (2012). particular implementation used derives FreeLunch
planning library (Balyo et al., 2012).
order obtain fair comparison used basic version PDRplan configured
way resembles workings minireachIC3. configuration follows
planning-specific version overall algorithm (Pseudocode 5) relies extend
procedure (Pseudocode 3) minimization phase reason computation (stage
three) enhanced induction (Pseudocode 4). additional improvements Section 4.5
disabled experiment.
compared systems search directions. forward direction, mean
one preferred paper, PDR constructs path initial state towards
goal. opposite, backward direction preferred original exposition PDR
used model-checking. start minireachIC3 backward direction inverted
encoded STS, reverse search direction PDRplan inverted planning problem
(as explained Section 4.4).17
5.2.1 Adding Invariants
invariant transition system property initial state preserved transitions. planning, one typically considers invariants form binary clauses (Rintanen,
1998), computed simple fixpoint algorithm (Rintanen, 2008b). Adding
invariant clauses encoding known speed plan search planning
satisfiability paradigm.
noticed performance PDRplan backward direction also
enhanced help invariants. PDR run backward direction,
sound strengthen every layer binary clauses precomputed invariant.
clauses help guide path construction towards initial state. Adding invariants
forward direction make sense PDRplan, generated states
reachable initial state and, therefore, satisfy invariant automatically.18
used invariant generation algorithm PDRplan also enhance encodings seq par run minireachIC3. turned case minireachIC3
invariants slightly help even forward direction.19 note binary clause invariants also explicitly included Mp encoding implicitly present SASE
encoding, relies SAS+ planning formalism (Backstrom & Nebel, 1995)
STRIPS problem converted help invariants (Helmert, 2009).
5.2.2 Detecting Auxiliary Transition Variables
essential good performance minireachIC3 combined encodings
algorithm make decisions prematurely.
17. One could also experiment encodings inverted problems. leave future work.
18. theory, corresponding notion backward invariant, property goal states preserved
traversing transitions backwards. Symmetrically, backward invariants could used enhance
performance forward PDR. practice, however, standard invariants typically
useful, rarely non-trivial binary clause backward invariant planning benchmarks.
19. explained observing SAT-solver necessarily construct successor state
first choosing action (or set actions, case par), would fully determine
successor. starts deciding state variables successor, invariants become useful.

296

fiProperty Directed Reachability Automated Planning

Example 4. Consider run algorithm forward direction encoding SPseq .
encoding action variables occur unprimed part transition
clauses seq , given state s, assignment = X A, already stores
information action applied next and, therefore, fully determines
value state variables X 0 successor. result, contrary intuition,
evaluation extension query
SAT ?[ Lits(s) seq (L)0 ]
boil choosing action applicable state (s X) original
planning task, successor state would satisfy clauses L, instead
involves choosing action applied already determined successor
successor (as valuation X 0 ) chosen action (as valuation A0 ) together
satisfy clauses (L)0 , which, general, span whole signature 0 . see
that, sense, decisions made one step early.
observed marked improvement performance minireachIC3 combined
encodings extended tool preprocessing step detects auxiliary
transition variables unprimed part transition clauses re-encodes
primed part order avoid committing decisions prematurely demonstrated
example above. Formally, given STS = (, I, G, ), auxiliary transition variables
Aux variables appear G and, primed, shared
0 . means
Aux 0 = 0 \ (Vars(I 0 ) Vars(G0 ) (Vars(T ) Vars(T 0 ))).
action variables SPseq encoding example auxiliary transition variables.
every transition clause c , preprocessing step identifies literals l c
Vars(l) Aux turns l l0 . soundness transformation easy
establish.
5.2.3 Results Experiment
results first experiment found Figure 3. several observations made. foretold, forward direction generally successful
backward. Within time limit 180 seconds, five systems solves problems forward direction backward direction. see backward
direction, invariants help improve performance PDRplan. Nevertheless, within
direction minireachIC3 combined Mp encoding successful.
successful system PDRplan forward direction. solves 8.6 percent problems
second best system, minireachIC3 combined Mp encoding forward
direction. Although consider results definitive answer PDRplan
vs. encodings question,20 decided focus PDRplan forward direction
(most of) subsequent experiments.
overall trends captured Figure 3 time respected comparison performed level individual problem domains (comparing number
20. instance, replacing Minisat minireachIC3 recent efficient SAT-solver could
change picture certain degree.

297

fiSuda

1400

1000

minireachIC3(seq)
minireachIC3(par)
minireachIC3(SASE)
minireachIC3(Mp)
PDRplan

1200

problems solved

1200

problems solved

1400

minireachIC3(seq)
minireachIC3(par)
minireachIC3(Mp)
minireachIC3(SASE)
PDRplan+i
PDRplan

800
600

1000
800
600

400

400

200

200

0

0
1

10
time (seconds)

100

1

10
time (seconds)

100

Figure 3: Comparing PDRplan minireachIC3 combined encodings. Number
problems solved within given time limit shown, separately backward
direction (left) forward direction (right).

problems solved 180 seconds), nevertheless notable exceptions worth
mentioning.
LOGISTICS domain PDRplan behaves better backward direction
without invariants. best system domain, however, minireachIC3
Mp encoding forward direction.
relatively difficult 2011-BARMAN domain almost fully solved (19 20
problems) PDRplan backward direction invariants. second best
system domain minireachIC3 par encoding backward direction
7 problems solved.
following among domains PDRplan best system: 1998MYSTERY (minireachIC3 SASE Mp encodings forward direction
solve 5 problems more), 2004-PHILOSOPHERS (18 problems solved
minireachIC3 par Mp encodings forward direction), 2011VISITALL (minireachIC3 Mp encoding solves 4 problems).
several domains minireachIC3 Mp encoding better
backward direction forward direction. difference pronounced
2006-OPENSTACKS, 2011-FLOORTILE.
observation last point accord Mp encoding used
Mp planner itself. Rintanen (2012) describes effectively depth-first backward
chaining planning algorithm inside SAT-solving framework. seen
298

fi1200

1200

1100

1100
problems solved

problems solved

Property Directed Reachability Automated Planning

1000
900
800
ind_off
min_off
default

700
600
1

10
time (seconds)

1000
900
800
700
cp_off
queue
default

600
500
100

1

10
time (seconds)

100

Figure 4: Tuning PDRplan. effect explicit (inductive) reason minimization (left),
clause propagation queue tie-breaking strategy (right).

close backward PDR coupled encoding. hypothesize
suitability Mp encoding backward direction search emerges also PDR.
5.3 Tuning PDRplan
second experiment (see Figure 4) focused several features standard
PDR tried established importance solving planning problems. used
PDRplan forward direction 180 seconds time limit. measured effect
feature separately reference configuration denoted default.
configuration one used previous experiment.
5.3.1 Explicit (Inductive) Reason Minimization
explicit minimization mean optional stage three reason computation
extend procedure, enhanced induction described Section 4.2.
Figure 4 (left) compare performance default configuration, relies
inductive version reason minimization (Pseudocode 4), configuration ind off,
use induction implements minimization described Pseudocode 3,
configuration min off, skips optional stage three altogether.
see positive effect explicit minimization slight consistent
along time axis, induction starts pay global scale time limit
exceeds 100 seconds. 180 seconds mark ind configuration solved 1.0 percent
fewer min configuration 2.4 percent fewer problems default.
Per domain view reveals induction especially important success 2000BLOCKS, 2004-PHILOSOPHERS, 2008-CYBER-SECURITY. domains
2002-ZENOTRAVEL 2008-TRANSPORT better turn minimization completely,
also domains, 1998-MYSTERY 2006-TRUCKS, pays
minimize, inductively. last two categories, however, difference never
299

fiSuda

problem two per domain thus could potentially equalized within
higher time limit.
Interestingly, total 1561 problems, execution default ind
diverged 145 problems.21 means problems induction
help minimize reasons beyond achieved non-inductive minimization.
give another statistics, note whole problem set call
extend procedure inductive minimization removes 1.49 literals computes reason
50.60 literals average. non-inductive minimization min removes 1.44 literals
generates reason 51.22 literals average.
5.3.2 Clause Propagation
Figure 4 (right) compare default configuration configuration
clause propagation turned (cp off). see clause propagation slows PDRplan slightly without clear benefit 180 seconds mark. Although later
independent experiment 1800 second time limit showed clause propagation
useful planning problems, questionable whether effect justifies relatively
high effort connected implementing technique.22
closer look reveals 28 percent tested problems clause successfully pushed forward 180 seconds bounded runs. may seem
contrast experience hardware model checking clause propagation plays
key role. main effect there, however, lies speeding convergence PDR
unsatisfiable problems. Since 99 percent planning benchmarks satisfiable, role clause propagation cannot demonstrated. fact, also independently
confirmed experiment minireachIC3 satisfiable hardware benchmarks23
clause propagation beneficial forward direction.
5.3.3 Stack vs. Queue Tie-breaking
evaluate effect strategy breaking ties popping obligations
set Q (see Section 3.6.4). stack strategy used default configuration
compared curve queue strategy Figure 4 (right). queue strategy
solves 5.9 percent fewer problems total. However, 18 problems solved
queue strategy (and 85 problems solved stack strategy).
interesting observations per domain scope probably
59 problems (out 60) 2000-BLOCKS domain solved stack strategy
compared 36 solved queue strategy,
2 problems (out 20) 2011-BARMAN domain solved queue strategy
compared 0 problems solved stack strategy.
21. either generating different number obligations successful termination differing
whether successfully terminated 180 seconds mark.
22. final comparison planners (see Section 5.5) clause propagation responsible 6 additional problems scored PDRplan.
23. benchmarks Hardware Model Checking Competitions 20072012 (Biere, Heljanko, Seidl, &
Wieringa, 2012) time limit 100 seconds.

300

fiProperty Directed Reachability Automated Planning

1300
1 = default
2 = 1 + lfcc
3 = 2 + side
4 = 3 + keep

1200

problems solved

1100
1000
900
800
700
600
1

10
time (seconds)

100

Figure 5: Improving PDRplan. default configuration progressively extended turning three different techniques.

Preferring explore longer paths short ones unpleasant side effect
also plans discovered stack strategy tend longer. Measured 1055
problems solved strategies, plans generated stack strategy average
24 percent longer.
detailed discussion topic plan quality postponed till Section 5.6.
5.4 Improving PDRplan
purpose third experiment evaluate three improvements proposed
Section 4.5. successively: 1) lazy false clause computation (lfcc), 2)
sidestepping technique (side), 3) keeping obligations iterations (keep). Figure 5
displays effect progressively enabling three techniques presented order.
see varying degrees technique represents improvement successive
configuration solves problems.
different perspective provided Table 2 also reveals many problems
uniquely solved one two successive configurations. shows none
improvements unambiguous across whole problem set
exceptions prevailing trends.
best highlighted level individual domains. instance,
number solved problems drops 2000-BLOCKS 2008-CYBER-SECURITY
lazy false clause computation (configuration 2), improved subsequently
enabled techniques. Sidestepping (configuration 3) makes performance worse 2002DRIVERLOG, 2004-SATELLITE, 2008-CYBER-SECURITY. hand,
technique represents huge improvement 2004-OPTICAL-TELEGRAPH domain
301

fiSuda

configuration
1 = default
2 = 1 + lfcc
3 = 2 + side
4 = 3 + keep

total
1145
1180
1195
1212

delta

35
15
17

gained

55
67
42

lost

20
52
25

Table 2: Number problems solved within 180 seconds (total). difference (delta) two successive configurations decomposed additionally solved problems
(gained) problems solved without improvement (lost).

1500
1400

problems solved

1300
1200
1100
1000
900
800
700

FF
LAMA-2011
Mp
PDRplan1.1

600
500
1

10

100
time (seconds)

1000

Figure 6: Comparing final version PDRplan planners. Showing number
problems solved within given time limit.

(from 2 14 problems solved) 2004-PHILOSOPHERS (from 11 29 problems
solved). Finally, keeping obligations (configuration 4) detrimental performance
2011-FLOORTILE domain (the number solved problems drops 19 13),
technique, example, helps recover 2008-CYBER-SECURITY problems
lost due sidestepping.
5.5 Comparing Planners
compared improved PDRplan configuration 4 previous experiment
denoted PDRplan1.1 following planners:
planner FF (Hoffmann & Nebel, 2001) baseline representative heuristic
search (Bonet & Geffner, 2001) planners. used version 2.3, enhanced input
302

fiProperty Directed Reachability Automated Planning

module make cope large problems recent IPC domains.
default parameters FF used.
planner Fast Downward (Helmert, 2006), current state art heuristic
search planner. used configuration LAMA-2011 (Richter & Westphal, 2010),
winner satisficing track IPC 2011.
Mp planner (Rintanen, 2012), probably current best representative
planning satisfiability approach (Kautz & Selman, 1996). used version 0.99999
default parameters.
experiment time limit increased 1800 seconds.
overall performance planners seen Figure 6. planner FF
fast startup solves problems (952) within one second. However, FF
worst planners make use additional time solves fewest problems
(1247) total. opposite side stands LAMA-2011 slowest startup (566
problems within one second), best total (1437). PDRplan1.1 Mp close
performance beginning PDRplan1.1 solves 741 Mp 790
problems within one second end total PDRplan1.1 solves 1333 problems
gaining slight edge Mp 1310 problems solved.
Table 3 shows domain-by-domain decomposition results. see
several domains PDRplan1.1 solved problems four planners, namely 2000-BLOCKS, 2002-FREECELL, 2004-PIPESWORLD-NOTANKAGE,
2006-TRUCKS domains. domains 2004-PHILOSOPHERS, 2006-PATHWAYS,
2006-STORAGE completely solved PDRplan1.1 Mp. hand, comparatively poor performance PDRplan1.1 observed 1998-LOGISTICS
1998-MPRIME domains, also 2011-PARKING (shared FF) 2008+2011SOKOBAN (shared Mp) domains.
5.6 Plan Quality
IPC 2008 (Helmert, Do, & Refanidis, 2008) introduced criterion measuring planner
performance takes account quality obtained plans. every problem
solved, planner aggregates score computed ratio c /c, c cost24
returned plan c cost best known plan (either plan computed beforehand
competition organizers best plan found participating systems).
viewing results previous experiment lenses criterion,
one discovers PDRplan1.1 drops second place last.
reviewed previously discussed features improvements discovered
configuration PDRplan1.1 best possible respect plan quality.
particular, switching queue tie-breaking strategy (we denote respective
configuration PDRplan1.1+queue) aggregated score planner improves. slight
24. mentioned before, consider action costs paper, so, setting, cost plan
simply equal length.

303

fiSuda

1998-GRID
1998-GRIPPER
1998-LOGISTICS
1998-MPRIME
1998-MYSTERY
2000-BLOCKS
2000-ELEVATOR
2000-LOGISTICS
2000-FREECELL
2002-DEPOTS
2002-DRIVERLOG
2002-ZENOTRAVEL
2002-FREECELL
2004-AIRPORT
2004-PIPESWORLD-NOTANKAGE
2004-PIPESWORLD-TANKAGE
2004-OPTICAL-TELEGRAPH
2004-PHILOSOPHERS
2004-PSR
2004-SATELLITE
2006-OPENSTACKS
2006-PATHWAYS
2006-PIPESWORLD
2006-ROVERS
2006-STORAGE
2006-TPP
2006-TRUCKS
2008-CYBER-SECURITY
2011-BARMAN
2008+2011-ELEVATORS
2011-FLOORTILE
2011-NOMYSTERY
2008+2011-OPENSTACKS
2008+2011-PARCPRINTER
2011-PARKING
2008+2011-PEGSOL
2008+2011-SCANALYZER
2008+2011-SOKOBAN
2008+2011-TRANSPORT
2011-VISITALL
2008+2011-WOODWORKING
TOTAL

size
5
20
35
35
30
60
150
36
60
22
20
19
20
50
50
50
14
29
50
36
30
30
50
40
30
30
30
30
20
50
20
20
50
50
20
50
50
50
50
20
50
1561

PDRplan1.1
5
20
18
25
19
60
150
36
57
21
18
19
20
40
45
37
14
29
50
28
30
30
32
39
30
30
27
30
6
40
14
14
49
50
8
50
46
11
27
9
50
1333

FF
5
20
35
34
18
48
150
36
60
21
18
19
19
38
32
17
14
14
42
34
30
20
21
40
18
28
12
4
0
50
10
7
50
50
7
50
44
40
38
4
50
1247

LAMA-2011
5
20
35
35
23
55
150
36
60
22
20
19
19
33
44
42
14
13
50
36
30
29
40
40
19
30
15
30
20
50
6
10
50
50
20
50
50
48
49
20
50
1437

Mp
5
20
32
34
19
46
150
36
44
22
20
19
15
49
42
38
14
29
50
35
19
30
25
40
30
30
19
30
8
50
20
19
18
50
20
50
48
9
26
0
50
1310

Table 3: Number problems solved within 1800 seconds, grouped domain. highlighted entries PDRplan1.1 solves problems shares
first place one planner. save space entries IPC 2008 domains
recurring later IPC 2011 merged respective entries IPC 2011.

304

fiProperty Directed Reachability Automated Planning

1300
1200

aggregated score

1100
1000
900
800
700

FF
LAMA-2011
Mp
PDRplan1.1
PDRplan1.1+queue

600
500
1

10

100
time (seconds)

1000

Figure 7: Comparing planners respect plan quality. Showing score aggregated planner within given time limit.

improvement also observed lazy false clause computation turned
PDRplan1.1. Interestingly, changes bring combined benefit.25
Figure 7 shows aggregated scores runs previous experiment together
run PDRplan1.1+queue.26 Although PDRplan1.1+queue solves 1263 problems
1800 seconds (compared 1333 solved PDRplan1.1), aggregates score 1141.1
points PDRplan1.1 reaches 1041.4. means former configuration catches
Mp, aggregates 1102.7 points.
note statistics taken grain salt,
provide plan quality view satisficing runs planners. None systems
explicitly attempting find short plans making use fact time limit
1800 seconds. Moreover, even setting plan quality typically improved
afterwards post-processing discovered plans (Balyo & Chrpa, 2014). later
incorporated polynomial Action Elimination algorithm (Nakhost & Muller, 2010)
plan post-processor PDRplan1.1 able improve aggregated score
7.0 percent. thorough investigation quality plans produced PDRplan,
well PDR general, left future work.

25. seems already carefully advancing PDRplan1.1+queue benefits speed provided
lazy false clause computation, whereas stack strategy helps wait precise
reasons (having lfcc turned off) allow planner search deep often.
26. reference values best known cost c collected runs figure.

305

fiSuda

5.7 Anytime PDR Optimal Planning
Recall PDR adjusted perform optimal planning turning obligation
rescheduling technique (and sidestepping).27 Alternatively, modify PDR continue
computation first plan found, afterwards reschedule obligations
part improving plan.28 anytime version PDR progressively reports
better better solutions finally terminating guarantee last reported
plan optimal one. happens reaches iteration equaling length
best discovered plan.
experiment focused optimal planning respect sequential plan
semantics.29 compared performance anytime version PDRplan1.1 (counting
solutions provably shown optimal) BJOLP (Domshlak et al., 2011), optimizing version Fast Downward, optimizing configuration Mp.30 Ordering
planners number problems optimally solved within 1800 seconds obtain:
1. BJOLP 668 problems solved,
2. PDRplan1.1-anytime 360 problems solved,
3. optimizing Mp 325 problems solved.
order preserved level individual domains, except several domains
Mp end last. Mp solves optimally problems 1998-MYSTERY,
2000-BLOCKS, 2008-CYBER-SECURITY, also 1998-MPRIME domain.
margin exceptionally pronounced last domain, Mp solves 32 35
problems, BJOLP solves 21 PDRplan1.1-anytime 20 problems.
5.8 Detecting Unsatisfiable Problems
Although main focus planning community, reflected International
Planning Competition, traditionally satisfiable problems only, recently,
importance detecting unsatisfiable instances getting recognized addressed
(Backstrom, Jonsson, & Stahlberg, 2013; Hoffmann, Kissmann, & Alvaro Torralba, 2014).
According experience hardware model checking, PDR particularly
strong detecting unsatisfiable instances. last experiment, tried established
whether also holds planning.
test problems, used collection Hoffmann et al. (2014) consisting 8
domains total 183 unsatisfiable benchmarks. Table 4 shows domain-by-domain
coverage results (for time limit 1800 seconds) following configurations PDR:
27. PDR looks minimal length witnessing paths respect encoded transition relation .
Using encoding sequential plan semantics (as implicitly done PDRplan) ensures optimizing
number actions resulting plan.
28. Formally, keep obligation (s, i) length path initial state sI plus value
index exceed length best plan found far.
29. choice ruled systems like SatPlan (Kautz et al., 2006) SASE (Huang et al., 2012)
comparison, optimize respect parallel plan semantics.
30. uses sequential encoding (option -P 0), skip horizon length (option -S 1), evaluates
single horizon length time (option -A 1).

306

fiProperty Directed Reachability Automated Planning

size
3UNSAT
Bottleneck
Mystery
UnsNoMystery
UnsPegsol
UnsRovers
UnsTiles
UnsTPP
Total

25
30
9
25
24
25
20
25
183

PDRplan
fwd bwd
10
10
19
24
4
9
12
11
14
8
11
11
0
0
5
6
75
79

minireachIC3 par
fwd bwd noind nocp
11
15
11
5
25
23
20
22
9
9
9
9
3
13
13
6
14
8
8
4
11
20
15
12
0
0
0
0
4
6
3
3
66
94
79
61

blind
15
10
2
0
24
0
10
5
66

M&S
cf1 cf2
15
15
10
21
9
6
25
25
24
24
17
9
10
10
9
9
119 119

Table 4: Unsatisfiable benchmarks. Number problems solved within 1800 seconds,
grouped domain. Best scores per domain typeset bold.

PDRplan, configuration first experiment (Section 5.2),
forward (fwd) backward (bwd) direction.
minireachIC3 combined par encoding (with invariants), also directions (fwd, bwd), and, backward direction, also inductive minimization
replaced non-inductive version (noind), and, independently, clause
propagation turned (nocp).
addition, Table 4 also contains entries adopted work Hoffmann et al. (2014).
belong Fast Downward planner equipped three different heuristics:
Configuration blind uses heuristic returns 0 goal states 1 elsewhere
essentially proves unsatisfiability enumerating reachable states.
Configuration cf1 cf2 use version merge-and-shrink (M&S) heuristic
(Helmert, Haslum, & Hoffmann, 2007), specifically adapted detecting unsatisfiable
problems (Hoffmann et al., 2014). two best performing configurations
experiment Hoffmann et al. (2014).
note Hoffmann et al. (2014) also used time limit 1800 seconds, ran
experiment 2.20 GHz Intel E5-2660 machines 4 GB memory limit. means
last three configurations could potentially solve problems setup.
5.8.1 Results Experiment
comparing various configurations PDR, see backward direction generally successful forward, although consistently across
domains. Interestingly, minireachIC3 par encoding backward direction
solves problems PDRplan. fact, preliminary test lower time limit
showed benchmarks configuration strongest considered
first experiment (Section 5.2). Finally, also see induction clause
propagation consistently helpful solving unsatisfiable problems.
307

fiSuda

PDR come winner comparison heuristic approach
Hoffmann et al. (2014), although able solve problems four domains.
two domains, however, PDR even dominated blind search, i.e. simple state
space enumeration. seems benchmarks needed establish
two approaches generally successful detecting unsatisfiable planning problems.
5.8.2 Performance UnsTiles
PDR particularly bad enumerating states little possibility generalize
encountered ones. manifested clearly UnsTiles domain,
PDR could solve single problem within given time limit. domain
represents well known sliding puzzle contains 10 problems 8 tiles 3 3
grid 10 problems 11 tiles 3 4 rectangular grid.31 ran PDRplan
forward direction end one smaller, 3 3 instances. took day
complete, processed 701704 obligations terminated clauses layer
11, total 181440 clauses, pushed layer 12 clause propagation phase
iteration 11.
Notice 181440 = 9!/2 half size state space. classical result
Johnson Story (1879), state space sliding puzzle decomposes exactly
two connected components depending value certain parity function defined
states. Unsatisfiable instances parity initial state
goal state different. state space consists two components,
unsatisfiable instance PDR must converge (with repeating layer) CNF description
component containing goal state. see, description large (in
number clauses) component (in number states), thus
sliding puzzle PDR benefit symbolic representation via CNF.
5.9 Summary
Let us summarize empirical findings obtained section. state general
claims keeping mind are, fact, derived performance two
particular benchmark sets: main set 1561 mostly satisfiable IPC problems
set 183 unsatisfiable problems used last experiment.
planning PDR pays look plan initial state towards
goal vice versa. words, progression preferable regression
PDR. holds even invariants employed, help improve
performance regression considerably.
Unsatisfiable instances, however, typically better detected via regression.
satisfiable problems SAT-solver free variant PDR planning-specific
extend procedure (as described Section 4) generally successful
standard version algorithm combined various encodings.
31. famous 15 tiles puzzle 4 4 grid (Wikipedia, 2014).

308

fiProperty Directed Reachability Automated Planning

Neither clause propagation inductive minimization, two techniques normally deemed essential performance PDR, helpful satisfiable
planning problems. techniques are, however, useful detecting unsatisfiability.
various ways tuning PDR improving performance planning.
tried identify configuration algorithm would successful
setup later used PDRplan comparison planners.
techniques turned improvement average, however,
exceptions form individual problems domains performance degraded.
represent interesting opportunity future investigations (see Section 7).32
compared planners PDRplan shows respectable performance. fact,
performance comparable even slightly better planner Mp,
state art representative planning satisfiability approach. also solves
problems tested planners several domains. Although PDRplan
reach score LAMA-2011, presented results quite encouraging,
especially given PDR relatively young algorithm potential
improvements.
plan quality important number problems solved,
pays switch stack queue tie-breaking strategy PDR.
configuration able keep improve upon performance Mp
respect plan quality metric based aggregated score.
Another option improving plan quality employ post-processing step
attempts remove redundant actions generated plan (Balyo & Chrpa, 2014).
PDR easily modified look increasingly better solutions given sufficient time eventually terminate optimality guarantee (with respect
plan length). Although LAMA-2011 much successful finding optimal plans,
fact PDRplans natural encoding follows sequential plan semantics could
reason PDRplan scores higher Mp respect.

6. Related Work: Graphplan
shown paper PDR algorithm closely related planning
satisfiability approach, although planning-specific implementation extend
procedure explicit encoding present. also highlighted connection heuristic
search planning, direct correspondence side explicitly explored reachable
states little subtle one side guiding layers, seen
continually refined admissible heuristic estimator. would like discuss
perhaps surprising relation PDR well-known Graphplan planning algorithm
Blum Furst (1997).
32. one hand, looking problems particular technique leads poor performance,
identify weak points attempt improve technique. hand, instead
relying overall best configuration also try decide prior running algorithm
promising set enabled features given problem based problems characteristics.

309

fiSuda

main data structure Graphplan planning graph, layered structure compressed representation reachability information given problem. individual
layers graph over-approximate set states reachable given number sets
parallel actions computed incrementally propagation called exclusion
relations actions state variables. planning graph searched plan
backward-chaining strategy, starting goal set regressing it, sense
parallel plan semantics, subgoals violate exclusions respective
layer. Candidate (sub)goal sets shown lead plan within specific number
steps memoized avoid repeating work future.
already shown Rintanen (2008a) exclusion relations planning graph
equivalent binary clause representation k-step reachability information. means
could represented inside PDR binary clauses respective layers. claim
additionally also memoized goal sets could stored layer clauses respective position: clause simply negation conjunctive description
goal set. two observations mind, state
Graphplan essentially version PDR specific implementation
extend procedure based parallel plan semantics.
correspondence allows us highlight differences two algorithms beyond preferred semantics emulated encoding.
planning graph built systematically Graphplan search plan
started (resumed) full new layer computed, PDR layer
construction lazy, triggered unsuccessful path extensions.
Goal set memoization Graphplan, however, follows lazy pattern.
Graphplan attempt reduce size memoized goal set, so, apart
binary clauses, deals long clauses representing negation
goal set. Notice would PDR correspond returning full reason set
Lits(s) unsuccessful extension state s.
subset memoization later proposed Long Fox (1999), corresponds finding smaller reason sets.
Graphplan searches plan backward direction. PDR, direction
changed, forward successful.33
equivalent obligation rescheduling Graphplan algorithm
always searches optimal plans (with respect parallel plan semantics).
wavefront heuristic described Long Fox (1999) enhancement
Graphplan, however, seems overcome limitation, similarly rescheduling.
realization PDR related Graphplan made us curious differences
two algorithms practice. set small experiment compared PDR
33. Changing search direction Graphplan running inverted problem (see Section 4.4)
possible, would likely lead fewer problems solved. related already mentioned
observation problems non-trivial backward invariants benchmark set.

310

fiProperty Directed Reachability Automated Planning

mature implementation Graphplan within planner IPP (Koehler, 1999).
order bring PDR close possible Graphplan does, represented
minireachIC3 combined simple parallel encoding SPpar (see Section 2.6) enhanced
binary clause invariant (as explained Section 5.2). ran minireachIC3
backward direction obligation rescheduling turned off, so, similarly IPP,
looking optimal plans. measuring number problems solved (out
main problem set described Section 5) within 180 seconds, obtained 466 solved IPP
484 configuration minireachIC3. noted IPP erroneously
reports UNSAT problems PARCPRINTER WOODWORKING
domains counted failures. minireachIC3, hand, solves
problems domains, score lowered 94 problems
obtain fair comparison problem set excludes two domains.
Notice performance IPP 466 solved problems quite low compared
best configuration PDRplan1.1, solves 1212 problems within 180 seconds.
raises question whether Graphplan could improved enhancing
obligation rescheduling trick. able confirm experimentally. relatively
straightforward modification IPP retries candidate goal set time + 1
failed time able solve 676 problems.34 Thus obligation rescheduling
seen answer long standing question posed last remark original
Graphplan paper Blum Furst (1997), i.e., way trade plan quality speed.

7. Discussion: Closer Look Two Domains
fact PDR maintains reachability information organized layers uses
simple language propositional clauses (CNF) express corresponding constraints
often allows us obtain additional insights algorithm traverses search
space inspecting layers generated concrete problems. especially rewarding
cases PDR seems struggling relatively simple problem, often
leads discovery ideas future improvements. section closer look
behavior PDR two simple domains. conjecture algorithm could
improved employing expressive constraint formalism CNF.
7.1 1998-LOGISTICS
task LOGISTICS domain transport packages locations. Locations
belong cities within city trucks may used move packages help
load-truck, drive-truck, unload-truck actions. Additionally, locations
designated airports airplanes may used transport packages airports
possibly across cities via load-airplane, fly-airplane, unload-airplane actions.
Although LOGISTICS domain generally considered simple one, Table 3
(page 304) reveals relatively poor performance PDRplan LOGISTICS problems.
two initial findings inspection layer clauses generated PDR,
shed light going hood.
34. Also performance corresponding configuration minireachIC3 goes mentioned
484 733 solved problems within 180 seconds obligation rescheduling turned on.

311

fiSuda

PDR often generates long clauses.

typically many distinct (although similar) ways achieve subgoal
need taken account, large reason sets computed
subsequently long clauses derived. example, package needs transported
one city another, available airplanes potentially used
purpose. often encounter derived clauses like
subg at(apn 1 , apt) at(apn 2 , apt) . . . at(apn n , apt)

(7)

expressing subgoal subg derived yet, least one
available airplanes apni need present airport apt.
PDR generates many similar clauses.

Even action one precondition false current state, one
preconditions reflected computed reason unsuccessful extension.
Thus many actions available achieving subgoal, sometimes many clauses
needed PDR tries find right achieving action satisfy preconditions.
addition clause (7) could see PDR subsequently derive following
clauses layer:
subg in(obj , apn 1 ) at(apn 2 , apt) . . . at(apn n , apt),

subg at(apn 1 , apt) in(obj , apn 2 ) . . . at(apn n , apt),
...

(8)

subg at(apn 1 , apt) at(apn 2 , apt) . . . in(obj , apn n ).
Note although pattern indicates n different clauses, worst
case 2n clauses potentially derivable arbitrary choice at(apn , apt)
in(obj , apn ) every i.
Although far described PDR algorithm based propositional logic,
believe could generalized take advantage first order constraints. Consider
clause (7) above. equivalent first order version (aware type airplane) would read
subg Apn airplane . at(Apn, apt),
much succinct.35 Moreover, could potentially derived analyzing
action schemes unload -airplane(Obj , Apn, Loc), . . . , etc., instead iterating
much larger set instantiated actions. Working missing details interesting
direction future research. inspiration could found work Ranise (2013),
whose setting security policy analysis close automated planning.
Another independent direction enhancing expressive power used constraints
could introduction conjunctive literals. Notice set clauses (8) is,
fact, subsumed single generalized clause
subg

n
_
i=1

in(obj , apn ) at(apn , apt),

35. Symbols starting uppercase letter, like Apn, stand first order variables.

312

fiProperty Directed Reachability Automated Planning

allow conjunctions place single literals. envisioned generalization
PDR, conjunctions would naturally come precondition lists actions,
use could help solving, e.g., LOGISTICS problems efficiently. course,
details would need worked out.
7.2 1998-GRIPPER
GRIPPER simple domain models robot two grippers trying move
balls one room another. domain fully solved PDRplan default
configuration. fact, although individual problems differ size, PDRplan able
(thanks obligation rescheduling) solve iteration 3 main loop.36
reason seems virtual independence individual goals,
considered one one PDR. conjecture algorithm solves problems
GRIPPER domain polynomial time.
Despite simplicity, GRIPPER known difficult solve optimally heuristic
search planners (see Helmert & Roger, 2008). also holds PDR, exhibits
exponential behavior attempting find minimal length plan, i.e., run
obligation rescheduling (and sidestepping) turned off. demonstrate reason, let us
abstract simplify GRIPPER bit consider domain task
achieve n independent goals set {g1 , . . . , gn }, achieving particular goal
trivial, individual goals achieved one one.
domain, PDR eventually need express via layer Li least (n i)
goals already achieved. counting constraint inherently large clausal
description. Namely, set Li takes form
^
gj0 . . . gji ,
conjunction ranges (i + 1)-element subsets {j0 , . . . , ji } {1, .. . , n}.
n
size layer Li is, therefore, proportional binomial coefficient i+1
, which,
particular, means size layer Lbn/2c grows exponentially n.
already suggested Helmert Roger (2008) phenomenon could overcome
exploiting symmetries (Fox & Long, 1999) inherently present problem. could
particularly rewarding PDR, layer clauses (although derived response
unsuccessful extensions arbitrary reachable states) logically depend goal
condition G, symmetries typically reside. Thus unlike Fox Long (1999),
define symmetric objects indistinguishable one another
terms initial goal configuration, one could PDR use stronger notion
symmetry derived goal condition only.

8. Conclusion
paper examined PDR, novel algorithm analyzing reachability symbolic transition systems, perspective automated planning. main contribution lies recognizing part algorithms work normally delegated
36. domains fully solved PDRplan particular fixed iteration 2002-ZENOTRAVEL
(iteration 3), 2004-PHILOSOPHERS (iteration 6), 2006,2008,2011-OPENSTACKS (iteration 4).

313

fiSuda

SAT-solver can, context planning, implemented directly polynomial time
procedure. experimentally confirmed modification, well several
proposed improvements, boost performance PDR planning benchmarks.
implementation algorithm called PDRplan able compete respectably
state art planners, solving problems several domains.
Despite already promising results, still room development. One
direction work extending PDRplan towards richer planning formalisms. example,
believe extend procedure enhanced cope conditional effects actions
straightforward way. Efficiently dealing action costs domain axioms could turn
difficult. Another promising direction idea generalize PDR
expressive constraint language CNF. clear stronger constraints
imply better guidance towards goal, devising efficient method combining new
constraints old ones obviously challenging task. seems, however,
departure beyond clausal level could simpler solution inside planningspecific framework extend procedure it, perhaps, within general purpose
constraint solvers.

Acknowledgments
thank Jussi Rintanen useful comments remarks, well help
Mp encoder. also thank Tomas Balyo providing us SASE encoding
tool. Finally, want thank anonymous reviewers insightful suggestions
Malte Helmert help preparation final version text.
research partially supported Czech Science Foundation project
P103-10-1287.

Appendix A. Pseudocode Improvements Section 4.5
Pseudocode 6 displays stage one procedure extend+ , enhancement extend
procedure lazy false clause computation technique (Section 4.5.1) support
sidestepping (Section 4.5.2). Stage two extend+ meant supplemented
stage original extend procedure (Pseudocode 3) stage three employes
inductive minimization described Section 4.2 (Pseudocode 4).
Pseudocode 7 details workings PDRplan1.1. help extend+ procedure realizes sidestepping (Section 4.5.2). Moreover, incorporates technique
keeping obligations iterations (Section 4.5.3). clause propagation phase
identical one already presented Pseudocode 5.

314

fiProperty Directed Reachability Automated Planning

Pseudocode 6 Stage one extend+ (s, i):
Input:
Obligation (s, i), i.e. state index i, 6|= Li1
Output:
Either obligation (t, 1) successor |= Li1 ,
obligation (t, i) successor s, |= Li
satisfies strictly clauses Li1 s,
inductive reason r Lits(s)
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:

Ls {c Li1 | 6|= c} /* Clauses false */
Rnoop {c | c Ls } /* reasons noop action */
assert Rnoop 6= /* Follows contract caller */
R {Rnoop } /* set reason sets collected far */
aside noop /* Current best candidate sidestepping (noop dummy value) */
xside |Ls | /* Score current best candidate */
foreach
pre sa {l pre | 6|= l} /* Preconditions false */
apply(s, (, eff )) /* Ignore preconditions apply effects */
Ls,t {c Ls | 6|= c} /* lazy approach: clauses false */
Ls,t = Ls /* improvement */
continue /* nothing: reason set would subsumed Rnoop */

14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:

pre sa = |Ls,t | < xside /* action promising . . . */
Lt {c Li1 | 6|= c} /* . . . must compute full Lt */
Lt =
return (t, 1) /* positive part: returning true successor */
Lt = Ls,t |= Li /* false clauses besides Ls,t */
aside
xside |Ls,t |
else
Lt Ls,t /* Save time using Ls,t instead full Lt */
Lt0 {c Lt | c pre sa = } /* False clauses non-subsumed reason */
Ra {{l} | l pre sa } {{l | l c l 6 eff } | c Lt0 }
R R {Ra } /* Record reason set */

xside < |Ls |
30:
assert aside 6= noop
31:
return (apply(s, aside ), i) /* Successfully sidestepping best candidate */
29:

32:

/* Continue stage two Pseudocode 3 stage three Pseudocode 4 */

315

fiSuda

Pseudocode 7 Algorithm PDRplan1.1(X, sI , G, A):
Input:
positive STRIPS planning problem P = (X, sI , g, A)
Output:
plan P guarantee plan exists
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:

L0 {{p} | p g} /* goal cube treated set unit clauses */
foreach j > 0 : Lj
Q {(sI , 0)}
k = 0, 1, . . .
/* Path construction: */
(s, i) Q k
pop (s, i) Q minimal
6|= Li
Q Q (s, + 1)
else = 0
return PLAN FOUND
else extend+ (s, i) returns obligation (t, j)
assert j = 1 j = /* Either regular extension sidestep */
Q Q {(s, i), (t, j)}
else
extend+ returned reason r Lits(s)
foreach 0 j : Lj Lj {r}
/* Obligation rescheduling: */
Q Q {(s, + 1)} /* Keep obligations + 1 > k till next iteration */
/* Clause propagation: */
= 1, . . . , k + 1
foreach c Li1 \ Li
/* Clause push check */
sc {p 7 0 | p c} {p 7 1 | p (X \ c)}
every : sc 6|= pre apply(sc , a) 6|= Li1
Li Li {c}
/* Convergence check */
Li1 = Li
return PLAN POSSIBLE

316

fiProperty Directed Reachability Automated Planning

References
Backstrom, C., Jonsson, P., & Stahlberg, S. (2013). Fast detection unsolvable planning
instances using local consistency. Helmert, M., & Roger, G. (Eds.), SOCS. AAAI
Press.
Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. Computational
Intelligence, 11, 625656.
Balyo, T., Bardiovsky, V., Dvorak, F., & Toropila, D. (2012). Freelunch planning library.
Available http://ktiml.mff.cuni.cz/freelunch/.
Balyo, T., & Chrpa, L. (2014). Eliminating redundant actions plans using SAT
MaxSAT. ICAPS 2014 Workshop Knowledge Engineering Planning
Scheduling (KEPS). appear.
Biere, A., Heljanko, K., Seidl, M., & Wieringa, S. (2012). Hardware model checking competition 2012. Web site, http://fmv.jku.at/hwmcc12/.
Blum, A., & Furst, M. L. (1997). Fast planning planning graph analysis. Artif.
Intell., 90 (12), 281300.
Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artif. Intell., 129 (12), 533.
Bradley, A. R. (2011). SAT-based model checking without unrolling. Jhala, R., &
Schmidt, D. A. (Eds.), VMCAI, Vol. 6538 Lecture Notes Computer Science, pp.
7087. Springer.
Bradley, A. R., & Manna, Z. (2007). Checking safety inductive generalization counterexamples induction. FMCAD, pp. 173180. IEEE Computer Society.
Clifford, R., & Popa, A. (2011). Maximum subset intersection. Inf. Process. Lett., 111 (7),
323325.
Domshlak, C., Helmert, M., Karpas, E., Keyder, E., Richter, S., Roger, G., Seipp, J., &
Westphal, M. (2011). BJOLP: big joint optimal landmarks planner. Seventh
International Planning Competition (IPC 2011), Deterministic Part, pp. 9195.
Een, N., Mishchenko, A., & Brayton, R. K. (2011). Efficient implementation property
directed reachability. Bjesse, P., & Slobodova, A. (Eds.), FMCAD, pp. 125134.
FMCAD Inc.
Een, N., & Sorensson, N. (2003). extensible SAT-solver. Giunchiglia, E., & Tacchella, A. (Eds.), SAT, Vol. 2919 Lecture Notes Computer Science, pp. 502518.
Springer.
Fox, M., & Long, D. (1999). detection exploitation symmetry planning
problems. Dean, T. (Ed.), IJCAI, pp. 956961. Morgan Kaufmann.
Gazen, B. C., & Knoblock, C. A. (1997). Combining expressivity UCPOP
efficiency Graphplan. Steel, S., & Alami, R. (Eds.), ECP, Vol. 1348 Lecture
Notes Computer Science, pp. 221233. Springer.
Ghallab, M., Nau, D. S., & Traverso, P. (2004). Automated planning theory practice.
Elsevier.
317

fiSuda

Haas, A. R. (1987). case domain-specific frame axioms. Frame Problem
Artificial Intelligence, Proceedings 1987 Workshop Reasoning Action.
Morgan Kaufmann.
Helmert, M. (2006). Fast Downward planning system. J. Artif. Intell. Res. (JAIR),
26, 191246.
Helmert, M. (2009). Concise finite-domain representations PDDL planning tasks. Artif.
Intell., 173 (56), 503535.
Helmert, M., Do, M., & Refanidis, I. (2008). IPC 2008, deterministic part. Web site,
http://ipc.informatik.uni-freiburg.de.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal
sequential planning. Boddy, M. S., Fox, M., & Thiebaux, S. (Eds.), ICAPS, pp.
176183. AAAI.
Helmert, M., & Roger, G. (2008). good almost perfect?. Fox, D., & Gomes, C. P.
(Eds.), AAAI, pp. 944949. AAAI Press.
Hoffmann, J., Kissmann, P., & Alvaro Torralba (2014). Distance? cares? Tailoring
Merge-and-Shrink heuristics detect unsolvability. ICAPS 2014 Workshop
Heuristics Search Domain-independent Planning (HSDIP). appear.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. J. Artif. Intell. Res. (JAIR), 14, 253302.
Howey, R., Long, D., & Fox, M. (2004). VAL: Automatic plan validation, continuous effects mixed initiative planning using PDDL. ICTAI, pp. 294301.
IEEE Computer Society. Software available http://www.plg.inf.uc3m.es/
ipc2011-deterministic/Resources.
Huang, R., Chen, Y., & Zhang, W. (2012). SAS+ planning satisfiability. J. Artif. Intell.
Res. (JAIR), 43, 293328.
IPC

(2014).
International planning competition.
icaps-conference.org/, accessed 19/05/2014.

Web

site,

http://ipc.

Johnson, W. W., & Story, W. E. (1879). Notes 15 puzzle. American Journal
Mathematics, 2 (4), 397404.
Kautz, H., Selman, B., & Hoffmann, J. (2006). SatPlan: Planning satisfiability.
Working Notes 5th International Planning Competition, Cumbria, UK. Software
available http://www.cs.rochester.edu/~kautz/satplan/.
Kautz, H. A., McAllester, D. A., & Selman, B. (1996). Encoding plans propositional
logic. Aiello, L. C., Doyle, J., & Shapiro, S. C. (Eds.), KR, pp. 374384. Morgan
Kaufmann.
Kautz, H. A., & Selman, B. (1992). Planning satisfiability. ECAI, pp. 359363.
Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logic
stochastic search. Clancey, W. J., & Weld, D. S. (Eds.), AAAI/IAAI, Vol. 2,
pp. 11941201. AAAI Press / MIT Press.
318

fiProperty Directed Reachability Automated Planning

Koehler, J. (1999). IPP Planning System ADL Resource-Constrained Planning
Problems. Habiliation thesis, University Freiburg.
Long, D., & Fox, M. (1999). Efficient implementation plan graph STAN. J. Artif.
Intell. Res. (JAIR), 10, 87115.
Massey, B. (1999). Directions Planning: Understanding Flow Time Planning.
Ph.D. thesis, University Oregon.
McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpoint
artificial intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence 4, pp.
463502. Edinburgh University Press.
Nakhost, H., & Muller, M. (2010). Action elimination plan neighborhood graph search:
Two algorithms plan improvement. Brafman, R. I., Geffner, H., Hoffmann, J.,
& Kautz, H. A. (Eds.), ICAPS, pp. 121128. AAAI.
Pettersson, M. P. (2005). Reversed planning graphs relevance heuristics AI planning.
Planning, Scheduling Constraint Satisfaction: Theory Practice, Vol.
117 Frontiers Artificial Intelligence Applications, pp. 2938. IOS Press.
Ranise, S. (2013). Symbolic backward reachability effectively propositional logic
applications security policy analysis. Formal Methods System Design, 42 (1),
2445.
Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytime
planning landmarks. J. Artif. Intell. Res. (JAIR), 39, 127177.
Rintanen, J. (1998). planning algorithm based directional search. Cohn, A. G.,
Schubert, L. K., & Shapiro, S. C. (Eds.), KR, pp. 617625. Morgan Kaufmann.
Rintanen, J. (2004). Evaluation strategies planning satisfiability. de Mantaras,
R. L., & Saitta, L. (Eds.), ECAI, pp. 682687. IOS Press.
Rintanen, J. (2008a). Planning graphs propositional clause-learning. Brewka, G., &
Lang, J. (Eds.), KR, pp. 535543. AAAI Press.
Rintanen, J. (2008b). Regression classical nondeterministic planning. Ghallab,
M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), ECAI, Vol. 178
Frontiers Artificial Intelligence Applications, pp. 568572. IOS Press.
Rintanen, J. (2012). Planning satisfiability: Heuristics. Artif. Intell., 193, 4586.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: parallel plans
algorithms plan search. Artif. Intell., 170 (1213), 10311080.
Suda, M. (2013a). DIMSPEC, format specifying symbolic transition systems. Web
site, http://www.mpi-inf.mpg.de/~suda/DIMSPEC.html.
Suda, M. (2013b). Duality STRIPS planning. CoRR, abs/1304.0897.
Suda, M. (2014). Property directed reachability automated planning. Web site, http:
//www.mpi-inf.mpg.de/~suda/PDRplan.html.
Wikipedia (2014). 15 puzzle wikipedia, free encyclopedia. Web site, http://en.
wikipedia.org/wiki/15_puzzle, accessed 19/05/2014.

319

fiJournal Artificial Intelligence Research 50 (2014) 105-140

Submitted 07/13; published 05/14

Finding Optimal Solutions Voting Game Design Problems
Bart de Keijzer

dekeijzer@dis.uniroma1.it

Web Algorithmics Data Mining,
Sapienza Universita di Roma,
Rome, Italy

Tomas B. Klos

t.b.klos@tudelft.nl

Algorithmics; Delft University Technology,
Delft, Netherlands

Yingqian Zhang

yqzhang@ese.eur.nl

Department Econometrics; Erasmus University Rotterdam,
Rotterdam, Netherlands

Abstract
many circumstances multiple agents need make joint decision, voting
used aggregate agents preferences. agents vote carries weight,
sum weights agents favor outcome larger equal
given quota, outcome decided upon. distribution weights leads
certain distribution power. Several power indices proposed measure
power. so-called inverse problem, given target distribution power,
asked come gamein form quota, plus assignment weights
playerswhose power distribution close possible target distribution
(according specified distance measure).
study solution approaches larger class voting game design (VGD)
problems, one inverse problem. general VGD problem, goal
find voting game (with given number players) optimizes function
games. inverse problem, example, look weighted voting game
minimizes distance distribution power among players given
target distribution power (according given distance measure).
goal find algorithms solve voting game design problems exactly,
approach goal enumerating games class games interest. first
present doubly exponential algorithm enumerating set simple games.
improve algorithm class weighted voting games obtain quadratic
2
exponential (i.e., 2O(n ) ) algorithm enumerating them. show improved
algorithm runs output-polynomial time, making fastest possible enumeration algorithm polynomial factor. Finally, propose exact anytime-algorithm
runs exponential time power index weighted voting game design problem (the
inverse problem).
implement algorithm find weighted voting game normalized Banzhaf
power distribution closest target power index, perform experiments obtain
insights set weighted voting games. remark algorithm applicable
optimizing exponential-time computable function, distance normalized
Banzhaf index target power index merely taken example.

c
2014
AI Access Foundation. rights reserved.

fiDe Keijzer, Klos, & Zhang

1. Introduction
many real-world settings involving multiple players come joint
decision, instance elections, need fair decision-making protocols
different players different amounts influence outcome decision. weighted
voting game (WVG) often used decision-making protocol. weighted voting
game, quota given, player (or agent) game certain weight.
total weight coalition agents smaller quota, coalition said
winning, otherwise, losing.
Weighted voting games arise various practical settings, political decision
making (decision making among larger smaller political parties), stockholder companies
(where number shares determines amount influence), elections (e.g., US
presidential election, state regarded player weight equal
number electors).
weight player equal actual influence outcome
decisions made using weighted voting game. Consider example weighted
voting game quota equal sum weights players.
game, players influence equal influence player regardless weight
has. Various power indices proposed literature, ways measure
players (a priori) power influencing outcome voting game (see Banzhaf III, 1965;
Dubey & Shapley, 1979; Shapley & Shubik, 1954). However, computing power index
turned challenge many cases: see work Algaba, Bilbao, Garca,
Lopez (2003), Deng Papadimitriou (1994), Matsui Matsui (2001), Prasad Kelly
(1990), De Keijzer (2009b) recent survey.
paper, instead analyzing power agent voting game, investigate problem referred inverse problem (see Alon & Edelman, 2010)
generalized apportionment problem (see Leech, 2003). call problem
weighted voting game design problem. power index voting game design problem,
given target power index agents, study design
weighted voting game power agent close possible given
target power index.
motivation behind work practical one: desirable algorithm
quickly compute fair voting protocol, given want agent
specified amount influence outcome. new decision making bodies must
formed, changes occur formation bodies, algorithm may
used design voting method fair possible.
intuitive approach solving weighted voting game design problem would
simply enumerate possible weighted voting games n players. However, enumerating weighted voting games efficiently quite straightforward seems.
even single weighted voting game infinite number weighted representations (the representation game listing quota weight player),
enumerating games weighted representation option. address problem, prove existence of, exploit, new partial order class weighted
voting games allows us efficiently enumerate weighted voting games. enumeration method leads exact algorithm used solve weighted voting

106

fiFinding Optimal Solutions Voting Game Design Problems

game design problem. Although algorithm runs exponential time, asymptotically
big improvement naive approach runs doubly exponential time,
show. Therefore, besides fact broaden understanding problem
improvement exponential time, algorithm allows us solve problem optimality small numbers players, find approximate solutions larger numbers
players, thanks anytime property.1 implement algorithm power
index voting game design problem power index choice (normalized)
Banzhaf index. emphasize choice power index quite arbitrary: could
pick power index well, normalized Banzhaf index merely taken
example. use implementation illustrate applicability approach
obtain relevant statistics set weighted voting games.
next section define relevant concepts set notation. Section 3
formally defines problem address, gives overview related work.
Section 4, analyze problem present solution. First address design
(monotonic) simple games Section 4.1. Then, important section (4.2),
focus weighted voting game design. Section 4.3 concludes part paper
improvements wish discuss separately main ideas. Section 5,
report experiments performed implementation main algorithm,
Section 6 concludes paper.

2. Preliminaries
section, discuss required preliminary definitions results related
theory cooperative simple games.2
cooperative game pair (N, v), N finite set players; subsets N
called coalitions, v : 2N R0 characteristic function gain function, mapping
coalitions non-negative real numbers. Intuitively, v describes much collective payoff
coalition players gain cooperate. set N also called grand
coalition. simple game cooperative game (N, v) codomain v restricted
{0, 1}.3 context, coalition called winning coalition v(S) = 1, losing
coalition otherwise. cooperative game (N, v) monotonic v(S) v(T )
pairs coalitions (S, ) 2N 2N satisfy . words: monotonic
game, value coalition decrease players added coalition.
paper, concerned class monotonic simple games,
denote Gmon . general, G class games, use G(n) denote class
1. algorithm said anytime property if: (i) able provide solution anytime
execution, (ii) solution quality improves longer algorithm runs, (iii) algorithm
guaranteed output optimal solution eventually.
2. Much information section found introductory text cooperative game theory
(e.g., Peleg & Sudholter, 2003) simple games (e.g., Taylor & Zwicker, 1999). Throughout
paper, assume familiarity big-O notation analysis algorithms, well knowledge
basic order-theoretic notions related graded partial orders. parts paper,
basic knowledge computational complexity theory assumed well, although parts
crucial understanding main results presented. cover topics section.
3. purposefully exclude games losing winning coalitions, customary.
reason including games make convenient later show particular
structure exists subclass simple games.

107

fiDe Keijzer, Klos, & Zhang

games, restricted set players {1, . . . , n}. Gmon (3) class monotonic simple
games 3 players.
various important ways represent (classes of) simple games. G = (N, v)
simple game, let WG LG Gs sets winning losing coalitions, respectively,
WG LG = 2N WG LG = . set Wmin,G WG Gs minimal winning
coalitions (MWC) contains every winning coalition cannot remove player
without making losing coalition. set Lmax,G LG Gs maximal losing coalitions
(MLC) defined analogously: coalition maximal losing losing player
added without making winning. describe simple game
following forms:
Winning coalition form: (N, WG ) called winning coalition form G.
Losing coalition form: (N, LG ) called losing coalition form G.
Minimal winning coalition form: (N, Wmin,G ) minimal winning coalition form
G. Observe Wmin,G fully describes v G monotonic.
Maximal losing coalition form: (N, Lmax,G ) maximal losing coalition form G.
Again, Lmax,G fully describes v G monotonic.
some, simple games, exists another representation.
Weighted form: simple game G = (N, v), exists quota q R0
weight wi R0 P
player N , coalition 2N holds
v(S) = 1 wi q, say G weighted weighted form,
vector w = (q, w1 , . . . , wn ), also written [q; w1 , . . . , P
wn ], called weighted
representation G. (We write w(S) shorthand wi .) Observe
every game weighted form also monotonic. converse true
general,4 interested monotonic games weighted
form.
Games weighted form, weighted voting games, main interest.
denote class weighted voting games Gwvg . weighted voting game
important type simple game compact representation,
used many practical situations, elections, (European Union) political decision
making, stockholder meetings. important property weighted voting games
use weighted representation game invariant scaling:
multiply quota weights weighted form WVG G
constant c R+ , resulting weighted form [cq; cw1 , . . . , cwn ] represents
game G, is, winning losing coalitions.
next turn attention topic influence power monotonic simple
games. monotonic simple game, possible define relation called desirability
relation among players (see Isbell, 1958):
4. see this, consider four-player monotonic game MWCs {1, 2} {3, 4}. Suppose, sake
contradiction, exist weights w1 , . . . , w4 quota q form weighted representation
game. w1 + w2 q w3 + w4 q, w1 + w2 + w3 + w4 2q. coalitions {1, 3}
{2, 4} losing, since (supersets of) MWCs, w1 + w3 < q w2 + w4 < q,
means w1 + w2 + w3 + w4 < 2q, yielding contradiction.

108

fiFinding Optimal Solutions Voting Game Design Problems

Definition 1 (Desirability relation). monotonic simple game (N, v), desirability
relation v defined follows: (i, j) N 2 :
N \ {i, j} : v(S {i}) v(S {j}), v j. say
desirable j.
N \ {i, j} : v(S {i}) = v(S {j}), v j. say j
equally desirable.
N \ {i, j} : v(S {i}) v(S {j}), j v (also written v j).
say less desirable j.
v j v j, v j. say strictly desirable j.
v j v j, v j. say strictly less desirable j.
Moreover, neither v j j v holds i, j N , call j
incomparable.
Using notion desirability, define class linear games.
Definition 2 (Linear game). simple game (N, v) linear game
monotonic, pair players N incomparable respect v . Thus,
linear game (N, v), v total preorder N . denote class linear games
Glin .
weighted voting games linear. (N, v) weighted voting game weighted
form [q; w1 , . . . , wn ], v j wi wj . So, every pair players comparable
respect v . fact, following sequence strict containments holds: Gwvg
Glin Gmon . following definitions two special classes games used subsequent
sections.
Definition 3 (Canonical weighted voting games canonical linear games). linear
game (N, v) canonical linear game whenever N = {1, . . . , n} n N>0 ,
desirability relation satisfies 1 2 n. G also weighted, G
canonical weighted voting game (CWVG). class canonical linear games denoted
Gclin , class CWVGs denoted Gcwvg . Note CWVG always
weighted representation nonincreasing.
two special ways representing canonical linear games. introduce these,
need notions left-shift right-shift.
Definition 4 (Left-shift right-shift). Let N set players {1, . . . , n} let
nonempty subset N . coalition 0 N direct left-shift whenever
exists 1 6 2 n 0 = (S \ {i}) {i 1}.
coalition 0 N left-shift whenever k 1 exists sequence
(S1 , . . . , Sk ) (2N )k , that:
S1 = S,
Sk = 0 ,
109

fiDe Keijzer, Klos, & Zhang

1 < k, Si+1 direct left-shift Si .
say coalition 0 strict left-shift 0 left-shift 0 6= S.
definitions direct right-shift (strict) right-shift obtained replace
definition 1 + 1 + 1 1.
example, coalition {1, 3, 5} direct left-shift coalition {1, 4, 5}
former coalition, player 4 replaced player 4 1 = 3, coalition {1, 2, 4} left-shift
{1, 4, 5}, former obtained latter sequence (three)
direct left shifts.
notions left-shift right-shift make sense canonical linear games canonical weighted voting games. Due specific desirability order holds canonical
linear games, left-shift winning coalition always winning game,
left-shift, player winning coalition replaced lower-numbered,
thus desirable player. Similarly, right-shift losing coalition always losing
game. allows us represent canonical linear game one following
two forms.
Definition 5 (Roof/ceiling coalition/form). Let G = (N, v) canonical linear game.
Also, let Wmin,G Gs set minimal winning coalitions let Lmax,G Gs set
maximal losing coalitions. minimal winning coalition Wmin,G roof coalition
whenever every right-shift losing. Let Wroof,G denote set Gs roof coalitions.
pair (N, Wroof,G ) called roof form G. maximal losing coalition Lmax,G
ceiling coalition whenever every left-shift winning. Let Wceil,G denote set
Gs ceiling coalitions. pair (N, Wceil,G ) called ceiling form G.5
2.1 Power Indices
consider weighted voting game weighted form [100; 98, 1, 1], see
weight player necessarily directly proportional influence game.
game, grand coalition winning. Since players need present
coalition winning, said influence, despite
fact huge difference weights first versus
players.
variety power indices proposed measure players influence (instead
weight) monotonic simple game. Power indices measure players priori power
voting game. reason, power indices rely (statistical) information
coalitions likely actually form due preferences players.
paper, focus normalized Banzhaf index (also called simply Banzhaf index,
see Banzhaf III, 1965), inasmuch used experiments Section 5. However,
theoretical part work, particular choice power index irrelevant.
Definition 6 (normalized Banzhaf index & raw Banzhaf index). (normalized) Banzhaf
index monotonic simple game (N = {1, . . . , n}, v) defined = (1 , . . . , n ),
5. terminology roof ceiling taken Peled Simeone (1985), Taylor Zwicker
(1999) call coalitions shift-minimal winning coalitions shift-maximal losing coalitions.

110

fiFinding Optimal Solutions Voting Game Design Problems

1 n,
0
= Pn

0
j=1 j

,



i0 = |{S N \ {i} : v(S) = 0 v(S {i}) = 1}|.

(1)

Here, i0 called raw Banzhaf index player i, counts number losing
coalitions agents player turn winning joining them.
problem computing power indices associated computational complexity
widely studied. survey complexity results, exact approximation
algorithms computing power indices, see work De Keijzer (2009b). Prasad
Kelly (1990) prove computation raw Banzhaf index #P-complete,6
fastest known exponential time algorithm computing
Banzhaf index due Klinz

Woeginger (2005), achieving runtime O(( 2)n n2 ).

3. Problem Statement Related Work
general statement, voting game design (VGD) problem problem
finding simple game optimizes given requirement. One obtains different variants
problem specifying (i) type simple game one interested in, (ii)
requirement optimized. paper, focus finding weighted voting game (in
weighted form), requirement normalized Banzhaf power index
game close possible given target power index. call variant power
index weighted voting game design (PIWVGD) problem. Please note approach
propose specific minimizing distance target power index;
optimization criteria addressed well. fact, follows pertains
enumerating games given classes, optimization part problem, let
alone focus (normalized Banzhaf) power index. (some of) experiments
focus normalized Banzhaf index. experiments, choose measure
closeness terms Euclidean distance Rn normalized Banzhaf power
index game target power index.
illustrate problem, visualize 3 player-instance problem,
done nicely two dimensions. normalized Banzhaf index weighted
voting game vector 2-dimensional unit simplex.7 analysis Section 4,
turn convenient restrict canonical WVGs (see Definition 3).
without loss generality, every WVG exists canonical
WVG obtained ordering players. three players, games
normalized Banzhaf power indices shaded area Figure 1, vertices
simplex labeled players numbers (1, 2 3). corresponding power
indices listed left.
four dark dots Figure 1 represent normalized Banzhaf power indices corresponding ten existing three-player canonical WVGs. Two ten games
6. #P complexity class contains counting versions problems NP. Problems complete
class believed hard solve, polynomial-time algorithm one problem
implies P = NP.


P
7. Recall n-dimensional unit simplex defined x (R0 )n+1 : n+1
i=1 xi = 1 , contains
(n + 1)-dimensional vectors non-negative real numbers elements sum 1.

111

fiDe Keijzer, Klos, & Zhang

(1, 0, 0)
(, , )

1

[999: 1000, 0, 0]
[999: 1000, 500, 500]
[999: 998, 2, 2]
[999: 1000, 1000, 0]

(, , 0)

[999: 500, 500, 0]
[999: 1000, 1000, 1000]

(, , )

[999: 500, 500, 500]
[999: 333, 333, 333]

2

3

Figure 1: games three players power indices.
degenerate, namely, two games winning losing coalitions, respectively.
Weighted form representations eight games given right figure, also shows different games may distribution power.
PIWVGD problem (for n = 3) now: given target power index (a point) somewhere
shaded area figure (and corresponding part (n 1)-dimensional unit
simplex general n), return weighted representation game closest
target (in terms Euclidean distance, example).
know couple studies propose algorithms inverse problem.
Fatima, Wooldridge, Jennings (2008) Aziz, Paterson, Leech (2007) present
similar algorithms inverse problem target Shapley-Shubik index (Shapley &
Shubik, 1954) Banzhaf index (Banzhaf III, 1965), respectively. algorithms iteratively update weight vector using update rules based distance current
weight vectors power index target power index. Fatimal et al. use two update rules
prove applying them, Shapley-Shubik index player cannot
get away target. Hence, proposed algorithm anytime algorithm.
Aziz et al. give analysis. Leech (2002a, 2003) proposes approach
largely resembles method Aziz et al., exception different updating
rule used. Neither algorithm comes approximation guarantee.
two recent interesting works voting game design problem. One
Kurz (2012b). Kurz proposes exact method using integer linear programming,
solving weighted voting game design problem Shapley-Shubik index
Banzhaf index. set linear games taken search space, branch-andbound techniques (along various insights set weighted voting games)
used order find set weighted voting game power index closest
target. Kurz provide runtime analysis. experiments performed show
algorithm works well small numbers players. work independent work
Kurz differs interested devising algorithm provable asgood-as-possible runtime guarantees. Moreover, approach take different
Kurz, theory necessary develop algorithm considered interesting
itself.

112

fiFinding Optimal Solutions Voting Game Design Problems

recent work De, Diakonikolas, Servedio (2012b). paper provides main result algorithm inverse power index problem case
Shapley-Shubik index, certain approximation guarantee: addition
target power index, algorithm takes precision parameter guarantees output
weighted voting game power index -close it, precondition
exists -close weighted voting game property quota
skewed, particular sense. is, knowledge, polynomial time algorithm
power index voting game design problem provides approximation guarantee
sense.
Closely related work two papers deal Chow parameters problem
(ODonnell & Servedio, 2011; De, Diakonikolas, Feldman, & Servedio, 2012a). results
paper stated terms boolean function theory learning theory,
translated setting, papers seen deal approximation algorithms
type value considered power index: Chow parameters given
player given game defined total number winning coalitions
player in. authors present papers, main result, polynomial time
approximation scheme computing Chow parameters weighted voting game.
problem enumerating set weighted voting games fixed number
players is, see, closely related approach take solving weighted
voting game design problem. enumeration problem studied Kurz (2012a),
uses integer programming techniques enumerate canonical weighted voting games
nine players. Kurz generates integer weighted representations games
classifies games unique minimum-sum integer weighted representation.
Threshold functions (Hu, 1965; Muroga, 1971) fundamental research interest
voting games, circuit complexity neural networks. problem realizing Boolean
threshold functions neural networks extensively studied (Parberry, 1994; Siu,
Roychowdhury, & Kailath, 1995; Freixas & Molinero, 2008), upper lower bounds
derived synaptic weights realizations. enumeration threshold
functions closely related enumeration weighted voting games (see Appendix
A): Threshold functions essentially weighted voting games negative weights
allowed. enumeration threshold functions six variables done Muroga,
Toda, Kondo (1962). Subsequently, work Winder (1965), Muroga, Tsuboi,
Baugh (1970), threshold functions respectively seven eight variables
enumerated. Krohn Sudholter (1995) enumerated canonical weighted voting games
eight players, well class canonical linear games. Kurz (2012a) first
enumerate nine player canonical weighted voting games, Freixas Molinero
(2010) first enumerate nine player canonical linear games. best
knowledge, enumerations 10 players carried out.
exists literature enumeration special subclasses voting games well:
see work Freixas, Molinero, Roura (2012) linear games two desirability
classes; work Freixas Kurz (2013a) weighted voting games one roof;
work Freixas Kurz (2013b) linear games certain special types voters
desirability classes.

113

fiDe Keijzer, Klos, & Zhang

work Krohn Sudholters (1995), enumeration canonical linear games
subclass thereof studied using various order theoretic concepts. directly address problem enumerating weighted voting games, although discuss
correspondence n-player proper weighted voting games (n + 1)-player
canonical decisive weighted voting games.8 class canonical linear games
much bigger class weighted voting games, algorithms imply efficient enumeration procedure weighted voting games, one main contributions
present work. However, connections work Krohn
Sudholter: enumeration procedures work exploiting graded posets, like
ours; although posets consist subsets winning coalitions together set
inclusion relation (for case decisive canonical linear games, use variant
poset), subsets minimal winning coalitions case. Although
idea using graded poset corresponds ours, seems us results cannot
connected stronger sense. Moreover, proofs properties
establish partially ordered set propose here, use vastly different ideas,
crucially exploit weightedness.
Alon Edelman (2010) observe need know priori estimates power
indices achievable simple games analyze accuracy kinds iterative
algorithms, i.e., need information distribution power indices
[0, 1]n . first step solving problem, prove specific result case
Banzhaf index monotonic simple games.
addition, applied work done design voting games. Laruelle
Widgren (1998), Sutter (2000) analyze design distribution voting power
European Union using iterative methods resemble algorithm Aziz et al.
(2007). Laruelle Widgrens algorithm systematically analyzed improved
De Nijs, Wilmer, Klos (2012). Similar work done Leech EU (Leech,
2002b), IMF (Leech, 2002c).
Finally, research direction related problem studying minimal
integer representations weighted voting games: Bounds maximum weight
representation provide us finite set weighted representations search through,
means solving design problem. explain greater detail next
section. classical relevant bounds found work Muroga (1971), Section
9.3. See work Freixas Kurz (2011), Freixas Molinero (2010) recent
work direction.

4. Solving Power Index Voting Game Design Problem
natural representation weighted voting game weighted representation.
However, invariance scaling weighted representations, exist infinite
number weighted representations individual weighted voting game, even though
every n, number weighted voting games finite: weighted voting games simple
n
games, 22 simple games n players. makes hard derive exact
algorithm weighted voting game design problem based working
8. game called proper complement winning coalition losing. game called decisive
proper complement losing coalition winning.

114

fiFinding Optimal Solutions Voting Game Design Problems

weighted representations alone, since immediately clear finite set weight
vectors algorithm search through.9 resort working alternative
representations.
approach voting game design problems devising enumeration method
generates every voting game relatively efficiently. First, discuss naive method
enumerates monotonic simple games given number players doubly exponential
time (Section 4.1). Subsequently, Section 4.2, case weighted voting games,
improve runtime exponentially showing enumerate weighted voting
games given number players within exponential time. Although runtime
enumeration method still exponential, see algorithm PIWVGD
problem results enumeration method (trivially) anytime property:
remember best game found far, longer run algorithm,
better result becomes. addition, guaranteed algorithm eventually
finds optimal answer. enumeration method exploits specific (graded) partial order
prove exist class weighted voting games.
dealing algorithms run exponential time, make use
-notation: function f : R R (g) g : R R
polynomial p : R R f O(g p). essentially means
make light polynomial factors.
4.1 Monotonic Simple Game Design
section consider briefly power index voting game design problem class
monotonic simple games.
monotonic simple game represented either set minimal winning coalitions
maximal losing coalitions, sets always forming antichain
-relation coalitions players:10 pair coalitions set minimal winning
(maximal losing) coalitions comparable respect , one
coalitions would minimal winning (maximal losing). exact algorithm solves
problem must therefore search antichain represents game (as either
list MWCs MLCs) power index closest target power index.
either case, simple exact algorithm problem would one considers every
possible antichain, computes antichain power index game
antichain represents, distance target power index, finally return game
minimizes distance.
number antichains set n elements known nth Dedekind number Dn . sequence Dedekind numbers (Dn ) quickly grows large,
algorithm high time complexity. Kleitman Markowski (1975) prove following
bounds Dn :
0 log n
n/2 )E
n
2(1+c n )En Dn 2(1+c2
,
(2)
9. However, literature provide us bounds maximum weight necessary integer
representation weighted voting game, could utilize order come enumeration algorithm based generating finite set integer weighted representations. elaborate
idea refwvgdesign.
10. family sets antichain respect relation R, pair sets
family comparable respect R.

115

fiDe Keijzer, Klos, & Zhang

c0 c constants En size largest antichain n-set.11
n
, result known Sperners theorem.
Sperner (1928) proves En = bn/2c
Sperners theorem Stirlings approximation, get
n
2
En
.
(3)
n
conclude Dn doubly exponential n. Therefore, algorithm solves
voting game design problem monotonic simple games way achieves running
n
time (22 h(n)). function h exponential popular power indices, e.g.,
Shapley-Shubik index Banzhaf index (see Aziz, 2008; Deng & Papadimitriou, 1994;
Prasad & Kelly, 1990).
4.2 Enumerating Weighted Voting Games
mentioned Section 3, literature voting game design problems focused
weighted voting game variant power index voting game design problem
power index choice either Banzhaf index Shapley-Shubik index. Here,
propose exact algorithm problem runs exponential time.
turn make algorithm interesting practical purposes anytime
algorithm (trivially): guaranteed output optimal solution eventually,
stop execution algorithm time, answer output closer
optimum, longer run it. advantage algorithm current local
search methods obviously get stuck local optima.
existing local search methods try solve weighted voting game
design problem use weighted representation directly, mentioned before,
exist infinitely many weighted representations even single weighted voting game,
algorithms stall move different weighted representation doesnt
represent different game. mentioned before, using weighted representations
basis enumeration algorithm possibility well, immediately clear
this, infinite set weighted representations every weighted
voting game. Muroga (1971, Thm. 9.3.2.1) provides us solution problem,
theorem tells us every weighted voting game exists integer weighted
representation none weights quota exceeds 2n log n . means
possible enumeration algorithm could work iterating 2(n+1)n log n integer
weight vectors weights fall within bounds, output weight vector
case corresponds weighted voting game output before.
yields improvement enumeration algorithm outlined Section 4.1 special
case weighted voting games. still consider satisfactory enumeration
procedure runtime algorithm still significantly larger known
upper bounds number weighted voting games (see Appendix A). enumeration
11. Korshunov (2003) devised asymptotically equal expression:
n/2

2 n5

n4

+n 2
n2
Dn 2C(n) ec(n)2
,


n
n
C(n) = bn/2c
c(n) = bn/2c1
. describes expression number monotonic
boolean functions, equal nth Dedekind number.

116

fiFinding Optimal Solutions Voting Game Design Problems

algorithm propose better runtime, indeed property
also efficient sense runs time polynomial number weighted voting
games outputs. algorithm rely weighted representations weighted
voting games; instead works representing weighted voting games sets
minimal winning coalitions.
4.2.1 New Structural Property Class Weighted Voting Games
enumeration algorithm propose enumerates canonical WVGs exploits fact
set canonical weighted voting games n players partially ordered specific
relation games sets minimal winning coalitions. particular, show
take canonical weighted voting game n players least one minimal
winning coalition (MWC), exists MWC C games set MWCs
that, remove C, resulting set MWCs represents another canonical weighted
voting game n players. analysis, also show check whether
set MWCs given game extended coalition form another games
set MWCs. way, start game zero MWCs, enumerate
games bottom up, according specific partial order.
proceed developing necessary theory behind algorithm
propose. focus class canonical weighted voting games since
noncanonical weighted voting game canonical one obtained merely
permutating players.
use order-theoretic notions section. given following
definition.
Definition 7 (Partial order, (graded) poset, cover, rank function, least element). set
S, partial order relation reflexive, x : x x; antisymmetric,
x, : ((x x) x = y); transitive, x, y, z : ((x
z) x z). partially ordered set poset set equipped partial order ,
i.e., pair (S, ). least element poset (S, ) element x x
S. minimal element (S, ) element x x implies
= x S. say covers x (S, ) x
z x z y. poset (S, ) graded exists rank function
: N that: (i) constant minimal elements (S, ), (ii) (x) (y)
x, x holds, (iii) pair x, holds covers
x (S, ), (y) = (x) + 1.
algorithm propose based new structural property allows us
enumerate class canonical weighted voting games efficiently. define relation
MWC prove number players n, class Gcwvg (n) forms graded
poset least element relation.
Definition 8 (The relation MWC ). Let G, G0 Gcwvg (n) two canonical weighted
voting games. define G MWC G0 hold exists k N1
sequence G1 , . . . , Gk canonical weighted voting games n players, G1 = G,
Gk = G0 , 1 < k holds Wmin,i Wmin,i+1 |Wmin,i | = |Wmin,i+1 |1,
Wmin,i denotes set minimal winning coalitions Gi .
117

fiDe Keijzer, Klos, & Zhang

following theorem provides foundation enumeration algorithm.
Theorem 1. n, (Gcwvg (n), MWC ) graded poset rank function
: Gcwvg (n)
N
G
7 |Wmin,G |.
Moreover, graded poset least element rank 0.
Proof Theorem 1. need prove (1) pair (Gcwvg (n), MWC ) poset,
requires showing relation MWC partial order Gcwvg (n), (2) partial
order graded, requires showing function rank function, (3)
graded poset least element rank 0. (1), relation MWC reflexive,
every game G Gcwvg (n), G MWC G holds: take k = 1 Definition 8,
required sequence games G. relation also antisymmetric,
G MWC G0 G0 MWC G true, exist two sequences CWVGs G1 , . . . , Gm
(with G1 = G Gm = G0 ), G1 , . . . , Gn (with G1 = G0 Gn = G),
conditions Definition 8 hold. Neither sequence length > 1, would
mean Wmin,G Wmin,G0 (or vice versa), inclusion wouldnt hold
direction. means = n = 1, G = G0 . Finally, relation
transitive, G MWC G0 G0 MWC G00 hold, exists sequences CWVGs
G1 , . . . , Gm (with G1 = G Gm = G0 ) G1 , . . . , Gn (with G1 = G0 Gn = G00 )
conditions Definition 8 hold. Concatenating sequences establishes
G MWC G00 holds.
order prove (2), poset graded rank function specified
theorem, show three conditions (i) (iii) Definition 7
hold function defined Theorem 1. condition (i), CWVG G
Wmin,G = minimal element: take arbitrary CWVG G0 G0 MWC G
holds. show G0 = G. G0 MWC G holds, exists sequence
CWVGs G1 , . . . , Gm (with G1 = G0 Gm = G) conditions Definition 8
hold. Wmin,G = , sequence length > 1, G0 = G.
G0 arbitrary, holds CWVGs, establishing G minimal element.
value rank function game G 0. show game G Wmin,G =
minimal element, prove following lemma constructively.
Lemma 1. every game G Gcwvg (n) nonempty set Wmin,G set minimal
winning coalitions, coalition C Wmin,G game G0 Gcwvg (n)
Wmin,G \ {C} set minimal winning coalitions G0 .
lemma implies every game G Gcwvg , exists sequence CWVGs
starts G ends game minimal winning coalitions. game
set MWCs one smaller previous game sequence. prove
Lemma 1, first prove two preliminary Lemmas (2 3).
Lemma 2. Let G = (N = {1, . . . , n}, v) weighted voting game, let ` = [q; w1 , . . . , wn ]
weighted representation G. player exists > 0
positive 0 < , vector `0 = [q; w1 , . . . , wi + 0 , wi+1 , . . . , wn ] also weighted representation G.
118

fiFinding Optimal Solutions Voting Game Design Problems

Informally, lemma states always possible increase weight player
amount without changing game.
Proof. Recall WG LG Gs sets winning losing coalitions, respectively.
Let wmax = maxCLG w(C) wmin = minCWG w(C), wmax < q largest weight
losing coalition, wmin q smallest weight winning coalition, wmax < wmin .
Take = wmin wmax note > 0. Increasing players weight positive
amount 0 less turn losing coalition winning coalition.
Also, 0 > 0, change weight turn winning coalition losing
coalition, weighted representation `0 represents game G.
Lemma 3. Let G = (N = {1, . . . , n}, v) weighted voting game, let w` (C)
weight coalition C game represented `. exists weighted representation
` G C, C 0 2N , C 6= C 0 , v(C) = v(C 0 ) = 1, holds
w` (C) 6= w` (C 0 ).
Or, informally stated: every weighted voting game, exists weighted representation winning coalitions different weight.
Proof. Let `0 = [q; w1 , . . . , wn ] weighted representation G. construct
required weighted representation ` `0 . First fix arbitrary player i. Lemma
2, > 0 increasing wi value 0 (0, ) result another
weighted representation G. Let E set choices 0 increasing wi
0 yields weighted representation ` two coalitions C, C 0 2N ,
C 6 C 0 , weight `. finitely many
pairs (C, C 0 ) E finite therefore (0, ) \ E non-empty. picking 0 value
(0, ) \ E, increasing weight player 0 , thus end weighting
` coalition C containing w` (C) equal coalition
containing i. Furthermore, C C 0 two arbitrary coalitions distinct
weights `0 , certainly distinct weights `.
sequentially applying operation N , end weighting
` holds every player coalition C containing
w` (C) equal weight coalition containing i.
Let C, C 0 2N arbitrary distinct coalitions. Assume without loss generality
C \ C 0 6= (otherwise, may swap names C C 0 ) let C \ C 0 .
C contains C 0 contain i, w` (C) 6= w` (C 0 ), completes
proof.
Using Lemma 3, prove Lemma 1, establishes Theorem 1.
Proof Lemma 1. Let G = ({1, . . . , n}, v) canonical weighted voting game. Let
Wmin,G set minimal winning coalitions let ` = [q; w1 , . . . , wn ] weighted
representation holds minimal winning coalitions different weight.
Lemma 3, representation exists. construct `00 ` holds
weighted representation canonical weighted voting game Wmin,G \ {C}
list minimal winning coalitions, C Wmin,G .

119

fiDe Keijzer, Klos, & Zhang

Let highest-numbered player coalition Wmin,G , i.e., least
desirable nondummy player. may assume without loss generality wj = 0
j > (i.e., dummy players), setting weights 0, still holds
minimal winning coalitions different weights. Let C Wmin,G minimal winning
coalition containing lowest weight among MWCs Wmin,G contain i.
Next, define `0 [q; w1 , . . . , wi (w` (C) q), . . . , wn ]. Note `0 weights
players still decreasing nonnegative: w` (C \ {i}) < q (due C \ {i}
losing coalition, C MWC), w` (C \ {i}) + wi = w` (C) < q + wi ,
wi > w` (C) q. player weight `0 indeed nonnegative. Player weight
decreased `0 , enough turn even lightest MWCs contain
losing coalition. G`0 = G` = G w`0 (C) = q. Moreover, weights
coalitions Wmin,G contain player still mutually distinct `0 .
decrease player weight further, amount small
minimal winning coalition turns losing coalition C. Note `0
(representing game G), minimal winning coalition C still lightest MWC
containing player i. Let C 0 Wmin,G second-lightest minimal winning coalition
containing i. Obtain `00 decreasing weight `0 positive amount smaller
w`0 (C 0 ) w`0 (C). Coalition C become losing coalition minimal
winning coalitions stay winning. new minimal winning coalition introduced
process: Suppose would new minimal winning coalition G`00 ,
contains players least desirable (the players weight
0). case 6 S, would also minimal winning coalition original
game G w`00 (S) = w` (S) q, contradicts fact new MWC
G`00 . case S, must \ {i} winning original game G (because
winning original game MWC original game, picked
least desirable nondummy player). Thus, w`00 (S \ {i}) = w` (S \ {i}) q,
contradiction MWC G`00 .
G`00 therefore n-player canonical weighted voting game whose set MWCs forms
subset MWCs G, cardinalities two sets differ exactly 1.
proves claim.
Continuing proof Theorem 1, follows Lemma 1 game
minimal winning coalitions unique minimal element. fact properties (ii)
(iii) hold rank function follows immediately definitions relation
MWC function . Regarding claim (3), poset least element rank
0, consider game G minimal winning coalitions. game G, G MWC G0
holds games G0 Gcwvg (n), G least element, rank 0.
Figure 2, (Gcwvg (4), MWC ) depicted graphically. Note convenience
display, figure exactly Hasse diagram poset (Gcwvg (4), MWC ).
clear Figure 2 (Gcwvg (4), MWC ) tree since one game covers
multiple games: game labelled 0110 two edges coming it, one
dashed. set minimal winning coalitions representing game, two
minimal winning coalitions (1001 0110) holds removed,
remaining set coalitions set minimal winning coalitions representing another

120

fiFinding Optimal Solutions Voting Game Design Problems



1000

1100

0100 0110 0111

1011

1101

0010 0011 0101 0110 0111 1001 0111

1011

1001

0001

0011

1010

1110

1111

0000

0110

0110

0111

0111

0101
0011

Figure 2: Graphical depiction (Gcwvg (4), MWC ). node graph represents
canonical weighted voting game four players. figure read follows:
node characteristic vector minimal winning coalition label; binary
sequence indicating player whether (1) (0) member coalition.
set minimal winning coalitions game corresponds certain node n
graph, elements coalitions described elements set Vn
characteristic vectors path top node n along solid edges. top node
corresponds canonical weighted voting game zero minimal winning coalitions
(i.e., every coalition loses). actual Hasse diagram poset obtained
changing label node n Vn including solid edges well dashed
edge diagram.

121

fiDe Keijzer, Klos, & Zhang

canonical weighted voting game. Since one could add number dummy players
game (i.e., players occur winning coalition), conclude following.
Proposition 1. every n 4, (Gcwvg (n), MWC ) tree.
develop algorithm next section, turn Proposition 1
makes things significantly complicated.
4.2.2 Algorithm
use results previous section develop exponential-time exact algorithm
power index voting game design problem. way algorithm works straightforward. naive algorithm suggested Section 4.1, enumerate complete
class games (weighted voting games case), compute game
output enumeration algorithm power index distance power index
target power index. keep track game minimizes distance.
key efficient enumeration utilizing Theorem 1, possible efficiently
generate minimal winning coalition listings canonical weighted games rank
(according graded poset defined) minimal winning coalition listings
canonical weighted voting games rank 1.
following two theorems show us this. Firstly, need result
work Peled Simeone (1985).
Theorem 2 (Peled & Simeone, 1985). exists polynomial time algorithm testing
whether game given list minimal winning coalitions weighted voting game.
Moreover, weighted voting game, list maximal losing coalitions
weighted representation found polynomial time.
algorithm proposed Peled Simeone (1985) above-named characteristics called Hop-Skip-and-Jump algorithm. algorithm originally designed
applications related solving problems fields threshold logic set covering,
matter changing terminology straightforward way see
Hop-Skip-and-Jump algorithm fulfills purposes well.
state next theorem, first define truncation operation.
Definition 9 (Right-truncation). Let N = {1, . . . , n} coalition players. Using
P (S, i) denote ith highest numbered player among players S, ith righttruncation S, denoted rtrunc(S, i), defined


= 0,

rtrunc(S, i) = \ {P (S, i), . . . , n} 0 < |S|,


undefined
otherwise.
canonical linear games, ith right-truncation coalition (for |S|)
coalition remains least desirable players removed S. example,
2nd right-truncation coalition {1, 2, 4, 6, 8} coalition {1, 2, 4}.

122

fiFinding Optimal Solutions Voting Game Design Problems

Theorem 3. n, let G, G0 Gclin (n) pair canonical linear games
respective sets minimal winning coalitions Wmin,G Wmin,G0 , Wmin,G
Wmin,G0 |Wmin,G0 | = |Wmin,G | + 1. Let Lmax,G Lmax,G0 sets maximal losing
coalitions G G0 , respectively. C Lmax,G N 0 n
Wmin,G0 = Wmin,G {rtrunc(C, i)}.
Proof. Let C 0 coalition Wmin,G0 = Wmin,G {C 0 }. Coalition C 0 cannot
superset coalition Wmin,G would minimal winning
coalition G0 . Therefore, C 0 losing coalition G, must subset coalition
Lmax,G . Suppose contradiction C 0 right-truncation maximal losing
coalition C Lmax,G . C Lmax,G C 0 subset C,
right-truncation C. means C 0 , player j C present,
least one less desirable player k > j C C 0 . implies left-shift C 00
C 0 C 00 subset coalition Lmax,G : C 00 obtained C 0 replacing
j k. C 00 subset C, C 00 still losing coalition G. C 00
superset coalition Wmin,G , hence C 00 also superset coalition
Wmin,G0 . C 00 losing coalition G0 . G0 canonical linear game,
desirability relation 1 n, C 00 winning coalition G0 left-shift
winning coalition C 0 . contradiction.
Theorems 2 3, becomes apparent use (Gcwvg (n), MWC )
enumerating class n-player canonical weighted voting games. start outputting
n-player weighted voting game zero minimal winning coalitions. that,
repeat following process find games: use Theorem 3 generate
minimal winning coalition lists canonical weighted voting games minimal
winning coalitions, using set canonical weighted voting games games i1 minimal
winning coalitions (also represented list minimal winning coalitions), starting = 1.
generated, choice output games either list minimal winning
coalitions weighted representation, using Hop-Skip-and-Jump algorithm.
Generating set games minimal winning coalitions works follows.
game G i1 minimal winning coalitions, obtain set maximal losing coalitions
using Hop-Skip-and-Jump algorithm. Next, check right-truncation
maximal losing coalition C Lmax,G whether, add Gs set minimal
winning coalitions, resulting set represents another weighted voting game. Again, testing whether game weighted voting game done using Hop-Skip-and-Jump
algorithm. game turns weighted, store output it.
one remaining problem approach: outputs duplicate games.
(Gcwvg (n), MWC ) tree, would case. However, Proposition
1, (Gcwvg (n), MWC ) tree n 4. Thus, duplicates check
weighted voting game find. principle, seems difficult.
game find, sort list minimal winning coalitions, check
list coalitions already occurs array listings minimal winning coalitions
correspond games already found. problem solution list
grow large, making checks time- space-consuming operations.
therefore use different method duplicates check: Suppose
found n-player canonical weighted voting game G minimal winning coalitions
123

fiDe Keijzer, Klos, & Zhang

adding coalition C minimal winning coalition listing canonical weighted voting
game already found. first sort Gs list minimal winning coalitions
according fixed total order. check coalition C 0 occurs
C sorted list, whether C 0 removal list results list minimal winning
coalitions canonical weighted voting game. C 0 , discard G,
otherwise, keep it. way, certain canonical weighted voting game
generated once. terms orderly generation combinatorial objects (McKay,
1998), method thus provides canonical construction path CWVGs.
Algorithm 1 gives pseudocode enumeration method. array element
games[i] list canonical weighted voting games minimal winning
n
coalitions; rank-i games. value exceed bn/2c
Sperners Theorem.
games represented lists minimal winning coalitions. algorithm iterates
every new game found, starting game games[0], zero minimal winning
coalitions.
Algorithm 1 enumeration algorithm class n player canonical weighted voting
games. hopskipjump refers Hop-Skip-and-Jump algorithm.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

Output [1; 0, . . . , 0]
. Output game MWCs
games[0] {}
. Add game list rank-0 games
n
= 1 bn/2c

G games[i 1]
. Evaluate game G rank 1
Lmax hopskipjump(Wmin,G )
. Obtain game Gs set MLCs
C Lmax
. Evaluate MLC C
j = 0 n
. Evaluate Cs right-truncations
G0 Wmin,G rtrunc(C, j)
. Call game evaluated G0
isweighted(G0 )
. requires solving LP
G0 passes duplicates check
Output weighted representation G0 .
Append G0 games[i].
end
end
end
end
end
end

Correctness algorithm follows discussion above. Next, analyze
time-complexity algorithm.
2 +2n

Theorem 4. Algorithm 1 runs (2n

) time.

Proof. Lines 5 16 executed every canonical weighted voting game.
Sperners Theorem, know list minimal winning coalitions fewer
n
elements. runtime Hop-Skip-and-Jump algorithm, line 5 runs time
bn/2c

2


n
n
n bn/2c
+ n3 bn/2c
= O(n2 n22n ). Within iteration outer loop (line 4),
124

fiFinding Optimal Solutions Voting Game Design Problems



n
= O( n2n ) times (because Lmax also anlines 9 14 executed n bn/2c
tichain, Sperners Theorem also applies maximal losing coalitions). time-complexity
one execution lines 9 14 follows.


n
line 9, must solve linear program, taking time n4.5 bn/2c
= O(n4 2n )
using Karmarkars interior point algorithm (Karmarkar, 1984).
line
10, must execute duplicates check. consists checking
n
bn/2c sets minimal winning coalitions whether weighted. involves
running Hop-Skip-and-Jump algorithm, followed solving linear program.

total, takes O(n3 n22n ) time.
Lines 11 12 take linear time.
Bringing everything together, see single pass lines 5 16 costs us O(n4 23n )
time. mentioned earlier, lines executed |Gcwvg (n)| times. Corol2
lary 1 Appendix know |Gwvg (n)| O(2n n ), course |Gcwvg (n)| <
2
|Gwvg (n)|, hence lines 5 16 executed O(2n n ) times, therefore run2
2
time algorithm O(2n +2n n4 ) = (2n +2n ).
Although runtime analysis Algorithm 1 precise, want emphasize
method runs exponential time instead doubly exponential time. also
show runtime algorithm polynomially greater amount
data output. implies Algorithm 1 essentially fastest possible enumeration
algorithm canonical weighted voting games, polynomial factor.
Theorem 5. Algorithm 1 runs output-polynomial time, i.e., polynomial number
bits Algorithm 1 outputs.
Proof. Lines 5 16 executed less |Gcwvg (n)| times. (5), lower
n2 (1

10

)

log n /(n!2n )). One execution lines 5 16 costs O(n4 23n )
bound |Gcwvg (n)| (2
time, thus one iteration runs
2

10
n (1 log
)
n /(n!2n )
O(n4 23n ) 2
O(|Gcwvg (n)|)

time. conclude algorithm runs O(|Gcwvg (n)|2 ) time.
Remark 1. cannot give sharp bound space complexity Algorithm 1 know much maximum cardinality antichain (Gcwvg (n), MWC
). (Nonetheless, obtain maximum sizes antichains n 8; see Figure 3
next section.) However, seen also possible generate games
poset depth-first manner, instead breadth-first manner like now.
case, amount space needs used bounded maximum length
2n
chain (Gcwvg (n), MWC ). total amount O(
) space.
n
briefly illustrate algorithm enumerates (four-player) CWVGs
referring Figure 2, afterwards indicate application solving power index
125

fiDe Keijzer, Klos, & Zhang

weighted voting game design problem. algorithm starts line 1 outputting
weighted representation game root node. game winning
coalitions. (By definition simple game, exists.) root games list MWCs
, added array element games[0] line 2. loop

n
possible values rank function defined Theorem 1 take: 1 bn/2c (see
Section 4.1). four players, values 1 6 correspond six horizontal
rank-levels root node graph Figure 2. every game G set
games one level higher graph (line 4), consider set maximal losing coalitions
Lmax,G (line 6), (line 7), evaluate whether game obtained
adding (at most) n right truncations (line 8) Wmin,G yields weighted voting
game (line 9). four player case, = 1, look single root game. Since
game losing coalitions, grand coalition element games set
MLCs. evaluate whether, grand coalitions five right truncations
(0 j 4), adding yields CWVG. turns true five cases,
yielding five CWVGs G (G) = 1 see rank-level 1 (the second level
top graph). games added games[1]. increase one,
iteratively consider five games turn.
apply enumeration algorithm power index weighted voting game design
problem, compute Banzhaf index every generated game, compute
distance target power index (according chosen distance function). store
update weighted representation game minimizes distance function,
output representation games generated.
4.3 Improvements Optimizations
Algorithm 1 current state quite suitable solving weighted voting game
design problem practice. section, describe several improvements
algorithm. improvements result version enumeration algorithm
expect output canonical weighted voting games steady rate, give us
practically applicable anytime-algorithm voting game design problems (defined small
numbers players).
Hop-Skip-and-Jump algorithm Peled Simeone (1985) works first generating list maximal losing coalitions game, given list minimal winning
coalitions game, subsequently solving linear program check whether game
weighted voting game. Peled Simeone give first improvement showing several ways improve compactify linear program question. smaller linear
program requires lists roof coalitions ceiling coalitions game.
next section, present strengthened version Theorem 3. strengthened
version implies necessary know games ceiling coalitions (instead
maximal losing coalitions) generate weighted voting games cover it. Section
4.3.2 give output-polynomial time algorithm enumerating ceiling coalitions,
given set roof coalitions.
using improvements, combined compact linear program,
eliminate need compute complete set maximal losing coalitions weighted
voting games enumerate. Instead, suffices keep track sets minimal

126

fiFinding Optimal Solutions Voting Game Design Problems

winning coalitions ceiling coalitions weighted voting games enumerated,
speed algorithm significantly.12
4.3.1 Better Way Finding New Minimal Winning Coalitions
Theorem 3 allows us find potential minimal winning coalitions extend
canonical weighted voting games generate new ones. see
really need consider every right-truncation every maximal losing coalition. fact,
need look ceiling coalitions.
Theorem 6. n, let G, G0 Gclin (n) pair canonical linear games
Wmin,G Wmin,G0 |Wmin,G0 | = |Wmin,G | + 1. Let Wmin,G Wmin,G0 sets
minimal winning coalitions G G0 , respectively, let Lceil,G Lceil,G0 sets
ceiling coalitions G G0 , respectively. C Lceil,G N
0 n Wmin,G0 = Wmin,G rtrunc(C, i).
Proof. Let C 0 coalition Wmin,G0 = Wmin,G {C 0 }. Theorem 3, C 0
right-truncation coalition Lmax,G . Suppose contradiction C 0
right-truncation ceiling Lceil,G . ceiling C 00 Lceil,G C 0
subset strict right-shift C 00 . (This definition subset right-shift
ceiling, C 0 subset S.) turn means strict left-shift
C 0 subset right-shift C 00 . Coalition superset
MWC Wmin,G losing G, superset C 0 either,
strict left-shift C 0 . follows losing coalition G0 . G0
canonical linear game, desirability relation 1 n satisfied.
left-shift C 0 , C 0 winning G0 , follows winning coalition G0 .
contradiction.
4.3.2 Algorithm Obtaining Ceiling-List Canonical
Weighted Voting Game
Using Hop-Skip-and-Jump algorithm, output polynomial time list
maximal losing coalitions list minimal winning coalitions, given weighted
voting game. Given this, interesting question point whether also output
polynomial time list ceiling coalitions list roof coalitions.
Appendix B, prove impossible general output may
exponentially sized input. Nevertheless, certainly still makes sense try
come efficient possible algorithm problem, considering
algorithm used combination improvements previous section
finding weight vectors weighted voting games. Using algorithm certainly
preferred using Hop-Skip-and-Jump algorithm, canonical linear game
always fewer roof coalitions minimal winning coalitions, fewer ceiling
coalitions maximal losing coalitions.
However, recent construction Polymeris Riquelme (2013) shows outputpolynomial time algorithm problem would sensational consequences, would
12. Related Proposition 2.3 Krohn Sudholter (1995), gives insight maximum number
ceiling coalitions canonical linear game have.

127

fiDe Keijzer, Klos, & Zhang

imply polynomial time algorithm monotone boolean duality problem (Fredman &
Khachiyan, 1996): well-known problem solved sub-exponential time,
known whether admits polynomial time algorithm.
Finding output-polynomial algorithm generating ceiling set game
roof set, thus interesting open problem, due alleged difficulty13
instead resort studying problem outputting ceiling set game set
minimal winning coalitions.
course, one could simply solve latter problem using Hop-Skip-and-Jump
algorithm. would provide us list MLCs input game,
could filter ceilings. algorithm would run O(nm2 + n3 m) time,
number MWCs. Below, provide alternative simpler algorithm
special case need output ceilings given game. remainder
section, use following definitions.
Definition 10. Let N set players {1, . . . , n} let N coalition.
functions b trunc defined follows.
b(S) highest-numbered player S.
a(S) highest-numbered player j N \ j + 1 (if j
exist, define a(S) = 0).
truncation S, defined trunc(S) = \ {a(S) + 1, . . . , n}.
example, N = {1, 2, 3, 4, 5} = {1, 2, 4}, highest numbered player
b(S) = 4, N \ = {3, 5}, highest numbered player j N \ j + 1
a(S) = 3, trunc(S) = \ {4, 5} = {1, 2}. = {1, 2, 3} N \ = {4, 5},
exists j N \ j + 1 S, a(S) = 0.
Theorem 7. Let G Gclin (n) canonical linear game players N = {1, . . . , n}, let
Wmin,G Gs set MWCs, let C set ceilings G, let C C
a(C) > 0. exists N0 , 1 < |C| |trunc(C)|, trunc(C)
{a(C)} {a(C) + j : 2 j i} minimal winning coalition.
Proof. coalition C ceiling, losing, implies trunc(C) also losing,
trunc(C) {b(C)} {b(C) + j : 2 j |C| |trunc(C)|} left-shift C, hence
winning. Therefore exists N0 , 2 |C| |trunc(C)|
(C 0 := trunc(C) {a(C)} {a(C) + j : 0 j i} winning)
(C 00 := trunc(C) {a(C)} {a(C) + j : 2 j 1} losing) (C 00 = C 0 ).
canonicity, means C 0 minimal winning coalition.
theorem becomes clear efficiently generate set ceilings
set minimal winning coalitions: MWC S, suffices check
k N0 , k n b(S) whether:
13. thank Andreas Polymeris Fabian Riquelme pointing us connection monotone
boolean duality problem, well pointing error preliminary version present paper.

128

fiFinding Optimal Solutions Voting Game Design Problems

(S \ {a(S) 1}) {a(S)} {b(S) + j : 1 j k} ceiling (in case a(S) 1 S),
(S \ {b(S)}) {b(S) + j : 1 j k} ceiling.
would generate ceilings C property b(C) > 0. furthermore
n ceilings C holds b(C) = 0, clear coalitions
generated checked straightforwardly.
runtime implied algorithm theoretically better Hop-Skip-andJump algorithm. However, due simplicity algorithm, due fact
algorithm finds ceilings (of general far less
MWCs), expect algorithm run much faster practice, cases.

5. Experiments
implemented Algorithm 1 together optimization strategies described
Section 4.3, allow us work ceiling coalitions, rather maximal losing coaltions. programming language used C. Execution algorithm
involves solving large number linear programs. this, made use GNU Linear Programming Toolkit (see Makhorin, 2004). implementation solves normalized
Banzhaf index weighted voting game design problem. means weighted
voting game output enumeration algorithm, must invoke procedure
computing normalized Banzhaf index. algorithm used simply naive
brute-force approach. (In experiments, runtime Banzhaf computation (to three
decimal places) different runtime without four players more.
eight players, including computation Banzhaf indices never increases runtime
0.6%.)
purpose experiments gain insight average optimal attainable
error random instances (for small n), well number weighted voting games
function number players number minimal winning coalitions.
Experiment 1. used enumeration algorithm compute n 1 n 8
n
0 bn/2c
, exact number canonical weighted voting games
n players minimal winning coalitions. results displayed Figure 3. Note
vertical axis log-scale. see choices n,
canonical weighted voting games relatively small number minimal winning

n
coalitions relative maximum possible number winning coalitions, bn/2c
.
Experiment 2. n 1 7, computed 1000 random instances
average optimal error. is, average error attained 1000 random
instances (i.e., uniform random vectors (n 1)-dimensional unit-simplex restricted
non-increasingness constraint) algorithm allowed run completion
instances. also report worst error attained among 1000 instances.
error function used square root sum squared errors. reason
using specific error measure nice geometric interpretation:
Euclidean distance target (input) vector closest point unit
simplex normalized Banzhaf index weighted voting game.

129

fiDe Keijzer, Klos, & Zhang

Figure 4, see errors decrease n gets larger. confirms
observation Alon Edelman (2010) number voters small,
clear one closely approximate every power vector. main result
paper states target vector lot weight concentrated strict subset
players, exists game Banzhaf vector close target. study
random vectors, still see general phenomenon number players
increases, exist games probability one close
target increases. also see worst case optimal error much worse
average case. expected, Alon Edelman show n, exist vectors
standard n-simplex approximated well. results computed
1000 random instances. Therefore, worst case optimal errors serve
lower bound worst case optimal error possible instances.
noted preliminary work (De Keijzer, Klos, & Zhang, 2012),
even earlier preliminary work (De Keijzer, 2009a), additional experiments reported:
Firstly, used implementation (respectively early version implementation)
find number weighted voting games n players, 1 n 8. However,
independent work (Kurz, 2012b) already published, authors compute
numbers 1 n 9 (using incomparable techniques). Secondly, experiments
performed order study time performance algorithm errorconvergence algorithm larger numbers players. omit experiments
(see De Keijzer et al., 2012, results) give short summary instead:
outcome experiments surprising line theoretical runtime
analysis previous section. runtime graph indeed looks like quadratic function,
shown log-scale. mentioned, computing Banzhaf index constitutes
fraction total runtime. error-convergence algorithm slow already
15 players, therefore algorithm practical number players
big, expected.14

6. Conclusions Future Work
paper, developed exact algorithm solving power index weighted voting
game design problems. First, derived doubly exponential algorithm large class
monotonic simple games. Subsequently, showed possible obtain (singly)
exponential algorithm important special case weighted voting games.
core algorithms methods enumerating weighted voting games
based new partial order class weighted voting games specific
interesting properties. enumeration algorithm resulting this, best
knowledge first enumeration algorithm weighted voting games provably runs
output-polynomial time.
algorithm works families minimal winning coalitions. demonstrated
possible improve runtime algorithm showing suffices work
subset minimal winning coalitions: i.e., roof coalitions. Using
idea, provided various techniques improve algorithm. Among improvements
14. detailed discussion results experiments, see work De Keijzer et al.
(2012).

130

fiFinding Optimal Solutions Voting Game Design Problems

# 1 player CWVGs MWCs
# 2 player CWVGs MWCs
# 3 player CWVGs MWCs
# 4 player CWVGs MWCs
# 5 player CWVGs MWCs
# 6 player CWVGs MWCs
# 7 player CWVGs MWCs
# 8 player CWVGs MWCs

Number canonical WVGs MWCs

100000

10000

1000

100

10

1
0

10

20

30

40

50

60

70

80

Number minimal winning coalitions

Figure 3: number canonical weighted voting games (y-axis) n players, 1 n
8, minimal winning coalitions (x-axis).

0.35

Maximal Euclidean error 1000 random instances
Average Euclidean error 1000 random instances

0.3

Error (Euclidean distance)

0.25

0.2

0.15

0.1

0.05

0
1

2

3

4

5

6

7

Number players

Figure 4: Optimal Euclidean error 1000 random n player instances, 1 n 7.
error bars indicate one standard deviation.

131

fiDe Keijzer, Klos, & Zhang

output-polynomial time algorithm outputting list ceiling coalitions linear
game, given list roof coalitions.
addition, implemented aforementioned enumeration algorithm weighted
voting games measure performance, obtained interesting data class
weighted voting games, validated theoretical results related weighted voting
games.
algorithm based enumeration procedure class weighted voting
games: works simply enumerating every game, verifying game whether
lies closer target power index games encountered
point. reason, algorithm anytime-property: run algorithm
longer period time, algorithm enumerates games quality
solution improve, algorithm guaranteed output optimal solution
long run.
choice normalized Banzhaf index implementation previous
section arbitrary: algorithm works choice power index. Moreover, due
genericity enumeration, use algorithm solve power index
voting game design problems, also voting game design problem.
thing adapt error-function algorithm (i.e., part algorithm
checks property question games enumeration procedure
outputs); enumeration procedure need changed.
future work, note real-life examples, number players
weighted voting game rather small: usually 10 50 players involved. Thus, one
goals get proposed algorithm yield good results within reasonable
amount time number players somewhere range. would already
interesting able solve problem ten players, aware
enumerations ten player canonical weighted voting games. However, concluded
current implementation algorithm yet fast enough able handle
ten players. Optimistic extrapolation tells us would take tens years; pessimistic
extrapolation gives us thousands years. However, current implementation really
efficient, hope future insights, together careful computer
programming, enumerating weighted voting games ten players within
scope. One way improve current algorithm study depth partial
order introduced paper. One possible prospect following. regard
weighted voting game design problems, suspect possible prune lot
areas partial order: Careful analysis partial order properties might
lead results allow us construct enumeration algorithm priori discards
certain (hopefully large) subsets weighted voting games.
moreover interested see algorithm performs searches
partial order greedy manner, happen use (possibly
heuristic) intelligent methods search partial order. First steps
direction taken Kleijn (2012). wonder possible use search method
still optimality guarantee approximation guarantee quality
solution. addition, also consider ideas presented postprocessing step
existing algorithms. words, might good idea first run algorithm
Fatima et al. (2008) Aziz et al. (2007) order obtain good initial game. Subse132

fiFinding Optimal Solutions Voting Game Design Problems

quently, try search neighborhood game find improvements,
according partial order introduced paper.
Lastly, related questions would interesting obtain answer
computational complexity power index voting game design problem,
also polynomial-time-approximability problem. quite straightforward
see decision version problem cases NP#P (and therefore
PSPACE), one could nondeterministically guess weight vector, subsequently
use #P-oracle obtain particular power index interest.15 hand,
moment ideas prove hardness problem
complexity class whatsoever. seems challenge come polynomial-time
reduction known computational problem hard nontrivial complexity
class.

Acknowledgments
thank Fabian Riquelme Andreas Polymeris pointing problem preliminary version paper (see Section 4.3.2). thank anonymous referees
extensive feedback, comments suggestions. extended version paper
published proceedings 2010 International Conference Autonomous Agents
Multi-Agent Systems (De Keijzer, Klos, & Zhang, 2010). research partially supported EU FET project MULTIPLEX 317532, ERC StG Project PAAI 259515,
Google Research Award Economics Market Algorithms. majority
research carried first author masters student Delft
University Technology. part research carried first author
Ph.D. student Centrum Wiskunde & Informatica (CWI), Amsterdam.

Appendix A. Number Weighted Voting Games
knowledge, existing game theory literature provide us insights
number weighted voting games n players, beyond n = 5. Fortunately
closely related field research, called threshold logic (see example Muroga, 1971),
relevant results.
Definition 11 (Boolean threshold function, realization, LT). Let f boolean function
n boolean variables. function f (boolean) threshold function exists
weight vector real numbers r = (r0 , r1 , . . . rn ) Rn+1 r1 x1 + + rn xn r0
f (x1 , . . . , xn ) = 1. say r realizes f . denote set threshold
functions n variables {x1 , . . . , xn } LT(n).16
Threshold functions resemble weighted voting games, except talk boolean variables instead players now. Also, important difference threshold functions
weighted voting games r0 , r1 , . . . , rn allowed negative threshold functions, whereas q, w1 , . . . , wn , must non-negative weighted voting games.
15. power indices proposed encountered known #P.
16. LT stands Linear Threshold function.

133

fiDe Keijzer, Klos, & Zhang

(Zunic, 2004) presents upper bound number threshold functions n vari2
ables: |LT(n)| 2n n+1 . Also, following asymptotic lower bound known (Zuev,
1989): large enough n,
|LT(n)| 2

10
n2 (1 log
)
n

.

(4)

bounds, deduce easy upper lower bounds |Gwvg |. First
observe following property set threshold functions n variables. Let
LT+ (n) set non-negative threshold functions variables (x1 , . . . , xn ), containing
threshold functions f LT(n) exists non-negative weight vector r
2
realizes f . Then, clear |Gwvg (n)| = |LT+ (n)| 2n n+1 n.
proceed obtaining lower bound number weighted voting games.
Corollary 1. large enough n, holds
|Gwvg (n)| 2

10
n2 (1 log
)n1
n

Proof. Let f non-negative threshold function let r non-negative weight vector
realizes f . 2n+1 possible ways negate elements r,
2n+1 1 threshold functions f 0 LT(n) \ LT+ (n) f 0 realization
obtained negating elements r. this, follows |LT+ (n)| |LT(n)|
,
2n+1
thus also |Gwvg (n)| | LT(n)
|. using (4) get |Gwvg (n)|
2n+1
2

10
n2 (1 log
)n1
n

n2 (1 10 )
log n
2n+1

2

=

.

next question is: canonical case, Gcwvg (n)? set Gcwvg (n)
subset Gwvg (n), noncanonical weighted voting game exists permutation players makes canonical one. Since n! possible permutations,
|G (n)|
must |Gcwvg (n)| wvgn! , thus obtain
|Gcwvg (n)|

2

10
n2 (1 log
)n1
n

n!

(5)

large enough n.

Appendix B. Generating Roofs Ceilings
section, answer question whether possible generate polynomial time
list ceiling coalitions linear game list roof coalitions: turns
case. give family examples canonical linear games
number roof coalitions exponential n, number ceiling coalitions
polynomial n. consequence, algorithm generates list roofs
list ceilings run exponential time worst case. symmetry also follows
generating list roof coalitions list ceiling coalitions possible
polynomial time.
Let us first define following specific type coalition.

134

fiFinding Optimal Solutions Voting Game Design Problems

Definition 12 ((k, i)-encoding coalition). Let N = {1, . . . , n} set players
n = 4i N. k satisfying 0 k < 2i 1, (k, i)-encoding coalition
Sk,i N defined
{4(j 1) + 2, 4(j 1) + 3 : jth bit binary representation k 0}
{4(j 1) + 1, 4(j 1) + 4 : jth bit binary representation k 1}
example, S2,2 = {1, 4, 6, 7}, S5,3 = {1, 4, 6, 7, 9, 12}. define canonical linear games roof coalitions (k, i)-encoding coalitions.
Definition 13 (i-bit roof game). Let N = {1, . . . , n} set players n = 4i
N. i-bit roof game N , denoted Gibit , canonical linear game
set roof coalitions G {S0,i , . . . , S2i 1,i }.
example, 2-bit roof game, G2bit , consists roofs {{2, 3, 6, 7}, {2, 3, 5, 8},
{1, 4, 6, 7}, {1, 4, 5, 8}}. Gibit well-defined binary representations
two arbitrary i-bit numbers k k 0 differ least one bit. Therefore, Si,k
superset left-shift Si,k0 hence set roofs defined Gibit
indeed valid set roofs (i.e., two roofs one left-shift
another).
n
game Gibit 2i = 2 4 roofs, i.e., exponential number n. show
number ceilings Gibit polynomially bounded. First let us use following
definitions convenience.
Definition 14 (Accepting roof set). Let G Gclin (n) canonical linear game players
N = {1, . . . , n}. Let C N coalition, let x natural number 1 x |C|,
let D(C, x) x-th desirable player C. accepting set roofs x-th
desirable player C, denoted A(C, x), set consisting roof coalitions R
either x-th desirable player R greater equal D(c, x),
|R| < x.
important observe following fact holds.
Proposition 2. canonical linear game, coalition C winning
T|C|
a=1 A(C, a) 6= .
Proof. lemma fact equivalent statement fact C winning
canonical linear game superset left-shift roof. R
T|C|
a=1 A(C, a) means replacing a-th desirable player R a-th
desirable player C a,1 R would result left-shift R
subset C, C must winning.
Conversely, suppose C winning. must roof R right-shift
subset C. removing C players higher number D(C, |R|),
obtain subset C 0 C |R| players. replacing a-th desirable player C
a-th desirable player R 1 R, obtain right-shift C
R. last step replaced player C 0 higher-numbered player,
T|R|
T|C|
get R a=1 A(C, a). R also a=|R|+1 A(C, a) definition.
135

fiDe Keijzer, Klos, & Zhang

Using notion accepting roof set, prove following technical lemma.
reader recall definition direct left-shift (Definition 4).
Lemma 4. Let C ceiling Gibit two distinct coalitions direct
left-shifts C, let p arbitrary player apply direct left-shift operation on, i.e., let p player C1 = C {p 1} \ {p} direct left-shift C.
Also, let number p = D(C, a). p = 2a.
Proof. Observe b holds every roof R Gibit either D(R, b) = 2b 1
D(R, b) = 2b. construction Gibit , number roofs Gibit contain player


2b 1 22 , number roofs contain player 2b also 22 .
C least two distinct direct left-shifts, must another player p0 , p0 6= p,
C2 = C {p0 1} \ {p0 } direct left-shift C.
First show p 2a. Assume therefore
p > 2a.

|A(C, a)| = 0, |A(C2 , a)| = 0 hence A(C2 , a) = . see C2 losing,
C2 direct left-shift C, ceiling, C2 winning. contradiction,
p 2a.
show p 2a. Assume therefore
p < 2a.

, A(C , a) = 2i . must
|A(C,
a)|
=
2
A(C
,
a)
=
1
1

A(C, a).


A(C,
a)
=


C

losing,

therefore
A(C
,
a)
=


C

losing. C1
1
1


also winning, left-shift ceiling C. contradiction, p 2a.
p 2a p 2a, conclude p = 2a.
Lemma 5. Gibit , ceiling two direct left-shifts.
Proof. contradiction, let C ceiling two direct left-shifts. Let k
number direct left-shifts C, let P = {p1 , . . . , pk } set containing
players C apply direct left-shift operation (we say apply
direct left-shift operation player q C {q 1} \ {q} left-shift C). Let
= {a1 , . . . , ak } numbers pj aj -th desirable player C,
1 j k. j {1, . . . , i} b {0, 1}, let R(j, b) denote
following set roofs Gibit :
R(j, b) = {Sk,i : j-th bit binary representation k b. }
Observe previous lemma, k-tuple bits (b1 , . . . , bk ) {0, 1}k
j 1 j k:
A(C, aj ) = R(dpj /4e, kj ).
two cases:
Case 1: players {p1 , . . . , pk } different multiples 4, i.e., dp1 /4e 6=
dp2 /4e =
6T =
6 dpk /4e.TThen properties binary numbers, intersection aA A(C, a) = pP R(dp/4e, b) empty, therefore C must winning,
contradiction C ceiling. case impossible.

136

fiFinding Optimal Solutions Voting Game Design Problems

Case 2: two distinct players p p0 , P , multiple
4, i.e., dp/4e = dp0 /4e. Assume without loss generality p < p0 .
A(C, a) A(C, a0 ) = . would able apply direct left-shift
player p00 without turning C winning coalition, i.e., C {p00 1} \ {p00 }
winning. C ceiling, contradiction.
previous lemma follows two players
multiple 4, two cases indeed exhaustive. cases
impossible, must reject assumption exists ceiling C
two left-shifts.
easy see exist O(n5 ) coalitions exactly two leftshifts, O(n3 ) coalitions one left-shift,
O(n) coalitions left-shifts. get following corollary.
Corollary 2. game Gibit (on n = 4i players) O(n5 ) ceilings.
conclude {Gibit : N} infinite family examples
exponentially many roofs ceilings. Hence, finally obtain:
Corollary 3. polynomial time algorithm generates list ceilings
linear game list roofs. polynomial time algorithm generates
list roofs linear game list ceilings.

References
Algaba, E., Bilbao, J. M., Garca, J. R. F., & Lopez, J. J. (2003). Computing power indices
weighted multiple majority games. Mathematical Social Sciences, 46, 6380.
Alon, N., & Edelman, P. H. (2010). inverse Banzhaf problem. Social Choice
Welfare, 34 (3), 371377.
Aziz, H. (2008). Complexity comparison influence players simple games. Proceedings 2nd International Workshop Computational Social Choice (COMSOC), pp. 6172.
Aziz, H., Paterson, M., & Leech, D. (2007). Efficient algorithm designing weighted voting
games. Proceedings IEEE International Multitopic Conference, pp. 16.
Banzhaf III, J. (1965). Weighted voting doesnt work: mathematical analysis. Rutgers
Law Review, 19 (2), 317343.
De, A., Diakonikolas, I., Feldman, V., & Servedio, R. A. (2012a). Nearly optimal solutions
Chow parameters problem low-weight approximation halfspaces.
Proceedings 44th Symposium Theory Computing, pp. 729746.
De, A., Diakonikolas, I., & Servedio, R. (2012b). inverse Shapley value problem.
Czumaj, A., Mehlhorn, K., Pitts, A., & Wattenhofer, R. (Eds.), Automata, Languages,
Programming, Vol. 7391 Lecture Notes Computer Science, pp. 266277.
Springer.

137

fiDe Keijzer, Klos, & Zhang

Deng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Mathematics Operations Research, 19 (2), 257266.
Dubey, P., & Shapley, L. S. (1979). Mathematical properties Banzhaf power index.
Mathematics Operations Research, 4 (2), 99131.
Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2008). anytime approximation method
inverse Shapley value problem. Proceedings Seventh International
Joint Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp.
935942.
Fredman, M. L., & Khachiyan, L. (1996). complexity dualization monotone
disjunctive normal forms. Journal Algorithms, 21 (3), 618628.
Freixas, J., & Kurz, S. (2011). minimal integer representations weighted games.
CoRR, abs/1303.0868.
Freixas, J., & Kurz, S. (2013a). Enumeration weighted games minimum
analysis voting power bipartite complete games minimum. Annals
Operations Research, Online first.
Freixas, J., & Kurz, S. (2013b). golden number Fibonacci sequences design
voting structures. European Journal Operational Research, 226 (2), 246257.
Freixas, J., & Molinero, X. (2008). greatest allowed relative error weights
threshold strict separating systems. IEEE Transactions Neural Networks, 19 (5),
770781.
Freixas, J., & Molinero, X. (2010). Weighted games without unique minimal representation
integers. Optimization Methods Software, 25 (2), 203215.
Freixas, J., Molinero, X., & Roura, S. (2012). Complete voting systems two classes
voters: weightedness counting. Annals Operations Research, 193 (1), 273289.
Hu, S. (1965). Threshold logic. University California Press.
Isbell, J. R. (1958). class simple games. Duke Mathematical Journal, 25 (3), 423439.
Karmarkar, N. (1984). new polynomial-time algorithm linear programming. Proceedings sixteenth annual ACM Symposium Theory computing (STOC),
pp. 302311.
De Keijzer, B. (2009a). design synthesis voting games: exact solutions
inverse problem. Masters thesis, Delft University Technology.
De Keijzer, B. (2009b). survey computation power indices. Tech. rep., Delft
University Technology.
De Keijzer, B., Klos, T., & Zhang, Y. (2010). Enumeration exact design weighted
voting games. Proceedings 9th International Conference Autonomous
Agents Multiagent Systems (AAMAS), pp. 391398.
De Keijzer, B., Klos, T., & Zhang, Y. (2012). Solving weighted voting game design problems
optimally: Representations, synthesis, enumeration. CoRR, abs/1204.5213.
Kleijn, A. (2012). Weighted voting game design heuristics. Masters thesis, Erasmus School
Economics, Erasmus University Rotterdam.
138

fiFinding Optimal Solutions Voting Game Design Problems

Kleitman, D., & Markowski, M. (1975). Dedekinds problem: number isotone
boolean functions II. Transactions American Mathematical Society, Vol. 213,
pp. 373390.
Klinz, B., & Woeginger, G. J. (2005). Faster algorithms computing power indices
weighted voting games. Mathematical Social Sciences, 49, 111116.
Korshunov, A. D. (2003). Monotone boolean functions. Russian Mathematical Surveys,
58 (5), 198162.
Krohn, I., & Sudholter, P. (1995). Directed weighted majority games. Mathematical
Methods Operations Research, 42 (2), 189216.
Kurz, S. (2012a). minimum sum representations weighted voting games. Annals
Operations Research, 196 (1), 361369.
Kurz, S. (2012b). inverse power index problem. Optimization, 61 (8), 9891011.
Laruelle, A., & Widgren, M. (1998). allocation voting power among EU states
fair?. Public Choice, 94, 317339.
Leech, D. (2002a). Computation power indices. Tech. rep. 664, Warwick Economic
Research Papers.
Leech, D. (2002b). Designing voting system EU Council Ministers. Public
Choice, 113 (34), 437464.
Leech, D. (2002c). Voting power governance International Monetary Fund.
Annals Operations Research, 109, 373395.
Leech, D. (2003). Power indices aid institutional design: generalised apportionment problem. Holler, M., Kliemt, H., Schmidtchen, D., & Streit, M. (Eds.),
European Governance, No. 22 Jahrbuch fur Neue Politische Okonomie, pp. 107121.
Mohr Siebeck.
Makhorin, A. (2004). GNU linear programming toolkit..
Matsui, Y., & Matsui, T. (2001). NP-completeness calculating power indices weighted
majority games. Theoretical Computer Science, 263 (12), 305310.
McKay, B. D. (1998). Isomorph-free exhaustive generation. Journal Algorithms, 26,
306324.
Muroga, S. (1971). Threshold logic applications. Wiley-Interscience.
Muroga, S., Toda, I., & Kondo, M. (1962). Majority functions six variables.
Mathematics Computation, 60 (80), 459472.
Muroga, S., Tsuboi, T., & Baugh, C. R. (1970). Enumeration threshold functions eight
variables. IEEE Transactions Computers, C-19 (9), 818825.
De Nijs, F., Wilmer, D., & Klos, T. (2012). Evaluation improvement LaruelleWidgren inverse Banzhaf approximation. Proceedings Benelux AI Conference
(BNAIC), pp. 194201.
ODonnell, R., & Servedio, R. A. (2011). Chow parameters problem. SIAM Journal
Computing, 40 (1), 165199.
139

fiDe Keijzer, Klos, & Zhang

Parberry, I. (1994). Circuit complexity neural networks. Mit Press.
Peled, U. M., & Simeone, B. (1985). Polynomial-time algorithms regular set-covering
threshold synthesis. Discrete Applied Mathematics, 12, 5769.
Peleg, B., & Sudholter, P. (2003).
Springer.

Introduction Theory Cooperative Games.

Polymeris, A., & Riquelme, F. (2013). complexity decisive problem simple,
regular weighted games. CoRR, abs/1303.7122.
Prasad, K., & Kelly, J. S. (1990). NP-completeness problems concerning voting
games. International Journal Game Theory, 19 (1), 19.
Shapley, L. S., & Shubik, M. (1954). method evaluating distribution power
committee system. American Political Science Review, 48 (3), 787792.
Siu, K., Roychowdhury, V., & Kailath, T. (1995). Discrete Neural Computation: Theoretical Foundation. Prentice Hall.
Sperner, E. (1928). Ein Satz uber Untermengen einer endlichen Menge. Mathematische
Zeitschrift, 27 (1), 544548.
Sutter, M. (2000). Fair allocation re-weighting votes voting power EU
next enlargement. Journal Theoretical Politics, 12, 433449.
Taylor, A. D., & Zwicker, W. S. (1999). Simple Games: Desirability Relations, Trading,
Pseudoweightings. Princeton University Press.
Winder, R. O. (1965). Enumeration seven-argument threshold functions. IEEE Transactions Electronic Computers, EC-14 (3), 315325.
Zuev, Y. A. (1989). Asymptotics logarithm number threshold functions
algebra logic. Soviet Math. Dokl., 39, 512513.
Zunic, J. (2004). encoding enumerating threshold functions. IEEE Transactions
Neural Networks, 15 (2), 261267.

140

fiJournal Artificial Intelligence Research 50 (2014) 31-70

Submitted 08/13; published 05/14

Knowledge Forgetting Answer Set Programming
Yisong Wang

CSC . YSWANG @ GZU . EDU . CN

Department Computer Science,
Guizhou University, Guiyang, China

Yan Zhang
Yi Zhou

YAN @ SCEM . UWS . EDU . AU
YZHOU @ SCEM . UWS . EDU . AU

Artificial Intelligence Research Group,
University Western Sydney, Australia

Mingyi Zhang

ZHANGMINGYI 045@ GMAIL . COM

Guizhou Academy Sciences, Guiyang, China

Abstract
ability discarding hiding irrelevant information recognized important
feature knowledge based systems, including answer set programming. notion strong
equivalence answer set programming plays important role different problems gives
rise substitution principle amounts knowledge equivalence logic programs.
paper, uniformly propose semantic knowledge forgetting, called HT- FLP-forgetting,
logic programs stable model FLP-stable model semantics, respectively. proposed
knowledge forgetting discards exactly knowledge logic program relevant forgotten variables. Thus preserves strong equivalence sense strongly equivalent logic
programs remain strongly equivalent forgetting variables. show
semantic forgetting result always expressible; prove representation theorem stating
HT- FLP-forgetting precisely characterized Zhang-Zhous four forgetting postulates HT- FLP-model semantics, respectively. also reveal underlying connections
proposed forgetting forgetting propositional logic, provide complexity
results decision problems relation forgetting. application proposed forgetting
also considered conflict solving scenario.

1. Introduction
Motivated Lin Reiters seminal work (Lin & Reiter, 1994), notion forgetting propositional first-order logics distilling knowledge base part relevant
subset alphabet attracted extensive interests KR community, (e.g., see Lang
& Marquis, 2010; Zhou & Zhang, 2011). recent years, researchers developed forgetting
notions theories non-classical logic systems various perspectives, forgetting description logics (Kontchakov, Wolter, & Zakharyaschev, 2008; Wang, Wang, Topor, &
Pan, 2010; Lutz & Wolter, 2011; Packer, Gibbins, & Jennings, 2011), forgetting logic programs
(Zhang & Foo, 2006; Eiter & Wang, 2008; Wong, 2009; Wang, Wang, & Zhang, 2013), forgetting modal logic (Zhang & Zhou, 2009; Su, Sattar, Lv, & Zhang, 2009; van Ditmarsch, Herzig,
Lang, & Marquis, 2009; Liu & Wen, 2011). logical notion, forgetting also studied
different terms variable elimination (Lang, Liberatore, & Marquis, 2003), irrelevance, independence, irredundancy, novelty, separability (Bobrow, Subramanian, Greiner, &
c
2014
AI Access Foundation. rights reserved.

fiWANG , Z HANG , Z HOU , & Z HANG

Pearl, 1997). shown study modeling agents behaviors, forgetting plays
important role conflict resolution (Zhang & Foo, 2006; Lang & Marquis, 2010).
propositional logic, result forgetting atom p formula , written Forget(, {p}),
formula [p/] [p/>], [p/] [p/>] formula obtained replacing occurrence atom p (false) > (true) respectively. Forgetting set atoms
formula defined Forget(, V {p}) = Forget(Forget(, {p}), V ) (Lin, 2001).
easy see forgetting preserves logical equivalence. is, logically equivalent formulas
(theories) remain logically equivalent forgetting atoms. well known that,
mention atoms V
|= iff Forget(, V ) |= .
sense forgetting propositional logic, called propositional forgetting, knowledge
forgetting since Forget(, V ) exactly contains logical content irrelevant V .
logic programs stable model/answer set semantics (Gelfond & Lifschitz, 1988), issue logical equivalence rather complicated due different notions equivalence: (weak)
equivalence strong equivalence. Two logic programs 1 2 (weakly) equivalent
1 2 stable models; 1 2 strongly equivalent
1 2 equivalent every logic program . well known strong equivalence important concept answer set programming (ASP), amounts knowledge
equivalence captures logical content logic program (Osorio & Zacarias, 2004; Osorio
& Cuevas, 2007; Delgrande, Schaub, Tompits, & Woltran, 2013), used simplifying
logic programs two strongly equivalent rules may interchangeable without affecting
original logic programs stable models (Pearce, Tompits, & Woltran, 2001; Ferraris, Lee, & Lifschitz, 2011; Lin & Chen, 2007; Lin & Zhou, 2011). strong equivalence characterized
logic here-and-there (HT), viz, two logic programs strongly equivalent
HT-models (Lifschitz, Pearce, & Valverde, 2001). instance, rule following form p p HT-models > (tautology), arbitrary
formula. Thus safely removed every logic programs without changing stable
models.
Besides stable model/answer set semantics logic programs (Gelfond & Lifschitz, 1988),
FLP-stable model semantics also steadily gains importance (Faber, Pfeifer, & Leone, 2011;
Truszczynski, 2010). notion strong equivalence similarly generalized logic programs
FLP-stable models semantics: two theories 1 2 strongly FLP-equivalent
1 2 FLP-stable models every logic program . shown
strong equivalence characterized terms FLP-models, viz, two logic programs
strongly FLP-equivalent FLP-models (Truszczynski, 2010).
develop notion forgetting logic programs, preserving strong equivalence
important, like propositional forgetting preserves equivalence propositional logic. Consider two agents need achieve agreement certain goal, agents knowledge
base represented logic program. Suppose two consistent1 logic programs,
combination inconsistent. achieve consistent combination, one may forget atoms
logic programs, combination forgetting results consistent.
forgetting may effectively used solve conflict two agents knowledge
1. logic program consistent stable models.

32

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

bases (Zhang & Foo, 2006; Eiter & Wang, 2008; Lang & Marquis, 2010). purpose simplicity, hand, agents may also replace knowledge bases strongly equivalent
syntactically simpler ones.
Let us consider simple Yale Shooting scenario logic program consisting
following rules:2
shoot aux;

aux shoot;

aux, shoot.

aux used generate possible occurrences action shoot. One interested
logic program represents knowledge auxiliary atom aux ignored.
intuitively results logic program 0 consisting rule3 :
shoot shoot,
captures exactly knowledge irrelevant aux. see 0
obtained HT-forgetting aux (cf. Example 5 atom names), cannot
obtained terms previous forgetting approaches logic programming (cf. Example 11).
turns preserving strong equivalence forgetting challenging.
several attempts define notion forgetting logic programs, none approaches
fully satisfactory. Zhang Foo (2006) first defined syntax oriented weak strong forgetting
notions normal logic programs. forgetting notions preserve neither (weak) equivalence
strong equivalence. Eiter Wang (2008) proposed semantic forgetting consistent
disjunctive logic programs, preserves equivalence strong equivalence. specifically indicated importance preserving strong equivalence logic programming forgetting
raised issue future work. Wong (2009) proposed two forgetting operators disjunctive logic programs. Although two operators indeed preserve strong equivalence, may lose
intuition weakening various circumstances (see Section 5 details). recently proposed
forgetting logic programs may introduce extra knowledge (cf., see Wang et al., 2013, Ex. 2).
Thus knowledge forgetting.
Together preserving strong equivalence, expressiveness another desired criterion
logic programming forgetting. Ideally would expect result forgetting atoms
logic program still expressible logic program. particularly necessary
view agents knowledge bases logic programs forgetting employed means conflict
solving among agents knowledge bases (Zhang & Foo, 2006). previous logic programming forgetting approaches meet criterion, see paper, consider
forgetting arbitrary logic programs, retaining expressibility challenging objective achieve
semantic forgetting notion.
Finally, believe way weakening, knowledge forgetting logic programs
obey common intuitions shared forgetting classical logics. instance, forgetting
something logic program lead weaker program certain sense.
hand, weakening associated relevant information forgotten.
purpose, Zhang Zhou (2009) proposed four forgetting postulates formalize
common intuitions showed forgetting propositional logic modal logic S5
precisely captured postulates. Surprisingly, none previous forgetting notions logic
2. due one anonymous reviewers.
3. rule strongly equivalent choice rule 0{shoot}1 normal rule.

33

fiWANG , Z HANG , Z HOU , & Z HANG

programs actually satisfies Zhang-Zhous postulates. sense previous forgetting notions
logic programs knowledge forgetting operators.
summary, consider following criteria knowledge forgetting notion logic programs meet:
Expressibility. result forgetting arbitrary logic program also expressible via logic program;
Preserving strong equivalence. Two strongly equivalent logic programs remain strongly
equivalent forgetting variables;
Satisfying common intuitions forgetting. Preferably, forgetting logic programs
semantically characterized Zhang-Zhous four forgetting postulates.
paper present comprehensive study knowledge forgetting context arbitrary logic programs (propositional theories) stable model FLP-stable models semantics,
called HT- FLP-forgetting respectively. show HT- FLP-forgetting meet
criteria, hence primary advantages compared previous logic program forgetting
notions.
main contributions paper may summarized follows, ? {HT, FLP },
- starting point, investigate model theoretical characterization strong equivalence logic programs stable model FLP-stable model semantics, explore
strong equivalence equivalence propositional logic.
- propose semantic ?-forgetting logic programs ?-stable model semantics respectively. HT-stable model means stable model. ?-forgetting result always
expressible via logic program preserves strong equivalence stable model
FLP-stable model semantics.
- investigate semantic properties ?-forgetting, show ?-forgetting satisfies
Zhang-Zhous four postulates ?-model respectively. particular, forgetting
result consists logical content irrelevant forgotten atoms.
- establish underlying connections ?-forgetting propositional forgetting,
based provide complexity results decision problems relation ?forgetting. particular, show resulting checking deciding logic program
result ?-forgetting set atoms logic program P2 -complete, related
inference problem terms ?-forgetting varies co-NP-complete P2 -complete.
theoretical negative results confirm easy task simplify logic programs
forgetting. fortunately, kind simplification computed offline general.
instance, problem domain description involves lot auxiliary propositional variables.
One firstly simplify description forgetting (part of) auxiliary propositional
variables, like kind compilation (Lang et al., 2003).
- Finally consider application knowledge forgetting solving conflicts
context logic programming.
34

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

rest paper organized follows. Section 2 briefly reviews necessary concepts
notions answer set programming. Section 3 presents characterizations strong equivalence
logic programs. firstly present uniform definition knowledge forgetting logic
programs section 4, explore expressibility, forgetting postulates, relationship
propositional forgetting, computational complexity application knowledge forgetting
conflict solving. Section 5 discusses forgetting approaches logic programs, finally,
Section 6 concludes paper remarks. proofs paper deferred
Appendix clarity.
paper revised extended version paper appeared Proceedings KR
2012 (Wang, Zhang, Zhou, & Zhang, 2012).

2. Answer Set Programming
section briefly recall basic notions logic programming stable model semantics, including syntax, reduction, stable model (Ferraris, 2005) FLP-stable models (Truszczynski, 2010) strong equivalence (Lifschitz et al., 2001; Truszczynski, 2010). paper stable
model called HT-stable model convenience, assume ? {HT , FLP }.
assume propositional language LA finite set propositional atoms,
called signature language LA .
2.1 Syntax
formulas LA built signature4 0-place connective (false) using
binary connectives , follows:
::= | p | | |

(1)

p A. > (true) shorthand , , ( ) (
). theory set formulas.
interpretation set atoms A, atom viewed true
I, false otherwise. propositional logic, notions model satisfaction relation |=
defined usual. following denote \ X X X A, Mod() {M |M |= },
/ M}
Mod() = Mod() (i.e. equivalent ) {I A|I

2 . formula irrelevant set V atoms, written IR(, V ), exists formula
mentioning atoms V .
convenience,

W
V also define following notations. Let finite set formulas.
W
denote SV(resp.
S) disjunction (resp. conjunction) formulas S,
denotes denotes >, |S| cardinality S. Similarly (resp. S) mean
{ | S} (resp. { | S}).
2.2 Reduct Stable Models
Let formula X A. ?-reduct w.r.t. X, written Red? (, X), recursively
uniformly defined follows:
4. rest paper, whenever confusion, may explicitly mention signature talk
formulas LA .

35

fiWANG , Z HANG , Z HOU , & Z HANG

(?-R1) Red? (, X) = ;
(?-R2) Red? (p, X) = p X |= p, otherwise;
(?-R3) Red? (1 2 , X) = Red? (1 , X) Red? (2 , X) X |= 1 2 {, },
otherwise;
(HT-R4) RedHT (1 2 , X) = RedHT (1 , X) RedHT (2 , X) X |= 1 2 , otherwise;

1 RedFLP (2 , X), X |= 1 2 ;
(FLP-R4) RedFLP (1 2 , X) =
>,
X 6|= 1 ;

,
otherwise (i.e. X 6|= 1 2 ).

Definition 1 set X ?-stable model formula X minimal (under set inclusion)
model Red? (, X). denote set ?-stable models SM ? ().
Please note that, traditionally, HT-reduct named reduct; Red HT (, X) written X ;
HT-stable model called stable model (Ferraris, 2005); RedFLP (, X) written X
(Truszczynski, 2010).
known that, HT-stable models FLP-stable models comparable sense
HT-stable models FLP-stable models, FLP-stable models HT-stable
models (cf., see Truszczynski, 2010, Exs. 1, 2, 4 5).
Example 1 Let us consider following formulas:
Let = p p p.
RedHT (, ) , RedHT (, {p}) >, RedFLP (, ) , RedHT (, {p}) p.
Thus SM HT () = , SM FLP () = {{p}}.
Let 1 = p p 2 = p p. following:
RedHT (i , ) > RedHT (i , {p}) p, = 1, 2,
RedFLP (1 , ) >, Red FLP (1 , {p}) p, RedFLP (2 , ) >, RedFLP (2 , {p}) >.
Thus, SM FLP (1 ) =

SM HT (1 )

= {, {p}}, SM FLP (2 ) = {}.

Definition 2 Two formulas 1 2 ?-SM -equivalent (under ?-stable model semantics), written 1 ?SM 2 , iff ?-stable models.
notion HT-SM -equivalence indeed notion equivalence logic programs
stable model semantics (cf., see Lifschitz et al., 2001, Thm. 1).
36

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

2.3 Strong Equivalence Knowledge Logic Programs
Unlike equivalence propositional logic, equivalence logic programs allow
equivalent replacement i.e., 1 2 may different stable models, even though 1
2 equivalent.
Example 2 Let 1 = p q 2 = p p. SM ? (1 ) = SM ? (2 ) = {}, 1 2
?-SM-equivalent; however, p 1 ?-stable model {p, q} unique ?-stable model
p 2 {p}. Thus allow replacing 1 2 p 1 . also indicates 1
different knowledge 2 ?-stable model semantics.
motivates notion strong equivalence.
Definition 3 Two formulas 1 2 strongly ?-equivalent (under ?-stable model semantics)
iff 1 ?SM 2 every formula . case 1 2 strongly ?-equivalent,
?-knowledge equivalent.
known notion strong ?-equivalence captured terms ?-models,
?-interpretation pair hX, X A. ?-satisfiability (thus ?-models),
denoted |=? , recursively defined follows:
(?-S1) hX, 6|=? ;
(?-S2) hX, |=? p p X;
(?-S3) hX, |=? 1 2 hX, |=? 1 hX, |=? 2 ;
(?-S4) hX, |=? 1 2 hX, |=? 1 hX, |=? 2 ;
(HT-S5) hX, |=HT 1 2 |= 1 2 ; hX, |=HT 1 implies hX, |=HT 2 ;
(FLP-S5) hX, |=FLP 1 2 |= 1 2 ; 6|= 1 X 6|= 1 hX, |=FLP 2 .
Mod? () denote set ?-models formula . Please note that, ?
either HT FLP . particular, ModHT () (resp. ModFLP ()) denotes set HT-models (resp.
FLP-models) . formulas 1 2 Example 2, one check none h, {p}i,
h{p}, {p}i h{p}, {p, q}i ?-model 1 , every ?-interpretation ?-model 2 .
Definition 4 formula logical ?-consequence formula , written |=? , iff Mod? ()
Mod? (); two formulas ?-equivalent (under ?-model semantics), written ? , iff
Mod? () = Mod? ().
following proposition, item (i) proved Lifschitz, Tang, Turner (cf., see Lifschitz
et al., 1999, (iii) Prop. 6).
Proposition 1 Let A, B, C, set atoms. following
V
W
V
W
(i) (A B) (D C) HT (A B C) D.
V
W
V
W
(ii) (A B) (D C) |=FLP (A B C) D.
37

fiWANG , Z HANG , Z HOU , & Z HANG

Please note inverse (ii) generally hold. instance, p p FLP >
h, {p}i 6|=FLP p p.
Given two formulas 1 2 , known 1 2 strongly HT-equivalent
HT -stable model semantics HT -equivalent, viz. 1 HT 2 ; 1 2
strongly FLP -equivalent FLP -stable model semantics FLP -equivalent,
viz. 1 FLP 2 (cf., see Truszczynski, 2010, Thm. 7). commonly recognized strong
equivalence amounts knowledge equivalence formulas. is, strong ?-equivalence captures
logical content formula ?-stable model semantics (Osorio & Zacarias, 2004; Osorio
& Cuevas, 2007; Delgrande et al., 2013). formally define knowledge logic programs.
Definition 5 ?-knowledge formula ?-stable model semantics, written Cn? (),
consists logical ?-consequence , viz, Cn? () = { | |=? }.
?-knowledge formula stands ?-logical content formula. instance,
CnHT (>) = CnHT (p p) CnHT (p q).
Recall that, ?-model semantics, every formula transformed conjunction
formulas following normal form:
^
_
(B C) (A D)
(2)
A, B, C, sets atoms (cf., ? = HT, see Cabalar & Ferraris, 2007, Thm. 2;
Truszczynski, 2010, Thm. 9 ? = FLP ). is, every formula , conjunction
formulas form (2) strongly ?-equivalent .
formula form (2) called rule, also generally written
a1 ; . . . ; al ; d1 ; . . . ; dn b1 , . . . , bk , c1 , . . . , cm

(3)

= {ai |1 l}, B = {bi |1 k}, C = {ci |1 m} = {di |1 n}.
logic program finite set rules. Let r rule form (2). said
disjunctive = ;
positive C = = ;
normal |A| 1 = ;
Horn |A| 1 C = = .
logic program disjunctive (resp. positive, normal, Horn) iff consists disjunctive
(resp. positive, normal, Horn) rules. logic program ?-consistent (under ?-stable model semantics) least one ?-stable model.
known every logic program HT-models FLP-models (cf., see Truszczynski, 2010, Prop. 8).
Proposition 2 Every logic program HT-

FLP-models.

3. Characterizations Knowledge Equivalence
section, perspective ?-models, consider characterization knowledge
equivalence various logic programs firstly, relate knowledge equivalence equivalence propositional logic secondly.
38

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

3.1 Model Theoretical Characterization
firstly recall basic properties ?-satisfiability (Ferraris & Lifschitz, 2005; Ferraris,
2005; Truszczynski, 2010).
Proposition 3 Let formula X A.
(i) hX, |=? hY, |=? (i.e., |= ).
(ii) hX, |=? iff |= .
(iii) hX, |=? iff X |= Red? (, ).
collection ?-interpretations ?-expressible whenever exists formula
Mod? () = M. collection ?-interpretations may ?-expressible. instance,
formula whose ?-models ones = {h, {p}i}. reason
formula Mod? () = h{p}, {p}i |=? (i) Proposition 3.
requires h{p}, {p}i belonging Mod? (), contradiction.
Given formula X A, hX, ?-countermodel hX, 6|=?
hY, |=? ; hY, ?-countermodel hY, 6|=? . Let X A, define
following formulas:
_
(X ) ((Y \ X) (Y \ X)),
_
^
FLP (X, ) = (X ) (X ),
^
(Y, ) = (Y ) ,
_
^
(X, ) = (X ) (Y \ X).
HT (X, ) =

^

(4)
(5)
(6)
(7)

? (X, ) (Y, ) capture ?-countermodel hX, hY, respectively.
following lemma shows ?-countermodel captured formula (cf.,
? = HT, see Cabalar & Ferraris, 2007, Prop. 1; Truszczynski, 2010, Props. 5 6 ? = FLP ).
Lemma 1 Let X U V A.
(i) hU, V ?-countermodel ? (X, ) iff U = X V = .
(ii) hU, V ?-countermodel (Y, ) iff V = .
Proposition 4 collection ?-interpretations ?-expressible iff
hX, implies hY, M.
Actually, satisfy condition (8) following logic program
? = {? (X, )|hX,
/ hY, M} {(Y, )|hY,
/ M}
captures sense Mod? (? ) = M.
39

(8)

fiWANG , Z HANG , Z HOU , & Z HANG

Note Wong (2009) presented model-theoretical characterization HT-models
disjunctive logic programs (cf., see Wong, 2009, Thm. 2.7). Formally speaking, collection
HT-interpretations disjunctively HT-expressible, i.e., disjunctive logic program
ModHT () = M, iff condition (8) following one hold:
hX, M, 0 hY 0 , 0 hX, 0 M.

(9)

Together Proposition 2,
Corollary 1 collection
tions (8) (9) hold.

FLP -interpretations

disjunctively

FLP -expressible

iff condi-

Actually, satisfies conditions (8) (9) following disjunctive logic program
captures M.
= {(X, )|hX,
/ hY, M} {(Y, )|hY,
/ M}.
Lemma
V
W2 Let A, B beVtwo sets
W atoms, X A. hX, |=?
B |= B A.

V

B

W

iff X |=

Proposition 5 set ?-interpretations positively ?-expressible, i.e., positive logic
program s.t Mod? () = M, iff satisfies criteria:
hX, iff X Y, hX, Xi hY, M.

(10)


Va matter
W fact, case satisfies condition (10), positive logic program =
/ M} captures M.
{ X X|hX, Xi

Corollary 2 Two positive logic programs strongly ?-equivalent equivalent
propositional logic.

Eiter, Fink, Tompits, Woltran (2004) showed disjunctive logic program
strongly equivalent normal logic program closed here-intersection, i.e.,
every pair HT-models hX, hX 0 , , hX X 0 , also HT-model (cf.,
see Eiter et al., 2004, Thms. 1 2). terms characterization disjunctive logic programs
Proposition 2, obtain ?-model characterization normal logic programs follows.
Corollary 3 set ?-interpretations normally ?-expressible, i.e., normal logic
program Mod? () = M, iff satisfies, addition (8) (9), following
criteria:
hX, hX 0 , hX X 0 , M.
(11)
Proposition 6 collection ?-interpretations Horn ?-expressible, i.e., Horn logic
program Mod? () = M, iff satisfies, addition (10), following criteria:
hX, hH, hX H, M.
40

(12)

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

3.2 Relating Knowledge Equivalence Propositional Logic
proved strong equivalence logic programs stable model semantics related
equivalence propositional logic (Pearce et al., 2001; Lin, 2002). holds strong
FLP-equivalence logic programs show following.
Firstly, extend language LA LAA0 A0 = {p0 |p A} p0 fresh atoms.
expression LA , 0 denote result obtained replacing atom p
corresponding atom p0 A0 . following denote
(A) = {p p0 | p A}.

(13)

Please note that, model (A), splitting MA0 =
MA0 = A0 and, every p , atom p0 A0 belongs MA0 . A0
denote set {p A|p0 }.
Definition 6 HT [.] FLP [.] recursively defined follows:
(T1) ? [] = ;
(T2) ? [p] = p;
(T3) ? [1 2 ] = ? [1 ] ? [2 ] {, };
(HT-T4) HT [1 2 ] = (01 02 ) (HT [1 ] HT [2 ]);
(FLP-T4) FLP [1 2 ] = (01 02 ) (1 01 FLP [2 ]).
Please note translation HT translation defined Pearce, Tompits,
Woltran (2001). One verify HT [] = 0 HT [], FLP [] = 0 . Given
theory LA , define ? [] = {? [] | }. evident ? [] linear size .
Example 3 Let = p p p.
HT [] = ((p0 p0 ) p0 ) ((p p p0 ) p) p0 ,
FLP [] = ((p0 p0 ) p0 ) ((p p) (p0 p0 ) p) p0 p.
unique FLP-model (over signature {p}) h{p}, {p}i. However, two HT-models
h, {p}i h{p}, {p}i. signature {p, p0 }, one easily check {HT []} (A)
two models {p, p0 } {p0 }, {FLP []} (A) unique model {p, p0 }.
V
W
Proposition 7 Let = (B C) (A D), A, B, C, subsets A.
(A) |= FLP [] HT [].
following proposition connects ?-equivalence equivalence classical propositional logic (cf., ? = HT, see Pearce et al., 2001, Lem. 2).
Proposition 8 Let formula LA X A. hX, ?-model iff
X 0 model (A) {? []}.
41

fiWANG , Z HANG , Z HOU , & Z HANG

following theorem shows strong ?-equivalence logic programs ?-stable
model semantics reduced equivalence propositional logic (cf., ? = HT, see
Ferraris et al., 2011, Thm. 9; Lin & Zhou, 2011, (5) Thm. 6).
Theorem 4 Two formulas ?-models (over A) iff (A){? []} (A)
{? []} models (over A0 ).
Based theorem, obtain following complexity result (cf., ? =
Tompits, & Woltran, 2009, Thms. 8 11).

HT ,

see Pearce,

Proposition 9 (i) problem deciding formula ?-satisfiable NP-complete.
(ii) problem deciding two formulas ?-equivalent co-NP-complete.

4. Knowledge Forgetting Logic Programs
mentioned introduction, concentrate knowledge forgetting logic programs
stable model semantics. formally stated following:
Definition 7 (Knowledge forgetting) Let logic program V A. logic program
result ?-knowledge forgetting V , consists ?-knowledge
mentions atom V .
show knowledge forgetting result always exists unique strong
equivalence (cf. Theorem 6) semantic ?-forgetting defined explored.
Let V, X, sets atoms. set V -bisimilar X, written V X, \V = X \V .
intuitively states interpretations X agree atoms V .
Two ?-interpretations hH, hX, V -bisimilar, written hH, V hX, i, H V X
V . Now, position define semantic knowledge forgetting terms
bisimulation.
Definition 8 (Semantic knowledge forgetting) Let formula V A. formula
result (semantic) ?-forgetting V whenever, every ?-interpretation ,
Mod? () iff 0 Mod? () s.t V 0 .

(14)

According definition, one see ?-models somehow exactly constructed
. motivates us define following notion extension.
Let V, X, sets atoms. V -extension X, denoted XV , collection
interpretations V -bisimilar X. V -extension ?-interpretation hH, i, denoted
hH, iV , collection ?-interpretations V -similar hH, i. instance, let
hH, = h{p, q}, {p, q}i V = {q, r}. hH, iV contains h{p}, {p}i, h{p}, {p, q}i,
h{p}, {p, q, r}i, h{p, q, r}, {p, q, r}i on. Intuitively speaking, V -extension interpretation collection interpretations formed freely adding removing
atoms
Sin V . V -extension collection (?-)interpretations, written MV , collection V .
classical propositional logic corresponds formula , i.e. = Mod(), MV
corresponds formula whose truth value nothing atoms V . intended
meaning case ?-models similar MV corresponds formula ?-model
42

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

semantics relevant atoms V . words, suppose MV = Mod? ().
hX, |=? hH, |=? H (resp. ) obtained X (resp. ) freely
adding removing atoms V whenever H . following lemma shows equivalent
condition semantic ?-knowledge forgetting.
Lemma 3 Let formula V A. formula result ?-forgetting V , iff
following condition holds:
Mod? () = Mod? ()V .
(15)
condition ?-forgetting generalization forgetting propositional logic (Lin &
Reiter, 1994) terms following corollary.
Corollary 5 formula result forgetting set V atoms formula iff Mod() =
Mod()V , Mod(.) refers classical propositional logic.
syntactic counterpart forgetting propositional logic defined follows (Lin, 2001;
Lang et al., 2003):
Forget(, {p}) = [p/] [p/>],
Forget(, V {p}) = Forget(Forget(, {p}), V )
[p/>] (resp. [p/]) formula obtained replacing every occurrence
atom p > (resp. ).
?-interpretations related given signature A, follows, shall assume
signature formula/theory implicitly given atoms occurring formula/theory,
unless explicitly stated otherwise. example illustrates ?-forgetting results
computed.
Example 4 Let following formula
(p q) (q p) (p ) (q ).
signature {p, q}, Mod? () = {h, {p, q}i, h{p, q}, {p, q}i}. Please note
? either HT FLP. Definition 8, verify Mod? (){p} =
{h, {q}i, h{q}, {q}i}{p} . corresponds formula = (p q ) (p q)
?-model semantics Proposition 4. matter fact, ? q ? q.
Note Forget(, {p}) = [p/>] [p/] q q 6? q. shows that, unlike
syntactic counterpart forgetting classical propositional logic, ?-forgetting results cannot
computed via [p/>] [p/] Mod? (q) = {h, {q}i, h{q}, {q}i}, Mod? (q) =
{h{q}, {q}i} (over signature {q}).

4.1 Expressibility
Please note Definition 8 guarantee existence forgetting results, however
next theorem shows ?-forgetting result always exists. also implies ?-forgetting
result unique (up strong ?-equivalence).
43

fiWANG , Z HANG , Z HOU , & Z HANG

Theorem 6 (Expressibility theorem) Let formula V set atoms. exists
formula Mod? () = Mod? ()V .
Here, uniqueness strong ?-equivalence ?-forgetting result follows fact
that, formula 0 result ?-forgetting V well Mod? ( 0 ) = Mod? ()V =
Mod? (), shows 0 strongly ?-equivalent ?-stable model semantics.
Based expressibility result abusing denotation, denote forgetting result
Forget? (, V ):
Definition 9 Let formula V A. Forget? (, V ) formula s.t Mod? () =
Mod? ()V , i.e., Forget? (, V ) result ?-forgetting V .
sense Forget? operator maps formula set atoms formula. According
Definition 8 expressibility theorem, following corollary easily follows.
Corollary 7 Let , formulas, V , V1 V2 sets atoms.
(i) Forget? (Forget ? (, V1 ), V2 ) ? Forget? (Forget ? (, V2 ), V1 ).
(ii) ? Forget? (, V ) ? Forget? (, V ).
firstly states ?-forgetting independent order forgotten atoms, secondly,
?-forgetting preserves strong ?-equivalence logic programs ?-stable model semantics.
investigate properties forgetting, introduce notion irrelevance
?-model semantics.
Definition 10 formula ?-irrelevant set V atoms, denoted IR? (, V ), exists
formula mentioning atoms V ? .
basic properties ?-forgetting presented below.
Proposition 10 Let two formulas V set atoms.
(i) IR? (Forget ? (, V ), V ).
(ii) ?-model iff Forget? (, V ) has.
(iii) |=? Forget? (, V ).
(iv) |=? Forget? (, V ) |=? Forget? (, V ).
(v) Forget? ( , V ) ? Forget? (, V ) Forget? (, V ).
(vi) Forget? ( , V ) |=? Forget? (, V ) Forget? (, V ).
(vii) Forget? ( , V ) ? Forget? (, V ) IR? (, V ).
44

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

Intuitively, (i) Proposition says ?-forgetting result irrelevant atoms V ,
i.e., forgotten atoms. sense, signature ?-forgetting result constrained
\ V . intended meaning others easily read out. E.g., item (iii) says
forgetting kind weakening, item (v) shows forgetting distributive property
disjunction.
mentioned earlier, disjunctive programs, positive programs, normal logic programs Horn
programs four types special cases (arbitrary) logic programs setting.
interesting consider whether expressibility result also holds special programs.
instance, would like know whether result ?-forgetting disjunctive (positive,
normal, Horn) logic program still expressible disjunctive (resp. positive, normal,
Horn) logic program.
indicated following two examples, HT- FLP-forgetting disjunctive, positive
normal logic programs possibly expressible either disjunctive positive logic programs.
simplicity, identify singleton set {} clear context, thus
denote Forget? (, {p}) Forget? (, p), IR? (, {p}) IR? (, p), M{p} Mp etc..
Example 5 Consider following normal logic program signature {p, q}:
(p q) (q p) (p q ).
Mod? () = {h{p}, {p}i, h{q}, {q}i}
Mod? ()p = {h, i, h{q}, {q}i}{p} .
h{p}, {p}i{p} = h, i{p} . implies Forget? (, p) ? q q. easily seen
q q cannot expressed disjunctive logic program Mod? ()p satisfy (9).
Hence Forget? (, p) cannot expressed normal logic program.
Please note q q HT q q. Thus q q also result HT-forgetting p .
However, q q result FLP-forgetting p q q FLP > 6FLP q q.
Example 6 Let positive logic program signature {p, q, r} follows:
(p q r) (p q r) (p r q) (q r p).
difficult verify that, signature {p, r}, Mod? (){q} consists
h, i, h, {p, r}i, h{p}, {p}i, h{p}, {p, r}i, h{r}, {r}i, h{r}, {p, r}i, h{p, r}, {p, r}i.
Clearly satisfy condition (9). Hence captured disjunctive logic program. matter fact, following
Forget HT (, q) HT HT (, {p}) HT (, {r}) = (r p p) (p r r),
Forget FLP (, q) FLP FLP (, {p}) FLP (, {r}) = (r p r p) (p p r r)
terms Proposition 4. Interestingly, example also shows that, though logic program may
HT-models FLP-models, HT-forgetting result may different FLPforgetting result.

45

fiWANG , Z HANG , Z HOU , & Z HANG

HT- FLP-forgetting Horn logic programs special interest, unlike disjunctive, positive normal logic programs, result HT- FLP-forgetting result Horn
logic program always expressible Horn logic program, show below.
Theorem 8 (Horn expressibility) Let Horn logic program V A. Horn
logic program 0 Forget? (, V ) ? 0 .
obtained model-theoretical characterization classes disjunctive normal
logic programs respectively, easily derive sufficient necessary condition HT-
FLP-forgetting results remain class, i.e., result HT- FLP-forgetting set
atoms disjunctive (resp. normal) logic program disjunctive (resp. normal) logic program.
Proposition 11 Let disjunctive logic program, V A. Forget? (, V )
expressible disjunctive logic programs if,
hH1 , T1 |=? , hT2 , T2 |=? T1 T2 hH3 , T3 |=? hH3 , T3 V hH1 , T2 i.
Proposition 12 Let normal logic program, V A. Forget? (, V ) expressible
normal logic programs if, addition condition (16), following condition holds,
hH1 , T1 |=? , hH2 , T2 |=? T1 V T2
hH3 , T3 |=? H3 V H1 H2 (T3 V T1 T3 V T2 ).

(16)

4.2 Forgetting Postulates
Zhang Zhou (2009) proposed four forgetting postulates work knowledge forgetting,
showed knowledge forgetting precisely characterized four postulates.
argued postulates viewed general semantic characterization
knowledge forgetting logics. Indeed, classical propositional forgetting also
characterized postulates. terms forgetting logic programs, addressed
introduction, imposing postulates feasible existing approaches. following,
show ?-forgetting exactly captured postulates, think one major
advantage logic program forgetting approaches.
notion forgetting closely related uniform interpolation property (Visser, 1996;
Goranko & Otto, 2007), instance, forgetting description logics (Lutz & Wolter, 2011)
semantic forgetting logic programs (Gabbay, Pearce, & Valverde, 2011). following
corollary follows Theorem 6, actually implies uniform interpolation property
logics ?-model semantics. Namely, formulas |=? , exists
formula |=? , |=? contains atoms occurring .
formula called uniform interpolant . stated as:
Corollary 9 Let two formulas, V set atoms IR? (, V ).
|=?

iff

Forget? (, V ) |=? .

Let two formulas V set atoms. following Zhang-Zhous four
postulates logic programs ?-model semantics.
46

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

(W) Weakening: |=? .
(PP) Positive persistence: IR? (, V ) |=? |=? .
(NP) Negative persistence: IR? (, V ) 6|=? 6|=? .
(IR) Irrelevance: IR? (, V ).
specifying ? Forget? (, V ), (W), (PP), (NP) (IR) called postulates knowledge
forgetting logic programs ?-stable model semantics. Viz, result ?-forgetting V
. Based uniform interpolation property (cf. Corollary 9), show following
representation theorem.
Theorem 10 (Representation theorem) Let two formulas V set atoms.
following statements equivalent:
(i) ? Forget? (, V ).
(ii) ? {0 | |=? 0 IR? (0 , V )}.
(iii) Postulates (W), (PP), (NP) (IR) hold.
theorem justifies knowledge forgetting (cf. Definition 7) exists unique
strong equivalence.
obvious consequence follows representation theorem
Forget? (, V ) ? { | |=? IR? (, V )}.
says result ?-forgetting V consists ?-logical consequence
?-irrelevant V . reason forgetting knowledge forgetting logic programs
stable models semantics. mentioned introduction none
forgetting approaches logic programs knowledge forgetting since satisfy
postulates (see Section 5 details).
One note representation theorem applicable forgetting classical
propositional logic, viz, Forget(, V ) { | |= IR(, V )}.
4.3 Relating Propositional Forgetting
shown strong equivalence logic programs may related equivalence
propositional logic (Pearce et al., 2001; Lin, 2002). ?-forgetting preserves strong equivalence
logic programs ?-stable model semantics, worth exploring connections
?-forgetting forgetting propositional logic. section, undertake in-depth
investigation aspect.
first provide direct connection ?-forgetting propositional forgetting via
following proposition.
Proposition 13 Let , 0 , formulas V ? Forget? (, V ) 0
Forget(, V ).
(i) 0 .
47

fiWANG , Z HANG , Z HOU , & Z HANG

(ii) 0 |=? .
result (i) Proposition 13 simply says result ?-forgetting classical propositional forgetting equivalent classical propositional logic. Thus forgetting classic propositional logic computed ?-forgetting logic programs. However seen
Example 4, Forget? (, V ) possibly ?-equivalent Forget(, V ). reverse (ii)
hold generally. instance, Forget? (p, q) ? p, Forget(p, q) p, evidently
p 6|=? p. result Theorem 8, immediately following corollary.
Corollary 11 Let Horn logic program V set atoms. Forget(, V ) expressible Horn logic program.
following result states that, Horn logic programs, ?-forgetting forgetting
propositional logic strongly ?-equivalent. Thus provides method computing ?-forgetting
results Horn logic programs propositional forgetting.
Proposition 14 Let 0 two Horn logic programs, V set atoms 0
Forget(, V ). 0 ? Forget? (, V ).
following proposition states ?-forgetting double negative formulas closely
connected classical propositional forgetting, used prove complexity
results later.
Proposition 15 Let two formulas V set atoms.
(i) Forget(, V ) iff ? Forget? (, V ).
(ii) Forget(, V ) Forget(, V ) iff Forget? (, V ) ? Forget? (, V ).
known strong equivalence logic programs closed related equivalence
propositional logic translating logic programs propositional theories (Pearce et al., 2001;
Lin, 2002). motivates us investigate connection forgettings view
translations. main result section stated follows.
Theorem 12 (?-forgetting vs propositional forgetting) Let two formulas LA
V A.
? Forget? (, V ) iff (A) |= ? [] Forget((A) {? []}, V V 0 ).
Theorem 12, know check whether formula result ?-forgetting set
V atoms formula , equivalent check whether ? [] classically equivalent
Forget((A) {? []}, V V 0 ) theory (A). following example shows
application theorem.
Example 7 [Example 5 continued] Recall following formula:
(p q) (q p) (p q )
48

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

Forget? (, p) ? q q. signature {p, q}, (A) = (p p0 ) (q q 0 ) and,
program translation yields:
? () (p0 q) (p0 q 0 ) (q 0 p) (q 0 p0 ) (p0 q 0 ).
Forget(? [] (A), {p, p0 }) equivalent to:
(q q 0 ) (q q 0 ),

i.e.

(q 0 q) (q q 0 )

equivalent q 0 q theory ({q}) = {q q 0 }. One check
? [q q] = q 0 q q q 0 q (under theory ({q})). Thus formula q q result
?-forgetting p Theorem 12.

following example shows (A) occurring Forget? ({ []} (A), V V 0 )
necessary Theorem 12.
Example 8 [Continued Example 6] Recall = {p, q, r}, (A) = {p p0 , q q 0 , r
r 0 } consists
(p q r) (p q r) (p r q) (q r p).
that,
HT [] ,
(A) |= ? [] ,
FLP [] (p q r) (p q p0 q 0 r) (p r p0 r 0 q) (q r q 0 r 0 p)
= (p0 q 0 r 0 ) (p0 r 0 q 0 ) (q 0 r 0 p0 ).
One check
Forget(HT [], {q, q 0 }) >,
(A) |= Forget(FLP [], {q, q 0 }) >.
Recall formula 1 = (r p p) (p r r) result HT-forgetting q ;
2 = (r p r p) (p p r r) result FLP-forgetting q .

HT [1 ] 01 (r r 0 p p p0 ) (p p0 r r r 0 ),
FLP [2 ] 02 (r r 0 p r p0 ) (p p0 p r r 0 ).
theory (A),
(A) |= HT [1 ] (p0 p r 0 ) (r 0 r p0 ),
(A) |= HT [1 ] (p0 p r 0 ) (r 0 r p0 ).
One verify model {p0 } (A) model HT [1 ], model
FLP [2 ], i.e. (A) 6|= HT [1 ] > (A) 6|= FLP [2 ] >. Actually, that,
(A) |= Forget({? []} (A), {q, q 0 }) ((p0 r 0 ) (p r) (p0 r 0 )).
One check
(A) |= (p0 p r 0 ) (r 0 r p0 ) ((p0 r 0 ) (p r) (p0 r 0 )),
shows 1 (resp. 2 ) result HT-forgetting (resp.
49

FLP-forgetting)

q .



fiWANG , Z HANG , Z HOU , & Z HANG

following result states reduce checking whether ?-forgetting results two
formulas strongly ?-equivalent checking whether propositional forgetting results corresponding two formulas equivalent.
Proposition 16 Let two formulas LA V set atoms. Forget? (, V ) ?
Forget? (, V ) iff following condition holds:
Forget({? []} (A), V V 0 ) Forget({? []} (A), V V 0 ).
4.4 Computation Complexity
Theorem 6 Propositions 4 10 imply naive approach compute ?-forgetting results. Formally speaking, given formula signature set V atoms, Forget? (, V )
computed follows:
(Step 1) Evaluating ?-models , denoted M.
(Step 2) Restrict \ V , denoted M|V , i.e.
M|V = {hH \ V, \ V i|hH, M}.
(Step 3) Enumerating following formulas (over signature \ V ) M|V :
? (X, ) hX,
/ M|V hY, M|V ,
(Y, ) hY,
/ M|V .
(Step 4) Finally, conjunct constructed formulas, denoted .
Corollary 13 Let , V given above. ? Forget? (, V ).
Alternatively, terms Theorem 10, compute Forget? (, V ) enumerating ?consequences ?-irrelevant V . exist sound complete axiomatic systems
HT-logic (Jongh & Hendriks, 2003), checking HT-consequence relation axiomatically
doable. Though sound complete axiomatic system FLP-logic recently unknown, still
enumerate formulas form (2) signature \ V check FLPconsequence . Nevertheless, also observed computational viewpoint, like
propositional forgetting, two approaches would expensive. appears
inevitable terms following complexity results, unless complexity hierarchy collapses.
Theorem 14 Let two formulas V set atoms.
(i) problem deciding ? Forget? (, V ) co-NP-complete.
(ii) problem deciding Forget? (, V ) ? Forget? (, V ) P2 -complete.
(iii) problem deciding ? Forget? (, V ) P2 -complete.
50

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

According representation theorem (i.e. Theorem 10), result (i) Theorem 14 means
checking ?-irrelevant V , i.e. IR? (, V ), intractable. result (ii) Theorem 14,
hand, presents complexity ?-forgetting equivalence checking, i.e., two formulas
strongly ?-equivalent restricted common signatures. last result (iii)
Theorem 14 states checking formula result ?-forgetting generally difficult.
Proposition 17 Let two formulas V set atoms.
(i) problem deciding whether |=? Forget? (, V ) P2 -complete.
(ii) problem deciding whether Forget? (, V ) |=? co-NP-complete.
Theorem 14 Proposition 17 tell us ?-forgetting, general complexity resulting checking inference problems located level complexity polynomial
hierarchy propositional forgetting.
4.5 Conflict Solving Based Knowledge Forgetting
following, consider application proposed forgetting conflict solving logic
program contexts, represent knowledge system consisting knowledge bases multiple
agents.
Definition 11 logic program context n-ary tuple = (1 , . . . , n ) consistent
logic program. ?-conflict-free 1 n consistent ?-stable model semantics.
Definition 12 Let = (1 , . . . , n ) logic program context. ?-solution minimal
subset (Forget? (1 , S), . . . , Forget? (n , S)) ?-conflict-free,
underlying signature.
obvious ?-solution ?-conflict-free logic program context .
consider following simplified Zhang Foos conflict solving scenario (cf., see Zhang
& Foo, 2006, Ex. 6).
Example 9 couple John Mary discussing family investment plan. four
different shares shareA, shareB, shareC shareD, shareA shareB high risk
also high return; shareC shareD low risk may suitable long term
investment. Johns Marys investment preference shares encoded following
logic programs J respectively:
J :

:

r1 :sA sB,

r10 :sC ,

r2 :sC sD,

r20 :sD ,

r3 :sD sC,

r30 :sB sA, sC,

r4 : sC, sD,
r40 : sA, sB,
s# stands share#. intuitive meaning rules easily read out. E.g. rule r1
says John wants buy shareA dont buy shareB, rules r2 , r3 r4 mean John
wants buy shareC shareD, them.
51

fiWANG , Z HANG , Z HOU , & Z HANG

one see J ?-stable model due confliction rule r4
r10 , r20 , logic program context = (J , ) ?-conflict-free.
= {sD}, following
Forget HT (J , S) HT {sA sB,
Forget HT (M , S) HT {sC ,

sC; sC },

sB sA, sC,

sA, sB}.

One check Forget HT (J , S) Forget HT (M , S) unique HT-stable model {sA, sC}.
Thus HT-solution . said John Mary may agreement
investment plan shares shareA, shareB shareC agree give belief
(knowledge) shareD. results investment shares shareA shareC,
shareB.
One check that, FLP-stable model semantics, John Mary give
belief shareD results investment plan shares shareA shareC,
share shareB. reason Forget FLP (J , S)Forget FLP (M , S) unique FLP-stable
model {sA, sC}.

5. Related Work
section compare ?-forgetting weak strong forgetting (Zhang & Foo, 2006),
semantic forgetting (Eiter & Wang, 2008) forgetting operators FS FW (Wong, 2009).
5.1 Weak Strong Forgetting
Let normal logic program p propositional atom. reduction respect p,
denoted Red(, {p}), normal logic program obtained
(1) rule r p Head(r), rule r 0 p Body+ (r 0 ),
replacing r 0
Head(r 0 ) Body(r), Body(r 0 ) \ {p}.
(2) rule r 0 replaced new rule previous step,
removing rule r remaining normal logic program.
Let X set propositional atoms. reduction respect X inductively
defined follows:
Red(, ) = ,
Red(, X {p}) = Red(Red(, {p}), X).
strong forgetting p normal logic program normal logic program SForget(, {p})
obtained Red(, {p}) removing rule r either r valid 5 p Head(r)
Body+ (r) Body (r). weak forgetting p normal logic program WForget(, {p})
obtained Red(, {p}) firstly removing rule r either r valid, p Head(r)
Body+ (r) removing p remaining rules.
5. rule r valid Head(r) Body+ (r) 6= Body+ (r) Body (r) 6= .

52

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

Let X set atoms. strong (and weak) forgetting X recursively defined
SForget(, ) = ;

WForget(, ) = ;

SForget(, X {p}) = SForget(SForget(, {p}), X);
WForget(, X {p}) = WForget(WForget(, {p}), X).
known two forgetting operators independent ordering forgotten atoms
sense strong HT-equivalence logic programs HT-stable model semantics (cf., see
Zhang & Foo, 2006, Prop. 2).
Example 10 Consider two normal logic programs:
= {p q,

q p,

r p},

= {p q,

q p,

r q}.

One check strongly equivalent.
SForget(, {p}) = ,

WForget(, {p}) = {r },

SForget(, {p}) = WForget(, {p}) = {r q}.
example shows neither weak forgetting preserves strong equivalence, strong forgetting. One verify |=? q r 6|=? r ? {HT, FLP }. Thus
strong forgetting satisfy positive persistence, weak forgetting satisfy weakening negative persistence. Actually, HT- FLP-forgetting,
following
Forget HT (, p) HT Forget HT (, p) HT {q r },
Forget FLP (, p) FLP Forget FLP (, p) FLP {q r }.
FLP follows fact HT Proposition 2.



5.2 Semantic Forgetting
addressed certain issues weak strong forgetting, Eiter Wang (2008) proposed
semantic forgetting consistent disjunctive logic programs. Formally speaking, let
consistent disjunctive logic program p atom. set atoms p-stable model iff
stable model stable model \ {p} \ {p}.
disjunctive logic program 0 represents result forgetting p ,
0 mention atom p,
set 0 atoms stable model 0 iff p-stable model 0 p .
terms definition, forgetting results unique strong equivalence.
means, forgetting preserve strong equivalence. compute result forgetting atom consistent disjunctive logic program, proposed three algorithms forget1 ,
forget2 forget3 (Eiter & Wang, 2008). example demonstrates difference
semantic forgetting ?-forgetting.
53

fiWANG , Z HANG , Z HOU , & Z HANG

Example 11 Let = {p q} program signature = {p, q, r}. Although program nothing atom r, forgeti (, r) = (i = 1, 2, 3),
seems intuitive loses information irrelevant want forget. However
Forget? (, r) ? .

example also shows semantic forgetting satisfy positive persistence
postulate |=? q p, lost semantic forgetting result forgeti (, r) = 1, 2, 3.
5.3 Forgetting Operators FS FW
Wong (2009) developed forgetting disjunctive logic programs. Differently work
Zhang Foo (2006), Eiter Wang (2008), Wongs forgetting defined based
HT-logic. sense, approach probably shares common logic ground HT-forgetting.
Wong also defined two forgetting operators FS FW , correspond two series program
transformations. See Appendix detailed definitions.
interesting feature Wongs forgetting preserves strong equivalence. However,
major issue forgetting that: one hand, forgetting FS may cause unnecessary
information loss; hand, forgetting FW may also introduce extra information
one want, illustrated following example.
Example 12 Let us consider normal logic program consisting of:
x,

a, z,

q p,

p q,

p, q.

have:
FS (, {a, p}) HT {y x, z},
FW (, {a, p}) HT {y x, z,

x,

Forget HT (, {a, p}) HT {y x, z,
Forget FLP (, {a, p}) FLP {y x, z,

q },
q q},
q q}.

Since |=HT {q q}, irrelevant atoms p, seems us forgetting
{a, p} affect fact. FS (, {a, p}) 6|=HT {q q}. sense,
see FS lost information wish keep. shows operator FS
satisfy positive persistence postulate.
hand, fact 6|=HT q FW (, {a, p}) |=HT q, appears FW may
introduce unnecessary information, indeed conflicts intuition program weakening via
forgetting, i.e., satisfy weakening postulate.

mentioned introduction, following example confirms expected result
obtained either one three forgetting approaches.
Example 13 [Continued Example 5] normal logic program :
(p q) (q p) (p q ),
54

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

following:
SForget(, {p}) = forget1 (, {p}) = FS (, {p}) = ,
WForget(, {p}) = FW (, {p}) = {q}.
Here, expected logic program represents information auxiliary atom
p ignored q q.


6. Concluding Remarks
paper two semantic knowledge forgetting approaches, called HT- FLP-forgetting respectively, proposed logic programs stable model FLP-stable model semantics respectively. knowledge forgetting results captured corresponding logical consequence forgotten logic programs irrelevant forgotten atoms. consequently preserves
strong equivalence logic programs HT- FLP-stable model semantics respectively.
major advantage compared existing forgetting approaches logic programming.
starting point, investigated model theoretical characterization logic programs HT- FLP-stable model semantics, studied respective strong equivalence problems
using classical propositional logic equivalence. Many properties forgetting explored,
existence forgetting results, representation theorem, complexity decision problems related forgettings. also considered application knowledge forgetting conflict solving.
Although presented abstract approaches computing forgetting results
showed underlying difficulties computation, valuable study practical algorithms
different subclasses logic programs. Another challenging future work extend knowledge forgetting nonmonotonic systems, particular first-order logic programs (Ferraris
et al., 2011). mentioned introduction forgetting effectively used
solve confliction, e.g. strong weak forgetting (Zhang & Foo, 2006) propositional forgetting (Lang & Marquis, 2010), application knowledge forgetting deserves
studying.
concentrate upon paper knowledge forgetting logic programs,
based notion strong equivalence, interesting work consider forgetting
stable model semantics logic programs along work (Wang et al., 2013). Last least,
logic programs supported model semantics enjoys similar properties logic
programs HT- FLP-stable models semantics (Truszczynski, 2010), consider
knowledge forgetting logic programs supported model semantics another paper.

Acknowledgments
thank Mirek Truszczynski encouraging us consider knowledge forgetting logic programs FLP-stable model semantics. thank anonymous reviewers insightful comments, Robin Bianchi help formatting paper. Yisong Wang partially
supported National Natural Science Foundation China grant 61370161 Stadholder
Foundation Guizhou Province grant (2012)62.
55

fiWANG , Z HANG , Z HOU , & Z HANG

Appendix A. Proofs Section 2
Proposition 1 Let A, B, C, set atoms. following
V
W
V
W
(i) (A B) (D C) HT (A B C) D.
V
W
V
W
(ii) (A B) (D C) |=FLP (A B C) D.

V
W
Proof:
(ii)
Suppose
hX,




FLP-model (A B) (D C) FLP-model
V
W
(A B C) D. follows following conditions hold:
V
V
(a) X |= (A B C), implies X |= (A B).
V
V
V
(b) |= (A B C), implies |= (A B) C,
W
W
(c) hX, 6|=FLP D, i.e. X 6|= D.
W
W
W
conditions (a) (b) show hX, |=FLP (D C), i.e. X |= |= C.
Together conditions (b) (c), contradiction follows.


Appendix B. Proofs Section 3
Proposition 4 collection ?-interpretations ?-expressible iff
hX, implies hY, M.

(17)

Actually, satisfy condition (17) following logic program
? = {? (X, )|hX,
/ hY, M} {(Y, )|hY,
/ M}
captures sense Mod? (? ) = M.
Proof: direction left right follows (i) Proposition 3. prove
direction. Let ? propositional theory consisting of, every X A,
? (X, ) hX,
/ hY, M,
(Y, ) hY,
/ M.
Lemma 1, Mod? (? ) = M.



Lemma
V
W2 Let A, B beVtwo sets
W atoms, X A. hX, |=?
B |= B A.

V

B

W

iff X |=

Proof: According (iii) Proposition 3 Proposition 2, sufficient show that,
case ? = HT,
^
_
^
_
^
_
X |= ( B
A)Y iff X |=
B
|=
B
A.

V
W
V
W
Note |= B X |= ( B)Y implies X
V () W
V |= ( A) . Suppose X 6|=
B A, i.e. B X X = . follows |= B due B ,
56

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

W
V
V
V
W
|= A,Wi.e. 6= . Thus X |= ( B)Y since ( B)Y = B. X |= ( A)Y
i.e. X |= A, X 6= , contradiction.
V
W
V
W
()VWe need show
X |= ( B)Y ( A)Y since |=
B
A. Suppose
W
X |=V( B)YW X 6|= ( A)Y . former implies B X , thus X 6=
X |= B A. latter implies X (A ) = , means X = since X ,
contradiction.

Proposition 5 set ?-interpretations positively ?-expressible, i.e., positive logic
program s.t Mod? () = M, iff satisfies criteria:
hX, iff X Y, hX, Xi hY, M.

(18)

Actually, satisfy condition (18) following logic program
^
_
X|hX, Xi
/ M}
? = { X

captures sense Mod? (? ) = M.

Proof: suffices prove case ? = HT Proposition 2.
() Let positive logic program whose HT-models exact ones M. every
HT-interpretation hX, i, Lemma 2, hX, |= HT iff X , X |= i.e. hX, Xi |= HT ,
hY, |=HT i.e. |= since every rule positive. condition (18) follows.
() Let N = {X A|hX, Xi M}. construct propositional theory consisting
^
_
X
X

every X N (= 2A \ N ).
Firstly show
V Mod()
W = N . Suppose X |= X 6 N . X N . follows
X 6|= X X belongs .
V hand,
W suppose X N X 6|= .
follows exists X 0 N X 6|= X 0 X 0 , i.e., X 0 X X X 0 = ,
X = X 0 thus X N , contradiction.
Secondly show ModHT () = M. one hand, let hX, |=HT . X |=
|= Lemma 2. follows X, N , implies hX, Xi hY, M.
Thus hX, (18). hand, let hX, M. terms (18),
hX, Xi hY, M. Thus X N N , i.e. X |= |= . Thus
hX, |=HT Lemma 2.

Proposition 6 collection ?-interpretations Horn ?-expressible, i.e., Horn logic
program Mod? () = M, iff satisfies, addition (10), following criteria:
hX, hH, hX H, M.

(19)

Proof: suffices prove case ? = HT Proposition 2.
() Suppose Horn logic program ModHT () = M. Proposition 5,
ModHT () satisfies (18). Suppose hX, hH, two HT-models . follows
X, Y, H models Lemma 2. Thus X H |= |= ,
hX H, |= due X H .
57

fiWANG , Z HANG , Z HOU , & Z HANG

() Let N ones defined proof Proposition 5. X, N X
N according (19). follows exists Horn logic program (a set Horn clauses) whose
0
models exactly
Vones inWN . matter fact, Horn program constructed
replacing X
^
^
X p1 , . . . , X pk
(20)


X = {Y 0 \ X|X 0 0 N } = {p1 , . . . , pk }.
firstly show 0 proving


^
_
^
^
X
X
|=
pi
1ik

V
W
pi (1 k) defined (20). direction right left trivial V X W
belongs V
. Let us consider direction. Suppose H |= , H model X
H 6|= X pi (1 k). X H H 6= . follows
H element {Y 0 \ X|X 0 0 N } {p1 , . . . , pk } H.
contradiction.
Finally ModHT (0 ) = follows ModHT () = Proposition 5.

V
W
Proposition 7 Let = (B C) (A D), A, B, C, subsets A.
(A) |= FLP [] HT [].
Proof: Note HT [p] = p p0 FLP [p] = p0 .
HT [] = 0

^

^

B

(c c0 )

cC

_



_

!

(d d0 ) ,

dD

^

_
FLP [] = 0
(B C B 0 C 0 ) (A 0 ) .

Since (A) |= p p0 p0 ,
0

(A) |= HT []

!
^
_
_
0
0
,
(B C )

dD

0

(A) |= FLP []
completes proof.

^


_
(B C ) (A 0 ) .
0



Proposition 8 Let formula LA X A. hX, ?-model iff X 0
model (A) {? []}.
Proof: prove case ? =

FLP

induction structures . Let X A.

= p = . trivial = . hand, hX, |=FLP p iff X |= p iff
X 0 |= p.
58

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

= 1 2 {, }. follows inductive assumption.
= 1 2 . FLP [1 2 ] = (01 02 ) (1 01 FLP [2 ]). Recall
hX, |=FLP 1 2 iff
|= (1 2 ) and,
either (a) X 6|= 1 , (b) 6|= 1 , (c) hX, |=FLP 2 .
Note
|= (1 2 ) iff 0 |= 01 02 iff X 0 |= 01 02 ,
(a) X 6|= 1 iff X 0 6|= 1 , (b) 6|= 1 iff 0 6|= 01 iff X 0 6|= 01 , (c)
hX, |=FLP 2 iff X 0 |= FLP [2 ] inductive assumption.
follows hX, |=FLP 1 2 iff X 0 |= FLP [1 2 ].


completes proof.

Theorem 4 Two formulas ?-models (over LA ) iff (A) {? []}
(A) {? []} models (over LAA0 ).
Proof: prove case ? = FLP .
() |= (A) {FLP []}
iff MA0 |= (A) {FLP []}
0

|=
iff hMA ,
0
FLP Proposition 8, MA0 = {p|p MA0 }

iff hMA , MA0 |=FLP since FLP
iff MA0 |= (A) {FLP []} Proposition 8
iff |= (A) {FLP []}.
() hX, |=FLP
iff X 0 |= (A) {FLP []} Proposition 8, 0 = {p0 |p }
iff X 0 |= (A) {FLP []} since (A) {FLP []} (A) {FLP []}
iff hX, |=FLP Proposition 8.



Proposition 9 (i) problem deciding formula ?-satisfiable NP-complete.
(ii) problem deciding two formulas ?-equivalent co-NP-complete.
Proof: (i) Membership. formula FLP-satisfiable exists FLP-interpretation
hH, hH, |=FLP . feasible guess FLP-interpretation check
condition hH, |=FLP . Thus problem NP.
Hardness. follows fact FLP-satisfiable iff satisfiable, NPhard, (ii) Proposition 3. shows problem NP-hard.
(ii) Membership. 6FLP exists hH, that, either
(a) hH, |=FLP hH, 6|=FLP ,
(b) hH, 6|=FLP hH, |=FLP .
59

fiWANG , Z HANG , Z HOU , & Z HANG

guess FLP-interpretation hH, check conditions (a) (b) feasible
polynomial time size . Thus problem co-NP.
Hardness. FLP
iff FLP-model
iff model (ii) Proposition 3
iff valid, co-NP-hard. Thus problem co-NP-hard.


Appendix C. Proofs Section 4
Lemma 3 Let formula V A. formula result ?-forgetting V , iff
following condition holds:
Mod? () = Mod? ()V .
Proof: result ?-knowledge forgetting V
iff, every ?-interpretation , |=? iff exists 0 |=? s.t. V 0
iff Mod? () = {M ?-interpretation | 0 |=? V 0 }
iff Mod? () = Mod()V .



Lemma 4 Let X, Y, H, V subsets A.
(i) X V H V X V H X V H .
(ii) X V H 0 V 0 0 H 0 V V 0 X 0 .
Proof: (i) Note (X ) \ V
=(X \ V ) (Y \ V )
=(H \ V ) (T \ V ) due X V H V
=(H ) \ V .
Thus X V . similarly prove X V H .
(ii) Please note 0 = {p0 |p }, V 0 = {p0 |p V } 0 = {p0 |p V }.
(H 0 ) \ (V V 0 ).
= (H \ (V V 0 )) (T 0 \ (V V 0 ))
= (H \ V ) (T 0 \ V 0 ) since H V 0 = 0 V =
= (X \ V ) (Y 0 \ V 0 ) since H V H 0 V 0 0
= (X \ (V V 0 )) (Y 0 \ (V V 0 )) since X V 0 = 0 V =
= (X 0 ) \ (V V 0 ).

follows H 0 V V 0 X 0 .
Theorem 6 (Expressibility theorem) Let formula V set atoms. exists
formula Mod? () = Mod? ()V .
Proof: every hX, Mod? ()V , exists hH, |=? hH, V hX, i,
i.e. X V H V . (i) Proposition 3, hT, |=? . Thus hY, Mod? ()V
due hY, V hT, i. follows collection Mod? ()V satisfies condition (8),
formula Mod? () = Mod? ()V Proposition 4.

Lemma 5 formula ?-irrelevant set V atoms iff hH, |=? implies hX, |=?
every two ?-interpretations hX, hH, hX, V hH,
60

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

Proof: ?-irrelevant V
iff exists formula mentioning atoms V ?
iff exists formula mentioning atoms V s.t Mod? () = Mod? ()
iff Mod? () = {hX, i|X hH, V hX, s.t hH, |=? }
iff hH, |=? implies hX, |=? every two ?-interpretations hX, hH,
hX, V hH, i.

Proposition 10 Let two formulas V set atoms.
(i) IR? (Forget ? (, V ), V ).
(ii) ?-model iff Forget? (, V ) has.
(iii) |=? Forget? (, V ).
(iv) |=? Forget? (, V ) |=? Forget? (, V ).
(v) Forget? ( , V ) ? Forget? (, V ) Forget? (, V ).
(vi) Forget? ( , V ) |=? Forget? (, V ) Forget? (, V ).
(vii) Forget? ( , V ) ? Forget? (, V ) IR? (, V ).
Proof: (i) immediately follows Lemma 5.
(ii) evident Mod? () 6= iff Mod? ()V 6= Definition 8.
(iii) easy see Mod? () Mod? ()V Definition 8.
(iv) Let |=? , hH, |=? Forget? (, V ), i.e. hH, Mod? ()V . terms
Definition 8, exists hH 0 , 0 |=? hH, V hH 0 , 0 i. implies hH 0 , 0 |=?
since |=? . Thus hH, Mod? ()V , i.e. hH, |=? Forget? (, V ).
(v) hH, |=? Forget? ( , V )
iff hH, Mod? ( )V
iff hH 0 , 0 |=? hH, V hH 0 , 0
iff hH 0 , 0 hH, V hH 0 , 0 and, either hH 0 , 0 |=? hH 0 , 0 |=?
iff hH, Mod? ()V hH, Mod? ()V
iff hH, |=? Forget? (, V ) hH, |=? Forget? (, V )
iff hH, |=? Forget? (, V ) Forget? (, V ).
(vi) hH, |=? Forget? ( , V )
hH, Mod? ( )V
hH 0 , 0 |=? hH, V hH 0 , 0
hH 0 , 0 that. hH, V hH 0 , 0 i, hH 0 , 0 |=? hH 0 , 0 |=?
hH, Mod? ()V hH, Mod? ()V
hH, |=? Forget? (, V ) hH, |=? Forget? (, V )
hH, |=? Forget? (, V ) Forget? (, V ).
(vii) direction left right follows (vi) fact IR(, V ), i.e. Forget? (, V ) ?
. Let us consider direction.
hH, |=? Forget? (, V )
hH, |=? Forget? (, V ) hH, |=?
hH 0 , 0 |=? hH, V hH 0 , 0 i, hH, |=?
61

fiWANG , Z HANG , Z HOU , & Z HANG

hH, V hH 0 , 0 hH 0 , 0 |=? IR(, V ) Lemma 5
hH, Mod? ( )V
hH, |=? Forget? ( , V ).



Theorem 8 (Horn expressibility) Let Horn logic program V A. Horn
logic program 0 Forget? (, V ) ? 0 .
Proof: terms Proposition 2, suffices prove ? = HT. Let = ModHT ()V .
Proposition 6, sufficient show satisfies conditions (5) (12).
first prove satisfies (5). HT-interpretation hX, M,
X , exists hH, ModHT () hX, V hH, i. Note positive,
shows hH, Hi hT, HT-models Lemma 2. Thus hX, Xi
hY, due X V H V . hand, suppose hX, Xi M, hY,
X . exist two HT-models hH 0 , 0 hH 00 , 00 hH 0 , 0 V hX, Xi
hH 00 , 00 V hY, i. Lemma 2, H 0 |= , 0 |= , H 00 |= 00 |= . Since
models Horn theories closed set intersection (Alfred, 1951), H 0 H 00 |= .
Lemma 2 again, hH 0 H 00 , 00 |=HT . Lemma 4, H 0 H 00 V X (= X). Thus
hH 0 H 00 , 00 V hX, i. follows hX, M.
show satisfies (12). Suppose hX, hH, two HT-interpretations
M. follows two HT-models hX 0 , 0 hH 0 , 0 hX 0 , 0 V
hX, hH 0 , 0 V hH, i. Since Horn, hH 0 X 0 , 0 0 |=HT
Proposition 6. Lemma 4, H 0 X 0 V H X 0 0 V . implies
hH 0 X 0 , 0 0 V hX H, i, thus hX H, M.

Proposition 11 Let disjunctive logic program, V A. Forget? (, V )
expressible disjunctive logic programs if,
hH1 , T1 |=? , hT2 , T2 |=? T1 T2 hH3 , T3 |=? hH3 , T3 V hH1 , T2 i.
Proof: Proposition 2, suffices prove ? = HT. Let 0 HT Forget HT (, V ). direction
left right obvious. show direction.
Suppose 0 expressible disjunctive logic programs. exists hX, |=HT 0 ,
0 hY 0 , 0 |=HT 0 hX, 0 6|=HT 0 . follows that, hH1 , T1 |=HT
hT2 , T2 |=HT hH1 , T1 V hX, i, T2 V 0 T1 T2 , exists
hH3 , T3 |=HT hH3 , T3 V hH1 , T2 i, viz. hH3 , T3 V hX, 0 hX, 0 V
hH1 , T2 i, contradiction.

Proposition 12 Let normal logic program, V A. Forget? (, V ) expressible
normal logic programs if, addition condition (21), following condition holds,
hH1 , T1 |=? , hH2 , T2 |=? T1 V T2
hH3 , T3 |=? H3 V H1 H2 (T3 V T1 T3 V T2 ).

(21)

Proof: Proposition 2, suffices prove ? = HT. Let 0 HT Forget HT (, V ). direction
left right easy. consider direction follows.
terms Proposition 11 Corollary 3, sufficient show that, hX, |=HT 0
hX 0 , |=HT 0 , hX X 0 , |=HT 0 according Corollary 3. Suppose hX,
62

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

hX 0 , two HT-models 0 . two HT-models hH1 , T1 hH2 , T2
hX, V hH1 , T1 hX 0 , V hH2 , T2 i. follows T1 V T2 and, condition (21), exists HT-model hH3 , T3 satisfying either hH3 , T3 V hH1 H2 , T1
hH3 , T3 V hH1 H2 , T2 i, shows hH3 , T3 V hX X 0 , i, hence hX X 0 , |=HT
0 .

Theorem 10 (Representation theorem) Let two formulas V set atoms.
following statements equivalent:
(i) ? Forget? (, V ).
(ii) ? {0 | |=? 0 IR? (0 , V )}.
(iii) Postulates (W), (PP), (NP) (IR) hold.
Proof: Let ? = { | |=? IR? (, V )}. evident IR? (? , V ).
equivalence (i) (ii) follows Corollary 9. (ii) obviously implies (iii).
suffices show (iii) (ii).
Positive Persistence, |=? ? , follows Mod? ()
Mod? (? ). hand, ( W) |=? (IR) IR? (, V ), follows ? . Thus
Mod? (? ) Mod? (). Thus ? ? .

Proposition 13 Let , 0 , formulas V ? Forget? (, V ) 0
Forget(, V ).
(i) 0 .
(ii) 0 |=? .
Proof: (i) |=
iff hT, |=? (i) Proposition 3
iff hT, |=? Forget? (, V ) since ? Forget? (, V )
iff hY, |=? hT, V hY, Definition 8
iff |= V (i) Proposition 3
iff |= Forget(, V ) Corollary 5
iff |= 0 since 0 Forget(, V ).
(ii) hH, |=? 0
|= 0 (i) Proposition 3
|= Forget(, V ) since 0 Forget(, V )
|= V Corollary 5
hH \ V, |=? V (ii) Proposition 3
hH, |=? Forget? (, V ) due hH \ V, V hH, Definition 8
hH, |=? due Forget? (, V ) ? .



Proposition 14 Let 0 two Horn logic programs, V set atoms 0
Forget(, V ). 0 ? Forget? (, V ).
63

fiWANG , Z HANG , Z HOU , & Z HANG

Proof: Proposition 2, suffices show ? = HT.
() hH 0 , 0 |=HT 0
H 0 |= 0 0 |= 0 Lemma 2
H, H |= , |= , H V H 0 V 0 0 Forget(, V )
H, H |= , |= , H V H 0 V 0
H, hH T, |=HT hH T, V hH 0 , 0
hH 0 , 0 |=HT Forget HT (, V ).
() hH 0 , 0 |=HT Forget HT (, V )
hH, |=HT hH 0 , 0 V hH,
H H |= , |= hH 0 , 0 V hH, Lemma 2
H 0 |= Forget(, V ) 0 |= Forget(, V )
H 0 |= 0 0 |= 0 due 0 Forget(, V )
hH 0 , 0 |=HT 0 .
Proposition 15 Let two formulas V set atoms.
(i) Forget(, V ) iff ? Forget? (, V ).
(ii) Forget(, V ) Forget(, V ) iff Forget? (, V ) ? Forget? (, V ).
Proof: (i) () hH, |=?
iff |= , i.e. |= (ii) Proposition 3
iff |= Forget(, V ) since Forget(, V )
iff |= i.e. |= V Corollary 5
iff hH \ V, |=? (H \ V \ V = \ V ) (ii) Proposition 3
iff hH, |=? Forget? (, V ) Definition 8.
() |= i.e. |=
iff hH, |=? (ii) Proposition 3
iff hH, |=? Forget? (, V ) H since ? Forget? (, V )
iff hX, |=? hH, V hX, Definition 8
iff |= V (ii) Proposition 3
iff |= Forget(, V ) Corollary 5.
(ii) () hH, |=? Forget? (, V )
iff hX, |=? hX, V hH, Definition 8
iff |= i.e. |= V (ii) Proposition 3
iff |= Forget(, V ) Corollary 5
iff |= Forget(, V ) since Forget(, V ) Forget(, V )
iff 0 |= i.e. 0 |= 0 V Definition 8
iff hX \ V, 0 |=? (ii) Proposition 3 (X \ V \ V = 0 \ V )
iff hH, |=? Forget? (, V ) hH, V hX \ V, 0 Definition 8.
() |= Forget(, V )
iff |= i.e. |= V Corollary 5
iff hX, |=? V (ii) Proposition 3
iff hX \ V, |=? Forget? (, V ) hX \ V, V hX, Definition 8
iff hX \ V, |=? Forget? (, V ) since Forget? (, V ) ? Forget? (, V )
iff hX 0 , 0 |=? hX \ V, V hX 0 , 0 Definition 8
64



fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

iff 0 |= i.e. 0 |= V 0 (ii) Proposition 3
iff |= Forget(, V ) Corollary 5.



Theorem 12 (?-forgetting vs propositional forgetting) Let two formulas LA
V A.
? Forget? (, V ) iff (A) |= ? [] Forget((A) {? []}, V V 0 ).
model (A).
Proof: () Let =
0
|= (A) {? []}
|= Proposition 8
iff hMA ,
0
?
|= Forget (, V ) since Forget (, V )
iff hMA ,
0
?
?
?
?
Definition 8
iff hH, |=? hH, V hMA ,
0

iff hH, |=? H V V
0
0
iff H |= (A) {? []} H V 0 V 0 MA0 Proposition 8
iff H 0 |= (A) {? []} H 0 V V 0 MA0 Lemma 4
iff MA0 |= Forget((A) {? []}, V V 0 ) Definition 8
iff |= Forget((A) {? []}, V V 0 ).
() hX, |=?
iff X 0 |= (A) {? []} Proposition 8
iff X 0 |= (A) Forget((A) {? []}, V V 0 )
iff |= (A) {? []} V V 0 X 0
|= X Proposition 8
iff hMA ,
0
V
?

A0
Definition 8.
iff hX, |=? Forget? (, V ) due hX, V hMA ,
0



Proposition 16 Let two formulas LA V set atoms. Forget? (, V ) ?
Forget? (, V ) iff following condition holds:
Forget({? []} (A), V V 0 ) Forget({? []} (A), V V 0 ).
Proof: () show Forget({? [] (A), V V 0 ) |= Forget({? [] (A), V V 0 ).
side similarly proved.
|= Forget({? []} (A), V V 0 )
N A0 N V V 0 N |= {? []} (A)
hX, |=? N = X 0 Proposition 8
hX, |=? Forget? (, V ) (iii) Proposition 10
hX, |=? Forget? (, V ) Forget? (, V ) ? Forget? (, V )
hH, |=? hH, V hX, Definition 8
H 0 |= ? [] (A) Proposition 8
X 0 |= Forget({? []} (A), V V 0 ) H 0 V V 0 X 0
|= Forget({? []} (A), V V 0 ) V V 0 X 0 (= N ).
() show Forget? (, V ) |=? Forget? (, V ). side similar.
hH, |=? Forget? (, V )
hX, |=? hH, V hX, i) Definition 8
X 0 |= {? []} (A) Proposition 8
X 0 |= Forget({? []} (A), V V 0 )
65

fiWANG , Z HANG , Z HOU , & Z HANG

X 0 |= Forget({? []} (A), V V 0 )
H1 T10 |= {? []} (A) H1 T10 V V 0 X 0
hH1 , T1 |=? Proposition 8
hX, |=? Forget? (, V ) hX, V hH1 , T1 Definition 8
hH, |=? Forget? (, V ) hX, V hH, i.



Theorem 14 Let two formulas V set atoms.
(i) problem deciding ? Forget? (, V ) co-NP-complete.
(ii) problem deciding Forget? (, V ) ? Forget? (, V ) P2 -complete.
(iii) problem deciding ? Forget? (, V ) P2 -complete.
Proof: (i) Membership. Recall |=? Forget? (, V ) (iii) Proposition 10.
6? Forget? (, V )
iff Forget? (, V ) 6|=?
iff hX, |=? Forget? (, V ) hX, 6|=?
iff hH, |=? hH, V hX, hX, 6|=? .
Since guessing hH, i, hX, checking ?-satisfiability done polynomial
time size V . Thus complement 6? Forget? (, V ), i.e. ? Forget? (, V ),
co-NP.
hardness follows fact that, (i) Proposition 15, ? Forget? (, V ) iff
Forget(, V ), co-NP-complete (cf., see Lang et al., 2003, Prop. 10).
(ii) Membership. Forget? (, V ) 6? Forget? (, V ) exists ?-interpretation hH,
either
(a) hH, |=? Forget? (, V ) hH, 6|=? Forget? (, V ),
(b) hH, 6|=? Forget? (, V ) hH, |=? Forget? (, V ).
one hand, guess ?-interpretation hH, feasible nondeterministic Turing machine. hand, checking hH, |=? feasible deterministic Turing machine;
hH, |=? Forget? (, V ) iff exists hX, |=? hX, V hH, i. Thus
checking conditions (a) (b) done polynomial time size calling
nondeterministic Turing machine. Thus problem P2 .
Note that, (ii) Proposition 15, Forget? (, V ) ? Forget? (, V ) iff Forget(, V )
Forget(, V ), P2 -complete (cf., see Lang et al., 2003, Prop. 24). Thus hardness
follows.
(iii) Membership. Note 6? Forget? (, V ) iff ?-interpretation hH,
hH, |=? hH, 6|=? Forget? (, V ),
hH, 6|=? hH, |=? Forget? (, V ).
Similar case (ii), guessing checking polynomial time size ,
V calling nondeterministic Turing machine. Thus problem P2 .
Note ? Forget? (, V ) iff ? Forget? (, V ) Forget? (, V ) ? Forget? (, V ),
latter P2 -hard (ii). hardness follows.

66

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

Proposition 17 Let two formulas V set atoms.
(i) problem deciding whether |=? Forget? (, V ) P2 -complete.
(ii) problem deciding whether Forget? (, V ) |=? co-NP-complete.
Proof: (i) Membership. Recall 6|=? Forget? (, V ) iff exists ?-model hH,
hH, 6|= Forget? (, V ). hH, 6|= Forget? (, V ) iff hX, 6|= every ?interpretation hX, hX, V hH, i. hH, guessed polynomial
time size , V . Checking hH, 6|= Forget? (, V ) possible polynomial time
size , V calling nondeterministic Turing machine. Thus original problem
p2 .
Hardness. follows following fact:
> |=? Forget? (, V )
iff > ? Forget? (, V )
iff > Forget(, V ) (i) Proposition 15 (> ? >)
iff QBF V V valid, P2 -complete (Papadimitriou, 1994).
(ii) Membership. Note
Forget? (, V ) 6|=?
iff hH, |=? Forget? (, V ) hH, 6|=
iff hX, |=? hX, V hH, hH, 6|= .
Since guessing checking polynomial size , V , original problem
co-NP.
Hardness follows fact
Forget? (, V ) |=?
iff |=? (ii) Proposition 10
iff ?-model, co-NP-complete Proposition 9.


Appendix D. Forgetting Operators FW FS
Wong proposed six postulates argued postulates respected forgetting
operators disjunctive logic programs strong equivalence:
(F-1) |=HT F (, a) |=HT F (, a);
(F-2) appear , F ({r} , a) HT F ({r}, a) ;
(F-3) F (, a) contain atoms ;
(F-4) F (, a) |=HT r F ({s}, a) |=HT r Cn();
(F-5) F (, a) |=HT (A B, C), |=HT (A B, C, a);
(F-6) F (F (, a), b) HT F (F (, b), a)
F forgetting operator, , disjunctive logic programs, b atoms, r
disjunctive rule,
Cn() ={r| r disjunctive rule |=HT r var(r) var()}.
67

fiWANG , Z HANG , Z HOU , & Z HANG

var() set atoms occurring .
Accordingly, proposed two forgetting operators FS FW : result forgetting atom
disjunctive logic program defined procedure:
(1) Let 1 = Cn().
(2) Form 1 , remove rules form (A B, a, C), replace rule form (A
{a} B, C, a) (A B, C, a). Let resulting logic program 2 .
(3) Replace remove rule 2 , form (A B, C, a) (A {a}
B, C) according following table:

W

B, C,
(remove)
B, C

{a} B, C
(remove)
B, C

Let 3 resulting logic program.
logic program 3 result forgetting p .

References
Alfred, H. (1951). sentences true direct unions algebras. Journal Symbolic
Logic, 16(1), 1421.
Bobrow, D. G., Subramanian, D., Greiner, R., & Pearl, J. (Eds.). (1997). Special issue relevance
97 (1-2). Artificial Intelligence Journal.
Cabalar, P., & Ferraris, P. (2007). Propositional theories strongly equivalent logic programs.
Theory Practice Logic Programming, 7(6), 745759.
Delgrande, J. P., Schaub, T., Tompits, H., & Woltran, S. (2013). model-theoretic approach
belief change answer set programming. ACM Transactions Computational Logic, 14(2),
A:1A:42.
Eiter, T., Fink, M., Tompits, H., & Woltran, S. (2004). eliminating disjunctions stable logic
programming. Principles Knowledge Representation Reasoning: Proceedings
Ninth International Conference (KR2004), pp. 447458, Whistler, Canada. AAAI Press.
Eiter, T., & Wang, K. (2008). Semantic forgetting answer set programming. Artificial Intelligence,
172(14), 16441672.
Faber, W., Pfeifer, G., & Leone, N. (2011). Semantics complexity recursive aggregates
answer set programming. Artificial Intelligence, 175(1), 278298.
Ferraris, P. (2005). Answer sets propositional theories. Logic Programming Nonmonotonic Reasoning, 8th International Conference, Vol. 3662 Lecture Notes Computer Science, pp. 119131, Diamante, Italy. Springer.
Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. Artificial Intelligence, 175(1), 236263.
Ferraris, P., & Lifschitz, V. (2005). Mathematical foundations answer set programming.
Artemov, S. N., Barringer, H., dAvila Garcez, A. S., Lamb, L. C., & Woods, J. (Eds.),
Show Them! Essays Honour Dov Gabbay, Vol. 1, pp. 615664. College Publications.
68

fiK NOWLEDGE F ORGETTING



NSWER ET P ROGRAMMING

Gabbay, D. M., Pearce, D., & Valverde, A. (2011). Interpolable formulas equilibrium logic
answer set programming. Journal Artificial Intelligence Research, 42, 917943.
Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming. Proceedings Fifth International Conference Symposium Logic Programming, pp.
10701080, Seattle, Washington. MIT Press.
Goranko, V., & Otto, M. (2007). Handbook Modal Logic, Vol. 3, chap. 5 Model Theory Modal
Logic, pp. 249329. Elsevier.
Jongh, D. D., & Hendriks, L. (2003). Characterization strongly equivalent logic programs
intermediate logics. Theory Practice Logic Programming, 3(3), 259270.
Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2008). tell difference dl-lite
ontologies?. Principles Knowledge Representation Reasoning: Proceedings
Eleventh International Conference, KR 2008, pp. 285295, Sydney, Australia. AAAI Press.
Lang, J., Liberatore, P., & Marquis, P. (2003). Propositional independence: Formula-variable independence forgetting. Journal Artificial Intelligence Research, 18, 391443.
Lang, J., & Marquis, P. (2010). Reasoning inconsistency: forgetting-based approach. Artificial Intelligence, 174(12-13), 799823.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM Transactions Computational Logic, 2(4), 526541.
Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. Annals
Mathematics Artificial Intelligence, 25(3-4), 369389.
Lin, F. (2001). strongest necessary weakest sufficient conditions. Artificial Intelligence,
128(1-2), 143159.
Lin, F. (2002). Reducing strong equivalence logic programs entailment classical propositional logic. Proceedings Eights International Conference Principles Knowledge Representation Reasoning (KR-02), pp. 170176, Toulouse, France. Morgan Kaufmann.
Lin, F., & Chen, Y. (2007). Discovering classes strongly equivalent logic programs. Journal
Artificial Intelligence Research, 28, 431451.
Lin, F., & Reiter, R. (1994). Forget it!. Proceedings AAAI Fall Symposium Relevance,
pp. 154159.
Lin, F., & Zhou, Y. (2011). answer set logic programming circumscription via logic GK.
Artificial Intelligence, 175(1), 264277.
Liu, Y., & Wen, X. (2011). progression knowledge situation calculus. IJCAI
2011, Proceedings 22nd International Joint Conference Artificial Intelligence, pp.
976982, Barcelona, Catalonia, Spain. IJCAI/AAAI.
Lutz, C., & Wolter, F. (2011). Foundations uniform interpolation forgetting expressive
description logics. IJCAI 2011, Proceedings 22nd International Joint Conference
Artificial Intelligence, pp. 989995, Barcelona, Catalonia, Spain. IJCAI/AAAI.
Osorio, M., & Cuevas, V. (2007). Updates answer set programming: approach based basic
structural properties. TPLP, 7(4), 451479.
69

fiWANG , Z HANG , Z HOU , & Z HANG

Osorio, M., & Zacarias, F. (2004). updates logic programs: properties-based approach.
Seipel, D., & Torres, J. M. T. (Eds.), FoIKS, Vol. 2942 Lecture Notes Computer Science,
pp. 231241. Springer.
Packer, H. S., Gibbins, N., & Jennings, N. R. (2011). on-line algorithm semantic forgetting. IJCAI 2011, Proceedings 22nd International Joint Conference Artificial
Intelligence, pp. 27042709, Barcelona, Catalonia, Spain. IJCAI/AAAI.
Papadimitriou, C. H. (1994). Computational complexity. Addison Wesley.
Pearce, D., Tompits, H., & Woltran, S. (2001). Encodings equilibrium logic logic programs
nested expressions. Proceedings the10th Portuguese Conference Artificial Intelligence Progress Artificial Intelligence, Knowledge Extraction, Multi-agent Systems,
Logic Programming Constraint Solving, pp. 306320, London, UK. Springer-Verlag.
Pearce, D., Tompits, H., & Woltran, S. (2009). Characterising equilibrium logic nested logic
programs: Reductions complexity. Theory Practice Logic Programming, 9(5),
565616.
Su, K., Sattar, A., Lv, G., & Zhang, Y. (2009). Variable forgetting reasoning knowledge.
Journal Artificial Intelligence Research, 35, 677716.
Truszczynski, M. (2010). Reducts propositional theories, satisfiability relations, generalizations semantics logic programs. Artificial Intelligence, 174(16-17), 12851306.
van Ditmarsch, H. P., Herzig, A., Lang, J., & Marquis, P. (2009). Introspective forgetting. Synthese,
169(2), 405423.
Visser, A. (1996). Uniform interpolation layered bisimulation. Godel96, pp. 139164.
Wang, Y., Wang, K., & Zhang, M. (2013). Forgetting answer set programs revisited. IJCAI
2013, Proceedings 23rd International Joint Conference Artificial Intelligence, pp.
11621168, Beijing, China. IJCAI/AAAI.
Wang, Y., Zhang, Y., Zhou, Y., & Zhang, M. (2012). Forgetting logic programs strong
equivalence. Principles Knowledge Representation Reasoning: Proceedings
Thirteenth International Conference, pp. 643647, Rome, Italy. AAAI Press.
Wang, Z., Wang, K., Topor, R. W., & Pan, J. Z. (2010). Forgetting knowledge bases dl-lite.
Annuals Mathematics Artificial Intelligence, 58(1-2), 117151.
Wong, K.-S. (2009). Forgetting Logic Programs. Ph.D. thesis, University New South
Wales.
Zhang, Y., & Foo, N. Y. (2006). Solving logic program conflict strong weak forgettings.
Artificial Intelligence, 170(8-9), 739778.
Zhang, Y., & Zhou, Y. (2009). Knowledge forgetting: Properties applications. Artificial Intelligence, 173(16-17), 15251537.
Zhou, Y., & Zhang, Y. (2011). Bounded forgetting. Proceedings Twenty-Fifth AAAI
Conference Artificial Intelligence, AAAI 2011, pp. 280285, San Francisco, California,
USA. AAAI Press.

70

fi
