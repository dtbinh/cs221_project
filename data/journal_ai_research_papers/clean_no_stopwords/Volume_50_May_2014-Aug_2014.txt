Journal Artificial Intelligence Research 50 (2014) 535-572Submitted 12/13; published 07/14Integrating Queueing Theory SchedulingDynamic Scheduling ProblemsDaria TerekhovTony T. Trandterekho@mie.utoronto.catran@mie.utoronto.caDepartment Mechanical Industrial EngineeringUniversity Toronto, Toronto, Ontario, CanadaDouglas G.downd@mcmaster.caDepartment Computing SoftwareMcMaster University, Hamilton, Ontario, CanadaJ. Christopher Beckjcb@mie.utoronto.caDepartment Mechanical Industrial EngineeringUniversity Toronto, Toronto, Ontario, CanadaAbstractDynamic scheduling problems consist challenging combinatorics, foundclassical scheduling problems, stochastics due uncertainty arrival times,resource requirements, processing times jobs. address two challenges,investigate integration queueing theory scheduling. former reasonslong-run stochastic system characteristics, whereas latter typically deals shortterm combinatorics. investigate two simple problems isolate core differencespotential synergies two approaches: two-machine dynamic flowshopflexible queueing network. show first time stability, fundamentalcharacteristic queueing theory, applied approaches periodically solve combinatorial scheduling problems. empirically demonstrate dynamic flowshop,use combinatorial reasoning little impact schedule quality beyond queueing approaches. contrast, complicated flexible queueing network, novelalgorithm combines long-term guidance queueing theory short-term combinatorial decision making outperforms tested approaches. knowledge,first time hybrid queueing theory scheduling techniquesproposed evaluated.1. Introductionbehave intelligently extended period time, situated agent must abledeal dynamic changes tasks goals. New tasks (e.g., targets surveillance, see Burns, Benton, Ruml, Yoon, & Do, 2012; deliveries, see Bent & Van Hentenryck,2007; requests drink, see Petrick & Foster, 2013) arrive continuously mustincorporated ongoing problem-solving process.Similarly, real-world scheduling problem, set jobs changes customer ordersarrive, processed, leave system. Different jobs different requirementsprocessing different resources, characteristics often become knownarrival job. Depending scheduling horizon, scheduler may numberpossibly conflicting objectives. Examples short-term objectives include minimizingc2014AI Access Foundation. rights reserved.fiTerekhov, Tran, Down, & Becktardiness makespan, long term scheduler may want guaranteefacility handle expected pattern demand without catastrophic failures (e.g.,without number jobs waiting processing becoming extremely large).thesis long-term stochastic reasoning studied queueing theoryusefully combined, theoretically algorithmically, shorter-term combinatorial reasoning traditionally studied scheduling within artificial intelligence(AI) operations research. combination challenging, queueing theoryscheduling developed independently many years and, consequence, different performance measures interest, standard problem settings, assumptions.paper, take steps toward integration queueing scheduling studyingtwo dynamic scheduling problems making following contributions:show fundamental queueing theory notion stability usedanalyze periodic scheduling algorithms, standard approach dynamic schedulingscheduling literature. show, problems studied,periodic scheduling algorithms proved maximally stable: queueingpolicy scheduling approach allow system operate higher loadachieve higher throughput.show, context one dynamic scheduling problem, long-term,stochastic reasoning queueing theory combined short-term combinatorial reasoning produce hybrid scheduling algorithm achieves better performance either queueing scheduling approaches alone.paper organized follows. Section 2 provides necessary backgrounddynamic scheduling algorithms, queueing theory, stability. Next, discuss generalproblem settings assumptions job arrivals time various problemcharacteristics become known. Section 3 addresses first, simpler problem, schedulingdynamic two-machine flowshop, presenting theoretical results stabilityempirical results comparing algorithm performance. Section 4 turns second,complex environment, flexible queueing network. problem schedulingsetting, addition theoretical numerical examination queueingscheduling approaches, propose analyze queueing/scheduling hybrid. Section5, discuss broader implications results scheduling AI problem solving.conclude Section 6.2. Preliminariessection introduces background forms context study. reviewgeneral dynamic scheduling problem two solution approaches: combinatorial schedulingqueueing theory. provide detailed discussion stability, fundamentalanalytical concept use theoretical contributions. Finally, discuss problemsettings assumptions.536fiIntegrating Queueing Scheduling Dynamic Scheduling Problems2.1 Dynamic Scheduling Problemsdynamic scheduling problems interested characterized streamjobs arriving stochastically time. job requires combination resources,sequentially and/or parallel, different processing times. existence particularjob corresponding characteristics known arrival. However, makeassumption, queueing theory unlike typical scheduling settings,stochastic information distribution job arrivals characteristics. Jobs mayrequire complex routing available resources, may heterogeneousknown deterministic capacities.scheduling problem may short- long-term objectives. typicalscheduling contexts, goal construct schedule achieves optimal levelperformance given optimization criterion (e.g., mean flow time) jobsactually arrive. Often settle evaluating algorithm performance finite timehorizon; refer criteria short-term criteria. contrast, long-term objectivesfocus system-level performance measures stability, establishes whetherinstantaneous number jobs remain finite infinite horizon particularsystem parameters.solve dynamic scheduling problem, jobs must assigned appropriate resources start times, respecting resource temporal constraints. jobs arrive,must online process make decisions: possible solve entireproblem offline.Solving dynamic scheduling problems challenging due combinatoricsinteraction jobs, resources, time, due stochastics: make decision,one use information known certainty decision pointstochastic properties scenarios may occur future.2.2 Combinatorial Schedulingclassical scheduling literature, common assume full information: jobscharacteristics known prior decision making. example, job shopscheduling problem (JSP) consists |J| jobs |M | resources (French, 1982). jobconsists set |M | completely ordered activities corresponding processing timeresource requirement: job must use specified resource full, uninterruptedprocessing time. number objective functions defined, common minimize makespan: time start first activityend last one. Many solution approaches proposed, ranging completetechniques branch-and-bound (Carlier & Pinson, 1989; Brucker, Jurisch, & Sievers,1994), mixed integer programming (Bowman, 1959; Manne, 1960), constraint programming (Fox, 1987; Baptiste, Le Pape, & Nuijten, 2001; Beck, 2007; Beck, Feng, & Watson,2011), dispatch rules (Pinedo, 2003) meta-heuristics (Nowicki & Smutnicki, 1996,2005).scheduling literature also addressed problems uncertainty. Pinedo (2003)refers stochastic scheduling problems random variables processingtimes and/or release dates (i.e., arrival times) jobs. acknowledging similaritydynamic problems studied queueing theory, Pinedo points primary537fiTerekhov, Tran, Down, & Beckdifference stochastic scheduling typically concerned optimizing schedulefinite number jobs rather long-term system behaviour potentiallyinfinite stream arriving jobs (Pinedo, 2003, ch. 11). Approaches solving stochasticscheduling problems often involve formulation determinstic scheduling problemoptimize expected value probabilistic measure objective function(Daniels & Carrillo, 1997; Pinedo, 2003; Beck & Wilson, 2007; Wu, Brown, & Beck, 2009),insertion temporal resource redundancy cope realizations random variables(Leon, Wu, & Storer, 1994; Davenport, Gefflot, & Beck, 2001), multi-stage stochasticprogramming (Herroelen & Leus, 2005).solving dynamic problems, scheduling community typically adopts periodic scheduling approach solving collection linked static sub-problems (Bidot, Vidal,Laborie, & Beck, 2009; Ouelhadj & Petrovic, 2009). given time point, staticproblem, consisting jobs currently present system, solved optimizeshort-term objective function. schedule executed (wholly partially)creation next sub-problem triggered. viewpoint means methods developed static scheduling problems become directly applicable dynamic ones.methods effectively deal complex combinatorics optimize qualityschedules static sub-problem. However, tend overlook long-run performancestochastic properties system.examples work modifies short-term objective problemsolving process address fact static problem part long-term schedulingproblem. Branke Mattfeld (2002, 2005) address dynamic job shop problemoverall objective minimizing mean tardiness jobs. use periodic schedulingapproach based genetic algorithm solves sub-problem minimize combination tardiness preference place resource idle time toward endsub-problem schedule. intuition later idle time allows jobs arrivefuture slotted current schedule little disruption. Empirical resultsdemonstrate lower idle time long term compared simply minimizing tardiness.Another example framework Online Stochastic Combinatorial Optimization(OSCO) (Van Hentenryck & Bent, 2006; Mercier & Van Hentenryck, 2007),set existing jobs plus sample future arrivals used create static schedulingsub-problem. Multiple samples optimizations intricately combined arriveset decisions existing jobs. Mercier Van Hentenryck (2007) showalgorithms scale better Markov Decision Processes (MDPs) result goodperformance small expected difference best performanceclairvoyant non-clairvoyant decision makers. Similar approaches developedAI planning (Yoon, Fern, Givan, & Kambhampati, 2008; Burns et al., 2012).examples employ underlying approach dynamic scheduling problems:adapt static technique incorporating intuitive (Branke & Mattfeld, 2002) sampled(Van Hentenryck & Bent, 2006) information future. approaches serveinspiration us develop formal general understanding long-termobjectives achieved solving series short-term, static scheduling problems.538fiIntegrating Queueing Scheduling Dynamic Scheduling Problems2.3 Queueing TheoryQueueing theory mathematical study waiting lines (Gross & Harris, 1998).models systems one servers (machines) one service stationsprocess arriving customer requests (jobs). Fundamentally, queueing theory focusesformal analysis evolution queues related metrics time given particular system definition class systems. standard notation describe queueingprocess, due mainly Kendall (1953), represented A/B/X/Y /Z. describesinter-arrival process (distribution time two successive arrivals), B servicetime distribution, X number parallel machines, buffer size (maximum job capacity system), Z queue discipline (scheduling order). Common distributionsfound literature B deterministic1 (D), exponential (M) general(G). Given defined arrival service time distribution, queueing discipline, numbermachines buffer capacity, queueing literature commonly interesteddetermining steady-state system parameters stability conditions, expected waitingtime expected queue length. Although significant portion literature focusesdescriptive models steady-state performance metrics, transient behaviourprescriptive models also studied, interest paper. Markov processes(Down & Meyn, 1994; Dai & Meyn, 1995; Bolch, Greiner, de Meer, & Trivedi, 2006), fluidmodels (Dai, 1995; Dai & Weiss, 1996), linear programming (LP) models (Andradottir,Ayhan, & Down, 2003; & Karakostas, 2008) typical approaches analyzingqueueing systems.area queueing theory deals prescriptive models frequently calleddesign control queueing systems (Tadj & Choudhury, 2005; Gross & Harris, 1998).queueing design control problems, goal find optimal valuescontrollable parameters queue. parameters include number machinesavailable processing arriving jobs, buffer capacity, arrival rate jobsqueue(s), service rates machine(s), well combination these. Queueingdesign problems static: optimal value controllable parameter determined,becomes fixed characteristic queue. Queueing control problems, contrary,dynamic: goal problems usually determine optimal action takesystem particular state. example, consider retail facility workersserve stochastically arriving customers also perform back-room tasksindependent customer arrival process (Terekhov, Beck, & Brown, 2009). orderoptimize performance facility, one solve queueing design problemfinding optimal number cross-trained servers employ well relatedqueueing control problem determining switch workers twotask types. refer reader papers Tadj Choudhury (2005) Crabill,Gross, Magazine (1977) overviews design control problems involving queues.Queueing theory taken viewpoint that, since impossible create optimalschedule every single sample path evolution system, one aimachieve optimal performance probabilistic sense (e.g., expectation) infinitetime horizon. goal could attained construction policy based globalstochastic properties system. example, policy could specify start time1. Deterministic refers inter-arrival service times value.539fiTerekhov, Tran, Down, & Beckassignments made whenever new job arrives completes processing. However,schedule resulting policy, good quality expectation, mayfar optimal particular realization uncertainty occurs. Moreover,queueing theory generally studies systems simple combinatorics, systemsamenable rigorous analysis stochastic properties.2.4 StabilityStability2 fundamental concept queueing theory forms main parttheoretical analysis. Informally, system stable queues remain bounded time.stability system dependent scheduling policy employs: given setproblem parameters (e.g., arrival processing distributions), one policy may stabilizesystem another might not. Knowledge whether system stable given jobarrival rate, processing rate scheduling policy considered precursor detailedanalysis essential practical applications (Kumar, 1994; Dai & Weiss, 1996).Formally, system operating particular queueing discipline stableMarkov process describes dynamics system positive Harris recurrent (Dai,1995). Positive Harris recurrence implies existence unique stationary distribution.Due considerable notation required, formally define positive Harris recurrence here, instead refer reader work Dai (1995), Dai Meyn (1995)Bramson (2008).special case state space Markov process countable3 statescommunicate, positive Harris recurrence equivalent widely-known conceptpositive recurrence (Bramson, 2008). Markov chain positive recurrent every statepositive recurrent: probability process starting state return1, expected time return state finite (Ross, 2003). particular,property guarantees system empty.2.5 Problem Settingsqueueing theory combinatorial scheduling focus efficient use scarceresources time. However, different emphases (i.e., stochastics vs. combinatorics)indicate may possible combine order provide better understandingof, stronger solution approaches to, dynamic scheduling problems.first challenge study determine problem settings assumptions.queueing scheduling sometimes make differing assumptions, guidedthree heuristics choosing problems. First, sought simplest problem settingsqueueing scheduling arrived solution. example, many singlemachine dynamic scheduling problems, identical, optimal dispatch rules/queueing policiesexist literatures. Second, assumptions two areas consistent,2. Unfortunately, stability multiple meanings closely related literature. scheduling literature,predictive schedule called stable execution close planned (Bidot et al., 2009).Similarly, work scheduling uncertainty, stability analysis concerns identificationrange values processing times may take given schedule remains optimal (Sotskov,Sotskova, Lai, & Werner, 2010). use meaning stability queueing theory.3. process referred continuous-parameter Markov chain book Gross Harris(1998).540fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsadopted them. third, assumptions contradictory, attempted chooserealistic settings also result novel challenging problems.consequence, make following assumptions two systems studied here.queueing, assume know distribution job inter-arrival times.assume job durations become known upon arrival realizationscorresponding known distributions. Queueing models typically assumedistribution job durations known, actual processing time jobavailable completion time.4 classical scheduling literature, exactjob durations known prior construction schedule jobs processedmachine have, general, different durations. knowledge distributionsactual durations upon arrival justified applications historicaldata available similar activities repeatedly executed (e.g.,serving static web page, cutting piece wood standardizeddimensions), adopt assumptions.queue, sequences processing times machines sequenceinter-arrival times independent identically distributed sequences.also mutually independent.Mean processing times mean inter-arrival times finite.inter-arrival times unbounded continuous.final three assumptions standard queueing literature dealingstability analysis (Dai, 1995) satisfied commonly used distributions (e.g., exponential distribution), combination first two assumptions typically receivedmuch attention queueing scheduling literature. setting somewhat similaronline-time setting online scheduling (Pruhs, Sgall, & Torng, 2004) jobs arrivesystem dynamically job processing times become known upon arrival. However,setting makes assumption known inter-arrival duration distributionalinformation.3. Two-Machine Dynamic Flowshopfirst problem consider dynamic two-machine permutation flowshop. Withinsetting, demonstrate stability periodic scheduling approach uses processing time information, provide numerical comparison queueing schedulingapproaches.dynamic two-machine permutation flowshop, arriving jobs must processed firstmachine 1 machine 2, order jobs processed twomachines must same. assume inter-arrival time distribution generalmean 1 , processing time distributions machine 1 2 generalmeans 11 12 , respectively. Thus, load machine 1 1 = 1 , load4. One exception deterministic distribution, durations jobs assumedidentical (Gross & Harris, 1998).541fiTerekhov, Tran, Down, & Beckmachine 2 2 = 2 . 1 2 assumed less 1, knownnecessary conditions stability (Gross & Harris, 1998). job arrives system,processing times machines become known certainty. machinesunary capacity. Preemptions allowed. queues front machine 1machine 2 assumed infinite size. goal problem sequencejobs machine 1 machine 2 order minimize flow time: timearrival job completion machine 2.dynamic flowshop (Park, 1988; Sarper & Henry, 1996; El-Bouri, Balakrishnan,& Popplewell, 2008) extension classical flowshop environmentextensively studied scheduling literature (Widmer & Hertz, 1989; Taillard, 1990).queueing literature, system known tandem queue network queuesseries also received significant attention (Burke, 1956; Reich, 1957; Jackson, 1957;Gross & Harris, 1998; Andradottir & Ayhan, 2005).3.1 Algorithmsconsider four periodic scheduling approaches two-machine dynamic flowshopproblem. case, schedule formed optimizing value interest subproblem: set jobs present system particular time. dynamic flowshop,start time every new sub-problem equal completion time last jobmachine 1 previous sub-problem, Figure 1. Since jobs new sub-problembegin execution scheduled jobs processed first machine,time scheduling may still jobs previous schedule need processingmachine 2. previous scheduling decisions altered next sub-problemsolved.Figure 1: Dynamic flowshop three sub-problems three jobs per sub-problem.start sub-problem start set jobs machine 1, end sub-problemend set jobs machine 2.best knowledge, queueing policy proved optimalflow time objective, even expected sense, dynamic two-machine flowshopassumptions. first two approaches, however, chosen theoreticalresults systems related ours, discussed below. dynamic flowshop, noneperiodic scheduling methods make use distributional information.542fiIntegrating Queueing Scheduling Dynamic Scheduling Problems3.1.1 FCFSJobs sub-problem sequenced non-decreasing order arrival timessystem. FCFS achieves smallest expected flow time two-machine dynamic flowshop class work-conserving, non-preemptive policies use processingtime information (Towsley & Baccelli, 1991). Note periodic FCFS policy createsidentical schedules standard (non-periodic) first-come, first-served policy queueingtheory, jobs processed order arrive.3.1.2 SPTsumJobs sub-problem processed non-decreasing order sum durationsmachine 1 machine 2. policy choice motivated fact that, caseserver single unary resource, shortest processing time first minimizes expectedflow time (Wierman, Winands, & Boxma, 2007).3.1.3 CompletionTimeSince minimizing sub-problem flow time assumptions equivalent minimizingsum job completion times sub-problem, natural sub-problem objectivesum completion times activities second machine. Optimizing totalcompletion time lead best short-run performance unclearmethod perform respect long-run objectives. Minimizing sum completiontimes two-machine flowshop NP-hard (Pinedo, 2003).3.1.4 Makespanfourth method employ motivated reasoning proxy measurespeculate may result strong long-run flow time performance. minimum makespanschedule sub-problem, definition, allows subsequent sub-problem startearly possible machine 2, implying potentially lower flow times future subproblems system empties. Therefore, likely achieve optimalflow time performance sub-problem, conjecture makespan minimizationmay lead better long-run flow time performance.optimal makespan schedule static two-machine flowshop foundpolynomial-time using Johnsons rule (Conway, Maxwell, & Miller, 1967). Johnsons ruledivides jobs two sets: set consists jobs whose processing time machine 1less equal processing time machine 2, set II consistsremaining jobs. Set processed set II. Note that, required, Johnsons rulecreates permutation schedules. Within set I, jobs sequenced non-decreasing orderprocessing time machine 1, within set II, jobs sequenced non-increasingorder processing times machine 2.3.2 Stabilitystudy compare stability one policies useprocessing time information, i.e., FCFS, one policies does, i.e., makespan.particular, show condition stability FCFS follows trivially known543fiTerekhov, Tran, Down, & Beckresults queueing literature. Using result, significantly, showmakespan approach stable condition. best knowledge,first example stability analysis scheduling policies based observed processingtimes.leave study stability two remaining methods utilize processingtime information future work. Showing stability completionTime approach mayprove especially challenging since possesses neither specific structureutilized proof property makes easily comparable FCFS.Theorem 1. min{1 ,2 } < 1, periodic FCFS policy stable two-machinedynamic flowshop.Proof. assumptions, dynamic two-machine flowshop generalized Jacksonnetwork, periodic FCFS policy equivalent standard, non-periodic implementation FCFS. Stability generalized Jackson networks conditionload machine strictly less 1 (in case, /1 < 1 /2 < 1) known(Dai, 1995).result extends |M | > 2 machines: fluid model methodology (Dai, 1995)used show stability FCFS |M |-machine flowshop conditionminm{1,...,|M |} {m } < 1.makespan policy, prove result holds every sample pathevolution system. Let sn tn time points sub-problem n startsmachine 1 completes machine 2, respectively, makespan approach. Let vnvn total processing time jobs completed time tn makespanpolicy arbitrary policy , respectively. Following queueing literature,refer vn vn work completed time tn .Lemma 1. amount work completed tn maximized makespan policy.is, vn vn n non-idling .Proof. arbitrary non-idling policy , vn written vn1, + vn2, , vn1,amount work completed tn machine 1 vn2, amount work completedtn machine 2. (In Figure 2, t0 5, v01, = 5 v02, = 3.) makespan approach,use notation without superscript , i.e., vn = vn1 + vn2 . dynamic flowshop,amount work completed tn machine 1 non-idling policy.Thus, remains prove vn2 vn2, . prove induction.Base Case: v02 v02, since policy makespan complete set initialjobs time makespan (t0 ) later.Inductive Hypothesis: Assume property true tn , is, vn2 vn2, .2,2Inductive Step: need show property tn+1 , i.e., vn+1vn+1.22makespan approach, vn+1 = vn + ((sn , sn+1 ]), ((sn , sn+1 ]) total machine2 workload arrives time period (sn , sn+1 ] and, therefore, workloadprocessed sub-problem starting sn+1 ending tn+1 .induction hypothesis, know tn , vn2 vn2, . amount work2,processed machine 2 time tn+1 policy , vn+1, equals amount work processedtime tn plus fraction difference amount work completed544fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsmakespan tn plus fraction amount machine 2 work arrives2,2 .(sn , sn+1 ]. Thus, vn+1vn2, + (vn2 vn2, ) + ((sn , sn+1 ]) = vn2 + ((sn , sn+1 ]) = vn+1Figure 2: Schedule policy two-machine flowshop.Figure 3: Schedule makespan problem instance Figure 2.example, consider schedules Figures 2 3: s0 = 0, s1 = 4, s2 = 9, t0 = 5,t1 = 11, t2 = 14, v22 = v12 + ((s1 , s2 ]) = 9 + 3 = 12, v22, = 7 + (9 7) + 1 12.5lemma hold idling since idling policy may create better schedulewaiting taking jobs account.Theorem 2. min{1 ,2 } < 1 periodic makespan policy stable twomachine dynamic flowshop.Proof. know FCFS stable given condition. Lemma 1, everysub-problem completion time, makespan approach finished least much workFCFS. Therefore, two-machine dynamic flowshop periodic makespan policystable condition FCFS.theorem provides sufficient condition stability. noted above,literature (see e.g., Gross & Harris, 1998), know 1 < 1 2 < 1 necessaryconditions stability system. Since ensuring min{1 ,2 } < 1ensuring 1 < 1 2 < 1, see min{1 ,2 } < 1 necessary sufficient conditionstability dynamic two-machine flowshop makespan policy.5. assume J7, J8 J9 arrive time period (4, 9].545fiTerekhov, Tran, Down, & BeckFigure 4: Schedule FCFS dynamic flowshop three machines.Figure 5: Schedule makespan dynamic flowshop three machines.Lemma 1 hold |M |-machine flowshop |M | > 2. illustratefact, consider problem instance Figures 4 5. example, sub-problem 0consists jobs J0 J1, makespan policy FCFS constructschedule, t0 = 7. second sub-problem consists J2 J3, two policiesresult different schedules. t0 = 7, amount work completed makespanv0 = 12, whereas amount work completed FCFS v0 = 13. Therefore,case, v0 < v0 , shows possible amount work completed tnmaximized makespan policy. nonetheless conjecture Theorem 2 extendscase two machines proved using fluid model approach.3.3 Numerical Resultspresent experiments comparing performance FCFS, SP Tsum , makespan completionTime models minimizing mean flow time long time horizon. completionTime model implemented via constraint programming ILOG Scheduler 6.5546fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsuses completion global constraint (Kovacs & Beck, 2011). remaining methodsimplemented using C++.evaluate performance four methods dynamic flowshop, consideredsystem exponentially distributed inter-arrival times exponentially distributedprocessing times means machines. Experiments uniformlydistributed processing times showed identical performance. parameters chosensatisfy stability conditions Theorems 1 2. fixed mean inter-arrival time,1/, 10, varied load system 0.1 0.95 changing meansprocessing time distributions 1 9.496. Note Theorems 1 2,parameters guarantee stability FCFS makespan. results experimentsshown Figure 6. point figure represents mean flow time 100 probleminstances 55,000 jobs each.experiments, completionTime model run time limit 1 second per sub-problem order ensure reasonable run-times. Moreover, since constraintprogramming efficient integer, rather real-valued, durations, usingcompletionTime approach set durations ceiling actual durationsmultiplied 100; resulting processing sequence used construct actualsub-problem schedule. Note time limit, completionTime always findoptimal sub-problem schedule. run Dual Core AMD 270 CPU 1MB cache, 4GB main memory, Red Hat Enterprise Linux 4, completionTimemodel able solve 100% sub-problems optimality loads 0.1 0.3,percentage decreases average 81.3% instances 0.95 load. changeperformance due increase sub-problem size load increases: averagesub-problem size increases 1.009 0.1 load 5.452 0.95 load,maximum sub-problem size encountered instances increases 5 0.1 load172 0.95 load. Experiments time limit 5 seconds showed similarperformance, mean flow time 0.95 load decreasing 368.985 (from 371.434completionTime model 1 second time limit) percentage instancessolved optimality 0.95 load increasing 83.8% machine 4 Intel Corei7-2600 CPUs @ 3.40GHz 8 MB cache 9871 MB main memory, running Red HatEnterprise Linux 6.3.Figure 6 shows little difference among methods. completionTimeslight advantage others loads 0.7 less. makespan modelbetter FCFS completionTime loads 0.8. SP Tsum best-performingmodel loads 0.8, static sub-problems become large. last observationsupported results Xia, Shanthikumar, Glynn (2000), shownSP Tsum asymptotically optimal static average completion time objectivenumber jobs two-machine flowshop increases. However, asymptotic resultimply applying SP Tsum sub-problem results best long-run behaviourhigh loads. FCFS, hand, worst performer loads,marginally so.empirical results contradictory Theorem 1. particular, factmakespan results largest amount workload completed particular timepoint imply minimize mean flow time. example, considersub-problem 1 Figure 3: sequence displayed figure, J5 J6 J4,547fiTerekhov, Tran, Down, & Beck200FCFSmakespanSPT_sumcompletionTime0100Mean Flow Time300Mean Flow Time Various Queue Loads0.20.40.60.81.0LoadsFigure 6: Mean flow times dynamic two-machine flowshop FCFS, SP Tsum , completionTime makespan models system load varies.sequence J6 J5 J4 minimize makespan, latter sequence achievelower total completion time (26 opposed 28 first sequence) hence lowermean flow time sub-problem.3.4 Discussionstudy dynamic two-machine flowshop provides partial support thesisutility combining queueing scheduling. shown stability analysisapplied periodic scheduling algorithms algorithms reasoncombinatorics achieve stability guarantees traditional queueing theoryapproaches. However, system able empirically demonstratescheduling algorithms (completionTime makespan) result better mean flow timeperformance queueing approaches.low loads, methods perform equivalently due small sub-problems; high loads,differences performance lead following observations. Firstly, performancecompletionTime degrades due inability find good solutions large sub-problemsgiven time limit; able find better solution, completionTime defaultsFCFS schedule. Secondly, motivation using makespan approach548fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsmaterialize: differences makespans makespan approach SPTsumlarge enough offset differences total completion time (which favourSPTsum ). Finally, conjecture implementation completionTime defaultsSPTsum schedule would outperform current approaches highest load.improvement result finding, sub-problem, optimal totalcompletion time schedule lowest possible makespan.Subsequent analytical work problem setting shows completionTimeapproach results smaller long-run mean flow time time periods makespan if,majority sub-problems, difference completionTime makespanindividual sub-problem total completion times larger difference makespansprior start sub-problem. Furthermore, complex problem setting(i.e., polling system two-machine flowshop server) shown, analyticallyempirically, objective minimizing long-run flow time, algorithmminimizes makespan sub-problems outperforms one minimizes sumcompletion times (Terekhov, 2013, ch. 7). results directly addresscombination queueing scheduling approaches, demonstrate impactsub-problem optimization criteria long-term performance measures delicateyet well understood.4. Queueing Network Flexible Serversdeeply investigate combination queueing theory scheduling, examinesecond system different combinatorial structure. first problem, provideanalysis stability numerical comparison queueing scheduling approaches.However, unlike first problem, setting also propose evaluate hybridqueueing/scheduling algorithm.system interest queueing network heterogeneous servers requiredserve jobs belonging specific classes. problem example classical queueingsystem (Bramson & Williams, 2000; Andradottir et al., 2003). system differsdynamic flowshop jobs may processed machine, assignmentjob machine must made. Jobs arrive time via arrival process rategenerally distributed inter-arrival times. arriving job belongs class kprobability pk . assume preemptions: job begins executionmust processed full processing time. server assigned job classk, jobs processing time generally distributed rate mk ; job j arrivessystem, processing times server become known denoted dmj .assume servers able serve jobs classes. multiple servers workingsingle class point time, work parallel job servedexactly one server.equivalent static problem scheduling literature parallel machinescheduling problem (Pinedo, 2003). However, scheduling literature either assumes machines related unrelated. related parallel machine scheduling problem,machine inherent speed determines job processing times. machine twicefast machine b, always require half time process job machineb does. machines unrelated, correlation processing times job549fiTerekhov, Tran, Down, & Beckdifferent machines. queueing network problem, processing times givenjob class stochastically related drawn distributiongiven machine. However, class relationships across different machinesmay ok < mk ol > ml 6= o, k 6= l. adopt queueing theoryassumption.4.1 Algorithmspresent five different approaches scheduling jobs queueing network flexibleservers: two queueing policies, two scheduling policies, hybrid queueing theoryscheduling method.illustrate five approaches, present small example possible realizationsystem two servers two job classes. total five jobs: threebelonging class 1 two belonging class 2. job represented J{k,j},k represents class job j job number. Table 1 provides arrivalprocessing times two machines (servers) job example. Noticeservers process class 2 jobs amount time, server 2 1.5 timesslower server 1 jobs class 1.{Class, Job ID}Arrival TimeServer 1 Processing TimeServer 2 Processing TimeJ{1,1}1812J{1,2}369J{1,3}546{2,1}066{2,2}1266Table 1: Example job arrival processing times.two queueing policies employ periodic scheduler. Instead, dispatchrules used decide job processed server becomes available.policies, linear program (LP), called allocation linear program, used determineportion total capacity server allocate job class (Andradottiret al., 2003). LP solved once, scheduling decisions made.allocation LP derived fluid representation queueing network assumesnumber jobs present system large exhibit propertiescontinuous fluid (Chen & Yao, 1992; Dai, 1995). allocation LP follows:max|M |Xs.t.mk mk pk , k K(1)m=1|K|Xmk 1,mM(2)k K;(3)k=1mk 0550fiIntegrating Queueing Scheduling Dynamic Scheduling Problems: arrival rate jobs,mk : fractional amount time server spend class k jobs,K: set job classes,: set servers.decision variables problem mk . objective maximizearrival rate jobs maintaining stability system. Stability achievedconstraint (1) ensures total capacity allocated job class greaterequal total amount work generated job class.solution allocation LP provides tight upper bound maximum arrivalrate system stabilized, , values resource allocation(Andradottir et al., 2003). However, provide method assignproportions, mkjobs servers decide sequence jobs. make decisions,Round Robin policy (Andradottir et al., 2003) linear programming-based affinityscheduling (LPAS ) heuristic (Al-Azzoni & Down, 2008) used.4.1.1 Round RobinRound Robin policy, server cyclically visits classes Vm , Vm> 0. serving class k Vm , serverordered list classes k mk mkprocesses lmk jobs moving next class. server idlepoint lmk jobs served, switches next class Vm . Given desired arrival1rate , let =+ , mk = mk , let 1{mk > 0} function equal 1values sufficientlymk > 0 0 otherwise. Andradottir et al. (2003) show mktracked stabilize system lmk chosenP> 0})(1 )( lK ml 1{mkmklmk =.mkFigure 7 shows schedule produced Round Robin policy five-job exam = 1, = 0, = 0.5, = 0.5.ple. Assume allocation LP results 11122122is, server 1 handles jobs class 1 only, server 2 handle classes. Further,assume calculated lmk value greater three server class pairs.situation, example three jobs per class, Round Robin policychange classes server processing available tasksclass start immediately. time 0, J{2,1} present system. Since server 2server handle class 2 jobs, job assigned begin immediately server 2.J{1,1} arrives, server 1 able start job instantly. Server 2 completes J{2,1}time 6, two jobs class 1 queue. Server 2 begins processing J{1,2}since arrived first. Server 1 completes J{1,1} time 9 starts processing J{1,3}.Server 1 completes J{1,3} server 2 completes J{1,2}. Although J{2,2} waiting= 0. J{2,2} must waitqueue time 13, assigned server 1 12server 2 available time 15. example schedule ends time 21 completionJ{2,2}.4.1.2 LPAS> 0 expected completeLPAS assigns arriving job machine mkjob earliest time. LPAS heuristic similar Round Robin,551fiTerekhov, Tran, Down, & BeckFigure 7: Example schedule produced Round Robin policy LPAS.guarantee stability. Rather, heuristic usesreason relative magnitudes mkmk reason server-class pairs efficient assignments. stabilityLPAS open question, though shown empirically perform well termsnumber jobs system (Al-Azzoni & Down, 2008).Figure 7 also presents schedule produced LPAS five-job example. SimilarRound Robin policy, assume allocation LP results server 1 processing class 1only, server 2 handling classes. time 0, J{2,1} arrives assigned server2. J{1,1} arrives time 1 processed either server. Starting immediatelyserver 1 would lead earlier completion time J{1,1}, make assignment.J{1,2} arrives time 3 also considered servers. Starting J{1,2} server 2time 6 leads earliest completion time, hence assignment made. J{1,3}arrives time 5 complete earliest assigned server 1. Finally, J{2,2} mustassigned server 2 end schedule. Therefore, resulting scheduleparticular example Round Robin policy LPAS.two scheduling models study, one simple dispatch policy similarqueueing policies presented above, second makes use periodic scheduler.4.1.3 MinFTdispatch policy MinFT greedily minimizes flow time jobs without exploitingsolution allocationPLP. setting, flow time job j, assignedserver m, fmj = + xm dmx + dmj , represents thePtotal remaining timeserver busy job currently served, xm dmx sumprocessing times jobs belonging , set jobs queued server m.job arrives, assigned server results smallest flow timejob given jobs already scheduled. Ties broken arbitrarily. Jobs sequencedfirst-come, first-served (FCFS) order server.schedule produced MinFT five-job example shown Figure 8.start schedule, J{2,1} considered servers, leadscompletion time either, MinFT arbitrarily chooses one servers. case,assume servers chosen lexicographically, job assigned server 1. time1, assigning J{1,1} server 2 lead smaller flow time, hence assignmentmade. process continues job, results schedule Figure 8.552fiIntegrating Queueing Scheduling Dynamic Scheduling ProblemsFigure 8: Example schedule produced MinFT.4.1.4 Makespanflowshop studied above, makespan model periodically solves static makespanminimization problems. period defined time scheduler evaluatessystem server available. jobs belonging previous periodyet completed stay assigned before.problem NP-hard, polynomial-time algorithms minimizemakespan two-machine dynamic flowshop problem. use mixed-integerprogramming (MIP) solve minimum makespan scheduling problem. beginningevery period, following MIP model solved minimize makespan setunscheduled jobs:min Cmax|J|Xs.t.xmj dmj + Cmax ,mM(4)jJ(5)j J;(6)j=1|M |Xxmj = 1,m=1xmj {0, 1},Cmax :xmj ::makespan period,1 job j assigned server m, 0 otherwise,remaining time server busy serving jobs belonging schedulesmade previous periods,J: set jobs scheduled period.model minimizes makespan, Cmax , constrained greaterequal maximum scheduled busy period server. amount timeP|J|server busy able serve new jobs, j=1 xmj dmj totalprocessing time allotted new jobs server m. sum two terms equalstotal time server busy following schedule. Constraint (5) ensuresjob assigned exactly one server.MIP model assigns jobs servers sequence jobs. orderachieve makespan since processing times jobs sequence independent.553fiTerekhov, Tran, Down, & Beckallow direct comparison policies defined above, FCFS used jobsassigned machines.Figure 9 gives schedule produced makespan five-job example. time0, 1 job available, makespan schedules J{2,1}. Assignment server 12 leads makespan, arbitrarily choose server 1. J{1,1} arrives,new sub-problem created since server 2 idle begin processing jobs immediately.Assigning arriving job server 2 leads minimizing makespan sub-problem 1.time 6, server 1 becomes idle finds two jobs queue (J{1,2} J{1,3}). Minimizingmakespan sub-problem 2 requires J{1,2} J{1,3} assigned server 1.final sub-problem starts time 13 server 2 finishes J{1,1}. point, onejob queue, assigned server 2 minimize makespan sub-problem 3.Figure 9: Example schedule produced makespan model.MinFT reason future jobs, makespan thoughtindirectly saving resources future jobs minimizing makespan current period.ability makespan model deal complex combinatorics allows takeadvantage systems state information, Round Robin LPAS able useknowledge processing arrival rates manage allocation servers. approachable reason types information may improve overall performance.Thus, integrate scheduling queueing theory algorithmic level createhybrid model.4.1.5 Hybrid Modelhybrid model periodic scheduler uses makespan model frameworkemploys mkvalues allocation LP. Recall values indicate bestlong-run proportional allocation servers job classes. MIP model solvedperiod is:554fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsmin Cmax + (1 )|M | |K|XXcmkm=1 k=1s.t.Constraints (4) (6)|J|XXxmj dmj mkxmj dmj cmk , k K;jSk(7)j=1cmk 0,k K;(8)cmk : deviation realized assignment server class ksuggests,mk: input parameter used scale importance deviation mkvalues versus makespan,Sk : set jobs belong class k.MIP model bi-criteria objective minimizing makespan deviationvalues. trade-off makespan deviation expressed ,mk0 1. = 1, model makespan model.Figure 10 illustrates schedule hybrid model might produce five-job= 1, = 0, = 0.5,values before, i.e., 11example assuming mk122122 = 0.5, assuming chosen close 1. Using high value makesillustration models behaviour simpler. Further, choice ensures minimizingvalues used breaking tiesmakespan important objective, mkdifferent schedules produce makespan. time 0, sub-problem 0 solvedJ{2,1} system. Although makespan regardlessserver responsible job, hybrid model chooses make assignment server= 0 = 0.5. Sub-problem 1 starts time 1 J{1,1} arrives2, 1222assigned server 1. time 6, J{1,2} J{1,3} queue, sub-problem 2 starts.J{1,2} assigned server 1 J{1,3} assigned server 2 minimize makespansub-problem 2. time 12, sub-problem 3 begins J{2,2} scheduled server 2.Figure 10: Example schedule produced hybrid model.555fiTerekhov, Tran, Down, & Beck4.2 Stabilityknow work Andradottir et al. (2003) Round Robin policy stable< , maximum stabilizable arrival rate. stability LPAS heuristicyet established.examine stability two scheduling policies hybrid model presentedabove. stability conditions makespan hybrid model determinedcomparison Round Robin policy. MinFT model shown guaranteestability conditions Round Robin policy.4.2.1 Stability MakespanGiven Round Robin achieve desired capacity < , followingtheorem.Theorem 3. Round Robin stable given arrival process rate ,makespan model also guaranteed stable.Proof. prove stability conditions makespan assuming makespan unstableRound Robin stable, deriving contradiction. Let Jt set jobssystem time makespan policy. assumption makespan (denotednotation) unstable means limt E(|Jt |) = .time t0 , makespan model completes period schedules set Jt0 .Denote earliest start time latest end time jobs Jt0 makespan policy S(Jt0 ) F (Jt0 ), respectively. makespan model minimize makespan,C(Jt0 ) = F (Jt0 ) S(Jt0 ). However, work remaining previous periods servers,represented , must accounted for. J 0 set jobs previous period,left-over work bounded maxmM ;jJ 0 (dmj ) server residualwork greater largest processing times would job reassignedfree machine previous sub-problem reduce sub-problem makespan.worst case, servers except one busy time next period oneserver available immediately, delaying optimal schedule less time units.define minimum makespan scheduling Jt0 residual work ignoredC (Jt0 ). easy show C(Jt0 ) C (Jt0 ) + . exists number jobs|J|1C (J)C(J)=1C(J)C(J), 0. true number jobs increases, becomes|J|negligible compared actual makespan schedule. Therefore, numberjobs system increases without bound, makespan converges optimal. Sincethroughput system exit rate jobs Round Robin best matchminimum makespan, system reached sufficiently large size J,throughput makespan least large Round Robin policy. Therefore,find contradiction: makespan cannot unstable Round Robin stablethroughput makespan least large Round Robin policy. Thus,guaranteed stabilizable system stabilized makespan.556fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsaspect proof technique,Note dependence |J|requirement stability. Stability property system dependnumber jobs system. However, proof depends achieving minimummakespan sub-problem, requires solving NP-hard problem. returnpoint Section 5.4.2.2 Stability Hybridprove stability conditions hybrid model way makespan.valuesfirst show exists minimum makespan schedule tracks mknumber jobs period sufficiently large.Proposition 1. number jobs scheduled period approaches , existsvalues allocation LP.schedule minimum makespan tracks mkProof. Denote set jobs schedule period J, set jobs assigned, makespanserver class k Qmk , resulting makespan server Cmsystem overPall machines set jobs J Cmax . time server spendsjobs class k jQmk dmj . proportion time server spends class k,denoted mk ,PPjQmk dmjjQmk dmjPmk = P.=CmkKjQmk dmjUsing Law Large Numbers, knowX1(dmj ) = 1mk .|Q||Qmk |mklimiQmkTaking limit number jobs system, |J|, goes , gives(|Qmk |lim|J| |Qmk | = ,lim|J| mkCmaxlim mk =|J|0lim|J| |Qmk | < .(1)multiply mk mk sum machines, getlim|J||M |Xmk mk = limm=11|J| Cmax|M |Xm=1pk |J|,C|J| max|Qmk | = limleft-hand side constraint (1) allocation LP. Re-arranging terms leads|M |Xmk mkpk |J||J|= lim= lim.pk|J||J| pk Cmax|J| Cmaxlimm=1Here, see since allocation LP aims maximize , equivalent minimizingmakespan Cmax, therefore schedule exists minimum makespan alsotracks mk .557fiTerekhov, Tran, Down, & BeckTheorem 4. Round Robin stable given arrival process rate ,hybrid model also stable.Proof. proof based proof Theorem 3. makespan replacedhybrid model (denoted h used superscript) proof follows exceptC h (Jth ) 6 C (Jth ). Due bi-criteria objective, model guaranteeminimum makespan schedules.take |J| , Proposition 1 states minimum makespan scheduletrack mkvalues cmk goes 0. Therefore, sufficiently largesystem size, cmk small enough ensure makespan schedule convergesmakespan and, similarly Theorem 3, hybrid model guarantees stabilitystabilizable system.4.2.3 Instability MinFTshow MinFT model cannot handle < , provide counter-example.Assume system two servers two job classes. arrival ratesystem = 1 p1 = p2 = 0.5. 11 = 10, 21 = 9, 12 = 9, 22 = 10,= 1, = 0, = 0, = 1 get = 20. orderallocation LP would assign 11211222system stable particular , scheduling algorithm must adequately trackvalues. , available freedom algorithm deviate goesmkmk0.Assignments MinFT model made greedily server minimizejobs flow time. Denoting completion time latest job server ,know arriving job j served faster server rather slowerserver l unless inequality + dmj > l + dlj true. inequality true,MinFT model assign arriving job server l since completion timeearlier. define j = dlj dmj j << dmj since differenceprocessing rates order magnitude smaller processing rates themselves.Consider two cases: (1) |1 2 | > j , (2) |1 2 | < j . case (1), arrivingjob assigned server smaller regardless classserver busy. MinFT model follows efficient assignment use faster servercase (2). case (1) scheduler make efficient assignment 50%time arriving job equal probability belonging either class. needshow P (|1 2 | > j ) > 0, MinFT model cannot guarantee stability likeRound Robin policy. Assume inequality false, i.e., P (|1 2 | > j ) = 0.scenario, know system point time adheres |1 2 | < j . However,job arrives, must scheduled onto one servers, making |1 2 | > minm1,2 (dmj )j > j . inequality results contradiction since, certainty, next arrivingjob force system case (1). Since case (1) occurs positive probability,inefficient assignment occur non-zero probability. Denote probabilityinefficient assignments b1 = P (1 2 > j )p1 b2 = P (1 2 < j )p2b = b1 = b2 (0.5)(0.5) system symmetry. realized proportions timeserver spends classes 11 = 1 b, 21 = b, 12 = b, 22 = 1 b. Therefore,obtainable capacity10(1 b) + 9b + 9b + 10(1 b) = 20 2b < 20,558fiIntegrating Queueing Scheduling Dynamic Scheduling Problemsb > 0. simple system, 2b < < , MinFT model cannotguarantee stability.4.3 Numerical Resultsexperimentally compare mean flow time performance proposed models. Twodifferent cases tested: two job classes two servers, four job classes fourservers. test case, five different loads 0.8 0.99 maximumtheoretical load simulated. load, 20 instances run 10,000 time units,resulting total 100 simulations per model two systems.Job arrivals follow Poisson process. order maintain relative processing timessingle job server, amount work job, wj , generated usingexponential distribution rate 1; augmented linearly processing ratewjserver, based jobs class, create processing time dmj = mk. useprocessing rates mk ranging one job per time unit ten jobs per time unit. testcases asymmetric: processing rates classes different different servers.Symmetric systems examined emphasize heterogeneity network.simulation implemented C++. LP MIP models use IBM ILOGCPLEX 12.1. experiments performed Dual Core AMD 270 CPU 1 MBcache, 4GB main memory, running Red Hat Enterprise Linux 4. Preliminary resultsshowed = 0.6 provided best performance hybrid method (Tran, 2011).Mean Flow TimeRound RobinMinFTLPASmakespanHybrid1100108082848688909294Percent Maximum Theoretical Load9698100Figure 11: Comparison mean flow times flexible queueing network two serverstwo classes.559fiTerekhov, Tran, Down, & BeckMean Flow TimeRound RobinMinFTLPASmakespanHybrid1100108082848688909294Percent Maximum Theoretical Load9698100Figure 12: Comparison mean flow times flexible queueing network four serversfour classes.Figures 11 12 present mean flow times averaged across problem instancesevery load. Note log-scale y-axes. Figure 11, see two schedulingmodels hybrid model create better schedules Round Robin.Increasing system size produces substantially different results. Figure 12 showslower loads, LPAS obtains lowest mean flow time. contrast performingworse makespan hybrid model loads smaller system.load increases, makespan model performance becomes better Round Robinstill become good LPAS. hybrid model able obtainperformance comparable LPAS lower loads provide best performancehigh loads. Thus, hybrid model maintains robust performance across varyingsystem loads. Even though performance hybrid falls short LPAS lowerloads, waiting times low loads almost negligible. heavy loads approaches, hybrid model outperforms algorithms 17%.good performance MinFT model lost larger system. loads0.9 greater, MinFT model able process jobs quickly enough dissipatebuild jobs. empirical confirmation MinFT stable parametersalgorithms stable, e.g., loads greater 90% Figure 12.investigate whether strong performance hybrid model indeed duevalues plot performanceguidance allocation LP values, alter mkFigure 13. following queueing guidance beneficial, deviating values.lead worse schedules. Therefore, replace mkvalues 1 mk560fiIntegrating Queueing Scheduling Dynamic Scheduling Problems3101*mk*mk2Mean Flow Time101100108082848688909294Percent Maximum Theoretical Load96981001Figure 13: Comparison mean flow times hybrid model guided mkmkflexible queueing network four servers four classes.resources allocation LP assignsfewer assigned hybridP class,model. Although method allows kK mk > 1, conceptual goal schedulingavoid allocation LP solution still maintained, validity modelcompromised since resource capacity limit essential solving fluid model.find incorrectly guided hybrid performs poorly loads; loads 0.9,system size grows rapidly behaves unstable. conclude usingproper guidance allocation LP crucial.4.3.1 Performance Analysisnumerical results show makespan model improved incorporatingqueueing analysis. understand result low loads considering systemtwo servers two classes. equal arrival rates processing rates 11 = 9, 12 == 0, = 1, = 0.5,2, 21 = 5, 22 = 1, solving allocation LP gives 11122122 = 0.5. system lightly loaded two class 1 jobs present,1processing times equal expected value ( m1: 19 server 1 15 server 2),makespan schedule one job servers. hybrid model would consider= 0 depending parameter chosen, could decide place jobsfact 11second server attempt perform well long run. Although hybrid, guidance sufficient performance improvementpartially guided mkmakespan.561fiTerekhov, Tran, Down, & Beck210Round RobinLPASmakespanHybrid1Mean Variance100101102108082848688909294Percent Maximum Theoretical Load9698100Figure 14: Comparison class flow time variance flexible queueing network fourservers four classes.so, contraryheavy loads, Proposition 1 states makespan track mkresults, would expect makespan hybrid models perform similarly.However, time server becomes busy idle, firstscheduling periods expected fewer jobs middle timespan, yet enough arrivals significant queues build up.Therefore, first periods resemble lightly loaded system. necessarilylarger queue formed. early decisionscase makespan track mkpropagate subsequent periods affect later jobs within busy period.hybrid model, start, able make better long-run decisions. Althoughhybrid model guarantee always make best choice, speculateincrease probability better choices made.instances four servers four job classes, LPAS better hybridlow loads worse high loads. Deeper analysis shows performance patternlargely due poor performance hybrid policy low loads. loads,hybrid make assignments inefficient long term jobssystem. argued hybrid model making better assignmentsmakespan guided queueing analysis. However, policy maintainsvalues, LPAS Round Robin, reserves serversstrict adherence mkjob classes efficient long term. Even though hybrid model incorporatesmkvalues decision-making process, guaranteed low loads562fiIntegrating Queueing Scheduling Dynamic Scheduling Problems. especiallymodel always make globally optimal decisions adhere mktrue chosen high.hybrid model outperforms LPAS heavy loads optimizing makespanperiod long-run impact. heavy loads hybrid model able matchvalues minimize makespan, whereas Round Robin formermkLPAS cannot guarantee either. hybrid model reduces makespan time unitscompared LPAS Round Robin, jobs next period able start timeunits earlier thereby net effect reducing mean flow time approximatelysubsequent set. reductions propagate subsequent periods serveridle.propagation effect reducing makespan earlier period propertyhybrid model inherited makespan model. such, expectmakespan exhibit behaviour well. numerical results show, expected,performance makespan good heavy loads. makespan model lacksqueueing guidance ensure even higher quality schedules earlier busy period.expected similar results makespan model dynamic flowshop problemSection 3 well. However, experimental results Section 3 show assumptionincorrect. conjecture one reasons see better performancemakespan queueing network flexible servers dynamic flowshoplatter differences optimal sub-problem makespansmakespans found methods substantial. queueing networkflexible servers, makespan may change significantly using different policies.Given complex nature systems, investigation performance trade-offsresulting different system parameters necessary future work. hopeinvestigation lead derivations general dynamic scheduling principles.4.3.2 Beyond Mean Flow TimeThough primary quantity interest mean flow time, variance also importantcriterion. perspective customer submitted job processing,high variance indicates actual flow time given job unlikely accuratelypredicted mean flow time.Figure 14 shows variance mean flow time job class four serversfour classes using Round Robin LPAS much larger makespanhybrid policies.see substantial difference (note log scale) among four algorithms.larger variance observed queueing models occurs policies use less information state system. policies may overcompensate serve jobclass immediately rather delaying service achieve fairer allocation. contrast,scheduling models make use state information perform better load balancingtherefore exhibit lower variance.5. Discussionmotivation studying integration scheduling queueingtwo areas address similar problems different ways, combination terms problem563fiTerekhov, Tran, Down, & Becksettings, performance measures algorithms provides richer set domains, goalstools. Given nascent nature study, looked two simple problem settingsdemonstrated following contributions.1. problem settings, showed possible establish stability periodicscheduling approaches, enhancing periodic scheduling framework guaranteestability traditionally available queueing approaches only. faraware, first time stability established algorithms use observed job characteristics instead of, addition to, stochasticinformation. Similarly, far aware, concept stability appearsqueueing theory examined combinatorial scheduling community.believe oversight arising areas focus short-term combinatorics suggest that, queueing theory, stability important criterionproblem must deal stream arriving resource requests.2. second problem setting, flexible queueing network, first,dynamic flowshop, demonstrated solution approaches combine guidancelong-run stochastic reasoning short-term combinatorial reasoning perform better queueing scheduling approaches alone. However, differencestwo problem settings, well work complex problemdomains (Tran, 2011), shows combination non-trivial workneeded place hybrid algorithms formal foundation.see variety additional ways integrate ideas queueing theory scheduling future. example, would like to: extend analysis generaldynamic scheduling environments, job shops; compare methods discussedpaper complex queueing approaches alternative dynamic schedulingapproaches, OSCO; investigate stability dynamic scheduling approachesOSCO based approximation algorithms (i.e., polynomial time approximationschemes applied every sub-problem); develop sophisticated hybrid queueingtheory scheduling models.broader direction future work fully investigate fact that,number applications, reasonable assume data probabilitydistributions actual job characteristics (at arrival time) available. best wayintegrate different data sources open question paper beguninvestigate perspective hybridization existing tools.5.1 Distributional Assumptionswork assumes that, queue, sequences processing times machines sequence inter-arrival times independent identically distributed sequences, sequences also mutually independent. many AI applications,assumptions may justified, data may non-stationary (time-dependent)and/or correlated. non-stationary models simple correlation structures alsoconsidered queueuing theory literature (Prabhu & Zhu, 1989; Massey, 2002; Gupta,Harchol-Balter, Scheller-Wolf, & Yechiali, 2006; Liu & Whitt, 2012).564fiIntegrating Queueing Scheduling Dynamic Scheduling ProblemsImportantly, note proof Lemma 1 holds non-stationary settingscheduling methods used dynamic flow shop distribution-independent.flexible queueing network, majority analysis based allocation LP,based fluid representation system. fluid analysis stability,i.i.d. assumption required; instead, necessary Law Large Numbershold inter-arrival processing time sequences. Thus, analysisextended including correlation structures long Law Large Numbers holds.algorithmic side, Round Robin, LPAS hybrid methods adaptednon-stationary setting periodically re-solving allocation LP using updatedvalues. fact, approach special case general principle needsconsidered dynamic scheduling problems: distributions may need updatednew data becomes available. surprisingly, queueing theory scheduling, nonstationary situations require periodic approaches.5.2 Computational Complexitysubstantial difference periodic scheduling approaches traditional queueing theory-based policies scheduling approaches may solve NP-hardproblems. indeed case completionTime algorithm two-machinedynamic flowshop problem (Section 3) makespan hybrid algorithmsqueueing network (Section 4). assumption work, consistentrelated work OSCO (Van Hentenryck & Bent, 2006; Mercier & Van Hentenryck,2007), dynamism system slow enough allow problem solving.report run-times solving problems make look arbitrarilygood bad making assumptions time granularity. example, timeunit problem corresponds one hour, algorithm run-times 10 20 secondsunlikely significant.applications finer time granularity, may able solve problemstraditional queueing policies appropriate. However, work raiseinteresting question stability polynomial-time algorithms provide approximation guarantees. proofs Theorems 2 4 depend finding optimal makespans,seem easy generalization.5.3 Online SchedulingOnline scheduling alternative approach dynamic scheduling problems (Pruhs et al.,2004), different classical combinatorial scheduling queueing theory.online scheduling literature focuses competitive analysis, proving worst-case boundsmuch worse deterministic randomized online algorithms are, compared fullinformation algorithm. queueing theory, rigorous mathematical approachonline scheduling tends limit combinatorial structure addressed. However,unlike queueing theory, uncommon assume knowledge stochastic distributionsjob arrivals characteristics drawn. Indeed, often results showingdifferences deterministic randomized online algorithms arise analysissystems adversary full knowledge online algorithm manipulatejob characteristics arbitrarily.565fiTerekhov, Tran, Down, & Beckchosen include online scheduling paper, believeimportant understand results insights area integratedwork order obtain even deeper understanding dynamic scheduling problems.5.4 Relevance AIDynamic scheduling requires series scheduling resource allocation decisionsmade online future tasks arrive characteristics, any, known.challenge sequential decision making uncertainty, problem receivedsignificant amount attention AI. Indeed, requirement agent make decisionstake actions without full knowledge future states world would appearcentral requirement embodied, intelligent agent. Investigation sequentialdecision making applications interest AI include planning task allocationuncertainty (Keller & Eyerich, 2012; Alighanbari & How, 2008), land purchasesconservation endangered species (Xue, Fern, & Sheldon, 2012), multi-playerstrategy games (Sturtevant, 2008; Balla & Fern, 2009).methodological approaches problems AI rely way MarkovDecision Processes (MDPs) (Puterman, 1994), notably area decision-theoreticplanning (Boutilier, Dearden, & Goldszmidt, 2000). challenge arising direct applications MDPs well-known curse dimensionality, state spacelarge problems cannot solved. Substantial work therefore focused approachesfactored MDPs (Meuleau, Hauskrecht, Kim, Peshkin, Kaelbling, Dean, & Boutilier,1998; Boutilier et al., 2000; Guestrin, Koller, & Parr, 2003), approximate dynamic programming (Powell, 2010), Monte Carlo Tree Search (Chaslot, 2011; Browne, Powley, Lucas,Cowling, Rohlfshagen, Tavener, Perez, Samothrakis, & Colton, 2012; Bellemare, Naddaf,Veness, & Bowling, 2013) Online Stochastic Combinatorial Optimization (Van Hentenryck & Bent, 2006).Queueing theory another approach sequential decision making uncertainty,one emphasizes time resources one that, knowledge,considered solving problems studied AI. Given concern time resources,dynamic scheduling natural problem choice investigation incorporationqueueing theory toolbox AI techniques. richness decision-makingproblems AI extends questions time resources (e.g., temporal planningproblems, see Coles, Coles, Fox, & Long, 2012) and, fact, much underlying analysisprescriptive queueing theory approaches founded MDPs (Stidham & Weber, 1993;Sennott, 1999; Meyn, 2008), believe application queueing theory AIhybridization queueing scheduling proposed paper, promising directionsfundamental applied research.6. Conclusionpaper, considered combination long-run stochastic reasoning shortterm combinatorial reasoning solve dynamic scheduling problems. specifically,investigated integration queueing theory scheduling two simple schedulingproblems: dynamic two-machine flowshop flexible queueing network. providedanalytical empirical results.566fiIntegrating Queueing Scheduling Dynamic Scheduling ProblemsAnalytically, demonstrated problem settings scheduling approaches make use observed job characteristics, opposed stochastic information job classes, proved stable. is, possible managesystem number jobs waiting processing remains finite, combinatorial scheduling algorithm so.Empirically, demonstrated common scheduling criterion possiblecreate hybrid algorithm guided long-term stochastic reasoning short-term combinatorial reasoning. Furthermore, algorithm shown stableempirically out-perform pure scheduling pure queueing approaches. However, result shown one two problem settings, suggesting currentlyunderstanding allow us systematically design successful hybrids.believe novel investigation integration problem settings, performance criteria, algorithms queueing theory combinatorial scheduling opensnumber interesting research directions surrounding approaches dynamic schedulingand, broadly, sequential decision making uncertainty.Acknowledgementsauthors would like thank reviewers associate editor comments,helped improve paper.Section 3 paper based previously published workshop conference papers(Terekhov, Tran, & Beck, 2010; Terekhov, Tran, Down, & Beck, 2012). work Section4 forms part Masters dissertation (Tran, 2011) appeared peerreviewed publication.research supported Natural Sciences Engineering ResearchCouncil Canada, Canadian Foundation Innovation, Ontario Research Fund,Ontario Ministry Research Innovation, Ireland Industrial DevelopmentAgency, Alcatel- Lucent, Microway Inc., IBM ILOG, University Toronto School Graduate Studies Doctoral Completion Award, Department Mechanical IndustrialEngineering University Toronto.ReferencesAl-Azzoni, I., & Down, D. G. (2008). Linear programming-based affinity schedulingindependent tasks heterogeneous computing systems. Parallel DistributedSystems, IEEE Transactions on, 19 (12), 16711682.Alighanbari, M., & How, J. P. (2008). robust approach UAV task assignmentproblem. International Journal Robust Nonlinear Control, 18, 118134.Andradottir, S., & Ayhan, H. (2005). Throughput maximization tandem lines twostations flexible servers. Operations Research, 53 (3), 516531.Andradottir, S., Ayhan, H., & Down, D. G. (2003). Dynamic server allocation queueingnetworks flexible servers. Operations Research, 51 (6), 952968.567fiTerekhov, Tran, Down, & BeckBalla, R.-K., & Fern, A. (2009). UCT tactical assault planning real-time strategygames. Proceedings 21st International Joint Conference Artificial Intelligence (IJCAI09), pp. 4045.Baptiste, P., Le Pape, C., & Nuijten, W. (2001). Constraint-based Scheduling. KluwerAcademic Publishers.Beck, J. C. (2007). Solution-guided multi-point constructive search job shop scheduling.Journal Artificial Intelligence Research, 29, 4977.Beck, J. C., Feng, T., & Watson, J. P. (2011). Combining constraint programming localsearch job-shop scheduling. INFORMS Journal Computing, 23 (1), 114.Beck, J. C., & Wilson, N. (2007). Proactive algorithms job shop scheduling probabilistic durations. Journal Artificial Intelligence Research, 28, 183232.Bellemare, M. G., Naddaf, Y., Veness, J., & Bowling, M. (2013). arcade learning environment: evaluation platform general agents. Journal Artificial IntelligenceResearch, 47, 253279.Bent, R., & Van Hentenryck, P. (2007). Waiting relocation strategies online stochasticvehicle routing.. Proceedings 20th International Joint Conference ArtificialIntelligence (IJCAI07), pp. 18161821.Bidot, J., Vidal, T., Laborie, P., & Beck, J. C. (2009). theoretic practical frameworkscheduling stochastic environment. Journal Scheduling, 12 (3), 315344.Bolch, G., Greiner, S., de Meer, H., & Trivedi, K. S. (2006). Queueing networksMarkov chains: modeling performance evaluation computer science applications. Wiley-Interscience.Boutilier, C., Dearden, R., & Goldszmidt, M. (2000). Stochastic dynamic programmingfactored representations. Artificial Intelligence, 121, 49107.Bowman, E. (1959). schedule-sequencing problem. Operations Research, 7 (5), 621624.Bramson, M. (2008). Stability queueing networks. Probability Surveys, 5, 169345.Bramson, M., & Williams, R. J. (2000). dynamic scheduling stochastic networksheavy traffic new results workload process. Proceedings39th IEEE Conference Decision Control, Vol. 1, pp. 516521.Branke, J., & Mattfeld, D. C. (2002). Anticipatory scheduling dynamic job shop problems. Proceedings ICAPS02 Workshop On-line Planning Scheduling,pp. 310.Branke, J., & Mattfeld, D. C. (2005). Anticipation flexibility dynamic scheduling.International Journal Production Research, 43 (15), 31033129.Browne, C., Powley, E., Lucas, S., Cowling, P. I., Rohlfshagen, P., Tavener, S., Perez, D.,Samothrakis, S., & Colton, S. (2012). survey Monte Carlo tree search methods.IEEE Transactions Computational Intelligence AI Games, 4 (1), 149.Brucker, P., Jurisch, B., & Sievers, B. (1994). branch bound algorithmjob-shop scheduling problem. Discrete Applied Mathematics, 49 (1), 107127.Burke, P. (1956). output queuing system. Operations Research, 4 (6), 699704.568fiIntegrating Queueing Scheduling Dynamic Scheduling ProblemsBurns, E., Benton, J., Ruml, W., Yoon, S., & Do, M. B. (2012). Anticipatory on-line planning. Proceedings Twenty-Second International Conference AutomatedPlanning Scheduling (ICAPS12), pp. 333337.Carlier, J., & Pinson, E. (1989). algorithm solving job-shop problem. Management Science, 35 (2), 164176.Chaslot, G. M. J.-B. (2011). Monte-Carlo Tree Search. Ph.D. thesis, Universeteit Maastricht.Chen, H., & Yao, D. D. (1992). fluid model systems random disruptions. Operations Research, 41 (2), 239247.Coles, A. J., Coles, A. I., Fox, M., & Long, D. (2012). COLIN: Planning continuouslinear numeric change. Journal Artificial Intelligence Research, 44, 196.Conway, R. W., Maxwell, W. L., & Miller, L. W. (1967). Theory Scheduling. AddisonWesley.Crabill, T., Gross, D., & Magazine, M. (1977). classified bibliography researchoptimal design control queues. Operations Research, 25 (2), 219232.Dai, J. G. (1995). positive Harris recurrence multiclass queueing networks: unifiedapproach via fluid limit models. Annals Applied Probability, 5 (1), 4977.Dai, J. G., & Meyn, S. P. (1995). Stability convergence moments multiclassqueueing networks via fluid limit models. IEEE Transactions Automatic Control,40 (11), 18891904.Dai, J. G., & Weiss, G. (1996). Stability instability fluid models reentrant lines.Mathematics Operations Research, 21 (1), 115134.Daniels, R., & Carrillo, J. (1997). -robust scheduling single-machine systemsuncertain processing times. IIE Transactions, 29, 977985.Davenport, A., Gefflot, C., & Beck, J. C. (2001). Slack-based techniques robust schedules.Proceedings Sixth European Conference Planning (ECP-2001).Down, D., & Meyn, S. (1994). survey Markovian methods stability networks.11th International Conference Analysis Optimization Systems: DiscreteEvent Systems, pp. 490504. Springer.Down, D. G., & Karakostas, G. (2008). Maximizing throughput queueing networkslimited flexibility. European Journal Operational Research, 187 (1), 98112.El-Bouri, A., Balakrishnan, S., & Popplewell, N. (2008). Cooperative dispatching minimizing mean flowtime dynamic flowshop. International Journal ProductionEconomics, 113 (2), 819833.Fox, M. S. (1987). Constraint-directed Search: Case Study Job-Shop Scheduling.Morgan-Kaufmann Publishers Inc.French, S. (1982). Sequencing Scheduling: Introduction MathematicsJob-shop. Ellis Horwood.Gross, D., & Harris, C. (1998). Fundamentals Queueing Theory. John Wiley & Sons,Inc.569fiTerekhov, Tran, Down, & BeckGuestrin, C., Koller, D., & Parr, R. (2003). Efficient solution algorithms factored MDPs.Journal Artificial Intelligence Research, 19, 399468.Gupta, V., Harchol-Balter, M., Scheller-Wolf, A., & Yechiali, U. (2006). Fundamental characteristics queues fluctuating load. ACM SIGMETRICS Performance Evaluation Review, 34 (1), 203215.Herroelen, W., & Leus, R. (2005). Project scheduling uncertainty: Survey researchpotentials. European Journal Operational Research, 165 (2), 289306.Jackson, J. (1957). Networks waiting lines. Operations Research, 5 (4), 518521.Keller, T., & Eyerich, P. (2012). PROST: Probabilistic planning based UCT. Proceedings 22nd International Conference Automated Planning Scheduling(ICAPS12), pp. 119127.Kendall, D. G. (1953). Stochastic processes occurring theory queuesanalysis method imbedded Markov chain. Annals MathematicalStatistics, 24 (3), 338354.Kovacs, A., & Beck, J. C. (2011). global constraint total weighted completion timeunary resources. Constraints, 16 (1), 100123.Kumar, P. R. (1994). Scheduling semiconductor manufacturing plants. IEEE Control Systems Magazine, 14 (6), 3340.Leon, V. J., Wu, S. D., & Storer, R. H. (1994). Robustness measures robust schedulingjob shop. IIE Transactions, 26 (5), 3243.Liu, Y., & Whitt, W. (2012). Gt /GI/st + GI many-server fluid queue. QueueingSystems, 71 (4), 405444.Manne, A. (1960). job-shop scheduling problem. Operations Research, 8 (2), 219223.Massey, W. A. (2002). analysis queues time-varying rates telecommunicationmodels. Telecommunication Systems, 21 (24), 173204.Mercier, L., & Van Hentenryck, P. (2007). Performance analysis online anticipatoryalgorithms large multistage stochastic integer programs. Proceedings20th International Joint Conference Artificial Intelligence, pp. 19791984. MorganKaufmann Publishers Inc.Meuleau, N., Hauskrecht, M., Kim, K. E., Peshkin, L., Kaelbling, L. P., Dean, T., &Boutilier, C. (1998). Solving large weakly coupled Markov decision processes.Proceedings 15th National Conference Artificial Intelligence (AAAI98).Meyn, S. P. (2008). Control Techniques Complex Networks. Cambridge University Press.Nowicki, E., & Smutnicki, C. (1996). fast taboo search algorithm job shop problem.Management Science, 42 (6), 797813.Nowicki, E., & Smutnicki, C. (2005). advanced tabu algorithm job shop problem.Journal Scheduling, 8, 145159.Ouelhadj, D., & Petrovic, S. (2009). survey dynamic scheduling manufacturingsystems. Journal Scheduling, 12 (4), 417431.570fiIntegrating Queueing Scheduling Dynamic Scheduling ProblemsPark, B. Y. (1988). evaluation static flowshop scheduling heuristics dynamicflowshop models via computer simulation. Computers & Industrial Engineering,14 (2), 103112.Petrick, R. P. A., & Foster, M. E. (2013). Planning social interaction robot bartenderdomain. Proceedings 23rd International Conference Automated PlanningScheduling, pp. 389397.Pinedo, M. L. (2003). Scheduling: Theory, Algorithms, Systems (2nd edition). PrenticeHall.Powell, W. (2010). Merging AI solve high-dimensional stochastic optimizationproblems using approximate dynamic programming. INFORMS Journal Computing, 22 (1), 217.Prabhu, N. U., & Zhu, Y. (1989). Markov-modulated queueing systems. Queueing Systems,5 (13), 215245.Pruhs, K., Sgall, J., & Torng, E. (2004). Online scheduling. Leung, J. Y.-T. (Ed.),Handbook Scheduling: Algorithms, Models Performance Analysis, chap. 15.CRC Press.Puterman, M. L. (1994). Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc.Reich, E. (1957). Waiting times queues tandem. Annals MathematicalStatistics, 28 (3), 768773.Ross, S. M. (2003). Introduction Probability Models, chap. 6 Continuous-Time MarkovChains, pp. 349399. Academic Press.Sarper, H., & Henry, M. C. (1996). Combinatorial evaluation six dispatching rulesdynamic two-machine flow shop. Omega, 24 (1), 7381.Sennott, L. I. (1999). Stochastic Dynamic Programming Control Queueing Systems. John Wiley & Sons, Inc.Sotskov, Y. N., Sotskova, N. Y., Lai, T.-C., & Werner, F. (2010). Scheduling Uncertainty: Theory Algorithms. Belorussian Science.Stidham, Jr., S., & Weber, R. (1993). survey Markov decision models controlnetworks queues. Queueing Systems, 13, 291314.Sturtevant, N. (2008). analysis UCT multi-player games. ProceedingsSixth International Conference Computers Games (CG2008), pp. 3749.Tadj, L., & Choudhury, G. (2005). Optimal design control queues. Sociedad deEstadstica e Investigacion Operativa, Top, 13 (2), 359412.Taillard, E. (1990). efficient heuristic methods flow shop sequencing problem.European Journal Operational Research, 47 (1), 6574.Terekhov, D. (2013). Integrating Combinatorial Scheduling Inventory ManagementQueueing Theory. Ph.D. thesis, Department Mechanical Industrial Engineering,University Toronto.571fiTerekhov, Tran, Down, & BeckTerekhov, D., Beck, J. C., & Brown, K. N. (2009). constraint programming approachsolving queueing design control problem. INFORMS Journal Computing,21 (4), 549561.Terekhov, D., Tran, T. T., & Beck, J. C. (2010). Investigating two-machine dynamic flowshops based queueing scheduling. Proceedings ICAPS10 WorkshopPlanning Scheduling Uncertainty.Terekhov, D., Tran, T. T., Down, D. G., & Beck, J. C. (2012). Long-run stability dynamic scheduling. Proceedings 22nd International Conference AutomatedPlanning Scheduling (ICAPS12), pp. 261269.Towsley, D., & Baccelli, F. (1991). Comparisons service disciplines tandem queueingnetwork real time constraints. Operations Research Letters, 10 (1), 4955.Tran, T. T. (2011). Using queueing analysis guide combinatorial scheduling dynamicenvironments. Masters thesis, Department Mechanical Industrial Engineering,University Toronto.Van Hentenryck, P., & Bent, R. (2006). Online Stochastic Combinatorial Optimization.MIT Press.Widmer, M., & Hertz, A. (1989). new heuristic method flow shop sequencingproblem. European Journal Operational Research, 41 (2), 186193.Wierman, A., Winands, E., & Boxma, O. (2007). Scheduling polling systems. Performance Evaluation, 64, 10091028.Wu, C. W., Brown, K. N., & Beck, J. C. (2009). Scheduling uncertain durations:Modeling -robust scheduling constraints. Computers & Operations Research,36 (8), 23482356.Xia, C. H., Shanthikumar, J. G., & Glynn, P. W. (2000). asymptotic optimalitySPT rule flow shop average completion time problem. Operations Research,48 (4), 615622.Xue, S., Fern, A., & Sheldon, D. (2012). Scheduling conservation designs via network cascadeoptimization. Proceedings 26th AAAI Conference Artificial Intelligence(AAAI12), pp. 391397.Yoon, S. W., Fern, A., Givan, R., & Kambhampati, S. (2008). Probabilistic planning viadeterminization hindsight. Proceedings 23rd AAAI Conference ArtificialIntelligence (AAAI08), pp. 10101016.572fiJournal Artificial Intelligence Research 50 (2014) 639696Submitted 02/14; published 07/14Planning Automatic Portfolio Configuration:PbP ApproachAlfonso Emilio GereviniAlessandro Saettialfonso.gerevini@unibs.italessandro.saetti@unibs.itDipartimento di Ingegneria dellInformazioneUniversita degli Studi di BresciaVia Branze 38, I-25123 Brescia, ItalyMauro Vallatim.vallati@hud.ac.ukSchool Computing EngineeringUniversity HuddersfieldHuddersfield, West Yorkshire, HD1 3DH, UKAbstractfield domain-independent planning, several powerful planners implementingdifferent techniques developed. However, one systems outperformsothers every known benchmark domain. work, propose multi-plannerapproach automatically configures portfolio planning techniques givendomain. configuration process given domain uses set training instances to:(i) compute analyze alternative sets macro-actions plannerportfolio identifying (possibly empty) useful set, (ii) select cluster planners,one identified useful set macro-actions, expected perform best,(iii) derive additional information configuring execution schedulingselected planners planning time. resulting planning system, called PbP (Portfoliobased Planner), two variants focusing speed plan quality. Different versionsPbP entered learning track sixth seventh International PlanningCompetitions. paper, experimentally analyze PbP considering planning speedplan quality depth. provide collection results help understand PbPsbehavior, demonstrate effectiveness approach configuring portfolioplanners macro-actions.1. Introductionlast fifteen years, field automated plan generation achieved significantadvancements, several powerful domain-independent planners today available, e.g.,propositional planning, FF (Hoffmann & Nebel, 2001), LPG (Gerevini, Saetti, & Serina,2003), SGPlan (Chen, Hsu, & Wah, 2006), Fast Downward (Helmert, 2006), LAMA(Richter & Westphal, 2010). Moreover, systems performs well(more less large) class planning domains problems, well-known oneoutperforms others every available benchmark domain (see, e.g., Roberts & Howe,2009). would useful multi-planner system automatically selectscombines efficient planner(s) portfolio given domain.c2014AI Access Foundation. rights reserved.fiGerevini, Saetti, & Vallatiperformance current planning systems typically affected structuresearch space, depends considered planning domain. many domains,planning performance improved exploiting knowledge domainstructure explicitly given part input formalization,automatically derived it. particular, several approaches encoding additional knowledge form macro-actions proposed (e.g., Botea, Enzenberger, Muller,& Schaeffer, 2005; Newton, Levine, Fox, & Long, 2007). macro-action (macro short)sequence actions planned one time like single action. usingmacros important tradeoff consider. use speedup planningprocess, reduces number search steps required reach solution, alsoincreases search space size, could slow planning process. Moreover,known effectiveness macros depend planning algorithm: setmacros increase performance planner, decrease it, irrelevant,another.paper, propose approach automatically configuring portfolio existingplanners, possibly using useful set macros them. configuration reliesstatistical analysis performance planners portfolio usefulnessautomatically generated sets macros, considering set training problem instancesgiven domain. configuration knowledge automatically generatedanalysis consists cluster planners defined by: ordered subset plannersinitial portfolio, planning time combined using round-robin strategy;set useful macros planner; sets planning time slots. planningtime slots specify amount CPU time allocated planner clusterplanning. resulting planning system called PbP (Portfolio-based Planner).current implementation PbP incorporates two systems generationmacros nine efficient planners, architecture open consider (currentfuture) planner additional alternative system. PbP used without configuration knowledge, planners portfolio scheduled (without macros) simpleround-robin strategy predefined CPU-time slots assigned (randomlyordered) planners. PbP used configuration knowledge domain consideration, selected cluster planners (possibly using relative selectedsets macros) scheduled, ordering favors planners configurationperformed best, planning time slots defined computed configurationknowledge. selection exploitation macros PbP, worth notingplanners portfolio configured PbP necessarily use macros learnedthem. configuration process, system evaluates planner portfolioset macros computed it, well empty macro set,independent planning systems.PbP two main variants: PbP.s, focusing speed, PbP.q, focusing planquality. preliminary implementation PbP.s (Gerevini, Saetti, & Vallati, 2009) enteredlearning track sixth international planning competition (IPC6) overallwinner competition track (Fern, Khardon, & Tadepalli, 2011).1 recently,1. observed IPC6 organizers, surprisingly, IPC6 problems use configurationknowledge considerably speedup version PbP.s. reasons implementation bugs concerning configuration phase planning phase, inefficient use640fiPlanning Automatic Portfolio Configuration: PbP Approachrevised optimized version PbP speed quality variants enteredlearning track seventh competition (IPC7), winnercompetition track (Coles, Coles, Olaya, Celorrio, Lopez, Sanner, & Yoon, 2012).large experimental analysis presented paper provides collection resultshelp understand performance behavior PbP effectiveness portfolioconfiguration methods. particular, analysis (i) confirms good performancePbP context IPC6-7 benchmarks, (ii) compares PbP existingapproaches configure planner portfolio, (iii) evaluates accuracy PbPs approachidentify effective cluster planners strength using (configuredunconfigured) multi-planner respect single planner, (iv) investigates usefulnessmacros considered benchmarks, showing PbP selects useful macro sets,(v) examines execution scheduling configuration PbP selected plannersconfigured portfolio, demonstrating default strategy works well comparedpossible strategies considered analysis.Several ideas techniques investigated context PbP use build previouswork. Besides presenting evaluating effective approach configuring plannerportfolio, research presented paper corroborates, validates evaluateshunches empirical studies done researchers planning. particular,experimental analysis confirms certain sets macros useful accelerateplanning speed improve plan quality (Botea et al., 2005; Coles & Smith, 2007; Newtonet al., 2007) others harmful, diversity planning techniques importantconstruction effective planner portfolio, observed by, e.g., Roberts Howe(2009), round-robin scheduling planner execution times robuststrategy planner portfolio (Howe, Dahlman, Hansen, vonMayrhauser, & Scheetz, 1999;Roberts & Howe, 2006).remainder paper organized follows. Section 2 discusses related work;Section 3 describes PbP approach; Section 4 presents results experimentalstudy; finally, Section 5 gives conclusions.2. Related Worksection, brief presentation prominent work algorithm portfoliodesign automated reasoning, describe related work others planner portfoliodesign automated planning, pointing important differences PbPrelated work. specific differences similarities indicatedfollowing sections presenting technical results.2.1 Algorithm Portfolio Design Automated Reasoningfield automated reasoning, idea using portfolio techniquesinvestigated several researchers. prominent example work Gomes Selman(2001), conducted theoretical experimental study parallel run stochasticalgorithms solving computationally hard search problems. work showsLinux shell scripts (evident especially small easy problems), correctedcompetition obtaining much better results (Gerevini et al., 2009).641fiGerevini, Saetti, & Vallaticonditions running different stochastic algorithms parallel give computational gainrunning multiple copies stochastic algorithm parallel.Many papers algorithm portfolio design concern definition models selectbest algorithm(s) instance certain problem according valuespredetermined features instance (Rice, 1976). example, algorithm portfoliosdesigned aim solve instances SAT, MaxSAT, QBF (Matos, Planes,Letombe, & Marques-Silva, 2008; Pulina & Tacchella, 2007; Xu, Hutter, Hoos, & LeytonBrown, 2008). SATzilla prominent example algorithm portfolio designed SAT(Xu et al., 2008). SATzilla uses machine learning techniques build predictorruntime class SAT solvers. SATzilla attempts solve instance SATproblem, computes values features instance, predicts performanceSAT solvers incorporates, selects promising SAT solvers orderaccordingly predicted performance, finally runs selected SAT solvers usingestablished ordering predicted required CPU times.Matos et al. (2008) propose algorithm portfolio solving MaxSAT problem.portfolio computes values several features given instance MaxSAT problem,estimates runtime solver portfolio, solves instanceestimated fastest solver. estimation done using (linear) model configuredperforming ridge regression (Marquardt & Snee, 1975). Similarly, Pulina Tacchella(2007) study algorithm portfolio solving QBF problem. identify featuresQBF problem, investigate usage four inductive models select bestsolver use according values identified features.2.2 Planner Portfolio Design Automated PlanningRegarding automated planning, prominent planners combining one algorithmsproposed. Blackbox (Kautz & Selman, 1999) use variety satisfiability engines (the initial version also included Graphplan algorithm), FF (Hoffmann & Nebel,2001), LPG (Gerevini et al., 2003; Gerevini, Saetti, & Serina, 2006) SGPlan5 (Chen et al.,2006) include backup strategy using alternative search technique rundefault method fails. algorithm combination systems straightforwarduse automatic portfolio configuration.Previous work planner portfolios includes approach proposed Howe collaborators (Howe et al., 1999; Roberts & Howe, 2007, 2009; Roberts, Howe, Wilson, &desJardins, 2008). rest paper, refer Howe collaborators approach using name first planner portfolio, BUS (Howe et al., 1999), althoughanalysis approach consider recent techniques plannerportfolio configuration. approach learns models performance set planners.planning time, round-robin policy used schedule runs plannersset, learned models exploited determine order runs.configuration-knowledge derived approach domain-independent: performancemodels planners built using several predictive models WEKA data miningpackage (Witten & Frank, 2005), set planners forming portfolio determinedset covering algorithm solved training problems across several differentplanning domains.642fiPlanning Automatic Portfolio Configuration: PbP Approachwork BUS originally inspired approach. PbP similarities it,computes uses different configuration knowledge, methods selectingordering portfolio planners considerably different. portfolio configurationPbP generates domain-optimized clusters planners, selection orderingPbP based statistical analysis planners performance set trainingproblems using Wilcoxon sign-rank test, also known Wilcoxon matched pairstest (Wilcoxon & Wilcox, 1964).2 Finally, system compute, analyze usemacros, consider plan quality.Similarly work Howe et al. (1999), Roberts Howe (2007), techniques used Cenamor, de la Rosa, Fernandez (2013), Fawcett, Vallati, Hutter,Hoffmann, Hoos, Leyton-Brown (2014) learn models performance set plannersaccording predetermined features. work Cenamor et al. (2013), features derived SAS+ representation planning problem. approach,learned models used determine planners run, order,long. selected planners run sequentially either using amount CPU timeuniformly assigned determined predicted execution time. experimental results work Cenamor et al. (2013) show problems domains differentused learn models, configured portfolios perform worse runningunconfigured portfolio consisting incorporated planners uniform CPU timeassigned them.work described Fawcett et al. (2014) focused generating models accurately predicting planners runtime. models exploit large set instance features,derived PDDL SAS+ representations problem, SAT encodingplanning problem, (short) runs planners. experimental results workFawcett et al. (2014) indicate generated performance models able produceaccurate runtime predictions.Fast Downward Stone Soup (here abbreviated FDSS) approach selecting combining set forward-state planning techniques (Helmert, Roger, & Karpas, 2011). UsingIPC6 scoring function, FDSS evaluates class candidate techniques basisperformance set training problem instances different domains,builds domain-independent sequential portfolio forward planners hill-climbing algorithm searching space possible sequential combinations evaluated candidatetechniques. automatic portfolio configuration FDSS PbP aims building different types planning systems: single efficient domain-independent planner portfolioFDSS; efficient domain-optimized portfolio planner given domain PbP.configuration processes resulting configured portfolios FDSS PbPsignificantly different. particular, PbP configures portfolio generic planners (usingdifferent styles planning), one (possibly empty) set useful learned macros,considered FDSS domain-independent purpose. Moreover,execution scheduling strategy PbP runs selected planners round-robin rathersequentially.2. context planning, Wilcoxon sign-rank test previously used also workLong Fox (2003), Gerevini, Haslum, Long, Saetti, Dimopoulos (2009), Gerevini et al. (2009),Roberts Howe (2009).643fiGerevini, Saetti, & VallatiParLPG (Vallati, Fawcett, Gerevini, Hoos, & Saetti, 2013b) Fast Downward-autotune(Fawcett, Helmert, Hoos, Karpas, Roger, & Seipp, 2011) configure parameters planners LPG Fast Downward (Helmert, 2006), respectively, using set training problemsgiven domain order obtain combinations parameters two plannersperform especially well given domain. frameworks uses stochastic localsearch procedure ParamILS search high-performance configurations parametersevaluating promising configurations (Hutter, Hoos, & Stutzle, 2007; Hutter, Hoos, LeytonBrown, & Stutzle, 2009). extended version FDSS (Seipp, Braun, Garimort, & Helmert,2012) involves twenty one configurations Fast Downward, obtained configuring parameters Fast Downward-autotune twenty one different domains (Fawcett et al.,2011), combined several alternative sequential strategies allocating CPUtimes them.ASAP (Vallati, Chrpa, & Kitchin, 2013a) recent system selecting promising planner set candidates planners derives much power useentanglements (Chrpa & Bartak, 2009; Chrpa & McCluskey, 2012). Entanglementsrelations planning operators predicates used reformulate domain modelremoving unpromising operator instances restricting applicability actionscertain states. problem resulting modified domain become significantlyeasier solve planner. hand, since ASAP uses approximate methoddecide entanglements, PSPACE-complete (Chrpa, McCluskey, & Osborne, 2012),problem solvable original domain become unsolvable reformulated domain. Given planning domain modified entanglements set planners,ASAP identifies promising planners one highest IPC score(Jimenez, Coles, & Coles, 2011) set training problems.3. Automated Planner Portfolio Design PbPsection, introducing preliminaries defining problem configuringplanner portfolio execution solve planning problems, describe architecturetechniques approach configure execute planner portfolio.3.1 Preliminaries Configuring Executing Planner PortfolioDifferently existing work algorithm portfolio designaware, PbP design planner portfolio solving specific instanceplanning problem according values predetermined features instance.Instead, planning problems gathered according planning domains, planner portfolio designed whole domain. basis choice empiricalobservation often exists single planner combination planners performs generally better problems domain. seems somethingpeculiar automated planning hold types reasoning problems,makes PbP somewhat atypical general literature algorithm portfolio design.Let planning domain, CPU-time limit, P set n planners (initialportfolio), predefined parameter values. problem configuringP consists computing set triples {hPi , Mi , Si | = 1 . . . m}, where: 1 n,Pi P, Mi (possibly empty) set macro operators learned Pi domain D, Si644fiPlanning Automatic Portfolio Configuration: PbP Approachsequence increasing CPU times. CPU times (real numbers) called planningtime slots, time lower equal .output set triples identified portfolio configuration algorithm configured(planner) portfolio P D, rest paper also called selectedplanner cluster (or simply cluster). Depending planners, macros planningtime slots chosen, many candidate solutions portfolio configurationproblem. special case, call unconfigured (planner) portfolio, defined{hPi , , Spre | = 1 . . . |P|}, Spre predefined h0.1, 1, 10, 100, 1000i (in seconds).Like BUS, PbP uses round-robin policy scheduling runs plannersconfigured portfolio. Let = {hPi , Mi , Si | = 1 . . . m} planner portfolio configureddomain D. Portfolio executed solve planning problem roundrobin scheduling processes where: process corresponds running planner Pimacros Mi (Pi + Mi short), according order time slices derivedsequences S1...m . precisely, circular order planners determinedconsidering values t1...m defined first planning time slotsequences S1 . . . Sm . ti < tj , Pi ordered Pj ; ti = tj , relative order PiPj arbitrarily decided (i.e., case Pi runs Pj iff < j), every i, j 1 . . .6= j. planner Pi + Mi initially run total CPU time allocatedprocess ti , planner terminates earlier. planner Pi + Mi terminatewithin assigned planning time slot ti , suspended, resumes next timetime slot assigned it. additional CPU time assigned processesalready terminated. When, according circularity order, planner Pi + Miresumes execution, total CPU time assigned (from start execution)equal next unprocessed time slot Si (i.e., j-th value Si j-th timePi + Mi runs).Figure 1 shows example round-robin scheduling portfolio {hP1 , M1 ,h10, 40, 160, . . . ii, hP2 , M2 , h20, 60, 180, . . . ii}, assuming P1 + M1 terminates using80 CPU time units, P2 + M2 using 120 CPU time units. P1 + M1 runsplanner P2 + M2 , first time slot P1 + M1 (i.e., 10) lower firsttime slot P2 + M2 (i.e., 20). round-robin scheduler suspends P1 + M1 10 timeunits, gives P2 + M2 20 time units CPU time. process repeated suspendingP1 + M1 total execution P1 + M1 consumed 40 time units, suspendingP2 + M2 total execution P2 + M2 consumed 60 time units. nextiteration, P1 + M1 suspended total execution time reaches 80 time units,but, end third time slot, i.e., time 140, P1 + M1 terminates needsCPU time. Then, P2 + M2 resumes run, terminates time 200.example, planners portfolio use first three time slots.Given set training problems domain D, propose approach configuringinitial planner portfolio statistical analysis performanceplanners initial portfolio alternative sets computed macros.effectiveness determined configured portfolios evaluated set testproblems D, experimental analysis disjoint training problem setthat, specified otherwise, always formed known benchmark problems.proposed approach implemented planning system called PbP (Portfolio-basedPlanner). following, depending context, PbP used indicate either645fiGerevini, Saetti, & VallatiP1 M1P2 M2103060100140200TimeFigure 1: example round-robin scheduling PbP running portfolio {hP1 , M1 , h10, 40, 160, . . . ii, {hP2 , M2 , h20, 60, 180, . . . ii} given planningproblem, assuming planner P1 using macros M1 takes total 80 CPUtime units terminate P2 M2 takes total 120 CPU-time units.method configuring planner portfolio, generated configured portfolio.experimental evaluation configured portfolios generated PbP, baselineplanner portfolio, use unconfigured planner portfolio, also calledunconfigured version PbP denoted PbP-nok (while PbP indicategenerated configured planner portfolio).3.2 Architecture Components PbParchitecture PbP consists following five main components, combineddescribed Figure 2.3.2.1 Macro-Actions Computationintegrated planner, PbP computes sets alternative macros using following two approaches.Wizard, PhD thesis version (Newton et al., 2007). system implements threelearning techniques based offline evolutionary methods, use genetic operatorscompute macros given planner plans solving set training probleminstances input domain. three learning techniques called chunking,bunching, clumping: chunking learns individual macros original domainoperators; bunching learns bunches macros given pool macros (suchmacros learned chunking process); clumping learns individualmacros sets macros simultaneously. learned macros filtered fitnessvalue. fitness value reflects filtering criteria including number solvedproblems CPU time required solve training problems using domainoperators augmented learned macros. computed macros,fitness value macro lower threshold, macro discarded. Therefore,planner incorporated PbP (expect Macro-FF), PbP using Wizardgenerate three sets macros planner. order determine setsmacros used configured portfolio, performance plannerevaluated PbP with/without using sets learned filtered macrostraining problems. evaluation performed Planner cluster646fiPlanningPlanning Automatic Portfolio Configuration: PbP ApproachIncorporated Planners:Domainproblem solveMulti-plannerround-robin schedulingTime limitFast-downward (Helmert, 2006)Cluster planners macrosPlanning timeTime slotsslots computationLPG-td (Gerevini, Saetti & Serina, 2006)Macro-FF (Botea et al., 2005)Marvin (Coles & Smith, 2007)Metric-FF (Hoffmann & Nebel, 2005)SGPLAN5 (Chen, Wah & Hsu, 2006)Portfolio configurationLAMA (Richter & Westphal, 2010)YAHSP (Vidal, 2004)Solution planfailurePlanner clusterselection & orderingPerformance planners macrosMacro-actionscomputationWizardPlanners macrosPerformancemeasurementMacroFFPlannersDomaintraining probsTime limitParLPG (Vallati et al., 2011)Figure 2: sketch PbPs architecture.selection ordering component. simplicity, sets learned macrosidentified names techniques used derive them.Macro-FF (Botea et al., 2005; Botea, Muller, & Schaeffer, 2007b). approachimplemented Macro-FF (Botea et al., 2005) computes macros analyzing solutions set training problem instances, macros appear frequentlysignificantly reduce required search effort preferred. particular,first Macro-FF solves training problems using enhanced version FF;generates macros considering frequency sequences actions formingmacros appear computed solutions.3 macro generation, Macro-FFsolves training problems using computed macros, ranks macros termsobtained search effort gain, using ranking selects five setsmacros M1..5 , Mi = 1..5 set macros formed best learnedmacros. version approach integrated PbP contains enhancementsdescribed Botea et al. (2007b). Since macros learned Macro-FF codedusing ad-hoc language, PbP five learned sets macros M1..5 usedMacro-FF planner.3.2.2 Planner Performance Measurementexpensive computation step configuration portfolio. PbPruns integrated planner expect Macro-FF without three sets macros3. experiments presented Section 4, observed Macro-FF computes macrosenhanced version FF solves training problem.647fiGerevini, Saetti, & Vallatilearned Wizard input training problem set, using input CPU timelimit planner run. Similarly, Macro-FF runs without five setsmacros learned itself. current implementation PbP incorporates eight well-knownsuccessful planners, Fast Downward (Helmert, 2006), LAMA (Richter & Westphal, 2010),LPG-td (Gerevini et al., 2006), Macro-FF (Botea et al., 2005, 2007b), Marvin (Coles & Smith,2007), Metric-FF (Hoffmann, 2003), SGPlan5 (Chen et al., 2006), YAHSP (Vidal, 2004)recent version LPG (ParLPG) using dedicated configuration phase automaticallyoptimize setting collection parameters governing behavior several partssystem (Vallati et al., 2013b). Basically, running ParLPG consists running LPG usingdomain-specific parameter configuration. Every incorporated planner runs usingdefault parameter configuration. Marvin, implies planning learnmemorize macros escape plateaus. run, PbP measures plannerperformance terms of: number problems solved within , CPU time required solvingtraining problems, quality computed solutions. incremental planners,i.e., LPG, ParLPG LAMA, PbP measures quality solutions generatedproblem corresponding CPU times. Finally, note macro-actionscomputation Macro-FF Wizard already run incorporated planners hence,principle, performance planners macros could measured Macro-FFWizard compute them. However, technical difficulties and, simplicity,PbP duplicates runs (incorporated) planners.3.2.3 Planning Time Slots Computationmethod computing planning time slots PbP variant CPU-time allocation strategy proposed Roberts Howe (2007) round-robin planner scheduling. Let hp1 , . . . , pn sequence increasing percentages, tpi (i {1, . . . , n})minimum CPU time required planner P set macros learned (P +short) order solve percentage training problems equal pi . PbPsconfiguration planner portfolio, planning time slots P + defined= htp1 , . . . , tpn i.difference planning time slots PbP approach RobertsHowe explained following example. Assume computed planningtime slots planner using macros (A+MA ) h0.20, 1.40, 4.80, 22.50, . . .planner B using macros MB (B + MB ) h14.5, 150.8, . . . i. Then, pairplanners, differently approach Roberts Howe, PbP extends first timeslot + (0.20) 4.80, i.e., greatest time slot + smallerfirst time slot B + MB ; similarly subsequent time slots. first time slot+ extended, slowest planner B + MB would initially run CPUtime much greater CPU time initially assigned fastest planner + ,many problems planner + quickly solves (e.g., using one CPU second),PbP would perform much slower. worth noting using time slot extensionobserved high performance gain small easy problems.rest paper, sequence increasing percentages hp1 , ..., pn used defineplanning time slots called problem coverage percentage vector (PCPV). default648fiPlanning Automatic Portfolio Configuration: PbP ApproachPCPV PbP sequence h25, 50, 75, 80, 85, 90, 95, 97, 99i (n = 9),used work Roberts Howe (2007).3.2.4 Planner Cluster Selection Orderinglast step configuration process PbP. PbP selects cluster plannersinitial portfolio (as described Section 3.3), one (possibly empty) setuseful macros, according measured performance computed planning timeslots.macro selection, note PbP explicit independent mechanismselecting macros used configured portfolio, macros sharedplanners tools used learn (Wizard Macro-FF) generatemacro sets specific input planner. Planners macro sets selected together,since planner cluster selection PbP considers candidate planner using two differentsets macros learned two different candidate planners.execution order planners selected cluster implicitly definedincreasing first planning time slots associated planners. Section 3.3 describesplanner cluster selection detail.3.2.5 Multi-Planner Round-Robin SchedulingPbP configured planner portfolio domain consideration,problem instance domain encountered, PbP runs selected ordered clusterplanners (each one using relative selected set macro-actions) round-robinscheduling algorithm using computed planning time slots, similar one investigated many portfolio algorithms (see, e.g., Howe et al., 1999; Roberts & Howe, 2006,2007). Alternative planner scheduling strategies possible, sequential executionor/and using configured planning time slots. However, according experimental resultspresented Section 4.8, default round-robin strategy planningtime slots derived default PCPV robust performs generally well. Concerningtermination resulting multi-planner, PbP.s terminates either given (execution)CPU-time limit exceeded, returning failure, one among selected planners computes solution (output PbP.s); PbP.q terminates either time exceeded,selected planners terminate. PbP.q generates solution within t, returns failure;otherwise, returns best computed solution.3.3 Selecting Planner Clusterperformance measurement time slot computation phases, PbP analyzesobtained results identify best cluster planners macros domainconsideration given CPU-time limit . done simulating, every clusterC k planners, (possibly empty) set macros, round-robin execution planners C solving training problems used performancemeasurement phase.4 simulation done using data runs conducted4. experiments parameter k set 3. k greater 3, experimentally observedconsidered benchmark domains problems cluster selected PbP would same.maximum number possible combinations planners currently incorporated PbP649fiGerevini, Saetti, & Vallatiperformance measurement phase (the planners re-run), ignoring dataplanners always perform worse another incorporated planner (i.e., plannerperforms worse another one across training problems domaindiscarded). CPU-time limit simulated execution cluster (thetime given run single planner performance measurement phase).performances simulated cluster runs compared statistical analysis basedWilcoxon sign-rank test (Wilcoxon & Wilcox, 1964). test applies set pairedobservations (a sample larger population), tells us plausible assumecorrelation pairwise observed quantities. case,paired observations are, e.g., simulated runtimes two clusters trainingproblem instance, correlation means equally likelysee one cluster solving problem faster see oppositesample problems.purposes, Wilcoxon sign-rank test appropriate requireus know sample distribution, makes assumption distribution.is, way know priori hard planning problem is, hencedistribution simulated performance clusters. Consequently, statedGibbons Chakraborti (2003), critical use non-parameterized test,Wilcoxon sign-rank test. also investigated usage methodscompare performance simulated runs planner clusters, including IPC scorefunction also used Vallati et al. (2013a). However, experimentally observedthat, IPC7 domains, method less effective usage Wilcoxonsign-rank test.PbP, performance measure considers either CPU time (PbP.s) planquality (PbP.q). data carrying test PbP.s derived follows.planning problem, system computes difference simulated executiontimes compared clusters. planner cluster solve problem, corresponding simulated time twice CPU-time limit;5 cluster solves problem,problem considered. difference simulated times normalizedvalue best simulated time comparison (e.g., cluster C1 requires 200seconds cluster C2 220, difference 10% favor C1 ). absolute valuesdifferences ranked increasing numbers, starting lowest value.(The lowest value ranked 1, next lowest value ranked 2, on.) rankspositive differences ranks negative differences summed, yieldingtwo values r+ r , respectively. performance two compared clusterssignificantly different, number positive differences r+ approximately equalnumber negative differences r , sum ranks setpositive differences approximately equal sum ranks set. Intuitively, test considers weighted sum number times cluster performs betterconsidered sets macroshence, k = 3, maximum number clustersP 38;38evaluated run simulation i=k= 9177. number clusters 3 differenti=1combinations planners macros 38 current implementation.5. minimum value ensures performance gap problem solved one clusterplanners unsolved compared cluster bigger performance gap problemsolved compared clusters.650fiPlanning Automatic Portfolio Configuration: PbP Approachcompared one. sum weighted test uses performancegap assign rank performance difference.number samples sufficiently large, T-distribution used Wilcoxonsign-rank test approximately normal distribution, characterized two parameters called z-value p-value. higher z-value, significantdifference performance is. p-value represents level significanceperformance gap. p-value greater 0.05, null hypothesisperformance compared pair planners statistically similar refused, alternative hypothesis performance statistically different accepted. Otherwise,statistically significant evidence perform differently, PbP considersperform pretty much similarly.results Wilcoxon sign-rank test used form directed graphnodes compared clusters, edge cluster C1 another cluster C2indicates C1 performs better C2 . graph already used LongFox present results 3rd International Planning Competition (Long & Fox,2003). strongly connected component graph collapsed single noderepresenting elements clusters collapsed nodes. resulting DAG,PbP considers nodes without incoming edges (the graph root nodes).one root node, selected cluster, otherwise PbP uses secondary criteriaselect promising cluster among root nodes. criteria numbersolved problems, sums ratios (simulated) CPU times plannerscompared clusters, first planning CPU-time slots involved planners.Specifically, PbP selects cluster among root nodes simulation solveshighest number training problems. break ties, every pair selected clusters x|sx sy |PbP computes ratio max{s, sx sy sums (simulated)x ,sy }CPU times clusters x y, respectively; ratio greater threshold 0.05,compared cluster worst sum CPU times discarded. numberremaining clusters still greater one, PbP selects cluster lowest firstplanning CPU-time slots involved planners. Finally, remaining ties brokenselecting cluster randomly, experiments cluster ever randomlyselected.method used select cluster planners macros PbP.q similar,applies plan qualities resulting cluster execution simulation, ratherCPU times done PbP.s. simulation, PbP.q considers also intermediatesolutions (i.e., generated last one, best quality)relative CPU times computed basic incremental planners consideredclusters. solutions ignored, simulated plan quality clusters includingincremental planners could much worse actual quality. example, assumeCPU-time limit 900 seconds, FF computes solution quality 50 using 100seconds, LAMA computes two solutions quality 20 19 using 120 880 seconds,respectively. intermediate solutions LAMA ignored, estimated plan qualitycluster formed planners FF LAMA would equal quality plangenerated FF (the second solution generated LAMA could computed clusterusing 980 seconds, greater CPU time limit), although intermediate(first) solution LAMA much better FFs solution.651fiGerevini, Saetti, & VallatiFinally, note performance incorporated planners measuredCPU-time limit , portfolio PbP.s/q (re)configured time limitsimply ignoring solutions computed time simulationplanner cluster performance. , equally distributed among plannersselected cluster. planner terminates allocated time, remaining timealso equally distributed planners still running.3.4 Integrated Basic Plannerssubsection, give brief description nine basic plannerscurrently incorporated PbP. Much detailed information availablecorresponding referred papers.Metric-FF (Version 2.1; Hoffmann, 2003). Metric-FF inherits main ideas used FF(Hoffmann & Nebel, 2001). FFs search strategy variation hill-climbing spaceworld states, FF goal distance estimated solving relaxed tasksuccessor world state. Compared first version FF, Metric-FF enhancedgoal orderings pruning techniques ordering knowledge provided goalagenda. Moreover, deals level 2 pddl2.1 (Fox & Long, 2003), i.e., numerical statevariables, numerical action preconditions effects.YAHSP (Version 1.1; Vidal, 2004). YAHSP extends search procedure FFinformation extracted FFs relaxed plan. evaluated world state, YAHSPexploits look-ahead strategy complete best-first search employing actionsrelaxed plans order find beginning valid plan lead reachableworld state.MacroFF (Botea et al., 2005, 2007b). Macro-FF extends FF support using macrooperators search, engineering enhancements. One main featuresplanner version integrated PbP use iterative macros (Botea et al., 2007b),i.e., runtime combinations macro operators, instantiated attempting usemany actions FFs relaxed plan possible. search procedure FF,iterative macros successfully instantiated considered generationnext world states.Marvin (Release 1; Coles & Smith, 2007). Marvin another planner based FF.main improvement w.r.t. FF memorizing plateau-escaping action sequences discovered(local) search FF. action sequences form macros, appliedlater plateaus once-again encountered FFs search order escapeplateaus quickly.SGPlan (Version 5.22; Chen et al., 2006) domain-modification script (Coles & Coles,2011). SGPlan5 exploits partition-and-resolve strategy partition mutual-exclusionconstraints planning problem subgoals subproblems, solves subproblems individually using modified version Metric-FF planner, resolvesviolated global constraints iteratively across subproblems. observedperformance SGPlan affected rules detecting domain namenumber domain operators (Coles & Coles, 2011). work, intend consider652fiPlanning Automatic Portfolio Configuration: PbP Approachavailable implemented systems chances perform well (possibly combinationothers) least one domain range varied existing benchmark domains.SGPlan definitely one systems. However, order prevent usagedomain-specific detection rules SGPlan that, differently planners incorporated PbP, would make SGPlan domain-specific domains, inducedSGPlan behave domain-independently domain modification script, proposedColes Coles (2011). script changes domain name, adds never-applicableaction domain, runs SGPlan obtained domain. addition,domain-modification script also changes names domain operators.Fast Downward (Version 1.0.1; Helmert, 2006). Fast Downward (abbreviated FD)translates input pddl problem specification multi-valued state variable representation SAS+ (Backstrom & Nebel, 1995), searches plan spaceworld states using heuristic derived causal graph, particular graph representingcausal dependencies SAS+ variables. PbP integrates 2006 version planner.main improvement compared earlier version planner 2004propositional satisficing track IPC4 addition safe abstraction, form problemsimplification allows planner solve certain kinds simple problems withoutsearch.LAMA (Version 2008; Richter & Westphal, 2010). LAMA built Fast Downward, usingSAS+ state variables multi-heuristic search. core feature use pseudoheuristic derived landmarks, propositions must true every solutionplanning task. Moreover, weighted A? search used iteratively decreasing weights,planner continues search plans better quality.LPG-td (Gerevini et al., 2006). LPG-td inherits main ideas used LPG (Gerevini et al.,2003). LPG uses stochastic local search space partial plans represented actiongraphs. search steps certain graph modifications transforming action graphanother one. LPG-td includes accurate heuristics selecting graph modificationsLPG.ParLPG (Version IPC7; Vallati et al., 2013b). ParLPG recent system basedidea automatically configuring generic, parameterized planner using set trainingplanning problems order obtain speed-optimized planners perform especially welldomains problems. ParLPG uses FocusedILS variant off-the-shelf,state-of-the-art automatic algorithm configuration procedure ParamILS (Hutter et al., 2007,2009), planning system LPG (ver. 1.0), several componentsconfigured flexibly via many exposed configurable parameters.4. Experimental Analysissection, present results large experimental study PbPfollowing main goals:(G1) describing configured portfolios analyzing configuration process PbP(Section 4.2);653fiGerevini, Saetti, & Vallati(G2) analyzing efficiency PbP.s/q terms speed plan quality contextplanning competitions IPC6-7 (Section 4.3);(G3) comparing performance planner portfolio configured PbP.s/q versusplanning systems based planner portfolios (Section 4.4);(G4) evaluating effectiveness using (automatically computed) domain-specificconfiguration knowledge PbP.s/q (Section 4.5);(G5) comparing performance planner portfolio configured PbP.s/q versussingle basic planners portfolio, evaluating accuracy plannercluster selection PbP.s/q (Section 4.6);(G6) analyzing kind macros selected PbP planners configuredportfolio, evaluating effectiveness using selected macro set, understanding PbP.s/qs accuracy selecting useful set (Section 4.7);(G7) investigating possible alternative methods scheduling executionplanners selected cluster, understanding effectiveness defaultround-robin strategy PbP.s/q (Section 4.8).experimental study uses various versions PbP, importantlisted Table 1. G1, show CPU time configuration step,evaluate size training problem set important derive effective configuredportfolios. G2, PbP compared planners entered learning trackIPC6-7 winner deterministic track IPC7. G3, performancePbP analyzed w.r.t. FDSS (Seipp et al., 2012) BUS, portfolio approach proposedRoberts Howe (2007). Although BUS FDSS propose design domainindependent planner portfolios, principle also used, like PbP, generatedomain-optimized planning systems. experimentally investigate also useapproaches, comparing PbP. G4, show results three differentexperimental comparisons: comparison PbP configured using learned domainspecific knowledge (DSK), unconfigured version PbP (PbP-nok) randomlyconfigured version PbP (PbP-rand); comparison performance gaps PbPPbP-nok w.r.t. gaps IPC6-7 planners with/without learned knowledge;comparison PbP using DSK, PbP configured single domain without usingmacros, PbP configured across IPC7 domains (PbP-allD). G5, conductedthree experiments which: performance PbP incorporated plannerscompared; performance PbP analyzed w.r.t. best incorporated planner (withoutusing macros) every IPC7 domain; and, finally, PbP compared best clusterincorporated planners (possibly using macros) every IPC7 domain. G6, compareperformance planners forming clusters selected PbP using (i) macros,(ii) set macros selected PbP, (iii) best performing set macros; moreover,show comment features sets macros selected used PbP. Finally,G7 perform two experimental analysis: comparison clusters selected PbPusing different scheduling strategies, comparison performance PbP usingdifferent PCPVs (PbP R1-R2/S1-S2).654fiPlanning Automatic Portfolio Configuration: PbP ApproachPbP (default)PbP-IPC6PbP-IPC7PbP-nokPbP-randPbP-noMPbP-allDPbP S1PbP S2PbP R1 PbPPbP R2PbP 10/30/60PbP versionsLast version PbP configured computing domain-specific knowledge (DSK)Version PbP entered IPC6 configured using DSKVersion PbP entered IPC7 configured using DSKUnconfigured portfolioRandomly configured portfolioConfiguration without macrosConfiguration without macros across IPC7 domainsConfiguration using sequential scheduling planners uniform time slotsConfiguration using sequential scheduling planners non-uniform time slotsConfiguration using round-robin scheduling planners default PCPVConfiguration using round-robin scheduling planners different PCPVsConfiguration using 10/30/60 training problemsTable 1: Main variants PbP generating different types planner portfolio configurationsused experimental analysis.presenting discussing results experimental analysis, describeexperimental settings.4.1 Experimental Settingsexperiment evaluating PbP.s/q respect IPC6-7 planners considersIPC6-7 benchmark domains (Fern et al., 2011; Jimenez et al., 2011),experiments focus recent IPC7 domains. Regarding training problems usedexperiments, IPC6 domains IPC6; IPC7domains, set 540 problems various sizes (60 problems IPC7 domain,unless otherwise specified particular experiment consideration)generated using problem generator made available organizers IPC7 (for IPC7,explicit set training problems provided). training problems usedlearning macros configuring portfolio. Since learning procedure Wizardrun planner training problems several times, order make trainingmuch time consuming, half training problem set designed formedproblems took 30 seconds solve planner; half formedproblems took 450 seconds (half CPU time limit used testingphase) solve.Regarding test problems, used problems used IPC6-7:IPC6 test problems used evaluating performance PbP.s/q respectplanners entered IPC6; IPC7 test problems, generally larger muchdifficult IPC6 problems, used evaluating PbP.s/q respectIPC7 planners, well experiments analysis.experiments conducted using last version PbP.s/q,exactly one entered IPC7 (PbP-IPC7 short) three reasons:6 (a) PbP-IPC7 properly compiled lack C-librariescompetition machine, discovered competition; (b) PbP-IPC7 containsminor syntax bug format output plans IPC7 domains madegenerated plans invalid program validating used competition (Howey,6. code last version PbP available http://chronus.ing.unibs.it/pbp/.655fiGerevini, Saetti, & VallatiLong, & Fox, 2004); (c) PbP-IPC7.s uses SGPlan5 without domain-modificationscript induces SGPlan5 behave domain-independently. Point (a) negatively affectedperformance PbP-IPC7.s/q, one incorporated planners (Macro-FF)could run selected. (b), many valid plans generated PbP-IPC7.s/qrejected plan validator IPC7. Point (c) changed composition clusters selected PbP-IPC7.q include SGPlan5, make performancePbP.q PbP-IPC7.q substantially different. difference plannerclusters selected PbP-IPC7.s PbP.s concerns domain Blocksworld,cluster PbP-IPC7.s consists ParLPG without macros, cluster selected PbP.sParLPG using Bunching set macros computed Wizard.comparison IPC6 planners, results PbP.s/q obtainedrunning last version machine similar (same CPU frequency amount RAM)one used obtain official IPC6 data (an Intel Core(tm) Quad-processor Q66003 Gbytes RAM). comparison PbP.s/q IPC7 planners, systemsrun using machine IPC7 (a Quad-core Intel Xeon 2.93 GHz 4 GbytesRAM) IPC-organizers made available us experiment. Unless otherwisespecified, experiments conducted using Quad-core Intel Xeon(tm) 3.16GHz 4 Gbytes RAM.experimental analysis required many days CPU time. Unless otherwise indicated,IPC6-7, CPU-time limit run PbP.s/q 15 minutes, PbP.s/q useddefault configuration process (the CPU-time limit simulated execution plannercluster 15 minutes), planners configured portfolio run roundrobin scheduling described Section 3.2. performance data planner PbP.s/qincorporating randomized algorithm (i.e., LPG, ParLPG LAMA) obtainedsingle run considered problem instance.experimental comparisons test instances generally use three alternativemethods: average performance data, IPC7 score function (Jimenez et al.,2011), Wilcoxon sign-rank test used planner cluster selectionconfiguration. Given two compared planners problem set, average CPU timeplanner computed problems set solved least onecompared planners, using CPU-time limit (900 seconds) CPU timeplanner solve problem; average plan quality computedproblems solved compared planners.IPC7 score function defined follows. Concerning planning speed, plannerP solves problem using CPU time, gets time score equal 1+log 1 (t/t ) ,10best time times required planners comparison solving. Concerning plan quality, P generates plan l actions solving , gets qualityscore equal , l number actions shortest plan computedcompared planners . P solve , gets zero score (bothspeed quality). Given domain D, time (quality) score planner Psum time (quality) scores assigned P considered test problems D.IPC7 score function speed refinement IPC6 score function.IPC6 IPC7 time scores defined according much slower planner performsbest performing one, IPC6 score penalizes slowdowns heavily656fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7 score. experiments, observed using IPC6 function, insteadIPC7 function, gives similar general results slightly favorable PbP.s.Wilcoxon sign-rank test, null hypothesis performancecompared pair planning systems statistically similar. level confidence usedp = 0.001. analysis involves comparison two planning systems,then, order maintain confidence level used one hypothesis tested(i.e., pair planners compared), confidence level modifiedBonferronis correction (Shaffer, 1995). analysis, usage Bonferroniscorrection implies that, experimental result obtain Wilcoxon sign-rank testderives comparison n planning systems, used confidence level 0.001n1 .Moreover, plan quality comparison using Wilcoxon sign-rank test, qualityplans computed two compared planners normalized length best plantest problems solved planners. Since Wilcoxon sign-rank test usesranking differences values sample pair, compared absoluteplan length directly, without normalization, differences values domainscould result unintended bias, small relative differences benchmark domainlarge solution plans weighted important larger relative differencesdomain small plans.4.2 Overview Configured Portfolios Generated PbPsection concerns experimental goal G1: give information configured portfolios (multi-planners) generated default version PbP.s/q (see Table 1),relative CPU times used automated portfolio configuration, sizetraining problem set used configuring PbP. Table 2 shows planners clusters selected PbP every IPC6-7 domain. planner cluster, tablealso indicates brackets sets macros selected PbP, availablehttp://chronus.ing.unibs.it/pbp (the computed planning time slots clustersomitted brevity clarity). example, Depots, PbP.q selects cluster formed(i) Macro-FF two learned macros frequently appear Macro-FFsplans solving training problems, (ii) ParLPG without computed macros,(iii) SGPlan5 set macros obtained chunking macro generation methodWizard. configured portfolios Table 2 derive following observation:Experimental result 4.2.1 planner clusters selected PbP often formed different sets planners macros: overall nine basic planners helpful (eachselected PbP.s/q least once), different sets macros considered helpfulothers, including, cases, empty set.Concerning planning speed, observe domains PbP.s relies singleplanner possibly using set macros. particular, 7 15 considered domainsParLPG outperforms incorporated planners, hence domainsselected cluster contains ParLPG. main reason better performance ParLPGuses LPG parameter configuration (automatically) optimizedevery considered domain, greatly speedup planner (Vallati et al., 2013b).657fiGerevini, Saetti, & VallatiDomainsIPC6 domainsGold-minerMatching-BWN-puzzleParkingSokobanThoughtfulIPC7 domainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPPbP.sPbP.qYAHSP (Cl)ParLPG ()ParLPG ()Macro-FF (M2)ParLPG ()FF (), YAHSP ()Macro-FF (M1), LAMA (B), LPG (0)Marvin (0), LAMA (), LPG (B)Fast Downward (), LAMA (), LPG (0)FF (0), LAMA ()Macro-FF (M2), LPG (B)Macro-FF (M5), Marvin (), LAMA ()SGPlan5 (B)ParLPG (B)Macro-FF (M2), ParLPG (0)ParLPG ()Macro-FF (M2)ParLPG ()ParLPG ()ParLPG ()Macro-FF (M1)SGPlan5 (Cl), FF (), LAMA ()ParLPG (), LPG (B)Macro-FF (M2), ParLPG (0), SGPlan5 (Ch)Marvin (), ParLPG ()FF (0), LAMA ()LAMA (), ParLPG ()ParLPG (), Marvin (0)LPG ()LAMA (), SGPlan5 (Ch)Table 2: Planners sets macros (in round brackets) cluster selected PbPIPC6-7 domains. 0 indicate macros generatedselected, respectively; Ch, B Cl abbreviate three sets macrosChunking, Bunching Clumping generated Wizard, respectively; M1M5five sets macros generated Macro-FF. order planners listedclusters corresponds order run.observed that, previous version PbP entered IPC6 without ParLPG,selected clusters even varied.interesting observe PbP selects Macro-FF configured portfolioplanner always uses non-empty set macros. fact selected cluster Macro-FF always uses one among learned sets macros indicates macroconstruction exploitation methods incorporated Macro-FF effectiveplanning system.Table 3 gives CPU times used PbP.s different phases portfolioconfiguration applied IPC7 domains, machine Quad-core IntelXeon(tm) 3.16 GHz 4 Gbytes RAM used.7 configuration times PbP.qsimilar PbP.s macro extraction cluster simulation phases,higher performance measurement, incorporated incrementalplanners use whole CPU-time limit order find good quality plans. Althoughconfiguring PbP specific domain requires considerable amount CPU time,considered configuration needs done once, since generatedconfigured portfolio (selected planner cluster) used problems domain.Finally, order understand small sets training problems sufficientderive informative DSK test problems larger training ones,7. every IPC7 domain, parameter configuration ParLPG required 1400 hours.658fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPMacro ExtractionMacro-FF Wizard37.528.516.444.27.182.945.312.923.886.518.20.014.141.35.250.819.33.9PerformanceMeasure121.692.792.496.8163.057.360.0110.734.5Simulation &Selection0.020.020.020.020.020.020.020.020.02Total187.6153.4182.4155.0273.375.6115.4116.857.8Table 3: CPU hours used configuration PbP.s IPC7 domains: extractionmacros Macro-FF Wizard (2nd 3rd columns), performance measurement phase (4th column), cluster run simulation best cluster selection (5thcolumn), total configuration time (6th column).compared performance PbP configured using default number 60 training problems using half one-sixth training problems. (The range problemsize three sets training problems.) results analysisTable 4. course, lower number training problems is, cheapertraining PbP is. hand, DSK computed using training problemssometime much less effective informative DSK obtaining using larger sets.Depots, PbP.s DSK derived 60 training problems performs muchbetter DSKs derived 30 10 training problems;domains, performance PbP.s three compared DSKs similar same.interesting observe Depots domain cluster PbP.s twoplanners. domain, cluster PbP.s derived 60 training problems consistsMacro-FF ParLPG: 16 training problems ParLPG hands solution PbP.s,44 training problems solution PbP.s obtained Macro-FF.DSK derived 30 20 training problems, either Macro-FF ParLPG partconfigured cluster PbP.s makes PbP.s performing worse.Depots, Satellite TPP, PbP.q DSK derived 60 training problemsperforms much better DSK derived 30 10 training problems.domains, performance PbP.q similar same.4.3 Performance PbP IPC6-7 Plannerssection concerns experimental goal G2: experimentally evaluate performancePbP context IPC6-7 aim showing competitiverecent planning systems using domain specific learned knowledge. Since timewriting several IPC6-7 planners relative domain specific knowledge available,experiment used official competition data (CPU times, plan qualitiesnumber solved problems) results obtained running last version PbP.659fiGerevini, Saetti, & VallatiIPC7DomainsDepotsParkingdomainsIPC7DomainsBlocksworldDepotsParkingSatelliteTPPdomainsTime score603026.02.67.44.933.47.0102.65.88.4Mean CPU time60301031.9312.5 312.5172.8 127.7 281.3110.2 209.8 292.6# solved problems603010264485734911Quality score60301029.929.6 29.624.78.69.24.82.82.029.60.027.814.87.70.0133.8 78.7 98.6Mean plan length603010269.9 272.8 272.8151.7 156.2 151.276.061.061.0325.3 326.6 326.0# solved problems60301030303026101053230028158013681100Table 4: Time/quality score, average CPU time/plan length number solved problemsPbP.s/q configured DSK computed using set either 60 (defaultversion PbP), 30 10 training problems. domains consideredIPC7 domains training phase PbP.s/q derives different DSKstraining problem sets different sizes.learning track IPC6 IPC7, competing teams awaredomains used evaluation submitting systems. code submission,contest two phases. first phase, domains released learningparts planners run automatically derive, domain, additionalknowledge using set training problems domain. second phase, submitting learned knowledge IPC organizers, planners run relativelearned knowledge, resulting performance data compared using IPC scorefunction. interested reader find details IPC6-7 organizationwell collection short papers describing IPC6-7 planners entered learningtrack work Fern et al. (2011), Jimenez et al. (2011).PbP, knowledge derived first phase competition portfolio configuration knowledge described previous section paper. knowledge learned IPC6 planner ObtuseWedge consists special patterns, extendnotion n-gram include argument relations, used aimspeeding enforced hill-climbing search (Yoon, Fern, & Givan, 2008). IPC6planning systems Wizard+FF Wizard+SGPlan learn set macro actions planners FF SGPlan5, respectively. IPC7 planners, Bootstrap-Planner learnsdomain-specific heuristic combining set existing heuristics weights obtainedevaluating performance heuristics training problems (Arfaee, Zilles, &Holte, 2010). Finally, knowledge learned OALDAEYASHP (Brendel & Schoenauer,2011), ParLPG, Fast Downward-autotune-speed Fast Downward-autotune-quality (Fawcettet al., 2011) consists domain-specific parameter configurations.Table 5 gives overall experimental evaluation best-performing plannersIPC6 (using IPC6 domains) best-performing planners IPC7 (using660fiPlanning Automatic Portfolio Configuration: PbP ApproachBest IPC6 plannersPbP.sPbP.qObtuseWedgePbP-IPC6.sPbP-IPC6.qRFA1Wizard+FFWizard+SGPlanBest IPC7 plannersPbP.sPbP.qBootstrap-PlannerFast Downward-autotune-speedFast Downward-autotune-qualityOALDAEYASHPParLPGPbP-IPC7.sPbP-IPC7.qLAMA-2011Problem Solved(%)97.095.065.095.692.847.256.751.1Time score(max = 180)105.56.8973.588.26.4314.747.356.1Quality score(max = 180)111.2169.175.6111.4132.352.372.465.2Problem Solved(%)87.483.74.0777.032.27.4157.0471.4870.3737.67Time score(max = 270)232.776.23.28110.035.35.70104.0178.171.137.9 (1st sol.)Quality score(max = 270)202.5221.710.93170.864.33.76146.0172.5192.782.4 (last sol.)Table 5: Percentage solved problems within 15 CPU minutes, time quality scoresPbP.s/q (best performing) planners took part learning trackIPC6-7 domains problems IPC6-7. Larger scores indicate betterperformances. PbP-IPC6 PbP-IPC7 indicate versions PbP took partIPC6 IPC7, respectively; LAMA-2011 winner deterministic trackIPC7.IPC7 domains), terms percentage solved problems, planning speed plan quality.compared planners run relative learned knowledge. dataTable 5, following general experimental result derived.Experimental result 4.3.1 IPC6-7 domains problems, PbP.s generallyfaster compared IPC6-7 planners, PbP.q performs generally better terms planquality, PbP.s/q solves many problems.8Remarkably, PbP.s/q solves high percentage IPC6-7 benchmark problemswithin 15 CPU minutes, PbP.q almost always computes plan betterplan computed competitor. contrast, time score PbP.q low, since8. version PbP used comparison suffer technical problems indicated Section4.1 affected performance PbP IPC7. IPC7 planners may suffered similarproblems, implementation might also improved versions considered.However, note even version PbP.s/q entered IPC7 performs generally bettercompeting planners.661fiGerevini, Saetti, & VallatiPbP.q usually runs one planner stops selected plannersterminate CPU-time limit exceeded.analysis competition results (planner CPU times plan qualities) usingWilcoxon sign-rank test instead IPC score functions performance comparisonconfirms PbP.q generates significantly better quality plans (z = 3.920, p < 0.0017 ).p-value obtained analysis 0.004 (with z-value equal 2.846). Since p-valueadjusted critical value 0.0017 , null hypothesis (the performance PbPsimilar performance IPC6-7 planners terms speed) accepted,thus research hypothesis (the performance PbP statistically different) rejected.However, worth pointing critical value 0.001 quite hard reach,especially given also apply experiment-wise error adjustment. setless stringent critical value, say 0.05, adjusted critical value would 0.057 = 0.0071,p-value 0.004 would significant.Table 6 gives details performance comparison IPC7 domain.terms speed, PbP.s best performance eight nine domains considered analysis; domain perform best Parking,Fast Downward-Autotune-speed performs better. Similarly, terms quality, PbP.qbest performance seven nine domains, performs well ParLPGPbP.q one domain (Spanner), performs worse Fast Downward-Autotune-speedtwo domains (Parking TPP). worth noting principle portfolio approachincorporate planners promising attempting problems domain.current version PbP integrates planners established state-of-the-artPbP developed, time Fast Downward-Autotune-speed available. results Table 6 indicate portfolio-based approach would reach betterperformance, also incorporated planner. instance, likely PbP wouldselect planner domain Parking, greatly improving performance domain.Finally, comment relative performance PbP winner deterministic satisficing track IPC7, 2011 version LAMA. course, cannot expectdomain-independent planner, LAMA, performs better planner exploiting(learned) specific domain knowledge. hand, definitely desired propertyway around holds: planning system uses form (automaticallyacquired) domain specific knowledge effective performs better state-ofthe-art domain-independent planner use additional knowledge.last lines Tables 5 6 indicate global domain-by-domain performanceLAMA-2011 respect planners learning track IPC7, consideringscore functions competition track.9 comparison, CPU time limit usedrun LAMA 15 minutes, time limit one used run PbP.s/qplanners took part learning track IPC7. worth notingIPC7 domains learning track propositional, IPC7 problems requireoptimization explicit specified plan metric; problems, LAMAPbP minimize number actions. seen PbP.s/q performs substantially9. Although experimental comparison considers planning time scores plan quality scores,noted deterministic track IPC7 focused plan quality, hence LAMA-2011presumably developed focusing quality rather speed. sense, results planquality comparison LAMA-2011 meaningful planning speed.662fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7 PlannersBootstrap-PlannerFDA-speedFDA-qualityOALDAEYASHPParLPGPbP-IPC7.sPbP-IPC7.qPbP.sPbP.qLAMA-11Solved problemsBarmanBWDepotsGripperParkingRoversSatSpannerTPP030000293030302112927203029303030290200017261026260030103030303030002090005855030300272730273030019703030303030130000303030303000301401500251520BarmanBWDepotsGripperParkingRoversSatSpannerTPP0.014.30.00.00.028.822.928.822.90.523.2812.19.315.7016.317.38.2730.08.2710.60.010.90.00.09.1825.13.0525.17.950.00.09.840.550.015.330.08.4730.08.470.00.018.75.670.00.00.02.627.142.622.80.013.511.40.017.527.08.2127.08.2110.00.06.391.920.017.730.010.230.010.23.50.00.810.510.016.230.07.3430.07.340.00.023.55.960.011.90.00.024.87.3710.5BarmanBWDepotsGripperParkingRoversSatSpannerTPP0.026.90.00.00.028.430.028.430.01.863.7613.213.310.921.724.129.821.129.821.80.020.00.00.08.3116.89.0116.823.00.00.028.80.00.028.627.529.927.529.90.00.017.29.000.00.00.04.099.084.093.80.024.222.80.021.419.330.019.330.024.70.015.76.670.028.526.530.026.530.011.00.00.00.00.030.030.030.030.030.00.00.024.812.60.07.540.00.023.914.919.3IPC7 PlannersBootstrap-PlannerFDA-speedFDA-qualityOALDAEYASHPParLPGPbP-IPC7.sPbP-IPC7.qPbP.sPbP.qLAMA-11 (1st sol.)Time scoreIPC7 PlannersBootstrap-PlannerFDA-speedFDA-qualityOALDAEYASHPParLPGPbP-IPC7.sPbP-IPC7.qPbP.sPbP.qLAMA-11 (last sol.)Quality scoreTable 6: Number solved problems, time/quality scores (best performing)IPC7 planners IPC7 domain. FDA, LAMA-11, BW Sat abbreviateFast Downward-Autotune, LAMA-2011, Blocksworld Satellite, respectively.better LAMA-2011. results Table 5 show PbP.s/q solves many IPC7problems, achieves considerably better overall time quality scores respectLAMA-2011s first best quality solutions, respectively. results Table 6 showthat: PbP.s much higher speed performance every domain, much higherquality performance domains; PbP.q much higher quality performanceseven domains, performs similarly two domains, muchhigher speed performance domains.Moreover, since deterministic track IPC7 CPU-time limit 30 minutes,compared LAMA-2011 PbP.s/q problems learning track usinglimit first planner, keeping 15 CPU minutes second. extra CPUtime LAMA-2011 considerably change results comparison: overall,663fiGerevini, Saetti, & Vallatitotal time scores LAMA-2011 PbP.s/q 61.9 231.9/116.5, respectively;total quality scores LAMA-2011 PbP.s/q 80.7 227.6/206.2, respectively;LAMA-2011 solves 101 problems PbP.s/q solve 238/230 problems.previous experimental analysis PbP.s/q LAMA-2011 summarizedfollowing claim, suggesting portfolio-based planner (automatically) configuredgiven domain, perform much better state-of-the-art fully domain-independentplanner.Experimental result 4.3.2 benchmark domains learning track IPC7,configured versions PbP.s/q perform better IPC7 winner deterministictrack.Since PbP without configuration knowledge (PbP-nok) fully domain-independentplanner, also interesting see well PbP-nok performs w.r.t. LAMA-2011.experimental comparison, also used benchmark domains problems deterministic track IPC7, CPU-time limit IPC7 run (30 minutes).Moreover, since deterministic track IPC7 focused plan quality, measured totalaction cost, considered quality version PbP-nok. LAMA-2011 optimizestotal action cost, PbP-nok.q incorporated planners consider number actionsplan quality. Although analysis relies total action cost, hence somewhatfavor LAMA-2011, observed PbP-nok.q competitive LAMA-2011.problems IPC7 deterministic track, total quality score number solvedproblems slightly lower PbP-nok.q LAMA-2011 (214.8 232.2,239 250, respectively). lower quality score PbP.q mainly twofourteen IPC7 domains (Elevator Parcprinter), PbP-nok.q obtains muchlower scores (1.0 19.0 3.0 19.6, respectively). test problemslearning track IPC7, PbP-nok.q performs even better LAMA-2011 (IPC qualityscore: 168.8 versus 97.5; solved problems: 181 versus 105).Experimental result 4.3.3 benchmark domains deterministic learningtracks IPC7, PbP.q without configuration knowledge (PbP-nok.q) competitivewinner IPC7 deterministic track.Given PbP.q without configuration performs already well, performance improvement obtained exploiting computed configuration knowledge even notable.Section 4.5 shows portfolio configuration PbP.s/q useful improveperformance.4.4 Performance PbP Planner Portfoliossection concerns experimental goal G3: compare PbP two planner portfolioapproaches: FDSS (Helmert et al., 2011) BUS (Roberts & Howe, 2007).664fiPlanning Automatic Portfolio Configuration: PbP Approach4.4.1 PbP versus FDSSTable 7 shows performance PbP.s/q w.r.t. FDSS without using macros.10results comparison summarized follows.Experimental result 4.4.1 benchmark domains learning track IPC7,terms number solved problems PbP.s/q performs always better FDSS, exceptdomains Rovers TPP, FDSS solves problems PbP.s PbP.q,respectively. terms time score, PbP.s always performs better FDSS. termsquality score, PbP.q performs always better except TPP.think least four reasons experiments PbP performed generallybetter FDSS. main reason that, PbP separately configured everyconsidered domain, FDSS always uses configuration determined probleminstances IPC16, designed using problem distributions quite differentlearning track IPC7 (Seipp et al., 2012). reasons (a) diversityplanning methods implemented planners incorporated PbP FDSS, (b)usage macros PbP.s/q, (c) different portfolio configuration techniquestwo compared systems. Concerning (a), consider instance domain Spanner,PbP.s/q outperforms FDSS PbPs configured portfolios use ParLPG/LPG (see Table2). every planner incorporated FDSS uses heuristic forward search techniques,ParLPG/LPG uses heuristic techniques searching space partial plans, seemseffective domain. (b), tried learn macros FDSS using Wizard,unfortunately useful macro learned planning system. Therefore, testedperformance FDSS using macros learned Wizard selected PbP.s/qplanners configured portfolios (see Table 2). results Table 7 indicatethat, using macros sometimes greatly improves performance PbP,really effective FDSS.Finally, order better understand importance (c), also developed compared PbP new variant FDSS, called FDSSd , restricting differencesFDSS PbP configuration techniques. Specifically, FDSSd following similarities differences w.r.t. original FDSS. FDSSd uses configurationtechniques FDSS, configures planner portfolio separately input domain(instead set domains altogether), uses macros, integrates plannersPbP (instead set forward-state planners). Then, important differencesPbP FDSSd method planner cluster selection schedulingstrategy used running planners forming clusters that, described Section 2,substantially different.Like PbP, computed two sets domain-optimized portfolio configurationsFDSSd : FDSS.sd focusing speed, FDSS.qd focusing plan quality. IPC7domains except Depots, planner clusters selected FDSS.sPbP.s. Depots, cluster FDSS.s consists Macro-FF using macro set M1Macro-FF using macro set M2, cluster PbP.s consists ParLPG using macroMacro-FF using macro set M2. domain FDSS.s PbP.s10. version FDSS run experiment uses 15 38 variants Fast Downward analyzedHelmert et al. (2011).665fiGerevini, Saetti, & VallatiPlannersPbP.sPbP.qFDSSFDSS+MPbP-nok.sPbP-nok.q# solved problemsBarmanBWDepotsGripperParkingRoversSatSpannerTPP3030002323303021101718262600883030002425850000273028282017303014141111303000131325151717710BarmanBWDepotsGripperParkingRoversSatSpannerTPP30.023.00.00.06.76.230.08.279.73.67.15.426.08.030.00.05.13.030.08.470.00.010.37.97.82.540.00.00.00.027.08.2117.117.19.85.830.010.28.88.84.74.130.07.30.00.05.35.323.77.18.59.03.23.8BarmanBWDepotsGripperParkingRoversSatSpannerTPP28.430.00.00.022.522.521.329.913.412.910.312.317.226.00.00.07.67.427.630.00.00.018.119.95.45.00.00.00.00.018.227.924.924.918.715.826.329.512.212.28.99.830.030.00.00.013.013.020.314.216.115.46.39.3PlannersPbP.sPbP.qFDSSFDSS+MPbP-nok.sPbP-nok.qTime scorePlannersPbP.sPbP.qFDSSFDSS+MPbP-nok.sPbP-nok.qTotal2362268069123125Total234.583.244.138.552.241.5Quality scoreTotal194.7222.566.665.4105.4110.0Table 7: Number solved problems, time/quality scores PbP, PbP-nok, FDSSwith/without using macros IPC7 domain. FDSS+M, BW Sat abbreviate FDSS using macros, Blocksworld Satellite, respectively.cluster, cluster formed single planner. Hence, running sequentialscheduling round-robin scheduling thing, compared plannerportfolios performance.planner clusters selected FDSS.q Table 8. domains Gripper, SatelliteTPP, PbP.q but, cases formedone planner. domains Satellite Gripper observed FDSS.q performsdifferently PbP.q different scheduling strategy. Table 9 shows results experimental comparison PbP FDSSd (results omittedcompared clusters formed single planner). Overall,derive following observation.Experimental result 4.4.2 almost benchmark problems domainslearning track IPC7, PbP.s fast FDSS.sd , Depots slightly faster;PbP.q computes plans always good better computed FDSS.qd ,solves problems.performance gap PbP FDSSd lower gap PbPFDSS, Depots PbP.s performs slightly better terms speed numbersolved problems, IPC7 domains PbP.q performs considerably betterterms plan quality. rationale behavior that, show Section 4.6,666fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7 DomainBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPFDSS.qd(Cl), FF, L,(B), FF (Ch), MFF (M1), FF (B),P, L, LPG (Ch), LPG (B)LPG, M, FF (Ch), MFF (M1), FF (Cl), (Ch), (Cl), P, MFF (M2), LM, PFF (Ch), FF, LFF, MFF (M1), L, LPGP,PL (), (Ch)Table 8: Planners sets macros (in round brackets) cluster selected FDSSdIPC7 domains. S, L, M, MFF P abbreviate SGPlan5, LAMA, Marvin,Macro-FF ParLPG, respectively; Ch, B Cl three setsmacros Chunking, Bunching Clumping generated Wizard; M1M5five sets macros generated Macro-FF.running planner clusters round-robin scheduling robust runningsequentially using possibly inadequate values planning time slots. Another explanation,especially high performance difference terms plan quality, different wayPbP FDSSd explore portfolio configuration spaces. FDSSd searchesplanner cluster use hill-climbing algorithm space possible clusters,PbP explores whole space possible clusters (with bound number plannersclusters). selected clusters PbP.s FDSS.sd almost alwaysIPC7 domains considered training problems configuring planner portfoliofocusing speed quite easy, cases single planner (possibly using macros)outperforms every planner. contrary, domains trainingproblems, configuring planner portfolio focusing plan quality difficultFDSSd , search space contains local minima prevent FDSSd findingbest-performing configuration (planner cluster), complete exploration searchspace allows PbP identify it.worth noting space planner clusters PbP much smallerspaces FDSS FDSSd , since space PbP cannot two different clustersformed planners relative macros, different relative sequencesplanning time slots (the sequence planning time slots planner relativeset macros derived according default PCPV). case, spaceclusters PbP would orders magnitude greater, time required PbPsimulating cluster execution would negligible w.r.t. timeconfiguration phases (see Table 3).performance comparison PbP.s FDSSd using Wilcoxon sign-rank testgives statistical result compatible performance data Table 9Experimental result 4.4.2: IPC7 domains, statistical differenceplanning CPU times PbP.s FDSS.sd (z = 1.257, p = 0.209), while,667fiGerevini, Saetti, & VallatiIPC7DomainsDepotsMaxscore30Time scorePbP.sFDSS.sd22.220.1Mean CPU timePbP.sFDSS.sd53.1126.3# solved problemsPbP.sFDSS.sd2623IPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsMaxscore303030303030303030270Quality scorePbP.qFDSS.qd30.030.030.014.424.219.230.023.74.82.829.817.330.025.030.030.015.015.0223.8177.4Mean plan lengthPbP.qFDSS.qd448.3448.3233.5340.2159.9169.1574.0581.770.671.7580.3600.2775.2775.2326.0326.0370.1370.1433.1448.7# solved problemsPbP.qFDSS.qd3030302026213024533018302530301515226186Table 9: Maximum score, time/quality score, average CPU time/plan length numbersolved problems PbP FDSSd benchmark problems Depotsplanning speed, IPC7 domains plan quality.terms plan quality, PbP.q performs significantly better FDSS.qd (z = 5.767,p < 0.001).4.4.2 PbP versus BUSAlthough BUS originally designed generate domain-independent configured planner portfolio, like FDSS, principle also used build domain-specific configuredportfolios. Domain specificity obtained simply training problems domain. fully-automated executable BUS available,experimental results presented Roberts Howe (2007) derived simulation(Roberts & Howe, 2012). Thereby, order compare PbP BUS, implementedBUS approach using planners macros integrated PbP, generateddomain-specific configured portfolios using implementation BUS.BUS selects planners configured portfolio greedy set coveringapproximation algorithm sets problems solved incorporated planners,planners forming clusters ordered according ranking algorithmSimon Kadane (1975). greedy set covering approximation algorithm iterativelyselects planner reduces set covering problem smaller one, originalinput set fully covered (Cormen, Stein, Rivest, & Leiserson, 2001). Let planningdomain, P set selected planners, set test problems cover. Initially, Pempty contains 60 training problems. iteration, algorithm choosesplanner largest set solved problems S, removes problemsS, adds selected planner P . number planners largest setsolved problems greater one, algorithm selects first evaluated planner668fiPlanning Automatic Portfolio Configuration: PbP Approach(the planner evaluation order random). process terminates empty.resulting set P contains planners configured portfolio.experimentally observed almost every considered domain, sinceone incorporated planner solves training problems domain, set plannersforming cluster selected BUS domain consists one planner (exceptdomain Parking two selected planners, LAMA FF using macro set Clumping). Moreover, choice planner among solve training problemsdrastically affected random order greedy set covering approximationalgorithm evaluates coverage planners. Hence, derive indicationperformance reached implementation BUS, ran portfolio configuration BUS nine times, tested obtained nine configured portfolios, analyzedthree sets experimental results CPU time three sets experimental resultsplan quality. three sets derived using: median performing configuredportfolio nine generated considered domain, best/worst performing configured portfolio possible portfolios generated greedyset covering approximation algorithm BUS. results experimental comparisongiven Table 10 summarized following observation.Experimental result 4.4.3 benchmark domains learning track IPC7,terms time score average CPU time, PbP.s/q performs much better worstmedian configured portfolios derived BUS; PbP.s performs slightly betterbest configured portfolio oracle would select among derivedBUS, PbP.q performs slightly worse. terms problem coverage (the criterion usedBUS select planners cluster), PbP.s solves number problemsbest configured portfolio derived BUS.results Table 10 show performance obtained configured portfoliosgenerated BUS varies greatly, indicating planner-selection method BUSaccurate derive efficient domain-specific configured portfolios. thinkmain reason planner selection BUS considers problemcoverage ignores CPU time plan quality incorporated planners. However,important note planner-selection method BUS originally proposeddifferent kinds data sets (problem instances set domains considered altogetherdifferent used experiment) different purpose (generatingdomain-independent planner portfolio), BUS prominent approach showedgood performance (Roberts & Howe, 2009).4.5 Effectiveness Computed Configuration Knowledgesection concerns experimental goal G4. order understand effectivenessautomated portfolio configuration PbP, compare performance PbPcomputed configuration knowledge (PbP.s/q), configuration (PbP-nok.s/q),random configuration (PbP-rand.s/q). PbP-nok.s/q, planners initialportfolio selected, macros used, planning time slotsplanners, execution order random. PbP-rand.s/q, PbP-nok.s/qexcept subset three randomly chosen planners (possibly empty)669fiGerevini, Saetti, & VallatiIPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPPbP.sdomains30.029.820.629.57.926.930.030.025.0229.7IPC7DomainsPbP.qBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomains30.029.924.429.04.325.130.030.014.5217.2Time scoreBUSW.sM.s0.027.37.416.17.614.317.317.57.27.21.78.70.00.015.022.40.08.256.2121.7Quality scoreBUSW.qM.q0.029.59.429.76.013.515.215.27.87.84.416.90.00.030.030.00.014.772.8157.9Mean CPU timeBUSW.sM.sB.s2.0900.02.72.09.9603.2135.119.7191.4590.9205.0 132.518.2183.887.318.3364.1428.1428.1428.150.5840.4411.550.528.3900.0900.070.216.9208.1151.116.9121.2900.0508.6175.363.2627.0299.670.3# solved problemsPbP.sBUSW.s M.s B.s30030303010303026112226302530308888275182730003030303030250152523689183 236Mean plan lengthBUSW.qM.q210.6198.4175.8231.8876.6876.677.477.4482.8522.4326.0326.0459.8464.9# solved problemsPbP.qBUSW.q M.q B.q30030303010303026112226303030305888295182930003030303030150152522694183 238PbP.sB.s30.023.521.128.97.226.923.030.021.3211.9PbP.qB.q30.029.922.829.97.829.028.530.021.5229.4198.4143.7577.087.8498.8326.0367.6B.q198.4190.5554.777.4420.0326.0358.7Table 10: Time/quality score, mean CPU time/plan length number solved problemsPbP.s/q, worst, median best portfolios derivedusing BUS IPC7 domains. W.s, M.s B.s denote worst, medianbest portfolios among BUS derive lowest, median,highest time score considered IPC7 test problems, respectively; similarlyW.q, M.q B.q denote worst, median best portfolios lowest,median, highest quality score, respectively.randomly chosen set learned macros used, instead planners, differentrandom configuration PbP.s/q generated every IPC7 problem.Figure 3 gives overall picture results problems IPC7 domainsconsidering different amounts CPU times portfolio configuration; specifically,time x-axis CPU-time limit given run planner (with setmacros) performance measurement simulation phase, (simulated) runcandidate clusters planners planning cluster selection ordering phase,run configured portfolio test phase. marked pointscurves PbP.s/q correspond performance scores different configured portfoliosobtained different considered CPU-time limits. results indicate that, everyconsidered CPU-time limit configuration phase, PbP.s/q clearly performs betterPbP-nok PbP-rand. Moreover, refined analysis considering domain separatelyshows PbP.s/q best performance also every single considered domain,terms problem coverage every considered CPU-time limit gaps670fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7 domainsTime score240PbP.sPbP-nok.sPbP-rand.s200IPC7 domainsQuality score240PbP.qPbP-nok.qPbP-rand.q200160160120120808040400011010010001101001000Figure 3: Time score (left plot) quality score (right plot) PbP, PbP-nok PbP-randrespect increasing CPU-time limit (ranging 1 1000 seconds)IPC7 domains.PbP.s/q two compared version PbP similar gaps plotsFigure 3.Experimental result 4.5.1 computed configuration knowledge considerably improve performance PbP.s/q w.r.t. unconfigured randomly configured versionsPbP (PbP-nok PbP-rand, respectively).terms planning speed, performance comparison three considered versions PbP.s/q, using Wilcoxon sign-rank test gives similar general result: PbP.sstatistically faster versions (z = 12.578, p < 0.0012 ). terms planquality, PbP.q performs statistically better unconfigured version (z = 13.205,p < 0.0012 ). comparison PbP.q PbP-rand.q, analyzed 47230 problems solved PbP.q, PbP-rand.q solves problems planquality comparisons consider problems solved compared planners. results Wilcoxon test indicates PbP.q performs similarly PbP-rand.q(z = 1.662, p = 0.096). However, noted low number consideredproblems makes statistical comparison Wilcoxon sign-rank testaccurate informative deriving general conclusions relative performancecase.also tested version PbP-nok incorporated planners runusing predetermined time slot sequence Spre planner runs ordered usingmethod used PbP, considers relative performance plannersset training problems instead random order. Overall performancePbP-nok remains much worse performance (the planner cluster selected by)configured version PbP.Table 11 analyzes impact performance using DSK (i.e., PbP, computedconfiguration knowledge) best-performing planners entered learning trackIPC6-7. results comparison confirm strong positive impact PbPs DSK.671fiGerevini, Saetti, & VallatiPlannerBest IPC6 plannersObtuseWedgePbP-IPC6.sPbP-IPC6.qWizard+FFWizard+SGPlanPbP.sPbP.qBest IPC7 plannersBootstrapPlannerFast Downward-autotune-speedFast Downward-autotune-qualityOALDAEYASHPParLPG-speedPbP-IPC7.sPbP-IPC7.qPbP.sPbP.qSolved (%)TimeQuality+17.3+3.6+0.96.61.7+5.0+3.3+34.1+ 65.2+5.8+21.0+17.6+82.5+6.3+23.73.0+0.715.23.13.2+37.5+4.1+43.3+14.118.9+9.3+5.6+7.4+21.48+20.74+3.3+65.3+16.017.3+42.1+116.5+24.3+171.1+29.4+10.9+99.1+26.440.4+15.6+16.8+40.9+46.8+69.8Table 11: Performance gaps best-performing IPC6-7 planners with/without DSKterms percentage solved problems, time quality scores IPC6-7benchmark domains problems. Planner RFA1 omitted worksDSK.Experimental result 4.5.2 IPC6 domains problems, DSK computedPbP.s PbP.q strongest impact among DSK IPC6 planners termsimproved speed (time) plan quality (quality), respectively. DSK computedObtuseWedge strongest impact terms percentage additional solved IPC6problems.reason impact DSK computed PbP quite low terms additionalsolved IPC6 problems PbP.s/q solves almost problems even without DSK.Experimental result 4.5.3 IPC7 domains problems, DSK computedPbP.s strongest impact terms improved speed (time) among DSKIPC7 planners. use computed DSK Fast Downward-Autotune-speedstrongest impact terms percentage additional solved problems improved planquality.Although terms percentage additional solved problems improved plan quality use DSK PbP.s/q highest impact, leads high improvements also PbP.s/q, allowing achieve performance generally betterFast Downward-Autotune-speed (see Quality Score column Table 5).Finally, conducted experiment understand configuring PbP specific domain generates DSK leads better performance w.r.t. configuring planner portfolio672fiPlanning Automatic Portfolio Configuration: PbP Approachset domains altogether. Table 12 compares performance PbP.s/qDSK, DSK obtained without using macros (PbP-noM.s/q), configuration knowledge computed across IPC7 domains (PbP-allD.s/q). planner cluster PbP-allD.sformed LPG SGPlan5, planner cluster PbP-allD.q formed LAMA,Marvin SGPlan5. results Table 12 indicate that, even without consideringusage macros, portfolio configuration considered domains together greatlydecreases performance PbP.Experimental result 4.5.4 IPC7 domains, terms time score, average CPUtime number solved problems, PbP.s performs much better PbP-noM.sPbP-allD.s. terms quality score number solved problems, PbP.q performs muchbetter PbP-noM.q PbP-allD.q. terms average plan length, PbP.qPbP-noM.q perform usually better PbP-allD.q.results Wilcoxon sign-rank test applied comparison PbPPbP-noM confirm that, IPC7 domains, PbP.s significantly fasterPbP-noM.s (z = 7.699, p < 0.001) and, terms plan quality, PbP.q performs significantly better PbP-noM.q (z = 5.465, p < 0.001). high performance gapPbP PbP-noM, favor PbP, clearly indicates usefulness using macros,showing portfolio planners macros much efficient portfolioplanners.4.6 Accuracy Planner Cluster Selectionsection concerns experimental goal G5. order test accuracy plannercluster selection PbP, carried three related experiments performancePbP using computed configuration knowledge compared performance(a) every basic planner incorporated initial portfolio, (b) best performingincorporated planner (without using macros) considered domain, (c) bestperforming planner cluster (possibly using macros) considered domain.following, Section 4.6.1 presents experiments (a) (b), Section 4.6.2 experiment (c).4.6.1 PbP Basic Portfolio PlannersFigure 4 gives overall picture performance PbP.s/q w.r.t. performancebasic planners (without macros) terms speed plan quality, using CPU-time limitrun ranging 1 1000 seconds. time/quality scores comparedsystem derived summing corresponding scores obtained systemIPC7 domain. analysis indicates that, every considered CPU-time limit, PbP.sDSK generally much faster incorporated basic planners, PbP.q generatesbetter quality plans.Experimental result 4.6.1 IPC7 domains, basic planner considered input portfolio PbP achieves overall performance better similarperformance PbP.s speed, PbP.q plan quality (except lowCPU-time limits, compared planners perform similarly terms plan quality).673fiGerevini, Saetti, & VallatiIPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsIPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsTime scorePbP.snoM30.012.030.017.322.316.530.030.07.86.227.027.030.030.030.030.023.711.9232.3 181.3allD10.98.38.715.00.013.618.311.30.086.1MeanPbP.s2.05.928.318.216.928.313.525.8CPU timenoMallD72.9138.648.1311.449.3134.818.2175.116.9192.728.3151.013.5272.044.7194.4# solved problemsPbP.s noM allD30303030302126211330303087027272630303030302525130236219175Quality scorePbP.qnoMallD29.929.80.029.918.513.425.87.22.830.030.021.44.84.82.029.629.622.129.929.98.830.030.08.014.814.812.3224.7 194.5 91.2MeanPbP.q222.6153.0578.976.0634.9715.1284.8370.1484.5plan lengthnoMallD307.0 340.8163.5 171.0578.9 675.976.061.0634.9 650.6715.1 731.9284.8 284.8370.1 374.5498.8 535.4# solved problemsPbP.q noM allD303003026162693303025552303023303093030815151322620599Table 12: Time/quality score, average CPU time/plan length number solved problems speed quality versions PbP, PbP-noM (abbreviated noM)PbP-allD (abbreviated allD) IPC7 domains.results Wilcoxon sign-rank test applied experiment confirm PbP.ssignificantly faster every incorporated planner (z = 5.773, p < 0.0019 ),terms plan quality PbP.q performs significantly better (z = 3.920,p < 0.0019 ) except ParLPG. According Wilcoxon sign-rank test, statisticaldifference quality performances PbP.q ParLPG. discrepancyresults analysis Figure 4 generated different waysunsolved problems handled quality score function Wilcoxon sign-ranktest comparing plan quality performance: first considers problems attemptedcompared planners (explicitly penalizing planner zero score unsolvedproblem), second considers subset test problems solvedcompared planners; PbP.q solves many problems ParLPG (230 179),reflected relative curves Figure 4 plan quality.observed domains Rovers, Satellite Gripper solutions PbP.qcomputed ParLPG; domains Blocksworld Depots, PbP.q using ParLPG solves5 3 problems, respectively; considered domains, ParLPG partselected cluster running planners. better understand importance ParLPG PbP,analyzed performance version PbP incorporate ParLPG.674fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7 domainsTime score240PbP.sFDLAMA (1st sol.)LPG-td (1st sol.)Macro-FFMarvinMetric-FFSGPlan5YAHSPParLPG20016012080IPC7 domainsQuality score210PbP.qFDLAMA (last sol.)LPG-td (last sol.)Macro-FFMarvinMetric-FFSGPlan5YAHSPParLPG180150120906040300011010010001101001000Figure 4: Time (left plot) quality (right plot) scores PbP.s/q relative computed configuration knowledge compared time quality scoresbasic incorporated planners IPC7 domains, using increasing CPU-timelimit. FD abbreviates Fast Downward.IPC7 domains, PbP.s/q incorporate ParLPG, problems solvedPbP.s/q decrease 10/12%, and, terms time score, PbP.s without ParLPGperforms worse ParLPG (156.1 vs. 176.5). However, terms quality score, PbP.qwithout ParLPG performs still much better ParLPG (183.1 vs. 144.5). resultsanalysis show performance PbP terms speed drastically affectedParLPG. hand, importance ParLPG PbP.q limitedparameter configuration ParLPG focused speed.two main reasons explaining observation derived Experimental result 4.6.1globally best performance PbP.s/q basic incorporated planner(even ParLPG) outperforms others every considered benchmark domain,PbP effectively selects combines efficient planners domainconsideration (possibly using useful set macro-actions).One may wonder picture different PbP.s/q compared basicincorporated planners using (possibly empty) set macros. Figure 5 shows resultscomparison, using CPU-time limit run ranging 1 1000 seconds.sake readability, names 38 combinations basic incorporated plannerssets macros (learned Wizard Macro-FF) omitted. time/qualityscores compared system derived summing corresponding scores obtained compared system IPC7 domain. domain combinationplanner P macro set empty, domain combinationrestricted P .results Figure 5 show that, terms CPU time, IPC7 domainsbasic planner PbP that, using learned macro set, achieves overall performancebetter similar performance PbP.s (except low CPU-time limits,compared planners macros perform similarly). terms plan quality,CPU-time limits lower 20 seconds, exist basic incorporated planners usingmacros perform better PbP.q; high CPU-time limits, PbP.q performs muchbetter every compared planner macros. combinations basic incorporated675fiGerevini, Saetti, & VallatiIPC7 domainsTime score240PbP.splanner set macros200IPC7 domainsQuality score240PbP.qplanner set macros200160160120120808040400011010010001101001000Figure 5: Time (left plot) quality (right plot) scores PbP.s/q relative computed configuration knowledge compared time quality scores 38combinations incorporated planners sets macros IPC7 domains.planners sets macros low CPU-time limits perform better PbP.qSGPlan5 using set learned macros, ParLPG using macro set bunching, YAHSPusing macro set clumping. low CPU-time limits, combinations plannersmacros overall performance better PbP.q, essentially dominatesingle domain: Barman SGPlan5, Blocksworld ParLPG YAHSP.Since analysis Figure 4 considered test domains altogether, order verifysupposition also given single domain PbP performs better worseevery basic incorporated planner, compared PbP.s/q best-performing basicplanner (according test problems relative IPC scores) considereddomain. planner, indicated BestP.s/q, single planner (without macros)would use oracle specifying best basic incorporated plannertest problems specific domain. results experiment shown Table 13.domains Gripper, Rovers, Satellite Spanner planner cluster PbP.sBestP.s. considered domains, time score averageCPU time PbP.s much better BestP.s. terms problem coverage, threedomains PbP.s solves much higher number problems; domainsproblem coverage BestP.s. results show that, order achievehigher planning speed, using cluster planners useful set macro-actions selectedPbP.s much better using single planner without macros. Sections 4.6.24.7 study usefulness using properly selected cluster plannersnon-empty set macros, respectively.Experimental result 4.6.2 IPC7 domain basic plannerconsidered input portfolio PbP.s faster, achieves better time score, solvesproblems PbP.s.Concerning plan quality, BestP.q contributes great deal success PbP.q, sincedomains except Barman Spanner included cluster selected PbP.q(see Table 2). Barman, Gripper, Parking, Rovers, Satellite, Spanner, TPP,cases BestP.q provides solution PbP.q.676fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7DomainsBestP.sBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPSGPlan5ParLPGParLPGParLPGFFParLPGParLPGParLPGParLPGdomainsIPC7DomainsBestP.qBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPSGPlan5ParLPGParLPGParLPGFFParLPGParLPGParLPGLAMAdomainsMaxscore303030303030303030270Time scorePbP.sBestP.s30.012.030.017.323.618.330.030.06.83.027.027.030.030.030.030.024.411.2232.8178.8Mean CPU timePbP.sBestP.s2.072.99.995.3109.5229.718.218.2364.1460.925.125.128.328.316.916.9121.2531.439.979.3# solved problemsPbP.sBestP.s3030303026213030872727303030302514236219Maxscore303030303030303030270Quality scorePbP.qBestP.q30.029.829.929.924.510.429.029.94.86.830.030.029.629.830.030.014.614.7222.4210.8Mean plan lengthPbP.qBestP.q449.3452.9269.9272.8160.1163.1577.3570.179.080.6694.7694.7785.2782.8326.0326.0370.1366.3472.6481.8# solved problemsPbP.qBestP.q3030303026113030573030303030301515226213Table 13: Maximum score, time/quality score, average CPU time/plan length, numberproblems solved PbP.s/q best planner (BestP.s/q) IPC7domains.Experimental result 4.6.3 IPC7 domains, terms plan quality, relativeperformance PbP.q best-performing basic planner (BestP.q) oracle wouldchoose generally slightly favor PbP.q: Blocksworld Depots PbP.q performsbetter, Parking BestP.q performs slightly better, rest IPC7 domainsperform similarly.Concerning Parking, Table 13 shows that, used benchmark problems,BestP.q-planner FF, correctly contained cluster selected PbP.qdomain (see Table 2). However, cluster also includes additional planner (LAMA)that, tested problems considered CPU-time limit, give usefulcontribution PbP.q (no solution found LAMA), introducing noisecluster selection. fact Parking useful set macros computedPbP.q main reasons PbP.q performs slightly worse BestP.q-plannersconsidered test problems domain Parking.Wilcoxon sign-rank test applied experiment confirms that, overall, PbP.ssignificantly faster BestP.s-planner domain (z = 3.134, p 0.001);terms plan quality, test results indicate performances PbP.q677fiGerevini, Saetti, & VallatiBestP.q-planner significantly different (z = 1.157, p = 0.247); words,test cannot derive one system performs statistically better other.Finally, compared PbP.s/q best-performing combination P +basic planner P non-empty set macros learned P IPC7 domain,except Spanner macro computed. experiment, best macro setP domain chosen considering performance P + trainingproblems D. Overall, terms speed score problem coverage, PbP.s performssimilarly P + five domains, performs much better three domains;terms quality score, PbP.q performs similarly four domains much betterfour domains. One reasons P + perform worse PbP.s/qdomains macros harmful, PbP.s/q correctly decides use them.discussed also context experiment presented Section 4.7,analyze usefulness macros accuracy selection PbP.s/q.4.6.2 PbP Best-Performing Portfolio Configurationorder test accuracy planner cluster selection PbP.s/q, alsocompared PbP computed configuration knowledge best-performing clusterplanners (with useful macros) considered test domain. (The worst-performingcluster solves problem.) Table 14 shows results experiment considering twobest-performing clusters three planners: considered IPC7 domain,BestC.s planner cluster highest time score among obtainedPbP.s using default PCPV; similarly, BestC.q planner cluster highestquality score. Therefore data time/quality score columns BestC.s/qmaximum values time/quality score sums planner clusters set testproblems IPC7 domain.every domain except Depots, time score PbP.s onebest cluster much greater zero (and thus much better scoreworst cluster). Also terms average CPU time problem coverage performancePbP.s best cluster almost always same. domain Depots PbP.sBestC.s perform slightly differently; case, planners relative macroscluster PbP.s different BestC.s. particular, Macro-FF selecteddifferent set macros, makes PbP.s slightly slower.Concerning PbP.q, overall, terms plan quality high performance gaprespect best cluster, although PbP.q performs worse domain TPP.domain, training problems used PbP.q informative enough. observationsupported fact best cluster computed using training problems, insteadtest problems, different one derived test problems.hand, observed that, size training problems similar size testproblems, configured portfolios PbP.q BestC.q same.Wilcoxon sign-rank test confirms that, overall, performance PbP.s/qbest cluster statistically significantly different (z = 0.422, p = 0.673, speedanalysis; z = 2.432, p = 0.015, quality analysis). Moreover, also observedPbP.s/q without configuration (PbP-nok.s/q) performs generally much worse678fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsIPC7DomainsBestC.sSGPlan5 (B)ParLPG (B)Macro-FF (M1)ParLPG ()Macro-FF (M2)ParLPG ()ParLPG ()ParLPG ()Macro-FF (M1)BestC.qBarmanSGPlan5 (Cl)BlocksworldParLPG ()DepotsMFF(M1),MFF(M2)GripperParLPG ()ParkingFF (0)RoversParLPG ()SatelliteParLPG ()SpannerLPG ()TPPMacro-FF (M1)domains-Maxscore303030303030303030270Time scorePbP.s BestC.s30.030.030.030.021.224.530.030.08.08.027.027.030.030.030.030.025.025.0231.2234.5Mean CPU timePbP.sBestC.s2.02.09.99.9165.982.518.218.2364.1364.125.125.128.328.316.916.9121.2121.247.436.7# solved probsPbP.s BestC.s3030303026283030882727303030302525236238Maxscore303030303030303030270Quality scorePbP.q BestC.q29.930.029.929.923.926.729.029.94.86.830.030.029.529.830.030.014.824.4221.8237.5Mean plan lengthPbP.qBestC.q449.3448.3269.9272.8160.1165.1577.3570.179.080.6694.7694.7785.2782.8326.0326.0370.1379.5461.2487.6# solved probsPbP.q BestC.q3030303026283030573030303030301525226240Table 14: Maximum score, time/quality score, average CPU time/plan length, numberproblems solved PbP.s/q best cluster (BestC.s/q) IPC7domains. MFF abbreviates Macro-FF. order planners listedcluster Depots corresponds order run.best cluster speed quality. Overall, experimental results derivefollowing observation.Experimental result 4.6.4 IPC7 benchmarks, terms time score, averageCPU time problem coverage, PbP.s performs well or, Depots, similarlyBestC.s. terms quality score, average plan length problem coverage, PbP.q performs well similarly BestC.q, except TPP, plan quality scoreproblem coverage PbP.q worse.Table 14 also shows often oracle would use single planner either quicklysolve IPC7 problems compute high-quality plans them. Hence, one may argueusing clusters formed one planner (possibly set useful macros)useful. rationale best clusters Table 14 formed single planneroften incorporated planner (even using macros) requires almost CPUtime solve IPC7 test problem (except domain Depots); thus remaining timeusually enough improve coverage quality (first) computed planrunning one planner. purpose computing high-quality plans,use set test problems smaller IPC7 problems, picture different.679fiGerevini, Saetti, & VallatiTable 15 compares performance PbP best performing cluster plannerssets randomly generated medium-size problems IPC7 domains (i.e.,size ranging largest training problems smallest testing problems).table, BestC.s/q indicates clusters oracle would use solve setsmedium-size problems.Experimental result 4.6.5 test problems IPC7 domains sizes rangingtraining problem sizes IPC7 test problem sizes, IPC7domains best planner clusters deriving high quality plans formedone planner.general, cluster planners containing certain planner performs worseplanner alone planning problems domain plannerportfolio configured efficiently solved planner alone, thus running alsoplanners cluster waste CPU time. cluster formed oneplanner performs better single portfolio planner considered domainplanner dominating others terms either problem coverage CPUtime, problem coverage plan quality.Interestingly, observed sometimes cluster selected PbP.q bestcluster intermediate-size test problems formed planner solvesproblems, produces low-quality plans, planners produce higher-qualityplans, solve problems. case Barman TPP. domains,although quality plans SGPlan5 low, SGPlan5 clusteruseful contributes greatly improve problem coverage cluster.Finally, results Table 15 also indicate sometimes effectivenessconfigured portfolio greatly affected difference size/hardnesstraining problems size/hardness test problems. particular, performancegap PbP.q best cluster considered randomly generated intermediatesize problems domain TPP lower PbP.q best cluster IPC7test problems TPP. indicates that, terms plan quality, effectivenessplanner portfolio configuration PbP.q computed using relatively small training problemsgradually decrease size/hardness test problems increased.4.7 Macro Usefulness Selection Accuracysection concerns experimental goal G6: analyze effectiveness using setmacros selected PbP planner, accuracy PbP selectinguseful set macros among computed Wizard Macro-FF plannerconfigured portfolio. shown Wizard Macro-FF often generateuseful sets macros speed planners (Botea et al., 2007b; Newton et al., 2007),also known guarantee using macros always leads improvingspeed planner, bad set macros could even make planner slower. Moreover,usually degree usefulness set macros depends specific planner usesthem.Concerning macros PbP.s, IPC7 domain least one non-empty setcomputed macros planner selected cluster (see Table 2), compared680fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7 domainsBestC.s(medium probs)BarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsIPC7 domains(B)ParLPG (B)MFF (M1), ParLPG (0)ParLPG ()MFF (M2)ParLPG ()ParLPG ()ParLPG ()Macro-FF (M1)BestC.q(medium probs)BarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomains(Cl), FF (), ()P (), MFF (M1), LPG (B)MFF (M1), P (), LPG ()ParLPG ()FF (), LAMA ()ParLPG ()ParLPG (), Marvin ()LPG ()MFF (M1), L (), (CH)Time scorePbP.s BestC.s30.030.030.030.028.929.730.030.022.022.030.030.030.030.030.030.030.030.0260.9261.7Mean CPU timePbP.sBestC.s1.51.57.37.357.452.513.213.2308.7308.717.617.614.314.313.613.693.693.650.950.4# solved probsPbP.s BestC.s303030303030303022223030303030303030262262Quality scorePbP.q BestC.q29.729.829.529.626.428.530.030.020.020.030.030.030.030.030.030.024.929.3221.8237.5Mean plan lengthPbP.qBestC.q327.2327.1174.7173.2143.1145.4472.3472.363.163.1694.7694.7524.6524.6257.2257.2219.4220.3462.6463.2# solved probsPbP.q BestC.q303030302830303020203030303030302530226240Table 15: Time/quality score, average CPU time/plan length, number problemssolved PbP.s/q best cluster (BestC.s/q) sets medium-sizeproblems IPC7 domains. S, M, MFF, P, L abbreviate SGPlan5, Marvin,Macro-FF, ParLPG, LAMA, respectively. order planners listedclusters corresponds order run.number solved problems, number visited search nodes, average CPU time timescore using: (a) macros, (b) set macros identified PbP.s useful planner,(c) set macros among computed planner terms time scoremakes perform best test problems. results experiment,given Table 16, following general observation derived.Experimental result 4.7.1 IPC7 domains, often candidate setmacros planner (computed Wizard Macro-FF) greatly increases speedperformance configured portfolio, PbP.s correctly selects it.Table 16 also indicates that, considered domains, performanceselected planners obtained using sets macros identified useful PbP.susually performance achieve using best sets macros.gives strong positive evidence effectiveness PbP.ss approach selectinguseful set macros planner configured portfolio. particular, bestset macros set macros selected PbP.s (see Table 2).exception sets macros identified PbP.s different best set681fiGerevini, Saetti, & VallatiDomain &PlannerBarmanSGPlan5BlocksworldParLPGDepotsMacro-FFParkingMacro-FFTPPMacro-FF#Smacros#NTS#SPbP.s macros#NTS#Sbest macros#NTS3072.912.0301.830.0301.830.030336195.317.330218.09.930.030218.09.930.002426780.02633654203.322.22821231105.126.221739406.90.68880.992.38.08880.992.38.0071594600.00.0252990121.225.0252990121.225.0Table 16: Number solved problems (#S), number visited search nodes (#N), averageCPU time (T) time score (TS) planners forming cluster selectedPbP.s using macro, set macros selected PbP.s, best performing set computed macros. domains considered IPC7 domainsleast one non-empty set computed macros. indicatenumber nodes visited SGPlan5 could measured.case Macro-FF domain Depots. However, shown Table 2, Depots PbP.sselects cluster contains Macro-FF macro set M2 ParLPG, obtainingoverall performance experimentally observed similar performanceMacro-FF best set macros, M1. worth noting candidate setsmacros computed ParLPG Depots harmful (i.e., make speed performancemuch worse) PbP.s correctly detects this, choosing run ParLPG zero macros(denoted ParLPG (0) Table 2).study computing using macros usually pursued main goalspeeding planning, possibly making quality computed plan lowermacros used. Interestingly, context PbP.q, several cases macros usefulalso improving plan quality. Specifically, nine fifteen IPC6-7 domains,configuration phase PbP.q selects clusters planners least one planner usingnon-empty set macros (see Table 2). experimentally observed, trainingproblems test problems, two reasons macros useful PbP.q:domains individual planners using macros leads betterquality plans. case, e.g., domains Barman Blocksworld using planners SGPlan5 LPG (first solution), respectively. behavior observedalso Botea et al. (2005), Coles Smith (2007), Newton et al. (2007).selected cluster includes planner configured use set macros, usuallyplanner quickly computes solution. somewhat helpful alsotest problems another planner cluster solve better solutions,enough CPU time, quick termination planner macrosleaves CPU time run cluster planner(s). CPU time,important especially incremental planner(s) included selected682fiPlanning Automatic Portfolio Configuration: PbP Approachcluster, like LAMA ParLPG. many problem instances domains Depots,Satellite TPP observed behavior.Experimental result 4.7.2 IPC7 domains, use macros selectedPbP.q lead better quality solutions.general, use macros make plan search effective because, e.g.,planning multiple actions one search step size possible plateausdepth local minima reduced. hand, large number macrosadded domain, size search space drastically increase, makingproblem harder solve. rest section, analyze kind numbermacros selected used PbP. consider macro operators, i.e., parameterizedmacros defined sequences (primitive) domain operators, macro actions, i.e., macrosderived instantiating parameters macro operators.Table 17 describes macro operators sets selected PbP.s plannerconfigured portfolio (see Table 2) terms of: number aggregated operators,number involved parameters, average numbers macro-actions primitive actionsaugmented domain, average plan lengths obtained considered planners withoutusing macros, using counting planned macro actions single action.data Table 17, derive interesting observations macrosused PbP considered domains. First, macro operators used PbPplanner three, often aggregate primitive operators. Secondly,planners handle macros simply adding instantiated macro operatorsdomain definition (SGPlan5 ParLPG), average number macro actionsaugmented domains much lower comparable number primitive domainactions, even domain Barman SGPlan5 uses large macro operators involvingseven primitive operators six parameters. Hence, planners domains,macro actions drastically increase search space. picture quite differentMacro-FF, macro operators selected PbP.s domains Depots, ParkingTPP, instantiated, generate number macro actions average oneorders magnitude greater number primitive domain actions. reasonMacro-FF successfully use macro operators even number domain macro actionshuge planner instantiates macro operators filters macro actions searchtime, according relaxed-plan heuristic applied current search state, rathersimply adding macro actions original domain planning.fact experiment PbP never generates configured portfolios largesets macro actions added domain description seems indicate that, numbermacro actions high w.r.t. number primitive actions, macro exploitationmethod usually makes performance planner using much worse. observation confirmed additional experiment added PDDL descriptionmacro operators learned Macro-FF domain Depots original descriptionDepots, run Macro-FF using resulting augmented domain. shown Table 17,Depots number learned macro actions one order magnitude greaternumber primitive actions. experimentally observed augmenteddomain Macro-FF (without method using macros) solves Depots problem.683fiGerevini, Saetti, & VallatiDomain &PlannerBarmanSGPlan5+BBlocksworldParLPG+BDepotsMacro-FF+M2ParkingMacro-FF+M2TPPMacro-FF+M1#operatorsevery m.7,4#parametersevery m.6,42,3,22,2,22,25,65,28,569#groundedmacros1645(397)17757(5812)224053(114600)billions(billions)billions(billions)#actions15610(3767)11983(5270)16005(8269)243223(151979)133145(78545)Plan lengthwithout m.452(57)415(107)143(23)Plan lengthm.374(45)153(42)119(26)64(11)238(51)Table 17: Number (primitive) operators forming selected macro operators,number parameters macro operator, average number instantiatedmacro actions, average number domain (primitive) actions, average plan lengthwithout using macros, average plan length using macros countingplanned macro action single action. number 2nd 3rd columnsrefers different macro operator. Numbers brackets standard deviations. domains considered IPC7 domains least one non-emptyset learned macros selected PbP.s. B abbreviates Bunching macroset learned Wizard; M1M2 two five sets macros generatedMacro-FF. indicate solution found within givenCPU-time limit.Moreover, results average plan length Table 17, show plansmacro actions much shorter computed original domain, countmacro single action. Given planning application currentsearch state macro (or possibly combination macros Macro-FF) generates singlesuccessor state, considered planners domains, average distanceinitial search state goal state much shorter search space includesmacros, hence searching solution plan space much faster.conclude, note usefulness macros also depend factors differentconsidered analysis, as, e.g., ratio number useful instantiations macro operator (providing shortcuts towards goal state)number instantiations guides search towards wrong direction (Botea, Muller,& Schaeffer, 2007a). factors might affect usefulness macro-operatorsplanning conjectured work McCluskey Porteous (1997).4.8 Planner Cluster Schedulingsection concerns experimental goal G7: experimentally analyze possible alternative strategies scheduling execution planners portfolio configuration PbP planning time. first experiment, investigate usePbP four sequential round-robin strategies predefined configured planningtime slots. second experiment, study importance choosing specific PCPV684fiPlanning Automatic Portfolio Configuration: PbP Approachdefining planning time slots (as described Section 3.1) particular PbPsdefault PCPV.Let input CPU-time limit, k maximum number planners cluster,n number single planners, combined set macros, portfolio (inexperiment, = 900 seconds, k = 3, 9 n 38 depending numbercomputed macro sets). experimentally compare performance PbP usingfollowing strategies planner cluster execution portfolio configuration:11S1. Sequential execution tuple k planners Tk seconds runPevery planner; number candidate configured portfolios ki=1 i! ni .next (S2) strategies, planner terminates end timeslot, remaining time slot used (uniformly) increase slotssubsequently running planners.S2. every combination time slots t1...k ti {0, 90, 180, 270, 360, 450,540, 630, 720, 810, 900}, {1 k} t1 + + tk = , sequential executiontuple k planners ti seconds runPi-thplanner sequence;number candidate configured portfolios ki=1 ni O(ui1 ), unumber non-zero planning time slots lower 900 (in experiment u = 9).R1. Round-robin execution set k planners planning time slotsderived default PCPV defined Section 3.1 (this isPPbPs defaultschedulingstrategy); number candidate configured portfolios ki=1 ni .R2. every PCPV p = hp1 , ..., p9 set P (defined below), round-robin executionset k planners planningtime uslots derived p;Pknnumber candidate configured portfolios i=1 O(s ), numberincrements considered pi (in experiment = 4).Set P R2 formed 100,000 PCPVs obtained setting percentagePCPV value ranging li ui , with: l1 , ..., l9 equal 10, 15, 20, 25, 30, 35,40, 45, 50; u1 , ..., u9 equal 70, 75, 80, 85, 90, 95, 98, 99, 100; increment step piequal ui 4li . instance, = 1, increment step p1 7010= 15.4Consequently, values used first percentage p1 considered PCPVs 10,25, 40, 55, 70.Concerning execution order planners cluster, considered sequencestrategies S1 S2, order defined planner order sequence (twosequences formed planners considered different clusters plannersdifferently ordered use different time slots); cluster planners strategiesR1 R2, execution order determined according increasing planning time slotsassociated planners cluster (this default execution order strategy).configuration phase PbP using four scheduling strategies generates fouralternative clusters planners, relative planning time slots, which, planning time,run corresponding scheduling strategies used configurationtime. noted portfolio configuration using strategies S2 R211. planners candidate cluster executed simulation, described Section 3.2.685fiGerevini, Saetti, & Vallaticomputationally much heavier configuration using S1 R1, respectively, sincemany candidate configured portfolios considered. hand, since PbPS2 R2 examines larger portfolio configuration spaces, principle, could obtainaccurate configured portfolios.Tables 18 19 compare performance PbP configured using S1-S2 R1-R2solving IPC7 domains problems. observed that, terms speed,IPC7 benchmark domains except Depots, considered scheduling strategiesaffect selection best cluster, since PbP.s always selects cluster formedsingle planner (possibly using macros). Depots, shown Tables 18 19, PbP.sround-robin scheduling strategies solves problems fastersequential scheduling strategies.Concerning plan quality, best cluster selected PbP.q contains oneplanner every IPC7 domain. Overall, following observation derived:Experimental result 4.8.1 IPC7 benchmark domains problems, PbP.qR1-R2 solves problems PbP.q S1-S2 and, terms plan quality, overallperforms similarly PbP.q S1-S2.think explanation PbP.q R1-R2 performs better terms number solved problems using round-robin strategy makes PbP.q robustusing sequential strategy respect possible incorrect ordering planner runsinadequate values planning time slots decided configuration time.training problems difficult used testing time (usually easier),inaccurate estimation effectiveness learned configuration knowledgearise. estimation time slot values incorrect planner executionorder damage severely sequential execution planners selectedcluster, since planners run once, using estimated time slot,round-robin execution iteratively run (multiple) timeslots, total CPU-time limit reached planners terminate.terms plan quality evaluated IPC quality scores, PbP.q R1-R2tends perform better PbP.q S1-S2. main reason PbP.q R1R2 solves problems PbP.q S1-S2, quality score unsolvedproblem zero. consider average plan quality (last four columns Tables 1819), observe mixed results: two domains PbP.q R1-R2 performs best,two worse, ones same. discrepancy evaluation resultsusing quality scores average plan qualities apparent, since quality scoreaverage quality evaluations different assumptions way considerunsolved problems. average plan quality, subset test problems solvedPbP using compared strategies considered; quality score, testproblems considered.Seipp et al. (2012) show sequential portfolio 21 domain-independent statebased forward planners solve problems planning time slots uniform,rather configured set training problems, because, considered plannerstest problems, planner either quickly solves problem solve all.context, observed sequentially run n planners PbP.q (i.e.,38 combinations 9 basic planners with/without computed sets macros)686fiPlanning Automatic Portfolio Configuration: PbP ApproachIPC7DomainsDepotsS120.8Time Score PbP.sS2R1R217.822.221.0Problems Solved PbP.sS1S2R1R226202726IPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsQuality Score PbP.qS1S2R1R230.030.030.030.016.716.730.030.06.16.124.425.229.929.928.928.93.74.64.34.329.029.025.225.229.821.029.529.730.030.030.030.013.713.714.712.8188.9 181.0 217.0 216.1Problems Solved PbP.qS1S2R1R2303030302121303088252730303030455529293030302130303030303014141513196188225225Table 18: Time/quality score number solved problems PbP.s/q using schedulingstrategies S1-S2 R1-R2 IPC7 benchmark domains problems.using uniform time slots, 137 test problems solved (against 225 solvedPbP); n-planners uniform strategy performs well PbP.q CPU-timelimit increased several times (keeping 900 seconds PbP.q). Differentlyobserved work Seipp et al. (2012), experimental evaluation includes manyproblems n planners PbP.q solve using considerable CPU time (e.g., numberproblems solved planner incorporated PbP, even using macros,within 10 seconds 80). Probably reason different behavior testproblems IPC7 learning track average difficult problemsIPC7 deterministic track, test problems used work Seipp et al.(2012).hand, PbP sequentially runs 3 planners, strategies S1S2, instead 38 possible combinations incorporated plannerslearned macros, obtain behavior similar observed Seipp et al. (2012).particular, results Tables 18 19 show terms number solved problemsspeed, configuring planning time slots sequential scheduling caseseven degrade performance PbP w.r.t. using uniform distribution CPU time(see results Tables 18 19 PbP.s using S1 S2 Depots PbP.q usingS1 S2 Satellite). However, context uniform distribution CPU timeplanners cluster selected PbP best one, since experimentallyobserved PbP S2 clearly outperforms PbP S1 configuration doneusing test problems rather training problems. believe main reasonbehavior experiment training problems much smallereasier test problems, several cases makes PbP S2 (configuredtraining problems) underestimate CPU times required solve test problems.687fiGerevini, Saetti, & VallatiIPC7DomainsDepotsAverage CPU Time PbP.sS1S2R1R2256.2 360.8 185.2185.0Std. Dev. CPU Time PbP.sS1S2R1R2122.3250.4206.178.2IPC7DomainsBarmanBlocksworldDepotsGripperParkingRoversSatelliteSpannerTPPdomainsAverage Plan QualityS1S2R1449.3 449.3 449.3310.3 310.3 236.7220.0 220.0 154.3570.1 570.1 588.784.083.382.0583.9 583.9 703.4747.8 747.8 751.6326.0 326.0 326.0364.0 364.0 362.6466.8 466.8 477.8Std. Dev. planS1S255.355.389.189.1118.2118.245.245.211.827.4158.2158.2161.3128.552.152.1101.4101.4217.9188.9PbP.qR2449.3236.7159.5588.782.0703.4751.6326.0362.6477.6quality PbP.qR1R255.355.368.668.632.532.838.038.024.824.8194.9194.9183.8183.852.152.199.199.1238.4238.8Table 19: Average standard deviation CPU time/plan quality PbP.s/q usingscheduling strategies S1-S2 R1-R2 IPC7 benchmark domainsproblems.Contrary PbP S1-S2, PbP R1-R2 performs similarly according threeevaluation criteria (solved problems, speed plan quality). result indicatesconfiguring planning time slots considering many alternative PCPVs leadhigh improvements respect using default predefined planning time slots,PbP configuring values planning time slots less crucial usinground-robin strategy using sequential strategy, PbP R1-R2less sensitive different size problems used configuration testing.Experimental result 4.8.2 IPC7 benchmark domains problems, PbP.s/qR1-R2 less sensitive definition planning time slots PbP.s/qS1-S2.rest section, study problem configuring PCPV used defineplanning time slots round-robin planner scheduling PbP. particular,address following questions focusing IPC7 benchmarks: important settingPCPV particular value given domain? oracle specifying bestPCPV test problems specific domain, good would default PCPVrespect it?data used analysis obtained follows. PCPV p set Pdefined well scheduling strategy R2 previous experiment, PbP.s/qrun using cluster selected simulating round-robin scheduling planningtime slots derived p described Section 3.1. Thereby PbP.s/q configured100,000 times different predefined PCPVs and, consequently, different predefinedplanning time slots. resulting configured portfolios run (by simulation)test problems learning track IPC7.688fiPlanning Automatic Portfolio Configuration: PbP ApproachTime scoreQuality score303025252020151510105500BarmanBWDepots Grip. Parking RoversSat. Spanner TPPBarmanBWDepots Grip. Parking RoversSat. Spanner TPPFigure 6: Distribution time (left plot) quality (right plot) scores PbP.s/q using100,000 PCPVs IPC7 problems. BW, Grip. Sat. abbreviateBlocksworld, Gripper Satellite, respectively.Figure 6 analyzes time quality scores configured portfolios boxwhisker plots. plot, bottom whisker worst score; bottombox lower quartile score; band box median score; topbox upper quartile score; top whisker best score; finally, crossscore PbP.s/q domain using default predefined PCPV. following,PCPV corresponding configured portfolio obtaining best time quality scoredomain called best-performing PCPV domain. Since best performingPCPV derived observed performance test problems, consideredbest PCPV P oracle would give us. experimental data usedFigure 6, derive following observation.Experimental result 4.8.3 Different IPC7 domains different best-performing PCPVsPbP.IPC7 domain length whisker Figure 6 zero, clusterselected PbP.s/q PCPV formed single planner, hencecases definition PCPV used derive planning time slots affectperformance PbP (all available CPU time assigned single selected planner).plot speed happens domains except Depots, plotplan quality, happens domain Spanner. domain Barman, clusters selectedPbP.q using configured PCPVs include SGPlan5 learned set macros,planner cluster finding solutions test problems domain.domains PbP.s/q always select singleton plannercluster PCPVs considered, specific used PCPV high impactPbPs performance, shown especially domains Depots, Gripper Satellitequality-score plot Figure 6. Interestingly, observe default predefinedPCPV used PbP.s/q generally good choice, since often crosses plotsappear (or near to) top position corresponding whiskers.689fiGerevini, Saetti, & VallatiExperimental result 4.8.4 every IPC7 domain, cluster selected PbP.s/q usingdefault PCPV h25, 50, 75, 80, 85, 90, 95, 97, 99i performs similarly PbP.s/q usingbest-performing PCPV, except PbP.q domains Parking TPP.Parking, best performance obtained running planners FF LAMAPCPV equal h10, 15, 60, 65, 70, 75, 80, 95.5, 96.5i; TPP, obtained running planners LAMA, Macro-FF SGPlan5 PCPV equal h10, 15, 20, 25, 30, 35, 40, 45, 50i.two domains, PbP.q default PCPV perform wellbest-performing PCPV (but still better median-performing PCPV). mainreason domains IPC7 test problems much larger (and harder)used training, which, also observed Section 4.6, affect accuracyportfolio configuration test problems terms selected planner clusterconfigured PCPVs.Overall, results experiment configured default PCPVs PbPindicate that, round-robin planner scheduling used, tuning PCPV (and consequently planning time slots) specific IPC7 domain greatly improveperformance resulting configured portfolio, since often default PCPV performs well best PCPV specified oracle. Consequently, given withoutPCPV tuning portfolio configuration much simpler faster, PbP uses defaultversion.5. Conclusionsexisting automated-planning technology offers large, growing set powerful techniques efficient domain-independent planners, none outperformsothers every planning domain. practical perspective, useful considerportfolio-based approach planning involves several techniques planners.paper, proposed approach automatically configuring portfolio planners learned macros given domain, implemented portfolio-basedplanner PbP. computed configuration knowledge consists promising combinationbasic planners portfolio, one (possibly empty) set useful macros,scheduling information specializing execution planning time.configured portfolio obtained automated statistical analysis performance set candidate clusters planners relative candidate sets macros, usingcollection training problems given domain. planner cluster performancecomputed simulating cluster execution using performance data runsindividual basic planners (and relative sets macros) portfolio.proposed approach portfolio planner configuration evaluatedlarge experimental analysis, focusing IPC6-7 domains, aim demonstrating high efficiency, understanding effectiveness automatic configuration,investigating importance main design choices. Several results derivedvarious experiments analysis. important experimental resultsindicate that:configured planner portfolios generated PbP.s/q perform well comparedstate-of-the-art planning systems using learning techniques, much better690fiPlanning Automatic Portfolio Configuration: PbP ApproachPbP-nok, i.e., unconfigured planner portfolio PbP (which competitiveLAMA, state-of-the-art domain independent planner);PbP.s/q performs much better existing domain-independent portfoliobased planners, often better domain-optimized planner portfolio approaches;computed configuration knowledge useful selection plannercluster forming configured portfolio generally accurate given planningdomain;macros planning domain always helpful planner improvingplanning speed plan quality, PbP.s/q generally selects helpful sets macros;context proposed approach, round-robin scheduling strategyplanner cluster execution robust strategy respect execution ordercluster planners planning time slots; moreover, configuring planningtime slots crucial given good default technique deriving currentlyimplemented PbP.s/q.Besides evaluating approach PbP configuring planner portfolio macros,experimental analysis corroborates validates results, observations empiricalstudies previous work researchers planning. include usefulnessharmfulness macros set prominent existing planners, importance diversityplanning techniques construction effective planner portfolio,robustness round-robin scheduling execution times multi-planner system.current version PbP uses portfolio formed specific set selectedtechniques plan synthesis, computation macros planner-parameter tuning,architecture PbP open sense additional alternative (current future)techniques integrated. Moreover, although chosen Wilcoxon sign-ranktest comparing candidate planner clusters macro sets, demonstrating effectiveness, methods could considered.limit current approach, affects also systems relying knowledgelearned examples, training problem set representativetest problems (e.g., problems much smaller easier test problems),computed portfolio configuration might accurate problems. Knowingconfiguration time enough information characterizing test problems obviouslyuseful generating representative training problem sets. planning PbP,experimentally observed that, minimum/maximum number objects involvedtest problems known, randomly generated training problem sets objectbounds sufficiently representative effective configuration PbP.think future work important study incorporate PbPadditional methods supporting problem-based configuration portfolio planner.methods could refine current domain-based configuration problemsdifferent size heuristically estimated hardness different, specialized configuredportfolios. Moreover, also important extend PbP.q plan qualitymeasured terms plan action costs rather number plan actions.directions research investigating use PbP.s/q optimalplanning metric-temporal domains (Fox & Long, 2003), extending portfolios691fiGerevini, Saetti, & Vallatiadditional automatically extracted domain-specific knowledge, entanglements(Vallati et al., 2013a). Finally, intend investigate idea making PbP fully domainindependent computing many portfolio configurations (planner clusters) differentknown domains, using classifier match new domain promisingstored configuration terms expected performance new domain. similar ideasuccessfully developed SAT (e.g., Xu et al., 2008).AcknowledgmentsMany ideas, techniques, systems investigated paper use build importantprevious work planning portfolio design, without research wouldpossible. thank authors work, particular authorsplanning systems macro generators incorporated PbP. special thank MarkRoberts Adele Howe clarifications configuration planner portfolio,Beniamino Galvani help implementation part preliminary versionPbP.s, IPC7 organizers letting us use competition machine oneexperiments conducted competition. would also like thankorganizers IPC6 IPC7 developed made available large collectionuseful benchmark domains, problems software tools used analysis.Finally, thank anonymous Reviewers Associate Editor helpfuldetailed comments.ReferencesArfaee, S., J., Zilles, S., & Holte, R., C. (2010). Bootstrap learning heuristic functions.Proceedings Third Annual Symposium Combinatorial Search (SOCS-10),pp. 5260. AAAI Press.Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. ComputationalIntelligence, 11 (4), 134.Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AIplanning automatically learned macro-operators. Journal Artificial Intelligence Research, 24, 581621.Botea, A., Muller, M., & Schaeffer, J. (2007a). Fast planning iterative macros.Proceedings Twentieth International Joint Conference Artificial IntelligenceIJCAI-07, pp. 18281833. AAAI Press.Botea, A., Muller, M., & Schaeffer, J. (2007b). Learning partial-order macros solutions.Proceedings Fifteenth International Conference Automated PlanningScheduling (ICAPS-05), pp. 231240. AAAI Press.Brendel, M., & Schoenauer, M. (2011). Instance-based parameter tuning evolutionary AI planning. Proceedings Thirteenth Annual Genetic EvolutionaryComputation Conference (GECCO-11), pp. 259260. ACM.Cenamor, I., de la Rosa, T., & Fernandez, F. (2013). Learning predictive models configure planning portfolios. Proceedings ICAPS-13 Workshop PlanningLearning.692fiPlanning Automatic Portfolio Configuration: PbP ApproachChen, Y., Hsu, C., & Wah, B. (2006). Temporal planning using subgoal partitioningresolution SGPlan. Journal Artificial Intelligence Research, 26, 323369.Chrpa, L., & Bartak, R. (2009). Reformulating planning problems eliminating unpromising actions. Proceedings Eighth Symposium Abstraction, Reformulation,Approximation, (SARA-09), pp. 5057. AAAI press.Chrpa, L., & McCluskey, T., L. (2012). exploiting structures classical planning problems: Generalizing entanglements. Proceedings Twentieth European Conference Artificial Intelligence (ECAI-12), pp. 240245. IOS Press.Chrpa, L., McCluskey, T., & Osborne, H. (2012). Reformulating planning problems:theoretical point view. Proceedings Twenty-Fifth International FloridaArtificial Intelligence Research Society Conference (FLAIRS-12), pp. 1419. AAAIPress.Coles, A., & Coles, A. (2011). LPRPG-P: Relaxed plan heuristics planning preferences. Proceedings Twenty-First International Conference AutomatedPlanning Scheduling (ICAPS-11), pp. 2633. AAAI Press.Coles, A., Coles, A., Olaya, A., Celorrio, S., Lopez, C., Sanner, S., & Yoon, S. (2012).survey seventh international planning competition. AI Magazine, 33 (1).Coles, A., & Smith, K., A. (2007). Marvin: heuristic search planner online macroaction learning. Journal Artificial Intelligence Research, 28, 119156.Cormen, T. H., Stein, C., Rivest, R. L., & Leiserson, C. E. (2001). Introduction Algorithms(3rd edition). McGraw-Hill.Fawcett, C., Helmert, M., Hoos, H., Karpas, E., Roger, G., & Seipp, J. (2011). FD-Autotune:Domain-specific configuration using Fast Downward. Proceedings ICAPS-11Workshop Planning Learning.Fawcett, C., Vallati, M., Hutter, F., Hoffmann, J., Hoos, H., H., & Leyton-Brown, K. (2014).Improved features runtime prediction domain-independent planners. Proceedings 24th International Conference Automated Planning Scheduling(ICAPS), pp. 355359. AAAI Press.Fern, A., Khardon, R., & Tadepalli, P. (2011). first learning track internationalplanning competition. Machine Learning, 84 (1), 81107.Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporalplanning domains. Journal Artificial Intelligence Research, 20, 61124.Gerevini, A., Haslum, P., Long, D., Saetti, A., & Dimopoulos, Y. (2009). Deterministicplanning fifth international planning competition: PDDL3 experimentalevaluation planners. Artificial Intelligence, 173 (5-6), 619668.Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local searchtemporal action graphs. Journal Artificial Intelligence Research, 20, 239290.Gerevini, A., Saetti, A., & Serina, I. (2006). approach temporal planning scheduling domains predictable exogenous events. Journal Artificial IntelligenceResearch, 25, 187231.693fiGerevini, Saetti, & VallatiGerevini, A., Saetti, A., & Vallati, M. (2009). automatically configurable portfolio-basedplanner macro-actions: PbP. Proceedings Nineteenth InternationalConference Automated Planning & Scheduling (ICAPS-09), pp. 350353. AAAIPress.Gibbons, J., & Chakraborti, S. (2003). Nonparametric Statistical Inference, Fourth Edition:Revised Expanded. Statistics: Series Textbooks Monographs. CRC Press.Gomes, C., P., & Selman, B. (2001). Algorithm portfolios. Artificial Intelligence, 126 (1-2),4362.Helmert, M. (2006). Fast Downward planning system. Journal Artificial IntelligenceResearch, 26, 191246.Helmert, M., Roger, G., & Karpas, E. (2011). Fast Downward Stone Soup: baselinebuilding planner portfolios. Proceedings ICAPS-11 Workshop PlanningLearning.Hoffmann, J. (2003). Metric-FF planning system: Translating ignoring delete listsnumeric state variables. Journal Artificial Intelligence Research, 20, 291341.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Howe, A., Dahlman, E., Hansen, C., vonMayrhauser, A., & Scheetz, M. (1999). Exploitingcompetitive planner performance. Proceedings Fifth European ConferencePlanning (ECP-99), pp. 6272. Springer.Howey, R., Long, D., & Fox, M. (2004). VAL: Automatic plan validation, continuous effectsmixed initiative planning using PDDL. Proceedings Sixteenth IEEEInternational Conference Tools Artificial Intelligence (ICTAI-04), pp. 294301. IEEE.Hutter, F., Hoos, H., H., & Stutzle, T. (2007). Automatic algorithm configuration basedlocal search. Proceedings Twenty-second National Conference ArtificialIntelligence (AAAI-07), pp. 11521157. AAAI Press.Hutter, F., Hoos, H. H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automaticalgorithm configuration framework. Journal Artificial Intelligence Research, 36,267306.Jimenez, S., C., Coles, A., & Coles, A. (2011). Seventh International Planning CompetitionIPC7 learning part. http://www.plg.inf.uc3m.es/ipc2011-learning.Kautz, H., A., & Selman, B. (1999). Unifying SAT-based graph-based planning.Proceedings Sixteenth International Joint Conferences Artificial Intelligence(IJCAI-99), pp. 318325. AAAI Press.Long, D., & Fox, M. (2003). third International Planning Competition: Resultsanalysis. Journal Artificial Intelligence Research, 20, 159.Marquardt, D., W., & Snee, D. (1975). Ridge regression practice. American Statistician, 29(1), 320.694fiPlanning Automatic Portfolio Configuration: PbP ApproachMatos, P., Planes, J., Letombe, F., & Marques-Silva, J. (2008). MAX-SAT algorithmportfolio. Proceedings Eighteenth European Conference Artificial Intelligence (ECAI-08), pp. 911912. IOS Press.McCluskey, T., L., & Porteous, J., M. (1997). Engineering compiling planning domainmodels promote validity efficiency. Artificial Intelligence, 95 (1), 165.Newton, M., Levine, J., Fox, M., & Long, D. (2007). Learning macro-actions arbitraryplanners domains. Proceedings Seventeenth International ConferenceAutomated Planning & Scheduling (ICAPS-07), pp. 256263. AAAI Press.Pulina, L., & Tacchella, A. (2007). multi-engine solver quantified boolean formulas.Proceedings Thirteenth International Conference Principles PracticeConstraint Programming (CP-07), pp. 574589. Springer.Rice, J. R. (1976). algorithm selection problem. Advances Computers, 15, 65118.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytimeplanning landmarks. Journal Artificial Intelligence Research, 39, 127177.Roberts, M., & Howe, A. (2006). Directing portfolio learning. ProceedingsAAAI 2006 Workshop Learning Search, pp. 129135.Roberts, M., & Howe, A. (2007). Learned models performance many planners.Proceedings ICAPS-07 Workshop AI Planning Learning.Roberts, M., & Howe, A. (2009). Learning planner performance. Artificial Intelligence,173 (5-6), 536561.Roberts, M., & Howe, A. (2012). Personal communication. December 14.Roberts, M., Howe, A., E., Wilson, B., & desJardins, M. (2008). makes plannerspredictable?. Proceedings Eighteenth International Conference AutomatedPlanning Scheduling (ICAPS-08), pp. 288295. AAAI Press.Seipp, J., Braun, M., Garimort, J., & Helmert, M. (2012). Learning portfolios automatically tuned planners. Proceedings Twenty-second International ConferenceAutomated Planning & Scheduling (ICAPS-12), pp. 368372. AAAI Press.Shaffer, J., P. (1995). Multiple hypothesis testing. Annual Review Psych, 46, 561584.Simon, H., & Kadane, J. (1975). Optimal problem-solving search: All-or-none solutions.Artificial Intelligence, 6, 235247.Vallati, M., Chrpa, L., & Kitchin, D. (2013a). automatic algorithm selection approachplanning. IEEE International Conference Tools Artificial Intelligence(ICTAI), pp. 18. IEEE.Vallati, M., Fawcett, C., Gerevini, A., Hoos, H., & Saetti, A. (2013b). Automatic generation efficient domain-optimized planners generic parametrized planners.Proceedings 6th Annual Symposium Combinatorial Search (SOCS-13), pp.184192. AAAI Press.Vidal, V. (2004). lookahead strategy heuristic search planning. ProceedingsFourteenth International Conference Automated Planning Scheduling (ICAPS04), pp. 150159. AAAI Press.695fiGerevini, Saetti, & VallatiWilcoxon, F., & Wilcox, R., A. (1964). Rapid Approximate Statistical Procedures.American Cyanamid Co., Pearl River, N.Y.Witten, I., H., & Frank, E. (2005). Data Mining: Practical machine learning toolstechniques. Morgan Kaufmann, San Francisco.Xu, L., Hutter, F., Hoos, H., H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-basedalgorithm selection SAT. Journal Artificial Intelligence Research, 32, 565606.Yoon, S., Fern, A., & Givan, R. (2008). Learning control knowledge forward searchplanning. Journal Machine Learning Research, 9, 683718.696fiJournal Artificial Intelligence Research 50 (2014) 141-187Submitted 9/13; published 5/14Enhanced Partial Expansion A*Meir GoldenbergAriel FelnerRoni SternGuni SharonMGOLDENBE @ GMAIL . COMFELNER @ BGU . AC . ILRONI . STERN @ GMAIL . COMGUNISHARON @ GMAIL . COMBen-Gurion University NegevBeer-Sheva, IsraelNathan SturtevantTURTEVANT @ CS . DU . EDUUniversity Denver,Denver, USARobert C. HolteJonathan SchaefferHOLTE @ CS . UALBERTA . CAJONATHAN @ CS . UALBERTA . CAUniversity AlbertaEdmonton, CanadaAbstractsolving instances problem domains feature large branching factor, A* maygenerate large number nodes whose cost greater cost optimal solution.designate nodes surplus. Generating surplus nodes adding OPEN list maydominate time memory search. recently introduced variant A* called PartialExpansion A* (PEA*) deals memory aspect problem. expanding node n,PEA* generates children puts OPEN children f = f (n). n reinserted OPEN list f -cost best discarded child. guarantees surplusnodes inserted OPEN.paper, present novel variant A* called Enhanced Partial Expansion A* (EPEA*)advances idea PEA* address time aspect. Given priori domain- heuristicspecific knowledge, EPEA* generates nodes f = f (n). Although EPEA*always applicable practical, study several variants EPEA*, make applicablelarge number domains heuristics. particular, ideas EPEA* applicableIDA* domains pattern databases traditionally used. Experimental studiesshow significant improvements run-time memory performance several standard benchmark applications. provide several theoretical studies facilitate understanding newalgorithm.1. IntroductionA* derivatives IDA* (Korf, 1985) RBFS (Korf, 1993) general state-basedsearch solvers guided cost function f (n) = g(n) + h(n). Given admissible (i.e. nonoverestimating) heuristic function h, A* guaranteed find optimal solution. paperYoshizumi, Miura, Ishida (2000), performance studies A* mostly concentratednumber nodes A* expanded.1 Furthermore, general result optimality A*1. Papers memory-bounded A* work Russell (1992) recent work Zhou Hansen(2002) form one notable exception statement. However, saving time heap operations reducing sizeOPEN list central focus papers.c2014AI Access Foundation. rights reserved.fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERrespect expanded nodes established (Dechter & Pearl, 1985). However, numberexpanded nodes clearly represent performance A* accurately enough. Rather,run-time performance A* determined net total many factors, numbergenerated nodes time updating data structures (the OPEN CLOSED lists).Motivated need view performance A* general context, focusnumber nodes A* expands number nodes A* generates.Let C cost optimal solution particular problem instance. A* expandnodes n f (n) < C guarantee optimality solution. nodes generatedwell. However, A* generates many nodes f (n) = C nodes f (n) > C well.call latter group nodes surplus (with f (n) > C ). Surplus nodes never expandedA* thus contribute finding optimal solution. Non-surplus nodes called useful.Many important problem domains feature large branching factor. solving problems, A* may generate large number surplus nodes. fact, execution time spentgenerating nodes may much larger time spent generating expandinguseful nodes. solving instances domains, number generated nodes centralperformance issue.first step address problem general manner taken Yoshizumi et al. (2000).introduced variant A* called Partial Expansion A* (PEA*), deals memoryaspect surplus nodes problem. Throughout paper, n denotes current nodeexpanded (unless different meaning explicitly specified), nc denotes child n.PEA* expands n, generates ns children adds OPEN children f (nc ) =f (n). guarantees surplus nodes inserted OPEN. rest childrendiscarded. n re-inserted OPEN f -cost best discarded child f (nc ) > f (n)(the one minimal f -value). node n expanded way several times, timedifferent f (n). Note PEA* addresses problem high memory consumptioncaused storing surplus nodes OPEN. time, PEA* incurs high price termsrun-time performance, since may generate children given node once.preface presentation contributions following observation. knowA* optimal respect number expanded nodes, give optimalityguarantees respect number generated nodes. reason optimality A*way consults heuristic decide node expand next (i.e. node minimalg(n) + h(n) among nodes OPEN). However, A* take h(n) considerationgenerates children n. A* could know, based h, nc surplus withoutactually generating nc , could avoid generating surplus nodes altogether.observation leads directly first important contribution paper: variant A* called Enhanced Partial Expansion A* (EPEA*) (Section 3). EPEA* generateschildren f (nc ) = f (n). contrast PEA*, children even generated.enabled using priori domain- heuristic-specific knowledge compute list operators lead children needed f -cost without actually generating children.knowledge algorithm using (also domain- heuristic-specific) form Operator Selection Function (OSF). given node expansion, OSF returns set childrenf (nc ) = f (n) smallest f -value among children f (nc ) > f (n).following example gives preview EPEA*. Consider four-connected grid-basedsingle-agent pathfinding domain (SAPF) Manhattan distance heuristic. OSF representsfollowing piece domain- heuristic-specific knowledge: goal North-West142fiE NHANCED PARTIAL E XPANSION A*NGW+0+0nE+2+2Figure 1: EPEA* uses domain heuristic-specific knowledge obtain set children ncnode n expanded f (nc ) = f (n).current location agent, moving North West result f -value,moving South East increase f -value two. example knowledge shownFigure 1. EPEA* expands node n first time, generates children nodesf (nc ) = f (n). OSF tells EPEA* nodes result applying operators NorthWest. Also, OSF determines cost n increased 2, corresponding costbest child generated. EPEA* keeps n new cost OPEN. nre-expanded, children n corresponding remaining operators (i.e. South East)generated.OSFs domain heuristic-dependent. minimum prerequisite applying EPEA*solve problem instances particular domain particular heuristic existencefull-checking OSF introduce Section 5 specific domain heuristic.paper organized follows. PEA* described Section 2. note PEA*described terms Collapsing Frontier Nodes (CFN) general techniqueused number well known algorithms. Section 3 presents EPEA*. Section 4 extendsideas IDA* resulting variant IDA* called Enhanced Partial Expansion IDA* (EPEIDA*).Sections 5-8 describe study experimentally different kinds OSFs. Sections 9 10presents analytical insights aspects EPEA*. Section 11 touches upon topic using PEA*EPEA* inconsistent heuristic exposes trade-off exists situation.paper introduces significant amount terminology. readers convenience,provided glossary terms Appendix A.preliminary version paper presented AAAI-2012 (Felner et al., 2012). current paper extends conference version deeper treatment EPEA* algorithm includingextended set experimental theoretical studies.2. Background KnowledgeEPEA* advances idea Partial Expansion A* (PEA*) (Yoshizumi et al., 2000). describePEA* general context technique called Collapsing Frontier Nodes (CFN).143fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERFigure 2: subtree rooted node n collapsed n, receives new stored valueF (n) = 8.2.1 Collapsing Frontier NodesDesignate set leaf nodes search tree frontier search. Best-first searchalgorithms choose frontier node lowest cost expansion. n expanded, nremoved frontier children added frontier. frontier maintainedeither memory (OPEN A*) logically (IDA*, RBFS). example, frontierIDA* given iteration nodes generated expandediteration (these nodes would stored OPEN A* used). either case, followingadmissibility invariant maintained: every node n frontier, cost n exceedcost possible solution passes n.Let n non-leaf node search tree R subset frontier, that, rR, path search tree root r passes n. is, n common ancestornodes R. Collapsing Frontier Nodes (CFN) technique relies observationpossible obtain smaller frontier replacing R n. Furthermore, cost nincreased, without violating admissibility invariant, minimum cost among nodes R.illustrated Figure 2 part frontier corresponding entire left subtree(i.e. R consists three nodes costs 9, 9 8) collapsed node n. cost nmodified minimum cost among collapsed leaves (8 case).collapse actions used many algorithms. SMA* (Russell, 1992), example, OPEN large, areas highest f -values OPEN collapsed. anotherexample, consider IDA*. IDA* iteration ends, seen collapsing entire frontier start node, gets f -value least cost frontier node thresholdnext iteration. (Ghosh, Mahanti, & Nau, 1994), IDA* allowed use given amountmemory. memory limit exceeded, collapsing used remove nodeslargest cost. Another important example RBFS. one branch tree plus childrennodes branch kept memory times. frontier nodes collapsed.use terminology coined Korf (1993). regular f = g + h value nodedesignated static value denoted f (n). f -value leaves propagatedcommon ancestor n collapse action called stored value n denotedF (n). static value n Figure 2 5, stored value collapse action 8.reach node n OPEN stored value F (n) = x x > f (n), known expanded least-cost frontier node static f -value x.144fiE NHANCED PARTIAL E XPANSION A*Figure 3: Example PEA* EPEA*. Two expansions node shown. Solid circlesdenote generated children, non-solid circles denote discarded/collapsedchildren.important note time set nodes collapsed n, stored value n may grow.stored value node never decreases.2.2 Partial Expansion A*Partial Expansion A* (PEA*) (Yoshizumi et al., 2000) variant A* reduces memoryoverhead A* putting surplus nodes OPEN. PEA* preserves admissibility usingcollapse actions. EPEA*, new variant A* introduced paper, works similarly PEA*.Therefore, clear grasp PEA* essential understanding EPEA*. following,(1) define PEA* (2) discuss performance overheads PEA* EPEA* addresses.simplicity, assume consistent heuristic.2 touch upon case inconsistentheuristic Section 11.PEA* maintains static stored value node. stored value obtainedcollapse actions describe below. PEA* expands nodes order least stored value.avoid putting surplus nodes OPEN, PEA* distinguishes two kinds nc :1. Provably useful, i.e. children f (nc ) F (n). Since n satisfies admissibilityinvariant, F (n) C . infer f (nc ) C , means nc useful.Thus, checking f (nc ) F (n) proves nc useful. words childrenf (nc ) F (n) provably useful sense A* cannot optimal without puttingnodes OPEN list. node provably useful necessary implyA* expand node.2. Possibly surplus, i.e. children f (nc ) > F (n). node nc might useful,cannot proven point search. Note possibly surplus nc becomeprovably useful n re-expanded higher stored value.2. heuristic h called consistent if, every node n child nc inequality h(n) h(nc ) + cost(n, nc )holds. Equivalently, heuristic h consistent results monotonically increasing f -values, i.e. every noden child nc , inequality f (nc ) f (n) holds.145fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERPEA* expands n, generates children n, inserts OPEN provablyuseful children f (nc ) = F (n). Since F (n) grow, provably useful childrenf (nc ) < F (n) known put OPEN previous expansions n. possiblysurplus children n collapsed n, re-inserted OPEN stored valueobtained collapse action. n possibly surplus children, re-insertedOPEN, moved CLOSED instead.refer provably useful children f (nc ) = F (n) currently needed. referchildren (i.e. possibly surplus children provably useful children f (nc ) <F (n)) currently unneeded. words, currently needed children n onesPEA* would insert OPEN current expansion n. designate operators resultcurrently needed children currently needed. operators designated currentlyunneeded.idea PEA* demonstrated Figure 3. top part, node expanded,children (x, y, z, w) generated. However, children f -value 3 (xy) currently needed. inserted OPEN. children possibly surplus.collapsed back a, gets new stored value F (a) = 4 (since f (z) = 4 leaststatic value among possibly surplus children a). Following this, re-inserted OPENF (a) = 4. two cases.re-expansion: Assume node g f (g) = 3 goal. case,expanded children costs larger 3 (z w) never putOPEN.Re-expansion a: chosen re-expansion F (a) = 4 (Figure 3 (bottom)),children generated. node z f (z) = 4 currently needed. placedOPEN. possibly surplus node w collapsed gets new stored valueF (a) = 5. currently unneeded nodes (x y) discarded. Since possiblysurplus children, put back OPEN.pseudo-code PEA* shown Procedure 1. clearly show differencesdifferent variants A*, show A*, PEA* EPEA* pseudo-code. makepseudo-code easier read, assign dummy stored value nodes A*, although A*really ever use it. PEA* generates new node, sets new nodes stored valueequal static value (lines 2, 18).3 Nodes expanded order best stored value(line 5). expanding n, PEA* generates children (line 7) inserts OPENchildren f (nc ) = F (n) (lines 11-18). nodes currently needed. childrenf (nc ) > F (n) possibly surplus. collapsed n, whose stored value becomeslowest static value among children (line 14). children f (nc ) < F (n) discarded(line 15). n possibly surplus children (i.e. children n inserted OPEN),n put CLOSED (line 20). Otherwise, n re-inserted OPEN new storedvalue (line 22).3. Although notion stored value defined context collapsing, view yet unexpanded nodefrontier node collapsed itself.146fiE NHANCED PARTIAL E XPANSION A*Procedure 1 A*, PEA* EPEA*.1: Generate start node ns2: Compute h(ns ) set F (ns ) f (ns ) h(ns )3: Put ns OPEN4: OPEN empty5:Get n lowest F (n) OPEN6:n goal exit// optimal solution found!7:A* PEA*: set N set children n initialize Fnext (n)8:EPEA*: set (N, Fnext (n)) OSF (n).9:nc N10:Compute h(nc ), set g(nc ) g(n) + cost(n, nc ) f (nc ) g(nc ) + h(nc )11:PEA*:12:f (nc ) 6= F (n)13:f (nc ) > F (n)14:Set Fnext (n) min(Fnext (n), f (nc ))15:Discard nc16:continue// next nc17:Check duplicates18:Set F (nc ) f (nc ) put nc OPEN19:Fnext (n) =20:Put n CLOSED// A*, always done21:else22:Set F (n) Fnext (n) re-insert n OPEN// Collapse23: exit// solution.2.3 Parameter C Comparison EPEA* PEA*PEA* saves memory putting surplus nodes OPEN, incurs large time performanceoverhead, since, whenever re-expands node n, generates children nodes ncomputes f -values, thus repeating work expanded n first time.domains children n assume large number different static values, run-timeoverhead large. make PEA* practicable domains, authors PEA* introducedC-parameter, determines trade-off amount memory saved runtime overhead paid. node n expanded, children F (n) f (nc ) F (n) + Cadded OPEN (the change made line 12 pseudo-code). C = 0 maximalmemory savings obtained. variant shown pseudo-code. C = , PEA*becomes equivalent A*. best choice C domain-, heuristic- instance-dependentpolicy selecting C reported.EPEA* memory-time trade-off. saves amount memoryPEA* C = 0, saving run-time well. Therefore, experiments, alwayscompare EPEA* PEA* C = 0.show Section 9 that, although PEA* motivated trying make OPEN smaller,sometimes exactly opposite effect.147fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER3. Enhanced Partial Expansion A*section presents new variant A*, Enhanced Partial Expansion A* (EPEA*). startimportant observation.3.1 Three Phases Way OPENOne key observations used EPEA* every node passes three phases inceptionentry OPEN:1. Discovering checking operator. search algorithm (a) discovers applicableoperator (b) checks whether operator applied. many commonly useddomains, list applicable operators (step (a) above) determined easily lookingcurrent state. planning domains, discovering operator consists checking operatorspreconditions. either case, A* PEA* generate children nodes correspondingapplicable operators. perform step (b) above. Checking operator refersdeciding whether apply available operator. now, step gone unnoticed.Distinguishing step key idea EPEA*.2. Applying operator. also refer phase generating node, since searchalgorithm generates child node applying operator node expanded.A*, generating node preceded making copy parent, IDA*needed.3. Inserting node OPEN. new node becomes part frontier nodes maintainedsearch algorithm.3.2 Operator Selection Function (OSF)difference EPEA* PEA* summarized follows. PEA* generateschildren nc n two objectives:1. put OPEN children f (nc ) = F (n)2. update stored value F (n).EPEA* achieves objectives without generating children. Instead, employs domainand heuristic-specific Operator Selection Function (OSF) generate children ncn f (nc ) = F (n) compute next F (n). section, describe OSF. nextsection, present EPEA* algorithm.OSF consists two components:1. Knowledge Component domain- heuristic-specific knowledge.2. Algorithmic Component algorithm uses knowledge component attainstated objectives OSF.example OSF, consider single-agent pathfinding domain (SAPF) Figure 4 (left).agent placed 4-connected grid (the shaded cell figure). agents arsenalactions consists 4 cardinal moves Wait move (where agent stands still). Assume148fiE NHANCED PARTIAL E XPANSION A*NGW33 4 55Ef (nc )012h(nc )-101OperatorsNorth, WestWaitSouth, EastFnext (n)12Figure 4: knowledge component OSF single-agent pathfinding Manhattandistance heuristic. part knowledge component case goal locatednorth-west current location shown.moves cost 1 heuristic function Manhattan distance (MD). figure, numbersinside cells corresponding h-values.Consider case goal located north-west current location. knowledge component OSF example shown Figure 4 (right) form table.table uses following convenient notation, continue use throughout paper.Consider expansion n operator produces child nc . denote changeheuristic value resulting applying operator h(nc ) = h(nc ) h(n) changef -value f (nc ) = f (nc ) f (n). current difference storedstatic value n denoted F (n) = F (n) f (n). next stored value n denotedFnext (n), F (n) corresponds stored value denoted Fnext (n).table groups operators according f (nc ) orders groups according increasingorder quantity. Note that, since quantities f (nc ) h(nc ) differ cost(n, nc ),constant domain, ordering operators either f (nc ) h(nc ) producesresult.EPEA* expands node n stored value F (n) needs generate childrennc f (nc ) = F (n), would invoke algorithmic component OSF to:1. Find row correspond f (nc ) = F (n) f (n),2. Generate currently needed children applying operators row,3. Return next stored value n: Fnext (n) = f (n) + Fnext (n).OSFs domain heuristic-dependent. Using EPEA* solve problem instances particular domain particular heuristic requires creation OSF specific domainheuristic. provide classification OSFs Section 5. particular, minimum prerequisite applying EPEA* existence full-checking OSF described sectiongiven domain heuristic. classification OSFs also serve general guideline OSFconstruction.OSF bears resemblance concept preferred operators, often used domainindependent planners FF (Hoffmann & Nebel, 2001) Fast Downward (Helmert, 2006;Richter & Helmert, 2009).4 Preferred operators subset actions assumedlikely lead goal. expanding node, FF generates nodes using4. FF, preferred operators called helpful actions.149fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERpreferred operators ignoring actions. often reduces search time costloss completeness. Fast Downward uses preferred operators conservative mannerpreserves completeness. Nodes generated preferred operators prioritizedexpanded often. done maintaining additional OPEN list containing nodesgenerated preferred operators. Fast Downward alternates expanding nodeadditional OPEN list regular OPEN list containing generated nodes.Preferred operators impose binary partition set operators: operator either preferred not. contrast, OSF provides finer grained operator partitioning, grouping operatorsaccording f values. Moreover, neither FF Fast Downward able completely avoidgenerating surplus nodes using preferred operators, EPEA* algorithm describedexactly using OSF.Note Fast Downward uses preferred operators conjunction another technique calleddeferred heuristic evaluation (Helmert, 2006; Richter & Helmert, 2009). Deferred heuristic evaluation saves heuristic computation time inserting generated nodes OPEN f -valueparent. heuristic node computed node reaches topOPEN list. Thus, deferred heuristic evaluation trades memory time spent OPEN listoperations saving heuristic computation time. One view deferred heuristic evaluationopposite collapse action (Section 2.1): collapse saves memory time neededOPEN list operations.ready describe EPEA* algorithm.3.3 Definition EPEA*flow EPEA* (Procedure 1) identical PEA*: (1) puts nodes OPENexpands order PEA* (2) collapses possibly surplus children nodes.Therefore, pseudo-code EPEA* similar PEA*. differences stemfact EPEA* uses domain- heuristic-specific Operator Selection Function (OSF):1. Instead generating children nodes discarding currently unneeded ones (PEA*,lines 7 15), EPEA* uses OSF generate currently needed children nodesstart (line 8).2. Instead looking children n compute next stored value (PEA*, line 14), EPEA*receives value OSF (line 8).already seen operation PEA* example Figure 3. Consider operationEPEA* example. Figure 3 (top), EPEA* uses OSF generatecurrently needed children x y. generate nodes z w, since possiblysurplus. OSF also determines next stored value (F (a) = 4) lowest cost amongnodes z w. Figure 3 (bottom), children x, z provably useful. However,z currently needed generated OSF, since costs x (3) lowerF (a) (4). important clearly see distinction PEA* EPEA*: nodesgenerated discarded PEA* nodes EPEA* generate.example concrete OSF, consider operation EPEA* SAPF exampleFigure 4 (left) OSF shown Figure 4 (right) described Section 3.2. Supposen (with agent shaded cell) expanded first time f (n) = F (n) = 10. EPEA*uses OSF get children f (nc ) = F (n) = 10. is, interested children150fiE NHANCED PARTIAL E XPANSION A*f (nc ) = 0. OSF uses information Figure 4 (right) produce childrencorrespond operators North West. children f (nc ) > F (n) collapsed n,gets stored value determined f -value operator next row. case,next row contains operator Wait f = 1, next stored value n Fnext (n) =f (n) + 1 = 11. convenience, next value F (n), Fnext (n) = Fnext (n) f (n),shown rightmost column table.n re-expanded f (n) = 10 F (n) = 11, OSF returns nodes nc f (nc ) =F (n) = 11 or, equivalently, f (nc ) = 1. corresponds applying Wait operator.remaining children f (nc ) > F (n) collapsed n, get stored valuef (n) + Fnext (n) = 10 + 2 = 12.Note table Figure 4 (right) expanding n located South-Eastgoal. complete knowledge component OSF domain contains seven tablespossible locations n relative goal.3.4 High-Level Comparison A*, PEA* EPEA*section, compare A*, PEA* EPEA* respect memory run-timeperformance.3.4.1 EMORY P ERFORMANCEA* puts OPEN every node generates generatedlower cost. PEA* improves memory performance A* putting OPENcurrently unneeded nodes. actual memory saving determined parameter C (seeSection 2.2), greatest saving achieved setting C = 0. EPEA* puts OPENnodes PEA* C = 0. Therefore, EPEA* affords memory savingsmemory-effective variant PEA*.3.4.2 RUN -T IME P ERFORMANCEFirst, compare node performance three algorithms:A* known optimal respect number expanded nodes (Dechter & Pearl,1985). give guarantees respect number generated nodes.Consider first expansion node expanded PEA*. expansionsA* performs. Also, PEA* performs expansions order A*. Therefore,PEA* optimal respect number unique node expansions.5 However, PEA* mayre-expand node many times. re-expansion, PEA* generatesnodes children. Therefore, PEA* may perform many node generations A*.EPEA* expands nodes PEA* order. Therefore, like PEA*,EPEA* optimal respect number unique node expansions. Unlike PEA*,EPEA* generate currently unneeded nodes. Therefore, EPEA* may skip generating states A* would generate. fact, optimality results respect5. Although number unique node expansions practical interest, interesting means understanding algorithm performance. Therefore, measure number unique node expansionsexperiments.151fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERVariantnodes generatednodes put OPENA*PEA*EPEA*, full-checking OSFCurrently needed,obtained checking operatorsCurrently needed,obtained direct computationCurrently neededCurrently neededEPEA*, direct-computation OSFCurrently neededTable 1: High-level comparison A*, PEA* EPEA*.number generated nodes recently proven variants EPEA* (Goldenberg, Felner, Stutervant, Holte, & Schaeffer, 2013).consider run-time performance three algorithms:Depending domain heuristic, A* may spend much time generating surplusnodes. Also, A* may pay penalty related usage large amounts memory.particular, OPEN list operations become expensive size search frontiergrows.cases (see Section 9), PEA* uses smaller amount memory A*, paysoverhead possible re-expansions single node generating children nodere-expansion.Similar PEA*, EPEA* pay price many possible re-expansions single node.However, EPEA* avoids two run-time overheads PEA* suffers from: generatinguseful node many times generating possibly surplus nodes. significancesavings depends size states domain amount computationneeds performed apply operator.Depending kind OSF used (the different kinds OSFs consideredSection 5), EPEA* may able avoid generating currently unneeded nodes,also checking operators result nodes (i.e. currently unneeded operators). differences A*, PEA* EPEA* respect phases describedSection 3.1 summarized Table 1. study time performance EPEA*deeply Section 10.4. Enhanced Partial Expansion IDA* (EPEIDA*)begin noting IDA* viewed partial expansion built algorithm.Namely, consider current iterations threshold stored value nodes iteration. IDA* completes iteration, collapses frontier nodes current iterationroot node, gets updated stored value next iterations threshold. Supposecurrent iterations threshold . n expanded, children generated.next level depth-first search, children nc n f (nc ) expanded,children f (nc ) > discarded. partial expansion following one difference.152fiE NHANCED PARTIAL E XPANSION A*PEA*, currently needed children children f (nc ) = F (n). childrenf (nc ) < F (n) need put OPEN, since children put OPENprevious expansions n. IDA* store information previous iterationstherefore needs search children f (nc ) < well. Therefore, context IDA*,need re-define notion currently needed children n include children ncf (nc ) .describe EPEIDA*. clearly see distinctions IDA* EPEIDA*,variants shown pseudo-code (Procedure 2). first difference EPEIDA* usesOSF obtain list currently needed children (those f (nc ) ) lowestcost among currently unneeded children (line 10). latter cost used update thresholdTnext next iteration (line 11). threshold initialized infinity beginningcurrent iteration (not shown pseudo-code). contrast, IDA* generates children nupdates value threshold next iteration iterating list children(IDA*, lines 5, 8). second difference EPEIDA* need check thresholdcondition (IDA*, line 4). threshold condition equivalent conditiondefinition currently needed node IDA*. Since OSF generates currently neededchildren, additional check needed.number nodes EPEIDA* generates approximately b times smaller numbernodes generated IDA*, b average branching factor domain. verifythis, let X number nodes expanded last iteration IDA*. number nodesgenerated iteration approximated bX. hand, EPEIDA* generatesX + (b 1)d nodes (more details given Section 10.1), depth search.Since (b 1)d usually small compared X, ratio bX X + (b 1)dapproximately equal b. repeatedly point fact discussion experimentalresults Sections 6-7.experimental results compare performance EPEIDA* performanceIDA* several domains heuristics. studying results, importantmind IDA* viewed partial expansion built algorithm. Therefore,compare EPEIDA* IDA*, really comparing EPEIDA* iterative deepeningversion PEA*.5. Classification OSFsRecall high-level comparison A*, PEA* EPEA* Table 1. table, principledistinctions EPEA* PEA* shown: EPEA* applies currently needed operators generate currently needed children, PEA* generates children noden expanded. Furthermore, Table 1 shows two possibilities exist obtaining listcurrently needed operators. possibilities correspond two classes OSFs:1. full-checking OSF obtains list currently needed operators checking operators,including currently unneeded ones.2. direct-computation OSF obtains list currently needed operators means directcomputation.two kinds OSF focus section. addition two pure classes,encounter hybrid OSF. happen domains heuristics153fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERProcedure 2 IDA* EPEIDA*.Variables:current depth search treethreshold current iterationTnext threshold next iteration, set infinity calling DFS().1: DFS(n, i, )2:Compute h(n) set f (n) g(n) + h(n)3:IDA*:4:f (n) >5:Set Tnext = min(Tnext , f (n))6:return// Threshold cut-off7:n goal halt// optimal solution found!8:IDA*: Set N set children n9:EPEIDA*:10:Set N, f BestN otN eeded OSF (n)11:Set Tnext = min(Tnext , f BestN otN eeded)12:nc N13:Set g(nc ) g(n) + cost(n, nc )14:Call DF S(nc , + 1, )able construct direct-computation OSF generate currently needed nodes certainvalues f (nc ), values f (nc ). domains, constructhybrid OSF, behave either direct-computation full-checking OSF different(re-)expansions n depending required f (nc ).show (Sections 6-8) OSF constructed well known domains heuristics. now, explain two pure classes OSFs using SAPF domainrunning example.5.1 Full-Checking OSFsknowledge component full-checking OSF SAPF consists eight tables. tablecorresponds one eight possible positions n relative goal. algorithmic component OSF determines tables must used given n based positionn relative goal. example, table case n located South-East goal (e.g.shaded cell Figure 5 (left)) shown Figure 5 (right). on, use tableFigure 5 (right) running example.operator applicable n, table records resulting changes h- f -values.OSFs algorithmic component needs check operators decide childrennodes currently needed. generates children. Also, computes next storedvalue n, Fnext (n), follows. Fnext (n) initialized infinity. Whenever OSF checksoperator results nc determines nc possibly surplus (i.e. f (nc ) > F (n)), updatesFnext (n) Fnext (n) = min(Fnext (n), f (nc )).154fiE NHANCED PARTIAL E XPANSION A*NGW33 4 55EOperatorWaitEastSouthWestNorthh(nc )011-1-1f (nc )12200Figure 5: knowledge component full-checking OSF single-agent pathfindingManhattan distance heuristic. part knowledge component casegoal located north-west current location shown.5.2 Direct-Computation OSFsdirect-computation OSF computes list currently needed operators directly, withoutneed check applicable operators. case SAPF, knowledge componentdirect-computation OSF obtained described full-checking OSF orderingrows eight tables order increasing f (nc ) merging rows corresponding f (nc ). table Figure 5 (right), corresponding knowledgecomponent direct-computation OSF shown Figure 4 (right). Given required f (nc ),row currently needed operators found algorithmic component quicklywithout checking operators.6 EPEA* apply operators generate corresponding currently needed children nodes.general, direct-computation OSF constructed states domainclassified several classes, that, class C, one following holds:table operators applicable states C ordered f (nc ) computedstored main search begins. option used OSFSAPF. case, class corresponded one eight possible locations nrespect goal.set operators given f (nc ) computed on-the-fly search.option use Section 6.2 pancake puzzle GAP heuristic (Helmert, 2010).Even one conditions satisfied, may impossible impracticalconstruct direct-computation OSF given domain heuristic onefollowing reasons:1. construct tables operators ordered f (nc ), large number state classes mustdefined, resulting large time memory requirements pre-compute storetables.2. determine class given state belongs to, operators applicable state needchecked.6. domain large number f (nc )-values, binary search hashing mechanism used.155fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERreasons clarified Section 6.1, explain cannot constructdirect-computation OSF 15-Puzzle Manhattan distance heuristic.Note even case direct-computation OSF available given domainheuristic, still construct direct-computation OSF given search node. Namely,n expanded first time, compute table operators applicable n orderedf (nc ) store table together n OPEN. subsequent re-expansionsn, table used knowledge component direct-computation OSF. decisionwhether construct direct-computation OSF individual search nodes depends followingtime-memory trade-off:Using technique eliminates need check operators re-expansion n.amount saved execution time depends many times n re-expanded, turndepends many different f -values taken children n.Storing table applicable operators every node OPEN may prohibitively expensive (memory-wise) domains high average branching factor.6. Experimental Study Different Kinds OSFstwo following sections, construct OSF show experimental resultsseveral domains heuristics. start relatively simple OSFs section movetowards complicated PDBs-based OSFs Section 7. move yetcomplicated additive PDBs-based OSFs Section 8. description OSF immediatelyfollowed experimental study OSF.start EPEIDA* two domains heuristics:15-puzzle Manhattan distance heuristic. domain, constructfull-checking OSF explain constructing direct-computation OSF impractical.pancake puzzle GAP heuristic. domain, construct hybrid OSF.see that, practice, OSF behaves direct-computation OSF expansions.One easily come interesting domains heuristics, pure direct-computationOSF constructed. However, decided focus well known benchmark domains.able show direct-computation OSFs domains context OSFs basedpattern databases (Culberson & Schaeffer, 1998; Felner, Korf, & Hanan, 2004) Sections 7 8.76.1 Full-Checking OSF 15-puzzle15-puzzle consists 4 4 square frame containing 15 numbered square tiles, emptyposition called blank. legal operators slide tile horizontally verticallyadjacent blank blank position. problem rearrange tiles randominitial configuration, e.g. Figure 6 (left), configuration Figure 6 (middle). Manhattandistance (MD) classic heuristic function puzzle. computed counting7. saw direct-computation OSF SAPF. However, searches state space SAPF feature smallnumber surplus nodes, makes uninteresting application EPEA*.156fiE NHANCED PARTIAL E XPANSION A*615813394 147123456789 10 11212 10 15 11Operator13 moves East6 moves South3 moves West14 moves North12 13 14 15h(nc )1-111f (nc )2022Figure 6: Left: possible state 15-Puzzle. Middle: goal state 15-Puzzle. Right: partknowledge component OSF 15-Puzzle Manhattan distanceheuristic case set applicable operators state left.number grid units tile displaced goal position, summing valuestiles.6.1.1 OSF15-puzzle, quantity f (nc ) operator applicable n completely determined by:1. location blank,2. identity tile moved operator,3. position tile relative blank.Therefore, construct knowledge component full-checking OSF 15-puzzlethree-dimensional array dimensions 16 15 4. dimensions stand 16 possiblelocations blank, 15 possible identities tile moved 4 possible positionstile moved relative blank. element array f (nc ) correspondingoperator.Example. operators applicable node n Figure 6 (left), knowledge component OSF would store f (nc )-values shown Figure 6 (right). example,operator moves 13 blank position, f (nc )-value (2) stored element[6][13][0], 6 denotes position blank, 13 identity tile moved 0denotes operator moves tile West blank blank position.node n, algorithmic component OSF would (1) check operators Figure 6 (right)looking corresponding entries three-dimensional array (i.e. knowledge component),(2) generate currently needed nodes applying operators f (nc ) = F (n) f (n),(3) compute next stored value n using minimal f (nc ) among possibly surpluschildren: Fnext (n) = f (n) + f (nc ).construct direct-computation OSF domain, need classify states twostates s1 s2 class (1) location blank s1 s2(2) identities tiles surrounding blank positions relative blanks1 s2 . Therefore, need define 16(15141312) classes. Pre-computing storingtable operators classes computation memory overhead. Furthermore,decide class given state belongs to, OSF need look identities tiles157fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERGen NodesTime (ms)IDA*363,028,07917,537EPEIDA*184,336,70514,020Ratio1.971.25Table 2: Comparison generated nodes time performance IDA* EPEIDA* 15Puzzle.surrounding blanks, equivalent checking operators. conclude constructingdirect-computation OSF 15-puzzle domain MD heuristic impractical.provided experimental results obtained full-checking OSF.6.1.2 E XPERIMENTAL R ESULTSOptimal solutions random instances 15-puzzle first found Korf (1985) using IDA*MD heuristic. Korf graciously made code available public. code(known highly optimized), look-up table pre-computed give heuristic value basedcurrent location tile, operator chosen tile currently occupying proposednew location blank. Note information exactly knowledge componentfull-checking OSF described above. However, Korfs code exploit information avoidgenerating currently unneeded nodes. Instead, generates children nodes useslook-up tables heuristic calculation.Table 2 presents results running Korfs IDA* code EPEIDA* 100 randominstances. observe factor 1.97 reduction number generated nodes. numberclose asymptotic branching factor domain reverse moves eliminated,reported 2.13 (Edelkamp & Korf, 1998). reduction number generatednodes translates 1.25-fold improvement run-time, significant given well knownefficiency Korfs code. timing results obtained Dell Optiplex 760.6.2 Hybrid OSF Pancake Puzzlepancake puzzle (Dweighter, 1975) analogous waiter navigating busy restaurantstack N pancakes. waiter wants sort pancakes ordered size. onefree hand, available operation lift top portion stack reverse it. statepermutation values 1...N . state N 1 children, k th successor formedreversing order first k + 1 elements permutation (1 k < N ). example,N = 4 children state (1, 2, 3, 4) (2, 1, 3, 4), (3, 2, 1, 4) (4, 3, 2, 1). However,may safely consider two successors parent position complete reversepancakes (the latter ignored search nodes GAP heuristic describedused). Therefore, branching factor domain approximately equal numberpancakes minus two. Since states reachable start state, size state spaceN !. number heuristics based pattern databases used puzzle (Zahavi,Felner, Holte, & Schaeffer, 2008; Felner, Zahavi, Holte, Schaeffer, Sturtevant, & Zhang, 2011;Yang, Culberson, Holte, Zahavi, & Felner, 2008), GAP heuristic discussed Helmertsignificantly outperforms (Helmert, 2010).158fiE NHANCED PARTIAL E XPANSION A*6134572Figure 7: state Pancake Puzzle seven pancakes. operator affect gap onelocation only.describe GAP heuristic. Two integers b consecutive |a b| = 1.given state, gap location j occurs pancakes location j j + 1 consecutive.goal defined pancake 1 location 1 gaps. GAP heuristiciterates state counts number gaps. Since operator reduce numbergaps one, heuristic admissible.gather insight necessary construct OSF, consider example Figure 7.seven pancakes, pancake 6 occupying location 1. Consider operator reverses firstfive pancakes. note operator affect number gaps pancakesreversed (i.e. gaps locations 1-5 pancakes 6, 1, 3, 4, 5). Indeed,gaps adjacent extreme pancakes reversed (i.e. pancakes 6 5) affected.case, consecutive pancakes 6 7 become adjacent, gap pancakes 5 7ceases exist. Thus, looking three pancakes (in case, 5, 6, 7), knownumber gaps (and hence GAP heuristic) decreased one f (nc ) = 0.generally, operator reverses j pancakes affects gaps formed threepancakes locations 1 (pancake P ), j (pancake X), j + 1 (pancake ). Three casespossible:1. X consecutive P are. case, one gap removedheuristic value decreases one. corresponds f (nc ) = 0.2. pancakes X, pancakes P, form form gap. caseheuristic value change. corresponds f (nc ) = 1.3. pancakes X, form gap, pancakes P, do. case, new gapintroduced heuristic grows one. corresponds f (nc ) = 2.Suppose need generate children n f (nc ) = 0. note donewithout checking currently unneeded operators (i.e. operators f (nc ) > 0). this,classify states based identity pancake location 1. state shown Figure 7belongs class pancake 6 location 1. enable OSF compute operatorsf (nc ) = 0 class on-the-fly maintaining following additional informationnode main search. pancake, keep current location pancakesconsecutive (note two pancakes; example, pancakesconsecutive pancake 6 5 7 locations 5 6, respectively). Now, suppose npancake P location 1. Then, use information stored Plocate pancakes P 1 P + 1 check pancakes directly left pancakes.example, P + 1s left neighbor pancake P + 2, reversing pancakes159fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER#IDA*20304050607018,592241,9471,928,77113,671,07292,816,534754,845,658Generated NodesEPEIDA*TotalFull-checking OSF1,0428,65550,777284,8381,600,31511,101,0911225491311211,118ratioIDA*Time (ms)EPEIDA*ratio17.8427.9537.9847.9957.9967.991.524.92472,05816,268155,0370.11.28.5573592,82111.2320.0030.7536.1545.3254.90Table 3: Comparison generated nodes time performance IDA* EPEIDA*Pancake Puzzle.left P + 1 decrease GAP heuristic result f (nc ) = 0. Thus, constructdirect-computation OSF case f (nc ) = 0.cannot construct direct-computation OSF cases f (nc ), since checkoperators find operators resulting f (nc ) = 1 f (nc ) = 2. cases,full-checking OSF constructed. OSF knowledge component. algorithmiccomponent simply checks operators applicable n and, operator, computesresulting f (nc ) looking three affected pancakes described above. operatorcurrently needed, corresponding child node generated.experimental results 100 random instances 20 70 pancakes given Table 3.table, compare performance EPEIDA* IDA*, using GAP heuristic.70 pancakes, EPEIDA* generated (the column titled Total) 68 times fewer nodes IDA*.reflected running time (54-fold). best knowledge,state-of-the-art results puzzle. Note versions tested domain, reductionnumber generated nodes almost branching factor domain.better understand behavior hybrid OSF domain, compare numberstwo columns EPEIDA* generated nodes. column left shows total numbergenerated nodes, column right shows many nodes generated usingfull-checking OSF. comparison two columns reveals that, vast majorityexpansions, operators f (nc ) = 0 currently needed, whereby EPEIDA*applied direct-computation OSF.7. OSFs Based Pattern DatabasesPattern Databases (PDBs) (Culberson & Schaeffer, 1998; Felner et al., 2004) powerful methodautomatically building admissible memory-based heuristics based domain abstractions.short background section, explain PDB-based full-checking direct-computation OSFsconstructed provide experimental results Rubiks cube domain CornersPDB heuristic.7.1 BackgroundView state domain assignment values number domain variables (hereaftervariables). main idea PDBs abstract state space considering subset160fiE NHANCED PARTIAL E XPANSION A*variables. concrete choice variables, abstraction formalized abstractionmapping, denote immediately define. state original state,abstract state (or pattern) (s) projection onto variables participate (or,short, projection onto ).PDB given constructed performing full breadth-first search abstract statespace abstract goal, i.e. (g), g goal state. Distances abstract statescalculated stored lookup table (PDB). values used throughout searchadmissible heuristics states original state space. Formally, state s, PDBcontains distance abstract space (s) (g). heuristic value requiredn, one simply looks PDB[(n)].interesting variation PDBs instance-dependent pattern databases (IDPDBs) (Felner& Adler, 2005; Zhou & Hansen, 2004; Silver, 2005). IDPDBs built lazily searchparticularly effective domains abstract space big stored completelymemory. first, directed search pattern space performed goal patternstart pattern (unlike regular PDBs complete breadth-first search performed).patterns seen search saved PDBs. Then, main search real state spacebegins. nodes generated, search pattern space continued lazilyPDB values found stored. Hierarchical search algorithms, Hierarchical A* (Holte,Perez, Zimmer, & MacDonald, 1996) Switchback (Larsen, Burns, Ruml, & Holte, 2010), usehierarchy abstract spaces create hierarchy PDBs, also created lazily similar manner.use IDPDBs experiments Section 8.4.present method constructing PDB-based OSF.7.2 PDB-Based OSFLet abstraction mapping given domain. Note operator original spaceprojection onto abstract operator modifies variables (s) wayoriginal operator modifies variables s.given , construct either full-checking direct-computation OSF. Intuitively,knowledge components OSFs similar tables constructed SAPFSections 5.1 5.2. Recall that, SAPF, knowledge component OSFs consistedeight tables. table corresponded one eight possible positions n relative goal.table recorded operators applicable n resulting f (nc ). Depending kindOSF, tables sorted either operators f (nc )-values. adopt methodconstruct OSF based follows. knowledge component OSF contains:table abstract state a. table records abstract operators applicablewell resulting change f -value. denote abstract operator ,result applying ac (= (a)) resulting change f -value f (ac ).Depending whether building full-checking direct-computation OSF,table sorted either abstract operators f (ac ).call data structure employed knowledge component -PDB distinguish-PDB sorted operators (used knowledge component full-checking OSF)-PDB sorted f (ac ) (used knowledge component direct-computation OSF).important note that:161fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER1. -PDB include regular PDB based on. Rather, -PDBs additionaldata structures enable PDB-based OSF. domains, trade-off(1) building -PDB, affords using EPEA* (2) building additional PDB,affords accurate heuristic. explore trade-off.2. entry -PDB different entry regular PDB. entry regular PDBcontains one value distance given abstract state abstract goal. entry-PDB contains table abstract operators f (ac )-values given abstract state.algorithmic component full-checking PDB-based OSF operates follows.operator applicable n, OSF (1) locates table (n) -PDB ordered operators(2) looks table f (ac )-value projection onto . valuerequired f (nc ), nc included set currently needed children.algorithmic component direct-computation OSF operates follows. given nrequired f (nc ), OSF (1) locates table (n) -PDB ordered f (ac )values (2) looks table abstract operators f (ac )-value equalrequired f (nc ). abstract operator, OSF determines set operatorsoriginal space correspond abstract operators. Thus, direct-computation OSFconstructed every abstract operator efficiently mapped corresponding operator(s) original space.clear that, unless branching factor abstract space large, improvementrun-time performance afforded using direct-computation OSF rather fullchecking OSF cannot large. algorithmic components kinds OSFneed perform one lookup -PDBs. difference full-checking OSFneeds scan array f (ac )-values corresponding abstract operators,usually large overhead.next section, consider OSF Rubiks Cube Corner PDBs heuristicsimple example PDB-based OSF. involved example OSF based additivePDBs (Felner et al., 2004; Yang et al., 2008) Multi-Agent Pathfinding domain (MAPF) (Standley, 2010; Sharon, Stern, Goldenberg, & Felner, 2011, 2012) given Section 8.7.3 OSF Rubiks CubeRubiks Cube invented 1974 Erno Rubik Hungary. standard version consists3 3 3 cube different colored stickers exposed squares sub-cubes,cubies. 20 movable cubies 6 stable cubies center face. movablecubies divided eight corner cubies, three faces each, twelve edge cubies,two faces each. Corner cubies move among corner positions, edge cubiesmove among edge positions.one 6 faces cube rotated 90, 180, 270 degrees relative restcube. results 18 possible moves state. Since twisting face twicerow redundant, branching factor first move reduced 15. addition,movements opposite faces independent. example, twisting left face rightface leads state performing moves opposite order. Pruning redundantmoves results search tree asymptotic branching factor 13.34847 (Korf, 1997).162fiE NHANCED PARTIAL E XPANSION A*#12131415IDA*EPEIDA*ratioIDA* EPEIDA*Corner PDBGenerated Nodes - ThousandsTime (mm:ss)45,8003,441 13.310:050.01434,67132,610 13.320:530:153,170,960237,343 13.375:311:32100,813,966 7,579,073 13.30 175:2547:16ratio43.533.683.71Table 4: Comparison generated nodes time performance IDA* EPEIDA*Rubiks Cube.goal state, squares side cube color. puzzlescrambled making number random moves, task restore cube originalunscrambled state. 4 1019 different reachable states.classic abstraction mapping Rubiks cube PDB based corner cubies (Korf,1997). abstraction 88, 179, 840 abstract states. branching factor abstract spacebranching factor original space. fact, operator abstract spacetrivially one-to-one-mapped operator original space.experimented full-checking direct-computation OSFs. expected,branching factor 18 large enough achieve run-time advantage using directcomputation OSF. fact, full-checking OSF marginally faster experiments.results full-checking OSF given Table 4. line average 100instances depth 12-15. reduction (ratio column) number nodes generated factor13.3 (again close known effective branching factor), time improvement3.7-fold. reason discrepancy constant time per node EPEIDA*larger IDA* since includes time retrieve values -PDB.8. Additive PDBs-Based OSFsection motivated Multi-Agent Pathfinding domain (MAPF), recently attracted significant attention researchers (Standley, 2010; Sharon et al., 2011, 2012).recent workshop dedicated problem, way use additive PDBs (Felner et al., 2004; Yanget al., 2008) solve instances problem presented (Goldenberg, Felner, Stern, & Schaeffer, 2012). develop additive PDBs-based OSF, generation surplus nodesavoided solving instances MAPF.keep section simple possible, leave description technically complicatedbackground details implementation OSF Appendices C D. current sectionorganized follows:1. brief description MAPF (Section 8.1). Standley (2010) introduced two MAPF-specificalgorithmic enhancements A* make problem instances MAPF solvable within reasonable time resources. mention enhancements describe Appendix Cpurpose self-contained.163fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER2. definition additive PDBs explanation PDBs built MAPF(Section 8.2).3. description basic additive PDBs-based OSF MAPF (Section 8.3).number performance enhancements OSF, described Appendix D.4. report experimental results (Section 8.4).8.1 Multi-Agent Pathfinding Domain (MAPF)Consider following commonly used variant MAPF (Standley, 2010; Sharon et al., 2011,2012). input consists of: (1) graph G(V, E) (2) k agents labeled a1 , a2 . . . ak . Everyagent ai coupled start goal vertices: si gi . initial time point = 0 everyagent ai located location si . successive time points, agent performmove action neighboring location wait (i.e. stay idle) current location. operatorconsists action (which may Wait) every agent. Every legal operator respect twoconstraints:1. vertex occupied one agent given time2. x neighboring vertices, two different agents cannot simultaneously traverseconnecting edge opposite directions (from x x). However, agentsallowed follow other, i.e., agent ai could move x time agentaj moves z.task find sequence legal operators bring agent goal positionminimizing global cost function. variant problem, cost function summation(over agents) number time steps required reach goal location. Therefore,Move Wait actions cost 1, except case Wait action applied agents goallocation, case costs 0. exception case agent waits times goallocation moves: cost move + 1.A*-based optimal solvers MAPF use Sum Individual Costs (SIC) heuristic,optimal cost solving problem legal operator constraints ignored. firstuse PDBs MAPF recently reported (Goldenberg et al., 2012). explainapplying abstraction-based heuristics challenging MAPF. Two techniques becomestandard A*-based optimal MAPF solvers (Standley, 2010):8Independence Detection (ID) tries reduce part MAPF problem instances complexity due agents interactions (i.e. legal operator constraints).Operator Decomposition (OD) reduces number surplus nodes generated A*.call resulting variant A* Operator Decomposition A* (ODA*).ID ODA* described detail Appendix C. appendix, also introducePartial Expansion ODA* (PEODA*), hybrid ODA* PEA*.8. recent papers Roger Helmert (2012) Bouzy (2013) stand far solving MAPF non-optimallyconcerned.164fiE NHANCED PARTIAL E XPANSION A*8.2 Additive PDBs MAPFsection, define additive PDBs show constructing PDBs MAPF challenging.8.2.1 EFINITION DDITIVE PDBConsider set abstractions = {1 , 2 , . . . , k } given domain. abstraction, PDB, denoted P DBi built. arbitrary state s, P DBi [i (s)] stores distancegoal abstractX space . set called additive if, stateoriginal state space, sumP DBi [i (s)] greater distance goaloriginal space. PDBs based additive abstractions called additive PDBs (Felner et al.,2004; Yang et al., 2008).Suppose built stored -PDB ordered f (ac ) abstractionadditive set abstractions . denote -PDBs -PDB1 , -PDB2 , . . . , -PDBk .make two assumptions motivated MAPF:1. variable participates least one abstractions .2. Given node n operator results nc , f (nc ) given by:f (nc ) =kXf (i (nc )),(1)i=1Intuitively, means operator may affect variables-PDBs looked determine f (nc ) particular operator.8.2.2 DDITIVE PDB MAPFgiven node n, say agents a1 , a2 , . . . , conflict SIC heuristicagents (i.e. agents ignored) perfect. Intuitively definition means that,whatever optimal plan chosen individual agent, plans cannot executed simultaneously without agents colliding other. PDBs MAPF provide useful heuristicinformation built agents conflict many nodes mainsearch. However, information known priori. solve problem caseabstractions consist two variables (i.e. locations two agents). call PDBs basedabstractions pairwise PDBs.Recall ID used top EPEA* (the reader unfamiliar ID refer Appendix C point). idea solution consider merge actions IDindication agents merged conflict many nodes main search. Namely,whenever ID merges two agents group, use information build pairwise PDBslater stages ID. build additive PDBs consist pairwise PDBs built way.Suppose, example, instance 10 agents. Consider execution ID, ignoringoperations except operation merging two groups single group. Suppose IDmerged agents {1, 5}, merged agents {2, 8} merged two groups together, forminggroup consisting agents {1, 2, 5, 8}. looking optimal path group,use two 2-agent PDBs: one states projected onto agents {1, 5} using projections165fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERf ([1 (n)])f ([2 (n)])f ([3 (n)])03511 = {11 , 12 }12 = {13 , 14 }13 = {15 }01321 = {21 }22 = {22 }23 = {23 }01431 = {31 }32 = {32 }33 = {33 , 34 }Figure 8: Entries -PDBs given node n.onto agents {2, 8}. experiments, used instance dependent pattern databases describedabove.following section, describe direct-computation OSF constructed additive PDBsbuilt described above. important note that, MAPF, operator affects agentsEquation 1 holds.Note SIC trivial case PDBs, since heuristic based single-agent additive PDBsexactly SIC heuristic. Therefore, OSF based additive abstractions developapplicable SIC well.8.3 Constructing Direct-Computation OSF Additive PDBsRecall Section 5.2 one way build direct-computation OSF defining classification states. particular, built direct-computation OSF single PDBSection 7.2, defined classes putting abstract state class own. contrast, set abstractions define classification states. Therefore, useclasses (this equivalent putting states one class). Instead, algorithmic componentOSF compute set operators required value f (nc ) on-the-flydescribe below.example, suppose three additive abstractions: 1 , 2 , 3 . Figure 8 shows entriescorresponding -PDBs ordered f (ac ) might contain particular node n expanded.Let ij denote j th abstract operator applicable (n). Figure 8 groups abstract operatorsresult f (ac ). groups denoted , i.e. ij j th group abstractoperators applicable (n). example, group 11 contains two abstract operators: 1112 . 5, 3 4 abstract operators available projections n onto threeabstractions, respectively. means could 5 3 4 = 60 operators noriginal space. However, may every combination legal operator originalspace. example, could changes variables performed 14 changesvariables performed 21 cannot applied time according rulesdomain (e.g. two agents cannot occupy location MAPF).Suppose need compute set operators applicable n f (nc ) = 8. According Equation 1, need find ways choose one abstract operator threeprojections n, sum corresponding f (ac )-values would equal eight. Onechoice 13 , 22 , 33 (these abstract operators f (ac )-values shown Figure 8bold). Furthermore, could choose one operator groups 12 , 22 , 33 .general, k abstractions, find operators required f (nc ) finding wayschoose one abstract operator abstraction, sum corresponding f (ac )values equal required f (nc ). note combinatorial problem exponential number abstractions. Since problem solved every expansion,166fiE NHANCED PARTIAL E XPANSION A*Procedure 3 Algorithmic component additive PDBs-based OSF MAPF.Variables:k number abstractionscurrent abstractionC sum f (ac )-values selected abstractions 1, 2, . . . , 1sum sum f (ac )-values selected abstractions 1, 2, . . . ,nOpsi number abstract operators applicable (n)opi current choice abstract operator (n)op current choice abstract operators abstractions 1, 2, . . . ,OP set ops result required f (nc ). ops may illegalN set currently needed nodes returned OSF1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:FindAbsOpSets(i, C, op)j 1 nOpsiSet opi ijSet sum C + f (ij [i (n)])sum > f (nc )Set Fnext (n) min(Fnext (n), sum)return== ksum == f (nc ) append op OPcontinueCall FindAbsOpSets(i + 1, sum, op)OSF(f (nc ))Set N , OP Fnext (n)Call FindAbsOpSets(1, 0, )op OPop legalAppend nc corresponding op Nreturn N, Fnext (n)critical problem solved efficiently. present simple basic algorithm solvingproblem Procedure 3. Enhancements simple algorithm presented Appendix D.addition finding operators required f (nc ), algorithm computes next storedvalue n, Fnext (n). Thus, Procedure 3 full-fledged direct-computation OSF.Procedure 3, main part OSF starts line 12. First, set currently neededoperators, N , initialized empty next stored value, Fnext (n) initialized infinity.also initialize empty set OP , whose meaning explained below. callFindAbsOpSets (which stands find abstract operator sets) procedure made. proceduretakes three parameters:1. current abstraction,2. C sum f (ac )s corresponding abstract operators chosen abstractions 1though 1,167fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER3. op current choice abstract operators abstractions 1, 2, . . . , i.produces two results:1. OP , set choices abstract operators, one per abstraction, result requiredf (nc )2. Fnext (n).OSF computes N filtering illegal operators OP returns (lines 15-end).walk FindAbsOpSets, implements simple recursive algorithm.given level recursion begins, abstract operator chosen abstractions 1, 2, . . . ,1. operators stored op. sum f (ac )s corresponding abstract operatorsstored C. two cases:1. current abstraction k (i.e. = k). base recursion. case,look abstract operators current abstraction f (ac ) complements Crequired f (nc ) (C + f (ac ) denoted sum Procedure 3). chosenoperator, tuple op appended operator stored OP (lines 8-10).2. current abstraction k (i.e. < k). case, look abstract operatorscurrent abstraction sum = C + f (ac ) would exceed required f (nc )invoke next level recursion (line 11).addition, whenever abstract operator results sum = C + f (ac ) exceedsrequired f (nc ) encountered, update Fnext (n) look following abstractions (lines 5-7).Appendix D, present four enhancements basic algorithm described.8.4 Experimental ResultsTables 5 6 compare node time performance, respectively, six A*-variants optimallysolving MAPF. EPEA*, two variants shown: one using SIC heuristic usingadditive PDBs-based OSF described above. -PDBs constructed on-the-fly.is, node n expanded first time, entries -PDBs correspondingabstractions n computed existed already.total 1,000 instances. instances, agents placed onto four-connected8x8 grid obstacles. varied number agents. algorithmic variants runID framework described footnote.9 variants given two minutes twogigabytes memory per instance. results bucketed according number agents (k,9. Since ID framework produce different results due reasons related performance properties different A* variants MAPF (see Appendix C), compared variants using followingapproach (Sharon et al., 2011). given instance, first ran ODA* ID framework savedlargest group inter-dependent agents. Then, original instance substituted another instance,agents largest group discarded. variants compared instances without useID.168fiE NHANCED PARTIAL E XPANSION A*Unique Nodes Generated, 103k InsA* ODA* PEA* PEODA* EPEA* EPEA* abstractionsInstances solved A* PEA* within two minutes 2GB memory2-6 79446.351.27 0.080.380.080.067-8 34 1,261.043.26 0.110.880.100.059-100n/an/an/an/an/an/aInstances solved neither A* PEA* within two minutes 2GB memory2-61n/a 335.34n/a105.149.949.317-8 25n/a 219.11n/a67.047.824.419-10 13n/a 705.76n/a211.54 17.5710.01Table 5: Comparison nodes performance six algorithms Multi-Agent Pathfinding.Run-Time, msk InsA* ODA* PEA* PEODA* EPEA* EPEA* abstractionsInstances solved A* PEA* within two minutes 2GB memory2-6 794647560652337-8 34 22,44014 14,8861221009-100n/an/an/an/an/an/aInstances solved neither A* PEA* within two minutes 2GB memory2-61n/a 2,153n/a1,8032783547-8 25n/a 1,637n/a1,3123352329-10 13n/a 16,660n/a8,846 3,0621,089Table 6: Comparison time performance six algorithms Multi-Agent Pathfinding.shown first column Tables 5 6) results instances falling bucketaveraged.Since basic A* PEA* perform much worse variants, split tablestwo halves. upper part table shows results instances solved withinallowed resources A* PEA*. see EPEA* generates four orders magnitudeless nodes three orders magnitude faster A*. Also, generates order magnitudeless nodes seven times faster ODA*. EPEA* additive PDBs-based OSFgenerates fewest number nodes among variants, fastest terms time.because, simple instances, overhead building (-)PDBs pay off.lower part table shows results instances solved either A*PEA*, solved variants. following trends observed. Applying partialexpansion top ODA* results three-fold reduction number generated nodestwo times speed-up ODA*. However, EPEA* generates yet another order magnitude lessnodes four times faster. EPEA* additive PDBs-based OSF clear winnerhard instances, running three times faster EPEA* based SIC heuristic.next two sections theoretical study PEA* EPEA*.9. Size OPEN: Limitation PEA* EPEA*section, show that, although purpose PEA* make OPEN smaller,sometimes exactly opposite effect.169fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERb s2g2s1g1Figure 9: instance MAPF, PEA*/EPEA* close even start node.Figure 10: Open (checkerboard) closed (gray) nodes 16 node expansions A* (left)PEA*/EPEA* (right).PEA*/EPEA* expands node n, puts OPEN currently needed childrenn. n possibly surplus children, n put back OPEN updated storedvalue. contrast A*, always puts n CLOSED expansion. mayresult PEA*/EPEA* maintaining much larger OPEN A*. Note OPEN frequentlyimplemented heap heap operations become slower number elements storedheap grows. Therefore, time performance may suffer considerably size OPENincreases.Consider MAPF example Figure 9. instance, two agents start locations (s1 , s2 )need get locations (g1 , g2 ). SIC heuristic start state 8, optimalsolution length 9 (namely, one agent wait agent pass). However,highest-cost (i.e. agents (a, b)) child start node f -value 12. Therefore,A* closes expanded nodes, PEA*/EPEA* never close nodes, evenstart node.Furthermore, possible node n closed PEA*/EPEA* even thoughneighbors n surely surplus. Figure 10 (left) shows instance singleagent pathfinding problem four-connected grid, shortest path needed cellcell G. Black cells obstacles. assume Manhattan distance heuristic. Noteshortest path length 10 16 gray cells f -value 8. Thus, A* starts expandingstates f = 8. 16 expansions states closed, 8 states around(marked checkerboard) OPEN list, f = 10.Consider operation PEA*/EPEA* example. PEA*/EPEA* expandsgray nodes close child f = 10. example,expanding state 10, operators North West f (nc ) = 0, operators East South170fiE NHANCED PARTIAL E XPANSION A*f (nc ) = 2. cell east 10 cell 1 already generated lower gvalue f = 8. However, PEA*/EPEA* perform duplicate detection currentlyunneeded nodes. Thus, cell 10 re-inserted OPEN list F = 10, received cell 1.Consequently, expanding gray cells first time, PEA*/EPEA* 16 OPEN nodesshown Figure 10 (right) CLOSED nodes. case PEA*, problem fixedexpense run-time overhead performing hash look currently unneededchildren discarding (note fix address large OPEN problem shownMAPF example above). case EPEA*, duplicate detection impossible, sinceEPEA* actually generate currently unneeded children.summarize, A* stores perimeter generated states OPEN list,PEA*/EPEA*, worst case, stores OPEN list states ever generated search. polynomial domains (defined footnote10 ), considerably affectstime performance PEA*/EPEA*. exponential domains, factor lesser importance,since, domains, A* stores nodes OPEN well.observe EPEA* slower A* experiments besides experimentsSAPF (not shown), EPEA* slightly slower A*.10. Performance analysispurpose section analytically estimate time performance EPEA*/EPEIDA*regular A*/IDA* compare. this, identify basic operations withinalgorithms give notation time costs operations. use notation giveprecise conditions obtaining time speed-up using enhanced partial expansion variantA*/IDA*.operations algorithms consideration listed Table 7. operation,denote applicability given algorithm putting + respective column.operation applicable full-checking OSF direct-computation OSF used,denote fact +(FC) +(DC), respectively. operations appear orderappear Procedures 1 2.11 introduce little notation possible, groupoperations together assign notation total time cost operationsgroup shown Table 8. Note time costs averages node expansionsgenerations, whichever applicable particular group operations. skip wordaverage text brevity. explain operations groups on-the-flyused analysis. Analysis EPEIDA* simpler analysis EPEA*. Thereforestart analysis EPEIDA*.10.1 Analysis EPEIDA*simplicity, restrict analysis last iteration IDA*. Let X number nodesexpanded iteration. Let b average branching factor domain. approximate10. Polynomial domains domains number distinct states depths breadth-first search treestarting given state (dm ), domain-specific constant. SAPF classical examplepolynomial domain. Exponential domains domains number distinct states depthsbreadth-first search tree starting given state (bd ), b average branching factor domain.15-puzzle, Rubiks cube pancake puzzle examples exponential domains.11. Hence heuristic computation appears twice: operation 3 A*, operation 9 IDA*.171fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFER#12345678910OperationApplicabilityA* PEA* EPEA* IDA* EPEIDA*Remove OPEN+++Recursive call IDA*++Compute nodes heuristic (IDA*) ++Check threshold condition IDA* ++Compute child nodes heuristic+(FC)+(FC)node generatedCheck one operator+(FC)+(FC)using full-checking OSFCheck one operator+(DC)+(DC)using direct-computation OSFApply operator+++++(in A*, includes copying parent)Compute child nodes heuristic++node generatedInsert one child OPEN+++-Table 7: Summary operations performed five algorithms consideration. plus signstands operation performed given algorithm, minus sign standsoperation applicable context given algorithm.Notationtetrtoftodtmt0mOperations18, 2, 3, 4678, 9, 108, 10Commentsdifferent cost A* EPEA*,so, EPEA*, use t0ecase EPEA*/EPEIDA*, also calls operation 5.A*EPEA*Table 8: Notation time costs groups operations. operations denotednumbers introduced Table 7.number nodes generated IDA* bX. Since EPEIDA* generates currently neededchildren (Section 4), expands nodes generates. exception rulesolution found. case, nodes generated upper levelsdepth-first tree may remain unexpanded. Therefore, EPEIDA* generates X + (b 1)d nodes.Since (b 1)d usually small compared X, ignore quantity followinganalysis. allow us express ratio run-time costs IDA* EPEIDA*terms parameters domain implementation without usage X.operator available given node n, IDA* generates child nc applyingoperator (operation 8), makes recursive call IDA* (operation 2), computes h(nc ) (operation3) checks threshold condition (operation 4). denote total time cost operations172fiE NHANCED PARTIAL E XPANSION A*tr . Since operations performed IDA* generated node, run-time costIDA* is:bXtr .(2)10.1.1 NALYSIS EPEIDA* F ULL -C HECKING OSFEPEIDA* full-checking OSF, node n expanded, cost tr spentcurrently needed operators applicable n. operators checked (operation 6),children generated. denoting time cost checking operator full-checkingOSF tof , run-time cost EPEIDA* given by:bXtof + Xtr .(3)ratio run-time costs IDA* EPEIDA* expressed by:btr.btof + tr(4)EPEIDA* faster IDA* ratio greater one, i.e.tof < trb1.b(5)10.1.2 NALYSIS EPEIDA* IRECT-C OMPUTATION OSFEPEIDA* direct-computation OSF checks operators leading X expandednodes. denoting time cost checking operator direct-computation OSF (operation7) tod , run-time cost EPEIDA* is:X(tod + tr ).(6)ratio run-time costs IDA* EPEIDA* expressed by:btr.tod + tr(7)EPEIDA* faster IDA* ratio greater one, i.e.tod < tr (b 1).(8)10.1.3 NALYSIS EPEIDA* H YBRID OSFRecall hybrid OSF behave either direct-computation full-checking OSFdifferent expansions depending required f (nc ). example, OSF pancakepuzzle introduced Section 6.2 direct-computation-OSF nodes f (nc ) = 0needed full-checking-OSF nodes f (nc ) = 1 f (nc ) = 2 needed.Let G0 X number nodes whose generation direct-computation OSF used. Also,let E 0 X number nodes whose expansion direct-computation OSF used. Notecannot easily express G0 terms E 0 (i.e. would wrong state G0 = 0 ), sincedirect-computation OSF generated currently needed children n. run-time costEPEIDA* givenG0 tod + b(X E 0 )tof + Xtr .(9)173fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERratio run-time costs IDA* EPEIDA* expressed by:G0 todbXtr.+ b(X E 0 )tof + Xtr(10)G0 E 0 known need use model allows detailed analysisestimate them. Fortunately, suitable model reported (Zahavi, Felner, Burch, & Holte,2010). Since using model estimate G0 E 0 technically involved provideimmediate insight efficiency EPEA*, defer analysis Appendix B.10.2 Analysis EPEA*analyze time performance EPEA*, need introduce two auxiliary parameterscharacterize performance EPEA*. Let average number times given nodeexpanded (each time different stored value). Let average number currentlyneeded children given node expansion. particular, = 1 = b (baverage branching factor), EPEA* equivalent A*. Note parameters domain,heuristic problem instance-dependent.Suppose A* performs X expansions bX generations. Since EPEA* expands nodeaverage times, perform total X expansions. Since EPEA* performs averagegenerations per expansion, perform total X generations.Let te denote time cost getting least cost node OPEN (operation 1).operator applicable n, A* generates child nc (operation 8), computes h(nc ) (operation 9)inserts nc OPEN (operation 10). denote total cost three operations tm .run-time cost regular A* given by:Xte + bXtm .(11)10.2.1 NALYSIS EPEA* F ULL -C HECKING OSFRecall Section 5.2 one trade memory speed imitating direct-computation OSFeven OSF available. following analysis pure version EPEA*full-checking OSF trade-off used.EPEA* performs X expansions, time checking b operators, followed generatingcurrently needed children nodes. Denote time cost expanding node EPEA* t0e . Notete t0e may different problem instance, since size OPEN differsexpansions A* EPEA*. Similarly, denote total time cost generating child nodenc , computing h(nc ) putting nc OPEN EPEA* t0m , might differ tm .run-time cost EPEA* given by:Xt0e + bXtof + Xt0m .(12)ratio run-time costs regular A* EPEA* expressed by:t0ete + btm.+ btof + t0m(13)EPEA* faster regular A* ratio greater one, i.e.tof <te + btm (t0e + t0m ).b174(14)fiE NHANCED PARTIAL E XPANSION A*10.2.2 NALYSIS EPEA* IRECT-C OMPUTATION OSFdirect-computation OSF, EPEA* performs X expansions, time checking operatorsgenerating currently needed children nodes. run-time cost EPEA* given by:Xt0e + X(tod + t0m ).(15)ratio run-time costs regular A* EPEA* expressed by:t0ete + btm.+ (tod + t0m )(16)EPEA* faster regular A* ratio greater one, i.e.tod <btm t0e + tet0m .(17)10.3 Conclusion Performance Analysisanalysis see whether EPEA*/EPEIDA* faster slower A*/IDA*depends on:1. average branching factor b domain,2. efficiency implementation A*/IDA* (expressed te , tr tm ),3. efficiency OSF used (expressed tof tod ),4. EPEA*, domain heuristic-dependent parameters .obtain experimental evidence analysis section, one would find wayreliably estimate quantities Table 8. However, estimation meets two challenges:1. operations discussion fine granularity. time performanceoperations cannot measured directly, measured sampling procedure.2. EPEA*, estimating parameters presents additional challenge.3. time performance operations discussion constant throughoutsearch. example, cost inserting node OPEN depends current sizeOPEN. Also, domains nodes variable branching factors.latter observation opens possibility algorithm that, depending current statesearch, switches A*/IDA* EPEA*/EPEIDA*.11. EPEA* Inconsistent Heuristicsheuristic h called consistent f -value decrease along path, i.e. f (nc ) f (n).Otherwise, h called inconsistent. far, assumed consistent heuristic. section,(1) show changes need made EPEA* (Procedure 1 Section 2.2)inconsistent heuristic h used (2) point one make choice using EPEA*175fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERProcedure 4 A*, PEA* EPEA* inconsistent heuristic.1: Generate start node ns2: Compute h(ns ) set F (ns ) f (ns ) h(ns )3: Put ns OPEN4: OPEN empty5:Get n lowest F (n) OPEN6:n goal exit// optimal solution found!7:A* PEA*: set N set children n initialize Fnext (n)8:EPEA*:9:f (n) = F (n)10:Set (N, Fnext (n)) OSFe (n).11:else12:Set (N, Fnext (n)) OSF (n).13:nc N14:Compute h(nc ), set g(nc ) g(n) + cost(n, nc ) f (nc ) g(nc ) + h(nc )15:PEA*:16:f (nc ) 6= F (n)17:f (nc ) > F (n)18:Set Fnext (n) min(Fnext (n), f (nc ))19:f (nc ) > F (n) F (n) 6= f (n)20:Discard nc21:continue// next nc22:Check duplicates23:Set F (nc ) f (nc ) put nc OPEN24:Fnext (n) =25:Put n CLOSED// A*, always done26:else27:Set F (n) Fnext (n) re-insert n OPEN// Collapse28: exit// solution.using heuristic value propagation techniques (such bidirectional pathmax (BPMX), Zahavi,Felner, Schaeffer, & Sturtevant, 2007) inconsistent heuristics. deep experimental studyEPEA* inconsistent heuristics including trade-off due aforementioned choicebeyond scope paper.11.1 Changes PEA* EPEA*start discussing PEA*, since PEA* makes choice nodes insert OPENexplicitly (line 12 Procedure 1).heuristic inconsistent, possible children nc n f (nc ) <f (n). children nodes surplus PEA* need insert OPENfirst expansion n. Thus, first expansion n definition currently needednode changed include children f (nc ) F (n).demonstrated Figure 11. node expanded, children (x, y, z, w)generated. However, children f -values exceeding 3 (x y) currently176fiE NHANCED PARTIAL E XPANSION A*Figure 11: Example PEA* inconsistent heuristic. first expansions nodeshown. Even children nodes whose f -value less f (a) generated.8BPMX6104BPMX2109654867726Figure 12: Two examples value propagation BPMX.needed. inserted OPEN. children possibly surplus. collapsedback a, gets new stored value F (a) = 4. Following this, re-inserted OPEN.on, treated consistent heuristic case.pseudo-code A*, PEA* EPEA* case inconsistent heuristic shownProcedure 4. Compared Procedure 1 Section 2.2, PEA* handles inconsistent heuristicperforming check line 19 discarding nc .EPEA*, case inconsistent heuristic also handled checking whether nexpanded first time (line 9). first expansion n, OSF returns setchildren f (nc ) F (n) used. call extended OSF denote OSFe (line 10).Note similar OSF used EPEIDA* (Section 4) well. expansions n,change OSF needed (line 12).11.2 Trade-Offinconsistent heuristic used, heuristic value propagation techniques applied takeadvantage regions state space high heuristic values. One effectivetechniques bidirectional pathmax (BPMX) (Zahavi et al., 2007). example BPMXsoperation shown Figure 12 (right). Assuming unit edge costs, h-value left grandchild(10) propagated search tree, increasing heuristic estimates statesneighborhood except gray node. general, two arbitrary states a, b V , heuristicestimate h(a, g) updated max {h(a, g), h(b, g) d(a, b)} (shown Figure 12 (left))BPMX uses rule directions search tree.177fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFEREPEA* used, possibly surplus children n generated and, therefore,propagation values children n available. introduces interesting tradeoff:EPEA* saves memory time generating surplus nodes,opportunity increase quality heuristic estimates using non-monotonicityf missed.separate study might dedicated trade-off.1212. Conclusions Future Workpresented Enhanced Partial Expansion A* (EPEA*), novel variant A*avoids generating surplus nodes. enabled using priori domain- heuristic-specificknowledge form Operator Selection Function (OSF) compute list operatorslead children needed f -cost without actually generating childrennode expanded. studied several kinds OSF, including OSFs based (additive)pattern databases. extended principles EPEA* IDA* resulting Enhanced PartialExpansion IDA* (EPEIDA*). Experimental results 15-puzzle, pancake puzzle,Rubiks cube multi-agent pathfinding show EPEA*/EPEIDA* achieves state-of-the-artrun-time performance. Furthermore, EPEA* fully maintains memory savings offered PEA*.EPEA* effective domains heuristics meet following criteria:1. domain possesses large branching factor. large branching factor indicatorA* may generate large number surplus nodes. EPEA* save overhead.2. set possible f -values children given node small. means EPEA*re-expand node many times.3. operators classified according f (nc ) value, operatorsneeded class applied without need check operators node expanded. words, direct-computation OSF available.conditions met specific domain heuristic interest,thorough assessment, experimenting prototype implementation, needed.addition, explained possibility poor performance EPEA* polynomialdomains.Future work seek applications EPEA* domains heuristics. particular,would interesting see whether EPEA* implemented best heuristicsused domain-independent planning. seems EPEA* easily implemented12. Related trade-off following observation (Felner et al., 2011, p. 22). studied following trade-offcontext applying BPMX IDA*. propagation children parent results cut-off, IDA*either backtrack immediately (this option called lazy propagation) look children hopes obtaineven higher value parent obtain cut-offs future. concluded backtracking immediatelypreferable domains studied. However, cannot conclude one always useEPEA* forgo propagation values children parents, since IDA* lazy BPMX propagationperform effective propagation backtracking.178fiE NHANCED PARTIAL E XPANSION A*STRIPS (Fikes & Nilsson, 1971) variable abstraction heuristics (Edelkamp, 2001). However, remains see whether EPEA* applied merge-and-shrink abstractions (Helmert,Haslum, & Hoffmann, 2007) landmarks (Karpas & Domshlak, 2009).promising direction future work implement OSF using symbolic representation,BDDs (Binary Decision Diagrams). Jensen, Bryant, Veloso (2002) proposed methodgroup state transitions effect f -value. grouping state transitionsreferred improvement partitioning used avoid generating node f -valueslarger given upper bound (Jensen, Hansen, Richards, & Zhou, 2006). Thus, believemay possible create OSF similar method.Another interesting direction see EPEA* used non-optimal searches.searches, notion surplus node needs defined based required qualitysolution.Furthermore, touched upon topic EPEA* inconsistent heuristics pointedtrade-off exists using EPEA* leveraging full power value propagationtechniques. experimental study trade-off remains subject future work.13. Acknowledgementsresearch supported Israeli Science Foundation (ISF) grant 305/09 Ariel FelnerNatural Sciences Engineering Research Council Canada grant Jonathan Schaeffer.Acknowledgements due Kobi Shmerkovich, Tal Beja, Idan Morad Shaked Zimmermann performing experiments paper.Appendix A. Glossary EPEA* TermsTable 9 lists terms introduced paper alphabetical order. provides brief definitionterm reference place term defined paper.TermBrief definitionSection(s)Algorithmic component OSFalgorithm OSF employs generate currentlyneeded nodes compute next stored value nodeexpanded.3.2CFNSee collapsing frontier nodes.2.1Checking operatorDeciding whether apply available operator generatechild node.3.1Collapse actionoperation substituting nodes search frontiercommon ancestor n, increasing cost n. Seestored value.2.1Collapsing frontier nodes (CFN)technique used number algorithms. See collapseaction.2.1179fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERCurrently neededchild nodenode A*/IDA* generate current expansion guarantee optimality. definition differs A*IDA*.2.2 4Currently neededoperatoroperator results currently needed child node.2.2 4Currentlyneedednodechild node currently needed.2.2 4Currentlyunneeded operatoroperator currently needed.2.2 4DirectcomputationOSFOSF need check operators generatecurrently needed nodes.5Full-checkingOSFOSF needs check operators generatecurrently needed nodes.5Hybrid OSFOSF behaves either direct-computation fullchecking OSF depending needed change f -value(f (nc )).5Knowledge component OSFdomain- heuristic-specific data structure OSFstores. algorithmic component uses knowledge component generate currently needed nodes computenext stored value node expanded.3.2Operatorselectionfunction (OSF)function uses domain- heuristic-specific knowledgegenerate currently needed nodes computenext stored value node expanded.3.2OSFSee operator selection function.3.2Possibly surpluschild nodechild node provably useful.2.2Provably usefulchild nodechild node proved useful. child node ncprovably useful f (nc ) F (n).2.2Pure OSFNon-hybrid OSF.5SAPFsingle-agent pathfinding domain.3.2Static valueregular g + h cost node, denoted f (n).2.1Stored valuecost node obtained collapse action denotedF (n).2.1unchild180fiE NHANCED PARTIAL E XPANSION A*Surplus nodenode whose static value greater cost optimalsolution.1Useful nodenode node surplus.1Table 9: terminology used paper.Appendix B. Analysis Hybrid OSFstart describing model aims predict number nodes expanded IDA* (Zahaviet al., 2010) (ZFBH).13 Later section, show model usedestimate quantities G0 E 0 introduced Section 10.1.3. model uses assumptionunit cost operators. analysis make assumption well.start result puts study hybrid OSF general frameworkpancake puzzle example.Lemma 1. Let H natural number hybrid OSF direct nodes f (nc )H needed. Then, whenever node n f (n) H expanded, thresholdcurrent iteration, hybrid OSF direct.Proof. Suppose n f (n) H expanded. Since IDA* nodesf (nc ) needed, need generate nodes f (nc ) = f (nc ) f (n)f (nc ) + H H. nodes OSF direct.Remark 1. pancake puzzle, H zero.Remark 2. chose focus simple model two ranges values f (nc ). resultssection generalized model number ranges designated H1 , H2 , . . . , Hm .B.1 Model ZFBH.ZFBH define Ni (s, d, v) number nodes IDA* generate level heuristicvalue equal v start state IDA*s iteration threshold. give recursiveformula approximate quantity follows:d(i1)Ni (s, d, v) =XNi1 (s, d, vp ) bvp p(v|vp ).(18)vp =0equation, p(v|vp ) probability child node heuristic value v givenparent heuristic value vp , bvp average branching factor nodes whose heuristic valuevp . quantities obtained sampling state space (we refer reader ZFBHdetails sampling process). explain reasoning behind equation. Sinceparent node located level 1 depth-search tree, could expanded13. use basic one-step model ZFBH.181fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERheuristic less equal (i 1) (otherwise, threshold condition wouldfailed). heuristic value vp , Ni1 (s, d, vp ) parent nodes, bvpchildren. However, children heuristic value v interest. Since, parentsheuristic value fixed vp , multiply conditional probability.total number nodes expanded iteration IDA* approximated by:XXdiXNi (s, d, v).(19)i=0 v=0first summation runs depths current iterations search tree. given depth i,nodes heuristic value less equal satisfy threshold condition.second summation runs heuristic values. depth heuristicvalue v fixed, Ni (s, d, v), given Equation 18, approximates number nodes expandedIDA*.B.2 Estimating E 0 .Lemma 1, hybrid OSF direct f (n) H. Subtracting level numberf (n), get equivalent condition:v (d i) H.(20)Therefore, modify Equation 19 estimate E 0 :E0XdiXNi (s, d, v).(21)i=0 v=(di)HB.3 Estimating G0 .Let G0i (s, d, v) denote number nodes EPEIDA* generate using direct-computationOSF level heuristic value equal v start state IDA*s iterationthreshold. approximate G0i (s, d, v) restricting summation Equation 18parent nodes expanded direct-computation OSF. Equation 20, condition is:vp [d (i 1)] H. have:d(i1)G0(s, d, v)X=Ni1 (s, d, vp ) bvp p(v|vp ).(22)vp =[d(i1)]Hestimate G0 as:0GXdiXG0 (s, d, v).(23)i=0 v=0G0 E 0 estimated, Equation 10 gives time speed-up EPEIDA* IDA*.interest note also estimate number nodes whose generation EPEIDA*save compared IDA* particular level i:+XNi (s, d, v).v=di+1182(24)fiE NHANCED PARTIAL E XPANSION A*summation, v starts + 1 nodes heuristic values range[0 . . . i] expanded level i.Appendix C. Algorithmic Enhancements Solving MAPFsection describe three MAPF-specific algorithmic enhancements A*. Two them,Independence Detection (ID) Operator Decomposition A* (ODA*) due Standley(2010). Partial Expansion ODA* (PEODA*) new hybrid ODA* PEA*.C.1 Independence Detection (ID)Two groups agents called independent optimal solution grouptwo solutions conflict. basic idea Independence Detection (ID) divideagents independent groups. Initially agent placed group. Shortest pathsfound group separately. resulting paths groups simultaneously performedconflict occurs two (or more) groups. Then, agents conflicting groupsunified new group, i.e. two groups merged. Whenever new group k 1 agentsformed, new k-agent problem solved optimally A*-based search. processrepeated conflicts groups occur. Standley observed since problemexponential k, A*-search largest group dominates running time solvingentire problem, searches involve smaller groups (for details ID, see Standley,2010).Note ID combined optimal MAPF solver. paper Standley (2010),ID combined ODA*. approach combines ID EPEA* OSF based additive abstractions. fact, use feedback received ID determine variablesincluded additive abstractions explained below.C.2 Operator Decomposition (OD)Standley (2010) introduced Operator Decomposition (OD) reduces number surplusnodes generated MAPF follows. OD introduces intermediate nodes regular statesA* search follows. Agents assigned arbitrary (but fixed) order. regular A*state expanded, OD considers moves first agent, results generatingcalled intermediate nodes. nodes, moves second agent consideredintermediate nodes generated. operator applied last agent, regular nodegenerated. solution found, intermediate nodes OPEN developedregular nodes, number surplus nodes significantly reduced. variant A*referred ODA*. ODA* still generate surplus nodes, intermediate regular.contrast, EPEA* never generates surplus nodes.C.3 Partial Expansion ODA*introduce Partial Expansion ODA* (PEODA*), hybrid ODA* PEA*. variantoperates similarly ODA* one exception. PEODA* generates intermediate children ncn, puts nc OPEN f (nc ) = F (na ), na standard node ancestor nc .particular, n standard node, na n.183fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERAppendix D. Enhancements OSF Based Additive PDBssection, present four enhancements OSF described Section 8.3. enhancement presented separate subsection.D.1 Avoiding Linear Search = kobvious enhancement FindAbsOpSets that, last level recursion (i = k),use fact -PDBk ordered f (ac ) quickly locate (e.g. binary search)f (ac )-values complete sum required f (nc ).D.2 Obtaining Cut-offs Line 5note possible obtain stronger condition cut-off line 5 Procedure 3.this, first expansion n, compute store n OPEN array k (the numberabstractions) elements:smallSums[i] =kXf (l1 [l (n)])l=i+1Intuitively, smallSums[i] sum smallest entries -PDBs n abstractions+ 1 k. note cut-off performed whenever sum + smallSums[i] >f (nc ) holds. Intuitively, means sum provably large, since even choosing smallest entries remaining abstractions would result exceeding required f (nc ). Whenevercut-off occurs, Fnext (n) set minimum current value Fnext (n)sum + smallSums[i].D.3 Obtaining Additional Cut-offobtain cut-off sum provably large, obtain cut-off sumprovably small. this, first expansion n, compute store n OPENarray k (the number abstractions) elements:largeSums[i] =kXf (l,nOpsl [l (n)])l=i+1cut-off performed whenever sum + largeSums[i] < f (nc ) holds.D.4 Per-Group Searchalready observed that, choice f (ac )-value abstractionsresults required f (nc ) found, take one abstract operator groupsresulting f (ac )-values. Therefore, change loop line 2 gopossible groups instead possible abstract operators. example, two choices groupsoperators result f (nc ) = 8:{(12 , 22 , 33 ), (13 , 23 , 31 )}.184fiE NHANCED PARTIAL E XPANSION A*FindAbsOpSets returns choices groups, one per abstractions result required f (nc ) (line 14), post-processing step would compute corresponding choices abstract operators. example, post-processing step would take choice (12 , 22 , 33 )compute four choices abstract operators:{(13 , 22 , 33 ), (14 , 22 , 33 ), (13 , 22 , 34 ), (14 , 22 , 34 )}.enhancement, domains MAPF, illegal operator pruning integratedpost-processing step. example, 22 cannot performed together 13 ,need consider choice operator third abstraction. MAPF, resultssignificant time speed-up.ReferencesBouzy, B. (2013). Monte-carlo fork search cooperative path-finding. IJCAI WorkshopComputer Games.Culberson, J. C., & Schaeffer, J. (1998). Pattern databases. Computational Intelligence, 14(3),318334.Dechter, R., & Pearl, J. (1985). Generalized best-first search strategies optimality A*.Journal Association Computing Machinery, 32(3), 505536.Dweighter, H. (1975). Problem e2569. American Mathematical Monthly, 82, 1010.Edelkamp, S. (2001). Planning pattern databases. European Conference Planning (ECP01), pp. 1324.Edelkamp, S., & Korf, R. E. (1998). branching factor regular search spaces. AAAI, pp.299304.Felner, A., & Adler, A. (2005). Solving 24-puzzle instance dependent pattern databases.SARA, pp. 248260.Felner, A., Goldenberg, M., Sharon, G., Stutervant, N., Stern, R., Beja, T., Schaeffer, J., & Holte, R.(2012). Partial-expansion A* selective node generation. AAAI.Felner, A., Korf, R. E., & Hanan, S. (2004). Additive pattern database heuristics. Journal ArtificialIntelligence Research (JAIR), 22, 279318.Felner, A., Zahavi, U., Holte, R., Schaeffer, J., Sturtevant, N., & Zhang, Z. (2011). Inconsistentheuristics theory practice. Artificial Intelligence, 175(9-10), 15701603.Fikes, R. E., & Nilsson, N. J. (1971). Strips: new approach application theorem provingproblem solving. Tech. rep. 43R, AI Center, SRI International.Ghosh, S., Mahanti, A., & Nau, D. S. (1994). ITS: efficient limited-memory heuristic tree searchalgorithm. AAAI, pp. 13531358.Goldenberg, M., Felner, A., Stern, R., & Schaeffer, J. (2012). A* variants optimal multi-agentpathfinding. Workshop Multiagent Pathfinding.Goldenberg, M., Felner, A., Stutervant, N., Holte, R., & Schaeffer, J. (2013). Optimal-generationvariants EPEA*. International Symposium Combinatorial Search (SoCS).185fiG OLDENBERG , F ELNER , TERN , HARON , TURTEVANT, H OLTE , & CHAEFFERHelmert, M. (2006). fast downward planning system.. Journal Artificial Intelligence Research (JAIR), 26, 191246.Helmert, M. (2010). Landmark heuristics pancake problem. International SymposiumCombinatorial Search (SoCS), pp. 745750.Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimal sequential planning. ICAPS, pp. 176183.Hoffmann, J., & Nebel, B. (2001). FF Planning System: Fast Plan Generation Heuristic Search. Journal Artificial Intelligence Research (JAIR), 14, 253302.Holte, R. C., Perez, M. B., Zimmer, R. M., & MacDonald, A. J. (1996). Hierarchical A*: Searchingabstraction hierarchies efficiently. AAAI, pp. 530535.Jensen, R. M., Hansen, E. A., Richards, S., & Zhou, R. (2006). Memory-efficient symbolic heuristicsearch. ICAPS, pp. 304313.Jensen, R. M., Bryant, R. E., & Veloso, M. M. (2002). SetA*: Efficient BDD-Based HeuristicSearch Algorithm. AAAI/IAAI, pp. 668673.Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. IJCAI, pp. 17281733.Korf, R. E. (1985). Depth-first iterative-deepening: optimal admissible treesearch. ArtificialIntelligence, 27(1), 97109.Korf, R. E. (1993). Linear-space best-first search. Artificial Intelligence, 62(1), 4178.Korf, R. E. (1997). Finding optimal solutions Rubiks Cube using pattern databases. AAAI,pp. 700705.Larsen, B. J., Burns, E., Ruml, W., & Holte, R. (2010). Searching without heuristic: Efficient useabstraction. AAAI.Richter, S., & Helmert, M. (2009). Preferred operators deferred evaluation satisficing planning.. ICAPS, pp. 273280.Roger, G., & Helmert, M. (2012). Non-optimal multi-agent pathfinding solved (since 1984).International Symposium Combinatorial Search (SoCS), pp. 15.Russell, S. J. (1992). Efficient memory-bounded search methods. ECAI-92.Sharon, G., Stern, R., Goldenberg, M., & Felner, A. (2011). increasing cost tree searchoptimal multi-agent pathfinding. IJCAI, pp. 662667.Sharon, G., Stern, R., Goldenberg, M., & Felner, A. (2012). Meta-agent conflict-based search optimal multi-agent path finding. International Symposium Combinatorial Search (SoCS).Silver, D. (2005). Cooperative pathfinding. AIIDE, pp. 117122.Standley, T. (2010). Finding optimal solutions cooperative pathfinding problems. AAAI, pp.173178.Yang, F., Culberson, J., Holte, R. C., Zahavi, U., & Felner, A. (2008). general theory additivestate space abstractions. Journal Artificial Intelligence Research (JAIR), 32, 631662.Yoshizumi, T., Miura, T., & Ishida, T. (2000). A* partial expansion large branching factorproblems. AAAI/IAAI, pp. 923929.186fiE NHANCED PARTIAL E XPANSION A*Zahavi, U., Felner, A., Burch, N., & Holte, R. C. (2010). Predicting performance IDA* (withBPMX) conditional distributions. Journal Artificial Intelligence Research (JAIR), 37,4183.Zahavi, U., Felner, A., Holte, R. C., & Schaeffer, J. (2008). Duality permutation state spacesdual search algorithm. Artificial Intelligence, 172(45), 514540.Zahavi, U., Felner, A., Schaeffer, J., & Sturtevant, N. R. (2007). Inconsistent heuristics. AAAI,pp. 12111216.Zhou, R., & Hansen, E. (2004). Space-efficient memory-based heuristics. AAAI, pp. 677682.Zhou, R., & Hansen, E. A. (2002). Memory-bounded A* graph search. Florida Artificial Intelligence Research Society (FLAIRS-02), pp. 203209.187fiJournal Artificial Intelligence Research 50 (2014) 409-446Submitted 12/13; published 6/14Multivariate Complexity Analysis LobbyingMultiple ReferendaRobert BredereckJiehua ChenSepp HartungStefan KratschRolf Niedermeierrobert.bredereck@tu-berlin.dejiehua.chen@tu-berlin.desepp.hartung@tu-berlin.destefan.kratsch@tu-berlin.derolf.niedermeier@tu-berlin.deTU Berlin, GermanyOndrej Suchyondrej.suchy@fit.cvut.czCzech Technical University Prague, Czech RepublicGerhard J. Woegingergwoegi@win.tue.nlTU Eindhoven, NetherlandsAbstractAssume n voters may may approve issues. agent (thelobby) may influence k voters, central question NP-hard Lobbyingproblem whether lobby choose voters influenced resultissue gets majority approvals. problem modeled simple matrixmodification problem: one replace k rows binary nm-matrix k all-1 rowscolumn resulting matrix majority 1s? Significantly extendingprevious work showed parameterized intractability (W[2]-completeness) respectnumber k modified rows, study natural parameters n, m, k,maximum number 1s missing column majority 1s (referredgap value g) govern computational complexity Lobbying. Amongresults, prove Lobbying fixed-parameter tractable parameter providegreedy logarithmic-factor approximation algorithm solves Lobbying even optimally4. also show empirically greedy algorithm performs well generalinstances. key result, prove Lobbying LOGSNP-completeconstant values g 1, thus providing first natural complete problem votingcomplexity class limited nondeterminism.1. IntroductionCampaign management comprises sorts activities influencing outcomeelection, including well-known scenarios bribery (Faliszewski, Hemaspaandra, &Hemaspaandra, 2009; Dorn & Schlotter, 2012; Schlotter, Elkind, & Faliszewski, 2011;Elkind, Faliszewski, & Slinko, 2012) control (Bartholdi III, Tovey, & Trick, 1992; Elkind,Faliszewski, & Slinko, 2011; Erdelyi, Piras, & Rothe, 2011). works relatecampaigning case classical voting scenarios one typically wants make specificcandidate win prevent winning, Christian, Fellows, Rosamond, Slinko(2007) introduced scenario lobbying multiple referenda. Intuitively, pointn voters, providing yes- no-answer issues.words, referendum issues voters decide on. Naturally,c2014AI Access Foundation. rights reserved.fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerreferendum held, campaigns run various parties interest groupsinfluence outcome referendum. Assuming complete knowledge currentvoter opinions assuming extreme scenario external agentthe lobbygainscomplete control specific voters, Christian et al. modeled basic scenario0/1-matrix modification problem, rows represent voters, columns representissues vote yes (1) (0), lobby goal represented 0/1-vector.LobbyingInput:matrix {0, 1}nm integer k 0.Question: one modify entries k rows resultingmatrix every column 1s 0s?context, modifying row means simply flip 0s 1s. Hence, modifyingminimum number rows interpreted lobby influencing minimum numbervoters reach certain goal. difference Christian et al., assumedesired outcome column 1 instead providing goal vector lobby. is,1 corresponds agreement lobby goal 0 corresponds disagreement. Clearly,appropriately flipping entries column always ensured. Furthermore,assume column majority 1s removed input matrix.following example, extract real-world data Section 6.2, illustratesmodel.Example 1. Consider following four issues voting behavior five factionleaders extracted recorded votes German parliament 2013. (See Section 6.2details full data set.)Selected issues:1. Water access human right.2. Forbid Nationalist Party.3. Financial help Ireland.4. Financial help Cyprus.BruderleGysiKauderKunastSteinmeier1YesYes2YesYesYes3YesYesYesYes4YesYesYesYesAssume lobby wants approve first two issues disapprove last twoissues. Then, matrix translates following binary matrix.01010010110100001000second column removedmajority voters already agreelobby. Modifying first third rowyields solution.Lobbying NP-complete (Christian et al., 2007). Moreover, setting parameterized complexity analysis (Downey & Fellows, 2013; Flum & Grohe, 2006; Niedermeier,2006), Christian et al. showed W[2]-complete respect parameter number k rows modify, is, even small number voters shall influencedproblem computationally intractable. work, provide significantly410fiA Multivariate Complexity Analysis Lobbying Multiple Referendarefined view parameterized multivariate computational complexity (Fellows,Jansen, & Rosamond, 2013; Niedermeier, 2010) Lobbying. end, identifyfollowing parameters naturally occurring Lobbying analyze influencecomputational complexity. studied parameters are:n: number rows;m: number columns1 ;k: number rows modify;k 0 :=d(n + 1)/2e k: below-guarantee parameter;2g:=maxmj=1Pngj : maximum gap value columns, gap value gj :=d(n +1)/2e i=1 Ai,j number missing 1s make column j 1s0s;s: maximum number 1s per row;t: maximum number 0s per row.1.1 Parameter Choiceparameters n, m, k naturally occurring parameters measure inputsize solution size, respectively. Scenarios voters issues clearlyinteresting realistic restrictions. Furthermore, also restriction instancessmall solutions natural limited budget lobby may allow (very)small amount bribery or, positively, advertisement. Additionally, k 0 complementsparameter k seems promising measures distance trivial typeyes-instances. Moreover, observe maximum gap value g lower boundnumber rows modified; precomputed linear time. Furthermore,sets issues single issue needs small amount additional approvalsdisapprovals bear good prospects lobby limited budget. Finally, measuredensity input matrix. model density matrix seendegree agreement voters lobby. Hence, worth investigatewhether high low density leads computational tractability.1.2 Parameter Relationsvarious relations parameters values above. instance, columnscontaining majority 1s safely removed (also implying positive gap valuescolumns). implies input matrix least many 0s 1s, followsleast one row least half entries 0s. Hence,2t. addition, input matrix contains column consisting 0s,one modify d(n + 1)/2e rows, implying corresponding Lobbying instance1. Christian et al. (2007) argued seldom exceeds 20.2. Clearly, lobbying d(n + 1)/2e voters, is, modifying d(n + 1)/2e rows input matrix yields alwaysdesired solution, making d(n + 1)/2e trivial upper bound k.411fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger(even constant parameter values)LOGSNP-hardmaximumgap value gNP-hardmaximum number1s per rowbelow-guaranteeparameter k 0(s, k 0 )W[2]-hardnumberk rowsmodify(s, k)(s, g)(m, g)numbern rows(m, k)(k, k 0 )ILP-FPT(m, k 0 )polynomial kernel(s, n)trivial FPT(parameters provide upper boundsinput size)maximum number0s per rownumbercolumns(m, n)FPT(fixed-parameter tractable)(t, n)Figure 1: Parameterized complexity Lobbying relations parametersconsidered paper. arc x means functionf x f (y). omit combined parameters one component upperbounded function component, example (n, k) omitted,k n. ILP-FPT means fixed-parameter tractability basesformulation integer linear program.yes-instance k d(n + 1)/2e. Also, assume n otherwisecolumn consisting 0s trivial input instance since wouldcheck whether k d(n + 1)/2e. relations parameterscombinations considered paper illustrated Figure 1.Finally, remark article focus plain lobbying multiplereferenda scenarios. leave considerations fine-grained aspects lobbyingprocess (such allowing different forms modifying input matrix) natural nextstep future work.412fiA Multivariate Complexity Analysis Lobbying Multiple Referenda1.3 Related Workcentral point reference work Christian et al. (2007) whose key resultproof W[2]-completeness Lobbying respect number k. Erdelyi,Hemaspaandra, Rothe, Spakowski (2007) generalized Lobbying weighted scenario showed efficient greedy algorithm achieves logarithmic approximationfactor (1 + ln(m d(n + 1)/2e)) weighted case. Moreover, showed essentially better approximation ratio proven algorithm. Later, modelslobbying probabilistic environment proposed Binkele-Raible, Erdelyi, Fernau,Goldsmith, Mattei, Rothe (2014), providing (parameterized) hardness tractabilityresults; interpret lobbying form bribery.special case combinatorial reverse auction problem (Sandholm, Suri, Gilpin,& Levine, 2002), optimization version Lobbying relevant combinatorial marketsmulti-agent systems. combinatorial reverse auctions, different itemsbuyer wants acquire lowest cost sellers. precisely, buyer wantsamount units item, U = (u1 , u2 , . . . , um ). seller submitsmany goods item, (i1 , i2 , . . . , im ) price pi wouldsell. goal minimize cost acquiring required amount unitsitem. easy see translate lobbying problem combinatorial reverseauction problem: issue j corresponds item j. buyers requirementitem j gap value corresponding column, uj := gj , j {1, . . . , m}. rowcorresponds seller offer ij := 1 Ai,j , j {1, . . . , m} price pi := 1.Lobbying also closely related bribery judgment aggregation (Baumeister, Erdelyi,& Rothe, 2011) judges submit binary opinions different propositionsgoal bribe judges possible order obtain certain outcome. Lobbyinginstance formulated equivalent instance bribery judgment aggregationproblem using premise-based procedure. precisely, given binary matrix A,propositional variable vj corresponds column j, judge corresponds rowjudgment set consisting variables vj satisfying Ai,j = 1, agenda consistspropositional variables premises conclusions. goal modifyingrows possible order 1s 0s column equivalentbribing judges possible order possible variables approvedhalf judges.Finally, refer survey articles discussion importance parameterizedcomplexity results context artificial intelligence (AI) (Gottlob, Scarcello, & Sideri,2002; Gottlob & Szeider, 2008) voting (Betzler, Bredereck, Chen, & Niedermeier, 2012).1.4 Contributionsinitiate systematic parameterized multivariate complexity analysis Lobbying problem. contribute theoretical well empirical side. Seepreliminaries Section 2 definitions parameterized complexity classes like.complexity results summarized Table 1. Let us sketch highlights.Section 3, show Lobbying remains NP-hard = 3 k 0 = 1. Thus,hope fixed-parameter tractability respect parameters k 0 .Moreover, special highlight work show even gap parameter g413fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerk0gk0gknILP-FPT (Thm. 9, Cor. 2)FPT (Thm. 10)(2m )2.52 +o(2 ) n(g + 1)m n23: NP-c (Thm. 1)FPT (Cor. 3)2: P (Thm. 6)NP-c(g + 1)4s n2 + 16g(Thm. 1) XP, FPT const. gFPT (Prop. 2)02g+12k2 (Thm. 11)2nW[2]-hLOGSNP-c (Thm. 2)W[2]-cakna. (Christian et al., 2007)Table 1: Summary results. parameter combination (row column) entriesindicate whether Lobbying fixed-parameter tractable (FPT), fixed-parametertractable based formulation integer linear program (ILP-FPT), polynomialtime solvable constant parameter values (XP), W[2]-hard (W[2]-h), W[2]complete (W[2]-c), LOGSNP-complete, meaning completeness class limitednondeterminism lying P NP constant parameter values (LOGSNPc), NP-complete even constant parameter values (NP-c). Entries maindiagonal represent results respect single parameters. Furthermore,(m, n), (t, n), (s, n), problem kernels polynomial sizeparameters naturally bound input size (see Figure 1). (m, k 0 )aware kernel size bounds. parameter combinations above,reasonable complexity-theoretic assumptions, cannot polynomialsize problem kernel (see Section 4).equal one, Lobbying remains intractable sense completelimited nondeterminism class LOGSNP (Papadimitriou & Yannakakis, 1996) (also seesurvey Goldsmith, Levy, & Mundhenk, 1996). particular interestleast two reasons. First, provides first natural voting problem completeLOGSNP. Second, one far rare examples complexity classused context parameterized complexity analysis.Section 4, reveal limitations effective polynomial-time preprocessing Lobbying, is, prove polynomial-size problem kernels unlikely exist.Section 5, show Lobbying fixed-parameter tractable parametermeans describing ILP formulation 2m variables. providetwo efficient algorithms yielding provably optimal results input matricesfour columns. One two algorithms based simple greedy strategyprovides logarithmic approximation ratio cases four columns.414fiA Multivariate Complexity Analysis Lobbying Multiple ReferendaFurthermore, develop several fixed-parameter algorithms various parametercombinations show Lobbying polynomial-time solvable 2.Finally, Section 6, experimentally compare greedy heuristic, heuristic work Erdelyi et al. (2007), implementation ILP formulationproviding solutions guaranteed optimal. empirical results random datareal-world data indicate Lobbying solved efficiently.2. Preliminariesaim provide deeper understanding computational complexity NPcomplete Lobbying problem. end, employ classical complexity classes P(polynomial time) NP (nondeterministic polynomial time) (Garey & Johnson, 1979)well class LOGSNP limited nondeterminism (lying P NP) (Papadimitriou & Yannakakis, 1996; Goldsmith et al., 1996) parameterized complexity classesFPT (fixed-parameter tractability), W[2] (second level weft hierarchypresumable parameterized intractability), XP (Downey & Fellows, 2013; Flum & Grohe,2006; Niedermeier, 2006). Throughout paper, denote log logarithm basetwo.2.1 LOGSNPLOGSNP introduced Papadimitriou Yannakakis (1996) precisely characterize computational complexity certain problems NP neither knownNP-complete known solvable polynomial time. LOGSNP subclassproblems NP decided polynomial time initial phase O(log2 N )nondeterministic steps, N overall input size. However, LOGSNP include problems decidable polynomial time nondeterministic phase sinceputs additional restrictions computation. Roughly speaking, one alloweduse constant number elements guessed solution.widely believed LOGSNP properly intermediate P NP. Problems complete LOGSNP polynomial-time reductions include Rich HypergraphCover (see Section 3 definition) Log Adjustment (Papadimitriou & Yannakakis, 1996), latter particular importance artificial intelligence. LogAdjustment, boolean expression conjunctive normal form r variables truthassignment given, question whether satisfying truth assignmentwhose Hamming distance log r.Alternative characterizations LOGSNP exist (Cai, Chen, Downey, & Fellows, 1997;Flum & Grohe, 2006, Sec. 15.2).2.2 Fixed-Parameter Tractability XPconcept parameterized complexity pioneered Downey Fellows (2013) (seealso textbooks: Flum & Grohe, 2006; Niedermeier, 2006). fundamental goalfind whether seemingly unavoidable combinatorial explosion occurring algorithmssolve NP-hard problems confined certain problem-specific parameters.parameter assumes small values applications, algorithm running415fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingertime exponential exclusively respect parameter may efficient.Lobbying, suggest number (potentially small) parameters. combined parameter(which vector parameters) can, sake convenience, simply seensum components.Formally, problem fixed-parameter tractable (equivalently, contained parameterized complexity class FPT) respect parameter p (equivalently, parameterized p) instance (I, p) problem solved f (p) |I|O(1) time,f solely depends p. problem solved polynomial running timedegree polynomial depends p (such |I|f (p) ), then, parameter p,problem said lie thestrictly larger (Downey & Fellows, 2013)parameterizedcomplexity class XP. Note containment XP ensures polynomial-time solvabilityconstant parameter p whereas FPT additionally ensures degree correspondingpolynomial independent parameter p.2.3 KernelizationAnother way showing fixed-parameter tractability kernelization. kernelization algorithm takes input problem instance together parameter ptransforms polynomial time instance 0 parameter p0 (I, p)yes-instance (I 0 , p0 ) yes-instance function fp0 f (p) |I 0 | f (p). function f measures size (problem) kernel (I 0 , p0 ).problem kernel said polynomial kernel f polynomially bounded. Notewell-known decidable problem fixed-parameter tractable respect parameter kernelizable (Cai et al., 1997). corresponding kernels, however,may exponential size particular interest determine problems,respect parameter(s), allow polynomial-size problem kernels (Bodlaender, 2009;Guo & Niedermeier, 2007) since total running time complexity may vary dependentkernel size. Using techniques developed Bodlaender, Downey, Fellows, Hermelin(2009) Fortnow Santhanam (2011), Szeider (2011) recently proposed examinepower kernelization several problems Artificial Intelligence. See Section 4discussion.2.4 Parameterized IntractabilityDowney Fellows (2013) also introduced framework parameterized intractability.framework, two basic complexity classes parameterized intractability W[1]W[2], problem shown W[1]- W[2]-hard providing parameterizedreduction W[1]- W[2]-hard problem problem question. parameterizedreduction problem 1 another problem 2 function f computable FPTtime function g instance (I2 , p2 ) produced f instance(I1 , p1 ) satisfies following:(I1 , p1 ) yes-instance problem 1 (I2 , p2 ) yes-instanceproblem 2 ,p2 g(p1 ).416fiA Multivariate Complexity Analysis Lobbying Multiple ReferendaW[1]-complete problems include Clique parameterized solution size (Downey &Fellows, 2013) W[2]-complete problems include Set Cover parameterizedsolution size (see Section 3.1 formal definition).problem shown NP-hard even parameter p constant, cannotcontained XP unless P = NP.3. Intractable Casessection, examine worst-case computational complexity Lobbying. BesidesNP-completeness one restricted case, also prove LOGSNP-completeness resultcase column one 1-entry missing reach majority 1s.3.1 NP-Completenesshardness reductions presented work, NP-complete variantsfollowing Set Cover (SC) problem used.Set Cover (SC)Input:family sets = {S1 , . . . , S` } universe U = {u1 , . . . , ur } elementsinteger h 0.Question: size-h set cover, is, collection h sets whose unionU?Note even 3-Set Cover (3-SC), set size three,NP-complete (Karp, 1972). order make reduction work, need let h, |S|,number occurrences every element sets fulfill following propertieswhose correctness easy see:1. add (multiple copies of) singletons family ensure |S| 2h + 1 0ensure every element appears least h sets S.2. also add new element u universe U, add h copies singleton {u }family S, set h := h + 1 ensure element appears|S| h sets S.common starting point SC reductions transform (and U)binary matrix similar way Christian et al. (2007) transformed Dominating Setinstances binary matrices. corresponding |S| |U|-matrix called SC-matrixdefined(1 uj Si ,(S, U) = (xi,j ) xi,j :=0 otherwise.Observe column j {1, . . . , |U|} 1s (|S| h) rows. makeuse SC-matrix Section 4 following theorem.instance Lobbying k d(n + 1)/2e (that is, half rowsmodified) yes-instance. Following general ideas Mahajan Raman (1999)context guarantee parameterization, investigate complexityLobbying case maximum number 1s per row bounded constant kslightly bound d(n + 1)/2e. parameterization called guarantee.417fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & WoegingerU = {1, 2, 3, 4, 5}= { S1 = {2, 4}S2 = {3, 5}S3 = {1, 2, 5}S4 = {1, 2, 3}S5 = {4, 5} }S1 :S2 :S3 :S4 :S5 :10011000210110003010100041000100501101006000001070000001k := |S| h = 3h=2Figure 2: Illustration reduction 3-SC Lobbying. Left: 3-SC instance;Right: constructed Lobbying instance. SC-matrix together twodummy rows two dummy columns (inside dashed polygon) ensureset rows selected solution size three correspondsset cover. 3-SC solution (S4 S5 ) highlighted boldfaceleft. Lobbying solution (modifying first three rows) highlightedgray backgrounds.Theorem 1. Lobbying remains NP-complete input matrices maximum number ones per row three k 0 = 1 guarantee parameter k 0 =(d(n + 1)/2e k).Proof. Obviously, given matrix k = d(n + 1)/2e 1 rows A, checkpolynomial time whether row three 1s whether modifyingk given rows makes every column 1s 0s. Hence, Lobbying = 3k 0 = 1 remains NP.NP-hardness result, describe polynomial-time reduction 3-SCLobbying row contains three 1s. reduction illustratedexample Figure 2. Let (S, U, h) denote 3-SC instance. First, compute SC-matrix(S, U), refer original rows original columns following. Second,add |S|2h+1 additional dummy rows |S|2h+1 additional dummy columns containing0s. Recall assume |S| 2h + 1 0. Finally, 1 |S| 2h + 1,change entry ith dummy column ith dummy row 1. completeconstruction set k := |S| h.original row three 1s since set three elements.dummy row exactly one 1. Further, guarantee parameter k 0 = d(n +1)/2e k = d(2|S| 2h + 1)/2e (|S| h) = 1. quota column 1s0s |S| h + 1. Since every original column 1s |S| h original rows1s dummy rows, original column 1s 0s matrix.precisely, jth original column gap value |S| h + 1 |{Si | uj Si }|. dummycolumn gap value |S| h. Hence maximum gap value g |S| h.418fiA Multivariate Complexity Analysis Lobbying Multiple ReferendaObviously, reduction runs polynomial time. Now, show (S, U, h)yes-instance 3-SC constructed matrix modified 1s0s every column changing k rows all-1-rows.part, suppose (S, U, h) yes-instance 3-SC. Let 0denote set cover size h. modifying original row corresponds setSi/ 0 , every column 1s 0s, is, least (|S| h + 1) 1s: jthdummy column gains (|S| h) 1s modified original rows another 1jth dummy row. original column gains (|S|h) 1s modified original rowsanother 1 unmodified original row, since sets corresponding unmodifiedoriginal rows form set cover.part, suppose constructed matrix 1s 0s everycolumn modifying k = |S| h rows. First, observe number modifiedrows exactly |S| h since maximum gap value |S| h. Second, dummy rowmodified: Assume towards contradiction i0 th dummy row modified. Sincei0 th dummy column one 1 matrix, namely, i0 th dummy row,column cannot get majority (|S| h + 1) 1s modification |S| h rowsincluding i0 th dummy rowa contradiction. Third, show sets correspondingunmodified original rows form size-h set cover (S, U, h). original column j 0gets exactly (|S| h) 1s modified original rows 1 dummy row.get majority (|S| h + 1) 1s, column j 0 must contain another 1 unmodifiedoriginal row. Hence, sets corresponding unmodified rows form set coversize k. shows correctness construction.Proposition 1. Lobbying remains NP-complete every constant integer value k 0 > 1below-guarantee parameter k 0 = (d(n + 1)/2e k).Proof. NP-containment follows analogously Theorem 1. show NP-hardnessconstant k 0 > 1, take SC-matrix (S, U) add x additional dummycolumns xk 0 additional dummy rows x := (|S| 2h 1)/k 0 + 2. Noteadd singletons family make sure k 0 divisor (|S| 2h 1). filladded entries follows: j {1, . . . , |U|}, set entries k 0 1 arbitrarydummy rows original column j 1. 1 j x, set entry jth dummycolumn [(j 1)k 0 + 1]th, [(j 1)k 0 + 2]th, . . ., [(j 1)k 0 + k 0 ]th dummy rows 1.Set k := |S| h.total, constructed matrix 2|S| 2h + 2k 0 1 rows |U| + x columns.quota column 1s 0s q = |S| h + k 0 . original columngap value q (|{Si | uj Si }| + k 0 1) = |S| h + 1 (|{Si | uj Si }|) dummycolumn gap value q k 0 = |S| h.reduction runs polynomial time. Now, remains show correctness.Suppose (S, U, h) set cover 0 size h. modifying original rowcorresponds set Sj/ 0 , every column 1s 0s.Conversely, suppose constructed matrix 1s 0s modifyingk rows. Using analogous reasoning proof Theorem 1,show exactly k original rows modified original rows modifiedcorrespond sets form set cover (S, U, h).419fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger3.2 LOGSNP-Completenesssection, show Lobbying instances constant maximum gap value g =1 LOGSNP-complete (Papadimitriou & Yannakakis, 1996) (see also Section 2discussion class). implies that,unless LOGSNP = P, Lobbying restricted instances constant value g cannotsolved polynomial time, hence, Lobbying parameterized g XP,unless LOGSNP = NP, Lobbying restricted instances constant value gNP-hard.Theorem 2. Lobbying instances constant maximum gap value g LOGSNP.Proof. First all, show k g (blog mc + 1), Lobbying instance (A, k)yes-instance. Recall row containing 0s least half columns(see parameter discussion Section 1). Modify row continue columnsnothing modified far. Again, row containing 0sleast half columns, one modify. repeat columntouched least once, decreasing g least one. takes (blog mc + 1) steps.Then, remove columns gap value zero. repeat procedure g timesend empty matrix, modifying altogether g (blog mc + 1) rows.follows observations Lobbying instance (A, k) solvedmodifying g (blog mc + 1) rows (independent value k). Since rowidentified O(log n) bits, certificate yes-instances problemuses O(log2 (n + m)) many bits. implies Lobbying problem belongsproblems decidable polynomial time O(log2 (n + m)) non-deterministic steps.already indicates Lobbying constant maximum gap lies somewhere PNP. show containment LOGSNP, reduce Lobbying constant maximum gap LOGSNP-complete Rich Hypergraph Cover problem (Papadimitriou& Yannakakis, 1996) polynomial time.Rich Hypergraph Cover (RHC)Input:family sets = {S1 , . . . , S` } universe U = {u1 , . . . , ur } evennumber r elements, |Sj | r/2 Sj , integer h 0.Question: subset U 0 U size h non-empty intersectionevery set Sj S?Let (A {0, 1}nm , k) input instance Lobbying constant maximum gapvalue g. First, column j {1, . . . , m}, let Zj set rows 0scolumn j let gj gap value column j, is, number missing 1smake column j 1s 0s. assume (A, k) non-trivial, is,column consists 0s gap values positive. Now, consider possiblesize-(|Zj | gj + 1) subsets row set Zj . set X rows intersectssubsets, modifying rows X make column j 1s 0s.exploit observation construct instance RHC (A {0, 1}nm , k).420fiA Multivariate Complexity Analysis Lobbying Multiple Referendarow {1, . . . , n}, add element ui universe U. column j{1, . . . , m}, add family possible size-(|Zj | gj + 1) subsets elementsset {ui | Zj }. say newly added subsets correspond column j. Letsolution size h equal k. completes reduction.Since g constant ng different subsets added S, reductionruns polynomial time. remains show correctness, is, (A, k) yes-instanceLobbying constructed instance (S, U, h) yes-instance RichHypergraph Cover.part, assume (A, k) yes-instance. Let R0 set rowssize k modifying makes every column 1s 0s. LetU 0 = {ui | R0 } set corresponding elements. show U 0 intersectsevery set S. Suppose sake contradiction setU 0 = . construction subsets S, let set correspond column j and,hence, |S | = |Zj | gj + 1. R0 contain (gj 1) rows Zj makescolumn j 1s 0sa contradiction.part, assume (S, U, h) yes-instance. Let U 0 set elementssize h intersects every set S. Let R0 = {i | ui U 0 } setcorresponding rows. show modifying rows R0 results matrixevery column 1s 0s. Suppose sake contradictioncolumn j many 1s 0s modifying rows R0 . means|Zj R0 | gj 1, hence Zj \ R0 contains least |Zj | gj + 1 rows. Thus,possible find size-(|Zj | gj + 1) set elements {ui | Zj \ R0 } Zjintersect U 0 contradiction.consequence proof, assume non-trivial instanceLobbying fulfills k < g (blog mc + 1). try combinations k rowsmodify, check whether every column 1s 0s,obtain algorithm solving Lobbying O(ng(dlog me+1) m) time. Now, supposeLobbying constant g NP-hard, implying polynomial-time reductionNP-complete problem P Lobbying constant g. wouldn = |I|O(1) = |I|O(1) constructed Lobbying instance |I| inputsize problem P. Thus, P would decidable |I|O(log |I|) time, implying followingcorollary.Corollary 1. Lobbying instances constant maximum gap value g NP-hardunless problems NP solved |I|O(log |I|) time, |I| size input.Next, show Lobbying LOGSNP-hard even column needs oneadditional 1 reach majority 1s, is, g = 1.Theorem 3. Lobbying instances maximum gap value g = 1 LOGSNP-hard.Proof. reduce polynomial time Rich Hypergraph Cover (RHC) Lobbying maximum gap value g = 1. definition RHC already given proofTheorem 2.Consider arbitrary RHC instance (S, U, h) |S| = ` |U| = r. alreadymentioned Papadimitriou Yannakakis (1996), assume h blog `c + 1421fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerotherwise (S, U, h) trivial yes-instance: Since set contains least halfelements U, one element appears least half setsS. Add solution element appears least half subsets deletesets contain element, repeat. Now, let w := max(dlog `e + 2, dlog re).implies r/2 2w1 , h w 1 2w 8` + 2r, is, 2w upper-boundedpolynomial ` r. Furthermore, let ~vi 1 2w 1 enumeration0/1-vectors length w exception all-zero vector. every vector ~vi ,let V(i) denote set ~vi0 (1 i0 2w 1) inner product ~vi ~vi0 odd;easily seen |V(i)| = 2w1 .Now, ready construct instance (A, k) Lobbying. Add matrixone element row element ui U one so-called dummy row i0 0/1vector ~vi0 (1 i0 2w 1) length w except all-zero vector. total number nrows r + 2w 1, odd, r even. quota column1s 0s q = r/2 + 2w1 . Let matrix total = ` (2w 1)columns, one column c(j,z) pair (j, z) 1 j ` 1 z 2w 1. fillentries follows: let column c(j,z) 0 element row correspondingset Sj contains element ui , 1 otherwise. Further, let column c(j,z) 0s q |Sj |arbitrarily chosen dummy rows i0 ~vi0 V(z) (that is, inner product ~vi0 ~vz odd),1s remaining dummy rows. Note choice w implies |Sj | q0 q |Sj | = r/2 + 2w1 |Sj | 2w1 enough dummy rows i0~vi0 V(z). way, fix entries matrix column exactlyq 1 ones q zeros, means maximum gap value g equals one.Finally, set parameter k h. completes reduction. Obviously, runspolynomial time. remains show RHC instance (S, U, h) yes-instanceconstructed Lobbying instance (A, k) yes-instance.part, assume RHC instance (S, U, h) yes-instance,certified subset U 0 size h = k. construction matrix A, modifyingelement rows corresponding elements U 0 makes every column c(j,z) gain leastone additional 1.part, assume modifying k rows matrix results matrixcolumn 1s 0s. Let R0 set modified element rows,define = {d1 , d2 , . . . , dy } d1 , . . . , dy modified dummy rows. Thus,k = h w 1. Let U 0 = {ui | R0 } set elements correspondelement rows R0 . sake contradiction, suppose set Sjintersect U 0 . Then, every 1 z 2w 1, column c(j,z) 1selement rows R0 . show even column c(j,z) 1severy dummy row D. order find column, first observe standardlinear algebra exists vector ~vz (1 z 2w 1) simultaneously satisfiesequations ~vdi ~vz = 0 finite field size two 1 y. (The equation systemhomogeneous, dimension underlying space w, w 1constraining equations.) Then, definition, none vectors ~vd1 , . . . , ~vdy containedset V(z). Thus, column c(j,z) 1s dummy rows d1 , . . . , dy contradictionsince c(j,z) gain additional 1 modifying rows R0 D.422fiA Multivariate Complexity Analysis Lobbying Multiple Referenda4. Limits PreprocessingEfficient preprocessing data reduction techniques key importance trying(exactly) solve NP-hard problems (Guo & Niedermeier, 2007); also refer Szeider(2011) general account showing limits preprocessing AI problems.section, prove almost fixed-parameter tractability results stated Table 1,Lobbying admit, reasonable complexity-theoretic assumption, efficientpreprocessing algorithm formalized polynomial kernelization parameterized algorithmics. sufficient assumption almost known lower bounds kernelizationNP * coNP/poly; known NP coNP/poly would imply collapse polynomialhierarchy third level (Yap, 1983). One way showing non-existence polynomial kernels give so-called polynomial time parameter transformationNP-hard problem already shown unlikely admit polynomial kernel (Bodlaender,Thomasse, & Yeo, 2011). polynomial time parameter transformation parameterized reduction required computable polynomial time parameterinstance one reduces polynomially upper-bounded parameterinstance one reduces from.prove Lobbying admits neither polynomial-size kernel respectcombined parameter (m, k) respect n. simple observations relations parameters, two results imply non-existence polynomial kernelsparameters parameter combinations listed Table 1. Recall Figure 1parameter discussion Section 1 details parameter relations. casesLobbying NP-hard even parameters constants (see s, k 0 , (s, k 0 )),cases parameters bounded functions depending n (see g, k, k 0 , n,combinations them) parameters bounded functions dependingk (see t, m, g, k, combinations them). (m, n), (t, n), (s, n)problem kernels linear ((m, n) (t, n)) polynomial ((s, n)) size,parameters naturally bound input size. question whether polynomial kernels remains open parameters (m, k 0 ) (t, k 0 ), equivalent respectquestion.prove conditional non-existence result Lobbying parameterized (m, k),employ incompressibility result Set Cover due work Dom, Lokshtanov,Saurabh (2009).Theorem 4. Unless NP coNP/poly, Lobbying admit polynomial-size problem kernel respect combined parameter (m, k), is, number columnscombined number rows modify .Proof. Dom et al. (2009) showed that, unless NP coNP/poly, Set Cover (SC)admit polynomial kernel respect combined parameter (|U|, h). showresult transfers Lobbying respect (m, k) describe polynomial timeparameter transformation SC respect (|U|, h).Let (S, U, h) SC-instance. Recall adding multiple copies setchange answer instance, assume without loss generalityelement occurs least h |S| h sets. First, compute SC-matrix(S, U), refer original rows original columns following,423fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerinvert 0s 1s. Second, add |S| 2h + 1 dummy rows containing 0s. every originalcolumn j, invert |S| |{Si : uj Si }| h + 1 0s arbitrary dummy rows 1s.Add one dummy column containing 1s dummy rows, 0s elsewhere. Finally, letk := h.Note number 0s dummy column |S|, number 0scolumn |S| h + 1, total number rows 2|S| 2h + 1. Thus, gaporiginal column exactly one gap dummy column h.show (S, U, h) yes-instance Set Cover constructedmatrix modified 1s 0s every column changing k = hrows all-1-rows.part, assume (S, U, h) yes-instance. Let 0 size-hset cover. Modifying (original) rows corresponding sets 0 results matrixcolumn 1s 0s: Since h modified original rows0 dummy column, dummy column gains h additional 1s. Furthermore,original row gets least one additional 1, 0 set cover.part, suppose constructed instance yes-instance. meansmodifying exactly k = h rows results matrix column 1s0s since maximum gap value h. Since gap value dummy column hdummy row contains 0 dummy column, solution cannot modify dummyrow. Since gap value original column exactly one, sets correspondingmodified rows Lobbying solution must form set cover.reduction polynomial time parameter transformation SC parameterized |U| h Lobbying parameterized k: matrix resultingLobbying instance |U| + 1 columns ask modify k = h rows. SinceLobbying contained NP since SC NP-hard, polynomial kernel Lobbyingrespect (m, k) would imply polynomial kernel SC respect (|U|, h)possible unless NP coNP/poly (Dom et al., 2009).Lobbying trivially fixed-parameter tractable respect number nrows, unlikely polynomial-size problem kernel parameterization.Theorem 5. Unless NP coNP/poly, Lobbying admit polynomial-size problemkernel respect number n rows (voters).Proof. Observe polynomial time parameter transformation proofTheorem 4 number rows constructed input matrix Lobbyingtwice number sets SC instance. Hence, SC admit polynomialkernel respect number sets (unless NP coNP/poly), Lobbying alsoadmit polynomial kernel respect n (unless NP coNP/poly). Next,show that, indeed, SC admit polynomial kernel respect numbersets.SC strongly related Hitting Set (HS) problem, which, given familysets SH universe UH integer h 1, one asked choose set U 0 UHsize h set SH non-empty intersection U 0 . Dom et al.(2009) showed that, unless NP coNP/poly, HS admit polynomial kernelrespect |UH |.424fiA Multivariate Complexity Analysis Lobbying Multiple Referendasimple polynomial time parameter transformation HS parameterized|UH | SC parameterized |S|: set Si SH HS instance addelement si universe set U SC instance. Finally, element e UHHS instance add set set family SC instance contains element siSi SH e Si . easy verify (SH , UH , h) yes-instance HS(S, U, h) yes-instance SC.5. Tractable Casessection, contrasting intractability results previous sections, demonstrate Lobbying efficiently solvable practically relevant cases. end,study numerous quantities (that is, parameters) influence computationalcomplexity Lobbying. instance, Section 3 seen Lobbying remainsNP-hard input matrices three 1s per row (Theorem 1)here showbecomes polynomial-time solvable matrices two 1s per row. Moreover,show fixed-parameter tractability Lobbying respect number columns(issues), four columns even linear-time solvable. Finally, shed lightseveral structural restrictions input matrix make solving Lobbyingfeasible.Note instances rows (voters) tractable, alreadynaive brute-force approach simply tries modify size-k subsets rows leadsalgorithm FPT running time respect parameter number n rows.Proposition 2. Lobbying solvable O(2n m) time.5.1 Two Ones per Rowfollowing result complements Theorem 1, altogether yielding complexity dichotomycontainment P NP-completeness respect maximum number1s per row.Theorem 6. Lobbying restricted input matrices two 1s per row, is,2, solvable O(nm log m) time.Proof. idea algorithm use special structure rows modifiedfact row two 1s. may modify k d(n + 1)/2e rowstrivially answer yes; otherwise column requires b := d(n + 1)/2e k additional1s outside k modified rows order reach d(n + 1)/2e 1s. algorithm seekselection rows (1) column b 1s inside selected rows (2)least k unselected rows left k modified. Modifyingk unselected rows gives total least b + k = d(n + 1)/2e 1s column. Notesolution k modified rows requires column initially contains leastb 1s; otherwise safely answer no.see problem finding desired selection rows b 1s per columncomes certain matching problem auxiliary graph G, constructnext. graph G gets one vertex column, add G edge rowcontains 1s corresponding two columns (a vertex pair may connected425fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingermultiple edges). b-matching graph subset edges vertexendpoint b edges subset. final algorithm essentially comecomputation maximum cardinality b-matching G. clarity, however, let usfirst show b-matchings G solutions lobbying question interact.First, assume exists solution Lobbying instance. Let R setrows let R choice k rows modifying gives columnleast d(n+1)/2e 1s. (Should R smaller k rows could added withoutharm.) follows rows, say, R0 = R\R , contribute least b = d(n+1)/2ek1s column. R0 get large b-matching G follows: columnarbitrarily mark b rows 1 column (so row markedtwice since 2). Let R0 denote set marked rows, let M2 denoteset rows marked twice. observe size b |M2 | sincemarked b times used two marks row M2 . Considering edges Gcorrespond elements M2 easy see vertex incidentb (we marked b times per vertex, twice marked rowsconsidered). Thus edges corresponding M2 constitute b-matching G.Second, consider set M2 rows correspond edges maximumb-matching G, is, vertex incident b edges; clearly |M2 | |M2 |.greedily add M2 rows column exactly b 1s created setrows. (This possible since column contains least b 1s; otherwise answeredbeginning.) let denote obtained set rows; i.e., M2added ones. observe |M | = b |M2 |, since add b 2|M2 | rowsM2 : need b 1s total, M2 contributes 2|M2 | 1s, greedily added rows giveone 1 each. follows|M | = b |M2 | b |M2 | = |M | |R0 | = |R| k.Thus, least k rows left outside modified all-1 rows.Together rows gives required number d(n + 1)/2e = k + b 1scolumn.Thus, solution gives rise b-matching maximum b-matching leadssolution (if one exists). algorithm therefore begins computing maximum bmatching G. Then, previous paragraph take corresponding rowsgreedily extend set get b 1s column. Finally, leaves least k rowsunused modifying k must give solution (as argued). Crucially,solution, showed gives sufficiently large b-matching G.computation maximum b-matching costly part; according Gabow(1983), maximum b-matching computed O(nm log m) time (see also Schrijver(2003, Chapter 31) general notion b-matchings).5.2 Columnsalready mentioned introductory section, Christian et al. (2007) pointednumber issues multiple referenda rarely exceeds value 20. makeswell-motivated, practically relevant parameter leads question influencescomputational complexity Lobbying. subsection, demonstrate426fiA Multivariate Complexity Analysis Lobbying Multiple Referendasolve Lobbying efficiently 4 (by matching-based greedy algorithm).Moreover, formulate Lobbying integer linear program number variablesbounded function deduce fixed-parameter tractability this.findings complemented no-polynomial-kernel result Section 4 (Theorem 4)experimental evaluations Section 6. start matching-based linear-timealgorithm Lobbying.Theorem 7. input matrices four columns Lobbying solvable lineartime.Proof. modify matching-based algorithm Theorem 6 cover cases4. = 1 = 2, modification needed. cases = 3 = 4observe first matching-based algorithm asked modify k rowsbi 1s column {1, . . . , m}.Now, = 3 input matrix contains c all-1 rows, removeexecute matching-based algorithm Theorem 6 resulting matrix (whereevery row contains two 1s) ask achieve d(n + 1)/2e c 1s column.case = 4 claim optimal solution onerow three 1s modified. prove that, consider solution modifying minimumnumber rows. assume rows last modifiedconsider situation row three 1s modified. suppose withoutloss generality row vector 0111 modified. positive gap firstcolumn whenever row 0 column, 0111 row. Hence,number 0s column least d(n + 1)/2e yet satisfied. numberd(n + 1)/2e, otherwise would d(n + 1)/2e row vectors 0111columns 2, 3, 4 would satisfied given matrixa contradiction. Thus,gap first column 1 enough modify row vector 0111 satisfyfirst column. another row three 1s modified, say row vector1011, one together 0111 row vectors would make gap valuesthird fourth columns negativea contradiction.summary, solve case = 4 branching five cases: One0111 row modified, one 1011 row modified, one 1101 row modified, one 1110 rowmodified, row three 1s modified. Then, modify appropriate rowremove rows containing least three 1s. count j number cj 1scolumn j removed rows. Finally, ask matching-based algorithm modifyk 1 (or k, according chosen branch) remaining rowscolumn j contains d(n + 1)/2e cj 1-entries. running time follows Theorem 6.attack matrices four columns, next develop simple greedystrategy case. Indeed, provides optimal results input matricesfour columns. show logarithmic-factor approximation algorithmunlimited number columns. Section 6, demonstrate excellent heuristicproperties.Let {0, 1}nm input matrix. Recall gap gj column j {1, . . . , m}number additional 1s column needs gain majority 1s. Let G := {gj |j {1, . . . , m}} set different gap values, let hGi sequence elements427fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & WoegingerG decreasing order, let hGij denote jth element hGi. Further, letgain(R) gain vector row vector R respect matrix A, definedgain(R) := (z1 , z2 , . . . , z|G| ),zj denotes number zeros row R columns gap value hGij . comparetwo gain vectors, use lexicographic order . row R highest gain Rgreatest element respect , is, every row R0 matrix holdsR0 R.present algorithm MaxGapZeros employs greedy heuristic deciderows modify. basic idea repeatedly choose row vector highest gainset 1s columns satisfied. Note gap valuecolumn may change one row modified. Hence, row vectors gain may also change.Algorithm 1 MaxGapZeros (A {0, 1}nm )compute gap values columnscolumn positive gap value existscompute gain vector row vectormodify arbitrary row vector highest gainupdate gap values columnsreturn modified rowsTheorem 8. Given input matrix n rows, columns, maximum gap g, MaxGapZeros finds solution size dlog g O(m n2 ) time; even findsoptimal solution Lobbying O(n2 ) time 4.Proof. First, show running time bound. Computing gap values columnstakes O(mn) time MaxGapZeros performs d(n + 1)/2e iterations.iteration computing gain vectors finding row maximum gain takes O(mn)time, sort columns according gap values (positive integerssize n) O(m+n) time using counting sort, compute row-wise gain vectorscomparing current maximum gain vector O(mn) time. Updating gapvalues takes O(m) time. Altogether, MaxGapZeros runs O(mn + n(m + n + mn + m)) =O(m n2 ) time.Second, show logarithmic approximation factor > 1. MaxGapZeros takesiteration row maximum number 0s columns maximum gap value.show that, this, MaxGapZeros reduces maximum gap value onedlog iterations.Let mg denote number columns gap value g, g maximum gapvalue columns. g > 1, always row strictly (mg /2)0s columns gap value g, otherwise matrix restricted columnsgap value g would contain many 0s 1s. MaxGapZeros select rowgain vector every row less (mg /2) 0s columns gap value gsmaller. Hence, maximum gap reduced one dlog(mg )e dlogiterations.428fiA Multivariate Complexity Analysis Lobbying Multiple Referendag = 1, possible row strictly (mg /2) 0s,matrix restricted columns gap one many 0s 1s. However, ithiteration MaxGapZeros satisfies least mg 2i columns, since always rowcontains least many 0s 1s columns gap one. Hence, dlog(mg )e iterations,one column gap one survives. Thus, showing actually MaxGapZerossatisfies mg /2 columns first iteration MaxGapZeros satisfiesmg /4 columns second iteration, show total MaxGapZeros needs dlog(mg )eiterations satisfy columns gap one. Assume MaxGapZeros satisfies exactlymg /2 columns first iteration. Without loss generality, let row selectedMaxGapZeros first iteration contain 1s first mg /2 columns gap one.Since columns gap one, must 0s 1s remaining rowsmatrix restricted columns. Thus, row (mg /4) 0scolumns gap one selected MaxGapZeros second iteration. Hence,columns maximum gap one satisfied dlog(mg )e dlog iterations.Summarizing, MaxGapZeros terminates dlog g iterations. Clearly, everysolution minimum size must contain least g rows.Third, show MaxGapZeros finds optimal solution 4. input matrices one two columns, MaxGapZeros clearly finds solution minimumsize. remainder proof, show MaxGapZeros also finds minimum-sizesolution input matrix contains three four columns. end, analyzestepwise modification input matrix MaxGapZeros comparestepwise modification input matrix following minimum-size solution.multiset row vectors X, let A(X) denote matrix resultingmodification row vectors X A, is, replacing row vectors Xnumber all-1-rows. Furthermore, hXi denotes sequence row vectorsX hXii denotes ith element sequence.analyze stepwise modification process follows: Let hRMGZ sequencerow vectors modified MaxGapZeros let hROPT arbitrary sequencerow vectors minimum size solution ROPT . Furthermore, let Ai matrixith row modification hRMGZ i, is, Ai := A({hRMGZ ii0 | i0 < i})gj (Ai ) denotes gap value jth column matrix Ai . Now, = 1 |RMGZ |,compare hRMGZ ii hROPT ii . Note hROPT ii run sequencesince show hRMGZ ii0 = hROPT ii0 , 1 i0 < i, clear hROPThRMGZ identical first 1 positions, either contain least elementsnone. comparing hRMGZ ii hROPT ii , whenever hRMGZ ii 6= hROPT ii replacereorder elements hROPT afterwards hRMGZ ii0 = hROPT ii0 , 1 i0 i, and,invariant, hROPT still corresponds solution minimum size. impliesAi = A({hRMGZ ii | i0 < i}) = A({hROPT ii | i0 < i}).following, assume 0 hRMGZ ii0 = hROPT ii0 , i0 < i. two rowvectors r1 , r2 {0, 1}m write r1 r2 r1 [x] = 0 r2 [x] = 0, 1 x m.easy see @i00 hRMGZ ii hROPT ii00 hRMGZ ii 6= hROPT ii00 ,MaxGapZeros would selected hROPT ii00 instead hRMGZ ii already iteration i.1 |hRMGZ i|, hRMGZ ii 6= hROPT ii , least one following fourcases occurs. Note case hRMGZ ii all-0s row subsumed Case 1.429fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & WoegingerFurthermore, three columns Case 2 also subsumed Case 1. Cases 24 implicitly assume Case 1 apply.Case 1. i0 hROPT ii0 hRMGZ ii . i00 > hROPT ii00 = hRMGZ ii ,swap ith i00 th element hROPT i. Otherwise, replace i0 th elementhROPT hRMGZ ii swap ith i0 th element hROPT i0 6= i.Case 2. hRMGZ ii contains exactly three 0s. Without loss generality let hRMGZ ii0s first three columns. implies last columns gap valuelarger first three columns gap values, is, gx (Ai )g4 (Ai ), x {1, 2, 3}. Since Case 1 apply, every position i0 holdshROPT ii0 0 column 4, least one 1 column sinceotherwise greedy algorithm would selected all-0-row hROPT ii0 step i.Thus, g4 (Ai ) positions safely replace ithelement hROPT hRMGZ ii .Case 3. hRMGZ ii contains exactly two 0s. Without loss generality, hRMGZ ii 0sfirst two columns. Due design MaxGapZeros holds first twocolumns gap values least large last two columns gap values, is,gx (Ai ) gy (Ai ), x {1, 2}, {3, 4}. position i0 hROPThROPT ii0 also 0s first two columns, otherwise hRMGZ ii hROPT ii0 ,possible since MaxGapZeros would selected hROPT ii0 insteadhRMGZ ii already iteration i. Thus, least g1 (Ai ) positions i1hROPT ii1 containing 1 second column least g2 (Ai ) positions i2hROPT ii2 containing 1 first column. Moreover, since Case 1apply and, hence, hROPT ii0 6 hRMGZ ii every i0 > i, corresponding rowvectors least two 0s. g1 (Ai ) = g2 (Ai ), approximation guaranteeMaxGapZeros also needs dlog 4e g1 (Ai ) = g1 (Ai ) + g2 (Ai ) rows.Thus, safely replace i0 th element hROPT hRMGZ ii0 i0 i.g1 (Ai ) > g2 (Ai ), must position i0 hROPT ii0contains 0 column {3, 4}, column already satisfied matrixA({hROPT ii00 | i00 < i0 }). position hROPT ii containing two0s: one 0 column one 0 column 1 2, replace th elementhROPT hRMGZ ii swap ith th element hROPT 6= i. Otherwise,every position holds hROPT ii contains 0 columnhROPT ii contains exactly three 0: one 0 column 3, one 0 column 4, one 0column 1 2. implies column 3 column 4 positivegap matrix A({hROPT ii00 | i00 < i0 }). Thus, replace i0 element hROPThRMGZ ii swap ith i0 th element hROPT i0 6= i.Case 4. hRMGZ ii contains exactly one 0. show casetwo columns positive gap values Ai . Let j column hRMGZ iione 0. column j, let R0 (j) index set rows containing 0column j. Consider column j 0 positive gap value. Ai contains rows0s j j 0 , is, R0 (j ) R0 (j 0 ) = , otherwise greedyalgorithm would selected rows. Thus, gap values j j 0 mustone, implying maximum gap value one. matrix contains least430fiA Multivariate Complexity Analysis Lobbying Multiple Referendathree columns maximum gap one, must row containing 0sleast two columns selected greedy algorithm.Thus, two columns positive gap Ai . Since MaxGapZerosoptimal two columns, safely replace i0 th element hROPThRMGZ ii0 i0 i.Finally, obtain minimum-size solution ROPT ROPT = RMGZ .five-column input matrices algorithm may provide optimalsolution. example, optimal solution 5 6-matrix000011001101010101101100110100contains two rows (row two three) algorithm may output three rowspossible solution since first three row vectors highest gain (1, 2). Notefirst column gap 2 columns gap 1. MaxGapZeros decidesmodify first row two rows, needs two rows satisfycolumns.Theorems 7 8 show case four issues Lobbying solvedefficiently. contrary, parameterized number columns,theoretical fixed-parameter tractability result; based famous theorem mathematical programming Lenstra (1983) improved Frank Tardos (1987)Kannan (1987). Roughly speaking, says solving integer linear programsnumber variables depending solely parameter p fixed-parameter tractable respect p. However, (worst-case) upper bound running time correspondingalgorithm impractical classification nature only. Nevertheless, experimentedpractical usefulness subsequent ILP formulation (see Section 6).Theorem 9. Lobbying fixed-parameter tractable respect parameter numbercolumns.Proof. describe integer linear program (ILP) 2m variables solvesLobbying.3 Then, Lobbying fixed-parameter tractable respect m,ILP variables L input bits solved O(2.5+o() L) time (Kannan, 1987;Frank & Tardos, 1987).2m different rows binary matrix columns. Let r1 , . . . , rlarbitrary ordering pairwise different rows A, 1 l let c(ri )number occurrences ri . 1 l 1 j let Bj (ri ) = 1jth column row ri value 0 and, otherwise, Bj (ri ) = 0. 1 l introduce3. Dorn Schlotter (2012) already mentioned ILP Swap Bribery problem couldadapted Lobbying.431fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerinteger variable bi , 0 bi c(ri ); value bi indicates often onemodify row type ri . ILP formulated follows. Recall gj numbermissing 1s make column j 1s 0s k number rows modify.lXbi k,(1)i=10 bi c(ri )gjlXbi Bj (ri )1 l,(2)1 j m.(3)i=1Constraint (1) ensures k rows modified. Constraint (2) ensuresamount rows modified type ri available input matrix.Constraint (3) ensures column j least gj rows 0-entry jthposition modified. Hence, ILP provides solution Lobbying kmodified rows.Since 2t, fixed-parameter tractability (Theorem 9) implies following.Corollary 2. Lobbying fixed-parameter tractable respect parameter maximum number zeros per row.5.3 Dynamic Programming Columns Small Gapuse reduction proof Christian et al. (2007), immediately gain W[2]hardness result respect maximum gap value g Lobbying. Furthermore,discussed Section 3.2, Lobbying LOGSNP-complete even g 1. So, reasonablecomplexity-theoretic assumptions, neither NP-hard XP constant g.section, prove tractability Lobbying respect parameter g combiningeither number columns (Theorem 10) even maximum number1s per row (Corollary 3).Theorem 10. Lobbying solvable O((g + 1)m n2 m) time.Proof. Let {0, 1}nm k N Lobbying input instance let g1 , g2 , . . . , gmcorresponding gap values A. solve problem via Dynamic Programmingemploying boolean table [i, l, g1 , . . . , gm ], {0, . . . , n}, l {0, . . . , k},gj {0, . . . , gj } j. entry [i, l, g1 , . . . , gm ] set True possible reducegap column j least gj modifying exactly l rows first rows A.Otherwise set entry False. Clearly, (A, k) yes-instance Lobbying[n, k, g1 , . . . , gm ] = True.initialize table, set [0, 0, g1 , . . . , gm ] True gj = 0 jFalse otherwise. compute entry [i, l, g1 , . . . , gm ] check two cases: First, set[i, l, g1 , . . . , gm ] True [i 1, l, g1 , . . . , gm ] = True (treating case row0 ]=contained solution). Second, set [i, l, g1 , . . . , gm ] True [i1, l1, g10 , . . . , gmTrue gj0 = gj row 1 column j gj0 = max{0, gj 1} row 0column j. none two cases applies, set [i, l, g1 , . . . , gm ] = False.432fiA Multivariate Complexity Analysis Lobbying Multiple ReferendaTable (g + 1)m (k + 1) (n + 1) entries table entry computedO(m) time, resulting overall running time O((g + 1)m k n m).Finally, harvest fixed-parameter tractability result Lobbyingsimply relating parameter values.Corollary 3. Lobbying solvable O((g + 1)4s n2 + 16g m) time.Proof. First, provide useful inequality (functions of) parameter values.Count number 1s input matrix. Since row,ns whole matrix. addition, least n/2 gcolumn and, hence, total number 1s least (n/2 g)m. follows(n/2 g)m ns.Now, employ derived inequality deduce fixed-parameter tractabilitycombined parameter (g, s). g n/4, nm/4 (n/2 g)m ns, hence 4suse O((g + 1)m n2 ) = O((g + 1)4s n2 ) time algorithm Theorem 10.Otherwise n < 4g solve problem brute force, testing possible subsetsrows modified O(2n m) = O(24g m) time.5.4 Close Guarantee Small Gapreasonable complexity-theoretic assumptions Lobbying neither XPbelow-guarantee parameter k 0 :=d(n+1)/2ek (see Theorem 1) XP maximumgap value g columns (see Theorem 3). However, using relationsparameters brute-force algorithm Proposition 2 show LobbyingXP combined parameter (g, k 0 ). precisely, show Lobbyingfixed-parameter tractable respect k 0 g constant.0Theorem 11. Lobbying solvable O(m2g+1 22k ) time.Proof. definition k 0 follows k + k 0 n/2. Furthermore,logarithmic factor approximation (see Theorem 8) follows k g log m. Combininggives n 2(g log + k 0 ). Thus, using brute-force algorithm Proposition 2,00Lobbying solvable O(2n m) = O(22glog 22k m) = O(m2g+1 22k ) time.remains open whether Lobbying fixed-parameter tractable combined parameter (g, k 0 ) (not assuming g constant).6. Experimental Evaluation Greedy ILP AlgorithmsRecall consider number columns parameter currentlystrongest support terms parameterized complexity analysis.seldom exceeds 20 (Christian et al., 2007). Hence, section present experimental results obtained testing greedy heuristic (MaxGapZeros) ILPformulation (ILP) Section 5.2 well slightly simpler greedy algorithm (MaxZeros) Erdelyi et al. (2007). Roughly speaking, whereas MaxZeros simply picks rowmaximum number 0s, MaxGapZeros uses gain measure 0s columns higher433fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingergap value given higher attention. Thus, comparing MaxGapZeros MaxZerosevaluated effect refined gain measure.evaluated efficiency solution quality greedy algorithms, comparingexact solutions delivered ILP. Note heuristic Erdelyi et al. (2007)designed solve general weighted variant Lobbying, hence,expect MaxZeros outperform MaxGapZeros terms solution quality. However,aware algorithm solving Lobbying compare with.used Gurobi 5.0.1 (integer) linear program solver handle ILP formulation Lobbying given proof Theorem 9. Recall number variablesILP formulation depends number different rows thusupper-bounded 2m .tested algorithms large set ( 3.3 105 matrices) random instancesinstances generated actual voting records German parliament. usedtwo types random models controlled several density parameters,determining fraction number 1s number 0s. row-orientedmodel randomly chooses density row sets row entry randomequals 1 probability equal chosen density value. similarway, column-oriented approach randomly chooses density columngenerates entries column random using density value probabilitygenerating 1. Section 6.1 contains detailed description random models.Section 6.3 present experimental findings.experiments performed Intel Xeon E5-1620 3.6GHz machine64GB memory running Debian GNU/Linux 6.0 operating system. greedyheuristics implemented C++. ILP implementation uses Gurobi4 5.0.1Java API. source code including data generator freely available.56.1 Random Instance Generationmodels, row-oriented column-oriented, process creating randominstance controlled two density parameters b 0 b 1. Subsequently,describing two models detail, randomly choosing number always refersrandom number generated using i.i.d. process uniform distribution.6.1.1 Row-Oriented Modelcertain values n, m, a, b b, row-oriented model creates binarymatrix {0, 1}nm follows. row i, chooses random number diinterval [a, b]. Then, 1 j m, entry Ai,j set 1 probability di . Usingrow-oriented model, created instances combinations {0.1, 0.2, 0.3, 0.4}b {0.5, 0.6, 0.65, 0.7, 0.8} + b < 1. Since expected fraction 1s rowdi expected fraction 1s (a + b)/2, implying case + b 1high fraction columns gaps zero, required + b < 1. Thus,combination n m, created 13 instances according model. Herein,started = 10 increased 10% step, rounding nearest4. http://www.gurobi.com/5. http://akt.tu-berlin.de/menue/software/434fiA Multivariate Complexity Analysis Lobbying Multiple Referendainteger necessary (formally, dm 1.1e), larger 300. assigned n110 equidistant values within [10, 991] (formally, n n + 9). Summarizing, 33different values 110 different values n, obtaining total 47 190 instancesrow-oriented model.6.1.2 Column-Oriented ModelHere, create matrix {0, 1}nm fixed b, column columnoriented model chooses random number di [a, b]. Then, denoting maximum possible gap d(n+1)/2e gmax , model assigns 1s (1di )gmax many entries column i,0 remaining entries. Observe ensures gap column di gmaxthus expected gap column ((a+b)/2)gmax . created instances combinations {0, 0.1, 0.2, 0.3, 0.4, 0.5} b {0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1}b. Thus, combination n created 51 instances. Thereby,started = 10 increased 10% step , roundingnearest integer necessary (formally, dm 1.1e) long smaller100. assigned n 110 equidistant values within [10, 991] (formally, n n + 9). Thus21 different values 110 n, obtaining total 142 810 instancescolumn-oriented model.discarded instances containing column gap zero. Furthermore,discuss instances less 10 columns tested algorithms extremelyfast (less 0.01 seconds average) greedy heuristic computed optimal solutions99% instances.6.2 Real-World Data Generationobtain data set representing realistic binary preferences politicians use welldocumented voting records German parliament, Bundestag. Votes issuesBundestag anonymous recorded votes. Whenever party parliament5% members request it, voters decision recorded together votersname. generated instances recorded votes 2012 2013freely available www.bundestag.de:issue recorded vote became issue model.several similar issues (for example similar amendments topic)took last one.member Bundestag became voter model. Bundestagmember show abstained voting assume opinionconsistent majority party. Bundestag member leftparliament period, collect votes. (This happenedtwice.)resulted matrix 67 columns 620 rows. Approximately half columnssmall gap value (less 25) half gap values greater 90.Roughly one third columns gap values greater 150. Even maximumpossible gap value 311 occurs twice.435fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger6.2.1 Goal LobbySince lobby actions usually well-documented one cannot (easily) identifyvoters bribed, decided guess goal lobby. Recallmodel, 1 (resp. 0) column j row input matrix means voter agrees(resp. disagrees) lobby respect issue j. Hence, get input matricesmodel, need set issues lobby disagrees majorityvoters. Issues goal lobby consistent majority votersalways ignored.6.2.2 Test Seriesperformed three experiments, one randomly selected issues small gap values(g < 30), one randomly selected issues high gap values (g > 90), onerandomly selected issues without restriction. number columns{5, 10, . . . , 30} extracted 100 instances first two experiments.{5, 10, . . . , 60} generated 100 instances last experiment. covers widerange scenarios differ number issues lobby wants change wellamount changes issue needs reach majority approvals.6.3 Resultsevaluated experimental results concerning time efficiency and, greedy heuristics, additionally respect solution quality (closeness optimal solutions), is,distance derived solutions optimal one.evaluate efficiency fixed attribute values (e.g., number columns)computed average running times corresponding instances. running timesgreedy algorithms small (below 0.1 seconds average). get reliablevalues ran greedy heuristics 20 times instance stored average value.ILP algorithm solved 95% instances within five minutes. countedrunning time remaining instances five minutes get lower boundcorrect average running times ILP algorithm.evaluate optimality computed percentage optimally solved instanceswell average difference optimal number lobbied voters numbervoters lobbied heuristic solution. following, denote distanceoptimality.6.3.1 Efficiency Row-Oriented Modelexpected, heuristic algorithms much faster ILP algorithm. Whereasheuristics needed less 0.1 seconds instances 300 columns1000 rows, ILP needed ten seconds average instancesleast 150 columns least 500 rows. See Figure 3 details. Somewhat surprisingly, MaxGapZeros turned faster MaxZeros instances24 columns well instances least 100 rows. reason seemsMaxGapZeros produces smaller solutions MaxZeros allowing earlier termination(see Figure 4).436fiA Multivariate Complexity Analysis Lobbying Multiple Referenda101running time seconds1011001001011011021021030501001502002500300100 200 300 400 500 600 700 800 900 1,000number rowsnumber columnsMaxGapZerosMaxZerosILPFigure 3: Row-oriented model: Running time depending number columnsnumber rows, respectively.101009distance optimality%optimal solutions9080706050403020108765432100050100150200250300050100150200250300number columnsnumber columnsMaxGapZerosMaxZerosFigure 4: Row-oriented model: Percentage optimal solutions average distanceoptimal solution greedy algorithms, depending numbercolumns.437fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerrunning time seconds1011011001001011021011031021020304050607080901000100 200 300 400 500 600 700 800 900 1,000number columnsMaxGapZerosnumber rowsMaxZerosILPFigure 5: Column-oriented model: Running time depending number columnsnumber rows, respectively.6.3.2 Optimality Row-Oriented Modelgreedy algorithm (MaxGapZeros) performed well data set termssolution size. 50% instances optimally solved, even300 columns. contrast, simpler greedy algorithm (MaxZeros) could solveinstances optimally. distance optimality, MaxGapZeros resultsaverage distance less one whereas average distance optimalityMaxZeros results exhibits logarithmic growth respect number issuesalways greater two. See Figure 4 details.6.3.3 Efficiency Column-Oriented ModelSimilarly row-oriented model, heuristic algorithms extremely fasttested instances. instances (which less 100 columns), MaxZerosslightly faster MaxGapZeros difference average running timeMaxGapZeros MaxZeros decreased increasing number issues. See Figure 5details.6.3.4 Optimality Column-Oriented ModelSimilarly row-oriented model, MaxGapZeros computed solutions relativelyclose optimum. Whereas percentage instances 30 100columns optimally solved MaxGapZeros slightly lower roworiented model, percentage instances optimally computed MaxZerostwice high row-oriented model. contrast, distance optimality,438fiA Multivariate Complexity Analysis Lobbying Multiple Referenda101009distance optimality%optimal solutions908070605040302010876543210010203040506070809010010number columns2030405060708090100number columnsMaxGapZerosMaxZerosFigure 6: Column-oriented model: Percentage optimal solutions average distanceoptimal solution greedy algorithms depending numbercolumns.results column-oriented model behaved similarly results roworiented model. Again, average distance optimality MaxZeros results exhibitslogarithmic growth respect number issues always greater three,average distance optimality MaxGapZeros results lower onetested instances. See Figure 6 details.6.3.5 Efficiency Real-World Data SetSurprisingly, algorithms including ILP algorithm could solve every single instanceextremely fast. MaxZeros slightly faster MaxGapZeros even ILP algorithmneeded less 0.07 seconds instance. reason seems politiciansparty often vote similarly different rows matrices and,hence, ILP much less variables handle worst case (only 103instead 620). expected, instances small maximum gap values could computed(slightly) faster.6.3.6 Optimality Real-World Data SetSomewhat unexpectedly, MaxGapZeros could solve instances optimally. Recallcase random data instances similar sizes. contrast MaxGapZeros,instances MaxZeros could find optimal solution. Especially instanceshigh gap values instances without restrictions gap values,distance MaxZeross solution size optimal solution size quite large. See Figure 7Figure 8 details. Interestingly, optimal solution size equals maximum gap439fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woeginger8100distance optimality7%optimal solutions906805704603504023012001051015202530510number columns15202530number columnsMaxGapZerosMaxZerosFigure 7: Real-world data, instances low gap values only: Percentage optimal solutions average distance optimal solution greedy algorithmsdepending number columns.100100distance optimality90%optimal solutions90807060504030201080706050403020100001020304050060102030405060number columnsnumber columnsMaxGapZerosMaxZerosFigure 8: Real-world data, instances low high gap values: Percentage optimalsolutions average distance optimal solution greedy algorithms depending number columns. results instances highgap values similar.440fiA Multivariate Complexity Analysis Lobbying Multiple Referendavalue almost instances. Note cannot explanation tractabilitysince instances general still NP-hard compute; see reduction usedproof Theorem 1.6.3.7 Conclusionshowed heuristics efficient synthetic random data reasonablesize, is, 300 columns 1000 rows. Whereas greedy heuristicErdelyi et al. (2007) computes solutions relatively far away optimum,greedy algorithm computed optimal solutions instances. However, notegreedy algorithm directly designed solve Lobbying whereas algorithm Erdelyiet al. (2007) designed general weighted variant Lobbying. Somewhatunexpectedly, also exact ILP algorithm solved instances within five minutes.Even instances 37 columns 100 rows optimally solvedILP within five minutes.data set based real-world data, algorithms behaved similarsynthetic case. greedy algorithm could solve instances optimally ILP algorithm could solve instances fast.7. ConclusionLobbying studied fundamental matrix modification problem rich combinatorial structure.6 started exploiting structure terms number naturalparameterizations corresponding parameterized multivariate complexity analysis.Table 1 Section 1 summarizes results. Indeed, space investigations couldextended introducing parameters also looking parameter combinations, time ultimate goal obtain (improved) fixed-parameter tractabilityresults (Komusiewicz & Niedermeier, 2012). far, results indicate making useparameter number columns particularly promising albeit theoreticalfixed-parameter tractability result based integer linear programming could proven.found well performing greedy algorithm turns deliver provably optimal results input matrices four columns. Based positive experimentalresults, suggest algorithm current method choice solving also largerLobbying instances getting close optimal solutions.methodological side, probably innovative contribution showLOGSNP-completeness (Papadimitriou & Yannakakis, 1996) case input matricesgap value 1 columns, is, situation lobby may hopeachieve goal low cost (meaning modified rows). result particular interestsince natural LOGSNP-complete problems known since seemsfirst use tool assessing parameterized complexity parameterized problemsXP class problems NP-hard even constant parameter values.independent future interest studying parameterized complexityproblems.6. recently, Lobbying useful assessing computational complexity matrix modification problem arising machine learning (Froese, van Bevern, Niedermeier, & Sorge, 2013).441fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & Woegingerfuture work, findings plain Lobbying problem may extended naturalvariants generalizations. includeallow lobby partially influence voters (that is, rows maychanged all-1 rows),head getting majority approvals certain (pre-specified) percentageissues (columns),consider modification operation adding voters (rows),consider modification operation deleting voters (rows).Moreover, interest extend multivariate studies scenarios probabilisticweighted lobbying studied previous work (Binkele-Raible et al., 2014;Erdelyi et al., 2007).conclude concrete open questions future research Lobbying.one replace integer linear program (see Theorem 9 Section 5.2) direct(more efficient) combinatorial algorithm fixed-parameter tractability resultLobbying parameterized number columns?fixed-parameter tractability results parameter combinations (m, k), (m, g),(m, s), (k, s), (g, s) theoretical nature onlycan made practical?showed Lobbying fixed-parameter tractable respect k 0 gconstant. also fixed-parameter tractable combined parameter (g, k 0 )?combined parameters (m, n), (t, n), (s, n) trivial polynomial-sizeproblem kernels Lobbying polynomials dependingrespective parameters upper-bound input size. showed that, except(m, k 0 ) remains open, fixed-parameter tractability resultspolynomial-size problem kernels, unless NP coNP/poly.possibility (provable) efficient effective preprocessing data reductionLobbying?results adhere worst-case analysiswhat complexity Lobbyingaverage? findings greedy heuristic suggest reasonbelieve Lobbying computationally hard worst-case analysis suggests. situation similar recent studies concerning seemingly pathological NP-hardness manipulation good solvability experimentalresults (Betzler, Niedermeier, & Woeginger, 2011; Davies, Katsirelos, Narodytska, &Walsh, 2011; Davies, Narodytska, & Walsh, 2012; Walsh, 2011). thoroughinvestigation direction concerning Lobbying seems promising.442fiA Multivariate Complexity Analysis Lobbying Multiple ReferendaAcknowledgmentsextended abstract work (without coauthor G.J. Woeginger) appearedProceedings 26th Conference Artificial Intelligence (AAAI 12) (Bredereck, Chen,Hartung, Kratsch, Niedermeier, & Suchy, 2012). long version, exclusivelyfocusing plain Lobbying problem, provide numerous detailsomitted extended abstract. Moreover, following new contributions:prove LOGSNP-completeness case gap-1 instances. show greedyalgorithm already presented extended abstract logarithmic approximationratio. Finally, present experimental results greedy algorithms integer linearprogram formulation Lobbying.Robert Bredereck supported German Research Foundation (DFG), researchproject PAWS (NI 369/10). Jiehua Chen supported Studienstiftung des DeutschenVolkes. Main work done Stefan Kratsch Utrecht University supported Netherlands Organization Scientific Research (NWO), project KERNELS(OND1336203), visiting TU Berlin, Germany. Ondrej Suchy supported DFGCluster Excellence Multimodal Computing Interaction (MMCI) DFGproject DARE (GU 1023/1-2). Main work done Universitat desSaarlandes, Saarbrucken visiting TU Berlin, Germany. Gerhard J. Woeginger supported DIAMANT (a mathematics cluster Netherlands Organization ScientificResearch NWO). Main work done staying recipient HumboldtResearch Award TU Berlin.grateful anonymous referees JAIR providing numerous insightfulremarks helped significantly improve paper. thank Kolja Stahl greatsupport extracting converting real-world data experiments.ReferencesBartholdi III, J. J., Tovey, C. A., & Trick, M. A. (1992). hard controlelection?. Mathematical Computer Modeling, 16 (8-9), 2740.Baumeister, D., Erdelyi, G., & Rothe, J. (2011). hard bribe judges?study complexity bribery judgment aggregation. Proceedings2nd International Conference Algorithmic Decision Theory, Vol. 6992 LNCS,pp. 115. Springer.Betzler, N., Bredereck, R., Chen, J., & Niedermeier, R. (2012). Studies computationalaspects votinga parameterized complexity perspective. Multivariate Algorithmic Revolution Beyond, Vol. 7370 LNCS, pp. 318363. Springer.Betzler, N., Niedermeier, R., & Woeginger, G. J. (2011). Unweighted coalitional manipulation Borda rule NP-hard. Proceedings 22nd International JointConference Artificial Intelligence, pp. 5560. AAAI Press.Binkele-Raible, D., Erdelyi, G., Fernau, H., Goldsmith, J., Mattei, N., & Rothe, J. (2014).complexity probabilistic lobbying. Discrete Optimization, 11, 121.443fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & WoegingerBodlaender, H. L. (2009). Kernelization: New upper lower bound techniques. Proceedings 4th International Workshop Parameterized Exact Computation,Vol. 5917 LNCS, pp. 1737. Springer.Bodlaender, H. L., Downey, R. G., Fellows, M. R., & Hermelin, D. (2009). problemswithout polynomial kernels. Journal Computer System Sciences, 75 (8), 423434.Bodlaender, H. L., Thomasse, S., & Yeo, A. (2011). Kernel bounds disjoint cyclesdisjoint paths. Theoretical Computer Science, 412 (35), 45704578.Bredereck, R., Chen, J., Hartung, S., Kratsch, S., Niedermeier, R., & Suchy, O. (2012).multivariate complexity analysis lobbying multiple referenda. Proceedings26th Conference Artificial Intelligence, pp. 12921298. AAAI Press.Cai, L., Chen, J., Downey, R. G., & Fellows, M. R. (1997). Advice classes parameterizedtractability. Annals Pure Applied Logic, 84 (1), 119138.Christian, R., Fellows, M., Rosamond, F., & Slinko, A. (2007). complexity lobbyingmultiple referenda. Review Economic Design, 11 (3), 217224.Davies, J., Katsirelos, G., Narodytska, N., & Walsh, T. (2011). Complexity algorithmsBorda manipulation. Proceedings 25th AAAI Conference ArtificialIntelligence, pp. 657662. AAAI Press.Davies, J., Narodytska, N., & Walsh, T. (2012). Eliminating weakest link: Makingmanipulation intractable?. Proceedings 26th AAAI Conference ArtificialIntelligence, pp. 13331339. AAAI Press.Dom, M., Lokshtanov, D., & Saurabh, S. (2009). Incompressibility colors IDs.Proceedings 36th International Colloquium Automata, Languages,Programming, Vol. 5555 LNCS, pp. 378389. Springer.Dorn, B., & Schlotter, I. (2012). Multivariate complexity analysis swap bribery. Algorithmica, 64 (1), 126151.Downey, R. G., & Fellows, M. R. (2013). Fundamentals Parameterized Complexity. TextsComputer Science. Springer.Elkind, E., Faliszewski, P., & Slinko, A. (2011). Cloning elections: Finding possiblewinners. Journal Artificial Intellligence Research, 42, 529573.Elkind, E., Faliszewski, P., & Slinko, A. (2012). Clone structures voters preferences.Proceedings 13th ACM Conference Electronic Commerce, pp. 496513.ACM.Erdelyi, G., Hemaspaandra, L. A., Rothe, J., & Spakowski, H. (2007). approximatingoptimal weighted lobbying, frequency correctness versus average-case polynomial time. Proceedings 16th International Symposium FundamentalsComputation Theory, Vol. 4639 LNCS, pp. 300311. Springer.Erdelyi, G., Piras, L., & Rothe, J. (2011). complexity voter partition Bucklinfallback voting: Solving three open problems. Proceedings 10th International Joint Conference Autonomous Agents Multiagent Systems, pp. 837844.IFAAMAS.444fiA Multivariate Complexity Analysis Lobbying Multiple ReferendaFaliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. A. (2009). hard briberyelections?. Journal Artificial Intelligence Research, 35, 485532.Fellows, M. R., Jansen, B. M., & Rosamond, F. (2013). Towards fully multivariate algorithmics: Parameter ecology deconstruction computational complexity.European Journal Combinatorics, 34 (3), 541566.Flum, J., & Grohe, M. (2006). Parameterized Complexity Theory. Springer.Fortnow, L., & Santhanam, R. (2011). Infeasibility instance compression succinctPCPs NP. Journal Computer System Sciences, 77 (1), 91106.Frank, A., & Tardos, E. (1987). application simultaneous diophantine approximationcombinatorial optimization. Combinatorica, 7 (1), 4965.Froese, V., van Bevern, R., Niedermeier, R., & Sorge, M. (2013). parameterized complexity analysis combinatorial feature selection problems. Proceedings38th International Symposium Mathematical Foundations Computer Science,Vol. 8087 LNCS, pp. 445456. Springer.Gabow, H. N. (1983). efficient reduction technique degree-constrained subgraphbidirected network flow problems. Proceedings 15th Annual ACM SymposiumTheory Computing, pp. 448456. ACM.Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA GuideTheory NP-Completeness. W. H. Freeman Company.Goldsmith, J., Levy, M. A., & Mundhenk, M. (1996). Limited nondeterminism. SIGACTNews, 27 (2), 2029.Gottlob, G., Scarcello, F., & Sideri, M. (2002). Fixed-parameter complexity AInonmonotonic reasoning. Artificial Intelligence, 138 (1-2), 5586.Gottlob, G., & Szeider, S. (2008). Fixed-parameter algorithms artificial intelligence,constraint satisfaction database problems. Computer Journal, 51 (3), 303325.Guo, J., & Niedermeier, R. (2007). Invitation data reduction problem kernelization.SIGACT News, 38 (1), 3145.Kannan, R. (1987). Minkowskis convex body theorem integer programming. Mathematics Operations Research, 12 (3), 415440.Karp, R. M. (1972). Reducibility among combinatorial problems. Complexity Computer Computations, pp. 85103. Plenum Press.Komusiewicz, C., & Niedermeier, R. (2012). New races parameterized algorithmics.Proceedings 37th Mathematical Foundations Computer Science, Vol. 7464LNCS, pp. 1930. Springer.Lenstra, H. W. (1983). Integer programming fixed number variables. MathematicsOperations Research, 8 (4), 538548.Mahajan, M., & Raman, V. (1999). Parameterizing guaranteed values: MaxSatMaxCut. Journal Algorithms, 31 (2), 335354.Niedermeier, R. (2006). Invitation Fixed-Parameter Algorithms. Oxford University Press.445fiBredereck, Chen, Hartung, Kratsch, Niedermeier, Suchy, & WoegingerNiedermeier, R. (2010). Reflections multivariate algorithmics problem parameterization. Proceedings 27th International Symposium Theoretical AspectsComputer Science, Vol. 5 Leibniz International Proceedings Informatics, pp.1732.Papadimitriou, C. H., & Yannakakis, M. (1996). limited nondeterminism complexity V-C dimension. Journal Computer System Sciences, 53 (2),161170.Sandholm, T., Suri, S., Gilpin, A., & Levine, D. (2002). Winner determination combinatorial auction generalizations. Proceedings First International ConferenceAutonomous Agents Multiagent Systems, pp. 6976. ACM.Schlotter, I., Elkind, E., & Faliszewski, P. (2011). Campaign management approvaldriven voting rules. Proceedings 25th AAAI Conference Artificial Intelligence, pp. 726731. AAAI Press.Schrijver, A. (2003).Springer.Combinatorial Optimization: Polyhedra Efficiency, Vol. A.Szeider, S. (2011). Limits preprocessing. Proceedings 25th AAAI ConferenceArtificial Intelligence, pp. 9398. AAAI Press.Walsh, T. (2011). computational complexity barrier manipulation?. AnnalsMathematics Artificial Intelligence, 62 (1-2), 726.Yap, C.-K. (1983). consequences non-uniform conditions uniform classes. Theoretical Computer Science, 26 (3), 287300.446fiJournal Artificial Intelligence Research 50 (2014) 573601Submitted 12/13; published 07/14False-Name Manipulation Weighted Voting Games HardProbabilistic Polynomial TimeAnja ReyJrg RotheREY @ CS . UNI - DUESSELDORF. DEROTHE @ CS . UNI - DUESSELDORF. DEInstitut fr InformatikHeinrich-Heine-Universitt Dsseldorf40225 DsseldorfGermanyAbstractFalse-name manipulation refers question whether player weighted voting gameincrease power splitting several players distributing weight amongfalse identities. Relatedly, beneficial merging problem asks whether coalition playersincrease power weighted voting game merging weights. problemswhether merging splitting players weighted voting games beneficial termsShapleyShubik normalized Banzhaf index, merely NP-hardness lower bounds known,leaving question exact complexity open. ShapleyShubik probabilistic Banzhaf index, raise lower bounds hardness PP, probabilistic polynomialtime, class considered far larger class NP. power indices, providematching upper bounds beneficial merging and, whenever new players weights given,also beneficial splitting, thus resolving previous conjectures affirmative. Relatedly,consider beneficial annexation problem, asking whether single player increase powertaking players weights. known annexation never disadvantageousShapleyShubik index, beneficial annexation NP-hard normalized Banzhafindex. show annexation never disadvantageous probabilistic Banzhaf index either, ShapleyShubik index probabilistic Banzhaf index showNP-complete decide whether annexing another player advantageous. Moreover, propose general framework merging splitting applied different classesrepresentations games.1. IntroductionAlgorithmic game theory studied intensely recent years (Nisan, Roughgarden, Tardos, &Vazirani, 2007; Chalkiadakis, Elkind, & Wooldridge, 2011). paper focuses algorithmiccomplexity-theoretic aspects problems cooperative game theory. central questionstudied whether merging splitting players coalitional game (with transferable utilities)raise power game. Power indices measure influential player forming winningcoalitions simple games. ShapleyShubik Banzhaf power indices prominentamong measures (Shapley & Shubik, 1954; Banzhaf III, 1965). Roughly speaking, simplegames indicate, respectively, many orders support probabilityplayer swing outcome coalition joining leaving it.Weighted voting games important class succinctly representable, simple games.used model cooperation among players scenarios player assignedweight, coalition players wins joint weight meets exceeds givenc2014AI Access Foundation. rights reserved.fiR EY & ROTHEquota. Typical real-world applications weighted voting games include decision-making legislative bodies (e.g., parliamentary voting) shareholder voting (for concrete applications literature pointers see Chalkiadakis et al., 2011). particular, algorithmiccomplexity-theoretic properties problems related weighted voting studied depth(for overview see, e.g., Elkind, Chalkiadakis, & Jennings, 2008; Elkind, Goldberg, Goldberg, &Wooldridge, 2009; Bachrach, Elkind, Meir, Pasechnik, Zuckerman, Rothe, & Rosenschein, 2009;Zuckerman, Faliszewski, Bachrach, & Elkind, 2012; Elkind, Pasechnik, & Zick, 2013; Chalkiadakiset al., 2011).weighted voting games, Bachrach Elkind (2008) first study complexityfalse-name manipulation: possible player increase power splitting severalplayers distributing weight among them? player may incentive manipulategame via introducing false names. Relatedly, also ask whether merging weightshelp two players weighted voting game increase power.PI-B ENEFICIAL ERGEopen questionPI-B ENEFICIAL PLITNP-hard (ShapleyShubikindex, = 2) *PI-A NNEXATIONnever disadv. (ShapleyShubik index) #NP-hard (ShapleyShubikindex)never disadv. (probabilistic Banzhaf index)PP (ShapleyShubik index, kSk = 2)NP-complete (kSk = 1)P (probabilistic Banzhafindex, kSk = 2)P (probabilistic Banzhafindex, = 2)PP-completePP-hard#NP-hard(Bachrach & Elkind, 2008)(Aziz & Paterson, 2009)(Aziz, Bachrach, Elkind, & Paterson, 2011)(Faliszewski & Hemaspaandra, 2009)paper(Felsenthal & Machover, 1995)Table 1: Overview history complexity results beneficial merging, splitting, annexation probabilistic Banzhaf index ShapleyShubik index. Key: kSk denotessize merging coalition number players given player splits into.Table 1 gives overview development problems complexity resultspower indices studied here, probabilistic Banzhaf index ShapleyShubik index,briefly elaborate now. Merging extending results Bachrach Elkind(2008) Aziz Paterson (2009), Aziz et al. (2011) particular study problem whether574fiFALSE -NAME ANIPULATION WVG H ARD PPmerging splitting players weighted voting games beneficial terms ShapleyShubikindex (Shapley, 1953; Shapley & Shubik, 1954) normalized Banzhaf index (Banzhaf III,1965) (see Section 2 formal definitions). results, however, provide merely NP-hardnesslower bounds. Aziz et al. (2011, p. 72, Remark 13) note quite possible problemsNP (and thus NP-complete). Faliszewski Hemaspaandra (2009) providebest known upper bound beneficial merging problem two players respectShapleyShubik index: contained class PP, probabilistic polynomial time,considered far larger class NP, conjecture problem PP-complete.observe arguments give PP upper bound beneficial merging also termsprobabilistic Banzhaf index.1 contrast normalized Banzhaf index ShapleyShubik index, show probabilistic Banzhaf index problems raising powermerging splitting P coalitions size two split two players, respectively.Furthermore, bridge gap NP-hardness lower bound PP upper boundproving beneficial merging splitting (if new weights given problem instance) PP-complete problems ShapleyShubik probabilistic Banzhaf index.Beneficial splitting general (i.e., number new false identities given, actualweights) PP-hard two indices. Thus, none six problems NP, unlesspolynomial hierarchy collapses first level, considered highly unlikely.Felsenthal Machover (1995) distinguish two types merging, voluntarily involuntarily, show latter, bloc two players (a.k.a. annexation one player another),never disadvantageous ShapleyShubik index, disadvantageous normalized Banzhaf index. latter index, Aziz et al. (2011) show NP-hard decidewhether player benefit annexing players. show NP-complete decidewhether annexing another player advantageous ShapleyShubik index, wellprobabilistic Banzhaf index. also show annexation never disadvantageousprobabilistic Banzhaf index, thus behaves like ShapleyShubik index regard.contribution paper propose general framework merging splitting applied various classes representations games. Introducing new propertiesmerging splitting functions, consistency independence, particular satisfiedstandard merging splitting functions weighted voting games, generalize Presults probabilistic Banzhaf index. one hand, properties desirabledesign merging splitting function; hand, approach axiomaticevaluation functions. analysis properties interesting task futurework. example applying general framework concrete class games,consider threshold network flow games hypergraphs, model adapted thresholdnetwork flow games introduced Bachrach Rosenschein (2009). unanimity gamesrespect probabilistic Banzhaf index, show splitting always disadvantageous neutral, whereas merging neutral size-two coalitions, yet advantageous coalitions leastthree players. strongly contrasts results Aziz et al. (2011) showing mergingalways disadvantageous splitting always advantageous normalized Banzhaf indexunanimity weighted voting games. two examples different propertiesgame restrictions caused certain representation lead different behavior consid1. Note arguments cannot transferred immediately corresponding problem normalizedBanzhaf index.575fiR EY & ROTHEering merging splitting (for overview different classes representations games see,example, Shoham & Leyton-Brown, 2009).2. Preliminariesstart providing needed concepts notation cooperative game theory complexity theory.2.1 Basic Notions Cooperative Game Theoryneed following concepts cooperative game theory, see, e.g., textbooksChalkiadakis et al. (2011) Peleg Sudhlter (2003).coalitional game transferable utilities, G = (N, v), consists set N = {1, . . . , n}players (or, synonymously, agents) coalitional function v : P(N) R v(0)/ = 0,P(N) denotes power set N. consider different classes games certain properties.example, coalitional game monotonic v(B) v(C) whenever B C coalitions B,C N,simple monotonic v : P(N) {0, 1} maps coalition C N valueindicates whether C successful (i.e., C wins: v(C) = 1) (i.e., C loses: v(C) = 0),require grand coalition N always winning (i.e., v(N) = 1).Since number coalitions exponential number players, specifying coalitionalgames listing values coalitional function would require exponential space. algorithmic purposes, however, important games represented succinctly. Weightedvoting games (a.k.a. weighted threshold games) important class simple gamescompactly representable (Bilbao, Fernndez, Jimnez, & Lpez, 2002). games, playergiven weight, coalition players successful sum weightsreaches exceeds given threshold, called quota. Formally, weighted voting game (WVG)G = (w1 , . . . , wn ; q) consists quota q N nonnegative integer2 weights wi , 1 n,wi ith players weight. coalition C N, letting w(C) denote iC wi , C winsw(C) q, loses otherwise. Requiring quota satisfy 0 < q w(N) ensuresempty coalition loses grand coalition wins. Weighted voting games intenselystudied computational complexity point view, see, e.g., work Elkind et al. (2009)book Chalkiadakis et al. (2011, ch. 4) overview.weighted majority game (WMG) special case WVG quota setq = bw(N)/2c + 1. WVGs compactly representable, although fully expressive (for simplegame cannot represented WVG see, e.g., Chalkiadakis et al., 2011, Example 4.17).precisely, every simple game represented k-weighted voting game,intersection k weighted voting games; smallest k dimension simple game;weighted voting games fully expressive class one-dimensional simple games(again, see book Chalkiadakis et al. (2011) details).coalitional game G = (N, v), let dG (C, i) = v(C {i}) v(C) marginal contributionplayer N coalition C N r {i}. simple game, player called pivotal (orcrucial critical) coalition C N r {i} C {i} successful, C not.dG (C, i) = 1 player pivotal C, dG (C, i) = 0 otherwise. term generalizednonsimple games, referring player pivotal C dG (C, i) > 0. power index measures2. See work Chalkiadakis et al. (2011, Thm. 4.2) nonnegative integer weights quotas may assumed.576fiFALSE -NAME ANIPULATION WVG H ARD PPplayers influence simple game. Banzhaf III (1965), rediscovered notion originallyintroduced Penrose (1946), defined raw Banzhaf power indexBanzhaf (G , i) =dG (C, i)CNr{i}game G = (N, v) player N. simple game, indicates number coalitionsplayer pivotal for. However, since ratios indices importantmagnitudes, useful normalize them. fact, two different ways normalizationproposed Banzhaf index.original definition normalized Banzhaf power index (Banzhaf III, 1965), rawBanzhaf index given player divided sum players raw Banzhaf indices:Banzhaf(G , i) =Banzhaf (G , i),nj=1 Banzhaf (G , j)players normalized Banzhaf indices add one. index analyzeddetail Dubey Shapley (1979), introduce alternative normalization, dividesraw Banzhaf index given player total number coalitions without playerdub probabilistic Banzhaf power index:Banzhaf(G , i) =Banzhaf (G , i).2n1Intuitively, index measures probability player pivotal possible coalition.Based comprehensive analysis comparing various mathematical properties two powerindices, Dubey Shapley (1979, p. 102) view probabilistic Banzhaf index manyrespects natural normalized Banzhaf index. particular, probabilistic Banzhafindex satisfies four fundamental axioms: (1) symmetry,3 (2) dummy player,4 (3) additivity,5(4) property call valuation.6 Neither valuation additivity satisfied normalizedBanzhaf index. beyond purpose paper give full explanation axioms,refer reader work Dubey Shapley (1979) careful, detailed discussion.normalized Banzhaf index lacks fourth axiom, Dubey Shapley (1979, Footnote 21)conclude: may taken initial sign trouble normalization [of normalized Banzhaf index]. also note probabilistic Banzhaf index better behavedanalyzing convergence (Dubey & Shapley, 1979, p. 116). Also, normalized Banzhaf indexsubject so-called bloc paradox (see Felsenthal & Machover, 1995), is, player losepower taking another players weight. probabilistic Banzhaf index paradoxdoesnt hold. (See Sections 3 4 computational complexity annexation problem.)hand, normalized Banzhaf power index advantages well, dependingsetting one considers. Aziz et al. (2011, p. 61) argue that: Although probabilistic3. game G , Banzhaf(G , i) = Banzhaf(G , j) whenever j symmetric, i.e., v(C {i}) = v(C { j})coalitions C N r {i, j}.4. game G , Banzhaf(G, i) = 0 whenever dummy player, i.e., v(C {i}) = v(C) coalition C N.5. two games G1 = (N, v1 ) G2 = (N, v2 ), Banzhaf(G1 + G2 , i) = Banzhaf(G1 , i) + Banzhaf(G2 , i)players N, G1 + G2 = (N, v1 + v2 ) defined via (v1 + v2 )(C) = v1 (C) + v2 (C) coalitions C N.6. two simple games G1 = (N, v1 ) G2 = (N, v2 ), holds Banzhaf(Gv1 v2 , i) + Banzhaf(Gv1 v2 , i) =Banzhaf(G1 , i) + Banzhaf(G2 , i) N, games Gv1 v2 = (N, v1 v2 ) Gv1 v2 = (N, v1 v2 )defined (v1 v2 )(C) = max(v1 (C), v2 (C)) (v1 v2 )(C) = min(v1 (C), v2 (C)) coalitions C N.577fiR EY & ROTHEBanzhaf index useful measuring actual probability influencing decision,fit framework using power indices share resources power, probabilisticBanzhaf index normalized. Here, normalization done respect number players/coalitions, makes games different numbers players better comparable. Duenormalization respect players game, monotonic games normalized Banzhafindex yields imputation (i.e., payoff vector (Banzhaf(G , 1), Banzhaf(G , 2), . . . , Banzhaf(G , n))satisfying efficiency, ni=1 Banzhaf(G , i) = v(N), individual rationality, Banzhaf(G , i) v({i})N), whereas probabilistic Banzhaf index efficient.unique imputation satisfying four axioms mentioned above, based ShapleyShubik power index (Shapley & Shubik, 1954), describes marginal contributionsplayer possible coalitions respect order players enter coalitions:ShapleyShubik (G , i) =kCk! (n 1 kCk)! dG (C, i),CNr{i}normalizedShapleyShubik (G , i).n!coalitional games, also known Shapley value (Shapley, 1953).Felsenthal Machover (2005, 1995) carefully discuss differences powerindices, refer reader work.ShapleyShubik(G , i) =2.2 Basic Notions Computational Complexity Theoryassume reader familiar basic notions complexity theory complexity classes P (deterministic polynomial time) NP (nondeterministic polynomial time),ppolynomial-time many-one reducibility, denoted , notions hardness comppleteness (of decision problems complexity classes) respect . backgrounddetails, see, e.g., textbooks Garey Johnson (1979), Papadimitriou (1995), Rothe(2005).Valiant (1979) introduces #P class functions give number solutionsinstances NP problems. decision problem NP, denote function #A.example, letting SAT denote satisfiability problem propositional logic, #SAT denotesfunction mapping boolean formula number truth assignments satisfying .several notions reducibility functional problems and, consequently, several notionshardness completeness complexity classes functions #P. Let f g twofunctions mapping N. say f many-one-reduces g exist two polynomialtime computable functions, , x , f (x) = (g((x))). notionfunctional many-one reducibility due Zank (1991); analogue (polynomial-time)many-one reducibility sets. special case identity yields parsimoniousreducibility, preserves number solutions: say f parsimoniously reduces gexists polynomial-time computable function x , f (x) = g((x)).Intuitively, parsimonious reductions preserve number solutions (for detailed discussionfunctional reducibilities see Faliszewski & Hemaspaandra, 2009). say g #P-parsimonioushard every function f #P parsimoniously reduces g. g #P-parsimonious-hard g#P, g #P-parsimonious-complete. notions #P-many-one-hardness #P-many-onecompleteness defined analogously. known that, given WVG G player i, computing578fiFALSE -NAME ANIPULATION WVG H ARD PPraw Banzhaf index #P-parsimonious-complete (Prasad & Kelly, 1990), whereas computingraw ShapleyShubik index (Faliszewski & Hemaspaandra, 2009), although #P-manyone-complete. recent #P-completeness results, refer work Aziz, Brandt,Brill (2013).Gill (1977) introduces class PP (probabilistic polynomial time) contains decisionproblems X exist function f #P polynomial p instances x,x X f (x) 2 p(|x|)1 . easy see NP PP; fact, PP consideredfar larger class NP, due Todas theorem (1991): PP least hard (in termspolynomial-time Turing reductions) problem polynomial hierarchy (i.e., PH PPP ).NPPP , second level Wagners counting hierarchy (1986), class problems solvableNP machine access PP oracle. Mundhenk, Goldsmith, Lusena, Allender (2000)identify NPPP -complete problems related finite-horizon Markov decision processes. Littman,Goldsmith, Mundhenk (1998) obtain NPPP -completeness results analyzing variantsatisfiability problem questions related probabilistic planning.3. Definition Beneficial Merging, Splitting, AnnexationAziz et al. (2011) introduce merging splitting operations WVGs. use followingnotation. Given WVG G = (w1 , . . . , wn ; q) nonempty7 coalition {1, . . . , n}, let G&S =(w(S), w j1 , . . . , w jnkSk ; q) { j1 , . . . , jnkSk } = N r denote new WVG playersmerged one new player weight w(S).8 power index PI, beneficialmerging problem defined follows.PI-B ENEFICIAL ERGEGiven:Question:WVG G = (w1 , . . . , wn ; q) nonempty coalition {1, . . . , n}.true PI(G&S , 1) > PI(G , i)?Similarly, given WVG G = (w1 , . . . , wn ; q), player i, integer 2, define setWVGs Gim = (w1 , . . . , wi1 , wi+1 , . . . , wn , wn+1 , . . . , wn+m ; q) weight wi splitnew players n + 1, . . . , n + weights wn+1 , . . . , wn+m mj=1 wn+ j = wi . (Noteset WVGs Gim , since might several possibilities distributing weightwi new players n + 1, . . . , n + satisfying mj=1 wn+ j = wi .)distinguish two different splitting problems.9 First, power index PI, considerproblem weighted voting game, player i, number false identities splitsgiven problem instance, weights new players:PI-B ENEFICIAL PLITGiven:Question:WVG G = (w1 , . . . , wn ; q), player i, integer 2.possible split new players n + 1, . . . , n + weights wn+1 , . . . , wn+msatisfying mj=1 wn+ j = wi new WVG, call Gim , holdsmj=1 PI(Gim , n + j) > PI(G , i)?7. omit empty coalition, since would slightly change idea problem.8. Note players order doesnt matter considering normalized probabilistic Banzhaf index.9. distinction wouldnt make sense beneficial merging annexation.579fiR EY & ROTHEmentioned above, instance (G , i, m) PI-B ENEFICIAL PLIT, might variousways distributing weight false identities, giving rise various new games Gim .second (more special) variant problem consider, new players weights givenexplicitly problem instance (and thus number false identities given implicitly).case, one unique new game Gim , splitting inverse function merging.use PI-B ENEFICIAL PLIT denote general problem without explicitly givenweights, explicitly mention whenever speak restricted variant.problems deal voluntary actions players, Felsenthal Machover (1995)study question whether possible player change power taking anotherplayers weight without players consent. introduce bloc paradox, statingpossible lose power annexing another players weight. instance, normalized Banzhafindex subject paradox. ShapleyShubik index, Felsenthal Machover showannexation never disadvantageous. Nevertheless, one still ask question whetherfact advantageous. following problem studied Aziz et al. (2011). Let PIpower index.PI-B ENEFICIAL NNEXATIONGiven:Question:WVG G = (w1 , . . . , wn ; q), player N, coalition {1, . . . , n} r {i}.true PI(G&(S{i}) , 1) > PI(G , i)?particular, Aziz et al. (2011) show NP-hard decide whether annexation beneficialnormalized Banzhaf index, respect power index always beneficialplayer annex another player larger weight. also introduce annexationnonmonotonicity paradox, says sometimes useful player annexanother player small weight annex another player large weight.goal paper classify problems terms complexityShapleyShubik probabilistic Banzhaf index. First, since allow players zero weight,analysis beneficial splitting problem requires another simple fact, useupcoming proofs Theorems 4.7 4.12.Lemma 3.1. probabilistic Banzhaf index ShapleyShubik index, givenweighted voting game, adding player weight zero change original playerspower indices, new players power index zero.proof Lemma 3.1 straightforward therefore omitted.4. Complexity Beneficial Merging, Splitting, Annexation Weighted VotingGamesAziz et al. (2011) analyze problems ShapleyShubik-B ENEFICIAL ERGEand ShapleyShubikB ENEFICIAL PLIT well Banzhaf-B ENEFICIAL ERGE Banzhaf-B ENEFICIAL PLITterms complexity. provide NP-hardness lower bounds, leave open whetherproblems NP. Indeed, Aziz et al. (2011, p. 72, Remark 13) note quite possibleproblems NP, raises natural question: upper bounds?Faliszewski Hemaspaandra (2009) establish upper bound restriction beneficialmerging problem weighted voting games originally proposed Bachrach Elkind580fiFALSE -NAME ANIPULATION WVG H ARD PP(2008) (Can two players increase joint ShapleyShubik index via merging?): problem complexity class PP. paper, Faliszewski Hemaspaandra study problemPI-P OWER C OMPARE weighted voting games, PI power index. prove PPcompleteness problem probabilistic Banzhaf ShapleyShubik index.section prove beneficial merging splitting PP-hard, provide matching upper bounds beneficial merging splitting (the latter variant new playersweights given), ShapleyShubik probabilistic Banzhaf index.4.1 Probabilistic Banzhaf Power Indexbeneficial merging problem coalition size 2 beneficial splitting problem= 2 false identities trivially decided polynomial time probabilistic Banzhafindex, since sum power (in terms index) two players always equal powerplayer obtained merging them.Proposition 4.1. Let G weighted voting game {1, . . . , n} coalition players.1. Banzhaf-B ENEFICIAL ERGE P instances (G , S) kSk = 2.2. Banzhaf-B ENEFICIAL PLIT P instances (G , i, 2).Proof. Let G = (w1 , . . . , wn ; q) weighted voting game. Without loss generality (see Footnote 8), let = {1, n}. obtain new game G&S = (w1 + wn , w2 , . . . , wn1 ; q), firstplayer new player merging S. Letting vG vG&S denote corresponding coalitional functions, holdsBanzhaf(G&S , 1) (Banzhaf(G , 1) + Banzhaf(G , n))!1= n2(vG&S (C {1}) vG&S (C))2C{2,...,n1}=12n112n1!(vG (C {1}) vG (C)) +C{2,...,n}(vG (C {n}) vG (C))C{1,...,n1}(2(vG&S (C {1}) vG&S (C))C{2,...,n1}(vG (C {1}) vG (C)) (vG (C {1, n}) vG (C {n}))!(vG (C {n}) vG (C)) (vG (C {n, 1}) vG (C {1})))=12n1!(2vG&S (C {1}) 2vG (C {1, n}) + 2vG (C) 2vG&S (C))C{2,...,n1}case splitting, similarly holdsBanzhaf(Gn2 , n + 1) + Banzhaf(Gn2 , n + 2) Banzhaf(G , n) = 0581= 0.fiR EY & ROTHEweighted voting game G = (N, v), = 2, and, without loss generality, player n G splittingplayers n + 1 n + 2 new game Gn2 .qAlthough may seem Proposition 4.1 implied merging (and splitting) neverbeneficial regarding index, cannot generalized merging (or splitting into)two players, repeatedly applying result pairs players step step. example,soon two players merge, third players probabilistic Banzhaf index might already changednew game, merging another player subsequent step. Suppose three players{1, 2, 3} want merge game G . Let Bi = Banzhaf(G , i), 1 3, original probabilisticBanzhaf indices. Let B common Banzhaf index merge. merging first twoplayers, let B01 B03 indices {1, 2} 3, respectively. Then, due Proposition 4.1, B =B01 +B03 = B1 +B2 +B03 . Hence, B > B1 +B2 +B3 B03 > B3 . is, probabilisticBanzhaf index, beneficial merging three players boils comparing index one playertwo gamesthe original game one two players merged.two arbitrary games, result PI-P OWER C OMPARE Faliszewski Hemaspaandra (2009)would applied. Here, however, indices need compared two closely related games;requires different proof. Indeed, next show far harder (unless polynomialhierarchy collapses first level) decide whether merging three players beneficial termsprobabilistic Banzhaf index two players. use following result dueFaliszewski Hemaspaandra (2009, Lemma 2.3).Lemma 4.2 (Faliszewski & Hemaspaandra, 2009). Let F #P-parsimonious-complete function. problem C OMPARE-F = {(x, y) | F(x) > F(y)} PP-complete.well-known NP-complete problem UBSET UM (which special variant K NAP problem) asks, given sequence (a1 , . . . , ) positive integers positive integer q,exist x1 , . . . , xn {0, 1} ni=1 xi ai = q? known #S UBSET UM #Pparsimonious-complete (for parsimonious reductions #3-SAT via #E XACT C B 3-S ETS#S UBSET UM see, e.g., Hunt, Marathe, Radhakrishnan, & Stearns, 1998; Papadimitriou, 1995).Hence, Lemma 4.2, following.SACKCorollary 4.3. C OMPARE-#S UBSET UM PP-complete.pgoal provide -reduction C OMPARE-#S UBSET UM Banzhaf-B ENEFICIAL ERGE. However, make reduction work, useful consider two restricted variants C OMPARE-#S UBSET UM, denote C OMPARE-#S UBSET UM-R C OM PARE-#S UBSET UM -RR, show PP-hardness, reduce C OMPARE-#S UBSET UM -RRBanzhaf-B ENEFICIAL ERGE. done Lemmas 4.4 4.5 Theorem 4.6.restricted variants C OMPARE-#S UBSET UM may assume, without loss generality,target value q related #S UBSET UM instance ((a1 , . . . , ), q) satisfies 1 q 1,= ni=1 ai .582fiFALSE -NAME ANIPULATION WVG H ARD PPC OMPARE -#S UBSET UM -RGiven:Question:sequence = (a1 , . . . , ) positive integers two positive integers q1 q21 q1 , q2 1, = ni=1 ai .number subsequences summing q1 greater numbersubsequences summing q2 , is, hold#S UBSET UM((a1 , . . . , ), q1 ) > #S UBSET UM((a1 , . . . , ), q2 )?pLemma 4.4. C OMPARE-#S UBSET UM C OMPARE-#S UBSET UM-R.Proof. Given instance (X,Y ) C OMPARE-#S UBSET UM, X = ((x1 , . . . , xm ), qx ) =((y1 , . . . , yn ), qy ), construct C OMPARE-#S UBSET UM-R instance (A, q1 , q2 ) follows. Let =i=1 xi define = (x1 , . . . , xm , 2y1 , . . . , 2yn ), q1 = qx , q2 = 2qy . constructionobviously achieved polynomial time.holds integers sum qx 1 contain multiples2, thus #S UBSET UM(A, q1 ) = #S UBSET UM((x1 , . . . , xm ), qx ). hand, q2 cannotobtained adding xi s, since would yield non-zero remainder modulo 2,i=1 xi = small. Thus, holds #S UBSET UM (A, q2 ) = #S UBSET UM ((y1 , . . . , yn ), qy ).follows (X,Y ) C OMPARE-#S UBSET UM (A, q1 , q2 ) C OMPARE #S UBSET UM -R.qorder perform next step, need ensure integers C OMPARE-#S UBSETS UM-R instance divisible 8. easily achieved, multiplying integerinstance ((a1 , . . . , ), q1 , q2 ) 8, obtaining ((8a1 , . . . , 8an ), 8q1 , 8q2 ) without changing numbersolutions related UBSET UM instances. Thus, on, without loss generality,assume given C OMPARE-#S UBSET UM-R instance ((a1 , . . . , ), q1 , q2 ), holdsai , q j 0 mod 8 1 n j {1, 2}.Now, consider even restricted variant problem.C OMPARE -#S UBSET UM -RRGiven:Question:sequence = (a1 , . . . , ) positive integers.number subsequences summing (/2)2, = ni=1 ai , greaternumber subsequences summing (/2) 1, i.e., true#S UBSET UM((a1 , . . . , ), (/2) 2) > #S UBSET UM((a1 , . . . , ), (/2) 1)?pLemma 4.5. C OMPARE-#S UBSET UM-R C OMPARE-#S UBSET UM-RR.Proof. Given instance (A, q1 , q2 ) C OMPARE-#S UBSET UM-R, assume =(a1 , . . . , ), q1 , q2 satisfy ai , q j 0 mod 8 1 n j {1, 2}, construct instanceB C OMPARE-#S UBSET UM-RR follows. (This reduction inspired standard reductionUBSET UM PARTITION due Karp, 1972.)Letting = ni=1 ai , defineB = (a1 , . . . , , 2 q1 , 2 + 1 q2 , 2 + 3 + q1 + q2 , 3).583fiR EY & ROTHEinstance obviously constructed polynomial time. Observe!nT=ai+ (2 q1 ) + (2 + 1 q2 ) + (2 + 3 + q1 + q2 ) + 3 = 10 + 4,i=1therefore, (T/2)2 = 5 (T/2)1 = 5 +1. show (A, q1 , q2 ) C OMPARE-#S UB SET UM -R B C OMPARE-#S UBSET UM -RR.First, examine subsequences B sum 5. Consider two cases.Case 1: 3 added, 2 +3+q1 +q2 cannot added, would large. Also, 2 +1q2cannot added, leading odd sum. So, 2 q1 added, remainingsmall. Since 3 + 2 q1 = 5 q1 , 5 achieved adding aiexists subset A0 {1, . . . , n} iA0 ai = q1 (i.e., A0 solutionUBSET UM instance (A, q1 )).Case 2: 3 added, 2 + 3 + q1 + q2 , even number achieved adding2 + 1 q2 , thus, 4 q1 remain. 2 q1 large, subsequence sums4q1 , assumption divisibility 8. neither 3 2 +3+q1 +q2added, remaining 5 + 1 q1 q2 small.Thus, possibility obtain 5 find subsequence adding q1 . Thus,#S UBSET UM(A, q1 ) = #S UBSET UM(B, 5).Second, similar reasons, sum 5 + 1 achieved adding 3 + (2 +1 q2 ) term iA0 ai , A0 subset {1, . . . , n} iA0 ai = q2 . Hence,#S UBSET UM(A, q2 ) = #S UBSET UM(B, 5 + 1).Thus, relation #S UBSET UM(A, q1 ) > #S UBSET UM(A, q2 ) holds #S UBSETS UM(B, 5) > #S UBSET UM(B, 5 + 1), completes proof.qready prove main theorem section.Theorem 4.6. Banzhaf-B ENEFICIAL ERGE PP-complete, even three players equalweight merge.Proof. Membership Banzhaf-B ENEFICIAL ERGE PP follows fact rawBanzhaf index #P #P closed addition multiplication two,10 and, furthermore, since comparing values two #P functions two (possibly different) inputs reducesPP-complete problem. technique (which proposed Faliszewski & Hemaspaandra,p2009, applies Lemma 2.10) works, since PP closed -reducibility.pshow PP-hardness Banzhaf-B ENEFICIAL ERGE means -reduction C OM PARE-#S UBSET UM -RR, PP-hard Corollary 4.3 via Lemmas 4.4 4.5.Given instance = (a1 , . . . , ) C OMPARE-#S UBSET UM-RR, construct followinginstance Banzhaf-B ENEFICIAL ERGE. Let = ni=1 ai . Define WVGG = (2a1 , . . . , 2an , 1, 1, 1, 1; )10. Again, note idea cannot transferred straightforwardly normalized Banzhaf index, since differentgames indices possibly different denominators, different factor power two,case probabilistic Banzhaf index.584fiFALSE -NAME ANIPULATION WVG H ARD PPn + 4 players, let merging coalition = {n + 2, n + 3, n + 4}.Letting N = {1, . . . , n}, holds(fi)fi1fiBanzhaf(G , n + 2) = n+3 C {1, . . . , n + 1, n + 3, n + 4} fi wi = 1fi iC2(fi(fi))fifi10fi0fi= n+3 N fi 2ai = 1 + 3 N fi 1 + 2ai = 1fi iA0fi2iA0fifi() !) (fifififi+ 3 A0 N fi 2 + 2ai = 1 + A0 N fi 3 + 2ai = 1fifiiA0iA0(fifi) () !fifi1fifi= n+3 3 A0 N fi 2ai = 2 + A0 N fi 2ai = 4 ,fi iA0fi iA02(1)(2)since 2ai add even number. first four sets (1) (2) referscoalitions contain players n + 1, n + 3, n + 4; second, third,fourth set (1) (2) refers coalitions containing either one, two, three them,respectively. Since players weight, players n + 3 n + 4probabilistic Banzhaf index player n + 2.Furthermore, new game merging G&{n+2,n+3,n+4} = (3, 2a1 , . . . 2an , 1; ) n + 2players, similarly Banzhaf index first player calculated follows:Banzhaf G&{n+2,n+3,n+4} , 1(fi)fi1fiC{2,...,n+2}w{3,2,1}=fifi iC2n+1(fi)fi10fi=N2a{3,2,1}fifi iA02n+1(fi) !fi0fi+ N fi 1 + 2ai { 3, 2, 1}fiiA0fifi() !) (fifi1fi0fi0N2a=4+2N2a=2=.fifin+1fi iA0fi iA02Altogether, holdsBanzhaf G&{n+2,n+3,n+4} , 1Banzhaf(G , i)i{n+2,n+3,n+4}fi(fi) () !fifi0fi0fi=N2a=2+N2a=42fifin+1fi iA0fi iA02(fifi) () !fifi3fifin+3 3 A0 N fi 2ai = 2 + A0 N fi 2ai = 4fi iA0fi iA021585fiR EY & ROTHEfi()fi0fi23N=2a=2fin+1n+3fi iA022fi()fi13fi+ n+1 n+3 A0 N fi 2ai = 4fi iA022(fi()fi11fi= n+3 A0 N fi ai = 1 + n+3 A0 Nfi iA022213greater zero(fi) (fi0fi0N2=fi> Nfi iA02fifififififififififi)2=,0 2iA0 ai = 2 1iA),turn case original instance C OMPARE-#S UBSET UM-RR. qAnalogously proof Theorem 4.6, shown beneficial splitting problemleast three false identities given new weights PP-complete. However,general beneficial splitting problem new players weights given, PP upper boundcannot shown straightforwardly. Yet, shown problem PP-hard, even threefalse identities.Theorem 4.7. Banzhaf-B ENEFICIAL PLIT PP-hard (even given player splitthree players equal weight).Proof. order show PP-hardness Banzhaf-B ENEFICIAL PLIT, use techniquesTheorem 4.6, appropriately modified. fact, show PP-hardness = 3 falseidentities. result expanded fixed 3 splitting additional playersweight 0. precisely, > 3, consider game G split threeplayers weight 1 3 players weight 0 each. Lemma 3.1, sumnew players Banzhaf power equal combined Banzhaf power three players. Thus,PP-hardness hold splitting > 3 players essentially arguments givensplitting three players.First, slightly change definition C OMPARE-#S UBSET UM-RR switching (/2)2 (/2) 1. problem (call C OMPARE-#S UBSET UM-R R) whether numbersubsequences given sequence positive integers summing (/2) 1 greaternumber subsequences summing (/2) 2, PP-hard proofLemma 4.5 roles q1 q2 exchanged.Now, reduce problem Banzhaf-B ENEFICIAL PLIT constructing following instance beneficial splitting problem instance = (a1 , . . . , ) C OMPARE-#S UBSETS UM-R R. Let G = (2a1 , . . . , 2an , 1, 3; ), = nj=1 j , let = n + 2 playersplit. G (apart order players) equivalent game obtained merging proofTheorem 4.6. Thus, letting N = {1, . . . , n}, Banzhaf(G , n + 2) equals(fifi) () !fifi10fi0fi2N2a=2+N2a=4fifi.jj00fi jAfi jA2n+1586fiFALSE -NAME ANIPULATION WVG H ARD PPAllowing players weight zero, different possibilities split player n + 2 threeplayers. Lemma 3.1, splitting n + 2 one player weight 3 two others weight 0beneficial. Likewise, splitting n + 2 two players weights 1 2 one playerweight 0 beneficial, Lemma 3.1 since splitting two players beneficial (byTheorem 1). Thus, possibility left splitting n + 2 three players weight 1 each.corresponds original game proof Theorem 4.6, Gi3 = (2a1 , . . . , 2an , 1, 1, 1, 1; ).Therefore,Banzhaf(Gi3 , n + 2) = Banzhaf(Gi3 , n + 3) = Banzhaf(Gi3 , n + 4)fifi() () !fifi1fifi00NN2a=2+2a=4=3fifi.0 j0 jfi jAfi jA2n+3Altogether, proof Theorem 4.6, sum three new players probabilisticBanzhaf indices minus probabilistic Banzhaf index original player greater zero(fifi) ()fifi0fifi0N fi j = ( /2) 1 > N fi j = ( /2) 2 ,fi jA0fi jA0true C OMPARE-#S UBSET UM-R R.qRemark 4.8. upper bound general beneficial splitting problem, showmembership NPPP , whenever number false identities given unary, conjectureproblem even complete class. number false identitiesweights given unary, exponentially many possibilities distribute split playersweight among false identities. Nondeterministically guessing distribution then,distribution guessed, asking appropriate PP oracle check polynomial time whethercombined Banzhaf power new game greater original players Banzhaf poweroriginal game, shows Banzhaf-B ENEFICIAL PLIT NPPP .Whenever number false identities given standard binary input format, evenupper bound might longer valid.given weighted voting game G two players j G , Proposition 4.1 impliesBanzhaf(G&{i, j} , 1) Banzhaf(G , i) = Banzhaf(G , j) 0.(3)Therefore, never disadvantageous player annex player j. Furthermore,following result complexity beneficial annexation probabilistic Banzhaf index.Theorem 4.9. Banzhaf-B ENEFICIAL NNEXATION NP-complete instances (G , i, S)kSk = 1.Proof. Equation (3) above, question whether new players probabilistic Banzhafindex greater original players probabilistic Banzhaf index equivalent questionwhether annexed player positive value original game. propertydecided nondeterministic polynomial time NP-hard result due Prasad Kelly(1990).q587fiR EY & ROTHERemark 4.10. Banzhaf-B ENEFICIAL NNEXATION immediately inherits NP-hardnessspecial case Theorem 4.9, problems NP upper bound generalize straightforwardly.4.2 ShapleyShubik Power Indexorder prove PP-hardness merging splitting problems respect ShapleyShubik index, need take step back.E XACT C 3-S ETS (X3C, short) another well-known NP-complete decision problem: Given set B size 3k family subsets B size three each,exist subfamily 0 B exactly covered 0 ?Theorem 4.11. ShapleyShubik-B ENEFICIAL ERGE PP-complete, even two playersequal weight merge.Proof. PP upper bound, already observed two players FaliszewskiHemaspaandra (2009), shown analogously proof Theorem 4.6.proving lower bound, observe size coalition player pivotal crucial determining players ShapleyShubik index. Pursuing techniques FaliszewskiHemaspaandra, examine problem COMPARE-#X3C, PP-complete Lemma 4.2.apply following useful properties X3C instances shown Faliszewski Hemaspaandra (2009, Lemma 2.7): Every X3C instance (B0 , 0 ) transformed X3C instance(B, ), kBk = 3k kS k = n, satisfies k/n = 2/3 without changing number solutions, i.e., #X3C(B, ) = #X3C(B0 , 0 ). Now, properties standard reductionX3C UBSET UM (which particular preserves number solutions, i.e., #X3C parsimoniously reduces #S UBSET UM, well input size n solution size k, see, e.g.,Papadimitriou, 1995), assume given C OMPARE -#S UBSET UM instance subsequence summing given integer q size 2n/3. Following track reductionsC OMPARE -#S UBSET UM via C OMPARE-#S UBSET UM-R C OMPARE-#S UBSET UM-RRLemmas 4.4 4.5, solution A0 {1, . . . , n} given instance = (a1 , . . . , ) latter problem (A0 satisfying either iA0 ai = (/2) 2 iA0 ai = (/2) 1, = ni=1 ai )assumed satisfy kA0 k = k = (n+2)/3. assumption, show PP-hardnessShapleyShubik-B ENEFICIAL ERGE via reduction C OMPARE -#S UBSET UM -RR. Giveninstance, construct WVG G = (a1 , . . . , , 1, 1; /2) consider coalition = {n +1, n + 2}. Let N = {1, . . . , n} define X = #S UBSET UM(A, (/2) 1) = #S UBSET UM(A,(/2) 2). Then,ShapleyShubik(G , n + 1) = ShapleyShubik(G , n + 2)=1kCk!(n+1kCk)!+(kCk+1)!(nkCk)!(n + 2)! CNCNai =(/2)1ai =(/2)2iC=iC1(X k!(n + 1 k)! +Y (k + 1)!(n k)!) .(n + 2)!588fiFALSE -NAME ANIPULATION WVG H ARD PPMerging players S, obtain G&S = (2, a1 , . . . , ; /2). ShapleyShubik indexnew player G&SShapleyShubik(G&S , 1) =1(n + 1)!kCk!(n kCk)!CNai {(/2)1,(/2)2}iC1=(X +Y ) (k + 1)!(n k)!.(n + 1)!all,ShapleyShubik(G&S , 1) (ShapleyShubik(G , n + 1) + ShapleyShubik(G , n + 2))(X +Y ) (k + 1)!(n k)! 2 (X k!(n + 1 k)! +Y (k + 1)!(n k)!)=(n + 1)!(n + 2)!k!(n k)!=(n 2k)(X +Y ).(n + 2)!(4)Since assumed k = (n+2)/3 also assume n > 4 (because added fourintegers construction proof Lemma 4.5), holdsn 2k =n4> 0.3Thus term (4) greater zero greater X, trueC OMPARE -#S UBSET UM -RR.qAnalogously probabilistic Banzhaf index, show also ShapleyShubikindex PP-complete decide splitting player players given weights beneficial.general case number false identities actual weights given,raise previously known lower bound PP-hardness. However, upper bound PPcannot transferred straightforwardly.Theorem 4.12. ShapleyShubik-B ENEFICIAL PLIT PP-hard (even given playersplit two players equal weight).Proof. PP-hardness shown analogously proof Theorem 4.7, appropriately modified use arguments proof Theorem 4.11 instead proof Theorem 4.6.qupper bound NPPP holds due analogous arguments proof Theorem 4.7,whenever given unary.Felsenthal Machover (1995) shown annexation never disadvantageousShapleyShubik index. Still, question whether advantageous hard decide.Theorem 4.13. ShapleyShubik-B ENEFICIAL NNEXATION NP-complete instances (G , i, S)kSk = 1.589fiR EY & ROTHEProof. Let G = (w1 , . . . , wn ; q) weighted voting game and, without loss generality, letplayer 1 annex player n. holdsShapleyShubik(G&{1,n} , 1) ShapleyShubik(G , 1)=1((v(C {1, n} v(C {1})) kCk!(n 1 kCk)!n! C{2,...,n1}+ (v(C {n} v(C)) (kCk + 1)!(n 2 kCk)!).Unlike probabilistic Banzhaf index, term general equal ShapleyShubik(G , n),greater zero player n pivotal least one coalition C {1, . . . , n 1}original game. So, analogously Theorem 4.9, property decided nondeterministicpolynomial time NP-hard result due Prasad Kelly (1990) (see also Deng &Papadimitriou, 1994).qRemark 4.14. Analogously annexation respect probabilistic Banzhaf index,ShapleyShubik-B ENEFICIAL NNEXATION immediately inherits NP-hardness special caseTheorem 4.13, problems NP upper bound generalize straightforwardly.5. Generalizing Merging Splitting Functionsextend definition merging splitting functions weighted voting games generalclasses (or representations) G coalitional games; one may think G class simplegames family weighted voting games representation simple gamesvector weighted voting games (Chalkiadakis et al., 2011), threshold network flow games dueBachrach Rosenschein (2009), even class coalitional games.merging function G,G : {G = (N, v) | G G} (P(N) r 0)/ G,turns given coalitional game G = (N, v) suitable representation given nonempty coalitionN new game G (G , S) = (N 0 , v0 ), N 0 = {i&S } (N r S) contains new player i&Smerging S, v0 : P(N 0 ) R new coalitional function whose values specifiedaccording type games class G. example, weighted voting games possible v0specified Section 3.Similarly, splitting function G,G : {G = (N, v) | G G} N (N r {0, 1}) P(G),turns given coalitional game G = (N, v), given player N, given integer 2set new games form (N 0 , v0 ), player split players N 0 = {n +1, . . . , n + m} (N r {i}) v0 : P(N 0 ) R new coalitional function whose valuesspecified according type games class G. Again, weighted voting games v0specified Section 3, classes coalitional games, v0 needs suitably defined.example, G class monotonic coalitional games, v0 must defined monotonicity590fiFALSE -NAME ANIPULATION WVG H ARD PPmaintained, since various possibilities so, various distinct splitting functionsdefined class games.example, let wvg wvg denote merging splitting functions weighted votinggames defined Section 3. is,weighted voting game G = (w1 , . . . , wn ; q) coalition N = {1, . . . , n}, definewvg (G , S) = G&S ,given weighted voting game G = (w1 , . . . , wn ; q), player i, integer 2, definewvg (G , i, m) set weighted voting games Gim .define following properties merging splitting functions.Definition 5.1. Let G class coalitional games let G merging function GG splitting function G.1. say G satisfies consistency G = (N, v) G coalition N,G (G , S) = (N 0 , v0 ) v(C S) = v0 (C {i&S }) holds coalition C N r S.2. say G satisfies independence G = (N, v) G coalition N,G (G , S) = (N 0 , v0 ) v(C) = v0 (C) holds coalition C N r S.3. say G satisfies consistency G = (N, v) G, player N,integer 2, (N 0 , v0 ) G (G , i, m) v(C {i}) = v0 (C {n + 1, . . . , n + m})coalition C N r {i}.4. say G satisfies independence G = (N, v) G, player N,integer 2, (N 0 , v0 ) G (G , i, m) v(C) = v0 (C) coalition C N r {i}.Intuitively, consistency means value coalition subject merging splittingoperations. Independence means value coalitionaffected merging splitting remain new game, i.e., dependsplayers coalition. weighted voting games, wvg wvg satisfy consistencyindependence, since weight new player G (G , S) equals wi merging, sincemj=1 wn+ j = wi splitting.following example presents merging function class weighted majority gamesneither consistency independence satisfied.Example 5.2. Let wmg merging function maps given weighted majority game G =(w1 , . . . , wn ) given coalition N new weighted majority game, playerkeeps weight, new player i&S merging receives weight wi&S = wi .Consider game G = (2, 3, 4, 4) coalition = {1, 3}. Then, game wmg (G , S) =(8, 3, 4) formed. value merged player new game v0 ({i&S }) = 1, whereasvalue original game v(S) = 0. Thus, wmg consistent. hand,value coalition players ({2, 4} G {2, 3} wmg (G , S)) decreases 10. Thus, wmg independent.similar example obtained using, e.g., maximum minimum weight coalitionsplayers instead product weights, function additive.591fiR EY & ROTHEgeneral, merging function csg class constant-sum games (i.e., games G = (N, v)v(C) + v(N r C) = v(N) holds coalition C N) neither consistent independent whenever G = (N, v), coalition N, csg (G , S) = (N 0 , v0 ),v(S) 6= v0 ({i&S }) v(N) = v0 (N 0 ), since v(N r S) 6= v0 (N r {i&S }).pointed anonymous reviewer, natural merging splitting functions may alsoexist important classes coalitional games transferable utilities playerposesses certain amount divisible resource, fractional matching games, bankruptcygames, market games (see, e.g., Shoham & Leyton-Brown, 2009). Moreover, one could considerclass path-disruption games (Bachrach & Porat, 2010; Rey & Rothe, 2011, 2012; Marple,Rey, & Rothe, 2014), merging two unconnected vertices might influence valuecoalition players. approach define merging splitting functionnetwork flow games found Section 5.2.5.1 Beneficial Merging Splitting Generalized: Case Two Playersdefine beneficial merging splitting problems general. Let G mergingfunction G splitting function class G coalitional games let PI powerindex. Define following generalized problems.G -PI-B ENEFICIAL ERGEGiven:Question:game G = (N, v) G nonempty coalition N.true PI(G (G , S), i&S ) > PI(G , i), G (G , S) = (N 0 , v0 ) N 0 ={i&S } (N r S)?G -PI-B ENEFICIAL PLITGiven:Question:game G = (N, v) G, N = {1, . . . , n}, player N, integer 2.game G 0 = (N 0 , v0 ) G (G , i, m) N 0 = {n + 1, . . . , n + m} (N r {i})mj=1 PI(G 0 , n + j) > PI(G , i)?Intuitively, G -PI-B ENEFICIAL ERGE problem whether coalition players benefit merging via G raising power terms f . Similarly, G -PI-B ENEFICIAL PLITproblem whether player benefit splitting number new players via Graising power terms PI.Generalizing Proposition 4.1, consistency independence satisfied merging function, coalition two players cannot benefit merging player benefit splittingtwo players considering probabilistic Banzhaf index.Theorem 5.3. Let G merging function let G splitting function, satisfyingconsistency independence.1. G -Banzhaf-B ENEFICIAL ERGE P instances (G , S) kSk = 2.2. G -Banzhaf-B ENEFICIAL PLIT P instances (G , i, 2).Proof. Let G = (N, v) coalitional game let G consistent independent mergingfunction. Without loss generality (see Footnote 8), let = {n 1, n}. obtain new game592fiFALSE -NAME ANIPULATION WVG H ARD PPG (G , S) = ({1, . . . , n 1}, v0 ), n 1 new player merging G . holdsBanzhaf(G (G , S), n1) (Banzhaf(G , n1) + Banzhaf(G , n))=12(v0 (C {n1}) v0 (C))2n1 C{1,...,n2}(v(C {n1}) v(C))CNr{n1,n}(v(C {n1}) v(C))CNr{n1},nC(v(C {n}) v(C))CNr{n,n1}=12n1(v(C {n}) v(C))CNr{n},n1C002v (C {n1}) 2v(C {n1, n}) + 2v(C) 2v (C) = 0.|{z}|{z}C{1,...,n2}= 0 (by consistency)= 0 (by independence)case splitting, consider game G = (N, v) n players, consistent independentsplitting function G , and, without loss generality, player n G splitting players n + 1n + 2, results new game G 0 G (G , n, 2). Now, similarly holdsBanzhaf(G 0 , n + 1) + Banzhaf(G 0 , n + 2) Banzhaf(G , n) = 0,qclaimed.particular, immediately implies Proposition 4.1 wvg wvg . another example,next consider threshold network flow games hypergraphs, class compactly representablesimple coalitional games.5.2 Example: Threshold Network Flow Games HypergraphsBachrach Rosenschein (2009) analyze threshold network flow games graphs. thresholdnetwork flow game (TNFG, short) defined edge-weighted graph n agentscontrol one edge, source vertex V target vertex V , threshold k R.coalitional function success function, coalition agents successfuldata flow size k sent edges represented agents coalition.merging splitting defined setting? Since agents control single edges,11merging two agents would yield one new agent controls one edgewould qualitively different remaining agents. Similarly, splitting agent severalsubagents would mean split original agents edge, unclear that.approach solving issue consider threshold network flow games hypergraphs rathergraphs. hyperedge hypergraph subset vertex set (so graph specialcase hypergraph hyperedges size two only). course, agents hypergraphcontrol hyperedges different sizes, merely quantitative difference.11. Kalai Zemel (1982a, 1982b) propose model agent controls set edges, single edge.suggested anonymous reviewer, natural merging function would assign merging coalitionunion sets edges controlled players coalition original game.593fiR EY & ROTHEDefinition 5.4. threshold hypergraph network flow game (THNFG, short) G = (N, v) setweighted hypergraph H = (V, E) vertex set V set E = {e1 , . . . , en } n weightedhyperedges (where agent represents hyperedge ei ), weight function w : E N (representedlist (w1 , . . . , wn ) wi = w(ei )), source vertex V target vertex V , thresholdk R. coalitional function v : P(N) {0, 1} defined v(C) = 1 data flow size kpossible H|C , subhypergraph H induced hyperedge set {ei | C},v(C) = 0 otherwise.Example 5.5. THNFG four agents Figure 1 may help visualize definitionstheorems given below. shows hypergraph (in standard bipartite graph representationhypergraphs) related game G = ({1, . . . , 5}, v)G = (H, s,t, w, k) = (({v1 , . . . , v5 }, {{v4 , v5 }, {v1 , v3 , v4 }, {v2 , v3 , v5 }, {v3 , v5 }}), v3 , v5 , (1, 2, 3, 4), 5).| {z } | {z } | {z } | {z }e1v1v2e1e2e3v3v4e3e2e4v5e4Figure 1: THNFG Example 5.5Possible applications THNFGs found grid computing manyoften thousands ofcomputers collaborate solve common task distributing various subtasks certainclusters computers, represent agents (respectively, hyperedges). Connecting number computer clusters corresponds forming coalition agents. Modeled game,coalition (i.e., set clusters) successful connects source target allowssufficient network data flow within capacity computers clusters, caseclusters assigned desired subtask. another example possible applicationTHNFGs, propose use model smart power grids deliver electricity suppliersconsumers. Success coalition would mean certain threshold exceededaccording consumers current demands, thus allowing sufficiently large power flow.TNFGs, determining raw Banzhaf index #P-complete, ShapleyShubikindex known least hard problems NP (Bachrach & Rosenschein, 2009).However, THNFGs, following results consequences corresponding resultsweighted voting games. easy hardness proof simply reduces problem WVGscorresponding problem THNFGs mapping given WVG G = (w1 , . . . , wn , q) THNFGH = (({v0 , v1 , . . . , vn+1 }, {e1 , . . . en }), v0 , vn+1 , (w1 , . . . , wn ), q),ei = {v0 , vi , vn+1 } i, 1 n, weights threshold. Since valuecoalition C G equals value C H , Banzhaf (G , i) = Banzhaf (H , i)594fiFALSE -NAME ANIPULATION WVG H ARD PPShapleyShubik (G , i) = ShapleyShubik (H , i) player i. Since reduction parsimonious, #P-parsimonious-hardness Banzhaf THNFGs inherited WVGs,#P-many-one-hardness ShapleyShubik THNFGs inherited WVGs.Proposition 5.6. Computing raw Banzhaf power index THNFGs #P-parsimonious-complete,computing raw ShapleyShubik power index THNFGs #P-many-one-complete.power compare problem weighted voting games respect power index PI(originally introduced Faliszewski & Hemaspaandra, 2009) defined analogouslyTHNFGs:PI-THNFG-P OWER C OMPAREGiven:Question:Two THNFGs, G G 0 , player occurring games.true PI(G , i) > PI(G 0 , i)?suitably extending reduction given right Proposition 5.6, following.Corollary 5.7. PI-THNFG-P OWER C OMPARE PP-hard PI {ShapleyShubik, Banzhaf}.use hyperedges makes possible that, THNFGs, coalition agents mergedsingle new agent controls hyperedge corresponds union vertices belonging hyperedges coalitions original agents. example grid computing, mergetwo clusters allows new connections well sum computing power computersclusters total weight. Similarly, possible agent setting splitseveral subagents partitioning agents hyperedge subsets controlled onenew subagents. define merging function splitting function THNFGsfollows:merging function thnfg THNFGs maps given THNFG G = (H, s,t, w, k), hypergraph H = (V, E), given coalition agents new THNFG thnfg (G , S) =(H&S , s,t, w&S , k), new hypergraph H&S = (V, E&S ) new set hyperSedges E&S = (E r {ei | S}) {e&S }, new agent i&S controls hyperedge e&S = ei ,new weight function w&S given w&S (ei ) = wi 6 S, w&S (e&S ) = wi .splitting function thnfg THNFGs maps given THNFG G = (H, s,t, w, k),hypergraph H = (V, E), given agent i, given integer 2 new THNFGthnfg (G , i, m) = (Him , s,t, wim , k), new hypergraph = (V, Eim )Eim = (E r {ei }) {en+1 , . . . , en+m }, agent split agents n + 1, . . . , n +mj=1 en+ j = ei en+ j e` = 0/ ` {1, . . . , n} r {i}, new weight functionwim given wim (e` ) = w` ` 6= i, new agents weights wn+ j = wim (en+ j ),1 j m, satisfy mj=1 wn+ j = wi .contrast weighted voting games, consistency satisfied general THNFGs, neitherthnfg thnfg . one hand, merging two agents via thnfg create new connectionsvertices thus allows new data flows emerge. hand, existing connectionsget lost splitting agent via thnfg (i.e., splitting corresponding hyperedge). Therefore,merging splitting thnfg thnfg might advantageous probabilistic Banzhaf index,even size-two coalitions split two players.595fiR EY & ROTHEExample 5.8 (continuing Example 5.5). Consider THNFG G Example 5.5. Mergingagents coalition = {1, 3} via thnfg , allows new connections, disadvantagousprobabilistic Banzhaf index new gamethnfg (G , {1, 3}) = (({v1 . . . , v5 }, {{v2 , v3 , v4 , v5 }, {v1 , v3 , v4 }, {v3 , v5 }}), v3 , v5 , (4, 2, 4), 5).|{z} | {z } | {z }e&{1,3}e2e4However, merging agents coalition = {1, 2} via thnfg , beneficial probabilisticBanzhaf index new gamethnfg (G , {1, 2}) = (({v1 . . . , v5 }, {{v1 , v3 , v4 , v5 }, {v2 , v3 , v5 }, {v3 , v5 }}), v1 , v5 , (3, 3, 4), 5).|{z} | {z } | {z }e&{1,2}e3e4comparison, let G 0 corresponding weighted voting game G 0 = (1, 2, 3, 4; 5) (i.e.,0weights threshold). Merging agents = {1, 3} G 0 via wvg (G 0 , S) = G&{1,3}=000(4, 2, 4; 5) well merging agents = {1, 2} G via wvg (G , S) = G&{1,2} = (3, 3, 4; 5)neutral probabilistic Banzhaf index.However, wvg wvg weighted voting games, thnfg thnfg satisfy independence THNFGs: value coalition depends hyperedges agentswithin coalition, hyperedges might merged split.5.3 Merging Splitting Unanimity Gamessimple game G = (N, v) called unanimity game grand coalition wins, i.e., v(C) = 1C = N, v(C) = 0 C ( N. example, weighted voting game G = (w1 , . . . , wn ; q)unanimity weighted voting game ni=1 wi miniN wi < q ni=1 wi .one possible merging function unanimity games. Let G unanimity gamelet N coalition. Define ug (G , S) = (N 0 , v0 ) N 0 = {i&S } (N r S) v0 (C) = 1C = N 0 , v0 (C) = 0 C ( N 0 . Obviously, ug satisfies consistency independence.unanimity weighted voting games, Aziz et al. (2011) show normalized Banzhafindex, merging always disadvantageous, whereas splitting always advantageous. (Thus onedecide polynomial time whether merging splitting beneficial.) strong contrast,show unanimity games respect probabilistic Banzhaf index, splitting alwaysdisadvantageous neutral, whereas merging neutral size-two coalitions, yet advantageouscoalitions least three players.Theorem 5.9. Let G unanimity game player set N.1. (G , S) 6 ug -Banzhaf-B ENEFICIAL ERGE N kSk = 2,2. (G , S) ug -Banzhaf-B ENEFICIAL ERGE N kSk 3.3. (G , i, m) 6 ug -Banzhaf-B ENEFICIAL PLIT N 2.Proof. first statement follows immediately Theorem 5.3.prove second statement, note unanimity game, player pivotalcoalition = N r {i}, always pivotal coalition. Thus raw Banzhaf596fiFALSE -NAME ANIPULATION WVG H ARD PPindex always equal one. follows Banzhaf(G , i) = 1/2n1 player N.arbitrary coalition merges, Banzhaf index player new game ug (G , S)Banzhaf(ug (G , S), i) = 1/2nkSk . Since kSk 3,Banzhaf(ug (G , S), i&S ) Banzhaf(G , i) =2kSk1 kSk> 0.2n1third statement shown similar arguments. particular, possible splitplayers integer weights,Banzhaf(ug (G , i, m), n + j) Banzhaf(G , i) =j=12m10.2n+m2qcompletes proof.6. Conclusions Future Workanalyzed beneficial merging, splitting, annexation problems terms complexity. particular, results complementby considering probabilistic Banzhaf powerindexthose Aziz et al. (2011) normalized Banzhaf power index weighted votinggames. extent, results differ normalized Banzhaf power index:probabilistic Banzhaf power index, beneficial merging splitting turns tractablemerger size-two coalitions split two players.One main results that, solving previous conjectures affirmative, pinpointed precise complexity beneficial merging problem weighted voting gamesShapleyShubik probabilistic Banzhaf index showing PP-complete cases.one hand, result interesting theoretical point view.hand, provides PP-completeness result natural problem game theory,far rarer NP-complete problems field. Since merging seen manipulative behavior, high complexity interpreted protection shield strategic interference.several known methods circumvent NP-hardnesssuch approximation, fixedparameter tractability, typical case analyses (for discussion applying methods NP-hardvoting problems see, e.g., Rothe & Schend, 2013), recent algebraic approach (Berghammer &Schnoor, 2014), methods less applicable circumvent hardness higher complexityclasses. Since PP considered much larger complexity class NP, PP-hardnessseen leading potentially higher degree protection mere NP-hardness. Still, hardness problems rests hardness compute related power indices. Notegood approximation schemes dynamic methods known computing ShapleyShubikindex (see, e.g., Bachrach, Markakis, Resnik, Procaccia, Rosenschein, & Saberi, 2010; Fatima,Wooldridge, & Jennings, 2008; Bilbao, Fernndez, Jimnez, & Lpez, 2000; Matsui & Matsui,2000; Shapley, 1953), though much known exact case.obtained PP-completeness result beneficial splitting (a.k.a. false-namemanipulation) whenever new players weights given. given number false identities,unknown weights, raised lower bound (known ShapleyShubik index) NPhardness PP-hardness showed contained NPPP whenever number false597fiR EY & ROTHEidentities given unary. problem, remains open whether shown completeNPPP , huge complexity class thatby Todas theorem (1991)contains entire polynomialhierarchy. NPPP interesting class, somewhat sparse natural complete problems.(natural) NPPP -completeness results aware due Littman et al. (1998), analyzevariant satisfiability problem questions related probabilistic planning, dueMundhenk et al. (2000), study problems related finite-horizon Markov decision processes.Another interesting open question whether results transferred also beneficialmerging splitting problems normalized Banzhaf index power indices.beneficial annexation problem takeover single player, showed NPcompleteness ShapleyShubik probabilistic Banzhaf index.Finally, proposed general framework merging splitting appliedvarious classes coalitional games transferable utilities. interesting task futureresearch study useful properties merging splitting functions, consistencyindependence, general applied particular classes games like network flow gamesmarket games. Another interesting question, raised anonymous reviewer, naturallyextend idea merging classes games players control several resources.properties want hold case? Also, merging function satisfies independenceconsistence unique certain class games? unanimity games observedone possible merging function guarantees unanimity. weighted voting games,however, uniqueness result hold, since different ways distributeplayers weights lead coalitional function. instance, games (1, 3, 4; 8)(2, 3, 4; 8) semantically same, even players merge. Restricting classes requiringproperties might imply uniqueness. Although consistency seems essential propertymerging splitting function, seen natural merging function threshold hypergraphnetwork flow games satisfy property, made similar observationsclasses games.AcknowledgmentsPreliminary versions parts paper appear proceedings 19th European Conference Artificial Intelligence (ECAI10) (Rey & Rothe, 2010a), 5th European Starting AIResearcher Symposium (STAIRS10) (Rey & Rothe, 2010b), 11th Latin American Theoretical Informatics Symposium (LATIN14) (Rey & Rothe, 2014). grateful anonymousJAIR, ECAI10, STAIRS10, LATIN14, CoopMAS14 reviewers helpful commentspaper. work supported part DFG grants RO 1202/11-1, RO 1202/12-1 (withinESF EUROCORES program LogICCC), RO 1202/14-1.ReferencesAziz, H., Bachrach, Y., Elkind, E., & Paterson, M. (2011). False-name manipulations weightedvoting games. Journal Artificial Intelligence Research, 40, 5793.Aziz, H., Brandt, F., & Brill, M. (2013). computational complexity random serial dictatorships. Economic Letters, 121(3), 341345.598fiFALSE -NAME ANIPULATION WVG H ARD PPAziz, H., & Paterson, M. (2009). False name manipulations weighted voting games: Splitting,merging annexation. Proceedings 8th International Joint Conference Autonomous Agents Multiagent Systems, pp. 409416. IFAAMAS.Bachrach, Y., & Elkind, E. (2008). Divide conquer: False-Name manipulations weighted voting games. Proceedings 7th International Joint Conference Autonomous AgentsMultiagent Systems, pp. 975982. IFAAMAS.Bachrach, Y., Elkind, E., Meir, R., Pasechnik, D., Zuckerman, M., Rothe, J., & Rosenschein, J.(2009). cost stability coalitional games. Proceedings 2nd InternationalSymposium Algorithmic Game Theory, pp. 122134. Springer-Verlag Lecture NotesComputer Science #5814.Bachrach, Y., Markakis, E., Resnik, E., Procaccia, A., Rosenschein, J., & Saberi, A. (2010). Approximating power indices: Theoretical empirical analysis. Journal Autonomous AgentsMulti-Agent Systems, 20(2), 105122.Bachrach, Y., & Porat, E. (2010). Path disruption games. Proceedings 9th InternationalJoint Conference Autonomous Agents Multiagent Systems, pp. 11231130. IFAAMAS.Bachrach, Y., & Rosenschein, J. (2009). Power threshold network flow games. Journal Autonomous Agents Multi-Agent Systems, 18(1), 106132.Banzhaf III, J. (1965). Weighted voting doesnt work: mathematical analysis. Rutgers LawReview, 19, 317343.Berghammer, R., & Schnoor, H. (2014). Control condorcet voting: Complexity relationalgebraic approach (extended abstract). Proceedings 13th International Joint Conference Autonomous Agents Multiagent Systems, pp. 13651366. IFAAMAS.Bilbao, J., Fernndez, J., Jimnez, N., & Lpez, J. (2000). Generating functions computingpower indices efficiently. Top, 8(2), 191213.Bilbao, J., Fernndez, J., Jimnez, N., & Lpez, J. (2002). Voting power European Unionenlargement. European Journal Operational Research, 143(1), 181196.Chalkiadakis, G., Elkind, E., & Wooldridge, M. (2011). Computational Aspects CooperativeGame Theory. Synthesis Lectures Artificial Intelligence Machine Learning. MorganClaypool Publishers.Deng, X., & Papadimitriou, C. (1994). complexity comparative solution concepts. Mathematics Operations Research, 4(2), 257266.Dubey, P., & Shapley, L. (1979). Mathematical properties Banzhaf power index. MathematicsOperations Research, 4(2), 99131.Elkind, E., Chalkiadakis, G., & Jennings, N. (2008). Coalition structures weighted voting games.Proceedings 18th European Conference Artificial Intelligence, pp. 393397. IOSPress.Elkind, E., Goldberg, L., Goldberg, P., & Wooldridge, M. (2009). computational complexityweighted voting games. Annals Mathematics Artificial Intelligence, 56(2), 109131.599fiR EY & ROTHEElkind, E., Pasechnik, D., & Zick, Y. (2013). Dynamic weighted voting games. Proceedings12th International Joint Conference Autonomous Agents Multiagent Systems, pp.515522. IFAAMAS.Faliszewski, P., & Hemaspaandra, L. (2009). complexity power-index comparison. Theoretical Computer Science, 410(1), 101107.Fatima, S., Wooldridge, M., & Jennings, N. (2008). linear approximation method shapleyvalue. Artificial Intelligence, 172(14), 16731699.Felsenthal, D., & Machover, M. (1995). Postulates paradoxes relative voting powercritical re-appraisal. Theory Decision, 38(2), 195229.Felsenthal, D., & Machover, M. (2005). Voting power measurement: story misreinvention.Social Choice Welfare, 25(2), 485506.Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory NPCompleteness. W. H. Freeman Company.Gill, J. (1977). Computational complexity probabilistic Turing machines. SIAM JournalComputing, 6(4), 675695.Hunt, H., Marathe, M., Radhakrishnan, V., & Stearns, R. (1998). complexity countingproblems. SIAM Journal Computing, 27(4), 11421167.Kalai, E., & Zemel, E. (1982a). Generalized network problems yielding totally balanced games.Operations Research, 30(5), 9981008.Kalai, E., & Zemel, E. (1982b). Totally balanced games games flow. Mathematics Operations Research, 7(3), 476478.Karp, R. (1972). Reducibility among combinatorial problems. Miller, R., & Thatcher, J. (Eds.),Complexity Computer Computations, pp. 85103. Plenum Press.Littman, M., Goldsmith, J., & Mundhenk, M. (1998). computational complexity probabilisticplanning. Journal Artificial Intelligence Research, 9(1), 136.Marple, A., Rey, A., & Rothe, J. (2014). Bribery multiple-adversary path-disruption gameshard second level polynomial hierarchy (extended abstract). Proceedings13th International Joint Conference Autonomous Agents Multiagent Systems.IFAAMAS. appear.Matsui, T., & Matsui, Y. (2000). survey algorithms calculating power indices weightedmajority games. Journal Operation Research Society Japan, 43(1), 7186.Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (2000). Complexity results finitehorizon Markov decision process problems. Journal ACM, 47(4), 681720.Nisan, N., Roughgarden, T., Tardos, ., & Vazirani, V. (Eds.). (2007). Algorithmic Game Theory.Cambridge University Press.Papadimitriou, C. (1995). Computational Complexity (Second edition). Addison-Wesley.Peleg, B., & Sudhlter, P. (2003). Introduction Theory Cooperative Games. KluwerAcademic Publishers.Penrose, L. (1946). elementary statistics majority voting. Journal Royal StatisticalSociety, 109(1), 5357.600fiFALSE -NAME ANIPULATION WVG H ARD PPPrasad, K., & Kelly, J. (1990). NP-completeness problems concerning voting games. International Journal Game Theory, 19(1), 19.Rey, A., & Rothe, J. (2010a). Complexity merging splitting probabilistic Banzhafpower index weighted voting games. Proceedings 19th European ConferenceArtificial Intelligence, pp. 10211022. IOS Press.Rey, A., & Rothe, J. (2010b). Merging splitting power indices weighted voting gamesnetwork flow games hypergraphs. Proceedings 5th European Starting AIResearcher Symposium, pp. 277289. IOS Press.Rey, A., & Rothe, J. (2011). Bribery path-disruption games. Proceedings 2nd International Conference Algorithmic Decision Theory, pp. 247261. Springer-Verlag LectureNotes Artificial Intelligence #6992.Rey, A., & Rothe, J. (2012). Probabilistic path-disruption games. Proceedings 20th European Conference Artificial Intelligence, pp. 923924. IOS Press. extended versionappears proceedings 6th European Starting AI Researcher Symposium, IOS Press,pages 264269, August 2012.Rey, A., & Rothe, J. (2014). False-name manipulation weighted voting games hard probabilistic polynomial time. Proceedings 11th Latin American Theoretical InformaticsSymposium, pp. 6071. Springer-Verlag Lecture Notes Computer Science #8392.Rothe, J. (2005). Complexity Theory Cryptology. Introduction Cryptocomplexity. EATCSTexts Theoretical Computer Science. Springer-Verlag.Rothe, J., & Schend, L. (2013). Challenges complexity shields supposed protectelections manipulation control: survey. Annals Mathematics ArtificialIntelligence, 68(13), 161193.Shapley, L. (1953). value n-person games. Kuhn, H., & Tucker, A. (Eds.), ContributionsTheory Games, Vol. II Annals Mathematics Studies 40. Princeton UniversityPress.Shapley, L., & Shubik, M. (1954). method evaluating distribution power committeesystem. American Political Science Review, 48(3), 787792.Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems. Algorithmic, Game-Theoretic,Logical Foundations. Cambridge University Press.Toda, S. (1991). PP hard polynomial-time hierarchy. SIAM Journal Computing,20(5), 865877.Valiant, L. (1979). complexity computing permanent. Theoretical Computer Science,8(2), 189201.Wagner, K. (1986). complexity combinatorial problems succinct input representations.Acta Informatica, 23, 325356.Zank, V. (1991). #P-completeness via many-one reductions. International Journal FoundationsComputer Science, 2(1), 7682.Zuckerman, M., Faliszewski, P., Bachrach, Y., & Elkind, E. (2012). Manipulating quotaweighted voting games. Artificial Intelligence, 180-181(0), 119.601fiJournal Artificial Intelligence Research 50 (2014) 369-407Submitted 10/13; published 6/14HC-Search: Learning Framework Search-basedStructured PredictionJanardhan Rao Doppadoppa@eecs.oregonstate.eduSchool EECS, Oregon State UniversityCorvallis, 97331-5501, USAAlan Fernafern@eecs.oregonstate.eduSchool EECS, Oregon State UniversityCorvallis, 97331-5501, USAPrasad Tadepallitadepall@eecs.oregonstate.eduSchool EECS, Oregon State UniversityCorvallis, 97331-5501, USAAbstractStructured prediction problem learning function maps structured inputsstructured outputs. Prototypical examples structured prediction include part-ofspeech tagging semantic segmentation images. Inspired recent successessearch-based structured prediction, introduce new framework structured predictioncalled HC-Search. Given structured input, framework uses search procedure guidedlearned heuristic H uncover high quality candidate outputs employsseparate learned cost function C select final prediction among outputs.overall loss prediction architecture decomposes loss due H leadinghigh quality outputs, loss due C selecting best among generatedoutputs. Guided decomposition, minimize overall loss greedy stage-wisemanner first training H quickly uncover high quality outputs via imitation learning,training C correctly rank outputs generated via H according truelosses. Importantly, training procedure sensitive particular loss functioninterest time-bound allowed predictions. Experiments several benchmarkdomains show approach significantly outperforms several state-of-the-art methods.1. Introductionconsider problem structured prediction, predictor must producestructured output given structured input. example, Part-Of-Speech (POS) tagging, structured input sequence words structured output correspondsPOS tags words. Image scene labeling another example, structuredinput image structured output semantic labeling image regions.Structured prediction tasks arise several domains ranging naturallanguage processing (e.g., named entity recognition, coreference resolution, semanticparsing) computer vision (e.g., multi-object tracking activity recognition videos)speech (e.g., text-to-speech mapping speech recognition) compuational biology(e.g., protein secondary structure prediction gene prediction).Viewed traditional classification problem, set possible classes structuredprediction exponential size input. Thus, problem producingc2014AI Access Foundation. rights reserved.fiDoppa, Fern, & Tadepallioutput combinatorial nature, introduces non-trivial choice selectingcomputational framework producing outputs. Importantly, framework needsbalance two conflicting criteria: 1) must flexible enough allow complexaccurate structured predictors learned, 2) must support inference outputswithin computational time constraints application. One core researchchallenges structured prediction achieve balance criteria.standard approach structured prediction learn cost function C(x, y)scoring potential structured output given structured input x. Given costfunction new input x, output computation involves solving so-called Argminproblem, find minimum cost output given input.= arg minyY(x) C(x, y)(1)example, approaches Conditional Random Fields (CRFs) (Lafferty, McCallum,& Pereira, 2001), Max-Margin Markov Networks (Taskar, Guestrin, & Koller, 2003)Structured SVMs (Tsochantaridis, Hofmann, Joachims, & Altun, 2004) represent costfunction linear model template features x y. Unfortunately, exactlysolving Argmin problem often intractable. Efficient solutions exist limitedcases dependency structure among features forms tree. cases, oneforced simplify features allow tractable inference, detrimentalprediction accuracy. Alternatively, heuristic optimization method usedloopy belief propagation variational inference. methods shownsuccess practice, difficult characterize solutions predictlikely work well new problem.inspired recent successes output-space search approaches (Doppa, Fern,& Tadepalli, 2012; Wick, Rohanimanesh, Bellare, Culotta, & McCallum, 2011), placerestrictions form cost function. methods learn use costfunction conduct search space complete outputs via search procedure(e.g., greedy search), return least cost output uncovered searchprediction. search procedure needs able efficiently evaluate costfunction specific input-output pairs, generally straightforward evencorresponding Argmin problem intractable. Thus, methods free increasecomplexity cost function without considering impact inference complexity.approaches achieved state-of-the-art performance numberbenchmark problems, primary contribution paper highlight fundamentaldeficiency share. particular, prior work uses single cost function servedual roles both: 1) guiding search toward good outputs, 2) scoring generatedoutputs order select best one. Serving dual roles often means costfunction needs make unclear tradeoffs, increasing difficulty learning. Indeed,traditional AI search literature, roles typically served different functions,mainly heuristic function guiding search, cost/evaluation function (often partproblem definition) selecting final output.paper, study new framework structured prediction called HC-Searchclosely follows traditional search literature. key idea learn distinct functionsroles: 1) heuristic function H guide search generate sethigh-quality candidate outputs, 2) cost function C score outputs generated370fiHC-Search: Learning Framework Search-based Structured Predictionheuristic H. Given structured input, predictions made using H guidesearch strategy (e.g., greedy search beam search) time bound generate setcandidate outputs returning generated output least cost according C.move HC-Search might appear relatively small, significantimplications terms theory practice. First, regret HC-Searchapproach decomposed loss due H leading high quality outputs,loss due C selecting best among generated outputs. decompositionhelps us target training minimize losses individually greedy stagewise manner. Second, show, performance approaches singlefunction arbitrarily bad compared HC-Search worst case.Finally, show practice HC-Search performs significantly better singlecost function search state-of-the-art approaches structured prediction.effectiveness HC-Search approach particular problem depends criticallyon: 1) quality search space complete outputs used, qualitydefined expected depth target outputs (zero loss outputs) located, 2)ability learn heuristic function effectively guiding search generate highquality candidate outputs, 3) accuracy learned cost function selectingbest output among candidate outputs generated heuristic function. work,assume availability efficient search space complete outputs provideeffective training regime learning heuristic function cost function withinHC-Search framework.1.1 Summary Contributionsmain contributions work follows: 1) introduce HC-Search framework, two different functions learned serve purposes search heuristiccost function search literature; 2) analyze representational powercomputational complexity learning within HC-Search framework; 3) identifynovel decomposition overall regret HC-Search approach terms generationloss, loss due heuristic generating high-quality candidate outputs, selectionloss, loss due cost function selecting best among generated outputs; 4)Guided decomposition, propose stage-wise approach learning heuristiccost functions based imitation learning; 5) empirically evaluate HC-Searchapproach number benchmarks, comparing state-of-the-art methods analyzing different dimensions framework.remainder paper proceeds follows. Section 2, introduce problemsetup, give high-level overview framework, analyze complexity HC-Searchlearning problem. describe approaches heuristic cost function learningSection 3. Section 4 presents experimental results followed engineering methodology applying framework new problems Section 5. Finally, Sections 6 7discuss related work future directions.371fiDoppa, Fern, & Tadepalli2. HC-Search Frameworksection, first state formal problem setup describe specificssearch spaces search strategies investigate work. Next, givehigh-level overview HC-Search framework along learning objective.2.1 Problem Setupstructured prediction problem specifies space structured inputs X , space structured outputs Y, non-negative loss function L : X 7 <+ L(x, 0 , )loss associated labeling particular input x output 0 true output . provided training set input-output pairs {(x, )} drawnunknown target distribution D. goal return function/predictor structured inputs outputs whose predicted outputs low expected loss respectdistribution D. Since algorithms learning heuristic cost functionsinput-output pairs, standard structured prediction, assume availabilityfeature function : X 7 <n computes n dimensional feature vectorpair. Importantly, employ two different feature functions H C heuristiccost function noting serving two different roles: heuristic makinglocal decisions guide search towards high-quality outputs cost functionmaking global decisions scoring candidate outputs generated heuristicframework.2.2 Search Spaces Search Strategiesoverview basic search concepts context search-based framework below.2.2.1 Search Spacesapproach based search space complete outputs, assumegiven. Every state search space complete outputs consists input-outputpair (x, y), representing possibility predicting output structured inputx. search space defined terms two functions: 1) initial state functionI(x) returns initial state input x, 2) successor functionsearch state (x, y), S((x, y)) returns set next states {(x, y1 ), , (x, yk )}share input x parent. example, sequence labeling problem,part-of-speech tagging, (x, y) sequence words corresponding part-of-speech(POS) labels. successors (x, y) might correspond ways changing oneoutput labels y, so-called flipbit space. Figure 1 provides illustrationflipbit search space handwriting recognition task.Search Space Quality. effectiveness HC-Search framework dependsquality search space used. quality search space turnunderstood terms expected amount search needed uncover correct output. search procedures, time required find target output growfunction depth target. Thus, one way quantify expected amountsearch, independently specific search strategy, considering expected depthtarget outputs . particular, given input-output pair (x, ), target depth372fiHC-Search: Learning Framework Search-based Structured PredictionFigure 1: example Flipbit search space handwriting recognition problem.search state consists complete input-output pair complete outputevery state differs parent exactly one label. highlightedstate corresponds one true output smallest depth,equal number errors initial state.373fiDoppa, Fern, & Tadepallidefined minimum depth find state corresponding targetoutput (d = 5 example flipbit space shown Figure 1). Clearly accordingdefinition, expected target depth flipbit space equal expected numbererrors output corresponding initial state.variety search spaces, flipbit space, Limited Discrepancy Search(LDS) space (Doppa et al., 2012), defined based hand-designed proposaldistributions (Wick et al., 2011) used past research. work appliesspace, focus LDS space experiment, showneffectively uncover high-quality outputs relatively shallow search depths (Doppa et al.,2012).LDS space defined terms recurrent classifier h uses next inputtoken, e.g. word, output tokens small preceding window, e.g. POS labels,predict next output token. initial state LDS space consists inputx paired output recurrent classifier h x. One problem recurrentclassifiers recurrent classifier makes mistake, effects get propagateddown-stream tokens. LDS space designed prevent error propagationimmediately correcting mistakes made continuing recurrent classifier.Since know mistakes made correct them, possiblecorrections, called discrepancies, considered. Hence successors state (x, y)LDS space consist results running recurrent classifier changing exactlyone label, i.e., introducing single new discrepancy, somewhere current outputsequence preserving previously introduced discrepancies. previous work,LDS space shown effective uncovering high-quality outputs relativelyshallow search depths, one would expect good recurrent classifier (Doppa et al.,2012). Appendix contains details examples LDS space employwork.2.2.2 Search StrategiesRecall HC-Search framework, role search procedure uncover highquality outputs. consider uninformed informed search strategies. However,uninformed search procedures like depth bounded breadth-first search practicalhigh-quality outputs exist small depths even feasible,good choice dont use search time bound intelligent waymake predictions. structured prediction problems, informed search strategiestake heuristic functions account, greedy search best-first search betterchoice, noting effectiveness depends quality search heuristic H. Priorwork (Doppa et al., 2012; Wick et al., 2011) shown greedy search (hill climbingbased heuristic value) works quite well number structured prediction tasksused effective search space. Thus, work, focus empirical workHC-Search framework using greedy search, though approach applies widely.2.3 HC-Search Approachapproach parameterized search space complete outputs (e.g., LDSspace), heuristic search strategy (e.g., greedy search), learned heuristic function374fiHC-Search: Learning Framework Search-based Structured PredictionFigure 2: high level overview HC-Search framework. Given structured input xsearch space definition , first instantiate search space completeoutputs. search node space consists complete input-output pair.Next, run search procedure (e.g., greedy search) guided heuristicfunction H time bound . highlighted nodes correspond searchtrajectory traversed search procedure, case greedy search.scores nodes correspond cost values, different heuristic scores (not shown figure). return least cost outputuncovered search prediction input x.H : X 7 <, learned cost function C : X 7 <. Given input xprediction time bound , HC-Search makes predictions follows. traverses searchspace starting I(x) using search procedure guided heuristic function Htime bound exceeded. cost function C applied find return least-costoutput generated search prediction input x. Figure 2 giveshigh-level overview HC-Search framework.formally, let YH (x) set candidate outputs generated using heuristic Hgiven input x. output returned HC-Search least cost outputset according C, i.e.,= arg minyYH (x) C(x, y)375fiDoppa, Fern, & TadepalliFigure 3: example illustrates C-Search suffer arbitrarily large loss compared HC-Search.expected loss HC-Search approach E(H, C) given heuristic H CdefinedE (H, C) = E(x,y )D L (x, y, )(2)goal learn heuristic function H corresponding cost function C minimizeexpected loss respective spaces H C, i.e.,(H , C ) = arg min(H,C)HC E (H, C)(3)contrast framework, existing approaches output space search (Doppa et al.,2012; Wick et al., 2011) use single function (say C) serve dual purpose heuristiccost function. raises question whether HC-Search, uses two different functions, strictly powerful terms achievable losses. followingproposition shows expected loss HC-Search arbitrarily smallerrestricting using single function C.Proposition 1. Let H C functions function space.learning problems, minC E(C, C) min(H,C) E(H, C). Moreover exist learning problemsminC E(C, C) arbitrarily larger (i.e. worse) min(H,C) E(H, C).Proof. first part proposition follows fact first minimizationsubset choices considered second.see second part, consider problem single training instance searchspace shown Figure 3. search procedure greedy search either guidedH HC-Search, C one function used. L(n) (n) representstrue loss feature vector node n respectively. cost heuristic functionslinear functions (n). Node 7 corresponds lowest-loss output greedy searchmust follow trajectory highlighted nodes order reach output. First considerHC-Search. highlighted path followed heuristic H needs satisfyfollowing constraints: H(3)<H(2), H(7)<H(6), weights wH = [1, 1, 1] result376fiHC-Search: Learning Framework Search-based Structured Predictionheuristic satisfies constraints. Given heuristic function, order return node7 final output, cost function must satisfy following constraints: C(7)<C(1),C(7)<C(2), C(7)<C(3), C(7)<C(6), weights wC = [1, 1, 0] solve problem.Thus see HC-Search achieve zero loss problem.consider case single function C used heuristic costfunction. order generate loss zero, function C must satisfy combinedset constraints placed heuristic cost function. However,verified set weights satisfies C(3)<C(2) C(7)<C(1),hence, single function C space achieve loss zero.scaling losses constant factors make loss suffered arbitrarily high.Thus, see potential representational advantages following HCSearch framework. follows, consider implications added expressivenessterms worst-case time complexity learning.2.4 Learning Complexityconsider feasibility efficient, optimal learning simplest setting greedysearch using linear heuristic cost functions represented weight vectors wHwC respectively. particular, consider HC-Search Consistency Problem,input training set structured examples, must decide whetherexists wH wC HC-Search using greedy search achieve zero losstraining set. first note, problem shown NP-Hard appealingresults learning beam search (Xu, Fern, & Yoon, 2009a). particular, resultsimply trivial cases, simply determining whether linearheuristic wH uncovers zero loss search node NP-Hard. Since HC-Searchreturn zero loss outputs heuristic able uncover them, see problemalso hard.prove stronger result provides insight HC-Search framework. particular, show even easy learn heuristic uncoverszero loss outputs, consistency problem still hard. shows, worst casehardness learning problem simply result hardness discoveringgood outputs. Rather problem additionally complicated potential interactionH C. Intuitively, learning H worst case ambiguitymany small loss outputs generate,able find effective C return best one. formalized followingtheorem, whose proof Appendix.Theorem 1. HC-Search Consistency Problem greedy search linear heuristiccost functions NP-Hard even restrict problems possibleheuristic functions uncover zero loss output.3. Learning Approachcomplexity result suggests that, general, learning optimal (H , C ) pairimpractical due potential interdependence. section, develop greedy377fiDoppa, Fern, & Tadepallistage-wise learning approach first learns H corresponding C. approachmotivated observing decomposition expected loss components due HC. Below, first describe decomposition staged learning approachmotivates. Next describe approaches learning heuristic cost functions.3.1 Loss Decomposition Staged Learningheuristic H cost function C, expected loss E (H, C) decomposedtwo parts: 1) generation loss H , due H generating high-quality outputs,2) selection loss C|H , additional loss (conditional H) due C selectingbest loss outputbest loss output generated heuristic. Formally, let yHset YH (x), i.e.,yH= arg minyYH (x) L(x, y, )express decomposition follows:E (H, C) = E(x,y )D L (x, yH, ) + E(x,y )D L (x, y, ) L (x, yH, y)|{z}|{z}H(4)C|HNote given labeled data, straightforward estimate generationselection loss, useful diagnosing HC-Search framework. example, oneobserves system high generation loss, little payoff workingimprove cost function. empirical evaluation illustratedecomposition useful understanding results learning.addition useful diagnosis, decomposition motivates learning approach targets minimizing errors separately. particular, optimizeoverall error HC-Search approach greedy stage-wise manner. first trainheuristic H order optimize generation loss component H train costfunction C optimize selection loss C|H conditioned H.H arg minHH HC arg minCC C|HNote approach greedy sense H learned without consideringproof Theorem 1 hinges coupling,implications learning C.found practice, learning H independently C effective strategy.follows, first describe generic approach heuristic function learningapplicable wide range search spaces search strategies, explaincost function learning algorithm.3.2 Heuristic Function Learninggenerally, learning heuristic viewed Reinforcement Learning (RL) problem heuristic viewed policy guiding search actions rewards378fiHC-Search: Learning Framework Search-based Structured Predictionreceived uncovering high quality outputs (Zhang & Dietterich, 1995). fact,approach explored structured prediction case greedy search (Wick,Rohanimanesh, Singh, & McCallum, 2009) shown effective given carefullydesigned reward function action space. viable approach, general purposeRL quite sensitive algorithm parameters specific definition rewardfunction actions, make designing effective learner quite challenging. Indeed, recent work (Jiang, Teichert, Daume III, & Eisner, 2012), shown generic RLalgorithms struggle structured prediction problems, even significant effortput forth designer. Hence, work, follow approach based imitationlearning, makes stronger assumptions, nevertheless effectiveeasy apply across variety problems.Algorithm 1 Heuristic Function Learning via Exact ImitationInput: = Training examples, (I, S) = Search space definition, L = Loss function, =Rank-based search procedure, max = search time boundOutput: H, heuristic function1: Initialize set ranking examples R =2: training example (x, )3:s0 = I(x) // initial state search tree4:M0 = {s0 } // set open nodes internal memory search procedure5:search step = 1 max6:Select state(s) expand: Nt =Select(A, L, Mt1 )7:Expand every state Nt using successor function S: Ct =Expand(Nt , S)8:Prune states update internal memory state search procedure:Mt =Prune(A, L, Mt1 Ct \ Nt )9:Generate ranking examples Rt imitate search step10:Add ranking examples Rt R: R = R Rt // aggregation training data11:end12: end13: H =Rank-Learner(R) // learn heuristic function ranking examples14: return learned heuristic function Hheuristic learning approach based observation many structuredprediction problems, quickly generate high-quality outputs guidingsearch procedure using true loss function L heuristic. Obviouslydone training data know . suggests formulating heuristiclearning problem framework imitation learning attempting learn heuristicmimics search decisions made true loss function training examples.learned heuristic need approximate true loss function uniformly outputspace, need make distinctions important guiding search.main assumptions made approach are: 1) true loss function provide effectiveheuristic guidance search procedure, worth imitating, 2)learn imitate search decisions sufficiently well.imitation learning approach similar prior work learning single cost functionsoutput-space search (Doppa et al., 2012). However, key distinction learning379fiDoppa, Fern, & Tadepallifocused making distinctions necessary uncovering good outputs (the purposeheuristic) hence requires different formulation. prior work, orderavoid need approximate loss function arbitrarily closely, restrictrank-based search strategies. search strategy called rank-based makessearch decisions comparing relative values search nodes (their ranks) assignedheuristic, rather sensitive absolute values heuristic. commonsearch procedures greedy search, beam search, best-first search fallcategory.3.2.1 Imitating Search BehaviorGiven search space complete outputs S, rank-based search procedure A,search time bound , learning procedure generates imitation training datatraining example (x, ) follows. run search procedure time boundinput x using heuristic equal true loss function, i.e. H(x, y) = L(x, y, ).search process observe pairwise ranking decisions made usingoracle heuristic record sufficient (see below) replicating search.state (x, y1 ) smaller loss (x, y2 ), ranking example generatedform constraint H(x, y1 )<H(x, y2 ). Ties broken using fixed arbitrator1 .aggregate set ranking examples collected training examples givenlearning algorithm learn weights heuristic function.learn function H hypothesis space H consistentranking examples, learned heuristic guaranteed replicate oracle-guidedsearch training data. Further, given assumptions base learning algorithm(e.g. PAC), generic imitation learning results used give generalization guaranteesperformance search new examples (Khardon, 1999; Fern, Yoon, & Givan, 2006;Syed & Schapire, 2010; Ross & Bagnell, 2010). experiments show, simpleapproach described above, performs extremely well problems.Algorithm 1 describes approach heuristic function learning via exact imitationsearch guided loss function. applicable wide-range search spaces, searchprocedures loss functions. learning algorithm takes input: 1) = {(x, )},set training examples structured prediction problem (e.g., handwriting recognition);2) = (I, S), search space complete outputs (e.g., LDS space), initialstate function successor function; 3) L, task loss function definedcomplete outputs (e.g., hamming loss); 4) A, rank-based search procedure (e.g., greedysearch); 5) max , search time bound (e.g., number search steps).algorithmic description Algorithm 1 assumes search proceduredescribed terms three steps executed repeatedly open list searchnodes: 1) selection, 2) expansion 3) pruning. execution, search procedureselects one open nodes internal memory expansion (step 6) basedheuristic value, expands selected nodes generate candidate set (step 7).retains subset open nodes expansion internal memoryprunes away remaining ones (step 8) based heuristic value. example,1. LDS Space employed work, implemented arbitrator breaks tiesbased position discrepancy (prefers earlier discrepancies).380fiHC-Search: Learning Framework Search-based Structured Predictiongreedy search maintains best node, best-first beam search retains best bnodes fixed beam-width b, pure best first search pruning.Algorithm 1 loops training example collects set ranking constraints. Specifically, example (x, ), search procedure run time boundmax using true loss function L heuristic (steps 2-12). search stepset pairwise ranking examples generated sufficient allowing search stepimitated (step 9) described detail below. constraintsaggregated across search steps training examples, given rank-learningalgorithm (e.g., Perceptron SVM-Rank) learn weights heuristic function(step 13).important step heuristic function learning algorithm generationranking examples imitate step search procedure (step 9). follows,give generic description sufficient pairwise decisions imitate search,illustrate greedy search simple example.3.2.2 Sufficient Pairwise Decisionsnoted need collect learn imitate sufficient pairwisedecisions encountered search. say set constraints sufficientstructured training example (x, ), heuristic function consistentconstraints causes search follow trajectory open lists encounteredsearch. precise specification constraints depends actual search procedureused. rank-based search procedures, sufficient constraintscategorized two types:1. Selection constraints, ensure search node(s) internal memorystate expanded next search step (are) ranked betternodes.2. Pruning constraints, ensure internal memory state (set search nodes)search procedure preserved every search step. specifically,constraints involve ranking every search node internal memory state better(lower H-value) pruned.Below, illustrate constraints concretely greedy search noting similarformulations rank-based search procedures straightforward (See (Doppa, Fern,& Tadepalli, 2014a) beam search formulation).3.2.3 Constraints Greedy Searchbasic rank-based search procedure. given input x, traversessearch space selecting next state successor current state looks bestaccording heuristic function H. particular, si search state step i, greedysearch selects si+1 = arg minsS(si ) H(s), s0 = I(x). greedy search, internalmemory state search procedure step consists best open (unexpanded)node si .381fiDoppa, Fern, & TadepalliFigure 4: example search tree illustrates greedy search loss function.node represents complete input-output pair evaluated using lossfunction. highlighted nodes correspond trajectory greedy searchguided loss function.Let (x, yi ) correspond input-output pair associated state si . Since greedysearch maintains single open node si internal memory every search step i,selection constraints. Let Ci+1 candidate set expanding state si ,i.e., Ci+1 = S(si ). Let si+1 best node candidate set Ci+1 evaluatedloss function, i.e., si+1 = arg minsCi+1 L(s). greedy search prunes nodescandidate set si+1 , pruning constraints need ensure si+1 ranked betternodes Ci+1 . Therefore, include one ranking constraint everynode (x, y) Ci+1 \ (x, yi+1 ) H(x, yi+1 ) < H(x, y).illustrate ranking constraints example. Figure 4 showsexample search tree depth two associated losses every search node.highlighted nodes correspond trajectory greedy search loss functionlearner imitate. first search step, {H(3) < H(2), H(3) < H(4)} pruningconstraints. Similarly, {H(10) < H(8), H(10) < H(9)} form pruning constraintssecond search step. Therefore, aggregate set constraints needed imitate greedysearch behavior shown Figure 4 are:{H(3) < H(2), H(3) < H(4), H(10) < H(8), H(10) < H(9)}.3.3 Cost Function LearningGiven learned heuristic H, want learn cost function correctly rankspotential outputs generated search procedure guided H. formally, let YH (x)set candidate outputs generated search procedure guided heuristic Hgiven input x, lbest loss best output among outputs evaluatedtrue loss function L, i.e., lbest = minyYH (x) L(x, y, ). exact learning scenario,goal find parameters cost function C every training example382fiHC-Search: Learning Framework Search-based Structured Prediction(x, ), loss minimum cost output equals lbest , i.e., L(x, y, ) = lbest ,= arg minyYH (x) C(x, y). practice, exact learning isnt possible, goalfind cost function average loss training data predicted outputusing cost function minimized.Algorithm 2 Cost Function Learning via Cross ValidationInput: = Training examples, = Search space definition, L = Loss function, =Search procedure, max = search time boundOutput: C, cost function1: Divide training set k folds D1 , D2 , , Dk2: // Learn k different heuristics H1 , , Hk3: = 1 k4:Ti = j6=i Dj // training data heuristic Hi5:Hi = Learn-Heuristic(Ti , , L, A, max ) // heuristic learning via Algorithm 16: end7: // Generate ranking examples cost function training8: Intialize set ranking examples R =9: = 1 k10:training example (x, ) Di11:Generate outputs running search procedure heuristic Hi timebound max : YHi (x) = Generate-Outputs(x, , A, Hi , max )12:Compute set best loss outputs: Ybest = {y YHi (x)|L(x, y, ) = lbest },lbest = minyYH (x) L(x, y, )13:pair outputs (ybest , y) Ybest YHi (x) \ Ybest14:Add ranking example C(x, ybest ) < C(x, y) R15:end16:end17: end18: // Train cost function ranking examples19: C = Rank-Learner(R)20: return learned cost function Cformulate cost function training problem instance rank learning problem(Agarwal & Roth, 2005). specifically, want best loss outputs YH (x)ranked better non-best loss outputs according cost function,bi-partite ranking problem. Let Ybest set best loss outputs YH (x), i.e.,Ybest = {y YH (x)|L(x, y, ) = lbest }. generate one ranking example every pairoutputs (ybest , y) Ybest YH (x) \ Ybest , requiring C(x, ybest )<C(x, y). searchprocedure able generate target output (i.e., lbest = 0), similarstandard learning CRFs SVM-Struct, results much simpler rank-learningproblem (cost function needs rank correct output incorrect outputsgenerated search). set best loss outputs Ybest large, bi-partiteranking may result highly over-constrained problem. cases, one could relaxproblem attempting learn cost function ranks least one output Ybest highernon-best loss outputs. easily implemented online-learning383fiDoppa, Fern, & Tadepalliframework follows. error (i.e., best cost output according currentweights/ Ybest ), weights updated ensure best cost output ybest Ybestaccording current weights ranked better outputs YH (x) \ Ybest .important note theory practice, distribution outputsgenerated learned heuristic H testing data may slightly differentone training data. Thus, train C training examples used train H, Cnecessarily optimized test distribution. mitigate effect, traincost function via cross validation (see Algorithm 2) training cost functiondata, used train heuristic. training methodology commonlyused Re-ranking style algorithms (Collins, 2000) among others.Algorithm 2 describes approach cost function training via cross validation.four main steps algorithm. First, divide training data k folds.Second, learn k different heuristics, heuristic Hi learned using datafolds excluding ith fold (Steps 3-6). Third, generate ranking examplescost function learning described using heuristic Hi datatrained (Steps 9-17). Finally, give aggregate set ranking examples R ranklearner (e.g., Perceptron, SVM-Rank) learn cost function C (Step 19).3.4 Rank Learnersection, describe specifics rank learner used learnheuristic cost functions aggregate sets ranking examples producedalgorithms. use off-the-shelf rank-learning algorithm (e.g., Perceptron,SVM-Rank) base learner train heuristic function set rankingexamples R. specific implementation employed online Passive-Aggressive(PA) algorithm (Crammer, Dekel, Keshet, Shalev-Shwartz, & Singer, 2006) baselearner. Training conducted 50 iterations experiments.PA online large-margin algorithm, makes several passes trainingexamples R, updates weights whenever encounters ranking error. Recallranking example form H(x, y1 ) < H(x, y2 ) heuristic training C(x, y1 ) <C(x, y2 ) cost function training, x structured input target output ,y1 y2 potential outputs x L(x, y1 , ) < L(x, y2 , ). Let >0difference losses two outputs involved ranking example.experimented PA variants use margin scaling (margin scaled ) slackscaling (errors weighted ) (Tsochantaridis, Joachims, Hofmann, & Altun, 2005). Sincemargin scaling performed slightly better slack scaling, report results PAvariant employs margin scaling. give full details margin scalingupdate.Let wt current weights linear ranking function.ranking errorcycling training data, i.e., wt (x, y2 ) wt (x, y1 ) < , newweights wt+1 corrects error obtained using following equation.wt+1 = wt + ((x, y2 ) (x, y1 ))384fiHC-Search: Learning Framework Search-based Structured Predictionlearning rate givenwt (x, y1 ) wt (x, y2 ) +=k(x, y2 ) (x, y1 )k2specific update previously used cost-sensitive multiclass classification(Crammer et al., 2006) (See Equation 51) structured output problems (Keshet,Shalev-Shwartz, Singer, & Chazan, 2005) (See Equation 7).4. Experiments Resultssection empirically investigate HC-Search approach comparestate-of-the-art structured prediction.4.1 Datasetsevaluate approach following four structured prediction problems includingthree benchmark sequence labeling problems 2D image labeling problem.Handwriting Recognition (HW). input sequence binary-segmentedhandwritten letters output corresponding character sequence [a z]+ .dataset contains roughly 6600 examples divided 10 folds (Taskar et al.,2003). consider two different variants task work Hal DaumeIII, Langford, Marcu (2009). HW-Small version, use one fold trainingremaining 9 folds testing, vice-versa HW-Large.NETtalk Stress. text-to-speech mapping problem, taskassign one 5 stress labels letter word. 1000 trainingwords 1000 test words standard dataset. use sliding window size3 observational features.NETtalk Phoneme. similar NETtalk Stress except taskassign one 51 phoneme labels letter word.Scene labeling. data set contains 700 images outdoor scenes (Vogel &Schiele, 2007). image divided patches placing regular grid size1010 entire image, patch takes one 9 semantic labels (sky,water, grass, trunks, foliage, field, rocks, flowers, sand ). Simple appearance featuresincluding color, texture position used represent patch. Trainingperformed 600 images, remaining 100 images used testing.4.2 Experimental SetupHC-Search experiments, use Limited Discrepancy Space (LDS) exactlydescribed work Doppa et al. (2012) search space structured outputs.Prior work HC-Search shown greedy search works quite well structured prediction tasks, particularly using LDS space (Doppa et al., 2012). Hence,consider greedy search experiments. would like point experiments shown using beam search best first search produce similar results.385fiDoppa, Fern, & Tadepallitraining testing set search time bound 25 search steps domainsexcept scene labeling, much larger search space uses = 150.found using values larger produce noticeable improvement.extremely small values , performance tends worse, increases quicklymade larger. also show results full spectrum time bounds later.domains, learn linear heuristic cost functions second order features unless otherwise noted. case, feature vector measures features neighboring label pairstriples along features structured input. measure error Hammingloss unless otherwise noted.4.3 Comparison State-of-the-Artcompare results HC-Search approach structured prediction algorithms including CRFs (Lafferty et al., 2001), SVM-Struct (Tsochantaridis et al., 2004),Searn (Hal Daume III et al., 2009), Cascades (Weiss & Taskar, 2010) C-Search,identical HC-Search except uses single-function output space search(Doppa et al., 2012). also show performance Recurrent, simplerecurrent classifier trained exactly work Doppa et al. (2012). top sectionTable 1 shows error rates different algorithms. scene labelingpossible run CRFs, SVM-Struct, Cascades due complicated grid structureoutputs (hence - table). report best published results CRFs,SVM-Struct, Searn. Cascades trained using implementation (Weiss, 2014) provided authors, used sequence labeling problems Hamming loss.would like point results cascades differ appearwork Doppa, Fern, Tadepalli (2013) obtained using updated2 versioncascades training code. Across benchmarks, see results HC-Search comparable significantly better state-of-the-art including C-Search, uses singlefunction heuristic function cost function. results scene labelingdomain significant improving error rate 27.05 19.71. resultsshow HC-Search state-of-the-art approach across problems learningseparate heuristic cost functions significantly improve output-space search.4.4 Higher-Order FeaturesOne advantages approach compared many frameworks structured prediction ability use expressive feature spaces without paying huge computationalprice. bottom part Table 1 shows results using third-order features (comparedsecond-order above) HC-Search, C-Search Cascades. Note practicalrun methods using third-order features due substantial increase inferencetime. overall error HC-Search higher-order features slightly improved comparedusing second-order features across benchmarks still better error-ratesC-Search Cascades third-order features, exception CascadesHW-Large. fact, HC-Search using second-order features still outperformingthird-order results methods three five domains.2. Personal communication author386fiHC-Search: Learning Framework Search-based Structured PredictionAlgorithmsHW-SmallHW-LargeDatasetsStress PhonemeScene labelingHC-SearchC-SearchCRFSVM-StructRecurrentSearnCascadesa. Comparison state-of-the-art12.8103.2317.5816.9117.0307.1621.0720.8119.9713.1121.4821.0919.6412.4922.0121.7034.3325.1327.1826.4217.8809.4223.8522.7413.0203.2220.4117.5619.7127.0543.3637.69-HC-SearchC-SearchCascadesb. Results Third-Order Features10.0402.2116.3214.2914.1504.7619.3618.1910.8202.1619.5117.4118.2525.79-Table 1: Error rates different structured prediction algorithms.4.5 Loss Decomposition Analysisexamine HC-Search C-Search terms loss decomposition (see Equation 4) generation loss H selection loss C|H . quantitieseasily measured HC-Search C-Search keeping track best loss outputgenerated search (guided either heuristic cost function C-Search)across testing examples. Table 2 shows results, giving overall error HCdecomposition across benchmarks HC-Search C-Search.first see generation loss H similar C-Search HC-Search acrossbenchmarks exception scene labeling, HC-Search generates slightly betteroutputs. shows least LDS search space difference performanceC-Search HC-Search cannot explained C-Search generating lower qualityoutputs. Rather, difference two methods reflected differenceselection loss C|H , meaning C-Search effective ranking outputsgenerated search compared HC-Search. result clearly shows advantageseparating roles C H understandable light training mechanismC-Search. approach, cost function trained satisfy constraints relatedgeneration loss selection loss. turns many generationloss constraints, hypothesize biases C-Search toward low generation lossexpense selection loss.results also show methods selection loss C|H contributes significantly overall error compared H . shows approachesable uncover high-quality outputs, unable correctly rank generatedoutputs according losses. suggests first avenue improving resultsHC-Search would improve cost function learning component, e.g. usingnon-linear cost functions.387fiDoppa, Fern, & Tadepalli4.6 Ablation Studyfuther demonstrate two separate functions (heuristic cost function)HC-Search lead accurate predictions compared using single functionC-Search, perform ablation experiments. study, take learnedheuristic function H cost function C HC-Search framwork, use onemake predictions. example, HH-Search corresponds configurationuse function H heuristic cost function. Similarly, CC-Search correspondsconfiguration use function C heuristic cost function.Table 2b shows results ablation experiments. make several interesting observations results. First, overall error HC-Search significantlybetter HH-Search CC-Search. Second, selection loss HH-Searchincreases compared HC-Search. understandable H trainedscore candidate outputs generated search. Third, generationloss CC-Search increases compared HC-Search behavior significant(increases 11.24 compared 5.82) scene labeling task. results provideevidence importance separating training heuristic costfunctions.HW-SmallC|HHStressC|HHHC03.207.1a. HC-Search vs. C-Search00.7 02.7 17.5 02.7 14.700.9 06.2 21.0 03.0 18.016.920.803.404.113.416.619.727.005.807.813.819.207.906.6b. Results Ablation study00.7 7.222.5 02.7 19.701.7 04.9 19.1 03.2 15.822.121.603.404.318.717.332.125.307.811.224.314.0c. Results heuristic function training via DAgger08.1 03.1 00.4 02.6 17.2 02.2 15.0 16.8 03.009.9 05.1 00.8 03.6 20.3 02.8 17.1 19.0 03.913.814.718.024.203.705.914.318.311.716.300.316.0DatasetsErrorHCHC-SearchC-Search12.817.504.704.908.012.6HH-SearchCC-Search18.416.204.705.313.710.9HC-SearchC-Search12.015.103.904.6HCHW-LargeC|HHHCPhonemeC|HHHCSceneC|HHd. Results Oracle HeuristicLC-Search(Oracle H)10.100.209.903.000.502.514.100.213.912.200.5Table 2: HC-Search: Error decomposition heuristic cost function.4.7 Results Heuristic Training via DAggerheuristic learning approach follows simplest approach imitation learning, exactimitation, learner attempts exactly imitate observed expert trajectories(here imitate search oracle heuristic). experiments show exactimitation performs quite well, known exact imitation certain deficienciesgeneral. particular, functions trained via exact imitation prone error propagation (Kaariainen, 2006; Ross & Bagnell, 2010), errors made test time changedistribution decisions encountered future compared training distribution.address problem, sophisticated imitation learning algorithms developed, state-of-the-art approach DAgger (Ross, Gordon, & Bagnell, 2011).388fiHC-Search: Learning Framework Search-based Structured Predictionconsider whether DAgger improve heuristic learning turn overallaccuarcy.DAgger iterative algorithm, iteration adds imitation data aggregated data set. first iteration follows exact imitation approach, datacollected observing expert trajectory (or number them). iterationimitation function (here heuristic) learned current data. Successive iterationsgenerate trajectories following mixture expert suggestions (in case ranking decisions) suggestions recently learned imitation function. decision pointalong trajectory added aggregate data set labeling expert decision.way, later iterations allow DAgger learn states visited possibly erroneous learned functions correct mistakes using expert input. Ross et al. (2011)show iterations DAgger using learned policy without mixingexpert policy performs well across diverse domains. Therefore, useapproach DAgger experiments. experiments run 5 iterations DAgger,noting noticable improvement observed 5 iterations.Table 2c shows results HC-Search C-Search obtained training DAgger. HC-Search, generation loss (H ) improved slightly sequence labelingproblems little room improvement, DAgger leads significant improvement generation loss challenging problem scene labeling. alsosee overall error HC-Search scene labeling reduces due improvementgeneration loss showing cost function able leverage better outputs producedheuristic. Similarly, overall error C-Search also improved DAgger acrossboard see significant improvements handwiriting scene labelingdomains. interesting note unlike HC-Search, improvement C-Searchmostly due improvement selection loss (C|H ) except scene labeling task,due improvement generation loss selection loss.results show improving heuristic learning able improve overallperformance. clear whether improvement, perhaps due futureadvances imitation learning, would yet lead overall improvement. is,may possible improve generation loss, clear cost functionable exploit improvments. help evaluate ran experimentgave HC-Search true loss function use heuristic (an oracle heuristic), i.e.,H(x, y) = L(x, y, ), training cost function testing. providesassessment much better might able could improve heuristiclearning. results Table 2, label LC-Search (Oracle H) showusing oracle heuristic, H negligible might expect smaller observedHC-Search. shows may possible improve heuristic learningvia better imitation.also see oracle results overall error HC betterHC-Search, HW-Small Scene labeling tasks, selection error C|H got slightlyworse.. indicates cost function learner able leverage, varying degrees, better outputs produced oracle heuristic. suggests improvingheuristic learner order reduce generation loss could viable wayreducing overall loss HC-Search, even without altering current cost learner. However, saw much less room improve heuristic learner389fiDoppa, Fern, & Tadepallidata sets hence potential gains less directly trying improve costlearner.4.8 Results Training Different Time boundsTrainalso trained HC-Search different time bounds (i.e., number greedy search steps)see overall loss, generation loss selection loss vary increase trainingtime bound. general, time bound increases, generation loss monotonicallydecrease, since strictly outputs encountered. hand difficultycost function learning increase time bound grows since must learn distinguish larger set candidate outputs. Thus, degree overallerror decreases (or grows) time bound depends combination muchgeneration loss decreases whether cost function learner able accuratelydistinguish improved outputs.Figure 5 shows performance HC-Search full spectrum time bounds.Qualitatively, see generation loss, due heuristic, decreases remarkablyfast benchmarks improves little initial decrease. also seecost function learner achieves relatively stable selection loss short time, thoughincrease bit time cases. combined effect see overallerror HC improves quickly increase time bound improvement tendssmall beyond certain time bound. Also, cases (e.g., phoneme predictionscene labeling) performance tends get slightly worse large time bounds,happens increase selection loss counteracted decreased generationloss.Loss FunctionHammingVCTestHammingVC1757465817694620Table 3: Results training non-hamming loss functions.4.9 Results Training Non-Hamming Loss functionsOne advantages HC-Search compared many approaches structuredprediction sensitive loss function used training. trained HCSearch different loss functions handwriting domain verify truepractice not. used hamming loss (uniform misclassification cost 1 characters)Vowel-Consonant (VC) loss (different misclassification costs vowels consonants)experiment. VC loss, used misclassification costs 4 2 vowelsconsonants respectively. Training done 5 folds remaining 5 folds usedtesting. Table 4.8 shows results training testing two loss functions.report cumulative loss testing examples. see, testingloss function, training loss function gives slightly better performancetraining using different loss function. shows HC-Search learning approach390fiHC-Search: Learning Framework Search-based Structured PredictionFigure 5: HC-Search results training different time bounds. training timebound (i.e., no. greedy search steps) x-axis error y-axis.three curves graph corresponding overall loss HC , generation loss Hselection loss C|H .391fiDoppa, Fern, & Tadepallisensitive loss function. However, result may hold generally muchdepends problem structure, loss function ability cost functioncapture loss.4.10 Discussion Efficiency HC-Search ApproachHC-Search framework, basic computational elements include generating candidatestates given state; computing heuristic function features via H cost functionfeatures via C candidate states; computing heuristic cost scores vialearned heuristic cost function pair (H, C). computational time generatingcandidate states depends employed search space = (I, S), initialstate function successor function. example, generation candidatesefficient Flipbit space compared LDS space (involves runningrecurrent classifier every action specified successor function S). Therefore,efficiency overall approach depends size candidate setgreatly improved generating fewer candidate states (e.g., via pruning) parallelizingcomputation. done preliminary work direction introducing sparseversions LDS Flipbit search spaces pruning actions based recurrentclassifier scores (as specified prunining parameter k). simple pruning strategyresulted 10-fold speedup little loss accuracy across several benchmarkproblems (Doppa et al., 2014a). However, work needs done learning pruningrules improve efficiency HC-Search approach.5. Engineering Methodology Applying HC-Searchsection, describe engineering methodology applying HC-Search framework new problems. high-level, methodology involves selecting effectivetime-bounded search architecture (search space, search procedure, search time-bound),leveraging loss decomposition terms generation selection loss trainingdebugging heuristic cost functions. describe steps detail.5.1 Selection Time-bounded Search Architecturetime-bounded search architecture instantiated selecting search space, searchstrategy, search time-bound. mentioned before, effectiveness HC-Searchdepends critically quality search space (i.e., search depth targetoutputs found) employed. fact, prior work empirically demonstrated performance gap search architectures Flipbit space LDSspace grows difference target depths increase (Doppa et al., 2014a).Therefore, important select/design high-quality search space problemhand.exists greedy predictor structured prediction problem, one could leverage define appropriate variant LDS space. Fortunately, greedypredictors several problems natural language processing, computer vision, relationalnetworks, planning preferences. example, transition-based parsers dependency parsing (Nivre, 2008; Goldberg & Elhadad, 2010); greedy classifiers co-reference392fiHC-Search: Learning Framework Search-based Structured Predictionresolution (Chang, Samdani, & Roth, 2013; Stoyanov & Eisner, 2012) event extraction(Li, Ji, & Huang, 2013); sequential labelers boundary detection objects images(Payet & Todorovic, 2013); iterative classifiers collective inference relational networks(Sen, Namata, Bilgic, Getoor, Gallagher, & Eliassi-Rad, 2008; Doppa, Yu, Tadepalli, &Getoor, 2009, 2010); classifier chains multi-label prediction (Read, Pfahringer, Holmes,& Frank, 2011); greedy planners planning preferences (Xu, Fern, & Yoon,2010). general, designing high-quality search spaces key research topicwork needs done direction. Learning search operators (macro actions)transformation rules Transformation-based Learning (TBL) (Brill, 1995) optimizesearch space one many possibilities. Sometimes problem structure also helpdesigning effective search spaces. example, multi-label prediction problems,outputs binary vectors small number active labels (highly sparse).simple flipbit space initialized null vector effective (Doppa, Yu,Ma, Fern, & Tadepalli, 2014b).picking search space, need select appropriate search proceduresearch time-bound. effectiveness search architecture measured performingoracle search (true loss function used heuristic cost function) trainingdata. one could perform oracle search (LL-Search) different search procedures (e.g.,greedy beam search) different time-bounds select search procedureeffective. see benefit beam search problems considered,expect change harder problems non-Hamming loss functions (e.g.,B-Cubed score co-reference resolution). search space redundant,fix search time-bound value performance search architecturestagnates. Otherwise, one allow slack search procedure recovererrors. experiments, found (size structured output)reasonable value time-bound (Figure 5 provides justification choice).5.2 Training Debuggingtraining procedure involves learning heuristic H cost function C optimizeperformance selected time-bounded search architecture training data.Following staged learning approach, one could start learning heuristic via exactimitation oracle search. that, learned heuristic H evaluatedmeasuring generation loss (HL-Search configuration). performance HLSearch configuration acceptable respect performance LL-Search,move cost function learning part. Otherwise, try improve heuristic eitheremploying sophisticated imitation learning algorithms (e.g., DAgger), enrichingfeature function H , employing powerful rank learner. Similarly, learningcost function C conditioned learned heuristic, measure selection loss.selection loss high, try improve cost function either addingexpressive features C employing powerful rank learner.6. Comparison Related Workdescribed earlier, majority structured prediction work focused useexact inference computing outputs tractable, approximate inference393fiDoppa, Fern, & Tadepallitechniques, loopy belief propagation relaxation methods, not. Learning focused tuning cost function parameters order optimize variousobjective functions, differ among learning algorithms (Lafferty et al., 2001; Taskaret al., 2003; Tsochantaridis et al., 2004; McAllester, Hazan, & Keshet, 2010). alsoapproximate cost function learning approaches employ inference routinetraining. example, piece-wise training (Sutton & McCallum, 2009), DecomposedLearning (Samdani & Roth, 2012) special case pseudo-max training (Sontag, Meshi,Jaakkola, & Globerson, 2010) fall category. training approachesefficient, still need inference algorithm make predictions testing.cases, one could employ Constrained Conditional Models (CCM) framework(Chang, Ratinov, & Roth, 2012) declarative (global) constraints make predictions using learned cost function. CCM framework relies Integer LinearProgramming (ILP) inference method (Roth & tau Yih, 2005). recent work attempted integrate (approximate) inference cost function learning principledmanner (Meshi, Sontag, Jaakkola, & Globerson, 2010; Stoyanov, Ropson, & Eisner, 2011;Hazan & Urtasun, 2012; Domke, 2013). Researchers also worked using higher-orderfeatures CRFs context sequence labeling pattern sparsity assumption(Ye, Lee, Chieu, & Wu, 2009; Qian, Jiang, Zhang, Huang, & Wu, 2009). However,approaches applicable graphical models sparsity assumptionhold.alternative approach addressing inference complexity cascade training (Felzenszwalb & McAllester, 2007; Weiss & Taskar, 2010; Weiss, Sapp, & Taskar, 2010),efficient inference achieved performing multiple runs inference coarse levelfine level abstraction. approaches shown good success, placerestrictions form cost functions facilitate cascading. Another potential drawback cascades approaches either ignore lossfunction problem (e.g. assuming Hamming loss) require loss functiondecomposable way supports loss augmented inference. approach sensitiveloss function makes minimal assumptions it, requiringblackbox evaluate potential output.Classifier-based structured prediction algorithms avoid directly solving Argmin problem assuming structured outputs generated making series discretedecisions. approach attempts learn recurrent classifier given inputx iteratively applied order generate series decisions producing targetoutput y. Simple training methods (e.g. Dietterich, Hild, & Bakiri, 1995) showngood success positive theoretical guarantees (Syed & Schapire, 2010;Ross & Bagnell, 2010). However, recurrent classifiers prone error propagation(Kaariainen, 2006; Ross & Bagnell, 2010). Recent work, e.g. SEARN (Hal Daume IIIet al., 2009), SMiLe (Ross & Bagnell, 2010), DAgger (Ross et al., 2011), attemptsaddress issue using sophisticated training techniques shown state-of-theart structured-prediction results. However, approaches use classifiers producestructured outputs single sequence greedy decisions. Unfortunately, manyproblems, decisions difficult predict greedy classifier, crucialgood performance. contrast, approach leverages recurrent classifiers define good394fiHC-Search: Learning Framework Search-based Structured Predictionquality search spaces complete outputs, allows decision making comparingmultiple complete outputs choosing best.also non-greedy methods learn scoring function search spacepartial structured outputs (DaumeIII & Marcu, 2005; Daume III, 2006; Xu, Fern, & Yoon,2009b; Huang, Fayong, & Guo, 2012; Yu, Huang, Mi, & Zhao, 2013). methodsperform online training, differ way search errors definedweights updated errors occur. Unfortunately, training scoring functiondifficult hard evaluate states partial outputs theoreticalguarantees learned scoring function (e.g., convergence generalization results)rely strong assumptions (Xu et al., 2009b).work closely related output space search approaches (Doppa et al.,2012; Wick et al., 2011), use single cost function serve search heuristicalso score candidate outputs. Serving dual roles often means costfunction needs make unclear tradeoffs, increasing difficulty learning. HCSearch approach overcomes deficiency learning two different functions, heuristicfunction guide search generate high-quality candidate outputs, cost functionrank candidate outputs. Additionally, error decomposition HC-Search termsheuristic error cost function error allows human designers learning systemdiagnose failures take corrective measures.approach also related Re-Ranking (Collins, 2002), uses generativemodel propose k-best list outputs, ranked separate rankingfunction. contrast, rather restricting generative model producing potentialoutputs, approach leverages generic search efficient search spaces guidedlearned heuristic function minimal representational restrictions, employslearned cost function rank candidate outputs. Recent work generating multiplediverse solutions probabilistic framework considered another way producingcandidate outputs. representative set approaches line work diverse Mbest (Batra, Yadollahpour, Guzman-Rivera, & Shakhnarovich, 2012), M-best modes (Park& Ramanan, 2011; Chen, Kolmogorov, Zhu, Metaxas, & Lampert, 2013) DeterminantalPoint Processes (Kulesza & Taskar, 2012).general area speedup learning studied planning search communityalso related work (Fern, 2010). problems, cost function typically knownobjective learn control knowledge (i.e., heuristic function) directing searchalgorithm low-cost terminal node search space. example, STAGE (Boyan &Moore, 2000) learns evaluation function states improve performancesearch, value state corresponds performance local search algorithmstarting state, (Zhang & Dietterich, 1995) use Reinforcement Learning (RL)methods learn heuristics job shop scheduling goal minimizing durationschedule. Unlike problems planning combinatorial optimization,cost function given structured prediction problems. Therefore, HC-Searchapproach learns cost function score structured outputs along heuristicfunction guide search towards low cost outputs.395fiDoppa, Fern, & Tadepalli7. Summary Future Workintroduced HC-Search framework structured prediction whose principal featureseparation cost function search heuristic. showed frameworkyields significantly superior performance state-of-the-art results, allows informative error analysis diagnostics.investigation showed main source error existing output-space approaches including approach (HC-Search) inability cost function correctly rank candidate outputs produced output generation process. analysissuggests learning powerful cost functions, e.g., Regression trees (Mohan, Chen,& Weinberger, 2011), eye towards anytime performance (Grubb & Bagnell, 2012;Xu, Weinberger, & Chapelle, 2012) would productive. results also suggestedroom improve overall performance better heuristic learning. Thus, anotherdirection pursue heuristic function learning speed process generatinghigh-quality outputs (Fern, 2010).Future work includes applying framework challenging problems natural language processing (e.g., co-reference resolution, dependency parsing, semanticparsing) computer vision (e.g., object detection biological images Lam, Doppa, Hu,Todorovic, Dietterich, Reft, & Daly, 2013, multi-object tracking complex sportsvideos Chen, Fern, & Todorovic, 2014). effectiveness HC-Search approach dependsquality search space, therefore, work needs done learningoptimize search spaces leveraging problem structure. Similarly, studying pruningtechniques improve efficiency learning inference another usefuldirection.Acknowledgementsauthors would like thank anonymous reviewers Jason Eisner, associateeditor, comments feedback. first author would also like thank TomDietterich encouragement support throughout work. work supported part NSF grants IIS 1219258, IIS 1018490 part Defense AdvancedResearch Projects Agency (DARPA) Air Force Research Laboratory (AFRL)Contract No. FA8750-13-2-0033. opinions, findings conclusions recommendations expressed material author(s) necessarily reflectviews NSF, DARPA, Air Force Research Laboratory (AFRL),US government. preliminary version article published AAAI-2013 (Doppaet al., 2013)Appendix A. Limited Discrepancy Search (LDS) SpaceLimited Discrepancy Search (LDS) space (Doppa et al., 2012, 2014a) defined termslearned recurrent classifier h. Thus, start describing recurrent classifierexplain key idea behind LDS space. simplicity, explain main ideas usingsequence labeling problem (handwriting recognition task) noting generalizenon-sequence labeling problems (for full details see Doppa et al., 2012, 2014a).396fiHC-Search: Learning Framework Search-based Structured PredictionFigure 6: Illustration recurrent classifier handwriting recognition problem. classifier predicts labels left-to-right order. makes labeling decisionposition greedily based character image predicted labelprevious position (shown dotted box). particular example,classifier makes mistake first position error propagatespositions leading bad output.A.1 Recurrent Classifiersequence labeling problem, recurrent classifier produces label positionsequence, based input position predicted labels previous positions(Dietterich et al., 1995). learned classifier accurate, number incorrectlabeling decisions relatively small. However, even small number errorspropagate cause poor outputs.Figure 6 illustrates recurrent classifier handwriting recognition example.classifier predicts labels left-to-right order. makes labeling decisionposition greedily based character image predicted label previousposition (shown dotted box). particular example, classifier makesmistake first position error propagates leading bad output (5errors).A.2 Limited Discrepancy Search (LDS)LDS originally introduced context problem solving using heuristic search(Harvey & Ginsberg, 1995). key idea behind LDS realize classifierprediction corrected small number critical errors, much better output397fiDoppa, Fern, & Tadepalli(a)(b)Figure 7: Illustration Limited Discrepancy Search (LDS) handwriting recognitionproblem. given discrepancy set D, generate unique outputrunning recurrent classifier changes D. (a) LDS onediscrepancy. introduce discrepancy first position label (shownred) run classifier, able correct two subsequent labels. (b)LDS two discrepancies. introduce additional discrepancy fifthposition label c (shown red) run classifier, recover targetoutput struct.would produced. LDS conducts (shallow) search space possible correctionshope finding output better original.Given classifier h sequence length , discrepancy pair (i, l){1, . . . , } index sequence position l label, generally differentprediction classifier position i. set discrepancies D,generate unique output h[D](x) running classifier changes D.discrepancies viewed overriding prediction h particular positions,possibly correcting errors, introducing new errors. one extreme, empty,get original output produced greedy classifier (see Figure 6).extreme, specifies label position, output influenced hcompletely specified discrepancy set. Figure 7 illustrates LDShandwriting example. introduce discrepancy first position label(shown red) run classifier, able correct two subsequent labels (seeFigure 7(a)). introduce additional discrepancy fifth position label c (shownred) run classifier, recover target output struct (see Figure 7(b)).398fiHC-Search: Learning Framework Search-based Structured PredictionFigure 8: example Limited Discrepancy Search (LDS) space handwriting recognitionproblem. highlighted state corresponds one true outputsmallest depth.practice, h reasonably accurate, primarily interested smalldiscrepancy sets relative length sequence. problem knowcorrections made thus LDS conducts search discrepancysets, usually small large sets.A.3 LDS SpaceGiven recurrent classifier h, define corresponding limited-discrepancy search spacecomplete outputs follows. state search space represented (x, D)x input sequence discrepancy set. view state (x, D) equivalentinput-output state (x, h[D](x)). initial state function simply returns (x, )corresponds original output recurrent classifier. successor functionstate (x, D) returns set states form (x, D0 ), D0 D,additional discrepancy. way, path LDS search space startsoutput generated recurrent classifier traverses sequence outputsdiffer original number discrepancies. Given reasonably accurate h,expect high-quality outputs generated relatively shallow depthssearch space hence generated quickly.399fiDoppa, Fern, & TadepalliFigure 8 illustrates3 limited-discrepancy search space. state consistsinput x, discrepancy set output produced running classifierspecified discrepancy set, i.e., h[D](x). root node empty discrepancy set. Nodeslevel one contain discrepancy sets size one. highlighted state correspondssmallest depth state containing target output.Appendix B. Hardness Proof HC-Search Consistency ProblemTheorem 2. HC-Search Consistency Problem greedy search linear heuristiccost functions NP-Hard even restrict problems possibleheuristic functions uncover zero loss output.Proof. reduce Minimum Disagreement problem linear binary classifiers,proven NP-complete work Hoffgen, Simon, Horn (1995).one statement problem given input set N , p-dimensional vectors= {x1 , . . . , xN } positive integer k. problem decide whetherp-dimensional real-valued weight vector w w xi < 0 kvectors.first sketch high-level idea proof. Given instance Minimum Disagreement, construct HC-Search consistency problem single structuredtraining example. search space corresponding training example designedsingle node n loss zero nodes loss1. linear heuristic functions greedy search paths terminate n ,generating set nodes/outputs path there. search space designedpossible path initial node n corresponds selecting k fewervectors , denote . traversing path, set nodesgenerated (and hence must scored C), say N , includes feature vectors correspondingalong negation feature vectors . definen assigned zero vector, cost node 0 weight vector.order achieve zero loss given path consideration, must weightvector wC wC x 0 x N . construction equivalentwC x < 0 x . possible found solution MinimumDisagreement problem since |T | k. remaining details show constructspace setting heuristic weights generate paths correspondingpossible way paths end n . completeness describeconstruction below.search node space n tuple (i, m, t) 1 N ,0 k, one 5 node types set {d, s+ , , x+ , x }.viewed indexing example xi effectively codes many instancesselected mistakes hence put . Finally, encodes typesearch node following meanings become clearconstruction: (decision), s+ (positive selection), (negative selection), x+ (positiveinstance), x (negative instance). search space constructed example xi3. may clear example, allow over-riding discrepancies provide opportunity recover search errors.400fiHC-Search: Learning Framework Search-based Structured PredictionFigure 9: example search space = {x1 , x2 , x3 } k = 1. greedy pathsterminate zero loss node n path selects one instanceinclude mistake set .considered order choice made whether count mistake (put) not. choice made decision nodes, form (i, m, d),indicating decision made example alreadyexamples selected . decision node < k two children (i, m, )(i, m, s+ ), respectively correspond selecting xi mistake set not.Later show features assigned nodes allow heuristic makeselection desired.selection node single node child. particular, positive selection node(i, m, s+ ) positive instance node (i, m, x+ ) child, negative selection nodes(i, m, ) negative instance node (i, m, x ) child. instance nodeeffectively implements process putting xi become clearfeature vectors described below. arriving either positive negative instancenode, consideration xi complete must move decision nextexample xi+1 . Thus, positive instance node (i, m, x+ ) single child decision node401fiDoppa, Fern, & Tadepalli(i + 1, m, d), negative instance node single child decision node (i + 1, + 1, d),noting number mistakes incremented negative nodes.final details search space structure ensure k mistakesallowed force search paths terminate n . particular, decisionnode (i, m, d) = k, know mistakes allowed hencedecisions allowed. Thus, node form path ngoes positive instance nodes (i, m, x+ ), . . . , (N, m, x+ ), reflects none{xi , . . . , xN } . Figure 9 shows example search space construction.Given search space, polynomial size (since k N ), one verifyset k fewer instances path root n goesnegative instance nodes instances positive instance nodesinstances . Further, possible path goes either positive negativeinstance node instance k negative nodes. Thus directcorrespondence paths mistake sets .describe assign features node way allowsheuristic function select path effectively construct set . nodeu feature vector (u) = (x, s, b). component x p-dimensional feature vectorcorrespond one xi . component N -dimensional vectorsi {1, 1} implement selection instances. Finally b binary valueequal 1 non-instance nodes 0 positive negative instance nodes.mapping nodes feature vectors follows. decision node (i, m, d),zeros, except b = 1. positive selection node (i, m, s+ ) zeros except si = 1b = 1. Negative selection nodes similar except si = 1. positive instancenode (i, m, x+ ) feature vector (xi , 0, 0) negative instance nodes (i, m, x )feature vector (xi , 0, 0). Finally feature vector n zeros.key idea note heuristic function effectively select positivenegative selection node setting weight si positive negative respectively.particular, set negative selection nodes visited (and hence negative instance nodes)correspond first k fewer negative weight values component featurevector. Thus, heuristic select set negative nodes wants go through,k. path three types nodes encounteredcost function must rank. First, control nodes (decision selection nodes)b = 1. Next positive instance nodes featurevector (xi , 0, 0) k negative instance nodes feature vectors (xi , 0, 0).cost function easily rank n higher control nodes setting weightb negative. find heuristic weights x component allows nranked highest solution original minimum disagreement problem.solution disagreement problem easy seealso solution HC-Search consistency problem selecting heuristic spansproper set .ReferencesAgarwal, S., & Roth, D. (2005). Learnability Bipartite Ranking Functions. ProceedingsInternational Conference Learning Theory (COLT), pp. 1631.402fiHC-Search: Learning Framework Search-based Structured PredictionBatra, D., Yadollahpour, P., Guzman-Rivera, A., & Shakhnarovich, G. (2012). Diverse MBest Solutions Markov Random Fields. Proceedings European ConferenceComputer Vision (ECCV), pp. 116.Boyan, J. A., & Moore, A. W. (2000). Learning Evaluation Functions Improve Optimization Local Search. Journal Machine Learning Research (JMLR), 1, 77112.Brill, E. (1995). Transformation-Based Error-Driven Learning Natural Language Processing: Case Study Part-of-Speech Tagging. Computational Linguistics, 21 (4),543565.Chang, K.-W., Samdani, R., & Roth, D. (2013). Constrained Latent Variable ModelCoreference Resolution. Proceedings Conference Empirical MethodsNatural Language Processing (EMNLP), pp. 601612.Chang, M.-W., Ratinov, L.-A., & Roth, D. (2012). Structured Learning ConstrainedConditional Models. Machine Learning Journal (MLJ), 88 (3), 399431.Chen, C., Kolmogorov, V., Zhu, Y., Metaxas, D., & Lampert, C. H. (2013). ComputingProbable Modes Graphical Model. Proceedings InternationalConference Artificial Intelligence Statistics (AISTATS).Chen, S., Fern, A., & Todorovic, S. (2014). Multi-Object Tracking via Constrained Sequential Labeling. appear Proceedings IEEE Conference Computer VisionPattern Recognition (CVPR).Collins, M. (2000). Discriminative Reranking Natural Language Parsing. ProceedingsInternational Conference Machine Learning (ICML), pp. 175182.Collins, M. (2002). Ranking Algorithms Named Entity Extraction: BoostingVoted Perceptron. ACL.Crammer, K., Dekel, O., Keshet, J., Shalev-Shwartz, S., & Singer, Y. (2006). Online PassiveAggressive Algorithms. Journal Machine Learning Research (JMLR), 7, 551585.Daume III, H. (2006). Practical Structured Learning Techniques Natural LanguageProcessing. Ph.D. thesis, University Southern California, Los Angeles, CA.DaumeIII, H., & Marcu, D. (2005). Learning Search Optimization: Approximate Largemargin methods Structured Prediction. ICML.Dietterich, T. G., Hild, H., & Bakiri, G. (1995). Comparison ID3 BackpropagationEnglish Text-to-Speech Mapping. Machine Learning Journal (MLJ), 18 (1), 5180.Domke, J. (2013). Structured Learning via Logistic Regression. Proceedings AdvancesNeural Information Processing Systems (NIPS), pp. 647655.Doppa, J. R., Fern, A., & Tadepalli, P. (2012). Output Space Search Structured Prediction. Proceedings International Conference Machine Learning (ICML).Doppa, J. R., Fern, A., & Tadepalli, P. (2013). HC-Search: Learning Heuristics CostFunctions Structured Prediction. Proceedings AAAI Conference ArtificialIntelligence (AAAI).Doppa, J. R., Fern, A., & Tadepalli, P. (2014a). Structured Prediction via Output SpaceSearch. Journal Machine Learning Research (JMLR), 15, 13171350.403fiDoppa, Fern, & TadepalliDoppa, J. R., Yu, J., Ma, C., Fern, A., & Tadepalli, P. (2014b). HC-Search Multi-LabelPrediction: Empirical Study. appear Proceedings AAAI ConferenceArtificial Intelligence (AAAI).Doppa, J. R., Yu, J., Tadepalli, P., & Getoor, L. (2009). Chance-Constrained ProgramsLink Prediction. Proceedings NIPS Workshop Analyzing NetworksLearning Graphs.Doppa, J. R., Yu, J., Tadepalli, P., & Getoor, L. (2010). Learning Algorithms LinkPrediction based Chance Constraints. Proceedings European ConferenceMachine Learning (ECML), pp. 344360.Felzenszwalb, P. F., & McAllester, D. A. (2007). Generalized A* Architecture. JournalArtificial Intelligence Research (JAIR), 29, 153190.Fern, A. (2010). Speedup Learning. Encyclopedia Machine Learning, pp. 907911.Fern, A., Yoon, S. W., & Givan, R. (2006). Approximate Policy Iteration PolicyLanguage Bias: Solving Relational Markov Decision Processes. Journal ArtificialIntelligence Research (JAIR), 25, 75118.Goldberg, Y., & Elhadad, M. (2010). Efficient Algorithm Easy-First Non-DirectionalDependency Parsing. Proceedings Human Language Technologies: ConferenceNorth American Chapter Association Computational Linguistic (HLTNAACL), pp. 742750.Grubb, A., & Bagnell, D. (2012). SpeedBoost: Anytime Prediction Uniform NearOptimality. Journal Machine Learning Research - Proceedings Track, 22, 458466.Hal Daume III, Langford, J., & Marcu, D. (2009). Search-based Structured Prediction.Machine Learning Journal (MLJ), 75 (3), 297325.Harvey, W. D., & Ginsberg, M. L. (1995). Limited Discrepancy Search. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 607615.Hazan, T., & Urtasun, R. (2012). Efficient Learning Structured Predictors GeneralGraphical Models. CoRR, abs/1210.2346.Hoffgen, K.-U., Simon, H.-U., & Horn, K. S. V. (1995). Robust Trainability SingleNeurons. Journal Computer System Sciences, 50 (1), 114125.Huang, L., Fayong, S., & Guo, Y. (2012). Structured Perceptron Inexact Search.Proceedings Human Language Technology Conference North AmericanChapter Association Computational Linguistics (HLT-NAACL), pp. 142151.Jiang, J., Teichert, A., Daume III, H., & Eisner, J. (2012). Learned PrioritizationTrading Accuracy Speed. Proceedings Advances Neural InformationProcessing (NIPS).Kaariainen, M. (2006). Lower Bounds Reductions. Atomic Learning Workshop.Keshet, J., Shalev-Shwartz, S., Singer, Y., & Chazan, D. (2005). Phoneme Alignment basedDiscriminative Learning. Proceedings Annual Conference InternationalSpeech Communication Association (Interspeech), pp. 29612964.404fiHC-Search: Learning Framework Search-based Structured PredictionKhardon, R. (1999). Learning Take Actions. Machine Learning Journal (MLJ), 35 (1),5790.Kulesza, A., & Taskar, B. (2012). Determinantal Point Processes Machine Learning.Foundations Trends Machine Learning, 5 (2-3), 123286.Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional Random Fields: ProbabilisticModels Segmenting Labeling Sequence Data. Proceedings InternationalConference Machine Learning (ICML), pp. 282289.Lam, M., Doppa, J. R., Hu, X., Todorovic, S., Dietterich, T., Reft, A., & Daly, M. (2013).Learning Detect Basal Tubules Nematocysts SEM Images. ICCV WorkshopComputer Vision Accelerated Biosciences (CVAB). IEEE.Li, Q., Ji, H., & Huang, L. (2013). Joint Event Extraction via Structured PredictionGlobal Features. Proceedings 51st Annual Meeting AssociationComputational Linguistics (ACL), pp. 7382.McAllester, D. A., Hazan, T., & Keshet, J. (2010). Direct Loss Minimization StructuredPrediction. Proceedings Advances Neural Information Processing Systems(NIPS), pp. 15941602.Meshi, O., Sontag, D., Jaakkola, T., & Globerson, A. (2010). Learning EfficientlyApproximate Inference via Dual Losses. Proceedings International ConferenceMachine Learning (ICML), pp. 783790.Mohan, A., Chen, Z., & Weinberger, K. Q. (2011). Web-Search Ranking InitializedGradient Boosted Regression trees. Journal Machine Learning Research - Proceedings Track, 14, 7789.Nivre, J. (2008). Algorithms Deterministic Incremental Dependency Parsing. Computational Linguistics, 34 (4), 513553.Park, D., & Ramanan, D. (2011). N-Best Maximal Decoders Part Models. ProccedingsIEEE International Conference Computer Vision (ICCV), pp. 26272634.Payet, N., & Todorovic, S. (2013). SLEDGE: Sequential Labeling Image EdgesBoundary Detection. International Journal Computer Vision (IJCV), 104 (1), 1537.Qian, X., Jiang, X., Zhang, Q., Huang, X., & Wu, L. (2009). Sparse Higher Order Conditional Random Fields Improved Sequence Labeling. Proceedings InternationalConference Machine Learning (ICML).Read, J., Pfahringer, B., Holmes, G., & Frank, E. (2011). Classifier Chains Multi-LabelClassification. Machine Learning, 85 (3), 333359.Ross, S., & Bagnell, D. (2010). Efficient Reductions Imitation Learning. JournalMachine Learning Research - Proceedings Track, 9, 661668.Ross, S., Gordon, G. J., & Bagnell, D. (2011). Reduction Imitation LearningStructured Prediction No-Regret Online Learning. Journal Machine LearningResearch - Proceedings Track, 15, 627635.405fiDoppa, Fern, & TadepalliRoth, D., & tau Yih, W. (2005). Integer Linear Programming Inference ConditionalRandom Fields. Proceedings International Conference Machine Learning(ICML), pp. 736743.Samdani, R., & Roth, D. (2012). Efficient Decomposed Learning Structured Prediction.Proceedings International Conference Machine Learning (ICML).Sen, P., Namata, G., Bilgic, M., Getoor, L., Gallagher, B., & Eliassi-Rad, T. (2008). Collective Classification Network Data. AI Magazine, 29 (3), 93106.Sontag, D., Meshi, O., Jaakkola, T., & Globerson, A. (2010). data means less inference:pseudo-max approach structured learning. Proceedings Advances NeuralInformation Processing Systems (NIPS), pp. 21812189.Stoyanov, V., & Eisner, J. (2012). Easy-first Coreference Resolution. ProceedingsInternational Conference Computational Linguistics (COLING), pp. 25192534.Stoyanov, V., Ropson, A., & Eisner, J. (2011). Empirical Risk Minimization GraphicalModel Parameters Given Approximate Inference, Decoding, Model Structure.Proceedings International Conference Artificial Intelligence Statistics(AISTATS), pp. 725733.Sutton, C. A., & McCallum, A. (2009). Piecewise Training Structured Prediction.Machine Learning Journal (MLJ), 77 (2-3), 165194.Syed, U., & Schapire, R. (2010). Reduction Apprenticeship Learning Classification. Proceedings Advances Neural Information Processing Systems (NIPS),pp. 22532261.Taskar, B., Guestrin, C., & Koller, D. (2003). Max-Margin Markov Networks. ProceedingsAdvances Neural Information Processing Systems (NIPS).Tsochantaridis, I., Hofmann, T., Joachims, T., & Altun, Y. (2004). Support Vector Machine Learning Interdependent Structured Output Spaces. ProceedingsInternational Conference Machine Learning (ICML).Tsochantaridis, I., Joachims, T., Hofmann, T., & Altun, Y. (2005). Large Margin MethodsStructured Interdependent Output Variables. Journal Machine LearningResearch (JMLR), 6, 14531484.Vogel, J., & Schiele, B. (2007). Semantic Modeling Natural Scenes Content-BasedImage Retrieval. International Journal Computer Vision (IJCV), 72 (2), 133157.Weiss, D. (2014). Structured Prediction Cascades code. http://code.google.com/p/structured-cascades/.Weiss, D., Sapp, B., & Taskar, B. (2010). Sidestepping Intractable Inference StructuredEnsemble Cascades. Proceedings Advances Neural Information ProcessingSystems (NIPS), pp. 24152423.Weiss, D., & Taskar, B. (2010). Structured Prediction Cascades. Journal MachineLearning Research - Proceedings Track, 9, 916923.Wick, M. L., Rohanimanesh, K., Bellare, K., Culotta, A., & McCallum, A. (2011). SampleRank: Training Factor Graphs Atomic Gradients. Proceedings InternationalConference Machine Learning (ICML).406fiHC-Search: Learning Framework Search-based Structured PredictionWick, M. L., Rohanimanesh, K., Singh, S., & McCallum, A. (2009). Training Factor GraphsReinforcement Learning Efficient MAP Inference. Proceedings AdvancesNeural Information Processing Systems (NIPS), pp. 20442052.Xu, Y., Fern, A., & Yoon, S. (2009a). Learning Linear Ranking Functions Beam SearchApplication planning. Journal Machine Learning Research, 10, 15711610.Xu, Y., Fern, A., & Yoon, S. W. (2009b). Learning Linear Ranking Functions BeamSearch Application Planning. Journal Machine Learning Research (JMLR),10, 15711610.Xu, Y., Fern, A., & Yoon, S. W. (2010). Iterative Learning Weighted Rule SetsGreedy Search. Proceedings International Conference Automated PlanningSystems (ICAPS), pp. 201208.Xu, Z., Weinberger, K., & Chapelle, O. (2012). Greedy Miser: Learning Test-timeBudgets. Proceedings International Conference Machine Learning (ICML).Ye, N., Lee, W. S., Chieu, H. L., & Wu, D. (2009). Conditional Random FieldsHigh-Order Features Sequence Labeling. Proceedings Advances NeuralInformation Processing Systems (NIPS), pp. 21962204.Yu, H., Huang, L., Mi, H., & Zhao, K. (2013). Max-Violation Perceptron ForcedDecoding Scalable MT Training. Proceedings Empirical Methods NaturalLanguage Processing (EMNLP), pp. 11121123.Zhang, W., & Dietterich, T. G. (1995). Reinforcement Learning Approach job-shopScheduling. Proceedings International Joint Conference Artificial Intelligence(IJCAI), pp. 11141120.407fiJournal Artificial Intelligence Research 50 (2014) 235-264Submitted 12/13; published 06/14Reconnection Ideal Tree: New ApproachReal-Time SearchNicolas Riveranicolas.rivera@kcl.ac.ukKings College LondonLondon, WC2R 2LS, UKLeon IllanesJorge A. Baierlillanes@uc.cljabaier@ing.puc.clDepartamento de Ciencia de la ComputacionPontificia Universidad Catolica de ChileVicuna Mackenna 4860, Santiago, ChileCarlos Hernandezchernan@ucsc.clDepartamento de Ingeniera InformaticaUniversidad Catolica de la Santsima ConcepcionCaupolican 491, Concepcion, ChileAbstractMany applications, ranging video games dynamic robotics, require solvingsingle-agent, deterministic search problems partially known environmentstight time constraints. Real-Time Heuristic Search (RTHS) algorithms specificallydesigned applications. subroutine, invoke standard,bounded, search algorithm searches goal. paper present FRIT,simple approach single-agent deterministic search problems tight constraintspartially known environments unlike traditional RTHS search goalrather searches path connects current state so-called ideal tree .agent observes arc tree cannot traversed actual environment, removes arc carries reconnection search whoseobjective find path current state node . reconnectionsearch done using algorithm passed parameter FRIT. parameterRTHS algorithm, resulting algorithm RTHS algorithm. show,addition, FRIT may fed (bounded) complete blind-search algorithm.evaluate approach grid pathfinding benchmarks including game maps mazes.results show FRIT, used RTAA*, standard RTHS algorithm, outperformsRTAA* significantly; one order magnitude tight time constraints. addition,FRIT(daRTAA*) substantially outperforms daRTAA*, state-of-the-art RTHS algorithm,usually obtaining solutions 50% cheaper average performing search effort.Finally, FRIT(BFS), i.e., FRIT using breadth-first-search, obtains best-quality solutionstime limited compared Adaptive A* Repeated A*. Finally showBug2, pathfinding-specific navigation algorithm, outperforms FRIT(BFS) planningtime extremely limited, given time, situation reverses.1. IntroductionReal-Time Heuristic Search (Korf, 1990) approach solving single-agent search problems limit imposed amount computation used deliberac2014AI Access Foundation. rights reserved.fiRivera, Illanes, Baier, & Hernandeztion. used solving problems agents start moving completesearch algorithm solve problem especially suitable problemsenvironment partially known advance.application real-time heuristic search algorithms goal-directed navigationvideo games (Bulitko, Bjornsson, Sturtevant, & Lawrence, 2011) computer characters expected find way partially known terrain. Game-developing companiesimpose constant time limit amount computation per move close one millisecond simultaneously moving characters (Bulitko et al., 2011). such, real-timesearch algorithms applicable since provide main loop quick movesallow implementing continuous character moves.standard real-time heuristic search algorithmse.g., LRTA* (Korf, 1990) LSSLRTA* (Koenig & Sun, 2009)are algorithms choice videogame developers, sincerequire characters re-visit many states order escape so-called heuristicdepressions, producing back-and-forth movements, also referred scrubbing (Bulitkoet al., 2011). underlying reason behavior heuristic used guidesearch must updatedin process usually referred heuristic learningwhenevernew obstacles found. exit so-called heuristic depressions, agent may needrevisit group states many times (Ishida, 1992).exploiting preprocessing (e.g., Bulitko, Bjornsson, Lustrek, Schaeffer, & Sigmundarson, 2007; Bulitko, Bjornsson, & Lawrence, 2010; Hernandez & Baier, 2011), one produce Real-Time Heuristic Search algorithms control agent waysensible human observer. Give map terrain, algorithms compute information offline later utilized online Real-Time Search algorithm findpaths quickly.Unfortunately, preprocessing applicable settings. example one wantsimplement agent knowledge terrain, mapavailable prior search hence preprocessing carried out. hand,knowledge terrain partial (i.e., agent may know locationobstacles them), using plain Real-Time Heuristic Searchalong partial information map obtained preprocessing (i.e., perfectheuristic computed partially known map) may still result performanceissues described above.paper present FRIT, real-time search algorithm necessarilyrely heuristic learning control agent, produces high-quality solutionspartially known environments. easily motivated game applications, algorithmdesigned general search problems. agent controlled algorithm alwaysfollows branch tree containing family solutions. call tree idealtree paths contains solutions world currently knownagent, solutions may legal actual world. agent movesstates ideal tree usually encounter states accessibleblock solution ideal tree. happens, secondary algorithmwhichgiven parameteris used perform search reconnect current stateanother state known ideal tree. reconnection succeeds agentstate updated ideal tree, continue following branch tree.236fiReconnection Ideal Tree: New Approach Real-Time Searchdiscuss two different ways algorithm given parameter FRITuseful real-time scenarios. first alternative feed FRIT real-timesearch algorithm. produces standard real-time search algorithm, so-calledagent-centered search algorithm (Koenig, 2001) since verify node connectedideal tree may need consider states far away current position.second option make FRIT amenable real-time scenarios consists feedingFRIT bounded complete search algorithm; i.e., complete search algorithmiteration expands bounded number states. performing limited numberexpansions, search algorithm may found reconnecting path. caseagent may may perform action depending domain-specific considerations.implementation chose perform move all.evaluated algorithm standard game maze pathfinding benchmarks usingblind, breadth-first search algorithm two different real-time search algorithmsreconnection. Even though algorithm guarantee optimality, solutions returned, terms quality total time, significantly better returnedstate-of-the-art real-time heuristic search algorithms compared to, search effortcomparable. Upon inspection route followed agent, observeusing blind-search algorithms reconnection contain back-and-forth, irrational movements, indeed look similar solutions returned so-called bugalgorithms (LaValle, 2006; Taylor & LaValle, 2009) developed robotics community.such, usually detects states need visited againsometimes referreddead-ends redundant states (Sturtevant & Bulitko, 2011; Sharon, Sturtevant, &Felner, 2013)without implementing specific mechanism detect them.also compared algorithm incremental heuristic search algorithmsmodified behave like real-time search algorithm. find that, although FRITreach solution quality, obtain solutions significantly bettertime deadline tight (under 40 sec).algorithm extremely easy implement and, case sufficient timepre-processing, utilize techniques already described literature, like so-called compressed path databases (Botea, 2011), compute initial ideal tree. Furthermore,provide proofs termination algorithm using real-time search blind-searchreconnection, provide bound number moves required find solutionarbitrary graphs.contributions presented article published conferencepaper (Rivera, Illanes, Baier, & Hernandez, 2013b). articles extends workincludes new material. particular:describe method use algorithm real-time search algorithm passedparameter, evaluate results obtained using two different real-timealgorithms.provide proofs termination algorithms obtained using aforementioned method, general proof convergence applicable algorithmspropose.incorporate small optimization affects InTree[c] function describedSection 3.237fiRivera, Illanes, Baier, & Hernandezextend previous empirical results including maze benchmarks,previously considered, evaluating problem instances.addition, compare algorithm Bug2 (Lumelsky & Stepanov, 1987)pathfinding algorithm.rest paper organized follows. Section 2 describe backgroundnecessary rest paper. Section 3 describe simple version algorithmreal-time. Section 4 describe two alternative ways make algorithmsatisfy real-time property. Section 5 present theoretical analysis, followeddescription experimental evaluation Section 6. describe relatedwork, finish summary.2. Backgroundsearch problems deal paper described tuple P = (G, c, sstart , g),G = (S, A) directed graph represents search space. set representsstates arcs represent available actions. State sstart initialstate state g goal state. assume finite, containelements form (s, s), G g reachable states reachablesstart . addition, non-negative cost function c : R associates costavailable actions. Naturally, cost path graph sumcosts arcs path. Finally g goal state. Note even thoughdefinition considers single goal state still model problems multiple goalstates since always transform multiple-goal problem single-goal problemadding new state g graph connecting goals original problem gzero-cost action.define distance function dG : R dG (s, t) denotes costshortest path graph G. heuristic search graph G nonnegative function h : R h(s) estimates dG (s, g). say h admissibleh(s) dG (s, g), S. addition, say heuristic h consistent everypair (s, t) holds h(s) c(s, t) + h(t), furthermore h(g) = 0. simpleprove consistency implies admissibility.2.1 Real-Time SearchGiven search problem P = (G, c, sstart , g), objective real-time search algorithmmove agent sstart g, low-cost path. algorithm satisfyreal-time property, means agent given bounded amount timedeliberating, independent size problem. deliberation, agentexpected move. move, time given deliberation looprepeats.Real-Time Heuristic Search algorithms rely execution boundedstandard state-space search algorithm (e.g., A*, Hart, Nilsson, & Raphael, 1968). orderapply algorithm partially known environments, carry searchgraph may correspond graph describing actual environment.particular, pathfinding grid worlds, assumed dimensions grid238fiReconnection Ideal Tree: New Approach Real-Time Searchknown, enable search free-space assumption (Zelinsky, 1992) made, whereby gridcells regarded obstacle-free unless known blocked.define version free-space assumption use general searchproblems. assume certain search graph GM given input agent.graph reflects agent knows environment, kept memorythroughout execution. assume graph satisfies following generalized versionfree-space assumption: actual search graph G = (S, A), GM spanningsupergraph G, i.e. GM = (S, A0 ), A0 . Note GM supergraphG dGM (s, t) dG (s, t) s, S, h admissible GMG.moving environment, assume agent capable observingwhether arcs search graph GM = (S, A0 ) present actualgraph. Specifically, assume agent state s, able sense whether(s, t) A0 traversable actual graph. arc (s, t) traversable,inaccessible hence agent removes GM arcs lead t. Notemeans GM satisfies free-space assumption initially, always satisfyexecution.Note following fact implicit definitions: environment static.G, unlike GM , never changes. free-space assumption also impliesagent cannot discover arcs environment present search graph GM .Many standard real-time search algorithms structure Algorithm 1,solves search problem iterating loop runs four procedures: lookahead,heuristic learning, movement, observation. lookahead phase (Line 3) runs timebounded search algorithm returns path later determines agent moves.heuristic learning procedure (Line 4) changes h-value statessearch space make informed. Finally, movement observation phase(Line 5), agent moves along path graph previously computed lookaheadsearch procedure. moving, agent observes environment, prunes awayGM arc perceived absent actual environment.Algorithm 1: Generic Real-Time Search AlgorithmInput: search graph GM , heuristic function h, goal state gEffect: agent moved initial state goal state trajectory exists1 agent reached goal state2scurr current state.3path LookAhead(scurr , g).4Update heuristic function h.5Move agent path. moving, observe environmentupdate GM , removing non traversable arcs. Stop arc path removedpath traversed completelyRTAA* (Koenig & Likhachev, 2006) instance Algorithm 1. lookaheadphase, runs bounded A* scurr towards goal state, executes regularA* execution stopped soon node lowest f -value Open goal239fiRivera, Illanes, Baier, & Hernandezstate soon k nodes expanded. path returned one connectsscurr best state Open (i.e., state lowest f-value Open).hand, heuristic learning carried using Algorithm 2, resets heuristicstates expanded lookahead according f -value best state Open. KoenigLikhachev (2006) prove Algorithm 2 maintains consistency h h initiallyconsistent.Algorithm 2: RTAA*s heuristic learning.1234procedure Update ()f minsOpen g(s) + h(s)Closedh(s) f g(s)LRTA* (Korf, 1990) also instance Algorithm 1; indeed, LRTA* instanceRTAA* k parameter set 1. nutshell, simple version LRTA*decides move looking best scurr neighbors, updatesheuristic scurr also based heuristic neighbors.easy see RTAA* LRTA* satisfy real-time property sinceoperations carried prior movement take constant time. algorithmsalso completein sense always find solution one existswhen inputheuristic consistent. prove completeness, heuristic learning key. First,learning guarantees state agent moves lower heuristic value comparedh(scurr ). Second, learning procedure guarantees heuristic always bounded (in case RTAA*, many algorithms, consistency, henceadmissibility preserved execution).Finally, bounds number execution steps known algorithms.LRTA*, example, solve search problem (|S|2 |S|)/2 iterations, |S|number nodes search graph (Edelkamp & Schrodl, 2011, Ch. 11).3. Searching via Tree Reconnectionalgorithm propose moves agent towards goal state partially knownenvironment following arcs so-called ideal tree . Whenever arctree cannot traversed actual environment, carries search reconnectcurrent state node . section describe simple version algorithmstill satisfy real-time property. Prior that, describe builtinitially.3.1 Ideal Treeideal tree intuitively corresponds family paths connect statessearch space goal state. tree ideal arcs tree mayexist actual search graph. Formally,240fiReconnection Ideal Tree: New Approach Real-Time SearchDefinition 1 (Ideal Tree) Given search problem P = (G, c, sstart , g), graph GMsatisfies generalized free-space assumption respect G, ideal treeP GM directed acyclic subgraph GM that:1. goal state g parent (i.e., root),2. child , (t, s) arc GM .Note arcs ideal tree directed point children parent(Figure 1 depicts ideal tree grid world). Properties 1 2 Definition 1 implygiven ideal tree node GM suffices follow arcs (whichalso GM ) reach goal state g. Property 2 corresponds intuitionideal : arcs may exist actual search graph correspondarcs GM necessarily G.note search problems search graph defined using successorgenerator (as case standard planning problems) possible build ideal treefirst setting states represent leaves tree, computing pathgoal states. way achieving relax successor generator(perhaps removing preconditions), allows including arcsoriginal problem. such, Property 2 require user provide inversesuccessor generator planning problems.internal representation ideal tree straightforward. nodestore pointer parent s, denote p(s). Formally p : {null}{null}, p(null) = null p(g) = null. Notice representation actuallyused describe forest. Below, sometimes refer forest F use conceptpaths F, correspond paths connected component F might.outset search, algorithm present starts ideal treealso spanning, i.e., contains states S. general case,spanning ideal tree computed running Dijkstras algorithm goal nodegraph like GM arcs inverted. Indeed, h(s) defined distanceg graph, ideal tree constructed using following rules:every \ {g} define p(s) = arg minu:(s,u)A[GM ] c(s, u) + h(u), A[GM ]arcs GM .applications like real-time pathfinding video games, environmentpartially known priori reasonable assume sufficient time preprocessing (Bulitko et al., 2010). preprocessing time, one could run Dijkstras algorithmevery possible goal state. memory problem, one could use so-called compressed pathdatabases (Botea, 2011), actually define spanning ideal trees every possible goalstate given grid.Moreover, gridworld pathfinding unknown terrain, ideal tree obstaclefree GM quickly constructed using information given standard heuristic.Manhattan distance octile distance correspondvalue returned Dijkstra call goal state 4-connected 8-connected grids,respectively. cases grid completely partially known initiallytime preprocessing, one still feed algorithm obstacle-free initial241fiRivera, Illanes, Baier, & Hernandezgraph obstacles regarded accessible neighbor states. Thus, callalgorithm like Dijkstra need made insufficient time.implementation algorithm gridworlds exploit facttree built fly. Indeed, need set p(s) every startingsearch; instead, set p(s) needed first time. such, timespent initializing ideal tree search. generally, depending problemstructure, specific implementations exploit fact need explicit tree.3.2 Following Reconnectingsearch algorithm, Follow Reconnect Ideal Tree (FRIT, Algorithm 3)receives input search graph GM , initial state sstart , goal state g, graphsearch algorithm A. GM search graph known agent initially, assumesatisfies generalized free-space assumption respect actual search graph.algorithm used reconnecting ideal tree. require receive followingparameters: initial state, search graph, goal-checking boolean function,receives state parameter.Algorithm 3: FRIT: Follow Reconnect Ideal TreeInput: search graph GM , initial state sstart , goal state g, searchalgorithm1 Initialization: Let ideal tree GM .2 Set sstart .3 Set c 0 color state GM 0.4 Set hobstacle .5 6= g6Observe environment around s.7newly discovered inaccesible state8h(o) < hobstacle9hobstacle h(o).1011121314Prune GM arcs lead o.p(s) = nullcc+1Reconnect (A, s, GM , InTree[c]()).Movement: Move agent p(s) set new positionagent.Algorithm 4: Reconnect component FRITInput: search algorithm A, initial state s, search graph GM goalfunction fGOAL ()1 Let path returned call A(s, GM , fGOAL ()).2 Assuming = s0 s1 , . . . sn make p(si ) = si+1 every {0, . . . , n 1}.242fiReconnection Ideal Tree: New Approach Real-Time Searchinitialization (Lines 14), sets ideal tree graph GM . discussedabove, tree retrieved database, pre-processing carried out.time pre-processing suitable heuristic available GM , computesfly. addition sets value variable c color every state 0,sets variable hobstacle . Note computed fly, state colorsalso initialized fly. hobstacle used maintain record smallest heuristicvalue observed inaccessible state. role state colors hobstacle becomeclear below, describe reconnection InTree[c] function. initialization,main loop (Lines 614), agent observes environment prunes GMarcs exist actual graph. Additionally, updates hobstacleneeded. current state agent observes parent reachableactual search graph, sets parent pointer s, p(s), null. agentmove immediately state p(s) unless p(s) = null. latter case, disconnectedideal tree , reconnection search carried shown Algorithm 4.procedure calls algorithm A. objective search reconnect state: goal function InTree[c]() returns true invoked state falseotherwise. path returned, reconnect current state pathfound move parent s. main loop Algorithm 3 finishesagent reaches goal.3.2.1 InTree[c] Functionkey component reconnection search InTree[c] function determines whetherstate . implementationshown Algorithm 5follows parentpointers state queried returns true reaches goal state statewhose h-value smaller hobstacle . last condition exploits fact waybuilt (i.e.: free-space assumption) ensures states closer goalobserved obstacle must still . merely optimization technique,removing incur small performance reduction, change actionsagent. addition, paints visited state color c, given parameter.algorithm returns false state visited parent paintedc (i.e., visited previous call InTree[c]reconnection search).Algorithm 5: InTree[c] functionInput: vertex1 6= g2h(s) < hobstacle3return true6Paint color c.p(s) = null p(s) color creturn false7p(s)458return true243fiRivera, Illanes, Baier, & HernandezFigure 1 shows example execution algorithm priori unknown gridpathfinding task. observed, agent moves wall encountered,continues bordering wall solves problem. simple see that,vertical longer, agent would traveled beside wall following similardown-up pattern.example reflects general behavior algorithm grid worlds: agentusually moves around obstacles, way resembles bug algorithms (LaValle, 2006;Taylor & LaValle, 2009). occurs agent believes path behindwall currently known always tries move state unless anotherstate allows reconnection found first. closer look shows timesagent walk exactly besides wall moves close it, performingsort zig-zag movement. occur search used consider costdiagonals. Breadth-First Search (BFS) Depth-First Search (DFS) may sometimes preferusing two diagonals instead two edges cost 1.avoid problem use variant BFS, that, iterations, generatesfirst non-diagonal successors later diagonal ones. nodes deeper searchuses standard ordering (e.g., clockwise). version BFS achieves practicebehavior similar bug algorithm.1 approach explored previouswork (Rivera et al., 2013b), overall improvements shown small.paper, use standard BFS. See Section 6.4 detailed comparison bugalgorithms.Note algorithm perform kind update heuristic h.contrasts traditional real-time heuristic search algorithms, rely increasingheuristic value h exit heuristic depressions generated obstacles.process may need revisit cell several times.4. Satisfying Real-Time PropertyFRIT, presented, satisfy real-time property. two reasons this:R1. number states expanded call algorithm passed parameter, A,depends search graph GM rather constant; and,R2. execution A, time checks whether state connectedideal tree , function InTree[c] may visit number states dependentsize search graph GM .present two natural approaches making FRIT satisfy real-time property.first approach use slightly modified, generic real-time heuristic search algorithmparameter algorithm. resulting algorithm real-time search algorithmsatisfies real-time property time movementsbounded constant. second approach limits amount reconnection searchguarantee time movements limited constant.1. Videos viewed http://web.ing.puc.cl/~jabaier/index.php?page=research.244fiReconnection Ideal Tree: New Approach Real-Time Search1234567812345678123456781BBBBCCCCEEEFF(a)ggF(b)2345678EgF(c)(d)Figure 1: illustration steps execution 4-connected gridpathfinding task, initial state cell D3, goal E6. search algorithmbreadth-first search, which, expanding cell, generates successors clockwiseorder starting node right. position agent shown blackdot. (a) shows true environment, known priori agent. (b) showsp pointers define ideal tree built initially Manhattan heuristic. Followingp pointers, algorithm leads agent D4, new obstacle observed. D5disconnected GM , reconnection search initiated. (c) shows statusreconnection search expands state D4, finding E4 . agentmoved E4, new reconnection search expands gray cells shown (d).problem solved simply following p pointers.4.1 FRIT Real-Time Heuristic Search Algorithmsnatural way addressing R1 using real-time search algorithm parameterFRIT. turns possible plug FRIT real-time search algorithmdirectly without modifications. However, modifications need make Algorithm 1simple. describe below.following two observations justify changes need made pseudocode generic real-time search algorithm. First observe objectivelookahead search procedure real-time heuristic algorithms like Algorithm 1 searchtowards goal thus heuristic h estimates distance goal. However,FRIT carries search sole objective reconnecting ideal tree,means goal condition heuristic changed. Second, onemain ideas underlying FRIT use maintain ideal tree ; is,agent found reconnecting path, p function needs updated accordingly.Algorithm 6 shows pseudocode modified generic real-time heuristic searchalgorithm, two main differences respect Algorithm 1. First, goalcondition given function gT , returns true evaluated state. Second, Line 5 Algorithm 6 connects states path found lookaheadsearch . implies also Reconnect procedure described Algorithm 4needs changed described Algorithm 7.turn attention guide search towards reconnection usingreconnecting heuristics. giving formal definition heuristics, introducelittle notation. Given graph GM = (S, A) ideal tree GM problemP goal state g, denote ST set states . ready definereconnecting heuristics formally.245fiRivera, Illanes, Baier, & HernandezAlgorithm 6: Generic Real-Time Search Algorithm FRITInput: search graph GM , heuristic function h, goal function gT ()receives state parameter.Effect: agent moved initial state goal state trajectoryexists. ideal tree updated.1 agent reached goal state2scurr current state3path LookAhead(scurr , gT ())4Update heuristic function h.5Given path = s0 s1 . . . sn , update p(si ) = si+1 every{0, . . . , n 1}.6Move agent path. moving, observe environmentupdate GM , removing non traversable arcs updating hobstacleneeded. Stop current state parent .Algorithm 7: Reconnect component FRIT real-time algorithmInput: real-time search algorithm A, initial state s, search graph GMgoal function fGOAL ()1 Call A(s, GM , fGOAL ).Definition 2 (Admissible Reconnecting Heuristic) Given ideal tree graphGM subset B ST , say function h : R+0 admissible reconnectingheuristic respect B iff every holds h(s) dGM (s, s0 ),s0 B.Intuitively, reconnecting heuristic respect B admissible heuristicgraph GM set goal states defined B. such, Algorithm 6initialized reconnecting heuristic, search guided towards connectedstates.Depending choose B, may obtain different heuristic. first glance,may seem sensible choose B ST . However, immediately obvious one wouldmaintain (i.e., learn) heuristic efficiently. ST changenew obstacles discovered. Initially ST contains states execution,states cease belong ST arc removed become membersreconnection completed.paper propose use easy-to-maintain reconnecting heuristic, which,initialized zero updated standard way. Below, proveupdate procedure standard properties, h corresponds reconnectingheuristic subset B = V (E) ST , V (E) defined follows:B = V (E) = {s ST : visited agent 6 E}.addition, E must set set states whose heuristic value potentiallyupdated real-time search algorithm. reason that, definition,246fiReconnection Ideal Tree: New Approach Real-Time Searchstates B h-value set zero thus want include Bstates potentially modified.prove simple heuristic initialized 0 states updatedstandard way indeed reconnecting heuristic.Proposition 1 Let FRIT modified initialize h null heuristic. Let E definedset states update procedure potentially updated.2 Furthermore, assumeinstance Algorithm 6 satisfying:P1. gT (s) returns true iff ST .P2. Heuristic learning maintains consistency; i.e., h consistent prior learning,remains learning.Then, along execution FRIT(A), h reconnecting heuristic respectB = V (E).Proof: First observe initially h reconnecting heuristic setzero every state. Let state s0 state B. proveh(s) d(s, s0 ). Indeed, let = s0 s1 . . . sn , s0 = sn = s, shortest paths0 . Since h consistent, holdsh(si ) c(si , si+1 ) + h(si+1 ),(1){0, . . . , n 1}. writeh(s) h(s0 ) =n1Xh(si ) h(si+1 )i=0n1Xc(si , si+1 ) = d(s, s0 )(2)i=0observe s0 B, h-value s0 could updatedalgorithm therefore h(s0 ) = 0, substituted Inequality 2, proves desiredresult.4.1.1 Tie-Breakingpathfinding, standard approach tie-breaking among states equal f-valuesselect state highest g-value. reconnection search, propose differentstrategy based selecting state based user-given heuristic guide searchtowards final goal state. example, experiments grids break tiesselecting state smallest octile distance goal. Intuitively, among two otherwiseequal states, prefer one seems closer final goal. seems likereasonable way use information commonly used search algorithms,unavailable reconnection search due initial use null heuristic.2. Note practice, E natural set states. example RTAA* used, set statespotentially updated expanded A* lookahead search.247fiRivera, Illanes, Baier, & Hernandez4.1.2 Making InTree[c] Real-Timebeginning Section 4 identified R1 R2 two reasons FRITsatisfy real-time property, discussed address R1 using real-timesearch algorithm. discuss address R2.address R2, simply make InTree[c] bounded algorithm. real-time searchalgorithms receive parameter allows bound computation carried persearch. Assume Algorithm 6 receives k parameter. Furthermore, assume withoutloss generality lookahead search implemented algorithm constantlyexpands states (such bounded A*). always choose implementation-specificconstants NE NT , associated respectively expansions performed lookaheadoperation follows p pointer InTree[c] function. Given enumber expansions performed lookahead search f number times ppointer followed run real-time search algorithm, modify stopcondition InTree[c] return false NE e + NT f > k. Also, modify lookaheadsearch stop condition holds true.Henceforth call FRITRT algorithm addresses R1 R2 using real-timesearch algorithm bounded version InTree[c]. Note computation per iteration FRITRT bounded, time agent moves bounded,thus FRITRT considered standard real-time algorithm, originally definedKorf (1990). Note however time reach state connected ideal treebounded, several calls real-time algorithm may required reachingstate.4.2 FRIT Bounded Complete Search Algorithmsprevious section proposed use standard real-time heuristic search algorithmreconnect ideal tree. potential downside approachalgorithms usually find suboptimal solutions sometimes require re-visitingstate many timesa behavior usually referred scrubbing (Bulitko et al., 2011).applications quality solution important, stillreal-time constraints possible make FRIT satisfy real-time property differentway.Imagine example, situation FRIT given sequencetime frames, short. time frame FRIT allowed returnmovement performed agent. model real-time behaviortermed game time model (Hernandez, Baier, Uras, & Koenig, 2012b) sinceclear application video games games main cycle reserve fixedusually short amount time plan next move automated characters.accommodate behavior FRIT apply simple idea already described Section 4.1.2, using complete search algorithm reconnection ratherreal-time search algorithm. described simply involves choosing implementationspecific constants NE NT , associated respectively expansions performed(now complete) search algorithm reconnection operation follows ppointer InTree[c] function. before, given e number expansionsperformed reconnection search f number times p pointer modify248fiReconnection Ideal Tree: New Approach Real-Time SearchReconnect algorithm return empty path soon NE e + NT f > k savelocal variables used InTree[c]. Reconnect called again, searchresumed point previous iteration e f set 0.Note instead returning empty path implementations may choosemove agent fashion meaningful specific application. leavethorough discussion implement movement strategy scopepaper since believe strategy usually application-specific. movementought carried time frame, agent could choose move back-andforth, choose moving strategy allows follow reconnection pathfound. Later, experimental evaluation, choose move agentcomputation exceeds parameter discuss seems good strategyapplication chose.Note non-empty path returned given time frame, FRIT,modified way described above, also real-time search algorithm, originallydefined Korf (1990). Finally, note implementing stop-and-resume mechanismdescribed easy search algorithms.5. Theoretical Analysisresults described section prove termination algorithms presentexplicit bounds number agent moves performed FRIT FRITRTreaching goal. Additionally, show algorithms converge second runsubsequent executions algorithm result identical paths. first theoremcorrectness InTree[c] function.5.1 Proofs InTree[c]determine whether state belongs ideal tree, InTree[c] function(Algorithm 5) follows p pointers goal reached state whoseh-value smaller hobstacle reached. prove InTree[c] correctsense returns true iff state belongs ideal tree. start provingfollowing intermediate result.Lemma 1 Let H = {s : h(s) < hobstacle }. Reconnection search never modifies parentpointer state H.Proof: Take state H. clear call InTree[c](s) immediatelyreturn true (Algorithm 5, Lines 2 3). effectively ends search, pathends selected. path change parent s.Note property described Lemma holds FRIT FRITRT .bounded version InTree[c] used FRITRT always answer true calledstate H. Indeed, states H part reconnection target set B,correctly identified execution.Theorem 1 initialized described Section 3 color c set increment reconnection search, InTree[c], described Algorithm 5, returns truestate iff .249fiRivera, Illanes, Baier, & HernandezProof: Note besides exit condition established Lines 2 3, algorithmtrivially correct. follows parent pointers, returns true reaches goal,returns false reaches dead end state already checked.Let H defined Lemma 1. need prove states H .know states original parent pointers set constructiondescribed Section 3. Note paths initial Ideal Tree monotonic;every state different goal holds h(s) h(p(s)). this, knowstate H, p(s) H true. proves ancestors H,therefore represent path existed initial modified.5.2 Termination Bound FRITRTfirst result proves termination algorithm uses real-time search algorithmparameter. provide explicit bound number agent moves reachinggoal.Theorem 2 Consider conditions Proposition 1 let modified real-timesearch algorithm described Algorithm 6, requires fA (x) agent movessolve problem x states, never updates h-value goal state.agent controlled FRITRT (A) reaches goal state performing O(|S|fA (|S|))moves.Proof: Let denote elements state space inaccessiblestate connected component contains sstart . Furthermore, let ideal treecomputed initialization. Note that, Proposition 1, know use reconnectingheuristic. definition, means heuristic always admissible subsetstates always contain least g. Therefore, know reconnectionseventually successful reconnection takes fA (|S|) steps. Noticeagent moves |S| steps Ideal Tree reaches inaccessible state.reconnection search invoked new inaccessible state detected,invoked |M| times. definition , know |M| reconnections,agent must able reach goal following . Therefore, total numbersteps |S| + |M|(fA (|S|) + |S|) O(|S|fA (|S|)).average length paths found FRITRT expected much lower. Indeed, number reconnections bounded number obstacles reachablestate GM , many cases much lower total number inaccessiblestates.5.3 Termination Bound FRITfollowing result provides bound length solutions found FRIT.Theorem 3 Given initial tree GM satisfies generalized free-space assumption,2FRIT solves P (|S|+1)agent moves.4250fiReconnection Ideal Tree: New Approach Real-Time SearchProof: Let described proof Theorem 2. Note goalstate g always part , thus never become empty reconnection alwayssucceed. FRITRT , reconnection search invoked |M| times.two consecutive calls reconnection search, agent moves tree thus cannot visitstate twice. Hence, number states visited two consecutive reconnectionsearches |S| |M|. conclude number moves algorithmterminates(|M| + 1)(|S| |M|),(3)largest |M| =|S|12 .Substituting value (3) gives desired result.Again, average complexity expected much lower bound.5.4 Convergencefollowing results prove termination either FRIT FRITRT , agentknows solution problem possibly shorter one found.Lemma 2 Let F forest defined p pointers. Throughout execution eitherFRIT FRITRT , path F goes sstart current positionagent.Proof: proof done induction number steps taken agent. Letrepresent current position agent. Initially, proposition trivial, sstart = s.Let s0 position agent moving. induction hypothesis, knowpath sstart s. s0 , know parent pointersstates different modified, therefore path extendsappending s0 valid satisfies property. s0 , know parentpointers states appear s0 modified, thereforevalid subpath goes sstart s0 satisfies property.Theorem 4 Running algorithm second time problem, without reinitializing ideal tree, results execution never runs reconnection search findspotentially better solution one found first run.Proof: proof straightforward Lemma 2. end execution,path F, specifically , sstart g. Note states pathnecessarily visited first execution, ensures new pathlong one resulting first execution.Note Theorem 4 implies algorithm return different path secondtrial, viewed optimized solution contain loopsfirst solution had. second execution algorithm naturally fast,reconnection search required.interesting note approach could used real-time searchalgorithm. storing visited state direction agent moved awayit, path loops goes sstart g immediately extractedsoon execution finishes.251fiRivera, Illanes, Baier, & Hernandez6. Empirical Evaluationobjective experimental evaluation compare performance algorithm various state-of-the-art algorithms task pathfinding real-timeconstraints. chose application since seems straightforward application real-time search algorithms.compared three classes search algorithms. first class, considered stateof-the-art real-time heuristic search algorithms corresponding versions FRITRTresult fed these. Specifically, compare RTAA* (Koenig &Likhachev, 2006) daRTAA* (Hernandez & Baier, 2012), variant RTAA*may outperform significantly. versions algorithm, tree ideal treebuilt outset search rather built on-the-fly, using heuristic function.second class, compared FRIT fed breadth-first-search algorithmincremental heuristic search algorithms Repeated A* (RA*) Adaptive A* (AA*).chose one hand fairly obvious modify satisfyreal-time property following approach follow FRIT, handreasonable performance. Indeed, include D* Lite (Koenig &Likhachev, 2002) since shown Repeated A* faster D* Liteinstances problems evaluate (Hernandez, Baier, Uras, & Koenig, 2012a).incremental search algorithms included since focus paperpropose strategies make various algorithms satisfy real-time property.Finally compare algorithm Bug2 (Lumelsky & Stepanov, 1987) so-called bugalgorithm, algorithm specifically designed path-planning. Bug algorithmneed limited computational requirements make decisions.Repeated A* Adaptive A* run complete A* search currently knownsearch graph goal reached. path found followed. followingpath, search graph updated newly found obstacles. agent stopsreaches goal reached path blocked obstacle.happens, iterate running another A* goal. make algorithms satisfyreal-time property, follow approach similar employed designalgorithm Time-Bounded A* (Bjornsson, Bulitko, & Sturtevant, 2009). iteration,allow algorithm expand k states. path goal foundagent move. Otherwise (the agent found path goal), agent makessingle move path.case FRIT(BFS), satisfy real-time property discussedsetting constants, NE NT , 1. means iteration, currentstate parent k states expanded/visited reconnectionsearch reconnection path found agent moved. Otherwise,current state non-null parent pointer, agent follows pointer.Therefore iteration FRIT(BFS), Repeated A* Adaptive A* two thingshappen: either agent moved agent moved one step. moving strategysensible applications like video games where, although characters expected movefluently, want force algorithm return arbitrary move pathfound, since would introduce moves may perceived pointlessusers. contrast, real-time search algorithms return move iteration.252fiReconnection Ideal Tree: New Approach Real-Time Search4 mazes - 500 runs4 mazes - 500 runs10000000FRIT_rt(RTAA)FRIT_rt(daRTAA)RTAAdaRTAA1000000Average Solution Cost (log-scale)Average Solution Cost (log-scale)10000000100000100001000020406080100120FRIT_rt(RTAA)FRIT_rt(daRTAA)RTAAdaRTAA100000010000010000140Average time per planning episode (us)020406080100120Average time per planning episode (us)(a) Real-time algorithms games.(b) Real-time algorithms mazes.Figure 2: Real-time algorithms: Total Iterations versus Time per Episodeuse eight-neighbor grids experiments since often preferred practice,example video games (Bulitko et al., 2011). algorithms evaluatedcontext goal-directed navigation priori unknown grids. agent capabledetecting whether eight neighboring cells blocked moveone unblocked neighboring cells. user-given h-values octile distances(Bulitko & Lee, 2006).carry experiments, used twelve maps deployed video games fourdifferent mazes. Six maps taken game Dragon Age, remainingsix taken game StarCraft. maps mazes retrievedNathan Sturtevants pathfinding repository (Sturtevant, 2012).3averaged experimental results 500 test cases reachable goal cellmap. test case start goal cells chosen randomly. realtime algorithms run 10 different parameter values. incremental algorithmsrun completion per test case, results processed showbehavior corresponding using 150,000 different values k parameter.experiments run 2.00GHz QuadCore Intel Xeon machine running Linux.6.1 Analysis Results Real-Time Search AlgorithmsFigure 2 shows two plots average solution cost versus average time per planningepisode four real-time search algorithms games mazes benchmarks.observe games benchmarks FRITRT outperforms RTAA* daRTAA*substantially. FRITRT (daRTAA*) finds solutions half cost founddaRTAA* given time deadline. Moreover, average planning time per episodeneeded FRITRT (daRTAA*) obtain particular solution quality one halfneeded daRTAA*. improvements pronounced FRITRT (RTAA*),3. Maps used Dragon Age: brc202d, orz702d, orz900d, ost000a, ost000t ost100d whose sizes481 530, 939 718, 656 1491, 969 487, 971 487, 1025 1024 cells respectively. MapsStarCraft: ArcticStation, Enigma, Inferno, JungleSiege, Ramparts WheelofWar sizes 768 768,768 768, 768 768, 768 768, 512 512 768 768 cells respectively.four mazes size, 512 512, different corridor widths: 4, 8, 16 32.253fiRivera, Illanes, Baier, & Hernandez100000000FRIT(BFS)RAAAoptimal1000000Average Solution Length (log-scale)Average Solution Length (log-scale)100000001000001000010000100200300400500600Average time per planning episode (us)FRIT(BFS)RAAAoptimal10000000100000010000010000100002004006008001000Average time per planning episode (us)(a) Incremental algorithms games.(b) Incremental algorithms mazes.Figure 3: Incremental algorithms: Total Iterations versus Time per Episodesolutions given time deadline least three times cheaper pure RTAA*one order magnitude cheaper small time frames. interestingnote even though daRTAA* improves significantly RTAA*, FRITRT (daRTAA*)marginally better FRITRT (RTAA*).mazes, FRITRT variants seem slightly better daRTAA*, bigger improvements performance noticeable time deadlines increased.best solutions found daRTAA* FRITRT (daRTAA*) comparable lengths,FRITRT (daRTAA*) finds solutions requiring slightly half time perplanning episode daRTAA*.6.2 Analysis Results Incremental Algorithms Modified SatisfyReal-Time PropertyFigure 3 shows two plots average number agent steps versus average time perplanning episode incremental search algorithms used real-time algorithmsdescribed aboved games mazes benchmarks. Figure 4 shows regionsplots Figure 3 FRIT(BFS) appears.observe FRIT(BFS) returns significantly better solutions time constraintstight. Indeed, games benchmarks algorithm need 41 secper planning episode return best solution. Given time limit per episode,AA* requires four times many iterations average. Furthermore, obtainsolution quality returned FRIT(BFS) 41 sec, AA* needs around 220 sec;i.e., 5 times long FRIT(BFS). behavior extreme casemazes, best solutions FRIT(BFS) obtained less 19 sec perplanning episode. time limit, number steps required average AA*whole order magnitude larger number required FRIT(BFS).Generally, FRIT(BFS) behaves much better RA* AA*, requiring feweriterations less time. Nevertheless, provided time, FRIT(BFS) takeadvantage resulting solutions cease improve. seen254fiReconnection Ideal Tree: New Approach Real-Time Search100000000FRIT(BFS)RAAAoptimal1000000Average Solution Length (log-scale)Average Solution Length (log-scale)1000000010000010000100001020304050FRIT(BFS)RAAAoptimal1000000010000001000001000010000Average time per planning episode (us)5101520Average time per planning episode (us)(a) Incremental algorithms games.(b) Incremental algorithms mazes.Figure 4: Incremental algorithms: Total Iterations versus Time per Episode (zoomed)FRIT(BFS)k Avg. Time/ep( s)1 1508631 0.04305 303483 0.214810 152858 0.428350 32401 2.0940100 17370 4.06785005449 16.11510004035 24.84050003073 39.316100003026 40.487500003011 40.8511000003011 40.869RA*moves Avg. Time/ep(%)( s)99.80 3505076 0.375499.01 702029 1.876198.03 351648 3.749990.71 71343 18.65582.67 36305 37.07744.748304 175.8925.384901 322.742.0462261 915.660.5011947 1171.90.0301726 1458.90.0071711 1484.7AA*moves Avg. Time/ep(%)( s)99.95 1144680 0.415299.76 229967 2.072799.51 115628 4.137697.60 24156 20.37895.29 12723 40.00479.423607 172.4165.132583 274.3524.441854 474.2912.261775 514.881.0411728 524.550.1331726 543.66moves(%)99.8499.2598.5192.8686.4452.1533.206.9042.7640.1170.014Table 1: Relationship search expansions number iterationsagent move games maps. table shows parameter k algorithm.case AA* Repeated A* parameter corresponds number expandedstates. case FRIT, parameter corresponds number visited statesiteration. addition, shows average time per search episode (Time/ep),percentage iterations agent move respect total numberiterations (No moves).Figure 3, across sets benchmarks, Table 1. example this, seek = 5000 k = 100000 number iterations required solve problemdecreases 62 steps, time used per search episode increases 1.55 sec.Effectively, means algorithm use extra time advantageousway. contrast usually expected real-time search algorithms.255fiRivera, Illanes, Baier, & Hernandezinteresting variable study number algorithm iterationsagent return move algorithm exceeded amount computationestablished parameter without finishing search. see Table 1, FRIT,using BFS parameter algorithm, best relationship time spent perepisode percentage no-moves total number moves. comparablereal-time heuristic search algorithms, would preferrable reduce numberincomplete searches much possible. mind, focus timeamount incomplete searches reduced less 1%. NoticeFRIT(BFS) somewhere around 40 s, whereas AA* RA* requires times514 1458 respectively.6.3 Comparison Two ApproachesFigure 5 shows plot average time per planning episode versus average numberagent steps FRITRT (daRTAA*) FRIT(BFS) games benchmarks.observe FRIT(BFS) obtains better resuts time limits. Indeed, giventime deadline 10 sec, FRIT(BFS) finds solution half longfound FRITRT (daRTAA*). smaller time deadlines results similaralgorithms. Furthermore, best solution obtained FRIT(BFS) is, average,less 60% long best solution obtained FRITRT (daRTAA*). mentionedabove, particular solution requires time deadline less 41 sec per planningepisode. number no-moves incurred time limit experiments465 iterations throughout experiments games benchmarks, correspondsapproximately one no-move every 40, 000 moves.12 maps - 500 runsAverage Solution Length (log-scale)10000000FRIT_rt(daRTAA)FRIT(BFS)10000001000001000010000102030405060Average time per planning episode (us)Figure 5: Comparison FRIT using real-time algorithm versus FRIT incrementalalgorithm games benchmarks.256fiReconnection Ideal Tree: New Approach Real-Time Search1234567891011121312345678910111213BBCCEEFFGGHH(a)(b)Figure 6: Bug2 (a) FRIT (b) pathfinding scenario goal cell E10initial cell E2. segmented line shows path followed agentfilled arrow m-line.6.4 Comparison Bug2 AlgorithmBug algorithms (LaValle, 2006; Taylor & LaValle, 2009) family pathfinding algorithms continuous 2D terrain. make decisions based sensory input, requirelimited time memory resources, inspired behavior insectsfinding way obstacles. Bug algorithms heuristic utilizeheuristic function make decisions (Rao, Kareti, Shi, & Iyengar, 1993).Bug2 (Lumelsky & Stepanov, 1987) bug algorithm simple implementguaranteed reach goal. agent controlled Bug2 follow straight lineconnecting initial position final positionthe so-called m-line, encountering obstacle reaching goal. obstacle encountered, saves positionobstacle hit variable called hit point starts followingboundary obstacle (either clockwise counterclockwise) m-line encountered again. Then, current position closer goal hit point, agentstarts following m-line process repeats.Figure 6 compares behaviors FRIT Bug2. particular situation, Bug2make good decision FRIT solves problem fairly quickly. coursepossible contrive families problems Bug2 always outperform FRIT.implemented Bug2 8-connected grid worlds. forbid diagonal movementstwo obstacles, essentially effect changing directionobstacles boundary followed. make comparison fair, also ran FRIT(BFS)additional restriction. used game maps, generated 500 solvablerandom problems them.Results FRIT(BFS) shown Table 2. average cost solutions obtainedBug2 6546, requiring 5766 iterations. addition, average runtime 2317s, yields, average, 0.4 spent per iteration. FRIT(BFS) spends around 0.4per search episode k = 12, requires 20 times iterations solveproblem yielding 97% no-moves. obtain solution comparable Bug2,FRIT(BFS) requires k set around 462, yields average time per searchepisode close 12 s, returning no-move 47% iterations. Finally, time257fiRivera, Illanes, Baier, & Hernandezk Avg. Time/ep ( s) moves (%)1 15440870.034699.815 3105790.172599.0310 1564110.344298.0750 333141.683090.91100 147153.271283.01500552113.00945.451000407020.13226.025000307932.1622.20710000302733.1930.54250000301233.5200.026100000301133.5320.006Table 2: Performance Indicators FRIT(BFS) diagonal movements allowedobstacles.available, FRIT(BFS) returns solutions average 50% cheaperobtained Bug2.conclusion observe pathfinding applications Bug2 runs fastersearch algorithm tried. disadvantage, Bug2 specific pathfindingcannot exploit additional time per episode obtain better solution, yielding solutionslonger obtained FRIT(BFS) time available. Thereforebug algorithms seem recommended real-time pathfinding applicationslittle time available per iteration. time available FRIT(BFS)recommended algorithm, leaving AA* choice applicationssignificantly time available.6.5 Usefulness Reconnecting HeuristicsDefinition 2 introduced idea admissible reconnecting heuristics, arguedimportant guide search towards reconnection. natural question ask whetherheuristics key performance FRITRT . Indeed, admissible heuristicproblem formally admissible reconnecting heuristic since simply needdefine B = {g} Definition 2. Nevertheless, intuitively problems heuristicguide towards reconnection ideal tree.evaluate usefulness reconnecting heuristics, implemented versionFRITRT (RTAA*) that:1. uses problems heuristic guide A* search,2. breaks ties favor states greater g-value,3. learns h using RTAA*s learning rule.compared standard FRITRT (RTAA*), uses admissible reconnectionh = 0 guide A* search, uses problem heuristic first tie breaker, uses258fiReconnection Ideal Tree: New Approach Real-Time Searchg-value second tie breaker, learns h using RTAA*s learning rule. ranalgorithms 12 game maps, using configuration described above.Figure 7 shows relative performance algorithms, confirming indeedpathfinding applications, using reconnection heuristics key performance. Usinggoal heuristic guide reconnection performs similar baseline (RTAA*).FRITRT , used problems heuristic, seen version RTAA*stops A* search early expands state agent believes connectedgoal (i.e., ideal tree). Although stopping search early saves time respectRTAA*, expensive goal conditionwhich verifies state idealtreeseems counter time savings unless lookahead parameter high.12 game maps - 500 runsAverage Solution Cost (log-scale)10000000FRIT_rt(RTAA) [h0=0]FRIT_rt(RTAA) [h0=octile]RTAA1000000100000100001000020406080100120Average time per planning episode (us)Figure 7: Comparison FRITRT using reconnecting heuristic (h=0) guide searchversus FRITRT using problems heuristic.7. Related WorkIncremental Heuristic Search Real-time Heuristic Search two heuristic search approaches solving search problems partially known environments using free-spaceassumption related approach propose here. Incremental search algorithms based A*, D* Lite (Koenig & Likhachev, 2002), Adaptive A* (Koenig& Likhachev, 2005) Tree Adaptive A* (Hernandez, Sun, Koenig, & Meseguer, 2011),reuse information previous searches speed current search. algorithmssolve sequences similar search problems faster Repeated A*, performsrepeated A* searches scratch.runtime, incremental search algorithms, like algorithm, store graphmemory reflecting current knowledge agent. first search, performcomplete A* (backward forward), subsequent searches perform lessintensive searches. contrast algorithm, searches return optimal paths connecting current state goal. FRIT similar incremental search algorithmssense uses ideal tree, information that, cases, may259fiRivera, Illanes, Baier, & Hernandezcomputed using search, differs objective searchcompute optimal paths goal. algorithm leverages speed simple blindsearch need deal priority queue, computationally expensivehandle.Many state-of-the-art real-time heuristic search algorithms (e.g., Koenig & Sun, 2009;Koenig & Likhachev, 2006; Sturtevant & Bulitko, 2011; Hernandez & Baier, 2012; Rivera,Baier, & Hernandez, 2013a), satisfy real-time property, rely updatingheuristic guarantee important properties like termination. algorithm,hand, need update heuristic guarantee termination. Like incrementalsearch algorithms, real-time heuristic search algorithms usually carry search pathcurrent node goal state. Real-time heuristic search algorithms cannotreturn likely better solution problem solved without performing search(cf. Theorem 4). Instead, running multiple trials eventually convergeoptimal solution offer guarantees solution quality. algorithm offerguarantees solution quality, even though experimental results positive.HCDPS (Lawrence & Bulitko, 2010) real-time heuristic algorithmemploy learning. algorithm tailored problems agent knows mapinitially, time preprocessing.idea reconnecting tree rooted goal state new tracedback bi-directional search (Pohl, 1971). recent Incremental Search algorithm, TreeAdaptive A* (Hernandez et al., 2011), exploits idea make subsequent searches faster.Real-Time D* (RTD*) (Bond, Widger, Ruml, & Sun, 2010) uses bi-directional searchperform searches dynamic environments. RTD* combines Incremental Backward Search(D*Lite) Real-Time Forward Search (LSS-LRTA*).Finally, notion generalized free-space assumption related proposedBonet Geffner (2011), case planning partially observable environments.certain circumstances, propose set unobserved variables action preconditions convenient way planning time, indeed corresponds addingarcs original search graph.8. Summary Future Workpresented FRIT, search algorithm follows path treethe ideal treerepresents family solutions graph currently known agent.algorithm simple describe implement, need update heuristicguarantee termination. FRIT uses secondary search algorithm search stateideal tree agent becomes disconnected it. show that, slightmodifications, real-time search algorithm search reconnection, obtainreal-time version FRIT, FRITRT . addition, propose different way using FRITapplications use real-time search feeding bounded, complete searchalgorithms.provide theoretical results proving FRIT FRITRT always find solutionsexist. Furthermore, give explicit bounds length obtained solutions.Finally, prove algorithms converge two trial runs.260fiReconnection Ideal Tree: New Approach Real-Time Searchexperiments show proposed algorithms return solutions fasterstate-of-the-art real-time search algorithms. particular FRIT(daRTAA*) substantiallyimproves performance daRTAA*, state-of-the-art Real-Time Search algorithm. Largerperformance improvements observed time constraints tighter. Additionally,compare approaches show FRIT(BFS)that is, FRIT fedbreadth first search algorithmproduces similar better results tight time constraints.comparison pathfinding-specific Bug2 algorithm, concludedlittle time per search episode given Bug2 delivers best-quality solutions, followedFRIT(BFS), eventually, significantly time available, followed state-ofthe-art incremental search algorithms.disadvantage approach, note FRIT cannot exploit computational time algorithms do. Indeed, incremental heuristic search algorithmsreturn better quality solutions allowed large time constraints, FRIT generally converge asymptotically optimal path given arbitrary time.left scope paper FRIT could used generalsearch spaces like ones described using planning language like STRIPS(Fikes & Nilsson, 1971) PDDL (McDermott, 1998). planning domains, search graphsimplicitly defined actions defined terms preconditions effects. Computingideal trees using Dijkstras algorithm, suggested above, simple since requiresgeneration number states exponential size problem description.Moreover, immediately obvious either build ideal tree standarddomain-independent heuristic, done pathfinding. Indeed, existdomain-independent planning heuristics admissible (e.g., Haslum & Geffner, 2000),easy show correspond perfect heuristic spanning supergraph original search space, implies possible use directlyconstruct ideal tree, loops may easily formed. Therefore, investigationneeded order adapt techniques presented planning applications.AcknowledgmentsNicolas Rivera, Leon Illanes, Jorge Baier partly funded Fondecyt ProjectNumber 11110321. thank anonymous JAIR reviewers, valuable input,SoCS2013 reviewers comments earlier version paper.ReferencesBjornsson, Y., Bulitko, V., & Sturtevant, N. R. (2009). TBA*: Time-bounded A*. Proc.21st Intl Joint Conf. Artificial Intelligence (IJCAI), pp. 431436.Bond, D. M., Widger, N. A., Ruml, W., & Sun, X. (2010). Real-time search dynamicworlds. Proc. 3rd Symposium Combinatorial Search (SoCS), Atlanta,Georgia.Bonet, B., & Geffner, H. (2011). Planning partial observability classical replanning: Theory experiments. Proc. 22nd Intl Joint Conf. ArtificialIntelligence (IJCAI), pp. 19361941, Barcelona, Spain.261fiRivera, Illanes, Baier, & HernandezBotea, A. (2011). Ultra-fast Optimal Pathfinding without Runtime Search. Proc.7th Annual Intl AIIDE Conference (AIIDE), Palo Alto, California.Bulitko, V., & Lee, G. (2006). Learning real time search: unifying framework. JournalArtificial Intelligence Research, 25, 119157.Bulitko, V., Bjornsson, Y., & Lawrence, R. (2010). Case-based subgoaling real-timeheuristic search video game pathfinding. Journal Artificial Intelligence Research,38, 268300.Bulitko, V., Bjornsson, Y., Lustrek, M., Schaeffer, J., & Sigmundarson, S. (2007). Dynamiccontrol path-planning real-time heuristic search. Proc. 17th IntlConf. Automated Planning Scheduling (ICAPS), pp. 4956.Bulitko, V., Bjornsson, Y., Sturtevant, N., & Lawrence, R. (2011). Real-time HeuristicSearch Game Pathfinding, pp. 130. Applied Research Artificial IntelligenceComputer Games. Springer Verlag.Edelkamp, S., & Schrodl, S. (2011). Heuristic Search: Theory Applications. MorganKaufmann.Fikes, R., & Nilsson, N. J. (1971). STRIPS: new approach application theoremproving problem solving. Artificial Intelligence, 2 (3/4), 189208.Hart, P. E., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determinationminimal cost paths. IEEE Transactions Systems Science Cybernetics, 4 (2),100107.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proc.5th Intl Conf. Artificial Intelligence Planning Systems (AIPS), pp. 140149.Hernandez, C., & Baier, J. A. (2011). Fast subgoaling pathfinding via real-time search.Proc. 21th Intl Conf. Automated Planning Scheduling (ICAPS),Freiburg, Germany.Hernandez, C., & Baier, J. A. (2012). Avoiding escaping depressions real-timeheuristic search. Journal Artificial Intelligence Research, 43, 523570.Hernandez, C., Baier, J. A., Uras, T., & Koenig, S. (2012a). Position paper: Incrementalsearch algorithms considered poorly understood. Proc. 5th SymposiumCombinatorial Search (SoCS).Hernandez, C., Baier, J. A., Uras, T., & Koenig, S. (2012b). TBAA*: Time-BoundedAdaptive A*. Proc. 10th Intl Joint Conf. Autonomous Agents MultiAgent Systems (AAMAS).Hernandez, C., Sun, X., Koenig, S., & Meseguer, P. (2011). Tree adaptive A*. Proc.10th Intl Joint Conf. Autonomous Agents Multi Agent Systems (AAMAS),Taipei, Taiwan.Ishida, T. (1992). Moving target search intelligence. Proc. 10th NationalConf. Artificial Intelligence (AAAI), pp. 525532.Koenig, S. (2001). Agent-centered search. Artificial Intelligence Magazine, 22 (4), 109131.262fiReconnection Ideal Tree: New Approach Real-Time SearchKoenig, S., & Likhachev, M. (2002). D* lite. Proc. 18th National Conf. ArtificialIntelligence (AAAI), pp. 476483.Koenig, S., & Likhachev, M. (2005). Adaptive A*. Proc. 4th Intl Joint Conf.Autonomous Agents Multi Agent Systems (AAMAS), pp. 13111312.Koenig, S., & Likhachev, M. (2006). Real-time Adaptive A*. Proc. 5th Intl JointConf. Autonomous Agents Multi Agent Systems (AAMAS), pp. 281288.Koenig, S., & Sun, X. (2009). Comparing real-time incremental heuristic searchreal-time situated agents. Autonomous Agents Multi-Agent Systems, 18 (3), 313341.Korf, R. E. (1990). Real-time heuristic search. Artificial Intelligence, 42 (2-3), 189211.LaValle, S. M. (2006). Planning algorithms. Cambridge University Press.Lawrence, R., & Bulitko, V. (2010). Taking learning real-time heuristic searchvideo-game pathfinding. Australasian Conf. Artificial Intelligence, pp. 405414.Lumelsky, V. J., & Stepanov, A. A. (1987). Path-planning strategies point mobileautomaton moving amidst unknown obstacles arbitrary shape. Algorithmica, 2,403430.McDermott, D. V. (1998). PDDL Planning Domain Definition Language. Tech.rep. TR-98-003/DCS TR-1165, Yale Center Computational Vision Control.Pohl, I. (1971). Bi-directional heuristic search. Machine Intelligence 6, pp. 127140.Edinburgh University Press, Edinburgh, Scotland.Rao, N. S., Kareti, S., Shi, W., & Iyengar, S. S. (1993). Robot navigation unknown terrains: Introductory survey non-heuristic algorithms. Tech. rep. ORNL-TM-12410,Oak Ridge National Laboratory.Rivera, N., Baier, J. A., & Hernandez, C. (2013a). Weighted real-time heuristic search.Proc. 11th Intl Joint Conf. Autonomous Agents Multi Agent Systems(AAMAS).Rivera, N., Illanes, L., Baier, J. A., & Hernandez, C. (2013b). Reconnecting idealtree: alternative heuristic learning real-time search. Proceedings 6thSymposium Combinatorial Search (SoCS).Sharon, G., Sturtevant, N., & Felner, A. (2013). Online detection dead states realtime agent-centered search. Proc. 6th Symposium Combinatorial Search(SoCS), Leavenworth, WA, USA.Sturtevant, N. R. (2012). Benchmarks grid-based pathfinding. IEEE TransactionsComputational Intelligence AI Games, 4 (2), 144148.Sturtevant, N. R., & Bulitko, V. (2011). Learning going whencecame: h- g-cost learning real-time heuristic search. Proc. 22ndIntl Joint Conf. Artificial Intelligence (IJCAI), pp. 365370, Barcelona, Spain.Taylor, K., & LaValle, S. M. (2009). I-bug: intensity-based bug algorithm. Proc.2009 IEEE Intl Conf. Robotics Automation (ICRA), pp. 39813986.263fiRivera, Illanes, Baier, & HernandezZelinsky, A. (1992). mobile robot exploration algorithm. IEEE Transactions RoboticsAutomation, 8 (6), 707717.264fiJournal Artificial Intelligence Research 50 (2014) 487-533Submitted 12/13; published 06/14Improving Delete Relaxation Heuristics ExplicitlyRepresented ConjunctionsEmil Keyderemilkeyder@gmail.comJorg Hoffmannhoffmann@cs.uni-saarland.deSaarland University66123 Saarbrucken, GermanyPatrik Haslumpatrik.haslum@anu.edu.auAustralian National University & NICTACanberra ACT 0200, AustraliaAbstractHeuristic functions based delete relaxation compute upper lower boundsoptimal delete-relaxation heuristic h+ , paramount importanceoptimal satisficing planning. introduce principled flexible techniqueimproving h+ , augmenting delete-relaxed planning tasks limited amountdelete information. done introducing special fluents explicitly representconjunctions fluents original planning task, rendering h+ perfect heuristic hlimit. Previous work introduced method growth taskpotentially exponential number conjunctions introduced. formulate alternative technique relying conditional effects, limiting growth task linearnumber. show method still renders h+ perfect heuristic hlimit. propose techniques find informative set conjunctions introduceddifferent settings, analyze extend existing methods lower-bounding upperbounding h+ presence conditional effects. evaluate resulting heuristicfunctions empirically set IPC benchmarks, show sometimes muchinformative standard delete-relaxation heuristics.1. IntroductionPlanning heuristic search one successful approaches planning.informative heuristic functions domain-independent planning obtainedestimated cost delete relaxation original planning task. deleterelaxation simplifies planning tasks assuming every variable value, achieved,persists execution rest plan. cost optimal planresulting relaxed planning task, denoted h+ , NP-complete compute, however whetherplan delete-relaxed task exists checked polynomial time (Bylander,1994). satisficing planning, heuristic admissible,latter fact exploited upper-bound h+ , generating necessarily optimalplan delete-relaxed task (Hoffmann & Nebel, 2001). optimal planning, lowerbounding methods devised based analysis landmarks, logical formulasset actions state necessary properties delete-relaxed plans (Karpas &c2014AI Access Foundation. rights reserved.fiKeyder, Hoffmann, & HaslumDomshlak, 2009; Helmert & Domshlak, 2009). cost estimates delete-relaxedtask used guide heuristic search state space original task.Since delete relaxation heuristics first proposed (Bonet & Geffner, 2001), muchwork done improve them. One approach focuses better approximationschemes h+ , obtaining tighter upper bounds thus better non-admissible estimates(Hoffmann & Nebel, 2001; Keyder & Geffner, 2008, 2009), tighter lower boundscorrespond informative admissible heuristics (Helmert & Domshlak, 2009; Bonet& Helmert, 2010). many domains, however, important heuristic abletake account delete information (Hoffmann, 2005), indeed long traditionworks proposing heuristics so. Several extend delete relaxationcapture strictly information (Fox & Long, 2001; Helmert, 2006; Helmert & Geffner,2008; Cai, Hoffmann, & Helmert, 2009; Katz, Hoffmann, & Domshlak, 2013),consider delete relaxation attempt find low-conflict relaxed plans (Baier &Botea, 2009), generate modified heuristic values based taking conflicts accountextent (Do & Kambhampati, 2001; Gerevini, Saetti, & Serina, 2003). Here,approach problem taking inspiration admissible hm family heuristics(Haslum & Geffner, 2000). important property heuristics introduce, sharedrecent work direction, technique renders h+ perfectheuristic h limit. words, technique offers trade-off amountdelete information considered computational overhead so. one endcontinuum, delete-relaxed plans become plans original task.hm heuristic function considers cost making true simultaneously sets fluentssize m. cost planning task estimated recursively taking costset fluents, goal set action preconditions, costcostly subset size m, ignoring cost achieving remaining fluentsset. possible subset size fluents task must considered,size representation required compute hm exponential m. hm heuristicsprovide guarantee exists hm = h (trivially satisfiedtotal number fluents task). However, value required achieveusually large make computing h method infeasible practice.hm heuristic recently recast hmax = h1 cost planning taskdeletes (Haslum, 2009). achieved representing conjunctions fluents csize original task new fluents c , called -fluents, modifyinginitial state, goal, operators planning task capture reasoningperformed hm sets within computation hmax . However, h+ (m )admissible (since separate copy action may needed establish-fluent), thus compilation useful obtaining admissible estimatesinformative h+ . recent C construction (Haslum, 2012) fixesissue (introducing action copy every subset -fluents may established),cost growing task representation exponentially number -fluents ratherlinearly representation. hand, C offers possibilityfine-grained tradeoff representation size heuristic accuracy, allowingchoice arbitrary set conjunctions C corresponding -fluents (which needsize). stands contrast hm heuristic compilation,sets conjunctions size represented.488fiImproving Delete Relaxation Heuristics Explicit ConjunctionsHaslum (2012) proposed repeatedly solve C optimally, within iterative procedureadds new conjunctions set C iteration. relaxed planscomputed therefore gradually become closer, sense, plans originaltask. instead explore idea using kind construction obtaining heuristicfunctions guiding search.Cintroduce related construction Cce similar , makes useconditional effects limit growth task worst case linear, ratherexponential, |C|. gain size comes price information loss relativeC . However, show, information loss affect fundamental propertytending towards perfect heuristic h enough conjunctions introduced: LikeC , Cce perfect limit, i. e. always exists set conjunctions Ch+ (Cce ) = h . Furthermore, information may lost, always case.Indeed, possible construct families planning tasks Cce represent+Cheuristic function C set conjunctions C, i. e., h+ (Cce ) = h ( ),Crepresentation ce occupies exponentially less space.said that, theoretical advantage Cce tend materialize practice(or least commonly used benchmarks): without optimizations Cindeed grows quickly practical, turns mutex pruning techniques (eliminating compiled actions conflicting preconditions) extremely effective keepingCsize C bay. therefore consider Cce , evaluating usefulnessdevising improved heuristic functions. focus two main questions:(A) obtain upper lower bounds h+ compiled tasks?(B) choose set conjunctions C maximize information gainedaddition planning task?response question (A), analyze extend three state-of-the-art methodsestimating h+ . satisficing setting (upper-bounding h+ ), consider problemfinding low-cost relaxed plans scheduled minimize costsequence actions required trigger given set conditional effects, avoiding unnecessaryrepeated applications action. problem scantily addressedprevious work. show problem optimal action scheduling givenset effects NP-complete, generalize approximation technique used FFplanner (Hoffmann & Nebel, 2001).optimal setting (lower-bounding h+ ), consider LM-cut heuristic (Helmert& Domshlak, 2009) well admissible heuristics based fluent landmarks (Karpas& Domshlak, 2009). former, findings mostly negative: First, showeven though introduction -fluents cannot decrease hmax h+ , lowerand upper-bound LM-cut, respectively, LM-cut heuristic value decrease. Second,show neither two straightforward adaptations LM-cut algorithmproblems conditional effects maintains admissibility domination hmax .1latter, show Cce used generate informative fluent landmarks.Recent work (Keyder, Richter, & Helmert, 2010) extracts landmarks task.1. sophisticated adaptation LM-cut, based idea context splitting, recentlyproposed ? (?). maintains properties.489fiKeyder, Hoffmann, & Haslumallows discovery -fluent landmarks corresponding conjunctive landmarksoriginal task, suffers due large number -fluents must considered.Cce compilation offers possibility discovering interesting conjunctive landmarksunbounded size, avoiding growing size compilation unnecessarily.response question (B), devise range strategies depending purposeCCce compilation used. parameterized termsallowed growth compiled task relative original task, thus allowtrade-off informativeness heuristic computational overhead.evaluate resulting heuristics wide range benchmarks International Planning Competition, varying relevant algorithm parameters determine individualeffect performance. results show, several domains heuristics muchinformative previous ones, leading significantly improved performance.next define basic concepts (Section 2), moving formal definitionCCce compilation previously introduced compilations (Section 3).CCSection 4, analyze ce relation theoretical perspective.Section 5 discusses practical issues arise using compilations purposesatisficing planning, describes obtained experimental results, Section 6case optimal planning. Finally, Section 7 summarizes main pointspaper indicates possible future research directions.2. Preliminariesplanning model based propositional STRIPS formalization, addaction costs conditional effects. States operators defined terms set Fpropositional variables, fluents. state F given set fluentstrue state. planning task described 4-tuple = hF, A, I, Gi, Fset variables, set actions, F initial state, G Fdescribes set goal states, given {s | G s}. action consists4-tuple hpre(a), add(a), del(a), ce(a)i, pre(a), add(a), del(a) subsets F .action cost cost(a) R+0 . ce(a) = {ce(a)1 , . . . , ce(a)n }, denote setconditional effects action a, triple hc(a)i , add(a)i , del(a)i subsetsF . simplify notations, require add(a) del(a) = ; needimpose restrictions deletes del(a)i conditional effects, conditionaleffects used within delete relaxation. ce(a) = A,conditional effects, say STRIPS planning task.action applicable pre(a) s. result applying given[[s[a] = (s \ (del(a)del(a)i )) (add(a)add(a)i ){i|c(a)i s}{i|c(a)i s}plan sequencePn actions = a1 , . . . , whose application results goalstate. cost i=1 cost(ai ). optimal cost minimal among planss; often denote optimal plans . plan also called plan ,simply plan.heuristic function h mapping states R+0 . perfect heuristich maps state cost optimal plan s. heuristic h admissible490fiImproving Delete Relaxation Heuristics Explicit Conjunctionsh(s) h (s) s. h(0 ), denote heuristic function whose valuegiven estimating cost corresponding state s0 modified task 0 . specify0 terms transformation = hF, A, I, Gi 0 = hF 0 , A0 , 0 , G0 i; s0 obtainedapplying transformation used obtain 0 I. sometimes usefulmake explicit h heuristic computed itself; denote h().Note modified task 0 used computation heuristic function.particular, actual search plan performed state space originalplanning task .delete relaxation + planning task obtained discarding deleteeffects. Formally, + = hF, A+ , I, Gi, A+ = {hpre(a), add(a), , ce+ (a)i | A},ce+ (a) = {hc(a)i , add(a)i , | ce(a)i ce(a)}. cost action a+ A+cost corresponding action cost(a). optimal delete relaxation heuristic h+defined cost h (+ ) optimal plan + .denote power set F P(F ) = {c | c F }. context hm ,C, Cce , refer fluent subsets c P(F ) sets conjunctions interchangeably.Throughout paper, assume conjunctions non-unit, i. e., |c| > 1.landmark planning task logical formula set fluents Fevery valid plan makes true state (Hoffmann, Porteous, & Sebastia, 2004).Orderings landmarks statements order states occur.natural ordering 1 n 2 means state sj satisfies 2 , state sioccurring sj 1 satisfied. necessary ordering 1 nec 2 means 1always true state immediately state 2 becomes true,greedy necessary ordering 1 gn 2 means relationship holds first time2 made true. Note necessary ordering 1 nec 2 implies greedy necessaryordering 1 gn 2 , vice versa. landmark graph G directed graph whosenodes landmarks, whose labelled edges correspond known orderingslandmarks.3. , C Cce Compilationscompilation (Haslum, 2009) first technique proposed made useidea -fluents explicitly represent conjunctions original task. Givenconjunction c F , c new fluent c 6 F unique c, i. e., c 6= c0 c 6= c0 .defining compilations discuss, use shorthand X C =X {c | c C c X}, X F set fluents, C P(F ) setconjunctions. words, X C consists set fluents X itself, together newfluents c whose intention represent conjunctions c C contained X,c X.Definition 1 (The compilation) Given STRIPS planning task = hF, A, I, Giparameter Z+ , planning task hF C , AC , C , GC i, C = {c | cF 1 < |c| m}, AC contains well action ac pair A, c Cdel(a) c = add(a) c 6= , ac given del(ac ) = , ce(ac ) = ,pre(ac ) = (pre(a) (c \ add(a)))Cadd(ac ) = add(a) {c0 | c0 C c0 (add(a) c)}491fiKeyder, Hoffmann, & Haslumparameter indicates maximum size conjunctions representedexplicitly resulting compiled task. -fluent inserted (by definition F C , cf.above) c F 1 < |c| m. c added fluent setstask (such initial state, action preconditions, goals) containing associatedset c. Furthermore, linear (in |C|) number representatives action addedtask model situation elements c made truealready true applied, adds remaining fluents c deletingnone them, thereby making every fluent c, therefore c , true. compilationallows admissible hm cost original task computed hmax costcompiled task.non-admissibility h (m ) = h+ (m ) due construction action representatives ac : Sets fluents simultaneously made true single applicationaction may require several representatives explicitly achieveeffect . Consider example action adding fluent p state qr already true. makes fluents p, q, r true simultaneously, whereas2 , two different representatives required: one c = {p, q} adding {p,q} ,one c = {p, r} adding {p,r} .C compilation solves problem instead creating number representatives exponential number -fluents may made true a.representatives corresponds application makes set -fluentstrue (Haslum, 2012). Following example, separate representatives wouldintroduced -fluent sets , {{p,q} }, {{p,r} }, {{p,q} , {p,r} },representative resulting last could applied make two -fluentstrue simultaneously. C also differs allows choice set C P(F ),introduces fluents c c C, rather subsets sizem:2Definition 2 (The C compilation) Given STRIPS planning task = hF, A, I, Giset non-unit conjunctions C P(F ), C planning task hF C , AC , C , GC i,0AC contains action aC pair A, C 0 C c0 C 0 ,(1) del(a) c0 = add(a) c0 6= ,(2) c C((c c0 add(a) c 6= ) = c C 0 ),000aC given del(aC ) = , ce(aC ) = ,[0pre(aC ) = (pre(a)(c0 \ add(a)))Cc0 C 0C0add(a ) = (add(a) (pre(a) \ del(a)))C {c0 | c0 C 0 }2. three differences definition Haslums (2012) definition actionsC . First, Haslums definition features delete effects, ensuring real (non-relaxed) plans correspondplans original task. Since consider delete relaxations compiled task, safelyomit these. Second, allow sets C 0 used construction actions contain conjunctions c0c add(a) (pre(a) \ del(a)); third, add(aC ) contains -fluents c c pre(a) \ del(a).latter two differences keep definitions simpler. redundant action representativesredundant add effects cause easily pruned practice.492fiImproving Delete Relaxation Heuristics Explicit Conjunctions0representatives aC enforce, every c0 C 0 , part c0 deleted,0non-added part c0 true already aC executed. Constraint (2)0ensures form non-redundancy: aC adds -fluent c0 , also adds -fluentsc c c0 , fluents c necessarily become true applicationaction. Note that, differently , add effects C include -fluents representingconjunctions fluents added action prevail fluents (non-deleted preconditions).necessary admissibility h+ (the primary purpose C ), neededcomputation h1 (the primary purpose ).C enumerates possible subsets C constructing representativesaction therefore grows exponentially |C|. exponentiality reminiscentcanonical conditional effects compilation used convert planning tasks conditionaleffects classical STRIPS planning tasks exponentially actions (Gazen &Knoblock, 1997). Cce compilation introduce result applyingroughly reverse transformation C , resulting closely related planning tasklinear (in |C|) number conditional effects:Definition 3 (The Cce compilation) Given STRIPS planning task = hF, A, I, GiCCCCset non-unit conjunctions C P(F ), Cce planning task hF , Ace , , GCCCCACce = {hpre(a ), add(a ), del(a ), ce(a )i | A},aC givenpre(aC ) = pre(a)Cadd(aC ) = (add(a) (pre(a) \ del(a)))Cdel(aC ) =ce(aC ) = {h(pre(a) (c \ add(a)))C , {c },| c C c del(a) = c add(a) 6= }Rather enumerating sets -fluents may made true action, Cceuses conditional effects implicitly describe conditions made true.information lost information encoded cross-context -fluentspreconditions, appear action representatives C , preconditionsC 0effect conditions corresponding actions Cce . action representatives0C , -fluents pre(aC ) exists c C 0 s.t. (c \ add(a))pre(a). situation discussed above, example, {q,r} precondition actionrepresentative adds {p,q} {p,r} C , appear conditionconditional effects corresponding action Cce . Since effect conditionsdetermined individually c , conditions never included. returndiscussing theoretical relationship C Cce .Example 1 Consider STRIPS planning task (adapted Helmert & Geffner, 2008)variables {x0 , . . . , xn , y}, initial state = {x0 , y}, goal G = {xn }, unit-cost actions: h, {y}, ,bi : h{xi , y}, {xi+1 }, {y},493fiKeyder, Hoffmann, & Haslum= 0, . . . , n 1.optimal solution planning task takes form b0 , a, b1 , a, . . . , bn1 ,cost 2n1. delete relaxation task, fact deleted applicationbi ignored, optimal plan cost n.-fluent xi ,y introduced Cce compilation, added preconditionaction bi , new conditional effects ce(a)i form h{xi }, {{xi ,y} }, createdaction a. conditional effects added b-actions, deletestherefore cannot achiever -fluent. increases optimal delete relaxationcost task 1, new instance must added relaxed plan achievenewly introduced precondition bi . -fluents form {xi ,y} introduced,delete relaxation cost Cce becomes 2n 1, optimal cost.set conjunctions renders delete relaxation cost C perfect (i. e.,2n 1). However, size C given conjunction set exponential n: actionmay principle achieve subset conjunctions, every subset C 0 induces0separate representative aC AC .Regarding compilation, h2 = hmax (2 ) also gives optimal cost task.However, computation requires consideration (n2 ) fluent pairs, ratherlinear number -fluents need introduced Cce . shall see (Theorem 6), example easily extended must scale n hm becomeCperfect, thus showing exponential separation Cce .important practical optimization C Cce mutex pruning. mutexinformation original planning task available, specifically given (some)m-tuples fluents reachable conjunction, discardcompiled task action representatives conditional effects requirem-tuple, without losing admissibility compilation. Namely, value h+ (C )(respectively h+ (Cce )) mutex pruning bounded value000h+ (C ) (respectively h+ (Cce )) larger set C C conjunctions: include-fluents size m, h mutexes found, i. e., none respective fluents reachable compiled task. Exploiting available mutex information allows usmake compilation informed without add additional -fluents,helping keep compilation small.Another optimization use eliminate dominated preconditions. Whenever addfluent c precondition action, condition conditional effect,remove condition fluents p c -fluents {c0 | c0 c}.achieving c implies achieving fluents well, methods count costseparately (such as, example, hadd related heuristics) would incur overestimation.Note, however, eliminate duplication caused -fluents representing different fluent sets non-empty intersection. Consider, example,action pre(a) = {p, q, r}. C = {{p, q}, {q, r}}, pre(a) = {{p,q} , {q,r} },cost achieving q implicitly counted twice hadd estimate costapplying a. possible solution, considered replacing overlapping -fluents c , c0cc0 . This, however, consistently improve heuristics computecompiled tasks.494fiImproving Delete Relaxation Heuristics Explicit Conjunctions4. Theoretical Properties Cce+Cdiscuss theoretical properties Cce , considering cost h (ce )optimal solutions instead practical approximations (note Cce versionC considered here, h+ = h delete effects present). proof sketchesshown, full proofs found Appendix A. first show fundamentalexpected property:Theorem 1 (Consistency admissibility) h+ (Cce ) consistent admissible.Proof: Regarding consistency, given s, s[a] = s0 , need show+C00C0C C .h+ (Cce )(s) cost(a) + h (ce )(s ). Let (s ) optimal plance0C sC [aC ] C taskaC (s0C ) necessarily plan sC Cce ,cedeletes. Admissibility follows consistency together fact h+ (Cce )(s) = 0goal states s.Furthermore, (ideal) delete relaxation lower bound improve add -fluents:Theorem 2 (h+ (Cce ) grows monotonically C) Given planning task sets0+C0C C non-unit conjunctions, h+ (Cce ) h (ce ).CC0Proof: follows fact given plan = aC1 , . . . , an0 for0 ce , 0 =000CCCCCCa1 , . . . , constitutes plan ce . show induction [a1 ] . . . [ai ]C0C0C0 =C [aC1 ] . . . [ai ] \ {c | c C \ C }, shows result since goal ce GGC \ {c | c C \ C 0 }, GC sC [] valid plan.0= 0, induction hypothesis holds since C = C \ {c | c C \ C 0 } definition.0000CCCC0C0> 0, aCapplicable [a1 ] . . . [ai1 ] since pre(ai ) = pre(ai ) \ {c | c C \ C },000C0CC CC [aC1 ] . . . [ai1 ] [a1 ] . . . [ai ] \ {c | c C \ C } induction hypothesis.CCCCCC{c | c (I [a1 ] . . . [ai ] \ [a1 ] . . . [ai1 ]) c C 0 }, either c add(ai )C ,0C0implies c add(aC) due definition ce , exists conditional effectC0cej (aC) = h(pre(a) (c \0 add(a))) , {c }, i. Since c C , must exist 0corresponding0CC0conditional effect ce definition, condition must true C [aC1 ] . . . [ai1 ]induction hypothesis.special case C 0 = , Theorem 2 gives us:+Corollary 1 (h+ (Cce ) dominates h ()) Given planning task set non-unit+C+conjunctions C, h (ce ) h ().domination strict, follows trivially convergence h (Theorem 5 below).consider relationship C Cce compilations. mentionedabove, information encoded cross-context preconditions lost movingCexponential C linear Cce . Estimates obtained ce may therefore inferiorobtained C :Theorem 3 (h+ (C ) dominates h+ (Cce )) Given planning task set nonunit conjunctions C, h+ (C ) h+ (C).cases inequality strict.ce495fiKeyder, Hoffmann, & HaslumProof sketch: standard conditional effects compilation STRIPS (Gazen & Knoblock,C1997), applied Cce , equivalent except presence cross-context preconditions C . Given this, plan C also plan Cce , yet inverseC CC1n,.. . , aCcase. show first part, show induction C [aCn ] [a1 , . . . , ]ce ,1I[. . . ]ce denotes result applying sequence actions initial state CCCce . Since goal tasks defined G , shows desired result.strictness result follows fact possible construct taskscross-context preconditions discussed play role, leading situationsCexist plans Cce shorter minimum-length plans .proof strictness (Appendix A), show planning task h+ (C )value strictly larger h+ (Cce ) value C chosen conjunctionssize 2. implies exist tasks necessary consider strictlylarger conjunctions Cce obtain equally good heuristic estimates obtainedCC . necessarily problematic however, differently hm , Cceintroduce conjunctions given size, therefore exponential maximumsize conjunctions considered.Cadvantage Cce potentially exponentially smaller |C|;domination therefore must qualified reduction size. Furthermore,Cce preserves ability compute perfect heuristic given sufficiently large set Cconjunctions. first consider equivalent result C , already proved Haslum(2012). provide alternative proof conveniently adapted showCproperty Cce . key proof following equivalenceh1 (m ) h1 (C ):Lemma 1 Given planning task , C = {c P(F ) | 1 < |c| m}, h1 (m ) = h1 (C ).Proof sketch: C identical except action sets. h1 values computedconsidering single add effect time. inequality h1 (m ) h1 (C )0easy see verifying that, every add effect c action aC C (unless0c pre(aC ) thus redundant), action ac dominates it, i. e., c add(ac )0pre(ac ) pre(aC ). proof similar inequality h1 (C ) h1 (m ), observingaction ac non-redundant add effect, exists dominating action0aC C .Theorem 4 (h+ (C ) perfect limit) Given planning task , exists Ch+ (C ) = h ().Proof: known h () = hm () sufficiently high values (Haslum &Geffner, 2000), shown Haslum (2009), hm () = h1 (m ). Lemma 1,C = {c P(F ) | 1 < |c| m}, h1 (m ) = h1 (C ). Choosing appropriatecorresponding C, thus h () = hm () = h1 (m ) = h1 (C ).Together fact h1 (C ) h+ (C ), since h+ (C ) h () admissibilityh+ (C ), claim follows.1C+Cshow claim Cce , remains relate h ( ) h (ce ):496fiImproving Delete Relaxation Heuristics Explicit ConjunctionsLemma 2 Given planning task set non-unit conjunctions C, h1 (C )h+ (Cce ).CProof sketch: Consider planning task Cno-cc identical except drops cross1context -fluents preconditions. show (A) h (C ) h1 (Cno-cc ), (B)1C+Ch (no-cc ) h (ce ).Similarly proof Lemma 1, (A) easy see showing every add effect0C 00 C : simply set C 00c action aC Cno-cc dominated actionminimal subset C 0 contains c satisfies condition (2) Definition 2 (inwords, reduce C 0 get rid cross-context -fluents).+C(B), suffices show h+ (Cno-cc ) h (ce ). holds because, actionC0relaxed plan ce , C set conjunctions added conditional0effects applied plan, action representative aC Cno-ccpreconditions a, used achieve set fluents.Theorem 5 (h+ (Cce ) perfect limit) Given planning task , exists Ch+ (C)=h ().ceProof: Choosing appropriate C, h () = hm () = h1 (m ), and,Lemma 1, h1 (m ) = h1 (C ). Lemma 2, get h1 (C ) h+ (Cce ). Since,(), shows claim.Theorem 1, h+ (C)hceNote that, Theorem 3, Theorem 4 actually corollary Theorem 5. presentation chosen make relation two results, role two lemmas,clearer.proofs Theorems 4 5 rely obtaining perfect hm , clearly unfeasiblegeneral since involves enumerating subsets fluents (and hence possible states)worst case. However, C Cce offer flexibility allowing us choose setC: selecting subsets guarantees perfect heuristic, may achievedmuch less effort, especially beneficial using Cce whose growth |C| linear.Indeed, task families obtaining h takes exponential effort hm ,requires exponentially-sized C , yet Cce remains small:C ) exist parameterized taskTheorem 6 (Expressive power Cce vs. hfamilies k1. hm (k ) = h (k ) k,C2. h+ (Ck ) = h (k ) implies number action representatives k exponential k,3. k exists Ck |Ck | (and therefore number conditional effects+C(k )Cce ) polynomial k, (b) h ((k )ce ) = h (k ).Proof: Members one family given combination k planning taskstype shown Example 1, size k, share among actionfluent needs made true step. k k goals, hm = h iffk.497fiKeyder, Hoffmann, & HaslumCCk (k )ce perfect, k -fluents {xi1 , y}, . . . , {xik , y} must introduced individual subtasks i, leading total k 2 -fluents. one-fluents present, precondition action bij (k )Cce , similarlyrepresentative C 0 = {} C,individualfluentpreconditionsy, xij ,kconsequence one actions reestablishing left plan.number conditional effects created (k )Cce linear number -fluents added.However, number action representatives (k )C exponential k: actionadds fluent y, belongs -fluents, hence one representativesubset -fluents.using h+ (Cce ) practice, typically able choose C resultsperfect heuristic. Instead, try pick set C yields informative heuristicwithout making size representation impractical work with.5. Heuristics Satisficing Planningconsider practical issues involved using Cce satisficing planning. Section 5.1 deals extraction relaxed plans, Section 5.2 deals strategieschoosing set conjunctions C. Section 5.3 presents experiments resultingsetup.5.1 Relaxed Planning Conditional EffectsTechniques extracting relaxed plans presence conditional effects longknown (Hoffmann & Nebel, 2001). Here, refine extend techniques.particularly important context as, unlike IPC benchmarks, structureconditional effects Cce rather complex, involving multiple dependenciesdifferent actions, even different executions action.3Non-admissible delete-relaxation heuristics typically obtained relaxed planextraction algorithm (Keyder & Geffner, 2008). different variants algorithmcharacterized best-supporter function bs : F 7 use. cases, bs(p)action adding p minimizes estimate cost making p true.conditional effects present, algorithms compute set actionsscheduled form relaxed plan planning task. Formally, algorithms constructrelaxed plan according following equations (Keyder & Geffner, 2008):({}p(p) =bs(p) (pre(bs(p))) otherwise[(P ) =(p)pPExisting methods choosing best supporters, hadd hmax , easilyextended conditional effects treating conditional effect task separate3. remark similar issues arise approaches compiling uncertainty classical planningconditional effects (Palacios & Geffner, 2009; Bonet, Palacios, & Geffner, 2009), techniques mayturn useful well.498fiImproving Delete Relaxation Heuristics Explicit Conjunctionsaction. particular, method employed, using hmax , compute FF heuristicfunction (Hoffmann & Nebel, 2001). precisely, relaxed conditional effectce(a)+condition c(a)i add add(a)i , action ai add effect add(ai ) =add(a) add(a)i precondition pre(ai ) = pre(a) c(a)i created. set effects (G)defined rules forms relaxed plan. presence conditional effects,however, implies problem schedule relaxed plan: differentschedules may require different numbers action applications, multiple applicationssingle action avoided making conditions multiple desired effects truegiven application a.illustration, consider planning task action move-briefcase n conditional effects, conditionally transports object location locationB inside briefcase. Using representation above, distinct moving actiongenerated conditional effect. one possible schedule relaxed plan repeatedlyputs object briefcase, applies move-briefcase, proceeds next object.plan n 1 steps longer optimal relaxed plan, first placesobjects briefcase applies move-briefcase once.words, single action execution may trigger several conditional effectsonce, may exist relaxed plan length less |(G)|. question arisesoptimally schedule relaxed plan, minimizing number action applicationsrequired. FF uses simple approximate solution problem, outlineimprove upon below. first note problem scheduling conditional relaxedplans (SCRP) actually NP-complete:Theorem 7 (Scheduling conditional relaxed plans) Let + relaxed planning taskconditional effects (G) set effects that, viewed set independent actions,constitutes plan + . Deciding whether exists sequence actions length kconditional effects (G) triggered NP-complete.Proof: Membership follows fact given sequence k actions, easilychecked polynomial time whether conditional effects (G) triggered. Hardnessfollows reduction shortest common supersequence problem (SCS) (Garey &Johnson, 1979). supersequence string x = d0 . . . dm alphabet stringalphabet belongs language L = d0 . . . dm . Giveninstance SCS problem strings x0 , . . . , xn alphabet {0, 1} askswhether exists supersequence strings length k, constructplanning task conditional effects = hF, A, I, Gi,F = ni=0 {yij | 0 j |xi |}= {a0 , a1 }, az = {, , , ce(az )}, ce(az ) given set conditionaleffectsn |x[|1[{hyij , yij+1 , | xij = z}i=0 j=0= {y00 , . . . , yn0 }G = {y0|x0 | , . . . , yn|xn | }499fiKeyder, Hoffmann, & Haslumtwo actions a0 a1 correspond addition symbols 0 1 respectivelysupersequence implicitly constructed, fluent yij encodes factcurrent string constitutes supersequence prefix xi0 , . . . , xij1 .seen valid plan planning task must trigger conditional effectstask, yet sequence actions length k exists iff commonsupersequence x0 , . . . , xn length k. transformation SCS problemplanning task conditional effects polynomial, shows claim.Note Theorem 7 relate (known) hardness optimal relaxed planning:wish schedule effects already selected know formrelaxed plan. source complexity has, yet, overlooked literature.Given hardness result, employ greedy minimization technique callconditional effect merging. Starting trivial schedule containing one action executioneffect (G), consider pairs effects e, e0 (G) conditional effectsaction a. two effects merged single execution conditionsachieved without use either add effects. FFs approximation methodapplies similar reasoning, captures special case condition holds:e e0 appear layer relaxed planning graph, triviallyimplies conditions effects independently achievable. However,may also case effects different layers relaxed planning graph.devise strictly general technique, capturing form independenceeffects using call best supporter graph (BSG) representation relaxed plan(for simplicity, assume task single goal fluent G0 , neededachieved introducing new action end whose preconditions original goals,adds G0 ):Definition 4 (Best supporter graph) Given relaxed planning task + best supporter function bs, best supporter graph directed acyclic graph = hV, Ei,V = (G), (G) above, E = {hv, v 0 | p pre(v 0 ) v = bs(p)}, vertexlabeled action whose conditional effect represents, edge labelledset preconditions {p | p pre(v 0 ) v = bs(p)}.nodes graph represent conditional effects appear relaxed plan,exists edge hv, v 0 two nodes effect represented v bestsupporter (pre)condition effect represented v 0 .4 bs valid best supporterfunction (i. e., relaxed plan (G) generated bs sound) sufficient conditionacyclic, easily shown topological sort soundrelaxed plan. implies that, path two conditional effectsaction, occur result action application, thereforemerged single occurrence action. nodes removedBSG, new node added represents effects, combining incomingoutgoing edges. process repeated node merges possible.algorithm runs polynomial time sound results BSGtopological sort constitutes relaxed plan . not, however, guaranteeoptimal scheduling original plan.4. edge labels used procedure choosing conjunction set C, described Section 5.2.500fiImproving Delete Relaxation Heuristics Explicit Conjunctionsexample, consider task move-briefcase n conditional effectstransporting object location location B inside briefcase. nodesBSG n put-into-briefcase(oi ) actions (one object oi ), well n copiesmove-briefcase(A, B) (one conditional effect regarding object oi ).one edge put-into-briefcase(oi ) respective copy move-briefcase(A, B), labeledin-briefcase(oi ). therefore path graph move-briefcase(A, B)node another, merged single node conditional effect mergingalgorithm. topological sorts merged BSG correspond optimal relaxed plans.5.2 Choosing C Relaxed PlanningAlgorithm 1 shows main procedure computing set conjunctions C used formCce task. algorithm applied once, start search, initialCstate planning task. resulting Cce (or ) task used subsequentheuristic evaluations. Conditional effect merging used conflict extractionphase configuration discussed below, i. e., use original non-merged BSGstated Definition 4.Algorithm 1: Choosing C relaxed plan heuristics.C== RelaxedPlan(Cce )plan size(Cce ) < boundC = C FindConflicts()= RelaxedPlan(Cce )Algorithm 1 is, high level, similar procedure previously introducedcomputing incremental cost lower bounds based C construction (Haslum, 2012).algorithm repeatedly generates relaxed plans initial state current compiledtask. adds new conjunctions C based conflicts found currentplan, i. e., based current relaxed plan fails executed original planningtask . process stops either conflicts found, implyingcurrent relaxed plan Cce plan original planning task, user-specifiedCbound size ce reached. express bound terms size Ccecompared (see below). also sometimes impose bound runtimealgorithm.bound specified, FindConflicts() returns least one new conjunctionlong plan , Algorithm 1 complete planning algorithm right.report results usage algorithm experiments below. relaxedplan generated iteration optimal, Algorithm 1 used compute sequenceadmissible cost estimates converges optimal plan cost (Haslum, 2012).focus, however, use Cce generating inadmissible heuristic functions.therefore use tractable, non-optimal, relaxed planning procedure, impose boundtypically stops Algorithm 1 plan original task found.remains specify FindConflicts procedure: Given relaxed plan failsexecute original planning task , select set new conjunctions C? One501fiKeyder, Hoffmann, & Haslumanswer question provided previous use Algorithm 1 computeplan cost lower bounds (Haslum, 2012). aim different computing heuristicssatisficing search-based planning make number changes previouslyproposed version FindConflicts. Section 5.2.1 summarizes original procedure,Section 5.2.2 describes changes make it.5.2.1 Conflict Extraction Incremental Plan Cost Lower BoundsGiven optimal relaxed plan plan original planning task, Haslums(2012) version FindConflicts returns set conjunctions C prevents relaxedplan solution next iteration. ensures progress, sensecost relaxed plan eventually increase, prove real plan cost.describe conflict extraction procedure, need two definitions:Definition 5 (Relaxed Plan Dependency Graph) Let non-redundant planrelaxed planning task + . Construct directed graph G () one node vaaction , plus node vG representing goal. Let pre(v) denote preconditionnode v, pre(a) node va G node vG . G (S) directed edgeva v 0 iff pre(v 0 ) relaxed reachable using set actions minus {a}.edge labelled subset pre(v 0 ) relaxed unreachable actions.relaxed plan dependency graph, RPDG(), transitive reduction G ().RPDG similar BSG (Definition 4), encodes necessary dependencies actions relaxed plan. path node va node vbRPDG implies precedes b every valid sequencing ; case, vb saidordered va . contrast, BSG encodes intentions relaxed planheuristic, form chosen best supporters, may impose orderings needrespected every valid sequencing plan (e. g. fluent p added anotheraction relaxed plan best supporter p). relaxed plannon-redundant, meaning action removed without invalidating it,path every action node RPDG goal node.Definition 6 (Dependency Closure) Let non-redundant plan relaxed planning task + , let v v 0 nodes RPDG(), v 0 ordered v. simpleq1q2qmdependency path path v v1 . . . v 0 v v 0 RPDG(), edgelabelled one fluent, chosen arbitrarily, edge label RPDG(). (Wheneverv 0 ordered v, simple dependency path v v 0 exists.) dependency closurev v 0 minimal, w.r.t. subset, union paths, (1) contains simpledependency path v v 0 , (2) q fluent labels edge node v 00closure, action q add(a), action associatedv 00 , closure contains simple dependency path v node correspondinga. (Such path guaranteed exist.)Recall input FindConflicts plan, , valid delete relaxation +original planning task delete effects considered.valid + , preconditions actions , well goals, must made true502fiImproving Delete Relaxation Heuristics Explicit Conjunctions...vdp1r...vfq1pvdq1...qnvfpnvjqm(b)(a)Figure 1: Relaxed plan failure scenarios. Wavy edges show deletions precondition.point. Thus, fails solve original task must case actiond, call deleter, deletes precondition action f , calledfailed action. Note failed action also goal. Let p pre(f )deleted fluent. procedure distinguishes two cases, based relationnodes vd vf RPDG:first case, illustrated Figure 1 (a), vf ordered vd . Choose dependencyclosure vd vf , let L set fluents labelling edges closure:set conflicts generated {{p, q} | q L}. (Note p 6 L, thus conflictproper conjunction.)first case hold, vd vf unordered. must nearestcommon descendant node, vj , RPDG, situation illustrated Figure 1(b). Choose dependency closure vd vj , let L1 set fluents labellingedges closure. Likewise, choose dependency closure vf vj , let L2set fluents labelling edges closure. set conflicts generated{{q, q 0 } | q L1 , q 0 L2 {p}}.Theorem 8 (Haslum, 2012, Theorem 6) Let = a1 , . . . , non-redundant plandelete relaxed task + valid original task , let C setconjunctions extracted procedure described above. action sequence 0 = a01 , . . . , a0na0i representative ai valid plan C .5.2.2 Changes Conflict Extraction Satisficing Planningnumber differences setting Haslum (2012).particular, although -fluents collected initial state, resulting Cce taskused heuristic evaluations states encountered search, growthsize Cce task incur overhead heuristic evaluation. Thus,objective find set C make heuristic accurate across states,keeping size C limited. hand, computing non-optimal relaxedplans computationally far cheaper optimal relaxed planning, afforditerations Algorithm 1.Therefore, make following modifications strategy: First, use BSGinstead RPDG. necessity orderings latter extend beyondcurrent (initial) state, therefore useful purpose. BSGrepresentative relaxed plans found non-optimal relaxed planning procedure.Second, introduce single -fluent iteration Algorithm 1.time, cause new relaxed plan found, allows algorithm focusfinding small number conflicts useful wide range states. chosenconflict {p, qn } case depicted Figure 1 (a), {pn , qm } Figure 1 (b).503fiKeyder, Hoffmann, & HaslumIntuitively, works better setting set conflicts generatedplan failure tends redundant, thus needlessly grows size taskleading slow evaluation times without much gain informativeness.changes affect fundamental property Algorithm 1, convergesreal plan. show convergence, property FindConflicts mustreturns least one new conjunction whenever fails solve original task.variant still gives guarantee:Lemma 3 Assume eliminate dominated preconditions 5 C . Let = a1 , . . . ,non-redundant plan C valid original task , let cconjunction extracted procedure described above. c 6 C.Proof: simply because, possible relaxed plan failure scenarios (Figure 1),chosen conjunction c = {x, y} ({x, y} = {p, qn } respectively {x, y} = {pn , qm }) containedprecondition failed action f . Assuming c = {x, y} C, eliminatedominated preconditions, action precondition C contains x y. Hence,case, c cannot chosen conjunction.Theorem 9 (Convergence conflict extraction) Assume eliminate dominated preconditions C , Algorithm 1 run without size bound. eventuallyplan .Proof: Follows Lemma 3 set possible conjunctions finite.Contrasting Theorem 9 Haslums variant (Theorem 8), latter gives strongerconvergence guarantee (only) sense guarantees certain minimum progressmade iteration.Lemma 3 (and thus Theorem 9) holds way Cce , i. e., sequenceCconditional effects ce , that, viewed set independent actions, constitutes nonredundant plan Cce . rely eliminating dominated preconditionsmakes proof simple, use technique practice anyway.verify whether convergence holds also dominated preconditions eliminated;conjecture does.Since multiple conflicts BSG relaxed plan, experimentschoose (arbitrarily) one minimizes number conditional effects (or STRIPSactions, case C ) created. place bound factor x Cce exceedssize original planning task . Precisely, x = 1, -fluents conditional+effects added, Cce = , resulting standard relaxed plan heuristic. growthbounds x > 1, -fluents added number conditional effects task reaches(x 1) |A|. C , x limits total number actions task multiple |A|.5. Recall eliminating dominated preconditions means that, whenever add fluent c precondition action, condition conditional effect, remove condition fluentsp c -fluents {c0 | c0 c}.504fiImproving Delete Relaxation Heuristics Explicit ConjunctionsExample 2 Consider STRIPS planning task Example 1, variables{x0 , . . . , xn , y}, initial state = {x0 , y}, goal G = {xn }, unit-cost actions: h, {y}, ,bi : h{xi , y}, {xi+1 }, {y},= 0, . . . , n 1.previously discussed, setting C = {x1 ,y , . . . , xn1 ,y } renders delete relaxationperfect, i. e., results relaxed plan re-establish every two bactions. Exactly set C iteratively selected procedure.Assuming best supporter function based either hadd hmax , first iterationAlgorithm 1 BSG be:b0x1b1x2...b2bn2xn1bn1relaxed plan fails execute trying apply second action, b1 . corresponding failure scenario matches Figure 1 (a):b0b1x1chosen conflict thus {y, x0 }. non-empty set conjunctions C containing single conjunction, precondition b1 contains {x1 ,y} mustestablished using action a, BSG takes form (note dominatedpreconditions xi b1 eliminated):b0x1{x1 ,y}b1b2x2...bn2xn1bn1relaxed plan fails execute trying apply fourth action, b2 .corresponding failure scenario is:b1x2b2chosen conflict {y, x2 }. Iterating procedure will, manner, selectexactly set C one-by-one, end relaxed plan solve originalplanning task.5.3 Experimentsevaluate impact using Cce compilation relaxed plan heuristic context greedy search. expected impact using heuristic based improvedrelaxation two-fold. one hand, make heuristic informative,505fiKeyder, Hoffmann, & Haslumenabling search find plans fewer node evaluations. hand,computational overhead associated growth problem, slowing heuristicevaluations. examine effects individually, well combined influence coverage, set problems planner able solve within given timememory bounds, take main measure performance.study, consider objective producing plans high quality (asmeasured plan length cost). plan quality unimportant. Rather,rationale decision methodological: Seeking high quality planproblem seeking find plan minimum search effort particularlyquality measured non-unit action costs requirements heuristicstwo problems quite different. Here, chosen focus one, viz. search efficiency,measured coverage node evaluations, rather conflate two. choiceplain greedy search algorithm also motivated decision. consequence,treat actions unit cost 1. Previous experiments showncontext greedy search, distinguishing action costs heuristic calculation tends resultlower coverage (Richter & Westphal, 2010). However, least assess impactheuristics plan quality, report data regarding plan length.next describe experiment setup baseline. discuss heuristic informativeness, computational overhead, impact conditional effect merging, impactplan length using Cce heuristics, comparison state-of-the-art heuristicsproblem, difference using C Cce compilations, findingplans search.5.3.1 Experiment Setup Baselinecompilation associated heuristics implemented Fast Downward planner(Helmert, 2006), used greedy best-first search, lazy evaluation secondopen list (with boosting) states resulting preferred operators. plannerstested STRIPS domains 19982011 editions InternationalPlanning Competition (IPC). domains last two IPCs, recentsets instances used. experiments run Opteron 2384 processorssettings used competition: memory limit 2Gb time limit 30 minutes.baseline planner configuration uses relaxed plan heuristic, best supportersidentified hadd , unmodified planning task (i. e., growth bound x = 1).known fact greedy search, particular greedy search lazy evaluationstrong bias towards preferred operators, highly sensitive small changesrelaxed plan, even changes alter heuristic value ratheroperators preferred. Unfortunately, fact rarely taken accountheuristics compared context greedy search. Since introduction -fluentsalters structure relaxed plan, believe particularly important determinewhether resulting differences planner performance really due relaxed plan(or less) informative.Therefore, first step towards accounting brittleness experimentsgreedy heuristic search, introduce simple variance measure use decideresults experiments considered significant. Variance performance506fiImproving Delete Relaxation Heuristics Explicit Conjunctionsbaseline planner measured randomizing choice supporters equalhadd values construction relaxed plan measuring maximum deviationresults baseline planner five repeated runs. results showncolumns labeled MaD (Tables 1 4). domain problem setwhole, deviation defined differences coverage median numberheuristic evaluations. Note interested whether randomization helpshurts search, rather magnitude variation causes.Ccomparing results planner using heuristics based Cce differentgrowth bounds results baseline planner, consider differencesignificant greater magnitude maximum deviation observedrandomization baseline. interpreted significancestatistical sense (although, assumed randomization affects heuristics equally,could estimate probability hypothesis difference), simply settingreasonable threshold counts substantial difference search performance.5.3.2 Heuristic Informativenesscomparison heuristic informativeness summarized right half Table 1,shows ratio median (per domain, tasks solved planners)number heuristic evaluations baseline planner planners usingCce -based heuristics. half domains, difference informativenessCce -based heuristics compared baseline exceed threshold significanceset sensitivity study (shown MaD column). Among domainssignificant difference, majority using Cce -based heuristics reducesnumber node evaluations, indicating augmented heuristics informative.cases, ratio grows -fluents added, i.e., growth boundx increased. drastic example seen Floortile domain,Cce -based heuristics evaluate four orders magnitude fewer nodes, comparedstandard delete relaxation heuristic. allows easily solve instancesdomain. comparison, planner IPC 2011 able solve 920 instances domain. Woodworking domain, Cce heuristicstwo orders magnitude informative, associated increase coveragetasks solved configurations.roughly third domains consistent (or nearly consistent) lossinformativeness, though significant. Note loss informativeness always correlate loss coverage. attributed differentfactors, including small magnitudes loss, well fact ratio nodeevaluations taken tasks solved planners compared. Another issuedramatic coverage losses often due computational overhead incurredCce compilation. particular, Openstacks Satellite domains, decreasenumber tasks solved Cce -based heuristics matches almost exactly numbertasks conflict selection compilation process fails complete within1800 seconds allocated per task. get back next subsection.507fiKeyder, Hoffmann, & Haslumworth noting quality Cce -based heuristics highly sensitiveprecise choice -fluents used compilation.6 Hence, may exist better policiesmaking choice relatively simple one used here.HO PO colums Table 1 (coverage only) examine effect newheuristic function, respectively new preferred operators returned function,separation. PO corresponds configuration uses relaxed plan Cce task(built x = 1.5 timeout = 60s, discussed Section 5.3.3) identifypreferred operators, together heuristic value baseline (x = 1) heuristic.HO, hand, uses heuristic values obtained x = 1.5 preferredoperators x = 1. Interestingly, either heuristic values preferred operators alonesufficient greatly improve coverage Floortile, domain techniquesgreatest impact. HO PO configurations able solve every instancedomain.7 effect domains mixed, configurations solvingsometimes more, sometimes fewer instances.5.3.3 Computational Overheadcomputational overhead Cce -based heuristics, compared standard relaxedplan heuristic, stems two sources: (1) time spent computing set -fluentsadd problem, (2) greater overhead heuristic evaluation Cce task.Table 2 shows three measures impact.first four columns (under Timeouts) show number instancesconstruction Cce task finish within 1800 seconds, second setfour columns (under > 60 sec) shows number instances constructiontime exceeds 60 seconds (inclusive instances first set columns). Notebehavior spending large amount time Cce construction without reachinggrowth bound partly due strategy selecting -fluents, since purposelychoose -fluents increase size compiled task least.several domains construction time frequently exceeds 60 seconds,happen domains Cce -based heuristic informative,Floortile Woodworking. suggests imposing time limit constructionCce task incur small loss informativeness. present coverage resultsstrategy (using 60 second time limit) Table 4 below. significantly betterbaseline planner, compares favourably state art heuristics.expected, domains evaluating heuristics Cce task slowerstandard delete relaxation, tends slow growth bound x increases,due larger number fluents actions compiled planning task. medianslowdown per domain typically order x itself, exceeds one order6. Indeed, results reported earlier paper (Keyder, Hoffmann, & Haslum, 2012) show increaseinformativeness Barman Parcprinter domains.7. plausible explanation behavior respect dead-end states (intuitively,robot painted corner) unrecognized standard delete relaxationheuristic, i. e., relaxed plan exists. appears Cce highly effective fixingissue: x = 1 search encounters millions states hFF () = , HO encountersFFstates hFF (C(Cce ) = (suggesting hce ) prunes dead-ends early on), PO encountersstates (suggesting hFF (C)preferredoperators prevent search enteringcedead-end regions first place).508fiImproving Delete Relaxation Heuristics Explicit ConjunctionsDomainx=1 MaDAirport (50)36Barman (20)13Blocksworld (35)35Depots (22)19Driverlog (20)20Elevators (20)19Floortile (20)6FreeCell (80)79Grid (5)5Gripper (20)20Logistics00 (28)28Logistics98 (35)34Miconic (150)150Mprime (35)35Mystery (30)16Nomystery (20)9Openstacks (20)20Parcprinter (20)16Parking (20)20Pathways (30)30Pegsol (20)20Pipes-NoTk (50)42Pipes-Tank (50)38PSR (50)50Rovers (40)40Satellite (36)35Scanalyzer (20)18Sokoban (20)19Tidybot (20)16TPP (30)30Transport (20)11Trucks (30)14Visitall (20)19Woodwork (20)20Zenotravel (20)20Total (1126)1002+2+5+0+1+0+3+0+2+0+0+0+1+0+0+0+2+0+7+1+2+0+1+4+0+0+1+1+1+3+0+1+0+1+0+1+19Coveragex =PO HO1.5 2 2.5 3 1.5 1.5+0+1 +3 +1 +2 +1+6 +3 +1 3 3 +5+0+0+0+0+0+0+0 1+2 +2 +2 +2+0+0+0+0+0+0+1 +1 +1 +1 +1 +1+14 +14 +14 +14 +14 +14+0 +1+1 3 4 2+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0+0 1+0 +1 +1+1+0+0+0+0+0+0+0+0+0+0+0+0+3 +3 +3 +3 +3 +12 3 3 3 1 29 9 9 9 1 111 8 7 7 4 10+0 62 8 7 5+01 2 5 1 1+0+0+0+0+0+0+0 1+0+0 1+0+0 +2 1 +3+3 +2+0+0+0+0+0+0+0+0+0 1+01+02 5 6 8 +1+2 +2 +2 +2 1 +2+0 22 2 3 3+0+0 1 1+02+0+0+0+0+0+0+2 2 +1 +1 7 3+0 +2+1 +3 +4 +2+1 +1 2 2 2 2+0+0+0+0+0+0+0+0+0+0+0+0+6 9 17 14 3 +3Median Node Evaluations Ratiox =1.522.534.321.36 : 11.34 : 11.40 : 11.50 : 19.911 : 1.631 : 2.221 : 8.331 : 2552.84 : 12.90 : 12.90 : 13.02 : 112.132.84 : 13.26 : 13.65 : 18.55 : 11.16 2.17 : 12.64 : 12.65 : 12.31 : 11.311.25 : 11.47 : 11.34 : 11.22 : 16.42 15013 : 115110 : 114757 : 119674 : 11.281 : 1.111 : 1.281 : 1.171 : 1.291.21 1.27 : 12.83 : 11.27 : 11.27 : 111 : 1.051 : 1.511 : 1.49 1.23 : 11.641.47 : 11.47 : 11.53 : 11.60 : 11.45 2.53 : 12.57 : 12.83 : 12.70 : 11 1.16 : 11.22 : 11.29 : 11.36 : 11.09 2.33 : 12.33 : 12.33 : 12.33 : 11.07 1.21 : 11.27 : 11.29 : 11.29 : 113.931 : 1.442.58 : 19.95 : 110.13 : 11.08 2.52 : 11.31 : 11 : 1.231 : 1.111.581 : 1.041 : 1.041 : 1.081 : 1.097.061 : 1.123.02 : 11.61 : 11.18 : 11.211 : 1.031:11 : 1.051 : 1.113.421.44 : 11.09 : 11.66 : 11.41 : 116.471 : 1.071.08 : 11.14 : 11.29 : 12.461:11:11:11 : 1.0511:11.02 : 11.12 : 11.12 : 11.331.12 : 11.15 : 11.12 : 11.20 : 11.361.15 : 11.36 : 11.30 : 11.29 : 11.851.17 : 11.80 : 13.43 : 13.25 : 11.461.17 : 11 : 1.091.01 : 11.06 : 11.221.15 : 11 : 1.251 : 1.381 : 1.082.291 : 1.201 : 1.131 : 1.191 : 1.012.731.20 : 11 : 1.111 : 1.291 : 1.011.661.16 : 11.97 : 17.27 : 14.57 : 11.341.01 : 11 : 1.081 : 1.091 : 1.4952.78 245.72 : 1263.3 : 1245.72 : 1245.72 : 11.281.22 : 11.24 : 11.36 : 11.42 : 1MaDTable 1: Planner coverage heuristic informativeness using Cce varying growth bounds,without conditional effect merging. Coverage shows number problems solved baselineconfiguration (x = 1), difference (increase/decrease) relative baselineconfigurations; PO uses preferred operators obtained Cce compilationx = 1.5 = 60s, returning x = 1 heuristic value, HO uses heuristic valuesobtained x = 1.5 = 60s, preferred operators x = 1. Heuristic informativenessmeasured ratio per-domain median number node evaluations, comparingbaseline configurations (across instances solved configurations), normalizedsmaller value 1. is, entry : 1 means baseline planner requires timesmany heuristic evaluations planner. Columns labeled MaD show magnitudemaximum deviation (in coverage ratio) baseline sensitivity study: valuesbold exceed threshold, therefore consider significant.magnitude Floortile domain x = 1.5. Somewhat surprisingly,domains heuristic evaluations become faster -fluents added. possibleexplanation eliminate dominated preconditions (cf. Section 3),number action preconditions decreases delete-relaxation hypergraphCce becomes graph-like result.509fiKeyder, Hoffmann, & HaslumDomainAirport (50)Barman (20)Blocksworld (35)Depots (22)Driverlog (20)Elevators (20)Floortile (20)FreeCell (80)Grid (5)Gripper (20)Logistics00 (28)Logistics98 (35)Miconic (150)Mprime (35)Mystery (30)Nomystery (20)Openstacks (20)Parcprinter (20)Parking (20)Pathways (30)Pegsol (20)Pipes-NoTank (50)Pipes-Tank (50)PSR (50)Rovers (40)Satellite (36)Scanalyzer (20)Sokoban (20)Tidybot (20)TPP (30)Transport (20)Trucks (30)Visitall (20)Woodwork (20)Zenotravel (20)Total (1126)Timeoutsx =1.5 2 2.5 311111.515> 60 secx =22.52023326193961610101211369109916161616141631661675935113513351346151228151629161741096118134148721310209323411Ratio Median Evaluations/secx =1.522.531.08 : 11.19 : 11.30 : 11.26 : 11.35 : 11.88 : 12.42 : 13.09 : 11.50 : 11.60 : 11.56 : 11.42 : 11.65 : 11.81 : 12.03 : 12.31 : 11.56 : 12.38 : 13.17 : 14.07 : 11.87 : 12.92 : 13.99 : 15.45 : 117.67 : 18.28 : 15.97 : 15.49 : 11.20 : 11.31 : 11.39 : 11.66 : 11.27 : 12.55 : 13.04 : 13.04 : 11 : 2.131 : 2.041 : 2.131 : 1.691.09 : 11 : 1.761 : 1.351 : 1.221.20 : 11.64 : 12.55 : 13.72 : 11.06 : 11.10 : 11.18 : 11.27 : 11.60 : 11.80 : 11.60 : 11.80 : 11.28 : 11.35 : 11.42 : 11.42 : 11.43 : 12.20 : 12.53 : 13.26 : 11.16 : 11.73 : 12.49 : 13.17 : 11 : 8.331 : 8.331 : 6.251 : 1.812.32 : 13.61 : 14.84 : 16.20 : 11.36 : 12.04 : 11.01 : 11.64 : 11.25 : 11.08 : 11.48 : 11.11 : 11.41 : 11.94 : 12.31 : 12.78 : 11.61 : 12.37 : 12.42 : 13.39 : 11:11:11.02 : 11 : 1.051.11 : 11.43 : 11.48 : 11.83 : 11.14 : 11.07 : 11 : 1.01 1.30 : 11.09 : 12.22 : 12.42 : 12.73 : 11.23 : 11.38 : 11.62 : 11.82 : 11.48 : 12.03 : 13.36 : 12.22 : 11.59 : 11.70 : 12.38 : 12.84 : 12.38 : 14.04 : 16.50 : 18.80 : 11.62 : 12.29 : 12.52 : 13.30 : 11 : 1.491 : 1.331 : 1.151 : 1.071 : 2.631 : 2.08 3.29 : 16.32 : 11.09 : 11:11.06 : 11.10 : 1Table 2: Computational overhead Cce . first set columns (Timeouts) shows numbertasks Cce construction finish within 1800 second time limit,second set (> 60 sec) shows number tasks construction time exceeds 60 seconds(inclusive first set columns). improve readability, non-zero entriesshown (i.e., blank cells columns zeroes). last set columns shows median(per domain, commonly solved tasks) ratio heuristic evaluations per second baselineplanner (x = 1) planner (x > 1). entry : 1 means baseline plannerperforms times many heuristic evaluations per second planner.5.3.4 Conditional Effect Mergingmajority domains, conditional effect merging slightly increases changeinformativeness Cce -based heuristics. exceptions Logistics00Gripper domains, merging results heuristic twice informative(using ratio median number evaluations metric presented Table 1),Nomystery domain order magnitude informative (for problemssolved heuristics), Barman domain four times lessinformative. general, higher informativeness occurs domains tasks510fiImproving Delete Relaxation Heuristics Explicit Conjunctionssolved planners, result increased coverage. Indeed, shownTable 4 below, conditional effect merging proves detrimental overall coverageCplanner using Cce -based heuristic: best ce configuration conditionaleffect merging solves, total, 4 tasks standard relaxed plan heuristic,configuration without conditional effect merging solves 20 tasks.runtime overhead merging procedure quite small, transitive closureoperation required check whether path two nodes BSGimplemented efficiently graph known directed acyclic, casehere. x = 1.5, comparing Cce -based heuristic conditional effect mergingwithout, ratio median number heuristic evaluations per second (themetric used right-hand side Table 2) shows maximal per-domain slow-down2.04, across-domain average 1.11. Coverage decreases domainsBarman therefore appear due sensitivity search small changesheuristic function (rather due time taken compute function).5.3.5 Plan Length Ccedetermine effect using Cce heuristics plan quality, compare lengthplans found Cheuristicsfound x = 1, standard delete relaxationceheuristic. plan length measure equivalent plan quality unit-cost setting.consider median ratio plan length found standard delete relaxationheuristic found Cce heuristic, set instances solvedconfigurations (Table 3). general, observe large differences,median ratio staying close 1. One notable exception blocksworld domain,heuristics based Cce compilation consistently find significantly shorter plans.Cresults ce heuristics ability deduce implicit ordering constraints domain,avoiding actions lead temporary improvements greedy search laterneed reversed, adding plan length. Cce also leads shorter plans Gripper,Mprime, Woodworking domains, tends result longer plans BarmanGrid domains.5.3.6 Comparison State ArtTable 4 shows coverage variety heuristics planners. best configurationstwo compilations x > 1 achieve better overall coverage resultsstandard relaxed plan heuristic. best-performing heuristics obtained Ccecompilation without conditional effect merging, C compilation, give coverages1022 1023 respectively. difference coverage baselineplanner greater significance threshold. numbers also far exceed coverage obtained hcea heuristic, fall short 1039 instances solveddual heuristic approach used LAMA. However, combining LAMA best Cce -nmconfiguration portfolio planner runs LAMA 1500 seconds searchCce -nm heuristic 300 seconds results coverage 1063 1115 solvable problems.Almost difference results Cce -based heuristics superior performanceFloortile, lesser extent, Airport domains.511fiKeyder, Hoffmann, & HaslumDomainAirportBarmanBlocksworldDepotsDriverlogElevatorsFloortileFreeCellGridGripperLogistics00Logistics98MiconicMprimeMysteryNomysteryOpenstacksParcprinterParkingPathwaysPegsolPipesworldPipesworldPSRRoversSatelliteScanalyzerSokobanTidybotTPPTransportTrucksVisitallWoodworkZenotravelx = 1.51 : 1.001 : 1.111.65 : 11.08 : 11.04 : 11 : 1.061 : 1.101 : 1.021 : 1.241.04 : 11 : 1.141.07 : 11 : 1.001.12 : 11 : 1.001 : 1.001 : 1.021 : 1.001.26 : 11 : 1.011 : 1.041 : 1.091 : 1.121 : 1.001 : 1.011 : 1.001 : 1.001 : 1.001 : 1.061 : 1.041 : 1.101 : 1.001.01 : 11.21 : 11 : 1.00x111.681.03111111.1611.0511.1711111111111111111111.211=:::::::::::::::::::::::::::::::::::21.001.12111.001.051.151.031.1711.1311.0011.001.021.021.001.011.001.001.001.001.001.001.001.001.031.191.021.161.001.0011.00x = 2.51 : 1.001 : 1.231.69 : 11.04 : 11 : 1.001 : 1.051 : 1.051 : 1.041 : 1.171.31 : 11 : 1.131.05 : 11 : 1.001.12 : 11 : 1.001 : 1.021 : 1.021 : 1.001.04 : 11 : 1.011 : 1.031 : 1.171 : 1.041 : 1.001.01 : 11 : 1.001 : 1.001.01 : 11 : 1.161 : 1.001 : 1.061 : 1.001 : 1.041.21 : 11 : 1.00x111.641.06111111.3111.061.011.171111.041111111111111111.211=:::::::::::::::::::::::::::::::::::31.001.32111.001.121.031.061.1711.121111.001.021.0111.001.021.021.141.061.001.001.011.001.031.131.001.131.001.0811.00Table 3: Median ratio length plans found x = 1, length plans found Ccedifferent values x, instances solved planners. entry : 1 meansbaselines plans times longer planner. conditional effect mergingused.5.3.7 C vs. CceGiven fixed number -fluents, difference size C Ccecompilations exponential worst case. Mutex pruning, however, mitigate muchgrowth C . Consider, example, action Cce compilation ndifferent conditional effects. mutexes considered, one would expect numberaction representatives generated set -fluents C 2n . If, however,n -fluents generating conditional effects shown mutexone another, number action representatives generated C also n.found experiments effect leads much slower growth Cmight expected. Consider Figure 2. point graph represents512fiImproving Delete Relaxation Heuristics Explicit ConjunctionsDomainAirport (50)Barman (20)Blocksworld (35)Depots (22)Driverlog (20)Elevators (20)Floortile (20)FreeCell (80)Grid (5)Gripper (20)Logistics00 (28)Logistics98 (35)Miconic (150)Mprime (35)Mystery (30)Nomystery (20)Openstacks (20)Parcprinter (20)Parking (20)Pathways (30)Pegsol (20)Pipes-NoTank (50)Pipes-Tank (50)PSR (50)Rovers (40)Satellite (36)Scanalyzer (20)Sokoban (20)Tidybot (20)TPP (30)Transport (20)Trucks (30)Visitall (20)Woodwork (20)Zenotravel (20)Total (1126)x=1361335192019679520283415035169201620302042385040351819163011141920201002MaD+2+5+0+1+0+3+0+2+0+0+0+1+0+0+0+2+0+7+1+2+0+1+4+0+0+1+1+1+3+0+1+0+1+0+1+19Cce371435222019208042028351503518920912242042415040361918143011161820201006CoverageC-nmCce36381918353521212020201920208079552020282835351501503535191971120205101815292920204242414050504040363620201717141630301511151620182020202010221023hFF342035182019679520283315035161020202030204339504036181914301119320201000hcea4203518202067952028351503519719122028204032504036203162917153820947LAMA3120352120205795202835150351913202020302044435040362019173019152020201039PF36203522202020795202835150351913202020302044445040362019173019162020201062Table 4: Comparison state-of-the-art-heuristics satisficing planning. Columns x = 1MaD Table 1. Column Cce shows coverage best configuration (in terms overallcoverage) compilation using conditional effect merging (namely x = 1.5, = 60);CCce -nm best ce configuration without conditional effect merging (which happens useCx t); best C configuration x > 1 (which happens usex t). Entries bold columns difference baseline plannerexceeds threshold significance (given MaD column). Column PF shows coverageportfolio planner runs LAMA 1500 seconds Cce 300 seconds.single problem instance (from instance set before), paired value x.CCce (x-axis) (y-axis), measure ratio growth |A| growth|F |, i. e., factor compilation increased size action set encoding(measured number actions C number conditional effects Cce ),divided factor compilation increased number fluents.513fiKeyder, Hoffmann, & Haslum1e+08Action set growth/uent set growth, CAction set growth/uent set growth, C4.543.532.521.510.5000.511.522.533.544.5Action set growth/uent set growth, Cce1e+071e+06100000100001000100101050100150200250300350Action set growth/uent set growth, Cce(a)(b)Figure 2: Growth problem size ratio growth |A| growth |F |, (a) without(b) mutex pruning. point corresponds single instance value x. f (x) = x alsoshown reference.words, assess growth encoding number conjunctions |C|,theory worst-case exponential C linear Cce .mutex pruning used (Figure 2 (b)), growth C rapidratio quickly increases millions; mutex pruning (Figure 2 (a)), growth Cstill faster Cce , difference much smaller.5.3.8 Finding Plans Searchgrowth time limit imposed construction C Cce tasks,Algorithm 1 used complete planning algorithm. competitiveheuristic search methods, nevertheless interesting observe performance detailsalgorithm various domains. coverage obtained algorithm usingC Cce compilations, well statistics growth compiledCtasks, shown Table 5. difference Cce much visible here,since number -fluents added is, general, much larger growth-boundedconstructions used heuristic computation. Cce able rapidly add muchlarger number -fluents, therefore find relaxed plans solutionsCoriginal planning task well. Overall, Cce solves 568 tasks compared 404 ,solves equal greater number tasks except 4 domains.Considering individual domains, seen C Cce able solvealmost tasks certain domains Logistics00, Mprime, Mystery, Parcprinter,PSR, Woodworking. domains, even addition small amountinformation sufficient obtain relaxed plans plans original task,maximum x values required solve tasks quite low. case Mprime,Mystery, Woodworking domains, maximum required x values 4.07, 4.62,1.35, respectively. others Elevators, Openstacks, Transport, Visitall,even smallest tasks quite large many different plans possible,possible introduce enough -fluents disqualify possible relaxed plansconstitute real plans, tasks solved.514fiImproving Delete Relaxation Heuristics Explicit ConjunctionsDomainAirport (50)Barman-sat (20)Blocksworld (35)Depots (22)Driverlog (20)Elevators-sat11 (20)Floortile-sat11 (20)FreeCell (80)Grid (5)Gripper (20)Logistics00 (28)Logistics98 (35)Miconic (150)Mprime (35)Mystery (30)Nomystery-sat11 (20)Openstacks-sat11 (20)Parcprinter-sat11 (20)Parking-sat11 (20)Pathways-noneg (30)Pegsol-sat11 (20)Pipes-NoTank (50)Pipes-Tank (50)PSR (50)Rovers (40)Satellite (36)Scanalyzer-sat11 (20)Sokoban-sat11 (20)Tidybot-sat11 (20)TPP (30)Transport-sat11 (20)Trucks (30)Visitall-sat11 (20)Woodwork-sat11 (20)Zenotravel (20)Total (1126)Cov.34033161504141627241063519502005191095021159012001502015568Min1.001.211.821.0031.4791.411.295.371.271.221.201.021.0216.723.661.7769.363.512.691.031.354.221.9022.421.175.541.001.00CceMax44.50141.7990.9337.11216.1891.4122.53208.7591.1041.16175.114.074.6259.8076.0451.72707.06187.4194.3377.38459.6643.6147.7522.4243.1221.361.3592.26CMed2.3111.448.488.92112.5091.411.4167.696.7931.1455.011.151.2541.149.957.26137.9811.6013.467.297.4019.1613.9322.4213.7513.561.247.25Cov.3103014140924627213635193090305849147101070802012404Min1.001.211.821.0048.92212.241.316.771.271.221.201.021.0221.911.602.3212.612.561.051.705.222.382.891.176.321.001.00Max168.45400.94221.4174.97633.11272.1241.22501.28585.53149.912706.8613.228.3443.50276.81203.41738.88110.511052.26645.00399.10161.422.89560.95100.151.40191.54Med3.5615.4912.459.96107.21242.181.5476.1214.115.8054.471.141.2033.2788.2389.79242.5411.7116.0426.0422.0944.212.8911.2741.051.2511.14Table 5: Solving planning tasks search. Table shows Coverage C Cce compilations, Minimum, Maximum, Median values x solved tasks.6. Heuristics Optimal Planningconsider admissible heuristics, optimal planning. Section 6.1 considersLM-cut heuristic, showing certain complications make difficultobtain improved heuristic estimates C Cce . Section 6.2, consideralternative method lower-bound h+ , namely admissible cost-partitioning heuristics basedconjunctive landmarks obtained Cce . detail choose Csetting, present experimental results Section 6.3.515fiKeyder, Hoffmann, & Hasluma1a2a3g2aC3g1g1a1a2a3g2aC20g3g3(a)0{g1 ,g2 ,g3 }aC10(b)Figure 3: LM-cut , C compilation, Example 3.6.1 LM-cutstate-of-the-art admissible approximation h+ computed LM-cut algorithm(Helmert & Domshlak, 2009). logical approach obtaining admissible heuristicsC Cce therefore apply LM-cut compilations. Unfortunately, turnsseveral serious obstacles this. discussing issues, first givebrief description LM-cut algorithm, present simpler case Ccompilation, additional complication conditional effects present.LM-cut computed planning task deletes, simple transformation first applied replaces goal set G single goal achievedgoal-achievement action whose precondition set G, adds dummy precondition actions whose precondition set empty. LM-cut initializes hLM-cut := 0and, repeats following steps hmax (G) becomes 0: (1) Compute hmax ; (2) applyprecondition choice function (PCF) action precondition pre(a) removespre(a) one fluents p pre(a) hmax (p) maximal; (3) constructjustification graph whose vertices fluents whose arcs precondition/effectpairs according PCF; (4) find cut L initial state goaljustification graph, given set actions enters goal zone, i. e., setfluents goal reached 0 cost; (5) add costmin := minaL cost(a)heuristic value hLM-cut , reduce cost L costmin . provedHelmert Domshlak (2009), algorithm two fundamental properties, namely (i)admissibility, hLM-cut h+ , (ii) domination hmax , hmax hLM-cut .would expected heuristic obtained manner C wouldstrictly informative obtained original planning task ,turns case. Indeed, heuristic become strictly less informative:Example 3 Let = hF, A, I, Gi given F = {g1 , g2 , g3 }, = {a1 , a2 , a3 },ai = h, {gi }, , i, = , G = {g1 , g2 , g3 } (Figure 3). words, three goals,achievable single action. Valid plans apply actionorder, make goals true. cuts found LM-cut algorithm task{a1 }, {a2 }, {a3 }, regardless PCFs chosen, LM-cut algorithm thereforealways computes optimal cost 3. Consider C compilation resultsset C = {{g1 , g2 , g3 }}. F C contains single -fluent {g1 ,g2 ,g3 } , representative00action aCconstructed sole non-empty subset C = {{g1 , g2 , g3 }} C.first cut found LM-cut contains three representatives, addsexpensive goal {g1 ,g2 ,g3 } . possible PCFs, next cut last,final heuristic estimate 2 two cuts found. If, example,516fiImproving Delete Relaxation Heuristics Explicit Conjunctions00Cprecondition choice function chooses g1 hmax justifier aC2 a3 , g20maxChjustifier a1 , cut {a1 , a2 }. cut, goal reached 0 cost{{g ,g ,g }}via a1 , a2 , a3 1 2 3 , hmax 0 LM-cut stops.+CNote (similarly h+ (Cce ), cf. Theorem 2) possible either h ( )hmax (C ) decrease addition -fluents, example hmaxcost task actually increases (from 1 2) addition -fluent {g1 ,g2 ,g3 } .However, type interactions introduced difficult LM-cut algorithmreason about, resulting worse admissible bounds practice. LM-cut course continues dominate hmax , proving sufficient number -fluents added, LM-cuteventually tend towards optimal cost task.weakness pointed Example 3 inherited application LM-cutalgorithm Cce compilation. Furthermore, application involves additional complication proves formidable: LM-cut defined conditional effects, thereforecannot directly applied Cce task. turns two straightforwardadaptations algorithm problems conditional effects, neither preservesproperties (i) admissibility (ii) domination hmax .see (ii) stake, consider planning task single actiontwo conditional effects ce(a)1 = h{p}, {q}, ce(a)2 = h{q}, {r}, i, initial state{p}, goal {r}. h+ () = hmax () = 2 due critical path ha, ai,justification graph considered LM-cut consists sequence. first cut found{a}. cost reduced, remaining task hmax cost 0, resultingcost estimate hLM-cut = 1.issue different conditional effects action may partcritical path. natural approach therefore reduce costs per individual conditionaleffect, rather effects action once. Unfortunately, turnspreserve admissibility (i). Indeed, detail Example 4 (Appendix A),exist STRIPS tasks whose Cce compilations following property:exists action reducing cost globally first encountered cutleads heuristic estimate less hmax (Cce ), treating effects+Cseparately leads estimate greater h (ce ) = h ().therefore simple strategy dealing conditional effects preserves(i) (ii) planning tasks. Since admissibility cannot sacrificed, mustreduce costs globally give dominating hmax . particular implication1Cso, despite Theorem 5 shows hmax (Cce ) = h (ce ) converges h (),convergence guaranteed hLM-cut (Cce ). could course fixed usingmax(hmax , hLM-cut ) heuristic value, yet hmax typically informative,strategy useful practice.detail Section 6.3 below, IPC benchmarks, using LM-cut computed either C Cce often results larger search spaces -fluents introduced. cases, overall performance worse hLM-cut (C ) hLM-cut (Cce )hLM-cut (). remains open question whether improved.517fiKeyder, Hoffmann, & Haslum6.2 Cce LandmarksLandmarks planning tasks formulas set fluents F property made true state execution valid plan.problem checking whether even single fluent landmark planning taskPSPACE-complete, approaches finding landmarks past focuseddelete relaxation, setting whether fluent landmark checkedpolynomial time. recently shown maximum fixpoint solutionset simple recursive equations defines complete set single fact delete-relaxationlandmarks, words landmark formulas consist single literal= p (Keyder et al., 2010). solution computed algorithm repeatedly updates set landmarks fluent action planning task,convergence. method naturally handle conditional effects treatingindependent actions, described Section 5.1.also shown equations applied AND/OR graphstructure, necessarily corresponding delete relaxation planning task.insight used obtain landmarks task. Single -fluent landmarkscorrespond conjunctive landmarks necessarily landmarksdelete relaxation + . approach suffers, however, large number -fluentsconsidered , rendering landmark generation impractical compilations larger tasks. aim take advantage flexibility Cce compilationobtain non-delete-relaxation landmarks original task, consideringfocused set -fluents given size m. before, allow usconsider larger conjunctions keeping size delete relaxation task low.using Cce landmark finding, focus technique keep overheadbay, choose set conjunctions C guarantee every -fluent landmarkCce (and therefore original planning task). accomplished extractinglandmark graph sets landmarks simultaneously achieved :Definition 7 (Simultaneously achieved landmarks) set landmarks Ls = {1 ,. . . , n } simultaneously achieved Lc = 1 ... n landmark .Maximal sets simultanously achieved landmarks easily extracted setlandmarks orderings. Given initial set landmarks L set orderings,following sets sets simultaneously achieved landmarks:LG = {{ | G |= }}Lnec = {{ | nec } | L}Lgn = {{ | gn } | L}LG contains single set made landmarks L entailed G. Sincevalid plan must make goals true final state, necessarily simultaneouslyachieved. Given landmark , Lnec contains set elements landmarks ordered necessarily . Due definition necessary orderings,must simultaneously true every state immediately precedes statebecomes true. Lgn similar set, yet since greedy necessary orderings518fiImproving Delete Relaxation Heuristics Explicit Conjunctionsweaker necessary orderings, sometimes contain sets appear Lnec ,therefore result larger overall set conjunctive landmarks. Note necessary orderings also greedy necessary orderings, conjunctive landmarkresults set necessary orderings therefore subset conjunctive landmarkresults greedy necessary orderings. include conjunctive landmarks resultnecessary orderings result stronger necessary orderings addedconjunctive landmark . Landmark heuristics sometimes inferconjunctive landmarks must reachieved landmark ordered necessarilyreachieved. case conjunctive landmarks derivedgreedy-necessary orderings, need achieved make landmarksordered true first time.Algorithm 2: Choosing C landmark generation.C=L = FindLandmarks(Cce )repeatC = C SimultaneouslyAchieved(L)L = FindLandmarks(Cce )SimultaneouslyAchieved(L) Cstrategy choosing C landmark generation shown Algorithm 2.new conjunctive landmarks L = p1 pn discovered, corresponding fluents{p1 ,...,pn } added Cce landmark computation step repeated. Noteprocess may go several iterations, run fixpoint reached,addition new -fluents Cce task result discovery new landmarks.process terminates new conjunctive landmarks discovered alreadyexist -fluents Cce . note method choosing C desiredCproperty mentioned above: -fluents introduced Cce represent fact landmarks ceconjunctive landmarks original task .strategy works especially well domains many landmarks several landmarks necessarily greedy necessarily ordered them. One domainoccurs Blocksworld (see illustration Figure 4), methodable find extremely informative conjunctive landmarks allow optimally solvetasks heuristic tested.6.3 Experimentsconsider performance LM-cut heuristic hLM-cut C Cce compilations, admissible landmark cost-partitioning heuristic hLM introducedKarpas Domshlak (2009) different landmark generation schemes, includingLM-cut used search algorithm, hLMlandmarks obtained Cce . huse LM-A , variant effective known fluent landmarks(Karpas & Domshlak, 2009). benchmarks, computers, time/memory limitsused Section 5.3.519fiKeyder, Hoffmann, & HaslumInformativenessCoverageDomainC , 1.5C,1.5Orig.x=1C , 1.5 Ccece , 1.5Airport1 : 49.021 : 52.9128281918Barman-opt1 : 1.061 : 1.124444Blocksworld4.22 : 11 : 1.7128282827Depots1 : 1.961 : 6.497544Driverlog1 : 23.71 : 48.3113131010Elevators-opt111.65 : 11 : 1.0318181615Floortile-opt1119.23 : 113.93 : 1761212FreeCell1.07 : 11 : 2.121515139Grid3.47 : 11 : 1.352221Gripper1:11:17766Logistics001 : 9.381 : 10.4720201615Logistics981 : 7.691 : 18.876623Miconic1 : 232.551 : 769.23 141 1415045Mprime13.08 : 11 : 1.1322222822Mystery1.03 : 11.07 : 116161717Nomystery-opt111 : 126.581 : 588.24141488Openstacks-opt111:11:114141414Parcprinter-opt111 : 1.141 : 4.2313131312Parking-opt112110Pathways-noneg1 : 15.721 : 51.815544Pegsol-opt111.08 : 11.08 : 117171717Pipes-NoTank1 : 1.481 : 2.0917171514Pipes-Tank1 : 1.301 : 2.25111087PSR1.04 : 11 : 1.0349494949Rovers1 : 1.721 : 3.567776Satellite1 : 3.771 : 33.337766Scanalyzer-opt111 : 1.361 : 1.06111145Sokoban-opt111 : 1.281 : 1.3120202020Tidybot-opt111 : 4.791 : 13.19131376TPP1 : 5.141 : 1.706666Transport-opt111 : 1.871.35 : 16667Trucks1 : 5.941 : 10.26101076Visitall-opt111 : 3.861 : 3.3210101010Woodwork-opt114.07 : 11 : 2.36111175Zenotravel1 : 39.371 : 153.85121288Total589 584444418CTable 6: LM-cut Cce . two columns left show ratio summednumber heuristic evaluations tasks solved configurations, comparing standardLM-cut results x = 1 LM-cut computed C Cce x = 1.5. example,first entry table, 1 : 49.02, shows LM-cut computed C growth boundx = 1.5 evaluates, sum commonly solved tasks, nearly 50 times many states LM-cutcomputed standard delete relaxation. last 4 columns show coverage. Column Originalshows results obtained Fast Downwards implementation LM-cut (which appliesstandard delete relaxation), column x = 1 shows results implementation LMcut unmodified delete relaxation (with differences two purely dueimplementation details). Entries bold indicate highest coverage domain, total.520fiImproving Delete Relaxation Heuristics Explicit Conjunctionsclear(a)gnclear(b)handemptyontable(b)clear(a)holding(b)natnatclear(b)handemptyon(b, a)clear(c)handemptyontable(c)clear(b)clear(d)gnon(b, a)holding(c)nat ontable(d)gnon(b, a)on(c, b)on(d, c)necclear(c)clear(c)clear(d)on(b, a) gn handemptyon(c, b)on(b, a)holding(d)on(c, b)ontable(d)Figure 4: Landmarks graph found Cce compilation small Blocksworld task,blocks initially table G = {on(b, a), on(c, b), on(d, c)}. smaller conjunctivelandmarks single fluent landmarks omitted.6.3.1 LM-cut C Cceevaluate impact using C Cce compilations LM-cut, constructedCCce tasks following procedure described Section 5.3, repeatedlyselecting conflicts increase size compiled task reached fixed growthbound x. Conflict selection based hmax supporters rather hadd supporters,hmax plays key role computation LM-cut, also resulted better performance.that, procedure used generate C Cce tasks same.Ctested value x set {1.5, 2, 2.5, 3} Cce . observedx = 1.5 dominated larger values x domain-by-domain overall basis,therefore report results two configurations. exceptionMystery domain, C x = 2.5 x = 3 solved 18 tasks compared 17x = 1.5.Overall, heuristic computed LM-cut algorithm standard delete relaxation + dominates computed C Cce , terms informativenessterms coverage. first two columns Table 6 show large majoritydomains, search using LM-cut computed C Cce performs many heuristicevaluations tasks solved configurations. Airport domain,instance, LM-cut standard delete relaxation requires approximately 50 times fewerheuristic evaluations solve set tasks either C Cce . domains, situation less extreme, standard delete relaxation continues givebetter heuristic estimates. exceptions Blocksworld, Elevators, Floortile,FreeCell, Grid, Mprime, Mystery, Pegsol, PSR, Transport Woodworking domains,+least one C Cce yields informative heuristic estimates .impressively, C Cce give estimates respectively 19 14 times informative estimates obtained + Floortile domain, estimates usingC 13 times informative + Mprime domain. termscoverage, translates 12 tasks solved C Cce Floortile domain,compared 7 standard version LM-cut, 28 tasks solved C521fiKeyder, Hoffmann, & HaslumMprime domain, compared 22. Mystery domain, coverage increased 1.domains, coverage achieved C Cce -based LM-cut less equalcoverage achieved standard LM-cut. Overall, standard version LM-cutsolves 589 planning tasks compared 445 C 418 Cce . Though large partdifference (90 tasks) comes Miconic domain, difference remainingdomains still significant.Comparing C Cce , seen additional loss information resultingtreatment conditional effects LM-cut leads worse heuristic estimatesCusing Cce . expected theoretical result ce grows linearlynumber -fluents, number -fluents added task usingCCce compilation almost always higher using . However treatmentconditional effects LM-cut (described above) turns greatly degrade performance,CLM-cut using Cce informative LM-cut using 4 domains.6.3.2 Admissible Landmark Heuristics Cce Landmarksadmissible landmark heuristic, hLM , uses action cost partitioning derive heuristicvalues collection (ordered) landmarks, distributing cost actionset landmarks achieves (Karpas & Domshlak, 2009). Cost partitioning donedifferent ways: optimal cost partitioning tractable, yields best possible heuristicvalue given set landmarks, practice slow coverage suffers; uniformpartitioning generally achieves better time/informativeness trade-off, therefore bettercoverage.evaluate potential informativeness landmarks obtained Cce usingiterative technique described Section 6.2, used landmarks optimal costpartitioning setting, since setting makes best possible use information presentgiven landmarks. compared informativeness heuristic usinglandmarks obtained compilation = 1 = 2 soundcomplete landmark generation algorithm (Keyder et al., 2010). results shownfirst two columns Table 7. show ratio total number heuristic evaluations,per domain, tasks solved configurations, hLM using landmarks 1heuristic using landmarks 2 Cce , respectively. Note landmarks2 compilations contain landmarks obtained 1generated Ccesubset, hLM optimal partitioning 2 Cce landmarks thereforedominates hLM optimal partitioning 1 landmarks. Hence ratio alwaysgreater 1.9 35 domains considered, neither addition 2 landmarks Cce landmarks leads informative heuristic (cases columns show value 1).remaining 26 domains, schemes improve 1 landmarks equal degree7, 2 improves 1 greater degree Cce 17. one case, Blocksworld,Clandmarksmuchinformativelandmarksfound methceods, improve informativeness baseline heuristic using 1 landmarksfactor 122.Uniform cost partitioning divides cost action evenly set landmarksachieves, rather searching partitioning maximizes heuristic value522fiImproving Delete Relaxation Heuristics Explicit ConjunctionsDomainAirportBarman-optBlocksworldDepotsDriverlogElevators-opt11Floortile-opt11FreeCellGridGripperLogistics00Logistics98MiconicMprimeMysteryNomystery-opt11Openstacks-opt11Parcprinter-opt11Parking-opt11Pathways-nonegPegsol-opt11Pipes-NoTankPipes-TankPSRRoversSatelliteScanalyzer-opt11Sokoban-opt11Tidybot-opt11TPPTransport-opt11TrucksVisitall-opt11Woodwork-opt11ZenotravelTotalInformativenessCoverage(optimal partitioning) (uniform partitioning)2C12Ccece1.031.0327112744425.65122.312628324.281.117771.021.0110991.541.541212123.281.022221.321.016038391.121.122221176713.6513.652022221.251.253333.913.911421421431.3912020202.1711515153.081.6920201811127114.091108109.841300114441.2511715171.371.271616161.641.131310112.681.23494949116651.061.066661.541.016361.0212014181.181.05149141166611666118671116993.041.1674511888604527570Table 7: hLM landmarks generated delete relaxation (1 ), 2 (Keyder et al., 2010)Cce . two columns left show ratio summed number heuristic evaluationstasks solved configurations, comparing 2 Cce baseline using landmarks1 . Using optimal cost partitioning hLM , landmarks yield better lower bounds,indeed ratios 1 (which use : 1 presentation, differentlyprevious tables). right-most three columns show coverage, using uniform cost partitioning.heuristic uniform partitioning solves tasks optimal cost partitioninglandmark generation schemes considered. Entries bold indicate best results, per domaintotal.523fiKeyder, Hoffmann, & Haslumstate. make hLM heuristic weaker, though typically much,also makes much faster compute, leading better coverage general. confirmeduniform cost partitioning results higher coverage optimal cost partitioningdomains three landmark generation schemes considered.three right-most columns Table 7 show coverage achieved hLMthree landmark generation schemes setting. seen using 1 landmarks results greater coverage combining either 2 Cce landmarks.2CCompared heuristic using landmarks, using ce landmarks solve manytasks every domain except Nomystery Rovers domains. Cce landmarks outperform 1 landmarks two domains: Blocksworld, using Clandmarksplannercefinds optimal solutions 32 35 tasks, tested heuristic,Miconic, 1 instance. domains, use Cce landmarks either1effect worsens coverage compared . Interestingly, informativenessLM-cut heuristic increases greatly C Cce compilations Floortile domain, corresponding increase compilations used find landmarks.conjunctive landmarks, besides goal, found.7. Conclusions Open Questionslong tradition works attempting devise heuristics taking accountdelete effects. However, techniques rendering h+ perfect limit thus allowingsmoothly interpolate h+ h proposed quite recently,Haslum (2012) Katz et al. (2013) respectively. extended Haslums approachintroducing new compilation method linear (vs. worst-case exponential) growth,demonstrated machinery needed using approach generate heuristics.evaluation shows that, domains, informedness dramatically improvedsmall cost terms computational overhead.main open issue lies use words domains here.domains, gain informativeness small, domains overall performancesuffers dramatically. domain-independent planning technique work wellevery domain, simple portfolio approach (cf. column PF Table 4) sufficesimprove state art satisficing planning, extent per-domain performance variation technique dramatic. obtain understandingcauses phenomena, ultimately exploit understanding devise reliable/effective practical methods? unchanged worse performance many domainsdue fundamental limitations technique, due particular instantiation(especially selection -fluents) run experiments?practical perspective, answering questions comes explorationtechniques predicting impact adding -fluents, making informeddecisions -fluents add. observed changes domain formulation, random reorderings, small changes heuristic criteria used -fluentselection large impact heuristic informativeness coverage. research formulate new heuristic criteria improve existing ones therefore could,potentially, provide better performance across wide range domains. might also in524fiImproving Delete Relaxation Heuristics Explicit Conjunctionsteresting systematically explore impact random/arbitrary changes, attemptbuilding complementary-strength compilations combined effective portfolios.theoretical perspective, currently approaching questionsterms analyzing conditions small (polynomial-size) set -fluentssuffices render h+ perfect. Applied individual domains, analysis offers wayanswering question whether lack performance improvement dueessential limitation due choosing wrong set -fluents. hopeeventually obtain syntactic criteria (e. g., based causal graph structure)automatically applied arbitrary planning task descriptions, serving select -fluents(or exclude subsets -fluents consideration) targeted manner. firstresults direction already published HSDIP14 (Hoffmann, Steinmetz,& Haslum, 2014).observations optimal planning pose many questions future work. simple onewhether effective Cce landmarks could extracted restricting techniquesadding -fluents guaranteed landmarks. daunting challenges regardLM-cut. observations suggest methods use suffer greatly suboptimalchoices precondition choice functions (PCFs). would therefore worthwhile investigate new methods obtaining better PCFs. Another important direction developextensions LM-cut conditional effects guarantee admissibility domination hmax . simple yet impractical method multiply conditional effects(enumerating subsets thereof). sophisticated method based context splitting, distinctions different occurences action introducedtargeted manner necessary, recently proposed (Roger, Pommerening,& Helmert, 2014).summary, explicitly represented conjunctions clearly exhibit potential dramatically improve delete relaxation heuristics. much remains done orderunderstand use effectively.AcknowledgmentsPart work leading publication carried Emil Keyder JorgHoffmann working INRIA Grand Est, Nancy, France. NICTA fundedAustralian Government Department Communications AustralianResearch Council ICT Centre Excellence Program. thank UniversityFreiburg allowing us use computional resources.Appendix A. ProofsTheorem 3 (h+ (C ) dominates h+ (Cce )) Given planning task set con+C+Cjunctions C, h ( ) h (ce ). cases inequality strict.Proof: follows fact plan C also plan Cce , yetCn plan C .1inverse case. show first part, let = haC,...,n1show sequence actions constitutes plan Cce , showingCn ] C [aC , . . . , aC ] , I[. . . ]1induction C [aC,...,denotesresultcenn ce11525fiKeyder, Hoffmann, & Haslumapplying sequence actions initial state C Cce . Since goal tasksdefined GC , shows desired result. base case, initial stateCC Cce , subset relation holds. inductive case, assumeCi1C1CCCCC[a1 , . . . , ai1 ] [aC1 , . . . , ai1 ]ce . Since precondition ai ce subsetCCC CCprecondition aCCi , ai applied [a1 , . . . , ai1 ]ceCinduction hypothesis. need show fluents added aCalsoCiCC CCCadded aCce applied [a1 , . . . , ai1 ]ce . add effect ai consistsCunion two sets, (add(a) (pre(a) \ del(a))) , also add effect aCCiC0C0ce therefore added, {c | c Ci }. Since ai applicable ,Ci11preconditions (pre(a) c0 Ci (c0 \add(a)))C must true C [aC1 , . . . , ai1 ], thereforeC0C [aC1 , . . . , ai1 ]ce , induction hypothesis. c C (and therefore c Ci , CiCCC), aCce conditional effect effect c condition (pre(a) (c \ add(a))) ,CiCapplies condition subset precondition ai . showsdesired property.strictness, consider planning task fluent set F = {p1 , p2 , r, g1 , g2 }, initialstate = {p1 }, goal G = {g1 , g2 }, actionsap2 : h{p1 }, {p2 }, {r, p1 }, ar : h, {r}, ,ag1 : h{p1 , r}, {g1 }, , ag2 : h{p2 , r}, {g2 }, ,Let C = {c F | |c| = 2}. optimal plan C sequencehar , ag1 , ap2 , ar , ag2 i. case C follows fact plan must includeag1 ag2 actions achieving two goals, therefore must achieveprecondition -fluents {p1 ,r} {p2 ,r} , respectively. -fluentsachieved ar , action achieves either p fluents without deletingr. single representative ar achieves {p1 ,r} {p2 ,r} ,representative would precondition {p1 ,p2 } , unreachable, sinceaction achieving p2 deletes p1 . plan C therefore must contain ag1 , ag2 , least twoinstances ar , ap2 .longer holds, however, considering Cce , action sequencehap2 , ar , ag1 , ag2 plan contains 4 actions. Cce , two possible -fluentsadded ar , {p1 ,r} {p2 ,r} , treated independently, separate conditional effectcreated each, conditions p1 p2 respectively. p1 p2achieved separately, single application action ar sufficient achievetwo -fluents, without making true (unreachable) cross-context -fluent {p1 ,p2 } .similar cases, exist plans Cce shorter minimum length plansC .Given STRIPS task = hF, A, I, G, costi, h1 heuristic set P fluents,defined follows (Bonet & Geffner, 2001):0p1h (p) =min{a|padd(a)} h1 (pre(a)) + cost(a) otherwiseh1 (P ) = max h1 (p)pP526fiImproving Delete Relaxation Heuristics Explicit Conjunctionsvalue heuristic given planning task taken h1 cost goalG, h1 () = h1 (G).Lemma 1 Given planning task C = {c P(F ) | 1 < |c| m}, h1 (C ) = h1 (m ).Proof: Let = hF, A, I, Gi. C identical except action sets.denote action set AC (m ) C AC (C ). deletesconditional effects either AC (m ) AC (C ), ignorefollows.first show h1 (C ) h1 (m ), h1 (m ) h1 (C ). directionbased following two observations. First, STRIPS planning task,split actions singleton add effects, without affecting h1 . Precisely, givenaction p add(a) \ pre(a), denote a[p] action pre(a[p]) = pre(a)add(a[p]) = {p}. Replacing split-up actions a[p] (i. e. generatingsplit-up action a[p] every non-redundant add effect a), h1 remains same. Second,say every split-up action a[p] action set dominated action a0 action setA0 , i. e., pre(a0 ) pre(a[p]) add(a0 ) add(a[p]). h1 using A0 lower boundh1 using A.prove h1 (C ) h1 (m ). every c F 1 < |c| m,del(a) c = , add(a) c 6= , AC (m ) contains action ac given pre(ac ) =(pre(a) (c \ add(a)))C , add(ac ) = add(a) {c0 | c0 C c0 (add(a) c)}. Let0p add(ac ). p add(a), aC C 0 = dominates ac [p]. Say p = c0c0 6 pre(ac ). obtain dominating action AC (C ), define:C 0 := {c00 C | del(a) c00 = , add(a) c00 6= , c00 c0 }C 0 C, c00 C 0 conditions (1) del(a) c00 = add(a) c00 6=(2) c C : ((c c00 add(a) c 6= ) = c C 0 ) Definition 2obviously satisfied.00Thus AC (C ) contains action aC given pre(aC ) = (pre(a) c00 C 0 (c00 \ add(a)))C0add(aC ) = (add(a) (pre(a) \ del(a)))C {c00 | c00 C 0 }. prove (a)00pre(aC ) pre(ac ) (b) p = c0 add(aC ).Regarding (a), every c00 C 0c00 \ add(a) c0 \ add(a) c \ add(a), thus c00 C 0 (c00 \ add(a)) c0 \ add(a) c \ add(a).Regarding (b), need prove c0 C, del(a)c0 = , add(a)c0 6= , c0 c0 .first last properties obvious, second one direct construction.third one, add(a) c0 6= , true otherwise would c0c \ add(a) implying contradiction construction c0 pre(ac ).remains prove h1 (m ) h1 (C ). every C 0 C conditions00(1) (2) stated above, AC (C ) contains action aC . Let p add(aC ). p-fluent, either p add(a) p pre(a) \ del(a). latter case irrelevant (and0split-up action generated); former case, setting c := add(a) get aC [p]dominated ac AC (m ). Say p = c . least one following casesmust hold: (a) c C 0 (b) c (pre(a) \ del(a)) (c) c (add(a) (pre(a) \ del(a)))c add(a) 6= . case (a), follows directly definition ac AC (m )00dominates aC [p]. case (b), p = c pre(aC ) case irrelevant. case (c),0c add(a) 6= c del(a) = ac AC (m ) dominates aC [p].concludes proof.527fiKeyder, Hoffmann, & HaslumLemma 2 Given planning task set non-unit conjunctions C, h1 (C )h+ (Cce ).CProof: Consider planning task Cno-cc identical exceptinclude cross-context preconditions. is, precondition action representative0aC modified following:0pre(aC ) = pre(a)C[(pre(a) (c0 \ add(a)))Cc0 C 01C+Cshow (A) h1 (C ) h1 (Cno-cc ), (B) h (no-cc ) h (ce ).first prove (A). proof Lemma 1, suffices prove that, every split0Caction aC [p] Cno-cc , exists dominating action . p -fluent,000aC C C 00 = dominates aC [p]. Otherwise, say p = c0 . least onefollowing cases must hold: (a) c0 C 0 (b) c0 (add(a) (pre(a) \ del(a))). case (b),000aC C C 00 = dominates aC [p]. case (a), obtain dominating action00aC C , defineC 00 := {c00 C | del(a) c00 = , add(a) c00 6= , c00 c0 }c00 C 00 satisfy conditions (1) del(a) c00 = add(a) c00 6= (2) c C :00((c c00 add(a) c 6= ) = c C 0 ) Definition 2, indeed aC action C .0000obviously c0 C 00 thus p add(aC ). remains prove pre(aC )0pre(aC [p]). so, intuitively, C 00 corresponds single conjunction c0 (plussubsumed conjunctions) hence cross-context fluents arise.S Specifically, every00c00 C 00 c00 \add(a) c0 \add(a). Thus pre(aC ) = (pre(a) c00 C 00 (c00 \add(a)))C =0(pre(a) (c0 \ add(a)))C . latter obviously contained pre(aC [p]), concludingproof (A).+C+Cremains prove (B). Since h1 (Cno-cc ) h (no-cc ), suffices prove h (no-cc )+C+Ch (ce ). Consider state s, relaxed plan ce ce . action ace+ , representing action original task , let C 0 set conjunctions c whosece+ C . C 0 obviously qualifies-fluents added ace execution cececonstraint (1) Definition 2; qualifies constraint (2) conditional effectc property triggered ace conditional effect suitable c0C 0 a. Define action sequence +triggered. Thus Cno-cc includes representativeC 0 + adds fluents ,C0Cceno-cc sequence . Obviously,precondition union ace conditional effects fire. Thus+C+C+ relaxed plan Cno-cc . follows h (no-cc ) h (ce ) desired.Example 4 Consider STRIPS planning task variables {i, p, q, r, z, g1 , g2 , g3 },initial state = {i}, goal G = {g1 , g2 , g3 }, actions follows:528fiImproving Delete Relaxation Heuristics Explicit ConjunctionsNamepreadd del ce costaqz{i}{q,z}4ari{i}{r}1pz{i, q}{p} {z}1aiqapz{r}{p}{z}4rg1{p, z} {g1 }1apzagiq2{i, q} {g2 }1g3ar{r} {g3 }1set C = {{i, q}, {p, z}}. operator adding part {i, q} aqzadds q.qzpz pzoperators adding part {p, z} ai adds z, aiq , ar add p;pzsince aiqapzdelete z, cannot used establish conjunction {p, z}.rThus actions Cce are:Namepreadd delce costqzqzai{i} {q, z}ce(ai )4ari{i}{r}1{i,q,}{p}1apzi,qiqpzar{r}{p}4{p, z, p,z } {g1 }1agpz1g2aiq{i, q, i,q } {g2 }1{r} {g3 }1agr3ce(aqz) contains two conditional effects:Namecadd deli,qei{i} {i,q }ep p,z{p} {p,z }pzClearly, respect hmax , -fluents preconditions aiq, agpz1 , agiq2 dominate respective preconditions actions (as pointed Section 5.1,implementation actually remove preconditions). Thus LM-cuts justificationgraph Cce would structure shown Figure 5.+Chmax (Cce ) = 10 due cost achieving g1 . h (ce ), constructqz pzplan Cce choice establish p. use ai , aiq ,use ari , apzr . latter case, make single application conditionalg2 g3r pz qz g1effects action aqz, relaxed plan 1 = hai , ar , ai , apz , aiq , ar i, whose cost 12.qzformer case, must use ai twice first i,q , p,z yielding relaxedpz qz g1g2 r g3+Cplan 2 = haqz, aiq , ai , apz , aiq , ai , ar i, whose cost 13. Thus h (ce ) = 12. Since,pzexecution 1 , delete ar , true anyhow stateexecution, 1 also solves original task get h () = h+ (Cce ) = 12.consider LM-cut, say produced cut conditional-effects actionp,zaqzconnects p p,z via conditional effect ep . two options discussedSection 6.1 (A) reduce cost aqzglobally, sticking original definitionLM-cut; (B) reduce cost ep p,z , conditional effect ei i,qp,zpart optimal-cost path ep thus serves justify hmax value.options violates one essential properties LM-cut:529fiKeyder, Hoffmann, & Haslumzpi,qaqz: eiaqzqaqz:ei i,q:rarg3p,zapziqei i,qi,qapzrarip,zaqz: epagiq2agpz1g1g2g3Figure 5: Illustration LM-cut justification graphs Cce Example 4. dashededges correspond preconditions critical (hmax -maximizing) start,become critical point execution LM-cut.p,z(A) configuration, LM-cut produces cuts {agpz1 } [cost 1], {aqz: ep } [cost 4],pz pzg2[cost 1], {ar , aiq } [cost 1], {aiq } [cost 1], {ari } [cost 1]. Note that,i,qp,zqzqzcut {aqz: ep }, cost ai reduced 0 globally; particular, cut {ai : ei }produced. get heuristic value hLM-cut = 9 < hmax (Cce ) = 10, LM-cutdominate hmax .(B) configuration, LM-cut produce following cuts. start, everyp,zpossible precondition choice function (pcf ), get cuts {agpz1 } [cost 1] {aqz: ep }[cost 4]. hmax 5 g1 , g2 ; say pcf selects g2 , get cut {agiq2 }pzmax 4[cost 1]. Now, pcf select g1 , getting cut {apzr , aiq } [cost 1]. Then, hg1g1 , g2 ; say pcf selects g1 . Say pcf selects p,z apz (anotherchoice would z), selects i,q apz(another choice would q), thus remainingiqi,q pznon-dashed part Figure 5. get cut {aqz: ei , ar } [cost 3]g1 reached 0 cost p i,q (we would get cut pcfselecting g1 , point). Now, hmax 2 g3 1 g1 , g2 , get cut{agr3 } [cost 1]. point, hmax 1 goal facts; say LM-cut selects g3 , thusget cut {ari } [cost 1] way achieve r. finally hmaxi,q1 g2 only, yielding cut {aqz: ei } [cost 1]. Overall, get heuristic valuehLM-cut = 13 > h () = h+ (Cce ) = 12, LM-cut admissible.{agr3 }BibliographyBaier, J. A., & Botea, A. (2009). Improving planning performance using low-conflict relaxedplans. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings530fiImproving Delete Relaxation Heuristics Explicit Conjunctions19th International Conference Automated Planning Scheduling (ICAPS09),pp. 1017, Thessaloniki, Greece. AAAI Press.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artificial Intelligence, 129 (12), 533.Bonet, B., & Helmert, M. (2010). Strengthening landmark heuristics via hitting sets.Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19th EuropeanConference Artificial Intelligence (ECAI10), pp. 329334, Lisbon, Portugal. IOSPress.Bonet, B., Palacios, H., & Geffner, H. (2009). Automatic derivation memoryless policiesfinite-state controllers using classical planners. Gerevini, A., Howe, A., Cesta,A., & Refanidis, I. (Eds.), Proceedings 19th International Conference Automated Planning Scheduling (ICAPS09), pp. 3441, Thessaloniki, Greece. AAAIPress.Bylander, T. (1994). computational complexity propositional STRIPS planning.Artificial Intelligence, 69 (12), 165204.Cai, D., Hoffmann, J., & Helmert, M. (2009). Enhancing context-enhanced additiveheuristic precedence constraints. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings 19th International Conference Automated PlanningScheduling (ICAPS09), pp. 5057, Thessaloniki, Greece. AAAI Press.Do, M. B., & Kambhampati, S. (2001). Sapa: domain-independent heuristic metric temporal planner. Cesta, A., & Borrajo, D. (Eds.), Recent Advances AI Planning. 6thEuropean Conference Planning (ECP01), Lecture Notes Artificial Intelligence,pp. 109120, Toledo, Spain. Springer-Verlag.Fox, M., & Long, D. (2001). STAN4: hybrid planning strategy based subproblemabstraction. AI Magazine, 22 (3), 8184.Garey, M. R., & Johnson, D. S. (1979). Computers IntractabilityA GuideTheory NP-Completeness. Freeman, San Francisco, CA.Gazen, B. C., & Knoblock, C. (1997). Combining expressiveness UCPOPefficiency Graphplan. Steel, S., & Alami, R. (Eds.), Recent Advances AIPlanning. 4th European Conference Planning (ECP97), Lecture Notes ArtificialIntelligence, pp. 221233, Toulouse, France. Springer-Verlag.Gerevini, A., Saetti, A., & Serina, I. (2003). Planning stochastic local searchtemporal action graphs. Journal Artificial Intelligence Research, 20, 239290.Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Chien, S.,Kambhampati, R., & Knoblock, C. (Eds.), Proceedings 5th International Conference Artificial Intelligence Planning Systems (AIPS00), pp. 140149, Breckenridge, CO. AAAI Press.Haslum, P. (2009). hm (P ) = h1 (P ): Alternative characterisations generalisationhmax hm . Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.), Proceedings 19th International Conference Automated Planning Scheduling(ICAPS09), pp. 354357, Thessaloniki, Greece. AAAI Press.531fiKeyder, Hoffmann, & HaslumHaslum, P. (2012). Incremental lower bounds additive cost planning problems.Bonet, B., McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22ndInternational Conference Automated Planning Scheduling (ICAPS12), pp.7482, Sao Paulo, Brasil. AAAI Press.Helmert, M. (2006). Fast Downward planning system. Journal Artificial IntelligenceResearch, 26, 191246.Helmert, M., & Domshlak, C. (2009). Landmarks, critical paths abstractions: Whatsdifference anyway?. Gerevini, A., Howe, A., Cesta, A., & Refanidis, I. (Eds.),Proceedings 19th International Conference Automated Planning Scheduling (ICAPS09), pp. 162169, Thessaloniki, Greece. AAAI Press.Helmert, M., & Geffner, H. (2008). Unifying causal graph additive heuristics.Rintanen, J., Nebel, B., Beck, J. C., & Hansen, E. (Eds.), Proceedings 18thInternational Conference Automated Planning Scheduling (ICAPS08), pp.140147, Sydney, Australia. AAAI Press.Hoffmann, J. (2005). ignoring delete lists works: Local search topology planningbenchmarks. Journal Artificial Intelligence Research, 24, 685758.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. Journal Artificial Intelligence Research, 14, 253302.Hoffmann, J., Porteous, J., & Sebastia, L. (2004). Ordered landmarks planning. JournalArtificial Intelligence Research, 22, 215278.Hoffmann, J., Steinmetz, M., & Haslum, P. (2014). take render h+ ( c )perfect?. Proceedings 6th Workshop Heuristics Search DomainIndependent Planning, ICAPS14.Karpas, E., & Domshlak, C. (2009). Cost-optimal planning landmarks. Boutilier, C.(Ed.), Proceedings 21st International Joint Conference Artificial Intelligence(IJCAI09), pp. 17281733, Pasadena, California, USA. Morgan Kaufmann.Katz, M., Hoffmann, J., & Domshlak, C. (2013). said need relax variables?.Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings23rd International Conference Automated Planning Scheduling (ICAPS13),pp. 126134, Rome, Italy. AAAI Press.Keyder, E., & Geffner, H. (2008). Heuristics planning action costs revisited.Ghallab, M. (Ed.), Proceedings 18th European Conference Artificial Intelligence (ECAI08), pp. 588592, Patras, Greece. Wiley.Keyder, E., & Geffner, H. (2009). Trees shortest paths vs. Steiner trees: Understandingimproving delete relaxation heuristics. Boutilier, C. (Ed.), Proceedings21st International Joint Conference Artificial Intelligence (IJCAI09), pp. 17341749, Pasadena, California, USA. Morgan Kaufmann.Keyder, E., Hoffmann, J., & Haslum, P. (2012). Semi-relaxed plan heuristics. Bonet, B.,McCluskey, L., Silva, J. R., & Williams, B. (Eds.), Proceedings 22nd International Conference Automated Planning Scheduling (ICAPS12), pp. 128136,Sao Paulo, Brasil. AAAI Press.532fiImproving Delete Relaxation Heuristics Explicit ConjunctionsKeyder, E., Richter, S., & Helmert, M. (2010). Sound complete landmarks And/Orgraphs. Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings 19thEuropean Conference Artificial Intelligence (ECAI10), pp. 335340, Lisbon, Portugal. IOS Press.Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planningproblems bounded width. Journal Artificial Intelligence Research, 35, 623675.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytimeplanning landmarks. Journal Artificial Intelligence Research, 39, 127177.Roger, G., Pommerening, F., & Helmert, M. (2014). Optimal planning presenceconditional effects: Extending LM-Cut context-splitting. Schaub, T. (Ed.),Proceedings 21st European Conference Artificial Intelligence (ECAI14),Prague, Czech Republic. IOS Press. appear.533fiJournal Artificial Intelligence Research 50 (2014) 1-30Submitted 12/13; published 05/14Topic-Based Dissimilarity Sensitivity ModelsTranslation Rule SelectionMin ZhangMINZHANG @ SUDA . EDU . CNProvincial Key Laboratory Computer Information Processing Technology,Soochow University, Suzhou, ChinaXinyan XiaoXIAOXINYAN @ ICT. AC . CNIIP Key Lab, Institute Computing Technology,Chinese Academy Sciences, ChinaDeyi XiongDYXIONG @ SUDA . EDU . CNProvincial Key Laboratory Computer Information Processing Technology,Soochow University, Suzhou, ChinaQun LiuLIUQUN @ ICT. AC . CNCNGL, School Computing, Dublin City University, IrelandIIP Key Lab, Institute Computing Technology,Chinese Academy Sciences, ChinaAbstractTranslation rule selection task selecting appropriate translation rules ambiguoussource-language segment. translation ambiguities pervasive statistical machine translation, introduce two topic-based models translation rule selection incorporates globaltopic information translation disambiguation. associate synchronous translation rulesource- target-side topic distributions.With topic distributions, propose topicdissimilarity model select desirable (less dissimilar) rules imposing penalties ruleslarge value dissimilarity topic distributions given documents. order encourage use non-topic specific translation rules, also present topic sensitivity modelbalance translation rule selection generic rules topic-specific rules. Furthermore,project target-side topic distributions onto source-side topic model space benefittopic information source target language. integrate proposed topic dissimilarity sensitivity model hierarchical phrase-based machine translation synchronoustranslation rule selection. Experiments show topic-based translation rule selection modelsubstantially improve translation quality.1. IntroductionTranslation rules bilingual segments1 establish translation equivalences sourcetarget language. widely used statistical machine translation (SMT) various representations ranging word pairs bilingual phrases synchronous rules word-, phraseand syntax-based SMT respectively. Normally, large number translation rules learntbilingual training data single source segment occurs different contexts.example, Xiong, Zhang, Li (2012) observe Chinese verb translated1. segment defined string terminals and/or nonterminals.c2014AI Access Foundation. rights reserved.fiZ HANG , X IAO , X IONG , & L IU140 different translation rules average. Therefore select appropriate translationrule ambiguous source segment crucial issue SMT.Traditionally appropriateness translation rule measured multiple probabilitiesestimated word-aligned data, bidirectional translation probabilities (Koehn, Och, &Marcu, 2003). probabilities fail capture local global contexts highly ambiguoussource segments, sufficient select correct translation rules segments. Therefore various approaches proposed capture rich contexts sentence level helpselect proper translation rules phrase- (Carpuat & Wu, 2007a) syntax-based SMT (Chan, Ng,& Chiang, 2007; He, Liu, & Lin, 2008; Liu, He, Liu, & Lin, 2008). studies show localfeatures, surrounding words, syntactic information on, helpful translation ruleselection.Beyond contextual features sentence level, conjecture translation rulesalso related high-level global information, topic (Hofmann, 1999; Blei, Ng, & Jordan,2003) information document level. order visualize relatedness translationrules document topics, show four hierarchical phrase-based translation rules topicdistributions Figure 1. figure, observeFirst, translation rules divided two categories terms topic distributions:topic-sensitive rules (i.e., topic-specific rules) topic-insensitive rules (i.e., non-topic specific generic rules). former rules, e.g., translation rule (a), (b) (d) Figure1, much higher distribution probabilities specific topics topics.latter rules, e.g., translation rule (c) Figure 1, even distribution topics.Second, topic information used disambiguate ambiguous source segments. Figure1, translation rule (b) (c) source segment. However topic distributionsquite different. Rule (b) distributes topic international relationshighest probability, suggests rule (b) much related topictopics. contrast, rule (c) even distribution topics. Therefore documentinternational relations, rule (b) appropriate rule (c) sourceX1 .segmenttwo observations suggest different translation rules different topic distributionsdocument-level topic information used benefit translation rule selection.article, propose framework translation rule selection exactly capitalizesdocument-level topic information. proposed topic-based translation rule selection frameworkassociates translation rule topic distribution (rule-topic distribution) sourcetarget side. source document also annotated corresponding topic distribution(document-topic distribution). Dissimilarity document-topic distribution rule-topicdistribution calculated used help select translation rules related documentsterms topics. particular,Given document translated, use topic dissimilarity model calculate dissimilarity translation rule document based topic distributions.translation system penalize candidate translations high dissimilarities.22. Section 6 explains system penalizes candidate translations high dissimilarities.2fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELS0.60.60.40.40.20.20U operational capability1(a)51015202503010.60.60.40.40.20.2015(c)X10101520255(b)301give X1(d) X1X10151 ! X52025302530grants X111021520held talks X1 X2Figure 1: Four synchronous rules topic distributions. sub-graph shows ruletopic distribution, X-axis shows topic index Y-axis topic probability. Notably, rule (b) rule (c) shares source Chinese string,different topic distributions due different English translations.dissimilarity topic-insensitive translation rule given source documentcomputed topic dissimilarity model often high documents normallytopic-sensitive. dont want penalize generic topic-insensitive rules. Thereforepropose topic sensitivity model rewards topic-insensitive rulescomplement topic dissimilarity model.associate translation rule rule-topic distribution source target side. order calculate dissimilarity target-side rule-topic distributionstranslation rules source-side document-topic distributions given documentsdecoding, project target-side rule-topic distributions translation rules onto spacesource-side document topic model one-to-many mapping.use hierarchical phrase-based SMT system (Chiang, 2007) validate effectivenesstopic-based models translation rule selection. Experiments Chinese-English translationtasks (Section 7) show method outperforms baseline hierarchial phrase-based system+1.2 B LEU points large-scale training data.use topic-based dissimilarity sensitivity models improve SMT first presentedprevious paper (Xiao, Xiong, Zhang, Liu, & Lin, 2012). article, providedetailed comparison related work formulations two models well integration3fiZ HANG , X IAO , X IONG , & L IUprocedure. importantly, carry large-scale experiments bilingual monolingual training data incorporate detailed analysis output topic-based dissimilaritysensitivity models document translation hypothesis level.rest article organized follows. Section 2 introduces related work. Section 3provides background knowledge statistical machine translation topic modeling. Section 4elaborates topic-based translation rule selection framework, including topic dissimilaritytopic sensitivity model. Section 5 discusses estimate rule-topic document-topic distributions project target-side rule-topic distributions onto source-side topic spaceone-to-many mapping fashion. Section 6 presents integration topic-based translation ruleselection models hierarchical phrase-based SMT. Section 7 describes series experimentsverify effectiveness approach. Section 8 provides detailed analysis outputmodels. Section 9 gives suggestions bilingual topic modeling perspectivemachine translation. Finally, conclude Section 10 future directions.2. Related Worktopic-based dissimilarity sensitivity models translation rule selection related threecategories work SMT: translation rule selection, topic models SMT document-leveltranslation. section, introduce related approaches three categories highlightdifferences method previous work.2.1 Translation Rule Selectionmentioned before, translation rule selection important task SMT. Several approaches proposed recently. Carpuat Wu explore word phrase sensedisambiguation (WSD PSD) translation rule selection phrase-based SMT (Carpuat & Wu,2007a, 2007b). WSD PSD system integrate sentence-level local collocation features. Experiments show multi-word PSD improve phrase selection. Also following WSD line,Chan et al. (2007) integrate WSD system hierarchical phrase-based SMT lexical selectionselection short phrases length 1 2. WSD system also adopts sentence-levelfeatures local collocations, surrounding words on.Different lexical phrasal selection using WSD/PSD, et al. (2008) propose maximum entropy (MaxEnt) based model context-dependent synchronous rule selection hierarchical phrase-based SMT. Local context features phrase boundary words part-of-speechinformation incorporated model. Liu et al. (2008) extends selection methodet al. integrate similar MaxEnt-based rule selection model tree-to-string syntax-basedSMT system (Liu, Liu, & Lin, 2006). model uses syntactic information source parsetrees features.significant difference topic-based rule selection framework previous approaches translation rule selection use global topic information help select translation rules ambiguous source segments rather sentence-level local context features.2.2 Topic Models SMTTopic modeling (Hofmann, 1999; Blei et al., 2003) popular technique discovering underlyingtopic structures documents. Recent years witnessed topic models explored4fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSSMT. Zhao Xing (2006, 2007) Tam, Lane, Schultz (2007) proposed topicspecific lexicon translation adaptation models improve translation quality. models focusword-level translations. first estimate word translation probabilities conditioned topics,adapt lexical translation probabilities phrases topic-conditioned probabilities. Sincemodern SMT systems use synchronous rules bilingual phrases translate sentences, believereasonable incorporate topic models phrase synchronous rule selectionlexical selection.Gong, Zhang, Zhou (2010) adopt topic model filter phrase pairs consistent source documents terms topics. assign topic documenttranslated. Similarly, phrase pair also assigned one topic. phrase pairdiscarded topic mismatches document topic. differences work twofold.First, calculate dissimilarities translation rules documents based topic distributions instead comparing best topics assigned translation rules documents.Second, integrate topic information SMT soft-constraint manner via topic-basedmodels. explore topic information hard-constraint fashion discarding translation rulesunmatched topics.Topic models also used domain adaptation translation language models SMT.Foster Kuhn (2007) describe mixture model approach SMT adaptation. dividetraining corpus different domains, used train domain-specific translationmodel. decoding, combine general domain translation model specific domaintranslation model selected according various text distances calculated topic model.Tam et al. (2007) Ruiz Federico (2011) use bilingual topic model project latent topicdistributions across languages. Based bilingual topic model, apply source-side topicweights onto target-side topic model adapt target-side n-gram language model.2.3 Document-Level Machine TranslationSince incorporate document topic information SMT, work also related documentlevel machine translation. Tiedemann (2010) integrates cache-based language translation models built recently translated sentences SMT. Gong, Zhang, Zhou (2011)extend cache-based approach introducing two additional caches: static cache storesphrases extracted documents training data similar document questiontopic cache target language topic words. Xiao, Zhu, Yao, Zhang (2011) try solvetranslation consistency issue document-level translation introducing hard constraintambiguous source words required consistently translated frequent translation options. Ture, Oard, Resnik (2012) soften consistency constraint integrating threecounting features decoder. studies normally focus surface structure capture inter-sentence dependencies document-level machine translation explore topicstructure document document translation.3. Preliminariesestablish section background knowledge statistical machine translationtopic modeling. Although introduction short, sufficient understanding5fiZ HANG , X IAO , X IONG , & L IUSub-modelsPIlogP (ei |f )P1IlogP (f |ei )P1IlogPlex (ei |f )P1IlogPlex (f |ei )P1|e|logP (ei |e1 ...ei1 )PI11 log(ei , f )|e|Descriptionsdirect translation probabilitiesinverse translation probabilitiesdirect lexical translation probabilitiesinverse lexical translation probabilitieslanguage modelreordering modelword countrule countTable 1: widely-used sub-models statistical machine translation. numbertranslation rules used generate target sentence e given source sentencef . ei f target source side translation rule ri .topic-based dissimilarity sensitivity models try bridge gap topic modelingstatistical machine translation.3.1 Statistical Machine TranslationGiven source sentence f , SMT systems find best translation e among possible translations follows.hPexph(f,e)1hPe = argmax Pee exp1 hm (f, e )#)("X(1)hm (f, e)= argmax expe= argmaxem=1(X)hm (f, e)m=1hm (f, e) feature function defined source sentence f correspondingtransla-ihPPtion e, weight feature function. Since normalization e exp1 hm (f, e )constant possible translations e , need calculate decoding.weighted model equation (1) log-linear model. feature functions hm (f, e)also referred sub-models3 components log-linear model. Table 1,show widely-used feature functions SMT. easily factoredtranslation rules, facilitates application dynamic programming decoding.show proposed topic-based dissimilarity sensitivity models also easily factorizedSection 4.3. notation used want emphasize sub-model component log-linear model. Otherwisecall models, language model, reordering model on.6fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSlog-linear model SMT, sub-models trained separately combinedassumption independent other. associated weights tunedusing minimum error rate training (MERT) (Och, 2003) Margin Infused Relaxed Algorithm(MIRA) (Chiang, Marton, & Resnik, 2008). Note normalization factor equation (1)calculated training algorithms. algorithms directly optimizelog-linear model SMT towards translation quality measure BLEU. Feature weightsoptimized towards criteria Maximum Mutual Information (MMI) necessarilyoptimal respect translation quality (Och, 2003).integrate proposed two models log-linear model hierarchical phrasebased SMT system (Section 6) order validate effectiveness two models, providedetails hierarchical phrase-based SMT (Chiang, 2005) section. Translation ruleshierarchial phrase-based SMT synchronous context-free grammar rules, denotedfollows.X h, ,(2)X undifferentiated nonterminal, strings terminals nonterminals4source target side respectively, denotes one-to-one mapping nonterminalsnonterminals . rules automatically extracted word-aligned bilingualtraining data. addition rules, two special rules also introduced hierarchicalphrase-based SMT.hX1 , X1hS0 X1 , S0 X1(3)two rules used serially concatenate nonterminal Xs monotonic manner forminitial symbol S, start symbol grammar hierarchical phrase-based SMT.log-linear model hierarchical phrase-based SMT formulated follows.!Xlog(t(r)) + lm logPlm (e) + wp |e| + rp(4)w(D) = exprDderivation defined set triples (r, i, j), denotes applicationtranslation rule spans words j source side. number translation rulesD. probability translation rule r definedt(r) = P (|)1 P (|)2 Plex (|)3 Plex (|)4(5)lexical translation probabilities Plex (|) Plex (|) estimate probabilitieswords translate words word-by-word fashion (Koehn et al., 2003).3.2 Topic ModelingTopic modeling used discover topics occur collection documents. LatentDirichlet Allocation (LDA) (Blei et al., 2003) Probabilistic Latent Semantic Analysis (PLSA)4. order simplify decoder implementation, two nonterminals allowed hierarchical translationrules.7fiZ HANG , X IAO , X IONG , & L IU(Hofmann, 1999) topic models. LDA widely used topic model, exploitmine topics translation rule selection.LDA views document mixture various topics, probability distribution words. particularly, LDA works generative process follows.document Dj , sample document-topic distribution (per-document topic distribution) j Dirichlet distribution Dir(): j Dir();word wj,i Nj words document Dj ,Sample topic assignment zj,i Multinomial(j );Sample word wj,i Multinomial(zj,i ) zj,i per-topic word distribution topic zj,i drawn Dir().Generally speaking, LDA contains two groups parameters. first group parameterscharacterizes document-topic distributions (j ), record distribution documenttopics. second group parameters used topic-word distributions (k ), representtopic distribution words.Given document collection observed words w = {wj,i }, goal LDA inferencecompute values two sets parameters well latent topic assignmentsz = {zj,i }. inference complicated due latent topic assignments z. efficient inferencealgorithm proposed address problem Collapsed Gibbs Sampling (Griffiths& Steyvers, 2004), two sets parameters integrated LDA model,latent topic assignments z sampled P (z|w). obtain values z,estimate recovering posterior distributions given z w. Section 4,use two sets estimated parameters topic assignments words calculateparameters models.4. Topic-based Dissimilarity Sensitivity Modelssection, elaborate topic-based models translation rule selection, including topicdissimilarity model topic sensitivity model.4.1 Topic Dissimilarity ModelSentences translated accordance topics (Zhao & Xing, 2006, 2007; Tamet al., 2007). Take translation rule (b) Figure 1 example. source side rule(b) occurs document international relations, hope encourage application rule(b) rather rule (c). achieved calculating dissimilarity probabilitydistributions translation rule document topics.order calculate topic dissimilarity translation rule selection, associatesource target side translation rule rule-topic distribution P (z |r ),placeholder source side f target side e, r source target side translationrule r, z corresponding topic r . Therefore translation rule two rule-topicdistributions: P (zf |rf ) source side P (ze |re ) target side.8fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSSupposing K topics, two distributions represented K-dimension vector. k-th component P (z = k|r ) denotes probability topic k given r . sourceand target-side rule-topic distributions separately estimated training data. estimationmethod described Section 5, also discuss reason estimateseparate manner.Analogously, represent topic information document translated documenttopic distribution P (z|d), also K-dimension vector. k-th dimension P (z = k|d)topic proportion topic k document d. Different rule-topic distribution,document-topic distribution directly inferred off-the-shelf LDA tool.Based defined rule-topic document-topic distributions, measure dissimilarity translation rule document decide whether rule suitable documenttranslation. Traditionally, similarity two probability distributions calculated information measurements Jensen-Shannon divergence (Lin, 2006) Hellinger distance (Blei &Lafferty, 2007).adopt Hellinger distance (HD) measure topic dissimilarity, symmetric widely used comparing two probability distributions (Blei & Lafferty, 2007). Givenrule-topic distribution P (z |r ) document-topic distribution P (z|d), HD computedfollows.K p2XpP (z = k|d) P (z = k|r )(6)HD(P (z|d), P (z |r )) =k=1Let derivation defined Section 3.1. Let P(z|r) represent corresponding rule-topicdistributions rules D. topic dissimilarity model Dsim(P (z|d), P(z|r)) derivationdefined HD equation (6) followsXDsim(P (z|d), P(z|r)) =HD(P (z|d), P (z |r ))(7)rDObviously, larger Hellinger distance candidate translation yielded derivationdocument, larger dissimilarity them. topic dissimilarity modeldefined above, aim select translation rules similar document translatedterms topics.4.2 Topic Sensitivity Modelintroduce topic sensitivity model, lets revisit Figure 1. easily findprobability rule (c) distributes evenly topics. indicates insensitive topics,therefore applied topics. contrast, distributions three rulespeak topics. Generally speaking, topic-insensitive rule fairly flat distributiontopics, topic-sensitive rule sharp distribution topics.document typically focuses topics, sharp distribution topics.words, documents normally topic-sensitive. Since distribution topic-insensitiverule fairly flat, dissimilarity topic-insensitive rule topic-sensitive documentlow. Therefore, system proposed topic dissimilarity model punishtopic-insensitive rules.9fiZ HANG , X IAO , X IONG , & L IUHowever, topic-insensitive rules may preferable topic-sensitive rules neithersimilar given documents. document topic love, rule (b) (c)Figure 1 dissimilar document rule (b) relates international relations topicrule (c) topic-insensitive. Nevertheless, since rule (c) occurs frequently across varioustopics, prefer rule (c) rule (b) translate document love.address issue topic dissimilarity model, propose topic sensitivitymodel. model employs entropy based metric measure topic sensitivity rulefollowsKXP (z = k|r ) log(P (z = k|r ))(8)H(P (z |r )) =k=1According equation, topic-insensitive rule normally large entropy topicsensitive rule smaller entropy.Given derivation rule-topic distributions P(z|r) rules D, topic sensitivitymodel defined follows.XH(P (z |r ))(9)Sen(P(z|r)) =rDIncorporating topic sensitivity model topic dissimilarity model, enable SMTsystem balance selection topic-sensitive topic-insensitive rules. Given rules approximately equal values topic dissimilarity, prefer topic-insensitive rules.5. EstimationUnlike document-topic distributions directly learned LDA tools, need estimaterule-topic distributions translation rules. want exploit topic informationsource target language, separately train two monolingual topic models sourcetarget side, learn correspondences two topic models via word alignmentsbilingual training data.Particularly, adopt two rule-topic distributions translation rule: 1) source-siderule-topic distribution P (zf |rf ) 2) target-side rule-topic distribution P (ze |re ),defined Section 4.1. two rule-topic distributions estimated using trainedtopic models way (Section 5.1). Notably, source-language documents availabledecoding. order compute dissimilarity target-side rule-topic distributiontranslation rule source-side document-topic distribution given document needproject target-side rule-topic distribution translation rule onto space source-sidetopic model (Section 5.2).also establish alternative approaches estimation rule-topic distributions viamultilingual topic models (Mimno, Wallach, Naradowsky, Smith, & McCallum, 2009; Boyd-Graber& Blei, 2009) bilingual topic models also infer word-to-word alignments document pairs(Zhao & Xing, 2006, 2007). former multilingual topic models require documentsdifferent languages comparable terms content similarity. contrast, latter bilingualtopic models require documents parallel, i.e., translations other, captureword alignments.10fiT OPIC -BASED ISSIMILARITYZNENSITIVITY ODELSZWNZWZtopiccorrespondenceN1Zkktargetsource(a)WNLNwordalignmentNWWZZeJW1L1LkfJkkBtargetsource(a*)(b)(c)Figure 2: Graphical model representations (a) bilingual topic model, (b) polylingual topicmodel Mimno et al. (2009), (c) bilingual topic model Zhao Xing (2007)number parallel sentence pairs document, word alignmentsource target sentence. simplicity, display HMM transitionsamong word alignments a. Subfigure (a*) shows build topic correspondences source target language source target topics separately learnedshown (a).biggest difference method multilingual/bilingual topic modelsuse per-tuple topic distribution documents tuple. definetuple set documents different languages. per-tuple topic distribution similarper-document topic distribution. difference per-tuple topicdistribution shared documents tuple.Topic assignments words languages naturally connected since sampledtopic distribution. contrast, assume document source/targetside sampled document-specific distribution topics. Topic correspondences source target document learned projection via word alignments. visualizedifference Figure 2.Yet another difference models topic-specific lexicon translation modelZhao Xing (2007) use bilingual topics improve SMT word levelinstead rule level. Since synchronous rule rarely factorized individual words,believe reasonable incorporate topic model directly rule level ratherword level. Section 7.2.3, empirically compare model topic-specific lexicontranslation model.Tam et al. (2007) also construct two monolingual topic models parallel source targetdocuments. build topic correspondences source target documents enforcing one-to-one topic mapping constraint. project target-side topics onto spacesource-side topic model one-to-many fashion. Section 7.3.1, compare two differentmethods building topic correspondences.11fiZ HANG , X IAO , X IONG , & L IU5.1 Rule-Topic Distribution Estimationestimate rule-topic distributions word-aligned bilingual training corpus documentboundaries explicitly given. source- target-side rule-topic distributions estimatedway. Therefore, simplicity, describe estimation source-side rule-topicdistribution P (zf |rf ) translation rule section.estimation rule-topic distributions analogous traditional estimation rule translation probabilities (Chiang, 2007). addition word-aligned corpus, input rule-topicdistribution estimation also contains source-side document-topic distributions inferred LDA tool.first extract translation rules bilingual training data traditional way.source side translation rule rf extracted source-language document df documenttopic distribution P (zf |df ), obtain instance (rf , P (zf |df ), ), fraction countinstance described Chiang (2007). way, collect set instances= {(rf , P (zf |df ), )} different document-topic distributions translation rule. Usinginstances, calculate probability P (zf = k|rf ) rf topic k follows:PP (zf = k|df )(10)P (zf = k|rf ) = PK IIPk =1II P (zf = k |df )Based equation, obtain two rule-topic distributions P (zf |rf ) P (ze |re )rule using source- target-side document-topic distributions P (zf |df ) P (ze |de ) respectively.5.2 Target-Side Rule-Topic Distribution Projectiondescribed previous section, also estimate target-side rule-topic distributions. However, directly use equation (6) calculate dissimilarity target-siderule-topic distribution P (ze |re ) translation rule source-side document-topic distributionP (zf |df ) source-language document translated. order measure dissimilarity, need project target-side topics onto source-side topic space. projection takesfollowing two steps.First, calculate correspondence probability p(zf |ze ) pair target-side topicze source-side topic zf , inferred two separately trained monolingualtopic models respectively.Second, project target-side rule-topic distribution translation rule onto sourceside topic space using correspondence probabilities learned first step.first step, estimate topic-to-topic correspondence probabilities using co-occurrencecounts topic assignments source target words word-aligned corpus. topic assignments source/target words inferred two monolingual topic models. topicassignments, characterize sentence pair (f, e) (zf , ze , a), zf ze two vectorscontaining topic assignments words source target sentence f e respectively,set word alignment links {(i, j)} source target sentence. Particularly, link(i, j) represents source-side position aligns target-side position j.12fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSnotations, calculate co-occurrence count source-side topic kftarget-side topic ke follows.X X(zfi , kf ) (zej , ke )(11)(zf ,ze ,a) (i,j)azfi zej topic assignments words fi ej respectively, (x, y) Kroneckerfunction, 1 x = 0 otherwise.compute topic-to-topic correspondence probability P (zf = kf |ze = ke )normalizing co-occurrence count follows.PP(zf ,ze ,a)(i,j)a (zfi , kf ) (zej , ke )PP(12)P (zf = kf |ze = ke ) =(zf ,ze ,a)(i,j)a (zej , ke )Overall, first step, obtain topic-to-topic correspondence matrix MKe Kf ,item Mi,j represents probability P (zf = i|ze = j).second step, given correspondence matrix MKe Kf , project target-side ruletopic distribution P (ze |re ) source-side topic space multiplication follows.(P (ze |re )) = P (ze |re ) MKe Kf(13)way, get second distribution translation rule source-side topic space,call projected target-side topic distribution (P (ze |re )).Word alignment noises may introduced equation (11), turn may flattensharpness projected topic distributions calculated equation (13). order decreaseflattening effects word alignment noises, take following action practice:topic-to-topic correspondence probability P (zf = kf |ze = ke ) calculated via word alignments1K predefined number topics, set 0 re-normalizeless Kcorrespondence probabilities target-side topic ke .Obviously, projection method allows one target-side topic ze align multiple source-sidetopics. different one-to-one correspondence used Tam et al. (2007). investigate correspondence matrix MKe Kf obtained training data. find topiccorrespondence source target language necessarily one-to-one. Typically,correspondence probability P (zf = kf |ze = ke ) target-side topic mainly distributes twothree source-side topics. Table 2 shows example target-side topic three mainlyaligned source-side topics.6. Integrationincorporate topic dissimilarity sensitivity model two new features hierarchicalphrase-based system (Chiang, 2007) log-linear discriminative framework (Och & Ney,2002). dissimilarity values positive Hellinger distances positive. weightdissimilarity feature tuned MERT negative. Therefore log-linear model favorcandidate translations lower values dissimilarity feature (less dissimilar).words, translation rules similar document translated terms topicsselected.13fiZ HANG , X IAO , X IONG , & L IUe-topicenterprisesruralstateagriculturalmarketreformproductionpeasantsownedenterpriseP (zf |ze )(agricultural)~(rural)(peasant)U(reform)(finance)(social)(safety)N(adjust)(policy)\(income)f-topic 1(enterprise)|(market)Ik(state)i(company)7K(finance)1(bank)(investment)+n(manage)U(reform)E(operation)f-topic 2u(develop)L(economic)E(technology )I(China)E(technique)(industry)((structure)M#(innovation)\(accelerate)U(reform)f-topic 30.380.280.16Table 2: example topic-to-topic correspondence. last line shows correspondenceprobability. column shows topic represented top-10 topical words. firstcolumn target-side topic, remaining three columns source-side topics.One possible side-effect integration dissimilarity feature systemfavour translations generated fewer translation rules generated translationrules translation rules result higher dissimilarity (see equation (7)).say, topic-based dissimilarity feature also acts translation rule count penalty derivations.Fortunately, however, also use translation rule count feature (see last row Table 1)normally favours translations yielded derivation large number translation rules.feature balance mentioned side-effect topic-based dissimilarity feature.translation rule associated source-side rule-topic distribution projectedtarget-side rule-topic distribution decoding, add four features follows.5Dsim(P (zf |d), P(zf |rf )) (or DsimSrc): Topic dissimilarity feature source-side rule-topicdistributions.Dsim(P (zf |d), (P(ze |re ))) (or DsimTrg): Topic dissimilarity feature projected targetside rule-topic distributions.Sen(P(zf |rf )) (or SenSrc): Topic sensitivity feature source-side rule-topic distributions.Sen(T (P(ze |re )) (or SenTrg): Topic sensitivity feature projected target-side rule-topicdistributions.source-side projected target-side rule-topic distributions translation rulescalculated decoding described last section. decoding, first infertopic distribution P (zf |d) given document source language. translation ruleadopted derivation, scores four features updated correspondingly accordingequation (7) (9). Obviously, computational cost features rather small.5. Since glue rule rules unknown words extracted training data, set values fourfeatures rules zero.14fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELStopic-specific lexicon translation models (Zhao & Xing, 2007; Tam et al., 2007), firstcalculate topic-specific translation probabilities normalizing entire lexicon translation tableadapt lexical weights translation rules correspondingly decoding. makesdecoder run slower. Therefore, comparing previous topic-specific lexicon translation methods, method provides efficient way incorporating topic models SMT.7. Experimentssection, conducted two groups experiments validate effectiveness topicbased translation rule selection framework. first group experiments, use medium-scalebilingual data train SMT system topic models. purpose group experimentsquickly answer following questions:topic dissimilarity model able improve translation rule selection terms B LEU?Furthermore, source-side target-side rule-topic distributions complementaryother?helpful introduce topic sensitivity model distinguish topic-insensitive topicsensitive rules?topic-based method better previous topic-specific lexicon translation method (Zhao& Xing, 2007) terms B LEU decoding speed?confirm efficacy topic-based dissimilarity sensitivity model mediumscale training data, conducted second group experiments large-scale training datainvestigate following questions:one-to-many target-side rule-topic projection method better previous methodsproposed Zhao Xing (2007) Tam et al. (2007)?effects models various types rules, phrase rules rulesnon-terminals?else achieve use monolingual data train topic models?7.1 Setupcarried experiments NIST Chinese-to-English translation. used NIST evaluation set 2005 (MT05) development set, sets MT06/MT08 test sets.numbers documents MT05, MT06, MT08 100, 79, 109 respectively. Case-insensitiveNIST B LEU (Papineni, Roukos, Ward, & Zhu, 2002) used measure translation performance.used minimum error rate training (Och, 2003) optimize feature weights.medium-scale experiments, used FBIS corpus bilingual training data,contains 10,947 documents, 239K sentence pairs 6.9M Chinese words 9.14M Englishwords. large-scale experiments, bilingual training data consists LDC2003E14, LDC2004T07, LDC2005T06, LDC2005T10 LDC2004T08 (Hong Kong Hansards/Laws/News).15fiZ HANG , X IAO , X IONG , & L IUselected corpora contain 103,236 documents 2.80M sentences. average, document 28.4 sentences.obtained symmetric word alignments training data first running GIZA++ (Och & Ney,2003) directions applying refinement rule grow-diag-final-and (Koehn et al.,2003). hierarchical phrase translation rules extracted word-aligned training data.used SRILM toolkit (Stolcke, 2002) train language models Xinhua portionGIGAWORD corpus, contains 238M English words. trained 4-gram language modelmedium-scale experiments 5-gram language model large-scale experiments.order train two monolingual topic models source target side bilingualtraining data, used open source LDA tool GibbsLDA++.6 GibssLDA++ implementationLDA using gibbs sampling parameter estimation inference. source- targetside topic models separately estimated Chinese English part bilingualtraining data. set number topic K = 30 source- target-side topic models,used default setting tool training inference.7 decoding, inferreddocument-topic distribution document dev/test sets translation usingtrained source-side topic model. Note topic inference dev/test sets performedparameters two topic models estimated training data.case-insensitive BLEU-4 used evaluation metric. performed statisticalsignificance BLEU differences using paired bootstrap re-sampling (Koehn, 2004). orderalleviate impact instability MERT, ran tuning process three timeslarge scale experiments presented average BLEU scores three runs followingsuggestion Clark, Dyer, Lavie, Smith (2011)7.2 Medium-Scale Experimentssection, conducted medium-scale experiments investigate effectiveness twotopic-based models translation rule selection.7.2.1 E FFECTOPIC ISSIMILARITY ODELquickly investigated effectiveness topic dissimilarity sensitivity model usingmedium-scale training data. Results shown Table 3. table, observeuse topic dissimilarity model source-side projected target-side ruletopic distributions (DsimSrc/DsimTrg table, see descriptions Section 5),obtain absolute improvement 0.48/0.38 B LEU points baseline.combine two topic dissimilarity features together, achieve improvement 0.16 B LEU points DsimSrc.two observations show topic dissimilarity model able improve translation qualityterms B LEU.6. http://gibbslda.sourceforge.net/7. determine K testing {15, 30, 50, 100, 200} preliminary experiments. find K = 30 producesslightly better performance values. order improve stability topic estimation, runtool multiple times use best model respect log-likelihood.16fiT OPIC -BASED ISSIMILARITYSystemBaselineTopicLexDsimSrcDsimTrgDsimSrc+DsimTrgDsim+SenMT0630.2030.6530.4130.5130.7330.95ENSITIVITY ODELSMT0821.9322.2922.6922.3922.6922.92Avg26.0726.4726.5526.4526.7126.94Speed12.63.311.511.711.210.2Table 3: Results topic dissimilarity sensitivity model terms B LEU speed (wordsper second), comparing traditional hierarchical system (Baseline) system topic-specific lexicon translation model (TopicLex). DsimSrc DsimTrg topic dissimilarity features source-side projected target-side ruletopic distributions respectively. Dsim+Sen activates two dissimilarity featurestwo sensitivity features described Section 6. Avg denotes average B LEUscores two test sets. Scores bold significantly better Baseline (p < 0.01).Speed denotes number words translated per second.Rule TypePhraseMonotoneReorderingCount3.9M19.2M5.7M28.8MSrc-Sen(%)83.485.385.985.1Trg-Sen(%)84.486.186.886.0Table 4: Percentages topic-sensitive rules listed rule types according entropiessource-side (Src) target-side (Trg) rule-topic distributions. Phrase rules fullylexicalized, monotone reordering rules contain nonterminals.order gain insights topic dissimilarity model helpful translation ruleselection, investigate many rules topic-sensitive. described Section 4.2,use entropy measure whether translation rule topic-sensitive based rule-topic distribution. entropy translation rule calculated equation (8) smaller certainthreshold, rule topic-sensitive. Since documents often focus topics, use average entropy document-topic distributions training documents threshold. compareentropies source-side target-side rule-topic distributions threshold. findingsshown Table 4. 85.5% translation rules topic-sensitive rules compare entropiessource-side rule-topic distributions threshold. compare entropies targetside rule-topic distributions threshold, topic-sensitive rules account 86%.strongly suggest rules occur documents specific topics topic informationused improve translation rule selection.7.2.2 E FFECTOPIC ENSITIVITY ODELsee Table 4, still 15% translation rules generic, sensitive topics. rules also widely used documents. mentioned before,17fiZ HANG , X IAO , X IONG , & L IUtopic dissimilarity model always punishes rules documents normally topic-specific.therefore introduce topic sensitivity model complement topic dissimilarity model. experiment result model show last line Table 3. obtain improvement0.23 B LEU points incorporating topic sensitivity model. indicates necessarydistinguish topic-insensitive topic-sensitive rules.7.2.3 C OMPARISONOPIC -S PECIFIC L EXICON RANSLATION ODELalso compared topic models topic-specific lexicon translation model proposedZhao Xing (2007). introduce framework combine Hidden Markov Model (HMM)LDA topic model SMT, shown Figure 2. framework, bilingual sentencepair single topic assignment sampled document-pair topic distribution .words target language (e.g., English) sampled given sentence-pair topic assignmentmonolingual per-topic word distribution . that, word alignments wordssource language sampled first-order Markov process topic-specific translationlexicon respectively.Zhao Xing integrate topic-specific word-to-word translation lexicons estimatedbilingual topic model described topic-specific lexicon translation model,formulated follows.P (we |wf , df ) P (wf |we , df )P (we |df )X=P (wf |we , z = k)P (we |z = k)P (z = k|df )(14)kmodel, probability candidate translation source word wf source document df calculated marginalizing topics corresponding topic-specific translationlexicons. simplify estimation p(wf |we , z = k) directly computing probabilitiesword-aligned corpus associated target-side topic assignments inferredtarget-side topic model. Despite simplification, improvement implementation comparable improvement obtained Zhao Xing (2007). Given new document, needadapt lexical translation weights rules. adapted lexicon translation model integratednew feature log-linear discriminative framework.show comparison results Table 3. topic-specific lexicon translation modelbetter baseline 0.4 B LEU points. However, topic-based method (the combinationtopic dissimilarity sensitivity models) outperforms baseline 0.87 B LEU points.also compare two methods terms decoding speed (words/second). baseline translates 12.6 words per second, system topic-specific lexicon translationmodel translates 3.3 words one second. overhead topic-specific lexicon translation model mainly comes adaptation lexical weights. takes 72.8% timeadaptation. contrast, method speed 10.2 words per second sentenceaverage, three times faster topic-specific lexicon translation method.7.3 Large-Scale Experimentssection, investigated deeper models second group experimentslarge-scale training data.18fiT OPIC -BASED ISSIMILARITY7.3.1 E FFECTENSITIVITY ODELSNE - -M P ROJECTIONdiscussed Section 5.2, need project target-side topics onto source-side topic spacecalculate dissimilarity target-side rule-topic distribution source-sidedocument-topic distribution. propose one-to-many projection method issue. orderinvestigate effectiveness method, conducted experiments large-scale trainingdata compare following 3 methods.One-to-One Mapping enforce one-to-one mapping source-side target-sidetopics, similar method Tam et al. (2007). achieve aligning target-sidetopic corresponding source-side topic largest correspondence probabilitycalculated Section 5.2.Marginalization Word Alignments Following Zhao Xing (2007), first obtaintopics target side using LDA retrieve topics source languagemarginalization word alignments follows.XP (wf |k) =P (wf |we )P (we |z = k)(15)Combination source target language documents concatenate target document aligned source document one document. run LDA toolcombined documents train one topic model mixed-language words. decoding,use trained topic model infer topics source documents.order compare one-to-many projection method three methods described above,add target-side topic dissimilarity feature (DsimTrg) log-linear translation model.experiment results reported Table 5. Clearly, four methods achieve improvementsbaseline. However, one-to-many projection method performs better threemethods. particular,method outperforms one-to-one topic mapping method, indicates sourceside target-side topics exactly match one-to-one correspondence manner.reason marginalization method performs worse among four methods maytopic model trained target documents.Surprisingly, combination method performs quite well. shows LDA modelfind hidden topics even mixed-language documents.7.3.2 E FFECTRULESOPIC -BASED RULE ELECTION F RAMEWORKVARIOUS YPESconducted experiments investigate effect topic-based models varioustypes rules selection. Particularly, divide translation rules hierarchical phrase-based SMTthree types: 1) phrase rules, contain terminals bilingual phrasepairs used phrase-based system; 2) monotone rules, contain non-terminals produce19fiZ HANG , X IAO , X IONG , & L IUSystemBaselineOne-to-OneMarginalizationCombinationOne-to-ManyMT0631.7732.1532.2332.1732.44MT0824.8925.3224.9925.5625.54Avg28.3328.7328.6128.8628.99Table 5: Effect one-to-many topic projection method methods. Marginalization: Marginalization Word Alignments; Combination: Combination sourcetarget language documents.SystemBaselinePhrase ruleMonotone ruleReordering ruleMT0631.7732.4332.2431.8232.77MT0824.8925.5325.6225.1526.29Avg28.3328.9828.9328.4829.53Table 6: Effect topic-based rule selection models three types rules. Phrase rulesfully lexicalized, monotone reordering rules contain nonterminals.monotone translations; finally 3) reordering rules, also contain non-terminals changeorder translations. define monotone reordering rules according Chiang et al.(2008).study impact topic-based models translation rule type A, activatefour features described Section 6 rules type A. Topic dissimilaritysensitivity features two types translation rules deactivated.Table 6 shows experiment results. table, observetopic-based models achieve highest improvement 0.65 B LEU points baseline phrase rules among three types translation rules. reasonable phraserules consist topical words.also obtain improvements 0.6 0.15 B LEU points baseline monotonereordering rules respectively. shows models also able help selectappropriate translation rules non-terminals.activate topic dissimilarity sensitivity models translation rules,still achieve additional improvement 0.55 B LEU points. total, models outperformbaseline absolute improvement 1.2 B LEU points.7.3.3 E FFECTORE ONOLINGUAL DATAComparing Table 6 Table 3, find topic-based dissimilarity sensitivity modelstrained medium-scale data (about 10K documents) collectively achieve improvement 0.8720fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSSystemBaselineDsimSrc + SenSrc + DsimTrg + SenTrgDsimSrc + SenSrc + DsimTrg + SenTrgDsimSrc + SenSrc + DsimTrg + SenTrgDsimSrc + SenSrc + DsimTrg + SenTrgMT0631.7732.7732.7032.3732.61MT0824.8926.2925.9125.8025.66Avg28.3329.5329.3129.0929.13Table 7: Effect using monolingual data train topic models. features boldtopic-based dissimilarity/sensitivity model LDA topic model trained usingcombination source/target part large-scale bilingual data correspondingmonolingual corpus.B LEU points baseline two models trained large-scale data (about 100K documents) obtain improvement 1.2 B LEU points. suggests performance gainsmay obtained data. parallel bilingual data document boundaries provided easily accessible, try collect monolingual data source or/and target language.interest study whether gain improvements using monolingual datatrain topic models.used Chinese monolingual corpus documents collected Chinese Sohuweblog 2009.8 collected Chinese corpus contains 500K documents 273.8M Chinesewords. also used English monolingual corpus documents collectedEnglish Blog Authorship corpus (Schler, Koppel, Argamon, & Pennebaker, 2006). Englishmonolingual corpus consists 371K documents 98M English words. combined newChinese corpus source part large-scale bilingual data train source-side LDA topicmodel ST . English monolingual corpus also combined target part large-scalebilingual data train target-side LDA topic model .used two topic models ST infer topics test sets. Topic information source target part large-scale bilingual training data inferred STused estimate source-side rule-topic distributions projected target-side rule-topic distributions. way, obtain new topic-based dissimilarity sensitivity modelsource/target side.Experiment results shown Table 7. Unfortunately, obtain improvements training topic models larger data, combination Chinese monolingualcorpus source part bilingual training data. Instead, performance drops 29.5329.31 use topic model ST build source-side dissimilarity sensitivity features29.09 adopt topic model build target-side dissimilarity sensitivityfeatures.One reason lower performance larger topic model training data mayuse 30 topics. Using topics may improve models larger corpora. orderinvestigate this, conducted new experiments topics 30. trained sourceside topic model using combination source part large-scale bilingual data Sohuweblog data. Based topic model, built source-side topic dissimilarity model8. http://blog.sohu.com/.21fiZ HANG , X IAO , X IONG , & L IUSystemBaselineK = 30K = 50K = 100K = 200MT0631.7732.3231.9632.2632.16MT0824.8925.4125.7325.5325.28Avg28.3328.8628.8528.9028.72Table 8: Experiment results different number topics (K). source-side topic dissimilarity model (DsimSrc) integrated SMT system.Test SetMT06MT08MonoSrc0.3590.232BiSrc0.2380.136MonoBiSrc0.2970.261Table 9: Hellinger distances MT06/08 test sets Chinese monolingual corpus(MonoSrc) source part bilingual training data (BiSrc) well combination (MonoBiSrc) terms average document-topic distributions.integrated SMT system. Experiment results shown Table 8. table,find using topics able improve model corpora.Yet another reason may additional monolingual corpus similar test setsterms topic distributions. order examine hypothesis, inferred document-topicdistributions documents test sets, Chinese monolingual corpus source partbilingual corpus using topic model ST . average document-topic distributionsobtain four average document-topic distributions MT06, MT08, Chinese monolingualcorpus source part bilingual corpus respectively. average topic distributions approximated corpus-topic distributions four corpora. calculateHellinger distances corpus-topic distributions test sets Chinesemonolingual corpus source part bilingual training data, shown Table 9.table, clearly find additional monolingual corpus much less similartest sets comparing bilingual training corpus. Hellinger distance testset MT08 MonoBiSrc corpus almost twice large bilingual training data(0.261 vs. 0.136). topic model trained enlarged corpus make topic-basedmodels select translation rules similar documents test sets terms topicdistributions. suggests select additional monolingual data similartest sets want obtain improvements.conducted new group experiments empirically examine hypothesistranslating web-domain test set similar additional weblog corpus termstopics. used web portion NIST MT06 set new development set webportion NIST MT08 new test set. Results displayed Table 10, showadditional monolingual data improve performance time. suggestsselect monolingual corpus similar test sets learn topics topic-baseddissimilarity sensitivity models.22fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSSystemBaselineDsimSrc + SenSrc + DsimTrg + SenTrgDsimSrc + SenSrc + DsimTrg + SenTrgMT08-web20.4521.4221.77Table 10: Results translating web-domain test set topic-based models traineddata augmented monolingual weblog corpus. features bold topicbased dissimilarity/sensitivity model LDA topic model trained usingcombination source/target part large-scale bilingual data correspondingmonolingual corpus. MT08-web web portion NIST MT08 test set.8. Analysissection, study details topic-based models translation rule selectionlooking differences make target documents individual translation hypotheses.differences help us gain insights presented models improve translationquality. analysis, baseline system system enhanced proposedtopic-based models (all four features Section 6 activated) trained large-scale bilingualdata described Section 7.1. notational convenience, hereafter refer baselinesystem BASE system enhanced topic-based dissimilarity sensitivity modelsTOPSEL.8.1 Differences Target Documentsorder measure impact topic-based models target documents, calculateHellinger distances target documents generated BASE / TOPSEL system reference documents generated human terms topics inferred target-side LDA topicmodel according following 4 steps. target-side LDA topic model trained targetpart large-scale bilingual data described Section 7.1.Use target-side LDA topic model infer document-topic distribution documentreference translations (called reference distribution).Use target-side LDA topic model infer document-topic distribution target document generated BASE system (called BASE distribution).Similarly, obtainTOPSEL system.TOPSELdistribution target document generatedCalculate dissimilarity BASE reference distribution well TOPSEL reference distribution according equation (6). dissimilarities first averaged documents averaged four reference translations.Table 11 shows calculated dissimilarities. According equation (6), smallerHellinger distance two items, similar are. average Hellinger distanceTOPSEL reference documents 0.123 distance BASE reference23fiZ HANG , X IAO , X IONG , & L IUSystemBASETOPSELMT060.1190.116MT080.1370.129Avg0.1280.123Table 11: Dissimilarities (measured Hellinger distance) reference documents targetdocuments generated BASE TOPSEL system terms topics accordingequation (6).similar (+)Less similar (-)p<MT0649300.05Table 12: number target documents generatederence documents BASE.MT0872370.01TOPSELmore/less similar ref-documents 0.128. Therefore, target documents generated TOPSEL systemMT06 MT08 similar documents reference translationsbaseline system. calculate number target documents generated TOPSELmore/less similar reference documents BASE based average Hellingerdistances. numbers shown Table 12. According sign test using numbers,TOPSEL statistically significantly better baseline system terms similaritytranslations generated two systems human-generated translations.8.2 Differences Translation Hypotheseslook deeper translation hypotheses understand models select translationrules. Table 13 shows three translation examples compare baseline systemenhanced topic-based models. order conduct quantitative comparison, calculatedissimilarity values (measured Hellinger distance) underlined phrases Table 13 usingtopic-based dissimilarity model. dissimilarity values computed projectedtarget-side rule-topic distributions underlined phrases source-side document-topicdistributions corresponding documents phrase used. values shownTable 14.two tables, easily observe system topic-based dissimilaritymodel prefers target phrases smaller Hellinger distances documentsoccur terms topic distributions. contrast, baseline able use document-leveltopic information translation rule selection. Figure 3 shows topic distributionssource-side document, TOPSEL phrase allow BASE phrase permit Eg. 2.major topics source-side document topic 12 36. TOPSEL phrase allow mainlydistributes 12 different topics9 including topic 12 36 BASE phrase permitmainly 10 different topics include topic 12.9. distribution probability topics larger 0.03.24fiT OPIC -BASED ISSIMILARITYSourceENSITIVITY ODELS7 8 { "described northern limit line unlawful .referred northern limit line legitimate .Reference pointed northern limit line legitimate .SourceBASEwould permit love others also accepted people .TOPSELallow love love others also accepted peopleReference would someone allow person loves accept peopleslove timeSourceBASEpresent , internet entitled statutory right leaveTOPSELpresent internet enjoy statutory right leaveReference present internet enjoy rightsBASEEg. 1TOPSEL#N gC < O<Eg. 28 p k { N |Eg. 3Table 13: Translation examples NIST MT06/08 test sets, comparing baselinesystem enhanced topic-based models. underlined words highlightdifference enhanced models baseline.PhraseunlawfullegitimatepermitallowentitledenjoyHD3.082.273.753.473.453.24Table 14: Dissimilarity values (measured Hellinger distance) underlined phrases Table 13 projected target-side rule-topic distributions correspondingsource-side document-topic distributions documents calculated topic-based dissimilarity model.9. Discussion Bilingual Topic ModelingAlthough topic models widely adopted monolingual text analysis, bilingual multilingualtopic models less explored, especially tailored multilingual tasks machinetranslation. section try provide suggestions bilingual topic modelingperspective statistical machine translation well practice integration topic models SMT. suggestions listed follows, also futuredirections.Investigation Topic divergences across different languages Cross-language divergencespervasive become one big challenges machine translation (Dorr, 1994).language-level divergences hint divergences topic concept level may also existacross languages. may explain one-to-many topic projection target side25fiZ HANG , X IAO , X IONG , & L IUFigure 3: Topic distributions source-side document (a),BASE phrase permit shown Eg. 2 Table 13.TOPSELphrase allow (b)source side better one-to-one mapping. Although Mimno et al. (2009)studied topic divergences using Wikipedia articles, believe deeper widerinvestigation topic divergence needed shed new light buildbetter bilingual topic models.Adding linguistic assumptions topic modeling Practices SMT show integrating linguistic knowledge machine translation normally generates better translations(Chiang et al., 2008). believe adding linguistic assumptions beyond bag-ofwords also improve topic modeling. flexible topic modeling framework allows usintegrate rich linguistic knowledge form features definitely facilitateapplication topic models natural language processing.Joint modeling topic induction synchronous grammar induction Synchronous grammar induction machine translation task automatically learning translation rulesbilingual data (Blunsom, Cohn, Dyer, & Osborne, 2009; Xiao & Xiong, 2013). Bayesianapproaches successfully used topic modeling synchronous grammar induction, joint modeling interesting direction, also benefit grammaradaptation one domain another domain machine translation.10. Conclusionsarticle presented topic-based translation rule selection framework incorporates topic information source target language translation rule disambiguation. Particularly, use topic dissimilarity model select appropriate translation rulesdocuments according similarities translation rules documents. also adopt26fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELStopic sensitivity model complement topic dissimilarity model order balance translationrule selection topic-sensitive topic-insensitive rules. order calculate dissimilarities source- target-side topic distributions, project topic distributions targetside onto source-side topic model space new efficient way.integrated topic-based rule selection models hierarchical phrase-based SMTsystem. Experiments medium/large-scale training data showtopic dissimilarity sensitivity model able substantially improve translationquality terms B LEU improve translation rule selection various types rules (i.e.,phrase/monotone/reordering rules).method better previous topic-specific lexicon translation method translation quality decoding speed.proposed one-to-many projection method also outperforms various methodsone-to-one mapping, marginalization via word alignments on.want use additional monolingual corpus train topic models, first investigate whether new monolingual corpus similar test data terms topicdistributions.Topic models provide global document-level information machine translation.future, would like use topic models address document-level machine translation issues,coherence cohesion (Barzilay & Lee, 2004; Hardmeier, Nivre, & Tiedemann, 2012).also want integrate topic-based models linguistically syntax-based machine translationsyntactic translation rule selection (Liu et al., 2006).Acknowledgmentswork sponsored National Natural Science Foundation China projects61373095 61333018. Qun Lius work partially supported Science Foundation Ireland(Grant No. 07/CE/I1142) part CNGL Dublin City University. would like thankthree anonymous reviewers insightful comments. corresponding author articleDeyi Xiong.ReferencesBarzilay, R., & Lee, L. (2004). Catching drift: Probabilistic content models, applicationsgeneration summarization. Susan Dumais, D. M., & Roukos, S. (Eds.), HLT-NAACL2004: Main Proceedings, pp. 113120, Boston, Massachusetts, USA. Association Computational Linguistics.Blei, D. M., & Lafferty, J. D. (2007). correlated topic model science. AAS, 1(1), 1735.Blei, D. M., Ng, A., & Jordan, M. (2003). Latent dirichlet allocation. JMLR, 3, 9931022.27fiZ HANG , X IAO , X IONG , & L IUBlunsom, P., Cohn, T., Dyer, C., & Osborne, M. (2009). gibbs sampler phrasal synchronousgrammar induction. Proceedings Joint Conference 47th Annual MeetingACL 4th International Joint Conference Natural Language ProcessingAFNLP, pp. 782790, Suntec, Singapore. Association Computational Linguistics.Boyd-Graber, J., & Blei, D. M. (2009). Multilingual topic models unaligned text. ProceedingsTwenty-Fifth Conference Uncertainty Artificial Intelligence, UAI 09, pp. 7582,Arlington, Virginia, United States. AUAI Press.Carpuat, M., & Wu, D. (2007a). phrase sense disambiguation outperforms word sense disambiguation statistical machine translation. Proceedings 11th ConferenceTheoretical Methodological Issues Machine Translation, pp. 4352.Carpuat, M., & Wu, D. (2007b). Improving statistical machine translation using word sense disambiguation. Proceedings 2007 Joint Conference Empirical Methods NaturalLanguage Processing Computational Natural Language Learning (EMNLP-CoNLL), pp.6172, Prague, Czech Republic. Association Computational Linguistics.Chan, Y. S., Ng, H. T., & Chiang, D. (2007). Word sense disambiguation improves statistical machine translation. Proceedings 45th Annual Meeting Association Computational Linguistics, pp. 3340, Prague, Czech Republic. Association ComputationalLinguistics.Chiang, D. (2005). hierarchical phrase-based model statistical machine translation. Proc.ACL 2005.Chiang, D. (2007). Hierarchical phrase-based translation. Computational Linguistics, 33(2), 201228.Chiang, D., Marton, Y., & Resnik, P. (2008). Online large-margin training syntactic structuraltranslation features. Proceedings 2008 Conference Empirical Methods Natural Language Processing, pp. 224233, Honolulu, Hawaii. Association ComputationalLinguistics.Clark, J. H., Dyer, C., Lavie, A., & Smith, N. A. (2011). Better hypothesis testing statisticalmachine translation: Controlling optimizer instability. Proceedings 49th AnnualMeeting Association Computational Linguistics: Human Language Technologies,pp. 176181, Portland, Oregon, USA.Dorr, B. J. (1994). Machine translation divergences: formal description proposed solution.Computational Linguistics, 20(4), 597633.Foster, G., & Kuhn, R. (2007). Mixture-model adaptation SMT. Proc. Second WorkshopStatistical Machine Translation, pp. 128135, Prague, Czech Republic.Gong, Z., Zhang, M., & Zhou, G. (2011). Cache-based document-level statistical machine translation. Proc. EMNLP 2011.Gong, Z., Zhang, Y., & Zhou, G. (2010). Statistical machine translation based LDA. Proc.IUCS 2010, p. 286 290.Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. Proceedings NationalAcademy Sciences, 101(Suppl. 1), 52285235.28fiT OPIC -BASED ISSIMILARITYENSITIVITY ODELSHardmeier, C., Nivre, J., & Tiedemann, J. (2012). Document-wide decoding phrase-based statistical machine translation. Proceedings 2012 Joint Conference EmpiricalMethods Natural Language Processing Computational Natural Language Learning,pp. 11791190, Jeju Island, Korea. Association Computational Linguistics.He, Z., Liu, Q., & Lin, S. (2008). Improving statistical machine translation using lexicalized ruleselection. Proceedings 22nd International Conference Computational Linguistics(Coling 2008), pp. 321328, Manchester, UK. Coling 2008 Organizing Committee.Hofmann, T. (1999). Probabilistic latent semantic analysis. Proc. UAI 1999, pp. 289296.Koehn, P. (2004). Statistical significance tests machine translation evaluation. ProceedingsEMNLP 2004, pp. 388395, Barcelona, Spain.Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. Proc. HLT-NAACL2003.Lin, J. (2006). Divergence measures based Shannon entropy. IEEE Trans. Inf. Theor., 37(1),145151.Liu, Q., He, Z., Liu, Y., & Lin, S. (2008). Maximum entropy based rule selection model syntaxbased statistical machine translation. Proceedings 2008 Conference Empirical Methods Natural Language Processing, pp. 8997, Honolulu, Hawaii. AssociationComputational Linguistics.Liu, Y., Liu, Q., & Lin, S. (2006). Tree-to-string alignment template statistical machine translation. Proc. ACL 2006.Mimno, D., Wallach, H. M., Naradowsky, J., Smith, D. A., & McCallum, A. (2009). Polylingualtopic models. Proc. EMNLP 2009.Och, F. J., & Ney, H. (2002). Discriminative training maximum entropy models statisticalmachine translation. Proc. ACL 2002.Och, F. J. (2003). Minimum error rate training statistical machine translation. Proc. ACL 2003.Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignment models.Computational Linguistics, 29(1), 1951.Papineni, K., Roukos, S., Ward, T., & Zhu, W.-J. (2002). BLEU: method automatic evaluationmachine translation. Proc. ACL 2002.Ruiz, N., & Federico, M. (2011). Topic adaptation lecture translation bilingual latentsemantic models. Proceedings Sixth Workshop Statistical Machine Translation.Schler, J., Koppel, M., Argamon, S., & Pennebaker, J. W. (2006). Effects age genderblogging. AAAI Spring Symposium: Computational Approaches Analyzing Weblogs, pp.199205.Stolcke, A. (2002). SRILM extensible language modeling toolkit. Proc. ICSLP 2002.Tam, Y.-C., Lane, I. R., & Schultz, T. (2007). Bilingual LSA-based adaptation statistical machinetranslation. Machine Translation, 21(4), 187207.Tiedemann, J. (2010). Context adaptation statistical machine translation using models exponentially decaying cache. Proceedings 2010 Workshop Domain Adaptation29fiZ HANG , X IAO , X IONG , & L IUNatural Language Processing, pp. 815, Uppsala, Sweden. Association ComputationalLinguistics.Ture, F., Oard, D. W., & Resnik, P. (2012). Encouraging consistent translation choices. Proceedings 2012 Conference North American Chapter Association Computational Linguistics: Human Language Technologies, pp. 417426, Montreal, Canada. Association Computational Linguistics.Xiao, T., Zhu, J., Yao, S., & Zhang, H. (2011). Document-level consistency verification machinetranslation. Proceedings 2011 MT summit XIII, pp. 131138, Xiamen, China.Xiao, X., & Xiong, D. (2013). Max-margin synchronous grammar induction machine translation. Proceedings 2013 Conference Empirical Methods Natural LanguageProcessing, pp. 255264, Seattle, Washington, USA. Association Computational Linguistics.Xiao, X., Xiong, D., Zhang, M., Liu, Q., & Lin, S. (2012). topic similarity model hierarchical phrase-based translation. Proceedings 50th Annual Meeting AssociationComputational Linguistics (Volume 1: Long Papers), pp. 750758, Jeju Island, Korea.Association Computational Linguistics.Xiong, D., Zhang, M., & Li, H. (2012). Modeling translation predicate-argument structureSMT. Proceedings 50th Annual Meeting Association ComputationalLinguistics (Volume 1: Long Papers), pp. 902911, Jeju Island, Korea. Association Computational Linguistics.Zhao, B., & Xing, E. P. (2007). HM-BiTAM: Bilingual topic exploration, word alignment,translation. Proc. NIPS 2007.Zhao, B., & Xing, E. P. (2006). BiTAM: Bilingual topic admixture models word alignment.Proc. ACL 2006.30fiJournal Artificial Intelligence Research 50 (2014) 723762Submitted 12/13; published 08/14Sentiment Analysis Short Informal TextsSvetlana KiritchenkoXiaodan ZhuSaif M. MohammadSvetlana.Kiritchenko@nrc-cnrc.gc.caXiaodan.Zhu@nrc-cnrc.gc.caSaif.Mohammad@nrc-cnrc.gc.caNational Research Council Canada1200 Montreal Rd., Ottawa, ON, CanadaAbstractdescribe state-of-the-art sentiment analysis system detects (a) sentimentshort informal textual messages tweets SMS (message-level task) (b)sentiment word phrase within message (term-level task). systembased supervised statistical text classification approach leveraging variety surfaceform, semantic, sentiment features. sentiment features primarily derivednovel high-coverage tweet-specific sentiment lexicons. lexicons automaticallygenerated tweets sentiment-word hashtags tweets emoticons.adequately capture sentiment words negated contexts, separate sentiment lexicongenerated negated words.system ranked first SemEval-2013 shared task Sentiment Analysis Twitter (Task 2), obtaining F-score 69.02 message-level task 88.93term-level task. Post-competition improvements boost performance F-score70.45 (message-level task) 89.50 (term-level task). system also obtains state-ofthe-art performance two additional datasets: SemEval-2013 SMS test setcorpus movie review excerpts. ablation experiments demonstrate useautomatically generated lexicons results performance gains 6.5 absolutepercentage points.1. IntroductionSentiment Analysis involves determining evaluative nature piece text. example, product review express positive, negative, neutral sentiment (or polarity).Automatically identifying sentiment expressed text number applications, including tracking sentiment towards products, movies, politicians, etc., improving customerrelation models, detecting happiness well-being, improving automatic dialogue systems. past decade, substantial growth use microbloggingservices Twitter access mobile phones world-wide. Thus, tremendousinterest sentiment analysis short informal texts, tweets SMS messages,across variety domains (e.g., commerce, health, military intelligence, disaster management).Short informal textual messages bring new challenges sentiment analysis.limited length, usually spanning one sentence less. tend manymisspellings, slang terms, shortened forms words. also special markershashtags used facilitate search, also indicate topic sentiment.paper describes state-of-the-art sentiment analysis system addressing two tasks:(a) detecting sentiment short informal textual messages (message-level task)c2014National Research Council Canada. rights reserved.fiKiritchenko, Zhu, & Mohammad(b) detecting sentiment word phrase within message (term-level task).system based supervised statistical text classification approach leveragingvariety surface-form, semantic, sentiment features. Given limited amountstraining data, statistical sentiment analysis systems often benefit use manuallyautomatically built sentiment lexicons. Sentiment lexicons lists words (and phrases)prior associations positive negative sentiments. lexicons additionallyprovide sentiment score term indicate strength evaluative intensity. Higherscores indicate greater intensity. example, entry great (positive, 1.2) statesword great positive polarity sentiment score 1.2. entry acceptable(positive, 0.1) specifies word acceptable positive polarity intensitylower word great.sentiment analysis system, utilize three freely available, manually created,general-purpose sentiment lexicons. addition, generated two high-coverage tweetspecific sentiment lexicons 2.5 million tweets using sentiment markers withinthem. lexicons automatically capture many peculiarities social media languagecommon intentional unintentional misspellings (e.g., gr8, lovin, coul, holys**t),elongations (e.g., yesssss, mmmmmmm, uugghh), abbreviations (e.g., lmao, wtf ).also include words usually considered expressing sentiment,often associated positive/negative feelings (e.g., party, birthday, homework ).Sentiment lexicons provide knowledge prior polarity (positive, negative, neutral)word, i.e., polarity contexts. However, particular context priorpolarity change. One obvious contextual sentiment modifier negation.negated context, many words change polarity least evaluative intensity.example, word good often used express positive attitude whereas phrasegood clearly negative. conventional way addressing negation sentiment analysisreverse polarity word, i.e. change words sentiment score(Kennedy & Inkpen, 2005; Choi & Cardie, 2008). However, several studies pointedinadequacy solution (Kennedy & Inkpen, 2006; Taboada, Brooke, Tofiloski,Voll, & Stede, 2011). show experiments Section 4.3 many positiveterms, though all, tend reverse polarity negated, whereas negativeterms remain negative change evaluative intensity. example, wordterrible conveys strong negative sentiment whereas phrase wasnt terrible mildlynegative. Also, degree intensity shift varies term term positive negative terms. adequately capture effects negation different terms,propose corpus-based statistical approach estimate sentiment scores individualterms presence negation. build two lexicons: one words negated contexts(Negated Context Lexicon) one words affirmative (non-negated) contexts (Affirmative Context Lexicon). word (or phrase) two scores, one NegatedContext Lexicon one Affirmative Context Lexicon. analyzing sentiment textual message, use scores Negated Context Lexicon wordsappearing negated context scores Affirmative Context Lexicon wordsappearing affirmative context.Experiments carried asses both, performance overall sentimentanalysis system well quality value automatically created tweet-specificlexicons. intrinsic evaluation lexicons, entries compared724fiSentiment Analysis Short Informal Textsentries manually created lexicons. Also, human annotators asked ranksubset lexicon entries degree association positive negative sentimentranking compared ranking produced automatic lexicon.experiments observe high agreement automatic manual sentimentannotations.extrinsic evaluation performed two tasks: unsupervised supervised sentiment analysis. supervised task, assess performance full sentimentanalysis system examine impact features derived automatic lexiconsoverall performance. testbed, use datasets provided SemEval2013 competition Sentiment Analysis Twitter (Wilson, Kozareva, Nakov, Rosenthal,Stoyanov, & Ritter, 2013).1 datasets provided two tasks, message-level taskterm-level task, two domains, tweets SMS. However, training dataavailable tweets. Among 77 submissions 44 teams, system placed firstcompetition tasks tweet test set, obtaining macro-averaged F-score69.02 message-level task 88.93 term-level task. Post-competition improvements system boost performance F-score 70.45 (message-level task)89.50 (term-level task). also applied classifier SMS test set withouttuning. classifier obtained first position identifying sentimentSMS messages (F-score 68.46) second position detecting sentimentterms within SMS messages (F-score 88.00; 0.39 points behind first-ranked system). post-competition improvements, system achieves F-score 69.77message-level task F-score 88.20 term-level task test set.addition, evaluate performance sentiment analysis system domainmovie review excerpts (message-level task only). system re-trained collection7,800 positive negative sentences extracted movie reviews. appliedtest set unseen sentences, system able correctly classify 85.5% testset. result exceeds best result obtained dataset recursive deep learningapproach requires access sentiment labels syntactic phrases trainingdata sentences (Socher, Perelygin, Wu, Chuang, Manning, Ng, & Potts, 2013).message-level task, make use sentiment labels phrases training data,often unavailable real-world applications.ablation experiments reveal automatically built lexicons gave systemcompetitive advantage SemEval-2013. use new lexicons results gains6.5 percentage points gains obtained use features.Furthermore, show lexicons built specifically negated contexts better modelnegation reversing polarity approach.main contributions paper three-fold. First, present sentimentanalysis system achieves state-of-the-art performance three domains: tweets, SMS,movie review excerpts. system replicated using freely available resources.Second, describe process creating automatic, tweet-specific lexiconsdemonstrate superior predictive power several manually automatically created general-purpose lexicons. Third, analyze impact negation sentimentpropose empirical method estimate sentiment words negated contexts1. SemEval international forum natural-language shared tasks. competition referSemEval-2013 Task 2 (http://www.cs.york.ac.uk/semeval-2013/task2).725fiKiritchenko, Zhu, & Mohammadcreating separate sentiment lexicon negated words. automatic lexicons describedpaper made available research community.2paper organized follows. begin description related work Section 2. Next, describe sentiment analysis task data used research(Section 3). Section 4 presents sentiment lexicons used system: existing manuallycreated, general-purpose lexicons (Section 4.1) automatic, tweet-specific lexicons(Section 4.2). lexicons built affirmative negated contexts described Section 4.3. detailed description supervised sentiment analysis system, includingclassification method feature sets, presented Section 5. Section 6 providesresults evaluation experiments. First, compare automatically created lexicons human annotations derived manual lexicons well collectedAmazons Mechanical Turk service3 (Section 6.1). Next, evaluate new lexiconsextrinsic task unsupervised sentiment analysis (Section 6.2.1). purposeexperiments compare predictive capacity individual lexicons without influence factors. Then, Section 6.2.2 assess performance entiresupervised sentiment analysis system examine contribution features derivedlexicons overall performance. Finally, conclude present directionsfuture work Section 7.2. Related Worklast decade, explosion work exploring various aspectssentiment analysis: detecting subjective objective sentences; classifying sentencespositive, negative, neutral; detecting person expressing sentiment targetsentiment; detecting emotions joy, fear, anger; visualizing sentimenttext; applying sentiment analysis health, commerce, disaster management.Surveys Pang Lee (2008) Liu Zhang (2012) give summary manyapproaches.Sentiment analysis systems applied many different kinds texts includingcustomer reviews, news paper headlines (Bellegarda, 2010), novels (Boucouvalas, 2002;John, Boucouvalas, & Xu, 2006; Francisco & Gervas, 2006; Mohammad & Yang, 2011),emails (Liu, Lieberman, & Selker, 2003; Mohammad & Yang, 2011), blogs (Neviarouskaya,Prendinger, & Ishizuka, 2011; Genereux & Evans, 2006; Mihalcea & Liu, 2006), tweets(Mohammad, 2012). Often systems cater specific needs textformality versus informality, length utterances, etc. Sentiment analysis systemsdeveloped specifically tweets include Pak Paroubek (2010), Agarwal, Xie,Vovsha, Rambow, Passonneau (2011), Thelwall, Buckley, Paltoglou (2011), BrodyDiakopoulos (2011), Aisopos, Papadakis, Tserpes, Varvarigou (2012), Bakliwal,Arora, Madhappan, Kapre, Singh, Varma (2012). recent survey Martnez-Camara,Martn-Valdivia, Urenalopez, Montejoraez (2012) provides overview researchsentiment analysis tweets.Several manually created sentiment resources successfully applied sentimentanalysis. General Inquirer sentiment labels 3,600 terms (Stone, Dunphy,2. www.purl.com/net/sentimentoftweets3. https://www.mturk.com/mturk/welcome726fiSentiment Analysis Short Informal TextsSmith, Ogilvie, & associates, 1966). Hu Liu (2004) manually labeled 6,800words used detecting sentiment customer reviews. MPQA SubjectivityLexicon, draws General Inquirer sources, sentiment labels8,000 words (Wilson, Wiebe, & Hoffmann, 2005). NRC Emotion Lexiconsentiment emotion labels 14,000 words (Mohammad & Turney, 2010).labels compiled Mechanical Turk annotations.Semi-supervised automatic methods also proposed detect polaritywords. Hatzivassiloglou McKeown (1997) proposed algorithm determinepolarity adjectives. SentiWordNet (SWN) created using supervised classifiers wellmanual annotation (Esuli & Sebastiani, 2006). Turney Littman (2003) proposedminimally supervised algorithm calculate polarity word determiningtendency co-occur small set positive seed words greater tendencyco-occur small set negative seed words. Mohammad, Dunne, Dorr (2009)automatically generated sentiment lexicon 60,000 words thesaurus.use several lexicons system. addition, create two new sentimentlexicons tweets using hashtags emoticons. Section 6, show tweetspecific lexicons higher coverage better predictive power lexiconsmentioned earlier.Since manual annotation data costly, distant supervision techniques actively applied domain short informal texts. User-provided indications emotionalcontent, emoticons, emoji, hashtags, used noisy sentiment labels.example, Go, Bhayani, Huang (2009) use tweets emoticons labeled datasupervised training. Emoticons :) considered positive labels tweetsemoticons :( used negative labels. Davidov, Tsur, Rappoport (2010)Kouloumpis, Wilson, Moore (2011) use certain seed hashtag words #cute#sucks labels positive negative sentiment. Mohammad (2012) developed classifier detect emotions using tweets emotion word hashtags (e.g., #anger, #surprise)labeled data.system too, make use emoticons hashtag words signals positivenegative sentiment. collected 775,000 sentiment-word hashtagged tweets used1.6 million emoticon tweets collected Go et al. (2009). However, unlike previous research,generate sentiment lexicons datasets use (along relativelysmall hand-labeled training dataset) train supervised classifier. approachfollowing benefits. First, allows us incorporate large amounts noisily labeled dataquickly efficiently. Second, classification system robust introduced noisenoisy data incorporated directly training instances indirectlyfeatures. Third, generated sentiment lexicons easily distributed amongresearch community employed applications domains (Kiritchenko,Zhu, Cherry, & Mohammad, 2014).Negation plays important role determining sentiment. Automatic negation handling involves identifying negation word not, determining scope negation(which words affected negation word), finally appropriately capturingimpact negation. (See work Jia, Yu, Meng (2009), Wiegand, Balahur, Roth,Klakow, Montoyo (2010), Lapponi, Read, Ovrelid (2012) detailed analysesnegation handling.) Traditionally, negation word determined small hand727fiKiritchenko, Zhu, & Mohammadcrafted list (Taboada et al., 2011). scope negation often assumed beginword following negation word next punctuation mark endsentence (Polanyi & Zaenen, 2004; Kennedy & Inkpen, 2005). sophisticated methodsdetect scope negation semantic parsing also proposed (Li, Zhou,Wang, & Zhu, 2010).common way capture impact negation reverse polaritiessentiment words scope negation. Taboada et al. (2011) proposed shiftsentiment score term negated context towards opposite polarity fixedamount. However, experiments shift-score model agree humanjudgment many cases, especially negated negative terms. complex approaches,recursive deep models, address negation semantic composition (Socher,Huval, Manning, & Ng, 2012; Socher et al., 2013). recursive deep models workbottom-top fashion parse-tree structure sentence infer sentiment labelsentence composition sentiment expressed constituting parts: wordsphrases. models require hand-crafted features semantic knowledge,list negation words. However, computationally intensive needsubstantial additional annotations (word phrase-level sentiment labeling) producecompetitive results (Socher et al., 2013). paper, propose simple corpus-basedstatistical method estimate sentiment scores negated words. shownSection 6.2.2, simple method able achieve level accuracy recursivedeep learning approach. Additionally, analyze impact negation sentiment scorescommon sentiment terms.promote research sentiment analysis short informal texts establishcommon ground comparison different approaches, international competitionorganized Conference Semantic Evaluation Exercises (SemEval-2013) (Wilsonet al., 2013). organizers created shared tweets training, development,testing. also provided second test set consisting SMS messages. purposeout-of-domain test set assess ability systems trained tweetsgeneralize types short informal texts. competition attracted 44 teams;48 submissions 34 teams message-level task 29 submissions23 teams term-level task. participants (including top 3 systems task)chose supervised machine learning approach exploiting variety features derivedngrams, stems, punctuation, POS tags, Twitter-specific encodings (e.g., emoticons,hashtags, abbreviations). one top-performing systems entirely rule-basedhand-written rules (Reckman, Baird, Crawford, Crowell, Micciulla, Sethi, & Veress,2013). Twitter-specific pre-processing (e.g., tokenization, normalization) well negationhandling commonly applied. Almost systems benefited sentiment lexicons:MPQA Subjectivity Lexicon, SentiWordNet, others. Existing, low-coverage lexiconssometimes extended distributionally similar words (Proisl, Greiner, Evert, &Kabashi, 2013) sentiment-associated words collected noisily labeled data (Becker,Erhart, Skiba, & Matula, 2013). extended lexicons, however, still ordermagnitude smaller tweet-specific lexicons created. full resultscompetition details refer reader Wilson et al. (2013).research approaches sentiment analysis two-tier problem: first piece textmarked either objective subjective, subjective text assessed728fiSentiment Analysis Short Informal Textsdetermine whether positive, negative, neutral (Wiebe, Wilson, & Cardie, 2005;Choi & Cardie, 2010; Johansson & Moschitti, 2013; Yang & Cardie, 2013). However,lead propagation errors (for example, system may mark subjective textobjective). Further, one argue even objective statements express sentiment(for example, sales Blackberries 0.002% used 5 years back).model sentiment directly three-class problem: positive, negative, neutral.Also, paper focuses sentiment analysis alone consider taskassociating sentiment targets. interesting work studyinglatter problem (e.g., Jiang, Yu, Zhou, Liu, & Zhao, 2011; Sauper & Barzilay, 2013).(Kiritchenko et al., 2014) show approach adapted identifysentiment specified target. system ranked first SemEval-2014 shared taskAspect Based Sentiment Analysis.3. Task Data Descriptionwork, follow definition task use data provided SemEval2013 competition: Sentiment Analysis Twitter (Wilson et al., 2013). competitiontwo tasks: message-level task term-level task. objective messagelevel task detect whether whole message conveys positive, negative, neutralsentiment. objective term-level task detect whether given target term (asingle word multi-word expression) conveys positive, negative, neutral sentimentcontext message. Note term may express different sentimentsdifferent contexts. example, word unpredictable expresses positive sentimentsentence movie unpredictable ending; whereas, expresses negative sentimentsentence car unpredictable steering.Two test sets one tweets one SMS messages providedparticipants task. Training development data available tweets.briefly describe data collected annotated (for details seetask description paper (Wilson et al., 2013)). Tweets collected publicstreaming Twitter API period one year: January 2012 January 2013.reduce data skew towards neutral class, messages contain polarityword listed SentiWordNet 3.0 discarded. remaining messages annotatedsentiment Mechanical Turk.4 annotator mark positive, negative,neutral parts message well provide overall polarity label message.Later, annotations combined intersection term-level taskmajority voting message-level task. details data collection annotationreleased participants competition.data characteristics tasks shown Table 1. training setdistributed tweet ids download script. However, tweets accessible.example, Twitter user could deleted messages, thus messageswould available. Table 1 shows number training examples abledownload. development test sets provided full FTP.4. Messages presented annotators polarity words marked way.729fiKiritchenko, Zhu, & MohammadTable 1: Data statistics SemEval-2013 training set, development set two testingsets. # tokens per mess. denotes average number tokens per messagedataset. Vocab. size represents number unique tokens excludingpunctuation numerals.DatasetPositiveMessage-level task:Training set3,045 (37%)Development set575 (35%)Tweet test set1,572 (41%)SMS test set492 (23%)Term-level task:Training set4,831 (62%)Development set648 (57%)Tweet test set2,734 (62%)SMS test set1,071 (46%)Number instancesNegativeNeutral1,209340601394(15%)(20%)(16%)(19%)2,5404301,5411,104(33%)(38%)(35%)(47%)4,0047391,6401,208(48%)(45%)(43%)(58%)38557160159(5%)(5%)(3%)(7%)Total# tokensper mess.Vocab.size8,2581,6543,8132,09422.0922.1922.1518.0521,8486,54312,9773,5137,7561,1354,4352,33422.5522.9322.6319.9515,2383,90910,3832,979tweets comprised regular English-language words well Twitter-specificterms, emoticons, URLs, creative spellings. Using WordNet 3.05 (147,278word types) supplemented large list stop words (571 words)6 repositoryEnglish-language words, found 45% vocabulary tweet datasetsout-of-dictionary terms. out-of-dictionary terms fall different categories, e.g.,named entities (names people, places, companies, etc.) found WordNet, hashtags,user mentions, etc. use Carnegie Mellon University (CMU) Twitter NLP toolautomatically identify categories. tool shown achieve 89% tagging accuracytweet data (Gimpel, Schneider, OConnor, Das, Mills, Eisenstein, Heilman, Yogatama,Flanigan, & Smith, 2011). Table 2 shows distribution out-of-dictionary termscategory.7 One observe out-of-dictionary terms named entitieswell user mentions, URLs, hashtags. also moderate amount creativelyspelled regular English words slang words used nouns, verbs, adjectives.SMS test set, out-of-dictionary terms constitute smaller proportion vocabulary,25%. mostly named entities, interjections, creative spellings, slang.SemEval-2013 training development data used train supervised sentiment analysis system presented Section 5. performance system evaluatedtest sets, tweets SMS (Section 6.2.2). test data also usedexperiments comparing performance sentiment lexicons unsupervised settings(Section 6.2.1).5. http://wordnet.princeton.edu6. SMART stopword list built Gerard Salton Chris Buckley SMART information retrievalsystem Cornell University (http://www.lextek.com/manuals/onix/stopwords2.html) used.7. percentages columns sum 100% terms used multiplecategories (e.g., noun verb).730fiSentiment Analysis Short Informal TextsTable 2: distribution out-of-dictionary tokens category SemEval-2013tweet SMS test sets.Category tokensnamed entitiesuser mentionsURLshashtagsinterjectionsemoticonsnounsverbsadjectivesadverbsothersTweet test set31.84%21.23%16.92%10.94%2.56%1.40%8.52%3.05%1.43%0.70%4.00%SMS test set32.63%0.11%0.84%0%10.32%1.89%25.47%18.95%4.84%6.21%15.69%addition SemEval-2013 datasets, evaluate system dataset moviereview excerpts (Socher et al., 2013). task predict sentiment label (positivenegative) given sentence, extracted longer movie review (message-level task).dataset comprised 4,963 positive 4,650 negative sentences split training (6,920 sentences), development (872 sentences), test (1,821 sentences) sets. Sincedetailed phrase-level annotations available real-world applications, usesentence-level annotations ignore phrase-level annotations parse-treestructures sentences provided data. train sentiment analysis systemtraining development subsets evaluate performance test subset.results experiments reported Section 6.2.2.4. Sentiment Lexicons Used System4.1 Existing, General-Purpose, Manually Created Sentiment Lexiconslexicons created manual annotation tend domain freeinclude thousand terms. lexicons use include NRC Emotion Lexicon(Mohammad & Turney, 2010), Bing Lius Lexicon (Hu & Liu, 2004), MPQA Subjectivity Lexicon (Wilson et al., 2005). NRC Emotion Lexicon comprised frequentEnglish nouns, verbs, adjectives, adverbs annotated eight emotions (joy, sadness,anger, fear, disgust, surprise, trust, anticipation) well positive negativesentiment. Bing Lius Lexicon provides list positive negative words manually extracted customer reviews. MPQA Subjectivity Lexicon contains words markedprior polarity (positive negative) discrete strength evaluative intensity(strong weak). Entities lexicons come real-valued score indicatingfine-grained evaluative intensity.731fiKiritchenko, Zhu, & Mohammad4.2 New, Tweet-Specific, Automatically Generated Sentiment Lexicons4.2.1 Hashtag Sentiment LexiconCertain words tweets specially marked hashtag (#) indicate topicsentiment. Mohammad (2012) showed hashtagged emotion words #joy,#sad, #angry, #surprised good indicators tweet whole (even withouthashtagged emotion word) expressing emotion. adapted ideacreate large corpus positive negative tweets. corpus automaticallygenerated high-coverage, tweet-specific sentiment lexicon described below.polled Twitter API every four hours April December 2012 searchtweets either positive-word hashtag negative-word hashtag. collection77 seed words closely associated positive negative sentiment #good,#excellent, #bad, #terrible used (30 positive 47 negative). termschosen entries positive negative Rogets Thesaurus8 . 2 million tweetscollected total. used metadata tag iso language code identify Englishtweets. Since tag always reliable, additionally discarded tweetsleast two valid English content words Rogets Thesaurus.9 step alsohelped discard short tweets tweets large proportion misspelled words.set 775,000 remaining tweets, refer Hashtag Sentiment Corpus,used generate large wordsentiment association lexicon. tweet consideredpositive one 30 positive hashtagged seed words, negative one47 negative hashtagged seed words. sentiment score term w calculatedpseudo-labeled tweets shown below:Sentiment Score (w) = PMI (w , positive) PMI (w , negative)(1)PMI stands pointwise mutual information:PMI (w , positive) = log2freq (w , positive) Nfreq (w ) freq (positive)(2)freq (w, positive) number times term w occurs positive tweets, freq (w)total frequency term w corpus, freq (positive) total number tokenspositive tweets, N total number tokens corpus. PMI (w, negative)calculated similar way. Thus, equation 1 simplified to:Sentiment Score (w) = log2freq (w , positive) freq (negative)freq (w , negative) freq (positive)(3)Since PMI known poor estimator association low-frequency events,ignore terms occurred less five times (positive negative) grouptweets.108. http://www.gutenberg.org/ebooks/106819. word thesaurus considered content word exception wordsSMART stopword list.10. threshold five occurrences least one class (positive negative) appliedautomatic tweet-specific lexicons discussed paper. thresholding sentimentscore.732fiSentiment Analysis Short Informal Textspositive sentiment score indicates greater overall association positive sentiment,whereas negative score indicates greater association negative sentiment.magnitude indicative degree association. Note exist numerousmethods estimate degree association term category (e.g., cross entropy,Chi-squared, information gain). chosen PMI simple robustsuccessfully applied number NLP tasks (Turney, 2001; Turney &Littman, 2003).final lexicon, refer Hashtag Sentiment Base Lexicon (HS Base)entries 39,413 unigrams 178,851 bigrams. Entries also generatedunigramunigram, unigrambigram, bigrambigram pairs necessarilycontiguous tweets corpus. Pairs least one terms punctuation (e.g.,,, ?, .), user mention, URL, function word (e.g., a, the, and)removed. lexicon entries 308,808 non-contiguous pairs.4.2.2 Sentiment140 LexiconSentiment140 Corpus (Go et al., 2009) collection 1.6 million tweets containemoticons. tweets labeled positive negative according emoticon.generated Sentiment140 Base Lexicon (S140 Base) corpus mannerdescribed hashtagged tweets using Equation 1. lexicon entries65,361 unigrams, 266,510 bigrams, 480,010 non-contiguous pairs. followingsection, build proposed approach create separate lexicons termsaffirmative contexts terms negated contexts.4.3 Affirmative Context Negated Context Lexiconsword negated context different evaluative nature wordaffirmative (non-negated) context. difference may include change polaritycategory (positive becomes negative vice versa), evaluative intensity, both.example, highly positive words (e.g., great) negated tend experience both, polaritychange intensity decrease, forming mildly negative phrases (e.g., great).hand, many strong negative words (e.g., terrible) negated keep negativepolarity shift intensity. conventional approach reversing polarityable handle cases properly.propose empirical method determine sentiment words presencenegation. create separate lexicons affirmative negated contexts. way, twosentiment scores term w computed: one affirmative contexts anothernegated contexts. lexicons created follows. Hashtag Sentiment Corpussplit two parts: Affirmative Context Corpus Negated Context Corpus. Followingwork Pang, Lee, Vaithyanathan (2002), define negated context segmenttweet starts negation word (e.g., no, shouldnt) ends onepunctuation marks: ,, ., :, ;, !, ?. list negation words adoptedChristopher Potts sentiment tutorial.11 Thus, part tweet marked negatedincluded Negated Context Corpus rest tweet becomes partAffirmative Context Corpus. sentiment label tweet kept unchanged11. http://sentiment.christopherpotts.net/lingstruc.html733fiKiritchenko, Zhu, & MohammadTable 3: Example sentiment scores Sentiment140 Base, Affirmative Context(AffLex) Negated Context (NegLex) Lexicons.TermSentiment140 LexiconsBase AffLex NegLexPositive termsgreatbeautifulnicegoodhonest1.1771.0490.9740.8250.3911.2731.1121.1491.1670.431-0.3670.217-0.912-1.414-0.123Negative termsterribleshamebaduglynegative-1.766-1.457-1.297-0.899-0.090-1.850-1.548-1.674-0.964-0.261-0.890-0.7220.021-0.7720.389corpora. Then, generate Affirmative Context Lexicon (HS AffLex)Affirmative Context Corpus Negated Context Lexicon (HS NegLex)Negated Context Corpus using technique described Section 4.2. refersentiment score calculated Affirmative Context Corpus score AffLex (w )score calculated Negated Context Corpus score NegLex (w ). Similarly,Sentiment140 Affirmative Context Lexicon (S140 AffLex) Sentiment140 NegatedContext Lexicon (S140 NegLex) built Affirmative Context NegatedContext parts Sentiment140 tweet corpus. employ lexicons separatedataset, apply technique split message affirmative negatedcontexts match words affirmative contexts Affirmative ContextLexicons words negated contexts Negated Context Lexicons.Computing sentiment score term w affirmative contexts makesscore AffLex (w ) precise since longer polluted negation. Positive terms getstronger positive scores negative terms get stronger negative scores. Furthermore,first time, create lexicons negated terms compute score NegLex (w ) reflects behaviour words presence negation. Table 3 shows examplespositive negative terms sentiment scores Sentiment140 Base, Affirmative Context (AffLex) Negated Context (NegLex) Lexicons. Fig. 1, visualizerelationship score AffLex (w ) score NegLex (w ) set words manually annotated sentiment MPQA Subjectivity Lexicon. x-axis score AffLex (w ),sentiment score term w Sentiment140 Affirmative Context Lexicon; y-axisscore NegLex (w ), sentiment score term w Sentiment140 Negated ContextLexicon. Dots plot correspond words occur MPQA Subjectivity Lexicon, Sentiment140 Affirmative Context Lexicon, Sentiment140 NegatedContext Lexicon. Furthermore, discard terms whose polarity category (positivenegative) Sentiment140 Affirmative Context Lexicon match polarityMPQA Subjectivity Lexicon. observe negated, 76% positive terms734fiSentiment Analysis Short Informal Texts3scoreNegLex(w)21scoreAffLex(w)0-4.5-3.5-2.5-1.5-0.50.51.52.53.54.5-1-2-3Figure 1: sentiment scores Sentiment140 AffLex Sentiment140 NegLex480 positive 486 negative terms MPQA Subjectivity Lexicon.x-axis score AffLex (w ), sentiment score term w Sentiment140Affirmative Context Lexicon; y-axis score NegLex (w ), sentiment scoreterm w Sentiment140 Negated Context Lexicon. dot correspondsone (positive negative) term. graph shows positive negative termsnegated tend convey negative sentiment. Negation affects sentimentdifferently term.reverse polarity whereas 82% negative terms keep polarity orientationshift sentiment scores. (This behaviour agrees well human judgmentsstudy Taboada et al. (2011).) Changes evaluative intensity vary termterm. example, score NegLex (good ) < score AffLex (good ) whereas score NegLex (great) >score AffLex (great).also compiled list 596 antonym pairs WordNet compare scoresterms Sentiment140 Affirmative Context Lexicon scores termsantonyms Sentiment140 Negated Context Lexicon. found 51% negatedpositive terms less negative corresponding antonyms (e.g.,score NegLex (good ) > score AffLex (bad )), 95% negated negative terms negativepositive antonyms (e.g., score NegLex (ugly) < score AffLex (beautiful )).experiments reveal tendency positive terms negated conveynegative sentiment tendency negative terms negated still conveynegative sentiment. Moreover, degree change evaluative intensity appearsterm-dependent. Capturing different behaviours terms negated contextsmeans Negated Context Lexicons empower automatic sentiment analysis systemdemonstrate experiments Section 6. Furthermore, believeAffirmative Context Lexicons Negated Context Lexicons valuable735fiKiritchenko, Zhu, & Mohammadapplications textual entailment recognition, paraphrase detection, machinetranslation. instance paraphrase detection task, given two sentences hotelroom wasnt terrible. hotel room excellent. automatic systemcorrectly infer sentences paraphrases looking score NegLex (terrible)score AffLex (excellent) seeing polarities intensities termsmatch (i.e., score AffLex (excellent) highly positive score NegLex (terrible) slightlynegative). time, mistake easily made conventional lexiconspolarity reversing strategy, according strong negative term terribleassumed convey strong positive sentiment presence negation and, therefore,polarities intensities two terms would match.4.4 Negated Context (Positional) Lexiconspropose improve method constructing Negated Context Lexiconssplitting negated context two parts: immediate context consisting single token directly follows negation word, distant context consistingrest tokens negated context. refer lexicons Negated Context(Positional) Lexicons. token Negated Context (Positional) Lexicon twoscores: immediate-context score distant-context score. benefits approachtwo-fold. Intuitively, negation affects words directly following negation wordstrongly words farther away. Compare, example, immediate negationgood distant negation good, good, good idea. Second,immediate-context scores less noisy. simple negation scope identification algorithmoccasionally fail include negated context parts tweet actuallynegated (e.g., punctuation mark missing). errors less effect immediatecontext. employing lexicons, use immediate-context score wordimmediately preceded negation word use distant-context scores wordsaffected negation. before, non-negated parts message, sentiment scoresAffirmative Context Lexicon used. Assuming words occur distant contextsoften immediate contexts, approach introduce sparsenesslexicons. Thus, apply back-off strategy: immediate-context score availabletoken immediately following negation word, distant-context score used instead.Section 6, experimentally show Negated Context (Positional) Lexicons provide additional benefits sentiment analysis system regular Negated ContextLexicons described previous section.4.5 Lexicon CoverageTable 4 shows number positive negative entries sentiment lexiconsdiscussed above. automatically generated lexicons order magnitude largermanually created lexicons. see manual lexicons containnegative terms positive terms. automatically generated lexicons, imbalanceless pronounced (49% positive vs. 51% negative Hashtag Sentiment Base Lexicon)even reversed (61% positive vs. 39% negative Sentiment140 Base Lexicon).Sentiment140 Base Lexicon created equal number positive negativetweets. Therefore, prevalence positive terms corresponds general trend736fiSentiment Analysis Short Informal TextsTable 4: number positive negative entries sentiment lexicons.LexiconNRC Emotion LexiconBing Lius LexiconMPQA Subjectivity LexiconHashtag Sentiment Lexicons (HS)HS Base Lexicon- unigrams- bigramsHS AffLex- unigrams- bigramsHS NegLex- unigrams- bigramsSentiment140 Lexicons (S140)S140 Base Lexicon- unigrams- bigramsS140 AffLex- unigrams- bigramsS140 NegLex- unigrams- bigramsPositive2,312 (41%)2,006 (30%)2,718 (36%)Negative3,324 (59%)4,783 (70%)4,911 (64%)Total5,6366,7897,62919,121 (49%)69,337 (39%)20,292 (51%)109,514 (61%)39,413178,85119,344 (51%)67,070 (42%)18,905 (49%)90,788 (58%)38,249157,858936 (14%)3,954 (15%)5,536 (86%)22,258 (85%)6,47226,21239,979 (61%)135,280 (51%)25,382 (39%)131,230 (49%)65,361266,51040,422 (63%)133,242 (55%)23,382 (37%)107,206 (45%)63,804240,4481,038 (12%)5,913 (16%)7,315 (88%)32,128 (84%)8,35338,041language supports Polyanna Hypothesis (Boucher & Osgood, 1969), statespeople tend use positive terms frequently diversely negative. Note,however, negative terms dominant Negated Context Lexicons sinceterms, positive negative, tend convey negative sentiment presencenegation. overall sizes Negated Context Lexicons rather small since negationoccurs 24% tweets Hashtag Sentiment140 corpora partmessage negation actually negated.Table 5 shows differences coverage lexicons. Specifically, givesnumber additional terms lexicon row X comparison lexicon columnpercentage tokens SemEval-2013 tweet test set covered extraentries lexicon X (numbers brackets). instance, almost half Bing Lius Lexicon(3,457 terms) found Sentiment140 Base Lexicon. However, additionalterms represent 0.05% tokens tweet test set. termsrarely used short informal writing (e.g., acrimoniously, bestial, nepotism).manually created lexicons covers extra 23% test data compared manuallexicons. hand, automatically generated lexicons cover 60% tokenstest data. automatic lexicons provide number terms found other.737fiKiritchenko, Zhu, & MohammadTable 5: Lexicons supplemental coverage: row X column Y, number LexiconXs entries found Lexicon (in brackets) percentagetokens SemEval-2013 tweet test set covered extra entries Lexicon X. NRC stands NRC Emotion Lexicon, B.L. Bing Lius Lexicon,MPQA MPQA Subjectivity Lexicon, HS Hashtag Sentiment BaseLexicon, S140 Sentiment140 Base Lexicon.LexiconNRCB.L.MPQAHSS140NRC3,179 (2.25%)3,010 (2.00%)2,480 (0.09%) 1,973 (0.05%)B.L.4,410 (1.72%)1,383 (0.70%)4,001 (0.07%) 3,457 (0.05%)MPQA3,905 (3.37%)1,047 (2.60%)3,719 (0.07%) 3,232 (0.04%)HS36,338 (64.23%) 36,628 (64.73%) 36,682 (62.84%)15,185 (0.59%)S14061,779 (64.13%) 62,032 (64.65%) 62,143 (62.74%) 41,133 (0.53%)-5. System5.1 Classifiersystem, NRC-Canada Sentiment Analysis System, employs supervised statistical machine learning. tasks, message-level term-level, train linear-kernel Support Vector Machine (SVM) (Chang & Lin, 2011) classifier available training data.SVM state-of-the-art learning algorithm proved effective text categorizationtasks robust large feature spaces. preliminary experiments, linear-kernelSVM outperformed maximum-entropy classifier. Also, linear-kernel SVM showed better performance SVM another commonly used kernel, radial basis function(RBF).classification model leverages variety surface-form, semantic, sentimentlexicon features described below. sentiment lexicon features derived threeexisting, general-purpose, manual lexicons (NRC Emotion Lexicon, Bing Lius Lexicon,MPQA Subjectivity Lexicon), four newly created, tweet-specific lexicons (HashtagSentiment Affirmative Context, Hashtag Sentiment Negated Context (Positional), Sentiment140 Affirmative Context, Sentiment140 Negated Context (Positional)).5.2 Features5.2.1 Message-Level Taskmessage-level task, following pre-processing steps performed. URLsuser mentions normalized http://someurl @someuser, respectively. Tweetstokenized part-of-speech tagged CMU Twitter NLP tool (Gimpel et al., 2011).Then, tweet represented feature vector. employ commonly used text classification features ngrams part-of-speech tag counts, well common Twitterspecific features emoticon hashtag counts. addition, introduce severallexicon features take advantage knowledge present manually automatically created lexicons. features designed explicitly handle negation. Table 6738fiSentiment Analysis Short Informal TextsTable 6: Examples features system would generate message GRRREATshow!!! Hope miss next one :). Numeric features presentedformat: <feature name>:<feature value>. Binary features italicized;features value 1 shown.Feature groupword ngramscharacter ngramsall-capsPOSautomatic lexiconfeaturesmanual lexiconfeaturespunctuationemoticonselongated wordsclustersExamplesgrrreat, show, grrreat show, miss NEG, miss NEGgrr, grrr, grrre, rrr, rrre, rrreaall-caps:1POS N:1 (nouns), POS V:2 (verbs), POS E:1 (emoticons),POS ,:1 (punctuation)HS unigrams positive count:4, HS unigrams negative total score:1.51,HS unigrams POS N combined total score:0.19,HS bigrams positive total score:3.55, HS bigrams negative max score:1.98MPQA positive affirmative score:2, MPQA negative negated score:1,BINGLIU POS V negative negated score:1punctuation !:1emoticon positive:1, emoticon positive lastelongation:1cluster 11111001110, cluster 10001111provides example features tweet GRRREAT show!!! Hope miss nextone :).features:word ngrams: presence absence contiguous sequences 1, 2, 3, 4 tokens;non-contiguous ngrams (ngrams one token replaced *);character ngrams: presence absence contiguous sequences 3, 4, 5 characters;all-caps: number tokens characters upper case;POS: number occurrences part-of-speech tag;hashtags: number hashtags;negation: number negated contexts. Negation also affects ngram features:word w becomes w NEG negated context;sentiment lexicons:Automatic lexicons following sets features generated separatelyHashtag Sentiment Lexicons (HS AffLex HS NegLex (Positional))Sentiment140 Lexicons (S140 AffLex S140 NegLex (Positional)).token w occurring tweet present lexicons, use sentimentscore (score AffLex (w ) w occurs affirmative context score NegLex (w )w occurs negated context) compute:number tokens score(w) 6= 0;Ptotal score = wtweet score(w);maximal score = max wtweet score(w);739fiKiritchenko, Zhu, & Mohammadscore last token tweet.features calculated positive tokens (tokens sentiment scoresgreater zero), negative tokens (tokens sentiment scores lesszero), tokens tweet. Similar feature sets also createdpart-of-speech tag hashtags. Separate feature sets producedunigrams, bigrams, non-contiguous pairs.Manual lexicons three manual sentiment lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon), computefollowing four features:sumsumsumsumpositive scores tweet tokens affirmative contexts;negative scores tweet tokens affirmative contexts;positive scores tweet tokens negated contexts;negative scores tweet tokens negated contexts.Negated contexts identified exactly described earlier Section 4.3 (themethod creating Negated Context Corpora). remaining partsmessages treated affirmative contexts. use score +1 positiveentries score -1 negative entries NRC Emotion LexiconBing Lius Lexicon. MPQA Subjectivity Lexicon, provides twogrades association strength (strong weak), use scores +1/-1weak associations +2/-2 strong associations. feature setsalso created part-of-speech tag, hashtags, all-caps tokens.punctuation:number contiguous sequences exclamation marks, question marks,exclamation question marks;whether last token contains exclamation question mark;emoticons: polarity emoticon determined regular expressionadopted Christopher Potts tokenizing script:12presence absence positive negative emoticons positiontweet;whether last token positive negative emoticon;elongated words: number words one character repeated twotimes, example, soooo;clusters: CMU Twitter NLP tool provides token clusters producedBrown clustering algorithm 56 million English-language tweets. 1,000 clusters serve alternative representation tweet content, reducing sparcitytoken space.presence absence tokens 1000 clusters.12. http://sentiment.christopherpotts.net/tokenizing.html740fiSentiment Analysis Short Informal Texts5.2.2 Term-level Taskpre-processing steps term-level task include tokenization stemmingPorter stemmer (Porter, 1980).13 Then, tweet represented feature vectorfollowing groups features:word ngrams:presence absence unigrams, bigrams, full word string targetterm;leading ending unigrams bigrams;character ngrams: presence absence two- three-character prefixes suffixeswords target term (note target term may multi-wordsequence);upper case:whether words target start upper case letter followedlower case letters;whether target words uppercase (to capture potential namedentity);stopwords: whether term contains stop-words. so, separate set featuresindicates whether 1, 2, 3, stop-words;negation: similar message-level task;sentiment lexicons: manual sentiment lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon) automatic sentimentlexicons (HS AffLex HS NegLex (Positional), S140 AffLex S140 NegLex(Positional) Lexicons), compute following three features:sum positive scores;sum negative scores;total score.manual lexicons, polarity reversing strategy applied negation.14 Notewords stems matched sentiment lexicons.punctuation: presence absence punctuation sequences ?! !!!;emoticons: numbers categories emoticons term contains15 ;elongated words: presence absence elongated words;lengths:length target term (number words);13. differences implementation, use stemmer, simply result different teammembers working two tasks.14. experiments development dataset, manual lexicon features showed better performanceterm-level task set four features used message-level task.15. http://en.wikipedia.org/wiki/List emoticons741fiKiritchenko, Zhu, & Mohammadaverage length words (number characters) term;binary feature indicating whether term contains long words;position: whether term beginning, end, another positiontweet;term splitting: term contains hashtag made multiple words (e.g., #biggestdaythisyear ), split hashtag component words;others:whether term contains Twitter user name;whether term contains URL.features extracted target terms well restmessage (the context). unigrams bigrams, use four words either sidetarget context. window size chosen experiments developmentset.6. Experimentssection presents evaluation experiments demonstrate state-of-the-art performance sentiment analysis system three domains: tweets, SMS, moviereview excerpts. experiments also reveal superior predictive power new,tweet-specific, automatically created lexicons existing, general-purpose lexicons. Furthermore, show Negated Context Lexicons bring additional gainsstandard polarity reversing strategy handling negation.begin intrinsic evaluation automatic lexicons comparingmanually created sentiment lexicons human annotated sentiment scores. Next,assess value lexicons part sentiment analysis system both, supervisedunsupervised settings. goal experiments unsupervised sentiment analysis(Section 6.2.1) compare predictive capacity lexicons simplest setupreduce influence factors (such choice features) much possible.Also, evaluate impact amount data used create automatic lexiconquality lexicon. Then, Section 6.2.2 evaluate performancesupervised sentiment analysis system analyze contributions features deriveddifferent sentiment lexicons.6.1 Intrinsic Evaluation Lexiconsintrinsically evaluate tweet-specific, automatically created sentiment lexicons, firstcompare existing manually created sentiment lexicons (Section 6.1.1). However,existing manual lexicons tend discrete labels terms (positive, negative,neutral) real-valued scores indicating intensity sentiment. Section 6.1.2,show collected human annotated real-valued sentiment scores using MaxDiffmethod annotation (Louviere, 1991). compare association scoresautomatically generated lexicons human annotated scores.742fiSentiment Analysis Short Informal TextsTable 7: Agreement polarity assignments Sentiment140 Affirmative ContextLexicon manual lexicons. Agreement two lexicons measuredpercentage shared terms given sentiment label (positivenegative) lexicons. agreement calculated three sets terms:(1) shared terms; (2) shared terms whose sentiment score S140 AffLexabsolute value greater equal 1 (|score(w)| 1); (3) shared termswhose sentiment score S140 AffLex absolute value greater equal2 (|score(w)| 2). Sentiment scores S140 AffLex range -5.9 6.8.LexiconNRC Emotion LexiconBing Lius LexiconMPQA Subjectivity LexiconNumbershared terms3,4723,2133,105terms73.96%78.24%75.91%Agreement|score(w)| 1 |score(w)| 289.96%98.61%92.32%99.45%90.26%98.59%6.1.1 Comparing Existing Manually Created Sentiment Lexiconsexamine terms intersection manual lexicon automatic lexiconmeasure agreement lexicons percentage shared termspolarity label (positive negative) assigned lexicons. Table 7 showsresults Sentiment140 Affirmative Context Lexicon three manual lexicons: NRCEmotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon. Similar figures (notshown table) obtained automatic lexicons (HS Base Lexicon, HS AffLex,S140 Base): agreement terms ranges 71% 78%. considerterms whose sentiment scores automatic lexicon higher absolute values,agreement numbers substantially increase. Thus, automatically generated entrieshigher absolute sentiment values prove reliable.6.1.2 Comparing Human Annotated Sentiment Association ScoresApart polarity labels, automatic lexicons provide sentiment scores indicatingdegree association term positive negative sentiment. notedindividual scores somewhat meaningless abilityindicate one word positive (or negative) another. However,exists resource used determine real-valued scores match humanintuition. section, describe collected human annotations termssentiment association scores using crowdsourcing.MaxDiff method annotation: people, assigning score indicating degreesentiment natural. Different people may assign different scores targetitem, hard even annotator remain consistent annotatinglarge number items. contrast, easier annotators determine whether one wordpositive (or negative) other. However, latter requires muchlarger number annotations former (in order N 2 , N numberitems annotated). MaxDiff annotation scheme retains comparative743fiKiritchenko, Zhu, & Mohammadaspect annotation still requiring small number annotations (Louviere,1991).annotator presented four words asked word positiveleast positive. answering two questions five sixinequalities known. Consider set respondent evaluates: A, B, C D.respondent says positive least positive, two responsesinform us that:> B, > C, > D, B > D, C >MaxDiff questions presented multiple annotators. responsesMaxDiff questions easily translated ranking termsalso real-valued score terms (Orme, 2009). two words differentdegrees association (for example, >> D), chosen positive muchoften chosen least positive much often A.eventually lead ranked list significantly farther apart,real-valued association scores also significantly different. hand,two words similar degrees association positive sentiment (for example,B), possible MaxDiff questions B, annotatorschoose positive, choose B positive. Further,B chosen positive (or negative) similar number times.result list B ranked close real-valuedassociation scores also close value.MaxDiff method widely used market survey questionnaires (Almquist & Lee,2009). also used determining relation similarity pairs items Jurgens,Mohammad, Turney, Holyoak (2012) SemEval-2012 shared task.Term selection: evaluation automatic lexicons, selected 1,455 highfrequency terms Sentiment140 Corpus Hashtag Sentiment Corpus.subset terms includes regular English words, Twitter-specific terms (e.g., emoticons, abbreviations, creative spellings), negated expressions. terms chosen follows.terms corpora, excluding URLs, user mentions, stop words, termsnon-letter characters, ordered frequency. reduce subset skew towardsneutral class, terms selected different ranges sentiment values. this,full range sentiment values automatic lexicons divided 10 equal-sizebins. bin, naff frequent affirmative terms nneg frequent negatedterms selected form initial list.16 . naff set 200 nneg 50bins except two middle bins contain words weak association sentiment (i.e., neutral words). two middle bins, naff = 80 nneg = 20. Then,initial list manually examined, ambiguous terms, rare abbreviations, extremelyobscene words (243 terms) removed. resulting list augmented25 frequent emoticons. final list 1,455 terms contains 1,202 affirmative terms253 negated terms; 946 words found WordNet 509 out-of-dictionaryterms. negated term presented annotators phrase negator + term,16. bins may contain fewer naff affirmative fewer nneg negated terms. case,available affirmative/negated terms selected.744fiSentiment Analysis Short Informal Textsnegator chosen frequent negator term (e.g., respect,acceptable).Annotation process: term list converted 3,000 MaxDiffsubsets 4 terms each. terms subsets chosen randomly termlist. duplicate terms allowed subset, subset unique.MaxDiff subset, annotators asked identify term associationpositive sentiment (i.e., positive term) term least associationpositive sentiment (i.e., negative term). subset annotated 10annotators. given question, refer option chosen oftenmajority answer. question answered randomly annotators, 25%annotators expected select majority answer (as question fouroptions). task, observed majority answer selected 72%annotators average.answers converted scores using counting procedure (Orme, 2009).term, score calculated percentage times term chosenpositive minus percentage times term chosen negative.scores normalized range [0,1]. Even though annotators might disagreeanswers individual questions, aggregated scores produced countingprocedure corresponding term ranking consistent. verified randomlydividing sets answers question two groups comparing scoresrankings obtained two groups annotations. average, scores differed0.04, Spearman rank correlation coefficient two sets rankings0.97. rest paper, use scores term ranking produced fullset annotations. refer scores human annotated sentiment associationscores.Comparing human annotated automatic sentiment scores: humanannotated scores used evaluate sentiment scores automatically generated,tweet-specific lexicons. scores meaningfulability rank terms order increasing (or decreasing) association positive (ornegative) sentiment. terms t1 t2 rank (t1 ) > rank (t2 ) perrankings (human automatic), term pair (t1 , t2 ) consideredrank order.17 measure agreement human automatic sentiment rankingspercentage term pairs rank order same.18two terms similar degree association sentiment,likely humans disagree regarding order. Similarly, greater difference true sentiment scores, likely humansagree regarding order. Thus, first create several sets termpairs pertaining various minimal differences human sentiment scores, calculateagreement sets. Every set pairsk term pairs (t1 , t2 )Human Score (t1 ) 6= Human Score (t2 ) |Human Score (t1 ) Human Score (t2 )| k,k varied 0 0.8 steps 0.1. Thus, pairs0 includes term pairs (t1 , t2 )Human Score (t1 ) 6= Human Score (t2 ). Similarly, pairs0 .1 includes term pairs|Human Score (t1 ) Human Score (t2 )| 0.1, on. agreement17. One swap t2 t1 without loss generality.18. measure agreement use similar Kendalls tau rank correlation coefficient.745fiKiritchenko, Zhu, & Mohammad100agreement9590HS Base LexiconS140 Base LexiconHS AffLex HS NegLexS140 AffLex S140 NegLex858075min. abs. score difference7000.10.20.30.40.50.60.70.8Figure 2: Agreement pair order ranking automatic lexicons human annotations. agreement (y-axis) measured percentage term pairsrank order obtained lexicon human annotations.x-axis represents minimal absolute difference human annotated scoresterm pairs (k). results HS AffLex HS NegLex close results HS Base Lexicon, and, therefore, two curves indistinguishablegraph.given set pairsk percentage term pairs set rank orderper human annotations automatically generated scores. expect higherrank-order agreement sets pertaining higher ksets larger difference human(or true) scores. plot agreement human annotations automaticlexicon function k (x-axis) Figure 2.agreement pairs0 used bottom-line overall agreement scorehuman annotations automatically generated scores. One observe overallagreement automatic lexicons 7578%. agreement curves monotonicallyincrease difference human scores getting larger, eventually reaching 100%.monotonic increase expected move farther right along x-axis, term pairsets higher average difference human scores considered. demonstratesautomatic sentiment lexicons correspond well human intuition, especiallyterm pairs larger difference human scores.6.2 Extrinsic Evaluation Lexicons6.2.1 Lexicon Performance Unsupervised Sentiment Analysisset experiments, evaluate performance individual lexiconmessage-level sentiment analysis task unsupervised settings. training and/or tuningperformed. Since lexicons provide association scores positivenegative classes only, subsection, reduce problem two-way classificationtask (positive negative). SemEval-2013 tweet test set SMS test set usedevaluation. neutral instances removed datasets.746fiSentiment Analysis Short Informal Textsclassify message positive negative, add scores matchesparticular lexicon assign positive label cumulative score greater zeronegative label cumulative score less zero. Again, use scores +1/-1NRC Emotion Lexicon Bing Lius Lexicon scores +1/-1 weak associations+2/-2 strong associations MPQA Subjectivity Lexicon. message leftunclassified score equal zero matches found.Table 8 presents results unsupervised sentiment analysis (1) manually created, general-purpose lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQASubjectivity Lexicon), (2) automatically created, general-purpose lexicons (SentiWordNet3.0 (Baccianella, Esuli, & Sebastiani, 2010), MSOL (Mohammad et al., 2009), OsgoodEvaluative Factor Ratings (Turney & Littman, 2003)), (3) automatically created,tweet-specific lexicons (Hashtag Sentiment Sentiment140 Lexicons). unigramentries used lexicon. automatic general-purpose lexicons large, opendomain lexicons providing automatically generated sentiment scores words takenhand-built general thesauri WordNet Macquarie Thesaurus.19 predictiveperformance assessed precision recall positive negative classeswell macro-averaged F-score two classes. Observelexicons, precision recall negative class lower positive class.particular, holds manual lexicons (rows ac) despite factsignificantly negative terms positive terms. One possible explanationphenomenon people express negative sentiment without using manyclearly negative words.threshold zero seems natural separating positive negative classesunsupervised polarity detection; however, better results possible thresholds.example, predictions produced Osgood Evaluative Factor Ratings (rows f)highly skewed towards positive class (recall 95.42 positive class 31.28negative class), negatively affects macro-averaged F-score. avoidproblem setting optimal threshold unsupervised settings, report AreaROC curve (AUC), takes account performance classifierpossible thresholds (see last column Table 8). calculate AUC, cumulativescores assigned lexicon test messages ordered decreasing order. Then,taking every score possible threshold, true positive ratio plotted falsepositive ratio area curve calculated. shown AUCclassifier equivalent probability classifier rank randomly chosenpositive instance higher randomly chosen negative instance. also equivalentWilcoxon test ranks (Hanley & McNeil, 1982).automatically generated lexicons match least one token test messagemanual lexicons unable cover 1020% tweet test set. Paying attentionnegation proves important general-purpose lexicons: macro-averaged Fscore AUC improved 14 percentage points. However, caseHashtag Sentiment Base (rows g) Sentiment140 Base Lexicons (rows k).polarity reversing strategy fails improve simple baseline disregarding negationlexicons.19. SentiWordNet 3.0 30,821 unigrams, MSOL Lexicon 55,141 unigrams, OsgoodEvaluative Factor Ratings Lexicon contains ratings 72,905 unigrams.747fiKiritchenko, Zhu, & MohammadTable 8: Prediction performance unigram lexicons unsupervised sentiment analysisSemEval-2013 tweet test set. Cover. denotes coverage percentagetweets test set least one match lexicon; P precision; Rrecall; Favg macro-averaged F-score positive negative classes;AUC area ROC curve.LexiconManual general-purpose lexiconsa. NRC Emotion Lexicon- disregarding negation- reversing polarityb. Bing Lius Lexicon- disregarding negation- reversing polarityc. MPQA Subjectivity Lexicon- disregarding negation- reversing polarityAutomatic general-purpose lexiconsd. SentiWordNet 3.0- disregarding negation- reversing polaritye. MSOL- disregarding negation- reversing polarityf. Osgood Evaluative Factor Ratings- disregarding negation- reversing polarityAutomatic tweet-specific lexiconsg. HS Base Lexicon- disregarding negation- reversing polarityh. HS AffLex- disregarding negation- reversing polarityi. HS AffLex HS NegLexj. HS AffLex HS NegLex (Posit.)k. S140 Base Lexicon- disregarding negation- reversing polarityl. S140 AffLex- disregarding negation- reversing polaritym. S140 AffLex S140 NegLexn. S140 AffLex S140 NegLex (Posit.)- tweet-specific entriesCover.PositivePRNegativePRFavgAUC76.3076.3084.77 58.78 56.83 34.61 56.22 70.6686.20 59.61 59.02 35.94 57.58 72.8377.5977.5990.73 61.64 65.94 45.42 63.60 79.0892.02 61.64 66.74 48.75 65.09 80.2088.3688.3682.90 71.56 58.57 38.10 61.49 73.0184.56 71.06 60.09 43.09 63.71 75.33100.00100.0082.40 71.76 44.93 59.73 64.00 71.5185.08 71.12 47.42 67.22 66.54 75.15100.00100.0077.18 74.43 38.66 27.79 54.06 63.4477.35 74.30 41.70 30.95 55.66 63.80100.00100.0075.65 97.65 74.31 17.80 56.99 75.3078.41 95.42 72.31 31.28 64.88 80.11100.00100.0089.15 72.65 51.79 76.87 70.97 82.5288.03 72.07 50.45 74.38 69.69 80.21100.00100.00100.00100.0087.53 80.41 57.75 70.05 73.56 83.0687.04 79.07 55.84 69.22 72.34 82.2189.44 77.04 55.92 76.21 73.64 84.6189.60 77.29 56.30 76.54 73.94 84.62100.00100.0088.60 77.61 55.78 73.88 73.15 84.4787.78 77.23 54.68 71.88 72.14 83.21100.00100.00100.00100.00100.0085.9687.1989.6589.7987.2674886.4585.3183.2183.3386.2664.0263.5663.0363.3165.1163.0667.0574.8875.2167.0574.8775.7577.3777.5976.4184.9486.0486.8887.1486.55fiSentiment Analysis Short Informal TextsCompared Base Lexicons, lexicons created affirmative contexts(rows h l) precise slightly improve predictive performance.substantial improvements obtained adding Negated Context Lexicons (rowsm). Furthermore, Sentiment140 Negated Context (Positional) Lexicon (row n) offersadditional gain 0.26 percentage points AUC regular Sentiment140 NegatedContext Lexicon (row m). Overall, Affirmative Context Lexicons NegatedContext (Positional) Lexicons outperform Base Lexicons 2 percentage pointsAUC.automatically created general-purpose lexicons (rows df) substantiallyhigher coverage; however, show better performance manual lexicons.hand, tweet-specific automatic lexicons demonstrate predictive powersuperior both, manually automatically created, general-purpose lexicons.differences especially pronounced Affirmative Context LexiconsNegated Context Lexicons. keeping level precision close manuallexicons, automatic tweet-specific lexicons able substantially improve recallpositive negative classes. increase recall particularly noticeablenegative class differences reach forty percentage points.investigate impact tweet-specific subset vocabulary (e.g., emoticons,hashtags, misspellings) performance automatic lexicons, conductexperiments reduced lexicon. Terms punctuation, numerals, stopwords, found WordNet removed S140 AffLexS140 NegLex (Positional) Lexicons. performance reduced lexicon (last rowtable) drops 0.6 percentage points AUC demonstrating value tweetspecific terms. Nevertheless, results achieved subset S140 AffLex S140NegLex (Positional) Lexicons still superior obtained automaticmanual lexicon. experiment suggests high-coverage automatic lexiconsalso successfully employed general-purpose sentiment lexicons and, therefore, appliedother, non-tweet domains. next section, show features derivedlexicons extremely helpful automatic sentiment analysis tweets,also SMS movie review data. Furthermore, (Kiritchenko et al., 2014)demonstrate usefulness lexicons domains restaurant laptop customerreviews.unsupervised sentiment analysis experiments SMS test set (Table 9), onesee trends similar ones observed tweet test set above. automaticlexicons built separately affirmative negated contexts (rows m) perform 36percentage points better corresponding Base Lexicons combination polarity reversing strategy (rows g k). Moreover, use Sentiment140 AffirmativeContext Lexicon Negated Context (Positional) Lexicon (row n) results higherperformance obtained manually automatically created lexiconused.get better understanding impact amount data used createautomatic lexicon quality lexicon, compare performance automatic lexicons built subsets available data. split tweet corpus (HashtagSentiment Corpus Sentiment140 Corpus) smaller chunks tweets time stamp.Fig. 3 shows performance Hashtag Sentiment Base, Hashtag Sentiment Affirma749fiKiritchenko, Zhu, & MohammadTable 9: Prediction performance unigram lexicons unsupervised sentiment analysisSemEval-2013 SMS test set. polarity reversing strategy appliednegation lexicons except Negated Context Lexicons. Cover. denotescoverage percentage SMS test set least one matchlexicon; P precision; R recall; Favg macro-averaged F-scorepositive negative classes; AUC area ROC curve.PositivePRNegativePRLexiconCover.FavgAUCManual general-purpose lexiconsa. NRC Emotion Lexiconb. Bing Lius Lexiconc. MPQA Subjectivity Lexicon70.8869.7583.8685.11 56.91 80.17 47.21 63.82 79.6687.90 61.99 86.36 48.22 67.30 83.2481.69 72.56 77.95 52.03 69.63 82.42Automatic general-purpose lexiconsd. SentiWordNet 3.0e. MSOLf. Osgood Evaluative Factor Ratings100.00100.00100.0077.36 79.88 73.87 70.30 75.32 81.3469.88 73.58 69.14 44.92 63.07 72.4966.15 95.33 87.01 39.09 66.02 84.01Automatic tweet-specific lexiconsg. HS Base Lexiconi. HS AffLex HS NegLexj. HS AffLex HS NegLex (Posit.)100.00100.00100.0088.41 41.87 56.20 93.15 63.47 75.4992.03 46.95 58.90 94.92 67.44 81.6792.00 46.75 58.81 94.92 67.31 82.05k. S140 Base Lexiconm. S140 AffLex S140 NegLexn. S140 AffLex S140 NegLex (Posit.)100.00100.00100.0085.71 73.17 71.67 84.77 78.31 86.0788.38 78.86 76.73 87.06 82.46 89.3488.69 79.67 77.48 87.31 83.02 89.60tive Context Hashtag Sentiment Negated Context Lexicons, Sentiment140 Base,Sentiment140 Affirmative Context Sentiment140 Negated Context Lexicons builtpartial corpora function corpus size. above, performancelexicons evaluated terms AUC unsupervised sentiment analysis SemEval2013 tweet test set. see Sentiment140 Lexicons generated halfavailable tweet set still higher predictive power full Hashtag Sentiment Lexicons. Interestingly, Hashtag Sentiment Lexicons seem stabilize corpus size400,000500,000 tweets whereas Sentiment140 Lexicons stabilize 800,000tweets. However, better results might still possible corpora ordersmagnitude larger.6.2.2 Lexicon Performance Supervised Sentiment Analysissection, evaluate supervised sentiment analysis system (described Section 5) three-class problem (positive, negative, neutral) message-leveltask term-level task. use data provided SemEval-2013 competition.examine contribution various feature groups, including features derivedsentiment lexicons: manually created lexicons (NRC Emotion Lexicon, Bing Lius Lexicon, MPQA Subjectivity Lexicon) automatically created lexicons (Hashtag750fiSentiment Analysis Short Informal Texts88AUC868482HS Base LexiconS140 Base LexiconHS AffLex HS NegLexS140 AffLex S140 NegLex807876# tweets (millions)7400.20.40.60.811.21.41.6Figure 3: Performance automatic tweet-specific lexicons unsupervised sentimentanalysis SemEval-2013 tweet test set different sizes tweet corpora.AUC denotes Area ROC Curve.Sentiment Sentiment140 Lexicons). Finally, compare performance differentstrategies process negation.tasks, train SVM classifier provided training data evaluateperformance learned models unseen tweet test set. models applied,without change, test set SMS messages. evaluate performancebottom-line evaluation measure used organizers SemEval-2013 competitionmacro-averaged F-score positive negative classes:Favg =Fpos + Fneg2(4)Note measure give credit correctly classifying neutral instances.Nevertheless, system predict three classes (positive, negative, neutral)avoid penalized misclassifying neutral instances positive negative. reportresults obtained system training set (ten-fold cross-validation), development set (when trained training set), test sets (when trained combinedset tweets training development sets). Significance tests performed usingone-tailed paired t-test approximate randomization p < .05 level (Yeh, 2000).order test system different domain, conduct experiments classifyingmovie review sentences positive negative (message-level task only). use datasetevaluation setup provided Socher et al. (2013). train systemtraining development subsets movie review excerpts dataset apply learnedmodel test subset. compare published results dataset, use accuracyevaluation measure.6.2.3 Results Message-Level Task(a) SemEval-2013 data: results obtained system SemEval2013 message-level task presented Table 10. official submission task751fiKiritchenko, Zhu, & MohammadTable 10: Message-level task: macro-averaged F-scores SemEval-2013 datasets.Classifiera. Majority baselineb. SVM-unigramsc. system:c.1. official SemEval-2013 submissionc.2. best resultTrain.Set26.9436.95Dev.Set26.8536.71Test SetsTweets SMS29.1919.0339.6139.2967.0968.1968.7268.4369.0270.4568.4669.77(row c.1) obtained macro-averaged F-score 69.02 tweet test set 68.46SMS test set. 48 submissions 34 teams, system ranked firstdatasets.20 replacing Base Lexicons Affirmative Context LexiconsNegated Context (Positional) Lexicons improvements feature set,achieved scores 70.45 tweet set 69.77 SMS set (row c.2).21differences best scores official scores test sets statisticallysignificant. table also shows baseline results obtained majority classifieralways predicts frequent class (row a). bottom-line F-score basedF-scores positive negative classes (and neutral), majoritybaseline chooses frequent class among positive negative, casepositive class.22 also include baseline results obtained using SVMunigram features alone (row b).Table 11 shows results ablation experiments repeat classification process remove one feature group time. influential features turnsentiment lexicon features (row b): provide gains 810 percentagepoints SemEval-2013 datasets. Note contribution automatic tweetspecific lexicons (row b.2) substantially exceeds contribution manual lexicons(row b.1). especially noticeable tweet test set use automaticlexicons results improvement 6.5 percentage points. Also, use bigramsnon-contiguous pairs (row b.5) bring additional gains using unigram lexicons.second important feature group message-level task ngrams (row c):word ngrams character ngrams. Part-of-speech tagging (row d) clustering (rowe) provide small improvements. Also, removing sentiment encoding features likehashtags, emoticons, elongated words (row f) little impact performance,probably discriminating information also capturedfeatures character word ngrams.Next, compare different strategies processing negation (Table 12). Observeprocessing negation benefits overall sentiment analysis system: methods test20. second-best results 65.27 tweet set 62.15 SMS set.21. contributions different versions automatic lexicons overall systems performancepresented later subsection.22. majority baseline calculated follows. Since instances predicted positive, Fneg = 0,Rpos = 1, Ppos = Npos /N, Npos number positive instances N total numberinstances dataset. Then, macro-averaged F-score positive negative classes Favg= (Fpos + Fneg )/2 = Fpos /2 = (Ppos * Rpos )/(Ppos + Rpos ) = Ppos /(Ppos + 1) = Npos /(Npos + N).752fiSentiment Analysis Short Informal TextsTable 11: Message-level task: macro-averaged F-scores obtained SemEval-2013datasets one feature groups removed. Scores marked *statistically significantly different (p < .05) corresponding scores rowa.ExperimentTrain.Set68.19Dev.Set68.43Test SetsTweets SMS70.4569.77b. - lexiconsb.1. - manual lexiconsb.2. - automatic lexiconsb.3. - Sentiment140 Lexiconsb.4. - Hashtag Sentiment Lexiconsb.5. - automatic lexicons bigrams& non-contiguous pairs60.08*66.59*65.17*66.84*67.65*58.98*66.24*64.15*66.80*67.8260.51*69.52*63.89*66.58*67.64*59.94*67.26*66.46*67.61*71.16*67.65*66.8467.44*69.42c. - ngramsc.1. - word ngramsc.2. - character ngrams64.07*66.64*67.64*65.68*66.70*68.2867.49*68.29*68.74*66.93*67.64*69.11d. - POSe. - clustersf. - encodings (elongated, emoticons,punctuations, all-caps, hashtags)67.54*68.21*67.6468.3370.4770.0068.42*68.56*67.99*68.6670.7969.82a. featuresoutperform baseline disregarding negation (row a.1). Employing Affirmative Context Lexicons Negated Context Lexicons (row b) provides substantial improvementstandard polarity reversing strategy Base Lexicons (row a.2). ReplacingNegated Context Lexicons Negated Context (Positional) Lexicons (row c) resultsadditional gains system.(b) Movie Reviews data: results obtained using systemmovie review excerpts dataset shown Table 13. system, trained sentencelevel annotations training development subsets, able correctly classify 85.5%test subset. Note ignore annotations word phrase levelwell parse tree structure used Socher et al. (2013). Even non-tweet domain,employing automatically generated, tweet-specific lexicons significantly improvesoverall performance: without use lexicons, performance drops 83.9%.Furthermore, system demonstrates state-of-the-art performance surpassing previous best result obtained dataset (Socher et al., 2013).6.2.4 Results Term-level TaskTable 14 shows performance sentiment analysis system SemEval-2013term-level task. official submission (row c.1) obtained macro-averaged F-score88.93 tweet set ranked first among 29 submissions 23 participating753fiKiritchenko, Zhu, & MohammadTable 12: Message-level task: macro-averaged F-scores Semeval-2013 datasetsdifferent negation processing strategies. Scores marked * statisticallysignificantly different (p < .05) corresponding scores row c (our bestresult).Experimenta. Base automatic lexiconsa.1. disregarding negationa.2. reversing polarityb. AffLex NegLexc. AffLex NegLex (Positional)Train.SetDev.SetTest SetsTweets SMS66.62*67.61*68.13*68.1967.3668.0468.4168.4367.99*68.95*69.95*70.4565.29*66.96*69.5969.77Table 13: Message-level task: results obtained movie review excerpts dataset.Systema. Majority baselineb. SVM-unigramsc. Previous best result (Socher et al., 2013)d. systemAccuracy50.171.985.485.5teams.23 Even tuning specific SMS data, system ranked second SMStest set F-score 88.00. score first ranking system SMS set88.39. post-competition bug-fix use Affirmative Context LexiconsNegated Context (Positional) Lexicons resulted F-score 89.50 tweets set88.20 SMS set (row c.2). difference best score official scoretweet test set statistically significant. table also shows baseline resultsobtained majority classifier always predicts frequent class output (rowa), additional baseline result obtained using SVM unigram features alone(row b).Table 15 presents results ablation experiments feature groups alternately removed final model. Observe sentiment lexicon features (rowb) useful groupremoving leads drop F-score 45 percentage points datasets. manual (row b.1) automatic (row b.2) lexiconscontribute significantly overall sentiment analysis system, automatic lexiconsconsistently showing larger gains.ngram features (row c) next useful group term-level task. Noteremoving word ngram features (row c.1) character ngram features(row c.2) results small drop performance. indicates two featuregroups capture similar information.last two rows Table 15 show results obtained features extractedcontext target (and target itself) (row f)extracted target (and context) (row g). Observe even23. second-best system used additional labeled data obtained score 86.98 tweettest set.754fiSentiment Analysis Short Informal TextsTable 14: Term-level task: macro-averaged F-scores SemEval-2013 datasets.Classifiera. Majority baselineb. SVM-unigramsc. system:c.1. official SemEval-2013 submissionc.2. best resultTrain.Set38.3878.04Dev.Set36.3479.76Test SetsTweets SMS38.1332.1180.2878.7186.8087.0386.4987.0788.9389.5088.0088.20Table 15: Term-level task: macro-averaged F-scores obtained SemEval-2013datasets one feature groups removed. Scores marked *statistically significantly different (p < .05) corresponding scores rowa.Experimenta. featuresTrain.Set87.03Dev.Set87.07Test SetsTweets SMS89.5088.20b. - lexiconsb.1. - manual lexiconsb.2. - automatic lexicons82.77*86.16*85.28*81.75*86.2285.66*85.56*88.21*88.02*83.52*87.27*86.39*c. - ngramsc.1. - word ngramsc.2. - char. ngrams84.08*86.65*86.67*84.94*86.3087.5885.73*88.51*89.2082.94*87.02*87.15*d. - stopwordse. - encodings (elongated words, emoticons,punctuation, uppercase)87.07*87.0889.42*88.07*87.1187.0889.4488.17f. - targetg. - context72.65*83.76*71.72*83.95*74.12*85.56*69.37*86.63*though target features substantially useful context features, addingcontext features system improves F-scores roughly 2 4 points.performance sentiment analysis system significantly higher term-leveltask message-level task. difference performance two tasksalso observed SVM-unigrams baseline. analyzed provided labeled datadetermine unigrams performed strongly term-level task, foundtest target tokens (85.1%) occur target tokens training data. Further,distribution occurrences target term different polarities skewed towards onepolarity other. average, word appears target phrases polarity 80.8%time. facts explain, least part, high overall result dominantrole unigrams term-level task. evaluate impact different feature groupstest data unseen target terms, split SemEval-2013 tweet test setthree subsets. Every instance first subset, targets fully seen training,target X (X single word multi-word expression) following property:exist instances training data exactly target. first subset755fiKiritchenko, Zhu, & MohammadTable 16: Term-level task: macro-averaged F-scores obtained different subsetsSemEval-2013 tweet test set one feature groups removed.number brackets difference scores row a. Scores marked* statistically significantly different (p < .05) corresponding scoresrow a.Classifiera. featuresb. - lexiconsb.1. - manual lexiconsb.2. - automatic lexiconsc. - ngramsTargetsfully seentraining93.3192.96 (-0.35)92.94 (-0.37)92.98 (-0.33)89.30 (-4.01)*Targetspartially seentraining85.4281.26 (-4.16)*84.51 (-0.91)84.08 (-1.34)81.61 (-3.81)*Targetsunseentraining84.0969.55 (-14.54)*79.33 (-4.76)*79.41 (-4.68)*80.62 (-3.47)*Table 17: Term-level task: macro-averaged F-scores SemEval-2013 datasetsdifferent negation processing strategies. Scores marked * statisticallysignificantly different (p < .05) corresponding scores row c (our bestresult).Experimenta. Base automatic lexiconsa.1. disregarding negationa.2. reversing polarityb. AffLex NegLexc. AffLex NegLex (Positional)Train.SetDev.SetTest SetsTweets SMS85.88*86.8586.8987.0386.37*86.48*86.60*87.0788.38*89.10*89.3389.5086.77*88.3487.8988.20comprises 55% test set. Every instance second subset, targets partially seentraining, target X following property: exist instances trainingdata whose target expression includes one more, all, tokens X. secondsubset comprises 31% test set. Every instance third subset, targets unseentraining, target X following property: instancestraining data whose target includes tokens X. third subset comprises14% test set. Table 16 shows results ablation experiments threesubsets. Observe instances unseen targets sentiment lexicons playprominent role, providing substantial gain (14.54 percentage points).next set experiments, compare performance different approachesnegation handling term-level task (Table 17). Similar message-level task,processing negation proves beneficial term-level task well. tested negationprocessing approaches show better results default strategy disregarding negation(row a.1). use Affirmative Context Lexicons Negated Context Lexicons(row b) especially Negated Context (Positional) Lexicons (row c) provides additionalgains results obtained use polarity reversing method (row a.2).756fiSentiment Analysis Short Informal Texts7. Conclusionscreated supervised statistical sentiment analysis system detects sentimentshort informal textual messages tweets SMS (message-level task) wellsentiment term (a word phrase) within message (term-level task). systemranked first tasks SemEval-2013 competition Sentiment Analysis Twitter.Moreover, demonstrated state-of-the-art performance two additional datasets:SemEval-2013 SMS test set corpus movie review excerpts.system, implemented variety features based surface form lexicalcategories. also included features derived several sentiment lexicons: (1) existing,manually created, general-purpose lexicons (2) high-coverage, tweet-specific lexiconsgenerated tweets sentiment-word hashtags tweets emoticons. experiments showed new tweet-specific lexicons superior sentimentprediction tweets unsupervised supervised settings.Processing negation plays important role sentiment analysis. Many previous studies adopted simple technique reverse polarity words scope negation.work, demonstrated polarity reversing method may always appropriate. particular, showed positive terms negated, tendconvey negative sentiment. contrast, negative terms negated, tendstill convey negative sentiment. Furthermore, evaluative intensity positivenegative terms changes negated context, amount change variesterm term. adequately capture impact negation individual terms, proposed empirically estimate sentiment scores terms negated context largetweet corpora, built two lexicons, one terms negated contexts one termsaffirmative (non-negated) contexts. using Affirmative Context LexiconsNegated Context Lexicons able significantly improve performanceoverall sentiment analysis system tasks. particular, features derivedlexicons provided gains 6.5 percentage points feature groups.system process 100 tweets second. Thus, suitable small- bigdata versions applications listed introduction. recently annotated 135 milliontweets cluster 50 machines 11 hours. already employed sentiment analysis system within larger systems detecting intentions behind political tweets(Mohammad, Kiritchenko, & Martin, 2013), detecting emotions text (Mohammad &Kiritchenko, 2014), detecting sentiment towards particular aspects target entities(Kiritchenko et al., 2014). also interested applying evaluating lexiconsgenerated tweets data kinds text blogs news articles.addition, plan adapt sentiment analysis system languages English. Along way, continue improve sentiment lexicons generatinglarger amounts data, different kinds data, tweets, blogs,Facebook posts. especially interested algorithms gracefully handle kindssentiment modifiers including negations, also intensifiers (e.g., very, hardly),discourse connectives (e.g., but, however).757fiKiritchenko, Zhu, & MohammadAcknowledgmentsthank Colin Cherry providing SVM code helpful discussions.ReferencesAgarwal, A., Xie, B., Vovsha, I., Rambow, O., & Passonneau, R. (2011). Sentiment analysistwitter data. Proceedings Workshop Languages Social Media, LSM11, pp. 3038, Portland, Oregon.Aisopos, F., Papadakis, G., Tserpes, K., & Varvarigou, T. (2012). Textual contextualpatterns sentiment analysis microblogs. Proceedings 21st International Conference World Wide Web Companion, WWW 12 Companion, pp.453454, New York, NY, USA.Almquist, E., & Lee, J. (2009). customers really want?. Harvard Business Review.Baccianella, S., Esuli, A., & Sebastiani, F. (2010). SentiWordNet 3.0: enhanced lexicalresource sentiment analysis opinion mining. Proceeding 7th International Conference Language Resources Evaluation, Vol. 10 LREC 10, pp.22002204.Bakliwal, A., Arora, P., Madhappan, S., Kapre, N., Singh, M., & Varma, V. (2012). Mining sentiments tweets. Proceedings 3rd Workshop ComputationalApproaches Subjectivity Sentiment Analysis, WASSA 12, pp. 1118, Jeju, Republic Korea.Becker, L., Erhart, G., Skiba, D., & Matula, V. (2013). Avaya: Sentiment analysistwitter self-training polarity lexicon expansion. Proceedings 7th International Workshop Semantic Evaluation (SemEval 2013), pp. 333340, Atlanta,Georgia, USA.Bellegarda, J. (2010). Emotion analysis using latent affective folding embedding.Proceedings NAACL-HLT 2010 Workshop Computational ApproachesAnalysis Generation Emotion Text, Los Angeles, California.Boucher, J. D., & Osgood, C. E. (1969). Pollyanna Hypothesis. Journal VerbalLearning Verbal Behaviour, 8, 18.Boucouvalas, A. C. (2002). Real time text-to-emotion engine expressive internet communication. Emerging Communication: Studies New Technologies PracticesCommunication, 5, 305318.Brody, S., & Diakopoulos, N. (2011). Cooooooooooooooollllllllllllll!!!!!!!!!!!!!!: using wordlengthening detect sentiment microblogs. Proceedings ConferenceEmpirical Methods Natural Language Processing, EMNLP 11, pp. 562570,Stroudsburg, PA, USA.Chang, C.-C., & Lin, C.-J. (2011). LIBSVM: library support vector machines. ACMTransactions Intelligent Systems Technology, 2 (3), 27:127:27.Choi, Y., & Cardie, C. (2008). Learning compositional semantics structural inferencesubsentential sentiment analysis. Proceedings Conference EmpiricalMethods Natural Language Processing, EMNLP 08, pp. 793801.758fiSentiment Analysis Short Informal TextsChoi, Y., & Cardie, C. (2010). Hierarchical sequential learning extracting opinionsattributes. Proceedings Annual Meeting AssociationComputational Linguistics, ACL 10, pp. 269274.Davidov, D., Tsur, O., & Rappoport, A. (2010). Enhanced sentiment learning using Twitter hashtags smileys. Proceedings 23rd International ConferenceComputational Linguistics: Posters, COLING 10, pp. 241249, Beijing, China.Esuli, A., & Sebastiani, F. (2006). SENTIWORDNET: publicly available lexical resourceopinion mining. Proceedings 5th Conference Language ResourcesEvaluation, LREC 06, pp. 417422.Francisco, V., & Gervas, P. (2006). Automated mark affective information Englishtexts. Sojka, P., Kopecek, I., & Pala, K. (Eds.), Text, Speech Dialogue, Vol.4188 Lecture Notes Computer Science, pp. 375382. Springer Berlin / Heidelberg.Genereux, M., & Evans, R. P. (2006). Distinguishing affective states weblogs. Proceedings AAAI Spring Symposium Computational Approaches AnalysingWeblogs, pp. 2729, Stanford, California.Gimpel, K., Schneider, N., OConnor, B., Das, D., Mills, D., Eisenstein, J., Heilman, M.,Yogatama, D., Flanigan, J., & Smith, N. A. (2011). Part-of-speech tagging Twitter:Annotation, features, experiments. Proceedings Annual MeetingAssociation Computational Linguistics, ACL 11.Go, A., Bhayani, R., & Huang, L. (2009). Twitter sentiment classification using distantsupervision. Tech. rep., Stanford University.Hanley, J., & McNeil, B. (1982). meaning use area Receiver Operating Characteristic (ROC) curve. Radiology, 143, 2936.Hatzivassiloglou, V., & McKeown, K. R. (1997). Predicting semantic orientation adjectives. Proceedings 8th Conference European Chapter AssociationComputational Linguistics, EACL 97, pp. 174181, Madrid, Spain.Hu, M., & Liu, B. (2004). Mining summarizing customer reviews. Proceedings10th ACM SIGKDD International Conference Knowledge Discovery DataMining, KDD 04, pp. 168177, New York, NY, USA. ACM.Jia, L., Yu, C., & Meng, W. (2009). effect negation sentiment analysisretrieval effectiveness. Proceedings 18th ACM Conference InformationKnowledge Management, CIKM 09, pp. 18271830, New York, NY, USA. ACM.Jiang, L., Yu, M., Zhou, M., Liu, X., & Zhao, T. (2011). Target-dependent Twitter sentiment classification. Proceedings 49th Annual Meeting AssociationComputational Linguistics, ACL 11, pp. 151160.Johansson, R., & Moschitti, A. (2013). Relational features fine-grained opinion analysis.Computational Linguistics, 39 (3), 473509.John, D., Boucouvalas, A. C., & Xu, Z. (2006). Representing emotional momentum withinexpressive internet communication. Proceedings 24th International Conference Internet Multimedia Systems Applications, pp. 183188, Anaheim,CA. ACTA Press.759fiKiritchenko, Zhu, & MohammadJurgens, D., Mohammad, S. M., Turney, P., & Holyoak, K. (2012). Semeval-2012 task 2:Measuring degrees relational similarity. Proceedings 6th InternationalWorkshop Semantic Evaluation, SemEval 12, pp. 356364, Montreal, Canada.Kennedy, A., & Inkpen, D. (2005). Sentiment classification movie product reviewsusing contextual valence shifters. Proceedings Workshop AnalysisInformal Formal Information Exchange Negotiations, Ottawa, Ontario,Canada.Kennedy, A., & Inkpen, D. (2006). Sentiment classification movie reviews using contextualvalence shifters. Computational Intelligence, 22 (2), 110125.Kiritchenko, S., Zhu, X., Cherry, C., & Mohammad, S. M. (2014). NRC-Canada-2014: Detecting aspects sentiment customer reviews. Proceedings InternationalWorkshop Semantic Evaluation, SemEval 14, Dublin, Ireland.Kouloumpis, E., Wilson, T., & Moore, J. (2011). Twitter sentiment analysis: GoodBad OMG!. Proceedings 5th International AAAI ConferenceWeblogs Social Media.Lapponi, E., Read, J., & Ovrelid, L. (2012). Representing resolving negation sentiment analysis. Vreeken, J., Ling, C., Zaki, M. J., Siebes, A., Yu, J. X., Goethals,B., Webb, G. I., & Wu, X. (Eds.), ICDM Workshops, pp. 687692. IEEE ComputerSociety.Li, J., Zhou, G., Wang, H., & Zhu, Q. (2010). Learning scope negation via shallow semantic parsing. Proceedings 23rd International Conference ComputationalLinguistics, COLING 10, pp. 671679, Beijing, China.Liu, B., & Zhang, L. (2012). survey opinion mining sentiment analysis.Aggarwal, C. C., & Zhai, C. (Eds.), Mining Text Data, pp. 415463. Springer US.Liu, H., Lieberman, H., & Selker, T. (2003). model textual affect sensing using realworld knowledge. Proceedings 8th International Conference IntelligentUser Interfaces, IUI 03, pp. 125132, New York, NY. ACM.Louviere, J. J. (1991). Best-worst scaling: model largest difference judgments.Working Paper.Martnez-Camara, E., Martn-Valdivia, M. T., Urenalopez, L. A., & Montejoraez, A. R.(2012). Sentiment analysis Twitter. Natural Language Engineering, 128.Mihalcea, R., & Liu, H. (2006). corpus-based approach finding happiness. Proceedings AAAI Spring Symposium Computational Approaches AnalysingWeblogs, pp. 139144. AAAI Press.Mohammad, S. M. (2012). #Emotional tweets. Proceedings First Joint ConferenceLexical Computational Semantics, *SEM 12, pp. 246255, Montreal, Canada.Mohammad, S. M., Dunne, C., & Dorr, B. (2009). Generating high-coverage semanticorientation lexicons overtly marked words thesaurus. ProceedingsConference Empirical Methods Natural Language Processing: Volume 2, EMNLP09, pp. 599608.760fiSentiment Analysis Short Informal TextsMohammad, S. M., & Kiritchenko, S. (2014). Using hashtags capture fine emotioncategories tweets. appear Computational Intelligence.Mohammad, S. M., Kiritchenko, S., & Martin, J. (2013). Identifying purpose behind electoral tweets. Proceedings 2nd International Workshop Issues SentimentDiscovery Opinion Mining, WISDOM 13, pp. 19.Mohammad, S. M., & Turney, P. D. (2010). Emotions evoked common wordsphrases: Using Mechanical Turk create emotion lexicon. ProceedingsNAACL-HLT Workshop Computational Approaches Analysis GenerationEmotion Text, LA, California.Mohammad, S. M., & Yang, T. W. (2011). Tracking sentiment mail: genders differemotional axes. Proceedings ACL Workshop Computational ApproachesSubjectivity Sentiment Analysis, WASSA 11, Portland, OR, USA.Neviarouskaya, A., Prendinger, H., & Ishizuka, M. (2011). Affect analysis model: novelrule-based approach affect sensing text. Natural Language Engineering, 17,95135.Orme, B. (2009). Maxdiff analysis: Simple counting, individual-level logit, HB. Sawtooth Software, Inc.Pak, A., & Paroubek, P. (2010). Twitter corpus sentiment analysis opinionmining. Proceedings 7th Conference International Language ResourcesEvaluation, LREC 10, Valletta, Malta.Pang, B., & Lee, L. (2008). Opinion mining sentiment analysis. Foundations TrendsInformation Retrieval, 2 (12), 1135.Pang, B., Lee, L., & Vaithyanathan, S. (2002). Thumbs up?: Sentiment classification usingmachine learning techniques. Proceedings Conference Empirical MethodsNatural Language Processing, EMNLP 02, pp. 7986, Philadelphia, PA.Polanyi, L., & Zaenen, A. (2004). Contextual valence shifters. Exploring AttitudeAffect Text: Theories Applications (AAAI Spring Symposium Series).Porter, M. (1980). algorithm suffix stripping. Program, 3, 130137.Proisl, T., Greiner, P., Evert, S., & Kabashi, B. (2013). Klue: Simple robust methodspolarity classification. Proceedings 7th International Workshop SemanticEvaluation (SemEval 2013), pp. 395401, Atlanta, Georgia, USA.Reckman, H., Baird, C., Crawford, J., Crowell, R., Micciulla, L., Sethi, S., & Veress, F.(2013). teragram: Rule-based detection sentiment phrases using sas sentimentanalysis. Proceedings 7th International Workshop Semantic Evaluation(SemEval 2013), pp. 513519, Atlanta, Georgia, USA.Sauper, C., & Barzilay, R. (2013). Automatic aggregation joint modeling aspectsvalues. Journal Artificial Intelligence Research, 46, 89127.Socher, R., Huval, B., Manning, C. D., & Ng, A. Y. (2012). Semantic compositionalityrecursive matrix-vector spaces. Proceedings Conference EmpiricalMethods Natural Language Processing, EMNLP 12, Jeju, Korea.761fiKiritchenko, Zhu, & MohammadSocher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., & Potts,C. (2013). Recursive deep models semantic compositionality sentimenttreebank. Proceedings Conference Empirical Methods Natural LanguageProcessing, EMNLP 13, Seattle, USA.Stone, P., Dunphy, D. C., Smith, M. S., Ogilvie, D. M., & associates (1966). GeneralInquirer: Computer Approach Content Analysis. MIT Press.Taboada, M., Brooke, J., Tofiloski, M., Voll, K., & Stede, M. (2011). Lexicon-based methodssentiment analysis. Computational Linguistics, 37 (2), 267307.Thelwall, M., Buckley, K., & Paltoglou, G. (2011). Sentiment Twitter events. JournalAmerican Society Information Science Technology, 62 (2), 406418.Turney, P. (2001). Mining web synonyms: PMI-IR versus LSA TOEFL.Proceedings Twelfth European Conference Machine Learning, pp. 491502,Freiburg, Germany.Turney, P., & Littman, M. L. (2003). Measuring praise criticism: Inference semanticorientation association. ACM Transactions Information Systems, 21 (4).Wiebe, J., Wilson, T., & Cardie, C. (2005). Annotating expressions opinions emotionslanguage. Language resources evaluation, 39 (2-3), 165210.Wiegand, M., Balahur, A., Roth, B., Klakow, D., & Montoyo, A. (2010). surveyrole negation sentiment analysis. Proceedings Workshop NegationSpeculation Natural Language Processing, NeSp-NLP 10, pp. 6068, Stroudsburg,PA, USA.Wilson, T., Kozareva, Z., Nakov, P., Rosenthal, S., Stoyanov, V., & Ritter, A. (2013).SemEval-2013 Task 2: Sentiment analysis Twitter. Proceedings International Workshop Semantic Evaluation, SemEval 13, Atlanta, Georgia, USA.Wilson, T., Wiebe, J., & Hoffmann, P. (2005). Recognizing contextual polarity phraselevel sentiment analysis. Proceedings Conference Human Language Technology Empirical Methods Natural Language Processing, HLT 05, pp. 347354,Stroudsburg, PA, USA.Yang, B., & Cardie, C. (2013). Joint inference fine-grained opinion extraction.Proceedings Annual Meeting Association Computational Linguistics,ACL 13.Yeh, A. (2000). accurate tests statistical significance result differences.Proceedings 18th conference Computational linguistics - Volume 2, COLING00, pp. 947953, Stroudsburg, PA, USA.762fiJournal Artificial Intelligence Research 50 (2014) 603-637Submitted 02/14; published 07/14Probabilistic Inference Credal Networks:New Complexity ResultsDenis Deratani Mauadenis.maua@usp.brEscola Politecnica, Universidade de Sao PauloAv. Prof. Luciano Gualberto, travessa 3, 380Sao Paulo, 05508-010 BrazilCassio Polpo de CamposAlessio BenavoliAlessandro Antonuccicassio@idsia.chalessio@idsia.chalessandro@idsia.chIstituto Dalle Molle di Studi sullIntelligenza ArtificialeGalleria 2Manno, 6928 SwitzerlandAbstractCredal networks graph-based statistical models whose parameters take valuesset, instead sharply specified traditional statistical models (e.g., Bayesiannetworks). computational complexity inferences models dependsirrelevance/independence concept adopted. paper, study inferential complexityconcepts epistemic irrelevance strong independence. show inferences strong independence NP-hard even trees binary variables exceptsingle ternary one. prove epistemic irrelevance polynomial-timecomplexity inferences credal trees likely extend general models(e.g., singly connected topologies). results clearly distinguish networks admitefficient inferences inferences likely hard, settle several openquestions regarding computational complexity. show results remainvalid even disallow use zero probabilities. also show computationbounds probability future state hidden Markov modelwhether assume epistemic irrelevance strong independence, prove similarresult inference naive Bayes structures. inferential equivalences importantpractitioners, hidden Markov models naive Bayes structures used realapplications imprecise probability.1. IntroductionBayesian networks multivariate probabilistic models stochastic independence assessments compactly represented acyclic directed graph whose nodes identifiedvariables (Pearl, 1988). addition acyclic directed graph, specificationBayesian network requires specification conditional probability distributionevery variable every assignment parents. information costly acquire,specifying conditional probabilities daunting task, whether estimated data elicited experts. causes inferences drawn modelcontain imprecisions arbitrarinesses (Kwisthout & van der Gaag, 2008).arguably principled approach coping imprecision numericalparameters incorporating formalism. One way meansc2014AI Access Foundation. rights reserved.fiMaua, de Campos, Benavoli & Antonucciclosed convex sets probability distributions, called credal sets (Levi, 1980).1Bayesian networks whose numerical parameters specified conditional credal setsknown credal networks (Cano, Cano, & Moral, 1994; Cozman, 2000, 2005). Credalnetworks successfully applied robust pattern recognition,2 knowledgebased systems, argued allowing parameters imprecisely specifiedfacilitates elicitation experts.3Bayesian network provides concise representation (single) joint probabilitydistribution consistent network parameters satisfies (at least) setstochastic independences encoded underlying graph. Analogously, credal networkprovides concise representation credal set joint distributions consistentlocal credal sets satisfy (at least) irrelevances encoded underlyinggraph. precise characterization joint credal set depends however conceptirrelevance adopted.two commonly used irrelevance concepts literature strong independence epistemic irrelevance. Two variables X strongly independentjoint credal set regarded originating number precise probabilitydistributions two variables stochastically independent. Strongindependence follows sensitivity analysis interpretation, regards imprecisionmodel arising partial ignorance ideal precise model. Epistemic irrelevance, hand, defined irrespective existence ideal precise model.variable X epistemically irrelevant variable marginal credal setcoincides conditional credal set given X. Unlike strong independence, epistemic irrelevance asymmetric concept cannot general characterizedproperties elements credal set alone (de Cooman et al., 2010).one hand flexibility provided credal sets arguably facilitates modelbuilding, other, imposes great burden computation inferences.example, whereas posterior probability variable polynomial-time computablepolytree-shaped Bayesian networks, analogous task computing upper lowerbounds posterior probability given variable polytree-shaped credal networksNP-hard task (de Campos & Cozman, 2005). however exceptional cases,case inference polytree-shaped credal networks binary variables,solved polynomial time strong independence (Fagiuoli & Zaffalon,1998). Like Bayesian networks, theoretical practical tractability inferencescredal networks depends strongly network topology cardinalityvariable domains. Credal networks however include another dimension parametrizedcomplexity inference, given type irrelevance concept adopted,1. approaches include random sets (Kendall, 1974), evidence theory (Shafer, 1976; Shenoy & Shafer,1988), possibility theory (Zadeh, 1978), conditional plausibility measures (Halpern, 2001), coherentlower previsions (Walley, 1991; de Cooman & Miranda, 2012), last one largely equivalentcredal sets (there one-to-one correspondence credal sets coherent lower previsions).2. example, see works Zaffalon, Wesnes, Petrini (2003), Zaffalon (2005), de Campos, Zhang,Tong, Ji (2009), Antonucci, Bruhlmann, Piatti, Zaffalon (2009), Corani, Giusti, Migliore,Schmidhuber (2010), Antonucci, de Rosa, Giusti (2011), de Campos Ji (2011).3. example, see works Walley (2000), Antonucci, Piatti, Zaffalon (2007), Salvetti, Antonucci,Zaffalon (2008), de Campos Ji (2008), Antonucci et al. (2009), Piatti, Antonucci, Zaffalon(2010), Antonucci, Huber, Zaffalon, Luginbuhl, Chapman, Ladouceur (2013).604fiProbabilistic Inference Credal Networks: New Complexity ResultsBayesian case usually fixed. instance, computing probability bounds tree-shapedcredal networks concept epistemic irrelevance performed polynomialtime (de Cooman et al., 2010), whereas show task NP-hardstrong independence.rest paper, properly define credal networks inference problemaddress (sect. 2), investigate parametrized theoretical computational complexityinferences credal networks (sect. 3), strong independence epistemicirrelevance. show particular type inference imprecise hidden Markov models(i.e., hidden Markov models uncertainty quantified local credal sets) invariantchoice either irrelevance concept, thus polynomial-time computable (asknown case epistemic irrelevance). obtain corollariesresult inferences strong independence epistemic irrelevance coincide alsotree-shaped networks evidence given, naive Bayes structures. alsoshow even tree-shaped credal networks inferences NP-hard assume strongindependence, complexity inference polytree-shaped credalnetworks irrelevance concepts, even assume variables (at most)ternary. prove so-called precise-vacuous models, is, credal networksvacuous root nodes precise non-root nodes, lead inferences whetherassume epistemic irrelevance strong independence, true (apartarbitrarily small error) vacuous nodes replaced near-vacuous ones,avoiding problematic case zero probabilities. last fact proves hardnessresults hold true even cases lower probability possible event strictlypositive.2. Updating Credal Networkssection, review necessary concepts definitions, formalize probleminference credal networks.2.1 Bayesian NetworksConsider finite set X = {X1 , . . . , Xn } categorical variables, let Z Xset variables. probability distributionPp Z non-negative real-valued functionspace assignments Z zZ p(z) = 1, notation z Z entailsz arbitrary (joint) assignment configuration variables Z. jointprobability distribution p induces probability measure Pp sigma-field subsetsassignments Z.Let G acyclic directed graph (DAG) nodes N = {1, . . . , n}. denoteparents node G Pa(i). set non-descendants i, written Nd(i),contains nodes reachable directed path. Note Pa(i) Nd(i).Fix probability measure P sigma-field subsets X associate every nodevariable Xi . DAG G represents following set stochastic independenceassessments known local Markov conditions:P(Xi = xi |XNd(i) = xNd(i) ) = P(Xi = xi |XPa(i) = xPa(i) ) ,605(1)fiMaua, de Campos, Benavoli & AntonucciN , x X. words, every variable stochastically independentnon-descendant non-parents given parents suitable measure P.Bayesian network triple (X, G, Q), Q set conditional probabilityassessmentsP(Xi = xi |XPa(i) = xPa(i) ) = q(xi |xPa(i) ) ,(2)N , xi Xi xPa(i) XPa(i) , q(Xi |xPa(i) ) probability distributionXi . assumption, Bayesian network defines joint probability distribution p Xp(x) =q(xi |xPa(i) ) ,(3)x X. difficult see (1) (2) imply (3) Chain Rule usingtopological ordering variables. (3) (2) imply (1) bit intricate seealso true (Cowell, Dawid, Lauritzen, & Spiegelhalter, 2007). Thus, two seeminglydifferent approaches specifying probability measure virtually equivalent.explicit: given Bayesian network, probability measure satisfies (1)(2) probability measure satisfies (3) (2), choose pairassumptions define (single) measure network. shall see, analogousequivalence observed probabilities imprecisely specified, leadsdifferent definitions credal networks different computational complexity.2.1.1 Probabilistic Inference Bayesian Networksessential task many applications probabilistic modeling compute certainprobability value implied Bayesian network. call computational taskBN-INF problem, define follows.BN-INFInput: Bayesian network (X, G, Q), target node t, target value xt Xt ,(possibly empty) set evidence nodes O, assignment xO XO .Output: conditional probability P(Xt = xt |XO = xO ), P probability measure specified network.problem assume P(XO = xO ) = 0 output special symbol(e.g. ) indicating problem solution undefined.Roth (1996) showed BN-INF #P-hard, defining lower bound complexityproblem. known (exact) algorithms take time least exponential treewidthnetwork worst case. treewidth measure resemblance networktree; small treewidth suggests tree-like structure treewidth tree oneminimal (Koller & Friedman, 2009). Recently, Kwisthout, Bodlaender, van derGaag (2010) proved contingent hypothesis satisfiability Boolean formulastakes exponential time worst-case (known ETH) best performancealgorithm BN-INF achieve. shall see next section, Bayesian networksparticular instances credal networks. such, complexity results set lowerbounds complexity inference credal networks.DAG said singly connected one undirected path connectingtwo nodes graph; tree additionally node one parent.606fiProbabilistic Inference Credal Networks: New Complexity Resultsgraph singly connected, say multiply connected. Singly connected directedgraphs also called polytrees. Pearls belief propagation algorithm (Pearl, 1988) computesBN-INF polynomial time singly connected Bayesian networks. generally,junction tree propagation algorithm (Cowell et al., 2007) solves BN-INF polynomial timenetwork bounded treewidth, includes singly connected networks boundedin-degree (i.e., maximum number parents).2.2 Credal Networkssection describe credal sets, irrelevance concepts, credal networks probabilisticinference credal networks.2.2.1 Credal SetsLet Z X. credal set closed convex set joint probability distributionsdomain, say z Z (Levi, 1980). vacuous credal set Z largestcredal set domain, denoted V (Z). extreme distribution credal setelement set cannot written convex combination elementsset. denote set extreme distributions credal set ext .credal set finitely generated contains finite number extreme distributions.finite representation finitely generated credal set means extreme distributionscalled vertex-based. finitely generated credal set Z defines (bounded) polytopeprobability simplex distributions Z, specified finite setlinear inequalities formdefEp (fl ) =Xfl (z)p(z) 0 ,(4)zZ{fl } finite collection real-valued functions Z (Cozman, 2000). conversealso true: finite set linear inequalities form determines (bounded)polytope probability simplex (Boyd & Vandenberghe, 2004, ch. 2), hencefinitely generated credal set. Thus, alternative finite representation credal setmeans finite set functions defining linear inequalities type above.representation called constraint-based.Example 1. Consider X = {X1 , X2 }, X1 takes values {0, 1, 2} X2 takesvalues {0, 1}. vacuous set X1 probability simplex plane, drawntriangle vertices (p(0), p(1), p(2)) = (0, 0, 1), (0, 1, 0) (1, 0, 0) Figure 1. Let(X1 |X2 = 0) = {p V (X1 ) : p(k) 1/3, k = 1, 2}(X1 |X2 = 1) = {p V (X1 ) : p(0) p(1) p(2)}conditional credal sets X1 given X2 , (X2 ) singleton containingdistribution p X2 p(0) = p(1) = 1/2. first two sets depicted Figure 1.607fiMaua, de Campos, Benavoli & Antonucci(0, 1, 0)(0, 1, 0)p5p3(0, 0, 1)p2p4p3p1(1, 0, 0)p1(1, 0, 0)(0, 0, 1)(a) (X1 |X2 = 0)(b) (X1 |X2 = 1)Figure 1: Barycentric coordinate-system visualization conditional credal sets Example 1 (hatched regions) corresponding extreme distributions (black circles).Let us represent generic function f {0, . . . , m} m-tuple (f (0), . . . , f (m)),definep1 = (1, 0, 0) ,p2 = (2/3, 1/3, 0) ,p3 = (1/3, 1/3, 1/3) ,p4 = (2/3, 0, 1/3) ,p5 = (1/2, 1/2, 0) ,f1 = (1, 2, 1) ,f2 = (1, 1, 2) ,f3 = (1, 1, 0) ,f4 = (0, 1, 1) ,f5 = (1, 1) .set (X1 |X2 = 0) represented vertex- constraint-based form, respectively, (X1 |X2 = 0) = co{p1 , p2 , p3 , p4 } (co denotes convex hull operator)(X1 |X2 = 0) = {p V (X1 ) : Ep (f1 ) 0, Ep (f2 ) 0}, set (X1 |X2 = 1)represented vertex- constraint-based forms (X1 |X2 = 1) = co{p1 , p3 , p5 }(X1 |X2 = 1) = {p V (X1 ) : Ep (f3 ) 0, Ep (f4 ) 0}, respectively. Similarly, (X2 )represented (X2 ) = {(1/2, 1/2)} vertex-based form, (X2 ) = {pV (X2 ) : Ep (f5 ) 0, Ep (f5 ) 0} constraint-based form.Vertex- constraint-based representations credal set different sizes. see this, consider single variable X taking values {0, . . . , m}, let= {p V (X) : p(k) 1/(m + 1), k = 1, . . . , m}. set isomorphic mdimensional hypercube, therefore 2m extreme distributions,4 whereas setrepresented constraint-based form degenerate functions X translated1/(m + 1). Moving vertex-based constraint-based representation also resultexponential increase size ofPinput. Consider variable XPtaking values{0, . . . , m} let = {f (X) 0 :k=1 |f (k) 1/(2m)| 1/(2m),k=0 f (k) = 1}.set affinely equivalent m-dimensional cross-polytope, hence requires2m inequalities described constraint-based form, represented4. non-negative integer k greater (potentially empty) subset {1, . . . , m}cardinality k, distribution assigns mass (m + 1 k)/(m + 1) p(0), mass 1/(m + 1) p(j)j S, zero mass elsewhere, , since satisfies constraints validdistribution. 2m distributions, one cannot written convex combinationdistribution set.608fiProbabilistic Inference Credal Networks: New Complexity Resultsvertex-based form 2m extreme distribution (Kalai & Ziegler, 2000, p. 11).5 Tessem(1992) de Campos, Huete, Moral (1994) studied representation credal setsdefined linear constraints form lx p(x) ux , lx ux real numbers,showed credal sets exponentially many extreme distributionsnumber constraints. Wallner (2007) proved attainable upper bound m! extremedistributions credal sets generally defined coherent lower probability functionm-ary variable. recently, Miranda Destercke (2013) investigated numberextreme distributions credal sets defined linear constraints form p(x) p(x0 )x 6= x0 , proved attainable upper bound 2m1 extreme distributionscase m-ary variable. Importantly, vacuous credal sets (of variables cardinality) credal sets binary variables succinctly represented either vertexor constraint-based form. complexity results obtain later use vacuouscredal sets and/or binary variables thus representation independent.2.2.2 Graph-Based Representationfar considered explicit representation finitely generated credal setfinite number functions representing either vertices set set linearinequalities. final goal however able specify credal sets large domainsx X. large set X, explicit representation difficult obtainlarge manipulate computer. Thus, analogously efficient graph-basedrepresentation large probability distribution given Bayesian network, large jointcredal set usually efficiently represented implicitly credal set satisfiesirrelevances encoded given graph agreeing projection local credalsets, latter credal sets efficiently represented (either vertex-constraint-based form) explicitly functions small subsets X.(separately specified) credal network N triple (X, G, Q), G DAGnodes N , Q set imprecise probability assessmentsXXf :f (xi )P(Xi = xi |XPa(i) = xPa(i) )minf (xi )q(xi ) ,(5)qQ(Xi |xPa(i) )xi Xixi Xione every N xPa(i) XPa(i) , Q(Xi |xPa(i) ) credal set Xif arbitrary real-valued function Xi . Note left unspecified credalsets represented.Example 2. Consider credal network N variables X1 , X2 X3 take values{0, 1}, graph structure shown Figure 2. local credal setsQ(X1 ) = {p V (X1 ) : 0.5 p(1) 0.6} = co{(0.4, 0.6), (0.5, 0.5)} ,Q(X2 ) = {p V (X2 ) : 0.5 p(1) 0.6} = co{(0.4, 0.6), (0.5, 0.5)} ,Q(X3 |X1 = i, X2 = j) = {pij } j, pij probability distribution{0, 1} pij (1) = 0 = j pij (1) = 1 otherwise.P5. m-dimensional cross-polytope set {f (X) : x |f (x)| 1}, whose extreme distributions{e1 , . . . , em }, ek (k = 1, . . . , m) degenerate distribution placing mass X = k.fact set cannot written less 2m inequalities follows dualm-dimensional hypercube.609fiMaua, de Campos, Benavoli & Antonucci123Figure 2: DAG credal network Example 2.node network associated variable Xi said precise (i.e., precisely specified) corresponding conditional credal sets Q(Xi |xPa(i) ) singletons,otherwise said imprecise (i.e., imprecisely specified). Example 2 variableX3 corresponding associated node precise, X1 X2 imprecise.local credal sets vacuous, node corresponding variable saidvacuous. Bayesian network simply credal network nodes precise.DAG G credal network specifies set conditional irrelevances setsvariables generalize Markov condition Bayesian networks. specifically,node G, set XNd(i)\Pa(i) non-descendant non-parent variables Xiassumed irrelevant Xi conditional parent variables XPa(i) . precise definitionstatement requires definition irrelevance concept. instance, stochasticindependence adopted irrelevance concept, DAG G describes set Markovconditions Bayesian network (stochastic irrelevance implies stochastic independence).credal network formalism, two common irrelevance concepts used strongindependence epistemic irrelevance.Fix joint credal set probability distributions X, consider subsets Y,Z W X. say set variables strongly independent setvariables Z given variables W Z stochastically independent conditionalW every extreme distribution p ext (X), implies every y, z wPp (Y = y|Z = z, W = w) = Pp (Y = y|W = w). say set variables Zepistemically irrelevant set variables conditional variables W everyfunction f assignments z w followsminpMXf (y)Pp (Y = y|Z = z, W = w) = minpMyYXf (y)Pp (Y = y|W = w) ,(6)yYequivalent say projection conditioned W = w Z = zequals projection conditioned W = w. immediate conclusionstrong independence implies epistemic irrelevance (and converse necessarilytrue) (Cozman, 2000; de Cooman & Troffaes, 2004). Variables Z epistemicallyindependent conditional W if, given assignment w, Z epistemicallyirrelevant (Walley, 1991, ch. 9).strong extension credal network N = (X, G, Q) largest credal set KSdistributions X whose extreme distributions satisfy strong independence assessmentsG (viz. every variable strongly independent non-descendant non-parentsgiven parents), whose projections local domains lie inside local credal setsspecified Q, is, KS convex hull set distributions X whose inducedmeasure satisfies (1) (5). One show strong extension equivalently610fiProbabilistic Inference Credal Networks: New Complexity Resultsdefined (Antonucci & Zaffalon, 2008; Antonucci, de Campos, & Zaffalon, 2014)()xPa(i)xPa(i)defqiKS = co p V (X) : p(x) =(xi ), qiext Q(Xi |xPa(i) ) .(7)epistemic extension credal network largest joint credal set KE Xsatisfies epistemic irrelevance assessments G (viz. non-descendant non-parentsirrelevant variable given parents), assessments Q. Equivalently,epistemic extension credal set KE defined set probability distributions pXXXf (xi )Pp (xi |xNd(i) )minf (xi )q(xi ) ,(8)qQ(Xi |xPa(i) )xixifunctions f Xi , assignment xNd(i) . Note inequalities turnedlinear inequalities form (4) multiplying sides Pp (xNd(i) ) rearranging terms.following example largely based Example 9.3.4 work Walley (1991).Example 3. Consider network Example 2, represent function f binaryvariable pair (f (0), f (1)). strong extension KS credal set whose extremedistributions four joint probability distributions p V (X1 , X2 , X3 )p(x1 , x2 , x3 ) = p1 (x1 )p2 (x2 )px3 1 x2 (x3 )x1 , x2 , x3 {0, 1} ,p1 {(0.4, 0.6), (0.5, 0.5)} ,p2 {(0.4, 0.6), (0.5, 0.5)} ,p00310p013 = p3 = (0, 1) .=p113= (1, 0) ,Note strong extension contains four extreme distributions. epistemic extensionKE set joint probability distributions p V (X1 , X2 , X3 ) satisfies systemlinear inequalities0.5 =min q(1) Pp (X1 = 1|x2 ) max q(1) = 0.6[x2 = 0, 1] ,min q(1) Pp (X2 = 1|x1 ) max q(1) = 0.6[x1 = 0, 1] ,qQ(X1 )0.5 =qQ(X2 )qQ(X1 )qQ(X2 )Pp (X3 = 1|X1 = x, X2 = x) = 0[x = 0, 1] ,Pp (X3 = 1|X1 = 0, X2 = 1) = Pp (X3 = 1|X1 = 1, X2 = 0) = 1 .One verify set KE following six extreme distributions:p1 = (0.25, 0, 0, 0.25, 0, 0.25, 0.25, 0) ,p2 = (0.16, 0, 0, 0.36, 0, 0.24, 0.24, 0) ,p3 = (0.2, 0, 0, 0.3, 0, 0.2, 0.3, 0) ,p4 = (0.2, 0, 0, 0.3, 0, 0.3, 0.2, 0) ,p5 = (2/9, 0, 0, 3/9, 0, 2/9, 2/9, 0) ,p6 = (2/11, 0, 0, 3/11, 0, 3/11, 3/11, 0) ,tuples right-hand side represent distributions p(x1 , x2 , x3 )(p(0, 0, 0), p(1, 0, 0), p(0, 1, 0), p(1, 1, 0), p(0, 0, 1), p(1, 0, 1), p(0, 1, 1), p(1, 1, 1)) .observe distributions p1 p4 extreme distributions strong extension,whereas p5 p6 strong extension.611fiMaua, de Campos, Benavoli & Antonucciexample shows interesting well-known relation epistemicstrong extensions, namely, latter always contained former, thusproduces precise results (Walley, 1991, ch. 9.2).already discussed choice representation credal sets affectcomplexity. following result connects vertex- constraint-based credal networksstrong independence.Proposition 1. vertex-based (separately specified) credal network efficientlyreduced constraint-based credal network larger set variables inducesstrong extension projected original set variables.Proof. Let Xi variable whose local credal set Q(Xi |xPa(i) ) specified extreme distributions p1 , . . . , pm , given assignment parents. Insert new vacuousvariable X taking values {1, . . . , m}, Xi child XPa(i) parents, redefine Q(Xi |xPa(i) ) singleton contains conditional distributionq(xi |xPa(i) , x = k) = pk (xi ). One verify strong extension new networkmarginalizing X coincides original strong extension.result cannot applied derive complexity singly connected networkssince reduction used proof inserts (undirected) cycles network. Thus,true hardness results obtained vertex-based singly connected networksimmediately extend constraint-based singly connected networks, even thoughalways case results present (for instance, use credal setseasily translated one representation hardness results). Conversely,tractability constraint-based singly connected networks immediately extendvertex-based singly connected networks. unclear whether constraint-based networksefficiently reduced vertex-based form inserting new variables, conjecturetrue.2.2.3 Probabilistic InferenceSimilarly Bayesian networks, primary use credal networks deriving boundsprobabilities implied model. precise characterization depends choiceirrelevance concept. define inference problem strong independence follows.STRONG-INFInput: credal network (X, G, Q), target node t, assignment xt Xt ,(possibly empty) set evidence nodes O, assignment xO XO .Output: numbersmin Pp (Xt = xt |XO = xO ) max Pp (Xt = xt |XO = xO ) ,pKSpKSKS strong extension network.analogous inference problem defined epistemic irrelevance, simplyreplacing strong extension output problem epistemic extension:612fiProbabilistic Inference Credal Networks: New Complexity ResultsEPISTEMIC-INFInput: credal network (X, G, Q), target node t, assignment xt Xt ,(possibly empty) set evidence nodes O, assignment xO XO .Output: numbersmin Pp (Xt = xt |XO = xO ) max Pp (Xt = xt |XO = xO ) ,pKEpKEKE epistemic extension network.assume problems lower probability evidence zero (i.e.,minp Pp (XO = xO ) = 0), value solution (that is, minimization may achievezero maximization one).6 recent treatment zero probability case, seework de Bock de Cooman (2013). emphasize complexity results holdtrue regardless zero probabilities treated, take appropriate careavoid conditioning event zero probability reductions (as becomeclear later on).Example 4. Consider network Example 2, assume target node= 3, xt = 0 XO empty set. strong extension KS definedExample 3. outcome STRONG-INFXmin P(X3 = 0) = minp1 (x1 )p2 (x2 )px3 1 x2 (0)pKSx1 ,x2= 1 + min{2p1 (0)p2 (0) p1 (0) p2 (0)}= 1 (2 1/2 1/2 1/2 1/2) = 1/2 ,minimizations right performed p1 p2 ,Xmax P(X3 = 0) = maxp1 (x1 )p2 (x2 )px3 1 x2 (0)pKSx1 ,x2= 1 + max{2p1 (0)p2 (0) p1 (0) p2 (0)}= 1 (2 0.4 0.4 0.4 0.4) = 0.52 .outcome EPISTEMIC-INF values solutions linear programsmin{p(0, 0, 0) + p(1, 1, 0) : p KE } = 5/11 < 1/2max{p(0, 0, 0) + p(1, 1, 0) : p KE } = 5/9 > 0.52 ,KE epistemic extension defined Example 3.fact lower bound (resp., upper bound) EPISTEMIC-INF examplesmaller (resp., greater) lower bound (upper bound) STRONG-INFdirect consequence fact strong extension contained epistemicextension.6. upper probability evidence positive, regular extension used compute nonvacuous inferences (see Walley, 1991, Appendix J).613fiMaua, de Campos, Benavoli & AntonucciLet also z denote Kroneckers delta function z, returns one z zeroelsewhere. Since one-to-one mapping expectation probability,state inference problems slightly different equivalent way.STRONG-INF2Input: credal network (X, G, Q), target node t, assignment xt Xt ,(possibly empty) set evidence nodes O, assignment xO XO .Output: solution optpKS Ep ([ xt ]xO ) = 0, KS strongextension network, opt {min, max}.EPISTEMIC-INF2Input: credal network (X, G, Q), target node t, assignment xt Xt ,(possibly empty) set evidence nodes O, assignment xO XO .Output: solution optpKE Ep ([ xt ]xO ) = 0, KEepistemic extension network, opt {min, max}.main advantage reformulations linear-fractional programmingproblem transformed linear programming problem, facilitates obtainingresults. refer reformulations interchangeably, mindequivalence.3. Complexity Resultssection study complexity inference credal networks respectirrelevance concept adopted, network topology variable domain cardinality.3.1 Previously Known ResultsComputing STRONG-INF notoriously hard task, whose complexity strongly dependstopology DAG cardinality variable domains. Cozman et al.(2004) proved problem NPPP -hard. De Campos Cozman (2005) studiedparametrized complexity concluded problem NP-hard even singlyconnected networks bounded treewidth. long-known positive result 2U algorithm Fagiuoli Zaffalon (1998), solves problem polynomial timeunderlying graph polytree variables binary. networks assuming naiveBayes topology (i.e., containing single root variable single parent remaining variables), Zaffalon (2002) showed STRONG-INF computed efficientlyquery root variable. Zaffalon Fagiuoli (2003) showed problempolynomial-time solvable tree-shaped networks evidence. De CamposCozman (2005) showed obtaining approximate solutions provably maximum error bound impossible unless P equals NP, even polytrees. hand,Maua, de Campos, Zaffalon (2013) showed variable cardinalitiestreewidth assumed bounded, fully polynomial-time approximation schemefinds solutions withing given error time polynomial input 1/.known positive result regarding complexity approximate inferencecredal networks exact solution NP-hard.614fiProbabilistic Inference Credal Networks: New Complexity ResultsMuch fewer known complexity EPISTEMIC-INF. positive resultgiven de Cooman et al. (2010), developed polynomial-time algorithm computations credal trees.3.2 Outline Contributionsfirst contribution (sect. 3.3) development credal networks polynomial-timecomputable numbers. show networks allow us approximate arbitrarily wellnetwork still inducing positive lower probabilities event. usefulextend subsequent complexity results (some involving events lower probabilityzero) case lower probability event strictly positive.proceed derive complexity results STRONG-INF EPISTEMICINF. first new complexity result concerns precise-vacuous networks, credalnetworks comprised vacuous root nodes precise non-root nodes (sect. 3.4). credalnetwork transformed precise-vacuous network STRONG-INF providesresults original network; moreover, STRONG-INF known NPPP hard models. show solutions STRONG-INF EPISTEMIC-INFcoincide precise-vacuous networks, implies NPPP -hardness EPISTEMIC-INF.hardness result holds even case binary variables (and multiply connectednetworks).next show problems remain NP-hard singly connected credal networkseven constraint variables take three values bound treewidthtwo (sect. 3.5). show sequence STRONG-INF NP-hard already credaltrees (sect. 3.6); discussed, EPISTEMIC-INF polynomial-time computable case.Imprecise hidden Markov models tree-shaped credal networks extend standard(precise) Hidden Markov Models (HMMs) allow imprecisely specified parametersform credal sets. HMMs commonly used represent time-dependent process wide applicability. Since imprecise HMMs particular instances credaltrees, EPISTEMIC-INF performed polynomial time models. showSection 3.7 target node last node longest directed pathnetwork inferences strong independence epistemic irrelevance coincide (incontext time-series prediction, inference known filtering). consequence,STRONG-INF also polynomial-time computable queries. despite factstrong epistemic extensions might disagree models, showcounter-example different type query. leave open complexitygeneral inferences imprecise HMMs strong independence.corollaries equivalence certain type inference HMMs, obtainSTRONG-INF EPISTEMIC-INF also coincide marginal inference (i.e., evidence) tree-shaped networks, last-node inference imprecise Markov chains (sect. 3.8)naive Bayes structures (sect. 3.9). results previously obtained independently irrelevance concept tractability thought coincidental.organize presentation mentioned results according complexityunderlying DAG, listing results complex structures simplestones. reason proceed fashion allow obtaining results simpler615fiMaua, de Campos, Benavoli & Antonuccimodels imprecise Markov chains naive Bayes structures corollaries resultscomplex models imprecise hidden Markov models.3.3 Networks Specified Computable Numberspresenting complexity results, need introduce concept polynomialtime computable numbers, discuss properties networks specifiednumbers. used within later proofs essential way, including (but only)showing hardness results hold true even assume possible eventpositive probability.number r polynomial-time computable exists transducer Turing machineMr that, integer input b (represented binary string), runs timepoly(b) (the notation poly(b) denotes arbitrary polynomial function b, mightindicate different polynomial time used) outputs rational numberr0 (represented numerator denominator binary strings) |rr0 | < 2b . special relevance us numbers form (2v1 2v2 )/(1 + 2v3 ),v1 , v2 v3 non-negative rationals greater two. rational vzero two build machine outputs rational r0 approximates2v precision b time poly(b) computing Taylor expansions 2v aroundzero sufficiently many terms (depending value b) similar proofLemma 4 work Maua et al. (2013). desired numbers obtainedcorresponding fractional expression. following lemmas ensure outcomeSTRONG-INF networks specified polynomial-time computable numbersapproximated arbitrarily well using network specified positive rational numbers.allows us specify desired precision nodes network numericalparameters approximated positive rational numbers.Lemma 1. Consider vertex-based credal network N whose numerical parametersspecified polynomial-time computable numbers encoded respective machines (ordirectly given rational numbers), let b size encoding N . Givensubset nodes N 0 N N rational number 1 2poly(b) , constructtime poly(b) vertex-based credal network N 0 variables whose numericalparameters specify credal sets nodes N 0 rational numbers greater2poly(b) (numerical parameters related nodes N 0 kept unchanged),polynomial-time computable surjection (p, p0 ) associates extreme pstrong extension N extreme p0 strong extension N 0 satisfyingmax |Pp0 (XA = xA ) Pp (XA = xA )| ,xAsubset XA X variables.Proof. Take N 0 equal N except computable number r used specification N nodes N 0 replaced rational r0 |r0 r| < 2(n+1)(v+1)1 ,n number variables, v maximum cardinality domainvariable N . 2poly(b) , run Turing machine Mr used represent rinput poly(b)+(n+1)(v+1)+1 obtain r0 time O(poly(poly(b) + (n + 1)(v + 1) + 1)),O(poly(b)). obtaining r0 , add 2(n+1)(v+1)1 ensure r < r0 <616fiProbabilistic Inference Credal Networks: New Complexity Resultsr + 2(n+1)(v+1) , is, approximation above. However, exactly oneprobability values distribution used represent extreme local credal setN 0 approximated way computed one minus sumnumbers ensure distribution adds exactly one; choose greatestvalue (by trying (at most) v states, probability value least1/v), error respect corresponding original computable number(v 1) 2(n+1)(v+1) < 2n(v+1) . construction ensures every createdrational number greater 2(n+1)(v+1)1 > 2poly(b) error2n(v+1) original corresponding number.Let qi (xi |xPa(i) ) qi0 (xi |xPa(i) ) denote, respectively, parameters N N 0 (i.e.corresponding extreme distributions local credal sets Q(Xi |xPa(i) ) twonetworks) qi0 (xi |xPa(i) ) approximated version computed qi (xi |xPa(i) )explained. Consider assignment x variables N (or NQ0 ). Let also pextreme strong extension N . p factorizes p(x) = qi (xi |xPa(i) ),combination extreme distributions qi (|xPa(i) ) Q(Xi |xPa(i) ), N . Finally,let p0 extreme distribution strong extension N 0 satisfies p0 (x) =Q00n(v+1) . followsqi (xi |xPa(i) ). construction, |qi (xi |xPa(i) ) qi (xi |xPa(i) )| 2binomial expansion factorization p0 (x) xp0 (x) =qi0 (xi |xPa(i) )2n(v+1) + qi (xi |xPa(i) )=X(2nvn )n|A|qi (xi |xPa(i) )iA2n 2nvn +qi (xi |xPa(i) )= p(x) + 2nv .second inequality follows fact one term p(x) expansion2n 1 terms written product 2n(v+1) non-negative numbersless equal one. similar reasoning, showp0 (x)qi (xi |xPa(i) ) 2n(v+1) p(x) 2nv .Thus, maxx |p0 (x) p(x)| 2nv . consider subset variables XAassignment xA XA . SinceXPp0 (XA = xA ) =p0 (x0 ) ,x0 :x0A =xAterm p0 (x0 ) sum satisfies p0 (x0 ) p(x0 ) + 2nv , lessv n 2vn terms summed, followsXPp0 (XA = xA )p(x) + 2vn Pp (XA = xA ) + .x0 :x0A =xAanalogous argument used show Pp0 (XA = xA ) Pp (XA = xA ) . Noteobtained mapping (p, p0 ) surjection construction.617fiMaua, de Campos, Benavoli & Antonuccilemma following direct consequence computationSTRONG-INF polynomial-time computable numbers. restriction application computable numbers must either zero greaterexponentially close zero.Corollary 1. Consider vertex-based credal network N whose numerical parametersspecified polynomial-time computable numbers encoded respective machines (ordirectly given rational numbers), number lies properly ]0, [,0 1. Let b size encoding network. Given subsetnodes N 0 N N rational number 2poly(b) < , constructtime poly(b) vertex-based credal network N 0 variables whose numericalparameters defining credal sets related nodes N 0 strictly positive rational numbersgreater 2poly(b) (numbers defining credal sets nodes N 0 kept unchanged),7|STRONG-INF(N 0 , t, xt , O, xO ) STRONG-INF(N , t, xt , O, xO )| ,query t, xt , O, xO either = minp Pp (xO ) > 0 N .Proof. According Lemma 1, polynomial-time computable network N 0 whosenumerical parameters specify credal sets related nodes N 0 positive rational numbers polynomial-time computable surjection (p, p0 ) p p0are, respectively, extreme distributions strong extension N N 0 , satisfy|Pp0 (xA ) Pp (xA )| n+1 /3 XA X xA XA . followsPp0 (xt |xO ) =Pp0 (xt , xO )Pp (xt , xO ) n+1 /3,Pp0 (xO )Pp (xO ) + n+1 /3p0 image p according surjection. Pp (xt , xO ) = 0, equationuseless vanishes. Otherwise, Lemma 7 work de Campos Cozman(2013),Pp (xt , xO ) n+1 /32n+1 /3P(x|x)Pp (xt |xO ) .pPp (xO ) + n+1 /3nside inequality obtained analogously (using Lemma 7work de Campos & Cozman, 2013, except case Pp (xt , xO ) = 0,following reasoning valid without need lemma):Pp (xt , xO ) + n+1 /32n+1 /3P(x|x)+pPp (xO ) n+1 /3n n+1 /32Pp (xt |xO ) +Pp (xt |xO ) + .3Pp0 (xt |xO )Hence, |Pp0 (xt |xO )Pp (xt |xO )| . Let p extreme distribution strong extensionN Pp (xt |xO ) = minqKS Pq (xt |xO ), KS denotes strong extension7. abuse notation STRONG-INF, defined opt {min, max}. intend meanequation valid options opt.618fiProbabilistic Inference Credal Networks: New Complexity ResultsN .min Pq (xt |xO ) = Pp (xt |xO ) Pp0 (xt |xO ) min0 Pq0 (xt |xO ) ,q 0 KSqKSp0 first inequality image p according surjection, KS0last inequality strong extension N 0 . followsmin Pq0 (xt |xO ) min Pq (xt |xO ) .q 0 KS0qKSside comes contradiction. Supposemin Pq (xt |xO ) min0 Pq0 (xt |xO ) > min Pq (xt |xO ) > min0 Pq0 (xt |xO ) .qKSq 0 KSq 0 KSqKSHence would exist extreme q 0 KS0 |Pq0 (xt |xO ) Pq (xt |xO )| >q KS , impossible mapping (q, q 0 ) surjection. analogous proofworks showing upper bounds according two networks differ.3.4 Precise-Vacuous Networksshow EPISTEMIC-INF NPPP -hard arbitrary networks, need followingresult, shows inferences strong independence epistemic irrelevancecoincide precise-vacuous networks.Proposition 2. Consider credal network whose root nodes vacuous non-rootnodes precise. Let non-root node, xt arbitrary value Xt = .STRONG-INF equals EPISTEMIC-INF.Proof. Let XR vacuous variables associated root nodes (hence vacuouslocal credal sets), XI denote remaining variables (which precise). everyxprecise node I, let qi Pa(i) (xi ) single distribution associated credal setQ(Xi |xPa(i) ). Consider arbitrary distribution p epistemic extension KE , let< topological ordering nodes. assignment x X, write x<i denotecoordinates j < x according topological ordering. every node set{j N : j < i} subset Nd(i), follows definition epistemic extensionxPp (xi |x<i ) = qi Pa(i) (xi ) every precise node assignments xi x<i .Chain Rulex X :Pp (x) = Pp (xR )Pp (xi |x<i ) = q(xR )iIxqi Pa(i) (xi ) ,iIq distribution XR (since nodes vacuous, distribution satisfiesconstraints KE them). stated, let xt value interest Xt . result619fiMaua, de Campos, Benavoli & AntonucciEPISTEMIC-INF thus givenmin Pp (Xt = xt ) =pKE=minqV (XR )minqV (XR )=minqV (XR )Xxt (xt ) q(xR )xXq(xR )xRXXYxqi Pa(i) (xi )iIxPa(i)qi(xi )xt (xt )xI iIq(xR ) g(xR ) ,xRxPa(i)def P Qg(xR ) =(xi ). According last equality, lowerxIiI xt (xt )qimarginal probability Xt = xt convex combination g(xR ). Hence,X xPa(i)min Pp (Xt = xt ) minqi(xi ) .pKExRxI\{q} iIrightmost minimization exactly value lower marginal probability returnedSTRONG-INF, since strong extension contained epistemic extension,inequality tight. analogous result obtained upper probabilitysubstituting minimizations maximization inverting inequality above.class networks considered result might seem restrictive firstsight. However, Antonucci Zaffalon (2008) showed STRONG-INF credalnetwork whose local credal sets represented vertex-based form reducedlinear time problem credal network containing vacuous precisenodes. network transformed linear time precise-vacuous network(i.e., one root nodes vacuous non-root nodes precise) applyingTransformation 6 work Maua, de Campos, Zaffalon (2012a),8 increasestreewidth network three. Hence, vertex-based credal networkreduced polynomial time precise-vacuous network STRONGINF provides result original network (and whose treewidth remainsbounded, originally were). hardness EPISTEMIC-INF precise-vacuous credalnetworks follows immediately hardness inference strong independenceProposition 2, following corollary shows.Corollary 2. STRONG-INF EPISTEMIC-INF NPPP -hard even variablesbinary numerical parameters strictly positive.Proof. Cozman et al. (2004) used reduction E-MAJSAT STRONG-INF withoutevidence binary credal network whose root nodes vacuous non-root nodesprecise show inference NPPP -hard. Since according Proposition 2 resultEPISTEMIC-INF same, EPISTEMIC-INF also NPPP -hard. order showresult valid also numerical parameters strictly positive, sketchproof avoid repeating formulation E-MAJSAT problem. UsingLemma 1 epsilon = 2poly(b) smaller precision number involved8. Strictly speaking, work Maua et al. (2012a) deals influence diagrams; linkcredal networks established Antonucci Zaffalon (2008) de Campos Ji (2008).620fiProbabilistic Inference Credal Networks: New Complexity Resultscalculation, build new network numerical parameters strictly positivevariation result STRONG-INF negligible still decideE-MAJSAT (further details small omitted simplicity,2gap instances large enough 2O((n+m) ) suffice, n,number variables clauses specification E-MAJSAT, see Park & Darwiche,2004, Thm. 2). EPISTEMIC-INF contains STRONG-INF, result applyingLemma 1 results STRONG-INF new network oldnetwork (the latter equals EPISTEMIC-INF). Hence, EPISTEMIC-INF newnetwork strictly positive numerical parameters also decides E-MAJSAT.Note result holds irrespective local credal sets represented, sincevacuous precise nodes mapped constraint-based vertex-based formvice-versa polynomial time.3.5 Singly Connected Networksturn attention singly connected networks. first result direct consequence Proposition 2 NP-hardness EPISTEMIC-INF singly connected credalnetworks, since STRONG-INF NP-hard singly connected networks, even admitimprecision root nodes:Corollary 3. EPISTEMIC-INF NP-hard singly connected credal networks.Proof. work de Campos Cozman (2005) shown STRONG-INFNP-hard precise-vacuous singly connected networks. Since Proposition 2 showsEPISTEMIC-INF reduced STRONG-INF input, result follows.proof NP-hardness STRONG-INF provided de Campos Cozman (2005)requires variable domain cardinalities unbounded. present strongerresult NP-hardness credal inference networks imprecise variables binaryprecise ones ternary. show NP-hardness credal inferencesingly connected networks bounded variable cardinality.Theorem 1. STRONG-INF EPISTEMIC-INF NP-hard even network singlyconnected treewidth two, imprecise variables binary, precisevariables (at most) ternary. Moreover, numerical parameters networkstrictly positive.Proof. defer treatment zero numerical parameters final part. buildsingly connected credal network underlying graph Figure 3. variables(associated nodes) upper row binary vacuous, namely X1 , . . . , Xk ,remaining variables Xk+1 , , X2k+1 ternary precise. local credalsets associated precise nodes singletons Q(Xk+1 ) contains uniformdistribution q(xk+1 ) = 1/3, and, = k + 2, . . . , 2k + 1, Q(Xi |xi1 , xik1 ) containsconditional distribution q(Xi |xi1 , xik1 ) specified Table 1. rational numbers vitable shall defined later on. Consider extreme distribution p(x) strong621fiMaua, de Campos, Benavoli & Antonuccik+1123k+2k+3k+4k2k+1Figure 3: Credal network structure used prove Theorem 1. shaded nodetarget.q(xi |xi1 , xik1 )xi = 1xi = 2xi = 3xi1 = 1, xik1 = 1xi1 = 2, xik1 = 1xi1 = 3, xik1 = 1xi1 = 1, xik1 = 0xi1 = 2, xik1 = 0xi1 = 3, xik1 = 02vi01001 2vi0101 2vi1001002vi0Table 1: Local probability distributions used prove Theorem 1extension network. follows xp(x) = q(xk+1 )2k+1q(xi |xi1 , xik1 )iAi=k+21 (xi )0 (xi ) ,iA/{1, . . . , k}. extreme distributions local vacuous setsbinary variables 0 1 , choice local extreme root nodeassociated choice either including excluding corresponding node in/fromdefA. Let = {1, . . . , k} \ denote complement set respect {1, . . . , k}.( Q2k+11q(xi |xi1 , xik1 ), xA = 1 xA = 0 ;p(x) = 3 i=k+20,otherwise.followsPp (X2k+1 = 1) =Xp(x)1 (x2k+1 ) =x2PiA3viPp (X2k+1 = 2) =2PiA3vi 2.show NP-hardness credal inference reducing NP-complete PARTITIONproblem (Garey & Johnson, 1979) computation maxpKS Pp (X2n+1 = 3).define PARTITION follows.PARTITIONInput: List positive integers z1 , . . . , zk .Output: subset {1, . . . , k}XXzi =zi ?iAiA622fiProbabilistic Inference Credal Networks: New Complexity Resultsh(v)1.21.1100.51v1.52Figure 4: Function used reduction proof Theorem 1.Notice equality equivalentkXzi /z = 1 ,1Xz =zi .2i=1iAdefdef PDefine exponentsTable1v=z/z,letv= iA vi . followsPvA = 2 iA vi . instance PARTITION yes-instance (i.e., outputPARTITION yes), vA = 1, whereas no-instance (i.e.,output no), A, follows |vA 1| 1/(2z) numbersinput integers hence sums two different sets either equal differleast one. Consider functionh(vA ) =2(vA 1) + 2vA 1.2graph function depicted Figure 4. Seen function continuous variablevA [0, 2], function strictly convex, symmetric around one, achievesminimum value one vA = 1. Thus, PARTITION returns yes minA h(vA ) = 1,returns4min h(vA ) 21/(2z)1 + 21/(2z)1 2(2z)> 1 + (2z)4 /2 = 1 + 1/(32z 4 ) ,second inequality due Lemma 24 work Maua et al. (2012a),4defstrict inequality follows first-order Taylor expansion 2(2z) . Let =(1 + z 4 /64)/3. computing STRONG-INF query X2n+1 = 3 evidence,decide PARTITION,1 max Pp (X2k+1 = 3) = min (Pp (X2k+1 = 1) + Pp (X2k+1 = 2)) = minph(vA )3result PARTITION yes. remains show polynomiallyencode numbers 2zi /z . done applying Lemma 1 small enough623fiMaua, de Campos, Benavoli & Antonucci0123kk+1k+2k+32kFigure 5: DAG credal tree used prove Theorem 2.computable time polynomial size partition problem: = 1/(3 64z 4 )suffices. Note apply Lemma 1 non-root nodes leave rootnodes untouched vacuous, according Proposition 2, outcome EPISTEMICINF same, proving also NP-hardness. Now, applying Lemma 1 rootvacuous nodes, ensure numerical parameters strictly positive still yieldresult used decide PARTITION. EPISTEMIC-INF contains STRONGINF, result applying Lemma 1 results STRONG-INFnew network network vacuous root nodes. Hence, EPISTEMIC-INFnew network strictly positive numerical parameters also decides PARTITION.3.6 Credal Treesprevious complexity results showed that, theoretical standpoint, computingEPISTEMIC-INF difficult solving STRONG-INF. underlying graphtree, de Cooman et al. (2010) showed EPISTEMIC-INF computed efficiently,previously unknown whether similar result could obtained STRONG-INF.next result shows case equivalence tractability twodifferent irrelevance concepts hold unless P equals NP.Theorem 2. STRONG-INF tree-shaped credal networks NP-hard, even one variable ternary precise rest binary, even numerical parametersstrictly positive.Proof. show hardness reduction PARTITION defined previously. before,Pdefdef Pdefine vi = zi /z, vA = iA vi , note vA = 2 iA vi . also let h(vA )(thus h strictly convex [0, 2], symmetric around one, achievesminimum value one vA = 1). Given instance PARTITION (i.e., list integers),build credal tree N variables X0 , . . . , X2k DAG Figure 5. rootvariable X0 takes values {1, 2, 3}, precise uniformly distributed (i.e., localcredal set contains distribution q0 (x0 ) = 1/3). remaining variablesbinary take values {0, 1}. = 1, . . . , k, specify local conditional credalsets Q(Xi |x0 ) singletons {qix0 }vivi2 /(1 + 2 ),qix0 (1) = 1/(1 + 2vi ),1/2,624x0 = 1,x0 = 2,x0 = 3.fiProbabilistic Inference Credal Networks: New Complexity Results= 1 + k, . . . , 2k specify local credal sets Q(Xi |xik ) = {p V (Xi ) : p(1)1}, = 2k3 /(64z 4 ). local credal sets represented eithervertex-based form two extreme distributions couple constraints.LetPp (X0 = 3, XO = xO )def= max Pp (X0 = 3|XO = xO ) = max.pKSpKSPp (XO = xO )Hence, solution"#Xmax(3 (x0 ) )Pp (X0 = x0 , XO = xO ) = 0 .pKSx0definition, extreme distribution p strong extension KS satisfies x Xxk+1 = xk+2 = = x2k = 1 equalityp(x) = q0 (x0 )kqix0 (xi )ixi ,i=1ixinumber [, 1]. Let = {k + 1, . . . , 2k} xO = (1, . . . , 1). followssolutionmaxX(3 (x0 ) )q0 (x0 )x0 ,...,xkkqix0 (xi )ixi = 0 ,i=1maximization performed i0 , i1 , = 1, . . . , k. Consider j {1, . . . , k}letx defj j =XX(3 (x0 )) q0 (x0 )qjx0 (xj )x0 ,...,xj1 xj+1 ,...,xkk[qix0 (xi )ixi ] .i=1,i6=jThen,Xmax(3 (x0 ) ) q0 (x0 )x0 ,...,xkj0k[qix0 (xi )ixi ] = max j0 j0 + j1 j1 .i=1j1Sincepositive, maximization right-hand side equalszero j0 j1 zero different signs. former case,value j0 j1 maximizes expression, assume (j0 , j1 ) equals (, 1)(1, ). latter case, j0 < j1 implies (j0 , j1 ) equals (, 1) order maximizeexpression, (j0 , j1 ) = (1, ) would otherwise. Since selected j arbitrarily,result holds j. Thus, maximization equivalent selecting, = 1, . . . , k,value yi {0, 1} i0 = 1yi i1 = yi . followsmaxXx0 ,...,xk(3 (x0 ) ) q0 (x0 )k[qix0 (xi )ixi ] =i=1maxy{0,1}kX(3 (x0 ) ) q0 (x0 )x0 ,...,xkk[qix0 (xi )(1xi )(1yi ) xi yi ] .i=1625fiMaua, de Campos, Benavoli & Antonuccirearranging terms, obtainmaxy{0,1}kX(3 (x0 ) ) q0 (x0 )x0kx0qi (0)1yi + qix0 (1)yi ,i=1construction equalskkki=1i=1i=11yivi 1yi1Y1+max[+ 2vi yi ] +[2+ yi ] +3332y{0,1}k!,Q= ki=1 qi2 (1) (recall qi2 (1) conditional probability value Xi = 1given X0 = 2). binary vector seen characteristic vector subset{1, . . . , k}. Definedef(1 + 2vi )(2vi + )bA =iAiAevery subset A. optimization rewritten following optimizationsubsets A: find!1 1+ k+ max (bA + bA ) = 0 .323Solving expression , get=1+21+!1kmin (bA + bA ).Define function g(a)defg(a) = 1 +21+k(1 + a)defreal number a, let aA = bA + bA 1 {1, . . . , k}. =(minA g(aA ))1 . Note g(aA ) > 1 + (1 + aA )2k , > 2k (this usedlater). follows Binomial Theorem value bA close value2vA above.2vA bA (2vA + 2k )(1 + )k(2vA + 2k )(1 + 2k)2vA + 2k+2 ,used inequality (1 + r/c)c 1 + 2r valid r [0, 1] positive integerc (Maua, de Campos, & Zaffalon, 2011, Lemma 37). Thus conclude value aAclose (again above) h(vA ) 1.h(vA ) 1 aA h(vA ) 1 + 2k+3 = h(vA ) 1 + 1/(64z 4 ) .626fiProbabilistic Inference Credal Networks: New Complexity ResultsNow, partition problem yes-instance, h(vA ) = 1 (recall behavior hproof Theorem 3) thus aA 1/(64z 4 ), no-instance,h(vA ) > 1 + 1/(32z 4 ) thus aA > 1/(32z 4 ). Hence, gap least 1/(64z 4 )value aA yes- no-instances, decide partition problemverifying whether g(3/(128z 4 ))1 . proof shall completed guaranteeapproximate polynomial time irrational numbers used specifycredal tree g(a) well enough g(3/(128z 4 ))1 falls exactly middlegap values yes- no-instances (because g linear a). First, notek1112gg=,32z 464z 464z 4 1 +greater 2k /(64z 4 ) (since > 2k ). gap value least11g(1/(32z 4 )) g(1/(64z 4 ))=g(1/(64z 4 )) g(1/(32z 4 ))g(1/(64z 4 ))g(1/(32z 4 ))g(1/(32z 4 )) g(1/(64z 4 ))>g(1/(32z 4 ))2k2 /(64z 4 )2k>.>1k )24 64z 4(1 + (1 + 32z4 )2k20apply Corollary 1 = 12 464z4 obtain N network N madepositive rational numbers. guarantees separation yes-instancesno-instances PARTITION continue exist.credal network used reduction proves previous result sensesimplest tree-shaped network solving STRONG-INF hard, since problemwould polynomial-time solvable root node replaced binary variable.also interesting describes naive Bayes structure single layer latent variables,useful topology robust classification problems non-linearly separable feature spaces.3.7 Imprecise Hidden Markov Modelsimprecise hidden Markov model (HMM) credal tree whose nodes partitionedhidden manifest nodes hidden nodes form chain (i.e., sequencenodes one node linking next sequence), manifestnodes leaves graph. HMMs widely used represent discrete dynamic systemswhose output given time step stochastically determined current statesystem, assumed partially observable.Since HMM simply credal tree, algorithm de Cooman et al. (2010)used efficiently compute EPISTEMIC-INF HMMs, 2U used solveSTRONG-INF variables binary. networks variables takingtwo values, polynomial-time known STRONG-INF. section, showevidence variables farther (in sense number nodespath) root node target variable, outcomes STRONG-INFEPISTEMIC-INF coincide. cases, run de Cooman et al.s (2010) algorithm627fiMaua, de Campos, Benavoli & Antonucci1243Figure 6: Credal HMM Example 5.compute STRONG-INF polynomial time. however always true, is,types queries results STRONG-INF EPISTEMIC-INF differ,following example shows.Example 5. Consider HMM length two whose topology depicted Figure 6.variables binary take values {0, 1}. Variables X1 X2 hidden,variables X3 X4 manifest. local credal sets given Q(X1 ) = Q(X2 |0) =Q(X4 |0) = {p V (X4 ) : p(1) = 1/4}, Q(X2 |1) = Q(X4 |1) = {p V (X4 ) : p(1) = 3/4},Q(X3 |0) = {p V (X3 ) : 1/2 p(1) 3/4} Q(X3 |1) = {p V (X3 ) : 1/4 p(1)1/2}. Thus, variable X3 imprecise, remaining variables precise. Considerquery target X4 = 0 evidence X3 = 0. lower bound STRONG-INFvalue solves equationXXminq3x2 (0)g (x2 ) =min q3x2 (0)g (x2 ) = 0 ,x2x2minimizations performed q3x2 Q(X3 |x2 ), x2 = 0, 1,def Xg (x2 ) =(0 (x4 ) ) q1 (x1 )q2x1 (x2 )q4x1 (x4 ) ,x1 ,x4q1 = q20 = q40 = (3/4, 1/4) q21 = q41 = (1/4, 3/4). values q3x2 (0) dependsigns g (0) g (1), ought different expression vanish.Solving four possibilities, taking minimum value , find= 4/7 > 1/2.lower bound EPISTEMIC-INF value solvesminXq1 (x1 )q2x1 (x2 )q4x1 (x4 )qx1 ,x2 ,x4 (0)h (x4 ) =x1 ,x2 ,x4(1 )Xq1 (x1 )q2x1 (x2 )q4x1 (0) min qx1 ,x2 ,0 (0)x1 ,x2Xq1 (x1 )q2x1 (x2 )q4x1 (1) max qx1 ,x2 ,1 (0) = 0 ,x1 ,x2h (x4 ) = 0 (x4 ) , q1 , q2x1 q4x1 defined before, qx1 ,x2 ,x4 Q(X3 |x2 )every x1 , x2 , x4 . Solving equation obtain = 13/28 < 1/2.example shows STRONG-INF EPISTEMIC-INF might differ, evensimple case HMMs binary variables. currently unknown whether typeinference hard STRONG-INF. following result shows least particularcase, computations STRONG-INF EPISTEMIC-INF HMMs coincide.628fiProbabilistic Inference Credal Networks: New Complexity Results02n-213n-1nFigure 7: DAG HMM considered Theorem 3.Theorem 3. Consider separately specified HMM variables X0 , . . . , Xn . variablesassociated odd numbers manifest, remaining variables hidden (seeFigure 7). Consider also target hidden node Xn = xn , evidence XO = xOsubset manifest nodes. outcomes STRONG-INF EPISTEMIC-INFsame.defProof. Define f (xn ) = xn (xn ) given , consider distribution pepistemic extension KE minimizesXf (xn )p(x) .xX:xO =xOLet < topological orderingnodes. Chain Rule, x pQnfactorizes p(x) = Pp (x0 ) i=1 Pp (xi |x<i ), x<i denotes coordinates xj xj < according topological ordering (we also write xi x>i denote analogousprojections). Assume non-negative integer less equal n holdsXXxPa(j)f (xn )p(x)f (xn )Pp (xj |x<j )pj(xj ) ,x:xO =xOxpj Pa(j)j<ix:xO =xOjirecursively defined extreme distribution local credal setQ(Xj |xPa(j) ) minimizes eitherX xPa(j)XxPa(k)pj(xj )f (xn )pk(xk ) ,xjj O,x>jxpj Pa(j) (xj )Xk>jf (xn )x>jxpk Pa(k) (xk ) ,k>jj O, xj value Xj compatible xO . show induction= n, . . . , 0 assumption true. 1XxPa(j)f (xn )Pp (xj |x<j )pj(xj ) =j<ix:xO =xOXjiPp (xj |x<j )x<i1 :xO =xO j<i1Xx<i1 :xO =xO j<i1Pp (xj |x<j )XPp (xi1 |x<i1 )xi1Xf (xn )xiXminqQ(Xi1 |xPa(i1) )Xx:xO =xO629q(xi1 )xi1f (xn )j<i1xpk Pa(k) (xk )kiXxif (xn )xpk Pa(k) (xk ) =k>iPp (xj |x<j )ji1xpj Pa(j) (xj ) ,fiMaua, de Campos, Benavoli & Antonucciinequality follows definitionPP epistemic extension, impliesh(x)P(x|x)minp Nd(i)qQ(Xi |xPa(i) )xixi h(xi )q(xi ) function h xi (noteNd(i) {j < i}, minimization right constant w.r.t. valuesxj<i:j Pa(i)). case node analogous sum substituted single/term. = n, followsXXXf (xn )Pp (xt |x<n )f (xn )p(x) =Pp (xj |x<j )xtxj<n :xO =xO jnx:xO =xOXf (xn )pnxn2 (xn )Pp (xj |x<j ) ,j<nx:xO =xObasis induction holds. = 0,XxPa(j)Xf (xn )p(x)f (xn )p0 (x0 )pj(xj ) ,x:xO =xOx:xO =xOlower bound STRONG-INF. Thus, since epistemic extension containsstrong extension, inequality tight. particular, equality holdslower bound EPISTEMIC-INF, followsXXminf (x)p(x) = minf (x)p(x) = 0 ,pKSx:xO =xOpKEx:xO =xOKS denotes strong extension. analogous proof shows also upperbounds coincide.previous result shows least particular case one seeks probability last variable, STRONG-INF computed polynomial time. Althoughrestrictive, type inference highly relevant, corresponds predicting futurestate partially observable dynamic system whose future state depends levelcurrent (unknown) state. also another type inference treesinsensitive irrelevance concept adopted, case marginal inferences:Corollary 4. Consider tree-shaped network N target Xt = xt .STRONG-INF(N , t, xt , , ) = EPISTEMIC-INF(N , t, xt , , ) .Proof. say node barren ancestor target evidence node.well-known removing barren nodes Bayesian network affectoutcome BN-INF (Koller & Friedman, 2009). Since inference strong independenceseen (exponentially many) inferences Bayesian networks, result STRONGINF also unaltered remove barren nodes. Moreover, since N tree, removing barrennodes leaves chain ancestors t. According Theorem 15 workCozman (2000), epistemic extension N projected ancestors t, is,set marginal distributions xA XA induced joint distributions epistemicextension, denotes ancestors t, epistemic extension networkget removing nodes A. implies barren nodes discarded alsoinferences epistemic irrelevance, result follows.630fiProbabilistic Inference Credal Networks: New Complexity Results0123Figure 8: DAG naive Bayes 3 feature variables.Zaffalon Fagiuoli (2003) developed linear-time algorithm compute marginalinferences strong independence trees by-product work imprecisetree-augmented naive Bayes classifiers. result shows algorithmused compute marginal inferences trees epistemic irrelevance; conversely,de Cooman et al.s (2010) algorithm epistemic trees used compute marginalinferences strong trees.3.8 Imprecise Markov Chainssimplest DAG structure forming connected graph chain, is,network variable one parent one child. Credal chainsusually known (imprecise) Markov chains. chain also tree, computingEPISTEMIC-INF done polynomial time; also case STRONG-INFchains binary variables, subcase binary polytrees. chain seenHMM values manifest variables deterministically determinedvalues hidden variables. such, equivalence types inferencecertain types HMMs extends chains:Corollary 5. Consider credal chain X0 Xn , target Xn = xn single leafvariable separately specified (imprecise) Markov chain, evidence XO = xOarbitrary non-leaf variables. outcomes STRONG-INF EPISTEMIC-INFcoincide.Proof. proof Theorem 3 applies here, omit manifest nodes.3.9 Imprecise Naive Bayeswidely used DAG structure naive Bayes, node (usually called class)nodes (called features) children, arc present. Figure 8 depictsnaive Bayes structure class variable X0 features X1 , X2 X3 . DAGconstitutes structure behind Naive Bayes Naive Credal Classifiers (Zaffalon,2002). tree, computing EPISTEMIC-INF done polynomial time;also case STRONG-INF target node class variable (Zaffalon, 2002).show next similar tractability coincidental: inferences yieldresult, even target class node. achieve result buildingHMM first hidden variable class hidden variablesstate space class deterministically determined value,manifest variables features naive Bayes structure. such, equivalenceinferences types irrelevance extends queries node naive Bayesstructure:631fiMaua, de Campos, Benavoli & AntonucciMODELSTRONG-INFEPISTEMIC-INF*Naive Bayes*Imprecise HMM (query last node)Imprecise HMMs*Credal trees (no evidence)Credal treesCredal polytrees binary variablesCredal polytrees ternary variablesBounded treewidth networksCredal networks*Precise-vacuousPPUnknownPNP-hardPNP-hardNP-hardNPPP -hardNPPP -hardPPPPPUnknownNP-hardNP-hardNPPP -hardNPPP -hardTable 2: Parametrized complexity inference credal networks.Corollary 6. Consider credal network N naive Bayes structure X0 X1 , X0X2 , , X0 Xn , target Xt = xt node t, evidence XO = xO arbitraryfeatures (leaf variables). outcomes STRONG-INF EPISTEMIC-INF coincide.Proof. Let X00 = X0 X10 , , Xn0 precise variables state spaceclass X00 probability distributions q(x0i |x0i1 ) = 1 x0i = x0i1 zero otherwise,= 1, . . . , n. Define Q(Xi |Xi0 = x0i ) using credal set Q(Xi |X0 = x0 ) originalnetwork N , whenever x0i = x0 , = 1, . . . , n. Without loss generality, assume= n (if query X0 , use Xn0 query instead Xn ). procedure createsimprecise HMM hidden nodes X00 , . . . , Xn0 , manifest nodes X1 , . . . , Xn1 , finalquery = n Xt = xt . HMM clearly yields inferential resultnaive Bayes network N STRONG-INF. Theorem 3, results STRONG-INFEPISTEMIC-INF coincide HMM, hence result EPISTEMIC-INF HMMequal result STRONG-INF N . construction, EPISTEMIC-INF HMMcontains result EPISTEMIC-INF N (that is, latter equal lies insideformer). EPISTEMIC-INF always contains STRONG-INF, particularnaive Bayes structure, must coincide.3.10 Summary Complexity Resultscomplexity results obtained section suggest inference credal networkscomputationally difficult wide variety model structures dimensionalities.case, instance, precise-vacuous networks singly connected networksternary variables, according negative results shown. importationexceptions obtained including last-node inference (filtering) imprecise HMMsMarkov chains inference naive Bayes structures. positive resultsimportant structures applications pattern recognition tasks activityrecognition (Antonucci et al., 2011) robust classification (Zaffalon et al., 2003).previously known new inferential complexity results summarized Table 2.star indicates models inferences irrelevance concepts coincide.632fiProbabilistic Inference Credal Networks: New Complexity ResultsYet another irrelevance concept adopted imprecisely specified models Kuznetsovindependence. define Kuznetsov extension analogously definitionsstrong epistemic extensions, define problem inference Kuznetsov independence accordingly. known Kuznetsov extension lies epistemicstrong extensions (Cozman & de Campos, 2014). implies outcomesinferences Kuznetsov independence coincide strong independence epistemic irrelevance whenever last two coincide. hence get corollariesresults shown inference Kuznetsov independence NPPP -hardprecise-vacuous networks, NP-hard singly connected networks ternary variables,polynomial-time computable HMMs Markov chains target variable lastnode, polynomial-time computable naive Bayes structures target variableroot node.4. ConclusionCredal networks generalize Bayesian networks allow representation uncertainknowledge form credal sets, closed convex sets probability distributions.use credal sets arguably facilitates constructions complex models, presentschallenge computation inferences model.paper studied theoretical complexity inferences credal networks,concerns topology network, semantics arcs (i.e., whetherepistemic irrelevance strong independence assumed), cardinality variabledomains. nutshell, computing credal networks NP-hard except casestree-shaped models epistemic irrelevance, binary polytree-shaped modelsstrong independence. notable exception computation probability boundsvalue last variable imprecise hidden Markov models, caseshown inferences epistemic irrelevance strong independence coincide,implies latter polynomial-time computable. leave open questioncomplexity generic inferences imprecise HMMs strong independence.Another possible avenue future research investigating complexity approximate inference. De Campos Cozman (2005) showed approximating inferencestrong independence NP-hard, even consider singly connected networksbounded treewidth. however case variables binary, caserun 2U algorithm obtain exact value. Maua, de Campos, Zaffalon(2012b) showed network bounded treewidth whose variables boundedcardinality exists fully polynomial time approximation scheme performing inference strong independence, is, algorithm given rational > 0 findssolutions within factor 1 + true value time polynomial input size 1/. Apart tractability credal trees, nothing knowncomplexity approximate inference epistemic irrelevance, unless caseprecise-vacuous networks, showed provide inferencesstrong independence epistemic irrelevance, results approximate inferenceformer extend latter.633fiMaua, de Campos, Benavoli & AntonucciAcknowledgmentsfirst author received financial support PNPD/CAPES Sao Paulo ResearchFoundation (FAPESP) grant no. 2013/23197-4. second third authors receivedfinancial support Swiss National Science Foundation grants no. 200021-146606/1no. 200020-137680/1, respectively. shorter version paper appeared (Maua,de Campos, Benavoli, & Antonucci, 2013).ReferencesAntonucci, A., Bruhlmann, R., Piatti, A., & Zaffalon, M. (2009). Credal networksmilitary identification problems. International Journal Approximate Reasoning,50, 666679.Antonucci, A., de Campos, C., & Zaffalon, M. (2014). Probabilistic graphical models.Augustin, T., Coolen, F., de Cooman, G., & Troffaes, M. (Eds.), IntroductionImprecise Probabilities, pp. 207229. John Wiley & Sons.Antonucci, A., de Rosa, R., & Giusti, A. (2011). Action recognition imprecise hidden Markov models. Proceedings 2011 International Conference ImageProcessing, Computer Vision Pattern Recognition (IPCV), pp. 474478.Antonucci, A., Huber, D., Zaffalon, M., Luginbuhl, P., Chapman, I., & Ladouceur, R. (2013).CREDO: military decision-support system based credal networks. Proceedings16th Conference Information Fusion (FUSION 2013).Antonucci, A., Piatti, A., & Zaffalon, M. (2007). Credal networks operational riskmeasurement management. International Conference Knowledge-BasedIntelligent Information & Engineering Systems (KES), Vol. LNCS 4693, pp. 604611.Antonucci, A., & Zaffalon, M. (2008). Decision-theoretic specification credal networks:unified language uncertain modeling sets Bayesian networks. InternationalJournal Approximate Reasoning, 49 (2), 345361.Boyd, S. P., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press.Cano, A., Cano, J. E., & Moral, S. (1994). Convex sets probabilities propagation simulated annealing. Proceedings Fith International Conference InformationProcessing Management Uncertainty Knowledge Based Systems (IPMU),pp. 48.Corani, G., Giusti, A., Migliore, D., & Schmidhuber, J. (2010). Robust texture recognitionusing credal classifiers. Proceedings British Machine Vision Conference(BMVA), pp. 78.178.10.Cowell, R., Dawid, P., Lauritzen, S., & Spiegelhalter, D. (2007). Probabilistic NetworksExpert Systems: Exact Computational Methods Bayesian Networks. StatisticsEngineering Information Science Series. Springer.Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120 (2), 199233.Cozman, F. G. (2005). Graphical models imprecise probabilities. International JournalApproximate Reasoning, 39 (23), 167184.634fiProbabilistic Inference Credal Networks: New Complexity ResultsCozman, F. G., de Campos, C. P., Ide, J. S., & da Rocha, J. C. F. (2004). Propositionalrelational Bayesian networks associated imprecise qualitative probabilistic assessments. Proceedings 20th Conference Uncertainty ArtificialIntelligence (UAI), pp. 104111.Cozman, F., & de Campos, C. (2014). Kuznetsov independence interval-valued expectations sets probability distributions: Properties algorithms. InternationalJournal Approximate Reasoning, 55 (2), 666682.de Bock, J., & de Cooman, G. (2013). Allowing probability zero credal networksepistemic irrelevance. Proceedings 8th International SymposiumImprecise Probabilty: Theories Applications (ISIPTA).de Campos, C., & Ji, Q. (2011). Bayesian networks imprecise Dirichlet model appliedrecognition problems. Liu, W. (Ed.), Symbolic Quantitative ApproachesReasoning Uncertainty, Vol. 6717 Lecture Notes Computer Science, pp.158169. Springer, Berlin / Heidelberg.de Campos, C. P., & Cozman, F. G. (2005). inferential complexity Bayesiancredal networks. Proceedings 19th International Joint Conference Artificial Intelligence (IJCAI), pp. 13131318.de Campos, C. P., & Cozman, F. G. (2013). Complexity inferences polytree-shapedsemi-qualitative probabilistic networks. Proceedings 27th AAAI ConferenceAdvances Artificial Intelligence, pp. 217223.de Campos, C. P., & Ji, Q. (2008). Strategy selection influence diagrams using imprecise probabilities. Proceedings 24th Conference Uncertainty ArtificialIntelligence (UAI), pp. 121128.de Campos, C. P., Zhang, L., Tong, Y., & Ji, Q. (2009). Semi-qualitative probabilisticnetworks computer vision problems. Journal Statistical Theory Practice,3 (1), 197210.de Campos, L., Huete, J., & Moral, S. (1994). Probability intervals: tool uncertainreasoning. International Journal Uncertainty, Fuzziness Knowledge-Based Systems, 2, 167196.de Cooman, G., Hermans, F., Antonucci, A., & Zaffalon, M. (2010). Epistemic irrelevancecredal nets: case imprecise Markov trees. International Journal ApproximateReasoning, 51 (9), 10291052.de Cooman, G., & Miranda, E. (2012). Irrelevant independent natural extensionsets desirable gambles. Journal Artificial Intelligence Research, 45, 601640.de Cooman, G., & Troffaes, M. C. M. (2004). Coherent lower previsions systems modelling: Products aggregation rules. Reliability Engineering & System Safety, 85 (13), 113134.Fagiuoli, E., & Zaffalon, M. (1998). 2U: exact interval propagation algorithm polytrees binary variables. Artificial Intelligence, 106 (1), 77107.Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide TheoryNP-Completeness. W.H. Freeman.635fiMaua, de Campos, Benavoli & AntonucciHalpern, J. (2001). Conditional plausibility measures Bayesian networks. JournalArtificial Intelligence Research, 14, 359389.Kalai, G., & Ziegler, G. N. M. (2000). Polytopes: Combinatorics Computation. DMVSeminar. Birkhauser Verlag.Kendall, D. G. (1974). Foundations theory random sets. Harding, E., & Kendall,D. G. (Eds.), Stochastic Geometry, pp. 322376. John Wiley & Sons.Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models. MIT press.Kwisthout, J., & van der Gaag, L. C. (2008). computational complexity sensitivityanalysis parameter tuning. Proceedings 24th Conference UncertaintyArtificial Intelligence (UAI), pp. 349356.Kwisthout, J. H. P., Bodlaender, H. L., & van der Gaag, L. C. (2010). necessitybounded treewidth efficient inference Bayesian networks. Proceedings19th European Conference Artificial Intelligence (ECAI), pp. 237242.Levi, I. (1980). Enterprise Knowledge. MIT Press.Maua, D. D., de Campos, C. P., Benavoli, A., & Antonucci, A. (2013). complexitystrong epistemic credal networks. Proceedings 29th ConferenceUncertainty Artificial Intelligence (UAI), pp. 391400.Maua, D. D., de Campos, C. P., & Zaffalon, M. (2011). Solving limited memory influencediagrams. CoRR, abs/1109.1754.Maua, D. D., de Campos, C. P., & Zaffalon, M. (2012a). Solving limited memory influencediagrams. Journal Artificial Intelligence Research, 44, 97140.Maua, D. D., de Campos, C. P., & Zaffalon, M. (2012b). Updating credal networksapproximable polynomial time. International Journal Approximate Reasoning,53 (8), 11831199.Maua, D. D., de Campos, C. P., & Zaffalon, M. (2013). complexity solvingpolytree-shaped limited memory influence diagrams binary variables. ArtificialIntelligence, 205, 3038.Miranda, E., & Destercke, S. (2013). Extreme points credal sets generated elementary comparative probabilities. Proceedings 12th European ConferenceSymbolic Quantitative Approaches Reasoning Uncertainty (ECSQARU),Vol. 7958, pp. 424435.Park, J. D., & Darwiche, A. (2004). Complexity results approximation strategiesMAP explanations. Journal Artificial Intelligence Research, 21, 101133.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference. Morgan Kaufmann.Piatti, A., Antonucci, A., & Zaffalon, M. (2010). Building Knowledge-Based SystemsCredal Networks: Tutorial. Nova Science.Roth, D. (1996). hardness approximate reasoning. Artificial Intelligence, 82 (12),273302.636fiProbabilistic Inference Credal Networks: New Complexity ResultsSalvetti, A., Antonucci, A., & Zaffalon, M. (2008). Spatially distributed identificationdebris flow source areas credal networks. Transactions 4th InternationalCongress Environmental Modelling Software Integrating Sciences Information Technology Environmental Assessment Decision Making (iEMSs), pp.380387.Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press.Shenoy, P. P., & Shafer, G. (1988). Axioms probability belief-function propagation. Proceedings Fourth Annual Conference Uncertainty ArtificialIntelligence (UAI), pp. 169198.Tessem, B. (1992). Interval probability propagation. International Journal ApproximateReasoning, 7 (34), 95120.Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall.Walley, P. (2000). Towards unified theory imprecise probability. International JournalApproximate Reasoning, 24 (23), 125148.Wallner, A. (2007). Extreme points coherent probabilities finite spaces. InternationalJournal Approximate Reasoning, 44 (3), 339357.Zadeh, L. A. (1978). Fuzzy sets basis theory possibility. Fuzzy Sets Systems,1 (1), 328.Zaffalon, M. (2002). naive credal classifier. Journal Statistical Planning Inference, 105 (1), 521.Zaffalon, M. (2005). Credible classification environmental problems. Environmentalmodelling software, 20 (8), 10031012.Zaffalon, M., & Fagiuoli, E. (2003). Tree-based credal networks classification. ReliableComputing, 9 (6), 487509.Zaffalon, M., Wesnes, K., & Petrini, O. (2003). Reliable diagnoses dementianaive credal classifier inferred incomplete cognitive data. Artificial IntelligenceMedicine, 29 (12), 6179.637fiJournal Artificial Intelligence Research 50 (2014) 885-922Submitted 4/14; published 8/14Demand Side Energy Management via Multiagent CoordinationConsumer CooperativesAndreas VeitANDREAS @ CS . CORNELL . EDUDepartment Computer ScienceCornell UniversityIthaca, NY 14853 USAYing XuRonghuo ZhengYINGX 1@ ANDREW. CMU . EDURONGHUOZ @ ANDREW. CMU . EDUTepper School BusinessCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213 USANilanjan ChakrabortyNILANJAN . CHAKRABORTY @ STONYBROOK . EDUDepartment Mechanical EngineeringStony Brook UniversityStony Brook, NY 11794 USAKatia SycaraKATIA @ CS . CMU . EDURobotics Institute, School Computer ScienceCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213 USAAbstractkey challenge creating sustainable energy-efficient society make consumerdemand adaptive supply energy, especially renewable supply. article,propose partially-centralized organization consumers (or agents), namely, consumer cooperative purchases electricity market. cooperative, central coordinator buyselectricity whole group. technical challenge consumers make demanddecisions, based private demand constraints preferences, sharecoordinator agents. propose novel multiagent coordination algorithm, shapeenergy demand cooperative. coordinate individual consumers incomplete information, coordinator determines virtual price signals sends consumers induceshift demands required. prove algorithm converges central optimal solution minimizes electric energy cost cooperative. Additionally,present results time complexity iterative algorithm implications agentsincentive compatibility. Furthermore, perform simulations based real world consumptiondata (a) characterize convergence properties algorithm (b) understand effectdiffering demand characteristics participants well different price functions costreduction. results show convergence time scales linearly agent populationsize length optimization horizon. Finally, observe participants flexibilityshifting demands increases, cost reduction increases cost reduction sensitivevariation consumption patterns consumers.2014 AI Access Foundation. rights reserved.fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA1. IntroductionTwo key issues creating sustainable energy-efficient society increase penetrationrenewable sources, manage supply demand reduce demand peaksmaintaining supply demand balance. One way, commonly used, achievedemand supply balance supply requested demand whenever occurs. However,attempting achieve demand supply balance adjusting supply side leads useflexible (usually diesel operated) power plants expensive, inefficient, emit largeamount carbon. alternative adjusting supply side only, also adjust demandconsumers (Palensky & Dietrich, 2011) via demand response programs. Demand Responsedefined changes electricity consumption end users normal consumptionpatterns response changes price electricity time (Albadi & El-Saadany, 2007).Several different forms demand response programs developed (for overviewsee Albadi & El-Saadany, 2007). typical example incentive based program, customers receive payment participation, Direct Load Control programs, utilitiesremotely control power consumption consumers appliances switching on/off.small scale pilot studies, direct load control successful reducing peak energy consumption, however consumers uncomfortable yielding control appliances utilitycompanies (Rahimi & Ipakchi, 2010; Medina, Muller, & Roytelman, 2010). Another type demand management program price based, energy rates variable follow real costelectricity. objective indirect method control overall demand incentivizing consumers flatten demand curve shifting energy peak off-peak times.typical example programs Time Use pricing, price peak timeshigher price off-peak times. Recent technological advances smart meterssmart appliances created potential enable direct real time participation individualconsumers energy market thus make real-time price based demand management programsreality. However, two key problems realizing potential. First, despite presencesmall pilot programs, utilities consider individual consumers insufficient size considereddemand response services. Second, consumers participate market directly, ratherutilities, stability system may compromised (e.g., herding) (Ramchurn,Vytelingum, Rogers, & Jennings, 2012). Considering challenges, Mohsenian-Rad, Wong,Jatskevich, Schober, Leon-Garcia (2010) argue good demand side management programfocus controlling aggregate demand (which also important economic load dispatching, Wood & Wollenberg, 1996) group consumers instead individual consumers.paper, problem coordinating group consumers called consumer cooperativeintroduced studied.consumer cooperative, collective, allows partial centralization consumers representedgroup coordinator (mediator) agent, purchases electricity utilities marketbehalf. consumer configurations potentially increase energy efficiency via aggregation demand reduce peak power demand. coordinator neither market makertraditional demand response aggregator (Jellings & Chamberlin, 1993), since set energyprices aims incur profits selling market. Rather, role akin social planners,sense manages demand associated consumer group (a) electricity costgroup minimized, (b) individual group members autonomously decentralizedmanner decide shift demands, maintaining privacy individual demand preferencesconstraints. members cooperative typically geographically co-located closeproximity one another, example small neighborhood households and/or enterprises.practice, close proximity required due limitations distribution infrastructure, geograph886fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTically separated system operators, markets, electricity suppliers. proposed coordinationalgorithm could also benefit already existing structures universities, malls, industrial parks,commercial estates, large residential complexes. Although organizations may already purchase electricity centralized manner, constituent members (e.g. firms industrial park)currently coordinated keep constraints private.Consumer cooperatives offer advantages energy utility companies consumers.utility companys perspective, consumer groups large enough useful demand response programs predictable demand shifts compared individual consumers. Barbose, Goldman, Neenan (2004) give survey utility experience price based programsconclude participants large industrial customers. individual consumers, participation energy groups allows retain control appliances. addition,consumers obtain electricity better prices would have, purchasedelectricity individually. price advantage due three reasons: First, groups size allowsgroup enter flexible purchase contracts, price paid consumersreflects actual cost production accurately. case current long term fixedcontract structures (Kirschen, 2003). Second, buying collectively, group benefitvolume discounts analogous group insurance programs. Third, negotiated electricity contracts,price usually consists two components, one reflecting actual energy production costpremium volatility energy demand and/or supply. Buying grouphelp reduce premium volatility, provided demands group memberscoordinated, making total demand stable.aim paper design effective schemes coordinating electricity demandagents purchasing electricity consumer cooperative. technical challengeendeavor fact central coordinator know constraints individualconsumers, thus cannot compute optimal demand schedule own. Furthermore,actual cost electricity consumption depends aggregate consumption profile agents.However, agents may want share demand patterns constraints agentscoordinator. Therefore, present algorithm designed enable central agent coordinate consumers achieve optimal centralized load, individual agents decidedemand shifting autonomously retain private knowledge demand constraints.1papers contributions follows. First, present iterative coordination algorithmminimize energy cost consumer cooperative preserves privacy individualdemand constraints costs consumers. Second, prove algorithm convergescentralized optimal solution provide computational complexity results. Third, provideformal arguments incentive compatibility coordination scheme. Fourth, presentdiscuss extensive simulation results based real world data. preliminary version workappeared work Veit, Xu, Zheng, Chakraborty, Sycara (2013).paper organized follows: Section 2 give overview related workpoint differences approach paper. Section 3 formulate cost optimization problem consumer cooperative. Then, Section 4 introduce demand schedulingalgorithms consumer cooperative. particular, Section 4.1 introduce basic iterative algorithm Section 4.2 prove convergence optimal solution. Section 5,introduce general iterative algorithm Section 5.3 prove convergence general1. problem surface resemblance problems centralized coordinator determines resource allocations agents private preferences, coordinator tries elicit. problems typically addressedvia Vickrey-Clark-Groves mechanisms. problem differs fundamental ways discussedRelated Work section.887fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAsettings. Section 5.4, provide complexity analysis algorithms convergence Section 5.5 provide formal arguments incentive compatibility consumers. Section 6evaluate coordination algorithms using simulations based real world consumption data.Finally, Section 7, summarize main contributions paper offer perspectivefuture work.2. Related Workmentioned introduction, demand response programs vary classical direct loadcontrol price based programs real time prices. paper, introduce algorithmuses variable price signals coordinate energy consumption consumer cooperative.Therefore, restrict discussion demand management using variable price signals.Current literature price-based demand shaping mostly operates assumptiondesirable automated autonomous system (e.g. smart meter) receives pricesignals uses help consumer schedule demand minimize electricity cost,satisfying demand preferences constraints. two types price signalsused: dynamic deterministic prices. literature price-based demand responseprograms considers case deterministic prices, electricity prices time slotsknown consumption. case applies long-term contracts day-ahead markets,planning horizon sufficiently short (see Vytelingum, Ramchurn, Rogers, & Jennings, 2010;Ramchurn, Vytelingum, Rogers, & Jennings, 2011). known electricity prices, consumerscompute consumption schedule ahead time, e.g., daily consumption plan, annualproduction plan. paper falls category demand scheduling deterministic prices.approaches demand scheduling proposed literature differ important characteristics. First, differ level problem studied secondly differobjective demand scheduling. different levels problem studied include level single consumer, market maker, grid operator. differentobjectives include minimizing cost single consumer, minimizing total cost powergeneration, reducing peak-to-average ratio demand, optimizing grid stability.papers studying demand scheduling problem level grid operators,major concern grid stability. particular, objectives include minimization powerflow fluctuations (Tanaka et al., 2011), minimization power losses voltage deviations (Clement-Nyns, Haesen, & Driesen, 2010).work demand scheduling done level consumers. important characteristic regime electricity prices often exogenously fixed influenceddemand scheduling; i.e., consumer price taker. Almost papers regime focus(micro) demand scheduling one multiple appliances single residential householdcommercial building, typical objective minimize incurred electricity cost. example, Chu Jong (2008) study air-conditioning load control; Pedrasa, Spooner, MacGill (2010)optimize operation schedule various distributed energy resources including space heaterpool pump, etc. papers studying problem different perspectives. example, Philpott Pettersen (2006) Samadi, Mohsenian-Rad, Wong, Schober (2013) addresschallenge uncertainty loads consumers energy consumption. streamresearch close work, since well study demand management levelconsumers. However, instead studying single consumer, consider group consumersconsumer cooperative, buys electricity utility company known price scheme.work differs literature following aspects: size shift, system stability,888fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTindirect control, and, crucially, information privacy. First, literatureconsiders control single consumer, practice, may difficult utility companiesgrid operators deal individual consumers demand response programs. demand shift individual consumer might small magnitude compared aggregatednecessary shift. Thus, unclear whether scheme induce shift sufficient size.contrast, utilitys perspective, consumer cooperative studied work large enoughuseful demand response programs. Second, literature assumesconsumers participate markets directly. However, concerns voiced that,without control utility companies, stability system may compromiseduncontrolled distributed interactions (Kirschen, 2003). contrast, demands consumersconsumer cooperative coordinated central coordinator minimize electricity procurement cost cooperative. Buying group helps reduce demand volatility,coordinated demand management achieve higher stability demand reduce demandpeaks. Third, common assumption literature demand manager directcontrol appliances household perfect knowledge loads operationconstraints. However, cooperative, coordinator lacks control demand schedulingindividual consumers. Moreover, demand constraints preferences private knowledgeindividual consumer known either coordinator consumers.Another stream research related work demand scheduling level market maker. contrast previous approaches, regime, coordinator (i.e., marketmaker) set electricity prices consumers, often use price lever influencedemand number consumers. studies stream categorized two groups:centralized decentralized. Dietrich, Latorre, Olmos, Ramos (2012) compare demand response programs electric system high wind penetration two different settings (i.e.,centralized vs. decentralized) show centralized approach often reaches higher overallcost savings, disadvantage central knowledge consumers constraints preferences necessary. partially decentralized approach avoids limitation keeps consumersconstraints preferences private also achieving proven optimality solution.coordinator uses prices incentivize consumers shift demand, coordinatorneeds pay close attention possibility herding phenomenon, whereby agents movedemand towards low price times simultaneously thus cause spike demand bringinstability system. address issue, addition price signal, papers adoptauxiliary methods make agents gradually change loads. Voice, Vytelingum, Ramchurn,Rogers, Jennings (2011) charge agents additional fee based much changedemand profile one period next. Ramchurn et al. (2011) introduce adaptive mechanism controlling rate frequency agents allowed adapt loadsreadjust demand profile. Vytelingum et al. (2010) introduce compensation signal sentagents, providing estimate much aim change behavior.approaches may perform well, but, unlike work, provide formal guaranteesproposed algorithms converge optimal solution. Moreover, approaches requirecoordinator market maker charge consumers arbitrarily, e.g., imposing additional fees, feature may implementable acceptable practice. contrast,coordinator akin social planner must ensure total charge energy demandagents equal actual amount paid energy supplier.papers address decentralized demand-side management problem game theoretic perspective. mainly focus deriving charging mechanism make consumersreach stable demand equilibrium, achieves central objective. papers often share889fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAunderlying assumption individual consumers unit electricity cost increases consumers aggregate consumption. assumption holds setting energy costperiod increases difference demand supply (Wu, Mohsenian-Rad, & Huang,2012) Peak-To-Average ratio (Mohsenian-Rad et al., 2010; Nguyen, Song, & Han,2012), unit market price per period increases aggregate demand (Vytelingum, Voice,Ramchurn, Rogers, & Jennings, 2011; Atzeni, Ordonez, Scutari, Palomar, & Fonollosa, 2013).work Mohsenian-Rad et al. (2010), Nash equilibrium demand achieves optimality viadesigned billing strategy individual cost proportional total energy cost. However, billing strategy, consumer must estimate consumers demandmaking decision. Therefore, implement proposed algorithms, consumersneeds coordinate iterative manner exchange demand profilesiteration, may cause invasions consumers privacy. works Wu et al.(2012), Nguyen et al. (2012), Vytelingum et al. (2011) Atzeni et al. (2013), individual consumers dont need interact other, communicate central coordinator.papers, coordinator maintains equilibrium designing unit price, basedaggregate demand. algorithm often implemented distributed iterative scheme:iteration agents report loads coordinator coordinator updates priceaccordingly. Although papers ensure minimum information exchange, nonetheoretically proven algorithms would converge centralized optimal solution.contrast, paper safeguards privacy consumers, also proves algorithmconverges centralized optimal solution.problem surface resemblance problems, central coordinator determines resource allocations agents private preferences, coordinator tries elicit.problems typically addressed via Vickrey-Clark-Groves mechanisms. reason considering VCG-type mechanisms problem one key requirements application coordinator pay supplier groups electricity demand pricesgiven supplier. Thus, revenue, namely sum payments individual agents makeequal actual amount paid supplier. words, jargon mechanism design, budget balance key requirement problem. well-documentedliterature VCG-type mechanisms guarantee budget balance (Green & Laffont, 1977;Hurwicz, 1975)2 impossible design mechanism achieves three properties,namely, efficiency, budget balance strategy-proofness. problem, addition budgetbalance, allocation efficiency also desired social goal. algorithm achieves budget balance (Lemma 2) allocation efficiency (Theorem 3). Although algorithm cannot guaranteestrategy-proofness, due impossibility results, prove manipulation strategy existsdominates truth reporting (Theorem 5).3. Problem Formulationmodel, consumer group consists N members planning period divideddiscrete time slots. number discrete time slots depends market price structure,differ depending utility companies. example, = 2 time-of-use pricingdifferent prices day night, whereas = 24 hourly time use pricing. LetR N matrix row matrix, ri electricity demand agent i,2. fact, shown Ausubel Milgrom (2006), context broadcast spectrum allocation,revenue obtained VCG-type mechanisms even zero! case, would mean agents wouldpay money coordinator, making impossible pay supplier.890fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT20Twolevel Threshold Rate1312high load119low load76540high load(Price: 10.34 Cents/kWh)16141210threshold hjTotal CostMarginal price pM(j)j108Twolevel Threshold Rate18(Dollars)(Cents/kWh)148low load(Price: 6.9 Cents/kWh)threshold hj64250100Aggregated demand j15000200(kWh)(a) Marginal electricity prices.50100Aggregated demand j150200(kWh)(b) Total electricity cost.Figure 1: Sample two-level increasing threshold pricing model used BC Hydro{1, 2, . . . , N }. call ri demand profile agent i. entry rij electricity demandPagent time slot j. total aggregated demand time slot j j = Ni=1 rij . averagemarket price unit electricity consumer group time slot j defined pj (j ).assume typical market price function, prices different time slotprice threshold structure. means marginal electricity prices differ among different demand levels. time slot, every unit electricity consumed specified pricethreshold charged lower price, additional unit exceeding threshold chargedhigher price. Thus, marginal electricity price time slot, denoted pmj (j ), nondecreasing function total demand. marginal price given demand level paymentincrement (decrement) adding (reducing) one unit electricity. Figure 1a shows exampletwo-level increasing threshold pricing model adopted BC Hydro.3 The(marginal pricepHj > hjjtwo-level threshold structure formally written follows: pm()=jjLp j j hjL+pHj > pj , hj price threshold time slot j. Let x denote positive value termx, i.e., x+ = max {0, x}, x denote negative value respectively, i.e., x = min {0, x}.total energy cost time slot j thus integral marginal prices. Figure 1b shows totalelectricity cost aggregated demand based two-level threshold pricing model. totalelectricity cost computed as:+LLpj (j ) j = pHj (j hj ) + pj (j hj ) + pj hj(1)demand profile agent ri must satisfy individual constraints. overall demandconsists two types loads: shiftable loads non-shiftable loads. Mohsenian-Rad et al. (2010),Mohsenian-Rad Leon-Garcia (2010) Wu et al. (2012) model demand constraintsshiftable non-shiftable loads. example non-shiftable loads typically refrigerator3. BC Hydro Canadian utility company. pricing model obtained www.bchydro.com.891fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAshiftable loads include dishwasher, electric vehicles, washer/dryer, etc. appliances modeledtotal demand required course planning horizon, upper lower boundsdemand time slot well earliest start latest end times. constraints formconvex set. problem, Palso assume total demand agent wholeplanning period fixed, i.e.,j=1 rij = , total demand agent i. Further,also consider loads, demand constraints form convex set denote Xi .constraint set private knowledge agent share it, neither firmscoordinator. application scenarios, agent determines energy demand profile,consider additional costs associated demand schedule. example, givenfactory energy commonly used production. Changing energy demand schedule,therefore, may mean changing production process and, thereby, production cost. agent i,cost denoted gi (ri ). assume cost function convex. overall cost functionPagentj=1 pj (j ) rij + gi (ri ).objective minimize sum agents costs, overall energy allocation problem written as:PPN PMpj (j )rij + Nmin C (R) :=i=1 gi (ri )i=1j=1PM(2)s.t. ri Xi , j=1 rij = .energy allocations rij optimization variables R matrix demandprofiles agents. Note problem defined convexXi . AlthoughP setPobjective function non-linear, convex following. First, Nj=1 pj (j ) rij =i=1PMj=1 pj (j ) j convex non-decreasing j indicated Equation 1. TogetherPMPNj =j=1 pj (j ) j convex rij , i, j, (Boyd & Vandeni=1 rij , concludeberghe, 2004). Since gi (ri ) also convex, total cost function C (R) summation convexfunctions also convex. Thus, Problem 2 convex minimization problem.4. Solution ApproachAlthough Problem 2 convex optimization problem, since constraints preferencesagents private knowledge, optimal demand profiles cannot computed directlycentral coordinator. objective function, although sum individual costs agent,coupled, price electricity time slot j depends aggregated demandagents j . However, since constraints Problem 2 agent-specific, naturallyseparable. Therefore, primal decomposition approach (Bertsekas & Tsitsiklis, 1989) usedsolve problem sub-problems correspond agent optimizing energycost subject individual constraints. central coordinator compute appropriateinformation sent agents guide demand pattern towards time slots lowerprices (this corresponds master problem primal decomposition methods).Since agents know electricity market prices, individually optimize demandaccording prices. Let resulting demand profile called uncoordinated demandprofile. Figure 2a depicts aggregated uncoordinated demand profile setting threetime slots. seen aggregated demand time slot 2 threshold, 2 > h2 ,aggregated demand time slots 1 3 below, 1 < h1 , 3 < h3 . Thus, shiftdemand time slot 2 time slots would reduce total cost group. However,since agents dont know demand agents, cannot shift demand.intuitive solution approach, coordinator, coordinate demand would inform892fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT21.5Thresholdh2High priceLow price1h13110.50h33312.5h12High priceThreshold3h31.5210.512Time slot j30Aggregated demand3.5h2Low price(c) Coordinated Scenario4Aggregated demand3.5232.5(b) Herding Scenario42Aggregated demand jAggregated demand jAggregated demandAggregated demand j(a) Initial Scenario43.5Threshold322.521.5High pricehLow price 11h23h310.512Time slot j3012Time slot j3Figure 2: comparison demand profiles Uncoordinated, Herding Coordinated scenarios.agents aggregated demand time slot. Knowing market price, agents couldsolve individual optimization problems. approach problematic, agentsdont know demand constraints preferences agents group, costsstrongly depend demand agents. example, agents knowing marketprice current aggregated demand could shift much demand possible supposedlycheap time slot. would lead load synchronization, herding phenomenon, agentsshift demand supposedly cheap time slot, resulting new demand peak time slotthus increasing total cost. effect herding phenomenon shown Figure 2b,much demand shifted time slot 2 resulting demand thresholdtime slots 1 3. Thus, key challenge design information coordinator sendsagents, virtual price signal, enable system minimize overall cost.virtual price signal final price agents pay, informationwould pay, given current aggregated demand. virtual price signal enablesagents foresee possible price increment/reduction caused demand shifting. Therefore, virtual price signal agent time slot j, svij (rij |R), function variable rij ,denoting new demand agent time slot j. price signal computed based previous aggregate demand profile R, therefore included price function. easereadability, time made explicit notation used proofs. superscript v indicates virtual price, contrast real market prices pj (j ). design virtualprice signal, coordinator first computes amount demand ideally shiftedtime slot. shown Figure (2a), amount, denoted j , j = 1, 2, 3, differencetotal aggregated demand price threshold time slot. readability,refer j delta increment, noting delta could negative values, i.e., coulddecrement. avoid herding, delta increment needs divided among agentsthreshold price signal needs designed agent, price thresholdlower price threshold. serves penalize total demand time slot going threshold. Thus, agents know maximum amount demand could shiftprices solve individual optimization problem. exact calculation pricesignal svij (rij |R) shown Section 4.1.2. Given price signal, virtual cost optimizationproblem agent solvesPvmin Cvi (ri |R) := minj=1 sij (rij |R) rij + gi (ri )P(3)s.t. ri Xi , j=1 rij = .Note problem, like overall problem, convex optimization problem thus solvable. However, individual constraints cost functions, agents mightable shift much demand assigned means virtual price signal.893fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAimplies aggregated demand shift less amount could achieved.Figure 2c shows case, total demand second time slot remains threshold, whole 2 could shifted. order shift remaining demand, anotherprice signal, dividing remaining amount, would necessary. motivates us designiterative algorithm coordinator update virtual price signal based consumersfeedback thus gradually adjust individual demands central optimal solution.4.1 Basic Coordination Algorithmpresent basic coordination algorithm details virtual price signal designenergy allocation setting planning horizon two time slots, = 2, costshifting demand, g() = 0. Although called basic setting paper, setting practicalrelevance, represents commonly used Time Use pricing schemes divideplanning horizon two time slots (Albadi & El-Saadany, 2007). One time slot typically highload high prices one time slot typically low load low prices electricity.4.1.1 OVERVIEW LGORITHMRecall ri denotes demand profile agent R matrix demand profilesagents. Let r0i updated demand profile agent iteration R0 newdemand profile agents.Initialization: agent computes initial uncoordinated electricity demand profile risolving Problem 3 based market prices sends coordinator.1. coordinator adds individual demands determine aggregated demand jtime slot j calculates delta increment j demand shiftedtime slot. Finally, coordinator divides demand among agents computesvirtual price signals svij (rij |R) agent time slot j.2. coordinator sends virtual price signals agents.3. receiving virtual price signal, agent individually calculate new demandprofiles r0i according optimization Problem 3.4. agents send new demand profiles back coordinator.5. coordinator compares new demand profiles old profiles. agent changeddemand profile, i.e., R = R0 , coordinator stops algorithm. Otherwise, sets R = R0goes step (1).4.1.2 C OORDINATION V IRTUAL P RICE IGNALvirtual price signal one agent one time slot threshold price function demandtime slot. demand specified threshold charged low price demandthreshold charged higher price. virtual price signal therefore parameterizedHlow marginal price, pLj , high marginal price, pj , price threshold, hij (R),specifies demand levels prices apply. virtual price, svij , agent time slot jcomputed based parameters follows( pL h (R)+pH (r h (R))ijijj ijjrij > hij (R)rijsvij (rij |R) =(4)Lpjrij hij (R)894fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTAggregated demand iteration1.75Agent 1 demand r1j43.5222.5h222j10.5010.750.50.251.751112h121r11h111112Time slot jh11.5r121.51.250Agent 2 demand rAggregated demand j3Agent 1 demand local optimizationr221.51.251h210.750.50.2522h2221r2102Time slot jAgent 2 demand local optimization12Time slot jFigure 3: Division j among agents virtual price signal. yellow demand belongsagent 1 red demand agent 2. 1 amount demand shiftedtime slot 1, 2 indicates amount demand needs shifted time slot 2.Agent 1 demand local optimization1.5r1.25h13.512120.750.50.253h11r11012Time slot jAgent 2 demand local optimization2j1.75Agent 2 demand rAggregated demand iteration41.51.2510.750.5h21r21h22Aggregated demand jAgent 1 demand r1j1.75r222.5h221.52h1110.50.250102Time slot j1Time slot j2Figure 4: Demand agents local optimization. Agent 1 cannot reduce entire demandtime slot 2 (i.e., r12 > h12 ), demand constraints (left top plot). Thus,aggregated demand time slot 1 still threshold (i.e., 01 < h1 ). Therefore, centralcoordinator sends modified price signal agents algorithm continuesagents stop shifting demands.895fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARALvAlthough prices pHj pj derived market prices, sij called virtual pricesignal, threshold hij (R) changes, agents change demand profiles.coordinator chooses hij (R) < rij induce agents reduce demand hij (R) > rijincrease demand one time slot. ij amount coordinator wants agent changedemand time slot j, threshold hij (R) updated based demand profiles submittedlast iteration:hij (R) = rij + ij(5)Thus, agents know that, current market price, change demandtime slot j ij . demand exceeding hij (R), need pay higher price.demand, j , coordinator wants change time slot j calculated differencecurrent aggregated demand threshold market price:j = hj j(6)Since coordinatorwants total demand change agents less j ,Pensure ij j . allowable shift agent proportional agents shareraggregated demand time slot, i.e., ij = Pj rijij . Figure 3 shows total demandchange divided among agents order create individual virtual price signals. leftside shows initial aggregated demand two agents. yellow demand belongs agent 1red demand agent 2. Since aggregated demand threshold time slot 1 (i.e.,1 < h1 ) threshold time slot 2 (i.e., 2 > h2 ), coordinator wants agentsshift demand time slot 2 time slot 1. amount demand shifted timeslot 1 1 , 2 amount demand shifted time slot 2. rightside shows individual thresholds agents determined central coordinator usingprocedure described above. allocation demand change agents illustrateddashed arrows. current demand agent 1 time slot 1 r11 threshold time slot1 h11 (the notations interpreted similarly).4.1.3 AGENT R ESPONSE V IRTUAL P RICE IGNALreceived virtual price signal, agents independently optimize demand profiles order minimize cost according Problem 3. agents objective function Cvi (ri |R)Pv=j=1 sij (rij |R) rij + gi (ri ) written as:Cvi(ri |R) =X+LLpHj (rij hij (R)) + pj (rij hij (R)) + pj hij (R) + gi (ri )(7)j=1Since agents pay high price pHj demand exceeding individual threshold,agent shift much demand, based false impression possible cost reduction. Figure 4 shows agents demand profiles individual optimization. left side showsindividual problems agents, optimized demand profile. comparisonright side Figure 3, seen agent 2 shifted whole allocated amount, agent 1shifted part (e.g., due constraints). right side Figure 4 shows centralproblem agents individual optimization. seen still demand leftshifted time slot 2 time slot 1. remaining demand would divided amongagents subsequent iteration.896fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT4.1.4 PAYMENT RULEalgorithm converged, agents pay virtual unit price demandtime slot. last iteration virtual unit price equals average unit price aggregate demand whole cooperative, agent changed demand profile, Equation 9.R final demand profiles whole cooperative ri final demand profile agent i,payment agent givenpaymenti =Xsvij (rij |R) rij(8)j=14.2 Convergence Basic Algorithmsection prove basic iterative procedure always converges optimal solutionLbasic setting = 2, gi () = 0 pHj > pk , j, k. Lemma 1, showalgorithm strictly reduces cost every iteration. fact used Theorem 1 showalgorithm always converges. Then, Theorem 2 show that, = 2, gi () = 0LpHj > pk , j, k, converged solution optimal solution. Subsequently, showalgorithm get stuck suboptimal solution general settings > 2 (Lemma 3)gi () 6= 0 (Lemma 4).Lemma 1. algorithm strictly reduces total cost every iteration: C (R0 ) < C (R).Proof. Lets first introduce notation used throughout proof. Let R totaldemand profile end iteration round R0 total demand profile end round+ 1. Similarly, let C(R) total cost end iteration C(R0 ) total costend iteration + 1. virtual prices round + 1 computed central coordinatorusing R. Let Cvi (ri |R) cost agent computed according virtual price signaldemands beginning round + 1 Cvi (r0i |R) end round + 1.beginning iteration total cost consumer group based market prices(given objective function Problem 2) equals sum individual cost agentsPvbased virtual price signals (given Problem 3), i.e., Ni=1 Ci (ri |R) = C (R):N XXsvij(rij |R) rij +gi (ri )i=1i=1 j=1N XXNX"+(hj j ) rijP=rij rij +riji=1 j=1(hj j ) rijP+ pLrr+ijijjrij# XN(hj j ) rijLP+ pj rij ++gi (ri )riji=1=pHjhNXX+LLpH(h)+p(h)+ph+gi (ri )jjjjjjjjj=1=(9)N XXi=1 j=1i=1pj (j ) rij +NXgi (ri )i=1897fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAalgorithm stopped, least one agent changed demand profile, i.e.,r0i 6= ri . Agents change demand profile, reduces cost according Problem 3.Thus, given virtual price, signal agent cost new demand profile r0i strictly lowerprevious demand profile ri :Cvi r0i |R < Cvi (ri |R)(10)agentssubmitted new demand profile, new aggregated demand comPN00puted as: j = i=1 rij . Next, show sum agents individual cost accordingvirtual price signals upper bound total central cost market prices. Thus, total cost,based new aggregated demand, lower equal sum agents individual cost,based new demand. fact important, prevents herding behavior:solution reduces cost agents individual problems lead worse solutioncentral problem. proved showing Equations 1 7 every time slot jdifference central cost aggregated demand sum agents individualcost less equal 0. following sketch proof omitting algebraic stepsease readability. Consult Appendix complete proof. time slot, j,NXNX000pj 0j rijsvij rij|R riji=1i=1(PN=0rijhij (R) 0j0HpLrij hij (R) 0jj pj0LpHprh(R)0ijjjij+H0pLrijhij (R)0j pji: r 0 hPN ij ij0 >hi: rijijhPNi=1= hPNi=1LpHj pj> hjhj(11)0j > hj0j hjPN v 00 j, also holds sum time slots:00Since i=1 pj j rij i=1 sij rij |R rijPv0C (R0 ) Ni=1 Ci (ri |R).Equations 9, 10 11 conclude that:PNNNXXC R0Cvi r0i |R <Cvi (ri |R) = C (R)i=1(12)i=1Thus, total cost strictly reduced iteration.Theorem 1. basic iterative algorithm solving Problem 2 always converges.Proof. definition Problem 2 convex lower bound total costobtained sum individual initial demand profile costs market prices. Lemma1 algorithm reduces total cost iteration. Thus, concludedalgorithm converges.PPN vNLemma 2. real market cost, Ni=1 pj i=1 rij rij , equals virtual costi=1 sij (rij |R) rijtime slot j, either i, rij hij (R) i, rij hij (R).Proof. i, rij hij (R), j hj first case Equation 11 follows costequal. i, rij hij (R), j hj second case Equation 11 follows costequal.898fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTTheorem 2. solution R basic algorithm optimal, either following casesA) j, R satisfies j 6= hj restrictions gi ()B) R satisfies j, s.t. j = hj = 2, gi () = 0 high price time slotLgreater low price time slot, i.e., pHj > pk , j, kProof. prove contradiction algorithm converged solution Rsatisfies Case A, solution R0 lower cost. Suppose exists solutionR0 , i.e., C(R0 ) < C(R). show contradicts convergence conditionsalgorithm i, ri solution agents individual problem, ri = arg minxi Xi Cvi (xi |R).Denote R# () = R+(1 ) R0 , (0, 1), linear combination R R0 . Since centralcost function convex C(R0 ) < C(R), also C(R# ()) < C(R). j, R satisfiesj 6= hj , demand beginning iteration rij j either i, rij > hij (R)i, rij < hij (R), j > 0 i, ij > 0 similarly j < 0 i, ij < 0.##follows, (0, 1), s.t. j, either i, rij() hij (R) i, rij(1 ) hij (R).PN#v= C(R# ()). Moreover,Therefore, Lemma 2,i=1 Ci ri () |RPvC(R# ()) < C(R) Equation 9 also Ni=1 Ci (ri |R) = C(R). follows,vvi, s.t. Cvi r#() |R < Ci (ri |R), conflicts ri = arg minxi Xi Ci (xi |R), i.e., risolution agents individual Problem.prove contradiction algorithm converged solution R satisfiesCase B, solution R0 lower cost. Assume exists solution R0C(R0 ) < C(R). Let 2 time slots {j, k}, 0j < j 0k > k (without lossgenerality). Note pmj (j ) > pk (k ), otherwise new cost would lower.HLj = hj , k = hk pmj (j ) = pj (as j decreases) pk (k ) = pk (as k increases).Lmarket price structure pHk > pj . follows pj (j ) < pk (k ), leadsLHcontradiction. j 6= hj , k = hk j < hj pj (j ) = pj pmk (k ) = pk thusHHHHpmj (j ) < pk (k ). j > hj pj (j ) = pj pk (k ) = pk . pk > pj ,otherwise shift j k would beneficial least one agent algorithm wouldstopped. follows pmj (j ) < pk (k ), leads contradiction. casej = hj , k 6= hk works similarly.follows R optimal solution, solution lower cost exists. Thus, proposed iterative algorithm converges optimal solution. Since problem convex solution also global optimal solution (Boyd & Vandenberghe, 2004).Lemma 3. basic algorithm could converge suboptimal solution R settings, Rsatisfies j, s.t. j = hj , > 2 gi () = 0.Proof. prove presenting counterexample basic algorithm convergesuboptimal solution settings, R satisfies j, s.t. j = hj , > 2 gi () = 0. Considerpopulation 2 agents, N = 2, planning horizon 3 time slots, = 3. agentsconstraints form converged solution aggregated demandthreshold one time slot, directly threshold another time slot one time slotthreshold.Let price function three time slots given as:HL HL H(pL1 , p1 ) = (3, 6), h1 = 10; (p2 , p2 ) = (2, 5), h2 = 10; (p3 , p3 ) = (1, 4), h3 = 10;899fi86p1H=6p2H=5p3H=4p1L=3p2L=2p3L=1(KWh)10demand agent 1demand agent 1(KWh)V EIT, X U , Z HENG , C HAKRABORTY, & YCARA42012310864201(KWh)10864201223time slotdemand agent 2demand agent 2(KWh)time slot3time slot1086420123time slot(b) Optimal Solution R0(a) Converged Solution R(T )Figure 5: Converged Optimal solution example Lemma 3. top row showsdemand agent 1 bottom row demand agent 2. dashed lines indicate upperlower bounds demands agents time slot. solid black lines show pricethresholds time slot.individual constraints agents demand are: (a) upper lower bounds demandtime slot (b) constant total demand time slots. Specifically,r11 [1, 4], r12 [1, 9], r13 [1, 9], r11 + r12 + r13 = 1 = 17r21 [1, 9], r22 [1, 9], r23 [8, 9], r21 + r22 + r23 = 2 = 17Let R(t) denote demand profile agents tth iteration let = 1 initialiteration = final iteration convergence. beginning agents compute(1)(1)initial demand profiles based marketprices r1 = (1, 7, 9), r2 = (1, 7, 9). cost basedinitial demand profiles C R(1) = 88. convergence, profiles two agents(T )(T )r1 = (4, 5, 8), r2 = (4, 5, 8) (see Figure 5a graphical representation). cost baseddemand profiles C R(T ) = 78. However, different demand profile agents existsr01 = (4, 7, 6), r02 = (6, 3, 8) (see Figure 5b graphical representation). profilefeasible leads lower total cost, i.e., C (R0 ) = 76. follows algorithm stoppedsuboptimal solution.Lemma 4. basic algorithm could converge suboptimal solution R settings, Rsatisfies j, s.t. j = hj , = 2 gi () 6= 0.Proof. Appendix B counterexample presented, proving basic algorithm convergesuboptimal solution settings, R satisfies j, s.t. j = hj , = 2 gi () 6= 0.900fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT5. General Coordination Algorithmprevious sections introduced basic iterative coordination algorithm optimal energyallocation basic setting planning horizon two time slots, = 2, costshifting demand, g() = 0. Moreover, presented counter examples showing that, generalsettings > 2 g() 6= 0, algorithm get stuck suboptimal solution.section, present general coordination algorithm energy allocation general settingstwo time slots non-zero individual costs shifting demand.5.1 Additional Phasereason convergence suboptimal solution coordinator cannot determineagents marginal valuation demand, aggregated demand time slotthreshold. agents might different marginal valuations, shift agentlower valuation agent higher valuation might beneficial. However, opportunityimprovement cannot realized, coordinator know marginal valuationsagents.introduce additional phase algorithm address problem. basicalgorithm converged, coordinator checks whether aggregated demand thresholdleast one time slot. case, algorithm stops solution optimal.However, demand threshold time slot, coordinator initiates another phase.basic idea that, besides virtual price signal, coordinator sends additional queryagents, requesting valuations -increase -decrease threshold timeslots, aggregated demand threshold. Then, coordinator uses informationadjust virtual price signals.+Let vijdenote value agent -increase threshold time slot j. Letij+Rdemand profile, resulting price signal agenttime slotthresholdj+vij+ij+virtual cost,j increased , i.e., hij (R ) = hij (R) + . Moreover, let Ci ri |Rthreshold time slot j increased .Definition 1. Agent marginal valuation -increase threshold time slot jdifference virtual cost original virtual problem virtual problem-increased threshold time slot j. valuation -decrease defined analogously.j+ij+0vijvij(R) = Cvi rj+|RCr|R;v(R)=Cr|RCi r0i |R .ij(13)agents receive virtual price signal query marginal valuations,first compute optimal demand profile r0i , based price signal. Second, compute+marginal valuations vij(R) vij(R) every time slot, aggregated demand+threshold. Let vector vi consist valuations -increments vi decrementsrespectively. Finally, agents send ri , vi+ vi back coordinator.received agents information, coordinator computes virtual price signalsnext iteration. aggregated demand thenthreshold,finds agents lowest+cost -increase threshold: l = arg mini vij lowest cost -decreasen+threshold: k = arg mini vij. combined cost negative vkj+ vlj< 0, beneficial shift901fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAagent l agent k exists. case, coordinator updates thresholds agents l, klj = , kj = .algorithm stops, demand threshold time slot time slots+thresholds pair {l, k} exists vkj+ vlj< 0. follows, algorithm converges,every time slot aggregated demand threshold, j = hj , agents, costreduction -increase threshold less additional cost -decreasethreshold agents, i.e.,+vljvkj, l, k {1, ..., N } j s.t. j = hj .(14)Otherwise, coordinator would change price signals algorithm would stop.5.2 General Algorithmgeneral algorithm designed iterative algorithm, coordinator updates virtualprice signals based consumers feedback thus gradually adjusts individual demandscentral optimal solution. overall algorithm shown Algorithm 1. iterationconsists two steps: First, central coordinator aggregates demand submitted agentscomputes virtual price signals agent. virtual price signals computedsubroutine CalculateVirtualPriceSignals (Algorithm 2). Second, individual agents usevirtual price signal solve individual cost optimization problem compute marginalvaluation electricity demand report coordinator. agents responsecomputed CalculateDemandProfileAndValuation (Algorithm 3).general algorithm first runs basic algorithm convergence subsequentlyperforms additional phase, necessary. particular, additional phase performed, basic algorithm converged (Algorithm 1 line 8) least one time slot aggregated demandthreshold (Algorithm 1 line 9). algorithm reaches optimal solution R =+R0 either j 6= hj , j additional phase vljvkj, l, k {1, ..., N }, j s.t. j = hj .5.3 Convergence General Algorithm -optimal SolutionPlease note Theorem 1 still holds general algorithm, algorithm still reducestotal cost iteration. Thus, extended algorithm converges. Theorem 3 provesolution general algorithm lies within -neighborhood optimal solution.Theorem 3. converged solution R general algorithm lies within neighborhoodoptimal solution R , amount agents compute marginal valuations.Proof. prove contradiction general algorithm converged solution R, solution R0 exists lower cost respect central Problem 2outside -neighborhood around R. Suppose exists solution R0 lower total energy cost R, i.e., C(R0 ) < C(R). show contradicts convergenceconditions general algorithm i, ri solution agents individual problem,+ri = arg minxi Xi Cvi (xi |R), vljvkj, l, k {1, ..., N } j s.t. j = hj .case left Theorem 2 j, j = hj , implies i, rij = hij (R),fififi0 > h (R) k K, r 0 < h (R), l, k s.t. r 0 r fiL, K 6= , s.t. l L, rljfi ljljkjlj fikjfififi 0fi, firkjrkj fi . show case conflicts convergence conditions, too.902fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTAlgorithm 1: Overall algorithm.Data: Scenario electricity contract agent definitions.Result: Optimal demand schedule R .123456789101112131415161718192021Initialization: agents compute initial energy demand profile ri solving Problem 3based market prices send coordinator.;addP hase = f alse;demand schedule R optimalCoordinator calculates price signals using Algorithm 2:svij (rij |R) , i, j CalculateVirtualPriceSignals (ri , vi+ , vi , addP hase);coordinator sends virtual price signals agents;Agents calculate demand profiles valuations time slots, j, using Algorithm 3:i: r0i , vi+ , vi CalculateDemandProfileAndValuation (svij (rij |R), addP hase);agents send new demand profiles valuations back coordinator;algorithm converged, i.e., R = R0j 6= hj , jdemand schedule R0 optimal;else+addP hase vljvkj, l, k {1, ..., N }, j s.t. j = hjdemand schedule R0 optimal;elsestart additional phase, i.e., addP hase = true;endendelseR R0 ;endendfifififi #() rlj fi =start case |L| = |K| = 1. (0, 1), s.t. firljfififi #fifirkj () rkj fi = . Moreover, denote R## () s.t.,##rit() =#rit() L K, = jritotherwisedemand profile reflecting changes demand time slot j resulting individ##ual problems agents demand threshold, rlj= hlj (R## ) rkj=##hkj (R ). Thus, Lemma 2 get sum virtual cost equal central cost.NX##vv####Cvi r#()|R+Cr()|R()+Cr()|R()lklki=1,i6=l,k=C(R# ()) < C(R) =NXCvi (ri |R)i=1903fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAAlgorithm 2: Calculation virtual price signal coordinator.1234CalculateVirtualPriceSignals (ri , vi+ , vi , addP hase);Data: demand profiles valuations agents, ri vi+ , vi , i.Result: virtual price signals agents, svij (rij |R) , i, j.PCompute aggregated demand: j Ni=1 rij ;Compute demand shifted time slot: j hj j ;rDivide demand among agents: ij Pj rijij ;567891011addP hasen+Find time slot j agents l, k s.t. min vljvkj;+vlj+ vkj< 0Adapt demand shifted agent l: lj agent k: kj ;endendCompute thresholds based demands shifted: hij rij + ij ;Algorithm 3: Calculation individual demand profiles marginal valuation energyagent i.1 CalculateDemandProfileAndValuation (svij (rij |R), addP hase);Data: virtual price signal svij (rij |R), j = 1, . . . , .Result: new demand profile r0i valuations vi+ , vi .2345678Compute new demand profile r0i according virtual price signal:ri = arg minxi Xi Cvi (xi |R);addP haseforeach time slot j threshold, rij = hij+ij+ Cv (r0 |R);Compute valuation increased threshold: vijCvi rj+|Rij Cv (r0 |R);Compute valuation decreased threshold: vijCvi rj|Rendendimplies eitherNXCvi r#() |R <i=1,i6=l,kNXCvi (ri |R)i=1,i6=l,kvi, s.t. Cvi r#() |R < Ci (ri |R)conflicts convergence condition ri = arg minxi Xi Cvi (xi |R);#v####Cvl r#()|R()+Cr()|R()< Cvl (rl |R) + Cvk (rk |R)klkh####Cvl r#() Cvl (rl |R) < Cvk r#() Cvk (rk |R)l () |Rk () |R904fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTfififi #fi## () equal Cv rj+ |Rij+firkj() rkj fi = get Cvl r#()|Rlll## () equal Cv rj |Rij . Thus, Equation 13 followsCvk r#kk () |Rk+vlj(R) < vkj(R)+conflicts convergence condition, l, k {1, 2, , N }, vlj(R) vkj(R).general case |L| , |K| 1, getNXXX####()() +Cvk r#Cvl r#Cvi r#() |R +k () |Rl () |Ri=1,iLK/=kKC(R# ()) < C(R) =NXCvi (ri |R)i=1implies eitherNXi=1,iLK/i, s.t. CviNXCvi r#()|R<Cvi (ri |R)i=1,iLK/r#() |R <Cvi(ri |R)conflicts convergence condition ri = arg minxi Xi Cvi (xi |R);XXXX#v####Cvk (rk |R)Cvl r#()|R()+Cr()|R()<Cvl (rl |R) +klkXkKCvlkK"#XXX####r#()Cvl (rl |R) <Cvk r#()Cvk (rk |R)l () |Rk () |RkKkKSince amount demand increased time slot j equal demand decreased, costdecrease LHS greater increase cost RHS, exists pair agents,l, k marginal cost decrease l larger marginal cost increase k+l L, k K, vlj(R) < vkj(R)+conflicts convergence condition, l, k {1, 2, , N }, vlj(R) vkj(R).solution R lies within neighborhood optimal solution R , amountagents compute marginal valuations. beneficial shift size greaterequal exists more, algorithm stops. However, beneficial shift smaller mightstill exist.5.4 Convergence Time Algorithmsection, give upper bound number steps algorithm needs converge.First, give bound basic algorithm Lemma 5 extended phase Lemma 6.Second, give bound general algorithm Theorem 4.905fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARALemma 5. basic algorithm converges within maximum log N e steps, Nnumber agents distance converged solution optimal solution basicalgorithm.Proof. prove showing upper bound number iterations needed one timeslot, say, time slot j, get initial demand level neighborhood optimaldemand level basic algorithm. sufficient, demand last timeslot reached optimal level, demand time slots also reached optimal level.proof consider time slot initial demand optimal demand.sufficient, every shift consists demand decrease least one time slot alsoincrease least one time slot. Thus, time slots optimal demandlevel, reached optimal level, remaining time slots also reached optimal levels.Since variables proof time slot j, omit subscript j increased readability. Let Dt difference optimal aggregated demand aggregated demanditeration t. Since demand assumed optimal demand, Dt > 0. Withoutloss generality, assume initial value Dt 1 (D0 = 1) optimum 0;agent i, initial demand rij = 1. worst case one agent (e.g., agent 1) increasedemand. case, agent 1 increase demand iteration, incrementequals amount demand shift assigned coordinator.denote increment agent 1s demand iteration ct agent 1s demanditeration (c0 = 1). N denoting total number agents, demand shift assignedragent given based definition price signal ij = PNj ij . Then,i=1 rijagent 1s incrementct1 Dt1.(15)N 1 + ct1Agent 1s demand iteration initial demand plus increments first iterations.Similarly, difference Dt initial difference minus agent 1s increments.=ct = 1 +Xal , Dt = 1l=1Xal = ct ct1 = Dt + Dt1 , ct = 2 Dt .l=1substituting Equation 15,(2 Dt1 ) Dt1N + 1 Dt12= 2Dt1 Dt1(N 1) Dt1=N + 1 Dt1Dt + Dt1 =2(N + 1) (Dt + Dt1 ) + Dt Dt1 Dt1DtSince n 1, Dt (0, 1), get(N 1) Dt1N 1 nDt <Dt <NNllogThus, > 0, = loglogN1 = log Nlog(N 1) , s.t., > , Dt < . Moreover,Nsince logarithm strictly increasing concave, log N log (N 1) >> 0, = log N e, s.t., > , Dt < .9061N.Thus,fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTLemma 6. extended phase converges maximum within number0l(C0 C )vsteps,C total cost solution basic algorithm, C total cost optimalsolution v minimum value marginal valuations -increase decreasethreshold one time slot.Proof. prove showing upper bound number iterations needed reducetotal cost solution basic algorithm, i.e., C0 , total cost optimalsolution, i.e., C . iteration extended phase, thresholds adapted two agents,+say k, j. Thus, total cost reduced vkj+ vlj(Equation 13). Let v minimum value+vkj + vlj . Then, long algorithm converge, iteration, total costl 0reduced least v . Thus, algorithm stops within (C vC ) steps.Theorem 4. time complexity general algorithm lies O(N + (C0 -C )), i.e., algorithm linear number agents pseudopolynomial (C 0 C ).Proof. Lemma 5 get upper bound number iterations basic algorithmdN log e. log constant, independent N , time complexitybasic algorithm O(Nl 0 ).Lemma 6 get upper bound number iterations(C C )extended phase. cost difference (C0 C ) depend N ,vspecific characteristics agents. minimum valuation v proportional sizethreshold increment/decrement . Thus v constant constant choice . Thus,bound extended phase pseudopolynomial (C0 C ).5.5 Incentive Compatibilitygeneral, allocation problems, three key properties interest, namely, efficiency,strategy-proofness, budget-balance. context problem, efficiency impliesoverall electricity consumption cost minimized. Strategy-proofness implies telling truthdominant strategy agents hence report truthfully. Budget-balance impliestotal amount paid members cooperative equal actual electricity consumption cost. two well known facts three properties literature: First,allocation efficient, way implement payments guarantee strategy-proofnessuse VCG-type mechanisms, see work Green Laffont (1977), Hurwicz (1975). Second, Green Laffont (1977) Hurwicz (1975) also prove, payments obtained VCG-typemechanisms cannot achieve budget balance. Thus, impossible design mechanismachieves three properties, namely, efficiency, budget balance strategy-proofness.stated discussion related work section, budget balance key requirement problem application point view. Furthermore, allocation efficiency desired social goal. algorithm achieves budget balance (Lemma 2) allocation efficiency(Theorem 3). Therefore, impossibility results, cannot achieve strategy-proofness, i.e.,truth telling cannot dominant strategy. However, believe agent may choose truthfully respond, agents cannot anticipate future development algorithm and,prove below, manipulation strategy exists dominates truth reporting. Therefore, definenotion weak incentive compatibility.Definition 2. algorithm satisfies weak incentive compatibility weakly incentive compatible,strategy dominates telling truth algorithm.907fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARATheorem 5. general algorithm weakly incentive compatible.Proof. algorithm agents two possible ways deviate truthful reporting: First,could report demand profile minimize individual cost accordingcurrent virtual price signals intent misreporting would benefit finalpayment. Second, could report marginal valuations differ true marginal valuations. analysis assume rational agents, i.e., agents always prefer lower cost.Note payment rule (Equation 8) agent pays electricity demand basedfinal price signal. iteration, truthful demand report minimizes agents cost givenprice signal. Therefore, agent report truthfully final price signal (i.e., finaliteration) incur higher cost. Furthermore, agents know whether given pricesignal final price signal not. is, agents limited knowledgeknow demand profiles agents constraints preferences. Thus, manipulationiteration may result higher cost truthful report. Therefore, manipulation strategyinvolving misreported demand profiles dominates truthful reporting.Regarding reporting marginal valuations (Definition 1), obvious deflatingvaluation hurts agent. demonstrate extension example Lemma 3,deviating truth revelation inflating reported marginal valuation also hurtagent. aggregated demand threshold time slot 2 coordinator asksagents valuations -increase threshold. Without loss generality assume = 1.+L= pHAgent 1s true valuation (reduce time slot 3 increase 2) v123 p2 = 2 agent 2s+L(reduce time slot 1 increase 2) v22 = pH1 p2 = 1. Lets assume agent 2 misreports+valuation v22 > 2. Then, coordinator increases threshold time slot 2 agent 2decreases threshold agent 1. follows agent 1 shift demand time slot 2time slot 3 agent 2 shift demand time slot 1 time slot 2. leadsdemand profiles: rdeviate= (4, 4, 9), rdeviate= (3, 6, 8). However, profile12lead increase total cost, also increase individual cost deviatingagent 2. Table 1 shows individual cost.4 Since misreporting valuations may result higherelectricity cost truthful report misreporting agent, manipulation strategy involvingmisreported marginal valuations dominates truthful reporting.costtruthful reportsagent 2 deviatesagent 1s cost37.14340.118agent 2s cost38,85738.882total cost7679Table 1: Cost different demand profiles individual agents.6. Simulationperform simulations based real world consumption data (a) characterize convergenceproperties algorithm (b) understand effect different parameters characterizeelectricity demand profile cost reduction coordination algorithm.results show algorithm scales linearly number agents time slots. Further,observe participants flexibility shifting demands increases, cost reduction4. Since Agent 2s deviation increases agent 1s well agent 2s cost, one might argue increasingagents cost could also incentive deviation. However, note cost agent visible others.Therefore, believe agent may choose report truthfully.908fielectricity price (Euro cents/kWh)ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTdayaheadspot marketprice642024681012141618202224time slotFigure 6: Day-ahead spot market prices EPEX Spot average Tuesday 2013increases well cost reduction sensitive whether consumers useelectricity evening day.6.1 DatasetsCER Electricity Consumption Data: use real electricity consumption data generate consumer demand profiles. data gathered Irish Commission Energy Regulation(CER) context smart metering study. study, electricity consumption data485 small medium enterprises 4, 225 private households collected period1.5 years. observation period divided time intervals 30 minutes. One datapoint represents average electricity consumption kilowatts one participant 30minute interval. particular, used data 46 enterprises. participating enterprisesalso answered questionnaires about, among others, number employees typical hoursoperation. refer data set CER data set5 .EEX Electricity Prices Market Data: generate cooperatives electricity prices using realday-ahead market electricity prices, gathered European Energy Exchange (EEX),leading energy exchange Europe. particular, use average hourly day-aheadprices EPEX Spot market 20 Tuesdays January 1st 2013 May 14th 2013.Figure 6 shows average day-ahead spot market prices observation period. referhourly market price data EEX data set6 .6.2 Simulation Parametersmodel work Mohsenian-Rad et al. (2010), wePdefine agent predetermined total electricity demand planning horizon, =r , upper lowerh j=1 ijibounds electricity demand time slot, i.e., rij rij , rij . Regarding individual cost functions gi , assume gi = 0, data industry specific costfunctions.5. data set available http://www.ucd.ie/issda/data/commissionforenergyregulation/.6. data available http://www.eex.com/en/Market%20Data.909fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA6.2.1 ODELING C OMPOSITION C OOPERATIVES :Agents variety different demand characteristics. reflect diversity, useCER data set identify two classes consumers similar characteristics. groupconsumers similar characteristics, clustered participants study using k-meansclustering based information questionnaires electricity consumption data.particular, used consumption profiles Tuesdays, Tuesday averagework day. Here, Class 1 represents consumers consuming electricity day,whereas Class 2 represents consumers stable consumption day, higherconsumption night. Based classes, cooperatives varying compositions simulated. parameter p fracAgent defines composition cooperative specifyingfraction agents Class 1 (and Class 2 1 p f racAgent).6.2.2 G ENERATING N OMINAL EMAND AGENTS :agents nominal demand value around agent vary demand. simulatescenarios {12, 24, 48} time slots use time intervals 30, 60 120 minutes,generate interpolating averaging data points two data sets. Then, j = 1represents first j = last time slot day. get different agents, nominaldemand agent time slot outcome xij random variable XCj . Let Cjmean average demands participants class C time slot j let Cjcorrected sample standard deviationof averagedemands. Thenominal demand drawnuniform distribution XCj U Cj Cj , Cj + Cj . distributions XCjtwo Classesshown Figure 7. total demand agent whole day, computedPx=j=1 ij .6.2.3 ODELING F LEXIBILITY C ONSUMERS :Agents different flexibilities changing demand profiles. Here, ability expressed agents upper lower bound constraints electricity demandtime slot. parameter p flexShift defines flexibility agents specifying percentage, agents vary demands nominal demand. Thus,larger p f lexShif t, apart upper lower bounds. parameteragents fixed one scenario. Based flexibility nominal demand, upperlower bounds computedrij = xij (1 p f lexShif t)rij = xij (1 + p f lexShif t)(16)6.2.4 ODELING E LECTRICITY P RICE :cooperatives electricity price function time slot defined marginal priceHlow load, pLj , high load, pj , price threshold, hj , specifying demandlevels marginal prices apply. use prices EEX data set exemplar pricesHgenerate pLj pj . Let mpj average spot market price EPEX Spot time slot j.910fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT1414exemplarynominaldemand1012electricity demand (kW)electricity demand (kW)12distributionnominaldemand8641020864202468101214161820220240246time slot81012141618202224time slot(a) Class 1 - day consumer(b) Class 2 - night consumerFigure 7: Distributions nominal demand two different consumer classes.compute marginal electricity pricespLj = mpjpHj = mpj +maxx{1,...,M }{mpx }minx{1,...,M }(17){mpx }keep marginal prices fixed across simulations. However, price thresholds mayvary across different simulation scenarios. example, price threshold couldaggregated nominal demand demand increased coulddemand reduced. parameter p distThresh defines distanceaggregated nominal demand price thresholds specifying percentage thresholdsaggregated nominal demand. negative value p distT hresh,thresholds lie positive value lie aggregated nominal demand.scenario one fixed value time slots. Figure 8a illustrates scenariosdifferent values p distT hresh. addition, price thresholds could either differenttime slot (e.g., following profile aggregated nominal demand) couldtime slot (flat thresholds). Here, compute flat thresholds defining movingaverage aggregated nominal demand. parameter p flatThresh defines flatnessthreshold specifying width interval thresholds flattenedmoving average. p f latT hresh = 0 thresholds follow exactly aggregated nominaldemand, whereas p f latT hresh = thresholds every time slot. Figure 8billustrates scenarios different values p f latT hresh. thresholds computed1hj =1 + 2p f latT hreshj+p f latTX hreshjp f latT hresh!(1 + p distT hresh)Xxij(18)6.2.5 IMULATION CENARIOS :create different scenarios, vary input parameters follows: p f racAgent {0, 0.25, 0.5,0.75, 1}, p f lexShif {0.1, 0.2, 0.3}, p f latT hresh {0, 12, 24}, p distT hresh {0.2,911fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA500500valuesp_distThresh0.240000.13000.2200100004000.1aggregated demand (kW)aggregated demand (kW)valuesp_flatThresh6243002001000246810121416182022024time slot024681012141618202224time slot(a) Price thresholds different values p distT hresh. (b) Price thresholds different values p f latT hresh.Figure 8: Price thresholds different values parameters p distT hresh p f latT hresh.0.1, 0, 0.1, 0.2}, #agents {20, 40, 60, 80, 100}, {12, 24, 48} {0.5, 1, 2}.leads 3375 different scenarios. define algorithm converged, cost reductionone iteration gets less 0.00001%, i.e., C (R) / C (R0 ) < 1.0000001.6.3 Simulation Resultsfirst present effects different parameters cost reduction algorithmsubsequently discuss convergence time.Definition 3. cost reduction difference cost uncoordinated profile C0(chosen agent optimizing cost according market price)coordinatedprofile C percentage cost uncoordinated profile, i.e., CR = C0C0C 100.Figure 9 shows subset results p f racAgent {0, 0.5, 1}, = 24, #agents = 40= 1. Figure 9a shows cost reduction cooperatives consisting consumers mainlyconsuming electricity night. Figure 9b shows cost reductions cooperatives consistconsumer classes equal proportions. Finally, Figure 9c shows cost reductions cooperatives consisting consumers main demand day. x-axis representsflexibility shifting demand, y-axis flatness thresholds z-axis heightthresholds. figures scenarios high cost reduction (white) scenariosless cost reduction (dark red). scenarios, observed mean cost reduction 2.57%,results varying 0% 7.44%. However, sampled cases represent combinationsinput parameters cannot say realistic individual settings are. example,many scenarios optimization possible put cost reduction 0%. optimizationpossible, price threshold provided supplier higher sum agents upperbound constraints price threshold lower sum lower bound constraints.taking account scenarios, observe mean 2.96%. Moreover, looking costreduction initial nominal demand profile, get mean 3.7%, results 11.1%.912fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT0.20.070.070.060.060.20.050.050.030.10.10.0400.030.10.3p_flexShift0120.010.1240p_flatThresh0.020.20.010.20.030.020.20.10.0400.10.020.2p_distThresh0.04p_distThresh0.100.060.20.050.1p_distThresh0.070.20.30120p_flatThreshp_flexShift0.010.1240.20.3p_flexShift012240p_flatThresh(a) consumers mainly con-(b) Consumers classes have(c) consumers mainly consume night, p f racAgent = 0.equal fractions, p f racAgent = 0.5 sume day, p f racAgent = 1.Figure 9: cost reduction algorithm function four input parameters:p f racAgent, p f latT hresh, p distT hresh p f lexShif t. Scenarios high cost reduction white scenarios less cost reduction dark red.6.3.1 ENSITIVITY NALYSISpurpose sensitivity analysis understand effect different input parameterscost reduction algorithm. sensitivity analysis perform multiplelinear regression. dependent variable (criterion) choose cost reduction (Definition 3).independent variables (predictors) choose smallest interpretable model provides goodadjusted R-squared. resulting model shown Table 2. model explains 76.36%variance adjusted R-squared 0.7571. remaining variance cannot explainedmodel, agents demand constraints generated randomly.predictorsp f racAgentp f latT hreshp f lexShif|p distT hresh|p distT hresh p f lexShifp f racAgent p f latT hreshcoefficient0.00190.00770.0114-0.00720.0018-0.0016stand. error0.00110.00170.00100.00080.00020.0005p-value0.09101.66E-051.35E-252.08E-166.67E-170.0035Table 2: Multiple linear regression model; adjusted R2 = 0.7571Result 1: agents flexibility shifting demands increases, cost reduction increases, i.e.,p f lexShif % G %.multiple linear regression model summarized Table 2 shows effect p f lexShifhighly significant p < 0.01. positive value coefficient (0.0114) showsincrease flexibility leads increased cost reduction.Intuitively, higher flexibility, demand time slots high prices shiftedlower prices. Consequently, higher cost reduction achieved. example,p f lexShif = 0, demand shifted cost reduced. However, another reasonhigh cost reduction uncoordinated profile algorithm higher cost. Recalluncoordinated demand profile agents optimize demand according hourly913fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA550550500500450aggregatednominal demand400aggregatedoptimal demandaggregated demand (kW)aggregated demand (kW)price thresholds350300250200150100450400350300250200150024681012141618202210024time slot024681012141618202224time slot(a) Lower flexibility, p f lexShif = 0.1.(b) Higher flexibility, p f lexShif = 0.3.Figure 10: Example scenarios different flexibilities agents shifting demands.market prices. Consequently, higher agents flexibility, adapt demandschedules hourly prices. However, since coordinated, agents shift muchdemand possible cheap time slots. leads load synchronization, total demandformer cheap slots exceeds thresholds, leading higher costs (herding behavior). Thus,high flexibility uncoordinated consumers leads highly synchronized demand. high initialcosts allow cost reduction algorithm. Figure 10 illustrates settings low(p f lexShif = 0.1) high (p f lexShif = 0.3) flexibility. figure shows clearlyinitial demand peak higher scenario flexibility. Recall Figure 6 slots14, 15, 16 17 relatively low priced slots 17 lowest. areared dashed curve uncoordinated demand profile coordinated demand profile graymultiplied respective marginal prices shows cost reduction coordination.increasing freedom Figure 10b seen area two curves increases.reason height peak stays same, first agents shift much demandpossible time slots aggregated demands thresholds (peaks) time slotsdemand levels thresholds. agents reach upper bounds timeslots, shift remaining demand time slots lowest prices threshold.According hourly prices, cheapest remaining time slot 17. Since freedom allowsdemanding remaining electricity time slot, height peak change.Result 2: absolute distance demand thresholds aggregated load profiledecreases, cost reduction increases, i.e., |p distT hresh| & G %.multiple linear regression model summarized Table 2 shows effect |p distT hresh|highly significant p < 0.01. negative coefficient (-0.0072) shows awaythresholds aggregated load profile less cost reduction achieved.Figure 11 illustrates settings low (p distT hresh = 0.2), normal (p distT hresh = 0)high (p distT hresh = 0.2) thresholds. cost reduction limited much agentsdecrease demand increase thresholds. demand thresholdsrepresented area initial demand profile (red dashed line) thresholds(yellow flat line) thresholds, unused demand thresholds areatwo lines thresholds. amounts also affected flatness914fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENT550550500500500400aggregatednominal demand350aggregatedoptimal demandaggregated demand (kW)aggregated demand (kW)price thresholds450450450400400350300350300250300250200250200150100aggregated demand (kW)55020015002468101214time slot161820222410015002468101214time slot1618202224100024681012141618202224time slot(a) Thresholds average load,(b) Thresholds average load,(c) Thresholds average load,p distT hresh = 0.2.p distT hresh = 0.p distT hresh = 0.2.Figure 11: Example scenarios different heights price thresholds.thresholds, i.e., flatter thresholds, larger two areas become. Thus, flatterthresholds cost reduction increases well. regression model supports this,parameter p f latT hresh positive coefficient (0.0077) highly significant p < 0.01.However, cost reduction scenario high thresholds Figure 11c greatercase normal thresholds Figure 11b. happens, flexibility shiftingdemand limiting factor. Since absolute distance upper lower boundssmaller time slots low demand, demand hits upper bounds time slotsreaches lower bounds time slots high demand. situation, incrementthresholds leads time slots thresholds thus possibilities shiftdemand. Consequently, flexibility limiting factor, cost reduction increases,thresholds slightly increased. supported regression model, interactionterm p distT hresh p f lexShif highly significant p < 0.01.Result 3: observe similar cost reductions groups mostly consumers one classgroups agents classes similar fractions.multiple linear regression model Table 2 shows parameter p f racAgentsignificant predictor cost reduction p > 0.05. supports observationsee cost reductions coordinated behavior two classes (day consumersnight consumers) well mixed groups. Figure 12 illustrates settings night consumers(Figure 12a), mixed group (Figure 12b), day consumers (Figure 12c). However,examples, increasing fraction day consumers, cost reduction decreases largerextent indicated parameter p f racAgent regression model. effect dueinteraction effect composition cooperative flatness thresholds.multiple linear regression model shows interaction term p f racAgent p f latT hreshsignificant predictor p < 0.01. negative value coefficient (-5.219e-04) showsflatness thresholds increases fraction day consumers also increases,cost reduction decreases. Figure 12 seen thresholds lying outsideagents demand bounds many time slots, thresholds time slot.situation thresholds, demand bounds limit potential cost reductioncoordination. Consequently, thresholds get flatter, get reach agents demandbounds. Since load profiles day consumers significant difference peaklow load, effect stronger groups larger fraction day consumers.915fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARA650600600price thresholds500aggregatednominal demandaggregated demand (kW)550450550500450450400350400350300350300250300250200250200150100550500aggregatedoptimal demand400aggregated demand (kW)650600aggregated demand (kW)65020015002468101214time slot161820222410015002468101214161820time slot2224100024681012141618202224time slot(a) consumers mainly con-(b) Consumers classes have(c) consumers mainly consumingsume night, p f racAgent = 0.equal fractions, p f racAgent = 0.5. day, p f racAgent = 1.Figure 12: Example scenarios different compositions consumer cooperative.6.3.2 C ONVERGENCE P ROPERTIES LGORITHMLet first iteration submission agents uncoordinated initial demand profiles. Then,second iteration coordinator sends first virtual price signals agents. Recallbeginning basic algorithm performed basic algorithm converged,additional phase started, necessary. Also recall defined algorithm converged,cost reduction one iteration gets less 0.00001%, i.e., C (R) / C (R0 ) < 1.0000001.simulations, basic algorithm converges average within 9.57 iterations. casesneed additional phase, general algorithm converges average additional 35.10 iterations.experiment setup using one HP Pavilion dmt4-1000 Intel Core i5 520Mtwo cores operating 2.4GHz 8 Gigabyte DDR3 physical memory. Using setup, oneiteration basic algorithm took average 25.12 seconds one iteration extendedphase took average 52.13 seconds. Looking agents demand profiles convergence,observe agent average 67.6% time slots demand bounds tight.sampled scenarios, least one time slot, demand bound tight,agents satisfy constant total demand whole planning horizon.Definition 4. convergence accuracy difference cost converged solutionoptimal solution percentage difference cost uncoordinated profile)C(R )optimal solution, i.e., C(R100.C(R1 )C(R )Result 4: simulations, basic algorithm achieves optimal solution 44.9%sampled scenarios.found 44.9% sampled cases basic algorithm achieves optimal solution.remaining scenarios basic algorithm comes average 1.06% close optimal solution.indicates cases basic algorithm provide good results.Result 5: simulations indicate larger step sizes, , lead faster convergencecost small reductions accuracy.parameter defines step size extended phase. Intuitively, larger steps lead fasterconvergence, cost reduced accuracy. Table 3 shows convergence accuracy averagenumber iterations convergence varying {0.5, 1, 2}. number agents timeslots fixed N = 40 = 24. results indicate increases, numberiterations convergence well accuracy decreases. However, reduction accuracysmall algorithm achieves good results . results indicate order916fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTachieve accurate solutions within iterations, step size adapted run-time.particular, value reduced time.Convergence accuracy0.5120.22%0.33%0.55%Number iterationsconvergence36.526.117.9Table 3: Convergence accuracy time varying step sizesResult 6: simulations indicate convergence time scales linearly agentpopulation size number time slots.analyze influence convergence time algorithm, vary number agents20 100 time slots 12 48. Table 4a shows convergence accuracy Table 4bnumber iterations convergence. step size fixed = 1. results indicatenumber iterations convergence increases linearly number agents timeslots. accuracy change much, increase agent population time slots.PtimeP slotsagents PPPPPP204060801001224480.21%0.24%0.23%0.26%0.25%0.19%0.29%0.26%0.26%0.28%0.18%0.20%0.28%0.30%0.38%(a) Convergence accuracyPtimeP slotsagents PPPP20406080100PP1224489.812.413.515.216.91620.123.727.128.222.430.235.440.343.2(b) Number iterations convergeceTable 4: Convergence accuracy time varying number agents time slots7. Conclusion Future Workpaper, presented iterative coordination algorithm minimize energy costconsumer cooperative, given information agents individual demand constraintspreferences remains private. proved algorithm converges optimal demand schedule presented results time complexity iterative algorithm agents incentivecompatibility. Additionally, conducted evaluations algorithm using multiagent simulation based real world consumption data. simulations, characterized convergenceproperties algorithm effect differing demand characteristics cooperativeprice functions cost reduction algorithm. results show convergencetime scales linearly population size length optimization horizon. Finally, observe participants flexibility shifting demands increases, cost reduction increasescost reduction sensitive variation consumption patterns consumers.work extended several directions. Future work investigate settingsagents might able compute guaranteed optimal solution individual problem,provably good approximation. could apply settings detailed load917fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARAmodels agents. overall demand come two types loads: shiftable loadsnon-shiftable loads. loads divided interruptible non-interruptibleloads. addition, loads subject temporal constraints. lead situationindividual problems agents longer convex, thus agent solveindividual problem optimally. Luo, Chakraborty, Sycara (2013) present distributed iterativealgorithm generalized task assignment problem context multirobot system (MRGAP). Based (approximate) best responses agents, algorithm provableapproximate ratio. would interesting investigate distributed algorithm contextproblem.paper, demand cooperative time slot solely consists aggregateddemand agents. Future work consider problems generation and/ storage (thatcentralized, i.e., owned cooperative, distributed, i.e., owned individual agent).Another avenue future work consider problem formulation cooperative facesuncertainty electricity prices. example, consider 24-hour planning horizon insteadlong term contract electricity bought hourly spot market. Here, schedulingdemand, one knows price next hour prices future hourly time slotsuncertain. spot market electricity price depends many factors controlledcoordinator. Hence, planning purposes, prices assumed externallyspecified stochastic process. assumption, goal would design algorithms (1)determining policies (for generation, storage, price signals sent firms) centralcoordinator (2) determine schedules individual firms, expected costbuying electricity minimized.Acknowledgementswork partially supported NSF award IIS-1218542.Appendix A. Proof: Virtual Cost Upper Bound Total CostProof. Here, give full proof showing sum agents individual cost accordingvirtual price signals upper bound total central cost market prices. prove this,showing Equations 1 7 every time slot j difference total costaggregated demand sum agents individual cost lower equal 0. Sincetrue every time slot, also true sum time slots.central cost aggregated demand given Equation 1NX0pj 0j rij, ji=1+0= pH0j hj + pL+ pLjj j hjj hj(H0L0pj j hj + pj hj j > hj=0L0j hjpLj j hj + pj hj(PPNN0pHrijhij + i=1 pLjj hijP= Pi=1NNL0+ i=1 pLj hiji=1 pj rij hij9180j > hj0j hjfiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTsum agents individual cost given Equation 7NX00sij rijrij , ji=1=N hX0pHrijhijj+0+ pLj rij hij+ pLj hiji=1difference two costs get:NXNX000pj 0j rijsij rijrij , ji=1i=1Ph+NL0L0HL0Hhhprhprhph+prpijijijj ijijjijjj ijijji=1= PN h+L0LH0L0Lrij hij pj rij hij pj hiji=1 pj rij hij + pj hij pjSincePNi=10j hjPN LpLhijji=1 pj hij equal removed.PhN pH r0 hij pH r0 hij + pL r0 hijjijjijjiji=1= PN h+L0H0L0prhprhprijijjijjijjij hiji=1Lets writePanalog Ni: r00j > hj0j hj+PN L 0PNH r0 hH r0 hprhpp0ijijijijijiji=1 ji=1 ji: rij >hij jPNPNPNH0rij hij . Lets also write i=1 i: r0 >hij + i: r0 hij .hij pjPNij=0j > hjijijNNH 0P H 0PH0L0i: r0 >h pj rij hij pj rij hij + i: r0 h pj rij hij pj rij hijiji:ijNP0 >hrijijiji:0j > hj termsPNi:0 hrijpHijj=i: r 0 hPN ij ij0 >hi: rijij0L0pLj rij hij pj rij hijremoved. 0j hj remove(PN0 hrijij0 >hrijijijNPL 00pj rij hij pHrijhij +j0i: rijPN0 >hrijijH 00pj rij hij pLj rij hijL 00pj rij hij pHrijhijj0j > hj0j hj0j > hjH0pLrijhij0j hjj pj(P0NHL0j > hji=1 pj pj rij hij= PN+LH0rijhij0j hji=1 pj pjh PNHL0rijhij0 0j > hji=1 pj pjh=P+NLH0rijhij0 0j hji=1 pj pj=i: r 0 hPN ij ij0 >hi: rijijLpHj pj9190j hjH r0 hpij equalijji:L0hij pj rij hij respectively.PNL pL pH out.Factor pHpjjjj(PN0j > hj0rijhijfiV EIT, X U , Z HENG , C HAKRABORTY, & YCARASince inequality true every time slot, also holds sum time slots. followssum agents individual cost according virtual price signals upper boundP0total central cost market prices, C (R0 ) Ni=1 Ci (ri ):N XXN XX000pj 0j rij+ gi (r0i )sij rijrij + gi (r0i )i=1 j=1i=1 j=1Appendix B. Proof Counterexample: Basic Algorithm ConvergeSuboptimal Solution Case gi () 6= 0present counterexample prove basic algorithm converge suboptimal solutiongeneral settings gi () 6= 0. Consider population 2 agents, N = 2, planninghorizon 2 time slots, = 2. agents constraints converged solution,aggregated demand equal threshold one time slot. Let price function given as:HL H(pL1 , p1 ) = (3, 8), h1 = 9 ; (p2 , p2 ) = (3, 8), h2 = 11individual constraints agents demand are:r11 [1, 3], r12 [4, 6], r11 + r12 = 1 = 7r21 [4, 6], r22 [4, 6], r21 + r22 = 2 = 10agents individual cost associated demand schedule given as:g1 (r1 ) = r151, g2 (r2 ) = r263(1)beginning, agents compute initial demand profiles based market prices r1 =(1)(1, 6), r2 = (4, 6). cost based demand profiles C R(1) = 109.(T )(T )convergence, final profiles twoagents r1 = (1.5, 5.5), r2 = (4.5, 5.5).cost based demand profiles C R(T ) = 107.5.However different demand profile agents exists r01 = (1, 6), r02 = (5, 5).profile feasible leads lower total cost, i.e., C (R0 ) = 107. follows algorithmstopped suboptimal solution.ReferencesAlbadi, M., & El-Saadany, E. (2007). Demand response electricity markets: overview.Power Engineering Society General Meeting, 2007. IEEE, pp. 15. IEEE.Atzeni, I., Ordonez, L., Scutari, G., Palomar, D., & Fonollosa, J. (2013). Demand-side managementvia distributed energy generation storage optimization. IEEE Transactions Smart Grid,4(2), 866876.Ausubel, L. M., & Milgrom, P. (2006). lovely lonely vickrey auction. Combinatorialauctions, 1740.Barbose, G., Goldman, C., & Neenan, B. (2004). survey utility experience real timepricing. Tech. rep., Ernest Orlando Lawrence Berkeley National Laboratory, Berkeley, CA,USA.920fiM ULTIAGENT C OORDINATION EMAND IDE E NERGY ANAGEMENTBertsekas, D. P., & Tsitsiklis, J. N. (1989). Parallel distributed computation: numerical methods. Prentice-Hall, Inc., Upper Saddle River, NJ, USA.Boyd, S., & Vandenberghe, L. (2004). Convex optimization. Cambridge university press.Chu, C., & Jong, T. (2008). novel direct air-conditioning load control method. IEEE TransactionsPower Systems, 23(3), 13561363.Clement-Nyns, K., Haesen, E., & Driesen, J. (2010). impact charging plug-in hybrid electricvehicles residential distribution grid. IEEE Transactions Power Systems, 25(1), 371380.Dietrich, K., Latorre, J., Olmos, L., & Ramos, A. (2012). Demand response isolated systemhigh wind integration. IEEE Transactions Power Systems, 27(1), 2029.Green, J., & Laffont, J.-J. (1977). Characterization satisfactory mechanisms revelationpreferences public goods. Econometrica: Journal Econometric Society, 427438.Hurwicz, L. (1975). existence allocation systems whose manipulative nash equilibriapareto-optimal. 3rd World Congress Econometric Society.Jellings, C. W., & Chamberlin, J. H. (1993). Demand Side Management: Concepts Methods.PennWell Books, Tulsa, OK, USA.Kirschen, D. (2003). Demand-side view electricity markets. IEEE Transactions Power Systems, 18(2), 520527.Luo, L., Chakraborty, N., & Sycara, K. (2013). Distributed algorithm design multi-robot generalized task assignment. Proceedings IEEE International Conference IntelligentRobots Systems.Medina, J., Muller, N., & Roytelman, I. (2010). Demand response distribution grid operations:Opportunities challenges. IEEE Transactions Smart Grid, 1(2), 193198.Mohsenian-Rad, A., Wong, V., Jatskevich, J., Schober, R., & Leon-Garcia, A. (2010). Autonomousdemand-side management based game-theoretic energy consumption schedulingfuture smart grid. IEEE Transactions Smart Grid, 1(3), 320331.Mohsenian-Rad, A., & Leon-Garcia, A. (2010). Optimal residential load control price prediction real-time electricity pricing environments. IEEE Transactions Smart Grid, 1(2),120133.Nguyen, H. K., Song, J. B., & Han, Z. (2012). Demand side management reduce peak-to-averageratio using game theory smart grid. IEEE Conference Computer CommunicationsWorkshops (INFOCOM WKSHPS), pp. 9196. IEEE.Palensky, P., & Dietrich, D. (2011). Demand side management: Demand response, intelligent energysystems, smart loads. IEEE Transactions Industrial Informatics, 7(3), 381388.Pedrasa, M., Spooner, T., & MacGill, I. (2010). Coordinated scheduling residential distributedenergy resources optimize smart home energy services. IEEE Transactions Smart Grid,1(2), 134143.Philpott, A., & Pettersen, E. (2006). Optimizing demand-side bids day-ahead electricity markets.IEEE Transactions Power Systems, 21(2), 488498.Rahimi, F., & Ipakchi, A. (2010). Demand response market resource smart gridparadigm. IEEE Transactions Smart Grid, 1(1), 8288.921fiV EIT, X U , Z HENG , C HAKRABORTY, & YCARARamchurn, S., Vytelingum, P., Rogers, A., & Jennings, N. (2012). Putting smartssmart grid: grand challenge artificial intelligence. Communications ACM, 55(4),8697.Ramchurn, S. D., Vytelingum, P., Rogers, A., & Jennings, N. (2011). Agent-based control decentralised demand side management smart grid. 10th International ConferenceAutonomous Agents Multiagent Systems-Volume 1, pp. 512.Samadi, P., Mohsenian-Rad, H., Wong, V., & Schober, R. (2013). Tackling load uncertaintychallenges energy consumption scheduling smart grid. IEEE Transactions SmartGrid, 4(2), 10071016.Tanaka, K., Uchida, K., Ogimi, K., Goya, T., Yona, A., Senjy, T., Funabashi, T., & Kim, C. (2011).Optimal operation controllable loads based smart grid topology considering insolationforecasted error. IEEE Transactions Smart Grid, 2(3), 438444.Veit, A., Xu, Y., Zheng, R., Chakraborty, N., & Sycara, K. (2013). Multiagent coordination energy consumption scheduling consumer cooperatives. Proceedings 27th AAAI Conference Artificial Intelligence, pp. 13621368.Voice, T., Vytelingum, P., Ramchurn, S., Rogers, A., & Jennings, N. (2011). Decentralised controlmicro-storage smart grid. Proceedings 25th AAAI Conference ArtificialIntelligence, pp. 14211427.Vytelingum, P., Ramchurn, S., Rogers, A., & Jennings, N. (2010). Agent-based homeostatic controlgreen energy smart grid. First International Workshop Agent TechnologiesEnergy Systems (ATES 2010).Vytelingum, P., Voice, T., Ramchurn, S., Rogers, A., & Jennings, N. (2011). Theoretical practical foundations large-scale agent-based micro-storage smart grid. Journal Artificial Intelligence Research, 42(1), 765813.Wood, A., & Wollenberg, B. (1996). Power Generation Operation Control. John Wiley & Sons.Wu, C., Mohsenian-Rad, H., & Huang, J. (2012). Wind power integration via aggregator-consumercoordination: game theoretic approach. Innovative Smart Grid Technologies (ISGT),2012 IEEE PES, pp. 16. IEEE.922fiJournal Artificial Intelligence Research 50 (2014) 763-803Submitted 1/14; published 8/14Policy Iteration Based Stochastic FactorizationAndre M. S. BarretoAMSB @ LNCC . BRLaboratorio Nacional de Computacao CientficaPetropolis, BrazilJoelle PineauDoina PrecupJPINEAU @ CS . MCGILL . CADPRECUP @ CS . MCGILL . CASchool Computer ScienceMcGill UniversityMontreal, CanadaAbstracttransition probability matrix represented product two stochastic matrices,one swap factors multiplication obtain another transition matrix retainsfundamental characteristics original. Since derived matrix much smallerprecursor, property exploited create compact version Markov decisionprocess (MDP), hence reduce computational cost dynamic programming. Buildingidea, paper presents approximate policy iteration algorithm called policy iterationbased stochastic factorization, PISF short. terms computational complexity, PISFreplaces standard policy iterations cubic dependence size MDP functiongrows linearly number states model. proposed algorithm also enjoysnice theoretical properties: always terminates finite number iterations returnsdecision policy whose performance depends quality stochastic factorization.particular, approximation error factorization sufficiently small, PISF computesoptimal value function MDP. paper also discusses practical ways factoring MDPillustrates usefulness proposed algorithm application involving large-scaledecision problem real economical interest.1. IntroductionDecisions rarely come alone real situations: usually, outcome decision effectnext one, turn impacts next, on. Thus, choice seems beneficialshort-sighted perspective may reveal disastrous long run. dealingsuccession interrelated choices, one must weigh immediate effects decisionlong-term consequences order achieve good overall performance. Formally, tasks involvingtrade-off short- long-term benefits called sequential decision-making problems.work focuses particular decision-making model known Markov decision process(MDP, Puterman, 1994). MDP simple yet important mathematical model describessequential decision task terms transition probabilities rewards. transition probabilitiesrepresent dynamics process, rewards provide evaluative feedback decisions made. Given MDP, one usually interested finding optimal decision policy,maximizes expected total reward decision maker receive long run. naturalc2014AI Access Foundation. rights reserved.fiBARRETO , P INEAU , & P RECUPway perform search resort dynamic programming, class methods solvingsequential decision problems developed concomitantly MDP model (Bellman, 1957).Since publication Bellmans (1957) seminal book, dynamic programming studied 50 years, supported strong well understood theoretical basis.Besides, long ago transcended limits academia tested real situations (White,1985, 1988, 1993). Despite success dynamic programming several applications,serious obstacle hinders widespread use: computational cost dynamic programmingalgorithms grows fast number states problem, precludes use manydomains. limitation noted Bellman (1961), also pointed numberstates decision process grows exponentially number dimensions state spaceaproblem came known dynamic programmings curse dimensionality.Nowadays consensus that, order solve large-scale sequential decision problems,one must exploit special structure corresponding model resort form approximation (Bertsekas & Tsitsiklis, 1996; Sutton & Barto, 1998; Powell, 2007). One way incorporatingapproximation dynamic programming framework create compact version MDPretains much possible information contained original model. approachpresented paper based idea. Specifically, builds following insight:transition probability matrix approximated product two stochastic matrices, oneswap factors multiplication obtain another transition matrix, possibly much smalleroriginal, related precursor. property, called stochastic-factorizationtrick, exploited create compact version MDP, hence reduce computational demands dynamic programming. main contribution paper approximatepolicy iteration algorithm named policy iteration based stochastic factorization (PISF).shown, performance decision policy computed PISF depends qualitystochastic factorization; particular, exact factorization leads optimal policy. Moreover, computational complexity iteration proposed algorithm linearnumber states MDP.stochastic factorization presented detail Section 2.4. Although simple,presentation depends basic concepts, introduced Sections 2.2 2.3.Section 3 discusses use stochastic factorization approximate MDP. section also introduces analyzes PISF algorithm, main contribution paper. Section 4 investigatescomputational issues surrounding use PISF practice presents possible solutionsefficiently compute factorization MDP. Section 5 proposed solutions puttest large-scale decision problem involving maintenance asset componentsdeteriorate time. Section 6 outlines relationship stochastic factorizationapproaches described literature. paper ends Section 7, brief summarypresented along suggestions future research.2. Backgroundsection introduces notation adopted briefly reviews concepts usedthroughout paper.764fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATION2.1 NotationBoldface letters used denote matrices vectors. Given matrix A, symbol ai usedrepresent ith row; ai j denotes jth element vector ai . Inequalities interpretedelement-wise; thus B means ai j bi j j. operators max argmaxapplied row-by-row, is, given R pq , max vector b R p bi = max j ai ji. Finally, symbols bmax bmin used shorthand maxi bi mini bi .2.2 Markov Decision Processessequential decision-making model considered decisions made discrete time steps.instant decision maker occupies state si must choose action setA. sets called state action spaces, respectively. paper assumedfinite (though possibly large). execution action state si movesdecision maker new state j , new action must selected, on. transitionsij certain probability occurrence associated reward r R. goaldecision maker find policy : 7 A, is, mapping states actions,maximizes expected return associated every state S.1 return defined follows:R (si ) = rt+1 + rt+2 + 2 rt+3 + ... + 1 rt+T = k=1 k1 rt+k ,(1)rt+k R reward received kth transition starting state si time step t.parameter [0, 1) discount factor, determines relative importance individualrewards depending far future received. sequential decision process maylast forever (T = ) decision maker reaches terminal state (T < ).decision-making process described formalized Markov decision process,MDP short. MDP tuple (S, A, P, R, ) (Puterman, 1994). element Pfamily transition probability functions, one action A. function Pa : 7 [0, 1]gives transition probabilities associated action a; Pa (s j |si ) probability transition|S|state j action executed state si . Note j=1 Pa (s j |si ) = 1,si (in paper | | used denote cardinality set absolute valuescalar; distinction clear context). remaining component MDP,R, fidefined analogouslyP: reward received transition sij given Ra (si , j ),fifiRa (si , j )fi Rmax < . Usually one interested expected reward resulting|S|execution action state si , is, ra (si ) = j=1 Ra (si , j )Pa (s j |si ). policy definedMDP induces Markov process . dynamics given P (si ) (|si ), (si )action selected state si . Likewise, expected reward collected state sigiven r (si ) (si ).state space action space finite, MDP representedmatrix form. function Pa becomes matrix Pa R|S||S| , paij = Pa (s j |si ). Sinceelements row Pa nonnegative sum one, stochastic matrix (seeDefinition 1). Stochastic matrices play important role rest paper. matrix1. generally, decision policies rules associating states actions, range generality randomizedhistory-dependent stationary deterministic (Puterman, 1994, Section 2.1.5). Since discounted MDPs finitestate action spaces always exists stationary deterministic policy performs optimally, paperfocus class decision policies (Puterman, 1994, Thm. 6.2.7).765fiBARRETO , P INEAU , & P RECUPform, function ra vector ra R|S| , ria = ra (si ). Thus, finite MDPrepresented |A| matrices Pa number vectors ra : (S, A, Pa , ra , ). decisionpolicy defined finite MDP vector A|S| whose element action selectedsi . Markov process induced represented matrix P R|S||S| vectorr R|S| . ith row P corresponds row index matrix Pi , is,pi = pi . entries r given ri = rii .paper assumed totally ordered set, symbol used referaction index A. slight abuse notation simplifies presentationconsiderably, distinction clear context.2.3 Dynamic Programmingdynamic programming theory built upon concept value function. value statesi policy , denoted V (si ), expected return decision maker receive sifollowing . Using (1), one write V (si ) = E {R (si )}. case finite state space,value function vector v R|S| . vector v makes possible impose partial orderingdecision policies. particular, policy considered least good another policyv v . goal sequential decision problem find optimal policyv v . well known always exists least one policy givenMDP (Bertsekas, 1987; Puterman, 1994). one optimal policy,share value function v .makes search optimal policy feasible Bellman equation, recursive relation state values lies core dynamic programming algorithms. Bellmanequation decision policy given v = r + P v . possible use equationcompute value function policy . One way simply convert socalled Bellman operator , v = r + P v. known (T )t v vvector v R|S| (Bertsekas, 1987; Puterman, 1994). direct approach compute vinterpret Bellman equation system linear equations compute value functionv = (I P )1 r , identity matrix dimension |S|.Given v , possible generate decision policy whose performance least goodoriginal policy . Let : R|S| 7 R|S||A| mapping associated given MDPv = Q, ath column Qqa = ra + Pa v.(2)clear (T v)i = (v)ia , = . instead = argmax j (v)i j , oneBellman operator MDPthat is, v = max v. Alternatively, v viewed singleapplication , = argmax v. driving force dynamic programming factderived v cannot perform worse . Therefore, dynamic programmingalgorithms variations basic scheme: starting arbitrary v R|S| , computepolicy = argmax v apply update rule v (T )t v > 0. Then, based v ,compute new decision policy , apply steps, on. shown that, regardlessvalue t, process eventually converge optimal policy (Bertsekas, 1987;Puterman, 1994).scheme described adopted = 1, process reduces successiveapplications Bellman operator , resulting method popular value iteration766fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONalgorithm. paper focus extreme spectrum, = . case onepolicy iteration method (Howard, 1960). Algorithm 1 shows step-by-step descriptioncomputations performed policy iteration (see also Appendix A.1).Algorithm 1 Policy iterationRequire: MDP M: Pa R|S||S| ra R|S| A, [0, 1)Ensure:1: random vector A|S|2: repeat3:4:i1, 2, ..., |S| pi pii ri riiv (I P )1 r6:argmax v7: =5:Ties broken randomly2.4 Stochastic-Factorization Tricksection presents stochastic-factorization trick, mathematical concept recently introducedBarreto Fragoso (2011) serve cornerstone subsequent developments.trick builds following definitions:Definition 1. matrix P Rnz called stochastic pi j 0 i, j zj=1 pi j = 1i. square stochastic matrix called transition matrix.Definition 2. Given stochastic matrix P Rnz , relation P = DK called stochastic factorization P Rnm K Rmz also stochastic matrices. integer > 0 orderfactorization.relation P = DK fact stochastic imply every row P obtainedconvex linear combination rows K. words, n stochastic vectors pi R1zlie within convex hull defined set stochastic vectors ki R1z . Obviously,n always possible find hull, is, always possible compute stochasticfactorization P. < n, however, exact factorization might possible. leadsfollowing definition:Definition 3. stochastic rank stochastic matrix P Rnz , denoted srk(P), smallestpossible order stochastic factorization P = DK.matrix called nonnegative elements greater equal zero. said,definitions nonnegative factorization nonnegative rank follow analogouslystochastic counterparts. Cohen Rothblum (1991) shown always possiblederive stochastic factorization nonnegative factorization stochastic matrix (seeTheorem 3.2). Since stochastic factorization also nonnegative factorization, followsnonnegative stochastic ranks stochastic matrix coincide. easy show Pone nonzero element per row, stochastic rank matrix coincides conventionalrank, is, srk(P) = rk(P). general case, however, thing saidrk(P) srk(P) min(n, z) (Cohen & Rothblum, 1991).767fiBARRETO , P INEAU , & P RECUP0.10 0.90 0.00P = 0.28 0.63 0.090.70 0.00 0.301.0 0.0= 0.7 0.30.0 1.0K=0.1 0.9 0.00.7 0.0 0.3P =0.73 0.270.70 0.30Figure 1: Reducing dimension Markov process n = 3 states = 2 artificial states.original states represented white circles; black circles depict artificial states.figures appeared article Barreto Fragoso (2011).stochastic factorization appeared literature, either defined (Cohen& Rothblum, 1991; Ho & van Dooren, 2007) slightly modified versions (Cutler & Breiman,1994; Ding et al., 2010). However, paper focus useful property type factorization recently noted (Barreto & Fragoso, 2011).Let P transition matrix dimension n representing dynamics Markov process.stochastic factorization P = DK admits interesting interpretation case. Suppose < n,order factorization. elements row seen transitionprobabilities states original Markov process set artificial states. Similarly,rows K may interpreted probabilities transitions opposite direction.interpretation mind, interesting ask product DK restitutes dynamicsoriginal process. answer question, suffices see element pi j =l=1 dil kl j sumprobabilities associated two-step transitions: si artificial stateback j . words, pi j accumulated probability possible paths sij stopover one artificial states. Following similar reasoning, difficult seeswapping factors stochastic factorization, is, switching DK KD,one obtains transition probabilities artificial states. makes possible definenew Markov process, composed artificial states, whose dynamics given P = KD.Figure 1 illustrates idea case Markov process three states reducedcompact model containing two artificial states.simply swapping factors stochastic factorization, possible derive new matrix P retains information dynamics original Markov process compactway. stochasticity P follows immediately property K.perhaps surprising fact matrix shares fundamental characteristicsoriginal matrix P. Specifically, possible show that: (i) recurrent class Pcorresponding class P period and, given simple assumptionsfactorization, (ii) P irreducible P irreducible (iii) P regular Pregular (see Barreto & Fragoso, 2011, details formal definitions). property calledstochastic-factorization trick:Given stochastic factorization square matrix, P = DK, swapping factors factorization yields another transition matrix P = KD, potentially much smaller original,retains basic topology properties P.768fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATION3. Policy Iteration Based Stochastic Factorizationsection introduces main contribution paper, approximate policy-iteration algorithm built upon stochastic-factorization trick. section starts descriptionstochastic-factorization trick used reduce computational cost evaluating Markovprocess, generalizes idea MDP.3.1 Approximating Markov ProcessSuppose search optimal policy given MDP one determine valuefunction decision policy . Instead computing directly, one generate compactversion Markov process induced use value function recover value functionoriginal process. following proposition provides mathematical foundationimplementation strategy above.Proposition 1. Let (S, A, Pa , ra , ) MDP, 0 < 1. Given policy A|S| , letP R|S||S| r R|S| transition probability matrix expected reward vectorMarkov process induced policy M. Let R|S|m nonnegative matrix, letK Rm|S| stochastic matrix, let r vector RmDK = P Dr = r .(3)Then,(i) P = KD r define Markov process states.Let v Rm value function computed discount factor . Then,(ii) v = Dv value function .Proof. Since K stochastic matrix nonnegative, equality DK = P impliesalso stochastic: 1 = j pi j = j l dil kl j = l dil j kl j = l dil . fact Knonnegative implies P nonnegative; since j pi j = j l kil dl j = l kil j dl j = l kil = 1,P transition matrix (see Definition 1). proves (i). order prove (ii), recall v ,value function , writtenv = r + P v(4)(the existence uniqueness solution (4) guaranteed stochastic property Pfact 0 < 1see, example, Lemma 2.3.3 Golub & Loan, 1996 Proposition 2.6 Bertsekas & Tsitsiklis, 1996). Multiplying sides (4) D, oneDv = Dr + DP v = r + DKDv = r + P Dv .(5)Expression (5) Bellman equation associated value function ; since equationsingle fixed point, (ii) must true (Bertsekas, 1987; Puterman, 1994).computation decision policys value function involves O(|S|3 ) arithmetic operations(Littman et al., 1995). theory, Proposition 1 makes possible reduce computational complexity procedure O(m3 ) (also see Appendices A.1 A.2). Practically speaking,769fiBARRETO , P INEAU , & P RECUPhowever, application Proposition 1 raises difficulties. First, one must determine reasonable value m, number artificial states compact model. Obviously, one wantsvalue small possible, trivial find smallest allowsapplication proposition. Even stochastic rank P known, might possiblesimultaneously satisfy equalities (3) = srk(P ). Moreover, computationD, K r requires number arithmetic operations easily exceed number operations involved original calculation v .2 reasons, one may resortapproximate factorization Markov process.approximate version stochastic factorization problem, one interested findingstochastic matrices K represent P well possible, i.e., minimize measuredissimilarity DK P . order apply Proposition 1, one must also searchvector r Rm makes Dr similar possible r . D, K, r determined,one swap factors stochastic factorization define Markov process artificialstates. described Proposition 1, value function resulting Markov process, v ,used restore value function original model. Obviously, DK P Dr r ,Dv be, too, approximation v . important issue case quantifyimpact errors approximation P r might computation valuefunction. section provides analysis specific dissimilarity measure. particular,presents upper bound k v Dv k based k P DK k k r Dr k . Here,k k denotes maximum norm, induces following norm space matrices:k k = maxi k ai k1 = maxi j |ai j |.Proposition 2. Let P R|S||S| r R|S| transition probability matrix expectedreward vector describing Markov process induced decision policy . Let R|S|mK Rm|S| stochastic matrices, let r vector Rm . Finally, let Markovprocess described P = KD r. Then,1k P DK k ,k v Dv k k r Dr k +(6)2(1 )v v value functions , computed [0, 1),, r= 1 1 12 k P DK k , = max(rmaxmax ) min(rmin , rmin ).Proof. Let Markov process transition matrix DK reward vector Dr.Proposition 1 follows value function given v = Dv . Recall Markovprocess seen MDP |A| = 1. Then, applying Whitts (1978) Theorem 6.2 (b), mappings two models taken identities, one concludesvi vi + i. Since mappings identity function, oneapply Theorem 6.2 (b) again, exchanging roles two models, obtain vi vi +i. upper bound (6) results combination two inequalities above.According Whitt (1978), possible construct examples showing (6) tight bound.Proposition 2 makes clear approximation v depends characteristics2. Vavasis (2009) shown determination nonnegative rank stochastic matrix NP-hard problem.implies polynomial-time algorithm computing K currently known; case, onecould compute one factorization value = |S|, |S| 1, ..., 1, stopping exact factorizationlonger possible, thus determining matrixs rank polynomial time.770fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONquality stochastic factorization. First, right-hand side (6) increases 1. expected, since magnitude individual rewards rateaccumulate time tend increase states values. important, differencev Dv directly depends stochastic factorization, DK P Dr rapproximation Dv gets closer real value function v . limit, k r Dr k = 0k P DK k = 0, one recovers Proposition 1.interesting point intriguing property Proposition 2. Observe increaseapproximation error k P DK k two opposite effects variables involvedderived bound: one hand increases coefficient multiplying , expected,hand also decreases factor 1/ scaling entire right-hand (6). preciselymakes bound tight, since latter effect tends alleviate first. Needless say,bound still monotonically increasing function k P DK k , one easily verifycomputing appropriate partial derivative.3.2 Approximating Markov Decision Processstraightforward way use stochastic-factorization trick search decisionpolicy factor one one Markov processes come search. specific,let arbitrary decision policy defined finite MDP let P r describeMarkov process induced policy. Given approximations DK P Dr r , onedefine new Markov process transition matrix P = KD reward vector r. auxiliarymodel potentially many fewer states original Markov process. determiningvalue function compact model, v , one compute approximation original valuefunction making v = Dv . Finally, new policy = argmax v derived, restartingusual dynamic programming loop. Notice DK = P Dr = r every policycomes search, process eventually converge optimal decision policy.direct consequence Proposition 1.Although feasible, strategy presents obvious drawback: new factorization mustcomputed Markov process encountered search decision policy. Another possibility factor entire MDP once. case, possible approach find approximatefactorizations Markov process , Da Ka Pa Da ra ra , A, solvereduced MDP whose transition matrices Ka Da whose expected reward vectors ra .However, MDP directly solved, quality solution found dependstochastic factorization only, even exact factorization MDP lead suboptimaldecision policies (for example, shown Barreto, Precup, & Pineau, 2011, Prop. 1, particular case single matrix used factor Markov processes, approximationerror also depends level stochasticity D, measured maxi (1 max j di j )). remaining section discusses alternative way factoring MDP performancefinal decision policy depends exclusively quality stochastic factorization.Let (S, A, Pa , ra , ) finite MDP. Let Da R|S|m K Rm|S| stochastic matricesDa K Pa A, let r Rm vector Da r ra , A. LetA|S| policy defined let corresponding Markov process. discussedSection 2.3, ith row P R|S||S| , transition matrix , ith row Pi ,action selected si (see line 4 Algorithm 1). approximations Da K Pa ,one see ith row Pi approximated di K (recall di ith row Di ).771fiBARRETO , P INEAU , & P RECUPThus, order build approximation P , suffices construct matrix R|S|m whoserows given di = di . determined, transition matrix associatedapproximated P K. Analogously, vector r R|S| approximatedr r.Using strategy above, straightforward extend ideas Proposition 1 factorization entire MDP. Given decision policy , one must first compute matrix describeddefine reduced Markov process transition matrix P = KD reward vectorr. corresponding value function v used compute approximation valuefunction , serve reference derivation new decision policy ,on. Algorithm 2 shows ideas embedded policy iteration, giving risepolicy iteration based stochastic factorization algorithm, simply PISF.Algorithm 2 Policy iteration based stochastic factorization (PISF)Require: Da R|S|m A, K Rm|S| , r Rm , [0, 1)Ensure:1: random vector A|S|2: repeat3:4:i1, 2, ..., |S| di dii5:P KD6:v (I P )1 r7:Let Q R|S||A|8:a1, 2, ..., |A| q ,a Da vq ,a ath column Q9:argmax QTies broken randomly10: =standard policy iteration algorithm, computation decision policys value functiontakes O(|S|3 ) arithmetic operations, derivation new policy O(|S|2 |A|) (Littmanet al., 1995). contrast, PISF needs O(|S|m|A|) operations derive new policyas shownlines 8 9 Algorithm 2and breaks value function computation several stepswhose overall complexity O(|S|m2 ). process computing v follows. First, onedetermine matrix , involves O(|S|) operations (line 4 Algorithm 2). Then,necessary perform O(m2 |S|) operations compute transition matrix P (line 5). Finally,one must calculate v , O(m3 ) (line 6). one see, computational complexityone iteration PISF linear number states |S|. Thus, |S|, numberarithmetic operations performed per iteration PISF much smaller number operationswould executed conventional policy iteration algorithm.Regarding space complexity PISF, storing Da , K r requires O(|S||A|m) bits. Notethough actual implementation matrices Da need stored main memory. Thus, one willing trade space timesince case would computedloaded demand, actual memory usage algorithm drops O(|S|m) only.772fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATION3.3 Convergence Error BoundPISF algorithm rests approximations Da K Pa Da r ra . approximationshappen exact, Proposition 1 directly applicable every decision policy generated algorithm, implies converge optimal policy . Nevertheless, order PISFconsidered stable method, necessary show errors approximationscause algorithm behave completely unpredictable way. following propositionshows PISF well-behaved algorithm, sense always terminates finite numberiterations quality decision policy returned improves kDa KPa k 0kDa rra k 0 A.Proposition 3. Let (S, A, Pa , ra , ) MDP [0, 1). Let Da R|S|m K Rm|S|stochastic matrices, A, let r R|S| . Then, PISF executed Da , K, r, ,(i) terminate finite number iterations.Let v value function policy returned PISF let ra = Da r A. Then,(ii)kv v k21maxa kra ramaxa k P K k ,k +2(1 )(7)min ra .v optimal value function = maxa rmaxminProof. Let (S, A, Da K, Da r, ), is, MDP whose transition matrices Da Kwhose expected reward vectors Da r, A. strategy proof showexecuting PISF Da , K, r, equivalent running standard policy iteration M.Let , v Q policy, value function, matrix computed PISF ith iteration(lines 3, 6, 8 Algorithm 2, respectively). definition Q , one writeq ,a = Da v = Da (r + P v ) = Da (r + KD v ) = Da r + Da KD v ,(8)also matrix constructed PISF ith iteration (line 4 Algorithm 2). Comparing (2) (8), clear Q = v . Proposition 1, follows v valuefunction Markov process described K r. exactly Markov processinduced (see line 4 Algorithm 1). Therefore, policy computed one iterationPISF starting , = argmax Q = argmax v , policy would computedone iteration standard policy iteration applied also starting . impliesPISF converge optimal policy finite number iterations, hence (i) holds(see, example, Puterman, 1994, Thm. 6.4.2).order show (ii), suffices resort Whitts (1978) results comparing dynamic programs, generalization MDPs proposed Denardo (1967). Specifically, one appliescorollary Whitts Lemma 3.1 M, mappings two MDPs takenidentities, follows2maxi j |hi j |,(9)k v v k1hi j elements matrix H = v v v optimal value function (sincepolicy computed PISF optimal M, last term appearing Whitts bound vanishes).773fiBARRETO , P INEAU , & P RECUPBased Corollary (b) Whitts Theorem 6.1, one write:maxi j |hi j | maxa k ra ra k +maxa k Pa Da K k .2(1 )(10)Substituting right-hand side (10) (9) one gets desired bound.3Proposition 3 states PISF converge decision policy finite number iterations. fact, proof proposition shows, solution returned PISF oneoptimal policies MDP (S, A, Da K, Da r, ). Thus, one look PISF fast specialized method solve MDPs specific type structurenamely, MDPs allowexact factorization single K single r. course, PISF converge decision policy even factorization exact; case algorithm becomes approximate policyiteration method.error bound provided Proposition 3 tight general. seen noting|A| = 1 bound (7) may looser counterpart (6). Also, boundpessimistic practical value many situations. Even so, Proposition 3 conceptualimportance establishes soundness PISF. particular, states performancepolicy returned algorithm gets closer optimal error MDP approximationdecreases. fact, difficult show that, errors approximations Da K PaDa r ra certain threshold, policy returned PISF performs optimally M.order that, first note ra = Da r implies rmin ria rmax a, thus one, max ra ] still get exact factorization.restrict elements r interval [mina rminmaxAssuming case, term appearing right-hand side (7) replacedmin ra . means max k Pa Da K k max k ra Da r kmaxa rmaxminterms (7) vary Da , K r, hence one make bound arbitrarily smalldriving approximation errors zero. Let A|S| set non-optimal policieslet = min k v v k . Since v value function specific policy, follows that,right-hand side (7) smaller , v = v . Therefore, exists scalarmaxa k Pa Da K k < maxa k ra Da r k < policy returned PISF optimal.4. Computing Stochastic Factorizationshown previous section, PISFs performance depends crucially approximationsDa K Pa Da r ra , A. section discusses compute Da , K, r. startsgeneric presentation problem gradually focuses specific formulationssolved much efficiently.4.1 Optimization Problemorder facilitate exposition, assumed vectors ra matrices Paconcatenated stacked obtain single matrix R|S||A||S|+1 representing entire MDP,3. Ravindran Barto (2004) follow similar strategy bound approximation loss resulting approximatehomomorphism.774fiP OLICY TERATION BASEDfollows:M=r11...1r|S|...|A|r1...|A|r|S|p111...p1|S|1...|A|p11...|A|p|S|1TOCHASTIC FACTORIZATIONp112...p1|S|2...|A|p12...|A|p|S|2p11|S|...p1|S||S|...|A|p1|S|...|A|p|S||S|..........(11)representation above, objective factorization problem reduces finding matricesW DW M. formally, approximate factorization MDPformulated constrained nonlinear optimization problem following way:Problem 1. Given matrix R|S||A||S|+1 representing MDP, find R|S||A|m WRm|S|+1 order minimize dissimilarity measure (M, DW), subjected following constraints:di j 0 = 1, 2, ...|S||A| j = 1, 2, ..., m,(12)wi j 0 = 1, 2, ...m j = 2, 3, ..., |S| + 1,(13)= 1 =j=1 j|S|+1wi j = 1j=21, 2, ...|S||A|,(14)= 1, 2, ...m.(15)Note problem formulation assumes first column reservedrewards, (11). elements first column W subjectedstochasticity constraints (13) (15). |A| = 1 model Markov process. Also,problem statement easily modified reflect case represents Markov chain(that is, rewards Markov processsee Barreto & Fragoso, 2011).modification major impact discussion follow.hard see feasible region defined constraints optimizationproblem convex set. Thus, continuously differentiable, one resort one severalmethods presented Bertsekas (1999) solve constrained nonlinear optimization problemconvex feasible region. Among them, obvious choice probably gradient projectionmethod, candidate solution iteratively refined update rule keeps withinproblems feasible region. Another approach seems promising context blockcoordinate descent method (Bertsekas, 1999). case, subset variables updatedtime remaining kept fixed. optimization problem hand, twoblocks variables corresponding elements matrices W. Thus, iterationalgorithm one applies following update rules:argmin (M, DW)DDW argmin (M, W),WW(16)R|S||A|m W Rm|S|+1 feasible regions W, respectively. Dependingcharacteristics dissimilarity measure adopted, repeated application775fiBARRETO , P INEAU , & P RECUPupdate rules eventually converge stationary point (Grippo & Sciandrone, 2000).true, example, (M, DW) =k DW kF , k kF Frobenius norm (Cutler &Breiman, 1994; Lin, 2007b). k kF used, one compute W constrainedleast-squares algorithm (Cutler, 1993).solution two subproblems (16) may require large number arithmetic operations. Therefore, instead searching exact minima, one take small step per iterationtowards solution subproblem, much like conventional iterative descent methods (Lee& Seung, 2000). case, relatively simple enforce stochasticity constraints projecting partial solutions onto feasible region incorporating penalty termdissimilarity measure (Lee & Seung, 1997). noted, however, iterativeupdate rule used place (16), guarantee convergence solution may lost (Lin,2007a).ideas extensively exploited study related optimization problemknown nonnegative matrix factorization. name suggests, version problemconstraints (12) (13) normally imposed (Paatero & Tapper, 1994; Lee & Seung, 1999).many works available discussing theoretical practical aspects nonnegative matrixfactorization (for survey, see Berry et al., 2007). ideas discussed works alsoapply problem considered here. particular, since one derive stochastic factorizationnonnegative factorization stochastic matrix, algorithm designed latteralso used compute former (Cohen & Rothblum, 1991).Instead addressing Problem 1 generic nonnegative factorization, one exploitparticular structure matrices W. discussed Section 2.4, fact stochasticimplies exact factorization DW = possible rows insideconvex hull defined rows W. So, one try solve problem (approximately)computing convex hull contains rows determining coefficientsrecover mi convex combination vertices hullwhich naturally give risestochastic D. approach closely related Cutler Breimans (1994) archetypal analysisDing et al.s (2010) convex nonnegative factorization. also interesting connectionproblem known spectral unmixing field imaging spectroscopy,determination matrix W usually referred task extracting end-members (Keshava& Mustard, 2002; Keshava, 2003).Yet another way approaching Problem 1 impose additional constraints resortspecialized methods. Consider example case one nonzero elementper row. case, factorization seen specific instance well-known dataclustering problem: vectors mi must grouped clusters C j whose centersvectors wj common choice define centers wj = 1/|C j | {i|mi C j } mi =1/|C j | {i|di j =1} mi (Hartigan, 1975). goal clustering problem determine assignment vectors mi clusters C j order minimize (M, DW). Since W automaticallydefined given assignment, problem reduces computing matrix D. advantage interpreting factorization clustering problem availability large number algorithmsspecifically designed solve type optimization (Kaufman & Rousseeuw, 1990; Gan et al.,2007). Conveniently, depending defined, cluster centers wj naturally satisfystochasticity constraints (12), (13), (14), (15). case Frobenius normadopted objective function.776fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATION4.2 Reducing Computational Cost Factorizationwork presents stochastic factorization general approach reduce number statesMDP. course, main reason one would interested reduction savecomputational resources. One potential gain amount memory required representmodel. Nevertheless, paper mainly concerned use stochastic factorizationstrategy reduce time complexity dynamic programming algorithms, is, numberarithmetic operations performed search decision policy. case, computationalcost factorization process concern. particular, makes sense resortstochastic factorization number operations involved factorization process muchsmaller number operations saved replacing original model compact one.discussed, stochastic factorization problem equivalent nonnegative matrix factorization. Nonnegative matrix factorization popular research topic last years,result efficiency algorithms increasing steadilyin fact, nowadayspossible compute nonnegative factorizations large matrices matter minutes (Esseret al., 2012; Bittorf et al., 2012). Recently, Thurau et al. (2011, 2012) proposed efficient algorithms approximately compute convex hull contains rows M. show that,exploiting extra structure Problem 1, one compute approximation DW muchfaster algorithms treat problem conventional nonnegative factorization.also methods spectral unmixing problem specifically designed computationally efficient (Nascimento & Dias, 2004; Chang et al., 2006). Finally, one interprets Problem 1clustering task, possible approximate large matrices using recentlyproposed methods (Boutsidis et al., 2010; Shindler et al., 2011).principle, methods used compute approximation DWrequired PISF. able solve problem time linear number rows(Shindler et al., 2011; Thurau et al., 2012). Unfortunately, comes Problem 1,mean factorization depend linearly |S|. problem vectors milive R|S|+1 . implies number states MDP defines numbervectors mi (the number rows M), also dimension (the number columns M).consequence, even linear methods run O(|S|2 ) time.Depending size MDP computational resources available, quadratic dependency |S| may acceptable. many algorithms available case. example,Shindler et al.s (2011) clustering method deliver approximation DW O(|S|2 |A|m)time, corresponds iterations value iteration algorithm (Littman et al., 1995).also situations transition matrices Pa sparse, meaning execution action state si lead number states z |S|. case factorization problemsolved time linear |S|. remaining section focuses worst case scenario,is, case sparse quadratic dependency |S| acceptable.4.2.1 B REAKINGOUBLE EPENDENCYIZEMDPorder make stochastic factorization problem tractable large MDPs, one needs circumvent fact |S| defines number rows number columns M.strategy proposed section rewrite problem terms dissimilarity measure whosecomputation depend number states MDP.777fiBARRETO , P INEAU , & P RECUPLet dissimilarity measure defined R|S|+1 R|S|+1 (such distance function,example). section assume measure previously introduced induced .examples, let B two arbitrary matrices dimension. one have,instance,(A, B) (ai , bi ) =k B kF ,(ai , bi ) k ai bi kF(ai , bi ) k ai bi k1(A, B) maxi (ai , bi ) = k B k , (17)q(ai , bi ) k ai bi k2 (A, B) max [(ai bi )x]2 = max k (A B)x k2 , (18)x,kxk2 =1x,kxk2 =1k k2 Euclidean norm. Based expressions above, clear order minimize (DW, M) one focus instead minimizing ( j di j wj , mi ) i. One way lookingj di j wj mi think rows wj set prototypical vectors representativedynamics MDP M. Recalling row forms convex combination, element di j seen weight representative vector wj approximation mi (Cutler &Breiman, 1994; Keshava & Mustard, 2002). core assumption section that, general,di j decrease (mi , wj ). Although necessarily true exact factorization,many approximation schemes rely implicitly explicitly premise (Hastie et al., 2002).One example local kernel smoothing techniques Nadaraya-Watson kernel-weightedestimator (Hastie et al., 2002, Chap. 6). case, elements would computed as:di j =exp( (mi , wj )/ ),k exp( (mi , wk )/ )(19)controls relative magnitude elements one row matrix. generally,di j computed based function non-increasing respect (mi , wj ).assumption di j decreases (mi , wj ) makes possible compute based exclusively , example given (19). also possible compute W usingdissimilarity measure. example, Thurau et al. (2012) argue that, one restricts rows Wsubset rows M, minimization defined (18) accomplishedmaximization volume simplex defined rows W. Based concepts distance geometry, authors show possible efficiently compute volumesimplex defined candidate W using only. also several clustering algorithmsrequire distance matrix work, never accessing vectors mi directly (Kaufman &Rousseeuw, 1990). Finally, one derive simple heuristics use compute matrix Wcovers well possible convex set defined M, ensuring every row mi closeleast one representative vector wj . example, one adopt constructive method goesvectors mi successively adds new rows matrix W order guaranteemin j (mi , wj ) < i, predefined threshold. Notice case numberrepresentative rows wj automatically determined value . ideaexplored Section 4.2.2.obvious advantage computing DW based solely problem reducingcomputational cost factorization comes finding efficient ways computing. Specifically, one replace approximation whose computation requires fewerarithmetic operations. One way define restrict computation (mi , j ) properlydefined subset elements mi j corresponds enforcing degree778fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONsparsity (see Mahoney, 2011). section goes another direction, though: exploitsfact vector mi associated specific state-action pair often representedfeature vector whose dimension much smaller |S|.dynamic programmings perspective, state sk nothing index k {1, 2, ..., |S|}.However, MDP describing real decision problem, state clear semantic interpretation. general, given state MDP represented set features descriptivereal state problem. Based state features, usually easy define featurevectors represent state-action pairs. Therefore, thought finite subsetvector space; slight abuse notation (si , a) used refer vectors representingstate-action pairs dim(S A) denote number components (si , a).many cases, reasonable assume state-action features provide informationregarding dynamics MDP. precise, let dissimilarity measure definedA. assumption that, state-action pair (sk , a) similar state-action pair (sl , b),associated transition probabilities rewards also similarthat is, distancecorresponding vectors mi j small. Thus, one use surrogate .Note direct relationship naturally happen MDPresult discretization model continuous state space, long functions definingMDPs dynamics reasonably smooth resolution discretization sufficientlyfine. Moreover, often relative magnitude distance matters proper functioningalgorithms (Kaufman & Rousseeuw, 1990; Thurau et al., 2012). Therefore, approximation((sk , a), (sl , b)) C (mi , j ), C > 0, suffice many cases.strategy replacing dissimilarity measure defined state-action spaceresult significant computational savings dim(S A) |S| + 1. akin wellknown kernel trick, algorithm rewritten terms inner productsreplaced appropriately defined kernel (Scholkopf & Smola, 2002). kernel trick allowsone work high-dimensional feature spaces without ever explicitly computing features.Similarly, adopting algorithm based exclusively , replacing latter , onecompute approximation DW without ever manipulating vectors mi directly.strategy used algorithm computes W based . illustration,next section describes concrete algorithm that.4.2.2 N LGORITHMC OMPUTEFACTORIZATIONMDPL INEAR IMEprevious sections discussed several ways address stochastic factorization problem (Problem 1). approach advantages drawbacks, decision methodadopt take account factors like size problem, level accuracy requiredsolution, computational resources available. section describes detailspecific algorithm compute approximation DW M. objective provide illustration ideas described implemented, also make discussionregarding computational theoretical aspects factorization problem concrete.proposed method, described Algorithm 3, builds ideas discussed Section 4.2.1.strategy select subset rows form matrix W, row mirepresentative vector wj within predefined neighborhood. neighborhood induceddissimilarity measure defined A. mechanics method simple. goesstate-action pair MDP computes distance -closest neighbors779fiBARRETO , P INEAU , & P RECUPset E state-action pairs already selected part model (line 7 Algorithm 3).distance closest neighbor predefined threshold , corresponding rowadded W (lines 9 11). not, number representative state-action pairs remains same.Regardless whether model grown not, -closest neighbors used computeelements zth row D, z index current state-action pair (lines 1314). elements di j computed function increase (seediscussion Section 4.2.1 equation (19) example).Algorithm 3 Stochastic-factorization computationMDPR|S||A||S|+1 corresponding features (si , a): (S A) (S A) 7 R similarity functionRequire: : R 7 Rnon-decreasing functionR+neighborhood radiusNnumber neighbors approximationEnsure: Factorization DW1: E{(s1 , 0)}E representative state-action pairs (|E| = m)2: D0 R|S||A|1 ; Wm1 R1|S|+13: 1, 2, ..., |S|4:1, 2, ..., |A|5:z(a 1) |S| +z row index (si , a) (see (11))6:h min( , |E|)7:find h nearest elements (si , a) E according ; call jth closest pair (s, b) j8:((s, b)1 , (si , a)) >new representative state-action pair must added9:EE+ {(s,a)}W10:WAdd one row Wz11:D[ 0 ]Add one column12:j1, 2, ..., h13:k index (s, b) j W14:dzk ( ((s, b) j , (si , a)))15:|E|j1, 2, ..., |E| dz j dz j / l=1 dzlMake sure stochasticparameter strong effect output Algorithm 3: decreasing value usuallyleads accurate approximation DW M, also increases number representative state-action pairs (or, equivalently, representative vectors wj ). algorithm gostate-action pairs MDP order, end every pair least one representative counterpart within distance space (S A, ). However, since Algorithm 3greedy method, set state-action pairs selected part model may change depending order pairs visited. parameter determines numberrepresentative vectors wj used approximate mi , seen device controllocal approximation (this akin setting parameter k k-nearest neighborapproximation; see Hastie et al., 2002, Chap. 2, intuitive discussion). parameter alsodirect effect computational cost algorithm, discussed next.demanding operation iteration Algorithm 3 computation nearest neighbors current state-action pair. several efficient algorithms available780fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONperform search, either exactly approximately (Liu et al., 2005). popular exactmethod use KD-tree, takes O(dim(S A)m log m) operations constructedallows search performed O( log m) time, average (Friedman et al., 1977). SinceAlgorithm 3 performs |S||A| iterations, overall complexity linear |S|. Therefore, usingalgorithm build approximation DW M, assuming number iterationsperformed PISF much smaller |S|, cost entire process computing decisionpolicy depends linearly number states MDP. best one withoutassuming extra structure model.space complexity Algorithm 3, note actual implementation matrixreally necessary, neither W must explicitly stored: W representedm-dimensional vector containing indices representative state-action pairsdata structure |S||A| nonzero elements di j .mentioned, Algorithm 3 terminates state-action pairs MDP least onerepresentative state-action pair within neighborhood radius defined space (S A, ).order extrapolate guarantee performance PISF, necessary relate . Let(sk , a) (sl , b) two state-action pairs associated vectors mi j , respectively. Then,((sk , a), (sl , b)) < = (mi , j ) < ,(20)relatively straightforward provide guarantees regarding PISFs solution. example,(17) adopted = 1, one resort Proposition 3 obtain guarantees.specific scenarios easy ensure assumptions like (20) hold,example MDP results discretization continuous model. may alsopossible derive guarantees similar (20) based knowledge problem, examplelooking transition equations describing dynamics MDP. general, though, maydifficult relate . Note trivial modify Algorithm 3 reflect casecomputed based subset elements mi j . case deriving guaranteesanalogous (20) considerably easier (see example Mahoney, 2011).Algorithm 3 relies two premises: (i) given W, making elements di j inverselyproportional (mi , wj ) results good approximation DW M; (ii) possible definedissimilarity measure : (S A) (S A) 7 R ((sk , a), (sl , b)) C (mi , j ),C > 0, mi j rows associated (sk , a) (sl , b), respectively.important point building algorithm based assumptions one possibleartifice circumvent computational cost factoring MDP. strategies may possible,resorting domain knowledge developing methods exploit structural regularityMDP (see Section 5.3.3). fact, scenarios exact factorization readilyavailable without need computation (see Barreto, 2014, example). case,next section shows empirically Algorithm 3 generate good decision policiesproblems.5. Computational Experimentsection illustrates PISF useful practice real-world application significanteconomical interest.781fiBARRETO , P INEAU , & P RECUP5.1 Multicomponent-Replacement Decision TaskOne big challenges faced industry maintenance assets long period time.example, commercial airline cargo company must operational fleet, powercompany needs maintain electric power grid functioning times (Powell, 2007). manycases, maintenance expensive equipments involves sums money counted millionsdollars. situations, decisions made maintenance activities mayenormous economical impact.Usually, equipment jet engine electric generator composed several components degrade time. critical component breaks, replaced immediately.often case maintenance operation associated setup cost independent number components replaced. may financial losses causedtime costs associated activities disassembling equipment, delivery newcomponents, displacement specialists. Thus, circumstances, may advantageousperform opportunistic replacements functioning components avoid future setup costs.discussed, trade-off immediate future costs typical decision making tasks.importance decision problem described attested huge body literatureoriginated 1960s spanning subsequent four decades (Barlow & Proschan, 1965;McCall, 1965; Pierskalla & Voelker, 1976; Sherif & Smith, 1981; Cho & Parlar, 1991; Dekkeret al., 1997; Wang, 2002). problem formalized follows. Suppose assetinterest nc components let l j N+ denote expected lifetime component c j measureddiscrete time unit. Then, state si vector si Nnc whose jth entry si j representsremaining lifetime component c j . time step remaining lifetime c j decreasedone, si j = 0 indicates component longer operational. Even c j reachedend useful life, may fail given probability, function si j possiblycomponents remaining lifetimes siu . inactive component c j causes entire assetstop working, c j replaced immediately penalty takes place nexttransition. avoid that, one must replace c j , incurs cost r j dollars. top that,every replacement activityjoint nothas associated setup cost. setup cost composedtwo terms, fixed amount Rs dollars plus extra fee R f dollars chargedcomponent failed reaching expected lifetime. extra fee covers expenseslast-minute measures required unexpected failures. Let action represented binaryvector ah {0, 1}nc ah j = 1 indicates component c j replaced. goaldecision maker select action ah time step order minimize expecteddiscounted future cost.one see, problem suffers particularly severe version curse dimensionality: state space grow fast nc , |S| = (li + 1), also cardinalityaction space exponential function variable, since |A| = 2nc . Thus, even instancesproblem small number components already represent difficult challengedynamic programming.Given scalability issue, researchers usually focus particular cases multicomponentreplacement task whose structure exploited somehow. example, notedliterature failure cost R f considered state space multicomponentreplacement problem reduced 50% simply eliminating statescomponents functional (i.e., si j > 0 j). Since one knows optimal action782fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONexcluded states replace zero components, modification change optimalpolicy problem (see Sun et al., 2007; Arruda & Fragoso, 2011). Note thoughR f > 0 may advantageous carry replacements even components expired;seen, case reduction strategies cited may fail.Researchers practitioners also explored constrained versions multicomponent-replacement task. example, replacement costs r j lifetimes l jcomponents c j , permutations given vector si considered state,reduces state space considerably (Haurie & LEcuyer, 1982). Another simplificationproblem assume probability component c j failing independentcomponents remaining lifetimes siu . case, components relatedeconomical dependence represented setup cost (Cho & Parlar, 1991). resultingmodel, factored MDP, solved orders magnitude faster conventional MDP (seeSection 5.3.3). also possible reduce action space multicomponent maintenancetask making assumptions regarding problems dynamics (Xia et al., 2008).Although methods effective particular instances maintenancetask, directly applicable general version problem, components different characteristics depend economically structurally.Hence, practice industry often relies simple threshold policies replace componentsremaining lifetime given value (Haurie & LEcuyer, 1982; van der Duyn Schouten& Vanneste, 1990). Unfortunately, known that, general, optimal policy multicomponent-replacement problem lie space threshold decision policies (Ozekici,1988; Xia et al., 2008).5.2 Experimental Setupexperiments described section carried assuming general version maintenance task components interact other. failure probability component c jmodeled linear function assets general condition. Suppose asset state sidecision maker decides perform action ah . Then, denoting next state sk , probabilitycomponent c j failing is:P(sk j = 0 | si j > 1, ah j = 0) = f( f fmin )(si j 1) u6= j (lu siu ),+flj 1u6= j lu(21)f , fmin f parameters model assumed l j > 1 j. motivationequation (21) probability given component failing dependcondition component itself, also condition components asset.fact generalization commonly used model problem; f = fmin f = 0,equation (21) reduces fixed failure probability often assumed literature (Sun et al.,2007; Arruda & Fragoso, 2011). experiments, equation (21) considered f = 0.1,fmin = 0.01, f = 0.1. Thus, many components asset expire, probabilitycomponent c j failing double.formulation problem considered also general respect characteristics individual components asset. Instead assuming componentslifetime cost, seems unrealistic, variables l j r j drawn normaldistributions means l = 10 r = 10 common standard deviation lr = 3 (the values783fiBARRETO , P INEAU , & P RECUPsampled l j rounded closest natural number sampled case resultsmaller 2). configuration, expected value models parameters coincideones adopted Sun et al. (2007). constant term setup cost fixed Rs = 10failure cost set R f = 5nc . discussed above, R f > 0 might happen(si ) 6= 0 even si j > 0 j. increases effective size state space, since onecannot simply discard states without expired components.multicomponent-replacement task modeled discounted problem = 0.999(as discussed Puterman, 1994, case seen way emulating devaluationmoney). value nc {2, 3, ..., 7}, 100 instances problem randomly generated.policy iteration algorithm used find optimal policy resulting MDPs (seeAppendix A.3). means comparison, policy iteration also applied reduced versionproblem, state si removed MDP si j > 0 j. Notemodification requires recalculation transition probabilities statesremain model (Arruda & Fragoso, 2011). Here, order accomplish reduction, actionsreplaced temporally extended counterparts, options, giving rise semi-MDP(options closed-loop policies well-defined termination condition initiation set; seeSutton et al., 1999, details) .order evaluate heuristics usually adopted industry, threshold policies using valuesranging 1 10 considered. value nc , policies comparedone providing lowest expected cost used comparisons algorithms.Notice threshold policy using value 0 corresponds naive strategy replacing non-operational components. performance policy used baselinecomparisons.discussed Section 4, PISFs configuration comes definition matricesR|S||A|m W Rm|S|+1 . experiments section matrices computedAlgorithm 3. following function used similarity measure state-action pairs:((si , ah ), (sk , ag )) =ah 6= ag ,nc(1 ah j )|r j |(si j sk j )2 otherwise.j=1(22)intuition behind (22) straightforward: two state-action pairs considered similarif, application actions corresponding states, remaining lifetimescomponents approximately (except eventual failures). Note differenceremaining lifetimes si j sk j weighed magnitude cost r j replacingjth component. parameters Algorithm 3 defined follows. numberneighbors used approximation set nc , function defined constant1/ , neighborhood radius varied {200, 400, 600}. Since parametervaried across experiments, specific instances PISF referred PISF- (seeAppendix A.3 details regarding implementation PISF).5.3 ResultsThroughout section, following measure used evaluate algorithms:(v , v | S) =vi vi1,|S| {i | S} |vi |784(23)fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATION0.150.160.17PIPIREDBEST THRPISF200PISF400PISF6000.120.130.14(v, vN)23456Number components (nc)7Figure 2: Expected gain multicomponent-replacement problem respect naivedecision policy. Error bars represent one standard error 100 runs.v value function policy returned algorithm evaluation, vreference value function, set test states used evaluation (notetake negative values).5.3.1 TANDARD OLUTIONStwo natural ways addressing multicomponent-replacement problem use dynamic programming resort threshold policies normally adopted practice. sectioncompares methods PISF. performance measure used evaluate algorithmsrelative gain one expect using instead naively replacing componentfails. Hence, reference function v (23) value function naive policy, vN .nc 5, possible compute value functions v vN exactly, thuscase set appearing (23) entire state space S. However, nc > 5 computing vvN becomes infeasible computers used experiments. case composed10, 000 test states si sampled uniformly random S, corresponding values vi vi Napproximated Monte Carlo roll-outs length 5, 000.4Figure 2 compares results policy iteration (PI), policy iteration applied reducedversion problem (PI-RED), best threshold policy (BEST THR), PISF using = 200,= 400, = 600. One thing immediately stands figure fact performance optimal policies improves number components nc increases. indicatesfinancial losses company make opportunistic replacements increasenumber components asset.4. roll-outs truncated point value rewards (in case current application,dollars) already decreased 99% (that is, 5000 < 0.01).785fiBARRETO , P INEAU , & P RECUPTHR policies perform better naive policy general. Notice though resultsshown Figure 2 correspond performance best THR policy selected independentlyvalue nc . So, example, average gain provided best THR policync = 5 13.36%, average gain worst policy type 3.77%. means that,order achieve level performance shown Figure 2 real application, one cannotarbitrarily pick one specific THR policy. Rather, necessary model problemwilling systematically compare possible threshold values. Even case, resulting policy suboptimal. example, nc = 5, making optimal decisions increasesexpected profit best THR policy 27.8%, average (see Figure 2). Consideringamounts money often involved maintenance activities, difference represent significant monetary gains. good illustration impact dynamic programming maypractice.Unfortunately, dynamic programming scale well number componentsmulticomponent-replacement task. mentioned above, experiments describedoptimal policy could computed instances problem nc > 5. Sincestandard dynamic programming algorithms easy way control amount memoryused, one left alternatives. case multicomponent-replacement task, onepossibility eliminate states si > 0 apply dynamic programing reduced MDP.strategy reduces state space considerably, makes possible solve MDPs one ordermagnitude bigger (see Figure 2). Although technique works well version problemconsidered Arruda Fragoso (2011), may fail version problem considered here,optimal policy may carry opportunistic replacements states without expiredcomponents. illustrated PI-RED curve Figure 2, clearly showsoptimal policies reduced MDPs perform optimally original models.PISF represents alternative two extremes computing optimal policyresorting simple heuristics threshold policies. contrast conventional dynamicprogramming algorithms, PISF provides practical mechanism control trade-offcomputational resources used quality resulting decision policy (the orderstochastic factorization, indirectly defined neighborhood radius ). point betterillustrated Figure 2 analyzed conjunction Figure 3, shows sizemodels generated algorithm associated time needed solve them.dimension matrices processed algorithms value function computation defined number states corresponding Markov process. Thus, numbergood measure algorithms time space complexities. case policy iteration,defines size Markov processes number states MDP; PISF, number m, order stochastic factorization. size Markov processes generatedmethod shown Figure 3a. figure makes clear amount memory requiredmethods restricts application. example, PI-RED run MDPsnc = 7 components, resulting Markov processes would bigger largestmodel shown.expected, size Markov processes generated PISF decreases . TakeMDPs nc = 5, instance. case average reduction original models providedPISF 60% = 200, 88% = 400, 95% = 600. analyzingnumbers, one keep mind computational cost evaluating decision policycubic size Markov process. Thus, value functions computed exactly,786fi1e+06P OLICY TERATION BASEDTOCHASTIC FACTORIZATION15502e+050e+00PIPIREDPISF200PISF400PISF600Hours10Size4e+05 6e+058e+05PIPIREDPISF200PISF400PISF60023456Number components (nc)72(a) Size Markov processes3456Number components (nc)7(b) Run time (PISFs values include time compute MDP factorization Algorithm 3)Figure 3: Size models generated algorithms associated time needed computesolution. Error bars represent one standard error 100 runs.reduction 88% models size translates decrease 99, 82% number arithmeticoperations performed value-function computation.course, real application value function seldom computed exactly. Besides,order use PISF one compute factorization MDP. Even considering factors,replacing PI PISF result significant time savings. illustrated Figure 3b,shows actual run times algorithms. concrete example, take MDPsnc = 5 components. case, adopting PISF-600 instead PI results 97% reductioncomputing timewhich equivalent saying former algorithm 37 times fasterlatter. put number perspective, possible run PI MDPs nc = 7components, finding decision policy would take 8 days. PISF-600 able computeapproximation less 5 hours.reduction computational cost memory usage provided PISF meaningless resulting decision policies perform poorly. Comparing Figures 2 3, one clearlysee case multicomponent-replacement problem. example, replacing PI PISF-400, average reduction computing time 90% values nc .contrast, expected decrease profit 6.2%. one adopts PISF-600 insteadPISF-400, reduction computational cost least 94%, values nc ,associated losses 9.5%. illustrates PISFs performance degrades gracefully quality MDPs factorization, indicated theoretical results presentedSection 3.3.however clear decrease expected gain provided PISF nc increases6 7, shown Figure 2. One possible explanation fact multicomponentreplacement task increasing number components asset increases sizestate space S, also number actions A. means dimension787fiBARRETO , P INEAU , & P RECUPnumber matrices Pa increase exponentially nc , making harder summarizeinformation single matrix K. top that, perhaps important, keepingneighborhood radius fixed, relative size models generated PISF actually decreases.example, PISF-400, average ratio m/|S| equal 0.23 nc = 3, 0.12 nc = 5,0.06 nc = 7. Thus, order keep relative size fixed, must increasenc . case, even MDPs nc = 7 components PISF clearly outperforms best THRpolicy, feasible alternative among methods considered section. nextsections investigate approximate solutions multicomponent-replacement problem.5.3.2 U PPER C ONFIDENCE B OUNDSREES (UCT)possible compute optimal policy multicomponent-replacement problemnumber components asset certain threshold defined computationalresources available. threshold, standard solution adopted industry resortsimple heuristics. previous section presented PISF alternative solution allowscontrol trade-off computational resources used quality resulting policy. natural ask whether approximate methods would also applicablecase.Two popular approaches approximately solving MDP value-function approximationstate aggregation. techniques closely related stochastic-factorization trick,discussed Section 6. section focus set methods collectively knownMonte-Carlo tree search (MCTS). MCTS methods capable computing approximate solutionslarge MDPs combining tree search random sampling (Browne et al., 2012).methods receiving lot attention recently due enormous success severalapplications, notably game Go (Bouzy & Helmstetter, 2003). MCTS algorithms useMonte Carlo roll-outs estimate return associated actions available current state.order so, build tree, rooted current state, whose structure reflects transitionsperformed roll-outs.main feature distinguishes different MCTS algorithms strategy used selectactions roll-outs. popular MCTS algorithm Kocsis Szepesvaris (2006)upper confidence bounds trees (UCT). UCT action selection process interpretedmulti-armed bandit problem arm corresponds action (Auer et al., 2002).Intuitively, UCT works adding exploration bonus values actionstried less often. One main parameters algorithm exploration constant C p usedweigh bonus value actions (Kocsis & Szepesvari, 2006).UCT nice theoretical properties: given > 0, guaranteed return -optimalaction depth tree number roll-outs large enough (Kocsis & Szepesvari,2006). Therefore, given enough computation, UCT always able perform levelPISF (and eventually better, PISFs policy optimal). interesting question casemuch computation needed practice happen.order answer question, experiment carried UCT PISFcompared multicomponent-replacement problem. algorithms evaluated 100MDPs nc = 5 components described Section 5.2. before, performance resultingpolicies contrasted naive policy N . comparisons based singleroll-out starting state selected uniformly random independently MDP.788fiONTOCHASTIC FACTORIZATION0.2P OLICY TERATION BASED0.20.4UCT0.6(v, vN)0.0PISF6001357911Seconds per step (tmax)1315Figure 4: Expected performance multicomponent-replacement problem respectnaive decision policy. Error bars shadow represent three standard errors 100 runs.specifically, set test states appearing (23) composed single state si , and,before, corresponding values vi viN approximated Monte Carlo roll-outlength 5, 000.5described above, action selection UCT builds tree based Monte-Carlo rollouts. number roll-outs grows, quality value function approximation increases,computational cost algorithm. Thus, one way evaluating UCT imposetime limit tmax iteration algorithm check performance resulting policyfunction tmax . Note that, given fixed time budget tmax , trade-offnumber roll-outs carried length, finding right compromisetwo corresponds finding right balance bias variance value functionapproximation (Hastie et al., 2002). issue resolved changing maximum depthtree, hmax , set {5, 50, 500, 5000}.6 Also, UCTs exploration parameter C p varied{100 , 101 , 102 , 103 }. Therefore, MDP value tmax , UCT run 16 timescorresponding possible combinations values hmax C p , best resultselected compared naive policy (23). Figure 4 shows average value(v , vN ) function tmax . reference comparison, average result PISF-600MDPs also shown.shown Figure 4, UCT performs worse naive policy N tmax 15. Assuminglogarithmic trend shown figure persist tmax > 15, UCT would need 46 secondsper step reach level performance N . order find solutions comparablefound PISF-600, UCT would require around 115 seconds per step, approximately 1.74 timestime needed former algorithm compute decision policy entire state space.5. policies evaluated single test state nature UCT algorithm makes computationally impractical carry many roll-outs length 5, 000. case, small variance (23) acrossMDPs indicates decision strong effect comparisons.|S|6. Since |(vmax vmin )/v | < 0.002 MDPs, v = 1/|S| i=1 vi , value leaf nodes set zero.789fiBARRETO , P INEAU , & P RECUPNote that, even though time limit tmax = 15 seconds per step may seem like much first,run time UCT quickly escalates horizon problem. becomes clearone observes trajectory 5, 000 steps UCT using tmax = 15 takes 20 hours,computing optimal decision policy problem takes average 34 minutes.mentioned basic version UCT used experimentssection. Nowadays several extensions available literature (see example Chaslotet al., 2008; Gelly et al., 2012; Keller & Eyerich, 2012). strategies, built topUCT, tend improve performance. said, fact UCT needs orders magnitudecomputation PISF reach level performance surprising, sinceformer uses MDP generative modelthat is, algorithm samplesconditional distributions represented transition matriceswhile latter fully exploitsinformation available model.5.3.3 FACTORED MDPprevious section illustrated exploiting information available problemimportant computational efficiency. section shifts focus discussion anotherissue, namely structure model. particular, describes specific structured modelknown factored MDPs.factored MDP transition dynamics described dynamic Bayesian network(DBN, Dean & Kanazawa, 1989; Boutilier et al., 1995). Let s(t) s(t+1) denote, respectively,state current time next step. transition graph DBN two-layer directed(t+1)(t+1)(t)(t+1)(t)acyclic graph whose nodes variables set = {s(t)1 , s2 , ..., sn , s1 , s2 , ..., sn }.(t)(t+1)arc j si indicates value ith variable time + 1 depends valuejth variable time t. Let (si(t+1) ) denote set nodes arc si(t+1) . transitionmodel factored MDP given P(s(t+1) |s(t) ) = P(si(t+1) | (si(t+1) )). allows compactrepresentationand efficient solutionof factored MDP assumption DBN sparse,is, (si(t+1) ) restricted small subset i. addition, assumed rewardgiven summation functions depend status variables.assumptions hold, is, MDP truly factored, possible represent models dynamics compactly using structures like decision trees algebraic decision diagrams (Boutilieret al., 1995; Hoey et al., 1999). Therefore, number states MDP remains same;computational gain comes fact state space never explicitly enumerated.first, one might expect structure factored MDP would induce value functionsimilar structure. indeed case, would possible compute optimal policyfactored MDP much faster dynamic programming algorithms ignore modelsspecial structure. Unfortunately, Koller Parr (1999) shown that, general, valuefunction factored MDP factored. Therefore, practical algorithms developed factoredMDPs compute approximate solution (see Guestrin et al., 2003, references therein).factored MDP model captures dynamics many real-world decision-making tasks (Powell, 2007). fact, safe say MDPs solved using technique among largestsolved date (Guestrin et al., 2003, see also Section 5.4). However, decision problemsgreat interest whose dynamics satisfy assumptions models. versionmulticomponent-maintenance problem addressed good example: since probabilitygiven component failing depends condition components, resulting DBN790fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONsparse (cf. equation (21)). happens one ignores fact MDP trulyfactored applies algorithms developed assumption anyway?help answering question, experiment performed following way. Letone MDPs nc = 5 components described Section 5.2. component c jvalue z {1, 2, 3, 4}, set z (c j ) {1, 2, 3, 4, 5} { j} containing z distinct elementsgenerated uniformly random. Then, value z, transition matricesregenerated (21) replaced( f fmin )(si j 1) u/ z (c j ) (lu siu ) + uz (c j ) (lu lu /2),+flj 1u6= j lu(24)giving rise MDP Mz . Using (24) corresponds enforcing sparsity DBN describingcomponents failure probabilities. Note that, instead completely ignoring influencecomponents cu u z (c j ), remaining lifetimes replaced lu /2, middle pointrange possible values. way making factored model closer originalone without incurring denser DBN. transition matrices Mz generated, policyiteration used compute optimal policy, z (note computation exact). Finally,performance z original MDP compared , optimal policy(thus, experiment reference value function v appearing (23) v , = S).entire process repeated one 100 MDPs nc = 5 components.Figure 5a compares performance z , policies returned policy iterationartificially-factored MDPs (PI-FAC), PISF-200, PISF-400, PISF-600. Observeperformance PI-FAC degenerates level sparsity z artificially-factored MDPsincreases. expected, since derived models deviate original ones z approachesnc . Since computational cost algorithms developed factored MDPs decreasesz, one trade performance speed choosing interactions variablesignore. important point note fact PI-FAC outperformed instancesPISF z > 1. Since z optimal policy factored MDPs, performancebest one reasonably hope using algorithms approximate it. words,factored MDP algorithm using (24) outperform PISF multicomponent-replacement taskapproximation computes luckily induces policy performs better zoriginal, non-factored, MDP.experiment shows that, pretending non-factored MDP factored, one mayseverely restrict quality resulting policy, regardless specific algorithm chosensolve factored MDP. reason believe phenomenon restrictedmulticomponent-replacement domain. Thus, niche problems bigsolved standard dynamic programming cannot reliably solved algorithms developedfactored MDPs. problems, might good alternative resort algorithmsexploit types structure, PISF.say stochastic-factorization trick seen alternative factored MDPs. principle, properties MDP factored factorizable orthogonal other, therefore structures potentially exploited conjunction.illustrate point, experiment carried PISF THR policies runfactored MDPs Mz . Note difference respect previous experiment:models Mz considered approximations MDPs M, assumedtrue models. Thus, PISF THR policies compared optimal policies z .P(sk j = 0|si j > 1, ah j = 0) = f791fiBARRETO , P INEAU , & P RECUPPISF40023Level sparsity (z)0.140.05PIFAC10.060.100.03(v, vz*)0.02PISF6000.04(v, v*)0.020.01PISF2004(a) Artificially-factored MDPsBEST THRPISF 200PISF 400PISF 600123Level sparsity (z)4(b) Truly-factored MDPsFigure 5: Expected loss multicomponent-replacement problem respect optimaldecision policy. Error bars shadows represent one standard error 100 runs.idea investigate structure transition matrix induced sparse DBN affects PISFsperformance. Figure 5b shows performance PISF best THR policy factoredMDPs Mz function level sparsity z (cf. equation (24)). Although performancePISF degenerates slightly z increases, relative performance respect best THRpolicy generally improves model gets sparse.experiment illustrates stochastic-factorization trick potentially usefulcomputation policy factored MDP, may lead solution largesequential decision problems. course, order simultaneously exploit factoredfactorizable structures model, one apply trick without explicitly manipulatingmatrices involved. constitutes interesting extension current research, leftsuggestion future work.5.4 Discussionsection described application PISF large problem real interest. shown that,using Algorithm 3 compute W, possible handle MDPs whose exponentially largestate action spaces preclude use standard dynamic programming. largest instanceproblem solved PISF 39, 916, 800 states 128 actions, 359 times sizelargest MDP solved policy iteration. Note maintenance problem studiedtrivial define heuristics perform reasonably well, applications maytrue. example, Dekker et al. (1996) point multicomponent-replacement problemstructure similar important decision-making tasks arising productioninventory control. scenarios PISF even valuable tool.792fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONmentioned experiments section considered classical scenariodynamic programming, one seeks decision policy defined entire state space S.formulations decision problem possible. example, field automatedplanning often assumed decision maker must perform well small numberinitial states only, state si small set actions A(s) available (Ghallabet al., 2004; Geffner & Bonet, 2013). top that, sometimes assumed dynamicsMDP truly factored (Sanner, 2010). assumptions hold, possibledecision maker perform well visiting small fraction state space, and, sinceMDPs dynamics factored, sometimes even small subset must explicitly enumerated.Therefore, algorithms developed scenario applied large MDPs (Keller &Eyerich, 2012; Kolobov et al., 2012).PISF direct competitor planning algorithms developed scenariodesigned assumptions mind. Since PISF offline method computespolicy entire state space, never scale MDPs large handled on-linemethods compute policy demand, UCT. Similarly, MDP truly factoreddynamics favor methods exploit structure. hand, experimentssection show, assumptions underlie planning algorithms hold,largely outperformed PISF.end, determines success given algorithm suitability underlyingassumptions scenario interest. PISF developed MDPs factorizablenearly soa structural regularity exploited dynamic programming algorithm.often structure arises problems interest well exploited togetherassumptions, usually considered automated planning, interesting questionsaddressed future research.6. Related Worksection reviews approaches proposed circumvent dynamic programmings curse dimensionality, discusses methods relate stochasticfactorization trick.6.1 Value-Function ApproximationPerhaps straightforward approach deal large MDP use compact parametricrepresentation value function. new idea; fact, Bellman Dreyfus exploreduse polynomials approximate value function early 1959. Since theoryevolved lot, nowadays possible find books cover subject detail (Bertsekas& Tsitsiklis, 1996; Powell, 2007).main issue regarding use parametric representation value function damaging effect may dynamic programming algorithms. particular, well knownuse general approximators may cause instabilities even divergence algorithms (Boyan& Moore, 1995; Baird, 1995; Tsitsiklis & Roy, 1996, 1997). common strategy dealproblem restrict structure approximator compact representationslinear dependence parameters (Tsitsiklis & Roy, 1997; Tadic, 2001; Schoknecht & Merke,2003). Indeed, use linear approximators led number successful algorithms793fiBARRETO , P INEAU , & P RECUPgood convergence properties (Tsitsiklis & Roy, 1996; Bradtke & Barto, 1996; Perkins & Precup,2003; Lagoudakis & Parr, 2003; Sutton et al., 2008).evidence literature instability caused function approximators related tendency exaggerate difference two successive estimatesvalue function (Thrun & Schwartz, 1993; Gordon, 1995; Ormoneit & Sen, 2002). reason,many researches advocated use conservative function approximators computevalue state weighted average states values (Gordon, 1995; Tsitsiklis & Roy, 1996;Rust, 1997; Munos & Moore, 1999; Ormoneit & Sen, 2002; Szepesvari & Smart, 2004). Examplesapproximators include kernel averaging, linear interpolation, k-nearest neighbor,types splines. general, combination approximators dynamic programmingleads convergent algorithms (Gordon, 1995; Tsitsiklis & Roy, 1996).Conservative function approximators similar nature stochastic-factorization trick.see so, consider class function approximators Gordon (1995) calledaveragers. averager approximates value state convex combination statesvalues possibly predetermined constants. Given MDP (S, A, P, R, ), letsubset state space S, |S| = m, let v Rm represent values statessubset. averager would compute approximation value functionvi = di0 ci + j=1 di j v j ,(25)ci R, di j R+ mj=0 di j = 1. Since approximation scheme valuesstates determined values states S, latter must updateddynamic programmings iterative process.sake simplicity, suppose averager dio = 0{1, 2, ..., |S|}. case, approximate dynamic programming using (25) corresponds exact|S|version reduced MDP (S, A, P, R, ) Pa (s j |si ) = k=1 paik dk j ra (si ) = ra (si ) (Gordon, 1995, Thm. 4.1). model represents particular case stochastic-factorization tricksingle matrix R|S|m one matrix Ka Rm|S| (Barretoet al., 2011). dynamics reduced model given Pa = Ka D, Ka matrixcomposed rows original transition matrix Pa R|S||S| associated states si S.interpreting conservative approximators particular case stochastic-factorization trick,schemes similar (25) thought approximating MDP itself. Thus, definitionapproximators architecture configuration parameters converted welldefined optimization problem, objective find matrices Wa minimize(Ma , DWa ) A.6.2 Model ReductionAnother way handling large-scale decision-making problems find compact representationassociated MDP. case, simplest idea aggregate states share commoncharacteristic. many proposals type literature, distinguishescriterion used group states. detailed account model approximation techniques,reader referred review provided Li et al. (2006).One earliest works model approximation Bertsekas Castanon (1989),propose aggregating disaggregating states dynamically, value function computation, according residual left applications Bellman operator. alternative794fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONapproach group states based associated transition probabilities rewards. Followingline, Givan et al. (2003) suggest notion stochastic bisimulation criterion aggregatestates. Roughly speaking, two states bisimilar expected reward associatedaction, transition probabilities groups bisimilar states. notionclosely related Ravindrans (2004) concept homomorphism MDPs. bisimulation homomorphism principled criteria state aggregation, guaranteeoptimality decision policy lifted compact model. However, restrictiveapplied many real situations. Realizing that, several authors proposed relaxed versionscriteria (Dean et al., 1997; Ferns et al., 2006; Ravindran, 2004; Sorg & Singh, 2009).Regardless specific criterion used group states, state aggregation naturallyrepresented stochastic factorization. case, rows matrix W represent dynamicsassociated group matrix one nonzero element per row indicating groupstate-action pair belongs (note flexibility aggregating state-action pairs insteadstates only). context, applying stochastic-factorization trick corresponds computingprobabilities transitions groups. slightly general approach model reduction assume soft aggregation states, state belongs group givenprobability (Singh et al., 1995; Sorg & Singh, 2009). Soft aggregation also naturally representedstochastic factorization letting one nonzero element per row. fact,shown Sorg Singhs (2009) concept soft homomorphism equivalent particularcase stochastic-factorization trick discussed Section 6.1 (Barreto et al., 2011).one see, stochastic-factorization trick serve useful formalism thinkingstate aggregation. example, hard aggregation states corresponds matrixrow contains single 1 rows associated given state nonzero element column. soft aggregation state-action pairs restrictions removed.Also, single application trick leads (soft) homomorphism, successive applicationslead aggregation/disaggregation scheme similar Bertsekas Castanons (1989) approach.Perhaps important, conservative approximators, stochastic factorization turnsaggregation problem well defined optimization problem. provide unifying framework analysis, comparison, solution different versions aggregation problem.7. Conclusionapproach presented paper builds simple idea, called stochastic-factorizationtrick: given stochastic factorization transition probability matrix, one swap factorsmultiplication obtain another transition matrix, possibly much smaller original.property exploited reduce number states Markov process. Intuitively,stochastic-factorization trick corresponds creating small number representative states (orstate-action pairs) redirecting transitions original model according similaritymeasure. Formally, process posed well defined optimization problem.stochastic-factorization trick extended MDP least two ways: onefactor Markov process comes search decision policy factor Markovprocesses associated actions problem search begins. single matrix Ksingle vector r used latter, PISF algorithm used compute decisionpolicy problem hand. PISF reduces computational complexity standard policyiteration cubic dependence |S| function grows linearly size795fiBARRETO , P INEAU , & P RECUPMDP. PISF also enjoys nice theoretical guarantees, since always converges decisionpolicy whose performance improves quality MDPs factorization. generalfactorization improves order, m, one use parameter control trade-offuse computational resources performance resulting policy.order apply PISF decision-making problem, one must find approximate factorizationcorresponding MDP, DW. One way compute factorization see rowsW prototypical vectors represent dynamics interpret elementssimilarity measure vectors rows M. way, Wcomputed based dissimilarity measure defined problems state-action space A.technique allows approximation DW computed time linear |S|. Therefore,entire process computing decision policy PISF depend linearly numberstates MDP. Exploiting fact, PISF able find approximate solutions instancesimportant decision task 5 billion state-action pairs. solutions foundconsiderably better found heuristic commonly adopted practice.Evidently, paper exhaust discussion stochastic-factorization trickPISF. One subject calls investigation development alternative methodsefficiently compute matrices W (or identification scenarios factorizationavailable easy compute). Another promising research topic application stochasticfactorization trick factored MDPs types structured models. Finally, PISF may alsouseful context model-based reinforcement learning. case, instead collectingsample transitions order estimate parameters MDP M, one leverage use datafocusing prototypical state-action pairs represented W. W determined,elements computed based measure similarity defined A, doneexperiment presented paper. topics constitute interesting directions futureresearch.Appendix A. Modified Policy Iteration Modified PISFThroughout paper, assumed value function v computed exactly steppolicy iteration. facilitates analysis theoretical properties computationalcomplexity algorithms. However, ideas discussed extend naturally casev approximated.A.1 Modified Policy IterationPuterman Shins (1978) modified policy iteration, v estimated applications. Thus, case value function computation involves O(|S|2 t) operations. Decreasingreduces computational cost evaluating decision policy, general also increasesnumber policies must evaluated convergence (Puterman, 1994). Note= 1 one recovers value iteration algorithm. Similarly, |S| one simply compute vexactly solving associated linear system, comes conventional policy iteration.Therefore, value iteration policy iteration seen special cases modified policyiteration.amount memory used modified policy iteration depends specific implementation adopted. general, memory usage inversely proportional algorithms effective runtime. One extreme implementation strategy store one vector corresponding current796fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONestimate value function, v . Note though case multiplication P v requiresloading rows P secondary memory (or computing demand), thus significantlyincreasing algorithms run time. One speed algorithm keeping entire MDPloaded memory times, therefore increasing use memory O(|S|) O(|S|2 |A|).intermediate solution two extremes load (or compute) P valuefunction computation, leads O(|S|2 ) memory usage.A.2 Modified PISFdefinition modified PISF straightforward: change needed replace exactcomputation v line 6 Algorithm 2 applications v = r + P v. case, usingPISF instead modified policy iteration reduces computational cost value functioncomputation O(|S|2 t) O(m2t). reduction memory usage depends strategyused represent models, discussed Appendix A.1.clear using modified PISF = 1 corresponds combining stochasticfactorization trick value iteration. Note though that, terms computational cost, maybest alternative. discussed Appendix A.1, decreasing tends increase numberiterations performed PISF. iteration PISF involves building matrix computingmultiplication KD (lines 4 5 Algorithm 2, respectively), seen constructing operator current . Since construction takes O(|S|2 m) operationsapplication O(m2 ), one may wasting computational effort applyingoperator once.A.3 Implementation Detailsexperiments Section 5 performed using modified policy iteration modified PISF(Appendices A.1 A.2, respectively). Instead fixing value t, iterative value functioncomputation interrupted according stop criterion described Putermans (1994) Proposition 6.6.5, = 106 . Policy iteration PISF run two successive policiesidentical, shown Algorithms 1 2. matrices P modified policy iteration loadedvalue function computation, since represents compromise memory usagecomputational cost (see Appendix A.1). case PISF matrix K kept memorytimes; matrices computed demand iteration algorithm.statements Section 5 regarding algorithms computational requirements refer specificimplementation.AcknowledgementsPart work done Andre Barreto postdoctoral fellow School ComputerScience McGill University. authors would like thank Amir-massoud Farahmand validdiscussions, also anonymous reviewers suggestions improve paper.experiments run using computational resources made available Compute Canada CalculQuebec. Funding research provided Coordenacao de Aperfeicoamento de Pessoalde Nvel Superior (CAPES), National Institutes Health (grant R21 DA019800), NSERCDiscovery Grant program, Projets de Recherche en Equipe (FQRNT).797fiBARRETO , P INEAU , & P RECUPReferencesArruda, E., & Fragoso, M. D. (2011). Time aggregated Markov decision processes via standarddynamic programming. Operations Research Letters, 39(3), 25762580.Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis multiarmed banditproblem. Machine Learning, 47(2-3), 235256.Baird, L. C. (1995). Residual algorithms: Reinforcement learning function approximation.Proceedings International Conference Machine Learning (ICML), pp. 3037.Barlow, R. E., & Proschan, F. (1965). Mathematical Theory Reliability. Wiley.Barreto, A. M. S. (2014). Tree-based on-line reinforcement learning. Proceedings AAAIConference Artificial Intelligence.Barreto, A. M. S., & Fragoso, M. D. (2011). Computing stationary distribution finite Markovchain stochastic factorization. SIAM Journal Matrix Analysis Applications,32, 15131523.Barreto, A. M. S., Precup, D., & Pineau, J. (2011). Reinforcement learning using kernel-basedstochastic factorization. Advances Neural Information Processing Systems (NIPS), pp.720728.Bellman, R. E. (1957). Dynamic Programming. Princeton University Press.Bellman, R. E. (1961). Adaptive Control Processes. Princeton University Press.Bellman, R. E., & Dreyfus, S. (1959). Functional approximations dynamic programming. Mathematical Tables Aids Computation, 13(68), 247251.Berry, M. W., Browne, M., Langville, A. N., Pauca, V. P., & Plemmons, R. J. (2007). Algorithmsapplications approximate nonnegative matrix factorization. Computational StatisticsData Analysis, 52(1), 155173.Bertsekas, D. P. (1987). Dynamic programming: deterministic stochastic models. Prentice-Hall.Bertsekas, D. P. (1999). Nonlinear Programming (2nd edition). Athena Scientific.Bertsekas, D. P., & Castanon, D. A. (1989). Adaptive aggregation methods infinite horizondynamic programming. IEEE Transactions Automatic Control, 34(6), 589598.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.Bittorf, V., Recht, B., Re, C., & Tropp, J. A. (2012). Factoring nonnegative matrices linearprograms. Advances Neural Information Processing Systems (NIPS), pp. 12141222.Boutilier, C., Dearden, R., & Goldszmidt, M. (1995). Exploiting structure policy construction.Proceedings International Joint Conferences Artificial Intelligence (IJCAI), pp.11041113.Boutsidis, C., Zouzias, A., & Drineas, P. (2010). Random projections k-means clustering.Advances Neural Information Processing Systems (NIPS), pp. 298306.Bouzy, B., & Helmstetter, B. (2003). Monte-Carlo Go developments. Advances ComputerGames, pp. 159174.798fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONBoyan, J. A., & Moore, A. W. (1995). Generalization reinforcement learning: Safely approximating value function. Advances Neural Information Processing Systems (NIPS),pp. 369376.Bradtke, S. J., & Barto, A. G. (1996). Linear least-squares algorithms temporal differencelearning. Machine Learning, 22(1/2/3), 3357.Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P. I., Rohlfshagen, P., Tavener, S.,Perez, D., Samothrakis, S., & Colton, S. (2012). survey Monte Carlo tree search methods.IEEE Transactions Computational Intelligence AI Games, 4, 143.Chang, C.-I., Wu, C.-C., Liu, W., & Ouyang, Y. C. (2006). new growing method simplex-basedendmember extraction algorithm. IEEE Transactions Geoscience Remote Sensing,44(10), 28042819.Chaslot, G. M. J.-B., Winands, M. H. M., van den Herik, H. J., Uiterwijk, J. W. H. M., & Bouzy, B.(2008). Progressive strategies Monte-Carlo tree search. New Mathematics NaturalComputation, 4, 343357.Cho, D. I., & Parlar, M. (1991). survey maintenance models multi-unit systems. EuropeanJournal Operational Research, 51(1), 123.Cohen, J. E., & Rothblum, U. G. (1991). Nonnegative ranks, decompositions factorizationsnonnegative matrices. Linear Algebra Applications, 190, 149168.Cutler, A. (1993). branch bound algorithm constrained least squares. CommunicationsStatisticsSimulation Computation, 22(2), 395321.Cutler, A., & Breiman, L. (1994). Archetypal analysis. Technometrics, 36(4), 338347.Dean, T., Givan, R., & Leach, S. (1997). Model reduction techniques computing approximatelyoptimal solutions Markov decision processes. Proceedings Conference Uncertainty Artificial Intelligence (UAI), pp. 124131.Dean, T., & Kanazawa, K. (1989). model reasoning persistence causation. Computational Intelligence, 5(2), 142150.Dekker, R., Wildeman, R. E., & van Egmond, R. (1996). Joint replacement operational planning phase. European Journal Operational Research, 91(1), 7488.Dekker, R., Wildeman, R. E., & van der Duyn Schouten, F. A. (1997). review multi-componentmaintenance models economic dependence. Mathematical Methods Operations Research, 45, 411435.Denardo, E. V. (1967). Contraction mappings theory underlying dynamic programming.SIAM Review, 9(2), 165177.Ding, C. H. Q., Li, T., & Jordan, M. I. (2010). Convex semi-nonnegative matrix factorizations.IEEE Transactions Pattern Analysis Machine Intelligence, 32(1), 4555.Esser, E., Mller, M., Osher, S., Sapiro, G., & Xin, J. (2012). convex model nonnegative matrixfactorization dimensionality reduction physical space. IEEE Transactions ImageProcessing, 21(7), 32393252.Ferns, N., Castro, P. S., Precup, D., & Panangaden, P. (2006). Methods computing state similarityMarkov decision processes. Proceedings Conference Uncertainty ArtificialIntelligence (UAI), pp. 174181.799fiBARRETO , P INEAU , & P RECUPFriedman, J. H., Bentley, J. L., & Finkel, R. A. (1977). algorithm finding best matcheslogarithmic expected time. ACM Transactions Mathematical Software, 3(3), 209226.Gan, G., Ma, C., & Wu, J. (2007). Data Clustering: Theory, Algorithms, Applications. ASASIAM Series Statistics Applied Probability. SIAM.Geffner, H., & Bonet, B. (2013). Concise Introduction Models Methods AutomatedPlanning. Synthesis Lectures Artificial Intelligence Machine Learning. Morgan &Claypool Publishers.Gelly, S., Kocsis, L., Schoenauer, M., Sebag, M., Silver, D., Szepesvari, C., & Teytaud, O. (2012).grand challenge computer Go: Monte Carlo tree search extensions. Communications ACM, 55(3), 106113.Ghallab, M., Nau, D., & Traverso, P. (2004). Automated Planning: Theory & Practice. MorganKaufmann Publishers Inc.Givan, R., Dean, T., & Greig, M. (2003). Equivalence notions model minimization Markovdecision processes. Artificial Intelligence, 147(1-2), 163223.Golub, G. H., & Loan, C. F. V. (1996). Matrix Computations (3rd edition). Johns HopkinsUniversity Press.Gordon, G. J. (1995). Stable function approximation dynamic programming. ProceedingsInternational Conference Machine Learning (ICML), pp. 261268.Grippo, L., & Sciandrone, M. (2000). convergence block nonlinear Gauss-Seidelmethod convex constraints. Operations Research Letters, 26, 127136.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research, 19, 399468.Hartigan, J. A. (1975). Clustering Algorithms. John Wiley Sons.Hastie, T., Tibshirani, R., & Friedman, J. (2002). Elements Statistical Learning: Data Mining,Inference, Prediction. Springer.Haurie, A., & LEcuyer, P. (1982). stochastic control approach group preventive replacementmulticomponent system. IEEE Transactions Automatic Control, 27, 387393.Ho, N.-D., & van Dooren, P. (2007). Non-negative matrix factorization fixed row columnsums. Linear Algebra Applications, 429(56), 10201025.Hoey, J., St-Aubin, R., Hu, A. J., & Boutilier, C. (1999). SPUDD: Stochastic planning using decisiondiagrams. Proceedings Conference Uncertainty Artificial Intelligence (UAI),pp. 279288.Howard, R. (1960). Dynamic Programming Markov Processes. MIT Press.Kaufman, L., & Rousseeuw, P. J. (1990). Finding Groups Data: Introduction ClusterAnalysis. John Wiley Sons.Keller, T., & Eyerich, P. (2012). PROST: Probabilistic planning based UCT. ProceedingsInternational Conference Automated Planning Scheduling.Keshava, N. (2003). Survey Spectral Unmixing Algorithms. Lincoln Laboratory Journal,14(1), 5578.800fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONKeshava, N., & Mustard, J. (2002). Spectral unmixing. Signal Processing Magazine, 19, 4457.Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. ProceedingsEuropean Conference Machine Learning (ECML), pp. 282293.Koller, D., & Parr, R. (1999). Computing factored value functions policies structured MDPs.Proceedings International Joint Conference Artificial Intelligence (IJCAI), pp.13321339.Kolobov, A., Mausam, & Weld, D. S. (2012). LRTDP versus UCT online probabilistic planning.Proceedings AAAI Conference Artificial Intelligence.Lagoudakis, M. G., & Parr, R. (2003). Least-squares policy iteration. Journal Machine LearningResearch, 4, 11071149.Lee, D. D., & Seung, H. S. (1997). Unsupervised learning convex conic coding. AdvancesNeural Information Processing Systems (NIPS), pp. 515521.Lee, D. D., & Seung, H. S. (1999). Learning parts objects non-negative matrix factorization. Nature, 401, 788791.Lee, D. D., & Seung, H. S. (2000). Algorithms nonnegative matrix factorization. AdvancesNeural Information Processing Systems (NIPS), pp. 556562.Li, L., Walsh, T. J., & Littman, M. L. (2006). Towards unified theory state abstraction MDPs.Proceedings International Symposium Artificial Intelligence Mathematics,pp. 531539.Lin, C.-J. (2007a). convergence multiplicative update algorithms nonnegative matrixfactorization. IEEE Transactions Neural Networks, 18, 1589 1596.Lin, C.-J. (2007b). Projected gradient methods nonnegative matrix factorization. Neural Computation, 19(10), 27562779.Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solving Markovdecision problems. Proceedings Conference Uncertainty Artificial Intelligence(UAI), pp. 394402.Liu, T., Moore, A. W., Gray, A., & Yang, K. (2005). investigation practical approximatenearest neighbor algorithms. Advances Neural Information Processing Systems (NIPS),pp. 825832.Mahoney, M. W. (2011). Randomized algorithms matrices data. Foundations TrendsMachine Learning, 3(2), 123224.McCall, J. J. (1965). Maintenance policies stochastically failing equipment: survey. Management Science, 11, 493524.Munos, R., & Moore, A. (1999). Barycentric interpolators continuous space & time reinforcement learning. Advances Neural Information Processing Systems (NIPS), pp. 10241030.Nascimento, J. M. P., & Dias, J. M. B. (2004). Vertex component analysis: fast algorithm unmixhyperspectral data. IEEE Transactions Geoscience Remote Sensing, 43, 898910.Ormoneit, D., & Sen, S. (2002). Kernel-based reinforcement learning. Machine Learning, 49 (23),161178.801fiBARRETO , P INEAU , & P RECUPOzekici, S. (1988). Optimal periodic replacement multicomponent reliability systems. Operations Research, 36, 542552.Paatero, P., & Tapper, U. (1994). Positive matrix factorization: non-negative factor modeloptimal utilization error estimates data values. Environmetrics, 5, 111126.Perkins, T. J., & Precup, D. (2003). convergent form approximate policy iteration. AdvancesNeural Information Processing Systems (NIPS), pp. 15951602.Pierskalla, W. P., & Voelker, J. A. (1976). survey maintenance models: control surveillance deteriorating systems. Naval Research Logistics Quarterly, 23(3), 353388.Powell, W. B. (2007). Approximate Dynamic ProgrammingSolving Curses Dimensionality.John Wiley & Sons, Inc.Puterman, M. L. (1994). Markov Decision ProcessesDiscrete Stochastic Dynamic Programming.John Wiley & Sons, Inc.Puterman, M. L., & Shin, M. (1978). Modified policy iteration algorithms discounted Markovdecision problems. Management Science, 24(11), 11271137.Ravindran, B. (2004). Algebraic Approach Abstraction Reinforcement Learning. Ph.D.thesis, University Massachusetts, Amherst, MA.Ravindran, B., & Barto, A. G. (2004). Approximate homomorphisms: framework non-exactminimization Markov decision processes. Proceedings International ConferenceKnowledge Based Computer Systems.Rust, J. (1997). Using randomization break curse dimensionality. Econometrica, 65(3),487516.Sanner, S. (2010). Relational dynamic influence diagram language (RDDL): Language description.Schoknecht, R., & Merke, A. (2003). Convergent combinations reinforcement learning linear function approximation. Advances Neural Information Processing Systems (NIPS),pp. 15791586.Scholkopf, B., & Smola, A. (2002). Learning Kernels. MIT Press.Sherif, Y. S., & Smith, M. L. (1981). Optimal maintenance models systems subject failureareview. Naval Research Logistics Quarterly, 28(1), 4774.Shindler, M., Wong, A., & Meyerson, A. W. (2011). Fast accurate k-means large datasets.Advances Neural Information Processing Systems (NIPS), pp. 23752383.Singh, S. P., Jaakkola, T., & Jordan, M. I. (1995). Reinforcement learning soft state aggregation. Advances Neural Information Processing Systems (NIPS), pp. 361368.Sorg, J., & Singh, S. (2009). Transfer via soft homomorphisms. Autonomous Agents & MultiagentSystems/Agent Theories, Architectures, Languages, pp. 741748.Sun, T., Zhao, Q., & Luh, P. (2007). Incremental value iteration time-aggregated Markovdecision processes. IEEE Transactions Automatic Control, 52, 21772182.Sutton, R. S., Szepesvari, C., & Maei, H. R. (2008). convergent O(n) algorithm off-policytemporal-difference learning linear function approximation. Advances Neural Information Processing Systems (NIPS), pp. 16091616.802fiP OLICY TERATION BASEDTOCHASTIC FACTORIZATIONSutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: Introduction. MIT Press.Sutton, R. S., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: frameworktemporal abstraction reinforcement learning. Artificial Intelligence, 112, 181211.Szepesvari, C., & Smart, W. D. (2004). Interpolation-based Q-learning. ProceedingsInternational Conference Machine Learning (ICML), pp. 791798.Tadic, V. (2001). convergence temporal-difference learning linear function approximation. Machine Learning, 42(3), 241267.Thrun, S., & Schwartz, A. (1993). Issues using function approximation reinforcement learning. Proceedings Fourth Connectionist Models Summer School, pp. 255263.Thurau, C., Kersting, K., Wahabzada, M., & Bauckhage, C. (2011). Convex non-negative matrixfactorization massive datasets. Knowledge Information Systems, 29, 457478.Thurau, C., Kersting, K., Wahabzada, M., & Bauckhage, C. (2012). Descriptive matrix factorizationsustainability adopting principle opposites. Data Mining Knowledge Discovery,24(2), 325354.Tsitsiklis, J. N., & Roy, B. V. (1996). Feature-based methods large scale dynamic programming.Machine Learning, 22, 5994.Tsitsiklis, J. N., & Roy, B. V. (1997). analysis temporal-difference learning functionapproximation. IEEE Transactions Automatic Control, 42, 674690.van der Duyn Schouten, F. A., & Vanneste, S. G. (1990). Analysis computation (n, n)strategies maintenance two-component system. European Journal OperationalResearch, 48(2), 260274.Vavasis, S. A. (2009). complexity nonnegative matrix factorization. SIAM JournalOptimization, 20, 13641377.Wang, H. (2002). survey maintenance policies deteriorating systems. European JournalOperational Research, 139(3), 469 489.White, D. J. (1985). Real applications Markov decision processes. Interfaces, 15, 7383.White, D. J. (1988). real applications Markov decision processes. Interfaces, 18, 5561.White, D. J. (1993). survey applications Markov decision processes. JournalOperational Research Society, 44(11), 10731096.Whitt, W. (1978). Approximations dynamic programs, I. Mathematics Operations Research,3(3), 231243.Xia, L., Zhao, Q., & Jia, Q.-S. (2008). structure property optimal policies maintenanceproblems safety-critical components. IEEE Transactions Automation Science Engineering, 5(3), 519531.803fiJournal Artificial Intelligence Research 50 (2014) 697-722Submitted 10/13; published 07/14MDD Propagation Sequence ConstraintsDavid Bergmandavid.bergman@business.uconn.eduSchool Business, University Connecticut2100 Hillside Road, Unit 1041, Storrs, CT 06260Andre A. CireWillem-Jan van Hoeveacire@andrew.cmu.eduvanhoeve@andrew.cmu.eduTepper School Business, Carnegie Mellon University5000 Forbes Avenue, Pittsburgh, PA 15213 USAAbstractstudy propagation Sequence constraint context constraint programming based limited-width MDDs. first contribution proving establishingMDD-consistency Sequence NP-hard. Yet, also show task fixed parameter tractable respect length sub-sequences. addition, proposepartial filtering algorithm relies specific decomposition constraintnovel extension MDD filtering node domains. experimentally evaluate performance proposed filtering algorithm, demonstrate strengthMDD propagation increases maximum width increased. particular, MDD propagation outperform conventional domain propagation Sequence reducingsearch tree size solving time several orders magnitude. Similar improvementsobserved respect current best MDD approach applies decompositionSequence Among constraints.1. Introductioncentral inference process constraint programming constraint propagation (Rossi,van Beek, & Walsh, 2006; Dechter, 2003; Apt, 2003). traditional constraint processingtechniques designed explicitly defined relations small arity, state-of-the-art constraint programming solvers apply specialized constraint propagation algorithms globalconstraints arity, often based efficient combinatorial methods networkflows (van Hoeve & Katriel, 2006; Regin, 2011).Conventional constraint propagation algorithms (or domain filtering algorithms) operate individual constraints given problem. role identify removevalues variable domains inconsistent respect constraintconsideration. Whenever domain variable updated (i.e., value removed),constraints variable appears reconsidered inspection.cascading process propagating changes variable domains constraintscontinues fixed point reached. constraint programming solvers assumevariable domains finite, ensures termination constraint propagationprocess. Note constraint propagation may sufficient determineresolution given problem. Therefore, constraint propagation normally appliedsearch state systematic search process.c2014AI Access Foundation. rights reserved.fiBergman, Cire & van Hoevemajor benefit propagating variable domains implemented efficientlymany cases. However, inherent weakness domain propagation implicitlyrepresents Cartesian product variable domains potential solution space.communicating domain changes, limits amount information sharedconstraints.address shortcoming domain propagation, Andersen, Hadzic, Hooker,Tiedemann (2007) proposed use multi-valued decision diagrams (MDDs) alternative variable domains context constraint propagation. MDDs directedacyclic layered graphs can, principle, compactly represent solutions combinatorial problem (Wegener, 2000). Andersen et al. (2007) showed MDDs limitedwidth provide much stronger relaxation solution space traditionalCartesian product variable domains, consequence MDDs allow representcommunicate refined information constraints. propagating MDDsrather variable domains, huge reductions search tree size computation timerealized (Andersen et al., 2007; Hadzic, Hooker, OSullivan, & Tiedemann, 2008a;Hadzic, Hooker, & Tiedemann, 2008b; Hadzic, OMahony, OSullivan, & Sellmann, 2009;Hoda, van Hoeve, & Hooker, 2010; Cire & van Hoeve, 2012, 2013).MDDs used represent individual (global) constraints, subsets constraints,constraints given problem. representing individual constraints,work Hawkins, Lagoon, Stuckey (2005) Cheng Yap (2008), higher-levelinformation carried MDD lost projecting variable domainstraditional domain propagation. highest potential MDD propagation insteadappears representing specific subsets constraints within MDD. is,given set constraints, create maintain one single limited-width MDD,propagated constraint set. Since MDD defined respectfixed variable ordering, useful select subset constraints compatibleordering. applied way, MDD propagation implemented parallelexisting domain propagation constraint programming systems, thus complementingpotentially strengthening domain propagation process. example, Cire van Hoeve(2013) introduced MDD propagation subset constraints representing disjunctivescheduling problems. embedded custom global constraint ILOG CPOptimizer constraint programming solver, greatly improved performance.1.1 MethodologyConstraint propagation based limited-width MDDs amounts MDD filtering MDDrefinement. role MDD filtering algorithm remove provably inconsistent arcsMDD (Hadzic et al., 2008b; Hoda et al., 2010). MDD refinement algorithmhand, aims splitting nodes MDD accurately reflect solutionspace (Hadzic et al., 2008a). order make approach scalable efficient, refinementalgorithms must ensure MDD remains within given maximum size (typicallyrestricting maximum widththe number nodes layer). increasingmaximum width, MDD relaxation strengthened desired level.is, maximum width 1 would correspond traditional Cartesian productvariable domains, infinite maximum width would correspond exact MDD698fiMDD Propagation Sequence Constraintsrepresenting solutions. However, increasing size MDD immediately impactscomputation time, one typically needs balance trade-off strengthMDD associated computation time.order characterize outcome MDD filtering algorithm, notion MDDconsistency introduced Andersen et al. (2007), similar domain consistencyfinite-domain constraint programming: Given MDD, constraint MDD consistentarcs MDD belong least one solution constraint. consequencericher data structure MDD represents, establishing MDD consistency maydifficult establishing domain consistency. example, Andersen et al. showestablishing MDD consistency Alldifferent constraint NP-hard,establishing traditional domain consistency done polynomial time (Regin, 1994).1.2 Contributionsmain focus paper Sequence constraint, defined specific conjunction Among constraints, Among constraint restricts occurrenceset values sequence variables within lower upper bound (Beldiceanu& Contejean, 1994). Sequence constraint finds applications in, e.g., car sequencingemployee scheduling problems (Regin & Puget, 1997; van Hoeve, Pesant, Rousseau, &Sabharwal, 2009). known classical domain consistency established Sequence polynomial time (van Hoeve, Pesant, Rousseau, & Sabharwal, 2006; van Hoeveet al., 2009; Brand, Narodytska, Quimper, Stuckey, & Walsh, 2007; Maher, Narodytska,Quimper, & Walsh, 2008; Downing, Feydy, & Stuckey, 2012). Furthermore, Hoda et al.(2010) present MDD filtering algorithm Among constraints establishing MDD consistency polynomial time. However, remained open question whether MDDconsistency Sequence established polynomial time well.work, answer question negatively first contribution showingestablishing MDD consistency Sequence constraint NP-hard.important result perspective MDD-based constraint programming. Namely,global constraints, Sequence constraint perhaps suitable combinatorialstructure MDD approach; prescribed variable ordering, combines subconstraints contiguous variables, existing approaches handle constraintfully using bounds reasoning only.second contribution, show establishing MDD consistency Sequence constraint fixed parameter tractable respect lengths subsequences (the Among constraints), provided MDD follows order Sequence constraint. proof constructive, follows generic algorithm filterone MDD another.third contribution partial MDD propagation algorithm Sequence,necessarily establish MDD consistency. relies decomposition Sequencecumulative sums, new extension MDD filtering informationstored nodes.last contribution experimental evaluation proposed partial MDD propagation algorithm. evaluate strength algorithm MDDs various maximumwidths, compare performance existing domain propagators Sequence.699fiBergman, Cire & van Hoevealso compare algorithm currently best known MDD approach usesnatural decomposition Sequence Among constraints (Hoda et al., 2010).experiments demonstrate MDD propagation outperform domain propagationSequence reducing search tree size, solving time, several orders magnitude. Similar results observed respect MDD propagation Among constraints.results thus provide evidence power MDD propagation contextconstraint programming.remainder paper structured follows. Section 2, provide necessary definitions MDD-based constraint programming Sequence constraint.Section 3, present proof establishing MDD consistency Sequence NPhard. Section 4 describes establishing MDD consistency fixed parameter tractable.Section 5, partial MDD filtering algorithm presented. Section 6 shows experimental results. present final conclusions Section 7.2. Definitionsfirst recall basic definitions MDD-based constraint programming, followingwork Andersen et al. (2007) Hoda et al. (2010). work, ordered MultivaluedDecision Diagram (MDD) directed acyclic graph whose nodes partitioned n + 1(possibly empty) subsets layers L1 , . . . , Ln+1 , layers L1 , . . . , Ln correspondrespectively variables x1 , . . . , xn . L1 contains single root node r, Ln+1 containssingle terminal node t. node u MDD, let L (u) denote indexlayer. MDD , width w(M ) maximum number nodes layer,maxni=1 {|Li |}. MDD-based CP, MDDs typically given fixed maximum width.arcs MDD directed upper lower layer; is, nodeLi node Lj < j. purposes convenient assume(without loss generality) arc connects two adjacent layers. arclayer Li labeled element domain D(xi ) xi . arc a, referlabel represents `(a). notational convenience, also write `(u, v) instead`((u, v)) arc (u, v). element D(xi ) appears labelarcs given node u Li . set A(u, v) arcs node u node v maycontain multiple arcs, denote label. Let (u) denote set arcscomingfi node u. define size anfi MDD number arcs, i.e.,|M | = fi{a | (u), u Li , = 2, . . . , n + 1}fi.arc label v leaving node layer represents assignment xi = v.path MDD r denoted arc labels v1 , . . . , vn pathidentified solution (x1 , . . . , xn ) = (v1 , . . . , vn ). path v1 , . . . , vn feasiblegiven constraint C setting (x1 , . . . , xn ) = (v1 , . . . , vn ) satisfies C. Constraint C feasibleMDD MDD contains feasible path C.constraint C called MDD consistent given MDD every arc MDDlies feasible path. Thus MDD consistency achieved redundant arcs(i.e., arcs feasible path) removed. also say MDD MDDconsistent respect C. Domain consistency C equivalent MDD consistencyMDD width one represents variable domains. is, equivalent700fiMDD Propagation Sequence ConstraintsMDD consistency MDD layer Li contains single node si ,A(si , si+1 ) = D(xi ) = 1, . . . , n.Lastly, formally recall definitions Among (Beldiceanu & Contejean, 1994),Sequence (Beldiceanu & Contejean, 1994), Gen-Sequence (van Hoeve et al., 2009)constraints. Among constraint counts number variables assignedvalue given set S, ensures number given lower upperbound:Definition 1 Let X set variables, l, u integer numbers 0 l u |X|,xX D(x) subset domain values. define Among(X, l, u, S)Xl(x S) u.xXNote expression (x S) evaluated binary value, i.e., resulting 1 x0 x/ S. Sequence constraint conjunction given Among constraintapplied every sub-sequence length q sequence n variables:Definition 2 Let X ordered set n variables, q, l, u integer numbers0 q n, 0 l u q, xX D(x) subset domain values.Sequence(X, q, l, u, S) =nq+1^Among(si , l, u, S),i=1si represents sub-sequence xi , . . . , xi+q1 .Finally, generalized Sequence constraint extends Sequence constraint allowingAmong constraints specified different lower upper bounds, subsequence length:Definition 3 Let X ordered set n variables, k natural number, ~s, ~l, ~u vectorslength k si sub-sequence X, li , ui N, 0 li ui n = 1, 2, . . . , k,xX D(x) subset domain values.Gen-Sequence(X, ~s, ~l, ~u, S) =k^Among(si , li , ui , S).i=13. MDD Consistency Sequence NP-Hardstated before, known non-trivial NP-hardness result global constraintcontext MDD-based constraint programming Andersen et al. (2007)Alldifferent constraint. challenge determining whether global constraintmade MDD consistent polynomial time must guaranteedgiven MDD. is, addition combinatorics global constraint itself,shape MDD adds another layer complexity establishing MDD consistency.proving NP-hardness, particular difficulty making sure reduction, MDDremains polynomial size. Sequence constraints, far unknown whetherpolynomial-time MDD consistency algorithm exists. section answer questionnegatively prove following result.701fiBergman, Cire & van HoeveTheorem 1 Establishing MDD consistency Sequence arbitrary MDD NPhard even MDD follows variable ordering Sequence constraint.Proof. proof reduction 3-SAT, classical NP-complete problem (Garey& Johnson, 1979). show instance 3-SAT satisfiedparticular Sequence constraint particular MDD polynomial size solution.Therefore, establishing MDD consistency Sequence arbitrary MDD leasthard 3-SAT.Consider 3-SAT instance n variables x1 , . . . , xn , consisting clauses c1 , . . . , cm .first construct MDD represents basic structure 3-SAT formula (seeExample 1 proof illustration). introduce binary variables yi,j i,jrepresenting literals xj xj per clause ci , = 1, . . . , j = 1, . . . , n (xj xjmay may exist ci ). order variables sequence , first indexclauses, index variables, yi,j , i,j clause ci variablexj . is, = y1,1 , 1,1 , y1,2 , 1,2 ,. . . ,y1,n , 1,n , . . . , ym,1 , m,1 , . . . ,ym,n , m,n .construct MDD layered graph, k-th layer corresponds k-thvariable sequence .clause ci represented 2n consecutive layers corresponding yi,1 , . . . , i,n .part MDD, identify precisely paths lead solution satisfyingclause. basis diamond structure pair literals (yi,j , i,j ),assigns either (0, 1) (1, 0) pair. variable appear clause,represent using diamond part MDD representing clause, thusensuring variable take assignment respect clause.variables appear clause, explicitly list allowed combinations.precisely, clause ci , first define local root node ri representing layer L (yi,1 ),set tag(ri ) = unsat. node u layer L (yi,j ) (for j = 1, . . . , n),following. variable xj appear ci , tag(u) sat, create two nodes v, v 0L i,j , one single node w L (yi,j+1 ), arcs (u, v) label 1, (u, v 0 ) label 0,(v, w) label 0, (v 0 , w) label 1. corresponds diamond structure.set tag(w) = tag(u). Otherwise (i.e., tag(u) unsat yi,j appears ci ), createtwo nodes v, v 0 L i,j , two nodes w, w0 L (yi,j+1 ), arcs (u, v) label 1, (u, v 0 )label 0, (v, w) label 0, (v 0 , w0 ) label 1. ci contains literal yi,j , settag(w) = sat tag(w0 ) = unsat. Otherwise (ci contains i,j ), set tag(w) = unsattag(w0 ) = sat.procedure initialized single root node r representing L (y11 ).iteratively append MDDs two consecutive clauses ci ci+1 merging nodeslast layer ci marked sat single node, let nodelocal root ci+1 . finalize procedure merging nodes last layermarked sat single terminal node t. construction, ensure oneyij ij set 1. Furthermore, variable assignment correspondingpath layers L (yi,1 ) L (yi+1,1 ) satisfy clause ci , exactly n literalschosen accordingly path.next need ensure feasible path MDD, variable xjcorrespond literal yi,j i,j clause ci . end, impose702fiMDD Propagation Sequence Constraintsrc1:0:1y1,1y1,1y1,2y1,2y1,3y1,3y1,4y1,4c2y2,1y2,1y2,2y2,2y2,3y2,3y2,4y2,4Figure 1: MDD corresponding Example 1.constraintSequence(Y, q = 2n, l = n, u = n, = {1})(1)MDD described above. sub-sequence length 2n starts positiveliteral yi,j , definition exactly n variables take value 1. sub-sequencestarts negative literal i,j instead, last variable sequence correspondsvalue xj next clause ci+1 , i.e., yi+1,j . Observe variables exceptfirst last sequence take value 1 already n 1 times. Therefore,first last variable sequence (which represent xj complement xjorder), one take value 1. is, xj must take value clause cici+1 . Since holds sub-sequences, variables xj must take valueclauses.MDD contains 2mn + 1 layers, layer contains six nodes.Therefore, polynomial size (in size 3-SAT instance), overall construction needs polynomial time.703fiBergman, Cire & van Hoeve:0:1x101x200011011000110110001101100011011x3x4x5x6Figure 2: exact MDD Sequence constraint Example 2.Example 1 Consider 3-SAT instance four Boolean variables x1 , x2 , x3 , x4 clausesc1 = (x1 x3 x4 ) c2 = (x2 x3 x4 ). corresponding MDD used reductiongiven Figure 1.4. MDD Consistency Sequence Fixed Parameter Tractablesection show establishing MDD consistency Sequence arbitraryMDD fixed parameter tractable, respect length sub-sequences q.already shown van Hoeve et al. (2006, 2009) exact MDD Sequenceconstraint exists O(n2q ) nodes (i.e., unfolded automaton Regular constraint), illustrated next example.Example 2 Consider constraint Sequence(X, q = 3, l = 1, u = 2, = {1})X = {x1 , x2 , . . . , x6 } ordered set binary variables. corresponding exact MDD,following order X, presented Figure 2. convenience, node MDDlabeled last q 1 labels represent sub-sequence node (startingq 1 layers up). example, second node third layer represents decisions x1 = 0x2 = 1, corresponding sub-sequence 01. construct next layer, either append0 1 sub-sequence (and remove first symbol), leading nodes labeled 1011, respectively. Note nodes labeled 00 must take arc label 1,l = 1. Similarly nodes labeled 11 must take arc label 0, u = 2. q704fiMDD Propagation Sequence Constraintslayers, possible sub-sequences created (maximally O(2q1 )), thus defineswidth subsequent layers.However, since given arbitrary MDD, necessarily exact MDD, needadditional steps exploit connection. apply generic approachshow fixed parameter tractability Sequence, fact applieddetermine whether MDD consistency tractable constraint.goal establish MDD consistency given MDD respect anotherMDD 0 set variables. compatible earlier definitions since0 interpreted define constraint. is, MDD consistent respect0 every arc belongs path (solution) also exists 0 . purposes,assume 0 follow variable ordering.establish MDD consistency first taking intersection 0 ,removing arcs compatible intersection. Computingintersection two MDDs well-studied, present top-down intersection algorithmfollows definitions Algorithm 1. description adapted meldingprocedure presented Knuth (2009).intersection MDD, denoted I, represents possible paths (solutions)present 0 . partial path root rI node u thusexist 0 , respective endpoints v, v 0 . information capturedassociating node u state s(u) = (v, v 0 ) representing nodes vv 0 0 . root initialized rI s(rI ) := (r, r0 ) r r0respective roots 0 (lines 1-2). algorithm then, top-down traversal,considers layer LIi I, augments node u LIi s(u) = (v, v 0 ) arc0 arc label v v 0 respectively (lines5-7). next layer already contains node u state re-use node.Otherwise add new node u LIi+1 add arc (u, u) I. Note last layercontains single terminal tI state s(tI ) = (t, t0 ), provided empty.last step (line 14) clean removing arcs nodes belongfeasible path. done bottom-up traversal I. Observe algorithmnecessarily create reduced MDD.Algorithm 2 presents algorithm establish MDD-consistency respect0. first compute intersection 0 (line 1). traversetop-down traversal, layer LMidentify remove infeasible arcs. this,define Boolean array Support[u, l] (initialized 0) represents whether arcnode u label l support (line 3). line 4, consider arcslayer LIi I. arc = (v, v) exists LIi label l s(v) = (u, u0 ), markassociated arc u supported setting Support[u, l] := 1 (lines 4-6).remove arcs LMsupport (lines 7-9). Lastly, cleanremoving arcs nodes belong feasible path (line 11).Theorem 2 Algorithm 2 establishes MDD-consistency respect 0 O(|M |w(M 0 ) time space.Proof. correctness Algorithm 1 follows induction number layers.prove Algorithm 2 establishes MDD-consistency, consider arc = (u, u)705fiBergman, Cire & van HoeveAlgorithm 1 Intersection(M ,M 0 )Input: MDD root r, MDD 0 root r0 . 0 definedordered sequence n variables.Output: MDD layers LI1 , . . . , LIn+1 arc set AI . node uassociated state s(u).1: create node r state s(r ) := (r, r 0 )2: LI1 := {r }3: = 1 n4:LIi+1 := {}5:u LIi s(u) = (v, v 0 )6:= (v, v) a0 = (v 0 , v 0 ) 0 `(a) = `(a0 )7:create node u state s(u) := (v, v 0 )8:w LIj+1 s(w) = s(u) u := w9:else LIi+1 += u end10:add arc (u, u) label `(a) arc set AI11:end12:end13: end14: remove arcs nodes path r tI LIn+115: returnAlgorithm 2 MDD-Consistency(M ,M 0 )Input: MDD root r, MDD 0 root r0 . 0 definedordered sequence n variables.Output: MDD-consistent respect 01: create := Intersection(M ,M 0 )2: = 1 n3:create array Support[u, l] := 0 u LMarcs u label l4:arcs = (v, v) AI s(v) = (u, u0 ) v LIi5:Support[u, `(a)] := 16:end7:arcs = (u, u) u LM8:Support[u, `(a)] = 0 remove end9:end10: end11: remove arcs nodes path r LMn+112: return706fiMDD Propagation Sequence Constraintsapplying algorithm. exists node v s(v) = (u, u0 ) solutionsrepresented paths r u r0 u0 0 equivalent.also exists arc aI = (v, v) AI label a. Consider s(v) = (w, w0 ). Sincedecision diagrams, label appears arc node.Therefore, w = u. Since aI belongs I, exist paths w (or u)w0 t0 0 equivalent. Hence, belongs feasible path (from ru, along u terminating t) equivalent path exists 0(from r0 u0 , w0 terminating t0 ).Regarding time complexity computing intersection, coarse upper boundmultiplies n (line 3), w(M ) w(M 0 ) (line 5), d2max (line 6), dmax representsmaximum degree node, maxxX |D(x)|. amortize steps since forloops lines 3 6 consider arc comparison arcs 0 . arccompared w(M 0 ) arcs (line 6); assume check constanttime whether node outgoing arc given label (using arc-label list).gives total time complexity O(|M | w(M 0 )). memory requirements boundedsize intersection, O(n w(M ) w(M 0 ) dmax ) = O(|M | w(M 0 )).dominates complexity Algorithm 2, since lines 2-12 performed lineartime space (in size ).Observe Algorithm 2 longer ensures solution representedpath 0 , case intersection. MDD-consistency merely establishesarc belongs solution also 0 . Although MDD intersectionsstronger MDD consistency, limitation width intersectionMDD may large product widths 0 . Therefore intersectingmultiple MDDs will, general, increase size resulting MDD exponentially.next apply Theorem 2 Sequence constraint.Corollary 1 Let X ordered sequence variables, C = Sequence(X, q, l, u, S)sequence constraint, arbitrary MDD following variable ordering X. Establishing MDD consistency C fixed parameter tractable respect parameter q.Proof. know exists exact MDD 0 size O(n2q1 ) represents C(van Hoeve et al., 2006, 2009). Applying Theorem 2 gives MDD-consistency algorithmtime space complexity O(|M | 2q1 ), result follows.note Theorem 2 also applied obtain tractability establishingMDD consistency constraints. Consider example constraint Among(x1 , x2 ,. . . , xn , l, u, S). variable ordering, construct exact MDD top-downprocedure associating node v number variables taking value alongpath r v, representing length path. Nodes lengthequivalent merged. largest layer u + 1 different pathlengths, exact MDD size O(nu), Theorem 2 establishing MDD consistencytractable Among. Indeed, Hoda et al. (2010) also showed MDD consistencyestablished constraint, quadratic time complexity.707fiBergman, Cire & van Hoeveconverse Theorem 2 hold: exist constraints MDDconsistency established polynomial time given MDD, minimalreduced exact MDD hasPexponential size. specific example, consider linear inequalityconstraints form ni=1 ai xi b xi integer variable, ai constant,= 1, . . . , n, b constant. MDD consistency established constraintslinear time, given MDD, computing arc longest r-t path (relativecoefficients ai ) uses arc (Andersen et al., 2007). However, Hosaka, Takenaga,Kaneda, Yajima (1997)provide following explicit linear inequality. k evenPn = k 2 , consider 1i,jk aij xij k(22k 1)/2, xij binary variable,aij = 2i1 + 2k+j1 , 1 i, j k. show that, variable order,sizen/2reduced ordered BDD inequality bounded (2).5. Partial MDD Filtering Sequencemany practical situations value q lead prohibitively large exact MDDsestablishing MDD consistency, limits applicability Corollary 1. Thereforenext explore practical partial filtering algorithm polynomial also q.One immediate approach propagate Sequence constraint MDDsnatural decomposition Among constraints, apply MDD filtering algorithmsAmong proposed Hoda et al. (2010). However, well-known classicalconstraint propagation based variable domains, Among decomposition substantially improved dedicated domain filtering algorithm Sequence (van Hoeveet al., 2006, 2009; Brand et al., 2007; Maher et al., 2008). Therefore, goal section provide MDD filtering Sequence stronger practice MDDfiltering Among decomposition, stronger domain filtering Sequence.follows, assume MDD hand respects ordering variablesSequence constraint.5.1 Cumulative Sums Encodingproposed algorithm extends original domain consistency filtering algorithmSequence van Hoeve et al. (2006) MDDs, following cumulative sums encoding proposed Brand et al. (2007). representation takes following form.sequence variables X = x1 , x2 , . . . , xn , constraint Sequence(X, q, l, u, S),first introduce variables y0 , y1 , . . . , yn , respective initial domains D(yi ) = [0, i]Pi = 1, . . . , n. variables represent cumulative sums X, i.e., yi representsj=1 (xj S) = 1, . . . , n. rewrite Sequence constraint followingsystem constraints:{1, . . . , n},(2)yi+q yi l{0, . . . , n q},(3)yi+q yi u{0, . . . , n q},(4)yi = yi1 + (xi ): X {0, 1} indicator function set S, i.e., (x) = 1 x(x) = 0 x/ S. Brand et al. show establishing singleton bounds consistencysystem suffices establish domain consistency original Sequence constraint.708fiMDD Propagation Sequence Constraintsorder apply similar reasoning context MDDs, crucial observationdomains variables y0 , . . . , yn naturally represented nodesMDD. words, node v layer Li represents domain yi1 , restrictedsolution space formed r-t paths containing v. Let us denote informationnode v explicitly interval [lb(v), ub(v)], refer node domainv. Following approach Hoda et al. (2010), compute information lineartime one top-down pass, using equation (2), follows:lb(v) = min(u,v)Ain (v) {lb(u) + (`(u, v))} ,ub(v) = max(u,v)Ain (v) {ub(u) + (`(u, v))} ,(5)nodes v 6= r, [lb(r), ub(r)] = [0, 0].individual Among constraints posted yi+q yi l yi+q yi u,also need compute node v layer Li+1 ancestors layer Li .done maintaining vector Av length q + 1 node v, Av [i] representsset ancestor nodes v i-th layer v, = 0, . . . , q. initializeAr = [{r}, , . . . , ], apply recursionAv [i] = (u,v)Ain (v) Au [i 1]= 1, 2, . . . , q,Av [0] = {v}.resulting top-down pass takes linear time (in size MDD), directimplementation recursive step node takes O(q (w(M ))2 ) operationsMDD . Now, relevant ancestor nodes node v layer Li+q stored Av [q],subset layer Li . similarly compute descendant nodes v vector Dvlength q + 1, Dv [i] contains descendants v i-th layer v,= 0, 1, . . . , q. initialize Dt = [{t}, , . . . , ].However, purposes need maintain minimum maximum valueunion domains Av , resp., Dv , constraints (3) (4) inequalities;see application Av Dv rules (8) below. makes recursive stepefficient, taking O(qw(M )) operations per node.Alternatively, approximate information maintaining minimummaximum node domain value layer, instead list ancestor layers.compromise filtering, may efficient practice, requiresmaintain two integers per layer.5.2 Processing Constraintsnext process constraints (2), (3), (4) turn remove provably inconsistent arcs, time filter node information.Starting ternary constraints type (2), remove arc (u, v) lb(u) +(`(u, v)) > ub(v). Updating [lb(v), ub(v)] node v done similar rules (5)above:lb(v) = max lb(v), min(u,v)Ain (v) {lb(u) + (`(u, v))} ,(6)ub(v) = min ub(v), min(u,v)Ain (v) {ub(u) + (`(u, v))} ,709fiBergman, Cire & van Hoeve:0:1y0[0,0[0,0]x1x1[0,0][0,0][1,1]y1[1,1]x2x2[0,0][2,2][1,1][0,0][2,2][1,1]y2x3x3[1,1][0,2][2,3][1,1][2,2][2,2]y3x4x4[1,1][0,2][1,4][1,1][2,2][3,3]y4x5x5[2,4][0,5]a. Initial MDDb. Node domainsy5c. MDD filteringFigure 3: MDD propagation constraint Sequence(X, q = 3, l = 1, u = 2, = {1})Example 3.fact, resulting algorithm special case MDD consistency equality propagator Hadzic et al. (2008a), thus inherit MDD consistency ternaryconstraints.Next, process constraints (3) (4) node v layer Li+1 (i = 0, . . . , n).Recall relevant ancestors Li+1q Av [q], relevant descendantsLi+1+q Dv [q]. variable corresponding node v yi , participatesfour constraints:yi l + yiq ,yi u + yiq ,(7)yi yi+q l,yi yi+q u.Observe apply constraints filter node domain [lb(v), ub(v)]corresponding yi . Namely, node domains corresponding variables yiqyi+q may find support nodes layer Li+1 v. update lb(v)ub(v) according equations (7):lb(v) = max{ lb(v),l + min lb(u),uAv [q]ub(v) = min{ ub(v), u + max ub(u),uAv [q]min lb(w) u },wDv [q]max ub(w) l }.(8)wDv [q]resulting algorithm specific instance generic MDD consistent binaryconstraint propagator presented Hoda et al. (2010), inherit MDDconsistency constraints. process constraints linear time (in sizeMDD) top-down bottom-up pass MDD.710fiMDD Propagation Sequence ConstraintsExample 3 Consider constraint Sequence(X, q = 3, l = 1, u = 2, = {1})ordered sequence binary variables X = {x1 , x2 , x3 , x4 , x5 }. Assume givenMDD Figure 3.a. Figure 3.b. show node domains result processingrules (5). Figure 3.c. shows resulting MDD processing constraints viarules (6) (8). example, consider middle node fourth layer, correspondingvariable y3 . Let node v. initial domain [0, 2], Av [q] containsroot node, domain [0, 0]. Since l = 1, reduce domain v [1, 2].next consider arcs v, conclude value 1 domain supported.reduces domain v [2, 2], allows us eliminate one incoming arc(from first node previous layer).resulting MDD Figure 3.c. reflects possible deductions madepartial algorithm. established MDD consistency however, witnessedinfeasible path (1, 1, 0, 0, 0).Observe proposed algorithm applied immediately generalGen-Sequence constraints Among constraint individual l, u q.cumulative sums encoding adjusted straightforward manner representdifferent values.5.3 Formal Analysisnext formally compare outcome partial MDD filtering algorithm MDDpropagation Among encoding domain propagation Sequence. First,recall following theorem.Theorem 3 (Brand et al., 2007, Thm. 4) Bounds consistency cumulative sumsencoding incomparable bounds consistency Among encoding Sequence.Note since variable domains Among cumulative sums encodingranges (intervals integer values), bounds consistency equivalent domain consistency.Corollary 2 MDD consistency cumulative sums encoding incomparable MDDconsistency Among encoding Sequence.Proof. apply examples proof Theorem 4 work Brand et al..Consider constraint Sequence(X, q = 2, l = 1, u = 2, = {1}) orderedsequence binary variables X = {x1 , x2 , x3 , x4 } domains D(xi ) = {0, 1} =1, 2, 4, D(x3 ) = {0}. apply trivial MDD width 1 representing Cartesianproduct variable domains. Establishing MDD consistency cumulative sumsencoding yieldsy0 [0, 0], y1 [0, 1], y2 [1, 2], y3 [1, 2], y4 [2, 3],x1 {0, 1}, x2 {0, 1}, x3 {0}, x4 {0, 1}.Establishing MDD consistency Among encoding, however, yieldsx1 {0, 1}, x2 {1}, x3 {0}, x4 {1}.711fiBergman, Cire & van HoeveConsider constraint Sequence(X, q = 3, l = 1, u = 1, = {1}) orderedsequence binary variables X = {x1 , x2 , x3 , x4 } domains D(xi ) = {0, 1} =2, 3, 4, D(x1 ) = {0}. Again, apply MDD width 1 representing Cartesianproduct variable domains. Establishing MDD consistency cumulative sumsencoding yieldsy0 [0, 0], y1 [0, 0], y2 [0, 1], y3 [1, 1], y4 [1, 1],x1 {0}, x2 {0, 1}, x3 {0, 1}, x4 {0},establishing MDD consistency Among encoding prune value.additional illustration Corollary 2, consider Example 3 Figure 3. MDDpropagation Among encoding eliminate value x4 = 0 infeasiblepath (1, 1, 0, 0, 0), whereas example showed MDD propagation cumulative sumsdetect this.Theorem 4 MDD consistency cumulative sums encoding Sequence incomparable domain consistency Sequence.Proof. first example proof Corollary 2 also shows domain consistencySequence stronger MDD consistency cumulative sums encoding.show opposite, consider constraint Sequence(X, q, l, u, = {1}) setbinary variables arbitrary size, arbitrary values q, l, u = |X| 1. LetMDD defined X consisting two disjoint paths r t: arcs one pathlabel 0, arcs value 1. Since projection ontovariable domains gives x {0, 1} x X, domain consistency deduceinfeasibility. However, establishing MDD consistency respect cumulativesums encoding detect this.Even though formally MDD propagation based cumulative sums incomparabledomain propagation Sequence MDD propagation Among constraints,next section show practice algorithm reduce search spaceorders magnitude compared methods.6. Computational Resultspurpose computational results evaluate empirically strength partial MDD propagator described Section 5. perform three main comparisons. First,want assess impact increasing maximum width MDD filtering.Second, want compare MDD propagation classical domain propagationSequence. particular, wish evaluate computational overhead MDDpropagation relative domain propagation, extent MDD propagationoutperform domain propagation. Third, compare filtering strength MDDpropagator Sequence filtering strength MDD propagators individual Among constraints, best MDD approach Sequence far (Hoda et al.,2010).712fiMDD Propagation Sequence Constraintsimplemented MDD propagator Sequence custom global constraintIBM ILOG CPLEX CP Optimizer 12.4, using C++ interface. Recall Section 5applying rules (8) either maintain minimum maximum value qprevious ancestors descendants node, approximate maintainingvalues simply layer. evaluated strategies found latterreduce amount filtering, nonetheless resulted much efficient performance(about twice fast average). Hence, reported results use implementation.MDD propagator Among, apply code (Hoda et al., 2010).domain propagation, applied three models. first uses domain consistent propagator Sequence van Hoeve et al. (2009), running O(n3 ) time. second usesdomain consistent propagator Sequence based network flow representationMaher et al. (2008), runs O(n2 ) time.1 third model, applied decomposition cumulative sums, uses explicit global constraint Sequence.Propagating decomposition also takes O(n2 ) worst case, considers O(n) variables constraints variable domains contain n elements. notealmost test instances, cumulative sums encoding established domain consistencySequence. additional advantage, cumulative sums encoding permitsinsightful comparison MDD propagator, since based cumulativesums decomposition.note Brand et al. (2007) introduce multiple-Sequence constraintrepresents conjunction multiple Sequence constraints set orderedvariables (as experimental setup). Narodytska (2011) shows establishing boundsconsistency system already NP-hard, presents domain consistent propagatorencodes system automaton Regular constraint. algorithm runsO(nmq ) time, n represents number variables, number Sequenceconstraints, q length largest subsequence.order compare algorithms multiple-Sequence constraint, conducted experiments identify suitable testbed. found instancesmultiple-Sequence constraint would run memory could solved instantlyusing domain propagator individual Sequence constraints, creatingdata structures multiple-Sequence constraint took substantially time average. instances challenging (as described next sections),multiple-Sequence constraint could applied due memory issues. thereforeexcluded algorithm comparisons sections below.single Sequence constraints solved polynomial time, considerinstances multiple Sequence constraints experiments. assumedefined ordered set variables. measure impact differentpropagation methods correctly, approaches apply fixed search strategy, i.e.,following given ordering variables, lexicographic value ordering heuristic.method, measure number backtracks failed search state wellsolving time. experiments performed using 2.33GHz Intel Xeon machine.1. thank Nina Narodytska sharing implementation us.713fiBergman, Cire & van Hoeve6.1 Systems Sequence Constraintsfirst consider systems multiple Sequence constraints defined setvariables. generate instances n = 50 variables domain {0, 1, . . . , 10},5 Sequence constraints. Sequence constraint, set length subsequence uniform randomly [5, n/2)q = (rand()%((n/2) 5)) + 5.Here, rand() refers standard C++ random number generator, i.e., rand()%k selectsnumber range [0, k 1]. Without minimum length 5, many instanceswould easy solve either method. next define difference lu := (rand()%q), setl := (rand()%(q )),u := l + .Lastly, define set values first defining cardinality (rand()%11) + 1,selecting many values uniformly random {0, 1, . . . , 10}. generated 250instances total.2solve instance using domain consistency propagator Sequence,cumulative sums encoding (domain propagation), MDD propagator maximumwidths 2, 4, 8, 16, 32, 64, 128. method given maximum time limit 1,800 secondsper instance.compare performance domain propagation MDD propagation Figure 4. figure, report given time point many instances couldsolved within time specific method. three domain propagation methodsrepresented Cumulative Sums (the cumulative sums decomposition), Sequence - HPRS(the Sequence propagator van Hoeve et al., 2006, 2009), Sequence - Flow (theflow-based propagator Maher et al., 2008). Observe cumulative sums domainpropagation, although guaranteed establish domain consistency, outperformsdomain consistent Sequence propagators. Also, MDD propagation maximum width2 already substantially outperform domain propagation. observelarger maximum widths require time MDDs processed, endallow solve instances: maximum MDD width 128 permits solve 250instances within given time limit, whereas domain propagation respectively solve220 (Sequence - Flow), 230 (Sequence - HPRS), 232 (Cumulative Sums) instances.illustrate difference domain MDD propagation detail, Figure 5 presents scatter plots comparing domain propagation (cumulative sums) MDDpropagation (maximum width 32). comparison particularly meaningfulpropagation methods rely cumulative sums representation. instance,Figure 5.a depicts number backtracks Figure 5.b depicts solving timemethods. instances solved within time limit collected(time out) method. Figure 5.a demonstrates MDD propagation leaddramatic search tree reductions, several orders magnitude. Naturally, MDD2. instances available http://www.andrew.cmu.edu/user/vanhoeve/mdd/.714fi200150100MDD Width 128MDD Width 32MDD Width 2Domain (Cumulative Sums)Domain (Sequence HPRS)Domain (Sequence Flow)050Number instances solved250MDD Propagation Sequence Constraints102101100101102103Time(s)Figure 4: Performance comparison domain MDD propagators Sequenceconstraint. data point reflects total number instances solvedparticular method within corresponding time limit.propagation comes computational cost, Figure 5.b shows almost instances (especially harder ones), search tree reductions correspond faster solvingtimes, often several orders magnitude.next evaluate impact increasing maximum widths MDD propagator.Figure 6, present method survival function respect numberbacktracks (a.) solving time (b.). Formally, applied combinatorial backtrack search algorithms, survival function represents probability run takingx backtracks (Gomes, Fernandez, Selman, & Bessiere, 2005). case,approximate function taking proportion instances need least x backtracks (Figure 6.a), respectively seconds (Figure 6.b). Observe log-log plots.respect search tree size, Figure 6.a clearly shows strengthening MDDpropagation maximum width increased. particular, domain propagationreflects linear behavior several orders magnitude typical heavy-tailedruntime distributions. Naturally, similar behavior present MDD propagation,much weaker form increasing maximum MDD widths. associated solving timespresented Figure 6.b. reflects similar behavior, also takes accountinitial computational overhead MDD propagation.715fi102101100102101MDD Propagator (Width 32) Time (s)106104102100MDD Propagator (Width 32) Backtracks103Bergman, Cire & van Hoeve100102104106102101100101102103Domain Propagator (Cumulative Sums) Time (s)Domain Propagator (Cumulative Sums) Backtracksb. Solving timea. Number backtracksFigure 5: Comparing domain MDD propagation Sequence constraints. datapoint reflects number backtracks (a.) resp. solving time seconds (b.)specific instance, solved best domain propagator (cumulativesums encoding) MDD propagator maximum width 32. Instanceseither method needed 0 backtracks (a.) less 0.01 seconds (b.)excluded. Here, stands timeout represents specific instancecould solved within 1,800s (Fig. b.). Figure a., instanceslabeled separately (at tick-mark 108 ); note reported numberbacktracks 1,800 seconds may much less 108 instances.reported instances fewer 108 backtracks solved within timelimit.6.2 Nurse Rostering Instancesnext consider structured problem class inspired nurse rostering problems.problem design work schedule nurse given horizon n days.day, nurse either work day shift (D), evening shift (E), night shift (N),day (O). introduce variable xi day = 1, . . . , n, domainD(xi ) = {O, D, E, N } representing shift. impose eight Sequence constraintsmodeling requirements listed Table 1.combinatorial nature problem, size CP search tree turnslargely independent length time horizon, lexicographic search (byincreasing day i) applied. however consider instances various time horizons(n = 40, 60, 80, 100), address potential scaling issues.results presented Table 2. columns Domain Sequence show totalnumber backtracks (BT) solving time seconds (CPU) domain consistentSequence propagator. Similarly, columns Domain Cumul. Sums show infor716fiMDD Propagation Sequence Constraints1.00.50.10.05Survival function0.1Domain ConsistencyMDD Width 2MDD Width 4MDD Width 8MDD Width 16MDD Width 32MDD Width 64MDD Width 1280.005 0.010.050.005 0.01Survival function0.51.0Domain ConsistencyMDD Width 2MDD Width 4MDD Width 8MDD Width 16MDD Width 32MDD Width 64MDD Width 128100101102103104105106107102Backtracks101100101102103Time (s)a. Survival function respect backtracksb. Survival function respect solving timeFigure 6: Evaluating impact increased width MDD propagation via survival function plots respect search backtracks (a.) solving time (b.). plotslog-log scale. data point reflects percentage instances require least many backtracks (a.) resp. seconds (b.) solvedparticular method.RequirementSequence(X, q, l, u, S)least 20 work shifts every 28 days:least 4 off-days every 14 days:1 4 night shifts every 14 days:4 8 evening shifts every 14 days:Nights shifts cannot appear consecutive days:2 4 evening/night shifts every 7 days:6 work shifts every 7 days:Sequence(X, 28, 20, 28, {D, E, N })Sequence(X, 14, 4, 14, {O})Sequence(X, 14, 1, 4, {N })Sequence(X, 14, 4, 8, {E})Sequence(X, 2, 0, 1, {N })Sequence(X, 7, 2, 4, {E, N })Sequence(X, 7, 0, 6, {D, E, N })Table 1: Nurse rostering problem specification. Variable set X represents shiftsassigned sequence days. possible shifts day (D), evening (E),night (N), day (O).mation cumulative sums domain propagation. subsequent columns shownumbers MDD propagator, MDDs maximum width 1, 2, 4, 8. Notepropagating MDD width 1 corresponds domain propagation, indeed associated number backtracks equivalent domain propagator cumulative sums.first observation, maximum width 2 already reduces number backtracksfactor 8.3. maximum width 8 MDD propagation even allows solve717fiBergman, Cire & van Hoeven406080100DomainSequenceBTCPU438,059 43.83438,059 78.26438,059 124.81438,059 157.75DomainCumul. SumsBTCPU438,059438,059438,059438,05932.2653.4071.3396.27MDDWidth 1BTCPU438,059 54.27438,059 80.36438,059 106.81438,059 135.37MDDWidth 2BTCPU52,44352,44352,44352,44312.9218.3628.5837.76MDDWidth 4BT CPU4394394394390.440.680.941.22MDDWidth 8BT CPU00000.020.040.060.10Table 2: Comparing domain propagation MDD propagation Sequence nurserostering instances. Here, n stands number variables, BT numberbacktracks, CPU solving time seconds.problem without search. computation times correspondingly reduced, e.g.,157s (resp. 96s) domain propagators 0.10s MDD propagator (width 8)instance n = 100. Lastly, observe case MDD propagationsuffer scaling issues compared domain propagation.final remark, also attempted solve nurse rostering instances usingSequence domain propagator CP Optimizer (IloSequence). able solveinstance n = 40 1,150 seconds, none others instances solved withintime limit 1,800 seconds.6.3 Comparing MDD Filtering Sequence Amonglast experiment, compare Sequence MDD propagator MDD propagator Among constraints Hoda et al. (2010). main goal determine whetherlarge MDD sufficient solve problem (irrespective propagating Amongcumulative sums decomposition), whether additional information obtainedSequence propagator makes difference.apply methods, MDD propagation Sequence MDD propagationAmong, data set Section 6.1 containing 250 instances. time limit1,800 seconds, run propagators maximum MDD widths 2, 8, 32, 128.first compare performance MDD propagators Among SequenceFigure 7. figure depicts number instances solved within giventime limit various methods. plot indicates Among propagatorsmuch weaker Sequence propagator, moreover larger maximum widthsalone suffice: using Sequence propagator maximum width 2 outperformsAmong propagators maximum widths 128.scatter plot Figure 8 compares MDD propagators Among Sequencedetail, widths 2, 8, 32, 128 (instances take 0 backtracks, resp. less0.01 seconds, either method discarded Figure 8.a, resp. 8.b). smallerwidths, several instances Among propagator solve faster,relative strength Sequence propagator increases larger widths. width128, Sequence propagator achieve orders magnitude smaller search trees718fi200150100Sequence Width 128Sequence Width 32Sequence Width 8Sequence Width 2Among Width 128Among Width 32Among Width 8Among Width 2050Number instances solved250MDD Propagation Sequence Constraints102101100101102103Time(s)103102101100101Sequence MDD Propagator Time (s)Width 2Width 8Width 32Width 128102102104106Width 2Width 8Width 32Width 128100Sequence MDD Propagator BacktracksFigure 7: Performance comparison MDD propagation Sequence Amongvarious maximum widths. data point reflects total number instancessolved particular method within corresponding time limit.100102104106102101100101102103Among MDD Propagator Time (s)Among MDD Propagator Backtracksb. Solving timea. Number backtracksFigure 8: Evaluating MDD propagation Sequence Among various maximumwidths via scatter plots respect search backtracks (a.) solving time(b.). plots log-log scale follow format Figure 5.719fiBergman, Cire & van Hoevesolving time Among propagators, demonstrates advantageMDD propagation Sequence compared Among decomposition.7. ConclusionConstraint propagation limited-width MDDs recently shown powerfulalternative conventional propagation variable domains constraint programming.work, studied MDD propagation Sequence constraint, appears in, e.g., rostering scheduling applications. first proved establishingMDD consistency Sequence NP-hard. However, also shown taskfixed parameter tractable respect length sub-sequences definedconstraint, provided MDD follows variable ordering specified constraint.proposed practical MDD propagation algorithm Sequence also polynomial length sub-sequences, based cumulative decomposition.provided extensive experimental results comparing MDD propagator Sequencedomain propagators Sequence well existing MDD propagator Among.computational experiments shown MDD propagator Sequenceoutperform domain propagators orders magnitude terms search tree sizesolving time. Similar results obtained compared existing MDD propagator Among, demonstrates practice large MDD alone sufficientsolve problems; specific MDD propagators global constraints Sequencelead orders magnitude speedups.Acknowledgmentsmaterial based upon work supported National Science FoundationGrant No. CMMI-1130012, Google Research Award. also thank reviewerswhose comments helped improve paper.ReferencesAndersen, H. R., Hadzic, T., Hooker, J. N., & Tiedemann, P. (2007). Constraint StoreBased Multivalued Decision Diagrams. Proceedings CP, Vol. 4741 LNCS,pp. 118132. Springer.Apt, K. R. (2003). Principles Constraint Programming. Cambridge University Press.Beldiceanu, N., & Contejean, E. (1994). Introducing global constraints CHIP. JournalMathematical Computer Modelling, 20 (12), 97123.Brand, S., Narodytska, N., Quimper, C., Stuckey, P., & Walsh, T. (2007). EncodingsSequence Constraint. Proceedings CP, Vol. 4741 LNCS, pp. 210224. Springer.Cheng, K., & Yap, R. (2008). Maintaining Generalized Arc Consistency Ad Hoc r-AryConstraints. Proceedings CP, Vol. 5202 LNCS, pp. 509523. Springer.Cire, A. A., & van Hoeve, W.-J. (2012). MDD Propagation Disjunctive Scheduling.Proceedings ICAPS, pp. 1119. AAAI Press.720fiMDD Propagation Sequence ConstraintsCire, A. A., & van Hoeve, W.-J. (2013). Multivalued Decision Diagrams SequencingProblems. Operations Research, 61 (6), 14111428.Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.Downing, N., Feydy, T., & Stuckey, P. (2012). Explaining Flow-Based Propagation.Proceedings CPAIOR, Vol. 7298 LNCS, pp. 146162. Springer.Garey, M., & Johnson, D. (1979). Computers Intractability - Guide TheoryNP-Completeness. Freeman.Gomes, C. P., Fernandez, C., Selman, B., & Bessiere, C. (2005). Statistical Regimes AcrossConstrainedness Regions. Constraints, 10 (4), 317337.Hadzic, T., Hooker, J. N., OSullivan, B., & Tiedemann, P. (2008a). Approximate Compilation Constraints Multivalued Decision Diagrams. Proceedings CP, Vol.5202 LNCS, pp. 448462. Springer.Hadzic, T., Hooker, J. N., & Tiedemann, P. (2008b). Propagating Separable EqualitiesMDD Store. Proceedings CPAIOR, Vol. 5015 LNCS, pp. 318322. Springer.Hadzic, T., OMahony, E., OSullivan, B., & Sellmann, M. (2009). Enhanced InferenceMarket Split Problem. Proceedings ICTAI, pp. 716723. IEEE.Hawkins, P., Lagoon, V., & Stuckey, P. (2005). Solving Set Constraint Satisfaction ProblemsUsing ROBDDs. JAIR, 24 (1), 109156.Hoda, S., van Hoeve, W.-J., & Hooker, J. N. (2010). Systematic Approach MDD-BasedConstraint Programming. Proceedings CP, Vol. 6308 LNCS, pp. 266280.Springer.Hosaka, K., Takenaga, Y., Kaneda, T., & Yajima, S. (1997). Size ordered binary decisiondiagrams representing threshold functions. Theoretical Computer Science, 180, 4760.Knuth, D. E. (2009). Art Computer Programming, Volume 4, Fascicle 1: BitwiseTricks & Techniques; Binary Decision Diagrams. Addison-Wesley Professional.Maher, M., Narodytska, N., Quimper, C.-G., & Walsh, T. (2008). Flow-Based PropagatorsSEQUENCE Related Global Constraints. Proceedings CP, Vol. 5202LNCS, pp. 159174. Springer.Narodytska, N. (2011). Reformulation Global Constraints. Ph.D. thesis, UniversityNew South Wales.Regin, J.-C. (1994). Filtering Algorithm Constraints Difference CSPs.Proceedings AAAI, Vol. 1, pp. 362367. AAAI Press.Regin, J.-C. (2011). Global Constraints: Survey. Van Hentenryck, P., & Milano, M.(Eds.), Hybrid Optimization, pp. 63134. Springer.Regin, J.-C., & Puget, J.-F. (1997). Filtering Algorithm Global Sequencing Constraints. Proceedings CP, Vol. 1330 LNCS, pp. 3246. Springer.Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). Handbook Constraint Programming.Elsevier.van Hoeve, W.-J., & Katriel, I. (2006). Global Constraints. Rossi, F. van Beek, P., &Walsh, T. (Eds.), Handbook Constraint Programming, chap. 6. Elsevier.721fiBergman, Cire & van Hoevevan Hoeve, W.-J., Pesant, G., Rousseau, L.-M., & Sabharwal, A. (2006). RevisitingSequence Constraint. Proceedings CP, Vol. 4204 LNCS, pp. 620634. Springer.van Hoeve, W.-J., Pesant, G., Rousseau, L.-M., & Sabharwal, A. (2009). New FilteringAlgorithms Combinations Among Constraints. Constraints, 14, 273292.Wegener, I. (2000). Branching Programs Binary Decision Diagrams: Theory Applications. SIAM monographs discrete mathematics applications. SocietyIndustrial Applied Mathematics.722fiJournal Artificial Intelligence Research 50 (2014) 847-884Submitted 11/13; published 8/14Arbitration StabilityCooperative Games Overlapping CoalitionsYair ZickYAIRZICK @ CMU . EDUSchool Computer ScienceCarnegie Mellon University, United StatesEvangelos MarkakisMARKAKIS @ GMAIL . COMDepartment InformaticsAthens University Economics Business, GreeceEdith ElkindELKIND @ CS . OX . AC . UKDepartment Computer ScienceUniversity Oxford, United KingdomAbstractOverlapping Coalition Formation (OCF) games, introduced Chalkiadakis, Elkind, Markakis,Polukarov Jennings 2010, cooperative games players simultaneously participate several coalitions. Capturing notion stability OCF games difficult task: deviating players may continue contribute resources joint projects non-deviators,crucial question payoffs deviators expect receive projects. Chalkiadakiset al. introduce three stability concepts OCF gamesthe conservative core, refined core,optimistic corethat based different answers question. paper,propose unified framework study stability OCF setting, encompassesstability concepts considered Chalkiadakis et al. well wide variety alternative stabilityconcepts. approach based notion arbitration functions, determine payoffobtained deviators, given deviation current allocation resources. providecharacterization stable outcomes arbitration. conduct in-depth study fourtypes arbitration functions, correspond four notions core; include threenotions core considered Chalkiadakis et al. results complement Chalkiadakiset al. answer questions left open work. particular, show OCF gamesconservative arbitration function essentially equivalent non-OCF games, relatingconservative core OCF game core non-overlapping cooperative game, useresult obtain strictly weaker sufficient condition conservative core non-emptinessone given Chalkiadakis et al.1. IntroductionConsider market exchange involving several agents, owning certain amount goods(say, oil, sugar flour). agents trade other, vendor may offer differentprices different buyers. Suppose one vendors 3 tons sugar agreed sellbuyers 1 2 buyer 1 receives 1 ton sugar pays 500 dollars, whereas buyer 2receives 2 tons sugar pays 900 dollars. vendor discovers sell one tonsugar third buyer 700 dollars. may decide unhappy amount moneyreceives transaction buyer 1, cancel deal favor buyer 3. However,buyer 2, upon hearing transaction buyer 1 canceled, may longer wishwork vendor, cancel agreement well. Therefore, decidingc2014AI Access Foundation. rights reserved.fiZ ICK , ARKAKIS , & E LKINDwhether deviation agreement profitable, vendor needs predict partiestrading would react actions. safe assume buyer 2 willing upkeepinteraction, deviation profitable; true, seller forgobetter deal buyer 3, lose deviation worth.setting possesses several interesting characteristics. First, vendor may allocate goodsseveral buyers, buyer may also purchase goods several vendors. words,agents may allocate fractions resources several profit-generating tasks. Second, agentsmay withdraw resources agreements, keeping others unchanged.example, oil vendor may wish sell less oil customer, change interactionsparties; similarly, buyer may want pay less vendors, maintainpayments others. Finally, trying strategically change agreement, agents must takeaccount impact actions contracts still maintain (possiblyunaffected) parties.features typical many multi-agent settings, agents collaborate allocatingparts resources working together order generate revenue, share resultingprofits. Profit sharing done directly, exchange goods results profit, e.g.,agents make new good using resources sell it; profit sharing also indirect,e.g., via setting price good sold. settings, even external constraintsprofits distributed, agents account individuals groups agentsunderpaid. group agents get money deviating proposed dealmay destabilize entire agreement, causing cascade deviations results less desirablestate. However, constitutes profitable deviation greatly depends non-deviatorsrespond deviating set.Modeling system incentives reactions challenge itself. Recently challengeaddressed Chalkiadakis, Elkind, Markakis, Polukarov, Jennings (2010), proposenovel approach modeling scenarios agents divide resources among several coalitions.introduce overlapping coalition formation (OCF) games, generalize classic modelcooperative games (Peleg & Sudholter, 2007).classic cooperative game theory model, set agents N ; subset Nform team generate profit members. transferable utility (TU) games, subsetagents N identified value v(S). value thought monetarypayoff set members agree work together, freely divided amongmembers S. argued above, desirable property payoff distribution scheme stabilityindividual group deviations, captured notion core (Gillies, 1953):payoff division said core every subset agents N receives total payoffleast value v(S).Classic cooperative game theory assumes agent may belong one coalitiongiven time. is, agents form coalition structures splitting disjoint groups,group working individual task. Consequently, classic approach well-suited handleoverlapping coalitions, intricacies deviation settings agent participatesseveral agreements. Indeed, classic cooperative game setting, set agents assessesdesirability payoff division make own: total payoff allottedleast v(S)? deviating agents break ties non-deviators,cannot expect non-deviators collaborate way. contrast,agents allowed split resources among multiple coalitions, notion profitable848fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSdeviation must reexamined, since partial coalitions allow partial deviations, meanseven though set agents decides deviate group agreement, remains involvedcollaborative projects non-deviators. non-deviators decide much deviatorsreceive projects. Hence, deviators decision whether withdrawtasks (and extent) depends expect receive collaborationnon-deviators.Chalkiadakis et al. (2010) propose model agents split resources among severalcoalitions, study effect joint projects non-deviators desirability deviationoverlapping coalition setting. propose discuss three notions reaction deviation.first reaction, term conservative, gives deviators share profitscoalitions maintain non-deviators. second reaction, termed refined, allows deviators keep payoffs coalitions unaffected deviation. Finally,optimistic reaction deviators may able receive revenue coalitioninvolved in, long non-deviators coalition guaranteed pre-deviation payoffs.reactions deviation correspond three notions stability OCF games, namely,conservative core, refined core, optimistic core.non-deviators reaction deviation extend beyond three notions. Many legalcontracts (e.g., ones involving service provider clients, vendors suppliers, severalcompanies working joint venture) designed explicit aim detailing consequences deviation parties. Typically, contracts impose fines parties breakagreement. However, also forms punishment: instance, company failsuphold contractual obligations may blacklisted clients, reputationtarnished bad press. Alternatively, one may actively rewarded deviating, e.g.,external party wishes break certain status-quo, encourage project diversification.adopting notion partial deviation possible reactions deviation, capture farnuanced scenarios described classic TU games.1.1 Contributionmain contribution broad generalization overlapping coalition formation (OCF) modelproposed Chalkiadakis et al. (2010). Chalkiadakis et al. describe three ways nondeviators may react deviation, propose general framework modeling reactions.framework based notion arbitration function (Section 3). function that,given deviating group players deviation, outputs, every coalition containingdeviators, amount deviators expect receive coalition post-deviation.Using arbitration functions, present class solution concepts OCF games callarbitrated cores (Section 4). show three concepts core described Chalkiadakiset al. (2010) special cases model, propose new concept core, callsensitive core. propose criterion checking whether outcome arbitratedcore, characterize core outcomes important arbitration functions. focusidentifying sufficient necessary conditions arbitrated core non-empty (Section 5). Building work Chalkiadakis et al., provide LP-based criterionnon-emptiness conservative core, derive criteria sensitive refined corenon-empty. use result identify interesting class OCF games whose refined coreguaranteed non-empty. Finally, show OCF games conservative arbitration849fiZ ICK , ARKAKIS , & E LKINDfunction essentially equivalent non-OCF games, relating conservative core OCFgame G core discrete superadditive cover, non-OCF game constructedG natural way. particular, means conservative core OCF game Gnon-empty discrete superadditive cover G supermodular. demonstratecondition strictly weaker convexity-based condition conservative core non-emptinessgiven Chalkiadakis et al.1.2 Related Workdirect precursor work work Chalkiadakis et al. (2010): generalizemodel capture broader class possible reactions deviation, solve problemleft open work.Incentives optimization collaborative multi-agent environments received plentyattention multiagent research community (Sims, Corkill, & Lesser, 2008; Airiau & Sen,2009; Rahwan & Jennings, 2008; Dang, Dash, Rogers, & Jennings, 2006; Shehory & Kraus, 1996;Lin & Hu, 2007; Zhang, Jiang, Su, Qi, & Fang, 2010); see also PhD thesis Rahwan (2007)recent book Chalkiadakis, Elkind, Wooldridge (2011) overview. studiesoften use cooperative game theory modeling framework.Several authors considered problem optimal coalition structure generation cooperative settings overlapping coalitions. Shehory Kraus (1996) initiated lineresearch; work, describe distributed coalition formation algorithm agents maysplit resources among several tasks order achieve better outcomes. Dang et al. (2006)consider overlapping coalitions sensor networks, agents sensors taskedtracking objects. Lin Hu (2007) provide parallel algorithm overlapping coalition formation. papers, underlying assumption agents fully cooperative, i.e.,seek maximize social welfare rather gains. contrast, work focusgame-theoretic aspects strategic behavior cooperative settings, taking agent incentivesaccount.model applies settings rational agents distribute resources among severalprojects, receiving profits each. scenario occurs variety applications. example,multi-commodity network flows easily modeled within overlapping coalition formationframework (for analysis underlying non-OCF game, see Markakis & Saberi, 2005).also case several fractional optimization problems (Deng, Ibaraki, & Nagamochi,1999). example, fractional matching problem thought OCF game,partial coalition pair agents describes amount resources agentsassigns respective task.Another class settings overlapping coalitions arise collaboration networks. Consider social network agent associated weighted node derives valueassigning certain portion weight collaborating neighbors. settingsreceived much attention recent years (for survey, see Jackson, 2003). instance, Anshelevich Hoefer (2010) discuss strategic aspects network formation settings agentsmay participate one coalition; however, contrast work, main focusanalysis individual rationality pairwise equilibria networks, rather groupstability. Fractional stable matchings discussed Aharoni Fleiner (2003), nontransferable utility model. recently, Ackerman Branzei (2014) analyzed research850fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONScollaboration using graphical model, authors devote efforts collaborativeprojects, receive credit work based authorship order model. AckermanBranzei mainly interested individually rational pairwise stable outcomes, much like Anshelevich Hoefer. OCF framework recently used model collaborative wirelessnetworks (Wang, Song, Han, & Saad, 2013; Zhang, Song, Han, Saad, & Lu, 2013).Overlapping coalition formation games, proposed Chalkiadakis et al. (2010), sharefeatures fuzzy games (Aubin, 1981). However, fundamental differencestwo models. Arguably, important difference Chalkiadakis et al. assume severalpartial coalitions may form, whereas Aubin assumes agents pool resources worksingle task, considers partial coalitions context potential deviations. Assumingformation single coalition eliminates many subtleties games overlappingcoalitions capture, emphasized Chalkiadakis et al.work presented paper computational nature, algorithmic issuesarise cooperative games overlapping coalitions discussed Chalkiadakis et al.(2010) subsequently Zick, Chalkiadakis, Elkind (2012); refer reader companion paper (Zick, Chalkiadakis, Elkind, & Markakis, 2014) in-depth analysis.2. PreliminariesThroughout paper, consider games finite set players N = {1, . . . , n}. useboldface lowercase letters denote vectors uppercase letters denote sets. Given set N ,write eS denote indicator vectorFurthermore, given vector x = (x1 , . . . , xn ) RnP S.subset N , set x(S) = xi .2.1 Classic TU Cooperative Gamestransferable utility (TU) cooperative game given set players, agents, N = {1, . . . , n}characteristic function u : 2N R u() = 0; write G = hN, ui. payoff vectorgame G = hN, ui vector x Rn x(N ) = u(N ). payoff vector x gameG = hN, ui said stable x(S) u(S) N . set stable payoff vectorsG called core G.sometimes assumed agents allowed form coalition structures; coalition structure CS simply partition N , value u(CS ) sum values constituentcoalitions. coalition part coalition structure CS , value S, u(S),freely divided among members S, transfers agents membersallowed, i.e., x payoff vector coalition structure CS x(S) = u(S)CS . core game G = hN, ui coalition structures set pairs (CS , x),CS coalition structure, x payoff vector CS , x(S) u(S) N .Cooperative games coalition structures first studied Aumann Dreze (1974),focus number recent papers multiagent research community (seeChalkiadakis et al., 2011).2.2 OCF GamesGiven set agents N = {1 . . . n}, partial coalition players N vector c = (c1 , . . . , cn )[0, 1]n . i-th coordinate c indicates fraction player resources contributed c.851fiZ ICK , ARKAKIS , & E LKINDfollows, omit word partial, refer vectors [0, 1]n coalitions.particular interest players actively participate c. players may rightfully claimshare cs profits, ones may potentially get hurt agent changescontribution c. Formally, support coalition c set supp(c) = {i N | ci > 0}.recall formal definition OCF games, given Chalkiadakis et al. (2010).Definition 2.1. OCF game G = hN, vi given set players N = {1, . . . , n}characteristic function v : [0, 1]n R+ , assigns non-negative real value partialcoalition; require v(0n ) = 0.characteristic function OCF game quite general; even require vmonotone. reasoning behind apparent leniency that, given v, agents N may formseveral coalitions order optimize revenue, process results coalition structure.is, however, one additional assumption v would like impose; introduce it,first need formally define concept coalition structure OCF game.Pcoalition structure N finite list coalitions CS = (c1 , . . . , cm )j=1 cj1n . coalition structure CS thought n matrix whose rows sum 1.requirement rows sum 1 means CS valid division playersresources, i.e., player gives 100% resources CS . readability, use setnotation referring coalition structures: e.g., referring coalition c appearsCS , write c CS , referring coalition structure CS 0 sublist CS ,write CS 0 CS .Recall coalition structure classic cooperative game partition agent set, i.e.,collection disjoint subsets N whose union N . particular, set agents appear twicecoalition structure. contrast, OCF games, possible coalition structure CScoalition appearing once. simply means respective agentscompleting two separate tasks, require resources generate revenue.Example 2.2. Consider setting two researchers collaborate. write single longresearch paper, require time, generate revenue $100000 (in, say,grant money performance payment). Alternatively, split time equally tworesearch projects, produce two shorter papers, generate $70000 each. setting,agents best interest split two identical coalitions form ( .5.5 ) rather formsingle coalition.Ptotal revenue generated coalition structure CS simply cCS v(c), denotedv(CS ).Given set agents N , say coalition structure CS supp(c)c CS . denote set coalitionstructures CS(S). weight vectorPcoalition structure CS w(CS ) = cCS c. vector w(CS ) indicates total amountresources player N invests coalition structure CS . Note w(CS ) [0, 1]n ,CS CS(S), w(CS ) eS ; say coalition structure CS efficientw(CS ) = eS . also write wS (CS ) denote total weight CS ; namely, i-thcoordinate wS (CS ) equals i-th coordinate w(CS ) S, 0 otherwise.shown Example 2.2, agents may form coalition structures order increase revenue. considerations naturally give rise following definition. superadditive cover852fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSv definedv (c) = sup{v(CS ) | CS CS(N ), w(CS ) c}.value v (c) players make using resources c. Note similarnotion superadditive cover exists classic coalitional games (Aumann & Dreze, 1974): givenfunction u : 2N R, superadditive cover function u : 2N R definedXu (S) = max{v(T ) | P partition S}.PRecall function f : Rn R called superadditive c, Rnf (c) + f (d) f (c + d);(1)f defined subdomain U Rn , condition (1) imposed vectors c,c + still U . definition following discrete analogue: function u : 2N Rcalled superadditive sets S, N =u(S) + u(T ) u(S ).(2)definitions explain term superadditive cover: easy see v minimalsuperadditive function [0, 1]n R v (c) v(c) every c [0, 1]n , and, similarly,u minimal superadditive function 2N R u (S) u(S) every N .ready formulate additional requirement wish impose v.Definition 2.3. characteristic function v efficient coalition structure property everyc [0, 1]n exists CS CS(N ) w(CS ) = c v (c) = v(CS ).characteristic functions efficient coalition structure property, sup definition v replaced max. follows, limit attention OCF games whosecharacteristic functions enjoy property. see efficient coalition structure propertydesirable OCF setting, consider function f given f (x) = x [0, 1]n \ {0n },positive constant. function efficient coalition structureproperty superadditive cover f (x) = x [0, 1]n \ {0n }. particular,means coalition structure optimal f : always possible increase social welfaresplitting coalition two non-zero coalitions. remark Chalkiadakis et al. (2010)impose number conditions characteristic function OCF game that, taken together,imply efficient coalition structure property; find convenient state propertydirectly.provide intuition concepts introduced far, describe simple classOCF games. often useful think agents using resources completegiven set tasks. Chalkiadakis et al. (2010) describe class OCF games, callThreshold Task Games (TTGs), based idea. TTG specified finite listtasks, = {t1 , ..., tk }, task t` requires weight (t` ) 0 completiongives certain payoff p(t` ) 0, list players weights, denoted (w1 , . . . , wn ). playerallocate fraction weight completion task. worth coalitionv(c) = max{p(t` ) | (t` )nXi=1853ci wi };fiZ ICK , ARKAKIS , & E LKINDis, value coalition simply value highest-paying task agentscomplete using combined weight. Threshold Task Games natural extension WeightedVoting Games (WVGs) (Chalkiadakis et al., 2011). Indeed, weighted voting game, agentN non-negative weight wi , value set players N 1 combinedweight members least given non-negative quota q, 0 otherwise. Thus,weighted voting games simply threshold task games single task weight qpayoff 1, overlapping coalitions allowed.2.3 Payoff Divisionsplit coalitions generated revenue, agents decide dividerevenue amongst agreeable manner. formally describe payoff divisionOCF games.imputation coalition structure CS = (c1 , ..., cm ) CS(N ) list vectors x =(x1 , ..., xm ); j = 1, . . . , m, xj vector Rn describes much agent Nreceives cj . Given coalition c CS imputation x CS , refer wayvalue c divided x(c); thus, payoff agent coalition c CS x x(c)i .order x valid division payoffs among agents, satisfy followingconditions.P{i}Individual Rationality:cCS x(c) v (e ) N .PPayoff Distribution: c CS holds x(c)i v(c), ci = 0 x(c)i = 0.denote set imputations CS I(CS ). Observe definition allowinter-coalitional transfers. is, agent N support c, cannotexpect receive payoff c. call tuple (CS , x), CS coalition structurex I(CS ), feasible outcome. Given set N , denote F(S) set feasibleoutcomes (CS , x) CS CS(S). Thus, F(N ) refers possible ways agents formcoalition structures divide payoffs.Given feasibleoutcome (CS , x) F(N ), define payoff agent NPp (CS , x) = cCS x(c)i . total payoff coalitions CS . Observepi (CS , x) uniquely defined: given outcome (CS , x), total payoff player dependssolely amount payoff received coalitions CS ,x,P determinedx alone. Similarly, total payoff set given p (CS , x) = p (CS , x).Definition 2.4. Given set N coalition structure CS CS (N ), coalition structureCS reduced definedCS |S = (c CS | supp(c) S) .coalitions comprised solely members S.coalitions CS |S fully controlled S. Hence, deviation members wouldaffect non-deviators changes contribution coalitions outside CS |S .ready formally define deviations OCF games. Loosely speaking, deviationset N coalition structure CS CS(N ) specifies amount resourceswithdraw coalitions CS |S .854fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSDefinition 2.5. Suppose CS \CS |S = (cj1 , . . . , cjk ). coalition structure CS 0 = (d1 , . . . , dk )deviation CS ` = 1, . . . , k holds d` cj` d` eS .deviation CS 0 describes set withdraws resources coalitions CS \ CS |S .requirement d` cj` captures fact cannot withdraw resourcescoalition cj` invested it. also require d` eS since deviation CS 0involve members only.sometimes convenient think deviation function that, coalition cCS \ CS |S , outputs much agents withdraw c. is, given coalition structureCS CS(N ), set N , deviation CS 0 CS , coalition cj` CS \ CS |S ,write dCS 0 (cj` ) refer coalition d` CS 0 corresponds deviationcj` . notation, (dCS 0 (cj` ))i specifies amount resources agent withdrawscoalition cj` CS 0 . deviation CS 0 understood context, omitsubscript CS 0 dCS 0 (c) refer deviation c d(c).Note withdraws resources CS \ CS |S , total weight availablew(CS |S ) + wS (CS \ CS |S ) = wS (CS ).Example 2.6. Consider three-player game described follows. several types tasks:t12 requires 50% player 1s resources player 2s resources, payoff 16;t012 requires 40% player 1s resources player 2s resources, payoff 10;t13 requires 50% player 1s resources player 3s resources, payoff 20;t1 requires 10% player 1s resources payoff 3.optimal coalition structure case0.50.5CS = c1 = 1 , c2 = 0.01coalitions c1 c2 complete tasks t12 t13 , respectively; thus, v(c1 ) = 16 v(c2 ) = 20.deviation player 1 CS would coalition structureCS 1 =0 , 0000.5 0.5. = 0, player 2 unaffected deviation; = 0player 3 unaffected deviation.possible player 1 deviates c1 changing contribution c2 , viceversa. Moreover, possible coalition resources withdrawn stillgenerate revenue. instance, player 1 withdraws 10% resources c1 ,remains c1 still generates revenue 10. opens opportunities nuanced postdeviation behavior: player 3 may decide break agreement player 1 = 0,= .1 player 2s payment original coalition structure less 10, player 1 hopeget payment reduced collaboration player 2.Example 2.6 illustrates, deviations OCF games may leave non-deviators unaffected deviation. Moreover, may possible deviators ensure non-deviatorsstill receive payoff allocated prior deviation. deviators agree assumemarginal loss deviation, possible non-deviators agree maintain coalitionsthem. notions formalized Section 3.855fiZ ICK , ARKAKIS , & E LKIND3. Arbitration Functionclassic cooperative game theory, set unhappy payoffs wants deviatecompares current payoff earn own. However, Example 2.6 shows,complex structure deviations OCF games lead variety ways agentsmay react deviation. deviating set still keeps resources invested coalitionsnon-deviators, may case continue receive payments coalitions.discuss stability OCF games, need describe agents react set Ndeviates (CS , x). One think process following manner: given outcome(CS , x) deviation CS 0 N CS , set may use available resources CS |SCS 0 order generate revenue itself. Moreover, coalition c CS \ CS |S needsdecide much payoff gives deviators; behavior specified arbitrationfunction.Definition 3.1. Given outcome (CS , x), set N deviation CS 0 CS ,arbitration function mapping assigns real value c (CS , x, S, CS 0 ) cCS \ CS |S .value c (CS , x, S, CS 0 ) represents amount coalition c pay S, givencurrent outcome (CS , x), identity deviators, nature deviation.3.1 Properties Arbitration FunctionsClearly, need impose restrictions amount deviators may expect getnon-deviators. example, would unreasonable deviating set expect payoffexceeds post-deviation value respective coalition. Another natural restriction that,deviators get payoff given coalition, every non-deviator coalitionreceive payoff deviation, i.e., non-deviators never agree paydeviating set expense non-deviating members.Formally, given outcome (CS , x), set N , deviation CS 0 CS , arbitration function whose output (CS , x, S, CS 0 ) described list values (c )cCS \CS |S ,require following properties:PAccountability: c (CS , x, S, CS 0 ) max{v(c d(c)) \S x(c)i , 0}.Deviation-Monotonicity: every pair subsets S, N respectivedeviations CS 0 CS 00 CS dCS 0 (c) dCS 00 (c) c CS \ CS |S ,holds c (CS , x, S, CS 0 ) c (CS , x, T, CS 00 ).first condition states general upper bound amount deviating set expectreceive coalition: deviation, coalition c generate profit v(c d(c)),deviating set expect receive v(c d(c)), minus original payments givennon-deviators (CS , x). second condition simply states punishment imposedarbitration function monotone size violation: deviators withdrawsmaller amount resources coalition, receive least much payoffreceived original deviation. rationale behind first condition strategicnature; stems assumption set agents engaged task agree paydeviating members deviators cannot ensure non-deviator paid amount856fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSprior deviation. stress however, accountability necessary componentproofs: results still hold even one assume accountability. second condition,sensible well, instrumental proving Theorem 3.4, necessary assumption. Finally,note possible coalition imposes fine deviating members, is, value cneed positive.total revenue deviating set given deviation CS 0 CS writtenA(CS , x, S, CS 0 ) = v (w(CS |S ) + w(CS 0 )) +Xc (CS , x, S, CS ).cCS \CS |SGiven outcome (CS , x) set N , get deviating (CS , x)(CS , x, S) = sup{A(CS , x, S, CS 0 ) | CS 0 deviation CS }.Now, order deem deviation profitable, members stand gainit. formal definition captures idea somewhat complicated, describedeviators share profit/loss allocated arbitration function.Definition 3.2. Given outcome (CS , x) deviation CS 0 N CS , sayCS 0 A-profitable deviation construct1. coalition structure CS w(CS ) = w(CS |S ) + w(CS 0 ) together imputation xd I(CS ),2. collection vectors = (yc )cCS \CS |S , every c CS \ CS |S holds(a) yc (R+ )n c (CS , x, S, CS 0 ) 0 yc (R )n otherwise,(b) (yc )i = 0 6 supp(c d(c)),Pn0(c)i=1 (yc ) = c (CS , x, S, CS ),Pevery holds pi (CS , xd ) + cCS \CS |S (yc )i > pi (CS , x).Simply put, given Ss deviation (CS , x) arbitration function A, agentsagree three things. First, decide coalition structure formpost-deviation resources. Second, come way dividing profitscoalition structure. Third, agree way dividing payoffs (or fines) assignedarbitration function. deviation profitable, agreementsagents receive strictly received (CS , x).agreement exists, cannot A-profitably deviate. Given (CS , xd ) y, total payoffagent deviating denoted q (xd , y).priori, seems possible that, even total payoff deviating setp (CS , x), members may unable divide revenue deviation waybenefits due coalitional restrictions. Chalkiadakis et al. (2010) showconservative arbitration function (see Section 3.2) case: way agentsjointly gain deviating, divide profits way benefits all.Theorem 3.4, show extend result general arbitration functions.857fiZ ICK , ARKAKIS , & E LKINDRemark 3.3. possible incorporate freely divisible value arbitration function.value payoff (or fine) assigned deviators external entity. paymentscoalitions CS \ CS |S , payment may depend original outcome, identitydeviating set, nature deviation. results paper carryaddition freely divisible value. Intuitively, value allows us extend notions-core (Maschler, Peleg, & Shapley, 1979) OCF games.3.2 Arbitration Functionspresent arbitration functions briefly discuss properties. Threearbitration functions correspond three notions core introduced Chalkiadakis et al.(2010) (the conservative core, refined core optimistic core), names usearbitration functions reflect this; contrast, sensitive arbitration function basednew idea.3.2.1 C ONSERVATIVE RBITRATION F UNCTIONsimplest assumption one make respect reaction deviation nondeviators react voiding agreements deviators; is, deviators expectpayment coalitions non-deviators, regardless contribution.reasoning gives rise conservative arbitration function; formally, defined settingc 0 given input. conservative arbitration function, deviating setrewarded way continued interaction non-deviators; thus, profit hopegain deviating exactly make own. Therefore, conservativearbitration function, denoted Ac , Ac (CS , x, S) = v (eS ) every outcome (CS , x).3.2.2 ENSITIVE RBITRATION F UNCTIONreasoning agents reaction deviation, natural assumption make nondeviators care deviating set does, long deviation affect them.approach captured sensitive arbitration function. function paymentdeviators obtain coalition c CS \ CS |S 0 c0 CS \ CS |Sd(c0 ) 6= 0 supp(c) supp(c0 ) N \ 6= ; otherwise, payment total payoffmembers receiving c prior deviation.sensitive arbitration function, denoted , deviating set getcomputed follows. First, clear benefit investing resourcesjoint projects non-deviating agents hurt way deviation. Thus,needs decide agents keep collaborating with; agents, breakagreements them. order describe payments sensitive arbitration function,employ following notation. Given set N , let CS set coalitionsCS involve members ;CS = (c CS | supp(c) 6= ).Now, set N chooses break agreements involve members , forgoes paymentscoalitions CS , use resources invested CS order maximizeprofits. is, obtain(CS , x, S) = max v w(CS |S ) + wS (CS ) + pS (CS \ (CS |S CS ), x) | N \ .858fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSdefinition extended follows: instead completely self-interested,agent N set players Si N cares about. agents Si hurtdeviation, agent allow deviating set payoff coalitionsinvolved in.3.2.3 R EFINED RBITRATION F UNCTIONsensitive arbitration function focuses impact deviation individual agents;contrast, refined arbitration function makes decisions based deviations impactcoalition. Specifically, arbitration function coalition c allows deviators keeppayoffs c withdrawn resources c. Formally, givendeviation CS 0 N CS outcome (CS , x), refined arbitration function, denotedAr , let keep payoff coalition c CS \ CS |S d(c) = 0, allocate payoffc otherwise. Note refined arbitration function generous deviatorssensitive arbitration function: deviator non-deviator j involved coalitionsc c0 , c0 affected deviation c not, refined arbitration functionreceive share cs payoffs, whereas sensitive arbitration function not.set expect gain deviating refined arbitration functioncomputed follows. First, note given coalition c CS \ CS |S , either withdrawresources c none all. Thus, needs find best set coalitions CSfully withdraw resources. Formally,c )) + pS (CS \ CSc , x) | CS |S CSc CS }.Ar (CS , x, S) = max{v (wS (CS3.2.4 PTIMISTIC RBITRATION F UNCTIONyet lenient reaction deviation captured optimistic arbitration function, denotedAo . arbitration function coalition willing pay deviating set longnon-deviators receive pre-deviation payoffs. Since require arbitration functionsaccountability property, means optimistic arbitration function gives deviating sethighest possible payoff receive arbitration function. Formally, given set S,outcome (CS , x) aPdeviation CS 0 CS , payoff gets coalition cmax{0, v(c d(c))/ x(c) }.order compute set get deviating optimistic arbitrationfunction, need determine amount resources going withdraw everycoalition involved in. obtainXc ) + w(CS 0 )) +c , x)},Ao (CS , x, S) = sup{v (wS (CSv(c d(c)) pN \S (CS \ CSccCS \CSc CS |S CSc CS (intuwhere supremum taken coalition structures CSitively, coalitions CS members withdraw resources)c.deviations CS 0 CS \ CS3.3 Redefining A-Profitable Deviationsdefinition A-profitable deviation somewhat difficult work with. remedy this,provide simple sufficient condition existence A-profitable deviation.859fiZ ICK , ARKAKIS , & E LKINDChalkiadakis et al. (2010) prove similar result conservative arbitration function,use techniques (most notably, coloring argument) proof.Theorem 3.4. Consider OCF game G = hN, vi, outcome (CS , x) G arbitrationfunction A. (CS , x, S) > pS (CS , x) N , subsetA-profitably deviate (CS , x).Proof. Consider set N (CS , x, S) > pS (CS , x). First, note spacepossible deviations coalition structure CS viewed subset RD (forappropriate value D) bounded described finitely many non-strict linearinequalities. Therefore space compact. Thus, exists deviation (CS , x)maximizing total payoff derive deviating; let CS 0 deviation.Since v efficient coalition structure property, exists coalition structure CSv(CS ) = v (w(CS |S ) + w(CS 0 )). every c CS \ CS |S , let c amountsupp(c d(c)) receives c deviation. objective find imputationxd I(CS ) along payoff divisions (c )cCS \CS |S would witness subsetA-profitable deviation (CS , x).Given coalition c CS \ CS |S , let Ic set possible ways c dividedamong members supp(c d(c)). Formally, c 0,Ic = {yc (R+ )n | supp(yc ) supp(c d(c))nX(yc )i = c };i=1nc < 0, IQc defined similarly, yc Ic vectors (R ) . Given xdI(CS ) cCS \CS |S Ic , recall q (xd , y) payoff agent deviationpayoffs CS arbitration functionQpayoffs divided according xd y,respectively. define function TL : I(CS ) cCS \CS |S Ic R follows:TL(xd , y) =Xmin pi (CS , x) q (xd , y), 0 .function TL measures total loss incurred members hurt deviation;members who, despite joining deviators,Q enjoy profit deviating.Observe TL continuous, I(CS ) cCS \CS |S Ic compact sets; thus,TL attains minimum value domain. Among minimizers function, pick onenumber agents pi (CS , x) < q (xd , y) largest; denote point(x0 , y0 ).Now, let us color agents follows: agent green pi (CS , x) < q (x0 , y0 );red pi (CS , x) > q (x0 , y0 ) white pi (CS , x) = q (x0 , y0 ). Green agents derive strictlypositive benefit proposed deviation, red agents suffer loss, white agents break even.Now, consider green agent g, suppose g legally transfer payoff agentx0 y0 , i.e., (a) g support coalition c CS g receivespositive payoff c, (b) g support coalition c d(c)c CS \ CS |S , c > 0, g receives positive payoff c, (c) gsupport coalition c d(c) c CS \ CS |S , c < 0, receives negative payoffc. red, g transfer small positive payoff remaining green, resultingpayoff division would strictly lower value TL (x0 , y0 ), contradiction. Similarly,860fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSwhite, g transfer small amount i, making green well, without changingvalue L; contradiction, since chose (x0 , y0 ) maximize number greenagents. Thus, g support coalition deviation (i.e., eithercoalition CS surviving coalition CS \ CS |S ), g cannot receive positive payoffcoalition. argument, coalition CS \ CS |S assigns negative payoffdeviating agents A, green agents incur loss coalition.Let Sg set green agents S. argued agents Sg receive payoffcoalitions form non-green agents S. follows Sg A-profitably deviate(CS , x). Indeed, suppose agents \ Sg deviate, agents Sg deviatewithdrawing resources need forming coalitions among CS ;resources Sg withdrew CS deviation CS 0 order invest coalitionsmembers \ Sg CS kept is. Since deviation-monotone, payment Sgreceives arbitration function new deviation weakly higher CS 0 .Furthermore, suppose Sg forms coalitions CS |Sg , divides payoffscoalitions according x0 , distributes arbitration function payoffs according y0 ,surplus payments arbitration function shared arbitrarily. payoffs membersSg least high CS 0 , x0 y0 ; since agents green,benefits new deviation. Finally, note Sg 6= , since pS (CS , x) < (CS , x, S).concludes proof.Simply put, Theorem 3.4 states set get deviating (CS , x)strictly greater payoff (CS , x), non-empty subsetA-profitably deviate. Note distinction coalitional value profitabilitydeviating exists cooperative games coalition structures well.Example 3.5. Consider modified version three player 2-majority game: agent setN = {1, 2, 3}, value coalition N size least 2 6, valuesingleton 1. Suppose agents form coalition N , divide payoffs agentreceives 2. set N earn forming coalition structure ({1, 2}, {3}), whose value7. However, way divide payoffs coalition structure every agentreceives 2: agent 3 receive 1, better off. Thus, N cannot deviatewhole, coalition {1, 2} singleton {3} (or both, depending valuegrand coalition distributed) profitable deviation.Theorem 3.4 provides us justification using (CS , x, S) measure deviators satisfaction outcome. Indeed, A-profitably deviate (CS , x) viadeviation CS 0 , clearly (CS , x, S) > pS (CS , x). hand, (CS , x, S) >pS (CS , x), A-profitably deviate (CS , x).4. Arbitrated CoreGiven OCF game G = hN, vi arbitration function A, say outcome (CS , x)A-stable set N A-profitably deviate (CS , x). arbitratedcore G respect arbitration function A, A-core G (denoted Core(G, A)),set A-stable outcomes G. Using Theorem 3.4, obtain following characterizationA-stable outcomes.861fiZ ICK , ARKAKIS , & E LKINDTheorem 4.1. Let G = hN, vi OCF game. outcome (CS , x) A-core Gevery N pS (CS , x) (CS , x, S).Proof. First, suppose every N pS (CS , x) (CS , x, S). Let CS 0arbitrary deviation CS . pS (CS , x) A(CS , x, S, CS 0 ). Thus, matterdivides deviation payoffs, would least one agent getspi (CS , x). true arbitrary deviation CS 0 , follows cannot A-profitablydeviate.Conversely, suppose pS (CS , x) < (CS , x, S). Theorem 3.4, subsetA-profitably deviate (CS , x), thus (CS , x) A-stable.Let two arbitration functions. Intuitively, clear lenientA, A-core contained A-core. Indeed, outcome (CS , x) stable respectalways pays deviators (thus making deviation tempting),(CS , x) A-stable well. formalize intuition, use following notation.Given two arbitration functions A, write every set N everyoutcome (CS , x) holds (CS , x, S) (CS , x, S). state observationfollows.Corollary 4.2. Core(G, A) Core(G, A).Proof. Suppose (CS , x) Core(G, A). means N pS (CS , x)(CS , x, S). Since A, follows pS (CS , x) (CS , x) N well,implies (CS , x) Core(G, A).conservative, sensitive, refined optimistic arbitration functions described Section 3.2,denoted Ac , , Ar Ao , respectively, satisfy Ao Ar Ac . Thus, Corollary 4.2implies conservative core contains sensitive core, contains refined core,contains optimistic core. observations (with respect conservative, refined,optimistic core only) made Chalkiadakis et al. (2010) well; fact, Chalkiadakiset al. show containments strict, i.e., games conservative corestrictly contains refined core, games refined core strictly containsoptimistic core. similar separation shown sensitive core.4.1 Arbitrated CoresUsing characterization result Theorem 4.1, proceed describe arbitrated cores,namely, corresponding arbitration functions introduced Section 3.2.4.1.1 C ONSERVATIVE C OREargued Section 3.2, every outcome (CS , x) every set N , getconservative arbitration function v (eS ). Thus, conservative core setoutcomes (CS , x) every set N holdspS (CS , x) v (eS ).862(3)fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS4.1.2 ENSITIVE C OREorder outcome (CS , x) stable sensitive arbitration function, every setN every N \ holdpS (CS , x) v (w(CS |S ) + wS (CS )) + pS (CS \ (CS |S CS ), x);recall CS set coalitions CS involve members . Subtracting paymentsassociated coalitions CS \ (CS |S CS ) sides inequality, getpS (CS |S , x) + pS (CS , x) v (w(CS |S ) + wS (CS )).Chalkiadakis et al. (2010) show CS optimal coalition structure (CS , x)conservative core consequently sensitive core either. Thus,assume CS optimal coalition structure, hence CS |S optimal N , i.e.,v(CS |S ) = v (w(CS |S )). also pS (CS |S , x) = v(CS |S ). implies that, order(CS , x) sensitive core, must case CS optimal coalition structureevery N every N \ holdspS (CS , x) v (w(CS |S ) + wS (CS )) v (w(CS |S )),(4)i.e., total payoff CS must least marginal benefit using resourcesinvested CS . Note take = N \ S, obtain conservative core condition.4.1.3 R EFINED C ORErefined core,c )) + pS (CS \ CSc , x) | CS |S CSc CS }.Ar (CS , x, S) = max{v (wS (CSThus, outcome (CS , x) refined core every N everyc containing CS |S holdscoalition structure CSc )) + pS (CS \ CSc , x).pS (CS , x) v (wS (CSc holdsConsequently, (CS , x) refined core every CSc , x) v (wS (CSc )).pS (CS(5)c containing CS |Swords, payoff every coalition structure CSc . Noteleast large get resources invested CScclimit coalition structures CS CS = CS |S CS N \ S,obtain sensitive core condition.4.1.4 PTIMISTIC C OREoptimistic arbitration function, Ao , shownXc ) + w(CS 0 )) +c , x)},Ao (CS , x, S) = sup{v (wS (CSv(c d(c)) pN \S (CS \ CSccCS \CS863fiZ ICK , ARKAKIS , & E LKINDc CS |S CSc CSsupremum taken coalition structures CSc . Thus, order outcome (CS , x) optimisticdeviations CS 0 CS \ CSc CS containingcore, must case every set N , every coalition structure CS0cCS |S every deviation CS CS \ CS holdsXc , x). (6)c ) + w(CS 0 )) +v(c d(c)) pN \S (CS \ CSpS (CS , x) v (wS (CSccCS \CSc , CS 0 ) denote coalition structure formed remains CS \ CScLet (CS \ CSP0withdrawn resources CS according CS . obtain cCS \CSc v(c d(c)) =0c , CS )). Thus, subtracting p (CS \ CSc , x) sides inequality (6)v((CS \ CSNccusing fact p (CS \ CS , x) = v(CS \ CS ), rewrite inequality (6)c , x) v (wS (CSc ) + w(CS 0 )) v(CS \ CSc ) v((CS \ CSc , CS 0 )) .pS (CS(7)optimistic core stability condition thus similar refined core stability condition; however,c willing assumealso allowed withdraw resources coalitions outside CSmarginal costs withdrawal.Example 4.3. Consider following example. three players, N = {1, 2, 3},following characteristic function:001111v 4 = 1,v 2 = 40,v 41 = 20,002v(c) = 0 every coalition c [0, 1]3 . First, observe optimal coalitionstructure (up order coalitions) CS = (c1 , c2 , c3 ),001111c2 = 41 ,c3 = 41 .c1 = 2 ,022words, players 1 2 collaborate one project (which requires 100% player 1s resources,50% player 2s resources), generate revenue 40; players 2 3 work twoidentical projects (each requiring 25% player 2s resources 50% player 3s resources),generating revenue 40 total well. Now, suppose payoffs divided accordingx = (x1 , x2 , x3 ),0040x2 = 0 ,x3 = 4 .x1 = 0 ,02016conservative arbitration function, payoff division stable: subset playersreceives less make own. However, sensitive arbitration function,longer case: player 2 must receive payoff least 2 c1 , combined payoffleast 2 c2 c3 .Now, let us suppose following payoff division proposed instead: = (y1 , y2 , y3 ),3800y2 = 0 ,y3 = 2 .y1 = 2 ,02086418fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSoutcome (CS , y) stable respect sensitive arbitration function; however,stable respect refined arbitration function: player 2 withdraw contribution c2earn strictly more. Thus, order imputation r-stable, player 2 must receive least2 c1 , least 1 c2 c3 .Example 4.3 illustrates interesting phenomenon: lenient arbitration functions forcepayments spread out: player 2 receives payoff, payoff must receiveddistributed manner lenient reactions deviations assumed.5. Non-emptiness Arbitrated CoresCore outcomes highly desirable classic cooperative games OCF games. Thus,important find conditions characteristic function OCF game would guaranteenon-emptiness arbitrated core, well identify classes OCF games whose arbitratedcore always non-empty, natural arbitration functions. note questionsbeand beenlooked lens computational complexity. is, one askwhether exist polynomial-time algorithms decide whether arbitrated core non-emptyfind outcome arbitrated core, either general model specific classes OCFgames. question explored Chalkiadakis et al. (2010) Zick et al. (2012),paper consider computational complexity issues focus instead characterizationresults (see, however, companion paper Zick et al., 2014).characterization results similar spirit celebrated BondarevaShapley conditioncore non-emptiness classic cooperative games (Bondareva, 1963; Shapley, 1967).briefly state condition. Given set PN = {1, . . . , n}, collection weights (S )SNcalled balanced 0 N S:iS = 1 N . view balancedcollection weights way agent partially participate sets contain i,contribution specified respective weight.Given cooperative game G = hN, ui u : 2NPR+ , say G balancedevery balanced collection weights (S )SN holds SN u(S) u(N ).Theorem 5.1 (BondarevaShapley Theorem). cooperative game G = hN, ui u : 2N R+non-empty core balanced.important feature characterization stated terms characteristicfunction itself, explicitly refer outcomes game. follows, describesimilar characterizations OCF games, conservative, sensitive refined arbitration functions.1 Specifically, arbitration functions, given OCF game G = hN, vicoalition structure CS CS(N ), characterize set imputations x I(CS )(CS , x) respective arbitrated core G. limit attention optimal coalition structures, i.e., assume v(CS ) = v (eN ): CS optimal, outcome form(CS , x) arbitrated core G arbitration functions, since grandcoalition profitably deviate (CS , x) (Chalkiadakis et al., 2010).1. case conservative arbitration function considered Chalkiadakis et al. (2010); reproduceresults completeness facilitate comparison two cases.865fiZ ICK , ARKAKIS , & E LKIND5.1 Conservative CoreGiven OCF game G = hN, vi coalition structure CS = (c1 , . . . , cm ), saycollection non-negative weights {(rj )mj=1 ; (S )SN } c-balancedP respect CS everyN every coalition cj supp(cj ) holds rj + S:iS = 1. Chalkiadakiset al. (2010) show following result.Theorem 5.2 (Chalkiadakis et al., 2010, Thm. 2). Given OCF game G = hN, vi optimal coalition structure CS CS(N ), exists outcome x I(CS ) (CS , x)conservative core G every collection non-negative weights {(rj )mj=1 ; (S )SN }c-balanced respect CS holdsXrj v(cj ) +j=1Xv (eS ) v (eN ).SNfirst observation proof Theorem 5.2, given work Chalkiadakis et al.(2010), gap. Appendix contains correction proof.provide alternative characterization OCF games non-empty conservativecore, establishing connection conservative core OCF game corerelated classic cooperative game.Given OCF game G = hN, vi, discrete superadditive cover classic cooperative gameG = hN, Uv i, Uv (S) = v (eS ). Simply put, value set N Gmake function v forming coalition structure. showconservative core G non-empty core G non-empty.Theorem 5.3. conservative core OCF-game G = hN, vi non-emptycore discrete superadditive cover G = hN, Uv non-empty.Proof. argued conservative core G non-empty, exists outcome(CS , x) N pS (CS , x) v (eS ). Note CS optimal coalitionstructure G, since v(CS ) = pN (CS , x) v (eN ). Consider payoff vector p = (p1 , . . . , pn )pi = pi (CS , x)P N . follows p core G. Indeed, since CSoptimal, ni=1 pi = v(CS ) = v (eN ) = Uv (N ), every Np(S) = pS (CS , x) v (eS ) = Uv (S).Conversely, let p = (p1 , . . . , pn ) payoff vector core G. Fix coalition structureCS = (c1 , . . . , cm ) v(CS ) = v (eN ). use p construct imputationx I(CS ) (CS , x) conservative core G.Given imputation z I(CS ), color agents N follows: green pi (CS , z) >p ; red pi (CS , z) < pi white pi (CS , z) = pi . Green agents better (CS , z)p, red agents worse (CS , z) p, white agents indifferent.Now, suppose z I(CS ) agent respective coloringgreen. Since CS optimal, means agent red either. Thus, agents white.turn implies N pS (CS , z) = p(S) Uv (S) = v (eS ), (CS , z)conservative core. Thus, need show exists z I(CS )agent respective coloring green.Let F : I(CS ) R defined follows:F (z) =nXmax{0, pi pi (CS , z)}.i=1866fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSfunction F measures agents total unhappiness outcome (CS , z) comparedp. F continuous function (it sum maxima functions continuous z),I(CS ) compact set. Thus, exists imputation x I(CS ) minimizes valueF . pick x arg min F (z) minimize number white agents respectivecoloring N .suppose exist green agent g, non-green agent coalition c CSg, supp(c) x(c)g > 0. > 0 setting x(c)g = x(c)gx(c)i = x(c)i + (i.e., transferring amount g within coalition c) resultsvalid payoff division CS keeps g green. white prior transfer,becomes green (and value F change). contradiction fact xminimizes number white agents. hand, red, transfer decreasescontribution F (while gs contribution F remains 0), contradiction factx arg min F (z). means green agents get zero payoff coalitions non-greenagents. Let us denote set green agents Sg .pSg (CS , x) = pSg (CS |Sg , x) v (eSg ).hand, Sg 6= , since Sg pi (CS , x) > pi , obtainpSg (CS , x) > p(Sg ) Uv (Sg ) = v (eSg ).contradiction shows Sg = , argued case agents white.completes proof.following corollary immediately implied proof Theorem 5.3.Corollary 5.4. Consider OCF game G = hN, vi. every payoff vector p = (p1 , . . . , pn )core G every optimal coalition structure CS CS(N ), exists x I(CS )pi = pi (CS , x) N .Corollary 5.4 enables us generalize following well-known result classic cooperativegames. Aumann Dreze (1974) show CS CS 0 optimal (non-overlapping) coalitionstructures G = hN, ui (CS , p) core G (CS 0 , p) also core G.words, CS opt set optimal coalition structures G, Istab setstable payoff divisions G, set core outcomes G CS opt Istab . UsingCorollary 5.4, extend result OCF games conservative arbitration function.Corollary 5.5. Consider OCF game G = hN, vi. every pair optimal coalition structuresCS , CS 0 CS(N ) every imputation x I(CS ) (CS , x) conservative core,exists imputation x0 I(CS 0 ) (CS 0 , x0 ) conservative core Gpi (CS , x) = pi (CS 0 , x0 ) N .5.1.1 C ONVEXITY OCF G AMES R EVISITEDclassic cooperative games, convexity, supermodularity, characteristic function wellknown sufficient condition non-emptiness core (Shapley, 1971). detail,recall cooperative game G = hN, vi said supermodular every pair sets S,N every R N \ holdsv(T R) v(T ) v(S R) v(S).867fiZ ICK , ARKAKIS , & E LKINDSupermodular games often referred convex games literature; however, avoid confusion notions convexity considered paper, use term supermodularity.Shapley (1971) proves following result.Theorem 5.6. cooperative game G supermodular, core non-empty.order extend Theorem 5.6 OCF games, Chalkiadakis et al. (2010) propose followingnotion convexity OCF games.Definition 5.7 (OCF convexity, Chalkiadakis et al., 2010). OCF game OCF-convexevery pair sets S, N , every R N \ , every outcome (CS , xS ) F(S),every outcome (CS , xT ) F(T ), every outcome (CS SR , xSR ) F(S R) followingcondition holds: pi (CS , xS ) pi (CS SR , xSR ) outcome(CS R , xT R ) F(T R)(1) pi (CS , xT ) pi (CS R , xT R ) ;(2) pi (CS SR , xSR ) pi (CS R , xT R ) R.Intuitively, Definition 5.7 simply means larger coalitions offer lucrative optionsplayers join them, compared smaller coalitions.Chalkiadakis et al. (2010) show OCF convexity sufficient condition nonemptiness conservative core.Theorem 5.8 (Chalkiadakis et al., 2010, Thm. 3). OCF game G OCF-convex,conservative core non-empty.hand, combining Theorem 5.3 Theorem 5.6, obtain following sufficientcondition conservative core non-emptiness.Proposition 5.9. Consider OCF game G. G = hN, Uv supermodular, conservativecore G non-empty.argue Proposition 5.9 strictly stronger Theorem 5.8, showingsupermodularity G strictly weaker condition OCF-convexity G. first showOCF-convexity G implies supermodularity G. present example gameG = hN, vi G supermodular, G OCF-convex (Example 5.13).implement first step plan, first establish following crucial proposition,may seem counterintuitive first sight. proof based coloring arguments similarones used proofs Theorems 3.4 5.3.Proposition 5.10. every pair sets S, N every pair optimalcoalition structures CS CS(S), CS CS(T ), exist imputations x I(CS )I(CS ) pi (CS , x) = pi (CS , y) S.Proof. Fix sets optimal coalition structures CS CS(S), CS CS(T ).first establish find imputations x0 I(CS ) y0 I(CS ) pi (CS , x0 )pi (CS , y0 ) S. show use fact prove original claim.Lemma 5.11. exist imputations x0 I(CS ) y0 I(CS ) pi (CS , x0 )pi (CS , y0 ) S.868fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSProof. Given pair imputations x I(CS ), I(CS ), color agents follows:agent green pi (CS , y) > pi (CS , x) \ pi (CS , y) > 0; redpi (CS , y) < pi (CS , x); white otherwise.define mapping : I(CS ) I(CS ) R settingXD(x, y) =max{0, pi (CS , x) pi (CS , y)}.function continuous compact set, thus attains minimum value point(x, y) I(CS ) I(CS ). Among points, pick one smallest number whiteagents denote (x0 , y0 ). Let q = pi (CS , y0 ) , pi = pi (CS , x0 ) S.show q pi S.Assume sake contradiction case. D(x0 , y0 ) > 0least one red agent . Since v (T ) v (S), also green agent .Now, consider green agent g non-green agent i. Suppose(a) exists coalition c CS g, supp(c) y0 (c)g > 0,(b) exists coalition c CS g, supp(c) x0 (c)i > 0.case (a) modify y0 making g transfer small amount payoff i, case (b)modify x0 making transfer small amount payoff g; choose transfersmall enough g remains green. white, becomes green, red,lowers contribution D. cases, get contradiction choice (x0 , y0 ). Thus,coalition c exists.Let Sg denote set green agents S, let Sng = \ Sg . x0 , every Snggets payoff coalitions CS whose support contains members Sg . Similarly, y0green agents get payoff coalitions CS contain members Sng .Now, suppose modify CS agents Sng abandon existing coalitionsform coalitions form among CS instead. Denote resulting coalitionstructure CS 0 . define imputation z0 CS 0 follows. imputation z0 coincidesy0 c supp(c) Sng = , coincides x0 coalition c0 formedmembers Sng . remaining coalitions CS 0 involve agents Sng agents\ Sng , may suffered reduction value relative CS Sng withdrewresources them; coalitions z0 distributes value arbitrarily among membersSng .argued above, (CS , x0 ) members Sng receive payoffs coalitionsfully control, pi (CS 0 , z0 ) pi (CS , x0 ) Sng . Further, since least oneagent red, pSng (CS , x0 ) > pSng (CS , y0 ). hand, (CS , y0 )members \ Sng receive payoff coalitions members Sng , letting Sngreceive payoffs coalitions affect payoff members\ Sng receive, relative received (CS , y0 ). Thus, \ Sng holdspi (CS 0 , z0 ) = pi (CS , y0 ). Hence, obtainv(CS 0 ) = pT (CS 0 , z0 )\Sng= p> p\Sng(8)0(CS , z0 ) + pSng(CS , y0 ) + p= v(CS ) = v (e ).8690(CS , z0 )Sng(CS , y0 )fiZ ICK , ARKAKIS , & E LKINDcontradiction shows set red agents empty hence pi (CS , y0 ) pi (CS , x0 )S.use Lemma 5.11 complete proof Proposition 5.10. DefineP (CS , CS ) = {(x, y) I(CS ) I(CS ) | pi (CS , y) pi (CS , x) S}.Lemma 5.11 implies P (CS , CS ) empty. Moreover, P (CS , CS ) compact; thus,contains point (x, y) minimizes value pS (CS , y) P (CS , CS ).Let (CS , CS ) set points (x, y) P (CS , CS ) minimize pS (CS , y);complete proof, identify point (x1 , y1 ) (CS , CS ) pS (CS , y1 ) =pS (CS , x1 ) = v (eS ).Given point (x, y) (CS , CS ), color agents follows: greenpi (CS , y) > pi (CS , x), white otherwise. Note that, since (x, y) P (CS , CS ),contains white agent i, pi (CS , y) = pi (CS , x). Let (x1 , y1 ) point(CS , CS ) maximizes number green agents .Now, consider green agent g white agent i. Suppose(a) g S, , coalition c CS g, supp(c) y(c)g > 0,(b) g, S, coalition c CS g, supp(c) x(c)i > 0.case (a) could transfer small amount payoff g CS either makegreen thereby increase number green vertices (if S) lower total payoffCS (if \ S), case (b) could transfer small amount payoff g CSmake green (again, choose transfer small enough g remains green).cases, get contradiction choice (x1 , y1 ).Let Sg set green agents S, let Sw = \ Sg set white agentsS. shown (CS , x1 ) members Sw receive payoffsjoint coalitions members Sg , (CS , y1 ) members Sg receive payoffs joint coalitions members Sw , pSw (CS , x1 ) v (eSw )pSg (CS , y1 ) v (eSg ). Thus, Sg 6= ,v (eS ) = pS (CS , x1 )(9)SgSwSg= p (CS , x1 ) + p(CS , x1 )< p (CS , y1 ) + v (eSw )v (eSg ) + v (eSw ).Thus, Sg 6= , v (eS ) < v (eSg ) + v (eSw ), contradiction superadditivity v .conclude Sg = , implies pi (CS , x1 ) = pi (CS , y1 ) S.Armed Proposition 5.10, ready prove following theorem.Theorem 5.12. G = hN, vi OCF-convex G = hN, Uv supermodular.Proof. Consider sets S, T, R N R N \ ; demonstrateUv (S R) Uv (S) Uv (T R) Uv (T ). Set 0 = R, 0 = R, consider coalition0structures CS CS(S), CS 0 CS(S 0 ) v(CS ) = v (eS ), v(CS 0 ) = v (eS ).870fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSProposition 5.10, exist imputations xS xS 0 pi (CS , xS ) = pi (CS 0 , xS 0 )S; thus, total payoff R (CS 0 , xS 0 ) v (eSR ) v (eS ).Consider outcome (CS , xT ) FT v(CS ) = v (eT ); since G OCF-convex,outcome (CS 0 , xT 0 ) better members 0 (CS 0 , xS 0 ), also paystotal least v (eT ). payoff R (CS 0 , xT 0 ) v(CS 0 ) pT (CS 0 , xT 0 ).v(CS 0 ) v (eT R ) pT (CS 0 , xT 0 ) v (eT ), payoff R (CS 0 , xT 0 )v (eT R ) v (eT ). Finally, OCF convexity G implies payoff R (CS 0 , xT 0 )least large payoff (CS 0 , xS 0 ). Combining inequalities, getUv (S R) Uv (S) = v (eSR ) v (eS )= pR (CS 0 , xS 0 )pR (CS 0 , xT 0 )v (eT R ) v (eT )= Uv (T R) Uv (T ),concludes proof.Theorem 5.12 shows OCF game OCF-convex, discrete superadditive coversupermodular. show converse always hold, i.e., supermodularitystrictly weaker property OCF convexity.Example 5.13. Consider game G = hN, vi N = {1, 2, 3} v defined follows:10v 0 = 1, v 1 = 1;00v1= 6, vv1= 4, v.50010.51011= 3;= 4;v(c) = 0 partial coalition c [0, 1]3 .Uv ({1}) = Uv ({2}) = 1, Uv ({3}) = 0;Uv ({1, 2}) = 6, Uv ({1, 3}) = Uv ({2, 3}) = 4;Uv (N ) = 9.One check Uv indeed supermodular.However, GIndeed,OCF-convex.set =001001{3}, = {1, 3}, R = {2}, CS =, CS =, CS SR =. Assume111players R share payoffs according xT = ((0, 0, 4)) xSR =((0, 4, 0)), respectively. G OCF-convex, exist coalition structure CSplayer 3 earns least 4 player 2 earnsleast 4. However,impossible: player 3 earns100least 4, CS contains either c = 0 c = 1 . c formed, player 2 get111; c0 formed, players 2 3 together get 4. Thus, waysatisfy agents demands.871fiZ ICK , ARKAKIS , & E LKIND5.2 Sensitive CoreRecall sensitive arbitration function, agent withhold payments deviators coalitions participates hurt deviation. Section 4.1, obtainedfollowing characterization sensitive core: outcome (CS , x) sensitive coreCS optimal coalition structure, set N holdsN \ total payoff receives investing resources coalitions involvingleast large marginal returns investing resources working (seeformula (4)).Let CS = (c1 , . . . , cm ) optimal coalition structure. Using characterization above,conclude deciding whether sensitive core contains outcome form (CS , x)equivalent determining whether value following linear program equals v (eN ).PminPj=1 isupp(cj )(10)xij v(cj )Ps.t.xijcj CSisupp(cj )pS (CS , x) v (wS (CS |S ) + wS (CS )) v (wS (CS |S )) N, N \note linear program (10) require xij 0 cj CSsupp(cj ). argument presented Appendix shows constraintssafely omitted. revisit point proof Theorem 5.15 contextrefined core.Consider dual linear program.maxPrj v(cj ) +j=1s.t.PPS,T (v (wS (CS |S ) +wS (CS )) v (wS (CS |S ))) (11)SN N \Srj +PPS:iSN \S:supp(cj )T 6=S,T = 1rj 0S,T 0cj CS , supp(cj )cj CSN, N \say collection non-negativeP weightsP {(rj )j=1 ; (S,T )SN ;T N \S } s-balancedrespect CS = (c1 , . . . , cm ) rj + S:iS N \S:supp(cj )T 6= S,T = 1 cj CSsupp(cj ). Applying linear programming duality linear programs (10) (11), obtainfollowing theorem.Theorem 5.14. sensitive core game G = hN, vi empty existscoalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ) every collectionnon-negative weights {(rj )mj=1 ; (S,T )SN ;T N \S } s-balanced respect CS holdsXj=1rj v(cj ) +XXS,T (v (wS (CS |S ) + wS (CS )) v (wS (CS |S ))) v (eN ).SN N \S872fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSTheorem 5.14 similar Theorem 5.2, presents criterion non-emptinessconservative core. main difference Theorem 5.2 considers collections weightscontain single weight set N , whereas sensitive core consider collectionsweights contain weight S,T pair disjoint sets S, N .5.3 Refined Coresensitive arbitration function, deviating players need decide nondeviating players wish work more. contrast, refined arbitrationfunction, deviators look coalitions non-deviators one one, decideworth keeping. provide characterization games nonempty refined core similar characterizations games non-empty conservativesensitive cores (Theorem 5.2 Theorem 5.14, respectively). Employing characterization,describe class OCF games non-empty refined core.Section 4.1, obtained following characterization outcomes refined core: givencoalition structure CS , imputation x I(CS ) (CS , x) refined corepS (CS 0 , x) v (wS (CS 0 )) every N every coalition structure CS 0 CScontaining CS |S .follows, given subset agents N coalition structure CS , write [CS ]S ={CS 0 CS | CS |S CS 0 }. Also, given coalition structure CS = (c1 , . . . , cm ), saycollection non-negative weights {(rj )mj=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respectCS cj CS supp(cj ) holdsXXrj +S,CS 0 = 1.S:iS CS 0 [CS ]S :cj CS 0ready present characterization.Theorem 5.15. refined core OCF game G = hN, vi non-emptyexists coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ) every collectionweights {(rj )mj=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respect CS holdsXrj v(cj ) +XXS,CS 0 v (wS (CS 0 )) v (eN ).SN CS 0 [CS ]Sj=1Proof. Fix coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ), consider following linear program.PminPj=1 isupp(cj )s.t.Pxij(12)xij v(cj )cj CSisupp(cj )pS (CS 0 , x) v (wS (CS 0 )) N, CS 0 [CS ]Sclaim refined core G contains outcome form (CS , x) valuelinear program v (eN ).873fiZ ICK , ARKAKIS , & E LKINDsee case, suffices observe that, argument Appendix A,omit constraints form xij 0 cj CS supp(cj ). fact, turnsrefined core, much simpler explanation holds: Non-negativity xij impliedstability constraints. see this, consider coalition cj supp(cj ). supp(cj ) = {i},xij = v(cj ) 0 done. Otherwise, consider coalition structure CS 0 = (CS |{i} , cj ).total payoff CS 0 pi (CS 0 , x) = pi (CS |{i} , x)+xij = v(CS |{i} )+xij . constraintcorresponds = {i} CS 0 states payoff must least v (w{i} (CS 0 )),least v(CS |{i} ), hence xij 0.Consider dual linear program (12).maxPPrj v(cj ) +j=1Prj +s.t.S,CS 0 v (wS (CS 0 ))(13)SNCS 0 [CS ]SS,CS 0 = 1cj CS , supp(cj )S,CS 0 0N, CS 0 [CS ]SS:iSCS 0 [CS ]S :cj CS 0rj 0cj CSObserve dual constraints (13) equalities since xij unconstrained (12). Notealso every feasible solution (13) corresponds collection non-negative weightsr-balanced respect CS . claim follows standard linear programming dualityargument.Theorem 5.15 enables us identify interesting class OCF games non-empty refinedcore. Recall function f : Rn R homogeneous degree k, k-homogeneous,f (x) = k f (x) R+ . Intuitively, means f scales consistent manner:players invest twice much resources coalition, get 2k times profit. returnsscale positive k 1 negative k < 1.Corollary 5.16. Consider OCF game G = hN, vi. v homogeneous degree k 1,refined core G non-empty.Proof. Consider coalition structure CS = (c1 , . . . , cm ) v(CS ) = v (eN ) collectionnon-negative weights {(rj )mj=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respect CS .According Theorem 5.15, suffices showXj=1rj v(cj ) +XS,CS 0 v (wS (CS 0 )) v (eN ).(14)SNCS 0 [CS ]SFirst, since v k-homogeneous,XSNCS 0 [CS ]SS,CS 0 v (wS (CS 0 )) v874XSNCS 0 [CS ]SS,CS 0 wS (CS 0 ).(15)fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSS,CS 0 wS (CS 0 ) .PDenote i-th coordinateSNCS 0 [CS ]S=XXS:iS CS 0 [CS ]S=Xcijj=1XS:iS=cijcj CS 0XS,CS 0CS 0 [CS ]cj CS 0XXS,CS 0S:cij (1 rj ),j=1Pfirst transition derived fact wi (CS 0 ) = cj CS 0 cij S,second transition uses fact {(rj )mj=1 ; (S,CS 0 )SN ;CS 0 [CS ]S } r-balanced respectCS . conclude right-hand side equation (15) upper-boundedv(X(1 rj )cj ).j=1consider first summand left-hand side (14). k-homogeneity v ,Xrj v(cj )j=1XXrj v (cj ) v (rj cj ).j=1j=1Using superadditivity v , obtain left-hand side (14) upper-boundedXXXv(rj cj +(1 rj )cj ) = v (cj ) = v (eN ).j=1j=1j=1concludes proof.fact, proof Corollary 5.16 shows stronger claim: v k-homogeneous, everyoptimal coalition structure CS admits imputation x I(CS ) (CS , x) refinedcore. case general; exist games optimal coalition structurescannot stabilized refined arbitration function, others can. illustratedfollowing example.Example 5.17. Consider following three-player game. four types tasks: tasktype t1 completed player 1 alone, requires resources, worth 5. tasktype t12 requires 50% player 2 player 1s resources worth 10. task type T12requires resources players 1 2 worth 20. Finally, task type t23 requiresplayer 3s resources 50% player 2s resources, worth 9. Consider coalitionstructures CS = (c1 , c2 ) CS 0 = (c01 ),.5.51c1 = .5 , c2 = .5 , c01 = 1 .008750fiZ ICK , ARKAKIS , & E LKINDeasy see CS CS 0 optimal game. Simply put, best players 12 work together earn total 20 (by completing t12 twice T12 once), player 3makes profit.First, claim CS cannot stabilized respect refined arbitration function.reason outcome (CS , x) refined core, must case player 2 getsleast 9 coalitions c1 c2 . However, means player 1 gets 2working player 2, get 5 working alone. hand, letimputation CS 0 splits payoff T12 evenly players 1 2. (CS 0 , y)refined core.Finally, note one cannot immediately employ LP duality argument characterizingOCF games non-empty optimistic core. difficulty optimistic arbitrationfunction number possible deviations infinite: deviating set needs specify amountresources withdraws coalition non-deviators. words, linear programdescribes optimistic core infinitely many constraints, dual infinitely manyvariables.6. Conclusions Future Workmain contribution work concept arbitration functions, analysisimpact arbitration stability cooperative games overlapping coalitions. conceptallows us put three notions stability proposed Chalkiadakis et al. (2010) broadercontext derive new notions stability sensitive core.Perhaps interesting results connection OCF games conservative arbitration function discrete superadditive covers. sense, showsplayers pessimistic assume post-deviation payoffs givenconservative arbitration function, little benefit employing OCF framework.words, main value OCF approach lies ability model non-trivial post-deviationinteractions. Thus, OCF framework eminently suitable settings agents reason expect deviating collaborative projects cause agentsboycott them. believe settings becoming increasingly common moderninterconnected society, multitasking norm collaboration necessary succeed.reaction non-deviators deviation plays decisive role analysis many strategicinteractions. example, Ackerman Branzei (2014) use concept arbitration functionanalysis Nash equilibrium pairwise equilibrium. Also, Branzei, Michalak, Rahwan,Larson, Jennings (2013) study matchings externalities; model viewedapplication idea arbitration functions matching problems. fact, strategic settingdeviating set must still interact non-deviators one reason nondeviators behavior deviation occurs. common make worst-case assumption,always appropriate realistic. Thus, notion similar arbitration functions mayuseful beyond setting cooperative games. instance, players interact market,behavior governed contracts (think wireless service provider consumer buyingnew data plan), clearly specify penalties failing fulfill ones obligations (in casewireless service providers, typically case withdrawal agreed-upon contractentails monetary penalty, i.e. worse-than-conservative reaction deviation). contracts876fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSviewed arbitration functions. Thus, concept arbitration function may usefulmodeling market interactions contracts.6.1 Future WorkSection 5, provided criteria core non-emptiness several arbitration functions.conservative refined core, also identified simple sufficient conditionscore non-empty (supermodularity discrete superadditive cover first-order homogeneity v , respectively). would useful obtain similar results natural notionsarbitration, sensitive arbitration function optimistic arbitration function.Another interesting research direction consider inverse problem: givenOCF game, generous arbitration function arbitrated coregame empty? formally, given game G, let us call arbitration function maxstable G Core(G, A) 6= , A0 A0 Core(G, A0 ) = .Simply put, arbitration function max-stable provides largest possible payoffsdeviators without destabilizing G. would interesting prove arbitration functionmax-stable class OCF games, or, ambitiously, completely characterize setmax-stable arbitration functions. line enquiry similar spirit concepts leastcore (Maschler et al., 1979), cost stability (Bejan & Gomez, 2009; Bachrach, Elkind, Meir,Pasechnik, Zuckerman, Rothe, & Rosenschein, 2009), taxation (Zick, Polukarov, & Jennings,2013).note model deviators allowed withdraw resources coalitions nondeviators, add resources coalitions. implications general definition,deviators add withdraw resources coalitions non-deviators,worth exploring well.analysis focuses core cooperative games overlapping coalitions. is,extent, reflection state art study classic cooperative games: corerelated notions (i.e., -core least core) studied greater detailcooperative solution concepts (barring, perhaps, Shapley value). analysis varioussolution concepts OCF games, nucleolus, kernel, bargaining set,relations one another, would greatly improve understanding overlapping coalitionformation. solution concepts OCF games briefly discussedZick Elkind (2011), analysis far complete.Finally, would interesting study models dynamic coalition formation cooperativegames overlapping coalitions. models explored classic cooperativegames (see, e.g., Arnold & Schwalbe, 2002; Lehrer & Scarsini, 2013), games overlapping coalitions fully cooperative agents (Shehory & Kraus, 1996), immediately clearextend prior work arbitrated OCF games. settings, arbitration functionsused method controlling coalition formation process: outcome stagecoalition formation process stable respect currently used arbitration function,permissive reaction deviation allowed future rounds; outcome unstable, playersassumed less tolerant towards deviators. Thus, controlling extent playersallowed deviate, one trade speed coalition formation process qualityresulting outcome.877fiZ ICK , ARKAKIS , & E LKINDAcknowledgmentsPart work done Y. Zick E. Elkind affiliated Nanyang Technological University, Singapore. Y. Zick supported Singapore International Graduate Award(SINGA), provided Agency Science, Technology Research (A*STAR). E. Markakissupported European Union (European Social Fund--ESF) Greek national fundsOperational Program Education Lifelong Learning National Strategic Reference Framework (NSRF)Research Funding Program: THALES. Investing knowledge societyEuropean Social Fund. E. Elkind supported National Research Foundation(Singapore) grant NRF RF2009-08. authors would like thank anonymous JAIRreviewers well anonymous reviewers earlier versions work (Zick & Elkind, 2011;Zick, Markakis, & Elkind, 2012). Y. Zick would also like thank anonymous reviewersPh.D thesis (Zick, 2014), parts incorporated paper.Appendix A. Note Characterization Conservative Corepurpose appendix fill gap proof characterization conservative core given Chalkiadakis et al. (2010) (see Theorem 5.2). argument alsoimplications characterization sensitive core (Section 5.2).proof Theorem 5.2 proceeds follows. Given optimal coalition structure CS =(c1 , . . . , cm ), consider following linear program:Pm Pminisupp(cj ) xjisupp(cj ) xj v(cj )j=1Ps.t.PPmj {1, . . . , m}(16)v (eS ) Nj=1 xjdual LP (16)maxs.t.Pmj=1 rj v(cj )rj ++PPSNS:iSv (eS )=1j, supp(cj )rj 0j {1, . . . , m}0N(17)Chalkiadakis et al. (2010)P argue LP (16) describes constraints conservative core,exception isupp(cj ) xij required least v(cj ) rather equal v(cj ).Thus,solution LP (16), (CS , x) conservative coreP xPis optimal= v(CS ) = v (eN ). LP duality implies value LP (17)xj=1isupp(cj ) jv (eN ) CS stabilized respect conservative arbitrationfunction.problem argumentPLP (16) require variablesP xj nonnegative, allows us rj + S:iS = 1 rather rj + S:iS 1dual LP. However, allow variables xij take negative values, effectivelybreaking payoff distribution requirement imputations. mention that, contrast,BondarevaShapley theorem acceptable impose non-negativity constraints explicitly,since stability constraints imply pi u({i}) 0. However, conservative core get878fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSv (e{i} ) N , imply individual xij non-negative.words, Chalkiadakis et al. (2010) show every c-balanced OCF game every optimalcoalition structure CS = (c1 , . . . , cm ) game admit pre-imputation x (CS , x)conservative core (recall x = (x1 , . . . , xm ) pre-imputationCS = (c1 , . . . , cm )Pfornnj = 1, . . . , holds xj vector R i=1 xij = v(cj )cij = 0 xij = 0, i.e., preimputation satisfies conditions imputation, exceptnon-negativity). argue one transform pre-imputation imputation.j:isupp(cj ) xjPTheorem A.1. exists pre-imputation x satisfies constraints LP (16),exists imputation x I(CS ) pi (CS , x) = pi (CS , x) N .Proof. Let Ipre (CS ) denote set pre-imputations coalition structure CS . Givenpoint x Ipre (CS ), define graph (x) = hV, Ei follows: vertices (x)V = {(i, j) | cj CS , supp(cj )} ,set edges E = E1 E2 ,E1 = (i, j), (i, j 0 ) | supp(cj ) supp(cj 0 ), j 6= j 0 ,E2 =(i, j), (i0 , j) | i, i0 supp(cj ), xij > 0 .is, E1 consists pairs (i, j), (i, j 0 ) supp(cj ) supp(cj 0 ), E2consists pairs (i, j), (i0 , j) i, i0 supp(cj ) cj CS xij > 0. edgeE2 means transfer small amount payoff i0 coalition cj , still maintainpositive payoff cj .Further, given point x Ipre (CS ), setTN (x) =XnXmin{0, xij }.j=1 i=1Fix arbitrary point x Ipre (CS ), consider setIpre (CS , x) = {y Ipre (CS ) | pi (CS , y) = pi (CS , x) N TN (y) TN (x)}.set Ipre (CS , x) compact TN continuous, exists point x Ipre (CS , x)maximizes TN Ipre (CS , x).Suppose exists coalition cj agent supp(cj ) xij < 0. Note(x) must edge E1 leaves (i , j ): otherwise, paid cj ,case wouldp (CS , x) =Xxij = xij < 0 v (e{i } ),j=1violating respective constraint LP (16).Let C minimum-length directed cycle (x) contains edge ((i , j ), (i , j0 ))cj0 CS well edges E2 . Note C contains path form(i, j1 ) (i, j2 ) (i, j3 );879fiZ ICK , ARKAKIS , & E LKINDedge ((i, j1 ), (i, j3 )) E1 , contradiction C minimum length.Moreover, C cannot contain path form(i1 , j) (i2 , j) (i3 , j);indeed, ((i1 , j), (i2 , j)) E2 , agent i1 receives positive payoff cj , henceedge ((i1 , j), (i3 , j)) also E2 , contradiction choice C.conclude minimum-length cycle passes (i , j ) intersects E2 mustform(i , j ) (i , j0 ) (i1 , j0 ) (i1 , j1 ) (i2 , j1 ) (it , j ) (i , j ).means receives positive payoff cj0 , i1 receives positive payoff cj1 , i2receives positive payoff cj2 and, general, i` receives positive payoff coalitioncj` 1 ` 1. Finally, player receives positive payoff cj .Now, pick satsifying0 < < min{xij0 , xij11 , . . . , xjt1, xijt },t1let = (y1 , . . . , ym ) pre-imputation obtained x transferring payoffi1 cj0 , i` i`+1 cj` ` =Pfrom ii cj .P1, . . . , i1,xcj CS .pi (CS , y) = pi (CS , x) N , isupp(cj ) yj =isupp(cj ) jTherefore, optimal solution LP (16). However, TN (y) > TN (x), contradictionchoice x. conclude (x) contains cycles pass (i , j ) intersect E2 .Let us defineNp = {i N | path (i , j ) (i, j) cj }.every Np every i0 N \Np , graph contains edge form ((i, j), (i0 , j)).Hence, i, i0 supp(cj ) xij 0. is, every coalition involves agents Npagents N \ Np payoffs split share agent Np non-positive.Hence, pNp (CS , x) pNp (CS |Np , x).Moreover, argue cj total share agents Np is, fact, negative,therefore pNp (CS , x) < pNp (CS |Np , x). Indeed, recall xij < 0. Suppose xij > 0Np ; note implies edge e = ((i, j ), (i , j )) E2 . Consider coalitioncj graph contains path P (i , j ) (i, j). j = j , adding e P obtaincycle passes (i , j ) intersects E2 . Otherwise, edge e0 = ((i, j), (i, j ))E1 , adding e0 e P results cycle passes (i , j ) intersects E2 .cases, get contradiction, argued cycle exists. Thus, playersNp get non-positive payoff cj , gets strictly negative payoff coalition.Consequently, pNp (CS , x) < pNp (CS |Np , x). hand,pNp (CS |Np , x) = v(CS |Np ) v (eNp );combining inequalities obtain pNp (CS , x) < v (eNp ), contradiction(CS , x) satisfying inequalities LP (16).conclude x imputation CS pi (CS , x) = pi (CS , x) Nxij 0 cj CS supp(cj ), concludes proof.880fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONS1,11,21,32,12,22,33,13,3Figure 1: graph (x) formed coalition structure imputation described Example A.2.Example A.2. Suppose players form coalition structure CS = (c1 , c2 , c3 ) given0.60.30.1c1 = 0.3 ,c2 = 0.6 ,c3 = 0.1 ,0.30use imputation x = (x1 , x2 , x3 ),02x1 = 2 ,x2 = 2 ,300.7x3 =301.resulting graph shown Figure 1, shortest cycle starting (3, 3) including edgesE2(3, 3) (3, 1) (1, 1) (1, 3) (3, 3).is, negative payoff player 3 c3 reduced player 3 transfers small amountpayoff player 1 c1 , player 1 transfers amount payoff player 3c3 ; instance, moving 1 unit payoff manner would result valid imputation.Theorem A.1 implies even assume xij unconstrained, solutionLP (16) value v (eN ), solution negative payoffs coalitionsvalue, i.e., optimal solution I(CS ). particular, meansloss generality assuming variables xij LP (16) unconstrained, thereforeTheorem 5.2 holds.ReferencesAckerman, M., & Branzei, S. (2014). Research quality, fairness, authorship order. Proceedings 13th International Conference Autonomous Agents Multiagent Systems(AAMAS-14), pp. 14871488.881fiZ ICK , ARKAKIS , & E LKINDAharoni, R., & Fleiner, T. (2003). lemma Scarf. Journal Combinatorial Theory, SeriesB, 87, 7280.Airiau, S., & Sen, S. (2009). fair payoff distribution myopic rational agents. Proceedings8th International Conference Autonomous Agents Multiagent Systems (AAMAS09), pp. 13051306.Anshelevich, E., & Hoefer, M. (2010). Contribution games social networks. Proceedings18th European Symposium Algorithms (ESA-10), pp. 158169.Arnold, T., & Schwalbe, U. (2002). Dynamic coalition formation core. Journal EconomicBehavior & Organization, 49(3), 363380.Aubin, J. (1981). Cooperative fuzzy games. Mathematics Operations Research, 6(1), 113.Aumann, R., & Dreze, J. (1974). Cooperative games coalition structures. International JournalGame Theory, 3, 217237.Bachrach, Y., Elkind, E., Meir, R., Pasechnik, D., Zuckerman, M., Rothe, J., & Rosenschein, J.(2009). cost stability coalitional games. Proceedings 2nd InternationalSymposium Algorithmic Game Theory (SAGT-09), pp. 122134.Bejan, C., & Gomez, J. C. (2009). Core extensions non-balanced TU-games. InternationalJournal Game Theory, 38(1), 316.Bondareva, O. (1963). applications linear programming methods theory cooperative games. Problemy kibernetiki, 10, 119139.Branzei, S., Michalak, T., Rahwan, T., Larson, K., & Jennings, N. R. (2013). Matchings externalities attitudes. Proceedings 12th International Conference AutonomousAgents Multi-Agent Systems (AAMAS-13), pp. 295302.Chalkiadakis, G., Elkind, E., Markakis, E., Polukarov, M., & Jennings, N. (2010). Cooperativegames overlapping coalitions. Journal Artificial Intelligence Research, 39, 179216.Chalkiadakis, G., Elkind, E., & Wooldridge, M. (2011). Computational Aspects CooperativeGame Theory. Morgan Claypool.Dang, V. D., Dash, R. K., Rogers, A., & Jennings, N. R. (2006). Overlapping coalition formationefficient data fusion multi-sensor networks. Proceedings 21st AAAI ConferenceAI (AAAI-06), pp. 635640.Deng, X., Ibaraki, T., & Nagamochi, H. (1999). Algorithmic aspects core combinatorialoptimization games. Mathematics Operations Research, 24(3), 751766.Gillies, D. (1953). Theorems n-Person Games. Ph.D. thesis, Princeton University.Jackson, M. O. (2003). survey models network formationstability efficiency.Demange, G., & Wooders, M. (Eds.), Group Formation Economics: Networks, ClubsCoalitions, chap. 1. Cambridge University Press.Lehrer, E., & Scarsini, M. (2013). core dynamic cooperative games. Dynamic GamesApplications, 3(3), 359373.Lin, C., & Hu, S. (2007). Multi-task overlapping coalition parallel formation algorithm. Proceedings 6th International Conference Autonomous Agents Multiagent Systems(AAMAS-07), p. 211.882fiA RBITRATION TABILITY C OOPERATIVE G AMES OVERLAPPING C OALITIONSMarkakis, E., & Saberi, A. (2005). core multicommodity flow game. Decision SupportSystems, 39(1), 310.Maschler, M., Peleg, B., & Shapley, L. S. (1979). Geometric properties kernel, nucleolus,related solution concepts. Mathematics Operations Research, 4(4), 303338.Peleg, B., & Sudholter, P. (2007). Introduction Theory Cooperative Games (Second edition)., Vol. 34 Theory Decision Library. Series C: Game Theory, Mathematical Programming Operations Research. Springer, Berlin.Rahwan, T. (2007). Algorithms Coalition Formation Multi-Agent Systems. Ph.D. thesis,University Southampton.Rahwan, T., & Jennings, N. (2008). improved dynamic programming algorithm coalitionstructure generation. Proceedings 7th International Conference AutonomousAgents Multiagent Systems (AAMAS-08), pp. 14171420.Shapley, L. S. (1967). balanced sets cores. Naval Research Logistics Quarterly, 14(4),453460.Shapley, L. S. (1971). Cores convex games. International Journal Game Theory, 1, 1126.Shehory, O., & Kraus, S. (1996). Formation overlapping coalitions precedence-ordered taskexecution among autonomous agents. Proceedings 2nd International ConferenceMulti-Agent Systems (ICMAS-96), pp. 330337.Sims, M., Corkill, D., & Lesser, V. (2008). Automated organization design multi-agent systems.Autonomous Agents Multi-Agent Systems, 16, 151185.Wang, T., Song, L., Han, Z., & Saad, W. (2013). Overlapping coalitional games collaborativesensing cognitive radio networks. Proceedings 2013 Wireless CommunicationsNetworking Conference (WCNC-13), pp. 41184123.Zhang, G., Jiang, J., Su, Z., Qi, M., & Fang, H. (2010). Searching overlapping coalitionsmultiple virtual organizations. Information Sciences, 180, 31403156.Zhang, Z., Song, L., Han, Z., Saad, W., & Lu, Z. (2013). Overlapping coalition formation gamescooperative interference management small cell networks. Proceedings 2013 WirelessCommunications Networking Conference (WCNC-13), pp. 643648.Zick, Y. (2014). Arbitration, Fairness Stability: Revenue Division Collaborative Settings.Ph.D. thesis, Nanyang Technological University.Zick, Y., Chalkiadakis, G., & Elkind, E. (2012). Overlapping coalition formation games: Chartingtractability frontier. Proceedings 11th International Conference AutonomousAgents Multiagent Systems (AAMAS-12), pp. 787794.Zick, Y., Chalkiadakis, G., Elkind, E., & Markakis, E. (2014). Cooperative games overlappingcoalitions: Charting tractability frontier. arXiv 1407:0420.Zick, Y., & Elkind, E. (2011). Arbitrators overlapping coalition formation games. Proceedings 10th International Conference Autonomous Agents Multiagent Systems(AAMAS-11), pp. 5562.Zick, Y., Markakis, E., & Elkind, E. (2012). Stability via convexity LP-duality OCF games.Proceedings 26th AAAI Conference AI (AAAI-12).883fiZ ICK , ARKAKIS , & E LKINDZick, Y., Polukarov, M., & Jennings, N. R. (2013). Taxation stability cooperative games.Proceedings 12th International Conference Autonomous Agents MultiagentSystems (AAMAS-13), pp. 523530.884fiJournal Artificial Intelligence Research 50 (2014) 805-845Submitted 02/14; published 08/14Speeding Iterative Ontology Alignment usingBlock-Coordinate DescentUthayasanker ThayasivamPrashant DoshiUTHAYASA @ CS . UGA . EDUPDOSHI @ CS . UGA . EDUTHINC Lab, Department Computer Science,University Georgia, Athens, GA 30602, USAAbstractdomains biomedicine, ontologies prominently utilized annotating data. Consequently, aligning ontologies facilitates integrating data. Several algorithms exist automatically aligning ontologies diverse levels performance. alignment applications evolveexhibit online run time constraints, performing alignment reasonable amount time without compromising quality alignment crucial challenge. large class alignmentalgorithms iterative often consumes time others delivering solutions highquality. present novel general approach speeding multivariable optimizationprocess utilized algorithms. Specifically, use technique block-coordinate descent(BCD), exploits subdimensions alignment problem identified using partitioningscheme. integrate approach multiple well-known alignment algorithms showenhanced algorithms generate similar improved alignments significantly less timecomprehensive testbed ontology pairs. BCD overly constrain partitionorder parts, vary partitioning ordering schemes order empirically determinebest schemes selected algorithms. biomedicine represents key applicationdomain ontologies, introduce comprehensive biomedical ontology testbed community order evaluate alignment algorithms. biomedical ontologies tend large,default iterative techniques find difficult produce good quality alignment within reasonableamount time. align significant number ontology pairs testbed using BCDenhanced algorithms. contributions represent important step toward making significantclass alignment techniques computationally feasible.1. IntroductionRecent advances Web-based ontologies provide needed alternative conventional schemasallowing descriptive annotations data sets. example, National Center BiomedicalOntology (NCBO) hosts 370 curated biomedical ontologies BioPortal includinghigh use SNOMED-CT, whose concepts participate 2 billion dataannotations (Musen et al., 2012). Therefore, present day challenge toward data integrationmanage multitude ontologies build bridges ontologies overlappingscope problem often referred ontology matching produces alignment (Euzenat & Shvaiko, 2007). illustrate partial alignment biomedical ontologies Fig. 1.Consequently, several algorithms exist automatically aligning ontologies using various techniques (Euzenat, Loup, Touzani, & Valtchev, 2004; Jian, Hu, Cheng, & Qu, 2005; Li, Li, & Tang,2007; Jean-Mary, Shironoshita, & Kabuka, 2009; Doshi, Kolli, & Thomas, 2009; Wang & Xu,2009; Hanif & Aono, 2009; Bock & Hettenhausen, 2010; Jimenez-Ruiz & Grau, 2011; Shvaiko &c2014AI Access Foundation. rights reserved.fiT HAYASIVAM & OSHIdatastarting material,intermediate material, endproducts scientificexperiment parametersprocessoccurrent entitiesaffect individualssamplespecimenagentresearcherindividual involvedexperimental processesroleEntitycontinuant entitiescausally affectindividuals processrole person,chemical compund,etc...worker_roleProcessual_Entity Publicsector workersexists time occurringhappening, temporal partsalways involves dependsentity.reagent_rolestatesdrugBuffer, dye, catalyst,solvating agent.drug_rolechemical substance that,absorbed cell,alters normal cell functiondrugregionregionSpecimenregionsampleregion(a)(b)Figure 1: Biomedicine important application domain ontologies. Alignment (showndashed red) portions of, (a) Parasite Experiment Ontology (PEO) and, (b)Ontology Biomedical Investigations (OBI) discovered automated algorithmcalled AgreementMaker (Cruz et al., 2012). ontologies available NCBO.identified map alignment signifies equivalence concepts.Euzenat, 2013), mixed levels performance. Crucial challenges algorithms involvescaling large ontologies performing alignment reasonable amount time withoutcompromising quality alignment. case point, 6 alignment algorithms (notincluding variants) 21 participated 2012 2013 instances annualontology alignment evaluation initiative (OAEI) competition (Shvaiko et al., 2012, 2013) generatedresults acceptable amount time aligning large biomedical ontologies.Although ontology alignment traditionally perceived offline one-time task, second challenge gaining importance. particular, Hughes Ashpole (2004) note, continuously evolving ontologies applications involving real-time ontology alignment semanticsearch Web service composition stress importance computational complexity considerations. Recently, established competitions OAEI (Shvaiko et al., 2011) began reportingexecution times participating alignment algorithms well. ontologies become larger,efficiency scalability become key properties alignment algorithms.large class algorithms performs automated alignment iterative nature (Melnik,Garcia-molina, & Rahm, 2002; Euzenat et al., 2004; Jian et al., 2005; Li et al., 2007; Doshi et al.,2009; Wang & Xu, 2009; Hanif & Aono, 2009; Bock & Hettenhausen, 2010). algorithmsrepeatedly improve previous preliminary solution optimizing measure solutionquality. Often, carried guided search alignment space using techniquesgradient descent expectation-maximization. algorithms may run convergence,means solution cannot improved a, possibly local, optimum.However, practice, runs often terminated ad hoc number iterations.repeated improvements, computed alignment usually high quality approachesalso consume time general non-iterative counterparts. example, algorithmsperforming among top three OAEI 2012 terms alignment quality YAM++ (Ngo& Bellahsene, 2012), ranked first conference track, Optima+, ranked third conference track, GOMMA (Kirsten et al., 2011), ranked first anatomy library tracks,806fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDiterative. 1 hand, YAM++ consumed excessive amount time completingconference track (greater 5 hours) Optima+ consumed comparatively time well.Furthermore, iterative techniques tend anytime algorithms, deliver alignmenteven algorithm interrupted convergence. considerations computationalcomplexity delivered ways scaling algorithms larger ontologies,ontology partitioning (Hu, Zhao, & Qu, 2006; Seddiqui & Aono, 2009; Stoutenburg, Kalita, Ewing,& Hines, 2010; Rahm, 2011) use inverted indices (Jimenez-Ruiz & Grau, 2011), seekspeed alignment process multiple algorithms. think considerations spacetime go hand hand context usability.primary contribution article general approach comprehensive evaluationsignificantly speeding convergence iterative ontology alignment techniques. Thayasivam Doshi (2012a) provide preliminary introduction approach. Objective functionsmeasure solution quality typically multidimensional. Instead traditional approachmodifying values large number variables iteration, decompose problem optimization subproblems objective optimized respect singlesmall subset, also called block, variables holding variables fixed. approachblock-coordinate descent (BCD) theoretically shown converge faster considerablyrelaxed conditions objective function pseudoconvexity even lackcertain cases existence optima variable (coordinate) block (Tseng, 2001).forms standard candidate tool multidimensional optimization statistics, appliedcontexts image reconstruction (Pinter, 2000; Fessler & Kim, 2011) channel capacitycomputation (Blahut, 1972; Arimoto, 1972), article presents use ontology alignment.extensively evaluate approach integrating multiple ontology alignment algorithms. selected Falcon-AO (Jian et al., 2005), MapPSO (Bock & Hettenhausen, 2010),OLA (Euzenat & Valtchev, 2004) Optima (Doshi et al., 2009) representative algorithms.algorithms participated OAEI competitions past, rankedtop tier. Consequently, algorithms default forms exhibit favorable alignment performance. Furthermore, implementations source codes needed approachfreely accessible.Using comprehensive testbed several ontology pairs large spanningmultiple domains, show significant reduction execution times alignment processesthereby converging faster. Corresponding alignment quality continues remainimproved small amount cases. enables application algorithmstoward aligning ontology pairs given amount time, subsets large ontologypartitions. Also, allows techniques run convergence possible contrastpredefined ad hoc number iterations, possibly leads similar improved alignments.useful context techniques guaranteed converge.BCD constrain alignment variables divided blocks except ruleblock chosen least cycle blocks. Furthermore, may orderblocks consideration manner within cycle. Consequently, second contributionempirical study impact different ordering partitioning schemes improvementBCD brings alignment. addition default ordering scheme based increasing heightgrouped entities, consider reversing ordering, third approach sample1. GOMMA utilizes multiple matching strategies may iterative, partly contributedtoward performance OAEI well.807fiT HAYASIVAM & OSHIblocks based probability distribution represents estimated likelihood finding largealignment block. context partitioning, additionally consider grouping alignmentvariables entities divided breadth-first search based partition. defaultapproach partitions one ontologies pair, also consider impact partitioning both.Performances iterative algorithms impacted differently various ways formulatingblocks ordering them. Notably, quality alignment may adversely impacted.Surprisingly, algorithms differ ordering partitioning scheme optimizesalignment performance. order comprehensively evaluate efficiency BCD-enhancedoptimized algorithms, contribute novel biomedical ontology alignment testbed. additionimportant application domain, aligning biomedical ontologies unique challenges. selected biomedical ontologies published NCBO testbed, also providesprimarily UMLS-sourced incomplete reference alignment. Thirty-two different biomedicalontologies form 50 pairs testbed half 3,000+ named classes.rest article organized follows. next section, briefly explain iterative ontology alignment introduce four representative iterative algorithms. Additionally,briefly review technical approach BCD. show BCD may integrated iterativeontology alignment algorithms Section 3. Section 4, empirically evaluate performancesBCD enhanced algorithms using comprehensive data set. Then, Section 5, exploreways ordering blocks partitioning alignment variables. Thereafter, Section 6,detail new biomedical ontology benchmark report performances BCD enhancedoptimized iterative techniques benchmark. discuss impact BCD alonglimitations Section 7, conclude article Section 8. Appendix outlines representative algorithms modifications utilize BCD, followed details biomedicalontology alignment testbed Appendix B.2. Backgroundprovide brief overview ontology alignment problem next subsection.followed brief descriptions four algorithms representative iterative alignmentapproaches. Finally, describe technique BCD general.2.1 Overview Ontology Alignmentontology specification knowledge pertaining domain interest formalizedentities relationships entities. Contemporary ontologies utilize description logics (Baader, Horrocks, & Sattler, 2003) Web Ontology Language (OWL) (McGuinness& Harmelen, 2004) order facilitate publication Web. OWL allows use classesrepresent entities, different types properties represent relationships, individuals includeinstances.ontology alignment problem find set correspondences two ontologies, O1O2 . Though OWL based description logic, several alignment algorithms model ontologieslabeled graphs (with possible loss information) due presence class hierarchyproperties relate classes, order facilitate alignment. example, Falcon-AOOptima transform OWL ontologies bipartite graph (Hayes & Gutierrez, 2004) OLAutilizes OL-graph (Euzenat et al., 2004). Consequently, alignment problem often castmatching problem graphs. ontology graph, O, defined as, = hV, E, Li where,808fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDV set uniquely labeled vertices representing entities, E set edges representingrelations, set ordered 2-subsets V , L mapping edgelabel. correspondence, , two entities, xa O1 O2 , consists relation,r {=, , }, confidence, c R. However, alignment algorithms use focuspossible presence = relation (also called equivalentClass OWL) entities only.case, alignment may represented |V1 | |V2 | matrix represents correspondencetwo ontologies, O1 = hV1 , E1 , L1 O2 = hV2 , E2 , L2 i:m11m12 m1|V2 |m21m22 m2|V2 |...=......m|V1 |1 m|V1 |2 m|V1 ||V2 |Note ontologies modeled graphs, rows columns conceptsO1 O2 defined description logic. assignment variable, , confidencecorrespondence entities, xa V1 V2 . Consequently, could realvalued matrix, commonly known similarity matrix two ontologies. However,confidence may also binary 1 indicating correspondence, otherwise 0, duematch matrix becomes binary matrix representing alignment. Two algorithmsuse maintain binary others use real .alignment limited correspondences entities alone, may include correspondences relationship labels well. order facilitate matching relationships,alignment techniques, including use transform edge-labeled graphs unlabeledbipartite ones elevating edge labels first-class citizens graph. process involvestreating relationships resources thereby adding nodes graph.2.2 Iterative Ontology Alignmentlarge class alignment algorithms iterative nature (Melnik et al., 2002; Euzenat et al., 2004;Jian et al., 2005; Li et al., 2007; Doshi et al., 2009; Wang & Xu, 2009; Hanif & Aono, 2009;Bock & Hettenhausen, 2010; Ngo & Bellahsene, 2012). Iterative algorithms utilize seed matrix,0 , iteratively improved converges. seed matrix either input usergenerated automatically often using fast string matching lexical matching.Two types iterative techniques predominant. differ next match matrix,, obtained previous iterations match matrix step. first type iterativealgorithms improve real-valued similarity matrix previous iteration, i1 , directlyupdating it:= U (M i1 )(1)where, U function updates similarities. type algorithms often convergesfixed point, , that, = U (M ). 2second type iterative algorithms repeatedly explicitly search space matchmatrices, denoted M. goal find alignment optimizes objective function,2. Convergence predicated U , fixed point may exist techniques. However, convergencedesirable property iterative alignment algorithms; absence stop criteria often ad hoc.809fiAlignment QualityHAYASIVAM & OSHISpace AlignmentsFigure 2: iterative update search jump one alignment another improvingprevious one. two differ obtain next alignment iterationqualitative metric used assessing it. alignment cannot improvedsignifies convergence.gives measure quality alignment context alignmentprevious iteration. approach appropriate search space boundedmatch matrix binary. Nevertheless, cardinality 2|V1 ||V2 | space could getlarge. algorithms sample space reduce effective search space though scalinglarge ontologies continues remain challenging. Formally,Mi = arg max Q(M, Mi1 )(2)where, Mi alignment optimizes Q function iteration given best alignmentprevious iteration, Mi1 . Convergence algorithms occurs iterations reachpoint, , cannot improved searching alignment matrix, M,Q(M, ) > Q(M , ). Equations 1 2 help solve multidimensional optimization problemiteratively variables. abstractly illustrate iterative approaches Fig. 2.Fig. 3, show abstract algorithms two types iterative approaches.iterative update Fig. 3(a), may settle near fixed point calculating distancepair alignment matrices (line 8) terminating iterations distance withinparameter, . 0 get closer fixed point obtain fixed point limit.Iterative search Fig. 3(b) often requires seed map (line 3) obtain 0 , typicallygenerated using fast lexical matching.Next, briefly review four ontology alignment algorithms optimize iteratively. selection algorithms based accessibility competitive performance previousOAEI competitions, meant representative iteration-based alignment algorithms. 32.2.1 FALCON -AOFalcon-AO (Jian et al., 2005) well-known automated ontology alignment system combiningoutput multiple components including linguistic matcher, iterative structural graph matching algorithm called GMO (Hu, Jian, Qu, & Wang, 2005), method partitioning largeontologies focusing parts.3. sought include YAM++ well evaluation, top performer conference track OAEI2012 2013. However, source code freely available could access it.810fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDTERATIVE U PDATE (O1 , O2 , )TERATIVE EARCH (O1 , O2 )Initialize:1. Iteration counter 02. Calculate similarityentities O1 O2 using measure3. Populate real-valued matrix, 0 ,initial similarity values4. 0Initialize:1. Iteration counter 02. Generate seed mapO1 O23. Populate binary matrix, 0 ,seed correspondences4. 0Iterate:5.6.ii+17.= U (M i1 )8.Dist(M , )9.10.11. Extract alignmentIterate:5.6.ii+17.Search arg max Q(M, i1 )8.9. 6= i110. Extract alignment(a)(b)Figure 3: General algorithms iterative (a) update, (b) search approaches toward aligningontologies. distance function, Dist, line 8 (a) measure differencetwo real-valued matrices.GMO measures structural similarity ontologies modeled bipartitegraphs (Hayes & Gutierrez, 2004). Matrix GMO real-valued similarity matrixiteratively updated (Eq. 1) updating variable, , average neighborhoodsimilarities stops changing significantly. GMO takes external input, typically obtainedlexical matching, seed. Equation 1 manifests GMO series matrix operations:= G1 i1 GT2 + GT1 i1 G2(3)Here, G1 G2 adjacency matrices bipartite models two ontologies O1 O2 ,respectively. first term summation, outbound neighborhood entities O1O2 considered, second term considers inbound neighborhood. Iterations terminatecosine similarity successive matrices, i1 , less parameter, .iterative update algorithm manifests Falcon-AO shown Fig. 17(a) Appendix A.2.2.2 AP PSOMapPSO (Bock & Hettenhausen, 2010) utilizes discrete particle swarms perform optimization. K particles swarm represents valid candidate alignment, updatediteratively. iteration, given particle(s) representing best alignment(s) swarm,alignments particles adjusted influenced best particle.Equation 2 manifests MapPSO two-step process consisting retaining best particle(s) (alignment(s)) replacing others improved ones influenced best alignmentprevious iteration. measure quality alignment k th particle determined811fiT HAYASIVAM & OSHImean measures correspondences shown below:Q(Mki )=|VP1 | |VP2 |f (xa , )a=1 =1|V1 ||V2 |(4)where, correspondence Mki f represents weighted combination multiple syntactic possibly semantic similarity measures entities two ontologies. Improvedparticles generated keeping aside random number best correspondences according fparticle, replacing others based correspondences previous best particle. Iterations terminate increment Q due new alignment matrix lower parameter,. Iterative search Eq. 2 manifests MapPSO shown algorithm Fig. 18(a).2.2.3 OWL-L ITE LIGNMENTOWL-Lite alignment (OLA) (Euzenat et al., 2004) limited aligning ontologies expressedOWL emphasis restricted dialect called OWL-Lite. OLA adopts bipartitegraph model ontology, distinguishes 8 types nodes classes, objects,properties, restrictions others; 5 types edges: rdfs:subClassOf, rdf:type,classes properties, objects property instances, owl:Restriction, properties individuals.OLA computes similarity pair entities two ontologies weightedaggregation similarities respective neighborhood entities. Due considerationmultiple types edges, cycles common. Consequently, computes similaritiesentities solution large system linear equations, solved iteratively fixed point.Let F(xa ) set nodes O1 , connected node xa via edge type,F. Formally, similarity Sim(xa , ), vertex, xa O1 , vertex, O2 , defined as,XSim(xa , ) =wFSetSim(F(xa ), F(y ))(5)F N (xa ,y ),where, N (xa , ) set edge types xa , Pparticipate. Weight, wFwF = 1. Function, SetSim,entity pair, xa , , edge type, F, normalized, i.e.,F N (xa ,y )evaluates similarity sets, F(xa ) F(y ), average maximal pairing.OLA initializes real-valued similarity matrix, 0 , values based lexical attributesonly, iterations update variable, , matrix using structure twoontologies. particular, two entities, xa type, updated usingEq. 5, otherwise value 0. Iterative update Eq. 1 realized OLA Fig. 19(a)Appendix A.2.2.4 PTIMAOptima (Doshi et al., 2009) formulates ontology alignment maximum likelihood problem,searches match matrix, , gives maximum conditional probability observingontology O1 , given ontology, O2 , match matrix .employs generalized expectation-maximization solve optimization problem which,iteratively evaluates expected log likelihood candidate alignment picks onemaximizes it. implements Eq. 2 two-step process computing expectation followed812fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDmaximization, iterated convergence. expectation step consists evaluatingexpected log likelihood candidate alignment given previous iterations alignment:Q(M |M i1 ) =|V1 | |V2 |XXP r(y |xa , i1 ) logP r(xa |y , )i(6)a=1 =1where, xa entities ontologies O1 O2 respectively, prior probability. P r(xa |y , ) probability node xa correspondence node givenmatch matrix . prior probability computed as,|V1 |=1 XP r(y |xa , i1 )|V1 |a=1generalized maximization involves finding matrix, Mi , improves previous one:Mi = : Q(M |Mi1 ) Q(Mi1 |Mi1 )(7)show iterative alignment algorithm Optima Fig. 20(a).Altogether, four alignment algorithms describe subsection represent broadvariety iterative update search techniques, realized different ways. facilitates broadevaluation usefulness BCD. years, algorithms Falcon-AO, OLA Optima performed satisfactorily annual OAEI competitions, Falcon-AO Optimademonstrating strong performances respect comparative quality generated alignment. example, Falcon-AO often ranked top 3 systems participated OAEIcompetitions 2005 2010, performance continues remain benchmarkalgorithms. Optima enhanced BCD (called Optima+) ranked second conferencetrack (F2-measure recall) 2012 edition OAEI competition (Thayasivam & Doshi,2012b). Consequently, representative algorithms exhibit strong alignment performances.hand, MapPSOs performance comparatively poor particle-swarm based iterative approach motivates selection representative set.2.3 Block-Coordinate DescentLarge-scale multidimensional optimization problems maximize minimize real-valued continuously differentiable objective function, Q, N real variables. Block-coordinate descent (BCD)(Tseng, 2001) established iterative technique gain faster convergence contextlarge-scale N -dimensional optimization problems. technique, within iteration, setvariables referred coordinates chosen objective function, Q, optimizedrespect one coordinate blocks coordinates held fixed. applicationsetting, recall coordinates alignment variables match matrix, .Let denote block coordinates, non-empty subset {1, 2, . . . , N }. Define setblocks as, B = {S0 , S1 , . . . , SC }, set subsets representing coordinateblock constraint that, S0 S1 . . . SC = {1, 2, . . . , N }. B could single blockpartition coordinates although required blocks may intersect. alsodefine complement coordinate block, Sc , c {0, 1, . . . , C}, as, Sc = B Sc .813fiT HAYASIVAM & OSHIillustrate, let domain real-valued, continuously differentiable, multidimensional function, Q,N = 10 be, = {m1 , m2 , m3 , . . . , m10 }, element variable. may partitionset coordinates two blocks, C = 2, that, B = {S0 , S1 }. Let S0 = {m2 , m5 , m8 }S1 = {m1 , m3 , m4 , m6 , m7 , m9 , m10 }. Finally, S0 denotes block, S1 .BCD converges fixed point local global optimum objective functionrelaxed conditions pseudoconvexity function requires functionbounded level sets (Tseng, 2001). pseudoconvex functions continue fixed points,may non-unique optima along different coordinate directions. absence pseudoconvexity, BCD may oscillate without approaching fixed point function. Nevertheless, BCDstill converges function unique optima coordinate blocks.order converge using BCD, must satisfy following rule, ensurescoordinate chosen sufficiently often (Tseng, 2001).Definition 1 (Cyclic rule) exists constant, C C > 0, every block, Sc ,chosen least ith iteration (i + 1)th iteration, i.context cyclic rule, BCD mandate specific partitioning ordering schemeblocks. simple way meet rule sequentially iterating blockalthough must continue iterating block converges fixed point.Recently, Saha Tewari (2013) show nonasymptotic convergence rate 4 BCDcyclic rule faster gradient descent (GC) startpoint, conditions objective function, Q, Lipschitz continuous gradient (itdifferentiable everywhere bounded derivative) strongly convex, QLisotonic, identity function L Lipschitz constant. Starting00 , letinitial map, MBCD= MGCBCD MGC denote alignment iteration BCDcyclic rule GC, respectively. condition objective function, Q, must). nonasymptoticsay, minimized, continuous isotonic, 1, Q(MBCD) Q(MGCconvergence rate BCD cyclic rule objective functions previous propertiesis, O(1/i), iteration count.3. Integrating BCD Iterative Alignmentmentioned previously, ontology alignment may approached principled multivariableoptimization objective function, variables correspondencesentities two ontologies. Different algorithms formulate objective function differently.objective functions often complex difficult differentiate, numerical iterative techniquesappropriate tend progress slowly. context, may speed convergencerate using BCD describe below.3.1 General ApproachSection 2.2, identified two types iterative ontology alignment algorithms. BCD mayintegrated types. order integrate BCD iterations, match matrix,, must first suitably partitioned blocks. course, existing algorithms may viewedsingle block variables therefore trivially utilizing BCD.4. rate convergence effective first iteration itself.814fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDThough matrix may partitioned using one several ways, adopt approachwell supported context ontology alignment. important heuristic, provedhighly successful ontology schema alignment, matches parent entities two ontologiesrespective child entities previously matched (Doan, Madhavan, Domingos, & Halevy,2003). motivates grouping together variables, , coordinate blockxa participating correspondence belong height leading partition. height ontology node length shortest path leaf node. Subsequently,alignment blocks less height (containing child entities) optimized first followedincreasing height (containing parent entities). determining height, utilizetree graph model ontology built internally respective ontology alignmentalgorithm. include property nodes may differ algorithms.Let partition coordinate blocks {MS0 , MS1 , . . . , MSC }, C heightlargest class hierarchy ontology O1 . Thus, block submatrix many rowsnumber entities O1 height number columns equal number entitiesO2 . example, correspondences leaf entities O1 entities O2 formblock, MS0 . context bipartite graph model utilized Falcon-AO Optima,represents properties ontology vertices well therefore part ,would included coordinate blocks.Iterative ontology alignment integrated BCD optimizes respect single block, MSc ,iteration keeping remaining blocks fixed. order meet cyclic rule, chooseblock, MSc , iterations, = c + qC q {0, 1, 2, . . .}. point BCD applicabletypes iterative alignment techniques outlined Section 2.2. Alignment algorithmsupdate similarity matrix iteratively Eq. 1 update current block interest,MSc , remaining blocks carried forward is, shown below:MSi c = USc (M i1 )MSi = MSi1Sc(8)Sc complement Sc B. Note MSi c combined MSi Sc forms. Update function, USc , modifies U Eq. 1 update block coordinates.Analogously, iterative alignment searches candidate alignment maximizesobjective function Eq. 2, choose block, MSc , iteration. searchreduced search space pertaining subset variables included MSc , bestcandidate coordinate block. Formally,MSi c , = arg max QS MSc , Mi1MSc MSc(9)= i1MS,cS,where, MSc space alignments limited block, Sc . original objective function, Q,modified QS provides measure quality block, MSc , given previousbest match matrix. Note previous iterations matrix, Mi1 , contains best blockinterest iteration.Performing update, USc , evaluating objective function, QS , focusing coordinate block may performed significantly reduced time compared performingoperations entire alignment matrix. may perform iterations cycle815fiT HAYASIVAM & OSHI2.2e+07Q-Value2.1e+072e+071.9e+071.8e+071.7e+07Optima BCDOptima1.6e+070102030405060time (s)Figure 4: BCD facilitates faster convergence aligning ontologies iasted sigkdd relatedconference organization.blocks, use partially updated matrices previous iteration evaluatingnext block facilitates faster convergence. illustrate impact BCD iterative searchperformed Optima example ontology pair Fig. 4. Alignment using BCD showsfaster convergence rate.TERATIVE U PDATE BCD (O1 , O2 , )TERATIVE EARCH BCD (O1 , O2 )Initialize:1. Iteration counter 02. Calculate similarityentities O1 O2 using measure3. Populate real-valued matrix, 0 ,initial similarity values4. Create partition :{MS0 , MS1 , . . . , MSC }5. 0Initialize:1. Iteration counter 02. Generate seed mapO1 O23. Populate binary matrix, 0 ,seed correspondences4. Create partition :{MS0 , MS1 , . . . , MSC }5. 0Iterate:6.7.c % (C + 1), + 18.MSi c USc (M i1 )9.MSi MSi1 Sc10. c = C11.Dist(M , )else12.high value13.14.15. Extract alignmentIterate:6.7.c % (C + 1), + 18.Search MSi c , arg max QS MSc , Mi1MSc MSci1MS,MS,Scc = Cchanged Mi 6= Mi1 ?else12.changed true13. changed14. Extract alignment Mi9.10.11.(a)(b)Figure 5: General iterative algorithms Fig. 3 modified obtain, (a) iterative update enhancedBCD, (b) iterative search enhanced BCD. update search steps linenumbers 8 9 modified update current block interest.816fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDAlgorithms Fig. 5 revise iterative update search algorithms Fig. 3 orderintegrate BCD. primary differences involve creating partition alignment matrix,(line 4), iterations sequentially process coordinate block keepingothers fixed (lines 7-9). completing cycle coordinate blocks determinedcheck line 10, evaluate whether new alignment matrix differs one previousiteration, continue iterations (lines 11-13). Observe regular iterationsimproving full match matrix replaced mini-iterations updating blocks.Given general modifications brought BCD, describe manifestfour iterative alignment systems form representative set. modifications basedtype iterative technique uniform within group. change corealignment approach algorithm given input see next.3.2 BCD Enhanced Falcon-AOenhance Falcon-AO modifying GMO utilize BCD iterates. depicted Fig. 17(b),begin partitioning similarity matrix used GMO C + 1 blocks based heightentities O1 part correspondences, mentioned previously. GMOmodified iteration, block similarity matrix updated blocksremain unchanged. block, Sc , updated iteration i, Eq. 3 becomes:MSi c = G1,Sc i1 GT2 + GT1,Sc i1 G2MSi = MSi1 Sc(10)Here, G1,Sc focuses portion adjacency matrix O1 corresponds outboundneighborhood entities participating correspondences block Sc , GT1,Sc focusesinbound neighborhood entities Sc . Adjacency matrix, G2 , utilized before. outcomematrix operations similarity matrix, many rows variables Sc columnscorresponding entities O2 . complete similarity matrix obtained iteration, i,carrying forward remaining blocks unchanged, utilized next iteration.general iterative update modified perform BCD Fig. 5(a) may realized Falcon-AOalgorithm Fig. 17(b) Appendix A.3.3 BCD Enhanced MapPSOmay integrate BCD MapPSO ordering particles swarm based measurequality coordinate block, Sc , particle iteration. Equation 4 modifiedmeasure quality correspondences coordinate block Sc , k th particletaking average:|VP1,c | |VP2 |f (xa , )a=1 =1QS (Mk ) =(11)|V1,c ||V2 |where, V1,c denotes set entities ontology, O1 , identical height participating correspondences included block Sc . before, retain best particle(s) based measure, remaining particles using bestimprove alignment coordinate block, Mk,Scparticle previous iteration. remaining coordinates held unchanged. Iterative searchMapPSO modified using BCD shown algorithm Fig. 18(b).817fiT HAYASIVAM & OSHI3.4 BCD Enhanced OLAexplained earlier, OLA evolves similarity matrix similarity exchange pairsneighboring entities. iteration, performs element-wise matrix update operation. OLAenhanced BCD adopting Eq. 8. Specifically, similarity values coordinateschosen block, Sc , updated using similarity computations (Eq. 5). remaining blocks,MSi , kept unchanged.cmia=Sim(xa , ) types xa, miaSc0otherwise(12)MSi = MSi1 Sc3.5 BCD Enhanced Optimamentioned previously, Optima utilizes generalized expectation-maximization iterativelyimprove likelihood candidate alignments. Jeffery Alfred (1994) discuss BCD inspired expectation-maximization scheme call space alternating generalized expectationmaximization (SAGE). Intuitively, SAGE maximizes expected log likelihood block coordinates thereby limiting hidden space, instead maximizing likelihood completealignment. sequence block updates SAGE monotonically improves objective likelihood. regular objective function, monotonicity property ensures sequencediverge, guarantee convergence. However, proper initialization lets SAGE convergelocally. 5 iteration, Optima enhanced using SAGE chooses block match matrix,MSi c , expected log likelihood estimated. previous techniques, choose blockssequential manner blocks iterated order.Equation 6 changes estimate expected log likelihood block candidate alignment:|V1,c | |V2 |QS (MSi c |M i1 ) =XXP r(y |xa , i1 ) logP r(xa |y , MSi c ) ,c(13)a=1 =1Recall V1,c denotes set entities ontology, O1 , participating correspondences, modified well utilize Vincluded Sc . Notice prior probability, ,c1,ccalculations.generalized maximization step involves finding match matrix block, MSi c , ,improves previous one:|Mi1 )MSi c , = MSi c MSc : QS (MSi c , |Mi1 ) QS (MSi1c ,(14)Here, MSi1part Mi1 .c ,iteration i, best alignment matrix Mi , formed combining block MSi c , ,i1improves QS defined Eq. 14 remaining blocks previous iteration, MS,,complement Sc , unchanged.5. Furthermore, convergence rate may improved choosing hidden space less Fisher information (Hero& Fessler, 1993).818fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDalgorithm Fig. 20(b) shows Optima may enhanced BCD. expect significant savings time search reduced space alignments focused block,MSc , iteration. Additionally, objective function, QS , prior operatesingle coordinate block reduced time. Finally, using aligned blocks next iteration improvesconvergence rate.4. Empirical Analysisuse BCD expected make iterative approaches exhibit greater rate improvement, approach converges, reach fixed point faster, seek empirically determine:1. amount speed obtained various alignment algorithms integrating BCD;2. Changes quality final alignment, any, due BCD. may happeniterations converge different local optimum.OntologyNamed ClassesConference domainekaw74sigkdd49iasted150cmt36edas104confOf38conference60Life Sciencesmouse anatomy2,744human anatomy3,304Properties3328415950366423Table 1: Ontologies OAEI 2012 used evaluation. show number named classesproperties estimate size. Notice evaluation includeslarge ontologies different domains well. Additionally, ThayasivamDoshi (2012a) present evaluations four pairs 300 range bibliographybenchmark competition.use comprehensive testbed several ontology pairs large spanningtwo domains. used ontology pairs OAEI competition 2012 version testbedevaluation (Shvaiko et al., 2012). Among OAEI tracks, focus test casesinvolve real-world ontologies reference (true) alignment provided OAEI.ontologies either acquired Web created independentlybased real-world resources. includes pairs expressive ontologies conferencetrack structure knowledge related conference organization, anatomy track,consists pair mid-sized ontologies life sciences describing anatomyadult mouse human. list ontologies OAEI participating evaluationTable 1 provide indication sizes. Additionally, Thayasivam Doshi (2012a)evaluate Falcon-AO, MapPSO Optima BCD four pairs 300 range819fiT HAYASIVAM & OSHIbibliography benchmark competition. Ontology pairs 100 200 ranges bibliographybenchmark utilized participating ontologies small 33 classes64 properties. Subsequently, representative iterative techniques align quicklyorder milliseconds leaving significant room improvement.align ontology pairs using four representative algorithms, original formsBCD using seed alignment, 0 , applicable. iterations run algorithmconverged measured total execution time, final recall, precision F-measure,number iterations performed convergence. Recall measures fraction correspondencesreference alignment found algorithm precision measures fractionfound correspondences reference alignment thereby indicating fractionfalse positives. F-measure represents harmonic mean recall precision.averaged results 5 runs every ontology pair using original BCDenhanced version algorithm. large number total runs, ran teststwo different computing platforms ensuring comparability. One Red Hat machineIntel Xeon Core 2, processor speed 3 GHz 8GB memory (anatomy ontologypair) one Windows 7 machine Intel Core i7, 1.6 GHz processor 4GBmemory (benchmark conference ontology pairs). comparing performance metricsstatistical significance, tested data normality used Students paired t-test exhibitsnormality. Otherwise, employed Wilcoxon signed-rank test. utilized 1% level (p0.01) deem significance.Thayasivam Doshi (2012a) previously evaluate OLA bibliography domainontology pairs, discuss performance article completeness. Similar algorithms, introduction BCD OLA reduced execution time four pairs total 1.3seconds compared original time 27.3 seconds. OLAs precision recall reduced slightlycausing F-measure reduce 1% ontology pair (302,101), alignmentspairs remained same.ontologies conference domain vary widely size structure. shownFig. 6, introduction BCD four iterative techniques clearly improves speedconvergence differences algorithm significant (Students paired t-test, p0.01). particular, observed order magnitude reduction time aligning relativelylarger ontologies iasted edas. example, pairs (conference, iasted) MapPSO(edas, iasted) Optima showed reductions. Overall, observed total reduction 50seconds Falcon-AO 3 minutes, 1 minute 37 seconds MapPSO, 31 seconds OLAtotal 1 minute 37 seconds, 29 minutes 20 seconds Optima 4 minutes53 seconds.Falcon-AO shows change due BCD alignment, holding precision 25%recall 66%. Optima shows 4% improvement average precision 56% 60% averagerecall reduced 70% 68%. Nevertheless, causes 2% improvement average F-measure64%. MapPSO BCD resulted significant improvement final precision 9%43% average, although difference recall significant. precision recallOLA remained unchanged.mid-sized anatomy ontologies mouse human successfully alignedMapPSO OLA despite use BCD. However, BCD reduced Falcon-AOs average execution time aligning single ontology pair 6.2 seconds 2.6 minutes, drasticallyreduced Optimas average execution time 4.4 minutes 62.7 minutes. alignment gen820fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD6020Falcon-AOFalcon-AO BCD1614Time (sec)40Time (sec)MapPSOMapPSO BCD1850302012108610420eerf(ct,Cdaencfe(C(c,i(e)f)awfO,ekt,cnfe(Cnftef,esigce))dakd,eig(ckdt,s))))enc(cfe(a),iced),sce(c(cw)kaf,ef,enfnfe(cs)dakdignfe(cd)teencnf(c(b)10OLAOLA BCDOptimaOptima BCD10008Time (sec)Time (sec)10064101200.1s)d)dakd(cg,sie,incenrfe(Cfeer(C)edst,eced)te-iada(eka(e)d)edstiaw,e)kdg,sit,(c(c)nConcfeawk(e(cd)f)fOkdn,co(cs,ida(e(d))edstg,sika(ed))kdedstiaw,sig,edst(iaFigure 6: Average execution time consumed by, (a) Falcon-AO, (b) MapPSO, (c) OLA, (d)Optima original form BCD, 6 21 ontology pairs conference domain. ran algorithms pairs, selected ontology pairsexhibited three highest three lowest differences average execution timesclarity. Note time axis (d) log scale. Notice improvementsexecution time larger pairs. Specifically, 50% reduction average execution time ontology pair (edas, iasted) Falcon-AO order magnitudereductions average run time ontology pairs (conference, iasted) MapPSO(edas, iasted) Optima, observed.erated Falcon-AO BCD remained unchanged 76.1% precision 80% recallalignment Optima BCD improved precision 96% recall 74.2%.Falcon-AO Optima automatically utilized ontology partitioning methods order alignmid-sized pairs.summary, introduction BCD led significant reductions convergence timefour iterative algorithms several ontology pairs, extending order magnitude. Simultaneously, quality final alignments indicated F-measure improved pairs,one pair showing reduction context Optima. However, observe changeF-measure many pairs. Therefore, empirical observations indicate BCDsignificant adverse impact quality alignment.821fiT HAYASIVAM & OSHI5. Optimizing BCD using Ordering Partitioning Schemesmentioned previously, BCD overly constrain formation coordinate blocksneither impose ordering consideration blocks, satisfyingcyclic rule. Consequently, explore ways ordering blocks partitioningalignment variables context representative algorithms. include:1. Ordered roots leaves: Cycle blocks decreasing height starting blockcontaining entities largest height.2. Ordered similarity distribution: Obtain aggregate measure lexical similarity ontology entities participating block. normalized distribution similarities provides likelihood picking next block.3. ontologies partitioned: block contains participating entities ontologyheight.4. Subtree-based partitioning: Transform ontology tree form block variablesparticipating entities part subtree predefined size.5. Random partitioning: Form block randomly selecting alignment variables inclusion.partitioning ordering utilized previous section intuitive, objectivediscover ways may improve run time performances algorithms. subsequent experimentation, exclude MapPSO representative set due randomnessalgorithm, leads comparatively high variability run times.5.1 Ordering Blocksorder blocks processed may affect performance. updatedcorrespondences previous blocks used generating alignment current block.Initially, blocks participating entities increasing height beginning leaves usedillustrated Fig. 7. ordering schemes could improve performance:may reverse previous ordering cycling blocks decreasing height, beginningblock contains entities largest height. leads processing parententities first followed children.may obtain quick approximate estimate amount alignment blockvariables. One way compute aggregate measure lexical similarityentities two ontologies participating block. Assuming similarity estimate amount alignment block, may convert estimatesprobability distribution gives likelihood finding multiple correspondencesblock. block process next sampled distribution. approachrequires relaxation cyclic rule particular block guaranteed selected. regard, expectation selecting block sufficient obtain asymptoticconvergence BCD (Nesterov, 2012).822fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDroleagentdataworker_rolesamplereagent_roleresearcherdrugdrug_roleSpecimenO2drugm11m12m13m14m15agentm21m22m23m24m25samplem31m32m33m34m35researcherm41m42m43m44m45m51m52m53m54m55O1dataFigure 7: Presence absence correspondences entities two ontologies representedmatch matrix. Concepts drug, sample, researcher leaves correspondences may grouped block (highlighted). may process blockfirst followed block containing data agent. Alternately, may reverseordering optimizing blocks.compare performances alternate ordering schemes initial 21 ontology pairs conference domain. results reversing order original schemeshown Fig. 8. Clearly, original ordering allows three BCD-enhanced approachesconverge faster general. Optimas average recall across pairs improved slightly68% 70%, average precision reduced 4% final 56%. Falcon-AOs average F-measureimproved insignificantly overall expense 40 seconds run time. Reversing orderimpact precision recall OLA. results insightful reinforceusefulness alignment heuristic motivating original ordering scheme.second alternate ordering scheme involves determining aggregate lexical similarity entities participating block. distribution similarities normalized nextblock consider sampled distribution. Notice Fig. 9 Falcon-AO OLAdemonstrate significant increases convergence time (p 0.01) compared utilizing BCDinitial ordering scheme; hand, overall time reduces Optima ordersmagnitude pairs containing larger ontologies edas iasted.select 6 pairs, exhibit highest lowest differences average execution times showFig. 9. Falcon-AOs precision recall show significant change F-measure remainsunchanged. OLA loses precision recall similarity distribution scheme. precision across pairs went 13% 37% along 24% drop recall 58% leadingdrop F-measure 19%. However, Optimas F-measure remains largely unaffected.Recall Falcon-AO OLA perform iterative updates Optima conductsiterative search. sampled blocks undergo updates iterative update algorithms, searchalgorithms may improve blocks low similarity. Consequently, blocks highsimilarity sampled often repeatedly improved. results quicker convergence823fiT HAYASIVAM & OSHIFalcon-AO BCDFalcon-AO BCD (ordered roots leaves)50OLA BCDOLA BCD (ordered roots leaves)141240Time (sec)Time (sec)10302086410200)(encfe(Cfenc,ianc(c(nCot,(c(a)1000eerfeds)e)d)tef,effe(Cksig,cn)dde,efe(C)),ct,cm)ddksigda)fn,co(c,eceenrfe(C(C(b)d)kdigenrfed)te,ice(cf,s)edst,iada(eOptima BCDOptima BCD (ordered roots leaves)Time (sec)100101)aw,ekfe(CencnfenCod)te,icef(c(d)te,ika(e)ddsid,est(iaddgkgksiw,ka(e))edstiaw,(c)Figure 8: Average execution times of, (a) Falcon-AO, (b) OLA, (c) Optima, BCDuses initial ordering scheme BCD ordering blocks root(s) leaves,6 21 ontology pairs conference domain. ran algorithmspairs, selected ontology pairs exhibited highest lowest differences average execution times. alternate ordering increases run timesconvergence observe significant improvements F-measures.different peculiar local optima blocks high similarity convergedothers predominantly remain unchanged. Thus, alignment quality remains largely unaffectedconvergence time reduced, see context Optima.5.2 Partitioning Alignment VariablesBCD impose particular way grouping variables, well-founded partitioning schemes may yield significant improvements:extension initial scheme (Fig. 10(a)) would group variables representingcorrespondences participating entities O1 O2height relation leaf entity ontology, illustrate Fig. 10(b). Note824fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD20Falcon-AO BCDFalcon-AO BCD (ordered similarity distribution)605015Time (sec)40Time (sec)OLA BCDOLA BCD (ordered similarity distribution)30102051000))fe(CfO(cawksigf,nc)dde,et,(c)ddksigda(ed),iaksig(eenft,C(a)1000nft,c(c(c))ncw,ka(ee))ddteks,e,edencfe((b))fO(cddgkf,snfenCo(Cd)te,iced)te,i(eOptima BCDOptima BCD (ordered similarity distribution)Time (sec)1001010.1(Crfed),ecekdigf,sengk,si(cs)da)dd(cda(e(c))))edsts,ifOawda(eddgkks,esiw,ka(eFigure 9: Average execution time consumed by, (a) Falcon-AO, (b) OLA (c) OptimaBCD utilizing previous ordering scheme BCD ordering blocks similarity distribution, 6 21 ontology pairs conference domain. Althoughran algorithms pairs, show ontology pairs exhibited highest lowest differences average execution times. new ordering helped Optimacut total execution time 262 seconds finding 1 correctcorrespondence 6 false positives across pairs.entity heights may differ two ontologies. based observationgeneralization-specialization hierarchy concepts pertaining subtopic usuallyinvariant across ontologies.sophisticated scheme founded observation temporarily transformontology, modeled labeled graph, tree. may utilize graphsearch technique handles repeated nodes, breadth-first search graphs (Russell& Norvig, 2010), obtain tree. ontology isolated graphs leading separatetrees, use owl:thing node combine single tree. Subsequently, groupvariables participating entities ontology part subtree825fiT HAYASIVAM & OSHImff mfimff mfifffifffimff mffmffff mff mfffimff mffmffff mff mfffiff fiff fimff mfifffimff mffmffff mff mfffiff fiFigure 10: Matrices representing intermediate alignment entities O1 O2 . (a)Identically shaded rows form block variables corresponding entitiesO1 height. (b) Identically shaded rows columns correspondentities heights O1 O2 , respectively. Variables overlapping regionsform block. (c) Entities corresponding identically shaded rows columns formsubtrees. fourth approach randomly select variables inclusion block.predefined size (Fig. 10(c)). may discard ontology trees forming blocks.previous schemes form blocks differing numbers variables, scheme formsone block number variables limiting subtree size.simple point comparison would scheme randomly selects alignment variablesinclusion block. clear way determine many variables includeblock, randomly inserted variables 5 blocks.Based findings previous subsection, blocks ordered based heightparticipating entities subtrees root nodes Falcon-AO OLA. begin blockssmaller height proceed increasing height. Optima, sample blocksusing distribution based lexical similarity participating entities.illustrated Fig. 11, partitioning ontologies helped Optima significantly saves execution times (p 0.01). pairs involving larger ontologies,reduced order magnitude. Furthermore, Optima gains precisionpairs 6% 1% reduction recall resulting 3% gain F-measure 67%. OLA savesexecution time well relatively less Optima slight improvement alignmentquality. hand, Falcon-AO experienced increase total execution timepairs. Optimas improved performance attributed blocks smaller allowingcomprehensive coverage search space less time. hand, iterative updatetechniques Falcon-AO show improvement smaller blocks maysign overpartitioning.Figure 12 illustrates impact subtree-based partitioning three algorithms. Falcon-AOexhibited significant reduction execution times (p < 0.01) simultaneously improvementprecision F-measure pairs 3%. Similar previous optimization, OLAsexecution time reduces significantly well (p < 0.01) keeping output unchanged.826fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD12Falcon-AO BCDFalcon-AO BCD (both ontologies partitioned)50OLA BCDOLA BCD (both ontologies partitioned)1040Time (sec)Time (sec)830206410200e,et,scm(cenrfe(Cd))d)gk,siffO(cw)gk(iasd)dae)gksi,ed)ed,ek,awk(e(e1000kde,scenrfe(Ckdigigt,s(c(a)d)d)dat,e(ct,(cs)ncfenCo(d)d)tes,iedkdsigw,ek((b)Optima BCDOptima BCD (both ontologies partitioned)Time (sec)1001010.1f))(aw,edfen,ek(cfedd)tes,ice(C)fOt,ccm((d)d)teiasw,ekkdig,ste(ia(c)Figure 11: Execution times consumed by, (a) Falcon-AO, (b) OLA, (c) Optima BCDuses blocks obtained partitioning single ontology BCD utilizespartitions ontologies, 6 21 ontology pairs conference domain.Although ran algorithms pairs, selected ontology pairs exhibited highest lowest differences execution times. Optimas total executiontime pairs reduced 274 seconds. False positive correspondences reduced37 expense 3 correct correspondences. OLA cut 10 seconds totalexecution time 2 incorrect correspondences.hand, partitioning technique reduces efficiency Optima small reductionalignment quality well. Falcon-AOs GMO employs approach relies inboundoutbound neighbors, benefited using blocks whose participating entities form subtrees.structure-based matching Optima limited looking correspondencesimmediate children, including larger subtrees blocks may benefit Optima.Finally, Fig. 13 explore impact randomly partitioning variables blocksthree alignment algorithms. Falcon-AO OLA showed significant increases execution time (p < 0.01) conference pairs. Falcon-AOs precision improved less1%, recall dropped 2% overall reduction F-measure 1%. OLA exhibited minor increase precision 0.2% recall remained unchanged resulting increaseF-measure 0.2%. Optima demonstrated mixed results shown Fig. 13(c) execution827fiT HAYASIVAM & OSHI3512Falcon-AO BCDFalcon-AO BCD (subtree based partitioning)30OLA BCDOLA BCD (subtree based partitioning)1025Time (sec)Time (sec)8201564102500f)f)fOfO(ce,icenfe(Cncfe(Cd))awten,con,coda(ed)teks,es,idaF)d)te,ia(ef,et,ck(e(cd)w)kafOawnff(c(c(a))awkd,ekig,sda(e(e)d)edst,iadakdig,s(e(b)1000Optima BCDOptima BCD (subtree based partitioning)Time (sec)100101(cf)d)fOtet,infe(Cnfe(C,iced)te,cce(ed)d)te,ikd(e,awd)teiasig,sk(e(c)Figure 12: Execution times consumed by, (a) Falcon-AO, (b) OLA, (c) Optima, BCDuses default partitioning approach BCD uses subtree-based partitioning, 6 21 ontology pairs conference domain. ran algorithmspairs selected ontology pairs exhibited highest lowestdifferences execution times. total execution time Falcon-AO completeconference track reduces 8 sec along reduction 71 false positives. OLAsaves 1.5 sec total execution time keeping output alignments unchanged.However, Optima consumes 192 seconds more.time increasing pairs reducing others. whole, observe statistically significant difference execution times. Furthermore, BCD due random partitioningimprove beyond seed alignment many pairs, overall decrease F-measure1% across pairs.summary, side-by-side comparison various block ordering partitioning techniquesdiscussed previously presented Fig. 14 three alignment algorithms single ontologypair, (edas, iasted). include random partitioning alignment performance termsrecall precision poor many ontology pairs making illsuited candidate.Differences run time performance algorithms (edas, iasted) representative828fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD4030Falcon-AO BCDFalcon-AO BCD (randomly partitioned)35OLA BCDOLA BCD (randomly partitioned)2520Time (sec)Time (sec)30252015151010550ncfe(C0)nfe,c)e,efe(C)w)nc,ekdag,sida(e(en,co(cwka(e(a)g,sid)w)fOkdkdiass,da(etef)d)d)(ckdig,eknf,s(c(ed)d)te,ikd(e,awd)teiasig,sk(e(b)10Time (sec)Optima BCDOptima BCD (randomly partitioned)10.1f)enrfe(Cda,eceenrfe(Cd)s)fO,ccekdig,sceenrfe(C(c(c))edst,iaffO(e)edst,iada)edst,iawka(eFigure 13: Execution times consumed by, (a) Falcon-AO, (b) OLA, (c) Optima, BCDuses default partitioning approach BCD uses random partitioning.show 6 21 ontology pairs conference domain. ran algorithmspairs selected ontology pairs exhibited highest lowestdifferences execution times. total execution time Falcon-AO completeconference track increases 19.5 secs due random partitioning. OLA takesadditional 28 secs total execution time Optima saves 8.5 secondspairs expense alignment quality.performances larger data set general. particular, Falcon-AOs run time reducesusing subtree-based partitioning obtain blocks. OLAs run time reducesontologies pair partitioned using entity height, Optima benefits orderingblocks based preliminary measure similarity participating entities formingblocks partitioning ontologies.6. Aligning Large Biomedical OntologiesOntologies becoming increasingly critical life sciences (Bodenreider & Stevens, 2006;Lambrix, Tan, Jakoniene, & Stromback, 2007) multiple repositories Bio2RDF (Belleau et al., 2008), OBO Foundry (Smith et al., 2007) NCBOs BioPortal (Musen et al., 2012)829fiT HAYASIVAM & OSHITime (sec)100defaultordered roots leavesordered similarity distributionontologies partitionedsubtree based partitioning101Falcon-AO BCDOLA BCDOptima BCDFigure 14: side-by-side comparison performances three iterative algorithms usingvarious block ordering formation techniques. single moderately large ontologypair, (edas, iasted), aligned. default represents iterative alignment algorithm BCD blocks ordered based height participatingentities leaves root single ontology partitioned form blocks.Differences run times indicative performance general.publishing growing number biomedical ontologies different domains anatomymolecular biology. example, BioPortal hosts 370 ontologies whose domains fallwithin life sciences. ontologies primarily used annotate biomedical dataliterature order facilitate improved information exchange. growth ontology usage,reconciliation overlap scope gains importance.Evaluation general ontology alignment algorithms benefited immensely standardsetting benchmark OAEI (Shvaiko et al., 2012). addition multiple tracks real-world testcases, competition emphasizes benchmark comparison tracks use test pairs modifications single ontology pair order systematically identify strengths weaknessesalignment algorithms. One tracks real-world ontology pairs involves aligningontology adult mouse anatomy human anatomy portion NCI thesaurus (Golbecket al., 2003), another seeks align foundational model anatomy (FMA), SNOMED CTnational cancer institute thesaurus (NCI). However, aligning biomedical ontologies posesunique challenges. particular,1. Entity names often identification numbers instead descriptive names. Hence, alignment algorithm must rely labels descriptions associated entities,expressed differently using different formats.2. Although annotations using entities ontologies gene ontology (Ashburneret al., 2000) growing rapidly, ontologies continue remain sparse. Consequently, may overly rely entity instances aligning biomedical ontologies.3. Finally, biomedical ontologies tend large many including thousand entities.motivates alignment approaches depend less brute-force steps, compelsassigning high importance issues related efficiency scalability.Given specific challenges, combed 370 ontologies hosted NCBO(Musen et al., 2012) OBO Foundry (Smith et al., 2007), isolated community benchmark830fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD50 different biomedical ontology pairs. Thirty-two ontologies sizes ranging hundredtens thousands entities constitute pairs. provide list ontologies participatingbenchmark ontology pairs Appendix B. new benchmark guides comparativeevaluation alignment algorithms context key application domain biomedicine.primary criteria including pair benchmark expectation sufficientamount correspondences ontologies pair, determined NCBOs BioPortal. particular, calculated ratio correspondences posted BioPortalontology pair largest number possible correspondences could exist. selected50 pairs largest ratio. Existing correspondences serve reference alignment.include maps UMLS Metathesaurus crowd sourced. Nevertheless, analysis reveals existing correspondences constitute small fractiontotal alignment possible two ontologies.sought align pairs new biomedical ontology alignment testbed using BCDenhanced representative algorithms. obtained alignments evaluated using existing correspondences previously present BioPortal; reference alignments pairs likelyincomplete. secondary objective discover new correspondences ontologiessubmit NCBOs BioPortal curation.Informed experimentation described Section 5, blocks BCD Falcon-AOformed using subtree-based partitioning one ontology ordered created. BlocksOLA formed similarly though ontologies partitioned blocks Optimaformed partitioning ontologies basis height entities orderedleaves root. execution times F-measure pairs successfully aligned withinarbitrary window 5 hours per pair BCD-enhanced algorithms shown Figs. 1516. point BCD speeds algorithms explicitly promote scalability.words, reduces time convergence provide way managememory order align large ontologies.OLA BCD failed align single pair within time window. Falcon-AO enhancedBCD without aligned 47 pairs within time window. Falcon-AO unable parseone ontologies remaining 3 pairs due results available these.Falcon-AO BCD aligned pairs taking 3.7 hours less time total originalconsumed 7.5 hours pairs. show time pair Fig. 15(a). closerlook reveals Falcon-AO BCD exhibited time greater default 9 47 pairs.Time pairs exceed 16 seconds due performingsubtree-based partitioning variables forming blocks BCD. corresponding Fmeasure change significantly due use BCD pairs F-measurepairs 54.7%.Optima enhanced BCD aligned 42 pairs within time window compared 30 pairswithout BCD. Optima unable parse one ontologies remaining 8 pairs dueresults available these. Focusing 30 pairs aligned withintime window (Fig. 16), Optima BCD aligned pairs 2.3 hours taking 11.4 hoursless time compared original algorithm. Simultaneously, found additional 269 correctcorrespondences across pairs increase F-measure 2%.LogMap, fast non-iterative algorithm targets biomedical ontologies returned alignments50 pairs 20 minutes total time. produced precision recall 23.5% 39.5%(F-measure = 29.5%), respectively pairs. significantly less831fiT HAYASIVAM & OSHI10000Falcon-AOFalcon-AO BCDTime (sec)1000100101)N))N)N) )L) )N) ))A) GAN) )))) AA A))T) A) A) O) RO A)I) DA EL DA)))BI DA P )))DA ER)A) ))RO)A) ))RO DAGA)RO)DA O) ,OB EH IFC ,EH V) HD FA AO AO V) HD FA AO EH O) HO HD HD B-B HD GM AR N, HD ,MA ,EV ,EH ,UB E) V) ,BT ,EV ,PO ,PO VM ,EH O-C DS EV HDEH ,TA SP S,,N O,E O,E O,Z O,X O,T O,U ,E ,E ,Z,T,U O, ,BT ,V A,E A,E O,F O,E O,T O,C O,U ERO ,E GGGG ,PA ,E ,U BT BT CV CV O,E D,C RO ,GR ,PS A, A,E,PFFILILBEHHHHHFA FA BBBBB(Z (Z (F (T (S (B (A (A (A (A (A (A (X (X (X (X (X (P (P (T (B (B (H (H (H (H (H (U (A (V (V (V (V (P (B (B (F (F (F (F (M (M (C (P (P (E (MOntology pair(a)1Falcon-AOFalcon-AO BCDF-measure0.80.60.40.20)N)) ))N)L) )N) ))A) GAN) )))) AA A) T) A) A) O) RON ) ))I) DA EL DA))BI DA P )))DA ERA) ))RO)A) ))RO DAGA)RO ))DA O) ,OB EH IFC EH V) HD FA AO AO V) HD FA AO EH O) HO HD HD B-B HD GM AR N, HD EV EH UB E) V) BT EV ,PO ,PO VM EH O-C DS EV HDEH ,TA SP S, ,N O, ,E ,E ,Z ,X ,T ,U ,E ,E ,Z ,T ,U O, ,BT ,V A,E A,E ,F ,E ,T ,C ,U RO ,E G, G, G, G, ,PA ,E ,U BT, BT, CV CV ,E D,C O, ,GR ,PS A, ,E,FA B- AD AO SP AO AO AO AO AO AO AO AO AO AO AO AO IL IL AO AO AO AO AO EO HO HO HO HO B- B- B- B- FO AR HD FAF(Z (Z (F (T (S (B (A (A (A (A (A (A (X (X (X (X (X (P (P (T (B (B (H (H (H (H (H (U (A (V (V (V (V (P (B (B (F (F (F (F (M (M (C (P (P (E (MOntology pair(b)Figure 15: (a) Time consumed, (b) F-measure attained original Falcon-AOoptimized BCD 47 pairs large biomedical ontology testbed, respectively.Note time axis log scale. Ontology names NCBO abbreviations.alignment performed Red Hat machine Intel Xeon Core 2, processor speed3 GHz 8GB memory.Falcon-AO, exhibited precision recall 80.9% 41.3% respectively, pairsaligned. Optima BCD exhibited precision 76.1% recall 35.8% overallF-measure 48.7%. recall less LogMap, F-measure significantly betterdue improved precision.Finally, submitted 15 new correspondences entities pairs testbedNCBO curation publication. nontrivial correspondences identified algorithms, present reference alignments appropriately validated us.832fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD100000OptimaOptima BCDTime (sec)10000100010010N)N)N) A)L)N) )N) ))))A))))I))A)RO)I)EL DA))))A) ))ROA) ))RO DAG DA DA -BT DA) RO ERO ,M DA) A) V)RO V)DAEBPOHD UBE )DA O) ,OB EH IFC ,EH V)N HHBHD FA AO AO V)HVM HHD FA AO EH O)EBG,BHO HV),P,,E,M,E,E,EH ,TA SPS, O,N PO O,E O,E O,Z O,X O,T O,U O,E O,E O,Z O,T O,U TO, ,BT O,V A,E A,E O,F O,E O,T O,C O,U ER O,E OG OG OG OG ,PA O,E O,U -BT -BT -CV -CV O,E D,C,FA ZFA FB TA SA BS AA AA AA AA AA AA XA XA XA XA XA PA PO TA BIL BIL HA HA HA HA HA UB AE VH VH VH VH PO BT BT FB FB FB FB MF MO(Z(((((((((((((((((((((((((((((((((((((((((Ontology pair(a)OptimaOptima BCD1F-measure0.80.60.40.20N)) ))N))L) )N) )N) )))) AA A) T) A) A) O) RON ) ))I) DA EL DA))BI))DA ERA) )RO))A) )RO DA)GRO )DA O) ,OB EH IFC ,EH V) HD FA AO AO V) HD FA AO EH O) HO HD HD B-B HD GM AR N, HD ,MA ,EV ,EH ,UB E) V) ,BT ,EV ,PO ,PO VMH,,EEEEZXUFECUNEEZUEV,E A,T -SP DS O, PO O, O, O, O, O, O, O, O, O, O, O, ,B O, A, A, O, O, O, O, O, ER O, OG OG OG OG ,P O,E O,U -BT -BT -CV -CV O,E D,CLLFB E H H H HB B B BFFB(Z (Z (F (T (S (B (A (A (A (A (A (A (X (X (X (X (X (P (P (T (B (B (H (H (H (H (H (U (A (V (V (V (V (P (B (B (F (F (F (F (M (MOntology pair(b)Figure 16: (a) Time consumed, (b) F-measure attained original Optimaoptimized BCD, 42 pairs biomedical ontology testbed, respectively. Notetime axis log scale.7. DiscussionPerformances iterative update search techniques impacted differently various waysformulating blocks order processing them. Importantly, quality alignmentmay adversely impacted. Nevertheless, approach grouping alignment variables blocksbased height participating entities ontologies motivated recognizedheuristic leads competitive performance observed negative impact precisionrecall alignments. However, different ontology pairs may lead differing numberblocks various sizes: particular, tall ontologies exhibit deep class hierarchy resultblocks short ontologies.833fiT HAYASIVAM & OSHIGiven BCD-based enhancement optimization, well algorithms compareterms execution time alignment quality state art? order answerquestion, compare performances 18 algorithms participated conferencetrack OAEI 2012 (Shvaiko et al., 2012). Among these, iterative alignment algorithm, YAM++,produced best F-measure 21 pairs followed LogMap utilize optimization CODI, Optima+, Optima augmented BCD. latter approachesproduced F-measures tied within 2% other. Optima+ ranked secondYAM++ alignment evaluated using F2 measure due comparatively high recall.OAEI reports run time larger task aligning 120 conference ontology pairs. task,YAM++ consumed 5 hours pairs, LogMap took slightly less 4minutes Optima+ consumed 22 minutes. Falcon-AO OLA participateOAEI 2012, ran separately 120 pairs machines, whose configurationscomparable utilized OAEI. Falcon-AO OLA enhanced BCD consumed 115 minutes respectively although alignment quality lower Optima+. wouldplace three representative algorithms top two-thirds among 18 participatedconference track OAEI terms run time OLA top half, Optima+ OLAgroup 1 respect alignment quality. 6 7 competing algorithms completed evaluationfaster, 5 exhibit alignment quality substantially worse representativealgorithms. absence BCD, representative algorithms would ranked amongbottom third exceeded 5 hour cut off. Performance anatomy pair due BCD wouldplace Falcon-AO Optima+ top half 14 algorithms participated termsrun time F-measure. Previously, Optima without BCD ranked bottom quarter.reductions convergence time observed increases precision alignmentdue BCD is, part, optimized correspondences found previous coordinate block, influence selection correspondences current coordinate block.Furthermore, mentioned previously, limiting randomly generated correspondencesMapPSO block instead whole ontology makes search guided. representative effect BCD iterative search general. Focusing single blocksignificantly reduces space alignments iterative techniques must search therebyarriving optimum quicker. However, greater number smaller optimization subproblems must solved results imply smaller optimization problem offsets expense.Given integrating BCD iterative algorithms converged different values Qfunction iterative search different match matrices, , iterative update,often produced better quality alignments, infer original algorithms converginglocal optima instead global optima, using BCD likely resulted convergence(better) local optima well. insight new (Euzenat et al., 2004), significantreinforces presence local optima alignment space algorithms.may limit efficacy iterative alignment techniques.Falcon-AO Optima+s comparatively better performance measured using F-measurefast, non-iterative algorithm, LogMap, biomedical ontology alignment testbed indicatesiterative techniques continue among best quality obtained alignment including large ontology pairs. motivates ways making efficient, BCD,scalable.6. Note MapPSO BCD would placed bottom third.834fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCD8. Conclusion Future Worktechniques scaling automated alignment large ontologies previously proposed, presented novel approach based BCD speed alignment processimportant class algorithms. algorithms iterative anytime demonstrating high quality alignments often consuming time non-iterative algorithms. demonstratedtechnique context four different iterative algorithms evaluated impacttotal time execution final alignments precision recall. reported significantreductions total execution times algorithms enhanced using BCD. reductionsnoticeable larger ontology pairs. Often algorithms converged lesser numberiterations. Simultaneously, utilizing default scheme grouping alignment variablesparticipating entities one ontology block height optimizing blocks order increasing height, observe improvement precisionalignments generated algorithms significant change recall.possible improve run time performance default partitioningordering scheme utilizing schemes, note may negatively impactalignment quality. Subsequently, default scheme generally recommended existing newiterative alignment techniques seek utilize BCD.ability improve quickly allows iterative alignment algorithm run convergencepossible, contrast common practice terminating alignment process arbitrarynumber iterations. predefining common bound number iterations difficult,speeding convergence becomes vital. observe BCD promote scalabilitylarge ontologies.Finally, demonstrated benefits BCD toward aligning pairs new biomedical ontology testbed. Due large number ontologies biomedicine, critical needontology alignment vast domain. future work continue focus methodswould allow general principled alignment approaches Falcon-AO Optima perform better testbed producing better quality alignment pairs less time,aligning large biomedical ontologies popular use SNOMED-CT NCI.Consequently, believe community benchmark could potentially drive future researchtoward pragmatic ontology alignment.9. Acknowledgmentresearch supported part grant number R01HL087795 National Heart, Lung,Blood Institute. content solely responsibility authors necessarilyrepresent official views National Heart, Lung, Blood Institute National Institutes Health. authors thank Todd Minning Rick Tarleton Center TropicalEmerging Diseases University Georgia Amit Sheth Wright State Universityuseful discussions. authors also thank anonymous reviewers feedback benefitedarticle greatly.835fiT HAYASIVAM & OSHIAppendix A. Representative Iterative Algorithms Enhanced BCDchose four representative iterative alignment algorithms, Falcon-AO, MapPSO, OLA Optima order illustrate iterative algorithms could enhanced BCD. section,present alignment algorithm original form enhanced BCD, facilitate directcomparison quick identification needed modifications.FALCON -AO/GMO-BCD (O1 , O2 , )FALCON -AO/GMO (O1 , O2 , )Initialize:1. Iteration counter 02. G1 AdjacencyMatrix (O1 )3. G2 AdjacencyMatrix (O2 )4. 05.16. 0Iterate:7.8.ii+19.G1 i1 GT2 + GT1 i1 G210. CosineSim(M , )11.12.13. Extract alignmentInitialize:1. Iteration counter 02. G1 AdjacencyMatrix (O1 )3. G2 AdjacencyMatrix (O2 )4. 05.16. Create partition :{MS0 , MS1 , . . . , MSC }7. 0Iterate:8.9.c % (C + 1), + 110. MSi c G1,Sc i1 GT2 + GT1,Sc i1 G211. MSi MSi1 Sc12. c = C13.CosineSim(M , )else14.high value15.16.17. Extract alignmentFigure 17: (a) Iterative update structural matcher, GMO, Falcon-AO. (b) Iterative updateGMO modified perform BCD.Fig. 17, show iterative algorithm GMO component Falcon-AOenhancement due use BCD. AdjacencyMatrix (O1 ) (line 2 Fig. 17(a)) produces binarymatrix, G1 , size |V1 | |V1 |, value 1 ith row j th column representsedge vertex indexed vertex indexed j bipartite graph model O1 ;analogously AdjacencyMatrix (O2 ). update distance functions implementedshown lines 9 10, respectively, algorithm. particular, cosine similarity computescosine two matrices consecutive iterations serialized vectors. Noticeiteration Fig. 17(b), block variables, MSi c , updated using Eq. 10 holdingremaining blocks fixed (lines 10 11). yields partially updated complete alignmentmatrix reduced time, utilized next iteration.MapPSOs iterative search algorithm performs particle swarm optimization modification due BCD shown Fig. 18. algorithm takes input number particles, K,836fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDAP PSO-BCD (O1 , O2 , K, )Initialize:1. Iteration counter 02. Generate seed mapO1 O23. Populate binary matrix, 0 ,seed correspondences4. Generate K particles using0seed 0 : P = {M10 , M20 , . . . , MK}5. Create partition :{MS0 , MS1 , . . . , MSC }6. Search M0 arg max Q(Mk0 )AP PSO (O1 , O2 , K, )Initialize:1. Iteration counter 02. Generate seed map O1 O23. Populate binary matrix, 0 ,seed correspondences4. Generate K particles using0seed 0 : P = {M10 , M20 , . . . , MK}005. Search arg max Q(Mk )Mk0 PMk0 PIterate:7.8.c % (C + 1), + 19.k 1, 2, . . . , K, Mi1 )U pdateBlock(Mk,S10.Mk,Scci111.Mk,Mk,S Sc12. Search Mi arg max QS (Mki )Iterate:6.7.ii+18.k 1, 2, . . . , K9.Mki U pdateP article(Mki , Mi1 )10. Search Mi arg max Q(Mki )Mki PMki P11. |Q(Mi ) Q(Mi1 )|12. Extract alignment Mic = Cchanged |Q(Mi ) Q(Mi1 )| ?else15.changed true16. changed17. Extract alignment Mi13.14.(a)(b)Figure 18: (a) Iterative search MapPSO. Objective function, Q, given Eq. 4. (b)MapPSOs particle swarm based iterative algorithm enhanced BCD.threshold, , addition two ontologies aligned. iteratively searchesalignment unable find one improves previous best alignmentequal . objective function, Q, modified QS Fig. 18(b), calculatedcoordinate block interest. coordinate block particle, k, updated keepingremaining blocks unchanged (lines 10 11), followed searching best particle basedmeasure alignment block (line 12). steps may performed reducedtime. Additionally, randomly generated mappings MapPSO limited block insteadwhole ontology, due search becomes guided.OLAs iterative algorithm shown Fig. 19 (a), enhancement due use BCDFig. 19(b). distance function line 11 measures similarity updated alignmentmatrix previous iteration. iterations terminate distance fallsparameter, . Observe cycle blocks BCD enhanced algorithmFig. 19 (b) coordinates belonging current block, MSi c , updated lines 8-11.837fiT HAYASIVAM & OSHIOLA-BCD (O1 , O2 , )OLA (O1 , O2 , )Initialize:1. Iteration counter 02. Fill real-valued matrix, 0 , lexical similarity3. 0Iterate:4.5. + 16.7. types xPwFSetSim(F(xa ), F(y ))8.F N (xa ,y )9.10.11.12.13.14.else0Dist(M , )Extract alignmentInitialize:1. Iteration counter 02. Populate real-valued matrix 0lexical similarity values3. Create partition :{MS0 , MS1 , . . . , MSC }4. 0Iterate:5.6. c % (C + 1), + 17. MSi c8. types xaPwFSetSim(F(a), F())9.F N (a,)10. else11. 012. MSi = MSi1 Sc13. c = C14.Dist(M , )else15.high value16.17.18. Extract alignment(a)(b)Figure 19: (a) OLA iteratively updates alignment matrix using combination neighboringsimilarity values. (b) OLAs BCD-integrated iterative ontology alignment algorithm.Finally, Fig. 20, outline iterative search undertaken Optima modificationdue BCD. Optimas expectation-maximization based iterative search uses binary matrix, ,represent alignment. Objective function, Q, defined Eq. 6. search improvedalignment line 8 implemented using two steps expectation maximization. Iterationsterminate sample M, improves objective function, Q further, available.search modified Fig. 20 (b) explore reduced search space, MSc , cycleblocks. objective function, QS , prior operate single coordinate block.Appendix B. Biomedical Ontology Alignment BenchmarkBiomedical ontologies bring unique challenges ontology alignment problem. Moreover,explicit interest ontologies ontology alignment domain biomedicine. Consequently, present new biomedical ontology alignment testbed, provides importantapplication context alignment research community. Due large sizes biomedical838fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDPTIMA -BCD (O1 , O2 )Initialize:1. Iteration counter 02. {1, 2, . . . , |V2 |}3.0 |V12 |4. Generate seed mapO1 O25. Populate binary matrix, M0 ,seed correspondences6. Create partition :{MS0 , MS1 , . . . , MSC }PTIMA (O1 , O2 )Initialize:1. Iteration counter 02. {1, 2, . . . , |V2 |}3.0 |V12 |4. Generate seed mapO1 O25. Populate binary matrix, M0 ,seed correspondencesIterate:7.8.c % (C + 1), + 19.Search MSi c , arg max QS (MSi c |Mi1 )Iterate:6.7.ii+18.Search Mi arg max Q(M |Mi1 )P|V1M|P r(y |xa , Mi1 )9.|V11 | a=110. Mi 6= Mi111. Extract alignment Mi10.11.12.13.MSc MSci1MS, MS, ScP|V1,c |1i1),c|V1,ca=1 P r(y |xa ,|c = Cchanged Mi 6= Mi1 ?else14.changed true15. changed16. Extract alignment Mi(a)(b)Figure 20: (a) Optimas expectation-maximization based iterative search algorithm.(b)Expectation-maximization based iterative ontology alignment Optima BCD.ontologies, testbed could serve comprehensive large ontology benchmark. Existing correspondences NCBO may serve reference alignments pairs, although analysisreveals maps represent small fraction total alignment possibletwo ontologies. Consequently, new correspondences discovered benchmarking maysubmitted NCBO curation publication.order create testbed, combed 370 ontologies hosted NCBOOBO Foundry, isolated benchmark 50 different biomedical ontology pairs. Thirty-twoontologies sizes ranging hundred tens thousands entities constitutepairs, listed Table 2. provide snapshot full benchmark Table 3. testbedreference alignments available download http://tinyurl.com/n4t2ns3.primary criteria including pair benchmark presence sufficient amountcorrespondences ontologies pair, determined NCBOs BioPortal.briefly describe steps creating testbed:1. selected ontologies, exist either OWL RDF models.839fiT HAYASIVAM & OSHI2. paired ontologies ordered pairs percentage available correspondences. ratio correspondences exist BioPortal pair ontologiesconsideration divided product number entities ontologies.3. Top 100 ontology pairs based ratio selected, followed ordering pairsbased joint sizes.4. created 5 bins equal sizes randomly sampled bin uniform distributionobtain final 50 pairs.NamedDataClassesProperties1140Bilateria anatomy (BILA)500Common Anatomy Reference Ontology (CARO)2822Plant Growth Development Stage (PO PSDA)8210FlyBase Controlled Vocabulary (FBcv)1290Spatial Ontology (BSPO)16030Amphibian gross anatomy (AAO)2380Anatomical Entity Ontology (AEO)12707Cereal plant gross anatomy (GR CPGA)1,2706Plant Anatomy (PO PAE)8210Subcellular Anatomy Ontology (SAO)1,0410Xenopus anatomy development (XAO)1,1840vertebrate Homologous Organ Groups (sHOG)1,9304Hymenoptera Anatomy Ontology (HAO)3,0390Teleost Anatomy Ontology (TAO)6280Tick gross anatomy (TADS)2,7885Zebrafish anatomy development (ZFA)4,3580Medaka fish anatomy development (MFO)5,1394BRENDA tissue / enzyme source (BTO)22740Expressed Sequence Annotation Humans (eVOC)7,7970Drosophila gross anatomy (FBbt)2,28124Phenotypic quality (PATO)7,294112Uber anatomy ontology (UBERON)6,5990Fly taxonomy (FBsp)1,3384Protein modification (MOD)2,3140Human developmental anatomy (EHDAA)8,3400Human developmental anatomy timed version (EHDA)1,5857Plant Ontology (PO)2,70373NIF Cell (NIF Cell)2,9821Mouse adult gross anatomy (MA)1,8643Mosquito gross anatomy (TGMA)3,537102Ontology Biomedical Investigations (OBI)31,4709Chemical entities biological interest (CHEBI)Table 2: Selected ontologies NCBO biomedical ontologyalignment testbed number named classes propertieseach. Notice data set includes large ontologies. NCBO abbreviations ontologies also provided.Ontology840ObjectProperties990109960085107490069710000077056060fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDBiomedical ontology alignment testbedOntology O1Ontology O2|V1 | |V2 |Common Anatomy Reference OntologyHuman developmental anatomy (EHDAA)115,700(CARO)Bilateria anatomy (BILA)Human developmental anatomy (EHDAA)263,796Bilateria anatomy (BILA)Human developmental anatomy (EHDAA)263,796Spatial Ontology (BSPO)Human developmental anatomy (EHDAA)298,506Plant Growth Development StagePlant Ontology (PO)446,970(PO PSDA)Anatomical Entity Ontology (AEO)Human developmental anatomy (EHDAA)550,732FlyBase Controlled Vocabulary (FBcv)Cereal plant gross anatomy (GR CPGA)1,042,670FlyBase Controlled Vocabulary (FBcv)Plant Ontology (PO)1,301,285Tick gross anatomy (TADS)Human developmental anatomy (EHDAA)1,453,192Amphibian gross anatomy (AAO)Xenopus anatomy development (XAO)1,668,723Cereal plant gross anatomy (GR CPGA)Plant Ontology (PO)2,012,950Plant Anatomy (PO PAE)Plant Ontology (PO)2,012,950Subcellular Anatomy Ontology (SAO)NIF Cell (NIF Cell)2,219,163Expressed Sequence Annotation HumansXenopus anatomy development (XAO)2,367,234(eVOC)Xenopus anatomy development (XAO)Human developmental anatomy (EHDAA)2,408,874vertebrate Homologous Organ Groups Expressed Sequence Annotation Humans2,692,416(sHOG)(eVOC)vertebrate Homologous Organ GroupsHuman developmental anatomy (EHDAA)2,739,776(sHOG)Xenopus anatomy development (XAO)Zebrafish anatomy development (ZFA)2,902,308Xenopus anatomy development (XAO)Teleost Anatomy Ontology (TAO)3,163,599vertebrate Homologous Organ GroupsMouse adult gross anatomy (MA)3,530,688(sHOG)Hymenoptera Anatomy Ontology (HAO)Mosquito gross anatomy (TGMA)3,597,520vertebrate Homologous Organ GroupsTeleost Anatomy Ontology (TAO)3,598,176(sHOG)Expressed Sequence Annotation HumansAmphibian gross anatomy (AAO)3,645,222(eVOC)Amphibian gross anatomy (AAO)Human developmental anatomy (EHDAA)3,709,342Hymenoptera Anatomy Ontology (HAO)Human developmental anatomy (EHDAA)4,466,020Amphibian gross anatomy (AAO)Zebrafish anatomy development (ZFA)4,469,164Amphibian gross anatomy (AAO)Teleost Anatomy Ontology (TAO)4,871,517Expressed Sequence Annotation HumansHuman developmental anatomy (EHDAA)5,262,036(eVOC)Phenotypic quality (PATO)Human developmental anatomy (EHDAA)5,278,234Zebrafish anatomy development (ZFA)Human developmental anatomy (EHDAA)6,451,432Plant Anatomy (PO PAE)BRENDA tissue / enzyme source (BTO)6,526,530Teleost Anatomy Ontology (TAO)Human developmental anatomy (EHDAA)7,032,246Xenopus anatomy development (XAO)Uber anatomy ontology (UBERON)7,593,054Zebrafish anatomy development (ZFA)Teleost Anatomy Ontology (TAO)8,472,732Continued next page841fiT HAYASIVAM & OSHIOntology 1vertebrate Homologous Organ Groups(sHOG)Medaka fish anatomy development(MFO)Medaka fish anatomy development(MFO)BRENDA tissue / enzyme source (BTO)Amphibian gross anatomy (AAO)BRENDA tissue / enzyme source (BTO)Hymenoptera Anatomy Ontology (HAO)Hymenoptera Anatomy Ontology (HAO)Expressed Sequence Annotation Humans(eVOC)Ontology 2|V1 | |V2 |Uber anatomy ontology (UBERON)8,636,096Expressed Sequence Annotation Humans(eVOC)9,910,092Human developmental anatomy (EHDAA)Expressed Sequence Annotation Humans(eVOC)Uber anatomy ontology (UBERON)Human developmental anatomy (EHDAA)Uber anatomy ontology (UBERON)Drosophila gross anatomy (FBbt)Uber anatomy ontology (UBERON)Expressed Sequence Annotation Humans(eVOC)Zebrafish anatomy development (ZFA)Uber anatomy ontology (UBERON)Uber anatomy ontology (UBERON)Mouse adult gross anatomy (MA)Ontology Biomedical InvestigationsFly taxonomy (FBsp)(OBI)BRENDA tissue / enzyme source (BTO)Uber anatomy ontology (UBERON)Drosophila gross anatomy (FBbt)BRENDA tissue / enzyme source (BTO)Chemical entities biological interestProtein modification (MOD)(CHEBI)Table 3: biomedical ontology pairs testbed sorted terms|V1 | |V2 |. metric illustrative complexity aligningpair.Drosophila gross anatomy (FBbt)10,084,41211,686,08611,692,28211,891,64614,077,42015,048,21016,586,55617,730,37820,335,67221,750,70823,340,66337,483,86640,068,78342,106,860ReferencesArimoto, S. (1972). algorithm computing capacity arbitrary discrete memorylesschannels. IEEE Transactions Information Theory, 18(1), 1420.Ashburner, M., Ball, C. A., Blake, J. A., Botstein, D., Butler, H., Cherry, J. M., Davis, A. P., Dolinski, K., Dwight, S. S., Eppig, J. T., Harris, M. A., Hill, D. P., Issel-Tarver, L., Kasarskis,A., Lewis, S., Matese, J. C., Richardson, J. E., Ringwald, M., Rubin, G. M., & Sherlock, G.(2000). Gene ontology: tool unification biology. gene ontology consortium..Nature genetics, 25(1), 2529.Baader, F., Horrocks, I., & Sattler, U. (2003). Description logics ontology languagessemantic web. Lecture Notes Artificial Intelligence, pp. 228248. Springer-Verlag.Belleau, F., Nolin, M.-A., Tourigny, N., Rigault, P., & Morissette, J. (2008). (bio2rdf): Towardsmashup build bioinformatics knowledge systems. Journal Biomedical Informatics,41(5), 706716.842fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDBlahut, R. E. (1972). Computation channel capacity rate-distortion functions. IEEE Transactions Information Theory, 18, 460473.Bock, J., & Hettenhausen, J. (2010). Discrete particle swarm optimisation ontology alignment.Information Sciences, 192, 122.Bodenreider, O., & Stevens, R. (2006). Bio-ontologies: current trends future directions. BriefBioinform, 7, 256274.Cruz, I. F., Stroe, C., & Palmonari, M. (2012). Interactive user feedback ontology matchingusing signature vectors. IEEE 28th International Conference Data Engineering, pp.13211324. IEEE Computer Society.Doan, A., Madhavan, J., Domingos, P., & Halevy, A. (2003). Ontology matching: machine learning approach. Handbook Ontologies Information Systems, pp. 397416. Springer.Doshi, P., Kolli, R., & Thomas, C. (2009). Inexact matching ontology graphs using expectationmaximization. Web Semantics: Science, Services Agents World Wide Web, 7(2),90106.Euzenat, J., Loup, D., Touzani, M., & Valtchev, P. (2004). Ontology alignment OLA.Proceedings 3rd EON Workshop, 3rd International Semantic Web Conference, pp.5968. CEUR-WS.Euzenat, J., & Valtchev, P. (2004). Similarity-based ontology alignment OWL-lite. EuropeanConference Artificial Intelligence (ECAI), pp. 333337.Euzenat, J., & Shvaiko, P. (2007). Ontology Matching. Springer.Fessler, J. A., & Hero, A. O. (1994). Space-alternating generalized expectation-maximization algorithm. IEEE Transactions Signal Processing, 42, 26642677.Fessler, J. A., & Kim, D. (2011). Axial block coordinate descent (abcd) algorithm X-ray CTimage reconstruction. Proceedings Fully 3D Image Reconstruction RadiologyNuclear Medicine, pp. 262265.Golbeck, J., Fragoso, G., Hartel, F., Hendler, J., Oberthaler, J., & Parsia, B. (2003). nationalcancer institutes thesaurus ontology. Journal web semantics, 1(1), 7580.Hanif, M. S., & Aono, M. (2009). Anchor-flood: results OAEI 2009. ProceedingsWorkshop Ontology Matching 8th International Semantic Web Conference, pp. 127134.Hayes, J., & Gutierrez, C. (2004). Bipartite graphs intermediate model RDF. Proceedings 3rd International Semantic Web Conference (ISWC), Lecture Notes ComputerScience, pp. 4761. Springer Berlin / Heidelberg.Hero, A. O., & Fessler, J. A. (1993). Asymptotic convergence properties (em)-type algorithms.Tech. rep., Department EECS, Univ. Michigan, Ann Arbor, MI.Hu, W., Jian, N., Qu, Y., & Wang, Y. (2005). GMO: graph matching ontologies. K-CapWorkshop Integrating Ontologies, pp. 4350.Hu, W., Zhao, Y., & Qu, Y. (2006). Partition-based block matching large class hierarchies.Proceedings 1st Asian Semantic Web Conference (ASWC), pp. 7283.843fiT HAYASIVAM & OSHIHughes, T. C., & Ashpole, B. C. (2004). semantics ontology alignment. InformationInterpretation Integration Conference (I3CON).Jean-Mary, Y. R., Shironoshita, E. P., & Kabuka, M. R. (2009). Ontology matching semanticverification. Web Semantics: Science, Services Agents World Wide Web, 7(3),235251.Jian, N., Hu, W., Cheng, G., & Qu, Y. (2005). Falcon-AO: Aligning ontologies Falcon.K-Cap Workshop Integrating Ontologies, pp. 8793.Jimenez-Ruiz, E., & Grau, B. C. (2011). LogMap: Logic-based scalable ontology matching.International Semantic Web Conference, pp. 273288.Kirsten, T., Gross, A., Hartung, M., & Rahm, E. (2011). GOMMA: component-based infrastructure managing analyzing life science ontologies evolution. JournalBiomedical Semantics, 2, 6.Lambrix, P., Tan, H., Jakoniene, V., & Stromback, L. (2007). Biological ontologies In: SemanticWeb: Revolutionizing Knowledge Discovery Life Sciences, pp. 8599. Springer.Li, Y., Li, J., & Tang, J. (2007).RiMOM: Ontology alignment strategy selection. Proceedings 6th International 2nd Asian Semantic Web Conference(ISWC2007+ASWC2007), pp. 5152.McGuinness, D., & Harmelen, F. (2004). Owl web ontology language overview. Tech. rep., W3C.Melnik, S., Garcia-molina, H., & Rahm, E. (2002). Similarity flooding: versatile graph matchingalgorithm. ICDE: Int. Conference Data Engineering, pp. 117128.Musen, M. A., Noy, N. F., Shah, N. H., Whetzel, P. L., Chute, C. G., Storey, M.-A. D., & Smith, B.(2012). national center biomedical ontology. JAMIA, 19(2), 190195.Nesterov, Y. (2012). Efficiency coordinate descent methods huge-scale optimization problems.SIAM Journal Optimization, 22(2), 341362.Ngo, D., & Bellahsene, Z. (2012). YAM++ : multi-strategy based approach ontology matchingtask. International Conference Knowledge Engineering Knowledge Management,pp. 421425.Pinter, J. D. (2000). Yair censor stavros a. zenios, parallel optimization theory, algorithms,applications. Journal Global Optimization, 16, 107108.Rahm, E. (2011). Towards large-scale schema ontology matching. Bellahsene, Z., Bonifati,A., & Rahm, E. (Eds.), Schema Matching Mapping, pp. 327. Springer.Russell, S. J., & Norvig, P. (2010). Artificial Intelligence - Modern Approach (3rd edition).Pearson Education.Saha, A., & Tewari, A. (2013). non-asymptotic convergence cyclic coordinate descentmethods. SIAM Journal Optimization, 23(1), 576601.Seddiqui, M. H., & Aono, M. (2009). efficient scalable algorithm segmented alignmentontologies arbitrary size. Web Semantics: Science, Services Agents WorldWide Web, 7, 344356.Shvaiko, P., & Euzenat, J. (2013). Ontology matching: State art future challenges. IEEETransactions Knowledge Data Engineering, 25(1), 158176.844fiS PEEDING U P TERATIVE NTOLOGY LIGNMENT USING BCDShvaiko, P., Euzenat, J., Heath, T., Quix, C., Mao, M., & Cruz, I. F. (Eds.). (2011). Proceedings6th International Workshop Ontology Matching, Vol. 814 CEUR Workshop Proceedings. CEUR-WS.org.Shvaiko, P., Euzenat, J., Kementsietsidis, A., Mao, M., Noy, N., & Stuckenschmidt, H. (Eds.).(2012). Results Ontology Alignment Evaluation Initiative (OAEI) 2012, Vol. 946CEUR Workshop Proceedings. CEUR-WS.org.Shvaiko, P., Euzenat, J., Srinivas, K., Mao, M., & Jimenez-Ruiz, E. (Eds.). (2013). PreliminaryResults Ontology Alignment Evaluation Initiative (OAEI) 2013, Vol. 1111 CEURWorkshop Proceedings. CEUR-WS.org.Smith, B., Ashburner, M., Rosse, C., Bard, J., Bug, W., Ceusters, W., Goldberg, L. J., Eilbeck,K., Ireland, A., Mungall, C. J., Leontis, N., Rocca-Serra, P., Ruttenberg, A., Sansone, S.-A.,Scheuermann, R. H., Shah, N., Whetzel, P. L., & Lewis, S. (2007). OBO foundry: coordinated evolution ontologies support biomedical data integration. Nature Biotechnology,25(11), 12511255.Stoutenburg, S. K., Kalita, J., Ewing, K., & Hines, L. M. (2010). Scaling alignment large ontologies. International Journal Bioinformatics Research Applications, 6, 384401.Thayasivam, U., & Doshi, P. (2012a). Improved convergence iterative ontology alignment usingblock-coordinate descent. Twenty-Sixth Conference Artificial Intelligence (AAAI), pp.150156.Thayasivam, U., & Doshi, P. (2012b). Optima+ results OAEI 2012. Workshop Ontology Matching 11th International Semantic Web Conference (ISWC). Vol. 946 CEURWS.org.Tseng, P. (2001). Convergence block coordinate descent method nondifferentiable minimization. Journal Optimization Theory Applications, 109, 475494.Wang, P., & Xu, B. (2009). Lily: Ontology alignment results OAEI 2008. ProceedingsWorkshop Ontology Matching 7th International Semantic Web Conference (ISWC).845fiJournal Artificial Intelligence Research 50 (2014) 321-367Submitted 1/14; published 6/14Game-Theoretic Security Patrolling Dynamic ExecutionUncertainty Case Study Real Transit SystemFrancesco M. Delle FaveAlbert Xin JiangZhengyu YinChao ZhangMilind Tambedellefav@usc.edujiangx@usc.eduzhengyuy@usc.eduzhan661@usc.edutambe@usc.eduUniversity Southern California,Los Angeles, CA 90089 USASarit Kraussarit@cs.biu.ac.ilBar Ilan University,Ramat Gan 52900, IsraelJohn P. Sullivanjpsulliv@lasd.orgLos Angeles County Sheriff DepartmentLos Angeles, CA 90059AbstractAttacker-Defender Stackelberg security games (SSGs) emerged importantresearch area multi-agent systems. However, existing SSGs models yield fixed, static,schedules fail dynamic domains defenders face execution uncertainty, i.e.,domains defenders may face unanticipated disruptions schedules. concreteexample application involving checking fares trains, defenders schedulefrequently interrupted fare evaders, making static schedules useless.address shortcoming, paper provides four main contributions. First,present novel general Bayesian Stackelberg game model security resource allocationdynamic uncertain domains. new model, execution uncertainty handledusing Markov decision process (MDP) generating defender policies. Second, studyproblem computing Stackelberg equilibrium game exploit problemstructure reduce polynomial-sized optimization problem. Shifting evaluation,third contribution shows, simulation, MDP-based policies overcomefailures previous SSG algorithms. doing, build complete system,enables handling schedule interruptions and, consequently, conduct firstcontrolled experiments SSGs field. Hence, final contribution, presentresults real-world experiment Metro trains Los Angeles validating MDPbased model, importantly, concretely measuring benefits SSGs securityresource allocation.1. Introductionrecent years, research algorithmic game theory started show significant interestsecurity resource optimization problems. research led decision aids realworld security agencies need deploy patrols checkpoints protect targetsterrorists criminals (Tambe, 2011). Stackelberg security games (SSGs)advocated powerful tool model problems (Gatti, 2008; Conitzer, 2012; Basilico,c2014AI Access Foundation. rights reserved.fiDelle Fave, Jiang, Yin, Zhang, Kraus, & TambeGatti, & Amigoni, 2009a; Vorobeychik & Singh, 2012; Vanek, Jakob, Lisy, Bosansky, &Pechoucek, 2011; Pita, Jain, Western, Portway, Tambe, Ordonez, Kraus, & Paruchuri, 2008;Tambe, 2011). SSG two-player game defender (the security agency)adversary (a terrorist criminal). defender commits mixed strategyrandomized resource allocation specified probability distribution deterministicschedules takes account adversarys best response observationmixed strategy1 . Several decision-support systems based SSGs successfullydeployed real world domains assisting security ports, airports, ferriestransit systems. Examples include ARMOR GUARDS airport security (Pita et al.,2008; Pita, Tambe, Kiekintveld, Cullen, & Steigerwald, 2011), IRIS allocating securitypersonnel international flights US Carriers (Tsai, Rathi, Kiekintveld, Ordonez, &Tambe, 2009), PROTECT randomized patrols security ports passenger ferriesports New York, Boston Los Angeles (Shieh, An, Yang, Tambe, Baldwin,DiRenzo, Maule, & Meyer, 2012; Fang, Jiang, & Tambe, 2013) TRUSTS patrollingMetro trains Los Angeles (Yin, Jiang, Johnson, Tambe, Kiekintveld, Leyton-Brown,Sandholm, & Sullivan, 2012).domains discussed involve patrolling transportation systemtrain-line, ferry flight system. settings, schedules typically timecritical depend time table vehicles (trains, ferries flights).However, interruptions frequent patrolling key transportation systemsofficer might respond emergency, provide assistance passengerneed arrest someone. example, patrolling trains, whenever officer delayedmidway, might become impossible officer complete patrol schedule. Hence,fixed schedules cannot updated interruption hard followofficer delayed. Unfortunately, previous work often provided static fixed patrollingschedules face problems presence unanticipated disruptions.general, execution uncertainty endemic transportation domainsaffect defender units ability carry planned schedules later time steps. Onemotivating example, used throughout work, TRUSTS systemscheduling fare inspections Los Angeles metro rail system (LA Metro). TRUSTS (Yinet al., 2012), currently evaluated Los Angeles sheriffs department (LASD),provides game-theoretic solution scheduling randomized patrols fare inspectionstrains stations. see later paper, real world trials carriedLASD, significant fraction executions pre-generated schedules gotinterrupted variety reasons writing citations, felony arrests, handlingemergencies. interruptions caused officers miss train supposedtake part patrol schedule. occasions, solution TRUSTSprovide instructions interruption making schedules uselessofficers.Previous work addressed aspects execution uncertainty. particular, Yin,Jain, Tambe, Ordonez (2011), Yin Tambe (2012) present two different approaches,one based robust optimization another Bayesian method, whereby defenderoptimizes mixed strategy taking account (small) fraction1. convention security games literature, defender referred adversaryhe.322fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyincorrectly executed. Unfortunately, discussed above, domains interestwork, including TRUSTS, significant fraction schedules interrupted.importantly, cases, previous work suggest alternatives wheneverdefenders patrol interruptedthus fails optimally use patrol time.clearly indicates key challenge still needs addressed SSGs: new frameworkneeded, generate patrol schedules robust execution uncertaintyprovide contingency plans whenever disruptions occur.provide framework, paper presents four main contributions. firstcontribution consists general Bayesian Stackelberg game model security patrollingexecution uncertainty. model, execution uncertainty handled via Markovdecision process (MDP). second contribution detailed study problemcomputing Stackelberg equilibrium (SSE) game. Computing SSE timelyfashion presents significant computational challenges defenders strategy space,already exponential real-world applications (Jain, Kardes, Kiekintveld, Tambe, &Ordonez, 2010; Conitzer, 2012), grows complexity given must addresscontingencies execution. address shortcoming, showgames utility functions specific separable structure, defenders strategy spacecompactly represented. using structure, reduce problempolynomial-sized optimization problem, solved existing approachessolving Bayesian Stackelberg games without execution uncertainty, e.g., DOBSS (Paruchuri,Pearce, Marecki, Tambe, Ordonez, & Kraus., 2008b). However, randomized patrolschedules obtain, well-defined MDP-policies, i.e., plans, takeaccount contingencies unexpected events. show remainder work,policies always generated polynomially-sized support. addition,policies loaded smart-phone application carried patrol units shift.next two contributions focus application former approach generatepatrol schedules fare inspection LA Metro. detail, third contributionshows simulation that, modeling execution uncertainty MDP, ablegenerate policies overcome failures existing SSG algorithms takeuncertainty account. addition, results numerical experiments showexecution uncertainty significant impact defenders expected utility.key question raised deployed applications SSGs evaluation performance field. Whereas many different evaluation metrics offered,difficult evaluate SSGs approaches resource allocation generateactual domains airport port security (Tambe, 2011). Fortunately, MDP policiesnew game model, loaded onto smartphonesan application discuss laterpaperenables us test use SSGs field alternatives.fundamentally new test real world validate new game model,generally, algorithmic game theory field. Therefore, fourth contributionreal-world experiment aims evaluate comprehensive game-theoretic systemfield. Specifically, ran 21-day experiment, compared schedules generated using approach competing schedules comprised random scheduleraugmented officers providing real-time knowledge current situation. resultsprovided evidence support MDP-based modelthe contingency plans providedMDP actually used significant frequency real world. importantly,323fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tamberesults showed game-theoretic schedules led statistically significant improvements competing schedules, despite fact latter improvedreal-time knowledge. results constitute first example head-to-head comparisonSSGs competing approaches field. fact, constitute firstdata obtained deploying algorithmic game theory real-world.summary, paper makes following contributions:present novel Bayesian Stackelberg game model accounts executionuncertainty security patrolling using MDP.study problem computing Stackelberg equilibrium (SSE) game.Specifically, derive conditions game represented compact form, solved polynomial time. resulting strategies are,however, MDP-policies, i.e., plans, take account contingencies unexpected events.present extensive empirical evaluation whereby analyze impact execution uncertainty new game model expected utility defender.present real-world experiment compared schedules generated usingapproach competing schedules comprised random scheduler. resultsshowed game-theoretic schedules outperformed competing schedules termsnumber fare evaders captured. doing, provide evidencebenefits deploying algorithmic game theory real-world.remainder paper organized follows: Section 2 presents related workSSGs handle uncertainty. Section 3 discusses motivating problempatrolling LA Metro system presents formal model problem BayesianStackelberg game. Section 4 discusses solution method. Section 5 discusses wayapply model defined Section 4 LA Metro problem. Section 6 discussesevaluation consisting simulations real world experiments and, finally Section 7concludes discusses future work.2. Related WorkStackelberg security games (SSGs) gathered significant attention literature (Basilicoet al., 2009a; Dickerson, Simari, Subrahmanian, & Kraus, 2010; Letchford, MacDermed,Conitzer, Parr, & Isbell, 2012; Letchford & Conitzer, 2013; Letchford & Vorobeychik, 2013;Korzhyk, Conitzer, & Parr, 2011a, 2011b). Indeed, stated earlier, SSGs modelsalgorithms used build decision aids including ARMOR (Pita et al., 2008), IRIS(Tsai et al., 2009), GUARDS (Pita et al., 2011) PROTECT (Shieh et al., 2012).importantly, two systems, namely TRUSTS (Yin et al., 2012) RaPtoR (Varakantham,Lau, & Yuan, 2013), used generate schedules patrolling public transitsystems LA Metro Singapore Metro system. Unfortunately,deployed applications take execution uncertainty account. consequence,useful settings interest paper, ones involving patrollingtransportation system disruptions may occur frequently.324fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyNonetheless, tackling uncertainty become one principal challenges SSGsresearch. particular, previous work focused different types uncertainties: uncertainty adversary response due bounded rationality (Yang, Kiekintveld, Ordonez,Tambe, & John, 2011; Nguyen, Yang, Azaria, Kraus, & Tambe, 2013), uncertainty adversary surveillance (An, Tambe, Ordonez, Shieh, & Kiekintveld, 2011), uncertainty adversary capability uncertainty defender execution strategies (Yin et al., 2011; Yin &Tambe, 2012)2 . respect bounded rationality, previous approaches focuseddifferent models bounded rationality, logit quantal response subjective utilityquantal response (Yang et al., 2011; Nguyen et al., 2013). However, frameworksaddress execution uncertainty and, consequence, address challengestudied work. respect adversary surveillance, previous approaches focused modeling fact many domains adversary partially observedefenders mixed strategy (An, Kempe, Kiekintveld, Shieh, Singh, & Tambe, 2012).Similarly, respect uncertainty adversarys surveillance capabilitydefenders execution strategy, previous approaches focused modeling uncertaintyusing Bayesian game (Yin & Tambe, 2012) using robust strategy computation,including robust optimization, provide safe quality guarantees obtained defendersstrategy (Yin et al., 2011). Unfortunately, discussed Section 1, approachessuggest alternative whenever defenders patrol interrupted. Thusaddress challenge setting, would generate schedules wouldbecome useless anytime defender interrupted.game theoretic perspective then, game model paper consideredextensive-form Stackelberg games chance nodes (Letchford & Conitzer, 2010),special case stochastic Stackelberg game follower chooseone action initial state stick action future states (Letchford et al.,2012). general cases games shown NP-hard. VorobeychikSingh provided mixed integer linear programs finding optimal approximate Markovstationary strategy general-sum stochastic Stackelberg games (Vorobeychik & Singh,2012). However, approach handle multiple adversary types MILPformulation lacks scalability large number states LA Metro problems.Another related line research equilibrium refinement dynamic games,trembling hand perfect equilibrium (Aoyagi, 1996), considers possibilitystrategy imperfectly executed. However research mainly interestedlimit uncertainty goes zero, real world settings probability imperfectexecution really non-zero.types SSGs include multi-robot adversarial patrolling games (MAPG).MAPG special restricted type SSG considers problem multi-robotpatrol around closed area existence adversary attempting penetratearea (Agmon, Kraus, & Kaminka, 2008a; Agmon, Kaminka, & Kraus, 2011).penetration requires time defender identify attacker attempt.literature uncertainty MAPGs studied uncertainty related type2. Execution uncertainty also studied context finding Nash-equilibrium standardmulti-player simultaneous move games (Bowling & Veloso, 2004; Archibald & Shoham, 2011). Despiteaddressing similar topic, however, literature scope work, centeredmodeling execution uncertainty SSGs.325fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambeknowledge attacker (Agmon, Sadov, Kaminka, & Kraus, 2008b; Basilico, Gatti,Rossi, Ceppi, & Amigoni, 2009b; Basilico, Gatti, & Villa, 2010). Furthermore, assumedadversary detected robots continue patrol around area lookingadditional attackers without need modify strategy. Thus, execution uncertainty,discussed work, addressed.One exception, closer work, work Sless, Agmon, Kraus(2014) requires robots physically inspect penetration attempts given timeperiod. This, work, far reaching consequences performancepatrol algorithm. Specifically, creates vulnerability points along patrol pathtaken advantage knowledgeable adversary. particular, Sless et al. (2014)investigate problem coordinated attacks, adversary initiates two attacksorder maximize chances successful penetration, assuming robot teamsent examine penetration attempt. suggest algorithm computingrobots strategy handling coordinated attacks, show despite exponentialtime complexity, practical run time algorithm significantly reduced withoutharming optimality strategy. Unfortunately, whereas work assumescontribution multiple patrol units covering edge additive, thus enablingformulate problem linear programming problem, Sless et al. settingshold multiple robot covering segment contribute singlerobot.Finally, since significant portion work deals deploying game-theoreticschedules field, relevant discuss existing literature addressed similarchallenge. discussed Section 6, deploy game-theoretic schedules deterfare evasion LA metro system. doing, work similar number studiesfare-evasion prevention conducted systems London Alberta (Clarke, 1993;Weidner, 1996; Clarke, Contre, & Petrossian, 2010). studies focused understandingimpact introducing automatic gates, turn-styles ticket prices, fare evasionrate. work, interested different aspect: understanding game-theoreticscheduling affect performance security resources responsible patrollingtransit system every day.Given focus validating game-theoretic scheduling real world, workshares many ideas literature game theory field. line researchfocused showing equilibrium concepts human animal activities (Ostling, Wang,Tao-yi, Chou, & Camerer, 2011; Brown, Camerer, & Lovallo, 2012). work sharesenthusiasm taking game theory field, fundamentally focuses algorithmicdeployments impact algorithms.3. Problem Statementsection discusses, first, Los Angeles Metro domain, key domain usedmotivation work. Second, presents Stackelberg game modeldefine formalize problem.326fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty3.1 Motivating Example: LA Metro Systemmodel quite general modeling time-sensitive patrols security domainsexecution uncertainty, study paper substantially motivated TRUSTS,application scheduling fare inspections Los Angeles Metro Rail system (Yinet al., 2012). LA Metro Rail system, similar proof-of-payment transit systemsworldwide, barrier-free transit system passengers legally required purchase tickets boarding, physically blocked gates turnstiles. Instead,security personnel dynamically deployed throughout transit system, randomly inspecting passenger tickets. approximately 300,000 daily riders, revenue loss duefare evasion significantthis cost estimated $5.6 million (Booz AllenReport, 2007). Los Angeles Sheriffs Department (LASD) deploys uniformed patrolsonboard trains stations fare-checking (and purposes crime suppression), order discourage fare evasion. limited resources devote patrols,impossible cover locations times.TRUSTS, currently evaluated LASD, provides game-theoretic solutionscheduling randomized patrols fare evasion deterrence. given day, TRUSTS generates one patrol schedule fare inspection team according pre-computed probability distribution large set possible patrol candidates. patrol schedule generatedsequence fare-check operations, alternating in-station on-train operations. operation indicates specifically patrol unit check fares.Unfortunately, security personnel may deviate given schedule varietyreasons, writing citations, felony arrests, handling emergencies, etc. Indeed, 5 realworld trials carried LASD, 4 times pre-generated schedules got interrupted.Often entire schedule got abandoned interruption operations specifiedafterwards became irrelevant. example, officer following pre-generated schedulewrite citation rider carrying valid ticket, preventing carryingrest schedule.3.2 Formal ModelFigure 1: Example schedule.first contribution work, present formal game-theoretic modelpatrolling dynamic execution uncertainty. patrolling game execution uncertaintytwo-player Bayesian Stackelberg game, leader (the defender) follower(the adversary). leader patrol units, commits randomized daily patrolschedule unit. patrol schedule consists list commands carriedsequence. command form: time , unit location l,327fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambeexecute patrol task a. patrol action current command, executedsuccessfully, take unit location time next command. graphicalrepresentation schedule shown Figure 1. unit faces uncertaintyexecution command: delays, called deal emergencies (possiblyanother location). result unit may end location time differentintended outcome action, thus rest naive patrol schedulecannot executed.use Markov Decision Processes (MDPs) compact representation modelindividual defender units patrol actions. emphasize MDPs wholegame: model defenders patrol actions environment executingpatrols; later describe interaction defender adversary.Formally, defender unit {1, . . . , } define MDP (Si , Ai , Ti , Ri ),Si finite set states. state si Si tuple (l, ) current locationunit current discretized time. denote l(si ) (si ) locationtime si , respectively.Ai finite set actions. Let Ai (si ) Ai set actions available state si .si Si action ai Ai (s), default next state n(si , ai ) Siintended next state executing action ai si . call transition (si , ai , si ) defaulttransition si = n(si , ai ) non-default transition otherwise.Ti (si , ai , si ) probability next state si current state siaction taken ai .Ri (si , ai , si ) immediate reward defender transition (si , ai , si ).example, available emergencies (such helping lost child) importantfunction police, take account optimization formulationusing Ri give positive rewards events.assume MDP acyclic: Ti (si , ai , si ) positive (si ) > (si ),i.e., transitions go forward time. Si+ Si subset states patrolcould start. patrol could end state. convenience, add dummy sourcestate s+Si actions deterministic transitions going states+Si , analogously dummy sink stateSi . Thus patrol defenderstarts s+ends.patrolexecutionspecified complete trajectory+ 1 1 2ti = (s+,,,,,...,),recordssequence states visited actionsperformed. joint complete trajectory, denoted = (t1 , . . . , ), tuple completetrajectories units. Let X finite space joint complete trajectories.immediate rewards Ri utility received defender. defenderalso receives rewards interactions adversary. adversary setpossible types finite set actions A. types drawn knowndistribution, p probability type . defender knowinstantiated type adversary, adversary condition decisiontype.general game model, utilities resulting defender-adversary interactioncould depend arbitrarily complete trajectories defender units. Formally,joint complete trajectory t, realized adversary type , action adversaryA, defender receives utility ud (t, , ), adversary receives ua (t, , ).328fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyinterested finding Strong Stackelberg Equilibrium (SSE) game,defender commits randomized policy define next, adversaryplays best response randomized policy. sufficient consider purestrategies adversary (Conitzer & Sandholm, 2006). Finding one SSE equivalentfollowing optimization problem:maxXp Et [ud (t, , ) +XRi (ti )](1)s.t. arg max Et [ua (t, , )],(2)Ri (ti ) total immediate reward trajectory ti , Et [] denotesexpectation joint complete trajectories induced defenders randomized policy .Whereas MDPs always Markovian deterministic optimal policies, gamedefenders optimal strategy may non-Markovian utilities dependtrajectories, may randomized interactions adversary. considertwo cases: coupled execution decoupled execution. coupled execution, patrol unitscoordinate other; is, behavior unit si could dependearlier joint trajectory units. Formally, let Ti set unit isQpartial Qtrajectories+ 1 1). coupled randomized policy function :(s+,,,,...,Ai Rspecifies probability distribution joint actions units joint partialtrajectory. Let (t; ) R probability joint complete trajectory Xinstantiated policy . decoupled execution, patrol units communicateother. Formally, decoupled randomized policy = (1 , . . . , ) uniti, : Ti Ai R specifies probability distribution actions given partialtrajectory i. Thus decoupled randomized policy (1Q, . . . , ) thoughtcoupled randomized policy (t, (a1 , . . . , )) = (ti , ai ).Coupled execution potentially yields higher expected utility decoupled execution.Suppose defender wants protect important target least one unit, unit1 assigned task. knows unit 1 dealing emergency unablereach target, reroute unit 2 cover target. However, coordinating amongunits presents significant logistical (as see paper) computational burden.4. Approachdefenders optimal strategy may coupled non-Markovian, i.e., policycould depend entire earlier trajectories units rather current states. makes solving game computationally difficultthe dimension spacemixed strategies exponential number states.Nevertheless, many domains, utilities additional structure.extensive research efficient computation SSE massive games structured utilityfunctions (Tambe, 2011), including LA Metro domain (Yin et al., 2012),works cannot deal type execution uncertainty studied paper. Section 4.1 show assumption utilities separable structure,possible efficiently compute SSE patrolling games execution uncertainty.Section 4.2 discuss generating patrol schedules solutions described Section 4.1.329fiDelle Fave, Jiang, Yin, Zhang, Kraus, & TambeSection 4.3 present procedure extract optimal mixed strategypolynomial-sized support. Section 4.4 consider general case partiallyseparable utilities.4.1 Efficient Computation via Compact Representation StrategiesConsider coupled strategy . Denote xi (si , ai , si ) marginal probability defenderunit reaching state si , executing action ai , ending next state si . Formally,xi (si , ai , si ) =X(t; )(ti , si , ai , si ),(3)tXvalue membership function (ti , si , ai , si ) equal 1 trajectory ticontains transition (si , ai , si ) equal 0 otherwise. defined Section 3.2,state tuple (l, ) current location unit current discretized time.Hence, marginal probability xi (si , ai , si ) takes account location,also time specific patrol action taken. see remaindersection, time location affect expected utility players. Hence,design choice improves accuracy model compared realP world problem. Letx RM vector marginal probabilities, = |Si |2 |Ai |. Similarly,let wi (sPi , ai ) marginal probability unit reaching si taking action ai . Letw R |Si ||Ai | vector marginal probabilities.goal compactly represent SSE problem terms w x,dimensions polynomial sizes MDPs. first show w x satisfylinear constraints:xi (si , ai , si ) = wi (si , ai )Ti (si , ai , si ), si , ai , siXXxi (si , ai , si ) =wi (si , ai ), siai(5)aisi ,aiX(4)wi (s+, ai ) =Xxi (si , ai ,) = 1,(6)si ,aiwi (si , ai ) 0, si , ai(7)Lemma 1. coupled randomized policy , resulting marginal probabilities wi (si , ai )xi (si , ai , si ) satisfy constraints (4), (5), (6), (7).Proof. Constraint (4) holds definition transition probabilities MDPs. Constraint(5) holds lhs rhs equal marginal probability reaching state s.Constraint (6) holds construction, marginal probability reaching s+1,marginal probability reaching si . Constraint (7) holds wi (si , ai )probability.Similar formulations marginal probabilities MDPs known (e.g., Filar & Vrieze,1996). However, unlike MDPs, general utility functions depend defenders complete trajectory adversarys type action, result w xsufficient determine expected utilities game. Thus, order make330fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyuse compact representation, need make restrictions structureutility functions. turns formulate expected utilities termsw x games utilities separable, intuitively means given adversarys strategy, utilities players sums contributions individual unitsindividual transitions:Definition 1. patrolling game execution uncertainty defined Section 3.2separable utilities exist utilities Ud (si , ai , si , ) Ua (si , ai , si , ) uniti, transition (si , ai , si ), , A, X , , A, defendersadversarys utilities expressedX Xud (t, , ) =(ti , si , ai , si )Ud (si , ai , si , )ua (t, , ) =si ,ai ,siX X(ti , si , ai , si )Ua (si , ai , si , ),si ,ai ,sirespectively.Let Ud , Ua RM |A| corresponding matrices. Ud , Ua completely specifiesutility functions ud ua .Recall (ti , si , ai , si ) equal 1 trajectory ti contains transition (si , ai , si )equal 0 otherwise. definition saying separable game, playersutility trajectory decomposed contributions transitionunits trajectory ti . natural extension additive reward modelMDPs multi-player setting. Separable games represent common attacker-defenderpatrolling scenarios, illustrated following example.0L1L1, 011.0StayL1, 12L20.9L1L10.10.1L2, 0Stay0.90.90.9L2L1, 20.10.1L21.0Stay1.0L2, 1Stay1.0L2, 2Figure 2: Example game separable utilities.Example 1. Consider simple example game one defender unit, whose MDPillustrated Figure 2. six states, shown circles figure, two locations L1 , L2 three time points 0 , 1 , 2 . states 0 1 , unittwo actions: stay current location, always succeeds, try go331fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambelocation, probability 0.9 succeeds probability 0.1 fails (incase stays current location). 12 transitions total,fewer number complete trajectories (18). single type adversary chooses one location L1 L2 one time point 1 2attack (0 cannot chosen). defender location time, attack fails players get zero utility. Otherwise, attack succeeds, adversary gets utility 1 defender gets 1. words, attack succeedsavoids defender units trajectory. game separable utilities:transition (si , ai , si ) MDP, let Ua (si , ai , si , ) 0 coincides si1 otherwise. players utility given trajectory expressed sumcontributions transitions, exactly Definition 1. example, utility expression adversary given trajectory ((L1 , 0 ), L2 , (L1 , 1 ), L2 , (L2 , 2 ))Ua ((L1 , 0 ), L2 , (L1 , 1 ), ) + Ua ((L1 , 1 ), L2 , (L2 , 2 ), ), gives correctutility value adversary: 0 equals (L1 , 1 ) (L2 , 2 ) 1 otherwise.straightforward show following.Lemma 2. Consider game separable utilities. Suppose x vector marginalprobabilities induced defenders randomized policy . Let R|A| vectordescribing mixed strategy adversary type , () denoting probabilitychoosing actionadversarys expected utilitiesPP . defendersinteractions p xT Ud p xT Ua , respectively.words, given adversarys strategy, expected utilities playerslinear marginal probabilities xi (si , ai , si ). Lemma 2 also applies (asSSE) adversary playing pure strategy, case 0-1 integer vector() = 1 action chosen. thus use compact representationdefender strategies rewrite formulation SSE (1) polynomial-sized optimizationproblem.maxw,x,yXp xT Ud +XXxi (si , ai , si )Ri (si , ai , si )(8)i=1si ,ai ,sis.t. constraints (4), (5), (6), (7)X() = 1,(9)() {0, 1},xarg max,Ua(10)(11)show Section 4.2, given solution w, x (8), calculate decoupledpolicy matches marginals w, x. Compared (1), optimization problem (8)exponentially fewer dimensions; particular numbers variables constraintspolynomial sizes MDPs. Furthermore, existing methods solving BayesianStackelberg games, mixed-integer linear program formulation (Paruchuri, Pearce,Marecki, Tambe, Ordonez, & Kraus, 2008a) branch-and-bound approach (Yin & Tambe,2012), adapted solve (8). example, Paruchuri et al. (2008a) formulated332fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyproblem mixed-integer quadratic program, transformed equivalentmixed-integer linear program, solved using standard optimization solvers likeCPLEX. Paruchuri et al. (2008a) assumed defenders strategy spacestandard simplex, replace simplex constraints flow constraints (4), (5),(6), (7), apply techniques described Paruchuri et al. (2008a) derivemixed-integer linear program.special case Ud + Ua = 0 , i.e., interaction defenderadversary zero-sum, SSE problem formulated following linearprogram (LP):XX Xmaxp u +xi (si , ai , si )Ri (si , ai , si )(12)w,x,usi ,ai ,sis.t. constraints (4), (5), (6), (7)u xT Ud e ,, A,(13)e basis vector corresponding adversary action . LP similarmaximin LPzero-sum game utilities given Ud Ua , except adP aPditional term si ,ai ,s xi (si , ai , si )Ri (si , ai , si ) representing defenders expected utilitiesimmediate rewards added objective. One potential issue arises:extra defender utilities immediate rewards, entire game longer zero-sum.still valid use maximin LP formulation? turns LP indeedvalid, immediate rewards depend adversarys strategy.Proposition 1. game separable utilities Ud + Ua = 0 ,solution LP (12) SSE.Proof. transform game equivalent zero-sum Bayesian game whose LPformulation equivalent (12). Specifically, given non-zero-sum Bayesian gamespecified above, consider Bayesian game following meta type distributionsecond player: corresponding type ,probability p = 0.5p , familiar utility functions; special typeprobability p = 0.5, whose action affectP eitherP players utility. Specificallyutilities special type ud (t, , ) = si ,ai ,s (ti , si , ai , si )Ri (si , ai , si )P Pua (t, , ) = si ,ai ,s (ti , si , ai , si )Ri (si , ai , si ). resulting game zeroisum, defenders utility exactly half objective (12). Since zero-sum gamesmaximin strategies SSE coincide, solution LP (12) optimal SSE marginalvector defender . hand, compare inducedP normal forms, difference adversary utility 0.5 eE Ue xe added,depend adversarys strategy. Therefore setSSE, implies solution LP SSE .4.2 Generating Patrol Schedulessolution (8) yet provide complete specification do. ultimately want explicit procedure generating patrol schedules. define Markovstrategy decoupled strategy (1 , . . . , ), : Si Ai R, distribution333fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambenext actions depends current state. Proposition 2 shows givenw, x, simple procedure calculate Markov strategy matches marginalprobabilities. implies w, x optimal solution (8), correspondingMarkov strategy achieves expected utility. thus shown gamesseparable utilities sufficient consider Markov strategies.Proposition 2. Given w, x satisfying constraints (4) (7), construct Markov strategyP(si ,ai )follows: si Si , ai Ai (si ), (si , ai ) = Pwiw) .wi (si , ai ) =(s,a0 set (si , ) arbitrary distribution. Suppose defender plays ,unit transition (si , ai , si ), probability (si , ai , si ) reached equalsxi (si , ai , si ).Proof. Markov strategy induces Markov chain states Si uniti. claim resulting marginal probability vector Markov chain matches x.show induction starting state s+successor states. marginal+probability Pr(s+,)reachingstatetakingactionai equal (s+, ai ), since+s+1 always reached. (si , ai ) =Pwi (s+,ai )w(s+,ai )= wi (s+, ai ) constraint (6),marginals matched s+. inductive step, marginal probability Pr(si , ai )reaching si taking action ai equal Pr(si )i (si , ai ), Pr(si ) probabilityreaching si . induction hypothesis,P Pr(si ) computed marginalsx, w previous states, Pr(si ) = ,a xi (si , ai , si ).Pr(si , ai ) = (si , ai )Xwi (si , ai ) Xxi (si , ai , si ) = Pxi (si , ai , si ) = wi (si , ai ))w(s,si ,aisi ,aiconstraint (5). Thus marginals matched states.practice, directly implementing Markov strategy requires unit drawaction according probability distribution (si , ) state si . possibleunit consult random-number generator, communicate centralcommand. However, certain domains requirement computation communicationtime step places additional logistical burden patrol unit. avoid unnecessarycomputation communication every time step, desirable let unit executedeterministic schedule (i.e., pure strategy). guarantee optimal expected utility,want deterministic schedule drawn distribution marginalsoptimal solution (8). say procedure generates patrols correctproperty. execution uncertainty, pure strategy specifiedcomplete trajectory unit. However, longer works case executionuncertainty, interruptions lead states outside trajectory.thus begin defining Markov pure strategy, specifies deterministic choicestate.Definition 2. Markov pure strategy q tuple (q1 , . . . , q ) unit i,qi : Si Ai .334fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintynote set Markov pure strategies subset pure strategies,generally condition choices earlier histories addition current states.Nevertheless, show Markov pure strategies useful part efficientprocedure sampling solution (8).Given Markov strategy , sample Markov pure strategy q follows:Procedure 1. Given , unit state si Si , sample action ai according, set qi (si ) ai . Output Markov pure strategy q.procedure correct since state MDP visited thusqi exactly simulates walk s+Markov chain induced .directly implement Markov pure strategy, unit needs either rememberentire mapping q receive action central command time step.alternative scheme requires small amount storage minimal amount communication following: central command sends unit trajectory assumingperfect execution, non-default transition happened unit communicates central command get new trajectory starting current state.Formally, given si Si qi , define optimistic trajectory si induced qi(si , qi (si ), n(si , qi (si )), . . . ), i.e, trajectory assuming always reaches defaultnext state. Given Markov pure strategy q, following procedure exactly simulates q:Procedure 2. unit i: (i) central command gives unit optimistic trajectorys+ induced qi ; (ii) unit follows trajectory terminal state reachedunexpected event happens takes state si ; (iii) latter case, centralcommand sends unit new optimistic trajectory si induced qi repeatstep (ii).4.3 Extracting Mixed Strategy Small Supportfar procedures generating patrol schedules described different implementations Markov strategy Proposition 2. corresponds mixed strategyset Markov pure strategies: Markov pure strategy q played probability equal probability sampled sampling procedure. supportmixed strategy, i.e., set pure strategies non-zero probability, generalexponential-sized set.practice, sometimes desirable mixed strategy polynomial-sizedsupport. example, security agency may need carry training exercisespure strategies support (e.g., Fang et al., 2013). cases, would likepolynomial-support mixed strategy achieves expected utility optimalsolution (8). following proposition shows always exists polynomialsupport mixed strategy matches given marginals w, x, therefore achievesoptimal expected utility w, x solution (8).Proposition 3. Given w, x satisfying constraints (4) (7), exists mixed strategypolynomial-sized support matches marginals.Proof. Since (w, x) polytope defined constraints (4) (7), extreme pointspolytope correspond pure strategies, Caratheodorys Theorem3 implies (w, x)3. See Chapter 3 (Gruber, 2007)335fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambewritten convex combination dim(w)+dim(x)+1 = O(pure strategies.P|Si |2 |A |)However, proof constructive. Grotschel, Lovasz, Schrijver (1981)provided polynomial-time procedure given point inside polytope, decomposesconvex combination polynomial number extreme points polytope;however method requires application ellipsoid method, tends slowpractice. section, provide efficient procedure generating mixed strategypolynomial-sized support matches marginals w, x.Procedure 3. Given (w, x), optimal solution (8), initialize mixed strategyempty support set.1. Compute Markov strategy (si , ai ) =Pwi (si ,ai ) .wi (si ,ai )Paiwi (si , ai ) = 0set (si , ) arbitrary distribution.2. Select Markov pure strategy q played positive probability . Onepossible way construct q follows: state si , set qi (si ) actionai played positive probability si .3. Compute marginals wq , xq corresponding pure strategy q. dones+successor states.4. Let q maximum w wq 0 x xq 0.5. Set w := w q wq , x := x q xq . Add pure strategy q support, playedprobability q .6. w = 0, Stop. Otherwise, go Step 1.Proposition 4. Procedure 3 outputs polynomial time mixed strategy polynomialsized support, matching marginals.Proof. Since wq , xq valid marginal vectors satisfying constraints (4) (7), updatedmarginals (w, x) Step 5 still satisfies flow conservation constraints (4), (5),nonnegativity constraint (7), total flow (corresponding (6)) reducedq . implies steps procedure well-defined; furthermoreprocedure stops, output sum 1, corresponding mixed strategy matchesmarginals wq , xq .remains show procedure stops polynomial number iterations.see this, note construction, execution Step 5 reduce least onecomponent (w, x) zero. otherwise could increase qP, contradictingStep 4. Therefore procedure stops dim(w) + dim(x) = O( |Si |2 |Ai |)iterations; since iteration adds one pure strategy support, resultingmixed strategy polynomial-sized support.336fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty4.4 Coupled Execution: Cartesian Product MDPWithout assumption separable utilities, longer sufficient consider decoupledMarkov strategies individual units MDPs. create new MDP captures jointexecution patrols units. simplicity exposition look case twodefender units. state new MDP corresponds tuple (location unit 1,location unit 2, time). action new MDP corresponds tuple (action unit1, action unit 2). Formally, unit 1 action a1 state s1 = (l1 , ) takess1 = (l1 , ) probability T1 (s1 , a1 , s1 ), unit 2 action a2 state s2 = (l2 , )takes s2 = (l2 , ) probability T2 (s2 , a2 , s2 ), create new MDPaction = (a1 , a2 ) state = (l1 , l2 , ) transitions = (l1 , l2 , )probability (s , , ) = T1 (s1 , a1 , s1 )T2 (s2 , a2 , s2 ). immediate rewards RMDP defined analogously. call resulting MDP (S , , , R ) CartesianProduct MDP.issue arises state individual units transitions different timedurations. example, unit 1 rides train takes 2 time steps reach next stationunit 2 stays station 1 time step. intermediate time stepsunit 2 free choice. model Cartesian Product MDP? Oneapproach create new states intermediate time steps. example, supposelocation LA time 1 non-default transition takes unit 1 location LA time 3.modify unit 1s MDP transition ends new state (L1A , 2) S1 , L1Aspecial location specifying unit become alive location LAone time step. one action (L1A , 2), one possible nextstate (LA , 3). modified individual units MDPs transitionstake exactly one time step, create Cartesian Product MDP describedprevious paragraph.Like units MDPs, Cartesian Product MDP also acyclic. Thereforeanalogously define marginal probabilities w (s , ) x (s , , ) Cartesian2Product MDP. Let w R|S ||A | x R|S | |A | corresponding vectors.Utilities generally cannot expressed terms w x . consider special caseutilities partially separable:Definition 3. patrolling game execution uncertainty partially separable utilities exist Ud (s , , , ) Ua (s , , , ) transition (s , , ),, A, X , P, A, defenders adversarysutilities expressed ud (t, , ) = ,a ,s (t, , , )Ud (s , , , )Pua (t, , ) = ,a ,s (t, , , )Ua (s , , , ), respectively.Partially separable utilities weaker condition separable utilities,expected utilities may sums contributions individual units. utilitiespartially separable, express expected utilities terms w x find,SSE solving optimization problem analogous (8). optimal w(s , ) =get Markov strategyw (s ,a )P,w (s,a )provably optimal coupledstrategy.approach cannot scale large number defender units, sizegrow exponentially number units. particular dimension Markov337fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambepolicy already exponential number units. overcome needcompact representation defender strategies. One approach use decoupledstrategies. resulting defender strategy model resembles transition independent DECMDP (Becker, Zilberstein, Lesser, & Goldman, 2004). However, due strategic interactionadversaries, existing methods DEC-MDPwhich compute pure strategiescannot directly applied. Efficient computation settings remains open problem.5. Case Study LA Metro Systemsection discusses apply model presented Section 3.2 approachpresented Section 4 problem patrolling LA Metro system fare evasion.particular, Section 5.1 discusses game model adapted LA metro patrollingproblem Section 5.2 discusses use framework build scheduling systemwhereby schedules generated central planner visualized smartphoneapplication running android phones.5.1 Application LA Metro Domainexplain proposed techniques used LA Metro domain.involves defining number parameters specific LA Metro domaininitialized real-world experiment Section 6. addition, see, althoughutilities domain separable, able provide upper bounddefender utilities separable utilities, allowing efficient computation.Similar work Yin et al. (2012), state comprises current stationtime unit, well necessary history information starting time4 . state,unit may stay current station conduct in-station operation timeride train conduct on-train operation current time coincidestrain schedule. Due execution uncertainty, unit may end stateintended outcome action. ease analysis, assume throughout restpaper single type unexpected event delays patrol unit time beyondintended execution time. Specifically, assume fare check operation taken,probability operation delayed, i.e., staying station(for in-station operations) train (for on-train operations) involuntarilytime. Furthermore, assume units involved events unrelatedfare enforcement thus check fares delayed period operation.Intuitively, higher chance delay leads less time spent fare inspection.see Section 6, initializing probability conducting real-world experiments requiredadopting robust approach based cross-validation (Kohavi, 1995; Jaulmes, Pineau, &Precup, 2007) address uncertainty related duration delay.adversary faced riders system. Specifically, modelcommon type riders use metro line every day go work comeback home. takes fixed route: starts specific station (at specifictime) ends new station B (at new time). Since exists multiple stationstime units, also exist multiple routes considered. address issue, define4. Interested readers encouraged read work Yin et al. (2012) details338fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintymultiple riders representing specific route. rider observes likelihoodchecked makes binary decision buying buying ticket. ridertype buys ticket, pays fixed ticket price . Otherwise, rides trainfree risks chance caught paying fine > . LASDs objectiveset maximize overall revenue whole system including ticket sales finecollected, essentially forming zero-sum game. revenue depends numberresources available LASD, i.e., ones deployed patrol5 . Givennumber available officers then, costs associated deployment (e.g., numberofficers working hours) incorporated objective function definingnegative rewards Equation 8.Since fare check operation performed determined actual transition ratheraction taken, define effectiveness transition (s, a, ) rider type, f (s, a, ), percentage riders type checked transition (s, a, ). Followingargument Yin et al. (2012), assume probability joint completetrajectory detects evader sum f transitions = (t1 , . . . , ) cappedone:XXPr(t, ) = min{f (si , ai , si )(ti , si , ai , si ), 1}.(14)i=1 si ,ai ,sitype joint trajectory t, LASD receives rider buys ticketPr(t, ) otherwise. utilities domain indeed separable even thoughmultiple units (or even single unit) may detect fare evader multiple times, evaderfined once. result, neither players utilities computed directly usingmarginal probabilities x w. Instead, provide upper bound defender utilityoverestimating detection probability following:\) =Pr(t,XXf (si , ai , si )(ti , si , ai , si ) Pr(t, ).(15)i=1 si ,ai ,si\),defender utility rider buy ticket upper-bounded Pr(t,separable. Given marginal vector x, detection probability upperboundedXX\Pr(x, ) =f (si , ai , si )xi (si , ai , si ).(16)i=1 si ,ai ,siEquation (16) leads following upper bound LP LA Metro problem:maxx,w,us.t.Xp u +XXRi (si , ai , si )(17)i=1 si ,ai ,siconstraints (4), (5), (6), (7)\)},u min{ , Pr(x,(18)5. number resources required maximize revenue LASD equal number numberedges MDP defined Section 4. Unfortunately, real world available resourcesmuch less number. Therefore, idea maximize revenue LASD givenresources available.339fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambeprove claims following two propositions.\) upper bound true detection probability coupledProposition 5. Pr(x,strategy marginals x.Proof. Consider coupled strategy . Recall (t; ) R probabilityjoint trajectoryP X instantiated. rider type , true detection probabilityPr(, ) = tX (t; )Pr(t, ). Applying Equations (14) (3) have,Pr(, )X(t; )XXf (si , ai , si )i=1 si ,ai ,si=Xf (si , ai , si )(ti , si , ai , si )i=1 si ,ai ,sitX=XXXX(t; )(ti , si , ai , si )tX\).f (si , ai , si )xi (si , ai , si ) = Pr(x,i=1 si ,ai ,siProposition 6. LP (17) provides upper bound optimal coupled strategy.Sketch. Let x w marginal coverage u value patrollerrider type optimal coupled strategy . suffices show (x , w ,u ) feasible point LP. Lemma 1, already know x w must satisfyconstraints (4) (7). Furthermore, u since rider pays ticket\) since Pr(x,\) overestimate true detectionprice. Finally, u Pr(x,probability.Intuitively, LP (17) relaxes utility functions allowing evader fined multiple times single trip. relaxed utilities separable thus relaxedproblem efficiently solved. Since solution returned x w satisfy constraints(4) (7), construct Markov strategy w described Section 4.2.Markov strategy provides approximate solution original problem, whose actualvalue evaluated using Monte Carlo simulation. strategy also sampledproduce patrol schedule uploaded smartphone applicationdiscussed next.5.2 Smartphone Applicationsmartphone app software agent carried patrol officer visualizespatrol schedules generates using approach discussed previous section. ShownFigure 3, app provides three principal features: (i) patrol schedule currentshift; (ii) system reporting passenger violations (iii) shift statistics summaryreport. beginning shift, patrol schedule loaded app eitherhand using database. app displays schedule current upcomingpatrol actions schedule view, shown Figure 3(a). Implementing recovery340fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty(a) Schedule View(b) Reporting View(c) Summary ViewFigure 3: smartphone user interfacereal-world unexpected events interrupt officers schedule, schedule view alsoallows officer manually set current location, triggering app select newpatrol schedule based officers current location time. so, numberpatrol schedules sampled Markov strategy (see Section 4.2) uploadedapp deployment. remainder work, refer actionrequesting update. app also allows patrol officers record passenger violations,fare evasion, current patrol action using Reporting View, shown Figure3(b). Officers also view edit passenger violations reported past actionsSummary View, shown Figure 3(c). Upon shift completion, officer also useSummary View submit app-generated shift statistics summary report, includingunexpected events violations reported throughout shift, database.app presents two key advantages security agencies. First, allowscollection patrol data, could used analyze behavior adversariesfare evaders criminals. Second, app-collected data could also benefit transitsystem security departments manually record violations data conductanalysis patrol strategy performance.6. Evaluationsection describes experiments. Section 6.1, describe datasetsinstantiated model parameters experiments. Section 6.2, discussessimulations studied key properties approach discussed Section5.1. Finally, Section 6.3 discusses real-world experiment ran head-to-headcomparison approach uniform random approach, automated approachsecurity agencies use using game-theoretic approach (Tambe, 2011).341fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe6.1 Data Setsexperiments presented work, either simulation real-world, basedfour data sets, based different Los Angeles Metro Rail line: Red (includingPurple), Blue, Gold, Green. data sets, train schedules obtainedhttp://www.metro.net ridership distributions line estimatedhourly boarding alighting counts provided LASD. allowed ontrain operation, i.e., train checks could two stations defined instation operations, i.e., station-checks, fixed intervals 10 20 minutes.recommended LASD, duration one security officers typically adoptconduct fare inspections train station. effectiveness fare check operationadjusted based volume riders period assumptionunit would check three riders per minute. ticket fare set $1.5 (the actualcurrent value), fine set $100 (fare evaders Los Angeles fined $200,however, also may issed warnings). rider always pay ticket price $1.5evade ticket expected fine lower. immediate rewards Riset zero. Table 1 summarizes detailed statistics four Metro lines.LineRedBlueGoldGreenStopsTrainsDaily RidersTypes16221914433287280217149991.576906.230940.038442.626033466304191019559Table 1: Statistics Los Angeles Metro lines.6.2 Simulationssimulations aimed analyze performance Markov strategies calculatedsolving LP defined Section 5.1. specifically, aim analyze key featuresapproach systematically manipulating parameters likelyvary significantly real world and, consequence, affect revenue defenderrate fare evaders captured. parameters include delay length, trainlines, levels execution uncertainty number available resources. alsotested runtime LP algorithm verify whether capable generatingoutput timely manner. result presented Red line only. ResultsBlue, Gold Green line presented Appendix A.simulations, found Markov strategy close optimalrevenue always 99% LP upper bound. Figure 4 shows result, assuming6 resources patrolling Red line 3 hours varying uncertainty probability (from 0%25%). Similar results found Blue, Green Gold lines reportedFigure 14 Appendix A. result indicated relaxed detection probabilitygiven Equation (16) provided good estimation true probability, implyingriders unlikely checked joint execution trajectories producedMarkov strategy data sets. reason, remainder342fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyFigure 4: Markov Strategy (Equation (17)) vs. true LP (Equation (8)).section report values Markov strategy without mentioning LP upperbound.experiments, compared, execution uncertainty, performanceMarkov strategy (obtained solving LP (17)) two types benchmarks: gametheoretic, deterministic, policies assuming execution uncertainty Markov policiestake execution uncertainty account, assign actions based uniformrandom probability. pre-generated schedules calculated using TRUSTS (Yin et al.,2012), original system developed patrolling train lines, based deterministicmodel assuming execution uncertainty. However, since actions take deviationsoriginal plan well-defined TRUSTS schedules, augmented pregenerated schedules two naive contingency plans indicating actions followunit deviates original plan. first plan, Abort, simply abandonentire schedule return base. second plan, Arbitrary, pick actionrandomly available actions decision point deviation. uniformrandom Markov strategy (Markov UR) assigns, given state Si MDP definedSection 3.2, uniform probability actions taken leading another stateSi . essence, strategy similar Arbitrary policy assumesresources always pick random action deviated. chosenapproach security agencies adopt using game-theoreticapproach randomization6 .strategies generated using CPLEX 12.2 barrier methodstandard 2.8GHz machines 4GB memory. Then, generate significant datapoints,strategy evaluated using Monte Carlo simulations 100000 samples.simulations, riders assumed choose best response based frequencychecked samples. discussion results follows.6. See work Tambe (2011) detail.343fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe(a) Varying uncertainty(b) Varying delayFigure 5: Defenders revenue per rider Red line: Markov vs. TRUSTS pre-generatedstrategies Markov UR6.2.1 Expected Revenue Varying Delay Probability Timerun experiment, fixed number units 6 patrol length 3 hoursvaried delay probability delay time. results presented basedsimulations Red line. Figure 15 Appendix shows results Blue,Green Gold lines.First, fixed delay time 10 minutes varied delay probability 0%25%. see Figure 5(a), Abort, Arbitrary Markov-UR performedpoorly presence execution uncertainty. increasing values , revenueAbort Arbitrary decayed much faster Markov strategy. fact,increasing delay probability, number interruptions also increased.situations, Abort Arbitrary strategies perform sub-optimal actions(dropping schedule selecting random action) yield poor performance.344fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyexample, increased 0% 25%, revenue Abort Arbitrarydecreased 75.4% 37.0% respectively Markov strategy decreased3.6%. contrast, performance ofMarkov-UR remained constantly aroundvalue of, approximately 0.4. expected, since strategy constantly performs randomactions, therefore performance independent delay probability.important observation revenue Abort decayed extremely fastincreasing even 5% probability delay, revenue Abort73.5% Markov strategy. conservative estimate 6% potential fareevaders (?) 300, 000 daily riders LA Metro Rail system, 26.5% differenceimplies daily revenue loss $6, 500 $2.4 million annually.Second, fixed 10% varied delay time 5 25 minutes. results,Figure 5(b), present similar trends ones Figure 5(a). three strategies Abort,Arbitrary Markov-UR performed worse Markov strategy. increasingdelay time, revenue Arbitrary, decayed faster rate Markov strategy.Similar discussed earlier, delay, strategy would start generate suboptimal actions would result low expected revenue. contrast, revenueAbort Markov-UR remained approximately same. timedelay matter Abort strategy resource abandon schedulefirst unexpected event. Similarly, time delay matter Markov-URresource performs random actions. delay time increased 525 minutes, revenue Abort Markov UR remained same, 0.4 0.75respectively, Arbitrary Markov strategy decreased 14.4% 3.6%respectively.Figure 6: Markov vs. deterministic strategies: evasion rate6.2.2 Fare Evasion Rate Varying Delay Probability Timesettings experiment ones experiment discussedabove. Here, present results Red line only. results Blue,Green Gold line, present similar trends shown Figure 16 AppendixA. discussed Section 6.1, considered rider prefer fare evasion345fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambeexpected penalty fare evasion lower $1.5, ticket price. resultsshown Figure 6, shows fare evasion rate four policies increasing .see, Abort, Arbitrary Markov UR showed extremely poor performanceevasion deterrence even tiny probability execution error. Similar firstexperiment, increasing number interruptions led two deterministic strategiesproduce sub-optimal actions yielding fewer number fare evaders captured. particular,delay probability increased 0% 5%, evasion rate Markovstrategy barely increased Abort Arbitrary increased 11.2%74.3% 43.9% respectively. contrast, Markov UR strategy remained stablearound fare evasion rate 80%. result confirms trend Markov URstrategy depicted Figure 5(a). delay probability affect performancestrategy consists computing random actions.20%Fare evasion rateRevenue per rider1.51.451.41.35BlueGoldGreenRed1.30 0.05 0.1 0.15 0.2 0.25Probability unexpected eventBlueGoldGreenRed15%10%5%0%0 0.05 0.1 0.15 0.2 0.25Probability unexpected event(a) Revenue per rider Markov strategy(b) Evasion rate Markov strategyFigure 7: Markov strategy different lines.6.2.3 Robustness Approach increasing Delay Probabilityrun experiment, fixed number units 6 patrol length 3 hours,varied delay probability 0% 25%. Figure 7(a) Figure 7(b) showexpected revenue per rider evasion rate four lines respectively7 .see, revenue decreased evasion rate increased increasing . However,Markov strategy able effectively allocate resources counter effect increasingterms revenue maximization evasion deterrence. example, ratiorevenue = 25% = 0% 97.2%, 99.1%, 99.9%, 95.3% Blue,Gold, Green Red line respectively. Similarly, increased 0% 25%,evasion rate Blue, Gold, Green Red line increased 4.6, 1.9, 0.1, 5.2percentage points respectively. Thus, Markov strategy performance degraded gracefullyuncertainty increased four lines.7. revenue Red line significantly lower lines fare check effectivenessf defined Section 5.1 set inversely proportional ridership volume.346fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyRevenue per rider1.51.3LowMediumHigh1.10.90.70 0.05 0.1 0.15 0.2 0.25Probability unexpected eventFigure 8: Revenue decay varying coverage levels6.2.4 Revenue per Rider Increasing Delay Probabilityexperiment, considered 3, 6 9 patrol units, representing three levels fareenforcement: low, medium high, respectively, evaluated revenue per riderincreasing . results red line depicted Figure 8. Results blue,green gold line present similar trends depicted Figure 17Appendix A. shown Figure 8, rate revenue decay respect decreasedincreased level fare enforcement low high. Intuitively,resources, defender could better afford time spent handling unexpected eventswithout sacrificing overall revenue. example, increased 0% 25%,revenue drop low, medium high enforcement setting 13.2%, 4.7%,0.4% respectively.Revenue per rider1.41.21= 0%= 10%= 20%0.80.62345Number patrol units6Figure 9: Revenue per rider increasing coverage347fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe6.2.5 Revenue per Rider Increasing Number ResourcesRuntime(in minutes)experiment, fixed patrol length 3 hours, considered three delayprobabilities = 0%, 10%, 20%, representing increasing level uncertainty.measure impact number units, increased number units 26. results Red line shown Figure 9, Figure 18 Appendix showsresults Blue, Green Gold lines. figures show revenue per riderdefender increasing number units. depicted figure, increasednumber, revenue increased towards maximal achievable value $1.5 (ticketprice). number resources increases, algorithm produces Markov strategiesdistribute resources check rider types. example, shownfigure, = 10%, revenue per rider $0.65, $1.12, $1.37 2, 4, 6patrol units respectively. addition, figure shows uncertainty increases,revenue per rider slightly decays. example, considering 4 units, revenue per rider1.09, 1.13 1.18 = 0%, 10% 20% respectively.60Blue5448Gold42Green36Red30241812600 0.05 0.1 0.15 0.2 0.25Probability unexpected eventFigure 10: Worst-case LP runtime6.2.6 Runtime LP Algorithmconfirm hypothesis, ran experiment considering worst-case runtime (over10 runs) LP increasing four metro lines. number unitsfixed 3 patrol length per unit fixed 3 hours. verify whether delayprobability impact runtime, ran simulations varying 0% 25%.results depicted Figure 10. see, algorithm could solveproblems within hour. example, = 10%, runtime Blue, Gold,Green, Red line 14.0, 24.3, 2.4, 4.3 minutes respectively.addition, results present number additional features analyzed.runtime varied among four Metro lines, related number statestypes. words, number stations daily trains (i.e. density trainschedule) affected runtime algorithm. example, since Green linesignificantly fewer types states, solving LP easier three lines.348fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintysurprising result fact found correlation runtimedelay probability . results showed that, four lines, stochastic models> 0% took less time solve deterministic models ( = 0%). precisely,increasing beyond 0%, runtime four lines fluctuated showed upwards trend, yet correlation runtime delay probability statisticallysignificant.6.3 Real-World Experimentresults simulations presented showed deterministic approachestake execution uncertainty account perform poorly. Given large numberinterruptions, officers rarely able complete schedule provided deterministicstrategies. discussed Section 1, results motivated work led newsolution concept based MDP. addition, considering limited timegiven LASD run experiment, decided use Markov UR strategybenchmark real world experiment. Real-world failure acceptableLASD. Therefore, recommended testing deterministic schedules further.addition, despite performing poorly simulation, Markov UR strategyused security agencies automatically allocate resources, schedulesupdated whenever interruption occurs.real world experiment took place 21 days months JulyAugust 2013. organization experiment (e.g., train security officers, designorganize experiment collaboration LASD) required approximately twoweeks. experiment two key purposes. first validate MDP modelreal world. second run head-to-head comparison gametheoretic approach Markov-UR approach. section discusses setupexperiment results obtained.6.3.1 Experiment Setupfare evasion experiment took place Blue line LA Metro system (see Figure11 map metro line). lines could tested, LASDallowed us use strategies Blue line real-world test. lineconsists 22 different stations one biggest lines LA Metro system.selected LASD, helped organize experiment (e.g., assign securityofficers patrol times).day, team two security officers (see Figure 12), randomly selectedLASD, patrol line duration 120 minutes. Patrols runmorning afternoon. days tests ended early due officersreassigned. One two officers acted leader team: givensmartphone, read schedule officers, collect dataeventually update whenever delay occurred. update could made eitherstation-check described Section 6.1) train-check. latter case,officers required leave train next station request update.required because, discussed Section 5.1, Markov strategy defined349fiDelle Fave, Jiang, Yin, Zhang, Kraus, & TambeFigure 11: map blue line LA MetroFigure 12: Two security officers performing fare checks train.state MDP (i.e., station, time). Thus new strategy sampledspecific state. Every week team provided one two types schedules:Game-theoretic schedules (GT): type schedule generated accordingLP Equation (17) presented Section 5.1.Markov UR schedules (UR): type schedule generated modelingproblem MDP, discussed Section 3.2. However, corresponding Markovstrategy si ,ai , state si action ai calculated assuming uniformprobability distribution.officers told schedule using bias performance. experiment, anticipated officers might view350fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyschedules leading low performance terms catching fare evaders.situation, officers, order avoid poor performance, might end voluntarily deviating given schedules reach better location unsatisfiedcurrent one. anticipation voluntary deviations, augmentedgame-theoretic UR schedules ability perform updates. specifically,allowed officers request VOLUNTARY INVOLUNTARY updates. VOLUNTARYupdates consisted officers updating current schedule opinion,current specified action fruitful venue check fares. Officers allowedchoose new location considered fruitful catching fare evadersrequest new schedule there. INVOLUNTARY updates consisted officers requesting new schedule delayed (e.g., issuing citations arrestingsuspect) unable perform next action schedule. typeupdate could requested anytime officer delayed. see officersused VOLUNTARY updates almost every day UR schedules, never GTschedules.Finally, important notice given duration experiment, gametheoretic schedules essentially testing maximin strategy. discussed Section5.1, LP computes Stackelberg strategy, strategy based assumptionriders conduct surveillance observe defenders mixed strategy. However,considering 21 days patrol whereby officers could patrol lesshours per day, either morning afternoon, cannot assume riderssufficient time conduct accurate surveillance, observe mixed strategy bestrespond it. Nonetheless, LP Section 5.1 solves zero-sum gameStackelberg equilibrium maximin strategy known equivalent (Yin et al.,2012). Thus, since maximin strategy provides guaranteed level defender utilitywithout making assumption adversarys surveillance defenders mixedstrategy, experiments compare benefit using maximin strategy(non-game-theoretic) approaches generating patrol schedules.6.3.2 Estimating Uncertainty ParameterGiven unpredictability real-world, two key parameters instantiatingMDPthe length delay and, importantly, probability delaycould happen could defined before-hand, done Section 6.1 remaining problem parameters. setting, adopting continuous-time MDP couldpossible alternative. However, continuous time MDP algorithms, involve techniquesforward search (Marecki & Tambe, 2008; Mausam, Benazera, Brafman, Meuleau,& Hansen, 2005), would appear difficult implement would add significant computational complexity. Another alternative, one adopted work, adopt crossvalidation approach, well-known technique used machine learning (Jaulmes et al., 2007)statistics (Kohavi, 1995). idea select policy robust uncertainty, i.e.,policy guarantees highest expected revenue worst case setting,uncertainty minimize defenders expected utility. achieve this, discretizeddelays defined MDP model assumed multiple delays, specificprobability. divided approach two steps. First, randomly generated N351fiDelle Fave, Jiang, Yin, Zhang, Kraus, & TambeGTURD16060D26060D39060D46060D59060D61075D790100D8110100D990100D109090D11105total855765Table 2: Patrol duration 21 days.MDPs. MDP generated assuming delay happen within time window30 minutes. words, assume resource experience delays 30minutes (any delay longer 30 minutes considered beyond repair newschedule generated). time window divided five different time intervals:[0, 6], [6, 12], [12, 18], [18, 24] [24, 30] minutes one delay sampled interval. essence, process discretizes unknown delay length 5 possible delaysdistributed within 30 minutes time window.Second, solve MDP-based patrolling game using LP Section 5.1.doing, obtain N Markov policies ik corresponding DP k . Next, crossvalidate policy ik DPk k 6= k , i.e., calculate expectedrevenue policy ik generates evaluated DP k . expectedrevenue calculated running 100000 Monte Carlo simulations. simulation consistssampling one policy defender calculate resulting expected utilityN MDPs. end simulations, obtain N N matrix rowsrepresented policies ik columns represent N MDPs. cell (k, k )matrix contains expected revenue obtained evaluating policy ik DP k .Then, policy deploy selected using maximin strategy. detail,chose policy maximizing expected utility worst case scenario, i.e.considering MDP yielding lowest expected utility among different MDPs.practical perspective, policy obtained earlier might yield schedulerepresent exactly delays might happen patrol. However,modelling five different delays, schedules able cover larger rangedelays. Hence, whenever officer interrupted requests update, smartphoneapplication simply search schedule state best matches officer currentlocation time present new list actions starting there.6.3.3 Results21 weekdays experiments, able run GT schedules 11 daystesting UR schedules deployed 10 days, resulting 855 765 patrolminutes, respectively. schedules compared using two different metrics. First,counted number passengers checked number captures endpatrol. captures defined sum number warnings, citations,arrests. Passengers without valid ticket could given warning cited violationdiscretion officer. metric chosen would allow us measureperformance schedule real world. Second, counted number timesupdate function used voluntarily involuntarily. involuntary updateshelped determine value using MDPs discussed below, voluntary updates measured352fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyGTURD100D212D331D411D511D602D722D822D943D1022D111total1816Table 3: Number INVOLUNTARY (delays) deviations day patrolGTURD101D200D301D401D501D600D701D801D901D1001D110total08Table 4: Number VOLUNTARY (updates) deviations day patrolhuman (officer) perception quality schedules voluntary updates,officers dissatisfied given action. Table 2 shows durationday patrol GT UR schedules8 .shown table, actual duration daily patrol often different21 days experiment, GT UR schedules. reason, providingcomparison normalized days experiment impossible. However,days, able collect data multiples 30 minutes (e.g., 60, 90 minutes).Hence, properly compare results, divided data 30 minutes segments.specifically, considered train station checks within time window 30minutes collected data resulting actions9 . defined datapoints, proceed analyze results.Validation MDP model: discussed beginning section GTUR schedules calculated solving MDP. reason schedules couldupdated request new schedule. Tables 3 4 show, day patrol,number VOLUNTARY INVOLUNTARY deviations requested officers.total, GT schedules updated 18 times, involuntary deviations,i.e., delays. update requests confirm MDP model able provideschedules could updated whenever necessary.INVOLUNTARY deviations due officers writing citations helpingpeople. average delay length 12 minutes (the largest delay 20 minutes).case, discussed beginning section, new schedule providedstarting officers current location closest time. Finally, Table 4 showsvoluntary deviations used UR schedules. result strongly suggestsofficers mostly satisfied GT schedules. addition, means GT schedules8. shown Table 2, day patrol correspond 2-day test GT schedules testedfirst day UR schedules tested second, identical times.9. doing, segments also statistically independent. Within segment officers checkdifferent people unable affect other. segment corresponds sample differenttrain riders taken different times locations. officers never check ridertwice importantly, 30 minutes, visit different locations riding trains(roughly, one train every 6 minutes blue line) inspecting stations (on-station operationslast longer 20 minutes).353fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe(a) Captures(b) Warnings(c) Violations(d) PassengersFigure 13: Results Fare Evasion testsreally compete UR schedules only. Rather, comparison URschedules augmented real-time human intelligence time (810 days). discuss results comparison next.Game-Theory vs. Uniform Random: results obtained shownFigure 13 Table 5. Figure 13 shows eight boxplots depicting datacollected patrol, using GT UR schedules. Respectively, fourfigures present data collected captures (Figure 13(a)), warnings (Figure 13(b)), violations(Figure 13(c)), passengers checked (Figure 13(d)) per 30 minutes patrolling10 .boxplot, top bottom box represent 75th 25th percentiles,respectively, middle line indicates median collected data. +data points indicate statistical outliers, whiskers show extreme nonoutlier data points. four figures (captures, warnings, violations passengerschecked) shows data collected using GT schedules higher valuesdata collected using UR schedules. shown Table 5, average, GT schedules ledto, respectively 15.52 captures, 10.42 warnings 5.03 violations issued every 30 minutesagainst, respectively 9.55 captures, 6.48 warnings 3.07 violations obtained usingUR schedules. confirm statistical significance results, ran numberweighted unpaired student t-tests (p = 0.05) (Goldberg, Kercheval, & Lee, 2005; Bland &Kerry, 1998) verified, metric, difference results statisticallysignificant. used weighted t-test data segments duration shorter30 minutes wanted use available data analysis. shownTable 2, patrol durations could properly divided finite number30 minutes segments (e.g., UR: D6, D7, D8, D9 GT: D6, D8, D11). Therefore,10. GT schedules also led two arrests day 6. patrol lasted 10 minutes.354fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyGTURDays1110avg. C15.529.55avg. W10.426.48avg. V5.033.07avg. P96.7760.85Table 5: Average captures (C), warnings (W), violations (V) passengers (P) basedresults obtained Figure 13calculated weighted average metric defined above, whereby segmentgiven weight defined based segments duration (longer segmentscorresponded higher weights).practical perspective, magnitude difference two approaches significant: cumulatively period 21 days GT would capture muchlarger total number fare evaders. result emphasized even correlate results shown Tables 4 3. running UR schedules officersrequesting INVOLUNTARY deviations essentially every day, whereas deviations requested running GT schedules. words, using real-timesituation awareness augment quality schedules, thus making UR schedulecompelling.results Table 5 also indicate GT schedules led 96.77 passengers checkedevery 30 minutes 60.85 passengers checked using UR schedules. discussedSection 5.1, GT schedules generated leveraging possible sequences trainstation checks taking account key dimensions discussed Section6.1, including train schedules, officers effectiveness and, importantly dailyridership statistics. means stations trains higher presence ridersgiven higher coverage probability since likely contain fare evaders.Hence, results confirm accuracy model Figure 13(d) Table 5show GT schedules led officers check passengers UR schedules.raises question whether static type schedule, deploysofficers crowded locations, would lead similar even better resultsobtained GT. Given limited amount time conductexperiments, unable compare GT schedules static deploymentkey weakness predictability longer term. Indeed, effective randomizationone main reasons LASD collaborate experiments security agenciesknow static schedules become predictable long term11 . certain amounttime, passengers would know officers located could exploitinformation avoid paying fare.7. Summary Future Workpaper addressed dynamic execution uncertainty security resources allocation.specifically, paper presented four main contributions. First, proposed generalBayesian Stackelberg game model security patrolling whereby execution uncertainty11. Tambe (2011) discusses benefits randomization detail.355fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambehandled via Markov decision process (MDP). Second, studied problem computingStackelberg equilibrium (SSE) game showed exploiting structuregames utility functions, could represent defenders strategy space compactform could efficiently solved using canonical algorithms solving Bayesian SSGs.addition, showed always possible generate mixed strategypolynomially-sized support. Third, ran number simulations whereby testedframework within various different settings. key result modeling executionuncertainty MDP, able generate policies overcame failuresexisting SSG algorithms take uncertainty account. Finally,fourth contribution, ran real-world experiment whereby compared schedulesgenerated using approach competing schedules comprised random scheduleraugmented officers providing real-time knowledge current situation. resultssupported MDP-based model actually able show usecontingency plans provided MDP real-world. addition, results showedgame-theoretic schedules outperformed competing schedules, despite factlatter improved real-time knowledge. doing, results constituteone first examples potential employing algorithmic game theory solvereal-world security allocation problems.terms future work, exist number challenges left address. One interesting technical challenge addressing adjustable autonomy (Huber, 1999; Scerri,Pynadath, & Tambe, 2002) mixed initiative planning (Ferguson, Allen, & Miller, 1996)context game theoretic scheduling. experiments showed officers mightdeviate schedule perceive might lead poor performance termsfare evaders captured. Hence, would interesting augment schedules takepossibility account. specifically, could extend game theoretic model described Section 3 account possibility officers would eventually deviateschedules execute action based real-time situational awareness.One interesting empirical challenge would run long-term controlled experiment(e.g., one year) complementary one present paper. idea wouldmeasure riders react game-theoretic scheduling. discussed Section 6.3,given practical difficulties related running real-world security experiments, securityagencies LASD typically prefer avoid running long term experimentswould interfere every-day security transit system. Nonetheless,could done, experiment would provide valuable insight effectsSSGs real-world.Acknowledgementsarticle product joint work Francesco M. Delle Fave Albert X. Jiang.first authors work.terms contributions, article extends paper Jiang, Yin, Zhang, Tambe,Kraus (2013). work, extend initial version following contributions: (i) present new theoretical result, whereby show always calculateoptimal mixed strategy defender polynomially-sized support; (ii) extend simulations presented Jiang et al. (2013) evaluating approach356fiGame-Theoretic Security Patrolling Dynamic Execution Uncertaintyuniform random scheduler; (iii) present results large scale real-world experimentwhereby validate MDP-based approach defined Jiang et al. (2013) field; (iv)experiment, compare actual outcome executing schedules generatedMDP-based approach ones generated using competing uniform randomscheduler presenting first results algorithmic game theory field; (v)run real-world experiments, describe development smartphone application load visualize game-theoretic schedules sampling technique instantiatekey parameters MDP; (vi) discuss significant new related work future work.thank Los Angeles Sheriffs Department exceptional collaboration.research supported TSA grant HSHQDC-10-A-BOA19, MURI grant W911NF-11-10332 3-6797.Appendixappendix complements simulations results discussed Section 6.2, presentingresults obtained Blue, Green Gold line. Figure 14 compares,former three lines, defenders revenue per rider obtained LP (Equation (8)), i.e.,upper bound, true value obtained running 100000 Monte Carlo simulationsMarkov strategy. experiment run assuming setting discussedbeginning Section 6.2: 3 hours patrolling 6 resources.Figure 15 shows simulation results complementing ones presented Section 6.2Hypothesis 1. setting described Section 6.2: 6 resources patrollingBlue, Green Gold lines 3 hours varying 0% 25%delay time 5 25 minutes.Figure 16 shows results complementing ones presented Section 6.2 validating hypothesis 2. simulation, considered 6 resources patrolling 3 hoursfour lines varied uncertainty 0% 25%.Figure 17 shows results complementing ones presented Section 6.2 validating hypothesis 4. simulation, considered 3, 6 9 resources representing 3levels coverage, low, medium high respectively. evaluated revenue perrider varying delay probability 0% 25%.Figure 18 shows results complementing ones presented Section 6.2 validating hypothesis 5. simulation, considered different delay probabilities (0%, 10%20%) evaluated revenue per rider varying number patrol units 26.357fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe(a) Blue line(b) Green line(c) Gold lineFigure 14: Markov Strategy (Equation (17)) vs. true LP (Equation (8))Blue, Green Gold lines358fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty(a) Blue line(b) Green line(c) Gold lineFigure 15: Defenders revenue per rider Blue, Green Gold line, varyinguncertainty delay time.359fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe(a) Blue line(b) Green line(c) Gold lineFigure 16: Fare evasion rate Blue, Green Gold lines varying delay probability360fiGame-Theoretic Security Patrolling Dynamic Execution Uncertainty(a) Blue line(b) Green line(c) Gold lineFigure 17: Revenue per rider Blue, Green Gold lines different allocationresources361fiDelle Fave, Jiang, Yin, Zhang, Kraus, & Tambe(a) Blue line(b) Green line(c) Gold lineFigure 18: Revenue per rider Blue, Green Gold lines three levels delayprobability362fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyReferencesAgmon, N., Kaminka, G. A., & Kraus, S. (2011). Multi-robot adversarial patrolling: facingfull-knowledge opponent. Journal Artificial Intelligence Research (JAIR), 42 (1),887916.Agmon, N., Kraus, S., & Kaminka, G. A. (2008a). Multi-robot perimeter patrol adversarial settings. Proceedings International Conference RoboticsAutomation (ICRA), pp. 23392345. IEEE.Agmon, N., Sadov, V., Kaminka, G., & Kraus, S. (2008b). impact adversarialknowledge adversarial planning perimeter patrol. Proceedings Seventh International Joint Conference Autonomous Agents Multiagent Systems(AAMAS), pp. 5562.An, B., Kempe, D., Kiekintveld, C., Shieh, E., Singh, S., & Tambe, M. (2012). Securitygames limited surveillance. Proceedings AAAI Conference ArtificialIntelligence (AAAI), pp. 12411247.An, B., Tambe, M., Ordonez, F., Shieh, E., & Kiekintveld, C. (2011). Refinement strongStackelberg equilibria security games. Proceedings Twenty-Fifth Conference Advancement Artificial Intelligence (AAAI), pp. 587593.Aoyagi, M. (1996). Reputation dynamic Stackelberg leadership infinitely repeatedgames. Journal Economic Theory, 71 (2), 378 393.Archibald, C., & Shoham, Y. (2011). Hustling repeated zero-sum games imperfectexecution. Proceedings Twenty-second International Joint ConferenceArtificial Intelligence (IJCAI), pp. 3136.Basilico, N., Gatti, N., & Amigoni, F. (2009a). Leader-follower strategies robotic patrolling environments arbitrary topologies. Proceedings Eight International Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp.5764.Basilico, N., Gatti, N., Rossi, T., Ceppi, S., & Amigoni, F. (2009b). Extending algorithmsmobile robot patrolling presence adversaries realistic settings.Proceeding Conference Intelligence Agent Technology (IAT), pp. 557564.Basilico, N., Gatti, N., & Villa, F. (2010). Asynchronous multi-robot patrolling intrusions arbitrary topologies. Proceeding Conference AdvancementArtificial Intelligence (AAAI), pp. 345350.Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2004). Solving Transition Independent Decentralized Markov Decision Processes. JAIR.Bland, M. J., & Kerry, S. M. (1998). Weighted comparison means. BMJ: British MedicalJournal, 316, 125129.Booz Allen Report (2007). Faregating analysis. Tech. rep., Booz Allen Hamilton Company. Report commissioned LA Metro, http://boardarchives.metro.net/Items/2007/11_November/20071115EMACItem27.pdf.Bowling, M., & Veloso, M. (2004). Existence multiagent equilibria limited agents.Journal Artificial Intelligence Research (JAIR), 22, 353384.363fiDelle Fave, Jiang, Yin, Zhang, Kraus, & TambeBrown, A., Camerer, C. F., & Lovallo, D. (2012). review review? limited strategic thinking movie box office. American Economic Journal: Microeconomics,4 (2), 126.Clarke, R. V. (1993). Fare evadion automatic ticket collection london underground. Crime Prevention Studies, 1, 135146.Clarke, R. V., Contre, S., & Petrossian, G. (2010). Deterrence Fare Evasion: ResultsNatural Experiment. Security Journal.Conitzer, V. (2012). Computing game-theoretic solutions applications security.Proceedings AAAI Conference Artificial Intelligence (AAAI), pp. 21062112.Conitzer, V., & Sandholm, T. (2006). Computing optimal strategy commit to.EC: Proceedings ACM Conference Electronic Commerce.Dickerson, J. P., Simari, G. I., Subrahmanian, V. S., & Kraus, S. (2010). graph-theoreticapproach protect static moving targets adversaries. ProceedingsNinth International Joint Conference Autonomous Agents Multiagent Systems,pp. 299306.Fang, F., Jiang, A., & Tambe, M. (2013). Protecting moving targets multiple mobileresources. Journal Artificial Intelligence Research (JAIR), 48, 583634.Ferguson, G., Allen, J., & Miller, B. (1996). Trains-95: Towards mixed-initiative planningassistant. Proceedings 3rd Conference Artificial Intelligence PlanningSystems (AIPS), pp. 7077.Filar, J., & Vrieze, K. (1996). Competitive Markov Decision Processes. Springer.Gatti, N. (2008). Game theoretical insights strategic patrolling: Model algorithmnormal form. Proceedings European Conference Artificial Intelligence(ECAI), pp. 403407.Goldberg, L. R., Kercheval, A. N., & Lee, K. (2005). t-statistics weighted meanscredit risk modeling. Journal Risk Finance, 6 (4), 349365.Grotschel, M., Lovasz, L., & Schrijver, A. (1981). ellipsoid method consequencescombinatorial optimization. Combinatorica, 1 (2), 169197.Gruber, P. M. (2007). Convex Discrete Geometry. Springer.Huber, M. J. (1999). Considerations flexible autonomy within bdi intelligent agent architectures. Proceedings AAAI Conference Artificial Intelligence (AAAI),pp. 431438.Jain, M., Kardes, E., Kiekintveld, C., Tambe, M., & Ordonez, F. (2010). Security gamesarbitrary schedules: branch price approach. AAAI.Jaulmes, R., Pineau, J., & Precup, D. (2007). formal framework robot learningcontrol model uncertainty. Proceedings International ConferenceRobotics Automation (ICRA), pp. 21042110. IEEE.Jiang, A. X., Yin, Z., Zhang, C., Tambe, M., & Kraus, S. (2013). Game-theoretic randomization security patrolling dynamic execution uncertainty. ProceedingsTwelfth International Conference Autonomous Agents Multiagent Systems,pp. 207214.364fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyKohavi, R. (1995). study cross-validation bootstrap accuracy estimationmodel selection. Proceedings Fourteenth International Joint ConferenceArtificial Intelligence (IJCAI), pp. 11371143.Korzhyk, D., Conitzer, V., & Parr, R. (2011a). Security games multiple attackerresources. Proceedings Twenty-second International Joint ConferenceArtificial Intelligence (IJCAI), pp. 273279.Korzhyk, D., Conitzer, V., & Parr, R. (2011b). Solving stackelberg games uncertainobservability. Proceedings Tenth International Conference AgentsMulti-agent Systems (AAMAS), pp. 10131020.Letchford, J., & Conitzer, V. (2013). Solving security games graphs via marginal probabilities. Proceedings AAAI Conference Artificial Intelligence (AAAI),pp. 591597.Letchford, J., & Vorobeychik (2013). Optimal interdiction attack plans. ProceedingsTwelfth International Conference Autonomous Agents Multi-agent Systems(AAMAS)., pp. 199206.Letchford, J., & Conitzer, V. (2010). Computing optimal strategies commitextensive-form games. Proceedings ACM Conference Electronic Commerce (EC), pp. 8392.Letchford, J., MacDermed, L., Conitzer, V., Parr, R., & Isbell, C. L. (2012). Computingoptimal strategies commit stochastic games. Proceedings AAAIConference Artificial Intelligence.Marecki, J., & Tambe, M. (2008). Towards faster planning continuous resourcesstochastic domains. Proceedings AAAI Conference Artificial Intelligence(AAAI), No. 10491055.Mausam, Benazera, E., Brafman, R. I., Meuleau, N., & Hansen, E. A. (2005). Planningcontinuous resources stochastic domains. Proceedings NineteenthInternational Joint Conference Artificial Intelligence, pp. 12441250.Nguyen, T. H., Yang, R., Azaria, A., Kraus, S., & Tambe, M. (2013). Analyzingeffectiveness adversary modeling security games. Proceedings AAAIConference Artificial Intelligence (AAAI), pp. 718724.Ostling, R., Wang, J., Tao-yi, J., Chou, E. Y., & Camerer, C. F. (2011). Testing game theoryfield: Swedish lupi lottery games. American Economic Journal: Microeconomics,3 (3), 133.Paruchuri, P., Pearce, J. P., Marecki, J., Tambe, M., Ordonez, F., & Kraus, S. (2008a).Playing games security: efficient exact algorithm Bayesian Stackelberggames. AAMAS.Paruchuri, P., Pearce, J. P., Marecki, J., Tambe, M., Ordonez, F., & Kraus., S. (2008b).Playing games security: efficient exact algorithm solving bayesian stackelberg games. Proceedings Seventh International Conference AutonomousAgents Multiagent Systems (AAMAS), pp. 539547.365fiDelle Fave, Jiang, Yin, Zhang, Kraus, & TambePita, J., Jain, M., Western, C., Portway, C., Tambe, M., Ordonez, F., Kraus, S., & Paruchuri,P. (2008). Deployed ARMOR protection: application game theroetic modelsecurity los angeles international airport. Proceedings SeventhInternation Conference Autonomous Agents Multi-Agent Systems (AAMAS).Pita, J., Tambe, M., Kiekintveld, C., Cullen, S., & Steigerwald, E. (2011). GUARDS game theoretic security allocation national scale. Proceedings TenthInternational Conference Autonomous Agents Multi-Agent Systems (AAMAS),pp. 3744.Scerri, P., Pynadath, D. V., & Tambe, M. (2002). Towards adjustable autonomyreal-world. Journal Artificial Intelligence Research (JAIR), 17, 171228.Shieh, E., An, B., Yang, R., Tambe, M., Baldwin, C., DiRenzo, J., Maule, B., & Meyer, G.(2012). Protect: deployed game theoretic system protect ports unitedstates. AAMAS.Sless, E., Agmon, N., & Kraus, S. (2014). impact adversarial knowledge adversarial planning perimeter patrol. Proceedings Thirteenth InternationalConference Autonomous Agents Multi-Agent Systems (AAMAS), p. press.Tambe, M. (2011). Security Game Theory: Algorithms, Deployed Systems, LessonsLearned. Cambridge University Press.Tsai, J., Rathi, S., Kiekintveld, C., Ordonez, F., & Tambe, M. (2009). IRIS - toolstrategic security allocation transportation networks. Proceedings EightInternational Conference Autonomous Agents Multi-Agent Systems (AAMAS),pp. 831839.Vanek, O., Jakob, M., Lisy, V., Bosansky, B., & Pechoucek, M. (2011). Iterative gametheoretic route selection hostile area transit patrolling. ProceedingsTenth International Conference Autonomous Agents Multi-Agent Systems(AAMAS), pp. 12731274.Varakantham, P., Lau, H. C., & Yuan, Z. (2013). Scalable randomized patrolling securingrapid transit networks. Proceedings Conference Innovative ApplicationsArtificial Intelligence (IAAI), pp. 15631568.Vorobeychik, Y., & Singh, S. (2012). Computing stackelberg equilibria discountedstochastic games. Proceedings AAAI Conference Artificial Intelligence(AAAI), pp. 14781484.Weidner, R. R. (1996). Target-hardening new york city subway station: Decreased fareevasion price?. Crime Prevention Studies, 6, 117132.Yang, R., Kiekintveld, C., Ordonez, F., Tambe, M., & John, R. (2011). Improving resourceallocation strategy human adversaries security games. ProceedingsInternational Joint Conference Artificial Intelligence (IJCAI), pp. 458464.Yin, Z., Jiang, A., Johnson, M., Tambe, M., Kiekintveld, C., Leyton-Brown, K., Sandholm,T., & Sullivan, J. (2012). Trusts: Scheduling randomized patrols fare inspectiontransit systems. Proceedings Conference Innovative ApplicationsArtificial Intelligence (IAAI), pp. 5972.366fiGame-Theoretic Security Patrolling Dynamic Execution UncertaintyYin, Z., Jain, M., Tambe, M., & Ordonez, F. (2011). Risk-averse strategies securitygames execution observational uncertainty. Proceedings AAAIConference Artificial Intelligence (AAAI), pp. 758763.Yin, Z., & Tambe, M. (2012). unified method handling discrete continuous uncertainty Bayesian stackelberg games. Proceedings Eleventh InternationalConference Autonomous Agents Multiagent Systems (AAMAS), pp. 234242.367fiJournal Artificial Intelligence Research 50 (2014)Submitted 10/13; published 05/14Decision-Theoretic Model AssistanceAlan FernAFERN @ EECS . OREGONSTATE . EDUSchool EECS, Oregon State University, Corvallis, USASriraam NatarajanNATARASR @ INDIANA . EDUSoIC, Indiana University, Bloomington, USAKshitij JudahJUDAHK @ EECS . OREGONSTATE . EDUSchool EECS, Oregon State University, Corvallis, USAPrasad TadepalliTADEPALL @ EECS . OREGONSTATE . EDUSchool EECS, Oregon State University, Corvallis, USAAbstractgrowing interest intelligent assistants variety applications sortingemail helping people disabilities daily chores. paper, formulateproblem intelligent assistance decision-theoretic framework, present theoreticalempirical results. first introduce class POMDPs called hidden-goal MDPs (HGMDPs),formalizes problem interactively assisting agent whose goal hidden whoseactions observable. spite restricted nature, show optimal action selectionHGMDPs PSPACE-complete even deterministic dynamics. introducerestricted model called helper action MDPs (HAMDPs), sufficient modeling manyreal-world problems. show classes HAMDPs efficient algorithms possible.interestingly, general HAMDPs show simple myopic policy achieves nearoptimal regret, compared oracle assistant knows agents goal. introducesophisticated versions policy general case HGMDPs combinenovel approach quickly learning agent assisted. evaluate approachtwo game-like computer environments human subjects perform tasks, real-worlddomain providing assistance folder navigation computer desktop environment.results show three domains framework results assistant substantially reducesuser effort modest computation.1. IntroductionPersonalized AI systems interactively assist human users received significant attention recent years (Yorke-Smith, Saadati, Myers, & Morley, 2012; Lieberman, 2009; Myers, Berry,Blythe, Conleyn, Gervasio, McGuinness, Morley, Pfeffer, Pollack, & Tambe, 2007). However,overarching formal framework interactive assistance captures different systemsprovides theoretical foundation largely missing. paper address lacuna introducing general framework decision-theoretic assistance, analyzing problem complexitydifferent assumptons, proposing different heuristic solutions, evaluating effectiveness.consider model assistant observes goal-oriented agent must select assistiveactions order best help agent achieve goals. real applications, requiresassistant able handle uncertainty environment agent, reason varyingc2014AI Access Foundation. rights reserved.fiF ERN , NATARAJAN , J UDAH , & TADEPALLIaction costs, handle unforeseen situations, adapt agent time. considerdecision-theoretic model, based partially observable Markov decision processes (POMDPs),naturally handles features, providing formal basis designing intelligent assistants.first contribution work formulate problem selecting assistive actionsclass partially observable Markov decision processes (POMDPs) called Hidden Goal MDPs(HGMDPs), jointly models application environment along agents policyhidden goals. key feature approach explicitly reasons environmentagent, provides potential flexibility assisting ways unforeseen developernew situations encountered. Thus, developer need design hand-coded assistivepolicy preconceived application scenario. Instead, using framework, burdendeveloper provide model application domain agent, alternativelymechanism learning one models experience. framework usesmodels attempt compute, situation, whether assistance could beneficialassistive action select.second contribution work analyze properties formulation. Despiterestricted nature HGMDPs, complexity determining HGMDP finite-horizonpolicy given value PSPACE-complete even deterministic environments. motivatesrestricted model called Helper Action MDP (HAMDP), assistant executes helperaction step. agent obliged accept helper action helpful goalreceives reward bonus (or cost reduction) so. Otherwise, agent continuepreferred action without reward penalty assistant. show classesproblem complete PSPACE NP. also show class HAMDPsdeterministic agents polynomial time algorithms minimizing expected worstcase regret relative oracle assistant knows goal agent. Further, showoptimal worst case regret characterized graph theoretic property called tree rankcorresponding all-goals policy tree computed linear time.principle, given HGMDP, one could apply POMDP solver order arrive optimalassistant policy. Unfortunately, relatively poor scalability POMDP solvers often force usutilize approximate/heuristic solutions. particularly true assistant continuallylearning updated models agent and/or environment, results sequenceaccurate HGMDPs, needs solved. third contribution work setmyopic action selection mecahnisms approximate optimal policy. HAMDPs,analyze myopic heuristic show regret upper bounded entropygoal distribution HAMDPs. Furthermore give variant policy ableachieve worst-case expected regret logarithmic number goals withoutprior knowledge goal distribution. also describe two approaches basedcombination explicit goal estimation, myopic heuristics, bounded searchgenerally applicable HGMDPs.order approach useful, HGMDP must incorporate reasonably accurate model agent assisted. fourth contribution work describe novelmodel-based bootstrapping mechanism quickly learning agent policy, importantusability assistant early lifetime. main idea assume agentclose rational decision-theoretic sense, motivates defining prior agent policiesplaces higher probability policies closer optimal. prior combination72fiA ECISION -T HEORETIC ODEL SSISTANCEBayesian updates allows agent model learned quickly rationality assumptionapproximately satisfied.final contribution work evaluate framework three domains. Firstconsider two game-like computer environments human subjects. results domainsshow assistants resulting framework substantially reduce amount workperformed human subjects. also consider realistic domain, folder navigator(Bao, Herlocker, & Dietterich, 2006) Task Tracer project. domain, user navigatesdirectory structure searching particular location open save file, unknownassistant. job assistant predict users destination folder take actionsprovide short cuts reach it. results show generic assistant framework comparesfavorably hand-coded solution Bao et al.remainder paper organized follows. next section, introduce formal problem setup terms HGMDPs, followed analysis computational complexityguarantees myopic heuristics case HAMDPs. Next, present approximate solution approach general HGMDPs based goal estimation online action selection. Finallygive empirical evaluation approach three domains conclude discussionrelated future work.2. Hidden Goal Markov Decision ProcessesThroughout paper refer entity attempting assist agentassisting entity assistant. consider episodic problem setting beginningepisode agent begins world state selects goal finite set possiblegoals. goal set, example, might contain possible dishes agent might interestedcooking, possible destination folders agent may possibly navigate to. Importantly, assistant fully observe world state agents actions, cannot observegoal agent. model interaction agent assistant sequentialagent assistant alternate turns, taking single action per turn (possibly noop).1 episodeends either agents assistants action leads goal state. immediate rewardaccumulated action episode. total reward episode equalsum rewards obtained episode. Note available actions agentassistant need may varying rewards. Since assistant agentshare objective, rewards viewed perspective agent. objectiveassistant behave way maximizes expected total reward episode.formally, model interaction via Hidden Goal Markov Decision Processes(HGMDPs). HGMDP MDP goal user observed restenvironment completely observed. HGMDP tuple hS, G, A, A0 , T, R, , , IGset states, G finite set possible agent goals, set agent actions,A0 set assistant actions. Typically A0 include noop action, allows assistantdecide provide assistance particular decision epoch. transition function(s, g, a, s0 ) probability transition state s0 taking action A0agents goal g. R reward function maps G (A A0 ) real values.1. consider strictly alternating turn model simplicity. However, straightforward use modelcapture interactions strictly alternating, e.g. allowing assistant agent take multiple actionsrow.73fiF ERN , NATARAJAN , J UDAH , & TADEPALLIagents policy maps G distributions need optimal sense.(IG ) initial state (goal) distribution.assistant policy HGMDP defines distribution actions given sequencepreceding observations, i.e., sequence state action pairs. important assistant policy depends history rather current state since entire history potentiallyprovide evidence goal agent, may necessary selecting appropriateaction. must define objective function used evaluate value particular assistant policy. consider finite-horizon episodic problem setting, HGMDPepisode begins drawing initial state goal g IG . process alternatesagent assistant executing actions (including noops) environmenthorizon terminal state reached. agent assumed select actions according .many domains, terminal goal state reached within horizon, though general, goalsarbitrary impact reward function. reward episode equal sumrewards actions executed agent assistant episode. objectiveassistant reason HGMDP observed state-action history order selectactions maximize expected (or worst-case) total reward episode.proceeding worth reviewing assumptions formulation potential implications.Partial Observability: definition HGMDP similar definitionPartially Observable Markov Decision Process (POMDP). fact, HGMDP specialcase POMDP unobserved part state space consists single component corresponds goal user. simplicity assumedworld state fully observable. choice fundamental framework oneimagine relatively straightforward extensions techniques model environmentpartially observable MDP (POMDP) world states fully observable.Section 3, shed light hardness HGMDPs describe specializedheuristic solutions performance guarantees.Agent Policy: also assumed agent modeled memoryless/reactivepolicy gives distribution actions conditioned current world stategoal. assumption also fundamental framework one also extendinclude complex models user, example, include hierarchical goalstructures. extension explored previously (Natarajan, Tadepalli, & Fern,2007).Sequential Interaction: also assumed simplicity interaction modelassistant agent involves interleaved, sequential actions rather parallel actions.This, example, precludes assistant taking actions parallel agent.parallel assistive actions useful many cases, many domains sequentialactions norm. especially motivated domains intelligent desktopassistants help store retrieve files, filter spam, sort email, etc., smart homesopen doors, switch appliances, on. Many opportunities assistancedomains sequential variety. many cases, tasks appear require parallelactivity often formulated set threads thread sequential hence74fiA ECISION -T HEORETIC ODEL SSISTANCEformulated separate assistant. Extending framework handle general parallelassistance interesting future direction.Goal-Dependent Transitions: dependence reward policy goal allowsmodel capture agents desires behavior goal. dependencegoal less intuitive many cases dependence usedmodel dynamics environment. However, allow goal dependencegenerality modeling. example, convenient model basic communicationactions agent changing aspects state, result actions oftengoal dependent.two main obstacles solving problem intelligent assistance framework.First, many scenarios, initially HGMDP directly disposal since lackaccurate information agent policy and/or goal distribution IG . often duefact assistant deployed variety initially unknown agents. Rather, assistant find environment given possible set goals. describedSection 5, approach difficulty learn approximate HGMDP estimating agentpolicy goal distribution IG . Furthermore, also describe bootstrapping mechanism learning approximations quickly. second obstacle solving HGMDPgenerally high computational complexity solving HGMDPs. deal issue Section 4considers various approximate techniques efficiently solving HGMDPs.mentioned possible provide assistance using simpler domain-specificengineered solutions. particular, domains consider later could solved using several lessexpensive solutions require machinery HGMDPs. fact, one domains,compare model existing supervised learning method. goal workprovide domain-independent framework potentially encapsulate several assistantsystems hope gives rise robust understanding methodology buildingsystems much less human effort future.3. Theoretical Analysissection, analyze hardness solving HGMDPs, show despitespecial case POMDPs, hard. motivates new model called Helper-ActionMDP (HAMDP) restricted amenable approximate solutions.introduce myopic heuristic solve HAMDPs analyze performance. alsoanalyze special cases HAMDPs permit efficient solutions.3.1 Complexity Results Hidden Goal MDPsGiven knowledge agents goal g HGMDP, assistants problem reduces solvingMDP assistant actions. MDP transition function captures state change dueassistant action also ensuing state change due agent action selected accordinggiven g. Likewise reward function transition captures reward due assistant actionensuing agent action conditioned g. optimal policy MDP correspondsoptimal assistant policy g. However, since real assistant often uncertaintyagents goal, unlikely optimal performance achieved.75fiF ERN , NATARAJAN , J UDAH , & TADEPALLIview HGMDP collection |G| MDPs share state space,assistant placed one MDPs beginning episode, cannot observeone. MDP result fixing goal component HGMDP definition onegoals. collection easily modeled restricted type partially observable MDP(POMDP) state space G. component completely observable, G component unobservable changes beginning episode (according IG )remains constant throughout episode. Furthermore, POMDP transition provides observations agent action, gives direct evidence unchanging G component.perspective HGMDPs appear significant restriction general POMDPs. However,first result shows despite restriction worst-case complexity reduced evendeterministic dynamics.Given HGMDP , horizon = O(|M |), reward target r , short-term rewardmaximization problem asks whether exists history-dependent assistant policy achievesexpected finite horizon reward least r . general POMDPs problem PSPACEcomplete (Papadimitriou & Tsitsiklis, 1987; Mundhenk, 2001), POMDPs deterministicdynamics, NP-complete (Littman, 1996). However, following result.Theorem 1. Short-term reward maximization HGMDPs deterministic dynamics PSPACEcomplete.Proof. Membership PSPACE follows fact HGMDP polynomially encoded POMDP policy existence PSPACE. show PSPACE-hardness,reduce PSPACE-complete problem TQBF (truth quantified Boolean formula) problemexistence history-dependent assistant policy expected reward r.Let quantified Boolean formula form x1 x2 x3 . . . xn {C1 (x1 , . . . , xn ) . . .Cm (x1 , . . . , xn )}, Ci disjunctive clause. us, goal gi clause,agent chooses goal uniformly randomly set goals formed hidesassistant. states consist pairs form (v, i), v {0, 1} current valuegoal clause, next variable set. actions assistant set existentiallyquantified variables. agent simulates setting universally quantified variables choosingactions set {0, 1} equal probability. episode terminates variablesset, assistant gets reward 1 value clause 1 end reward 0otherwise.Note assistant get useful informtion goal terminationepisode. satisfiable, assistant policy leads reward 1goals choices agent actions, hence expected value 1 goaldistribution. not, least one goals satisfied setting universalquantifiers, leading expected value < 1. Hence TQBF problem reduces decidingHGMDP policy expected reward 1.result shows POMDP encoded HGMDP deterministic dynamics, stochastic dynamics POMDP captured via stochastic agent policyHGMDP. However, HGMDPs resulting PSPACE-hardness reduction quite pathological compared likely arise realistic assistant domains. importantly,agents actions provide practically information agents goal end episode,late exploit knowledge. suggests search restricted classesHGMDPs allow efficient solutions performance guarantees.76fiA ECISION -T HEORETIC ODEL SSISTANCE3.2 Helper Action MDPsmotivation Helper Action MDPs (HAMDPs) place restrictions agent assistant avoid following three complexities arise general HGMDPs: 1) agentbehave arbitrarily poorly left unassisted agent actions may provide significant evidence goal; 2) agent free effectively ignore assistants helpexploit results assistive action, even would beneficial; 3) assistantactions possibility negatively impacting agent compared assistant.HAMDPs address first issue assuming agent competent (approximately)maximizing reward without assistant. second third issues addressed assuming agent always detect exploit helpful actions assistant actionsnever hurt agent even unhelpful.Informally, HAMDP provides assistant helper action agents actions. Whenever helper action h executed directly corresponding agent action a,agent receives bonus reward 1. However, agent accept helper action h(by taking a) hence receive bonus, action agent considers goodachieving goal without assistant. Thus, primary objective assistant HAMDPmaximize number helper actions get accepted agent.2simple, model captures much essence assistive domains assistantactions cause minimal harm agent able detect accept good assistancearises.HAMDP HGMDP hS, G, A, A0 , T, R, , , IG following constraints:agent assistant actions sets = {a1 , . . . , } A0 = {h1 , . . . , hn },ai corresponding helper action hi .state space = W (W A0 ), W set world states. States W A0encode current world state previous assistant action.reward function R 0 assistant actions. agent actions reward zerounless agent selects action ai state (s, hi ) gives reward 1. is,agent receives bonus 1 whenever takes action directly corresponding helperaction.assistant always acts states W , taking hi deterministicallytransitions (s, hi ).agent always acts states A0 , resulting states according transition function depend hi , i.e. ((s, hi ), g, ai , s0 ) = 0 (s, g, ai , s0 )transition function 0 .Finally, agent policy, let (s, g) function returns set actions P (s, g)distribution actions. view (s, g) set actions agent2. Note assumed bonus rewards 1 simplicity. results easily extendednon-uniform positive bonus rewards. particular main result concerning bounding regretmyopic policy, analogous result simply includes constant factor equal maximum possible reward bonus.exceptions Theorems 7 8, currently analogous results non-uniform rewardbonuses.77fiF ERN , NATARAJAN , J UDAH , & TADEPALLIconsiders acceptable (or equally good) state goal g. agent policy always selectsai helper action hi whenever ai acceptable. is, ((s, hi ), g) = ai wheneverai (s, g). Otherwise agent draws action P (s, g).HAMDP, primary impact assistant action influence reward followingagent action. Also notice HAMDPs rewards inherent underlyingenvironment. Rather, rewards bonuses received whenever agent accepts helperaction. could defined model include environmental reward additionhelper bonuses, unnecessarily complicates model (as following hardness result shows).Instead, assume inherent environmental reward already captured agent policyvia (s, g), considered contain actions approximately optimize reward.example, HAMDP model captures doorman domain, desktop domain experiments. doorman domain, helper actions correspond opening doorsagent, reduces cost navigating one room another. desktop domain, helper actions correspond offering shortcuts users destination folders. Importantlyopening incorrect door offering incorrect shortcut increase (physical) costagent assistant all, key property HAMDPs.Despite apparent simplification HAMDPs HGMDPs, turns somewhatsurprisingly worst case computational complexity reduced.Theorem 2. Short-term reward maximization HAMDPs PSPACE-complete.Proof. Membership PSPACE follows easily since HAMDPs specialization HGMDPs.proof PSPACE-hardness identical Theorem 1 except here, insteadagents actions, stochastic environment models universal quantifiers. agent acceptsactions last one sets variable suggested assistant.assistants actions, environment chooses value universally quantified variable equalprobability. last action accepted agent goal clause evaluates 1, otherwise not.history-dependent policy whose expected reward greater equal numberexistential variables quantified Boolean formula satisfiable.Unlike case HGMDPs, stochastic dynamics essential PSPACE-hardnessshown later section. Despite negative result, following sections demonstrate utility HAMDP restriction giving performance guarantees simple policies improvedcomplexity results. far, analogous results general HGMDPs.3.3 Myopic Heuristic AnalysisHAMDPs closely related sequential prediction framework Littlestone (1988).framework, round learner shown new instance predicts binary label.prediction incorrect, mistake made, learner given true label. realizablesetting, true labels determined hypothesis target class. optimal predictionalgorithm minimizes upper bound number mistakes possible hypotheses.view helper action HAMDP prediction user action. Maximizing bonusreward HAMDP equivalent minimizing number mistakes sequential prediction.Unlike sequential prediction, predictions (actions) need binary. sequentialprediction sequence states arbitrarily chosen, assume generated78fiA ECISION -T HEORETIC ODEL SSISTANCEMarkov process. spite differences, results sequential predictionadapted HAMDPs albeit using different terminology. However, derive resultsfirst principles consistency.Given assistant policy 0 , regret particular episode extra reward oracleassistant knowledge goal would achieve 0 . HAMDPs oracle assistantalways achieve reward equal finite horizon m, always select helper actionaccepted agent. Thus, regret execution 0 HAMDP equalnumber helper actions accepted agent, call mispredictions.know optimizing regret PSPACE-hard thus focus boundingexpected worst-case regret assistant. introduce first myopic heuristicshow able achieve regret bounds logarithmic number goals.Coarsened Posterior Heuristic. Intuitively, myopic heuristic select actionhighest probability accepted respect coarsened version posteriordistribution goals. myopic policy state given history H based consistent goalset C(H), set goals non-zero probability respect history H.straightforward maintain C(H) observation (observations include world stateagents actions). myopic policy defined as:(s, H) = arg max IG (C(H) G(s, a))G(s, a) = {g | (s, g)} set goals agent considersacceptable action state s. expression IG (C(H) G(s, a)) viewed probabilitymass G(s, a) coarsened goal posterior assigns goals outside C(H) probabilityzero otherwise weighs proportional prior.Theorem 3. HAMDP expected regret coarsened posterior heuristic boundedentropy goal distribution H(IG ).Proof. main idea proof show misprediction myopic policy (i.e.selected helper action accepted agent) uncertainty goal reducedconstant factor, allow us bound total number mispredictions trajectory.Consider misprediction step coarsened posterior heuristic selects helper action histate given history H, agent accept action instead selects 6= ai .definition myopic policy know IG (C(H) G(s, ai )) IG (C(H) G(s, )), sinceotherwise assistant would chosen hi . fact argue IG (C(H 0 ))IG (C(H))/2 H 0 history misprediction. is, probability massIG consistent goal set misprediction less half consistent goal setmisprediction. show consider two cases: 1) IG (C(H) G(s, ai )) <IG (C(H))/2, 2) IG (C(H) G(s, ai )) IG (C(H))/2. first case, immediately getIG (C(H) G(s, )) < IG (C(H))/2. Combining fact C(H 0 ) C(H)G(s, ) get desired result IG (C(H 0 )) IG (C(H))/2. second case, noteC(H 0 ) C(H) (G(s, ) G(s, ai ))C(H) (C(H) G(s, ai ))Combining assumption second case immediately implies IG (C(H 0 ))IG (C(H))/2.79fiF ERN , NATARAJAN , J UDAH , & TADEPALLIshows misprediction made histories H H 0 IG (C(H 0 ))IG (C(H))/2. implies episode, n mispredictions resulting history Hn ,IG (C(Hn )) 2n . consider arbitrary episode true goal g. knowIG (g) lower bound IG (C(Hn )), implies IG (g) 2n equivalently nlog(IG (g)). Thus episode goal g maximum number mistakes boundedlog(IG (g)). Using fact get thePexpected number mispredictions episoderespect IG bounded g IG (g) log(IG (g)) = H(IG ), completesproof.Since H(IG ) log(|G|), result implies HAMDPs expected regret myopicpolicy logarithmic number goals. Furthermore, uncertaintygoal decreases (decreasing H(IG )) regret bound improves get regret 0 IGputs mass single goal. turns logarithmic bound asymptotically tightworst case.Theorem 4. exists HAMDP assistant policy expected regret leastlog(|G|)/2.Proof. Consider deterministic HAMDP environment structured binary treedepth log(|G|), leaf corresponds one |G| goals. considering uniformgoal distribution easy verify node tree equal chance truegoal left right sub-tree episode. Thus, policy 0.5 chancecommitting misprediction step episode. Since episode length log(|G|),expected regret episode policy log(|G|)/2.Resolving gap myopic policy bound regret lower bound open problem.3.3.1 PPROXIMATE G OAL ISTRIBUTIONS .0 instead true underlyingSuppose assistant uses approximate goal distribution IGgoal distribution IG computing myopic policy. is, assistant selects actions0 (C(H) G(s, a)), refer myopic policy relative 0 .maximize IGG0 instead bounded terms KullbackLeibler (KL) diverextra regret using IGG0 ), zero 0gence (Kullback & Leibler, 1951) distributions KL(IG k IGGequals IG .Theorem 5. HAMDP goal distribution IG , expected regret myopic policy0 bounded H(I ) + KL(I k 0 ).respect distribution IGGGGProof. proof similar Theorem 3, except since myopic policy respect0 rather , derive that, episode, maximum number mispredictions nIGG80fiA ECISION -T HEORETIC ODEL SSISTANCE0 (g)). Using fact, average number mispredictions given by:bounded log(IGPgPgPg=1)=IG (g) log( 0IG (g)1IG (g) log( 0) + log(IG (g)) log(IG (g)) =IG (g)XIG (g)IG (g) log(IG (g))IG (g) log( 0)IG (g)g0H(IG ) + KL(IG k IG).Note random variable X distribution P finite domain size N ,KL(P k U ) = log(N ) H(P ), U uniform distribution. Thus, consequenceTheorem 5 myopic policy respect uniform goal distribution expected regretbounded log(|G|) HAMDP, showing logarithmic regret achieved withoutknowledge IG . strengthened hold worst case regret.Theorem 6. HAMDP, worst case hence expected regret myopic policyrespect uniform goal distribution bounded log(|G|).Proof. proof Theorem 5 shows number mispredictions episode bounded0 ). case 0 = 1/|G| shows worst case regret bound log(|G|).log(IGGimmediately implies expected regret bound uniform myopic policy boundedlog(|G|).3.4 Deterministic Agent Policiesconsider several special cases HAMDPs. First, restrict agents policydeterministic goal, i.e. (s, g) single action state-goal pair (s, g).Theorem 7. myopic policy achieves optimal expected reward HAMDPs deterministic agent policies.proof given Appendix. sometimes desirable minimize worst possible regretcompared oracle assistant knows agents goal. show below, capturedgraph-theoretic notion tree rank generalizes rank decision trees (Ehrenfeucht &Haussler, 1989).Definition 1. rank rooted tree rank root node. node leaf noderank(node) = 0, else node least two distinct children c1 c2 equal highest ranksamong children, rank(node) = 1+ rank(c1 ). Otherwise rank(node) = rank highestranked child.optimal trajectory tree (OTT) HAMDP deterministic environments treenodes represent states HAMDP reached prefixes optimal action sequencesdifferent goals starting initial state.3 node tree represents state set3. multiple initial states, build OTT initial state. rank would maximumranks trees.81fiF ERN , NATARAJAN , J UDAH , & TADEPALLIgoals optimal path initial state. Since agent policy deterministic,one trajectory per goal tree. Hence size optimal trajectory treebounded number goals times maximum length trajectory,size state space deterministic domains. following Lemma follows inductiondepth optimal trajectory tree. proof Appendix.Lemma 1. minimum worst-case regret policy HAMDP deterministic environments deterministic agent policies equal tree rank optimal trajectory tree.leads following.Theorem 8. agent policy deterministic, problem minimizing maximum regretHAMDPs deterministic environments P.Proof. first construct optimal trajectory tree. compute rank linear timesimultaneously computing optimal minimax policy using recursive definition tree rank.result follows Lemma 1.3.5 Bounded Branching Factor Policiesassumption deterministic agent policy may restrictive many domains.consider agent policies may constant number possible actions (s, g)state-goal pair defined below.Definition 2. branching factor HAMDP largest number possible actions (s, g)agent state goal assistants action.Doorman domain Section 6.1 branching factor 2 since two optimalactions reach goal state.Theorem 9. Minimizing worst-case regret finite horizon HAMDPS deterministic environments constant branching factor k NP-complete.proof appendix. also show minimizing expected regret boundedk NP-hard. conjecture problem also NP, question remains open.4. Solving Practical HGMDPsAlthough HAMDPs offer theoretically elegant framework, requirements practical assistantsystems easily satisfed assumptions. section, consider generalproblem solving HGMDPs offer practical heuristic solutions inspiredtheoretical analysis.principle could use general purpose POMDP solver solve HGMDPs.POMDP solvers based point-based methods search-based methods become efficient years, still inefficient used interactive setting,parameters POMDP continually updated. Moreover, analysis previoussection suggests, simple myopic heuristics based knowledge goal distributionoptimal policies given goals appear promising yield respectable performance. reason,adopt approach based Bayesian goal estimation followed heuristic action selection,evaluate three different domains. Below, first give overview solution algorithmdescribe components detail.82fiA ECISION -T HEORETIC ODEL SSISTANCE4.1 Overviewsection, assume given HGMDP , delegating problem learningSection 5. Let Ot = o1 , ..., ot observation sequence observed assistantbeginning current trajectory time t. observation tuple world statepreviously selected action (by either assistant agent). Given Ot goal computeassistant action whose value (close to) optimal.motivate approach, useful consider special characteristics HGMDP.importantly, belief state corresponds distribution agents goal. Since agentassumed goal directed, observed agent actions provide substantial evidencegoal might might be. fact, even assistant nothing, agents goalsoften rapidly revealed analyzing relevance agents initial actions possiblegoals. cases, suggests state/goal estimation problem HGMDP maysolved quite effectively observing agents actions relate various possible goals,rather requiring assistant select actions explicitly purpose information gatheringagents goals. words, cases, expect purely (or nearly) myopicaction selection strategies, avoid reasoning information gathering, effective.Reasoning information gathering one key complexities involved solving POMDPscompared MDPs. leverage intuitive properties HGMDP gain tractabilitylimiting completely avoiding reasoning. course, shown PSPACE-hardnessresults, goals always rapidly revealed non-myopic reasoning essential.note cases, assistant pure information-gathering actionsdisposal, e.g. asking agent question. consider actions experiments,believe actions handled naturally framework incorporatingsmall amount look-ahead search.motivation, assistant architecture, depicted Figure 1, alternatesgoal estimation action selection follows:1. observing agents next action, update goal distribution based HGMDPmodel.2. Based updated distribution evaluate effectiveness assistant actions (includingnoop) building sparse-sampling look-ahead tree bounded depth (perhaps depthone), leaves evaluated via myopic heuristic.key element architecture computation myopic heuristics. topheuristic, optionally obtain non-myopic behavior via search building look-ahead sparsesampling tree. experiments show search improve performance small marginsignificant computational cost. note idea utilizing myopic heuristics selectactions POMDPs new, see example (Cassandra, 1998; Geffner & Bonet, 1998),similar methods used previously success applications computer bridge(Ginsberg, 1999). main contribution show approach particularly wellsuited setting evaluate efficiently computable heuristics specifically designedsolving HGMDPs. describe goal estimation action selection operationsdetail.83fiF ERN , NATARAJAN , J UDAH , & TADEPALLIGoal EstimationP(G)Action SelectionAssistantOtWtEnvironmentUserUtFigure 1: Depiction assistant architecture. agent hidden goal selects actionsUt cause environment change world state Wt , typically moving closergoal. assistant (upper rectangle) able observe world state alongobservations generated environment, setting contain user/agentactions along world state. assistant divided two components. First,goal estimation component computes posterior agent goals P (G) given observations. Second, action selection component uses goal distribution computebest assistive action via combination bounded search myopic heuristiccomputation. best action might noop cases none assistiveactions higher utility user.84fiA ECISION -T HEORETIC ODEL SSISTANCE4.2 Goal EstimationGiven HGMDP agent policy initial goal distribution IG , objective maintainposterior goal distribution P (g|Ot ), gives probability agent goal gconditioned observation sequence Ot . Note since assumed assistant cannotaffect agents goal, observations related agents actions relevant posterior.Given agent policy , straightforward incrementally update posterior P (g|Ot ) uponagents actions.beginning episode initialize goal distribution P (g|O0 ) IG . timestepepisode, Ot involve agent action, leave distribution unchanged. Otherwise, agent selects action state s, update posterior according P (g|Ot ) =(1/Z) P (g|Ot1 ) (a|s, g), Z normalizing constant. is, distribution adjusted place weight goals likely cause agent execute action s.accuracy goal estimation relies well policy learned assistant reflectstrue agent policy. described Section 5.2, use model-based bootstrapping approachestimating update estimate end episode. Provided agent closeoptimal, experimental domains, approach lead rapid goal estimation, even earlylifetime assistant.assumed simplicity actions agent directly observable.domains, natural assume state world observable, ratheractual action identities. cases, observing agent transitioning s0use MDP transition function marginalize possible agent actions yielding update,P (g|Ot ) = (1/Z) P (g|Ot1 )X(a|s, g)T (s, a, s0 ).aA4.3 Action SelectionGiven HGMDP distribution goals P (g|Ot ), address problemselecting assistive action. mechanisms utilize combination bounded look-ahead searchmyopic heuristic computations. increasing amount look-ahead search actionsreturned closer optimal cost computation. Fortunately, many HGMDPs,useful assistant actions computed relatively little search. first describe severalmyopic heuristics used either greedy action selection combination search.Next, review utilize sparse sampling obtain non-myopic action selection.4.3.1 ACTION ELECTION H EURISTICSexplain action selection procedure, introduce idea assistant MDP relativegoal g , denote (g). MDP (g) identical exceptchange initial goal distribution P (G0 = g) = 1. is, goal always fixed gepisode. Since hidden component state space goal, fixing goal(g) makes state fully observable, yielding MDP. episode (g) evolves drawinginitial world state selecting assistant actions goal g achieved. Notestate transition assistant action a0 state result successive state transitions, firstdue assistant action due ensuing agent action, selected basedagent policy goal g. optimal policy (g) gives optimal assistive action assuming85fiF ERN , NATARAJAN , J UDAH , & TADEPALLIagent acting achieve goal g. denote Q-function (g) Qg (s, a),expected cost executing action state following optimal policy.consider second heuristic action selection, accounts non-uniform rewards true goal posterior, unlike coarsened posterior heuristic introduced Section 3.3.simply expected Q-value action assistant MDPs, also called QMDPmethod Cassandra (1998). heuristic value assistant action state given observationsOtXQg (s, a) P (g|Ot ).H(s, a, Ot ) =gIntuitively H(s, a, Ot ) measures utility taking action assumptiongoal ambiguity resolved one step. Thus, heuristic value information-gatheringutility action. Rather, heuristic favor assistant actions make progress toward goalshigh posterior probability. goal posterior highly ambiguous often leadassistant prefer noop, least hurt progress toward goal. Noteheuristic, well others below, used evaluate utility state s, ratherstate-action pair, maximizing actions maxa H(s, a, Ot ).primary computational complexity computing H solve assistant MDPsgoal order obtain Q-functions. Technically, since transition functions assistantMDPs depend approximate agent policy , must re-solve MDP updatingestimate end episode (see Section 5.2 policy learning). However, using incremental dynamic programming methods prioritized sweeping (Moore & Atkeson, 1993)alleviate much computational cost. particular, deploying assistant solveMDP offline based default agent policy given Boltzmann bootstrapping distribution describe Section 5.2. deployment, prioritized sweeping used incrementallyupdate Q-values based learned refinements make .practical exactly solve assistant MDPs, may resort various approximations. consider two approximations experiments. One replace users policyused computing assistant MDP fixed default user policy, eliminating needcompute assistant MDP every step. denote approximation Hd . Another approximation uses simulation technique policy rollout (Bertsekas & Tsitsiklis, 1996) approximateQg (s, a) expression H. done first simulating effect taking actionstate using estimate expected cost agent achieve g resultingstate. is, approximate Qg (s, a) assuming assistant select singleinitial action followed agent actions. formally, let Cn (, s, g) function simulates n trajectories achieving goal state averaging trajectory costs.H(s, a, Ot ) except replace Qg (s, a) expectationP heuristic H0r identical0s0 (s, a, ) C(, , g). also combine heuristics, using fixed defaultuser policy policy rollouts, denote Hd,r .4.3.2 PARSE AMPLINGheuristics somewhat myopic sense take accountpotentially persistent ambiguity agents goal consider use informationgathering actions resolve ambiguity. cases beneficial consider nonmyopic reasoning, one combine heuristics shallow search belief space86fiA ECISION -T HEORETIC ODEL SSISTANCEassistant MDP. purpose utilize depth bounded sparse sampling trees (Kearns,Mansour, & Ng, 1999) compute approximation Q-function given belief state(st , Ot ), denoted Qd (st , a, Ot ). Given particular belief state, assistant selectaction maximizes Qd . Note convenience represent belief state paircurrent state st observation history Ot . lossless representation belief state sinceposterior goal distribution computed exactly Ot goal hiddenportion POMDP state.base case Q0 (st , a, Ot ) equal one myopic heuristics described above.Increasing depth result looking ahead state transitions evaluating oneheuristics. looking ahead possible track potential changes belief statetaking certain actions determine whether changes belief would beneficialrespect providing better assistance. Sparse sampling look-ahead approximatelycomputing:Qd (s, a, O) = E[R(s, g, a) + V d1 (s0 , O0 )]V (s, O) = max Q (s, a, O)(1)(2)g random variable distributed according goal posterior P (g|O) (s0 , O0 )random variable represents belief state taking action belief state (s, O).particular, s0 world state arrived O0 simply observation sequence extendedobservation obtained state transition. first term expectationrepresents immediate reward assistant action goal g.Sparse sampling approximates expectation averaging set b samples successor belief states. sparse-sampling pseudo-code presented Table 4.3.2. Given input beliefstate (s, O), assistant action a, heuristic H, depth bound d, sampling width b algorithm returns (an approximation of) Qd (s, a, O). First, depth bound equal zero heuristicvalue returned. Otherwise b samples observations resulting taking action belief state(s, O) generated. observations form oi = (s0i , ai , si ), s0i stateresulting taking action state s, ai ensuing agent action selected s0i based goaldrawn goal posterior, si result taking action ai state s0i . observation oicorresponds new belief state (si , [O; oi ]) [O; oi ] simply concatenation oi O.code recursively computes value belief states maximizing Qdactions averages results.b become large, sparse sampling produce arbitrarily close approximationtrue Q-function belief state MDP. computational complexity sparse sampling linearb exponential d. Thus depth must kept small real-time operation.5. Learning HGMDPssection, tackle problem learning HGMDP interacting environment assist agent. assume set goals G known agent. primaryrole learning acquire agents policy goal distribution. assumption naturalsituations assistant applied many times environment, possiblydifferent agents. example, desktop environment, environment MDP correspondsdescription various desktop functionalities, remains fixed across users. one87fiF ERN , NATARAJAN , J UDAH , & TADEPALLIGiven: heuristic function H, belief state (s, O), action a, depth bound d, sampling width bReturn: approximation Qd (s, a, O) value belief state (s, O)1. = 0 return H(s, a, O)2. Sample set b observations {o1 , . . . , ob } resulting taking actionbelief state (s, O) follows:(a) Sample s0i environment MDP transition function (s, a, )(b) Sample goal gi P (gi |O)(c) Sample agent action ai agent policy (|s0i , gi )(d) oi = (s0i , ai , si ), si sample environment MDP transitionfunction (s0i , ai , )3. oi = (s0i , gi , ai , si ) compute Vi = maxa0 Qd1 (si , a0 , [O; oi ])P4. Return Qd (s, a, O) = 1b R(s, gi , a) + ViTable 1: Pseudo-code Sparse Sampling HGMDPprovided description MDP typically straightforward learn modelprimary cost longer warming period assistant.Relaxing assumption provided set possible goals problematiccurrent framework. saw Section 4, solution methods depend knowing setgoals clear learn observations, since goals, unlike statesactions, directly observable assistant. Extending framework assistantautomatically infer set possible user goals, allow user define goals,interesting future direction. note, however, often possible designer enumerateset user goals deployment perhaps complete, allows useful assistanceprovided.5.1 Maximum Likelihood Estimatesstraightforward estimate goal distribution G0 agent policy simply observingagents actions, possibly assisted, compute empirical estimates relevantquantities. done storing goal achieved end episode alongset world state-action pairs observed agent episode. estimate IGbased observed frequency goal (usually Laplace correction avoidextreme values probabilities). Likewise, estimate (a|s, g) simply frequencyaction taken agent state goal g. limitmaximum likelihood estimates converge correct values true HGMDP, practiceconvergence slow. slow convergence lead poor performance early stagesassistants lifetime. alleviate problem propose approach bootstrappinglearning agent policy .88fiA ECISION -T HEORETIC ODEL SSISTANCE5.2 Model-Based Bootstrappingleverage environment MDP model order bootstrap learning agent policy.particular, assume agent near optimal sense that, particular goalworld state, likely select actions close optimal. unrealisticmany application domains might benefit intelligent assistants. particular,many tasks, conceptually simple humans, yet quite tedious, e.g., navigatingdirectory structure computer desktop. Performing optimally tasks difficulthumans.Given near rationality assumption, initialize estimate agents policyprior biased toward optimal agent actions. consider environment MDPassistant actions removed solve Q-function Q(a, s, g) using MDP planningtechniques. Q-function gives expected cost executing agent action world stateacting optimally achieve goal g using agent actions. world without assistant,rational agent would always select actions maximize Q-function state goal.Furthermore, close-to-rational agent would prefer actions achieve higher Q-values highlysuboptimal actions. first define Boltzmann distribution, used defineprior,1(a|s, g) =exp(K Q(a, s, g))(3)Z(s, g)Z(s, g) normalizing constant, K temperature constant. Using larger valuesK skews distribution heavily toward optimal actions. Given definition, priordistribution (|w, g) taken Dirichlet parameters (1 , . . . , |A| ), =0 (ai |s, g). 0 parameter controls strength prior. Intuitively 0thought number pseudo-actions represented prior, representingnumber pseudo-actions involved agent action ai . Since Dirichlet conjugatemultinomial distribution, form (|s, g), easy update posterior(|s, g) observation. One take mode mean posterior pointestimate agent policy used define HGMDP.experiments, found prior provides good initial proxy actual agentpolicy, allowing assistant immediately useful. updating posterior tunesassistant better peculiarities given agent. example, many casesmultiple optimal actions posterior come reflect systematic bias among equallygood actions agent has. Computationally main obstacle approach computingQ-function, needs done given application domain since environmentMDP constant. Using dynamic programming accomplished polynomial timenumber states goals. practical, number alternatives exist includinguse factored MDP algorithms (Boutilier et al., 1999), approximate solution methods (Boutilieret al., 1999; Guestrin et al., 2003), developing domain specific solutions.Finally, work, utilize uninformative prior goal distribution. interestingfuture direction would bootstrap goal distribution estimate based observationspopulation agents.89fiF ERN , NATARAJAN , J UDAH , & TADEPALLI6. Experimental Resultssection, present results conducting user studies simulations three domains:two game-like environments folder predictor domain intelligent desktop assistant.user studies two game-like domains, episode, users assistants actionsrecorded. user studies performed using 12 human subjects (graduate students CSdepartment Oregon State University) single session. ratio cost achievinggoal assistants help optimal cost without assistant calculated averagedmultiple trials user. present similar results simulations well. thirddomain folder predictor domain, simulated user used one heuristicsgenerate top 3 recommended folders user. present number clicks requiredaverage user reach desired folder. Two three domains, namely, doormandomain folder predictor domain, fall category HAMDPs since assistiveactions merely viewed helper actions agent ignore. kitchen domainhand needs slightly general formulation since agent assistantstrictly alternate, assistants actions cannot ignored agent.6.1 Doorman Domaindoorman domain, agent set possible goals collect wood, foodgold. grid cells blocked. cell four doors agent opendoor move next cell (see Figure 2). door closes one time-step timeone door open. goal assistant help user reach goal faster openingcorrect doors.state tuple hs, di, stands agents cell door open.total number states 245 (49 squares 5 possibilities door). actions agentopen door move 4 directions pickup whatever cell,total 9 actions. assistant open doors perform noop (5 actions. agentsassistants actions strictly alternate domain, satisfying definition HAMDPs.reward 1 (or cost 1) user open door reward assistantsaction. trial ends agent picks desired object. Note includednoop action assistant, domain action never selected, since cost openingwrong door noop same, potential benefit selecting noop.experiment, evaluated two heuristics: one fixed user policy defaultpolicy HGMDP creation (Hd ) avoiding need repeated computation HGMDPevery step second use policy rollout calculate Q-values (Hr ).trial, system chooses goal one two heuristics random. user showngoal tries achieve it, always starting center square. every users action,assistant opens door nothing. user may pass door open different door.user achieves goal, trial ends, new one begins. assistant usesusers trajectory update agents policy.results user studies doorman domain presented Tabe 2. first tworows give cumulative results user study actions selected greedily according HrHd respectively. Rather reporting negtive rewards, table shows total number90fiA ECISION -T HEORETIC ODEL SSISTANCEFigure 2: Doorman Domain. agents goal fetch resource. grid cells separateddoors must opened passing through.actions trials across users without assistant N, total number actionsassistant U, average percentage savings (1-(U/N)) trials users.4seen, methods reduce number actions 50%. Noteassistant selects among four doors random would reduce number actions25% comparison. omniscient assistant knows users goal reduces numberactions 78%. 100% first door always opened user.experiments, count users first action, number actions reduces 65%.5observed Hr appears slight edge Hd . One possible reasonusing Hd , re-solve MDP updating user policy, Hr alwaysusing updated user policy. Thus, rollout reasoning accurate model user.HeuristicHrHdHr= 2, b = 1= 2, b = 2= 3, b = 1= 3, b = 2TotalActionsN75088215501337130411671113UserActionsU339435751570521467422Fractional Savings1 (U/N )0.55 0.0550.51 0.050.543 0.170.588 0.170.597 0.170.6 0.150.623 0.15Timeperaction (in secs0.05620.00210.0310.0970.350.3842.61Table 2: Results experiments Doorman Domain. first two rows table presentresults user studies rest table presents results simulation.4. gives pessimistic estimate usefulness assistant assuming optimal user measure utilitynormalized optimal utility without aid assistant.5. Note first action requirement easily aviodable. simply equivalent switch indicateuser ready move grid. also replace requirement explicitly adding buttoninterface start new episode.91fiF ERN , NATARAJAN , J UDAH , & TADEPALLIAnother interesting observation individual differences among users.users always prefer fixed path goal regardless assistants actions. usersflexible. survey conducted end experiment, learned onefeatures users liked system tolerant choice suboptimal paths.data reveals system able reduce costs approximately 50% evenusers chose suboptimal trajectories.also conducted experiments using sparse sampling non-zero depths. considereddepths = 1 = 2 using sampling widths b = 1 b = 2. leaves sparsesampling tree evaluated using Hr simply applies rollout user policy. Hence sparsesampling = 0 b = 1, would correspond heuristic Hr . experiments,conduct user studies, due high cost effort required humans studies,simulated human users choosing actions according policies learned observedactions previous user study. results presented last 5 rows Table 2. Noteabsolute numbers actions user studies simulations comparablebased different numbers trajectories. human users tested fewer trajectoriesminimize fatigue. see sparse sampling increased average run time (last column)order magnitude, able produce reduction average cost user. resultsurprising hindsight, simulated experiments, sparse sampling able sampleexact user policy (i.e. sampling learned policy, also usedsimulations). results suggest small amount non-myopic reasoningpositive benefit substantial computation cost. Note, however, bulk benefitrealized assistant obtained without reasoning, showing myopic heuristicswell-suited domain.6.2 Kitchen Domainkitchen domain, goals agent cook various dishes. 2 shelves3 ingredients each. dish recipe, represented partially ordered plan. ingredientsfetched order, mixed heated. shelves doorsmust opened fetching ingredients one door open time.8 different recipes. state consists location ingredients(bowl/shelf/table), mixing state temperature state ingredient (if bowl)door open. state also includes action history preserve orderingplans recipes. users actions are: open doors, fetch ingredients, pourbowl, mix, heat bake contents bowl, replace ingredient back shelf.assistant perform user actions except pouring ingredients replacing ingredientback shelf. restricted assistant pouring ingredients irreversible action. reward non-pour actions -1. Experiments conducted 12 human subjectscomputer science graduate students. Unlike doorman domain, allowedassistant take multiple consecutive actions. turn switches user assistantexecutes noop action.domain large state space hence possible update user policyevery trajectory. Hence, two heuristics compare use default user policy.second heuristic addition uses policy rollout compare actions. words, compareHd Hd,r . results user studies shown top part Table 3. doorman92fiA ECISION -T HEORETIC ODEL SSISTANCEFigure 3: kitchen domain. user prepare dishes described recipesright. assistants actions shown bottom frame.domain, total number agent actions without assistant, percentage reduction due assistant presented. number user actions summed 12 userscumulative results presented. observed Hd,r performs better Hd .observed experiments Hd,r technique aggressive choosing non-noopactions Hd , would wait goal distribution highly skewed toward particulargoal.HeuristicHd,rHdHd,r= 2, b = 1= 2, b = 2= 3, b = 1= 3, b = 2TotalActionsN3188317564986532647765366585UserActionsU1175145823322427229324582408Fractional Savings1 (U/N )0.6361 0.150.5371 0.100.6379 0.140.6277 0.140.646 0.140.6263 0.150.645 0.14Timeperaction (secs)0.0130.0130.0130.0540.1900.1700.995Table 3: Results experiments Kitchen Domain. first two rows table presentresults user studies last 5 rows present results simulation.compared use sparse sampling heuristic simulated user trajectoriesdomain well (see last 5 rows Table 3). Again, absolute numbers actionsuser studies comparable simuations due different numbers trajectoriescase. Since sparse sampling considers larger number trajectories methods,policies learned sometimes better learned heuristics, although tooktime execute. However, significant difference solution qualityrollouts sparse sampling simulations, showing myopic heuristics performing93fiF ERN , NATARAJAN , J UDAH , & TADEPALLIwell sparse sampling much less computation. Sparse sampling higher depths requiresorder magnitude computation time compared rollout.6.3 Folder Predictorsection, present evaluation framework real-world domain. partTask Tracer project (Dragunov, Dietterich, Johnsrude, McLaughlin, Li, & Herlocker, 2005),researchers developed file location system called folder predictor (Bao et al., 2006). ideabehind folder predictor learning users file access patterns, assistanthelp user file accesses predicting folder file accessedsaved.setting, goal folder predictor minimize number clicks user.predictor would choose top three folders would minimize cost appendUI (shown ovals Figure 4). Also, user taken first recommended folder.users target folder first recommended folder, user would reach folder zero clicksreach second third recommended folder one click. user either choose onerecommendations navigate windows folder hierarchy recommendationsrelevant.Figure 4: Folder predictor (Bao et al., 2006).Bao et al. considered problem supervised learning problem implemented costsensitive algorithm predictions cost number clicks user (Baoet al., 2006). But, algorithm take account response userpredictions. instance, user chooses ignore recommended folders navigatesfolder hierarchy, make re-predictions. due fact modelone-time prediction consider user responses. Also, algorithm considersrestricted set previously accessed folders ancestors possible destinations.precludes handling possibility user accessing new folder.decision-theoretic model naturally handles case re-predictions changing recommendations response user actions. first step, used data collecteduser interface used model make predictions. use users response predic94fiA ECISION -T HEORETIC ODEL SSISTANCEtions make predictions. Also, handle possibility new folder, considerfolders folder hierarchies prediction. used mixture density obtainprobability distribution folders.P (f ) = 0 P0 (f ) + (1 0 )Pl (f )P0 probability according Bao et.als algorithm (2006), Pl uniform probability distribution set folders 0 ratio number times previously accessedfolder accessed total number folder accesses.idea behind using density function early stages task, useraccessing new folders later stages user access folders particular taskhierarchy. Hence number folder accesses increases value 0 increases wouldeventually converge 1, hence resulting distribution would converge P0 . data setconsists collection requests open file (Open) save file (saveAs), ordered time.request contains information as, type request (open saveAs), current task,destination folder, etc. data set consists total 810 open/saveAs requests. folderhierarchy consists 226 folders.state space consists 4 parts: current folder user accessing threerecommendations two unordered. would correspond state space size226 225 2242 . action user either choose recommended folder selectdifferent folder. action assistant corresponds choosing top 3 foldersaction space size 225 2242 . reward case negative number userclicks. domain, assistant users actions strictly alternate assistant revisespredictions every user action. prior distribution initialized using rewards computedmodel developed Bao et al. (2006).applied decision theoretic model data set. request, assistant wouldmake prediction using Hd,r heuristic (which uses default user policy rolloutmethod) user simulated. user would accept recommendation shortenspath goal, otherwise would act according optimal policy. userconsidered close optimal, unrealistic real world. compare results,also used model developed Bao et al. data set present results Table 4.Restricted folder setFoldersOne-time Prediction1.37241.319Repredictions1.341.2344Table 4: Results experiments folder predictor domain. numbers indicate average number clicks required agent reach his/her correct folder. entrytop left hand cell performance current Task Tracer, onebottom right hand cell performance decision-theoretic assistant.table shows average cost folder navigation 4 different cases: Bao et.als originalalgorithm, algorithm modified include mixture distributions model withoutmixture distributions. seen model use mixture distributionsleast user cost navigation hence effective. Bao et. al shown95fiF ERN , NATARAJAN , J UDAH , & TADEPALLIalgorithm performs significantly better windows default prediction average2.6 clicks per folder navigation. improvement attributed two modificationsmentioned earlier. First, use re-predictions model natural decisiontheoretic framework model makes one-time prediction hence cannot make useusers response recommendations. Secondly, considering folders hierarchyprediction including possibility user accessing new folder found useful.observed either modifications yields lower cost original algorithm,combining two changes significantly effective.7. Discussion Related Workwork inspired growing interest success building useful software assistants(Yorke-Smith et al., 2012; Lieberman, 2009; Myers et al., 2007). effort focusedbuilding desktop assistants help tasks calendar scheduling (Refanidis, Alexiadis, & Yorke-Smith, 2011), email filtering (Cohen, Carvalho, & Mitchell, 2004), on-line diagnostics (Skaanning, Jensen, & Kjaerulff, 2000), travel planning (Ambite, Barish, Knoblock,Muslea, Oh, & Minton, 2002). tasks typically requires designing software systemaround specialized technologies algorithms. example, email filtering typically posedsupervised learning problem (Cohen et al., 2004), travel planning combines information gatheringsearch constraint propagation (Ambite et al., 2002), printer diagnostics formulatedBayesian network inference (Skaanning et al., 2000). approaches focus socially assistive robots setting robot designed aid human agents achieving goals (Johnson,Cuijpers, Juol, Torta, Simonov, Frisiello, Bazzani, Yan, Weber, Wermter, et al., 2013). Unfortunately plethora systems approaches lacks overarching conceptual framework,makes difficult build others work. paper, argue decision-theoreticapproach provides common framework allows design systems respondnovel situations flexible manner reducing need pre-programmed behaviors. formulate general version assistantship problem involves inferring users goals takingactions minimize expected costs.Earlier work learning apprentice systems focused learning users observation (Mahadevan, Mitchell, Mostow, Steinberg, & Tadepalli, 1993; Mitchell, Caruana, Freitag,J.McDermott, & Zabowski, 1994). work also closely related learning demonstrationprogramming demonstration (Johnson, 2014; Konidaris, Kuindersma, Grupen, & Barto, 2012;Atkeson & Schaal, 1997; Cypher, 1993; Lau, Wolfman, Domingos, & Weld, 2003). emphasissystems provide interface computer system unobtrusively observehuman user task learn itself. human acts user teacher.performance system measured quickly system learns imitate user,i.e., supervised learning setting. Note imitation assistance two different thingsgeneral. expect secretaries learn us, typically expected replaceus. setting, assistants goal reduce expected cost users problem solving.user assistant capable exactly set actions, assistants actions costnothing compared users, makes sense assistant try completely replacehuman. Even case, assistantship framework different learning demonstrationstill requires assistant infer users goal actions trying achieveit. Moreover, assistant might learn solve goal reasoning action set96fiA ECISION -T HEORETIC ODEL SSISTANCErather shown examples user. general, however, actionset user assistant may different, supervised learning appropriate.example, case folder predictor. system needs decide set folderspresent user, user needs decide choose. awkwardimpossible formulate problem supervised learning programming demonstration.Taking decision-theoretic view helps us approach assistantship problem principledmanner taking account uncertainty users goals costs taking differentactions. assistant chooses action whose expected cost lowest. framework naturallyprevents assistant taking actions (other noop) assistive actionexpected reduce overall cost user. Rather learning user behave,framework assistant learns users policy. similar secretary learnshabits boss, much imitate her, help effective way. workassumed user MDP small enough solved exactly given users goals.assumption may always valid, makes sense cases learn userbehave. natural treat case users actions provide exploratoryguidance system (Clouse & Utgoff, 1992; Driessens, 2002). gives opportunitysystem imitate user knows nothing better improve upon users policycan.personal assistant systems based POMDP models. However,systems formulated domain-specific POMDPs solved offline. instance,COACH system helped people suffering dementia giving appropriate promptsneeded daily activities (Boger, Poupart, Hoey, Boutilier, Fernie, & Mihailidis, 2005).use plan graph keep track users progress estimate users responsivenessdetermine best prompting strategy. distinct difference approachsingle fixed goal washing hands, hidden variable user responsivenesseither low high. Rather, formulation goal random variable hiddenassistant. Since state-action space significantly smaller (1280 2 108 statesfolder predictor domain), possible solve POMDP exactly. Given needre-solve POMDP every user action, becomes prohibitively expensive. Yet anotherdifference length trajectory goal small case hence plan graphwould suffice capture user policy. model, restrict plan graph insteadsolve user MDP bootstrap policy. mentioned learning user policyfuture direction. work, even though start initial estimate user policy,update every goal achieved. considered online learning user policyreasonably good prior. note combination two frameworks (one modelingusers responsiveness modeling users goal) would useful, assistantinfers agent goals relevant hidden properties user, responsiveness.Electric Elves, assistant takes many mundane responsibilities humanagent including rescheduling meeting appear user likely miss it.domain-specific POMDP formulated solved offline using variety techniques. oneapproach, since system monitors users short regular intervals, radical changes beliefstates usually possible pruned search space (Varakantham, Maheswaran,& Tambe, 2005). Neither exact approximate POMDP solvers feasible online setting,POMDP changing learn user, must repeatedly solved.either costly run (Boger et al., 2005), complex implement baseline, e.g., Electric97fiF ERN , NATARAJAN , J UDAH , & TADEPALLIElves (Varakantham et al., 2005). experiments demonstrate simple methods onestep look-ahead followed rollouts would work well many domains POMDPssolved online. distinct related work (Doshi & Gmytrasiewicz, 2004), authors introducesetting interactive POMDPs, agent models agents beliefs. Clearly,general complex ordinary POMDPs. model simpler assumesagent oblivious presence beliefs assistant. simplified model sufficesmany domains, relaxing assumption without sacrificing tractability would interesting.several dialogue systems proposed many based decisiontheoretic principles (Walker, 2000; Singh, Litman, Kearns, & Walker, 2002). instance,NJFun system designed MDP provide assistance user interacting userproviding answer users questions. uses automatic speech recognizer (ASR)interpret human dialogues uses dialogue policy choose best action (the response).goals user could set standard queries locations restaurants, wineries,shopping centers etc. state space would dialogue states, i.e., current statedialogue user assistant (such greeting, choice state etc). observationsinterpretations dialogues human ASR. NJFun system usefullymodeled HGMDP, goal assistant infer users query given observations provide appropriate response. initial assistant policy learned trainingdata, manner similar dialogue policy NJFun system.work also related on-line plan recognition naturally extended includehierarchies hierarchical versions HMMs (Bui, Venkatesh, & West, 2002) PCFGs(Pynadath & Wellman, 2000). Blaylock Allen describe statistical approach goal recognitionuses maximum likelihood estimates goal schemas parameters (Blaylock & Allen, 2004).approaches notion cost reward. incorporating plan recognitiondecision-theoretic context, obtain natural notion optimal assistance, namely maximizingexpected utility.substantial research area user modeling. Horvitz et al. took Bayesianapproach model whether user needs assistance based actions attributes providedassistance needed spreadsheet application (Horvitz et al., 1998). Hui Boutilier usedsimilar idea assistance text editing (Hui & Boutilier, 2006). use DBNs handcodedparameters infer type user compute expected utility assisting user.would interesting explore use ideas plan recognition (Charniak & Goldman, 2013;Gal, Reddy, Shieber, Rubin, & Grosz, 2012; Chu, Song, Kautz, & Levinson, 2011) systemtake account users intentions attitudes computing optimal policyassistant.Recently, methods proposed solving POMDPs called point based methods (Pineau, Gordon, & Thrun, 2003; Porta, Vlassis, Spaan, & Poupart, 2006; Kurniawati, Hsu,& Lee, 2008; Shani, Pineau, & Kaplow, 2013). example method point based valueiteration (PBVI) (Pineau et al., 2003; Porta et al., 2006) takes set belief points B inputmaintains set POMDP -vectors iteration. iteration produces new set vectors optimal belief point respect -vectors previous iteration.approximation made PBVI compared value iteration guaranteeset -vectors optimal entire belief space. omitting -vectors, PBVImaintains constant run time per iteration. Application efficient point based methods98fiA ECISION -T HEORETIC ODEL SSISTANCEPBVI decision-theoretic assistance problem evaluation performance comparedpolicy rollout sparse sampling methods remains promising research direction.8. Summary Future Workintroduced decision-theoretic framework assistant systems described HGMDPappropriate model selecting assistive actions. computational complexity HGMDPsmotivated definition simpler model called HAMDP, allows efficient myopic heursticstractable special cases.also described approximate solution approach based iteratively estimating agentsgoal selecting actions using myopic heuristics. evaluation using human subjects twogame-like domains show approach significantly help user. also demonstratedreal world folder predictor decision-theoretic framework effective stateart techniques folder prediction.One future direction consider complex domains assistant able series activities parallel agent. Another possible direction assume hierarchical goalstructure user goal estimation context. Recently, assistantship modelextended hierarchical relational settings (Natarajan et al., 2007) including parameterizedtask hierarchies conditional relational influences prior knowledge assistant. priorknowledge would relax assumption user MDP solved tractably. knowledgecompiled underlying Dynamic Bayesian network, Bayesian network inference algorithms used infer distribution users goals given sequence atomic actions.parameters users policy estimated observing users actions.framework naturally extended case environment partially observable agent and/or assistant. requires recognizing actions taken gatherinformation, e.g., opening fridge decide make based available. Incorporating sophisticated user modeling includes users forgetting goals, paying attentionimportant detail, and/or changing intentions would extremely important buildingpractical systems. assistive technology also useful assistant quickly learnnew tasks expert users transfer knowledge novice users training.Acknowledgementsmaterial based upon work supported Defense Advanced Research Projects Agency(DARPA), Department Interior, NBC, Acquisition Services Division, Contract No. NBCHD030010. opinions, findings, conclusions recommendations expressedmaterial authors necessarily reflect views DARPA. AlanFern Prasad Tadepalli gratefully acknowledge following grants: NSF IIS-0964705 ONRN00014-11-1-0106. Sriraam Natarajan thanks Army Research Office grant number W911NF-13-10432 Young Investigator Program.Appendix A. Proof Theorem 7According theory POMDPs, optimal action POMDP maximizes sumimmediate expected reward value resulting belief state (of assistant) (Kaelbling,99fiF ERN , NATARAJAN , J UDAH , & TADEPALLILittman, & Cassandra, 1998). agent policy deterministic, initial goal distributionIG history agent actions states H fully captures belief state agent. LetV (IG , H) represent value current belief state. value function belief stategiven following Bellman equation, H 0 stands history assistantsaction hi agents action aj .V (IG , H) = max E(R((s, hi ), g, aj )) + V (IG , H 0 )hiH0(4)Since one agents action (s, g), agent action aj , subsequent state s0value depend hi . Hence best helper action h assistant given by:h (IG , H) = arg max E(R((s, hi ), g, (s, g)))hiX= arg maxIG (g)I(ai (s, g))higC(H)= arg max IG (C(H) G(s, ai ))hiC(H) set goals consistent current history H, G(s, ai ) set goalsai good state s. I(ai (s, g)) indicator function = 1 ai (s, g).Note h exactly myopic policy. 2Appendix B. Proof Lemma 1worst-case regret pair (s, G) HAMDP given following Bellman equation.assuming G set possible goals agent current state s. Regret(s, G) = 0terminal state goals G satisfied s. Otherwise, Regret(s, G) = mini maxj6=i{Regret(si , Gi ), 1 + Regret(sj , Gj ))} (si , Gi ) (sj , Gj ) Children((s, G)).outer min due assistant picking helper action goal Gi maximizereward inner max due agent either accepting it, picking different goalminimize reward. proof induction. node trajectory tree represents stateset goals G state optimal path.Basis: (s, G) leaf node, either terminal state goals G satisfied s. Hencerank equals reward 0.Inductive step: Suppose induction true children (s, G). consider twocases.Case 1. unique child (s, G) representing (s1 , G1 ) highest regret amongchildren. inductive hypothesis, rank((s1 , G1 )) = regret(s1 , G1 ). assistant chooseshelper action corresponds (s1 , G1 ), agent choose actions yield lowerregret worst case. Choosing helper action would increase regret, sinceagent could choose a1 add 1 regret. have, regret(s, G)= regret(s1 , G1 ) =rank((s1 , G1 )) = rank((s, G)).Case 2. least two children (s1 , G1 ) (s2 , G2 ) (s, G) highest rankamong children. inductive hypothesis, rank((s1 , G1 )) = rank((s2 , G2 )) = regret(s1 , G1 )= regret(s2 , G2 ). agent increase regret 1 choosing goal G2assistant chooses G1 vice versa. Hence, regret(s, G)= 1+regret(s1 , G1 ) = 1+rank((s1 , G1 )) =100fiA ECISION -T HEORETIC ODEL SSISTANCErank((s, G)).Hence cases, shown regret(s, G) rank((s, G)). 2Appendix C. Proof Theorem 9first show problem NP. build tree representation history-dependent policyinitial state. Every node tree represeted triple (s, i, G), state,G set goals good path, index helper action chosenpolicy node. root node corresponds possible initial state initial goalset IG . children node tree represent possible successor nodes (sj , j, Gj ) reachedagents response hi , whether accepting hi executing ai executing actions.children resulting ai called accepted, latter called rejected. Notemultiple children result action dynamics function agentsgoal.guess policy tree check maximum regret, i.e. maximum numberrejected children path root leaf, within bounds. verify optimalpolicy tree polynomial size note number leaf nodes upper bounded |G|maxg N (g), N (g) number leaf nodes generated goal g. estimate N (g),start root navigate downwards. node contains g goal set,accepted child contains g, child reached g. not,misprediction k children reached. Hence, number nodes reached ggrows geometrically number mispredictions. Theorem 6, sincelog |G| mispredictions path, N (g) k log2 |G| = k logk |G| log2 k = |G|log2 k . Hencetotal number leaf nodes tree bounded |G|1+log k , total number nodestree bounded m|G|1+log k , number steps horizon. Sincepolynomial problem parameters, problem NP.show NP-hardness, reduce 3-SAT given problem. consider 3-literal clauseCi propositional formula possible goal. rest proof identicalTheorem 1 except variables set assistant since universal quantifiers.agent rejects setting last variable clause clause evaluates 0.worst regret goal 0 iff 3-SAT problem satisfying assignment. 2ReferencesAmbite, J. L., Barish, G., Knoblock, C. A., Muslea, M., Oh, J., & Minton, S. (2002). Gettingthere: Interactive planning agent execution optimizing travel. ProceedingsFourteenth Conference Innovative Applications Artificial Intelligence, pp. 862869.Atkeson, C. G., & Schaal, S. (1997). Learning tasks single demonstration. ProceedingsIEEE International Conference Robotics Automation, pp. 17061712.Bao, X., Herlocker, J. L., & Dietterich, T. G. (2006). Fewer clicks less frustration: reducingcost reaching right folder. Proceedings Eleventh International ConferenceIntelligent User Interfaces, pp. 178185.Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-Dynamic Programming. Athena Scientific.101fiF ERN , NATARAJAN , J UDAH , & TADEPALLIBlaylock, N., & Allen, J. F. (2004). Statistical goal parameter recognition. ProceedingsFourteenth International Conference Automated Planning Scheduling, pp. 297305.Boger, J., Poupart, P., Hoey, J., Boutilier, C., Fernie, G., & Mihailidis, A. (2005). decisiontheoretic approach task assistance persons dementia. Proceedings Nineteenth International Joint Conference Artificial Intelligence, pp. 12931299.Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptionscomputational leverage. Journal Artificial Intelligence Research, 11, 194.Bui, H., Venkatesh, S., & West, G. (2002). Policy recognition abstract hidden markov models.Journal Artificial Intelligence Research, 17, 451499.Cassandra, A. R. (1998). Exact approximate algorithms partially observable Markov decision processes. Ph.D. thesis, Brown University.Charniak, E., & Goldman, R. (2013). Plan recognition stories life. CoRR, abs/1304.1497.Chu, Y., Song, Y., Kautz, H., & Levinson, R. (2011). start thingdo? interactive activity recognition prompting. Proceedings Twenty-Fifth AAAIConference Workshop Artificial Intelligence Smarter Living, pp. 1521.Clouse, J. A., & Utgoff, P. E. (1992). teaching method reinforcement learning. ProceedingsNinth International Workshop Machine Learning, pp. 92110.Cohen, W. W., Carvalho, V. R., & Mitchell, T. M. (2004). Learning classify email speech acts.Proceedings Conference Empirical Methods Natural Language Processing, pp.309316.Cypher, A. (1993). Watch Do: Programming Demonstration. MIT Press.Doshi, P., & Gmytrasiewicz, P. (2004). particle filtering algorithm interactive POMDPs.Proceedings Workshop Modeling Agents Observations, pp. 8793.Dragunov, A. N., Dietterich, T. G., Johnsrude, K., McLaughlin, M., Li, L., & Herlocker, J. L. (2005).Tasktracer: desktop environment support multi-tasking knowledge workers. Proceedings Tenth International Conference Intelligent User Interfaces, pp. 7582.Driessens, K. (2002). Adding guidance relational reinforcement learning. Third FreiburgLeuven Workshop Machine Learning.Ehrenfeucht, A., & Haussler, D. (1989). Learning decision trees random examples. Information Computation, 82(3), 231246.Gal, Y., Reddy, S., Shieber, S., Rubin, A., & Grosz, B. (2012). Plan recognition exploratorydomains. Artificial Intelligence, 176(1), 22702290.Geffner, H., & Bonet, B. (1998). Solving large POMDPs using real time dynamic programming.Proceedings AAAI Fall Symposium POMPDs.Ginsberg, M. L. (1999). GIB: Steps Toward Expert-Level Bridge-Playing Program. Proceedings Sixteenth International Joint Conference Artificial Intelligence, pp. 584589.Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithmsfactored MDPs. Journal Artificial Intelligence Research, 19, 399468.102fiA ECISION -T HEORETIC ODEL SSISTANCEHorvitz, E., Breese, J., Heckerman, D., Hovel, D., & Rommelse, K. (1998). lumiere project:Bayesian user modeling inferring goals needs software users. ProceedingsFourteenth Conference Uncertainty Artificial Intelligence, pp. 256265.Hui, B., & Boutilier, C. (2006). Whos asking help?: Bayesian approach intelligent assistance. Proceedings Eleventh International Conference Intelligent User Interfaces,pp. 186193.Johnson, D., Cuijpers, R., Juol, J., Torta, E., Simonov, M., Frisiello, A., Bazzani, M., Yan, W.,Weber, C., Wermter, S., et al. (2013). Socially assistive robots: comprehensive approachextending independent living. International Journal Social Robotics, 6(2), 195211.Johnson, M. (2014). Inverse optimal control deterministic continuous-time nonlinear systems.Ph.D. thesis, University Illinois Urbana-Champaign.Kaelbling, L., Littman, M., & Cassandra, A. (1998). Planning acting partially bservablestochastic domains. Artificial Intelligence, 101(1-2), 99134.Kearns, M. J., Mansour, Y., & Ng, A. Y. (1999). sparse sampling algorithm near-optimalplanning large markov decision processes. Proceedings Sixteenth InternationalJoint Conference Artificial Intelligence, pp. 13241331.Konidaris, G., Kuindersma, S., Grupen, R., & Barto, A. (2012). Robot learning demonstrationconstructing skill trees. International Journal Robotics Research, 31(3), 360375.Kullback, S., & Leibler, R. (1951). information sufficiency. Annals MathematicalStatistics, 22(1), 7986.Kurniawati, H., Hsu, D., & Lee, W. (2008). Sarsop: Efficient point-based POMDP planningapproximating optimally reachable belief spaces. Proceedings Robotics: ScienceSystems IV.Lau, T., Wolfman, S., Domingos, P., & Weld, D. (2003). Programming demonstration usingversion space algebra. Machine Learning, 53(1-2), 111156.Lieberman, H. (2009). User interface goals, AI opportunities. AI Magazine, 30(3), 1622.Littlestone, N. (1988). Learning quickly irrelevant attributes abound: new linear-thresholdalgorithm. Machine Learning, 2(4), 285318.Littman, M. L. . (1996). Algorithms Sequential Decision Making. Ph.D. thesis, Brown University.Mahadevan, S., Mitchell, T. M., Mostow, J., Steinberg, L. I., & Tadepalli, P. (1993). apprenticebased approach knowledge acquisition.. Artificial Intelligence, 64(1), 152.Mitchell, T. M., Caruana, R., Freitag, D., J.McDermott, & Zabowski, D. (1994). Experiencelearning personal assistant. Communications ACM, 37(7), 8091.Moore, A. W., & Atkeson, C. G. (1993). Prioritized sweeping: Reinforcement learning lessdata less time. Machine Learning, 13, 103130.Mundhenk, M. (2001). complexity planning partially-observable Markov DecisionProcesses. Ph.D. thesis, Friedrich-Schiller-Universitdt.103fiF ERN , NATARAJAN , J UDAH , & TADEPALLIMyers, K., Berry, P., Blythe, J., Conleyn, K., Gervasio, M., McGuinness, D., Morley, D., Pfeffer,A., Pollack, M., & Tambe, M. (2007). intelligent personal assistant task timemanagement. AI Magazine, Vol. 28, pp. 4761.Natarajan, S., Tadepalli, P., & Fern, A. (2007). relational hierarchical model decision-theoreticassistance. Proceedings Seventeenth Annual International Conference InductiveLogic Programming, pp. 175190.Papadimitriou, C., & Tsitsiklis, J. (1987). complexity Markov Decision Processes. Mathematics Operations Research, 12(3), 441450.Pineau, J., Gordon, G., & Thrun, S. (2003). Point-based value iteration: anytime algorithmPOMDPs. Proceedings Eighteenth International Joint Conference ArtificialIntelligence, pp. 1025 1030.Porta, J., Vlassis, N., Spaan, M., & Poupart, P. (2006). Point-based value iteration continuousPOMDPs. Journal Machine Learning Research, 7, 23292367.Pynadath, D. V., & Wellman, M. P. (2000). Probabilistic state-dependent grammars plan recognition. Proceedings Sixteenth Conference Uncertainty Artificial Intelligence,pp. 507514.Refanidis, I., Alexiadis, A., & Yorke-Smith, N. (2011). Beyond calendar mashups: Intelligent calendaring. Proceedings Twenty-First International Conference Automated PlanningScheduling System Demonstrations.Shani, G., Pineau, J., & Kaplow, R. (2013). survey point-based POMDP solvers. AutonomousAgents Multi-Agent Systems, 27(1), 151.Singh, S. P., Litman, D. J., Kearns, M. J., & Walker, M. A. (2002). Optimizing dialogue management reinforcement learning: Experiments njfun system.. Journal ArtificialIntelligence Research, 16, 105133.Skaanning, C., Jensen, F. V., & Kjaerulff, U. (2000). Printer troubleshooting using bayesian networks. Proceedings Thirteenth International Conference Industrial Engineering Applications Artificial Intelligence Expert Systems, pp. 367379.Varakantham, P., Maheswaran, R. T., & Tambe, M. (2005). Exploiting belief bounds: practicalPOMDPs personal assistant agents. Proceedings Fourth Internation ConferenceAutonomous Agents Multiagent Systems, pp. 978985.Walker, M. A. (2000). application reinforcement learning dialogue strategy selectionspoken dialogue system email. Journal Artificial Intelligence Research, 12, 387416.Yorke-Smith, N., Saadati, S., Myers, K., & Morley, D. (2012). design proactive personalagent task management. International Journal Artificial Intelligence Tools, 21(1), 90119.104fiJournal Artificial Intelligence Research 50 (2014) 923970Submitted 06/14; published 08/14Belief Tracking Planning Sensing: Width,Complexity ApproximationsBlai Bonetbonet@ldc.usb.veDepartamento de ComputacionUniversidad Simon BolvarCaracas, VenezuelaHector Geffnerhector.geffner@upf.eduICREA & Universitat Pompeu FabraRoc Boronat 13808018 Barcelona, SpainAbstractconsider problem belief tracking planning setting states valuations set variables partially observable, beliefs stand setsstates possible. problem intractable worst case,recently shown deterministic conformant contingent problems, belief tracking exponential width parameter often bounded small. work,extend results two ways. First, introduce width notion appliesnon-deterministic problems well, develop factored belief tracking algorithm exponential problem width, show applies existing benchmarks. Second,introduce meaningful, powerful, sound approximation scheme, beam tracking,exponential smaller parameter, problem causal width, much broader applicability. illustrate value algorithm large instances problemsBattleship, Minesweeper, Wumpus, yields state-of-the-art performancereal-time.1. IntroductionPlanning incomplete information formulated search problem belief spacetwo issues need addressed: keeping track beliefs, searching goalbelief (Bonet & Geffner, 2000). two tasks intractable worst casecompact representations, approach adopted recent conformantcontingent planners beliefs handled using SAT, regression techniques, logicalnormal forms CNF, DNF, OBDDs, search goal beliefs guideddomain-independent heuristics (Bertoli, Cimatti, Roveri, & Traverso, 2001; Hoffmann &Brafman, 2006; Bryce, Kambhampati, & Smith, 2006; To, Pontelli, & Son, 2011; Shani &Brafman, 2011; Brafman & Shani, 2012).Recently, complexity belief tracking deterministic conformant contingentplanning shown exponential problem width parameter oftenbounded small (Palacios & Geffner, 2009; Albore, Palacios, & Geffner, 2009).bound follows family translations developed compiling planning problemsbeliefs planning problems states. translations exponential problemc2014AI Access Foundation. rights reserved.fiBonet & Geffnerwidth, deterministic conformant problems result problems solvedclassical planners.difficulty extending results Palacios, Albore, Geffner nondeterministic setting consequence special role played initial situationdeterministic problems. case, uncertainty, particular, uncertaintyobservations, action preconditions, goals, one matterscomplete planner, result uncertainty initial situation. nondeterministic setting, hand, uncertainty produced dynamically resultapplication non-deterministic actions. Moreover, uncertain initial situationalways modeled fully known initial situation dummy non-deterministicaction, opposite transformation simple. Indeed, non-deterministic effectscompiled deterministic effects conditional value hidden variables,number hidden variables required must grow planning horizon(Weld, Anderson, & Smith, 1998; Albore, Ramirez, & Geffner, 2010).aim work study computational complexity belief trackingterms novel width parameters apply deterministic non-deterministicplanning problems, formulation practical approximate belief tracking algorithmsefficient effective even problems large width. achieveconsidering two decomposition schemes belief tracking, three algorithms baseddecompositions. precisely, introduce:1. width notion planning close correspondence notion introducedPalacios, Albore, Geffner applies non-deterministic problemswell.2. first belief tracking algorithm, factored belief tracking, sound completedeterministic non-deterministic problems P , runs time spaceexponential problem width w(P ). algorithm based decompositionproblem P projected subproblems PX , one every goal preconditionvariable X, one including variables relevant X.3. second belief tracking algorithm, causal belief tracking, based alternativedecomposition scheme, subproblems PX defined every goal, precondition,observable variable X, one including variables causally relevantX. algorithm sound complete large meaningful class problems,still time exponential problem width, space exponentialcausal width problem often much smaller.4. final belief tracking algorithm, beam tracking sound incomplete approximation causal belief tracking, often practical enough, even problemslarge widths, runs time space exponential problem causalwidth.power last algorithm, beam tracking, shown empirically largeinstances problems Minesweeper, Battleship, Wumpus, state-of-the924fiBelief Tracking Planning Sensingart performance obtained real-time combining belief tracking algorithmsimple heuristics action selection.1organization paper follows structure, preceded overviewrelevant notation background, followed description experiments,discussion related work, summary. paper integrates results two conferencepapers (Bonet & Geffner, 2012b, 2013), providing proofs additional details. workrelated proposals tractable forms belief tracking logical probabilisticframeworks (Doucet, Freitas, Murphy, & Russell, 2000; Amir & Russell, 2003), yettwo key differences. One start exact account used determinecertainty whether goal achieved action applicable. secondbelief tracking accounts planning complete formulas. ordersound complete planner, beliefs observations, action preconditions,goals required. important observations, action preconditions,goals given, structure actions, sensors, goals exploitedtrack beliefs efficiently. observation implicit lazy belief trackingschemes planning incomplete information appeal SAT-solvers (Hoffmann &Brafman, 2006) regression (Shani & Brafman, 2011). Well say related workSection 12.2. Modelmodel planning sensing simple extension model conformantplanning goal achieved certainty spite uncertainty initialsituation action effects (Goldman & Boddy, 1996; Smith & Weld, 1998). modelconformant planning characterized tuple = hS, S0 , SG , A, Ffinite state space,S0 non-empty set possible initial states, S0 S,SG non-empty set goal states, SG S,set actions A(s) denoting sets actions applicable S,F non-deterministic state-transition function F (a, s) denotes nonempty set possible successor states follow action s, A(s).solution conformant model action sequence maps possible initial stategoal state. precisely, = ha0 , . . . , an1 conformant plan possiblesequence states s0 , s1 , . . . , sn s0 S0 si+1 F (ai , si ), = 0, . . . , n 1,action ai applicable si sn goal state.Conformant planning cast path finding problem beliefs, definedsets states deemed possible time point (Bonet & Geffner, 2000).initial belief b0 S0 , belief ba results action belief state b is:ba = {s0 | b s0 F (a, s)} ,(1)1. real-time animation algorithm several instances Minesweeper seen https://www.youtube.com/watch?v=U98ow4n87RA, source code graphical interfacesobtained http://code.google.com/p/belief-tracking.925fiBonet & Geffneraction applicable b applicable state b. formulation,conformant plan action sequence maps initial belief b0 goal belief bG ;i.e., set goal states.Contingent planning planning sensing planning uncertaintyfeedback. model contingent planning model conformant planning extendedsensor model. sensor model function O(s, a) mapping state-action pairsobservations tokens o. expression O(s, a) means token possibleobservation true state system last action done.observed token provides partial information true possibly hidden systemstate token may possible different states. two different tokens o1o2 belong O(s, a), means either one observedlast action. Sensing deterministic noiseless O(s, a) contains one token, elsenon-deterministic noisy. contingent model similar POMDPs (Kaelbling,Littman, & Cassandra, 1999) uncertainty encoded sets states ratherprobability distributions.Executions contingent setting sequences ha0 , o0 , a1 , o1 , . . .i pairs actionsai observations oi . b = bi belief state action ai applied oitoken observed, belief ba action = ai given (1),belief bi+1 = boa follows observing token is:boa = {s | ba O(s, a)} .(2)execution ha0 , o0 , a1 , o1 , . . .i possible starting initial belief b0 , actionai applicable belief bi (i.e., ai A(s) bi ), 0, belief biempty.off-line contingent planning, action selection strategy sought ensurespossible executions end goal belief. on-line contingent planning, actionselection strategy sought ensures single execution resultsinteraction real system simulator, ends goal belief. cases,action selection strategy expressed partial function beliefs, called policy,(b) action belief b. function partialdefined initial belief b0 non-goal beliefs b; namely,reached b0 off-line planning, reachedb0 on-line planning.3. LanguageSyntactically, conformant problems expressed compact form setstate variables, convenience assume multi-valued.2 precisely,conformant planning problem tuple P = hV, I, A, Gi V stands problemvariables X, one finite discrete domain DX , set clausesV -literals defining initial situation, set actions, G set V -literalsdefining goal. Every action precondition P re(a) given set V -literals,2. Multi-valued variables compiled boolean variables compilation affects syntacticstructure problem. principle, structure could recovered boolean encodingswould result complex formulation.926fiBelief Tracking Planning Sensingset conditional effects C E1 | . . . |En C Ei sets (conjunctions)V -literals. conditional effect non-deterministic n > 1; else n = 1 effectdeterministic.problem P = hV, I, A, Gi defines conformant model S(P ) = hS, S0 , SG , A, F i,set possible valuations variables V , S0 SG sets valuationssatisfy G respectively, A(s) set operators whose preconditions trues, F (a, s) non-deterministic transition function results collectingsuccessor states may follow selecting one head Ei conditionaleffect C E1 | . . . |En whose body C true s.3Contingent problems described extending syntactic description conformant problems compact encoding sensor model. this, assume setV 0 observable multi-valued variables , necessarily disjoint state variablesV (i.e., state variables may observable), formulas Wa (Y = y) statevariables, action possible value observable variable .formula Wa (Y = y) implicitly encodes states observation literal =possible last action executed. formulas Wa (Y = y) differentvalues DY must logically exhaustive, every state-action pair must give riseobservation = y. addition, formulas Wa (Y = y) different valueslogically exclusive, every state-action pair gives rise single observation =sensing deterministic. state variable X observable, Wa (X = x)formula X = x.contingent problem P tuple P = hV, I, A, G, V 0 , W defines contingentmodel made conformant model hS, S0 , SG , A, F determined first fourcomponents P , sensor model O(a, s) determined last two components,O(a, s) iff valuation observable variables V 0 =true formula Wa (Y = y) W true DY .standard language representing contingent problems compact form featuring incomplete information, non-deterministic actions sensors. twodistinctive features relation similar languages use multi-valued variables,distinction state observable variables.illustration, X encodes position agent, encodes positionobject seen agent X = , observable variableZ {Y es, N o} encoding whetherobject seen agentWW not, definedformulas Wa (Z = es) = lD (X = lY = l), Wa (Z = N o) = lD (X = lY = l),set possible locations action. deterministicsensor. non-deterministic sensor could used if, example, agent cannot detect0presenceW object certain locations l . this, suffices pushdisjunct lD0 (X = l) formulas characterizing Wa (Z = es) Wa (Z = N o),two observations Z = es Z = N would possible agentposition l D0 .Since conformant problem hV, I, A, Gi expressed contingent problemhV, I, A, G, V 0 , W one (dummy) observable variable Z, Z/ V domain3. conditional effects must consistent sense explained below.927fiBonet & GeffnerDZ = {>}, observation model Wa (Z = >) = true every action a, focusgeneral contingent problem.Likewise, convenience, variable boolean, often represent literals= true = f alse . Similarly, variable observable, unless statedotherwise, assume observation model deterministic formulaWa (Y = f alse) becomes complement formula Wa (Y = true).4. Belief Tracking Problem Flat Belief Tracking Algorithmexecution problem P = hV, I, A, G, V 0 , W sequence ha0 , o0 , a1 , o1 , . . .iactions ai observations oi ai observation oi fullvaluation observation variables V 0 . execution ha0 , o0 , . . . , , possibleproblem P non-empty belief state b0 , generates sequence beliefs b0 , . . . , bnpreconditions action ai true belief bi , belief statesbi empty. problem belief tracking contingent planning problemdetermining execution possible final belief state achieves goal:Definition 1. Belief tracking planning (BTP) problem determining whetherexecution ha0 , o0 , a1 , o1 , . . .i planning problem P = hV, I, A, G, V 0 , W possible,so, whether resulting belief state makes goal G true.complete planner needs solve problem determining actions applicable given execution, observations may result, whether goalachieved. machinery develop aimed slightly generalbelief tracking problem generalized executions: executions ha0 , o0 , a1 , o1 , . . .iobservations oi partial rather full valuations observable variables. Moreover, suffices consider generalized executions observationsvaluations single observable variable. observations oi representedobservation literals `i :Definition 2. Generalized belief tracking planning (GBTP) problem determining whether generalized execution ha0 , `0 , a1 , `1 , . . .i planning problem P =hV, I, A, G, V 0 , W possible, so, whether achieves given goal, precondition,observation literal.Given procedure deciding GBTP, simple decide BTP executioncalling procedure deciding GBTP generalized execution 0 replacesobservation oi sequence observation literals true oi separatedNO-OP actions (actions effects).Proposition 3. BTP polynomial-time reducible GBTP.interest belief tracking planning, find convenient focusgeneralized problem, none belief update equations algorithms sensitivedistinction. simplicity, however, talk belief tracking, makeexplicit distinctions BTP GBTP, normal generalizedexecutions, needed.928fiBelief Tracking Planning Sensingplain solution belief tracking problem given updates expressedEqs. 1 2, belief states explicitly represented sets states, states fullvaluations state variables, actions, transition function, observationsobtained syntactic representation problem:Definition 4. flat belief tracking algorithm execution ha0 , o0 , a1 , o1 , . . .iproblem P , starts belief b0 contains states satisfy initial situation,setting next belief state bi+1 boa using (1) (2) b = bi , = ai , = oi .complexity flat belief tracking exponential number state variables. Yet,often state variables add complexity tracking beliefs. Syntactically,happens state variable X initially known, variables causallyrelevant X (see below) initially known well, neither X variablecausally relevant X appears head non-deterministic effect. sayvariables determined value every reachable belief known, fullypredicted preceding actions preceding values. example, variableencodes position agent Wumpus game determined, initialvalue known effect actions variable deterministic dependsprevious value.Formally, define set variables determined problemlargest set state variables X problem initially known everystate variable X 0 causally relevant X belongs set. set variableseasily identifiable low polynomial time. complexity flat belief trackingexpressed follows:Theorem 5. Flat belief tracking exponential |VU |, VU = V \ VK VKset state variables determined problem.Given result, first question arises bad naive approach flat belieftracking. Interestingly, following result decision problem shows flat belieftracking bad worst case:Theorem 6. BTP GBTP Turing complete class PNP .is, BTP GBTP decided polynomial time using oracle NP (SAT,example), every decision problem decided polynomial timeoracle, decided polynomial time oracle BTP GBTP.complexity class PNP includes classes NP coNP, contained PSPACE(Sipser, 2006).5. Structure Widthpossible improve complexity flat belief tracking specific problemexploiting structure problem. introducing graph capturesstructure, convenient make explicit assumptions restrictgenerality approach make definitions simpler. First, assumeformula encoding initial situation contains positive negative literals; i.e., unitclauses only. restrictive assumption since set clauses encoded929fiBonet & Geffnerhelp dummy observations. Second, assume non-deterministic effectsinvolve one variable heads. Again, always achieved adding extravariables effects. example, non-deterministic effect X Z | Zaction replaced deterministic effects X W Z X W Z,along non-deterministic effect true W | W , W new random booleanvariable initially unknown changes randomly. Third, assume problemconsistent, meaning initial situation logically consistent initialbelief state b0 empty, effects action consistentheads deterministic conditional effects applicable reachable state s, alongchoice heads non-deterministic conditional effects applicables, jointly consistent.4 Last, assume every observable variable relevantvariable appearing precondition goal, notion relevance spelledbelow. Observable variables dont comply condition eliminatedproblem relevant information loss.5.1 Relevance Widthvariable X, whether state variable, observable variable, both, immediatecauses X defined follows:Definition 7. variable X immediate cause variable problem P , writtenX Ca(Y ), iff X 6= , either X occurs body C conditional effect CE1 | |En occurs head Ei , 1 n, observable variable Xoccurs formula Wa (Y = y) DY action a.Basically, X immediate cause uncertainty X may affectuncertainty directly, variables. X necessarily immediatecause X appears precondition action affects , preconditionsmust known certainty, hence, propagate uncertainty. notioncausal relevance given transitive closure immediate cause relation:Definition 8. X causally relevant P X = , X Ca(Y ), X causallyrelevant variable Z causally relevant .order test whether given literal Z = z known certain executionha0 , a1 , . . . , ai actions conformant setting, possible show oneprogress state variables X causally relevant Z:Proposition 9. Belief tracking deterministic non-deterministic conformant setting exponential maximum number non-determined variables causallyrelevant variable appearing action precondition goal.bound closely related bound obtained Palacios Geffnerdeterministic setting. Indeed, refer number non-determined state variables4. semantic point view, means state s0 possible successor stateaction applicable s, i.e. s0 F (a, s), iff every literal X = x true s0 , X = x headdeterministic non-deterministic conditional effect action whose body true s, X = xtrue s, effect action X = x0 head, x0 6= x, whose bodytrue s.930fiBelief Tracking Planning Sensingcausally relevant X, conformant width X, set width Pmaximum conformant width variables X appear action preconditionsgoals, Proposition 9 simply says belief tracking non-deterministic conformantproblem exponential problem width. width notion, however, exactlyequivalent notion Palacios Geffner used deterministic settingdefined variables rather literals. say distinctionbelow. general, however, two accounts yield similar widths deterministicbenchmarks.contingent setting, variables whose uncertainty may affect variableZ causally relevant Z. situation similar one arisingBayesian networks (Pearl, 1988), relevance flows causally, directionarrows, evidentially, observations direction arrows.Definition 10. X evidentially relevant P X observable variablecausally relevant X.notion relevance captures transitive closure (directional) causal evidential relations:Definition 11. X relevant X causally evidentially relevant , Xrelevant variable Z relevant .Thus, variable X = W1 relevant variable = Wn iff chain variablesWi , 1 n 1, variable Wi causally evidentially relevant nextvariable Wi+1 chain. example, X causally relevant Z,observable variable, relevant Z evidentially relevant X Xcausally relevant Z.Like Bayesian networks, relevance relations understood graph-theoretically.Thus, directed edge Z stands Z immediate cause , Xcausally relevant X 0 directed path X X 0 , X evidentiallyrelevant X 0 X observable variable, directed path X 0X. terms Bayesian networks, relevance relation takes transitive closurecausal evidential relationships, encodes potential dependency givenmay observed, using information certain variables observed (areobservable). Unlike Bayesian networks, means however relevance relationsymmetric. Namely, cause X relevant , automaticallyrelevant X causally relevant observable variable Z, mayitself. context variable set variables problem relevantX:Definition 12. context variable X, Ctx(X), denotes set state variablesproblem relevant X.width variable defined number state variables contextdetermined:Definition 13. width variable X, w(X), |Ctx(X) VU |, VU = V \ VKVK set state variables determined.931fiBonet & Geffnerwidth problem then:Definition 14. width w(P ) conformant contingent problem P , whether deterministic not, maxX w(X) X ranges variables appear goalaction precondition P .relation width complexity expressed as:Theorem 15. Belief tracking P exponential w(P ).proof theorem follows results algorithmachieves complexity bound presented. significance theorem belieftracking planning domains width bounded constant becomes polynomialnumber problem variables. see examples below. complexity boundsimilar ones obtained deterministic conformant contingent problems (Palacios& Geffner, 2009; Albore et al., 2009). main difference new account appliesnon-deterministic problems well. new account simpler general,see, also slightly less tight deterministic domains.6. Examplesillustrate definitions benchmark domains, starting DET-Ring(Cimatti, Roveri, & Bertoli, 2004). domain, ring n roomsagent move forward backward along ring. room windowopened, closed, locked closed. Initially, status windowsknown agent know initial location. domain agentmeans obtaining information status windows position,goal windows locked. plan deterministic conformant problemrepeat n times actions (close, lock, f wd), skipping last f wd action. Alternatively,action f wd replaced action bwd throughout plan. state variablesproblem encode agent location Loc {1, . . . , n}, status window,W (i) {open, closed, locked}, = 1, . . . , n. location variable Loc (causally) relevantwindow variable W (i), window variable W (i) relevant Loc W (k)k 6= i, W (i) causally relevant observable variable. None variablesdetermined largest contexts window variables W (i) include twovariables, W (i) Loc. result width domain 2, independentnumber state variables W (i) grows number rooms n. causalgraph problem, directed edge X means X immediate causeshown Figure 1a.NON-DET-Ring variation domain actions f wd bwdagent non-deterministic effect status windows locked,capturing possibility external events open close unlocked windows.non-determinism effect causal graph variables. result,change effect contexts domain width remains bounded equal2 number rooms n.last version domain considered Cimatti et al. NON-DET-Ring-Key,key required lock windows. initial position key known,932fiBelief Tracking Planning SensingLocLocW (1)W (2)W (n)W (1)(a) DET-RingW (2)KLocW (n)H(b) CONT-NON-DET-Ring-KeyFigure 1: Causal graphs problems DET-Ring (left) CONT-NON-DET-Ring-Key(right). latter, variable H observable tells us whether key heldnot. arc X denotes X immediate cause . graphs, variablespreconditions goals underlined yellow colored, observable variablesenclosed blue circle.yet agent tries collect key room key there, agentkey. conformant plan problem repeat actions pick f wd, ntimes, skipping last f wd action, following plan DET-Ring. NON-DETRing-Key, additional state variable, KLoc {1, . . . , n, hand}, representskey location. agent location Loc relevant KLoc relevant windowvariable W (i). result, size contexts Ctx(W (i)) problem widthincrease 1. width however remains bounded value 3 independentlynumber rooms n.5presence partial observability, analysis similar necessaryconsider relevance relationships arise due presence observable variables.example, one express agent always observe whether holdingkey not, boolean observable variable H (deterministic) observationmodel Wa (H = true) given KLoc = hand, actions a. new relevancerelation among state variables arises adding observable variableLoc KLoc, causally relevant H. Before, Loc relevant KLocway around. Yet affect domain width remains 3n. causal graph resulting domain shown Figure 1b.7. Factored Belief TrackingBelief tracking problem P exponential width w(P ) P . algorithmachieves bound exploits relevance relations encoded variable contextsdecomposing beliefs. particular, variable relevant variable,problem width 1, beliefs variable maintained separately.belief decomposition obtained projecting problem P smaller problems PSset state variables P . Semantically, projected problems PS capturedynamics problem P expressed subset state variables. Syntactically,projected problems PS defined means logical notion projection.5. problem also encoded making holding key precondition rather conditionlocking windows. encoding, variable KLoc longer relevant windowvariables W (i) according definitions, KLoc = hand must known certainty,hence uncertainty windows variables W (i) affected uncertainty KLoc.result encoding, domain width reduces 2.933fiBonet & Geffnerlogical projection formula F subset variables refers formula F 0defined variables S, valuations satisfy F 0 exactlyextended valuations satisfy F (Darwiche & Marquis, 2002). Likewise,projection conditional effect C E 1 | |E n conditional effect CS ES1 | |ESnbody C effects E replaced logical projections CS ESirespectively.Definition 16. projection problem P = hV, I, A, G, V 0 , W set variablesV problem PS = hVS , , , GS , VS0 , WS VS S, GSinitial goal formulas G logically projected variables S,preconditions conditional effects projected S, VS0 V 0 , WS setformulas Wa (Y = y) W logically projected variables S.notion projected planning problem used settingclassical planning introducing class admissible heuristics known pattern databases(Edelkamp, 2001). use richer contingent setting decomposing belieftracking problem P belief tracking problem smaller problems PS obtainedP projecting away state variables P .defining target subproblems PS decomposition, notice variablesstate observable variables P S, belong VS0VS , meaning observable variables projected problem PS .Moreover, formulas variables WS become Wa (Y = y) = trueDY , meaning problem PS , observations = possibley, regardless state last action done. observations thus completelyirrelevant PS effect. case, P PS share set actionsset observations even actions observations PS maydefined smaller set state variables.target subproblems PS defined terms set state variablesrelevant precondition goal variables. Recall assume observablevariable problem relevant action precondition goal, else variablecould safely removed.Definition 17. projection problem P variable X, denoted PX ,projection PS P set variables = Ctx(X), Ctx(X) contextX P ; i.e., set state variables P relevant X.Two basic properties projected problems PX are:Proposition 18. variable X appears goal precondition, number statevariables PX determined bounded w(P ).Proposition 19. execution ha0 , o0 , a1 , o1 , . . .i possible P , also possiblePX state variable X P .b belief results execution P , call bX beliefresults execution projected problem PX . completenessdecomposition global belief b P expressed terms local beliefs bXsubproblems PX . treat beliefs b bX relations database934fiBelief Tracking Planning Sensingstate variables beliefs columns possible combination values(states local states) rows. projection b, set variables thusrepresents combination values variables possible b,join bXnbY represents combination values x sets variablestwo beliefs bX x coincide variables X. example, b contains valuations (states) X = 1, = 1 X = 2, = 2,projection {X} b contain valuations X = 1 X = 2. Likewise, b0 contains= 1, Z = 1 = 1, Z = 2, join bn b0 contain X = 1, = 1, Z = 1X = 1, = 1, Z = 2.Theorem 20. state variable X, let b bX beliefs result executionpossible P PX . Then,X bX = X b .(3)Equation 3 states literal X = x possible true global belief b iffpossible belief bX results execution projected problemPX . exactly type completeness needed planning variableX involved action precondition goal. stronger form completenessformulas, expressednX bX = b ,(4)n stands join operation X ranges precondition goal variablesproblem, needed, actually necessarily true, even statevariables appear context Ctx(X). example, value boolean variableZ initially unknown, variables X initially false, action conditionaleffects Z X Z Z results belief b two states, correspondingterms Z X Z X . X precondition goal variablesrelevant other, projected problem PX contain variablesX Z, projected problem PY contain variables Z. beliefbX resulting execution action PX include local statescorresponding terms Z X Z X, belief PY includelocal states corresponding terms Z Z . Clearly, projection bbX (bY ) variable X (Y ) coincide dictated (3), join two localbeliefs bX yield global belief b would correspond (4); indeed,formula like X false latter former. (3), proveinductively size execution that:Theorem 21. 1) execution possible P iff possible subproblemsPX X precondition goal variable P . 2) execution preconditiongoal variable X, X = x (resp. X 6= x) true b iff X = x (resp. X 6= x) truebX , b bX beliefs result executing P PX respectively.Since plain belief tracking projected problem PX exponential sizePX , bounded w(P ) determined variables excluded, follows that:935fiBonet & GeffnerTheorem 22. Flat belief tracking projected problems PX Xprecondition goal variable P , provides sound complete factored algorithmbelief tracking P time space exponential width P .call algorithm, factored belief tracking. order check whether preconditiongoal literal X = x true execution, factored belief tracking checks whetherX = x true belief bX results execution subproblem PX .execution possible action precondition X = x true bX resultsempty belief subproblem. Theorem 22 thus says factored belief trackingsound complete algorithm BTP time space complexity exponentialproblem width. Indeed, since every observable variable relevant preconditiongoal variable X assumption, every direct cause Z relevant Xevidentially relevant X. Thus, formula Wa (Y = y) evaluated bXdetermine whether observation = necessary, possible impossible applyingaction a. Thus, factored belief tracking also solves generalized BTP problem.illustration Theorem 22, let us go back DET-Ring problems P whosestructure analyzed before. theorem implies order check whether givenpossible execution achieves goal P , sufficient check whether goal literalW (i) = locked, 1 n, achieved execution subproblem PW (i) . Thus,factored belief tracking P done O(n2 ) time since n subproblemsPW (i) , one involving 2 variables: W (i) constant-size domain Locdomain size n.exact situation arises non-deterministic conformant problem NON-DETRing whose causal graph one DET-Ring. hand, NONDET-Ring-Key, subproblems must keep track KLoc variable encoding keylocation, thus belief update operation requires O(n3 ) time, still much betterflat belief tracking P requires time exponential n. complexityresults applies problem longer conformant agent observe whetherholding key not.experimental figures domains shown Table 1, factored belieftracking used combination simple heuristics. experiments runXeon Woodcrest 5140 CPU running 2.33 GHz 8 GB RAM. plannerKACMBP Cimatti et al. uses OBDD-based belief representation cardinalityheuristics, solve problems n = 20 rooms, producing plans 206steps slightly 1,000 seconds NON-DET-Ring-Key. Conformant plannersT0 (Palacios & Geffner, 2009) cannot used problem non-deterministic.Tables 1a 1b show scalability factored belief tracking algorithm contextgreedy best-first search Pheuristic h(b), similar one used Albore, Ramirez,Geffner (2011), h(b) = ni=1 h(bi ), bi belief factor projectedproblem goal variable W (i) representing status ith window, h(bi )representing fraction states bi goal W (i) = locked false. displayedtables, resulting planner scales polynomially, NON-DET-Ring-Key100 rooms, produces plan 1, 111 actions 783.1 seconds. contingentversion problem agent detects key room, CONT-DETRing-Key, policy greedy cardinality heuristic h(b) = maxni=1 |bi | used instead,936fiBelief Tracking Planning Sensingnstepsexp.timenstepsexp.timenavg. stepsavg. time102030405060708090100681382082773454154765456106793557051,0551,4001,7402,0902,3952,7403,0653,410< 0.10.10.93.18.318.634.562.8106.4171.01020304050607080901001181982784884384685436166821,1117701,2201,6703,2102,5702,6603,0803,4803,8807,220< 0.10.84.215.234.452.2100.6172.9285.6783.1102030405060708090100326.8 4.31, 036.0 13.52, 068.0 26.53, 462.9 47.25, 130.7 71.07, 070.9 100.99, 334.1 127.611, 724.0 162.214, 617.4 204.617, 891.2 252.30.00.10.51.84.49.317.530.650.079.0(a) DET-Ring-Key(b) NON-DET-Ring-Key(c) CONT-DET-Ring-KeyTable 1: Results conformant contingent Ring problems obtained combining factored belief tracking simple heuristics. data point panel (c) contingentproblem average (and sample standard deviation) 1,000 random instances. Timesseconds. column exp. contains number expansions.ties broken randomly, bi belief factor goal variable W (i).seen Table 1c, resulting planner runs polynomial time solve problems100 rooms. Thus, heuristic policy weak, long executions result,belief tracking problem efficient scales well.8. Causal Belief TrackingFactored belief tracking exponential problem width. many problems, however,width may high method usable practice. illustration,consider problem P state variables X1 , . . . , Xn+1 , observable variables O1 , . . . ,Oi true iff Xi = Xi+1 . sensors thus Wa (Oi = true) = (Xi = Xi+1 )Wa (Oi = f alse) = (Xi 6= Xi+1 ) actions 1 n. Let us also assumeactions problem may affect Xi variables introducecausal relations among them, state variables appear preconditionsgoals. causal graph problem shown Figure 2. width n + 1state variables interact. Indeed, variable Xi relevant variable Xk ,relevance flowing Xi Xi+1 , vice versa, variables causally relevantobservable variable Oi evidentially relevant both. resultproblem P projected problems PXi coincide denote problem,contexts state variables include state variables.focus different decomposition belief tracking maps problem Psmaller subproblems PXc whose size bounded number state variablescausally relevant given precondition, goal, observation variable. new widthmeasure called causal width problem. problem shown Figure 2width n + 1 causal width 2. explore belief tracking algorithmsexponential problem causal width analyze conditions937fiBonet & GeffnerX1X2X3XnO1O2O3Xn+1Figure 2: Causal graph 2-layer network example state variables X1 , . . . , Xn+1observable variables O1 , . . . , On+1 . immediate causes observable Oivariables Xi Xi+1 . Precondition goal variables appear underlinedyellow box, observable variables appear within blue circle. Since Xi variablesrelevant other, width problem n + 1. hand, sincetwo variables causally relevant precondition, goal, observable variable,causal width problem 2.complete. this, first generalize make explicit decomposition underlyingfactored belief tracking algorithm:Definition 23. decomposition problem P pair = hT, Bi, setvariables X appearing P , called target variables decomposition, Bcollection beams B(X) associated target variable madestate variables P .decomposition = hT, Bi maps P set subproblems PXD , one variableX , corresponds projections P state variables beam B(X).decomposition underlies factored belief tracking is:Definition 24. factored decomposition F = hTF , BF P decompositiontarget variables TF given state variables X appearing action preconditions goals,beams BF (X) given state variables relevant X.Factored belief tracking flat belief tracking applied subproblems determinedfactored decomposition. algorithms introduce next based differentdecomposition:Definition 25. causal decomposition C = hTC , BC P decompositiontarget variables TC given observable variables state variables appearingaction precondition goals, beams BC (X) given state variablescausally relevant X.causal decomposition determines larger number subproblems, subproblemsalso generated observable variables, subproblems smaller beamsBC (X), contain state variables causally relevant X opposedvariables relevant X. causal width problem given sizelargest beam causal decomposition, discounting variables determinedproblem:Definition 26. causal width variable X problem P , wc (X), numberstate variables causally relevant X determined. causal width938fiBelief Tracking Planning SensingP maxX wc (X), X ranges target variables causal decompositionP .first simplest belief tracking algorithm defined causal decompositioncall Decoupled Causal Belief Tracking, runs time spaceexponential problem causal width:Definition 27. Decoupled causal belief tracking (Decoupled CBT) flat belief trackingapplied independently problems PXC determined causal decompositionC = hTC , BC P . subproblem PXC problem P projected variablesBC (X) X TC ; i.e., PXC = PBC (X) .Since causal width never greater width often much smaller, DecoupledCBT runs much faster factored belief tracking general. This, however, comesprice express using expression b denoting projection (the statesthe) belief b variables S.Theorem 28. Decoupled CBT runs time space exponential wc (P ),sound complete. is, target variable X causal decomposition,b bX beliefs resulting execution P PXC respectively,bX BC (X) b necessarily true, bX BC (X) b not.One reason incompleteness beliefs bX associated different targetvariables X assumed independent Decoupled CBT maytrue. Indeed, causal decomposition problem may give rise beam BC (Y )involving variable X, second beam BC (Z) involving variable X anothervariable X 0 . variable observed, X = x may become false,observation Z may lead X 0 = x0 becoming false well. Yet, Decoupled CBT,inference cannot captured information flow across beams. factoreddecomposition situation like cannot happen variable X 0 relevant variableX hence beams contain X necessarily contain X 0 (X 0 relevant Xcausally relevant Z evidentially relevant X).causal decomposition, beams kept small closing relevancerelation, result, beliefs beams longer independent. However,regarding beliefs tables relations, consistency relation among local beliefscausal decomposition enforced means join operation. resultingalgorithm Coupled Causal Belief Tracking, abbreviated simply Causal Belief Tracking:Definition 29. Causal Belief Tracking (CBT) belief tracking algorithm operatescausal decomposition C = hTC , BC setting beliefs b0X time 0 beamBC (X) projection BC (X) initial belief, X TC , successive beliefsbi+1X as:bi+1n{(biY )oa : TC relevant X}(5)X = BC (X)= ai = oi action observation time execution,(biY )oa boa Eqs. 1-2 b = biY .CBT, beliefs tracked independently subproblems PXCcausal decomposition; rather, beliefs first progressed filtered independently,939fiBonet & Geffnermerged projected back onto beams, making consistentother. progression filtering local beliefs causal decomposition performed time space exponential problem causal width, full consistencyoperation captured join-project operation (5) requires time worst caseexponential problem width:Theorem 30. CBT space exponential causal width problem, timeexponential width.CBT sound incomplete. However, range problem CBT complete,unlike Decoupled CBT, large meaningful enough, includes example threedomains considered experiments below: Battleship, MinesweeperWumpus. express completeness conditions CBT introducing notionmemory variables:Definition 31. state variable X memory variable problem P value X kvariable X time point k execution determined uniquely observationvalue X X time point i, k, actions execution, initialbelief state problem.example, static variables memory variables change thusknowing value time point determines value point. Determinedvariables (Section 4) also memory variables since value X k variablesdetermined initial belief actions done time k. Likewise, variablespermutation domains actions permute values variables (Amir & Russell,2003), also memory variables. three sufficient conditions state variablememory variable easy check. problem said causallydecomposable following condition holds:Definition 32. problem P causally decomposable every pair beams BC (X)BC (X 0 ) causal decomposition P non-empty intersection, X 0observation variable, either 1) variables intersection memory variables,2) variable W causal decomposition relevant X X 0whose causal beam BC (W ) contains BC (X) BC (X 0 ).problem causally decomposable, filtering implemented updatesCBT using Equation 5 suffices completeness:Theorem 33. Causal belief tracking always sound complete causally decomposable problems.importance result many meaningful domains whose probleminstances causally decomposable; particular, domains variables appeartwo different beams static (this include Minesweeper), domains variablesappear two different beams either static determined (this includes Wumpus,non-static variable agent location determined), domainshidden non-static state variables appear one beam (this includes Battleshiphidden non-static variables appear intersection beams), caseswell. Sect. 11.4, present variation Wumpus monster movesnon-deterministically grid also instance causally-decomposableproblem.940fiBelief Tracking Planning Sensing9. Approximation: Beam Trackingcausal belief tracking algorithm shows possible track beliefs planningsound complete manner large meaningful class problems, consideringbeliefs subproblems smaller factored decomposition.algorithm, however, space exponential causal width problem,time exponential problem width. global consistency operationenforced (5). Beam tracking final belief tracking algorithm consider:replaces global consistency operation local consistency operationperformed polynomial time. Beam tracking thus approximation causal belieftracking aimed efficient effective rather complete.Definition 34. Beam tracking belief tracking algorithm operates causaldecomposition C = hTC , BC i, setting beliefs b0X time 0 projection initialbelief beam X TC , setting successive beliefs bi+1X two steps. First,set progressed filtered belief ba b = bX , = ai = oi ,ai oi action observation time execution. Then, local formconsistency enforced upon beliefs means following updates fixedpoint reached:i+1(6)bi+1nbi+1)X = BC (X) (bXrefers target variable causal decomposition BC (Y )BC (X) non-empty.filtering represented iterative update Eq. 6 defines form relationalarc consistency (Dechter & Beek, 1997) equality constraints among beams sharingcommon variables enforced polynomial time space size beams. Beamtracking remains sound complete. causally decomposable problems, however,incompleteness sole result replacing global local consistency.10. Extensions, Modeling, Widthtesting beam tracking algorithm empirically, present two simple extensionslanguage contingent planning useful modeling, briefly discussmodeling choices affect causal width problem. first extension allowsuse defined variables preconditions goals; second extension allows usestate constraints restricting possible value combination subsets variables.10.1 Defined Variablesvariable Z domain DZ defined function subset state variablesproblem, function belief variables. example, boolean variableZ defined true two variables X equal, third variable Wknown true. Defined variables Z function set SZ state variablesfunction belief variables, handled action preconditionsgoals introducing beam decomposition includes variables SZalong variables relevant causally relevant them, according whetherdecomposition factored causal. width causal width problem follow941fiBonet & Geffnerthen, before, size largest beam factored causal decompositionsdetermined variables excluded.10.2 State ConstraintsState constraints used restrict value combinations given subsets state variables. game Battleship, example, modeled state variables associatedcells grid representing whether cell part ship, sizeship cell belongs (if any), relative position cell within shipcell belongs (if any), whether ship placed vertically horizontally. state variables, however, independent, indeed, ship size 10horizontally placed cell (0, 0), cells (0, i), {0, 1, . . . , 9} must belong (thesame) ship.Formally, state constraint represented formula C state variablesencoded means dummy observable variable always observedtrue, observed true states C holds; i.e., modelWa (Y = true) = C every action a. implementation, however, pays treatconstraints C relations (the set valuations satisfy C), includejoins beliefs include variables C. causal belief trackingeffect completeness complexity algorithm, beam tracking,changing update (6)i+1n C1nn Cn )n bi+1bi+1X = BC (X) (bX(7)C1 , . . . , Cn state constraints whose variables included BC (X) BC (Y ),makes local consistency stronger effect complexity algorithm. Moreover, one pair beams state constraint, state constraintsincrease causal width problem constant factor 2 most, yeteffective causal width problem change, beams associateddummy observables introduced constraints redundant ignored.later case, using beam tracking, constraints Ci need storedextensional form relations handled intentionally boolean functionstest whether assignment join two beams satisfies constraint.10.3 Modeling Widthcomplexity belief tracking algorithms function width causal widthproblem, turns depends way problem encoded. Often smallchanges encoding drastic effect resulting widths. example,Wumpus problem (Russell & Norvig, 2009), natural define conditionsstench signal received setting observation model to:WWWa (stench = true) = c (pos = c) c0 wumpc0pos encodes agent position, c ranges possible cells, c0 ranges cellsadjacent c, wumpc0 denotes presence wumpus c0 . encoding,however, results beam observable variable stench includes wumpc942fiBelief Tracking Planning Sensingszx,yhitx,ywaterx,ynhitsx,yancx,yhzx,yFigure 3: Causal graph fragment Battleship. Circled variables observableothers state variables. problem one type variable cell (x, y)grid. Causal width problem 5.variables, hence whose size grows grid size. better alternative resultsbeams bounded causal width exploit fact position agent posdetermined. Taking advantage this, observable variable stench replacedobservable variables stenchc , one cell grid, sensors characterizedmodel:Wa (stenchc = true) = (pos = c)Wc0wumpc0 .beams stenchc variables contain four wumpc0 variables, one cellc0 adjacent c. way, causal width Wumpus problem becomes boundedindependent grid size, number wumpus pits (see below).ideaW generalized automated. observation model form Wa (Z =z) = x (x) (x), (x) formula constructed determined variables,replaced observation models Wa (Zx = z) = (x) (x) expandingnumber observable variables. Likewise, multiple observation models Wai (Z = z) =one observable variable Z different actions {ai }iR conveniently replacedobservation models Wai (Zi = z) = , R different observable variables Zi ,different formulas involve different variables. alternatives domain encodingdifference bounded unbounded causal width, hence, whethercomplexity beam tracking grow polynomially exponentially.11. Experimentstested beam tracking large instances Battleship, Minesweeper, Wumpus, combination simple heuristics action selection make use computed beliefs. width problems bounded, hence, neither factoredcausal belief tracking used except small instances. hand,domains small bounded causal widths encodings provided, hencebeam tracking runs efficiently time space. Exact belief trackingdomains difficult (Kaye, 2000; Scott, Stege, & Rooij, 2011), sizesinstances considered much larger used contingent planning. Moreover,domains full contingent solutions. thus compare on-lineplanner relies handcrafted heuristics two reported solvers rely belieftracking algorithms tailored domains. also consider non-deterministic versionWumpus domain. results obtained Xeon Woodcrest 5140 CPUrunning 2.33 GHz 8GB RAM.943fiBonet & Geffner11.1 BattleshipBattleship popular two-player guessing game. standard version consists fourships length 2, 3, 4 5 units secretly placed 10-by-10 grid, shipadjacent diagonally adjacent another. task sink ships firing torpedosspecific cells. fired torpedo, told whether torpedo hits water ship.ship sunk cells hit. problem encoded 6 state variablesper cell (x, y):6 hitx,y tells torpedo fired cell, szx,y tells sizeship occupying cell (0 ship), hzx,y tells ship placed horizontallyvertically (true ship), nhitsx,y tells number hits ship (0ship), ancx,y tells relative position ship cell (0 ship).single observable boolean variable water deterministic sensor model givenWf ire(x,y) (waterx,y = true) = (szx,y = 0). action model complex firingtorpedo (x, y) may cause change variables associated cells (x0 , 0 ).Indeed, denotes maximum size ship (5 standard game), f ire(x, y)includes conditional effects variables referring cells (x0 , 0 ) verticalhorizontal distance units. goal problem achieve equalitynhitsx,y = szx,y cells may contain ship. State constraints usedconstraining sets state variables described above. encoding, causal beamsnever contain 5 variables, even though problem width boundedgrows grid size. Figure 3 shows fragment causal graph Battleship.Table 2 shows results two policies: random policy fires non-fired cellrandom, greedy policy fires non-fired cell likely contain ship.Approximations probabilities obtained beliefs maintained beamtracking.7 difference performance two policies shows beliefsinformative. Moreover, 10 10 game, agent fires 40.0 6.9 torpedosaverage, matching quite closely average results Silver Veness (2010)obtained combination UCT (Kocsis & Szepesvari, 2006) action selection,particle filter (Doucet et al., 2000) hand-tuned domain belief tracking.approach, however, involves 65,000 simulation per action result order 2 secondsper game 10 10 instances, greedy approach takes 0.0096 seconds per game.11.2 Minesweeperobjective Minesweeper clear rectangular minefield without detonating mine.play either opens flags cell. first case, cell contains mine, gameterminated; otherwise integer counting number mines surrounding cellrevealed. initial configuration minesweeper consists n minefield krandomly-placed mines. three standard difficulty levels gamemade 8 8, 16 16 16 30 boards 10, 40 99 mines respectively.6. rich encoding allows accommodate observation ship fully sunk.experiments, however, observation used order compare results reportedSilver Veness (2010).7. Probabilities events defined variables beam obtained ratio number statesbeam satisfy event total number states beam.944fiBelief Tracking Planning Sensingavg. time perdimpolicy#ships#torpedosdecisiongame10 1020 2030 3040 40greedygreedygreedygreedy48121640.0 6.9163.1 32.1389.4 73.4723.8 129.22.4e-46.6e-41.2e-32.1e-39.6e-31.0e-14.9e-11.510 1020 2030 3040 40randomrandomrandomrandom48121694.2 5.9387.1 13.6879.5 22.31,572.8 31.35.7e-57.4e-58.5e-59.5e-55.3e-32.8e-27.4e-21.4e-1Table 2: Results Battleship. table contains results greedy randompolicies described text. 10 10 board, 4 ships sizes 2, 3, 4 5.size board increased n, number ships size gets multipliedn. Average sample standard deviation number torpedos required sunkships, calculated 10,000 random instances board, shown. Average timesseconds.problem encoded 3mn boolean state variables minex,y , openedx,yf laggedx,y denote presence/absence mine cell (x, y) whether cellopened flagged, mn observable variables obsx,y domain = {0, . . . , 9}.two type actions open(x, y) f lag(x, y) first precondition effect f laggedx,y openedx,y , second precondition minex,yeffect f laggedx,y . sensor model given formulas specify integeragent receives opening cell terms status minex0 ,y0 variablessurrounding cells. formulas are:Wopen(x,y) (obsx,y = 9) = minex,y ,Wopen(x,y) (obsx,y = k) = minex,yWtN (x,y,k) ,0 k < 9 ,Wopen(x,y) (obsx0 ,y0 = k) = true ,(x0 , 0 ) 6= (x, y) 0 k 9 ,Wf lag(x,y) (obsx0 ,y0 = k) = true ,(x0 , 0 ) 0 k 9 ,N (x, y, k) terms 8 cell variables minex0 ,y0 surrounding cell (x, y)make exactly k literals true. initial situation, variables openedx,yf laggedx,y false minex,y unknown. goal problem get disjunction f laggedx,y openedx,y cell (x, y) without triggering explosion.beams result factored decomposition contain 3mn state variables, making beams identical resulting unbounded width 3mn. causalwidth, hand, 9 causal beams openedx,y f laggedx,y identicalcontain 3 variables, beams obsx,y contain 9 minex0 ,y0 variablescells (x0 , 0 ) surround cell (x, y) along variable minex,y . Figure 4contains fragment causal graph Minesweeper.945fiBonet & Geffnerminex0 ,y0minex,yf laggedx,yopenedx,yobsx,yFigure 4: Sketch causal graph Minesweeper. observable variables obsx,ystate variables minex,y , f laggedx,y openedx,y cell (x, y). cell (x0 , 0 )represents one adjacent cells (x, y). Since 8 cells, causal widthproblem 9.avg. time perdim#minesdensity%win#guessdecisiongame8816 1616 3032 6410409932015.6%15.6%20.6%15.6%83.479.835.980.36066702,4766728.3e-31.2e-21.1e-21.3e-20.211.422.862.89Table 3: Results Minesweeper. table contains results three standard levelsgame plus larger instance. Average results 1,000 runs shown. Averagetimes seconds.Table 3 shows results three standard levels game much largerinstance. Battleship, greedy policy used action selection makes use beliefscomputed beam tracking, flagging opening cell certain content, elseselecting cell lowest probability containing mine opening it,probabilities approximated beliefs beams indicated before. Despitecomplexity game, NP-complete checking consistency (Kaye, 2000) coNPcomplete inference (Scott et al., 2011), beam tracking scales well solves difficultgames quickly. Moreover, results shown table competitive recentlyreported Lin, Buffet, Lee, Teytaud (2012), obtained combinationUCT action selection, domain-specific CSP solver tracking beliefs. successratios report are: 80.2 0.48% 8 8 instances 10 mines, 74.4 0.5%16 16 instances 40 mines, 38.7 1.8% 16 30 instances 99mines. authors report times.11.3 WumpusWumpus game (Russell & Norvig, 2009) consists maze agentmoves around looking gold avoiding hidden pits wumpus monsters.Initially, agent know positions gold, pits wumpuses, sensesglitter cell gold, senses stench breeze adjacentcell wumpus pit respectively. n instance described known statevariables position orientation agent, hidden boolean variablescell tell whether pit, wumpus, nothing cell. One946fiBelief Tracking Planning Sensingheadinggold-pospospitx0 ,y0wumpx0 ,y0glitterdeadx0 ,y0breezex,ystenchx,yFigure 5: Fragment causal graph Wumpus. observable variablesbreezex,y , stenchx,y deadx,y , state variables heading, pos, pitx,y wumpx,y ,(x, y) ranging grid cells. Cells (x0 , 0 ) stand cells adjacent (x, y).causal width problem 4 4 cells, state variables headingpos determined.hidden state variable stores position gold. observable variables boolean:glitter, breezex,y , stenchx,y deadx,y , (x, y) ranging different cells.actions move forward, rotate right left, grab gold. causal widthencoding 4 problem width grows n. Figure 5 shows fragmentcausal graph Wumpus. size causal beams breeze stenchvariables bounded 4 cell 4 neighbors headingposition variables agent determined.Table 4 shows results different grid sizes number pits wumpus,agent selects actions greedy policy based heuristic returns lengthminimum-length safe path nearest cell may contain gold. beliefscomputed beam tracking used determine cells safe (known containwumpus pit) may contain gold. aware testedscalable solver Wumpus making comparison, exception recentLW1 planner built work (Bonet & Geffner, 2014). figures tableshow clearly beam tracking computes beliefs effectively efficiently domain.instance, 30 30 instances 32 pits 32 wumpus solved successfully 89%time, less 4.4 seconds average. Moreover, unsolved instancesactually shown unsolvable sense agent could reach unvisitedcell safe manner. proved unsolved instance calling SAT solverpropositional theory encodes game literals learned agentexecution.11.4 Non-Deterministic Moving Wumpusorder evaluate beam tracking complex non-deterministic domain (the NONDET-Ring-Key domain Section 7 small width), designed non-deterministicvariant Wumpus domain. Moving Wumpus one wumpus gridwumpus moves around non-deterministically everytime agent moves.grid still contains hidden pits hidden gold, order make game saferagent, wumpus sensor enhanced detect position wumpus(euclidean) distance less 3 agent (else safe strategy escapingdeath general).947fiBonet & Geffneravg. time perdim#pits/#wumpus%density#decisions%windecisiongame5510 1015 1520 2025 2530 3035 3540 4045 4550 501/12/24/48/816 / 1632 / 3264 / 64128 / 128256 / 256512 / 5128.04.03.54.05.17.110.416.025.240.922,86375,507165,263295,305559,595937,6742,206,9054,471,1686,026,6257,492,50393.698.397.997.894.089.054.37.30.80.13.8e-49.6e-41.6e-32.4e-33.8e-34.7e-33.7e-32.8e-38.6e-31.3e-28.7e-37.2e-22.6e-17.2e-12.14.48.212.751.8100.4Table 4: Results Wumpus. size, performed 1,000 runs. table showstotal number density pits wumpus grid, total number decisionsacross runs, percentage runs agent found gold, averagetime seconds per decision game.Moving Wumpus causally decomposable thus incompleteness beam trackingdomain due replacement full consistency among beams doneCBT weaker efficient (relational) arc consistency done beam tracking.see this, observe variable memory variable positionwumpus WLoc. However, two beams causal decompositioncontain variable: beam WLoc beam observable variabletells position wumpus, former beam contained latter beam.8Experimental results beam tracking domain presented Table 5policy obtained using AOT lookahead algorithm based AO* (Bonet & Geffner, 2012a)builds lookahead tree depth 10 using 50 expansions, heuristic functionmeasures distance agent position closest unvisited cell.algorithm evaluated different instances grids nn n = 4, 6, 8, . . . , 20,number pits equal (n 4)/2. grid size, performed 1,000evaluations different initial configurations wumpus, pits gold randomlyplaced. instance game may turn unsolvable gold isolatedagent pits, agent finds position safe movement,agent exceeded maximum number actions (set 3 times numbercells grid).8. Indeed, general version problem involves wumpuses move non-deterministicallygrid. version also causally decomposable beams positions wumpuses(one wumpus) contained beam observable variable. general case,problem would causal width equal m.948fiBelief Tracking Planning Sensingavg. time perdim#pits%density#decisions%windecisiongame44668810 1012 1214 1416 1618 1820 200123456780.02.73.13.02.72.52.32.12.013,77030,66654,52885,635123,921159,977231,307309,919362,81697.695.094.893.093.693.491.790.090.83.5e-21.6e-14.1e-18.5e-11.32.23.14.15.34.9e-15.122.773.5173.4352.4722.01,282.31,942.8Table 5: Results Non-Deterministic Moving Wumpus domain. grid size,averages 1,000 runs shown. table shows total number density pitsgrid, total number decisions across runs, percentage runsagent found gold, average time seconds per decision game.12. Related Workformulation paper closely related recent translation-based approachesconformant contingent planning compile beliefs away (Palacios & Geffner, 2009;Albore et al., 2009). translations, however, assume problems deterministic.account yields similar widths deterministic benchmarks,simpler, defined multi-valued variables, general,handles non-deterministic actions. Yet account also less tight deterministic problems. illustration, = {x1 xn } actions ai ,conditional effect xi G, = 1, . . . , n, conformant problem goal G width1 Palacios Geffners account, width n ours. relevance account basedliterals indeed finer one based variables also difficultgeneralize non-deterministic settings. difference seem practicaleffects benchmarks disjunctions initial situation exclusiveimplicitly encode possible values set multi-valued variables. Another importantdifference approaches complete translations always exponentialproblem width, complexity bound worst case; i.e., variables contextshighly correlated, actual complexity factored belief tracking much lower.notion width appears also Bayesian networks inference exponentialwidth network (Pearl, 1988). Three differences pointedrelation notion width 1) exploit knowledge certain variablesobservable, 2) determine use knowledge certain variablesdetermined, 3) make use distinction action conditions preconditions planning. example, problem agent go n doorswhose status, open closed, observed agent near door,width smaller n modeled dynamic Bayesian network, doorvariables affect agent location variable. setting, however, problem width949fiBonet & Geffner1 status door need known agent open, closewalk door.causal decomposition resulting causal belief tracking algorithms similarly related ideas variable splitting renaming graphical models,variable X appearing different factors fi replaced different variables Xi , one perfactor fi (Choi & Darwiche, 2006; Ramirez & Geffner, 2007), problem widthreduced. Then, equality constraints relating Xi variables must enforced.Approximate belief tracking algorithms dynamic bayesian networks POMDPsalso appealed idea decomposing global beliefs variables local beliefs subsets variables (Boyen & Koller, 1998; Shani, Poupart, Brafman, & Shimony,2008). key difference causal belief tracking algorithm provideconditions type decomposition remains sound complete.hand, deal uncertainty represented sets states, probabilitydistributions.number logical schemes representing tracking beliefs useddeveloped contingent planning, appealing OBDDs, CNF, DNF representations(Bertoli et al., 2001; Bryce et al., 2006; et al., 2011), relevance considerations (Tran,Nguyen, Son, & Pontelli, 2013), lazy SAT regression techniques (Hoffmann & Brafman, 2005; Rintanen, 2008; Shani & Brafman, 2011). None approaches, however,tried domains considered paper instances similar size.Indeed, causal width domains bounds complexity beam tracking, similar bound known schemes unlike beam tracking complete.Moreover, principle schemes handle non-determinism naturally,methods like based SAT not. K-replanner (Bonet & Geffner, 2011) alsobased efficient effective belief tracking method polynomialfully general cannot deal non-deterministic actions. follow LW1 planner(Bonet & Geffner, 2014) shares features K-replanner complete width-1problems.experimental perspective, several comments questions orderrelation beam tracking algorithms used belief tracking contingentplanners existing benchmarks. First all, practically benchmarks usedfar contingent planning easy belief tracking point view. Indeed,quadratic linear time representation beliefs CLG LW1 respectively,shown adequate problems, including Wumpus problems above.exception Minesweeper, belief tracking provably NP-hardlinear approximation LW1 turns much weaker beam tracking, failingsolve without guessing instances beam tracking solveway (Bonet & Geffner, 2014). means that, whether width problemslow high, effective width 1, cases, beam tracking cannot helpcomputationally, actually, may degrade performance (except Minesweeper), beamtracking exponential problem causal width, lower width generalusually higher 1. effective width problem P minimum non-negativeinteger value contingent translation Xi (P ) (Palacios & Geffner, 2009; Alboreet al., 2009) solution. effective width problem never greater widthmuch smaller width causal width. example,950fiBelief Tracking Planning Sensingavg. time perdim#mines%density%succ%failure%aborteddecisiongame8816 1630 1610409915.615.620.693.094.065.07.06.06.00.00.029.00.84.912.456.31,268.45,998.6Table 6: Comparison SDR on-line planner Minesweeper instances. SDR fedrandom hidden states solutions (action sequences) computed beam trackingguessing. planner task check applicability actions givensolution whether goal holds. instance size, SDR tested 100 differentrandom problems. column failure indicates number times SDR ableverify correct solution, column aborted indicates number timesSDR terminated early due bug. Times seconds. Beam tracking takesseconds solving instances (see Table 3).problem actions ai conditional effects map valuations vi set variablesX1 , . . . , Xn goal literal = y, width causal width smallern variables Xi causally relevant . Yet effective widthproblem may 1 values Xi variables observed directlyinferred observations, also, goal achieved without usingactions all. sense, notion effective width provides lower boundnumber state variables whose uncertainty must tracked jointly order makeproblem solvable, notions width, characterized syntactically, provides upperbound number state variables whose uncertainty must tracked jointlysolution would missed. gap two bounds large indeed,obtaining syntactic characterizations former open problem.related question various belief tracking algorithms used contingent planning regression, OBDDs, CNF, DNF, scale domains.general comparison complete exponential algorithms incomplete polynomial algorithms like beam tracking (over domains bounded causal width) wouldfair, would still interesting find easy cases algorithms scale polynomially exponentially. Performing tests, however,simple, requires getting code planners wouldfollow fixed common policy instance, thus leaving planning component aside.Moreover, even fixing policy instance, enough, plannersoff-line hence track beliefs many possible executions one,case on-line planners.purpose illustration performed test one difficultdomains, Minesweeper, supplying on-line planner SDR (Shani & Brafman, 2011)execution computed beam tracking along hidden initial stateexecution. setting, on-line planner SDR planning, rathertracking beliefs problem verify goal achievement preconditionsgiven applicable action time point. Minesweeper instances solved951fiBonet & Geffnerbeam tracking without guessing; i.e., pure inference first fixed choice. Table 6shows results SDR tracks beliefs using form regression (Rintanen, 2008;Shani & Brafman, 2011). Two observations made comparing resultstable Table 3 beam tracking. First, SDR takes 56.3, 1,268.45,998.6 seconds average verifying solutions 8 8, 16 16 30 16 instancesrespectively, beam tracking takes 0.21, 1.42 2.86 seconds finding solutionsfollowing greedy policy. Since finding solutions expensive verifyingone must least identify applicable actions time point differenceperformance turns several orders magnitude, growing grid size.addition, regression mechanism SDR fails verify correct solutions several casesaborts failure large number cases large instances. case,performance gap surprising: belief tracking Minesweeper NP-hard, thuscomplete algorithms like regression run exponential time worst case,beam tracking remains polynomial causal width domain bounded.challenging problems, gap performance beam tracking complete belieftracking algorithms similar. Beam tracking useful causal widthproblem bounded large, trading principled way completenesstractability.13. SummaryEffective belief tracking crucial planning incomplete information sensing.problem intractable general, shown elsewhere belief tracking deterministic problems exponential width parameter often boundedsmall. work, introduced related formulation applies nondeterministic problems well. factored belief tracking algorithm results setprojected problems whose size bounded problem width. beliefs goalspreconditions obtained directly beliefs projected problemsmaintained independently. developed different decompositionscheme belief tracking algorithm maintains beliefs smaller projections,provided conditions algorithm complete. Causal belief trackingspace exponential problem causal width remains time exponential problem width, global consistency beliefs smaller projections needenforced. Finally, beam tracking sound incomplete approximation causal belieftracking global consistency replaced local powerful form consistency.Beam tracking runs time space exponential problem causal widthoften much smaller problem width. tested beam tracking largeinstances Battleship, Minesweeper, Wumpus, combination simple heuristicsaction selection, performance compares well state-of-the-art solversusing orders-of-magnitude less time. future, would like explore extensionsproposed framework belief tracking POMDPs, belief states setsstates probability distributions, particle-based algorithms provide commonapproximation (Doucet et al., 2000).952fiBelief Tracking Planning SensingAcknowledgmentsthank Gabriel Detoni Java Tewnta framework (http://code.google.com/p/tewnta) implementing client/server games graphical interface developed graphical interfaces Battleship, Minesweeper Wumpus. Thanks alsoJames Biagioni wumpuslite JAVA simulator (http://www.cs.uic.edu/~jbiagion/wumpuslite.html) adapted run experiments Wumpus, Guy Shanihelp running SDR. Hector Geffner partially supported EU FP7 Grant# 270019(Spacebook) MICINN CSD2010-00034 (Simulpast).Appendix A. ProofsFormal results needed stated propositions theoremsmain text article appear form lemmas.A.1 Complexity Flat Belief TrackingLet us first formally define decision problems BTP GBTP. BTP languageBTP = {hP, : P contingent problem, possible execution, b |= G}P = hV, I, A, G, V 0 , W i, = ha0 , o0 , . . . , , execution, b beliefresults execution initial belief state. GBTP like BTP exceptconsists triplets hP, , `i P contingent problem, possible generalizedexecution, ` goal, precondition observation literal, b |= `.Observe BTP GBTP respectively include tuples hP, hP, , `iproblem empty initial belief state, due two complementary literals appearing unit clauses I, since case every execution trivially possible btrivially entails literal `.Proposition 3. BTP polynomial-time reducible GBTP.Proof. idea map normal execution generalized execution resultsreplacing pair ha, oi sequence ha, `1 , noopa , `2 , . . . , noopa , `|V 0 |`1 , . . . , `|V 0 | observation literals made true o, one observable variableV 0 , noopa action requires nothing nothing whose sensormodel Wnoopa (`) = Wa (`) observation literal `.Formally, given instance hP, BTP, reduction must generate polynomialtime instance hP 0 , 0 , `i GBTP hP, BTP iff hP 0 , 0 , `i GBTP.problem P 0 problem P extended actions noopa , new booleanvariable Xgoal denotes achievement goal G P , new action agoalprecondition G effect Xgoal , new dummy observable variable domain{>} models Wa (Y = >) = true actions a. hand, generalizedexecution 0 hm , agoal , = >i ` = Xgoal . Clearly, reduction works polynomialtime hP, BTP iff hP 0 , 0 , `i GBTP.Theorem 5. Flat belief tracking exponential |VU |, VU = V \ VK VKset state variables V determined.953fiBonet & GeffnerProof. described Definition 4, flat belief tracking consists explicit representationbeliefs set states, savings space time obtained notingvariables VK determined.explicit representation beliefs, belief tracking problem gets trivially solvedchecking whether execution = ha0 , o0 , . . . , , possible literal `true reduces computing belief bn+1 results checking whetherbn+1 empty whether every state satisfies `. time complexity algorithmtime needed compute initial belief b0 plus (n + 1) multiplied time neededcompute bi+1 bi plus time needed check validity `. Among times,last easiest calculate linear size bn+1 . thus need boundfirst two times. begin proof showing flat belief tracking donetime exponential |V | reduce exponential dependency |V | |VU |.computing b0 enough generate possible states (valuations variables)filter satisfy clauses I. total time thus spent|V | |I| 2O(|V |) since 2O(|V |) valuations, |I| clauses, clause|V | literals.9time compute bi+1 bi consists time check preconditionshold b, times compute ba b boa ba b = bi , = ai= oi . preconditions easily verified iterating states b. timebounded |V | 2O(|V |) since contains |V | preconditions b contains2O(|V |) states. precondition satisfied state b, executionpossible.belief ba computed b iterating state b,possible state s0 ba , checking whether s0 F (a, s). two nestediterations require time 2O(|V |) 2O(|V |) = 2O(|V |) . test s0 F (a, s) performedtime exponential |V | follows. Let Ci E1i | |Eni , 1 m,collection conditional effects action trigger state s. s0 F (a, s),s0 result applying one head conditional effect s. Sinceproblem |V | variables, among heads |V | heads maps0 rest (if any) subsumed first. subsets heads size|V | enumerated 2O(|V |) time, subset checking whether getsmapped s0 requires O(|V |) time. Therefore, checking s0 F (a, s) requires 2O(|V |) timewell computing ba b.ba obtained, boa calculated removing (filtering) ba statescomply observation o. state ba observation literal` compatible o, state belongs boa iff |= Wa (`). latter testperformed time linear |Wa (`)|, size formula Wa (`). Hence, since|V 0 | observation literals compatible o, boa computed ba time O(|ba ||V 0 | |Wa |) |Wa | = max` |Wa (`)| max ranges observation literals `.boa empty ba non-empty, execution possible.9. calculation, implicitly assume variable domains constant size. Otherwise,domains size n linear input size, number valuations bounded 2O(|V | log n)instead 2O(|V |) . either case, number valuations still exponential number variableswell resulting complexity flat belief tracking.954fiBelief Tracking Planning Sensingtimes weighed in, see flat belief tracking done timeexponential |V |.reduce exponent |V | |VU |. direct since determinedvariable valuation across states reachable belief. Hence, variablescontribute increase number states reachable beliefs. Likewise,subsets heads size |VU | need considered computing belief ba b.Hence, computations done time space exponential |VU |.Theorem 6. BTP GBTP Turing complete class PNP .Proof. Proposition 3, BTP polynomial-time reducible GBTP, thus enoughshow hardness BTP inclusion GBTP.class PNP set decisions problems decided (deterministic)polynomial time using oracle SAT. show BTP hard class,enough show UNSAT reduced polynomial time BTP since everycall NP oracle replaced call BTP oracle. hand,show GBTP belongs PNP , enough show algorithmcomplement GBTP (since PNP closed complementation) runs polynomialtime makes calls oracle SAT.Hardness. Let = {C1 , . . . , Cm } CNF theory boolean variables X1 , . . . , Xn .need construct polynomial time contingent problem P = hV, I, A, G, V 0 , Wexecution hP, BTP iff unsatisfiable. variablesproblem P boolean given V = {X1 , . . . , Xn , Q} V 0 = {Z1 , . . . , Zm }.empty set clauses G = {Q = true}. actions a1 , . . . , , emptypreconditions conditional effects, sensor model Wai (Zi = true) = Ci QWai (Zj = true) = f alse j 6= i. Finally, execution = ha1 , o1 , . . . , , omoi V 0 -valuation makes Zi true Zj false j 6= i.Note initial belief contains 2n+1 V -valuations, half satisfyingQ half Q. first observation o1 received, valuationssatisfy clause C1 Q preserved. Thus, inductively, observation oireceived, valuations satisfy clauses {C1 , C2 , . . . , Ci } Q preserved.Therefore, b set valuations satisfy Q hence non-empty (i.e.,possible execution). Thus, b |= G iff valuations Q gone iff unsatisfiable.Inclusion. complement GBTP consists tuples hP, , `i b0 non-emptyeither non-executable b 6|= `. Since consists unit clauses, b0 6= iffcontains pair complementary literals. Assume = ha0 , `0 , a1 , `1 , . . . , , `n i,literals `i observation literals, let bi belief action aiapplied; i.e., bi = boa b = bi1 , = ai1 = `i1 . Then, possible iffbi non-empty action ai applicable bi . Assume establishedprefix = ha0 , `0 , . . . , ai1 , `i1 possible, checking whether i+1 possibleinvolves two operations: 1) checking precondition literal ai holds bi12) checking whether least one state bai complies `i , b = bi1 .first check done calling SAT oracle CNF theory i1 ,time-indexed propositions state-variable literals actions, encodes possiblestate trajectories fixed valuation actions. time horizon theory955fiBonet & Geffner= 0, . . . , 1, theory built way satisfiable iff statetime (i.e., bi1 ) satisfy least one precondition ai . theorypolynomial size built polynomial time. Likewise, second checkperformed calling SAT oracle CNF theory i1 propertysatisfiable iff state bi1 complies observation `i .Hence, algorithm decides complement GBTP works building theories= 0, . . . , n. stage t, ACCEPTs input satisfiableunsatisfiable. If, end, algorithm accepted yet, builds another theoryn+1 , like instead checking whether precondition action ai doesnthold, checks whether input literal ` doesnt hold. n+1 satisfiable, ACCEPTssince belief b satisfy `, else REJECTs hP, , `i GBTP.A.2 Factored Belief Trackingfollowing, state (valuation variables) subset variables, writes|S denote valuation restricted variables S, also called projectionS. general, use symbols s, primed versions denote states,symbols u, v primed versions denote projected states (restrictionspartial valuations).Proposition 9. Belief tracking deterministic non-deterministic conformant setting exponential maximum number non-determined variables causallyrelevant variable appearing action precondition goal.Proof. proposition special case Theorem 15 (and also Theorem 33).Theorem 15. Belief tracking P exponential w(P ).Proof. conformant setting, observable variables hence evidentialrelevance relation empty relevant relation equals causally relevant relation.Therefore, context variable X equals set variables causally relevantX, theorem establish Proposition 9 conformant setting.general setting, theorem shown constructing algorithm belieftracking whose time complexity exponential w(P ). definition analysisalgorithm done series claims terminate Theorem 22 below.Proposition 18. variable X appears goal precondition, number statevariables PX determined bounded w(P ).Proof. number state variables PX |Ctx(X)| number state variablesdetermined PX |Ctx(X) VU |. definition width, quantityless equal w(P ) X goal precondition variable.establish two fundamental lemmas progression actions projection observable models. following, say subset variable causallyclosed variable X variable causally relevant X, S.Likewise, causal closure variable Z minimum (with respect set inclusion)subset variables causally closed includes Z.956fiBelief Tracking Planning SensingLemma 1 (Factored Progression). Consider consistent problem P . Let state,action applicable s. Then, causally-closed subset variables:1) every u0 , u0 FS (a, s|S ) s0 F (a, s) u0 = s0 |S ,2) every s0 , s0 F (a, s) s0 |S FS (a, s|S )FS transition function projected problem PS . Therefore, F (a, s) =FS (a, s|S ) every state applicable, F (a, U ) = FS (a, U ) everyset U valuations applicable.Proof. Part 1. Let u0 element FS (a, s|S ) let HS = {ESi }mi=1 collectionheads conditional effects CSi ESi trigger s|S result u0 .fixed {1, . . . , m}, know s|S |= CSi . ESi 6= then, definition causallyrelevant relation, V ars(C ) thus CSi = C . Therefore, |= C effect alsotriggers applied s. show effect affects variabletriggers applied s. Indeed, conditional effect C F affectsvariable triggers, |= C thus s|S |= CS FS HS . Finally, effectstrigger affect variables problems P PS . Since Pconsistent, set effects {E }mi=1 contained set H heads effectstrigger applied s. Therefore, u0 projection state s0results applying effects H s; i.e., u0 = s0 |S .Part 2. Let s0 element F (a, s) let H = {E }mi=1 collection headsconditional effects C E trigger result s0 . fixed {1, . . . , m},know |= C thus s|S |= C |S . Therefore, effects CSi ESi also triggerapplied s|S PS . show effect affects variabletriggers applied s|S PS . Indeed, let us suppose projected conditionaleffect CS FS affects variable triggers s|S . Then, V ars(F ) thusV ars(C) S, since causally closed, CS = C. Therefore, |= C effectalso triggers applied s. Finally, since effects trigger affectvariables problems P PS , s0 |S result applying0projected effects {ESi }mi=1 s|S ; i.e., |S FS (a, s|S ).Lemma 2 (Observational Closure). every variable X, action a, observation literal` = Z = z, Wa (`)S either Wa (`) true, = Ctx(X).Proof. Let {X1 , . . . , Xn } variables Wa (`). definition relevant relation,Z relevant Xi vice versa. Hence, Z Xi belongs S, ZXi belongs well. Therefore, Wa (`)S either Wa (`) true.following results obtained induction length executions.noted before, loss generality consider generalized executions insteadexecutions. However, easier consider even general executions correspondfinite sequences alphabet {ha, `i : A, ` Lits(V 0 )}set actions Lits(V 0 ) set observation literals. type executionsgeneral require interleaving actions observations; i.e.,execution may contain multiple actions observations sequence. example,957fiBonet & Geffnerexecution like ha0 , a1 , ha2 , `2 i, ha3 , `3 i, . . .i indicates initial belief needsprogressed actions a0 a1 , filtered formula Wa2 (`2 ), filteredformula Wa3 (`3 ), on. case normal generalized executions,direct mapping generalized executions new type executions.one execution, b denotes belief results applying initialbelief, b = b , ba ba,` denote beliefs result executions0 = h, ai 0 = h, ha, `ii respectively. Therefore, making inductionlength executions prove claim, need show claim initial beliefcorresponds empty execution, beliefs form ba ba,` b = b .next definition lemma make precise notion decomposable beliefplays fundamental role results. Intuitively, belief b decomposableevery pair states s, b, state w b agrees variablessubset agrees variables subset (where certainsubsets variables); symbols, w b w|S = s|S w|T = t|T .Definition Lemma 3 (Decomposability). belief state b decomposable iffevery variable X, observation literal ` = Z = z, action a, subset V ars(Wa (`))causally closed Ctx(X) = , holds:s, s, b = w w b w|Ctx(X) = s|Ctx(X) w|T = t|T .turns every reachable belief decomposable.Proof. Let b reachable belief. Then, execution b = b .proof induction length . empty, claim holds since containsunit clauses Ctx(X) = .Assume beliefs reachable executions length less equaln decomposable, consider execution 0 length n + 1 augmentsexecution length n. following, b denotes belief b , res(a, s) denotesstate results applying deterministic action state s.Case: 0 = h, a0 i. Let X, `, statement lemma, = Ctx(X),let s0 , t0 two states ba0 . Therefore, two determinizations a1 a2a0 s0 = res(a1 , s) t0 = res(a2 , t) s, b. Apply inductive hypothesisobtain w b w|S = s|S w|T = t|T . Since disjointcausally closed, determinization10 a3 a0 res(a1 , s)|S = res(a3 , w)|Sres(a2 , t)|T = res(a3 , w)|T . sought w0 ba0 thus w0 = res(a3 , w).Case: 0 = h, ha0 , `0 ii. before, let X, `, statement lemma,0 0let `0 = Z 0 = z 0 , let s0 , t0 two states ba ,` . consider two subcases whetherV ars(Wa0 (`0 )) not, = Ctx(X):Subcase: V ars(Wa0 (`0 )) S. Since, s0 , t0 b, apply inductive hypothesis get w0 b0 0w0 |S = s0 |S w0 |T = t0 |T . Then, w0 ba ,` w0 |S = s0 |S |= Wa0 (`0 )S =Wa0 (`0 ).10. existence determinization granted second assumption planning problemfact sets variables disjoint.958fiBelief Tracking Planning SensingSubcase: V ars(Wa0 (`0 )) * S. Lemma 2, V ars(Wa0 (`0 )) = . Let 0 minimalcausally-closed subset variables includes V ars(Wa0 (`0 )). Observe 0 =since belongs intersection, Z 0 relevant , relevant X, thusZ 0 relevant X contradicting V ars(Wa0 (`0 )) = . Apply inductive hypothesisusing 0 get w0 b w0 |S = s0 |S w0 |T 0 = t0 |T 0 . w00 0looking 0 thus w0 |T = t0 |T , w0 ba ,` sincew0 |T 0 = t0 |T 0 |= Wa0 (`0 )T 0 = Wa0 (`0 ).last technical lemma, giving proofs Theorems 20 22, establishexistence partial valuations projection filtered beliefs following:Lemma 4 (Factored Filtering). Let X variable, = Ctx(X), b reachable belief,action, ` = Z=z observation literal. ba,` non-empty uu b u |= Wa (`)S , u ba,` .Proof. Assume ba,` non-empty let u S-valuation satisfies antecedent lemma. Wa (`)S = Wa (`), u |= Wa (`) u ba,` .Wa (`)S 6= Wa (`) Lemma 2, V ars(Wa (`)) = . Let minimalcausally-closed subset variables includes V ars(Wa (`)). NoteZ evidentially relevant relevant X, thus Z relevant XV ars(Wa (`)) S. Therefore, = . Let ba,` b apply Lemma 3 getw b w|S = u w|T = t|T . Hence, w|T |= Wa (`)T = Wa (`), w ba,`u ba,` .Theorem 20. state variable X, let b bX beliefs result executionpossible P PX . Then, X bX = X b.Proof. Let execution possible P PX . provegeneral result bX = b = Ctx(X); general XX bX = X b = X b. proof induction length . emptyexecution, result follows readily since contains unit clauses. Assumeclaim holds executions length n, let 0 execution length n + 1augments execution length n possible P PX . Further, let bbX beliefs result P PX respectively. Then, inductivehypothesis bX = b.Case: 0 = h, ai. need show bX,a = ba . following, FS denotestransition function PX . forward inclusion given1u0 bX,a = u u bX u0 FS (a, u)2= us u bX u0 FS (a, u) b s|S = u3= uss0 u bX u0 FS (a, u) b s|S = u s0 F (a, s) s0 |S = u04= ss0 b s0 F (a, s) s0 |S = u065= s0 s0 ba s0 |S = u0 = u0 ba959fiBonet & Geffner1 definition bX,a , 2 inductive hypothesis, 3 Lemma 1, 56 definitions ba ba respectively. backward inclusion21s0 |S ba = b s0 F (a, s) = b s0 F (a, s) s0 |S FS (a, s|S )43= s|S bX s0 |S FS (a, s|S ) = s0 |S bX,a1 definition ba , 2 Lemma 1, 3 inductive hypothesis, 4definition bX,a . Therefore, bX,a = ba .a,`Case: 0 = h, ha, `ii. need show ba,`X = b . forward inclusion123a,`u ba,`X = u bX u |= Wa (`)S = u b u |= Wa (`)S = u b1 definition ba,`X , 2 inductive hypothesis, 3 Lemma 4.backward inclusion123s|S ba,` = b |= Wa (`) = s|S bX s|S |= Wa (`)S = s|S ba,`X .1 definition ba,` , 2 inductive hypothesis, 3 definitiona,`a,`ba,`X . Therefore, bX = b .Theorem 21. 1) execution possible P iff possible subproblemsPX X precondition goal variable P . 2) execution preconditiongoal variable X, X = x (resp. X 6= x) true b iff X = x (resp. X 6= x) truebX , b bX beliefs result executing P PX respectively.Proof. Part 1. proof induction length executions. base caseinduction empty execution possible P PX . Assumeclaim holds executions length n, let b bX beliefs resultP subproblem PX respectively. Let 0 execution lengthn + 1 augments . following, F denotes collection precondition goalvariables P , = Ctx(X) X F.Case: 0 = h, ai. First, assume 0 possible P . need show 0 possiblePX X F. assumption, literal ` P re(a) b, |= `.Let ` literal P re(a)S u bX X F. Then, V ars(`) and, inductivehypothesis Theorem 20 (since applicable P PX ) applied , u = s|Sb. Therefore, u |= ` applicable bX .Now, assume 0 possible PX X F. need show 0possible P . ` = X = x precondition a, ` P re(a)S ` holdsstate u bX . b then, inductive hypothesis Theorem 20 applied ,u bX s|S = u. Thus, |= ` applicable b.Case: 0 = h, ha, `ii. First, assume 0 possible P ; i.e., ba,` non-empty. needshow ba,`X non-empty well X F.123ba,` = b |= Wa (`) = s|S bX s|S |= Wa (`)S = s|S ba,`X960fiBelief Tracking Planning Sensing1 definition ba,` , 2 inductive hypothesis Theorem 20, 3a,`definition ba,`X . Hence, bX non-empty.Finally, assume 0 possible PX ; i.e., ba,`X non-empty X F.a,`need show b non-empty. Let X F Wa (`)S = Wa (`)= Ctx(X); exists fourth assumption problem P Lemma 2.12u ba,`X = u bX u |= Wa (`)S = u bX u |= Wa (`)S b u = s|S3= u bX |= Wa (`) b u = s|S54= |= Wa (`) b = ba,`1 definition ba,`X , 2 inductive hypothesis Theorem 20, 3Wa (`)S = Wa (`), 5 definition ba,` . Hence, ba,` non-empty.Part 2. Let possible execution P , hence, part 1, also possible PX .Let b bX beliefs result P PX respectively. Theorem 20,X bX = X b. Therefore, X = x (or X 6= x) holds bX iff holds b.Theorem 22. Flat belief tracking projected problems PX Xprecondition goal variable P , provides sound complete factored algorithmbelief tracking P time space exponential width P .Proof. direct Theorem 21. Let execution b bX,beliefs result executing P PX respectively. Then, possible P iffpossible PX . Therefore, flat belief tracking subproblems PX tells whetherpossible P . Furthermore, precondition goal variable X, X = x holdsb iff holds bX, . Thus, flat belief tracking subproblems PX sufficientdetermine action applicable goal belief reached.Theorem 5, flat belief tracking subproblem PX exponential |Ctx(X) VU |.Therefore, flat belief tracking subproblems PX (simultaneously) exponentialmaxX |Ctx(X) VU | max ranges precondition goal variables X.latter expression one defines w(P ).Proposition 19. execution ha0 , o0 , a1 , o1 , . . .i possible P , also possiblePX state variable X P .Proof. X precondition goal variable, claim follows Theorem 21. So,assume X state variable appear precondition goal. showusing induction length (generalized) execution possible Palso possible PX . base case empty executions direct. Considerexecution 0 length n + 1 extends execution length n. Let b bXresult applying execution P PX respectively, let = Ctx(X).Case: 0 = h, ai. Let ` = = precondition P re(a)S = Ctx(Y ). Then,Ctx(Y ) Ctx(X) relevant X. Lemma 5 (below), bX .961fiBonet & Geffnerhand, Theorem 21, |= ` every . Therefore, ` holds statebX , applicable bX , 0 possible PX .Case: 0 = h, ha, `ii. Wa (`)S = true, ba,`X = bX non-empty inductivehypothesis thus 0 possible PX . Wa (`)S 6= true ` = Z = z, Zrelevant X. Since assumption precondition goal variable Zrelevant , difficult show X relevant . Thus, Ctx(X) Ctx(Y )bX Lemma 5. Since 0 possible P ba,`non-empty Theorem 21,0 possible P .ba,`non-emptyXXA.3 Causal Belief TrackingLemma 5 (Soundness Causally-Closed Decompositions). Let = hT, Bi decomposition whose beams causally closed, let PXD subproblem correspondingprojection P variables B(X) X . target variable X , bbX beliefs resulting execution P PXD respectively, bX B(X) b.Proof. proof induction length executions. empty execution,claims holds since contains unit clauses. Let 0 execution length 0augments . following, b bX denote beliefs P PXD resultingexecution , denotes B(X).Case: 0 = h, ai. Let u0 ba . Then, b u0 F (a, s).Lemma 1, u0 FS (a, s|S ). Thus, since s|S bX inductive hypothesis, u0 bX,a .Case: 0 = h, ha, `ii. Let s|S ba,` . b |= Wa (`). inductivehypothesis, s|S |= Wa (`)S s|S bX . Thus, s|S ba,`X .Theorem 28. Decoupled CBT runs time space exponential wc (P ),sound complete. is, target variable X causal decomposition,b bX beliefs resulting execution P PXC respectively,bX BC (X) b necessarily true, bX BC (X) b not.Proof. Soundness follows directly Lemma 5. bounds time space alsodirect size beam BC (X) bounded causal width wc (P ).Theorem 30. CBT space exponential causal width problem, timeexponential width.Proof. CBT maintains beliefs beams causal decomposition whose sizebounded causal width problem. join-project operation CBTperformed across time, considering one valuation time, without need firstcompute store full joint. done recursively iterating beliefs(bY )oa participate join (5), combining partial valuations belief,storing projection resulting belief bi+1X . number valuations joinO(w(P))(5) bounded 2variable Z BC (Y ), relevant X, relevantX thus Z Ctx(X).962fiBelief Tracking Planning Sensingremains show Theorem 33 (stated below). proof straightforwardsplit two parts. first part reformulates CBT algorithm called Wide(Causal) Belief Tracking (WBT), like CBT performs join operationbeliefs variables problem variables relevantX, shows soundness completeness WBT. second part, showCBT simply WBT applied subproblem PCtx(X) associated variable Xfactored decomposition F , use soundness completeness factoreddecomposition finish proof. first part proof consists Lemmas 68,second part consists Lemma 9 Theorem 33.WBT works causal decomposition C = hTC , BC like CBT. beliefs time0 WBT CBT: initial belief projected causalbeams BC (X) X TC . Beliefs later times associated executions 0augment executions . denote belief variable X TC executionbX, , update equations WBT are:bX,h,ai = BC (X)n{FT (a, bY, ) : TC } ,bX,h,ha,`ii = BC (X)n{F ilter(Wa(`)T , bY, ) : TC }(8)(9)= BC (Y ) beam , FT (a, U ) set uU FT (a, u), F ilter(, U )set {u U : u |= }. equations essentially equation (5) CBT,progression filtering separated, except join performedtarget variables instead joining target variables relevant X.following basic facts joins, projections filtering easily shownused proofs. (We include proofs here.) statements, setsU Ui refer sets valuations, refers collection subset variables, referssubset variables Si = V ars(Ui ), refers logical formula. facts are:BF1. Un{S U : S},BF2. collection {Ui }iI ,n{Sin{Ui : I} : I} =n{Ui : I},BF3. F ilter(, U ) F ilter(S , U ).Definition Lemma 6. decomposition = hT, Bi factors set U V -valuationsiff U =n{B(X) U : X }.decomposition = hT, Bi preserves transitions set U V -valuations iffpair variables X, , Z B(X) B(Y ), either i) Z known U (i.e.,u[Z] = u0 [Z] u, u0 U ), ii) B(X) B(Y ) B(W ) variable W ,iii) every action a, transition function FS (a, ) 1-1 variable Z U ,causal closure Z.Let = hT, Bi decomposition V = XT B(X) B(X) causallyclosed X , U set V -valuations, V -formula. followingclaims hold:1. factors U ,F (a, U )n{B(X)F (a, U ) : X } =n{FB(X)(a, B(X)U ) : X } .963fiBonet & Geffner2. factors preserves transitions U ,F (a, U ) =n{B(X)F (a, U ) : X } =n{FB(X)(a, B(X)U ) : X } .3. factors U X B(X) = ,F ilter(, U ) =n{B(X)F ilter(, U ) : X } =n{F ilter(B(X), B(X)U ) : X } .Proof. Part 1. containment direct BF1, equality follows directlyB(X) F (a, U ) = FB(X) (a, B(X) U ) Lemma 1.Part 2. second equality forward inclusion first equalityPart 1. thus need show F (a, U )n{B(X) F (a, U ) : X }. Letu0 element right-hand side expression X . Then, u0 |B(X)B(X) F (a, U ) (by Lemma 1) uX B(X) U u0 |B(X) FB(X) (a, uX ).claim {uX }XT consistent collection valuations. Indeed, not,valuations uX , uY variable Z uX [Z] 6= uY [Z]. Clearly, Z knownU . B(X) B(Y ) B(W ) W , exchange uX uYuW |B(X) uW |B(Y ) respectively. Otherwise, see function FS (a, ),causal closure Z, 1-1 Z, contradicting assumptions. Therefore,valuation u u|B(X) = uX X (i.e., un{B(X) U : X }) thus,assumption, u U . Finally, since B(X) F (a, u) = FB(X) (a, u|B(X) ) = FB(X) (a, uX )Lemma 1, u0 |B(X) B(X) F (a, u) u0 F (a, U ).Part 3. First, observe BF1 BF3 imply chain containmentsF ilter(, U )n{B(X)F ilter(, U ) : X }n{F ilter(B(X), B(X)U ) : X } .finish showing equality holds proving last subset containedfirst. Let u0 element last subset. u0 belongsn{B(X) U : X }also U since factors U . thus need show u0 |= . directsince assumption X B(X) = , thus u0 |B(X) |= B(X) = .Lemma 7 (Soundness WBT). WBT sound. is, C = hTC , BC causaldecomposition problem P , {bX }XTC local beliefs time i, b globalbelief time i, bn{bX : X TC } BC (X) b bX X TC .Proof. really need proof first claim bn{bX : X TC } secondfollows directly observing bX belief variables BC (X).proof first claim induction length executions. basecase empty execution easily verified. Assume claims hold executionslength n let 0 execution length n + 1 augments executionlength n. Observe C factors U =n{bY, : TC } BF2, b U inductivehypothesis.Case: 0 = h, ai.n{bX,10: X TC } =n{BC (X)n{FBC (Y )(a, bY, ) : TC } : X TC }964fiBelief Tracking Planning Sensing2n{BC (X)n{FBC (Y )(a, BC (Y )U ) : TC } : X TC }34F (a, U ) F (a, b ) = b 01 Eq. 8, 2 bY, BC (Y ) U , 3 part 1 Lemma 6, 4inductive hypothesis.Case: 0 = h, ha, `ii.n{bX,90: X TC } =n{BC (X)n{F ilter(Wa(`)BC (Y ), bY, ) : TC } : X TC }10n{BC (X)n{F ilter(Wa(`)BC (Y) , BC (Y ) U ): TC } : X TC }1211= F ilter(Wa (`), U ) F ilter(Wa (`), b ) = b 09 Eq. 9,inductive hypothesis.10bY, BC (Y ) U ,11part 3 Lemma 6,12Lemma 8 (Completeness WBT). Let C = hTC , BC causal decompositionproblem P . C preserves transitions every reachable belief state, WBT complete.is, {bX }XTC local beliefs time i, b global belief time i,b=on{bX : X TC } BC (X) b = bX X TC .Proof. proof induction length executions. base caseempty execution easily verified since contains unit clauses. Assume claimshold executions length n let 0 execution length n + 1 augmentsexecution length n. Observe C factors U =n{bY, : TC } BF2,inductive hypothesis implies b = U bY, = BC (Y ) U . proof first claimb=on{bX : X TC } exactly like proof Lemma 7 except containmentsreplaced equalities, either using part 2 Lemma 6 inductive hypothesis.second claim, make similar induction (in tandem first induction).Again, base case induction easily verified. inductive step,Case: 0 = h, ai.12bX, 0 = BC (X)n{FBC (Y )(a, bY, ) : TC } = BC (X)n{FBC (Y )(a, BC (Y )U ) : TC }34= BC (X) F (a, U ) = BC (X) F (a, b ) = BC (X) b 01 Eq. 8, 2 4 inductive hypothesis, 3 part 2 Lemma 6.Case: 0 = h, ha, `ii.5bX, 0 = BC (X)n{F ilter(Wa(`)BC (Y ), bY, ) : TC }6= BC (X)n{F ilter(Wa(`)BC (Y ), BC (Y )U ) : TC }78= BC (X) F ilter(Wa (`), U ) = BC (X) F ilter(Wa (`), b ) = BC (X) b 05 Eq. 9, 6 8 inductive hypothesis, 7 part 3 Lemma 6.965fiBonet & Geffnerfollowing lemma shows tracking CBT variable X equivalenttracking WBT subproblem PX factored decomposition (i.e.,PX = PBF (X) factored decomposition F = hTF , BF i).Lemma 9. Let F = hTF , BF C = hTC , BC factored causal decompositionsWproblem P . execution X TC state variable, bCX = bXCbX denotes local belief variable X computed CBT problemP , bWX denotes local belief variable X computed WBTsubproblem PBF (X) .Proof sketch. simple tedious proof, provide sketch. Let CX =hTX , BX causal decomposition subproblem PBF (X) X TF (i.e.,causal decomposition subproblem associated variable X TF factoreddecomposition). beams participate join CBT beamsvariables TC relevant X; variables appear TX well. TXvariables however: observable variables relevant X. Yet, sincestate variables PBF (X) relevant X, projected formulas Wa (Y = y)BF (X)variables equal true. Hence, beams variablesempty set variables contain empty valuation. Therefore, beamsremoved join defines WBT problem PBF (X) without altering value.resulting join WBT PBF (X) contain beams variables TCrelevant X.fact observed, proof consists simple induction lengthexecutions. induction left exercise.Theorem 33. Causal belief tracking always sound. complete causally decomposable problems.Proof. Let F = hTF , BF C = hTC , BC factored causal decompositionsproblem P , CX = hTX , BX causal decomposition subproblem PBF (X)X TF (notice X state variable TF comprised such). Further, letWexecution, let bCX bX local beliefs variable X computedCBT problem P WBT problem PBF (X) respectively, let bFX local beliefvariable X computed factored belief tracking problem P , let b(global) belief problem P .observable variable relevant X, BC (X) = BF (X) CBT X equalfactored belief tracking X sound complete Theorem 20.observable variables relevant X, first noticeWFbCX = bX BC (X) bX = BC (X) b(10)Lemma 9, soundness WBT (cf. Lemma 7), soundness completeness FBT (cf. Theorem 20). Therefore, CBT sound.causal decomposition CX preserves transitions every reachable belief stateproblem PBF (X) , containment (10) equality CBT complete well.thus finish proof showing decomposition CX causally-decomposableproblems decomposition preserves transitions reachable belief PBF (X) .966fiBelief Tracking Planning SensingLet X TC variable, let bX reachable belief problem PBF (X) , let X 0two variables TX (the target variables causal decomposition problemPBF (X) ), let Z variable BC (X 0 ) BC (X 00 ). show either 1) Zknown bX , 2) BC (X 0 ) BC (X 00 ) BC (W ) variable W TX , 3) everyaction a, transition function FS (a, ) 1-1 variable Z bX causalclosure Z. case, causal decomposition CX preserves transitions everyreachable belief problem PBF (X) .X 00consider two cases:Case: X 0 X 00 observable. First, apply causal-decomposability P concludeeither variable W TC relevant X 0 X 00 BC (W ) BC (X 0 )BC (X 00 ), Z memory variable. former case, W relevant X thusbelongs TX . latter case, show either Z known bX transitionfunction FS (a, ) 1-1 Z bX , causal closure Z actionapplicable bX .Indeed, proof contradiction let us suppose Z known bXtransition function 1-1. Then, two valuations s1 , s2 bX twoprogressions s01 FX (a, s1 ) s02 FX (a, s2 ) s1 [Z] 6= s2 [Z] s01 [Z] = s02 [Z].Therefore, observing value Z state s01 knowing initial beliefactions execution h, ai (where execution leads bX ), one cannot infervalue Z bX two different values compatibleobservation, namely s1 [Z] s2 [Z]. Hence, Z memory variable contradictingassumed causal-decomposability P .Case: X 0 X 00 observables. divide case two subcaseswhether variables X 0 X 00 causal ancestors X not. affirmativesubcase, BC (X 0 ) BC (X 00 ) BC (X). negative subcase, assume without lossgenerality X 0 causal ancestor X. Then, observable variableX 0 causal ancestor relevant X. Hence, BC (Y ) BC (X 0 )implies Z BC (Y ) BC (X 00 ) case reduced previous case.ReferencesAlbore, A., Palacios, H., & Geffner, H. (2009). translation-based approach contingentplanning. Proc. 21st Int. Joint Conf. Artificial Intelligence, pp. 16231628,Pasadena, California.Albore, A., Ramirez, M., & Geffner, H. (2010). Compiling uncertainty away nondeterministic conformant planning. Proc. 19th European Conf. Artificial Intelligence, pp. 465470, Lisbon, Portugal.Albore, A., Ramirez, M., & Geffner, H. (2011). Effective heuristics belief trackingplanning incomplete information. Proc. 21st Int. Conf. AutomatedPlanning Scheduling, pp. 29, Freiburg, Germany.Amir, E., & Russell, S. (2003). Logical filtering. Proc. 18th Int. Joint Conf. ArtificialIntelligence, pp. 7582, Acapulco, Mexico.967fiBonet & GeffnerBertoli, P., Cimatti, A., Roveri, M., & Traverso, P. (2001). Planning nondeterministic domains partial observability via symbolic model checking. Nebel, B.(Ed.), Proc. 17th Int. Joint Conf. Artificial Intelligence, pp. 473478, Seattle, WA.Morgan Kaufmann.Bonet, B., & Geffner, H. (2000). Planning incomplete information heuristic searchbelief space. Chien, S., Kambhampati, S., & Knoblock, C. (Eds.), Proc. 5thInt. Conf. Artificial Intelligence Planning Systems, pp. 5261, Breckenridge, CO.AAAI Press.Bonet, B., & Geffner, H. (2011). Planning partial observability classical replanning:Theory experiments. Proc. 22nd Int. Joint Conf. Artificial Intelligence, pp.19361941, Barcelona, Spain.Bonet, B., & Geffner, H. (2012a). Action selection MDPs: Anytime AO* vs. UCT.Proc. 26th AAAI Conf. Artificial Intelligence, pp. 17491755, Toronto, Canada.Bonet, B., & Geffner, H. (2012b). Width complexity belief tracking nondeterministic conformant contingent planning. Proc. 26th AAAI Conf.Artificial Intelligence, pp. 17561762, Toronto, Canada.Bonet, B., & Geffner, H. (2013). Causal belief decomposition planning sensing:Completeness results practical approximation. Proc. 23rd Int. Joint Conf.Artificial Intelligence, pp. 22752281, Beijing, China.Bonet, B., & Geffner, H. (2014). Flexible scalable partially observable planninglinear translations. Proc. 28th AAAI Conf. Artificial Intelligence, pp. 22352241,Quebec City, Canada.Boyen, X., & Koller, D. (1998). Tractable inference complex stochastic processes.Cooper, G., & Moral, S. (Eds.), Proc. 14th Conf. Uncertainty Artificial Intelligence, pp. 3342, Madison, WI. Morgan Kaufmann.Brafman, R. I., & Shani, G. (2012). Replanning domains partial informationsensing actions. Journal Artificial Intelligence Research, 1 (45), 565600.Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics beliefspace search. Journal Artificial Intelligence Research, 26, 3599.Choi, A., & Darwiche, A. (2006). edge deletion semantics belief propagationpractical impact approximation quality. Proc. 21st Nat. Conf. ArtificialIntelligence, pp. 11071114.Cimatti, A., Roveri, M., & Bertoli, P. (2004). Conformant planning via symbolic modelchecking heuristic search. Artificial Intelligence, 159, 127206.Darwiche, A., & Marquis, P. (2002). knowledge compilation map. Journal ArtificialIntelligence Research, 17, 229264.Dechter, R., & Beek, P. V. (1997). Local global relational consistency. TheoreticalComputer Science, 173 (1), 283308.Doucet, A., Freitas, N. D., Murphy, K., & Russell, S. (2000). Rao-blackwellised particle filtering dynamic bayesian networks. Proc. 16th Conf. Uncertainty ArtificialIntelligence, pp. 176183.968fiBelief Tracking Planning SensingEdelkamp, S. (2001). Planning pattern databases. Cesta, A. (Ed.), Proc. 6thEuropean Conf. Planning, pp. 1324, Toledo, Spain. Springer: LNCS.Goldman, R. P., & Boddy, M. S. (1996). Expressive planning explicit knowledge.Drabble, B. (Ed.), Proc. 3rd Int. Conf. Artificial Intelligence Planning Systems,pp. 110117, Edinburgh, Scotland. AAAI Press.Hoffmann, J., & Brafman, R. I. (2005). Contingent planning via heuristic forward searchimplicit belief states. Biundo, S., Myers, K., & Rajan, K. (Eds.), Proc. 15thInt. Conf. Automated Planning Scheduling, pp. 7180, Monterey, CA. MorganKaufmann.Hoffmann, J., & Brafman, R. I. (2006). Conformant planning via heuristic forward search:new approach. Artificial Intelligence, 170, 507541.Kaelbling, L. P., Littman, M., & Cassandra, A. R. (1999). Planning acting partiallyobservable stochastic domains. Artificial Intelligence, 101, 99134.Kaye, R. (2000). Minesweeper NP-Complete. Mathematical Intelligencer, 22 (2), 915.Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. Proc. 17thEuropean Conf. Machine Learning, pp. 282293. Springer.Lin, W., Buffet, O., Lee, C., & Teytaud, O. (2012). Optimistic heuristics Minesweeper.Proc. Int. Computer Symposium (ICS-12). http://hal.inria.fr/docs/00/75/05/77/PDF/mines3.pdf.Palacios, H., & Geffner, H. (2009). Compiling uncertainty away conformant planningproblems bounded width. Journal Artificial Intelligence Research, 35, 623675.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems. Morgan Kaufmann.Ramirez, M., & Geffner, H. (2007). Structural relaxations variable renamingcompilation solving MinCostSAT. Proc. 13th Int. Conf. PrinciplesPractice Constraint Programming, pp. 605619. Springer.Rintanen, J. (2008). Regression classical nondeterministic planning. Ghallab,M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), Proc. 18th EuropeanConf. Artificial Intelligence, pp. 568572, Patras, Greece.Russell, S., & Norvig, P. (2009). Artificial Intelligence: Modern Approach (3rd edition).Prentice Hall.Scott, A., Stege, U., & Rooij, I. V. (2011). Minesweeper may NP-CompleteHard nonetheless. Science+Business Media, LLC, 33 (4), 517.Shani, G., & Brafman, R. I. (2011). Replanning domains partial informationsensing actions. Proc. 22nd Int. Joint Conf. Artificial Intelligence, pp. 20212026, Barcelona, Spain.Shani, G., Poupart, P., Brafman, R. I., & Shimony, S. (2008). Efficient ADD operationspoint-based algorithms. Rintanen, J., Nebel, B., & J. C. Beck, E. A. H. (Eds.),Proc. 18th Int. Conf. Automated Planning Scheduling, pp. 330337, Sydney,Australia.969fiBonet & GeffnerSilver, D., & Veness, J. (2010). Monte-Carlo planning large POMDPs. Proc. 24thAnnual Conf. Advances Neural Information Processing Systems, pp. 21642172.Sipser, M. (2006). Introduction Theory Computation (2nd edition). Thomson CourseTechnology, Boston, MA.Smith, D., & Weld, D. (1998). Conformant graphplan. Mostow, J., & Rich, C. (Eds.),Proc. 15th Nat. Conf. Artificial Intelligence, pp. 889896, Madison, WI. AAAIPress / MIT Press.To, S. T., Pontelli, E., & Son, T. C. (2011). effectiveness CNF DNF representations contingent planning. Proc. 22nd Int. Joint Conf. Artificial Intelligence,pp. 20332038, Barcelona, Spain.Tran, V., Nguyen, K., Son, T. C., & Pontelli, E. (2013). conformant planner basedapproximation: CpA(H). ACM Trans. Intelligent Systems Technology, 4 (2),36.Weld, D., Anderson, C., & Smith, D. (1998). Extending Graphplan handle uncertaintysensing actions. Proc. 15th Nat. Conf. Artificial Intelligence, pp. 897904.AAAI Press.970fiJournal Artificial Intelligence Research 50 (2014) 189-233Submitted 03/14; published 05/14Efficient Algorithm Estimating State SequencesImprecise Hidden Markov ModelsJasper De BockGert de CoomanJASPER . DEBOCK @ UGENT.GERT. DECOOMAN @ UGENT.Ghent University, SYSTeMS Research GroupTechnologieparkZwijnaarde 9149052 Zwijnaarde, BelgiumAbstractpresent efficient exact algorithm estimating state sequences outputs observations imprecise hidden Markov models (iHMMs). uncertainty linking one state next,linking state output, represented set probability mass functions insteadsingle mass function. consider best estimates state sequences maximal sequences posterior joint state model conditioned observed output sequence, associatedgain function indicator state sequence. corresponds generalisesfinding state sequence highest posterior probability (precise-probabilistic) HMMs,thereby making algorithm generalisation one Viterbi. argue computational complexity algorithm worst quadratic length iHMM, cubicnumber states, essentially linear number maximal state sequences. importantfeature imprecise approach may one maximal sequence, typicallyinstances precise-probabilistic counterpart sensitive choice prior.binary iHMMs, investigate experimentally number maximal state sequences depends model parameters. also present application optical character recognition,demonstrating algorithm usefully applied robustify inferences madeprecise-probabilistic counterpart.1. Introductionfield Artificial Intelligence, probabilistic graphical models become powerful tool,especially domains reasoning uncertainty needed (Koller & Friedman, 2009;Pearl, 1988). Usually, uncertainty expressed probabilities, estimated dataelicited domain experts. However, assumption probabilities obtained,matter, exist, always realistic. example happen multipleexperts disagree, rounding errors occur, available data limited; lattereither inherent problem consequence economic temporal constraints.order relax assumption, one use theory imprecise probabilities. basicidea allow sets probability distributions rather requiring specification singleone. way, partial probabilistic information expressed easily, example, meanslinear constraints probability distributions. theory imprecise probability encompassesnumber different, closely related frameworks; coherent lower previsions (Walley, 1991),interval probabilities (Weichselberger, 2000) belief functions (Dempster, 1967; Shafer, 1976)well-known examples.c2014AI Access Foundation. rights reserved.fiD E B OCK & E C OOMANcontext graphical models, imprecise-probabilistic ideas used developnotion credal network (Cozman, 2000, 2005). similar Bayesian network,general sense allows local uncertainty models imprecisely specified,sets probability distributions. gain generality, however, comes price addedcomputational complexity existing algorithms either approximative cannot handlelarge networks. fact, inferences credal networks proven NP-hard even singlyconnected networks ternary variables (Mau, de Campos, Benavoli, & Antonucci, 2013).notable exception intractability inference problems credal networks occursdrop so-called strong independence assumption usually associated credal networks replace assessment epistemic irrelevance. Strong independence requirescredal network convex hull (precise) Bayesian networks, whereas epistemic irrelevanceless restrictive property, imposed imprecise model instead individual precise models consists of; information difference twoapproaches, see example pioneering work Cozman (2000). Recent work (De Cooman,Hermans, Antonucci, & Zaffalon, 2010) shown use epistemic irrelevance guarantees efficient algorithm updating beliefs single target node credaltree, essentially linear number nodes tree. imprecise-probabilistic hidden Markov models (iHMMs), credal network equivalent hidden Markov models(HMMs), efficiency single target node inferences succesfully exploited developimprecise-probabilistic counterpart Kalman filter (Benavoli, Zaffalon, & Miranda, 2011).paper, tackle imprecise-probabilistic counterpart another important applicationHMMs: finding sequence hidden states highest posterior probability conditional observed sequence outputs (Rabiner, 1989). HMMs precise local transitionemission probabilities, efficient dynamic programming algorithm performing taskdeveloped Viterbi (1967). imprecise-probabilistic HMMs however, know algorithm literature computational complexity comes even close Viterbis.remedy situation developing efficient exact algorithm, called EstiHMM1 , solvesfollowing imprecise-probabilistic generalisation state estimation problem: given observed sequence outputs, maximal (Troffaes, 2007; Walley, 1991) state sequencesposterior joint model?important difference imprecise approach conventional preciseprobabilistic approach EstiHMM algorithm may sometimes return one solution,whereas Viterbi algorithm always produce single one. imprecise iHMMis, maximal state sequences be. precise HMMs, EstiHMM Viterbialgorithms produce identical results. advantage behaviour EstiHMM algorithmtypically return one maximal sequence instances preciseapproach sensitive choice prior. cases, set-valued solution EstiHMMalgorithm likely contain correct hidden sequence. application optical characterrecognition (see Section 9) illustrates advantage convincingly.credal network point view, main contribution paper EstiHMM algorithm itself. especially surprising algorithm, provides efficientsolution inference problem deals multiple target nodes once, situation which,general, difficult handle current state art algorithms field. think1. EstiHMM: Estimation imprecise Hidden Markov Models190fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSpromising results paper motivate study similar problems network topologiesgo beyond HMMs.importance results HMM community and, extension, field AIgeneral, illustrate model uncertaintynot confused probabilisticuncertainty intrinsic model itselfcan dealt efficiently can,time, lead informative, set-valued estimates (sets maximal state sequences) usefullyapplied real-life problems. believe model uncertainty relevant subfields AIdifficultif impossibleto accurately pinpoint single probability distribution.model uncertainty might severe impact resulting inferences and, so,taken account basing decisions inferences.start Section 3 describing imprecise hidden Markov models special casecredal trees epistemic irrelevance. show particular use ideas underlyingMePiCTIr2 algorithm (De Cooman et al., 2010) construct conservative joint modelimprecise local transition emission models. also derive number interestinguseful formulas construction. results section assume basic knowledgetheory coherent lower previsions. include short introduction theory Section 2.Section 4, explain maximality criterion show leads set optimalestimates hidden state sequence. Finding maximal state sequences seems dauntingtask first: search space grows exponentially length Markov chain.However, shown Section 5, use basic formulas Section 3 derive appropriateversion Bellmans Principle Optimality (Bellman, 1957), resulting exponential reductionsearch space. using number additional tricks, including clever reformulationmaximality criterion, enables us Section 6 devise EstiHMM algorithm,efficiently constructs set maximal state sequences.Section 7 discusses computational complexity EstiHMM algorithm. showessentially linear number maximal sequences, quadratic length chain,cubic number states. perceive complexity comparable Viterbialgorithm, especially realising latter makes simplifying step resolving tiesless arbitrarily order produce single optimal state sequence.Section 8, consider special case binary iHMMs, investigate experimentallynumber maximal state sequences depends model parameters. comment interesting structures emerge, provide heuristic explanation them. also demonstratealgorithms efficiency calculating maximal sequences iHMM length 100.Finally, Section 9, present application optical character recognition. clearlydemonstrates advantages algorithm gives clear indication EstiHMM algorithm able robustify results existing Viterbi algorithm intelligent manner.conclude paper Section 10 discuss number possible avenues future research. order make main argumentation readable possible, technical proofsrelegated appendix.2. Freshening Coherent Lower Previsionsbegin basic theory coherent lower previsions; information, referWalleys book (1991) recent survey Miranda (2008).2. MePiCTIr: Message Passing Credal Trees Irrelevance.191fiD E B OCK & E C OOMANCoherent lower previsions special type imprecise probability model. Roughly speaking,whereas classical probability theory assumes subjects uncertainty representedsingle probability mass function, theory imprecise probabilities effectively works setspossible probability mass functions, thereby allows imprecision well indecisionmodelled represented. people unfamiliar theory, looking wayrobustifying classical theory perhaps easiest way understand interpret it,use approach here.2.1 Unconditional Lower PrevisionsLet X non-empty, finite3 set possible states. call real-valued function f Xgamble denote set gambles X G (X). Consider set probability massfunctions X. mass function p , associate linear previsionor expectation functionalPp , defined G (X). every gamble f G (X) , Pp ( f ) := xX p(x) f (x)expected value f , associated probability mass function p. define lowerprevisionor lower expectation functionalPM corresponds set followinglower envelope linear previsions:PM ( f ) := inf {Pp ( f ) : p } f G (X).(1)Similarly, define upper previsionor upper expectation functionalPMPM ( f ) := sup {Pp ( f ) : p } = inf {Pp ( f ) : p } = PM ( f ) f G (X). (2)mostly talk lower previsions, since follows conjugacy relation (2)two models mathematically equivalent.event subset set possible values X: X. event,associate indicator IA , gamble X assumes value 1 A, 0 outside A.callPM (A) := PM (IA ) = inf p(x) : pxAlower probability event A, similarly PM (A) := PM (IA ) upper probability.shown (Walley, 1991) functional PM satisfies following set interestingmathematical properties, define coherent lower prevision:C1. PM ( f ) min f f G (X),C2. PM ( f ) = PM ( f ) f G (X) real 0,C3. PM ( f + g) PM ( f ) + PM (g) f , g G (X).[non-negative homogeneity][superadditivity]Every set mass functions uniquely defines coherent lower prevision PM , generalconverse hold. However, limit sets mass functionsclosed convexwhich makes credal setsthey one-to-one correspondencecoherent lower previsions (Walley, 1991). implies use theory coherent3. theory coherent lower previsions applicable non-finite sets well, expense complications.However, present purposes, suffices consider finitary case only.192fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSlower previsions tool reasoning closed convex sets probability mass functions.on, longer explicitly refer credal sets , simply talkcoherent lower previsions P. useful keep mind always unique credal setcorresponds coherent lower prevision: P = PM unique credal set , given= {p : ( f G (X))Pp ( f ) P( f )}.special kind imprecise model X vacuous lower prevision. modelrepresents complete ignorance therefore set possible mass functions Xcredal set . shown easily every f G (X), corresponding lower previsiongiven P( f ) = min f .2.2 Conditional Lower PrevisionsConditional lower upper previsions, extensions classical conditional expectation functionals, defined similar, intuitively obvious way: lower envelopes associatedsets conditional mass functions.Consider variable X X variable . conditional lower prevision P(|Y )set G (X) gambles X two-place real-valued function. gamble f X, P( f |Y )gamble , whose value P( f |y) lower prevision f , conditional event= y. , lower prevision P(|y) coherentsatisfies conditions C1C3thencall conditional lower prevision P(|Y ) separately coherent. sometimes usefulextend domain conditional lower prevision P(|y) G (X) G (X ) lettingP( f |y) := P( f (, y)|y) gambles f X .number conditional lower previsions involving number variables,must separately coherent, also make sure satisfy stringentjoint coherence requirement. Explaining detail would take us far; Walley (1991) providesdetailed discussion motivation. present purposes, suffices say joint coherenceclosely related making sure conditional lower previsions lower envelopesassociated conditional mass functions satisfy Bayess Rule.given lower prevision P G (X ), may one corresponding conditional lower prevision P(|Y ) jointly coherent P. Depending updating methodused, one obtains different model.use naturalcoherent lower prevision P(|Y ) definedextension, conditionalP( f |y) := max R : P(I{y} [ f ]) 0 P({y}) > 0 vacuous thus givenP( f |y) := min f P({y}) = 0. smallest, conservative coherent way conditioninglower prevision. P({y}) > 0, corresponds conditioning every probability mass functioncredal set P observation = taking lower envelopeconditioned mass functions.use regular extension, P(|Y ) defined P( f |y) := max { R : P(Iy [ f ]) 0}P({y}) > 0 vacuous P({y}) = 0. P({y}) > 0, regular extension (a) gives usgreatestmost informativeconditional lower prevision jointly coherent originalunconditional lower prevision (b) corresponds taking mass functions p credal setP p(y) 6= 0, conditioning observation = taking lowerenvelope.Natural regular extension coincide P({y}) > 0 P({y}) = 0 may differP({y}) > P({y}) = 0. latter case, natural extension vacuous, regular extension usu193fiD E B OCK & E C OOMANally remains informative. Furthermore, P({y}) > 0, every coherent updating methodyields conditional lower prevision lies obtained natural regular extension (Walley, 1991; Miranda, 2009).2.3 Different Interpretations Lower Previsionsseen, coherent lower prevision P serves alternative representationclosed convex set probability mass functions. Often, credal set interpretedset candidates one true unknown probability mass function. interpretation particularly intuitive people used working classical probability theory.Walley (1991, Section 2.10.4) calls sensitivity analysis interpretation. sake completeness, mention coherent lower previsions also given behavioural interpretation, without using notion probability mass function. lower prevision P( f )gamble f G (X) interpreted supremum acceptable buying price subjectwilling pay order gain thepossibly negativereward f (x) outcome x Xexperiment determined. Walley discusses alternative interpretation extensively.3. Basic Notionsimprecise hidden Markov model depicted using following probabilistic graphicalmodel:Q1 ()Q2 (|X1 )Qk (|Xk1 )Qn (|Xn1 )State sequence:X1X2XkXnOutput sequence:O1O2OkS1 (|X1 )S2 (|X2 )Sk (|Xk )Sn (|Xn )Figure 1: Tree representation hidden Markov modeln natural number. state variables X1 , . . . , Xn assume values respective finitesets X1 , . . . , Xn , output variables O1 , . . . , assume values respective finite sets O1 ,. . . , . denote generic values Xk xk , xk zk , generic values Ok ok .3.1 Local Uncertainty Modelsassume following local uncertainty models variables. X1 ,marginal lower prevision Q1 , defined set G (X1 ) real-valued mapsor gamblesX1 . subsequent states Xk , k {2, . . . , n}, conditional lower previsionQk (|Xk1 ) defined G (Xk ), called transition model. order maintain uniformity notation,also denote marginal lower prevision Q1 conditional lower prevision Q1 (|X0 ),X0 denotes variable may assume single value x0 X0 := {x0 }, whose194fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSvalue therefore certain. gamble fk G (Xk ), Qk ( fk |Xk1 ) interpreted gambleXk1 , whose value Qk ( fk |xk1 ) xk1 Xk1 lower prevision gamble fk (Xk ),conditional Xk1 = xk1 .addition, output Ok , k {1, . . . , n}, conditional lower previsionSk (|Xk ) defined G (Ok ), called emission model. gamble gk G (Ok ), Sk (gk |Xk )interpreted gamble Xk , whose value Sk (gk |xk ) xk Xk lower previsiongamble gk (Ok ), conditional Xk = xk .take localmarginal, transition emissionuncertainty models separatelycoherent. Recall simply means k {1, . . . , n}, lower prevision Qk (|xk1 )coherentas unconditional lower previsionfor xk1 Xk1 Sk (|xk )coherent xk Xk .3.2 Interpretation Graphical Structureassume graphical representation Figure 1 represents following irrelevanceassessments: conditional mother variable, non-parent non-descendants variabletree epistemically irrelevant variable descendants. say variableX epistemically irrelevant variable observing X affect beliefs .Mathematically stated terms lower previsions: P( f (Y )) = P( f (Y )|x) f G (Y )x X.go on, useful introduce mathematical short-hand notationdescribing joint variables tree Figure 1. 1 k ` n, denote tuple(Xk , Xk+1 , . . . , X` ) Xk:` , tuple (Ok , Ok+1 , . . . , O` ) Ok:` . Xk:` variable assumevalues set Xk:` := `r=k Xr , Ok:` variable assume values setOk:` := `r=k . Generic values Xk:` denoted xk:` , xk:` zk:` , generic values Ok:`ok:` .Example 1. Consider variable Xk mother variable Xk1 Figure 1. variables X1:k2O1:k1 non-parent non-descendants, variables Xk+1:n Ok:n descendants.interpretation graphical structure Figure 1 implies knowconditionalonthe value xk1 Xk1 , additionally learning values variables X1 , . . . , Xk2O1 , . . . , Ok1 change beliefs Xk:n Ok:n .3.3 Constructing Global Uncertainty ModelUsing local uncertainty models, want construct global model: joint lower previsionP G (X1:n O1:n ) variables (X1:n , O1:n ) tree. joint lower prevision(i) jointly coherent local models; (ii) encode epistemic irrelevance assessmentsencoded tree; (iii) small, conservative,4 possible. special casegeneral problem credal trees, discussed solved great detail De Cooman etal. (2010). section, summarise solution iHMMs give heuristic justificationit; De Cooman et al. prove joint model presented indeedconservative lower prevision coherent local models captures epistemicirrelevance assessments encoded tree.4. Recall pointwise smaller lower previsions correspond larger credal sets.195fiD E B OCK & E C OOMANproceed recursive manner. k {1, . . . , n} xk1 Xk1 , considersmallest coherent joint lower prevision Pk (|xk1 ) G (Xk:n Ok:n ) variables (Xk:n , Ok:n )iHMM depicted Figure 2, representing subtree tree represented Figure 1,lower prevision Qk (|xk1 ) acting marginal model first state variable Xk . Note that,due notational trick introduced Section 3.1, global model P identifiedconditional lower prevision P1 (|x0 ).Qk (|xk1 )Qk+1 (|Xk )XkXk+1Pk (|Xk1 )E k (|Xk )OkOk+1Sk (|Xk )Sk+1 (|Xk+1 )Pk+1 (|Xk )Figure 2: Subtree iHMM involving variables (Xk:n , Ok:n )aim develop recursive expressions enable us construct Pk (|xk1 )Pk+1 (|Xk ), Sk (|Xk ) Qk (|xk1 ). Using expressions eventuallyyield global model P = P1 (|x0 ).first step, consider xk Xk combine joint model Pk+1 (|xk ) variables(Xk+1:n , Ok+1:n ), defined G (Xk+1:n Ok+1:n )see thick dotted lines Figure 2,withlocal model Sk (|xk ) variable Ok , defined G (Ok ). lead joint model E k (|xk )variables (Xk+1:n , Ok:n ), defined G (Xk+1:n Ok:n )see semi-thick dotted linesFigure 2. trivial k = n, since must E n (|xn ) = Sn (|xn ).k 6= n, solution less obvious. joint model constructed many different ways,impose conditions. first condition E k (|xk ) coherentlower prevision jointly coherent marginal models Pk+1 (|xk ) Sk (|xk ). second, rather obvious, condition E k (|xk ) coincide Pk+1 (|xk ) Sk (|xk )respective domains. third condition model capture epistemic irrelevanceassessments encoded tree. particular state that, conditional Xk = xk , two variables (Xk+1:n , Ok+1:n ) Ok epistemically independent, words, epistemicallyirrelevant one another.model meets conditions called independent product (De Cooman, Miranda, & Zaffalon, 2011) Pk+1 (|xk ) Sk (|xk ). Generally speaking, independent product unique. call pointwise smallest, conservative, possible independent196fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSproducts, always exists, independent natural extension (Walley, 1991; De Cooman et al.,2011) Pk+1 (|xk ) Sk (|xk ), denote Pk+1 (|xk ) Sk (|xk ).Summarising, E k (|xk ) given(Sn (|xn )k = nE k (|xk ) :=Sk (|xk ) Pk+1 (|xk ) k = n 1, . . . , 1.(3)conditionally independent natural extension properties studied great detailDe Cooman et al. (2011). purposes paper, suffice recallstudy thatvery much like independent products precise probability modelssuch independentnatural extensions factorising, implies particularE k ( f g|xk ) = E k (gE k ( f |xk )|xk ) = Sk (gPk+1 ( f |xk )|xk )(Sk (g|xk )Pk+1 ( f |xk )=Sk (g|xk )Pk+1 ( f |xk )Pk+1 ( f |xk ) 0Pk+1 ( f |xk ) 0= Sk (g|xk ) fi Pk+1 ( f |xk ),(4)f G (Xk+1:n Ok+1:n ) non-negative g G (Ok )we call gamble non-negativevalues are. expression, first equality actual factorisation property. secondequality holds E k (|xk ) coincides Pk+1 (|xk ) Sk (|xk ) respective domains.third equality follows conjugacy relationEquation (2)and coherence conditionC2, fourth used shorthand notation fi x := max{0, x} + min{0, x}.on, also use analogous notation n fi x := n max{0, x} + n min{0, x}.second final step, combine joint model E k (|Xk ) variables (Xk+1:n , Ok:n ),defined G (Xk+1:n Ok:n ), local model Qk (|xk1 ) variable Xk , defined G (Xk ),joint model Pk (|xk1 ) variables (Xk:n , Ok:n ), defined G (Xk:n Ok:n ).shown elsewhere (Miranda & de Cooman, 2007; Walley, 1991) conservative coherentway this, means marginal extension, also known law iterated lowerexpectations. leads Pk (|xk1 ) := Qk (E k (|Xk )|xk1 ), or, allow xk1 rangeXk1 :Pk (|Xk1 ) := Qk (E k (|Xk )|Xk1 ).(5)practical purposes, useful see equivalentPk ( f |Xk1 ) = Qkxk XkfifiI{xk } E k ( f (xk , Xk+1:n , Ok:n )|xk )fiXk1f G (Xk:n Ok:n ). Recall expression, indicator I{xk } gamble Xkassumes value 1 Xk = xk 0 Xk 6= xk .197fiD E B OCK & E C OOMAN3.4 Interesting Lower Upper ProbabilitiesWithout much trouble,5 use Equations (3)(5) derive following expressionsnumber interesting lower upper probabilities:nPk ({ok:n } {xk:n }|xk1 ) = Si ({oi }|xi )Qi ({xi }|xi1 )(6)Pk ({ok:n } {xk:n }|xk1 ) = Si ({oi }|xi )Qi ({xi }|xi1 )(7)i=kni=kxk1 Xk1 , xk:n Xk:n , ok:n Ok:n k {1, . . . , n},nE k ({ok:n } {xk+1:n }|xk ) = Sk ({ok }|xk )Si ({oi }|xi )Qi ({xi }|xi1 )(8)Si ({oi }|xi )Qi ({xi }|xi1 ).(9)i=k+1nE k ({ok:n } {xk+1:n }|xk ) = Sk ({ok }|xk )i=k+1xk Xk , xk+1:n Xk+1:n , ok:n Ok:n k {1, . . . , n}. Recall equate eventsindicators, lower upper prevision indicators correspond lowerupper probability event; see Section 2. example, Equation (6), Pk ({ok:n }{xk:n }|xk1 ) := Pk (I{ok:n } I{xk:n } |xk1 ) lower probability that, conditional Xk1 = xk1 ,rest hidden sequence value xk:n , corresponding observations ok:n . joint lowerprobablity obtained simply multiplying relevant local lower (transition emission) probabilities.assume throughoutP({x1:n } {o1:n }) > 0 x1:n X1:n o1:n O1:nor, equivalentlyby Equation (7), k = 1, local upper probabilities positive,sense (De Cooman et al., 2010):Qk ({xk }|xk1 ) > 0 Sk ({ok }|xk ) > 0k {1, . . . , n}, xk1 Xk1 , xk Xk ok Ok . (10)assumption weak restrictive practical purposes. impreciseprobabilistic local models often constructed adding margin error around precisemodel, thereby making upper transition probabilities positive construction. however allow lower transition probabilities zero, something happen oftenpractical problems.Proposition 1. local upper probabilities positiveEquation (10),k {1, . . . , n}, xk Xk , xk1 Xk1 ok:n Ok:n Pk ({ok:n }|xk1 ) > 0 E k ({ok:n }|xk ) > 0.5. example, derive Equations (6) (7) Appendix A.198fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS4. Estimating States Outputshidden Markov model, states directly observable, outputs are, generalaim use outputs estimate states. concentrate following problem: Supposeobserved output sequence o1:n , estimate state sequence x1:n . use essentially Bayesian approach so, need allow fact working impreciserather precise probability models. consider optimal estimates state sequencesmaximal, criterion introduce Section 4.2; see Section 4.3 two alternative criteria,consider context paper. main contribution sectionformulation maximality stated directly terms unconditional global model P,instead conditional model P(|o1:n ) conventionally used purpose. Furthermore,rather surprisingly, alternative formulation valid regardless whether use regularnatural extension derive P(|o1:n ) P.4.1 Updating iHMMfirst step approach consists updating (or conditioning) joint model P := P1 (|x0 )observed outputs O1:n = o1:n . mentioned Section 2, unique coherent wayperform updating. However, particular problem solving paper,happens makes difference updating method used, long coherent.time being, use regular extension, later Section 4.2, showcoherent updating method yields results.Since follows positivity assumption (10) Proposition 1 P({o1:n }) > 0, regularextension leads us consider updated lower prevision P(|o1:n ) G (X1:n ), given by:P( f |o1:n ) := max R : P(I{o1:n } [ f ]) 0 gambles f X1:n .(11)Using coherence joint lower prevision P, hard prove P({o1:n }) > 0,P(I{o1:n } [ f ]) strictly decreasing continuous function , therefore uniquezerosee Lemma 7(i)&(iii) Appendix A. consequence, f G (X1:n )P( f |o1:n ) 0 ( > 0)P(I{o1:n } [ f ]) < 0 P(I{o1:n } f ) 0.(12)fact, hard infer strictly decreasing continuous character P(I{o1:n } [ f ])P( f |o1:n ) P(I{o1:n } f ) sign. either negative, positiveequal zero; see also Figure 3.P(I{o1:n } f )P(I{o1:n } [ f ])P( f |o1:n )Figure 3: Conditional versus unconditional lower prevision199fiD E B OCK & E C OOMANEquation (12) crucial importance on. However, general, want allowP({o1:n }) zerosince may happen allow lower transition probabilities zero,requiring P({o1:n }) > 0because follows positivity assumption (10)Proposition 1. will, generally speaking, invalidate second equivalence Equation (12):turns implication only. But, limit specific type gambles X1:nform f = I{x1:n } I{x1:n } , still prove following important theorem.Theorem 2. local upper probabilities positiveEquation (10), fixed valuesx1:n , x1:n X1:n o1:n O1:n , P(I{o1:n } [I{x1:n } I{x1:n } ]) P(I{x1:n } I{x1:n } |o1:n )sign. positive, negative zero.4.2 Maximal State Sequencesnext step consists using posterior model P(|o1:n ) find best estimates statesequence x1:n . Bayesian approach, usually done solving decision-making,optimisation problem: associate gain function I{x1:n } every candidate state sequence x1:n ,select best estimates state sequences x1:n maximise posterior expected gain,resulting state sequences maximal posterior probability.generalise decision-making approach towards working imprecise probabilitymodels. criterion use decide estimates optimal given gain functions(WalleySen) maximality (Troffaes, 2007; Walley, 1991). Maximality numberdesirable properties make sure works well optimisation contexts (De Cooman & Troffaes,2005; Huntley & Troffaes, 2010), well-justified behavioural point view, wellrobustness approach, shall see presently.express strict preference two state sequence estimates x1:n x1:nfollows:x1:n x1:n P(I{x1:n } I{x1:n } |o1:n ) > 0.behavioural interpretation, expresses subject lower prevision P(|o1:n ) disposed pay strictly positive amount utility replace gain associated estimatex1:n gain associated estimate x1:n ; Walley (1991, Section 3.9) provides additionalinformation. Alternatively, robustness point view, expresses conditionalmass function p(|o1:n ) credal set associated updated lower prevision P(|o1:n ),state sequence x1:n posterior probability p(x1:n |o1:n ) strictly higher posteriorprobability p(x1:n |o1:n ) state sequence x1:n .binary relation thus defined strict partial orderan irreflexive transitive binaryrelationon set state sequences X1:n , consider estimate x1:n optimalundominated, maximal, strict partial order:x1:n opt (X1:n |o1:n ) (x1:n X1:n )x1:n 6 x1:n(x1:n X1:n )P(I{x1:n } I{x1:n } |o1:n ) 0(x1:n X1:n )P(I{o1:n } [I{x1:n } I{x1:n } ]) 0,(13)useful last equivalence follows Theorem 2. summary then, aimpaper develop efficient algorithm finding set maximal estimates opt (X1:n |o1:n ).statement Section 4.1, coherent updating method would yield resultsregular extension, justified. Since coherent updating unique P({o1:n }) > 0,200fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSsince case P({o1:n }) = 0 excluded Proposition 1 positivity assumption (10),need motivate statement special case P({o1:n }) = 0 P({o1:n }) > 0.use regular extension update model, optimal estimates given Equation (13). special case P({o1:n }) = 0, find x1:n X1:n x1:n X1:nP(I{o1:n } [I{x1:n } I{x1:n } ]) P(I{o1:n } ) = P({o1:n }) = 0,first inequality follows monotonicity coherent lower previsions (as consequence C1 C2). Therefore, find P({o1:n }) = 0, sequences optimal,resulting opt (X1:n |o1:n ) = X1:n .use natural extension update joint model, optimal state sequencesstill given Equation (13), final equivalence longer holds uses Theorem 2,assumes use regular extension perform updating joint model. However,special case P({o1:n }) = 0, natural extension definition leads updated modelequal vacuous one. Therefore, find x1:n X1:n x1:n X1:nP(I{x1:n } I{x1:n } |o1:n ) = min(I{x1:n } I{x1:n } ) 0.implies special case P({o1:n }) = 0 P({o1:n }) > 0identicalfound regular extensionnatural extension also results sequences optimal, meaningopt (X1:n |o1:n ) = X1:n .thus shown that, even special case P({o1:n }) = 0 P({o1:n }) > 0,set optimal sequences same, regardless whether use natural regular extensionupdate joint model. Since special case, every coherent updating method liestwo methods, bound yield opt (X1:n |o1:n ).therefore conclude results paper depend particular updating methodchosen, long coherent.4.3 Decision CriteriaInstead looking maximal state sequences, one could use decision criteria well (Troffaes, 2007), two discuss present section.first approach consider on, consists trying find so-called-maximin state sequences x1:n , maximise posterior lower probability:x1:n argmax P({x1:n }|o1:n ).x1:n X1:napproach basically optimises worst-case scenariothe lower probabilityand therefore regarded risk averse choice. computational point view, finding maximin sequences rather complicated affair. need optimise exponential number sequences, top that, every single lower probability P({x1:n }|o1:n )optimisation problem hard compute. positive side, recently discovered thatincase epistemic irrelevanceit possible calculate lower probabilities efficientlyrecursive manner. However, results published yet fall beyond scopecurrent paper. know algorithm calculate lower probabilities efficiently.case, issue still remains need optimise exponentially large set X1:n .201fiD E B OCK & E C OOMANsecond approach considered consists working so-calledE-admissible sequences, sequences maximise expected gain least oneconditional mass function p(|o1:n ) credal set associated updated lower previsionP(|o1:n ). one interprets imprecise model collectiona credal setof precise models,one unknown true model, one E-admissible solutions unknowntrue solution. E-admissible state sequences difficult compute. intuitive reasonneed solve precise problem every p(|o1:n ) credal set associatedP(|o1:n ), infinitely many. State art algorithms (Kikuti, Cozman, & de Campos, 2005; Utkin & Augustin, 2005) avoid issue, still quadratic search space.makes intractable present problem search space X1:n exponentiallength iHMM.Besides computational difficulties approaches, number additional reasons why, paper, focus maximal state sequences rather -maximinE-admissible ones. first important reason able develop algorithmdetermine efficiently; see Sections 6 7. Secondly, common advantagemaximality E-admissibility: higher imprecision model, solutionsreturned. contrast, even high imprecision, cases, one -maximinsequence (except two sequences highest conditional lower probability).application Section 9 clearly illustrates emitting single solution indeeduseful. Thirdly, cases decision criteria preferred, maximal state sequences still use every -maximin E-admissible state sequence guaranteedmaximal well (Troffaes, 2007). algorithm yields single maximal solution,also unique -maximin E-admissible solution. one maximal sequencereturned, regarded preprocessing step. example, know maximalsolutions, finding -maximin solutions amounts comparing posterior lower probabilitiesmaximal sequences only, instead sequences X1:n .4.4 Maximal Subsequencesshall see order find set maximal estimates, useful considergeneral sets so-called maximal subsequences: k {1, . . . , n} xk1 Xk1 , defineopt (Xk:n |xk1 , ok:n ):xk:n opt (Xk:n |xk1 , ok:n ) (xk:n Xk:n ) Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) 0.(14)interpretation sets immediate consider part original iHMMdepicted Figure 4, take Qk (|xk1 ) marginal model first state Xk . Then,explained Section 3.3, corresponding joint lower prevision G (Xk:n Ok:n ) preciselyPk (|xk1 ), sequence outputs ok:n , opt (Xk:n |xk1 , ok:n ) set statesequence estimates undominated estimate Xk:n . clearset opt (X1:n |o1:n ) eventually looking for, also written opt (X1:n |x0 , o1:n ).4.5 Useful Recursion EquationsFix k {1, . . . , n}. look Equation (14), see useful derive manageable expression lower prevision Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ). easily donesee202fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSQk (|xk1 )Qr (|Xr1 )Qn (|Xn1 )State subsequence:XkXrXnOutput subsequence:OkSk (|Xk )Sr (|Xr )Sn (|Xn )Figure 4: Tree representation part original iHMMAppendix Aby using Equations (3)(7) algebraic manipulations. consider three different cases. xk = xk k {1, . . . , n 1} then, using notation introduced Section 3.3:Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 )= Qk ({xk }|xk1 )Sk ({ok }|xk ) fi Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } ]|xk ). (15)xn = xnPn (I{on } [I{xn } I{xn } ]|xn1 ) = 0.(16)Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) = Qk (I{xk } (xk:n ) I{xk } (xk:n )|xk1 ),(17)xk 6= xk k {1, . . . , n}define, xk:n Xk:n :n(xk:n ) := E k (I{ok:n } I{xk+1:n } |xk ) = Sk ({ok }|xk )Si ({oi }|xi )Qi ({xi }|xi1 )(18)Si ({oi }|xi )Qi ({xi }|xi1 ).(19)i=k+1n(xk:n ) := E k (I{ok:n } I{xk+1:n } |xk ) = Sk ({ok }|xk )i=k+1useful realise (xk:n ) (xk:n ) shorthand notations lower upperprobabilities Equations (8) (9), fixed sequence observations. given sequencestates xk:n Xk:n , (xk:n ) (xk:n ) found simple backward recursion:(xk:n ) := (xk+1:n )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk )(xk:n ) := (xk+1:n )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk ),(20)(21)k {1, . . . , n 1}, starting from:(xn:n ) = (xn ) := Sn ({on }|xn ) (xn:n ) = (xn ) := Sn ({on }|xn ).203(22)fiD E B OCK & E C OOMAN5. Principle OptimalityDetermining state sequences opt (X1:n |o1:n ) directly using Equation (13) clearly complexity exponential length chain. going take dynamic programming approach (Bellman, 1957) reducing complexity deriving recursion equationsets optimal (sub)sequences opt (Xk:n |xk1 , ok:n ).Theorem 3 (Principle Optimality). k {1, . . . , n 1}, xk1 Xk1 xk:n Xk:n :Qk ({xk }|xk1 ) > 0 Sk ({ok }|xk ) > 0,xk:n opt (Xk:n |xk1 , ok:n ) xk+1:n opt (Xk+1:n |xk , ok+1:n ) .immediate consequence, findopt (Xk:n |xk1 , ok:n ) cand (Xk:n |xk1 , ok:n ) ,(23)set cand (Xk:n |xk1 , ok:n ) consists sequences Xk:n still elementopt (Xk:n |xk1 , ok:n ) according Theorem 3:cand (Xk:n |xk1 , ok:n ):=[xk opt (Xk+1:n |xk , ok+1:n )[xk Xk+1:n . (24)xk Pos/k (xk1 )xk Posk (xk1 )denotes concatenation state sequences set states Posk (xk1 ) Xk definedxk Posk (xk1 ) Qk ({xk }|xk1 ) > 0 Sk ({ok }|xk ) > 0.(25)Equation (24) simplifiescand (Xk:n |xk1 , ok:n ) =[xk opt (Xk+1:n |xk , ok+1:n )(26)xk Xklocal lower probabilities positive, generally true general caseconsidering here, upper probabilities required positive.6. Algorithm Finding Maximal State Sequencesuse Equation (23) devise algorithm constructing set opt (X1:n |o1:n ) maximalstate sequences recursive manner.6.1 Initial Set-up Using Backward Recursionbegin defining auxiliary notions. First all, consider following thresholds:nk (xk , xk |xk1 ) := min 0 : Qk (I{xk } aI{xk } |xk1 ) 0(27)k {1, . . . , n}, xk1 Xk1 x1 , x1 X1 x1 6= x1 .204fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSNext, definekmax (xk ) := max (zk:n ) kmax (xk ) := max (zk:n )zk:n Xk:nzk =xkzk:n Xk:nzk =xk(28)k {1, . . . , n} xk Xk . Using Equations (20)(21), calculated efficientlyusing following backward recursive (dynamic programming) procedure:kmax (xk ) =maxmax k+1(xk+1 )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk )xk+1 Xk+1max= Sk ({ok }|xk ) max k+1(xk+1 )Qk+1 ({xk+1 }|xk ),xk+1 Xk+1(29)kmax (xk ) =maxmax k+1(xk+1 )Sk ({ok }|xk )Qk+1 ({xk+1 }|xk )xk+1 Xk+1max= Sk ({ok }|xk ) max k+1(xk+1 )Qk+1 ({xk+1 }|xk ),xk+1 Xk+1(30)k {1, . . . , n 1}, startingnmax (xn ) = (xn ) = Sn ({on }|xn ) nmax (xn ) = (xn ) = Sn ({on }|xn ).(31)Finally, letoptk (xk |xk1 ) := max kmax (xk )k (xk , xk |xk1 ),xk Xkxk 6=xk(32)k {1, . . . , n}, xk1 Xk1 xk Xk .6.2 Recursive Solution Methodoptturns k (xk |xk1 ), calculated Equation (32), extremely useful. provedAppendix A, allow us significantly simplify Equation (14) follows:noptopt (Xk:n |xk1 , ok:n ) = xk:n cand (Xk:n |xk1 , ok:n ) : (xk:n ) k (xk |xk1 ) ,(33)which, k = n, reducesopt (Xn |xn1 , ) = xn Xn : (xn ) nopt (xn |xn1 ) .(34)Since opt (X1:n |x0 , o1:n ) = opt (X1:n |o1:n ), suggest following algorithm constructingset maximal state sequences.205fiD E B OCK & E C OOMANAlgorithm 1: ConstructMaximalsoptData: local lower upper probabilities parameters kmax k(calculated Section 6.1)Result: set maximal state sequences: opt (X1:n |o1:n )12345678910xn1 Xn1opt (Xn |xn1 , ) 0/xn Xnopt(xn ) n (xn |xn1 ) add xn opt (Xn |xn1 , )k n 1 1xk1 Xk1opt (Xk:n |xk1 , ok:n ) 0/xk:n cand (Xk:n |xk1 , ok:n )opt(xk:n ) k (xk |xk1 ) add xk:n opt (Xk:n |xk1 , ok:n )return opt (X1:n |x0 , o1:n )Algorithm 1 already much efficient straightforward implementationEquation (13), still room improvement. Posk (xk1 ) 6= Xk , Equation (24),know cand (Xk:n |xk1 , ok:n ) number elements exponential lengthconsidered sequences, making inefficient execute steps Lines 8 9 Algorithm 1.order circumvent problem, propose method require explicit checkinequality Criterion (33) elements cand (Xk:n |xk1 , ok:n ). approach identicalAlgorithm 1, except Lines 8 9, replaced Lines 8 9, givenAlgorithm 2.Algorithm 2: efficient alternative Lines 8 9 Algorithm 1.........xk Xkoptkmax (xk ) k (xk |xk1 ) Recur(xk , k)89...order able define recursive procedure Recur used Line 9 Algorithm 2,need additional notation. First all, k {1, . . . , n}, {k, . . . , n}, xk1 Xk1 ,xk:s Xk:s ok:n Ok:n , definecandxk:s (Xk:n |xk1 , ok:n ) := {xk:n cand (Xk:n |xk1 , ok:n ) : xk:s = xk:s } .(35)optSecondly, k {1, . . . , n}, {k, . . . , n}, xk1 Xk1 xk:s Xk:s , define k (xk:s |xk1 )optoptfollows. = k, let k (xk:k |xk1 ) := k (xk |xk1 ), given Equation (32).206fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSopt{k + 1, . . . , n}, k (xk:s |xk1 ) recursively definedoptoptk (xk:s |xk1 )k (xk:s1 |xk1 )=.Ss1 ({os1 }|xs1 )Qs ({xs }|xs1 )(36)Procedure Recur(xk:s , s)123456= nadd xk:n opt (Xk:n |xk1 , ok:n )elsexs+1 Xs+1candxk:s xs+1 (Xk:n |xk1 , ok:n ) 6= 0/optmax (xs+1s+1 ) k (xk:s xs+1 |xk1 ) Recur(xk:s xs+1 , + 1)following result establishes Lines 8 9 Algorithm 2 indeed valid alternativeLines 8 9 Algorithm 1.Theorem 4. set opt (Xk:n |xk1 , ok:n ) obtained executing Algorithm 2 correct,sense satisfies Equation (33).show Section 7, Algorithm 2 surprisingly efficient. One reasonsefficiency checking if-conditions Lines 5 6 Procedure Recur really easy,perhaps contrast one might think first sight. condition Line 6,optoptone use Equation (36) derive k (xk:s xs+1 |xk1 ) k (xk:s |xk1 ), latteropteither available previous call Procedure Recur or, = k, equal k (xk |xk1 ),already calculated initial set-up phase (see Section 6.1).explain checking condition Line 5 easy well, first need introduce datastructure use store sets opt (Xk:n |xk1 , ok:n ) optimal sequences.k = n, opt (Xn |xn1 , ) simply list states xn Xn . k < n, could also storeoptimal sequences xk:n opt (Xk:n |xk1 , ok:n ) simple list, would imply storinginformation multiple times, since initial part sequences identical.Furthermore, would make checking condition Line 5 Procedure Recur elaborate.therefore choose represent set opt (Xk:n |xk1 , ok:n ) collection trees. xk Xksatisfies inequality Line 9 corresponds root tree. paths treescorrespond elements opt (Xk:n |xk1 , ok:n ).Example 2. consider simple binary HMM with, {1, . . . , n}, Xi = {0, 1}.k = n 7, could example findopt (Xk:n | 0, ok:n ) = {00001000, 00001010, 00001110, 00011110, 10001010, 10001110}.set optimal sequences also represented collection trees, depictedFigure 5.Representing opt (Xk:n |xk1 , ok:n ) collection trees two important advantages.first advantage collection trees constructed step step running Algorithm 2. Line 9 algorithm, every call Procedure Recur, add current207fiD E B OCK & E C OOMAN00010011100001111010001010110Figure 5: Tree representation opt (Xk:n | 0, ok:n ), k = n 7state xk root node new tree. every subsequent recursive call Procedure Recur(in Line 6 procedure), add new child xs+1 already existing node xs , xslast state presently considered sequence xk:s .order step step construction lead representation opt (Xk:n |xk1 , ok:n ),path resulting set trees must length n k + 1. words, necessaryevery node representation least one child, except nodes form endpath length n k + 1. Equivalently, technically, necessary everyexecution Line 4 Procedure Recur, least one xs+1 Xs+1 satisfies subsequentif-conditions (in Lines 5 6). following result establishes condition always met.Theorem 5. Fix k {1, ..., n 1} {k, ..., n 1} consider execution Procedure Recur(xk:s , s) running Algorithm 2. least one xs+1 Xs+1obtain candxk:s xs+1 (Xk:n |xk1 , ok:n ) 6= 0/ [the if-condition Line 5]optmax (xs+1s+1 ) k (xk:s xs+1 |xk1 ) [the if-condition Line 6].left explain if-condition Line 5 Procedure Recurchecked efficiently. consider two distinct cases: xk Posk (xk1 ) xk/ Posk (xk1 ).xk/ Posk (xk1 ), Equations (24) (35), findcandxk:s xs+1 (Xk:n |xk1 , ok:n ) = xk:s xs+1 Xs+2:n 6= 0,/makes if-condition Line 5 trivially true. xk Posk (xk1 ), Equations (24) (35), candxk:s xs+1 (Xk:n |xk1 , ok:n ) 6= 0/ opt (Xk+1:n |xk , ok+1:n ) containssequence starts xk+1:s xs+1 . represent opt (Xk+1:n |xk , ok+1:n ) collectiontrees, equivalent checking whether xs+1 child node corresponds laststate sequence xk:s .brings us second advantage representing sets optimal sequences collection trees: makes checking if-condition Line 5 Procedure Recur elegantefficient. Line 8 Algorithm 2, xk/ Posk (xk1 ), subsequent callsProcedure Recur, Line 5 simply ignored. xk Posk (xk1 ), subsequent calls Procedure Recur, Lines 5 6 condensed single for-loopruns children node corresponds xs . Hence, xk Posk (xk1 ), executingLine 8 Algorithm 2including subsequent recursive calls Procedure Recurcan208fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSdone efficiently traversing depth-first trees make representationopt (Xk+1:n |xk , ok+1:n ), copying go, except nodes conditionLine 6 Procedure Recur satisfied.Example 3. continue Example 2. time, let k = n 8, implies Figure 5representation opt (Xk+1:n | 0, ok+1:n ). sake example, let us assume0 Posk (0) 1/ Posk (0). know Equations (23) (24) every sequencexk:n opt (Xk:n | 0, ok:n ) element either 0 opt (Xk+1:n | 0, ok+1:n ) 1 Xk+1:n . Hence,opt (Xk:n | 0, ok:n ) might example representation looks like one depicted Figure 6.0100000011101100111101111101Figure 6: Tree representation opt (Xk:n |0, ok:n ), k = n 8Figure 7 clarify Algorithm 2 constructs representation. two sequencesopt (Xk:n | 0, ok:n ) start 0 correspond greengrey monochrome versionspaperbranches topmost part Figure 7. first node two sequences addedLine 9 Algorithm 2 (in case, if-condition line turned true).green nodes topmost part Figure 7 added subsequent callsProcedure Recur. Checking if-condition Line 5 procedures done traversingdepth-first nodes representation opt (Xk+1:n | 0, ok+1:n ). redgreythicker outline monochrome versions papernodes correspond statesif-condition Line 6 satisfied. (white) descendants red nodes nevervisited algorithm; depict allow easy comparison Figure 5.tree representation three sequences opt (Xk:n | 0, ok:n ) start 1 constructedsimilar manner, illustrated bottommost part Figure 7. main differencesequences, since 1/ Posk (0), if-condition Line 5 Procedure Recurtrivially true, implying algorithm need traverse tree representationopt (Xk+1:n | 1, ok+1:n ), rather trough complete set Xk+1:n . Again, stop wheneverif-condition Line 6 satisfied, symbolised red nodes.6.3 Additional Commentmight happen available information consists assessments lower uppertransition emission probabilities only:Qk ({xk }|xk1 ), Qk ({xk }|xk1 ), Sk ({ok }|xk ) Sk ({ok }|xk )209fiD E B OCK & E C OOMANopt (Xk+1:n | 0, ok+1:n )000100111000011110100010101100000001100111101100001111101Figure 7: Clarification construction opt (Xk:n |0, ok:n ), k = n 8k {1, . . . , n}, xk1 Xk1 , xk Xk ok Ok . case, one use following method construct, k {1, . . . , n}, xk1 Xk1 xk , xk Xk xk 6= xk ,conservative value threshold k (xk , xk |xk1 ).conservative coherent models Qk (|Xk1 ) correspond assessments lowerupper probabilities singletons 2-monotone (de Campos, Huete, & Moral, 1994). Duecomonotone additivity (De Cooman, Troffaes, & Miranda, 2008), implies that:Qk (I{xk } aI{xk } |xk1 ) = Qk ({xk }|xk1 ) aQk ({xk }|xk1 )0, therefore Equation (27) leadsk (xk , xk |xk1 ) =Qk ({xk }|xk1 )Qk ({xk }|xk1 ).right-hand side smallest possible value threshold k (xk , xk |xk1 ) correspondingassessments Qk ({xk }|xk1 ) Qk ({xk }|xk1 ), leading conservative inferencestherefore largest possible sets maximal sequences correspond assessments.210fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS7. Discussion Algorithms Complexitysection discusses computational compexity different steps EstiHMM algorithm, developed previous section. end, find total complexityEstiHMM algorithm polynomial size inputquadratic length iHMMcubic number states, well linear size outputthe number maximal sequences opt (X1:n |o1:n ). linearity size output especially interesting;discuss Section 7.4.7.1 Preparatory Calculationsbegin preparatory calculations quantities Equations (27)(32). thresholds k (xk , xk |zk1 ) Equation (27), computational complexity clearly cubic numberstates, andexcept stationary iHMMslinear length iHMM. Calculatingkmax (xk ) kmax (xk ) Equations (29) (30) linear length iHMMeven staopttionary iHMMsand quadratic number states. complexity finding k (xk |xk1 )Equation (32) thereforein worst, non-stationary caselinear lenght iHMMcubic number states.7.2 Algorithm 2computational complexity Algorithm 2 less trivial. Let us start noting construction essentially consists repeating small step again, namely executingProcedure Recur. explained previous section, data structurea collectiontreesenables us efficiently. three if-conditions Procedure Recurchecked constant time. Therefore, taking account for-loop Line 4, findcomputational complexity single execution Procedure Recur linear numberstates.Next, notice every optimal sequence xk:n obtained running Algorithm 2 constructed adding extra states xs+1 already constructed sequence xk:s , repeating goingk n 1. Adding state means executing Procedure Recur once, thereforelinear number states. Similarly, creating first state xk linear numberstates welldue for-loop Line 8 Algorithm 2. Hence, constructing single optimalsequence xk:n linear length sequence, well linear number states.Theorem 5, also know every execution Procedure Recur guaranteed partconstruction least one optimal sequence. Therefore, find constructing singleset opt (Xk:n |xk1 , ok:n )executing Algorithm 2is linear number optimal sequencesconsists of, linear length sequences linear number states.7.3 Algorithm 1Algorithm 1 basically obtain set opt (X1:n |o1:n ) construct setsopt (Xk:n |xk1 , ok:n ), every xk1 Xk1 , letting k run n 1. k = n fixedxn1 Xn1 , linear number statessee Lines 3 4 Algorithm 1. k < nfixed xk1 Xk1 , comes executing Algorithm 2. shown previoussection, Algorithm 2 linear number optimal sequences opt (Xk:n |xk1 , ok:n ), linearlength sequences (n k + 1) linear number states. Hence, conclude211fiD E B OCK & E C OOMANcomplexity Algorithm 1 quadratic length iHMM, quadratic numberstates roughly speaking6 linear number maximal sequences.7.4 Total Complexitycomplete EstiHMM algorithm consists preparatory calculations Section 6.1 single execution Algorithm 1, where, latter, Lines 8 9 replaced efficientversions Algorithm 2. conclude previous sections total computational complexity isat worstquadratic length iHMM, cubic numberstates, roughly speaking linear number maximal sequences.linearity number maximal sequences clearly remaining bottleneckalgorithm, since may exponentially many sequences. However, leadreader conclude EstiHMM algorithm exponential complexity, meaningexponential size inputthe length iHMM number states. crucialrealise complexity linear size outputthe number maximal sequences,turn may exponential input. However, long size output bounded,algorithm guaranteed computational complexity polynomial sizeinput. guarantee given algorithms whose complexity linear sizeinputfor example naive implementation Algorithm 1 replace Lines 8 9efficient counterparts Algorithm 2.Although linearity size output might seem rather bad, fact hope for.Even simply printing outputall maximal sequencesalready computational complexitylinear size well linear length iHMM. Linearity size outputinherent problems necessarily lead single solution, allow set-valuedsolutions well. size output large, algorithm, however cleverly designed,overcome hurdle.order EstiHMM algorithm choke number maximal sequenceslarge, one keep trackfor every set opt (Xk:n |xk1 , ok:n )of many times Line 2Procedure Recur executed far, aborting algorithm whenever preset tresholdexceeded. however possible return k best solutions, simplything better worse maximal sequence; incomparable.way number maximal sequences reduced decreasing imprecisionmodel: gather extra data expert knowledge, leading smaller local credal sets, pointwiselarger local lower previsions therefore fewer maximal sequences. Alternatively, one could alsoconsider using E-admissable sequencesof may multiple well, manymaximal onesor -maximin sequencesof which, instances, one. However,know algorithm calculate E-admissable -maximin sequences efficientmanner, let alone one linear output; see Section 4.3.7.5 Comparison Viterbis Algorithmprecise HMMs, state sequence estimation problem solved efficientlyViterbi algorithm (Rabiner, 1989; Viterbi, 1967), whose complexity linear lengthHMM, quadratic number states. However, algorithm emits single optimal6. every k xk1 Xk1 , constructing set opt (Xk:n |xk1 , ok:n ) linear complexity number optimalsequences stage.212fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSprobablestate sequence, even cases multipleequally probableoptimalsolutions: course simplifies problem. would content givingsingle maximal solution, ensuing version algorithm would complexitysimilar Viterbis.So, allow fair comparison Viterbis algorithm ours, would need alterViterbis algorithm way longer resolves ties arbitrarily, emits allequallyprobableoptimal state sequences. new version remain linear length HMM,quadratic number states, also added complexity. discussedprevious section, even printing optimal sequences linear number thereforepossibly exponential, example possible solutions equally probableimagine preciseHMM local probability mass functions uniform.complexity time-consuming part algorithmAlgorithm 1,difference this: Viterbis approach linear quadratic length HMM.difference come from? imprecise HMMs mutually incomparable solutions,whereas precise HMMs optimal solutions indifferent, equally probable. makessure algorithm precise HMMs requires forward loops, case EstiHMMalgorithm, every time run Algorithm 2. believe added complexity reasonableprice pay robustness working imprecise-probabilistic models offers.8. ExperimentsSince complexity EstiHMM algorithm depends crucially number maximalsequences emits, present section study number detail. takingcloser look depends transition probabilities model, evolveslet imprecision local models grow. shall see number maximalsequences displays interesting behaviour explained, even predictedextent. allow easy visualisation, limit discussion stationary binary iHMMs,state output variables assume two possible values, say 0 1.8.1 Describing Stationary Binary iHMMprecise transition probabilities going one state next completely determinednumbers unit interval: probability p go state 0 state 0, probabilityq go state 1 state 0. pin HMM also need specify marginalprobability first state 0, two emission probabilities: probability remitting output 0 state 0 probability emitting output 0 state 1.binary case, coherent imprecise-probabilistic models found contamination:taking convex mixtures precise models, mixture coefficient 1 , vacuous model,mixture coefficient , leading so-called linear-vacuous model (Walley, 1991), often referred-contaminated model well. simplify analysis, let emission model remainprecise, use mixture coefficient marginal transition models.ranges zero one, evolve precise HMM towards iHMM vacuousmarginal transition models (and precise emission models).213fiD E B OCK & E C OOMAN8.2 iHMM Length Twoexamine behaviour iHMM length two, following precise probabilitiesfixed:= 0.1, r = 0.8 = 0.3.Fixing output sequence value , use algorithm calculate correspondingnumbers maximal state sequences p q range unit interval. resultsrepresented conveniently form heat plot. plots Figure 8 correspond outputsequence o1:2 = 01.11qq= 2%00p= 5%110011qq= 10%0p0p= 15%100p1Figure 8: Heat plots o1:2 = 01number maximal state sequences clearly depends transition probabilities pq. rather large parts probability space coloured white, get single maximalsequenceas would HMMs, continuous regions see higher number appear. present examplea binary chain length two, highest possible numbermaximal sequences course four. dark grey area, three maximal sequences,two light grey regions. plots show happens let increase: greyareas expand number maximal sequences increases. = 15%, even find smallareacoloured blackwhere four possible state sequences maximal: locally, due relatively high imprecision local models, cannot provide useful robust estimatestate sequence producing output sequence o1:2 = 01.214fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSsmall , areas one maximal state sequence quite small seemresemble strips narrow lines tends zero. suggests ableexplain least qualitatively areas come looking compatible precise models:regions iHMM produces different maximal (mutually incomparable) sequences,widened versions loci indifference precise HMMs.locus indifference, mean set (p, q) correspond two given state sequencesx1:2 x1:2 equal posterior probability:p(x1:2 |o1:2 ) = p(x1:2 |o1:2 ),or, provided p(o1:2 ) > 0,p(x1:2 , o1:2 ) = p(x1:2 , o1:2 ).example, o1:2 = 01, find following expressions four possiblestate sequences:p(00, 01) = mr(1 r)p;p(10, 01) = (1 m)s(1 r)q;p(01, 01) = mr(1 s)(1 p);p(11, 01) = (1 m)s(1 s)(1 q).100 110110011110 111000 0101q11000010p1Figure 9: Loci indifference o1:2 = 01equating two expressions, express corresponding two state sequencesequal posterior probability. Since resulting equations function p q only,six possible combinations defines locus indifference. depicted linesFigure 9.215fiD E B OCK & E C OOMAN111000001101000010001000011111111110111101000010110110110000 . . .111000001101000010001000011111111110111101000010110110110000110000001101000010001000011111111110111101000010110110110000111000000101000010001000011111111110111101000010110110110000111000001100000010001000011111111110111101000010110110110000111000001101000000001000011111111110111101000010110110110000...............Figure 10: Maximal sequences iHMM length 100Parts loci, depicted bluedarker bolder monochrome versions paper,demarcate three regions state sequences 01, 10 11 optimalhave highestposterior probability.happens transition models become imprecise? Roughly speaking, nearby valuesoriginal p q enter picture, effectively turning locilinesof indifferencebands incomparability: emergence regions two maximal sequencesseen originate loci indifference; compare Figure 9 Figure 8.8.3 iHMM Length 100order demonstrate algorithm indeed efficient, let determine maximalsequences random output sequence length 100.consider stationary binary HMM before, following precise marginalemission probabilities:= 0.1, r = 0.98, = 0.01.practical applications, probability output variable value corresponding hidden state variable usually quite high, explains chosen rclose 1 0, respectively. contrast previous experiments, lettransition probabilities vary, fix following values:p = 0.6 q = 0.5.local models iHMM use determine maximal sequences generated -contaminating precise local models. use mixture coefficientmarginal, transition emission models. Figure 10, show five maximal sequencescorrespond highlighted output sequence, = 2%. Due space constraints,display first 60 digits sequences. Since emission probabilities chosenquite accurate, surprise output sequence one maximal sequences.addition, indicated bold face state values differ outputs outputsequence; 40 digits displayed, differences occured. see modelrepresents indecision values state variables move awayend sequence. result phenomenon called dilation, whichas notedanother paper (De Cooman et al., 2010)tends occur inferences credal tree proceedleaves towards root.efficiency algorithm: took 0.2 seconds calculate 5 maximalsequences.7 reason could done fast algorithm less linear7. Running Python program 2012 MacBook Pro.216fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSnumber solutions (see Section 7), case 5. let growexample 5%, number maximal sequences output sequence 764determined 32 seconds. demonstrates complexity indeedless proportional toand therefore linear inthe number solutions algorithmefficiently calculate set maximal sequences, even long output sequences. larger values, say 10%, took 30 minutes determine maximal sequences, leading us abortalgorithm. lead reader conclude large , EstiHMM algorithmlonger linear number maximal sequences. No, simply means thatat least longiHMMsthis number maximal sequences increase quickly soon passes criticalboundary.9. Application Optical Character Recognitionfirst application, use EstiHMM algorithm detect correct mistakes words.hidden sequence x1:n corresponds original, correct version word, outputsequence o1:n artificially corrupted version. way, simulate observational processesperfectly reliable, output Optical Character Recognition (OCR) device.leads observed output sequences may contain errors, try detectcorrect. original words taken Dantes Divina Commedia, 1018 wordssecond canto used training set initial 200 words first canto testset. comparing results EstiHMM algorithm Viterbi algorithm,able illustrate advantages former.9.1 Learning Local Modelsorder apply algorithm, must identify local uncertainty model originalobserved letter: marginal model Q1 first letter X1 original word, transition modelQk (|Xk1 ) subsequent letters Xk , k {2, . . . , n}, emission model Sk (|Xk )observed letters Ok , k {1, . . . , n}. use state space X = variables,consisting 21 letters Italian alphabet. sake simplicity, assume stationarity,making transition emission models independent k.identification local models iHMM, use imprecise Dirichlet model(IDM) (Walley, 1996). corresponds considering set Dirichlet priors fixedstrength > 0, using lower upper bounds inferences obtained priorsmodel. example, marginal model Q1 , applying IDM leads followinglower upper probabilities:Q1 ({x}) =nx+ nxQ1 ({x}) =x X,+ zX nz+ zX nzwhere, z X, nz number words training text first letter X1equal z. hyperparameter regarded degree caution taken accountinferences. use = 2; Walley (1996, Section 2.5) provides number argumentsfavour choice. transition emission models, proceed similarly, countingtransitions one letter another, respectively original word observationprocess. way, obtain lower upper transition emission probabilities singletons,which, pointed Section 6.3, suffice run algorithm. fact, since IDM leads217fiD E B OCK & E C OOMANlocal models linear-vacuous hence completely therefore also 2-monotone,approach described Section 6.3 actually leads exact values parameters k (xk , xk |xk1 )instead conservative approximation.identification local models precise HMM, use similar preciseDirichlet model approach, Perkss prior prior strength = 2. example,precise marginal model Q1 , leads following simple identification:Q1 ({x}) =s/|X | + nx+ zX nz,|X | number states.difference precise imprecise models constructed way described relatively small. example, using training set 1018 words, 67start letter A, obtained following (lower, upper precise) probability firstletter word A:Q1 ({A}) = 0.06569, Q1 ({A}) = 0.06578 Q1 ({A}) = 0.06765.Nevertheless, illustrated next section, imprecise model lead results ratherdiferent obtained precise model.9.2 ResultsLet us first discuss example difference results obtained ViterbiEstiHMM algorithm, order illustrate important advantage latter. OCR softwaremistakenly read Italian word QUANTO OUANTO. Using precise model, Viterbi algorithm correct mistake, suggests original correct word DUANTO.EstiHMM algorithm hand, using imprecise model, returns CUANTO, DUANTO,FUANTO QUANTO maximal, undominated solutions, including correct one. coursewould still pick correct solution set suggestionsfor example using dictionary human opinion, using EstiHMM algorithm, managedreduce search space possible five letter words much smaller set four wordsgiven above. Notice solution Viterbi algorithm included maximal solutionsEstiHMM returns. One easily prove always case.applied method first 200 words first canto Dantes Divina Commedia,137 correctly read artifical OCR device 63 contained errors.tried correct errors using EstiHMM Viterbi algorithm, compareapproaches. results summarised Table 1.Viterbi algorithm, main conclusion applying output OCR deviceresults decreased number incorrect words. number correct words rises 68.5%78.5%. However, Viterbi algorithm also introduces new errors 5 correctly read words.EstiHMM algorithm manages suggest original correct word one solutions86% cases. Assuming able detect correct word, percentage correctwords rises 68.5% 86% applying EstiHMM algorithm, thereby outperformingViterbi algorithm almost 10%. Secondly, also notice EstiHMM algorithm neverintroduced new errors words already correct.218fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELStotal numberViterbicorrect solutionwrong solutionEstiHMMcorrect solution includedcorrect solution includedtotal number200 (100%)correct OCR137 (68.5%)wrong OCR63 (31.5%)157 (78.5%)43 (21.5%)13252538172 (86%)28 (14%)13703528Table 1: Summary results EstiHMM Viterbi algorithmcourse, since EstiHMM algorithm allows multiple solutions, instead single one,surprise manage increase amount times suggest correct solution.would happen even added random extra solutions solution Viterbi algorithm.Giving extra solutions seen improvement done smartly. investigatethis, distinguish cases EstiHMM algorithm returns single solution,returns multiple solutions; look Viterbi EstiHMM algorithmscompare two cases.EstiHMM algorithm returned single solution 155 200 words.already mentioned above, single solution always coincide one given Viterbialgorithm. results EstiHMM Viterbi algorithms summarised Table 2.EstiHMM (single solutions)total numbersingle correct solutionsingle wrong solutiontotal number155 (100%)134 (86.5%)21 (13.5%)correct OCR129 (83.2%)1290wrong OCR26 (16.8%)521Table 2: instances EstiHMM produces single estimatepercentage words correctly read OCR software 83.2% instead global68.5%. result EstiHMM algorithm single solution, serves indicationword trying correct fairly high probability already correct. alsosee eventual percentage correct words 86.5%, slight improvement83.2% already correct applying algorithms.Next, look remaining 45 words, EstiHMM algorithm returnsone maximal element. case, see significant difference resultsViterbi EstiHMM algorithm Viterbi algorithm always returns singlesolution. results algorithms listed Table 3.first important conclusion drawn table EstiHMM algorithm indecisive, serves rather strong indication word applyingalgorithm indeed contain errors: EstiHMM algorithm returns multiple solutions,original word incorrectly read OCR software 82.2% cases.219fiD E B OCK & E C OOMANtotal numberEstiHMM (multiple solutions)correct solution includedcorrect solution includedViterbicorrect solutionwrong solutiontotal number45 (100%)correct OCR8 (17.8%)wrong OCR37 (82.2%)38 (84.4%)7 (15.6%)8030723 (51.1%)22 (48.9%)352017Table 3: instances EstiHMM produces set-valued estimatesecond conclusion, related first, EstiHMM algorithm indecisive,also serves indication result returned Viterbi algorithm less reliable:percentage correct words applying Viterbi algorithm dropped 51.1%, contrastglobal percentage 78.5%. EstiHMM algorithm, however, still gives correctword one solutions 84.4% cases, almost high global percentage86%. set given EstiHMM algorithm contains correct solution, Viterbi algorithmmanages pick correct solution set 60.5% cases. see EstiHMMalgorithm seems notice dealing difficult words therefore gives usmultiple solutions, cannot decide.9.3 Advantages Imprecise Approachlearn experiments EstiHMM algorithm usefully applied makeresults Viterbi algorithm robust, gain appreciation likely gowrong. EstiHMM algorithm indeterminate, serves indication robustness issueswould occur solved problem Viterbi algorithm. instances,EstiHMM algorithm returns multiple solutions, cannot decide, whereasViterbi algorithm pick one set fairly arbitrary waydepending choiceprior, thereby increasing amount errors made.leads us conclude imprecise approach EstiHMM algorithm two mainadvantages. first advantage easily detect precise approach becomessensitive adopted prior: kind sensitivity occurs exactly instancesEstiHMM algorithm returns indeterminate result. second advantage that, instead simplydetecting sensitivity choice prior, EstiHMM algorithm also offers alternativesolution suffer issues, form set maximal sequencesa setsuggestions correct hidden word. illustrated experiments, set oftencontain actual correct word.Future work could try exploit set-valued solutions trying pick correct wordgiven set options non-arbitrary way. could example donecomparing options entries dictionary. Alternatively, one could consider askinguser feedback, asking choose among options. way, additional data gatheredused build better model less sensitive choice prior.220fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELS10. ConclusionsInterpreting graphical structure imprecise hidden Markov model credal networkepistemic irrelevance leads efficient algorithm finding maximal, undominated hiddenstate sequences given observed sequence. interesting feature algorithmcomputational complexity linear size outputthe number maximal statesequences. Preliminary simulations show that, even long iHMMs transition modelsnon-negligible imprecision, number maximal state sequences often reasonably low.remains seen whether observation corroborated deeper theoretical analysis.application OCR clearly shows EstiHMM algorithm able robustifyresults Viterbi algorithm. reduce amount wrong conclusionsproviding extra possible solutions, intelligent manner. adds extra solutionsspecific cases Viterbi algorithm likely wrong, thereby also serving indicatorreliability result given Viterbi algorithm. Since set-valued solutions oftencontain correct hidden state sequence, usefully applied postprocessing phase,example offering set user, asking feedback.first important avenue future research would compare EstiHMM algorithmmethods also try robustify Viterbi algorithm producing set-valued solutions.distinguish two different approaches.one hand, imprecise methods one adopted us. combineimprecise model imprecise-probabilistic decision criterion. paper, chosenuse maximality decision criterion. However, decision criteria adopted well; seeSection 4.3. criteria, E-admissibility, also lead set-valued estimates.common feature methods take account model uncertainty:happens inferences model imperfect? happens instead single probability mass function, set possible candidates? many instances, resulting inferencesstill determinate. Set-valued solutions typically obtained instancesprecise-probabilistic approach likely wrong.hand, precise models may lead set-valued solutions well. contextHMMs, important example seems k-best Viterbi algorithm (Brown & Golod,2010). Instead returning posteriori probable hidden state sequence, k-bestViterbi algorithm returns k probable hidden state sequences. two importantdifferences imprecise approaches described above. First all, k-best approachnothing model uncertainty. Instead, deals probabilistic uncertaintyinherent model itself, assuming model perfectly known. modelindeed correct, returning k probable sequences, probability correctestimate included set-valued solution increases, expense losing determinacy.Secondly, related previous difference, k-best method always return k sequences,regardless accuracy 1-best approach. contrast, imprecise approaches typicallyable distinguish easy hard cases, producing determinate answers formerset-valued answers latter. Nevertheless, despite differences, one gets impressionk-best method used tackle similar applications EstiHMM algorithm. wouldinteresting check whether indeed case, compare respective results.leave topic future research.221fiD E B OCK & E C OOMANAnother, theoretical avenue future research investigate extentideas presented paper applied credal networks iHMMs epistemicirrelevance. two specific instances concrete ideas proceed. Firstall, strong reasons believe possible derive similarly efficient algorithmiHMMs whose graphical structure interpreted credal network strong independencerather epistemic irrelevance. could interesting relevant, stringentindependence condition leads joint models less imprecise, therefore produce fewermaximal state sequencesalthough included solutions. Secondly, EstiHMMalgorithm demonstrates efficient inference credal trees epistemic irrelevancenecessarily limited queries single target node only. fact, believe possibledevelop polyonomial time algorithms, capable solving wide classes inference problemscredal trees epistemic irrelevance, thereby extending results De Cooman et al. (2010).AcknowledgmentsJasper De Bock Ph.D. Fellow Research Foundation - Flanders (FWO) Ghent University, developed algorithm described context Masters thesis,close cooperation Gert de Cooman, acted thesis supervisor. present articledescribes main results Masters thesis. Research De Cooman supportedSBO project 060043 IWT-Vlaanderen.authors would like thank anonimous referees paper previous conference version useful, constructive comments. led significant improvementcurrent version, notably regarding presentation. paper also benefitted discussions Marco Zaffalon, Alessandro Antonucci, Alessio Benavoli, Cassio de Campos, ErikQuaeghebeur Filip Hermans. grateful Marco Zaffalon providing travel funds,allowed us visit IDSIA discuss practical applications.Appendix A. Proofs Main Resultsappendix, justify formulas (6), (7), (15), (16), (17), (33) (34) give proofsProposition 1 Theorems 25. frequently use terms positive, negative,decreasing increasing. therefore start clarifying mean them. x R,say x positive x > 0, negative x < 0, non-negative x 0 non-positive x 0.call real-valued function f defined R:(i) increasing (x, R)(x > f (x) > f (y));(ii) decreasing (x, R)(x > f (x) < f (y));(iii) non-decreasing (x, R)(x > f (x) f (y));(iv) non-increasing (x, R)(x > f (x) f (y)).222fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSProof Equation (6). k {1, . . . , n}, xk1 Xk1 , xk:n Xk:n ok:n Ok:n inferEquation (5)Pk (I{xk:n } I{ok:n } |xk1 ) = Qk (E k (I{xk:n } I{ok:n } |Xk )|xk1 )fifi= Qk I{zk } E k (I{xk } (zk )I{xk+1:n } I{ok:n } |zk )fixk1zk Xk= Qk (I{xk } E k (I{xk+1:n } I{ok:n } |xk )|xk1 ).Since E k (I{xk+1:n } I{ok:n } |xk ) 0 C1, see C2 transforms= Qk (I{xk } |xk1 )E k (I{xk+1:n } I{ok:n } |xk ),reformulated= Qk (I{xk } |xk1 )Sk (I{ok } |xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk )= Qk ({xk }|xk1 )Sk ({ok }|xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk ),take account Equation (4), since Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) 0 C1.Repeating steps eventually yields Equation (6):nPk (I{xk:n } I{ok:n } |xk1 ) = Qi ({xi }|xi1 )Si ({oi }|xi ).i=klast step, k = n, used equality E n ({on }|xn ) = Sn ({on }|xn ), followsEquation (3).Proof Equation (7). k {1, . . . , n}, xk1 Xk1 , xk:n Xk:n ok:n Ok:n inferconjugacy Equation (5)Pk (I{xk:n } I{ok:n } |xk1 ) = Pk (I{xk:n } I{ok:n } |xk1 )= Qk (E k (I{xk:n } I{ok:n } |Xk )|xk1 )fifi= Qk I{zk } E k (I{xk } (zk )I{xk+1:n } I{ok:n } |zk )fixk1zk Xk= Qk (I{xk } E k (I{xk+1:n } I{ok:n } |xk )|xk1 )= Qk (I{xk } (E k (I{xk+1:n } I{ok:n } |xk )))|xk1 ).Since E k (I{xk+1:n } I{ok:n } |xk ) = E k (I{xk+1:n } I{ok:n } |xk ) 0 conjugacy Lemma 6, seeC2 Equation (2) transform= E k (I{xk+1:n } I{ok:n } |xk ) Qk (I{xk } |xk1 )= Qk (I{xk } |xk1 )E k (I{xk+1:n } I{ok:n } |xk ),reformulated= Qk (I{xk } |xk1 )Sk (I{ok } |xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk )= Qk (I{xk } |xk1 )Sk (I{ok } |xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk )= Qk ({xk }|xk1 )Sk ({ok }|xk )Pk+1 (I{xk+1:n } I{ok+1:n } |xk ),223fiD E B OCK & E C OOMANusing conjugacy Equation (4), since Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) 0. last inequality trueknow Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) = Pk+1 (I{xk+1:n } I{ok+1:n } |xk ) conjugacyPk+1 (I{xk+1:n } I{ok+1:n } |xk ) 0 Lemma 6.Repeating steps again, eventually yields Equation (7):nPk (I{xk:n } I{ok:n } |xk1 ) = Qi ({xi }|xi1 )Si ({oi }|xi ).i=klast step, k = n, used equality E n ({on }|xn ) = Sn ({on }|xn ), followsEquation (3) conjugacy.Lemma 6. Consider coherent lower prevision P G (X). Then, f G (X),min f P( f ) P( f ) max f and, R, P( f ) = P() = .Proof. prove inequalities min f P( f ) P( f ) max f one one. first oneC1. follows C3 P( f f ) P( f ) + P( f ) therefore, since knowC2 P(0) = 0P(0) = 0, implies P( f ) P( f ) = P( f ), using conjugacy lastequality. gamble f , C1 yields min f P( f ) turn implies max f =min f P( f ) = P( f ).conclude, P( f ) = P() = follows applying inequalities f = .Proof Proposition 1. ObservePk (I{ok:n } |xk1 ) = Pk I{ok:n }zk:n Xk:nfifififiI{zk:n } fixk1 Pk I{ok:n } I{zk:n } fixk1 > 0,zk:n element Xk:n . equality follows zk:n Xk:n I{zk:n } = 1, first inequalityLemma 8(ii), second one positivity assumption (10) Equation (7).way, easily provefifififiE k ({ok:n }|xk ) = E k I{ok:n }I{zk+1:n } fixk E k I{ok:n } I{zk+1:n } fixk > 0.zk+1:n Xk+1:ntime, used positivity assumption (10) Equation (9) last inequality.Proof Theorem 2. Consider real-valued function , defined() := P(I{o1:n } [I{x1:n } I{x1:n } ]) R.follows Equation (11) P(I{x1:n } I{x1:n } |o1:n ) rightmost zero, also know(0) = P(I{o1:n } [I{x1:n } I{x1:n } ]). Furthermore, non-increasing continuous Lemma7(i), least one zero Lemma 7(ii). Hence, (0) > 0, least one positivezero P(I{x1:n } I{x1:n } |o1:n ) > 0. (0) < 0, negative zeroes findP(I{x1:n } I{x1:n } |o1:n ) < 0. Hence, proving theorem comes proving (0) = 0implies () < 0 > 0, since turn implies P(I{x1:n } I{x1:n } |o1:n ) = 0.prove implication. consider two different cases.224fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELScase x1 = x1 . real > 0:() = P(I{o1:n } [I{x1:n } I{x1:n } ])= Q1 (E 1 (I{o1:n } [I{x1:n } I{x1:n } ]|X1 ))= Q1 I{x1 } E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) +I{z1 } E 1 (I{o1:n } |z1 ) .(37)z1 6=x1coefficients E 1 (I{o1:n } |z1 ) written E 1 ({o1:n }|z1 ) conjugacy C2,makes negative, decreasing functions , since E 1 ({o1:n }|z1 ) > 0 positivity assumption (10) Proposition 1.coefficient E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ), consider two possible cases.E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) > 0, know E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) decreasing function Lemma 7(vi). Therefore, argument Q1 Equation (37) decreasespointwise , Lemma 8(i) implies () decreasing function therefore() < (0) = 0.If, hand, E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) 0, know Lemma 8(ii)E 1 (I{o1:n } [I{x2:n } I{x2:n } ]|x1 ) 0, implying() Q1I{z1 } E 1 (I{o1:n } |z1 )z1 6=x1Q1 I{z1 } E 1 (I{o1:n } |z1 ) = E 1 ({o1:n }|z1 )Q1 {z1 } < 0.expression, z1 arbitrary z1 6= x1 . first two inequalities due Lemma 8(ii).Conjugacy C2 yield equality last inequality consequence positivity assumption (10) Proposition 1. Also case, therefore, find () < 0.case x1 6= x1 . real > 0:() = P(I{o1:n } [I{x1:n } I{x1:n } ])= Q1 (E 1 (I{o1:n } [I{x1:n } I{x1:n } ]|X1 ))= Q1 I{x1 } E 1 (I{o1:n } [I{x2:n } ]|x1 ) + I{x1 } E 1 (I{o1:n } [I{x2:n } ]|x1 )+I{z1 } E 1 (I{o1:n } |z1 )(38)z1 6=x1 ,x1proof case x1 = x1 , already shown coefficients E 1 (I{o1:n } |z1 )negative, decreasing functions . Together Lemma 8(ii), allows us inferE 1 (I{o1:n } [I{x2:n } ]|x1 ) E 1 (I{o1:n } |x1 ) < 0, turn Lemma 7(vii) impliesE 1 (I{o1:n } [I{x2:n } ]|x1 ) decreasing function . left consider coefficient E 1 (I{o1:n } [I{x2:n } ]|x1 ). two possibilities.E 1 (I{o1:n } I{x2:n } |x1 ) > 0, Lemma 7(vi) implies E 1 (I{o1:n } [I{x2:n } ]|x1 ) decreasingfunction . Therefore, argument Q1 Equation (38) decreases pointwise ,Lemma 8(i) implies () decreasing function therefore () < (0) = 0.225fiD E B OCK & E C OOMANIf, hand, E 1 (I{o1:n } I{x2:n } |x1 ) = 0, Lemma 8(ii), E 1 (I{o1:n } [I{x2:n } ]|x1 ) 0,implying() Q1 (I{x1 } E 1 (I{o1:n } [I{x2:n } ]|x1 ))Q1 (I{x1 } E 1 (I{o1:n } |x1 )) = E 1 ({o1:n }|x1 )Q1 ({x1 }) < 0.first two inequalities follow Lemma 8(ii). Conjugacy C2 yield equality,last inequality consequence positivity assumption (10) Proposition 1. Alsocase, then, find () < 0.Lemma 7. Let P coherent lower prevision G (X). f G (X) , considerreal-valued map defined R () := P(I{y} [ f ]) real . followingstatements hold:(i) non-increasing, concave continuous.(ii) least one zero.(iii) P({y}) > 0, decreasing unique zero.(iv) P({y}) = 0, identically zero.(v) P({y}) = 0 P({y}) > 0, zero (, P( f |y)], negative decreasing(P( f |y), +).(vi) (a) > 0 a, decreasing unique zero.(vii) negative interval (a, b), also decreasing (a, b).Proof. start proving (i). follows directly Lemma 8(ii) non-increasing .consider 1 2 R 0 1. concave( 1 + (1 )2 ) = P(I{y} [ f ( 1 + (1 )2 )])= P( I{y} [ f 1 ] + (1 )I{y} [ f 2 ])P( I{y} [ f 1 ]) + P((1 )I{y} [ f 2 ])= P(I{y} [ f 1 ]) + (1 )P(I{y} [ f 2 ])= (1 ) + (1 )(2 ),inequality follows C3 subsequent step due C2. prove ()continuous, consider 1 2 R, see(2 ) = P(I{y} [ f 2 ]) = P(I{y} [ f 1 + (1 2 )])= P(I{y} [ f 1 ] + I{y} (1 2 )) P(I{y} [ f 1 ]) + P(I{y} (1 2 ))= (1 ) P({y}) fi (2 1 ),inequality follows C3, last equality due conjugacy C2. Hence|(1 ) (2 )| |2 1 |P({y}), proves Lipschitz continuous, therefore alsocontinuous.226fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSprove (ii), first notice (min f ) = P(I{y} [ f min f ]) P(I{y} [min f min f ]) = 0(max f ) = P(I{y} [ f max f ])E P(I{y} [max f max f ]) = 0. inequalities consequenceLemma 8(ii), last equalities follow Lemma 6. Since () continuous, impliesexistence zero min f max f .Property (iii) proved considering 1 2 R 2 > 1 . P({y}) > 0, seedecreasing, since(1 ) = P(I{y} [ f 1 ]) = P(I{y} [ f 2 + (2 1 )])= P(I{y} [ f 2 ] + I{y} (2 1 )) P(I{y} [ f 2 ]) + P(I{y} (2 1 ))= (2 ) + (2 1 )P({y}) > (2 ),first inequality follows C3 last equality C2. know (ii)least one zero, must unique decreasing.prove (iv), first note P({y}) = 0 also implies P({y}) = 0, Lemma 6. fixR choose b R< min{0, min{ f }} max{0, max{ f }} < b.find () = P(I{y} [ f ]) P(I{y} a) = aP({y}) = 0 () = P(I{y} [ f ])P(I{y} b) = bP({y}) = 0, using Lemma 8(ii), C2 conjugacy. conclude () = 0R.proof (v) starts noticing () 0 (, P( f |y)] () < 0(P( f |y), +), due definition P( f |y) (see Equation (11)), fact nonincreasing (i). proof (iv), already shown non-positive P({y}) = 0,allows us conclude () = 0 (, P( f |y)]. left provedecreasing interval (P( f |y), +). contradiction. Supposedecreasing interval, 1 2 interval, 2 > 10 > (2 ) (1 ). Since zero (, P( f |y)), also choose 0 < 1(0 ) = 0. existence 0 , 1 2 contradicts concavity , established (i).prove (vi), observe P({y}) P({y}) 0 Lemma 6. implies three casesconsidered (iii), (iv) (v) exhaustive mutually exclusive.(a) > 0, case considered (iii), implies decreasingunique zero.remains prove (vii). repeating argument proof (vi), seenegative interval (a, b), cases considered (iii) (v) obtain. (iii),decreasing entire domain. (v), definitely decreasing (a, b).Lemma 8. Consider coherent lower prevision P G (X) two gambles f , g G (X).(i) f (x) > g(x) x X, P( f ) > P(g).(ii) f (x) g(x) x X, P( f ) P(g).Proof. start (i). Since f g pointwise positive, min( f g) > 0 thereforeP( f g) min ( f g) > 0, using C1 first inequality. follows C3P( f ) = P(( f g) + g) P( f g) + P(g), therefore P( f ) P(g) P( f g) > 0, whenceindeed P( f ) > P(g). proof (ii) analogous; time, min( f g) 0therefore P( f ) P(g) P( f g) min ( f g) 0.227fiD E B OCK & E C OOMANProof Equation (15). Let [xk:n , xk:n ] := I{ok:n } [I{xk:n } I{xk:n } ]. Since considering casek {1, . . . , n 1} xk = xk , find[xk:n , xk:n ] = I{ok:n } [I{xk:n } I{xk:n } ] = I{ok } I{xk } I{ok+1:n } [I{xk+1:n } I{xk+1:n } ]= I{ok } I{xk } [xk+1:n , xk+1:n ],turn impliesPk ([xk:n , xk:n ]|xk1 ) = Qk (E k (I{ok } I{xk } [xk+1:n , xk+1:n ]|Xk )|xk1 )= Qk (I{xk } E k (I{ok } [xk+1:n , xk+1:n ]|xk )|xk1 )= Qk ({xk }|xk1 ) fi E k (I{ok } [xk+1:n , xk+1:n ]|xk )= Qk ({xk }|xk1 )Sk ({ok }|xk ) fi Pk+1 ([xk+1:n , xk+1:n ]|xk ),proving Equation (15). first equality follows Equation (5). second equality holdsI{xk } (zk ) = 0 zk 6= xk , implyingE k (I{ok } I{xk } [xk+1:n , xk+1:n ]|Xk ) = I{xk } E k (I{ok } [xk+1:n , xk+1:n ]|xk ).third equality follows conjugacy C2, last one follows Equation (4).Proof Equation (16). Since xn = xn , Lemma 6 yields:Pn (I{on } [I{xn } I{xn } |xn1 ) = Pn (I{on } [I{xn } I{xn } |xn1 ) = Pn (0|xn1 ) = 0.Proof Equation (17). k {1, . . . , n} xk 6= xk ,Pk (I{ok:n } [I{xk:n } I{xk:n } |xk1 ) = Qk (E k (I{ok:n } [I{xk:n } I{xk:n } ]|Xk )|xk1 )= Qk (I{xk } E k (I{ok:n } I{xk+1:n } |xk ) + I{xk } E k (I{ok:n } I{xk+1:n } |xk )|xk1 )= Qk (I{xk } E k (I{ok:n } I{xk+1:n } |xk ) I{xk } E k (I{ok:n } I{xk+1:n } |xk )|xk1 )= Qk (I{xk } (xk:n ) I{xk } (xk:n )|xk1 ),proving Equation (17). reasons equalities hold, analogous ones givenproof Equation (15).Proof Theorem 3. Fix k {1, . . . , n 1}, xk1 Xk1 xk:n Xk:n . assumexk+1:n/ opt (Xk+1:n |xk , ok+1:n ) show xk:n/ opt (Xk:n |xk1 , ok:n ). follows assumption Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } |xk ) > 0 xk+1:n Xk+1 . prefix statesequence xk+1:n state xk form state sequence xk:n , implying xk = xk .infer Equation (15)Pk (I{ok:n } [I{xk:n } I{xk:n } |xk1 ) = Qk ({xk }|xk1 )Sk ({ok }|xk )Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } |xk ) > 0,tells us indeed xk:n/ opt (Xk:n |xk1 , ok:n ).228fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSProof Equations (33) (34). First, consider k = n. every xn1 Xn1 , determineopt (Xn |xn1 , ) set elements xn Xn(xn Xn \ {xn })Qn (I{xn } nmax (xn ) I{xn } (xn )|xn1 ) 0,condition equivalent optimality condition (14) k = n, taking account Equations (16), (17) (31). show condition also equivalent(xn Xn \ {xn })(xn ) nmax (xn )n (xn , xn |xn1 ),(39)see this, consider two different cases. xn nmax (xn ) = 0, inequalities Qn (I{xn } nmax (xn ) I{xn } (xn )|xn1 ) 0 (xn ) nmax (xn )n (xn , xn |xn1 ) triviallysatisfied since (xn ) = Sn ({on }|xn ) > 0 positivity assumption (10). nmax (xn ) > 0,inequalities equivalent C2 Equation (27):(xn ) fifimaxQn (I{xn } n (xn ) I{xn } (xn )|xn1 ) 0 Qn I{xn } I{xn } maxfixn1 0n (xn )(xn )n (xn , xn |xn1 )maxn (xn )(xn ) nmax (xn )n (xn , xn |xn1 ).optUsing Equation (32), Equation (39) reformulated (xn ) n (xn |xn1 ), completes proof equivalence.Next, consider k {1, . . . , n1} xk1 Xk1 . must determine opt (Xk:n |xk1 , ok:n ).know Principle Optimality (23) limit candidate optimal sequencesxk:n set cand (Xk:n |xk1 , ok:n ). Consider xk:n , must check xk:n Xk:nwhether Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) 0; see Equation (14).xk:n xk = xk , inequality always satisfied. Indeed, xk/ Posk (xk1 ),infer Equation (25) Qk ({xk }|xk1 ) = 0 Sk ({ok }|xk ) = 0, Equation (15) tellsus Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) = 0. xk Posk (xk1 ), know Equation (24)xk+1:n opt (Xk+1:n |xk , ok+1:n ), turn implies Pk+1 (I{ok+1:n } [I{xk+1:n } I{xk+1:n } ]|xk ) 0.Hence Pk (I{ok:n } [I{xk:n } I{xk:n } ]|xk1 ) 0, Equation (15).means limit checking inequality xk:n xk 6= xk .fix xk 6= xk , must check whether(xk+1:n Xk+1:n )Qk (I{xk } (xk:n ) I{xk } (xk:n )|xk1 ) 0;see Equation (17). Equation (28) Lemma 8, equivalentQk (I{xk } kmax (xk ) I{xk } (xk:n )|xk1 ) 0,turn seen equivalent (xk:n ) kmax (xk )k (xk , xk |xk1 ), using coursereasoning completely analogous one used case k = n. Since inequality mustopthold every xk 6= xk , infer Equation (32) must (xk:n ) k (xk |xk1 ).must check condition candidate sequences xk:n cand (Xk:n |xk1 , ok:n ),proves Equation (33).229fiD E B OCK & E C OOMANProof Theorem 4. start proving every sequence xk:n added Line 2Procedure Recur(xk:n , n) indeed element opt (Xk:n |xk1 , ok:n ). Line 2 Procedure Recur(xk:n , n) executed, means Procedure Recur(xk:n1 , n 1) executedprevious step, point, if-conditions Lines 5 6 satisfied. Duefirst if-condition, know xk:n candxk:n (Xk:n |xk1 , ok:n ) therefore, Equation (35),also xk:n cand (Xk:n |xk1 , ok:n ). second if-condition, infer nmax (xn )optoptk (xk:n |xk1 ), seen equivalent (xk:n ) k (xk |xk1 ), Equation (31)repeated use Equations (36) (20). follows Equation (33) xk:nelement opt (Xk:n |xk1 , ok:n ).conclude proof, show sequence xk:n added coursealgorithm cannot element opt (Xk:n |xk1 , ok:n ). sequence xk:n added,either implies element cand (Xk:n |xk1 , ok:n ) [the if-condition Line 5Procedure Recur satisfied], {k, . . . , n} imax (xi ) <optk (xk:i |xk1 ) [the if-condition Line 9 Algorithm 2 Line 5 Procedure Recursatisfied]. first case, follows directly Equation (33) xk:n cannot elementoptopt (Xk:n |xk1 , ok:n ). second case, find imax (xi ) < k (xk:i |xk1 ) impliesoptopt(xk:n ) < k (xk |xk1 ), seen equivalent (xk:n ) < k (xk |xk1 )repeated use Equations (36) (20). follows Equation (33) xk:n cannotelement opt (Xk:n |xk1 , ok:n ).Proof Theorem 5. Equation (28) implies least one sequence xs+1:nXs+1:nmax(xs xs+1:n ) = (xs ). prove first state xs+1 sequence meetscriteria theorem.optknow candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ smax (xs ) k (xk:s |xk1 ) conditions necessary order Procedure Recur(xk:s , s) executed running Algorithm 2. = k, condition candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ explicitely checked Algorithm 2, nevertheless also true Equations (24) (35) knowopt (Xk+1:n |xk , ok+1:n ) 6= 0/ [because every finite partially ordered set least one maximalelement].optSince (xs xs+1:n) = smax (xs ) k (xk:s |xk1 ), know Equations (20) (36)opt|xmax(xs+1:n) k (xk:s xs+1k1 ). combining Equation (28), find s+1 (xs+1 )optk (xk:s xs+1 |xk1 ), meaning xs+1 satisfies if-condition Line 6.Due Lemma 9, infer candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ (xs xs+1:n) = smax (xs )candxk:s xs+1(Xk:n |xk1 , ok:n ) 6= 0,/ meaning xs+1 satisfies if-condition Line 5 well.Lemma 9. Consider k {1, . . . , n 1}, {k, . . . , n 1}, xk1 Xk1 , xk:s Xk:s xs+1:nmaxXs+1:n . candxk:s (Xk:n |xk1 , ok:n ) 6= 0/ (xs xs+1:n ) = (xs ), alsocandxk:s xs+1(Xk:n |xk1 , ok:n ) 6= 0./Proof. Let zs+1:n sequence Xs+1:n xk:s zs+1:n cand (Xk:n |xk1 , ok:n );possible because, assumption, candxk:s (Xk:n |xk1 , ok:n ) 6= 0./q {k, . . . , 1} xq/ Posq (xq1 ), denote smallest qq . case, Equation (24), find xq :s xs+1:nxq :s zs+1:n elementscand (Xq :n |xq 1 , oq :n ). q exists, let q := s. case, since xq Posq (xq1 )230fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSq {k, . . . , 1}, follows xk:s zs+1:n cand (Xk:n |xk1 , ok:n ) repeated use Equations (24) (23) xs zs+1:n belongs cand (Xs:n |xs1 , os:n ). Since (xs xs+1:n) = smax (xs ),infer Lemma 10 xs+1:nopt (Xs+1:n |xs , os+1:n ) therefore, Equation (24),xs xs+1:n cand (Xs:n |xs1 , os:n ).case, q {k, . . . , s} xq :s xs+1:nxq :s zs+1:n belongcand (Xq :n |xq 1 , oq :n ) which, q {k, . . . , q 1}, xq Posq (xq1 ). q = k,concludes proof. Therefore, consider case q {k + 1, . . . , s}.first recall cand (Xk:n |xk1 , ok:n ) constructed applying Equations (33) (24)repeatedly. Therefore, since know xq :s zs+1:n cand (Xq :n |xq 1 , oq :n ) xk:s zs+1:ncand (Xk:n |xk1 , ok:n ), must(xq:s zs+1:n ) qopt (xq |xq1 ) q {k + 1, . . . , q }.(40)Furthermore, since (xs xs+1:n) = smax (xs ), infer Equation (28) (xs xs+1:n)(xs zs+1:n ) therefore, Equation (20), find hat(xq:s xs+1:n) (xq:s zs+1:n ) q {k + 1, . . . , s}.Hence, Equation (40):(xq:s xs+1:n) qopt (xq |xq1 ) q {k + 1, . . . , q }.(41)Since cand (Xk:n |xk1 , ok:n ) constructed repeatedly applying Equations (33) (24)xq :s xs+1:ncand (Xq :n |xq 1 , oq :n ), infer Equation (41) xk:s xs+1:ncand (Xk:n |xk1 , ok:n ).Lemma 10. Consider {1, . . . , n 1}, xs Xs xs+1:nXs+1:n .(xs xs+1:n) = smax (xs ) = xs+1:nopt (Xs+1:n |xs , os+1:n ) .Proof. Assume (xs xs+1:n) = smax (xs ) consider zs+1:n Xs+1:n . knowEquation (28) (xs xs+1:n) (xs zs+1:n ) therefore, Equation (19) (7),Ss ({os }|xs )Ps+1 (I{xs+1:n} I{os+1:n } |xs ) Ss ({os }|xs )Ps+1 (I{zs+1:n } I{os+1:n } |xs ).Together positivity assumption (10), impliesPs+1 (I{xs+1:n} I{os+1:n } |xs ) Ps+1 (I{zs+1:n } I{os+1:n } |xs ).(42)C3, also knowPs+1 (I{xs+1:n} I{os+1:n } |xs ) Ps+1 (I{os+1:n } (I{zs+1:n } I{xs+1:n} )|xs ) + Ps+1 (I{zs+1:n } I{os+1:n } |xs )which, conjugacy, impliesPs+1 (I{os+1:n } (I{zs+1:n } I{xs+1:n} )|xs ) Ps+1 (I{zs+1:n } I{os+1:n } |xs ) Ps+1 (I{xs+1:n} I{os+1:n } |xs ).Using Equation (42), see Ps+1 (I{os+1:n } (I{zs+1:n } I{xs+1:n} )|xs ) 0. Since holdszs+1:n Xs+1:n , infer Equation (14) xs+1:nopt (Xs+1:n |xs , os+1:n ).231fiD E B OCK & E C OOMANReferencesBellman, R. (1957). Dynamic Programming. Princeton University Press, Princeton.Benavoli, A., Zaffalon, M., & Miranda, E. (2011). Robust filtering coherent lower previsions. Automatic Control, IEEE Transactions on, 56(7), 15671581.Brown, D. G., & Golod, D. (2010). Decoding HMMs using k best paths: algorithms applications.. BMC Bioinformatics, 11(S-1), 28.Cozman, F. G. (2000). Credal networks. Artificial Intelligence, 120, 199233.Cozman, F. G. (2005). Graphical models imprecise probabilities. International JournalApproximate Reasoning, 39(2-3), 167184.de Campos, L. M., Huete, J. F., & Moral, S. (1994). Probability intervals: tool uncertainreasoning. International Journal Uncertainty, Fuzziness Knowledge-Based Systems,2, 167196.De Cooman, G., Miranda, E., & Zaffalon, M. (2011). Independent natural extension. ArtificialIntelligence, 175, 19111950.De Cooman, G., Hermans, F., Antonucci, A., & Zaffalon, M. (2010). Epistemic irrelevance credalnets: case imprecise Markov trees. International Journal Approximate Reasoning,51, 10291052.De Cooman, G., & Troffaes, M. C. M. (2005). Dynamic programming deterministic discretetime systems uncertain gain. International Journal Approximate Reasoning, 39, 257278.De Cooman, G., Troffaes, M. C. M., & Miranda, E. (2008). n-Monotone exact functionals. JournalMathematical Analysis Applications, 347, 143156.Dempster, A. P. (1967). Upper lower probabilities induced multivalued mapping. AnnalsMathematical Statistics, 38, 325339.Huntley, N., & Troffaes, M. C. M. (2010). Normal form backward induction decision treescoherent lower previsions. Annals Operations Research. Submitted publication.Kikuti, D., Cozman, F., & de Campos, C. (2005). Partially ordered preferences decision trees:computing strategies imprecision probabilities. IJCAI Workshop AdvancesPreference Handling, pp. 13131318.Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques Adaptive Computation Machine Learning. MIT Press.Mau, D., de Campos, C., Benavoli, A., & Antonucci, A. (2013). complexity strongepistemic credal networks. Proceedings 29th Conference Uncertainty ArtificialIntelligence, pp. 391400. AUAI Press.Miranda, E. (2008). survey theory coherent lower previsions. International JournalApproximate Reasoning, 48(2), 628658.Miranda, E. (2009). Updating coherent lower previsions finite spaces. Fuzzy Sets Systems,160(9), 12861307.232fiE STIMATING TATE EQUENCES MPRECISE H IDDEN ARKOV ODELSMiranda, E., & de Cooman, G. (2007). Marginal extension theory coherent lower previsions. International Journal Approximate Reasoning, 46(1), 188225.Pearl, J. (1988). Probabilistic Reasoning Intelligent Systems: Networks Plausible Inference.Morgan Kaufmann, San Mateo, CA.Rabiner, L. R. (1989). tutorial hidden Markov models selected applications speechrecognition. Proceedings IEEE, 77(2), 257286.Shafer, G. (1976). Mathematical Theory Evidence. Princeton University Press, Princeton, NJ.Troffaes, M. C. M. (2007). Decision making uncertainty using imprecise probabilities. International Journal Approximate Reasoning, 45(1), 1729.Utkin, L. V., & Augustin, T. (2005). Powerful algorithms decision making partial prior information general ambiguity attitudes. in: Proceedings 3th International Symposium Imprecise Probability: Theories Applications (ISIPTA), Prague,Czech Republic,pp. 349358.Viterbi, A. J. (1967). Error bounds convolutional codes asymptotically optimum decodingalgorithm. IEEE Transactions Information Theory, 13(2), 260269.Walley, P. (1991). Statistical Reasoning Imprecise Probabilities. Chapman Hall, London.Walley, P. (1996). Inferences multinomial data: learning bag marbles. JournalRoyal Statistical Society, Series B, 58, 357. discussion.Weichselberger, K. (2000). theory interval probability unifying concept uncertainty.International Journal Approximate Reasoning, 24(23), 149170.233fiJournal Artificial Intelligence Research 50 (2014) 447-485Submitted 2/14; published 6/14Monotone Temporal Planning:Tractability, Extensions ApplicationsMartin C. CooperFrdric MarisPierre RgnierCOOPER@IRIT.FRMARIS@IRIT.FRREGNIER@IRIT.FRIRIT, Paul Sabatier University118 Route de Narbonne31062 Toulouse, FranceAbstractpaper describes polynomially-solvable class temporal planning problems. Polynomiality follows two assumptions. Firstly, supposing sub-goal fluent establishedone action, quickly determine actions necessary plan. Secondly,monotonicity sub-goal fluents allows us express planning instance STP (SimpleTemporal Problem difference constraints). class includes temporally-expressive problemsrequiring concurrent execution actions, potential applications chemical, pharmaceutical construction industries.also show (temporal) planning problem monotone relaxation leadpolynomial-time detection unsolvability certain cases. Indeed show relaxation orthogonal relaxations based ignore-deletes approach used classical planningsince preserves deletes also exploit temporal information.1. IntroductionPlanning field AI intractable general case (Erol, Nau & Subrahmanian,1995). particular, propositional planning PSPACE-Complete (Bylander, 1994). Identifying tractable classes planning important least two reasons. Firstly, real-world applications may fallclasses. Secondly, relaxing arbitrary instance falls tractable classprovide useful information concerning polynomial time.Temporal planning important extension classical planning actions durativemay overlap. important aspect temporal planning that, unlike classical planning, permits us model problems execution two actions parallel essential order solve problem (Cushing, Kambhampati, Mausam & Weld, 2007). Although planningstudied since beginnings research Artificial Intelligence, temporal planning relatively new field research. tractable classes specifically defined temporal frameworkresearch described paper. present class temporal planning problemssolved polynomial time. particular, considerably extend theoretical results givenconference papers (Cooper, Maris & Rgnier, 2012, 2013b) considering plans optimalmakespan, relaxing assumption two instances action overlapintroducing notion unitary actions. also give previously unpublished results experimentaltrials benchmark problems. first, review previous work identification tractableclasses classical planning problems.2014 AI Access Foundation. rights reserved.fiCOOPER, MARIS, & REGNIERlot work done computational complexity non-optimal optimal planningclassical benchmark domains. non-optimal case, Helmert (2003, 2006) provedbenchmarks solved simple procedures running low-order polynomial time.optimal case, finding optimal plan famous blocksworld domain NP-hard (Gupta & Nau,1992) Slaney Thibaux (2001) proved domain tractable searching nonoptimal plan.Moreover, planners empirically showed number benchmark problemssolved without search may even larger number tractable problems identified theoretically. FF planner (Hoffmann, 2005) demonstrated domains constantbounded heuristic plateaus theoretically solved polynomial time using h+ heuristic.eCPT planner (Vidal & Geffner, 2005) solve, use inference, many instances benchmarkdomains without backtrack.Since work Bckstrm Klein (1991a) SAS formulation planning, several studies also performed define tractable classes planning problems. Many results(Bylander, 1994; Bckstrm & Nebel, 1995; Erol, Nau & Subrahmanian, 1995; Jonsson & Bckstrm, 1998) based syntactic restrictions set operators. example, operatorssingle effect, two operators effect, etc.Another important body work focused underlying structure planning problemshighlighted using causal graph, directed graph describes variable dependencies(Knoblock, 1994). Jonsson Bckstrm (1995) presented class planning problems acyclic causal graph unary operators. "3S" class, variables either Static, Symmetricallyreversible, Splitting; plan existence determined polynomial time plan generationprovably intractable. Gimnez Jonsson (2008) designed algorithm solves problemspolynomial time producing compact macro plan place explicit exponential solution. also proved problem plan existence planning problems multi-valuedvariables chain causal graphs NP-hard. Plan existence planning problems binary statevariables polytree causal graphs also proven NP-complete.Jonsson Bckstrm (1994, 1998) considered optimal non-optimal plan generation presented exhaustive map complexity results based syntactic restrictions (using SAS+ formulation planning) together restrictions causal graph structure (interference-safe, acyclic, prevail-order-preserving). present planning algorithm correct runs polynomial time restrictions. Williams Nayak (1997) designed polynomial-time algorithm solving planning problems acyclic causal graphs reversible actions. DomshlakDinitz (2001) investigated connections structure causal graph complexitycorresponding problems case coordination problems dependent agents independent goals acting environment. general problem shown intractable,significant subclasses NP even polynomial.Brafman Domshlak (2003, 2006) studied complexity planning propositionalSTRIPS formalism restrictions unary operators acyclic graphs. give polynomial planning algorithm domains whose causal graph induces polytree bounded indegree.However, also demonstrated singly connected causal graphs problem NP-complete.Gimnez Jonsson (2012) gave polynomial algorithm class P(k) k-dependent planningproblems binary variables polytree causal graphs fixed value k. also showed448fiMONOTONE TEMPORAL PLANNINGif, addition, causal graph bounded depth, plan generation linear size input. Haslum (2008) defines planning problems terms graph grammars. method reducesoriginal problem graph parsing, solved polynomial time certain restrictions grammar. Haslum thus explores novel classes restrictions distinctpreviously known tractable classes. Katz Domshlak (2008) showed planning problems whosecausal graphs inverted forks tractable root variable domain fixed size. Jonsson(2007, 2009) introduced class IR inverted tree reducible planning problems gave algorithm uses macros solve problems class. complexity depends sizedomain transition graph runs polynomial time several subclasses IR. Chen Gimnez (2008) gave unified framework classify complexity planning causal graph restrictions. give complete complexity classification sets causal graphs reversibleplanning problems. graph property determines tractability existence constant boundsize strongly connected components.However, real application domains, sequential nature classical plans often restrictivetemporal plan required consisting set instances durative actions may overlap.Whereas classical planning consists scheduling action-instances, temporal planning seenscheduling events (such establishment destruction fluents) action-instances subjecttemporal constraints capturing internal structure actions. temporal planning frameworkmust therefore used formalize temporal relations events within differentactions-instances. PDDL 2.1 temporal framework (McDermott, 1998; Fox & Long, 2003),PSPACE-complete complexity classical planning preserved different instancesaction cannot overlap. overlap, testing existence valid plan becomesEXPSPACE-complete problem (Rintanen, 2007).paper present polynomially-solvable sub-problem temporal planning.knowledge previous work specifically addressed issue. Polynomiality followsdouble assumption sub-goal fluent established one action also satisfies monotonicity condition. allows us express temporal planning instancepolynomial-time solvable problem STP (Simple Temporal Problem difference constraints).STP instance consists set real-valued variables set constraints three following forms xy < c, xy c xy c, x,y variables c constant.tractable class includes temporally-expressive problems requiring concurrent execution actions, potential industrial applications. also show derive, arbitrary (temporal) planning problem, relaxed version belonging tractable class. leadpolynomial-time detection unsolvability certain cases. also provides polynomial-time heuristic detecting actions fluents satisfying certain properties.article organized follows: Section 2 reviews existing temporal planners usetemporal constraints. Section 3 presents temporal framework. Section 4 introduces notionmonotonicity fluents. Section 5 shows notion monotonicity extended monotonicity* order define larger tractable class presents main theorem. Section 6 demonstrates build tractable relaxation temporal planning problem (or classical planningproblem) based simple temporal problems. Section 7 shows determine whether fluentsmonotone* using relaxation describes tractable class temporal planning problems. Section 8 describes experimental trials validate identify limits temporal relaxation. Section 9 gives examples temporal planning problems solved polynomial time, including449fiCOOPER, MARIS, & REGNIERdetailed example involving concrete mixing, delivery use. worth noting solutionsexamples discussed Section 9 require concurrent actions. Sections 10 11 conclude discuss avenues future research.2. Temporal Constraint Solving Temporal Planningfirst temporal planner DEVISER (Vere, 1983), planners FORBIN (Dean, Firby &Miller, 1988) quite rapidly used independent module, called Time-Map Manager (Dean &McDermott, 1987), handle temporal constraints. HTN (Hierarchical Tasks Network) plannersIxTeT (Ghallab & Alaoui, 1989; Laborie & Ghallab, 1995), TRIPTIC (Rutten & Hertzberg, 1993)TEST (Reichgelt & Shadbolt, 1990) kept idea Independent module manage temporaldata.Todays temporal planners essentially based one three types algorithms: plan-spacesearch, state-space search GRAPHPLAN (Blum & Furst, 1995).plan-space planners HTN POP (Partially Ordered Planning) first extendedtemporal framework. general, use temporal intervals representation actionspropositions, causality relation actions replaced temporal order partialplans. Conflict handling performed system inspired Time-Map Manager. example,VHPOP planner (Younes & Simmons, 2003) uses system simple temporal constraints (STP:Simple Temporal Problem) (Dechter, Meiri & Pearl, 1991), whereas DT-POP (Schwartz & Pollack,2004) based system disjunctive temporal constraints (DTP: Disjunctive Temporal Problem)(Stergiou & Koubarakis, 2000). advantage STPs solved polynomial time.DTPs cannot solved polynomial time, allow user express temporal constraints"A appears B", lightens work planner.State-space search planners associate start instant world state. Search based firstinstants event occur: decision form "when perform action"taken decisions form "which action performed". approach called Decision Epoch Planning. Search also based first finding actions use schedulingactions time: decisions form "when perform action" takendecisions form "which action performed" taken. approach calledTemporally Lifted Progression Planning.GRAPHPLAN also extended temporal domains use solvers, planners LPGP (Long & Fox, 2003), TM-LPSAT (Shin & Davis, 2004) TLP-GP (Maris & Rgnier,2008).seen, many temporal planners use resolution system temporal constraints.However, even system constraints solved polynomial time, casesimple temporal constraints, PSPACE complexity classical planning remains. Indeed, certainplanners even solve system disjunctive temporal constraints, known NP-hard.tractable classes classical planning (discussed Section 1) explicitly extendedtemporal planning. paper present knowledge first tractable class temporal planning problems. solution algorithm based solving system simple temporal constraints.450fiMONOTONE TEMPORAL PLANNING3. Definitionsstudy temporal propositional planning language based temporal aspectsPDDL2.1 (Fox & Long, 2003). fluent positive negative atomic proposition. PDDL2.1,consider changes values fluents instantaneous conditions valuefluents may imposed interval. action quadruple <Cond(a), Add(a), Del(a), Constr(a)>, set conditions Cond(a) set fluents required trueexecuted, set additions Add(a) set fluents established a, set deletions Del(a) set fluents destroyed a, set constraints Constr(a) setconstraints relative times events occur execution a. eventcorresponds one four possibilities: establishment destruction fluent action a,beginning end interval fluent required action a. PDDL2.1, eventsoccur beginning end actions, relax assumption events occur time provided constraints Constr(a) satisfied. Note Add(a) Del(a) maynon-empty. Indeed, unusual durative action establish fluent beginningaction destroy end. also observe duration action, timefirst last events action, need explicitly stored.represent non-instantaneous actions rectangle. duration action given squarebrackets name action. Conditions written action, effects below.action LOAD(m,c) shown Figure 1 represents loading batch concrete c mixer m.Cond(LOAD(m,c)) = {Fluid(c), Empty(m), At-factory(m)}. see figure mixermust empty start loading, whereas concrete must fluid mixer factory whole duration loading. Del(LOAD(m,c)) = {Empty(m)}Add(LOAD(m,c) = {On(m,c)}. see figure soon loading starts, mixerlonger empty end loading mixer contains concrete.Fluid(c)Empty(m)At-factory(m)LOAD(m,c)[5]On(m,c)Empty(m)Figure 1: example representation durative actionuse notation f denote event action establishes fluent f, f denoteevent destroys f, f | f | a, respectively, denote beginning endinterval requires condition f. f already true (respectively, false) eventf (a f ) occurs, still consider establishes (destroys) f. temporal plan may containseveral instances action, since temporal plans studied paper containone instance action, notational simplicity, make distinctionactions action-instances absolutely necessary. use notation (e) representtime plan event e occurs.451fiCOOPER, MARIS, & REGNIERgiven action (or action-instance) a, let Events(a) represent different events constitute definition, namely (a f ) f Add(a), (a f ) f Del(a), ( f | a)( f | a) f Cond(a). definition action includes constraints Constr(a) relative times events Events(a). example, internal structure fixed-length actionLOAD(m,c) shown Figure 1 defined constraints(Fluid(c) | LOAD(m,c)) (Fluid(c) | LOAD(m,c)) = 5(LOAD(m,c) On(m,c)) (Fluid(c) | LOAD(m,c)) = 0PDDL2.1, consider length time events Events(a) necessarilyfixed Constr(a) set interval constraints pairs events,( f | a) ( f | a) [, ] constants ,. use [a(e1, e2), a(e1, e2)] denote interval possible values relative distance events e1, e2 action a. fixed length timeevents e1, e2 Events(a) can, course, modelled setting a(e1, e2) = a(e1, e2). Similarly, absence constraint modelled interval [, +]. introduce twobasic constraints temporal plans must satisfy.inherent constraints set action-instances A: aA, satisfies Constr(a), i.e.pairs events e1, e2 Events(a), (e1) (e2) [a(e1, e2), a(e1, e2)].contradictory-effects constraints set action-instances A: ai, aj A, positivefluents f Del(ai) Add(aj), (ai f ) (aj f ).inherent constraints define internal structure action-instance, whereas contradictory-effects constraints ensure truth-value fluent never becomes undefinedexecution temporal plan. example, plan contains instance action LOAD(m,c)shown Figure 1 instance b another action CLEAN(m) Empty(m)Add(CLEAN(m)), temporal plan must satisfy contradictory-effects constraint(a EMPTY(m)) (b EMPTY(m)).Definition 3.1. temporal planning problem <I,A,G> consists set actions A, initial stategoal G, G sets fluents.Notation: set action-instances, Events(A) union sets Events(a) (foraction-instances A).Definition 3.2. P = <A,>, finite set action-instances {a1,..., an} real-valuedfunction Events(A), temporal plan problem <I, A, G>(1) A,(2) P satisfies inherent contradictory-effect constraints A;P executed (i.e. fluents established destroyed times given ) startinginitial state I:(3) ai A, f Cond(ai) true required,(4) goal fluents g G true end execution P.(5) P robust infinitesimal shifts starting times actions.452fiMONOTONE TEMPORAL PLANNINGEvents instantaneous, whereas actions durative may also variable length.Thus temporal plan P schedule action-instances directly schedules eventsaction-instances.Condition (5) Definition 3.2 means disallow plans require perfect synchronisationdifferent actions. Fox, Long Halsey (2004) show condition imposedwithin PDDL2.1. require plans fluents established strictly beginninginterval required. exception rule fluent f established required action a. allow possibility perfect synchronization withinaction, means (a f ) = ( f | a). Similarly, fluents destroyedstrictly end interval required. exception rulefluent f required destroyed action a, case ( f | a) =(a f ). example, fluent Empty(m) simultaneously required destroyed actionLOAD(m,c) shown Figure 1.Since set actions viewed set action-instances action occurs exactlyonce, apply constraints, inherent contradictory-effects constraints, setactions rather set action-instances. look detail type constraintsimpose relative times events within action-instance.Definition 3.3. interval constraint C(x,y) real-valued variables x,y binary constraintform xy [a,b] a,b real constants.Definition 3.4. (Jeavons & Cooper, 1995) binary constraint C(x,y) min-closed pairsvalues (x1,y1), (x2,y2) satisfy C, (min(x1,x2),min(y1,y2)) also satisfies C. binary constraintC(x,y) max-closed pairs values (x1,y1), (x2,y2) satisfy C, (max(x1,x2),max(y1,y2))also satisfies C.Lemma 3.5. Let = {a1,..., an} set actions set action-instances actionai (i =1,..., n) occurs ti1 times. Let real-valued function set events A.e Events(ai), let e[ j] ( j =1,...,ti) represent occurrence event e within instance number j ai.{1,...,n}, define real-valued functions min, max set events set actionsmin(e) = min{(e[ j]) | j =1,..., ti} max(e) = max{(e[ j]) | j =1,..., ti}. satisfies inherent constraints A, min max satisfy inherent constraints A.Proof: interval constraints min-closed max-closed (Jeavons & Cooper, 1995).applying definition min-closedness (respectively, max-closedness) ti 1 times, action ai,deduce satisfies interval constraint ti instances ai, min (max)satisfies constraint action ai. words, pairs events e1, e2 Events(ai),(e1[ j]) (e2[ j]) [a(e1, e2), a(e1, e2)] j=1,...,ti, min(e1) min(e2) [a(e1, e2), a(e1, e2)]max(e1) max(e2) [a(e1, e2), a(e1, e2)]. Hence satisfies inherent constraints A, minmax satisfy inherent constraints A.Definition 3.6. temporal planning problem <I,A,G> positive negative fluentsconditions actions goal G.453fiCOOPER, MARIS, & REGNIERpaper, consider positive temporal planning problems <I,A,G>. well knownplanning problem transformed equivalent positive problem linear timeintroduction, positive fluent f, new fluent notf replace occurrences f conditions actions (Ghallab, Nau & Traverso, 2004). important note, however, transformation may conserve properties instance. assumption problems positive, G Cond(a) (for action a) composed positive fluents. convention, Add(a)Del(a) also composed exclusively positive fluents. initial state I, however, may containnegative fluents.simplicity presentation, assume throughout paper set actions undergone filtering operation consisting eliminating actions cannot possiblyexecuted since Cond(a) subset Add(A).need following notion establisher-uniqueness order define tractable classtemporal planning problems. equivalent post-uniqueness SAS+ planning (Jonsson &Bckstrm, 1998) restricted Boolean variables specialised applies specific subsetpositive fluents. next section, apply subset positive fluents mayrequired realisation goal.Definition 3.7. set actions = {a1,...,an} establisher-unique (EU) relative set positivefluents j, Add(ai) Add(aj) = , i.e. fluent established two distinct actions A.set actions establisher-unique relative set sub-goals problem, determine polynomial time set actions necessarily present temporal plan.remains problem determining many times action must occur scheduling action-instances order produce valid temporal plan. Establisher-uniqueness alone cannotprevent minimal plans exponential size (Bckstrm & Klein, 1991b).4. Monotone Planningsection, introduce notion monotonicity fluents. Together establisheruniqueness, monotonicity fluents sufficient condition existence polynomial-timealgorithm temporal planning.Definition 4.1. fluent f monotone (relative positive temporal planning problem <I,A,G>) if,destroyed f never re-established temporal plan <I,A,G>. fluent f+monotone (relative <I,A,G>) if, established f never destroyed temporalplan <I,A,G>. fluent monotone (relative <I,A,G>) either + monotone (relative<I,A,G>).Example 4.2: Consider two actions shown Figure 2: LIGHT-MATCH LIGHT-CANDLE.action LIGHT-MATCH requires match live, order light it. match remains litblown end action. constraint Constr(LIGHT-MATCH) imposesduration action, i.e. (LIGHT-MATCH Match-lit) (LIGHT-MATCH Match-lit),1 10 time units. second action LIGHT-CANDLE requires match lit dur454fiMONOTONE TEMPORAL PLANNINGing two time units candle lit. initial state = {live, Match-lit} set goalsG = {Candle-lit}, clear temporal plans problem involve executing two actionsparallel start (respectively, end) LIGHT-MATCH strictly (after) start(end) LIGHT-CANDLE. one match available, means LIGHT-MATCHexecuted once. means fluent Match-lit monotone since cannotestablished destroyed. fluent Match-lit +monotone since destroyedestablished.LiveMatch-litLIGHT-MATCHLiveLIGHT-CANDLE[2]Candle-litMatch-litMatch-litFigure 2: example set actions allows us light candle using single match.Notation: set actions, use notation Del(A) represent union sets Del(a)(for actions A). Add(A), Cond(A), Constr(A) defined similarly.following lemma follows trivially Definition 4.1.Lemma 4.3. f Add(A) Del(A), f monotone +monotone relative positivetemporal planning problem <I,A,G>.Certain physical actions chemical reactions irreversible. Examples include bursting balloon, killing fly, adding milk cup coffee burning fuel. Since action destroy corresponding fluents Burst, Fly-dead, Milk-added, Fuel-burnt, fluents necessarilymonotone +monotone Lemma 4.3. similar remark holds fluents may trueinitial state action establishes them, Fly-alive, example.Example 4.2, fluent Live monotone +monotone since action establish it, fluent Candle-lit monotone +monotone since action destroy it.introduce three sets constraints, authorisation constraints appliedmonotone fluents f +authorisation constraints +monotone fluents. causality constraintsfluent f valid unique action-instance establishes f.authorisation constraints positive fluent f set action-instances A:ai aj A, f Del(aj) Cond(ai), ( f | ai) < (aj f ); ai A, f Del(ai)Cond(ai), ( f | ai) (ai f ).+authorisation constraints positive fluent f set action-instances A: ai,aj A,f Del(aj) Add(ai) (Cond(A) G), (aj f ) < (ai f ).causality constraints positive fluent f set action-instances A: ai aj A,f(Cond(aj) Add(ai))\I, (ai f ) < ( f | aj); ai A, f (Cond(ai) Add(ai))\(ai f ) ( f | ai).455fiCOOPER, MARIS, & REGNIERWithin action-instance ai, perfect synchronisation possible events f | aiai f. Indeed, one way ensuring action executed temporalplan create fluent fa Cond(a) Del(a) simultaneously required deletedstart established action. example, action LIGHTMATCH Example 4.2, fa fluent live. hand, condition (5) Definition 3.2temporal plan, cannot perfect synchronisation events distinct action-instances.explains authorisation constraints impose strict inequality ( f | ai) < (aj f )ai aj non-strict inequality ( f | ai) (aj f ) ai = aj. similar remarkholds perfect synchronisation events ai f f | aj permittedcausality constraints ai = aj.Definition 4.4. temporal plan <A,> positive temporal planning problem <I,A,G> monotonepair action-instances (in A) satisfies +authorisation constraints +monotone fluentssatisfies authorisation constraints monotone fluents.Definition 4.5. Given temporal planning problem <I,A,G>, set sub-goals minimum subset SG Cond(A) G satisfying1. G SG2. A, Add(a) (SG \ I) , Cond(a) SG.reduced set actions Ar = {a | Add(a) (SG \ I) }.determine SG Ar polynomial time result unique. see considersimple algorithm initialises SG G repeatedly adds SG set fluents Funion (Cond(a) \ SG) actions Add(a) (SG \ I) ,F=. simple algorithm worst-case time complexity O(n3), n total numberevents actions A, produces unique result clearly minimum set fluentssatisfying two conditions Definition 4.5. Note algorithm similar standardmethod relevance detection used GRAPHPLAN (Blum & Furst, 1995).order state theorem, require relaxed definition set sub-goalsreduced set actions take account case fluents initial state destroyedre-established. Let SG p (the set possible sub-goals) denote minimal set fluents satisfying1. G SG p2. actions A, Add(a) SG p Cond(a) SG p.Let Ap set actions { | Add(a) SG p }. difference Ar Apset actions could occur minimal temporal plan fluents initialstate destroyed re-established. SG Ar, SG p Ap unique determined O(n3) time.pfluent Cond(Ar) G monotone, say plan P temporal planning problem <I,A,G> satisfies authorisation constraints monotone fluent satisfies authorisation constraints +monotone fluent satisfies +authorisation constraints (it assumedknow, fluent f Cond(Ar) G, whether f + monotone).456fiMONOTONE TEMPORAL PLANNINGfollowing theorem contains minor improvements corrections compared conferenceversion present paper (Cooper, Maris & Rgnier, 2012). Since corollary Theorem 5.6(proved following section), omit proof.Theorem 4.6. Given positive temporal planning problem <I,A,G>, let SG Ar be, respectively,set sub-goals reduced set actions, Ap defined above. Suppose Constr(Ar)interval constraints, set actions Ar establisher-unique relative SG \ I, fluentCond(Ar) G monotone relative <I,Ar,G> fluent (Cond(Ar) G) monotonerelative <I,Ap,G>. <I,A,G> temporal plan P(1) G (I \ Del(Ar)) Add(Ar)(2) Cond(Ar) Add(Ar)(3) fluents g G Del(Ar) Add(Ar) +monotone relative <I,Ar,G>(4) set authorisation, inherent, contradictory-effects causality constraints solutionset actions Ar.5. Extending Monotonicity Fluentssection introduce notion monotonicity*, thus allowing us define larger tractable class temporal planning problems.Definition 5.1. plan minimal removing non-empty subset action-instances producesinvalid plan. fluent f monotone* (relative positive temporal planning problem <I,A,G>) if,destroyed f never re-established minimal temporal plan <I,A,G>. fluent f+monotone* (relative <I,A,G>) if, established f never destroyed minimaltemporal plan <I,A,G>. fluent monotone* (relative <I,A,G>) either + monotone*(relative <I,A,G>).Example 5.2. give example monotone* fluent monotone, consider following planning problem actions instantaneous:Start_vehicle: kDrive: d,Unload: p= {k}, G = {p}. fluents represent ignition key (k), engine (o),destination reached (d) package delivered (p). one minimal plan, namely Start_vehicle, Drive, Unload, also non-minimal plan Start_vehicle,Drive, Start_vehicle, Unload fluent established, destroyed re-established.Hence monotone* monotone.+monotone (monotone) fluent clearly +monotone* (monotone*) since plan, including minimal plans, established (destroyed) never destroyed (re-established).order prove equivalent Theorem 4.6 monotone* fluents, first require another definitiontwo minor technical results.457fiCOOPER, MARIS, & REGNIERDefinition 5.3. minimal temporal plan <A,> positive temporal planning problem <I,A,G>monotone* pair action-instances satisfies +authorisation constraints+monotone* fluents satisfies authorisation constraints monotone* fluents.following lemma follows directly Definition 5.1 monotonicity* fluent alongfact fluent cannot simultaneously established destroyed temporal plan.Lemma 5.4. Suppose positive fluent f monotone* relative positive temporal planningproblem <I,A,G>. Let <A,> minimal temporal plan <I,A,G> actions ai, ajf Add(ai) Del(aj). f +monotone* relative problem, (aj f ) < (ai f ). fmonotone* relative problem, (ai f ) < (aj f ).Proposition 5.5. fluent Cond(A) monotone* relative positive temporal planning problem <I,A,G>, minimal temporal plans <I,A,G> monotone*.Proof: Let P minimal temporal plan. Consider firstly positive monotone* fluent f.show authorisation constraints satisfied f P, i.e. f destroyed (ortime as) required P. must case since P plan f cannot reestablished destroyed. Consider secondly positive +monotone* fluent f. Lemma 5.4,+authorisation constraint satisfied f P.give main theorem generalizes Theorem 4.6 monotone* fluents.Theorem 5.6. Given positive temporal planning problem <I,A,G>, let SG Ar be, respectively,set sub-goals reduced set actions. Suppose constraints Constr(Ar) interval constraints, set actions Ar establisher-unique relative SG \ I, fluent Cond(Ar) Gmonotone* relative <I,Ar,G> fluent (Cond(Ar) G) monotone* relative<I,Ap,G>. <I,A,G> temporal plan P(1) G (I \ Del(Ar)) Add(Ar)(2) Cond(Ar) Add(Ar)(3) fluents g G Del(Ar) Add(Ar) +monotone* relative <I,Ar,G>(4) set authorisation, inherent, contradictory-effects causality constraints (given Sections 3 4) solution set actions Ar (where +authorisation constraints apply+monotone* fluent authorisation constraints apply monotone* fluent).Proof: () <I,A,G> temporal plan, clearly minimal plan P. Ar setactions establish sub-goals f SG \ I. definition, SG = Cond(Ar) G. Since Ar establisherunique relative SG \ I, sub-goal f SG \ unique action establishes it. Henceaction Ar must occur plan P. Furthermore, (Add(A) \ Add(Ar)) (Cond(Ar) \ I) = Definition 4.5. follows (2) necessary condition temporal plan P exist.Let P p version P keep actions Ap. P p valid temporal plan since,definition Ap, fluent (Cond(Ap) G) established actions \ Ap. Indeed, since Passumed minimal, must P p =P. let P version P keepactions Ar. Definition 4.5, conditions actions P goals G established458fiMONOTONE TEMPORAL PLANNINGactions eliminated P, except possibly also I. Thus show P alsovalid temporal plan need show establishment fluent f (Cond(Ar) G)P action Ap \ Ar unnecessary. hypothesis, f monotone* relative <I,Ap,G>hence f cannot established P destroyed. Since f I, means establishment f P unnecessary. Hence P valid temporal plan. Indeed, since P assumedminimal, must P=P.seen P contains exactly actions Ar. Hence, fluents gG (which necessarily positive hypothesis positive planning problem) either present initial state deleted action Ar must established action Ar. follows (1)necessary condition P valid temporal plan. Consider g G Del(Ar) Add(Ar).Lemma 5.4, deduce g cannot monotone*, since g true end executionP. Thus (3) holds. Let Pmin=<Ar,min> version temporal plan P=<Ar,>keep one instance action ai Ar (and instances actions \ Ar) min definedtaking first instance event Events(ai), action ai Ar, describedstatement Lemma 3.5. show Pmin satisfies authorisation, inherent, contradictory-effects causality constraints.know P temporal plan problem <I,A,G>. Hence also temporal planproblem <I,Ar,G>, since uses actions Ar. hypothesis, fluents Cond(Ar)monotone relative <I,Ar,G>. Therefore, Proposition 5.5, temporal plan P monotone*. SinceP monotone* definition temporal plan, authorisation constraints satisfied.P must also, definition temporal plan, satisfy inherent contradictory-effects constraints.follows Lemma 3.5 Pmin also satisfies inherent constraints. Since events Pminsimply subset events P, Pmin necessarily satisfies authorisation constraintscontradictory-effects constraints.Consider positive fluent f (Cond(aj) Add(ai)) \ I, ai, aj Ar. Since aj Ar, knowAdd(aj) (SG \ I) hence Cond(aj) SG, definition set sub-goals SG.Since f Cond(aj) deduce f SG. fact, f SG \ since assume f I. followsf Add(a) A, Ar. know Ar establisher-unique (relativeSG). Hence, since f Cond(aj) Cond(Ar) f Add(ai), f established single actiona=ai A. Since f I, first establishment f instance ai must occur P f firstrequired instance aj. follows causality constraint must satisfied f Pmin.() Suppose conditions (1)-(4) satisfied Ar. Let P solution set authorisation,inherent, contradictory-effects causality constraints Ar. solution constraints usesaction Ar (in fact, uses action exactly since assigns one start time actionAr). Consider g G. (1), g (I \ Del(Ar)) Add(Ar). g Del(Ar), g necessarilytrue end execution P. hand, g Del(aj) action aj Ar,(1) necessarily action ai Ar establishes g. Then, (3) g +monotone*. Since Psatisfies +authorisation constraint g, ai establishes g deletions g. follows gtrue end execution P.Consider monotone* f Cond(aj) aj Ar. Since authorisation constraintsatisfied f P, f deleted P required aj. Therefore, remains459fiCOOPER, MARIS, & REGNIERshow f either true initial state established time requiredaj. (2), f Add(Ar), need consider case f f Add(ai)action ai Ar. Since P satisfies causality constraint, (ai f ) < ( f | aj) hence,execution P, f true required action aj.Consider f Cond(aj), aj Ar, f monotone*. assumptions theorem, f necessarily +monotone* f I. First, consider case f Del(Ar)Add(Ar). Lemma 4.3, f monotone (and hence monotone*) contradicts assumption.Therefore f Del(ak) Add(ai), ai, ak Ar, recall f I. Since +authorisationconstraint satisfied f P, destruction f occurs f established ai. followscausality constraint condition f true required aj executionP.makespan temporal plan P = <A,> time interval first last eventsP, i.e. max{(e) | eEvents(A)} min{(e) | eEvents(A)}. problem finding plan minimum makespan polytime approximable polynomial-time algorithm which, giventemporal planning problem <I,A,G> > 0, finds temporal plan whose makespanMopt + , Mopt minimum makespan temporal plans <I,A,G>.constraints Constr(a) impose time interval pair eventsEvents(a) fixed, say action rigid.express complexities terms total number n events actions A. Without lossgenerality, assume actions contain least one event fluents occur leastone event. Hence number actions fluents bounded n.Theorem 5.7: Let EUM* class positive temporal planning problems <I,A,G>establisher-unique relative Cond(A) G, fluents Cond(A) G monotone* relative<I,A,G> fluents (Cond(A) G) monotone* relative <I,A,G>. EUM*solved time O(n3) space O(n2), n total number events actions A. Indeed,even find temporal plan minimum number action-instances minimal cost,action associated non-negative cost, complexity. Furthermore, actionsrigid problem finding plan minimum makespan polytime approximable.Proof: fact EUM* solved time O(n3) space O(n2) follows almost directlyTheorem 5.6 fact set authorisation, inherent, contradictory-effects causalityconstraints form STP, simple temporal problem difference constraints (Koubarakis, 1992).instance STP solved O(n3+k) time O(n2+k) space (Gerevini & Cristani, 1997),n number variables k number difference constraints (i.e. constraintsform xj xi d). Here, difference constraints contradictory-effects constraintsn2, k=O(n2). Furthermore, pointed Section 4, calculation SGAr O(n3).Establisher-uniqueness tells us exactly actions must belong minimal temporal plans. Then,seen proof Theorem 5.6, monotonicity* assumptions imply needone instance actions. trivially follows solve optimal versiontemporal planning problem, aim find temporal plan minimum number460fiMONOTONE TEMPORAL PLANNINGaction-instances minimal cost, action associated cost, solving set authorisation, inherent, contradictory-effects causality constraints.suppose actions rigid. express problem minimising makespanignoring contradictory-effects constraints linear program. showalways possible satisfy contradictory-effects constraints (without violating constraints)making arbitrarily small perturbations start times actions. assume eventssingle action-instance satisfy contradictory-effects authorisation constraints; since actionsrigid checked independently action polynomial time. Let P temporalplan <I,A,G> minimum makespan. showed proof Theorem 5.6 Pmin,obtained P keeping one instance action P, also valid temporal plan. Sincemakespan cannot increased eliminating action-instances temporal plan, Pmin also minimises makespan. Let C set inherent, authorisation causality constraints Pmin mustsatisfy. C contains equality constraints form xj xi = d, constant xj, xi timesevents action, constraints form xj xi < d, constant xj, xitimes events different actions. introduce two variables begin, end denote Coptset constraints C together constraints begin (e) (e) end eEvents(Ar).linear program minimises end begin subject constraints Copt minimises makespantake account contradictory-effects constraints C must satisfied validtemporal plan. Let PLP solution linear program. makespan clearly greaterMopt, minimum makespan temporal plans (since valid temporal plans must satisfy constraints C C ). Let minimum difference (xj xi) PLP constraints formxj xi < C. Let minimum non-zero difference | (xj xi) | PLP contradictoryeffects constraints xj xi C . Suppose Ar = {a1,...,am}. Let P identical PLP exceptadd = min{,,}(i1)/m (e) eEvents(ai). construction, contradictory-effectsconstraints violated PLP satisfied P, contradictory-effects constraintssatisfied PLP still satisfied P, strict inequalities satisfied PLPstill satisfied P. inequalities begin (e) still satisfied P. Finally, order guaranteesatisfying inequalities (e) end, suffices add end. resulting solution P correspondsvalid temporal plan whose makespan Mopt + . result follows factlinear programming solvable O(n3.5L) time Karmarkars interior-point algorithm, nnumber variables L number bits required encode problem (Karmarkar,1984).ffa1a1a1ga2ghha2fa2f(a)gff(b)g(c)Figure 3: (a) instances action a1 occur strictly instances action a2, (b) instancesa2 contained instances a1 (c) instances a1 overlap instances a2.461fiCOOPER, MARIS, & REGNIERclass EUM*, sub-goal fluents f SG true single interval Int(f, P) execution temporal plan P. f +monotone*, Int(f, P) necessarily form [t1,) t1moment f first established. f monotone*, Int(f, P) necessarily form[t1, t2] t1 moment f first established (or 0 f I) t2 first momentt1 f destroyed (or [t1,) f never destroyed). class EUM* solvable polynomialtime due fact establisher-uniqueness ensures choice concerning actions include plan monotonicity* ensures choice concerning timeevents within interval. Given two restrictions quite surprising large range industrial planning problems fall class (Cooper, Maris & Rgnier, 2012, 2013b). EU monotoneplanning sufficiently powerful modelling language allow us impose constraintsaction occurs plan instances event e1 occur instances evente2. illustrate this, Figure 3 shows impose precedence, containment overlapping constraints actions a1 a2 introduction of, respectively, one, two three fluentsf, g, h occur events shown Figure 3. Lemma 4.3, fluents f, g, hnecessarily monotone +monotone temporal plans.6. Temporal RelaxationRelaxation ubiquitous Artificial Intelligence. valid relaxation instance solutionsolution. Hence relaxation solution, implies unsolvabilityoriginal instance I. tractable relaxation built solved polynomial time.traditional relaxation propositional non-temporal planning problems consisting ignoringdeletes two drawbacks. Firstly, traditionally used forward search, validtemporal planning unless specific transformation applied beforehand set actions (Cooper, Maris & Rgnier, 2013a). Secondly, use information may essentialdetection unsolvability original instance, namely destruction fluents temporal information relative duration actions. section present valid tractablerelaxation inspired EU monotone temporal planning. following section show usetemporal relaxation detect monotonicity* fluents. possible applications,detection action landmarks (actions occur solution plan) (Karpas & Domshlak,2009), immediately leads lower bound cost plan action associated cost (Cooper, de Roquemaurel & Rgnier, 2011).traditional relaxation classical non-temporal planning problems consists ignoring deletesactions. finding cost optimal relaxed plan, relaxation used calculateadmissible h+ heuristic. shown Betz Helmert (2009), h+ informative unfortunately NP-hard compute (Bylander, 1994) also hard approximate (Betz & Helmert, 2009).relaxation use information may essential detection un-solvabilityoriginal instance (namely destruction fluents), lot research carriedtake deletes account (Fox & Long, 2001; Gerevini, Saetti & Serina, 2003; Helmert, 2004;Helmert & Geffner, 2008; Keyder & Geffner, 2008; Cai, Hoffmann & Helmert, 2009). Another recentapproach (Haslum, Slaney & Thibaux, 2012; Keyder, Hoffmann & Haslum, 2012) consists enriching classical relaxation set fact conjunctions. Finally red-black relaxation (Katz,Hoffmann & Domshlak, 2013a, 2013b) generalizes delete-relaxed planning relaxing subsetstate variables.462fiMONOTONE TEMPORAL PLANNINGUnfortunately, relaxations directly generalize temporal planning, since techniquesbased combination ignoring deletes forward search valid temporal planning unless specific transformation applied beforehand set actions. important aspect temporal planning, absent non-temporal planning, certain temporal planning problems, known temporally-expressive problems, require concurrency actions ordersolved (Cushing, Kambhampati, Mausam & Weld, 2007). typical example temporallyexpressive problem cooking: several ingredients must cooked simultaneously orderready moment. previous paper (Cooper, Maris & Rgnier, 2010), identified subclass temporally expressive problems, known temporally-cyclic, require cyclicallydependent sets actions order solved.Wages-paidPAY(1)WORK(10)Job-startedJob-startedJob-finishedWages-paidFigure 4: example temporally cyclic temporal planning problem.simple temporally-cyclic problem shown Figure 4, = G = {Job-finished}.condition workman start work paid (at end job) whereas employerpay started work. valid temporal plan problem actions PAYWORK must executed parallel execution action PAY contained within interval action WORK executed. applying traditional ignore-deletes relaxation,forward chaining initial state would able start either two actions sincemissing condition. Thus, certain proposed techniques, although useful guidingheuristic search (Eyerich, Mattmller & Rger, 2009; & Kambhampati, 2003), validtemporally cyclic problems. Different solutions exist get round problem temporal cycles.example, gave polynomial-time algorithm transform temporally-cyclic problemequivalent acyclic one (Cooper, Maris & Rgnier, 2013a). transformations proposedliterature (Long & Fox, 2003; Coles, Fox, Long & Smith, 2008) also eliminate possibility temporal cycles, although explicitly-stated aim descriptionstransformations: temporal cycles avoided decomposing durative actions instantaneous actions denoting start end action. Intermediate conditions also managed splittingactions component actions enclosed within envelope action (Smith, 2003). case, ignoring deletes transformed problem followed forward search provides valid relaxation.original problem temporarily cyclic, ignoring deletes followed forward searchvalid relaxation.section, present alternative form relaxation, call TR (for Temporal Relaxation), inspired EU monotone planning, comprising STP instance solutionoriginal temporal planning instance solution. incomparable relaxation basedignoring deletes, show temporal non-temporal examples, senseinstances detected unsolvable using EU monotone relaxation ignoring deletes (and vice versa).463fiCOOPER, MARIS, & REGNIERapplying following simple rule convergence transform (in polynomial time)temporal planning problem P relaxed version P EU relative set sub-goalsSG: sub-goal fluent f established two distinct actions, delete f goal GCond(a) actions a. consequence, f longer sub-goal SG recalculated.Clearly, P valid relaxation P. assume temporal planning problem EUrelative SG.denote ALM set action landmarks detected (Karpas & Domshlak,2009). Action landmarks also known indispensable actions (Cooper, de Roquemaurel & Rgnier, 2011). Establisher-uniqueness implies easily identify many actions, particular set actions Ar establish sub-goals present initial state I.cannot assume STP single instance action sufficient. action landmark event e Events(a), introduce two variables first(e), last(e) representing times first last occurrences event e plan. constraints temporalrelaxation TR include versions internal, contradictory-effects, authorization causality constraints (which give below) together following obvious constraint:intrinsic TR-constraints: aALM, events e Events(a), first(e) last(e).conference version paper described preliminary version TR (Cooper,Maris & Rgnier 2013b), made assumption two instances action overlap. assumption, e1, e2 Events(a), first occurrences e1, e2 plan correspondinstance action a. similar remark holds last occurrences e1, e2. turnsneed make assumption order apply TR inherent constraint Constr(a)independently values first(e) last(e) (for e Events(a)). Indeed, according Lemma 3.5, assuming Constr(Ar) interval constraints, instance action satisfies inherent constraints, first last satisfy inherent constraints events action a:inherent TR-constraints: aALM, e1,e2 Events(a), first(e1) first(e2) [a(e1,e2), a(e1,e2)]last(e1) last(e2) [a(e1,e2), a(e1,e2)].contradictory-effects constraints TR follows:contradictory-effects TR-constraints: ai, aj ALM, positive fluents f Del(ai) Add(aj),L1,L2 {first,last}, L1(ai f ) L2(aj f ).positive fluent f known monotone*, apply TR following modified version authorisation constraints f:authorisation TR-constraints: ai aj ALM, f Del(aj) Cond(ai), last( f | ai) <first(aj f ); ai ALM, f Del(ai) Cond(ai), last( f | ai) first(ai f ).positive fluent f known +monotone*, apply TR following modifiedversion +authorisation constraints f:+authorisation TR-constraints: ai, aj ALM, f Del(aj) Add(ai), last(aj f ) <first(ai f).check every condition every goal established, i.e. Cond(ALM) Add(A)G (I \ Del(ALM)) Add(A). not, consider relaxation TR solution.464fiMONOTONE TEMPORAL PLANNINGalso apply TR following causality constraints positive fluent f:causality TR-constraints: ai aj ALM, f (Cond(aj) Add(ai)) \ first(ai f ) <first(f | aj); ai ALM, f (Cond(ai) Add(ai)) \ first(ai f ) first( f | ai).also apply following goal constraints g G:goal TR-constraints: ai, aj ALM, g Del(aj) Add(ai), last(aj g) < last(ai g).course, causality goal constraints necessary conditions existence plan ALM EU relative (Cond(ALM) \ I) (G Del(A)).Definition 6.1: action aA unitary temporal planning problem <I,A,G> minimaltemporal plan <I,A,G> contains one instance a.action aALM known unitary, TR, event e Events(a), replacetwo variables first(e), last(e) constraints unique variable (e).Thus TR consists first eliminating G Cond(a) (for A) fluents establishedtwo distinct actions, then, checking Cond(ALM) Add(A) G (I \ Del(ALM))Add(A), solving STP consisting intrinsic, inherent, contradictory-effects, authorisation,+authorisation, causality goal TR-constraints, given above.TR valid relaxation since constraints TR must clearly satisfied temporal plan.Furthermore, plan exists minimal plan necessarily exists minimal plansone instance unitary action. assumptions establisher-uniqueness monotonicity*, TR fact solution procedure tractable class described Theorem 5.7.temporal relaxation TR significantly strengthened prior identification unitaryactions. therefore present lemmas cover several simple common casesactions identified unitary. first give lemma allows us simplify certain actions.Lemma 6.2: Suppose f f monotone* positive temporal planning problem<I,A,G>. Let identical set actions except f deleted Add(a)action a. minimal temporal plans <I,A,G> minimal temporal plans <I,A,G>vice versa.Proof: P minimal temporal plan <I,A,G>, then, since f monotone*, cannot established destroyed P. follows establishments f P unnecessarysince occur f already true. Hence, P also plan <I,A,G>. alsominimal <I,A,G> since conditions goals identical problems. minimal temporal plan <I,A,G> necessarily temporal plan <I,A,G>, since conditions goalspositive, necessarily minimal since conditions goals identical problems.assume rest paper TR set actions simplified indicatedLemma 6.2.465fiCOOPER, MARIS, & REGNIERLemma 6.3: f monotone*, f Cond(a), f Del(a) simultaneously requires destroys f(i.e. Constr(a) contains constraints ( f | a) = ( f | a) = (a f )), unitary.Proof: Let P minimal temporal plan containing consider instance Pfirst destroys f. condition (5) Definition 3.2 temporal plan, two instancessynchronised destroy f simultaneously, instance unique. monotonicity*,f cannot later established P. Hence instance require (and destroy) finstant. follows minimal temporal plan P contain one instance a.Hence unitary.Lemma 6.4: Let <I,A,G> positive temporal planning problem aA actionrigid two instances overlap temporal plan <I,A,G>. threefollowing cases unitary <I,A,G>: (1) fluents Add(a) monotone*, (2) Add(a)G\Cond(A), (3) Add(a) = {h} fluent hG, unique action b hCond(b), furthermore b unitary.Proof: Let P minimal temporal plan <I,A,G> containing action a. First, consider case (1)fluents Add(a) monotone*. Monotone* fluents never need establishedminimal plan. minimal plans, +monotone* fluentestablished, cannot destroyed and, monotone* fluent established,destroyed established again. follows first establishmentfluent Add(a) unnecessary P. Whether rigid two instances overlapP, first establishments fluents Add(a) correspond instancea. instances thus deleted P without destroying validity. Henceunitary.consider case (2), i.e. Add(a) G\Cond(A). last establishment fluentAdd(a) unnecessary P, since fluents Add(a) conditions actions A.Whether rigid two instances overlap P, last establishmentsfluents Add(a) correspond instance a. instances thusdeleted P without destroying validity. Hence unitary.consider case (3). Since b unitary, minimal plan P contains one instanceb. instance last establishes h required unique instance bactually necessary. instances deleted P without destroyingvalidity. Hence unitary.often case two instances action executed parallel, example duelimited resources. therefore quite common modelling temporal planning problemforbid two instances action overlap. achieved introducing fluentf Cond(A\{a}) Add(A\{a}) Del(A\{a}) G, adding f placing events f | a,f | f beginning event f end a. Alternatively,place event f beginning events f | a, f | f end a,case need fI. either case, say f non-overlap fluent a.state general version Lemma 6.4.466fiMONOTONE TEMPORAL PLANNINGLemma 6.5: Let <I,A,G> positive temporal planning problem aA action fnon-overlap fluent a. three following cases unitary <I,A,G>: (1)fluents Add(a)\{f} monotone*, (2) Add(a)\{f} G\Cond(A), (3) Add(a)\{f} = {h}fluent hG, unique action b h Cond(b), furthermore bunitary.Proof: Let P minimal temporal plan <I,A,G> containing action a. two instancesoverlap P. proof Lemma 6.4, need keep single instance a: case (1)first instance a, case (2) last instance a, case (3) last instance h required b. Hence unitary.temporal relaxation TR uses two types information used ignore-deletes relaxation:destruction fluents temporal information. give two simple examples illustratethis.Example 6.6: simplest possible example showing TR detect unsolvability planning problem cannot detected ignore-deletes relaxation consists initial state= {f}, goal G = {f, g} single action simultaneously establishes g destroys f. Unsolvability detected TR since condition G \ Del(ALM) Add(A) satisfied.Example 6.7: Consider problem lighting candle using single match described Example 4.2. Suppose match short burn two time units.problem clearly establisher-unique. Furthermore, actions belong Ar hence landmarks. deduce LIGHT-MATCH unitary Lemma 6.3 LIGHT-CANDLEunitary Lemma 6.4 (case (2)). Thus, TR single variable (e) eventeEvents(A). already seen, Match-lit monotone, TR contains authorisationconstraint (match-lit | LIGHT-CANDLE) < (LIGHT-MATCH match-lit). also containscausality constraint (LIGHT-MATCH match-lit) < (match-lit | LIGHT-CANDLE).two inherent constraints (LIGHT-MATCH match-lit) (LIGHT-MATCH match-lit) 2(match-lit | LIGHT-CANDLE) (match-lit | LIGHT-CANDLE) = 2 provide contradiction. form relaxation take account duration actions detectunsolvability problem, since identical problem different durations given Example 4.2 solution.Example 6.8: give generic example involving choice two alternativestemporal relaxation TR detect unsolvable problems cannot detected ignoringdeletes. illustrate generic example simple non-temporal planning problem Pinitial state = {f}, goal G = {g,h} following two actions:B: f f, gC: f f, hfluents many possible interpretations, including: f = packet, g = sentpacket Destination1, h = sent packet Destination2. Clearly problem solution, discovered ignore-deletes relaxation (which cannot take account factlonger packet sent somewhere).467fiCOOPER, MARIS, & REGNIERshow TR solution give proof general case ALM EU, actionsB,C ALM instantaneous, f (Cond(B) Del(B) Cond(C) Del(C) I)\Add(A), g Add(B)(G\I) h Add(C) (G\I). fluent f monotone Lemma 4.3 since actionestablish it. TR solution since obtain following contradiction sequence authorisation, inherent, intrinsic, authorisation, inherent intrinsic (respectively) constraints: last(f | B)< first(C f) = first(f | C) last(f | C) < first(B f) = first(f | B) last(f | B).point improved versions ignore-deletes relaxation retain information concerning deletes would also able detect unsolvability simple problem.example, transformation Keyder, Hoffmann Haslum (2012) detect unsolvabilityintroducing special fluent representing conjunction g h .Example 6.9: show temporal relaxation TR detect unsolvable problemsnecessarily establisher-unique. example, actions instantaneous hence present form non-temporal planning problem P initial state = {j,m,d}, goal G = {g}following three actions:Buy: j, h, d,Sell: h m, hMort2: d, h m, d, ginterpret fluents follows: j = job, = money, = debt-free, h =house, g = taken second mortgage. example, action Buy possiblejob money put deposit house; result housedebt longer money. goal take second mortgage via action Mort2.problem solution, fact detected standard relaxation consistingignoring destructions fluents. set TR, first determine action landmarks ALM = {Buy,Mort2} easily identified landmarks rules given Cooper, de Roquemaurel Rgnier(2011) since establish sub-goals h g, respectively, present initial state. ObserveALM EU relative set sub-goals {g,h} retains destructions fluents. applying Lemma 6.3 fluent (which monotone Lemma 4.3), deduce Mort2unitary. deduce Lemma 6.4 (case (3)) Buy unitary, since Add(Buy) = {h}Mort2 action requiring h. Thus, TR single variable (e) eventeEvents(ALM). TR contains following constraints: (d | Mort2) = (h | Mort2) internalTR-constraint Mort2; (Buy h) = (Buy d) internal TR-constraint Buy; (Buy h)< (h | Mort2) causality TR-constraint h; (d | Mort2) < (Buy d)authorisation TR-constraint, since monotone. set four constraints solution,deduce P solution. example shows temporal relaxation useful even non-temporal planning problems establisher-unique.examples show EU monotone relaxation TR stronger relaxationbased ignoring deletes two reasons: TR uses temporal information, example concerningduration actions, retains destructions fluents. see ignoring deletes strongerEU monotone relaxation, consider problem unique goal g produced uniqueaction Cond(a) = {f} fluent f produced two distinct actions b c.EU monotone relaxation, fluent f deleted Cond(a), since established two distinctactions, relaxed version problem immediately solvable plan containing single468fiMONOTONE TEMPORAL PLANNINGaction a. Ignoring deletes, hand, detect unsolvability original problemcertain cases, example, actions b c instantaneous, b action establishesfluent p Cond(c) \ c action establishes fluent q Cond(b) \ I.obvious application temporal relaxation detection action landmarks followingclassic technique applies valid relaxation (Hoffmann, Porteous & Sebastia, 2004;Cooper, de Roquemaurel & Rgnier, 2011). Let P [-a] represent planning problem P withoutparticular action a. temporal relaxation P [-a] solution, concludeaction landmark P.following sections investigate applications temporal relaxation concerningdetection different forms monotonicity. basic idea H hypothesis testedH expressed conjunction STP constraints, add H constraintstemporal relaxation TR. thus obtain STP instance denote TR[H]: TR[H]solution H cannot true solution planning problem. case, complexitysolving TR[H] O(n3) time O(n2) space, n total number events actions(as already seen proof Theorem 5.7).7. Detecting Monotonicity* Using Temporal Relaxationsubclass instances NP-hard problem generally considered tractable satisfies twoconditions: (1) polynomial-time algorithm solve , (2) polynomial-timealgorithm recognize . clearly polynomial-time detect whether actions establisherunique. hand, general definition monotonicity fluents impliescase determining whether fluents monotone. section show temporalrelaxation used detect monotonicity* certain fluents. Unfortunately, following theorem shows that, general, detection monotonicity* difficult temporal planning.Theorem 7.1. Determining whether fluent temporal planning problem <I,A,G> monotone (ormonotone*) PSPACE-hard overlapping instances action allowed plansEXPSPACE-complete overlapping instances action allowed.Proof: Notice <I,A,G> solution, fluents trivially monotone (and hence monotone*) Definition 4.1, since neither established destroyed plan. sufficientadd two new goal fluents f1, f2 two new instantaneous actions A, a1 simply adds f1 a2f1 condition, adds f2 deletes f1 (a1 a2 independent fluents)problem <I,A,G>: f1 monotone (monotone*) resulting problem temporal plan. theorem follows fact testing existence temporal plantemporal planning problem <I,A,G> PSPACE-hard overlapping instances actionallowed plans EXPSPACE-complete overlapping instances action allowed (Rintanen, 2007).nevertheless detect monotonicity* certain fluents polynomial time. sectiongive rules applied polynomial time. Given Theorem 7.1, clearly claimable detect monotone* fluents rules. set temporal planning problemswhose fluents proved +monotone* monotone* rules given section, re469fiCOOPER, MARIS, & REGNIERquired conditions Theorem 5.7, represents tractable class, since recognizedsolved polynomial time.detect +monotonicity (+monotonicity*) fluent f suffices give proof f cannotdestroyed (minimal) plan established. conference version papergave rules provide proof, based knowledge monotonicity fluents (Cooper,Maris & Rgnier, 2012). turns simpler general proof rule (althoughcomputationally expensive) involves solving STP pair actions a, bf Add(a) Del(b). set actions establisher-unique, one action a. try prove b cannot destroy f establishes f, set relaxation TR[Before(a,f, b)] consisting temporal relaxation TR planning problem together single hypothesis constraint: Before(a, f, b) = { first(a f ) < last(b f )}. consider casepair actions a,b exist (see Lemma 4.3) simply special case rule. Note, however, fact TR[Before(a, f, b)] solution necessary sufficient conditionexistence valid temporal plan b destroys f establishes f. Indeed, Theorem 7.1tells us highly unlikely polynomial-time algorithm exists determining whetherfluent monotone*.detect monotonicity* fluent f need prove f cannot established minimal plan destroyed. corresponding STP TR[After(a, f, b)], hypothesis is: After(a, f, b) = {first(b f ) < last(a f )}. assume setting temporal relaxationTR[Before(a, f, b)] TR[After(a, f, b)] apply rules given previous section identification unitary actions. implies implicitly considering minimal planshence detect monotonicity* rather monotonicity.Lemma 7.2. Suppose set actions EU. TR[Before(a, f, b)] solution pairactions a,b f Add(a) Del(b), f +monotone* relative <I,A,G>.TR[After(a, f, b)] solution pair actions a, b f Add(a) Del(b), fmonotone* relative <I,A,G>.order apply Theorem 5.6, also prove fluents (Cond(Ar) G)monotone* relative <I,Ap,G>. plan problem <I,Ap,G> necessarily includes actionsALM, may may include actions Ap \ ALM. consequence this,impose constraints actions ALM. Indeed, extra hypothesis set actions Apestablisher-unique, corresponding STP identical TR[After(a, f, b)].Lemma 7.3. set actions Ap establisher-unique temporal relaxation TR[After(a, f, b)]solution pair actions a, b Ap f Add(a) Del(b), f monotone*relative <I,Ap,G>.give simple lemma detect certain +monotone* fluents based notion unitaryaction. assume Lemmas 6.3, 6.4 6.5 used detect unitary actions.Lemma 7.4. establisher-unique action aA unitary, fluents f Add(a)(G \(I \Del(ALM))) +monotone* relative temporal planning problem <I,A,G>.470fiMONOTONE TEMPORAL PLANNINGProof: Let f Add(a) (G \ (I \ Del(ALM))) let P minimal plan <I,A,G>. fluentsG\(I \ Del(ALM)) must established P. Thus P must contain instance action a, since establisher-unique. Indeed, since unitary, P contains exactly one instance a. Therefore, f established exactly P, furthermore cannot later destroyed P since f goal fluent. follows f +monotone*.Example 7.5. Consider following simple example planning problem instantaneous actions:Wash_hair: d, cDry_clean_hair: cmeans dry hair c means clean hair, = G = {d,c}. Note impose condition hair must clean dried. fluent monotone since solution plan Wash_hair, Dry_clean_hair, Wash_hair, Dry_clean_hair (in last two actionsclearly redundant) destroys, establishes, destroys re-establishes d, plan clearlyminimal. deduce Lemma 6.4 (case(2)) Dry_clean_hair unitary. Lemma 7.4tells us +monotone* since Add(Dry_clean_hair) (G \(I \ Del(ALM))) = {d}.following theorem follows Theorem 5.7 together fact STPsolved polynomial time. Recall class tractable recognised solved polynomial time.Theorem 7.6. Let 1 class positive temporal planning problems <I,A,G> Constr(Ar) interval constraints, Ar establisher-unique relative SG, fluents Cond(Ar) Gmonotone* relative <I,Ar,G> fluents (Cond(Ar) G) monotone* relative<I,Ap,G>, monotonicity* fluents detected applying Lemmas 7.3 7.4.1 tractable.already seen proof Theorem 5.7 temporal relaxation solvedO(n3) time O(n2) space, n total number events actions A. numbertemporal relaxations solve, order prove temporal planning problem belongs 1,proportional number triples (a, f, b) a, b Ap f Add(a) Del(b). numberpairs ( f, b) b Ap f Del(b) bounded n. Ap establisher-unique,one action Ap f Add(a). Therefore, complexity recognizing1 O(n4) time O(n2) space. conference version paper (Cooper, Maris & Rgnier,2012) gave simple rules used recognize subclass 1 O(n2) time O(n)space.discuss rules detection monotone* fluents. show monotone* fluents detected polynomial time cost greater computational complexity.say action-instance usefully produces fluent h execution plan hfalse established a. say usefully produces required fluent h usefully produces h either h G fluent h condition action c plan(a h) < (h | c). state following general proposition.471fiCOOPER, MARIS, & REGNIERProposition 7.7. Suppose set actions EU relative set sub-goals letunique action establishes sub-goal f. (a) b f Del(b), minimalplan instance b destroys f instance establishes f,instance first establishes f last instance b last destroys f usefully produce required fluents, f +monotone*. (b) b f Del(b), minimalplan instance establishes f instance b destroys f,instance last establishes f instance b first destroys f usefully producerequired fluents, f monotone*.Proof: (a) Let P minimal plan instance b destroys f instanceestablishes f. Then, hypothesis proposition, either instance first establishesf P last instance b last destroys f P usefully produce required fluent.Hence P cannot minimal, since could delete either instance b instance Pleave another valid plan. contradiction shows f +monotone*. proof case (b)similar.give lemma allows us deduce one hypotheses Proposition 7.7hence deduce fluent f +monotone* monotone*. simplify expressionlemma, suppose goal-achieving action aG must executed endplans Cond(aG) = G. simply means goal fluents h need treatedspecial cases.Lemma 7.8. Suppose EU relative set sub-goals SG let unique action establishes fluent f SG. Let b f Del(b).(a) Let h SG Add(a) h SG Add(b). following conditions hold,minimal plan P last destruction f instance b occurs first establishment f instance a, instance b usefully produces required fluent hinstance usefully produces required fluent h:(1) actions c,c h Cond(c), h Cond(c), TR[Before(a,f,b) For(a,first,h,c)For(b,last,h,c)] solution, For(x,L,h,c) = {L(x h) < last(h | c)}.(2) Constr(b) imposes fixed interval destruction f establishment h b,h monotone* actions c,c h Cond(c) h Cond(c), TR[Before(a,f,b)Once(b) For(a,first,h,c) For(b,last,h,c)] solution, Once(x) = {first(E) = last(E)| E Events(x)}.(b) Let h SG Add(a) h SG Add(b). following conditions hold,minimal plan P last establishment f instance occurs first destruction f instance b, instance usefully produces required fluent hinstance b usefully produces required fluent h:(1) actions c,c h Cond(c), h Cond(c), TR[After(a,f,b) For(a,last,h,c)For(b,first,h,c)] solution.(2) Constr(b) imposes fixed interval destruction f establishment h b,h monotone* actions c,c h Cond(c) h Cond(c), TR[After(a,f,b)Once(a) For(a,last,h,c) For(b,first,h,c)] solution.472fiMONOTONE TEMPORAL PLANNINGProof: (a) suppose EU relative SG, f SG Add(a) Del(b), h SG Add(a)h SG Add(b).(1) TR[Before(a,f,b) For(a,first,h,c) For(b,last,h,c)] solution actions c,ch Cond(c), h Cond(c), cannot case minimal plan P first establishment f occurs last destruction f instance b, instancefirst establishes f usefully produces required fluent h P, instance blast destroys f usefully produces required fluent h P.(2) h monotone*, instance b first establishes h usefully produce hP. Since fixed interval destruction f establishment h b,necessarily instance b first destroys f. Since instance b lastdestroys f assumed usefully produce h, deduce instances b synchronised destroy f exactly moment. contradicts Condition (5)Definition 3.2 temporal plan, unless one instance b P. result followsargument case (2) extra constraint Once(b) one instance b P.proof part (b) lemma similar.Example 7.9. Consider following EU temporal planning problem actions instantaneous:Check: p g,Drive: p, a, gTake: g p= {g} G = {a}. One interpretation actions fluents is: Have_Engine_checked(Check), Drive_to_destination (Drive), Take_Petrol (Take), Have_petrol (p), At_garage (g), Engine_OK (o), Arrived (a). fluent g monotone since plan Take, Check, Drive,Check (in last action clearly redundant) establishes, destroys, establishes g.However, g monotone* since minimal plan action Check cannot usefully produce fluenth Add(Check) = {g, o} action Drive destroyed g. case h=g, Lemma7.8(b)(1): Take action g Cond(Take), TR[After(Check,g,Drive)For(Check,last,g, Take)] solution. case h = o, Lemma 7.8(b)(2) sincemonotone* (by Lemma 4.3) TR[After(Check,g,Drive) Once(Check)] solution. Notesince a, p monotone Lemma 4.3, deduce Lemma 6.4 (case (1)) actions DriveTake unitary. follows Lemma 6.4 (case (3)) action Check also unitary.therefore impose TR actions Check, Drive Take occur once; followscould deduced g monotone* directly Lemma 7.2 without use Lemma 7.8.Combining Proposition 7.7 Lemma 7.8 allows us define tractable class temporal planning problems larger class described Theorem 7.6.Theorem 7.10. Let 2 class positive temporal planning problems <I,A,G> Constr(Ar) interval constraints, Ar establisher-unique relative SG, fluents Cond(Ar) Gmonotone* relative <I,Ar,G> fluents (Cond(Ar) G) monotone* relative473fiCOOPER, MARIS, & REGNIER<I,Ap,G>, monotonicity* fluents deduced Proposition 7.7, Lemmas 7.47.8. 2 tractable.number temporal relaxations solve, order prove temporal planning problembelongs 2, proportional number septuples (a,f,b,c,h,c,h) a,b,c,c Ap,f Add(a) Del(b), h Add(a) Cond(c) h Add(b) Cond(c). seen Section 5that, assuming establisher-unique, number triples (a,f,b) satisfying a,b Apf Add(a) Del(b) bounded n, total number events actions A. number pairs (c,h) c Ap h Cond(c) bounded n. Therefore, number relaxations solved O(n3). seen proof Lemma 4.3 temporalrelaxation solved O(n3) time O(n2) space. follows complexity recognizing2 O(n6) time O(n2) space.8. Experiments IPC-2011 Benchmarksconducted experiments benchmark problems temporal deterministic track7th international planning competition IPC-2011, order test applicability proposedtemporal relaxation TR well relative utility various lemmas detection monotonicity*. main drawback temporal relaxation concerns EU fluents (i.e. fluents f single action f Add(a)). Indeed, first step setting TRremove fluents EU goal. goal fluents removed problemsfollowing domains: floortile, matchcellar, parking, pegsol, openstacks, sokoban, storage,turnandopen. therefore concentrated experiments three domains crewplanning,parcprinter, tms. problem domain, let SGp denote set possible sub-goalsoriginal unrelaxed problem. 20 problems domains, determinedset EUSGp possible sub-goals SGp EU. EU possible sub-goalsunrelaxed problem remain possible sub-goals TR, since TR remove fluentsEU conditions actions. calculated set possible sub-goals relaxed problem,call SGp(rel) distinguish set set possible sub-goals SGp unrelaxedproblem. Moreover, calculated set actions produce possible sub-goals relaxedproblem, call Ap(rel) distinguish set Ap unrelaxed problem. first threecolumns Table 8.1 show minimum, mean maximum percentages possible sub-goalsremain possible sub-goals TR (i.e. ratio | SGp(rel) | / | SGp | ) 20 problems.used fluents EUSGp and, particular, ones SGp(rel) test relative frequencymonotonicity*. results SGp(rel) shown next three columns Table 8.1.parcprinter domain, EUSGp fluents detected monotone*. problemcrewplanning domain, almost fluents EUSGp detected monotone*. problemtms domain, 37% fluents EUSGp detected monotone*, 50% SGp(rel).results indicate certain temporal planning problems EU monotone* fluents quitecommon, others TR provide useful information since goals EU.474fiMONOTONE TEMPORAL PLANNINGIPC 2011DomainSGp(rel)Monotone* SGp(rel)Unitary Ap(rel)MIN MEAN MAX MIN MEAN MAX MIN MEAN MAXCrewplanning21%36%94%87%98% 39%56%71%Parcprinter4%8%15% 100% 100% 100% 56%72%94%Tms60%60%60%54%54%50%95%50%50% 54%Table 8.1. Results experiments three domains IPC 2011.last three columns Table 8.1 give number actions Ap(rel) detected unitary TR. identification unitary actions Lemmas 6.3, 6.4 6.5 achieved lineartime provides useful information used TR detection monotonicity*. average, half actions Ap(rel) found unitary.detected monotonicity* applying lemmas increasing order computational complexity: Lemma 4.3, Lemma 7.4, Lemma 7.2, Lemma 7.8. domains, majorityfluents recognised monotone* recognised applying Lemma 4.3, fluents recognised monotone* applying Lemma 7.4 monotone* fluents recognised Lemma 7.2 (which uses temporal relaxation TR). found monotone* fluentsrequired Lemma 7.8 detected. significantly greater complexity applying Lemma 7.8compared Lemma 7.2 means worth applying systematically problems.hand, experiments confirmed Lemmas 4.3, 7.4 7.2 effective detection monotonicity*. Table 8.2 shows three domains, minimum, meanmaximum percentage fluents SGp detected three lemmas.IPC 2011DomainMINCrewplanning MEANMAXMINParcprinterMEANMAXMINTmsMEANMAXLemma 4.380%87%95%88%95%100%29%29%29%Monotone* SGp(rel)Lemma 7.4 Lemma 7.20%0%0%7%0%13%0%0%0%5%0%12%21%0%21%0%21%0%87%95%98%100%100%100%50%50%50%Table 8.2. Percentages fluents detected monotone* three different lemmas.illustrate degree variation different problems within domain, Figures8.3, 8.4 8.5 show details 20 problems three different domains.problem show number monotone* fluents SGp(rel) detected different lemmas.475fiCOOPER, MARIS, & REGNIERFigure 8.3. number fluents SGp(rel) detected monotone* different lemmascrewplanning domain.Figure 8.4. number fluents SGp(rel) detected monotone* different lemmasparcprinter domain.476fiMONOTONE TEMPORAL PLANNINGFigure 8.5. number fluents SGp(rel) detected monotone* different lemmastms domain.general conclusion experimental trials, seen many problems TR provides useful information since goal fluents removed. Nevertheless, identified various benchmark domains applied. fact large percentage fluentsfound monotone* large percentage actions found unitary demonstratespotential importance notions beyond use temporal relaxation TR. experimental trials together investigation specific examples (such Example 7.9 Temporal Cement Factory domain described following section) seem indicate integratingdetection unitary actions TR provides much information computationally expensive approach Lemma 7.8.9. Examples Applications EU Monotone Planningpreviously shown EU monotone planning potential applications various industrial settings, construction chemical pharmaceutical industries (Cooper, Maris &Rgnier, 2012, 2013b). example, Temporal Chemical Process domain, described detailCooper, Maris Rgnier (2013b), involves different kinds operations chemicals performed industrial production compounds. raw material, operatoractivate source. Then, raw material catalysed different ways synthesize differentproducts. products mixed reacted using raw material producedesired compound. example, acetylene raw material derived calcium carbide using water. Then, vinyl chloride monomer produced acetylene hydrogen chloride using mercuricchloride catalyst. PVC produced polymerization. examples occur pharmaceutical industry production drugs (such paracetamol ibuprofen) and, general,many processes requiring production combination several molecules, givenunique way obtain (which often case due industrial constraints).477fiCOOPER, MARIS, & REGNIERgive detail example construction industry show detection unitary actions greatly speed recognition problems. Temporal Cement Factoryplanning domain (Cooper, Maris & Rgnier, 2013b) allows us plan concrete mixing, deliveryuse. action duration 30 time units makes times batch concrete fluid timeunit 3 30 (after sets). time, concrete-mixer must cleaned, orderconcrete loaded, driven building site, unloaded. concrete mustused still fluid. process illustrated temporal plan given Figure 5. setactions (illustrated temporal plan shown Figure 5) landmarks. initial stategoal G given= {At-factory(m), Available(c)}G = {Delivered(m,c,s), Used(c)}Given temporal planning problem <I,A,G>, set actions TemporalCement Factory domain, set sub-goals SG reduced set actions Ar are:SG = {Delivered(m,c,s), Used(c), Fluid(c), At(m,s), Available(c),On(m,c), At-factory(m), Empty(m)}Ar = {USE(c), UNLOAD(m,c,s), DRIVE(m,s), LOAD(m,c), CLEAN(m), MAKEAND-TIME-CONCRETE(c)}ai aj A, Add(ai) Add(aj) SG = . Hence, Definition 3.3, set actions EU relative SG. immediately remark actions delete fluents Used(c),Delivered(m,c,s) At(m,s), actions add fluents Available(c) Atfactory(m). Thus, Lemma 4.3, fluents monotone +monotone relative <I,A,G>. Lemma 7.2, deduce On(m,c) monotone since temporal relaxation TR[After(LOAD(m,c),On(m,c),UNLOAD(m,c,s))] solution. similar argument,Fluid(c) also monotone Lemma 7.2.Available(c)MAKE-AND-TIME-CONCRETE(c)[30]Available(c)Fluid(c)Fluid(c)At-factory(m)At-factory(m)DRIVE(m,s)[6]CLEAN(m)[4]At(m,s)At-factory(m)Empty(m)Fluid(c)Empty(m)At-factory(m)At(m,s)On(m,c)LOAD(m,c)[5]Empty(m)Delivered(m,c,s)Fluid(c)Fluid(c)USE(c)[4]UNLOAD(m,c,s)[7]On(m,c)On(m,c)Used(c)Delivered(m,c,s)Figure 5: Ready-mix Concrete Delivery Temporal Plandetect unitary actions. Lemma 6.4 (case (1)), deduceUNLOAD(m,c,s) unitary. Then, applying Lemma 6.4 (case (3)), h = On(m,c) b =478fiMONOTONE TEMPORAL PLANNINGUNLOAD(m,c,s), tells us LOAD(m,c) unitary. Finally, applying Lemma 6.4 (case (3)), h= Empty(m) b = LOAD(m,c), tells us CLEAN(m) unitary. Since CLEAN(m) unitary,effectively add constraint Once(CLEAN(m)) TR constraint Lemma 7.2 sufficient detect Empty(m) monotone*. Thus, using new notion unitary actionlinear-time rules detect actions given Section 6, prove monotonicity* fluentswithout needing use computationally expensive Lemma 7.8 previously proposed (Cooper,Maris & Rgnier, 2013b).possible apply Theorem 5.6, since EU, fluents monotone* fluentsmonotone*. follows TR solution procedure problem. problem <I,A,G>solution-plan, found TR, shown Figure 5. represent non-instantaneous actionsrectangle. Conditions written action, effects below; causality constraints represented bold arrows, authorisation constraints dotted arrows.example extended generic case several sites, several batchesconcrete several mixers. monotone remains EU provided goals (via fluentsDelivered(m,c,s)) specify mixer deliver batch c building site s.instances solved polynomial time Theorem 7.10.10. Discussionresults paper also applied non-temporal planning since, example, classical STRIPS planning problem modelled temporal planning problem actionsinstantaneous. worth pointing tractable class classical planning problemsactions establisher-unique fluents detectable (both + ) monotoneapplying Lemma 4.3, covered PA tractable class Jonsson Bckstrm (1998).obvious question whether establisher-uniqueness monotonicity necessary obtain tractability. affirmative answer question follows intractability results nontemporal planning: Bckstrm Klein (1991b) showed establisher-uniqueness alone cannotprevent minimal plans exponential size, Jonsson Bckstrm (1998) showed conditions implying monotonicity fluents (the class BA terminology), planningNP-hard.+simplicity presentation conformity PDDL2.1, considered inherentconstraints times events within action-instance interval constraints.can, however, remark Theorem 5.6 still holds inherent constraints arbitrary minclosed constraints, since property required constraints proof Theorem5.6. example constraint C(x,y) binary interval constraint variable bounds:yx [f(x,y),g(x,y)], min-closed provided f(x,y) monotone increasing function xg(x,y) monotone decreasing function y. shift-monotonic constraints used PraletVerfaillie (2012) scheduling agile satellites subclass constraints since shiftmonotonic constraints f(x,y) g(x,y) monotone increasing functions x monotonedecreasing functions y. consistency set shift-monotonic constraints tested timeO(n3).479fiCOOPER, MARIS, & REGNIERimportant aspect temporal planning, absent non-temporal planning, certain temporal planning problems, known temporally-expressive problems, require concurrencyactions order solved (Cushing, Kambhampati, Mausam & Weld, 2007). cement factoryplanning problem given Section 9 example temporally-expressive problem, since concurrency actions required solution. Indeed, industrial environments, concurrency actionsoften used keep storage space turn-around times within given limits. previous paper(Cooper, Maris & Rgnier, 2013a), identified subclass temporally expressive problems,known temporally-cyclic, require cyclically-dependent sets actions order solved.simple commonly occurring example given Figure 4, concerning agreementemployer employee. tractable class temporal planning problems described Theorem7.6 contains temporally-expressive temporally-cyclic problems. example, temporally-cyclic problem given Figure 4 establisher-unique fluents + monotone(this follows Lemma 4.3 since fluents destroyed either action).temporal planning problems fall tractable class EU monotone problems.Even so, may certain sub-problems fall class. Given temporal planning problem<I,A,G>, test polynomial time, fluent f, whether sub-problem <I,A,{f}> satisfiesconditions Theorem 7.6 (i.e. EU monotone, monotonicity detectable using temporalrelaxation TR). case, find polynomial time plan Pf establishesfluent f. plan Pf considered action could added set actionsorder facilitate solution original problem <I,A,G>.work related literature regarding landmarks. Porteous, Sebastia Hoffmann (2001)Keyder, Richter Helmert (2010) define landmark fact must true pointevery valid solution-plan. Landmarks used planning two main ways. first oneconception heuristic functions guide search algorithms (Richter, Helmert & Westphal, 2008;Richter & Westphal, 2010; Helmert & Domshlak, 2009). Another use landmarks partitionproblem easier subproblems whose goals disjunctions landmarks (Hoffmann, Porteous &Sebastia, 2004; Sebastia, Onaindia & Marzal, 2006). recently, Vernhes, Infantes Vidal(2013) define landmark-based meta best-first search algorithm.Landmarks also used detection unsolvable temporal planning problems (Marzal, Sebastia & Onaindia, 2008). graph built adding causal relationships extractedlandmarks. temporal intervals associated landmark intervals, togethercausal relationships, define set constraints. Finally, CSP solver checks consistencyset indicates problem solution inconsistency found. Unlikeset constraints temporal relaxation TR, set constraints fall tractableclass. research required determine whether certain constraints could usefullycombined STP constraints temporal relaxation TR obtain even stronger tractablerelaxation.general case, verifying fact landmark PSPACE-complete (Hoffmann, Porteous& Sebastia, 2004). However, landmarks found efficiently using various techniques: Porteous Cresswell (2002) Hoffmann, Porteous Sebastia (2004) present methodsdetecting landmarks relations landmarks based backchaining goalsrelaxed planning graph, whereas Zhu Givan (2003) use forward propagation graphRichter, Helmert Westphal (2008) use domain transition graph, graph whose nodes480fiMONOTONE TEMPORAL PLANNINGrepresent possible values variable edges represent possible transitions values induced actions.notion monotonicity* introduced paper depends relative order establishment destruction fluent within minimal plan. experiments demonstrated many fluents benchmark problems indeed monotone*. interesting avenue future research would investigate, theoretically empirically, relative order establishment destruction different fluents within minimal temporal plan.closely related research landmarks. Different orderings landmarks studiednon-temporal planning. orderings guaranteed hold every solution-planprune solution space (they sound): "Natural" (Koehler & Hoffmann, 2000), "Necessary""Greedy-necessary" (Hoffmann, Porteous & Sebastia, 2004). natural orderinggeneral greedy-necessary ordering necessary ordering. Others orderings "Reasonable", "Obedient-Reasonable" (Koehler & Hoffmann, 2000) sound (it possiblesolution-plan respects orderings) may prune solution space. orderings landmarks defined assuming instantaneous actions would need redefinedtemporal framework. research required determine whether landmark orderings could usefully extended incorporate orderings types events temporal plans (the establishment destruction fluent action landmark, beginning end intervalfluent required action landmark).11. Conclusionpresented class temporal planning problems solved polynomial timenumber possible applications, notably chemical, pharmaceutical construction industries. notion monotonicity temporal planning essential part definition class. extended basic notion monotonicity monotonicity* consideringminimal plans.also shown planning problems relaxation based EU monotone planninginteresting alternative standard relaxation produced ignoring deletes. also provides means detecting action landmarks monotone* fluents.research required discover possible application areas and, practical level,develop tools help users find model problem involving monotone* fluentsmodel exists. theoretical level, interesting avenue future research extensiontractable classes presented paper relaxing condition establisher-uniquenessfluent established one action provided one action establish given moment.Acknowledgementsresearch supported ANR Project ANR-10-BLAN-0210. gratefully acknowledgehelp reviewers whose constructive suggestions led significant improvementspresentation paper.481fiCOOPER, MARIS, & REGNIERReferencesBckstrm C. & Klein I. (1991a) Parallel non-binary planning polynomial time. ProceedingsIJCAI1991, 268-273.Bckstrm C. & Klein I. (1991b) Planning polynomial time: SAS-PUBS class,Computational Intelligence 7 (3), 181-197.Bckstrm C. & Nebel B. (1995) Complexity results SAS+ planning. ComputationalIntelligence 11(4), 625-655.Baier J. A. & Botea A. (2009). Improving planning performance using low-conflict relaxed plans.Proc. 19th International Conference Automated Planning Scheduling (ICAPS2009).Betz C. & Helmert M. (2009). Planning h+ Theory Practice. KI 2009: AdvancesArtificial Intelligence, LNCS Vol. 5803, 9-16.Blum A.L. & Furst M.L. (1995) A.L. Blum, M.L. Furst, Fast planning planning-graphsanalysis, in: Proceedings 14th International Joint Conference Artificial Intelligence(IJCAI-95), Montral, Qubec, Canada, 1636-1642.Bonet B., Loerincs G. & Geffner H. (1997) Robust Fast Action Selection MechanismPlanning, Proceedings AAAI-97/IAAI-97, 714-719.Brafman R.I. & Domshlak C. (2003) Structure Complexity Planning UnaryOperators. Journal Artificial Intelligence Research 18, 315-349.Brafman R.I. & Domshlak C. (2006) Factored Planning: How, When, Not. Proc. 21stNational Conference Artificial Intelligence, 809-814.Bylander T. (1994) Computational Complexity Propositional STRIPS Planning. ArtificialIntelligence 69(1-2), 165-204.Cai D., Hoffmann J. & Helmert M. (2009). Enhancing context-enhanced additive heuristicprecedence constraints. Proc. 19th International Conference Automated PlanningScheduling (ICAPS2009), 5057.Chen H. & Gimnez O. (2008) Causal Graphs Structurally Restricted Planning. Proc. 18thInternational Conference Automated Planning Scheduling (ICAPS2008), 36-43.Coles A., Fox M., Long D. & Smith A. (2008) Planning Problems Requiring TemporalCoordination, Proc. AAAI 2008, 892-897.Cooper M.C., de Roquemaurel M. & Rgnier, P. (2011) weighted CSP approach costoptimal planning, Artificial Intelligence Communications 24(1), 1-29.Cooper M.C., Maris F. & Rgnier P. (2010) Solving temporally cyclic planning problems,International Symposium Temporal Representation Reasoning (TIME), 113-120.Cooper M.C., Maris F. & Rgnier, P. (2012) Tractable monotone temporal planning, ProceedingsICAPS 2012, 20-28.Cooper M.C., Maris F. & Rgnier, P. (2013a) Managing Temporal Cycles Planning ProblemsRequiring Concurrency, Computational Intelligence 29(1), 111-128.Cooper M.C., Maris F. & Rgnier P. (2013b) Relaxation Temporal Planning Problems,International Symposium Temporal Representation Reasoning (TIME), 37-44.Cushing W., Kambhampati S., Mausam & Weld D.S. (2007) Temporal Planning ReallyTemporal? Proceedings 20th International Joint Conference Artificial Intelligence,IJCAI2007, 1852-1859.Dean T., Firby J. & Miller D. (1988) Hierarchical Planning involving deadlines, travel timeressources. Computational Intelligence 6(1), 381-398.482fiMONOTONE TEMPORAL PLANNINGDean T. & McDermott D.V. (1987) Temporal Data Base Management. Artificial Intelligence32(1), 1-55.Dechter R., Meiri I. & Pearl J. (1991) Temporal Constraint Networks, Artificial Intelligence 49(13), 61-95.M.B. & Kambhampati S. (2003) Sapa: Multi-objective Metric Temporal Planner, JournalArtificial Intelligence Research 20, 155-194.Domshlak C. & Dinitz Y. (2001) Multi-agent off-line coordination: Structure complexity.Proceedings 6th European Conference Planning, ECP2001, 277-288.Erol K., Nau D.S. & Subrahmanian V.S. (1995) Complexity, decidability undecidabilityresults domain-independent planning. Artificial Intelligence 76(1-2), 75-88.Eyerich P., Mattmller R. & Rger G. (2009) Using Context-enhanced Additive HeuristicTemporal Numeric Planning, Proceedings ICAPS 2009, 130-137.Fox, M. & Long, D. (2001). Stan4: hybrid planning strategy based subproblem abstraction.AI Magazine 22(3), 8184.Fox M. & Long D. (2003) PDDL2.1: Extension PDDL Expressing Temporal PlanningDomains, Journal Artificial Intelligence Research 20, 61-124.Fox M., Long D. & Halsey K. (2004). Investigation Expressive Power PDDL2.1,Proc. 16th European Conference Artificial Intelligence, 328-342.Gerevini A. & Cristani M. (1997) Finding Solution Temporal Constraint SatisfactionProblems. Proc. 15th International Joint Conference Artificial Intelligence, 1460-1465.Gerevini, A., Saetti, A. & Serina, I. (2003). Planning stochastic local search temporalaction graphs. Journal Artificial Intelligence Research 20, 239290.Ghallab M. & Alaoui A.M. (1989) Managing Efficiently Temporal Relations IndexedSpanning Trees. Proc. 11th Int. Joint Conference Artificial Intelligence, 1297-1303.Ghallab M., Nau D.S. & Traverso P. (2004) Automated Planning: Theory Practice, MorganKaufmann.Gimnez O. & Jonsson A. (2008) complexity planning problems simple causalgraphs. Journal Artificial Intelligence Research 31, 319-351.Gimnez O. & Jonsson A. (2012). influence k-dependence complexity planning.Artificial Intelligence 177-179, 25-45.Haslum P. (2008) New Approach Tractable Planning. Proceedings ICAPS2008, 132139.Haslum P., Slaney J. & Thibaux S. (2012). Incremental lower bounds additive cost planningproblems. Proc. 22nd International Conference Automated Planning Scheduling(ICAPS2012), 7482.Helmert M. (2003) Complexity results standard benchmark domains planning. ArtificialIntelligence 143 (2), 219-262.Helmert M. (2004). planning heuristic based causal graph analysis. Proc. 14th InternationalConference Automated Planning Scheduling (ICAPS2004), 161170.Helmert M. (2006) New Complexity Results Classical Planning Benchmarks. Proc. 16thInternational Conference Automated Planning Scheduling (ICAPS2006), 52-61.Helmert M. & Geffner H. (2008). Unifying causal graph additive heuristics. Proc. 18thInternational Conference Automated Planning Scheduling (ICAPS2008), 140147.Helmert M. & Domshlak C. (2009) Landmarks, Critical Paths Abstractions: WhatsDifference Anyway? Proc. International Conference Automated Planning Scheduling(ICAPS 2009), 162-169.483fiCOOPER, MARIS, & REGNIERHoffmann J. (2005) Ignoring Delete Lists Works, Local Search Topology PlanningBenchmarks. Journal Artificial Intelligence Research 24, 685-758.Hoffmann J., Porteous J. & Sebastia L. (2004) Ordered Landmarks Planning. JournalArtificial Intelligence Research 22, 215278.Jeavons P. & Cooper M.C. (1995) Tractable constraints ordered domains, ArtificialIntelligence 79, 327-339.Jonsson A. (2007) Role Macros Tractable Planning Causal Graphs. Proc. 20thInternational Joint Conference Artificial Intelligence (IJCAI2007), 1936-1941.Jonsson A. (2009) Role Macros Tractable Planning. Journal Artificial IntelligenceResearch 36, 471-511.Jonsson P. & Bckstrm C. (1994) Tractable planning state variables exploiting structuralrestrictions. Proc. AAAI1994, 998-1003.Jonsson P. & Bckstrm C. (1995) Incremental Planning. New Directions AI Planning: 3rdEuropean Workshop Planning, EWSP1995, 79-90.Jonsson P. & Bckstrm C. (1998) State-variable planning structural restrictions:Algorithms complexity. Artificial Intelligence 100(1-2), 125-176.Karmarkar N. (1984) new polynomial time algorithm linear programming. Combinatorica 4(4) 373395.Karpas E. & Domshlak C. (2009) Cost-optimal planning landmarks, International JointConference Artificial Intelligence (IJCAI2009), 17281733.Katz M. & Domshlak C. (2008) New Islands Tractability Cost-Optimal Planning. JournalArtificial Intelligence Research 32, 203-288.Katz M., Hoffmann J. & Domshlak C. (2013a). said need relax variables? Proc.23rd International Conference Automated Planning Scheduling, (ICAPS2013).Katz M., Hoffmann J. & Domshlak C. (2013b). Red-Black Relaxed Plan Heuristics. Proc. 27thAAAI Conference Artificial Intelligence (AAAI2013).Keyder E. & Geffner H. (2008). Heuristics planning action costs revisited. Proc. 18thEuropean Conference Artificial Intelligence (ECAI2008), 588592.Keyder E., Hoffmann J. & Haslum P. (2012) Semi-Relaxed Plan Heuristics, Proc. 22ndInternational Conference Automated Planning Scheduling, ICAPS2012, 128-136.Keyder E., Richter S. & Helmert M. (2010) Sound Complete Landmarks And/Or Graphs.Proceedings European Conference Artificial Intelligence (ECAI), 335-340.Knoblock C.A. (1994) Automatically Generating Abstractions Planning. Artificial Intelligence68(2), 243-302.Koehler J. & Hoffmann J. (2000) reasonable forced goal orderings useagenda-driven planning algorithm. Journal Artificial Intelligence Research 12, 338386.Koubarakis M. (1992) Dense Time Temporal Constraints . Proc. 3rd InternationalConference Principles Knowledge Representation Reasoning (KR1992), 24-35.Laborie P. & Ghallab M. (1995) Planning Sharable Resource Constraints. Proc. 14thInternational Joint Conference Artificial Intelligence, 1643-1651.Long D. & Fox M. (2003) Exploiting graphplan framework temporal planning, Proc. 13thInternational Conference Automatic Planning Scheduling, 52-61.Maris F. & Rgnier P. (2008) TLP-GP: Solving Temporally-Expressive Planning Problems,TIME 2008, 137-144.484fiMONOTONE TEMPORAL PLANNINGMarzal E., Sebastia L. & Onaindia E. (2008) Detection unsolvable temporal planning problemsuse landmarks. Proceedings ECAI2008. 919-920.McDermott D. (1998) PDDL, Planning Domain Definition Language. Technical Report,http://cs-www.cs.yale.edu/ homes/dvm/.Porteous J. & Cresswell S. (2002) Extending landmarks analysis reason resourcesrepetition. Proceedings PLANSIG2002, 4554.Porteous J., Sebastia L. & Hoffmann J. (2001) Extraction, Ordering, UsageLandmarks Planning. Recent Advances AI Planning. European Conference Planning(ECP 2001), 3748.Pralet C. & Verfaillie G (2012) Time-Dependent Simple Temporal Networks, Proc. 18thInternational Conference Principles Practice Constraint Programming, 608-623.Reichgelt H. & Shadbolt N. (1990). Specification Tool Planning Systems. Proc. 9thEuropean Conference Artificial Intelligence, 541-546.Richter S., Helmert M. & Westphal M. (2008) Landmarks revisited. Proc. 23rd AAAI ConferenceArtificial Intelligence (AAAI'08). 975-982.Richter S. & Westphal M. (2010) LAMA Planner: Guiding Cost-Based Anytime PlanningLandmarks. Journal Artificial Intelligence Research (JAIR) 39: 127-177.Rintanen J. (2007) Complexity Concurrent Temporal Planning. Proc. 17th InternationalConference Automated Planning Scheduling (ICAPS2007), 280-287.Rutten E. & Hertzberg J. (1993) Temporal Planner = Nonlinear Planner + Time Map Manager.Artificial Intelligence Communications 6(1), 18-26.Schwartz P. & Pollack M.E. (2004) Planning Disjunctive Temporal Constraints. Proc.ICAPS'04 Workshop Integrating Planning Scheduling, 67-74.Sebastia L., Onaindia E. & Marzal E., (2006) Decomposition planning problems. AICommunications 19:4981.Shin J. & Davis E. (2004) Continuous Time SAT-Based Planner. Proc. 19th NationalConference Artificial Intelligence (AAAI'04), 531-536.Slaney J. & Thibaux S. (2001) Blocks World revisited. Artificial Intelligence 125, 119-153.Smith D.E. (2003) Case Durative Actions: Commentary PDDL2.1, JournalArtificial Intelligence Research 20, 149-154.Stergiou K. & Koubarakis M. (2000) Backtracking algorithms disjunctions temporalconstraints. Artificial Intelligence 120(1):81117.Vere S. (1983) Planning Time: Windows Durations Activities Goals. IEEE Trans.Pattern Analysis Machine Intelligence 5, 246-267.Vernhes S., Infantes G. & V. Vidal V. (2013) Problem Splitting using Heuristic SearchLandmark Orderings. Proc. 23rd International Joint Conference Artificial Intelligence(IJCAI2013), 2401-2407.Vidal V. & Geffner H. (2005) Solving Simple Planning Problems InferenceSearch. Proc. 11th International Conference Principles Practice ConstraintProgramming, CP'05, 682-696.Williams B.C. & Nayak P. (1997) reactive planner model-based executive. Proc. 15thInternational Joint Conference Artificial Intelligence, 1178-1185.Younes H.L.S. & Simmons R.G. (2003) VHPOP: Versatile Heuristic Partial Order Planner.Journal Artificial Intelligence Research 20, 405-430.Zhu L. & Givan R. (2003) Landmark extraction via planning graph propagation. ICAPS2003Doctoral Consortium, 156160.485fiJournal Artificial Intelligence Research 50 (2014) 265-319Submitted 10/13; published 06/14Property Directed Reachability Automated PlanningMartin Sudasuda@mpi-inf.mpg.deMax-Planck-Institut fur Informatik,Saarbrucken, GermanyCharles University, Prague, Czech RepublicAbstractProperty Directed Reachability (PDR) promising recent method decidingreachability symbolically represented transition systems. originally conceivedmodel checking algorithm hardware circuits, already successfully appliedseveral areas. paper first investigation PDR perspectiveautomated planning.Similarly planning satisfiability paradigm, PDR draws strength internally employing efficient SAT-solver. show standard encoding schemesplanning SAT directly used turn PDR planning algorithm.non-obvious alternative, propose replace SAT-solver inside PDR planningspecific procedure implementing interface. SAT-solver free variantefficient, offers additional insights opportunities improvements.experimental comparison state art planners finds highly competitive,solving problems several domains.1. IntroductionProperty Directed Reachability (PDR), also known IC3, recently proposed algorithmdeciding reachability symbolically represented transition systems (Bradley, 2011; Een,Mishchenko, & Brayton, 2011).1 Since discovery 2010, already establishedone strongest model checking algorithms used hardware verification.original inspiring way PDR harnesses power modern SAT-solvergives algorithm unique ability discover long counterexample paths combinedremarkable performance proving unreachability. interesting traits includetypically small memory footprint good potential parallelization.awareness well-known equivalence model checking automatedplanning, aim work investigate PDR planning perspective.main goal establish whether practical success algorithm repeatedplanning benchmarks. Moreover, also interested relation PDRcurrently used planning techniques. illustrative highlighting interestingfeatures algorithm start preliminary comparison right away.fact PDR builds upon SAT-solving technology makes obviously relatedplanning satisfiability approach (Kautz & Selman, 1996). planningsatisfiability underlying SAT-solver receives formulas increasing size methodprogresses check existence increasingly longer plans, PDR SAT-solver call1. IC3 name Aaron Bradley, originator algorithm, gave first implementation (Bradley,2011). descriptive name Property Directed Reachability coined Een et al. (2011).c2014AI Access Foundation. rights reserved.fiSudacorresponds single step transition system. algorithmsometimes said operate without unrolling. Dealing formulas fixed signaturelifts computational burden SAT-solver, making respondreliable way.Similarly planning satisfiability, PDR proceeds iteratively, gradually disprovingexistence plans length 0, 1, 2,. . . . Due so-called obligation rescheduling technique,however, PDR discover plan length l already iteration k < l, is,existence shorter plans necessarily ruled yet. typically leadsimproved performance, allows algorithm avoid completing potentiallyexpensive non-existence proofs. similar effect achieved planning satisfiability approach running several SAT-solvers parallel interleaved (Rintanen, 2004).modification, however, requires non-trivial engineering effort resultingsystem contains parameters need tuned problem hand. contrast,rescheduling PDR amounts literally one-line change algorithm.line disabled, PDR resorts expensive search optimal length plan.Surprisingly, PDR also naturally compared explicit heuristic search planning (Bonet & Geffner, 2001). Indeed, PDR probably best understood hybridexplicit symbolic approaches. satisfying assignment PDRbuilt systematically, one transition time, finished part corresponds explicit path transition system last piece state expanded next.time, PDR maintains symbolic reachability information form sequencesets clauses. k-th set sequence over-approximates k-fold preimageset goal states. clause sets play role similar admissible heuristic.represent lower bound estimate distance state goal thus providemeans guide search towards it. However, heuristic value particular statenormally computed remains constant search plan,clause sets PDR refined continually. refinement happens demand, drivenstates encountered search.1.1 Paper Overvieworder apply PDR planning problem, problem processedsuitable form. Section 2 introduce symbolic transition system, descriptionreachability task based clausal language propositional logic, servesgeneric input PDR. observe standard encoding schemes planningSAT provide us description. means general implementationalgorithm, describe detail Section 3, combined encodingalready yields stand-alone planner. is, however, efficient path take.main contribution paper presented Section 4. show insteadrelying encoding general purpose SAT-solver, can, least casesequential plan semantics, delegate single step reachability queries planning-specificprocedure. gain polynomial time guarantee answering individualqueries, decoupling PDR underlying SAT-solver also gain additionalinsights ideas improvements.266fiProperty Directed Reachability Automated Planningimplemented proposed idea new planner PDRplan. Section 5 experimentally confirm efficient standard PDR combined encodings.also evaluate practical impact various improvements, compare successful configuration PDRplan state art planners encouraging results.Section 6 returns related work uncovers perhaps surprising connectionPDR Graphplan algorithm Blum Furst (1997). Finally, Section 7 usesexamples behavior PDR two classical planning domains discuss possibilitiesfuture extensions algorithm Section 8 concludes.2. Preliminariessection build necessary background explaining PDR. recallingbasic notions propositional logic fixing notation, introduce symbolic transitionsystems, serve canonical input algorithm. observe encodingpart well-known planning satisfiability paradigm seen translate givenplanning problem symbolic transition system. means combiningencoding PDR one already obtains standalone planner.2.1 Propositional Logicsignature finite set propositional variables. Formulas built variablesusing propositional connectives negation , conjunction , disjunction , implication . Given formula F denote Vars(F ) set variables actuallyoccurring F (i.e. Vars(F ) ). literal l either variable p negation p.first case, literal called positive. define complement l literal lp l = p, p l = p. Also contexts, double negations silentlyreduced away.consistent conjunction literals referred cube disjunction clause.cube r full Vars(r) = . describing algorithms, advantageous treatcubes clauses simply sets literals leave interpretation followcontext. Then, complementing cube r obtain clause r = {l | l r}also vice versa. call clause positive literals positive. clause c saidsubsume another clause c d. usual, sets clauses stand conjunction.semantics propositional logic built around notion assignment,mapping : {0, 1} signature truth values {0, 1}. write|= F assignment satisfies formula F . formula F called satisfiableassignment satisfies it, called valid F satisfiable. Assignmentsnaturally correspond full cubes: Given assignment define full cubeLits(s) = {p | p s(p) = 1} {p | p s(p) = 0}.exactly one assignment, namely s, satisfies Lits(s).2.2 Encoding Discrete Timereasoning systems evolve time, use basic signature ={p, q, . . .} describe current state system introduce disjoint copy267fiSudadenoted 0 = {p0 , q 0 , . . .} represent state system one step. Similarly,copies 00 , 000 , . . . (also written (2) , (3) , . . .) stand statesfuture. priming notation extended formulas assignments following way.F 0 denote formula obtained formula F priming every variable occurringF . assignment : {0, 1}, denote s0 : 0 {0, 1} assignmentbehaves primed symbols unprimed ones, i.e., s0 (p0 ) = s(p) everyp . two assignments , let (s, t0 ) denote joint assignment(s t0 ) : 0 {0, 1}. means(s(p)(s, t0 )(x) =t(p)x = p ,x = p0 0 .assignment gives truth value formulas joint signature 0 .2.3 Symbolic Transition Systemssymbolic transition system (STS) tuple = (, I, G, ), signature, I,called initial formula, G, goal formula, sets clauses , ,transition formula, set clauses 0 . STS symbolically representsexplicit transition system TS = (S, SI , SG , RT ), describe next. Noticesymbolic representation exponentially succinct explicit system.explicit transition system TS consistsset states S, identified set assignments := {s | : {0, 1}},subset SI initial states, states satisfy initial formula:SI = {s | |= I},subset SG goal states, states satisfy goal formula:SG = {s | |= G},transition relation RT pairs states (also called transitions)jointly satisfy transition formula:RT = {(s, t) | s, (s, t0 ) |= }.path TS finite sequence s0 , . . . , sk states (sj , sj+1 ) RT everyj = 0, . . . k 1. interested existence paths connecting initial stategoal state. say STS satisfiable path s0 , . . . , sk TSs0 SI sk SG . simplicity, call path witnessing path S.268fiProperty Directed Reachability Automated PlanningSISGbbbbs01 = {p 7 0, q 7 1}s00 = {p 7 0, q 7 0}s11 = {p 7 1, q 7 1}s10 = {p 7 1, q 7 0}Figure 1: explicit transition system TS represented STS Example 1.four states correspond four assignments signature = {p, q}.Example 1. Consider STS = (, I, G, ), = {p, q}, = {p}, G = {p, q},= {p p0 q 0 , p q p0 , p q q 0 , p q p0 , q p0 q 0 }.Notice prefer formula notation (as opposed set notation) concreteclauses. means consist one G two unit clauses, i.e. clausessingle literal. corresponding explicit transition system TS shown Figure 1.path s00 , s01 , s10 , s11 example witnessing path S. STS satisfiable.useful notice definition STS symmetrical following sense.Given STS = (, I, G, ) inverted STS defined 1 = (, G, I, 1 ),1 obtained simultaneously removing primes occurrencesprimed variables adding primes occurrences originally unprimed variables.corresponds, explicit side, exchanging initial goal states invertingdirection transitions. Therefore, STS satisfiable 1 is.Moreover, witnessing path recovered witnessing path 1 (alsovice versa) reading respective sequence backwards.2.4 Propositional STRIPS Planningpaper work planning problems described STRIPS planning formalism. Similarly states transition systems, states world STRIPS planningidentified propositional assignments. propositional variables encoding statecontext called state variables denote set X.action determined tuple = (pre , eff ), pre , called preconditionlist, eff , effect list, cubes X, i.e. consistent conjunctive sets literals.action applicable state |= pre . case applying actionresults successor state = apply(s, a), unique state satisfieseff every p X occurring eff t(p) = s(p). degenerate actionempty precondition effect lists called noop action. applicable statecorresponding successor identical original state: apply(s, noop) = s.STRIPS planning problem tuple P = (X, sI , g, A), X set statevariables, sI initial state, g goal condition form cube X,set actions. plan P finite sequence a1 , . . . , ak actionsstates s0 , . . . , sk satisfying following conditions:269fiSudas0 = sI ,aj applicable sj1 j = 1, . . . , k,sj = apply(sj1 , aj ) j = 1, . . . , k,sk |= g.Notice empty sequence plan P sI |= g.2.5 Planning Satisfiabilitybasic idea behind planning satisfiability paradigm (Kautz & Selman, 1992, 1996)follows. Given planning problem P define sequence propositional formulasF0 , F1 , . . . plan P formula Fi satisfiablei. individual formulas Fi iteratively checked using SAT-solversatisfiable Fi found, plan recovered corresponding satisfying assignment.concrete form formulas sequence dictated encoding scheme(see, e.g., Kautz, McAllester, & Selman, 1996; Rintanen, Heljanko, & Niemela, 2006; Huang,Chen, & Zhang, 2012). encoding schemes simple structure capturedSTS = (, I, G, ), individual formulas Fi obtainedFi = (0) (1) . . . (i1) G(i) .(1)Note use priming notation described Section 2.2 thus (0) standsformula , (1)formula 0 , etc. resulting formula (1)Fi , signature j=0,...,i (i) , expresses existence witnessing pathlength i. encoding scheme uses called sequential plan semantics,witnessing path also directly corresponds plan length i. equivalent sayingtransition relation encoded allows application single action onestep. Parallel plan semantics allow multiple actions applied one time step.leads compact representation potentially faster discovery plans. Additionalconditions parallel actions need imposed, however, guarantee truesequential plan recovered end (see Rintanen et al., 2006, details).2.6 Two Simple Encodingsclose section introducing two example encodings STRIPS planning problemP = (X, sI , g, A) STS. perhaps simplest representatives encodingschemes sequential parallel plan semantics, respectively. later refertheoretical considerations.transition systems SPseq SPpar corresponding two encodings share severalbuilding blocks. Let signature consist state variables X union setfresh auxiliary variables = {pa | A} used encoding applied actions. Further,let us identify initial formula cube Lits(sI ) define goal formula Greinterpreting goal condition g, formally cube, set unit clausesG = {{l} | l g}. action mechanics encodings captured followingaction precondition axioms AP action effect axioms AE :AE = {pa l0 | A, l eff }.AP = {pa l | A, l pre },270fiProperty Directed Reachability Automated Planningencodings differ formalize preserving part actions semantics.sequential encoding SPseq relies called classical frame axiomsCF (McCarthyW& Hayes, 1969) complemented single at-least-one axiom alo = aA pa :CF = {pa l l0 | A, l literal X l 6 eff l 6 eff }.Putting together, obtain SPseq = (, I, G, seq ), seq = AP AE CF alo.Note at-least-one axiom needed, without transition arbitrarystate would possible state action applied, i.e. state pafalse every A. hand, classical frame axioms ensure twoactions applied together state effects must identical. Thus extracting(sequential) plan witnessing path SPseq arbitrarily choose stepaction pa true corresponding state.parallel encoding SPpar uses following explanatory frame axioms EF (Haas, 1987)EF = {l l0WaA leff pa| l literal X},combination called conflict exclusion axioms CECE = {pa pb | a, b A, 6= b, actions b conflicting},two actions considered conflicting ones precondition inconsistentothers effect, i.e. literal l Xeither l pre l eff b , l pre b l eff .sum, define SPpar = (, I, G, par ) par = AP AE EF CE . encodingtwo actions applied parallel consistent effects (action effect axioms)one destroy precondition (conflict exclusion axioms).recovering sequential plan, parallel actions serialized order.Please consult work Ghallab, Nau, Traverso (2004, ch. 7.4) details.3. Property Directed Reachabilitysection present PDR algorithm deciding satisfiability symbolic transition systems. algorithm probably best understood explicit searchgiven transition system complemented symbolic reachability analysis. explicitside, constructs path starting initial state extending step step towardsgoal.2 time, maintains symbolic stepwise approximating reachability information, locally refined whenever current path cannot extended further.reachability information guides path construction also bound eventuallyconverge certificate non-reachability, witnessing path exists.2. standard formulation, PDR actually builds path way round, goal statebackwards towards initial state. small detail theory point view, sincedefinition STS symmetrical. hand, later show, direction adoptgives rise much successful algorithm typical planning benchmarks.271fiSuda3.1 Extension Query Reason ComputationLet us assume STS = (, I, G, ) given. basic building blockconstructed path state, reachability information composed sets clauses.core operation, around algorithm built, extending current path onestep. Given state set clauses L, ask whether state t, successorrespect , satisfying clauses L. question delegatedSAT-solver posing following query:SAT ?[ Lits(s) (L)0 ].(2)answer positive, extract successor state satisfying assignment,necessarily form (s, t0 ), extend current path. unsatisfiablecase, compute reason successor property L.reason cube r Lits(s) already formula r (L)0 unsatisfiable. PDRremoves path learns clause c = r prevent situationhappening future. clause c property preimage L respectstate fails satisfy.important efficiency algorithm always compute reasonsmall possible. reason fewer literals gives rise shorter clause,better generalizes current situation. clause learnedstate also many similar states known successor satisfying L.several techniques computing small reasons. describe twothem: SAT-solving assumptions explicit minimization. postpone discussingthird one, inductive minimization, till Section 3.5. important correctnessPDR final reason consistent goal formula G. close sectionexplaining property achieved.3.1.1 SAT-solving AssumptionsMany modern SAT-solvers simply return UNSAT, able identifyinput clauses actually used derivation unsatisfiability. Solvingassumptions particular, simple efficient form unsatisfiable core extractiontechnique, first introduced Een Sorensson (2003) SAT-solver Minisat.assumptions technique understand designated unit (single literal) clauses passedalong rest input solver. case input unsatisfiable, solverable report units actually used proof.Solving assumptions provides us essentially free mechanism computingsmall reasons. simply designate literals Lits(s) treated unit assumptionsquery (2) above. unsatisfiable case, obtain reason r Lits(s) required.3.1.2 Explicit Minimizationsubset r assumption literals Lits(s) returned solver typicallyreduced. explicitly minimize trying remove literals one one.respective query remains unsatisfiable leave literal out. Otherwise putback. number steps proportional |r| obtain final reason set r r minimal272fiProperty Directed Reachability Automated Planningrespect subset relation querySAT ?[ r (L)0 ],unsatisfiable. Note order literals tried influences finalresult may subject heuristical tuning. Although reason minimization expensive operation (we need one extra SAT-solver call per literal), experiments showimportant ingredient solving hard problems.3.1.3 Keeping Reason Disjoint Gbecome clear later, ensure correctness PDR require computedreason r consistent goal formula G. words, formula r G mustunsatisfiable. always achieved, algorithm never attemptsextend goal state thus start minimizing unsatisfiable Lits(s) G.particularly simple strategy, works whenever goal formula G formset unit clauses (as case planning), minimizes reason much possible,afterwards puts single literal back r provided required unsatisfiability conditionwould otherwise compromised. look literal l added r (unless foundalready present) {l} G. condition is, assumptions,sufficient necessary ensure r G unsatisfiable established withoutadditional calls SAT-solver.Another option make sure beforehand set goal states includedpreimage respect transition relation . instance, making transitionrelation reflexive adding self-loops every state achieves without actually affectingexistence length shortest witnessing path. planning, simplyinclude noop action action set.3.2 Data Structures Main Invariantscontinue exposition PDR describing main data structures. clause setsrepresenting reachability information organized sequence3 L0 , L1 , . . .refer layers. moment run algorithm layers satisfyfollowing three invariants:1) L0 equivalent G,2) Lj+1 Lj thus Lj Lj+1 j 0,3) (Lj )0 Lj+1 j 0, i.e., Lj+1 over-approximates preimage Lj .algorithm starts, layer L0 initialized equal set Gremaining layers empty. Thus, initially, invariants 1), 2), 3) triviallysatisfied. return invariants appropriate place argueindeed maintained algorithm.constructed paths actually one represented viacalled obligations.4 Formally, obligation pair (s, i) consisting state3. point time finitely many layers non-empty need represented memory.4. full term proof obligation. comes verification perspective, obligation mustproven unreachable, otherwise property system hold counter-example found.273fiSudaindex i. index natural number denoting position respectlayers. may seen stand lower bound estimate distance towardsgoal. practical implementation obligation also stores link parent, i.e.obligation derived, use links recover full witnessingpath goal reached.3.3 Algorithmready look overall structure PDR (see Pseudocode 1).initializing layers (line 1), algorithm proceeds iterations, counted variablek. main part iteration path construction phase algorithmattempts build path step step terminates full witnessing path actuallydiscovered. iteration k finishes without completing path, PDR establishedwitnessing path transition system length k less.describe detail below, path construction enhanced obligationrescheduling technique, allows algorithm iteration k consider pathspotentially longer k. Path construction iteration complemented clausepropagation phase, attempts push clauses low index layers high indexones checks global convergence within layers, occurrence implieswitnessing path (of length) possible. Neither obligation reschedulingclause pushing needed ensuring correctness algorithm, typically greatlyimprove performance.3.3.1 Path Constructionpath construction phase iteration k starts using SAT-solver pick initialstate satisfying Lk (lines 4 5). manipulates set Q, working priority queue,storing obligations. set Q initialized (line 6) obligation (s, k).inner loop (starting line 7) processes individual obligations, selecting firstestimated closer goal (line 8). Let (s, i) selected obligation. = 0,means full witnessing path constructed algorithm terminates(line 10). path extension query described previously executed next (line 11). looksuccessor would satisfy clauses Li1 . Since originally obtainedsatisfying Li , represents attempt extend current path one step closer towardsgoal. extension successful new obligation (t, i1) worked nextcurrent (s, i) stored Q (lines 12, 13). opposite case, new clausederived reason failure used strengthen layers L0 , . . . , Li (lines 15,16). Notice strengthening state longer satisfies Li . meansapproximation become strictly precise, ensures progress.3.3.2 Obligation Reschedulingunsatisfiable branch extension attempt continues two lines (19, 20),necessary correctness PDR. Without obligation rescheduling technique, algorithm would forget obligation (s, i) would return workparent. would correspond strict backtracking behavior, set Q functioningstack. Instead, try reuse obligation reschedule one step274fiProperty Directed Reachability Automated PlanningPseudocode 1 Algorithm PDR(, I, G, ):Input:symbolic transition system = (, I, G, )Output:witnessing path guarantee path exists1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:L0 G; foreach j > 0 : Lj /* Initialize layers */k = 0, 1, . . ./* Path construction: */SAT ?[ Lk ]extract state modelQ {(s, k)}Q emptypop (s, i) Q minimal= 0return WITNESSING PATH FOUNDSAT ?[ Lits(s) (Li1 )0 ]extract successor state modelQ Q {(s, i), (t, 1)}elsecompute reason r Lits(s) r G unsatisfiableforeach 0 j : Lj Lj {r}/* Obligation rescheduling: */< kQ Q {(s, + 1)}/* Clause propagation: */= 1, . . . , k + 1foreach c Li1 \ Li/* Clause push check */SAT ?[ c (Li1 )0 ]Li Li {c}/* Convergence check */Li1 = Lireturn PATH POSSIBLE275fiSudab(t, 1)b(s, 2)L2G?L0Gbrb(s, 2)L1bb(t, 2)L2L0L1Figure 2: Layers, obligations rescheduling.goal. typically boosts performance allows PDR discover paths longercurrent iteration number k, existence paths length k ruled out.Without obligation rescheduling, PDR looks optimal length paths.obligation rescheduling technique well general interaction layers,obligations, reasons illustrated Figure 2. There, PDR middle pathconstruction phase iteration 2. algorithm attempting extend obligation (t, 1)reach goal state one step (left). attempt fails (right), PDR generalizest, obtains reason r, learns new clause c = r strengthen layers L1L0 . Notice obligation rescheduled (t, 2) PDR attempt extendsatisfy new L1 one step. Without rescheduling, PDR would forget wouldgo back extending (s, 2) instead.3.3.3 Clause PropagationLet us proceed clause propagation phase. checks every clause c lying layerLi1 Li (line 24) whether could pushed forward added strengthenlayer Li . done query line 26 returns UNSAT, means(Li1 )0 c,adding clause Li preserve invariant 3). motivation clause propagationstronger layers provide better guidance following path constructionphase. Indeed, notice clauses may even enter till empty layer Lk+1 .importantly, however, clause propagation opportunity check equalitytwo neighboring layers (line 29).5 explain later, equality implieswitnessing path transition system length PDR terminates (line 30).3.3.4 Example ExecutionLet us recall STS = (, I, G, ) Example 1, defined two variable signature= {p, q} initial, goal, transition formulas = {p}, G = {p, q},= {p p0 q 0 , p q p0 , p q q 0 , p q p0 , q p0 q 0 },5. necessary perform relatively expensive clause pushing (which requires one SAT-solver callper clause) checking layer equivalence. Experience model-checking suggests, however,pushing substantially helps speed convergence clause propagation one keyingredients efficiently detecting unsatisfiable problems.276fiProperty Directed Reachability Automated Planningstep12345678910111213141516171819202122232425event / queryeffect / explanationInitializationPath construction (iteration 0)SAT ?[ L0 ] falseClause propagationSAT ?[ p (L0 )0 ] falsepush p add L1SAT ?[ q (L0 )0 ] truePath construction (iteration 1)SAT ?[ L1 ] falseClause propagationSAT ?[ q (L0 )0 ] trueSAT ?[ p (L1 )0 ] truePath construction (iteration 2)SAT ?[ L2 ] trueextract state initialize QSAT ?[ Lits(s) (L1 )0 ] falsecompute reason learn clauseSAT ?[ L2 ] trueextract state initialize QSAT ?[ Lits(t) (L1 )0 ] trueextract state store QSAT ?[ Lits(u) (L0 )0 ] trueextract state . . .. . . store Qwitnessing path foundL0 = {p, q}; Li = > 0k=0p p unsat.p (p p0 q 0 ) (p q)0 unsat.L1 = {p}q (p q)0 sat.k=1p p unsat.q (p q)0 sat.p p0 sat.k=2p sat.= {p 7 0, q 7 0}; Q = {(s, 2)}p q (p q p0 ) (p)0 unsat.r = p q; L2 = {p q}, L1 = . . .p (p q) sat.= {p 7 0, q 7 1}; Q = {(t, 2)}p q (p)0 sat.u = {p 7 1, q 7 0}; Q = {(t, 2), (u, 1)}p q (p q)0 sat.v = {p 7 1, q 7 1};Q = {(t, 2), (u, 1), (v, 0)}return t, u, vTable 1: Execution trace PDR STS Example 1.respectively. Table 1 showcases execution trace PDR STS. listsSAT-solver queries order execution, provides explanation results formunsatisfiable cores, tracks changes global variables. Notice step 6clause p successfully pushed layer L0 L1 . step 17 new clause p qformally added L2 , L1 , L0 . However, properly strengthens layer L2 .3.4 Correctnessshow correctness PDR first review invariants 1)3) demonstrateindeed preserved run algorithm. add fourth observation,invariant 4), important showing correctness unsatisfiable case. invariantsused prove independent lemma and, finally, also main correctness theorem.277fiSuda3.4.1 Four InvariantsInvariant 1) states layer L0 equivalent G. could violatednew clause c added L0 (line 16). since c = r reason r assumer G unsatisfiable (recall Section 3.1.3), G c invariant 1) preserved.Invariant 2) asserts Lj+1 Lj index j 0. trivially maintainednew clause added layers (line 16) clause pushing (line 27).Invariant 3) statement (Lj )0 Lj+1 j 0. new clause cadded layers L0 , . . . , Li (line 16) unsuccessful extension obligation(s, i), means c = r reason r Lits(s). definition reasonformula r (Li1 )0 unsatisfiable and, therefore, (Li1 )0 c.guarantees invariant 3) hold j = 1 clause c added Li . However,layers index j < 1 even stronger Li1 invariant 2), invariant3) also hold j < 1. Finally, case j > 1 trivial. already discussed(recall Section 3.3.3) invariant 3) also preserved clause propagation.one observation need order show correctness PDR.Let us call invariant 4). Invariant 4) states path construction iterationk finishes initial state satisfying Lk . follows fact queryline 4 must unsatisfiable path construction finish.3.4.2 Correctness TerminationLemma 1. PDR creates (either line 6 line 13) new obligation (s, i)|= Li . Moreover, 6|= Lj j < i. latter property maintained throughoutrun algorithm and, particular, holds also rescheduling (line 20).Proof. First note sufficient show second part j = 1use invariant 2). Also note run PDR clauses added neverremoved layers. means sufficient focus moments newobligation created: 6|= Lj obligation (s, i) created, must also holdlater, layer Lj strengthened addition new clauses.Let us consider iteration k. creating new obligation (s, k) line 6,|= Lk construction 6|= Lk1 invariant 4). creating new obligation(t, 1) line 13, assume parent (s, i) already satisfies lemma and,particular, 6|= Li1 . |= Li1 , construction, > 1infer 6|= Li2 assumption invariant 3). Finally, obligation(s, i) rescheduled (s, + 1) addition clause c = r Lir Lits(s). means 6|= Li time rescheduling.Lemma 1 captures intuition state obligation (s, i) always leaststeps reaching goal. follows lemma PDR never attemptsextend goal state, assumption relied Section 3.1.3 showalways keep reasons disjoint goal formula G.Theorem 1 (Bradley, 2011). Given STS = (, I, G, ) algorithm terminatesreturns witnessing path satisfiable.278fiProperty Directed Reachability Automated PlanningProof. easy see PDR returns path (line 10)6 witnessing path S.Indeed, every considered obligation (s, i) state reachable initial state= 0 state satisfies L0 , equivalent G invariant 1).PDR terminates claiming witnessing path exists (line 30) path constructionphase iteration k finished index 0 j k Lj = Lj+1 .combining invariants 1)3) detected equality obtain G Lj (Lj )0 Lj .together invariant 4) rules existence witnessing path length.7address termination first show path construction phase iteration kcannot run indefinitely. Recall PDR always selects extension obligationminimal index (line 8). Thus follows Lemma 1 successful extensionobligation (s, i) new extracted state equal state previouslyconsidered iteration k (t currently state satisfies Li1 ).hand, unsuccessful extension obligation (s, i) addition new clause clayer Li ensures 6|= Li anymore (recall c = r r Lits(s)).means cannot k 2|| repetitions Q-processing while-loop(line 7) 2|| repetitions outer while-loop path construction (line 4).left bound maximal number iterations PDR. invariant 2) setsstates represented individual layers ordered inclusion clausepropagation phase iteration k finishes first k + 1 sets necessarily distinct.Thus cannot 2|| iterations PDR terminates.3.5 Inductive Reason MinimizationInductive reason minimization technique obtaining small reasons unsuccessfulextensions. postponed discussing technique presentation PDR,relies non-obvious way overall architecture algorithm. Moreover,although inductiveness one main initial ideas behind PDR (Bradley, 2011),experiments suggest practical value relatively advanced techniqueautomated planning may limited.demonstrate inductive minimization let us recall situation unsuccessful extension obligation (s, i). want compute reason r, subsetLits(s), ideally small possible, formular (Li1 )0(3)unsatisfiable. Now, crucial observation since next step goingstrengthen layers L0 , . . . , Li (and, particular, layer Li1 ) clause c = r,may already assume c primed side (3) minimizing r. means,use stronger queryr (Li1 r)0 .r sides transition breaks monotonicity: r gets weaker, r getsstronger. Satisfiable query may become unsatisfiable literals removed6. Line 10 Pseudocode 1 reports existence path. true witnessing path can, however,easily recovered following parent pointers (see Section 3.2) last obligation (s, 0).7. layer Lj understood promised certificate non-reachability. propertygoal states incompatible initial formula preserved traversing transitions backwards.279fiSudar. makes task finding subset-minimal inductive reason computationallydifficult (Bradley & Manna, 2007).Pseudocode 2 Inductive Reason Minimization:Input:set clauses L cube rformulas r (L)0 r G unsatisfiableOutput:Minimized inductive reason r r, i.e.,formulas r (L r )0 r G unsatisfiable1:2:3:4:5:6:7:8:repeatr0 rforeach l r /* Check literal r0 */l0 (r0 \ {l}) {l0 } G /* try removing l */r0 (r0 \ {l})SAT ?[ r0 (Li1 r0 )0 ]r0 (r0 {l}) /* Put literal back */r = r0 /* removal last iteration */9:10:return rPseudocode 2 present simple version inductive reason minimizationminimality guarantee, was, however, successfully applied hardware model checking(Een et al., 2011). procedure meant improve replace explicit reasonminimization described Section 3.1.2. assumes goal formula G formset unit clauses keep reason disjoint G (see Section 3.1.3). Noticenon-monotone setting inductive minimization makes sense retry literalssingle literal successfully removed. procedure employesouter loop continue minimizing till true fixed point reached.3.6 Notes Implementationseveral important points relevant practical implementation PDRfit level detail presented pseudocode. moved section.3.6.1 Representation Layersindividual clause sets Li ordered inclusion advantageous storeclause once, namely position appears last. conventionnamed delta encoding Een et al. (2011). defined setting= Li \ Li+1Li =ji j .delta encoded layers clause propagation moves clauses around instead copyingequality check neighboring layers becomes emptiness checkrespective delta.280fiProperty Directed Reachability Automated Planning3.6.2 Clause Subsumptionobserved PDR often derives clause c layer Li weaker clausealready present. pays remove (so effectively L0 , . . . , Li )clauses subsumed new clause c. Keeping layers small way (whilepreserving semantic strength) helps speed algorithm several places.reduces load SAT-solver (provided retract subsumed clause it)also means fewer clauses need checked pushing.3.6.3 Obligation SubsumptionAnother place subsumption (and should) employed dealingobligations. may happen obligation (s, i) handled, layer Li ,obligation belongs, gets meantime strengthened way longersatisfies Li . point already know obligation cannot extended,save one SAT-solver call directly reschedule obligation. situationdetected subsumption: state satisfy clause set Lclause c L c Lits(s). insert test point algorithmnew clause c derived Li . check subsumption obligationsform (s, i) currently set Q.3.6.4 Breaking Ties Popping Qpopping obligations set Q (line 8) make sure select amongestimated closest goal. necessary ensuring termination algorithm.Otherwise, however, free choose obligation minimal index i. Twoprominent strategies resolving dont-care non-determinismselect recently added obligation first, call stack strategy,select least recently added obligation first, queue strategy.stack strategy prefers exploring longer paths short ones, queue strategyopposite. Een et al. (2011) report small performance gain stack strategyhardware model checking benchmarks. used stack strategy defaultexperiments observed superiority queue strategy satisficing planning,also slightly unfavorable effect plan quality (see Section 5.3.3).4. PDR without SAT-solverAlthough possible encode STRIPS planning problem STS use generalimplementation PDR solve it, efficient approach adopted. approachrelies observation work normally delegated PDR SAT-solvercase planning sequential plan semantics instead implemented directlyplanning-specific procedure. gain procedure polynomialtime guarantee response extension query, ensuing perspective alsoenables us devise new improvements overall algorithm.SAT-solver employed several places within PDR. start focusingprimary role lies extending current path one step. Section 4.1281fiSudadevelop procedure extend replace SAT-solver path extension queries. separatesection devoted discussing inductive reason minimization planning context.Section 4.3 deal replacing remaining SAT-solver calls. showefficiently implement clause pushing positive STRIPS planning problems, subclassSTRIPS problems typically used practice. discuss possibilityreversing default search direction PDR Section 4.4 and, finally, propose severalimprovements algorithm Section 4.5.4.1 Planning-Specific Path ExtensionsLet us recall interface path extensions, normally implemented PDRcall SAT-solver (Section 3.1). Given state set clauses L decide whetherexists state t, successor respect transition relation ,satisfies L. positive case, refer successful extension, return t.negative case, successor exists, compute reason r failureform preferably small subset literals defining s, state satisfyingr successor would satisfy L.Let us assume STRIPS planning problem P = (X, sI , g, A) given. graduallywork towards planning-specific implementation interface within procedureextend(s, L). central idea emulate mechanics sequential encoding SPseq(see Section 2.6). makes implementation particularly straightforwardperspective positive part interface. Given state s, simply iterateactions A, generate successor ta = apply(s, a) whenever applicable s,check ta whether satisfies clauses L. successor found,returned procedure terminates. iteration clearly affordablecomplexity point view. fact, similar spirit explicit stateplanners need do: enumerate successor states evaluate heuristic value.non-trivial part extend procedure deals computing small reasoncase unsuccessful extension. conceptually simplify problem first separatelycollecting set reasons Ra every action computing overall reasonr union[r=ra(4)aAreason contributions ra Ra selected way minimizes size union.idea ra Ra distinct reason action cannot appliedproduce successor state would satisfy clauses L. union (4)justifies successor state via action whatsoever.rest section, first explain individual reasons ra Raaction derived actions failed preconditions clauses Lrespective successor state fails satisfy. show reason collectingprocess practice sped employing certain subsumption concepts. Finally,present approach obtaining small overall reason r, along detailed pseudocodeextend procedure proof correctness. satisfy requirement PDRfinal reason disjoint set goal states, adopt solutionformally adding noop action action set (see Section 3.1.3).282fiProperty Directed Reachability Automated Planning4.1.1 Reasons Individual Actionsconstruct set reasons Ra particular action follows. First checkwhether action applicable given state s. preconditionliteral l pre false s. negation literal represents singleton reason{l} Lits(s) add Ra . Clearly, long state satisfies l wayused produce successor state, let alone one would satisfy L.Next, compute successor state ta = apply(s, a). Strictly speaking, ta cannotregarded true successor applicable s. Nevertheless, ta useful evencomputing reasons, namely reasons corresponding clauses L falseta . either clauses already false failed make trueclauses became false due effect a. clause c add Rareason rc consisting negations literals l c. optimization, includenegated literals made false effect a. Since literalsalways false applied due effects, long satisfies rc , successor tacannot satisfy c. Summarizing formally, final set reasons obtain:Ra = {{l} | l pre 6|= l} {rc | c L ta 6|= c},rc = {l | l c l 6 eff }. easy check rc Lits(s) required.Notice set Ra empty action applicable successorta satisfies clauses L.Example 2. Starting state = {o 7 0, p 7 0, q 7 0, r 7 0}, let us computereasons action = (pre , eff ) pre = {p, q} eff = {o, r} respectclause set L = {o q, p r}. precondition q satisfied s, onereason {q}. Next compute ta = apply(s, a) = {o 7 1, p 7 0, q 7 0, r 7 0}.first clause, q satisfied ta give rise reason. second clause,p r, however, false ta . reason corresponding second clause {p}.negated literal, r, part reason, explicitly set falseeffect a. final reason set Ra obtain thus {{p}, {q}}. Noticecomputed reasons subsets Lits(s) = {o, p, q, r}.Correctness reason set construction captured following lemma.Lemma 2. Let ra Ra reason action {noop} defined above.ra AP AE CF (L)0 |= pa ,AP , AE CF are, respectively, action precondition, action effectclassical frame axioms used transition formula seq sequential encoding SPseq .Proof. Let us first assume ra = {l} reason derived failed preconditionliteral l pre . action precondition axiom pa l APconclusion pa follows single resolution inference unit assumption l.possibility ra = {l | l c l 6 eff } clause c L falsesuccessor state ta . must action effect axiom pa l0 AE everyliteral l c l eff also classical frame axiom pa l l0 CF everyliteral l c l 6 eff (if literal l eff clause c would satisfied283fiSudata ). resolving axioms respective primedliterals l0 primed versionW00(c) (L) clause c obtain clause pa lra l final unit clausepa derived resolution available assumptions ra .4.1.2 Reason Subsumptiondescribe compute overall reason r actions contributionsRa , let us note two useful notions subsumption individualreasons reason sets, used simplify reason setscomputation started. subsumption individual reasons inside one particularRa simply subset relation. make sense keep r1 r2 inside Rar1 r2 . Keeping smaller r1 sufficient, whenever would decide pick r2reason inside union (4), switching r1 instead could make resultsmaller. practice, check kind subsumption unit reasonsfailed preconditions reasons false clauses.8 implementedsimply ignoring false clauses would true action applicable.Dually above, discard whole reason set Ra actionanother action b reason set Rbrb Rb ra Ra ra rb .remove reason set Ra , sense lean,contribution rb Rb choice ra Ra would dominated rbfinal union r. efficiency reasons, exploit trick implementationrespect one particular action role subsuming action b, namelynoop action. mentioned before, include noop action action set ensurePDRs correctness. reason set Rnoop consists reasons corresponding clausesL false s.9 action make clauses truecorresponding successor state, reason set Ra subsumed described senseRnoop skipped.4.1.3 Computing Overall ReasonComputing overall reason r amounts selecting every particular reason ra Raunion (4) small possible. Stated general form facingoptimization version NP-complete problem. fact, easily seen dualMaximum Subset Intersection problem shown NP-complete Clifford Popa (2011).therefore attempt find optimal solution contendreasonable approximation instead.sort reason sets Ra according size |Ra | traverse smallerlarger ones. idea deal constrained cases first movingfreedom. traversal, maintain unfinishedunion r0 initialized empty set . reason set Ra consideredturn pick reason ra Ra minimizes size r0 ra update8. sufficient, PDR keeps layers L subsumption reduced reasons false clausessubsumption reduced free.9. PDR calls extend(s, L) 6|= L, always least one clause.284fiProperty Directed Reachability Automated Planningset r0 accordingly describe union reasons selected far. Althoughgreedy pass action sets guarantee final value r0 minimal,already gives satisfactory results.improve quality reason set even further, minimize r0 respectsubset relation explicitly trying remove individual literals checking whetherresult still valid overall reason. direct adaptation explicit reasonminimization procedure employed original PDR (recall Section 3.1.2). detail,iteratively pick literal l r0 check every action whether reason ra Rara (r0 \ {l}). indeed case, r0 shrunk (r0 \ {l}), otherwisecontinue old r0 try another literal instead. literalstried out, obtain final result r.4.1.4 Pseudocode Correctnesscode procedure extend(s, L) detailed Pseudocode 3. correspondingreason construction proceeds three stages. first stage collect reasonsindividual actions, constructing sets Ra . performed iterationaction set establishes whether successor state satisfying L exists.either terminates discovering computes non-empty set Ra every actiona. first stage also includes subsumption-based filtering reasons, withinparticular actions reason set reason sets noop action oneaction. second stage, described simple greedy pass sets Racomputes initial overall reason, explicitly minimized stage three.Correctness extend procedure positive case well factreturned reason r r Lits(s) easy establish. remaining argumentcaptured following lemma.Lemma 3. Let r cube returned procedure extend(s, L). formular seq (L)0(5)unsatisfiable, seq transition formula sequential encoding SPseq .Proof. WeSfirst observe every action {noop} reason rar = aA{noop} ra . actions Ra R reason initiallypicked stage two (line 22) possibly later changed reason rara (r \ {l}) stage three (line 26). actions whose reason set subsumedRnoop (line 14) formally pick reason noop.Since ra r every action {noop}, use Lemma 2 infer formula(5) entails unit clause pa every WA {noop}. formula (5) alsotrivially entails at-least-one axiom alo = aA{noop} pa , must unsatisfiable.easy see procedure extend(s, L) runs time polynomial |X|,number state variables, |A|, number actions planning problem, |L|,size given clause set. mainly enabled fact extend emulates285fiSudaPseudocode 3 Procedure extend(s, L):Input:State s; set clauses L 6|= LOutput:Either state t, successor |= Lreason r Lits(s) state satisfying r successor satisfying L1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:/* Stage one: look successor state prepare reason sets */Ls {c L | 6|= c} /* Clauses false */Rnoop {c | c Ls } /* reasons noop action */assert Rnoop 6= /* Follows contract caller */R {Rnoop } /* set reason sets collected far */foreachpre sa {l pre | 6|= l} /* Preconditions false */apply(s, (, eff )) /* Ignore preconditions apply effects */Lt {c L | 6|= c} /* Clauses false */pre sa = Lt =return /* positive part: returning successor */else Ls Ltpass /* nothing: reason set would subsumed Rnoop */elseLt0 {c Lt | c pre sa = } /* False clauses non-subsumed reason */Ra {{l} | l pre sa } {{l | l c l 6 eff } | c Lt0 }R R {Ra } /* Record reason set *//* Stage two: compute overall reason */r21: foreach Ra R ordered |Ra | small large22:pick ra Ra |r ra | minimal23:r r ra19:20:/* Stage three (optional): minimize reason */foreach l r26:every Ra R ra Ra ra (r \ {l})27:r (r \ {l})24:25:28:29:return r /* negative part: returning (subset minimal) reason cube */286fiProperty Directed Reachability Automated Planningsequential encoding SPseq individual actions first stage consideredindependently.10similar complexity guarantee seems achievable within general-purpose SATsolver supplied encoding configured prefer branchingaction variables setting first true. However, inherent overhead connectedexplicitly generating corresponding axioms storing memoryprobably noticeable practice. Moreover, reason set subsumption optimizationcounterpart general-purpose solver.4.2 Inductive Reason Minimization Procedure extendInductive minimization based idea checking whether particular literal lremoved final reason r assume clause c = r0 correspondingreduced reason r0 = (r\{l}) already present set clauses L (see Section 3.5).perform inductive minimization within extend procedure speculatingaction whether would able satisfy additional clause c applying a.answer positive need look proper reason ra Ra .Pseudocode 4 Stage three extend(s, L); inductive version:1: repeat2:r0 r3:foreach l r /* Check literal r0 */4:l0 (r0 \ {l}) l0 g /* attempt remove l */5:r0 (r0 \ {l})6:foreach7:every l0 eff : l0 6 r08:continue /* passed inductive argument */9:Ra R ra R ra r010:continue /* passed; small reason */11:Ra 6 R ra Rnoop ra r012:continue /* Ra subsumed Rnoop contains small reason */13:/* Action says: Literal l cannot removed */15:r0 (r0 {l}) /* Put literal back */16:break17: r = r0 /* removal last iteration */14:18:19:return ridea demonstrated Pseudocode 4, regarded replacementstage three original extend procedure. Notice longer considernoop action part action set11 thus need explicitly check10. devising analogous procedure parallel plan semantics, one would general needconsider every subset actions applied together. seems make polynomial timesolution much difficult, hopeless. However, see Section 6 interesting connection.11. noop action trivially passes inductiveness check, never make clause true.287fiSudaremains least one literal incompatible goal condition g (line 4). stillactions, however, whose reason set subsumed Rnoop lookreason Rnoop (line 11) whenever fail pass inductiveness check (line 7).avoid confusion remark continue break commands refer innermost cycle, iterates actions (line 6). Finally, note presence smallreason Rnoop depends current value r0 corresponding checkcould precomputed outside inner cycle.Example 3. Recall Example 2, action = ({p, q}, {o, r}) failed state= {o 7 0, p 7 0, q 7 0, r 7 0} provide successor state would satisfy clausesL = {o q, p r} computed reason set Ra = {{p}, {q}}. Assumeapart action set contains one action, namely b = ({r}, {p}),obtain reason set Rb = {{o, q}}. overall reason stage twothus necessarily r = {o, q}. Assuming goal condition given problemg = {o, p, q, r}, inductive minimization reason r could proceed follows.First try reason r0 = {o}. Since eff cannot use inductive argumentaction also proper reason ra Ra property ra r0 . Thusliteral q cannot removed r. Next try reason r0 = {q}. Since neitheraction b contain literal q effect lists, smaller reason justifiedinductively actions overall reason r reduced {q}. cannot minimizer further, remain least one literal l0 r l g.Looking perspective final learned clause c = r observe inductiveminimization allows us (as example above) remove c every literal cannotmade true action action set A. Although may seem like powerful(global) criterion, effectively made redundant practice called relaxed reachability analysis (see Hoffmann & Nebel, 2001, Section 4.3), standard preprocessing stepwhich, actual search started, removes problem unattainablevariables well actions mention precondition lists. Non-trivialinvocations inductive minimization actually quite rare experiments.4.3 Replacing Remaining SAT-solver CallsBeside query extending states, two points formulation PDR(recall Pseudocode 1 page 275) SAT-solver call employed. used pickinitial states beginning path construction phase (line 4) also centralverifying condition pushing clauses clause propagation phase (line 26).planning, easily without SAT-solver first case, oneinitial state picked, namely state sI , need verify sI satisfiesclauses Lk path construction phase iteration k started.basically two options deal second case. Since clause pushingneed ensuring correctness PDR, simply leave operation out.later show experiments, significantly affect performance planningbenchmarks, typically satisfiable. second option, propose restrictplanning formalism query corresponding push check clause c, i.e.,SAT ?[ c (L)0 ],288(6)fiProperty Directed Reachability Automated Planningdecided polynomial time.12 say STRIPS planning problem positiveprecondition list every action goal condition problem consistpositive literals only.13 easy see running positive STRIPS problem,PDR deals positive clauses. unit clauses layer L0 , describe goal,positive assumption learned clauses transitively builtgoal literals action precondition literals. observation allows us reducequery (6) evaluation positive part interface path extensions.Lemma 4. Let P = (X, sI , g, A) positive STRIPS planning problem seqtransition formula sequential encoding SPseq . Further, let L set positive clausesX, c positive clause X, sc : X {0, 1} state defined every p X(0 p c,sc (p) =1 otherwise.following formulaFc = c seq (L)0satisfiable action sc |= pre apply(sc , a) |= L.Proof. Let us first assume action applicable scsuccessor state = apply(sc , a) satisfies clauses L. Notice Vars(Fc ) = XX 0 , = {pa | A} set variables used encoding applied actions.define following assignment : {0, 1}:= {pa 7 1} {pb 7 0 | b A, b 6= a}.easy verify joint assignment (sc t0 ) satisfies Fc .opposite direction, let us assume assignment V : X X 0 {0, 1}satisfies formula Fc . fix actionmustW V (pa ) = 1. actionseqexist, V satisfies at-least-one axiom alo = aA pa , part .restricting V , first, state variables X, and, second, primed variables X 0 ,extract, respectively, state = V X state t0 = V X 0 . axiomsseq ensure action applicable = apply(s, a).notice |= c, means s(p) = 0 every p c. Thusdifference states sc variables p 6 c s(p) = 0sc (p) = 1. means, one thing, since action applicable s,must also applicable sc (preconditions positive) and, other, since |= L,successor state tc = apply(sc , a) corresponding sc must also satisfy clauses L(the implication p X : s(p) = 1 sc (p) = 1 preserved transition becomesp X : t(p) = 1 tc (p) = 1 clauses L positive assumption).12. current setting, seem general polynomial solution. fact, evendegenerate case encoding transition single noop action c empty clause,query (6) boils satisfiability L evaluation thus NP-complete problem.13. standard planning benchmarks positive STRIPS. Moreover, well-known reduction (Gazen & Knoblock, 1997) turns general STRIPS problem positive one. reductionintroduces new variable p every variable p occurs negatively precondition goalupdates actions always force p opposite value p.289fiSudaPseudocode 5 Algorithm PDRplan(X, sI , g, A):Input:positive STRIPS planning problem P = (X, sI , g, A)Output:plan P guarantee plan exists1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:L0 {{p} | p g} /* goal cube treated set unit clauses */foreach j > 0 : Ljk = 0, 1, . . ./* Path construction: */sI |= LkQ {(sI , k)}Q emptypop (s, i) Q minimal= 0return PLAN FOUNDextend(s, Li1 ) returns successor stateQ Q {(t, 1), (s, i)}elseextend returned reason r Lits(s)foreach 0 j : Lj Lj {r}/* Obligation rescheduling: */< kQ Q {(s, + 1)}/* Clause propagation: */= 1, . . . , k + 1foreach c Li1 \ Li/* Clause push check */sc {p 7 0 | p c} {p 7 1 | p (X \ c)}every : sc 6|= pre apply(sc , a) 6|= Li1Li Li {c}/* Convergence check */Li1 = Lireturn PLAN POSSIBLE290fiProperty Directed Reachability Automated Planningversion PDR specialized positive STRIPS planning shown Pseudocode 5.calls SAT-solver original formulation replaced, respectively, simpleentailment check (line 5), call extend procedure (line 11), enumerationsuccessor states state sc defined Lemma 4 (line 26).4.4 Reversing Search Directionmentioned original formulation PDR based opposite searchdirection one described paper extends paths goal statebackwards towards initial state. would like test algorithm directionssee one favorable practice.One possibility achieve provide PDR inverted version input,initial goal states swapped transition relation turnedaround. straightforward input STS (recall Section 2.3),case general version PDR. situation complicated SATsolver free version, directly takes STRIPS planning problem input. Indeed,seems extend procedure substantially relies forward direction.Interestingly, exists transformation inverting STRIPS planning problems.first described Massey (1999) dissertation. present streamlined version due Pettersson (2005) relies problem positive. Let usstart introducing alternative representation positive STRIPS planning problems,makes description transformation particularly straightforward. positiveSTRIPS planning problem subset representation given tuple P = (X, i, g, A),i, g X initial goal conditions, respectively, every actionencoded triple = (pre , add , del ), consisting precondition list, add listdelete list, subsets X pre add = add del = .subset representation differs one presented Section 2 encoding initialstate set variables true it:sI (p) = 1 p i,splitting actions effects positive negative ones:eff = add {p | p del }.goal condition g precondition lists pre remain intact, may understood subsets X since problem positive. clear subsetrepresentation one Section 2 equivalent.Now, action = (pre , add , del ) inverted action a1 formed exchangingprecondition delete list: a1 = (del , add , pre ). set actions setinverted actions A1 = {a1 | A}. Given planning problem P = (X, i, g, A)subset representation, inverted problem P 1 obtained exchanging initialgoal conditions taking complements respect X using invertedaction set:P 1 = (X, (X \ g), (X \ i), A1 ).original problem inverted version related following sense:291fiSudaTheorem 2. sequence actions a0 , a1 , . . . , ak plan planning problem P111 .sequence a1k , ak1 , . . . , a0 plan Pmeans performing forward search (also called progression) P equivalentperforming backward search (regression) P 1 vice versa. Notice that, priori,computational overhead incurred transformation: inverted problemnumber actions well set state variables X representationstates size. proof Theorem 2 along intuition behindtransformation theoretical practical implications described Suda (2013b).4.5 Improvementsdescribe three additional modifications PDR aim make algorithm efficient practice. first planning-specific improvement extend procedure,two focus obligations handled overall algorithm. Section 5experimentally evaluate effect modifications solving planning problems.interested reader find pseudocode modifications Appendix A.4.5.1 Lazy False Clause ComputationOne way speed extend procedure practice technique named lazy falseclause computation. based following two observations:Ls , set clauses false state s, typically small subset L, setclauses successor state satisfy,small fraction available actions makes clauses Ls truerespective successor.idea avoid relatively expensive computation set clauses falsesuccessor t, i.e. computation set Lt line 10 (Pseudocode 3), insteadfirst look truth value clauses Ls . (Notice Ls precomputedstart iterating actions.) find actionpreconditions satisfied makes clauses Ls true respectivesuccessor t, classify action promising go back computing full Lt . Thus,non-promising actions save computational time. may pay littleside quality reason set, use Ls,t = {c Ls | 6|= c}instead full Lt computing reasons. hand, promising actionscomplete test necessary distinguish true successor satisfying Laction repairs everything false s, breaks something else instead.4.5.2 SidesteppingSidestepping technique propose make PDR active early explorationpromising paths. partially circumvents limitation stemming fact extendprocedure emulates sequential encoding SPseq .Imagine want extend obligation (s, i), i.e. find successor wouldsatisfy Li1 , two clauses c1 , c2 Li1 false s. Let us think two clauses292fiProperty Directed Reachability Automated Planningtwo independent subgoals achieved. two actions a1 a2 applicables. Action a1 makes c1 true successor state a2 makes c2 true, actionmake clauses true one step. means extension cannot successfulPDR learn new clause c = c1 c2 (or superset thereof). clause c expressesfact order reach state satisfying Li1 one step, least one two clausesc1 , c2 must satisfied beforehand. could important ingredient showingpath length k reach goal, helping algorithm eventually advance nextiteration. However, planning usually interested actually findingplans showing non-existence, deriving clause c could represent unnecessaryextra work. idea behind sidestepping make extend procedure succeedoften, even mean directly advancing next layer. example,return successor state = apply(s, a1 ) additional flag informing callernew obligation index usual 1. effectivelysidestepping (s, i) (t, i). next round obligation (t, i) pickedsuccessfully (provided actions a1 a2 interfere) extended (u, 1) viaaction a2 . way end state satisfying Li1 almost executedtwo actions a1 a2 parallel.Let us present sidestepping technique detail. order actionrespective successor ta = apply(s, a) qualify sidestep extensionobligation (s, i) following conditions must met:1) applicable s,2) ta improves respect set satisfied Li1 clauses:Lti1= {c Li1 | ta 6|= c} Lsi1 = {c Li1 | 6|= c},3) ta satisfies Li clauses.Notice require improvement strict (condition 2). ensuressidestepping compromise termination. also make sure new statestays within Li (condition 3) improvement one respect payedoverall deterioration.action qualifies sidestep, compute return reason setusual. Otherwise, choose among action size Lti1tasmallest. case |Li1 | = 0 corresponds regular successful extension newobligation (ta , 1) stored set Q. |Lti1| > 0, store (ta , i) instead,means perform sidestep.sidestepping old obligation (s, i) new (ta , i) occupyindex Q. important prioritize latter former picking (e.g.,even otherwise want use queue tie-breaking strategy; see Section 3.6.4),prevent algorithm sidestepping way once.14Notice sidestepping extension PDR relies modificationplanning-specific extend procedure. immediate counterpartoriginal algorithm, path extensions delegated SAT-solver.14. time (s, i) reconsidered must unsuccessful extension (ta , i), means Ligot meantime strengthened ta longer satisfies it.293fiSuda4.5.3 Keeping Obligations IterationsLet us return obligation rescheduling (lines 18 19 Pseudocode 5) discuss oneadditional aspect feature. Notice reschedule obligation (s, i) < knew obligation (s, + 1) never positioned goal k stepsiteration k. Obligations form (s, k) simply forgotten ensurespath construction phase eventually terminates. viable alternative strategyreschedule obligations queue Q index k + 1, set dormantstate return next iteration. understoodeffectively enlarging set initial states next iteration includesstates reached far.Although modification quite simple implement seems go wellspirit obligation rescheduling itself, publicly described yet. potentialdisadvantage could increased memory consumption, since states ever encountered run must stored algorithm. utility modification may,therefore, depend application domain.5. Experimentssection report series experiments aimed establish practical relevancePDR automated planning. first compare standard version algorithmcombined encodings SAT-solver free variant PDR proposed paper.latter implemented new planner PDRplan. Next, measure influenceseveral design choices mentioned Section 3 well various improvementsproposed Section 4.5 performance PDRplan. successful configurationPDRplan compared planners, including state art representativesheuristic search planning planning satisfiability paradigms. Finally, also assessPDRplan perspective plan quality, finding optimal length plans detectingunsatisfiable problems.5.1 Setupperformed experiments machines 3.16 GHz Intel Xeon CPU, 16 GB RAM,running Debian 6.0. Although multiple cores available machine, plannersused one core made sure busy process running concurrently would compete planner memory, etc. main measured resourcecomputation time. used time limit 180 seconds per problem instanceruns, increased 1800 seconds main comparison.increase level confidence towards correctness implementationgenerated plans subsequently checked latest version plan validator VAL(Howey, Long, & Fox, 2004). discrepancies found experiments reportedpaper.tested planners STRIPS15 benchmarks International PlanningCompetition (IPC, 2014). far, altogether seven repetitions competitionhappening biennially 1998 2008 2011. time planners competed15. richer ADL formalism currently supported PDRplan.294fiProperty Directed Reachability Automated Planningseveral benchmark domains various planning scenarios. used availableSTRIPS domains except following:1998-MOVIE, turned technically difficult validate plans.16Note domain is, fact, trivial solve.2000-SCHEDULE, originally ADL domain. competition archive contains also STRIPS version, accompanied note saying version laterproved problematic dropped competition.2002-ROVERS, problems included set 2006-ROVERS.2002-SATELLITE 2011-TIDYBOT, make use actions negative preconditions, feature supported parser.Altogether, collected 1561 problems 49 domains (see Table 3 page 304 detailedlist). 2008 2011 competition benchmarks specify action costs. modifiedrespective files remove feature, supported PDRplan.implemented PDR extend procedure described Section 4PDRplan system. code PDRplan (approximately 2K lines C++) built topPDDL parser grounder adopted SatPlan 2006 (Kautz, Selman, & Hoffmann,2006). modified parser successfully process large problems recentIPC domains. source code PDRplan publicly available web page (Suda,2014), also contains material relevant reproducing experiments.5.2 PDRplan v.s. Standard PDR plus Encodingsmain purpose first experiment compare PDRplan planning-specificimplementation extend procedure composition general PDR, usesSAT-solver answer one-step reachability queries, various encodings planningSTS. also wanted establish two possible search directionsPDR favorable discovering plans.took implementation PDR called minireachIC3, originally developedmodel checking tool hardware circuits. internally relies SAT-solver Minisat(Een & Sorensson, 2003) version 2.2. extended minireachIC3 able readdescription STS. designed new input format purpose, callDIMSPEC (Suda, 2013a). simple modification well-known DIMACS CNFformat used SAT-solvers extended define individual clause sets STS.coupled minireachIC3 four encoders planning STS. first twoencoders, seq par, implementations two simple encoding SPseq SPpar ,respectively (recall Section 2.6). third encoder version planner Mp (Rintanen,2012) modified output encoded instance form STS quit startingactual solving process. Mp uses -step parallel encoding scheme Rintanen et al.(2006). Finally, fourth encoder implements SASE encoding scheme introduced16. parser adopted PDRplan removes vacuous arguments operators resulting actionsnames. validator VAL complains resulting plans.295fiSudaHuang et al. (2012). particular implementation used derives FreeLunchplanning library (Balyo et al., 2012).order obtain fair comparison used basic version PDRplan configuredway resembles workings minireachIC3. configuration followsplanning-specific version overall algorithm (Pseudocode 5) relies extendprocedure (Pseudocode 3) minimization phase reason computation (stagethree) enhanced induction (Pseudocode 4). additional improvements Section 4.5disabled experiment.compared systems search directions. forward direction, meanone preferred paper, PDR constructs path initial state towardsgoal. opposite, backward direction preferred original exposition PDRused model-checking. start minireachIC3 backward direction invertedencoded STS, reverse search direction PDRplan inverted planning problem(as explained Section 4.4).175.2.1 Adding Invariantsinvariant transition system property initial state preserved transitions. planning, one typically considers invariants form binary clauses (Rintanen,1998), computed simple fixpoint algorithm (Rintanen, 2008b). Addinginvariant clauses encoding known speed plan search planningsatisfiability paradigm.noticed performance PDRplan backward direction alsoenhanced help invariants. PDR run backward direction,sound strengthen every layer binary clauses precomputed invariant.clauses help guide path construction towards initial state. Adding invariantsforward direction make sense PDRplan, generated statesreachable initial state and, therefore, satisfy invariant automatically.18used invariant generation algorithm PDRplan also enhance encodings seq par run minireachIC3. turned case minireachIC3invariants slightly help even forward direction.19 note binary clause invariants also explicitly included Mp encoding implicitly present SASEencoding, relies SAS+ planning formalism (Backstrom & Nebel, 1995)STRIPS problem converted help invariants (Helmert, 2009).5.2.2 Detecting Auxiliary Transition Variablesessential good performance minireachIC3 combined encodingsalgorithm make decisions prematurely.17. One could also experiment encodings inverted problems. leave future work.18. theory, corresponding notion backward invariant, property goal states preservedtraversing transitions backwards. Symmetrically, backward invariants could used enhanceperformance forward PDR. practice, however, standard invariants typicallyuseful, rarely non-trivial binary clause backward invariant planning benchmarks.19. explained observing SAT-solver necessarily construct successor statefirst choosing action (or set actions, case par), would fully determinesuccessor. starts deciding state variables successor, invariants become useful.296fiProperty Directed Reachability Automated PlanningExample 4. Consider run algorithm forward direction encoding SPseq .encoding action variables occur unprimed part transitionclauses seq , given state s, assignment = X A, already storesinformation action applied next and, therefore, fully determinesvalue state variables X 0 successor. result, contrary intuition,evaluation extension querySAT ?[ Lits(s) seq (L)0 ]boil choosing action applicable state (s X) originalplanning task, successor state would satisfy clauses L, insteadinvolves choosing action applied already determined successorsuccessor (as valuation X 0 ) chosen action (as valuation A0 ) togethersatisfy clauses (L)0 , which, general, span whole signature 0 . seethat, sense, decisions made one step early.observed marked improvement performance minireachIC3 combinedencodings extended tool preprocessing step detects auxiliarytransition variables unprimed part transition clauses re-encodesprimed part order avoid committing decisions prematurely demonstratedexample above. Formally, given STS = (, I, G, ), auxiliary transition variablesAux variables appear G and, primed, shared0 . meansAux 0 = 0 \ (Vars(I 0 ) Vars(G0 ) (Vars(T ) Vars(T 0 ))).action variables SPseq encoding example auxiliary transition variables.every transition clause c , preprocessing step identifies literals l cVars(l) Aux turns l l0 . soundness transformation easyestablish.5.2.3 Results Experimentresults first experiment found Figure 3. several observations made. foretold, forward direction generally successfulbackward. Within time limit 180 seconds, five systems solves problems forward direction backward direction. see backwarddirection, invariants help improve performance PDRplan. Nevertheless, withindirection minireachIC3 combined Mp encoding successful.successful system PDRplan forward direction. solves 8.6 percent problemssecond best system, minireachIC3 combined Mp encoding forwarddirection. Although consider results definitive answer PDRplanvs. encodings question,20 decided focus PDRplan forward direction(most of) subsequent experiments.overall trends captured Figure 3 time respected comparison performed level individual problem domains (comparing number20. instance, replacing Minisat minireachIC3 recent efficient SAT-solver couldchange picture certain degree.297fiSuda14001000minireachIC3(seq)minireachIC3(par)minireachIC3(SASE)minireachIC3(Mp)PDRplan1200problems solved1200problems solved1400minireachIC3(seq)minireachIC3(par)minireachIC3(Mp)minireachIC3(SASE)PDRplan+iPDRplan800600100080060040040020020000110time (seconds)100110time (seconds)100Figure 3: Comparing PDRplan minireachIC3 combined encodings. Numberproblems solved within given time limit shown, separately backwarddirection (left) forward direction (right).problems solved 180 seconds), nevertheless notable exceptions worthmentioning.LOGISTICS domain PDRplan behaves better backward directionwithout invariants. best system domain, however, minireachIC3Mp encoding forward direction.relatively difficult 2011-BARMAN domain almost fully solved (19 20problems) PDRplan backward direction invariants. second bestsystem domain minireachIC3 par encoding backward direction7 problems solved.following among domains PDRplan best system: 1998MYSTERY (minireachIC3 SASE Mp encodings forward directionsolve 5 problems more), 2004-PHILOSOPHERS (18 problems solvedminireachIC3 par Mp encodings forward direction), 2011VISITALL (minireachIC3 Mp encoding solves 4 problems).several domains minireachIC3 Mp encoding betterbackward direction forward direction. difference pronounced2006-OPENSTACKS, 2011-FLOORTILE.observation last point accord Mp encoding usedMp planner itself. Rintanen (2012) describes effectively depth-first backwardchaining planning algorithm inside SAT-solving framework. seen298fi1200120011001100problems solvedproblems solvedProperty Directed Reachability Automated Planning1000900800ind_offmin_offdefault700600110time (seconds)1000900800700cp_offqueuedefault600500100110time (seconds)100Figure 4: Tuning PDRplan. effect explicit (inductive) reason minimization (left),clause propagation queue tie-breaking strategy (right).close backward PDR coupled encoding. hypothesizesuitability Mp encoding backward direction search emerges also PDR.5.3 Tuning PDRplansecond experiment (see Figure 4) focused several features standardPDR tried established importance solving planning problems. usedPDRplan forward direction 180 seconds time limit. measured effectfeature separately reference configuration denoted default.configuration one used previous experiment.5.3.1 Explicit (Inductive) Reason Minimizationexplicit minimization mean optional stage three reason computationextend procedure, enhanced induction described Section 4.2.Figure 4 (left) compare performance default configuration, reliesinductive version reason minimization (Pseudocode 4), configuration ind off,use induction implements minimization described Pseudocode 3,configuration min off, skips optional stage three altogether.see positive effect explicit minimization slight consistentalong time axis, induction starts pay global scale time limitexceeds 100 seconds. 180 seconds mark ind configuration solved 1.0 percentfewer min configuration 2.4 percent fewer problems default.Per domain view reveals induction especially important success 2000BLOCKS, 2004-PHILOSOPHERS, 2008-CYBER-SECURITY. domains2002-ZENOTRAVEL 2008-TRANSPORT better turn minimization completely,also domains, 1998-MYSTERY 2006-TRUCKS, paysminimize, inductively. last two categories, however, difference never299fiSudaproblem two per domain thus could potentially equalized withinhigher time limit.Interestingly, total 1561 problems, execution default inddiverged 145 problems.21 means problems inductionhelp minimize reasons beyond achieved non-inductive minimization.give another statistics, note whole problem set callextend procedure inductive minimization removes 1.49 literals computes reason50.60 literals average. non-inductive minimization min removes 1.44 literalsgenerates reason 51.22 literals average.5.3.2 Clause PropagationFigure 4 (right) compare default configuration configurationclause propagation turned (cp off). see clause propagation slows PDRplan slightly without clear benefit 180 seconds mark. Although laterindependent experiment 1800 second time limit showed clause propagationuseful planning problems, questionable whether effect justifies relativelyhigh effort connected implementing technique.22closer look reveals 28 percent tested problems clause successfully pushed forward 180 seconds bounded runs. may seemcontrast experience hardware model checking clause propagation playskey role. main effect there, however, lies speeding convergence PDRunsatisfiable problems. Since 99 percent planning benchmarks satisfiable, role clause propagation cannot demonstrated. fact, also independentlyconfirmed experiment minireachIC3 satisfiable hardware benchmarks23clause propagation beneficial forward direction.5.3.3 Stack vs. Queue Tie-breakingevaluate effect strategy breaking ties popping obligationsset Q (see Section 3.6.4). stack strategy used default configurationcompared curve queue strategy Figure 4 (right). queue strategysolves 5.9 percent fewer problems total. However, 18 problems solvedqueue strategy (and 85 problems solved stack strategy).interesting observations per domain scope probably59 problems (out 60) 2000-BLOCKS domain solved stack strategycompared 36 solved queue strategy,2 problems (out 20) 2011-BARMAN domain solved queue strategycompared 0 problems solved stack strategy.21. either generating different number obligations successful termination differingwhether successfully terminated 180 seconds mark.22. final comparison planners (see Section 5.5) clause propagation responsible 6 additional problems scored PDRplan.23. benchmarks Hardware Model Checking Competitions 20072012 (Biere, Heljanko, Seidl, &Wieringa, 2012) time limit 100 seconds.300fiProperty Directed Reachability Automated Planning13001 = default2 = 1 + lfcc3 = 2 + side4 = 3 + keep1200problems solved11001000900800700600110time (seconds)100Figure 5: Improving PDRplan. default configuration progressively extended turning three different techniques.Preferring explore longer paths short ones unpleasant side effectalso plans discovered stack strategy tend longer. Measured 1055problems solved strategies, plans generated stack strategy average24 percent longer.detailed discussion topic plan quality postponed till Section 5.6.5.4 Improving PDRplanpurpose third experiment evaluate three improvements proposedSection 4.5. successively: 1) lazy false clause computation (lfcc), 2)sidestepping technique (side), 3) keeping obligations iterations (keep). Figure 5displays effect progressively enabling three techniques presented order.see varying degrees technique represents improvement successiveconfiguration solves problems.different perspective provided Table 2 also reveals many problemsuniquely solved one two successive configurations. shows noneimprovements unambiguous across whole problem setexceptions prevailing trends.best highlighted level individual domains. instance,number solved problems drops 2000-BLOCKS 2008-CYBER-SECURITYlazy false clause computation (configuration 2), improved subsequentlyenabled techniques. Sidestepping (configuration 3) makes performance worse 2002DRIVERLOG, 2004-SATELLITE, 2008-CYBER-SECURITY. hand,technique represents huge improvement 2004-OPTICAL-TELEGRAPH domain301fiSudaconfiguration1 = default2 = 1 + lfcc3 = 2 + side4 = 3 + keeptotal1145118011951212delta351517gained556742lost205225Table 2: Number problems solved within 180 seconds (total). difference (delta) two successive configurations decomposed additionally solved problems(gained) problems solved without improvement (lost).15001400problems solved1300120011001000900800700FFLAMA-2011MpPDRplan1.1600500110100time (seconds)1000Figure 6: Comparing final version PDRplan planners. Showing numberproblems solved within given time limit.(from 2 14 problems solved) 2004-PHILOSOPHERS (from 11 29 problemssolved). Finally, keeping obligations (configuration 4) detrimental performance2011-FLOORTILE domain (the number solved problems drops 19 13),technique, example, helps recover 2008-CYBER-SECURITY problemslost due sidestepping.5.5 Comparing Plannerscompared improved PDRplan configuration 4 previous experimentdenoted PDRplan1.1 following planners:planner FF (Hoffmann & Nebel, 2001) baseline representative heuristicsearch (Bonet & Geffner, 2001) planners. used version 2.3, enhanced input302fiProperty Directed Reachability Automated Planningmodule make cope large problems recent IPC domains.default parameters FF used.planner Fast Downward (Helmert, 2006), current state art heuristicsearch planner. used configuration LAMA-2011 (Richter & Westphal, 2010),winner satisficing track IPC 2011.Mp planner (Rintanen, 2012), probably current best representativeplanning satisfiability approach (Kautz & Selman, 1996). used version 0.99999default parameters.experiment time limit increased 1800 seconds.overall performance planners seen Figure 6. planner FFfast startup solves problems (952) within one second. However, FFworst planners make use additional time solves fewest problems(1247) total. opposite side stands LAMA-2011 slowest startup (566problems within one second), best total (1437). PDRplan1.1 Mp closeperformance beginning PDRplan1.1 solves 741 Mp 790problems within one second end total PDRplan1.1 solves 1333 problemsgaining slight edge Mp 1310 problems solved.Table 3 shows domain-by-domain decomposition results. seeseveral domains PDRplan1.1 solved problems four planners, namely 2000-BLOCKS, 2002-FREECELL, 2004-PIPESWORLD-NOTANKAGE,2006-TRUCKS domains. domains 2004-PHILOSOPHERS, 2006-PATHWAYS,2006-STORAGE completely solved PDRplan1.1 Mp. hand, comparatively poor performance PDRplan1.1 observed 1998-LOGISTICS1998-MPRIME domains, also 2011-PARKING (shared FF) 2008+2011SOKOBAN (shared Mp) domains.5.6 Plan QualityIPC 2008 (Helmert, Do, & Refanidis, 2008) introduced criterion measuring plannerperformance takes account quality obtained plans. every problemsolved, planner aggregates score computed ratio c /c, c cost24returned plan c cost best known plan (either plan computed beforehandcompetition organizers best plan found participating systems).viewing results previous experiment lenses criterion,one discovers PDRplan1.1 drops second place last.reviewed previously discussed features improvements discoveredconfiguration PDRplan1.1 best possible respect plan quality.particular, switching queue tie-breaking strategy (we denote respectiveconfiguration PDRplan1.1+queue) aggregated score planner improves. slight24. mentioned before, consider action costs paper, so, setting, cost plansimply equal length.303fiSuda1998-GRID1998-GRIPPER1998-LOGISTICS1998-MPRIME1998-MYSTERY2000-BLOCKS2000-ELEVATOR2000-LOGISTICS2000-FREECELL2002-DEPOTS2002-DRIVERLOG2002-ZENOTRAVEL2002-FREECELL2004-AIRPORT2004-PIPESWORLD-NOTANKAGE2004-PIPESWORLD-TANKAGE2004-OPTICAL-TELEGRAPH2004-PHILOSOPHERS2004-PSR2004-SATELLITE2006-OPENSTACKS2006-PATHWAYS2006-PIPESWORLD2006-ROVERS2006-STORAGE2006-TPP2006-TRUCKS2008-CYBER-SECURITY2011-BARMAN2008+2011-ELEVATORS2011-FLOORTILE2011-NOMYSTERY2008+2011-OPENSTACKS2008+2011-PARCPRINTER2011-PARKING2008+2011-PEGSOL2008+2011-SCANALYZER2008+2011-SOKOBAN2008+2011-TRANSPORT2011-VISITALL2008+2011-WOODWORKINGTOTALsize52035353060150366022201920505050142950363030504030303030205020205050205050505020501561PDRplan1.152018251960150365721181920404537142950283030323930302730640141449508504611279501333FF520353418481503660211819193832171414423430202140182812405010750507504440384501247LAMA-20115203535235515036602220191933444214135036302940401930153020506105050205050484920501437Mp52032341946150364422201915494238142950351930254030301930850201918502050489260501310Table 3: Number problems solved within 1800 seconds, grouped domain. highlighted entries PDRplan1.1 solves problems sharesfirst place one planner. save space entries IPC 2008 domainsrecurring later IPC 2011 merged respective entries IPC 2011.304fiProperty Directed Reachability Automated Planning13001200aggregated score11001000900800700FFLAMA-2011MpPDRplan1.1PDRplan1.1+queue600500110100time (seconds)1000Figure 7: Comparing planners respect plan quality. Showing score aggregated planner within given time limit.improvement also observed lazy false clause computation turnedPDRplan1.1. Interestingly, changes bring combined benefit.25Figure 7 shows aggregated scores runs previous experiment togetherrun PDRplan1.1+queue.26 Although PDRplan1.1+queue solves 1263 problems1800 seconds (compared 1333 solved PDRplan1.1), aggregates score 1141.1points PDRplan1.1 reaches 1041.4. means former configuration catchesMp, aggregates 1102.7 points.note statistics taken grain salt,provide plan quality view satisficing runs planners. None systemsexplicitly attempting find short plans making use fact time limit1800 seconds. Moreover, even setting plan quality typically improvedafterwards post-processing discovered plans (Balyo & Chrpa, 2014). laterincorporated polynomial Action Elimination algorithm (Nakhost & Muller, 2010)plan post-processor PDRplan1.1 able improve aggregated score7.0 percent. thorough investigation quality plans produced PDRplan,well PDR general, left future work.25. seems already carefully advancing PDRplan1.1+queue benefits speed providedlazy false clause computation, whereas stack strategy helps wait precisereasons (having lfcc turned off) allow planner search deep often.26. reference values best known cost c collected runs figure.305fiSuda5.7 Anytime PDR Optimal PlanningRecall PDR adjusted perform optimal planning turning obligationrescheduling technique (and sidestepping).27 Alternatively, modify PDR continuecomputation first plan found, afterwards reschedule obligationspart improving plan.28 anytime version PDR progressively reportsbetter better solutions finally terminating guarantee last reportedplan optimal one. happens reaches iteration equaling lengthbest discovered plan.experiment focused optimal planning respect sequential plansemantics.29 compared performance anytime version PDRplan1.1 (countingsolutions provably shown optimal) BJOLP (Domshlak et al., 2011), optimizing version Fast Downward, optimizing configuration Mp.30 Orderingplanners number problems optimally solved within 1800 seconds obtain:1. BJOLP 668 problems solved,2. PDRplan1.1-anytime 360 problems solved,3. optimizing Mp 325 problems solved.order preserved level individual domains, except several domainsMp end last. Mp solves optimally problems 1998-MYSTERY,2000-BLOCKS, 2008-CYBER-SECURITY, also 1998-MPRIME domain.margin exceptionally pronounced last domain, Mp solves 32 35problems, BJOLP solves 21 PDRplan1.1-anytime 20 problems.5.8 Detecting Unsatisfiable ProblemsAlthough main focus planning community, reflected InternationalPlanning Competition, traditionally satisfiable problems only, recently,importance detecting unsatisfiable instances getting recognized addressed(Backstrom, Jonsson, & Stahlberg, 2013; Hoffmann, Kissmann, & Alvaro Torralba, 2014).According experience hardware model checking, PDR particularlystrong detecting unsatisfiable instances. last experiment, tried establishedwhether also holds planning.test problems, used collection Hoffmann et al. (2014) consisting 8domains total 183 unsatisfiable benchmarks. Table 4 shows domain-by-domaincoverage results (for time limit 1800 seconds) following configurations PDR:27. PDR looks minimal length witnessing paths respect encoded transition relation .Using encoding sequential plan semantics (as implicitly done PDRplan) ensures optimizingnumber actions resulting plan.28. Formally, keep obligation (s, i) length path initial state sI plus valueindex exceed length best plan found far.29. choice ruled systems like SatPlan (Kautz et al., 2006) SASE (Huang et al., 2012)comparison, optimize respect parallel plan semantics.30. uses sequential encoding (option -P 0), skip horizon length (option -S 1), evaluatessingle horizon length time (option -A 1).306fiProperty Directed Reachability Automated Planningsize3UNSATBottleneckMysteryUnsNoMysteryUnsPegsolUnsRoversUnsTilesUnsTPPTotal253092524252025183PDRplanfwd bwd10101924491211148111100567579minireachIC3 parfwd bwd noind nocp111511525232022999931313614884112015120000463366947961blind15102024010566M&Scf1 cf2151510219625252424179101099119 119Table 4: Unsatisfiable benchmarks. Number problems solved within 1800 seconds,grouped domain. Best scores per domain typeset bold.PDRplan, configuration first experiment (Section 5.2),forward (fwd) backward (bwd) direction.minireachIC3 combined par encoding (with invariants), also directions (fwd, bwd), and, backward direction, also inductive minimizationreplaced non-inductive version (noind), and, independently, clausepropagation turned (nocp).addition, Table 4 also contains entries adopted work Hoffmann et al. (2014).belong Fast Downward planner equipped three different heuristics:Configuration blind uses heuristic returns 0 goal states 1 elsewhereessentially proves unsatisfiability enumerating reachable states.Configuration cf1 cf2 use version merge-and-shrink (M&S) heuristic(Helmert, Haslum, & Hoffmann, 2007), specifically adapted detecting unsatisfiableproblems (Hoffmann et al., 2014). two best performing configurationsexperiment Hoffmann et al. (2014).note Hoffmann et al. (2014) also used time limit 1800 seconds, ranexperiment 2.20 GHz Intel E5-2660 machines 4 GB memory limit. meanslast three configurations could potentially solve problems setup.5.8.1 Results Experimentcomparing various configurations PDR, see backward direction generally successful forward, although consistently acrossdomains. Interestingly, minireachIC3 par encoding backward directionsolves problems PDRplan. fact, preliminary test lower time limitshowed benchmarks configuration strongest consideredfirst experiment (Section 5.2). Finally, also see induction clausepropagation consistently helpful solving unsatisfiable problems.307fiSudaPDR come winner comparison heuristic approachHoffmann et al. (2014), although able solve problems four domains.two domains, however, PDR even dominated blind search, i.e. simple statespace enumeration. seems benchmarks needed establishtwo approaches generally successful detecting unsatisfiable planning problems.5.8.2 Performance UnsTilesPDR particularly bad enumerating states little possibility generalizeencountered ones. manifested clearly UnsTiles domain,PDR could solve single problem within given time limit. domainrepresents well known sliding puzzle contains 10 problems 8 tiles 3 3grid 10 problems 11 tiles 3 4 rectangular grid.31 ran PDRplanforward direction end one smaller, 3 3 instances. took daycomplete, processed 701704 obligations terminated clauses layer11, total 181440 clauses, pushed layer 12 clause propagation phaseiteration 11.Notice 181440 = 9!/2 half size state space. classical resultJohnson Story (1879), state space sliding puzzle decomposes exactlytwo connected components depending value certain parity function definedstates. Unsatisfiable instances parity initial stategoal state different. state space consists two components,unsatisfiable instance PDR must converge (with repeating layer) CNF descriptioncomponent containing goal state. see, description large (innumber clauses) component (in number states), thussliding puzzle PDR benefit symbolic representation via CNF.5.9 SummaryLet us summarize empirical findings obtained section. state generalclaims keeping mind are, fact, derived performance twoparticular benchmark sets: main set 1561 mostly satisfiable IPC problemsset 183 unsatisfiable problems used last experiment.planning PDR pays look plan initial state towardsgoal vice versa. words, progression preferable regressionPDR. holds even invariants employed, help improveperformance regression considerably.Unsatisfiable instances, however, typically better detected via regression.satisfiable problems SAT-solver free variant PDR planning-specificextend procedure (as described Section 4) generally successfulstandard version algorithm combined various encodings.31. famous 15 tiles puzzle 4 4 grid (Wikipedia, 2014).308fiProperty Directed Reachability Automated PlanningNeither clause propagation inductive minimization, two techniques normally deemed essential performance PDR, helpful satisfiableplanning problems. techniques are, however, useful detecting unsatisfiability.various ways tuning PDR improving performance planning.tried identify configuration algorithm would successfulsetup later used PDRplan comparison planners.techniques turned improvement average, however,exceptions form individual problems domains performance degraded.represent interesting opportunity future investigations (see Section 7).32compared planners PDRplan shows respectable performance. fact,performance comparable even slightly better planner Mp,state art representative planning satisfiability approach. also solvesproblems tested planners several domains. Although PDRplanreach score LAMA-2011, presented results quite encouraging,especially given PDR relatively young algorithm potentialimprovements.plan quality important number problems solved,pays switch stack queue tie-breaking strategy PDR.configuration able keep improve upon performance Mprespect plan quality metric based aggregated score.Another option improving plan quality employ post-processing stepattempts remove redundant actions generated plan (Balyo & Chrpa, 2014).PDR easily modified look increasingly better solutions given sufficient time eventually terminate optimality guarantee (with respectplan length). Although LAMA-2011 much successful finding optimal plans,fact PDRplans natural encoding follows sequential plan semantics couldreason PDRplan scores higher Mp respect.6. Related Work: Graphplanshown paper PDR algorithm closely related planningsatisfiability approach, although planning-specific implementation extendprocedure explicit encoding present. also highlighted connection heuristicsearch planning, direct correspondence side explicitly explored reachablestates little subtle one side guiding layers, seencontinually refined admissible heuristic estimator. would like discussperhaps surprising relation PDR well-known Graphplan planning algorithmBlum Furst (1997).32. one hand, looking problems particular technique leads poor performance,identify weak points attempt improve technique. hand, insteadrelying overall best configuration also try decide prior running algorithmpromising set enabled features given problem based problems characteristics.309fiSudamain data structure Graphplan planning graph, layered structure compressed representation reachability information given problem. individuallayers graph over-approximate set states reachable given number setsparallel actions computed incrementally propagation called exclusionrelations actions state variables. planning graph searched planbackward-chaining strategy, starting goal set regressing it, senseparallel plan semantics, subgoals violate exclusions respectivelayer. Candidate (sub)goal sets shown lead plan within specific numbersteps memoized avoid repeating work future.already shown Rintanen (2008a) exclusion relations planning graphequivalent binary clause representation k-step reachability information. meanscould represented inside PDR binary clauses respective layers. claimadditionally also memoized goal sets could stored layer clauses respective position: clause simply negation conjunctive descriptiongoal set. two observations mind, stateGraphplan essentially version PDR specific implementationextend procedure based parallel plan semantics.correspondence allows us highlight differences two algorithms beyond preferred semantics emulated encoding.planning graph built systematically Graphplan search planstarted (resumed) full new layer computed, PDR layerconstruction lazy, triggered unsuccessful path extensions.Goal set memoization Graphplan, however, follows lazy pattern.Graphplan attempt reduce size memoized goal set, so, apartbinary clauses, deals long clauses representing negationgoal set. Notice would PDR correspond returning full reason setLits(s) unsuccessful extension state s.subset memoization later proposed Long Fox (1999), corresponds finding smaller reason sets.Graphplan searches plan backward direction. PDR, directionchanged, forward successful.33equivalent obligation rescheduling Graphplan algorithmalways searches optimal plans (with respect parallel plan semantics).wavefront heuristic described Long Fox (1999) enhancementGraphplan, however, seems overcome limitation, similarly rescheduling.realization PDR related Graphplan made us curious differencestwo algorithms practice. set small experiment compared PDR33. Changing search direction Graphplan running inverted problem (see Section 4.4)possible, would likely lead fewer problems solved. related already mentionedobservation problems non-trivial backward invariants benchmark set.310fiProperty Directed Reachability Automated Planningmature implementation Graphplan within planner IPP (Koehler, 1999).order bring PDR close possible Graphplan does, representedminireachIC3 combined simple parallel encoding SPpar (see Section 2.6) enhancedbinary clause invariant (as explained Section 5.2). ran minireachIC3backward direction obligation rescheduling turned off, so, similarly IPP,looking optimal plans. measuring number problems solved (outmain problem set described Section 5) within 180 seconds, obtained 466 solved IPP484 configuration minireachIC3. noted IPP erroneouslyreports UNSAT problems PARCPRINTER WOODWORKINGdomains counted failures. minireachIC3, hand, solvesproblems domains, score lowered 94 problemsobtain fair comparison problem set excludes two domains.Notice performance IPP 466 solved problems quite low comparedbest configuration PDRplan1.1, solves 1212 problems within 180 seconds.raises question whether Graphplan could improved enhancingobligation rescheduling trick. able confirm experimentally. relativelystraightforward modification IPP retries candidate goal set time + 1failed time able solve 676 problems.34 Thus obligation reschedulingseen answer long standing question posed last remark originalGraphplan paper Blum Furst (1997), i.e., way trade plan quality speed.7. Discussion: Closer Look Two Domainsfact PDR maintains reachability information organized layers usessimple language propositional clauses (CNF) express corresponding constraintsoften allows us obtain additional insights algorithm traverses searchspace inspecting layers generated concrete problems. especially rewardingcases PDR seems struggling relatively simple problem, oftenleads discovery ideas future improvements. section closer lookbehavior PDR two simple domains. conjecture algorithm couldimproved employing expressive constraint formalism CNF.7.1 1998-LOGISTICStask LOGISTICS domain transport packages locations. Locationsbelong cities within city trucks may used move packages helpload-truck, drive-truck, unload-truck actions. Additionally, locationsdesignated airports airplanes may used transport packages airportspossibly across cities via load-airplane, fly-airplane, unload-airplane actions.Although LOGISTICS domain generally considered simple one, Table 3(page 304) reveals relatively poor performance PDRplan LOGISTICS problems.two initial findings inspection layer clauses generated PDR,shed light going hood.34. Also performance corresponding configuration minireachIC3 goes mentioned484 733 solved problems within 180 seconds obligation rescheduling turned on.311fiSudaPDR often generates long clauses.typically many distinct (although similar) ways achieve subgoalneed taken account, large reason sets computedsubsequently long clauses derived. example, package needs transportedone city another, available airplanes potentially usedpurpose. often encounter derived clauses likesubg at(apn 1 , apt) at(apn 2 , apt) . . . at(apn n , apt)(7)expressing subgoal subg derived yet, least oneavailable airplanes apni need present airport apt.PDR generates many similar clauses.Even action one precondition false current state, onepreconditions reflected computed reason unsuccessful extension.Thus many actions available achieving subgoal, sometimes many clausesneeded PDR tries find right achieving action satisfy preconditions.addition clause (7) could see PDR subsequently derive followingclauses layer:subg in(obj , apn 1 ) at(apn 2 , apt) . . . at(apn n , apt),subg at(apn 1 , apt) in(obj , apn 2 ) . . . at(apn n , apt),...(8)subg at(apn 1 , apt) at(apn 2 , apt) . . . in(obj , apn n ).Note although pattern indicates n different clauses, worstcase 2n clauses potentially derivable arbitrary choice at(apn , apt)in(obj , apn ) every i.Although far described PDR algorithm based propositional logic,believe could generalized take advantage first order constraints. Considerclause (7) above. equivalent first order version (aware type airplane) would readsubg Apn airplane . at(Apn, apt),much succinct.35 Moreover, could potentially derived analyzingaction schemes unload -airplane(Obj , Apn, Loc), . . . , etc., instead iteratingmuch larger set instantiated actions. Working missing details interestingdirection future research. inspiration could found work Ranise (2013),whose setting security policy analysis close automated planning.Another independent direction enhancing expressive power used constraintscould introduction conjunctive literals. Notice set clauses (8) is,fact, subsumed single generalized clausesubgn_i=1in(obj , apn ) at(apn , apt),35. Symbols starting uppercase letter, like Apn, stand first order variables.312fiProperty Directed Reachability Automated Planningallow conjunctions place single literals. envisioned generalizationPDR, conjunctions would naturally come precondition lists actions,use could help solving, e.g., LOGISTICS problems efficiently. course,details would need worked out.7.2 1998-GRIPPERGRIPPER simple domain models robot two grippers trying moveballs one room another. domain fully solved PDRplan defaultconfiguration. fact, although individual problems differ size, PDRplan able(thanks obligation rescheduling) solve iteration 3 main loop.36reason seems virtual independence individual goals,considered one one PDR. conjecture algorithm solves problemsGRIPPER domain polynomial time.Despite simplicity, GRIPPER known difficult solve optimally heuristicsearch planners (see Helmert & Roger, 2008). also holds PDR, exhibitsexponential behavior attempting find minimal length plan, i.e., runobligation rescheduling (and sidestepping) turned off. demonstrate reason, let usabstract simplify GRIPPER bit consider domain taskachieve n independent goals set {g1 , . . . , gn }, achieving particular goaltrivial, individual goals achieved one one.domain, PDR eventually need express via layer Li least (n i)goals already achieved. counting constraint inherently large clausaldescription. Namely, set Li takes form^gj0 . . . gji ,conjunction ranges (i + 1)-element subsets {j0 , . . . , ji } {1, .. . , n}.nsize layer Li is, therefore, proportional binomial coefficient i+1, which,particular, means size layer Lbn/2c grows exponentially n.already suggested Helmert Roger (2008) phenomenon could overcomeexploiting symmetries (Fox & Long, 1999) inherently present problem. couldparticularly rewarding PDR, layer clauses (although derived responseunsuccessful extensions arbitrary reachable states) logically depend goalcondition G, symmetries typically reside. Thus unlike Fox Long (1999),define symmetric objects indistinguishable one anotherterms initial goal configuration, one could PDR use stronger notionsymmetry derived goal condition only.8. Conclusionpaper examined PDR, novel algorithm analyzing reachability symbolic transition systems, perspective automated planning. main contribution lies recognizing part algorithms work normally delegated36. domains fully solved PDRplan particular fixed iteration 2002-ZENOTRAVEL(iteration 3), 2004-PHILOSOPHERS (iteration 6), 2006,2008,2011-OPENSTACKS (iteration 4).313fiSudaSAT-solver can, context planning, implemented directly polynomial timeprocedure. experimentally confirmed modification, well severalproposed improvements, boost performance PDR planning benchmarks.implementation algorithm called PDRplan able compete respectablystate art planners, solving problems several domains.Despite already promising results, still room development. Onedirection work extending PDRplan towards richer planning formalisms. example,believe extend procedure enhanced cope conditional effects actionsstraightforward way. Efficiently dealing action costs domain axioms could turndifficult. Another promising direction idea generalize PDRexpressive constraint language CNF. clear stronger constraintsimply better guidance towards goal, devising efficient method combining newconstraints old ones obviously challenging task. seems, however,departure beyond clausal level could simpler solution inside planningspecific framework extend procedure it, perhaps, within general purposeconstraint solvers.Acknowledgmentsthank Jussi Rintanen useful comments remarks, well helpMp encoder. also thank Tomas Balyo providing us SASE encodingtool. Finally, want thank anonymous reviewers insightful suggestionsMalte Helmert help preparation final version text.research partially supported Czech Science Foundation projectP103-10-1287.Appendix A. Pseudocode Improvements Section 4.5Pseudocode 6 displays stage one procedure extend+ , enhancement extendprocedure lazy false clause computation technique (Section 4.5.1) supportsidestepping (Section 4.5.2). Stage two extend+ meant supplementedstage original extend procedure (Pseudocode 3) stage three employesinductive minimization described Section 4.2 (Pseudocode 4).Pseudocode 7 details workings PDRplan1.1. help extend+ procedure realizes sidestepping (Section 4.5.2). Moreover, incorporates techniquekeeping obligations iterations (Section 4.5.3). clause propagation phaseidentical one already presented Pseudocode 5.314fiProperty Directed Reachability Automated PlanningPseudocode 6 Stage one extend+ (s, i):Input:Obligation (s, i), i.e. state index i, 6|= Li1Output:Either obligation (t, 1) successor |= Li1 ,obligation (t, i) successor s, |= Lisatisfies strictly clauses Li1 s,inductive reason r Lits(s)1:2:3:4:5:6:7:8:9:10:11:12:13:Ls {c Li1 | 6|= c} /* Clauses false */Rnoop {c | c Ls } /* reasons noop action */assert Rnoop 6= /* Follows contract caller */R {Rnoop } /* set reason sets collected far */aside noop /* Current best candidate sidestepping (noop dummy value) */xside |Ls | /* Score current best candidate */foreachpre sa {l pre | 6|= l} /* Preconditions false */apply(s, (, eff )) /* Ignore preconditions apply effects */Ls,t {c Ls | 6|= c} /* lazy approach: clauses false */Ls,t = Ls /* improvement */continue /* nothing: reason set would subsumed Rnoop */14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:pre sa = |Ls,t | < xside /* action promising . . . */Lt {c Li1 | 6|= c} /* . . . must compute full Lt */Lt =return (t, 1) /* positive part: returning true successor */Lt = Ls,t |= Li /* false clauses besides Ls,t */asidexside |Ls,t |elseLt Ls,t /* Save time using Ls,t instead full Lt */Lt0 {c Lt | c pre sa = } /* False clauses non-subsumed reason */Ra {{l} | l pre sa } {{l | l c l 6 eff } | c Lt0 }R R {Ra } /* Record reason set */xside < |Ls |30:assert aside 6= noop31:return (apply(s, aside ), i) /* Successfully sidestepping best candidate */29:32:/* Continue stage two Pseudocode 3 stage three Pseudocode 4 */315fiSudaPseudocode 7 Algorithm PDRplan1.1(X, sI , G, A):Input:positive STRIPS planning problem P = (X, sI , g, A)Output:plan P guarantee plan exists1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:19:20:21:22:23:24:25:26:27:28:29:30:31:L0 {{p} | p g} /* goal cube treated set unit clauses */foreach j > 0 : LjQ {(sI , 0)}k = 0, 1, . . ./* Path construction: */(s, i) Q kpop (s, i) Q minimal6|= LiQ Q (s, + 1)else = 0return PLAN FOUNDelse extend+ (s, i) returns obligation (t, j)assert j = 1 j = /* Either regular extension sidestep */Q Q {(s, i), (t, j)}elseextend+ returned reason r Lits(s)foreach 0 j : Lj Lj {r}/* Obligation rescheduling: */Q Q {(s, + 1)} /* Keep obligations + 1 > k till next iteration *//* Clause propagation: */= 1, . . . , k + 1foreach c Li1 \ Li/* Clause push check */sc {p 7 0 | p c} {p 7 1 | p (X \ c)}every : sc 6|= pre apply(sc , a) 6|= Li1Li Li {c}/* Convergence check */Li1 = Lireturn PLAN POSSIBLE316fiProperty Directed Reachability Automated PlanningReferencesBackstrom, C., Jonsson, P., & Stahlberg, S. (2013). Fast detection unsolvable planninginstances using local consistency. Helmert, M., & Roger, G. (Eds.), SOCS. AAAIPress.Backstrom, C., & Nebel, B. (1995). Complexity results SAS+ planning. ComputationalIntelligence, 11, 625656.Balyo, T., Bardiovsky, V., Dvorak, F., & Toropila, D. (2012). Freelunch planning library.Available http://ktiml.mff.cuni.cz/freelunch/.Balyo, T., & Chrpa, L. (2014). Eliminating redundant actions plans using SATMaxSAT. ICAPS 2014 Workshop Knowledge Engineering PlanningScheduling (KEPS). appear.Biere, A., Heljanko, K., Seidl, M., & Wieringa, S. (2012). Hardware model checking competition 2012. Web site, http://fmv.jku.at/hwmcc12/.Blum, A., & Furst, M. L. (1997). Fast planning planning graph analysis. Artif.Intell., 90 (12), 281300.Bonet, B., & Geffner, H. (2001). Planning heuristic search. Artif. Intell., 129 (12), 533.Bradley, A. R. (2011). SAT-based model checking without unrolling. Jhala, R., &Schmidt, D. A. (Eds.), VMCAI, Vol. 6538 Lecture Notes Computer Science, pp.7087. Springer.Bradley, A. R., & Manna, Z. (2007). Checking safety inductive generalization counterexamples induction. FMCAD, pp. 173180. IEEE Computer Society.Clifford, R., & Popa, A. (2011). Maximum subset intersection. Inf. Process. Lett., 111 (7),323325.Domshlak, C., Helmert, M., Karpas, E., Keyder, E., Richter, S., Roger, G., Seipp, J., &Westphal, M. (2011). BJOLP: big joint optimal landmarks planner. SeventhInternational Planning Competition (IPC 2011), Deterministic Part, pp. 9195.Een, N., Mishchenko, A., & Brayton, R. K. (2011). Efficient implementation propertydirected reachability. Bjesse, P., & Slobodova, A. (Eds.), FMCAD, pp. 125134.FMCAD Inc.Een, N., & Sorensson, N. (2003). extensible SAT-solver. Giunchiglia, E., & Tacchella, A. (Eds.), SAT, Vol. 2919 Lecture Notes Computer Science, pp. 502518.Springer.Fox, M., & Long, D. (1999). detection exploitation symmetry planningproblems. Dean, T. (Ed.), IJCAI, pp. 956961. Morgan Kaufmann.Gazen, B. C., & Knoblock, C. A. (1997). Combining expressivity UCPOPefficiency Graphplan. Steel, S., & Alami, R. (Eds.), ECP, Vol. 1348 LectureNotes Computer Science, pp. 221233. Springer.Ghallab, M., Nau, D. S., & Traverso, P. (2004). Automated planning theory practice.Elsevier.317fiSudaHaas, A. R. (1987). case domain-specific frame axioms. Frame ProblemArtificial Intelligence, Proceedings 1987 Workshop Reasoning Action.Morgan Kaufmann.Helmert, M. (2006). Fast Downward planning system. J. Artif. Intell. Res. (JAIR),26, 191246.Helmert, M. (2009). Concise finite-domain representations PDDL planning tasks. Artif.Intell., 173 (56), 503535.Helmert, M., Do, M., & Refanidis, I. (2008). IPC 2008, deterministic part. Web site,http://ipc.informatik.uni-freiburg.de.Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics optimalsequential planning. Boddy, M. S., Fox, M., & Thiebaux, S. (Eds.), ICAPS, pp.176183. AAAI.Helmert, M., & Roger, G. (2008). good almost perfect?. Fox, D., & Gomes, C. P.(Eds.), AAAI, pp. 944949. AAAI Press.Hoffmann, J., Kissmann, P., & Alvaro Torralba (2014). Distance? cares? TailoringMerge-and-Shrink heuristics detect unsolvability. ICAPS 2014 WorkshopHeuristics Search Domain-independent Planning (HSDIP). appear.Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generationheuristic search. J. Artif. Intell. Res. (JAIR), 14, 253302.Howey, R., Long, D., & Fox, M. (2004). VAL: Automatic plan validation, continuous effects mixed initiative planning using PDDL. ICTAI, pp. 294301.IEEE Computer Society. Software available http://www.plg.inf.uc3m.es/ipc2011-deterministic/Resources.Huang, R., Chen, Y., & Zhang, W. (2012). SAS+ planning satisfiability. J. Artif. Intell.Res. (JAIR), 43, 293328.IPC(2014).International planning competition.icaps-conference.org/, accessed 19/05/2014.Website,http://ipc.Johnson, W. W., & Story, W. E. (1879). Notes 15 puzzle. American JournalMathematics, 2 (4), 397404.Kautz, H., Selman, B., & Hoffmann, J. (2006). SatPlan: Planning satisfiability.Working Notes 5th International Planning Competition, Cumbria, UK. Softwareavailable http://www.cs.rochester.edu/~kautz/satplan/.Kautz, H. A., McAllester, D. A., & Selman, B. (1996). Encoding plans propositionallogic. Aiello, L. C., Doyle, J., & Shapiro, S. C. (Eds.), KR, pp. 374384. MorganKaufmann.Kautz, H. A., & Selman, B. (1992). Planning satisfiability. ECAI, pp. 359363.Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logicstochastic search. Clancey, W. J., & Weld, D. S. (Eds.), AAAI/IAAI, Vol. 2,pp. 11941201. AAAI Press / MIT Press.318fiProperty Directed Reachability Automated PlanningKoehler, J. (1999). IPP Planning System ADL Resource-Constrained PlanningProblems. Habiliation thesis, University Freiburg.Long, D., & Fox, M. (1999). Efficient implementation plan graph STAN. J. Artif.Intell. Res. (JAIR), 10, 87115.Massey, B. (1999). Directions Planning: Understanding Flow Time Planning.Ph.D. thesis, University Oregon.McCarthy, J., & Hayes, P. J. (1969). philosophical problems standpointartificial intelligence. Meltzer, B., & Michie, D. (Eds.), Machine Intelligence 4, pp.463502. Edinburgh University Press.Nakhost, H., & Muller, M. (2010). Action elimination plan neighborhood graph search:Two algorithms plan improvement. Brafman, R. I., Geffner, H., Hoffmann, J.,& Kautz, H. A. (Eds.), ICAPS, pp. 121128. AAAI.Pettersson, M. P. (2005). Reversed planning graphs relevance heuristics AI planning.Planning, Scheduling Constraint Satisfaction: Theory Practice, Vol.117 Frontiers Artificial Intelligence Applications, pp. 2938. IOS Press.Ranise, S. (2013). Symbolic backward reachability effectively propositional logicapplications security policy analysis. Formal Methods System Design, 42 (1),2445.Richter, S., & Westphal, M. (2010). LAMA planner: Guiding cost-based anytimeplanning landmarks. J. Artif. Intell. Res. (JAIR), 39, 127177.Rintanen, J. (1998). planning algorithm based directional search. Cohn, A. G.,Schubert, L. K., & Shapiro, S. C. (Eds.), KR, pp. 617625. Morgan Kaufmann.Rintanen, J. (2004). Evaluation strategies planning satisfiability. de Mantaras,R. L., & Saitta, L. (Eds.), ECAI, pp. 682687. IOS Press.Rintanen, J. (2008a). Planning graphs propositional clause-learning. Brewka, G., &Lang, J. (Eds.), KR, pp. 535543. AAAI Press.Rintanen, J. (2008b). Regression classical nondeterministic planning. Ghallab,M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), ECAI, Vol. 178Frontiers Artificial Intelligence Applications, pp. 568572. IOS Press.Rintanen, J. (2012). Planning satisfiability: Heuristics. Artif. Intell., 193, 4586.Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: parallel plansalgorithms plan search. Artif. Intell., 170 (1213), 10311080.Suda, M. (2013a). DIMSPEC, format specifying symbolic transition systems. Website, http://www.mpi-inf.mpg.de/~suda/DIMSPEC.html.Suda, M. (2013b). Duality STRIPS planning. CoRR, abs/1304.0897.Suda, M. (2014). Property directed reachability automated planning. Web site, http://www.mpi-inf.mpg.de/~suda/PDRplan.html.Wikipedia (2014). 15 puzzle wikipedia, free encyclopedia. Web site, http://en.wikipedia.org/wiki/15_puzzle, accessed 19/05/2014.319fiJournal Artificial Intelligence Research 50 (2014) 105-140Submitted 07/13; published 05/14Finding Optimal Solutions Voting Game Design ProblemsBart de Keijzerdekeijzer@dis.uniroma1.itWeb Algorithmics Data Mining,Sapienza Universita di Roma,Rome, ItalyTomas B. Klost.b.klos@tudelft.nlAlgorithmics; Delft University Technology,Delft, NetherlandsYingqian Zhangyqzhang@ese.eur.nlDepartment Econometrics; Erasmus University Rotterdam,Rotterdam, NetherlandsAbstractmany circumstances multiple agents need make joint decision, votingused aggregate agents preferences. agents vote carries weight,sum weights agents favor outcome larger equalgiven quota, outcome decided upon. distribution weights leadscertain distribution power. Several power indices proposed measurepower. so-called inverse problem, given target distribution power,asked come gamein form quota, plus assignment weightsplayerswhose power distribution close possible target distribution(according specified distance measure).study solution approaches larger class voting game design (VGD)problems, one inverse problem. general VGD problem, goalfind voting game (with given number players) optimizes functiongames. inverse problem, example, look weighted voting gameminimizes distance distribution power among players giventarget distribution power (according given distance measure).goal find algorithms solve voting game design problems exactly,approach goal enumerating games class games interest. firstpresent doubly exponential algorithm enumerating set simple games.improve algorithm class weighted voting games obtain quadratic2exponential (i.e., 2O(n ) ) algorithm enumerating them. show improvedalgorithm runs output-polynomial time, making fastest possible enumeration algorithm polynomial factor. Finally, propose exact anytime-algorithmruns exponential time power index weighted voting game design problem (theinverse problem).implement algorithm find weighted voting game normalized Banzhafpower distribution closest target power index, perform experiments obtaininsights set weighted voting games. remark algorithm applicableoptimizing exponential-time computable function, distance normalizedBanzhaf index target power index merely taken example.c2014AI Access Foundation. rights reserved.fiDe Keijzer, Klos, & Zhang1. Introductionmany real-world settings involving multiple players come jointdecision, instance elections, need fair decision-making protocolsdifferent players different amounts influence outcome decision. weightedvoting game (WVG) often used decision-making protocol. weighted votinggame, quota given, player (or agent) game certain weight.total weight coalition agents smaller quota, coalition saidwinning, otherwise, losing.Weighted voting games arise various practical settings, political decisionmaking (decision making among larger smaller political parties), stockholder companies(where number shares determines amount influence), elections (e.g., USpresidential election, state regarded player weight equalnumber electors).weight player equal actual influence outcomedecisions made using weighted voting game. Consider example weightedvoting game quota equal sum weights players.game, players influence equal influence player regardless weighthas. Various power indices proposed literature, ways measureplayers (a priori) power influencing outcome voting game (see Banzhaf III, 1965;Dubey & Shapley, 1979; Shapley & Shubik, 1954). However, computing power indexturned challenge many cases: see work Algaba, Bilbao, Garca,Lopez (2003), Deng Papadimitriou (1994), Matsui Matsui (2001), Prasad Kelly(1990), De Keijzer (2009b) recent survey.paper, instead analyzing power agent voting game, investigate problem referred inverse problem (see Alon & Edelman, 2010)generalized apportionment problem (see Leech, 2003). call problemweighted voting game design problem. power index voting game design problem,given target power index agents, study designweighted voting game power agent close possible giventarget power index.motivation behind work practical one: desirable algorithmquickly compute fair voting protocol, given want agentspecified amount influence outcome. new decision making bodies mustformed, changes occur formation bodies, algorithm mayused design voting method fair possible.intuitive approach solving weighted voting game design problem wouldsimply enumerate possible weighted voting games n players. However, enumerating weighted voting games efficiently quite straightforward seems.even single weighted voting game infinite number weighted representations (the representation game listing quota weight player),enumerating games weighted representation option. address problem, prove existence of, exploit, new partial order class weightedvoting games allows us efficiently enumerate weighted voting games. enumeration method leads exact algorithm used solve weighted voting106fiFinding Optimal Solutions Voting Game Design Problemsgame design problem. Although algorithm runs exponential time, asymptoticallybig improvement naive approach runs doubly exponential time,show. Therefore, besides fact broaden understanding problemimprovement exponential time, algorithm allows us solve problem optimality small numbers players, find approximate solutions larger numbersplayers, thanks anytime property.1 implement algorithm powerindex voting game design problem power index choice (normalized)Banzhaf index. emphasize choice power index quite arbitrary: couldpick power index well, normalized Banzhaf index merely takenexample. use implementation illustrate applicability approachobtain relevant statistics set weighted voting games.next section define relevant concepts set notation. Section 3formally defines problem address, gives overview related work.Section 4, analyze problem present solution. First address design(monotonic) simple games Section 4.1. Then, important section (4.2),focus weighted voting game design. Section 4.3 concludes part paperimprovements wish discuss separately main ideas. Section 5,report experiments performed implementation main algorithm,Section 6 concludes paper.2. Preliminariessection, discuss required preliminary definitions results relatedtheory cooperative simple games.2cooperative game pair (N, v), N finite set players; subsets Ncalled coalitions, v : 2N R0 characteristic function gain function, mappingcoalitions non-negative real numbers. Intuitively, v describes much collective payoffcoalition players gain cooperate. set N also called grandcoalition. simple game cooperative game (N, v) codomain v restricted{0, 1}.3 context, coalition called winning coalition v(S) = 1, losingcoalition otherwise. cooperative game (N, v) monotonic v(S) v(T )pairs coalitions (S, ) 2N 2N satisfy . words: monotonicgame, value coalition decrease players added coalition.paper, concerned class monotonic simple games,denote Gmon . general, G class games, use G(n) denote class1. algorithm said anytime property if: (i) able provide solution anytimeexecution, (ii) solution quality improves longer algorithm runs, (iii) algorithmguaranteed output optimal solution eventually.2. Much information section found introductory text cooperative game theory(e.g., Peleg & Sudholter, 2003) simple games (e.g., Taylor & Zwicker, 1999). Throughoutpaper, assume familiarity big-O notation analysis algorithms, well knowledgebasic order-theoretic notions related graded partial orders. parts paper,basic knowledge computational complexity theory assumed well, although partscrucial understanding main results presented. cover topics section.3. purposefully exclude games losing winning coalitions, customary.reason including games make convenient later show particularstructure exists subclass simple games.107fiDe Keijzer, Klos, & Zhanggames, restricted set players {1, . . . , n}. Gmon (3) class monotonic simplegames 3 players.various important ways represent (classes of) simple games. G = (N, v)simple game, let WG LG Gs sets winning losing coalitions, respectively,WG LG = 2N WG LG = . set Wmin,G WG Gs minimal winningcoalitions (MWC) contains every winning coalition cannot remove playerwithout making losing coalition. set Lmax,G LG Gs maximal losing coalitions(MLC) defined analogously: coalition maximal losing losing playeradded without making winning. describe simple gamefollowing forms:Winning coalition form: (N, WG ) called winning coalition form G.Losing coalition form: (N, LG ) called losing coalition form G.Minimal winning coalition form: (N, Wmin,G ) minimal winning coalition formG. Observe Wmin,G fully describes v G monotonic.Maximal losing coalition form: (N, Lmax,G ) maximal losing coalition form G.Again, Lmax,G fully describes v G monotonic.some, simple games, exists another representation.Weighted form: simple game G = (N, v), exists quota q R0weight wi R0 Pplayer N , coalition 2N holdsv(S) = 1 wi q, say G weighted weighted form,vector w = (q, w1 , . . . , wn ), also written [q; w1 , . . . , Pwn ], called weightedrepresentation G. (We write w(S) shorthand wi .) Observeevery game weighted form also monotonic. converse truegeneral,4 interested monotonic games weightedform.Games weighted form, weighted voting games, main interest.denote class weighted voting games Gwvg . weighted voting gameimportant type simple game compact representation,used many practical situations, elections, (European Union) political decisionmaking, stockholder meetings. important property weighted voting gamesuse weighted representation game invariant scaling:multiply quota weights weighted form WVG Gconstant c R+ , resulting weighted form [cq; cw1 , . . . , cwn ] representsgame G, is, winning losing coalitions.next turn attention topic influence power monotonic simplegames. monotonic simple game, possible define relation called desirabilityrelation among players (see Isbell, 1958):4. see this, consider four-player monotonic game MWCs {1, 2} {3, 4}. Suppose, sakecontradiction, exist weights w1 , . . . , w4 quota q form weighted representationgame. w1 + w2 q w3 + w4 q, w1 + w2 + w3 + w4 2q. coalitions {1, 3}{2, 4} losing, since (supersets of) MWCs, w1 + w3 < q w2 + w4 < q,means w1 + w2 + w3 + w4 < 2q, yielding contradiction.108fiFinding Optimal Solutions Voting Game Design ProblemsDefinition 1 (Desirability relation). monotonic simple game (N, v), desirabilityrelation v defined follows: (i, j) N 2 :N \ {i, j} : v(S {i}) v(S {j}), v j. saydesirable j.N \ {i, j} : v(S {i}) = v(S {j}), v j. say jequally desirable.N \ {i, j} : v(S {i}) v(S {j}), j v (also written v j).say less desirable j.v j v j, v j. say strictly desirable j.v j v j, v j. say strictly less desirable j.Moreover, neither v j j v holds i, j N , call jincomparable.Using notion desirability, define class linear games.Definition 2 (Linear game). simple game (N, v) linear gamemonotonic, pair players N incomparable respect v . Thus,linear game (N, v), v total preorder N . denote class linear gamesGlin .weighted voting games linear. (N, v) weighted voting game weightedform [q; w1 , . . . , wn ], v j wi wj . So, every pair players comparablerespect v . fact, following sequence strict containments holds: GwvgGlin Gmon . following definitions two special classes games used subsequentsections.Definition 3 (Canonical weighted voting games canonical linear games). lineargame (N, v) canonical linear game whenever N = {1, . . . , n} n N>0 ,desirability relation satisfies 1 2 n. G also weighted, Gcanonical weighted voting game (CWVG). class canonical linear games denotedGclin , class CWVGs denoted Gcwvg . Note CWVG alwaysweighted representation nonincreasing.two special ways representing canonical linear games. introduce these,need notions left-shift right-shift.Definition 4 (Left-shift right-shift). Let N set players {1, . . . , n} letnonempty subset N . coalition 0 N direct left-shift wheneverexists 1 6 2 n 0 = (S \ {i}) {i 1}.coalition 0 N left-shift whenever k 1 exists sequence(S1 , . . . , Sk ) (2N )k , that:S1 = S,Sk = 0 ,109fiDe Keijzer, Klos, & Zhang1 < k, Si+1 direct left-shift Si .say coalition 0 strict left-shift 0 left-shift 0 6= S.definitions direct right-shift (strict) right-shift obtained replacedefinition 1 + 1 + 1 1.example, coalition {1, 3, 5} direct left-shift coalition {1, 4, 5}former coalition, player 4 replaced player 4 1 = 3, coalition {1, 2, 4} left-shift{1, 4, 5}, former obtained latter sequence (three)direct left shifts.notions left-shift right-shift make sense canonical linear games canonical weighted voting games. Due specific desirability order holds canonicallinear games, left-shift winning coalition always winning game,left-shift, player winning coalition replaced lower-numbered,thus desirable player. Similarly, right-shift losing coalition always losinggame. allows us represent canonical linear game one followingtwo forms.Definition 5 (Roof/ceiling coalition/form). Let G = (N, v) canonical linear game.Also, let Wmin,G Gs set minimal winning coalitions let Lmax,G Gs setmaximal losing coalitions. minimal winning coalition Wmin,G roof coalitionwhenever every right-shift losing. Let Wroof,G denote set Gs roof coalitions.pair (N, Wroof,G ) called roof form G. maximal losing coalition Lmax,Gceiling coalition whenever every left-shift winning. Let Wceil,G denote setGs ceiling coalitions. pair (N, Wceil,G ) called ceiling form G.52.1 Power Indicesconsider weighted voting game weighted form [100; 98, 1, 1], seeweight player necessarily directly proportional influence game.game, grand coalition winning. Since players need presentcoalition winning, said influence, despitefact huge difference weights first versusplayers.variety power indices proposed measure players influence (insteadweight) monotonic simple game. Power indices measure players priori powervoting game. reason, power indices rely (statistical) informationcoalitions likely actually form due preferences players.paper, focus normalized Banzhaf index (also called simply Banzhaf index,see Banzhaf III, 1965), inasmuch used experiments Section 5. However,theoretical part work, particular choice power index irrelevant.Definition 6 (normalized Banzhaf index & raw Banzhaf index). (normalized) Banzhafindex monotonic simple game (N = {1, . . . , n}, v) defined = (1 , . . . , n ),5. terminology roof ceiling taken Peled Simeone (1985), Taylor Zwicker(1999) call coalitions shift-minimal winning coalitions shift-maximal losing coalitions.110fiFinding Optimal Solutions Voting Game Design Problems1 n,0= Pn0j=1 j,i0 = |{S N \ {i} : v(S) = 0 v(S {i}) = 1}|.(1)Here, i0 called raw Banzhaf index player i, counts number losingcoalitions agents player turn winning joining them.problem computing power indices associated computational complexitywidely studied. survey complexity results, exact approximationalgorithms computing power indices, see work De Keijzer (2009b). PrasadKelly (1990) prove computation raw Banzhaf index #P-complete,6fastest known exponential time algorithm computingBanzhaf index due KlinzWoeginger (2005), achieving runtime O(( 2)n n2 ).3. Problem Statement Related Workgeneral statement, voting game design (VGD) problem problemfinding simple game optimizes given requirement. One obtains different variantsproblem specifying (i) type simple game one interested in, (ii)requirement optimized. paper, focus finding weighted voting game (inweighted form), requirement normalized Banzhaf power indexgame close possible given target power index. call variant powerindex weighted voting game design (PIWVGD) problem. Please note approachpropose specific minimizing distance target power index;optimization criteria addressed well. fact, follows pertainsenumerating games given classes, optimization part problem, letalone focus (normalized Banzhaf) power index. (some of) experimentsfocus normalized Banzhaf index. experiments, choose measurecloseness terms Euclidean distance Rn normalized Banzhaf powerindex game target power index.illustrate problem, visualize 3 player-instance problem,done nicely two dimensions. normalized Banzhaf index weightedvoting game vector 2-dimensional unit simplex.7 analysis Section 4,turn convenient restrict canonical WVGs (see Definition 3).without loss generality, every WVG exists canonicalWVG obtained ordering players. three players, gamesnormalized Banzhaf power indices shaded area Figure 1, verticessimplex labeled players numbers (1, 2 3). corresponding powerindices listed left.four dark dots Figure 1 represent normalized Banzhaf power indices corresponding ten existing three-player canonical WVGs. Two ten games6. #P complexity class contains counting versions problems NP. Problems completeclass believed hard solve, polynomial-time algorithm one problemimplies P = NP.P7. Recall n-dimensional unit simplex defined x (R0 )n+1 : n+1i=1 xi = 1 , contains(n + 1)-dimensional vectors non-negative real numbers elements sum 1.111fiDe Keijzer, Klos, & Zhang(1, 0, 0)(, , )1[999: 1000, 0, 0][999: 1000, 500, 500][999: 998, 2, 2][999: 1000, 1000, 0](, , 0)[999: 500, 500, 0][999: 1000, 1000, 1000](, , )[999: 500, 500, 500][999: 333, 333, 333]23Figure 1: games three players power indices.degenerate, namely, two games winning losing coalitions, respectively.Weighted form representations eight games given right figure, also shows different games may distribution power.PIWVGD problem (for n = 3) now: given target power index (a point) somewhereshaded area figure (and corresponding part (n 1)-dimensional unitsimplex general n), return weighted representation game closesttarget (in terms Euclidean distance, example).know couple studies propose algorithms inverse problem.Fatima, Wooldridge, Jennings (2008) Aziz, Paterson, Leech (2007) presentsimilar algorithms inverse problem target Shapley-Shubik index (Shapley &Shubik, 1954) Banzhaf index (Banzhaf III, 1965), respectively. algorithms iteratively update weight vector using update rules based distance currentweight vectors power index target power index. Fatimal et al. use two update rulesprove applying them, Shapley-Shubik index player cannotget away target. Hence, proposed algorithm anytime algorithm.Aziz et al. give analysis. Leech (2002a, 2003) proposes approachlargely resembles method Aziz et al., exception different updatingrule used. Neither algorithm comes approximation guarantee.two recent interesting works voting game design problem. OneKurz (2012b). Kurz proposes exact method using integer linear programming,solving weighted voting game design problem Shapley-Shubik indexBanzhaf index. set linear games taken search space, branch-andbound techniques (along various insights set weighted voting games)used order find set weighted voting game power index closesttarget. Kurz provide runtime analysis. experiments performed showalgorithm works well small numbers players. work independent workKurz differs interested devising algorithm provable asgood-as-possible runtime guarantees. Moreover, approach take differentKurz, theory necessary develop algorithm considered interestingitself.112fiFinding Optimal Solutions Voting Game Design Problemsrecent work De, Diakonikolas, Servedio (2012b). paper provides main result algorithm inverse power index problem caseShapley-Shubik index, certain approximation guarantee: additiontarget power index, algorithm takes precision parameter guarantees outputweighted voting game power index -close it, preconditionexists -close weighted voting game property quotaskewed, particular sense. is, knowledge, polynomial time algorithmpower index voting game design problem provides approximation guaranteesense.Closely related work two papers deal Chow parameters problem(ODonnell & Servedio, 2011; De, Diakonikolas, Feldman, & Servedio, 2012a). resultspaper stated terms boolean function theory learning theory,translated setting, papers seen deal approximation algorithmstype value considered power index: Chow parameters givenplayer given game defined total number winning coalitionsplayer in. authors present papers, main result, polynomial timeapproximation scheme computing Chow parameters weighted voting game.problem enumerating set weighted voting games fixed numberplayers is, see, closely related approach take solving weightedvoting game design problem. enumeration problem studied Kurz (2012a),uses integer programming techniques enumerate canonical weighted voting gamesnine players. Kurz generates integer weighted representations gamesclassifies games unique minimum-sum integer weighted representation.Threshold functions (Hu, 1965; Muroga, 1971) fundamental research interestvoting games, circuit complexity neural networks. problem realizing Booleanthreshold functions neural networks extensively studied (Parberry, 1994; Siu,Roychowdhury, & Kailath, 1995; Freixas & Molinero, 2008), upper lower boundsderived synaptic weights realizations. enumeration thresholdfunctions closely related enumeration weighted voting games (see AppendixA): Threshold functions essentially weighted voting games negative weightsallowed. enumeration threshold functions six variables done Muroga,Toda, Kondo (1962). Subsequently, work Winder (1965), Muroga, Tsuboi,Baugh (1970), threshold functions respectively seven eight variablesenumerated. Krohn Sudholter (1995) enumerated canonical weighted voting gameseight players, well class canonical linear games. Kurz (2012a) firstenumerate nine player canonical weighted voting games, Freixas Molinero(2010) first enumerate nine player canonical linear games. bestknowledge, enumerations 10 players carried out.exists literature enumeration special subclasses voting games well:see work Freixas, Molinero, Roura (2012) linear games two desirabilityclasses; work Freixas Kurz (2013a) weighted voting games one roof;work Freixas Kurz (2013b) linear games certain special types votersdesirability classes.113fiDe Keijzer, Klos, & Zhangwork Krohn Sudholters (1995), enumeration canonical linear gamessubclass thereof studied using various order theoretic concepts. directly address problem enumerating weighted voting games, although discusscorrespondence n-player proper weighted voting games (n + 1)-playercanonical decisive weighted voting games.8 class canonical linear gamesmuch bigger class weighted voting games, algorithms imply efficient enumeration procedure weighted voting games, one main contributionspresent work. However, connections work KrohnSudholter: enumeration procedures work exploiting graded posets, likeours; although posets consist subsets winning coalitions together setinclusion relation (for case decisive canonical linear games, use variantposet), subsets minimal winning coalitions case. Althoughidea using graded poset corresponds ours, seems us results cannotconnected stronger sense. Moreover, proofs propertiesestablish partially ordered set propose here, use vastly different ideas,crucially exploit weightedness.Alon Edelman (2010) observe need know priori estimates powerindices achievable simple games analyze accuracy kinds iterativealgorithms, i.e., need information distribution power indices[0, 1]n . first step solving problem, prove specific result caseBanzhaf index monotonic simple games.addition, applied work done design voting games. LaruelleWidgren (1998), Sutter (2000) analyze design distribution voting powerEuropean Union using iterative methods resemble algorithm Aziz et al.(2007). Laruelle Widgrens algorithm systematically analyzed improvedDe Nijs, Wilmer, Klos (2012). Similar work done Leech EU (Leech,2002b), IMF (Leech, 2002c).Finally, research direction related problem studying minimalinteger representations weighted voting games: Bounds maximum weightrepresentation provide us finite set weighted representations search through,means solving design problem. explain greater detail nextsection. classical relevant bounds found work Muroga (1971), Section9.3. See work Freixas Kurz (2011), Freixas Molinero (2010) recentwork direction.4. Solving Power Index Voting Game Design Problemnatural representation weighted voting game weighted representation.However, invariance scaling weighted representations, exist infinitenumber weighted representations individual weighted voting game, even thoughevery n, number weighted voting games finite: weighted voting games simplengames, 22 simple games n players. makes hard derive exactalgorithm weighted voting game design problem based working8. game called proper complement winning coalition losing. game called decisiveproper complement losing coalition winning.114fiFinding Optimal Solutions Voting Game Design Problemsweighted representations alone, since immediately clear finite set weightvectors algorithm search through.9 resort working alternativerepresentations.approach voting game design problems devising enumeration methodgenerates every voting game relatively efficiently. First, discuss naive methodenumerates monotonic simple games given number players doubly exponentialtime (Section 4.1). Subsequently, Section 4.2, case weighted voting games,improve runtime exponentially showing enumerate weighted votinggames given number players within exponential time. Although runtimeenumeration method still exponential, see algorithm PIWVGDproblem results enumeration method (trivially) anytime property:remember best game found far, longer run algorithm,better result becomes. addition, guaranteed algorithm eventuallyfinds optimal answer. enumeration method exploits specific (graded) partial orderprove exist class weighted voting games.dealing algorithms run exponential time, make use-notation: function f : R R (g) g : R Rpolynomial p : R R f O(g p). essentially meansmake light polynomial factors.4.1 Monotonic Simple Game Designsection consider briefly power index voting game design problem classmonotonic simple games.monotonic simple game represented either set minimal winning coalitionsmaximal losing coalitions, sets always forming antichain-relation coalitions players:10 pair coalitions set minimal winning(maximal losing) coalitions comparable respect , onecoalitions would minimal winning (maximal losing). exact algorithm solvesproblem must therefore search antichain represents game (as eitherlist MWCs MLCs) power index closest target power index.either case, simple exact algorithm problem would one considers everypossible antichain, computes antichain power index gameantichain represents, distance target power index, finally return gameminimizes distance.number antichains set n elements known nth Dedekind number Dn . sequence Dedekind numbers (Dn ) quickly grows large,algorithm high time complexity. Kleitman Markowski (1975) prove followingbounds Dn :0 log nn/2 )En2(1+c n )En Dn 2(1+c2,(2)9. However, literature provide us bounds maximum weight necessary integerrepresentation weighted voting game, could utilize order come enumeration algorithm based generating finite set integer weighted representations. elaborateidea refwvgdesign.10. family sets antichain respect relation R, pair setsfamily comparable respect R.115fiDe Keijzer, Klos, & Zhangc0 c constants En size largest antichain n-set.11n, result known Sperners theorem.Sperner (1928) proves En = bn/2cSperners theorem Stirlings approximation, getn2En.(3)nconclude Dn doubly exponential n. Therefore, algorithm solvesvoting game design problem monotonic simple games way achieves runningntime (22 h(n)). function h exponential popular power indices, e.g.,Shapley-Shubik index Banzhaf index (see Aziz, 2008; Deng & Papadimitriou, 1994;Prasad & Kelly, 1990).4.2 Enumerating Weighted Voting Gamesmentioned Section 3, literature voting game design problems focusedweighted voting game variant power index voting game design problempower index choice either Banzhaf index Shapley-Shubik index. Here,propose exact algorithm problem runs exponential time.turn make algorithm interesting practical purposes anytimealgorithm (trivially): guaranteed output optimal solution eventually,stop execution algorithm time, answer output closeroptimum, longer run it. advantage algorithm current localsearch methods obviously get stuck local optima.existing local search methods try solve weighted voting gamedesign problem use weighted representation directly, mentioned before,exist infinitely many weighted representations even single weighted voting game,algorithms stall move different weighted representation doesntrepresent different game. mentioned before, using weighted representationsbasis enumeration algorithm possibility well, immediately clearthis, infinite set weighted representations every weightedvoting game. Muroga (1971, Thm. 9.3.2.1) provides us solution problem,theorem tells us every weighted voting game exists integer weightedrepresentation none weights quota exceeds 2n log n . meanspossible enumeration algorithm could work iterating 2(n+1)n log n integerweight vectors weights fall within bounds, output weight vectorcase corresponds weighted voting game output before.yields improvement enumeration algorithm outlined Section 4.1 specialcase weighted voting games. still consider satisfactory enumerationprocedure runtime algorithm still significantly larger knownupper bounds number weighted voting games (see Appendix A). enumeration11. Korshunov (2003) devised asymptotically equal expression:n/22 n5n4+n 2n2Dn 2C(n) ec(n)2,nnC(n) = bn/2cc(n) = bn/2c1. describes expression number monotonicboolean functions, equal nth Dedekind number.116fiFinding Optimal Solutions Voting Game Design Problemsalgorithm propose better runtime, indeed propertyalso efficient sense runs time polynomial number weighted votinggames outputs. algorithm rely weighted representations weightedvoting games; instead works representing weighted voting games setsminimal winning coalitions.4.2.1 New Structural Property Class Weighted Voting Gamesenumeration algorithm propose enumerates canonical WVGs exploits factset canonical weighted voting games n players partially ordered specificrelation games sets minimal winning coalitions. particular, showtake canonical weighted voting game n players least one minimalwinning coalition (MWC), exists MWC C games set MWCsthat, remove C, resulting set MWCs represents another canonical weightedvoting game n players. analysis, also show check whetherset MWCs given game extended coalition form another gamesset MWCs. way, start game zero MWCs, enumerategames bottom up, according specific partial order.proceed developing necessary theory behind algorithmpropose. focus class canonical weighted voting games sincenoncanonical weighted voting game canonical one obtained merelypermutating players.use order-theoretic notions section. given followingdefinition.Definition 7 (Partial order, (graded) poset, cover, rank function, least element). setS, partial order relation reflexive, x : x x; antisymmetric,x, : ((x x) x = y); transitive, x, y, z : ((xz) x z). partially ordered set poset set equipped partial order ,i.e., pair (S, ). least element poset (S, ) element x xS. minimal element (S, ) element x x implies= x S. say covers x (S, ) xz x z y. poset (S, ) graded exists rank function: N that: (i) constant minimal elements (S, ), (ii) (x) (y)x, x holds, (iii) pair x, holds coversx (S, ), (y) = (x) + 1.algorithm propose based new structural property allows usenumerate class canonical weighted voting games efficiently. define relationMWC prove number players n, class Gcwvg (n) forms gradedposet least element relation.Definition 8 (The relation MWC ). Let G, G0 Gcwvg (n) two canonical weightedvoting games. define G MWC G0 hold exists k N1sequence G1 , . . . , Gk canonical weighted voting games n players, G1 = G,Gk = G0 , 1 < k holds Wmin,i Wmin,i+1 |Wmin,i | = |Wmin,i+1 |1,Wmin,i denotes set minimal winning coalitions Gi .117fiDe Keijzer, Klos, & Zhangfollowing theorem provides foundation enumeration algorithm.Theorem 1. n, (Gcwvg (n), MWC ) graded poset rank function: Gcwvg (n)NG7 |Wmin,G |.Moreover, graded poset least element rank 0.Proof Theorem 1. need prove (1) pair (Gcwvg (n), MWC ) poset,requires showing relation MWC partial order Gcwvg (n), (2) partialorder graded, requires showing function rank function, (3)graded poset least element rank 0. (1), relation MWC reflexive,every game G Gcwvg (n), G MWC G holds: take k = 1 Definition 8,required sequence games G. relation also antisymmetric,G MWC G0 G0 MWC G true, exist two sequences CWVGs G1 , . . . , Gm(with G1 = G Gm = G0 ), G1 , . . . , Gn (with G1 = G0 Gn = G),conditions Definition 8 hold. Neither sequence length > 1, wouldmean Wmin,G Wmin,G0 (or vice versa), inclusion wouldnt holddirection. means = n = 1, G = G0 . Finally, relationtransitive, G MWC G0 G0 MWC G00 hold, exists sequences CWVGsG1 , . . . , Gm (with G1 = G Gm = G0 ) G1 , . . . , Gn (with G1 = G0 Gn = G00 )conditions Definition 8 hold. Concatenating sequences establishesG MWC G00 holds.order prove (2), poset graded rank function specifiedtheorem, show three conditions (i) (iii) Definition 7hold function defined Theorem 1. condition (i), CWVG GWmin,G = minimal element: take arbitrary CWVG G0 G0 MWC Gholds. show G0 = G. G0 MWC G holds, exists sequenceCWVGs G1 , . . . , Gm (with G1 = G0 Gm = G) conditions Definition 8hold. Wmin,G = , sequence length > 1, G0 = G.G0 arbitrary, holds CWVGs, establishing G minimal element.value rank function game G 0. show game G Wmin,G =minimal element, prove following lemma constructively.Lemma 1. every game G Gcwvg (n) nonempty set Wmin,G set minimalwinning coalitions, coalition C Wmin,G game G0 Gcwvg (n)Wmin,G \ {C} set minimal winning coalitions G0 .lemma implies every game G Gcwvg , exists sequence CWVGsstarts G ends game minimal winning coalitions. gameset MWCs one smaller previous game sequence. proveLemma 1, first prove two preliminary Lemmas (2 3).Lemma 2. Let G = (N = {1, . . . , n}, v) weighted voting game, let ` = [q; w1 , . . . , wn ]weighted representation G. player exists > 0positive 0 < , vector `0 = [q; w1 , . . . , wi + 0 , wi+1 , . . . , wn ] also weighted representation G.118fiFinding Optimal Solutions Voting Game Design ProblemsInformally, lemma states always possible increase weight playeramount without changing game.Proof. Recall WG LG Gs sets winning losing coalitions, respectively.Let wmax = maxCLG w(C) wmin = minCWG w(C), wmax < q largest weightlosing coalition, wmin q smallest weight winning coalition, wmax < wmin .Take = wmin wmax note > 0. Increasing players weight positiveamount 0 less turn losing coalition winning coalition.Also, 0 > 0, change weight turn winning coalition losingcoalition, weighted representation `0 represents game G.Lemma 3. Let G = (N = {1, . . . , n}, v) weighted voting game, let w` (C)weight coalition C game represented `. exists weighted representation` G C, C 0 2N , C 6= C 0 , v(C) = v(C 0 ) = 1, holdsw` (C) 6= w` (C 0 ).Or, informally stated: every weighted voting game, exists weighted representation winning coalitions different weight.Proof. Let `0 = [q; w1 , . . . , wn ] weighted representation G. constructrequired weighted representation ` `0 . First fix arbitrary player i. Lemma2, > 0 increasing wi value 0 (0, ) result anotherweighted representation G. Let E set choices 0 increasing wi0 yields weighted representation ` two coalitions C, C 0 2N ,C 6 C 0 , weight `. finitely manypairs (C, C 0 ) E finite therefore (0, ) \ E non-empty. picking 0 value(0, ) \ E, increasing weight player 0 , thus end weighting` coalition C containing w` (C) equal coalitioncontaining i. Furthermore, C C 0 two arbitrary coalitions distinctweights `0 , certainly distinct weights `.sequentially applying operation N , end weighting` holds every player coalition C containingw` (C) equal weight coalition containing i.Let C, C 0 2N arbitrary distinct coalitions. Assume without loss generalityC \ C 0 6= (otherwise, may swap names C C 0 ) let C \ C 0 .C contains C 0 contain i, w` (C) 6= w` (C 0 ), completesproof.Using Lemma 3, prove Lemma 1, establishes Theorem 1.Proof Lemma 1. Let G = ({1, . . . , n}, v) canonical weighted voting game. LetWmin,G set minimal winning coalitions let ` = [q; w1 , . . . , wn ] weightedrepresentation holds minimal winning coalitions different weight.Lemma 3, representation exists. construct `00 ` holdsweighted representation canonical weighted voting game Wmin,G \ {C}list minimal winning coalitions, C Wmin,G .119fiDe Keijzer, Klos, & ZhangLet highest-numbered player coalition Wmin,G , i.e., leastdesirable nondummy player. may assume without loss generality wj = 0j > (i.e., dummy players), setting weights 0, still holdsminimal winning coalitions different weights. Let C Wmin,G minimal winningcoalition containing lowest weight among MWCs Wmin,G contain i.Next, define `0 [q; w1 , . . . , wi (w` (C) q), . . . , wn ]. Note `0 weightsplayers still decreasing nonnegative: w` (C \ {i}) < q (due C \ {i}losing coalition, C MWC), w` (C \ {i}) + wi = w` (C) < q + wi ,wi > w` (C) q. player weight `0 indeed nonnegative. Player weightdecreased `0 , enough turn even lightest MWCs containlosing coalition. G`0 = G` = G w`0 (C) = q. Moreover, weightscoalitions Wmin,G contain player still mutually distinct `0 .decrease player weight further, amount smallminimal winning coalition turns losing coalition C. Note `0(representing game G), minimal winning coalition C still lightest MWCcontaining player i. Let C 0 Wmin,G second-lightest minimal winning coalitioncontaining i. Obtain `00 decreasing weight `0 positive amount smallerw`0 (C 0 ) w`0 (C). Coalition C become losing coalition minimalwinning coalitions stay winning. new minimal winning coalition introducedprocess: Suppose would new minimal winning coalition G`00 ,contains players least desirable (the players weight0). case 6 S, would also minimal winning coalition originalgame G w`00 (S) = w` (S) q, contradicts fact new MWCG`00 . case S, must \ {i} winning original game G (becausewinning original game MWC original game, pickedleast desirable nondummy player). Thus, w`00 (S \ {i}) = w` (S \ {i}) q,contradiction MWC G`00 .G`00 therefore n-player canonical weighted voting game whose set MWCs formssubset MWCs G, cardinalities two sets differ exactly 1.proves claim.Continuing proof Theorem 1, follows Lemma 1 gameminimal winning coalitions unique minimal element. fact properties (ii)(iii) hold rank function follows immediately definitions relationMWC function . Regarding claim (3), poset least element rank0, consider game G minimal winning coalitions. game G, G MWC G0holds games G0 Gcwvg (n), G least element, rank 0.Figure 2, (Gcwvg (4), MWC ) depicted graphically. Note conveniencedisplay, figure exactly Hasse diagram poset (Gcwvg (4), MWC ).clear Figure 2 (Gcwvg (4), MWC ) tree since one game coversmultiple games: game labelled 0110 two edges coming it, onedashed. set minimal winning coalitions representing game, twominimal winning coalitions (1001 0110) holds removed,remaining set coalitions set minimal winning coalitions representing another120fiFinding Optimal Solutions Voting Game Design Problems100011000100 0110 0111101111010010 0011 0101 0110 0111 1001 011110111001000100111010111011110000011001100111011101010011Figure 2: Graphical depiction (Gcwvg (4), MWC ). node graph representscanonical weighted voting game four players. figure read follows:node characteristic vector minimal winning coalition label; binarysequence indicating player whether (1) (0) member coalition.set minimal winning coalitions game corresponds certain node ngraph, elements coalitions described elements set Vncharacteristic vectors path top node n along solid edges. top nodecorresponds canonical weighted voting game zero minimal winning coalitions(i.e., every coalition loses). actual Hasse diagram poset obtainedchanging label node n Vn including solid edges well dashededge diagram.121fiDe Keijzer, Klos, & Zhangcanonical weighted voting game. Since one could add number dummy playersgame (i.e., players occur winning coalition), conclude following.Proposition 1. every n 4, (Gcwvg (n), MWC ) tree.develop algorithm next section, turn Proposition 1makes things significantly complicated.4.2.2 Algorithmuse results previous section develop exponential-time exact algorithmpower index voting game design problem. way algorithm works straightforward. naive algorithm suggested Section 4.1, enumerate completeclass games (weighted voting games case), compute gameoutput enumeration algorithm power index distance power indextarget power index. keep track game minimizes distance.key efficient enumeration utilizing Theorem 1, possible efficientlygenerate minimal winning coalition listings canonical weighted games rank(according graded poset defined) minimal winning coalition listingscanonical weighted voting games rank 1.following two theorems show us this. Firstly, need resultwork Peled Simeone (1985).Theorem 2 (Peled & Simeone, 1985). exists polynomial time algorithm testingwhether game given list minimal winning coalitions weighted voting game.Moreover, weighted voting game, list maximal losing coalitionsweighted representation found polynomial time.algorithm proposed Peled Simeone (1985) above-named characteristics called Hop-Skip-and-Jump algorithm. algorithm originally designedapplications related solving problems fields threshold logic set covering,matter changing terminology straightforward way seeHop-Skip-and-Jump algorithm fulfills purposes well.state next theorem, first define truncation operation.Definition 9 (Right-truncation). Let N = {1, . . . , n} coalition players. UsingP (S, i) denote ith highest numbered player among players S, ith righttruncation S, denoted rtrunc(S, i), defined= 0,rtrunc(S, i) = \ {P (S, i), . . . , n} 0 < |S|,undefinedotherwise.canonical linear games, ith right-truncation coalition (for |S|)coalition remains least desirable players removed S. example,2nd right-truncation coalition {1, 2, 4, 6, 8} coalition {1, 2, 4}.122fiFinding Optimal Solutions Voting Game Design ProblemsTheorem 3. n, let G, G0 Gclin (n) pair canonical linear gamesrespective sets minimal winning coalitions Wmin,G Wmin,G0 , Wmin,GWmin,G0 |Wmin,G0 | = |Wmin,G | + 1. Let Lmax,G Lmax,G0 sets maximal losingcoalitions G G0 , respectively. C Lmax,G N 0 nWmin,G0 = Wmin,G {rtrunc(C, i)}.Proof. Let C 0 coalition Wmin,G0 = Wmin,G {C 0 }. Coalition C 0 cannotsuperset coalition Wmin,G would minimal winningcoalition G0 . Therefore, C 0 losing coalition G, must subset coalitionLmax,G . Suppose contradiction C 0 right-truncation maximal losingcoalition C Lmax,G . C Lmax,G C 0 subset C,right-truncation C. means C 0 , player j C present,least one less desirable player k > j C C 0 . implies left-shift C 00C 0 C 00 subset coalition Lmax,G : C 00 obtained C 0 replacingj k. C 00 subset C, C 00 still losing coalition G. C 00superset coalition Wmin,G , hence C 00 also superset coalitionWmin,G0 . C 00 losing coalition G0 . G0 canonical linear game,desirability relation 1 n, C 00 winning coalition G0 left-shiftwinning coalition C 0 . contradiction.Theorems 2 3, becomes apparent use (Gcwvg (n), MWC )enumerating class n-player canonical weighted voting games. start outputtingn-player weighted voting game zero minimal winning coalitions. that,repeat following process find games: use Theorem 3 generateminimal winning coalition lists canonical weighted voting games minimalwinning coalitions, using set canonical weighted voting games games i1 minimalwinning coalitions (also represented list minimal winning coalitions), starting = 1.generated, choice output games either list minimal winningcoalitions weighted representation, using Hop-Skip-and-Jump algorithm.Generating set games minimal winning coalitions works follows.game G i1 minimal winning coalitions, obtain set maximal losing coalitionsusing Hop-Skip-and-Jump algorithm. Next, check right-truncationmaximal losing coalition C Lmax,G whether, add Gs set minimalwinning coalitions, resulting set represents another weighted voting game. Again, testing whether game weighted voting game done using Hop-Skip-and-Jumpalgorithm. game turns weighted, store output it.one remaining problem approach: outputs duplicate games.(Gcwvg (n), MWC ) tree, would case. However, Proposition1, (Gcwvg (n), MWC ) tree n 4. Thus, duplicates checkweighted voting game find. principle, seems difficult.game find, sort list minimal winning coalitions, checklist coalitions already occurs array listings minimal winning coalitionscorrespond games already found. problem solution listgrow large, making checks time- space-consuming operations.therefore use different method duplicates check: Supposefound n-player canonical weighted voting game G minimal winning coalitions123fiDe Keijzer, Klos, & Zhangadding coalition C minimal winning coalition listing canonical weighted votinggame already found. first sort Gs list minimal winning coalitionsaccording fixed total order. check coalition C 0 occursC sorted list, whether C 0 removal list results list minimal winningcoalitions canonical weighted voting game. C 0 , discard G,otherwise, keep it. way, certain canonical weighted voting gamegenerated once. terms orderly generation combinatorial objects (McKay,1998), method thus provides canonical construction path CWVGs.Algorithm 1 gives pseudocode enumeration method. array elementgames[i] list canonical weighted voting games minimal winningncoalitions; rank-i games. value exceed bn/2cSperners Theorem.games represented lists minimal winning coalitions. algorithm iteratesevery new game found, starting game games[0], zero minimal winningcoalitions.Algorithm 1 enumeration algorithm class n player canonical weighted votinggames. hopskipjump refers Hop-Skip-and-Jump algorithm.1:2:3:4:5:6:7:8:9:10:11:12:13:14:15:16:17:18:Output [1; 0, . . . , 0]. Output game MWCsgames[0] {}. Add game list rank-0 gamesn= 1 bn/2cG games[i 1]. Evaluate game G rank 1Lmax hopskipjump(Wmin,G ). Obtain game Gs set MLCsC Lmax. Evaluate MLC Cj = 0 n. Evaluate Cs right-truncationsG0 Wmin,G rtrunc(C, j). Call game evaluated G0isweighted(G0 ). requires solving LPG0 passes duplicates checkOutput weighted representation G0 .Append G0 games[i].endendendendendendCorrectness algorithm follows discussion above. Next, analyzetime-complexity algorithm.2 +2nTheorem 4. Algorithm 1 runs (2n) time.Proof. Lines 5 16 executed every canonical weighted voting game.Sperners Theorem, know list minimal winning coalitions fewernelements. runtime Hop-Skip-and-Jump algorithm, line 5 runs timebn/2c2nnn bn/2c+ n3 bn/2c= O(n2 n22n ). Within iteration outer loop (line 4),124fiFinding Optimal Solutions Voting Game Design Problemsn= O( n2n ) times (because Lmax also anlines 9 14 executed n bn/2ctichain, Sperners Theorem also applies maximal losing coalitions). time-complexityone execution lines 9 14 follows.nline 9, must solve linear program, taking time n4.5 bn/2c= O(n4 2n )using Karmarkars interior point algorithm (Karmarkar, 1984).line10, must execute duplicates check. consists checkingnbn/2c sets minimal winning coalitions whether weighted. involvesrunning Hop-Skip-and-Jump algorithm, followed solving linear program.total, takes O(n3 n22n ) time.Lines 11 12 take linear time.Bringing everything together, see single pass lines 5 16 costs us O(n4 23n )time. mentioned earlier, lines executed |Gcwvg (n)| times. Corol2lary 1 Appendix know |Gwvg (n)| O(2n n ), course |Gcwvg (n)| <2|Gwvg (n)|, hence lines 5 16 executed O(2n n ) times, therefore run22time algorithm O(2n +2n n4 ) = (2n +2n ).Although runtime analysis Algorithm 1 precise, want emphasizemethod runs exponential time instead doubly exponential time. alsoshow runtime algorithm polynomially greater amountdata output. implies Algorithm 1 essentially fastest possible enumerationalgorithm canonical weighted voting games, polynomial factor.Theorem 5. Algorithm 1 runs output-polynomial time, i.e., polynomial numberbits Algorithm 1 outputs.Proof. Lines 5 16 executed less |Gcwvg (n)| times. (5), lowern2 (110)log n /(n!2n )). One execution lines 5 16 costs O(n4 23n )bound |Gcwvg (n)| (2time, thus one iteration runs210n (1 log)n /(n!2n )O(n4 23n ) 2O(|Gcwvg (n)|)time. conclude algorithm runs O(|Gcwvg (n)|2 ) time.Remark 1. cannot give sharp bound space complexity Algorithm 1 know much maximum cardinality antichain (Gcwvg (n), MWC). (Nonetheless, obtain maximum sizes antichains n 8; see Figure 3next section.) However, seen also possible generate gamesposet depth-first manner, instead breadth-first manner like now.case, amount space needs used bounded maximum length2nchain (Gcwvg (n), MWC ). total amount O() space.nbriefly illustrate algorithm enumerates (four-player) CWVGsreferring Figure 2, afterwards indicate application solving power index125fiDe Keijzer, Klos, & Zhangweighted voting game design problem. algorithm starts line 1 outputtingweighted representation game root node. game winningcoalitions. (By definition simple game, exists.) root games list MWCs, added array element games[0] line 2. loopnpossible values rank function defined Theorem 1 take: 1 bn/2c (seeSection 4.1). four players, values 1 6 correspond six horizontalrank-levels root node graph Figure 2. every game G setgames one level higher graph (line 4), consider set maximal losing coalitionsLmax,G (line 6), (line 7), evaluate whether game obtainedadding (at most) n right truncations (line 8) Wmin,G yields weighted votinggame (line 9). four player case, = 1, look single root game. Sincegame losing coalitions, grand coalition element games setMLCs. evaluate whether, grand coalitions five right truncations(0 j 4), adding yields CWVG. turns true five cases,yielding five CWVGs G (G) = 1 see rank-level 1 (the second leveltop graph). games added games[1]. increase one,iteratively consider five games turn.apply enumeration algorithm power index weighted voting game designproblem, compute Banzhaf index every generated game, computedistance target power index (according chosen distance function). storeupdate weighted representation game minimizes distance function,output representation games generated.4.3 Improvements OptimizationsAlgorithm 1 current state quite suitable solving weighted voting gamedesign problem practice. section, describe several improvementsalgorithm. improvements result version enumeration algorithmexpect output canonical weighted voting games steady rate, give uspractically applicable anytime-algorithm voting game design problems (defined smallnumbers players).Hop-Skip-and-Jump algorithm Peled Simeone (1985) works first generating list maximal losing coalitions game, given list minimal winningcoalitions game, subsequently solving linear program check whether gameweighted voting game. Peled Simeone give first improvement showing several ways improve compactify linear program question. smaller linearprogram requires lists roof coalitions ceiling coalitions game.next section, present strengthened version Theorem 3. strengthenedversion implies necessary know games ceiling coalitions (insteadmaximal losing coalitions) generate weighted voting games cover it. Section4.3.2 give output-polynomial time algorithm enumerating ceiling coalitions,given set roof coalitions.using improvements, combined compact linear program,eliminate need compute complete set maximal losing coalitions weightedvoting games enumerate. Instead, suffices keep track sets minimal126fiFinding Optimal Solutions Voting Game Design Problemswinning coalitions ceiling coalitions weighted voting games enumerated,speed algorithm significantly.124.3.1 Better Way Finding New Minimal Winning CoalitionsTheorem 3 allows us find potential minimal winning coalitions extendcanonical weighted voting games generate new ones. seereally need consider every right-truncation every maximal losing coalition. fact,need look ceiling coalitions.Theorem 6. n, let G, G0 Gclin (n) pair canonical linear gamesWmin,G Wmin,G0 |Wmin,G0 | = |Wmin,G | + 1. Let Wmin,G Wmin,G0 setsminimal winning coalitions G G0 , respectively, let Lceil,G Lceil,G0 setsceiling coalitions G G0 , respectively. C Lceil,G N0 n Wmin,G0 = Wmin,G rtrunc(C, i).Proof. Let C 0 coalition Wmin,G0 = Wmin,G {C 0 }. Theorem 3, C 0right-truncation coalition Lmax,G . Suppose contradiction C 0right-truncation ceiling Lceil,G . ceiling C 00 Lceil,G C 0subset strict right-shift C 00 . (This definition subset right-shiftceiling, C 0 subset S.) turn means strict left-shiftC 0 subset right-shift C 00 . Coalition supersetMWC Wmin,G losing G, superset C 0 either,strict left-shift C 0 . follows losing coalition G0 . G0canonical linear game, desirability relation 1 n satisfied.left-shift C 0 , C 0 winning G0 , follows winning coalition G0 .contradiction.4.3.2 Algorithm Obtaining Ceiling-List CanonicalWeighted Voting GameUsing Hop-Skip-and-Jump algorithm, output polynomial time listmaximal losing coalitions list minimal winning coalitions, given weightedvoting game. Given this, interesting question point whether also outputpolynomial time list ceiling coalitions list roof coalitions.Appendix B, prove impossible general output mayexponentially sized input. Nevertheless, certainly still makes sense trycome efficient possible algorithm problem, consideringalgorithm used combination improvements previous sectionfinding weight vectors weighted voting games. Using algorithm certainlypreferred using Hop-Skip-and-Jump algorithm, canonical linear gamealways fewer roof coalitions minimal winning coalitions, fewer ceilingcoalitions maximal losing coalitions.However, recent construction Polymeris Riquelme (2013) shows outputpolynomial time algorithm problem would sensational consequences, would12. Related Proposition 2.3 Krohn Sudholter (1995), gives insight maximum numberceiling coalitions canonical linear game have.127fiDe Keijzer, Klos, & Zhangimply polynomial time algorithm monotone boolean duality problem (Fredman &Khachiyan, 1996): well-known problem solved sub-exponential time,known whether admits polynomial time algorithm.Finding output-polynomial algorithm generating ceiling set gameroof set, thus interesting open problem, due alleged difficulty13instead resort studying problem outputting ceiling set game setminimal winning coalitions.course, one could simply solve latter problem using Hop-Skip-and-Jumpalgorithm. would provide us list MLCs input game,could filter ceilings. algorithm would run O(nm2 + n3 m) time,number MWCs. Below, provide alternative simpler algorithmspecial case need output ceilings given game. remaindersection, use following definitions.Definition 10. Let N set players {1, . . . , n} let N coalition.functions b trunc defined follows.b(S) highest-numbered player S.a(S) highest-numbered player j N \ j + 1 (if jexist, define a(S) = 0).truncation S, defined trunc(S) = \ {a(S) + 1, . . . , n}.example, N = {1, 2, 3, 4, 5} = {1, 2, 4}, highest numbered playerb(S) = 4, N \ = {3, 5}, highest numbered player j N \ j + 1a(S) = 3, trunc(S) = \ {4, 5} = {1, 2}. = {1, 2, 3} N \ = {4, 5},exists j N \ j + 1 S, a(S) = 0.Theorem 7. Let G Gclin (n) canonical linear game players N = {1, . . . , n}, letWmin,G Gs set MWCs, let C set ceilings G, let C Ca(C) > 0. exists N0 , 1 < |C| |trunc(C)|, trunc(C){a(C)} {a(C) + j : 2 j i} minimal winning coalition.Proof. coalition C ceiling, losing, implies trunc(C) also losing,trunc(C) {b(C)} {b(C) + j : 2 j |C| |trunc(C)|} left-shift C, hencewinning. Therefore exists N0 , 2 |C| |trunc(C)|(C 0 := trunc(C) {a(C)} {a(C) + j : 0 j i} winning)(C 00 := trunc(C) {a(C)} {a(C) + j : 2 j 1} losing) (C 00 = C 0 ).canonicity, means C 0 minimal winning coalition.theorem becomes clear efficiently generate set ceilingsset minimal winning coalitions: MWC S, suffices checkk N0 , k n b(S) whether:13. thank Andreas Polymeris Fabian Riquelme pointing us connection monotoneboolean duality problem, well pointing error preliminary version present paper.128fiFinding Optimal Solutions Voting Game Design Problems(S \ {a(S) 1}) {a(S)} {b(S) + j : 1 j k} ceiling (in case a(S) 1 S),(S \ {b(S)}) {b(S) + j : 1 j k} ceiling.would generate ceilings C property b(C) > 0. furthermoren ceilings C holds b(C) = 0, clear coalitionsgenerated checked straightforwardly.runtime implied algorithm theoretically better Hop-Skip-andJump algorithm. However, due simplicity algorithm, due factalgorithm finds ceilings (of general far lessMWCs), expect algorithm run much faster practice, cases.5. Experimentsimplemented Algorithm 1 together optimization strategies describedSection 4.3, allow us work ceiling coalitions, rather maximal losing coaltions. programming language used C. Execution algorithminvolves solving large number linear programs. this, made use GNU Linear Programming Toolkit (see Makhorin, 2004). implementation solves normalizedBanzhaf index weighted voting game design problem. means weightedvoting game output enumeration algorithm, must invoke procedurecomputing normalized Banzhaf index. algorithm used simply naivebrute-force approach. (In experiments, runtime Banzhaf computation (to threedecimal places) different runtime without four players more.eight players, including computation Banzhaf indices never increases runtime0.6%.)purpose experiments gain insight average optimal attainableerror random instances (for small n), well number weighted voting gamesfunction number players number minimal winning coalitions.Experiment 1. used enumeration algorithm compute n 1 n 8n0 bn/2c, exact number canonical weighted voting gamesn players minimal winning coalitions. results displayed Figure 3. Notevertical axis log-scale. see choices n,canonical weighted voting games relatively small number minimal winningncoalitions relative maximum possible number winning coalitions, bn/2c.Experiment 2. n 1 7, computed 1000 random instancesaverage optimal error. is, average error attained 1000 randominstances (i.e., uniform random vectors (n 1)-dimensional unit-simplex restrictednon-increasingness constraint) algorithm allowed run completioninstances. also report worst error attained among 1000 instances.error function used square root sum squared errors. reasonusing specific error measure nice geometric interpretation:Euclidean distance target (input) vector closest point unitsimplex normalized Banzhaf index weighted voting game.129fiDe Keijzer, Klos, & ZhangFigure 4, see errors decrease n gets larger. confirmsobservation Alon Edelman (2010) number voters small,clear one closely approximate every power vector. main resultpaper states target vector lot weight concentrated strict subsetplayers, exists game Banzhaf vector close target. studyrandom vectors, still see general phenomenon number playersincreases, exist games probability one closetarget increases. also see worst case optimal error much worseaverage case. expected, Alon Edelman show n, exist vectorsstandard n-simplex approximated well. results computed1000 random instances. Therefore, worst case optimal errors servelower bound worst case optimal error possible instances.noted preliminary work (De Keijzer, Klos, & Zhang, 2012),even earlier preliminary work (De Keijzer, 2009a), additional experiments reported:Firstly, used implementation (respectively early version implementation)find number weighted voting games n players, 1 n 8. However,independent work (Kurz, 2012b) already published, authors computenumbers 1 n 9 (using incomparable techniques). Secondly, experimentsperformed order study time performance algorithm errorconvergence algorithm larger numbers players. omit experiments(see De Keijzer et al., 2012, results) give short summary instead:outcome experiments surprising line theoretical runtimeanalysis previous section. runtime graph indeed looks like quadratic function,shown log-scale. mentioned, computing Banzhaf index constitutesfraction total runtime. error-convergence algorithm slow already15 players, therefore algorithm practical number playersbig, expected.146. Conclusions Future Workpaper, developed exact algorithm solving power index weighted votinggame design problems. First, derived doubly exponential algorithm large classmonotonic simple games. Subsequently, showed possible obtain (singly)exponential algorithm important special case weighted voting games.core algorithms methods enumerating weighted voting gamesbased new partial order class weighted voting games specificinteresting properties. enumeration algorithm resulting this, bestknowledge first enumeration algorithm weighted voting games provably runsoutput-polynomial time.algorithm works families minimal winning coalitions. demonstratedpossible improve runtime algorithm showing suffices worksubset minimal winning coalitions: i.e., roof coalitions. Usingidea, provided various techniques improve algorithm. Among improvements14. detailed discussion results experiments, see work De Keijzer et al.(2012).130fiFinding Optimal Solutions Voting Game Design Problems# 1 player CWVGs MWCs# 2 player CWVGs MWCs# 3 player CWVGs MWCs# 4 player CWVGs MWCs# 5 player CWVGs MWCs# 6 player CWVGs MWCs# 7 player CWVGs MWCs# 8 player CWVGs MWCsNumber canonical WVGs MWCs10000010000100010010101020304050607080Number minimal winning coalitionsFigure 3: number canonical weighted voting games (y-axis) n players, 1 n8, minimal winning coalitions (x-axis).0.35Maximal Euclidean error 1000 random instancesAverage Euclidean error 1000 random instances0.3Error (Euclidean distance)0.250.20.150.10.0501234567Number playersFigure 4: Optimal Euclidean error 1000 random n player instances, 1 n 7.error bars indicate one standard deviation.131fiDe Keijzer, Klos, & Zhangoutput-polynomial time algorithm outputting list ceiling coalitions lineargame, given list roof coalitions.addition, implemented aforementioned enumeration algorithm weightedvoting games measure performance, obtained interesting data classweighted voting games, validated theoretical results related weighted votinggames.algorithm based enumeration procedure class weighted votinggames: works simply enumerating every game, verifying game whetherlies closer target power index games encounteredpoint. reason, algorithm anytime-property: run algorithmlonger period time, algorithm enumerates games qualitysolution improve, algorithm guaranteed output optimal solutionlong run.choice normalized Banzhaf index implementation previoussection arbitrary: algorithm works choice power index. Moreover, duegenericity enumeration, use algorithm solve power indexvoting game design problems, also voting game design problem.thing adapt error-function algorithm (i.e., part algorithmchecks property question games enumeration procedureoutputs); enumeration procedure need changed.future work, note real-life examples, number playersweighted voting game rather small: usually 10 50 players involved. Thus, onegoals get proposed algorithm yield good results within reasonableamount time number players somewhere range. would alreadyinteresting able solve problem ten players, awareenumerations ten player canonical weighted voting games. However, concludedcurrent implementation algorithm yet fast enough able handleten players. Optimistic extrapolation tells us would take tens years; pessimisticextrapolation gives us thousands years. However, current implementation reallyefficient, hope future insights, together careful computerprogramming, enumerating weighted voting games ten players withinscope. One way improve current algorithm study depth partialorder introduced paper. One possible prospect following. regardweighted voting game design problems, suspect possible prune lotareas partial order: Careful analysis partial order properties mightlead results allow us construct enumeration algorithm priori discardscertain (hopefully large) subsets weighted voting games.moreover interested see algorithm performs searchespartial order greedy manner, happen use (possiblyheuristic) intelligent methods search partial order. First stepsdirection taken Kleijn (2012). wonder possible use search methodstill optimality guarantee approximation guarantee qualitysolution. addition, also consider ideas presented postprocessing stepexisting algorithms. words, might good idea first run algorithmFatima et al. (2008) Aziz et al. (2007) order obtain good initial game. Subse132fiFinding Optimal Solutions Voting Game Design Problemsquently, try search neighborhood game find improvements,according partial order introduced paper.Lastly, related questions would interesting obtain answercomputational complexity power index voting game design problem,also polynomial-time-approximability problem. quite straightforwardsee decision version problem cases NP#P (and thereforePSPACE), one could nondeterministically guess weight vector, subsequentlyuse #P-oracle obtain particular power index interest.15 hand,moment ideas prove hardness problemcomplexity class whatsoever. seems challenge come polynomial-timereduction known computational problem hard nontrivial complexityclass.Acknowledgmentsthank Fabian Riquelme Andreas Polymeris pointing problem preliminary version paper (see Section 4.3.2). thank anonymous refereesextensive feedback, comments suggestions. extended version paperpublished proceedings 2010 International Conference Autonomous AgentsMulti-Agent Systems (De Keijzer, Klos, & Zhang, 2010). research partially supported EU FET project MULTIPLEX 317532, ERC StG Project PAAI 259515,Google Research Award Economics Market Algorithms. majorityresearch carried first author masters student DelftUniversity Technology. part research carried first authorPh.D. student Centrum Wiskunde & Informatica (CWI), Amsterdam.Appendix A. Number Weighted Voting Gamesknowledge, existing game theory literature provide us insightsnumber weighted voting games n players, beyond n = 5. Fortunatelyclosely related field research, called threshold logic (see example Muroga, 1971),relevant results.Definition 11 (Boolean threshold function, realization, LT). Let f boolean functionn boolean variables. function f (boolean) threshold function existsweight vector real numbers r = (r0 , r1 , . . . rn ) Rn+1 r1 x1 + + rn xn r0f (x1 , . . . , xn ) = 1. say r realizes f . denote set thresholdfunctions n variables {x1 , . . . , xn } LT(n).16Threshold functions resemble weighted voting games, except talk boolean variables instead players now. Also, important difference threshold functionsweighted voting games r0 , r1 , . . . , rn allowed negative threshold functions, whereas q, w1 , . . . , wn , must non-negative weighted voting games.15. power indices proposed encountered known #P.16. LT stands Linear Threshold function.133fiDe Keijzer, Klos, & Zhang(Zunic, 2004) presents upper bound number threshold functions n vari2ables: |LT(n)| 2n n+1 . Also, following asymptotic lower bound known (Zuev,1989): large enough n,|LT(n)| 210n2 (1 log)n.(4)bounds, deduce easy upper lower bounds |Gwvg |. Firstobserve following property set threshold functions n variables. LetLT+ (n) set non-negative threshold functions variables (x1 , . . . , xn ), containingthreshold functions f LT(n) exists non-negative weight vector r2realizes f . Then, clear |Gwvg (n)| = |LT+ (n)| 2n n+1 n.proceed obtaining lower bound number weighted voting games.Corollary 1. large enough n, holds|Gwvg (n)| 210n2 (1 log)n1nProof. Let f non-negative threshold function let r non-negative weight vectorrealizes f . 2n+1 possible ways negate elements r,2n+1 1 threshold functions f 0 LT(n) \ LT+ (n) f 0 realizationobtained negating elements r. this, follows |LT+ (n)| |LT(n)|,2n+1thus also |Gwvg (n)| | LT(n)|. using (4) get |Gwvg (n)|2n+1210n2 (1 log)n1nn2 (1 10 )log n2n+12=.next question is: canonical case, Gcwvg (n)? set Gcwvg (n)subset Gwvg (n), noncanonical weighted voting game exists permutation players makes canonical one. Since n! possible permutations,|G (n)|must |Gcwvg (n)| wvgn! , thus obtain|Gcwvg (n)|210n2 (1 log)n1nn!(5)large enough n.Appendix B. Generating Roofs Ceilingssection, answer question whether possible generate polynomial timelist ceiling coalitions linear game list roof coalitions: turnscase. give family examples canonical linear gamesnumber roof coalitions exponential n, number ceiling coalitionspolynomial n. consequence, algorithm generates list roofslist ceilings run exponential time worst case. symmetry also followsgenerating list roof coalitions list ceiling coalitions possiblepolynomial time.Let us first define following specific type coalition.134fiFinding Optimal Solutions Voting Game Design ProblemsDefinition 12 ((k, i)-encoding coalition). Let N = {1, . . . , n} set playersn = 4i N. k satisfying 0 k < 2i 1, (k, i)-encoding coalitionSk,i N defined{4(j 1) + 2, 4(j 1) + 3 : jth bit binary representation k 0}{4(j 1) + 1, 4(j 1) + 4 : jth bit binary representation k 1}example, S2,2 = {1, 4, 6, 7}, S5,3 = {1, 4, 6, 7, 9, 12}. define canonical linear games roof coalitions (k, i)-encoding coalitions.Definition 13 (i-bit roof game). Let N = {1, . . . , n} set players n = 4iN. i-bit roof game N , denoted Gibit , canonical linear gameset roof coalitions G {S0,i , . . . , S2i 1,i }.example, 2-bit roof game, G2bit , consists roofs {{2, 3, 6, 7}, {2, 3, 5, 8},{1, 4, 6, 7}, {1, 4, 5, 8}}. Gibit well-defined binary representationstwo arbitrary i-bit numbers k k 0 differ least one bit. Therefore, Si,ksuperset left-shift Si,k0 hence set roofs defined Gibitindeed valid set roofs (i.e., two roofs one left-shiftanother).ngame Gibit 2i = 2 4 roofs, i.e., exponential number n. shownumber ceilings Gibit polynomially bounded. First let us use followingdefinitions convenience.Definition 14 (Accepting roof set). Let G Gclin (n) canonical linear game playersN = {1, . . . , n}. Let C N coalition, let x natural number 1 x |C|,let D(C, x) x-th desirable player C. accepting set roofs x-thdesirable player C, denoted A(C, x), set consisting roof coalitions Reither x-th desirable player R greater equal D(c, x),|R| < x.important observe following fact holds.Proposition 2. canonical linear game, coalition C winningT|C|a=1 A(C, a) 6= .Proof. lemma fact equivalent statement fact C winningcanonical linear game superset left-shift roof. RT|C|a=1 A(C, a) means replacing a-th desirable player R a-thdesirable player C a,1 R would result left-shift Rsubset C, C must winning.Conversely, suppose C winning. must roof R right-shiftsubset C. removing C players higher number D(C, |R|),obtain subset C 0 C |R| players. replacing a-th desirable player Ca-th desirable player R 1 R, obtain right-shift CR. last step replaced player C 0 higher-numbered player,T|R|T|C|get R a=1 A(C, a). R also a=|R|+1 A(C, a) definition.135fiDe Keijzer, Klos, & ZhangUsing notion accepting roof set, prove following technical lemma.reader recall definition direct left-shift (Definition 4).Lemma 4. Let C ceiling Gibit two distinct coalitions directleft-shifts C, let p arbitrary player apply direct left-shift operation on, i.e., let p player C1 = C {p 1} \ {p} direct left-shift C.Also, let number p = D(C, a). p = 2a.Proof. Observe b holds every roof R Gibit either D(R, b) = 2b 1D(R, b) = 2b. construction Gibit , number roofs Gibit contain player2b 1 22 , number roofs contain player 2b also 22 .C least two distinct direct left-shifts, must another player p0 , p0 6= p,C2 = C {p0 1} \ {p0 } direct left-shift C.First show p 2a. Assume thereforep > 2a.|A(C, a)| = 0, |A(C2 , a)| = 0 hence A(C2 , a) = . see C2 losing,C2 direct left-shift C, ceiling, C2 winning. contradiction,p 2a.show p 2a. Assume thereforep < 2a., A(C , a) = 2i . must|A(C,a)|=2A(C,a)=11A(C, a).A(C,a)=Closing,thereforeA(C,a)=Closing. C111also winning, left-shift ceiling C. contradiction, p 2a.p 2a p 2a, conclude p = 2a.Lemma 5. Gibit , ceiling two direct left-shifts.Proof. contradiction, let C ceiling two direct left-shifts. Let knumber direct left-shifts C, let P = {p1 , . . . , pk } set containingplayers C apply direct left-shift operation (we say applydirect left-shift operation player q C {q 1} \ {q} left-shift C). Let= {a1 , . . . , ak } numbers pj aj -th desirable player C,1 j k. j {1, . . . , i} b {0, 1}, let R(j, b) denotefollowing set roofs Gibit :R(j, b) = {Sk,i : j-th bit binary representation k b. }Observe previous lemma, k-tuple bits (b1 , . . . , bk ) {0, 1}kj 1 j k:A(C, aj ) = R(dpj /4e, kj ).two cases:Case 1: players {p1 , . . . , pk } different multiples 4, i.e., dp1 /4e 6=dp2 /4e =6T =6 dpk /4e.TThen properties binary numbers, intersection aA A(C, a) = pP R(dp/4e, b) empty, therefore C must winning,contradiction C ceiling. case impossible.136fiFinding Optimal Solutions Voting Game Design ProblemsCase 2: two distinct players p p0 , P , multiple4, i.e., dp/4e = dp0 /4e. Assume without loss generality p < p0 .A(C, a) A(C, a0 ) = . would able apply direct left-shiftplayer p00 without turning C winning coalition, i.e., C {p00 1} \ {p00 }winning. C ceiling, contradiction.previous lemma follows two playersmultiple 4, two cases indeed exhaustive. casesimpossible, must reject assumption exists ceiling Ctwo left-shifts.easy see exist O(n5 ) coalitions exactly two leftshifts, O(n3 ) coalitions one left-shift,O(n) coalitions left-shifts. get following corollary.Corollary 2. game Gibit (on n = 4i players) O(n5 ) ceilings.conclude {Gibit : N} infinite family examplesexponentially many roofs ceilings. Hence, finally obtain:Corollary 3. polynomial time algorithm generates list ceilingslinear game list roofs. polynomial time algorithm generateslist roofs linear game list ceilings.ReferencesAlgaba, E., Bilbao, J. M., Garca, J. R. F., & Lopez, J. J. (2003). Computing power indicesweighted multiple majority games. Mathematical Social Sciences, 46, 6380.Alon, N., & Edelman, P. H. (2010). inverse Banzhaf problem. Social ChoiceWelfare, 34 (3), 371377.Aziz, H. (2008). Complexity comparison influence players simple games. Proceedings 2nd International Workshop Computational Social Choice (COMSOC), pp. 6172.Aziz, H., Paterson, M., & Leech, D. (2007). Efficient algorithm designing weighted votinggames. Proceedings IEEE International Multitopic Conference, pp. 16.Banzhaf III, J. (1965). Weighted voting doesnt work: mathematical analysis. RutgersLaw Review, 19 (2), 317343.De, A., Diakonikolas, I., Feldman, V., & Servedio, R. A. (2012a). Nearly optimal solutionsChow parameters problem low-weight approximation halfspaces.Proceedings 44th Symposium Theory Computing, pp. 729746.De, A., Diakonikolas, I., & Servedio, R. (2012b). inverse Shapley value problem.Czumaj, A., Mehlhorn, K., Pitts, A., & Wattenhofer, R. (Eds.), Automata, Languages,Programming, Vol. 7391 Lecture Notes Computer Science, pp. 266277.Springer.137fiDe Keijzer, Klos, & ZhangDeng, X., & Papadimitriou, C. H. (1994). complexity cooperative solution concepts. Mathematics Operations Research, 19 (2), 257266.Dubey, P., & Shapley, L. S. (1979). Mathematical properties Banzhaf power index.Mathematics Operations Research, 4 (2), 99131.Fatima, S. S., Wooldridge, M., & Jennings, N. R. (2008). anytime approximation methodinverse Shapley value problem. Proceedings Seventh InternationalJoint Conference Autonomous Agents Multi-Agent Systems (AAMAS), pp.935942.Fredman, M. L., & Khachiyan, L. (1996). complexity dualization monotonedisjunctive normal forms. Journal Algorithms, 21 (3), 618628.Freixas, J., & Kurz, S. (2011). minimal integer representations weighted games.CoRR, abs/1303.0868.Freixas, J., & Kurz, S. (2013a). Enumeration weighted games minimumanalysis voting power bipartite complete games minimum. AnnalsOperations Research, Online first.Freixas, J., & Kurz, S. (2013b). golden number Fibonacci sequences designvoting structures. European Journal Operational Research, 226 (2), 246257.Freixas, J., & Molinero, X. (2008). greatest allowed relative error weightsthreshold strict separating systems. IEEE Transactions Neural Networks, 19 (5),770781.Freixas, J., & Molinero, X. (2010). Weighted games without unique minimal representationintegers. Optimization Methods Software, 25 (2), 203215.Freixas, J., Molinero, X., & Roura, S. (2012). Complete voting systems two classesvoters: weightedness counting. Annals Operations Research, 193 (1), 273289.Hu, S. (1965). Threshold logic. University California Press.Isbell, J. R. (1958). class simple games. Duke Mathematical Journal, 25 (3), 423439.Karmarkar, N. (1984). new polynomial-time algorithm linear programming. Proceedings sixteenth annual ACM Symposium Theory computing (STOC),pp. 302311.De Keijzer, B. (2009a). design synthesis voting games: exact solutionsinverse problem. Masters thesis, Delft University Technology.De Keijzer, B. (2009b). survey computation power indices. Tech. rep., DelftUniversity Technology.De Keijzer, B., Klos, T., & Zhang, Y. (2010). Enumeration exact design weightedvoting games. Proceedings 9th International Conference AutonomousAgents Multiagent Systems (AAMAS), pp. 391398.De Keijzer, B., Klos, T., & Zhang, Y. (2012). Solving weighted voting game design problemsoptimally: Representations, synthesis, enumeration. CoRR, abs/1204.5213.Kleijn, A. (2012). Weighted voting game design heuristics. Masters thesis, Erasmus SchoolEconomics, Erasmus University Rotterdam.138fiFinding Optimal Solutions Voting Game Design ProblemsKleitman, D., & Markowski, M. (1975). Dedekinds problem: number isotoneboolean functions II. Transactions American Mathematical Society, Vol. 213,pp. 373390.Klinz, B., & Woeginger, G. J. (2005). Faster algorithms computing power indicesweighted voting games. Mathematical Social Sciences, 49, 111116.Korshunov, A. D. (2003). Monotone boolean functions. Russian Mathematical Surveys,58 (5), 198162.Krohn, I., & Sudholter, P. (1995). Directed weighted majority games. MathematicalMethods Operations Research, 42 (2), 189216.Kurz, S. (2012a). minimum sum representations weighted voting games. AnnalsOperations Research, 196 (1), 361369.Kurz, S. (2012b). inverse power index problem. Optimization, 61 (8), 9891011.Laruelle, A., & Widgren, M. (1998). allocation voting power among EU statesfair?. Public Choice, 94, 317339.Leech, D. (2002a). Computation power indices. Tech. rep. 664, Warwick EconomicResearch Papers.Leech, D. (2002b). Designing voting system EU Council Ministers. PublicChoice, 113 (34), 437464.Leech, D. (2002c). Voting power governance International Monetary Fund.Annals Operations Research, 109, 373395.Leech, D. (2003). Power indices aid institutional design: generalised apportionment problem. Holler, M., Kliemt, H., Schmidtchen, D., & Streit, M. (Eds.),European Governance, No. 22 Jahrbuch fur Neue Politische Okonomie, pp. 107121.Mohr Siebeck.Makhorin, A. (2004). GNU linear programming toolkit..Matsui, Y., & Matsui, T. (2001). NP-completeness calculating power indices weightedmajority games. Theoretical Computer Science, 263 (12), 305310.McKay, B. D. (1998). Isomorph-free exhaustive generation. Journal Algorithms, 26,306324.Muroga, S. (1971). Threshold logic applications. Wiley-Interscience.Muroga, S., Toda, I., & Kondo, M. (1962). Majority functions six variables.Mathematics Computation, 60 (80), 459472.Muroga, S., Tsuboi, T., & Baugh, C. R. (1970). Enumeration threshold functions eightvariables. IEEE Transactions Computers, C-19 (9), 818825.De Nijs, F., Wilmer, D., & Klos, T. (2012). Evaluation improvement LaruelleWidgren inverse Banzhaf approximation. Proceedings Benelux AI Conference(BNAIC), pp. 194201.ODonnell, R., & Servedio, R. A. (2011). Chow parameters problem. SIAM JournalComputing, 40 (1), 165199.139fiDe Keijzer, Klos, & ZhangParberry, I. (1994). Circuit complexity neural networks. Mit Press.Peled, U. M., & Simeone, B. (1985). Polynomial-time algorithms regular set-coveringthreshold synthesis. Discrete Applied Mathematics, 12, 5769.Peleg, B., & Sudholter, P. (2003).Springer.Introduction Theory Cooperative Games.Polymeris, A., & Riquelme, F. (2013). complexity decisive problem simple,regular weighted games. CoRR, abs/1303.7122.Prasad, K., & Kelly, J. S. (1990). NP-completeness problems concerning votinggames. International Journal Game Theory, 19 (1), 19.Shapley, L. S., & Shubik, M. (1954). method evaluating distribution powercommittee system. American Political Science Review, 48 (3), 787792.Siu, K., Roychowdhury, V., & Kailath, T. (1995). Discrete Neural Computation: Theoretical Foundation. Prentice Hall.Sperner, E. (1928). Ein Satz uber Untermengen einer endlichen Menge. MathematischeZeitschrift, 27 (1), 544548.Sutter, M. (2000). Fair allocation re-weighting votes voting power EUnext enlargement. Journal Theoretical Politics, 12, 433449.Taylor, A. D., & Zwicker, W. S. (1999). Simple Games: Desirability Relations, Trading,Pseudoweightings. Princeton University Press.Winder, R. O. (1965). Enumeration seven-argument threshold functions. IEEE Transactions Electronic Computers, EC-14 (3), 315325.Zuev, Y. A. (1989). Asymptotics logarithm number threshold functionsalgebra logic. Soviet Math. Dokl., 39, 512513.Zunic, J. (2004). encoding enumerating threshold functions. IEEE TransactionsNeural Networks, 15 (2), 261267.140fiJournal Artificial Intelligence Research 50 (2014) 31-70Submitted 08/13; published 05/14Knowledge Forgetting Answer Set ProgrammingYisong WangCSC . YSWANG @ GZU . EDU . CNDepartment Computer Science,Guizhou University, Guiyang, ChinaYan ZhangYi ZhouYAN @ SCEM . UWS . EDU . AUYZHOU @ SCEM . UWS . EDU . AUArtificial Intelligence Research Group,University Western Sydney, AustraliaMingyi ZhangZHANGMINGYI 045@ GMAIL . COMGuizhou Academy Sciences, Guiyang, ChinaAbstractability discarding hiding irrelevant information recognized importantfeature knowledge based systems, including answer set programming. notion strongequivalence answer set programming plays important role different problems givesrise substitution principle amounts knowledge equivalence logic programs.paper, uniformly propose semantic knowledge forgetting, called HT- FLP-forgetting,logic programs stable model FLP-stable model semantics, respectively. proposedknowledge forgetting discards exactly knowledge logic program relevant forgotten variables. Thus preserves strong equivalence sense strongly equivalent logicprograms remain strongly equivalent forgetting variables. showsemantic forgetting result always expressible; prove representation theorem statingHT- FLP-forgetting precisely characterized Zhang-Zhous four forgetting postulates HT- FLP-model semantics, respectively. also reveal underlying connectionsproposed forgetting forgetting propositional logic, provide complexityresults decision problems relation forgetting. application proposed forgettingalso considered conflict solving scenario.1. IntroductionMotivated Lin Reiters seminal work (Lin & Reiter, 1994), notion forgetting propositional first-order logics distilling knowledge base part relevantsubset alphabet attracted extensive interests KR community, (e.g., see Lang& Marquis, 2010; Zhou & Zhang, 2011). recent years, researchers developed forgettingnotions theories non-classical logic systems various perspectives, forgetting description logics (Kontchakov, Wolter, & Zakharyaschev, 2008; Wang, Wang, Topor, &Pan, 2010; Lutz & Wolter, 2011; Packer, Gibbins, & Jennings, 2011), forgetting logic programs(Zhang & Foo, 2006; Eiter & Wang, 2008; Wong, 2009; Wang, Wang, & Zhang, 2013), forgetting modal logic (Zhang & Zhou, 2009; Su, Sattar, Lv, & Zhang, 2009; van Ditmarsch, Herzig,Lang, & Marquis, 2009; Liu & Wen, 2011). logical notion, forgetting also studieddifferent terms variable elimination (Lang, Liberatore, & Marquis, 2003), irrelevance, independence, irredundancy, novelty, separability (Bobrow, Subramanian, Greiner, &c2014AI Access Foundation. rights reserved.fiWANG , Z HANG , Z HOU , & Z HANGPearl, 1997). shown study modeling agents behaviors, forgetting playsimportant role conflict resolution (Zhang & Foo, 2006; Lang & Marquis, 2010).propositional logic, result forgetting atom p formula , written Forget(, {p}),formula [p/] [p/>], [p/] [p/>] formula obtained replacing occurrence atom p (false) > (true) respectively. Forgetting set atomsformula defined Forget(, V {p}) = Forget(Forget(, {p}), V ) (Lin, 2001).easy see forgetting preserves logical equivalence. is, logically equivalent formulas(theories) remain logically equivalent forgetting atoms. well known that,mention atoms V|= iff Forget(, V ) |= .sense forgetting propositional logic, called propositional forgetting, knowledgeforgetting since Forget(, V ) exactly contains logical content irrelevant V .logic programs stable model/answer set semantics (Gelfond & Lifschitz, 1988), issue logical equivalence rather complicated due different notions equivalence: (weak)equivalence strong equivalence. Two logic programs 1 2 (weakly) equivalent1 2 stable models; 1 2 strongly equivalent1 2 equivalent every logic program . well known strong equivalence important concept answer set programming (ASP), amounts knowledgeequivalence captures logical content logic program (Osorio & Zacarias, 2004; Osorio& Cuevas, 2007; Delgrande, Schaub, Tompits, & Woltran, 2013), used simplifyinglogic programs two strongly equivalent rules may interchangeable without affectingoriginal logic programs stable models (Pearce, Tompits, & Woltran, 2001; Ferraris, Lee, & Lifschitz, 2011; Lin & Chen, 2007; Lin & Zhou, 2011). strong equivalence characterizedlogic here-and-there (HT), viz, two logic programs strongly equivalentHT-models (Lifschitz, Pearce, & Valverde, 2001). instance, rule following form p p HT-models > (tautology), arbitraryformula. Thus safely removed every logic programs without changing stablemodels.Besides stable model/answer set semantics logic programs (Gelfond & Lifschitz, 1988),FLP-stable model semantics also steadily gains importance (Faber, Pfeifer, & Leone, 2011;Truszczynski, 2010). notion strong equivalence similarly generalized logic programsFLP-stable models semantics: two theories 1 2 strongly FLP-equivalent1 2 FLP-stable models every logic program . shownstrong equivalence characterized terms FLP-models, viz, two logic programsstrongly FLP-equivalent FLP-models (Truszczynski, 2010).develop notion forgetting logic programs, preserving strong equivalenceimportant, like propositional forgetting preserves equivalence propositional logic. Consider two agents need achieve agreement certain goal, agents knowledgebase represented logic program. Suppose two consistent1 logic programs,combination inconsistent. achieve consistent combination, one may forget atomslogic programs, combination forgetting results consistent.forgetting may effectively used solve conflict two agents knowledge1. logic program consistent stable models.32fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGbases (Zhang & Foo, 2006; Eiter & Wang, 2008; Lang & Marquis, 2010). purpose simplicity, hand, agents may also replace knowledge bases strongly equivalentsyntactically simpler ones.Let us consider simple Yale Shooting scenario logic program consistingfollowing rules:2shoot aux;aux shoot;aux, shoot.aux used generate possible occurrences action shoot. One interestedlogic program represents knowledge auxiliary atom aux ignored.intuitively results logic program 0 consisting rule3 :shoot shoot,captures exactly knowledge irrelevant aux. see 0obtained HT-forgetting aux (cf. Example 5 atom names), cannotobtained terms previous forgetting approaches logic programming (cf. Example 11).turns preserving strong equivalence forgetting challenging.several attempts define notion forgetting logic programs, none approachesfully satisfactory. Zhang Foo (2006) first defined syntax oriented weak strong forgettingnotions normal logic programs. forgetting notions preserve neither (weak) equivalencestrong equivalence. Eiter Wang (2008) proposed semantic forgetting consistentdisjunctive logic programs, preserves equivalence strong equivalence. specifically indicated importance preserving strong equivalence logic programming forgettingraised issue future work. Wong (2009) proposed two forgetting operators disjunctive logic programs. Although two operators indeed preserve strong equivalence, may loseintuition weakening various circumstances (see Section 5 details). recently proposedforgetting logic programs may introduce extra knowledge (cf., see Wang et al., 2013, Ex. 2).Thus knowledge forgetting.Together preserving strong equivalence, expressiveness another desired criterionlogic programming forgetting. Ideally would expect result forgetting atomslogic program still expressible logic program. particularly necessaryview agents knowledge bases logic programs forgetting employed means conflictsolving among agents knowledge bases (Zhang & Foo, 2006). previous logic programming forgetting approaches meet criterion, see paper, considerforgetting arbitrary logic programs, retaining expressibility challenging objective achievesemantic forgetting notion.Finally, believe way weakening, knowledge forgetting logic programsobey common intuitions shared forgetting classical logics. instance, forgettingsomething logic program lead weaker program certain sense.hand, weakening associated relevant information forgotten.purpose, Zhang Zhou (2009) proposed four forgetting postulates formalizecommon intuitions showed forgetting propositional logic modal logic S5precisely captured postulates. Surprisingly, none previous forgetting notions logic2. due one anonymous reviewers.3. rule strongly equivalent choice rule 0{shoot}1 normal rule.33fiWANG , Z HANG , Z HOU , & Z HANGprograms actually satisfies Zhang-Zhous postulates. sense previous forgetting notionslogic programs knowledge forgetting operators.summary, consider following criteria knowledge forgetting notion logic programs meet:Expressibility. result forgetting arbitrary logic program also expressible via logic program;Preserving strong equivalence. Two strongly equivalent logic programs remain stronglyequivalent forgetting variables;Satisfying common intuitions forgetting. Preferably, forgetting logic programssemantically characterized Zhang-Zhous four forgetting postulates.paper present comprehensive study knowledge forgetting context arbitrary logic programs (propositional theories) stable model FLP-stable models semantics,called HT- FLP-forgetting respectively. show HT- FLP-forgetting meetcriteria, hence primary advantages compared previous logic program forgettingnotions.main contributions paper may summarized follows, ? {HT, FLP },- starting point, investigate model theoretical characterization strong equivalence logic programs stable model FLP-stable model semantics, explorestrong equivalence equivalence propositional logic.- propose semantic ?-forgetting logic programs ?-stable model semantics respectively. HT-stable model means stable model. ?-forgetting result alwaysexpressible via logic program preserves strong equivalence stable modelFLP-stable model semantics.- investigate semantic properties ?-forgetting, show ?-forgetting satisfiesZhang-Zhous four postulates ?-model respectively. particular, forgettingresult consists logical content irrelevant forgotten atoms.- establish underlying connections ?-forgetting propositional forgetting,based provide complexity results decision problems relation ?forgetting. particular, show resulting checking deciding logic programresult ?-forgetting set atoms logic program P2 -complete, relatedinference problem terms ?-forgetting varies co-NP-complete P2 -complete.theoretical negative results confirm easy task simplify logic programsforgetting. fortunately, kind simplification computed offline general.instance, problem domain description involves lot auxiliary propositional variables.One firstly simplify description forgetting (part of) auxiliary propositionalvariables, like kind compilation (Lang et al., 2003).- Finally consider application knowledge forgetting solving conflictscontext logic programming.34fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGrest paper organized follows. Section 2 briefly reviews necessary conceptsnotions answer set programming. Section 3 presents characterizations strong equivalencelogic programs. firstly present uniform definition knowledge forgetting logicprograms section 4, explore expressibility, forgetting postulates, relationshippropositional forgetting, computational complexity application knowledge forgettingconflict solving. Section 5 discusses forgetting approaches logic programs, finally,Section 6 concludes paper remarks. proofs paper deferredAppendix clarity.paper revised extended version paper appeared Proceedings KR2012 (Wang, Zhang, Zhou, & Zhang, 2012).2. Answer Set Programmingsection briefly recall basic notions logic programming stable model semantics, including syntax, reduction, stable model (Ferraris, 2005) FLP-stable models (Truszczynski, 2010) strong equivalence (Lifschitz et al., 2001; Truszczynski, 2010). paper stablemodel called HT-stable model convenience, assume ? {HT , FLP }.assume propositional language LA finite set propositional atoms,called signature language LA .2.1 Syntaxformulas LA built signature4 0-place connective (false) usingbinary connectives , follows:::= | p | | |(1)p A. > (true) shorthand , , ( ) (). theory set formulas.interpretation set atoms A, atom viewed trueI, false otherwise. propositional logic, notions model satisfaction relation |=defined usual. following denote \ X X X A, Mod() {M |M |= },/ M}Mod() = Mod() (i.e. equivalent ) {I A|I2 . formula irrelevant set V atoms, written IR(, V ), exists formulamentioning atoms V .convenience,WV also define following notations. Let finite set formulas.Wdenote SV(resp.S) disjunction (resp. conjunction) formulas S,denotes denotes >, |S| cardinality S. Similarly (resp. S) mean{ | S} (resp. { | S}).2.2 Reduct Stable ModelsLet formula X A. ?-reduct w.r.t. X, written Red? (, X), recursivelyuniformly defined follows:4. rest paper, whenever confusion, may explicitly mention signature talkformulas LA .35fiWANG , Z HANG , Z HOU , & Z HANG(?-R1) Red? (, X) = ;(?-R2) Red? (p, X) = p X |= p, otherwise;(?-R3) Red? (1 2 , X) = Red? (1 , X) Red? (2 , X) X |= 1 2 {, },otherwise;(HT-R4) RedHT (1 2 , X) = RedHT (1 , X) RedHT (2 , X) X |= 1 2 , otherwise;1 RedFLP (2 , X), X |= 1 2 ;(FLP-R4) RedFLP (1 2 , X) =>,X 6|= 1 ;,otherwise (i.e. X 6|= 1 2 ).Definition 1 set X ?-stable model formula X minimal (under set inclusion)model Red? (, X). denote set ?-stable models SM ? ().Please note that, traditionally, HT-reduct named reduct; Red HT (, X) written X ;HT-stable model called stable model (Ferraris, 2005); RedFLP (, X) written X(Truszczynski, 2010).known that, HT-stable models FLP-stable models comparable senseHT-stable models FLP-stable models, FLP-stable models HT-stablemodels (cf., see Truszczynski, 2010, Exs. 1, 2, 4 5).Example 1 Let us consider following formulas:Let = p p p.RedHT (, ) , RedHT (, {p}) >, RedFLP (, ) , RedHT (, {p}) p.Thus SM HT () = , SM FLP () = {{p}}.Let 1 = p p 2 = p p. following:RedHT (i , ) > RedHT (i , {p}) p, = 1, 2,RedFLP (1 , ) >, Red FLP (1 , {p}) p, RedFLP (2 , ) >, RedFLP (2 , {p}) >.Thus, SM FLP (1 ) =SM HT (1 )= {, {p}}, SM FLP (2 ) = {}.Definition 2 Two formulas 1 2 ?-SM -equivalent (under ?-stable model semantics), written 1 ?SM 2 , iff ?-stable models.notion HT-SM -equivalence indeed notion equivalence logic programsstable model semantics (cf., see Lifschitz et al., 2001, Thm. 1).36fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMING2.3 Strong Equivalence Knowledge Logic ProgramsUnlike equivalence propositional logic, equivalence logic programs allowequivalent replacement i.e., 1 2 may different stable models, even though 12 equivalent.Example 2 Let 1 = p q 2 = p p. SM ? (1 ) = SM ? (2 ) = {}, 1 2?-SM-equivalent; however, p 1 ?-stable model {p, q} unique ?-stable modelp 2 {p}. Thus allow replacing 1 2 p 1 . also indicates 1different knowledge 2 ?-stable model semantics.motivates notion strong equivalence.Definition 3 Two formulas 1 2 strongly ?-equivalent (under ?-stable model semantics)iff 1 ?SM 2 every formula . case 1 2 strongly ?-equivalent,?-knowledge equivalent.known notion strong ?-equivalence captured terms ?-models,?-interpretation pair hX, X A. ?-satisfiability (thus ?-models),denoted |=? , recursively defined follows:(?-S1) hX, 6|=? ;(?-S2) hX, |=? p p X;(?-S3) hX, |=? 1 2 hX, |=? 1 hX, |=? 2 ;(?-S4) hX, |=? 1 2 hX, |=? 1 hX, |=? 2 ;(HT-S5) hX, |=HT 1 2 |= 1 2 ; hX, |=HT 1 implies hX, |=HT 2 ;(FLP-S5) hX, |=FLP 1 2 |= 1 2 ; 6|= 1 X 6|= 1 hX, |=FLP 2 .Mod? () denote set ?-models formula . Please note that, ?either HT FLP . particular, ModHT () (resp. ModFLP ()) denotes set HT-models (resp.FLP-models) . formulas 1 2 Example 2, one check none h, {p}i,h{p}, {p}i h{p}, {p, q}i ?-model 1 , every ?-interpretation ?-model 2 .Definition 4 formula logical ?-consequence formula , written |=? , iff Mod? ()Mod? (); two formulas ?-equivalent (under ?-model semantics), written ? , iffMod? () = Mod? ().following proposition, item (i) proved Lifschitz, Tang, Turner (cf., see Lifschitzet al., 1999, (iii) Prop. 6).Proposition 1 Let A, B, C, set atoms. followingVWVW(i) (A B) (D C) HT (A B C) D.VWVW(ii) (A B) (D C) |=FLP (A B C) D.37fiWANG , Z HANG , Z HOU , & Z HANGPlease note inverse (ii) generally hold. instance, p p FLP >h, {p}i 6|=FLP p p.Given two formulas 1 2 , known 1 2 strongly HT-equivalentHT -stable model semantics HT -equivalent, viz. 1 HT 2 ; 1 2strongly FLP -equivalent FLP -stable model semantics FLP -equivalent,viz. 1 FLP 2 (cf., see Truszczynski, 2010, Thm. 7). commonly recognized strongequivalence amounts knowledge equivalence formulas. is, strong ?-equivalence captureslogical content formula ?-stable model semantics (Osorio & Zacarias, 2004; Osorio& Cuevas, 2007; Delgrande et al., 2013). formally define knowledge logic programs.Definition 5 ?-knowledge formula ?-stable model semantics, written Cn? (),consists logical ?-consequence , viz, Cn? () = { | |=? }.?-knowledge formula stands ?-logical content formula. instance,CnHT (>) = CnHT (p p) CnHT (p q).Recall that, ?-model semantics, every formula transformed conjunctionformulas following normal form:^_(B C) (A D)(2)A, B, C, sets atoms (cf., ? = HT, see Cabalar & Ferraris, 2007, Thm. 2;Truszczynski, 2010, Thm. 9 ? = FLP ). is, every formula , conjunctionformulas form (2) strongly ?-equivalent .formula form (2) called rule, also generally writtena1 ; . . . ; al ; d1 ; . . . ; dn b1 , . . . , bk , c1 , . . . , cm(3)= {ai |1 l}, B = {bi |1 k}, C = {ci |1 m} = {di |1 n}.logic program finite set rules. Let r rule form (2). saiddisjunctive = ;positive C = = ;normal |A| 1 = ;Horn |A| 1 C = = .logic program disjunctive (resp. positive, normal, Horn) iff consists disjunctive(resp. positive, normal, Horn) rules. logic program ?-consistent (under ?-stable model semantics) least one ?-stable model.known every logic program HT-models FLP-models (cf., see Truszczynski, 2010, Prop. 8).Proposition 2 Every logic program HT-FLP-models.3. Characterizations Knowledge Equivalencesection, perspective ?-models, consider characterization knowledgeequivalence various logic programs firstly, relate knowledge equivalence equivalence propositional logic secondly.38fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMING3.1 Model Theoretical Characterizationfirstly recall basic properties ?-satisfiability (Ferraris & Lifschitz, 2005; Ferraris,2005; Truszczynski, 2010).Proposition 3 Let formula X A.(i) hX, |=? hY, |=? (i.e., |= ).(ii) hX, |=? iff |= .(iii) hX, |=? iff X |= Red? (, ).collection ?-interpretations ?-expressible whenever exists formulaMod? () = M. collection ?-interpretations may ?-expressible. instance,formula whose ?-models ones = {h, {p}i}. reasonformula Mod? () = h{p}, {p}i |=? (i) Proposition 3.requires h{p}, {p}i belonging Mod? (), contradiction.Given formula X A, hX, ?-countermodel hX, 6|=?hY, |=? ; hY, ?-countermodel hY, 6|=? . Let X A, definefollowing formulas:_(X ) ((Y \ X) (Y \ X)),_^FLP (X, ) = (X ) (X ),^(Y, ) = (Y ) ,_^(X, ) = (X ) (Y \ X).HT (X, ) =^(4)(5)(6)(7)? (X, ) (Y, ) capture ?-countermodel hX, hY, respectively.following lemma shows ?-countermodel captured formula (cf.,? = HT, see Cabalar & Ferraris, 2007, Prop. 1; Truszczynski, 2010, Props. 5 6 ? = FLP ).Lemma 1 Let X U V A.(i) hU, V ?-countermodel ? (X, ) iff U = X V = .(ii) hU, V ?-countermodel (Y, ) iff V = .Proposition 4 collection ?-interpretations ?-expressible iffhX, implies hY, M.Actually, satisfy condition (8) following logic program? = {? (X, )|hX,/ hY, M} {(Y, )|hY,/ M}captures sense Mod? (? ) = M.39(8)fiWANG , Z HANG , Z HOU , & Z HANGNote Wong (2009) presented model-theoretical characterization HT-modelsdisjunctive logic programs (cf., see Wong, 2009, Thm. 2.7). Formally speaking, collectionHT-interpretations disjunctively HT-expressible, i.e., disjunctive logic programModHT () = M, iff condition (8) following one hold:hX, M, 0 hY 0 , 0 hX, 0 M.(9)Together Proposition 2,Corollary 1 collectiontions (8) (9) hold.FLP -interpretationsdisjunctivelyFLP -expressibleiff condi-Actually, satisfies conditions (8) (9) following disjunctive logic programcaptures M.= {(X, )|hX,/ hY, M} {(Y, )|hY,/ M}.LemmaVW2 Let A, B beVtwo setsW atoms, X A. hX, |=?B |= B A.VBWiff X |=Proposition 5 set ?-interpretations positively ?-expressible, i.e., positive logicprogram s.t Mod? () = M, iff satisfies criteria:hX, iff X Y, hX, Xi hY, M.(10)Va matterW fact, case satisfies condition (10), positive logic program =/ M} captures M.{ X X|hX, XiCorollary 2 Two positive logic programs strongly ?-equivalent equivalentpropositional logic.Eiter, Fink, Tompits, Woltran (2004) showed disjunctive logic programstrongly equivalent normal logic program closed here-intersection, i.e.,every pair HT-models hX, hX 0 , , hX X 0 , also HT-model (cf.,see Eiter et al., 2004, Thms. 1 2). terms characterization disjunctive logic programsProposition 2, obtain ?-model characterization normal logic programs follows.Corollary 3 set ?-interpretations normally ?-expressible, i.e., normal logicprogram Mod? () = M, iff satisfies, addition (8) (9), followingcriteria:hX, hX 0 , hX X 0 , M.(11)Proposition 6 collection ?-interpretations Horn ?-expressible, i.e., Horn logicprogram Mod? () = M, iff satisfies, addition (10), following criteria:hX, hH, hX H, M.40(12)fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMING3.2 Relating Knowledge Equivalence Propositional Logicproved strong equivalence logic programs stable model semantics relatedequivalence propositional logic (Pearce et al., 2001; Lin, 2002). holds strongFLP-equivalence logic programs show following.Firstly, extend language LA LAA0 A0 = {p0 |p A} p0 fresh atoms.expression LA , 0 denote result obtained replacing atom pcorresponding atom p0 A0 . following denote(A) = {p p0 | p A}.(13)Please note that, model (A), splitting MA0 =MA0 = A0 and, every p , atom p0 A0 belongs MA0 . A0denote set {p A|p0 }.Definition 6 HT [.] FLP [.] recursively defined follows:(T1) ? [] = ;(T2) ? [p] = p;(T3) ? [1 2 ] = ? [1 ] ? [2 ] {, };(HT-T4) HT [1 2 ] = (01 02 ) (HT [1 ] HT [2 ]);(FLP-T4) FLP [1 2 ] = (01 02 ) (1 01 FLP [2 ]).Please note translation HT translation defined Pearce, Tompits,Woltran (2001). One verify HT [] = 0 HT [], FLP [] = 0 . Giventheory LA , define ? [] = {? [] | }. evident ? [] linear size .Example 3 Let = p p p.HT [] = ((p0 p0 ) p0 ) ((p p p0 ) p) p0 ,FLP [] = ((p0 p0 ) p0 ) ((p p) (p0 p0 ) p) p0 p.unique FLP-model (over signature {p}) h{p}, {p}i. However, two HT-modelsh, {p}i h{p}, {p}i. signature {p, p0 }, one easily check {HT []} (A)two models {p, p0 } {p0 }, {FLP []} (A) unique model {p, p0 }.VWProposition 7 Let = (B C) (A D), A, B, C, subsets A.(A) |= FLP [] HT [].following proposition connects ?-equivalence equivalence classical propositional logic (cf., ? = HT, see Pearce et al., 2001, Lem. 2).Proposition 8 Let formula LA X A. hX, ?-model iffX 0 model (A) {? []}.41fiWANG , Z HANG , Z HOU , & Z HANGfollowing theorem shows strong ?-equivalence logic programs ?-stablemodel semantics reduced equivalence propositional logic (cf., ? = HT, seeFerraris et al., 2011, Thm. 9; Lin & Zhou, 2011, (5) Thm. 6).Theorem 4 Two formulas ?-models (over A) iff (A){? []} (A){? []} models (over A0 ).Based theorem, obtain following complexity result (cf., ? =Tompits, & Woltran, 2009, Thms. 8 11).HT ,see Pearce,Proposition 9 (i) problem deciding formula ?-satisfiable NP-complete.(ii) problem deciding two formulas ?-equivalent co-NP-complete.4. Knowledge Forgetting Logic Programsmentioned introduction, concentrate knowledge forgetting logic programsstable model semantics. formally stated following:Definition 7 (Knowledge forgetting) Let logic program V A. logic programresult ?-knowledge forgetting V , consists ?-knowledgementions atom V .show knowledge forgetting result always exists unique strongequivalence (cf. Theorem 6) semantic ?-forgetting defined explored.Let V, X, sets atoms. set V -bisimilar X, written V X, \V = X \V .intuitively states interpretations X agree atoms V .Two ?-interpretations hH, hX, V -bisimilar, written hH, V hX, i, H V XV . Now, position define semantic knowledge forgetting termsbisimulation.Definition 8 (Semantic knowledge forgetting) Let formula V A. formularesult (semantic) ?-forgetting V whenever, every ?-interpretation ,Mod? () iff 0 Mod? () s.t V 0 .(14)According definition, one see ?-models somehow exactly constructed. motivates us define following notion extension.Let V, X, sets atoms. V -extension X, denoted XV , collectioninterpretations V -bisimilar X. V -extension ?-interpretation hH, i, denotedhH, iV , collection ?-interpretations V -similar hH, i. instance, lethH, = h{p, q}, {p, q}i V = {q, r}. hH, iV contains h{p}, {p}i, h{p}, {p, q}i,h{p}, {p, q, r}i, h{p, q, r}, {p, q, r}i on. Intuitively speaking, V -extension interpretation collection interpretations formed freely adding removingatomsSin V . V -extension collection (?-)interpretations, written MV , collection V .classical propositional logic corresponds formula , i.e. = Mod(), MVcorresponds formula whose truth value nothing atoms V . intendedmeaning case ?-models similar MV corresponds formula ?-model42fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGsemantics relevant atoms V . words, suppose MV = Mod? ().hX, |=? hH, |=? H (resp. ) obtained X (resp. ) freelyadding removing atoms V whenever H . following lemma shows equivalentcondition semantic ?-knowledge forgetting.Lemma 3 Let formula V A. formula result ?-forgetting V , ifffollowing condition holds:Mod? () = Mod? ()V .(15)condition ?-forgetting generalization forgetting propositional logic (Lin &Reiter, 1994) terms following corollary.Corollary 5 formula result forgetting set V atoms formula iff Mod() =Mod()V , Mod(.) refers classical propositional logic.syntactic counterpart forgetting propositional logic defined follows (Lin, 2001;Lang et al., 2003):Forget(, {p}) = [p/] [p/>],Forget(, V {p}) = Forget(Forget(, {p}), V )[p/>] (resp. [p/]) formula obtained replacing every occurrenceatom p > (resp. ).?-interpretations related given signature A, follows, shall assumesignature formula/theory implicitly given atoms occurring formula/theory,unless explicitly stated otherwise. example illustrates ?-forgetting resultscomputed.Example 4 Let following formula(p q) (q p) (p ) (q ).signature {p, q}, Mod? () = {h, {p, q}i, h{p, q}, {p, q}i}. Please note? either HT FLP. Definition 8, verify Mod? (){p} ={h, {q}i, h{q}, {q}i}{p} . corresponds formula = (p q ) (p q)?-model semantics Proposition 4. matter fact, ? q ? q.Note Forget(, {p}) = [p/>] [p/] q q 6? q. shows that, unlikesyntactic counterpart forgetting classical propositional logic, ?-forgetting results cannotcomputed via [p/>] [p/] Mod? (q) = {h, {q}i, h{q}, {q}i}, Mod? (q) ={h{q}, {q}i} (over signature {q}).4.1 ExpressibilityPlease note Definition 8 guarantee existence forgetting results, howevernext theorem shows ?-forgetting result always exists. also implies ?-forgettingresult unique (up strong ?-equivalence).43fiWANG , Z HANG , Z HOU , & Z HANGTheorem 6 (Expressibility theorem) Let formula V set atoms. existsformula Mod? () = Mod? ()V .Here, uniqueness strong ?-equivalence ?-forgetting result follows factthat, formula 0 result ?-forgetting V well Mod? ( 0 ) = Mod? ()V =Mod? (), shows 0 strongly ?-equivalent ?-stable model semantics.Based expressibility result abusing denotation, denote forgetting resultForget? (, V ):Definition 9 Let formula V A. Forget? (, V ) formula s.t Mod? () =Mod? ()V , i.e., Forget? (, V ) result ?-forgetting V .sense Forget? operator maps formula set atoms formula. AccordingDefinition 8 expressibility theorem, following corollary easily follows.Corollary 7 Let , formulas, V , V1 V2 sets atoms.(i) Forget? (Forget ? (, V1 ), V2 ) ? Forget? (Forget ? (, V2 ), V1 ).(ii) ? Forget? (, V ) ? Forget? (, V ).firstly states ?-forgetting independent order forgotten atoms, secondly,?-forgetting preserves strong ?-equivalence logic programs ?-stable model semantics.investigate properties forgetting, introduce notion irrelevance?-model semantics.Definition 10 formula ?-irrelevant set V atoms, denoted IR? (, V ), existsformula mentioning atoms V ? .basic properties ?-forgetting presented below.Proposition 10 Let two formulas V set atoms.(i) IR? (Forget ? (, V ), V ).(ii) ?-model iff Forget? (, V ) has.(iii) |=? Forget? (, V ).(iv) |=? Forget? (, V ) |=? Forget? (, V ).(v) Forget? ( , V ) ? Forget? (, V ) Forget? (, V ).(vi) Forget? ( , V ) |=? Forget? (, V ) Forget? (, V ).(vii) Forget? ( , V ) ? Forget? (, V ) IR? (, V ).44fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGIntuitively, (i) Proposition says ?-forgetting result irrelevant atoms V ,i.e., forgotten atoms. sense, signature ?-forgetting result constrained\ V . intended meaning others easily read out. E.g., item (iii) saysforgetting kind weakening, item (v) shows forgetting distributive propertydisjunction.mentioned earlier, disjunctive programs, positive programs, normal logic programs Hornprograms four types special cases (arbitrary) logic programs setting.interesting consider whether expressibility result also holds special programs.instance, would like know whether result ?-forgetting disjunctive (positive,normal, Horn) logic program still expressible disjunctive (resp. positive, normal,Horn) logic program.indicated following two examples, HT- FLP-forgetting disjunctive, positivenormal logic programs possibly expressible either disjunctive positive logic programs.simplicity, identify singleton set {} clear context, thusdenote Forget? (, {p}) Forget? (, p), IR? (, {p}) IR? (, p), M{p} Mp etc..Example 5 Consider following normal logic program signature {p, q}:(p q) (q p) (p q ).Mod? () = {h{p}, {p}i, h{q}, {q}i}Mod? ()p = {h, i, h{q}, {q}i}{p} .h{p}, {p}i{p} = h, i{p} . implies Forget? (, p) ? q q. easily seenq q cannot expressed disjunctive logic program Mod? ()p satisfy (9).Hence Forget? (, p) cannot expressed normal logic program.Please note q q HT q q. Thus q q also result HT-forgetting p .However, q q result FLP-forgetting p q q FLP > 6FLP q q.Example 6 Let positive logic program signature {p, q, r} follows:(p q r) (p q r) (p r q) (q r p).difficult verify that, signature {p, r}, Mod? (){q} consistsh, i, h, {p, r}i, h{p}, {p}i, h{p}, {p, r}i, h{r}, {r}i, h{r}, {p, r}i, h{p, r}, {p, r}i.Clearly satisfy condition (9). Hence captured disjunctive logic program. matter fact, followingForget HT (, q) HT HT (, {p}) HT (, {r}) = (r p p) (p r r),Forget FLP (, q) FLP FLP (, {p}) FLP (, {r}) = (r p r p) (p p r r)terms Proposition 4. Interestingly, example also shows that, though logic program mayHT-models FLP-models, HT-forgetting result may different FLPforgetting result.45fiWANG , Z HANG , Z HOU , & Z HANGHT- FLP-forgetting Horn logic programs special interest, unlike disjunctive, positive normal logic programs, result HT- FLP-forgetting result Hornlogic program always expressible Horn logic program, show below.Theorem 8 (Horn expressibility) Let Horn logic program V A. Hornlogic program 0 Forget? (, V ) ? 0 .obtained model-theoretical characterization classes disjunctive normallogic programs respectively, easily derive sufficient necessary condition HT-FLP-forgetting results remain class, i.e., result HT- FLP-forgetting setatoms disjunctive (resp. normal) logic program disjunctive (resp. normal) logic program.Proposition 11 Let disjunctive logic program, V A. Forget? (, V )expressible disjunctive logic programs if,hH1 , T1 |=? , hT2 , T2 |=? T1 T2 hH3 , T3 |=? hH3 , T3 V hH1 , T2 i.Proposition 12 Let normal logic program, V A. Forget? (, V ) expressiblenormal logic programs if, addition condition (16), following condition holds,hH1 , T1 |=? , hH2 , T2 |=? T1 V T2hH3 , T3 |=? H3 V H1 H2 (T3 V T1 T3 V T2 ).(16)4.2 Forgetting PostulatesZhang Zhou (2009) proposed four forgetting postulates work knowledge forgetting,showed knowledge forgetting precisely characterized four postulates.argued postulates viewed general semantic characterizationknowledge forgetting logics. Indeed, classical propositional forgetting alsocharacterized postulates. terms forgetting logic programs, addressedintroduction, imposing postulates feasible existing approaches. following,show ?-forgetting exactly captured postulates, think one majoradvantage logic program forgetting approaches.notion forgetting closely related uniform interpolation property (Visser, 1996;Goranko & Otto, 2007), instance, forgetting description logics (Lutz & Wolter, 2011)semantic forgetting logic programs (Gabbay, Pearce, & Valverde, 2011). followingcorollary follows Theorem 6, actually implies uniform interpolation propertylogics ?-model semantics. Namely, formulas |=? , existsformula |=? , |=? contains atoms occurring .formula called uniform interpolant . stated as:Corollary 9 Let two formulas, V set atoms IR? (, V ).|=?iffForget? (, V ) |=? .Let two formulas V set atoms. following Zhang-Zhous fourpostulates logic programs ?-model semantics.46fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMING(W) Weakening: |=? .(PP) Positive persistence: IR? (, V ) |=? |=? .(NP) Negative persistence: IR? (, V ) 6|=? 6|=? .(IR) Irrelevance: IR? (, V ).specifying ? Forget? (, V ), (W), (PP), (NP) (IR) called postulates knowledgeforgetting logic programs ?-stable model semantics. Viz, result ?-forgetting V. Based uniform interpolation property (cf. Corollary 9), show followingrepresentation theorem.Theorem 10 (Representation theorem) Let two formulas V set atoms.following statements equivalent:(i) ? Forget? (, V ).(ii) ? {0 | |=? 0 IR? (0 , V )}.(iii) Postulates (W), (PP), (NP) (IR) hold.theorem justifies knowledge forgetting (cf. Definition 7) exists uniquestrong equivalence.obvious consequence follows representation theoremForget? (, V ) ? { | |=? IR? (, V )}.says result ?-forgetting V consists ?-logical consequence?-irrelevant V . reason forgetting knowledge forgetting logic programsstable models semantics. mentioned introduction noneforgetting approaches logic programs knowledge forgetting since satisfypostulates (see Section 5 details).One note representation theorem applicable forgetting classicalpropositional logic, viz, Forget(, V ) { | |= IR(, V )}.4.3 Relating Propositional Forgettingshown strong equivalence logic programs may related equivalencepropositional logic (Pearce et al., 2001; Lin, 2002). ?-forgetting preserves strong equivalencelogic programs ?-stable model semantics, worth exploring connections?-forgetting forgetting propositional logic. section, undertake in-depthinvestigation aspect.first provide direct connection ?-forgetting propositional forgetting viafollowing proposition.Proposition 13 Let , 0 , formulas V ? Forget? (, V ) 0Forget(, V ).(i) 0 .47fiWANG , Z HANG , Z HOU , & Z HANG(ii) 0 |=? .result (i) Proposition 13 simply says result ?-forgetting classical propositional forgetting equivalent classical propositional logic. Thus forgetting classic propositional logic computed ?-forgetting logic programs. However seenExample 4, Forget? (, V ) possibly ?-equivalent Forget(, V ). reverse (ii)hold generally. instance, Forget? (p, q) ? p, Forget(p, q) p, evidentlyp 6|=? p. result Theorem 8, immediately following corollary.Corollary 11 Let Horn logic program V set atoms. Forget(, V ) expressible Horn logic program.following result states that, Horn logic programs, ?-forgetting forgettingpropositional logic strongly ?-equivalent. Thus provides method computing ?-forgettingresults Horn logic programs propositional forgetting.Proposition 14 Let 0 two Horn logic programs, V set atoms 0Forget(, V ). 0 ? Forget? (, V ).following proposition states ?-forgetting double negative formulas closelyconnected classical propositional forgetting, used prove complexityresults later.Proposition 15 Let two formulas V set atoms.(i) Forget(, V ) iff ? Forget? (, V ).(ii) Forget(, V ) Forget(, V ) iff Forget? (, V ) ? Forget? (, V ).known strong equivalence logic programs closed related equivalencepropositional logic translating logic programs propositional theories (Pearce et al., 2001;Lin, 2002). motivates us investigate connection forgettings viewtranslations. main result section stated follows.Theorem 12 (?-forgetting vs propositional forgetting) Let two formulas LAV A.? Forget? (, V ) iff (A) |= ? [] Forget((A) {? []}, V V 0 ).Theorem 12, know check whether formula result ?-forgetting setV atoms formula , equivalent check whether ? [] classically equivalentForget((A) {? []}, V V 0 ) theory (A). following example showsapplication theorem.Example 7 [Example 5 continued] Recall following formula:(p q) (q p) (p q )48fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGForget? (, p) ? q q. signature {p, q}, (A) = (p p0 ) (q q 0 ) and,program translation yields:? () (p0 q) (p0 q 0 ) (q 0 p) (q 0 p0 ) (p0 q 0 ).Forget(? [] (A), {p, p0 }) equivalent to:(q q 0 ) (q q 0 ),i.e.(q 0 q) (q q 0 )equivalent q 0 q theory ({q}) = {q q 0 }. One check? [q q] = q 0 q q q 0 q (under theory ({q})). Thus formula q q result?-forgetting p Theorem 12.following example shows (A) occurring Forget? ({ []} (A), V V 0 )necessary Theorem 12.Example 8 [Continued Example 6] Recall = {p, q, r}, (A) = {p p0 , q q 0 , rr 0 } consists(p q r) (p q r) (p r q) (q r p).that,HT [] ,(A) |= ? [] ,FLP [] (p q r) (p q p0 q 0 r) (p r p0 r 0 q) (q r q 0 r 0 p)= (p0 q 0 r 0 ) (p0 r 0 q 0 ) (q 0 r 0 p0 ).One checkForget(HT [], {q, q 0 }) >,(A) |= Forget(FLP [], {q, q 0 }) >.Recall formula 1 = (r p p) (p r r) result HT-forgetting q ;2 = (r p r p) (p p r r) result FLP-forgetting q .HT [1 ] 01 (r r 0 p p p0 ) (p p0 r r r 0 ),FLP [2 ] 02 (r r 0 p r p0 ) (p p0 p r r 0 ).theory (A),(A) |= HT [1 ] (p0 p r 0 ) (r 0 r p0 ),(A) |= HT [1 ] (p0 p r 0 ) (r 0 r p0 ).One verify model {p0 } (A) model HT [1 ], modelFLP [2 ], i.e. (A) 6|= HT [1 ] > (A) 6|= FLP [2 ] >. Actually, that,(A) |= Forget({? []} (A), {q, q 0 }) ((p0 r 0 ) (p r) (p0 r 0 )).One check(A) |= (p0 p r 0 ) (r 0 r p0 ) ((p0 r 0 ) (p r) (p0 r 0 )),shows 1 (resp. 2 ) result HT-forgetting (resp.49FLP-forgetting)q .fiWANG , Z HANG , Z HOU , & Z HANGfollowing result states reduce checking whether ?-forgetting results twoformulas strongly ?-equivalent checking whether propositional forgetting results corresponding two formulas equivalent.Proposition 16 Let two formulas LA V set atoms. Forget? (, V ) ?Forget? (, V ) iff following condition holds:Forget({? []} (A), V V 0 ) Forget({? []} (A), V V 0 ).4.4 Computation ComplexityTheorem 6 Propositions 4 10 imply naive approach compute ?-forgetting results. Formally speaking, given formula signature set V atoms, Forget? (, V )computed follows:(Step 1) Evaluating ?-models , denoted M.(Step 2) Restrict \ V , denoted M|V , i.e.M|V = {hH \ V, \ V i|hH, M}.(Step 3) Enumerating following formulas (over signature \ V ) M|V :? (X, ) hX,/ M|V hY, M|V ,(Y, ) hY,/ M|V .(Step 4) Finally, conjunct constructed formulas, denoted .Corollary 13 Let , V given above. ? Forget? (, V ).Alternatively, terms Theorem 10, compute Forget? (, V ) enumerating ?consequences ?-irrelevant V . exist sound complete axiomatic systemsHT-logic (Jongh & Hendriks, 2003), checking HT-consequence relation axiomaticallydoable. Though sound complete axiomatic system FLP-logic recently unknown, stillenumerate formulas form (2) signature \ V check FLPconsequence . Nevertheless, also observed computational viewpoint, likepropositional forgetting, two approaches would expensive. appearsinevitable terms following complexity results, unless complexity hierarchy collapses.Theorem 14 Let two formulas V set atoms.(i) problem deciding ? Forget? (, V ) co-NP-complete.(ii) problem deciding Forget? (, V ) ? Forget? (, V ) P2 -complete.(iii) problem deciding ? Forget? (, V ) P2 -complete.50fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGAccording representation theorem (i.e. Theorem 10), result (i) Theorem 14 meanschecking ?-irrelevant V , i.e. IR? (, V ), intractable. result (ii) Theorem 14,hand, presents complexity ?-forgetting equivalence checking, i.e., two formulasstrongly ?-equivalent restricted common signatures. last result (iii)Theorem 14 states checking formula result ?-forgetting generally difficult.Proposition 17 Let two formulas V set atoms.(i) problem deciding whether |=? Forget? (, V ) P2 -complete.(ii) problem deciding whether Forget? (, V ) |=? co-NP-complete.Theorem 14 Proposition 17 tell us ?-forgetting, general complexity resulting checking inference problems located level complexity polynomialhierarchy propositional forgetting.4.5 Conflict Solving Based Knowledge Forgettingfollowing, consider application proposed forgetting conflict solving logicprogram contexts, represent knowledge system consisting knowledge bases multipleagents.Definition 11 logic program context n-ary tuple = (1 , . . . , n ) consistentlogic program. ?-conflict-free 1 n consistent ?-stable model semantics.Definition 12 Let = (1 , . . . , n ) logic program context. ?-solution minimalsubset (Forget? (1 , S), . . . , Forget? (n , S)) ?-conflict-free,underlying signature.obvious ?-solution ?-conflict-free logic program context .consider following simplified Zhang Foos conflict solving scenario (cf., see Zhang& Foo, 2006, Ex. 6).Example 9 couple John Mary discussing family investment plan. fourdifferent shares shareA, shareB, shareC shareD, shareA shareB high riskalso high return; shareC shareD low risk may suitable long terminvestment. Johns Marys investment preference shares encoded followinglogic programs J respectively:J ::r1 :sA sB,r10 :sC ,r2 :sC sD,r20 :sD ,r3 :sD sC,r30 :sB sA, sC,r4 : sC, sD,r40 : sA, sB,s# stands share#. intuitive meaning rules easily read out. E.g. rule r1says John wants buy shareA dont buy shareB, rules r2 , r3 r4 mean Johnwants buy shareC shareD, them.51fiWANG , Z HANG , Z HOU , & Z HANGone see J ?-stable model due confliction rule r4r10 , r20 , logic program context = (J , ) ?-conflict-free.= {sD}, followingForget HT (J , S) HT {sA sB,Forget HT (M , S) HT {sC ,sC; sC },sB sA, sC,sA, sB}.One check Forget HT (J , S) Forget HT (M , S) unique HT-stable model {sA, sC}.Thus HT-solution . said John Mary may agreementinvestment plan shares shareA, shareB shareC agree give belief(knowledge) shareD. results investment shares shareA shareC,shareB.One check that, FLP-stable model semantics, John Mary givebelief shareD results investment plan shares shareA shareC,share shareB. reason Forget FLP (J , S)Forget FLP (M , S) unique FLP-stablemodel {sA, sC}.5. Related Worksection compare ?-forgetting weak strong forgetting (Zhang & Foo, 2006),semantic forgetting (Eiter & Wang, 2008) forgetting operators FS FW (Wong, 2009).5.1 Weak Strong ForgettingLet normal logic program p propositional atom. reduction respect p,denoted Red(, {p}), normal logic program obtained(1) rule r p Head(r), rule r 0 p Body+ (r 0 ),replacing r 0Head(r 0 ) Body(r), Body(r 0 ) \ {p}.(2) rule r 0 replaced new rule previous step,removing rule r remaining normal logic program.Let X set propositional atoms. reduction respect X inductivelydefined follows:Red(, ) = ,Red(, X {p}) = Red(Red(, {p}), X).strong forgetting p normal logic program normal logic program SForget(, {p})obtained Red(, {p}) removing rule r either r valid 5 p Head(r)Body+ (r) Body (r). weak forgetting p normal logic program WForget(, {p})obtained Red(, {p}) firstly removing rule r either r valid, p Head(r)Body+ (r) removing p remaining rules.5. rule r valid Head(r) Body+ (r) 6= Body+ (r) Body (r) 6= .52fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGLet X set atoms. strong (and weak) forgetting X recursively definedSForget(, ) = ;WForget(, ) = ;SForget(, X {p}) = SForget(SForget(, {p}), X);WForget(, X {p}) = WForget(WForget(, {p}), X).known two forgetting operators independent ordering forgotten atomssense strong HT-equivalence logic programs HT-stable model semantics (cf., seeZhang & Foo, 2006, Prop. 2).Example 10 Consider two normal logic programs:= {p q,q p,r p},= {p q,q p,r q}.One check strongly equivalent.SForget(, {p}) = ,WForget(, {p}) = {r },SForget(, {p}) = WForget(, {p}) = {r q}.example shows neither weak forgetting preserves strong equivalence, strong forgetting. One verify |=? q r 6|=? r ? {HT, FLP }. Thusstrong forgetting satisfy positive persistence, weak forgetting satisfy weakening negative persistence. Actually, HT- FLP-forgetting,followingForget HT (, p) HT Forget HT (, p) HT {q r },Forget FLP (, p) FLP Forget FLP (, p) FLP {q r }.FLP follows fact HT Proposition 2.5.2 Semantic Forgettingaddressed certain issues weak strong forgetting, Eiter Wang (2008) proposedsemantic forgetting consistent disjunctive logic programs. Formally speaking, letconsistent disjunctive logic program p atom. set atoms p-stable model iffstable model stable model \ {p} \ {p}.disjunctive logic program 0 represents result forgetting p ,0 mention atom p,set 0 atoms stable model 0 iff p-stable model 0 p .terms definition, forgetting results unique strong equivalence.means, forgetting preserve strong equivalence. compute result forgetting atom consistent disjunctive logic program, proposed three algorithms forget1 ,forget2 forget3 (Eiter & Wang, 2008). example demonstrates differencesemantic forgetting ?-forgetting.53fiWANG , Z HANG , Z HOU , & Z HANGExample 11 Let = {p q} program signature = {p, q, r}. Although program nothing atom r, forgeti (, r) = (i = 1, 2, 3),seems intuitive loses information irrelevant want forget. HoweverForget? (, r) ? .example also shows semantic forgetting satisfy positive persistencepostulate |=? q p, lost semantic forgetting result forgeti (, r) = 1, 2, 3.5.3 Forgetting Operators FS FWWong (2009) developed forgetting disjunctive logic programs. Differently workZhang Foo (2006), Eiter Wang (2008), Wongs forgetting defined basedHT-logic. sense, approach probably shares common logic ground HT-forgetting.Wong also defined two forgetting operators FS FW , correspond two series programtransformations. See Appendix detailed definitions.interesting feature Wongs forgetting preserves strong equivalence. However,major issue forgetting that: one hand, forgetting FS may cause unnecessaryinformation loss; hand, forgetting FW may also introduce extra informationone want, illustrated following example.Example 12 Let us consider normal logic program consisting of:x,a, z,q p,p q,p, q.have:FS (, {a, p}) HT {y x, z},FW (, {a, p}) HT {y x, z,x,Forget HT (, {a, p}) HT {y x, z,Forget FLP (, {a, p}) FLP {y x, z,q },q q},q q}.Since |=HT {q q}, irrelevant atoms p, seems us forgetting{a, p} affect fact. FS (, {a, p}) 6|=HT {q q}. sense,see FS lost information wish keep. shows operator FSsatisfy positive persistence postulate.hand, fact 6|=HT q FW (, {a, p}) |=HT q, appears FW mayintroduce unnecessary information, indeed conflicts intuition program weakening viaforgetting, i.e., satisfy weakening postulate.mentioned introduction, following example confirms expected resultobtained either one three forgetting approaches.Example 13 [Continued Example 5] normal logic program :(p q) (q p) (p q ),54fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGfollowing:SForget(, {p}) = forget1 (, {p}) = FS (, {p}) = ,WForget(, {p}) = FW (, {p}) = {q}.Here, expected logic program represents information auxiliary atomp ignored q q.6. Concluding Remarkspaper two semantic knowledge forgetting approaches, called HT- FLP-forgetting respectively, proposed logic programs stable model FLP-stable model semantics respectively. knowledge forgetting results captured corresponding logical consequence forgotten logic programs irrelevant forgotten atoms. consequently preservesstrong equivalence logic programs HT- FLP-stable model semantics respectively.major advantage compared existing forgetting approaches logic programming.starting point, investigated model theoretical characterization logic programs HT- FLP-stable model semantics, studied respective strong equivalence problemsusing classical propositional logic equivalence. Many properties forgetting explored,existence forgetting results, representation theorem, complexity decision problems related forgettings. also considered application knowledge forgetting conflict solving.Although presented abstract approaches computing forgetting resultsshowed underlying difficulties computation, valuable study practical algorithmsdifferent subclasses logic programs. Another challenging future work extend knowledge forgetting nonmonotonic systems, particular first-order logic programs (Ferrariset al., 2011). mentioned introduction forgetting effectively usedsolve confliction, e.g. strong weak forgetting (Zhang & Foo, 2006) propositional forgetting (Lang & Marquis, 2010), application knowledge forgetting deservesstudying.concentrate upon paper knowledge forgetting logic programs,based notion strong equivalence, interesting work consider forgettingstable model semantics logic programs along work (Wang et al., 2013). Last least,logic programs supported model semantics enjoys similar properties logicprograms HT- FLP-stable models semantics (Truszczynski, 2010), considerknowledge forgetting logic programs supported model semantics another paper.Acknowledgmentsthank Mirek Truszczynski encouraging us consider knowledge forgetting logic programs FLP-stable model semantics. thank anonymous reviewers insightful comments, Robin Bianchi help formatting paper. Yisong Wang partiallysupported National Natural Science Foundation China grant 61370161 StadholderFoundation Guizhou Province grant (2012)62.55fiWANG , Z HANG , Z HOU , & Z HANGAppendix A. Proofs Section 2Proposition 1 Let A, B, C, set atoms. followingVWVW(i) (A B) (D C) HT (A B C) D.VWVW(ii) (A B) (D C) |=FLP (A B C) D.VWProof:(ii)SupposehX,FLP-model (A B) (D C) FLP-modelVW(A B C) D. follows following conditions hold:VV(a) X |= (A B C), implies X |= (A B).VVV(b) |= (A B C), implies |= (A B) C,WW(c) hX, 6|=FLP D, i.e. X 6|= D.WWWconditions (a) (b) show hX, |=FLP (D C), i.e. X |= |= C.Together conditions (b) (c), contradiction follows.Appendix B. Proofs Section 3Proposition 4 collection ?-interpretations ?-expressible iffhX, implies hY, M.(17)Actually, satisfy condition (17) following logic program? = {? (X, )|hX,/ hY, M} {(Y, )|hY,/ M}captures sense Mod? (? ) = M.Proof: direction left right follows (i) Proposition 3. provedirection. Let ? propositional theory consisting of, every X A,? (X, ) hX,/ hY, M,(Y, ) hY,/ M.Lemma 1, Mod? (? ) = M.LemmaVW2 Let A, B beVtwo setsW atoms, X A. hX, |=?B |= B A.VBWiff X |=Proof: According (iii) Proposition 3 Proposition 2, sufficient show that,case ? = HT,^_^_^_X |= ( BA)Y iff X |=B|=BA.VWVWNote |= B X |= ( B)Y implies XV () WV |= ( A) . Suppose X 6|=B A, i.e. B X X = . follows |= B due B ,56fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGWVVVW|= A,Wi.e. 6= . Thus X |= ( B)Y since ( B)Y = B. X |= ( A)Yi.e. X |= A, X 6= , contradiction.VWVW()VWe need showX |= ( B)Y ( A)Y since |=BA. SupposeWX |=V( B)YW X 6|= ( A)Y . former implies B X , thus X 6=X |= B A. latter implies X (A ) = , means X = since X ,contradiction.Proposition 5 set ?-interpretations positively ?-expressible, i.e., positive logicprogram s.t Mod? () = M, iff satisfies criteria:hX, iff X Y, hX, Xi hY, M.(18)Actually, satisfy condition (18) following logic program^_X|hX, Xi/ M}? = { Xcaptures sense Mod? (? ) = M.Proof: suffices prove case ? = HT Proposition 2.() Let positive logic program whose HT-models exact ones M. everyHT-interpretation hX, i, Lemma 2, hX, |= HT iff X , X |= i.e. hX, Xi |= HT ,hY, |=HT i.e. |= since every rule positive. condition (18) follows.() Let N = {X A|hX, Xi M}. construct propositional theory consisting^_XXevery X N (= 2A \ N ).Firstly showV Mod()W = N . Suppose X |= X 6 N . X N . followsX 6|= X X belongs .V hand,W suppose X N X 6|= .follows exists X 0 N X 6|= X 0 X 0 , i.e., X 0 X X X 0 = ,X = X 0 thus X N , contradiction.Secondly show ModHT () = M. one hand, let hX, |=HT . X |=|= Lemma 2. follows X, N , implies hX, Xi hY, M.Thus hX, (18). hand, let hX, M. terms (18),hX, Xi hY, M. Thus X N N , i.e. X |= |= . ThushX, |=HT Lemma 2.Proposition 6 collection ?-interpretations Horn ?-expressible, i.e., Horn logicprogram Mod? () = M, iff satisfies, addition (10), following criteria:hX, hH, hX H, M.(19)Proof: suffices prove case ? = HT Proposition 2.() Suppose Horn logic program ModHT () = M. Proposition 5,ModHT () satisfies (18). Suppose hX, hH, two HT-models . followsX, Y, H models Lemma 2. Thus X H |= |= ,hX H, |= due X H .57fiWANG , Z HANG , Z HOU , & Z HANG() Let N ones defined proof Proposition 5. X, N XN according (19). follows exists Horn logic program (a set Horn clauses) whose0models exactlyVones inWN . matter fact, Horn program constructedreplacing X^^X p1 , . . . , X pk(20)X = {Y 0 \ X|X 0 0 N } = {p1 , . . . , pk }.firstly show 0 proving^_^^XX|=pi1ikVWpi (1 k) defined (20). direction right left trivial V X Wbelongs V. Let us consider direction. Suppose H |= , H model XH 6|= X pi (1 k). X H H 6= . followsH element {Y 0 \ X|X 0 0 N } {p1 , . . . , pk } H.contradiction.Finally ModHT (0 ) = follows ModHT () = Proposition 5.VWProposition 7 Let = (B C) (A D), A, B, C, subsets A.(A) |= FLP [] HT [].Proof: Note HT [p] = p p0 FLP [p] = p0 .HT [] = 0^^B(c c0 )cC__!(d d0 ) ,dD^_FLP [] = 0(B C B 0 C 0 ) (A 0 ) .Since (A) |= p p0 p0 ,0(A) |= HT []!^__00,(B C )dD0(A) |= FLP []completes proof.^_(B C ) (A 0 ) .0Proposition 8 Let formula LA X A. hX, ?-model iff X 0model (A) {? []}.Proof: prove case ? =FLPinduction structures . Let X A.= p = . trivial = . hand, hX, |=FLP p iff X |= p iffX 0 |= p.58fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMING= 1 2 {, }. follows inductive assumption.= 1 2 . FLP [1 2 ] = (01 02 ) (1 01 FLP [2 ]). RecallhX, |=FLP 1 2 iff|= (1 2 ) and,either (a) X 6|= 1 , (b) 6|= 1 , (c) hX, |=FLP 2 .Note|= (1 2 ) iff 0 |= 01 02 iff X 0 |= 01 02 ,(a) X 6|= 1 iff X 0 6|= 1 , (b) 6|= 1 iff 0 6|= 01 iff X 0 6|= 01 , (c)hX, |=FLP 2 iff X 0 |= FLP [2 ] inductive assumption.follows hX, |=FLP 1 2 iff X 0 |= FLP [1 2 ].completes proof.Theorem 4 Two formulas ?-models (over LA ) iff (A) {? []}(A) {? []} models (over LAA0 ).Proof: prove case ? = FLP .() |= (A) {FLP []}iff MA0 |= (A) {FLP []}0|=iff hMA ,0FLP Proposition 8, MA0 = {p|p MA0 }iff hMA , MA0 |=FLP since FLPiff MA0 |= (A) {FLP []} Proposition 8iff |= (A) {FLP []}.() hX, |=FLPiff X 0 |= (A) {FLP []} Proposition 8, 0 = {p0 |p }iff X 0 |= (A) {FLP []} since (A) {FLP []} (A) {FLP []}iff hX, |=FLP Proposition 8.Proposition 9 (i) problem deciding formula ?-satisfiable NP-complete.(ii) problem deciding two formulas ?-equivalent co-NP-complete.Proof: (i) Membership. formula FLP-satisfiable exists FLP-interpretationhH, hH, |=FLP . feasible guess FLP-interpretation checkcondition hH, |=FLP . Thus problem NP.Hardness. follows fact FLP-satisfiable iff satisfiable, NPhard, (ii) Proposition 3. shows problem NP-hard.(ii) Membership. 6FLP exists hH, that, either(a) hH, |=FLP hH, 6|=FLP ,(b) hH, 6|=FLP hH, |=FLP .59fiWANG , Z HANG , Z HOU , & Z HANGguess FLP-interpretation hH, check conditions (a) (b) feasiblepolynomial time size . Thus problem co-NP.Hardness. FLPiff FLP-modeliff model (ii) Proposition 3iff valid, co-NP-hard. Thus problem co-NP-hard.Appendix C. Proofs Section 4Lemma 3 Let formula V A. formula result ?-forgetting V , ifffollowing condition holds:Mod? () = Mod? ()V .Proof: result ?-knowledge forgetting Viff, every ?-interpretation , |=? iff exists 0 |=? s.t. V 0iff Mod? () = {M ?-interpretation | 0 |=? V 0 }iff Mod? () = Mod()V .Lemma 4 Let X, Y, H, V subsets A.(i) X V H V X V H X V H .(ii) X V H 0 V 0 0 H 0 V V 0 X 0 .Proof: (i) Note (X ) \ V=(X \ V ) (Y \ V )=(H \ V ) (T \ V ) due X V H V=(H ) \ V .Thus X V . similarly prove X V H .(ii) Please note 0 = {p0 |p }, V 0 = {p0 |p V } 0 = {p0 |p V }.(H 0 ) \ (V V 0 ).= (H \ (V V 0 )) (T 0 \ (V V 0 ))= (H \ V ) (T 0 \ V 0 ) since H V 0 = 0 V == (X \ V ) (Y 0 \ V 0 ) since H V H 0 V 0 0= (X \ (V V 0 )) (Y 0 \ (V V 0 )) since X V 0 = 0 V == (X 0 ) \ (V V 0 ).follows H 0 V V 0 X 0 .Theorem 6 (Expressibility theorem) Let formula V set atoms. existsformula Mod? () = Mod? ()V .Proof: every hX, Mod? ()V , exists hH, |=? hH, V hX, i,i.e. X V H V . (i) Proposition 3, hT, |=? . Thus hY, Mod? ()Vdue hY, V hT, i. follows collection Mod? ()V satisfies condition (8),formula Mod? () = Mod? ()V Proposition 4.Lemma 5 formula ?-irrelevant set V atoms iff hH, |=? implies hX, |=?every two ?-interpretations hX, hH, hX, V hH,60fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGProof: ?-irrelevant Viff exists formula mentioning atoms V ?iff exists formula mentioning atoms V s.t Mod? () = Mod? ()iff Mod? () = {hX, i|X hH, V hX, s.t hH, |=? }iff hH, |=? implies hX, |=? every two ?-interpretations hX, hH,hX, V hH, i.Proposition 10 Let two formulas V set atoms.(i) IR? (Forget ? (, V ), V ).(ii) ?-model iff Forget? (, V ) has.(iii) |=? Forget? (, V ).(iv) |=? Forget? (, V ) |=? Forget? (, V ).(v) Forget? ( , V ) ? Forget? (, V ) Forget? (, V ).(vi) Forget? ( , V ) |=? Forget? (, V ) Forget? (, V ).(vii) Forget? ( , V ) ? Forget? (, V ) IR? (, V ).Proof: (i) immediately follows Lemma 5.(ii) evident Mod? () 6= iff Mod? ()V 6= Definition 8.(iii) easy see Mod? () Mod? ()V Definition 8.(iv) Let |=? , hH, |=? Forget? (, V ), i.e. hH, Mod? ()V . termsDefinition 8, exists hH 0 , 0 |=? hH, V hH 0 , 0 i. implies hH 0 , 0 |=?since |=? . Thus hH, Mod? ()V , i.e. hH, |=? Forget? (, V ).(v) hH, |=? Forget? ( , V )iff hH, Mod? ( )Viff hH 0 , 0 |=? hH, V hH 0 , 0iff hH 0 , 0 hH, V hH 0 , 0 and, either hH 0 , 0 |=? hH 0 , 0 |=?iff hH, Mod? ()V hH, Mod? ()Viff hH, |=? Forget? (, V ) hH, |=? Forget? (, V )iff hH, |=? Forget? (, V ) Forget? (, V ).(vi) hH, |=? Forget? ( , V )hH, Mod? ( )VhH 0 , 0 |=? hH, V hH 0 , 0hH 0 , 0 that. hH, V hH 0 , 0 i, hH 0 , 0 |=? hH 0 , 0 |=?hH, Mod? ()V hH, Mod? ()VhH, |=? Forget? (, V ) hH, |=? Forget? (, V )hH, |=? Forget? (, V ) Forget? (, V ).(vii) direction left right follows (vi) fact IR(, V ), i.e. Forget? (, V ) ?. Let us consider direction.hH, |=? Forget? (, V )hH, |=? Forget? (, V ) hH, |=?hH 0 , 0 |=? hH, V hH 0 , 0 i, hH, |=?61fiWANG , Z HANG , Z HOU , & Z HANGhH, V hH 0 , 0 hH 0 , 0 |=? IR(, V ) Lemma 5hH, Mod? ( )VhH, |=? Forget? ( , V ).Theorem 8 (Horn expressibility) Let Horn logic program V A. Hornlogic program 0 Forget? (, V ) ? 0 .Proof: terms Proposition 2, suffices prove ? = HT. Let = ModHT ()V .Proposition 6, sufficient show satisfies conditions (5) (12).first prove satisfies (5). HT-interpretation hX, M,X , exists hH, ModHT () hX, V hH, i. Note positive,shows hH, Hi hT, HT-models Lemma 2. Thus hX, XihY, due X V H V . hand, suppose hX, Xi M, hY,X . exist two HT-models hH 0 , 0 hH 00 , 00 hH 0 , 0 V hX, XihH 00 , 00 V hY, i. Lemma 2, H 0 |= , 0 |= , H 00 |= 00 |= . Sincemodels Horn theories closed set intersection (Alfred, 1951), H 0 H 00 |= .Lemma 2 again, hH 0 H 00 , 00 |=HT . Lemma 4, H 0 H 00 V X (= X). ThushH 0 H 00 , 00 V hX, i. follows hX, M.show satisfies (12). Suppose hX, hH, two HT-interpretationsM. follows two HT-models hX 0 , 0 hH 0 , 0 hX 0 , 0 VhX, hH 0 , 0 V hH, i. Since Horn, hH 0 X 0 , 0 0 |=HTProposition 6. Lemma 4, H 0 X 0 V H X 0 0 V . implieshH 0 X 0 , 0 0 V hX H, i, thus hX H, M.Proposition 11 Let disjunctive logic program, V A. Forget? (, V )expressible disjunctive logic programs if,hH1 , T1 |=? , hT2 , T2 |=? T1 T2 hH3 , T3 |=? hH3 , T3 V hH1 , T2 i.Proof: Proposition 2, suffices prove ? = HT. Let 0 HT Forget HT (, V ). directionleft right obvious. show direction.Suppose 0 expressible disjunctive logic programs. exists hX, |=HT 0 ,0 hY 0 , 0 |=HT 0 hX, 0 6|=HT 0 . follows that, hH1 , T1 |=HThT2 , T2 |=HT hH1 , T1 V hX, i, T2 V 0 T1 T2 , existshH3 , T3 |=HT hH3 , T3 V hH1 , T2 i, viz. hH3 , T3 V hX, 0 hX, 0 VhH1 , T2 i, contradiction.Proposition 12 Let normal logic program, V A. Forget? (, V ) expressiblenormal logic programs if, addition condition (21), following condition holds,hH1 , T1 |=? , hH2 , T2 |=? T1 V T2hH3 , T3 |=? H3 V H1 H2 (T3 V T1 T3 V T2 ).(21)Proof: Proposition 2, suffices prove ? = HT. Let 0 HT Forget HT (, V ). directionleft right easy. consider direction follows.terms Proposition 11 Corollary 3, sufficient show that, hX, |=HT 0hX 0 , |=HT 0 , hX X 0 , |=HT 0 according Corollary 3. Suppose hX,62fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGhX 0 , two HT-models 0 . two HT-models hH1 , T1 hH2 , T2hX, V hH1 , T1 hX 0 , V hH2 , T2 i. follows T1 V T2 and, condition (21), exists HT-model hH3 , T3 satisfying either hH3 , T3 V hH1 H2 , T1hH3 , T3 V hH1 H2 , T2 i, shows hH3 , T3 V hX X 0 , i, hence hX X 0 , |=HT0 .Theorem 10 (Representation theorem) Let two formulas V set atoms.following statements equivalent:(i) ? Forget? (, V ).(ii) ? {0 | |=? 0 IR? (0 , V )}.(iii) Postulates (W), (PP), (NP) (IR) hold.Proof: Let ? = { | |=? IR? (, V )}. evident IR? (? , V ).equivalence (i) (ii) follows Corollary 9. (ii) obviously implies (iii).suffices show (iii) (ii).Positive Persistence, |=? ? , follows Mod? ()Mod? (? ). hand, ( W) |=? (IR) IR? (, V ), follows ? . ThusMod? (? ) Mod? (). Thus ? ? .Proposition 13 Let , 0 , formulas V ? Forget? (, V ) 0Forget(, V ).(i) 0 .(ii) 0 |=? .Proof: (i) |=iff hT, |=? (i) Proposition 3iff hT, |=? Forget? (, V ) since ? Forget? (, V )iff hY, |=? hT, V hY, Definition 8iff |= V (i) Proposition 3iff |= Forget(, V ) Corollary 5iff |= 0 since 0 Forget(, V ).(ii) hH, |=? 0|= 0 (i) Proposition 3|= Forget(, V ) since 0 Forget(, V )|= V Corollary 5hH \ V, |=? V (ii) Proposition 3hH, |=? Forget? (, V ) due hH \ V, V hH, Definition 8hH, |=? due Forget? (, V ) ? .Proposition 14 Let 0 two Horn logic programs, V set atoms 0Forget(, V ). 0 ? Forget? (, V ).63fiWANG , Z HANG , Z HOU , & Z HANGProof: Proposition 2, suffices show ? = HT.() hH 0 , 0 |=HT 0H 0 |= 0 0 |= 0 Lemma 2H, H |= , |= , H V H 0 V 0 0 Forget(, V )H, H |= , |= , H V H 0 V 0H, hH T, |=HT hH T, V hH 0 , 0hH 0 , 0 |=HT Forget HT (, V ).() hH 0 , 0 |=HT Forget HT (, V )hH, |=HT hH 0 , 0 V hH,H H |= , |= hH 0 , 0 V hH, Lemma 2H 0 |= Forget(, V ) 0 |= Forget(, V )H 0 |= 0 0 |= 0 due 0 Forget(, V )hH 0 , 0 |=HT 0 .Proposition 15 Let two formulas V set atoms.(i) Forget(, V ) iff ? Forget? (, V ).(ii) Forget(, V ) Forget(, V ) iff Forget? (, V ) ? Forget? (, V ).Proof: (i) () hH, |=?iff |= , i.e. |= (ii) Proposition 3iff |= Forget(, V ) since Forget(, V )iff |= i.e. |= V Corollary 5iff hH \ V, |=? (H \ V \ V = \ V ) (ii) Proposition 3iff hH, |=? Forget? (, V ) Definition 8.() |= i.e. |=iff hH, |=? (ii) Proposition 3iff hH, |=? Forget? (, V ) H since ? Forget? (, V )iff hX, |=? hH, V hX, Definition 8iff |= V (ii) Proposition 3iff |= Forget(, V ) Corollary 5.(ii) () hH, |=? Forget? (, V )iff hX, |=? hX, V hH, Definition 8iff |= i.e. |= V (ii) Proposition 3iff |= Forget(, V ) Corollary 5iff |= Forget(, V ) since Forget(, V ) Forget(, V )iff 0 |= i.e. 0 |= 0 V Definition 8iff hX \ V, 0 |=? (ii) Proposition 3 (X \ V \ V = 0 \ V )iff hH, |=? Forget? (, V ) hH, V hX \ V, 0 Definition 8.() |= Forget(, V )iff |= i.e. |= V Corollary 5iff hX, |=? V (ii) Proposition 3iff hX \ V, |=? Forget? (, V ) hX \ V, V hX, Definition 8iff hX \ V, |=? Forget? (, V ) since Forget? (, V ) ? Forget? (, V )iff hX 0 , 0 |=? hX \ V, V hX 0 , 0 Definition 864fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGiff 0 |= i.e. 0 |= V 0 (ii) Proposition 3iff |= Forget(, V ) Corollary 5.Theorem 12 (?-forgetting vs propositional forgetting) Let two formulas LAV A.? Forget? (, V ) iff (A) |= ? [] Forget((A) {? []}, V V 0 ).model (A).Proof: () Let =0|= (A) {? []}|= Proposition 8iff hMA ,0?|= Forget (, V ) since Forget (, V )iff hMA ,0????Definition 8iff hH, |=? hH, V hMA ,0iff hH, |=? H V V00iff H |= (A) {? []} H V 0 V 0 MA0 Proposition 8iff H 0 |= (A) {? []} H 0 V V 0 MA0 Lemma 4iff MA0 |= Forget((A) {? []}, V V 0 ) Definition 8iff |= Forget((A) {? []}, V V 0 ).() hX, |=?iff X 0 |= (A) {? []} Proposition 8iff X 0 |= (A) Forget((A) {? []}, V V 0 )iff |= (A) {? []} V V 0 X 0|= X Proposition 8iff hMA ,0V?A0Definition 8.iff hX, |=? Forget? (, V ) due hX, V hMA ,0Proposition 16 Let two formulas LA V set atoms. Forget? (, V ) ?Forget? (, V ) iff following condition holds:Forget({? []} (A), V V 0 ) Forget({? []} (A), V V 0 ).Proof: () show Forget({? [] (A), V V 0 ) |= Forget({? [] (A), V V 0 ).side similarly proved.|= Forget({? []} (A), V V 0 )N A0 N V V 0 N |= {? []} (A)hX, |=? N = X 0 Proposition 8hX, |=? Forget? (, V ) (iii) Proposition 10hX, |=? Forget? (, V ) Forget? (, V ) ? Forget? (, V )hH, |=? hH, V hX, Definition 8H 0 |= ? [] (A) Proposition 8X 0 |= Forget({? []} (A), V V 0 ) H 0 V V 0 X 0|= Forget({? []} (A), V V 0 ) V V 0 X 0 (= N ).() show Forget? (, V ) |=? Forget? (, V ). side similar.hH, |=? Forget? (, V )hX, |=? hH, V hX, i) Definition 8X 0 |= {? []} (A) Proposition 8X 0 |= Forget({? []} (A), V V 0 )65fiWANG , Z HANG , Z HOU , & Z HANGX 0 |= Forget({? []} (A), V V 0 )H1 T10 |= {? []} (A) H1 T10 V V 0 X 0hH1 , T1 |=? Proposition 8hX, |=? Forget? (, V ) hX, V hH1 , T1 Definition 8hH, |=? Forget? (, V ) hX, V hH, i.Theorem 14 Let two formulas V set atoms.(i) problem deciding ? Forget? (, V ) co-NP-complete.(ii) problem deciding Forget? (, V ) ? Forget? (, V ) P2 -complete.(iii) problem deciding ? Forget? (, V ) P2 -complete.Proof: (i) Membership. Recall |=? Forget? (, V ) (iii) Proposition 10.6? Forget? (, V )iff Forget? (, V ) 6|=?iff hX, |=? Forget? (, V ) hX, 6|=?iff hH, |=? hH, V hX, hX, 6|=? .Since guessing hH, i, hX, checking ?-satisfiability done polynomialtime size V . Thus complement 6? Forget? (, V ), i.e. ? Forget? (, V ),co-NP.hardness follows fact that, (i) Proposition 15, ? Forget? (, V ) iffForget(, V ), co-NP-complete (cf., see Lang et al., 2003, Prop. 10).(ii) Membership. Forget? (, V ) 6? Forget? (, V ) exists ?-interpretation hH,either(a) hH, |=? Forget? (, V ) hH, 6|=? Forget? (, V ),(b) hH, 6|=? Forget? (, V ) hH, |=? Forget? (, V ).one hand, guess ?-interpretation hH, feasible nondeterministic Turing machine. hand, checking hH, |=? feasible deterministic Turing machine;hH, |=? Forget? (, V ) iff exists hX, |=? hX, V hH, i. Thuschecking conditions (a) (b) done polynomial time size callingnondeterministic Turing machine. Thus problem P2 .Note that, (ii) Proposition 15, Forget? (, V ) ? Forget? (, V ) iff Forget(, V )Forget(, V ), P2 -complete (cf., see Lang et al., 2003, Prop. 24). Thus hardnessfollows.(iii) Membership. Note 6? Forget? (, V ) iff ?-interpretation hH,hH, |=? hH, 6|=? Forget? (, V ),hH, 6|=? hH, |=? Forget? (, V ).Similar case (ii), guessing checking polynomial time size ,V calling nondeterministic Turing machine. Thus problem P2 .Note ? Forget? (, V ) iff ? Forget? (, V ) Forget? (, V ) ? Forget? (, V ),latter P2 -hard (ii). hardness follows.66fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGProposition 17 Let two formulas V set atoms.(i) problem deciding whether |=? Forget? (, V ) P2 -complete.(ii) problem deciding whether Forget? (, V ) |=? co-NP-complete.Proof: (i) Membership. Recall 6|=? Forget? (, V ) iff exists ?-model hH,hH, 6|= Forget? (, V ). hH, 6|= Forget? (, V ) iff hX, 6|= every ?interpretation hX, hX, V hH, i. hH, guessed polynomialtime size , V . Checking hH, 6|= Forget? (, V ) possible polynomial timesize , V calling nondeterministic Turing machine. Thus original problemp2 .Hardness. follows following fact:> |=? Forget? (, V )iff > ? Forget? (, V )iff > Forget(, V ) (i) Proposition 15 (> ? >)iff QBF V V valid, P2 -complete (Papadimitriou, 1994).(ii) Membership. NoteForget? (, V ) 6|=?iff hH, |=? Forget? (, V ) hH, 6|=iff hX, |=? hX, V hH, hH, 6|= .Since guessing checking polynomial size , V , original problemco-NP.Hardness follows factForget? (, V ) |=?iff |=? (ii) Proposition 10iff ?-model, co-NP-complete Proposition 9.Appendix D. Forgetting Operators FW FSWong proposed six postulates argued postulates respected forgettingoperators disjunctive logic programs strong equivalence:(F-1) |=HT F (, a) |=HT F (, a);(F-2) appear , F ({r} , a) HT F ({r}, a) ;(F-3) F (, a) contain atoms ;(F-4) F (, a) |=HT r F ({s}, a) |=HT r Cn();(F-5) F (, a) |=HT (A B, C), |=HT (A B, C, a);(F-6) F (F (, a), b) HT F (F (, b), a)F forgetting operator, , disjunctive logic programs, b atoms, rdisjunctive rule,Cn() ={r| r disjunctive rule |=HT r var(r) var()}.67fiWANG , Z HANG , Z HOU , & Z HANGvar() set atoms occurring .Accordingly, proposed two forgetting operators FS FW : result forgetting atomdisjunctive logic program defined procedure:(1) Let 1 = Cn().(2) Form 1 , remove rules form (A B, a, C), replace rule form (A{a} B, C, a) (A B, C, a). Let resulting logic program 2 .(3) Replace remove rule 2 , form (A B, C, a) (A {a}B, C) according following table:WB, C,(remove)B, C{a} B, C(remove)B, CLet 3 resulting logic program.logic program 3 result forgetting p .ReferencesAlfred, H. (1951). sentences true direct unions algebras. Journal SymbolicLogic, 16(1), 1421.Bobrow, D. G., Subramanian, D., Greiner, R., & Pearl, J. (Eds.). (1997). Special issue relevance97 (1-2). Artificial Intelligence Journal.Cabalar, P., & Ferraris, P. (2007). Propositional theories strongly equivalent logic programs.Theory Practice Logic Programming, 7(6), 745759.Delgrande, J. P., Schaub, T., Tompits, H., & Woltran, S. (2013). model-theoretic approachbelief change answer set programming. ACM Transactions Computational Logic, 14(2),A:1A:42.Eiter, T., Fink, M., Tompits, H., & Woltran, S. (2004). eliminating disjunctions stable logicprogramming. Principles Knowledge Representation Reasoning: ProceedingsNinth International Conference (KR2004), pp. 447458, Whistler, Canada. AAAI Press.Eiter, T., & Wang, K. (2008). Semantic forgetting answer set programming. Artificial Intelligence,172(14), 16441672.Faber, W., Pfeifer, G., & Leone, N. (2011). Semantics complexity recursive aggregatesanswer set programming. Artificial Intelligence, 175(1), 278298.Ferraris, P. (2005). Answer sets propositional theories. Logic Programming Nonmonotonic Reasoning, 8th International Conference, Vol. 3662 Lecture Notes Computer Science, pp. 119131, Diamante, Italy. Springer.Ferraris, P., Lee, J., & Lifschitz, V. (2011). Stable models circumscription. Artificial Intelligence, 175(1), 236263.Ferraris, P., & Lifschitz, V. (2005). Mathematical foundations answer set programming.Artemov, S. N., Barringer, H., dAvila Garcez, A. S., Lamb, L. C., & Woods, J. (Eds.),Show Them! Essays Honour Dov Gabbay, Vol. 1, pp. 615664. College Publications.68fiK NOWLEDGE F ORGETTINGNSWER ET P ROGRAMMINGGabbay, D. M., Pearce, D., & Valverde, A. (2011). Interpolable formulas equilibrium logicanswer set programming. Journal Artificial Intelligence Research, 42, 917943.Gelfond, M., & Lifschitz, V. (1988). stable model semantics logic programming. Proceedings Fifth International Conference Symposium Logic Programming, pp.10701080, Seattle, Washington. MIT Press.Goranko, V., & Otto, M. (2007). Handbook Modal Logic, Vol. 3, chap. 5 Model Theory ModalLogic, pp. 249329. Elsevier.Jongh, D. D., & Hendriks, L. (2003). Characterization strongly equivalent logic programsintermediate logics. Theory Practice Logic Programming, 3(3), 259270.Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2008). tell difference dl-liteontologies?. Principles Knowledge Representation Reasoning: ProceedingsEleventh International Conference, KR 2008, pp. 285295, Sydney, Australia. AAAI Press.Lang, J., Liberatore, P., & Marquis, P. (2003). Propositional independence: Formula-variable independence forgetting. Journal Artificial Intelligence Research, 18, 391443.Lang, J., & Marquis, P. (2010). Reasoning inconsistency: forgetting-based approach. Artificial Intelligence, 174(12-13), 799823.Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM Transactions Computational Logic, 2(4), 526541.Lifschitz, V., Tang, L. R., & Turner, H. (1999). Nested expressions logic programs. AnnalsMathematics Artificial Intelligence, 25(3-4), 369389.Lin, F. (2001). strongest necessary weakest sufficient conditions. Artificial Intelligence,128(1-2), 143159.Lin, F. (2002). Reducing strong equivalence logic programs entailment classical propositional logic. Proceedings Eights International Conference Principles Knowledge Representation Reasoning (KR-02), pp. 170176, Toulouse, France. Morgan Kaufmann.Lin, F., & Chen, Y. (2007). Discovering classes strongly equivalent logic programs. JournalArtificial Intelligence Research, 28, 431451.Lin, F., & Reiter, R. (1994). Forget it!. Proceedings AAAI Fall Symposium Relevance,pp. 154159.Lin, F., & Zhou, Y. (2011). answer set logic programming circumscription via logic GK.Artificial Intelligence, 175(1), 264277.Liu, Y., & Wen, X. (2011). progression knowledge situation calculus. IJCAI2011, Proceedings 22nd International Joint Conference Artificial Intelligence, pp.976982, Barcelona, Catalonia, Spain. IJCAI/AAAI.Lutz, C., & Wolter, F. (2011). Foundations uniform interpolation forgetting expressivedescription logics. IJCAI 2011, Proceedings 22nd International Joint ConferenceArtificial Intelligence, pp. 989995, Barcelona, Catalonia, Spain. IJCAI/AAAI.Osorio, M., & Cuevas, V. (2007). Updates answer set programming: approach based basicstructural properties. TPLP, 7(4), 451479.69fiWANG , Z HANG , Z HOU , & Z HANGOsorio, M., & Zacarias, F. (2004). updates logic programs: properties-based approach.Seipel, D., & Torres, J. M. T. (Eds.), FoIKS, Vol. 2942 Lecture Notes Computer Science,pp. 231241. Springer.Packer, H. S., Gibbins, N., & Jennings, N. R. (2011). on-line algorithm semantic forgetting. IJCAI 2011, Proceedings 22nd International Joint Conference ArtificialIntelligence, pp. 27042709, Barcelona, Catalonia, Spain. IJCAI/AAAI.Papadimitriou, C. H. (1994). Computational complexity. Addison Wesley.Pearce, D., Tompits, H., & Woltran, S. (2001). Encodings equilibrium logic logic programsnested expressions. Proceedings the10th Portuguese Conference Artificial Intelligence Progress Artificial Intelligence, Knowledge Extraction, Multi-agent Systems,Logic Programming Constraint Solving, pp. 306320, London, UK. Springer-Verlag.Pearce, D., Tompits, H., & Woltran, S. (2009). Characterising equilibrium logic nested logicprograms: Reductions complexity. Theory Practice Logic Programming, 9(5),565616.Su, K., Sattar, A., Lv, G., & Zhang, Y. (2009). Variable forgetting reasoning knowledge.Journal Artificial Intelligence Research, 35, 677716.Truszczynski, M. (2010). Reducts propositional theories, satisfiability relations, generalizations semantics logic programs. Artificial Intelligence, 174(16-17), 12851306.van Ditmarsch, H. P., Herzig, A., Lang, J., & Marquis, P. (2009). Introspective forgetting. Synthese,169(2), 405423.Visser, A. (1996). Uniform interpolation layered bisimulation. Godel96, pp. 139164.Wang, Y., Wang, K., & Zhang, M. (2013). Forgetting answer set programs revisited. IJCAI2013, Proceedings 23rd International Joint Conference Artificial Intelligence, pp.11621168, Beijing, China. IJCAI/AAAI.Wang, Y., Zhang, Y., Zhou, Y., & Zhang, M. (2012). Forgetting logic programs strongequivalence. Principles Knowledge Representation Reasoning: ProceedingsThirteenth International Conference, pp. 643647, Rome, Italy. AAAI Press.Wang, Z., Wang, K., Topor, R. W., & Pan, J. Z. (2010). Forgetting knowledge bases dl-lite.Annuals Mathematics Artificial Intelligence, 58(1-2), 117151.Wong, K.-S. (2009). Forgetting Logic Programs. Ph.D. thesis, University New SouthWales.Zhang, Y., & Foo, N. Y. (2006). Solving logic program conflict strong weak forgettings.Artificial Intelligence, 170(8-9), 739778.Zhang, Y., & Zhou, Y. (2009). Knowledge forgetting: Properties applications. Artificial Intelligence, 173(16-17), 15251537.Zhou, Y., & Zhang, Y. (2011). Bounded forgetting. Proceedings Twenty-Fifth AAAIConference Artificial Intelligence, AAAI 2011, pp. 280285, San Francisco, California,USA. AAAI Press.70fi