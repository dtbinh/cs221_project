Journal Artificial Intelligence Research 53 (2015) 659-697

Submitted 4/15; published 8/15

Evolutionary Dynamics Multi-Agent Learning:
Survey
Daan Bloembergen
Karl Tuyls

d.bloembergen@liverpool.ac.uk
k.tuyls@liverpool.ac.uk

Department Computer Science, University Liverpool
Ashton Building, Ashton Street, Liverpool L69 3BX, UK

Daniel Hennes

daniel.hennes@esa.int

Advanced Concepts Team, European Space Agency
Keplerlaan 1, 2201 AZ Noordwijk, NL

Michael Kaisers

m.kaisers@cwi.nl

Centrum Wiskunde & Informatica
Science Park 123, 1098 XG Amsterdam, NL

Abstract
interaction multiple autonomous agents gives rise highly dynamic nondeterministic environments, contributing complexity applications automated
financial markets, smart grids, robotics. Due sheer number situations may
arise, possible foresee program optimal behaviour agents beforehand. Consequently, becomes essential success system agents
learn optimal behaviour adapt new situations circumstances. past
two decades seen emergence reinforcement learning, single multiagent settings, strong, robust adaptive learning paradigm. Progress
substantial, wide range algorithms available. important challenge
domain multi-agent learning gain qualitative insights resulting system
dynamics. past decade, tools methods evolutionary game theory
successfully employed study multi-agent learning dynamics formally strategic
interactions. article surveys dynamical models derived various
multi-agent reinforcement learning algorithms, making possible study compare
qualitatively. Furthermore, new learning algorithms introduced using evolutionary game theoretic tools reviewed. evolutionary models
used study complex strategic interactions. Examples analysis given
domains automated trading stock markets collision avoidance multi-robot systems. paper provides roadmap progress achieved analysing
evolutionary dynamics multi-agent learning highlighting main results
accomplishments.

1. Introduction
multi-agent system, several autonomous agents interact environment.
Therefore, multi-agent systems used model many complex problems todays
society, urban air traffic control (Agogino & Tumer, 2012), multi-robot coordination (Ahmadi & Stone, 2006; Claes, Hennes, Tuyls, & Meeussen, 2012), distributed
sensing (Mihaylov, Tuyls, & Nowe, 2014), energy distribution (Pipattanasomporn, Feroze,
& Rahman, 2009), load balancing (Schaerf, Shoham, & Tennenholtz, 1995; Verbeeck,
c
2015
AI Access Foundation. rights reserved.

fiBloembergen, Tuyls, Hennes, & Kaisers

Nowe, & Tuyls, 2005). fact multiple agents interact leads highly dynamic,
non-deterministic environment. environment, defining proper behaviour
agent advance non-trivial therefore learning crucial. Recent publications
agents machine learning conferences, well papers published related mainstream
journals, make clear number newly proposed multi-agent learning algorithms
constantly growing. overview well-established multi-agent learning algorithms
various purposes attained previous multi-agent learning survey papers
(Panait & Luke, 2005; Hoen, Tuyls, Panait, Luke, & Poutre, 2005; Busoniu, Babuska, &
De Schutter, 2008; Tuyls & Weiss, 2012), demonstrates need comprehensive
understanding qualitative similarities differences. Although single-agent learning particular reinforcement learning extensively studied acquired
strong theoretical foundation (Kaelbling, Littman, & Moore, 1996; Sutton & Barto, 1998),
thorough understanding learning multi-agent settings long remained open
problem (Tuyls, Hoen, & Vanschoenwinkel, 2006).
Learning multi-agent systems relevant within field artificial intelligence extensively studied game theory economics well (Shoham,
Powers, & Grenager, 2007). surprising then, fields share lot common ground. Indeed, game theory often provides context multi-agent systems
modelled evaluated. Recently, multi-agent learning research shifted
focus traditional game theory evolutionary game theory (Tuyls et al., 2006; Tuyls
& Parsons, 2007). concepts employed evolutionary game theory prove well suited
describe learning multi-agent systems. fields concerned dynamic environments high level uncertainty, characterised fact agents lack complete
information (Tuyls et al., 2006). Moreover, exists formal relation behaviour one basic reinforcement learning algorithms, Cross learning (Cross,
1973), population dynamics evolutionary game theory, described replicator dynamics (Borgers & Sarin, 1997). Although link originally established
context stateless normal-form games only, since extended complex
scenarios well (e.g., Hennes, Tuyls, & Rauterberg, 2009; Tuyls & Westra, 2009; Galstyan,
2013; Panozzo, Gatti, & Restelli, 2014).
Understanding relation sheds light black box reinforcement learning
making possible analyse learning dynamics multi-agent systems detail
compare behaviour different algorithms principled manner. turn
facilitates important tasks parameter tuning, helps selecting specific learner
given problem. Tuyls Nowe (2005) Tuyls et al. (2006) first present
overview evolutionary game theoretic approach multi-agent learning.
build connection Cross learning replicator dynamics extend
link learning automata Q-learning well. However, much progress
made past decade, warranting up-to-date overview roadmap research
area. precisely aim work.
believe evolutionary game theory lot offer understanding
application multi-agent learning. Shoham et al. (2007) call grounded
approach research multi-agent learning, suggesting five agendas research
could contribute. also caution rely strongly requirements
convergence Nash equilibrium evaluating learning algorithms multi-agent
660

fiEvolutionary Dynamics Multi-Agent Learning

setting. response, Tuyls Parsons (2007) argue favour evolutionary game theory,
rather classical game theory, preferable framework within study multiagent learning formally. show research evolutionary framework contributes
five agendas research identified Shoham et al. (2007). Moreover, allows
us move away static Nash equilibrium, focus instead transient
dynamics learning process.
article describe formal relation evolutionary game theory
multi-agent learning detail survey recent advances extensions
made area.1 end present categorisation related work based
nature environment (stateless multi-state games) actions (discrete
continuous) available learning agents. Moreover, provide examples
successful application approach relation parameter tuning, design new
learning algorithms, analysis complex strategic interactions automated
trading multi-robot collision avoidance. evolutionary game theoretic approach
offers promising new paradigm within study multi-agent learning, provides
new insights towards understanding, analysis, design multi-agent reinforcement
learning algorithms.
paper proceeds follows. Section 2 provides necessary background (multiagent) reinforcement learning evolutionary game theory. Section 3 introduces link
replicator dynamics Cross learning outlines methodology
survey. overview recent advances extensions given Section 4, supported
empirical validation Section 5. Section 6 presents examples application
evolutionary game theoretic approach. Section 7 concludes article.

2. Preliminaries
section, outline fundamentals multi-agent learning. Firstly, concisely
present Markov decision processes (MDPs) standard formal framework singleagent decision making, together well-known reinforcement learning algorithm, Qlearning. proceed present stochastic games, also called Markov games, multiagent extension MDPs, well three approaches learning extended setting:
independent learning, joint action learning, gradient based methods. Finally, discuss
evolutionary game theory used reason multi-agent interactions, paving
way formally relate two fields Section 3.
2.1 Reinforcement Learning
Reinforcement learning based concept trial-and-error learning, underlies
many theories (human) learning intelligence (Sutton & Barto, 1998). reinforcement learning agent continuously interacts environment, perceiving state,
taking actions, observing effect actions (see Figure 1). Actions yield
positive effect higher chance executed future,
1. attempt present broad survey multi-agent learning general focus solely
works explicitly model multi-agent learning using methods evolutionary game theory.
excellent survey taxonomy multi-agent learning algorithms general found
work Busoniu et al. (2008).

661

fiBloembergen, Tuyls, Hennes, & Kaisers

Agent
st

rt


rt+1
st+1

Environment

Figure 1: reinforcement learning agent perceives state st environment time
t, decides take action , upon environment transitions state st+1
agent receives reward rt+1 .
say reinforced within agents behaviour. effect, agent receives
reward signal indicates quality actions taken; however, reward may
stochastic, delayed, accumulated sequences actions. Therefore, agent needs
balance exploration exploitation, avoid getting stuck local optima. objective
learning agent discover policy, represented mapping states actions,
maximises long-term expected reward.
single-agent reinforcement learning setting formalised Markov decision
process (MDP) (Puterman, 1994). MDP defined finite state action sets,
A, one-step state transition dynamics

0
Pss
0 = P (st+1 = |st = s, = a)

(1)

describing probability transitioning state s0 taking action state
s, expected value next reward
Rass0 = E(rt+1 |st = s, = a, st+1 = s0 )

(2)

given previously executed action resulting state transition. state transitions
rewards stochastic, fact learning stochastic models key task
many reinforcement learning problems. learning goal MDP find policy
maps states action selection probabilities, maximising expected reward.
following fixed policy define value state policy total
amount reward R agent expects accumulate starting state following
thereafter:

X
V (s) = E (Rt |st = s) = E (
k rt+k+1 |st = s).
k=0

rewards discounted factor [0, 1) ensure bounded sum infinite horizon
MDPs. value function policy calculated iteratively using Bellman
equation (Bellman, 1957). Starting arbitrarily chosen value function V ,
iteration state value function updated based immediate
reward current estimate V :
X
X

0

(s, a)
Pss
V (s)
0 [Rss0 + V (s )].
aA(s)

s0

662

fiEvolutionary Dynamics Multi-Agent Learning

Bellman equation expresses recursive relation value state
successor states, averages possibilities, weighing probability
occurring. setting, finding optimal policy equivalent finding policy
maximises value function, i.e.,


V (s) = max V (s) S.


model environment available, particular P R known,
Bellman equation applied compute optimal policy directly, using dynamic
programming technique value iteration policy iteration (Sutton & Barto, 1998).
general, however, model may available. case, reinforcement learning used find optimal mapping states actions. Arguably
famous example reinforcement learning algorithm model-free temporal difference
algorithm Q-learning (Watkins & Dayan, 1992). Q-learning maintains value function
state-action pairs, Q(s, a), updates based immediate reward
discounted expected future reward according Q:
h

Q(st , ) Q(st , ) + rt+1 + max Q(st+1 , a) Q(st , ) .
(3)


Here, discount factor future rewards before, [0, 1] learning rate
determines quickly Q updated based new reward information. Q-learning
proven converge optimal policy, given sufficient updates state-action
pair, decreasing learning rate 0 (Watkins & Dayan, 1992).
Choosing action take crucial aspect learning process.
agent exploit actions yielded high reward past, explore order
achieve potentially better results future, thereby risking low reward now? Neither
two sufficient own, dilemma find right balance (Kaelbling
et al., 1996; Sutton & Barto, 1998). Two often used action selection mechanisms greedy softmax Boltzmann exploration (Sutton & Barto, 1998). -Greedy selects
best action (greedy w.r.t. Q) probability 1 , probability selects
action random. Boltzmann exploration mechanism makes use temperature
parameter controls balance exploration exploitation. Action ai
chosen state probability
e Q(s,ai )/
pi = X
.
e Q(s,aj )/

(4)

j

high temperature drives mechanism towards exploration, whereas low temperature
promotes exploitation, favouring actions higher Q-values.
2.2 Single-Agent Multi-Agent Learning
MDP framework assumes single agent active environment. multiple
agents interact learn simultaneously, model needs extended. Stochastic games,
Markov games, offer generalisation MDPs multi-agent domain (Littman, 1994).
stochastic game, agent set actions, i.e., n agents joint-action
663

fiBloembergen, Tuyls, Hennes, & Kaisers

space = A1 A2 . . . . state transition reward functions depend
joint action agents:
R : A1 . . . 7 Rn
P : A1 . . . 7 [0, 1].
immediate rewards may agents need general.
special case stochastic games stateless setting described normal-form games.
Normal-form games one-shot interactions, agents simultaneously select
action receive reward based joint action, game ends.
state transition function, reward function represented n-dimensional
payoff matrix, n agents. agents policy simply probability distribution
actions. Repeated normal form games common benchmarks multi-agent learning.
scenarios detailed Section 2.3.
Learning multi-agent setting inherently complex single-agent
case described previously, agents interact environment potentially
other. Learning simultaneous, meaning changes policy one agent
may affect rewards hence optimal policy others. Moreover, agents may
conflicting interests, yet cooperation competitors may yield short long term
benefits. makes difficult judge learning process, since myopic maximisation
individual rewards might lead best overall solution. fact reward
function depends actions agents leads important characteristic
multi-agent reinforcement learning: environment non-stationary result
agent essentially pursuing moving target (Busoniu et al., 2008). Moreover, fact
multiple agents influence environment means that, perspective
individual agents, Markov property longer holds. Two different approaches multiagent learning distinguished: independent learning joint-action learning (Claus
& Boutilier, 1998). following briefly discuss approaches, list notable
algorithms class. detailed taxonomy multi-agent learning algorithms,
refer excellent survey Busoniu et al. (2008).
2.2.1 Independent Learning
Independent learners mutually ignore other, thereby effectively reducing multiagent learning problem single-agent one. Interaction agents implicitly
perceived noise stochastic environment. advantage approach
single-agent learning algorithms straightforwardly applied multi-agent setting,
scalability number agents issue.2 However, stochasticity
environment means convergence guarantees single-agent setting lost.
particular, Markov property proofs typically based, longer holds.
Moreover, explicit mechanism coordination available agents. Despite
drawbacks, independent learners shown good performance many multi-agent settings (Busoniu et al., 2008).
2. Computational complexity increases linearly number agents. Performance may vary
depending specific domain algorithm.

664

fiEvolutionary Dynamics Multi-Agent Learning

Traditional single-agent reinforcement learning algorithms, Q-learning (Watkins
& Dayan, 1992) (networks of) learning automata (Narendra & Thathachar, 1974;
Wheeler Jr & Narendra, 1986; Vrancx, Verbeeck, & Nowe, 2008b), directly applied
setting. Moreover, various new independent learning algorithms proposed
specifically multi-agent setting mind. example, Bowling Veloso (2001)
proposed policy hill climbing win learn fast heuristic (WoLF-PHC), show
algorithm rational convergent multi-agent domains. examples
include frequency maximum Q-learning (Kapetanakis & Kudenko, 2002), algorithm tailored coordinate cooperative multi-agent systems, class regret minimisation
algorithms (Blum & Mansour, 2007) guarantee performance close best fixed
action hindsight opponent. Finally, two extensions Q-learning
proposed alleviate certain artifacts algorithm non-stationary (e.g. multiagent) environments: frequency-adjusted Q-learning (Kaisers & Tuyls, 2010), repeated
update Q-learning (Abdallah & Kaisers, 2013). Frequency-adjusted Q-learning
proven converge two-player two-action normal-form games (Kaisers & Tuyls, 2011;
Kianercy & Galstyan, 2012).
2.2.2 Joint-Action Learning
Whereas independent learners completely ignore presence agents, joint-action
learners explicitly take account. Joint-action learners achieve learning
space joint actions, rather individual action space (Claus &
Boutilier, 1998). observe actions agents order estimate policy,
act optimally given estimated policies. way, joint action learners
better means coordination. drawback agent needs able observe
agents actions, assumptions opponents adaptation mechanism necessary derive reasonable predictions opponents future actions. Moreover, complexity algorithm grows exponentially number agents. Examples joint
action learners minimax-Q (Littman, 1994), fictitious play AWESOME (Brown,
1951; Conitzer & Sandholm, 2007), hyper-Q (Tesauro, 2003), Nash-Q (Hu & Wellman,
2003). Worth mentioning well related stream work Bayesian reinforcement learning (Dearden, Friedman, & Russell, 1998; Strens, 2000). particular interest
discussion multi-agent learning work Chalkiadakis Boutilier (2003),
use Bayesian framework explicitly model agents uncertainty
model environment strategies agents.
2.2.3 Gradient Ascent Optimisation
somewhat separate stream multi-agent learning research revolves around gradient ascent based algorithms. methods often fall independent learning
joint-action learning, worth mentioning separately important
discussion Section 4.1. Gradient ascent (or descent) well-known optimisation technique field machine learning. Given well-defined differentiable objective function,
learning process follow direction gradient order find local optimum.
concept adapted multi-agent learning learning agents policies
follow gradient individual expected reward.
665

fiBloembergen, Tuyls, Hennes, & Kaisers

Examples gradient ascent algorithms infinitesimal gradient ascent (IGA),
designed specifically two-player two-action normal-form games (Singh, Kearns, &
Mansour, 2000), generalized infinitesimal gradient ascent (GIGA), extends IGA
games arbitrary number actions (Zinkevich, 2003). algorithms
combined win learn fast (WoLF) heuristic order improve convergence
stochastic games (Bowling & Veloso, 2002; Bowling, 2005). IGA GIGA assume
agents knowledge (reward) structure game, least
mechanism approximating gradient value function, generally
feasible practice. However, recent algorithm weighted policy learning (WPL)
relaxes assumption (Abdallah & Lesser, 2008).
2.3 Game Theory
Game theory (Von Neumann & Morgenstern, 1944; Gibbons, 1992) theory interactive
strategic decision making, therefore utmost importance multi-agent systems.
studies decision making form cooperative competitive games.
games, player set actions preference joint action outcome,
captured numerical payoff signal. games two players played
once, i.e., one-shot two-player games, payoffs represented bi-matrix
(A, B), gives payoff row player A, column player B (see
Figure 2). example, row player chooses one two rows, column player
chooses columns, outcome joint action determines payoff
both. goal player come strategy (a probability distribution
actions) maximises expected payoff game. Note games, players,
strategies, payoffs game theory map one-to-one environments, agents, policies,
rewards multi-agent systems literature.
players thought individually rational, sense player
perfectly logical tries maximise payoff, assuming others likewise.
assumption, Nash equilibrium (NE) solution concept used study
players reasonably choose do. set strategies forms NE single player
better unilaterally switching different strategy. words, strategy
NE best response strategies equilibrium.
game one Nash equilibrium, may preferred
equally. Moreover, NE may best outcome social point view.
example, consider Prisoners Dilemma (Axelrod & Hamilton, 1981), depicted Figure 3
(left). game, two players simultaneously choose either cooperate (C) defect
(D). Individually, defection best response opponent strategy, result
mutual defection single Nash equilibrium game. However, players would
better would cooperate hence dilemma.



a11 , b11 a12 , b12
a21 , b21 a22 , b22



Figure 2: General payoff bi-matrix (A, B) two-player two-action normal form game.
666

fiEvolutionary Dynamics Multi-Agent Learning

C



C
3, 3 0, 5
5, 0 1, 1


H

H

4, 4 1, 3
3, 1 3, 3

H



H
1, 0 0, 1
0, 1 1, 0

Figure 3: Payoff matrix Prisoners Dilemma (left), Stag Hunt (center),
Matching Pennies (right).
second example given Stag Hunt (Skyrms, 2004), shown Figure 3 (center).
coordination game, players prefer jointly choose either hunt stag (S)
hare (H). Hunting hare provides safe choice, payoff action independent
choice opponent. Hunting stag risky, however players yield higher
payoff manage coordinate. game two pure Nash equilibria, (S, S)
(H, H), one mixed Nash equilibrium players randomise play
probability 32 .
Finally, Matching Pennies game (Figure 3, right) two players simultaneously
choose side coin display, either heads (H) tails (T). choose
side, first player gets keep coins. pick opposite sides, second
player keeps coins. zero-sum game, single mixed NE players
randomise uniformly actions.
2.4 Evolutionary Game Theory
Classical game theory assumes full knowledge game available players,
together assumption individual rationality necessarily reflect
dynamic nature real world interactions. Evolutionary game theory relaxes rationality assumption replaces biological concepts natural selection
mutation (Maynard Smith & Price, 1973; Weibull, 1997; Hofbauer & Sigmund, 1998; Gintis, 2009). Central evolutionary game theory replicator dynamics describe
population individuals evolves time evolutionary pressure. individual certain type, individuals randomly paired interaction.
reproductive success determined fitness, results interactions.
replicator dynamics dictate population share certain type increase
individuals type higher fitness population average; otherwise
population share decrease. population
described state vector
P
x = (x1 , x2 , . . . , xn )>, 0 xi 1 xi = 1, representing fractions
population belonging n types. suppose fitness type given
Pby fit
ness function fi (x), average fitness population given f (x) = j xj fj (x).

Using xi denote dx
dt , population change time written


xi = xi fi (x) f(x) .
(5)
replicator dynamics describe change time large population individuals.
However, model interpreted alternatively representing strategy single
player, population share type represents probability
player selects corresponding pure action, summarised Table 1. replicator
dynamics describe players strategy change time repeatedly plays
667

fiBloembergen, Tuyls, Hennes, & Kaisers

Table 1: Correspondence terminology domains reinforcement learning,
game theory, evolutionary game theory.
Reinforcement Learning
environment
agent
action
policy
reward

Game Theory
game
player
action
strategy
payoff

Evolutionary Game Theory
game
population
type
distribution types
fitness

game iteratively updates policy.
Evolutionary game theory refines static
Nash equilibrium (NE) concept notion evolutionarily stable strategies (ESS).
strategy x ESS immune invasion mutant strategies, given mutants
initially occupy small fraction population. Let f (x, y) (expected) fitness
strategy x strategy y. Formally then, strategy x ESS iff, mutant
strategy y, following hold:
1. f (x, x) f (y, x),
2. f (x, x) = f (y, x), f (x, y) > f (y, y).
first condition states ESS also NE original game. second
condition states invading strategy well original strategy
original strategy itself, original strategy must better
invader invader itself. means ESS refinement
NE solution concept. Moreover, every ESS asymptotically stable fixed point
replicator dynamics (Weibull, 1997).
two-player game, player described evolving population,
every iteration game one individual players population drawn interact.
Therefore, fitness type depends population distribution coplayer, i.e., two populations co-evolving. two players populations given
x fitness functions payoff matrices B, write
expected fitness type population x
X
fi (x) =
aij yj = (Ay)i
j

similarly write average population fitness
X X
f(x) =
xi
aij yj = x>Ay.


j

Following similar reasoning population y, rewrite Equation 5 two
populations
h

xi = xi (Ay)i x>Ay
h

(6)
yi = yi (x>B)i x>By .
668

fiEvolutionary Dynamics Multi-Agent Learning

1

1

1

0.75

0.75

0.75



1



1

0.5

0.25

0
0



1

0.5

0.25

0.25

0.5

x1

0.75

1

0
0

0.5

0.25

0.25

0.5

x1

0.75

1

0
0

0.25

0.5

x1

0.75

1

Figure 4: replicator dynamics, plotted unit simplex, prisoners dilemma
(left), stag hunt (center), matching pennies (right).

illustrate dynamics Equation 6, analyse three games presented Figure 3.
Since players strategy two actions fully defined probability first action
(as x2 = 1 x1 ), plot strategy space games two-dimensional unit
simplex tuple (x1 , y1 ). Plugging payoff matrix game replicator
dynamics Equation 6, find direction relative speed change point
unit simplex. resulting vector fields three games shown Figure 4.
Figure 4 shows players prisoners dilemma drawn (D, D)
equilibrium, NE ESS. stag hunt, pure NE, (S, S)
(H, H), also ESS, mixed NE not. fixed point, asymptotically
stable. Finally, matching pennies game single mixed NE ( 21 , 12 ),
players randomise uniformly actions. However, ESS; instead
trajectories cycle around fixed point.

3. Relating Reinforcement Learning Replicator Dynamics
Recent research analysing dynamics multi-agent learning builds seminal work
Borgers Sarin (1997), first proved formal relation replicator
dynamics evolutionary game theory reinforcement learning. section,
first summarise proof. Next, present categorisation recent work, based
nature environment actions available agents.
3.1 Replicator Dynamics Continuous Time Limit Cross Learning
Multi-agent learning evolutionary game theory share substantial part foundation, deal decision making processes boundedly rational
agents, players, uncertain environments. link two fields
intuitive one, made formal proof continuous time limit
Cross learning converges replicator dynamics (Borgers & Sarin, 1997).
669

fiBloembergen, Tuyls, Hennes, & Kaisers

Cross learning (Cross, 1973) one basic stateless reinforcement learning
algorithms, updates policy3 based reward r received taking action j

r (i)r = j
(i) (i) +
.
(7)
(i)r
otherwise
valid policy ensured update rule long rewards normalised, i.e.,
0 r 1. Cross learning closely related finite action-set learning automata (Narendra
& Thathachar, 1974; Thathachar & Sastry, 2002). particular, equivalent learning
automaton linear reward-inaction (LRI ) update scheme learning step size ()
1.
estimate expected change policy, E [(i)], induced Equation 7
(Borgers & Sarin, 1997). probability (i) action affected selected
another action j selected. Let Ei [r] expected reward taking action i.
write
h
X
h

E [(i)] = (i) Ei [r] (i)Ei [r] +
(j) Ej [r](i)
j6=i

h

= (i) Ei [r]


(j)E
[r]
.
j
j

P

(8)

Assuming learner takes infinitesimally small update steps, continuous time limit
Equation 8 taken
t+ (i) = (i) + (i)
lim 0. yields continuous time system expressed
partial differential equation
h

P
(i) = (i) Ei [r] j (j)Ej [r]
two-player normal form game, write policy agent simply probability
distribution actions, i.e. x. defined, given payoff matrices B
policies x two players, respectively, yields
h

xi = xi (Ay)i x>Ay
h

(9)
yi = yi (x>B)i x>By
exactly multi-population replicator dynamics Equation 6.
link made explicit theoretically also empirically, shown
Figure 5. Here, simulate learning process two Cross learners taking
small policy update steps (by multiplying update term Equation 7 =
0.001), starting different initial policies, overlaying resulting policy traces
replicator dynamics Figure 4. observed, learning traces follow
replicator dynamics precisely. similar fashion, dynamical models different (and
complex) reinforcement learning algorithms derived. discussed
following sections.
3. dependency policy state dropped stateless environments, dependence
time implied omitted notational convenience.

670

fiEvolutionary Dynamics Multi-Agent Learning

1

1

1

0.75

0.75

0.75



1



1

0.5

0.25

0
0



1

0.5

0.25

0.25

0.5

x1

0.75

1

0
0

0.5

0.25

0.25

0.5

x1

0.75

1

0
0

0.25

0.5

x1

0.75

1

Figure 5: Policy traces Cross learning, plotted unit simplex overlaid
replicator dynamics, prisoners dilemma (left), stag hunt (center), matching
pennies (right).

3.2 Categorisation Learning Dynamics
divide learning algorithms corresponding dynamics presented
work four categories, based nature environment actions available agent. distinguish stateless normal-form games, games multiple
states probabilistic transitions them, represented stochastic games (see
also Section 2.2). Moreover, differentiate settings agent finite,
discrete choice actions, settings offer continuous range choices. Table 2
lists four resulting categories, along references work done
category. focus solely work explicitly relates dynamical models learning
multi-agent systems. large body work available discusses extensions
replicator dynamics evolutionary game theoretic viewpoint only, however, fall
outside scope survey.4
Cross learning, detailed previously, belongs first category stateless games
discrete actions. examples category stateless Q-learning related
frequency adjusted (FAQ) lenient (LFAQ) versions, regret minimisation, gradient
ascent algorithms. second category comprises stateless games continuous action
space. Typically, function approximators used settings (a recent overview
provided Busoniu, Babuska, De Schutter, & Ernst, 2010), however work
category far limited single-agent learning. Here, summarise approaches
model games using continuous action replicator dynamics. third category
stochastic (i.e. multi-state) games discrete actions. Dynamics derived
networks learning automata, particular piece-wise state-coupled replicator
dynamics, variation RESQ-learning incorporates exploration learning
process.
fourth category Table 2, comprising stochastic games continuous actionspaces, strikingly empty. Indeed, domain main interest future work,
attempts made far derive learning dynamics setting. Combining
techniques approaches second third category could fruitful starting
4. See e.g. textbooks Weibull (1997) Hofbauer Sigmund (1998) introduction.

671

fiBloembergen, Tuyls, Hennes, & Kaisers

Table 2: Categorisation dynamical models multi-agent learning available
literature.
Discrete actions

Continuous actions

Q-learning1
Normal form
games

Stochastic
games
1

FAQ-learning2
Regret Minimisation3
Lenient FAQ-learning4
Gradient ascent5
Piecewise replicator dynamics8
State-coupled replicator
dynamics9
RESQ-learning10

Tuyls et al. (2003)

4

Kianercy Galstyan (2012)
2
3

Continuous action replicator
dynamics6
Q-learning7

Kaisers Tuyls (2010, 2011)

5

Klos et al. (2010)

6

Panait et al. (2008)

7

Galstyan (2013)

Bloembergen et al. (2011)

8

Vrancx et al. (2008a)

Kaisers et al. (2012)

9

Hennes et al. (2009)

Tuyls Westra (2009)

10

Hennes et al. (2010)

point endeavour. next section provide overview work listed
Table 2, following categorisation.

4. Overview Learning Dynamics
categorisation presented Table 2 hand, give overview
dynamics various multi-agent reinforcement learning algorithms. First, learning dynamics
normal-form games discussed. Next, present replicator dynamics continuous
strategy spaces. Finally, multi-state learning dynamics described.
4.1 Learning Dynamics Normal-Form Games
Repeated normal-form games characterised stateless games, agents
choose discrete finite set actions time step. greatly simplifies
analytical approaches, time still allowing capture interesting strategic
interactions. result, normal-form games frequently used test-bed
multi-agent learning (Busoniu et al., 2008). Several learning algorithms devised
specifically normal-form games; multi-state algorithms Q-learning
straightforwardly applied removing state dependency learning update
rule. before, remainder define x policies two
agents stateless setting.
4.1.1 Independent Reinforcement Learners
described Section 3, Cross learning (CL) first algorithm linked
replicator dynamics evolutionary game theory (Borgers & Sarin, 1997). particular,
infinitesimal time limit Cross learning update rule (Equation 7) converges
672

fiEvolutionary Dynamics Multi-Agent Learning

replicator dynamics. link simple policy learner Cross learning,
dynamical system policy space may seem intuitive. However, link
extended value-based (and complex policy-based) learners well. selectionmutation model Boltzmann Q-learning proposed Tuyls et al. (2003), assuming
constant temperature .5 Tuyls et al. show dynamical system decomposed
terms exploitation (selection following replicator dynamics) exploration
(mutation randomisation based Boltzmann mechanism):6
xi =

h


P
xi h
(Ay)i x>Ay xi log xi k xk log xk .
|
{z
}
{z
}
|
exploitation

(10)

exploration

Another way view two terms Equation 10 relation thermodynamical
concepts energy entropy, selection analogous energy, mutation
entropy. entropy term subdividedPin entropy one individual strategy, log xi , entropy entire population, k xk log xk . sense, mutation
determined difference entropy individual strategy compared entropy
whole population (Tuyls et al., 2003).
dynamical model Equation 10 assumes actions updated simultaneously, case Cross learning. Q-learning, however, updates Q-value
selected action, causing discrepancies predicted dynamics actual learning behaviour algorithm. variation frequency-adjusted Q-learning (FAQ) (Kaisers
& Tuyls, 2010) mimics simultaneous action updates modulating update rule (Equation 3) inversely proportional xi , thereby following dynamical model Equation 10
precisely. Dropping state dependency, yields


1
Q(i) Q(i) + r + max Q(j) Q(i) .
j
xi
Using replicator dynamics model Equation 10, two independent proofs convergence
FAQ derived two-player two-action normal-form games, showing convergence near Nash equilibria given decreasing exploration temperature (Kaisers & Tuyls,
2011; Kianercy & Galstyan, 2012).
Lenient FAQ (LFAQ) (Bloembergen et al., 2011) variation aimed overcoming
convergence suboptimal equilibria mis-coordination early phase cooperative
learning processes, mistakes one agent may lead penalties others, irrespective
quality actions. Leniency towards mistakes achieved collecting
rewards action, updating Q-value based highest rewards.
causes (optimistic) change expected reward actions learning
agent, incorporating probability potential reward action highest
consecutive tries (Panait et al., 2008). expected reward action Ay
5. model Boltzmann Q-learning dynamics varying temperature, see work Kaisers, Tuyls,
Parsons, Thuijsman (2009) Kaisers (2012).
6. on, derive dynamics one agent only. dynamics agents follow
straightforwardly, similar Equation 9.

673

fiBloembergen, Tuyls, Hennes, & Kaisers

Equation 10 replaced utility vector u,
hP
P






X ij j
k:aik aij k
k:aik <aij k
P
ui =
k:aik =aij yk

(11)

j

P
k:statement implies summing indices k statement holds.
Recently, evolutionary framework also extended polynomial weights
algorithm, implements regret minimisation (RM) (Blum & Mansour, 2007; Klos
et al., 2010). learner calculates loss (or regret) li taking action rather
best action hindsight li = r r r actual reward received, r
optimal reward. learner maintains set weights w actions, updates
weights according perceived loss, derives new policy normalisation:
wi wi [1 li ]
wi
xi = P
.
j wj

(12)

form regret, computed time step, known external regret, whereas
internal regret computed loss respect policy replaces given action
action j occurrence (Blum & Monsour, 2007). Despite great
difference update rule policy generation compared Cross learning Q-learning,
Klos et al. (2010) show infinitesimal time limit regret minimisation similarly
linked dynamical system replicator dynamics numerator:


xi (Ay)i x>Ay
xi =
.
(13)
1 [maxk (Ay)k x>Ay]
denominator interpreted learning rate modulation dependent best
actions update, corresponding weighting action probability update expected
loss.
4.1.2 Gradient Ascent Algorithms
Gradient ascent (or descent) well known optimisation technique field Machine
Learning. Given well-defined differentiable objective function, learning process
follow direction gradient order find local optimum. concept
adapted multi-agent learning learning agents policies follow gradient
individual expected payoff. approach assumes expected payoff function
known (or accurately learned by) agents, may generally feasible
practice, since multi-agent settings payoff function usually depends (possibly
frequently changing) unobservable internal states agents.
One algorithm implementing gradient ascent multi-agent learning infinitesimal
gradient ascent (IGA) (Singh et al., 2000), learner updates policy
taking infinitesimal steps direction gradient expected payoff.
proven that, two-player two-action games, IGA either converges Nash equilibrium,
asymptotic expected payoff two players converges expected payoff
Nash equilibrium (Singh et al., 2000). discrete time algorithm using finite decreasing
674

fiEvolutionary Dynamics Multi-Agent Learning

step size shares properties. Take V (x) : Rn R value function maps
policy expected payoff. policy update rule IGA defined
V (x)
xi
x projection(x + x)

xi

(14)

denotes learning step size. intended change x may take x outside
valid policy space, case projected back nearest valid policy
projection function.
Win learn fast (IGA-WoLF) (Bowling & Veloso, 2002) variation IGA
uses variable learning rate. intuition behind scheme agent
adapt quickly performing worse expected, whereas cautious
winning. modified learning rule IGA-WoLF

V (x) min V (x) > V (x )
xi
xi
max otherwise
(15)
x projection(x + x)
x reference policy, e.g., policy belonging arbitrary Nash equilibrium.
weighted policy learner (WPL) (Abdallah & Lesser, 2008) second variation
IGA also modulates learning rate, contrast IGA-WoLF require
reference policy. update rule WPL defined

V (x) xi
Vx(x)
<0

xi
xi
1 xi otherwise
(16)
x projection(x + x)
update weighted either xi 1 xi depending sign gradient.
means x driven away boundaries policy space.
next section, derive dynamical model gradient ascent algorithms two-player two-action games, show remarkable similarities
dynamics reinforcement learners discussed Section 4.1.1.
4.1.3 Comparative Overview Learning Dynamics 2x2 Games
two-agent two-action games, dynamical models presented previous sections
simplified (Kaisers et al., 2012). Let h = (1, 1), x = (x, 1x) = (y, 1y).
learning dynamics completely described pair (x, y), denote probability
change first action learners. Cross learning (CL) leads
simplified form


x = x (Ay)1 x>Ay


= x(1 x) (a11 a12 a21 + a22 ) + a12 a22


= x(1 x) yhAh> + a12 a22
a12 a22 elements payoff matrix A. shorten notation twoaction games, let
= (Ay>)1 (Ay>)2 = yhAh> + a12 a22
675

fiBloembergen, Tuyls, Hennes, & Kaisers

denote gradient, CL dynamics written x = x(1 x). Then,
similarly, simplified FAQ dynamics read



x
x = x(1 x)
.
log

1x
dynamics RM slightly complex, denominator depends
action gives highest reward. derived gradient: first action
maximal iff > 0. Using insight, dynamics RM two action games
written follows:

(1 + x)1
< 0
x = x(1 x)
1
(1 (1 x))
otherwise.
IGA, update rule worked similar fashion. main term
update rule gradient expected reward, two player two-action games
written


V (x)


=
(x, 1 x)A
1y
x
x
= y(a11 a12 a21 + a22 ) + a12 a22
= yhAh> + a12 a22
= .
reduces dynamics update rule IGA two-player two-action games
x = . extension dynamics IGA IGA-WoLF WPL straightforward.
Table 3 lists dynamics six discussed algorithms: IGA, IGA-WoLF, WPL,
CL, FAQ RM. immediately clear table algorithms share
basic term dynamics: gradient . Depending algorithm,
gradient scaled learning speed modulation. Interestingly, dynamics IGA
completely independent learners current policy x. words, IGA
Table 3: table shows overview learning dynamics, rewritten specific
case two-agent two-action games (Kaisers et al., 2012).
Algorithm
IGA
IGA-WoLF
WPL
CL
FAQ
RM

x


min V (x) > V (x )

max otherwise

x
< 0

(1 x) otherwise
x(1 x)


x
x(1 x) 1 log 1x

(1 + x)1
< 0
x(1 x)
1
(1 (1 x))
otherwise
676

fiEvolutionary Dynamics Multi-Agent Learning

off-policy algorithm assumes actions sampled equally often. contrast,
multi-agent learning setting (gradient the) value function known,
learners necessarily need on-policy, otherwise cannot learn true value
function. light, argued Cross learning implements stochastic onpolicy gradient ascent (Kaisers et al., 2012). Finally, FAQ yields dynamics
additionally add exploration terms process.
analysis shows merits evolutionary game theoretic approach study
multi-agent learning. deriving mathematical models infinitesimal time limit
various learning algorithms, formally establish underlying differences
commonalities.
4.2 Replicator Dynamics Continuous Action Spaces
dynamics algorithms discussed previously assume discrete, finite action space.
contrast, many real-world settings feature actions rather continuous nature.
settings tabular notation Q-functions policies longer feasible
function approximators need used. One approach discretise continuous parameters ranges, treat range one instance. However, straightforward
general design good discretisation, details might lost. Another approach
model continuous actions directly, moving discrete probability vectors actions probability density functions. Examples Q-learning algorithms continuous action spaces fitted Q-iteration (Ernst, Geurts, & Wehenkel, 2005) NEAT+Q-learning
(Whiteson & Stone, 2006). Learning automata similarly extended continuous action spaces. instance, Santharam, Sastry, Thathachar (1994) propose continuous
action-set learning automata (CALA) use Gaussian distribution model policy.
also possible use nonparametric distribution, employed continuous action
reinforcement learning automata (CARLA), allowing diverse exploration strategy
convergence potentially multi-modal distribution (Howell, Frost, Gordon, & Wu,
1997; Rodrguez, Vrancx, Grau, & Nowe, 2012). in-depth discussion learning
methods falls outside scope paper. Instead, focus modelling
algorithms extending replicator dynamics continuous action spaces.7
Suppose agents action space described continuous parameters x =
(x1 , x2 , . . . , xD ), x RD , allowed action space. two-player
setting, reward playing action x opponent plays given f (x, y).
agents policy time given probability density function action
space, (x, t),
Z
(x, t)dx = 1.


write continuum limit standard replicator dynamics (Equation 5)
partial differential equation (Oechssler & Riedel, 2001; Cressman, 2005; Tuyls & Westra,
2009):
h

(x, t)
= (x, t) V (x, t) E(t)
(17)

7. recent extensive overview function approximation methods reinforcement learning provided
Busoniu et al. (2010).

677

fiBloembergen, Tuyls, Hennes, & Kaisers



Z
f (x, y)(y, t)dy

V (x, t) =
Z
E(t) =

V (x, t)(x, t)dx.


Here, V (x) depicts expected reward action x, E overall average reward.
context statistical mechanics terms thought local potential
total energy, respectively.
Similar discrete action dynamics discussed before, add mutation terms
Equation 17 model exploration learning agents. straightforward
approach including diffusion term replicator dynamics,
allows mutation strategies slightly different ones nearby. procedure
originally proposed Hofbauer Sigmund (1998), Ruijgrok Ruijgrok
(2005) provided rigorous mathematical foundation subsequent analysis. Ruijgrok
Ruijgrok add diffusion term continuous action replicator dynamics
find even small mutation rate may greatly alter outcome learning process,
leading favourable results in, e.g., ultimatum game. Specifically, add
transition probability per unit time qij spontaneous transfer strategy
strategy j. way discrete replicator equations mutation written
follows:
X
xi = xi (Vi E) +
(qij xj qji xi ).
j

Ruijgrok Ruijgrok follow method Van Kampen (1992) derive continuum
limit mutation term. Using approach, arrive continuous replicator equation Hofbauer Sigmund:
h

(x, t)
= (x, t) V (x, t) E(t) + (x, t)2 (x, t).
(18)

Ruijgrok Ruijgrok study equation number games transformed continuous strategy setting. is, however, reason assume mutations restricted adjacent strategies. Therefore, building work, Tuyls
Westra (2009) compare three different diffusion-based mutation terms, find
type mutation also significantly influence resulting dynamics. Specifically,
replace simple isotropous diffusion term containing mutation rate Ruijgrok
Ruijgrok mimicking effect anisotropous deterministic mutations. start
continuous time discrete action replicator equations mutation,
derive different formulation continuous action space:
h

h

(x, t)
= (x, t) V (x, t) E(t) + (x) V (x)(x, t) .

new formulation able capture certain aspects evolution driven game
theoretic interactions absent original formulation Hofbauer Sigmund,
Ruijgrok Ruijgrok Equation 18. dynamics approach even
complex different mutation rates provide entirely different stationary solutions. Full
details found work Tuyls Westra.
678

fiEvolutionary Dynamics Multi-Agent Learning

Although dynamical models Equations 17 18 yet directly linked
specific learning algorithm, Galstyan (2013) recently proposed dynamical model
continuous action version Boltzmann Q-learning. Galstyans model similar selection
term based local potential V (x) total energy E, mutation term
entropy term derived Boltzmann distribution, Equation 10. Galstyan
finds mutation drives learning process away pure Nash equilibria helps
convergence uniformly mixed equilibria, similar discrete action Q-learning (see Kaisers
& Tuyls, 2011; Kianercy & Galstyan, 2012).
4.3 State-Coupled Replicator Dynamics
far, discussion learning dynamics limited stateless games. Although
many real-world interactions indeed cast form repeated normal-form games,
always case. Therefore, need understand learning dynamics
statefull environments well. Vrancx et al. (2008a) propose combination replicator dynamics switching dynamics model learning automata stochastic (Markov) games.
learning automata definition stateless (see Section 3.1), extension needed
multi-state games. One option agent maintain network learning automata
(Wheeler Jr & Narendra, 1986; Vrancx et al., 2008b), one state. game
progresses, control passed one automaton depending current
state game. Instead performing policy updates active automaton based
immediate reward rt , update delayed automaton becomes active again,
time updated based average reward received period. Based
mechanism, Vrancx et al. (2008a) partition state-space cells, corresponding
different attractors average reward games. cell fixed replicator dynamic,
based agents policies updated. update makes system leave
current cell, new replicator dynamic takes over. Hennes, Tuyls, Rauterberg (2008)
formalise piece-wise replicator dynamics.
piece-wise model suffers several shortcomings, however, demonstrated
Hennes et al. (2009). Firstly, model approximates learning behaviour assuming fixed dynamics cell, secondly, discrete switching cells causes
discontinuities present real traces learning process. order alleviate shortcomings, Hennes et al. propose state-coupled replicator dynamics
(SC-RD) model uses direct state coupling rather piece-wise switching dynamics. direct state coupling eliminates anomalies discontinuities caused linear
approximations discrete cell switching. SC-RD
defined follows. Let
set policies n agents, i.e., = 1 , 2 , . . . , n . Moreover, let = a1 , a2 , . . . ,
joint action. Assuming game absorbing states (i.e., set states
ergodic), exists stationary
states ,

P distribution
frequency state sS
= 1. calculate limiting average
reward r playing specific joint-action state s, given fixed policies
states s0 ,

ri (s, a) =
r (s, a) +

X
s0 S{s}

679


0

s0 f



(19)

fiBloembergen, Tuyls, Hennes, & Kaisers

f (s0 ) expected reward (fitness) agent state s0 , calculated
X



f (s) =




r (s, a)

Qn

Aj

j=1

n




k



k

s,



!
.

k=1

set system differential equations agent action j, similar
Equation 9, payoff matrix substituted limiting average reward r.
Furthermore, instead single
opponent policy agents policies

= 1 . . . i1 , i+1 . . . n . expected payoff player playing pure action j
state given



X


ri s, a0
fji (s) =
k s, a0k
a0

Q

l6=i

Al

k6=i


a0 = a1 . . . ai1 , j, ai . . . . Essentially, enumerate possible joint actions
fixed action j agent i. general, mixed policy , agent receives
expected payoff




ri s, a0
k s, a0k


f (s, ) =

X
ai Ai


X

(s, ai )
a0

Q

l6=i

Al

k6=i

r limiting average reward given Equation 19. Writing xi (s) (s)
probability distribution actions agent j state s, define
multi-population state-coupled replicator dynamics following system differential
equations:


xij (s) = xij (s)xs f (s, ej ) f s, xi (s)
(20)
ej j th -unit vector,
policy plays pure action j.
P corresponding
P
total system N = sS ni=1 |Ai | replicator equations. Hennes et al. show
SC-RD model describes true learning dynamics networks learning automata
far precise piece-wise replicator dynamics.
Recently, replicator dynamics extended sequence form representation extensive-form games well (Gatti, Panozzo, & Restelli, 2013; Lanctot, 2014).
allows us model even complex games, e.g. sequential moves imperfect information. Panozzo et al. (2014) developed new version Q-learning works
sequence form, along dynamical model matches learning process based
sequence-form replicator dynamics mutation term similar Equation 10.
show that, although selection mechanism sequence-form normal-form
replicator dynamics realization equivalent (Gatti et al., 2013; Lanctot, 2014), mutation term not. in-depth discussion findings falls outside scope
article, would require addition much broader background extensive-form
games. However, recent works show promise evolutionary framework
multi-agent learning beyond normal-form even stochastic games well.
680

fiEvolutionary Dynamics Multi-Agent Learning

5. Experimental Overview
established link multi-agent reinforcement replicator dynamics
evolutionary game theory Section 3, provided overview learning dynamics
normal-form games, continuous strategy spaces, stochastic (Markov) games Section 4.
Here, show set experiments empirically validate models two-player twoaction normal-form games. restrict games simplicity allows
easy visual analysis, preserving explanatory power dynamical models.
end section provide overview related empirical work complex
interactions.
described earlier, two-player two-action games policy space compactly
represented unit simplex completely defined probability
agents select first action. makes easy plot visually inspect
learning dynamics interactions. Section 3.1, Figure 5, example analysis
found Cross learning, compared standard replicator dynamics. Similar
analysis performed different learning algorithms, plotting policy traces
learning behaviour overlaid vector field corresponding dynamical model (see
e.g. Tuyls et al., 2006; Klos et al., 2010; Kaisers & Tuyls, 2010, 2011; Bloembergen et al.,
2011). Figure 6 shows standard frequency-adjusted Q-learning (FAQ),
lenient counterpart (LFAQ), top two rows. Whereas dynamics different
algorithms similar convergence behaviour one equilibrium present,
case prisoners dilemma matching pennies, stag hunt differences
observed. notion leniency, introduced overcome convergence suboptimal
equilibria, works drive learning process towards optimal outcome game (S,
top right corner), easily observed investigating vector field. Interestingly,
Cross learning standard replicator dynamics converge matching
pennies game, (L)FAQ sprial inwards towards single Nash equilibrium ( 12 , 21 ),
evolutionarily stable classical replicator dynamics model (Section 2.3).
additional exploration term makes difference here.
far, analysed dynamics two identical learners pitted
other. However, replicator dynamics model allows heterogeneous systems well,
different agents follow different learning rules. cases, policy change
individual agent modelled different variation replicator dynamics,
corresponding agents learning rule. bottom row Figure 6 shows
situation FAQ LFAQ pitted other. games selfplay dynamics learners similar, prisoners dilemma matching
pennies, mixed dynamics change significantly. cases, stag
hunt, learning process clearly influenced different dynamics mix. LFAQ
stronger tendency play optimal action S, FAQ persuaded likewise.
analysis makes possible compare behaviour learning algorithms heterogeneous
environments, compare different parameter settings single algorithm.
final example, revisit comparison gradient ascent-based reinforcement
learning algorithms Section 4.1.3. Figure 7 shows learning dynamics predicted
models derived presented Table 3, matching pennies game. Regret
minimisation (RM) omitted dynamics visually indistinguishable Cross
681

fiBloembergen, Tuyls, Hennes, & Kaisers

FAQ-learning
1

1

1

0.75

0.75

0.75

y1

y1

0.5

0.25

y1

0.5

0.25

0
0

0.25

0.5
x1

0.75

0.25

0
0

1

0.5

0.25

0.5
x1

0.75

0
0

1

0.25

0.5
x1

0.75

1

0.25

0.5
x1

0.75

1

0.75

1

Lenient FAQ-learning
1

1

1

0.75

0.75

0.75

y1

y1

0.5

0.25

y1

0.5

0.25

0
0

0.25

0.5
x1

0.75

0.25

0
0

1

0.5

0.25

0.5
x1

0.75

0
0

1

1

1

0.75

0.75

0.75

0.5

0.25

0
0

LFAQ: y1

1

LFAQ: y1

LFAQ: y1

FAQ vs LFAQ

0.5

0.25

0.25

0.5
FAQ: x1

0.75

Prisoners Dilemma

1

0
0

0.5

0.25

0.25

0.5
FAQ: x1

Stag Hunt

0.75

1

0
0

0.25

0.5
FAQ: x1

Matching Pennies

Figure 6: Policy traces FAQ LFAQ, plotted unit simplex overlaid
respective dynamical model, prisoners dilemma (left), stag hunt (center),
matching pennies (right) (Bloembergen et al., 2011).

682

fiEvolutionary Dynamics Multi-Agent Learning

1



1



1

0.5

0
0



1

0.5

0.5
x

0
0

1

1

0.5

0.5
x

0
0

1



0.5

1



1

1

CL

1

0
0

IGA
WoLF
WPL
CL
FAQ

1

0.5

0.5

0.5
x

1

WPL

1

1

0.5
x
1

IGA-WoLF

1

0
0

1

1

IGA



1

0.5
x
1

FAQ

1

0
0

0.5
x

1

1

Traces

Figure 7: Overview dynamics various gradient ascent reinforcement learning algorithms matching pennies. bottom right panel shows single trace
dynamical models, using initial policy (indicated ) (Kaisers et al., 2012).

learning (CL). clearly observe similarity CL infinitesimal gradient
ascent (IGA), cycle around central equilibrium point without converging.
Win-or-learn-fast IGA (WoLF) weighted policy learner (WPL) converge due
learning rate modulator; case WoLF, two learning rates used (for
winning loosing), whereas WPL uses continuum learning rates, resulting nonlinear dynamics. difference clearly observed comparing vector fields
respective dynamical models. noted before, FAQ spirals inwards towards Nash
equilibrium although hard observe vector field alone, fact
verified following trace dynamics, shown bottom right panel Figure 7
different algorithms. traces highlight (subtle) similarities differences
diverse algorithms.
Similar analyses performed investigate learning dynamics complex
(e.g., multi-state) games, highlight influence certain parameters learning
process. instance, Tuyls et al. (2003) first derive selection-mutation
dynamics Q-learning discrete-action normal-form games, visually compare traces
learning algorithm predicted dynamics model. Similar derivations
analyses later provided algorithms learning automata (Tuyls
683

fiBloembergen, Tuyls, Hennes, & Kaisers

et al., 2006) regret minimisation (Klos et al., 2010). Others focused learning
dynamics multi-state (stochastic) games, particular deriving dynamics networks
learning automata (Vrancx et al., 2008a; Hennes et al., 2009). others derived new
learning algorithms based desirable dynamical model, leading FAQ-learning (Kaisers
& Tuyls, 2010) lenient FAQ (Bloembergen et al., 2011) normal-form games,
RESQ-learning stochastic games (Hennes et al., 2010). Finally, several authors
used insights stemming dynamical models compare different algorithms,
investigate convergence. example, Bowling Veloso (2002) introduce
variable learning rate WoLF heuristic prove used make IGA convergent
normal-form games. Abdallah Lesser (2008) introduce WPL compare IGA
IGA-WoLF, show WPL converges normal-form games well, without
requiring much information IGA-WoLF. Kaisers Tuyls (2011) use dynamical
model FAQ demonstrate near-NE convergence normal-form games, Galstyan
(2013) similarly shows continuous-action Q-learning (see also Section 6.1.2).
Table 4 presents overview related works, clustered interaction type i.e.,
normal form games discrete continuous actions spaces, stochastic games
lists relevant learning algorithms investigated. purposely list
works explicitly focus relation multi-agent learning algorithms
evolutionary dynamical model. works utilises extends connection
order gain qualitative insights behaviour algorithms variety
settings.

Table 4: overview related empirical evaluations learning dynamics. NFG: normalform games; CNFG: continuous action normal-form games; SG: stochastic (Markov) games.
Type

Algorithm

Reference

NFG

Q-learning

Tuyls et al. (2003, 2006)

NFG

regret minimisation

Klos et al. (2010)

NFG

FAQ

Kaisers Tuyls (2010, 2011)

NFG

lenient FAQ

Bloembergen et al. (2011)
Kaisers (2012)

NFG

WoLF

Bowling Veloso (2002)

NFG

IGA, IGA-WoLF, WPL

Abdallah Lesser (2008)

CNFG

Q-learning

Galstyan (2013)

SG

networks learning
automata

Vrancx et al. (2008a)
Hennes et al. (2009)

SG

RESQ-learning

Hennes et al. (2010)

684

fiEvolutionary Dynamics Multi-Agent Learning

6. Applications
previous sections highlighted descriptive power replicator dynamics
model multi-agent learning. Here, focus prescriptive power well. example, use dynamical models easy parameter tuning learning algorithms.
Moreover, starting desired dynamics, possible reverse-engineer learning algorithm exhibits preferred behaviour. Finally, evolutionary models
used analyse complex strategic interactions, automated trading. Focusing
meta-strategies rather primitives reduces complexity interactions enough
study dynamics analytically.
6.1 Parameter Tuning
Parameter tuning traditionally cumbersome task involving many simulation trials, often
following evolutionary optimisation approach. However, deterministic dynamical model effect various parameters learning process readily observable.
following, provide examples lenient learning, balancing exploration
exploitation.
6.1.1 Degree Leniency
Lenient learning introduced way overcome problem suboptimal convergence cooperative multi-agent settings, initial mis-coordination leads
undervaluation optimal action (Panait et al., 2008). problem also known
relative overgeneralisation (Wiegand, 2003) action shadowing (Fulda & Ventura, 2007).
focusing learning update maximal rewards rather average, learner effectively ignores low rewards due suboptimal behaviour others early
phases learning process. achieved collecting rewards action
performing update based highest rewards (Panait et al., 2008;
Bloembergen et al., 2011). details dynamical model lenient frequency-adjusted
Q-learning (LFAQ) given Section 4.1.1, Equation 11.
main parameter LFAQ degree leniency, . One main advantages
dynamical model allows studying tuning parameter without
need extensive simulations. Instead, directly analyse dynamical model.
Figure 8 shows dynamics LFAQ, following Equation 11, stag hunt,
{1, 2, 5, 25}. stag hunt two pure Nash equilibria also evolutionarily stable
strategies, agents either play H, (0, 0), S, (1, 1) (see Section 2.3).
dilemma game choice safe action H, always gives
reward independent agents action, S, optimal,
players coordinate. precisely problem leniency aims solve. Figure 8
shows degree leniency increases, basin attraction optimal
outcome (1, 1). Depending nature game opponent, balance needs
found leniency one hand, risk exploited, lagging
behind changing environment, other. dynamical model greatly facilitates
gaining quick insight effects.
685

fi1

1

0.75

0.75

0.75

0.75

0.5

0.25

0
0

0.5

0.25

0.25

0.5
0.75
LFAQ: x1

=1

1

0
0

LFAQ: y1

1

LFAQ: y1

1

LFAQ: y1

LFAQ: y1

Bloembergen, Tuyls, Hennes, & Kaisers

0.5

0.25

0.25

0.5
0.75
LFAQ: x1

1

=2

0
0

0.5

0.25

0.25

0.5
0.75
LFAQ: x1

=5

1

0
0

0.25

0.5
0.75
LFAQ: x1

1

= 25

Figure 8: effect degree leniency convergence stag hunt game.
solid line indicates boundary basins attraction two equilibria;
global optimum located (1, 1) (Bloembergen et al., 2011).

6.1.2 Tuning Exploration Rate FAQ-Learning
Balancing exploration exploitation vital importance learning task, particular dynamic environments multiple learning agents interact. (FA)Q-learning
Boltzmann exploration (Equation 4), temperature parameter controls level
exploration high temperature promotes exploration, whereas low temperature favours
exploitation. dynamical model FAQ (Equation 10) allows study effect
exploration rate behaviour convergence learner multi-agent setting,
demonstrated Kaisers Tuyls (2011).
Figure 9 shows effect dynamics convergence FAQ battle
sexes. game, players need coordinate either one two actions, however
different preference joint outcomes:

B
B
2, 1 0, 0

0, 0 1, 2
first three frames figure show dynamics computed fixed points
different temperatures (first frame = , second frame = 0.72877, third frame = 0).
fixed points move discrete values indicated paths shown
fourth frame. game three Nash equilibria, (0, 0), (1, 1), ( 32 , 13 ). However,
high values replicator model yields one attracting fixed point, moves
( 12 , 21 ) towards mixed equilibrium ( 23 , 13 ). Kaisers Tuyls show fixed
point splits supercritical pitchfork bifurcation critical temperature crit 0.72877
position (x1 , y1 ) (0.5841, 0.4158). low temperatures < crit , dynamics
yield three fixed points move closer corresponding equilibria decreased.
two fixed points moving toward pure equilibria (0, 0) (1, 1) attracting,
third one moving toward ( 32 , 13 ) repelling.
similar analysis Boltzmann Q-learning performed Kianercy Galstyan (2012). also observe fixed points dynamical model move towards
Nash equilibria 0 relate temperature Boltzmann mechanism
thermodynamical concept free energy (Galstyan, 2013). Gomes Kowalczyk (2009)
propose dynamical model -greedy Q-learning, show model accurately
686

fiEvolutionary Dynamics Multi-Agent Learning

1

1

1

1

0.8

0.8

0.8

0.8

0.6

0.6

y1

0.6

0.6

y1

y1

y1

0.4

0.4

0.4

0.4

0.2

0.2

0.2

0.2

0
0

0.2

0.4

x1

0.6

0.8

1

0
0

0.2

0.4

x1

0.6

0.8

0
0

1

0.2

0.4

x1

0.6

0.8

0
0

1

0.2

0.4

x1

0.6

0.8

1

Figure 9: Replicator dynamics (arrows) fixed points () = {, 0.72877, 0}
(first three frames). Right-most frame shows trajectories fixed points temperature
decreased (Kaisers & Tuyls, 2011).

predicts empirical findings. Similarly, Wunder, Littman, Babes (2010) present
detailed study -greedy Q-learning various classes normal-form games provide
proofs (non-) convergence class, varying rapid convergence stable oscillations. works shows great applicability benefit replicator
dynamics model multi-agent learning, investigating effect various parameters
learning process.
6.2 Design New Learning Algorithms
far, taken forward approach: starting learning algorithm derived
dynamical model accurately predicts behaviour algorithm limit.
can, however, also take inverse approach starting set desired dynamics
reverse-engineering learning algorithm exhibits dynamical properties (Hennes
et al., 2010; Tuyls, Heytens, Nowe, & Manderick, 2003).
example, consider state-coupled replicator dynamics (SC-RD) introduced Section 4.3. dynamics describe behaviour networks learning automata, essentially exploiting, exploration solely induced stochastic
action-selection process. However, results domain stateless games suggest
exploration aids convergence mixed equilibria, purely exploitative learners enter
cycles (see Section 5, particular Figure 7). Hennes et al. (2010) extend SC-RD model
(Equation 20) exploration term FAQ-learning (Equation 10), leads

xij (s)

=

xij (s)xs

"


f (s, ej ) f s, xi (s)




log xij +

X



xik log xik

#
.

k

dynamics translated learning algorithm adding similar exploration
term policy update network learning automata. reward remains equal
average accumulated reward since last visit particular automata,
687

fiBloembergen, Tuyls, Hennes, & Kaisers

policy update taking action j computed
(
P
r (i)r (log (i) + k (k) log (k)) = j
P
(i) (i) +
(i)r (log (i) + k (k) log (k))
otherwise.
Hennes et al. show RESQ-learning able converge two-state version matching
pennies, standard SC-RD cycle around equilibrium.
Another example given work Tuyls et al. (2003), standard replicator
dynamics extended ensure stable convergence Nash equilibria classes twoagent two-action normal-form games. Based extended replicator dynamics Tuyls
et al. derive extended Cross learning algorithm adheres preferred dynamics.
6.3 Evolutionary Analysis Complex Strategic Interactions
addition relatively simple, stylised games, also analyse much complex
systems. accomplished taking high-level view focusing meta-strategies,
rather atomic actions, scenarios. example, allows us study
evolutionary dynamics various trading strategies stock markets (Kaisers et al., 2009;
Hennes, Bloembergen, Kaisers, Tuyls, & Parsons, 2012; Bloembergen, Hennes, McBurney,
& Tuyls, 2015). Similarly, possible compare auction mechanisms (Phelps, Parsons, &
McBurney, 2005), strategies game poker (Ponsen, Tuyls, Kaisers, & Ramon, 2009),
even collision avoidance methods multi-robot systems (Hennes, Claes, & Tuyls, 2013).
Moreover, link replicator dynamics reinforcement learning allows us
predict happen agents learn optimise strategy scenarios.
following, present two examples analyses. Firstly, detail heuristic
payoff tables method estimate payoff high-level meta-strategies empirically.
Next, present use analysis evaluate trading strategies stock markets
(Section 6.3.2), collision avoidance strategies multi-robot systems (Section 6.3.3).
6.3.1 Heuristic Payoff Tables
order analyse evolutionary strength high-level meta-strategies, need
estimate expected payoff strategies relative other. evolutionary
game theoretic terms, relative fitness various strategies, dependent
current frequencies strategies population. evolutionary model assumes
infinite population. cannot compute payoff population directly,
approximate evaluations finite population. possible distributions
k strategies enumerated finite population n individuals. Let N
matrix,
row Ni contains one discrete distribution. matrix yield
n+k1
rows. distribution strategies simulated (using appropriate
n
model environment), returning vector expected relative rewards u(Ni ). Let U
matrix captures rewards corresponding rows N , i.e., Ui = u(Ni ).
heuristic payoff table H = (N, U ) proposed Walsh, Das, Tesauro, Kephart (2002)
capture payoff information possible discrete distributions finite population.
example heuristic payoff table given Table 5. example,
k = 3 different meta-strategies, distributed population n = 6 individuals.
row N specifies exactly many individuals use three strategy types,
688

fiEvolutionary Dynamics Multi-Agent Learning

Table 5: Example heuristic payoff table k = 3 strategies finite population
n = 6 individuals.
Ni1
6
5
3
0

Ni2
0
1

1

0

Ni3
0
0

Ui1
0.5
0.4

2

0.3

6

0

Ui2
0
0.7

0.5

0

Ui3
0
0
0.8
0.9

row U specifies estimated payoff. discrete distribution Ni features zero
individuals type j, payoff naturally cannot measured, set Uij = 0.
order approximate payoff arbitrary mix strategies infinite population distributed species according x, n individuals drawn randomly
infinite distribution. probability selecting specific row Ni computed
x Ni


k
n
N
P (Ni |x) =
xj ij .
Ni1 , Ni2 , . . . , Nik
j=1

expected payoff strategy i, fi (x), computed weighted combination
payoffs given rows:
P
j P (Nj |x)Uji
fi (x) =
.
1 (1 xi )k
expected payoff function used Equation 5 compute evolutionary
population change according replicator dynamics.
6.3.2 Value Information Markets
example, consider market differently informed traders bid certain
asset (Bloembergen et al., 2015). Depending information level, traders
certain amount foresight regarding future value stock. information gives
better approximation real current value asset; however, information comes
price. use replicator dynamics model analyse effect various pricing
schemes information, e.g. cost, fixed cost amount information, cost
function linear amount information. Traders also choose acquire
additional information instead rely solely current market price. running
market simulations different distributions information levels among traders,
compute heuristic payoff table described above, use table basis
replicator model.
Figure 10 shows resulting dynamics three types traders (uninformed ZI;
averagely informed I3; insiders I9), three different cost functions described
above. absence costs, best strategy obtain much information
689

fiBloembergen, Tuyls, Hennes, & Kaisers

F9

ZI

F9

F3

ZI

F9

F3

ZI

F3

Figure 10: Vector field showing evolutionary dynamics market three information levels different cost functions information: cost (left), fixed cost (center),
linear cost (right) (Bloembergen et al., 2015).

possible, leading domination I9 traders entire interior simplex. Adding
fixed costs gives small boost I0 traders (who pay), allowing
survive equilibrium alongside insiders. linear cost function gives rise
internal equilibrium types coexist. analysis valuable tool
gain insight dynamics stock markets, helps predict effect external
influences (such costs, e.g. form taxing schemes) market whole.
6.3.3 Collision Avoidance Multi-robot Systems
Autonomous collision avoidance complex task field robotics, especially
presence dynamic obstacles. task increases complexity dynamic
obstacles mobile robots also take actions avoid collisions. However, assuming
mutual avoidance (reciprocity) may potentially improve avoidance behaviour since
robot needs take half responsibility avoiding pairwise collisions. order
test hypothesis employ meta-strategy approach evaluate
evolutionary strength different collision avoidance strategies (Hennes et al., 2013).
One approach collision avoidance continuous spaces velocity obstacle (VO)
paradigm, first introduced Fiorini Shiller (1998) local collision avoidance
navigation dynamic environments multiple moving objects. VO strategy
modified include reciprocity, yielding reciprocal velocity obstacle (RVO); hybrid
two given HRVO. Figure 11 (left) shows evolutionary dynamics
resulting heuristic payoff table three strategies. pure population states
asymptotically stable fixed points replicator dynamics. Although basin
attraction RVO considerably smaller, see clearly dominant strategy
setting. pairwise comparison two strategies, along faces simplex,
strategy inferior; three strategies evolutionarily stable.
VO takes obstacles account, independent distance. may greatly
reduce mobility robots highly cluttered environment. order overcome
problem, VO truncated ignore obstacles farther away. Truncation
yields significantly different complex dynamics, shown Figure 11 (right).
pairwise comparison (faces simplex), RVO dominated VO well HRVO.
690

fiEvolutionary Dynamics Multi-Agent Learning

VO

HRVO

VO

RVO

HRVO

RVO

Figure 11: Evolutionary dynamics three strategies multi-robot collision avoidance,
without truncation (left) truncation (right) (Hennes et al., 2013).
However, reciprocal velocity obstacle robust presence three strategies
(interior simplex), explained aggressive,
least restricting, strategy.

7. Conclusions
article surveyed recent advances study evolutionary dynamics
multi-agent learning. particular, presented formal relation reinforcement learning replicator dynamics evolutionary game theory. modifying
standard replicator dynamics, behaviour various state-of-the-art reinforcement learning algorithms multi-agent setting modelled accurately. far, link
established stateless environments (e.g. normal form games), discrete
continuous action spaces, multi-state environments (e.g. stochastic games)
discrete action space. Therefore, important avenue future work extension
theory stochastic games continuous action spaces.
analytical study multi-agent learning dynamics offers several important advantages. particular, sheds light black box reinforcement learning, making
possible analyse learning dynamics multi-agent systems detail, compare behaviour different algorithms principled manner. turn facilitates
important tasks parameter tuning. Furthermore, studying dynamics different
learning algorithms helps selecting specific learner given problem. Moreover,
possible derive new learning algorithms first designing preferred dynamics. Finally, theory applied complex strategic interactions real-world settings
analysing meta-strategies, demonstrated automated trading multi-robot collision
avoidance.

691

fiBloembergen, Tuyls, Hennes, & Kaisers

Acknowledgments
grateful editor anonymous reviewers JAIR valuable feedback
helpful suggestions.

References
Abdallah, S., & Kaisers, M. (2013). Addressing policy-bias Q-learning repeating
updates. Proc. 2013 int. conf. Autonomous Agents Multi-Agent
Systems (AAMAS 2013), pp. 10451052. International Foundation AAMAS.
Abdallah, S., & Lesser, V. (2008). multiagent reinforcement learning algorithm
non-linear dynamics. Journal Artificial Intelligence Research, 33 (1), 521549.
Agogino, A. K., & Tumer, K. (2012). multiagent approach managing air traffic flow.
Autonomous Agents Multi-Agent Systems, 24 (1), 125.
Ahmadi, M., & Stone, P. (2006). multi-robot system continuous area sweeping tasks.
ICRA, pp. 17241729.
Axelrod, R., & Hamilton, W. D. (1981). evolution cooperation. Science, 211 (4489),
13901396.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bloembergen, D., Hennes, D., McBurney, P., & Tuyls, K. (2015). Trading markets
noisy information: evolutionary analysis. Connection Science, appear.
Bloembergen, D., Kaisers, M., & Tuyls, K. (2011). Empirical theoretical support
lenient learning. Tumer, Yolum, Sonenberg, & Stone (Eds.), Proc. 10th Intl.
Conf. Autonomous Agents Multiagent Systems (AAMAS 2011), pp. 1105
1106. International Foundation AAMAS.
Blum, A., & Mansour, Y. (2007). Learning, regret minimization equilibria. Cambridge
University Press.
Blum, A., & Monsour, Y. (2007). external internal regret. Journal Machine
Learning Research, 8, 13071324.
Borgers, T., & Sarin, R. (1997). Learning reinforcement replicator dynamics.
Journal Economic Theory, 77 (1).
Bowling, M., & Veloso, M. (2002). Multiagent learning using variable learning rate.
Artificial Intelligence, 136, 215250.
Bowling, M. (2005). Convergence no-regret multiagent learning. Advances neural
information processing systems, 17, 209216.
Bowling, M., & Veloso, M. (2001). Rational convergent learning stochastic games.
Proc. 17th Intl. Joint Conf. Artificial Intelligence, pp. 10211026.
Brown, G. W. (1951). Iterative solution games fictitious play. Activity analysis
production allocation, 13 (1), 374376.
692

fiEvolutionary Dynamics Multi-Agent Learning

Busoniu, L., Babuska, R., & De Schutter, B. (2008). comprehensive survey multiagent
reinforcement learning. IEEE Transactions Systems, Man, Cybernetics, Part
C: Applications Reviews, 38 (2), 156172.
Busoniu, L., Babuska, R., De Schutter, B., & Ernst, D. (2010). Reinforcement learning
dynamic programming using function approximators. CRC Press.
Chalkiadakis, G., & Boutilier, C. (2003). Coordination multiagent reinforcement learning:
Bayesian approach. Proc. 2nd intl. joint conf. Autonomous Agents
MultiAgent Systems, pp. 709716. ACM.
Claes, D., Hennes, D., Tuyls, K., & Meeussen, W. (2012). Collision avoidance bounded
localization uncertainty. IROS, pp. 11921198.
Claus, C., & Boutilier, C. (1998). dynamics reinforcement learning cooperative
multiagent systems. AAAI/IAAI, pp. 746752.
Conitzer, V., & Sandholm, T. (2007). Awesome: general multiagent learning algorithm
converges self-play learns best response stationary opponents.
Machine Learning, 67 (1-2), 2343.
Cressman, R. (2005). Stability replicator equation continuous strategy space.
Mathematical Social Sciences, 50 (2), 127147.
Cross, J. G. (1973). stochastic learning model economic behavior. Quarterly
Journal Economics, 87 (2), 239266.
Dearden, R., Friedman, N., & Russell, S. (1998). Bayesian Q-learning. AAAI/IAAI.
Ernst, D., Geurts, P., & Wehenkel, L. (2005). Tree-based batch mode reinforcement learning.
Journal Machine Learning Research, pp. 503556.
Fiorini, P., & Shiller, Z. (1998). Motion planning dynamic environments using velocity
obstacles. International Journal Robotics Research, 17, 760772.
Fulda, N., & Ventura, D. (2007). Predicting preventing coordination problems cooperative Q-learning systems.. Proceedings International Joint Conference
Artificial Intelligence (IJCAI-07), Vol. 2007, pp. 780785.
Galstyan, A. (2013). Continuous strategy replicator dynamics multi-agent q-learning.
Autonomous agents multi-agent systems, 26 (1), 3753.
Gatti, N., Panozzo, F., & Restelli, M. (2013). Efficient evolutionary dynamics
extensive-form games. Twenty-Seventh AAAI Conference Artificial Intelligence,
pp. 335341.
Gibbons, R. (1992). Primer Game Theory. Pearson Education.
Gintis, H. (2009). Game Theory Evolving (2nd edition). University Press, Princeton NJ.
Gomes, E. R., & Kowalczyk, R. (2009). Dynamic analysis multiagent Q-learning
-greedy exploration. Proceedings 26th Annual International Conference
Machine Learning, pp. 369376. ACM.
Hennes, D., Bloembergen, D., Kaisers, M., Tuyls, K., & Parsons, S. (2012). Evolutionary
advantage foresight markets. Proceedings Genetic Evolutionary
Computation Conference (GECCO 2012), pp. 943950.
693

fiBloembergen, Tuyls, Hennes, & Kaisers

Hennes, D., Claes, D., & Tuyls, K. (2013). Evolutionary advantage reciprocity collision avoidance. Proc. AAMAS 2013 Workshop Autonomous Robots
Multirobot Systems (ARMS 2013).
Hennes, D., Kaisers, M., & Tuyls, K. (2010). RESQ-learning stochastic games.
Adaptive Learning Agents Workshop AAMAS 2010, p. 8.
Hennes, D., Tuyls, K., & Rauterberg, M. (2008). Formalizing multi-state learning dynamics. Proceedings 2008 IEEE/WIC/ACM International Conference Web
Intelligence Intelligent Agent Technology, pp. 266272. IEEE Computer Society.
Hennes, D., Tuyls, K., & Rauterberg, M. (2009). State-coupled replicator dynamics. Proceedings 8th International Conference Autonomous Agents Multiagent
Systems-Volume 2, pp. 789796. International Foundation Autonomous Agents
Multiagent Systems.
Hofbauer, J., & Sigmund, K. (1998). Evolutionary games population dynamics. Cambridge University Press.
Howell, M. N., Frost, G. P., Gordon, T. J., & Wu, Q. H. (1997). Continuous action reinforcement learning applied vehicle suspension control. Mechatronics, 7 (3), 263276.
Hu, J., & Wellman, M. P. (2003). Nash q-learning general-sum stochastic games.
Journal Machine Learning Research, 4, 10391069.
Kaelbling, L., Littman, M., & Moore, A. (1996). Reinforcement learning: survey. Journal
Artificial Intelligence Research, 4, 237285.
Kaisers, M., & Tuyls, K. (2010). Frequency adjusted multi-agent Q-learning. Proc.
9th Intl. Conf. Autonomous Agents Multiagent Systems (AAMAS 2010), pp.
309315.
Kaisers, M. (2012). Learning Learning - Evolutionary Dynamics Reinforcement
Learning Algorithms Strategic Interactions. Ph.D. thesis, Maastricht University.
Kaisers, M., Bloembergen, D., & Tuyls, K. (2012). common gradient multi-agent reinforcement learning. Proc. 11th Int. Conf. Autonomous Agents Multiagent
Systems (AAMAS 2012), pp. 13931394.
Kaisers, M., & Tuyls, K. (2011). Faq-learning matrix games: Demonstrating convergence
near nash equilibria, bifurcation attractors battle sexes. Workshop
Interactive Decision Theory Game Theory (IDTGT 2011). Assoc.
Advancement Artif. Intel. (AAAI).
Kaisers, M., Tuyls, K., Parsons, S., & Thuijsman, F. (2009). evolutionary model
multi-agent learning varying exploration rate. Proc. 8th Intl. Conf.
Autonomous Agents Multiagent Systems (AAMAS 2009), pp. 12551256. International Foundation Autonomous Agents Multiagent Systems.
Kapetanakis, S., & Kudenko, D. (2002). Reinforcement learning coordination cooperative multi-agent systems. AAAI/IAAI, 2002, 326331.
Kianercy, A., & Galstyan, A. (2012). Dynamics boltzmann Q learning two-player
two-action games. Phys. Rev. E, 85 (4), 041145.
694

fiEvolutionary Dynamics Multi-Agent Learning

Klos, T., Van Ahee, G. J., & Tuyls, K. (2010). Evolutionary dynamics regret minimization. Machine Learning Knowledge Discovery Databases, pp. 8296.
Springer.
Lanctot, M. (2014). developments extensive-form replicator dynamics using
sequence-form representation. Proceedings 2014 international conference
Autonomous agents multi-agent systems, pp. 12571264. International Foundation
Autonomous Agents Multiagent Systems.
Littman, M. L. (1994). Markov games framework multi-agent reinforcement learning.. ICML, Vol. 94, pp. 157163.
Maynard Smith, J., & Price, G. R. (1973). logic animal conflict. Nature, 246 (2),
1518.
Mihaylov, M., Tuyls, K., & Nowe, A. (2014). decentralized approach convention
emergence multi-agent systems. Autonomous Agents Multi-Agent Systems,
28 (5), 749778.
Narendra, K. S., & Thathachar, M. A. L. (1974). Learning automata - survey. IEEE
Transactions Systems, Man, Cybernetics, 4 (4), 323334.
Oechssler, J., & Riedel, F. (2001). Evolutionary dynamics infinite strategy spaces. Economic Theory, 17 (1), 141162.
Panait, L., Tuyls, K., & Luke, S. (2008). Theoretical advantages lenient learners:
evolutionary game theoretic perspective. Journal Machine Learning Research, 9,
423457.
Panait, L., & Luke, S. (2005). Cooperative multi-agent learning: state art.
Autonomous Agents Multi-Agent Systems, 11 (3), 387434.
Panozzo, F., Gatti, N., & Restelli, M. (2014). Evolutionary dynamics Q-learning
sequence form. Twenty-Eighth AAAI Conference Artificial Intelligence, pp.
20342040.
Phelps, S., Parsons, S., & McBurney, P. (2005). evolutionary game-theoretic comparison
two double-auction market designs. Faratin, P., & Rodrguez-Aguilar, J. (Eds.),
Agent-Mediated Electronic Commerce VI. Theories Engineering Distributed
Mechanisms Systems, Vol. 3435 Lecture Notes Computer Science, pp. 101
114. Springer Berlin Heidelberg.
Pipattanasomporn, M., Feroze, H., & Rahman, S. (2009). Multi-agent systems distributed smart grid: Design implementation. Power Systems Conference
Exposition, pp. 18. IEEE.
Ponsen, M., Tuyls, K., Kaisers, M., & Ramon, J. (2009). evolutionary game-theoretic
analysis poker strategies. Entertainment Computing, 1 (1), 3945.
Puterman, M. L. (1994). Markov decision processes: Discrete dynamic stochastic programming. John Wiley & Sons, New York.
Rodrguez, A., Vrancx, P., Grau, R., & Nowe, A. (2012). RL approach commoninterest continuous action games. Proceedings 11th International Conference
695

fiBloembergen, Tuyls, Hennes, & Kaisers

Autonomous Agents Multiagent Systems, pp. 14011402. International Foundation Autonomous Agents Multiagent Systems.
Ruijgrok, M., & Ruijgrok, T. W. (2005). Replicator dynamics mutations games
continuous strategy space. arXiv preprint nlin/0505032.
Santharam, G., Sastry, P. S., & Thathachar, M. A. L. (1994). Continuous action set learning
automata stochastic optimization. Journal Franklin Institute, 331 (5), 607
628.
Schaerf, A., Shoham, Y., & Tennenholtz, M. (1995). Adaptive load balancing: study
multi-agent learning. J. Artif. Intell. Res. (JAIR), 2, 475500.
Shoham, Y., Powers, R., & Grenager, T. (2007). multi-agent learning answer,
question?. Artificial Intelligence, 171 (7), 365377.
Singh, S., Kearns, M., & Mansour, Y. (2000). Nash convergence gradient dynamics
general-sum games. Proceedings Sixteenth conference Uncertainty
artificial intelligence, pp. 541548. Morgan Kaufmann Publishers Inc.
Skyrms, B. (2004). stag hunt evolution social structure. Cambridge University
Press.
Strens, M. (2000). Bayesian framework reinforcement learning. ICML, pp. 943950.
Sutton, R., & Barto, A. (1998). Reinforcement Learning: introduction. MA: MIT Press,
Cambridge.
Hoen, P. J., Tuyls, K., Panait, L., Luke, S., & Poutre, J. A. L. (2005). overview
cooperative competitive multiagent learning. LAMAS, pp. 146.
Tesauro, G. (2003). Extending q-learning general adaptive multi-agent systems..
NIPS, Vol. 4.
Thathachar, M., & Sastry, P. S. (2002). Varieties learning automata: overview. IEEE
Transactions Systems, Man, Cybernetics, Part B: Cybernetics, 32 (6), 711722.
Tuyls, K., Hoen, P. J., & Vanschoenwinkel, B. (2006). evolutionary dynamical analysis multi-agent learning iterated games. Autonomous Agents Multi-Agent
Systems, 12, 115153.
Tuyls, K., Heytens, D., Nowe, A., & Manderick, B. (2003). Extended replicator dynamics
key reinforcement learning multi-agent systems. Machine Learning: ECML
2003, pp. 421431. Springer.
Tuyls, K., & Nowe, A. (2005). Evolutionary game theory multi-agent reinforcement
learning. Knowledge Engineering Review, 20 (01), 6390.
Tuyls, K., & Parsons, S. (2007). evolutionary game theory tells us multiagent
learning. Artificial Intelligence, 171 (7), 406416.
Tuyls, K., Verbeeck, K., & Lenaerts, T. (2003). selection-mutation model q-learning
multi-agent systems. Proc. 2nd Intl. Conf. Autonomous Agents Multiagent Systems (AAMAS 2003), pp. 693700, New York, NY, USA. ACM.
Tuyls, K., & Weiss, G. (2012). Multiagent learning: Basics, challenges, prospects. AI
Magazine, 33 (3), 41.
696

fiEvolutionary Dynamics Multi-Agent Learning

Tuyls, K., & Westra, R. (2009). Replicator dynamics discrete continuous strategy
spaces. Uhrmacher, A. M., & Weyns, D. (Eds.), Multi-Agent Systems: Simulation
Applications, pp. 215240. CRC Press.
Van Kampen, N. (1992). Stochastic Processes Physics Chemistry. Elsevier Science
Publishers, Amsterdam.
Verbeeck, K., Nowe, A., & Tuyls, K. (2005). Coordinated exploration multi-agent reinforcement learning: application load-balancing. AAMAS, pp. 11051106.
Von Neumann, J., & Morgenstern, O. (1944). Theory Games Economic Behavior.
Princeton University Press.
Vrancx, P., Tuyls, K., Westra, R., & Nowe, A. (2008a). Switching dynamics multi-agent
learning. Proc. 7th intl. joint conf. autonomous agents multiagent systems (AAMAS 2008), pp. 307313. International Foundation Autonomous Agents
Multiagent Systems.
Vrancx, P., Verbeeck, K., & Nowe, A. (2008b). Decentralized learning markov games.
Systems, Man, Cybernetics, Part B: Cybernetics, IEEE Transactions on, 38 (4),
976981.
Walsh, W., Das, R., Tesauro, G., & Kephart, J. (2002). Analyzing complex strategic interactions multi-agent systems. AAAI-02 Workshop Game-Theoretic
Decision-Theoretic Agents.
Watkins, C. J. C. H., & Dayan, P. (1992). Q-learning. Machine Learning, 8 (3), 279292.
Weibull, J. W. (1997). Evolutionary game theory. MIT press.
Wheeler Jr, R., & Narendra, K. S. (1986). Decentralized learning finite markov chains.
IEEE Transactions Automatic Control, 31 (6), 519526.
Whiteson, S., & Stone, P. (2006). Evolutionary function approximation reinforcement
learning. Journal Machine Learning Research, 7, 877917.
Wiegand, R. P. (2003). Analysis Cooperative Coevolutionary Algorithms. Ph.D.
thesis, George Mason University.
Wunder, M., Littman, M. L., & Babes, M. (2010). Classes multiagent q-learning dynamics
epsilon-greedy exploration. Proceedings 27th International Conference
Machine Learning (ICML-10), pp. 11671174.
Zinkevich, M. (2003). Online convex programming generalized infinitesimal gradient
ascent. Proc. 20th Intl. Conf. Machine Learning (ICML-2003).

697

fiJournal Artificial Intelligence Research 53 (2015) 745-778

Submitted 02/15; published 08/15

AutoFolio:
Automatically Configured Algorithm Selector
Marius Lindauer

lindauer@cs.uni-freiburg.de

University Freiburg

Holger H. Hoos

hoos@cs.ubc.ca

University British Columbia

Frank Hutter

fh@cs.uni-freiburg.de

University Freiburg

Torsten Schaub

torsten@cs.uni-potsdam.de

University Potsdam
INRIA Rennes

Abstract
Algorithm selection (AS) techniques involve choosing set algorithms
one expected solve given problem instance efficiently substantially
improved state art solving many prominent AI problems, SAT, CSP,
ASP, MAXSAT QBF. Although several procedures introduced,
surprisingly, none dominates others across scenarios. Furthermore,
procedures parameters whose optimal values vary across scenarios. holds
specifically machine learning techniques form core current procedures, hyperparameters. Therefore, successfully apply new problems,
algorithms benchmark sets, two questions need answered: (i) select
approach (ii) set parameters effectively. address problems
simultaneously using automated algorithm configuration. Specifically, demonstrate
automatically configure claspfolio 2, implements large variety
different approaches respective parameters single, highly-parameterized
algorithm framework. approach, dubbed AutoFolio, allows researchers practitioners across broad range applications exploit combined power many different
methods. demonstrate AutoFolio significantly improve performance
claspfolio 2 8 13 scenarios Algorithm Selection Library, leads
new state-of-the-art algorithm selectors 7 scenarios, matches state-ofthe-art performance (statistically) scenarios. Compared best single
algorithm scenario, AutoFolio achieves average speedup factors 1.3
15.4.

1. Introduction
last decade, tremendous progress Boolean constraint solving technology
achieved several areas within AI, SAT (Biere, 2013), ASP (Gebser, Kaufmann,
& Schaub, 2012), CSP (Tamura, Taga, Kitagawa, & Banbara, 2009), Max-SAT (Abrame
& Habet, 2014) QBF (Janota, Klieber, Marques-Silva, & Clarke, 2012).
areas, multiple algorithms complementary solving strategies exist, none dominates others kinds problem instances. fact exploited algorithm selection (AS) (Rice, 1976) methods, use characteristics individual probc
2015
AI Access Foundation. rights reserved.

fiLindauer, Hoos, Hutter, & Schaub

lem instances (so-called instance features) choose promising algorithm instance. Algorithm selectors empirically shown improve state art
solving heterogeneous instance sets and, result, many prizes competitions. instance, SATzilla (Xu, Hutter, Hoos, & Leyton-Brown, 2008) several
categories multiple SAT competitions, claspfolio 1 (Gebser, Kaminski, Kaufmann,
Schaub, Schneider, & Ziller, 2011b) NP-track 2011 ASP Competition, CPHydra (OMahony, Hebrard, Holland, Nugent, & OSullivan, 2008) 2008 CSP
competition, ISAC++ (Ansotegui, Malitsky, & Sellmann, 2014) partial Max-SAT
Crafted Industrial track 2014 Max-SAT Competition, AQME (Pulina &
Tacchella, 2009) first stage main track 2010 QBF Competition.
Although many new approaches proposed years (cf. Smith-Miles,
2008; Kotthoff, 2014), two flexible frameworks allow re-implementing
comparing existing approaches fair uniform way: LLAMA (Kotthoff, 2013)
claspfolio 2 (Hoos, Lindauer, & Schaub, 2014). these, claspfolio 2
comprehensive, encompassing strategies algorithm selection systems 3S (Kadioglu,
Malitsky, Sabharwal, Samulowitz, & Sellmann, 2011), aspeed (Hoos, Kaminski, Lindauer,
& Schaub, 2015), claspfolio 1 (Gebser et al., 2011b), ISAC (Kadioglu, Malitsky, Sellmann, & Tierney, 2010), ME-ASP (Maratea, Pulina, & Ricca, 2014), SNNAP (Collautti,
Malitsky, Mehta, & OSullivan, 2013) SATzilla (Xu et al., 2008; Xu, Hutter, Hoos,
& Leyton-Brown, 2011).
Figure 1 illustrates performance benefits existing selection strategies (as realized claspfolio 2) yield across wide range benchmarks Algorithm Selection Library (Bischl et al., 2015b, 2015a). observe approach strengths
weaknesses different scenarios. SATzilla11-like approach (the default
claspfolio 2) performs best overall, achieves better performance
approaches considered 8 13 scenarios, 3S, aspeed ISAC yielding
better performance remaining cases.
note selection approaches used fixed default parameter
configuration might therefore fall short full performance potential. example, imputation missing instance features used approaches considered Figure 1; use improve performance scenarios (e.g.,
ASP-POTASSCO), yields improvements others (e.g., SAT12-RAND,
SATzilla11-like approach plus mean imputation outperforms single best algorithm
factor 1.2).
Generally, well known performance many machine learning techniques
depends hyper-parameter settings (e.g., case SVM, kernel, kernel hyperparameter soft margin; cf. Bergstra, Bardenet, Bengio, & Kegl, 2011; Snoek, Larochelle,
& Adams, 2012; Thornton, Hutter, Hoos, & Leyton-Brown, 2013). However, hyperparameters machine learning models used Figure 1 fixed manually, based
limited experiments. Therefore, performance algorithm selection systems
considered could likely improved using carefully chosen hyper-parameter
settings.
Facing new algorithm selection problem, thus answer three salient questions: (i) selection approach use; (ii) set parameters selection
approach (and underlying machine learning model) effectively; (iii) make
746

filio
-1.
0-l
ISA
ike
C-l
ike

-AS
P-l
ike
SA
Tzi
lla
'09
-lik
SA
e
Tzi
lla
'11
-lik
Au
e
toF
oli


cla

sp
fo


asp

ee

3S

-lik

e

AutoFolio: Automatically Configured Algorithm Selector

ASP-POTASSCO
CSP-2010
MAXSAT12-PMS
PREMARSHALLING
PROTEUS-2014
QBF-2011
SAT11-HAND
SAT11-INDU
SAT11-RAND
SAT12-ALL
SAT12-HAND
SAT12-INDU
SAT12-RAND

4.1
1.5
6.5
2.9
10.9
7.7
2.6
1.2
3.9
1.5
1.7
1.2
0.8

1.4
1.0
2.7
3.6
6.3
4.9
3.6
1.1
4.7
1.1
1.8
0.8
0.8

2.8
2.1
1.6
1.2
3.5
2.3
1.1
1.2
1.2
1.2
1.1
1.2
0.6

3.8
2.1
4.9
1.3
4.3
2.8
1.2
1.3
2.5
1.1
1.1
1.2
0.9

1.9
2.6
2.1
1.1
3.1
2.8
1.0
1.2
1.8
1.1
1.0
1.1
0.9

2.9
2.5
3.4
1.5
4.9
3.7
1.9
1.1
2.6
1.4
1.5
1.3
0.9

4.2
3.1
8.6
2.3
6.5
9.8
2.3
1.2
3.8
1.8
1.9
1.3
0.9

4.2
3.2
8.6
3.5
7.8
10.1
3.2
1.5
15.4
3.0
3.2
1.8
1.3

geo. mean

2.6

2.0

1.5

1.9

1.5

2.0

2.8

3.9

Figure 1: Factors selection approach re-implemented claspfolio 2 outperformed single best algorithm 13 ASlib scenarios w.r.t. penalized average runtime
(PAR10, counts timeout 10 times given runtime cutoff). results
10-fold cross-validation, ignoring test instances solved solver.
last row shows geometric mean 13 scenarios.

best use techniques augmenting pure AS, pre-solving schedules (Xu et al., 2008;
Kadioglu et al., 2011). Instead common, manual trial-and-error approach, propose automatically answer questions using automated algorithm configuration
methods (Hutter, Hoos, Leyton-Brown, & Stutzle, 2009) configure flexible frameworks. manual approach error-prone, potentially biased requires substantial human expert time knowledge, approach introduce fully automatic,
unbiased, leverages full power broad range methods. thus facilitates
easier effective use algorithm selection makes techniques accessible
broader community.
Specifically, present AutoFolio, general approach automatically determining
strong algorithm selection method particular dataset, using algorithm configuration
search flexible design space algorithm selection methods. also provide
open-source implementation AutoFolio (www.ml4aad.org/autofolio/) based
algorithm configurator SMAC (Hutter, Hoos, & Leyton-Brown, 2011) algorithm
selection framework claspfolio 2 (Hoos et al., 2014). last column Figure 1 previews
results obtained AutoFolio clearly shows significant improvements
claspfolio 2 10 13 scenarios ASlib.
747

fiLindauer, Hoos, Hutter, & Schaub

Instance

Algorithm
Portfolio

Compute
Features

Select Algorithm

Solve Instance
Algorithm

Figure 2: General outline algorithm selection.

2. Background: Algorithm Configuration Selection
section, briefly introduce standard approaches algorithm selection algorithm configuration form basis AutoFolio approach.
2.1 Algorithm Selection
Figure 2 shows general outline algorithm selection (Rice, 1976). given problem
instance, first compute cheap instance features; numerical characteristics,
including simple ones (such number variables clauses SAT instance)
complex ones (such statistics gathered short probing runs actual SAT
solver given instance). Based features, appropriate algorithm
algorithm portfolio (Huberman, Lukose, & Hogg, 1997; Gomes & Selman, 2001) selected
solve given instance. overall workflow subject runtime cutoff.
One major challenge algorithm selection find good mapping instance
features algorithms. general offline algorithm selection approach consider,
done based training data. Specifically, given portfolio algorithms set
problem instances I, use training data performance matrix size #I #A
feature matrix containing fixed-size feature vector I. Based training
data, learn mapping instance features algorithms using machine learning
techniques, k-NN (Maratea et al., 2014), g-means (Kadioglu et al., 2010) random
forests (Xu et al., 2011).
2.1.1 Related Work Algorithm Selection Systems
Recent successful algorithm selection systems include SATzilla (Xu et al., 2008; Xu, Hutter, Hoos, & Leyton-Brown, 2012a), 3S (Kadioglu et al., 2011; Malitsky, Sabharwal, Samulowitz, & Sellmann, 2012, 2013b), ISAC (Kadioglu et al., 2010; Ansotegui et al., 2014),
CSHC (Malitsky, Sabharwal, Samulowitz, & Sellmann, 2013a) claspfolio 1 (Gebser
et al., 2011b). recent years, systems showed excellent performance competitions
SAT, MAXSAT ASP. briefly review following.
original version pioneering algorithm selection system SATzilla (Xu et al.,
2008) learned mapping instance features algorithms training ridge regression models. regression model predicts performance algorithm given
instance. Based predicted performances, SATzilla selects algorithm
best predicted performance. SATzillas latest version (Xu et al., 2011) uses classification
models that, pair algorithms, predict better-performing one, selects
algorithm run using simple voting predictions thus obtained. models
also cost-sensitive, is, training instance pairwise classification models
748

fiAutoFolio: Automatically Configured Algorithm Selector

weighted performance loss incurred selecting worse two algorithms.
Furthermore, SATzilla introduced concept pre-solving schedules, is, short
instance-independent schedule algorithms running limited amount time. one
algorithm pre-solving schedule solves given instance, SATzilla immediately
terminate successfully, saving time required compute instance features. Furthermore,
pre-solving schedules increase robustness algorithm selectors relying
one selected algorithm also pre-solvers solve given instance. One drawback
SATzilla use grid search possible pre-solving schedules three
pre-solvers; schedule considered, SATzilla performs algorithm subset selection
trains classification models, require substantial amounts time (in
experiments, 4 CPU days).
3S (Kadioglu et al., 2011; Malitsky et al., 2012, 2013b) uses k-nearest neighbour
approach select algorithm. given problem instance solved, determines
set similar training instances instance feature space selects algorithm
best performance instance set. performance k-NN approach
improved distance-based weighting (that is, weighting algorithm performance
instance instances distance new given instance) using clusteringbased adaptive neighbourhood size (to adjust size neighbourhood different
areas feature space). Furthermore, 3S uses mixed integer programming compute
pre-solving schedules efficiently SATzilla.
ISAC (Kadioglu et al., 2010) clusters instances instance feature space using
g-means algorithm stores cluster centre well best-performing algorithm
cluster. new problem instance, determines nearest cluster centre
(1-NN) selects algorithm associated it.
cost-sensitive hierarchical clustering system CSHC (Malitsky et al., 2013a) also
partitions feature space clusters, instead ISACs unsupervised clustering
approach, creates partitioning supervised top-down fashion, much like decision
regression tree algorithm. Starting instances (the entire feature space)
root tree, recursively splits instances associated node two child
nodes, choosing split along single feature value, performance
best-performing algorithm child node optimized. cost-sensitive supervised
approach based trees closely resembles cost-sensitive random forests SATzilla,
difference that, contrast SATzillas pairwise voting approach, builds
single model.
Last least, claspfolio 1 (Gebser et al., 2011b) predecessor claspfolio 2, use (and describe Section 2.1.2). contrast flexible framework claspfolio 2, claspfolio 1 inspired earlier version SATzilla
uses regression approach, different machine learning method (support
vector regression instead ridge regression).
systems algorithm selection combine extend techniques, example, combining regression clustering approaches (Collautti et al., 2013),
selecting algorithm portfolios (Yun & Epstein, 2012; Lindauer, Hoos, & Hutter, 2015a)
schedules (Amadini, Gabbrielli, & Mauro, 2014) instead single algorithm. additional information, refer interested reader two recent surveys algorithm
selection (Smith-Miles, 2008; Kotthoff, 2014).
749

fiLindauer, Hoos, Hutter, & Schaub

Feature
Generator

Training Instances

Algorithms

Instance Features
Groups

Algorithm
Performance
ASlib Scenario

Feature
Preprocessing

Performance
Preprocessing
Train
Selection Model(s)



Performance Estimation

Pre-Solving Schedule
aspeed

Selection

Scheduling
Offline Training

(Test) Instance

Compute Features

Select Algorithm

failed
Run Backup
Algorithm

Run Pre-Solving
Schedule
successful
Run Selected
Algorithm
Online Solving

Figure 3: General workflow claspfolio 2. Objects algorithms instances
shown rectangles, activities depicted rectangles rounded corners.
Activities related algorithm selection shown red activities related algorithm
schedules yellow.
2.1.2 Algorithm Selection Framework claspfolio 2
explain algorithm selection framework claspfolio 2 (Hoos et al., 2014; Lindauer, Hoos, & Schaub, 2015c) detail, since provides basis
concrete implementation general AutoFolio approach, used experiments.
claspfolio 2 framework implements idea algorithm selection flexible
general way. provides general view individual components algorithm
selectors, based implements many different selection approaches associated
techniques. Therefore, claspfolio 2 natural candidate serve basis
AutoFolio approach.
Figure 3 shows workflow claspfolio 2, divided ASlib Scenario
input claspfolio 2; Offline Training Selection Scheduling; Online Solving
new instance:
ASlib scenario. input, claspfolio 2 reads algorithm selection scenario, supporting format Algorithm Selection library, ASlib. consists
performance matrix, instance features, groups instance features1 optional information, cross-validation splits ground truth problem
1. note that, according definition ASlib, feature group enables list instance features
computed common block feature computation code, jointly incur cost
running code.

750

fiAutoFolio: Automatically Configured Algorithm Selector

instances (for example, whether SAT instance satisfiable unsatisfiable).
full specification ASlib format, refer interested reader aslib.net.
Offline training selection. Based given scenario (training) data, claspfolio 2
pre-processes instance features (for example, normalization feature imputation)
performance data (for example, log-transformation). Using machine learning
techniques, claspfolio 2 learns selection model maps instance features
algorithms.
Offline training scheduling. compute efficient pre-solving schedule, claspfolio 2 first estimates performance Selection module using internal
cross-validation training data (Arrow I). Based performance estimation,
claspfolio 2 computes timeout-minimal pre-solving schedule using Answer Set
Programming aspeed (Hoos et al., 2015), assigning algorithm (potentially
zero-length) time slice overall runtime budget. estimation Selection
module necessary compute runtime budget pre-solving schedule.
Selection module performs well, pre-solving schedule may empty,
pre-solving schedule cannot perform better perfect predictor (that is, predictor always selects best solver). contrast, prediction performs
poorly (for example, result non-informative instance features), pre-solving
schedule may allocated complete time budget, Selection module
ignored.
Online solving. Solving workflow follows: feature generator computes
instance features new problem instance solved; computation fails
(for example, time memory constraints) feature imputation
strategy selected, backup solver i.e., single best performing solver
offline training run instance; otherwise, previously trained selection
model uses instance features select algorithm expected perform well.
pre-solving schedule available, schedule runs either instance feature
computation selection algorithm, depending parameter setting
claspfolio 2 latter version shown Figure 3. former
advantage time compute instance features saved instance
solved pre-solving. latter advantage algorithm chosen
selector removed pre-solving schedule prevent running twice.
list techniques implemented modules given Section 3.2.
2.2 Algorithm Configuration
Figure 4 shows general outline algorithm configuration methods. Given parameterized algorithm possible parameter settings C, set training problem instances
I, performance metric : C R, objective algorithm configuration
problem find parameter configuration c C minimizes across instances
I. Prominent examples performance metric optimized runtime,
solution quality, misclassification cost target algorithm achieves. configuration
751

fiLindauer, Hoos, Hutter, & Schaub

Instances

Algorithm
Configuration Space C

Select c C

Assess A(c)
0

Returns
Best Found
Configuration c

Return Performance
Configuration Task

Figure 4: General outline algorithm configuration.
procedure (or short configurator ) iteratively evaluates performance parameter configurations c C (by running one instances I) uses
result decide next configurations evaluate. given budget configuration process exhausted, configurator returns best known parameter
configuration found then.
n parameters p1 , . . . , pn , respective domains D1 , . . . , Dn , parameter
configuration space C = D1 Dn cross-product domains,
parameter configuration c C assigns value parameter. several types
parameters, including real-valued, integer-valued categorical ones (which finite,
unordered domain; example, choice different machine learning algorithms).
Furthermore, configuration spaces structured; specifically, parameter pi
conditional another parameter pj , value pi relevant parent
parameter pj set specific value. example, case pj categorical
choice machine learning algorithms, pi sub-parameter one
algorithms; pi active pj chooses algorithm parameterizes further.
date, four general configuration procedures: ParamILS (Hutter et al.,
2009), GGA (Ansotegui, Sellmann, & Tierney, 2009), irace (Lopez-Ibanez, Dubois-Lacoste,
Stutzle, & Birattari, 2011), SMAC (Hutter et al., 2011). principle, could use
configurator general AutoFolio approach. practice,
found SMAC often yield better results ParamILS GGA (Hutter et al., 2011;
Hutter, Lindauer, Balint, Bayless, Hoos, & Leyton-Brown, 2015; Lindauer, Hoos, Hutter, &
Schaub, 2015b), thus use basis concrete implementation AutoFolio
discussed following. describe SMAC detail.
2.2.1 SMAC: Sequential Model-Based Algorithm Configuration
sequential model-based algorithm configuration method SMAC (Hutter et al., 2011;
Hutter, Hoos, & Leyton-Brown, 2015a) uses regression models approximate performance metric : C R (Hutter, Xu, Hoos, & Leyton-Brown, 2014). follows
general algorithm configuration workflow above, alternating evaluations
parameter configurations instances decision phases, configurator uses
data gathered far select configurations evaluate next instances.
SMACs decision phases involve constructing regression model : C R based
data observed far, using model (as well models uncertainty
predictions) select promising configurations try next. step automatically
752

fiAutoFolio: Automatically Configured Algorithm Selector

trades exploration (evaluating regions configuration space model
uncertain) exploitation (evaluating configurations predicted perform well).
order save time evaluating new configurations cnew C, SMAC first evaluates
single instance I; additional evaluations carried (using doubling
schedule) if, based evaluations date, cnew appears outperform SMACs best
known configuration c. evaluated number runs cnew c,
cnew still performs better, SMAC updates best known configuration c cnew .
2.2.2 Previous Applications Algorithm Configuration
Algorithm configuration demonstrated effective optimizing algorithms wide range problems, including SAT-based formal verification (Hutter, Babic,
Hoos, & Hu, 2007), timetabling (Chiarandini, Fawcett, & Hoos, 2008), multi-objective optimization (Lopez-Ibanez & Stutzle, 2010), mixed integer programming (Hutter, Hoos, &
Leyton-Brown, 2010), AI planning (Vallati, Fawcett, Gerevini, Hoos, & Saetti, 2013), generation heuristics (Mascia, Lopez-Ibanez, Dubois-Lacoste, & Stutzle, 2014), occupancy
scheduling (Lim, van den Briel, Thiebaux, Backhaus, & Bent, 2015) kidney exchange
matching (Dickerson & Sandholm, 2015). important special case algorithm configuration hyperparameter optimization machine learning (Bergstra et al., 2011; Snoek
et al., 2012; Eggensperger et al., 2013).
previous line work related application configuration algorithm
selection Auto-WEKA (Thornton et al., 2013). Auto-WEKA addresses combined
problem selecting machine learning algorithm WEKA framework (Hall, Frank,
Holmes, Pfahringer, Reutemann, & Witten, 2009) optimizing hyperparameters.
AutoFolio also needs solve combined algorithm selection hyperparameter
optimization problem, particular needs problem formulations
considers: regression, classification clustering. important design choices
AutoFolio pre-solving parameters, well instance features use.
AutoFolio applies one meta-solving strategy (algorithm configuration) another one
(algorithm selection). previous application meta-solving strategy selfconfiguration ParamILS (Hutter et al., 2009). However, case, self-configuration
yielded modest improvement default configuration ParamILS, whereas
here, achieve substantial improvements default configuration claspfolio 2.
Algorithm configuration algorithm selection previously combined
different way, using configuration find good parameter settings highly parameterized algorithm, using selection choose per-instance
basis. Two systems implement approach date: ISAC (Kadioglu et al., 2010)
Hydra (Xu, Hoos, & Leyton-Brown, 2010). ISAC first clusters training problem instances
homogeneous subsets, uses configurator find good solver parameterization
cluster, uses selector choose parameterizations. Hydra
iteratively adds new solver parameterizations initially empty portfolio-based selector,
step tasking configurator find solver parameterization improves
current portfolio.
753

fiLindauer, Hoos, Hutter, & Schaub

Training Data

Test Data

10-fold cross-validation = 10 meta instances

Figure 5: Split instance sets algorithm selection scenarios; cross-validation performed
inside configuration process, test set withheld evaluating configured selector.

3. Configuration Algorithm Selectors
present AutoFolio approach using algorithm configurators automatically
customize flexible algorithm selection (AS) frameworks specific scenarios. apply
algorithm configuration context, need specify parameterized selector
configuration space, well performance metric judge performance.
3.1 Formal Problem Statement
judge performance algorithm selection (AS) system scenario,
crucial partition given set problem instances training test set, use
system training set train selector s, evaluate test
set instances. (If training set instead used evaluate performance, perfect
system could simply memorize best solver instance without learning anything
useful new problem instances). standard notion training-test split
machine learning.
scenario includes algorithms A, problem instances I, performance feature
data D, loss function l : R minimized (for example, algorithms
runtime solution cost), data split disjoint sets Dtrain Dtest . Let
S(Dtrain ) : denote selector learned system trained data
Dtrain . Then, performance S, P (S) average performance algorithms
selects instances test data set Dtest :
P (S) =

X
1

l(S(Dtrain ), i).
|Dtest |

(1)

iDtest

Likewise, evaluate performance system Sc parameterized
configuration c P (Sc ). However, perform algorithm configuration simply
minimizing P (Sc ) respect c C: would amount peeking test set
many times, even though would yield configuration c low P (Sc ), could
expected perform well instances contained Dtest . Instead, order
obtain unbiased evaluation configured selectors performance end, need
hold back test set instances touched configuration process.
order still able optimize parameters without access test set, standard
solution machine learning partition training set further, k cross-validation
folds. Overall, use instance set selection scenario illustrated Figure 5:
(i) split full set instances training test set (ii) training data
754

fiAutoFolio: Automatically Configured Algorithm Selector

Algorithm 1: AutoFolio: Automated configuration algorithm selector
Input : algorithm configurator AC, algorithm selector S, configuration space C
S, training data algorithm scenario (with performance feature
matrix), number folds k

5

randomly split D(1) , . . . , D(k)
start AC D(1) , . . . , D(k) meta instances, using average loss across
meta-instances performance metric m, using target algorithm
configuration space C
configuration budget remaining
AC selects configuration c C meta instance n {1 . . . k}
train Sc D\D(n) , assess loss D(n) return loss AC

6

return best configuration c found AC

1
2

3
4

partitioned k folds (in experiments, use k = 10), used
follows.
(1)
(k)
Let Dtrain , . . . , Dtrain random partition training set Dtrain . crossvalidation performance CV (Sc ) Sc training set then:


k
X
X
1
1


(j)
CV (Sc ) =
l(Sc (Dtrain \Dtrain ), i)
(2)
(j)
k
|Dtrain |
(j)
j=1
iDtrain

end, optimize performance CV (Sc ) determining configuration c C
selector good cross-validation performance
c arg min CV (Sc ),

(3)

cC

evaluate c training selector Sc entire training data evaluating
P (Sc ) Dtest , defined Equation 1.
(j)
Following Thornton et al. (2013), use k folds Dtrain one instance within
configuration process. order avoid confusion instances
base-level problem instances (e.g., SAT instances) solved inside instance,
refer instance meta-instance. note many configurators, FocusedILS (Hutter et al., 2009), irace (Lopez-Ibanez et al., 2011) SMAC (Hutter et al.,
2011), discard configurations perform poorly subset meta-instances
therefore evaluate k cross-validation folds every configuration.
saves time lets us evaluate configurations within configuration
budget. Based considerations, Algorithm 1 outlines process configure
algorithm selector AutoFolio.
Since instances scenario could split configuration testing sets
many different ways, one split necessarily yield representative performance
estimate. Therefore, yield confident results evaluation, perform additional outer cross-validation (as given ASlib scenario) instead single training-test
755

fiLindauer, Hoos, Hutter, & Schaub

split. is, consider multiple training-test splits, configure selector training set, assess final configurations respective test data sets, average results.
note, however, practical application AS, one would single training set (which would still split k cross-validation splits internally) single test
set.
3.2 Configuration Space Selectors
existing algorithm selectors implement one specific algorithm selection approach, using
one specific machine learning technique. note, however, selection approaches,
least implicitly, admit flexibility, particular could used range
machine learning techniques. example, SATzilla11 (Xu et al., 2011) uses voting
pairwise performance predictions obtained cost-sensitive random forest classifiers, but,
principle, could use cost-sensitive binary classifiers instead random forests.
Based observation, consider hierarchically structured configuration space
top-level parameter determines overall algorithm selection approach
example, regression approach, used SATzilla09 (Xu et al., 2008) k-NN
approach, used ME-ASP (Maratea et al., 2014). selection approaches,
choose different regression techniques, example, ridge regression, lasso
regression, support vector regression random forest regression. machine
learning techniques configured (hyper-)parameters.
Besides selection approach, techniques used preprocessing training data (for example, z-score feature normalization feature preprocessing step
log-transformation runtime data performance preprocessing step). Preprocessing
techniques configured independently selection approach, therefore
also handled top-level parameters.
use third group parameters control pre-solving schedules (Kadioglu et al.,
2011; Xu et al., 2011), including parameters determine time budget pre-solving
number pre-solvers considered. Pre-solving techniques freely combined
selection approaches; always needed, added top-level binary
parameter completely activates deactivates use pre-solvers; presolving parameters conditional switch.
implemented choices claspfolio 2 system described Section 2.1.2.
Figure 6 illustrates complete configuration space thus obtained. current version,
use concrete implementation AutoFolio approach, covers six
different algorithm selection approaches:
(hierarchical) regression (inspired SATzilla09; Xu et al., 2008) learns regression
model algorithm; new instace, selects algorithm best
predicted performance;
multiclass classification (inspired LLAMA; Kotthoff, 2013) learns classification
model directly selects algorithm based features new instance;
pairwise classification (inspired SATzilla11; Xu et al., 2011) learns (cost-sensitive)
classification model pairs algorithms; new instance, evaluates models selects algorithm votes;
756

fiAutoFolio: Automatically Configured Algorithm Selector

transformation

pre-solving

yes

instance
weighting

contribution
filtering

normalization

approach

imputation

p : PCA

Performance Preprocessing

max_feature_time

Feature Preprocessing

4
multi-class
classification

pairwise
classification

c (SVM)
gamma(SVM)

(hierarchical)
regression

clustering

SNNAP

k : k-NN

max cluste r

k
best_n

random
forest

SVM

gradient
boosting

random
forest

SVM

gradient
boosting

ridge

lasso

SVR

random
forest

ridge

lasso

SVR

random
forest

3

2

3

3

2

3

1

1

3

2

1

1

3

2

k-means

Gaussian
mixture

spectral
clustering

Figure 6: Configuration space claspfolio 2, including 22 categorial parameters, 15
integer valued parameters 17 continous parameters. Parameters double boxes
top-level parameters; single boxes represent algorithm selection approaches based classes
machine learning techniques, dashed boxes machine learning techniques dotted boxes
indicate number low-level parameters. Parameter boxes used default configuration filled grey.
clustering (inspired ISAC; Kadioglu et al., 2010) determines subsets similar training
instances feature space best algorithm subsets; new
instance, determines nearest cluster center selects associated algorithm;
k-NN (inspired 3S; Kadioglu et al., 2011, ME-ASP; Maratea et al., 2014) determines set similar training instances feature space given new instance
selects algorithm best performance instance set;
SNNAP (inspired Collautti et al., 2013) predicts performance algorithm
regression models uses information k-NN approach predicted
performance space.
approaches, claspfolio 2 covers least three different machine
learning techniques (where appropriate). listed Figure 6; example, pairwise
classification based random forests, SVMs gradient boosting (with 3, 2 3
hyper-parameters, respectively). preprocessing strategies, supports:
Performance preprocessing:
transformation applies log (Xu et al., 2008) z-score normalization (Collautti
et al., 2013) performance data;
instance weighting weights instances impact performance
algorithm selector, is, instances get low weight available algorithms perform equally, high weight algorithms differ substantially
performance (Kotthoff, Gent, & Miguel, 2012);
contribution filtering removes algorithms less specified contribution performance oracle (also known virtual best solver) (Xu
et al., 2012a); form algorithm subset selection.

757

fiLindauer, Hoos, Hutter, & Schaub

Feature preprocessing:
normalization transforms instance features min-max, z-score, decimalpoint, log scheme application PCA;
p:PCA applies principal component analysis features selects top p
principal components, p parameter (if PCA activated);
imputation fills missing feature values median, average frequent
value feature imputation deactivated feature vector incomplete
given instance, single best solver statically selected;
max feature time limits amount time spent collect features ensures
much time spent feature computation; however, result
incomplete features missing values (which get imputed imputation
active).
chose default configuration claspfolio 2 (used initialize algorithm
configurator) SATzilla11-like configuration, since shown effective
SAT (Xu et al., 2012a) ASP (Hoos et al., 2014), since overall high performance
evident results Figure 1. configuration uses pairwise cost-sensitive random
forest classifiers, z-score feature normalization pre-solving schedule three
pre-solvers. Since assume prior knowledge algorithm selection scenarios,
default configuration uses default instance features defined scenario designers.
chose claspfolio 2 basis AutoFolio, designed
flexible known perform well.2 note principle, selectors,
SATzilla (Xu et al., 2008), ISAC (Kadioglu et al., 2010), SNNAP (Collautti et al.,
2013) LLAMA (Kotthoff, 2013), could generalized similar way.
addition using claspfolio 2 algorithm selection framework, current
version AutoFolio employs algorithm configurator SMAC (described Section
2.2.1). Like selection framework, configurator also exchangeable: chose
SMAC, performed best across algorithm configuration problems studied
far, principle, configurators could also used, as, GGA (Ansotegui et al.,
2009) irace (Lopez-Ibanez et al., 2011). Preliminary results (Lindauer et al., 2015b)
showed ParamILS also optimize performance claspfolio 2,
inferior SMAC one scenario, performance advantage small.

4. Empirical Performance Analysis
section, empirically analyze performance AutoFolio approach.
experiments, AutoFolio employs claspfolio 2 using well-known machine learning package scikit-learn (Pedregosa et al., 2011) (version 0.14.1) algorithm configurator SMAC (version 2.08.00). ran AutoFolio thirteen algorithm selection
scenarios make Algorithm Selection Library 1.0 (Bischl et al., 2015b).3
2. Results performance claspfolio 2 compared state-of-the-art algorithm selectors
found aslib.net.
3. note experiments ASlib scenarios, claspfolio 2 algorithm selectors
need perform actual runs algorithms feature generators, ASlib scenarios already

758

fiAutoFolio: Automatically Configured Algorithm Selector

shown Table 1, scenarios comprise wide variety hard combinatorial
problems; includes performance data range solvers (between 2
31) set instances, instance features organized feature groups associated
costs. scenarios consider here, performance objective runtime minimization.
high level, scenarios comprise following data:
ASP-POTASSCO: runtimes different parameter configurations ASP solver
clasp broad range ASP instances collected Potassco group (Gebser,
Kaminski, Kaufmann, Ostrowski, Schaub, & Schneider, 2011a);
CSP-2010: runtimes single solver two different configurations (with
without lazy learning; Gent, Jefferson, Kotthoff, Miguel, Moore, Nightingale, & Petrie,
2010) collection CSP instances;
MAXSAT12-PMS: runtime data 2012 MaxSAT Evaluation;
PREMARSHALLING: runtimes -based IDA -based solvers premarshalling problem, real-world, time-sensitive pre-marshalling problem instances
operations research literature;
PROTEUS-2014: runtimes different CSP SAT solvers range CSP
instances, preprocessed various CSP-to-SAT translation techniques;
QBF-2011: runtime data QBF solvers AQME system (Pulina &
Tacchella, 2009) QBF instances 2010 QBF Solver Evaluation;
SAT11-HAND, SAT11-INDU SAT11-RAND: runtime data respective tracks 2011 SAT Competition;
SAT12-ALL, SAT12-HAND, SAT12-INDU SAT12-RAND: runtimes various SAT solvers broad range SAT instances used train algorithm
selection system SATzilla (Xu, Hutter, Shen, Hoos, & Leyton-Brown, 2012b)
respective tracks 2012 SAT Challenge.
refer Bischl et al. (2015b) details scenarios, including baseline
experiments showing algorithm selection applied effectively scenarios. point using common library allows us compare AutoFolio
fair uniform way algorithm selection methods. However, price pay
uniform comparison necessarily consider current state-of-the-art
algorithms solving respective problems, since ASlib data collected
several years ago. Furthermore, note current version ASlib consists
deterministic performance data. expect future versions also consider scenarios stochastic performance data multiple runs per algorithm instance, using
different pseudo-random number seeds. AutoFolio applied stochastic scenarios straightforward manner, optimizing mean performance across runs
instance
contain necessary performance data feature vectors (in order allow fair comparison
algorithm selectors based data, without confounding factor due hardware platform
used run experiments).

759

fiLindauer, Hoos, Hutter, & Schaub

Scenario
ASP-POTASSCO
CSP-2010
MAXSAT12-PMS
PREMARSHALLING
PROTEUS-2014
QBF-2011
SAT11-HAND
SAT11-INDU
SAT11-RAND
SAT12-ALL
SAT12-HAND
SAT12-INDU
SAT12-RAND

#I
1294
2024
876
527
4021
1368
296
300
600
1614
767
1167
1362

#U #A #f #fg
82
253
129
0
428
314
77
47
108
20
229
209
322

11
2
6
4
22
5
15
18
9
31
31
31
31

138
86
37
16
198
46
115
115
115
115
115
115
115

4
1
1
1
4
1
10
10
10
10
10
10
10

tc
600
5000
2100
3600
3600
3600
5000
5000
5000
1200
1200
1200
1200

Reference
(Hoos et al., 2014)
(Gent et al., 2010)
(Malitsky et al., 2013)
(Tierney & Malitsky, 2015)
(Hurley et al., 2014)
(Pulina & Tacchella, 2009)
(Xu et al., 2008)
(Xu et al., 2008)
(Xu et al., 2008)
(Xu et al., 2012b)
(Xu et al., 2012b)
(Xu et al., 2012b)
(Xu et al., 2012b)

Table 1: Overview algorithm selection scenarios Algorithm Selection Library,
showing number instances #I, number unsolvable instances #U (U I), number
algorithms #A, number features #f , number feature groups #fg , cutoff time tc
literature reference.

4.1 Algorithm Configuration Setup
Following standard practice (Hutter et al., 2009), performed multiple (in case, 12)
independent runs algorithm configurator SMAC scenario selected
configuration claspfolio 2 best performance training data. configurator run allocated total time budget 2 CPU days. single run claspfolio 2
limited 1 CPU hour, using runsolver tool (Roussel, 2011). performance
metric, used penalized average runtime penalty factor 10 (PAR10), counts
timeout 10 times given runtime cutoff (runtime cutoffs differ ASlib
scenarios). study optimization PAR10 influenced metrics,
number timeouts. time required evaluate single configuration claspfolio 2 varied 10 CPU seconds 1 CPU hour reference machine (see
below), mostly depending difficulty optimizing pre-solving schedules.
obtain robust estimate AutoFolios performance, used 10-fold outer crossvalidation given specific ASlib scenarios, is, configured claspfolio 2 ten
times scenario (with different training-test splits). Therefore, total, performed
12 10 = 120 configuration runs 2 CPU days three different configuration spaces
(see Section 4.2) thirteen ASlib benchmarks, requiring total 9 360
CPU days (25 CPU years). note although thorough evaluation AutoFolio
required substantial amounts computation, applying single benchmark set
given training-test split would require 12 independent configuration runs two
days could thus performed weekend modern desktop machine.
Furthermore, applying AutoFolio new algorithm selection benchmark set cheap
comparison collecting data new benchmark set. instance, collect
760

fiAutoFolio: Automatically Configured Algorithm Selector

AutoFoliovote
AutoFolio
AutoFolioext

categorical

integer

real

conditionals

configurations

18 28
28 38
47 247

7
15
15

3
15
15

14
44
44

1 106 6 108
3 1011 2 1014
2 1017 2 1077

Table 2: Overview configuration spaces number categorical, integer-valued
real-valued parameters, number conditionals, estimation number
configurations ignoring real-valued parameters. number categorical values
varies scenarios depending number algorithms, features feature
groups.
algorithm performance data ASlib scenarios required 25.7 CPU days
(ASP-POTASSCO) 596.7 CPU days (PROTEUS-2014), average 212.3
CPU days (9 times much configuration budget AutoFolio).
performed experiments bwUniCluster Karlsruhe, whose machines
equipped two Octa-Core Intel Xeon E5-2670 (2.6 GHz, 20 MB cache) CPUs
64 GB RAM each, running Hat Enterprise Linux 6.4. note, however, runtimes
selected algorithms feature computations part ASlib scenarios
depend hardware used.
4.2 Different Configuration Spaces
mentioned earlier, AutoFolio used optimize performance single approach algorithm selectors, SATzilla, multi-approach selectors, LLAMA
claspfolio 2, much larger configuration spaces (see Figure 6). Therefore, studied three different parameter spaces AutoFolio based claspfolio 2:
AutoFolio considers configuration space described Section 3.2 additionally
adds binary parameters enable disable feature groups4 defined
specific algorithm selection scenario. Algorithm subset selection done using
heuristic based marginal contribution algorithm oracle performance;
AutoFoliovote considers subset configuration space AutoFolio,
fixes algorithm selection approach pairwise classification voting scheme;
AutoFolioext considers configuration space AutoFolio, instead parameters feature group, added binary parameters instance feature
selectable algorithm. increases number parameters substantially example, adds 220 additional parameters PROTEUS-2014
scenario.

4. selected feature groups result empty feature set, claspfolio 2 statically select single
best algorithm training data.

761

fiLindauer, Hoos, Hutter, & Schaub

Scenario
ASP-POTASSCO
CSP-2010
MAXSAT12-PMS
PREMARSHALLING
PROTEUS-2014
QBF-2011
SAT11-HAND
SAT11-INDU
SAT11-RAND
SAT12-ALL
SAT12-HAND
SAT12-INDU
SAT12-RAND

Default
PAR10 #TOs
124.8
384.7
264.0
2513.8
3274.2
1068.4
7093.2
7851.2
3684.0
2087.0
2081.2
1019.8
708.2

19
10
7
33
321
26
29
37
34
261
86
69
52

AutoFoliovote
PAR10
#TOs
119.8
329.7
135.7
1953.6
1274.0
866.6
5781.4
6616.5
1441.9
890.4
1079.5
682.9
391.6

18
8
3
24
110
19
23
31
12
102
43
44
29

AutoFolio
PAR10
#TOs
125.0
355.1
246.3
2005.1
1379.2
910.2
5552.8
5932.3
967.4
979.1
1212.3
774.6
440.8

19
9
7
25
117
21
22
27
7
115
49
52
33

AutoFolioext
PAR10
#TOs
152.7
358.1
268.2
1922.5
3102.7
946.9
8085.8
7671.3
1301.7
1077.0
1285.5
990.7
543.1

25
9
8
24
280
22
33
36
10
126
52
67
41

Table 3: Comparing different configuration spaces AutoFolio based test performance. best performance shown bold face; indicate performance significantly better default configuration claspfolio 2 significance levels
= 0.05 = 0.1, respectively, according one-sided permutation test 100 000
permutations. Performances values that, according permutation test, significantly worse (at = 0.05) best performance given scenario marked
.

fixed selection approach AutoFoliovote pairwise classification
voting scheme, since SATzilla11-like promising single approach experiments (see, e.g., Figure 1). hand, extended configuration space,
AutoFolioext , obtained adding algorithm subset selection feature selection
configuration task. Feature selection well known improve many machine learning
models, often small subset instance features necessary predict runtime
algorithms (Hutter, Hoos, & Leyton-Brown, 2013).
note configuration AutoFoliovote also found AutoFolio,
configuration AutoFolio also part AutoFolioext , is, AutoFoliovote
AutoFolio AutoFolioext . Table 2 gives overview configuration space sizes.
4.3 Analysis Configuration Process
Table 3, compare performance default configuration claspfolio 2
(namely, SATzilla11-like) configurations optimized AutoFoliovote ,
AutoFolio AutoFolioext . selection scenarios, AutoFoliovote improved
performance test data comparison default configuration claspfolio 2.
AutoFolio improved one scenario AutoFolioext three scenarios.
Performance improvements test data statistically significant = 0.1 = 0.05
ten seven scenarios AutoFoliovote , nine seven AutoFolio,
five four AutoFolioext , respectively, according one-sided permutation test
100 000 permutations.
762

fiAutoFolio: Automatically Configured Algorithm Selector

11 13 ASlib scenarios, configuration least one configuration
spaces considered led statistically significant improvements ( = 0.1); discuss
remaining two scenarios, ASP-POTASSCO CSP-2010. ASP-POTASSCO,
performance improved substantially training data (AutoFolio reduced PAR10
score 30%), transfer test data (with none differences
test performances statistically significant). note default configuration
claspfolio 2 manually optimized scenario (Hoos et al., 2014),
AutoFolio found similar configurations similar performance. CSP2010, AutoFolio variants improved default, insignificantly so.
note hard improve performance substantially benchmark,
contains two algorithms.
PREMARSHALLING, AutoFolio solved 8 additional problem instances reduced PAR10 25%; nevertheless, performance difference weakly
significant (at = 0.1). due strong constraints pre-solving schedule
default configuration claspfolio 2 (at 3 solvers 256 seconds).
extensive pre-solving schedules decreased number timeouts PREMARSHALLING, also introduced overhead many instances
scenario, making harder AutoFolio achieve significant performance improvements. scatter plot Figure 7a shows AutoFolio produced fewer timeouts
default claspfolio 2, AutoFolio required higher runtime instances (points diagonal). Similarly, AutoFolio solved lot instances
PROTEUS-2014 QBF-2011, AutoFolio higher runtime
instances (see Figure 7c 7b). However, number timeouts improved much PROTEUS-2014 (from 321 117) performance improvement
statistically significant here. Finally, SAT12-ALL example clear-cut
case: AutoFolio improved performance claspfolio 2 instances also
substantially reduced number timeouts (see Figure 7d).
Overall, AutoFoliovote performed best experiments, followed AutoFolio,
distance, AutoFolioext . respect statistical significance, AutoFoliovote AutoFolio performed quite similarly, former better three times
latter better once. Based results, suspect added flexibility
AutoFolio compared AutoFoliovote pays configuration budget
large enough evaluate enough configurations effectively search larger space.
case three SAT11 scenarios, AutoFolio reached best
performance: scenarios contain relatively problem instances, making
evaluation claspfolio 2 quite fast allowing SMAC evaluate 40 000 configurations within 2 days. contrast, evaluation configuration largest ASlib
scenario, PROTEUS-2014, cost hour, SMAC evaluated 600
configurations, enough explore design space AutoFolio; accordingly, performance AutoFolioext PROTEUS-2014 improved slightly
comparison default configuration, AutoFoliovote made progress faster
performed statistically significantly better AutoFolio. Therefore, believe
AutoFolio good choice evaluate many configurations,
scenario small large configuration budget available. hand,
763

fiLindauer, Hoos, Hutter, & Schaub

100x

10x

2x

100x

10x

2x

2x

2x

1000

1000
10x

10x

100

100
100x

Configured

Configured

100x

10

10

1

1

0.1

0.1

0.01
0.01

0.1

1

10
Default

100

0.01
0.01

1000

0.1

1

10
Default

100

1000

(a) PREMARSHALLING. Number timeouts (b) QBF-2011. Number timeouts reduced
reduced 33 (default) 25 (configured).
26 (default) 21 (configured).
100x

10x

2x

100x

1000

2x

10x

2x
2x

1000
10x

100

10x

10

100x

100

Configured

Configured

100x

10

1

1

0.1

0.1
0.01
0.01

0.1

1

10
Default

100

0.01
0.01

1000

0.1

1

10
Default

100

1000

(c) PROTEUS-2014. Number timeouts
(d) SAT12-ALL. Number timeouts reduced
reduced 321 (default) 117 (configured). 261 (default) 115 (configured).

Figure 7: Scatter plots comparing per-instance performance default claspfolio 2
(SATzilla11-like) AutoFolio. Left: PREMARSHALLING, AutoFolio improved penalized average runtime (PAR10) reducing number timeouts,
cost increased runtimes many instances. Right: SAT12-ALL, AutoFolio
improved performance instances also reduced number timeouts.

AutoFoliovote used larger scenarios configuration budget
quite small.
Figure 8 shows progress configuration process terms training performance
function time SAT11-HAND PROTEUS-2014, scenarios
764

fiAutoFolio: Automatically Configured Algorithm Selector

8000
3000
Performance

PAR10

7000
6000
5000

Autofolio
Autofolio_ext
Autofolio_vote

4000
29

210

211

212

213 214
Time (s)

2500
2000

Autofolio
Autofolio_ext
Autofolio_vote

1500
1000
215

216

217

29

210

(a) SAT11-HAND

211

212

213 214
Time (s)

215

216

217

(b) PROTEUS-2014

Figure 8: training PAR10 performance best configuration time. line
shows median 10 folds outer cross-validation filled area indicates
performance 25 75-quantile.

fewest configuration evaluations performed fixed configuration budget.
scenarios, large configuration space AutoFolioext resulted period
stagnation performance improved. PROTEUS-2014, performance started
improve near end configuration budget. contrast, AutoFolio
AutoFoliovote performed quite similarly scenarios, AutoFoliovote
somewhat faster make progress (note logarithmic time axis). Surprisingly us,
different selection approaches chosen AutoFolio AutoFoliovote .
restricted configuration space, AutoFoliovote choose pairwise classification
voting scheme, AutoFolio also used approaches outer folds
scenarios: regression (2 times two scenarios), clustering (1 3 times,
resp.) SNNAP (3 4 times, resp.).
Figure 8, also estimate influence configuration budget
performance final algorithm selector. example, halve configuration time
budget 1 day, penalized average runtime training set increases
8%.
4.4 Choices Lead Good Performance?
analyze choices important AutoFolio, applied two complementary methods assessing parameter importance algorithm configuration spaces:
functional ANOVA (Hutter, Hoos, & Leyton-Brown, 2014, 2015b) global measure
parameter importance ablation analysis (Fawcett & Hoos, 2015b, 2015a) local
measure. high-level overview parameters AutoFolio, refer back
Section 3.2; full details, including default values ranges parameters, given
online appendix available www.ml4aad.org/autofolio.
765

fiLindauer, Hoos, Hutter, & Schaub

4.4.1 Functional ANOVA (fANOVA)
Functional ANOVA (fANOVA, see, e.g., Sobol, 1993) general method partitioning
variance function components corresponding subsets arguments. Hutter
et al. (2014) demonstrated technique applied efficiently quantify
importance algorithms parameters. approach re-use performance data
collected configuration process purpose (without requiring new algorithm
executions) therefore computationally efficient (in experiments, required
minutes). overall approach fit empirical performance model (Hutter, Xu, Hoos,
& Leyton-Brown, 2014) : C R measured performance data,
used predict performance arbitrary configurations instances, study
parameter importance model. fitting model, fANOVA marginalizes
across problem instances:
1 X
f(c) =

m(c, i).
(4)
|I|
iI

computes variance function f across entire configuration space C
partitions variance additive components due subset algorithms
parameters. particular interest unary subsets, often explain substantial part
variance tend easiest interpret. important note fANOVA
partitions variance f entire configuration space. provides
global measure parameter importance, takes account many poorly-performing
configurations.
use fANOVA context study, ASlib scenario, merged
performance data 12 independent SMAC runs removed data points reported timeout5 resulted empty feature set. latter,
case claspfolio 2 statically selects single best solver, causing parameters
become unimportant performance claspfolio 2.
brevity, report results scenario SAT12-ALL. Table 4 shows ten
important parameters AutoFolio AutoFolioext scenario.
configuration spaces, maximal time spent compute instance features (max-featuretime) turned important parameter. parameter important,
setting small result features (or even none, disabling
selection mechanism) setting large lead increased overhead feature
computation (see Figure 9).
second important parameter AutoFolio marginal contribution
filtering heuristic algorithm subset selection. Algorithm subset selection especially important scenarios based SAT solving, include many SAT
solvers performance solvers often highly correlated (Xu et al.,
2012a). AutoFolioext , contribution filtering heuristic less important,
configuration space includes binary parameters individual algorithm, allowing
configurator (here SMAC) directly perform subset selection. context, including mphaseSATm marchrw special importance. solver mphaseSATm
single best algorithm SAT12-ALL one highest marginal contributions
5. observed timeouts particular configuration larger data sets: clustering approach
spectral clustering.

766

fiAutoFolio: Automatically Configured Algorithm Selector

Parameter

Main Effect

max-feature-time
contr-filter
approach
feature-step:CG
pre-solving
impute
perf:transformation
time-pre-solving
feature:normalization
pre-solving:max-solver

Parameter

23.43% 2.05
6.82% 2.30
6.39% 0.63
0.76% 0.09
0.69% 0.09
0.29% 0.06
0.26% 0.05
0.22% 0.06
0.06% 0.01
0.05% 0.01

Main Effect

max-feature-time
approach
pre-solving
contr-filter
algorithms:mphaseSATm
imputation
F:algorithms:marchrw
time-pre-solving
pre-solving:sec mode
perf:transformation

(a) AutoFolio

11.07% 5.32
5.90% 4.40
1.29% 1.61
0.80% 0.92
0.72% 0.22
0.69% 0.27
0.30% 0.18
0.23% 0.41
0.11% 0.24
0.11% 0.04

(b) AutoFolioext

Table 4: Average main effects ( stdev) outer cross-validation splits ten
important claspfolio 2 parameters SAT12-ALL according fANOVA.

Marginal PAR10 Scores

5851

4475

30920

100 200 300 400 500 600
max-feat-time [sec]

Figure 9: Marginal performance predictions parameter max-feature-time data
one outer fold configuration space AutoFolio. blue line indicates mean
predicted marginal performance red area standard deviation.
oracle. Similarly, marchrw high marginal contribution algorithm
whose performance highly correlated another solver (see exploratory
data analysis Bischl et al., 2015b).
note analysis determines global parameter importance
respect entire parameter space. example, importance maximal feature
computation time mostly high, crucial change improve
performance claspfolio 2, configuration space contains settings
drastically worsen performance. gain complementary insights parameters changed improve performance, next performed ablation analysis.6
6. note fANOVA also used yield local analysis parameter importance partitioning variance performance high-performance regions given configuration space (Hutter

767

fi2000

2200

1800

2000

1600

1800

1400

1600
PAR10

PAR10

Lindauer, Hoos, Hutter, & Schaub

1200
1000

1400
1200

800

1000

600

800

400
ute ime lter lize :sp ans opt :CG eaf aps sic res jois
impture-t ontr-finorma -stepsnce_trspeed--steps ples_pl s:ls_s eps:Ba_featups:lob

c
ure ature n_same-ste ure-st f-max re-ste
-fe
featperfor
fe f-mi atur feat ing:r eatu
max
vot f
ng:r fe



v

600

e e e p f r c
s:CG put tim -op aliz ran joi sap s:s lea ure filte asi
tep im ature- speed normance_teps:lobps:ls_re-stepmples_x_featcontr- teps:B

e
te
-s

ur
-fe
form re-s e-s atu n_s f-m eature
feat
max
per featu featur fge:rf-mioting:r
f
v
n
voti

(a) 2nd outer fold

(b) 7th outer fold

Figure 10: Ablation paths two outer-folds SAT12-ALL. (a), important
parameter impute feature-step:CG smaller effect. (b), feature-step:CG
important parameter impute effect performance.

4.4.2 Ablation Analysis
Ablation analysis provides answer question changes parameter values
one configuration another caused biggest improvement performance?.
iteratively changing parameter value largest impact performance
path two given configurations, e.g., default configuration algorithm
optimized configuration. Unlike fANOVA, ablation analysis attempt
summarize parameter importance across entire configuration space, focusses locally
paths configurations interest. results obtained ablation analysis
therefore complementary fANOVA. Unfortunately, ablation costly,
since requires new algorithm runs assess performance configurations path
two given configurations. AutoFolio experiments SAT12-ALL,
allocated time budget 6 days maximum wall-clock time permitted jobs
cluster ablation 10 outer cross-validation folds, within
budget, obtained results 6 those.
ablation results indicate feature-step:CG Boolean parameter enables
disables computation clause graph features single important parameter
change claspfolio 2s default. default, feature-step:CG activated,
turns clause graph features often expensive compute within
time allow feature computation. Therefore, indeed good decision
configuration procedure deactivate optional feature computation step. According
ablation results, done 5 6 outer cross-validation folds and, average,
5 folds, responsible 99% performance improvements achieved
et al., 2014); here, this, since used ablation analysis study parameter importance
locally.

768

fiAutoFolio: Automatically Configured Algorithm Selector

configuration (standard deviation 37%7 ). contrast, seen fANOVA results,
feature-step:CG quite unimportant globally, main effect 0.76%. second
important parameter change activation feature imputation (impute);
average, responsible 39% overall performance improvement (standard
deviation 56%) made 6 outer cross-validation folds analyzed.8 However,
impute effect performance feature-step:CG deactivated
impute changed ablation path. case 2 6 ablation
paths (e.g., see Figure 10a) hence, impute impact performance 4
paths (e.g., see Figure 10b). two parameters dependent effects, since imputation
particularly important clause graph features computed: features time
many large instances thus require imputation.
globally important parameter, according fANOVA, max-feature-time,
found rather unimportant change default value. parameter
changed default optimized configuration outer folds SAT12-ALL,
since default value already good average 2% overall performance improvement could attributed change. note along
Ablation path, max-feature-time never flipped value resulted worse performance default configuration, many poorly-performing values
exist explain globally high importance parameter.
4.5 Comparison Algorithm Selectors
Table 5, compare AutoFolio SATzilla159 (Xu et al., 2011), SNNAP (version 1.4; Collautti et al., 2013) ISAC (implementation SNNAP 1.4; Kadioglu
et al., 2010).10 note ISAC SNNAP pure algorithm selectors, whereas
SATzilla15 claspfolio 2 additionally use pre-solver schedules. Furthermore,
added nave approach, RandSel, simulating uninformed user selects uniformly random SNNAP, ISAC SATzilla15. Overall, AutoFolio performed best 7 13 scenarios statistically indistinguishable
best system scenarios, according one-sided permutation test 100 000
permutations significance level = 0.05. Therefore, AutoFolio system
achieves state-of-the-art performance scenarios.
SATzilla15 performed second best, yielded statistically significantly worse performance AutoFolio 5 13 scenarios. Even though statistically significant,
SATzilla15 performed slightly better AutoFolio 5 scenarios. reason
7. large standard deviation arises fact folds, parameter change actually
responsible 100% performance difference: folds, change alone would
sufficed achieve better performance optimized configuration.
8. sum relative performance subset parameter improvements limited 100%, since
computed relative difference default optimized configuration. 5
6 ablation paths, parameter changes lead better performance final optimized
configuration, parameter changed worsened performance again.
9. Alexandre Frechette, current main developer SATzilla, provided internal new implementation
SATzilla (version 0.9.1b-count-cheap-feat-12) longer limited SAT.
10. state-of-the-art selectors, 3S (Kadioglu et al., 2011) CSHC (Malitsky et al., 2013a),
publicly available training procedures, therefore unable train
scenarios.

769

fiLindauer, Hoos, Hutter, & Schaub

ASP-POTASSCO
CSP-2010
MAXSAT12-PMS
PREMARSHALLING
PROTEUS-2014
QBF-2011
SAT11-HAND
SAT11-INDU
SAT11-RAND
SAT12-ALL
SAT12-HAND
SAT12-INDU
SAT12-RAND

Oracle

SB

SNNAP

ISAC

21.3
107.7
40.7
227.6
26.3
95.9
478.3
419.9
227.3
93.7
113.2
88.1
46.9

534.1
1087.4
2111.6
7002.9
10756.3
9172.3
17815.8
8985.6
14938.6
2967.9
3944.2
1360.6
568.5

203.8
1087.5
895
9042.1
4058.7
7386.2
9209.3
6632.6
4859
1427.5
2180.5
789
593.1

291.9
1027
786.4
5880.8
3328
3813.5
13946.2
8461.2
3140.4
2989.3
4110.8
1409.5
434.5

SATzilla15 RandSel AutoFolio
170
276
166.8
3179.1
2050.3
1245.2
6211.5
8048.8
877.5
876.9
1031.5
839.7
485.3

221.6
796.8
615.6
6034
3145.6
4148.3
9789
7714.2
2958.9
1764.5
2440.9
1012.7
504.3

125
355
246.3
2005.1
1379.2
910
5552.7
5932.3
967
979
1212
774.6
440

Table 5:
Performance comparison AutoFolio, SNNAP, ISAC,
SATzilla15, well single best solver (SB, selected based PAR10 training
set) baseline, oracle (also known virtual best solver) bound optimal performance algorithm selector. show PAR10 scores averaged 10 outer
cross-validation folds, instances solved solver removed test set
avoid artificially inflating PAR10-scores. RandSel column shows expected
performance picking uniformly random one SNNAP, ISAC SATzilla15.
best performance shown bold face. performance values statistically significantly better best-performing system given scenario, according
one-sided permutation test 100 000 permutations significance level = 0.05,
marked .
might SATzilla15 performs extensive search determine best combination pre-solving schedule (grid search), algorithm subset (iterated local search)
trained selection model.
note that, order compensate 24 CPU days spent find well-performing
configuration AutoFolio, compared simply using single best solver, average
across scenarios AutoFolio would consecutively solve instances 42 CPU
days (standard deviation 23), less two times configuration budget.
Although AutoFolio improved substantially single best solver (SB)
scenarios (up speedup factor 15.4 SAT11-RAND), still gap
Oracle performance (also known virtual best solver SAT community).
gap could closed least two ways: (i) using larger configuration budget
AutoFolio, (ii) developing better instance features, basis
algorithm selection methods.

5. Conclusions
presented AutoFolio best knowledge, first approach automatically configuring algorithm selectors. Using concrete realization approach based
highly parameterized algorithm selection framework claspfolio 2, showed
using state-of-the-art algorithm configurators, algorithm selectors customized
770

fiAutoFolio: Automatically Configured Algorithm Selector

robustly achieve peak performance across range algorithm selection scenarios.
resulting approach performs significantly (and sometimes substantially) better manually configured selectors applied out-of-the-box previously unseen algorithm
selection scenarios.
comprehensive experiments 13 algorithm selection scenarios different
domains (SAT, Max-SAT, CSP, ASP, QBF, container pre-marshalling) make
algorithm selection library ASlib, concrete realization AutoFolio outperformed
best single solver selection benchmark factors 1.3 15.4 (geometric
average: 3.9) terms PAR10 scores. Overall, AutoFolio established improved stateof-the-art performance 7 13 scenarios performed par previous
state-of-the-art approaches scenarios; overall, clearly yielded robust
performance across diverse set benchmarks.
also studied effect different configuration spaces. Here, showed
medium-size configuration space AutoFolio lead state-of-the-art performance
configuration budget allows evaluation sufficiently many configurations.
contrast, selection scenario large (in terms number algorithms problem
instances), configuration budget limited, configuration constrained
space, used AutoFoliovote , typically leads better performance.
performance AutoFoliovote independently verified ICON Challenge
Algorithm Selection (Kotthoff, 2015), evaluated 8 different systems
small configuration budget 12 CPU hours respect three metrics: PAR10 score,
number instances solved misclassification penalty. throughout paper,
metric optimized AutoFolio PAR10 score, AutoFolio ranked first
respect metric. also ranked first respect number instances solved
second respect misclassification penalty (leading overall second place).
future work, plan investigate potential gains larger configuration
spaces (including feature algorithm subset selection) used effectively.
end, would like (i) study performance larger configuration budgets
allow configurator assess configurations; (ii) evaluate algorithm configurators, irace (Lopez-Ibanez et al., 2011) GGA (Ansotegui et al., 2009); (iii)
extend configuration space AutoFolio implementing algorithm selection
approaches (e.g., CSHC; Malitsky et al., 2013a); (iv) shrink larger configuration space
based analysis parameter importance fANOVA (Hutter et al., 2014)
Ablation (Fawcett & Hoos, 2015b), allowing configurator focus important parameters; (v) automatically select pre-configured algorithm selectors,
based features given algorithm selection scenario, improve performance
starting automatic configuration configurations thus selected (Feurer, Springenberg, & Hutter, 2015). Another promising avenue reducing computational cost
approach would pre-select algorithms, features, problem instances based
techniques proposed Hoos et al. (2013) based collaborative filtering approach
Misir Sebag (2013). Finally, plan investigate extent AutoFolio
configure algorithm selection systems selecting parallel portfolios (Lindauer et al.,
2015a) exploit increasing availability parallel computing resources.
Overall, believe automated configuration algorithm selection systems improves performance versatility systems across broad range application
771

fiLindauer, Hoos, Hutter, & Schaub

domains. AutoFolio approach also facilitates future improvements, making easier realize assess performance potential inherent new design choices
various components algorithm selection system. open-source implementation
AutoFolio available www.ml4aad.org/autofolio/.

Acknowledgements
M. Lindauer supported DFG (German Research Foundation) Emmy
Noether grant HU 1900/2-1 project SCHA 550/8-3, H. Hoos NSERC Discovery
Grant, F. Hutter DFG Emmy Noether grant HU 1900/2-1 T. Schaub
DFG project SCHA 550/8-3, respectively. work performed
computational resource bwUniCluster funded Ministry Science, Research Arts
universities State Baden-Wurttemberg, Germany, within framework
program bwHPC.

References
Abrame, A., & Habet, D. (2014). extension learning Max-SAT. Endriss, U.,
& Leite, J. (Eds.), Proceedings 7th European Starting AI Researcher Symposium
(STAIRS14), Vol. 264 Frontiers Artificial Intelligence Applications, pp. 1
10. IOS Press.
Amadini, R., Gabbrielli, M., & Mauro, J. (2014). SUNNY: lazy portfolio approach
constraint solving. Theory Practice Logic Programming, 14 (4-5), 509524.
Ansotegui, C., Malitsky, Y., & Sellmann, M. (2014). Maxsat improved instance-specific
algorithm configuration. Brodley, C., & Stone, P. (Eds.), Proceedings Twentyeighth National Conference Artificial Intelligence (AAAI14), pp. 25942600. AAAI
Press.
Ansotegui, C., Sellmann, M., & Tierney, K. (2009). gender-based genetic algorithm
automatic configuration algorithms. Gent, I. (Ed.), Proceedings
Fifteenth International Conference Principles Practice Constraint Programming (CP09), Vol. 5732 Lecture Notes Computer Science, pp. 142157. SpringerVerlag.
Bergstra, J., Bardenet, R., Bengio, Y., & Kegl, B. (2011). Algorithms hyper-parameter
optimization. Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., & Weinberger,
K. (Eds.), Proceedings 25th International Conference Advances Neural
Information Processing Systems (NIPS11), pp. 25462554.
Biere, A. (2013). Lingeling, plingeling treengeling entering sat competition 2013.
Balint, A., Belov, A., Heule, M., & Jarvisalo, M. (Eds.), Proceedings SAT Competition 2013: Solver Benchmark Descriptions, Vol. B-2013-1 Department
Computer Science Series Publications B, pp. 5152. University Helsinki.
Bischl, B., Kerschke, P., Kotthoff, L., Lindauer, M., Malitsky, Y., Frechette, A., Hoos, H.,
Hutter, F., Leyton-Brown, K., Tierney, K., & Vanschoren, J. (2015a). www.aslib.net.
772

fiAutoFolio: Automatically Configured Algorithm Selector

Bischl, B., Kerschke, P., Kotthoff, L., Lindauer, M., Malitsky, Y., Frechette, A., Hoos,
H., Hutter, F., Leyton-Brown, K., Tierney, K., & Vanschoren, J. (2015b). Aslib:
benchmark library algorithm selection. Computing Research Repository (CoRR),
abs/1506.02465.
Chiarandini, M., Fawcett, C., & Hoos, H. (2008). modular multiphase heuristic solver
post enrolment course timetabling. Proceedings Seventh International
Conference Practice Theorysy Automated Timetabling (PATAT08, pp.
18.
Collautti, M., Malitsky, Y., Mehta, D., & OSullivan, B. (2013). SNNAP: Solver-based
nearest neighbor algorithm portfolios. Blockeel, H., Kersting, K., Nijssen,
S., & Zelezny, F. (Eds.), Machine Learning Knowledge Discovery Databases
(ECML/PKDD13), Vol. 8190 Lecture Notes Computer Science, pp. 435450.
Springer-Verlag.
Dickerson, J., & Sandholm, T. (2015). Futurematch: Combining human value judgments
machine learning match dynamic environments. Bonet, B., & Koenig,
S. (Eds.), Proceedings Twenty-nineth National Conference Artificial Intelligence (AAAI15), pp. 622628. AAAI Press.
Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., & Leyton-Brown,
K. (2013). Towards empirical foundation assessing Bayesian optimization
hyperparameters. NIPS Workshop Bayesian Optimization Theory Practice.
Fawcett, C., & Hoos, H. (2015a). www.cs.ubc.ca/labs/beta/Projects/Ablation/.
Fawcett, C., & Hoos, H. (2015b). Analysing differences algorithm configurations
ablation. Journal Heuristics, 128.
Feurer, M., Springenberg, T., & Hutter, F. (2015). Initializing Bayesian hyperparameter
optimization via meta-learning. Bonet, B., & Koenig, S. (Eds.), Proceedings
Twenty-nineth National Conference Artificial Intelligence (AAAI15), pp. 1128
1135. AAAI Press.
Gebser, M., Kaminski, R., Kaufmann, B., Ostrowski, M., Schaub, T., & Schneider, M.
(2011a). Potassco: Potsdam answer set solving collection. AI Communications,
24 (2), 107124.
Gebser, M., Kaminski, R., Kaufmann, B., Schaub, T., Schneider, M., & Ziller, S. (2011b).
portfolio solver answer set programming: Preliminary report. Delgrande, J.,
& Faber, W. (Eds.), Proceedings Eleventh International Conference Logic
Programming Nonmonotonic Reasoning (LPNMR11), Vol. 6645 Lecture Notes
Computer Science, pp. 352357. Springer-Verlag.
Gebser, M., Kaufmann, B., & Schaub, T. (2012). Conflict-driven answer set solving:
theory practice. Artificial Intelligence, 187-188, 5289.
Gent, I., Jefferson, C., Kotthoff, L., Miguel, I., Moore, N., Nightingale, P., & Petrie, K.
(2010). Learning use lazy learning constraint solving. Coelho, H., Studer,
R., & Wooldridge, M. (Eds.), Proceedings Nineteenth European Conference
Artificial Intelligence (ECAI10), pp. 873878. IOS Press.
773

fiLindauer, Hoos, Hutter, & Schaub

Gomes, C., & Selman, B. (2001). Algorithm portfolios. Artificial Intelligence, 126 (1-2),
4362.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. (2009).
WEKA data mining software: update. SIGKDD Explorations, 11 (1), 1018.
Hoos, H., Kaminski, R., Lindauer, M., & Schaub, T. (2015). aspeed: Solver scheduling via
answer set programming. Theory Practice Logic Programming, 15, 117142.
Hoos, H., Kaufmann, B., Schaub, T., & Schneider, M. (2013). Robust benchmark set selection boolean constraint solvers. Pardalos, P., & Nicosia, G. (Eds.), Proceedings
Seventh International Conference Learning Intelligent Optimization
(LION13), Vol. 7997 Lecture Notes Computer Science, pp. 138152. SpringerVerlag.
Hoos, H., Lindauer, M., & Schaub, T. (2014). claspfolio 2: Advances algorithm selection
answer set programming. Theory Practice Logic Programming, 14, 569585.
Huberman, B., Lukose, R., & Hogg, T. (1997). economic approach hard computational
problems. Science, 275, 5154.
Hurley, B., Kotthoff, L., Malitsky, Y., & OSullivan, B. (2014). Proteus: hierarchical
portfolio solvers transformations. Simonis, H. (Ed.), Proceedings
Eleventh International Conference Integration AI Techniques Constraint Programming (CPAIOR14), Vol. 8451 Lecture Notes Computer Science,
pp. 301317. Springer-Verlag.
Hutter, F., Babic, D., Hoos, H., & Hu, A. (2007). Boosting verification automatic tuning
decision procedures. OConner, L. (Ed.), Formal Methods Computer Aided
Design (FMCAD07), pp. 2734. IEEE Computer Society Press.
Hutter, F., Hoos, H., & Leyton-Brown, K. (2010). Automated configuration mixed integer
programming solvers. Lodi, A., Milano, M., & Toth, P. (Eds.), Proceedings
Seventh International Conference Integration AI Techniques Constraint Programming (CPAIOR10), Vol. 6140 Lecture Notes Computer Science,
pp. 186202. Springer-Verlag.
Hutter, F., Hoos, H., & Leyton-Brown, K. (2011). Sequential model-based optimization
general algorithm configuration. Coello, C. (Ed.), Proceedings Fifth
International Conference Learning Intelligent Optimization (LION11), Vol.
6683 Lecture Notes Computer Science, pp. 507523. Springer-Verlag.
Hutter, F., Hoos, H., & Leyton-Brown, K. (2014). efficient approach assessing
hyperparameter importance. Xing, E., & Jebara, T. (Eds.), Proceedings 31th
International Conference Machine Learning, (ICML14), Vol. 32, pp. 754762.
Omnipress.
Hutter, F., Hoos, H., & Leyton-Brown, K. (2015a). www.ml4aad.org/smac.
Hutter, F., Hoos, H., & Leyton-Brown, K. (2015b). www.ml4aad.org/fanova.
Hutter, F., Hoos, H., Leyton-Brown, K., & Stutzle, T. (2009). ParamILS: automatic
algorithm configuration framework. Journal Artificial Intelligence Research, 36,
267306.
774

fiAutoFolio: Automatically Configured Algorithm Selector

Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2013). Identifying key algorithm parameters
instance features using forward selection. Pardalos, P., & Nicosia, G. (Eds.),
Proceedings Seventh International Conference Learning Intelligent Optimization (LION13), Vol. 7997 Lecture Notes Computer Science, pp. 364381.
Springer-Verlag.
Hutter, F., Lindauer, M., Balint, A., Bayless, S., Hoos, H., & Leyton-Brown, K. (2015).
Configurable SAT Solver Challenge (CSSC). Artificial Intelligence. review.
Hutter, F., Xu, L., Hoos, H., & Leyton-Brown, K. (2014). Algorithm runtime prediction:
Methods evaluation. Artificial Intelligence, 206, 79111.
Janota, M., Klieber, W., Marques-Silva, J., & Clarke, E. (2012). Solving QBF counterexample guided refinement. Cimatti, A., & Sebastiani, R. (Eds.), Proceedings
Fifteenth International Conference Theory Applications Satisfiability Testing (SAT12), Vol. 7317 Lecture Notes Computer Science, pp. 114128.
Springer-Verlag.
Kadioglu, S., Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2011). Algorithm selection scheduling. Lee, J. (Ed.), Proceedings Seventeenth International Conference Principles Practice Constraint Programming (CP11),
Vol. 6876 Lecture Notes Computer Science, pp. 454469. Springer-Verlag.
Kadioglu, S., Malitsky, Y., Sellmann, M., & Tierney, K. (2010). ISAC - instance-specific
algorithm configuration. Coelho, H., Studer, R., & Wooldridge, M. (Eds.), Proceedings Nineteenth European Conference Artificial Intelligence (ECAI10),
pp. 751756. IOS Press.
Kotthoff, L. (2013). LLAMA: leveraging learning automatically manage algorithms.
Computing Research Repository (CoRR), abs/1306.1031.
Kotthoff, L. (2014). Algorithm selection combinatorial search problems: survey. AI
Magazine, 4860.
Kotthoff, L. (2015). ICON Challenge Algorithm Selection..
icon-fet.eu/challengeas.

http://challenge.

Kotthoff, L., Gent, I., & Miguel, I. (2012). evaluation machine learning algorithm
selection search problems. AI Communications, 25 (3), 257270.
Lim, B., van den Briel, M., Thiebaux, S., Backhaus, S., & Bent, R. (2015). HVAC-Aware
Occupancy Scheduling. Bonet, B., & Koenig, S. (Eds.), Proceedings Twentynineth National Conference Artificial Intelligence (AAAI15), pp. 679686. AAAI
Press.
Lindauer, M., Hoos, H., & Hutter, F. (2015a). sequential algorithm selection parallel
portfolio selection. Dhaenens, C., Jourdan, L., & Marmion, M. (Eds.), Proceedings Nineth International Conference Learning Intelligent Optimization
(LION15), Lecture Notes Computer Science, pp. 116. Springer-Verlag.
Lindauer, M., Hoos, H., Hutter, F., & Schaub, T. (2015b). Autofolio: Algorithm configuration algorithm selection. Proceedings Workshops Twenty-nineth
National Conference Artificial Intelligence (AAAI15).
775

fiLindauer, Hoos, Hutter, & Schaub

Lindauer, M., Hoos, H., & Schaub, T. (2015c). www.cs.uni-potsdam.de/claspfolio/.
Lopez-Ibanez, M., Dubois-Lacoste, J., Stutzle, T., & Birattari, M. (2011). irace package,
iterated race automatic algorithm configuration. Tech. rep., IRIDIA, Universite
Libre de Bruxelles, Belgium.
Lopez-Ibanez, M., & Stutzle, T. (2010). Automatic configuration multi-objective ACO
algorithms. Dorigo, M., M-Birattari, Caro, G. D., Doursat, R., Engelbrecht,
A. P., Floreano, D., Gambardella, L., Gro, R., Sahin, E., Sayama, H., & Stutzle,
T. (Eds.), Proceedings Seventh International Conference Swarm Intelligence
(ANTS10), Lecture Notes Computer Science, pp. 95106. Springer-Verlag.
Malitsky, Y., Mehta, D., & OSullivan, B. (2013). Evolving instance specific algorithm
configuration. Helmert, M., & Roger, G. (Eds.), Proceedings Sixth Annual
Symposium Combinatorial Search (SOCS14). AAAI Press.
Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2012). Parallel SAT solver
selection scheduling. Milano, M. (Ed.), Proceedings Eighteenth International Conference Principles Practice Constraint Programming (CP12),
Vol. 7514 Lecture Notes Computer Science, pp. 512526. Springer-Verlag.
Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2013a). Algorithm portfolios
based cost-sensitive hierarchical clustering. Rossi, F. (Ed.), Proceedings
23rd International Joint Conference Artificial Intelligence (IJCAI13), pp. 608
614.
Malitsky, Y., Sabharwal, A., Samulowitz, H., & Sellmann, M. (2013b). Boosting sequential solver portfolios: Knowledge sharing accuracy prediction. Pardalos, P.,
& Nicosia, G. (Eds.), Proceedings Seventh International Conference Learning Intelligent Optimization (LION13), Vol. 7997 Lecture Notes Computer
Science, pp. 153167. Springer-Verlag.
Maratea, M., Pulina, L., & Ricca, F. (2014). multi-engine approach answer-set programming. Theory Practice Logic Programming, 14, 841868.
Mascia, F., Lopez-Ibanez, M., Dubois-Lacoste, J., & Stutzle, T. (2014). Grammar-based
generation stochastic local search heuristics automatic algorithm configuration tools. Computers & OR, 51, 190199.
Misir, M., & Sebag, M. (2013). Algorithm selection collaborative filtering problem.
Tech. rep., INRIA & LRI, Universite Paris Sud XI.
OMahony, E., Hebrard, E., Holland, A., Nugent, C., & OSullivan, B. (2008). Using casebased reasoning algorithm portfolio constraint solving. Bridge, D., Brown,
K., OSullivan, B., & Sorensen, H. (Eds.), Proceedings Nineteenth Irish Conference Artificial Intelligence Cognitive Science (AICS08).
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel,
M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau,
D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learning
Python. Journal Machine Learning Research, 12, 28252830.
Pulina, L., & Tacchella, A. (2009). self-adaptive multi-engine solver quantified boolean
formulas. Constraints, 14 (1), 80116.
776

fiAutoFolio: Automatically Configured Algorithm Selector

Rice, J. (1976). algorithm selection problem. Advances Computers, 15, 65118.
Roussel, O. (2011). Controlling solver execution runsolver tool. Journal
Satisfiability, Boolean Modeling Computation, 7, 139144.
Smith-Miles, K. (2008). Cross-disciplinary perspectives meta-learning algorithm
selection. ACM Computing Surveys, 41 (1).
Snoek, J., Larochelle, H., & Adams, R. P. (2012). Practical Bayesian optimization machine learning algorithms. Bartlett, P., Pereira, F., Burges, C., Bottou, L., &
Weinberger, K. (Eds.), Proceedings 26th International Conference Advances
Neural Information Processing Systems (NIPS12), pp. 29602968.
Sobol, I. (1993). Sensitivity estimates nonlinear mathematical models. Mathematical
Modeling Computational Experiment, 1 (4), 407414.
Tamura, N., Taga, A., Kitagawa, S., & Banbara, M. (2009). Compiling finite linear CSP
SAT. Constraints, 14 (2), 254272.
Thornton, C., Hutter, F., Hoos, H., & Leyton-Brown, K. (2013). Auto-WEKA: combined
selection hyperparameter optimization classification algorithms. I.Dhillon,
Koren, Y., Ghani, R., Senator, T., Bradley, P., Parekh, R., He, J., Grossman, R., &
Uthurusamy, R. (Eds.), 19th ACM SIGKDD International Conference Knowledge Discovery Data Mining (KDD13), pp. 847855. ACM Press.
Tierney, K., & Malitsky, Y. (2015). algorithm selection benchmark container premarshalling problem. Dhaenens, C., Jourdan, L., & Marmion, M. (Eds.), Proceedings Nineth International Conference Learning Intelligent Optimization
(LION15), Lecture Notes Computer Science, pp. 1722. Springer-Verlag.
Vallati, M., Fawcett, C., Gerevini, A., Hoos, H., & Saetti, A. (2013). Automatic generation
efficient domain-optimized planners generic parametrized planners. Helmert,
M., & Roger, G. (Eds.), Proceedings Sixth Annual Symposium Combinatorial
Search (SOCS14). AAAI Press.
Xu, L., Hoos, H., & Leyton-Brown, K. (2010). Hydra: Automatically configuring algorithms portfolio-based selection. Fox, M., & Poole, D. (Eds.), Proceedings
Twenty-fourth National Conference Artificial Intelligence (AAAI10), pp. 210216.
AAAI Press.
Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based algorithm selection SAT. Journal Artificial Intelligence Research, 32, 565606.
Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2011). Hydra-MIP: Automated algorithm configuration selection mixed integer programming. RCRA workshop
Experimental Evaluation Algorithms Solving Problems Combinatorial
Explosion International Joint Conference Artificial Intelligence (IJCAI).
Xu, L., Hutter, F., Hoos, H., & Leyton-Brown, K. (2012a). Evaluating component solver
contributions portfolio-based algorithm selectors. Cimatti, A., & Sebastiani,
R. (Eds.), Proceedings Fifteenth International Conference Theory Applications Satisfiability Testing (SAT12), Vol. 7317 Lecture Notes Computer
Science, pp. 228241. Springer-Verlag.
777

fiLindauer, Hoos, Hutter, & Schaub

Xu, L., Hutter, F., Shen, J., Hoos, H., & Leyton-Brown, K. (2012b). SATzilla2012: improved
algorithm selection based cost-sensitive classification models. Balint, A., Belov,
A., Diepold, D., Gerber, S., Jarvisalo, M., & Sinz, C. (Eds.), Proceedings SAT
Challenge 2012: Solver Benchmark Descriptions, Vol. B-2012-2 Department
Computer Science Series Publications B, pp. 5758. University Helsinki.
Yun, X., & Epstein, S. (2012). Learning algorithm portfolios parallel execution.
Hamadi, Y., & Schoenauer, M. (Eds.), Proceedings Sixth International Conference Learning Intelligent Optimization (LION12), Vol. 7219 Lecture Notes
Computer Science, pp. 323338. Springer-Verlag.

778

fiJournal Artificial Intelligence Research 53 (2015) 169-222

Submitted 11/14; published 06/15

Using Machine Translation Provide Target-Language
Edit Hints Computer Aided Translation Based
Translation Memories
Miquel Espla-Gomis
Felipe Sanchez-Martnez
Mikel L. Forcada

mespla@dlsi.ua.es
fsanchez@dlsi.ua.es
mlf@dlsi.ua.es

Dept. de Llenguatges Sistemes Informatics
Universitat dAlacant, E-03071 Alacant, Spain

Abstract
paper explores use general-purpose machine translation (MT) assisting
users computer-aided translation (CAT) systems based translation memory (TM)
identify target words translation proposals need changed (either
replaced removed) kept unedited, task term word-keeping recommendation.
MT used black box align source target sub-segments fly translation units (TUs) suggested user. Source-language (SL) target-language (TL)
segments matching TUs segmented overlapping sub-segments variable
length machine-translated TL SL, respectively. bilingual subsegments obtained matching SL segment TU segment
translated employed build features used binary classifier
determine target words changed kept unedited. approach,
MT results never presented translator. Two approaches presented
work: one using word-keeping recommendation system trained TM
used CAT system, basic approach require training.
Experiments conducted simulating translation texts several language
pairs corpora belonging different domains using three different MT systems.
compare performance obtained previous works used statistical
word alignment word-keeping recommendation, show MT-based approaches
presented paper accurate scenarios. particular, results
confirm MT-based approaches better alignment-based approach
using models trained out-of-domain TMs. Additional experiments also performed
check dependent MT-based recommender language pair MT
system used training. experiments confirm high degree reusability
recommendation models across various MT systems, low level reusability across
language pairs.

1. Introduction
Computer-aided translation (CAT) systems based translation memory (TM) (Bowker,
2002; Somers, 2003) translation technology choice professional translators, especially translation tasks repetitive effective recycling previous
translations feasible. reasons choice conceptual simplicity fuzzymatch scores (FMS) (Sikes, 2007) ease used determine
usefulness translations proposed CAT system estimate remainc
2015
AI Access Foundation. rights reserved.

fiEspla-Gomis, Sanchez-Martnez & Forcada

Figure 1: Procedure followed translate document using TM-based CAT system.
ing effort needed turn adequate translations. FMS function measures
similarity two text segments, usually computing variant word-based edit
distance (Levenshtein, 1966), although FMS proprietary tools publicly
described.
TM-based CAT system used translate new source document, system
first segments document, then, source segment 0 , provides translator
subset translation units (TUs) (S, ) TM FMS 0
selected threshold . translator must choose TU (S, )
best fits needs post-edit target segment produce 0 , adequate
translation 0 . Figure 1 illustrates procedure.
showing subset matching TUs translator, TM-based CAT
systems highlight words differ 0 order ease task
post-editing . is, however, translator identify specific words
changed (either replaced removed) order convert 0 ,
problem deal paper term word-keeping recommendation.
experiments professional translators show TM-based CAT system capable
word-keeping recommendation improves productivity 14% ideal case
recommendations indeed correct (see Appendix details).
Word-keeping recommendation related translation spotting (Veronis & Langlais,
2000; Simard, 2003; Sanchez-Martnez, Carrasco, Martnez-Prieto, & Adiego, 2012),
consists solving problem finding parallel sub-segments parallel texts. Translation
spotting used, example, bilingual concordancers (Bourdaillet, Huet, Langlais, & Lapalme, 2010), types tools help translator retrieve occurrences sub-segment
parallel corpus corresponding translation. examples commercial bilingual concordancers Webitext,1 Linguee,2 Reverso Context.3 Translation spotting
also particularly relevant example-based machine translation (Somers, 1999), uses
technique build sub-segmental TM used translate new materials. MT quality
estimation (de Gispert, Blackwood, Iglesias, & Byrne, 2013; Specia, Raj, & Turchi, 2010),
also shares features task: cases objective discover whether
1. http://www.webitext.com [last visit: 15th May 2015]
2. http://www.linguee.com [last visit: 15th May 2015]
3. http://context.reverso.net/translation/ [last visit: 15th May 2015]

170

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

translation proposal 4 valid translation given source language segment 0 .
parallelisms become stronger case word-level quality estimation (Ueffing & Ney,
2005; Bojar et al., 2014; Espla-Gomis, Sanchez-Martnez, & Forcada, 2015), which,
word-keeping recommendation, every word proposal analysed decide whether
likely belong final translation. critical differences
scenarios quality estimation word-keeping recommendation operate: quality
estimation detects words changed segments likely
inadequately written TL, intended translations 0 ; conversely, wordkeeping recommendation intended work segments usually adequately
written TL, translation 0 (unless exact match
0 found).
Espla, Sanchez-Martnez, Forcada (2011) performed word-keeping recommendation using statistical word-alignment models (Och & Ney, 2003) align sourcelanguage (SL) target-language (TL) words TU TM. TU (S, )
suggested translator, pre-computed word alignments used determine target words changed kept unedited. Analogously, Kranias Samiotou
(2004) align words TU different sub-segment levels using, among
resources, bilingual dictionary words phrases (Meyers, Kosaka, & Grishman, 1998),
suffix lists deal morphological variations, list closed-class words
categories (Ahrenberg, Andersson, & Merkel, 2000). authors use alignments
detect words changed use MT propose translation them.
best knowledge, specific details Kranias Samiotou method
works published. patent published Kuhn, Goutte, Isabelle, Simard
(2011) describes similar method also based statistical word alignment order
detect words changed translation proposal. Unfortunately, patent
provide detailed description actual procedure used.
Espla-Gomis, Sanchez-Martnez, Forcada (2011) follow different approach
necessitate computation word alignments. Instead, make use
available MT system source bilingual information compute set features
used perceptron classifier estimate probability pK target word
kept unedited. done by: obtaining matching TUs TM using FMS
given threshold; segmenting SL TL segments TUs
overlapping sub-segments variable length; machine translating sub-segments
TL SL, respectively, order learn sub-segment alignments; using
sub-segment alignments matching 0 build features
used classifier. basic idea behind method word likely
kept unedited appears translation sub-segments common
0 , segment translated. Finally, pK used word-keeping recommendation
marking words pK < 12 change, otherwise keep.
Although latter approach requires training procedure run TM, EsplaGomis et al. (2011) show that, translation Spanish texts English, model
used perceptron classifier trained TM domain different
actual TM used text translated. Furthermore,
4. case quality estimation, segment evaluated originates MT, wordkeeping recommendation, originates TM-based CAT tool proposal.

171

fiEspla-Gomis, Sanchez-Martnez & Forcada

results obtained system similar obtained Espla et al. (2011), based
statistical word alignments, models trained texts domain
text translated, much better models trained out-of-domain texts, shown
Section 7.
paper revisit approach Espla-Gomis et al. (2011), propose new
feature sets capture information machine-translated sub-segments
successful way features therein. addition, complex multilayer perceptron binary classifier used work, improves results obtained
simpler perceptron classifier proposed Espla et al. (2011). improvements binary classification compared previous approach exhaustive evaluation
framework, including new domains language pairs (see below). Finally, introduce
new method word-keeping recommendation also able use available MT
system source bilingual information, require training procedure
run advance. training-free method uses sub-segment pairs match
compute alignment strength (Espla-Gomis, Sanchez-Martnez, & Forcada,
2012b) words . alignment strength two words sk
tj measures amount evidence relates two words giving
weight evidence shorter sub-segments, involves sharper picture
relation sk tj . Alignment strengths used similar fashion
Espla et al. (2011) determine words changed kept unedited.
mentioned above, experiments performed work compare two MTbased approaches (that requires training training-free)
alignment-based approach Espla et al. (2011) using ten different language pairs, TMs
three different domains, three different MT systems. experiments
cover ideal scenario, trained recommendation models tested
conditions language pair, TM domain, MT system used training,
also scenarios conditions change order test reusability
models. Namely, experiments carried using recommendation models trained on:
TM different domain, different MT system, different language pair.
results obtained show MT-based approaches superior alignment-based
approach regards accuracy scenarios. results additionally confirm
MT-based approaches produce recommendation models portable across
TM domains based word alignment. also provides good reusability
different MT systems, poor reusability translating different pair languages
used training; fact, training-free MT-based method provides better results
scenario.
remainder paper organised follows. following section reviews
previous works integration TMs MT. Section 3 reviews statistical wordalignment-based approach defined Espla et al. (2011), used paper
reference compare new methods presented. Section 4 tackles problem wordkeeping recommendation using binary classifier several sets features based
coverage sub-segment pairs obtained machine translating sub-segments different
sizes segments translation proposal, matching source-side
proposal segment translated. Section 5 shows use
bilingual sub-segments compute alignment strength SL TL words
172

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

TU, used word-keeping recommendation without training.
Section 6 describes experimental framework, Section 7 presents discusses
results obtained. paper ends concluding remarks. Two appendices
included paper: one including experiments aimed measuring impact wordkeeping recommendation productivity professional translators, one
reporting results filtered-out data set check performance ideal setting.

2. Integration Machine Translation Translation Memories
literature subject contains several approaches combine benefits MT
TMs ways different presented paper, go beyond
obvious -combination scenario defined Simard Isabelle (2009), MT
used translate new segment matching TU fuzzy-match score threshold
found TM.
Marcu (2001) integrates word-based statistical machine translation (SMT) subsegmental TM. method uses IBM model 4 (Brown, Della Pietra, Della Pietra, &
Mercer, 1993) word-based translation model build sub-segmental TM learn wordlevel translation probabilities. done training IBM model 4 TM used
translation. source language (SL) segments target language (TL) segments
translation unit (TU) TM aligned word level using
Viterbi algorithm. Finally, sub-segmental TM built parallel phrases
similar way occurs modern phrase-based statistical MT systems (Koehn,
2010): parallel phrases identified pairs sub-segments
words SL side aligned word TL side NULL (unaligned),
vice versa. translation process carried two stages: first, occurrences
SL phrases sub-segmental TM translated using corresponding TL phrase;
second, words covered translated using word-level translation model learned
IBM model 4. similar approach proposed Langlais Simard (2002),
also use translation sub-segment level. case, segment translated split
sub-segments, online bilingual concordancer used find translations.
word-based SMT decoder Nieen, Vogel, Ney, Tillmann (1998) used
choose best sub-segments put best order according model.
Bicici Dymetman (2008) integrate phrase-based SMT (PBSMT) (Koehn, 2010)
system TM-based CAT system using discontinuous bilingual sub-segments.
PBSMT system trained TM, new source segment 0
translated, segments best matching TU used bias statistical
translation 0 towards . done augmenting translation table PBSMT
system bilingual sub-segments originating fuzzy match (S, )
source part common sub-sequence 0 , target part sub-sequence
detected aligned counterpart sub-sequence S. Simard
Isabelle (2009) propose similar approach new feature function introduced
linear model combination PBSMT system promote use bilingual
sub-segments originating best fuzzy match (S, ). Following similar approach,
Laubli, Fishel, Volk, Weibel (2013) use mixture-modeling technique (Foster & Kuhn,
2007) learn domain-adapted PBSMT system combining in-domain TM
173

fiEspla-Gomis, Sanchez-Martnez & Forcada

general parallel corpora. worth noting none three approaches guarantees
PBSMT system produce translation containing translation
sub-segments common 0 . contrast, Zhechev van Genabith (2010)
Koehn Senellart (2010), also use PBSMT system, guarantee subsegments detected aligned sub-segments matched
0 appear translation.
Example-based machine translation (EBMT) (Somers, 1999) also frequently
used take advantage TMs sub-segment level (Simard & Langlais, 2001). EBMT
systems based partial matches TMs, case TM CAT tools.
case, matching TUs aligned detect sub-segment pairs reused
translation. sub-segment pairs combined produce suitable
translation 0 . instance, commercial TM-based CAT tool Deja Vu 5 integrates
example-based MT order suggest candidate translations cases
exact match found, partial matches available (Garcia, 2005; Lagoudaki, 2008).
example-based-inspired MT system used propose translation putting together
sub-segments partial matchings available. Unfortunately, unable find
details method works.6 Approaches combine several MT systems
also available. example, Gough, Way, Hearne (2002) use several online MT
systems enlarge example database EBMT system. authors claim
permits better exploitation parallel information TM new translations.
approach differs described two ways. First, aforementioned
approaches use TM improve results MT, use MT translate sub-segments
TUs, MT-based approaches presented paper use MT improve
experience using TM-based CAT system without actually showing machine
translated material translator. Second, approaches above, sole exception
Gough et al. (2002), focus specific MT system family MT systems
(namely, SMT EBMT), whereas MT-based approaches use MT black box,
therefore able use one MT systems once. addition, MTbased approaches need access inner workings MT systems,
capable using MT systems available on-line (thus avoiding need
local installation) even source bilingual information dictionaries,
glossaries, terminology databases, sub-segment pairs bilingual concordancers.
works cited section, Zhechev van Genabith (2010)
Koehn Senellart (2010) use PBSMT, may easily extended order
use different MT system. approaches share similarities ours:
also try detect word phrase alignments source information find
parts translation proposal kept unedited. main difference
approach Zhechev van Genabith Koehn Senellart use
MT produce final translation segment translated, comes closer
MT TM-based CAT. One aims approach minimally disturb
way translators work TM-based CAT system keeping translation proposals
found TM.
5. http://www.atril.com [last visit: 15th May 2015]
6. usually called advanced leveraging (Garcia, 2012).

174

fiTarget-Language Edit Hints CAT Tools Based TM Means MT



[keep]

[edit]

[?]

[?]

tj

tj 0

tj 00

tj 000

?


si

si0

matched unmatched
0
0

si00
matched
0


?



000
si
si0000AA

matched
0

unmatched
0

Figure 2: Example possible word-alignments obtained pair segments (S, ). Target word tj may remain unedited aligned
source word si part matches 0 . Target word tj 0
may changed aligned source word si0
part match 0 . target word tj 00 aligned
source word S, evidence could used make recommendation it. case word tj 000 special, since aligned two
words, one matching 0 matching 0 , straightforward
recommendation cannot provided.

3. Word-Keeping Recommendation Based Statistical Word Alignment
section reviews first approach word-keeping recommendation, introduced Espla et al. (2011), used statistical word alignment detect words
kept edited translation proposal. Given segment 0 translated TU
(S, ) proposed TM-based CAT system, method first computes matching
0 aligns words using word-based statistical
translation models implemented GIZA++ (Och & Ney, 2003). Alignments used
follows: let tj word j-th position aligned word si ,
word i-th position S. si part matching 0 , indicates
tj might part translation 0 therefore remain unedited,
occurs word tj Figure 2. Conversely, si part match
0 , indicates tj might translation words 0
edited, occurs word tj 0 Figure 2. complex situations
TL word aligned one SL word tackled following voting scheme,
explained below. main limitation approach that, word tj
unaligned, occurs word tj 00 Figure 2, evidence could used
make recommendation it. Although might possible decide unaligned
words by, example, using aligned words surrounding them, wrong recommendation
could worse translator making recommendation all. idea
behind claim wrong keep recommendation may lead wrong translation,
would clearly undesirable.
order determine whether word tj target proposal changed
kept unedited, fraction words aligned tj common 0
175

fiEspla-Gomis, Sanchez-Martnez & Forcada

La
situacin
humanitaria
parece
ser


ul
ic



hu



di
ff



th
e

ita
ria
n
si
tu

io
ap n
pe
ar


difcil

Figure 3: Word alignments TU (la situacion humanitaria parece ser difcil,
humanitarian situation appears difficult).

computed:
X
fK (tj , 0 , S, ) =

matched(si )

si aligned(tj )

|aligned(tj )|

aligned(tj ) set source words aligned target word tj ,
matched(si ) equals 1 word si part match 0 , segment
translated, 0 otherwise. Function matched(x) based optimal edit path,7
obtained result word-based edit distance (Levenshtein, 1966) 0 .
fraction fK (tj , 0 , S, ) may interpreted likelihood keep word tj
unedited. mentioned above, tj may aligned several words S,
may common 0 others may not, occurs word tj 000 Figure 2.
Espla et al. (2011) propose two possible heuristics deal this:
unanimity: word tj , recommendation made aligned matched
words (fK () = 1), unmatched words (fK () = 0) S, recommendation made otherwise;
majority: heuristic uses voting scheme, tj aligned
matched words unmatched words (fK () > 21 ), recommendation made
kept, vice versa. tj aligned number
matched unmatched words (fK () = 21 ) recommendation made.
Let us suppose TU (S, ) = (la situacion humanitaria parece ser difcil,
humanitarian situation appears difficult) proposed order translate new
segment 0 = la situacion poltica parece ser difcil, word-alignment
7. may occur one optimal path available align two segments 0 . case,
one chosen arbitrarily.

176

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

(S, ) depicted Figure 3. words the, situation, would marked
kept, since aligned single word part matching
0 , compatible possible translation 0 =the political situation appears
difficult. word difficult would also marked kept, since, even though
aligned two words, part matching 0 . However,
evidence word humanitarian ambiguous; aligned words la
situacion, part matching, also humanitaria not.
unanimity criterion used, recommendation would made it,
use majority criterion would result keeping recommendation. Finally,
recommendation would made word appears, since aligned word.
main disadvantage approach requires word-alignment model
trained directly TM used translation order maximise coverage,
means re-training alignment model every time TM updated new TUs.
may also occur TM sufficiently large able obtain recommendations
acceptable quality, signifying necessary use external parallel corpora
order train models. Incremental training (Gao, Lewis, Quirk, & Hwang, 2011)
online training (Bertoldi, Farajian, & Federico, 2009) statistical word alignment models
could means reduce training time TM modified, even adapt
general alignment models specific domains, thus improving coverage.
case, incremental training would useful regards adapting existing models new
TM, on-line training would allow models updated new TU
added TM. However, paper focuses using machine translation source
bilingual information word-keeping recommendation: therefore keep original
word-alignment-based approach described Espla et al. (2011) use
reference comparing new approaches proposed here.

4. Word-Keeping Recommendation Binary Classification
work tackle problem word-keeping recommendation binary classification problem. new segment 0 TU (S, ) suggested translator
TM-based CAT system, set features computed word tj , binary
classifier used determine whether tj kept unedited changed (either
replaced deleted). Henceforth, shall refer approach trained MT-based
recommender, differentiate training-free MT-based recommender presented
Section 5.
features use based assumption MT, source
bilingual information, provide evidence whether word tj
changed kept unedited. Let sub-segment one matching TUs
(S, ), related MT sub-segment . related MT mean
machine translating leads , vice versa. hypothesise that:
words matching new segment translated 0 provide evidence
words kept unedited (keeping evidence);
words matching new segment translated 0 provide evidence
words changed (changing evidence).
177

fiEspla-Gomis, Sanchez-Martnez & Forcada

(la,the) [keeping evidence],
(situacion,situation) [keeping evidence],
(humanitaria, humanitarian) [changing evidence],
(ser,be) [keeping evidence],
(ser,to be) [keeping evidence],
(difcil,difficult) [keeping evidence],
(situacion humanitaria,humanitarian situation),
(ser difcil, difficult) [keeping evidence],
(la situacion humanitaria, humanitarian situation).

Figure 4: Example collection overlapping machine translated pairs subsegments (S, ) = (la situacion humanitaria parece ser difcil, humanitarian situation appears difficult). Sub-segment pairs (, )
matching matching highlighted bold type.

continue example proposed Section 3, which: (S, ) = (la situacion humanitaria parece ser difcil, humanitarian situation appears difficult), 0 =
la situacion poltica parece ser difcil, segment possible overlapping
sub-segments translate MT system obtain collection subsegment pairs (, ) matching (S, ) shown Figure 4. sub-segment pairs,
(parece, appear), included list translations subsegment one side match equivalents side. example, parece
translated English seems, appear translated Spanish aparecer.
pairs (, ) list words match 0 provide strong evidence
words corresponding target part kept unedited. example,
words the, situation, difficult, compatible possible translation
0 =the political situation appears difficult. Conversely, pairs (, )
words match 0 provide strong evidence words target part
changed. case, occurs word humanitarian.
hand, one word evidence obtained (appears)
matched MT system. case, possible provide translator
recommendations occurs, analogous reasons, alignment-based approach
described Section 3. Note pair (, ) =(situacion humanitaria,humanitarian
situation) contains source word (situacion) matches 0 another (humanitaria)
match 0 . Dealing ambiguous evidence, along combining
evidence different (, ) (which may contradictory) leads additional problem.
order deal ambiguous evidence, define three feature sets model combine keeping changing evidence, described Sections 4.1, 4.2,
4.3.
worth noting pre-processing methods could used order to, hopefully, exploit evidence bilingual sources information efficiently,
stemming/lemmatisation, morphological analysis, even integration syntactic features proposed Ma, He, Way, van Genabith (2011). However,
178

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

objective approach avoid complex processing order obtain fast recommendations translating texts pair languages, domain,
re-using already available sources bilingual information, numerous MT
systems available Internet.
4.1 Features Based Matching/Mismatching Sub-segments
Unconstrained Length Relations [MM-U]
feature set proposed Espla-Gomis et al. (2011) used reference
remaining feature sets proposed work. feature set considers, given
(, ) pair segments, that:
common sub-segment new segment translated 0
source segment S, likely words changed
(keeping evidence);
sub-segment 0 , likely words
changed (changing evidence).
seen, rather conservative criterion discards information
matching words partially matching sub-segment 0 S,8 probably
capable providing high accuracy recommending word kept.
flexible approach presented Section 4.2.
Based proposed rationale, four sets features computed: two sets keeping
features, provide information chances keeping tj , two sets changing
features, provide information chances changing tj . Given maximum
sub-segment length L, keeping feature set Km defined word tj every
value [1, L] follows:
Km (j, 0 , S, ) =

tcover(j, segm (S) segm (S 0 ), seg (T ), )
,
tcover(j, segm (S), seg (T ), )

segm (X) represents set possible m-word sub-segments segment X,
seg (X) similar segm (X) without length constraints, tcover(j, S, , )
defined as:
tcover(j, S, , ) = |{ : (, ) j span( , )}|,
seg (S), seg (T ), function span( , ) returns set word positions
spanned sub-segment segment .9 Function tcover(j, S, , ) therefore
computes number target sub-segments containing word tj related
MT sub-segment S.
Similarly Km , Kn computed using target sub-segments length n:
Kn (j, 0 , S, ) =

tcover(j, seg (S) seg (S 0 ), segn (T ), )
.
tcover(j, seg (S), segn (T ), )

8. example, sub-segment 5 words 4 matched one unmatched would
considered changing evidence.
9. Note sub-segment may found segment : function span( , ) returns
possible positions spanned.

179

fiEspla-Gomis, Sanchez-Martnez & Forcada

Analogously, changing feature sets Cm Cn defined as:
Cm (j, 0 , S, ) =

tcover(j, segm (S) segm (S 0 ), seg (T ), )
,
tcover(j, segm (S), seg (T ), )

Cn (j, 0 , S, ) =

tcover(j, seg (S) seg (S 0 ), segn (T ), )
.
tcover(j, seg (S), segn (T ), )

case four features, numerator denominator happen
zero pair (, ) covers tj , value feature set 12 .
four features computed every value 1 L 1 n L,
L maximum sub-segment length used, resulting 4L features. features
take values [0, 1] may probabilistic interpretation, 12 means dont
know. feature set termed MM-U features. similar collection
features tried constrained length (m) (n). However,
results confirmed improvement obtained adding feature set.
running example, show feature set could computed word be,
sixth word (t6 ). Please recall (S, ) = (la situacion humanitaria parece
ser difcil, humanitarian situation appears difficult). Using collection
translated pairs overlapping sub-segments shown Figure 4, three sub-segment
pairs (, ) cover word be:
= {(ser, be), (ser, be), (ser difcil, difficult)}.
pairs (, ) contain sub-segments [1, 2]. value function
tcover is:
tcover(6, seg1 (S), seg (T ), ) = |{be, be}| = 2
tcover(6, seg2 (S), seg (T ), ) = |{be difficult}| = 1
values m. addition, value tcover sub-segments match
0 is:
tcover(6, seg1 (S) seg1 (S 0 ), seg (T ), ) = |{be, be}| = 2
tcover(6, seg2 (S) seg2 (S 0 ), seg (T ), ) = |{be difficult}| = 1
value corresponding features therefore:
K1 (6, 0 , S, ) =

tcover(6, seg1 (S) seg1 (S 0 ), seg (T ), )
2
= =1
tcover(6, seg1 (S), seg (T ), )
2

K2 (6, 0 , S, ) =

tcover(6, seg2 (S) seg2 (S 0 ), seg (T ), )
1
= =1
tcover(6, seg2 (S), seg (T ), )
1

Features K1 (6, 0 , S, ) K2 (6, 0 , S, ) computed analogously. case
rather simple, since evidence available word indicates kept.
However, word situation (t3 ), keeping changing evidence coexist
set translated sub-segments pairs:
= {(situacion, situation), (situacion humanitaria, humanitarian situation),
(la situacion humanitaria, humanitarian situation)}
180

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

case, sub-segments take lengths [1, 3], produces following values
tcover():
tcover(3, seg1 (S), seg (T ), ) = |{situation}| = 1
tcover(3, seg2 (S), seg (T ), ) = |{humanitarian situation}| = 1
tcover(3, seg3 (S), seg (T ), ) = |{the humanitarian situation}| = 1
However, case, match 0 :
tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), ) = |{situation}| = 1
tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), ) = || = 0
tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), ) = || = 0
allows us compute following keeping features:
K1 (3, 0 , S, ) =

1
tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), )
= =1
tcover(3, seg1 (S), seg (T ), )
1

K2 (3, 0 , S, ) =

tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), )
0
= =0
tcover(3, seg2 (S), seg (T ), )
1

K3 (3, 0 , S, ) =

tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), )
0
= =0
tcover(3, seg3 (S), seg (T ), )
1

Analogously, changing features, have:
tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), ) = || = 0
tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), ) = |{humanitarian situation}| = 1
tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), ) = |{the humanitarian situation}| = 1
allow us obtain following features:
C1 (3, 0 , S, ) =

tcover(3, seg1 (S) seg1 (S 0 ), seg (T ), )
0
= =0
tcover(3, seg1 (S), seg (T ), )
1

C2 (3, 0 , S, ) =

1
tcover(3, seg2 (S) seg2 (S 0 ), seg (T ), )
= =1
tcover(3, seg2 (S), seg (T ), )
1

C3 (3, 0 , S, ) =

tcover(3, seg3 (S) seg3 (S 0 ), seg (T ), )
1
= =1
tcover(3, seg3 (S), seg (T ), )
1

case, ambiguity features managed binary classifier,
determine corresponding weights training.
181

fiEspla-Gomis, Sanchez-Martnez & Forcada

4.2 Features Based Partially Matching Sub-segments Constrained
Length Relations [PM-C]
feature set slightly different previous one regards way
evidence pairs sub-segments (, ) used. case, features
represent fraction words match 0 given word tj related
means sub-segment pairs (, ). worth noting previous feature set,
matching sub-segment pairs (, ) evaluated whole sub-segment . However,
new feature set, keeping changing features computed using
matched/unmatched words . objective feature set use positive
evidence partially matching sub-segments efficiently. following equation
W :
defines new keeping feature Kmn
W
Kmn
(j, 0 , S, )

=

|S|
X

stcover(j, k, segm (S), segn (T ), ) match(k, 0 , S)

k=1

j position tj , k position sk S, match(k, 0 , S) 1 sk
part match 0 , 0 otherwise,10 function stcover(j, k, S, , )
defined as:
stcover(j, k, S, , ) = |{(, ) : j span( , ) k span(, S)}|
W as:
Similarly, define changing feature Cmn

W
Cmn
(j, 0 , S, ) =

|S|
X

stcover(j, k, segm (S), segn (T ), ) (1 match(k, 0 , S)).

k=1

Function stcover(j, k, S, , ) differs tcover(j, S, , ) that, given pair
(, ), former takes account latter takes account
W
W C W complementary, whereas K
. makes Kmn
mn Cmn not. Kmn
mn
W may combined single normalised feature term KCW :
Cmn
mn
|S|
X
0
KCW
mn (j, , S, ) =

stcover(j, k, segm (S), segn (T ), ) match(k, 0 , S)

k=1
|S|
X
stcover(j, k, segm (S), segn (T ), )

,

(1)

k=1

feature set described Section 4.1, KCW
mn takes values [0, 1], and,
case, evidence found tj , value corresponding feature set 21 .
feature set results L2 features referred PM-C.
10. function match(k, 0 , S) based optimal edit path obtained result word-based
edit distance (Levenshtein, 1966) 0 S. Although frequent, may occur
one optimal paths available: case, one chosen arbitrarily.

182

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

running example, compute PM-C features word situation,
occurred Section 4.1. previous example, use collection translated
sub-segments Figure 4. set sub-segments pairs covering word situation is:
= {(situacion, situation), (situacion humanitaria, humanitarian situation),
(la situacion humanitaria, humanitarian situation)}
W (3, 0 , S, ), KC W (3, 0 , S, ), KC W (3, 0 , S, ) comand features KC1,1
2,2
3,3
puted them. seen stcover() happens different zero k = 1:

stcover(3, 1, seg1 (S), seg1 (T ), ) = |{(situacion, situation)}| = 1
case, see situacion (s2 ) related situation sub-segment pair
(, )=(situacion, situation). case, completely matches 0 , therefore
that:
|S|
X
stcover(3, k, seg1 (S), seg1 (T ), ) match(k, 0 , S)
W
KC1,1
(3, 0 , S, ) =

k=1
|S|
X

=

1
=1
1

stcover(3, k, seg1 (S), seg1 (T ), )

k=1
W (3, 0 , S, ) slightly complex. Here, stcover() happens
case KC2,2
different zero k [1, 2]:

stcover(3, 1, seg2 (S), seg2 (T ), ) =
|{(situacion humanitaria, humanitarian situation)}| = 1
stcover(3, 2, seg2 (S), seg2 (T ), ) =
|{(situacion humanitaria, humanitarian situation)}| = 1
observed, words situacion humanitaria related situation
pair (, )=(situacion humanitaria,humanitarian situation). Here, one
two words matches 0 , hence:
|S|
X
W
KC2,2
(3, 0 , S, ) =

stcover(3, k, seg2 (S), seg2 (T ), ) match(k, 0 , S)

k=1

=

|S|

X

1
= 0.5
2

stcover(3, k, seg2 (S), seg2 (T ), )

k=1
W (3, 0 , S, ), stcover() happens different zero
Finally that, KC3,3
k [1, 3]:

stcover(3, 1, seg3 (S), seg3 (T ), ) =
|{(la situacion humanitaria, humanitarian situation)}| = 1
183

fiEspla-Gomis, Sanchez-Martnez & Forcada

stcover(3, 2, seg3 (S), seg3 (T ), ) =
|{(la situacion humanitaria, humanitarian situation)}| = 1
stcover(3, 3, seg3 (S), seg3 (T ), ) =
|{(la situacion humanitaria, humanitarian situation)}| = 1
time, three words related situation, sub-segment
pair (, )=(la situacion humanitaria,the humanitarian situation). case, la
situacion match 0 , humanitaria not. resulting feature therefore:
|S|
X
W
KC3,3
(3, 0 , S, ) =

stcover(3, k, seg3 (S), seg3 (T ), ) match(k, 0 , S)

k=1

=

|S|

2
' 0.67
3

X
stcover(3, k, seg3 (S), seg3 (T ), )
k=1

Note feature collection constrains length time.
configuration also tried previous feature set (MM-U), improvements
obtained compared constraining lengths separately. feature
set possibilities also tried, constraining length
time proved lead better results.
4.3 Features Combining Partially Matching Sub-segments Constrained
Length Relations Information Coverage [PM-C+C]
Features KCW
mn may hide amount keeping/changing evidence, since
take account fraction keeping evidence total amount evidence.11
deal this, propose feature set defined Section 4.2 combined
new feature Emn :
Emn (j, S, ) = |{(, ) : segm (S) segn (T ) j span( , )}|

(2)

feature counts number sub-segment pairs (, ) covering word tj , thus providing measure amount evidence supporting value feature KCW
mn .
0 , S, ),
propose new feature set, 2L2 features, using KCW

E
(j,

mn
mn
referred PM-C+C. similar feature set tried, Emn normalised
dividing maximum number pairs (, ) could covered tj (m n).
However, set features show improvement therefore discarded.
running example, pairs (, ) cover word (t6 ) are:
= {(ser, be), (ser, be), (ser difcil, difficult)}.
Therefore, features Emn different zero word are:
E1,1 (6, S, ) = |{(ser, be)}| = 1
11. example, would 1 keeping evidence 1 evidence 5 keeping evidences
5 evidences; however, second case considered reliable, since evidence
confirms keeping recommendation.

184

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

E1,2 (6, S, ) = |{(ser, be)}| = 1
E2,2 (6, S, ) = |{(ser difcil, difficult)}| = 1
Given single pair (, ) covers word n, features
set 1. However, evidence (, )=(ser,be difficult) could used, value
E1,2 would become higher:
E1,2 (6, S, ) = |{(ser, be), (ser, difficult)}| = 2

5. Word-Keeping Recommendation Based MT Alignment Strengths
collection sub-segment pairs (, ) related MT used wordkeeping recommendation directly, i.e., without run training procedure.
propose using training-free MT-based recommender based alignment
strengths described Espla-Gomis, Sanchez-Martnez, Forcada (2012a) EsplaGomis et al. (2012b). metric determines relatedness association strength
j-th word k-th word defined as:
L X
L
X
stcover(j, k, segm (S), segn (T ), )
A(j, k, S, ) =
mn
m=1 n=1

alignment strength based idea matched sub-segment pairs apply pressure
words, signifying larger surface covered sub-segment pair, lower
pressure applied individual word. Figure 5 shows words TU
covered bilingual sub-segments (left), result computing alignment
strengths (right).
order perform word-keeping recommendation using alignment strengths,
define function G(j, 0 , S, ) computes fraction alignment strength
relates word tj words sk part matching 0 S,
sum alignment strength words S:
|S|
X

G(j, 0 , S, ) =

A(j, k, S, ) match(k, 0 , S)

k=1
|S|
X
A(j, k, S, )

(3)

k=1

Word keeping recommendation performed following simple manner:
G(j, 0 , S, ) 21 , word tj marked changed, otherwise kept.
evidence (, ) spanning tj , recommendation provided tj .
worth noting A(j, k, S, ) similar particular linear combination
PM-C feature set described Section 4.2, weight feature directly set
1
mn
, rather chosen optimising recommendation accuracy training
set. results shown Section 6 prove method less accurate trained
MT-based approach, still provides reasonably good results.
185

fiEspla-Gomis, Sanchez-Martnez & Forcada

La

La 1.11 0.11 0.11

situacin

situacin 0.11 0.36 1.36

humanitaria

humanitaria 0.11 1.36 0.36

ul
ic

hu



di
ff

ul
ic

di
ff

hu





0.25 1.25



difcil


difcil

th
e

ita
ria
n
si
tu

io
ap n
pe
ar


0.50 1.75 0.25



ser



ser



parece

th
e

ita
ria
n
si
tu

io
ap n
pe
ar


parece

Figure 5: Sub-segment pairs covering words TU (la situacion humanitaria parece
ser difcil, humanitarian situation appears difficult) (left),
alignment strengths obtained (right). weight sub-segment
pair taken 1 divided surface covers compute
pressure exerted individual word.

running example, use scores shown Figure 5; seen, word
situation related three words: La, score 0.11, situacion, score 1.36,
humanitaria, score 0.36. value G(3, 0 , S, ) therefore:
G(3, 0 , S, ) =

0.11 1 + 1.36 1 + 0.36 0
1.47
=
' 0.8
0.11 + 1.36 + 0.36
1.83

case, G(3, 0 , S, ) > 12 , means word situation must remain unedited.
However, humanitarian, related words Spanish, have:
G(2, 0 , S, ) =

0.47
0.11 1 + 0.36 1 + 1.36 0
=
' 0.3
0.11 + 0.36 + 1.36
1.83

Since G(2, 0 , S, ) 21 , word humanitarian would marked changed.

6. Experimental Settings
experiments conducted consisted simulating translation texts several
language pairs text domains. language pairs involved experiments
GermanEnglish (deen), EnglishGerman (ende), EnglishSpanish (enes), Spanish
English (esen), EnglishFinnish (enfi), FinnishEnglish (fien), EnglishFrench (enfr),
FrenchEnglish (fren), SpanishFrench (esfr), FrenchSpanish (fres). Three
thematic TMs created language pair extracting domain-specific TUs
DGT-TM (Steinberger, Eisele, Klocek, Pilos, & Schluter, 2012), TM published
European Commission Directorate-General Translation (European Commission
Directorate-General Translation, 2009).
186

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

compared two MT-based approaches described Sections 4 5 nave
baseline also based binary classifier, using fuzzy-match score
(FMS) 0 feature, (henceforth FMS-only baseline, see Section 6.5),
statistical word-alignment-based approach described Section 3, different
scenarios. first evaluated approaches optimal case, models
(either word-alignment models classification models) trained TM used
translating, and, case MT-based approaches, employing MT system
used translation. evaluation extended evaluate:
reusability across domains: word-alignment models classification models trained out-of-domain TMs;
reusability across MT systems: models trained TM used
translation, using different MT system;
reusability across language pairs: models trained TM
domain used translation, different language pair, obviously,
using different MT system.
reusability across MT systems evidently evaluated case MT-based
approaches. regards reusability across language pairs, one hand, FMS-only
baseline language independent, other, statistical word-alignment models
used alignment-based approach trained pair languages
used translation.
extensive evaluation allow us ascertain degree independence
recommendation model regard domain TM, MT system,
language pair used training. key point, since high independence
part variables would allow computer-aided translation (CAT) users reuse existing
feature weights obtained without run training procedure change
domain texts translated, MT system use even languages
working with. case domain independence particularly relevant since
covers problem using different TM, also case new TUs
seen training added TM.
regard MT systems, used statistical MT system Google,12
Power Translator (Depraetere, 2008) version 15,13 free/open-source, shallow-transfer
MT system Apertium (Forcada et al., 2011).14 Unfortunately, MT systems mentioned available language pairs. Table 1 shows MT system(s)
available language pair included experiments.
Even though used large data sets batch mode obtain results reported
paper, wanted ensure MT-based approaches would able provide
recommendations real time translation tasks. main part computation
time MT-based approaches spent segmenting machine-translating
resulting sub-segments. order prove could done real MT-based
12. http://translate.google.com [last visit: 15th May 2015]
13. http://www.lec.com/power-translator-software.asp [last visit: 15th May 2015]
14. http://www.apertium.org [last visit: 15th May 2015]

187

fiEspla-Gomis, Sanchez-Martnez & Forcada

Language pair
GermanEnglish (deen)
EnglishGerman (ende)
EnglishSpanish (enes)
SpanishEnglish (esen)
EnglishFinnish (enfi)
FinnishEnglish (fien)
EnglishFrench (enfr)
FrenchEnglish (fren)
SpanishFrench (esfr)
FrenchSpanish (fres)

Apertium

3
3

3
3

Google Translate

Power Translator

3
3
3
3
3
3
3
3
3
3

3
3
3
3

3
3
3
3

Table 1: MT systems available translation direction () used experiments.

CAT scenario, prototype15 plug-in implementing training-free approach built
free/open-source CAT system OmegaT16 and, experiments using on-line
MT systems Apertium Google Translate, confirm recommendations
obtained almost instantaneously.
6.1 Evaluation
FMS-only baseline, statistical alignment-based approach proposed Section 3,
MT-based approaches proposed Sections 4, 5 tested using test set
(TS) parallel segments {(Sl0 , Tl0 )}N
domain. SL segment
l=1 , TM
0
N
0
Sl TS, set matching TUs {(Si , Ti )}i=1 TM FMS threshold
obtained. Please recall FMS measures similarity translation
proposals segments translated. FMS threshold usually set values
60% (Bowker, 2002, p. 100) experiments therefore used several values
60% 90%.17 set matching TUs obtained,
recommendations every word tj every target-language segment Ti obtained
evaluated using Tl0 , translation Sl0 , gold standard. words Tl0 Ti
matched using Levenshtein edit distance (Levenshtein, 1966), allows us
check whether given word tj , j-th word Ti , actually kept final
translation. thus possible determine whether recommendation tj successful
if:
tj recommended changed Ti match word Tl0 ,
tj recommended kept Ti match word Tl0 .
15. http://www.dlsi.ua.es/~mespla/edithints.html [last visit: 15th May 2015]
16. http://www.omegat.org [last visit: 15th May 2015]
17. MT-based approaches require training, different models trained every value
included experiments.

188

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

pairs (Sl0 , Tl0 ) TS used obtain corresponding sets
0
matching TUs {(Si , Ti )}N
i=1 , recommendations obtained checked,
several metrics used evaluation. Accuracy (A) computed fraction successful recommendations total number words recommendation
made. worth noting methods proposed provide recommendations words; another interesting metric therefore fraction
words covered (NC) system, is, fraction words recommendation made. combination two metrics helps us understand
method perform test set. addition accuracy fraction words covered, also compute precision recall regards keeping
recommendations (PK RK , respectively) changing recommendations (PC
RC , respectively). latter metrics useful since provide specific information
successful keeping recommendations change recommendations, separately,
NC provide information general performance recommender.
code used perform experiments freely available license GNU General Public License v3.0 (Free Software Fundation, 2007) downloaded
http://transducens.dlsi.ua.es/~mespla/resources/wkr/.
6.2 Corpora
corpus used experiments DGT-TM (Steinberger et al., 2012). translation memory collection documents Official Journal European Union 18
aligned segment level several languages (multilingual TUs). Segment
alignment DGT-TM expected high level quality, since part alignments manually checked, actually generated computer-aided translation
professional translators.
TUs DGT-TM contain segments many official languages European Union
labelled domain codes19 used create three domain-specific TU
collections. done using following domain codes: elimination barriers
trade (code 02.40.10.40), safety work (code 05.20.20.10), general information
public contracts (code 06.30.10.00). TUs containing corresponding segments
five languages used experiments included TU collections.
collection TUs used build bilingual TM test set language pair randomly selecting pairs segments without repetition.20 addition
pre-processing already performed creators DGT-TM (European Commission
Joint Research Center, 2007) segments included TMs test set used
experiments tokenised lowercased. TMs consist 6, 000 TUs each,
simulate TM translator may use translating CAT tool. test set
consist 1, 500 TUs whose source language side simulates segments translated
using TMs (the translators job), target language side may considered
reference translation segment translated.
18. http://eur-lex.europa.eu [last visit: 15th May 2015]
19. http://old.eur-lex.europa.eu/RECH_repertoire.do [last visit: 15th May 2015]
20. TMs test set obtained way downloaded http://transducens.dlsi.ua.
es/~mespla/resources/mtacat/ [last visit: 15th May 2015]

189

fiEspla-Gomis, Sanchez-Martnez & Forcada

02.40.10.40
02.40.10.40
05.20.20.10
06.30.10.00

05.20.20.10

(8o )

(76o )

0.99
0.26 (75o )
0.24 (76o )

0.24
0.98 (11o )
0.23 (76o )

06.30.10.00
0.20 (78o )
0.23 (76o )
0.97 (14o )

Table 2: Cosine similarity (and corresponding angle) English side
EnglishSpanish TMs belonging three domains experiments: elimination barriers trade (code 02.40.10.40), safety work (code 05.20.20.10),
general information public contracts (code 06.30.10.00).

domains chosen experiments little overlap vocabulary, evidenced
cosine similarity measure shown Table 2.21 technique maps text onto
vocabulary vector, word dimension number occurrences
word text value dimension. vocabulary vectors
used compare two texts computing cosine angle them. cosine
similarity computed using English side three EnglishSpanish TMs
splitting 6,000 segments two halves. table shows cosine similarity
first half domain (rows) second half (columns).
noted, cosines vocabulary vectors domain
close 1, angles 8o 14o . However, cosines
vocabulary vectors different domains much smaller, angles 75o
79o . therefore conclude considerable differences TMs
used experiments.
regards number TUs matched simulating translation Spanish
segments English test set, Table 3 reports, fuzzy-match scores four different
ranges, average number TUs matched per segment translated total
number words provide recommendation. data provide idea
repetitiveness corpora used carry experiments. seen,
corpus domain 02.40.10.40 repetitive two. worth noting
domains 05.20.20.10 06.30.10.00 notable differences low values FMS
threshold , differ much higher values.
6.3 Fuzzy-Match Score Function
experiments, many TM-based CAT systems, chosen fuzzy-match
score function based word-based Levenshtein edit distance (Levenshtein, 1966):
FMS(S 0 , S) = 1

D(S 0 , S)
max(|S 0 |, |S|)

21. cosine similarity computed lowercased corpora, removing punctuation characters
stopwords provided 4.7.2 version Lucene: http://lucene.apache.org/core/ [last visit: 15th
May 2015].

190

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

(%)

filtering

domain

TUavg

Nwords

60

02.40.10.40
05.20.20.10
06.30.10.00

3.71
0.62
5.68

95,881
9,718
34,339

70

02.40.10.40
05.20.20.10
06.30.10.00

2.36
0.37
0.99

65,865
6,883
10,327

80

02.40.10.40
05.20.20.10
06.30.10.00

1.58
0.14
0.45

46,519
3,015
4,726

90

02.40.10.40
05.20.20.10
06.30.10.00

0.70
0.05
0.03

26,625
1,599
1,268

Table 3: Average number matching TUs (TUavg ) per segment total number target
words (Nwords ) recommendation provided translating
Spanish English three different domains. results obtained
different values FMS threshold ().

|x| length (in words) string x D(x, y) refers word-based Levenshtein
edit distance x y.22
6.4 Binary Classifier
Espla-Gomis et al. (2011) used simple perceptron classifier defined, translation source segment 0 , probability keeping j-th word , targetlanguage segment TU (S, ) as:
pk (j, 0 , S, ) =

1
1+

eg(j,S 0 ,S,T )

(4)


0

g(j, , S, ) = 0 +

NF
X

k fk (j, 0 , S, ).

(5)

k=1

perceptron uses sigmoid function incorporates linear combination
different features fk corresponding weights k learned classifier.
22. Many TM-based CAT tools implement variations FMS rank translation proposals regards
edition effort required (for instance, disregarding punctuation signs numbers 0 ,
using stemmed versions 0 ). experiments continue use original FMS, since
ranking important experiments. owing fact proposals
threshold evaluated, highest score.

191

fiEspla-Gomis, Sanchez-Martnez & Forcada

work, complex multilayer perceptron (Duda, Hart, & Stork, 2000, Section 6) used, namely, implemented Weka 3.7 (Hall et al., 2009). Multilayer
perceptrons (also known feedforward neural networks) complex structure
incorporates one hidden layers, consisting collection H perceptrons, placed
input classifier (the features) output perceptron. hidden
layer makes multilayer perceptrons suitable non-linear classification problems (Duda
et al., 2000, Section 6). fact, Hornik, Stinchcombe, White (1989) proved neural
networks single hidden layer containing finite number neurons universal
approximators may therefore able perform better simple perceptron
complex problems. case, output perceptron provides classification takes
output hl perceptrons H input. Eq. (5) therefore needs
updated follows:
0

g(j, , S, ) = 0 +

|H|
X

l hl (j, 0 , S, ).

(6)

l=1

perceptron hl H works similarly perceptron described eq. (4):
hl (j, 0 , S, ) =

1
1 + egl (j,S 0 ,S,T ) )


gl (j, 0 , S, ) = l0 +

NF
X

lk fk (j, 0 , S, ).

k=1

seen, besides collection weights main perceptron, different
collection weights 0l needed perceptron hl hidden layer H.
weights obtained using backpropagation algorithm (Duda et al., 2000, Section
6.3) training, updates using gradient descent error function.
case, used batch training strategy, iteratively updates weights order
minimise error function. training process stops error obtained
iteration worse obtained previous 10 iterations.23
validation set 10% training examples used training,
weights therefore iteratively updated basis error computed
90%, decision stop training (usually referred convergence condition)
based validation set. usual practice whose objective minimise
risk overfitting.
Hyperparameter optimisation carried using grid search (Bergstra, Bardenet,
Bengio, & Kegl, 2011) strategy based accuracy obtained EnglishSpanish
TM 02.40.10.40 domain. 10-fold cross-validation performed training
corpus order choose following hyperparameters:
23. usual set number additional iterations error stops improving, case function
local minimum, error starts decreasing iterations. error
continues worsen 10 iterations, weights used obtained iteration
lowest error.

192

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

Number nodes hidden layer : Weka (Hall et al., 2009) makes possible
choose among collection predefined network designs; best
performed training corpus number nodes
hidden layer number features.
Learning rate: parameter allows dimension weight updates regulated applying factor error function iteration; value
best performed experiment 0.4.
Momentum: updating weights end training iteration, momentum
modifies new value, signifying depends current gradient
direction, also previous weight value. objective technique
smooth training process faster convergence. case experiments,
set 0.1.
6.5 Reference Results
mentioned previously, performance two MT-based approaches proposed
work compared two different approaches: nave FMS-only baseline,
uses classifier described Section 6.4 employs FMS 0
feature, approach reviewed Section 3, uses statistical word alignment
relate words two segments TU (S, ). nave FMS-only baseline
trained datasets described Section 6.2 different values FMS threshold
. worth mentioning resulting models classify target words
kept. consequence fact that, value FMS training
set, words kept changed.
alignments used alignment-based approach obtained means
free/open-source MGIZA++ toolkit (Gao & Vogel, 2008), implementation
GIZA++ toolkit (Och & Ney, 2003) eases task training alignment models
parallel corpus aligning different one using models learned. wordbased alignment models (Brown et al., 1993; Vogel, Ney, & Tillmann, 1996) separately
trained TMs defined Section 6.2 JRC-Acquis 3.0 (Steinberger et al.,
2006) corpus (a large multilingual parallel corpus includes, among others, texts
TMs, given built texts DGT-TM).24 alignments
used result running MGIZA++ translation directions (source-totarget target-to-source) symmetrising sets alignments means
usual grow-diag-final-and (Koehn et al., 2005) heuristic. symmetrisation technique
found provided best compromise coverage accuracy
word-keeping recommendation (Espla et al., 2011).25
Table 4 shows accuracy obtained nave FMS-only baseline. fraction
words covered, is, words recommendation provided,
included table since baseline provides recommendation every word
24. https://ec.europa.eu/jrc/en/language-technologies/jrc-acquis [last visit: 15th May 2015]
25. Symmetrisation necessary MGIZA++ produces alignments source word
aligned many target words, whereas target word aligned one source word.
use symmetrisation allows alignments combined directions order obtain N
alignments.

193

fiEspla-Gomis, Sanchez-Martnez & Forcada

(%)

A(%)

60
70
80
90

82.69.24
88.37.25
91.65.25
93.98.29

Table 4: Accuracy A(%) obtained nave FMS-only baseline translating
enes domain 02.40.10.40. Accuracy obtained different FMS thresholds
. language pairs domains behave way.

test set. due fact nave FMS-only baseline depend
coverage source information.
general, see accuracy obtained nave FMS-only baseline
quite high. is, fact, hard-to-beat nave baseline, although results
reasonable, since relatively high values FMS threshold imply high
number words kept unedited translation proposals.
regard alignment-based approach, several options evaluated order
choose configuration. one hand, tried two decision criteria described
Section 3 (unanimity majority). hand, tried two alignment models:
one trained translation memory used experiments (as occurred
trained MT-based recommender), another trained JRC Acquis parallel
corpus. objective comparing models confirm corpus
adequate regards training alignment-based recommender: one reduced
domain focused, one bigger generic, although still containing
text domain. results presented Table 5, accuracy
percentage words covered measured four combinations decision
criteria training corpora. already mentioned Section 3, unanimity criterion
focused accuracy, majority criterion focused coverage.
order confirm method better, statistical significance test performed
results obtained using approximate randomisation test.26 free/open-source
tool SIGF V.2 (Pado, 2006) used statistical significance testing results
described throughout section. test confirmed cases alignment
models trained TM used testing outperform trained JRC Acquis
corpus. approach trained TM used testing used experiments
shown following section, decision criterion used unanimity,
reason consider accuracy relevant coverage wordkeeping recommendation, since mentioned above, believe better make
recommendation make wrong one.
26. Approximate randomisation compares difference accuracy/coverage two classifiers
test set. method randomly interchanges predictions classifiers every
instance test set. difference accuracy/coverage randomised datasets
compared original set. process iterativelly repeated confirm whether results
regards randomised predictions consistently worse original results.

194

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

(%)

training 02.40.10.40

method

training JRC Acquis

(%)

NC (%)

(%)

NC (%)

60

unanimity
majority

93.90.16
92.96.17

6.09.15
4.39.13

93.14.17
93.05.17

6.29.15
5.39.14

70

unanimity
majority

94.32.18
93.47.19

5.90.18
4.45.16

93.67.19
93.59.19

6.15.18
5.42.17

80

unanimity
majority

95.10.20
94.49.21

5.37.21
4.31.19

94.56.21
94.52.21

5.87.21
5.33.20

90

unanimity
majority

95.34.26
95.10.27

4.93.26
4.35.25

94.97.27
94.95.27

5.48.27
5.04.26

Table 5: Accuracy (A) fraction words covered (NC) obtained alignmentbased approach described Section 3 different FMS thresholds , translating Spanish English domain 02.40.10.40. results show accuracy
obtained using model trained TM belonging 02.40.10.40 domain JRC-Acquis corpus, using unanimity majority
decision criteria. behaviour also observed remaining TMs used
experiments. Statistically significant differences accuracy approach different values p 0.05 highlighted bold type,
also occurs fraction words covered.

7. Results Discussion
section present results obtained two approaches proposed paper
compare performance nave FMS-only baseline alignment-based
approach Espla et al. (2011). large amount variables taken consideration
(feature sets, language pairs, domains, MT systems, sub-segment length) forced us
select experiments performed. parameters therefore chosen basis
results obtained translation Spanish English, language
pair used Espla et al. (2011) Espla-Gomis et al. (2011). domain chosen
preliminary experiments elimination barriers trade (02.40.10.40), higher
matching rates (see Table 3) therefore data obtained.
7.1 Parameter Selection
first attempted determine optimal sub-segment maximum length L experiments training-free recommender trained recommender. Table
6 shows fraction words covered depending value L recommenders together. fraction words covered 16% 19% using
sub-segments one word, percentage diminishes context provided
translations. seen, fraction words covered starts stabilise
L = 4, since difference L = 5 0.25%.
Table 7 shows impact value L accuracy obtained trainingfree recommender trained recommender using different sets features
195

fiEspla-Gomis, Sanchez-Martnez & Forcada

(%)
60
70
80
90

Fraction words without recommendation (%)
L=1

L=2

L=3

L=4

L=5

16.42.24
16.74.28
17.37.34
18.18.46

10.22.19
10.66.24
11.25.29
11.80.39

7.24.16
7.34.20
7.65.24
8.05.33

5.13.14
5.18.17
5.53.21
5.86.28

4.90.14
4.94.17
5.29.20
5.59.28

Table 6: Percentage words covered MT-based approaches enes language pair domain 02.40.10.40 using combination MT systems available.
fraction words covered obtained different FMS thresholds
using different values maximum sub-segment length L.

(%)

Accuracy (%) classification

Method
L=1

L=2

L=3

L=4

L=5

60

MM-U
PM-C
PM-C+C
training-free

93.51.17
93.62.17
93.59.17
93.63.17

93.40.17
94.07.16
94.36.15
93.78.16

93.58.16
94.31.15
94.57.15
93.79.16

93.57.16
94.18.15
95.14.14
93.27.16

93.77.16
94.37.15
95.41.14
92.90.17

70

MM-U
PM-C
PM-C+C
training-free

94.79.19
94.75.19
94.81.19
94.76.19

94.72.18
94.89.18
95.16.17
94.77.18

94.77.18
95.12.17
95.33.17
94.77.18

94.70.18
94.94.17
95.63.16
94.14.18

94.82.17
95.05.17
95.92.16
93.78.19

80

MM-U
PM-C
PM-C+C
training-free

96.09.19
96.09.19
96.11.19
96.05.20

96.14.19
96.14.19
96.24.18
95.97.19

95.92.19
96.11.18
96.34.18
95.88.19

96.00.18
96.01.18
96.39.17
95.29.20

96.02.18
95.98.18
96.58.17
94.98.20

90

MM-U
PM-C
PM-C+C
training-free

96.84.23
96.84.23
96.84.23
96.80.23

96.85.22
96.82.23
96.95.22
96.72.23

96.80.22
96.87.22
96.95.22
96.70.22

96.74.22
96.85.22
96.90.21
96.61.22

96.75.22
96.87.22
97.00.21
96.42.23

Table 7: Accuracy obtained trained MT-based recommender using different
feature combinations described Section 4 training-free MT-based
recommender enes language pair. Accuracy obtained different
FMS thresholds using different values maximum sub-segment length
L. Statistically significant accuracy results L = 4 (the value L
used remaining experiments) p 0.05 highlighted bold type.

196

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

described Section 4. seen, accuracy training-free system drops
slightly longer sub-segments introduced. reasonable since longer subsegments used, higher number words recommendation made (see
Table 6). Words covered long sub-segments difficult
classify, since sub-segments contain evidence regarding words therefore
less precise. interesting observe that, case feature sets,
trained recommender behave manner, since able learn reliable
longer sub-segments are. case feature set MM-U, accuracy almost
constant values L, means using longer sub-segments
impact accuracy case. event, worth noting
results obtained using training-free recommender quite accurate, confirms
sub-segment pairs discovered using MT good source information wordkeeping recommendation. Moreover, results indicate long sub-segments less
informative short sub-segments. general, small improvements accuracy
coverage occur values L higher 4. remaining experiments
section therefore performed L = 4.
results Table 7, namely column L = 4, also used
determine best feature combination trained MT-based recommender.
first glance, set features based matching words, namely PM-C (see Section 4.2),
PM-C+C (see Section 4.3), perform best. commented Section
4.2, MM-U features consider partial matching sub-segments negative evidence,
PM-C PM-C+C also attempt extract positive evidence sub-segments,
thus using bilingual information efficiently. However, results obtain
close, particularly case high values . statistical significance test
confirmed PM-C+C superior feature combinations value
p 0.05. feature set PM-C+C therefore used trained classifier
approach remaining experiments section.
accuracy obtained using approaches presented previous
section lower expected, particularly considering results obtained EsplaGomis et al. (2011) Espla et al. (2011) trained MT-based approach
alignment-based approach obtained average accuracy 5% higher
obtained experiments. intuition leads us believe drop
accuracy may due fact data sets used previous works might
cleaner used here. confirm this, additional set experiments carried
using additional cleaning criteria ensure quality datasets used
evaluation. results study presented Appendix B.
7.2 General Results
parameters chosen (maximum sub-segment length L = 4 MT-based approaches,
PM-C+C feature set trained MT-based approach, unanimity criterion
models trained TM used experiments alignment-based approach)
used perform several experiments order check performance system.
Tables 8 9 show results obtained trained MT-based recommender
translating Spanish segments English. Table 8, different MT systems available
197

fiEspla-Gomis, Sanchez-Martnez & Forcada

(%)
60
70
80
90

Apertium

Google Translate

Power Translator

(%)

NC (%)

(%)

NC (%)

(%)

NC (%)

94.61.17
95.40.19
96.49.20
97.25.23

27.89.28
28.32.34
28.39.41
28.49.54

95.08.14
95.54.16
96.34.18
96.99.21

6.22.15
6.38.19
6.52.22
6.31.29

94.52.17
95.47.19
96.46.20
97.01.24

28.99.29
29.62.35
29.59.42
28.50.54

Table 8: Accuracy (A) fraction words covered (NC) obtained translating
esen domain 02.40.10.40 trained MT-based approach. results
obtained separate use MT systems available language
pair: Apertium, Google Translate, Power Translator. every value ,
results supersede rest statistically significant margin p 0.05
highlighted bold type, accuracy fraction words
covered.

used separately obtain recommendations 02.40.10.40 domain. results
confirm that, accuracy remains stable,27 coverage strongly depends MT system.
may interpreted follows: MT-based approaches robust bilingual sources
information low coverage. experiments confirmed best coverage
obtained Google Translate, whereas Apertium Power Translator produce similar
results. However, Apertium Power Translator produce higher precision change
recommendations, three MT systems perform similarly regards precision
keep recommendations.
Table 9 compares performance alignment-based approach trained
MT-based recommender three MT systems available used time
language pair esen. table shows results obtained separately
alignment-based approach trained MT-based approach regards three domains: 02.40.10.40, 05.20.20.10 06.30.10.00. results quite similar
approaches. MT-based approach slightly outperforms alignment-based approach
accuracy, results alignment-based approach better coverage, particularly case 06.30.10.00 domain. event, leads us believe
approaches obtain comparable results across domains.
Tables 10 11 present results regards accuracy fraction words
covered, respectively, obtained trained MT-based approach
alignment-based approach language pairs. case trained MT-based
approach, MT systems available used (Table 1 lists MT systems available
language pair).
results confirm hypothesis alignment-based approach generally obtains
better results regards coverage MT-based approach language pairs,
reasonable, given alignment models trained TM
used translation. Accuracy yet strongest point trained MT27. Although differences accuracy observed, possible state MT system
better statistical significance p 0.05 case =60% =90%.

198

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

02.40.10.40

(%) method

(%)
trained
alignment
trained
70
alignment
trained
80
alignment
trained
90
alignment

60

95.14.1
93.90.2
95.63.2
94.32.2
96.39.2
95.10.2
96.90.2
95.34.3

05.20.20.10

NC (%)
5.13.1
6.09.2
5.18.2
5.90.2
5.53.2
5.37.2
5.86.3
4.93.3

(%)

06.30.10.00

NC (%)

95.62.4
92.97.5
97.02.4
94.16.6
95.78.8
94.56.8
95.361.1
94.261.2

7.20.5
6.22.5
6.44.6
5.96.6
10.421.1
5.51.8
11.131.5
5.191.1

(%)

NC (%)

94.87.3
91.38.3
94.93.5
94.57.5
95.00.7
95.20.6
97.65.9
96.471.1

11.33.3
18.31.4
10.55.6
7.78.5
12.841
4.80.6
9.311.6
6.151.3

Table 9: Accuracy (A) fraction words covered (NC) obtained trained
MT-based approach alignment-based approach translating esen
three different domains using MT systems. corpus
value , statistical significance test performed approaches
regards accuracy fraction words covered. results
show improvement statistically significant p 0.05
highlighted bold type.

60(%)
lang.
pair
esen
enes
deen
ende
fren
enfr
fien
enfi
esfr
fres

trained
95.1.1
90.0.2
94.2.2
88.9.2
95.2.1
89.7.2
93.2.2
89.1.2
91.2.2
89.4.2

70(%)

alignment

trained

93.9.2
88.7.2
92.6.2
87.9.2
93.4.2
89.4.2
91.9.2
87.1.2
89.4.2
88.6.2

95.5.2
91.5.2
95.8.2
91.1.2
96.3.2
91.9.2
94.6.2
90.2.3
93.2.2
92.1.2

alignment
94.3.2
89.8.2
93.8.2
89.7.2
95.1.2
91.3.2
93.1.2
88.5.3
90.7.2
91.1.2

80(%)
trained
96.3.2
92.3.2
96.6.2
93.0.2
97.0.2
93.3.2
94.7.2
90.3.3
94.8.2
93.5.2

alignment
95.1.2
90.4.2
94.7.2
91.5.2
96.0.2
92.1.2
93.3.3
88.4.3
92.8.2
92.2.2

90(%)
trained

alignment

97.0.2
93.0.2
97.2.2
92.8.3
97.6.2
95.7.2
94.8.3
90.6.4
96.0.2
93.6.3

95.3.3
91.8.3
95.5.3
91.5.3
96.4.2
94.3.3
92.8.4
88.9.4
94.3.2
92.2.3

Table 10: Accuracy (A) obtained trained MT-based approach
alignment-based approach translating language pairs
domain 02.40.10.40. results obtained several values FMS
threshold using available MT systems language pair.
language pair value , statistical significance test performed
accuracy obtained approaches. results show
improvement statistically significant p 0.05 highlighted
bold type.

199

fiEspla-Gomis, Sanchez-Martnez & Forcada

60(%)
lang.
pair

trained

esen
enes
deen
ende
fren
enfr
fien
enfi
esfr
fres

6.2.1
7.3.1
10.5.2
11.6.2
7.7.2
7.9.1
11.2.2
11.6.2
17.8.2
19.5.2

alignment
6.1.1
7.7.1
5.8.1
5.6.1
4.3.1
5.9.1
9.9.2
7.2.2
4.9.1
10.3.1

70(%)

80(%)

trained

alignment

trained

6.4.2
8.3.2
10.7.2
12.4.2
7.7.2
8.8.2
11.3.3
11.0.3
18.4.2
19.4.3

5.9.2
8.8.2
6.2.2
6.2.2
4.1.2
6.0.2
10.2.2
7.0.2
4.9.1
9.5.2

6.5.2
8.6.2
10.9.3
13.0.3
8.1.3
9.6.2
11.5.3
12.0.3
18.6.3
20.4.3

alignment
5.4.2
9.4.2
6.0.2
6.5.2
4.2.2
6.0.2
10.6.3
7.2.2
5.0.2
10.5.2

90(%)
trained

alignment

6.3.3
9.5.3
12.4.4
14.5.4
7.6.3
9.4.3
11.6.4
12.6.4
21.2.4
17.6.4

4.9.3
10.7.3
6.0.3
6.6.3
3.5.2
7.8.3
10.9.4
8.0.3
5.6.2
5.9.2

Table 11: Fraction words covered (NC) obtained trained MT-based
approach alignment-based approach translating
language pairs domain 02.40.10.40. results obtained several values FMS threshold using available MT systems language
pair. language pair value , statistical significance
test performed fraction words covered obtained
approaches. results show improvement statistically significant p 0.05 highlighted bold type.

200

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

based recommender. Another interesting detail experiments language pairs
English target language obtain better accuracy experiments
inverse language pairs. due fact DGT-TM, usual find free
translations languages English, original language
documents TM.28 particularly frequent find additional information
technical English words languages. example, software translated
Spanish, translated segments include text equipo logico (software).
translation includes correct translation original word, order keep
meaning original English segment. important issue since, free
translations used reference evaluate accuracy approaches presented
work, lead lower accuracy. problem analysed, partially bypassed,
additional experiments presented Appendix B. seen, trained MT-based
approaches provide, general, better accuracy. However, language pairs,
coverage obtained alignment-based approach much better. Nevertheless
results still reasonably similar considered comparable.
Table 12 shows results obtained different approaches:29 nave FMSonly baseline, alignment-based approach, trained training-free
MT-based approaches, esen language pair 02.40.10.40 domain using
MT systems available simultaneously. table provides detail: addition
accuracy percentage words covered, also includes precision recall
keeping recommendations changing recommendations. table allows
better understand differences approaches starting complex
comparison different scenarios. Throughout section provide information regarding
precision recall significant tables presented.
Leaving aside nave FMS-only baseline, observed accuracy
similar approaches, trained MT-based recommender obtains slightly
better results. already mentioned, amount words covered similar
MT-based approaches alignment-based approach. regards precision,
trained MT-based approach seems outperform others, although approaches
obtain comparable scores. results coherent obtained rest
language pairs: general recall precision keep recommendations similar
approaches, MT-based approach seems precise case
change recommendations, difference much higher, specially higher values
FMS threshold . conclusions extensible data shown Table 13.
results shown Table 12 extended repeating experiment computing
recommendations content words (i.e. ignoring stopwords). done using
list stopwords provided 4.7.2 version Lucene30 language utilised
experiments. results experiments found Table 13. seen,
results change much, thus confirming approaches perform equally
well content stopwords.
28. According Steinberger et al. (2012), English source language 72% documents.
29. nave FMS-only baseline recommend word changed, explained Section 6.5,
signifying Pc cannot computed approach Rc always 0. Similarly, words
approach covered, therefore Rk always 1.
30. http://lucene.apache.org/core/ [last visit: 15th May 2015]

201

fiEspla-Gomis, Sanchez-Martnez & Forcada

(%)

Method

(%)

NC (%)

Pk (%)

Rk (%)

Pc (%)

Rc (%)

60

FMS-only
alignment
trained
training-free

82.7.2
93.9.2
95.1.1
93.3.2

100%0
6.1.2
5.1.1
5.1.1

82.7.2
96.3.1
96.5.1
95.2.1

100%0
96.5.1
97.8.1
96.8.1


80.8.3
87.6.2
82.2.3

0%0
80.2.3
81.8.3
74.9.3

70

FMS-only
alignment
trained
training-free

88.4.3
94.3.2
95.6.2
94.1.2

100%0
5.9.2
5.2.2
5.2.2

88.4.3
96.6.1
96.8.1
95.9.2

100%0
97.2.1
98.4.1
97.7.1


73.0.4
83.7.3
75.8.3

0%0
69.1.4
71.8.4
63.6.4

80

FMS-only
alignment
trained
training-free

91.7.3
95.1.2
96.4.2
95.3.2

100%0
5.4.2
5.5.2
5.5.2

91.7.3
96.8.2
97.2.2
96.5.2

100%0
98.0.1
99.0.1
98.5.1


68.4.4
80.8.4
71.0.4

0%0
57.2.5
61.1.5
51.3.5

90

FMS-only
alignment
trained
training-free

94.0.3
95.3.3
96.9.2
96.6.2

100%0
4.9.3
5.9.3
5.9.3

94.0.3
96.5.2
97.3.2
97.4.2

100%0
98.7.1
99.6.1
99.2.1


57.1.6
72.9.6
60.2.6

0%0
32.4.6
30.1.6
32.6.6

Table 12: Comparison results obtained using trained MT-based approach,
training-free MT-based approach, alignment-based approach nave
FMS-only baseline. accuracy (A) fraction words covered (NC)
reported, together precision (P ) recall (R) regards keeping
recommendations changing recommendations. results obtained
several values FMS threshold translating esen domain
02.40.10.40, using MT systems available. Statistically significant results
p 0.05 highlighted bold type. values two values
highlighted column; means statistically
significant difference results, significantly
better values.

202

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

(%)

Method

(%)

NC (%)

Pk (%)

Rk (%)

Pc (%)

Rc (%)

60

FMS-only
alignment
trained
training-free

81.2.3
93.7.2
95.1.2
93.3.2

100%0
6.2.2
5.6.2
5.6.2

81.2.3
96.1.1
96.5.1
95.3.2

100%0
96.4.1
97.6.1
96.6.1


82.1.3
88.1.2
83.0.3

0%0
80.8.3
83.7.3
77.9.3

70

FMS-only
alignment
trained
training-free

87.3.3
94.0.2
95.6.2
93.9.2

100%0
5.9.2
5.7.2
5.7.2

87.3.3
96.3.2
96.9.2
95.9.2

100%0
97.0.1
98.2.1
97.3.1


74.0.4
84.3.3
76.0.4

0%0
69.6.4
74.9.4
67.1.4

80

FMS-only
alignment
trained
training-free

90.8.3
94.9.2
96.4.2
95.1.2

100%0
5.2.2
6.1.2
6.1.2

90.8.3
96.6.2
97.3.2
96.5.2

100%0
97.9.1
98.8.1
98.2.1


70.5.5
81.6.4
71.5.5

0%0
58.7.5
65.6.5
55.4.5

90

FMS-only
alignment
trained
training-free

93.4.3
94.9.3
96.9.2
96.5.3

100%0
4.5.3
6.6.3
6.6.3

93.4.3
96.1.3
97.3.2
97.4.2

100%0
98.6.2
99.5.1
99.0.1


58.9.7
74.0.6
60.5.7

0%0
33.0.7
34.5.7
36.9.7

Table 13: Comparison results obtained using trained MT-based approach,
training-free MT-based approach, alignment-based approach nave
FMS-only baseline. accuracy (A) fraction words covered (NC)
reported, together precision (P ) recall (R) keeping
recommendations changing recommendations. Unlike Table 12, metrics
computed content words only. results obtained several
values FMS threshold translating esen domain 02.40.10.40,
using MT systems available. Statistically significant results p 0.05
highlighted bold type. values two values highlighted
column; means statistically significant difference
results, significantly better
values.

203

fiEspla-Gomis, Sanchez-Martnez & Forcada

training
language pair
esen
enes
deen
ende
fren
enfr
fien
enfi
esfr
fres
training-free

(%)
60

70

80

90

95.08.14
90.84.19
92.52.17
92.20.18
92.65.17
90.91.19
92.38.17
91.05.19
92.36.17
91.91.18
93.36.16

95.54.16
91.80.22
93.46.20
93.22.20
94.16.19
92.23.21
93.93.19
93.36.20
93.40.20
92.24.21
94.28.18

96.34.18
93.35.23
95.09.20
94.31.22
95.78.19
93.84.23
95.30.20
95.20.20
94.56.21
93.16.24
95.41.20

96.99.21
94.94.27
96.41.23
94.88.27
96.67.22
95.24.26
96.35.23
96.47.23
96.42.23
95.49.26
96.72.22

Table 14: Accuracy obtained trained MT-based recommender translating
Spanish English domain 02.40.10.40 using recommendation models
trained language pairs domain. first row, highlighted
grey, corresponds reference results obtained model trained
esen. Google Translate used experiment. Statistically
significant results p 0.05 highlighted bold type. values
two values highlighted column; means
statistically significant difference results,
significantly better values.

experiments carried point confirmed three approaches
proposed work perform similarly different scenarios. word-alignment
based approach provides highest coverage is, therefore, able provide recommendations, MT-based approaches robust obtain higher stable
accuracy independently language pair domain used. results led us
believe approach clearly stands better, may
useful different scenarios, depending resources available translation
conditions.
7.3 Experiments Reusability Across Language Pairs
Table 14 presents results obtained trained MT-based recommender used
domain different language pair. experiments performed
domain 02.40.10.40 translating Spanish segments English re-using models
trained language pairs. results obtained model trained
pair languages included table give idea upper-bound,
corresponding row filled grey. models used, training testing,
source information used Google Translate, since MT system
available language pairs used experiments.
204

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

results show clear decline regards results obtained recommendation model learned esen learned language pairs,
particularly low values FMS threshold . cases, accuracy obtained
training recommender language pairs different used
testing worse obtained using training-free approach. exception
model trained fren pair, similar pair esen.
statistical significance test confirms that, values , either model
training-free approach best ones. difference accuracy obtained
approaches =70% =90% fact statistically significant.
results led us believe trained method highly dependent
language pair used training, thus making reasonable conclude better
use training-free MT-based recommender MT-based recommender trained
different language pair.
7.4 Experiments Reusability Across Domains
Table 15 presents results experiments concerning domain independence. objective experiments verify dependent trained MT-based recommender
domain training corpus. case, re-used recommendation models
trained three domains esen translation translate Spanish segments
domain 02.40.10.40 English, using MT systems available.
drop accuracy observed re-using models trained out-of-domain
TMs rather training TM used translation. However, case
accuracy closer obtained recommendation model trained
TM used testing (in-domain). regard results obtained
alignment-based approach, difference accuracy MT-based approaches
higher statistically significant p 0.05. say, training-free MT-based
approach models trained domain 05.20.20.10 perform best,
statistically significant difference values . Similarly, coverage
alignment-based approach clearly drops using out-of-domain models. due
fact that, case alignment-based approach, words seen
training cannot aligned, since translation probabilities learned them.
contrast, case MT-based approaches linguistic resources learned
training, rather obtained MT systems available: training
MT-based recommender instead focuses relevance sub-segment lengths
amount sub-segment pairs covering word. general, conclusion drawn
experiment using either training-free approach classification model trained
corpus different domain valid options perform better
alignment-based approach. closer look data one observe
bigger differences precision change recommendations, MT-based
approach outperforms alignment-based approach.
7.5 Experiments Reusability Across Machine Translation Systems
Table 16 presents results experiments concerning MT system independence. Three
models trained three TM belonging domain 02.40.10.40, case
205

fiEspla-Gomis, Sanchez-Martnez & Forcada

alignment

MT-based
training-free
(%)

(%)

training corpus

60

02.40.10.40
05.20.20.10
06.30.10.00

93.90.16 6.09.15
91.77.18 9.63.19
90.23.20 11.67.20

95.14.14
93.34.16
92.02.18

93.27.16

5.13.14

70

02.40.10.40
05.20.20.10
06.30.10.00

94.32.18 5.90.18
92.68.21 9.71.23
91.60.23 11.61.25

95.63.16
94.03.19
92.74.20

94.14.18

5.18.17

80

02.40.10.40
05.20.20.10
06.30.10.00

95.10.20 5.37.21
93.82.23 9.20.26
93.21.24 11.05.28

96.39.17
95.56.19
94.27.22

95.29.20

5.53.21

90

02.40.10.40
05.20.20.10
06.30.10.00

95.34.26 4.93.26
94.61.28 8.90.34
94.20.30 10.27.37

96.90.21
96.53.23
96.31.23

96.61.22

5.86.28

(%)

NC (%)

trained
(%)

NC (%)

Table 15: Accuracy (A) fraction words covered (NC) obtained alignmentbased recommender, trainng-free MT-based recommender, trained
MT-based recommender translating Spanish segments English domain 02.40.10.40. results obtained re-using recommendation
alignment models learned TMs belonging domains indicated
second column. results obtained models trained domain 02.40.10.40
included (highlighted gray) reference. MT systems available
used training testing. Statistical significance tests carried
out, separately accuracy fraction words covered. Differences
results statistically significant p 0.05 highlighted
bold type. values , difference accuracy
MT-based approaches statistically significant, differences
alignment-based approach statistically significant p 0.05.

206

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

(%) trained

(%)
60
70
80
90

Apertium

Google Translate

92.94.17
93.41.20
95.57.19
96.65.22

95.08.14
95.54.16
96.34.18
96.99.21

(%) training-free
Power Translator
91.12.19
93.02.20
94.78.21
96.47.23

93.36.16
94.28.18
95.41.20
96.72.22

Table 16: Accuracy (A) obtained trained MT-based recommender trainingfree MT-based recommender translating Spanish segments English
domain 02.40.10.40 using Google Translate MT system testing.
trained approach, results obtained re-using recommendation
models learned TM language pairs using three different
MT systems. results obtained using model trained Google (column
gray) included upper-bound, included comparison.
every value highest accuracy, statistically significant difference
p 0.05 compared values, highlighted bold type.

using one three MT systems available. models used translate segments
Spanish English within domain using Google Translate MT
system, order obtain sub-segment translations testing. results
table similar presented last set experiments, reusability
across different domains studied. general terms, would appear drop
accuracy making change recommendations quite similar models trained
Apertium Power Translator. addition, observed accuracy obtained
two models similar obtained training-free recommender.
training-free approach is, fact, performs best 60% 70%
difference accuracy statistically significant p 0.05. However, 80%
trained approach using model trained Apertium performs best.
Finally, difference among results = 90%.
general, would appear re-using models trained MT system
different used translation feasible, although using training-free approach
provide better results.
7.6 Error Analysis
following sample frequent errors made different approaches
proposed work word-keeping recommendation. objective error analysis
propose strategies deal errors (when possible) future work.
7.6.1 Errors Caused Synonyms Equivalent Expressions
incorrect change recommendations experiments resulted use
different synonyms translation proposal reference 0 used gold
standard. Let us suppose translation proposal (S, )= (the natural isotopic abundance
207

fiEspla-Gomis, Sanchez-Martnez & Forcada

lithium-6 approximately 6,5 weight per cent (7,5 atom per cent)., la proporcion
natural del isotopo litio-6 es de aproximadamente 6,5% del peso (7,5% de atomos).),
sentence 0 = natural isotopic abundance lithium-6 approximately 6,5 weight
% (7,5 atom %). whose reference translation 0 = la proporcion natural del isotopo 6
en el litio es de aproximadamente 6,5% en peso (7,5% de atomos).. seen,
0 semantically equivalent written almost same, although percentage
symbol (%) used 0 , expression per cent used S. Although two
options equivalent, per cent considered part matching
0 occurrences. sub-segment pair (, ) =per cent =%,
may led two occurrences symbol % changed, obviously
necessary. Since symbol % also used reference translation 0 ,
fact considered wrong recommendations evaluation.
7.6.2 Errors Caused Morphological Differences Languages
problem respects similar previous one, although problem
concern using different words concept, rather presence word
one languages may different morphologies language.
example, found proposal (S, )= (optical equipment follows:,equipo optico
segun se indica:), sentence 0 = optical detectors, follows: whose reference
translation 0 = detectores opticos segun se indica:. case word optical
matched 0 , singular plural 0 . English
forms share orthography, Spanish, plural mark added 0 (opticos),
therefore differing singular form (optico). result, word optico would
probably recommended kept, although actually final translation
(or least inflected way). worth noting would bad
recommendation, since difference word kept word needed
translation same, inflected different way. Whatever case might be,
would necessary indicate situations way, order let user know
change must made.
7.6.3 Errors Caused Fertility
refers fact translation single word one language translated
two word language. words form multi-word expression
translated properly using sub-segment covering whole expression.
Sub-segments covering part expression lead out-of-context translations
produce wrong evidence. instance, TU (S, )= (wavelength less
1400nm, longitud de onda inferior 1400nm), proposed sentence 0 = wavelength equal greater 1400nm whose reference translation 0 = longitud de
onda igual superior 1400nm word wavelength English translated longitud
de onda Spanish. Since wavelength appears 0 , obvious three
words multi-word expression kept. However, context, word de
translated of, also appears matched 0 . word de
may therefore obtaining keeping evidence sub-segments covering whole
expression longitud de onda, changing evidence sub-segments covering
208

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

part expression. situation may easily result change recommendation.
probably difficult error fix, since motivated specifics
language may, cases, extremely complex.

8. Concluding Remarks
paper presented new approach assist CAT users employ TMs
providing recommendations target-side words translation
proposals provided CAT system changed (modified removed) kept
unedited. method propose imposes constraints type MT system
used, since used black box. method may use one MT system
time obtain set features combined using binary classifier
determine whether target words changed remain unedited.
event, MT results never presented translator. version method
require training also proposed alternative.
experiments carried bear witness feasibility methods proposed
comparing accuracy coverage previous approach based statistical
word alignment word-keeping recommendation. experiments tackle problem
different scenarios, comparing results obtained different domains, MT systems
language pairs. results obtained confirm viability MT-based methods
proposed work, particularly case trained MT-based approach (see
Section 4), obtains better results regards accuracy obtained
statistical alignment-based approach (see Section 3). case coverage, results
obtained MT-based approaches general worse obtained using
alignment-based approach alignment models trained in-domain TMs,
better trained out-of-domain TMs. results also show reasonable
degree independence MT-based models respect domain TM
MT system(s) used training. results suggest need re-train
classifier new TM and, even importantly, necessary
every time new TU added TM.
general, models trained MT-based recommender much portable
across domains trained alignment-based approach. approaches
compared training-free approach (see Section 5), also uses MT source
evidence word-keeping recommendation, need training.
experiments confirm results obtained training-free MT-based recommender
worse obtained trained recommender trained
TM used translating new texts. However, advisable use training-free
MT-based approach recommendation models TM available
trained MT-based recommender.
summary, MT-based approaches perform better alignment-based approaches accuracy important coverage, trained
out-of-domain TMs. regard MT-based approaches, better use trained
MT-based recommender model available pair languages MT system(s) used translating, use training-free MT-based recommender
otherwise.
209

fiEspla-Gomis, Sanchez-Martnez & Forcada

principal conclusion work three approaches comparable
useful depending needs translator resources available translation.
might even possible combine three approaches (trained MT-based, training-free
MT-based, statistical alignment-based) order prove, example, recommendations words covered approaches others.
results obtained study also opened new horizons future
work, as: extending method able provide user
recommendations words keep unedited, also actively suggest translation
words change; trying alternative parametric classifiers; using sources
bilingual knowledge, glossaries, dictionaries, bilingual concordancers, etc.
improve results MT-based approaches word-keeping recommendation.
Appendix presents study confirms usefulness word-keeping recommendation translators, showing improvement productivity 14% translation
task Spanish English. plan extend experiments explore new
ways performing word-keeping recommendation. instance, would interesting
compare productivity translators receiving recommendations content words, optionally partial recommendations (on stems), receiving change
recommendations. also believe would interesting evaluate amount
minimum recommendations needed segment make tool useful translators, computing productivity translators regards proposals low coverage.
One main interests able model cost errors recommendations, i.e.
confirm whether wrong keeping recommendation expensive translator
wrong changing recommendation. ideas require new set experiments
professional translators order obtain optimal method present
recommendations, order maximise improvement productivity already shown
Appendix A.
study impact noise data set used evaluation paper included
Appendix B. study uses heuristic31 filter free wrong translations
data sets. translated materials obtained experiments described Appendix
additionally used clean data set produced directly professional translators.
results appendix show accuracy classification significantly
improved using clean data sets.
Finally, prototype plug-in free/open-source CAT system OmegaT32
implements training-free approach described Section 5 proof concept, available downloaded http://www.dlsi.ua.es/~mespla/edithints.html.
prototype uses free on-line MT systems perform word-keeping recommendation,
thus confirming technical feasibility approach regards making on-the-fly recommendations real-world settings.

31. heuristic based distance segment translate 0 source side
translation proposal S, distance reference translation 0 used gold standard
evaluation target side translation proposal .
32. http://www.omegat.org [last visit: 15th May 2015]

210

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

Acknowledgments
work supported Spanish government projects TIN2009-14009-C02-01
TIN2012-32615. would like thank Juan Antonio Perez-Ortiz, Andy Way
Harold Somers suggestions. also thank anonymous reviewers helped
improve original manuscript suggestions.

Appendix A. Experiment Concerning Effect Word-Keeping
Recommendation Translator Productivity
Word-keeping recommendation relatively new task. based assumption
providing translators using translation memory (TM) tools hints words
change keep unedited translation proposal increase productivity. Although might appear obvious assumption, needs empirically confirmed.
objective experiment described appendix verify impact wordkeeping recommendation translation productivity, independently approach used
obtain recommendations.
A.1 Methodology
experiment, productivity professional translators measured translating several documents English Spanish using computer-aided translation
(CAT) tool OmegaT, first without word-keeping recommendations them.
task, five translators previous experience using OmegaT hired.
translate three projects: short training project (training), used
familiarisation tool kind documents translate; project translated standard version OmegaT (standard ); project translated
modified version OmegaT provided word-keeping recommendations (recommendation).
training project five translators, five different standard
projects created (one translator). standard projects reused recommendation projects rotating translators, thus signifying none translated
project twice. decision made use translations obtained standard projects reference computing word-keeping recommendations
recommendation projects; would equivalent perfect classifier.
often called oracle setting.
Following structure described, experiment driven way
translations would done time, room, using identical
computers. experiment divided two phases: first, training standard
projects translated, break half hour took place
recommendation project translated.
A.1.1 Corpus
DGT-TM (Steinberger et al., 2012) translation memory published European
Commission Directorate-General Translation used build translation memories
translation projects used experiment. 90% document pairs
211

fiEspla-Gomis, Sanchez-Martnez & Forcada

used TM segment alignment. remaining 10% used build translation
projects: documents selected segments matched least one translation
unit (TU) TM fuzzy-match score (FMS) higher equal 50%.
Six translation projects created selection: one containing single document
127 words (the training project) five containing three different documents
1,000 words total.
A.1.2 OmegaT
experiment, version 3.1 free/open-source CAT tool OmegaT used
plug-in OmegaT SessionLog 33 version 0.2, silently logs actions performed
translator. initial version OmegaT modified avoid exact matches
(FMS=100%) proposed, since would possible evaluate impact wordkeeping recommendation kind proposals.34 modified version OmegaT
created also make word-keeping recommendations based former translations.
version tool computes, given translation proposal, edit distance
reference translation proposal, colours words kept green
words removed replaced proposal red. means
recommendations made version OmegaT professional
translator would make translating, i.e. perfect recommendations. (oracle setting).
A.2 Results
results experiment shown Table 17. worth noting contains
results four data sets, given one translators forgot translate
part standard project assigned her, thus invalidating corresponding results.
table shows time devoted translating test set, without using
word-keeping recommendation. Translation time measured segment.
tool used capture edition information revealed segment usually selected
(or visited ) several times whole process, translate review it.
order show information clearly, two different measures obtained
segment: total translation time (columns 2 3), time spent
segment taking account every visit it, edit time (columns 4 5),
time spent translating first time using translation proposal.
second measure, longest edit visit segment taken account,
assuming edits made later visits corresponded review process. last
row table presents total translation time column. seen,
total time devoted translation reduced 14% using word-keeping
recommendation. Moreover, editing time, word-keeping recommendation
main impact, reduced 20%. gain translation time proved
statistically significant p 0.05 performing approximate randomisation test

33. https://github.com/mespla/OmegaT-SessionLog [last visit: 15th May 2015]
34. assumed exact match provides translation need edited, therefore,
possible evaluate advantage word-keeping recommendations.

212

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

test set
1
2
3
4
test sets

total time

edition time

without WKR

WKR

without WKR

WKR

3,664s
3,613s
4,251s
3,787s

2,611s
3,467s
3,709s
3,315s

2,441s
3,080s
2,674s
2,432s

1,917s
2,293s
2,310s
1,937s

15,315s

13,102s

10,627s

8,457s

Table 17: Time spent translation. Columns 2 3 compare total time spent translating test set, respectively, using version OmegaT without
word-keeping recommendation. Columns 4 5 present comparison,
taking account time actually spent reviewing test set.

1,000 iterations.35 free/open-source tool SIGF V.2 Pado (2006) used
experiments.
results obtained experiment confirm assumption word-keeping recommendation significantly improve productivity translators use translation
memory tools. Although extensive experiment, including translators documents domains, would needed confirm this, current results encouraging.
addition, translators participating experiment agreed word-keeping
recommendation useful translators working TM-based CAT tools.
worth noting experimental framework presented appendix
specifically designed measure word-keeping recommendation results obtained
cannot therefore straightforwardly assumed every translation project. example, projects translated experiment used TM, thus ensuring least one
translation proposal would provided FMS higher 50%, TM
type coverage may available given project. addition, translations
performed humans used experiment compute word-keeping recommendations, would usually called gold standard. translations would
obviously available real scenario recommendations would approximate.
use gold-standard-based recommendations may also boost confidence
translators using tool, since experiment correct times.
therefore consider results correspond upper bound productivity
gain. Nevertheless, results obtained experiment allowed us obtain
clearer idea usefulness word-keeping recommendation confirm relevance
problem obtaining fast accurate word-keeping recommendations.
35. Here, approximate randomisation applied time devoted translating segment
without word-keeping recommendation concatenated data sets. method first computes
difference time needed translate entire data sets. randomly interchanges time spent
translating segments sets results recomputes total time.
equal higher time gain obtained randomised lists times, means result
significant.

213

fiEspla-Gomis, Sanchez-Martnez & Forcada

Appendix B. Experiments High Quality Gold Standards
appendix tackle problem associated use free translations references evaluation. already mentioned Section 7, pair segments (Sl0 , Tl0 )
test set, obtain matching TUs (Si , Ti ), set word-keeping recommendations provided every segment Ti . Tl0 used gold standard
recommendations purpose evaluation. method assumes way
Sl0 translated Tl0 similar way Si translated Ti , thus enabling
use Tl0 reference.36 However, may case several reasons,
wrong segment alignments, errors translations, or, case, free (but still adequate)
translations. Following example shown Section 4, illustrate impact free
translation evaluation method. Let us assume segment 0 translated
la situacion poltica parece ser difcil, matching TU (S, ) retrieved CAT
tool (la situacion humanitaria parece ser difcil, humanitarian situation appears
difficult), gold standard 0 test set situation,
political point view, appears tortuous, semantically valid translation 0 ,
different . checking validity translation occurred Section
4, words common 0 the, appears, situation, remaining
words would considered words change order produce correct translation.
However, sufficient replace word humanitarian political produce
valid translation 0 . therefore obvious 0 good reference
evaluate recommendations performed .
consequence free translations test set, fraction recommendations actually correct considered inadequate evaluation since
match reference test set. accuracy obtained approaches
presented work therefore lower expected.
Although loss accuracy affects methods work way
conclusions obtained therefore valid, wished see reliable results
regards performance approaches could attained. therefore performed
set additional experiments order bypass problem free translations.
one hand, repeated experiments shown Section 7 using
constrained test set pairs segments likely wrong
(or free) translations discarded. hand, performed experiment
re-using test set TMs described Appendix A.
mentioned previously, first group experiments defined constraint
order attempt evaluate pairs segments test set Section 6.2
reliable. done employing filtering based fuzzy-match
score (FMS) used choose candidate TUs given segment translated.
condition relies assumption FMS 0 (FMSS )
similar FMS 0 (FMST ), since number words differed
pairs segments proportional languages. Based idea,
set threshold pairs TUs fulfilling condition |FMSS FMST |
36. similar mean matching parts Sl0 Si translated way, thus
producing differences Tl0 Ti parts corresponding differences Sl0
Si .

214

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

(%)

domain

filtering

0.05

TUavg

Nwords

TUavg

Nwords

60

02.40.10.40
05.20.20.10
06.30.10.00

3.71
0.62
5.68

95,881
9,718
34,339

1.59
0.39
0.52

44,240
6,198
6,956

70

02.40.10.40
05.20.20.10
06.30.10.00

2.36
0.37
0.99

65,865
6,883
10,327

1.16
0.26
0.26

31,022
4,862
4,194

80

02.40.10.40
05.20.20.10
06.30.10.00

1.58
0.14
0.45

46,519
3,015
4,726

0.97
0.09
0.09

24,928
1,889
2,143

90

02.40.10.40
05.20.20.10
06.30.10.00

0.70
0.05
0.03

26,625
1,599
1,268

0.50
0.03
0.03

15,154
975
943

Table 18: Average number matching TUs (TUavg ) per segment total number
words (Nwords ) provide recommendation translating esen
three different domains. results obtained different ranges
FMS threshold (), filtering = 0.05 filtering
applied.

used training testing. worth mentioning experiments also
performed applying filtering test set, difference results
significant. experiments, arbitrarily set value 0.05, i.e.
divergence 5% permitted FMS source language segments
target language segments, since threshold constrains examples used
highly controlled scenario, reasonable number samples maintained
experiments, shown Table 18.37
B.1 Experiments Constrained Test Sets
table shows, esen language pair fuzzy-match scores four different
ranges, average number TUs matched per segment translated total
number words recommendation provided. results obtained
filtering threshold filtering applied. worth noting
case domains 05.20.20.10 06.30.10.00 noticeable differences
matching restriction applied, similar data obtained
filtering = 0.05. led us believe TUs belonging domain
05.20.20.10 regular translation domain 06.30.10.00.
37. Note objective experiments compare different approaches (this already done), rather confirm whether improvement accuracy exists using less noisy data
sets. statistical significance different approaches therefore re-computed.

215

fiEspla-Gomis, Sanchez-Martnez & Forcada

(%)

Method

(%)

NC (%)

Pk (%)

Rk (%)

Pc (%)

Rc (%)

60

FMS-only
alignment
trained
training-free

84.7.3
96.4.2
96.9.2
95.2.2

100%0
4.8.2
4.7.2
4.7.2

84.7.3
98.2.1
97.9.1
96.5.2

100%0
97.5.2
98.4.1
97.9.1


85.8.3
90.8.3
87.3.3

0%0
89.4.3
88.2.3
79.9.4

70

FMS-only
alignment
trained
training-free

90.5.3
97.0.2
97.4.2
96.1.2

100%0
4.7.2
4.4.2
4.4.2

90.5.3
98.5.1
98.3.2
97.1.2

100%0
98.2.2
98.8.1
98.6.1


81.7.4
87.3.4
83.4.4

0%0
83.9.4
82.7.4
69.8.5

80

FMS-only
alignment
trained
training-free

93.2.3
97.4.2
98.0.2
96.7.2

100%0
4.6.3
4.6.3
4.6.3

93.2.3
98.7.1
98.7.2
97.5.2

100%0
98.5.2
99.2.1
98.0.2


77.1.5
86.5.4
79.8.5

0%0
79.4.5
79.5.5
61.7.6

90

FMS-only
alignment
trained
training-free

96.5.3
97.9.2
98.6.2
98.3.2

100%0
4.1.3
4.2.3
4.2.3

96.5.3
98.9.2
99.0.2
98.9.2

100%0
98.9.2
99.6.1
99.4.1


68.0.8
81.7.6
74.0.7

0%0
68.0.8
62.8.8
60.8.8

Table 19: Comparison results obtained using trained MT-based approach,
training-free MT-based approach, alignment-based approach nave
FMS-only baseline. accuracy (A) fraction words covered (NC)
reported, together precision (P ) recall (R) keeping
recommendations changing recommendations. results obtained
several values FMS threshold translating esen domain
02.40.10.40, using MT systems available filtering = 0.05 (see
text).

observed, threshold, approximately half training samples kept domain
02.40.10.40 two thirds domain 05.20.20.10. case domain 06.30.10.00
different; filtering removes far training samples low values FMS threshold
, higher values loss high, similar domain 05.20.20.10.
Table 19 equivalent Table 12, contains detailed comparison
approaches, using filtering described data set. noted,
results obtained case clearly better approaches obtained
experiments filtering.
Finally, Table 20 shows accuracy obtained trained MT-based approach
alignment-based approach language pairs, occurs Table 10. worth
noting that, although differences results obtained approaches
similar, noticeably better.
B.2 Experiment Human-Produced Test Sets
second group experiments used documents described Appendix
test set evaluate word-keeping recommendation. case, original documents
216

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

60(%)

70(%)

80(%)

90(%)

lang.
pair

trained

alignment

trained

alignment

trained

alignment

trained

alignment

esen
enes
deen
ende
fren
enfr
fien
enfi
esfr
fres

96.9.2
95.1.2
96.9.2
96.3.2
96.9.2
95.9.2
96.0.2
96.3.2
95.6.2
95.2.2

96.4.2
93.6.2
96.3.2
94.8.2
96.7.2
95.5.2
96.0.2
94.8.3
95.3.2
94.8.2

97.5.2
96.4.2
97.7.2
97.2.2
97.9.2
97.4.2
97.3.2
97.2.2
96.8.2
96.7.2

97.0.2
94.8.2
96.8.2
95.7.2
97.7.2
96.8.2
97.1.2
95.5.3
96.5.2
96.3.2

98.0.2
97.1.2
98.3.2
97.6.2
98.4.2
98.1.1
97.7.2
97.7.2
97.7.2
97.3.2

97.4.2
95.5.2
97.4.2
96.2.2
98.0.2
97.3.2
97.5.2
96.0.3
97.2.2
97.0.2

98.5.2
97.8.2
98.3.2
97.9.2
98.5.2
98.3.2
98.0.3
97.7.3
98.1.2
97.4.2

97.9.2
96.9.3
97.5.3
97.0.3
98.1.2
97.5.2
97.5.3
97.5.3
97.4.2
97.0.3

Table 20: Accuracy (A) obtained trained MT-based approach
alignment-based approach translating language pairs
domain 02.40.10.40. results obtained several values FMS
threshold using available MT systems language pair.

(%)

(%)

NC (%)

(%)

(%)

NC (%)

60
70
80
90

97.8.1
98.6.1
99.0.1
98.7.2

10.0.2
8.5.2
8.1.3
7.3.4

60
70
80
90

95.6.1
96.2.1
96.7.2
96.4.2

9.8.2
8.5.2
8.1.2
8.1.3

Table 21: Accuracy (A) fraction words covered (NC) obtained translating
trained MT-based approach reusing data set described Appendix A. left-hand table contains results translating Spanish
English, right-hand table contains results translating English
Spanish.

Spanish translated English professional translators, told translate
faithfully possible. parallel documents therefore expected totally
fit requirements evaluation.
experiment, TM used professional translators Appendix used
evaluate translation texts English Spanish vice versa. In-domain
models also trained TM which, already mentioned above, consists
629 TUs. Table 21 presents accuracy fraction words covered
obtained data set, enes esen. Although coverage slightly lower
obtained system data sets, accuracy much better,
even better obtained constrained test sets.
217

fiEspla-Gomis, Sanchez-Martnez & Forcada

results presented appendix allow us confirm accuracy
approaches presented work may noticeably higher presented Section
7, lack valid gold standard experiments allows us approximate
results.

References
Ahrenberg, L., Andersson, M., & Merkel, M. (2000). Parallel text processing: alignment
use translation corpora, chap. knowledge-lite approach word alignment.
Kluwer Academic Publishers. Edited J. Veronis.
Bergstra, J. S., Bardenet, R., Bengio, Y., & Kegl, B. (2011). Algorithms hyper-parameter
optimization. Advances Neural Information Processing Systems 24, pp. 2546
2554. Curran Associates, Inc.
Bertoldi, N., Farajian, A., & Federico, M. (2009). Online word alignment online adaptive
machine translation. Proceedings Workshop Humans Computerassisted Translation, pp. 120127, Gothenburg, Sweden.
Bicici, E., & Dymetman, M. (2008). Dynamic translation memory: Using statistical machine translation improve translation memory fuzzy matches. Proceedings
9th International Conference Intelligent Text Processing Computational
Linguistics, Vol. 4919 LNCS, pp. 454465, Haifa, Israel.
Bojar, O., Buck, C., Federmann, C., Haddow, B., Koehn, P., Leveling, J., Monz, C., Pecina,
P., Post, M., Saint-Amand, H., Soricut, R., Specia, L., & Tamchyna, A. (2014). Findings 2014 Workshop Statistical Machine Translation. Proceedings
Ninth Workshop Statistical Machine Translation, pp. 1258, Baltimore, USA.
Bourdaillet, J., Huet, S., Langlais, P., & Lapalme, G. (2010). TransSearch: bilingual
concordancer translation finder. Machine Translation, 24 (34), 241271.
Bowker, L. (2002). Computer-aided translation technology: practical introduction, chap.
Translation-memory systems, pp. 92127. University Ottawa Press.
Brown, P. F., Della Pietra, S. A., Della Pietra, V. J., & Mercer, R. L. (1993). mathematics statistical machine translation: Parameter estimation. Computational Linguistics, 19 (2), 263311.
de Gispert, A., Blackwood, G., Iglesias, G., & Byrne, W. (2013). N-gram posterior probability confidence measures statistical machine translation: empirical study.
Machine Translation, 27 (2), 85114.
Depraetere, I. (2008). LEC Power Translator 12. MultiLingual, September 2008, 1822.
Duda, R. O., Hart, P. E., & Stork, D. G. (2000). Pattern Classification (second edition).
John Wiley Sons Inc.
Espla, M., Sanchez-Martnez, F., & Forcada, M. L. (2011). Using word alignments
assist computer-aided translation users marking target-side words change
keep unedited. Proceedings 15th Annual Conference European
Associtation Machine Translation, pp. 8189, Leuven, Belgium.
218

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2011). Using machine translation computer-aided translation suggest target-side words change.
Proceedings 13th Machine Translation Summit, pp. 172179, Xiamen, China.
Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2015). Using on-line available
sources bilingual information word-level machine translation quality estimation. Proceedings 18th Annual Conference European Associtation
Machine Translation, pp. 1926, Antalya, Turkey.
Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2012a). Using external sources
bilingual information on-the-fly word alignment. Tech. rep., Universitat dAlacant.
Espla-Gomis, M., Sanchez-Martnez, F., & Forcada, M. L. (2012b). simple approach
use bilingual information sources word alignment. Procesamiento de Lenguaje
Natural, 49.
European Commission Directorate-General Translation (2009). Translation Tools
Workflow. Directorate-General Translation European Commission.
European Commission Joint Research Center (2007). EUR-Lex pre-processing. http:
//optima.jrc.it/Resources/Documents/DGT-TM_EUR-LEX-preprocessing.pdf.
Last retrieved: 15th May 2015.
Forcada, M. L., Ginest-Rosell, M., Nordfalk, J., ORegan, J., Ortiz-Rojas, S., Perez-Ortiz,
J. A., Sanchez-Martnez, F., Ramrez-Sanchez, G., & Tyers, F. M. (2011). Apertium:
free/open-source platform rule-based machine translation. Machine Translation,
25 (2), 127144. Special Issue Free/Open-Source Machine Translation.
Foster, G., & Kuhn, R. (2007). Mixture-model adaptation SMT. Proceedings
Second Workshop Statistical Machine Translation, StatMT 07, pp. 128135,
Prague, Czech Republic.
Free Software Fundation (2007). GNU general public license, version 3. http://www.gnu.
org/licenses/gpl.html. Last retrieved: 15th May 2015.
Gao, Q., Lewis, W., Quirk, C., & Hwang, M. (2011). Incremental training intentional
over-fitting word alignment. Proceedings 13th Machine Translation Summit, pp. 106113, Xiamen, China.
Gao, Q., & Vogel, S. (2008). Parallel implementations word alignment tool. Proceedings
Software Engineering, Testing, Quality Assurance Natural Language
Processing Workshop, pp. 4957, Columbus, USA.
Garcia, I. (2005). Long term memories: Trados TM turn 20. Journal Specialised
Translation, 4, 1831.
Garcia, I. (2012). Machines, translations memories: language transfer web
browser. Perspectives, 20 (4), 451461.
Gough, N., Way, A., & Hearne, M. (2002). Example-based machine translation via web.
Richardson, S. D. (Ed.), Machine Translation: Research Real Users, Vol.
2499 Lecture Notes Computer Science, pp. 7483. Springer Berlin Heidelberg.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009).
WEKA Data Mining Software: Update. SIGKDD Explorations, 11 (1), 1018.
219

fiEspla-Gomis, Sanchez-Martnez & Forcada

Hornik, K., Stinchcombe, M., & White, H. (1989). Multilayer feedforward networks
universal approximators. Neural Networks, 2 (5), 359366.
Koehn, P. (2010). Statistical Machine Translation. Cambridge University Press.
Koehn, P., & Senellart, J. (2010). Convergence translation memory statistical machine translation. Proceedings 2nd Joint EM+/CNGL, Workshop Bringing
MT User: Research Integrating MT Translation Industry, pp. 2131,
Denver, USA.
Koehn, P., Axelrod, A., Mayne, A. B., Callison-Burch, C., Osborne, M., & Talbot, D.
(2005). Edinburgh system description 2005 IWSLT speech translation evaluation. Proceedings International Workshop Spoken Language Translation,
Pittsburgh, USA.
Kranias, L., & Samiotou, A. (2004). Automatic translation memory fuzzy match postediting: step beyond traditional TM/MT integration. Proceedings 4th
International Conference Language Resources Evaluation, pp. 331334, Lisbon, Portugal.
Kuhn, R., Goutte, C., Isabelle, P., & Simard, M. (2011). Method system using
alignment means matching translation. USA patent application: US20110093254
A1.
Lagoudaki, E. (2008). value machine translation professional translator.
Proceedings 8th Conference Association Machine Translation
Americas, pp. 262269, Waikiki, USA.
Langlais, P., & Simard, M. (2002). Merging example-based statistical machine translation: experiment. Richardson, S. (Ed.), Machine Translation: Research
Real Users, Vol. 2499 Lecture Notes Computer Science, pp. 104113. Springer
Berlin Heidelberg.
Laubli, S., Fishel, M., Volk, M., & Weibel, M. (2013). Combining statistical machine translation translation memories domain adaptation. Proceedings 19th
Nordic Conference Computational Linguistics, pp. 331341, Oslo, Norway.
Levenshtein, V. (1966). Binary codes capable correcting deletions, insertions reversals. Soviet Physics Doklady, 10 (8), 707710.
Ma, Y., He, Y., Way, A., & van Genabith, J. (2011). Consistent translation using discriminative learning: translation memory-inspired approach. Proceedings 49th
Annual Meeting Association Computational Linguistics: Human Language
Technologies - Volume 1, HLT 11, pp. 12391248, Portland, Oregon.
Marcu, D. (2001). Towards unified approach memory- statistical-based machine
translation. Proceedings 39th Annual Meeting Association Computational Linguistics, ACL 01, pp. 386393, Toulouse, France.
Meyers, A., Kosaka, M., & Grishman, R. (1998). multilingual procedure dictionarybased sentence alignment. Machine translation information soup: Proceedings third conference Association Machine Translation
Americas, Vol. 1529 LNCS, pp. 187198, Langhorne, USA.
220

fiTarget-Language Edit Hints CAT Tools Based TM Means MT

Nieen, S., Vogel, S., Ney, H., & Tillmann, C. (1998). DP based search algorithm
statistical machine translation. Proceedings 36th Annual Meeting Association Computational Linguistics 17th International Conference Computational Linguistics - Volume 2, ACL 98, pp. 960967, Montreal, Canada.
Och, F. J., & Ney, H. (2003). systematic comparison various statistical alignment
models. Computational Linguistics, 29 (1), 1951.
Pado, S. (2006). Users guide sigf: Significance testing approximate randomisation.
Sanchez-Martnez, F., Carrasco, R. C., Martnez-Prieto, M. A., & Adiego, J. (2012). Generalized biwords bitext compression translation spotting. Journal Artificial
Intelligence Research, 43, 389418.
Sikes, R. (2007). Fuzzy matching theory practice. MultiLingual, 18 (6), 3943.
Simard, M. (2003). Translation spotting translation memories. Proceedings
HLT-NAACL 2003, Workshop Building Using Parallel Texts: Data Driven
Machine Translation Beyond, pp. 6572, Edmonton, Canada.
Simard, M., & Isabelle, P. (2009). Phrase-based machine translation computer-assisted
translation environment. Proceedings 12th Machine Translation Summit, pp.
120127, Ottawa, Canada.
Simard, M., & Langlais, P. (2001). Sub-sentential exploitation translation memories.
Proceedings Machine Translation Summit VIII, pp. 335339, Santiago de
Compostela, Spain.
Somers, H. (2003). Computers translation: translators guide, chap. Translation memory systems, pp. 3148. John Benjamins Publishing, Amsterdam, Netherlands.
Somers, H. (1999). Review article: Example-based machine translation. Machine Translation, 14 (2), 113157.
Specia, L., Raj, D., & Turchi, M. (2010). Machine translation evaluation versus quality
estimation. Machine Translation, 24 (1), 3950.
Steinberger, R., Pouliquen, B., Widiger, A., Ignat, C., Erjavec, T., & Tufis, D. (2006).
JRC-Acquis: multilingual aligned parallel corpus 20+ languages. Proceedings
5th International Conference Language Resources Evaluation, pp. 2142
2147, Genoa, Italy.
Steinberger, R., Eisele, A., Klocek, S., Pilos, S., & Schluter, P. (2012). DGT-TM: freely
available translation memory 22 languages. Proceedings 8th International
Conference Language Resources Evaluation, LREC12, pp. 454459, Istambul,
Turkey.
Ueffing, N., & Ney, H. (2005). Word-level confidence estimation machine translation
using phrase-based translation models. Proceedings Conference Human
Language Technology Empirical Methods Natural Language Processing, HLT
05, pp. 763770, Vancouver, Canada.
Veronis, J., & Langlais, P. (2000). Evaluation parallel text alignment systems. Veronis,
J. (Ed.), Parallel Text Processing, Vol. 13 Text, Speech Language Technology,
pp. 369388. Springer Netherlands.
221

fiEspla-Gomis, Sanchez-Martnez & Forcada

Vogel, S., Ney, H., & Tillmann, C. (1996). HMM-based word alignment statistical translation. Proceedings 16th International Conference Computational Linguistics, pp. 836841, Copenhagen, Denmark.
Zhechev, V., & van Genabith, J. (2010). Seeding statistical machine translation translation memory output tree-based structural alignment. Proceedings
COLING10, Workshop Syntax Structure Statistical Translation, pp. 4351,
Beijing, China.

222

fiJournal Artificial Intelligence Research 53 (2015) 497-540

Submitted 01/15; published 07/15

Satisfiability Systematicity
Matthew L. Ginsberg
Connected Signals, Inc.
355 Goodpasture Island Road, Suite 200
Eugene, Oregon 97401

Abstract
introduce new notion systematicity satisfiability algorithms restarts,
saying algorithm strongly systematic systematic independent restart
policy weakly systematic systematic restart policies others.
show existing satisfiability engines generally weakly systematic, describe
flex, strongly systematic algorithm uses amount memory polynomial
size problem. large number factoring problems, flex appears outperform
weakly systematic approaches.

1. Introduction
upon time, dpll (Davis, Logemann, & Loveland, 1962; Davis & Putnam, 1960)
algorithm choice solving Boolean satisfiability problems, sat. three
reasons this.
First, dpll systematic particular problem solution, dpll would
eventually find it. problem solution, dpll would identify unsatisfiable.
properties essential want simply invoke solver, allow long necessary
solve problem, assured answer always result.
Second, dpll used amount memory polynomial size problem.
amount time used was, course, exponential given NP-complete nature sat.
memory used polynomial, therefore logarithmic running time.
finally, dpll worked. success harbinger uses later sat
engines would put, range problems dpll could practically applied
exceeded previous general-purpose NP algorithm. Today range wider still,
including microprocessor verification (Kaivola, Ghughal, Narasimhan, Telfer, Whittemore,
Pandav, Slobodov, Taylor, Frolov, Reeber, & Naik, 2009), device driver validation (Moura
& Bjrner, 2010) many others (Biere, Heule, van Maaren, & Walsh, 2009).
Two changes led significant algorithmic improvements. first recognition
dpll backtrack best thought move tree-like search space,
instead resolution-based inference step. idea appeared first Stallman
Sussmans (1977) work dependency-directed backtracking Doyles subsequent (1979)
work truth maintenance. earlier authors, however, described algorithms
might accumulate exponential number resolution consequences search
proceeded.
Ginsbergs (1993) work dynamic backtracking first show systematic nonchronological inference methods could constructed using polynomial
amount memory, describing algorithm extension backjumping (Gaschnig,
c
2015
AI Access Foundation. rights reserved.

fiGinsberg

1979). Bayardo Schrag (1997) continued work approach, renaming (sensibly) relevance-bounded learning. ideas currently known conflict driven clause
learning, cdcl, name introduced Ryan (2002) popularized
Marques-Silva, Lynce Malik (2009).
work 1997 involved using scheme retaining learned clauses guaranteed polynomial number clauses would kept particular
point search. grasp (Marques-Silva & Sakallah, 1999), requirement
dropped. Virtually modern sat solvers use cdcl, generally modified way
either allows unlimited number clauses collected (as tinisat, Huang, 2006;
Quest0.5, Lynce, Baptista, & Marques-Silva, 2001) or, commonly, way
longer guarantees systematicity (zChaff, Moskewicz, Madigan, Zhao, Zhang, & Malik,
2001; rsat, Pipatsrisawat & Darwiche, 2007; minisat, Sorensson & Een, 2005, many
others).
abandonment systematicity linked inclusion restarts satisfiability
algorithms. appears due Gomes, Selman colleagues (1998);
basic idea escape areas solver thrashing (searching nearly endlessly
without ever identifying real source problem) simply restarting scratch. Put
somewhat differently (but equivalently), restarts provide solver makes
mistake near root search tree, Harvey (1995) refers early mistake.
setting provided dpll, restarting prover inevitably result nonsystematicity. crucial information state search stored
position search tree, restarting search abandons information.
work restarts matured two separate directions. First,
considerable body work examining theoretical properties search restarts
cdcl case clauses retained search proceeds. search
obviously systematic, since limited number new clauses learned
either solution found empty clause derived (proving original problem
unsatisfiable).
interesting conclusions drawn, however, fact restarts
prevent thrashing appears related fact appear allow foxr
flexible inference schema previous methods. work begun Beame
colleagues (2004), continued Buss et al. (2008) Hertel et al. (2008), extended
Pipatsrisawat Darwiche (2011), showed cdcl restarts
equivalent general resolution. Cdcl without restarts known generally able
produce proofs exponentially shorter tree-based resolution, general resolution
lead exponentially shorter proofs tree-based resolution many instances (BenSasson, Impagliazzo, & Wigderson, 2000).1
addition theoretical work, practical work proceeding well, focusing
large measure development strategies identifying points search
restarted. realized fairly quickly virtually restart policy
improvement restarting all. Luby et al. (1993) developed restart policy
showed within logarithmic factor optimal wide range problems.
1. also known tree-based resolution cant polynomially simulate general resolution (Bonet &
Johannsen, 2014).

498

fiSatisfiability Systematicity

Luby restart policy shown outperform variety alternatives sat domain
Huang (2007).
Luby restart policy involves gradually (but monotonically) increasing number backtracks restarts; roughly speaking, 2kth restart first allows
2k backtracks restarting again. refer effort undertaken
consecutive restarts probe; number backtracks restarts called
size probe.
Luby approach two useful consequences. first total number
backtracks grows quadratically number restarts infrequency
probes large size.
second consequence Luby policy search systematic,
assuming original procedure, without restarts, systematic. reason
Luby restart policy eventually involve probes sufficiently large size
systematicity guaranteed.
distinction worth formalizing. Given algorithm involves restart
policy, say strongly systematic systematic independent restart
policy chosen. say weakly systematic systematic restart
policies others, say nonsystematic systematic
restart policy.
connection systematicity amount memory used sufficiently
important present following classification sat solvers:

Exp-space
Polyspace

Strongly
Systematic
tinisat
?

Weakly
Systematic

minisat

Nonsystematic

wsat

exp-space, mean algorithms demonstrably may take amount space
exponential size problem solved; polyspace algorithms
remove learned clauses thus could, least theory, use polynomial amounts
space result.
Memory cheap days; perhaps exp-space much drawback
was. turns case, following reason.
CPU time consumed sat engines spent unit propagation procedure, finds obvious consequences variable assignments made particular
point search. Although variety engineering improvements
speed process considerably (Moskewicz et al., 2001), overall time still linear
size accumulated clausal database. database grows exponentially
size, time needed single inference therefore grow exponentially well.
Given tinisats existence upper left, little interest exp-space
solver weaker systematicity properties. tinisat cannot really considered
production solver; difficult problems, number stored clauses grows impractically
solver essentially grinds halt.
previously discussed wsat family algorithms (Selman, Kautz, &
Cohen, 1993), shall we. algorithms different spirit ones
described thus far, working complete variable assignments using hill
499

fiGinsberg

climbing attempt gradually convert assignments solutions problems
investigated. competitive 1990s, progress systematic algorithms
fundamentally nonsystematic approaches currently given relatively little attention, although recent work shown connection
algorithms cdcl approach closer one might think (Goultiaeva & Bacchus,
2012).
modern sat solvers join minisat middle bottom row, weakly systematic using relatively modest amount memory get job done. Removing
clauses essential practical solver simply known strongly
systematic algorithm capable so. general view although
strongly systematic, systems work exceptionally well practice, including managing
produce proofs unsatisfiability necessary.
noted, however, loss systematicity simple theoretical concession. obviously important, example, distinct probes begin
search distinct locations search space. starting locations close
sense, also important corresponding probes overlap little possible.
believe experimental results Section 4 support intuition.
remarked, work dynamic backtracking introduced first nonchronological, polyspace, weakly systematic sat engine. goal current paper describe new cdcl-based sat engine flex polyspace strongly systematic.
outline paper follows. Section 2, introduce necessary notation
describe standard cdcl algorithm. also describe choices typically made
implementing algorithms.
Section 3 describes flex algorithm; proof systematic polyspace
deferred appendix. discuss additional data structures needed guarantee
systematicity, restrictions must placed standard choices result.
Experimental results presented Section 4 concluding remarks Section 5.

2. Background, Notation Existing Work
satisfiability problem, mean collection clauses Boolean variables
as:
ab
b
b
b c
clauses disjunction, goal value variables
clause satisfied. particular example, make b true, c
false.
Definition 2.1 variable letter, a, b, c on. literal variable
negation variable. clause disjunction literals; (unsatisfiable) empty
clause denoted . theory conjunction clauses.
500

fiSatisfiability Systematicity

interpretation bias assignment true false variable theory.
interpretation said model theory every clause satisfied
interpretation.
often call theories sat instances satisfiability problems, think
clauses simply sets literals contain, writing, example, b.
similarly think theories sets clauses, think size theory
simply number clauses , denoting |T |.2
Modern satisfiability algorithms work manipulating partial assignments values
variables; idea either extend partial assignment value variables
(and eventually model theory question) show particular partial
assignment cannot extended model.
Definition 2.2 partial assignment sequence P = hl1 , l2 , . . . , ln literals
6= j, li 6= lj li 6= lj . variable v called valued P v P
v P . literal l called satisfied P l P , called falsified P
l P . clause c called falsified P every literal l c falsified P .
practice, variables assigned values partial assignment typically annotated
reasons sort. variable value may result choice made search
engine, obvious result previous choices:
Definition 2.3 annotated partial assignment sequence h(l1 , c1 ), (l2 , c2 ), . . . , (ln , cn )i
pairs, pair contains literal li clause ci . clause ci called
reason li , set {c1 , . . . , cn } {} denoted R(P ) called reasons
annotated partial assignment.
Given annotated partial assignment P , ith pair (l, c) P called justified
either c = l c every literal c l lj j < i. annotated
partial assignment P called justified every (l, c) P justified.
Note justified partial assignment always contain pairs form (l, ), since
justification condition trivially satisfied. use indicate l choice
made search algorithm:
Definition 2.4 P annotated partial assignment (l, ) P , say l
choice P . set choices P denoted C(P ). set negations
choices P denoted C(P ).
Similarly, justified partial assignment always contain pairs form (l, l),
use indicate l proven consequence theory
investigated.
general, partial assignments consider justified.
2. complexity perspective, might seem natural think size theory total
number literals clauses . choice bit convenient notationally theory
involving v variables, total number literals obviously v|T |.

501

fiGinsberg

Definition 2.5 Let P annotated partial assignment. (l, c) ith element
P , say assertion level l
|{j i|cj = }|
clause , say assertion level maximum assertion
levels literals .
words, assertion level literal number choice variables
precede P .
Definition 2.6 Let P annotated partial assignment theory . clause =
l1 ln literal satisfied P , exactly one literal unvalued
P , called unit.
single literal l unvalued P unsatisfied clause , extension
P model must include l, P remain justified partial assignment
add (l, ) end. called unit propagation:
Definition 2.7 Unit propagation procedure unit accepts input theory
justified partial assignment P . returns pair (P 0 , c) P 0 maximal justified
partial assignment extends P , P P 0 , either c = true c falsified
P 0 .
unit propagation returns c = true, unit propagation succeeded. returns partial
assignment P 0 clause c falsified P 0 , contradiction found c
reason.
Definition 2.8 say backtrack level zero every literal
assertion level, second greatest assertion levels literals otherwise.
Given annotated partial assignment P clause , define result backtracking , denoted backtrack(P, ), result removing P
literal assertion level greater backtrack level .
clause backtrack level n 6= 0, clearly literal l
assertion level l greater n. literal l unique, backtracking
backtrack level leave every element l unchanged,
(which contradiction prior backtrack) unit clause backtrack
complete.
sat implementations spend bulk time unit procedure;
consequence fact must search theory unit clauses. Moskewicz
et al.s (2001) introduction so-called watched literals zChaff sped process considerably, continues consume bulk computational resources implemented
systems.
Eventually, unit propagation either terminates without finding contradiction (presumably unit clauses remain ), returns clause c falsified
current justified partial assignment P . latter case, satisfiability engine needs
502

fiSatisfiability Systematicity

respond new information modify P way. Dpll, example, would
modify P simply returning recent choice point resuming search.
Cdcl implementations work differently. take P c produce new clause
entailed captures, best possible, reason went wrong.
example, suppose P gives = b c reason c (so P contains
a, b therefore c), = c appears . clause falsified
P . resolve get new clause b, also falsified P
suggests (correctly) either b source problem even many
variable choices appear subsequently P itself. may enable much deeper backtrack
simply returning recent choice point.
Definition 2.9 Let P justified partial assignment, c clause falsified P .
(P, c)-conflict mean clause logical consequence c together
reasons P also falsified P , c R(P ) |= P |= .
shown above, unit propagation identifies contradiction, use resolution
derive (P, c)-conflict P current partial assignment c conflicting
clause .
also sometimes more. Consider following theory:
b

(1)

b e c

(2)

e

(3)

f c

(4)

imagine e f true, choose make true well. unit
propagation allows us conclude b c b (and e), also c
(and e f ). single resolution (2) (the reason c) (4) (the reason
c) allow us conclude
b e f
(5)
go further, resolving (5) reason (1) b get e f
also resolving reason (3) get simply e f . last
conclusion correctly identifies source problem e f
true.
see example single (P, c) pair may many conflicts
generally need identify single conflict continue search.
general, want select conflict single literal assertion level.
allow algorithm redraw conclusion question backtracking
backtrack level conflict. Continuing example, suppose levels
choice literals involved 1 e f 4 choice literal a. explained,
following possible learned clauses case:
clause
b e f
e f
e f

assertion
level
4
4
4
503

literals
assertion level
b,
a,


backtrack
level
1
1
1

fiGinsberg

learn last clauses able draw unit conclusion
(a) backtracking level one.

Definition 2.10 Given justified partial assignment P clause , let n assertion level . called unique implication point, uip, unique
literal whose assertion level n.

Uips introduced grasp (Marques-Silva & Sakallah, 1999), experience
shown part strategy selecting conflict clause always select
uip. done resolving away reasons multiple literals assertion
level .
describe cdcl-based inference engine. so, recall Definition 2.1 bias complete assignment values variables. B bias v
variable, denote B(v) value specified bias v, B(v) B
B(v) = v B(v) = v. also define:

Definition 2.11 bias B set literals S, define result restricting B
S, denoted B|S , B|S = B {l|l S}.

Informally, result restricting bias label literals true, removing
negations appeared bias restriction performed.
bias intended capture current guess likely values model
. extend partial assignment take value new variable, choose
variable use value suggested bias. specific example idea
introduced Pipatsrisawat Darwiche (2007) rsat called phase saving
work.3

3. similar idea introduced slightly earlier Selmann Ansotegul (2006); earlier still, Beck (2005)
introduced idea saving preferred values use next portion search.

504

fiSatisfiability Systematicity

Procedure 2.12 (CDCL) Let theory, set clauses |= , B
bias . compute cdcl(T, , B, n), one of: shown unsatisfiable,
model P one found, unknown solution found n steps:
1 0;
2 < n
3
(P, c) unit(T , P );
4
c = true
5
P assigns value every variable return P ;
6
v variable unvalued P ;
// choice
7
(P, c) unit(T , hP, (B(v), )i);
8
(P, c)-conflict uip;
// choice
9
{};
10
B B|P ;
11
return ;
12
P backtrack(P, );
13
discard(, P );
// choice
14
ii+1
15 return unknown
algorithm hardly original us, let us give explanation event.
algorithm proceeds, P justified partial assignment considered
collection learned clauses.
algorithm works extending partial assignment P either solution
found (line 5) new clause learned (line 7 c 6= true). latter case,
identify new conflict-driven uip (line 8), add , backtrack unit,
repeat. update bias search proceeds; present line 10 rsat choice
updating bias every time variable set unit propagation. see
Section 3, choices also possible.4
new clause discovered added line 9, discard elements
(line 13); potentially shrink relatively small (and
potentially polynomial) number clauses retained. either give
encountered n backtracks, continue searching.
Recall annotated partial assignment P , R(P ) set reasons literals
P . (P, c) value returned unit propagation, abuse notation
somewhat use R(P, c) denote simply R(P ). have:
Lemma 2.13 Suppose R(unit(T , P )) discard() = ,
never discard reasons unit clauses become reasons. throughout
execution Procedure 2.12, |= P justified partial assignment
. addition:
4. attentive reader may wonder test line 11 appear added
line 9 bias updated line 10. reason flex may perform additional inference
point.

505

fiGinsberg

1. Procedure 2.12 returns , unsatisfiable. Procedure 2.12 returns P
partial assignment P , literals P model .
2. theory v variables n 2v , Procedure 2.12 return unknown,
independent nature discard.
Proof. first show invariants mentioned above. P justified partial assignment follows fact returned unit; justified partial assignment
obviously remain backtrack appears line 12. |= follows
fact entails (P, c)-conflict P justified partial assignment
c T.
consider various points Procedure 2.12 returns. line 5, P
model . line 11, unit propagation resolution collectively derived
(P, c)-conflict, |= unsatisfiable.
Procedure 2.12 return unknown bit subtle. see this, suppose
partial assignment P . associate P sequence positive
integers hn0 , n1 , . . . , nk i, nj number literals P assertion level j.
call sequence size P denote size(P ).
let n = hn0 , n1 , . . . , nk = hm0 , m1 , . . . , ml two sizes. say
smaller n, writing < n, one following two conditions holds:
1. j mj 6= nj and, first j, mj > nj .
2. mi = ni k, j k < j l mj > 1.
Informally, size partial assignment gets smaller, made progress
derived consequences earlier search tree, unexplored
region search space therefore gotten smaller. formalize via following
two claims:
1. Denote Pi partial assignment line 3 Procedure 2.12 given value
i. size(Pi+1 ) < size(Pi ).
2. s1 > s2 > > sz properly descending sequence sizes, z 2v , v
number variables theory question.
Note two results suffice complete proof, since follow
loop Procedure 2.12 repeated 2v times.
first claim, note new clause unit backtrack line 12.
Since unit, reason unit(T , P ) therefore cannot discarded
discard. let j assertion level . immediate unit
propagation line 12, least one new variable assigned value level j.
suppose size(Pi ) = hn0 , n1 , . . . , nk i, size(Pi+1 ) = hm0 , m1 , . . . , mj i. (The
number assertion levels Pi+1 necessarily equal j.) Pi Pi+1 agree
point backtrack, mk = nk k < j. j k (so backtrack brought
us Pi ), mj > nj size(Pi+1 ) < size(Pi ). If, hand, j > k,
506

fiSatisfiability Systematicity

sizes agree k mj > 1 conclusion unit consequence
level. proves first claim.
second, note first ordering conditions
unchanged append
P
end size hn0 , n1 , . . . , nk enough 1s ni = v. essentially pretends
added values subsequent variables, unit propagations
variables. write n result extending sequence way,
easy see n < n < m.
let n size. claim descending sequence length least 2vn0
steps beginning n ending size m0 > n0 . proof induction
v n0 .
v n0 = 1, n0 = v 1 must n = hv 1, 1i.
way make smaller = hvi, m0 > n0 .
inductive step, suppose n = hn0 , 1, . . .i. 2vn0 1 steps,
gotten hn0 , 2, . . .i inductive hypothesis. 2vn0 2 steps,
gotten hn0 , 3, . . .i, on. therefore arrive hn0 , v n0

vn
0 1
X

2vn0 = 2vn0 2

i=1

steps. One step, total 2vn0 1, causes n0 increment. 2vn0 steps thus cause
n0 increment well. completes induction.
imagine add new variable w theory, w appears clauses
evaluated first search begins. new theory v + 1 variables, given
size partial assignment must first component incremented
2(v+1)1 steps, either learned something w (an impossibility)
derived empty clause . Thus second claim follows lemma proved.
proof similar spirit proof Theorem 3.10, main theoretical
result.
general, Lemma 2.13 appears common knowledge sat community,
although unaware published proof second claim
completely clear sat community knows true.5
point, yet included restarts algorithm,
straightforward. define:

Definition 2.14 restart policy mapping r : IN, set positive
integers.
restart policy simply gives number backtracks permitted function
probe.
5. similar result, similar proof based assumption clauses ever deleted,
appear Section 4.2 Zhangs (2003) Ph.D. thesis.

507

fiGinsberg

Procedure 2.15 (CDCL restarts) Let theory r restart policy.
compute sat(T, n), either empty clause unsatisfiable model :
1 ;
2 B bias ;
// choice
3 1;
4 true
5
x cdcl(T, , B, r(i));
6
x 6= unknown return x;
7
+ 1;

2.1 Theoretical Results
show following:
Proposition 2.16 Let theory involving v variables, r restart policy.
Procedure 2.15 returns , unsatisfiable. Procedure 2.15 returns partial assignment
P , literals P model . addition:
1. R(unit(T , P )) discard(, P ) = r(i) 2v ,
Procedure 2.15 always terminate.
2. discard(, P ) = R(unit(T , P )), || v Procedure 2.15 executed.
3. discard(, P ) = , size may grow exponential v, independent
restart policy r.

Proof. proof Lemma 2.13 also shows Procedure 2.15 correct.
Claim 1 Proposition 2.16 follows immediately claim 2 Lemma 2.13. Claim
2 follows fact variable one reason R(P ). Claim 3
follows fact amount memory used Procedure 2.15 linear
run time clauses ever discarded, known many problems
shortest resolution proof exponential length (Bonet, Pitassi, & Raz, 1997;
Haken, 1985, 1995; Krajicek, 1997; Pudlak, 1997; Tseitin, 1970).
Corollary 2.17 weakly systematic, polyspace instances Procedure 2.15.
strongly systematic, exp-space instances Procedure 2.15.
Proof. Take discard(, P ) = R(unit(T , P )) get weakly systematic polyspace
instance virtue first two claims Proposition 2.16. discard() = ,
resulting instance strongly systematic instantiation eventually run
new clauses learn, may use exponential amount memory third
claim Proposition 2.16.
Tinisat exp-space, strongly systematic instance. Minisat (potentially) polyspace, weakly systematic instance.
508

fiSatisfiability Systematicity

2.2 Practical Concerns
addition selection restart policy, three points explicit
choice must made Procedure 2.12, one choice must made Procedure 2.15. line 6 Procedure 2.12, variable selected addition P . line 8,
particular conflict clause selected addition . line 13, set reduced,
presumably order conserve memory (and thereby speed unit propagation).
line 2 Procedure 2.15, initial bias selected.
Given much work sat currently focuses one implementation Procedure 2.15
(and therefore Procedure 2.12) another, considerable volume literature
choices. summarize work here, providing additional details
areas ideas constrain allowed options.
Variable bias selection Variables generally selected cdcl prover using
heuristic called vsids (variable state independent decaying sum) introduced
zChaff (Moskewicz et al., 2001). continue use vsids work
describe here.
also need specify initial bias, search choice valued
variables. real reason prefer one initial bias another, especially given
values likely overwritten search moves forward. follow
minisats example set every variable false initial bias.6
Conflict clause selection already remarked particular (P, c) pair
may many associated conflicts, generally wise select one uip.
allow algorithm redraw conclusion question backtracking
backtrack level conflict, central proof Lemma 2.13.
sometimes more. Recall running example, derived uip
e f . Suppose also actual choice literal level one g, e f
following g e g f respectively. continue resolution process,
using
g
learned clause instead e f . so?
Definition 2.18 uip called decision uip, duip, C(P ) |= ,
every literal negation choice P .
Proposition 2.19 Let P justified partial assignment clause falsified P .
(P, ) unique duip.
Proof. way construct duip resolve literals away decisions
remain. hard see set decisions obtained independent
order resolutions.
always work duip algorithm proceeds? Surprisingly, answer
appears no; extra resolutions seem move conflict away real
problem often not. one thing remove literals
6. naturally occurring problems, effectiveness biasing every variable false perhaps rooted
so-called closed world assumption (Clark, 1978; Reiter, 1978), concern us here.

509

fiGinsberg

simply unnecessary. running example reason f e f ,
obviously wise resolve conflict clause learned, replacing e f
properly stronger e.
Zhang et al. define first uip follows.7 basic idea want define
first uip uip minimal close eventual conflict possible.
Definition 2.20 annotated partial assignment P conflict c, (P, c)-conflict
uip called reduced proper subset (P, c)-conflict.
close eventual conflict, Zhang et al. actually mean uip question
late conflict graph possible:
Definition 2.21 Let P annotated partial assignment suppose 1 2
clauses falsified P . write 1 <P 2 every literal 1 either appears 2
reason includes least one literal 2 . (P, c)-conflict reduced
minimal transitive closure <P called first uip, fuip.
remarked above, 1 <P 2 1 closer eventual contradiction (and therefore
later implication graph) 2 .
Proposition 2.22 (Zhang, Madigan, & Moskewicz, 2001) Let P justified partial
assignment clause falsified P . (P, ) unique fuip.
basic idea proof construct fuip resolving enough
ensure working uip removing literals subsumed
literals . Additional resolutions needed produce new clauses
minimal <P .
Cdcl-based provers work uip, performance generally best
fuips used (Zhang et al., 2001).
learned clauses interact bias; general, want learn clause
conflict bias (and therefore encourages us adjust bias useful way).
Definition 2.23 Given bias B, uip called bias uip B, buip B,
B |= . buip minimal transitive closure <p Definition 2.21
called first buip, fbuip.
case bias B contains negations literals P (as Procedure 2.12 written), uip buip, since literals P always conflict
values B. case, fuip fbuip well.
also have:
Definition 2.24 Let P annotated partial assignment B bias. say
P supported B C(P ) B, every choice literal P appears B.
7. Zhangs description fuip bit less formal; Definitions 2.20 2.21 simply formalization
ideas.

510

fiSatisfiability Systematicity

words, bias supports annotated partial assignment choices made
P suggested bias.
Lemma 2.25 Let P justified partial assignment c clause falsified P ,
suppose B bias supports P . duip (P, c) also buip.
follows Proposition 2.19 bias supports annotated partial
assignment, least one buip, therefore least one fbuip.
difficult see fbuip unique (basically, stop resolving soon necessary
conditions met). Fbuips share crucial property modify learned clause
minimally subject restriction contradicts bias uip.
Discard strategy Clause reduction generally proceeds estimating likely future
value clause subsequent search. least valuable clauses periodically
removed search proceeds. free follow identical strategy, although
marked essential preserving systematicity. clauses
need retained independent estimated future value. procedure use
polynomial amounts memory, number clauses must guaranteed grow
polynomially size problem.

3. FLEX
Consider search polyspace, strongly systematic satisfiability algorithm.
immediately have:
Observation 3.1 Strongly systematic, polyspace satisfiability algorithms exist.
reason obvious. Imagine implementation cdcl restarts,
suppose maintain, one restart another, separate partial assignment PD
constructed dpll. additional data structure requires polynomial memory (at
v clauses, size v), simply incorporate clauses
PD , resulting algorithm clearly systematic.
practice, however, essentially value. systematicity guaranteed
dpll completely separate inference going individual probes,
unlikely additional clauses much constrain search. addition,
restart policies restart relatively infrequently, guarantee
2v restarts required satisfying theoretical perspective, may little
value practice.
3.1 Pure FLEX
Far interesting would find instance Procedure 2.15 strongly
systematic. Showing possible main theoretical result paper.
basic idea behind method manage set learned clauses
retain enough information ensure solver making progress lexicographic
sense, identify variables lexicographically earlier others.
lexicographic ordering quite weak, weakened possible search
511

fiGinsberg

proceeds. So, example, make progress eliminating one possible value
variable a, drop restrictions relative ordering variables follow
(although need remember indeed follow a).
get somewhat better feel this, imagine ordered variables
theory way, variables ordered v1 < v2 < < vm .
view progress eliminate value variable vi without
introducing new possible values vj j < i. repeatedly this,
eventually manage eliminate value v1 , value remain eliminated
search proceeds. eventually eliminate one two values v2 , on.
say making lexicographic progress happens.
fact, dont need maintain complete ordering variables question.
make progress eliminating value vi , really need remember variables precede vi ordering (since eliminated values must remain
eliminated). Variables following vi ordering reordered subsequent search
suggests so.
formalize this, maintain partial order variables appearing theory
Procedure 2.12 executed.8 learn something new particular variable
x, should, described above, free discard information regarding relative
ordering variables follow x partial order. Since eliminated value
variable x, ordering information longer needed. formalize
follows:
Definition 3.2 partial order x point, define weakening
x, denoted x , partial order given x z z either
= z x 6< y.
words, weakened partial order original forgets
< z x < < z, z follow x partial order.
Proposition 3.3 x partial order.
Proof. Reflexivity immediate. transitivity, suppose u x v x w. u = v,
u x w since v x w. u 6= v, x 6< u since u x v. also u v w
u w. Thus u x w. Anti-symmetry x follows immediately anti-symmetry
.
specific example, initial partial order < given < b < c < d, weakening partial order b produces <b b, b <b c b <b d. c incomparable
b , since followed b original partial order.
imagine justified partial assignment P . (l, ) pair P , isWreasonable
think implying l. words, think disjunction = j lj
l1 li1 li+1 lk li
8. note passing possible, difficulty, modify work deal
case preorder instead partial order. provides additional flexibility
manipulation bias, obvious additional flexibility practical value.
discuss partial order case interest maintaining clarity exposition.

512

fiSatisfiability Systematicity

li = l literal (l, ) pair. retain partial assignment
one search probe another, retain partial ordering use split
antecedent conclusion particular clause. specific example, c
follows b ordering, c b c, clause b c interpreted
b c.
general, clause partial order, think -maximal elements
conclusion, rest antecedent:
Definition 3.4 Let clause partial order variables contains.
conclusion , denoted , disjunction
= {l | 6 , > l}
antecedent , denoted , = ( ).
conclusion learned clause disjunction maximal literals ,
antecedent negation whats left.
Again, example may help. Suppose = b c partial order
c b d. c maximal elements , conclusion
disjunction c d. antecedent
= ( )
= ({a, b, c, d} {c, d})
= {a, b}
= (a b)
= b
one would expect. learned clause effectively rewritten
b c
cavalier use notation, switching freely representing
disjunction set.
Definition 3.5 set learned clauses partial order, denote
conjunction antecedents . denote conjunction
conclusions .
finally position describe procedure add new clause
. Procedure 2.12, via simple {} line 9, bit
complex. addition also modify partial order replace
lexicographically stronger clause circumstances:
513

fiGinsberg

Procedure 3.6 compute add(, , ):
1 = return (, {}, );
2 select l ;
// l intended conclusion
3 = l
4
return add(resolve(, ), , )
5 add x l x ;
6 l ;
7 remove c either c {l, l} =
6 c {x|l < x} =
6
|c | > 1;
8 return (, {}, )
Line 1 handles edge case actually derived contradiction. Line 4
calls resolution l l appear conclusions clauses , line 7 says
clauses deleted include either l l antecedent,
ambiguous conclusions based variables follow l partial order.
keeping overall lexicographic approach: make progress
particular literal l, forget everything following literals partial order,
removing relative orderings (as per weakening line 6 Procedure 3.6)
clauses contain (as per removal line 7).

Proposition 3.7 Suppose contains n clauses involving v variables. Procedure 3.6 executed O(v 3 + nv 2 ) time.

Proof. Except recursion, expensive steps line 6, potentially
take time O(v 2 ) line 7, take time O(nv). assumes determine
whether x < time O(1), whatever data structure used retain partial
order, always compute entire partial order iteration loop,
take time O(v 2 ). total time taken without recursion thus bounded
O(v 2 + nv).
maximum number recursive calls O(v), since variable resolved
upon once.
o(v 2 ) unit propagation procedure remains practical problems containing
millions variables, expect add procedure 3.6 well. (And roughly
reasons: Clauses length v, literals generally appear relative
handful clauses, on.)
Procedure 3.6 primary difference standard cdcl algorithm flex;
replace act adding involved Procedure 3.6.
so, note Procedure 3.6 may actually derive empty clause line 4;
return theory containing empty clause line 1, leading failure line 11
Procedure 2.12. have:
514

fiSatisfiability Systematicity

Procedure 3.8 (Pure FLEX) Let theory, set clauses |= ,
partial order variables , B bias . compute flex(T, , , B, n),
one of: shown unsatisfiable, model P one found, unknown
solution found n steps:
1 0;
2 < n
3
(P, c) unit(T , P );
4
c = true
5
P assigns value every variable return P ;
6
v variable unvalued P ;
7
(P, c) unit(T , hP, (B(v), )i);
8
(P, c)-conflict uip B |= ;
9
(, , ) add(, , );
10
B B| ;
11
return ;
12
P backtrack(P, );
13
ii+1
14 return unknown
Note require selection buip line 8 Procedure 3.8 (since require
B |= ), adjust bias cater conclusion new clause
line 10. observations important discuss practical implementation
methods.
modification needed Procedure 2.15 initialize use partial
order :
Procedure 3.9 (Pure FLEX restarts) Let theory r restart policy.
compute sat(T, n), either empty clause unsatisfiable model :
1 ;
2 ;
3 B bias ;
4 1;
5 true
6
x flex(T, , , B, r(i));
7
x 6= unknown return x;
8
+ 1;
finally have:
Theorem 3.10 Suppose theory n clauses involving v variables. Then:
1. loop Procedure 3.8 executed time O(v 3 + nv 2 ),
2. || v Procedure 3.9 executed,
515

fiGinsberg

3. n
n.

Pn

i=0 r(i)

2v , Procedure 3.9 finish completing iteration

Corollary 3.11 Procedure 3.9 strongly systematic polyspace.

proof Theorem 3.10 lengthy appears appendix.
Note contribution show possible ensure systematicity
retaining sufficient number learned clauses. Tinisat already shown this,
Lecoutre et al. shown (2007) retaining single nogood per restart suffice.
work, number restarts grows polynomially number
backtracks, therefore potentially exponentially problem size. earlier
results thus may require keeping exponential number learned clauses; contribution
show polynomial number nogoods suffice.
3.2 Hybrid FLEX
Procedures 3.8 3.9 achieve basic theoretical goal set paper, direct
implementation procedures written encounters two practical difficulties.
First, add procedure expensive. Executing every backtrack introduces
overall computational burden greater unit propagation.
Second, search Procedure 3.8 guided bias B, bias modified
match every unit propagation, match conclusions newly learned
clauses. Experimentation shows rsat bias, matching result every
unit propagation, effective practice. cannot value newly selected variables
rsat, since bias doesnt support nogood, may buip line 8
Procedure 3.8. fact, experimentation number factoring problems shows approximately 40% time, none clauses learned particular probe resolved
buip.
Nevertheless, straightforward way deal issues still preserve
intuition underlying approach. probe, follow bias new
clause learned. new clause buip (because bias followed
constructing it), incorporate new clause usual. complete
probe using rsat bias. this, follow rsat bias almost time
call add per probe, eliminating substantial computational overhead
procedure might introduce.
refer compound procedure hybrid flex, simply flex. order
implement it, need maintain two biases, refer B (for flex
component) R (for rsat component), two sets learned clauses,
refer (for flex component) (for conventional component). finally
have:
516

fiSatisfiability Systematicity

Procedure 3.12 (FLEX) Let theory, sets clauses |= ,
partial order variables , B R biases . compute
flex(T, , , B, , R, n), one of: shown unsatisfiable, model P one
found, unknown solution found n steps:
1 0;
2 < n
3
(P, c) unit(T , P );
4
c = true
5
P assigns value every variable return P ;
6
v variable unvalued P ;
7
= 0 l B(v);
8
else l R(v);
9
(P, c) unit(T , hP, (l, )i);
10
= 0
11
(P, c)-conflict uip B |= ;
12
(, , ) add(, , );
13
B B|
14
else
(P, c)-conflict uip;
15
{};
16
R R|P
17
return ;
18
P backtrack(P, );
19
discard();
20
ii+1
21 return unknown

Procedure 3.13 (FLEX restarts) Let theory r restart policy.
compute sat(T, n), either empty clause unsatisfiable model :
1 ;
2 ;
3 B R bias ;
4 1;
5 true
6
x flex(T, , , B, , R, r(i));
7
x 6= unknown return x;
8
+ 1;
Theorem 3.10 Corollary 3.11, have:
Corollary 3.14 Procedure 3.13 strongly systematic polyspace discard procedure ensures polyspace.
517

fiGinsberg

4. Experimental Results
present experimental results based methods, let us describe setting
experiments performed.
First, expect value results vary problem size. one major
advantage existing methods, strong systematicity approach cause
probes late search examine areas search space unexplored earlier.
advantage also drawback, however. Especially early search,
probes small, rsat bias known extremely effective likely see
performance degradation fact cannot follow bias first set
choices particular probe.
easy problems, would expect methods perform worse conventional ones inability begin probes following rsat bias. difficult
problems, would expect methods perform better conventional ones,
manage reach new areas search space older methods reexamining previously explored regions. dont know transition
two general problem types.
order evaluate this, used two separate sets problems experiments.
first set 1030 problems sat 2013 benchmarks. problems solved
5000 second cutoff order ensure processes terminated.
second set problems used number factoring problems (Bebel & Yuen, 2013).
Although subexponential algorithms number factoring known exist (Buhler,
Lenstra, & Pomerance, 1993, great deal subsequent work), reason
believe techniques involved bear significantly sat encodings
problems.
One advantage using number factoring problems gradually increasing difficulty run completion every case, avoiding fact simple timeout less
informative regarding overall computational efficacy time needed actually
solve problem. Problems gradually increasing difficulty generated simply
increasing magnitudes numbers factored.
number factoring problems generated using iterated Miller-Rabin test
generate pairs primes using Purdom/Sabry (2005) sat generator produce
sat encoding problem factoring product primes. order avoid
situations factoring problem might easy, prime factors selected
sizes binary representations within three bits one another.
given problem size (number bits number factored), fifty instances
generated randomly.
baseline solver, used minisat 2.2 (Sorensson & Een, 2005).
fact three separate sets changes needed make produce flex:
1. First, converted minisat C C++ changed use C++ standard
library many locations instead variety specialized techniques included
minisat. refer solver stlsat.
2. Second, flex expected efficient number restarts increases.
minisat similar solvers, number backtracks restarting given
518

fiSatisfiability Systematicity

10000

1.22 x ** 0.9916
x

1000

stlsat

100

10

1

0.1

0.01
0.01

0.1

1

10
minisat

100

1000

10000

Figure 1: minisat vs. stlsat, sat competition problems (CPU time seconds)
specified original Luby policy (Luby et al., 1993), instead multiplying
Luby numbers constant (generally taken 100, first probe
involves 100 backtracks). order increase number probes, reduced
multiplicative factor four (so first probe involves four backtracks).
refer solver stlsat4 .
3. Finally, modified stlsat produce flex, also initial probe size four.
present results sat 2013 benchmarks first, followed results number
factoring. compare minisat stlsat, stlsat stlsat4 , stlsat4 flex.
experiments run 24-core Intel Xeon machine running 2.2GHz 256K
L2 cache per processor, 24GB main memory, 75GB swap space. 24 problems
solved time, swap space needed deal larger sat
competition instances, since many running parallel.9
software used experiments available online appendix paper.
stlsat.zip contains source stlsat, flex.zip contains source flex. (Stlsat
flex various extensions removed.)
4.1 Sat Competition Problems
Figure 1 compares minisat stlsat sat competition problems. solver
closer original minisat always x-axis, modification y-axis,
9. evaluate impact use swap running times larger problems, although
obviously might substantial. practice, however, significant amounts swap used,
none systems evaluated able solve problem question. addition, running
problems serially would simply impractical given available hardware.

519

fiGinsberg

10000

1.14 x ** 0.9999
x

1000

stlsat_4

100

10

1

0.1

0.01
0.01

0.1

1

10
stlsat

100

1000

10000

Figure 2: stlsat vs. stlsat4 , sat competition problems (CPU time seconds)

axes plotted using log scale dashed line giving = x baseline. One
point plotted problem solved either two methods. point x =
means old solver better; point x = y, new solver better.
many cases, also give best polynomial fit form = axb fixed
b. Figure 1, stlsat seen 22% worse minisat outset,
exponent slightly one indicates disparity shrinking problems
become difficult. (Indeed, apparent looking graph itself.)
find polynomial fit, use standard technique minimizing
squared vertical distance point line question. reason
flipped axes, would minimizing squared horizontal distance
line, potentially different fit would found. ensure fit
found independent axis selection, minimized sum squares actual
(perpendicular) distances data points line question.
cases, split data depending whether problem instances
solved satisfiable. interesting distinction here.
results one might expect. Without fine-tuned data structures minisat, stlsat performs slightly worse. significant easy problems,
two solvers appear virtually identical difficult instances.
Figures 2 3 show impact reducing number backtracks per probe. Overall
(Figure 2), 14% cost making change, cost nearly independent
problem size. Somewhat curiously, however, cost significantly different satisfiable
instances (a 22% cost, top Figure 3) compared unsatisfiable ones (a 7% savings,
bottom Figure 3).
520

fiSatisfiability Systematicity

10000

1.22 x ** 1.0043
x

stlsat_4 -- SAT

1000

100

10

1

0.1

0.01
0.01

stlsat_4 -- UNSAT

10000

0.1

1

10
stlsat -- SAT

100

1000

10000

0.93 x ** 0.9999
x

1000

100
100

1000
stlsat -- UNSAT

10000

Figure 3: stlsat vs. stlsat4 , sat competition problems (CPU time seconds)

521

fiGinsberg

100000

3.60 x ** 0.9935
x

10000

1000

flex

100

10

1

0.1

0.01
0.01

0.1

1

10
stlsat_4

100

1000

10000

Figure 4: stlsat4 vs. flex, sat competition problems (CPU time seconds)

Note scatter cases much significant Figure 1.
expected stlsat intended essentially unchanged minisat
algorithmic perspective, change restart frequency expected
fairly dramatic effects. Note also collection points either x = 5000 = 5000,
indicating problem solved one method timed using other.
Finally, Figure 4 compares stlsat4 flex sat competition problems, flex
factor 3.6 slower (4.53 times slower satisfiable instances; 2.01 times slower
unsatisfiable ones).10 Many problems time flex modified
version minisat.
shown clearly Figure 5, compare number problems
solved stlsat4 flex sat competition problems. specific time
cutoff, stlsat4 solves 2.5 times many problems flex.
appear case, however, performance gap narrowing
problems become difficult; example, flex solves 36 problems 3000
5000 seconds; stlsat4 solves 42 problems time. reason
examined number factoring problems well.11

10. graphs satisfiable unsatisfiable instances shown; look basically
Figure 4.
11. Note cannot simply increase timeout limit sat competition problems; caused
relative handful new problems solved. generate interesting number
difficult problems, want instances known satisfiable, number factoring seems
simplest way go.

522

fiSatisfiability Systematicity

300

flex
stlsat4

250

problems solved

200

150

100

50

0
0.01

0.1

1

10
CPU time (secs)

100

1000

10000

Figure 5: stlsat4 vs. flex, sat competition problems (5000 second timeout)
100000

1.06 x ** 1.0069
x

10000
1000
100

stlsat_4

10
1
0.1
0.01
0.001
0.0001
1e-05
0.0001

0.001

0.01

0.1

1
10
stlsat (all SAT)

100

1000

10000

100000

Figure 6: stlsat vs. stlsat4 , factoring problems (CPU time seconds)

4.2 Number Factoring
number factoring, generated 50 factoring problems size five 45 bits.
problems run stlsat, stlsat4 flex.
523

fiGinsberg

100000

1.41 x ** 0.9743
x

10000
1000
100

flex

10
1
0.1
0.01
0.001
0.0001
1e-05
1e-05

0.0001

0.001

0.01

0.1
1
10
stlsat_4 (all SAT)

100

1000

10000

100000

Figure 7: stlsat4 vs. flex, factoring problems (CPU time seconds; 5000 second timeout)

(relatively uninteresting) result comparing stlsat stlsat4 shown
Figure 6. sat competition problems, reducing size first probe four
backtracks leads small degradation performance satisfiable problems. include
primarily ensure change probe size responsible results
following figures.
Flex stlsat4 compared Figure 7. Here, show problems one
method able solve 5000 seconds less, although exact times
solution used solvers. figure also includes dotted lines indicating 5000
second timeout either solver.
overall results similar previous section, although flexs performance improved somewhat. sat competition problems, 3.6 times slower overall
4.53 times slower satisfiable problems specifically. number factoring problems,
flex 41% slower stlsat4 .
curve fit dominated large number easy problems case.
addition, appears flex actually better stlsat4 problems
become difficult; many problems appear timing stlsat4 (points
right x = 5000 seconds Figure 7) flex (points = 5000
figure). suggests instead looking easiest factoring problems, look
hardest ones.
done Figure 8, consider problems one two solvers
required least 5000 seconds reach solution. results strikingly different.
glance shows flex general solving problems quickly stlsat4 ; fact,
524

fiSatisfiability Systematicity

100000

0.24 x ** 1.0010
x

flex

10000

1000

100

10

10

100

1000
stlsat_4 (all SAT)

10000

100000

Figure 8: stlsat4 vs. flex, factoring problems (CPU time seconds; 5000 seconds
harder)

100000

0.13 x ** 1.0101
x

flex

10000

1000

100

10
100

1000

10000

100000

stlsat_4 (all SAT)

Figure 9: stlsat4 vs. flex, factoring problems (CPU time seconds; 10,000 seconds
harder)

525

fiGinsberg

100000

stlsat
flex

10000

average CPU time (secs)

1000

100

10

1

0.1

0.01

0.001

0.0001

5

10

15

20

25
bits

30

35

40

45

Figure 10: stlsat4 vs. flex, average time factor n-bit number

line best fit shows flex four times fast stlsat4 . Restricting
problems took least 10,000 seconds makes distinction sharper still;
(Figure 9) flex eight times faster stlsat4 .
Similar results appear Figure 10, shows average running time needed
flex stlsat factor number n bits. Flex slower smaller numbers
faster larger ones. unfortunately impractical extend graph much further, since
average runtime stlsat single 45-bit factoring problem already approximately
six hours.
previously, show number difficult problems (40 bits more) solved
solvers function time Figure 11. cutoff less 1000 seconds, stlsat4
performs best; problems get harder, reversed.

5. Conclusion Future Work
fundamental claim made paper sat community
need abandon systematicity methods switched dpll-style
provers cdcl-based ones. showed possible simultaneously guarantee
systematicity, maintain polynomially-sized set learned clauses, restart prover
frequently desired. Furthermore, showed hybrid pure
systematic prover typical cdcl engine incurs significant computational cost
achieving goals, cost recovered run time appears reduced
difficult problems.
Looking forward, two obvious ways work extended.
526

fiSatisfiability Systematicity

300

flex
stlsat4

250

problems solved

200

150

100

50

0
1

10

100
1000
CPU time (secs)

10000

100000

Figure 11: stlsat4 vs. flex, factoring problems (40 bits larger)

First, seen value methods increases number restarts
increases. One principal reasons limit number restarts cdcl-based
prover restarting prover expensive. Recent work Ramos et al. (2011),
however, suggests significant part expense avoided. basic idea
particular probe may well begin search repeating many literal
choices unit propagations previous probe. case, reason
backtrack past point two probes first diverge. Incorporating idea
methods improve value enabling larger number restarts
thus making systematic component offer effective.
Second, hope overall approach proposed guaranteeing systematicity retaining partial order appropriate set learned clauses finally
puts rest notion sat engines achieve systematicity careful management
search space defined partial assignments. instead learned clausal database
guarantees systematicity semantic methods.
general conclusion lead variety new algorithmic choices.
example, values represented bias presumably best thought probabilistic
estimates regarding likelihood particular literal appearing model
theory question. probabilistic approach gives different flavor satisfiability
general, suggests recent results Monte Carlo Tree Search, mcts (Browne,
Powley, Whitehouse, Lucas, Cowling, Rohlfshagen, Tavener, Perez, Samothrakis, & Colton,
2012; Kocsis & Szepesvari, 2006, others) may well find place sat well.
527

fiGinsberg

Acknowledgments
would like thank Connected Signals Time Systems coworkers, especially
Aran Clauson Heidi Dixon, useful technical advice assistance. would also
like thank anonymous referees many carefully considered comments
suggestions, improved paper enormously. Finally, would like thank David
McAllester many contributions work years; work presented draws
greatly McAllesters original work (1993) partial-order dynamic backtracking.

Appendix A. Proof Theorem 3.10
proof Theorem 3.10 depend certain invariants maintained Procedure 3.8 executed. begin discussing invariants.
A.1 Learned Clauses
understand them, suppose set learned clauses derived
course systematic search. conditions would expect satisfy?
answer this, imagine partial assignment P derived
new learned clause add .
certainly expect P satisfy existing learned clauses. also assume
P satisfies antecedents learned clauses; keeping idea
learned clauses continue relevant portion search space
explored.
new clause ? First, turn unique
conclusion partial order . addition, new learned clause new
knowledge sense eliminates portion search space still admissible
. words, expect conclusion distinct conclusions
elements .
Formally, have:
Definition A.1 say partial order parses learned clause | | = 1.
say set learned clauses acceptable partial order
following conditions hold:
1. , parses ,
2. 1 , 2 , 1 = 2 , 1 = 2 ,
3. 6|= .
first condition repeats requirement conclusions individual
literals. second condition says contain two distinct learned clauses
conclusion. third says least possible find partial
assignment P described above, since collection learned clauses consistent
antecedents learned clauses.
Lemma A.2 acceptable partial order , contains one learned
clause particular variable x conclusion.
528

fiSatisfiability Systematicity

Proof. contains clauses x x conclusions, impossible
, contradicting requirement acceptability.
Proposition A.3 set clauses involving v variables acceptable partial
order , || v.
A.2 Search Space Size
considering general way new clause allows us improve bias,
way new clause incorporated , let us examine simple special
case fact total order variables question. means
particular learned clause always interpreted forcing value single variable
contains occurs latest ordering .
given set learned clauses , extend P either solve problem
derive new learned clause . Given bias B, assuming B |=
learned clause allows us improve bias, already remarked assume
B consistent . follows consistent well. l
conclusion , update ?
Note first l conclusion. were,
would |= l therefore |= also. two cases: may
contain learned clause conclusion l, may contain learned clause.
contain learned clause conclusion l, would like simply add
. may cause become unacceptable, since may contain learned
clause l antecedent. simply add , result unacceptable
respect impossible satisfy elements
simultaneously satisfying antecedents.
example, suppose contains learned clause c d, antecedent
c. learn c simply add , includes c
c, contradiction.
case remove every learned clause l
antecedent; call result 0 . take add(, ) 0 {}. parses
obviously continues parse learned clauses remaining 0 . 0 {} therefore
acceptable respect , since l longer appear antecedent learned
clause 0 .
Given discarded learned clauses , basis
concluding procedure eventually terminate? do. mentioned
main body text, key observation made lexicographic progress
search space. true allowed domains variables following
l may gotten bigger replaced 0 , domain l gotten
smaller. Since l precedes variables total order, made lexicographic
progress systematicity remains guaranteed.
Consider second case, contain learned clause conclusion l.
Note first since acceptable, learned clause concluding l must unique.
resolve learned clause obtain new learned clause . Every variable
precedes l according ordering , conclusion must precede l well.
thus continue make lexicographic progress define add(, ) add(, ),
529

fiGinsberg

essentially chosen incorporate lexicographically powerful resolvent
instead original learned clause .
ensure ideas clear, suppose original learned clause set
given following, ordering ranks variables alphabetically:
ac

(6)

cd e
new learned clause b f , simply add . learned clause
need removed conclusion f appear antecedent learned
clause .
added b f , suppose learn c. example above,
add learned clause remove every learned clause whose antecedent includes
c, means original learned clauses removed , although
b f retained. new set is:
ab f

(7)

c
made lexicographic progress. true, original learned clause set (6)
allowed c either true false; new learned clause set (7) forces c false.
Reducing number possible values c counts progress, whatever happens
possible values subsequent variables.
Suppose instead learning c, learned c f . conflicts
b f , resolve two together obtain b c, total order
causes us interpret b c. add previous paragraph;
again, lexicographic progress made.
restricted example contains essence ideas use general
case. general case complex because, must ensure remains
acceptable, would also like ensure partial order remains flexible
possible. approach total order, would tend force specific interpretations
newly learned clauses, reducing ability reverse decisions made early
search. would mean would relatively little flexibility modifying
bias; would always simply flip bias variable recently valued
even evidence accumulated variable valued correctly.
begin formalizing notion lexicographic progress.
Definition A.4 set learned clauses total order, denote
||x number elements conclusion either x x. denote
|>x| number > x.
v number variables considered, define total order size

X
sizet (, ) = 2v
2|>x| ||x
(8)
x

Proposition A.5 acceptable total order , 2v sizet (, ) > 0.
530

fiSatisfiability Systematicity

Proof. first inequality immediate. second, since ||x 1,
sizet (, ) 2v

X

2|>x|

x

consider summation isolation, have:
X

2|>x|

x

v
X

2i1 = 2v 1.

i=1

Thus sizet (, ) > 0.
moving on, let us explain intuition underlying Definition A.4. basic
idea expression (8) reflect size search space remaining
considered,
X
2|>x| ||x
x

counts number potential models eliminated learned clauses .
fairly clear. unique learned clause ||x eliminates value
x. elimination corresponds removal subtree overall search
space. size subtree given 2|>x| , since |>x| number variables properly
following x ordering.
Proposition A.6 Fix total order , let 0 two sets learned clauses.
Assume x ||x < |0 |x ||y = |0 |y < x.
0 total order agrees restricted set {y, z|y, z x},
sizet (0 , 0 ) < sizet (, ).
Proof. simply formalization lexicographic argument made earlier. show
sizet (, ) sizet (0 , 0 ) > 0,
sizet (, ) sizet (0 , 0 ) =

X

0

2|> y| |0 |y

X

y0

2|>y| ||y

(9)



show:
1. < x,
0

2|> y| |0 |y = 2|>y| ||y

(10)

2|> x| |0 |x 2|>x| ||x 2|>x|

(11)

2. = x,
0

3. > x,
X

2|>y| ||y < 2|>x|



531

(12)

fiGinsberg

Collectively, suffice. terms (10) < x effect difference (9).
amount contributed term (11) = x greater amount subtracted
terms (12) > x. Thus total sum positive result follows.
(10) consequence fact x, |>0 y| = |>y| |0 |y = ||y . (11),
since |0 |x > ||x , get
2|>x| ||x 2|>x| (|0 |x 1)
0

= 2|> x| |0 |x 2|>x|
(12), sum essentially identical appearing end previous
proof.
Definition A.7 partial order 0 called refinement partial order x
x 0 y. refinement total order called total refinement .
Definition A.8 set learned clauses partial order , define size
, denoted size(, ), maximum sizet (, 0 ) total refinements
0 .
following immediate consequence Proposition A.5:
Corollary A.9 acceptable partial order , 2v size(, ) > 0.
point state desiderata add bit precisely.
need:
1. Polynomial space: acceptable respect ( 0 , 0 , 0 ) = add(, , ),
want 0 acceptable respect 0 . allow us use Proposition A.3 conclude stored polynomial space algorithm
proceeds. bias B obviously stored polynomial space well.
2. Systematicity: ( 0 , 0 , 0 ) = add(, , ), want size(0 , 0 ) < size(, ).
allow us use Corollary A.9 conclude add invoked
2v times entire search space eliminated.
A.3 Systematicity
Recall:
Procedure 3.6 compute add(, , ):
1
2
3
4
5
6
7

8

= return (, {}, );
select l ;
// l intended conclusion
= l
return add(resolve(, ), , )
add x l x ;
l ;
remove c either c {l, l} =
6 c {x|l < x} =
6
|c | > 1;
return (, {}, )
532

fiSatisfiability Systematicity

Proposition A.10 Suppose acceptable respect , 6|= .
( 0 , 0 , 0 ) = add(, , ), 0 acceptable respect 0 .
Proof. Note first procedure terminates. possible source nontermination recursive call line 4, conclusion resolvent necessarily <
conclusion . number recursive calls therefore bounded, procedure
terminates.
show 0 acceptable, consider first nonrecursive case
conclusion l. three conditions Definition A.1, have:
1. show 0 parses c c 0 , two cases.
c learned clause , know construction 0 includes x every
appearing c.
case c , need following lemma:
Lemma A.11 Suppose x u x 60 u. l <0 x l < x.
Proof. Suppose denote + partial order constructed line 5
procedure, additional arcs added original . Since + refinement
, clear x u, x + u well.
+
0
+
0 =+
l , way x u x 6 u l < x,
0
l < x well.

show l < x, note l <0 x, l <+ x arcs removed
construction <0 <+ . l <+ x must also l < x, since arcs
added construction <+ form z < l.
0

Returning proof proposition, suppose y, z c z
incomparable 0 . either l <0 l <0 z, clause question would
eliminated line 7 add construction, follows l 6<0
l 6<0 z.
claim u c < u. u, would
0
0 u virtue lemma, 6 c . Similarly u c z < u.
Thus y, z c therefore = z, since parses c.
2. show two elements 0 conclusion, note first two
elements 0 conclusion original partial order .
true construction two elements . new learned clause
conclusion element , would |= .
way conclusion c 0 0 different conclusion
y, z c < z z <0 y. lemma
must l < l <0 y. Since l < < z, l < z therefore l <0 z.
weakening line 6 causes z incomparable <0 .
533

fiGinsberg

3. Finally, must show 00 6|= 0 , 00 0 consistent.
see this, use fact 6|= find complete assignment P
values variables satisfies , . Note P must satisfy
antecedent include l order falsify .
claim P |l satisfies 00 0 . P |l continues satisfy antecedent
, since l 6 , P |l satisfies since contains l. therefore need consider
c 0 appear well.
Since P satisfies c c , way P |l might satisfy c c0
P |l fails satisfy c conclusion c longer satisfied, P |l fails
satisfy c0 one terms antecedent longer satisfied.
first cannot happen P |l differs P l, l cannot cs
conclusion. second cannot happen l appears antecedent c,
c would removed construction 0 .
concludes proof remains acceptable nonrecursive path taken
add; see recursive path remains acceptable well, need show
fundamental requirement 6|= holds recursive call.
words, proof complete show 6|= resolve(, ) line 4.
Suppose |= resolve(, ), note
resolve(, ) =
, must therefore
|=
would imply |= , contradicting assumptions proposition.
proof complete.
Proposition A.12 Suppose acceptable respect , 6|= .
( 0 , 0 , 0 ) = add(, , ), size(0 , 0 ) < size(, ).
Proof. need following lemma:
Lemma A.13 Let partial order x point. Tx total refinement
x , total refinement Tx agree restricted
{y, z|y, z Tx x}.
Proof. Define 0 z following three conditions hold:
1. y, z Tx x Tx z,
2. x <Tx y, z z,
3. Tx x <Tx z.
534

fiSatisfiability Systematicity

claim 0 partial order satisfying requirements lemma. (Informally,
0 partial order matches x Tx x.)
0 reflexive clear. transitivity, suppose u 0 v 0 w. x <Tx u,
second clause definition one support u 0 v, must
x <Tx v similarly x <Tx w together u v w, u 0 w. w Tx x,
analogous argument applicability first clause requires v Tx x similarly
u Tx x; transitivity Tx gives u Tx w u 0 w also. Finally, u Tx x <Tx w,
get u 0 w directly.
see 0 anti-symmetric, suppose u 0 v 0 u u 6= v. cannot
u Tx x Tx v v Tx x Tx u Tx partial order, either first
second clause definition 0 must apply. Either way, must u = v
Tx partial orders.
see Tx 0 agree restricted points z y, z Tx x, note
first clause definition ever asserts 0 x y, clause
says Tx 0 match.
remains show 0 refinement , z, 0 z.
suppose z. x y, x x therefore x Tx y. Similarly,
x Tx z. Thus case 2 definition applies, 0 z.
If, hand, x 6 y, x z definition weakening x . Thus
Tx z well. two cases, depending Tx relationship x
y:
1. x Tx y, x Tx z well case 2 definition implies 0 z.
2. Tx x (recall Tx total), two subcases:
(a) x Tx z, case 3 definition applies 0 z.
(b) z Tx x, case 1 applies.
cases, conclude 0 z z.
shows 0 partial order satisfying conditions lemma. Taking
total refinement 0 completes proof.
return proof Proposition A.12. earlier, denote +
partial order obtained line 5 add procedure, added new constraints
based selection l conclusion . show
size(0 , 0 ) < size(, + ) size(, )

(13)

second inequality easy; since + refinement , fewer
refinements consider Definition A.4 size. first inequality, 1 total
order used evaluate size(0 , 0 ), must show total order 2 used
evaluate size(, + ) sizet (0 , 1 ) < sizet (, 2 ).
Recall lines 5 6 Procedure 3.6 constructed 0 +
l . follows 1
total refinement +
.

therefore
know


lemma

2
l
total refinement + 1 2 agree {x, y|x, 1 l}. Since 0 ,
|0 |l > ||l thus apply Proposition A.6 conclude
sizet (0 , 1 ) < sizet (, 2 )
535

fiGinsberg

follows maximum 1 less maximum 2 s,

size(0 , 0 ) < size(, + )
needed (13). proof complete.
Procedure 3.8 Let theory, set clauses |= , partial order
variables , B bias . compute flex(T, , , B, n), one of:
shown unsatisfiable, model P one found, unknown solution
found n steps:
1 0;
2 < n
3
(P, c) unit(T , P );
4
c = true
5
P assigns value every variable return P ;
6
v variable unvalued P ;
7
(P, c) unit(T , hP, (B(v), )i);
8
(P, c)-conflict uip B |= ;
9
(, , ) add(, , );
10
B B| ;
11
return ;
12
P backtrack(P, );
13
ii+1
14 return unknown
Proposition A.14 every iteration loop Procedure 3.8, following conditions
hold:
1. B |= C(P ).
2. 6|= C(P ).
3. |= .
4. acceptable .
Proof. see B |= C(P ), note obviously true start, C(P ) =
. three places could fail: line 7 new variable assignment
made unit propagated, line 3 P extended unit propagation, line 10,
B modified incorporate conclusion .
Line 7 consistent B construction. Line 3 change C(P ), since new
choices made. line 10, always unit backtrack line 12, adding
conclusion B conflict choice survives backtrack.
B |= throughout bit subtle; begin showing B |=
specifically. Clearly B |= , since bias modified satisfy conclusion .
see B |= , note prior adjustment line 10, B |= construction
B |= . Negating conclusion change this.
536

fiSatisfiability Systematicity

Next, must show , B |= line 10 complete.
order B stop entailing particular learned clause , conclusion must
, since modified line 10. case, resolution
performed add different returned. Thus B |= .
order B stop entailing particular antecedent , must included
antecedent. case, learned clause question removed
add procedure. Thus B |= well. concludes proof first claim
Proposition A.14.
second claim follows this; |= C(P ), B would entail C(P )
C(P ) would inconsistent result.
see |= , note first |= line 8 construction buip.
add procedure 3.6 adds either result resolving existing elements
; either way, clause added necessarily entailed . fact various
learned clauses may removed clearly affect conclusion |= .
Finally, 6|= virtue facts B |= B |= . Thus
Proposition A.10 used conclude remains acceptable .
Theorem 3.10 Suppose theory n clauses involving v variables. Then:
1. loop Procedure 3.8 executed time O(v 3 + nv 2 ),
2. || v Procedure 3.9 executed,
P
3. n ni=0 r(i) 2v , Procedure 3.9 finish completing iteration
n.
Proof. Since acceptable respect , second claim follows Proposition A.3. first claim follows Proposition 3.7. third claim follows
Proposition A.5, bounds size(, ) 0 2v , Proposition A.12,
ensures size decreases pass loop Procedure 3.8.

References
Bayardo, R. J., & Schrag, R. C. (1997). Using CSP look-back techniques solve real-world
SAT instances. Proceedings Fourteenth National Conference Artificial
Intelligence, pp. 203208.
Beame, P., Kautz, H., & Sabharwal, A. (2004). Towards understanding harnessing
potential clause learning. Journal Artificial Intelligence Research, 22, 319351.
Bebel, J., & Yuen, H. (2013). Hard SAT instances based factoring. Proceedings
SAT Competition 2013: Solver Benchmark Description, p. 102, Helsinki, Finland.
Beck, J. C. (2005). Multi-point constructive search. Proc. Eleventh Intl. Conf.
Principles Practice Constraint Programming (CP05), pp. 737741.
Ben-Sasson, E., Impagliazzo, R., & Wigderson, A. (2000). Near-optimal separation treelike general resolution. Tech. rep., Electronic Colloquium Computation Complexity.
537

fiGinsberg

Biere, A., Heule, M. J. H., van Maaren, H., & Walsh, T. (Eds.). (2009). Handbook
Satisfiability, Vol. 185 Frontiers Artificial Intelligence Applications. IOS
Press.
Bonet, M. L., & Johannsen, J. (2014). Improved separations regular resolution clause
learning proof systems. Journal Artificial Intelligence Research, 49, 669703.
Bonet, M. L., Pitassi, T., & Raz, R. (1997). Lower bounds cutting planes proofs
small coefficients. Journal Symbolic Logic, 62 (3), 708728.
Browne, C., Powley, E., Whitehouse, D., Lucas, S., Cowling, P. I., Rohlfshagen, P., Tavener,
S., Perez, D., Samothrakis, S., & Colton, S. (2012). survey Monte Carlo tree
search methods. IEEE Transactions Computational Intelligence AI Games,
4 (1), 149.
Buhler, J., Lenstra, H., & Pomerance, C. (1993). Factoring integers number field
sieve, Vol. 1554 Lecture Notes Mathematics, pp. 5094. Springer-Verlag.
Buss, S. R., Hoffmann, J., & Johannsen, J. (2008). Resolution trees lemmas: Resolution
refinements characterize DLL algorithms clause learning. Logical Methods
Computer Science, 4.
Clark, K. L. (1978). Negation failure. Gallaire, H., & Minker, J. (Eds.), Logic
Data Bases, pp. 293322. Plenum, New York.
Davis, M., & Putnam, H. (1960). computing procedure quantification theory. J.
Assoc. Comput. Mach., 7, 201215.
Davis, M., Logemann, G., & Loveland, D. (1962). machine program theorem-proving.
Communications ACM, 5 (7), 394397.
Doyle, J. (1979). truth maintenance system. Artificial Intelligence, 12, 231272.
Gaschnig, J. (1979). Performance Measurement Analysis Certain Search Algorithms.
Ph.D. thesis, Carnegie-Mellon University.
Ginsberg, M. L. (1993). Dynamic backtracking. Journal Artificial Intelligence Research,
1, 2546.
Gomes, C. P., Selman, B., & Kautz, H. (1998). Boosting combinatorial search
randomization. Proceedings Fifteenth National Conference Artificial Intelligence (AAAI98), pp. 431437, Madison, Wisconsin.
Goultiaeva, A., & Bacchus, F. (2012). trail: Re-examining CDCL algorithm.
Proceedings 15th International Conference Theory Applications
Satisfiability Testing (SAT-2012), pp. 3043.
Haken, A. (1985). intractability resolution. Theoretical Computer Science, 39, 297
308.
Haken, A. (1995). Counting bottlenecks show monotone P 6= N P . Proceedings 36th
Annual IEEE Symp. Foundations Computer Science (FOCS-95), pp. 3640,
Milwaukee, MN. IEEE.
Harvey, W. D. (1995). Nonsystematic Backtracking Search. Ph.D. thesis, Stanford University, Stanford, CA.
538

fiSatisfiability Systematicity

Hertel, P., Bacchus, F., & Pitassi, T. (2008). Clause learning effectively P-simulate general propositional resolution. Proceedings Twenty-Third National Conference
Artificial Intelligence, pp. 283290.
Huang, J. (2006). TINISAT SAT-race 2006..
Huang, J. (2007). effect restarts efficiency clause learning. Proceedings
20th International Joint Conference Artifical Intelligence, IJCAI07, pp.
23182323, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.
Kaivola, R., Ghughal, R., Narasimhan, N., Telfer, A., Whittemore, J., Pandav, S., Slobodov,
A., Taylor, C., Frolov, V., Reeber, E., & Naik, A. (2009). Replacing testing formal
verification Intelr Core i7 processor execution engine validation. Bouajjani,
A., & Maler, O. (Eds.), Computer Aided Verification, Vol. 5643 Lecture Notes
Computer Science, pp. 414429. Springer Berlin Heidelberg.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. In: ECML-06.
Number 4212 LNCS, pp. 282293. Springer.
Krajicek, J. (1997). Interpolation theorems, lower bounds proof systems, independence results bounded arithmetic. J. Symb. Logic, 62 (2), 457486.
Lecoutre, C., Sas, L., Tabary, S., & Vidal, V. (2007). Recording minimizing nogoods
restarts. J. Satisfiability, Boolean Modeling Computation (JSAT), 1,
147167.
Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup Las Vegas algorithms.
Information Processing Letters, 47, 173180.
Lynce, I., Baptista, L., & Marques-Silva, J. (2001). Stochastic systematic search algorithms
satisfiability. LICS Workshop Theory Applications Satis Testing,
pp. 17.
Marques-Silva, J. P., & Sakallah, K. A. (1999). GRASP search algorithm propositional satisfiability. Computers, 48 (5), 506521.
Marques-Silva, J., Lynce, I., & Malik, S. (2009). Conflict-Driven Clause Learning SAT
Solvers, Vol. 185 Frontiers Artificial Intelligence Applications, pp. 131153.
IOS Press.
McAllester, D. A. (1993). Partial order backtracking. Unpublished.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering
efficient SAT solver. 39th Design Automation Conference.
Moura, L., & Bjrner, N. (2010). Bugs, moles skeletons: Symbolic reasoning software
development. Giesl, J., & Hahnle, R. (Eds.), Automated Reasoning, Vol. 6173
Lecture Notes Computer Science, pp. 400411. Springer Berlin Heidelberg.
Pipatsrisawat, K., & Darwiche, A. (2007). lightweight component caching scheme
satisfiability solvers. Proceedings 10th International Conference Theory
Applications Satisfiability Testing (SAT), pp. 294299.
Pipatsrisawat, K., & Darwiche, A. (2011). power clause-learning SAT solvers
resolution engines. Artif. Intell., 175 (2), 512525.
539

fiGinsberg

Pudlak, P. (1997). Lower bounds resolution cutting planes proofs monotone
computations. J. Symbolic Logic, 62 (3), 981998.
Purdom, P., & Sabry, A. (2005). CNF generator factoring problems.. cgi.cs.indiana.
edu/~sabry/cnf.html.
Ramos, A., Tak, P., & Heule, M. (2011). restarts backjumps. Sakallah,
K., & Simon, L. (Eds.), Theory Applications Satisfiability Testing - SAT 2011,
Vol. 6695 Lecture Notes Computer Science, pp. 216229. Springer.
Reiter, R. (1978). closed world data bases. Gallaire, H., & Minker, J. (Eds.), Logic
Data Bases, pp. 119140. Plenum, New York.
Ryan, L. (2002). Efficient algorithms clause-learning SAT solvers. Masters thesis, Simon
Fraser University.
Sellmann, M., & Ansotegui, C. (2006). Disco Novo GoGo: Integrating local search
complete search restarts. Proceedings Twenty-First National Conference
Artificial Intelligence, pp. 10511056.
Selman, B., Kautz, H. A., & Cohen, B. (1993). Local search strategies satisfiability testing. Proceedings 1993 DIMACS Workshop Maximum Clique, Graph Coloring,
Satisfiability.
Sorensson, N., & Een, N. (2005). Minisat v1.13 - SAT solver conflict-clause minimization. 2005. SAT-2005 poster. Tech. rep..
Stallman, R. M., & Sussman, G. J. (1977). Forward reasoning dependency-directed
backtracking system computer-aided circuit analysis. Artificial Intelligence,
9, 135196.
Tseitin, G. (1970). complexity derivation propositional calculus. Slisenko,
A. (Ed.), Studies Constructive Mathematics Mathematical Logic, Part 2, pp.
466483. Consultants Bureau.
Zhang, L. (2003). Searching Truth: Techniques Satisfiability Boolean Formulas.
Ph.D. thesis, Princeton University, Princeton, NJ.
Zhang, L., Madigan, C. F., & Moskewicz, M. H. (2001). Efficient conflict driven learning
boolean satisfiability solver. ICCAD, pp. 279285.

540

fiJournal Artificial Intelligence Research 53 (2015) 699-720

Submitted 03/15; published 08/15

Tree-Width Computational Complexity
MAP Approximations Bayesian Networks
Johan Kwisthout

j.kwisthout@donders.ru.nl

Radboud University Nijmegen
Donders Institute Brain, Cognition Behaviour
Montessorilaan 3, 6525 HR Nijmegen, Netherlands

Abstract
problem finding probable explanation designated set variables given partial evidence (the MAP problem) notoriously intractable problem
Bayesian networks, compute exactly approximate. known,
theoretical considerations practical experience, low tree-width typically
essential prerequisite efficient exact computations Bayesian networks.
paper investigate whether holds approximating MAP. define four
notions approximating MAP (by value, structure, rank, expectation) argue
intractable general. prove efficient value-approximations,
structure-approximations, rank-approximations MAP instances high tree-width
violate Exponential Time Hypothesis. contrast, show MAP sometimes efficiently expectation-approximated, even instances high tree-width,
probable explanation high probability. introduce complexity class
FERT, analogous class FPT, capture notion fixed-parameter expectationapproximability. suggest road-map future research yields fixed-parameter
tractable results expectation-approximate MAP, even graphs high tree-width.

1. Introduction
One important computational problems Bayesian networks MAP problem, i.e., problem finding joint value assignment designated set variables
(the MAP variables) maximum posterior probability, given partial observation
remaining variables. MAP problem notably intractable; NPPP -hard,
strictly harder (given usual assumptions computational complexity theory)
PP-hard inference problem (Park & Darwiche, 2004). sense, seen combining
optimization problem inference problem, potentially contribute
problems complexity (Park & Darwiche, 2004, p. 113). Even variables
network binary network (very restricted) polytree topology, MAP
remains NP-hard (De Campos, 2011). optimization inference
part problem computed tractably (for example, tree-width
network small, cardinality variables low, probable joint value
assignment high probability) MAP computed tractably (Kwisthout, 2011).
known that, arbitrary probability distributions assumption
Exponential Time Hypothesis, low tree-width moralized graph Bayesian network
necessary condition Inference problem Bayesian networks tractable

2015 AI Access Foundation. rights reserved.

fiKwisthout

(Kwisthout, Bodlaender, & van der Gaag, 2010); result easily extended MAP,
show Section 4.
MAP also intractable approximate (Abdelbar & Hedetniemi, 1998; Kwisthout,
2011, 2013; Park & Darwiche, 2004). obviously case particular instance
MAP problem approximated efficiently computed exactly
efficiently, yet unclear whether approximate MAP computations rendered
tractable different conditions exact MAP computations. Crucial
question mean statement algorithm approximates MAP problem.
Typically, computer science, approximation algorithms guarantee output
algorithm value within bound value optimal solution.
example, canonical approximation algorithm Vertex Cover problem selects
edge random, puts endpoints vertex cover, removes nodes
instance. algorithm guaranteed get solution twice
number nodes vertex cover optimal vertex set. However, typical Bayesian
approximation algorithms guarantee; contrast, may converge
optimal value given enough time (such Metropolis-Hastings algorithm), may
find optimal solution high probability success (such repeated local search
strategies).
paper assess four different notions approximation relevant MAP
problem; particular value-approximation, structure-approximation, rank-approximation,
expectation-approximation MAP. introducing notation providing
preliminaries (Section 2), show approximations intractable
assumption P 6= NP, respectively NP 6 BPP (Section 3). Building result
Kwisthout et al. (2010) show Section 4 bounded tree-width indeed
necessary condition efficient value-approximation, structure-approximation, rankapproximation MAP. Section 5 argue need case expectationapproximation. introduce parameterized complexity classes FERT (Fixed Error
Randomized Tractable) FPERT (Fixed Parameter Error Randomized Tractable)
natural extensions class FPT. introduce MAP variant additional
constraints show Constrained-MAP intractable (PP-hard) general;
however, Constrained-MAP FERT parameterized probability
probable explanation, even tree-width high. conclude paper Section
6.

2. Preliminaries
section, introduce notational conventions provide preliminaries
Bayesian networks, graph theory, complexity theory; particular definitions
MAP problem, tree-width, parameterized complexity theory, Exponential Time
Hypothesis. thorough discussion concepts, reader referred
textbooks Darwiche (2009), Arora Barak (2009), Downey
Fellows (1999).
700

fiTree-Width MAP Approximations

2.1 Bayesian Networks
Bayesian network B = (GB , Pr) graphical structure succinctly represents joint
probability distribution set stochastic variables. B includes directed acyclic graph
GB = (V, A), V models (in one-to-one mapping) stochastic variables
models conditional (in)dependences them, set parameter probabilities
Pr form conditional probability tables (CPTs), capturing strengths
relationships
Q variables. network models joint probability distribution
Pr(V) = ni=1 Pr(Vi | (Vi )) variables; here, (Vi ) denotes parents Vi GB .
notational convention use upper case letters denote individual nodes
network, upper case bold letters denote sets nodes, lower case letters denote value
assignments nodes, lower case bold letters denote joint value assignments sets
nodes. use node variable interchangeably.
One key computational problems Bayesian networks problem find
probable explanation set observations, i.e., joint value assignment designated set variables (the explanation set) maximum posterior probability given
observed variables (the joint value assignment evidence set) network.
network bi-partitioned explanation variables evidence variables problem
known Probable Explanation (MPE). general problem,
network also includes variables neither observed explained (referred
intermediate variables) known (Partial Marginal) MAP. problem
typically defined formally follows:
MAP
Instance: Bayesian network B = (GB , Pr), V partitioned set
evidence nodes E joint value assignment e, set intermediate nodes I,
explanation set H.
Output: joint value assignment h H joint value assignments h0
H, Pr(h | e) Pr(h0 | e).
remainder, use following definitions. arbitrary MAP instance
{B, H, E, I, e}, let cansol B refer set candidate solutions {B, H, E, I, e},
optsol B cansol B denoting optimal solution (or, case draw, one optimal
solutions) MAP instance. cansol B ordered according probability
candidate solutions (breaking ties candidate solutions probability
arbitrarily), optsol 1...m
refers set first elements cansol B , viz.
B
probable solutions MAP instance. particular notion approximation,
refer (unspecified) approximate solution approxsol B cansol B .
2.2 Tree-Width
important structural property Bayesian network B tree-width,
defined minimum width tree-decomposition (or equivalently, minimal size
largest clique triangulation) moralization GM
B network. Treewidth plays important role complexity analysis Bayesian networks, many
otherwise intractable computational problems rendered tractable, provided
tree-width network small. moralization (or moralized graph) GM
B
701

fiKwisthout

undirected graph obtained GB adding arcs connect pairs
parents variable, dropping directions. triangulation GM
B

chordal graph GT embeds GB subgraph. chordal graph graph
include loops three variables without pair adjacent.
tree-decomposition (Robertson & Seymour, 1986) triangulation GT tree
TG node Xi TG bag nodes constitute clique GT ;
every i, j, k, Xj lies path Xi Xk TG , Xi Xk Xj .
context Bayesian networks, tree-decomposition often referred junction
tree clique tree B. width tree-decomposition TG graph GT defined
size largest bag TG minus 1, i.e., maxi (|Xi | 1). tree-width tw
Bayesian network B minimum width possible tree-decompositions
triangulations GM
B .
2.3 Complexity Theory
assume reader familiar basic notions complexity theory,
intractability proofs, computational complexity classes P NP, polynomialtime reductions. section shortly review additional concepts use
throughout paper, namely complexity classes PP BPP, Exponential Time
Hypothesis basic principles parameterized complexity theory.
complexity classes PP BPP defined classes decision problems
decidable probabilistic Turing machine (i.e., Turing machine makes stochastic
state transitions) polynomial time particular (two-sided) probability error.
difference two classes bound error probability. Yes-instances
problems PP accepted probability 1/2 + , may depend exponentially
input size (i.e., = 1/cn constant c > 1). Yes-instances problems BPP
accepted probability polynomially bounded away 1/2 (i.e., = 1/nc ).
PP-complete problems, problem determining whether majority truth
assignments Boolean formula satisfies , considered intractable; indeed,
shown NP PP. contrast, problems BPP considered tractable.
Informally, decision problem BPP exists efficient randomized (Monte
Carlo) algorithm decides high probability correctness. Given error
polynomially bounded away 1/2, probability answering correctly boosted
arbitrarily close 1 still requiring polynomial time. obviously
BPP PP, reverse unlikely; particular, conjectured BPP = P (Clementi,
Rolim, & Trevisan, 1998).
Exponential Time Hypothesis (ETH), introduced Impagliazzo Paturi (2001),
states exists constant c > 1 deciding 3Sat instance n
variables takes least (cn ) time. Note ETH stronger assumption
assumption P 6= NP. sub-exponential
polynomial-time algorithm

3
3Sat, algorithm running O(2 n ), would contradict ETH would
imply P = NP. assume ETH proofs show necessity low
tree-width efficient approximation MAP.
Sometimes problems intractable (i.e., NP-hard) general, become tractable
parameters problem assumed small. problem called
702

fiTree-Width MAP Approximations

fixed-parameter tractable parameter (or set {1 , . . . , } parameters)
solved time, exponential (or even worse) polynomial input size
|x|, i.e., time O(f () |x|c ) constant c > 1 arbitrary computable function
f . practice, means problem instances solved efficiently, even
problem NP-hard general, known small. contrast, problem
NP-hard even small, problem denoted para-NP-hard .
parameterized complexity class FPT consists fixed parameter tractable problems .
traditionally defined mapping problem instances natural numbers
(e.g., Flum & Grohe, 2006, p. 4), one easily enhance theory rational parameters
(Kwisthout, 2011). context paper, particular consider rational
parameters range [0, 1], liberally mix integer rational parameters.

3. Approximating MAP
widely known, practical experiences theoretical results, small
tree-width often necessary constraint render exact Bayesian inferences tractable.
However, often assumed intractable computations efficiently approximated using inexact algorithms; assumption appears warranted observation
many cases approximation algorithms seem reasonable job in, e.g., estimating posterior distributions, even networks high tree-width exact computations
infeasible (Cheng & Druzdzel, 2000; Sontag, Meltzer, Globerson, Weiss, & Jaakkola,
2008). Whether observation firm theoretical basis, i.e., whether approximation
algorithms cannot principle perform well even situations tree-width
grow large, date known.
Crucial answering question make precise efficiently approximated actually pertains to. on-line Merriam-Webster dictionary lists one entries
approximate similar exactly like (something). computer science,
similarity typically defined terms value: approximate solution value
close value optimal solution. However, notions approximation
relevant. One think approximating value optimal solution,
appearance: approximate solution A0 closely resembles optimal solution. Also, one
define approximate solution one ranks close optimal solution: approximate solution A00 ranks within top-m solutions. Note notions refer
completely different solutions. One situations second-best solution
resemble optimal solution all, whereas solutions look almost
low value compared optimal solution (Van Rooij & Wareham, 2012;
Kwisthout, 2013). Similarly, second-best solution may either value almost
good optimal solution, much worse.
many practical applications, particular Bayesian inferences, definitions
approximation (fully) capture actual notion interested in. example, trying approximate MAP explanation using sort randomized
computation, guarantee quality solution found, however, may
bound likeliness good solution. current state-of-the-art approximate
algorithms MAP (AnnealedMAP, Yuan, Lu, & Druzdzel, 2004; P-Loc, Park & Darwiche, 2001; BP-LS, Park & Darwiche, 2004) employ strategy. added notion
703

fiKwisthout

approximation here, induced use randomized computations, allowance
bounded amount error.1
remainder section elaborate notions approximation
applied MAP problem. give formal definitions approximate
problems show intractable general. MAP-approximation
value structure interpret known results literature. MAPapproximation rank give formal proof intractability; MAP-approximation
using randomized algorithms give argument complexity theory.
3.1 Value-Approximation
Value-approximating MAP problem finding explanation approxsol B cansol B
value, close value optimal solution. closeness defined
additive relative manner; additive meaning absolute difference
probability optimal approximate solution smaller value ;
relative ratio probability optimal approximate solution
smaller value . problems intractable general. Abdelbar
Hedetniemi (1998) proved NP-hardness relative value-approximation constant
1. result holds networks binary variables, three incoming
arcs per variable, evidence. addition, Kwisthout (2011) showed NP-hard
general find explanation approxsol B Pr(approxsol B , e) > constant
> 0, thus Pr(optsol B , e) Pr(approxsol B , e) > Pr(optsol B , e) .
latter result holds even networks binary variables, two incoming
arcs per variable, single evidence variable, intermediate variables (i.e.,
approximate MPE problem).
Definition 3.1 (additive value-approximation MAP) Let optsol B optimal
solution MAP problem. explanation approxsol B cansol B defined -additive
value-approximate optsol B Pr(optsol B , e) Pr(approxsol B , e) .
Result 3.2 (Kwisthout, 2011) NP-hard -additive value-approximate MAP
> Pr(optsol B , e) constant > 0.
Definition 3.3 (relative value-approximation MAP) Let optsol B optimal
solution MAP problem. explanation approxsol B cansol B defined -relative
Pr(optsol B | e)
value-approximate optsol B Pr(approxsol
| e) .
B

Result 3.4 (Abdelbar & Hedetniemi, 1998) NP-hard -relative value-approximate
Pr(optsol B | e)
MAP Pr(approxsol
| e) > 1.
B

1. Observe algorithms always converge optimal solution, may take exponential time
(e.g., MCMC-type approaches). However, turn algorithm expectationapproximation algorithm adding clock halts computations time, polynomially input
size, returning current best solution may may optimal (Gill, 1977).

704

fiTree-Width MAP Approximations

3.2 Structure-Approximation
Structure-approximating MAP problem finding explanation approxsol B
cansol B structurally resembles optimal solution. captured using solution
distance function, metric associated optimization problem relating candidate
solutions optimal solution (Hamilton, Muller, van Rooij, & Wareham, 2007).
MAP, typical structure distance function dH (approxsol B , optsol B ) Hamming distance explanation approxsol B probable explanation optsol B .
shown Kwisthout (2013) algorithm calculate value even single
variable probable explanation polynomial time, unless P = NP; is,
NP-hard find explanation dH (approxsol B , optsol B ) |optsol B | 1, even
variables network bi-partitioned explanation evidence variables,
variable three possible values.
Definition 3.5 (structure-approximation MAP) Let optsol B optimal solution MAP problem let dH Hamming distance. explanation approxsol B
cansol B defined d-structure-approximate optsol B dH (approxsol B , optsol B ) d.
Result 3.6 (Kwisthout, 2013) NP-hard d-structure-approximate MAP
|optsol B | 1.
3.3 Rank-Approximation
Apart allowing explanation resembles, probability close to,
probable explanation, also define approximate solution approxsol B explanation one best explanations, constant m, is, approxsol B
optsol 1...m
m. Note explanation may resemble probable
B
explanation needs relatively high probability, ranked within
probable explanations. denote approximation rank-approximation.
Definition 3.7 (rank-approximation MAP) Let optsol 1...m
cansol B set
B
probable solutions MAP problem let optsol B optimal solution.
explanation approxsol B cansol B defined m-rank-approximate optsol B approxsol B
optsol 1...m
.
B
prove NP-hard m-rank-approximate MAP constant m.
reduction variant LexSat, based reduction Kwisthout, Bodlaender,
van der Gaag (2011). LexSat defined follows:
LexSAT
Instance: Boolean formula n variables X1 , . . . , Xn .
Output: lexicographically largest truth assignment x X = {X1 , . . . , Xn }
satisfies ; output satisfiable.
Here, lexicographical order truth assignments maps truth assignment x = x1 , . . . , xn
string {0, 1}n , {0}n (all variables set false) lexicographically smallest,
{1}n (all variables set true) lexicographically largest truth assignment. LexSat
NP-hard; particular, LexSat proven complete class FPNP (Krentel,
705

fiKwisthout

V









X0

X1





X2

X3

X4

X
Figure 1: Example construction Bex LexSat0 instance ex
1988). proofs use following variant always returns truth assignment
(rather , case unsatisfiable):
LexSAT0
Instance: Boolean formula n variables X1 , . . . , Xn .
Output: lexicographically largest satisfying truth assignment x = (X0 )
satisfies .
Note satisfiable, X0 never set false lexicographically largest
satisfying truth assignment , yet X0 necessarily set false satisfiable;
hence, unsatisfying truth assignments always ordered satisfying truth assignments lexicographical ordering. Note LexSat trivially reduces LexSat0 using
simple transformation. claim following.
Theorem 3.8 algorithm find approximation approxsol B optsol 1...m
,
B
constant m, polynomial time, unless P = NP.
proof describe polynomial-time one-Turing reduction2 LexSat0 mrank-approximated-MAP arbitrary constant m. reduction largely follows
reduction presented Kwisthout et al. (2011) additions. take
following LexSat0 -instance running example proof: ex = X1 (X2 X3 );
correspondingly, ex = (X0 ) (X1 (X2 X3 )) example. set = 3
example construct. construct Bayesian network B follows (Figure 1).
variable Xi , introduce binary root variable Xi B possible
values true false. set prior probability distribution variables
i+1 1
Pr(Xi = true) = 1/2 22n+2
. addition, include uniformly distributed variable
Xn+1 B values x1n+1 , . . . , xm
n+1 . variables X0 , . . . , Xn together form set
X. Note prior probability joint value assignment x X higher prior
probability different joint value assignment x0 X, corresponding
2. function problem f polynomial-time one-Turing reducible function problem g exist
polynomial-time computable functions T1 T2 every x,f (x) = Tl (x, g(T2 (x))) (Toda,
1994). One-Turing reductions seen equivalent many-one reductions, applied
function problems.

706

fiTree-Width MAP Approximations

truth assignment x LexSat0 instance lexicographically larger truth assignment
x0 . running example, Pr(X0 = true) = 15/32, Pr(X1 = true) =
13/32, Pr(X2 = true) = 9/32, Pr(X3 = true) = 1/32, Pr(X4 = x1 ) = Pr(X4 =
4
x24 ) = Pr(X4 = x34 ) = 1/3. Observe Pr(X0 ) . . . Pr(Xi1 ) Pr(Xi ) >
Pr(X0 ) Pr(Xi1 ) Pr(Xi ) every i, i.e., ordering property stated
attained.
logical operator , introduce additional binary variable B
possible values true false, parents sub-formulas (or single subformula, case negation operator) bound operator. conditional
probability distribution variable matches truth table operator, i.e., Pr(T =
true | (T )) = 1 operator evaluates true particular truth
value sub-formulas bound . top-level operator denoted V . readily
seen Pr(V = true | x) = 1 truth assignment variables
matches x satisfies , Pr(V = true | x) = 0 otherwise. Observe
m-valued variable Xn+1 independent every variable B . note
network, including prior conditional probabilities, described using number
bits polynomial size . MAP instance constructed , set
V evidence set V = true observation set X {Xn+1 } explanation
set.
Proof. Let instance LexSat0 , let B network constructed
described above. joint value assignment x X Pr(X = x | V =
true) = Pr(X = x) normalization constant > 0 x corresponds satisfying
truth assignment , Pr(X = x | V = true) = 0 x corresponds non-satisfying
truth assignment . Given prior probability distribution variables X,
satisfying joint assignments x X ordered posterior probability
Pr(x | V = true) > 0, non-satisfying joint value assignments probability
Pr(x | V = true) = 0 thus ordered satisfying assignments. joint value
assignment highest posterior probability thus lexicographically largest
satisfying truth assignment .
take m-th valued variable Xn+1 account, every x,
joint value assignments X {Xn+1 } probability since Pr(x, Xn+1 | V =
true) = Pr(x | V = true) Pr(Xn+1 ). then, joint value assignments xm
X {Xn+1 } correspond lexicographically largest satisfying truth assignment x
posterior probability Pr(xm | V = true). Thus, algorithm
returns one m-th ranked joint value assignments explanation set X {Xn+1 }
evidence V = true transformed polynomial time algorithm
solves LexSat0 . conclude algorithm m-rank-approximate MAP,
constant m, polynomial time, unless P = NP.

Note that, technically speaking, result even stronger: LexSat0 FPNP complete reduction described actually one-Turing reduction LexSat0
m-rank-approximation-MAP, latter problem FPNP -hard. strengthen
result observing variables (minus V ) mimic operators deterministically depend parents thus added explanation set without
substantially changing proof above. implies m-rank-approximation-MPE
also FPNP -hard. Lastly, strengthen result replacing m-th valued variable
707

fiKwisthout

Xn+1 dlog2 unconnected binary variables Xn+1 Xn+dlog2 uniform probability. Still, algorithm returning one m-th ranked joint value assignments
X{Xn+1 , . . . , Xn+dlog2 } polynomial time effectively solve LexSat0 polynomial
time.
Result 3.9 NP-hard m-rank-approximate MAP constant m.
3.4 Expectation-Approximation
last notion MAP approximation discuss returns polynomial time
explanation approxsol B cansol B likely probable explanation,
allows small margin error; i.e., small probability answer
optimal solution, guarantees given quality solution.
approximations closely related randomized algorithms run polynomial
time whose output small probability error, viz., Monte Carlo algorithms.
notion approximationwhich refer expectation-approximation (Kwisthout &
van Rooij, 2013)is particularly relevant typical Bayesian approximation methods,
Monte Carlo sampling repeated local search algorithms.
Definition 3.10 (expectation-approximation MAP) Let optsol B optimal solution MAP problem let E expectation function (Papoulis, 1984).
explanation approxsol B cansol B defined -expectation-approximate optsol B
E(Pr(optsol B ) 6= Pr(approxsol B )) < .
order practical relevance, want error small, i.e., casted
decision problem, want probability answering correctly bounded away
1/2. case, amplify probability answering correctly arbitrarily
close 1 polynomial time, repeated evocation algorithm. Otherwise, e.g.,
error depends exponentially size input, need exponential number
repetitions achieve result. Problems enjoy polynomial-time Monte Carlo
algorithms complexity class BPP; problems may need exponential time
reduce probability error arbitrarily close 0 complexity class PP.
MAP NP-hard, efficient randomized algorithm solving MAP polynomial time
bounded probability error, would imply NP BPP. considered
highly unlikely, almost every problem enjoys efficient randomized algorithm
proven P, i.e., decidable deterministic polynomial time.3 various
grounds believed BPP = P (Clementi et al., 1998), thus efficient randomized algorithm MAP would (under assumption) establish P = NP. Therefore,
algorithm expectation-approximate MAP polynomial time bounded margin
error unless NP BPP. result holds also MPE, already NP-hard,
even binary variables in-degree 2 (Kwisthout, 2011).4
3. dramatic example problem PRIMES: given natural number, decide whether
prime. efficient randomized algorithms PRIMES around quite time
(establishing PRIMES BPP), fairly recently proven PRIMES P (Agrawal,
Kayal, & Saxena, 2004).
4. fact, holds value-approximation, structure-approximation, rank-approximation MAP
well, three problems NP-hard (see also Abdelbar & Hedetniemi, 1998, p. 35).

708

fiTree-Width MAP Approximations

Result 3.11 cannot exist randomized algorithm -expectation-approximates
MAP polynomial time < 1/2 1/nc constant c unless NP BPP.
3.5 Discussion
previous subsections showed approximation notions established
fact intractable, various assumptions. results hold MAP general,
many cases strengthened hold MPE (i.e., network two-partitioned
evidence explanation variables); either case, cardinality c in-degree
nodes (and consequently, size CPTs) bounded. results hold
empty (or singleton) evidence sets. results summarized Table 1.
Approximation
value, additive
value, ratio
structure
rank
expectation

constraints
c = 2, = 2,
|E| = 1, =
c = 2, = 3,
E=
c = 3, = 3,
I=
c = 2, = 2,
|E| = 1, =
c = 2, = 2,
|E| = 1, =

assumption
P 6= NP

reference
(Kwisthout, 2011, p. 1462)

P 6= NP

(Abdelbar & Hedetniemi, 1998, p. 24)

P 6= NP

(Kwisthout, 2013, p. 345)

P 6= NP

Section 3.3

NP 6 BPP

Section 3.4

Table 1: Summary intractability results MAP approximations

4. Necessity Low Tree-Width Efficient Approximation MAP
previous section shown four notions approximating MAP,
efficient general approximation algorithm constructed unless either P = NP NP
BPP. However, MAP fixed-parameter tractable number problem parameters;
example, {tw, c, q}MAP FPT parameters tree-width (tw), cardinality
variables (c = maxi |(Vi V)|), probability probable solution (q =
Pr(optsol B , e)). Surely, compute {1 , . . . , }MAP exactly FPT time,
also approximate {1 , . . . , }MAP FPT time. question remains, however, whether
approximate MAP fixed-parameter tractable different set parameters
exact MAP.
Tree-width shown necessary parameter efficient exact computation Inference problem (and, trivial adjustment illustrated Section 4.3,
also MAP), assumption ETH holds (Kwisthout et al., 2010).
section, show low tree-width also necessary parameter efficient
approximate computation value-approximations, structure-approximations, rankapproximations. also argue (in Section 5) necessary parameter
efficient expectation-approximation. next sub-section review so-called treewidth-preserving reductions (tw-reductions), special kind polynomial many-one reductions preserve tree-width instances (Kwisthout et al., 2010). Sub-section
709

fiKwisthout

4.2 sketch notion used tw-reduce Constraint Satisfaction
Inference. Together known result Constraint Satisfaction instances
high tree-width cannot sub-exponential algorithms, unless ETH fails (Marx,
2007), established Kwisthout et al. cannot (general-purpose) algorithm decides Inference instances high tree-width sub-exponential time,
unless ETH fails. Here, Inference problem problem deciding whether
Bayesian network B designated sets H E rational number q, case
Pr(H = h | E = e) > q. precisely, following theorem proved:
Theorem 4.1 exists computable function f Inference decided
algorithm running time
f (GM
B )

o(

kBk

tw(GM
B ) )
log tw(GM )
B

arbitrary Inference instances (B, H, h, E, e, q) moralized graph GM
B treeM
width tw(GB ), ETH fails.
reader referred Kwisthout et al. (2010) full proof.5 remainder
section, show proof augmented establish similar results
MAP, value-approximate MAP, structure-approximate MAP, rank-approximate MAP
(Sub-sections 4.3 4.4).
4.1 Tree-Width-Preserving Reductions
Tree-width-preserving reductions defined Kwisthout et al. (2010) means reduce
Constraint Satisfaction Inference ensuring tree-width preserved
instances reduction, modulo linear factor.
Definition 4.2 (Kwisthout et al., 2010) Let B computational problems
tree-width defined instances B. say polynomialtime tree-width-preserving reducible, tw-reducible, B exists polynomial-time
computable function g linear function l x g(x) B
tw(g(x)) = l(tw(x)). pair (g, l) called tw-reduction.
use notion show Constraint Satisfaction also tw-reduces MAP,
value-approximate MAP, structure-approximate MAP, rank-approximate MAP.
4.2 Proof Sketch
tw-reduction (binary) Constraint Satisfaction Inference, presented
Kwisthout et al. (2010), constructs Bayesian network BI instance = (V, D, C)
Constraint Satisfaction, V denotes set variables I, denotes set
values variables, C denotes set binary constraints defined V V.
5. results Kwisthout et al. (2010) rule existence special-case algorithms,
assume (and utilize) particular property instance, particular orientation arcs
particular planarity properties graph structure, failing assumption violated.
results current paper, built result, inherit constraint.

710

fiTree-Width MAP Approximations

R1

R4
X1

X2

X4
X3
R2

R3

Figure 2: Example construction BI example CSP instance
constructed network BI includes uniformly distributed variables Xi , corresponding
variables V, binary variables Rj , corresponding constraints C.
parents variables Rj variables Xi bound constraints;
conditional probability distributions match imposed constraints variables
(i.e., Pr(Rj = true | x ((Rj ))) = 1 joint value assignment x
variables bound Rj matches constraints imposed Rj . Figure 2,
taken Kwisthout et al., shows result construction far example
Constraint Satisfaction instance four variables X1 X4 , C contains four
constraints bind respectively (X1 , X2 ), (X1 , X4 ), (X2 , X3 ), (X3 , X4 ).
tree-width thus obtained network equals max(2, tw(GI )), GI
primal graph I; note tree-width BI increases tree-width GI
1. order enforce constraints simultaneously enforced, constraint nodes
Rj need connected extra nodes mimicking operators. crucial aspect
tw-reduction topography connection nodes Rj : care must taken
blow tree-width arbitrarily connecting nodes, e.g., log-deep binary
tree. original proof uses minimal tree-decomposition moralization BI
describes procedure select nodes need connected tree-width
resulting graph tree-width GI plus 3. conditional probability
distribution nodes Ak defined follows.
V

1 x = V (Ak ) (V = true)
Pr(Ak = true | x) =
0 otherwise
node Ak without parents, Pr(Ak = true) = 1. graph results
applying procedure example given Figure 3 (also taken Kwisthout
et al., 2010). Now, Pr(A1 = true | x) = 1 x corresponds satisfying value assignment
V 0 otherwise; correspondingly, Pr(A1 = true) > 0 Constraint
Satisfaction instance satisfiable.
4.3 MAP Result
tw-reduction described previous sub-section easily modified twreduction Constraint Satisfaction MAP. adding binary node
711

fiKwisthout

R1

R4
X1

X2

X4
X3

A1

R2

R3

A2

A3

A4

A5

A6

Figure 3: Resulting graph BI adding nodes Ak appropriate arcs
VI thus obtained graph, A1 parent conditional probability
Pr(VI = true | A1 = true) = 1 Pr(VI = true | A1 = false) = 1/2 ,
number, smaller 1/|D||V| . Consequently, Pr(VI = true) > 1/2
satisfiable, Pr(VI = true) < 1/2 satisfiable; hence, MAP query
explanation set H = {VI } return VI = true satisfiable. added
single node BI , A1 parent, thus increasing tree-width BI
1. Hence, Constraint Satisfaction tw-reduces MAP.
4.4 Approximation Intractability Results
similar way modify reduction Sub-section 4.2 show valueapproximations, structure-approximations, rank-approximations tw-reduced
Constraint Satisfaction, sketched below.
4.4.1 Value-Approximation
add binary node VI , A1 parent, conditional probability
Pr(VI = true | A1 = true) = 1 Pr(VI = true | A1 = false) = 0. observe
variable set true. enforces Pr(A1 = true | VI = true)
non-zero probability (i.e., solvable) since otherwise conflicting evidence
thus constructed network. Thus, value-approximation algorithm explanation
set H = {A1 } evidence e = {VI = true} return solution approxsol B
cansol B Pr(approxsol B , e) > constant > 0, (that is, approximates additively
B)
) effectively solves Constraint
> Pr(optsol B ) relatively > Pr(optsol

Satisfaction: exists solution non-zero probability, construction dictates
must solvable. Given added single node BI , A1 parent,
increases tree-width BI 1. Hence, Constraint Satisfaction twreduces value-approximate MAP.
712

fiTree-Width MAP Approximations

4.4.2 Structure-Approximation
Observe tw-reduction MAP Sub-section 4.3 that, since H consists
singleton binary variable, trivially algorithm find explanation
approxsol B cansol B dH (approxsol B , optsol B ) |optsol B | 1 = 0 since would
solve MAP query. extend result hold explanation sets size
k constant k, i.e., structure-approximation algorithm guarantee return
correct value one k variables H polynomial time instances high
tree-width, unless ETH fails.
Instead adding single binary node VI tw-reduction MAP, add k
binary nodes VI1 . . . VIk , A1 parent Pr(VIj = true | A1 =
true) = 1 Pr(VIj = true | A1 = false) = 1/2 1 j k

described Sub-section 4.3. MAP query explanation set H = 1jk VIj
return 1jk VIk = true satisfiable; satisfiable, MAP
query return 1jk VIk = false probable explanation. Hence, structureapproximation algorithm correctly return value one variables H,
effectively solves Constraint Satisfaction. added k nodes BI , A1
parent outgoing arcs, tree-width BI increases 1. Hence,
Constraint Satisfaction tw-reduces structure-approximate MAP.
4.4.3 Rank-Approximation
modify proof Sub-section 4.3 follows. addition adding binary node
VI specified section, also add dlog2 unconnected binary variables MI =
dlog
{MI1 . . . MI 2 } uniform probability H; m-rank-approximate MAP query
explanation set H = {VI } MI return VI = true (and MI set arbitrary value)
satisfiable. addition MI increase tree-width, hence,
Constraint Satisfaction tw-reduces m-rank-approximate MAP.
4.5 Discussion
efficient exact computation, value-approximation, structure-approximation, rankapproximation MAP showed bounded tree-width necessary condition, assumption ETH, general-purpose algorithm accepts arbitrary
instances. rule possibility may exist special-purpose algorithms compute approximate MAP explanations specific networks
special structure distribution (as already concluded Kwisthout et al. (2010)
Inference problem Bayesian networks). However, previous sub-section
shows, approximation problems intractable even extreme lower bounds
approximation quality, nature reductions follows
effectively approximate MAP explanations value, structure, rank, decide
problem exactly well. leaves little room efficient approximation algorithms
MAP instances high tree-width approximate value, structure, rank.
713

fiKwisthout

5. Expectation-Approximation Classes FERT FPERT
previous section showed cannot value-approximate, structure-approximate,
rank-approximate MAP instances high tree-width, unless ETH fails.
expectation-approximation? appears strategy employed
previous subsection cannot used show similar result expectation-approximation. fact, reasons believe efficient expectation-approximation MAP
indeed depends different set parameters notions approximation
discussed above, bounded tree-width necessary particular notion
approximation. notion parameterized approximability well captured
traditional fixed parameter tractable class FPT; therefore, introduce parameterized complexity classes FERT (Fixed Error Randomized Tractable) FPERT
(Fixed Parameter Error Randomized Tractable) characterize notion efficient parameterized expectation-approximation. Intuitively, contrast class FPT,
parameterizes running time, classes parameterize error probability (FERT),
respectively running time error probability (FPERT).
best knowledge, previous work proposes parameterize probability acceptance probabilistic Turing machine. Montoya Muller
(2013) define class BPFPT assumes bounded error independent
parameterization , amount randomness (operationalized number
coins used) bounded. Arvind Raman (2002) propose randomized approximation
algorithms counting problems, running time approximation ratio
parameterized, error probability constant. authors, however, assume
bounded (rather parameterized) error.
next section set formal machinery results. introduce natural parameterizations MajSAT, respectively E-MajSAT, FERT,
respectively FPERT. show restricted variant MAP indeed FERT, parameterized probability probable explanation, Frugal
Explanations problem (Kwisthout, 2015) FPERT number parameterizations.
elaborate relation classes classes BPP, PP, FPT,
finally, propose road map future research.
5.1 Parameterizing Error Bound Randomized Algorithms
formally define complexity class FERT follows:
Definition 5.1 Let decision problem let parameterization .
FERT exists probabilistic Turing machine
halts time, polynomial size input x, following acceptance criteria.
accepts Yes-instances probability 1/2 + min(f (), 1/|x|c ) constant c
arbitrary function f : R h0, 1/2]; No-instances accepted probability 1/2.
Observe definition demand halts time, polynomial input
size (and independent parameterization ), yet probability acceptance
Yes-instances may depend function . Intuitively, class FERT characterizes
problems efficiently computed randomized algorithm (i.e., polynomial
time, error arbitrarily close 0) bounded. canonical parameterized problem
714

fiTree-Width MAP Approximations

FERT {r}MajSAT, r denotes fraction satisfying truth assignments (or, equivalently, probability random truth assignment accepts).
follows corollary following result Littman, Majercik, Pitassi (2001):
Lemma 5.2 (adapted Littman et al., 2001) Let v number accepting
truth assignments Boolean formula , let v estimate v found via random
sampling using w samples variables . Let > 0 target approximation
2
error. probability |v v| > less 2e2 w .
Note solving MajSAT-instance, target approximation error directly
depends probability r random truth assignment accepts, acceptable error
(i.e., error still gives correct answer MajSAT instance) random
sampling algorithm = |r 1/2|. So, probability acceptance random truth
assignment polynomially bounded away 1/2, guarantee arbitrarily small
error using polynomially many samples using straightforward randomized algorithm.
Corollary 5.3 {r}MajSAT FERT.
allow parameterization running time probability acceptance, get complexity class FPERT defined follows:
Definition 5.4 Let decision problem let {1 , 2 } parameterization
. {1 , 2 } FPERT exists probabilistic Turing
machine halts time O(f1 (1 ) |x|c1 ), accepts Yes-instances
probability 1/2 + min(f2 (2 ), 1/|x|c2 ), accepts No-instances probability 1/2.
Here, f1 : R R f2 : R h0, 1/2] arbitrary computable functions c1 c2
constants.
also define canonical problem FPERT, based observation {p}-SAT
FPT (Flum & Grohe, 2006, parameter p denotes number variables
formula) Corollary 5.3:
E-MajSAT
Instance: Let Boolean formula n variables xi , = 1, . . . , n, n 1,
furthermore partition variables sets XE XM .
Question: truth assignment XE majority truth
assignments XM satisfy ?
Parameter: 1 = p; 2 = r; p number variables set XE ; define r
follows. Let rxE denote ratio accepting truth assignments XM given
particular truth assignment xE XE . define r = minxE (|1/2 rxE |).
Informally, r describes minimum absolute distance 1/2 fraction accepting
truth assignments truth assignment xE XE . Observe try (bruteforce) truth assignments XE and, truth assignment, expectation-approximate
whether truth assignment majority truth assignments XM satisfy
. algorithm runs time O(2p nc ) constant c, probability least
1/2 + f (r) answering correctly (using polynomial number samples).
Corollary 5.5 {p, r}E-MajSAT FPERT.
715

fiKwisthout

5.2 Parameterized Expectation-Approximation MAP
Proving problem FPT normally done constructively, i.e., giving
deterministic algorithm decides time O(f () |x|c ) constant c > 1. Similarly,
proving FERT done giving randomized algorithm6 decides
polynomial time error 1/2 min(f (), 1/|x|c ). succeed giving
algorithm MAP general, however, prove restricted variant MAP
FERT parameterized probability probable explanation,
despite restricted variant remains PP-complete general bounded treewidth necessary parameter approximate problem value, structure, rank:
ConstrainedMAP
Instance: MAP. addition, demand E = , H consists singleton
node H outgoing edges, (H) = {true, false}.
Question: Pr(H = true) > 1/2?
Parameter: q = Pr(H = true).
PP-completeness Constrained-MAP follows trivial modification PPcompleteness proof Inference described Kwisthout (2009, Lemma 2.7 Lemma
2.9). Furthermore, given reductions Constraint Satisfaction MAP,
value-approximate MAP, structure-approximate MAP, rank-approximate MAP respect
restrictions imposed Constrained-MAP, necessity bounded treewidth follows.
show {q}Constrained-MAP FERT, parameter q = Pr(H =
true), give following approximation algorithm. Observe H binary sink
node (i.e., outgoing edges) B evidence. simple forward sampling
strategy (Henrion, 1986) approximate distribution H sampling values
variables network according probability distribution CPTs.
thus estimate Pr(H) taking samples; decide upon approxsol B using estimation.
Note degree error given particular number samples depends directly
probability q. precise, using Chernoff bound compute number

samples N needed degree error lower 1/(q 1/2)2 ln 1/ . gives
us fixed-parameter randomized tractable algorithm parameter {q}.
Corollary 5.6 {q}Constrained-MAP FERT.
Another parameterized problem shown fixed-error, fixed parameter
randomized tractable Frugal Explanations heuristic approach MAP, introduced Kwisthout (2015). heuristic (that either marginalizes samples intermediate variables, based subjective partition intermediate variables (into
set I+ set ) according expected contribution deciding upon MAP
explanation) expectation-approximated tractably tree-width network low, cardinality variables small, set I+ small, probability
distribution samples suffice decide upon MFE explanation
high probability. first three parameters ensure bounded running time, whereas
6. refer algorithm fixed-error randomized tractable algorithm.

716

fiTree-Width MAP Approximations

para-NPPP
FPERT

para-PP

FERT

para-NP

BPP

FPT
P

Figure 4: Inclusion properties complexity classes P, BPP, FERT, FPERT, FPT,
para-NP, para-PP, para-NPPP

final parameter ensures bounded probability error. Hence, {tw, c, |I+ |} {b}MFE
FPERT, tw denotes tree-width network, c denotes cardinality
variables, |I+ | denotes number variables marginalize (not sample) over, b
denotes parameter describing bias towards particular explanation. addition
shown {|H|, c, |I+ |} {b}MFE FPERT, |H| denotes size
explanation set.
Corollary 5.7 {tw, c, |I+ |} {b}MFE FPERT {|H|, c, |I+ |} {b}MFE FPERT.
5.3 Relation FERT, FPERT, Complexity Classes
complexity class FERT introduced randomized analog FPT. Rather
parameterizing running time (as arbitrary function polynomially
input size), parameterize probability acceptance Yes-instances. BPP, FERT,
para-PP form natural analogs P, FPT, para-NP, respectively. class FPERT
parameterizes running time probability acceptance, using two parameter
sets 1 2 . thus BPP FERT PP, FERT FPERT,
FPT FPERT. Obviously, FPERT para-NPPP , every slice {1 , 2 }1 NPPP (see
Flum & Grohe, 2006, discussion slices parameterized problems). inclusion
relations depicted Figure 4.
conjectured BPP = P (Clementi et al., 1998); however, clear whether
conjecture transposed parameterized world; is, whether
conjectured FERT = FPT. known {q, |I|}MAP {q, tw}MAP fixed
parameter tractable (Kwisthout, 2011); Constrained-MAP special case MAP,
results also hold Constrained-MAP. However, intractability proof
neither |I| tw bounded. best knowledge parameterized
complexity result known (in either direction) {q}Constrained-MAP.
717

fiKwisthout

5.4 Efficient MAP Approximation: Road-map Future Research
established particular, constrained version MAP efficiently approximated expectation-approximations probability MAP explanation
high (where tree-width instance may unbounded). next step would
investigate parameterized approximability current state-of-the-art approximation
algorithms MAP show parameterization regimes algorithms
shown FERT FPERT.
different perspective, interesting explore parameterization
error randomized algorithms (for example) establish analog Whierarchy parameterizations. allows us derive fine-grained negative
parameterization results, similar way proving W[1]-hardness leads finegrained negative results proving para-NP-hardness.

6. Conclusion
paper analyzed whether low tree-width prerequisite approximating MAP
Bayesian networks. formalized four distinct notions approximating MAP (by value,
structure, rank, expectation) argued approximate MAP intractable general
using either notions. case value-approximation, structure-approximation,
rank-approximation showed MAP cannot approximated using notions
(non-trivial) instances high tree-width, ETH holds. However, showed
constrained version MAP, despite PP-hard general, tractably
expectation-approximated probable explanation high probability.
proposed complexity classes FERT FPERT capture parameterization
error (respectively error running time), rather running time. results
contributed fuller understanding make state-of-the-art
approximation algorithms MAP feasible practice.

7. Acknowledgements
previous version paper (Kwisthout, 2014) published Proceedings
Seventh European Workshop Probabilistic Graphical Models (PGM 2014). author
wishes thank workshop participants (both sets of) anonymous reviewers stimulating discussion worthwhile suggestions. thanks particular Hans Bodlaender
Todd Wareham valuable comments earlier version manuscript.

References
Abdelbar, A. M., & Hedetniemi, S. M. (1998). Approximating MAPs belief networks
NP-hard theorems. Artificial Intelligence, 102, 2138.
Agrawal, M., Kayal, N., & Saxena, N. (2004). PRIMES P. Annals Mathematics,
160 (2), 781793.
Arora, S., & Barak, B. (2009). Computational Complexity: Modern Approach. Cambridge
University Press.
718

fiTree-Width MAP Approximations

Arvind, V., & Raman, V. (2002). Approximation algorithms parameterized counting problems. Bose, P., & Morin, P. (Eds.), Algorithms Computation, Vol. 2518
Lecture Notes Computer Science, pp. 453464. Springer Berlin Heidelberg.
Cheng, J., & Druzdzel, M. (2000). AIS-BN: adaptive importance sampling algorithm
evidential reasoning large Bayesian networks. Journal Artificial Intelligence
Research, 13 (1), 155188.
Clementi, A., Rolim, J., & Trevisan, L. (1998). Recent advances towards proving P=BPP.
Allender, E. (Ed.), Bulletin EATCS, Vol. 64. EATCS.
Darwiche, A. (2009). Modeling Reasoning Bayesian Networks. Cambridge University Press.
De Campos, C. P. (2011). New complexity results MAP Bayesian networks.
Walsh, T. (Ed.), Proceedings Twenty-Second International Joint Conference
Artificial Intelligence, pp. 21002106.
Downey, R. G., & Fellows, M. R. (1999). Parameterized Complexity. Springer Verlag, Berlin.
Flum, G., & Grohe, M. (2006). Parameterized Complexity Theory. Springer, Berlin.
Gill, J. T. (1977). Computational complexity Probabilistic Turing Machines. SIAM
Journal Computing, 6 (4), 675695.
Hamilton, M., Muller, M., van Rooij, I., & Wareham, H. (2007). Approximating solution
structure. Demaine, E., Gutin, G., Marx, D., & Stege, U. (Eds.), Structure Theory
FPT Algorithmics Graphs, Digraphs Hypergraphs, No. 07281 Dagstuhl
Seminar Proceedings.
Henrion, M. (1986). Propagating uncertainty Bayesian networks probabilistic logic
sampling. Kanal, L., & Lemmer, J. (Eds.), Proceedings Second Annual
Conference Uncertainty Artificial Intelligence, pp. 149164. New York: Elsevier
Science.
Impagliazzo, R., & Paturi, R. (2001). complexity k-SAT. Journal Computer
System Sciences, 62 (2), 367 375.
Krentel, M. W. (1988). complexity optimization problems. Journal Computer
System Sciences, 36, 490509.
Kwisthout, J. (2009). Computational Complexity Probabilistic Networks. Ph.D.
thesis, Faculty Science, Utrecht University, Netherlands.
Kwisthout, J. (2011). probable explanations Bayesian networks: Complexity
tractability. International Journal Approximate Reasoning, 52 (9), 1452 1469.
Kwisthout, J. (2013). Structure approximation probable explanations Bayesian
networks. van der Gaag, L. (Ed.), Proceedings Twelfth European Conference
Symbolic Quantitative Approaches Reasoning Uncertainty, Vol. 7958
LNAI, pp. 340351. Springer-Verlag.
Kwisthout, J. (2014). Treewidth computational complexity MAP approximations.
van der Gaag, L., & Feelders, A. (Eds.), Proceedings Seventh European
Workshop Probabilistic Graphical Models, Vol. 8754 Lecture Notes Computer
Science, pp. 271285. Springer International Publishing.
719

fiKwisthout

Kwisthout, J. (2015). frugal explanations Bayesian networks. Artificial Intelligence,
218, 56 73.
Kwisthout, J., Bodlaender, H. L., & van der Gaag, L. C. (2010). necessity bounded
treewidth efficient inference Bayesian networks. Coelho, H., Studer, R.,
& Wooldridge, M. (Eds.), Proceedings 19th European Conference Artificial
Intelligence, pp. 237242. IOS Press.
Kwisthout, J., Bodlaender, H. L., & van der Gaag, L. C. (2011). complexity finding
kth probable explanations probabilistic networks. Cerna, I., Gyimothy, T.,
Hromkovic, J., Jefferey, K., Kralovic, R., Vukolic, M., & Wolf, S. (Eds.), Proceedings
37th International Conference Current Trends Theory Practice
Computer Science, Vol. LNCS 6543, pp. 356367. Springer.
Kwisthout, J., & van Rooij, I. (2013). Bridging gap theory practice
approximate Bayesian inference. Cognitive Systems Research, 24, 28.
Littman, M. L., Majercik, S. M., & Pitassi, T. (2001). Stochastic boolean satisfiability.
Journal Automated Reasoning, 27 (3), 251296.
Marx, D. (2007). beat treewidth?. Proceedings 48th Annual IEEE
Symposium Foundations Computer Science, pp. 169179.
Montoya, J.-A., & Muller, M. (2013). Parameterized random complexity.. Theory Computing Systems, 52 (2), 221270.
Papoulis, A. (1984). Probability, Random Variables, Stochastic Processes (2nd edition).
New York: McGraw-Hill.
Park, J. D., & Darwiche, A. (2001). Approximating MAP using local search. Proceedings
17th Conference Uncertainty Artificial Intelligence, pp. 403410. Morgan
Kaufmann Publishers, San Francisco, California, 2001.
Park, J. D., & Darwiche, A. (2004). Complexity results approximation settings
MAP explanations. Journal Artificial Intelligence Research, 21, 101133.
Robertson, N., & Seymour, P. (1986). Graph minors II: Algorithmic aspects tree-width.
Journal Algorithms, 7, 309322.
Sontag, D., Meltzer, T., Globerson, A., Weiss, Y., & Jaakkola, T. (2008). Tightening LP
relaxations MAP using message-passing. Proceedings 24th Conference
Uncertainty Artificial Intelligence, pp. 503510. AUAI Press.
Toda, S. (1994). Simple characterizations P(#P) complete problems. Journal
Computer System Sciences, 49, 117.
Van Rooij, I., & Wareham, H. (2012). Intractability approximation optimization
theories cognition. Journal Mathematical Psychology, 56 (4), 232 247.
Yuan, C., Lu, T., & Druzdzel, M. J. (2004). Annealed MAP. Chickering, D., & Halpern,
J. (Eds.), Proceedings Twentieth Conference Uncertainty Artificial Intelligence, pp. 628635. AUA.

720

fiJournal Artificial Intelligence Research 53 (2015) 439-496

Submitted 12/14; published 07/15

Bypassing Combinatorial Protections: Polynomial-Time
Algorithms Single-Peaked Electorates
Felix Brandt

brandtf@in.tum.de

Institut fur Informatik
TU Munchen
85748 Garching, Germany

Markus Brill

brill@cs.duke.edu

Department Computer Science
Duke University
Durham, NC 27708, USA

Edith Hemaspaandra

eh@cs.rit.edu

Department Computer Science
Rochester Institute Technology
Rochester, NY 14623, USA

Lane A. Hemaspaandra

lane@cs.rochester.edu

Department Computer Science
University Rochester
Rochester, NY 14627, USA

Abstract
many election systems, bribery (and related) attacks shown NP-hard using constructions combinatorially rich structures partitions covers. paper shows voters follow central political-science model electorates
single-peaked preferencesthose hardness protections vanish. using single-peaked preferences simplify combinatorial covering challenges, first time show NPhard bribery problemsincluding Kemeny Llull electionsfall polynomial
time single-peaked electorates. using single-peaked preferences simplify combinatorial partition challenges, first time show NP-hard partition-of-voters problems fall polynomial time single-peaked electorates. show single-peaked
electorates, winner problems Dodgson Kemeny elections, though p2 -complete
general case, fall polynomial time. completely classify complexity
weighted coalition manipulation scoring protocols single-peaked electorates.

1. Introduction
Elections perhaps important framework preference aggregation. election
system (or election rule) mapping takes input preferences voters
respect set candidates (alternatives) returns set winners,
subset candidate set. Elections central preference aggregation among humans
everything political elections selecting good singers popular television shows.
Elections rapidly increasing importance electronic settings multiagent
systems, used proposed varied tasks recommender systems
collaborative filtering (Ghosh, Mundhe, Hernandez, & Sen, 1999; Pennock, Horvitz, &
c
2015
AI Access Foundation. rights reserved.

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Giles, 2000), web spam reduction improved web-search engines (Dwork, Kumar, Naor,
& Sivakumar, 2001), planning (Ephrati & Rosenschein, 1997). electronic settings,
elections may huge numbers voters alternatives.
One natural worry elections agents may try slant outcome, example, bribing voters. Motivated work economics political science showing
reasonable election systems always allow manipulation cases (Gibbard, 1973;
Satterthwaite, 1975; Duggan & Schwartz, 2000), starting 1989, Bartholdi, Orlin, Tovey,
Trick (Bartholdi, Tovey, & Trick, 1989; Bartholdi & Orlin, 1991; Bartholdi, Tovey,
& Trick, 1992) made thrilling suggestion elections protected via complexity
theorynamely, making attackers task NP-hard. line active ever
since. resulted NP-hardness protections proven many election systems,
attacks bribery (the attacker budget buy alter
voters votes, Faliszewski, Hemaspaandra, & Hemaspaandra, 2009), manipulation (a coalition voters wishes set votes make given candidate win, Bartholdi et al.,
1989; Bartholdi & Orlin, 1991), control (an agent seeks make given candidate win
adding/deleting/partitioning voters candidates, Bartholdi et al., 1992). book
chapter Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2009b) surveys
NP-hardness results, apply many important election systems plurality,
single transferable voting, approval voting.
past years, flurry papers come asking whether NP-hardness
protections satisfying. particular, papers explore possibility heuristic
algorithms may well frequently approximation algorithms may exist.
papers questioned. example, influential frequency paper (Friedgut, Kalai, & Nisan, 2008, see also journal version, Friedgut, Kalai, Keller,
& Nisan, 2011) assumes voter random independent candidate preference
ordering, model seem reflect typical voter behavior. approximations, work showing certain voter-control settings (different
studied paper) polynomial-time algorithms use, example,
log number candidates times many added voters optimal approach
would need (Faliszewski, Hemaspaandra, & Hemaspaandra, 2013). However, campaign
manager might well financial resources motivate many extra people
come vote, rather would want know smallest possible number votes
add reach victory.
present paper questions NP-hardness results completely different direction. political science, perhaps canonical model electorates unidimensional single-peaked model. model, electorate preferences
one-dimensional spectrum (e.g., liberal conservative) along
candidates also located, voters preferences (loosely put)
peak, affinity declining one moves away peak. brilliant paper Walsh
(2007) recently asked whether NP-hardness protections manipulation fall apart
electorates single-peaked. case Walsh looked at, answer proved no;
looked particular NP-hardness manipulation protection proved holds even
single-peaked societies. Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2011),
inspired Walshs work, looked range election systems came sharply dif440

fiBypassing Combinatorial Protections

Problem

General cases complexity

Single-peaked cases
complexity

approval:
bribery
negative-bribery
strongnegative-bribery

NP-comp. (Faliszewski et al., 2009)
NP-comp. (Thm. 4.3, part 1)
NP-comp. (Thm. 4.3, part 1)

P (Thm. 4.2)
P (Thm. 4.3, part 2)
P (Thm. 4.3, part 2)

NP-comp.
NP-comp.
NP-comp.
NP-comp.
NP-comp.

P (Thm. 4.7)
P (Thm. 4.7)
P (Thm. 4.7)
NP-comp. (Thm. 4.7)
P (Thm. 5.3)

Llull:
bribery
$bribery
weighted-bribery
weighted-$bribery
control
voter partition
Kemeny:
winner
bribery
$bribery
weighted-bribery
weighted-$bribery

(Faliszewski
(Faliszewski
(Faliszewski
(Faliszewski
(Faliszewski

et
et
et
et
et

al.,
al.,
al.,
al.,
al.,

2009)
2009)
2009)
2009)
2009a)

p2 -comp. (Hemaspaandra et al., 2005)
p2 -hard (Thm. 4.8)
p2 -hard (Thm. 4.8)
p2 -hard (Thm. 4.8)
p2 -hard (Thm. 4.8)

P (Thm. 3.3)
P (Thm. 4.9)
P (Thm. 4.9)
P (Thm. 4.9)
NP-comp. (Thm. 4.9)

Table 1: single-peakedness (often) lowers complexity key election problems.

fering conclusion many crucial cases, NP-hardness protections manipulation
control vanish single-peaked electorates.
present paper young line research complexity manipulative actions
context single-peaked electorates. work seeks take line research
new directions, improve one existing direction, following contributions:
1. (Section 3) show checking winner Dodgson, Young, Kemeny elections, known p2 -complete general case (respectively due
Hemaspaandra, Hemaspaandra, & Rothe, 1997, due papers Theorem A.2
based adapting proof Rothe, Spakowski, & Vogel, 2003, due Hemaspaandra, Spakowski, & Vogel, 2005), polynomial time single-peaked electorates
(Corollary 3.3 Theorem 3.4).
algorithm shows Dodgson elections good example general
technical theme paper: single-peakedness often precludes combinatorial explosion. particular case, single-peakedness simplify seemingly
exponential-sized search space series exchanges provide upper bounds
Dodgson scores, allow us instead search polynomial-sized possibility space related particular, simple set exchanges happening limited
two voters.
2. (Section 4) first time study effect single-peaked electorates
complexity bribery. show many NP-hardness protections bribery
441

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

general case vanish single-peaked electorates. (Table 1 provides key
examples examples lowering complexity.) show this,
give polynomial-time bribery algorithms single-peaked electorates many settings. polynomial-time algorithms apply approval voting (Theorem 4.2
Theorem 4.3) rich range weak-Condorcet consistent election systems
even systems merely known weak-Condorcet consistent
electorate single-peaked (Corollary 4.5), including weakBlack, weakDodgson,
Fishburn, Kemeny, Llull, Maximin, Schwartz, Young, two variants Nanson
due Fishburn Schwartz.
right general interpretation underlies NP-hardness results
use (in outputs reductions establishing NP-hardness) sets voter preferences
intricate simply cannot realized single-peaked societies.
practical lesson skeptical NP-completeness results
electorate may limitations (such single-peakedness) ensembles
votes produces. specific technical reason obtain polynomial-time
bribery algorithms NP-hardness proofs based combinatorially
rich structure covering problems (whose core challenge incomparability
voters), (see proof Theorem 4.2) use single-peakedness create
directional attack covering problems effect locally removing
incomparability.
3. (Section 5) first time study effect single-peaked electorates
complexity control partition voters, voters partitioned
two groups vote candidates primary elections, winners
primaries compete final election. one seven types control
introduced seminal control paper Bartholdi et al. (1992), control
partition voters previously addressed single-peaked case.
show known NP-hardness protections control-by-partition vanish
single-peaked electorates, giving polynomial-time algorithms
single-peaked control partition (Theorems 5.2 5.6, Corollary 5.3).
general interpretation practical lesson
mentioned bribery case. However, technical way obtain control-bypartition result differs here. technical challenge exponential number
partitions, algorithms circumvent using single-peakedness allow
us effect structure huge number partitions polynomial number
classes partitions class look class rather
explore member partitions.
shared technical theme bribery case single-peakedness
used tame combinatorial explosion (of partitions covers)
general case protected elections attack, particular single-peakedness yields
polynomial-time attack algorithms.
4. final contribution (Section 6) strong extension important result
Faliszewski et al. (2011). broad class election systems known scoring
protocols, Faliszewski et al. gave complete characterization computational
442

fiBypassing Combinatorial Protections

complexity (weighted, coalition) manipulation problem case singlepeaked elections three candidates. characterizations important
tell systems easily manipulable systems
makes easily manipulable. extend providing, single-peaked
electorates, complete characterization easy manipulability scoring protocols
(Theorem 6.2). is, extend three-candidate theorem Faliszewski et al.
(2011) result holds number candidates, allows one
immediately read complexity manipulation scoring protocol,
single-peaked electorates.
proof organization follows. four result sections contains one
spotlight theorem, whose proof give within section itself. proofs seek
give key flavor techniques, text proofs often try
informally describe proofs ideas approaches. first three four spotlight
proofs directly support, fourth spotlight proof part, papers technical
theme single-peakedness tames combinatorial explosion. appendix contains,
completeness, proofs results, definitions omitted main
text.

2. Preliminaries
section presents preliminaries topics election systems, preferences, notions
related Condorcet consistency, single-peakedness.
2.1 Election Systems, Preferences, weakCondorcet Consistency
election system (or election rule) mapping finite set candidates C
finite collection V voter preferences candidates collection W C
called winner set.1 one election systems cover, voters
preference linear order (by always mean strict linear order: irreflexive,
antisymmetric, complete, transitive relation) candidates. election system
called approval voting, voter votes bit-vector, approving disapproving
candidate separately. Voters preferences input list ballots (i.e., votes),
multiple voters preference, ballot appear separately V .
briefly describe election systems central paper. approval
voting, preferences approval vectors, candidate gets highest number
approvals among candidates belongs winner set. systems use,
voters vote linear orders. candidate said Condorcet winner (respectively,
weak Condorcet winner ), candidate preferred candidate strict
majority (respectively, least half) voters. Condorcet voting (or Condorcet
elections) winners precisely set Condorcet winners. election system
1. social choice theory, called social choice correspondence. Social choice theorists often exclude
case allowing function empty set winners, following Bartholdi et al. (1992)
many computationally oriented papers, artificially exclude case definitions.
However, except elections zero candidates, systems discuss might ever output
empty set winners Condorcet weakCondorcet.

443

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

weakCondorcet, winners precisely set weak Condorcet winners.
known two hundred years election instances neither Condorcet winners
weak Condorcet winners (Condorcet, 1785). course, election instance
one Condorcet winner, whereas might several weak Condorcet
winners.
Let , 0 1, rational number. Copeland (Copeland, 1951, = 12 ;
Faliszewski et al., 2009a, general rational ) election system defined follows.
pair distinct candidates, consider one (if any) preferred
two strict majority voters. one gets one Copeland point
pairwise contest gets zero Copeland points. candidates
pair tie pairwise contest (which happen number voters
even), gets points. = 1, Copeland known Llull, system defined
mystic Ramon Llull thirteenth century (see Hagele & Pukelsheim, 2001).
Llulls election system known remarkably resistant, computationally, bribery
control attacks (Faliszewski et al., 2009a, although see also Erdelyi, Nowak, & Rothe,
2009, Erdelyi & Rothe, 2010, Erdelyi, Piras, & Rothe, 2011, Menton, 2013, different
highly resistant systems, see Hemaspaandra, Hemaspaandra, & Rothe, 2009, regarding
extremely resistant artificial systems constructed).
important class elections, focus Section 6, class
scoring protocols. scoring protocol fixed number candidates defined
scoring vector = (1 , 2 , . . . , ) Nm , 1 2 . Voters votes
linear orders, voter contributes 1 points preferred candidate,
2 points next preferred candidate, on. candidate whose
total number points least great totals candidate winner.
example, m-candidate plurality voting scoring protocol defined scoring
m1
z }| {
vector = (1, 0, . . . , 0). m-candidate Borda voting scoring protocol defined
scoring vector = (m 1, 2, . . . , 0).
Kemeny elections based
P concept Kemeny consensus. linear order > minimum Kemeny score, a,bC, > b k{v V | v prefers b a}k, said
Kemeny consensus. usual, kSk denotes cardinality finite set S. candidate c
Kemeny winner c ranked first Kemeny consensus. Kemeny elections
introduced Kemeny (1959, see also Kemeny & Snell, 1960).
Black elections (respectively, weakBlack elections), Condorcet winner (respectively, weak Condorcet winners), defines winners, otherwise Bordas method used select winners. Black elections introduced Black
(1958) weakBlack elections (somewhat confusingly called Black elections there)
introduced Fishburn (1977). Dodgson elections (respectively, weakDodgson elections),
whichever candidates fewest repeated transpositions adjacent candidates
voters orders become Condorcet winners (respectively, weak Condorcet winners)
winners. Dodgson elections introduced 1800s Dodgson (1876) weakDodgson elections (somewhat confusingly called Dodgson elections there) introduced
Fishburn (1977) studied McCabe-Dansted, Pritchard, Slinko (2008).
Young elections (respectively, strongYoung elections), whichever candidates
deletion fewest voters become weak Condorcet (respectively, Condorcet) winners
444

fiBypassing Combinatorial Protections

winners. Young elections introduced Young (1977) strongYoung elections
(somewhat confusingly called Young elections there) introduced Rothe et al. (2003).
important notion paper weakCondorcet-consistent. election system said weakCondorcet-consistent (which earlier wrote, equivalently,
weak-Condorcet consistent), every input least one weak Condorcet winner, winners election system exactly set weak Condorcet winners.2
bribery results hold election systems weakCondorcetconsistent, even election systems restricted single-peaked electorates
weakCondorcet-consistent.
Fishburn (1977) noted election systems weakBlack, weakDodgson, Fishburn, Maximin, Young weakCondorcet-consistent. add observation
Llull elections easily seen definition weakCondorcet-consistent.
also make (new) observation election systems Kemeny, Schwartz,
two variants Nanson due Fishburn Schwartz weakCondorcet-consistent
restricted single-peaked electorates. (By Fishburn, 1977, Niou, 1987, systems
known weakCondorcet-consistent general case.) also note
Black, Dodgson, original version Nanson, , 0 < 1, Copeland elections weakCondorcet-consistent even restricted single-peaked electorates.
seen following universal counterexample. Let two voters preferences b > > c c > b > a. preferences single-peaked respect
societal ordering L b L c (the notion societal orders explained two paragraphs present one). Candidates b c weak Condorcet winners,
mentioned election systems chooses b. Similarly, note strongYoung
weakCondorcet-consistent single-peaked electorates election two
voters whose preferences > b > c c > b > a, candidates weak Condorcet
winners, strongYoung yields candidates c. appendix includes definitions
election systems Fishburn, Maximin (a.k.a. Simpson), Nanson, proves
new observations made paragraph.
2.2 Single-Peaked Preferences
papers theme combinatorial protections crumble case single-peaked
electorates. briefly define single-peaked preferences motivation is.
single-peaked preference model introduced half century ago Black
(1948, 1958) influential ever since. model captures case
electorate polarized single issue dimension, voters utility along
dimension either one peak rises falls. Candidates positions (locations)
along dimension. voters preferences (in linear order model) simply order
candidates utility (except ties allowed). Since utility curves flexible,
amounts overall societal ordering L candidates,
voter placed location candidates
2. nomenclature literature varied here. authors use term weak Condorcetconsistent mean systems always select weak Condorcet winners perhaps additional winners. denote weakCondorcet-consistent precisely Fishburn (1977) calls
[obeying the] strict Condorcet principle.

445

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

voters
v1
v2
v3
v4

utility

c1
liberal

c2

c3

c4

candidates

c5
conservative

Figure 1: Example single-peaked electorate four voters, utility functions
shown.

right preferences drop left, although within framework,
right left candidates interspersed other. picture make
clearer. Figure 1 shows electorate four voters five candidates,
societys polarization (liberal-to-conservative) axis. picture, see
v1 preferences c5 > c4 > c3 > c2 > c1 , v2 preferences c1 > c2 > c3 > c4 > c5 ,
v3 preferences (note interleaving) c2 > c3 > c1 > c4 > c5 , v4 preferences
c4 > c5 > c3 > c2 > c1 .
Formally, many equivalent ways capture behavior, use
following definition. collection V votes (each linear ordering >i
candidates) candidate set C said single-peaked exactly exists linear ordering L C triple candidates a, b, c, holds
(a L b L c c L b L a) (i) [a >i b b >i c].
single-peaked model intensely studied, strengths limitations. positive side, excellent rough model wide range elections.
Votes ranging American presidential elections US Supreme Court votes hiring
votes within CS department often shockingly close reflecting single-peaked preferences. certainly vastly reasonable model settings assuming
voters random independent, although latter model receiving
huge amount study recently. fact, wide range scholarly studies argued
value single-peaked model (Black, 1948, 1958; Davis, Hinich, & Ordeshook, 1970;
Niemi & Wright, 1987; Procaccia & Rosenschein, 2007; Krehbiel, 1998), model
one first taught students positive (i.e., theoretical) political science courses.
hand, electorates certainly driven multidimensional concerns,
even heavily unidimensional electorate may outside-the-box voters (e.g., voters
election polarized liberal-conservative axis decide votes instead based
on, example, religion race). Simply put, model, speaks simplified
version world.
446

fiBypassing Combinatorial Protections

single-peaked model also makes sense approval voting (Faliszewski et al., 2011):
There, voter intuitively may thought utility threshold starting
approves candidates. means voters approved candidates
must contiguous within societys linear order L. Formally, define saying
election instance (of approval voters) single-peaked exactly exists linear
order L triple candidates a, b, c, L b L c (i) [{a, c}
Approvesi b Approvesi ], Approvesi set candidates voter approves.
Following suggestion Walshs (2007) seminal work, assume (except
make something else clear) societys linear order part input singlepeaked winner, bribery, manipulation, control problems. However, mention
passing given election instance, one polynomial time tell whether voters
single-peaked also polynomial time compute societal linear order
instantiating single-peakedness (by Bartholdi Trick, 1986, Doignon Falmagne,
1994, Escoffier, Lang, Ozturk, 2008, linear-order preferences and, pointed
Theorem 2.1 Faliszewski et al., 2011, Fulkerson Gross, 1965, Booth
Lueker, 1976, approval preferences). One course also easily, polynomial
time, check whether given linear order one respect given set votes
single-peaked.
want get results quickly possible, define needed
notions winner, bribery, control, manipulation start section
particular topic.

3. WeakCondorcet Elections, Single-Peaked Electorates, Bypassing
Winner-Problem Complexity
main results sections paper study whether single-peakedness bypasses
complexity-theoretic protections attacks elections. moving sections, quickly present results showing single-peakedness also bypasses
complexity results systems even telling won. Unlike protection
attack complexity-shield bypassings, sense bad news (for security election systems), winner-hardness complexity-shield bypassings
good newstaming complexity election systems Dodgson Kemeny
single-peaked case, despite fact known NP-hard winner problems
general case.
given election system E, winner problem takes input election, (C, V ),
candidate p C, asks p winner election whose candidates C
whose votes V (where V collection votes candidate set C).
speak single-peaked case winner problem, input also contain linear
order L relative election single-peaked. (Formally, part winner-problem
task check input indeed single-peaked relative L. However, since
polynomial-time check caseslinear orders approval vectorsthat deal
with, tacitly view appropriateness L syntactic condition input,
although really syntactic.) Note weakCondorcet winner problem P
general case thus certainly single-peaked case. Furthermore, something
447

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

used often papers proofs following standard fact Condorcet voting
medians.
Fact 3.1. Let (C, V ) election votes linear orders C, let L
linear order respect (C, V ) single-peaked. Associate voter
candidate top voters preference ordering. Order voters respect L
terms association.
kV k odd unique weakCondorcet Condorcet winner winner
top preference median voter. kV k even weakCondorcet winner set
set candidates L fall range, inclusively, top preference
leftmost two median voters top preference rightmost two
median voters (and two coincide, candidate Condorcet winner
otherwise Condorcet winner).
example, ordered-by-L picture candidates voters
top choices are:
v3
v6
v1
v2
v4
v5
c1

c2

c3

c4

c5

c6

c2 , c3 , c4 weak Condorcet winners, since candidates preferred
candidates right v1 , v2 , v3 , candidates left v4 , v5 ,
v6 . c1 weak Condorcet winner, since voters v1 prefer c2 c1 .
c5 c6 weak Condorcet winners, since v1 , v2 , v3 , v4 prefer c4 c5 c6 .
Finally, note Condorcet winner, since Condorcet winner unique
weak Condorcet winner.
immediate consequence Fact 3.1 well-known fact single-peaked
elections, always least one weak Condorcet winner (we tacitly assuming
C 6= ). Since earlier noted winner problem P weakCondorcet elections,
following holds.
Theorem 3.2. election system E weakCondorcet-consistent restricted
single-peaked electorates, winner problem P restricted single-peaked
elections.
course, many systems winner problem obviously P even general.
Yet get interesting consequences Theorem 3.2 following (recall
Section 2 Young weakDodgson weakCondorcet-consistent, Kemeny
weakCondorcet-consistent restricted single-peaked electorates).
Corollary 3.3. restricted single-peaked electorates, winner problems Kemeny, Young, weakDodgson elections P.
contrast, general-case Kemeny winner problem problem proven Hemaspaandra et al. (2005) p2 -complete.3 prove paper generalcase winner problems Young weakDodgson elections p2 -complete well (see
3. p2 class sets solved polynomial-time parallel access NP (Papadimitriou &
Zachos, 1983; Hemachandra, 1989). Throughout paper, completeness always refers completeness
respect polynomial-time many-one reductions.

448

fiBypassing Combinatorial Protections

Theorems A.2 A.4 appendix). So, Theorem 3.2 implies sharp complexity simplifications three election systems. mention passing even generalization single-peakedness known bounded single-peaked width (Cornaz, Galand,
& Spanjaard, 2012), work Cornaz, Galand, Spanjaard (2013) done subsequent Corollary 3.3 (Brandt, Brill, Hemaspaandra, & Hemaspaandra, 2010) shows
polynomial time one find Kemeny winner, find score
winnerand thus Kemeny winnerswill have. (This necessarily mean one
polynomial-time algorithm testing, generalized setting, whether given
candidate Kemeny winner.)
identify weakCondorcet approach worked Young weakDodgson elections apply Dodgson strongYoung elections. However,
constructed direct algorithms solve winner problems polynomial time
single-peaked case. state theorem, prove immediately
spotlight proof section.
Theorem 3.4. restricted single-peaked electorates, winner problems Dodgson strongYoung elections P.
Proof. Recall following easy characterization Condorcet winners singlepeaked setting. kV k odd, top choice median voter Condorcet winner.
kV k even, two cases: either median voters top choice
not. former case, median voters preferred candidate Condorcet winner,
latter case Condorcet winner (since top choices two medians,
different, tie other).
Given election instance (C, V ) valid single-peaked order L, show
compute strongYoung winners polynomial time. Recall strongYoung winners
candidates made Condorcet winners fewest voter deletions.
mention C = never winners. zero voters, candidates
strongYoung winners, tie distance , convention.4 (C, V )
Condorcet winner, unique strongYoung winner. Otherwise kV k 2 even
two median voters different top choices, say m` mr . strongYoung
winner set {m` , mr }, two candidates strongYoung score 1, one
score 0, everyone else score least 2.
show Algorithm 1, clearly runs polynomial time, computes
Dodgson winners. Recall Dodgson winners candidates fewest
repeated transpositions adjacent candidates voters orders (so-called switches) become
Condorcet winners. kCk = 0, winners, kV k = 0, C ties
winners, (C, V ) Condorcet winner, candidate unique Dodgson
winner. assume kV k 2 even two median voters different top choices,
say m` mr , m` L mr , candidate Dodgson score 0. intuition behind
4. Regarding line Algorithm 1 handling zero-voter zero-candidate case, one might
wonder dont define election problems allow cases. answer is, first,
unattractive simplify proofs altering problems. But, compellingly, control problems
important papers, control problems inputs small number
candidates (respectively, voters) create situations small numbers candidates
(respectively, voters). particular, legal partitions within partition-control types leave one
candidates voters.

449

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

algorithm follows. show every Dodgson winner weak Condorcet winner.
show always turn weak Condorcet winner Condorcet winner
minimum number switches making changes two voters.5 proof
correctness follows immediately Claims 3.5 3.6 below. Note Fact 3.1,
set weak Condorcet winners consists candidates L fall range,
inclusively, m` mr . denote set [m` , mr ]L .
Claim 3.5. Algorithm 1 find correct Dodgson score candidate p [m` , mr ]L .
Claim 3.6. Every Dodgson winner [m` , mr ]L .
proofs two claims, use following simple claim.
Claim 3.7.

1. Let p [m` , mr ]L . (a L b L p p L b L a) ties p, b ties p.

2. mr L d, mr beats d. L m` , m` beats d.6
Proof Claim 3.7.
1. know half voters prefer p half voters prefer p a.
voters prefer p also prefer b p. implies p best ties b.
Fact 3.1, p weak Condorcet winner. follows p ties b.
2. prove first statement. proof second statement analogous. Suppose
contradiction mr beat d. Since mr weak Condorcet winner,
mr ties d. Let db candidate immediately right mr (with respect L).
Using part 1 claim, follows db ties mr .
Since db weak Condorcet winner, exists candidate c c beats
b Note c L mr L db mr L db L c. c L mr L d,
b every voter prefers c
d.
b mr beats d,
b contradicts fact mr ties
db also prefers mr d.
b
b
d. mr L L c, every voter prefers c db also prefers db mr . c
db beat mr , contradicts fact mr weak Condorcet winner.
q Claim 3.7
Proof Claim 3.5. Consider optimal (with respect number switches) way
turn p Condorcet winner. first assume T` 6= Tr 6= . Let c`
leftmost candidate T` let cr rightmost candidate Tr . Since p needs
gain vote c` , exists voter v` c` >v` p p gets switched beyond c`
v` . Since p needs gain vote cr , exists voter vr cr >vr p p
gets switched beyond cr vr . Let A` , B` , C` sets candidates v` order
form
A` > c` > B` > p > C` .
5. One might think turning weak Condorcet winner Condorcet winner would equivalent
making sure median voters candidate top choice. However, note
electorate may longer single-peaked switches, footnoted statement
surprising harder prove one might think.
6. Note possible candidate weak Condorcet winner tie weak Condorcet
winner. example, universal counterexample end Section A.2, candidate a,
weak Condorcet winner, ties weak Condorcet winner c.

450

fiBypassing Combinatorial Protections

Algorithm 1 Dodgson winners
1: kV k = 0 kCk = 0
2:
return C
3: else kV k odd (kV k even two median voters top choice)

4:
return candidate chosen median voter(s)
5: else
6:
Let m` mr , m` L mr , top choices median voters
7:
p [m` , mr ]L
8:
DodgsonScore(p)
9:
Let T` set candidates c c L p c ties p
10:
Let Tr set candidates c p L c c ties p
11:
v` , vr V T` >v` p Tr >vr p
12:
Move p order v` beyond every candidate T`
13:
Move p order vr beyond every candidate Tr
14:
Let n number switches used
15:
n < DodgsonScore(p)
16:
DodgsonScore(p) n
17:
return {p C | DodgsonScore(p) DodgsonScore(c) c [m` , mr ]L }
Let Ar , Br , Cr sets candidates vr order form
Ar > cr > Br > p > Cr .
Note T` >v` p >v` Tr Tr >vr p >vr T` . Clearly, v` 6= vr takes kB` k + 1
switches switch p beyond c` v` takes kBr k + 1 switches switch p beyond cr
vr . kB` k + kBr k + 2 switches, v` order turned A` > p > c` > B` > C`
vr order turned Ar > p > cr > Br > Cr . Since T` Cr , still
ensure p gains vote every candidate A` T` since Tr C` , still
ensure p gains vote every candidate Ar Tr . So,
DodgsonScore(p) kB` k + kBr k + 2 + kA` T` k + kAr Tr k.
show Algorithm 1 correctly computes Dodgson score p. First note
algorithm computes upper bound Dodgson score, since p made
Condorcet winner iteration loop (recall Fact 3.1 p already
weak Condorcet winner). consider score computed algorithm voters v`
vr (since T` >v` p Tr >vr p, algorithm consider two voters).
analysis, may help keep mind c` L T` {c` } L p L Tr {cr } L cr .
top choice v` c` left c` , A` T` = . case,
moving p order v` beyond every candidate T` gives
A` > p > c` > B` > C` .
top choice v` right c` , every candidate c A` , c` L c L p.
follows Claim 3.7.1 A` = A` T` . case, algorithm changes v`
p > A` > c` > B` > C` .
451

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

cases, algorithm uses kB` k + 1 + kA` T` k switches v` . argument
shows algorithm uses kBr k + 1 + kAr Tr k switches vr . clearly makes p
Condorcet winner using kB` k + kBr k + 2 + kA` T` k + kAr Tr k switches. Since
also upper bound (see above), follows
DodgsonScore(p) = kB` k + kBr k + 2 + kA` T` k + kAr Tr k.
still handle case T` = Tr = . Without loss generality,
assume Tr = . Since m` mr tie p m` 6= mr , follows T` 6= . Let c`
leftmost candidate T` . previous case, exist voter v` sets
candidates A` , B` , C` v` order form
A` > c` > B` > p > C`

DodgsonScore(p) kB` k + 1 + kA` T` k.
show Algorithm 1 correctly computes Dodgson score p. Consider
score computed algorithm voter v` letting vr arbitrary voter.
Since T` >v` p Tr >vr p (since Tr = ), algorithm consider two voters.
previous case, algorithm uses kB` k + 1 + kA` T` k switches v` .
since Vr = , algorithm uses zero switches vr . clearly makes p Condorcet
winner using kB` k + 1 + kA` T` k switches. Since also upper bound, follows

DodgsonScore(p) = kB` k + 1 + kA` T` k.
q Claim 3.5
Proof Claim 3.6. Let 6 [m` , mr ]L . Without loss generality, assume mr L d.
show DodgsonScore(d) > DodgsonScore(mr ), implies
Dodgson winner. Let set candidates C {mr } mr ties with. Note
6= , since m` ties mr . every c , c L mr (by Claim 3.7.2) beat
c (half voters prefer c mr , since c L mr L d, voters prefer c mr d).
Consider optimal (with respect number switches) way turn
Condorcet winner. Let c` leftmost candidate . Since half voters prefer c`
mr d, exists voter v c` >v mr >v gets switched beyond c`
v. Let A, B, C1 , C2 sets candidates vs order form
> c` > B > mr > C1 > > C2 .
takes kBk + kC1 k + 2 switches switch beyond c` v, switches, vs
order turned
> > c` > B > mr > C1 > C2 .
still ensure gains vote every candidate . So,
DodgsonScore(d) kBk + kC1 k + 2 + kA k.
consider mr . Since c` leftmost candidate every c , c L mr ,
holds >v mr . Since mr weak Condorcet winner, moving mr order
452

fiBypassing Combinatorial Protections

v beyond every candidate makes mr Condorcet winner gives upper bound
Dodgson score mr .
top choice v c` left c` , = . case, moving
mr order v beyond every candidate gives
> mr > c` > B > C1 > > C2 .
top choice v right c` , every candidate c A, c` L c L mr .
follows Claim 3.7.1 = . case, moving mr order v beyond
every candidate gives
mr > > c` > B > C1 > > C2 .
cases, use kBk + 1 + kA k switches v. clearly makes mr Condorcet
winner,
DodgsonScore(mr ) kBk + 1 + kA k < DodgsonScore(d).
q Claim 3.6

follows Dodgson winner.

q Theorem 3.4
claims Theorem 3.4 contrast directly known p2 -completeness
general-case Dodgson (Hemaspaandra et al., 1997) strongYoung (Rothe et al., 2003)
winner problems, thus reflect substantial complexity simplification holds
electorates single-peaked. section focused election systems
Dodgson, Kemeny, Young, natural, important first three election
systems proven p2 -complete winner problems (for least one strong
weak variants). commend reader issue obtaining, election
systems hard winner problems, reductions winner complexity single-peaked
case.
Although Theorem 3.4 winners rather bribery/manipulation/control
protections, proof good, simple example papers theme single-peakedness
tames combinatorial explosions. Taking Dodgson example: general case (not
necessarily single-peaked votes), set paths potentially implement best Dodgson
scores combinatorially explosive (to best current knowledge). contrast,
single-peaked case searching paths implement best Dodgson scores turns
restrict changing two voters particularly simple way yields
polynomial-sized set options search space.

4. Bribery Single-Peaked Elections
section shows single-peakedness undercuts many, although all, NP-hardness
protections bribery problems.
453

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

4.1 Notions
bribery notions presented here, except negative approval bribery, paper started complexity-theoretic study bribery (Faliszewski, Hemaspaandra, &
Hemaspaandra, 2009). Given election system E, E-bribery problem takes input
C, V , p C, k {0, 1, 2, . . .}, asks if, changing votes k members V , p made winner election respect E. basic
bribery problem. modified combination following items. $
means voter price (belonging {1, 2, 3, . . .}) question whether
set voters whose total price k changing votes
make p winner. intuition prices voters swayed
easily others. Weighted means vote weight (belonging {1, 2, 3, . . .}),
weight w vote bribed indivisible object, applying E, viewed
w identical regular votes. intuition weights electionse.g.,
stockholdersvoters differing weights.
case V consists linear orders, negative mean bribe
voter bribe voter must p top choice unless p already
top choice bribe.7 intuition negative bribery one trying
stay radar directly helping ones candidate. voting approval
vectors, give definitions capture analog linear-preference negative
notion defined (negative) one one would get taking Faliszewski
et al. (2009) utterly literally (strong negative)see Footnote 7 background.
approval-vector votes, negative mean bribe voter,
after-bribe vector approve p before-bribe vector approved p.
strongnegative mean bribe voter voter bribed cannot
approve p. notions described occur combination, e.g., speak
Llull-negative-weighted-$bribery.
speak single-peaked case above, mean electorate
single-peaked, L relative votes single-peaked part
input. Further, bribes must result votes consistent input
societal order L. Taking L part input, binding legal bribes,
natural bribery analog manipulation model Walsh (2007) Faliszewski et al.
(2011). Binding bribes respect L natural, e.g., L widely known, central
authority may simply reject (as obviously manipulative votes) votes violate L.
although core model, many results carry models flexible
points, times point outsee Footnote 8, Footnote 9, final
paragraph Section 5.1.
7. Faliszewski et al. (2009) definition negative bribery naturally read quite
different semantics bribed voter must, bribe, p top choice.
Since paper used negative bribery plurality, issue made difference paper,
indeed since look negative bribery linear orders mostly respect weakCondorcet
single-peaked contexts, key issue either. switched definition
captures attractive notion: cannot directly boost preferred candidate p top,
votes p already top shift remaining preferences. distinction
two approaches negative change proofs case approval voting,
give separate definitions capture notion.

454

fiBypassing Combinatorial Protections

often speak bribery (or, later, manipulation control) problems
P (or polynomial time). Although formally asserts P algorithm
exists say whether successful bribery (or manipulation control) action exists, fact
every instance proof show addition obtain actual, successful
bribery (or manipulation control) action one exists. reason worth
mentioning that, even context elections, search plausibly harder
decision (Hemaspaandra, Hemaspaandra, & Menton, 2013).
4.2 Approval-Bribery Results
spotlight result approval-bribery, prove bribery protection
complexity gives fails single-peaked electorates.
Theorem 4.1 (Faliszewski et al., 2009). Approval-bribery NP-complete.
Theorem 4.2. Approval-bribery P single-peaked electorates.8
prove Theorem 4.2, informally explain key challenge (namely,
incomparability) exists regarding proving proof overcomes challenge
(namely, using directionality).
So, recall approval bribery single-peaked setting, societal order, L,
part input voter approves (possibly empty) set candidates
contiguous respect L. Suppose input linear order L c1 L c2 L c3 L L c100
respect society single-peaked. Suppose candidate briber trying
make win c25 . Suppose input limit number people briber
bribe 2009 suppose input election 5000 voters 3000 (call V )
initially approve c25 2000 (call V+ ) initially approve c25 . Now,
clearly, spend 2009 bribes voters V+ , voters already
approve c25 , bribing voter V+ never better bribing voter
V . So, goal seek good set 2009 voters V , exists.
key challenge, even given single-peakedness, stated word: incomparability. is, given know number approvals c25 go exactly
2009 bribe, given know total number approvals candidate
gets bribe, candidate ci c25 target number ni
among 2009 votes choose bribe V , least ni must initially
approved ci (in order c25 beat ci bribe).
Now, rub. Consider two voters V , one approves c30
c55 approves c40 c80 . Among two votes,
former helps us address positive ni values 30 39, latter helps us
address positive ni values 56 80. Since neither voters approval set contains
others, offer differing advantages, neither is, first glance, obviously one
include 2009. fact 3000 voters V thicket
incomparabilities. Indeed, trying find subset size 2009 (in particular example,
8. result holds model L part input model must find
L consistent input relative bribery possible. result also holds even
modelnot core model prove itin bribed voters need respect
societal order bribed.

455

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

number vary input) feels much like covering problem, fact
exactly path general case proven NP-hard Faliszewski et al.
(2009).
However, use single-peakedness tame combinatorial challenge choosing
good subset. particular use single-peakedness induce directional attack
locally make incomparability disappear moment need make
decision choosing 2009. (Although focus bribery,
construction arguments tailored that, mention line attack
modeled Faliszewski et al., 2011, call smart greedy algorithms
use study control attacks.) full proof appendix, key idea
easily conveyed reader kind visualize along us moment.
Consider largest ni > 0, (for purpose example) suppose
strictly greater 25let us say 93, suppose n93 = 3.
must include 2009 least three members V approve c93 .
three? Isnt incomparability still problem? No! Since chose largest
ni > 0, clearly n94 = = n100 = 0. although among voters V approve
c93 may incomparability approval ranges, range differences right
c93 utterly irrelevant, c25 already beating candidates anyway.
interesting issue is, among voters V approve c93 , leftmost approved
candidate isthe leftward better help possible ni deficits.
direct comparisons take action: put 2009
three voters (among V voters initially approve c93 ) whose approval range
leftmost. (If V lacks three voters approve c93 , since n93 = 3, successful bribery
impossible.) process continues one would expect: Based three
votes, ni values updated next leftmost ni > 0 satisfying 26 similarly
handled, ni > 0 26 handled, starting
end L analogously handle c1 c24 . neutralize ni > 0 within
2009 bribes among V , successful bribery, otherwise none possible.
concludes example single-peakedness creates directionality tames rich
covering problem caused incomparability.
fact, example essentially (if one removes particular integer values
used) complete proof case k kV k. note k kV k,
always make p winner bribing voters V , since bribe voters approve
p. following proof Theorem 4.2 gives careful exposition process.
However, reader comfortable somewhat informal presentation given may
wish least initially simply skip following detailed proof.
Proof Theorem 4.2. Let (C, V ) instance single-peaked election
societal order L given c1 L c2 L L ckCk let k bribe limit.
decide whether designated candidate p C made approval winner bribing
k voters. Without loss generality, assume bribe, bribed
voters approve p disapprove candidates.
Partition multiset V voters multiset V+ voters approve p
multiset V voters disapprove p. k kV k, obviously make p
winner bribing voters V , since bribe voters approve p. (The
case need bribe voter V+ everybody approves p (i.e., V = ),
456

fiBypassing Combinatorial Protections

exists candidate p also approved every voter, want
make p unique approval winner; case, bribing one arbitrary voter obviously
suffices.)
assume k < kV k. Without loss generality, assume bribe
exactly k voters, successful bribe involves k voters
successful bribe involves exactly k voters. also argue bribing
voter V+ never profitable bribing voter V . reason
ci C {p}, bribing voter V+ lowers quantity number approvals
ci number approvals p 1, whereas bribing voter V lowers
quantity least 1. Thus assume without loss generality bribe
voters V know bribe, p exactly b
k = kV+ k + k approvals.
candidate ci C {p}, let Vci multiset voters approve ci
define surplus ni ci ni = kVci k b
k. order make p winner, bribe
least ni voters Vci V candidates ci positive surplus.
Let us first consider candidates right p, i.e., candidates c p L c. order
avoid incomparability problems, start right end L. Let ci rightmost
candidate positive surplus ni > 0. know bribe least ni
voters Vci V , question ones. nj 0 j > i, solely
focus candidates left ci bribe ni voters Vci V whose approval
range extends furthest left ci . bribe, voters approve p only.
thereby achieved ni = 0 clear choice optimal sense
choice would removed greater number approvals candidates
p (ignoring candidates right ci ).
update surplus candidates move next rightmost candidate ci0 right p positive surplus. (Observe i0 < j > i,
nj initially nonpositive surplus candidate never grows bribing voter
approve p.) repeat procedure candidates right p
nonpositive surplus, point mirror societal order repeat whole
process, thereby handling candidates c c L p.
exceed bribe limit k process, cannot successful bribery
action: choices made algorithm provably least good
choice would been. If, hand, bribing k 0 k voters suffices
make surpluses nonpositive, bribe (k k 0 ) additional voters chosen arbitrarily
V (to ensure p b
k approvals) thereby found successful bribery
action.
q Theorem 4.2
general approach used prove Theorem 4.2using directional attack
single-peaked setting tame incomparability challenges covering problems
establish following two additional cases NP-hard bribery problems fall
P single-peaked case.
Theorem 4.3. following hold:9
9. claim standard model: nonunique-winner model (i.e., ask preferred candidate p
made winner); societal order L given part input; bribed voters must still
respect L. However, note passing claim still holds choices one make

457

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

1. Approval-negative-bribery approval-strongnegative-bribery NP-complete.
2. single-peaked electorates, approval-negative-bribery approval-strongnegativebribery P.
Faliszewski, Hemaspaandra, Hemaspaandra (2011a, see also Faliszewski, Hemaspaandra, & Hemaspaandra, 2011b) observed constructions proofs
Theorem 4.2 Theorem 4.3 (part 2) used show results hold even
flexible model logarithmic number voters violate
societal linear order.
4.3 Llull-Bribery Kemeny-Bribery Results: weakCondorcet Consistency
state following eight-case result. membership-in-P claims Theorem 4.4
proven direct algorithmic attacks using connection weakCondorcet
median voters. theorems NP-completeness claims shown reductions
NP-complete problems Knapsack Partition.
Theorem 4.4. single-peaked electorates, weakCondorcet-weighted-$bribery, weakCondorcet-negative-weighted-bribery, weakCondorcet-negative-weighted-$bribery
NP-complete, remaining five cases (weakCondorcet-bribery, weakCondorcet$bribery, weakCondorcet-weighted-bribery, weakCondorcet-negative-bribery, weakCondorcetnegative-$bribery) P.
Theorem 4.4 interesting says weakCondorcet elections,
immediate consequences election systems.
Corollary 4.5. Let E election system weakCondorcet-consistent
merely weakCondorcet-consistent single-peaked inputs. three NP-completeness
five P results Theorem 4.4 hold (for single-peaked electorates) E.
discussions earlier paper, Corollary 4.5 applies Llull, Kemeny,
Young, weakDodgson, Maximin, Schwartz, weakBlack, Fishburn, two variants
Nanson due Fishburn Schwartz. light this, Corollary 4.5 quietly establishing
large number claims NP-hardness shields failing single-peaked electorates.
example, following claims.
Theorem 4.6 (Faliszewski et al., 2009). Llull-bribery, Llull-$bribery, Llull-weighted-bribery,
Llull-weighted-$bribery NP-complete.
Theorem 4.7 (follows Corollary 4.5). single-peaked electorates: Llull-bribery,
Llull-$bribery, Llull-weighted-bribery P Llull-weighted-$bribery NPcomplete.
regarding: nonunique-winner model vs. unique-winner model; L part input vs. asking
whether exists valid L respect successful bribery accomplished;
bribed voters respect L model vs. model bribed voters may violate L. Seeing
result holds various alternate models requires natural modifications proof cases
(e.g., nonunique vs. unique), requires taking advantage specific properties construction
cases (e.g., regarding allowing bribed voters violate L, constructions actually bribe
voters end approving zero one candidate, votes consistent every ordering).

458

fiBypassing Combinatorial Protections

best knowledge, bribery Kemeny elections never studied. Note,
however, winner problem election system E many-one reduces
eight types bribery problems mentioned Theorem 4.4, except weakCondorcet
replaced E. holds ask whether preferred candidate wins
given bribe limit 0, captures winner problem. So, known
p2 -completeness winner problem Kemeny elections (Hemaspaandra et al., 2005),
following result, gives us eight contrasts hardness (three
p2 -hardness NP membership five p2 -hardness P membership).
Theorem 4.8. Kemeny elections, eight types bribery mentioned Theorem 4.4
p2 -hard.
Theorem 4.9 (follows Corollary 4.5). single-peaked electorates, Kemeny-weighted$bribery, Kemeny-negative-weighted-bribery, Kemeny-negative-weighted-$bribery NPcomplete (and particular belongs NP). single-peaked electorates,
remaining five types bribery Kemeny elections P.
final remark regarding Theorem 4.4, note even within single-peaked
cases studies, one twist, changing bribery negative bribery
changes complexity, namely, single-peaked electorates, weakCondorcet-weightedbribery P weakCondorcet-negative-weighted-bribery NP-complete. Here, decreasing set bribes available briber actually boosts complexity
bribers task. (The explanation is, loosely intuitively speaking,
among set bribes negativity removes search space set bribes
used P-time nonnegative case bribery attack.)

5. Control Partition Single-Peaked Electorates
control problems elections ask whether various types changes elections
structure given candidate made winner. (In papers, seeking make
candidate winner structural changes called constructive control distinguish
destructive case trying preclude candidate winning.
However, paper always use control constructive sense, unless explicitly
mention otherwise.) types control introduced 1992 Bartholdi, Tovey,
Trick, (give take slight refinements) studied subsequent
papers, addition/deletion/partition voters/candidates. However, best
knowledge previous study complexity control single-peaked electorates (such
Faliszewski et al., 2011) focused exclusively additions deletions candidates
voters.
first time study complexity partition problems case singlepeaked electorates. show broad range election systems control
partition voters problem P single-peaked electorates. Among systems
Llull Condorcet elections, whose control partition voters problem
known NP-complete general electorates. proofs work using singlepeakedness tame combinatorial explosionin case, number partitions
must examined reduced exponential number partitions polynomial
number classes partitions checked block.
459

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

5.1 Notions
define key types control study: control partition
voters, control adding voters, control deleting voters.
Partition voters models case partitioned electorate primaries.
example Faliszewski et al. (2009a) business group powerful manager studies
issue splitting group two task forces (by voting) recommend
alternatives part final vote conducted entire group. (loosely)
corresponds control partition. Control adding voters loosely models actions
targeted get-out-the-vote drives. Control deleting voters loosely models actions
targeted attempts voter suppression.
partition case, two first-round elections second-round
election, two different approaches candidates move forward
first-round election. One Ties Promote (TP) model, winners firstround election move forward. Ties Eliminate (TE) model, which,
first-round election, unique winner moves forward unique winner
otherwise one moves forward first-round election. consistency, control
definitions adopted, often word-for-word, papers Hemaspaandra
et al. (2013), Faliszewski et al. (2009a), Faliszewski, Hemaspaandra, Hemaspaandra
(2014).
Definition 5.1. Let E election system.
1. control partition voters problem E, TP TE tie-handling rule
model, given election (C, V ) candidate p C. partition10
V V1 V2 p winner two-stage election winners
election (C, V1 ) survive tie-handling rule compete winners
(C, V2 ) survive tie-handling rule? two first-round one
second-round elections conducted using election system E.11
2. control adding voters problem E given set candidates C,
two collections voters, V (often referred collection registered voters)
W (often referred collection unregistered voters), preferences
C, candidate p C, nonnegative integer K. ask whether
subcollection W 0 W (a) kW 0 k K, (b) p winner E election
(C, V W 0 ).
3. control deleting voters problem E given election (C, V ),
candidate p C, nonnegative integer K. ask whether collection
V 0 voters obtained V deleting K voters p
winner E election (C, V 0 ).
10. partition collection pair collections (A1 , A2 ) A1 A2 = A1 A2 = ;
since different voters preferences, multiset operations.
11. important note definition draw it, speak election,
(C 0 , V 0 ), always implicitly mean vote V 0 passed election system
version restricted candidates C 0 . particular, relevant second-round
election here.

460

fiBypassing Combinatorial Protections

three definitions called nonunique-winner model,
namely, question is: p made winner final election? Another model
studied literature called unique-winner model,
questions replaced with: p made uniquely win final election?
find natural study TP, nonunique-winner model. (TP nonunique-winner
pair naturally, TE unique-winner.) contrast, seminal control paper
Bartholdi et al. (1992) used unique-winner model. clear broad possible
models results hold in, checked results hold
four model combinations (i.e., TP unique-winner, TP nonunique winner, TE
unique-winner, TE nonunique-winner).
speak control problem single-peaked electorates, mean
societal order L part input. mean single-peakedness must hold
entire input (including potentially added candidates voters). However,
control, turns just-mentioned model polynomial-time membership holds
polynomial-time membership holds model one given L
part input rather one asked whether exists linear order L relative
input (as before, even including potentially added candidates voters)
single-peaked goal achieved given control action.
claim formalized Theorem A.5 proven appendix. light Theorem A.5,
simply assume control results default model (societal order part
input).
5.2 Control Results Related weakCondorcet Elections
section present control results, focus control partition voters. see although Llull Condorcet elections NP-hard voter-partition
control problems, problems fall polynomial time single-peaked electorates.
spotlight result section states partition-by-voters control weakCondorcet
elections P.
Theorem 5.2. weakCondorcet elections, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,
Ties Promote model Ties Eliminate model.
giving Theorem 5.2s proof, let us note consequences contrasts.
Corollary 5.3. Let E election system weakCondorcet-consistent singlepeaked inputs. election system E, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,
Ties Promote model Ties Eliminate model. particular, holds
election systems Llull, Kemeny, Young, weakDodgson, Maximin, Schwartz, weakBlack,
Fishburn, two variants Nanson due Fishburn Schwartz.
Llull elections, provides clear contrast known NP-completeness
control type general case.
Theorem 5.4 (Faliszewski et al., 2009a). Llull elections, control partition voters
NP-complete, nonunique-winner model unique-winner model,
Ties Promote model Ties Eliminate model.
461

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Algorithm 2 weakCondorcet Control Partition Voters
1: a, b, c, C L b, c L d, L c, p weakCondorcet winner
(C 0 , V ) C 0 = {e C | L e L b c L e L d}
2:
k {0, 1, 2, . . . , kV k}
3:
let r number interesting regions
P
4:
` = (`1 , `2 , . . . , `r ) Nr ri=1 `i = k
5:
define P` set partitions (V1 , V2 ) i, `i
number voters V1 whose top choice Ri
6:
P` 6=
7:
let (V1 , V2 ) arbitrary partition P`
8:
set weakCondorcet winners (C, V1 ) equals [a, b]
set weakCondorcet winners (C, V2 ) equals [c, d]
9:
return (V1 , V2 )
10: return partition voters makes p weakCondorcet winner

turn proof Theorem 5.2. idea behind proof differs completely
approach used polynomial-time control proofs Faliszewski et al. (2011),
is, think, novel.
Proof Theorem 5.2. Let (C, V ) election L linear order C respect
electorate single-peaked. decide whether designated candidate
p C made overall winner partitioning set voters appropriate
way.
algorithm tailored natural Ties Promote, nonunique-winner model,
end proof mention adapted models.
natural model, want find partition (V1 , V2 ) p weakCondorcet winner
election (C 0 , V ) C 0 union weakCondorcet winners (C, V1 )
(C, V2 ).
show Algorithm 2 returns partition property whenever one exists.
Algorithm 2 loops 4-tuples a, b, c, candidates tests whether voters
partitioned (V1 , V2 ) way (a) weakCondorcet winners (C, V1 )
[a, b] (i.e., candidates {x C | L x L b}, writing L z (y = z L z)),
(b) weakCondorcet winners (C, V2 ) [c, d], (c) p weakCondorcet winner
([a, b] [c, d], V ).
4-tuple a, b, c, d, divide set C candidates disjoint interesting
regions. Regions defined follows. candidates a, b, c, constitutes
region itself. Furthermore, contiguous (with respect L) interval two
four candidates region. Finally, two additional regions, namely one
interval consisting candidates left a, b, c, one interval consisting
candidates right a, b, c, d.
Note intervals containing a, b, c, may empty,
set {a, b, c, d} may contain adjacent even identical candidates. easy see
number interesting (i.e., nonempty) regions nine, equal nine
adjacent identical candidates among a, b, c, d. Assuming
462

fiBypassing Combinatorial Protections

case, three possible situations, depending relation intervals
[a, b] [c, d].
1. intervals disjoint:

R1

R2

c

b
R3

R4

R5

R6


R7

R8

R9

2. intervals nonempty intersection, neither contains other:


R1

R2

c

R3

R4

b

R5

R6



R7

3. One interval contains other:

c


R1

R2

R3

R4

R5

R6

R8

R9

b

R7

R8

R9

set {a, b, c, d} contains adjacent identical elements, regions pictured
empty identical, less nine interesting regions.
r interesting regions, denote R1 , . . . , Rr , left right
respect L.
Associate voter candidate top voters preference order.
following observation turns helpful. [a, b] set weakCondorcet winners
(C, V1 ), voters V1 top choice x <L x <L b.
Similarly, voter V2 top choice strictly c d. is, region
consists voters whose top choice lies strictly either b c fully
determined regard question many voters V1 V2 . example,
case [c, d] contained [a, b], five nine regions fully determined:
voters R3 , R4 , R6 , R7 V2 must voters
region R5 , voters would lie b c d.
argument, one see maximum number regions fully determined
7 (in case intervals [a, b] [c, d] disjoint). Clearly, number
ways kV k divided 7 ordered numbers bounded kV k6 .
fact weakCondorcet winners (C, V1 ) (C, V2 ) efficiently checked
due following key observation. Within region, thing affects
winner set number voters put V1 , voters use achieve
number. is, need check partition individually (there
exponential number them), rather deal large number partitions simultaneously. formally, suppose r interesting regions let ` = (`1 , `2 , . . . , `r )
463

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

r-dimensional vector natural numbers. define P` set partitions
(V1 , V2 ) V i, `i number voters V1 whose top choice
Ri .
P` 6= , key observation restated follows. [a, b] set
weakCondorcet winners election (C, V1 ) (V1 , V2 ) P` [a, b]
set weakCondorcet winners every election (C, V1 ) (V1 , V2 ) P` . is,
want check whether [a, b] set weakCondorcet winners primary
elections (C, V1 ) induced partitions (V1 , V2 ) P` , suffices check one
obtain answer. check easily done counting. symmetry,
statement holds [c, d] weakCondorcet winners elections (C, V2 )
(all four combinations).
reason true that, given number voters region, easy
recognize region(s) median voter(s) (just counting). Since a, b, c,
constitute region own, equally easy tell whether median voter
four candidates top choice.
Implementing idea, algorithm loops possible sizes k V1 (line 2)
possibilities k divided r numbers `1 , `2 , . . . , `r , checks (line 8)
gives partition required. argued last paragraphs, query
efficiently answered.
running time Algorithm 2 thus bounded follows. number
iterations loops lines 1, 2, 4, bounded kCk4 , kV k + 1, kV k6 ,
respectively. Moreover, shown queries line 8 answered
polynomial time. Altogether, yields running time obviously polynomial
size input.
Correctness Algorithm 2 clear explanations above: find
partition makes p overall weakCondorcet winner partition
exists. particular, observe setting k = 0 line 2 handles case p
already weakCondorcet winner original election.12 Note algorithms theme
perfectly supports theme paper: algorithm used single-peakedness bypass
combinatorial richness partitions.
completes proof TP, nonunique-winner model. TP, uniquewinner model, line 1 Algorithm 2 needs adapted loop choices
a, b, c, make p unique weakCondorcet winner (C 0 , V ). TE, unique-winner
model dealt Theorem 5.6 page 465. (By Fact 3.1 page 448,
unique weakCondorcet winner tantamount Condorcet winner single-peaked
electorates.)
true TE, nonunique-winner model. Here, weakCondorcet
winner final election suffices, Algorithm 3 (which found appendix)
easily adapted take consideration.
q Theorem 5.2
12. see this, assume p [m` , mr ], [m` , mr ] interval weakCondorcet winners
(C, V ). Observe set a, b, c, [a, b] = C [c, d] = [m` , mr ], C 0 = {e C |
L e L b c L e L d} = C obviously p weakCondorcet winner (C 0 , V ). Thus,
choice a, b, c, considered line 1. setting k 0 uniquely defines ` (0, . . . , 0) P`
consists partition (, V ) only. Due choice a, b, c, d, answer query line 8
yes (, V ) correctly output partition makes p overall winner.

464

fiBypassing Combinatorial Protections

turn weakCondorcet Condorcet elections, state result
quickly give us number additional contrasts general-case control complexity
single-peaked control complexity.
Theorem 5.5. weakCondorcet elections, control adding voters control deleting voters P single-peaked electorates, nonunique-winner model
unique-winner model.
usual, immediately follows result applies standard long
list systems (e.g., Kemeny, Young, weakDodgson elections) weakCondorcetconsistent single-peaked electorates. appendix contains similar results Condorcet
elections. However, winner problem general case trivially many-one polynomialtime reduces control adding voters (via asking p made win adding 0
voters; see Hemaspaandra et al., 2009, Section 2.4). Thus, existing p2 -hardness results
Kemeny winner problem (both nonunique-winner model, Hemaspaandra et al.,
2005, unique-winner model, Hemaspaandra et al., 2009), Young winner
problem (both nonunique-winner model unique-winner model, see
papers Theorem A.2), weakDodgson winner problem (both nonunique-winner
model unique-winner model, see papers Theorem A.4), imply
control adding voters p2 -hard Kemeny, Young, weakDodgson elections
(in nonunique-winner model unique-winner model). comments
hold control deleting voters. Thus single-peaked general cases control
adding deleting voters differ Kemeny, Young, weakDodgson elections.
5.3 Control Results Related Condorcet Elections
Control Condorcet elections studied much detail (Bartholdi et al., 1992;
Hemaspaandra, Hemaspaandra, & Rothe, 2007), (see Table 1 Hemaspaandra et al.,
2007) standard control type known either never change outcome
polynomial-time algorithm, three exceptions. Namely, Bartholdi et al.
(1992) proved seminal paper control, control addition voters control
deletion voters NP-complete Condorcet elections; control partition
voters also NP-complete Condorcet elections (due Bartholdi et al., 1992, nownonstandard partition model, due Faliszewski et al., 2009a, now-standard
partition model).13 However, following results show resistance results vanish
single-peaked electorates.
Theorem 5.6. Condorcet elections, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,
Ties Promote model Ties Eliminate model (note four cases
coincide here).
13. entire Bartholdi, Tovey, Trick paper unique-winner model, discussion unique-winner model. thus need establish contrasting polynomial-time
results unique-winner model want meaningful contrast. address this, ensure
contrasting results hold models. holds trivially prove either model,
Condorcet elections, nonunique-winner unique-winner coincide Ties Promote Ties
Eliminate coincideboth one never two winners.

465

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Theorem 5.7. Condorcet elections, control adding voters control deleting
voters P single-peaked electorates, nonunique-winner model
unique-winner model.
So, standard control cases Condorcet voting known NP-hard
general case (Bartholdi et al., 1992; Faliszewski et al., 2009a), shown
Condorcet-voting control falls polynomial time single-peaked electorates.14

6. Manipulation Single-Peaked Electorates: Dichotomy
Constructive Coalition Weighted Manipulation
Faliszewski et al. (2011) completely characterized, three-candidate elections, scoring protocols polynomial-time constructive coalition weighted manipulation problems
NP-complete constructive coalition weighted manipulation problems.
achieve far sweeping dichotomy theoremour result applies scoring protocols,
regardless number candidates. Scoring protocols arguably important
broad class election systems.
constructive coalition weighted manipulation problem, input candidate
set C, nonmanipulative voters (each preference order C weight),
manipulative voters (each weight), candidate p C, question
whether way setting preferences manipulative voters p
winner given election rule manipulative nonmanipulative voters
vote weighted election.
Theorem 6.1 (Faliszewski et al., 2011). Consider three-candidate scoring protocol,
namely, = (1 , 2 , 3 ), 1 2 3 , 1 N, 2 N, 3 N. single-peaked case,
constructive coalition weighted manipulation problem (in nonunique-winner
model unique-winner model) NP-complete 1 3 > 2(2 3 ) > 0
polynomial time otherwise.
extension three-candidate, single-peaked electorate result case
scoring protocol single-peaked electorates somewhat complicated. Yet, since
complete characterizationa dichotomization complexities, factit
sense simply reflecting subtlety complexity scoring systems. (For general
i.e., necessarily single-peakedcase, known characterization simple regardless
number candidates: NP-completeness holds kCk 2 2 6= kCk
otherwise problem P (Hemaspaandra & Hemaspaandra, 2007, see also Conitzer,
Sandholm, Lang, 2007, Procaccia Rosenschein, 2007.) following theorem
sections soleand spotlightresult.
Theorem 6.2. Consider m-candidate scoring protocol, namely, = (1 , 2 , . . . , )
Nm , 1 2 .
14. sharp-eyed reader may wonder whether concept possible general-case
polynomial-time results control (e.g., Condorcet control deleting candidates) might suddenly,
freakishly get harder single-peaked case. all, Faliszewski et al. (2011) show freakish case
limiting single-peaked case increases manipulation complexity. However, hard
seeby reasoning related used prove Theorem A.5that control type polynomial
time general case single-peaked case remains polynomial time.

466

fiBypassing Combinatorial Protections

2 2 > b m1 c+2 exist integers i, j > 1 + j + 1
2
(1 )(1 j ) > (i i+1 )(j j+1 ), constructive coalition weighted
manipulation problem single-peaked case NP-complete.
2 2 = b m1 c+2 1 > 2 > (2 > m1 1 >
2
2(2 )), constructive coalition weighted manipulation problem
single-peaked case NP-complete.
cases, constructive coalition weighted manipulation problem
single-peaked case P.
example, constructive coalition weighted manipulation single-peaked case
m-candidate plurality m-candidate veto P, m-candidate Borda
P 3 NP-complete otherwise.
Note Theorem 6.1 follows Theorem 6.2, since 1 3 > 2(2 3 ) equivalent
1 2 > 2 3 . also note specific cases more-than-three-candidate
scoring protocolssuch four-candidate Borda m-candidate vetothat analyzed
single-peaked case Faliszewski et al. (2011) yielded results completely consistent
Theorem 6.2s characterization. P cases Theorem 6.2s dichotomy align
theme single-peakedness often foiling combinatorial protections.
Proof Theorem 6.2. first give intuition conditions theorem.
P cases exactly cases optimal manipulator vote. example,
show Lemma 6.6 (1 )(1 j ) (i i+1 )(j j+1 ) i, j > 1
+ j + 1, candidates scoring higher p one side p,
say left, societal order. case optimal manipulators rank
p first, candidates ps right, candidates ps left.
contrast, NP-complete cases exists societal order
construct elections p two main rivals, say b, two different
types optimal votes manipulators different effects scores
b. NP-hardness proofs follow via reductions well-known NP-complete
problem Partition (see, e.g., Garey Johnson, 1979). problem, given
nonempty collection (k1 , . . . , kn ) positive integers sum 2K, ask whether
exists subcollection k1 , . . . , kn sums K. cases carefully
define societal order, weights votes nonmanipulators, weights
manipulators weights manipulators voting one two
optimal vote types successful manipulation correspond partition vice versa.
turn formal proof theorem. 1, problem trivial
thus P. So, assume 2. split proof Theorem 6.2 three lemmas:
2 > b m1 c+2 NP-complete cases (Lemma 6.4), 2 > b m1 c+2 P cases (follow
2
2
Lemma 6.6), 2 = b m1 c+2 cases (Lemma 6.7).
2
proof, use following notation. V collection voters c candidate,
scoreV (c) denotes score c V , i.e., number points c receives
voters V . V clear context, simply write score(c). section,
usually denote collection nonmanipulators collection manipulators
.
First prove following simple lemma.
467

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Lemma 6.3. constructive coalition weighted manipulation problem singlepeaked case scoring protocols, p made winner, p made winner
manipulation manipulators rank p first.
Proof Lemma 6.3. Let > p > b1 > > b` single-peaked vote,
set candidates order. exists ordering
p > > b1 > > b` also single-peaked. Note new vote, every candidate
c, score(p) score(c) decrease. So, p winner election, p still
winner replace every single-peaked vote form > p > b1 > > b`
single-peaked vote form p > > b1 > > b` .
q Lemma 6.3
Lemma 6.4. Let = (1 , 2 , . . . , ) scoring protocol 2 2 >
b m1 c+2 . exist integers i1 , i2 > 1 i1 +i2 m+1 (1 i1 )(1 i2 ) >
2
(i1 i1 +1 )(i2 i2 +1 ), constructive coalition weighted manipulation problem
single-peaked case NP-complete.
Proof Lemma 6.4. Let i1 , i2 integers fulfill conditions lemma
i1 i2 i2 minimal, i.e., 1 < i1 i2 , i1 + i2 + 1, (1 i1 )(1 i2 ) >
(i1 i1 +1 )(i2 i2 +1 ), i01 , i02 1 < i01 i02 < i2 i01 + i02 + 1,
holds (1 i01 )(1 i02 ) (i01 i01 +1 )(i02 i02 +1 ).
reduce Partition constructive coalition weighted manipulation
problem single-peaked electorates. Let (k1 , . . . , kn ) instance Partition, i.e.,
(k1 , . . . , kn ) nonempty collection positive integers sum 2K. Let societys
order
am1 L L a1 L p L b1 L L bm2 ,
m2 = max(d m1
2 e, i2 1) m1 = m2 1. Note i2 m2 + 1. Since
i1 +i2 m+1, follows immediately i1 m1 +1. Also note 1 m1 m2 m2.
make reduction work, also need following claim.
Claim 6.5. m1 +2 < 2 .
Proof Claim 6.5.

m1 = b m1
2 c, immediate, since 2 > b m1 c+2 . not,
2

m2 = i2 1 i2 1 > m1
2 e 2. Since i2 minimal, conditions lemma
fulfilled i1 = i2 = 2, (1 2 ) (2 3 ). 2 = m1 +2 ,
2 = 3 , follows 1 = 2 thus 1 = m1 +2 . choice i1 , i2
fulfill conditions lemma, since 1 i1 = 0.
q Claim 6.5
Let consist two voters, one voter weight `1 preference order
a1 > > ai1 1 > p > b1 >
(the end vote denotes remaining candidates listed arbitrary,
single-peaked order) one voter weight `2 preference order
b1 > > bi2 1 > p > a1 > ,
468

fiBypassing Combinatorial Protections

let weights k1 , k2 , . . . , kn ,
= (1 i1 )(1 i2 ) (i1 i1 +1 )(i2 i2 +1 ),
`1 = ((21 2 m2 +2 )(1 i2 ) + (i2 i2 +1 )(21 2 m1 +2 ))K,
`2 = ((1 i1 )(21 2 m1 +2 ) + (i1 i1 +1 )(21 2 m2 +2 ))K.
values chosen (using Cramers Rule)
(1 i1 )`1 (i2 i2 +1 )`2 = (21 2 m2 +2 )K
(i1 i1 +1 )`1 + (1 i2 )`2 = (21 2 m1 +2 )K.
Note positive, since (1 i1 )(1 i2 ) > (i1 i1 +1 )(i2 i2 +1 ). Note
`1 `2 also positive, since (1 i1 ) (1 i2 ) positive,
(21 2 m1 +2 ) (21 2 m2 +2 ), Claim 6.5 fact m1 m2 .
prove reduction works, first suppose k1 , . . . , kn partition, i.e.,
subcollection k1 , . . . , kn sums K. show p made winner
follows. Let K weight vote
p > a1 > > am1 > b1 >
let K weight vote
p > b1 > > bm2 > a1 > .
Note i, 1 m1 , score(ai ) score(a1 ) i, 1 m2 ,
score(bi ) score(b1 ) suffices show score(a1 ) score(p) score(b1 )
score(p). Note
score(p) = i1 `1 + i2 `2 + 21 K,
score(a1 ) = 1 `1 + i2 +1 `2 + 2 K + m2 +2 K,
score(b1 ) = 1 `2 + i1 +1 `1 + 2 K + m1 +2 K.
choice , `1 , `2 , follows score(a1 ) = score(p) score(b1 ) = score(p).
converse, suppose voters vote p becomes winner
. observations above, follows
scoreT (a1 ) (2 + m2 +2 )K
scoreT (b1 ) (2 + m1 +2 )K.
Lemma 6.3 assume p ranked first every voter . implies
every voter ranks a1 b1 second. Let Wa total weight voters rank
a1 second. follows
scoreT (a1 ) 2 Wa + m2 +2 (2K Wa )
scoreT (b1 ) 2 (2K Wa ) + m1 +2 Wa .
observations, fact > 0 2 > m1 +2 (by Claim 6.5) (and
thus also 2 > m2 +2 ), follows Wa K (2K Wa ) K. So, exactly
half vote weight ranks a1 second. weights voters rank
a1 second correspond partition.
q Lemma 6.4

469

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Lemma 6.6. Let = (1 , 2 , . . . , ) scoring protocol. i, j > 1
+ j + 1, holds
(1 )(1 j ) (i i+1 )(j j+1 ),
constructive coalition weighted manipulation problem single-peaked case
P.
Proof Lemma 6.6. Let am1 L L a1 L p L b1 L L bm2 societys order.
immediate scoreS (ai ) scoreS (p) i, 1 m1 , p made winner
p winner every voter votes
p > a1 > > am1 > b1 > > bm2 .
Similarly, scoreS (bi ) scoreS (p) i, 1 m2 , p made winner
p winner every voter votes
p > b1 > > bm2 > a1 > > am1 .
show cases occur. immediately implies
Lemma 6.6.
So, remainder proof, suppose contradiction collection
voters integers i1 i2 1 i1 m1 , 1 i2 m2 , scoreS (ai1 ) > scoreS (p),
scoreS (bi2 ) > scoreS (p).
1 < m1 +1, let `i total weight voters rank candidate
{a1 , . . . , am1 } first rank p ith place. Note voters rank candidates
{b1 , . . . , bm2 } p. 1 < m2 + 1, let `0i total weight voters
rank candidate {b1 , . . . , bm2 } first rank p ith place. Note
voters rank candidates {a1 , . . . , am1 } p. follows immediately
scoreS (ai1 ) scoreS (p)

X

(1 )`i +

1<im1 +1

scoreS (bi2 ) scoreS (p)

X

X

(i+1 )`0i

1<im2 +1

(1

)`0i

+

1<im2 +1

X

(i+1 )`i .

1<im1 +1

Since scoreS (ai1 ) > scoreS (p) scoreS (bi2 ) > scoreS (p), follows
X

1<im1 +1

X

X

(1 )`i >
(1

1<im2 +1

(i i+1 )`0i

1<im2 +1

)`0i

X

>

(i i+1 )`i .

1<im1 +1

Since sides inequalities nonnegative, follows



X
X

(1 )`i
(1 )`0i >
1<im1 +1

1<im2 +1

470

fiBypassing Combinatorial Protections




X



(i i+1 )`0i

1<im2 +1

(i i+1 )`i .

1<im1 +1

Multiplying out, follows
X
(1 )(1 j )`i `0j >
1<im1 +1
1<jm2 +1


X

X

(i i+1 )(j j+1 )`i `0j .

1<im1 +1
1<jm2 +1

Since = m1 + m2 + 1, contradicts assumption i, j > 1
+ j + 1 holds
(1 )(1 j ) (i i+1 )(j j+1 ).
q Lemma 6.6
Lemma 6.6 handles 2 > b m1 c+2 P cases Theorem 6.2. Note lemma
2
limited use 2 = b m1 c+2 , since case lemma applies = 2 1 = 2 =
2
b m1 c+2 . 2 = b m1 c+2 cases Theorem 6.2 handled following lemma
2
2
combination standard observation scoring protocol (1 , 2 , . . . , )
behavior scoring protocol (1 , 2 , . . . , m1 , 0).
Lemma 6.7. Let = (1 , 2 , . . . , ) scoring protocol 2, = 0,
2 = b m1 c+2 . 2 = 0 1 = 2 (2 = m1 1 22 ) constructive
2
coalition weighted manipulation problem single-peaked case P; otherwise,
NP-complete.
Proof Lemma 6.7. 2 = 0, vote form p > optimal
manipulator vote. 1 = 2 , 1 = b m1 c+2 . Let j i, j > 1
2

m1
+ j + 1. min(i, j) b m+1
2 c = b 2 c + 1 (1 )(1 j ) = 0.
follows Lemma 6.6 case P.
remainder proof, assume 1 > 2 > 0.
consider case 2 = m1 1 22 . Consider societys order. p
leftmost rightmost candidate, exactly one vote puts p first,
optimal manipulator vote. Otherwise, let leftmost candidate societys
order, b rightmost. b candidates occur last
vote. Since 1 22 , follows scoreS (a) + scoreS (b) 2scoreS (p). Without loss
generality, let scoreS (a) scoreS (b). scoreS (a) scoreS (p) vote form
p > > b optimal manipulator vote.
concludes P cases. turn NP-complete cases. cases,
reduce Partition.
First assume 2 = m1 1 > 22 . Let k1 , . . . , kn nonempty
collection positive integers sum 2K. construct following election: Societys
order L p L L b. consists two voters, weight (21 2 )K. One
voter votes > p > > b voter votes b > > p > a. Note
candidates c 6 {a, b}, scoreS (c) = scoreS (p). weights manipulators
(1 22 )k1 , . . . , (1 22 )kn . proof correctness reduction similar

471

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

(but easier than) corresponding proof Lemma 6.4. First suppose exists
subcollection k1 , . . . , kn sums K. set K vote weight p > > > b
K vote weight p > > b > a. Note resulting election,
score(p) = (22 (21 2 ) + 21 (1 22 ))K = (212 222 )K
score(a) = score(b) = (1 (21 2 ) + 2 (1 22 ))K = (212 222 )K.
converse, suppose p made winner. observations above,
immediate
scoreT (a) 2 (1 22 )K scoreT (b) 2 (1 22 )K.
Let Wa total weight voters rank b last. follows
scoreT (a) 2 Wa scoreT (b) (2(1 22 )K Wa )2 .
observations, assumption 2 > 0, follows Wa = (1 22 )K.
So, exactly half vote weight ranks b last. weights voters
rank b last correspond partition.
Finally, handle last case, namely, 1 > 2 > m1 . Let
b smallest index
m1
c
+
2
<

b
<
m.
Take
societys
order
2 >
.
Note

b
b
2
ab m1 c L L a1 L p L b1 L L bd m1 e .
2

2

reducing Partition. Let k1 , . . . , kn nonempty collection positive
integers sum 2K. Let consist two voters, weight (21 2
b )K,
voting
ab m1 c(mm)
b > > a1 > p > b1 > > bd m1 e(mm)
b >
2

2

bd m1 e(mm)
b > > b1 > p > a1 > > ab m1 c(mm)
b >
2

2

let weights (1 2 )k1 , . . . , (1 2 )kn . Since b m1
b =m
b
2 c (m m)
m1
m1
m1
(d m1
e+1)

m(b
b
c+2)
>
0

b
c(m
m)+1+d
b
e(m
m)
b
=
2
mm
b
<
m,
b
2
2
2
2
following scores.
scoreS (p) = 22 (21 2
b )K,
scoreS (ab m1 c(mm)
b )K,
b ) = (1 + 2 )(21 2
2

scoreS (bd m1 e(mm)
b ) = scoreS (ab m1 c(mm)
b ).
2

2

k1 , . . . , kn partition, set (1 2 )K vote weight
p > a1 > > ab m1 c > b1 > > bd m1 e(mm)
b >
2

2

set (1 2 )K vote weight
p > b1 > > bd m1 e > a1 > > ab m1 c(mm)
b > .
2

2

472

fiBypassing Combinatorial Protections

Note ab m1 c(mm)
b bd m1
e(mm)
b candidates score higher
2
2
p
2
2
score(p) = (22 (21 2
b ) + 21 (1 2 ))K = (21 + 21 2 22
b 22 )K.

score(ad m1 e(mm)
b ) = score(bd m1 e(mm)
b )=
2

2

2
2
((1 + 2 )(21 2
b ) + (2 +
b )(1 2 ))K = (21 + 21 2 22
b 22 )K.

So, p winner resulting election.
converse, suppose p made winner. Assume (using Lemma 6.3)
p ranked first every manipulator. observations above, immediate

scoreT (ab m1 c(mm)
b )(1 2 )
b ) (2 +
2

scoreT (bd m1 e(mm)
b )(1 2 ).
b ) (2 +
2

Let Wa total weight voters ab m1 c(mm)
b > bd m1
e(mm)
b .
2
2
follows
scoreT (ab m1 c(mm)
b (2(1 2 )K Wa )
b ) 2 Wa +
2

scoreT (bd m1 e(mm)
b Wa + 2 (2(1 2 )K Wa ).
b )
2

observations, fact 2 > , follows Wa = (1 2 )K.
weights voters ab m1 c(mm)
b > bd m1
e(mm)
b correspond
2
2
partition.
q Lemma 6.7
q

Theorem 6.2

7. Related Work, Additional Discussion, Open Problems
two papers related work Walsh (2007) Faliszewski, Hemaspaandra, Hemaspaandra, Rothe (2011). Walshs paper first raised (among many
interesting issues, possible necessary winners, Konczak & Lang, 2005, singlepeaked settings) issue effect single-peaked electorates manipulation.
particular case looked atweighted coalition manipulation single transferable vote electionshe showed manipulation remains hard even single-peaked electorates. Faliszewski et al. showed cases single-peakedness removes complexity shields
manipulation, also opened study (nonpartition) control. paper
contrast Walshs stresses cases single-peakedness removes combinatorial protections. go beyond Faliszewski et al. (2011) first time studying bribery
single-peaked electorates partition-control single-peaked electorates.
new cases, show many election systems (for example Llull elections)
polynomial-time algorithms single-peaked electorates, even system known
NP-hard analogous general case. also generalize Faliszewski et al. (2011)
473

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

dichotomy theorem manipulation three-candidate scoring protocols case
arbitrary scoring protocols.
Although closely related Faliszewski et al. (2011) present paper,
came present paper, important mention work Faliszewski
et al. (2011b, 2014) explores interesting issue seeing whether results
Faliszewski et al. (2011) still hold even electorate merely near
single-peaked (see also Cornaz et al., 2012; Bredereck et al., 2013; Erdelyi et al., 2013; Sui
et al., 2013, regarding nearness single-peakedness weaker forms single-peakedness).
Since large real-world electorates unlikely (perfectly) single-peaked, natural
important study weaker forms single-peakedness.
Although Walsh (2007) Faliszewski et al. (2011) far related work,
work much worth mentioning. Bartholdi Trick (1986), Doignon Falmagne
(1994), Escoffier et al. (2008) provided efficient algorithms finding single-peaked
orderings. Conitzer (2009) studied effect single-peaked electorates preference
elicitation. Indeed, single-peakedness much current interest computational settings.
example, least four papers IJCAI-2013 conference, including Bredereck
et al. (2013) paper mentioned related single-peakedness.
p2 -completeness winner problems Dodgson, Kemeny, strongYoung
elections established, respectively, Hemaspaandra et al. (1997), Hemaspaandra et al.
(2005), Rothe et al. (2003). literature contains many papers complexity
(when single-peaked preferences assumed) manipulation control (as pointer
those, see Faliszewski et al., 2009b, Faliszewski, Hemaspaandra, & Hemaspaandra, 2010, citations therein), even contains number papers
younger topic complexity bribery (e.g., Faliszewski et al., 2009; Faliszewski, 2008;
Faliszewski et al., 2009a). Although nonunique-winner model unique-winner
model typically complexity results, Faliszewski, Hemaspaandra,
Schnoor (2008, drawing also Conitzer et al., 2007) show always case.
NP-completeness p2 -completeness worst-case notions. natural wonder
whether problems classes solved frequently heuristic algorithms.
much experimental study theme (see, e.g., Walsh, 2009).
hand, known (see Hemaspaandra Williams, 2012) polynomial-time deterministic heuristic algorithm NP-complete (or p2 -complete) problem asymptotically
makes subexponentially many errors, polynomial hierarchy collapses.
worry comes immediate minds social choice theorists expressed
follows: Since known that, single-peaked electorates, median voting leaves voters
voting sincerely optimal strategy, single-peaked elections interesting
terms election systems, since median voting used. detailed discussion
worry would fill paper. briefly mention three reasons
objection serious might first seem. First, nonmanipulability claims
regarding single-peaked elections median voting manipulability, say
nothing about, example, control. Indeed, weakCondorcet effect type
median voting single-peaked electorates, example partition voters
algorithm makes clear control exercised interesting ways.15 Second, even
15. explicit, natural way framing median voting, median voting weakCondorcet (and weakCondorcet-consistent rules) exactly single-peaked electorates.

474

fiBypassing Combinatorial Protections

median voting nice properties, simple truth real world, society
virtually elections electorateshas chosen (perhaps due transparency, comfort,
tradition) use voting systems clash sharply median voting. prominence
plurality voting dramatic case. since real world use
rich range election systems, make sense understand behavior. Third, one
must careful terms strategy-proof. paper people commonly
mention showing median voting strategy-proof Barbera (2001).
papers results social choice functions (election rules kCk 1 always
exactly one winner), notas paper isabout election rules select set
winners. one cannot simply assume case median voting (say, weakCondorcet
elections) never gives incentive misrepresent preferences.
Actually, certain problem settings, one never incentive misrepresent ones
top choice (in single-peaked weakCondorcet elections ones top choice affects
outcome) weakCondorcet elections (which social choice correspondence).
example, ones goal Seek make top choice weakCondorcet winner,
one never incentive misstate ones top choice. another example, ones
goal (for fixed k) Seek make least one first k choices among
weakCondorcet winners, one never incentive misstate ones top
choice (which thing matters ones vote).16 hand,
reasonable problem settings, misstating may make sense. ones goal Make
top choice unique winner failing make second choice unique winner
... failing make last choice unique winner failing make
multiple winners, two-candidate single-peaked election voter 1 votes > b
voter 2 prefers b already gives voter 2 incentive vote, insincerely, > b.
leaving topic, stress previous paragraphs discussions
model manipulators come complete preference orders. However,
Bartholdi et al. (1989) model (which paper complexity papers use
studying manipulation), manipulative coalition blank slate goal
make certain candidate p winner.
open issue already mentioned paper following. Section 6 provided
single-peaked electorates manipulation-complexity dichotomy applies scoring
rules (and see Hemaspaandra & Hemaspaandra, 2007, holds without singlepeaked restriction). Although broad set rules, theorem connecting
specification system systems complexitya natural connection. However,
paper establishes many results regarding bribery control weakCondorcet context
single-peaked electorates.
16. mention passing two incentive manipulate claims made weakCondorcet
elections single-peaked electorates also hold family related election systems single-peaked
electorates. weakCondorcet, sorting voters first choice (under single-peaked ordering
candidates), candidates fall median voter(s) winners. think
MedianVoting 1 , rational , 0 12 , single-peaked voting
2
consider rule, MedianVoting , ordering voters first-choice makes winners
candidates societal order L fall inclusive interval (a) leftmost voter vleft
least kV ke voters first preference vleft left L
vleft , (b) rightmost voter vright least kV ke voters first preference
vright right L vright . rule MedianVoting share incentive
manipulate properties mentioned text.

475

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

also natural wonder whether one tightly link social-choice-favored properties
rule manipulation (or bribery control) complexity. give idea kind
theorem thinking of, mention following known theorem linking social-choiceproperties winner-problem complexity (the statement involves notions
define here): Every election system neutral, Condorcet-consistent, consistent
p2 -complete winner problem (Hemaspaandra et al., 2005, see also discussion
Hemaspaandra Hemaspaandra, 2000). However, just-quoted winner result
something cheat one system satisfies propertiesKemeny
elections. dream case manipulationand bribery controlwould find
broad link social-choice properties complexity single-peaked case
general case. true dream case, might completely characterize terms
statement social-choice properties election systems easy manipulation
(or bribery control) problems, single-peaked case general case.
final open direction find cases partition-of-candidates control shifts
NP-hard polynomial time restricted single-peaked electorates.

8. Conclusions
theme paper single-peaked electorates often tame combinatorial explosion.
saw first case winner problem. case, taming good.
shows single-peaked electorates, election systems Kemeny efficient
winner algorithms, despite p2 -hardness general case. bribery
control (and part, manipulation), saw many cases NP-hard problems fell
polynomial time single-peaked electorates, via algorithms bypassed generalcase combinatorial explosions covers partitions. Since NP-hardness results
protections attacks elections, results serve warning
protections core dependent extreme flexibility voter preference
collections general case allows. single-peaked electorates, protections vanish.

Acknowledgments
work supported part ARC grant DP1101011792, DFG grants BR-2312/{32,6-1}, NSF grants CCF-{0426761,0915792,1101452,1101479} IIS-0713061, European Science Foundations EUROCORES program LogICCC, Friedrich Wilhelm Bessel
Research Awards Edith Hemaspaandra Lane A. Hemaspaandra. work done
part Felix Brandt Ludwig-Maximilians-Universitat Munchen Markus
Brill Ludwig-Maximilians-Universitat Munchen TU Munchen, done
part visits Edith Hemaspaandra Lane A. Hemaspaandra Heinrich-HeineUniversitat Dusseldorf Ludwig-Maximilians-Universitat Munchen. preliminary version paper appeared proceedings 24th AAAI Conference Artificial
Intelligence, July 2010 (Brandt, Brill, Hemaspaandra, & Hemaspaandra, 2010).
grateful Steven Brams, Piotr Faliszewski, Felix Fischer, Zack Fitzsimmons,
Paul Harrenstein, Jerome Lang, Ariel Procaccia, Jorg Rothe, Hans Georg Seedig, Troels
Srensen, anonymous conference journal referees helpful comments
476

fiBypassing Combinatorial Protections

valuable suggestions. grateful Piotr Faliszewski email exchange led
Theorem A.5 Paul Harrenstein preparing figures.

Appendix A. Additional Definitions Proofs
appendix provides additional definitions proofs.
A.1 Additional Definitions
Let us define additional election systems mentioned Section 2.
Nanson elections runoff methods based Bordas scoring protocol. Nansons
(1882) original definition, series Borda elections held candidates
stage average Borda score excluded unless candidates
identical Borda scores, case candidates declared winners
election. exist two variants Nanson due Fishburn Schwartz, exclude
candidates lowest Borda score candidates whose Borda score less
average score, respectively. three versions fail weakCondorcet-consistent (Niou,
1987).
Maximin (a.k.a. Simpson-Kramer) elections (Simpson, 1969; Kramer, 1977) choose
candidates fare best worst pairwise comparison candidate.
remaining three election systems based pairwise majority relation.
Schwartz (1972) elections (sometimes also called top cycle), winners defined
maximal elements asymmetric part transitive closure majority relation. winners Fishburn (1977) elections maximal elements Fishburn
relation F , defined letting F b every candidate beats pairwise
comparison also beats b exists candidate beats b a.
A.2 Proofs Section 2
Theorem A.1. Kemeny, Schwartz, Fishburns Schwartzs versions Nanson
weakCondorcet-consistent single-peaked electorates.
Proof. statements rely observation pairwise majority relation, >m ,
single-peaked electorates transitive (Black, 1948, 1958). observe weak
Condorcet winners precisely maximal elements pairwise majority relation.
follows immediately Schwartz weakCondorcet-consistent.
P case Kemeny, note (again writing >m pairwise majority relation)
{a,b}C,a6=b,am b k{v V | v prefers b a}k lower bound Kemeny score
linear order. score realized linear order > > consistent >m ,
i.e., every a, b C, >m b > b. pairwise majority relation transitive
c weak Condorcet winner, c Kemeny winner, evidenced following
Kemeny consensus: rank c first greedily keep adding, successive positions
consensus, maximal (with respect >m ) unranked candidates. Since > consistent
>m , > Kemeny consensus. immediate weak Condorcet
winner, ranked first linear order consistent >m .
Nanson, prove weak Condorcet winner eliminated stage
election. First let us normalize Borda scores subtracting (kV k (m 1))/2
477

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Borda score every candidate. ensures average normalized Borda score
precisely zero. Now, observe normalized Borda score candidate simply half
sum, candidates b, number voters prefer b minus
number voters prefer b a. consequence, normalized Borda score every
weak Condorcet winner least zero. Moreover, case single-peaked electorate,
due transitivity majority relation, always candidate negative
normalized Borda score unless candidates identical score zero. latter
case, three versions Nanson terminate. former case, neither Fishburns
Schwartzs variant exclude weak Condorcet winners score least
large average score.
q
fact Black, Dodgson, original version Nanson, Copeland elections
[0, 1) weakCondorcet-consistent single-peaked electorates seen
following universal counterexample. Let two voters preferences b > > c
c > b > a. preferences single-peaked respect societal ordering
L b L c. Candidates b c weak Condorcet winners, mentioned
election systems chooses b. Similarly, strongYoung weakCondorcet-consistent
single-peaked electorates election two voters whose preferences
> b > c c > b > a, candidates weak Condorcet winners, strongYoung
yields candidates c.
A.3 Additional Proofs Section 3
Theorem A.2. winner problem Young elections p2 -complete,
nonunique-winner model unique-winner model.
Proof. p2 -completeness (nonunique) winner problem strongYoung elections
(somewhat confusingly called Young elections there) shown Rothe et al. (2003).
proof also establishes p2 -completeness unique winner model (Hemaspaandra
et al., 2009). p2 upper bound easy show, argument used
show p2 upper bound Young winner problem (in nonunique-winner
model unique-winner model). p2 -hardness winner problem strongYoung
elections shown Theorem 2.5 Rothe et al. (2003) via reduction p2 complete problem Maximum Set Packing Compare (MSPC, short): Given two sets, B1
B2 , two collections sets S1 S2 , Si nonempty, finite
subset Bi , case (S1 ) (S2 )? Here, (Si ) denotes maximum number
pairwise disjoint sets Si . Rothe et al., assume (Si ) > 2.
proofs Theorems 2.3 2.5 Rothe et al. (2003) show construct
given MSPC instance = (B1 , B2 , S1 , S2 ) election (D, W ) two designated
candidates, c d, (a) (S1 ) (S2 ) c strongYoung winners
(D, W ), (b) (S2 ) > (S1 ) unique strongYoung winner (D, W ).
show proof adapted work Young elections. Please
refer Rothe et al. (2003) definitions details construction,
point differences here. Given MSPC instance = (B1 , B2 , S1 , S2 ), construct
478

fiBypassing Combinatorial Protections

election (C 0 , V 0 ) c designated candidates C 0 , holds
YoungScore(C 0 , c, V 0 ) = 2 (S1 ) YoungScore(C 0 , d, V 0 ) = 2 (S2 ).17
Let C 0 = C V 0 = V {v(2.4) , v(2.7) }, (C, V ) election constructed
proof Theorem 2.3 Rothe et al. (2003), v(2.4) one two voters V
referred voters form (2.4) Rothe et al. v(2.7) one two voters
V referred voters form (2.7) Rothe et al.18 One define
submultiset V0 voters V 0 V0 = V {v(2.4) }, V defined page 381
Rothe et al. kV0 k = 2 (S1 ) c weak Condorcet winner (C 0 , V0 ),
implying YoungScore(C 0 , c, V 0 ) 2 (S1 ).
show YoungScore(C 0 , c, V 0 ) 2 (S1 ), adapt Lemma 2.4 Rothe et al.
(2003) following way. (The proof Lemma A.3 similar proof Lemma 2.4
Rothe et al., 2003, omit here.)
Lemma A.3. 3 < kS1 k + 1, let V submultiset V 0 V
contains exactly 1 voters form (2.4) (2.5) c weak Condorcet winner
(C 0 , V 0 ). V contains exactly 1 voters form (2.3) voters form
(2.6), (2.7), (2.8). Moreover, 1 voters form (2.3) V represent pairwise
disjoint sets S1 .
Let V0 V 0 kV0 k 2 (S1 ) c weak Condorcet winner
Suppose exactly 1 voters form (2.4) (2.5) V0 . Since
(S1 ) > 2, follows kV0 k 6, thus > 3 order beat c. Also,
1 kS1 k, since exactly kS1 k voters form (2.4) (2.5) V 0 . Lemma A.3
implies exactly 1 voters form (2.3) V0 , voters represent
pairwise disjoint sets S1 , V0 contains voters form (2.6), (2.7), (2.8).
Hence, kV0 k = 2 ( 1) 2 (S1 ).
thus YoungScore(C 0 , c, V 0 ) = 2 (S1 ). Analogously, one show
YoungScore(C 0 , d, V 0 ) = 2 (S2 ). Thus
(C 0 , V0 ).

(S1 ) (S2 )



YoungScore(C 0 , c, V 0 ) YoungScore(C 0 , d, V 0 ),

proves p2 -hardness comparing Young scores. show winner problem
Young elections p2 -hard, alter election (C 0 , V 0 ) way (C, V )
17. Note proof, follow Rothe et al.s (2003) convention Young scores define
YoungScore(C, c, V ) candidate c election (C, V ) size maximal submultiset
voters c weak Condorcet winner. Hence, set Young winners consists candidates
whose YoungScore least large YoungScore candidate.
18. completeness, give definition (C 0 , V 0 ). C 0 = B1 B2 {a, b, c, d} V 0 consists


following voters. (For ordered set = {m1 , . . . , mk }, write m1 > > mk .)




(2.3) E S1 , one voter preference order E > > c > B1 E > B2 > b > d.




(2.4) One voter preference order c > B1 > > B2 > b > d.




(2.5) kS1 k 1 voters preference order B1 > c > > B2 > b > d.




(2.6) F S2 , one voter vF preference order F > b > > B2 F > B1 > > c.




(2.7) One voter preference order > B2 > b > B1 > > c.




(2.8) kS2 k 1 voters preference order B2 > > b > B1 > > c.

479

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

altered Theorem 2.5 Rothe et al. (2003). Let (D0 , W 0 ) altered election.19 One
show Young scores c (D0 , W 0 ) (C 0 , V 0 ),
candidates Young score (D0 , W 0 ) 2. Thus, since
Young scores c least 6, comparing Young scores c (D0 , W 0 )
tantamount deciding c Young winner.
Altogether, (a) (S1 ) (S2 ) c Young winner (D0 , W 0 ),
(b) (S2 ) > (S1 ) unique Young winner (D0 , W 0 ). follows
MSPC-instance MSPC c Young winner (D0 , W 0 ), implying
p2 -hardness Young winner problem nonunique-winner model. uniquewinner model, follow argument proof Theorem 2.3 Hemaspaandra
et al. (2009): Observe MSPC unique winner
(D0 , W 0 ). Thus complement unique-winner problem Young elections p2 hard. Since p2 closed complement, proves unique-winner problem
Young elections p2 -hard well.
q
Theorem A.4. winner problem weakDodgson elections p2 -complete,
nonunique-winner model unique-winner model.
Proof. p2 -completeness (nonunique) winner problem Dodgson elections
shown Hemaspaandra et al. (1997). proof also establishes p2 -completeness
unique winner model (Hemaspaandra et al., 2009). p2 upper bound easy
show, argument used show p2 upper bound weakDodgson
winner problem (in nonunique-winner model unique-winner model). p2 hardness winner problem Dodgson shown reduction p2 -hard
problem Two Election Ranking (2ER, short) (Hemaspaandra et al., 1997): Given two
Dodgson triples (C, c, V ) (D, d, W ), kV k kW k odd c 6= d,
Dodgson score c (C, V ) less equal Dodgson score (D, W )?
Here, Dodgson triple (C, c, V ) election (C, V ) designated candidate c C.
reduction 2ER winner problem Dodgson elections works merging
elections E1 = (C, V ) E2 = (D, W ) new election E3 = (C 0 , V 0 )
C C 0 following properties satisfied:
(i) Dodgson-ScoreE3 (c) = Dodgson-ScoreE1 (c) + 1,
(ii) Dodgson-ScoreE3 (d) = Dodgson-ScoreE1 (d) + 1,
(iii) Dodgson-ScoreE3 (x) > Dodgson-ScoreE3 (c) x C 0 {c, d}.
Here, Dodgson-ScoreE (x) denotes minimal number switches required make candidate x Condorcet winner election E. Thus, immediately c Dodgson
winner E3 Dodgson-ScoreE1 (c) Dodgson-ScoreE2 (d).20
19. completeness, (D0 , W 0 ) defined follows. replace every candidate g C 0 {c, d} kV 0 k
0
candidates g 0 , . . . , g kV k1 . replace occurrence candidate g ith voter V 0
0
0
0
0
g mod kV k > g (i+1) mod kV k > > g (i+kV k1) mod kV k .
20. noted fixable problem construction Hemaspaandra et al. (1997). problem
page 822 end proof Lemma 3.7, proving Dodgson-ScoreE3 (dkDk1 ) >

480

fiBypassing Combinatorial Protections

show approach Hemaspaandra et al. (1997) adapted
work weakDodgson. First, observe problem Weak Two Election Ranking
(w2ER), defined like 2ER except Dodgson score replaced weakDodgson
score, inherits p2 -hardness 2ER Dodgson scores weakDodgson scores
coincide instances odd number voters. (If number voters odd,
weak Condorcet winner tantamount Condorcet winner, since
ties pairwise comparisons.) Also observe, inspection p2 -hardness proof
Hemaspaandra et al. (1997), 2ER w2ER still p2 -hard restrict
Dodgson-ScoreE3 (c), claimed argument applies candidate (C D)\{c, d}.
Though claim clearly true candidate D{d}, true candidate C {c},
since preference orders voter groups (b) (c), candidates C {c} separated
candidates set separating candidates. consequence, may possible make
candidate C {c} Condorcet winner less kSk/2 switches voter groups.
problem avoided changing t1 < < tkT k < c < s1 < < skSk < c1 < <
ckCk1 prefix preference orders voters groups (b) (c) c < t1 < < tkT k <
c1 < < ckCk1 < s1 < < skSk . gives following set voters. (In footnote use
< b < c-notation specifying votes, rather c > b > a-notation used throughout rest
paper, order match approach expressing votes used Hemaspaandra et al., 1997.
make comparisons paper straightforward possible.)
(a) voter e1 < < ekCk V , voter < s1 < < skSk < d1 < < dkDk1 < t1 < <
tkT k < e1 < < ekCk .
(b) voter e1 < < ekDk W , voter c < t1 < < tkT k < c1 < < ckCk1 < s1 < <
skSk < e1 < < ekDk .
l
l

k
(c) kV2 k kW
voters c < t1 < < tkT k < c1 < < ckCk1 < s1 < < skSk < d1 < <
2
dkDk1 < d.
l

(d) kV2 k voters t1 < < tkT k < c1 < < ckCk1 < d1 < < dkDk1 < skSk < < s1 < c < d.
l

k
(e) kW
voters t1 < < tkT k < c1 < < ckCk1 < d1 < < dkDk1 < s1 < < skSk < < c.
2
Intuitively, changed construction symmetrical original one, preferences
voter groups (a) (b) defined analogously, roles C (and )
interchanged.
Using proof Lemma 3.7 Hemaspaandra et al. (1997), easy see three
properties mentioned hold. particular, c preferred half
voters, Dodgson score c change. every candidate d0 D, d0 occur
prefix preference order changed Dodgson score d0 change.
remains show Dodgson-ScoreE3 (x) > Dodgson-ScoreE3 (c) x (C {c}).
proof Lemma 3.7, know Dodgson-ScoreE3 (c) < kSk/2 kSk = kT k. order
become Condorcet winner, needs gain least one vote d. Note changed
preferences, need kSk switches switch beyond d, change preferences
lower Dodgson score kSk/2. order become Condorcet winner,
shown Hemaspaandra et al. needs gain least one vote c need
kSk/2 switches that. Since preferred c voters groups (b) (c)
original changed election, voters used gain vote c. follows
changed election, needs kSk/2 switches become Condorcet winner. Finally, let
c0 C {c}. argument Hemaspaandra et al. every d0 {d} needs gain least
one vote c order become Condorcet winner, need kSk/2 switches
used (by symmetry construction) show every c0 C {c} needs gain
least one vote order become Condorcet winner, need kSk/2
switches that.

481

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

problem Dodgson triples least three voters. Let w2ER0 thus-restricted
version w2ER.
reduction w2ER0 winner problem weakDodgson elections.
Given two Dodgson triples (C, c, V ) (D, d, W ), denote corresponding elections
E1 = (C, V ) E2 = (D, W ). convenience, denote v = kV k w = kW k. Recall
v w odd least three assume without loss generality
C = v w. Define = v kCk + w kDk observe strict
upper bound weakDodgson
E1 E2 : Even worst case (a candidate
scores

least preferred voters), v2 (kCk 1) < switches suffice
make candidate

weak Condorcet winner E1 (by making top choice v2 voters), analogous
statement holds E2 .
define new election E3 = (C 0 , V 0 ). set C 0 candidates E3 defined
C 0 = C U , C candidates elections E1 E2
= {s1 , . . . , sm }, = {t1 , . . . , tm }, U = {u1 , . . . , um } 3m new candidates.
order define voters E3 , introduce following abbreviations notational convenience. (ordered) set = {m1 , . . . , mk }, > > b shorthand
> mk > > m1 > b. Furthermore, let c1 , . . . , ckCk1 d1 , . . . , dkDk1 arbitrary
enumerations C = C {c} = {d}, respectively. voters V 0 E3 consist
following subgroups:
(a) every voter E1 preference order Ci C, one voter preference order
Ci > > > > > U.
(b) every voter E2 preference order Dj D, one voter preference order
Dj > > C > > c > U.

(c) v2 w2 voters preference order
> > > C > > c > U.
(d)

v
2

voters preference order
> c > U > > > C > T.

(e)

w
2

1 voters preference order
c > > U > > > C > T.

(f) one voter preference order
> > C > > c > > U.
Since v odd, total number voters kV 0 k = 2v + w + 1. v w odd,
kV 0 k even weak Condorcet winner preferred every candidate

0
least kV2 k = v + w2 voters. show following three properties
satisfied:
482

fiBypassing Combinatorial Protections

(i) weakDodgson-ScoreE3 (c) = weakDodgson-ScoreE1 (c),
(ii) weakDodgson-ScoreE3 (d) = weakDodgson-ScoreE1 (d),
(iii) weakDodgson-ScoreE3 (x) > weakDodgson-ScoreE3 (c) x C 0 {c, d}.
0

(i), observe c preferred every candidate C 0 C least kV2 k
voters. Thus, computing weakDodgson score c, take care
candidates C = {c1 , . . . , ckCk1 }. Let xi number voters group
(a)
prefer c ci . number voters V 0 prefer c ci xi + v2 + w2 1.
Candidate c weak Condorcet winner E3 number greater


0
equal kV2 k = v + w2 , case xi v2
{1, . . . , kCk 1}. means c Condorcet winner E1 . definition,
achieved k switches, k = weakDodgson-ScoreE1 (c). thus
shown upper bound weakDodgson-ScoreE3 (c) weakDodgson-ScoreE1 (c). assume
weakDodgson-ScoreE3 (c) < weakDodgson-ScoreE1 (c). Due construction,
switches optimal sequence occur voters group (a), making c beat
candidate C would require switches relevant voter groups
(b), (c), (f). means way make c weak Condorcet winner E1
less weakDodgson-ScoreE1 (c) switches, contradiction. thereby shown
weakDodgson-ScoreE3 (c) = weakDodgson-ScoreE1 (c). proof property (ii)
analogous.
(iii), recall chosen sufficiently large strict upper bound
weakDodgson-ScoreE1 (c) thus, (i), weakDodgson-ScoreE3 (c). show
candidates C 0 c weakDodgson score least E3 .
Consider candidate S. order become weak Condorcet winner, must
v
beat
contest. preferred
c w + 2
particular

v tie
c pairwise

w
w
0 , needs gain least v extra votes c voter
+
1
=
+
voters

V
2
2
2
2
groups (a), (d), (e). gaining one extra vote c would require
switches, separated c least candidates voter
groups.

similar argument applies candidates: Candidates need w2 extra
votes (b), (c), (d), (e), one extra
vote requires switches

v
voters. Candidates U need 2 extra votes di (a), (b), (c),
(f), one extra vote requires switches. Candidates need v2
extra votes c (a), (d),
(e), one extra vote requires switches.
w
Candidates C need 2 extra votes (b), (c), (d), (e), one extra vote
requires switches. Thus, shown weakDodgson-ScoreE3 (x) > >
weakDodgson-ScoreE3 (c) x C 0 {c, d}.
easy see (1) weakDodgson-ScoreE1 (c) weakDodgson-ScoreE2 (d),
c weakDodgson winner E3 , (2) weakDodgson-ScoreE1 (c) >
weakDodgson-ScoreE2 (d), unique weakDodgson winner E3 . Let =
((C, c, V ), (D, d, W )) instance w2ER0 . argued w2ER0
c weakDodgson winner E3 , immediately implies p2 -hardness
weakDodgson winner problem nonunique-winner model. unique-winner
model, follow argument proof Theorem 2.3 Hemaspaandra et al.
483

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

(2009): Observe w2ER0 unique weakDodgson winner
E3 . Thus complement unique-winner problem weakDodgson elections
p2 -hard. Since p2 closed complement, proves unique-winner problem
weakDodgson elections also p2 -hard.
q

A.4 Additional Proofs Section 4
Theorem 4.3. following hold (see Footnote 9):
1. Approval-negative-bribery approval-strongnegative-bribery NP-complete.
2. single-peaked electorates, approval-negative-bribery approval-strongnegativebribery P.
Proof. polynomial-time algorithms witnessing P-membership approval-negativebribery approval-strongnegative-bribery flavor algorithm
approval-bribery (Theorem 4.2), present first.
Let (C, V ) instance single-peaked approval election L valid single-peaked
ordering candidates. decide whether designated candidate p C
made winner bribing k voters. proof Theorem 4.2, define Vc
multiset voters approve candidate c. V+ = Vp multiset voters
approving p V = V V+ multiset voters disapproving p.
Approval-strongnegative-bribery like approval-bribery, except bribed voters
bribe allowed approve p. Consequently, bribing voter approves p
always pointless bribe voters V . Also, without loss
generality assume bribed voters disapprove candidates bribe,
clearly best possible action regard goal make p winner. algorithm
similar one presented proof Theorem 4.2. Define surplus n(c)
candidate c C {p} n(c) = kVc k kVp k consider rightmost candidate c0
right p positive surplus. order make p winner, obviously
bribe least n(c0 ) voters Vc0 V . definition, candidates right c0
nonpositive surplus, whyin deciding n(c0 ) voters Vc0 V
bribewe solely focus candidates left c0 choose n(c0 ) voters
Vc0 V whose approval range extends furthest left. mentioned above,
bribe voters disapprove everyone, thereby making n(c0 ) = 0. recalculate
surpluses candidates left c0 (note candidates surplus never grows
thus ignore candidates right c0 ) repeat process
rightmost candidate right p positive surplus.
time candidates right p nonpositive surplus,
mirror societal order L repeat procedure nonpositive-surplus candidates originally left p respect L. make surpluses
nonpositive without exceeding bribe limit k, found successful bribery action. Otherwise, successful bribery action exist, decisions (concerning
voters bribe) provably optimal.
case approval-negative-bribery, bribed candidates may approve p
bribe approved p bribe. model, sometimes make sense
484

fiBypassing Combinatorial Protections

bribe voters V+ . pose problem, following observation
shows. approval score p remains unchanged every optimal bribe. Here, optimal
bribe defined either bribing voter V+ disapprove everyone except p,
bribing voter V disapprove everyone. Again, case strongnegativebribery, without loss generality assume bribes optimal. Thus,
observation tells us differentiate bribing voters V+
V , cases thing care removal approvals
candidates p. Hence, algorithm strongnegative bribery,
except considering positive-surplus candidate c deciding voters
Vc bribe, consider voters disapprove p also voters
approve p.
go show bribery problems NP-complete general (i.e.,
necessarily single-peaked) case. Membership NP obvious problems.
hardness proof approval-strongnegative-bribery adaptation proof
approval-bribery NP-hard (Faliszewski et al., 2009, Thm. 4.2). Please refer
proof point differences. reduction NP-hard problem
Exact Cover 3-sets (X3C), define bribery instance Theorem 4.2 Faliszewski
et al. (2009), except number voters approve
p changed
instead m. exists cover kAk = iA Si = B, bribe
vi approve zero candidates (this slight additional change).
candidates tie approvals win. Looking direction, exists
successful bribe voters, since p approvals 3t candidates
B + 1 approvals, bribe increase number approvals p (in
negative strongnegative bribery setting), clearly p still approvals
bribes. So, 3t candidates B (that started + 1 approvals)
must lost exactly one approval (if lost one approval, one would
lost zero approvals would beat p; lost zero approvals, would beat p). So,
exact cover 3-sets.
Due construction, one use proof show NP-hardness approvalnegative-bribery: voters approving p voters approve p obviously never bribed.
q
Theorem 4.4. single-peaked electorates, weakCondorcet-weighted-$bribery, weakCondorcet-negative-weighted-bribery, weakCondorcet-negative-weighted-$bribery
NP-complete, remaining five cases (weakCondorcet-bribery, weakCondorcet$bribery, weakCondorcet-weighted-bribery, weakCondorcet-negative-bribery, weakCondorcetnegative-$bribery) P.
Proof. general setting eight bribery problems describe
here. Let (C, V ) election instance let L linear order candidates
electorate single-peaked respect L. question whether
designated candidate p C made weakCondorcet winner bribing k
voters.
p weakCondorcet winner election (C, V ), successful bribery action obviously possible bribe voter. thus focus case p
485

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

weakCondorcet winner (C, V ). case, definition weakCondorcet
implies p contained median interval (i.e., p
/ [m` , mr ]L , m`
mr top choices median voters). Assume without loss generality p lies
strictly right median interval, i.e., mr L p (otherwise, mirror
societal order L).
Identify voter preferred candidate. Define V` = {v V | v L p}
multiset voters lying left p respect L Vr = V V` = {v
V | v = p p L v} multiset voters lying p right p. settings
voters weights, mr L p immediately implies
l kV` k >m kVr k that,
rk
order make p weakCondorcet winner, need bribe kV` kkV
voters V`
2
make p top choice (or, negative-bribery settings, make candidate
right
p
top choice). voters weights, shift total weight least
l
w(V` )w(Vr )
, w(V 0 ) submultiset V 0 V voters defined natural way
2
P
sum weights voters contained V 0 , i.e., w(V 0 ) = vV 0 w(v).
Observe eight bribery problems easily seen NP. prove
assertions Theorem 4.4 order mentioned statement
theorem.
(i) weakCondorcet-weighted-$bribery NP-complete.
Define k weight needs shifted V` p, i.e.,


w(V` ) w(Vr )
k =
.
2
problem weakCondorcet-weighted-$bribery stated follows.
given collection objects (voters), positive integer weight
positive integer price, bounds k k, question whether exists
subset whose price k whose weight least k. so, bribe
first-choose p. holds (or p initially wins), succeed, else fail.
straightforward show NP-hard problem Knapsack (see, e.g., Garey
& Johnson, 1979) reduces directly problem, establishing NP-hardness
weakCondorcet-weighted-$bribery.
(ii) weakCondorcet-negative-weighted-bribery NP-complete.
give reduction NP-complete problem Partition (see proof
Theorem 6.2). Given collection (k1 , k2 , . . . , kn ) positive integers sum
2K, define single-peaked election (C, V ) C = {a, p, c}, L p L c,
ki one voter vi whose first choice whose weight ki . Set
budget k equal n. easy see p win via negative bribery
(k1 , k2 , . . . , kn ) partitioned two equal-sum parts.
(iii) weakCondorcet-negative-weighted-$bribery NP-complete.
follows (ii).
(iv) weakCondorcet-bribery P.
486

fiBypassing Combinatorial Protections

algorithm easy: Bribe k voters chosen arbitrarily V` make p top
choice. If, bribe, p weakCondorcet winner, successful. Otherwise,
successful bribery action exists.
(v) weakCondorcet-$bribery P.
algorithm (iv), except bribe voters order
price tags, starting cheapest voter.
(vi) weakCondorcet-weighted-bribery P.
algorithm (iv), except bribe voters order
weights, starting voter highest weight.
(vii) weakCondorcet-negative-bribery P.
follows (viii).
(viii) weakCondorcet-negative-$bribery P.
Recall p lies strictly right median interval. case negative
bribery, bribed voters must p top choice. Thus, p never made
weakCondorcet winner either (a) voter p first choice kV k
odd, (b) p right end societal order L. (Since p lies strictly
right median interval, p cannot left end L.)
Otherwise, let p candidate right p respect L. Successful
bribery possible if, greedily bribing voters V` (starting
cheapest voter) p top choice, make p weakCondorcet winner.
q
final comment, note easy see problems solved
pseudo-polynomial time dynamic programming, NP-completeness results
strengthened strong NP-completeness unless P = NP.
A.5 Additional Proofs Section 5
Let one 22 control types defined Faliszewski et al. (2009a), i.e., eleven
types (adding/deleting candidates/voters (4 types); unlimited-adding candidates (1
type); three partition types TP TE (6 types)), constructive cases (making c win uniquely win) destructive cases (making c win
unique winner). Let E election system. following holds
unique-winner model nonunique-winner model. (Recall Section 5.1
speak control problem single-peaked, mean single-peakedness
holds even including potentially added candidates voters.)
Theorem A.5. control problem E P single-peaked electorates
default model (in societal order L part input) control
problem E P single-peaked electorates exists-L model (in ask
exists order L relative input single-peaked
goal achieved type control action).
487

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Proof. Note control problem instance L0 L00 valid
societal orders relative instance (and crucial notion
instancenot voters/candidates left endmust respect order
valid), set successful (resp., unsuccessful) control actions L0
exactly L00 . Thus, following key observation:
(?) exists valid single-peaked order relative control problem instance successfully controlled control problem instance
successfully controlled every valid single-peaked order.
So, control problem P model L part input via algorithm A,
exists-L model, given instance compute valid L (e.g., using
algorithm Escoffier et al., 2008) hand A. (?) correctness A,
know gives correct answer.
direction, control problem P exists-L model, thanks
(?), simply strip L input model L part input
safely (knowing answer correct original issue) ask existential question
hypothetical P algorithm exists-L version.
q
particular instances Theorem A.5 argued directly particular cases E
Faliszewski et al. (2011), Theorem A.5 provides tool removes need
case-specific arguments.
Theorem 5.5. weakCondorcet elections, control adding voters control deleting voters P single-peaked electorates, nonunique-winner model
unique-winner model.
Proof. give algorithms nonunique-winner model. unique-winner
model, see proof Theorem 5.7 (by Fact 3.1 page 448, unique weakCondorcet
winner tantamount Condorcet winner single-peaked electorates).
Associate voter preferred candidate. goal make p
weakCondorcet winner, i.e., want end one following two situations:
1. kV k odd median voter p top choice.
2. kV k even p lies (inclusive) interval [m` , mr ]L , m` mr
median voters. (This includes case m` = mr .) following,
refer [m` , mr ]L median interval.
easy algorithm case control addition voters: See
current median (or median interval) is. p median (or p lies median interval),
done. Otherwise, assume without loss generality median (interval) lies
left p. add unregistered voters whose top choice either p candidate
right p p weakCondorcet winner hit addition bound
added unregistered voters sort. point succeeded,
success impossible.
algorithm control-by-deletion-of-voters case similar: See current
median (or median interval) is. p median (or p lies median interval),
488

fiBypassing Combinatorial Protections

done. Otherwise, need shift location median voter(s) towards p. Without
loss generality assume median (interval) lies left p. start
deleting voters left end L make p weakCondorcet winner hit
deletion bound without success.
q
Theorem 5.6. Condorcet elections, control partition voters P singlepeaked electorates, nonunique-winner model unique-winner model,
Ties Promote model Ties Eliminate model (note four cases
coincide here).
Proof. Let (C, V ) instance Condorcet election let L linear order
respect electorate single-peaked. Without loss generality assume kCk 2
(otherwise, problem trivial). Furthermore, p C designated candidate
question whether exists partition (V1 , V2 ) p Condorcet winner
overall election. clear case exists partition
(V1 , V2 ) p Condorcet winner (C, V1 ) (C, V2 ) Condorcet winner,
Condorcet winner p beats pairwise comparison, p Condorcet winner.
show Algorithm 3 returns partition property whenever one exists.
Algorithm 3 loops candidates c p beats pairwise comparison
possible sizes V1 (line 2). set C candidates divided five regions
R1 , R2 , . . . , R5 defined follows. Without loss generality assume p <L c,
i.e., c lies right p respect societal order L (otherwise, mirror
everything). Region R1 consists candidates left p, i.e., R1 = {x C | x <L p},
region R2 consists p only. Similarly, R5 consists candidates right c
R4 consists c only. Finally, R3 consists remaining candidates, namely,
candidates lie p c respect L. Note regions except R2
R4 may empty. following picture:
p
R1

R2

c
R3

R4

R5

Associate voter candidate top voters preference order.
define P` , set partitions V respect regions defined. Let
` = (`1 , `2 , . . . , `5 ) five-dimensional vector natural numbers. Define P` set
partitions (V1 , V2 ) V property that, i, `i number voters
V1 whose top choice Ri .
P` 6= , key observation following: x {p, c} holds x
Condorcet winner election (C, V1 ) (V1 , V2 ) P` x Condorcet
winner every election (C, V1 ) (V1 , V2 ) P` . is, want check whether x
Condorcet winner primary elections (C, V1 ) induced partitions
(V1 , V2 ) P` , suffices check one obtain answer. symmetry,
statement holds Condorcet winners elections (C, V2 ).
reason true that, given number voters region,
easy compute region(s) median voter(s) (just counting). Since p
489

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Algorithm 3 Condorcet Control Partition Voters
1: candidates c lose p pairwise comparison
2:
k {1, 2, . . . , kV k}
P
3:
` = (`1 , `2 , . . . , `5 ) N5 5i=1 `i = k
4:
define P` set partitions (V1 , V2 ) V i, `i
number voters V1 whose top choice Ri
5:
P` 6=
6:
let (V1 , V2 ) arbitrary partition P`
7:
p Condorcet winner (C, V1 )
8:
either c p Condorcet winner (C, V2 )
9:
return (V1 , V2 )
10:
else (V1 , V2 ) P` : (C, V2 ) Condorcet winner
11:
return (V1 , V2 )
12: return partition makes p overall Condorcet winner

c constitute region own, equally easy tell whether Condorcet
winners (using Fact 3.1).
shown queries lines 7 8 Algorithm 3 efficiently
answered. go show query line 10 efficiently answered,
i.e., given `, partition (V1 , V2 ) P` (C, V2 ) Condorcet winner.
Clearly, cannot happen odd number voters V2 . assume kV2 k
even let m1 m2 median voters. region Ri , know number
V2 -voters whose top choice Ri (this number kRi k `i ). Thus know
regions median voters fall (again counting). Now, least one m1 m2 fall
R2 R4 (i.e., p c), (C, V2 ) cannot possibly Condorcet winner
p c (there may Condorcet winners). three cases, partition
action successful21 return arbitrary partition P` .
remaining cases m1 m2 fall R1 R3 R5 . m1
m2 fall different regions, obviously Condorcet winner done.
Assume, therefore, m1 m2 fall Ri {1, 3, 5}. goal assign
qi = kRi k `i voters top choice Ri V2 way median pair
V2 fall candidate. Let median pair rth (r + 1)st
V2 -voter Ri . Here, r (1 r qi 1) known (by numbers V2 -voters left
right Ri ) count left right respect societal order L.
try accomplish goal brute force, namely, pair candidates (d` , dr )
Ri d` <L dr , let us try ensure rth V2 -voter Ri left falls
left d` (r + 1)st falls right dr .
k{x V | x falls Ri x L d` }k r k{x V | x falls Ri dr L x}k qi r.
cost check O(kCk2 ), pair candidates Ri , easy
counting.
Summing up, running time Algorithm 3 bounded follows. number
iterations loops lines 1, 2, 3, bounded kCk, kV k, kV k5 , respectively.
cost one iteration inner loop clearly dominated cost answering
21. fact, either p c Condorcet winner (C, V2 ), would already detected line 8.

490

fiBypassing Combinatorial Protections

query line 10. cost bounded O(kCk2 ), argued last paragraph.
Altogether, yields running time obviously polynomial size input.
Correctness Algorithm 3 clear explanations above,
argued find partition makes p overall Condorcet winner
partition exists. particular, observe never need consider cases
k = 0 p never Condorcet winner (C, ). case p already
Condorcet winner original election (C, V ) handled setting k kV k line 2
(and c arbitrary candidate C {p} line 1).
q
Theorem 5.7. Condorcet elections, control adding voters control deleting
voters P single-peaked electorates, nonunique-winner model
unique-winner model.
Proof. Associate voter preferred candidate. goal
make p Condorcet winner, i.e., want end situation p
preferred candidate median voter(s).
easy algorithm case control addition voters: See
current median (or median pair) is. p, done. Otherwise, add unregistered
voters whose top choice p added succeed hit
addition bound. succeed hit addition bound, done (with without
success). yet hit addition bound, move follows. p strictly
two median voters point, success impossible. one two distinct
median voters (without loss generality say rightmost two median voters)
median interval contain p (without loss generality say interval lies
left p), add unregistered voters right p make p Condorcet
winner hit addition bound added unregistered voters
sort. point succeeded, success impossible.
algorithm control-by-deletion-of-voters case similar: See current
median (or median pair) is. p, done. Otherwise, need shift location
median voter(s) towards p. Without loss generality assume median (or
median interval) lies left p. start deleting voters left end L
make p Condorcet winner hit deletion bound without success. Note p
initially lies two median voters, never made Condorcet winner
deleting voters.
q

References
Barbera, S. (2001). introduction strategy-proof social choice functions. Social Choice
Welfare, 18 (4), 619653.
Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice Welfare, 8 (4), 341354.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989). computational difficulty manipulating election. Social Choice Welfare, 6 (3), 227241.
491

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Bartholdi, III, J., Tovey, C., & Trick, M. (1992). hard control election?
Mathematical Computer Modeling, 16 (8/9), 2740.
Bartholdi, III, J., & Trick, M. (1986). Stable matching preferences derived
psychological model. Operations Research Letters, 5 (4), 165169.
Black, D. (1948). rationale group decision-making. Journal Political Economy,
56 (1), 2334.
Black, D. (1958). Theory Committees Elections. Cambridge University Press.
Booth, K., & Lueker, G. (1976). Testing consecutive ones property, interval graphs,
graph planarity using PQ-tree algorithms. Journal Computer System
Sciences, 13 (3), 335379.
Brandt, F., Brill, M., Hemaspaandra, E., & Hemaspaandra, L. (2010). Bypassing combinatorial protections: Polynomial-time algorithms single-peaked electorates. Proceedings 24th AAAI Conference Artificial Intelligence, pp. 715722. AAAI
Press.
Bredereck, R., Chen, J., & Woeginger, G. (2013). nicely structured preference
profiles nearby? Proceedings 23rd International Joint Conference Artificial
Intelligence, pp. 6268. AAAI Press.
Condorcet, J. (1785). Essai sur lApplication de LAnalyse la Probabilite des Decisions
Rendues la Pluralite des Voix. Facsimile reprint original published Paris, 1972,
Imprimerie Royale.
Conitzer, V. (2009). Eliciting single-peaked preferences using comparison queries. Journal
Artificial Intelligence Research, 35, 161191.
Conitzer, V., Sandholm, T., & Lang, J. (2007). elections candidates
hard manipulate? Journal ACM, 54 (3), Article 14.
Copeland, A. (1951). reasonable social welfare function. Mimeographed notes
Seminar Applications Mathematics Social Sciences, University Michigan.
Cornaz, D., Galand, L., & Spanjaard, O. (2012). Bounded single-peaked width proportional representation. Proceedings 20th European Conference Artificial
Intelligence, pp. 270275. IOS Press.
Cornaz, D., Galand, L., & Spanjaard, O. (2013). Kemeny elections bounded singlepeaked single-crossing width. Proceedings 23rd International Joint Conference Artificial Intelligence, pp. 7682. AAAI Press.
Davis, O., Hinich, M., & Ordeshook, P. (1970). expository development mathematical model electoral process. American Political Science Review, 54 (2),
426448.
Dodgson, C. (1876). method taking votes two issues. Pamphlet printed
Clarendon Press, Oxford, headed yet published.
Doignon, J., & Falmagne, J. (1994). polynomial time algorithm unidimensional unfolding representations. Journal Algorithms, 16 (2), 218233.
492

fiBypassing Combinatorial Protections

Duggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness shared
beliefs: GibbardSatterthwaite generalized. Social Choice Welfare, 17 (1), 8593.
Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methods
web. Proceedings 10th International World Wide Web Conference, pp.
613622. ACM Press.
Ephrati, E., & Rosenschein, J. (1997). heuristic technique multi-agent planning.
Annals Mathematics Artificial Intelligence, 20 (14), 1367.
Erdelyi, G., Lackner, M., & Pfandler, A. (2013). Computational aspects nearly singlepeaked electorates. Proceedings 27th AAAI Conference Artificial Intelligence, pp. 283289.
Erdelyi, G., Nowak, M., & Rothe, J. (2009). Sincere-strategy preference-based approval
voting fully resists constructive control broadly resists destructive control. Mathematical Logic Quarterly, 55 (4), 425443.
Erdelyi, G., Piras, L., & Rothe, J. (2011). complexity voter partition Bucklin
fallback voting: Solving three open problems. Proceedings 10th International Conference Autonomous Agents Multiagent Systems, pp. 837844.
International Foundation Autonomous Agents Multiagent Systems.
Erdelyi, G., & Rothe, J. (2010). Control complexity fallback voting. Proceedings
16th Australasian Theory Symposium, pp. 3948. Australian Computer Society.
Escoffier, B., Lang, J., & Ozturk, M. (2008). Single-peaked consistency complexity.
Proceedings 18th European Conference Artificial Intelligence, pp. 366370.
IOS Press.
Faliszewski, P. (2008). Nonuniform bribery. Proceedings 7th International Conference Autonomous Agents Multiagent Systems, pp. 15691572. International
Foundation Autonomous Agents Multiagent Systems.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2009). complexity bribery
elections. Journal Artificial Intelligence Research, 35, 485532.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2010). Using complexity protect
elections. Communications ACM, 53 (11), 7482.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011a). complexity manipulative attacks nearly single-peaked electorates. Tech. rep. arXiv:1105.5032 [cs.GT],
Computing Research Repository, arXiv.org/corr/. Revised, July 2012.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2011b). complexity manipulative attacks nearly single-peaked electorates. Proceedings 13th Conference Theoretical Aspects Rationality Knowledge, pp. 228237. ACM Digital
Library.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2013). Weighted electoral control. Proceedings 12th International Conference Autonomous Agents
Multiagent Systems, pp. 367374. International Foundation Autonomous Agents
Multiagent Systems.
493

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2014). complexity manipulative attacks nearly single-peaked electorates. Artificial Intelligence, 207, 6999.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009a). Llull
Copeland voting computationally resist bribery constructive control. Journal
Artificial Intelligence Research, 35, 275341.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009b). richer understanding complexity election systems. Ravi, S., & Shukla, S. (Eds.), Fundamental Problems Computing: Essays Honor Professor Daniel J. Rosenkrantz,
pp. 375406. Springer.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2011). shield
never was: Societies single-peaked preferences open manipulation
control. Information Computation, 209, 89107.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter.
Proceedings 7th International Conference Autonomous Agents Multiagent Systems, pp. 983990. International Foundation Autonomous Agents
Multiagent Systems.
Fishburn, P. (1977). Condorcet social choice functions. SIAM Journal Applied Mathematics, 33 (3), 469489.
Friedgut, E., Kalai, G., Keller, N., & Nisan, N. (2011). quantitative version
Gibbard-Satterthwaite Theorem three alternatives. SIAM Journal Computing,
40 (3), 934952.
Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections manipulated often. Proceedings 49th IEEE Symposium Foundations Computer Science, pp. 243249.
IEEE Computer Society Press.
Fulkerson, D., & Gross, G. (1965). Incidence matrices interval graphs. Pacific Journal
Mathematics, 15 (5), 835855.
Garey, M., & Johnson, D. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman.
Ghosh, S., Mundhe, M., Hernandez, K., & Sen, S. (1999). Voting movies: anatomy
recommender systems. Proceedings 3rd Annual Conference Autonomous
Agents, pp. 434435. ACM Press.
Gibbard, A. (1973). Manipulation voting schemes. Econometrica, 41 (4), 587601.
Hagele, G., & Pukelsheim, F. (2001). electoral writings Ramon Llull. Studia Lulliana,
41 (97), 338.
Hemachandra, L. (1989). strong exponential hierarchy collapses. Journal Computer
System Sciences, 39 (3), 299322.
Hemaspaandra, E., & Hemaspaandra, L. (2000). Computational politics: Electoral systems.
Proceedings 25th International Symposium Mathematical Foundations
Computer Science, pp. 6483. Springer-Verlag Lecture Notes Computer Science
#1893.
494

fiBypassing Combinatorial Protections

Hemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy voting systems. Journal
Computer System Sciences, 73 (1), 7383.
Hemaspaandra, E., Hemaspaandra, L., & Menton, C. (2013). Search versus decision
election manipulation problems. Proceedings 30th Annual Symposium
Theoretical Aspects Computer Science, pp. 377388. Leibniz International Proceedings Informatics (LIPIcs).
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (1997). Exact analysis Dodgson
elections: Lewis Carrolls 1876 voting system complete parallel access NP.
Journal ACM, 44 (6), 806825.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone him: complexity
precluding alternative. Artificial Intelligence, 171 (56), 255285.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Hybrid elections broaden
complexity-theoretic resistance control. Mathematical Logic Quarterly, 55 (4), 397
424.
Hemaspaandra, E., Spakowski, H., & Vogel, J. (2005). complexity Kemeny elections.
Theoretical Computer Science, 349 (3), 382391.
Hemaspaandra, L., & Williams, R. (2012). atypical survey typical-case heuristic
algorithms. SIGACT News, 43 (4), 7189.
Kemeny, J. (1959). Mathematics without numbers. Ddalus, 88 (4), 571591.
Kemeny, J., & Snell, L. (1960). Mathematical Models Social Sciences. Ginn.
Konczak, K., & Lang, J. (2005). Voting procedures incomplete preferences. Proceedings Multidisciplinary IJCAI-05 Workshop Advances Preference Handling,
pp. 124129.
Kramer, G. (1977). dynamical model political equilibrium. Journal Economic
Theory, 16 (2), 310334.
Krehbiel, K. (1998). Pivotal Politics: Theory U.S. Lawmaking. University Chicago
Press.
McCabe-Dansted, J., Pritchard, G., & Slinko, A. (2008). Approximability Dodgsons
rule. Social Choice Welfare, 31 (2), 311330.
Menton, C. (2013). Normalized range voting broadly resists control. Theory Computing
Systems, 53 (4), 507531.
Nanson, E. (1882). Methods election. Transactions Proceedings Royal Society
Victoria, 19, 197240. Available 2009 facsimile reprint Kessinger Publishing.
Niemi, R., & Wright, J. (1987). Voting cycles structure individual preferences.
Social Choice Welfare, 4 (3), 173183.
Niou, E. (1987). note Nansons Rule. Public Choice, 54 (2), 191193.
Papadimitriou, C., & Zachos, S. (1983). Two remarks power counting. Proceedings 6th GI Conference Theoretical Computer Science, pp. 269276.
Springer-Verlag Lecture Notes Computer Science #145.
495

fiBrandt, Brill, Hemaspaandra, & Hemaspaandra

Pennock, D., Horvitz, E., & Giles, C. (2000). Social choice theory recommender systems:
Analysis axiomatic foundations collaborative filtering. Proceedings
17th National Conference Artificial Intelligence, pp. 729734. AAAI Press.
Procaccia, A., & Rosenschein, J. (2007). Junta distributions average-case complexity
manipulating elections. Journal Artificial Intelligence Research, 28, 157181.
Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity winner problem
Young elections. Theory Computing Systems, 36 (4), 375386.
Satterthwaite, M. (1975). Strategy-proofness Arrows conditions: Existence correspondence theorems voting procedures social welfare functions. Journal
Economic Theory, 10 (2), 187217.
Schwartz, T. (1972). Rationality myth maximum. Nous, 6 (2), 97117.
Simpson, P. (1969). defining areas voter choice: Professor Tullock stable voting.
Quarterly Journal Economics, 83 (3), 478490.
Sui, X., Boutilier, C., & Sandholm, T. (2013). Analysis optimization multidimensional percentile mechanisms. Proceedings 23rd International Joint
Conference Artificial Intelligence, pp. 367374. AAAI Press.
Walsh, T. (2007). Uncertainty preference elicitation aggregation. Proceedings
22nd AAAI Conference Artificial Intelligence, pp. 38. AAAI Press.
Walsh, T. (2009). really hard manipulation problems? phase transition
manipulating veto rule. Proceedings 21st International Joint Conference
Artificial Intelligence, pp. 324329. AAAI Press.
Young, H. (1977). Extending Condorcets rule. Journal Economic Theory, 16 (2), 335
353.

496

fiJournal Artificial Intelligence Research 53 (2015) 271-314

Submitted 12/14; published 07/15

Model Theory XPath Data Trees.
Part I: Bisimulation Characterization
Diego Figueira

diego.figueira@labri.fr

CNRS, LaBRI, France

Santiago Figueira

santiago@dc.uba.ar

Universidad de Buenos Aires CONICET, Argentina

Carlos Areces

carlos.areces@gmail.com

Universidad Nacional de Cordoba CONICET, Argentina

Abstract
investigate model theoretic properties XPath data (in)equality tests
class data trees, i.e., class trees node contains label finite
alphabet data value infinite domain.
provide notions (bi)simulations XPath logics containing child, parent,
ancestor descendant axes navigate tree. show notions precisely characterize equivalence relation associated logic. study formula
complexity measures consisting number nested axes nested subformulas
formula; notions akin notion quantifier rank first-order logic. show
characterization results fine grained notions equivalence (bi)simulation take
account complexity measures. also prove positive fragments
logics correspond formulas preserved (non-symmetric) simulations. show
logic including child axis equivalent fragment first-order logic
invariant corresponding notion bisimulation. upward navigation allowed
characterization fails weaker result still established. results hold
class possibly infinite data trees class finite data trees.
Besides intrinsic theoretical value, argue bisimulations useful tools
prove (non)expressivity results logics studied here, substantiate claim
examples.

1. Introduction
study expressive power model theory XPatharguably widely used
XML query language. Indeed, XPath implemented XSLT XQuery used
constituent part many specification update languages. XPath is, fundamentally,
general purpose language addressing, searching, matching pieces XML
document. open standard constitutes World Wide Web Consortium (W3C)
Recommendation (Clark & DeRose, 1999).
Core-XPath (term coined Gottlob, Koch, & Pichler, 2005) fragment XPath
1.0 containing navigational behavior XPath. express properties underlying tree structure XML document, label (tag name) node,
cannot express conditions actual data contained attributes. words,
allows reasoning trees finite alphabet. Core-XPath well studied
satisfiability problem known decidable even presence Document
c
2015
AI Access Foundation. rights reserved.

fiFigueira, Figueira, & Areces

Type Definitions (DTDs) (Marx, 2004; Benedikt, Fan, & Geerts, 2008). Moreover,
known equivalent FO2 (first-order logic two variables) appropriate
signature trees terms expressive power (Marx & de Rijke, 2005),
strictly less expressive PDL converse trees (Benedikt & Koch, 2008).
database perspective, however, Core-XPath fails include single important
construct query language: join. Without ability relate nodes based
actual data values attributes, logics expressive power inappropriate many
applications.
extension Core-XPath (in)equality tests attributes elements
XML document named Core-Data-XPath work Bojanczyk, Muscholl,
Schwentick, Segoufin (2009). Here, call logic XPath= . Models XPath=
data trees seen XML documents. data tree tree whose nodes
contains label finite alphabet data value infinite domain (see Figure 1
example). relax condition finiteness consider also infinite data
trees, although results hold also finite structures.
main characteristic XPath= allow formulas form h = i,
, path expressions, navigate tree using axes: descendant, child, ancestor,
next-sibling, etc., make tests intermediate nodes. formula true
node x data tree nodes y, z reached relations denoted
, , respectively, data value equal data value z.
Recent articles investigate several algorithmic problems logics evaluated data
trees. example, satisfiability evaluation discussed works Figueira
(2010) Bojanczyk Parys (2011). particular, logics studied article
decidable satisfiability problem (Figueira & Segoufin, 2011; Figueira, 2012); tools
investigate expressive power still lacking. good reasons this:
presence joins data values, classical notions Ehrenfeucht-Frasse games
structural bisimulations difficult handle. article take first steps
towards understanding expressive power model theory XPath= data trees.
article focus basic model theory tool bisimulations, defines
structural conditions necessary ensuring two models coincide properties
expressible logic. Whereas basic notion bisimulation introduced
basic modal logic, one find adequate notions bisimulations different logics,
sense capture notion indistiguishability logic. challenge
find adequate notions bisimulation logics XPath, whose navigation akin
modal logics PDL, also test equality data values data
tree.
Contribution: XPath= navigate data tree means axes like child (that
note ), descendant ( ), parent (), ancestor ( ), etc. XPath= also navigate
data tree horizontally, going next previous sibling current node. However,
focus vertical axes allow downward upward exploration. particular,
discuss following languages: XPath= () (XPath= ); XPath= () (XPath=
); XPath= ( ) (XPath= ); XPath= ( ) (XPath= ,
, ); positive fragments. main contributions summarized
follows:
272

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

3 introduce bisimulation notions XPath= (), XPath= ( ), XPath= ( ),
XPath= (), XPath= ( ) show precisely characterize logical
equivalence relation corresponding logic. also consider fine grained versions
bisimulations indexed two measures formula complexity. first
measure formula complexity consists maximum number nested axes
formula, call downward depth case XPath= () vertical depth
case XPath= (). second one number nested subformulas, called
nesting depth.
notion bisimulation XPath= () relies normal form also
introduce. Basically, normal form restricts navigation expressions
simple: either going downward going upward downward. Similar
normal forms langauges trees folklore, work consists mainly
adapting setup tests data values.
also show simulations associated defined bisimulations characterize
positive fragments logics: formula equivalent positive formula
invariant simulations.
4 characterize XPath= () fragment first-order logic data trees
(over signature includes child relation equivalence relation)
invariant bisimulations. consider XPath= () instead characterization fails show counter-example. However, weaker result still
established, namely first-order formula bisimulation-invariant, bisimulation notion corresponding fixed number nested axes, equivalent
XPath= () formula.
Using bisimulations show (non)expressivity results XPath= 5.
show, example, formulas XPath= () nesting depth n+1 downward
depth expressive power nesting downward depth n
respectively, long n < d.
results proved class arbitrary (possibly infinite) data trees,
class finite data trees.
1.1 Related Work
notion bisimulation introduced independently van Benthem (1976)
context modal correspondence theory, Milner (1980) Park (1981) concurrency
theory, Forti Honsell (1983) non-wellfounded set theory (for historical
outlook see work Sangiorgi, 2009). classical work defines standard notion
bisimulation notion suitably adapted particular, given logic.
notion bisimulation given logic L defines two models indistinguishable
L, is, formula L true one model false
other. XPath known closely connected known modal languages,
PDL modal -calculus, depending fragments taken account (ten Cate,
Fontaine, & Litak, 2010). However, fragments studied hitherto data unaware,
is, allowing express structure model well fixed set labels.
273

fiFigueira, Figueira, & Areces

best knowledge present first work bisimulations invariance
logics data tests.
Bisimulations also used obtain model theoretic characterizations identifies
expressive power logic L1 terms bisimulation invariant fragment
logic L2 which, hopefully, better understood. challenge, here, pinpoint
appropriate notion bisimulation required adequate framework logic L2 .
classical example result kind Van Benthems characterization
basic modal logic bisimulation (with standard notion bisimulation) invariant
fragment first-order logic (van Benthem, 1976). Van Benthems original result
arbitrary structures proved hold finite structures Rosen (1997). proof
simplified unified Otto (2004a, 2006), later expanded Dawar Otto
(2009) classes structures. formalisms different expressive power
also considered querying data trees, first-order logic two variables
(Bojanczyk et al., 2009), tree patterns (David, 2008; Figueira & Libkin, 2014), register
automata (Neven, Schwentick, & Vianu, 2004), -calculus registers (Jurdzinski &
Lazic, 2011), datalog programs (Abiteboul, Bourhis, Muscholl, & Wu, 2013).
absence data values, logics semi-structured databases often seen modal
logics. fact, structural characterizations XPath without equality test studied
work Gyssens, Paredaens, Gucht, Fletcher (2006), XPath known
captured PDL (Harel, 1984), whose bisimulation well-understood (Blackburn, de Rijke,
& Venema, 2001). natural look intuitive bisimulation definition
XPath= .
first significant result concerning algorithmic solution bisimulation problem basic modal logic given Hopcroft (1971), polynomial time algorithm state minimization deterministic finite automaton. problem equivalent
determine coarsest partition set stable respect finite set functions. Paige Tarjan (1987) solved problem general case,
restriction stability concerns finite set relations. Kanellakis Smolka (1990)
first recognize algorithm Paige Tarjan used determine
maximum bisimulation basic modal logic arbitrary graph. Hence
decided polynomial time whether two nodes finite models bisimilar basic
modal logic though length actual formulas distinguish two non-bisimilar
nodes cannot polynomially bounded respect size models (Figueira &
Gorn, 2010). case, deciding whether two nodes finite data trees bisimilar
also solved polynomial time.
preliminary version present paper appeared work Figueira, Figueira,
Areces (2014). Also, continuation (a Part II): work Abriola, Descotte,
Figueira (2015), preliminary version Abriola, Descotte, Figueira (2014),
address model theoretical questions definability separation,
bisimulation notions pairs nodes (instead single nodes) capture idea
indistinguishability means path expressions (instead node expressions).
274

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

2. Preliminaries
Let N = {1, 2, 3, . . . } let [n] = {1, . . . , n} n N. use symbol denote
finite alphabet, denote infinite domain (e.g., N) data values.
examples consider = N. write empty string.
Let Trees(A) set ordered unranked trees arbitrary alphabet A.
say data tree tree Trees(A D) finite set labels
infinite set data values. Figure 1 shows example (finite) data tree.

x


a, 2

a, 2

b, 2

b, 9

z b, 5

b, 3

a, 2

b, 1

b, 2

Figure 1: data tree Trees(AD) = {a, b} = N.
data tree finitely branching every node finitely many children.
given data tree , denote set nodes. use letters x, y, z, v, w variables
nodes. Given node x , write label (x) denote nodes label,
data(x) denote nodes data value.
n
Given two nodes x, write xy child x, xy descendant
1
0
x distance n. particular, , identity relation.

n
write xy denote (x, y) reflexive transitive closure . (x) denotes
n
set descendants x distance n, (y) denotes sole ancestor
distance n (assuming one).
Let P property nodes data trees. property P true node u data
tree , say (T , u) satisfies P . binary relation R nodes data trees,
say property P R-invariant whenever following condition holds: every
data tree u , (T , u) satisfies P (T , u) R-related (T 0 , u0 ) (T 0 , u0 )
satisfies P .
introduce query language XPath adapted data trees abstractions XML
documents. work simplification XPath, stripped syntactic sugar.
consider fragments XPath correspond navigational part XPath 1.0 data
equality inequality. XPath= two-sorted language, path expressions (that
write , , ) node expressions (that write , , ). fragment XPath= (O),
{, , , }, defined mutual recursion follows:
, ::= | | | []
, ::= | | | | hi | h = | h 6=

{}

aA

formula XPath= (O) either node expression path expression.
formally define semantics XPath= follows, data tree:
275

fiFigueira, Figueira, & Areces

[[]]T = {(x, y) | xy}

[[ ]]T = reflexive transitive closure [[]]T
[[]]T = {(x, y) | yx}

[[ ]]T = reflexive transitive closure [[]]T
[[]]T = {(x, x) | x }

[[]]T = {(x, z) | (y ) (x, y) [[]]T , (y, z) [[]]T }

[[ ]]T = [[]]T [[]]T

[[[]]]T = {(x, x) | x [[]]T }

[[a]]T = {x | label (x) = a}

[[]]T = \ [[]]T

[[ ]]T = [[]]T [[]]T

[[hi]]T = {x | (y ) (x, y) [[]]T }

[[h = i]]T = {x | (y,z )(x, y) [[]]T , (x, z) [[]]T , data(y) = data(z)}
[[h 6= i]]T = {x | (y,z )(x, y) [[]]T , (x, z) [[]]T , data(y) 6= data(z)}
example, data tree shown Figure 1,
[[h [ b h[b] 6= [b]i ]i]]T = {x, y, z},

formula reads: descendant node labeled b, two children labeled b
different data values.
data tree u , say , u pointed data tree, write
, u |= denote u [[]]T , say , u satisfies . say node
expressions , XPath= equivalent (notation: ) iff [[]]T = [[]]T data
trees . Similarly, path expressions , XPath= equivalent (notation: ) iff
[[]]T = [[]]T data trees .
fragment downward XPath denoted XPath= () vertical XPath
denoted XPath= ().
terms expressive power, easy see unessential: every XPath= node
expression equivalent 0 path expressions. 0 computed
exponential time without incrementing maximum number nested axes
maximum number nested subformulas. enough use following equivalences
eliminate occurrences
h fi h fi

h( 0 ) 0 h 0 h0 0

h fi ( 0 ) 0 h fi 0 h fi 0 0
fi {=, 6=}. henceforth assume formulas contain union path
expressions. sequel see situations also expressions form
[] sometimes avoided (3.2.1), although downward axes
(Lemma 10).
276

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

2.1 Translating First-Order Logic
section show truth-preserving translation XPath= ()
first-order logic appropriate signature. so, first must interpret data trees
relational structures, standard way: using binary child
relation, equivalence relation testing data equality, monadic relations test
labels. Fix signature binary relations
, unary predicate Pa
A. data tree seen first-order -structure




PaT

= {(x, y) 2 | child x};

= {(x, y) 2 | data(x) = data(y)};
= {x | label (x) = a}.

give translation XPath first-order logic . tranlsation
function indexed free variables formula produced one node expressions,
two path expressions.
(a A)

Trx (a) = Pa (x)
Trx ( ) = Trx () Trx ()

( {, })

Trx () = Trx ()

Trx (hi) = (y)Trx,y ()


Trx (h = i) = (y)(z) z Trx,y () Trx,z ()

Trx (h 6= i) = (y)(z) 6 z Trx,y () Trx,z ()

(y new variable)
(y, z new variables)
(y, z new variables)

Trx,y () = (x = y)

Trx,y () = (x

y)

Trx,y () = (y

x)


Trx,y () = (z) Trx,z () Trz,y ()

(z new variable)

Trx,y ( ) = Trx,y () Trx,y ()
Trx,y ([]) = Trx () (x = y).

Proposition 1.
1. XPath= () node expression, u [[]]T iff |= Trx ()(u).
2. XPath= () path expression, (u, v) [[]]T iff |= Trx,y ()(u, v).
Proof. proof structural induction .
FO(), let qr() quantifier rank, i.e., depth nesting quantifiers.
Observe fi {=, 6=}
qr(Trx (hi)) = 1 + qr(Trx ())
qr(Trx (h fi i)) = 2 + max(qr(Trx ()), qr(Trx ()))

qr(Trx,y ()) = 1 + max(qr(Trx,y ()), qr(Trx,y ()))
qr(Trx,y ([])) = qr(Trx ()).
277

fiFigueira, Figueira, & Areces

3. Bisimulation
section define notions bisimulation downward vertical fragments
XPath, show coincide corresponding logical equivalence relation.
case vertical XPath bisimulation notion relies normal form
introduce purpose.
3.1 Downward XPath
write dd() denote downward depth defined follows:
dd(a)
dd( )
dd()
dd(hi)
dd(h fi i)

=
=
=
=
=

0
dd() =
max{dd(), dd()}
dd() =
dd()
dd([]) =
dd()
dd() =
max{dd(), dd()}

0
dd()
max{dd(), dd()}
1 + dd()

A, fi {=, 6=}, path expression empty string . Let
`-XPath= () fragment XPath= () consisting formulas dd() `.
Let 0 data trees, let u , u0 0 . say , u 0 , u0
equivalent XPath= () (notation: , u 0 , u0 ) iff node expression
XPath= (), , u |= iff 0 , u0 |= . say , u 0 , u0 `-equivalent
XPath= () (notation: , u ` 0 , u0 ) iff node expression `-XPath= (),
, u |= iff 0 , u0 |= .1
first show that, every `, finitely many different formulas
dd() ` logical equivalence. Formally, usually referred saying `
finite index.
Proposition 2. ` finite index.
Proof. easily shown induction node expression `-XPath= ()
unnecessary uses (recall ) qr(Trx ()) bounded.
well-known result first order finitely many nonequivalent formulas
bounded quantifier rank. Hence finitely many nonequivalent node expressions
bounded downward depth.
Corollary 3. {T 0 , u0 | , u ` 0 , u0 } definable node expression `,T ,u `XPath= ().
Proof. Consider conjunction `-XPath= () formulas , u |= .
Proposition 2, logical equivalence, finitely many s, hence
conjunction equivalent finite one. Define `,T ,u finite conjunction.
1. Two pointed data trees equivalent indistinguishable formulas given logic.
adopted terminology literature, used first word, second.
reader confuse notion equivalent formulas.

278

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

3.1.1 Bisimulation `-bisimulation
Let 0 two data-trees. say u u0 0 bisimilar
XPath= () (notation: , u 0 , u0 ) relation Z 0 uZu0
x x0 0
Harmony: xZx0 label (x) = label (x0 ).
n



n



Zig: xZx0 , xv xw v 0 , w0 0 x0 v 0 , x0 w0
1. data(v) = data(w) data(v 0 ) = data(w0 ),




2. (v) Z (v 0 ) 0 < n,




3. (w) Z (w0 ) 0 < m.

following picture illustrates intended requirements.


x

x

T0

0

Z
n


9v 0

n

=

)

8w

(6=

(6=

)

=

8v

9w0



n



Zag: xZx0 , x0 v 0 x0 w0 v, w xv, xw
items 1, 2 3 verified.
bisimulation generalizes classical bisimulation relation (Sangiorgi, 2009),
Zig simply: xZx0 , xv, v 0 x0 v 0 vZv 0 (the Zag
symmetrical). fact, restrict Zig condition n = = 1 v = w,
Zag condition n = = 1 v 0 = w0 , obtain relation corresponds,
precisely, classical bisimulation relation. Thus, bisimilar notion
define implies bisimlar classical notion.
example, dotted lines following two data trees represent bisimulation
XPath= ().
$#

x

a, 1

y1

a, 2 a, 2

y2

x0

a, 1

a, 2

y0

v a, 1 a, 3 w

w0a, 3 a, 1 v 0



T0

279

fiFigueira, Figueira, & Areces

notion bisimulation seen, usual, Ehrenfeucht-Frasse game,
Spoiler tries find difference (through logics glasses) nodes u u0 ,
Duplicator tries copy him, showing u u0 indistinguishable. gain intuition
notion bisimulation, briefly explain associated game (without going
technical details). board consists data trees 0 ,
two pebbles p p0 , along game, p always node ,
p0 always node 0 . Initially, p u, p0 u0 . u u0
satisfy label Spoiler declared winner game finishes. game
proceeds rounds. Suppose round, pebbles p p0 positions x
x0 satisfying label. round consists one move Spoiler, followed
answer Duplicator, final decision made spoiler.
Step 1. Spoilers first move: chooses pebble, two integers n m, two
paths, one length length n. paths start x chose p
x0 chose p0 . Suppose chose p (the case p0 analogous data

tree 0 instead ). first path represented w xw,
n
second path represented v xv.
Step 2. Duplicators answer: shows two paths 0 (or case duplicator
chosen p0 instead p), one length length n, starting
x0 , data(u) = data(v) iff data(u0 ) = data(v 0 ). paths,
Spoiler declared winner game finishes.
Step 3. Final move Spoiler: chooses




either {0 . . . n 1}, places pebble p (v) pebble p0 (v 0 )




{0 . . . 1}, places pebble p (w) pebble p0 (w0 )

pebbles two nodes satisfy label, game proceeds.
Else, Spoiler declared winner game finishes.
Duplicator wins spoiler never declared winner game infinitely many rounds.
resemblance game rules Harmony, Zig Zag evident. One see
spoiler winning strategy game whose initial pebbles placed x x0
, u 0 , u0 .
interesting compare game one capturing bisimulation
basic modal logic. latter, Spoiler chooses successor x (or x0 ) following
accessibility relation. also case Core-XPath PDL. case,
adding comparison data values, Spoiler choose whole path (in fact, two paths),
making game less local one basic modal logic (or Core-XPath PDL).
analogous view game XPath= () would allow Spoiler build paths
step-by-step fashion, is, extending paths constructed far new single
node, thus giving Duplicator less certainty. possible change rules game
second step round Spoiler builds paths step-by-step fashion?
No. Even Spoiler freedom extend step-by-step one paths,
would unfair Duplicator. Indeed, consider last example bisimilar , x
0 , x0 . Spoiler would initially declare first path x0 length 0,
280

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

Duplicator define first path x length 0. Spoiler construct,
step-by-step, second path. Initially shows path x0 0 Duplicator. Duplicator
two possible answers: either path xy1 xy2 . Suppose chooses xy1 (the
case xy2 analogous). Spoiler extends path x0 0 x0 0 w0 . Since y1
one child, Spoiler one possible answer extending path: xy1 v.
Next, Spoiler declares done: constructed two paths starting x0 , one
length 0 one x0 0 w0 , length 2. Duplicator constructed one
path length 0 xy1 v. Duplicator looses, data(x0 ) 6= data(w0 )
data(x) = data(v). example shows game fairness established spoiler
tells duplicator advance two paths chooses.
data tree u , let |u denote subtree induced {v |
n
(n) uv}. Observe root |u u. following results straightforward
consequences definition bisimulation:
Observation 4. , u (T |u), u.
Observation 5. subtree 0 u , u 0 , u.
say u u0 0 `-bisimilar XPath= () (notation: , u `

family relations (Zj )j` 0 uZ` u0 j `,
x x0 0
0 , u0 )

Harmony: xZj x0 label (x) = label (x0 ).
n



Zig: xZj x0 , xv xw n, j v 0 , w0 0
n

x0 v 0 , x0 w0
1. data(v) = data(w) data(v 0 ) = data(w0 ),




2. (v) Zjn+i (v 0 ) 0 < n,




3. (w) Zjm+i (w0 ) 0 < m.
n



Zag: xZj x0 , x0 v 0 x0 w0 n, j v, w
n

xv, xw items 1, 2 3 verified.
notion `-bisimulation corresponds game spoiler duplicator
` rounds.
Clearly , u 0 , u0 , u` 0 , u0 `.
Observation 6. Suppose 0 height `, u , u0 0 .
, u ` 0 , u0 iff , u 0 , u0 .
data tree u , let |` u denote subtree induced {v |
n
(n `) uv}.
Observation 7. , u ` (T |` u), u.
281

fiFigueira, Figueira, & Areces

3.1.2 Equivalence Bisimulation
show coincides finitely branching data trees, `
coincides ` .
Theorem 8.
1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0 finitely
branching.
2. , u ` 0 , u0 iff , u ` 0 , u0 .
theorem shown consequence Propositions 9 11:
Proposition 9. , u ` 0 , u0 implies , u ` 0 , u0 .
Proof. actually show , u` 0 , u0 via (Zi )i` 0 n j `,
dd() j, dd() j:
1. xZj x0 , x |= iff 0 , x0 |= ;
n

n





2. xv, x0 v 0 (v) Z(jn)+i (v 0 ) 0 n, (x, v) [[]]T iff
0
(x0 , v 0 ) [[]]T .
show 1 2 induction || + ||.
Let us see item 1. base case = A. Harmony, label (x) =
label (x0 ) , x |= iff 0 , x0 |= . Boolean cases straightforward.
Suppose = h = i. show , x |= 0 , x0 |= , assume , x |= .
n

Suppose v, w n, j xv, xw, (x, v) [[]]T , (x, w)
n

[[]]T data(v) = data(w). Zig, v 0 , w0 0 x0 v 0 , x0 w0 ,




(v) Zjn+i (v 0 ) 0 n, (w) Zjm+i (w0 ) 0 m, data(v 0 ) =
0
0
data(w0 ). inductive hypothesis 2 (twice), (x0 , v 0 ) [[]]T (x0 , w0 ) [[]]T . Hence
0 , x0 |= . implication 0 , x0 |= , x |= analogous. case = h 6=
shown similarly. case = hi similar (and simpler) previous case.
Let us analyze item 2. show direction. base case
0
{, }. = v = x n = 0. Since v 0 = x0 , conclude (x0 , v 0 ) [[]]T .
0
= xv , n = 1. Since x0 v 0 , (x0 , v 0 ) [[]]T .
inductive step, let x0 , . . . , xn x00 , . . . , x0n 0
x = x0 x1 x2 xn = v
0

x =

x00 x01 x02 x0n

=v

0

,

0 ,
0

xi Zji x0i 0 n. Assume, contradiction, (x0 , v 0 )
/ [[]]T . Then,
0
subformula k {0, . . . , n} , xk |= , x0k 6|= next
Lemma shows.
n

n

Lemma 10. Let path expression XPath= ( ). Let xv x0 v 0
0
(x, v) [[]]T (x0 , v 0 )
/ [[]]T . subformula
k

k

k {0, . . . , n} , (v) |= 0 , (v 0 ) 6|= .
282

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

Proof Lemma. Let x = v0 v1 vn = v x0 = v00 v10 vn0 = v 0 .
proceed induction ||. = x = v n = 0. Hence x0 = v 0
0
(x0 , v 0 ) [[]]T , contradicts hypothesis, thus statement trivially
0
true. = xv n = 1. Hence x0 v 0 (x0 , v 0 ) [[]]T . case
also trivial. case = similar.
0
Suppose = []. Since (x0 , v 0 )
/ [[]]T , x0 = v 0 0 , v 0 6|= . Taking
k = 0 = statement holds. Observe subformula .
Suppose = . k (x, vk ) [[]]T (vk , v) [[]]T .
0
0
0
Since (x0 , v 0 )
/ [[]]T , (x0 , vk0 )
/ [[]]T (vk0 , v 0 )
/ [[]]T . either case, apply
inductive hypothesis straightforwardly.

contradicts inductive hypothesis 1.
Proposition 11. , u ` 0 , u0 implies , u ` 0 , u0 .
Proof. Fix u u0 0 , u ` 0 , u0 . Define (Zi )i`
xZi x0

iff , x 0 , x0 .

show Z `-bisimulation , u 0 , u0 . hypothesis, uZ` u0 . Fix
h `. construction, Zh satisfies Harmony. Let us see Zh satisfies Zig (the case
Zag analogous). Suppose xZh x0 ,
x = v0 v1 vn = v

x = w0 w1 wm = w

,
,

data(v) = data(w) (the case data(v) 6= data(w) shown similar way),
m, n h. Let P 02 defined
n



P = {(v 0 , w0 ) | x0 v 0 x0 w0 data(v 0 ) = data(w0 )}.
Since , x h 0 , x0 , dd(hn =m i) h , x |= hn =m i, conclude P 6= .
next show exists (v 0 , w0 ) P
i. x0 = v00 v10 vn0 = v 0 0 ,
0 = w 0 0 ,
ii. x0 = w00 w10 wm

iii. (i {0, . . . , n}) , vi hi 0 , vi0 ,
iv. (j {0, . . . , m}) , wj hj 0 , wj0 ,
hence Zig satisfied Zh . way contradiction, assume (v 0 , w0 ) P
satisfying ii either
(a) (i {0, . . . , n}) , vi 6hi 0 , vi0 ,
(b) (j {0, . . . , m}) , wj 6hj 0 , wj0 .
283

fiFigueira, Figueira, & Areces

Fix > tautology dd(>) = 0. (v 0 , w0 ) P define two families
node expressions,
0v0 ,w0 , . . . , nv0 ,w0

v00 ,w0 , . . . , vm0 ,w0 ,

satisfying dd(iv0 ,w0 ) h {0, . . . , n} dd(vj 0 ,w0 ) h j
j {0, . . . , m} follows:
Assume (a) smallest number , vi 6hi 0 , vi0 . Let iv0 ,w0
dd(iv0 ,w0 ) h , vi |= iv0 ,w0 0 , vi0 6|= iv0 ,w0 . k
{0, . . . , n} \ {i}, let kv0 ,w0 = >, k {0, . . . , m}, let vk0 ,w0 = >.
Suppose (a) hold. (b) holds. Let j smallest number
, wj 6hj 0 , wj0 . Let vj 0 ,w0 dd(vj 0 ,w0 ) h j , wj |= vj 0 ,w0
0 , wj0 6|= vj 0 ,w0 . k {0, . . . , m} \ {j}, let vk0 ,w0 = >, k {0, . . . , n}, let
kv0 ,w0 = >.

{0, . . . , n} j {0, . . . , m}, let
=

^

iv0 ,w0



(v 0 ,w0 )P

j =

^

vj 0 ,w0 .

(1)

(v 0 ,w0 )P

However conjunctions could potentially infinite trees infinitely branching. Since dd(iv0 ,w0 ) h i, Proposition 2 finitely many non-equivalent node

expressions iv0 ,w0 applies vj 0 ,w0 . Hence, infinite conjunctions (1)
equivalent finite ones, may assume j well-formed formulas. Finally, let = [0 ][1 ] [n ] = [0 ][1 ] [m ]. construction,
dd(), dd() h dd(h = i) h.
clear construction (x, v) [[]]T (x, w) [[]]T , therefore , x |=
h = i. see next 0 , x0 6|= h = i. contradicts , x h 0 , x0 ,
hence done. Suppose 0 , x0 |= h = i. (v 0 , w0 ) P
0
0
(x0 , v 0 ) [[]]T (x0 , w0 ) [[]]T . particular, ii true, either (a)
0
(b) hold. first case, have, construction, (x0 , v 0 )
/ [[]]T , second
0
clear (x0 , w0 )
/ [[]]T . either case, arrive contradiction.
Proof Theorem 8. Item 2 direct consequence Propositions 9 11.
left-to-right argument item 1 seen consequence item 2. Indeed,
, u 0 , u0 implies , u ` 0 , u0 `, item 2 implies , u ` 0 , u0
`, turn entails , u 0 , u0 .
right-to-left argument item 1 similar Proposition 11, defining
Z xZx0 iff , x 0 , x0 . conjunctions (1) finite 0 finitely
branching, P finite (the fact finitely branching used show Zag
satisfied).
284

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

3.2 Vertical XPath
study bisimulation XPath= (). Interestingly, notion give simpler
one XPath= () due normal form enjoyed logic.
downward fragment XPath= used dd() measure maximum depth
current point evaluation formula access. vertical fragment
XPath= , need define maximum distance r going downward
maximum distance going upward formula reach. call pair (r, s)
vertical depth formula (notation: vd()). nesting depth formula
(notation: nd()) maximum number nested [ ] appearing .
vd(a)
vd( )
vd()
vd(hi)
vd(h fi i)

=
=
=
=
=

(0, 0)
vd() = (0, 0)
max{vd(), vd()}
vd() = vd()
vd()
vd([]) = max{vd(), vd()}
vd()
vd() = max{(0, 0), vd() + (1, 1)}
max{vd(), vd()}
vd() = max{(0, 0), vd() + (1, 1)}

nd(a)
nd( )
nd()
nd(hi)
nd(h fi i)

=
=
=
=
=

0
max{nd(), nd()}
nd()
nd()
max{nd(), nd()}

nd()
nd()
nd([])
nd()
nd()

=
=
=
=
=

max{nd(), nd()}
0
1 + nd()
0
0

where, A, fi {=, 6=}, + max performed component-wise, path
expression empty string .
Let (r, s, k)-XPath= () set formulas XPath= () vd() (r, s)
nd() k. Let , u 0 , u0 pointed data trees. say , u 0 , u0
equivalent XPath= () (notation: , u 0 , u0 ) iff XPath= (),
, u |= iff 0 , u0 |= . , x 0 , x0 (r, s)-equivalent [resp. (r, s, k)-equivalent]

0 0
0 0
XPath= () (notation: , x
r,s , x [resp. , x r,s,k , x ]) satisfy
node expressions XPath= () vd() (r, s) [resp. vd() (r, s)
nd() k].
3.2.1 Normal Form
define normal form XPath= () implicitly used definition
bisimulation section. n 0, let n denote concatenation n symbols .
I.e., 0 empty string , 1 = , n+1 = n (similarly n ).
path expression XPath= () downward [resp. upward] form
n
[] [resp. []n ] n > 0 XPath= (). example, [hi] downward
expression whereas [hi] not. up-down expression expression form ,
, upward downward. Henceforth use , ,
denote upward expressions , , denote downward expressions , ,
denote up-down expressions. Note particular downward upward expression
up-down expression. XPath= () formula up-down normal form every
path expression contained up-down every data test form h fi
fi {=, 6=}. Next, show every XPath= () formula equivalent
285

fiFigueira, Figueira, & Areces

one up-down normal form. course, idea replacing child axes parent axes
means novel, number works rewriting expressions
equivalent ones improve performance streamability, works Olteanu
(2007) Olteanu, Meuss, Furche, Bry (2002). However, rewrite systems aim
removing backward axes (parent, ancestor, etc) maintaining equivalence root,
different end, maintain equivalence path expressions pair
nodes. Further, doubt normal form useful scenarios since
computational streamability perspective resulting formula up-down normal
seems complex. Although regular, nested modalities
introduces parent axes, shown later. motivation normal form
simplify defintion bisimulation means rendering formula simple
possible form.
Given path expression , navigation (notation: nav()) string
{, } results removing node expressions [] . example,
nav([hi][h = i][b]) = .
Proposition 12. Let (r, s, k)-XPath= (), XPath= () up-down
normal form following hold
1. ;
2. vd( ) = (r, s);
3. nd( ) k (r + + 2).
Proof. idea factorize path tree going node
test expression. Consider instance expression = [a]. immediate
equivalent up-down expression [h[h[a]i]i], up-down normal
form.
use following directed equivalences translate path expression
equivalent up-down expression.


()

[1 ][2 ] [1 2 ]


n 1 0 1 n



n n1 0



0 1 n

(merge)

[hn n 1 1 0 i]
n

[h0 1 . . . n i]
n

[h0 1 n i]

(factor )
(shift-r )
(shift-l )

expressions above, empty string, form [1 ][2 ] . . . [n ],
path expression, empty string, path expression.
idea (factor ) converts expression goes n times n times
node expression, this, test done i-th node going
merged (n i)-th test going up. example, [a][c][b]
[h[a][b][c]i]. hand, (shift-r ) (shift-l ) group node tests
lowest node expression, making use fact parent relation functional.
Thus, example [a][b] [h[b][a]i] [a][b] [h[a][b]i]. thus clear
left right expressions semantically equivalent.
286

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

following lemma treats case path expressions:
Lemma 13. Let XPath= ()-path expression vd() = (r, s) nd() =
k, up-down path expression that:
1.

2. vd( ) = (r, s),
3. nd( ) k + r + + 1.

Proof Lemma. first apply rule (factor ) many times possible. clear
nav() form n n, 0 rule (factor ) cannot
applied done. Hence, suppose nav() contains pattern . Let
= 1
1
1 = 1 n
. . . 01 . . . n1 1
{z
}
| 1
matches (factor )

2
2 n
. . . 02 . . . n2 2
2

|

{z

matches (factor )

..
.

}


m1 n
. . . 0m . . . nmm ,
|
{z
}
matches (factor )

nav( ), nav(m ) , nav( ), nav(1 ) , ji empty string,
i,j
i,j
[i,j
1 ][2 ] . . . [hi,j ]. Furthermore, assume maximal (i.e., impossible
apply (factor ) s) length minimal (i.e.,
case nav(i ) ends nav(i+1 ) begins ). Observe
nav(i ) . apply rule (factor ) 1 marked places obtain
1
1 1 1
2 = 1 [hn
1 1
1 0 i]
1 n1
|
{z
}
(factor ) applied

2
2 2 2
2 [hn
2 1
1 0 i]
2 n2

|

{z

(factor ) applied

..
.

}



m1 [hn
1
1 0 i] ,
nm
{z
}
|
(factor ) applied

Let vd(nav(1 )) = (r1 , s1 ). Since nav() = nav( 1 ) contains pattern ,
r1 > 0. shown vd( 2 ) = (r, s), nd(2 ) nd(1 ) + 1,
vd(nav(2 )) (r1 1, s1 ). repeat procedure 2
longer apply rule (factor ), end up-down path expression f

287

fiFigueira, Figueira, & Areces

1. f 1 ,
2. vd( f ) = (r, s),
3. nd(f ) nd(1 ) + r1 .
applying () (merge) f many times possible, obtain
equivalent 0 , vertical nesting depth f , form
0 = 1 2 . . . n n+1 n+2 . . . n+m ,
(possibly empty) string form [1i ] . . . [ni ]. apply (shift-l )
(shift-r ) 0 obtain equivalent 00 vertical depth (i.e. vd(00 ) =
vd(0 ) = (r, s)) nesting depth equal nd(0 ) + 1 form
= 0 n 00 ,
0 00 empty string form []. Observe nd( ) =
nd(0 ) + 1 k + r1 + 1 r + + 1, satisfies requirements lemma.
concludes proof Lemma 13.


following lemma treats case data tests:
Lemma 14. Let , up-down path expressions let = h fi (for
fi {=, 6=}) vd() = (r, s) nd() = k. up-down path
expression that:
1. h ,
2. vd( ) = (r, s),
3. nd( ) k + 1.
Proof Lemma. Let us analyse case = [ ]n [ ] =
[ ]n [ ], n + > 0, n + > 0, , , , up-down
normal form (the remaining cases = = simpler). Suppose,
without loss generality, n n .
Hence, h fi h i,
= [ ]n [ h fi n n [ ]i].
clear formulas equivalent (cf. picture below).
288

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

}

}

|
|
{z

|

}

|

|

{z

}
{z

{z

n

{z

{z



[ ]

|



l

|

|

z

"#

[ ]



n

}

{

n

n

n

{z



"#



}

[

]
[

[ ]

}

}

[ ]

[

]



^

]

Moreover, right-hand formula one nesting lefthand formula, vertical depth (r, s). concludes proof
Lemma 14.

induction , using Lemmas 13 14, one show
desired.
3.2.2 Finite Index
Contrary case XPath= () (cf., Proposition 2), logical equivalence relation
restricted XPath= ()-formulas bounded vertical depth infinitely many equivalence
classes.
Proposition 15. r + 2
r,s infinite index.
}
Proof. show every r, r + = 2 infinite set {r,s
i0
non-equivalent node expressions vertical depth (r, s). thus follows every r,
r + 2,
r,s infinite index.
Consider following formulas.
i+1

1,1
= h = [1,1
]i

0
1,1
= h =

i+1

0,2
= h = [1,1
]i

0
0,2
= h =

i+1

2,0
= h = [1,1
]i

0
2,0
= h =

n ) = (r, s) nd( n ) = n every n. formula n intuitively says
Note vd(r,s
r,s
r,s
chain length n depicted Figure 2.
n , x
n0
data tree Tn figure, Tn , xr,s |= r,s
n r,s 6|= r,s
}
n0 > n. Therefore, {r,s
i0 infinite set non-equivalent formulas vertical depth
(r, s).

proof proposition need use formulas unbounded nesting
depth. fact, restricted bounded nesting depth finitely many
formulas logical equivalence, stated next.
289

fiFigueira, Figueira, & Areces

x2,0
Tn :

x1,1

...
x0,2





n times



Figure 2: Model verifying ij n verifying l l < n. Dotted lines
represent equal data values.

Proposition 16.
r,s,k finite index.
Proof. argument proof Proposition 2.
0 0
Corollary 17. {T 0 , u0 | , u
r,s,k , u } definable node expression (r, s, k)XPath= ().

Proof. Similar proof Corollary 3.
3.2.3 Bisimulation (r, s, k)-bisimulation
advantage normal form presented Section 3.2.1 makes possible use
simple notion bisimulation. disadvantage that, since preserve

corresponds
nesting depth,
r,s,k correspond precisely r,s,k , although
precisely . Nonetheless, obtain, r, s, k,

r,s,k
r,s,k r,s,k(r+s+2) .

Let 0 two data-trees. say u u0 0 bisimilar
XPath= () (notation: , u 0 , u0 ) iff relation Z 0 uZu0
x x0 0
Harmony: xZx0 label (x) = label (x0 ),
n



n



Zig: xZx0 , x z 0 , z 0 0 0 x0 , 0 z 0 , data(z)
= data(x) data(z 0 ) = data(x0 ), zZz 0 .
following picture illustrates intended requirements
290

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

T0



9y 0

8y


n

9z 0

n

=

)

x

(6=

(6=

)

=

8z
Z

x0



n



Zag: xZx0 , 0 x0 0 z 0 y, z x, z, data(z)
= data(x) data(z 0 ) = data(x0 ), zZz 0 .
definitions heavily rely normal form Proposition 12. fact,
normal form strictly necessary giving notion bisimulation vertical
fragment. case downward fragment, normal form used, every path
expression essentially repetition node test child relation. contrary,
case vertical fragment, use normal form would beneficial.
notion bisimulation taking account existence normal form would
rule Zig form: xZx0 n1 , . . . , nk , m1 , . . . , mk , n1 , . . . , nk m1 , . . . , mk

{1, . . . , k},
v1i . . . vni w1i . . . wm

{1, . . . , k},
v1i . . . vni w1i . . . wm


v1i = w1i v1i = w1i
= v i+1 w = v i+1
wm
ni+1
mi
ni+1


x = vn1 1 x = vn1 1
0i {1, . . . , k}, v 0i , . . . , v 0i , w 0i , . . . , w 0i
v10i , . . . , vn0ii 0 , w10i , . . . , wm
1
1
ni
mi

0 {1, . . . , k}
0i 0 ,
v10i . . . vn0ii 0 w10i . . . wm

0i 0 ,
v10i . . . vn0ii 0 w10i . . . wm


v10i = w10i v10i = w10i
0i = v 0i+1 w 0i = v 0i+1
wm
ni+1
mi
ni+1


x = vn011 x = vn011
vji Zvj0i , wji Zwj0i , vji Z vj0i , wji Z wj0i
data(wnk k ) = data(wnk k ) iff data(wn0k ) = data(wn0k )
k

k

291

fiFigueira, Figueira, & Areces

Intuitively, definition establishes every paths p p going down, many
times , similar paths p0 p0 , going many times,
respecting shape p p respectively j-th node p connected
j-the node p0 via Z, nodes along p, data
values last node p p equal data values last
nodes p0 p0 so.
definition natural extension downward bisimulation, instead
considering downward paths, considers general ones. happens
downward bisimulation, every intermediate node paths related
corresponding node 0 . one immediately see, definition quite long
checks many conditions. Working normal forms allow us get much simpler
definition bisimulation, two main advantages: a) one path
data tree, b) require intermediate nodes related Z. two
features direct consequences up-down normal form, normal form a)
compares values root (so one non-empty path expression
diamond node expression) b) make tests beginning end
path expressions (but intermediate nodes). However, notice due
normal form definitions denote bisimulation relation.
say u u0 0 (r, s, k)-bisimilar XPath= () (notation:
0
0 0
k
, u
r,s,k , u ) family relations (Zr,s )r+sr+s,kk
k u0 r + r + s, k k, x x0 0 following
uZr,s
conditions hold.
k x0 label (x) = label (x0 ).
Harmony: xZr,s
n



k x0 , x z n r + n 0 , z 0 0
Zig: xZr,s
n



0 x0 , 0 z 0 , following hold
1. data(z) = data(x) data(z 0 ) = data(x0 ),

0
0
0
2. k > 0, zZrk1
0 ,s0 z r = r + n m, = n + m.
n



k x0 , 0 x0 0 z 0 n r + n y, z
Zag: xZr,s
n



x, z, items (1) (2) verified.
n

n

k x0 , x 0 x0 follows yZ k1 0 , r 0 = r + n,
Observation 18. xZr,s
r0 ,s0
k case bisimilarity.
s0 = n. occurs Z instead Zr,s

data tree u , let |sr u denote subtree induced


n

{v | (m s) (n r + m) (w ) wu wv}.

Observation 19. , u
r,s,k (T |r u), u.

292

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

3.2.4 Equivalence Bisimulation
next result says coincides finitely branching data trees, states

precisely way
r,s,k related r,s,k .
Theorem 20.
1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0
finitely branching.

0 0
0 0
2. , u
r,s,k(r+s+2) , u implies , u r,s,k , u .

0 0
0 0
3. , u
r,s,k , u implies , u r,s,k , u .

theorem shown consequence following Propositions 21
22.

0 0
0 0
Proposition 21. , u
r,s,k(r+s+2) , u implies , u r,s,k , u .
0 0
Proof. show , u
r,s,k , u via
k
(Zr,s
)r+sr+s,kk

n r + n, up-down normal form vd() (r, s),
nd() k, upward expression up-down normal form, downward
expression up-down normal form vd( ), vd( ) (r, s), nd( ), nd( ) k:
k x0 , x |= iff 0 , x0 |= .
1. xZr,s
n

n





0

k1 0
2. x, 0 x0 , x Zr,s
x , (x, y) [[ ]]T iff (x0 , 0 ) [[ ]]T .
0
0
0
iff
3. z, 0 z 0 , z Zrk1
0 ,s0 z r = r + n m, = n + m, (y, z) [[ ]]
0
(y 0 , z 0 ) [[ ]]T .

Hence, Proposition 12, main statement follows. simultaneously show 1, 2
3 induction || + | | + | |.
Let us see item 1. base case = A. Harmony, label (x) =
label (x0 ) , x |= iff 0 , x0 |= . Boolean cases straightforward.
Suppose = h = i. show , x |= 0 , x0 |= , assume , x |= .
n

Suppose y, z n s, r + n x, z, (x, y) [[ ]]T ,
0
(y, z) [[ ]]T data(x) = data(z). Zig, 0 , z 0 0 zZrk1
0 ,s0 z
r0 = r + n m, s0 = n + m, data(x0 ) = data(z 0 ). inductive hypothesis 2
0
0
3, (x0 , 0 ) [[ ]]T (y 0 , z 0 ) [[ ]]T . Hence 0 , x0 |= . implication 0 , x0 |=
, x |= analogous. cases = h 6= i, = h fi i, = h fi
(fi {=, 6=}) = hi (for up-down normal form) shown similar way.
cases = h fi (fi {=, 6=}) trivial.
293

fiFigueira, Figueira, & Areces

Let us analyze item 2. Let = []n (n 0), let x0 , . . . , xn
0

x00 , . . . , x0n

= x0 x1 xn = x
0

=

x00 x01 x0n

=x

0

,

0 ,

k1 0
0
0
0
x . Observation 18, x0 Zrk1
xZr,s
0 ,s0 x0 , r = r + n, = n. Assume
0
contradiction (x0 , 0 )
/ [[ ]]T . necessarily means , x0 |= 0 , x00 6|= .
subformula , nd() k 1 nd() (r0 , s0 ) contradicts
inductive hypothesis 1.
Item 3 shown similar way. Let = [] (m 0), let z0 , . . . , zm
0
0 0
z0 , . . . , z

= z0 z1 zm = z
0

=

0
z00 z10 zm

=z

0

,

0 ,
0

0
0 0 / [[ ]]T . necessarily means
zZrk1
0 ,s0 z . Assume contradiction (y , z )

, xm |= 0 , x0m 6|= . subformula , nd() k 1 nd() (r0 , s0 )
contradicts inductive hypothesis 1.

0 0
0 0
Proposition 22. , u
r,s,k , u implies , u r,s,k , u .
0 0
k
Proof. Fix u u0 0 , u
r,s,k , u . Define (Zr,s )r+sr+s,kk
k 0
x
xZr,s

iff

, x

r,s,k

0 , x0 .

k (r, s, k)-bisimulation , u 0 , u0 . hypothesis, uZ k u0 .
show Zr,s
r,s

k satisfies Harmony. Let us see Z k
fix r + r + s, k k. construction, Zr,s
r,s
k x0 ,
satisfies Zig (the case Zag analogous). Suppose xZr,s

= x0 x1 vn = x
= z0 z1 zm = z

,
,

data(x) = data(z) (the case data(x) 6= data(z) shown similar way),
r + n. Let P 02 defined
n



P = {(y 0 , z 0 ) | 0 x0 0 z 0 data(x0 ) = data(z 0 )}.
n
n
0 0
Since , x
r,s,k , x , vd(h = i) (r, s), nd(h = i) = 0, , x |= h =
n
i, conclude P 6= . next show exists (y 0 , z 0 ) P

i. 0 = x00 x01 x0n = x0 0
0 = z 0 0 ,
ii. 0 = z00 z10 zm

294

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

iii. , x

r,s,k1

0 , x0 ,

iv. , z 0

r ,s0 ,k1

0 , z 0 , r0 = r + n m, s0 = n + m,

k . way contradiction, assume
hence, inductive hypothesis, Zig satisfied Zr,s
0
0
(y , z ) P satisfying ii either

(a) , x 6

r,s,k1

(b) , z 60

0 , x0 ;

r ,s0 ,k1

0 , z 0 r0 = r + n m, s0 = n + m.

Fix > tautology vd(>) = (0, 0), nd(>) = 0. (y 0 , z 0 ) P
define node expressions, y0 ,z 0 y0 ,z 0 , satisfying vd(y0 ,z 0 ) (r, s), nd(y0 ,z 0 ) < k
vd(y0 ,z 0 ) (r0 , s0 ), nd(y0 ,z 0 ) < k follows:
Suppose (a) holds. Let y0 ,z 0 vd(v0 ,w0 ) (r, s), nd(v0 ,w0 ) < k,
, x |= y0 ,z 0 0 , x0 6|= y0 ,z 0 ; let v0 ,w0 = >.
Suppose (a) hold. (b) holds. Let y0 ,z 0 vd(y0 ,z 0 ) (r0 , s0 ),
nd(y0 ,z 0 ) < k , z |= y0 ,z 0 0 , z 0 6|= y0 ,z 0 ; let y0 ,z 0 = >.
Let
=

^

y0 ,z 0



(y 0 ,z 0 )P

=

^

y0 ,z 0 .

(2)

(y 0 ,z 0 )P

Since vd(y0 ,z 0 ) (r, s), nd(y0 ,z 0 ) < k, Proposition 16, finitely many nonequivalent formulas y0 ,z 0 . applies formulas y0 ,z 0 . Hence infinite conjunctions (2) equivalent finite ones, therefore without loss generality
may assume well-formed formulas.
Finally, let
= []n = [].
construction, vd( ) (r, s), nd( ) k. Furthermore, , x |= h =
0 , x0 6|= h = i, contradicts fact , x 0 , x0 .
r,s,k

Proof Theorem 20. Items 2 3 shown Propositions 21 22.
left-to-right argument item 1 seen consequence item 2. Indeed,

0 0
0 0
, u 0 , u0 implies , u
(r,s) , u r, s, item 2 implies , u (r,s) , u

r, s, turn entalis , u 0 , u0 .
right-to-left argument item 1 similar Proposition 22, working
k )
0
single Z instead (Zr,s
r,s,k . converse implication, define Z xZx iff
, x 0 , x0 . conjunctions (2) finite 0 finitely branching,
P finite (the fact finitely branching used showing Zag
satisfied).

Corollary 23.
r,s,k finite index.
Proof. Immediate Theorem 20 Proposition 16.
295

fiFigueira, Figueira, & Areces

3.3 Simulation
section define notions directed (non-symmetric) simulations XPath= ()
XPath= (), done, e.g., works Kurtonina de Rijke (1997) Lutz,
Piro, Wolter (2011) modal logics. obtain results similar Theorems 8
20 relating simulation notion corresponding logical implication.
say XPath= formula positive contains negation inequality data tests h 6= i. L one XPath= (), XPath= (), XPath= ( ),
XPath= ( ), write L+ positive fragment L.
simulation XPath= () [resp. XPath= ()] simply bisimulation
Zag clause half first condition Zig clause omitted.
Observe simulations need symmetric.
Formally, say u similar u0 0 XPath= () (notation: , u
0
, u0 ) iff relation Z 0 uZu0 x x0 0

Harmony: xZx0 label (x) = label (x0 ).
n



n



Zig: xZx0 , xv xw v 0 , w0 0 x0 v 0 , x0 w0
1. data(v) = data(w) data(v 0 ) = data(w0 ),




2. (v) Z (v 0 ) 0 < n,




3. (w) Z (w0 ) 0 < m.

u similar u0 0 XPath= () (notation: , u 0 , u0 ) iff
relation Z 0 uZu0 x x0 0
Harmony: xZx0 label (x) = label (x0 ).
n



n



Zig: xZx0 , x z 0 , z 0 0 0 x0 , 0 z 0 , zZz 0 ,
data(z) = data(x) data(z 0 ) = data(x0 ).
Relations `
r,s,k defined accordingly. define one-way (non-symmetric)
logical implication models follows. write , u V 0 , u0
( XPath= ()+ ) [T , u |= 0 , u0 |= ].
+
+
Define V` , V , V
r,s,k analogous way `-XPath= () , XPath= () , (r, s, k)XPath= ()+ , respectively. bisimulation, coincides V.

Theorem 24.
1. Let {, }. , u 0 , u0 implies , u V 0 , u0 . converse holds 0
finitely branching.
2. , u ` 0 , u0 iff , u V` 0 , u0 .

0 0
0 0
3. , u
r,s,k(r+s+2) , u implies , u Vr,s,k , u .

296

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization


0 0
0 0
4. , u V
r,s,k , u implies , u r,s,k , u .

Proof. proofs straightforward adaptations proofs Propositions 9 11
Propositions 21 22 respectively, ommitted here. particular,
part, adaptation proofs Propositions 11 22, simulations defined

xZi x0 iff , x Vi 0 , x

k 0
xZr,s
x iff , x V

r,s,k

0, x

respectively, conditions (a) (b) page 283 become
(a) [i {0, . . . , n} XPath= ()+ ] dd() h , vi |= 0 , vi0 6|= ;
(b) [j {0, . . . , m} XPath= ()+ ] dd() h j , wj |= 0 , wj0 6|= ,

(a) [i {0, . . . n} XPath= ()+ ] vd() (r + i, i) nd() k 1 , vi |=
0 , vi0 6|= ;
(b) [j {0, . . . m} XPath= ()+ ] vd() (r + j 0 , j 0 ) j 0 = n + j
nd() k 1 , wj |= 0 , wj0 6|=
respectively.
say 0 substructure 0 data tree results removing
nodes , i.e., 0 u, v 0 have: 1) uv iff uv 0 ; 2)
label (u) 0 equals label (u) ; 3) data(u) 0 equals data(u) . Equivalently,
seen -structures, 0 -substructure induced 0 . One verify
identity 0 simulation XPath= () 0 .
Lemma 25. 0 substructure u0 0 0 , u0 , u0 .
Lemma 26.
+
(1) {T 0 , u0 | , u ` 0 , u0 } definable node expression +
`,u,T XPath= ()
downward depth `.
+
0 0
+
(2) {T 0 , u0 | , u
r,s,k , u } definable node expression r,s,k,u,T XPath= ()
vertical depth (r, s) nesting depth k.

0 0
0 0
Proof. item (2), let sim
r,s,k (T , u) = {T , u | , u r,s,k , u }. Let 0 ,u0 set
positive node expressions XPath= ()+ vertical depth (r, s) nesting
depth k 0 , u0 |= . Let
_
^
=
0 ,u0 .
0 ,u0 sim
r,s,k (T ,u)

297

fiFigueira, Figueira, & Areces

Since every 0 ,u0 finite logical equivalence Proposition 16, follows
valid node expression. show defines sim
r,s,k (T , u).
V

0
0
0
0
Let , u simr,s,k (T , u). Then, , u |= 0 ,u0 thus 0 , u0 |= .
V
hand 0 , u0 |= 0 , u0 |= 00 ,u00 00 , u00 sim
r,s,k (T , u)


00 00
0 0
00 00
0 , u0
r,s,k , u . Theorem 20-3 , u r,s,k , u ,



0 0
00 00
00 00
0 0
particular 00 , u00
r,s,k , u . Since , u r,s,k , u , u r,s,k , u ,


0 0
0 0
, u
r,s,k , u (by transitivity r,s,k ) thus , u simr,s,k (T , u).
Item (1) shown similar way, using Proposition 2 Theorem 8-2.

obtain node expressions XPath= invariant simulations are, precisely, positive ones.
Theorem 27.
1. XPath= () -invariant [resp. ` ] iff equivalent node expression
XPath= ()+ [resp. `-XPath= ()+ ].
2. XPath= () -invariant iff equivalent node expression XPath= ()+ .
3. XPath= ()
r,s,k -invariant equivalent node expression
(r, s, k)-XPath= ()+ .
4. XPath= () equivalent node expression (r, s, k)-XPath= ()+
0

r,s,k0 -invariant, k = k (r + + 2).
Proof. start item (1), case ` . part straightforward
Theorem 24-2, focus part. Let preserved ` .
Let {(Ti , ui )}in set pointed models modulo ` (which finite due
Theorem 8-2 together Proposition 2). claim
, u |= iff Ti , ui ` , u n.

(3)

one hand, , u |= n Ti , ui ` , u,
Ti , ui ` , u. hand, suppose Ti , ui ` , u i. Since preserved
` Ti , ui |= , conclude , u |= .
+
Let
W `,ui ,Ti XPath= () , dd(i ) `, Lemma 26-(1). Using (3) one shows
`,ui ,Ti .
case item (1), direction follows Theorem 24-1.
direction, let preserved . easy see preserved
iff preserved dd() . apply reasoning
statement follows.
Item (3) follows argument item (1) time using Corollary 23
Lemma 26-(2).
Item (4) straightforward Theorem 24-3.
Item (2) follows items (3) (4) observation preserved

iff preserved
r,s,k(r+s+2) vd() = (r, s) nd() = k.
298

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

3.4 Transitive Axes
happens, example, basic modal logic propositional dynamic logic,
notion bisimulation [resp. simulation] logic captures logical equivalence [resp. logical implication] corresponding fragments including also reflexivetransitive closure axes present. Intuitively, occurs
infinite union compositions , similarly . Hence notions bisimulations

XPath= ( ) XPath= ( ) (denoted respectively) coincide
, respectively.

Let logical equivalence relation fragments XPath= ( )

XPath= ( ) respectively, let V V logical implication
XPath= ( )+ XPath= ( )+ respectively.
Theorem 28. Let { , }.

1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0 finitely
branching.

2. , u 0 , u0 implies , u V 0 , u0 . converse also holds 0 finitely
branching.
Proof. proof , u 0 , u0 , u 0 , u0 follows simple adaptation
Proposition 9 logic XPath= ( ) Lemma 10. fact finitely branching,
, u 0 , u0 , u 0 , u0 straightforward Theorem 8-1 since .
cases XPath= ( ), XPath= ( ) XPath= ( )+ analogous.
hard see adequate notion (bi)simulation intermediate fragment XPath= () XPath= ( ) XPath= ( )
XPath= ( ) also corresponds XPath= () sense statement
above.
hand, restrict formulas transitive axes, obtain
notion bisimulation XPath= ( ) coarser bisimulation notion, define
next.
Let 0 two data-trees. say u u0 0 bisimilar
XPath= ( ) (notation: , u 0 , u0 ) iff relation Z 0 uZu0
x x0 0
Harmony: xZx0 label (x) = label (x0 ).


















Zig: xZx0 xv1 vn , xw1 wm





0
x0 v10 vn0 , x0 w10 wm
0
0 ),
1. data(vn ) = data(wm ) data(vn0 ) = data(wm

2. vi Z vi0 1 n,
3. wi Z wi0 1 m.







0 0
Zag: xZx0 x0 v10 vn0 , x0 w10 wm






xv1 vn , xw1 wm items 1, 2 3
verified.

299

fiFigueira, Figueira, & Areces

before, one define `-bisimilarity XPath= ( ), notated , u ` 0 , u0 ,
also notions equivalence ` expected.
notions bisimulation coincide corresponding logical equivalences:
Theorem 29.
1. , u 0 , u0 implies , u 0 , u0 . converse also holds 0
finite.
2. , u ` 0 , u0 iff , u ` 0 , u0 .
case XPath= ( ) obvious adapt bisimulation vertical
XPath, since normal form results hold XPath= ( ).

4. Characterization
Section 4.1 characterize XPath= () fragment first-order logic -invariant
data trees. Section 4.2 show result fails XPath= () general,
weaker result holds: first-order formula
r,s,k -invariant r, s, k equivalent
XPath= () formula.
4.1 Downward XPath
Recall data tree u , let |` u denote subtree induced {v
n
| (n `) uv}. data tree regarded -structure, explained 2.1.
FO()-formula (x) `-local data trees u , |= (u)
|` u |= (u). Recall FO(), qr() quantifier rank .
Observe following result two readings: one classical, one restricted
finite models.
Theorem 30 (Characterization). Let (x) FO(). following equivalent:
1. -invariant [finite] data-trees;
2. logically equivalent [finite] data-trees node expression `-XPath= (),
` = 2qr() 1.
proof theorem, whose proof afterwards, consequence
following three propositions:
Proposition 31. -invariant (x) FO() [finite] data-trees `-local
` = 2qr() 1.
Proof. follow proof Otto (2004a). Assume (x) FO() -invariant,
let q = qr(), put ` = 2q 1. Given data tree u suffices show
existence data trees 0 00 , corresponding elements u0 0 u00 00

(a) 0 , u0 , u,
300

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

(b) 00 , u00 (T |` u), u,
(c) 0 , u0 q 00 , u00 .
Indeed, conditions follows
|= (u) iff 0 |= (u0 )

((a) -invariance )

iff 00 |= (u00 )

(c)

iff (T |` u) |= (u),

((b)

-invariance

)

hence `-local. Observation 4 one may assume u root .
define 0 00 , structures disjoint copies sufficiently many isomorphic
copies |` u, respectively, tied together common root. structures
q isomorphic copies |` u, distinguish nature
one extra subtree, u0 u00 live, respectively: u0 root one
copies u00 root one copies |` u. Consider structures 0
00 diagram below,

u00

u0

q
| {z }
q copies

| {z }

| {z }

q copies

q copies

| {z }
q copies

distinguished elements u0 u00 marked ; open cones stand copies
, closed cones copies |` u. new isomorphic copies data
values original one. new root arbitrary, fixed, data value label.
Observation 5, straightforward conditions (a) (b) satisfied. Condition (c)
true one exhibit strategy player II q-round Ehrenfeucht-Frasse
game structures 0 00 . strategy exactly one used
paper Otto (2004a).
Proposition 32. -invariant (x) FO() [finite] data-trees `-local,
` -invariant.
Proof. Let (x) `-local -invariant. Suppose , u ` 0 , u0 |= (u).
`-locality, |` u |= (u).
, u` 0 , u0 iff (T |` u), u` (T 0 |` u0 ), u0

iff (T |` u), u (T 0 |` u0 ), u0 .

(Obs. 7)
(Obs. 6)

-invariance, 0 |` u0 |= (u0 ) `-locality again, 0 |= (u0 ).
Proposition 33. (x) FO() ` -invariant [finite] data-trees,
`-XPath= () Trx () logically equivalent [finite] data-trees.
301

fiFigueira, Figueira, & Areces

Proof. Corollary 3, every data tree u node expression `,T ,u
`-XPath= () , u ` 0 , u0 iff 0 , u0 |= `,T ,u . Let
_
`,T ,u .
=
|=(u)

Since `,T ,u `-XPath= () and, Proposition 2, ` finite index, follows
equivalent finite disjunction.
show Trx (). Let us see |= Trx (). Suppose |= (u). Since
, u |= `,T ,u , , u |= |= Trx ()(u). Let us see Trx () |= .
Assume |= Trx ()(u), , u |= . exists 0 , u0 0 |= (u0 )
, u |= `,T 0 ,u0 . property `,T 0 ,u0 , , u ` 0 , u0 since
` -invariant (and hence ` -invariant Theorem 8-2) conclude |= (u).
Proof theorem 30. implication 2 1 follows straightforwardly Theorem 8.
proof 1 2 follows: First, show -invariant (x) FO() `-local
` = 2qr() 1 (Proposition 31). Then, prove -invariant (x) FO()
`-local ` -invariant (see Proposition 32 below). Finally, show FO()definable property ` -invariant definable `-XPath= () (see Proposition 33
below).
4.2 Vertical XPath
analog Theorem 30 fails XPath= ().
basically property
p(x) =the tree x belongs contains label -invariant expressible XPath= (). Notice that, however, p -invariant. expected, since
otherwise p would expressed XPath= () formula. Indeed, consider two data trees
two nodes, root leaf, labeled respectively a, b one tree, b, b
tree. Note leafs trees -bisimilar although dont coincide
property p.
Lemma 34. FO()-formula (x) Pa (x) -invariant though logically equivalent
[finite] data-trees node expression XPath= ().
Proof. Let (x) FO()-formula node labeled tree, i.e., (x) =
(y) Pa (y). prove -invariant [finite] data-trees, though logically
equivalent [finite] data-trees node expression XPath= ().
see -invariant [finite] data-trees, take , u 0 , u0
, u 0 , u0 |= (u). Furthermore, suppose , u |= n adequate n
m. Theorem 20, 0 , u0 |= n 0 |= (u0 ).
Assume contradiction XPath= () , u |= iff |= (u)
data-tree u . Suppose vd() = (r, s) nd() = k. Let data tree
formed chain length r+1 starting root u nodes containing label
b except leave, label (the data values irrelevant). Observation 19


, u
r,s,k (T |r u), u. Since , u |= , Theorem 20, (T |r u), u |= ,
|sr u |= (u). last fact contradiction node |sr u labeled
a.
302

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

Hence XPath= () fragment FO() -invariant [finite] datatrees. However, following analog Proposition 33 (needed proof Theorem 30)
still holds case XPath= (): r, s, k, every first-order formula
r,s,k invariant equivalent XPath= () formula.
Proposition 35. Let k 0 = k (r + + 2). (x) FO()
r,s,k0 -invariant [finite]
data-trees, (r, s, k)-XPath= () Trx () logically equivalent
[finite] data-trees.
Proof. Corollary 17, every data tree u node expression r,s,k,T ,u
0 0
0 0
(r, s, k)-XPath= () , u
r,s,k , u iff , u |= r,s,k,T ,u . Let
=

_

r,s,k,T ,u .

|=(u)

r,s,k,T ,u (r, s, k)-XPath= () and, Proposition 16,
r,s,k finite index,
follows equivalent finite disjunction. proof (x) Trx () similar
Proposition 33, show next. Let us see |= Trx (). Suppose |= (u). Since
, u |= r,s,k,T ,a , , u |= |= Trx ()(u). Let us see Trx () |= .
Assume |= Trx ()(u), , u |= . exists 0 , u0 0 |= (u0 )
0 0
, u |= r,s,k,T 0 ,u0 . property r,s,k,T 0 ,u0 , , u
r,s,k , u since
r,s,k(r+s+2) -invariant (and hence r,s,k -invariant Theorem 20-2) conclude |=
(u).

Notice counterexample Lemma 34 unrestricted, existential formula.
One may wonder might possible extend expressive power XPath= ()
accout unrestricted quantification. natural candidate would modal operator
E (usually known existential modality) which, intuitively, let us express
node model formula holds. even additional expressive power provided E analog Theorem 30 fails. Formally, consider logic
XPath= (l E), results adding operator E XPath= () following
semantics: [[E]]T = [[]]T 6= , [[E]]T = otherwise.
following lemma shows counterexample analog Theorem 30, showing
XPath= (l E) fragment FO() -invariant [finite] data-trees.
Lemma 36. FO()-formula (y, z) [y z Pa (y) Pb (z)] -invariant though
logically equivalent [finite] data-trees node expression XPath= (l E).
Proof. Let (x) FO()-formula two nodes data value
labels b respectively, i.e., (x) = (y, z) [y z Pa (y)Pb (z)]. show cannot
expressed XPath= (, , E). Suppose, means contradiction, node
expression XPath= (, , E) expressing , vd() = (r, s) (vd() XPath= (, , E)
defined together clause vd(E) = vd()). Let n = r + s, let
chain-like data-tree u0 u1 un label (u0 ) = a, label (un ) = b,
label (ui ) = c {1, . . . n 1} data(ui ) = {0, . . . , n}.
Let 0 chain-like data-tree u00 u01 u0n label (u0i ) = label (ui )
{0, . . . n}, data(u0i ) = data(ui ) {0, . . . , n 1} data(u0n ) = 0. Note
303

fiFigueira, Figueira, & Areces

6|= (u0 ) 0 |= (u00 ). However, one show {0, . . . , n}
, ui |= iff 0 , u0i |= . Hence, express thus expressible
XPath= (, , E).

5. Applications
devote section exemplify model theoretic tools developed
used show expressiveness results XPath= . intend comprehensive;
rather exhibit number different results show possible uses notions
bisimulation introduced.
5.1 Safe Operations Models
Bisimulations also used show certain operations models preserve truth.
operations usually called safe given logic, applied model
without changing truth values formula language. Observation 4,
example, already example kind results showing class models
formula closed sub-model generation. show elaborate example.
say 0 subtree replication , 0 result inserting |x
sibling x, x node different root. Figure 3 gives
schematic representation operation.


Figure 3: Closure subtree replication.
Proposition 37. XPath= ( ) closed subtree replication, i.e. 0 subtree

replication , u 0 , u , u.
Proof. Suppose x root , 0 result inserting |x
sibling x. Let us call Tx new copy |x inserted 0 , let X
set nodes |x. Furthermore, v X vx corresponding node Tx .
Nodes v vx label data value, position v |x coincides
position vx Tx .
Theorem 28, suffices verify , u 0 , u via Z 0 defined by:
Z = {(y, y) | } {(v, vx ) | v X}.
Z depicted dotted lines Figure 3.
304

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

5.2 Non-expressivity Results
Finally, use bisimulation show expressivity limits different fragments
XPath. Let key(a) property stating every node label different data
value. Let fk(a, b) (for foreign key) property (x)[Pa (x) (y)[Pb (y) x y]].
Proposition 38.
1. key(a) expressible XPath= ( ).
2. fk(a, b) expressible XPath= ( ) expressible XPath= ( )
XPath= ( )+ .
Proof. first item follows Proposition 37. Since logic closed subtree
replication, trees equivalent.
x

a, 1

a, 2

$l

a, 1

x0

a, 2 a, 2

key(a) holds one other, statement follows.
second item, easy see fk(a, b) expressible formula
h [a h = [b]i]i. However, property cannot expressed XPath= ( )
models 0 bisimilar XPath= () via Z, depicted dotted
lines.


x

c, 0

b, 1 b, 2

a, 1 a, 2



x


c, 0

a, 3 a, 2 a, 1

b, 2

b, 1

Since , x satisfies fk(a, b) 0 , x0 not, Theorem 28 follows fk(a, b)
expressible XPath= ( ).
Finally, suppose exists XPath= ( )+ expressing fk(a, b). Since
substructure 0 , x 0 , x Lemma 25. Theorem 28(2) fact
, x |= , 0 , x |= , contradiction.
Let dist3 (x) property stating nodes y, z xyz x, y, z
pairwise distinct data values.

305

fiFigueira, Figueira, & Areces

Proposition 39.
1. dist3 expressible XPath= ();
2. dist3 expressible XPath= ( );
3. neither dist3 complement expressed XPath= ( )+ .
Proof. 1, one check , x |= iff , x satisfies dist3 ,
= h 6= [h 6= [h 6= i]i]i.
Let us see 2. Consider data trees , x 0 , x0 depicted below. straightforward
, x satisfies dist3 0 , x0 not.
x

a, 2



$#

a, 1

a, 1 a, 2

a, 1 a, 2

a, 3

x

a, 2

0

T0
a, 1

a, 1

a, 1 a, 2

Let v10 v20 leaves 0 let v node data value 3.
One check , x 0 , x0 via Z 0 defined
Z = {hu, u0 | h(u) = h(u0 ) data(u) = data(u0 )} {hv, v10 i, hv, v20 i},
h(y) height y, i.e., distance root corresponding tree
(Z depicted dotted lines picture above). Since , x satisfies dist3 0 , x0
not, Theorem 28 follows dist3 expressible XPath= ( ).
3, one verify , x 0 , x0 via Z defined above. dist3 definable
XPath= ( )+ via fact , x |= , Theorem 28(2) would
0 , x0 |= , contradiction.
Let dist3 denote complement dist3 , i.e., dist3 (x) iff y, z xyz,
x, y, z pairwise distinct data values. 0 , x0 satisfies dist3
, x not. Since 0 substructure , argument analog one used
proof Proposition 38-2, dist3 expressible XPath= ( )+ .
5.3 Expressiveness Hierarchies
Define `,k equivalence ` restricted formulas nesting depth k,
is, , u `,k 0 , u0 iff XPath= () dd() ` nd() k
, u |= iff 0 , u0 |= . Define fine-grained notion bisimulation similar
way. say u u0 0 (`, k)-bisimilar XPath= () (notation:
, u`,k 0 , u0 ) family relations (Zj,t )j`,tk 0 uZ`,k u0
j `, k, x x0 0
306

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

0,0 = 0,1 = 0,2 = 0,3 = 0,4










1,0 1,1 = 1,2 = 1,3 = 1,4










2,0 2,1 2,2 =

2,3 = 2,4










3,0 3,1 3,2 3,3 = 3,4
..
.

..
.

..
.

.

..
.

..

..
.

Figure 4: Hierarchy XPath= ().
Harmony: xZj,t x0 label (x) = label (x0 ).
n



Zig: xZj,t x0 , xv xw n, j v 0 , w0 0
n

x0 v 0 , x0 w0
1. data(v) = data(w) data(v 0 ) = data(w0 ),




2. > 0, (v) Zjn+i,t1 (v 0 ) 0 < n,




3. > 0, (w) Zjm+i,t1 (w0 ) 0 < m.
n



Zag: xZj,t x0 , x0 v 0 x0 w0 n, j v, w
n

xv, xw items 1, 2 3 verified.
Following ideas used Propositions 9 11, easy show (`, k)bisimulations characterize (`, k)-equivalence.
Proposition 40. , u `,k 0 , u0 iff , u `,k 0 , u0 .
following theorem characterizes increase nesting depth results
increase expressive power (see Figure 4). speculate similar hierarchy holds
absence data values, direct consequence result.
Theorem 41. `, k 0, 1, `,0 ) `,1 )
`,k ) `+i,k .



) `,` = `,`+i ,

Proof. Consider data trees Tni , Tn0i (n 0, {1, 2}) defined every k.
307

fiFigueira, Figueira, & Areces

1,0

x10

a, 1
a, 2

b, 1

b, 2

0,0
a, 1

b, 1

0,0

T01

x1n
a, 1

Tn1

Tn1

Tn2

1
Tn+1

a, 1

x1
0

b, 2

a, 1

a, 2

a, 1

n+1,n
Tn1

1,0
a, 2

b, 1

T01

n+2,n+1

Tn2

x20

b, 2

0,0
a, 1

b, 1

0,0

T02

x1
n

Tn1

x2n
a,12

Tn2

Tn1

1
Tn+1

Tn1

Tn2

2
Tn+1

x2
0
a, 2

b, 2

T02

n+2,n+1
a,12

n+1,n
Tn2

a, 2

Tn2

x2
n

Tn1

Tn2

2
Tn+1

Note `,k+1 `,k `+1,k `,k definition. show `,k 6= `,k+1


1 1
` k + 1. purpose, show Tk1 , x1k k+1,k Tk01 , x01
k Tk , xk 6k+1,k+1
Tk01 , x01
k.
Tk1 , x1k 6k+1,k+1 Tk01 , x01
k results fact property path
length k + 1 ending label whose every pair consecutive nodes distinct data
value definable following formula k+1 depth k + 1 nesting depth k + 1,

1 = h 6= [a]i

i+1 = h 6= [i ]i

> 0.


01 01
1 1
Since Tk1 , x1k |= k+1 Tk01 , x01
k 6|= k+1 , follows Tk , xk 6k+1,k+1 Tk , xk .


1 1
01 01
show Tk1 , x1k k+1,k Tk01 , x01
k use Proposition 40 show Tk , xk k+1,k Tk , xk .
Note Tk1 Tk2 (resp. Tk01 Tk02 ) equal modulo renaming data values,
also showing roots two data trees subindex k (k +1, k)-bisimilar.

Observation 42. Note set immediate subtrees roots Tk1 , Tk01 , Tk2 , Tk02
Tk01 , Tk2 , Tk02 (and Tk1 , Tk01 , Tk02 ) construction.

show Tk1 , x1k k+1,k Tk01 , x01
k . every j k + 1, k, let Zj,t set pairs
(x, y) Tk1 Tk01 x xik0 x0ik0 {1, 2} k 0 (the notation
xik0 x0ik0 necessarily identify unique node but, possibly, many; intended
meaning refer them). Observe
Zj+1,t Zj,t

j, k.

(4)

show (Zj,t )jk+1,tk verify bisimulation conditions. proceed induction j + t. base case, j = = 0, trivial. case l > 0, = 0 also
straightforward.
Suppose > 0. Let (u, u0 ) Zj,t . Again, Harmony met since Zl,t relates
0
nodes label a. Let us suppose u x1t0 u0 x01
t0 t,
cases similar simpler.
n

Let us show Zig. Let v, w x1t0 v x01
t0 w n, j.
308

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

v inside subtree Tt20 1 Tt10 , x2t0 1 , choose v 0
1
2
corresponding node inside subtree Tt10 1 Tt01
0 . Remember Tt0 1 Tt0 1
isomorphic modulo renaming data values, corresponding mean node
position tree. data(v) = data(v 0 ) Observation 42. Furthermore,
since every node Tt10 1 Zj,t1 -relation corresponding node Tt20 1




construction Zj,t1 , follows (v)Zj,t1 (v 0 ) n. Thus, (4),




(v)Zjn+i,t1 (v 0 ) n.

02
If, hand, v x2t0 1 , choose v 0 root Tt02
0 1 , xt0 1 . Again,
0
0
data(v ) = data(v) construction vZj,t1 v . Thus, (4),
vZj1,t1 v 0 .
0
01
Finally, v falls outside Tt02
0 1 , choose v node Tt0 , course




data(v) = data(v 0 ) (v)Zj,t1 (v 0 ) n. Thus,




(4), (v)Zjn+i,t1 (v 0 ) n.

w w0 . Since every case reach node
data value corresponding nodes path Zj,t1 -related, follows
Zig condition satisfied. Zag condition easier, hence conclude
Tk1 , xk+1,k Tk0 1 , x0 every k.
therefore `,k+1 ( `,k ` k + 1.

fact `+1,k ( `,k course trivial, formulas depth ` + 1 express
tree least depth ` + 1, cannot expressed formulas depth `.
remains show `,k = `,k+1 ` k. show this, prove , x`,k+1

0 , x0 every , 0 , x`,k 0 , x0 . prove induction ` + k. base
case easy.
inductive case, let Zj,t = j,t j `, k. Hence, (Zj,t )j`,tk verify
bisimulation conditions. Let Z`,k+1 = {(x, x0 )}. show Z`,k+1 together
(Zj,t )j`,tk verifies bisimulation conditions. Harmony follows xZ`,k x0 . show
n

Zig since Zag equivalent. Suppose xv, xw n, `. Then, since Z`,k verifies
n

Zig, x0 v 0 , x0 w0
(1) data(v) = data(w0 ) iff data(v 0 ) = data(w0 ),




(2) (v)Z`n+i,k1 (v 0 ) {0, . . . , n 1},




(3) (w)Z`m+i,k1 (w0 ) {0, . . . , 1}.
Since ` k, `n+i k 1. Further, `n+i+k < `+k, means


apply inductive hypothesis. Hence, inductive hypothesis, , (v)`n+i,k 0 , (v 0 )








thus (v)Z`n+i,k (v 0 ). indentical reasoning, , (w)`n+i,k 0 , (w0 )




thus (w)Z`n+i,k (w0 ). Thus, Zig condition `,k+1 verified. Zag condition
holds symmetry.
309

fiFigueira, Figueira, & Areces


respect vertical XPath, note since
r,s,k r0 ,s0 ,k0 (r, s, k)
consequence Proposition 15 obtain every r, s, k r +


2 k 0 > k
r,s,k ) r,s,k0 . fact, conjecture r,s,k )

(r0 , s0 , k 0 ),


r,s,k+1 every k. argue proven models (Tn )n

proof Proposition 15, showing Tk , xr0 ,s0
r,s,k Tk+1 , xr0 ,s0 Tk , xr0 ,s0 6r,s,k+1



Tk+1 , , xr0 ,s0 every (r, s) (r0 , s0 ). fact
r,s,k ) r+1,s,k r,s,k ) r,s+1,k
straightforward. would obtain following.

0 0 0
Conjecture 43.
r,s,k ) r0 ,s0 ,k0 (r, s, k) < (r , , k ), r + 2.

6. Discussion
article studied model theoretic properties XPath finite arbitrary
data trees using bisimulations. One main results discuss characterization
downward vertical fragments XPath fragments first-order logic
invariant suitable notions bisimulation. seen first step
larger program studying model theory expressiveness XPath data
values and, generally, logics data trees. would interesting study notions
bisimulation descendant; characterizations XPath child descendant,
fragment FO descendant relation data trees.
considered XPath horizontal navigation siblings,
axes next-sibling () previous-sibling (). fact, adding axes results
fragment somewhat less interesting since adequate bisimulation notion
finite data trees corresponds precisely data tree isomorphism modulo renaming
data values. Next explain so. Consider following notation denoting
positions nodes tree. Positions elements (N N) , roots position
empty string , position node tree concatenation
position parent pair (l, r), l number siblings
left node r number siblings right. every position p (N N)
tree, path expression p XPath= () access node
position (and position) root. p defined = root;

(l,r) = l+1 [hk hk+1 i] (l, r) N N;
V p(l,r) = p (l,r) p (N N) ,
(l, r) N N. easy check testing p hp [hi]i p ranges leaf
positions given tree tests property subtree hanging node
formula evaluated structurally isomorphic . Further, also adding tests
hp [a] = p0 [a0 ]i every pair positions p, p0 label a, a0 data
value, well hp [a] 6= p0 [a0 ]i different data value, yields property
equal , isomorphism data values.
Section 5 show number concrete application model theoretic tools
developed, discussing expressivity non-expressivity results. also show examples
operations safe given XPath fragment. would worthwhile devise
model operations preserve truth XPath formulas show case
subtree replication.
important application bisimulation minimization method: given data
tree T1 want find data tree T2 , small possible, T1 T2 bisimilar
310

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

fragment L XPath. Since L cannot distinguish T1 T2 ,
use T2 representative T1 expressive power L required
given application. complexity several inference tasks (e.g., model checking) depends
directly model size. cases may profitable first apply
minimization step.
existence efficient minimization algorithms intimately related bisimulations:
minimize data tree partitioning terms maximum auto-bisimulation
(observe identity always auto-bisimulation, union two bisimulations bisimulation; therefore maximum, often called coarsest, bisimulation).
idea find coarsest auto-bisimulation Z given data-tree . One
cannot simply make quotient Z, result necessarily tree
clear assign data values class quotient. However, one make
quotient equivalence relation Z data value. so, obtain
smaller structure, evaluate queries here.
Determining maximum auto-(bi)simulation, either downward vertical, finite
data tree done polynomial time. naive algorithm starts defining Z
set nodes satisfy Harmony. time Zig Zag satisfied, removes
Z pair responsible Zig Zag true. repeats fixed point
Z found; maximum auto-bisimulation . one interested deciding
two nodes different finite data trees bisimilar, one use idea: answer
yes fixed point empty set. Since checking validity Zig
Zag polynomial time computable (because linearly many paths tree),
step algorithm decreases size Z, whole process polynomial
time. Better implementations, based sophisticated ideas, works
Henzinger, Henzinger, Kopke (1995) Dovier, Piazza, Policriti (2004), lead
efficient polynomial time algorithms. plan design implement algorithms
data tree minimization using bisimulation investigate computational complexity.

Acknowledgements
work partially supported grant ANPCyT-PICT-2013-2011, ANPCyT-PICT2010-688, ANPCyT-PICT-2011-0365, UBACyT 20020110100025 FP7-PEOPLE2011-IRSES Project Mobility Europe Argentina applying Logics Systems
(MEALS) Laboratoire International Associe INFINIS.

References
Abiteboul, S., Bourhis, P., Muscholl, A., & Wu, Z. (2013). Recursive queries trees
data trees. International Conference Database Theory, pp. 93104.
Abriola, S., Descotte, M. E., & Figueira, S. (2014). Definability downward vertical
XPath data trees. Workshop Logic, Language, Information Computation,
Vol. 6642 Lecture Notes Computer Science, pp. 2034.
Abriola, S., Descotte, M. E., & Figueira, S. (2015). Model theory XPath data trees.
Part II: Binary bisimulation definability. appear Information Computation. http://www.glyc.dc.uba.ar/santiago/papers/xpath-part2.pdf.
311

fiFigueira, Figueira, & Areces

Benedikt, M., Fan, W., & Geerts, F. (2008). XPath satisfiability presence DTDs.
Journal ACM, 55 (2), 179.
Benedikt, M., & Koch, C. (2008). XPath leashed. ACM Computing Surveys, 41 (1).
Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal Logic, Vol. 53 Cambridge Tracts
Theoretical Computer Science. Cambridge University Press.
Bojanczyk, M., Muscholl, A., Schwentick, T., & Segoufin, L. (2009). Two-variable logic
data trees XML reasoning. Journal ACM, 56 (3), 148.
Bojanczyk, M., & Parys, P. (2011). XPath evaluation linear time. Journal ACM,
58 (4), 17.
Clark, J., & DeRose, S. (1999). XML path language (XPath). Website. W3C Recommendation. http://www.w3.org/TR/xpath.
David, C. (2008). Complexity data tree patterns XML documents. Mathematical
Foundations Computer Science, Vol. 5162 Lecture Notes Computer Science,
pp. 278289. Springer.
Dawar, A., & Otto, M. (2009). Modal characterisation theorems special classes
frames. Annals Pure Applied Logic, 161 (1), 142.
Dovier, A., Piazza, C., & Policriti, A. (2004). efficient algorithm computing bisimulation equivalence. Theor. Comput. Sci, 311, 221256.
Figueira, D. (2010). Reasoning Words Trees Data. PhD thesis, Laboratoire
Specification et Verification, ENS Cachan, France.
Figueira, D. (2012). Decidability downward XPath. ACM Transactions Computational
Logic, 13 (4).
Figueira, D., & Segoufin, L. (2011). Bottom-up automata data trees vertical XPath.
International Symposium Theoretical Aspects Computer Science, Vol. 9
LIPIcs, pp. 93104. Leibniz-Zentrum fur Informatik.
Figueira, D., Figueira, S., & Areces, C. (2014). Basic model theory XPath data trees.
International Conference Database Theory, pp. 5060.
Figueira, D., & Libkin, L. (2014). Pattern logics auxiliary relations. Logic
Computer Science, pp. 40:140:10.
Figueira, S., & Gorn, D. (2010). size shortest modal descriptions.. Advances
Modal Logic, Vol. 8, pp. 114132.
Forti, M., & Honsell, F. (1983). Set theory free construction principles. Annali Scuola
Normale Superiore, Pisa, X (3), 493522.
Goranko, V., & Otto, M. (2007). Model theory modal logic. P. Blackburn, J. V. B., &
Wolter, F. (Eds.), Handbook Modal Logic, Vol. 3 Studies Logic Practical
Reasoning, chap. 5, pp. 249329. Elsevier.
Gottlob, G., Koch, C., & Pichler, R. (2005). Efficient algorithms processing XPath
queries. ACM Transactions Database Systems, 30 (2), 444491.
312

fiModel Theory XPath Data Trees. Part I: Bisimulation Characterization

Gyssens, M., Paredaens, J., Gucht, D. V., & Fletcher, G. (2006). Structural characterizations semantics XPath navigation tool document. Principles
Database Systems, pp. 318327. ACM.
Harel, D. (1984). Dynamic logic. Gabbay, D., & Guenthner, F. (Eds.), Handbook
Philosophical Logic. Vol. II, Vol. 165 Synthese Library, pp. 497604. D. Reidel
Publishing Co., Dordrecht. Extensions classical logic.
Henzinger, M. R., Henzinger, T. A., & Kopke, P. W. (1995). Computing simulations
finite infinite graphs. Proc. 36th Annual Symposium Foundations
Computer Science, pp. 453462. IEEE Computer Society Press.
Hopcroft, J. (1971). nlog(n) algorithm minimizing states finite automaton.
Z. Kohave, editor, Theory Machines Computations. Academic Press.
Jurdzinski, M., & Lazic, R. (2011). Alternating automata data trees xpath satisfiability. ACM Transactions Computational Logic, 12 (3), 19.
Kanellakis, P., & Smolka, S. (1990). CCS expressions, finite state processes, three
problems equivalence. Inf. Comput., 86 (1), 4368.
Kurtonina, N., & de Rijke, M. (1997). Simulating without negation. Journal Logic
Computation, 7, 503524.
Lutz, C., Piro, R., & Wolter, F. (2011). Description logic tboxes: Model-theoretic characterizations rewritability. International Joint Conference Artificial Intelligence,
Barcelona, Catalonia, Spain, July 16-22, 2011, pp. 983988.
Marx, M. (2004). XPath conditional axis relations. International Conference
Extending Database Technology, Vol. 2992 Lecture Notes Computer Science, pp.
477494. Springer.
Marx, M., & de Rijke, M. (2005). Semantic characterizations navigational XPath. SIGMOD Record, 34 (2), 4146.
Milner, R. (1980). Calculus Communicating Systems, Vol. 92 Lecture Notes
Computer Science. Springer.
Neven, F., Schwentick, T., & Vianu, V. (2004). Finite state machines strings infinite
alphabets. ACM Transactions Computational Logic, 5 (3), 403435.
Olteanu, D. (2007). Forward node-selecting queries trees. ACM Transactions
Database Systems, 32 (1), 3.
Olteanu, D., Meuss, H., Furche, T., & Bry, F. (2002). XPath: Looking forward. International Conference Extending Database Technology, pp. 109127.
Otto, M. (2004a). Elementary proof van Benthem-Rosen characterisation theorem.
Tech. rep. 2342, Fachbereich Mathematik, Technische Universitat Darmstadt.
Otto, M. (2004b). Modal guarded characterisation theorems finite transition
systems. Annals Pure Applied Logic, 130 (1-3), 173205.
Otto, M. (2006). Bisimulation invariance finite models. Logic Colloquium02, Vol. 27
Lecture Notes Logic, pp. 276298.
313

fiFigueira, Figueira, & Areces

Paige, R., & Tarjan, R. (1987). Three partition refinement algorithms. SIAM J. Comput.,
16 (6), 973989.
Park, D. (1981). Concurrency automata infinite sequences. Theoretical Computer
Science, Vol. 104 Lecture Notes Computer Science, pp. 167183. Springer.
Rosen, E. (1997). Modal logic finite structures. Journal Logic, Language
Information, 6 (4), 427439.
Sangiorgi, D. (2009). origins bisimulation coinduction. ACM Transactions
Programming Languages Systems, 31 (4).
ten Cate, B., Fontaine, G., & Litak, T. (2010). modal aspects XPath. Journal
Applied Non-Classical Logics, 20 (3), 139171.
van Benthem, J. (1976). Modal Correspondence Theory. PhD thesis, Universiteit van
Amsterdam.

314

fiJournal Artificial Intelligence Research 53 (2015) 633-658

Submitted 01/15; published 08/15

Placement Loading Stations Electric Vehicles:
Detours Necessary!
Stefan Funke
Andre Nusser

funke@fmi.uni-stuttgart.de
nusser@fmi.uni-stuttgart.de

Universitat Stuttgart
Institut fur Formale Methoden der Informatik
70569 Stuttgart, Germany

Sabine Storandt

storandt@cs.uni-freiburg.de

Albert-Ludwigs-Universitat Freiburg
Institut fur Informatik
79110 Freiburg, Germany

Abstract
Compared conventional cars, electric vehicles (EVs) still suffer considerably
shorter cruising ranges. Combined sparsity battery loading stations, complete transition E-mobility still seems long way go. paper, consider
problem placing loading stations possible shortest path
sufficiently many run energy. show model problem
introduce heuristics provide close-to-optimal solutions even large road networks.

1. Introduction
Battery-powered, electric vehicles (EVs) important means towards reduction
carbon dioxide emissions recharged using renewable energies, e.g. solar wind
power. Despite environmental advantages EVs still wait breakthrough
main reason limited cruising range (often less 200km) together
sparsity battery loading stations (BLSs). Planning trip B EV
nowadays non-trivial undertaking; locations BLSs taken account,
many destinations completely range.
Hence, early phase E-mobility important goal establish network
BLSs using EV becomes worry-free enterprise. modern BLSs require
little space (see Figure 1, left, illustration), placed almost everywhere.
generates costs, natural objective minimize number installed BLSs.
previous work (Storandt & Funke, 2013), heuristic proposed determine BLS
locations one get anywhere anywhere road network without
running energy (when choosing suitable route). Unfortunately, approach
guarantees connectivity reasonability routes. fact, even rather close
destinations routes one recharging stop possible, might require long
detours several recharging stops due placement BLSs. related approach
Lam, Leung Chu (2013) suffers similar drawbacks. long run, E-Mobility
prevail road trip EV undertaken without unreasonable detours
c
2015
AI Access Foundation. rights reserved.

fiFunke, Nusser, & Storandt

Figure 1: Inner-City battery loading station (left image), feasible loading station cover
small map cut-out (right image).

introduced. paper ask placement BLSs
shortest path enough BLSs get stranded starting fully loaded
battery like typically case gas stations conventional cars. call
set BLS locations EV Shortest Path Cover (ESC) define respective
optimization problem follows.
Definition 1 (EV Shortest Path Cover (ESC)). Given (di)graph G(V, E), edge costs
c : E R+ function path decides whether path traveled
along without recharging EV, problem determining minimum subset L V
BLSs every shortest path wrt c traveled without running energy
called EV Shortest Path Cover Problem.
See Figure 1, right, idea valid ESC looks like. remainder
define n = |V | = |E| otherwise noted. Also consider sake
clearer presentation assume unique shortest paths (which enforced using
standard techniques like symbolic perturbation). describe deal ambiguous shortest paths towards end paper. function captures energy
characteristics network considered vehicle. Typically, mountainous areas
roads rough surfaces, minimal paths EV runs energy
considerably shorter flat terrain downhill. experiments determined
energy consumption road segment e = (v, w) E elevations h(v), h(w)
distance(e) + max(h(w) h(v), 0) weighting parameter (dependent
EV). is, energy consumption determined Euclidean distance
height differences, similar energy model used previous work (Artmeier, Haselmayr,
Leucker, & Sachenbacher, 2010) disregarding energy recuperation (negative edge costs).
function compares path accumulated energy consumption along edges
EVs battery capacity B R+ determine recharging necessary. Note
one could employ kind monotonous function here, approaches introduce
following work notwithstanding particular choice.
634

fiPlacement Loading Stations Electric Vehicles

1.1 Contribution
describe model ESC problem instance Hitting Set problem
sets shortest paths require least one battery recharge. allows
us use algorithms developed solving Hitting Set problems, e.g. standard greedy
approach. Unfortunately, turns difficulty computing ESC solution
already instance construction. (n2 ), n = |V | shortest paths network,
extracting storing naively requires much time space practical.
therefore design new shortest path extraction representation techniques,
allow tackle even large road networks. Moreover, develop several refinements
heuristics provide feasible ESC solutions efficiently. priori
approximation guarantee shown solutions, prove posteriori using
instance-based lower bounds real-world instances actual approximation ratio
small constant.
extended version original paper (Funke, Nusser, & Storandt, 2014b),
present following new results insights regarding ESC: prove ESC problem NP-hard (and even hard approximate). proven hardness motivation
justification development heuristic algorithms. Furthermore, explain
transform shortest paths one (newly developed) representation another, along
theoretical run time analysis experiments. ability transform representations allows flexibility might prove useful applications
compact representations shortest paths used. also describe simple minimality
checks shortest paths deciding whether need considered respective Hitting Set instance. Especially large networks, checks reduce number shortest
paths stored significantly. addition, provide details involved
lower bound constructions. Finally, lay methods dealing ambiguous shortest
paths, augmenting already existing loading station set case loading
station locations restricted subset nodes network.

2. Theoretical Analysis
Let us first prove ESC problem NP-hard, hope efficient algorithms
solve ESC optimality (unless P=NP). Hence remainder paper
focus designing algorithms compute good approximate solutions.
Theorem 1 (Hardness). EV-Shortest Path Cover problem (ESC) NP-hard.
prove NP-hardness ESC solution size preserving reduction Vertex Cover
(VC), one classical NP-hard problems. use following definition
notation VC:
Definition 2 (Vertex Cover). Given graph G(V, E), goal find vertex set C V
minimal cardinality e E : e C 6= .
prove Theorem 1, show ability solve ESC problem efficiently implies
ability solve VC efficiently well. Hence, ESC NP-hard otherwise
would contradiction NP-hardness VC. end construct given
635

fiFunke, Nusser, & Storandt

1
1

1

1
1

1
1

1

1

1

1

1

1
1

Figure 2: Left: Vertex Cover instance optimal solution size 3 (red circled nodes).
Right: Respective ESC instance constructed inserting auxiliary edge per
node graph left, augmenting edges cost 1. circled
nodes indicate optimal Hitting Set path cost least 3 unhit.

VC instance Gvc (Vvc , Evc ) corresponding instance ESC specified G(V, E), c
follows:
V = Vvc , E = Evc i.e. ESC instance initially contains nodes edges
VC instance
v V add auxiliary vertex v 0 auxiliary edge {v, v 0 } G
e E set costs c(e) uniformly 1
true paths consisting less three edges false otherwise, i.e. every
shortest path traverses least three edges loading station
make set loading stations feasible ESC
construction requires polynomial time size Gvc . Figure 2 illustrates
transformation Vertex Cover instance ESC instance small example.
first show Vertex Cover solution Gvc also ESC solution ESC
instance constructed described above.
Lemma 1. Vertex Cover C Gvc yields ESC L G, c, |L| = |C|.
Proof. Let C Vvc VC solution Gvc . ESC graph G contains corresponding
vertex every v Vvc , simply set L = C (so obviously |L| = |C|). remains show
placing loading stations according L, every shortest path G traveled
without running energy. Assume contradiction exists shortest path
G consisting three edges {u, v}{v, w}{w, x} neither v w L. every
edge e Evc least one two vertices L (because L = C Vertex Cover
Evc ), follows {v, w} auxiliary edge present G
Gvc . auxiliary edges cannot middle path containing three edges,
every auxiliary vertex degree 1. every path consisting three edges contains
loading station, hence L valid ESC.
complete proof Theorem 1, show valid ESC solution leads
valid Vertex Cover solution well.
636

fiPlacement Loading Stations Electric Vehicles

Lemma 2. ESC L G, c, yields Vertex Cover C Gvc |C| |L|.
Proof. Let L valid ESC solution. L might contain auxiliary vertices, construct
C replacing every auxiliary vertex v 0 L respective original vertex v. v
might also part L, conclude |C| |L|. show C valid Vertex
Cover Gvc , prove every edge {v, w} Evc either v w C.
Assume contradiction exists edge {v, w} Evc {v, w} C = .
Accordingly, neither v, w, respective auxiliary vertices v 0 w0 part
ESC solution L. implies shortest path {v 0 , v}, {v, w}, {w, w0 } three edges
loading station G. contradicts L valid ESC solution, conclude
every edge {v, w} C 6= therefore C valid Vertex Cover.
L optimal solution ESC, obviously |C| = |L| fulfilled Lemma 2,
placing loading station auxiliary vertex v 0 corresponding original vertex v
time renders loading station v 0 superfluous. Hence optimal solution,
never vertices v v 0 L. combination Lemma 1, showed
every instance VC, construct polynomial time instance ESC
optimal solution translates optimal solution VC instance
size straightforward manner. Therefore hardness results VC carry
ESC. proves Theorem 1 furthermore rules existence (1 + )
polynomial-time approximation schemes ESC via proven APX-hardness factor
better 1.3606 VC (Dinur & Safra, 2004):
Corollary 1. ESC cannot approximated better 1.3606.
proven hardness, efficient algorithms solve ESC problem optimality
might difficult design unless one make use certain problem aspects battery
capacity parameter road network characteristics.

3. Modeling ESC Hitting Set Problem
following, aim good approximation algorithms heuristics solve
ESC problem practice. particular, exploit fact ESC modeled
instance well-known Hitting Set problem therefore algorithms suitable
Hitting Set computations transfer ESC. classical Hitting Set (HS) problem defined
follows:
Definition 3 (Hitting Set). Given set system (U, S) U universe elements
collection subsets U , goal find minimum cardinality subset L U
set hit least one element L, i.e. : L 6= .
case, U consists nodes road network (the possible BLS locations).
set composed vertex sets shortest s-t-paths (excluding themselves)
fully charged battery suffice reach t. function characterizes
paths energy consumption traversing exceeds battery capacity
B R+ call paths B-violating. Clearly, need consider set-minimal
paths supersets hit automatically. Theorem 2 shows Hitting Set formulation
indeed solves ESC problem (see also Figure 3 illustration).
637

fiFunke, Nusser, & Storandt

v

B

l
l

v

l


B


B


B


v





Figure 3: shortest path exhibits B-violating prefix (s-v, marked red),
according Hitting Set formulation loading station l
subpath. vehicle fully reloads l, argumentation applies
subpath l-t, illustrated picture cutting prefix
s-l every layer. final s-t-path B-violating anymore. Therefore
originally considered s-t-path traveled visiting three indicated
loading stations. blue Bs mark nodes battery fully loaded,
i.e. charge level equal battery capacity.

Theorem 2 (Correctness). Hitting Set formulation leads feasible ESC solution,
i.e. placing loading stations according Hitting Set solution L, every shortest
path G traversed EV without running energy according .
Proof. Let (s, t) shortest path G B-violating, let EV
fully loaded s. Let (s, v) minimal B-violating prefix (s, t). prefix
hit loading station l L l 6= s, l 6= v demanded Hitting Set
formulation. EV reach l s, (s, v) minimal B-violating prefix l
appears v (s, v). l EV fully re-charged. Hence whole argumentation
transfers subpath (l, t). Applying argument recursively, EV finally
reach loading station (s, t) suffix path longer B-violating.
Therefore EV reach via (s, t) without running energy.

Note precision loss reformulating ESC Hitting Set problem
instance, since every solution ESC feasible solution exactly cardinality
respective Hitting Set problem instance.
point, common Hitting Set solving techniques applied solve ESC, e.g.
standard greedy algorithm. greedy algorithm repeatedly picks node hitting
far unhit sets adds solution. terminates soon sets
hit. solution computed greedy algorithm guaranteed ((ln |S|) + (1))approximation (Chvatal, 1979); ignore lower-order term (1) on.
application, number sets system upper bounded number shortest
paths graph. Therefore, |S| n2 hence greedy algorithm provides
2 ln(n) approximation guarantee. running time greedy algorithm depends
crucially fast access far unhit sets round.
638

fiPlacement Loading Stations Electric Vehicles

112
43

34
16
10
7

11

9
6

1

28





4

Figure 4: Cut-out CH-graph: Black edges original edges, blue edges indicate shortcuts. red node labels reflect contraction order. So, example,
moment node labeled 6 contracted, shortcut node 10 node 9
inserted shortest path 10 9 went 6. right side,
search space query leftmost rightmost node illustrated.
Green edges show Gout (s) purple edges Gin (t).

remainder paper, investigate efficient construction set
system using different path extraction representation schemes study influence
greedy algorithm.

4. Basics Practical ESC Computation
determine suitable BLS positions, first construct set shortest paths
EV would run energy (according ). Computing shortest path
two nodes one nodes classically performed using Dijkstras
algorithm (also shortly called Dijkstra). large street networks Dijkstra slow
process large number queries (as necessary application), though.
Therefore, instrument speed-up techniques developed accelerating shortest path
queries achieve better running times approaches. particular, employ
Contraction Hierarchies (CH) (Geisberger, Sanders, Schultes, & Delling, 2008)
purpose. basic idea behind CH augment graph G(V, E) set E 0
called shortcuts, span (large) sections shortest paths. Using shortcuts instead
original edges allows dramatic reduction operations Dijkstra run.
central operation CH preprocessing node contraction. Considering
graph G(V, E) node v contracted, goal remove v G without
affecting shortest path distances remaining nodes. achieved
creating additional shortcut edges neighbors v follows: every pair
neighbors u, w v (u, v), (v, w) E, shortcut (u, w) created (with cost
path uvw) uvw shortest path u w. resulting graph (with
v removed necessary shortcuts added) exhibits shortest path distances
original graph. CH preprocessing phase instruments node contraction first
assigning label l : V N node. Then, nodes contracted increasing label
order. contracted nodes constructed set shortcuts E 0 way,
639

fiFunke, Nusser, & Storandt

return result preprocessing phase CH-graph G0 (V, E E 0 ), is, original
graph augmented shortcuts (and labeling), see Figure 4 (left) example.
According labels, original shortcut edges (v, w) referred upwards
l(v) < l(w) downwards otherwise; paths called up/downwards consist
exclusively edges type. shown way created shortcuts,
node pair s, V shortest path exists G0 = G(V, E E 0 )
decomposed upward path starting followed downward path ending t;
highest node path wrt l called peak node following. property
path allows restrict bidirectional Dijkstra run Gout (s) Gin (t) refer
subgraphs G0 containing upwards paths starting downwards paths
ending respectively. Figure 4 (right), subgraphs illustrated. resulting
optimal path found bidirectional Dijkstra costs shortest path
original graph. representation path different, path
consists (partly) shortcuts. get shortest path original graph,
unpacking procedure applied. every shortcut, two edges (original shortcut)
directly spans memorized CH construction. Thus, unpacking one
recursively replace shortcuts spanned edges original edges identified.
Note CH scheme also employed represent shortest path
concisely replacing many subpaths possible shortcuts. also call
representation CH-path. experiments turns CH-paths
extremely economic representation scheme shortest paths.
one-to-all shortest path problem, PHAST algorithm (Delling, Goldberg,
Nowatzyk, & Werneck, 2011) also takes advantage CH-preprocessing scheme.
first phase nodes Gout (s) source V settled via Dijkstra run.
second phase downward edges (v, w) relaxed decreasing order induced l(w),
thereby computing correct distances nodes V . second phase simply sweep
subset edges requires linear time. Correctness PHAST results
fact every node shortest path decomposed
upwards path (with contained nodes settled first phase) downwards
path. set downwards edges forms directed acyclic graph labels l(w)
induce topological order, sweep edges order assures moment
edge (v, w) relaxed, node v already settled. Hence PHAST computes exact shortest
path distances nodes network. Note single shortest path query
PHAST method choice, techniques like pure CH-Dijktra computations
normally run time clearly sublinear number edges practice.

5. Construction Set System
section, investigate several strategies extract set system given ESC
instance, i.e. set minimal shortest paths G B-violating. Along
different extraction strategies, present different ways represent store respective
set shortest paths discuss advantages disadvantages representations.
640

fiPlacement Loading Stations Electric Vehicles

5.1 Naive Extraction
simplest approach comes mind compute shortest path tree (via Dijkstra)
every V identify nodes tree accumulated energy cost values
B. nodes priority queue Dijkstra settled predecessors
already belong B-violating paths, abort exploration source s.
respective paths search tree backtracked stored e.g. complete
vertex sets. small exploration radii (small bounds B) practical approach,

larger B space consumption O(n2 n), n = |V | enormous (assuming average

path length n). Even store Dijkstra search tree V via
predecessor labels, still space consumption O(n2 ). course, could easily
achieve linear space consumption number B-violating paths, storing
source vertex target vertex path. want access
nodes certain path, run Dijkstra computation network
t. huge sets paths computing nodes always demand
time-intensive. matter representation use store paths, time
complexity O(n (n log n + m)), = |E| naive extraction already limits usability
real-world instances; O(n log n + m) runtime one Dijkstra run.
fact, also main difficulty Hitting Set-type problems street
networks. example, speed-up techniques shortest path queries like Transit Nodes
(TN) (Bast, Funke, & Matijevic, 2009) Hub Labeling (HL) (Abraham, Delling, Goldberg,
& Werneck, 2012) based hitting certain set shortest paths well. Methods
complete instance construction impractical there. Therefore several custom-tailored
heuristics developed allow efficient computation without explicitly constructing
(Arz, Luxen, & Sanders, 2013). setting differs significantly ours,
setting poses additional criterion c identifying paths contained S. Hence
distance bound employed setting leads set equal length paths,
scenario, due different energy consumption driving uphill downhill,
lengths minimal B-violating paths differ vastly. unfortunately TN HL (and
related) heuristics carry setting. Therefore need explore new
ways extracting storing shortest path sets.
5.2 PHAST-Based Extraction
large bounds B finding B-violating paths source node resembles one-to-all
shortest path problem. PHAST explicitly designed solve task efficiently.
paths backtrack respective search tree CH-representation, i.e.
consist partly shortcuts. huge advantage compared conventional paths
terms storage, shortcuts spanning large portions shortest path
number nodes CH-path significantly smaller (about two orders magnitude
street network Germany). downsides, though: Nodes processed
second phase PHAST l-order increasingly distance; hence incorporating
B stopping criterion seems difficult. Moreover, B large leads paths
vastly differing lengths, (n2 ) lower bound (accumulated) runtime PHAST
every source might already result large overhead. Hence propose different
strategy also based CH potential significantly faster.
641

fiFunke, Nusser, & Storandt

p

B = 10
3

2
3
4
2

1

5

G2
2 ]8,10]

G1

p

9

6
4

7
4

7
8 ]4,8]

3
]7,8]

9

]1,8]

1

Figure 5: Left: Schematic representation CH-graph height nodes indicating contraction order. blue-marked peak p, G1 := Gin (p) colored
red G2 := Gout (p) colored green. Note nodes bottom
layer, G1 G2 empty nothing done (which practice
true 50% nodes). Right: Energy cost labels (black) assigned
G1 G2 resulting two Dijkstra runs starting blue node.
resulting intervals nodes G2 expressed purple. we, example,
search matching targets source node labeled 3 G1 , intervals
reveal node labeled 9 G2 suitable candidate.

5.3 Peak Node Mapping (PNM)
large number B-violating paths originate source V . Exploring
paths Dijkstra PHAST time-consuming. core idea PNM
enumerate B-violating paths completely different also taking CH-representation
paths consideration. explained above, shortest CH-paths unimodal respect
labeling l node maximal label called peak. Intuitively, nodes
high label appear shortest paths peaks. fact, real-world graphs,
5% nodes highest level constitute peaks reasonably long shortest paths.
gives rise path enumeration algorithm, explores paths source
peak, resulting dramatically reduced search spaces majority nodes.
Algorithm. PNM algorithm works follows: consider one one every node
p V potential peak. shortest paths peak p contain nodes
smaller label, need search upwards paths ending p downwards paths
starting p prefix suffix candidates. respective subgraphs CH-graph
G0 containing paths called G1 := Gin (p) G2 := Gout (p), see Figure 5, left,
illustration. conventional Dijkstra run G1 G2 (which typically
sparse) reveals distances p contained nodes. interested
combinations shortest (upward) paths G1 shortest (downward) paths G2
leading minimal B-violating paths. Testing naively expensive. Therefore,
construct p interval tree (Berg, Cheong, Kreveld, & Overmars, 2008)
nodes G2 . interval ]a, b], associate node t, denotes range
possible energy consumption values path prefix (s, p) G1 (s, p) (p, t)
minimal B-violating path. intervals easily computed single pass
Dijkstra search tree G2 , see Figure 5, right, example. every possible
642

fiPlacement Loading Stations Electric Vehicles

Figure 6: Illustration three methods representing storing shortest paths (stored
elements always colored orange): left complete vertex set,
middle shortcut set/CH-path (the heights vertices image correspond l-value), right triple consisting source, target
peak vertex.

source G1 , query interval tree set targets time O(log(|G2 |) + |T |)
storing resulting paths quadruples (s, p, t, c(s, p) + c(p, t)), . Note
employment interval trees make use special choice . different choices
interval computation procedure adapted.
Filtering. nodes processed, set B-violating paths which,
unfortunately, shortest paths. concatenation two shortest paths ((s, p)
(p, t)) need shortest path itself. remains filter set
appropriately. achieved using distance oracles quasi constant look-up
time e.g. provided HL another pass nodes role peak, always
pruning quadruple s, shorter path found p0 6= p. Note, pruning
already employed construction phase intermediate path set sizes
become large. final set paths stored list triples (s, p, t) even
compact representation CH-representation. Figure 6, visual comparison
provided storing path vertex set, shortcut set, PNM triple.
Accessing nodes respective shortest s-t-path G required greedy
Hitting Set algorithm longer trivial sophisticated representation schemes,
though. Therefore, develop suitable adaptions greedy algorithm work
CH-representations PNM triples Section 6.
5.4 Minimality Checks
mentioned introducing Hitting Set formulation ESC, need extract
store minimal B-violating shortest paths, i.e. paths subpath B-violating
well. Adding non-minimal paths set system course invalidate
solution, increases complexity storing sets, running time greedy
algorithm later on.
naive extraction scheme, B-violating path = sv1 . . . vk identified Dijkstra run might minimal, path might still B-violating without
prefix. precisely, check path remains B-violating removing
first edge (s, v1 ), so, dont include S. respective Dijkstra run
considering v1 source ensure B-violating path missed.
643

fiFunke, Nusser, & Storandt

PHAST-based extraction, minimality check becomes complex.
paths CH-representation, might direct access first edge path
original graph (if path starts shortcut). unpack first
shortcut performing minimality check.
PNM prefix suffix deletion might lead subpath still B-violating.
immediately decision favor triple (s, p, t), check first edge
path p last edge path p removal
destroy property path B-violating. Again, like PHAST, paths
CH-representation construction, therefore unpack shortcuts first.
5.5 Transformability
Note, extraction scheme tie us certain path representation. fact,
mentioned representations (vertex sets, source-target-pairs, CH-paths, triples)
converted other. Especially transformation vertex sets CH-paths
turn favorable, CH-paths yield fair trade-off space consumption
applicability greedy algorithm explained detail Section 6.
provide details transformations including theoretical transformation times.
latter assume complete vertex set representation contains k elements.
source-target-pairs vertex sets. Given s, t, complete path computed via
Dijkstra run G backtracking, requiring O(n log n + m) time.
vertex sets CH-paths. assume CH-labels l : V N available.
recursive procedure allows turn vertex set CH-path. first
identify node v0 vertex set highest l-value (the peak).
split vertex set prefix v0 suffix v0 .
sub-paths search node highest l-value, providing us
v1 , v2 . two nodes connected v0 via direct edge/shortcut CHgraph (as nodes contracted before), (v1 , v0 ), (v0 , v2 ).
provides us prefix (nodes v1 ) suffix (nodes v2 )
recurse. algorithm stops prefix suffix
(or prefix monotonously increasing wrt l suffix monotonously
decreasing), see Figure 7, top, illustration. Assuming CH-representation
contains h shortcuts, transformation performed O(k h).
CH-paths PNM triples. need extract peak vertex (besides
source target) done O(h) CH-path consists h shortcuts.
PNM triples CH-paths. Given source s, target t, peak p, run Dijkstra
starting p G1 := Gin (p) G2 := Gout (p) settled.
number edges CH-graph assumed O(m), runtime single
transformation O(n log n+m) like transformation source-targetpairs vertex sets. typically peak small l-value small G1
G2 , peak high l-value generates many s-t-paths once, amortized
costs per path considerably smaller.
644

fiPlacement Loading Stations Electric Vehicles

Figure 7: vertex sets CH-paths back. first row, vertex set given.
l-values derived CH construction indicated vertex elevations.
recursively vertex highest l value (marked red images)
prefix suffix path extracted shortcuts added span
path sections lower l-value. second row, CH-path recursively
unpacked. Shortcuts colored blue. red arrows point replacement
edges next unpacking step. final path started
first row, contain shortcuts.

CH-paths vertex sets. Given CH-path, apply unpacking method
described Section 4, i.e. recursively replace shortcuts spanned edges
path consists original edges (see Figure 7, bottom). resulting
path consists k vertices, unpacking performed O(k).
vertex sets source-target-pairs. first last vertex complete
path stored rest neglected. transformation costs O(1) O(k)
consider deletion k 2 elements well.
following, longer investigate source-target pair representation,
storing PNM triples requires one item per path time allows
efficient access paths vertices.

6. Greedy Hitting Set Computation
explained above, greedy approach natural strategy solve Hitting Set
problem approximately. Theoretically yields solutions within factor 2 ln(n)
optimum setting. practice greedy performs much better theoretical,
priori approximation guarantee implies.
simplest set system representation application greedy Hitting
Set algorithm straightforward requires deliberate operations set
system/path representations see following.
6.1 Complete Vertex Sets
paths simply given set contained vertices, single scan
sets determine best node hitting paths. Another scan remove paths
645

fiFunke, Nusser, & Storandt

hit selected node. two scans also combined one
updating counter values removing newly hit paths (an initial count
still necessary). Unfortunately, space consumption approach enormous, also
making single scan quite expensive.
6.2 CH-Paths
representing minimal B-violating paths CH-paths, could convert single
paths original paths unpacking shortcuts operate complete
vertex set path. Note paths would processed one one one
unpacked path would kept memory time. much better strategy
uncompressing every single CH-path get original node sets: maintaining
usage counter edge (counting many shortest paths use edge), first
scan edges CH-paths set system hit, incrementing respective
counters. traverse shortcut edges graph decreasing order
construction CH-preprocessing, incrementing counters spanned edges.
node counters, maintained identify maximum node, derived final
scan original (non-shortcut) edges. Keeping reverse information edges
spanned shortcut also allows identification sets hit
node. update edge counters removing CH-paths set, picking
node requires one scan edges push counts non-shortcut
edges, one scan usage counters one scan set CH-paths.
6.3 Peak Node Triples
paths described triples source, target, peak node, get CHpath representation described Section 5.5. proceed CH-path
representation. Note, CH-path representation computed demand
peak every round avoid keeping paths CH-representation permanently memory.

7. Multi-stage Construction
country-sized graphs, even improved set system extraction methods representations reduce space time consumption enough practical. Therefore
introduce procedure interleaves set extraction greedy Hitting Set
computation multi-stage algorithm. multi-stage algorithm requires significantly
less space complete construction set system, therefore applied
considerably larger instances.
7.1 Nested Hitting Sets
instance ESC problem determined battery capacity B, make
following important observation: every capacity B 0 B, Hitting Set L0
instance corresponding B 0 also feasible original instance (having enough BLSs
smaller battery capacity also suffices larger battery capacity). So, example,
B = 20kWh, solving problem e.g. B 0 = 5kWh would feasible well.
construction L0 B 0 B might considerably faster due smaller exploration
646

fiPlacement Loading Stations Electric Vehicles

4

4

4


6



6

5

6



B 0 = 5, B B 0 = 15



B 0 = 10, B B 0 = 10



B 0 = 13, B B 0 = 7

4
5

2
4

B = 20

4

2
4



5

2

4
5

2
6

Figure 8: battery capacity B = 20 kWh, shortest path needs
hit loading station exhibits energy costs 21. conventional
construction, complete s-t-path would part Hitting Set instance.
three lower images illustrate happens use nested construction different values B 0 . red+purple/dashed subpath indicates
minimal B 0 -violating path starting s. brown square possible hitter
path. purple/dashed+blue path indicates minimal (B-B 0 )-violating
path starting brown square. path always subpath s-t matter B 0 chosen. hitting blue+purple path (large dot image)
assures B-violating paths hit well. nodes marked brown
squares part final solution.

radii, L0 typically also much larger necessary instance defined B.
simply using solution B 0 = 5kWh although real battery capacity B = 20kWh,
expect result many superfluous loading stations.
another advantage first quickly computing Hitting Set small value
B 0 : allows us construct new, smaller problem instance feasible Hitting
Set L00 also feasible original problem (defined B) L00 hopefully much
smaller L0 . second instance defined set paths originating L0
(B-B 0 )-violating.
prove Lemma 3 Hitting Set L00 second instance indeed also
Hitting Set original instance.
Lemma 3. Given battery capacity B, second capacity B 0 < B. Let L0 feasible
ESC solution B 0 , L feasible Hitting Set minimal shortest (B-B 0 )-violating
paths originating L0 , L valid ESC solution battery capacity B.
Proof. Consider B-violating s-t-path original instance. must hit
node v L0 less B 0 away s. path v, . . . , hitter
target (or prefix thereof) new constructed path set (B-B 0 )-violating
paths originating L0 . Therefore subpath hitter L. Hence L hits Bviolating shortest path, makes L valid ESC solution battery capacity B. Figure
8 illustrates proof small example.
647

fiFunke, Nusser, & Storandt

7.2 Path Cover
small values B, even compute Hitting Sets without exploration
evaluation function purely based connectivity structure graph using
so-called k-Hop Path Cover (Funke, Nusser, & Storandt, 2014a) generalization
Vertex Cover. construct set vertices C V directed (not
necessarily shortest) k-hop path G contains least one vertex C (for k = 1
simply Vertex Cover). C ESC solution B B maximal energy
cost k-hop path, easily upper bounded k times maximal energy
cost edge. values k 48 takes minutes even large graphs using
variant depth first search, making step negligible overall running time.
7.3 Combination
implementation combined nested Hitting Sets k-Hop Path Covers multistage procedure, constructing sequence Hitting Sets Lr , Lr1 , , L1 = L sequence
values Br < Br1 < < B1 = B, finally returning L Hitting Set given
instance.
first Br results k-Hop Cover small value k, subsequent solutions
apply nested Hitting Set approach (and choose Bi manually). might
loss terms quality compared greedy algorithm full set system due
nested construction. experimental evaluation show, though, loss terms
quality pronounced, running times drastically improved,
graph sizes handle approach much larger.

8. Refinements Lower Bounds
section introduce speed-up strategy greedy algorithm independent employed set representation. develop algorithms construct
instance-based lower bounds ESC solution. bounds helpful
experimental evaluation, prove posteriori, running algorithms
computed solutions fact pretty close optima.
8.1 Multiple Hitters Heuristic
Even non-naive representations, considerable work involved picking
next best node greedy algorithm. might worthwhile add several
nodes Hitting Set round. Normally, pick node hits
far unhit sets, refrain picking nodes round picking
first node influences hit counters others. hand, pick nodes
interfere other, quality solution decline severely.
One way achieve generate list nodes sorted ascending order
hit counters, always picking first one going list selecting next
nodes shortest path distances least nodes already picked.
appropriately chosen, e.g. upper bound longest shortest path
B-violating. Thereby make sure path set increased hit counter two
nodes picked one round.
648

fiPlacement Loading Stations Electric Vehicles

Figure 9: Set seven node-disjoint B-violating paths (highlighted grey) small example graph. Every valid Hitting Set B-violating paths graph
contain least seven vertices, vertex hit one grey
marked paths. Therefore size set node-disjoint paths feasible lower
bound optimal Hitting Set size.

8.2 Simple Instance-Based Lower Bounds
evaluate quality heuristics, would like compare outcome
optimal solution. optimal value typically unknown, instead compare
good, easily computable lower bound. study Transit Nodes (Eisner & Funke,
2012) rather involved lower bound proposed, takes effort comparable
solving Hitting Set problem itself. propose much simpler alternative suffices
purposes: by-product generation set system obtain
set node-disjoint B-violating paths. two paths set non-empty
intersection. Clearly, feasible solution must contain extra node per path set.
Hence size set node-disjoint paths yields valid lower bound, see Figure 9
illustration.
case generate set system explicitly (because use nested Hitting Sets),
greedily extract set node-disjoint paths running Dijkstra computations
random sources adding B-violating paths set long intersect
previously selected ones. size set provides valid lower bound time.

9. Dealing Real-world Settings
Throughout paper, made assumptions ESC problem sake
clean definition easier algorithm descriptions. assumptions necessarily
met practice, explain following adapt algorithms still perform
well real-world settings.
649

fiFunke, Nusser, & Storandt

9.1 Ambiguous Shortest Paths
exposition always assume uniqueness shortest paths. section
discuss necessary modifications case shortest paths ambiguous.
First all, enforce uniqueness shortest paths symbolic perturbation.
end define cost path = v0 v1 . . . vk sum c edge costs,
vector (c , v0 , v1 , . . . , vk ). Two cost vectors compared lexicographically,
is, two t-paths 1 = sv1 . . . 2 = sw1 . . . aggregated edge
costs, minimal vi 6= wi , 1 considered shorter vi < wi , otherwise
2 considered shorter. symbolic perturbation easily incorporated e.g.
Dijkstras algorithm. computation shortest paths node consider
(possibly tentative) distance label node v aggregated edge costs
ds (v) along respective path tuple (ds (v), preds (v)), preds (v) denotes
predecessor current path v. ordering case identical ds (v) values
determined node ID predecessor. Edge relaxations well organization
priority queue made according augmented distance labels. easy
see yields canonical unique shortest paths described above.
edge lengths typically measured precision around one meter rarely happens two paths exhibit exactly length. circumstances, though,
might desirable actually maintain multiple shortest paths nodes (hitting
/ allowing travel along without running energy). Fortunately, adapt algorithms cater shortest paths. minimal
change backtracking Dijkstra exploration well PNM approach
slight change CH construction. former, retrieve paths/sets, instead
following predecessor reference node v (which set edge relaxation),
inspect adjacent nodes check whether distance labels respective edge
cost sums distance label v. yields neighbors v lie shortest
path v. Recursing neighbors obtain shortest paths. CH
construction, crucial operation contraction node v. original version,
every pair neighbors u, w v (u, v), (v, w) E, shortcut (u, w) created
(with cost path uvw) uvw shortest path u w. maintain
shortest paths, add shortcut uvw shortest path u w (but possible
existence shortest paths). way every shortest path CH representation;
comes cost slightly shortcuts added.
lower bound construction Section 8.2 modified also yield lower bound
case ambiguous shortest paths follows: s-t-pair contribute
lower bound shortest paths require least one recharging event.
compute valid lower bound retrieve maximal set vertex pairs,
two vertex pairs set respective shortest path node sets allowed overlap.
generalizes idea node-disjoint shortest paths case ambiguous shortest paths.
experiments showed, though, considering shortest paths yield
noticeably different results mainly due rarity reasonably long ambiguous shortest
paths. disregard ambiguities implementation, extremely small
battery capacities (corresponding cruising range less 2km), found ambiguous
650

fiPlacement Loading Stations Electric Vehicles

shortest paths covered BLS placement. larger battery capacities
BLS placement fact covered (of few) ambiguous shortest paths.
9.2 Restricted Loading Station Placement
assume ESC problem definition loading stations placed every
node network. practice, though, set possible locations might restricted
due technical, financial legal reasons. set V 0 V candidate nodes
loading stations, incorporate algorithms follows: construction
set system, check every shortest path whether least one nodes
V 0 . Otherwise, ignore path completely (as never hit anyway).
CH-based extraction methods, set flag every edge/shortcut indicating whether
spanned path contains node V 0 not. allows perform check
CH-path without unpack it. actual Hitting Set computation simply
skip nodes V 0 compute feasible solution.
Note, depending choice V 0 final Hitting Set might allow drive
shortest paths without running energy, though. incorporate
locations suitable become loading stations others without losing global
reachability demanded ESC problem formulation, introduce prize function
p : V R+ . higher prize complicated expensive place
charging station node. exploit weighted Hitting Set problem
basis computations. goal find set L elements
P universe
hit sets set system minimizing accumulated prize p(l).
set system extraction methods remain unaffected prizes. greedy Hitting
Set computation step, selection next best hitter changes. Previously, selected
node next hits far unhit sets. Now, S(v) denotes set far unhit
sets contain v, select node minimizes average prize per set p(v)/|S(v)|.
approximation guarantee greedy algorithm weighted Hitting Set problem
unweighted Hitting Set problem (Chvatal, 1979). expect
solution consist mainly cheap charging stations possibly expensive ones
required establish reachability two nodes.
9.3 Placement Given Initial Loading Station Set
Another assumption made ESC problem definition try construct
network loading stations scratch, i.e. starting loading stations all.
loading stations still sparse many areas, ones already installed
ignored. Existing loading stations easily taken account solving
ESC problem: given initial set loading stations L0 , check extraction
set system path already hit L0 . case, path
pruned. remaining steps Hitting Set computation work like before.

10. Experimental Evaluation
proposed techniques computing ESC solutions evaluated multi-threaded
implementation written C++ executed 2nd generation Intel Core desktop hard651

fiFunke, Nusser, & Storandt

ware, i7-3930 (6 cores, 64GB RAM) complete set generations i7-2700 (4
cores, 32GB RAM) multi-stage construction nested Hitting Sets. use
following abbreviations state results: K=103 , M=106 , s=seconds, m=minutes, h=hours,
d=days, GB=109 Bytes. distinguish CPU time (total CPU usage) real time
(wall clock time). Several road networks Germany derived OpenStreetMap data
region
Pforzheim
Tubingen
Baden-Wurttemberg South
Southern Germany
Germany

abb.
(PF)
(TU)
(BW)
(SG)
(GE)

|V |
0.2M
0.5M
2.2M
4.2M
17.7M

|E|
0.4M
1.0M
4.6M
8.6M
36.0M

Table 1: Test graph characteristics.
(OSM, 2015) used evaluation, see Table 1 overview. edge cost function
c used travel time along edge, paths hit indeed quickest paths (the
term shortest paths conventionally used subsuming kinds metrics). Energy consumption EV modeled explained introduction using distance data
OSM elevations provided Shuttle Radar Topography Mission (NASA, 2015). B
corresponds battery capacity translates certain terrain dependent cruising
range. use capacity B PF TU allows drive 40 kilometers average,
125 kilometers larger graphs. , models much going uphill
increases energy consumption, equals 4.
10.1 Dealing Complete Set Systems
Construction Representation. Let us first examine time space complexity
extracting complete set minimal B-violating paths. constructed set systems
using naive strategy (NAIVE representing path complete sequence
vertices), PHAST-based exploration (PHAST paths CH representation),
peak node mapping (PNM representing path source,peak,target triple).
respective results found Table 2. Unfortunately, two smallest instances
feasible process using strategies; already BW graph, time space
consumption NAIVE exploded (extrapolated 500GB 23 CPU
days). comparison, PHAST factor 3 faster NAIVE, space
consumption CH-paths improvement least order magnitude. PNM
construct BW instance 4.4 CPU hours, compared week needed PHAST,
space consumption using triples decreases another factor 2 (note longer
paths advantage PNM vs. CH representation increases). SG GE, also
PHAST PNM took much time space (e.g. extrapolated 557GB/112days
PHAST). larger networks, constructing complete set systems seems infeasible.

Comparison Path Representations. explained Section 5.5, path extraction
scheme tie us path representation. Instead, transform extracted
652

fiPlacement Loading Stations Electric Vehicles

Graph

PF
TU
BW
Graph

PF
TU
BW

# paths

38M
168M
2715M

space consumption
NAIVE
PHAST
PNM
vertex sets CH-paths
triples
5.2GB
0.2GB
0.1GB
24.0GB
2.1GB
0.9GB
[526.3GB]
34.6GB 14.3GB

computation time
NAIVE
PHAST
PNM
CPU
real
CPU
real
CPU
real
1.5h
0.3h 26.7m 5.0m
1.8m 25.1m
24.6h
4.1h
7.5h
1.4h 27.3m
5.4m
[23.1d] [3.9d]
7.5d 33.1h
4.4h 47.0m

Table 2: Comparison path extraction/representation schemes. B corresponds
40km (PF TU) 125km (BW) cruising range flat terrain. Timings include
CH-construction PHAST/PNM. Values brackets extrapolated.

paths introduced representations storing them. representation
provides trade-off space consumption access times single paths. Figure
10 illustrates values small large benchmark instance (TU GER).
Note, access times paths represented triples amortized. really
want extract single path only, costs comparable ones (s, t)
representation. greedy algorithm, require access huge sets paths
every round, (s, p, t) representation pays off. CH representation, access
times reported figure purely completeness. significant
greedy Hitting Set computation, though, specialized greedy algorithm CH paths
require unpack paths. fact, access times relevant greedy
algorithm even ones vertex set representation, CH representation
contains far less elements sweep over. Hence, regard CH-paths best
path representation soon set system fits memory representation.
transformation times two path representations estimated
results reported Figure 10 well. Every transformation runs constant linear
time according analysis cost less comparable accessing paths vertex
set representation. transformation time CH-paths vertex sets vice versa
corresponds access time paths CH representation. transform triples
CH-paths, need time access path triple form minus time unpack
CH-path.
Hitting Set Computation. evaluated standard greedy algorithm well
multiple hitters (MH) variation set systems PF, TU, BW varying choices
B. Figure 11 shows performance terms quality (standard greedy vs. MH)
well running time (how much faster MH compared standard greedy). ratios
averaged test graphs; bound B chosen almost zero 60 percent
653

fiFunke, Nusser, & Storandt

Figure 10: Comparison several path representation schemes terms space consumption access time. axes log scale.

maximum energy consumption shortest path respective network (in fact
long paths, set systems got simple greedy even constructed optimum,
hence approximation ratio 1 Figure 11). cases, greedy produces results much
closer optimum theoretical 2 ln n guarantee, maximum deviation
lower bound indeed less 4.5. Employing MH strategy increases HS size
slightly, yields significantly decreased running times especially smaller bounds B
(where hitters chosen). Still, compared construction time
set systems, Hitting Set computation times negligible, state
explicitly here. change employ multi-stage construction, though.
10.2 Multi-stage Construction
construction complete set system proven infeasible larger road
networks, make use idea multi-stage construction.
k-Hop Cover+PNM. Let us first examine compact set system constructed
using PNM approach initial k-Hop Path Cover. BW network
computed k = 32-Hop Cover C (146, 494 nodes) corresponds ESC solution
B 0 = 8832 (and cruising range 9km flat terrain). PNM used
create final compact set system considering (B B 0 )-violating paths start
nodes C. surprisingly, number paths hit reduces drastically
2715M Table 2 24M Table 3. running times still quite high, though,
approach save exploration peak (therefore stages
654

fiPlacement Loading Stations Electric Vehicles

40
35
runtime ratio

6
quality greedy
quality MH
runtime greedy/runtime MH

5

30
4

25
20

3

15
10

2

approximation factor

45

5
0

1
10

20
30
40
percentage max B

50

60

Figure 11: Performance greedy algorithm multiple hitters variant (MH)
averaged PF, TU BW.
Graph
BW
SG
GE

|C|
146,494
180,455
769,760

B0
8832
10048
15808

CPU
2.2h
6.0h
64.8h

real
35.5m
2.8h
27.6h

# paths
24M
75M
1085M

Table 3: Instance creation (B = 40K) via PNM initial k-hop solution C k = 32.
help much here). Since improvements terms running time using PNM
multi-stage approach cannot expected, let us concentrate naive approach
extracted paths converted CH-representation.
Multi-Stage Hitting Sets. employ following strategy: first, construct k-Hop Cover
C e.g. k = 32 yields initial Hitting Set Lr bound Br .
construct reduced set system consisting (Br1 Br )-violating paths starting
nodes Lr compute Hitting Set Lr1 set system. Here, use naive
Graph
TU
SG
TU
SG
GE
GE
GE

Br


1.8k
4.2k
15.8k
6.2k
15.8k

Bi nested HS
1k,5k,40k
2k,10k,125k
4.8k,40k
12.2k,125k
17.8k,33.8k,125k
8.2k,24.2k,125k
17.8k,25.8k,49.8k,125k

|L|
120
106
116
110
868
728
1212

LB
33
33
33
33
190
190
190

APX
3.64
3.21
3.52
3.33
4.57
3.83
6.38

CPU
9m
404m
8m
242m
908m
1156m
645m

real
3m
106m
2m
63m
265m
322m
209m

Table 4: Multi-stage Hitting Set computation (LB = lower bound, APX = approximation
factor). last two experiments seen detail Table 5.

655

fiFunke, Nusser, & Storandt


4
3
2
1
P

Bi
6.2k
8.2k
24.2k
125k


5
4
3
2
1
P

Bi
15.8k
17.8k
25.8k
49.8k
125k

tSS

363m
249m
467m
1079m
tSS

203m
101m
81m
146m
531m

#paths

34.6M
36.8M
13.5M

#paths

19.7M
17.1M
9.2M
5.6M


tHS
14s
25m
21m
31m
77m
tHS
36s
25m
21m
17m
50m
113m

|Li |
1388k
223k
16k
728

|Li |
770k
208k
38.6k
8445
1212


CPU
14s
388m
270m
498m
1156m
CPU
36s
228m
122m
98m
196m
645m

Table 5: Statistics 4-stage run starting k = 16-Hop Cover (above), 5stage construction initialized k = 32-Hop Cover (below) GE. column
#paths gives number sets hit respective stage. tSS tHS
denote CPU time set system construction Hitting Set computation
respectively.

extraction transform vertex sets CH-paths efficient storage. proceed
iteratively reaching B1 = B final Hitting Set L1 = L. intuitive demand
gap B2 B1 large make sure last Hitting Set
instance still faithfully characterizes original Hitting Set instance. Table 4 shows
results various choices multi-stage parameters. Table 5 give detailed
account intermediate calculations large GE graph. experiments confirm
larger gap B2 B1 is, better quality final Hitting
Set. comes cost expensive last stage, though. contrast
experiments, first two calculations Table 4 conducted without initial
k-Hop Cover. results obtained TU SG suggest initial k-Hop Cover
accelerates calculation maintaining similar Hitting Set size. Furthermore,
APX values remain low even though lower bounds obtained naive way.
Note example graph Germany, priori approximation guarantee
plain greedy algorithm (which feasible due excessive running time space
consumption) 2 ln n 19.5. proves excellent quality Hitting Sets
particular instances. Table 5 shows introducing multiple stages keeps intermediate
set systems rather compact, efficient computation actually possible.

11. Conclusions Future Work
showed model solve natural important facility location problem
E-mobility context, taking radically different approach previous ones avoiding
detours loading stations EVs.
656

fiPlacement Loading Stations Electric Vehicles

naive strategy allows solution small instances hundred
thousand nodes, compact representation schemes underlying set systems
heuristic modifications standard greedy approach make computation solution
even country-sized networks like Germany possible. Instance-based lower bounds
certify solution quality close optimal (within factor 4) far
pessimistic theoretically achievable approximation bound. fact remarkable
all, possible compute 4-approximate solution seemingly intractable Hitting
Set problem within hours quadcore desktop PC. computation determined
around 800 locations placing BLSs would establish complete coverage Germany.
framework require metric decides shortest paths
hit identical metric determines paths shortest. fact
factored using function, depending application scenario
also used implement hitting criteria (e.g. hop distances risk values).
future work intend examine exact hitting requirement relaxed.
Naturally, necessary always BLS right respective shortest
path, nearby one suffices. could modeled enlarging vertex sets
respective shortest paths surrounding vertices. Hitting Set sizes variant
expected considerably smaller hitting shortest paths directly. Another
direction research take account capacity constraints BLSs (Lam et al.,
2013); particular urban areas certainly necessary provide recharging stations
large number vehicles.

References
Abraham, I., Delling, D., Goldberg, A. V., & Werneck, R. F. (2012). Hierarchical hub
labelings shortest paths. European Symposium Algorithms (ESA), pp. 24
35. Springer.
Artmeier, A., Haselmayr, J., Leucker, M., & Sachenbacher, M. (2010). shortest path
problem revisited: Optimal routing electric vehicles. German Conference
Artificial Intelligence (KI), pp. 309316.
Arz, J., Luxen, D., & Sanders, P. (2013). Transit Node routing reconsidered. International
Symposium Experimental algorithms (SEA), pp. 5566. Springer.
Bast, H., Funke, S., & Matijevic, D. (2009). Ultrafast shortest-path queries via Transit
Nodes. shortest path problem : 9th DIMACS implemenation challenge, Vol. 74
DIMACS Series Discrete Mathematics Theoretical Computer Science, pp.
175192, Providence, RI. AMS.
Berg, M. d., Cheong, O., Kreveld, M. v., & Overmars, M. (2008). Computational Geometry:
Algorithms Applications (3rd ed. edition). Springer-Verlag TELOS, Santa Clara,
CA, USA.
Chvatal, V. (1979). greedy heuristic set-covering problem. Math. Oper. Res.,
4 (3), 233235.
657

fiFunke, Nusser, & Storandt

Delling, D., Goldberg, A. V., Nowatzyk, A., & Werneck, R. F. F. (2011). PHAST: Hardwareaccelerated shortest path trees. International Parallel Distributed Processing
Symposium (IPDPS), pp. 921931.
Dinur, I., & Safra, S. (2004). hardness approximating minimum Vertex Cover.
Annals Mathematics, 162, 2005.
Eisner, J., & Funke, S. (2012). Transit Nodes - lower bounds refined construction.
Algorithm Engineering Experiments (ALENEX).
Funke, S., Nusser, A., & Storandt, S. (2014a). k-Path Covers applications.
International Conference Large Databases (VLDB).
Funke, S., Nusser, A., & Storandt, S. (2014b). Placement loading stations electric
vehicles: detours necessary!. AAAI Conference Artificial Intelligence.
Geisberger, R., Sanders, P., Schultes, D., & Delling, D. (2008). Contraction Hierarchies:
faster simpler hierarchical routing road networks. International Workshop
Experimental Algorithms (WEA), pp. 319333. Springer.
Lam, A., Leung, Y.-W., & Chu, X. (2013). Electric vehicle charging station placement.
International Conference Smart Grid Communications (SmartGridComm), pp.
510515.
NASA (2015). Shuttle Radar Topography Mission. Online. http://www2.jpl.nasa.gov/srtm.
OSM (2015). OpenStreetMap Project. Online. http://www.openstreetmap.org.
Storandt, S., & Funke, S. (2013). Enabling E-Mobility: Facility location battery loading
stations. Conference Artificial Intelligence (AAAI).

658

fiJournal Artificial Intelligence Research 53 (2015) 1-40

Submitted 08/14; published 05/15

Coactive Learning
Pannaga Shivaswamy

pshivaswamy@linkedin.com

LinkedIn Corporation
2029 Stierlin Ct
Mountain View, CA 94043, USA

Thorsten Joachims

tj@cs.cornell.edu

Department Computer Science
Cornell University
Ithaca, NY 14853, USA

Abstract
propose Coactive Learning model interaction learning system
human user, common goal providing results maximum utility
user. Interactions Coactive Learning model take following form:
step, system (e.g. search engine) receives context (e.g. query) predicts object
(e.g. ranking); user responds correcting system necessary, providing slightly
improved necessarily optimal object feedback. argue preference
feedback inferred large quantity observable user behavior (e.g., clicks
web search), unlike optimal feedback required expert model cardinal
valuations required bandit learning. Despite relaxed requirements feedback,
show possible adapt many existing online learning algorithms
coactive

framework. particular, provide algorithms achieve O(1/ ) average regret
terms cardinal utility, even though learning algorithm never observes cardinal utility
values directly. also provide algorithm O(log(T )/T ) average regret
case -strongly convex loss functions. extensive empirical study demonstrates
applicability model algorithms movie recommendation task, well
ranking web search.

1. Introduction
wide range systems use today, interaction human system takes
following form. user issues command (e.g. query) receives possibly
structured result response (e.g. ranking). user interacts results (e.g.
clicks), thereby providing implicit feedback users utility function. three
examples systems typical interaction patterns:
Web Search: response query, search engine presents ranking [A, B, C, D, ...]
observes user clicks documents B D.
Movie Recommendation: online service recommends movie user. However,
user rents movie B browsing collection.
Machine Translation: online machine translator used translate wiki page
language B. system observes corrections user makes translated text.
c
2015
AI Access Foundation. rights reserved.

fiShivaswamy & Joachims

examples, user provides feedback results
system. However, feedback incremental improvement, necessarily
optimal result. example, clicks web search results infer
user would preferred ranking [B, D, A, C, ...] one presented. However,
unlikely best possible ranking. Similarly recommendation example,
movie B preferred movie A, may even better movies
user find browsing. machine translation example, corrected text need best possible translation language language B.
three examples, algorithm typically receives slightly improved result user
feedback, necessarily optimal prediction cardinal utilities. conjecture
many applications fall schema, ranging news filtering personal
robotics.
paper, propose Coactive Learning model system-user interactions.
formalize Coactive Learning general model interaction learning system
user, define suitable notion regret, validate key modeling assumption
namely whether observable user behavior provide valid feedback model
user study web search. new model viewed cooperative learning process
system user, parties aim optimize utility lack means
achieve goal own. Specifically, (boundedly rational) user computationally
limited maximizing utility space alternatives, system limited
well knows users utility function.
proposed online learning framework differs significantly existing online learning
models terms observed feedback (see related works section comparison).
strength proposed framework possible derive wide range coactive
learning algorithms adapting existing online algorithms convex optimization.
provide template Coactive Learning algorithms show several instances
template paper, case, prove worst case analysis
algorithm carries conventional online learning framework coactive
learning despite differences two models.In particular, cases linear
utility models convex cost functions show O(1/ ) regret bounds matching
lower bound. also show regret bound improved second order
algorithm strongly convex functions. learning algorithms perform structured output
prediction (see Bakir, Hofmann, Scholkopf, Smola, Taskar, & Vishwanathan, 2007) thus
applied wide variety problems. study several interesting extensions
framework using batch updates, expected feedback, exponentiated learning
algorithm. Finally, provide extensive empirical evaluations algorithms movie
recommendation web search task, showing algorithms highly efficient
effective practical settings.
rest paper organized follows. discuss related work Section 2.
Section 3 formally introduce coactive learning model also motivate model
real-world user study. present linear version algorithm along
several extensions Section 4. Section 5, detail general schema deriving
coactive learning algorithms regret bounds. particular, derive exponentiated gradient algorithm Section 5.1, propose coactive learning algorithms
minimizing general convex losses -strongly convex losses Sections 5.2 5.3.
2

fiCoactive Learning

empirical evaluation proposed framework algorithms done Section 6
conclude Section 7. include proofs Appendix.

2. Related Works
Coactive Learning Model bridges gap two forms feedback
well studied online learning. one side multi-armed bandit model (e.g.,
Auer, Cesa-Bianchi, Freund, & Schapire, 2002b; Auer, Cesa-Bianchi, & Fischer, 2002a),
algorithm chooses action observes utility (only) action.
side, utilities possible actions revealed case learning
expert advice (e.g., Cesa-Bianchi & Lugosi, 2006a). Online convex optimization (Zinkevich,
2003; Hazan, Agarwal, & Kale, 2007) online convex optimization bandit setting
(Flaxman, Kalai, & McMahan, 2005) continuous relaxations expert
bandit problems respectively. model, information two arms revealed
iteration (the one presented one receive feedback user),
sits expert bandit setting. closely related Coactive Learning
dueling bandits setting (Yue, Broder, Kleinberg, & Joachims, 2009; Yue & Joachims,
2009). key difference arms chosen algorithm dueling
bandits setting, whereas one arms chosen user Coactive Learning
setting. model allows contextual information like contextual bandits (Langford &
Zhang, 2007), however, arms problem structured objects rankings.
summary framework compares existing frameworks shown
Table 1. types feedback also explored literature. example,
multi-class classification problems, algorithm makes prediction based
context, feedback received whether prediction correct wrong opposed
actual label (Crammer & Gentile, 2011; Kakade, Shalev-Shwartz, & Tewari, 2008).
seen observing partial feedback (as opposed actual cardinal feedback)
bandit problem.
pointed above, Coactive Learning algorithms conventional online learning
algorithms operate different types environments. Coactive Learning algorithms present
object observe another object feedback, online convex learning algorithms
pick vector step observe gradient vector feedback. Despite
contrast online learning Coactive Learning, two algorithms presented
paper closely related work Zinkevich (2003) Hazan et al.
(2007). show possible adapt regret bounds algorithms
corresponding regrets bounds Coactive Learning. heart algorithms
analysis well-known idea (Polyak & Tsypkin, 1973) descent algorithms
necessarily need know gradients, vector positive inner product
gradient expectation suffices.
feedback Coactive Learning takes form preference, different
ordinal regression ranking. Ordinal regression (e.g., Crammer & Singer, 2001) assumes
training examples (x, y), rank. Coactive Learning model, absolute ranks
never revealed. closely related learning pairs examples (Herbrich, Graepel, & Obermayer, 2000; Freund, Iyer, Schapire, & Singer, 2003; Chu & Ghahramani, 2005),
since circumvents need absolute ranks; relative orderings required. Vari3

fiShivaswamy & Joachims

Framework
Bandits
Experts
Dueling Bandits
Coactive Learning

Algorithm
pull arm
pull arm
pull two arms
pull arm

Feedback
observe cardinal reward arm pulled
observe cardinal rewards arms
observe feedback one better
observe another arm better

Table 1: comparison different online learning frameworks.

ants pairwise ranking algorithms applied Natural Language Processing
(Haddow, Arun, & Koehn, 2011; Zhang, Lei, Barzilay, Jaakkola, & Globerson, 2014)
image annotation (Weston, Bengio, & Usunier, 2011). However, existing approaches require
iid assumption typically perform batch learning. Finally, large body
work ranking (see Liu, 2009). approaches different Coactive Learning
require training data (x, y) optimal ranking query x. However,
draw upon structured prediction approaches ranking problems design
models.
Coactive learning first proposed Shivaswamy Joachims (2012); paper
serves journal extension paper, adding complete discussion batch updates
expected feedback, exponentiated gradient algorithm, O(log(T )/T ) algorithm
-strongly convex loss functions, substantially extended empirical evaluation.
Since then, coactive learning applied intrinsically diverse retrieval (Raman,
Shivaswamy, & Joachims, 2012), learning ranking function click feedback (Raman,
Joachims, Shivaswamy, & Schnabel, 2013), optimizing social welfare (Raman & Joachims,
2013), personal robotics (Jain, Wojcik, Joachims, & Saxena, 2013), pattern discovery (Boley,
Mampaey, Kang, Tokmakov, & Wrobel, 2013), robotic monitoring (Somers & Hollinger,
2014), extended allow approximate inference (Goetschalckx, Fern, & Tadepalli, 2014).

3. Coactive Learning Model
introduce coactive learning model interaction (in rounds) learning
system (e.g. search engine) human (search user) human learning
algorithm goal (of obtaining good results). round t, learning
algorithm observes context xt X (e.g. search query) presents structured object
yt (e.g. ranked list URLs). utility yt user context xt X
described utility function U (xt , yt ), unknown learning algorithm.
feedback human user returns improved object yt (e.g. reordered list URLs),
i.e.,1
U (xt , yt ) > U (xt , yt ),

(1)

object yt exists. fact, also allow violations (1) formally
model user feedback Section 3.1.
process user generates feedback yt understood
approximately utility-maximizing action, user modeled boundedly rational
1. improvements strict, margin, clear Section 3.1.

4

fiCoactive Learning

agent. particular, user selects feedback object yt approximately maximizing
utility user-defined subset Yt possible Y.
yt = argmaxyY U (xt , y)

(2)

approximately boundedly rational user may employ various tools (e.g., query
reformulations, browsing) construct subset perform search. Importantly,
however, feedback yt typically optimal label defined as,
yt := argmaxyY U (xt , y).

(3)

way, Coactive Learning covers settings user cannot manually optimize
argmax full (e.g. produce best possible ranking web search),
difficulty expressing bandit-style cardinal rating U (xt , yt ) yt consistent manner.
puts preference feedback yt stark contrast supervised learning approaches
require (xt , yt ). even importantly, model implies reliable preference feedback (1) derived observable user behavior (i.e., clicks),
demonstrate Section 3.2 web search. conjecture similar feedback strategies
exist many application settings (e.g., Jain et al., 2013; Boley et al., 2013; Somers &
Hollinger, 2014; Goetschalckx et al., 2014), especially users assumed act
approximately boundedly rational according U .
Despite weak preference feedback, aim algorithm nevertheless present
objects utility close optimal yt . Whenever, algorithm presents
object yt context xt , say suffers regret U (xt , yt ) U (xt , yt ) time
step t. Formally, consider average regret suffered algorithm steps
follows:
REGT =


1X
(U (xt , yt ) U (xt , yt )) .


(4)

t=1

goal learning algorithm minimize REGT , thereby providing human
predictions yt high utility. Note, however, cardinal value U never observed
learning algorithm, U revealed ordinally preferences (1).
3.1 Quantifying Preference Feedback Quality
provide theoretical guarantees regret learning algorithm coactive
setting, need quantify quality user feedback. Note quantification
tool theoretical analysis, prerequisite parameter algorithm. quantify
feedback quality much improvement provides utility space. simplest case,
say user feedback strictly -informative following inequality satisfied:
U (xt , yt ) U (xt , yt ) (U (xt , yt ) U (xt , yt )).

(5)

inequality, (0, 1] unknown parameter. Feedback utility
yt higher yt fraction maximum possible utility range U (xt , yt )
U (xt , yt ). term right hand side inequality ensures user feedback
5

fiShivaswamy & Joachims

yt better yt , also better margin (U (xt , yt )U (xt , yt )). Violations
feedback model allowed introducing slack variables :2
U (xt , yt ) U (xt , yt ) = (U (xt , yt ) U (xt , yt )) .

(6)

Note restricted positive, negative well. refer
feedback model -informative feedback. Note also possible express
feedback quality using (6) appropriate value . regret bounds
contain , quantifying extent -informative modeling assumption violated.
Finally, also consider even weaker feedback model positive utility
gain achieved expectation user actions:
Et [U (xt , yt ) U (xt , yt )] = (U (xt , yt ) U (xt , yt )) .

(7)

refer feedback expected -informative feedback. equation,
expectation users choice yt given yt context xt (i.e.,
distribution Pxt [yt |yt ] dependent xt ).
rest paper, use linear model utility function,
U (x, y) = w> (x, y),

(8)

w RN parameter vector unknown learning system users
: X RN known joint feature map known system that3
k(x, y)k`2 R,

(9)

x X Y. Note x structured objects.
3.2 User Study: Preferences Clicks
validate reliable preferences specified Equation (1) indeed inferred
implicit user behavior. particular, focus preference feedback clicks
web-search draw upon data user study (Joachims, Granka, Pan, Hembrooke,
Radlinski, & Gay, 2007). study, subjects (undergraduate students, n = 16)
asked answer 10 identical questions 5 informational, 5 navigational using Google
search engine. queries, result lists, clicks recorded. subject, queries
grouped query chains question4 . average, query chain contained 2.2
queries 1.8 clicks result lists.
use following strategy infer ranking users clicks: prepend
ranking first query chain results user clicked throughout
whole query chain. assess whether U (x, y) indeed larger U (x, y) assumed
learning model, measure utility terms standard
measure retrieval quality
P10 r(x,y[i])
Information Retrieval. use DCG@10(x, y) = i=1 log i+1 , r(x, y[i])
relevance score i-th document ranking (see Manning, Raghavan, & Schutze,
2. Strictly speaking, value slack variable depends choice definition utility.
However, brevity, explicitly show dependence notation.
3. make slightly different assumption Section 5.1.
4. done manually, automated high accuracy (Jones & Klinkner, 2008).

6

fiCumulative Distribution Function

Coactive Learning

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Normal Condition
Swapped Condition
Reversed Condition
Conditions
-5

-4

-3

-2

-1
0
1
DCG(x,ybar)-DCG(x,y)

2

3

4

5

Figure 1: Cumulative distribution utility differences presented ranking
click-feedback ranking terms DCG@10 three experimental conditions
overall.
2008). get ground-truth relevance assessments r(x, d), five independent human assessors
(students) asked manually rank set results encountered query
chain. assessors also given true answers navigational queries.
linearly normalize resulting ranks relative relevance score r(x, d) [0..5]
document.
evaluate whether feedback ranking indeed better ranking
originally presented, i.e., DCG@10(x, y) > DCG@10(x, y). Figure 1 plots
Cumulative Distribution functions (CDFs) DCG@10(x, y) DCG@10(x, y) three
experimental conditions, well average conditions. CDFs shifted far
right 0, showing preference feedback strategy highly accurate
informative. Focusing first average conditions, utility difference strictly
positive 60% queries, strictly negative 10%. imbalance
significant (binomial sign test, p < 0.0001). Among remaining 30% cases
DCG@10 difference zero, 88% due = (i.e. click top 1 click).
Note learning algorithm easily detect cases may explicitly eliminate
feedback. Overall, shows implicit feedback indeed produce accurate
preferences.
remains shown whether reliability feedback affected
quality current prediction, i.e., U (xt , yt ). user study, users actually
received results retrieval quality degraded purpose. particular,
one third subjects received Googles top 10 results reverse order (condition reversed) another third received rankings top two positions swapped (condition
swapped). Figure 1 shows, find users provide accurate preferences across
substantial range retrieval quality. Intuitively, worse retrieval system may make
harder find good results, also makes easier baseline yt improve upon.
intuition formally captured definition -informative feedback. optimal value
vs. trade-off, however, likely depend many application-specific factors,
like user motivation, corpus properties, query difficulty. following, therefore
present algorithms require knowledge , theoretical bounds hold
value , experiments explore large range .
7

fiShivaswamy & Joachims

Algorithm 1 Preference Perceptron.
Initialize w1 0
= 1
Observe xt
Present yt argmaxyY wt> (xt , y)
Obtain feedback yt
Update: wt+1 wt + (xt , yt ) (xt , yt )
end

4. Preference Perceptron Coactive Learning
section, start presenting analyzing basic algorithm coactive learning model, call Preference Perceptron (Algorithm 1). Preference
Perceptron maintains weight vector wt initialized 0. time step t,
algorithm observes context xt presents object maximizes wt> (xt , y).
algorithm observes user feedback yt weight vector wt updated
direction (xt , yt ) (xt , yt ).
Although update preference perceptron appears similar standard perceptron multi-class classification problems, key differences. First, standard
perceptron algorithm requires true label feedback, whereas much weaker feedback
suffices algorithm. Second, standard analysis perceptron bounds
number mistakes made algorithm based margin radius examples.
contrast, analysis bounds different regret captures graded notion utility.
Further, standard perceptron mistake bound (Novikoff, 1962) contains R2 kwk2
bound following Theorem contains Rkwk R defined (9).
Theorem 1 average regret preference perceptron algorithm upper bounded,
(0, 1] w follows:


1 X
2Rkw k
.
REGT
+


t=1

(10)

Proof First, consider kwT +1 k2 , have,
wT>+1 wT +1 = wT> wT + 2wT> ((xT , yT ) (xT , yT ))
+ ((xT , yT ) (xT , yT ))> ((xT , yT ) (xT , yT )
wT> wT + 4R2 4R2 T.
line one, simply used update rule algorithm 1. line two, used
fact wT> ((xT , yT ) (xT , yT )) 0 choice yT Algorithm 1
k(x, y)k R. Further, update rule algorithm 1, have,
wT>+1 w = wT> w + ((xT , yT ) (xT , yT ))> w
=


X

(U (xt , yt ) U (xt , yt )) .

t=1

8

(11)

fiCoactive Learning

use fact wT>+1 w kw kkwT +1 k (Cauchy-Schwarz inequality),
implies

X

(U (xt , yt ) U (xt , yt )) 2R kw k.
t=1

-informative modeling user feedback (6),



X

(U (xt , yt ) U (xt , yt ))

t=1


X


2R kw k,

t=1

claimed result follows.
first term regret bound denotes quality feedback terms violation
-informative feedback. particular, user feedback strictly
-informative

, slack variables (10) vanish REGT = O(1/ ).
trivial design algorithms (with even better regret) strict -informative
assumption cardinality context set X finite. One interesting aspects
bound (Theorem 1) subsequent results minimize
regret even context xt different every step. Thus, |X | could infinite
regret bound still holds.
note bound Theorem 1 holds w (0, 1]. slacks
based corresponding w .
Though user feedback modeled via -informative feedback, algorithm
require knowledge ; plays role analysis.
far, characterized user behavior terms deterministic feedback actions.
However, bound expected regret suffices, weaker model Expected Informative Feedback Equation (7) applicable.
Corollary 2 expected -informative feedback model, expected regret (over
user behavior distribution) preference perceptron algorithm upper bounded
follows:


E[REGT ]

1 X 2Rkw k
.
+



t=1

(12)

corollary proved following argument Theorem 1, taking
expectations user feedback:
E[wT>+1 wT +1 ] = E[wT> wT ] + E[2wT> ((xT , yT ) (xT , yT ))]
+ ET [((xT , yT ) (xT , yT ))> ((xT , yT ) (xT , yT )]
E[wT> wT ] + 4R2 .
above, E denotes expectation user feedback yt given yt context
xt . follows E[wT>+1 wT +1 ] 4T R2 .
9

fiShivaswamy & Joachims

Algorithm 2 Batch Preference Perceptron.
Initialize w1 0
l1
s0
= 1
Observe xt
Present yt argmaxyY wl> (xt , y)
Obtain feedback yt
== + k
P
Update: wl+1 wl + tj=s (xj , yj ) (xj , yj )
l l+1
st
end
end

Applying Jensens inequality concave function , get:
q
>
E[wT w ] kw kE[kwT k] kw k E[wT> wT ].
corollary follows definition expected -informative feedback.
4.1 Lower Bound
show upper bound Theorem 1 cannot improved general respect
scaling . following lemma, given Coactive Learning algorithm,
construct sequence examples
where, even = 1 feedback, algorithm suffers

average regret (1/ ).
Lemma 3 coactive learning algorithm
linear utility, exist xt , objects
w REGT steps (1/ ).
Proof Consider problem = {1, +1}, X = {x RT : kxk = 1}. Define
joint feature map (x, y) = yx. Consider contexts e1 , . . . , eT ej
j th component equal one others equal zero. Let y1 , .
. . yT
T,
sequence outputs



contexts
e
,
.
.
.
,
e
.
Construct
w
=
[y
/
1

1

>
y2 / , . . . , yT / ] , construction kw k = 1. Let user feedback
tth step yt . choices, user feedback
always -informative = 1
1 PT

since yt = yt . Yet, regret algorithm t=1 (w> (et , yt ) w> (et , yt )) =
( 1T ).
4.2 Batch Update
Preference Perceptron stated Algorithm 1 makes update every iteration.
applications, due high volumes feedback, might possible
update frequently. scenarios, natural consider variant Algorithm 1
makes update every k iterations; algorithm simply uses wt obtained
10

fiCoactive Learning

Algorithm 3 Generic Template Coactive Learning Algorithms
Initialize w1
= 1
Observe xt
Present yt argmaxyY wt> (xt , y)
Obtain feedback yt
Perform update wt using gradient w> ((xt , yt )(xt , yt )) obtain wt+1 .
end
previous update next update. type updates shown Algorithm 2 called
mini-batch updates used distributed online optimization (Dekel, GiladBachrach, Shamir, & Xiao, 2012). steps batch update algorithm shown
Algorithm 2. easy show following regret bound batch updates:
Lemma 4 average regret batch preference perceptron algorithm upper
bounded, (0, 1] w follows:


1 X
2Rkw k k

REGT
+
.



t=1
lemma implies mini-batches slow learning factor equal
batch size, see Section 6.2.3 empirically convergence substantially faster.

5. Deriving Algorithms Coactive Learning
Preference Perceptron regret minimizes, defined Eqn. (4),
one point design space different regret definitions learning algorithms
coactive learning. section, outline general strategy deriving coactive
learning algorithms existing algorithms online optimization. Furthermore,
demonstrate general notions regret meaningful feasible coactive
learning, derive coactive learning algorithms general convex -strongly convex
losses.
coactive learning algorithms derive section follow general template
outlined Algorithm 3. initializing w1 , iteration context xt observed
algorithm presents yt maximizing current utility estimate represented wt .
feedback yt observed, algorithm simply takes gradient w> ((xt , yt )
(xt , yt )) uses update standard online convex optimization algorithm
obtain wt+1 wt .
case, upper bound regret proposed algorithm derived
using following strategy. First, start notion regret suited
coactive learning. upper bound regret first reducing form
results standard online convex opimization regret bound applied.
gives regret bound original coactive algorithm turn. case, use
template algorithm derive specific algorithm. However, still provide self-contained
proof (in appendix) clearly pointing used regret bound
corresponding online convex optimization algorithm.
11

fiShivaswamy & Joachims

Algorithm 4 Exponentiated Preference Perceptron
Intialize w1i N1
2S1T
= 1
Observe xt
Present yt argmaxyY wt> (xt , y)
Obtain feedback yt

wt+1
wti exp((i (xt , yt ) (xt , yt )))/Zt , Zt weights add
one.
end

5.1 Exponentiated Preference Perceptron
illustrate generic strategy deriving coactive learning algorithms, first derive
exponentiated gradient algorithm coactive learning used alternative
Preference Perceptron. exponentiated gradient algorithm inherits ability
learn quickly sparse weight vectors.
Unlike additive updates Preference Perceptron, exponentiated gradient
algorithm summarized Algorithm 4 performs multiplicative updates. exponentiated
algorithm closely related exponentiated algorithms classification (Kivinen &
Warmuth, 1997). start, initializes weights uniformly. subsequent update
step rate associated it. rate depends upper bound ` norm
features (i.e., k(, )k` S) time horizon . multiplicative
update, weights normalized sum one, steps algorithm repeat.
Since updates multiplicative weights initially positive, wt guaranteed
remain positive orthant algorithm. note Algoithm 4 assumed
know S. standard techniques (see Cesa-Biachi & Lugosi, 2006b)
convert algorithm dependence , however, extensions
focus paper.
provide regret bound Algorithm 4. regret bounds Algorithm 1
Algorithm 2 depended `2 norm features, bound exponentiated
algorithm depends ` norm features.
Theorem 5 w RN kw k`1 = 1, w 0, (expected) informative feedback average (expected) regret Exponentiated Preference Perceptron upper bounded as:

1 X
2 log(m)S


REGT
+
+ ,


2
t=1

E[REGT ]


1 X 2 log(m)S


+
+ ,


2
t=1

k(x, y)k` S.
12

fiCoactive Learning

Proof start regret coactive learning algorithm defined (4):
REGT =

=


1X
(U (xt , yt ) U (xt , yt ))

t=1

X

1


1
=


(U (xt , yt ) U (xt , yt )) +

t=1

X


1 X


t=1

w> (xt , yt )

t=1





w> (xt , yt )


1 X

+


(13)

t=1

equation, used definition -informative feedback defined
Eqn. (6). viewing Algorithm 4 exponentiated online gradient descent algorithm,
easy derive following regret bound using techniques initially introduced Kivinen
Warmuth (1997),



X
X


>
(wt ((xt , yt ) (xt , yt )))
(U (xt , yt ) U (xt , yt )) + 2 log(N )S +
.
2
t=1

t=1

Since could find specific bound literature, self-contained proof provided
Appendix A. proof, REGT first upper bounded terms difference
KL(w||wt+1 ) KL(w||wt ). telescoping argument used get result.
Observing wt> ((xt , yt ) (xt , yt )) 0, get,

X
t=1




(U (xt , yt ) U (xt , yt )) 2 log(N )S +
.
2

(14)

Combining (13) (14), obtain average regret bound. proof expected
regret bound analogous Preference Perceptron.
Like result Theorem 1, result (Theorem 5) also bounds regret
terms noisein feedback (first term) additional terms converge zero
rate O(1/ ). key difference Theorem 1 regret bound
exponentiated algorithm scales logarithmically number features,
`1 -norm w, advantageous optimal w sparse.
5.2 Convex Preference Perceptron
Generalizing definition regret Eqn. (4), allow every time step
t, (unknown) convex loss function ct : R R determines loss
ct (U (xt , yt ) U (xt , yt )) time based difference utility yt
optimal yt . functions ct assumed non-increasing. Non-increasing assumption
ct based intuition loss higher U (xt , yt ) farther
U (xt , yt ). Further, sub-derivatives ct assumed bounded. Formally, c0t ()
[G, 0] R c0t () denotes sub-derivative ct () .
vector w determines utility yt context xt assumed closed
13

fiShivaswamy & Joachims

Algorithm 5 Convex Preference Perceptron.
Initialize w1 0
= 1
Set 1t
Observe xt
Present yt argmaxyY wt> (xt , y)
Obtain feedback yt
Update: wt+1 wt + ((xt , yt ) (xt , yt ))
Project: wt+1 arg minuB ku wt+1 k2
end
bounded convex set B whose diameter denoted |B|. case convex losses,
consider following notion regret:


1X
1X

CREGT :=
ct (U (xt , yt ) U (xt , yt ))
ct (0)


t=1

(15)

t=1

bound (16), ct (0) minimum possible convex loss since U (xt , yt ) U (xt , yt )
never greater zero definition yt . Hence regret compares loss
algorithm best loss could achieved convex loss. Note that,
case ct () = , definition regret reduces earlier definition regret
linear case (Eqn. (4)).
Algorithm 5 minimizes average convex loss. two differences
algorithm Algorithm 1. First, rate associated update time
t. Second, every update, resulting vector wt+1 projected back set B.
Algorithm 5 also closely related online convex optimization algorithm propsed
Zinkevich (2003). However, online convex optimization algorithm assumes
gradient loss (ct ()) observed iteration. algorithm doesnt observe
gradient directly, observes improved object yt presenting object
yt .
earlier regret bounds expressed terms slack variables . However,
following section, bounds expressed terms clipped version
slack variables defined t+ := max(0, ).
Theorem 6 Convex Preference Perceptron -informative feedback, nonincreasing convex losses ct () bounded sub-derivative, have, (0, 1]
w B,



2G X + G
|B|
|B| 4R2
+
CREGT
+
+
.

2


t=1

(16)

Similarly, expected -informative feedback, have,



2G X + G
|B|
|B| 4R2
+
E[CREGT ]
+
+
.

2


t=1
14

(17)

fiCoactive Learning

proof Theorem provided Appendix B. idea proof
first divide time steps two types depending
nature feedback.
PT
allows us upper bound CREGT terms t=1 (wt w )> ((xt , yt ) (xt , yt )).
term upper bounded following argument Zinkevich (2003) even
Coactive Learning framework.
definition CREGT Eqn. (15), theorem upper bounds
average convex loss via minimum achievable loss quality feedback. Like
previous result (Theorem 1), strict
-informative feedback, average loss approaches best achievable loss O(1/ ), albeit larger constant factors.
case linear utility bounds Theorem 1 Theorem 5, sufficient
average slack variables zero achieve zero regret. However,
case convex losses, upper bound regret approaches zero average
clipped slack variables zero.
5.3 Second-Order Preference Perceptron
particular class convex functions, turns give much stronger
regret bounds general convex losses. improvement special class losses
parallels improvements online convex optimization general convex losses (Zinkevich,
2003) -strongly convex losses (Hazan et al., 2007).
Definition 7 convex function f : R -strongly convex points x
D, following condition satisfied fixed > 0:
f (x) f (y) + f (x)> (x y)


||y x||2 ,
2

(18)

f (x) denotes sub-derivative x.
Algorithm 6 shows Second-order Preference Perceptron -strongly convex losses.
Like previous algorithms, Second-order Preference Perceptron also maintains
weight vector wt , step presenting yt based context xt still
previous algorithms. However, addition weight vector, also maintains
additional matrix constructed outer product vector (xt , yt )
(xt , yt ). update step projection steps involve shown
Algorithm 6. Algorithm 6 closely related online convex optimization algorithm
proposed Hazan et al. (2007). However, pointed case Algorithm 5,
algorithm observes user preference feedback step unlike online convex
optimization algorithms observe gradients. still possible prove regret bound
-strongly convex case, following result.
Theorem 8 second order preference learning algorithm, (expected) -strongly
convex, non-increasing functions ct , bounded sub-derivatives, have,
2



X + 2 2G X + G|B|
GN
4R
CREGT
+
+
+
log
+1 ,
(19)
2T 2


2T

t=1
t=1
2



4R
X +2 2G X + G|B|
GN
E[CREGT ]
+
+
+
log
+1 ,
(20)
2T 2


2T

t=1

t=1

15

fiShivaswamy & Joachims

Algorithm 6 Second-order Preference Perceptron.
Intialize w1 0
A0
/G.
= 1
Observe xt
Present yt argmaxyY wt> (xt , y)
Obtain feedback yt
At1 + [(xt , yt ) (xt , yt )][(xt , yt ) (xt , yt )]>
Update: wt+1 wt + A1
[(xt , yt ) (xt , yt )]
Project: wt+1 = arg minwB (wt+1 w)> (wt+1 w)
end
where, > 0 initialization parameter, shown Algorithm 6.
prove Theorem Appendix C. Like proof Theorem 6, divide
time steps two types. Starting this, possible upper bound CREGT
form resulting terms upper bounded using similar arguments
online strongly convex optimization (Hazan et al., 2007).
user feedback strictly -informative w B, first two
terms regret bound (19) result O( logT ) scaling . However,
linear dependence dimensionality joint feature map regret bound
Second-order Preference Perceptron algorithm.
Even though appears like need invert matrix Second-order Preference Perceptron, avoided since updates rank one.
Woodbury matrix inversion lemma, have:
> > 1
A1
= (At1 + [(xt , yt ) (xt , yt )][(xt , yt ) (xt , yt )] ) )

= A1
t1

> 1
A1
t1 [(xt , yt ) (xt , yt )][(xt , yt ) (xt , yt )] At1

1/() + [(xt , yt ) (xt , yt )]> A1
t1 [(xt , yt ) (xt , yt )]

.

Thus, practice, Second-order Preference Perceptron update
Bt iteration. Nevertheless, projection step obtain wt+1 involves solving
quadratically-constrained quadratic program B ball fixed radius, still
takes O(N 3 ) time. Hence, Second-order Preference Perceptron computationally
demanding Convex Preference Perceptron. show experiments,
Second-order Preference Perceptron might still quite useful low-noise data.

6. Experiments
empirically evaluate Coactive Learning algorithms two real-world datasets.
two datasets differ nature prediction feedback. first dataset,
algorithms operate structured objects (rankings) whereas second dataset, atomic
items (movies) presented received feedback.
16

fiCoactive Learning

6.1 Datasets User Feedback Models
First, provide detailed description two datasets used experiments. Along this, provide details strategies used dataset
generating user feedback.
6.1.1 Structured Feedback: Web-Search
first dataset publicly available dataset Yahoo! (Chapelle & Chang, 2011)
learning rank web-search. dataset consists query-url feature vectors (denoted
xqi query q URL i), relevance rating riq ranges zero (irrelevant)
four (perfectly relevant). pose ranking structured prediction problem, defined
joint feature map follows:
w> (q, y) =

5
X
w> xqyi
.
log(i + 1)

(21)

i=1

equation, denotes ranking yi index URL
placed position ranking. Thus, measure considers top five URLs
query q computes score based graded relevance. Note utility
function defined via feature-map analogous DCG@5 (see, Manning et al., 2008)
replacing relevance label linear prediction based features.
query qt time step t, Coactive Learning algorithms present ranking ytq
maximizes wt> (qt , y). Note merely amounts sorting documents
scores wt> xqi , done efficiently. utility regret Eqn. (4), based
P
definition utility w> (q, y) given T1 Tt=1 w> ((qt , yqt ) (qt , yqt )). yqt
denotes optimal ranking respect w , consider best least
squares fit relevance labels features using entire dataset. obtain
yqt Eqn. 3, is, yqt = argmaxyY w> (qt , y). experiments, query
ordering randomly permuted twenty times report average standard error
results.
used following two user models generating simulated user feedback
experiments. first feedback model idealized version feedback whereas second
feedback based directly relevance labels available dataset:
Strict -informative feedback: model, user assumed provide
strictly -informative feedback given value (i.e., slacks zero). Given predicted ranking yt , user would go list found five URLs that,
placed top list, resulting yt satisfied strictly -informative
feedback condition w.r.t. optimal w . model assumes user
access w hence idealized feedback.
Noisy feedback depth k: feedback model, given ranking query,
user would go list inspecting top k URLs (or URLs list
shorter) specified k value. Five URLs highest relevance labels (riq )
placed top five locations user feedback. Note produces noisy
feedback since linear model perfectly fit relevance labels dataset.
17

fiShivaswamy & Joachims

6.1.2 Item Feedback: Movie Recommendation
contrast structured prediction problem previous dataset, considered
second dataset atomic predictions, namely movie recommendation. iteration,
movie presented user, feedback consists single movie well.
used MovieLens dataset grouplense.org consists million ratings
3900 movies rated 6040 users. movie ratings range one five.
randomly divided users two equally sized sets. first set used obtain
feature vector xj movie j using SVD embedding method collaborative
filtering (see Bell & Koren, 2007, Eqn. (15)). dimensionality feature vectors
regularization parameters chosen optimize cross-validation accuracy
first dataset terms squared error. second set users, considered
problem recommending movies based movie features xj . experiment setup
simulates task recommending movies new user based movie features old
users.
Tx
user second set, found best least squares approximation wi
j
users utility functions available ratings. enabled us impute utility
values movies explicitly
rated user. Furthermore, allowed us
P
> (x x ), average difference
measure regret user T1 Tt=1 wi


utility recommended movie xt best available movie xt . denote
best available movie time xt obtained Eqn. 3. experiment,
user gave particular movie feedback, recommended movie
feedback movie removed set candidates subsequent recommendations.
experiments report (average) regret values averaged 3020 users
test set.
simulate user behavior, considered following two feedback models
dataset:
Strict -informative feedback: previous dataset, model, user
assumed provide strictly -informative feedback given value (i.e., slacks
zero). Given predicted movie yt , user assumed watch movie
already highest rating remaining corpus movies. not, user
picks another movie corpus lowest utility still satisfies strict informative assumption. model assumes user access w ,
hence idealized feedback.
Noisy feedback: feedback model, given movie y, user assumed
access either actual rating movies (when available) assumed
round imputed rating nearest legal rating value. used two sub-strategies
user provides feedback. better feedback, user provides
smallest rating (actual rating rounded rating) strictly better
rating y. best feedback, user provides
highest rating (actual rating rounded rating) remaining corpus. could
multiple movies satisfying criteria, ties broken uniformly
random among movies. Note feedback model results noisy feedback
due rounding movie ratings discrete values.
18

fiCoactive Learning

6.2 Preference Perceptron
first set experiments, analyze empirical performance scaling behavior
basic Preference Perceptron Algorithm variants.
6.2.1 Strong Versus Weak Feedback
goal first experiment explore regret algorithm changed feedback quality. get feedback different quality levels , used strict -informative
feedback various values.
1.8

6

= 0.1
= 0.5
= 1.0

1.6

= 0.1
= 0.5
= 1.0

5

avg. util regret

avg. dcg regret

1.4
1.2
1
0.8

4

3

2

0.6
0.4

1
0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10



1

2

10

10

3

10



Figure 2: Regret based strict -informative feedback various values websearch (left) movie recommendation (right).
Figure 2 shows results experiment three different values. Overall, regret
typically substantially reduced tens hundreds iterations. expected,
regret = 1.0 lower compared regret lower values. Note, however,
difference two curves much smaller factor ten. Also note
differences less prominent case web-search. strictly
-informative feedback also strictly -informative feedback . So,
user feedback model, could providing much stronger feedback required
particular value. expected theoretical bounds, since user feedback
based linear model noise, utility regret approaches zero cases. Note
show standard error plots, giving indication statistical significance.
left plots Figure 2, standard errors high lower iterations become lower
iterations. plots rest paper, error bars small
may difficult visually identify.
rest paper, strict -informative feedback, consider = 0.5
unless explicitly mention otherwise.
6.2.2 Noisy Feedback
previous experiment, user feedback based actual utility values computed
optimal w . next study regret changes noisy feedback user behavior
19

fiShivaswamy & Joachims

follow linear utility model. web-search dataset, use noisy feedback
depths 10 25, movie dataset use noisy feedback
better best variant it.
1.6

6

depth=10
depth=25

1.4

better
best

5

avg. util regret

avg. util regret

1.2
1
0.8
0.6

4

3

2

0.4
1

0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10



1

2

10

10

3

10



Figure 3: Regret based noisy feedback web-search (left) movie recommendation
(right).

results experiment shown Figure 3. first observation make
case web-search, regret values converge zero. Similarly,
case movie recommendation regret values higher previous
experiment. results line theory shows regret converging
average slack variables user provide strict informative feedback
. Interestingly, case web-search average regret slightly higher
user goes greater depth providing feedback. due fact relevance
labels dataset noisy user maximizes (noisy) utility larger set
URLs, selection (true) utility maximizers becomes less reliable, degrades
user feedback quality.
rest paper, web-search consider noisy feedback depth=10.
case movie recommendation, consider better version noisy feedback
unless explicitly mention otherwise.
6.2.3 Batch Updates
section, consider Batch Preference Perceptron
algorithm (Algorithm 2).

regret bound Section 4.2 scales factor k strict -informative feedback,
update made every k iterations algorithm. verify whether
empirical performance scales suggested bound. web-search movies,
considered strict -informative feedback noisy feedback. types
feedback, use Batch Perceptron Algorithm various values k report
resulting average regret.
results experiments shown Figure 4 Figure 5. expected,
value k becomes smaller, regret converges faster. However, observe
20

fiCoactive Learning

1.6

6

k=1
k = 10
k=20
k=50

1.4

k=1
k=10
k=20
k=50

5

avg. util regret

avg. util regret

1.2
1
0.8
0.6

4

3

2

0.4
1

0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10

1

2

10



10

3

10



Figure 4: Regret versus time based batch updates strict -informative feedback
web-search (left) movie recommendation (right).

1.6
1.4
1.2
1

4

3

0.8

2

0.6

1

0.4 0
10

1

10

2

3

10

10

k=1
k=10
k=20
k=50

5

avg. util regret

avg. util regret

6

k=1
k = 10
k=20
k=50

0 0
10

4

10



1

2

10

10

3

10



Figure 5: Regret versus time based batch updates noisy feedback web-search
(left) movie recommendation (right).


empirical scaling k substantially better k factor suggested Lemma 4.
results show feasibility using Coactive Learning algorithms systems
might impractical update every iteration.
6.2.4 Expected User Feedback
user feedback deterministic experiments far. sub-section, consider probabilistic feedback study behavior Preference Perceptron algorithm.
Recall provided upper bound expected regret expected user feedback
Corollary 2.
provide -informative feedback expectation, consider following strategy.
Given object yt context xt , user would first generate deterministic feedback yt
21

fiShivaswamy & Joachims

following strict -informative feedback model ( = 0.5 web-search = 1.0
movie recommendation).5 addition, consider five randomly generated objects
feedback. put uniform probability mass randomly generated objects
remaining mass deterministic feedback user feedback still
-informative = 0.5 expectation.
6

Expct. feedback
Det. feedback

1.6
1.4

Expct. Feedback
Det. Feedback

5

avg. util regret

avg. util regret

1.2
1
0.8
0.6

4

3

2

0.4
1
0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10



1

2

10

10

3

10



Figure 6: Expected feedback versus deterministic feedback web-search (left) movie
recommendation (right).

results experiment shown Figure 6. reference, also plot
regret curve deterministic -informative feedback = 0.5. seen
much difference deterministic expected feedback higher numbers
iterations. also seen regret converges zero even -informative
feedback expectation suggested Corollary 2.
6.2.5 Comparison Ranking SVM
compare algorithms several baselines, starting conventional
Ranking SVM (Joachims, 2002) repeatedly trained. iteration, previous
qt
SVM model used present ranking user (ysvm
). user returns ranking
qt
(ysvm ) based strict -informative feedback one experiment based noisy
qt
qt
feedback other. pairs examples (qt , ysvm
) (qt , ysvm
) used training
pairs ranking SVM. Note training ranking SVM iteration would
prohibitive expensive, since involves solving quadratic program cross-validating
regularization parameter C. Thus, retrained SVM whenever 10% examples
added training set. first training first iteration
one pair examples (starting random yq1 ), C value fixed 100
50 pairs examples, reliable cross-validation became possible.
50 pairs training set, C value obtained via five-fold cross5. Note that, case web-search, user model provide strictly -informative larger
0.5.

22

fiCoactive Learning

validation. C value determined, SVM trained training
examples available time. SVM model used present rankings
next retraining.
1.6

6

SVM
Pref. Perceptron

1.4

SVM
Pref. Perceptron

5

avg. util regret

avg. util regret

1.2
1
0.8
0.6

4
3
2

0.4
1
0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10

1

2

10

10

3

10





Figure 7: Preference Perceptron versus Ranking SVM strict -informative feedback web-search (left) movie recommendation (right).

6

SVM
Pref. Perceptron

1.4

5

1.2

4

avg. util regret

avg. util regret

1.6

1

3

0.8

2

0.6

1

0.4 0
10

1

10

2

3

10

10

0 0
10

4

10

SVM
Pref. Perceptron

1

2

10

10

3

10





Figure 8: Preference Perceptron versus Ranking SVM noisy feedback web-search
(left) movie recommendation (right).

results experiment shown Figure 7 Figure 8. case
strict -informative feedback, Preference Perceptron performed much better
SVM movie recommendation, comparably web search. case
noisy feedback, Preference Perceptron performs significantly better SVM
range datasets. took around 20 minutes run
Preference Perceptron experiment, took 20 hours run SVM experiment
23

fiShivaswamy & Joachims

web-dataset permutation dataset. Similary, movie recommendation
task took around 125 seconds run preference perceptron user took
around 260 seconds run SVM user. results show preference
perceptron perform par better SVMs tasks fraction
computational cost.
6.2.6 Comparison Dueling Bandit
second baseline, compare Preference Perceptron algorithm dueling
bandit approach Yue Joachims (2009). step, dueling bandit algorithm
makes comparison vector w perturbed version w1 (in random
direction u w1 = w + u). results produced two weight vectors
assessed user techniques interleaving (Radlinski, Kurup, & Joachims,
2008), providing preference w w1 . preference feedback determines
update dueling bandits algorithm makes w. w preferred, retained
next round. w1 preferred, small step length taken direction
perturbation u.
1.8

Dueling Bandit
Pref. Perceptron

1.6

1.6

1.4

1.4

1.2

1.2

avg. util regret

avg. util regret

1.8

1
0.8

1
0.8

0.6

0.6

0.4

0.4

0.2

0.2

0 0
10

1

10

2

3

10

10

0 0
10

4

10



Dueling Bandit
Pref. Perceptron

1

10

2

3

10

10

4

10



Figure 9: Preference Perceptron versus Dueling Bandit web-search. left plot based
strict -informative feedback, right plot shows noisy feedback.
first experiment web-search, step, first obtained two ranked lists
based w w1 . features used obtain ranked lists identical
used Preference Perceptron. two rankings interleaved. interleaved
ranking presented user. first experiment, user provided strict informative feedback interleaved ranking. second experiment, user
provided noisy feedback. Depending feedback, inferred two rankings preferred using Team-Game method proposed Radlinski et al. (2008).
w preferred tie, step taken. w1 preferred,
step length taken direction u. regret dueling bandit algorithm
measured considering utility interleaved ranking. Unlike Preference
Perceptron algorithm, dueling bandit algorithm two parameters ( ) need
24

fiCoactive Learning

tuned. considered 25 values parameters (5x5 grid) simply chose
best parameter values dueling bandits algorithm hindsight.
results experiment shown Figure 9. Despite advantage setting
parameters best possible values, seen dueling bandit algorithm performs
significantly worse compared preference perceptron algorithm orders magnitude.
example, performance dueling bandit around 28,000 iterations matched
preference perceptron less 100 iterations types feedback.
surprising, since dueling bandit algorithm basically relies random vectors
determine direction step needs taken. Coactive Learning model,
user feedback provides (better random) direction guide algorithm.
6

Dueling Bandit
Pref. Perceptron

5

5

4

4

avg. util regret

avg. util regret

6

3

3

2

2

1

1

0 0
10

1

2

10

10

0 0
10

3

10



Dueling Bandit
Pref. Perceptron

1

2

10

10

3

10



Figure 10: Preference Perceptron versus Dueling Bandit movie recommendation.
left plot based utility values whereas right plot shows results
rounded values.

Similarly, also conducted comparison dueling bandit algorithm
movie recommendation dataset. However, unlike web-search experiment, dueling
bandit model somewhat unnatural dataset experimental setup, since interleaving two rankings natural whereas interleaving two items not. therefore consider
different setup. Two movies obtained based w w1 dueling bandit
algorithm. User feedback merely indicate two movies higher
rating. noisy case, user feedback based actual rating rounded rating. noise-free case, user feedback based utility values. either case,
utility dueling bandit considered average utility two movies selected
comparison.
performance dueling bandit algorithm experiment shown Figure 10. Preference Perceptron algorithm, regret curves strict -informative
feedback ( = 0.5) better noisy feedback also shows reference.
seen dueling bandit algorithm performs substantially worse compared
Preference Perceptron algorithm.
25

fiShivaswamy & Joachims

6.3 Exponentiated versus Additive Updates
experiment, compare exponentiated algorithm (Algorithm 4) additive
Preference Perceptron algorithm. exponentiated algorithm, components
must non-negative.6 obtained non-negative follows:
[we ]i


=

min(0, [w ]i )
1 m,
max(0, [w ]im ) + 1 2m.

(22)

equation, [we ]i denotes ith component . Moreover, also modified
joint feature map exponentiated algorithm follows:
e



[ (x, y)]i =

+[(x, y)]i
1im
[(x, y)]im + 1 2m

(23)

modifications, non-negative components moreover, easy verify > e (x, y) = w> (x, y). makes regret
exponentiated algorithm directly comparable regret additive algorithm.
exponentiated algorithm fixed rate parameter inversely depends
time horizon . large, small. situation, consider update
Algorithm 4:

wt+1
wti exp((i (xt , yt ) (xt , yt )))/Zt .
Since, small, approximate exponential term equation
first order approximation:
exp((i (xt , yt ) (xt , yt ))) 1 + (i (xt , yt ) (xt , yt )).
Thus exponentiated updates resemble updates additive algorithm
normalization factor. Despite normalization factor, empirically observed behavior two algorithms nearly identical (though exact). thus empirically
evaluated exponentiated algorithm variable rate parameter = 2S1t time t.
Note empirical result without formal theoretical guarantees variable
rate.
Results experiment shown Figure 11 Figure 12 strict -informative
feedback noisy feedback respectively. seen exponentiated algorithm tends performs slightly better additive algorithm small number
iterations. time horizon becomes large, two algorithms seem comparable
performance cases.
6.4 Minimizing Convex Losses
section, empirically evaluate Convex Preference Perceptron (Algorithm 5)
Second-Order Preference Perceptron (Algorithm 6).
6. put superscript e distinguish joint feature map w used experiments
exponentiated algorithm.

26

fiCoactive Learning

1.6

6

Exponentiated
Pref. Perceptron

1.4

Exponentiated
Pref. Perceptron

5

avg. util regret

avg. util regret

1.2
1
0.8
0.6

4

3

2

0.4
1

0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10

1

2

10



10

3

10



Figure 11: Exponentiated versus Additive strict -informative feedback websearch (left) movie recommendation (right).

1.6

6

Exponentiated
Pref. Perceptron

1.4

Exponentiated
Pref. Perceptron

5

avg. util regret

avg. util regret

1.2
1
0.8
0.6

4

3

2

0.4
1

0.2
0 0
10

1

10

2

3

10

10

0 0
10

4

10



1

2

10

10

3

10



Figure 12: Exponentiated versus Additive noisy feedback web-search (left)
movie recommendation (right).

6.4.1 Convex Perceptron Versus Second-Order Algorithm
regret bounds Section 5 show one get lower regret -strongly convex
functions using second-order algorithm, first-order Convex Perceptron applies
general convex functions. section, evaluate relative performance
first-order second-order algorithms empirically. purpose, considered
quadratic loss c() = ( )2 largest utility value possible (x, y)
w convex ball radius kw k. verified loss function -strongly
convex. B set 100 algorithms datasets.
27

fiShivaswamy & Joachims

Second Order
Convex Perceptron

0.05

500

0.04

400

0.03

300

0.02

200

0.01

100

0 0
10

1

2

10

Second Order
Convex Perceptron

600

Util regret

Quad regret

0.06

3

10

10

0 0
10

4

10

1

2

10

3

10



10

4

10



Figure 13: Cumulative regret convex perceptron second order convex perceptron web-search.

0.03

250

Second Order
Convex Perceptron

200

0.02

Util regret

Quad. regret

0.025

Second Order
Convex Perceptron

0.015

150

100

0.01
50

0.005
0 0
10

1

2

10

10

0 0
10

3

10



1

2

10

10

3

10



Figure 14: Cumulative regret convex perceptron second order convex perceptron movie recommendation.

first set experiments, considered strict -informative feedback. ran
second-order algorithm well Convex Preference Perceptron algorithm 5.
value second order perceptron simply set one. recorded REGT
CREGT values methods. Note REGT corresponds utility
regret defined 4.
Results experiment shown Figure 13 Figure 14. demonstrate
qualitative difference two algorithms, plot cumulative regret (i.e.
REGT CREGT ) figures. cumulative regret second-order
algorithm linear log-scale. shows convergence regret indeed
28

fiCoactive Learning

logarithmic, compared much slower convergence Convex Preference Perceptron.
Interestingly, even cumulative regret based raw utility values empirically shows
similar behavior. purely empirical result, since theoretically, O(log(T )/T ) average
regret holds strongly convex losses linear loss strongly convex.
0

10

weak@5000
strong@5000
weak@15000
strong@15000
weak@25000
strong@25000

1

Util. regret

Quad regret

10

4

weak@5000
strong@5000
weak@15000
strong@15000
weak@25000
strong@25000

10

3

10

2

10

3

10

2

6

4

10

2

10

0

10

10

2

10

10 6
10

4

10

4

2

10

0

10



10

2

10

4

10



Figure 15: Sensitivity second order preference perceptron algorithm parameter
value .

1.2

10

weak@5000
strong@5000
weak@15000
strong@15000
weak@25000
strong@25000

Quad. regret

1.4

10

10

2.4

10
Util. regret

1.3

10

weak@5000
strong@5000
weak@15000
strong@15000
weak@25000
strong@25000

2.5

1.5

10

2.3

10

1.6

10

2.2

10
1.7

10

2.1

4

10

2

0

10

10

2

10

4

10



10

4

10

2

0

10

10

2

10

4

10



Figure 16: Sensitivity second order preference perceptron algorithm parameter
value movie recommendation.

previous experiment, fixed value second-order algorithm one.
study sensitivity second-order algorithm value parameter.
Figures 15 16 show regret values given number iterations swept
range values. dotted lines show performance Convex Preference
Perceptron comparison. case web-search, wide range parameter
29

fiShivaswamy & Joachims

values performance algorithm good. parameter takes extreme
value either side, performance algorithm deteriorates. range suitable
values much broader web-search dataset movie recommendation.
interesting note algorithms performed empirically best = 1 among
values tried.
0.12

14000

Second Order
Convex Perceptron

12000

0.1

Second Order
Convex Perceptron

Util regret

Quad regret

10000
0.08
0.06
0.04

6000
4000

0.02
0 0
10

8000

2000
1

2

10

3

10

10

0 0
10

4

10

1

2

10

3

10

10

4

10





Figure 17: Strong convex versus weak convex noisy feedback web-seach.

1400

Second Order
Convex Perceptron

0.14

1200

0.12

1000

0.1

Util regret

Quad. regret

0.16

0.08

Second Order
Convex Perceptron

800
600

0.06
400

0.04

200

0.02
0 0
10

1

2

10

10

0 0
10

3

10



1

2

10

10

3

10



Figure 18: Strong convex versus weak convex noisy feedback movie recommendation.

also tested convex algorithms noisy feedback. regret bounds contain slack terms right hand side. Thus, user feedback -informative
, regret bounds second-order algorithm first-order algorithm
dominated slack variables. empirical performance two algorithms noisy feedback shown Figures 17 18. case web-search,
results second-order algorithm first-order algorithm nearly identi30

fiCoactive Learning

cal. However, case movie recommendation, still advantage
second-order algorithm.
summary, second-order algorithm performs substantially superior no-noise
circumstances. presence noise feedback, two algorithms show
drastically different behaviors.

7. Conclusions
proposed Coactive Learning new model online learning preferences
especially suited implicit user feedback. Unlike supervised learning approaches,
Coactive Learning algorithms require optimal labels, merely (noisy) feedback
improves prediction. model, cardinal utilities observed,
sits experts bandits settings, argue Coactive Learning
applicable wide range systems aim optimize based observable
user actions.
provide several algorithms provably optimize regret Coactive Learning
framework, empirically validate effectiveness proposed framework
web-search ranking movie recommendation datasets simulations noisy
noise-free feedback. recurring theme paper wide variety conventional
online learning algorithms converted Coactive Learning algorithms, despite
differences learning model itself, nature feedback notion regret.
conjecture many online learning algorithms could similarly converted
practically useful Coactive Learning algorithms.
Coactive Learning model, algorithms proposed, ability use weak
feedback observable user behavior offer wide range opportunities new learning
approaches application problems ranging natural language processing information retrieval robotics. also several opportunities developing
algorithms Coactive Learning model. example, algorithm convex loss
minimization assume gradient convex losses bounded. However,
practical situations, convex loss minimized known apriori.
interesting research direction study whether algorithms utilize
gradient loss perform better either theoretically empirically. Another question
whether better algorithms exist special cases linear utility model. lower
bound based argument dimensionally joint feature maps grow
given horizon . dimensionality joint feature map fixed,
interesting research question is: algorithms better regret proposed
algorithms?

Acknowledgments
work funded part NSF awards IIS-0905467, IIS-1247637, IIS-1142251.
work done Pannaga Shivaswamy postdoctoral associate Cornell
University. thank Peter Frazier, Bobby Kleinberg, Karthik Raman, Tobias Schnabel
31

fiShivaswamy & Joachims

Yisong Yue helpful discussions. also thank anonymous reviewers thoughtful
comments earlier version paper.

Appendix A. Proof Theorem 5
Proof look KL divergence w wt evolves,
KL(w||wt ) KL(w||wt+1 ) =

=

N
X
i=1
N
X


wi log(wt+1
/wti )

wi ((i (xt , yt ) (xt , yt ))) log(Zt )

i=1

= w> ((xt , yt ) (xt , yt )) log(Zt ).
(24)
P

second line, pulled log(Zt ) sum since N
i=1 w = 1. Now, consider


last term equation. Denoting (xt , yt ) (xt , yt ) brevity,
have, definition,
!
N
X
log(Zt ) = log
wti exp(i )
log

i=1
N
X

wti (1



2



2

!

+ + )

i=1



log 1 + wt> + 2 2
wt> + 2 2 .

(25)

second line used fact exp(x) 1 + x + x2 x 1. rate ensures
(i ) 1. last line, used fact log(1 + x) x. Combing (24)
(25), get,
(w wt )>

KL(w||wt ) KL(w||wt+1 )
+ 2 .


Adding inequalities, get:


1
X
X
KL(w||wt ) KL(w||wt+1 ) X 2
(w wt )> ((xt , yt ) (xt , yt ))
+
.

t=1

t=1



t=1

KL(w||w0 )
+ 2 T.


Rearranging inequality, substituting value Algorithm 4,
get:



X
X


>
(U (xt , yt ) U (xt , yt ))
wt ((xt , yt ) (xt , yt )) + 2 log(N )S +
2
t=1
t=1



2 log(N )S +
.
2
32

fiCoactive Learning

above, also used fact KL(w||w1 ) log(N ) since w1 initialized uniformly. Moreover, Holders inequality, obtained
wt> (xt , yt ) kwt k`1 k(xt , yt )k` S.
inequality along -informative feedback gives claimed result.

Appendix B. Proof Theorem 6
Proof First, divide set time steps two different sets based nature
feedback:
:= {t : U (xt , yt ) U (xt , yt )) 0; 1 },
J := {t : U (xt , yt ) U (xt , yt )) < 0; 1 }.
brevity denote (xt , a) (xt , b) by7 (a, b) rest proof. start
considering following term single time step t:
ct (U (xt , yt ) U (xt , yt )) ct (0)

>
wt (yt , yt )

ct (U (xt , yt ) U (xt , yt )) ct


>

>
wt (yt , yt )
w (yt , yt )

ct
=ct




>

>
(w wt ) (yt , yt ) 0 w (yt , yt )


ct






+
>
>
(wt (yt , yt ) + w (yt , yt ))G/


(wt> (yt , yt ) + t+ )G/
J.
w> (y ,y )

inequalities, second line follows fact 0 ct ()
non-increasing. third line follows -informative feedback (Eqn. (6)). fourth
line follows since function ct convex.8 obtain first term next inequality
(in either case) since c0t () [G, 0] wt> (yt , yt ) 0 choice yt
algorithm. second terms (in either case) obtained fact c0t (w> (yt , yt ))
upper bounded t+ G. step clipped version slack variables
needed proof. Finally, w> (yt , yt ) either positive negative depending
feedback leads two different cases depending whether J.
7. Since context xt always clear, suppress notation brevity.
8. convex function f , f (y) f (x) (y x)f 0 (y) f 0 (y) denotes sub-derivative f y.

33

fiShivaswamy & Joachims

Summing inequalities 1 , get:

X

ct (w> (yt , yt ))

t=1






GX


G


wt> (yt , yt ) +

t=1

X


X

ct (0)

t=1

X

G


t+

t=1

tI

(wt w )> (yt , yt ) +

t=1

GX >
w (yt , yt )


G



X
t=1

t+ +

GX >
w (yt , yt ).


(26)

tJ

P
obtained last line simply adding subtracting G tJ w> (yt , yt )/
right side previous inequality. point, mostly follow proof
techniques online convex optimization (Zinkevich, 2003).
bound first term right hand side (26). purpose, consider
following:
kwt+1 w k2 = kwt + (yt , yt ) w k2
= kwt w k2 + t2 k(yt , yt )k2 + 2t (wt w )> (yt , yt ).

(27)

Rearranging terms equation, get:
1
kwt w k2
2t
1

kwt w k2
2t

(wt w )> (yt , yt ) =

1

kwt+1 w k2 + k(yt , yt )k2
2t
2
1
kwt+1 w k2 + 2t R2
2t

where, last line, used fact kwt+1 w k2 kwt+1 w k2 since wt+1
projection wt+1 convex set B (which contains vector w ).
bound first term (26) using following telescoping argument.


X
1
1
2
2
2
kwt w k
kwt+1 w k + 2t R
2t
2t
t=1



X
X
1
1
1
2
kw1 w k +

kwt w k2 + 2R2


21
2t 2t1
t=2
t=1


X

1
1
1

|B| +

|B| + 2R2 (2 1)
21
2t 2t1
t=2


+1

|B| + 4R2 .
2
above, obtained second line simply rearranging terms expression
above.
line, used boundedness property set B, well

PTOn third
fact t=1
2 1. final line follows cancelling terms fact
= 1/ .
34

fiCoactive Learning

Now, consider third term right hand side (26):

w> (yt , yt )
+
+
w> (yt , yt ) + .




first inequality follows -informative feedback. Whereas second inequal

ity follows fact w> (yt , yP
) 0 definition yt . Finally, bound (16)
+
G
follows trivial fact 0 tI .
obtain bound expected regret, consider convex loss step conditioned user behavior far:


wt> (yt , yt )
Et ct



>

>
Et [w (yt , yt ) ]
wt (yt , yt )
ct
Et ct




>
>

w (yt , yt )
wt (yt , yt )
Et ct
Et ct



+
>
>

GEt [wt (yt , yt ) + w (yt , yt )]/


GEt [wt> (yt , yt ) + t+ ]/
tJ
ct (w> (yt , yt ))



second line follows definition expected -informative feedback
third line follows Jensens inequality. obtain last line following argument
similar proof Theorem 6. bound follows expected version
(27).

Appendix C. Proof Theorem 8
Proof First, divide time steps two different sets based nature feedback:

:= {t : U (xt , yt ) U (xt , yt )) 0; 1 },
J := {t : U (xt , yt ) U (xt , yt )) < 0; 1 }.
35

fiShivaswamy & Joachims

start considering single time step t, have:
ct (w> (yt , yt )) ct (0)
>

wt (yt , yt )
>

ct (w (yt , yt )) ct

>
>

+
w (yt , yt )
wt (yt , yt )
ct
ct






2

+ >
>
w (yt , yt ) t+
(w wt )> (yt , yt ) t+
(w wt ) (yt , yt )
0
ct









2







2
+
+
>
>



wt> (yt ,yt )
,yt )

tI
+ w (y
2 (w wt ) (yt ,yt )
G






(28)





+
+ 2
> (y ,y )
> (y ,y )



w
(w
w
)








+ 2

J.
G


w> (y ,y )

inequalities, second line follows fact 0 ct ()
non-increasing. third line follows fact function ct () non-increasing
following inequality follows definition t+ :
U (xt , yt ) U (xt , yt ) + (U (xt , yt ) U (xt , yt )) t+ .
fourth line follows strong convexity. last line follows line
reasoning proof Theorem 6.
consider last term cases:


2
=


2

=


2




2




2

2
(w wt )> (yt , yt ) t+





2
2
(w wt )> (yt , yt )
t+
t+ (w wt )> (yt , yt )

+

22
2


2
2
(w wt )> (yt , yt )
+ w> (yt , yt ) t+ wt> (yt , yt ) t+
+ 2




2
22

2


2
(w wt )> (yt , yt )
t+
t+
t+
>

+
w (yt , yt ) +




22


2
2
(w wt )> (yt , yt )
+
+ 2.
(29)

2


equations, second third lines follow simple algebraic expansion
expression first line. fourth line follows definition -informative
feedback fact wt> (yt , yt ) 0. last line follows fact
w> (yt , yt ) 0 definition yt .
36

fiCoactive Learning

Now, summing terms (28) substituting bound, get,


X

ct (w> (yt , yt ))

t=1


X

ct (0)

t=1

2 !
X w> (yt , yt ) PT + 2
(w wt )> (yt , yt )

t=1
G
+
G


22
t=1
tI
!


2

>
>
X (wt w ) (yt , yt ) (w wt ) (yt , yt )
G


2

t=1
P
P
2
Tt=1 t+
G Tt=1 t+
GX >
+
w (yt , yt ) +
+

22

tJ

2 PT + 2 2G PT +
GX

>
>
t=1
t=1

(wt w ) (yt , yt )
(wt w ) (yt , yt )
+
.
+

2
22


X

wt> (yt , yt ) t+
+



2



t=1

>
P
,yt )
above, obtained third inequality adding subtracting G tJ w (y
.

2
obtain last line, used fact 1/ 1/ since (0,

P 1]). Finally,
> (y , )
used argument similar proof theorem 6 bound G
w



tJ

obtained factor two sum slacks term. point, use arguments
similar online convex optimization strongly convex losses (Hazan et al.,
2007).

Next, consider (wt+1 w )> (wt+1 w ) express interms wt At1 :

(wt+1 w )> (wt+1 w )
1
>
=(wt A1
(yt , yt ) w ) (wt (yt , yt ) w )
>
=(wt w )> (wt w ) + (yt , yt )> A1
(yt , yt ) 2(wt w ) (yt , yt )

=(wt w )> (yt , yt )(yt , yt )> (wt w ) + (wt w )> At1 (wt w )
>
+ (yt , yt )> A1
(yt , yt ) + 2(w wt ) (yt , yt )

Rearranging terms equation, get:


(wt w )> (yt , yt )(yt , yt )> (wt w )
2
(wt w )> At1 (wt w ) (wt+1 w )> (wt+1 w ) + (yt , yt )> A1
(yt , yt ).
2(wt w )> (yt , yt )

37

fiShivaswamy & Joachims

identify term left hand side inequality occurs
expression would like bound (29). therefore have,
2




X

t=1

X

(wt w )> (yt , yt ) ((wt w )> (yt , yt ))2




(wt w )> At1 (wt w ) (wt+1 w )> (wt+1 w ) + (yt , yt )> A1
( byt , yt )

t=1

(w1 w )> A0 (w1 w ) +


X

(yt , yt )> A1
(yt , yt )

t=1

|B| +

N
log




4R2



+1 .

P
2
above, used fact Tt=1 (yt , yt )> A1
(yt , yt ) N log(4R /+1),
N dimens ionality (x, y) R upper bound norm joint
feature maps (i.e. k(x, y)k`2 R. proof fact found Hazan et al. (2007).

References
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002a). Finite-time analysis multiarmed
bandit problem. Machine Learning, 47 (2-3), 235256.
Auer, P., Cesa-Bianchi, N., Freund, Y., & Schapire, R. (2002b). non-stochastic multiarmed bandit problem. SIAM Journal Computing, 32 (1), 4877.
Bakir, G. H., Hofmann, T., Scholkopf, B., Smola, A., Taskar, B., & Vishwanathan, S. (Eds.).
(2007). Predicting Structured Data. MIT Press.
Bell, R. M., & Koren, Y. (2007). Scalable collaborative filtering jointly derived neighborhood interpolation weights. ICDM.
Boley, M., Mampaey, M., Kang, B., Tokmakov, P., & Wrobel, S. (2013). One click mining:
Interactive local pattern discovery implicit preference performance learning. Proceedings ACM SIGKDD Workshop Interactive Data Exploration
Analytics, pp. 2735.
Cesa-Bianchi, N., & Lugosi, G. (2006a). Prediction, learning, games. Cambridge University Press.
Cesa-Bianchi, N., & Lugosi, G. (2006b). Prediction, Learning, Games. Cambridge
University Press, Cambridge, UK.
Chapelle, O., & Chang, Y. (2011). Yahoo! learning rank challenge overview. JMLR Proceedings Track, 14, 124.
Chu, W., & Ghahramani, Z. (2005). Preference learning gaussian processes. ICML.
Crammer, K., & Singer, Y. (2001). Pranking ranking. NIPS.
38

fiCoactive Learning

Crammer, K., & Gentile, C. (2011). Multiclass classification bandit feedback using
adaptive regularization. Proceedings 28th International Conference Machine Learning (ICML).
Dekel, O., Gilad-Bachrach, R., Shamir, O., & Xiao, L. (2012). Optimal distributed online
prediction using mini-batches. JMLR, 13, 165202.
Flaxman, A., Kalai, A. T., & McMahan, H. B. (2005). Online convex optimization
bandit setting: gradient descent without gradient. SODA.
Freund, Y., Iyer, R. D., Schapire, R. E., & Singer, Y. (2003). efficient boosting algorithm
combining preferences. Journal Machine Learning Research, 4, 933969.
Goetschalckx, R., Fern, A., & Tadepalli, P. (2014). Coactive learning locally optimal
problem solving.. Conference American Association Artificial Intelligence
(AAAI), pp. 18241830.
Haddow, B., Arun, A., & Koehn, P. (2011). Samplerank training phrase-based machine
translation. Proceedings Sixth Workshop Statistical Machine Translation,
pp. 261271, Edinburgh, Scotland. Association Computational Linguistics.
Hazan, E., Agarwal, A., & Kale, S. (2007). Logarithmic regret algorithms online convex
optimization. Machine Learning, 69 (2-3), 169192.
Herbrich, R., Graepel, T., & Obermayer, K. (2000). Large margin rank boundaries
ordinal regression. Advances Large Margin Classifiers. MIT Press.
Jain, A., Wojcik, B., Joachims, T., & Saxena, A. (2013). Learning trajectory preferences
manipulators via iterative improvement. Neural Information Processing Systems
(NIPS), pp. 575583.
Joachims, T. (2002). Optimizing search engines using clickthrough data. ACM SIGKDD
Conference Knowledge Discovery Data Mining (KDD), pp. 133142.
Joachims, T., Granka, L., Pan, B., Hembrooke, H., Radlinski, F., & Gay, G. (2007). Evaluating accuracy implicit feedback clicks query reformulations web
search. ACM Transactions Information Systems (TOIS), 25 (2).
Jones, R., & Klinkner, K. (2008). Beyond session timeout: automatic hierarchical
segmentation search topics query logs. CIKM.
Kakade, S. M., Shalev-Shwartz, S., & Tewari, A. (2008). Efficient bandit algorithms
online multiclass prediction. Proceedings 25th International Conference
Machine Learning (ICML).
Kivinen, J., & Warmuth, M. (1997). Exponentiated gradient versus gradient gradient descent linear predictors. Journal Information Computation, 132 (1), 164.
Langford, J., & Zhang, T. (2007). epoch-greedy algorithm multi-armed bandits
side information. NIPS.
Liu, T.-Y. (2009). Learning rank information retrieval. Foundations Trends
Information Retrieval, 3.
Manning, C., Raghavan, P., & Schutze, H. (2008). Introduction Information Retrieval.
Cambridge University Press.
39

fiShivaswamy & Joachims

Novikoff, A. (1962). convergence proofs perceptrons. Proceedings Symposium
Mathematical Theory Automata, Vol. XII, pp. 615622.
Polyak, B., & Tsypkin, Y. (1973). Pseudogradient adaptation training algorithms.
Automatic Remote Control, 12, 8394.
Radlinski, F., Kurup, M., & Joachims, T. (2008). clickthrough data reflect retrieval quality?. Conference Information Knowledge Management (CIKM).
Raman, K., & Joachims, T. (2013). Learning socially optimal information systems
egoistic users. European Conference Machine Learning (ECML), pp. 128144.
Raman, K., Joachims, T., Shivaswamy, P., & Schnabel, T. (2013). Stable coactive learning
via perturbation. International Conference Machine Learning (ICML), pp.
837845.
Raman, K., Shivaswamy, P., & Joachims, T. (2012). Online learning diversify
implicit feedback. KDD.
Shivaswamy, P., & Joachims, T. (2012). Online structured prediction via coactive learning.
ICML.
Somers, T., & Hollinger, G. (2014). Coactive learning human expert robotic
monitoring. RSS Workshop Robotic Monitoring.
Weston, J., Bengio, S., & Usunier, N. (2011). Wsabie: Scaling large vocabulary
image annotation. Proceedings International Joint Conference Artificial
Intelligence (IJCAI).
Yue, Y., Broder, J., Kleinberg, R., & Joachims, T. (2009). k-armed dueling bandits
problem. COLT.
Yue, Y., & Joachims, T. (2009). Interactively optimizing information retrieval systems
dueling bandits problem. ICML.
Zhang, Y., Lei, T., Barzilay, R., Jaakkola, T., & Globerson, A. (2014). Steps excellence: Simple inference refined scoring dependency trees. Proceedings
52nd Annual Meeting Association Computational Linguistics (Volume
1: Long Papers), pp. 197207, Baltimore, Maryland. Association Computational
Linguistics.
Zinkevich, M. (2003). Online convex programming generalized infinitesimal gradient
ascent. ICML.

40

fiJournal Artificial Intelligence Research 53 (2015) 721-744

Submitted 9/14; published 8/15

Mechanisms Multi-unit Combinatorial
Auctions Distinct Goods
Piotr Krysta

p.krysta@liverpool.ac.uk

Deparment Computer Science
University Liverpool, United Kingdom

Orestis Telelis

telelis@gmail.com

Department Digital Systems
University Piraeus, Greece

Carmine Ventre

c.ventre@tees.ac.uk

School Computing
Teesside University, United Kingdom

Abstract
design analyze deterministic truthful approximation mechanisms multiunit Combinatorial Auctions involving constant number distinct goods,
arbitrary limited supply. Prospective buyers (bidders) preferences multisets
items, i.e., one unit per distinct good. objective determine
allocations multisets maximize Social Welfare. main results multiminded submodular bidders. first setting bidder positive value
allocated one multiset prespecified demand set alternatives. second
setting bidder associated submodular valuation function defines value
multiset allocated. multi-minded bidders, design truthful Fptas
fully optimizes Social Welfare, violating supply constraints goods
within factor (1 + ), fixed > 0 (i.e., approximation applies constraints
Social Welfare). result best possible, full optimization
impossible without violating supply constraints. submodular bidders, obtain
Ptas approximates optimum Social Welfare within factor (1 + ), fixed
> 0, without violating supply constraints. result best possible well.
allocation algorithms Maximal-in-Range yield truthful mechanisms, paired
Vickrey-Clarke-Groves payments.

1. Introduction
paper study design analysis truthful multi-unit Combinatorial Auctions, constant number distinct goods, limited supply. Arguably,
widespread modern application general setting allocation radio spectrum
licences (Milgrom, 2004); license use specific frequency band electromagnetic spectrum, within certain geographic area. design Spectrum
Auctions, licenses area considered identical units single good (the
area), number distinct geographic areas is, course, bounded constant.
formally, consider problem auctioning (allocating) one go multiple
units constant number distinct goods, prospective buyers private
multi-demand combinatorial valuation functions, maximize Social Welfare.
c
2015
AI Access Foundation. rights reserved.

fiKrysta, Telelis, & Ventre

multi-demand buyer setting may distinct positive values distinct multisets
goods, i.e., multiset may demand one unit per good. aim
devise deterministic truthful auction mechanisms, wherein every bidder finds
best interest reveal value truthfully multiset items (i.e., truthful report
valuation functions dominant strategy). Additionally, interested mechanisms
compute approximately efficient allocation polynomial time. problem generalizes simultaneously Combinatorial Auctions multiple goods Multi-unit
Auctions single good multi-unit combinatorial settings respectively.
Since work Lehmann, OCallaghan, Shoham (2002), Mechanism Design
Combinatorial Auctions multiple heterogeneous goods (each unitary supply) received significant attention recent years (Holzman, Kfir-Dahav, Monderer, & Tennenholtz, 2004; Lehmann, Lehmann, & Nisan, 2006; Dobzinski, Nisan, & Schapira, 2010; Lavi
& Swamy, 2011), due various applications, especially online trading systems
Internet. mechanism elicits bids interested buyers, determine
assignment bundles payments way, bidders best
interest reveal valuation function truthfully mechanism. line research,
introduces algorithmic efficiency considerations design truthful mechanisms,
initialized work Nisan Ronen (2001).
related problem auctioning multiple say units single good multidemand bidders already considered Vickrey seminal paper (Vickrey,
1961). bidders submodular private valuation functions, Vickrey gave extension
celebrated single-item Second-Price Auction mechanism, retains truthful revelation valuation functions (weakly) dominant strategy bidders fully optimizes
Social Welfare. drawback mechanism computationally
efficient (constant number of) units, allocation algorithm must
process (s) bids least many steps, whereas input number,
require number steps bounded polynomial log s. Several drawbacks
generalized Vickrey-Clarke-Groves (truthful) auction mechanism identified
Ausubel Milgrom (2010). Polynomial-time approximation mechanisms multiunit auctions designed relatively recently (Mualem & Nisan, 2002, 2008; Dobzinski &
Nisan, 2010; Vocking, 2012; Nisan, 2014). particular, Nisan (2014) devised deterministic, polynomial time auction mechanism, multi-unit setting submodular bidders
first considered Vickrey (1961). Vocking designed analyzed recently randomized
universally truthful polynomial-time approximation scheme, bidders unrestricted
valuation functions (Vocking, 2012).
Results general setting multi-unit Combinatorial Auctions relatively
scarcer (Bartal, Gonen, & Nisan, 2003; Grandoni, Krysta, Leonardi, & Ventre, 2014; Lavi
& Swamy, 2011). exactly setting consider here, constant number
distinct goods, similarly setting considered Grandoni et al. (2014); particular,
number cases auctions analyze Maximal-in-Range (MiR) allocation
algorithms (Nisan & Ronen, 2007), paired Vickrey-Clarke-Groves
payment rule, yield truthful mechanisms.
722

fiMechanisms Multi-unit Combinatorial Auctions

1.1 Contribution
main results concern multi-unit Combinatorial Auctions constant number
distinct goods two broad classes bidders, specified associated valuation
functions:
1. Multi-minded Bidders: setting bidder associated demand set
alternative multisets (the multiple minds). bidders valuation function assigns
(possibly distinct) positive value every alternative demand set (and least
much value every superset alternative) zero elsewhere.
2. Submodular Bidders: setting value bidder particular multiset
items given submodular valuation function.
multi-minded bidders design analyze Section 4 truthful Fptas1 ,
fully optimizes Social Welfare polynomial time, violating supply constraints
goods factor (1 + ), fixed > 0. violation supply
constraints practical well theoretical justification. one hand conceivable
that, certain environments, slight augmentation supply economically viable,
sake better solutions (e.g., auctioneers well supplied stocks easily handle
occurrences modest overselling). hand, note relaxation
supply constraints necessary obtaining Fptas, problem otherwise strongly
NP-hard, 2 goods (please see related discussion Section 4). result
significantly improves upon Fptas Grandoni et al. (2014), approximates
Social Welfare supply constraints within factor2 (1+), bidders singleparameter (i.e., associate positive value multiset demand set)
overbid demands. Technically, Fptas Grandoni et al. (2014) based
design monotone algorithms (Lehmann et al., 2002; Briest, Krysta, & Vocking,
2011) requires no-overbidding assumption demands (cf. discussion therein).
Section 5 revisit general technique introduced Dobzinski Nisan (2010),
multi-unit auction Mechanism Design, generalize setting multiple distinct goods, limited supply. discuss generalization yields truthful
Ptas immediately multi-minded bidders, violate supply constraints
approximates Social Welfare within factor (1+), fixed > 0. Subsequently,
use technique design truthful Ptas bidders submodular valuation functions, assuming values (bids) accessed value queries algorithm.
Prior result, time-efficient deterministic truthful mechanism known submodular bidders, even 2.3 Although technique Dobzinski Nisan
facilitated development factor 2 approximation mechanism bidders general
valuation functions single-good multi-unit setting, direct extension setting
multiple distinct goods appear work (for general valuation functions).
1. Fully Polynomial Time Approximation Scheme.
2. context Social Welfare maximization, approximation within factor 1 (or, equivalently,
-approximation, 1) mean recovering least fraction 1 welfare optimum
allocation. switch temporarily using 1 Section 5, technical convenience.
3. Nisan (2014) devised optimal polynomial time auction = 1, i.e., single good.

723

fiKrysta, Telelis, & Ventre

show, however, appropriate extension dedicated treatment case
Dobzinski Nisan yields constant (m + 1)-approximation (Section 6).
assumption constant number = O(1) distinct goods important,
otherwise problems become Combinatorial Auctions, thus, hard approximate

polynomial time within less O( m) (Lehmann et al., 2002) multi-minded bide
ders within less e1
submodular bidders (Khot, Lipton, Markakis, & Mehta,
2008; Mirrokni, Schapira, & Vondrak, 2008). Moreover, recent results Daniely, Schapira,
Shahaf (2015) imply that, unrestricted m, techniques cannot yield truthful

polynomial-time mechanisms approximation factors less O(m) O( m), respectively. Regarding generalization Dobzinski-Nisan technique, existence
Fptas multi-minded bidders single good excluded, unless P = NP (Dobzinski
& Nisan, 2010). lower bounds imply results best possible. Finally,
shown Nisan Segal (2006) Dobzinski Nisan (2010), regarding general valuation functions, deterministic MiR algorithm achieves better 2-approximation
single good communication complexity o(s), supply good.
Closing gap lower bound upper bound (m + 1) constant
number multiple distinct goods, remains open problem.

2. Related Work
Mechanism Design multi-unit auctions initiated already celebrated work
Vickrey (1961), extended famous mechanism case multiple units,
bidders symmetric submodular valuation functions (Lehmann et al., 2006).
mechanism however computationally efficient respect number available
units, already discussed. requires bidders place marginal bid per additional
unit wish receive allocation algorithm processes marginal bids.
recently, Nisan (2014) exhibited polynomial-time truthful mechanism case.
design multi-unit mechanisms polynomially bounded running time log s, denoting number units, first considered Mualem Nisan (2008). work,
Mualem Nisan designed analyzed truthful polynomial-time 2-approximation
mechanism multi-unit combinatorial setting, involving multiple distinct goods,
limited supply, single-minded bidders. Subsequently, Archer, Papadimitriou, Talwar,
Tardos (2003) improved upon approximation ratio similar setting,
developed mechanism based randomized rounding truthful expectation. recently, Briest et al. (2011) designed analysed Fptas, single-minded
bidders multi-unit combinatorial setting.
Dobzinski Nisan (2010) analyzed general scheme designing MiR polynomialtime truthful approximation mechanisms, single-good multi-unit auctions. resulted
Ptas case multi-minded bidders, 2-approximation general valuation
functions accessed (by allocation algorithm) value queries,
4
3 -approximation symmetric subadditive valuation functions. Moreover, authors
applied scheme class piecewise linear (multi-unit) valuation functions
number units single good, obtain truthful Ptas mechanism. special case
class valuation functions earlier studied Kothari, Parkes, Suri
(2005); authors designed Fptas mechanism was, however, approximately
724

fiMechanisms Multi-unit Combinatorial Auctions

truthful. Dobzinski Dughmi (2013) gave randomized truthful expectation Fptas
multi-minded bidders. Relatively recently, Vocking (2012) gave universally truthful
randomized Ptas general valuation functions accessed value queries (in contrast,
mechanisms deterministic). multi-unit combinatorial setting (i.e.,
one distinct goods) known results concern mainly bidders demands
single unit good (Lehmann et al., 2002; Briest et al., 2011; Blumrosen &
Nisan, 2007). contrast, consider constant number goods, multi-demand
bidders. Bartal et al. (2003) proved approximation competitiveness results truthful
multi-unit Combinatorial Auctions multi-demand bidders, bidders demands
numbers units upper lower bounded. derived approximation guarantees
depend bounds. Lavi Swamy (2011) improved upon approximation
guarantees, devising randomized mechanisms truthful expectation.
study constant number goods, arbitrary limited supply, initiated
Grandoni et al. (2014). authors utilized methods multi-objective optimization
(approximate Pareto curves Langrangian relaxation) design analyze truthful
polynomial-time approximation schemes variety settings. particular, devised truthful Fptases approximate objective function (Social Welfare
Cost) multi-capacitated versions problems within factor (1 + ), violating
capacity constraints factor (1 + ) (capacity corresponds limited supply
distinct goods). Problems considered Grandoni et al. include multi-unit
auctions, minimum spanning tree, shortest path, maximum (perfect) matching matroid
intersection; subclass problems truthful Ptas also analyzed,
violate capacity constraints.
particular interest practice Combinatorial Auctions (also multi-unit
case, good available limited supply identical copies), efficient
(near-)optimal resolution Winner Determination problem (Lehmann, Muller, &
Sandholm, 2010). Given input set bids prespecified format (formally termed
language), items sale, Winner Determination problem prescribes determination feasible allocation items bidders, sum bids
corresponding received allocation maximized. Thus, Winner Determination
problem implicitly prescribes determination winning bidders receiving allocation, revenue collected corresponding bids maximized. Notice that,
comparison work, truthful report bidders valuation functions concern
setting. significant volume research concerned study approximation
algorithms derivation hardness results (see, e.g., Lehmann et al., 2010), much
development global optimization techniques (Sandholm, 2010). Kelly (2004) studies
Multi-unit Combinatorial Auctions distinct goods, determining allocation computational resources. particular, devises optimal algorithm
Winner Determination problem, low-dimensional setting ours.
Finally let us mention work Bikhchandani, de Vries, Schummer, Vohra
(2011) investigates multi-unit Combinatorial Auction premises similar ours, without
restriction number distinct goods. Instead, authors devise ascending price
auction selling subsets goods constitute bases matroid, polymatroid, case
multi-unit demand bidders limited supply distinct good. auction
truthful runs polynomial pseudopolynomial time, respectively. accesses
725

fiKrysta, Telelis, & Ventre

bidders combinatorial valuation functions Demand Queries; bidders
presented prices goods announce subset willing pay for.
comparison, mechanisms use Value Queries, mechanism asks
value bidder particular set items. Value queries weaker device
simulated (but cannot generally simulate) demand queries (Blumrosen
& Nisan, 2007).

3. Definitions
Let [m] = {1, . . . , m} set goods, assumed fixed constant.
s` N units (copies) good ` [m] available. multiset goods denoted vector
x = (x(1), x(2), . . . , x(m)), x(`) number units good ` [m], ` = 1, . . . , m.
set multisets denoted U =
`=1 {0, 1, . . . , s` }. Let [n] = {1, . . . , n}
set n agents (prospective buyers/bidders). Every bidder [n] private valuation
function
vi : U 7 R+ ,
vi (x) x U denotes maximum monetary amount willing
pay x U, referred value x. valuation functions normalized, i.e.,
vi (0, . . . , 0) = 0 assumed monotone non-decreasing: two multisets x
holds component-wise, assume vi (x) vi (y). is, auction theory
terms, assume free disposal (i.e., enlarging set increasing number items
allocation never decreases value incurred bidder).
mechanism consists allocation method (algorithm), A, payment rule, p.
allocation method elicits bids b = ( b1 , b2 , . . . , bn ) bidders that, presumably, describe valuation functions outputs allocation A(b) = (x1 , x2 , . . . , xn ),
xi U multiset goods allocated bidder i. purposes discussion section, deliberately ignore fact bidders valuation functions may
succinct representation facilitate efficient communication
allocation algorithm; recall bidders valuation functions generally defined
U =
`=1 {0, 1, . . . , s` }. succinct representation indeed,
allocation algorithms discussed paper access bidders valuation functions iteratively, polynomially many Value Queries; is, algorithm iteration
asks every bidder bid specific multiset items.
payment rule determines vector p(b) = ( p1 (b), p2 (b), . . . , pn (b) ), pi (b)
payment bidder i. Every bidder bids maximize quasi-linear utility,
defined as:
ui (b) = vi ( A(b) ) pi (b),
where, assumption externalities, i.e., value bidder A(b)
depends individual allocation others, obtain
vi ( A(b) ) = vi (xi ).
study truthful mechanisms (A, p) wherein bidder maximizes utility
reporting valuation function truthfully, i.e., bidding bi = vi , independently
bidders reports, bi = (b1 , . . . , bi1 , bi+1 , . . . , bn ):
726

fiMechanisms Multi-unit Combinatorial Auctions

Definition 1 mechanism (A, p) truthful if, every bidder bidding profile bi ,
satisfies ui (vi , bi ) ui (vi0 , bi ), every vi0 .
definition, profile b = v dominant strategy equilibrium. objective
design analyze truthful mechanisms, (A, p) render truthful reporting
bidders valuation dominant strategy equilibrium, wherein, Social Welfare
resulting allocation, SW ( A(b) ) = SW ( A(v) ) (approximately) optimized. social
welfare allocation, X = (x1 , x2 , . . . , xn ) defined as:
SW (X) =

n
X

vi (xi ),

i=1

sequel use simply X, allocation output A, without specific reference
b, since analyze truthful mechanisms, dictate b = v.
well understood general method design truthful mechanisms
Vickrey-Clarke-Groves (VCG) auction mechanism (Vickrey, 1961; Clarke, 1971; Groves,
1973), generalization Vickreys Single-Item 2nd Price Multi-unit Auctions (Vickrey,
1961). Deployment VCG auction, however, requires utilization allocation
algorithm, A, outputs welfare-maximizing allocation underlying setting;
rarely constitutes computationally efficient alternative combinatorial settings,
underlying optimization problem NP-hard.
problems consider work indeed NP-hard, mechanisms use
Maximal-in-Range (MiR) allocation algorithms (Nisan & Ronen, 2007), maximize
social welfare approximately.
Definition 2 (Nisan & Ronen, 2007) algorithm choosing output set
possible allocations MiR, fully optimizes Social Welfare subset R
allocations.
Note subset R, also called range, defined independently bidders declarations. Nisan Ronen (2007) identified MiR allocation algorithms sole device
that, along VCG payments, yields truthful mechanisms Combinatorial Auctions.
particular, given MiR allocation algorithm, A, using algorithm computing
output allocation computing payments manner VCG payments
scheme, suffices obtain truthful mechanism. particular, given MiR allocation algorithm, payment bidder computed follows:
pi (b) =

X

vi0 ( A(bi ) )

i0 6=i

X

vi0 ( A(b) )

i0 6=i

Notice payment scheme coincides VCG payment scheme, use
optimal allocation algorithm place A. starting point work Nisan
Ronen (2007) pair observations that: (i) VCG mechanism requires full
optimization social welfare underlying setting, NP-hard problem
interesting settings (ii) VCG-based mechanisms (wherein polynomial-time allocation
algorithm outputs welfare-suboptimal allocations) necessarily truthful.
727

fiKrysta, Telelis, & Ventre

4. Multi-minded Bidders
section consider multi-minded bidders; every bidder [n] associated
collection multisets Di U, referred demand set. assume
[n] values multiset = (d(1), . . . , d(m)) Di amount vi (d) > 0. every
multiset e U \ Di define:

fi
n

max vi (d) fifi e
Di exists
dDi
vi (e) =

0
otherwise.
Naturally, vi (0) = 0, 0 = (0, . . . , 0). Consequently, setting, valuation
function bidder compactly expressed collection (vi (d), d)dDi .
related literature, assume therefore algorithm expects input bids form,
rather (an oracle representing) entire valuation function. say bidder
winner auction, assigned exactly one alternatives Di (or
superset one alternatives); corresponds XOR-bidding language
Combinatorial Auctions (Lehmann et al., 2006).
design Fptas, maximizes Social Welfare may violate supply
constraints goods factor (1 + ), fixed > 0.
allocation algorithm mechanism. analyzing performance respect
welfare optimality allocation outputs bounded violation
supply constraints, prove MiR algorithm, thus paired VCG
payments, yield truthful mechanism. high level, algorithm reminiscent
one yields Fptas well-known one-dimensional knapsack problem (see
e.g., Vazirani, 2003, ch. 8). proceeds follows. chosen fixed > 0, first
discards alternatives bidders demand sets, cannot satisfied, given
supply constraints. alternatives multisets already exceed supply
least one good. Subsequently, quantities goods multisets remaining
within bidders demand sets appropriately rounded; supply adjusted well.
thus obtain rounded instance. Then, search welfare maximizing allocation
rounded instance, usage dynamic programming. allocation shown
optimal initial instance, well, feasible, modulo violation initial
supply constraints within factor (1 + ). light turning algorithm
truthful mechanism, use notation actual valuation functions definition
analysis below.
Fix constant > 0. First, [n], remove alternatives Di
d(`) > s` ` = 1, . . . , (if alternatives bidder removed, remove
i). Henceforth, use notation, U, [n], Di , etc., remaining alternatives
bidders. demands alternatives Di [n] rounded follows.
every [n] every Di , produce multiset d0 = (d0 (1), . . . , d0 (m))
that, distinct good ` [m], d0 (`) = b nd(`)
s` c. adapt supply
n
0
good appropriately, s` = e. Given rounded version problem instance,
use dynamic programming produce allocation it, immediately
translate allocation original problem instance, welfare-optimal
violates (original) supply constraints factor (1 + ). purposes
description follows, denote d0 rounded version demand d.
728

fiMechanisms Multi-unit Combinatorial Auctions

define dynamic programming table V(i, Y1 , . . . Ym ) = 1, . . . , n Y`
{0, 1, 2, . . . , s0` } ` [m]. cell V(i, Y1 , . . . , Ym ) stores maximum welfare
P
nx (`)
allocation X, i.e., j vj (xj ), whose rounded version X0 = (b sj` c)j,` uses multisets
demand sets bidders
P {1, 2, . . . , i}, total demand w.r.t. good
` = 1, . . . , precisely Y` , i.e., x0i (`) = Y` .
compute entries table V, observe that, problem V(1, Y1 , . . . Ym )
collection Y` that: (Y1 , . . . , Ym ) {0, 1, . . . , n e}m , easy solve.
entry V(1, Y1 , . . . Ym ) check bidder 1 alternative D1
d0 (`) = Y` , ` [m]. yes, let alternative maximum valuation;
assign V(1, Y1 , . . . , Ym ) = v1 (d) build auxiliary table A[1, Y1 , . . . Ym ] set
case {(1, d)}. Otherwise, bidder 1 alternative, assign
V(1, Y1 , . . . Ym ) = 0 A[1, Y1 , . . . Ym ] = {(1, 0)}. define V(i + 1, Y1 , . . . , Ym ), consider
bidder + 1 alternatives = (d(1), . . . , d(m)) Di+1 ; let
i+1

n

fi

fi
0
0
= max vi+1 (d) + V i, Y1 (1), ..., Ym (m) fi d0
dDi+1

(1)

where, i, define V(i, Y1 , . . . Ym ) = and, accordingly, A[i, Y1 , . . . Ym ] = { (i, 0) },
demand Di satisfying d0 Y. Consequently:
n

V(i + 1, Y1 , . . . , Ym ) = max i+1 , V(i, Y1 , . . . Ym ) .
Accordingly, i+1 V(i, Y1 , . . . Ym ), set:
A[i + 1, Y1 , . . . , Ym ] = A[i, Y1 , . . . , Ym ] {(i + 1, 0)},
otherwise:
A[i + 1, Y1 , . . . , Ym ] = A[i, Y1 d0 (1), . . . , Ym d0 (m)] {(i + 1, d)},
alternative Di+1 maximizing (1). Finally, inspect solutions
entries V(n, Y1 , . . . , Ym ) vectors (Y1 , . . . , Ym ) {0, 1, . . . , n e}m , take one
maximizes Social Welfare output solution given corresponding entry
table.
size table V n(d n e+1)m need time roughly O(maxi |Di |+m) compute
one entry table, overall time algorithm leads Fptas. optimality
respect sum bidders values easy verify. Let X = (x1 , x2 , . . . , xn )
denote feasible allocation original problem instance.
every good, ` = 1, . . . , m,
P j xi (`)n k n
P
P xi (`)n
n
have: xi (`) s` , or, equivalently, s` , thus s` = s0` .
is, X also feasible rounded problem instance. dynamic programming
algorithm inspect feasible solutions rounded problem instance output
one largest welfare it, optimum solution original problem instance
inspected well.
argue supply constraints s` , ` = 1, . . . , m, violated factor
1 + 2. Fix good ` {1, . . . , m} let X output allocation, respect
729

fiKrysta, Telelis, & Ventre

original problem instance. X chosen algorithm means dynamic programming search rounded
problem instance, feasible rounded
P j nxi (`) k
s0` = n e and, since:
problem instance. Thus, have:

s`
X n xi (`)


s`






obtain:

P

xi (`)

X n xi (`)
lnm


s`
+n

+ |{i|xi Di }|

n
+ 1 + n,


(1 + 2)s` .

Example Let us illustrate algorithms functionality simple example.
Consider n = 3 bidders = 2 distinct goods. Let supplies goods s1 = s2 = 4.
bidders values demand sets defined follows:
Bidder
Valuation Function
Demand Set
1
v1 ( (3, 4) ) = 1 v1 ( (4, 3) ) = 2 D1 = { (3, 4), (4, 3) }
2
v2 ( (3, 3) ) = 3
D2 = { (3, 3) }
3
v3 ( (2, 3) ) = 4 v3 ( (3, 2) ) = 5 D3 = { (2, 3), (3, 2) }
example evident feasible allocations involve assignment demand
single bidder, given supplies goods 4. Thus, optimal allocation
X ( 0, 0, (3, 2) ). Consider rounded problem = 2. rounded supply
two goods dn/e = d4/2e = 2. rounded demands bidders
follows:
Bidder
1
2
3
Demands (3, 4) (4, 3) (3, 3) (2, 3) (3, 2)
Rounded Demands (1, 1) (1, 1) (1, 1) (0, 1) (1, 0)
Observe demands bidder 1 rounded (1, 1). pose
problem, algorithm processes original demands, uses rounded
versions validate feasibility allocation builds respect rounded supply.
example, rounded supply good 2, algorithm output
allocation X = ( 0, (3, 3), (3, 2) ), welfare 8 superoptimal
inital instance. Although rounded versions allocated demands violate
rounded supplies goods (equal 2), violate original supplies 4, less
factor 1 + = 3 (particularly example, factor 1.5).
Note algorithm exact, grants every bidder multiset
demand set (or none). Assuming = O(1) essential result, even presence
supply constraints relaxation. proof claim given end section.
truthfulness Fptas, denoted below, follows fact optimizes
fixed range solutions.
Theorem 1 exists truthful Fptas multi-unit combinatorial auction problem
fixed number goods, bidders private multi-minded valuation functions,
defined, bidder, private collection multisets goods. fixed > 0,
Fptas fully optimizes social welfare, violating supplies goods within factor
(1 + ).
730

fiMechanisms Multi-unit Combinatorial Auctions

Proof. prove theorem show MiR range R = {X|b : A(b) =
X}. is, allocation X R bid vector
b, show SW (A(b), b)
SW (X, b), bid vector b = (bi (d), d)dDi
allocation X R,


let SW (X, b) Social
P Welfare allocation X, evaluated according bid
vector b, i.e., SW (X, b) = bi (X).


Fix allocation X bid vector b = (bi (d), d)dDi
; definition range,



A(b) = X. Recall
exists bid vector b, b = (bi (d), d)dDi


xi (`), bidder ` = 1, . . . , m, variable indicating many copies item
`, allocation X grants bidder i. Note X = A(b) grants
demanded alternatives (by exactness), exists demand di Di {0} that,
` = 1, . . . , m, xi (`)j= di (`).
Since X output A, definition
P ndi (`) k n
` = 1, . . . , m, s` .
let C set bidders b = (bC , bC ) b = (bC , bC ), is,
b b differ bids bidders set C. bidders C assume
true valuation function bi . bidder evaluates alternative xi = di
granted allocation X ei Di {0}. is, vi (di ) = vi (ei ). Assume,
sake contradiction, SW (X, b) > SW (A(b), b), i.e.:
X

bi (ei ) +

X

bj (X) >

j6C

iC

X

bi (A(b)) +

X

bj (A(b)).

(2)

j6C

iC

Since di (`) ei (`) ` = 1, . . . , C, setting ei = di 6 C, obtain:
X n ei (`)


s`



X n di (`)


s`



lnm


,

` = 1, . . . , m. solution grants bidder alternative ei Di {}
considered algorithm input b. solution Social Welfare SW (X, b)
therefore (2) contradiction definition A.
2
related result Briest et al. (2011) truthful Fptas single good limited
(not violated) supply; cannot generalized setting one supply
constraints.
4.1 Note Hardness
Note problem strongly NP-hard, allow violate supply constraints 2 (Chekuri & Khanna, 2005). well known problem strongly
NP-hard, exist FPTAS problem, unless P=NP (see, e.g., Vazirani, 2003). Also assumption fixed constant necessary. Otherwise
problem equivalent multi-unit Combinatorial Auctions hard approximate
polynomial time within m1/2 , > 0 (Lehmann et al., 2002). claim true,
even allow solutions violate supplies. particular:
731

fiKrysta, Telelis, & Ventre

Proposition 1 multi-unit combinatorial auction distinct goods, NPhard approximate Social Welfare within factor better m1/2 , even allow
multiplicative (1 + )-relaxation supply constraints, < 1.
Proof. argument follows: known hard approximate maximum
independent set problem graph G = (V, E) within factor m1/2 > 0,
|E| = (Hastad, 1996). using reduction Lehmann et al. (2002), reduce
problem problem set goods [m] = E set single-minded
bidders V ; bidders u V set contains edges adjacent u graph G
bidders valuation set 1. allow violate supply 1
good factor 1 + , < 1, feasible solution relaxed problem
independent set graph G. Thus relaxed problem equivalent maximum
independent set problem G.
2
4.2 Multi-dimensional Knapsack
discuss application Fptas, relation Multi-dimensional Knapsack
Problem (MdKP) (Chekuri & Khanna, 2005). Suppose given MdKP instance,
constant number distinct compartments, = O(1), compartment,
` = 1, 2, . . . , m, capacity s` . problem asks fit knapsack subset
universe, U, n given m-dimensional objects, sum collected objects
sizes dimension, `, exceed s` total value collected objects
maximized. object, = 1, . . . , n MdKP instance represented
vector di , represents dimensions, (di (1), . . . , di (m)) value, vi ,
hvi , di ( (R+ {0}) U ). Then, object corresponds single bidder i,
setting analyzed Section 4, valuation function vi (d) vi , every di ,
vi (d) = 0, every d(`) < di (`), ` = 1, . . . , m. Notice bidder
single-parameter, valuation function takes single non-zero value every
di demand set, Di , singleton, i.e., contains single multiset, di . Thus,
MdKP corresponds single-parameter version problem treated above.
apply Fptas MdKP, algorithm exact, mentioned
previously, allocates every bidder (read as: fits knapsack) either exact
alternative demand set, Di , none. worth mentioning singleparameter version, Fptas Section 4 shown monotone (Lehmann et al.,
2002; Briest et al., 2011), one carefully fixes tie-breaking rule. monotone allocation
algorithm ensures that: (single-parameter) bidder allocated single demand di
declares truthfully hvi , di i, also receives (declared) demand d0i ,
declares hvi0 , d0i i, vi0 vi d0i di (i.e., intuitively, asks less items offering
money). exact monotone allocation algorithm yield truthful mechanism
single-parameter setting, incorporation critical value payments see
work Lehmann et al. (2002) details.
Let us note that, generalize MdKP further, following manner. Instead
packing constraints (of form ) dimensions knapsack,
handle mix packing covering constraints (i.e., forms {, }),
long constant number dimensions, = O(1), one covering
packing constraint per dimension. generalized scenario follow
732

fiMechanisms Multi-unit Combinatorial Auctions

approach similar approach Section 4 obtain truthful Fptas fully
optimizes total value fitted items violates constraints factor
(1 + ). Violation constraints needed reason mentioned above,
note computational hardness, end Section 4.

5. Generalized Dobzinski-Nisan Method
discuss direct generalization method designed Dobzinski Nisan (2010),
truthful single-good multi-unit auction mechanisms. use methods generalization multiple goods next subsection, obtain truthful Ptas bidders
submodular valuation functions (over multisets). Let polynomial-time MiR
allocation algorithm = O(1) bidders s` units good ` = 1, . . . , m,
time complexity TA (t, s), = (s1 , . . . , sm ), approximation ratio 1. Then, algorithm
used routine within procedure Figure 1, obtain polynomial-time

MiR algorithm n bidders, approximation ratio ( t+1
).
Given = O(1), procedure executes algorithm every subset bidders
every combination certain pre-specified quantities goods. output
allocation considers rest bidders allocates optimally integral
number (multi-unit) bundles good. main result shown Dobzinski
Nisan (2010) single good also proved goods:
Theorem 2 Let Maximal-in-Range algorithm complexity TA (t, (s1 , . . . , sm )),
bidders s` units good ` = 1, . . . , m. Dobzinski-Nisan Method
MiR runs time polynomial log s1 , . . . , log sm , n, TA (t, (s1 , . . . , sm )), every

= O(1). Moreover, outputs allocation value least fraction ( t+1
)
optimum Social Welfare.
proof direct extension proof given Dobzinski Nisan (2010) single
good. Consider MiR algorithm A, used within Dobzinski-Nisan method;
executes polynomial time = O(1) bidders = O(1) distinct goods,
limited supply s` , ` [m]. Let RA denote range algorithm. verified
method outputs allocations (R, t, 1 , . . . , )-round, given following
definition round allocations (Dobzinski & Nisan, 2010):
Definition 3 = O(1), allocation (R, t, 1 , . . . , )-round if:
R set allocations and, X R, bidders allocated nonempty bundles. bidders allocated together s` ` units good
` = 1, . . . , m.
exists set |T | bidders, allocated according
allocation R.
`

P
bidder [n] \ receives exact
multiple max b 2n
units good `
2 c, 1

`
and:
x
(`)

n

max
b
c,
1
,

`
=
1,
.
.
.
,

i[n]\T
2n2

733

fiKrysta, Telelis, & Ventre

1. ` = 1, . . . , do:
1
(a) define u` := (1 + 2n
)



blogu s` c
2
`
(b) define L` := 0, 1, bu` c, bu` c, . . . , u`
, s`

2. every subset [n] bidders, |T | t, do:


1. every (1 , . . . , )
L
`=1 ` do:
1 Run s` ` units good ` [m] bidders .
2 Split remaining ` units (if ` > 0) fromeach good
` [m]
`
c,
1
units.
2n2 bundles (per good), max b 2n
2
3 Find optimal allocation equi-sized bundles among bidders [n] \ .
3. Return best allocation found.
Figure 1: Dobzinski-Nisan Method multiple goods.
definition, R corresponds range A, parameterized subset
bidders , i.e., R = RA (T ), executed. Then, = O(1), range
method subset allocations (RA (T ), , 1 , . . . , )-round, that:
(1 , . . . , ) (m
`=1 L` ), L` defined step 1.(b) method Figure 1,
[n], = |T | t. Formally, methods range RDN subset allocations:

n fi
fi
L
)


=
|T
|


RDN = X fi X (RA (T ), , 1 , . . . , )-round, (` )` (m
`=1 `
Example Part (I) continuing analyze methods range, let us exemplify
concept (R, t, 1 , . . . , )-round allocations. consider small instance
multi-minded bidders, similar considered previous section. argue
later, Dobzinski-Nisan method yield truthful Ptas (that respects supply
constraints goods), multi-minded bidders. Assume = 2 distinct goods, n = 5
bidders. assume supplies s1 = 200 = s2 goods. bidders demands
follows:
Bidder
Demand Set
1
D1 = { (75, 51), (49, 73) }
2
D2 = { (51, 27), (25, 49) }
3
D3 = { (48, 1) }
4
D4 = { (1, 1) }
D5 = { (1, 48) }
5
Let us exhibit round allocation instance, according Definition 3. = 2
1 = 2 = 100, consider first allocation:
X = ( (75, 51), (25, 49), (48, 2), (2, 2), 0 ),
734

fiMechanisms Multi-unit Combinatorial Auctions

x1 = (75, 51), x2 = (25, 49), x3 = (48, 2), x4 = (2, 2), x5 = 0. allocation
(R, 2, 100, 100)-round, according Definition 3, R denotes subset allocations
2 bidders receiving non-empty multisets remaining ones receiving appropriate multi-unit bundles per good. Indeed, set = {1, 2} (for corresponding
subset 2 bidders); bidders 1 2 obtains one demands. total
number units allocated two bidders per good exactly 100 = s` ` .
remaining 100 = ` units good, make 50 bundles ` /(2n2 ) = 2 units per
bundle. Bidder 3 receives 24 2-units bundles good 1 one 2-units bundle
good 2. Bidder 4 obtains one 2-units bundle good. Finally, bidder 5 receives
empty allocation. Notice x3 x4 essentially satisfy unique demands (48, 1)
(1, 1) bidders 3 4 respectively.
Another (R, 2, 100, 100)-round allocation (according Definition 3) is:
X0 = ( (75, 51), (52, 28), (48, 2), 0, 0 ),
required subset bidders = {1}. Bidder 1 obtains one demands;
bidders 2 3 receive 2-units bundles good; bidders 4 5 receive empty
allocations (i.e., zero 2-units bundles good). Notice X0 also (R, 1, 100, 100)round (i.e., set = 1). let us choose algorithm Dobzinski-Nisan
method, exhaustive search procedure, optimizes welfare (thus, approximation ratio = 1). Notice range RA (T ) A, chosen values
1 , 2 , trivially contains allocation bidders 1 2 receive X (when = {1, 2})
allocation bidder 1 X0 (when = {1, 2} = {1});
optimizes feasible allocations supplies 200 1 = 100 200 2 = 100
two choices . Thus, allocations X X0 also belong range RDN ,
defined above.
show optimization RDN approximates socially optimal allocation within

factor ( t+1
).
Lemma 1 Let X = (x1 , . . . , xn ) socially optimal allocation. exists allocation

X RDN SW (X) ( t+1
) SW (X ).
Proof. proof make use notation L` u` , defined Figure 1. Without
loss generality (because monotonicity valuation functions), assume units
goods allocated X v1 (x1 ) v2 (x2 ) P
vn (xn ). every good
` = 1, . . . , choose largest value ` L` s` ` ti=1 xi (`). executed
subset bidders = {1, . . . , t} s` P
` units good
P ` = 1, . . . , m, algorithm
outputs allocation (x1 , . . . , xt ) ti=1 vi (xi ) ti=1 vi (xi ).
consider good ` = 1, . . . , bidder jP
` {t + 1, . . . , n} maximum

number units X good. Define r` = ni=t+1 xi (`). xj` (`) rn` .
definition r` ` good `, r` ` . Also, ` chosen
Pt
2
largest possible value L` = { 0, 1, bu` c, bu` c, . . . , s` } satisfying s` ` + i=1 xi (`),
r`
. every bidder + 1 6= j` ` = 1, . . . , m,
must ` ur`` r` 2n
`

round allocation respect good ` multiple max b 2n
2 c, 1 . extra
units good ` take bidders j` may obtain unit good.
735

fiKrysta, Telelis, & Ventre

`
`
Observe may need add n 2n
2 2n extra units good `,
`
r`
take bidder j` , least n n units.
Thus, bidders except j` , ` = 1, . . . , increased units P
goods

1

obtain. j` + 1 v1 (x1 ) vn (xn ), vj` (xj` ) t+1
i=1 vi (xi )
vi (xi ) vi (xi ) 6= j` , ` = 1, . . . m. Then:

SW (X) =

X

vi (xi )






X

=

X

X

i=1

vi (xi )

X

vi (xi )

it+1

vi (xi )

it+1



t+1

vi (xi ) +

i=1

vi (xi ) +

i=1




X


X

vi (xj` )

`=1

+

X

vi (xi )




it+1



t+1



SW (X )
2

concludes proof.
lemma completes proof Theorem 2.

Example Part (II) revisit example discussed right statement
proof Lemma 1, order exemplify approximation implied Lemma.
end, assign values bidders demands described following table,
v > 0 small positive number V >> v large one. before,
s1 = s2 = 200.
Bidder
Valuation Function
1
v1 ( (75, 51) ) = v v1 ( (49, 73) ) = V
2
v2 ( (51, 27) ) = V v2 ( (25, 49) ) = v
3
v3 ( (48, 1) ) = V
4
v4 ( (1, 1) ) = v
5
v5 ( (1, 48) ) = V

D1
D2
D3
D4
D5

=
=
=
=
=

Demand Set
{ (75, 51), (49, 73) }
{ (51, 27), (25, 49) }
{ (48, 1) }
{ (1, 1) }
{ (1, 48) }

following socially optimal allocation X instance welfare 4V + v:
X = ( (49, 73), (51, 27), (48, 1), (1, 1), (1, 48) )
choosing = 2 = {1, 2}, exhibit welfare-approximate allocation
implied Lemma 1, follows. maximum value possible 1 2
satisfying s` ` x1 (`) + x2 (`) 100 = 1 = 2 . remaining bidders, bidder
3 maximum number units good 1 X bidder 5 maximum
number units good 2 X . Thus, j1 = 3 j2 = 5. Then, round
allocations bidders 3 4 w.r.t. good 2, one 2-units bundle (for them),
taking two units bidder j2 = 5. Accordingly, round allocations bidders
4 5 w.r.t. good 1, taking two units bidder j1 = 3. resulting allocation is:
X = ( (49, 73), (51, 27), (46, 2), (2, 2), (2, 46) )
welfare 2V + v, approaches half optimal welfare (as v becomes vanishingly small). Lemma 1 example guarantees least 1/3 optimal welfare,
736

fiMechanisms Multi-unit Combinatorial Auctions

algorithm used within Dobzinski-Nisan method welfare-optimizing exhaustive
search procedure. hand notice that, particular example = 2,
1 = 2 = 100, allocation = ( (49, 73), (51, 27), (48, 2), 0, (2, 48) ) almost optimal welfare, 4V , round according Definition 3. Thus, Dobzinski-Nisan
method examine return allocation least good.
Let us explain find optimal allocation multi-unit bundles goods (i.e.,
bundles identical units) bidders [n] \ , step 2.1.3 algorithm (Figure 1).
use dynamic programming. re-indexing bidders appropriately, assume
= {n + 1, . . . ,n}, thus [n]\ = {1, . . . , n t}. every = 1, . . . , n every
2
q = (q1 , . . . , qm )
i=1 [2n ] , define V(i, q) = V(i, (q1 , . . . , qm )) maximum value
welfare obtained allocating q` equi-sized bundles (of units)
good ` = 1, . . . , bidders 1, . . . , i. entry V(i, q) dynamic programming
table computed using:


0
0
0
V(i, q) = max
v
(q

b
,
.
.
.
,
q

b
)
+
V(i

1,
q

q
)
,

1

1

0
q q

q0 q taken component-wise; i.e., maximization occurs vectors q0
q 0 (`) q(`) ` = 1, . . . , m.
5.1 Simple Application: Multi-minded Bidders
generalized Dobzinski-Nisan method multiple distinct goods applied immediately setting multi-minded bidders, yield Ptas respects fully supply
constraints goods. = O(1) goods constant number bidders
optimum assignment found exhaustively polynomial time log s` , ` = 1, . . . , s,
m. particular, every bidders demand sets contains k demands,
exactly O(k ) cases examined exhaustively, optimum found. Plugging
algorithm procedure Figure 1, yields Ptas that, complementarily developments previous section, approximates optimum Social Welfare within factor
(1 + ) respects supply constraints.
5.2 Submodular Valuation Functions
consider submodular valuation functions multisets U, defined Kapralov,
Post, Vondrak (2013):
Definition 4 ` = 1, . . . , let e` unary vector e` (`) = 1 e` (j) = 0,
j 6= `. Let x denote two multisets U, x y, holds
component-wise. Then, non-decreasing function v : U 7 R+ submodular v(x + e` )
v(x) v(y + e` ) v(y).
assume valuation functions, exponentially large describe,
accessed algorithm value queries; i.e., algorithm asks bidders
value, particular multiset needs process.
design MiR approximation algorithm A, needed method. range
consider setting extension one considered Dobzinski Nisan
737

fiKrysta, Telelis, & Ventre

(2010). > 0, define = 1 + ; assigning bidders multi-unit bundles
good ` [m], cardinality equal integral power . every good
` [m], one n bidders (possibly different bidder per good) always obtain
remaining units specific good. show optimization range provides
good approximation unrestricted optimum Social Welfare; also, optimizing
range yields Fptas constant number n bidders. This, used within generalized
Dobzinksi-Nisan method yield Ptas number bidders.
Lemma

2 optimum assignment within defined range recovers least factor
2
socially optimal welfare.
2+2
Proof. Let X = (x1 , . . . , xn ) denote welfare maximizing assignment. round
iteratively particular good ` [m] iteration assignment units
bidder X , integral power . Let X[`] assignment rounding
respect `-th good. final assignment X X[m] approximate welfare
X[0] X .
beginning `-th iteration process assignment X[`1] , rounding
[`1]
[`1]
assignment multi-unit bundles good `. Assume w.l.o.g. x1 (`) x2 (`)
[`1]
xn (`). Also w.l.o.g., assume every bidder except bidder 1 receives
integral power units good `; bidder 1 receives remaining units. Let set
bidders partitioned [n] = E contains odd indices bidders E
even ones. consider two cases:
X [`1] X [`1]
X [`1] X [`1]
v xi

vi x

v xi
<
vi xi
.
(3)
iO

iE

iO

iE
[`1]

first case, every \ {1} round xi
(`) closest integral
[`1]
power , obtaining extra units rounding xi1 (`), 1 E,
[`]

[`1]

nearest appropriately chosen integral power . obtain xi (`) xi
[`1]

[`1]

[`1]

xi1 (`) = xi1 (`) ( 1)xi
[`1]

[`1]

(`) and:

[`1]

(`) xi1 (`) ( 1)xi1 (`)

[`1]

thus, xi1 (`) (2 )xi1 (`). ensure bidder 1 obtain integral power
[`1]

[`]

[`1]

, may need divide xi1 (`) , thus: xi1 (`) 1 xi1 (`) =
welfare emerging assignment X[`] is:

X X X
[`]
[`]
[`]
SW X[`] =
vi xi =
v xi +
vi xi
iO

i[n]



X



[`1]

vi x



iE

2 X [`]
+
v xi

iE

iO


X

2
[`1]
=
vi
+
SW X[`1]
v xi

iO
iO


2 2 X [`1] 2
v xi
+
SW X[`1]
=


X



[`1]
xi



iO

738

!

2 [`1]
xi1 (`).

fiMechanisms Multi-unit Combinatorial Auctions




2




1
1
SW X[`1] +
SW X[`1] =
SW X[`1]


1+
[`]

[`1]

second line follows submodularity; ` [m], xi1 (`) 2
xi1 (`),




[`]
[`1]
2
vi1 xi1 vi xi1 . last inequality, recall examining
P
[`1]
left-hand side case (3), thus, use that:
) 12 SW (X[`1] ).
iO vi (xi



P
P
[`1]
[`1]
Consider second case (3), iO vi xi
< iE vi xi
.
[`1]

E \ {2} round xi
(`) closest integral power ; extra units
[`1]
obtain 1 O, rounding xi1 (`) appropriately chosen
[`1]

closest integral power . x2 (`) rounded closest integral power
[`1]
[`1]
[`]
(contrary rest xi
(`), E), i.e., x2 (`) 1 x2 (`). E \ {2}
[`]

[`1]

xi (`) xi

(`) take:
[`]

xi1 (`)

2
1 [`1]
[`1]
[`1]
xi1 (`) ( 1)xi
(`)
xi1 (`)



(4)

Then, Social Welfare X[`] have:
X X X

[`]
[`]
[`]
v xi =
v xi +
v xi
SW X[`] =
i[n]

iO

iE


X
2 X [`1] 1 [`1]
[`]

v xi
+ v 2 x2
+
v xi


iO
iE\{2}
!
X




X
1 [`1]
2
[`1]
[`1]
SW X[`1]
v xi
+ v 2 x2
+
v xi
=


iE
iE\{2}






X
2
2 2
1
[`1]
[`1]
v2 x2
+
SW X[`1]
=
vi xi
+



iE\{2}


1
2

1 X
[`1]
[`1]
>
vi x
+
v 2 x2
+
SW X[`1]



iE\{2}

2




1
2

SW X[`1] +
SW X[`1] =
SW X[`1]
2

2 + 2
second line derivation due submodularity: factors sum
[`1]
[`]
[`1]
odd-indexed bidders v2 (x2 ) follow (4) x2 (`) 1 x2 (`).
last inequality, used fact examining right-hand side case
P
[`1]
(3); then, iE vi ( xi
) 12 SW (X[`1] ).
Thus, > 0, assignment
range approximates
within
p thedescribed
q
2
1
optimum Social Welfare within factor 2+2 1+ , integers p, q,
p + q = m. result follows

1
1+



2
2+2 .

obtain following (intermediate) result:
739

2

fiKrysta, Telelis, & Ventre

Theorem 3 multi-unit combinatorial auctions n = O(1) submodular bidders,
= O(1) distinct goods, good ` [m] available arbitrary supply, exists
truthful deterministic Fptas that, 1, approximates optimum Social Welfare
within factor (1 + ).
Proof. fixed > 0 search specified range exhaustively polynomial
time; find allocation maximum Social Welfare, try O(log s` ) cases
n 1 bidders, given fixed bidder assigning remaining units. Thus
time required trying possible bundle assignments ofa specific good `
possible choices remainders bidder n(log s` )n1 . every fixed
allocation specific good need try possible allocations remaining 1
goods, overall complexity total nm (log max` s` )(n1)m , polynomially
bounded constant n. Also notice that, 1 obtain Fptas, because:
log max s` = (log2 (1 + ))1 (log2 max s` )
`

`

log21 (1 + ) 1 .

2

Using Theorem 3 within general Dobzinski-Nisan method, obtain:
Corollary 1 exists truthful Ptas multi-unit combinatorial auctions constant number distinct goods submodular valuation functions.

6. General Valuation Functions
Interestingly, direct generalization Dobzinski-Nisan method constant number multiple goods immediately yield, general valuation functions, result
comparable one shown Dobzinski Nisan (2010) single good; = 1
truthful 2-approximation mechanism obtained (and factor shown optimal). = 1, relevant MiR algorithm involved Theorem 2 solves optimally
case = 1 bidder, allocating units goods him. monotonicity
valuation functions guarantees allocation optimal = 1 bidder. factor 2
approximation follows. > 1 goods however, Theorem 2 appears require different
algorithm (for, possibly, > 1 bidders), yield comparable (constant approximation)
result. Instead, constant (m+1)-approximation case general valuation functions
accessed value queries obtained, simple modification direct approach
given Dobzinski Nisan, general valuation functions.
describe scratch MiR allocation algorithm. algorithm splits every
good number units n2 equi-sized bundles size b` = b ns`2 c; also creates single
extra bundle (per distinct good, `), containing remaining units r` , n2 b` +r` = s` .
algorithm allocates optimally whole bundles units good n bidders.
First show range approximates factor (m + 1) optimum Social
Welfare. Let X = (x1 , . . . , xn ) denote socially optimal allocation. Beginning
X , produce allocation range within algorithm optimizes,
approximates SW (X ) within factor (m + 1). Assume w.l.o.g. items allocated
X (by monotonicity valuation functions) and, good ` = 1, . . . , m, let
740

fiMechanisms Multi-unit Combinatorial Auctions

j` = arg maxi xi (`). xj` (`)
here.
Either:


X

vj` (xj` )

`=1



s`
n.

X

Define L = {j1 , . . . , jm }. consider two cases

vi (xi ),

i6L

or:


X
`=1

vj` (xj` ) <

X

vi (xi ).

i6L

first case, let us denote Y` = (y1` , y2` , . . . , yn` ) ` = 1, . . . ,
allocation assigns bundles goods bidder j` L (thus, yi` = (0, . . . , 0),
every 6= j` ). allocations, consider = arg maxY` vj` (yj`` ). Then, SW (Y)
P
1 Pm


i6L vi (xi ). Putting inequalities together
`=1 vj` (xj` ), thus, also: SW (Y)

1
yields SW (Y) m+1 SW (X ). Notice allocation examined MiR
algorithm. second case build allocation X, rounding separately
good ` (optimal) allocation bidders 6 L nearest multiple b` .
units needed purpose find good ` corresponding bidder
j` L, may obtain unit X. possible add n ns`2 =
s`

X gives
n xj` (`) units total rounding. way make allocation P
multi-unit bundles good bidders [n] \ L satisfies SW (X) i6L vi (xi ),
1 Pm
1


thus, also: SW (X) >
`=1 vj` (xj` ). Then, deduce SW (X) m+1 SW (X ). Notice
allocation X also examined MiR algorithm. Thus, exists solution
within range, approximates SW (X ) within constant factor, (m + 1).
complete analysis, show compute MiR allocation described
range, using dynamic programming. Let r = (r1 , . . . , rm ) denote vector amounts
correspond bundles remainders per good described above. Given L 2{1,...,m}
denote r[L] projection r indices L; remaining coordinates set
0. Let b = (b1 , . . . , bm ). subset L 2{1,...,m} , define V L (i, q), q = (q1 , . . . , qm )
maximum welfare achievable allocating q` multi-unit bundles
good ` = 1, . . . , among bidders 1, . . . , remainders bundle goods
` L. compute V L (i, q) follows:
n


0
0
0
L\L0
0
V L (i, q) = max
max
v
(q

b
,
.
.
.
,
q

b
)
+
r[L
]
+
V
(i

1,
q

q
)

1

1

0
0
0 q
L L q1 q1 ,...,qm


= O(1), entries dynamic programming table computed
polynomial time. Thus:
Theorem 4 exists truthful polynomial-time mechanism multi-unit Combinatorial Auctions constant number distinct goods, m, general valuation functions
that, using value queries, approximates welfare socially optimal assignment within
constant factor, (m + 1).

7. Conclusions
paper analyzed deterministic mechanisms multi-unit Combinatorial Auctions
constant number distinct goods, limited supply. analyzed particular
Maximal-in-Range allocation algorithms (Nisan & Ronen, 2007), optimizing Social
Welfare multi-unit combinatorial setting that, paired VCG payments, yield
741

fiKrysta, Telelis, & Ventre

truthful auctions. main results include (i) truthful Fptas multi-minded bidders,
approximates supply constraints within factor (1 + ) optimizes Social
Welfare; (ii) deterministic truthful Ptas submodular bidders, approximates
Social Welfare within factor (1 + ) without violating supply constraints. achieving
(ii), used direct generalization single-good multi-unit allocation method proposed
Dobzinski Nisan (2010). discussed developments best possible
terms time-efficient approximation, follows relevant hardness results. Finally,
showed treat general (unrestricted) valuation functions setting, appropriately adjusting analysis Dobzinski Nisan (2010). Closing gap
communication complexity lower bound 2 (for single good) Dobzinski Nisan
(m + 1)-approximation result = O(1) goods, requires understanding
communication complexity general setting.

Acknowledgments
thank three anonymous reviewers helping us significantly improving presentation work. also thank Jinshan Zhang, pointing technical inconsistency
earlier version paper, Fabrizio Grandoni Stefano Leonardi,
useful discussions early stage work.
Piotr Krysta acknowledges support EPSRC grant EP/K01000X/1.
Carmine Ventre acknowledges support EPSRC grant EP/M018113/1.
Orestis Telelis acknowledges support research project DDCOD(PE6-213), implemented within framework Action Supporting Postdoctoral Researchers
Operational Program Education Lifelong Learning (Actions Beneficiary: General Secretariat Research Technology), co-financed European Union
(European Social Fund ESF) Greek State.

References
Archer, A., Papadimitriou, C. H., Talwar, K., & Tardos, E. (2003). Approximate Truthful Mechanism Combinatorial Auctions Single Parameter Agents. Internet
Mathematics, 1 (2), 129150.
Ausubel, L. M., & Milgrom, P. (2010). Lovely Lonely Vickrey Auction. Cramton,
P., Shoham, Y., Smith, V. L., & Steinberg, R. (Eds.), Combinatorial Auctions, pp.
1740. MIT Press.
Bartal, Y., Gonen, R., & Nisan, N. (2003). Incentive Compatible Multi Unit Combinatorial Auctions. Halpern, J. Y., & Tennenholtz, M. (Eds.), Proceedings 9th
Conference Theoretical Aspects Rationality Knowledge (TARK-2003), pp.
7287. ACM.
Bikhchandani, S., de Vries, S., Schummer, J., & Vohra, R. (2011). Ascending Vickrey
Auction Selling Bases Matroid. Operations Research, 59 (2), 400413.
742

fiMechanisms Multi-unit Combinatorial Auctions

Blumrosen, L., & Nisan, N. (2007). Combinatorial Auctions. Nisan, N., Roughgarden,
T., Tardos, E., & Vazirani, V. V. (Eds.), Algorithmic Game Theory, pp. 267299.
Cambridge University Press.
Briest, P., Krysta, P., & Vocking, B. (2011). Approximation Techniques Utilitarian
Mechanism Design. SIAM Journal Computing, 40 (6), 15871622.
Chekuri, C., & Khanna, S. (2005). Polynomial Time Approximation Scheme
Multiple Knapsack Problem. SIAM Journal Computing, 35 (3), 713728.
Clarke, E. (1971). Multipart Pricing Public Goods. Public Choice, 11 (1), 1733.
Daniely, A., Schapira, M., & Shahaf, G. (2015). Inapproximability Truthful Mechanisms
via Generalizations VC Dimension. Servedio, R. A., & Rubinfeld, R. (Eds.),
Proceedings 47th Annual ACM Symposium Theory Computing, STOC
2015, Portland, OR, USA, June 14-17, 2015, pp. 401408. ACM.
Dobzinski, S., & Dughmi, S. (2013). Power Randomization Algorithmic Mechanism Design. SIAM Journal Computing, 42 (6), 22872304.
Dobzinski, S., & Nisan, N. (2010). Mechanisms Multi-Unit Auctions. Journal Artificial
Intelligence Research, 37, 8598.
Dobzinski, S., Nisan, N., & Schapira, M. (2010). Approximation Algorithms Combinatorial Auctions Complement-Free Bidders. Mathematics Operations Research,
35 (1), 113.
Grandoni, F., Krysta, P., Leonardi, S., & Ventre, C. (2014). Utilitarian Mechanism Design
Multi-Objective Optimization. SIAM Journal Computing, 43 (4), 12631290.
Groves, T. (1973). Incentives Teams. Econometrica, 41 (4), 617631.
Hastad, J. (1996). Clique Hard Approximate Within n1 . 37th Annual Symposium Foundations Computer Science (FOCS96), pp. 627636. IEEE Computer
Society.
Holzman, R., Kfir-Dahav, N. E., Monderer, D., & Tennenholtz, M. (2004). Bundling Equilibrium Combinatorial Auctions. Games Economic Behavior, 47 (1), 104123.
Kapralov, M., Post, I., & Vondrak, J. (2013). Online Submodular Welfare Maximization:
Greedy Optimal. Khanna, S. (Ed.), Proceedings Twenty-Fourth Annual
ACM-SIAM Symposium Discrete Algorithms (SODA13), pp. 12161225. SIAM.
Kelly, T. (2004). Generalized Knapsack Solvers Multi-Unit Combinatorial Auctions:
Analysis Application Computational Resource Allocation. Faratin, P., &
Rodrguez-Aguilar, J. A. (Eds.), Agent-Mediated Electronic Commerce VI, Theories
Engineering Distributed Mechanisms Systems (AAMAS 2004 Workshop, AMEC 2004), Vol. 3435 LNCS.
Khot, S., Lipton, R. J., Markakis, E., & Mehta, A. (2008). Inapproximability Results
Combinatorial Auctions Submodular Utility Functions. Algorithmica, 52 (1),
318.
Kothari, A., Parkes, D. C., & Suri, S. (2005). Approximately-Strategyproof Tractable
Multiunit Auctions. Decision Support Systems, 39 (1), 105121.
743

fiKrysta, Telelis, & Ventre

Lavi, R., & Swamy, C. (2011). Truthful Near-Optimal Mechanism Design via Linear
Programming. Journal ACM, 58 (6), 25.
Lehmann, B., Lehmann, D. J., & Nisan, N. (2006). Combinatorial Auctions Decreasing
Marginal Utilities. Games Economic Behavior, 55 (2), 270296.
Lehmann, D., Muller, R., & Sandholm, T. (2010). Winner Determination Problem.
Cramton, P., Shoham, Y., Smith, V. L., & Steinberg, R. (Eds.), Combinatorial
Auctions. MIT Press.
Lehmann, D. J., OCallaghan, L., & Shoham, Y. (2002). Truth Revelation Approximately
Efficient Combinatorial Auctions. Journal ACM, 49 (5), 577602.
Milgrom, P. (2004). Putting Auction Theory Work. Cambridge University Press.
Mirrokni, V. S., Schapira, M., & Vondrak, J. (2008). Tight Information-Theoretic lower
bounds Welfare Maximization Combinatorial Auctions. Proceedings 9th
ACM Conference Electronic Commerce (ACM EC), pp. 7077.
Mualem, A., & Nisan, N. (2002). Truthful Approximation Mechanisms Restricted
Combinatorial Auctions. Dechter, R., & Sutton, R. S. (Eds.), Proceedings
Eighteenth National Conference Artificial Intelligence Fourteenth Conference
Innovative Applications Artificial Intelligence (AAAI/IAAI 2002), pp. 379384.
AAAI Press / MIT Press.
Mualem, A., & Nisan, N. (2008). Truthful Approximation Mechanisms Restricted
Combinatorial Auctions. Games Economic Behavior, 64 (2), 612631.
Nisan, N. (2014). Algorithmic Mechanism Design, Lens Multi-Unit Auctions.
Aumann, R., & Hart, S. (Eds.), Handbook Game Theory, Vol. IV. Elsevier NorthHolland.
Nisan, N., & Ronen, A. (2007). Computationally Feasible VCG Mechanisms. Journal
Artificial Intelligence Research, 29, 1947.
Nisan, N., & Segal, I. (2006). Communication Requirements Efficient Allocations
Supporting Prices. Journal Economic Theory, 129 (1), 192224.
Nisan, N., & Ronen, A. (2001). Algorithmic Mechanism Design. Games Economic
Behavior, 35 (1-2), 166196.
Sandholm, T. (2010). Optimal Winner Determination Algorithms. Cramton, P., Shoham,
Y., Smith, V. L., & Steinberg, R. (Eds.), Combinatorial Auctions. MIT Press.
Vazirani, V. V. (2003). Approximation Algorithms. Springer-Verlag.
Vickrey, W. (1961). Counterspeculation, Auctions, Competitive Sealed Tenders. Journal Finance, 16 (1), 837.
Vocking, B. (2012). Universally Truthful Approximation Scheme Multi-Unit Auctions.
Rabani, Y. (Ed.), Proceedings Twenty-Third Annual ACM-SIAM Symposium
Discrete Algorithms (SODA12), pp. 846855. SIAM.

744

fiJournal Artificial Intelligence Research 53 (2015) 779-824

Submitted 05/15; published 08/15

Belief Change Uncertain Action Histories
Aaron Hunter

aaron hunter@bcit.ca

British Columbia Institute Technology
Burnaby, BC, Canada

James P. Delgrande

jim@cs.sfu.ca

Simon Fraser University
Burnaby, BC, Canada

Abstract
consider iterated belief change occurs following alternating sequence
actions observations. instant, agent beliefs actions
occurred well beliefs resulting state world. represent
problems sequence ranking functions, agent assigns quantitative plausibility
value every action every state point time. resulting formalism able
represent fallible belief, erroneous perception, exogenous actions, failed actions.
illustrate framework generalization several existing approaches belief
change, appropriately captures non-elementary interaction belief update
belief revision.

1. Introduction
Many formal approaches introduced reasoning belief change context actions observations (Jin & Thielscher, 2004; Shapiro, Pagnucco, Lesperance,
& Levesque, 2011; Delgrande & Levesque, 2012). general, underlying assumption
agents perform belief update following actions belief revision following observations. Existing formalisms, part, treated actions observations
independently, little explicit discussion interaction two.
paper, consider belief change occurs due alternating sequence actions
observations. interested action domains agent may erroneous
beliefs, state world well action history.
Let K denote beliefs agent, given set possible worlds. 1 n,
let Ai denote action let Oi denote observation. Informally, interested
sequences form
K A1 O1
(1)
update operator revision operator. interpretation
expression flexible actions may understood represent actions executed
particular agent, may exogenous. Note sequences may contain
conflicting information. example, observation may possible following
actions A1 , . . . , . case, two options.
1. Reject .
2. Accept , modify A1 , . . . , .
c
2015
AI Access Foundation. rights reserved.

fiHunter & Delgrande

order determine option preferable specific problem, agent needs
able compare plausibility plausibility Ai .
Expressions form (1) previously addressed, assumption
ontic action histories infallible recent observations take precedence older observations (Hunter & Delgrande, 2011). Clearly, action domains
assumptions reasonable. paper, propose flexible approach
actions observations represented Spohn-style ranking functions.
take approach gives uniform treatment plausibility beliefs, observations, actions. presented conflicting information, agent simply
compare relative plausibility action observation; uniform representation
events makes straightforward determine plausible sequence. Moreover, quantitative plausibility values, encode variety distinct scenarios
manipulating magnitudes plausibility values alternative events.
paper makes several contributions existing work epistemic action effects.
main contribution formal mechanism reasoning incorrect weakly held
beliefs related action histories. Existing formalisms generally unable compare
plausibility action occurrence plausibility state world.
problem because, practical reasoning problems, agents often put position
either believe certain fact holds believe action
occurred. using formal tool represent beliefs actions states,
explicitly address manner prior action occurrences postulated retracted
response new observations.
second contribution work flexible treatment weak unreliable observations. revision operators incorporate new observation, obvious
desirable feature many reasoning domains. many cases, preferable
discard unreliable observation conflicts current, strongly held beliefs. However,
approach simply allow unreliable observation discarded. Since
use ranking functions represent observations, observation also includes plausible
alternatives. such, observation actually provide evidence several different
states, differing degrees. see useful representing observations
states similar appearance. Similarly, ranking functions give natural representation addititive evidence, form observations must occur several times
changing agents beliefs.
formulate results simple transition system framework makes
treatment action effects explicit easy compare elaborate action
formalisms. However, fundamental approach dealing uncertainty
actually require transition systems used action effects. intend
methodology described compete alternative formalisms representing
epistemic action effects; rather, provide high-level approach dealing uncertain
action histories focuses specifically interaction actions observations.
significant feature work demonstrates single representation
plausibility used model iterated beliefs actions states simultaneously;
basic approach could employed action formalisms. practical level,
demonstrate utility work giving series examples involving belief change
relative weight given actions observations varies. suggest
780

fiBelief Change Uncertain Action Histories

work advances existing work reasoning epistemic action effects provide
flexible, elaboration tolerant approach capturing several different kinds belief change
occur uncertainty action occurrences. Note paper
extended version work presented Hunter Delgrande (2006).
proceed follows. Section 2, introduce formal preliminaries.
define general class plausibility functions Section 3, show sequence
plausibility functions used represent uncertain sequence actions
observations. refer sequence graded world view, demonstrate
agents beliefs event histories captured graded world views
taking aggregates constituent plausibility functions. Section 4, demonstrate
graded world views seen epistemic states, use basic framework
define belief change domains involving uncertainty actions observations
occurred. compare approach related work Section 5,
discuss limitations advantages Section 6. Section 7, offer concluding
remarks.

2. Preliminaries
section, introduce standard formal machinery modelling belief change,
reasoning action effects. also introduce simple motivating example
illustrate sort problem would like address.
2.1 Belief Revision
Belief revision refers process agent incorporates new information along
pre-existing beliefs. influential approach belief revision AGM
approach (Alchourron, Gardenfors, & Makinson, 1985). Let F denote finite set fluent
symbols, represent binary properties world may change time.
example, may fluent symbol Raining F true case raining.
state propositional interpretation F, indicating fluents true
false. AGM approach belief revision, beliefs agent represented
belief set, deductively closed set formulas F. Since F finite,
equivalently define beliefs agent represented single formula.
Informally, belief revision operator function takes belief set formula revision input returns new formula represents new belief set
incorporating . AGM revision operator binary function satisfies AGM
postulates. following reformulation AGM postulates due Katsuno
Mendelzon (1991). postulates, denotes logical equivalence.
[R1]
[R2]
[R3]
[R4]
[R5]
[R6]

implies .
satisfiable, .
satisfiable, satisfiable.
1 2 1 2 , 1 1 2 2 .
( ) implies ( ).
( ) satisfiable, ( ) implies ( ) .

781

fiHunter & Delgrande

class AGM revision operators captured semantically introducing
formal notion plausibility. particular agent, say state world
plausible another state s0 agent likely abandon belief
s0 presented new information. turns every AGM revision operator
characterized class plausibility orderings set states.
proved several different representations plausibility, including total pre-orders
states (Katsuno & Mendelzon, 1991), systems spheres (Grove, 1988), ordinal
conditional functions (Spohn, 1988).
belief state set states, informally set states agent considers
possible. observation also set states, informally represents peice
information agent receives provides evidence actual state .
paper, primarily interested belief change process states rather
formulas; clear AGM approach equivalently defined belief states.
restricted set fluents set actions finite,
really convenience discussing examples. formal model based
transition systems ranking functions sets. would certainly possible
define transition relations ranking functions infinite sets. Since definition
aggregate general, would introduce formal complications. However,
point on, maintain restriction finite domains order simplify
discussion.
2.2 Transition Systems
interested action domains described supplementing set F
fluent symbols finite set action symbols transition system describing
effects actions (Gelfond & Lifschitz, 1998). pair (F, A) called action signature.
defined state interpretation F, often convenient
identify state set fluent symbols true s. use convention
following definition, throughout rest paper.
Definition 1 transition system pair hS, Ri 2F , R S.
restrict attention deterministic transition systems, i.e. assume hs, A, s0 R
hs, A, s00 R implies s0 = s00 . also assume always contains distinguished
null action symbol denoted .
Belief update belief change occurs agent becomes aware change
state world. Note distinct process belief revision,
typically understood capture belief change occurs agent obtained new information unchanged world. One highly influential approach
belief update Katsuno-Mendelzon approach (Katsuno & Mendelzon, 1992),
superficially similar AGM revision new information incorporated
encoded propositional formula. contrast, paper, define update
respect action effects given underlying transition system. words,
define belief update operators take belief state action input, return
new belief state represents agents new beliefs action executed.
782

fiBelief Change Uncertain Action Histories

Definition 2 Let = hS, Ri transition system. update function : 2S 2S
given = {s | hs0 , A, si R s0 }.
remark notion belief change also called belief progression action
progression. Note possible general case result update
empty, case transition system include outgoing edge labelled
state . order avoid problem, often convenient restrict attention
transition systems every action outcome every state. practice,
achieved assuming self-loop action state outcome
state given.
2.3 Belief Evolution
previous work, introduced so-called belief evolution operators reason alternating sequences updates revisions (Hunter & Delgrande, 2011). belief evolution
operator defined respect fixed AGM revision operator fixed update
operator . action observation , let 1 (A) denote set
{s} . Note set may empty. belief evolution operator defined
that, belief state ,
hA, = ( 1 (A)) A.
complete definition actually defines belief change sequence actions
observations; details definition required present. important
point way observation incorporated depends preceding actions.
intuition behind belief evolution final state must possible effect
recently executed action A. intuition satisfied original definition
revising initial belief set prior computing effects A. result, belief evolution
operators non-Markovian character; observation incorporated
considering current state world. Instead, agent incorporates new observation
looking back original state together complete history actions. However,
operation also understood Markovian manner allow current belief
state include representation states ruled based
actions previously occurred. manner, define Markovian form
belief revision equivalent belief evolution (Hunter, 2014).
Belief evolution provides reasonable model problems like Moores litmus paper
problem (Moore, 1985). problem, agent dips piece litmus paper beaker
determine beaker contains acid base. Hence, agent performing
action first observing results. seems, however, observed results
affect agents initial belief state. is, litmus paper turns red,
agent likely conclude beaker contained acid even dipping.
Belief evolution operators satisfy following properties. properties, A,
denotes sequence action symbols indeterminate length, 2F denotes set
states F. symbols range 2F , though think
belief state think observation. Following standard convention
postulates, implicitly quantify universally variables.
783

fiHunter & Delgrande

1. (2F A) 6= , ( A)
2. (2F A) = , ( A) =
3. ( A) ( A)
4. ( A) 6= , ( A) ( A)
5. ( A) 2F
Informally, properties assert agent respect history actions executed incorporating new observation. Note assuming AGM
revision operator, would appear make properties (1) (3) trivial. However,
included properties belief evolution emphasize fact actions
preceding obervation need considered cases revision occurs (Hunter
& Delgrande, 2011).
One main limitations belief evolution possible represent
erroneous action histories; assumed action history always correct.
reasonable assumption action domains single agent executing actions
fail. However, exogenous failed actions permitted, assumption
difficult support. general, agent may incorrect beliefs actions
occurred past. One aims paper generalize previous work
allow erroneous action histories.
2.4 Motivating Example
introduce common-sense example agent needs compare plausibility
certain actions plausibility observations. return example
periodically introduce formal machinery.
Consider simple action domain involving four agents: Bob, Alice, Eve, Trent. Bob
places chocolate chip cookie desk leaves room; believes one
likely eat cookie gone. Time 1, Bob knows Alice desk.
Time 2, Bob knows Eve desk. Eve leaves desk, Trent comes
tells Bob bite taken cookie.
Given preceding information, Bob draw three reasonable conclusions: Alice
bit cookie, Eve bit cookie, Trent gave poor information. Bob
additional information world, conclusion equally plausible. However,
suppose Bob additional information. particular, suppose
Alice close friend Bob shared cookies past. Moreover, suppose
Bob believes Trent always honest. Bobs additional information Alice
Trent provides sufficient basis determining three possible conclusions
plausible.
Informally, prior Trents report, Bob believes cookie unbitten
earlier points time. Trent tells cookie bitten, must determine
plausible world history consistent information. case, plausible
solution conclude Alice bit cookie. Note conclusion requires Bob
alter subjective view action history. non-monotonic character
784

fiBelief Change Uncertain Action Histories

belief change context, Bob may forced postulate retract actions
time response new observations. consequences changing action history
determined underlying transition system. order represent kind
reasoning, need able compare plausibility action occurrences different
points time.
example illustrates kind action scenario would like capture,
requires agent determine plausible history given priori
notion plausibility actions observations. instance, intuitively clear
problem resolved without comparing plausibility Trents report
accurate versus plausibility Alice biting cookie. addressing issue
straightforward manner, demonstrate existing actions formalisms extended
employed handle similar situations.
possibly one contentious issue discussion example. information provided Trent really observation usual sense word; instead,
report information external source. However, sections follow,
treat reports observations manner. Specifically, capture
ranking function states indicates states supported
observation/report degree. course, reality, observations reports
quite different manner report incorporated depends trust
reporting agent. relationship trust belief change topic current
interest, generally handled introducing extra formal machinery encode
trust held another agent (Lorini, Jiang, & Perrussel, 2014; Hunter & Booth, 2015).
would certainly possible follow approach present paper, using distinct
formal tools capture trust phenomenon distinct perceived accuracy
sensing. However, mathematically, would like end single ranking
states nevertheless. such, present paper, convenient represent reported information single combined ranking captures final plausibility
attached state based considerations agent might make.

3. Ranking Functions Actions States
approach presented paper based simple notion: agent uncertain
action observation, resolving uncertainty generally involves comparing
relative likelihood possible alternatives. work distinguished fact
use sequences ranking functions represent uncertainty actions states.
see sequences ranking functions capture many natural reasoning problems.
developing high-level representations problems, see notion
magnitude likelihood useful reasoning belief change uncertain action
histories. allows us compare work existing formalisms reasoning
epistemic action effects, particularly representation uncertainty
limited orderings states. fundamental goal demonstrate that,
cases, sequences quantitative plausibility orderings expressive advantage
significant perspective knowledge representation. aim develop
approach high-level, manner easily translated action
formalisms.
785

fiHunter & Delgrande

3.1 Plausibility Functions
interested action domains agents beliefs action history may
incorrect. context, action believed executed given point
time represented total pre-order possible actions. minimal elements
pre-order represent actions likely executed, moving higher
ordering gives increasingly implausible possibilities. Representing actions
manner allows agent determine plausible alternative actions face conflicting
evidence. Similarly, agent needs mechanism ordering states order represent
fallible observations fallible beliefs. Moreover, would like able compare
orderings actions orderings states. One natural way create mutually
comparable orderings assigning quantitative plausibility values every action
state every point time. Towards end, define plausibility functions.
Definition 3 Let X non-empty set. plausibility function X function
r : X N.
r plausibility function r(x) r(y), say x least plausible
y. interested plausibility functions finite sets, always
non-empty set minimally ranked elements.
Plausibility functions inspired Spohns ordinal conditional functions (Spohn,
1988), important differences. First, allow plausibility functions
arbitrary set X, rather restricting attention propositional interpretations.
allows us treat actions manner treat observations. Another
important difference ordinal conditional functions must always assign rank 0
non-empty subset elements domain. Plausibility functions restricted
manner; minimal rank given plausibility function may greater 0.
defined plausibility functions manner interested taking sums
plausibility functions, need ensure sums also define plausibility
functions.
remark Darwiche Pearl also consider ranking functions necessarily assign rank 0 states (Darwiche & Pearl, 1997). However, Darwiche Pearl
define belief state associated r set states assigned rank 0.
convention, ranking functions never assign rank 0 associated
empty belief state. contrast, associate non-empty belief state every plausibility
function.
introduce useful terminology notation. Let r plausibility function
X. minimum maximum values obtained r denoted minr maxr ,
respectively. define Bel(r) set {s | r(s) = minr }. notation intended
suggest Bel(r) set actions states believed. clear,
say state believed, mean far agent concerned, actual world
could described s. hand, say action believed,
mean agent views action executed. Note minr always
defined, non-empty set natural numbers minimum element.
hand, maxr guaranteed defined X finite. However,
concerned plausibility functions states actions; finite sets
according original definitions.
786

fiBelief Change Uncertain Action Histories

X, define r() minimum value obtained r .
degree strength plausibility function r least n minr +n = r(s)
6 Bel(r). Hence, degree strength r span plausibility
minimally ranked elements non-minimally ranked elements. r degree
strength n, means every 6 Bel(r) plausibility value least n
higher r(Bel(r)). two natural interpretations degree strength
plausibility function r set states. think r initial epistemic state,
degree strength indication strongly believed actual state
Bel(r). think r observation, degree strength measure
subjective reliability r. case X set states, use terms
degree strength degree belief interchangeably.
notion degree strength crucial importance approach. use
total pre-order represent plausibility, really corresponding notion
strength distinguish situation plausible belief strongly held
versus one weakly held. kind distinction essential
sort sequence events; need notion strength belief decide
state action hardest give up. possible represent kind information
ordering empty levels, course. However, focus aggregating
sequences belief states actions. order make simple possible, suggest
better use compact representation given quantitative ranking function
lends naturally arithmetical combinations.
Note Spohn (1988) defines degree strength subset X, rather
degree strength ranking function. definition coincides Spohns definition
identify degree strength r Spohns degree strength set Bel(r).
Hence, use conception degree strength, interested
strength belief minimally ranked elements.
order illustrate application plausibility functions different domains,
continue simple example.
Example (contd) Let F = {B iteT aken} let = {B iteAlice, BiteEve}.
actions effect, namely make fluent B iteT aken become true.
represent problem 3 plausibility functions: a1 , a2 , o2 .
1. a1 plausibility function actions Time 1
2. a2 plausibility function actions Time 2
3. o2 plausibility function states Time 2
Informally, function obtain minimum value event Bob considers
plausible given point time. Since Bob initially believes one
eat cookie, a1 a2 obtain minimum value null action . Trents
report cookie bitten Time 2 represented plausibility function
states, defining o2 minimum set worlds cookie bite
it. Note generally treat reported information manner; degree
strength report indication trust agent providing report.
787

fiHunter & Delgrande

additional soft constraints Bobs relationships used determine magnitude
values event. Define a1 a2 values following table.
a1
a2


0
0

B iteAlice
1
10

B iteEve
10
3

columns table give plausibilities action time. particular,
a1 encodes plausibility occurs 0, whereas plausibility B iteAlice
B iteEve 1 10, respectively. degree strength a1 1, whereas degree
strength a2 3. fact Alice likely bite cookie represented
assigning low plausibility value B iteAlice Time 1.
define o2 follows, give plausibility values states time 2.
o2


9

{B iteT aken}
0

Hence, observation {B iteT aken} assigned minimum plausibility value,
alternative observation assigned high plausibility value. degree
strength o2 9. reflects fact Trents report understood stronger
assumption Alice Eve bite cookie.
Note degree strength a1 less degree strength a2 o2 .
gives indication Bob comparatively less confidence beliefs
action Time 1.
Note that, example, explicitly referred points time. not,
however, include formal representation time framework; reference
time interpreted informal explanatory device. concerned
reasoning scenarios involve sequences actions action instantanenous, actions executed consecutively. Nevertheless, since allow observations
following null actions, imagine actions executed accordance
bounded global clock allows one action per tick.
3.2 Graded World Views
define graded world view alternating sequence plausibility functions
2F plausibility functions A. Hence, time i, use plausibility function
2F represent agents beliefs state world use plausibility
function represent agents beliefs action occurs. Informally,
graded world view represents agents subjective view evolution world
context imperfectly known action histories. rationale behind using sequence
ranking functions eventually make possible compare likelihood actions
observations different points sequence, arrive plausible sequence
events. following formal definition.
Definition 4 graded world view length n (2n + 1)-tuple
hOBS0 , ACT1 , OBS1 , . . . , ACTn , OBSn
788

fiBelief Change Uncertain Action Histories

OBSi plausibility function 2F ACTi plausibility function
A.
time i, plausible actions minimally ranked actions ACTi
plausible states minimally ranked states OBSi . take OBS0 represent initial belief state, subsequent OBSi represent new observation.
ACT = hACT1 , . . . , ACTn OBS = hOBS0 , . . . , OBSn i, write hACT, OBSi
shorthand graded world view hOBS0 , ACT1 , OBS1 , . . . , ACTn , OBSn i. Informally, graded world view represents agents subjective view history actions
observations.
remark briefly intuition behind graded world views. interested
action domains involving actions partially observable fallible. However,
moment consider failed actions; address issue briefly 4.6.
plausibility action represents agents confidence successfully executed
given instant. Hence, lowest plausibility values assigned actions
agent executed, actions agent observed directly. Higher plausibility
values assigned exogenous actions assumed unlikely, action
occurrences believed based external reports. 3.4, provide
additional motivation plausibility values illustrating correspondence subjective
probability functions.
Note graded world views essentially represent initial belief state observation time 0. underlying assumption graded world view initial belief
state different subsequent observation; reason automatically
prefer initial beliefs new information, reason automatically
disregard initial beliefs given new information. definition graded world view,
used indices manner symmetric order emphasize unique
stature OBS0 . particular, note ACT0 definition. simple
notational convention intended highlight fact OBS0 slightly different
stature informal level.
3.3 Aggregate Plausibility Functions
Given graded world view hACT, OBSi, would like able determine
plausible history world. formally define notion history transition
system.
Definition 5 Let = hS, Ri transition system. history length n tuple
hs0 , A1 , . . . , , sn i:
1. si S,
2. Ai A,
3. hsi , Ai+1 , si+1 R.
Let HISTn denote set histories length n.
Note HISTn (A S)n . Ideally, would like use graded world views
assign plausibility values histories. However, graded world view provide
789

fiHunter & Delgrande

sufficient information define unique plausibility function histories. example,
graded world view indicate relative weight recent information versus initial
information. order determine plausible history, need mechanism
combining sequence plausibility functions.
Although graded world view define unique plausibility function histories, define general notion consistency graded world views plausibility functions histories. Let r0 , . . . , rn plausibility functions X0 , . . . , Xn ,
respectively. Let r plausibility function X0 Xn . say r consistent
hr0 , . . . , rn if, every every xi , x0i Xi
ri (xi ) < ri (x0i )

r(hx0 , . . . , xi , . . . , xn i) < r(hx0 , . . . , x0i , . . . , xn i)
r consistent hACT, OBSi case r increases monotonically respect
component hACT, OBSi. plausibility function r consistent
hACT, OBSi provides potential candidate ranking histories.
Define aggregate plausibility function function maps every graded world
view length n plausibility function HISTn . interested aggregate
plausibility functions output always consistent input. Hence,
say aggregate plausibility function agg admissible if, every hACT, OBSi,
function agg(hACT, OBSi) consistent hACT, OBSi.
provide examples. Note aggregate plausibility functions return function
value; specify behaviour aggregate specifying plausibility value
pair consisting graded world view history. Let h = hs0 , A1 , . . . , , sn i.
One admissible aggregate obtained taking sum plausibility values.
sum(hACT, OBSi)(h) =

n
X

ACTi (Ai ) +

i=1

n
X

OBSi (si )

i=0

weighted sum used reflect relative importance different time points.
i, let bi positive integer.
sums (hACT, OBSi)(h) =

n
X

ACTi (Ai ) +

i=1

n
X

bi OBSi (si ).

i=0

setting bi = 2i , aggregate function sums used represent strict preference
recent observations. standard assumption many approaches belief revision.
could add similar weight action histories well, would give another
distinct aggregate. functions sum sums two simple examples; many
examples defined specifying aggregate functions increase monotonically
component.
return cookie example illustrate reasoning involved captured
graded world views aggregate plausibility functions.
Example (contd) already defined plausibility functions a1 , a2 o2 . order
give complete graded world view, need define two plausibility functions
790

fiBelief Change Uncertain Action Histories

states. particular, need give plausibility function o0 representing Bobs initial
beliefs need give plausibility function o1 representing null observation
Bob makes Time 1.
First, reiterate description a1 a2 following table.

a1
a2


0
0

B iteAlice
1
10

B iteEve
10
3

fact Alice likely bite cookie represented assigning lower
plausibility value B iteAlice Time 1.
plausibility function o0 assign minimum value state cookie
unbitten. plausibility function o1 assign value every state.
plausibility function o2 (given previously) represents Trents report cookie
bitten. noted previously, treat reported information observation, use
degree strength reported information indication reliability
source. case, degree strength o2 indication trust Trent. define
o0 , o1 , o2 next table.

o0
o1
o2


0
0
9

{B iteT aken}
9
0
0

Note degree strength o2 higher degree strength a1 a2 .
reflects fact Trents report understood supersede assumption
Alice Eve bite cookie. Graded world views defined precisely
kind comparison action plausibilities state plausibilities.
use aggregate function sum, interested finding minimal sum
plausibilities ho0 , a1 , o1 , a2 , o2 i. inspection, find minimum plausibility
obtained following history:
h = h, B iteAlice, B iteT aken, , B iteT akeni.
history represents sequence events Alice bites cookie time 1.
Intuitively, correct solution: given choice Alice Eve, Bob believes
Alice plausible culprit.
remark graded world views bear resemblance generalized belief change
framework proposed Liberatore Schaerf (2000). However, Liberatore-Schaerf
approach associates penalty state change, minimized determining
plausible models. such, difficult represent problems non-null actions
strictly plausible null actions. contrast, graded world views implicit
preference null actions. Moreover, approach differs allow actions
conditional effects given transition system.
791

fiHunter & Delgrande

3.4 Subjective Probabilities
One issue arises definition graded world view fact clear
plausibility values assigned practical problems. address problem
illustrating correspondence plausibility functions probability functions.
simplify discussion restricting attention rational-valued probability functions
follows.
Definition 6 Let X non-empty set. probability function X function
P r : X Q
x X, 0 P r(x) 1
P

xX P r(x) = 1.
need axioms probability theory present purposes.
common-sense level, clear means say action occurred time
probability p. contrast, problem plausibility values obvious
sense scale; difficult assign numerical plausibility values, numbers
clear meaning. illustrate probability functions translated uniformly
plausibility functions, thereby giving sense scale meaning plausibility values.
Let P r probability function finite set X. Let Q denote least common
denominator rational numbers pq P r(x) = pq x X. Define
plausibility function r follows.
1. P r(x) minimal, set r(x) = Q.
2. Otherwise, P r(x) =

p
Q,

set r(x) = Q p.

Hence, every probability function translated plausibility function.
Example (contd) Consider following probability functions cookie example.

P ra1
P ra2


.5
.5

B iteAlice
.45
.15

B iteEve
.05
.35


.9
.5
.1

P ro0
P ro1
P ro2

{B iteT aken}
.1
.5
.9

corresponding plausibility functions given following tables.

a01
a02


10
10

B iteAlice
11
20

B iteEve
20
13

o00
o01
o02


1
2
10

{B iteT aken}
10
2
1

easy see plausibility functions obtained plausibility
functions given earlier adding constant value. 4.2, illustrate adding
constant manner affect class minimally ranked histories.
Connecting plausibility functions subjective probabilities provides justification use aggregate function sum. particular, assume subjective
792

fiBelief Change Uncertain Action Histories

probability functions independent, probability given sequence events
determined taking product. cookie example, compare probability
Alice biting cookie versus Eve biting cookie:
1. P r(h, B iteAlice, B iteT aken, , B iteT akeni)
= .9 .45 .5 .5 .9 = .091125
2. P r(h, , , B iteEve, B iteT akeni)
= .9 .5 .5 .35 .9 = .070875
easy check history Alice bites cookie actually probable history. So, example, minimally ranked history according aggregate
function sum also probable history according sequence probability
functions. general property translation: maximizing probability independent probability functions corresponds minimizing sum plausibility values.
follows simply fact probable events assigned minimal plausibility values, fact summation natural numbers increasing
function, whereas multiplication fractions less 1 decreasing.
correspondence descibed section relies assumption sequences
actions independent. worth noting, however, often case
practice. Instead, often case actions occur sequences clear
dependence individual actions. However, concern present.
reason considering probability functions provide intuition motivation
way plausibility values assigned.
3.5 Summation Convention
order ground discussion, useful choose fixed aggregate function assigning plausibility values histories. such, unless otherwise indicated, assume
plausibility values assigned histories aggregate function sum. Although
approach combining plausibility functions, provides simple admissible aggregate function appropriate many cases. particular, saw
previous section sum appropriate domains plausibility functions
obtained independent subjective probabilities.
introduce notation simplify results next sections.
Recall sum(hACT, OBSi) plausibility function histories. underlying
graded world view clear context, write plaus(h) shorthand
sum(hACT, OBSi)(h).
useful introduce operator maps graded world view plausible
histories.
Definition 7 Let W Vn denote set graded world views length n fixed action
signature. Define : W Vn 2HISTn follows:
(hACT, OBSi) = {h | plaus(h) plaus(g) g HISTn }.
following obvious equivalence
(hACT, OBSi) = Bel(sum(hACT, OBSi)).
793

fiHunter & Delgrande

also useful use plaus define plausibility function states.
Definition 8 Let hACT, OBSi graded world view. state s, define
plaus state(hACT, OBSi)(s)
least n plaus(hACT, OBSi)(h) = n history h final state
s.
plausibility state rank plausible history ending s.
underlying graded world view clear context, simply write plaus state(s)
plausibility state s. extend operator Bel() graded world views
defining Bel(hACT, OBSi) Bel(plaus state(hACT, OBSi)). Hence, Bel takes
graded world view argument returns plausible set terminal states.
3.6 Uniform Representation
considering applications formal results, briefly discuss novel
significant features approach. notion plausibility relation theory
change explored extensively literature. Work nonmonotonic consequence
operators, example, informed notions preferred models (Kraus, Lehmann,
& Magidor, 1990) conditional knowledge (Lehmann & Magidor, 1992). also
great deal research different representations plausibility, ranging orderings (Baltag & Smets, 2006, 2008; Britz & Varzinczak, 2013), quantitative approaches
possibility (Benferhat, Dubois, & Prade, 1999), variations probabilistic models
(Friedman & Halpern, 2001). take moment position work context.
stated several times, sets work apart apply
notion plausibility uniformly states actions. contrasts existing
work, model plausibility used representing initial beliefs, actions
handled different formal machinery. many cases, actions atomic; belief
change due action concerned complicated plausibility structure changes
response distinct action occurence.
model, action occurrence another plausibility function. several
advantages, show next sections. First, allows us easily compare
strength belief state strength belief action occurence. example,
believe lamp also believe toggled switch: believe?
Situations form common, require comparison two different
forms likelihood. general, natural logical aparatus help resolve
problem; need extra-logical information belief stronger, belief
state belief action. natural intuition actually need
given rankings make determination; exactly here.
second advantage using uniform representation plausibility actions
allows us consider alternative actions. Looking literature belief change
preferential models, clear actually need orderings states order
perform many kinds reasoning. reason need orderings need
able specify best alternatives things believed true. argue
true actions. find action occur, need
794

fiBelief Change Uncertain Action Histories

mechanism determining next best alternative. see next
section many practical examples important, examples
captured straightforward way plausibility functions.
tempting look model try position context
alternative models plausibility, argue best way look
work. fact, could propose approach similar one paper based
sequences probability functions suitable aggregates. fact using
Spohn-style ranking functions particular important point.
important using measure plausibility uniformly observations
actions, plausibility measure feature differences plausibility
magnitude. allows us determine alternatives current beliefs
states actions abandoned, appeal single notion
magnitude determine notion minimal change.

4. Using Graded World Views
section, consider basic approach one use try find
minimally ranked history.
4.1 Pointwise Minima
Let W = hACT, OBSi graded world view
ACT = hACT1 , . . . , ACTn

OBS = hOBS0 , . . . , OBSn i.
easiest way determine minimally ranked history simply take plausible
actions plausible worlds point time. following definition makes
notion precise.
Definition 9 Given history h = hs0 , A1 , . . . , , sn i, say h pointwise minimum
hACT, OBSi if, i,
1. A, ACTi (Ai ) ACTi (A),
2. 2F , OBSi (si ) OBSi (s).
following proposition states that, graded world view pointwise minima,
plausible histories.
Proposition 1 Let W = hACT, OBSi graded world view let set
pointwise minima W . 6= , (W ) = .
Proof sufficient note that, h , plaus(h) plaus(g) histories g.
Note, however, histories restricted world must outcome
preceding action. such, possible graded world view pointwise
minimum. preceding proposition starts assumption set
795

fiHunter & Delgrande

pointwise minima non-empty. cases pointwise minima,
still minimally plausible histories.
Finding pointwise minima easy general case.
Proposition 2 Determining graded world view pointwise minimum N P complete.
Proof Given history, clear checking pointwise minimum
done linear time; problem lies N P . Assume fixed set F fluent symbols.
Let W = hACT, OBSi OBS length 2|F| , assume OBSi obtains
minimum distinct interpretation F. pointwise minimum W correspond
Hamiltonian path underlying transition system. result follows since finding
Hamiltonian path NP-complete.
fact already intractable find pointwise minimum suggests finding
minimal histories complicated aggregate function likely computationally
difficult. major concern present purposes however, view graded
world views high-level tool capture variety belief change scenarios. one
interested modelling concrete action domains, important choose aggregate
functions well understood computationally easy minimize.
4.2 Equivalence
Clearly possible two distinct graded world views set minimally
ranked world histories. fact, possible two distinct graded world views induce
preference ordering histories. section, define natural equivalence
relation graded world views eye towards categorical representations. start
defining relation plausibility functions.
Definition 10 Let r1 r2 plausibility functions set X. say r1
= r2
if, every x, X,
r1 (x) r1 (y) = r2 (x) r2 (y).
easy verify following:
= equivalence relation, r1 r2 degree
strength, r1
r
implies
Bel(r1 ) = Bel(r2 ). Essentially, difference
= 2
equivalent plausibility functions minimum value; make idea
precise defining notion normalization plausibility functions.
Let r plausibility function. integer z minr , translation r
z plausibility function x 7 r(x) + z. easy prove r
= r0
0
r translation r. define normalization r translation minr .
normalization r unique plausibility function equivalent r obtains
minimum 0.
extend notion equivalence graded world views.
Definition 11 Let W1 W2 graded world views histories fixed action signature given underlying transition system. say W1
= W2 if, every pair
histories g h,
sum(W1 )(g) sum(W1 )(h) = sum(W2 )(g) sum(W2 )(h).
796

fiBelief Change Uncertain Action Histories

Unlike plausibility functions, possible construct equivalent pairs graded world
views obtained translations.
following proposition illustrates every graded world view equivalent
graded world view consisting normalized plausibility functions.
Proposition 3 Let hACT, OBSi graded world view. hACT 0 , OBS 0 obtained
normalizing component ACT OBS,
hACT, OBSi
= hACT 0 , OBS 0 i.
Proof
Let g, h histories. ease readability, let plaus1 plaus2 denote
sum(hACT, OBSi) sum(hACT 0 , OBS 0 i), respectively. Hence, plaus1 plaus2
functions histories, obtained minimization total sum. such, plaus1
plaus2 must minimum value, corresponding lowest possible sum
terms. following equalities immediate:
plaus2 (g) plaus2 (h) = plaus1 (g) min plaus1 (h) + min
plaus1

plaus1

= plaus1 (g) plaus1 (h).

Hence, although allow plausibility functions minimum values larger 0
graded world view, always pass equivalent graded world view consisting
normalized plausibility functions. remark, however, graded world view defined
sequence normalized plausibility functions need obtain minimum 0.
case, minimum 0 graded world view pointwise minimum.
also important note Proposition 3 holds aggregate plausibility
function sum.
4.3 Representing Belief States
Plausibility functions defined simply pick distinguished set elements
domain. X c integer, let c denote function X set
integers defined follows:

0
c (s) =
c otherwise
c positive integer, c denotes plausibility function elements
plausible, everything else equally implausible. Plausibility functions
form c called simple. X set states, simple plausibility functions
correspond belief states; X set actions, simple plausibility functions pick
actions believed occurred. Using terminology introduced earlier,
say held degree belief c.
c > 0, c actually define plausibility function. However, allowing
negative values leads simple symmetry notation. following proposition,
denotes complement set difference. set states, = 2F .
797

fiHunter & Delgrande

Proposition 4 set positive integer c
c
= c.
Proof Let s, states. definition,

, 6
c
c 6 ,
c (s) c (t) =

0
otherwise.


(c)
c
c (s) c (t) =

0

6 ,
, 6
otherwise.

Clearly, right hand sides equality same.
Suppose
ACT = hACT1 , . . . , ACTn

OBS = hOBS0 , . . . , OBSn
ACTi OBSi simple, maximum plausibility c. means
ACTi OBSi assigns either value 1 value c every element
respective domains. case, essentially belief states plausibility
ordering. case, easy show
hs0 , A1 , . . . , , sn (hACT, OBSi)
cardinality
{Ai | Ai ACTi } {si | si OBSi }
maximal among histories. words, plausible histories
agree hACT, OBSi highest number components. reasonable
approach take trivial case prior ranking states actions.
emphasize special case plausibility functions simple
share degree strength. next section, define belief change
operations terms general concatenation plausibility functions. restrict
plausiblity functions here, get much wider range possible belief
change operations.
4.4 Graded World Views Epistemic States
epistemic state representation agents belief state defines total pre-order
states (Darwiche & Pearl, 1997). t, underlying agent believes
likely actual state world t. current belief
state given set -minimal states. Recall also graded world view defines
798

fiBelief Change Uncertain Action Histories

plausibility function plaus state states. graded world view clearly defines
ordering states, think graded world view defining epistemic
state. worlds receive minimal rank graded world view worlds
supported reliable observations actions. Using ranking define
plausibility ordering tantamount assuming plausibility completely
determined reliability source reporting occurs.
viewing graded world views epistemic states, define belief change operations
familiar manner. particular, define belief change simple
concatenation operator graded world views. Given sequence plausibility functions
r = hr1 , . . . , rn plausibility function r, let r r denote sequence hr1 , . . . , rn , ri.
Let hACT, OBSi graded world view, let rA plausibility function actions
let rS plausibility function states. Define follows:
hACT, OBSi hrA , rS = hACT rA , OBS rS i.
context initial epistemic state given hACT, OBSi, represents
agents priori beliefs history observed actions states. New actions
observations incorporated simply concatenating new plausibility functions
initial graded world view. new graded world view used define new
ordering histories aggregate function. example, using sum
default aggregate, new ordering immediate. Note new graded world view
obtained manner also includes historical information required future belief
change. special case simple concatenation operation, get new approach
update. set X, let 0 denote plausibility function uniformly assigns 0
every element X. identify update hACT, OBSi rA following
operation:
hACT, OBSi hrA , 0i.
also define natural approach revision manner. Let null denote
plausibility function assigns plausibility 0 null action , assigns everything
else plausibility larger maximum value obtained sum(hACT, OBSi).
identify revision hACT, OBSi rS following operation:
hACT, OBSi hnull, rS i.
Using plausibility functions represent observations allows us represent natural
problem domains easily represented restrict observations sets
possible worlds. particular, consider action domain observations
varying degrees reliability. domains, agent makes observation
inconsistent current belief state, two factors considered:
strength belief current belief state reliability observation.
obvious conflict arises attempt address factors simultaneously.
example, suppose underlying agent strongly believes possible state
world. suppose agent makes two observations.
1. One observation suggests possible, comes unreliable source.
799

fiHunter & Delgrande

2. Another observation suggests possible, comes reliable
source.
difficult determine appropriate belief change scenario, particularly
strength belief observational reliability treated independently. quantifying
reliability every observation, graded world views make easy resolve kind
issue. remark problems form also addressed use
prioritized merging operators (Delgrande, Dubois, & Lang, 2006).
Note asymmetry definition revision update
operator. case update, assume final observation assigns
plausibility every state. symmetric definition single observation would
defined follows:
hACT, OBSi h0, rS i.
However, definition allows arbitrary action occur immediately observation. want assume graded world view hACT, OBSi gives complete picture
world time observation, need assume intermediary
action null. Hence, asymmetry due significant difference actions
observations; asymmetry simply due fact graded world views involve
alternating sequences actions observations, actions occurring first default.
section illustrated graded world view defines epistemic state.
take epistemic state total pre-order states, converse clearly
false: ordering states provide enough information define numerical ranking
functions states. move epistemic states graded world views motivated
kind concern motivates move belief states epistemic states.
particular, belief states AGM revision understood represent minimal
elements ordering states. Hence, belief state provide partial description
ordering, ordering turn provide partial description graded world
view. belief state sufficient single-shot revision, provided ordering implicit
revision operator. However, belief state sufficient need explicitly
reason way plausibility orderings modified. Similarly, orderings states
sufficient reasoning preferences states, sufficient need
explicitly reason action histories. next section, clarify point
practical examples.
4.5 Representing Natural Action Domains
illustrate interesting phenomena represented graded world views.
simplest examples involve graded world views length 1. particular, initially
focus graded world views form
hIN hrA , rS i.
context, represents initial belief state agent, rA represents agents
beliefs action executed, rS represents observed state
world. Previously used OBS0 initial plausibility function states;
change notation emphasize priori initial ordering
800

fiBelief Change Uncertain Action Histories

states. clear, , rA , rS plausibility functions. such,
define degree strength each. facilitate exposition, denote degrees
strength deg(IN ), deg(rA ), deg(rS ) respectively. Varying magnitudes
values allows us capture several different underlying assumptions.
1. Fallible initial beliefs: deg(IN ) < deg(rA ) deg(IN ) < deg(rS ).
2. Erroneous perception: deg(rS ) < deg(IN ) deg(rS ) < deg(rA ).
3. Fallible action history: deg(rA ) < deg(IN ) deg(rA ) < deg(rS ).
simple example, suppose agent believes certain lamp initially on,
power switch toggled, agent observes lamp actually still
on. Clearly sequence events consistently believed rational agent.
Manipulating degrees strength , rA rS gives agent mechanism
resolving conflicts. case (1), agent completely certain lamp
initially on. such, easiest way incorporate new information change
initial belief state. contrast, case (2), agent completely certain
lamp still toggling switch. case, since agent confident
lamp initially switch toggled, natural reject observation
believe lamp off. distinction two cases cannot
captured without notion reliability. case (3), agent would resolve conflict
believing attempt toggle power switch failed.
special case degree strength 0 also captures important
phenomena. Note plausibility function r degree strength 0 case
constant c r(x) = c x. such, degree 0 indicates every
element domain receives minimal rank. consider informal interpretation
degree 0 plausibility function schematic example.
1. deg(IN ) = 0, every initial state equally plausible. agent
contingent priori beliefs state world.
2. deg(rO ) = 0, rO represents null observation. observation OBS
provide evidence particular state.
3. deg(rA ) = 0, every action equally likely. agent completely ignorant
action occurred, think rA exogenous action
beyond agents control.
relatively crude distinctions, still capture important classes problems.
Roughly speaking, problems addressed thus far captured
plausibility ordering sequences form
A1 1 n
belief state, Ai action symbol, observation.
purpose comparison, remark belief evolution operators defined
Section 2.3 useful problems underlying plausibility ordering
801

fiHunter & Delgrande

given follows, permutation p1 , . . . , pn 1, . . . , n.

A1

..
. p1 p2 pn


contrast, graded world views suitable total pre-order A1 , 1 , . . . , , n .
entire class problems representable graded world views. using
ranking function event, able draw two additional distinctions
represented simple ordering. First, able represent changes plausibility
affect ordering states. useful representing action domains
agent must observe single piece evidence multiple times believing
correct. Second, able represent graded evidence; use term graded evidence
describe situations observation actually supports several different conclusions
different degrees confidence. conclude section two examples illustrating
action domains difficult represent ordering plausibility
events.
Example (Additive Evidence) Bob believes turned lamp office,
completely certain. leaving building, talks first Alice
Eve. Alice tells lamp still on, believe mistaken.
Similarly, Eve tells lamp still on, believe mistaken.
However, Alice Eve tell Bob lamp still on, believe
fact still on.
example easily represented graded world view follows. assume
underlying action signature contains, among others, fluent symbol LampOn
action symbol urnLampOff . underlying transition system defines effects
turning lamp obvious manner. Let denote set states
LampOn true. following plausibility functions define graded world view
represents action domain.
1. OBS0 = 10
2. ACT1 = {T urnLampOff } 3
3. OBS1 = 2
4. ACT2 = 10
5. OBS2 = 2
Note (hOBS0 , ACT1 , OBS1 i) consists histories lamp turned
time 1. However, (hOBS0 , ACT1 , OBS1 , ACT2 , OBS2 i) consists histories
lamp turned time 1. Two observations required make Bob believe
turn lamp off.

Example (Graded Evidence) Bob receives gift estimates worth approximately $7. curious price, tries glance quickly receipt without
802

fiBelief Change Uncertain Action Histories

anyone noticing. believes receipt says price $3. far low
believable, Bob concludes must mis-read receipt. Since 3 looks
similar 8, concludes price receipt must actually $8.
represent example, first define ACT1 = 10 Bob believes ontic actions occurred. assume fluent symbols Cost1, Cost2, . . . , Cost9
interpreted represent cost gift. define plausibility function OBS0 representing Bobs initial beliefs.

0 = {Cost7}
1 = {Cost6} = {Cost8}
OBS0 (s) =

3 otherwise
Note Bob initially believes cost $7, comparatively plausible
cost one dollar less. Finally, define plausibility function OBS1 representing
observation receipt.

0 = {Cost3}
1 = {Cost8}
OBS1 (s) =

3 otherwise
Bob believes observed digit likely 3, plausible alternative visually similar digit 8.
Given plausibility functions, plausible state world state
price $8. order draw conclusion, Bob needs observations provide
graded evidence states world needs able weight information
initial beliefs.
preceding examples illustrate natural common-sense reasoning problems agent needs consider aggregate plausibilities sequence actions
observations. Graded world views well-suited reasoning problems.
4.6 Non-deterministic Failed Actions
section, consider actions non-deterministic effects. remark, particular,
fallible actions understood actions non-deterministic effects; fallible
actions actions possible outcomes considered failures.
simplest case, example, failed action might one leaves state world
unchanged. Hence, addressing non-deterministic effects, also handling actions
might fail. basic approach following. introduce new machinery
representation non-deterministic actions, demonstrate new
machinery unnecessary use summation determine plausibility histories.
such, reasonably restrict attention deterministic actions proving formal
expressibility results graded world views.
Given non-deterministic transition system = hS, Ri graded world view W ,
clear choose effects action plausible world
histories. problem solved attaching plausibility value possible effects
action (Boutilier, 1995). action state s, let EF F (A, s) denote
803

fiHunter & Delgrande

set states s0 (s, A, s0 ) R. Hence EF F (A, s) set states may
result, given action executed state s.
Definition 12 effect ranking function function maps every action-state pair
(A, s) plausibility function EF F (A, s).
Informally, effect ranking function gives plausibility possible effect
action. instance, want model coin flipping action, corresponding effect
ranking function would constant: outcomes coin flip would considered
equally plausible.
non-deterministic graded world view pair hW, W graded world view
effect ranking function. illustrate example.
Example Consider action domain involving single fluent symbol LampOn indicating
whether certain lamp turned on. two action symbols P ress
hrowP aper respectively representing acts pressing light switch, throwing
ball paper light switch. Informally, throwing ball paper light switch
likely turn lamp. suppose agent reason believe
piece paper thrown lamp and, moreover, lamp turned on.
illustrate non-deterministic graded world views provide representation
problem.
actions non-deterministic effects may cause LampOn become
true, may also fail so. define graded world view hACT, OBSi length
1. First, define ACT hrowP aper likely action time 1.

ACT1


10

P ress
2

hrowP aper
1

Next define OBS initially light off, light on.

OBS0
OBS1


10
0

LampOn
0
10

Finally, define effect ranking function represents fact pressing
likely turn light on.

(P ress, {LampOn})
(P ress, )
(T hrowP aper, {LampOn})
(T hrowP aper, )


0
10
9
0

{LampOn}
10
0
0
9

Lines 1 2 table indicate pressing switch likely change
state lamp. Lines 3 4 indicate throwing paper switch likely
804

fiBelief Change Uncertain Action Histories

effect, change caused paper ball seen plausible
failed effect button pressed.
preceding example, two possible solutions: either plausible event occurs
unlikely outcome, less plausible event occurs expected outcome.
priori preference given occurrence plausibilities effect plausibilities;
framework flexible enough represent either possibility.
Introducing effect ranking functions makes distinction action occurrences
action effects explicit, turn gives straightforward treatment failed actions. However, need introduce extra machinery order determine
plausible action history. general approach extend definition
aggregate plausibility function: non-deterministic aggregate plausibility function takes
non-deterministic graded world view argument, returns plausibility function
histories. admissible non-deterministic aggregate plausibility function one
increases monotonically respect given graded world view, well given
effect ranking function.
using function sum standard aggregate plausibility function.
natural extension sum non-deterministic graded world views following.
history h = s0 , A1 , . . . , , sn , define
X
sum(hACT, OBSi, )(h) =
OBSi (si ) + ACTi (Ai ) + (Ai , si1 )(si ).


easy see admissible non-deterministic aggregate function. Returning
lamp example, two minimally ranked histories function: one
lamp turned pressing switch one lamp
turned throwing piece paper switch.
remainder section, assume sum default aggregate
function non-deterministic world views. assumption, demonstrate
non-deterministic graded world views translated graded world views
extended action signature.
Let = hS, Ri non-deterministic transition system action signature hA, Fi.
Let hhACT, OBSi, non-deterministic graded world view. extend action
signature new action signature A0 every edge corresponds unique
action symbol. particular, let A0 = {A(s,A,t) | (s, A, t) R}. Let 0 = hS, R0 R0
closure set {hs, A(s,A,t) , ti | s, S}. Suppose ACT = ACT1 , . . . , ACTn .
Define ACT 0 = ACT10 , . . . , ACTn0 where, i, ACTi0 (A(s,A,t) ) = ACTi (A) + (A, s)(t).
Proposition 5 non-deterministic transition system , history
h = s0 , A1 , . . . , , sn
obtains rank hhACT, OBSi,
h0 = s0 , A(s0 ,A1 ,s2 ) , . . . , A(sn1 ,An ,sn ) , sn
obtains hACT 0 , OBSi.
805

fiHunter & Delgrande

Proof plausibility h obtained taking sum
X
OBSi (si ) + ACTi (Ai ) + (Ai , si1 )(si ),


clearly sum taken determine plausibility h0 .
Hence non-deterministic actions failed actions represented graded world
view, simply setting plausibility functions carefully.
remark conceptually interesting distinction lost translation. Informally, distinction action fails occur action
occurs, fails produce expected effect. distinction clear consider
difference failing drop glass ground, dropping glass fails
break hits ground. first case, agent executes drop action
fails occur; perhaps glass sticks agents hand. second case,
glass successfully dropped without breaking. framework, events
represented dropping action null effect. suggest acceptable
treatment, cases sequence actions states identical. such,
cannot distinguish scenarios based definition history. However,
may able distinguish indirectly based values fluents. instance,
location glass going change case successfully dropped.

5. Comparison Related Formalisms
Belief change due actions observations addressed previously literature.
section, consider approach related existing work area.
5.1 Representing Single-Shot Belief Change
focus thus far use graded world views representation
iterated belief change due actions observations, simplest scenario involves
single ontic epistemic action. important, therefore, verify singleshot belief change operators induced graded world view reasonable respect
existing work area. Recall defined graded world views
shorthand notation associated concatenation operations. Based results
section, clear shorthand natural appropriate.
first consider case single ontic action.
Proposition 6 Let hACT, OBSi graded world view. plausibility function r
A,
Bel(hACT, OBSi hr, 0i) = Bel(hACT, OBSi) Bel(r).
Proof Since every action always executable, Bel(hACT, OBSi hr, 0i)
s0 Bel(hACT, OBSi) s0 = Bel(r). Hence
Bel(hACT, OBSi hr, 0i) Bel(hACT, OBSi) Bel(r).
Proposition 6 important primarily interested belief states ontic actions.
Basically, case, graded world views unnecessary. plausible final belief
state determined simply looking belief state associated initial
graded world view.
806

fiBelief Change Uncertain Action Histories

consider case single observation. present, primarily interested
comparing expressive power graded world views AGM revision operators.
one sense graded world views clearly expressive AGM
operators. particular, new observation need incorporated agents beliefs
observation come reliable source. demonstrate that,
context single observation, essentially difference graded world
view AGM revision operator. specifically, see belief change
defined concatenating single observation onto graded world view captured
AGM operator, provided observation degree strength higher
fixed threshold.
start proving every plausibility function defines system spheres,
defined Grove (1988). first review definition system spheres. Let ML
denote set consistent, complete theories L. set subsets ML system
spheres centered X X ML , satisfies conditions:
S1. totally ordered
S2. X minimum
S3. ML
S4. formula || =
6 , least sphere c() c() || =
6
U || =
6 implies c() U every U
picture system spheres series concentric circles, innermost circle X.
Let r plausibility function X minimum value minr . n, let r[n]
denote set complete, consistent theories satisfied interpretation
r(I) n.
Proposition 7 Let r plausibility function finite action signature. collection
R = {r[n] | n minr } system spheres centered r[minr ].
Proof Clearly, n, r(n) r(n + 1). Hence R totally ordered .
r[minr ], satisfied r(I) minr . then, n,
satisfied r(I) n. Hence r[minr ] r[n] r[n].
Since action signature finite, finitely many states. Hence
state assigned maximum plausibility, say maxr . Therefore, r[maxr ] set
complete, consistent theories.
Let consistent formula. Since finitely many states, must
state r(s) r(t) . Let n = r(s). Clearly r(n) 6= .
suppose U U 6= . Suppose U = r(m), U set complete,
consistent theories satisfied r(I) m. Since elements U also
, follows n. Therefore r[n] U , r[n] least sphere intersecting .
Using result, show single-shot revision graded world views
captured AGM revision operators. make claim precise next proposition.
807

fiHunter & Delgrande

Proposition 8 Let hACT, OBSi graded world view. AGM revision function natural number n that, plausibility function r states
degree strength larger n,
Bel(hACT, OBSi h n, ri) = Bel(hACT, OBSi) Bel(r).
Proof Recall plaus plausibility function histories defined minimizing sums hACT, OBSi, plaus state corresponding plausibility function
final states.
Let n natural number n > plaus(h) every history h. Let r
plausibility function rank n. follows Bel(hACT, OBSih n, ri)
following conditions hold:
1. Bel(r)
2. plaus state(s) minimal among states satisfying 1.
Proposition 7, plaus state defines system spheres centered Bel(plaus state).
follows Groves representation result (Grove, 1988) AGM revision
function that, observation , Bel(plaus state)
following conditions hold:
1.
2. plaus state(s) minimal among states satisfying 1.
Setting = Bel(r) gives desired result.
Proposition 8 illustrates that, single observation, plausible worlds
determined without considering history actions observations. determine
plausible worlds following observation simply abstracting belief state
graded world view, performing AGM revision. easy show converse
also true: every AGM revision operator represented graded world view.
precisely, following result.
Proposition 9 Let AGM revision operator let belief state.
graded world view hACT, OBSi Bel(hACT, OBSi) = natural number n
that, every non-empty observation ,
= Bel(hACT, OBSi h n, ri)
r plausibility function states minimal ranked elements
degree larger n.
Proof Groves representation result, captured system spheres S.
Define graded world view hACT, OBSi system spheres given
Proposition 7. Set n n > plaus(h) every history h. result immediate.

Taken together, Propositions 8 9 illustrate graded world views equivalent
808

fiBelief Change Uncertain Action Histories

AGM revision restrict attention single observation sufficiently high degree
reliability. Hence, single-shot belief change, full expressive power graded world
views unnecessary. ontic actions observations, define
belief change operations start belief state. also correspondence
Nayaks work iterated revision (Nayak, 1994); observation sufficiently
plausible, every state observation ends strictly plausible
every state.
5.2 Representing Conditionalization
Spohn uses ranking functions define different form single-shot belief change called
conditionalization (Spohn, 1988). idea new evidence presented pair
(, m), set states 0; value indication strength
observation . Informally, conditionalization r new function
minimally ranked -worlds receive rank 0 non- worlds shifted m.
section, illustrate conditionalization defined terms graded world
views.
First, define conditionalization formally. Let r plausibility function minr =
0 let subset domain r. Let min() denote minimum value r(s)
. Spohn defines plausibility function r(|) follows:
r(s|) = r(s) min().
call r(s|) -part r. conditionalization r, written r(,m) , following
plausibility function.

r(s|)

r(,m) (s) =
+ r(s|)
6
conditionalization r -part R together -part shifted appropriately.
show conditionalization easily represented taking minimal sums
plausibility functions.
Definition 13 Let r plausibility function 2F , let non-empty subset 2F ,
let natural number. Define rC (, m) follows:

0

rC (, m) (s) =
+ min() 6
refer rC (, m) conditionalizer r respect m. following
proposition illustrates define conditionalization plausibility function
taking appropriate sum.
Proposition 10 Let r plausibility function minr = 0. , m, normalization r + rC (, m) conditionalization r(,m) .
Proof ,
r(s) + rC (, m)(s) = r(s) + 0 = r(s).
809

fiHunter & Delgrande

6 ,
r(s) + rC (, m)(s) = r(s) + + min().
Since r(s) 0 0, follows minimum value obtained r + rC (, m)
min(). Hence, normalization r + rC (, m) plausibility function r0 defined
follows.
r0 (s) = r(s) + rC (, m)(s) min()
equal r(,m) , wanted show.
Proposition 10 illustrates conditionalization r (, m) defined
taking minimal sum two plausibility functions. restricted attention
plausibility functions minimum 0 class coincides closely Spohns
ranking functions. However, define conditionalizer manner
plausibility functions non-zero minimums. also define conditionalization
graded world view. Informally, simply conditionalize associated plausibility
function states. Hence, identify conditionalization respect h, mi
following operation:
hACT, OBSi h, plaus stateC (, m)i.
straightforward show gives desired result.
5.3 Representing Belief Evolution Operators
noted previously, previously defined so-called belief evolution operators capture iterated belief change due actions observations (Hunter & Delgrande, 2011).
section, show graded world views actually extend approach, verifying
every belief evolution operator captured graded world view.
two underlying assumptions definition belief evolution:
1. plausibility observation determined ordering, recency default.
2. action history assumed correct.
assumptions represented graded world view setting
plausibility functions appropriately.
Belief evolution operators defined respect metric transition systems.
metric transition system transition system, along metric gives distance
states. metric defines belief revision operator follows (Delgrande, 2004):
= {w | v1 v2 , v3 K
d(w, v1 ) d(v2 , v3 )}.
Assume fixed initial belief state , along metric transition system
defining revision operator update operator . Let belief evolution
operator obtained . Let
= hA1 , . . . ,
810

fiBelief Change Uncertain Action Histories

action trajectory, let
= h1 , . . . , n
observation trajectory. want construct graded world view Wev assigns
minimal plausibility value histories corresponding hA, i.
define Wev = hACT, OBSi presently. combining metric given
metric transition system, define plausibility function BASE represents
initial ordering states implicit . particular, s, set
BASE(s) = min({d(s, k) | k }).
Using plausibility function, define observation trajectory OBS. Let max
denote maximum value obtained BASE.

BASE
= 0
OBSi =
(2i + max) otherwise
incrementing plausibility false observations exponentially, assure
recent observations given greater credence.
Informally, action symbol Ai translated plausibility function obtains
minimum value set {Ai }. Formally, following, 1 n:
ACTi = Ai (2n+1 + max).
Proposition 11 hA, = h0 , . . . , n i,
h (Wev )

h = hs0 , A1 , . . . , , sn si i.
Proof Assume moment hA, consistent. Let h = hv0 , B1 , . . . , Bn , vn i.
definition h (Wev ) sum
n
X

ACTi (Bi ) +

i=1

n
X

OBSi (vi )

(2)

i=0

minimal. Since hA, consistent, exist histories hs0 , A1 , . . . , , sn
si . histories, sum (2) becomes
n
X

ACTi (Ai ) +

i=1

n
X

OBSi (si ) = 0 + OBS0 (s0 )

i=0

remark sum less sum obtained history
either Bi Ai si 6 . Therefore h (Wev )
following three conditions hold:
1. Bi = Ai > 0
811

fiHunter & Delgrande

2. vi > 0
3. OBS0 (v0 ) minimal among states satisfying 1 2.
order satisfy condition 2, must case v0 set
\
V =
i1 (Ai ).


order simultaneously satisfy condition 3, must also case v0 minimally
distant according metric d. words, v0 V . Therefore, h
(Wev ) Bi = Ai following conditions hold:

1. v0 i1 (Ai ),
2. vi = v0 Ai .
definition hA, i, completes proof.
case hA, inconsistent similar. difference need
notice degree strength observation increases power 2.
use fact that, natural number p, 2p larger every sum terms 2i
< p. such, order minimize sum (2), need work backwards
observations, keeping observation consistent observations followed.
equivalent specification (Wev ) increasing powers exponentially forces
strict preference recent observations.
Proposition 11 demonstrates graded world views represent belief evolution
operator defined respect distance function. perspective graded world
views, assumption action histories infallible essentially restriction
admissible plausibility functions.
conclude section brief remarks use orderings resolve
inconsistency iterated belief change. well-known Darwiche-Pearl postulates iterated belief change (Darwiche & Pearl, 1997) satisfied assume
recent observation takes precedence previous observations. contrast, Papini
illustrates alternative approach iterated revision earlier observations take
precedence later observations (Papini, 2001). generally, defined belief evolution operators respect arbitrary total ordering observations.
natural extension belief evolution would extend ordering include observations
actions. Using techniques section, easy see extended conception belief evolution corresponds class graded world views arbitrary
initial observation followed plausibility functions form 2i , distinct. Hence, even general extension belief evolution represented
relatively restricted class graded world views.
5.4 Relation Situation Calculus
Situation Calculus (SitCalc) well-establishing framework reasoning
effects actions. Action descriptions SitCalc formulated many-sorted firstorder logic along single second-order induction axiom. Briefly, variables range
812

fiBelief Change Uncertain Action Histories

situations, entities, actions. Situations understood represent current
state world, including complete history actions occurred.
distinguished constant symbol S0 denotes initial situation distinguished
function symbol maps action situation situation results
executing situation s. Predicate symbols take situation argument
called fluents. detailed introduction, refer reader foundational summary
presented Levesque, Pirri Reiter (1998).
epistemic extension SitCalc introduces sensing actions, alternative initial
situations, accessibility relation, plausibility ordering situations (Shapiro
et al., 2011). situations agent believes possible minimal accessible
situations, effect sensing action changes set accessible states.
results form belief revision satisfies AGM postulates.
previously proved belief revision SitCalc captured belief evolution
operator natural translation (Hunter & Delgrande, 2011); therefore follows
Proposition 11 belief change operators defined standard SitCalc approach
captured graded world views.
similar conclusion drawn regarding representation uncertain actions.
Bacchus et. al. (1999) extend SitCalc include noisy sensors non-deterministic
actions. Roughly, idea define complex actions terms set primitive
actions. manner, non-deterministic action represented probability function
set primitive actions. similar result Proposition 5, proves
capture non-deterministic actions introducing ranking functions action
effects. think action effect primitive action, essentially
representation Bacchus et. al. except use ranking functions rather
probabilities. Moreover, section 3.4 demonstrated translation probabilities
plausibilities straightforward.
approach appears sufficiently general capture belief change
uncertainty actions defined given epistemic extensions SitCalc,
important note respects approach actually expressive.
particular, allow revision arbitrary rankings formulas; require
fixed set sensing actions. approach also allows flexible representation
interaction uncertainty actions observations, elaboration
tolerant sense need modify aggregates plausibility functions
capture different phenomena. hand, SitCalc provides rigorous
precise treatment actions effects ontic change. example, SitCalc treatment
property persistence (Kelly & Pearce, 2010) captures natural feature certain world
properties captured graded world view ad hoc restriction
plausibility functions. Overall, see approach high-level model belief change
capture dynamics belief SitCalc, losing
advantages SitCalc model action effects.
5.5 Relation Dynamic Epistemic Logic
notion belief change due reported information addressed Dynamic
Epistemic Logic (DEL) (van Ditmarsch, van der Hoek, & Kooi, 2007). context, belief
813

fiHunter & Delgrande

change captured plausibility models. plausibility model Kripke structure,
associate well-ordering possible states state; ordering indicates states seen plausible state structure. Belief update
captured setting state-changing actions allow different agents
different awareness action executed (Baltag & Smets, 2008); belief
revision captured mapping plausibility models syntactically defined
suitable modal operators (Baltag & Smets, 2006; Van Benthem, 2007). Although
common use ordering represent plausibility DEL, also variants
plausibility captured quantitative values. example, Laverny Lang
(2005) define logic incorporates actions uses ranking functions N {}
model strength belief formulas without nested modalities.
two main distinctions work related work DEL tradition. first distinction superficial, related high-level perspective new
information. DEL, external perspective new information, structures explicitly model way agent system views new information.
DEL expressive respect nested multi-agent beliefs: able
explicit perspective agent. presented paper, think
graded world views taking internal perspective single agent. provide
ranking function represents observation, external knowledge
actual state world. advantage approach every observation (resp.
action) always possible. contrast, external perspective DEL, may
situations certain information simply cannot provided information update.
example, underlying Kripke structure contains states true,
information update provided make agent believe false.
second distinction work existing work DEL related
uniform representation observations actions. DEL, distinction often drawn
so-called hard updates soft updates (Van Benthem, 2007). hard update
occurs information definite sense, incorporated modifying
accessible states. might occur, example, common knowledge
certain state-changing action occurred. soft update corresponds belief revision,
information incorporated modifying plausbility ordering. However,
practical setting, often case one distinguish kind change
actually occur. kind ambiguity occur case graded world views,
belief change operations handled uniform manner taking aggregates
plausibility functions. Morever, hard update soft update, update typically
single piece information single level plausibility. Hence, observations
actions represented graded manner. one distinguishing features
present work: allow observations (and actions) provide different levels evidence
several different states simultaneously.
Despite differences, important emphasize actually see graded
world views alternative DEL. Instead, see approach presented tool
could used basis belief change suitably defined DEL quantitative
plausibility rankings. analogous way formal belief change operators
incorporated modal logics. Iterated revision operators lexicographic revision
(Nayak, 1994) natural revision (Boutilier, 1996) originally defined general
814

fiBelief Change Uncertain Action Histories

setting orderings, used motivating examples information update
DEL. Similarly, suggest modal logic could defined semantics
iterated propositional updates based aggregates plausibility functions.
logic would able model practical domains discussed paper,
would also able capture complex multi-agent situations involving nested belief.
5.6 Representations Plausibility
Following Spohn (1988), taken quantitative ranking functions representation
plausibility. However, literature belief change defeasible reasoning contains
great deal work different representations plausibility. section, briefly
consider alternative approaches literature, argue approach
suitable kind reasoning intend capture.
basic representation plausibility literature total pre-order
states, often see AGM-inspired work. normally think ordering
terms series levels plausibility. obvious limitation approach
notion magnitude respect differences plausibility, although
introduced allowing empty levels. event, clear ranking
functions expressive total pre-orders respect modelling plausibility.
interesting distinction occurs notion plausibility, orderings
used DEL tradition. noted above, plausibility context typically captured
well-ordering (Van Benthem, 2007). necessary because, setting,
want states comparable; want certain states innaccessible
others. One might ask ranking functions limited sense respect
well-orderings used plausibility models. choice ranking functions motivated
internal-external distinction discussed previous section. individual agent need
consider impossible states order modify beliefs appropriately, need
consider highly unlikely states.
Note approach superficially similar related work defeasible reasoning
featuring form preferential ordering states. possible, example, reason
typicality supplementing Kripke structure single ordering states
(Britz & Varzinczak, 2013). alternative model setting description logics also
proposed, function introduced map concept set elements
deemed typical (Giordano, Olivetti, Gliozzi, & Pozzato, 2013). However,
despite superficial similarities, important clear initial plausibility
function intended representation typicality normality absolute
sense. model plausibility corresponds closely pointed plausibility model
includes distinguished actual state.
Alternative quantitative models plausibility also explored literature.
One influential approaches based possibility measures,
functions map states [0, 1] (Benferhat et al., 1999). main difference
possibility measure plausibility function really possibility measure 0 actually corresponds impossibility, corresponding plausibility value. However,
already shown plausibility functions used capture rational-valued
815

fiHunter & Delgrande

functions [0,1]; would straightforward modify proof deal real number
values.
One general measures plausibility literature plausibility space,
analogous probability space except range plausibility values
set (Friedman & Halpern, 2001). Plausibility spaces intended
general model subsumes great deal existing work reasoning plausibility.
Indeed, plausibility functions clearly special case plausibility space;
representation belief seen special case general approach.
section, restricting discussion alternative representations
plausibility states. noted previously, approach representation plausibility
states actually new therefore easy position work context.
novel feature approach use notion plausibiility actions,
order develop novel approach reasoning iterated belief change due actions
observations

6. Limitations Advantages
focus previous sections establishing expressive power graded
world views, compared existing frameworks reasoning belief change.
result, focused problems involving priori graded world view, along
new information. However, restriction new information artificial.
general case, reason restrict attention problems agent
receives information actions observations occurring recent point
time. agent could certainly receive new information earlier events actions.
Hence, general problem involves agent underlying graded world view,
together set constraints plausible histories. section, consider
representation problems general form.
6.1 Constrained World Views
Suppose hACT, OBSi graded world view length n. action constraint
pair (A, i) action symbol n. Define (hACT, OBSi) (A, i)
set histories minimal plausibility, subject restriction ith
action executed A. define observation constraints analogous manner,
let (hACT, OBSi) (, i) set minimally ranked histories ith state
. set constraints, define (hACT, OBSi) set
minimally ranked histories satisfying every constraint . refer histories
constrained histories refer graded world view together set
constraints constrained world view.
presented constrained world views illustrate graded world views
useful many problems beyond normally considered realm
standard belief change operator. example, suppose Bob sends encrypted
email message Alice, inviting party house. Bob aware Eve
system administrator, could potentially manipulate message
delivering it. Alice show up, Bob concludes Eve deliver
message. Bob concerned Eve read message hurt feelings
816

fiBelief Change Uncertain Action Histories

invited. However, looking every possible action Eve could take, Bob concludes
Eve could decrypted message.
preceding example, Bob needs consider possible actions Eve could
executed. conclusion Bob draws Eves knowledge party invariant
respect actions. formally define invariance follows.
Definition 14 Let hACT, OBSi graded world view. say set states
i-invariant hACT, OBSi if, every A, Bel(hACT, OBSi (A, i)) .
intuition behind i-invariance that, regardless action time i, underlying
agent always believe actual world . Reasoning invariant properties
essential agent trying ensure property must hold action domain
involving exogenous actions. required, example, reasoning cryptographic
protocols.
Reasoning invariance one new kind problem addressed
constrained world views. suggest constraints also used provide natural
representations hypothetical reasoning abductive reasoning.
6.2 Belief Extrapolation
Constrained world views similar belief extrapolation operators (Dupin de Saint-Cyr
& Lang, 2011). Briefly, belief extrapolation operator l takes sequence formulas,
called scenario input, outputs another scenario. intuition output
gives general sequence formulas possibly true, given input
assumption fluents tend inertial. give brief description basic
construction.
trajectory sequence interpretations fixed signature. Let (i) denote
ith interpretation trajectory . Given scenario , let Traj () denote set
trajectories satisfy formula point-by-point basis. Every ordering
class trajectories defines extrapolation operator l follows:
|( l (t))| = { (t) | Min(, Traj ())}
Hence, l picks minimal trajectories satisfying .
present purposes, important feature belief extrapolation operator
defined respect ordering histories. Given ordering
histories together sequence formulas, belief extrapolation operator returns
plausible sequences states. case constrained world views, essentially
thing. given graded world view defines ordering states,
constraints give sequence conditions need satisfied. easy show
that, using summation aggregate, every graded world view captured belief
extrapolation operator. section, consider converse problem: every belief
extrapolation operator represented suitable graded world view?
key observation mapping graded world views orderings
histories surjective; orderings histories described
graded world view. example, graded world view explicitly capture
plausibilities form A1 occurs time i, A2 likely occur time + 1.
817

fiHunter & Delgrande

easy see, graded world view ranks histories combining sequence
rankings instant. course, might possible devise sequence rankings
along aggregate function happened support conditional plausibility
fixed action signature. would domain-specific property, temporal
relation actions expressed two independent plausibility functions.
Informally, graded world view represent domains ordering histories
built pointwise manner plausibilities point time. section,
use limitation establish difference expressive power constrained
world views belief extrapolation operators.
First, need formalize problem would like address precisely.
Given belief extrapolation operator, would like able find graded world view
captures information.
Definition 15 Let l belief extrapolation operator. say l representable
graded world view hACT, OBSi that, every scenario length n,
Traj ( l) = (hACT, OBSi) .
l representable, behaviour l simulated graded world view.
remark abused notation definition Traj ( l) collection
sequences states, whereas (hACT, OBSi) collection histories. interpret
equality mean two collections equal ignore action symbols
latter.
following proposition indicates belief extrapolation operators expressive advantage.
Proposition 12 belief extrapolation operator l representable.
Proof Let ordering following trajectories minimal.
1. h{a, b}, {a, b}, {a, b}i
2. h{a, b}, {a, b}, {a, b}i
3. h{a, b}, {a, b}, {a, b}i
Let l associated belief extrapolation operator. show l representable.
Let = ha, b, bi. Note satisfied three minimal trajectories. Therefore
raj( l) precisely set minimal trajectories.
suppose hACT, OBSi graded world view
hACT, OBSi
assigns minimal plausibility 1, 2, 3. Hence, exist actions A1 , A2 , A3 , B1 , B2 , B3
following sums obtain minimum possible rank:
1. OBS0 ({a, b}) + ACT1 (A1 ) + OBS1 ({a, b}) + ACT2 (B1 ) + OBS2 ({a, b})
2. OBS0 ({a, b}) + ACT1 (A2 ) + OBS1 ({a, b}) + ACT2 (B2 ) + OBS2 ({a, b})
818

fiBelief Change Uncertain Action Histories

3. OBS0 ({a, b}) + ACT1 (A3 ) + OBS1 ({a, b}) + ACT2 (B3 ) + OBS2 ({a, b})
must case ACT1 (A1 ) = ACT1 (A2 ), otherwise either 1 2 could
reduced changing first action. Similarly, must case ACT2 (B1 ) =
ACT2 (B3 ), otherwise either 1 3 would minimal. So, rewrite
sums follows:
1. OBS0 ({a, b}) + ACT1 (A1 ) + OBS1 ({a, b}) + ACT2 (B1 ) + OBS2 ({a, b})
2. OBS0 ({a, b}) + ACT1 (A1 ) + OBS1 ({a, b}) + ACT2 (B2 ) + OBS2 ({a, b})
3. OBS0 ({a, b}) + ACT1 (A3 ) + OBS1 ({a, b}) + ACT2 (B1 ) + OBS2 ({a, b})
1 2, follows basic algebra
ACT2 (B1 ) + OBS2 ({a, b}) = ACT2 (B2 ) + OBS2 ({a, b}).
Substituting 3 gives another minimal sum:
OBS0 ({a, b}) + ACT1 (A3 ) + OBS1 ({a, b}) + ACT2 (B2 ) + OBS2 ({a, b}).
corresponds trajectory
h{a, b}, {a, b}, {a, b}i.
Hence, graded world view assigning minimum plausibility 1-3, must also assign
minimum plausibility fourth trajectory. Informally, 1-3 preferred trajectories
according graded world view, forced accept another preferred trajectory.
already saw raj( l) consists 1-3. Therefore l representable.

Note proof Proposition 12 constructive demonstrates
simple, concrete, extrapolation operator representable.
Informally, Proposition 12 follows fact orderings histories
defined graded world view. particularly important applications
agent preferences order events occur. applications,
useful assign plausibilities certain sequences actions. suggest, however,
class orderings definable graded world views natural class orderings.
particular, many action domains agent preconceived assumptions
order exogenous actions occur. Graded world views provide reasonable tool representation action domains. Graded world views also
expressive advantage explicitly represent fallible actions well
forms uncertainty action effects.
seen represent every belief extrapolation operator,
would mistake conclude graded world views strictly less expressive. Belief
extrapolation really says nothing explicit actions, leads several differences
approach. Given ordering histories length n, clear use
belief extrapoloation incorporate new action followed new observation;
fixed method extending orderings n-tuples orderings n + 1 tuples.
819

fiHunter & Delgrande

case graded world view, however, clear new ordering defined
actions performed. such, graded world views appropriate
representation epistemic action domains expect new observations actions
occur. course, approach, fixed length initial graded world
view. Since null actions, however, value n really maximum length
sequence actions occurred. such, graded world views sensible domains
imagine maximum number actions previously occurred
bounded. Again, suggest class domains satisfies constraint
large natural.
6.3 Beliefs Action Effects
Despite flexible representation observations actions, one aspect
representation quite rigid. Specifically, single underlying transition system
gives effects actions; mechanism changing transition system
response new information. addressed Varzinczak (2010) modal
setting, introducing formal mechanism allows effects actions change
response new information. Combining idea notion plausibility graded
world view would give even complete picture way agents reason
effects actions uncertain effects. leave treatment idea future
work.
related problem fact underlying transition system framework
essentially known agent. words, given perfect information
current state world action executed, agent knows
resulting state. alternative approach due Eiter et al. (2010) start
action description specifies actions effects. introduce suitable
information update mechanisms based (partial) description effects, rather
assuming definite underlying transition system. is, however, superficial
distinction. using effect ranking functions, essentially give partial description
action effects corresponds action description. manner, straightforward
define so-called Action Description Update problems graded world views.

7. Conclusion
introduced formalism reasoning sequences actions observations.
formalism uses Spohn-style ranking functions instant determine
plausible action observation, determines plausible histories aggregate
function instants. proved formalism subsumes belief revision,
belief evolution, conditionalization. Moreover, suitable representation
fallible beliefs, erroneous perception, exogenous actions, failed actions. used
transition systems representation actions order facilitate comparison
wide range action formalisms. future work, interested axiomatizing
belief change permitted class admissible aggregate functions.
main advantage graded world views related formalisms graded world
views provide uniform mechanism dealing imperfect information actions
observations. such, graded world views allow observations need incor820

fiBelief Change Uncertain Action Histories

porated agent convinced certain action occurred previously.
hand, graded world views also allow agent retract belief action occurred
strong belief observation. Graded world views provide tool representing opposing conclusions, simply considering magnitudes plausibilities,
well underlying aggregate.
existing work, belief change caused actions often represented starting
action formalism adding revision operators. One problem approach
allow beliefs action occurrences. sense, graded world views
take opposite approach. start ranking functions, originally defined
reasoning belief change static environment, plug actions.
agents beliefs actions occur independent formal representation
action effects. such, although presented graded world views terms
transition systems, would certainly possible use different action formalism.
key point that, using ranking functions represent uncertainty states
actions, define framework reasoning epistemic action effects
primary importance placed evolution agents beliefs.
conclude brief remark overall approach taken framework.
distinction commonly drawn update revision belief change literature,
despite fact difficult practice determine appropriate
operation given particular piece information. many cases, simply clear
conflicting information result unseen action result erroneous
beliefs. One solution problem define single, general belief change operation
subsumes (Kern-Isberner, 2008). contrasat, maintain explicit distinction
way beliefs change due actions observations, use uniform model
uncertainty agent level focuses finding plausible sequence events
explain available evidence. seems like natural approach many applications,
agents perception past events likely influenced conviction
respect senses beliefs.

References
Alchourron, C., Gardenfors, P., & Makinson, D. (1985). logic theory change:
Partial meet functions contraction revision. Journal Symbolic Logic, 50 (2),
510530.
Bacchus, F., Halpern, J., & Levesque, H. (1999). Reasoning noisy sensors effectors
situation calculus. Artificial Intelligence, 111 (1-2), 171208.
Baltag, A., & Smets, S. (2006). Dynamic belief revision multi-agent plausibility models.
Proceedings Logic Foundations Game Decision Theory (LOFT),
pp. 1124.
Baltag, A., & Smets, S. (2008). qualitative theory dynamic interactive belief revision.
Proceedings Logic Foundations Game Decision Theory (LOFT).
Benferhat, S., Dubois, D., & Prade, H. (1999). Possibilistic standard probabilistic
semantics conditional knowledge bases. Journal Logic Computation, 9 (6),
873895.
821

fiHunter & Delgrande

Boutilier, C. (1995). Generalized update: Belief change dynamic settings. Proceedings
Fourteenth International Joint Conference Artificial Intelligence (IJCAI
1995), pp. 15501556.
Boutilier, C. (1996). Iterated revision minimal change conditional beliefs. Journal
Philosophical Logic, 25, 263305.
Britz, K., & Varzinczak, I. (2013). Defeasible modalities. Proceedings 14th Conference Theoretical Aspects Rationality Knowledge (TARK), pp. 4960.
Darwiche, A., & Pearl, J. (1997). logic iterated belief revision. Artificial Intelligence, 89 (1-2), 129.
Delgrande, J. (2004). Preliminary considerations modelling belief change operators metric spaces. Proceedings 10th International Workshop NonMonotonic Reasoning (NMR 2004), pp. 118125.
Delgrande, J., Dubois, D., & Lang, J. (2006). Iterated revision prioritized merging.
Proceedings 10th International Conference Principles Knowledge Representation Reasoning (KR2006).
Delgrande, J., & Levesque, H. (2012). Belief revision sensing fallible actions.
Thirteenth International Conference Principles Knowledge Representation
Reasoning (KR2012), pp. 148157.
Dupin de Saint-Cyr, F., & Lang, J. (2011). Belief extrapolation (or reason
observations unpredicted change). Artificial Intelligence, 2, 760790.
Eiter, T., Erdem, E., Fink, M., & Senko, J. (2010). Updating action domain descriptions.
Artificial Intelligence, 174 (15), 11721221.
Friedman, N., & Halpern, J. (2001). Plausibility measures default reasoning. Journal
ACM, 48 (4), 648685.
Gelfond, M., & Lifschitz, V. (1998). Action languages. Linkoping Electronic Articles
Computer Information Science, 3 (16), 116.
Giordano, L., Olivetti, N., Gliozzi, V., & Pozzato, G. (2013). non-monotonic description
logic reasoning typicality. Artificial Intelligence, 195, 165202.
Grove, A. (1988). Two modellings theory change. Journal Philosophical Logic, 17,
157170.
Hunter, A. (2014). Belief change non-deterministic actions. Proceedings
Canadian Conference Artificial Intelligence, pp. 289294.
Hunter, A., & Booth, R. (2015). Trust-sensitive belief revision. Proceedings
International Joint Conference Artificial Intelligence (IJCAI15).
Hunter, A., & Delgrande, J. (2006). Belief change context fallible actions observations. Proceedings National Conference Artificial Intelligence(AAAI06),
pp. 257262.
Hunter, A., & Delgrande, J. (2011). Iterated belief change due actions observations.
Journal Artificial Intelligence Research (JAIR), 40, 269304.
822

fiBelief Change Uncertain Action Histories

Jin, Y., & Thielscher, M. (2004). Representing beliefs fluent calculus. Proceedings
European Conference Artificial Intelligence(ECAI04).
Katsuno, H., & Mendelzon, A. (1991). difference updating knowledge base
revising it. Proceedings Second International Conference Principles
Knowledge Representation Reasoning (KR 1991), pp. 387394.
Katsuno, H., & Mendelzon, A. (1992). difference updating knowledge
base revising it. G ardenfors, P. (Ed.), Belief Revision, pp. 183203. Cambridge
University Press.
Kelly, R., & Pearce, A. (2010). Property persistence situation calculus. Artificial
Intelligence, 174 (12-13), 865888.
Kern-Isberner, G. (2008). Linking iterated belief change operations nonmonotonic reasoning. Proceedings Eleventh International Conference Principles
Knowledge Representation Reasoning (KR08), pp. 166176.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models cumulative logics. Artificial Intelligence, 4, 167207.
Laverny, N., & Lang, J. (2005). knowledge-based programs graded belief-based
programs, part i: On-line reasoning. Synthese, 147 (2), 277321.
Lehmann, D., & Magidor, M. (1992). conditional knowledge base entail?.
Artificial Intelligence, 55, 160.
Levesque, H., Pirri, F., & Reiter, R. (1998). Foundations situation calculus.
Linkoping Electronic Articles Computer Information Science, 3 (18), 118.
Liberatore, P., & Schaerf, M. (2000). BReLS: system integration knowledge
bases. Proceedings KR2000, pp. 145152. Morgan Kaufmann Publishers.
Lorini, E., Jiang, G., & Perrussel, L. (2014). Trust-based belief change. ECAI 2014 21st European Conference Artificial Intelligence, pp. 549554.
Moore, R. (1985). formal theory knowledge action. Hobbs, J., & Moore, R.
(Eds.), Formal Theories Commonsense World, pp. 319358. Ablex Publishing.
Nayak, A. (1994). Iterated belief change based epistemic entrenchment. Erkenntnis, 41,
353390.
Papini, O. (2001). Iterated revision operations stemming history agents
observations. Rott, H., & Williams, M. (Eds.), Frontiers Belief Revision, pp.
279301. Kluwer Academic Publishers.
Shapiro, S., Pagnucco, M., Lesperance, Y., & Levesque, H. (2011). Iterated belief change
situation calculus. Artificial Intelligence, 175 (1), 165192.
Spohn, W. (1988). Ordinal conditional functions. dynamic theory epistemic states.
Harper, W., & Skyrms, B. (Eds.), Causation Decision, Belief Change, Statistics, vol. II, pp. 105134. Kluwer Academic Publishers.
Van Benthem, J. (2007). Dynamic logic belief revision. Journal applied non-classical
logics, 17 (2), 129155.
823

fiHunter & Delgrande

van Ditmarsch, H., van der Hoek, W., & Kooi, B. (2007). Dynamic Epistemic Logic.
Springer.
Varzinczak, I. (2010). action theory change. Journal Artificial Intelligence Research
(JAIR), 37, 189246.

824

fiJournal Artificial Intelligence Research 53 (2015) 375-438

Submitted 01/15; published 07/15

Approximate Value Iteration
Temporally Extended Actions
Timothy A. Mann
Shie Mannor

mann@ee.technion.ac.il
shie@ee.technion.ac.il

Electrical Engineering
Technion - Israel Institute Technology,
Haifa, Israel

Doina Precup

dprecup@cs.mcgill.ca

School Computer Science
McGill University,
Montreal, QC, H3A2A7, Canada

Abstract
Temporally extended actions proven useful reinforcement learning,
duration also makes valuable efficient planning. options framework provides
concrete way implement reason temporally extended actions. Existing
literature demonstrated value planning options empirically,
lack theoretical analysis formalizing planning options efficient
planning primitive actions. provide general analysis convergence rate
popular Approximate Value Iteration (AVI) algorithm called Fitted Value Iteration (FVI)
options. analysis reveals longer duration options pessimistic estimate
value function lead faster convergence. Furthermore, options improve
convergence even suboptimal sparsely distributed throughout statespace. Next consider problem generating useful options planning based
subset landmark states. suggests new algorithm, Landmark-based AVI (LAVI),
represents value function landmark states. analyze FVI
LAVI using proposed landmark-based options compare two algorithms.
experimental results three different domains demonstrate key properties
analysis. theoretical experimental results demonstrate options play
important role AVI decreasing approximation error inducing fast convergence.

1. Introduction
consider problem planning Markov Decision Processes (MDPs; Puterman,
1994, see Section 2) large even infinite state-spaces. setting, traditional
planning algorithms, Value Iteration (VI) Policy Iteration (PI), intractable
computational memory complexities iteration scale (polynomially
linearly, respectively; Littman, Dean, & Kaelbling, 1995) number states
target MDP. Approximate Value Iteration (AVI) algorithms scalable VI,
compactly represent value function (Bertsekas & Tsitsiklis, 1996).
allows AVI algorithms achieve per iteration computational memory complexities
independent size state-space. However, many challenges
c
2015
AI Access Foundation. rights reserved.

fiMann, Mannor, & Precup

using AVI algorithms practice. AVI VI often need many iterations solve MDP
(Munos & Szepesvari, 2008). turns temporally extended actions play
important role reducing number iterations.
options framework defines unified abstraction representing temporally
extended actions primitive actions (Sutton, Precup, & Singh, 1999). option
initialized, immediately selects primitive action (or lower-level option) execute
return control agent. Then, following timestep, option tests
whether return control agent called option continue selecting
another primitive action (or lower-level option). represent temporally
extended actions, options provide valuable tool efficient planning (Sutton et al., 1999;
Silver & Ciosek, 2012). analyses AVI, one iteration corresponds planning
one additional timestep future. hand, performing single iteration
AVI temporally extended actions, one iteration could instead correspond planning
several timesteps future. derive bounds help us reason AVI
temporally extended actions converges faster AVI primitive actions.
options framework appealing investigating planning temporally extended
actions. one thing, class options includes primitive actions well wide
range temporally extended actions, many well-known properties Markov
Decision Processes generalize arbitrary options added (e.g., Value Iteration
Policy Iteration still converge, Precup & Sutton, 1997; Precup, Sutton, & Singh, 1998;
Sutton et al., 1999). addition, much effort gone algorithms learn good
options exploration (Iba, 1989; Stolle & Precup, 2002; Mannor, Menache, Hoze, & Klein,
2004; Konidaris & Barto, 2007). algorithms may produce options also useful
planning. Lastly, options allow greater flexibility modeling problems
actions temporal resolution. example, inventory management
problems placing orders may occur regular intervals (Minner, 2003)
RoboCup Keepaway domain agents make decisions control
soccer ball (Stone, Sutton, & Kuhlmann, 2005). Thus, options important candidate
investigating planning temporally extended actions.
1.1 Motivation
Ultimately care time takes solve MDP. However, focus analyzing convergence rate AVI options, faster convergence rate implies
solution fewer iterations. Using convergence rate determine total
computational cost planning bounding computational cost iteration.
total computational cost options smaller primitive actions, planning
options faster planning primitive actions.
focus convergence rate provide valuable insight
planning options faster planning primitive actions. However,
present full computational complexity planning options computational cost per iteration highly domain dependent. Therefore, convergence rate
planning options gives us insight planning options may faster
planning primitive actions without getting bogged domain specific details. example, computational cost iteration depends (1) computational
376

fiApproximate Value Iteration Temporally Extended Actions

complexity simulating option, (2) computational complexity value function
approximation method, (3) number primitive actions temporally extended
actions initialized state.
sake clarity, discuss factors impact computational
complexity AVI.
1.1.1 Cost Simulating Actions Options
computational cost simulating option depends simulator. assume
simplicity primitive actions simulated approximately
computational cost. main question is: compuational cost simulating
temporally extended actions compared cost simulating primitive actions?
general, simulator primitive actions used simulate options executing
sequence primitive actions prescribed option. computational cost
equal cost simulating sequence primitive actions. However,
simulator inexpensive, simulation costs may outweighed cost fitting
data function approximator. seen experiments section 5.
cases, specialized simulators constructed temporally extended
actions approximately cost primitive actions. discrete state MDPs,
accomplished preprocessing step composing options primitive
actions (Silver & Ciosek, 2012). large- continuous-state MDPs, linear options
framework enables construction option models composing models primitive
actions (Sorg & Singh, 2010). addition, existing simulators carefully designed
simulating actions long short timescales (Chassin, Fuller, & Djilali, 2014).
1.1.2 Cost Value Function Approximation
choice function approximation architecture drastic implications
computational cost iteration. Ridge Regression, LASSO, SVR, Neural Networks,
etc. computational costs scale number features varying rates.
cases, cost training suitable function approximation architecture may
significantly expensive cost querying simulator. cases,
decreasing number iterations result significant overall computational savings
even options require queries simulator.
1.1.3 Number Actions Options
iteration, AVI samples actions collection states. large (or
even infinite) number primitive actions, planning made computationally
efficient sample efficient planning instead smaller number options.
1.1.4 Cost Acquiring Options
One final consideration computational cost acquiring options. options
designed advance experts, additional cost. However, options
discovered generated, cost factored total cost
algorithm. landmark-based option generation approach proposed section 5.3.2
377

fiMann, Mannor, & Precup

almost overhead, given set landmark states. However, computationally
expensive methods acquiring options (Simsek & Barto, 2004; Mannor et al., 2004) could
justified options reused planning many tasks (Fernandez & Veloso,
2006).
1.2 Contributions
main contributions paper following:
propose Options Fitted Value Iteration (OFVI) algorithm, variant popular Fitted Value (or Q-) Iteration (FVI, Riedmiller, 2005; Munos &
Szepesvari, 2008; Shantia, Begue, & Wiering, 2011) algorithm samples generated
options.
analyze OFVI Theorem 1, characterizing asymptotic loss convergence behavior planning given set options. give two corollaries
specifying bound simplifies when: (1) options minimum duration > 1 (Corollary 1) (2) option set contains long duration options
primitive actions (Corollary 2).
introduce novel method generating options, based landmark states.
suggests new algorithm, Landmark-based Approximate Value Iteration (LAVI),
needs model value finite set states rather whole value
function.
analyze asymptotic loss convergence behavior LAVI Theorem 2
OFVI landmark options Theorem 3. Comparing bounds LAVI
OFVI suggests LAVI may converge faster OFVI. However, asymptotic
losses directly comparable.
provide detailed experimental comparison FVI primitive actions, OFVI
hand-coded options, OFVI landmark options, LAVI. experiments
domain realistic pinball-like physics complex inventory management
problem, demonstrate LAVI achieves favorable performance versus time tradeoff.
rest paper organized follows. Section 2 introduces background
Markov Decision Processes, Dynamic Programming, previous analysis FVI, Semi-Markov
Decision Processes, options. Section 3 defines Options Fitted Value Iteration
(OFVI) algorithm compares Primitive Actions Fitted Value Iteration (PFVI)
considered previous work. Section 3.2 provides detailed discussion convergence
properties OFVI different conditions. Section 4 introduces landmark options
explains landmarks used generate useful options planning. section also provides analyses convergence rates LAVI OFVI landmark-based
options. Section 5 provides experiments results comparing PFVI OFVI three
different domains. Section 6 discusses relationship results presented
previous work, well as, extensions directions future work.
378

fiApproximate Value Iteration Temporally Extended Actions

2. Background
Let X subset d-dimensional Euclidean space, (X) set probability measures X, f : X R function vectors X real numbers.
max-norm kf k = supxX |f (x)|. p 1 (X), (p, )-norm defined
1/p
R
kf kp, =
(x)kf (x)kp dx
.
MDP defined 5-tuple hX, A, P, R, (Puterman, 1994) X set
states, set primitive actions, P maps state-action pairs probability
distributions states, R mapping state-action pairs reward distributions
bound interval [RMAX , RMAX ], [0, 1) discount factor. Let B(X; VMAX )
denote set functions domain X range bounded [VMAX , VMAX ]
MAX
VMAX R1
. Throughout paper consider MDPs X bounded subset
d-dimensional Euclidean space finite (non-empty) set actions.
policy : X mapping states actions. denote set deterministic, stationary Markov policies . standard objective planning MDP
derive policy maximizes
"
#
X


V (x) = E
(1)
Rt (xt , (xt ))|x0 = x, ,
t=0

x long-term value following starting state x. function V called
value function respect policy well known written
recursively solution
Z

V , E [R(x, (x))] + P (y|x, (x))V (y)dy,
(2)
Bellman operator respect V unique fixed point. Given
vector V B(X; VMAX ), greedy policy respect V defined
Z
(x) = arg max E [R(x, a)] + P (y|x, (x))V (y)dy .
(3)
aA

denote optimal value function V = max V .
Definition 1. policy optimal corresponding value function V . policy
-optimal V (x) V (x) x X.
Bellman optimality operator defined


Z
(T V )(x) = max E [R(x, a)] + P (y|x, a)V (y)dy ,
aA

(4)



V B(X; VMAX ), known fixed point V . Value Iteration (VI),
popular planning algorithm MDPs, defined repeatedly applying (4). algorithm
produces series value function estimates V0 , V1 , V2 , . . . , VK greedy policy K
constructed based VK . Since VI converges limit, policy K may
optimal. However, would still like measure quality K compared .
measure quality policy need define notion loss. following
defines loss policy respect set states loss policy respect
probability distribution.
379

fiMann, Mannor, & Precup

Definition 2. Let x X. subset-loss policy respect set states
X defined
LY () = max (V (x) V (x)) ,
(5)
xY

denote special case X L (). Let p 1 (X).
loss policy respect distribution states defined
Lp, () = kV V kp, .

(6)

VI operates entire state space. able decrease L error,
VI computationally intractable MDPs extremely large continuous state
spaces. Thus approximate forms VI generally seeks decrease loss respect
probability distribution state space.
2.1 Approximate Value Iteration (AVI)
Approximate Value Iteration (AVI) family algorithms estimate optimal
(action-)value function iteratively applying approximation Bellman optimality
operator. many possible relaxations VI. states backed according , representation value function estimates, number times sample
simulator, etc. impact loss resulting policy.
One popular family AVI algorithms Fitted Value Iteration (FVI) algorithms.
algorithms use function approximator represent value function estimates
iteration. Primitive action Fitted Value Iteration (PFVI) generalization VI handle
large continuous state spaces. PFVI runs iteratively producing sequence K 1
estimates {Vk }K
k=1 optimal value function returns policy K greedy
respect final estimate VK . iteration k, algorithm computes
set empirical estimates Vk Vk1 n states, fits function approximator
Vk . generate Vk , n states {xi }ni=1 sampled distribution (X).
}m rewards
sampled state xi primitive action A, next states {yi,j
j=1
}m
th iteration, estimates
{ri,j
j=1 sampled MDP simulator S. k
Bellman backups computed


1 X

Vk (xi ) = max
ri,j + Vk1 (yi,j
) ,
aA

(7)

j=1

V0 initial estimate optimal value function given argument PFVI.
k th estimate optimal value function obtained applying supervised learning
algorithm A, produces
n fi
fip
X
fi
fi
Vk = arg min
fif (xi ) Vk (xi )fi ,
f F

(8)

i=1

p 1 F B(X; VMAX ) hypothesis space supervised learning
algorithm.
work Munos Szepesvari (2008) presented full finite-sample, finite-iteration
analysis PFVI guarantees dependent Lp -norm rather much
380

fiApproximate Value Iteration Temporally Extended Actions

conservative infinity/max norm. enabled analysis instances PFVI use one
many supervised learning algorithms minimizing L1 L2 norm. key assumption
needed analysis notion discounted-average concentrability future state
distributions.
Assumption 1. [A1(, )] [Discounted-Average Concentrability Future-State
Distributions] (Munos, 2005; Munos & Szepesvari, 2008) Given two distributions
defined state space X, 1, arbitrary policies 1 , 2 , . . . , ,
assume P 1 P 2 . . . P absolutely continuous respect implying


d(P 1 P 2 . . . P )
def
< + ,
c(m) =
sup
(9)



1 ,2 ,...,m

assume

def

C, = (1 )2

X

m1 c(m) < +

m1

discounted average concentrability coefficient, P denotes transition kernel
induced executing action prescribed policy .
Intuitively, assumption prevents much transition probability mass landing
small number states. condition C, finite depends c(m) growing
subexponentially. See work Munos (2005) complete discussion
Assumption 1. note work Farahmand, Munos, Szepesvari (2010)
presents refined analysis using expectation (9) rather supremum.
results tighter bounds bounds difficult interpret due blowup
notation.
work Munos Szepesvari (2008) shows given MDP, select probability distributions , (X), positive integer p, supervised learning algorithm
bounded function space F returns function f F minimizes
empirical p-norm error, V0 F initial estimate optimal value function, > 0
(0, 1]. K 1, probability least 1 , exist positive
integers n, m, K policy K returned PFVI satisfies




2
1/p
K+1 1/p 2 kV V0 k
Lp, (K )
C bp, (T F, F) + +
,
(10)
(1 )2 ,
(1 )2
bp, (T F, F) = sup inf kT f gkp, inherent Bellman error F respect
f F gF
.1

Bellman operator
inherent Bellman error measure well chosen
hypothesis space F represent Vk iteration. first term (10) called
approximation error corresponds error introduced inability
supervised learning algorithm exactly capture Vk iteration, second
term, estimation error, due using finite number samples estimate Vk .
last term controlled number iterations K algorithm. increasing K
1. paper, consider multi-sample variant PFVI uses fresh samples iteration.
bound single-sample variant PFVI, uses batch samples iteration,
almost identical (10). See work Munos Szepesvari (2008) details.

381

fiMann, Mannor, & Precup

last term shrinks exponentially fast. last term characterizes convergence rate
algorithm. size discount factor controls rate convergence. Convergence
faster smaller. Unfortunately, part problem definition. However,
options execute multiple timesteps, option effective discount
factor smaller .
2.2 Semi-Markov Decision Processes
Semi-Markov Decision Processes (SMDPs) generalization Markov Decision
Process (MDP) model incorporates temporally extended actions. Temporally extended
actions primarily applied direct exploration reinforcement learning (Iba,
1989; Mannor et al., 2004; Konidaris & Barto, 2007; Jong & Stone, 2008). However,
may also play important role planning (Precup & Sutton, 1997; Precup et al., 1998;
Sutton et al., 1999; Silver & Ciosek, 2012). example, popular dynamic programming
algorithms VI PI still converge applied SMDPs (Puterman, 1994). work
Precup et al. (1998) shows options MDP form SMDP. works Sutton
et al. (1999) Silver Ciosek (2012) provide experimental results demonstrating
options speed planning finite state MDPs. However, works apply
options tasks continuous state spaces theoretical analysis
convergence rate planning options compared planning primitive actions.
use SMDP framework investigate planning temporally extended actions.
MDP paired set temporally extended actions called options, denoted
O, forms SMDP.
Definition 3. (Sutton et al., 1999) option defined 3-tuple hIo , ,
Io set states initialized from, stationary policy defined
primitive actions followed lifetime o, : X [0, 1] determines
probability terminate given state.
state x X, denote set options initialized x
Ox = {o | x Io }. Options generalization actions. fact encompass,
primitive actions temporally extended actions, also stationary policies
control structures. take actions options always terminate
finite number timesteps. Policies hand never terminate. example,
stationary policy represented option setting termination probabilities
(x) = 0 states.
option = hIo , , i, denote probability initialized state

x terminates subset states X exactly timesteps P
(Y |x)
P

discounted termination state probability distribution Peo (Y |x) =
t=1 Pt (Y |x).
state-option pair (x, o), discounted cumulative reward distribution
e o).
options execution denoted R(x,
objective planning options derive policy : X states
options maximizes
h
Z
e (x)) + Pe(x) (y|x)V (y)dy .
V (x) = E R(x,
382

(11)

fiApproximate Value Iteration Temporally Extended Actions

Bellman operator SMDP defined
h

Z

e o) + Pe (y|x)V (y)dy ,
(TV )(x) = max E R(x,
oOx

(12)

defined set options instead primitive actions A. differences
(4) (12) could potentially lead widely different results embedded
FVI algorithm.

3. Options Fitted Value Iteration
Algorithm 1 Options Fitted Value Iteration (OFVI)
Require: Collection options O, SMDP simulator S, state distribution , function
space F, initial iterate V0 F, n number states sample, number
samples obtain state-option pair, K number times iterate
returning
1: k = 1, 2, . . . , K {Generate K iterates V1 , V2 , . . . VK .}
2:
{Collect new batch samples.}
3:
= 1, 2, . . . , n {Sample N states.}
4:
x {Sample state distribution .}
5:
Ox
6:
j = 1, 2, . . .,
, ro ,
7:
yi,j
i,j i,j S(x, o) {Query simulator terminal state, discounted
cumulative reward, duration executing (x, o).}
8:
end
9:
end
10:
end
11:
{Estimate Bellman
Backups.}
h


1 Pm

)
12:
V j=1 ri,j + i,j Vk1 (yi,j
{Find best fitting approximation V .}
14:
Vk = arg inf f F kf V kn
15: end
16: return K {Return greedy policy wrt VK .}
13:

Algorithm 1 generalization multisample FVI algorithm case
samples generated options (with primitive actions special case). algorithm,
Options Fitted Value Iteration (OFVI), takes arguments positive integers n, m, K,
(X), initial value function estimate V0 F, simulator S. iteration
k = 1, 2, . . . , K, states xi = 1, 2, . . . , n sampled, option Oxi ,
, r , S(x , o) sampled
next states, rewards, option execution times hyi,j

i,j i,j
j = 1, 2, . . . , m. update resulting applying Bellman operator
previous iterate Vk1 estimated



1 Xh

Vk (xi ) max
ri,j + i,j Vk1 (yi,j
) ,
(13)
oOxi
j=1

383

fiMann, Mannor, & Precup

apply supervised learning algorithm obtain best fit according (8).
given simulator differs simulator PFVI. returns state option
returned control agent, total cumulative, discounted reward received
execution, duration number timesteps option executed. additional information needed compute (13). Otherwise differences PFVI
OFVI minor natural ask OFVI similar finite-sample convergence
behavior compared PFVI.
3.1 Simple Analysis
Notice PFVI special case OFVI given options contain
primitive action set (i.e., A). Therefore, cannot expect OFVI always outperform
PFVI. Instead, aim show OFVI converge slowly PFVI
identify cases OFVI converges quickly PFVI. following proposition
provides general upper bound loss policy derived OFVI contains
A. bound compared bounds loss policy derived PFVI.
Proposition 1. , > 0 K 1. Fix p 1. Let set options
contains set primitive actions A. Given initial state distribution (X),
sampling distribution (X), V0 B(X, VMAX ), A1(, ) (Assumption 1) holds,
exists positive integers n OFVI executed,




2
1/p
K+1 1/p 2 kV V0 k
Lp, (K )
C bp, (TF, F) + +
(14)
(1 )2 ,
(1 )2
holds probability least 1 .
proof Proposition 1 well sufficient values n given appendix. Proposition 1 suggests long contains A, OFVI performance least
comparable PFVI (if better). two main differences bound
Proposition 1 work Munos Szepesvari (2008, Thm. 2). First, inherent
Bellman error Proposition 1 may larger inherent Bellman error
primitive actions. Second, convergence rate OFVI tracks convergence rate
SMDP Bellman operator rather MDP Bellman operator .
Proposition 1 implies OFVI converges approximately fast PFVI
contains A. However, two algorithms may converge different value functions due
larger inherent Bellman error OFVI.
Proposition 1 two limitations. First considers case contains
A. Second, describe OFVI converges quickly PFVI.
following section, investigate possibilities.
3.2 General Analysis
two perspectives explain applying options AVI decrease
number iterations needed find near-optimal policy.
first perspective, options increase information flow otherwise temporally
disparate states facilitating fast propagation value throughout state-space. example, takes many primitive actions transition state x state y, planning
384

fiApproximate Value Iteration Temporally Extended Actions

primitive actions require many iterations information propagated
back x. However, given option initialized state x, terminates
y, value propagated back x every iteration.
second perspective, options long duration cause rapid contraction toward optimal near-optimal value function. discounted average reward
objectives, proof VI converges based contraction argument (for details,
see Puterman, 1994). turns options long duration induce faster
contraction primitive actions (or faster options shorter durations).
options influence convergence rate AVI depends critically agents
objective. paper, analyze discounted reward objective. However, put
results context, section, comment finite horizon average
reward objectives well.
Undiscounted, Finite Horizon: agent maximizes sum rewards received
H 1 timesteps. options short circuit number iterations needed
propagate reward back H steps. effect naturally described increasing
information flow temporally disparate states.
Discounted Reward (our analysis): analysis uses contraction argument
show faster convergence information flow argument show fast contraction occur even temporally extended actions sparsely distributed
state-space.
Average Reward: agent maximizes average infinite sequence rewards. consider discounted reward setting, similar contraction
arguments could provably applied show options produce closer approximation optimal value function fewer iterations.
approach based contraction mapping argument. applying MDP
Bellman operator V B(X, VMAX ), obtain following contraction mapping
kV V k kV V k

(15)

(the discount factor) serves contraction coefficient. Since < 1, left hand
side strictly smaller kV V k . Smaller values imply faster convergence rate,
discount factor part problem description cannot changed. However,
apply MDP Bellman operator , > 1 times, obtain contraction
mapping contraction coefficient < . Temporally extended options
similar effect. Options speed convergence rate SMDP Bellman operator
inducing smaller contraction coefficient depends number timesteps
option executes for.
Intuitively, options long duration desirable planning options
execute many timesteps enable OFVI look far future single
iteration. However, duration depends option state option
initialized. following definition makes notion options duration precise.

385

fiMann, Mannor, & Precup

Definition 4. Let x X state Ox option. duration executing
option state x number timesteps executes terminating (i.e.,

returning control option policy). denote Dx,Y
random variable representing
duration initializing option state x terminating X.
h set


options O, define minimum duration dmin = min inf X E Dx,Y .
xX,oOx

First notice duration option random variable depends
state option initialized. complicates analysis compared assuming
temporally extended actions terminate fixed number timesteps,
allows much greater flexibility selecting options use planning.
Similar analysis PFVI, analysis OFVI depends concentrability
future state distributions. introduce following assumption future state
distributions MDPs set options. given set options may may
contain entire set primitive actions underlying MDP.
Assumption 2. [A2(, )] [Option-Policy Discounted-Average Concentrability
Future-State Distributions] Given two distributions defined state
space X, 1, m, arbitrary option policies 1 , 2 , . . . , , assume
Pt1 2 ...m absolutely continuous respect implying


(Pt1 2 ...m )

< + ,
ct (m) =
sup
(16)



1 ,2 ,...,m

assume
C, = (1 )

2


X

t1

t=1

max

m{1,2,...,t}

ct (m) < +

(17)

option discounted average concentrability coefficient, Pt1 2 ...m (y) assigns
probability mass according event sequence options terminate
state exactly timesteps initial state sampled sequence
options executed ith option sequence chosen according .
Assumption 2 analogous Assumption 1. Despite fact options
general framework set primitive actions, Assumption 2 results smaller
concentrability coefficient Assumption 1.
Lemma 1. Let , (X). Assumption A1(, ) implies Assumption A2(, ) (i.e.,
C, C, ).
Proof. First notice since timestep sequence actions generated sequence
1 , 2 , . . . , option policies expressed sequence primitive policies
1 , 2 , . . . , . Thus
...m
d(Pt 1 2
)

ct (m) = sup1 ,2 ,...,m







1
2

sup1 ,2 ,...,t d(P Pd ...P )


= c(t) .

386

fiApproximate Value Iteration Temporally Extended Actions

Since ct (m) c(t) 1 m,
P
t1 max
C, = (1 )2
m{1,2,...,t} ct (m)
t=1
P

2
t1
(1 )

c(t)
t=1
= C, .

Lemma 1 implies Assumption 2 holds set options whenever Assumption
1 holds. main reason sequence options executes timesteps
fewer degrees freedom sequence primitive policies. Furthermore, proof
Lemma 1 tells us important property discounted concentrability future
states number options executed sequence number timesteps
sequence options executes for.
analysis convergence rates OFVI, report bounds containing
coefficient C, rather C, . because, cases option set contains
mostly temporally extended actions, C, may smaller C, . However, Lemma 1
tells us replace C, bounds C, purposes comparing
(10) (14).
important properties temporally extended actions cause faster convergence
(1) quality policy follow, (2) long action executes (or
duration). following definition describes set states exists option
follows near-optimal policy sufficient duration.
Definition 5. Let X set states MDP option set O, 0, dmin .
(, d)-omega set defined





,d x X | oOx s.t. inf E Dx,Y Q (x, o) V (x) ,
(18)
X

set states -optimal temporally extended action duration
longer optimal option policy.
states ,d particularly long duration follow -optimal policy. However, states outside ,d not. states, either available options
sufficiently temporally extended follow suboptimal policy. obtain faster
convergence, need way connecting convergence rates states outside ,d
convergence rates states ,d .
Assumption 3. [A3(, d, , , j)] Let , , j 0, dmin , (X). 0
option policies 1 , 2 , . . . , , let = P 1 P 2 . . . P . exists -optimal option
policy either (1) Prx [x ,d ] 1 (2) i{1,2,...,j} Pryi [y ,d ]

1 = P 1 P 2 . . . P P = 1, 2, . . . , j.
Assumption 3 points three key features impact planning performance
options:
1. Quality option set controlled ,
387

fiMann, Mannor, & Precup

2. Duration options specified d,
3. Sparsity ,d state-space characterized j .
refer policy bridge policy, bridges gap
states ,d states. Notice assume planner
knowledge . enough policy exists. Assumption 3 says matter
policies followed, either (1) agent end ,d high probability
(2) exists near-optimal option policy transport agent ,d
j timesteps high probability. enables us account problems
states temporally extended actions, states reached quickly without
following policy suboptimal.
following theorem provides comprehensive description convergence behavior
OFVI (with PFVI special case = A).
Theorem 1. Let , > 0, , , j 0, K, p 1, dmin , 0 Z K, , (X).
Suppose A2(, ) (Assumption 2) A3(, d, , , j) (Assumption 3) hold. Given
V0 B(X, VMAX ), first Z iterates {Vk }Z
k=0 produced algorithm pessimistic

(i.e., Vk (x) V (x) x X), exists positive integers n
OFVI executed,
Lp, (K ) Lp, ( ) +

2 dmin 1/p
C (bp, (TF, F) + ) +
(1 )2 ,

1/p
+ dmin (K+1)+(1)(ddmin )bZ/jc


!
2 V V0
(19)
(1 )2

holds probability least 1 optimal option policy respect
given options j = j + 1.
Theorem 1 bounds loss option policy K returned performing K 1
iterations value iteration respect (p, )-norm. distribution thought
initial state distribution. places probability mass regions
state space want policy K best performance. value p 1
generally determined function approximation procedure. p = 1, function
approximation procedure minimizes L1 -norm p = 2, function approximation
procedure minimizes L2 -norm.
right hand side (19) contains four terms.
1. first term bounds abstraction loss, loss optimal
policy primitive actions optimal option policy.
2. second term bounds approximation error, error caused
inability function approximation architecture exactly fit Vk (xi )
iteration shows term due bootstrapping options
dmin
follow -optimal policies gain faster convergence. Notice (1)
2 shrinks
dmin grows. Thus option sets longer minimum duration shrink approximation
error.
388

fiApproximate Value Iteration Temporally Extended Actions

3. third term sample error, controlled number samples
taken iteration.
4. last term controls convergence error. Notice , discount factor,
[0, 1) therefore last term shrinks rapidly exponent grows. OFVI
actually converge sense loss may never go zero, last
term goes zero K . worst case, convergence rate controlled
dmin (K+1) , convergence rate significantly faster Z large
j small.
iterate V : X R pessimistic


yX V (y) V (y) ,
optimal policy defined option set O. Whether iterates pessimistic
(or not) critical impact convergence rate OFVI. understand why, suppose
q Ox option initialized state x X q -optimal


respect (i.e., Q (x, q) V (x) ) long duration (at least timesteps).
V pessimistic, Bellman optimality operator performs update
h

Z

e
e
(TV )(x) = max E R(x, o) + P (y|x)V (y)dy ,
definition (12).
oOx
h
Z
e q) + Peq (y|x)V (y)dy .
E R(x,
update option q.



Since known monotone operator, V (x) (TV )(x). Taken together,
facts imply even option q selected update, (TV )(x)

least close V (x) q selected. allows us prove iterates
pessimistic, convergence rate OFVI rapid (depending d). Unfortunately,
iterates pessimistic, reasoning longer holds convergence may
depend options duration dmin instead.
Z iterations estimate value function pessimistic, OFVI
exploits options duration rather dmin . However, get samples
options states ,d . states outside ,d benefit rapid
convergence states ,d j additional iterations. main reason
take j steps propagate value states ,d back states.
Using Theorem 1 possible consider convergence rates OFVI wide range
planning problems. following subsections, examine special cases Theorem
1. First, consider happens dmin greater 1 ignoring possibility
exploiting options longer duration. Second, consider happens mix
primitive actions temporally extended actions.
3.2.1 Abstraction
important case involves planning temporally extended actions available.
main advantage case guarantee upper bound convergence
389

fiMann, Mannor, & Precup

rate algorithm strictly faster upper bound PFVI. However, solution
OFVI converges may inferior solution converged PFVI best
policy respect given set options poor.
Corollary 1. Let , > 0, K, p, dmin 1, , (X). Given V0 B(X, VMAX ),
A2(, ) (Assumption 2) A3( = 0, dmin , = 0, , j = 0) (Assumption 3) hold,
exist positive integers n OFVI executed
Lp, (K ) Lp, ( ) +

2 dmin 1/p
C bp, (TF, F) +
(1 )2 ,

1/p
+ dmin (K+1)


!
2 V V0
(20)
(1 )2

holds probability least 1 , optimal option policy respect
given options O.
First notice Corollary 1, upper bound respect loss optimal
policy (over primitive actions). bound loss Corollary 1 depends four
terms,
1. first term controlled error optimal policy best
policy respect given options O,
2. second term controlled option policy future state concentrability coefficient C, inherent bellman error bp, (TF, F),
3. third term simply estimation error term (which controlled amount
sampling done OFVI),

4. last term convergence error controlled dmin (K+1) .
dmin > 1 convergence rate OFVI significantly faster PFVI,
loss term Lp, ( ) may large given option set cannot represent sufficiently
good policy.
Although abstraction setting fast convergence rate, quality policies
produced depends best possible option policy derived given set options.
policy poor, policy produced OFVI also poor. next
subsection, try overcome limitation augmenting set primitive actions
instead discarding them.
3.2.2 Augmentation Sparsely Scattered Temporally Extended Actions
Experimental results demonstrated well placed temporally extended actions often improve convergence rate planning (Precup et al., 1998). would like
describe conditions sparsely scattered temporally extended actions cause faster
convergence.
following theorem gives bound OFVI environments sparsely distributed
temporally extended actions.
390

fiApproximate Value Iteration Temporally Extended Actions

Corollary 2. Let , > 0, , 0, K, p, d, j 1, 0 Z K, , (X).
Suppose A2(, ) (Assumption 2) A3(, d, , , j) (Assumption 3) hold. Given
V0 B(X, VMAX ), first Z iterates {Vk }Z
k=0 produced algorithm pessimistic
(i.e., Vk (x) V (x) x X), exist positive integers n
OFVI executed,
Lp, (K )

2
C 1/p (bp, (TF, F) + ) +
(1 )2 ,

1/p 2 kV V k
0
K+1+(1)(d1)bZ/jc
+
(21)
(1 )2

holds probability least 1 j = j + 1.
=
Notice abstraction loss Lp, ( ) disappears special case VM
VM . improvement convergence rate first Z pessimistic iterates
small penalty appears approximation error term due exploitation optimal temporally extended actions. convergence rate Corollary 2 driven
K+1+(1)(d1)bZ/jc K+1 , demonstrating OFVI converge faster PFVI.
Notice j large, meaning take timesteps visit ,d ,
convergence rate slower j small. means convergence improvement
may less dramatic temporally extended actions sparse. j = 1,
convergence rate controlled K+1+(1)(d1)Z K+1 .


4. Generating Options via Landmarks
One limitation planning options options typically need designed
expert. section, consider one approach generating options automatically.
approach similar spirit successful FF-Replan algorithm (Yoon, Fern, &
Givan, 2007), plans deterministic projection target MDP. algorithm
replans whenever agent enters state part current plan. However,
unlike FF-Replan, approach scalable plan globally entire
system.
specifically, assume access simulator SM target MDP =
c
b
hX, A, P, R, simulator SM
c relaxed MDP = hX, A, P , R, deterministic transition dynamics. Given state x option Ox , simulator returns
discounted cumulative reward R executing option, duration options
execution , termination state y.
c deterministic transition probabilities, dynamics captured diSince
rected graph G = hX, Pbi. Furthermore, R specifies reward associated edge.
two actions transition state x state y, maximum reward
actions associated edge (x, y) G. denote maximum reward path
x X g X pG (x, g) length maximum reward path |pG (x, g)|.
Throughout section assume rewards non-positive (i.e. bound
[RMAX , 0]). reason stochastic shortest path problems undefined
MDP contains positive reward cycles, however, experiments relax
assumption.
391

fiMann, Mannor, & Precup

^

x

l4

l6
l5

Optimal Trajectory
Optimal Landmark Trajectory
Landmark Trajectory
w/Local Planner

l3

l2

l1
(a)

l4


x

l2

l7

g
l8

l5

l6

l7

g
l8

Optimal Trajectory
Noise-Free Landmark Trajectory
Landmark Trajectory
w/Local Planner

l3

l1
(b)

Figure 1: trajectory state x state g. Error introduced planning policy
landmark options rather following optimal policy. (a) determinc, errors caused landmarks exactly
istic relaxation
optimal trajectory local planner taking maximum reward path
one landmark another. (b) stochastic target problem , errors
introduced noise, causes agent reach states nearby
landmark states path goal.

392

fiApproximate Value Iteration Temporally Extended Actions

c computationally efficient planning algorithms
purpose introducing
known minimum cost path problems (Dijkstra, 1959; Hart, Nilsson, & Raphael,
1968), equivalent maximum reward path planning problems provided
c reasonable approximation ,
positive reward cycles. Thus,
c. assume efficient local
dynamically generate options planning
planner P exists G.
However, large directed graphs, even called efficient algorithms
computationally expensive. Thus, assume P given maximum planning horizon
d+ 1.
Recent work finding minimum cost paths large graphs shown paths
found efficiently introducing landmarks (Sanders & Schultes, 2005),
intuition used robotic control long time (Lazanas & Latombe, 1992).
Definition 6. landmark set L finite, non-empty subset state-space.
landmark single state, landmark set induces directed graph
state-space. Obtaining provably good landmark set generally hard problem (Peleg
& Schaffer, 1989). assume landmark states given, could
c work Simsek Barto (2004)
acquired analyzing dynamics
demonstrations work Konidaris, Kuindersma, Barto, Grupen (2010).
Given set landmarks, define corresponding set options, follows.
Definition 7. Let 0 metric state-space. landmark set L
local planner P, set landmark options, denoted O, contains one option
ol = hIl , l , l landmark state l L,
1. Il = {x X||P(x, l)| d+ } initialization set,
2. l (x) = P(x, l) policy x X,

1 (x, l) x
/ Il
3. l (x) =
defines termination probabilities state
0 otherwise
x X.
c,
words, landmark options result planning deterministic MDP
terminate vicinity landmark reached. landmark ls
option executed states reaching l graph would take less
d+ timesteps. discovered, options executed target MDP .
denote number valid landmark-option pairs L. Note principle,
landmarks might reachable within given planning horizon.
idea plan using set landmark options. achieve this, require
local planner derive path least one landmark state every state
X:
Assumption 4. x X exists l L |P(x, l)| d+ .
deterministic MDP, starting landmark state, possible avoid visiting
non-landmark states (Figure 1a). case, possible ignore states
393

fiMann, Mannor, & Precup

plan entirely based landmark states. However, stochastic MDPs, landmark options
always terminate landmark states. solve problem allowing landmark
options terminate near landmark states (Figure 1b).
Landmark-based options used directly OFVI alternatively used
create new AVI algorithm maintains estimates value function
finite number landmark states therefore avoids explicit function approximation.
section, discuss approaches analyze convergence properties.
4.1 Landmark-Based Approximate Value Iteration
Landmark-based Approximate Value Iteration (LAVI), Algorithm 2, belongs family
AVI algorithms. takes arguments: (1) K number iterations perform, (2)

landmark set L, (3) initial guess V0 value function V states L, (4)
number times sample landmark-option pair updates m, (5)
simulator S. output, algorithm produces value estimates landmark states L.
Algorithm 2 Landmark-based AVI
Require: K, L, V0 , m,
1: k = 1, 2, . . . , K
2:
l L
3:
ol Ol
(j)
4:
(Rl,o , (j) , (j) ) S(l, ol ) j = 1, 2, . . . ,
5:
end
(j)
1 Pm
(j) (V
(j)
6:
Vk (l) max
k1 , )
j=1 Rl,o +
oOl

end
8: end
9: return VK
7:

Unlike basic VI, LAVI scales large infinite MDPs estimates values
landmark states, time avoiding use complicated function
approximation algorithms.
target MDP deterministic dynamics, ensure options
always terminate landmark states. construct backups directly V (y)
L. However, stochastic dynamics, may impossible guarantee
options terminate landmark states. less restrictive requirement assume
options terminate near landmark state high probability. notion closeness
requires metric : X X [0, ). small positive constant
state x X, define
L (x) = {l L | (x, l) < }

(22)

set landmark states closer x X. function

(V, x) =

maxlL (x) V (l) L (x) 6= ,
0
otherwise
394

(23)

fiApproximate Value Iteration Temporally Extended Actions

takes consideration fact options necessarily terminate landmark
states. distance termination state landmark l less ,
plug V (l). Otherwise, assume value 0.
Algorithm 2 returns K th estimate landmark values VK , define
greedy policy LAVI
!
Z
X
K (x) = arg max Rxo +
Pto (y|x)(VK , y)dy .
(24)
oOx

t=1

4.1.1 Analysis
provide theoretical analysis LAVI along two dimensions. (1) bound loss
associated policies returned LAVI compared optimal policy primitive
actions, (2) analyze convergence rate LAVI. save space, proofs
deferred Appendix C.
c. Thus, error introduced stochasticity
deterministic MDPs, =
environment. However, selection landmark states local planner
introduce error.
Definition 8. (Landmark Error) Given landmark set L, smallest L
x X l {l0 L | dbmin |P(x, l0 )| dmax }



|pG (x,l)| V (l) ,

VM
(x)

R
+

(25)
L
pG (x,l)
c
c

optimal value function
c Rp (x,l)
called landmark error V c
G

c.
discounted reward optimal path x l

landmark error quantifies well chosen landmark states preserve maximum
reward paths. Figure 1a, landmark error represented distance
landmarks optimal trajectory. definition assumes local planner
optimal, however, may convenient use suboptimal local planner.
Definition 9. (Local Planning Error) Given local planner P landmark set L,
smallest P x X l L P(x, l) < d+ , path P(x, l) generated
P satisfies





|P(x,l)|
RpG (x,l) + |pG (x,l)| VM
(l)

R
+

V
(l)
P ,
(26)
P(x,l)
c
c

called local planning error.
local planning error quantifies loss due using local planner P instead
planner returns maximum reward path x nearby landmark state.
Figure 1a, local planning error represented trajectory (dashed line)
transitions landmark landmark, follow shortest path
landmarks.
far, considered factors impact planning error environment
deterministic. contains stochastic dynamics, need way bound error
395

fiValue

Mann, Mannor, & Precup




V*
State-Space

Figure 2: Optimal value function one dimensional state space landmarks depicted black circles. gray hourglass shapes around landmarks depict
change slowly around
landmark error. Assumption 5 requires VM
landmarks. value function may change rapidly regions landmarks.

c. stochastic, landmark option may
following policy planned
trouble reaching particular state. Thus, need relax condition
option always terminates landmark state.
Assumption 5. (Locally Lipschitz around Landmarks) given metric
(l) V (x)(x, l)
state-space X l L x X, (x, l) < , VM

0.
change dramatically
Assumption 5 says optimal value function VM
states close landmark states. assumption violated, options terminating arbitrarily close landmark state may unboundedly lower value respect
. would lead unboundedly suboptimal landmark policies. Thus, Assumption 5
VM
critical obtain meaningful bounds quality landmark policies. Notice, however,
Assumption 5 applies near landmarks. Figure 2 depicts value function
change rapidly regions
one-dimensional state-space illustrates fact VM
state-space close landmark.
Assumption 5 allows us treat hypersphere radius around landmark state
one state. However, treating states introduces following
error.

Definition 10. (Local Lipschitz Error) define local Lipschitz error bound
H = .
local Lipschitz error largest possible difference value landmark l value state within -radius hypersphere centered l.
essentially error introduced allowing landmark options terminate state
within distance l.
need define error caused following policy whose options planned
c .


396

fiApproximate Value Iteration Temporally Extended Actions

Definition 11. (Stochastic Plan Failure) Let Assumption 5. stochastic planning failure smallest value
Pr
(R, ,y)SM (x,ol )

[(y, l) > ]

x X ol Ox l landmark associated ol .
stochastic plan failure bounds probability path landmark state
c terminate state far desired landmark state
planned
executed .
c .
also need way characterizing good approximation
turns characterize relationship simple way.
Definition 12. (Relaxation Error) relaxation error





b




R = max VM
VM

V

V
,
0
,


c
c





b optimal option policy
c.
optimal option policy
Surprisingly, relaxation error depends difference optimal
c.
policies primitive actions optimal policies options
c good approximation , even dynamics
policies similar values
noisy.
Finally, sampling error controlled Algorithm 2. Increasing corresponds collecting samples consequently decreases .
Theorem 2. (LAVI Convergence) Let > 0, (0, 1]. exists



1
LK
m=O
ln

(S (1 )2 (1 dmin ))2
probability greater 1 , Algorithm 2 executed K 1 iterations,
greedy policy K derived VK satisfies
!

!
V V0
2(L + P )

(K+1)dmin
L
L1, (K )
+ R + + +
,
(27)
dmin
bmin

1


1



dmin
min
= 1
1 + (1)
(VMAX + (1 )H ) dbmin dmin mindmin

1 min
c , respectively.
imum duration landmark-option pair
proof Theorem 2 appears Appendix C. Surprisingly, Eq. (27) holds
initial state distribution even though LAVI maintains value estimates states L.
Although bound directly comparable bounds derived FVI, many
characteristics bounds found works Farahmand et al. (2010)
Mann Mannor (2014). example, first three terms right hand side
Eq. (27) correspond approximation error, estimation error controlled
level sampling, last term characterizes convergence behavior
397

fiMann, Mannor, & Precup

algorithm. FVI approximation error caused choosing function approximation
architecture rich enough represent estimates value function
iteration. LAVI approximation error caused choosing landmark set
sufficiently rich using planner cannot reliably reach vicinity landmark
states.
first four terms right hand side (27) describe worst case loss
policy derived LAVI K . first term corresponds error associated
choice landmarks using suboptimal local planner. LAVI uses optimal
local planner, , P = 0. second term relaxation error (discussed
below). controlled stochastic plan failure local Lipschitz error H .
both, H small small. addition, longer duration options (i.e.,
larger dmin ) decreases . sample error decreased increasing m.
last term corresponds LAVIs convergence rate one keys LAVIs
speed. convergence rate dmin faster , convergence rate FVI
primitive actions (Munos & Szepesvari, 2008; Mann & Mannor, 2014). minimum
duration dmin controlled minimum time landmark regions. convergence
faster landmarks provide greater mobility throughout state-space.
closer


,

look last term Eq. (27) shows convergence error depends V0 VM
L
max-norm landmark states L. last term represents fact
LAVI needs estimate value function landmark states.
c
relaxation error term R (27) determines good approximation
given set landmark options. One naive bound R terms bound
transition dynamics respect primitive actions




= max P (|s, a) Pb(|s, a)
1

(s,a)SA

k k1 L1 norm, P transition probabilities , Pb state
transitions (degenerate probability distributions mass single next state)
c. difficult show R 2D . However, bound generally extremely

1
c whereas
conservative. R depends loss best option policies
influenced primitive actions states may never visited option
policies.
total number samples used LAVI LKm, L number valid
landmark-option pairs, K number iterations, number landmarkoption samples. hand, number samples used analysis Fitted Value Iteration depends complexity function approximation architecture
(Munos & Szepesvari, 2008). MDPs complex value functions, Pinball
domain (see Section 5.2), complex function approximation schemes necessary get
FVI work. hand, appropriate landmark set, LAVI simply skip
complex regions value function.
Notice executing policy derived output LAVI requires sampling
simulator. number samples needed depends discount factor .
close 1, samples needed ensure policy behaves near-optimally.
However, acceptable cost simulator relatively inexpensive compared
overall cost planning.
398

fiApproximate Value Iteration Temporally Extended Actions

4.2 Landmark-based Options Fitted Value Iteration
also possible consider using landmark-based options OFVI. refer
resulting case algorithm Landmark-based Options Fitted Value Iteration (LOFVI).
Theorem 3. (LOFVI Convergence) Let > 0, (0, 1] set landmark-based
options. assumption A2(, ) (Assumption 2) A3( = 0, = dmin , = 0, , j = 0)
(Assumption 3) hold, exists n m, probability greater
1 , Algorithm 1 executed K 1 iterations, greedy policy K derived VK
satisfies
Lp, (K )

2(L + P )
1 dbmin

!
+ R

+

2 dmin 1/p
C bp, (TF, F) +
(1 )2 ,


+ dmin (K+1)

1/p


!
2 VM
V0
, (28)
(1 )2

c ,
dbmin dmin minimum duration landmark-option pair
respectively.
Theorem 3 comparable Theorem 2 provides (p, )-norm bound rather
(1, )-norm bound. consider case p = 1, compare Theorem 3
Theorem 2. theorems share abstraction loss. Although convergence
rates similar, LAVIs convergence term (Theorem 2) significantly smaller
convergence term OFVI. However, LOFVIs convergence depends explicit representation state-space LAVIs convergence depends values maintained
landmark states.
main advantage LOFVI LAVI potential lower sample complexity
querying policy. Although shown here, easy extend analysis
OFVI produce action-value functions rather value functions. explicit
action-value function querying policy require additional samples.
may important consideration simulator computationally expensive.
4.3 Additional Considerations
One barrier applying landmark-based options need access deterministic
relaxation target MDP local planning. many domains, deterministic model
may already created domain experts. However, relaxation unavailable,
might wonder one could acquired.
One simple strategy obtaining deterministic MDP target MDP simulator
would use frequently sampled next state. Algorithm 3 demonstrates one
possible implementation strategy. algorithm builds deterministic model
H : X R X new state-action pairs requested. takes arguments
target MDP simulator SM state-action pair (x, a), number samples 1,
partial deterministic model H returns 3-tuple containing reward r
terminal state y. Furthermore, Algorithm 3 easily extended continuous state
setting matching states close together. cost Algorithm 3 depends
399

fiMann, Mannor, & Precup

Algorithm 3 DREX (Deterministic RElaXation)
Require: SM , x X, A, N, H : X R X
1: H(x, a) 6= {Model entry (x, a).}
2:
= 1, 2, . . . ,
3:
(ri , , yi ) SM (x, a)
4:
end
P
5:
arg maxi=1,2...,m
j=1 I{yi = yj } {Assign frequent next state.}
P

1
6:
rm
I{y
=

}r
{Average reward next state y.}
i=1
7:
H(x, o) (r, y)
8: end
9: return H(x, o)

cost sampling primitive action times, chosen ensure
highest probability terminal state chosen high probability. approach
makes sense exists probable next state (region) state-action
pair. Nevertheless, may capture wide range real-world domains.
used example deterministic relaxation local planning. Landmark options could implemented using alternative local planning algorithms, example,
UCT (Kocsis & Szepesvari, 2006), Episodic Natural Actor Critic (Peters & Schaal, 2008),
etc. approaches advantage applied directly target
MDP simulator. theoretical guarantees provided deterministic planners easily
adapted black box planners whenever local planning error bounded.
However, focus analysis deterministic local planners brevity clarity.

5. Experiments Results
compared PFVI OFVI three different tasks: (1) optimal replacement problem
(Munos & Szepesvari, 2008), (2) pinball domain (Konidaris & Barto, 2009), (3)
eight commodity inventory management problem (Mann & Mannor, 2014).
theoretical analysis previous sections characterizes convergence rates.
However, also interested trade-off planning effort performance (i.e., cumulative reward) resulting policy. possible compare
time-to-solution, requires setting potentially arbitrary performance threshold. Choosing performance threshold unfairly bias judgment algorithm achieves
best overall performance-time trade-off. measure trade-off introducing
following statistic:
V k (x)
(x, k) = Pk
,
(29)
i=1 ti
x start state used evaluation k refers number iterations
performed algorithm far. = 1, 2, . . . , k value ti time seconds
ith iteration. Higher values desirable imply performance
less time spent planning.
experiments, simulated options simulating individual primitive actions, selected option terminates maximum number timesteps (100
400

fiApproximate Value Iteration Temporally Extended Actions

18
16

k =1

||V Vk||1

14
12

k =2
k =3

10
84

3

2

1

0

1

Deviation x

2

3

4

Figure 3: Optimal Replacement: Expected loss iterates V1 , V2 , V3 OFVI given
primitive actions single option varying quality. Error bars represent
1 standard deviation. Results averaged 20 trials.

experiments) occurs. potentially places options-based planning methods disadvantage. Nevertheless, experiments provide strong evidence options speed
convergence rate planning, leads smaller time-to-solution.
experiments implemented Java executed using OpenJDK 1.7 desktop computer running Ubuntu 12.04 64-bit 8 core Intel Core i7-3370 CPU 3.40GHz
8 gigabytes memory.
5.1 Optimal Replacement Task
optimal replacement problem, compare PFVI OFVI hand crafted
options. Due simplicity task, option generation unnecessary include
task comparison previous work. problem, agent selects one
two actions K R, whether maintain product (action K) maintenance cost c(x)
depends products condition x replace (action R) product new one
fixed cost C. problem easy visualize single dimension,
optimal value function optimal policy derived closed form (Munos &
Szepesvari, 2008) compare PFVI OFVI directly optimal policy.
used parameter values = 0.6, = 0.5, C = 30 c(x) = 4x (identical
used work Munos & Szepesvari, 2008) inverse mean
exponential distribution driving transition dynamics task. Similar work
Munos Szepesvari (2008), used polynomials approximate value function.
results presented used fourth degree polynomials. optimal policy keeps
product point x replaces product state equals exceeds x.
OFVI condition, introduced single option keeps product
point x = x + terminates state equals exceeds x. modifying ,
controlled optimality given option. predicted analysis, adjusting
away 0 (i.e., reducing option quality), resulted slower convergence
401

fiMann, Mannor, & Precup

Time (s) per Iteration

0.006

0.005

0.004

0.003

0.002

0.001

0.000

PFVI

OFVI

Figure 4: Optimal Replacement: Time seconds per iteration PFVI OFVI
optimal replacement task averaged 20 trials.

Optimal Replacement Task

Convergence w/V0 =0

4

6

8

10

2

10

50
40
30
20
10
00

2

||V Vk ||1

PFVI
OFVI

4

6

8

10

4

6

8

10

||V Vk ||

2

||V Vk ||

50
40
30
20
10
00

Convergence w/V0 = 75

50
40
30
20
10
00

PFVI
OFVI

||V Vk ||1

50
40
30
20
10
00

2

4

6

Iteration # (k)

8

(a) Optimistic (V0 > V )

Iteration # (k)

(b) Pessimistic (V0 V )

Figure 5: Optimal Replacement: Convergence rates PFVI OFVI Optimal
Replacement Task. (a) initial value function estimate optimistic,
difference convergence rates PFVI OFVI. (b)
However, value function estimate pessimistic, OFVI converges faster
PFVI. Results averaged 20 trials.

initial value function pessimistic (see Figure 3). optimistic initial value function,
behavior PFVI OFVI almost identical.
402

fiPFVI

Approximate Value Iteration Temporally Extended Actions

20
40

OFVI

0

PFVI

4

6

8

10

20
40
0

OFVI

2

V

20
30
40
50
60
200
30
40
50
60
0

2

V

4

6

k=2

V

2

4

4

6

k=2

40

40

0

2

4

6

8

10

0

20

20

40

40

4

6

8

10

10

0

2

4

6

8

10

8

(a) Optimistic (V0 > V )
20
30
40
50
60
10 200 2 4 6 8 10
30
40
50
60
10
0 2 4 6 8 10

20
30
40
50
60
200
30
40
50
60
0

2

4

6

8

10

2

4

6

8

10

8

0

2

4

2

10

V

2

20

8



6

20

6

k=5

8

k=5

k=10

k=10

(b) Pessimistic (V0 V )
Figure 6: Optimal Replacement: Average iterates Vk (k = 2, 5, 10) PFVI
OFVI (a) optimistic (b) pessimistic initial value functions.
pessimistic value function OFVI converges significantly faster PFVI.

Figure 4 shows OFVI takes slightly longer per iteration PFVI, OFVI
considers primitive temporally extended actions. Figure 5a shows average
convergence rates PFVI OFVI (with = 0), initial value function estimate
optimistic max-norm L1 -norm error. cases value functions
converge almost identical rates predicted analysis. Figure 5b shows average
convergence rates PFVI OFVI, initial value function estimate pessimistic.
pessimistic initial value function, OFVI converges significantly faster PFVI
predicted analysis.
Figure 6 compares average iterates Vk OFVI PFVI k = 2, 5, 10
optimistic (Figure 6a) pessimistic (Figure 6b) initial value function estimates. solid
black line depicts optimal value function V . optimistic initial value function
behavior PFVI OFVI qualitatively identical. However, pessimistic
initial value function, OFVIs second iterate qualitatively similar PFVIs fifth iterate.
pessimistic initial value function estimate, even suboptimal options able
improve convergence rates, though lesser degree = 0.
403

fiMann, Mannor, & Precup

Figure 7: Instance pinball domain used experiments. Black polygons
obstacles. large red circle target, smaller blue circle
controlled ball.

5.2 Pinball
Pinball domain (Konidaris & Barto, 2009) agent applies forces control ball
2-dimensional surface containing polygonal obstacles. agents goal direct
ball goal region. Figure 7 depicts instance Pinball domain used experiments. state-space consists four continuous dimensions (x, y, x, y) corresponding
coordinates (x, y) ball velocity (x, y). Similar work Tamar, Castro, Mannor (2013), added zero-mean Gaussian noise velocities standard
deviation 0.03. discount factor = 0.95.
pinball domain contains five primitive actions: (1) accelerate along X-axis, (2)
decelerate along X-axis, (3) accelerate along Y-axis, (4) decelerate along Y-axis,
(5) leave velocities unchanged. Since unclear create useful hand-coded
options, decided compare PFVI LOFVI LAVI options
generated. experimented randomly placed landmarks landmarks placed
grid. cases, one landmark manually placed goal state. Randomly
placed landmarks uniformly sampled coordinates state-space. Grid
landmarks placed two-dimensional grid X coordinates statespace. landmarks corresponded states ball zero velocity.
sampled landmark fell inside obstacle, new landmark sampled
landmarks corresponded valid states task.
metric used determine distance two states ~x = (x, y, x, y)
~x0 = (x0 , 0 , x0 , 0 ) given
p
p
(~x, ~x0 ) = (x x0 )2 + (y 0 )2 + (x x0 ))2 + (y 0 )2 ,
(30)
404

fiApproximate Value Iteration Temporally Extended Actions

90
15000

Time (s) per Iteration

80

5000

0

5000

20

Iteration #

25

30

35

(a)

)
96
(1

20

96
)

VI

0
15

LA
VI

10

30

I(1

5

40

FV

0

50

LO

15000

60

10

LAVI(196)
LOFVI(196)
PFVI

10000

70

PF

Performance

10000

(b)

Figure 8: Pinball: Comparison planning PFVI, LOFVI, LAVI 196 landmarks (+1 goal) arranged grid Pinball domain. (a) Performance
policies derived iteration PFVI, LOFVI, LAVI. Shaded regions represent 1 standard deviation. (b) Time seconds compute
iteration PFVI, LOFVI, LAVI. Results averaged 20 trials.

, places less emphasis differences velocity differences
coordinates. chose = 0.01 experimentation.
PFVI LOFVI, tried many different function approximation architectures
including Radial Basis Function Networks (RBF), Cerebellar Model Arithmetic Computer
(CMAC), linear regression various features, found experimentation
nearest neighbor approximation fast able capture complexity
value function. LOFVI, used one-nearest neighbor approximation N = 1, 000
states sampled iteration. PFVI, averaged value states within 0.1
radius queried state N = 30, 000 states sampled iteration. Without
30, 000 samples, PFVI either failed solve task produced policy solved
task unreliably. PFVI LOFVI used L = 5 samples state-option pair.
chose settings resulted strongest performance PFVI
LOFVI.
landmark options, experimented different numbers landmarks.
simplicity selected landmarks formed uniform grid pinball domains Xand -coordinates. choosing grid sizes 10 10, 12 12, 14 14, number
landmarks 100, 144, 196, respectively. fewer 100 landmarks performance
LOFVI LAVI degraded significantly. radius hypercube around landmarks
set = 0.03, landmark options available state corresponded
landmarks distance less 0.2 balls current state, approximates local planning horizon d+ . brevity, consider results landmark
options arranged grid. Randomly selected landmarks gave qualitatively similar results
slightly higher variance.
Figure 8a compares performance PFVI, LOFVI, LAVI pinball domain
196 landmarks (+1 landmark goal). six iterations, LOFVI
405

fiMann, Mannor, & Precup

Perf. / Cumulative Time

103

LAVI(196)
LOFVI(196)
PFVI

102

101

100

101

102

0

5

10

15

Iteration #

20

25

30

Figure 9: Pinball: Performance cumulative time seconds received policies
iteration. Higher better. Results averaged 20 trials.

Time-to-Solution (in Minutes)

30

25

20

15

10

5

0

PFVI

LOFVI

LAVI

Figure 10: Pinball: Cumulative time-to-solution minutes PFVI, LOFVI, LAVI
averaged 20 trials. LAVI smallest time-to-solution.

406

fiApproximate Value Iteration Temporally Extended Actions

LAVI able solve task. However, PFVI takes 25 iterations solve
task. Figure 8b compares time per iteration PFVI, LOFVI, LAVI pinball
domain. PFVI highest time per iteration cost. needed use
lot samples per iteration PFVI solve task. Notice LAVI less expensive
LOFVI. due fact LAVI needs sample landmark states,
whereas LOFVI samples larger number states sampled iteration (although
less PFVI).
Figure 9 compares performance cumulative time spent planning. PFVI
poor performance time trade-off iteration takes time LOFVI
LAVI, takes many iterations achieve high performance. LOFVI LAVI
achieve similar performance, LAVI higher score due fact spends less
time planning per iteration. Figure 10 compares time minutes PFVI, LOFVI,
LAVI produce policy achieves performance greater 8,000. PFVI takes
longer LOFVI LAVI, converges slowly uses expensive function
approximation step iteration. Despite fact LOFVI LAVI use
landmark options, LAVI faster LOFVI, LAVI approximates
value function around landmark states.
5.3 Inventory Management Task
basic inventory management task, objective maintain stock one
commodities meet customer demand time minimizing ordering costs
storage costs (Scarf, 1959; Sethi & Cheng, 1997). time period, agent
given opportunity order shipments commodities resupply warehouse.
created inventory management problem agent restocks warehouse
n = 8 different commodities (Mann, 2014). warehouse limited storage (500
units experiments). Demand commodity stochastic depends
time year. Orders placed twice month total 24 order periods per
demand cycle.
state h, xi inventory management problem vector specifying time
year vector x specifying quantity commodity (denoted xi ith
commodity) stored warehouse. timestep, demand vector drawn
sampling demand commodity independently normal distribution
mean depended time year (see Table 1 parameters used experiments).
demand vector subtracted quantity commodity stored
warehouse. commodities negative subtracting demand vector,
agent receives unmet demand penalty

P
Pn
ub + us ni=1 [xi ]
i=1 [xi ] < 0 ,
pud (x ) =
(31)
0
otherwise ,
ub = 2 represents base
unmet demand cost, us = 10 represents per unit
x x < 0
unmet demand cost, [x] =
.
0 otherwise
demand subtracted, agent given opportunity either resupply
warehouse order nothing. set possible primitive actions n501 = 8501 . Searching
set would intractable. Therefore, designed smaller set primitive actions.
407

fiMann, Mannor, & Precup

Table 1: Commodity Properties
Commodity Index
1
2
3
4
5
Unit Cost (os,i )
1
3
1
2 0.5
Demand Peak (Month)
1
3
7 10 8.5
Demand Std. Deviation
2
1
2
3
2
Max. Expected Demand 16 10 20 4 10

6
1
12
2
9

7
1
1
1
20

8
1
5.5
2
16

primitive actions available agent ability order nothing order
single commodity quantities 25 maximum size warehouse.
resulted (8 (500/25)) + 1 = 161 primitive actions. action = hi, qi defined
commodity index quantity q. cost order defined

0
q = 0 ,
poc (i, q) =
(32)
ob + os,i q otherwise ,
ob = 8 base ordering cost os,i (see Table 1) commodity dependent
unit cost. new state steps forward half month future quantities
inventory updated remove purchased commodities add ordered
commodities (if any). agent orders fit inventory,
portion order fits warehouse kept (but agent charged
complete order). end decision step, agent receives negative
reward (i.e., cost)
R(x, a) = (pud (x ) + poc (i, q)) ,
(33)
negative sum unmet demands order costs depending
inventory levels x, demand , action = hi, qi. storage
cost, limit inventory forces agent make careful decision
commodities order. discount factor = 0.9.
high dimensionality state space (1 dimension commodity 1 dimension time) required function approximation architecture good generalizability.
tried many different function approximation architectures settling Radial Basis Function networks (RBFs) grid 1-dimensional radial bases. limiting
dimensionality radial bases able achieve good generalization performance
samples. divided state space 24 time periods, value function approximation implemented 24 RBFs. number bases per dimension
25 basis widths controlled = 0.1. Throughout experiments
sampled n = 1000 states iteration sampled option = 20 times.
5.3.1 Hand-crafted Options
difficult design good policy problem hand. Inventory management
received lot attention operations research community. One main
findings optimal strategy large class inventory management problems
belong simple family policies called (s, S)-policies (Scarf, 1959). problem
stationary demand distribution single commodity, (s, S)-policy orders enough
stock bring inventory level whenever inventory level falls
408

fiApproximate Value Iteration Temporally Extended Actions

Inventory Management Task
8000

0

LOFVI(100)
OFVI
PFVI

7000

1000

6000

2000

Value

Value

5000
4000
3000

3000
4000

2000

5000

1000

6000

0

7000

1000

0

5

10

Iteration #

15

8000

20

(a) Optimistic (V0 > V )

LOFVI(100)
OFVI
PFVI

0

5

10

Iteration #

15

20

(b) Pessimistic (V0 V )

Figure 11: Inventory Management: Average value iterates produced LOFVI, OFVI
PFVI. Results averaged 20 trials. Shaded regions represent 1
standard deviation.

orders new stock otherwise. inventory management task Markov demand,
(s, S)-policies optimal demand state (Sethi & Cheng, 1997).
problem described cleanly fit Markov demand setting,
notion (s, S)-policies provides potential idea temporally extended action.
Since high base order cost (Eq. (32) ob = 8) storage free, reasonable
policy prefer make large orders whenever possible maximize number
timesteps nothing ordered. One way encode prior knowledge provide
temporally extended actions follow policy order nothing threshold
met. addition primitive actions, provided OFVI 20 temporally extended
actions commodity. policy followed temporally extended actions
order nothing terminate inventory level particular commodity fell
constant level (one 20 levels spanning 0 maximum storage
warehouse).
Since know optimal value function problem, cannot compare
iterates PFVI, OFVI, LOFVI ground truth. However, still examine
iterates. Figure 11a shows average iterates produced PFVI, OFVI, LOFVI
optimistic V0 . case, see PFVI, OFVI, LOFVI appear
decrease similar rates. Figure 11b shows average iterates produced PFVI, OFVI,
LOFVI pessimistic V0 . see OFVI LOFVI increase values
(toward V ) quickly PFVI. LOFVI appears converge different solution
PFVI OFVI, probably due fact landmark options used
experiment may powerful actions available PFVI OFVI. Note
comparison value function produced LAVI straightforward
produce approximation states (only landmark states).
409

fiMann, Mannor, & Precup

7000

7000

6000

6000

Discounted
Cumulative Reward

Discounted
Cumulative Reward

Inventory Management Task

5000

4000

3000

LOFVI(100)
LAVI(100)
OFVI
PFVI
1-Step Greedy
Rand

2000

1000

0

5

10

Iteration #

15

5000

4000

3000

LOFVI(100)
LAVI(100)
OFVI
PFVI
1-Step Greedy
Rand

2000

1000

20

0

(a) Optimistic (V0 > V )

5

10

Iteration #

15

20

(b) Pessimistic (V0 V )

Figure 12: Inventory Management: Performance policies iteration LAVI,
LOFVI, OFVI PFVI starting state inventory. LAVI settles near-optimal policy single iteration. Results averaged
20 trials. Shaded regions represent 1 standard deviation.

considered performance policies derived iterates PFVI OFVI.
V0 initialized pessimistically, Figure 12b shows OFVI quickly converges
better policy PFVI. takes PFVI several iterations equally successful
policy found. compared policies policy selected uniformly random
available primitive actions (denoted Random) policy selects action
immediate lowest cost (denoted 1-Step Greedy). initial state set
beginning year zero inventory. case V0 optimistically
initialized, Figure 12 shows performance PFVI OFVI quickly improve beyond
Random 1-Step Greedy policies, performance similar iterate.
5.3.2 Landmark-Based Options
LAVI, set = 20 (where controls number samples per state-option pair)
experimentation showed value works reasonably well. Since state-space
problem large use generic graph-based planner, constructed heuristic
local planner used deterministic instance problem transition close
possible landmark states. Given definition inventory management task,
easy define deterministic model replacing samples Gaussian distributions
expectation distributions. Given landmark l, current state
lower l ith commodity, would order amount needed reach ith
commoditys quantity l plus expected demand ith commodity. current
state higher l ith commodity, would place order commodity.
Notice local planner efficient able make use entire set primitive
actions. used Euclidean distance set = 0.05 500 500 maximum
410

fi30

6000

25

VI

0

FV



PF

00
)2
(1

LO

LA
VI

LA
VI

(1

)2

00
)

0

)1
00

I(1
00

FV

LO

FV
I(1

LO



FV
I2

0

VI
2

FV


PF


R

1

0
0

0

I1

5



1000

(a)

)

10

00

2000

15

LA
VI
(1

3000

20

00
)

4000

I(1

5000

FV


Time (s) per Iteration

7000

PF
VI
1

Performance

Approximate Value Iteration Temporally Extended Actions

(b)

Figure 13: Inventory Management: (a) Comparison performance first last
policies derived PFVI, OFVI, LAVI. (b) Comparison time per iteration seconds. Results averaged 20 trials. Error bars represent 1
standard deviation.

Perf. / Cumulative Time

104

LAVI(100)
LOFVI(100)
OFVI
PFVI
103

102

101

0

5

10

Iteration #

15

20

Figure 14: Inventory Management: Comparison performance cumulative time
seconds (higher better). LAVI achieves higher performance time invested
even compared LOFVI also uses landmark options. Results averaged 20 trials.

inventory level d+ = . reason set d+ = successfully managing
inventory requires making large jumps state-space (e.g., going 0 inventory
maximum inventory levels) single timestep.
Figure 13a compares performance policy selects primitive actions uniformly
random policies derived first last iterates PFVI, OFVI, LOFVI,
411

fiMann, Mannor, & Precup

Time-to-Solution (s)

100

80

60

40

20

)
00
(1

I(1
FV
LO

LA
VI

00
)


FV


PF

VI

0

Figure 15: Cumulative time-to-solution (with performance threshold 5,500) averaged
10 independent trials PFVI, OFVI, LOFVI 100 landmarks, LAVI
100 landmarks. LAVI smallest time-to-solution.

LAVI. task, LAVI outperforms PFVI OFVI first iteration,
LOFVI ultimately higher performance. Figure 13b compares time per iteration
seconds PFVI, OFVI, LOFVI, LAVI. task, LAVI significantly faster
PFVI, OFVI, LOFVI. Figure 14 shows LAVI achieves better performance-time
trade-off iterations.
Figure 15 shows cumulative time seconds derive policy achieves performance 5,500 averaged 10 independent trials. OFVI, uses mixture
options primitive actions, slightly faster time-to-solution PFVI, despite
evaluate primitive temporally extended actions iteration. Thus,
OFVIs faster time-to-solution due faster convergence rate. LOFVI LAVI
smaller time-to-solution PFVI OFVI. Although approximately
number primitive actions landmark options initialized
state, LOFVI LAVI faster PFVI converge faster. Finally, LAVI
faster LOFVI uses computationally efficient estimate value function
based landmark states, whereas LOFVI (1) uses potentially expensive
function approximation architecture (2) make explicit use landmark
state locations.
5.4 Experimental Domains versus Theoretical Assumptions
useful exercise consider theoretical assumptions map onto experimental
domains.
First, consider concentrability coefficient (Assumptions 1 2). Unfortunately,
cannot estimate concentrability coefficients domains depend
supremum norm sequences policies. However, concentrability coefficients
412

fiApproximate Value Iteration Temporally Extended Actions

generally smaller stochastic domains, every policy broad future state
distribution (meaning long-term value state depends little bit lots
states). Along line reasoning, expect optimal replacement
inventory management problems might smaller concentrability coefficients
pinball domain. Consistent hypothesis, found algorithms
much sensitive sampling distribution pinball domain two
domains.
addition, Lemma 1 suggests options concentrability coefficient always
less (or equal to) concentrability coefficient primitive actions. also supported experiments pinball domain, PFVI much sensitive
sampling distribution LOFVI LAVI.
Second, let us consider Assumption 3 respect experimental domains. Assumption 3 deals sparseness options state-space. Informally, says
nearly-optimal temporally extended actions abundant state-space.
landmark options, holds true pinball inventory management domains
definition, result LAVI LOFVI achieve fast convergence. hand-crafted
options optimal replacement inventory management domains, hand,
may terminate immediately states long duration others. may
account landmark-based options resulted faster convergence experiments.
consider assumptions definitions analysis LAVI.
locally Lipschitz assumption probably holds inventory management domain
high stochasticity generally smooths value function. pinball domain,
regions state-space probably Lipschitz due complex obstacles.
Two states opposite side obstacle relatively close extremely
different values. However, LAVI needs locally Lipschitz assumption hold around
landmark states. Since majority state-space pinball domain probably
smooth, local Lipschitz assumption likely holds landmark configurations
experiments.
Landmark error decreases add landmark states. pinball inventory management domains task could solved landmarks. However,
surprised pinball inventory management domains 100 landmarks needed learn reasonable solutions. Furthermore, pinball domain,
landmark states chosen large effect performance. Thus gridbased layout landmarks produced slightly better policies uniformly sampled
landmark states. suggests landmark error could made small experimental domains small number landmarks.
Local planning error error due using imperfect deterministic planner.
inventory management task, local planning error 0, able
use deterministic model specify order get landmark state.
pinball domain, local planning error may large used greedy algorithm
select actions move agent straight line toward landmark. local
planner fail ball needs pushed around corner, worked well
experiments. suggests local planning error may small average.
Stochastic plan failure occurs noise environment prevents landmark option
terminating sufficiently close designated landmark state. analysis
413

fiMann, Mannor, & Precup

LAVI, even small probability stochastic plan failure caused large increase
approximation error. due possibility failing reach landmark may leave
agent non-recoverable state. However, pinball (Konidaris & Barto, 2009)
inventory management (Mann & Mannor, 2014) domains, agent eventually recover
mistake. stochastic plan failure generally much smaller consequence
predicted (27).
relaxation error quantifies much worse best landmark option policy
target MDP deterministic relaxation. Despite fact pinball
domain inventory management domain significant stochasticity, LAVI
LOFVI able derive good policies. Unfortunately, clear measure
relaxation error.

6. Discussion
proposed analyzed Options Fitted Value Iteration Landmark-based Approximate Value Iteration. algorithms longer temporally extended actions result
faster convergence smaller approximation error. OFVI, analysis shows
value function estimate pessimistic respect optimal value function,
convergence rate OFVI take advantage temporally extended actions
smaller effective discount factor options minimum duration. Furthermore,
options improve convergence even suboptimal spread throughout
environment. fact, LAVI LOFVI converge faster landmark-based options
spread environment.
Approximate Modified Policy Iteration (Scherrer, Ghavamzadeh, Gabillon, & Geist,
2012) related planning options sense modified policy iteration performs
backups d-step rollouts (rather 1-step rollouts) greedy policy. However,
planning options flexible options termination conditions
depend state time. Furthermore, analysis work Scherrer et al.
(2012) point improvement convergence rates increasing length
rollouts used perform backups.
Special representations factorization tasks state action spaces
exploited achieve faster planning (Hoey, St-Aubin, Hu, & Boutilier, 1999; Barry,
Kaelbling, & Lozano-Prez, 2011). However, many problems simulator already exists
simulators convenient way represent task. fact, work Dietterich,
Taleghan, Crowley (2013) presents example simulator representing
task computationally efficient, exact inference factored representation
task computationally intractable. Therefore, ability plan black box simulators
generally applicable requiring problem special representation.
focus planning black box simulator.
Option discovery investigated extensively, many approaches explore heuristics related finding useful subgoals (McGovern & Barto, 2001; Simsek & Barto, 2004;
Stolle & Precup, 2002; Wolfe & Barto, 2005), similar spirit finding landmarks.
approaches, however, emphasis finding useful subgoals.
analysis provides instead way use arbitrary set landmarks, quantify
quality obtained policy. less careful approach selecting landmarks,
414

fiApproximate Value Iteration Temporally Extended Actions

use local planning deterministic problem, scalability LAVI
significantly better, especially high-dimensional problems.
Given collection policies, works Comanici Precup (2010) Mankowitz,
Mann, Mannor (2014) investigated creating useful options applying option
interruption. methods rely given collection policies.
make use deterministic local planner instead, gives LAVI LOFVI
flexibility since restricted predefined policies.
clarity, focused learning good approximation optimal value
function showed resulting greedy policy bounded loss. However,
practice cannot directly obtain greedy policy value function. must
approximated samples. However, results easily extended handle
arguments used prove Thm. 3 work Munos & Szepesvari, 2008
approximating action-value function (Farahmand, Ghavamzadeh, Szepesvari, &
Mannor, 2008).
brevity generality, presented analysis convergence behavior
AVI algorithms (not computational complexity). possible using bounds
Theorem 1 Theorem 2 obtain bounds computational complexity. However,
two critical decisions needed determine computational complexity. first
computational complexity sampling options. example, smart grid simulator
Gridlab-d efficiently simulate actions multiple timescales (Chassin et al., 2014).
hand, simulators may require sampling outcome sequence
primitive actions. second decision involves choice function approximation,
vary widely.
Planning options important setting options natural model
settings decisions made irregular time intervals. Furthermore, algorithms
plan options potentially make use many algorithms proposed learning options data (Iba, 1989; Mannor et al., 2004). However, algorithms produce
good options planning open question, since majority previous research
considered generating options exploration. analysis landmark-based options
helps address question landmark-options similar spirit many existing techniques option generation, skill chaining (Konidaris & Barto, 2009)
bottleneck discovery (McGovern & Barto, 2001; Simsek & Barto, 2004).
Options may benefits planning besides improving convergence rate
(and thus overall speed planning). example, options may enable planning
algorithm skip regions state space highly complex dynamics without
impacting quality planned policy. particular, LAVI models value
function around landmark states, allows perform well tasks
value function highly nonlinear (such Pinball domain Section 5.2). partially
observable environments, options may exploited decrease uncertainty hidden
state skipping regions state space large observation variance,
testing hypotheses hidden state. Options may also play important role
robust optimization, dynamics temporally extended actions known
greater certainty dynamics primitive actions. fact, macro-actions
already used planning partially observable environments success (He,
415

fiMann, Mannor, & Precup

Brunskill, & Roy, 2011). However, results consider narrow definition
temporally extended actions excludes closed loop policies options.
focused generalizations value iteration, many algorithms planning benefit options. example, approximate policy iteration
(Lazaric, Ghavamzadeh, & Munos, 2010; Scherrer et al., 2012) may also exploit options
speed convergence. Another interesting family planning algorithms sparse sampling framework, estimates value single state using either breadth-first-like
search (Kearns, Mansour, & Ng, 2002) rollouts (Kocsis & Szepesvari, 2006). Options
may enable sparse sampling algorithms derive higher quality policies smaller
dependence horizon.
option generation, assumed existence efficient local planner. many
applications may much easier create and/or learn efficient local planner
global planner. especially true domains local dynamics tend remain
similar throughout large regions environment (Brunskill, Leffler, Li, Littman, & Roy,
2008).

Acknowledgments
work funded part NSERC Discovery grant program European
Research Council European Unions Seventh Framework Programme (FP/20072013) / ERC Grant Agreement n.306638.

Appendix A. Proof Proposition 1
Proof. (of Proposition 1) proposition follows Theorem 1. see why, consider
Z 0, least one optimal policy defined primitive actions satisfies
Assumption 3 values = 0, = 1, = 0, arbitrary (X), j = 0.
case, Theorem 1 gives us following high probability (> 1 ) bound = 0:
||V V K ||p,


+


1/p
2
C (bp, (TF, F) + ) +
(1)2 ,


1/p
Z
2kV V0 k
(1)d+ + KZ+1
(1)2
1/p 2kV V0 k
1/p
2
K+1

C
b
(TF,
F)
+

+

(1)2 , p,
(1)2

,

replace C, C, since Lemma 1 tells us C, C, .

Appendix B. Proof Theorem 1 Supporting Lemmas
appendix, prove Theorem 1 provide sufficient values arguments n
m, n controls number states sampled iteration controls
number samples simulated state-action pairs.
proof Theorem 1 similar structure Thm. 2 work Munos &
Szepesvari, 2008 several changes due differences options primitive
actions. proof Theorem 1 following structure:
416

fiApproximate Value Iteration Temporally Extended Actions

1. Appendix B.1, derive Lemma 2, bounds number states n
number samples state-option pair necessary achieve
high-probability bound error single iteration AVI. Lemma 2 used
directly proof Theorem 1 supporting lemmas.
2. Appendix B.2, derive Lemma 6, provides pointwise bound loss
policy produced OFVI K 1 iterations. start deriving
upper bound policys pointwise loss based value functions pointwise
error (Lemma 3). use Lemma 3, need bounds value function estimates
pointwise error. derive upper lower bounds pointwise error K
iterations (Lemma 4). Lemma 6 puts Lemmas 3 4 together exploits options
follow near-optimal policy get tighter bound estimate
value function pessimistic. technical reasons, important next part
proof (Appendix B.3) coefficients pointwise bound sum 1.
Therefore, introduce coefficients k k = 0, 1, 2, . . . , K show
indeed sum 1 (Lemma 5).
3. Appendix B.3, convert pointwise bound derived Appendix B.2
Lp -norm bound, well as, deriving convergence behavior OFVI (Lemma 8).
Lemma 7 shows concentrability assumption (Assumption 2) allows us
replace error according future state distribution error according
sampling distribution. use Lemma 7, well as, Assumption 3 prove
Lemma 8.
4. Appendix B.4 proves Theorem 1. proof uses Lemma 2 select number
samples needed ensure error K 1 iterations low high
probability. apply Lemma 8 bound error K iterations.
moving onto proofs, first introduce additional notation. contrast
discounted termination state probability density Pe, denote undiscounted
probability option executed state x X terminate subset
states X

X

P (Y |x) =
Pto (Y |x) .
(34)
t=dmin

R
R
Notice (34) undiscounted Peo (y|x)dy < P (y|x)dy = 1. option
policy : X O, denote Pe discounted termination state probability distribution executing state (executing option termination)
undiscounted termination state probability distribution P analogously. Notice
option policy, also

X
P (Y |x) =
Pt (Y |x)
(35)
t=dmin

X x X.
417

fiMann, Mannor, & Precup

Notice f option, option policy, policy primitive actions
write discounted termination state probability density
Pef (Y |x) =


X
t=dmin

Ptf (Y |x)

(36)

X x X. compose options o1 , o2 , . . . om , write Peo1 o2 ...om =
Peo1 Peo2 . . . Peom , write
Peo1 o2 ...om (Y |x) =


X
t=mdmin

(P o1 P o2 . . . P om )t (Y |x)

(37)

X x X.
assume throughout supplementary material refer optimal
policy , policy primitive actions. contains set primitive actions
A, fixed point SMDP Bellman operator MDP Bellman operator


optimal value function V . Thus equivalent .
B.1 Bounding Number Samples
following lemma used Theorem 1 select sufficient values parameters n
ensure per iteration error less > 0 probability least
1 .
Lemma 2. Let
p SMDP option set O, F B(X; VMAX ) bounded function
space 81 4 , p -covering number bounded N , V F, p fixed positive integer,
V 0 result single iteration OFVI derived (13) followed (8).
, > 0,
0

V TV bp, (TV, F) +
p,
holds probability least 1 provided


8VMAX 2p
n > 128
(log(1/) + log(32N ))


(38)



8(RMAX + VMAX )2
(log(1/) + log(8n|O|)) .
(39)
2
proof Lemma 2 follows proof Lemma 1 work Munos &
Szepesvari, 2008 simply replacing MDP Bellman operator SMDP Bellman
operator everywhere occurs, noting must sample |O| options rather
|A| primitive actions. omit proof brevity.
m>

B.2 Bounding Pointwise Propagation Error
interested bounding loss due following policy K derived OFVI
rather following optimal policy . use fact








kV V K kp, V V + V V K
(40)
p,

418

p,

fiApproximate Value Iteration Temporally Extended Actions



triangle inequality focus bounding kV V K kp, , loss due
following policy K produced OFVI instead optimal option policy .
OFVI value-based method, directly improve policy
iteration. Instead performing iterations improves estimate


optimal option




K
policys value function V . Thus, need relate loss V V p, quality
final value function estimate VK produced OFVI algorithm. following


lemma develops pointwise relationship V V K V VK .
Lemma 3. Suppose OFVI executed K iterations iterates Vk k = 0, 1, 2, . . . , K.
Let optimal policy respect given options K greedy option
policy respect K th final iterate VK ,




V V K (I PeK )1 Pe PeK V VK ,
(41)
identity matrix.




Proof. Since TV = V TK V K = V K , get


V V K

=
=
=
=

=
=
=



TV TK V K



TV VK + VK TK V K




Pe V VK + VK TK V K




Pe V VK + VK TVK + TVK TK V K



Pe V VK + TVK TK V K



Pe V VK + TK VK TK V K



Pe V VK + PeK (VK V K )






Pe V VK + PeK VK V + V V K ,


initial equality based fact V fixed point V K


fixed point TK . first step obtained inserting (T VK +T VK ) = 0.


second step pulls discounted transition probability kernel Pe subtracting VK

TV . Since backups performed
policy , immediate reward



terms canceled, leaving Pe V V K . third step inserts (TVK +TVK ) =


0. Since VK TVK , obtain fourth step dropping terms VK TVK ,
vector whose elements less zero. obtain fifth step noticing
since K greedy policy respect VK , TVK = TK VK . sixth step pulls


PeK subtracting TK V K TK VK . seventh step inserts (V +V ) = 0.
manipulate inequality



e V VK + PeK VK V + V V K
V V K P








V V K
Pe PeK V VK + PeK V V K








V V K PeK V V K

Pe PeK V VK








PeK V V K

Pe PeK V VK ,


identity matrix, V V K terms left hand side.
Since (I PeK ) invertible inverse monotone operator, get




V V K (I PeK )1 Pe PeK V VK ,
419

fiMann, Mannor, & Precup





relates (V V K ) (V VK ).
Lemma 3 provides us relationship quality estimates
value function quality resulting policy, need bound quality value
function estimates. iteration k = 1, 2, . . . , K OFVI results error
k = TVk1 Vk ,

(42)

induced fitting process. One main issues proof Theorem 1
determine fitting errors propagate iterations.

following lemma helps bound error V VK developing

pointwise upper lower bounds V VK show error propagates recursively
iteration.
Lemma 4. Suppose optimal policy respect options O, OFVI executed
K iterations iterates Vk k = 0, 1, 2, . . . , K iteration errors k k =
1, 2, . . . , K defined (42), following upper bound
V



VK

K
X


Pe

Kk

k=1

K
k + Pe
(V V0 ) ,

(43)

following lower bound


V V K K +

K1
X
k=1





PeK1 PeK2 . . . Pek k + PeK1 PeK2 . . . Pe0 V V0 .
(44)


Proof. First derive upper bound V VK . equation (42),


V Vk =
=

=



TV TVk1 + k




V Vk1 + Vk1 TVk1 + k


TV Vk1 + k



Pe V Vk1 + k .

recursing inequality, obtain upper bound


V VK

K
X


Pe

Kk

k=1

K
k + Pe
(V V0 ) .



derive lower bound V VK . Let k denote greedy policy
respect Vk . (42),


V Vk =
=

=



TV TVk1 + k



TV Tk1 V + Tk1 V TVk1 + k

Tk1 V TVk1 + k


Pek1 V Vk1 + k .
420

fiApproximate Value Iteration Temporally Extended Actions

recursing inequality, obtain lower bound


V VK K +

K1
X
k=1





PeK1 PeK2 . . . Pek k + PeK1 PeK2 . . . Pe0 V V0 .

Lemma 3 gives relationship quality value function estimates
quality resulting greedy policy, Lemma 4 gives upper lower bounds value
function estimates. next step combine results lemmas derive

pointwise error bound V V K .
make use following definition deriving point-wise error bound.
lambda values used simplify notation, also use fact
carefully designed sum 1.
Definition 13. = 1, 2, . . . , , let
k =

1
(Kk)
1 K+1

(45)

k = 0, 1, . . . , K.
following lemma shows k values sum 1.
P
Lemma 5. values defined (45) satisfy K
k=0 k = 1 .
Proof.
PK

k=0 k

PK
1
(Kk)
=
k=0 1 K+1
P
K
1
k
= 1
K+1
k=0
P
k
= 11K+1 K
k=0 (1 )
= 11K+1 (1 K+1 )
= 1 .


ready derive point-wise error bound V V K .
Lemma 6. Let Z {0, 1, 2, . . . , K}, k greedy policy respect k th iterate
Vk derived OFVI, option policy Q (x, (x)) V (x) x X,
= dmin . A3(, d, , , j) (Assumption 3) true first Z iterates OFVI

pessimistic (i.e., x X k {0, 1, 2, . . . , Z}, V (x) Vk (x)),

difference V value option policy K returned OFVI bounded

X
K
X

V V K
k Pk,t |k | ,
t=1 k=0

k defined (45),

=

2(1 K+1 )
(1 )3
421


,

fiMann, Mannor, & Precup

Pk,t

1,


h


KZ P Zk

P
0kZ

h



Kk
1
=
P
+ (P K1 P K2 . . . P k )t Z < k < K
2



1
k=K

V V0 k = 0
k =
+
1kZ
k
k
Z<kK

.

Proof. place upper bound (43) lower bound (44) relationship

VK V . use information bound difference

V K V . However, lemma, exploit pessimism first Z iterates
option policy achieve informative bound.

iterate Vk pessimistic V Vk lower bounded 0. upper bound,





V Vk = V V + V Vk

+ V Vk

= + V TVk1 + k

= + V Vk1 + Vk1 TVk1 + k

+ V Vk1 + k
Pe (V Vk1 ) + (k + ) ,




initial inequality inserts term (T V + V ) = 0. first step follows
fact following single decision following produces


-optimal policy, V V . second step due definition k
(42). third step inserts (T Vk1 + Vk1 ) = 0. fourth step removes
Vk1 TVk1 sum two terms less equal zero (since
updates using max operator, updates using policy ). fifth final
step pulls discounted transition probability kernel Pe .
recursing inequality Z 0 times obtain

Z=0
V
V0


Zj
Z

PZ
V VZ
. (46)

e
(j + ) + Pe
V V0 1 Z K

j=1 P
combining upper bound recursion (43) (46), obtain terms


Z


KZ


e

P
Pe
V V0 k = 0






Zk
KZ

e
uk k =
P
Pe
(k + ) k = 1, 2, . . . , Z








Kk


Pe
k
k = Z + 1, Z + 2, . . . , K




V VK
422

K
X
k=0

uk k

fiApproximate Value Iteration Temporally Extended Actions



upper bounds difference V final iterate derived OFVI, VK .

Now, since 0 lower bounds difference V first Z iterates OFVI,
use 0 lower bound first Z iterations fill rest iterates
(44). gives us terms

0kZ

h0

PeK1 PeK2 . . . Pek k Z < k < K 1 ,
lk k =


K
K



V VK
lower bounds
difference V
P
VK | K
(u
k=0 k lk )k .
Lemma 3,



K
X

lk k

k=0


final iterate VK . implies |V


P

K
(u

l
)
(I PeK )1 Pe PeK
k k
fi
fi P k=0 k


fi
fi
K
1



(u
+
l
)|
|
(I Pe K ) fiPe Pe K fi
k
k
k=0 k
P

K

1
(I Pe K )
(uk + lk )|k |
k=0

P
P
K

eK )i
(u
+
l
)|
|
=
(
P
k
k
k=0 k
i=0

P PK

i=0
k=0 (uk + lk )|k |

P PK
(u
+
l
)|
|


k
k
k
k=0
i=0
PK
1
(u
+
lk )|k | ,
k=0 k



V V K

first step taken absolute value
fisides inequality,
fi
fi e
fi

min
second step used fact
fiP PeK fi. remainder
proof denote dmin .
k = 0,

=
=

2
2






(u0 + l0 )|0 |
1


1(u0|0 |)

2
1



1
2




Pe

KZ



Pe

Z

Z

|0 |



KZ
Pe
|0 |
Pe

P

2

K P0,t |0 |
(1) K+1t=1
P

2(1
)

1
K P | |
=

0,t 0
t=1 1 K+1
(1)2

P

0 P0,t |0 | .




2
1

t=1

k = 1, 2, . . . , Z,


(uk + lk )|k |
1
423

fiMann, Mannor, & Precup

2
2

=
=


=




1(uk|k |)


Zk
KZ

e
P
Pe
|k |

KZ Zk
2
Pe
Pe
|k |
1
P


2
Kk Pk,t |k |
(1)
t=1



2(1 K+1 ) P
1
Kk P | |

k,t k
(1)2
1 K+1


2
1






P

t=1



1
2

t=1

k Pk,t |k | .

k = Z + 1, Z + 2, . . . , K,

(uk + lk )|k |
1
2
2




1

(uk + lk ) |k |

Kk h
2
1




=
+ Pe K1 Pe K2 . . . Pe k |k |
Pe
1 2

P

2

Kk Pk,t |k |
(1)
t=1



2(1 K+1 ) P
1
Kk P | |
=

k,t k
2
K+1
(1)
1

=



=


P

t=1

t=1

k Pk,t |k | .


plugging
results three inequalities, obtain V V K
P
PK
t=1 k=0 k Pk,t |k |.
B.3 Pointwise Lp -norm Propagation Error
Lemma 6 gives us pointwise bound loss policy K derived OFVI compared
following optimal option policy , common function approximation architectures minimize Lp -norm (not pointwise loss). subsection, derive Lemma
8 transforms pointwise bound Lp -norm bound weighted arbitrary distribution M(X). key transformation based A2(, ) (Assumption 2),
allows us bound pointwise transition probability kernels Pk,t Lemma 6
c() Assumption 2 iteration k {1, 2, . . . , K}. following lemma provides
first step transformation.
Lemma 7. Suppose A2(, ) (Assumption 2) holds,
Pk,t

max

m{1,2,...,i+t}

ct (m) ,

, (X).
Proof. two cases consider (case 1) 1 k Z (case 2) Z < k K.
424

(47)

fiApproximate Value Iteration Temporally Extended Actions

case 1,
Pk,t =

h



P

KZ

(P )Zk

ct (K k) .




case 2,
h

Kk
Pk,t = 21 P
+ (P K1 P K2 . . . P k )t
h

Kk
+ (P K1 P K2 . . . P k )t
= 12 P
12 [ct (K k) + ct (K k)]
= ct (K k) .
derive Lp -norm bound, need following additional notation represent
set options initialized state x X duration longer
1.
Definition 14. Let 1, x X state, set options. set Ox,d
denotes
h subset
options initialized state x,

inf X E Dx,Y d.
Notice assumption Ox,dmin Ox .
Lemma 8. Let K 1, > 0, Z {0, 1, 2, . . . , K}. Suppose Assumption 2
Assumption 3 true first Z iterates OFVI pessimistic,
!

1/p 2 V V0

2

kV V K kp,
C1/p (+)+ dmin (K+1)+(1)(ddmin )bZ/jc
(1 )2 ,
(1 )2
(48)
holds, provided approximation errors k satisfy kk kp, k = 1, 2, . . . , K.
Proof. First note

(x) =


arg maxoOx,d Q (x, o) x ,d
(x)
otherwise

.



policy Q (x, (x)) V (x) x X. Therefore, Lemma 6,

X
K
X

V V K
k Pk,t |k | .
t=1 k=0

Now,


V V K p
p,

fi
fip
(x) fiV (x) V K (x)fi dx
K
p
R
P P

(x)
k Pk,t |k |(x) dx
t=1 k=0


p
P
K
R
P

p

(x)
k Pk,t |k + | + 0 P0,t |V V0 | (x) dx ,
=

R

t=1 k=1

425

fiMann, Mannor, & Precup



initial equality due definition kkp, . first step replaces V V K
P PK

t=1
k=0 k Pk,t |k |. last step pulls k = 0 sum moves outside
integral.
K
P
Recall Lemma 5
k = 1. apply Jensens inequality twice;
k=0

convex function | |p parameters P
k k = 0, 1, . . . , K, parameters
determined stochastic operators
t=1 Pk,t , obtain
#
Z "X
X
K

p



k Pk,t |k + |p + 0 P0,t |V V0 |p (x)dx .
V V K p
p,

t=1 k=1





Noticing |V V0 | bounded kV V0 k , obtain



P PK
p
p
V V K p

t=1
k=1 k Pk,t |k + | +
p,

R

(x)0 P0,t kV V0 kp dx .
Assumption 2 Lemma 7,
Pk,t

max

m{1,2,...,Kk+t0 1}

cKk+t0 1 (m) ,

t0 = (K k) + 1. Thus
K P

P
k=1 t=1

k Pk,t |k + |p

K P

P
k=1

t0 =1

1
Kk
1 K+1

max

m{1,2,...,Kk+t0 1}




K P
P

k=1 t0 =1



0 1

0
1
Kk 1
(1 K+1 )

max

m{1,2,...,Kk+t0 1}



(1)2
1 K+1

K P

P

k=1 t0 =0

max

m{1,2,...,k+t0 }




cKk+t0 1 (m)kk + kpp,

cKk+t0 1 (m)kk + kpp,
0

k+t

ck+t0 (m)kk + kpp,


P
1
(1 )2
t1 maxm{1,2,...,t} ct (m)kk
1 K+1
t=1
1
C ( + )p ,
1 K+1 ,

+ kpp,

C, SMDP discounted average concentrability coefficient Assumption 2.
P PK
p
replacing
t=1
k=1 k Pk,t |k + | , get

p


2(1 K+1 )
1
V V K p
C ( + )p +

(1)2
1 K+1 ,
p,

(49)
P R

p

(x)
P
kV

V
k
dx
.

0
0,t
0
t=1
426

fiApproximate Value Iteration Temporally Extended Actions

Consider second term last step (49). replacing P0,t definition,
get




Z
R
R
P
P
KZ
(1)
K


(x)
0 P0,t dx =
(x)

dx
(P )
P
1 K+1
K+t1
t=1
t=1




Z
R
P
KZ
(1)
K
t1


=
(x)

(P )
dx
P
t1 (1 K+1 )
K+t1
t=1




Z

(1)2 R
1
(x) (Pe )KZ Pe
dx
K+1


(1)2 dmin K+(1)(ddmin )bZ/jc

1 K+1

,

(50)
initial equality due expanding P0,t definition. first step simplifies

KZ
drops dependence (1 )(I PeK )1 1. final step replaces PeK
Z
Z

(KZ)

(1)dbZ/
jc+d
Z
e
min
min

P

. case, Pe
dmin K .
Assumption 3 probability (1 ) either (a) state transitioned ,d ,
case effective discount factor , (b) following bridge policy
current state reaches state ,d j timesteps. timesteps
agent ,d effective discount factor dmin , probability (1)
Z
happen Z bZ/jc times during. Thus Pe
(1+)dmin Z+(1)(ddmin )bZ/jc
dmin K+(1)(ddmin )bZ/jc .
replacing second term (49) (50), get
p



2(1 K+1 )
1
V V K p
C ( + )p +

(1)2
1 K+1 ,
p,

(1)2 dmin K+(1)(ddmin )bZ/jc

kV
1 K+1

Since 1 K+1


V V K p
p,

p



1
1 K+1





p h

2
(1)2



V0 kp


.

1,


C, ( + )p + (1 )2 dmin K+(1)(ddmin )bZ/jc kV V0 kp

Thus,


V V K
p,



1/p
2
C (
(1)2 ,


1/p


2kV V0 k
+ ) + dmin (K+1)+(1)(ddmin )bZ/jc
.
2
(1)

B.4 Proof Theorem 1
Proof. (of Theorem 1) use Lemma 2 select appropriate values n m,
1/p
0 = (1 )2 /(2C, ) 0 K .
Since iterates V1 , V2 , . . . , VK random objects, cannot directly apply Lemma
2 bound error iteration. However, problem resolved proof
427



.

fiMann, Mannor, & Precup

Thm. 2 work Munos & Szepesvari, 2008 using fact algorithm
collects independent samples iteration.
iterate Vk+1 depends random variable Vk random samples Sk containing n |O| next states, rewards, trajectory lengths. Let function


f (Sk , Vk ) = kVk+1 (Vk , Sk ) TVk kp, dp, (TVk , F) + 0 (1 0 ) ,
written Vk+1 (Vk , Sk ) emphasize Vk+1 dependence random variables Vk Sk . Notice Vk Sk independent Sk used
generate Vk simulator generates independent samples. Vk Sk independent random variables, apply Lemma 5 work Munos & Szepesvari,
2008. lemma tells us E [f (Sk , Vk ) | Vk ] 0 provided E [f (Sk , v)] 0
allv F. v F, Lemma 2, choice n m,
P kVk+1 (v, Sk ) Tvkp, dp, (Tv, F) + 0 1 0 . implies E [f (Sk , v)] 0.
Lemma 5 work Munos & Szepesvari, 2008,
E [f (Sk , Vk ) | Vk ] 0.
0
Thus P kVk+1 (Vk , Sk ) TVk kp, dp, (Tv, F) + 1 0 . union
bound, ensures kkp, K iterations probability least 1 K 0 =
1 K(/K) = 1 .
result follows applying Lemma 8 kk kp, dp, (TVk , F) + 0 .
kV V K kp,





V V p, + V V K p,
1/p

2
0
Lp, ( ) + (1)
2 C, (bp, (TF, F) + + )

1/p


2kV V0 k
+ dmin (K+1)+(1)(ddmin )bZ/jc
2
(1)


1/p
2
2 /(2C1/p )
C
b
(TF,
F)
+

+
(1

)
= Lp, ( ) + (1)
,
,
p,
2


1/p


2kV V0 k
+ dmin (K+1)+(1)(ddmin )bZ/jc
(1)2
1/p

2
= Lp, ( ) + (1)
2 C, (bp, (TF, F) + ) +

1/p


2kV V0 k
+ dmin (K+1)+(1)(ddmin )bZ/jc
.
(1)2

Appendix C. Proof Theorems 2, 3
appendix, prove Theorems 2, 3. First analyze LAVI proving
Theorem 2. use one lemmas developed analyzing LAVI analyze OFVI
landmark-based options prove Theorem 3. Throughout appendix assume
rewards bound [RMAX , 0], stochastic shortest path problems well
defined.
iteration Algorithm 2 performs operator Tbm defined





1 X e(j)
(j)
b
Tm V (x) = max
Rx,o + (V, (j) )
oOx
j=0

428

(51)

fiApproximate Value Iteration Temporally Extended Actions

Table 2: Errors Impacting Landmark-based VI
Error Name
Landmark Error
Loc. Planning Error
Loc. Lipschitz Error

Symbol
L
P
H

Stoc. Plan Failure



Relaxation Error
Sampling Error

R


Due . . .
selected landmarks
c
Ps sub-optimality
terminate
(y, l) > 0
prob. terminating far
L
increased cost
finite # samples

state x X

(V, y) =

maxlL (y) V (l) L (y) 6=
0
otherwise

.

consider limit Tbm , obtain defined


Z

X
e

(T V ) (x) = max R
Pto (y|x)(V, y)dy
x,o +
oOx

(52)

(53)

t=1 yX

state x X.
However, would like compare Bellman optimality operator defined


Z
X
e

(TV ) (x) = max R
Pto (y|x)V (y)dy ,
(54)
x,o +
oOx

t=1 yX

well known converge optimal value function respect option
set O.
Throughout analysis work vectors dimension |X| mostly
focus |L| elements. vectors V V 0 [VMAX , 0]|X| , define max-norm
respect subset states L X


fi
fi
V V 0 = max fiV (l) V 0 (l)fi ,
(55)
L


measures difference V V 0 states L.
Table 2 provides overview errors contribute sub-optimality
policies derived LAVI.
C.1 Proof Theorem 2
proceed bounding value estimation error, use bound loss
derived policy. Next bound error due using deterministic local planner. Finally,
use results prove Theorem 2.
429

fiMann, Mannor, & Precup

C.1.1 Bounding Value Estimation Error
Lemma 9. (Bound Value Estimation Error Tbm ) Let 1 > 0, (0, 1], K 1,
V [VMAX , 0]|S| , L set landmark states, set landmark options,
optimal policy respect O.


2LK
1
ln
,
(56)
m>
2(1 (1 ))2

landmark-option pairs duration least dmin , Assumption 5 holds,
probability least 1 /K





b



Tm V VM
dmin VMAX + (1 ) + (1 ) V VM
+ 1
L

L

stochastic plan failure, distance threshold, Lipschitz
coefficient Assumption 5. recursing inequality K times, obtain



K
dmin (VMAX + (1 )) + 1




dmin
+
(1

)
V

V
VK VM



0

min
1
L
L

(57)

probability least 1 .
Proof. Notice l L
fi
fi
fi
fi
fi b
(l)fi = fi(T
)(l)fi
fi(Tm V )(l) VM
fi
fi bm V )(l) (TVM
fi
fi
fi

fi b
)(l) + (T V )(l) (TV )(l)fi
= fi(Tm V )(l) (T VM
fi

fi
fi fi
fi



fi b
fi
)(l) + fi(T V )(l) (TV )(l)fi
fi(Tm V )(l) (T VM
fi




(58)



(l) = (TV )(l), first step inserts
initial equality due fact VM





(T VM )(l) + (T VM )(l) = 0,
last
step
uses

triangle
inequality.
fi
fi

fi b
fi
let X denote event fi Tm V (l) (T V ) (l)fi 1 . event X occurs,

first term last step inequality (58)

!
fi
fi
fi
R
fi
P

fi b
fi
)(l)
el,o +
Pto (y|x)(V, y)dy
fi(Tm V )(l) (T VM
fi = fifi max R
oOl
t=1 yX
!fi
R
fi
P

, y)dy fi +
el,o +
max R
Pto (y|x)(VM
1
fi
oOl

max

R
P

oOl t=1 yX

dmin max

t=1 yX

fi
fi
, y)fi dy +
Pto (y|x) fi(V, y) (VM
1

P

R

oOl t=d
min yX

fi
fi
, y)fi dy + ,
Pto (y|x) fi(V, y) (VM
1

last step previous inequality due fact landmark-option
pairs execute least dmin timesteps (meaning effective discount factor
less equal dmin ). choice using Hoeffdings inequality
easily shown event X occurs landmark-option pair probability least
430

fiApproximate Value Iteration Temporally Extended Actions

1 /LK. Since L =

P


|Ol | total landmark-option pairs, using union

bound
P event X holds landmark-options pairs probability
least 1 L
i=1 /LK = 1 L (/LK) = 1 /K.
, y)| = |0 0| = 0. hand,
Now, L (y) = , |(V, y) (VM
L (y) 6= ,
fi
fi
fi
fi
fi
fi
fi(V, y) (V , y)fi = fi max V (l0 ) max V (l0 )fi


fil0 L (y)
fi
l0 L (y) fi
fi
0
0

fi
fi
max V (l ) VM (l )
l0 L (y)




V VM
,
L
fi
fi


fi
)(l)fi dmin (1 ) V V + holds
implies fi(Tbm V )(l) (T VM
fi
1
L
landmarks probability least 1 /K.
second term last step inequality (58)
!
fi
R
fi
fi
fi
P



, y)dy
el,o +
fi(T V )(l) (TV )(l)fi = fi max R
Pto (y|x)(VM


fi oOl
t=1 yX
!fi
R
fi
P

(y)dy fi
el,o +
max R
Pto (y|x)VM
fi
oOl
t=1 yX
R
fi
fi
P
, y) V (y)fi dy
max
Pto (y|x) fi(VM

oOl t=1 yX

dmin max


P

R

oOl t=d
min yX

fi
fi
, y) V (y)fi dy
Pto (y|x) fi(VM


last step previous inequality due fact landmark-option
pairs execute least dmin timesteps.
, y) V (y)| |0 V (y)| V
probability , |(VM
MAX


, y) V (y)| | max 0
(l0 ) V (y)| .
probability 1 |(VM
V
l L (y)

fi
fi


Thus, fi(T V )(l) (TV )(l)fi dmin (VMAX + (1 )).
two terms last step

inequality
(58) obtain result
replacing
V V dmin VMAX + (1 ) + V V +1 probability least
L
L
1 /K.
C.1.2 Bounding Policy Error
Lemma 10. (Bound Policy Error) Let 2 > 0, set landmark options dmin 1
|L|

minimum duration state-options pairs,
MAX , 0] , 0,

V [V


optimal policy respect O. Suppose V VM
L


Z
X
e

(x) = arg max R
Pto (y|x) max (V, y)dy
x,o +
oOx

t=1 yX



greedy policy respect V . Assumption 5 holds,


dmin ((1 ) ( + ) + VMAX )


VM VM
1 dmin

431

(59)

fiMann, Mannor, & Precup

holds.

Proof. Let x X, = (x), = (x). Since (x) = o,

ex,o +
R

Z
X
t=1 yX



ex,o +
Pto (y|x)(V, y)dy R

Z
X

Pto (y|x)(V, y)dy .

(60)

t=1 yX

Let G = {y X | L (y) 6= } G = X\G. set G contains states closer
least one landmark state. rearranging obtain

ex,o R
ex,o
R

R
P
t=1 yX
R
P




Pto (y|x) Pto (y|x) (V, y)dy




Pto (y|x) Pto (y|x) (V, y)dy
t=1 yG

R

+
Pt (y|x) Pto (y|x) (V, y)dy

ex,o R
ex,o
R

ex,o R
ex,o
R
ex,o R
ex,o
R
ex,o R
ex,o
R

yG

P

R

t=1 yG




Pto (y|x) Pto (y|x) max V (l0 )dy


P

R

t=1

yG


P
t=1

l0 L (y)




Pto (y|x) Pto (y|x)







!

max VM (l0 ) + dy
!


R


(y) + + dy
Pt (y|x) Pto (y|x) VM
,
l0 L (y)

yG

initial inequality rearranges (60) isolate reward terms. first step
obtained dividing sum states states L (y) 6= states
L (y) = . third step replaces (V, y) definition. Since (V, y) = 0
L (y) = , second term right hand side disappears. fourth step
(l0 ) + , final step uses Assumption 5 replace V (l0 )
replaces V (l0 ) VM

(y) + .
VM
432

fiApproximate Value Iteration Temporally Extended Actions


R


(y) P (y|x)V (y) dy
(x) V (x) = R
ex,o + P
ex,o R
Pto (y|x)VM
VM



t=1 yX

ex,o R
ex,o
= R


P R
(y) P (y|x)V (y) dy
+
Pt (y|x)VM


+

t=1 yG
R
P

t=1 yG



(y) P (y|x)V (y) dy
Pto (y|x)VM



ex,o R
ex,o
R


P R
(y) P (y|x)V (y) dy
+
Pt (y|x)VM


t=1 yG

+ dmin VMAX
!
R



P




Pt (y|x) Pt (y|x) VM (y) + + dy
t=1 yG
!
R


P





+
Pt (y|x)VM (y) Pt (y|x)VM (y) dy
t=1 yG

+
dmin VMAX
R


P
(y) P (y|x) V (y) + +
Pto (y|x)VM
=


t=1 yG



(y) + + P (y|x)V (y) dy + dmin V

+ Pt (y|x) VM
MAX


!
R

P
(y) V (y) + + dy + dmin V
Pto (y|x) VM
dmin
MAX

t=1 yG



V + + + dmin V
dmin (1 ) VM
MAX .

recursing inequality, obtain




VM VM





dmin ((1 )( + ) + VMAX )
.
1

C.1.3 Bounding Error Deterministic Relaxation
b optimal policy options
c,
Lemma 11. Let


b



V
VM
c
c






2(L + P )
1

holds.
Proof. l L,


b



eP(l,l0 ) + P(l,l0 ) V b (l0 ) .
VM
(l)

V
(l)

V
(l)

max
R
c
c
c
c
0



l

433

fiMann, Mannor, & Precup

definition landmark error,




b


ep (l,l0 ) + |pG (l,l0 )| V (l0 ) max R
eP(l,l0 ) + |P(l,l0 )| V b (l0 ) + L ,
VM
(l)

V
(l)

max
R
c
c
c
c
G
0
0



l Ls

l

definition planning error,




b


eP(l,l0 ) + |P(l,l0 )| V b (l0 ) max R
eP(l,l0 ) + |P(l,l0 )| V (l0 ) +L +P .
VM
(l)V
(l)

max
R
c
c
c
c
0
0



l

l

take max set valid landmark destinations l, get


b
(l) V
eP(l,l0 ) |P(l,l0 )| V (l0 ) + L + P
eP(l,l0 ) + |P(l,l0 )| V b (l0 ) R
(l)

max
R
Vc
c
c
c




l0


0

b
(l0 ) V
0
|P(l,l )| V c
max
c (l ) + L + P .
0


l




Since
landmarks separated paths length least planning P,

b
L +P

obtain V c
Vc
.
1


L
Therefore similar reasoning above, see state x X
b



VM
c(x) VM
c (x) L + P +

(L + P )
2 (L + P )

.


1
1

C.1.4 Proof Theorem 2
Proof. (of Theorem 2)
apply Lemma 9 1 =

(1 dmin )2
(1) dmin

(0, 1] Lemma 10 obtain





dmin

K
VMAX + (1 ) +
VM VM
1 dmin
1,




1
dmin

dmin K
[VMAX + (1 )] +
+ (1 )
.
VM V0


min
min
1
1
L
(61)
replacing H 1 , get



K
V

V



1,



dmin
1 dmin


1+

(1 ) dmin
1 dmin



(VMAX + (1 )H ) +

!
V V0

L
+ (1 )2 (K+1)dmin
(62)
1 dmin

rearranging terms.
Due definition relaxation error


V V

1,


(Definition 12),



b

V

V
+ R

c
c

2(L +P )
b
1 dmin

434

1,

+ R

(63)

fiApproximate Value Iteration Temporally Extended Actions

last step due Lemma 11.
combining (62) (63), obtain


kV V

K k

1,




=



dmin
1 dmin


1+

2(L +P )
1 dmin
b

2(L +P )
1 dmin
b

+ R + + + (1
+ R + + +

(1) dmin
1 dmin







VM V0

)2 (K+1)dmin

(K+1)dmin

1 dmin





VM V0
1 dmin

!
L

!
L

(VMAX + (1 )H ).

C.2 Proof Theorem 3
Proof. (of Theorem 3)
Corollary 1,
Lp, (K ) Lp, ( ) +

1/p

2 dmin 1/p
dmin (K+1)
C
b
(TF,
F)
+

+

p,

(1 )2 ,



2 kV V0 k
(1 )2


.
(64)

(63),
Lp, ( )

2(L + P )
1 dbmin

+ R .

result follows replacing Lp, ( ) (64) right hand side previous
inequality.

References
Barry, J. L., Kaelbling, L. P., & Lozano-Prez, T. (2011). DetH*: Approximate Hierarchical
Solution Large Markov Decision Processes. International Joint Conference
Artificial Intelligence.
Bertsekas, D. P., & Tsitsiklis, J. (1996). Neuro-dynamic programming. Athena Scientific.
Brunskill, E., Leffler, B. R., Li, L., Littman, M. L., & Roy, N. (2008). CORL: ContinuousState Offset-Dynamics Reinforcement Learner. Proceedings 24 th Conference
Uncertainty Artificial Intelligence (UAI-08).
Chassin, D. P., Fuller, J. C., & Djilali, N. (2014). GridLAB-D: agent-based simulation
framework smart grids. Journal Applied Mathematics, 2014.
Comanici, G., & Precup, D. (2010). Optimal policy switching algorithms reinforcement
learning. Proceedings 9 th International Conference Autonomous Agents
Multiagent Systems, pp. 709714.
Dietterich, T. G., Taleghan, M. A., & Crowley, M. (2013). PAC optimal planning invasive
species management: Improved exploration reinforcement learning simulatordefined MDPs. Proceedings National Conference Artificial Intelligence.
Dijkstra, E. (1959). note two problems connexion graphs. Numerische Mathematik, 1 (1), 269271.
435

fiMann, Mannor, & Precup

Farahmand, A., Ghavamzadeh, M., Szepesvari, C., & Mannor, S. (2008). Regularized fitted
Q-iteration: Application planning. Recent Advances Reinforcement Learning,
pp. 5568. Springer.
Farahmand, A., Munos, R., & Szepesvari, C. (2010). Error propagation approximate
policy value iteration. Advances Neural Information Processing Systems.
Fernandez, F., & Veloso, M. (2006). Probabilistic policy reuse reinforcement learning
agent. Proceedings 5th International Joint Conference Autonomous Agents
Multiagent Systems, pp. 720727.
Hart, P., Nilsson, N., & Raphael, B. (1968). formal basis heuristic determination
minimum cost paths. Systems Science Cybernetics, IEEE Transactions on,
4 (2), 100107.
He, R., Brunskill, E., & Roy, N. (2011). Efficient planning uncertainty macroactions. Journal Artificial Intelligence Research, 40, 523570.
Hoey, J., St-Aubin, R., Hu, A. J., & Boutilier, C. (1999). SPUDD: Stochastic Planning
Using Decision Diagrams. Proceedings Uncertainty Artificial Intelligence,
Stockholm, Sweden.
Iba, G. A. (1989). heuristic approach discovery macro-operators. Machine
Learning, 3, 285317.
Jong, N. K., & Stone, P. (2008). Hierarchical model-based reinforcement learning: Rmax +
MAXQ. Proceedings 25th International Conference Machine Learning.
Kearns, M., Mansour, Y., & Ng, A. Y. (2002). sparse sampling algorithm near-optimal
planning large Markov decision processes. Machine Learning, 49 (2-3), 193208.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo Planning. Machine
Learning: ECML2006, pp. 282293. Springer.
Konidaris, G., & Barto, A. (2009). Skill discovery continuous reinforcement learning
domains using skill chaining. Advances Neural Information Processing Systems
22, pp. 10151023.
Konidaris, G., & Barto, A. G. (2007). Building portable options: Skill transfer reinforcement learning.. Proceedings International Joint Conference Artificial
Intelligence, Vol. 7, pp. 895900.
Konidaris, G., Kuindersma, S., Barto, A., & Grupen, R. (2010). Constructing skill trees
reinforcement learning agents demonstration trajectories. Advances Neural
Information Processing Systems, pp. 11621170.
Lazanas, A., & Latombe, J.-C. (1992). Landmark-based robot navigation. Tech. rep.,
Stanford University.
Lazaric, A., Ghavamzadeh, M., & Munos, R. (2010). Analysis classification-based policy
iteration algorithm. Proceedings 27th International Conference Machine
Learning.
Littman, M. L., Dean, T. L., & Kaelbling, L. P. (1995). complexity solving
Markov decision problems. Proceedings 11th conference Uncertainty
artificial intelligence, pp. 394402.
436

fiApproximate Value Iteration Temporally Extended Actions

Mankowitz, D. J., Mann, T. A., & Mannor, S. (2014). Time-regularized interrupting options.
Proceedings 31st International Conference Machine Learning.
Mann,
T.
A.
(2014).
Cyclic
Inventory
Management
https://code.google.com/p/rddlsim/source/browse/trunk/files/
rddl2/examples/cim.rddl2. Accessed: 2015-06-29.

(CIM).

Mann, T. A., & Mannor, S. (2014). Scaling approximate value iteration options:
Better policies fewer iterations. Proceedings 31 st International Conference Machine Learning.
Mannor, S., Menache, I., Hoze, A., & Klein, U. (2004). Dynamic abstraction reinforcement
learning via clustering. Proceedings 21st International Conference Machine
learning, ICML 04, pp. 71, New York, NY, USA. ACM.
McGovern, A., & Barto, A. G. (2001). Automatic discovery subgoals reinforcement
learning using diverse density. Proceedings 18th International Conference
Machine Learning, pp. 361 368, San Fransisco, USA.
Minner, S. (2003). Multiple-supplier inventory models supply chain management:
review. International Journal Production Economics, 8182, 265279. Proceedings
11th International Symposium Inventories.
Munos, R. (2005). Error bounds approximate value iteration. Proceedings
National Conference Artificial Intelligence.
Munos, R., & Szepesvari, C. (2008). Finite-time bounds fitted value iteration. Journal
Machine Learning Research, 9, 815857.
Peleg, D., & Schaffer, A. A. (1989). Graph spanners. Journal Graph Theory, 13 (1),
99116.
Peters, J., & Schaal, S. (2008). Reinforcement learning motor skills policy gradients.
Neural Networks, 21, 682691.
Precup, D., & Sutton, R. S. (1997). Multi-time models temporally abstract planning.
Advances Neural Information Processing Systems 10.
Precup, D., Sutton, R. S., & Singh, S. (1998). Theoretical results reinforcement learning
temporally abstract options. Machine Learning: ECML1998, pp. 382393.
Springer.
Puterman, M. L. (1994). Markov Decision Processes - Discrete Stochastic Dynamic Programming. John Wiley & Sons, Inc.
Riedmiller, M. (2005). Neural fitted Q iterationfirst experiences data efficient
neural reinforcement learning method. Machine Learning: ECML2005, pp. 317
328. Springer.
Sanders, P., & Schultes, D. (2005). Highway hierarchies hasten exact shortest path queries.
Brodal, G., & Leonardi, S. (Eds.), Algorithms: ESA2005, Vol. 3669 Lecture
Notes Computer Science, pp. 568579. Springer Berlin Heidelberg.
Scarf, H. (1959). optimality (s,S) policies dynamic inventory problem. Tech.
rep. NR-047-019, Office Naval Research.
437

fiMann, Mannor, & Precup

Scherrer, B., Ghavamzadeh, M., Gabillon, V., & Geist, M. (2012). Approximate Modified
Policy Iteration. Proceedings 29th International Conference Machine
Learning, Edinburgh, United Kingdom.
Sethi, S. P., & Cheng, F. (1997). Optimality (s,S) policies inventory models
markovian demand. Operations Research, 45 (6), 931939.
Shantia, A., Begue, E., & Wiering, M. (2011). Connectionist reinforcement learning
intelligent unit micro management starcraft. Proceedings International
Joint Conference Neural Networks, pp. 17941801. IEEE.
Silver, D., & Ciosek, K. (2012). Compositional planning using optimal option models.
Proceedings 29th International Conference Machine Learning, Edinburgh.
Simsek, O., & Barto, A. G. (2004). Using relative novelty identify useful temporal abstractions reinforcement learning. Proceedings 21st International Conference
Machine Learning, pp. 95102, New York, NY, USA. ACM.
Sorg, J., & Singh, S. (2010). Linear options. Proceedings 9th International Conference Autonomous Agents Multiagent Systems, pp. 3138.
Stolle, M., & Precup, D. (2002). Learning options reinforcement learning. Abstraction,
Reformulation, Approximation, pp. 212223. Springer.
Stone, P., Sutton, R. S., & Kuhlmann, G. (2005). Reinforcement learning robocup soccer
keepaway. Adaptive Behavior, 13 (3), 165188.
Sutton, R. S., Precup, D., & Singh, S. (1999). MDPs semi-MDPs: framework
temporal abstraction reinforcement learning. Artificial Intelligence, 112 (1), 181
211.
Tamar, A., Castro, D. D., & Mannor, S. (2013). TD methods variance rewardto-go. Proceedings 30 th International Conference Machine Learning.
Wolfe, A. P., & Barto, A. G. (2005). Identifying useful subgoals reinforcement learning
local graph partitioning. Proceedings 22nd International Conference
Machine Learning, pp. 816823.
Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: Baseline Probabilistic Planning. Proceedings International Conference Automated Planning
Scheduling, Vol. 7, pp. 352359.

438

fiJournal Artificial Intelligence Research 53 (2015) 91-126

Submitted 12/14; published 05/15

Ceteris Paribus Structure Logics Game Forms
Davide Grossi

d.grossi@liverpool.ac.uk

Department Computer Science
University Liverpool

Emiliano Lorini

emiliano.lorini@irit.fr

IRIT-CNRS
Universite Paul Sabatier

Francois Schwarzentruber

francois.schwarzentruber@ens-rennes.fr

ENS Rennes - IRISA

Abstract
article introduces ceteris paribus modal logic, called CP, interpreted
equivalence classes induced finite sets propositional atoms. logic studied
used embed three logics strategic interaction, namely atemporal STIT,
coalition logic propositional control (CLPC) starless fragment dynamic
logic propositional assignments (DLPA). embeddings highlight common ceteris
paribus structure underpinning key operators apparently different logics
show, argue, remarkable similarities behind influential formalisms
reasoning strategic interaction.

1. Introduction
logical analysis agency gamesfor expository introduction field see van
der Hoek Paulys overview paper (2007)has boomed last two decades giving
rise plethora different logics particular within multi-agent systems field.1
heart logics always representations possible choices (or actions)
groups players (or agents) powers force specific outcomes game.
logics take former primitives, like STIT (the logic seeing that, Belnap, Perloff,
& Xu, 2001; Horty, 2001), take latter like CL (coalition logic, Pauly, 2002; Goranko,
Jamroga, & Turrini, 2013) ATL (alternating-time temporal logic, Alur, Henzinger, &
Kupferman, 2002).
formalisms power players modeled terms notion effectivity.
strategic game, -effectivity group players consists sets outcomes
game players collective action forces outcome
game end set, matter players (Moulin & Peleg,
1982). So, set outcomes X belongs -effectivity set players J,
exists individual action agent J that, actions players,
outcome game contained X. keep actions agents
1. richness logical landscape object IJCAI13 invited talk A. Herzig Logics
Multi-Agent Systems: Critical Overview.
c
2015
AI Access Foundation. rights reserved.

fiGrossi, Lorini, & Schwarzentruber

fixed, selection individual action agent J corresponds choice
J assumption agents stick choices.
already observed van Benthem, Girard, Roy (2009) formalization
choice power games things equal, ceteris paribus, nature.
Considering outcomes game possible set players J
players fixed actions, amounts considering may case
ceteris paribus condition actions agents J equal (to current
ones). aforementioned work van Benthem et al. also show intuition
used, instance, give modal formulation Nash equilibria one-shot games.2
current paper leverage intuition show provide novel
systematization many influential formalisms field logic games.
1.1 Scientific Context
Formal relationships linking logics (or fragments thereof) mentioned
object several publications. Notable examples are: embedding CL
next-time fragment ATL (Goranko, 2001) embedding CL NCL (normal
coalition logic, Broersen, Herzig, & Troquard, 2007; Balbiani, Gasquet, Herzig, Schwarzentruber, & Troquard, 2008a), embedding CL ATL STIT (Broersen, Herzig,
& Troquard, 2005, 2006). Earlier contributions also attempted comprehensive
systematizations field logic games. Two particular worth mentioning:
Goranko Jamrogas work (2004), compares game logics based computation tree abstraction like ATL variants; Herzigs work (2014), provides
conceptual syntax-basedwhile favor semantic methodscomparison
main formalisms literature.
1.2 Aim Paper
aim paper provide technical contribution towards unification field
logic games. set develop series embeddings highlight common
structure representation choice power, underpins semantics
logics mentioned above.
focus components semantics logics directly
representation choice power, abstract away representation
time repeated interaction. logics working are: atemporal
fragment STIT, logic CLPC (coalition logic propositional control, van der Hoek &
Wooldridge, 2005) starless fragment DLPA (dynamic logic propositional
assignments, van Eijck, 2000; Balbiani, Herzig, & Troquard, 2013). logics cover,
arguably, large spectrum influential existing formalisms.3 Logic STIT often
considered standard literature, embeds CL ATL (Broersen et al., 2005,
2. refer reader Osborne Rubinsteins textbook (1994) introduction basic notions
game theory.
3. worth stressing focus logics choice power (that is, notion effectivity) formalisms incorporating also explicit representation choice power
implemented (that is, explicit notion strategy), instance ATL explicit strategies
(Walther, van der Hoek, & Wooldridge, 2007).

92

fiThe Ceteris Paribus Structure Logics Game Forms

CLPC

DLPA

CP
one
nti
al

S5

bo

un
de





od

el


exp

STIT

restricted languages

NCL

Figure 1: Summary embeddings established paper known literature
arrow indicates formula source logic satisfiable
suitable translation formula satisfiable target logic. DLPA
denotes starless version dynamic logic propositional assignments, NCL
STIT denote atemporal version of, respectively, normal coalition logic
seeing-to-it logic. S5 denotes normal modal logic equivalence relations. Dotted lines indicate embeddings known literature: CLPC
DLPA (Balbiani et al., 2013) STIT NCL (and vice versa) respect fragments respective languages (Lorini & Schwarzentruber, 2011).
embedding STIT CP assumes bound STIT-models.
embeddings polynomial except one CP S5.

2006), use natural starting point. Logic CLPC influential extension
CL strong formal ties (Dunne, van der Hoek, Kraus, & Wooldridge, 2008) the,
equally influential, Boolean games model (Harrenstein, van der Hoek, Meyer, & Witteveen,
2001) multi-agent systems. Finally, logic DLPA extension PDL (propositional
dynamic logic, Harel, Kozen, & Tiuryn, 2000), recently proposed new
standard representation choice power (Herzig, Lorini, Moisan, & Troquard,
2011; Balbiani et al., 2013).
articulate analysis, whose main technical tool consists satisfiability-preserving
embeddings, paper introduces studiesin axiomatization complexitya
simple ceteris paribus logic based propositional equivalence, call CP.
logic yardstick allowing us compare unify STIT, CLPC DLPA.
1.3 Outline Summary Results
Section 2 introduces logic CP. logic compared S5 axiomatized.
Section 3 provides study relationship atemporal version STIT
CP. show CP embeds atemporal group STITthe fragment atemporal STIT
actions individuals groups representedunder assumption
agents choices bounded. call latter atemporal bounded group STIT.
Moreover, show CP embeds atemporal individual STITthe variant atemporal
93

fiGrossi, Lorini, & Schwarzentruber

STIT actions individuals represented. former embedding
used transfer complexity results CP. also present embedding CP variant
atemporal group STIT groups nested (i.e., given two sets agents J J 0
either J J 0 viceversa).
Section 4 provides embedding coalition logic propositional control atemporal
bounded group STITand therefore, indirectly, CPas well direct embedding
CLPC CP.
Section 5 provides embedding starless fragment DLPA CP well
embedding CP DLPA therefore, indirectly, STIT (on bounded models)
CLPC DLPA.
Finally, Section 6 discuss obtained results, put perspective related
work draw general implications field. conclude Section 7. Longer
proofs collected technical appendix end paper.
Figure 1 gives graphical presentation embeddings established paper
well relevant ones already known literature. Two embeddings known
logics: embedding CLPC DLPA (Balbiani et al., 2013),
embedding STIT NCL, vice versa, language STIT (and NCL)
restricted fragment allow nesting modalities.4

2. Ceteris Paribus Logic Based Propositional Equivalence
section introduce study logic used target logic
embeddings present. section starts definition equivalence modulo
set atoms. present ceteric paribus logic CP whose semantics based
equivalence relations. section finishes exponentially embedding ceteris
paribus logic CP S5 proving CP-satisfiability problem decidable.
2.1 Equivalence Modulo Set Atoms
Consider structure (W, V ) W set states, V : P 2W valuation
function countable set atomic propositions P subsets W .5
Definition 1. (Equivalence modulo X) Given pair (W, V ), X P |X| < ,
relation VX W 2 defined as:

w VX w0 p X : w V (p) w0 V (p)
X singleton (e.g. p), often write Vp instead V{p} . Also, order
avoid clutter, often drop reference V VX clear context.
Intuitively, two states w w0 equivalent set X, X-equivalent,
satisfy atoms X (according given valuation V ). finiteness
4. reader referred Lorini Schwarzentrubers paper (2011) BNF language.
5. literature game logics sometimes defined countable set atoms (e.g., Balbiani et al.,
2013) sometimes finite set atoms (e.g., van der Hoek & Wooldridge, 2005). opt
generality define language CP countable set. assumption finite supply
atoms results present later would trivialize (for instance CP satisfiability problem
would PTIME) would therefore hide interesting technical features CP.

94

fiThe Ceteris Paribus Structure Logics Game Forms

X clearly essential definition. assumed because, see, set
X taken model set actions agent game form sets actions
always assumed finite.
state following simple fact without proof. highlights interesting features
notion propositional equivalence modulo subsets P, use
later paper.
Fact 1. (Properties P ) following holds set states W , valuation V :
P 2W finite sets X, P:
(i) X reflexive, transitive symmetric;
(ii) X X ;
(iii) X singleton, X induces partition W 2 cells;
(iv) X = XY ;
(v) = W 2 .
Intuitively: (i) states X equivalence relation; (ii) states larger
set atoms, refined equivalence relation indexed it; (iii) states
set atom singleton, equivalence relation would induce partition
one (if proposition singleton globally true globally false model) two
cells (otherwise); (iv) states relation indexed union two sets atoms
relation one obtains intersecting relations two sets; finally (v) states
relation empty set atoms global relation.
2.2 Modal Logic X Relation
section consider simple modal language interpreted relations X axiomatize logic class structures (W, V ). key modal operator language
hXi, whose intuitive meaning case state X-equivalent
current one or, stress ceteris paribus reading, possible things expressed
X equal. call resulting logic propositional ceteris paribus logic, CP short.
2.2.1 Syntax CP.
Let P countable set atomic propositions. language LCP (P) defined
following BNF:
LCP (P) : ::= p | | ( ) | hXi
p ranges P X finite subset atomic propositions (X P X finite).
Note set finite subsets atomic propositions countable, language
LCP (P) also countable. Boolean connectives >, , , dual operators [X]
defined usual. Although taken diamond operators primitive,
convenience also make use box operators state results later sections.
set SF () subformulas formula defined inductively follows:
SF (p) = {p};
95

fiGrossi, Lorini, & Schwarzentruber

SF () = {} SF ();
SF ( ) = { } SF () SF ();
SF (hXi) = {hXi} SF ().
say signature X appears exists formula hXi SF ().
2.2.2 Semantics CP
class models working with:
Definition 2. (CP-models) Given countable set P, CP-model LCP (P) tuple
= (W, V ) where:
W non-empty set states;
V : P 2W valuation function.
CP-model called universal W = 2P V s.t. V (p) = {w | p w}. called
non-redundant P identity relation W 2 .
Intuitively, CP-model consists state-space valuation function given
set atoms. satisfaction relation defined follows:
Definition 3. (Satisfaction CP-models) Let = (W, V ) CP-model LCP (P),
w W , LCP (P):
M, w |=CP p w V (p);
M, w |=CP M, w 6|=CP ;
M, w |=CP M, w |=CP M, w |= ;
M, w |=CP hXi w0 W : w VX w0 M, w0 |=CP
Formula CP-satisfiable, exists model state w
M, w |=CP . Formula valid M, noted |=CP , w W ,
M, w |=CP . Finally, CP-valid, noted |=CP , valid CP-models.
logical consequence formula set formulae, noted |=CP , defined
usual.
So, modal operators interpreted equivalence relations X induced
valuation model. worth observing logic class models
closed uniform substitution,6 is, logic CP uniform.7 witness that, notice
formula [{p}]p [{p}]p valid, whereas [{p}] [{p}] not.
Let us give simple illustration semantics.
Example 1. Let us consider following model made 5 states w, x, u, y, z:
6. definition uniform substitution reader referred textbook Blackburn, de Rijke,
Venema (2001, Def. 1.18).
7. terminology comes Goldblatts work (1992).

96

fiThe Ceteris Paribus Structure Logics Game Forms

w : p, q

x:p

u : p, q, r

z:q



instance, M, w |=CP h{p, q}ir M, z |=CP [{p}]r.
following lemmas state simple facts concerning relation logic CP logic
S5 isolate interesting class CP-models.
Lemma 1. Let LCP (P) set formulae LCP (P) containing hi operators.
set formulae LCP (P) CP-valid modal logic Kripke frames (W, W 2 ),
i.e., logic S5.
Proof. follows directly Fact 1 item (v).
words, hi operator LCP nothing global modality (Blackburn
et al., 2001, pp. 367370). next lemma states CP actually logic class
relevant CP-models.
Lemma 2. Every satisfiable CP-formula satisfiable non-redundant model.
Proof. Assume M, w |= . show MP , |w|P |= MP quotient
equivalence relation P (defined natural way) |w|P set
states P -equivalent w. proceed induction structure .
propositional Boolean cases obvious. Let = hXi X P.
assumption semantics CP operators exists v w X v
M, v |= . construction directly |w|P X |v|P . IH MP , |v|P |= ,
therefore MP , |w|P |= hXi.
2.2.3 Axiomatics CP
obtain axiom system CP standard reduction technique exploiting Lemma
1. axiom system given Figure 2. first thing notice system consists
usual S5 axioms plus Reduce axiom. Logic S5 known sound strongly
complete class models accessibility relation total relation W 2
(Blackburn et al., 2001), modality hi therefore axiomatized (dual of)
global modality.
said this, soundness strong completeness system easy
establish.
Theorem 1. axiom system given Figure 2 sound strongly complete
class CP-models.
Proof. Soundness suffices show Reduce CP-valid, follows straightforwardly Definition 1. Completeness obtain completeness proceed customary
DEL (van Ditmarsch, Kooi, & van der Hoek, 2007; Wang & Cao, 2013). first fix
97

fiGrossi, Lorini, & Schwarzentruber

(P)

tautologies propositional calculus

(K)

[]( ) ([] [])

(T)

hi

(4)

hihi hi

(5)

hi []hi





^
^
^
^
^

p
p []
p
[X]
p

(Reduce)

X

(MP)
(N)

pY

pY

pX\Y

pX\Y

`CP `CP `CP
`CP `CP []

Figure 2: Axiom schemas rules CP. X, range finite elements 2P , ,
LCP (P), p P. usual, `CP means exists sequence
formulae either axiom obtained previous formulae
application inference rule.

translation tr0 : LCP (P) LCP (P) follows:
tr0 (p) = p
tr0 () = tr0 ()
tr0 ( ) = tr0 () tr0 ()





^
^
^
^
^

tr0 ([X]) =
p
p []
p
p tr0 ()
X

pY

pY

pX\Y

pX\Y

also write tr0 () {tr0 () | }. Notice translation removes occurrences
hXi [X] operators formulae X 6= structure axiom
Reduce. Consider following rule substitution provable equivalents (REP):
(REP)

`CP 0 `CP [/0 ]

[/0 ] formula results replacing zero occurrences
, , 0 . rule REP derivable axiom system Figure 2 ().
proof claim provided Appendix A. using axiom Reduce rule REP
obtain () that, LCP (P), `CP tr0 () (). proceed follows:
|=CP tr0 () |=CP tr0 () (); Lemma 1 strong completeness
S5 thus obtain tr0 () `S5 tr0 () therefore tr0 () `CP tr0 (); finally ()
follows `CP , proves strong completeness.
98

fiThe Ceteris Paribus Structure Logics Game Forms

crux reduction argument lies use axiom Reduce.
axiom enable reduction [X]-formulae taking care possible truth
V
V
value combinations atoms X. given combination, e.g.,
p

p
,
pY
pX\Y
true given state (for ), accessible states, combination
true, occurs scope [X] also true.
opted axiomatization virtue simplicity, alternative systems
course possible. One particular worth mentioning. first reduces hpi operators
axiom:
hpi ((p hi(p )) (p hi(p )))

(1)

states hpi equivalent either case current state satisfies p
exists (possibly different) p-state true, case p true
exists (possibly different) p-state true (recall property (iii) Fact
1). Given reduction, one use axioms enforce appropriate behavior
X relations X consists one atom. aim, axioms used
known canonical properties (ii) (iv) Fact 1, namely:
hX hXi

(2)

hXii hY ii hX ii

(3)

ranges set nominals. complete system could obtained
axiomatizing behavior nominalsthrough axioms rules used hybrid logic
(Areces & Ten Cate, 2006). system, named canonical model could built
(i.e., canonical model maximal consistent sets contain exactly one nominal)
axioms Formulae 1-3 would enforce desirable properties canonical
relations.
2.3 Exponentially Embedding CP S5
property expressed axiom Reduce enables truth-preserving translation CP
S5 via translation tr0 provided proof Theorem 1. translation is, however,
length translated formula grows exponentially tower exponents
height equal modal depth original formula.
section propose translation single exponential preserves satisfiability. Take standard modal language L (P) one modal operator defined
set atoms P. S5-models structures = (W, V ) W set states,
V : P 2W valuation function. Given S5-model = (W, V ) state w W ,
truth conditions defined follows:
M, w |=S5 u W : M, u |=S5
S5-satisfiability defined usual. possible define exponential truth-preserving
reduction tr : LCP (P) L (P) follows:
^
tr(0 ) = p0
(p tr1 ())
SF (0 )

99

fiGrossi, Lorini, & Schwarzentruber

p fresh atomic proposition (note p0 p formula 0 itself,
also subformula 0 )8 , ranging SF (0 ) tr1 defined follows:
tr1 (p) = p

p P

tr1 () = tr1 ()
tr1 ( ) = tr1 () tr1 ()
tr1 ([]) = p



tr1 ([X]) =

^

^


X

pY

p

^





p

^
pY

pX\Y

p

^



p p

pX\Y

Intuitively, translation designed operate like axiom Reduce avoiding exponential blow-up pile modal depth formula. atomic propositions
p tr1 ([X]) avoid non-elementary size tr(0 ). definition tr1 ([]) corresponds degenerated case tr1 ([X]) X = .The following theorem states
satisfiability preservation. proof given Appendix B.
Theorem 2. (tr preserves satisfiability) Let 0 CP-formula. two following statements equivalent: 0 CP-satisfiable; tr(0 ) S5-satisfiable.
consequence, also obtain following result.
Corollary 1. (Decidability) satisfiability problem CP decidable NEXPTIME.
Proof. satisfiability problem S5 decidable NP (Blackburn et al., 2001, Ch.
6). result follows Theorem 2 decision procedure may work follows:
order check satisfiable compute formula tr() apply NP-decision
procedure check whether tr() S5-satisfiable not.
Notice cardinality X appears operators [X] bounded
fixed integer, translation tr becomes polynomial size . Thus,
S5-satisfiability problem NP-complete, CP-satisfiability problem bounded
cardinality restrictions set atomic propositions modal operators NP.
trivially NP-hard, NP-complete.
Section 3, embed atemporal version STIT (the logic seeing that)
CP thereby obtaining lower bounds results.

3. Ceteris Paribus Structure STIT Logic
section, investigate possibility embedding logic agency STIT
CP. STIT logic (the logic seeing that, Belnap et al., 2001; Horty, 2001) one
prominent logical accounts agency. logic constructions form
agent (or group J) sees . STIT non-standard modal semantics based
concepts moment history. However, shown Balbiani, Herzig, Troquard
(2008b) Herzig Schwarzentruber (2008), basic STIT language without temporal
operators simulated standard Kripke semantics.
8. use fresh atomic propositions obtain efficient satisfiability preserving translations
based propositional logic technique known Tseitin transformation (Tseitin, 1968).

100

fiThe Ceteris Paribus Structure Logics Game Forms

3.1 Atemporal Group STIT
First let us recall syntax semantics atemporal group STIT. language
logic built countable set atomic propositions P finite set agents
AGT = {1, . . . , n} defined following BNF:
LGSTIT (P, AGT ) : ::= p | | ( ) | [J : stit]
p ranges P J ranges 2AGT . construction [J : stit] read group
J sees true regardless agents choose. define dual
def
operator hJ : stiti = [J : stit]. J = , construction [ : stit] read
true regardless every agent chooses simply necessarily true.
Definition 4 (STIT-Kripke model, Herzig & Schwarzentruber, 2008). STIT-Kripke model
= (W, {RJ }JAGT , V ) 3-tuple where:
W non-empty set worlds;
J AGT , RJ equivalence relation that:
i) RJ R ;

ii) RJ = jJ R{j} ;
iii)
w W (w1 , . . . , wn ) W n , u1 R{1} (w), . . . , un R{n} (w)
1jn R{j} (uj ) 6= ;
V : P 2W valuation function atomic propositions;
RJ (w) = {u W : (w, u) RJ } J 2AGT .
partition induced equivalence relation RJ set possible choices
group J.9 Indeed, STIT choice group J given world w identified
set possible worlds RJ (w). call RJ (w) set possible outcomes group
Js choice world w, sense group Js current choice w forces possible
worlds RJ (w). set R (w) simply set possible outcomes w, said
differently, set outcomes current game w. According Condition (i),
set possible outcomes group Js choice subset set possible outcomes.
Condition (ii), called additivity, means choices agents group J made
choices individual agent more. Condition (iii) corresponds
property independence agents: whatever agent decides do, set outcomes
corresponding joint action agents non-empty. intuitively, means
agents never deprived choices due choices made agents.
Lorini Schwarzentrubers work (2011) determinism group AGT assumed.
say set outcomes corresponding joint action agents
singleton. Hortys group STIT logic (Horty, 2001) suppose this. deal
Hortys version STIT. STIT model game form joint action
agents might determine one outcome.
9. One also see partition induced equivalence relation Rj set actions agent j
try, notion trying corresponds notion volition studied philosophy action
(e.g., OShaughnessy, 1974; McCann, 1974).

101

fiGrossi, Lorini, & Schwarzentruber

w

u

v

r





z

R{1}
R{2}

Figure 3: STIT-model
Example 2. tuple = (W, R , R{1} , R{2} , R{1,2} , V ) defined by:
W = {w, u, v, r, s, t, z};
R = W W ;
R{1} = {w, u, v}2 {r, s}2 {t, z}2 ;
R{2} = {w, r, t}2 {u, v, s, z}2 ;
R{1,2} = {(w, w), (r, r), (s, s), (t, t), (z, z), (u, u), (v, v), (u, v), (v, u)};
p P, V (p) = .
STIT-Kripke model. Figure 3 shows model M. equivalence classes induced
equivalence relation R{1} represented ellipses correspond choices
agent 1. equivalence classes induced equivalence relation R{2} represented
rectangles correspond choices agent 2. choice group {1, 2}
given world determined intersection choice agent 1 choice
agent 2 world. example, choice agent 1 world u {w, u, v} whereas
choice agent 2 world u {u, v, s, z}. choice group {1, 2} u {u, v}.
Note Condition (iii) Definition 4 ensures choice agent 1
choice agent 2 intersection two choices non-empty. is,
equivalence class induced relation R{1} equivalence class induced
relation R{2} , intersection two equivalence classes non-empty.
Given STIT-Kripke model = (W, {RJ }JAGT , V ) world w M, truth
conditions STIT formulae following:
M, w |=STIT p w V (p);
M, w |=STIT M, w 6|=STIT ;
M, w |=STIT M, w |=STIT M, w |=STIT ;
M, w |=STIT [J : stit] v RJ (w) : M, v |=STIT
RJ (w) = {u W | (w, u) RJ }.
102

fiThe Ceteris Paribus Structure Logics Game Forms

3.2 Embedding Atemporal STIT CP
able embed group STIT CP many reasons. first one
group STIT satisfiability problem undecidable 3 agents
(Herzig & Schwarzentruber, 2008).10 second one group STIT
finite model property. Indeed Herzig Schwarzentruber (2008) provide translation
product logic S5n group STIT logic, S5n finite model
property (Gabbay, Kurucz, Wolter, & Zakharyaschev, 2003), atemporal group STIT
it. contrary CP inherits finite model property S5. Indeed,
formula CP-satisfiable, Theorem 2 says tr() S5-satisfiable. S5
polynomial model property, exists polynomial-sized S5-model tr() size
tr(). words, exists exponential S5-model tr() size .
Theorem 2 ensures exists exponential CP-model size .
nevertheless embed variant group STIT assumption every
agent finite bounded number actions repertoire. every agent j,
Rj -equivalence class Rj (u) corresponds action agent j. say agent j kj
actions STIT model exactly kj Rj -equivalence classes M.
game structure STIT-models enforced CP-models.
introduce special atomic propositions encode game structure. Without loss
generality, assume set P contains special atomic propositions rep j1 , rep j2 , . . .
agents j used represent actions agents. Let k maximal
number actions: k = maxjAGT kj . every agent, represent actions numbers
` {0, . . . , k 1} atomic propositions encode binary representation `.
Let integer represents number digits need represent action.
instance let = dlog2 ke (the ceiling logarithm k). given agent j,
Rjm = {rep j1 , . . . , rep jm } set atomic propositions represent binary digits
action agent j. suppose j 6= Rjm Rim = .
Example 3. example, model Example 2, agent 1 k1 = 3 actions agent
2 k2 = 2 actions. k = 3 = dlog2 3e = 2. R1m = {rep 11 , rep 12 }
R2m = {rep 21 , rep 22 }. instance, may represent action agent 1 corresponding
R{1} (w) = {w, u, v} valuation rep 11 rep 12 , action agent 1 corresponding
{r, s} rep 11 rep 12 , action agent 1 corresponding {t, z} rep 11 rep 12 ,
action agent 2 corresponding {w, r, t} rep 21 rep 22 action agent 2
corresponding {u, v, s, z} rep 21 rep 22 .

Let Rm = jAGT Rjm set atomic propositions used denote actions. Let
us define following CP formula:
def

GRIDm =

V

xRm []((x

hRm \ {x}ix) (x hRm \ {x}ix))

(4)

formula enforces CP model universal (over Rm ), is, contain possible
valuations Rm (recall Definition 2). model satisfies GRIDm interpreted
game form valuation Rjm represents action player j.
10. See Lorini Schwarzentrubers paper (2011) study decidable fragments group STIT.

103

fiGrossi, Lorini, & Schwarzentruber

Example 4. instance, world CP model M0 satisfies GRID2 ,
skeleton M0 following form (we intentionally draw skeleton
model M0 looks like model M):






|

{z

}

worlds
rep 21 rep 22
true

|

{z

worlds
rep 11 rep 12 true
worlds
rep 11 rep 12 true
worlds
rep 11 rep 12 true

}

worlds
rep 21 rep 22
true

R{1}
R{2}

define translation LGSTIT LCP (P) follows:
tr2 (p) = p

p P

tr2 () = tr2 ()
tr2 ( ) = tr2 () tr2 ()
[
tr2 ([J : stit]) = [
Rjm ]tr2 ()
jJ

translation tr2 parameterized m. notational convenience,
follows write tr2 instead tr2m leaving implicit parameter m.

set jJ Rjm represents atomic propositions used represented actions
coalition J.
Example 5. instance, = 2,
tr2 ([{1} : stit][{1, 2} : stit]p) = [{rep 11 , rep 12 }][{rep 11 , rep 12 , rep 21 , rep 22 }]p.
obtained desired satisfiability-preservation result. proof given
Appendix C.
Theorem 3. Let us consider group STIT formula . Let integer.
following items equivalent:
1. STIT-satisfiable STIT-model agent 2m actions;
2. STIT-satisfiable STIT-model agent exactly 2m actions;
3. GRIDm tr2 () CP-satisfiable.
104

fiThe Ceteris Paribus Structure Logics Game Forms

3.3 Atemporal Individual STIT
subsection, consider following fragment STIT called atemporal individual
STIT 11 :
LISTIT (P, AGT ) : ::= p | | ( ) | [{j} : stit]
p ranges P j ranges AGT .
fragment STIT, axiomatized Xu (1998), exponential finite model
property (see Lemma 7 Balbiani et al., 2008b). Moreover, following theorem
highlights, embedded logic CP.
Theorem 4. Let us consider STIT formula individual STIT fragment. Let
length . following three items equivalent:
1. STIT-satisfiable
2. STIT-satisfiable model agent 2m actions;
3. GRIDm tr2 () CP-satisfiable.
Proof. 1 2 Consider STIT formula individual STIT fragment. STITsatisfiable length , STIT-satisfiable model
2m worlds (see Lemma 7 Balbiani et al., 2008b). implies
2m actions model. implications 2 3 3 1 come Theorem
3.
Thanks Theorem 4, reduce NEXPTIME-complete satisfiability problem
individual STIT (Balbiani et al., 2008b) CP-satisfiability problem. reduction
polynomial, obtain following lower bound complexity result CP-satisfiability
problem.
Corollary 2. CP-satisfiability problem NEXPTIME-hard.
3.4 Group STIT Coalitions Nested
subsection address satisfiability problem fragment CP consisting
formulae LCP sets atomic propositions appear operator [X]
occurring form linear set sets atomic propositions. formally, [X] [X 0 ]
two operators occurring either X X 0 X 0 X. instance, formula
[{p, q}]( [{p}][{p, q, r, s}]) belongs fragment {p} {p, q} {p, q, r, s}.
contrary, formula [{p}]p [{q}]p element fragment CP.
call satisfiability problem fragment CP CP-nested satisfiability
problem. Due embedding proposed Theorem 3 STIT CP, provide
following lower bound complexity result CP-nested satisfiability problem. proof
given Appendix D.
Theorem 5. CP-nested satisfiability problem PSPACE-hard.
11. authors (e.g., Broersen, 2008; Wansing, 2006) use term multi-agent STIT designate
logic operators form [{j} : stit]. prefer use explicit term individual
STIT Herzig Schwarzentrubers work (2008).

105

fiGrossi, Lorini, & Schwarzentruber

following theorem provides upper bound complexity result fragment
CP. proof given Appendix E.
Theorem 6. CP-nested satisfiability problem PSPACE.
concludes analysis STIT logics via CP. next section move normal
coalition logic.
3.5 Normal Coalition Logic
conclude section STIT briefly mentioning related system, normal coalition
logic. Normal coalition logic NCL introduced Broersen et al. (2007) provide
embedding normal modal logic influentialand non-normalcoalition logic
(Pauly, 2002). embedding based general simulation technique developed
Gasquet Herzig (1994) showed first time coalition logicwhich
already recognized fragment ATL containing next operator
(Goranko, 2001)could actually interpreted traditional structures Kripke
frames based equivalence relations. NCL studied Balbiani et al. (2008a).
Also NCL known atemporal variant, introduced studied Balbiani et al. (2008a)
Lorini Schwarzentruber (2011).
Two results atemporal NCL literature worth mentioning context.
First, Balbiani et al. (2008a, Thm. 38) show satisfiability problem atemporal
NCL (when |AGT | 2) NEXPTIME-complete, like CP; second, Lorini Schwarzentruber (2011, Prop. 1) show |AGT | 2, atemporal STIT embeddable
atemporal NCL vice versa, embedding (in directions) general
case possible considerably restricting syntax LSTIT .

4. Ceteris Paribus Structure Coalition Logic Propositional
Control
section study relationships CP, atemporal bounded group STIT,
another well-known game logic, logic CLPC (coalition logic propositional control ).12 Specifically, show CLPC embedded, preserving satisfiability,
atemporal bounded group STIT and, fact atemporal bounded group STIT
embedded CP (Section 3.1), indirectly show CLPC embedded
CP. complete picture also provide direct embedding CLPC CP.
latter embedding particular interest highlight striking similarities
models CP CLPC.
CLPC introduced van der Hoek Wooldridge (2005) formal language
reasoning capabilities agents coalitions multiagent environments.
logic notion capability modeled means concept control. particular,
assumed agent associated specific finite subset Pi finite set
propositions P. Pi set propositions controlled agent i. is, agent
ability assign (truth) value proposition Pi cannot affect truth
12. Gerbrandys work (2006) generalizations assumptions underlying CLPC
studied. consider original version CLPC proposed van der Hoek Wooldridge.

106

fiThe Ceteris Paribus Structure Logics Game Forms

values propositions P \ Pi . variant CLPC studied van der Hoek
Wooldridge (2005) also assumed control propositions exclusive, is, two
agents cannot control proposition (i.e., 6= j Pi Pj = ). Moreover,
assumed control propositions complete, is, every proposition controlled
least one agent (i.e., every p P exists agent p Pi ).
preceding concepts assumptions precisely formulated following section, illustrates syntax formal semantics CLPC.
4.1 Syntax Semantics CLPC
language CLPC built finite set atomic propositions P finite set
agents AGT = {1, . . . , n}, defined following BNF:
LCLPC (P, AGT ) : ::= p | | ( ) | J
p ranges P J ranges 2AGT . Operator J called cooperation modality,
construction J means group J contigent ability achieve .
Definition 5 (CLPC model). model CLPC tuple = (P1 , . . . , Pn , X) where:
P1 , . . . , Pn partition P among agents AGT ;
X P set propositions true initial state.

every group agents J AGT , let PJ = iJ Pi set atomic propositions
controlled group J. Moreover, every group J AGT every set atomic
propositions X P, let XJ = X PJ set atomic propositions X controlled
group J. Sets XJ called J-valuations.
Given CLPC model = (P1 , . . . , Pn , X), truth conditions CLPC formulae
following:
|=CLPC p p X;
|=CLPC 6|=CLPC ;
|=CLPC |=CLPC |=CLPC ;

|=CLPC J XJ0 PJ :
XJ0 |=CLPC


L

XJ0 CLPC model (P1 , . . . , Pn , X 00 ) that:
00
XAGT
\J = XAGT \J

XJ00 = XJ0
is, J true given model if, coalition J change truth
values atoms controls way true afterwards (i.e., given
actual truth-value combination atoms controlled J, exists
truth-value combination atoms controlled J ensures ).
Let us illustrate CLPC semantics example.
107

fiGrossi, Lorini, & Schwarzentruber

Example 6. Let AGT = {1, 2, 3}, P = {p, q, r}, P1 = {p}, P2 = {q} P3 = {r}.
Consider CLPC model = (P1 , P2 , , P3 , {r}). that:
|=CLPC {1,2} ((p q r) (p q r)).
0
Indeed, exists set atoms X{1,2}
P{1,2} controlled {1, 2}
L 0
0
X{1,2} |=CLPC ((p q r) (p q r)). example X{1,2}
= {p} P{1,2} ,
which,
(P
,
P
,
P
,
{p,
r})
|=
((p

q

r)

(p

q

r))

(P
1
2
3
1 , P2 , P3 , {p, r}) =
CLPC
L
{p}.

4.2 Embedding CLPC STIT
aim section provide embedding CLPC variant atemporal group STIT bounded choices (atemporal bounded group STIT)
presented Section 3.1.
Let us provide following STIT formulae catpure four basic assumptions
CLPC:
^
^
def
EXC + =
(h : stiti[{i} : stit]p h : stiti[{j} : stit]p)
(5)
pP i,jAGT :i6=j

EXC

def

=

^

^

(h : stiti[{i} : stit]p h : stiti[{j} : stit]p)

(6)

pP i,jAGT :i6=j
def

COMPL =

^

_

[ : stit]([{i} : stit]p [{i} : stit]p)

(7)

pP iAGT


def

GRID =

^

h : stiti

XP


^

p

pX

^

p

(8)

pP\X

Formulae EXC + EXC mean control atomic propositions P exclusive
(i.e., proposition P forced true false one
agent), whereas formula COMPL means exercise control atomic propositions
P complete (i.e., every proposition P exists least one agent either forces
true forces false). Finally, formula GRID means possible
truth-value combinations atomic propositions P possible. Note EXC + ,
EXC , COMPL GRID well-formed STIT formulae assumption
set P finite.13
define following translation LCLPC (P, AGT ) LSTIT (P, AGT ):
tr3 (p) = p

p P

tr3 () = tr3 ()
tr3 ( ) = tr3 () tr3 ()
tr3 (J ) = hAGT \ J : stititr3 ()
following theorem highlights bounded group STIT embeds CLPC. proof
given Appendix F.
13. assumption also made van der Hoek Wooldridge (2005).

108

fiThe Ceteris Paribus Structure Logics Game Forms

Theorem 7. Let = |P|. Then, CLPC formula CLPC-satisfiable
(EXC + EXC COMPL GRID ) tr3 () satisfiable STIT model
agent 2m actions.
CP embeds atemporal bounded group STIT (Theorem 3 Section 3.1), Theorem 7 follows CP also embeds CLPC. Indeed, given CLPC-satisfiable formula
, one use translation tr2 given Section 3.1 order find corresponding STIT
formula STIT-satisfiable. Then, one uses preceding translation tr3 order
find corresponding CP formula CP-satisfiable.
Corollary 3. Let = |P|. Then, CLPC formula CLPC-satisfiable
GRID tr2 ((EXC + EXC COMPL GRID ) tr3 ()) CP-satisfiable.
4.3 Directly Embedding CLPC CP
complete picture, study direct embedding CLPC CP.
Definition 6 (From CLPC CP models). Let = (P1 , . . . , Pn , X) CLPC-model.
Define MCP = (W, V ) follows:
W = 2P ;
V V (p) = {w | p w} p P.
Intuitively, V truth-assignment P witnessed exactly one
w W wX witness truth assignment represented X (i.e., makes
atoms X true rest false). MCP non-redundant universal CP model
MCP , X pointed CP-model (Definition 2). define following translation
LCLPC (P, AGT ), partition P1 , . . . , Pn P, LCP (P):
tr4 (p) = p

p P

tr4 () = tr4 ()
tr4 ( ) = tr4 () tr4 ()
tr4 (J ) = hYJ itr4 ()
YJ =



jAGT

Pj (i.e., atoms controlled anybody J).

Theorem 8. Let = (P1 , . . . , Pn , X) CLPC-model LCLPC (P, AGT ):
|=CLPC MCP , X |=CP tr4 ()
Proof. proceed induction syntax . Base Trivial construction
MCP (Definition 6). Step cases Boolean connectives straightforward.
focus modal case:
|=CLPC J MCP , X |=CP hYJ itr4 ()
109

fiGrossi, Lorini, & Schwarzentruber

YJ =



jN

Pj . case proven following series equivalences:

|=CLPC J XJ0 PJ :

L

XJ0 |=CLPC

Semantics J
XJ0 PJ : (P1 , . . . , Pn , XJ0 XAGT \J ) |=CLPC
L
Definition
XJ0 PJ : MCP , XJ0 XAGT \J |=CP tr4 ()
Definition 6 IH
YJ X MCP , |=CP tr4 ()
Definition 1
MCP , X |=CP hYJ itr4 ()
Definition 3

completes proof.

5. Ceteris Paribus Structure Dynamic Logic Propositional
Assignments
dynamic logic propositional assignments (DLPA) concrete variant propositional dynamic logic (PDL) (Harel et al., 2000) atomic programs assignments
propositional variables true false.14 complexities model checking
satisfiability problem DLPA recently studied Balbiani et al. (2013).
starless version DLPA previously studied van Eijck (2000) recently
put use Herzig et al. (2011), shown embeds CLPC. next
section study relationship CP DLPA. Specifically, provide truthpreserving embedding starless DLPA CP well truth-preserving embedding
CP DLPA.
DLPA, argued Herzig et al. (2011), represents general
direct link PDLnatural formalism reasoning agency.
results section, argue, point similar status CLPC, modulo use
Kleene star comment Section 7.

14. Programs standard PDL abstract letters a, b, . . . alphabet.

110

fiThe Ceteris Paribus Structure Logics Game Forms

5.1 Syntax Semantics DLPA
language DLPA built finite set atomic propositions P defined
following BNF:
::= +p | p | ; | | | ?
LDLPA (P) : ::= p | | ( ) | hi
use p denote (+p p).
Definition 7 (DLPA model). DLPA-model set X P.
is, DLPA model propositional valuation.
semantics given induction follows:
J+pK = {(X, X 0 ) | X 0 = X {p}};

JpK = {(X, X 0 ) | X 0 = X {p}};

J; 0 K = JK J 0 K;

J 0 K = JK J 0 K;

J K = kN JKk ;
J?K = {(X, X) | X JK};
JpK = {X | p X};
JK = 2P JK;
J K = JK JK;

JhiK = {X | exists X 0 s.th. (X, X 0 ) JK X 0 JK}.

write X |=DLPA X JK. refer fragment DLPA without
operator starless DLPA.
5.2 Properties DLPA
Like PDL, program constructors ; , ? eliminable:
Fact 2. following DLPA validities:
h; 0 hih 0
h 0 hi h 0
h?i
However, unlike PDL, operator also eliminable DLPA:
Fact 3 (Balbiani et al., 2013). every LCLPC (P) exists 0 LCLPC (P)
0 DLPA valid.
111

fiGrossi, Lorini, & Schwarzentruber

5.3 Embedding Starless DLPA CP
direct adaptation Definition 6 above, DLPA model X translated
pointed CP model MCP , X defined Definition 6. fix following translation:15
tr5 (p) = p

p P

tr5 () = tr5 ()
tr5 ( ) = tr5 () tr5 ()
tr5 (h+pi) = hP \ {p}i(p tr5 ())
tr5 (hpi) = hP \ {p}i(p tr5 ())
Notice translation starless DLPA CP need include cases
sequential composition (;), nondeterministic choice () test (?) since
eliminable DLPA. Therefore, guarantees CP could kind
reasoning starless DLPA:
Theorem 9. Let X DLPA model belong language starless DLPA:
X |=DLPA MCP , X |=CP tr5 ()
Proof. proceed induction syntax . Base Trivial construction
MCP (Definition 6). Step cases Boolean connectives straightforward.
focus modal case:
X |=DLPA h+pi MCP , X |=CP hP \ {p}itr5 ()
case proven following series equivalences:
X |=DLPA h+pi X {p} |=DLPA

Semantics h+pi

P{p} X : MCP , |=CP tr5 () Definition 1 IH
MCP , X |=CP hP \ {p}itr5 ()

Definition 3

case hpi identical.
5.4 Embedding CP Starless DLPA
subsection shown semantics CP DLPA closely related.
However, DLPA built-in assumption effect valuation (i.e., set
atoms) feasible. point view CP means DLPA actually works
universal models (cf. Definition 2). Here, establish embedding CP interpreted
universal models,16 starless DLPA. Consider following translation LCP (P)
15. must observed translation work P finite. not, {p} co-finite
{p} would belong LCP .
16. class models one axiomatize extending axiom system Figure 2 axioms
form hi ranges propositional formulae encoding one single valuation.

112

fiThe Ceteris Paribus Structure Logics Game Forms

LDLPA (P):
tr7 (p) = p

p P

tr7 () = tr7 ()
tr7 ( ) = tr7 () tr7 ()
tr7 (hXi) = hp1 . . . hpn itr7 ()
p1 , . . . , pn enumeration atoms P \ X.17 following result:
Theorem 10. Let CP-model LCP (P):
M, w |=CP w |=DLPA tr7 ()
Proof. proceed induction syntax . Base Trivial construction
MCP (Definition 6). Step cases Boolean connectives straightforward.
focus modal case:
M, w |=CP hXi w |=DLPA hp1 . . . hpn itr7 ()
p1 , . . . , pn enumeration atoms P\X. case proven following
series equivalences:
M, w |=CP hXi w0 X w s.t. M, w0 |=CP

Definition 1

w0 X w s.t. w0 |=DLPA tr7 ()

IH

w0 s.t. w0 = (. . . (wF{p1 })F . . .)F{pn }
w0 |=DLPA tr7 ()
w |=DLPA hp1 . . . hpn itr7 ()

Definition 1
Semantics DLPA

F {, }, p1 , . . . , pn enumeration atoms P X.
Theorem 10 obtain corollary satisfiability-preserving embedding CP
DLPA. Fix formula18


^
^
^
def
GRID =
hi
p
p
(9)
XP

pX

pP\X

which, easy see, forces CP-model contain propositional valuations P.
have:
Corollary 4. Let LCP (P). Then, tr7 () DLPA satisfiable iff GRID CP
satisfiable.
concludes presentation embeddings STIT, CLPC DLPA
CP (Figure 1). following section take stock commenting technical results
presented drawing links related work.
17. Again, crucial P finite.
18. Cf. Formula (8).

113

fiGrossi, Lorini, & Schwarzentruber

6. Discussion Related Work
section provide summary results presented discuss implications.
also position work respect existing contributions literature logic
games.
6.1 Discussion
paper introduced modal logic arises naturally interpreting modal operators equivalence relations induced finite sets propositional atoms. logic,
called CP, axiomatized embedded (exponentially) S5. CP
used tool compare three logics one-shot strategic interactionatemporal STIT,
coalitional logic propositional control CLPC dynamic logic propositional
assignments DLPA. logics embedded CP.
embeddings (recall Figure 1) put us position draw following
general remarks.
appears justified talk common ceteris paribus structure underpinning several main logics game forms embeddable CP.
illustrates striking uniformity logical tools needed expressing choice
effectivity games logical languages, CP appears offer well-suited
abstraction systematizing existing formalisms.
Furthermore, logics embeddable S5 (either directly via CP), highlighting fact order reason choice effectivity games one
essentially reasons suitably defined partitions state space.
New interesting far unexplored embeddings obtainable corollaries.
particular, follows results atemporal STIT bounded models
embedded starless DLPA via CP.
Via logic S5, one easily show embeddings directions also
possible (albeit exponential cost), arrows Figure 1 may actually
made symmetric. S5 embeds CP, also directly embeddable
mentioned logic, contain universal modality, following forms: hi
CP, hAGT \ : stiti atemporal STIT, AGT CLPC hp1 . . . hpn
DLPA (where p1 , . . . , pn enumeration P).
results unveil strikingand extent unexpecteduniformity
underpinning formalisms considered.
6.2 Related Work
review two sets related contributions.
6.2.1 CP Modal Ceteris Paribus Logics
two logics modal logic literature strictly related CP: release
logic, logic ceteris paribus preference.
114

fiThe Ceteris Paribus Structure Logics Game Forms

Release logic relatively less known formalism landscape modal logics
artificial intelligence. introduced studied Krabbendam Meyer (2003,
2000) order provide modal logic characterization general notion irrelevancy.
Modal operators release logic S5 operators indexed subsets finite set Iss
abstract elements denoting issues taken irrelevant, released,
evaluating formula scope operator. release model therefore tuple
(W, {rX }XIss , V ) rX equivalence relations additional constraint
X rX rY , is, releasing issues one obtains coarse
equivalence relation. Formally, semantics release operators:
M, w |= X w0 W : w rX w0 M, w0 |=
X Iss = (W, {rX }XIss , V ).
One easily observe that, Fact 1 (clause (ii)), CP models release models
Iss = P release relation rX =X . Vice versa, Iss = P, release
models CP models. consequence, logic hXi operators CP conservative
extension logic X release operators.
Preference logic also long concerned so-called ceteris paribus preferences,
is, preferences incorporating things equal condition. first logical
analysis preferences dates back Von Wrights work (1963), dyadic modal
operators studied representing statements like preferred , ceteris paribus.
recently, van Benthem et al. (2009) studied modal logic ceteris paribus preferences based
standard unary modal operators. Leaving preferential component logic aside,
ceteris paribus fragment concerns sentences form hi whose intuitive meaning
exists state equivalent current (evaluation) state respect
formulae (finite) set satisfies , formulae
atoms formulae full language. Logic CP is, therefore, fragment
ceteris paribus logic studied van Benthem et al. allowed consist
finite set atoms.
6.2.2 Contributions Systematization Game Logics
Despite wealth approaches found literature game logics,
papers attempted form comparison spanning across several formalisms,
attempting kind systematization. Two particular worth mentioning here.
recent one Herzigs work (2014), provides comprehensive
analysis field classifying existing logics depending aspects agency
(e.g., whether capture strategic interaction not, whether handle uncertainty
epistemic attitudes) capture languages. logics considered
paper, instance, would fall strategic uncertainty categories according
terminology used Herzig. analysis conceptual predominantly driven
syntactic features logics, is, theorems agency enable.
earlier work methodologically closer focus semantics
Goranko Jamrogas work (2004). paper compares ATL, epistemic variant ATEL
(epistemic ATL, van der Hoek & Wooldridge, 2003) ECL (extended CL,19 Pauly, 2001)
19. CL extended Kleene star operator.

115

fiGrossi, Lorini, & Schwarzentruber

providing constructive transformations models establishing, particular,
ATL subsumes ECL ATEL embedded ATL preserving satisfiability.

7. Conclusions Future Work
paper provided unification the, date, influential logics representation one-shot strategic interactionatemporal STIT, CLPC starless DLPA
ceteris paribus abstraction formalized logic CP.
One natural future research direction presents itself, consists extending logic
CP Kleene star operator, analogy DLPA. conjecture DLPA
embeddable CP Kleene star remains investigated whether new
logic could play unifying role logics extensive form games, show
plays atemporal case. complete systematization program initiated
current paper.
Related question, somewhat technical vein, shown
paper CP atemporal individual STIT high complexity
satisfiability problem consider whole languages. study efficient
syntactic fragments important intend pursue study parallel
CP atemporal individual STIT. expect several complexity results
fragments atemporal STIT may transferred fragments CP viceversa.

Acknowledgments
authors wish thank anonymous reviewers JAIR thorough helpful
comments. paper greatly improved thanks feedback.

Appendix A. Proof Claim () Theorem 1
Proof. One show REP derivable every operator [X] follows: first one shows
[X] operator satisfies Axiom K rule necessitation N.
provide syntactic proofs two claims. notational convenience use following abbreviation:


def
Yb =


^

p

pY

116

^
pX\Y

p

fiThe Ceteris Paribus Structure Logics Game Forms

1.

Derivation K [X]:


^
`CP [X]( )
Yb [] Yb ( )
X

2.

Reduce




`CP Yb ( ) (Yb ) (Yb )
P

3.

^

`CP





^
Yb [] Yb ( )
Yb [] (Yb ) (Yb )

X

X

4.

P, 2 rule RM [] (i.e., ` ` [] [])




^
^
`CP
Yb [] (Yb ) (Yb )
Yb [](Yb ) [](Yb )

5.

K P





^
^
Yb [](Yb ) [](Yb )
Yb [] Yb
`CP

X

X

X

X




^



Yb [] Yb




X

P
6.

^

`CP (





^
Yb [] Yb
Yb [] Yb ) ([X] [X])

X

X

Reduce
7.

`CP [X]( ) ([X] [X])
1 3-6
Derivation N [X]:

1.

`CP
hypothesis

2.

`CP []

3.

1 N []


^
`CP
[] Yb
X

4.

2 S5 theorem [] []( )


^
`CP
Yb [] Yb
X

3 P
5.

`CP [X]
4 Reduce MP

117

fiGrossi, Lorini, & Schwarzentruber

one proves REP derivable induction routine analogous one used
Chellas (1980, Thm. 4.7).

Appendix B. Proof Theorem 2
Let 0 CP-formula. equivalence 0 CP-satisfiable tr(0 )
S5-satisfiable.
Proof. Suppose exists CP-model = (W, V ) world w W
M, w |=CP 0 . Let V 0 valuation V modified p true exactly
worlds u M, u |=CP . Let M0 S5-model defined (W, V 0 ). standard
induction provides M0 , w |=S5 tr(0 ). precisely, let us prove induction
SF (0 ), M, u |=CP iff M0 , u |=S5 tr1 () u W .
Propositional case: atomic propositions p, M, u |=CP p iff u V (p) iff
u V 0 (p) iff M0 , u |=S5 tr1 (p).
Negation: M, u |=CP iff M, u 6|=CP iff M0 , u 6|=S5 tr1 () iff M0 , u |=S5 tr1 ().
Conjunction: M, u |=CP iff M, u |=CP M, u |=CP iff M0 , u |=S5 tr1 ()
M0 , u |=S5 tr1 () iff M0 , u |=S5 tr1 ( ).
Case formula form [X]:
M, u |=CP [X]
iff v W , u VX v implies M, v |=CP
iff v W , u VX v implies M0 , v |=S5 p
(by construction V 0 )
iff M0 , u |=S5 tr1 ([X])
V
construction V 0 , M0 , w |=S5 SF (0 ) (p tr1 ()). M, w |=CP 0
M0 , w |=S5 tr1 (0 ) thus M0 , w |=S5 p0 construction V 0 . result, M0 , w |=S5
tr(0 ).
Suppose exists S5 model M0 = (W, V ) world w W
0
, w |=S5 tr(0 ). define relations X X P Definition 1. Let
CP-model equal (W, V ). standard induction provides M, w |=CP 0 .
precisely, let us prove induction SF (0 ), M, u |=CP iff
M0 , u |=S5 tr1 () u W .
Propositional case: atomic propositions p, M, u |=CP p iff u V (p) iff
u V 0 (p) iff M0 , u |=S5 tr1 (p).
Negation: M, u |=CP iff M, u 6|=CP iff M0 , u 6|=S5 iff M0 , u |=S5 .
Conjunction: M, u |=CP iff M, u |=CP M, u |=CP iff M0 , u |=S5 tr1 ()
M0 , u |=S5 tr1 () iff M0 , u |=S5 tr1 ( ).
118

fiThe Ceteris Paribus Structure Logics Game Forms

Case formula form [X]:
M, u |=CP [X]
iff v W , u VX v implies M, v |=CP
iff v W , u VX v implies M0 , v |=S5 tr1 ()
(by induction)
iff v W , u VX v implies M0 , v |=S5 p
(because, M0 , w |=S5 tr(0 )
v W , M0 , v |=S5 (p tr1 ()))
iff M0 , u |=S5 tr1 ([X])
M0 , w |=S5 tr(0 ), M0 , w |=S5 (p0 tr1 (0 )) M0 , w |=S5 p0 . Thus,
M0 , w |=S5 tr1 (0 ). Hence M, w |=CP 0 .

Appendix C. Proof Theorem 3
Let us consider group STIT formula . Let integer. following items
equivalent:
1. satisfiable model agent 2m actions;
2. satisfiable model agent exactly 2m actions;
3. GRIDm tr2 () CP-satisfiable.
Proof. 1 2 Let M0 = (W 0 , {RJ0 }JAGT , V 0 ) STIT-model 2m actions
per agent w W 0 M0 , w |=STIT . construct sequence models
Mj = (W j , {RJj }JAGT , V j ) agents j 0 {1, . . . , j} exactly 2m actions
Mj Mj bisimilar Mj1 . construct Mj Mj1 follows.
j1
j1
j1
Let R{j}
(w1 ), . . . , R{j}
(wk ) enumeration R{j}
- classes (that is, actions agents
j1
j), k 2m . Let (Copy` )`{k+1,...,2m } family disjoint copies R{j}
(w1 ).
write uCv say u = v v copy u u copy v. model
Mj = (W j , {RJj }JAGT , V j ) defined follows:

W j = W j1 `{k+1,...,2m } Copy` ;
j
j1
R{j}
= R{j}




`{k+1,...,2m } {(u, v)

| u, v Copy` }

j
j1
0
R{j
0 } = C R{j 0 } C j 6= j;

V j (p) = {v W j | vCu u V j1 (p)}.
119

fiGrossi, Lorini, & Schwarzentruber

construction makes Mj Mj1 bisimilar induction
agents j 0 {1, . . . , j} exactly 2m actions Mj . Finally, Mn , w |=STIT
agent exactly 2m actions Mn .
23
Let
us
consider

STIT
model

= (W, {RJ }JAGT , V ) agent exactly 2 actions. Let w W
M, w |=STIT . j AGT , let R{j} (wj,1 ), . . . , R{j} (wj,2m ) enumeration R{j} -classes M. Let us extend V worlds R{j} (wj,i )
valuations atomic propositions Rj correspond binary digits binary
representation i. {1, . . . , m}:
[
R{j} (wj,i )
(10)
V (rep jd ) =
i=1..2m | dth digit 1

Independence agents ensures M, w |=CP GRIDm . prove M, u |=CP
tr2 () iff M, u |=STIT induction subformulae .
3 1 Let = (W, V ) CP-model w W M, w |=CP GRIDm
tr2 (). define RJ =SjJ Rj . resulting Kripke-model M0 = (W, {RJ }JAGT , V )
STIT-model agent exactly 2m actions. particular, satisfies
independence agents M, w |=CP GRIDm . prove M, u |=CP tr2 () iff
M0 , u |=STIT induction subformulae .

Appendix D. Proof Theorem 5
CP-nested satisfiability problem PSPACE-hard.
Proof. reduce satisfiability problem STIT-formulae coalitions taken
linear set coalitions, PSPACE-complete (Schwarzentruber, 2012)
CP-nested satisfiability problem: use translation tr2 Subsection 3.1. Let
STIT-formula. STIT-satisfiable iff tr2 () CP-satisfiable.
stated Schwarzentruber (2012), STIT coalitions taken
linear set coalitions exponential model property. result Theorem 3
true. Hence STIT-satisfiable GRIDm tr2 () CP-satisfiable (where
length ). Hence tr2 () CP-satisfiable.
Suppose exists CP-model = (W, V ) w W M, w |=
tr2 (). define RJ =SjJ . STIT model M0 = (W, (RJ )J , V )
M0 , w |= . Remark need specify relations RJ J. long
RJ specified coalitions J appear RJ RJ 0 J 0 J,
extend Kripke model M0 completely specified STIT-model also satisfying .20

Appendix E. Proof Theorem 6
CP-nested satisfiability problem PSPACE.
Proof. reduce CP-nested satisfiability problem satisfiability problem STIT
coalitions taken linear set coalitions. define AX = {jp p X}
20. See Schwarzentrubers paper (2012) details construnction.

120

fiThe Ceteris Paribus Structure Logics Game Forms

jp fresh agent corresponding atomic proposition p. Let us define following translation:
tr(p) = p;
tr() = tr();
tr( ) = tr() tr0 ();
tr([X]) = [AX : stit]tr().
Let us consider fixed CP-formula . recall signature X appears
exists formula hXi SF (). also define following formula
V
CON ROL = [ : stit] X appearing
V
pX (p [AX : stit]p) (p [AX : stit]p).
tr() CON ROL STIT-formula computable polynomial time
satisfies condition nesting groups (i.e., two operators [J : stit]
[J 0 : stit] occurring formula either J J 0 J 0 J). also
CP-satisfiable iff tr() CON ROL satisfiable STIT-model.
Suppose exists CP-model = (W, V ) w W
M, w |=CP . define RAX =X . STIT model M0 = (W, (RAX )X , V )
M0 , w |=STIT tr() CON ROL. Remark need specify
relations RJ J. long RJ specified coalitions J appear
tr() CON ROL RJ RJ 0 J 0 J, extend Kripke model M0
completely specified STIT-model also satisfying tr() CON ROL.21

Suppose


exists

STIT-model
M0 = (W, (RAX )X , V ) world w W M0 , w |=STIT tr() CON ROL.
M0 , w |= CON ROL, X = RAX . reason define =
(W, {X }X2P , V ). Consequently, M, w |=CP .

Appendix F. Proof Theorem 7
Let = |P|. Then, CLPC formula CLPC satisfiable (EXC +
EXC COMPL GRID ) tr3 () satisfiable STIT model agent
2m actions.
Proof. Let us suppose |P| = m.
Let = (P1 , . . . , Pn , X ) CLPC model |=CLPC ,
P1 , . . . , Pn partition P among agents AGT .
build STIT
model = (W, {RJ }JAGT , V ) follows:
W = {X : X P},
J AGT X, X 0 W , (X, X 0 ) RJ0 XJ = XJ0 ,
21. see Schwarzentrubers paper details construction.

121

fiGrossi, Lorini, & Schwarzentruber

p P X W , X V (p) p X,

X P J AGT , XJ = X PJ (with PJ = iJ Pi ). size
2m . follows number RAGT -equivalence classes (alias joint actions)
equal lower 2m . Consequently, number actions every agent bounded
2m .
straightforward prove X W M, X |=STIT EXC +
EXC COMPL GRID . Moreover, induction structure , prove
M, X |=STIT tr3 (). interesting case = J :
|=CLPC J iff exists XJ PJ s.t.



XJ |=CLPC

iff exists XJ PJ s.t.

M, XJ XAGT
\J |=STIT tr3 () (by I.H.)

iff M, X |=STIT hAGT \ J : stititr3 ()
Let = (W, {RJ }JAGT , V ) STIT model number actions
every agent bounded 2m w0 W M, w0 |=STIT (EXC + EXC
COMPL GRID ) tr3 ().
AGT , let



M, v |= [{i} : stit]p
Ctrl = p P : v W,


M, v |= [{i} : stit]p







set atoms P controlled agent i. J AGT , let Ctrl J =



iJ

Ctrli .

Lemma 3. J AGT , X P, X X w W have:
(i) CtrlJ = X CtrlAGT \J = P \ X,
V
V
(ii) M, w |=STIT p+ p p p CtrlJ = X then, v RJ (w),
X V
X
V
M, v |=STIT p+ p p p,
X

X

0
(iii) CtrlJ = X then, P\X
P\X, exists v RJ (w) M, v |=STIT
V
V
p

p.
0+
0
p
p
P\X

P\X

+

X P X X, X
= X X
= X \ X .

Proof. (i) Let us suppose p 6 CtrlJ . going prove p CtrlAGT \J .
p 6 CtrlJ follows w W M, v |=STIT p v RJ (w).
implies J w W M, w |=STIT [{i} : stit]p
[{i} : stit]p. M, w0 |=STIT COMPL follows AGT \ J
M, w |=STIT [{i} : stit]p [{i} : stit]p w W . latter implies
p CtrlAGT \J . direction (i.e., p CtrlJ implies p 6 CtrlAGT \J ) follows
M, w0 |=STIT EXC + EXC .
122

fiThe Ceteris Paribus Structure Logics Game Forms

(ii) Let us suppose M, w |=

V

+
pX

p

V


pX

p CtrlJ = X. fact

+
relations RJ reflexive, follows that, p X
, exists J

M, w |=STIT [{i} : stit]p p X exists J M, v |=STIT [{i} :
+
stit]p. latter follows p X
M, w |=STIT [J : stit]p

p V


M,
v
|=
[J
:
stit]p.
Therefore,
v RJ (w),
STIT
X
V
M, v |=STIT p+ p p p.
X

X

0
P\X
(iii) Let us suppose CtrlJ = X let us consider arbitrary P\X

w W .VFrom M, wV
|=
GRID

follows


exists
v

W


0
STIT
M, v |=STIT p0+ p p0 p. item (ii), latter implies exists
P\X
P\X
V
V
v W M, v |=STIT [AGT \J : stit]( p0+ p p0 p). constraint
P\X

P\X


V independence
V agents follows exists v RJ (w) M, v |=STIT
p

0+
p
p 0 p.
P\X

P\X

transform STIT model CLPC model = (P1 , . . . , Pn , X ) follows:
p P, p X w0 V (p),
p P AGT , p Pi p Ctrli .
item (i) Lemma 3 easy check indeed CLPC model.
particular, P1 , . . . , Pn partition P among agents AGT .
induction structure using Lemma 3 straightforward prove
|=CP . interesting case = J :
M, w0 |=STIT hAGT \ J : stititr3 ()
iff M, v |=STIT tr3 () v RAGT \J (w0 )
iff exists XJ PJ s.t.

(P1 , . . . , Pn , XJ XAGT
\J ) |=CP

(by I.H., items (ii) (iii)
Lemma 3)
iff |=CP J
completes proof.

References
Alur, R., Henzinger, T., & Kupferman, O. (2002). Alternating-time temporal logic. Journal
ACM, 49, 672713.
Areces, C., & Ten Cate, B. (2006). Hybrid logics. Blackburn, P., van Benthem, J., &
Wolter, F. (Eds.), Handbook Modal Logic, pp. 821868. Elsevier.
Balbiani, P., Gasquet, O., Herzig, A., Schwarzentruber, F., & Troquard, N. (2008a). Coalition games kripke semantics. Degremont, C., Keiff, L., & Ruckert, H. (Eds.),
Festschrift Honour Shahid Rahman, pp. 112. College Publications.
123

fiGrossi, Lorini, & Schwarzentruber

Balbiani, P., Herzig, A., & Troquard, N. (2008b). Alternative axiomatics complexity
deliberative stit theories. Journal Philosophical Logic, 37 (4), 387406.
Balbiani, P., Herzig, A., & Troquard, N. (2013). Dynamic logic propositional assignments:
well-behaved variant PDL. Proceedings 28th ACM/IEEE Symposium
Logic Computer Science (LICS 2013), pp. 143152. IEEE Computer Society.
Belnap, N., Perloff, M., & Xu, M. (2001). Facing future: agents choices
indeterminist world. Oxford University Press, USA.
Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal Logic. Cambridge University
Press, Cambridge.
Broersen, J. (2008). complete STIT logic knowledge action,
applications. Proceedings 6th International Workshop Declarative Agent
Languages Technologies (DALT 2008), Vol. 5397 LNCS, pp. 4759. SpringerVerlag.
Broersen, J., Herzig, A., & Troquard, N. (2005). coalition logic STIT. Lomuscio,
A., de Vink, E., & Wooldridge, M. (Eds.), Proceedings Third International
Workshop Logic Communication Multi-agent Systems (LCMAS05), pp.
2335.
Broersen, J., Herzig, A., & Troquard, N. (2006). Embedding alternating-time temporal logic
strategic STIT logic agency. Journal Logic Computation, 16 (5), 559578.
Broersen, J., Herzig, A., & Troquard, N. a. (2007). normal simulation coalition logic
epistemic extension. Samet, D. (Ed.), Proceedings TARK07, pp. 92101.
ACM Press.
Chellas, B. F. (1980). Modal Logic. Introduction. Cambridge University Press, Cambridge.
Dunne, P., van der Hoek, W., Kraus, S., & Wooldridge, M. (2008). Cooperative boolean
games. Proceedings AAMAS 2008, pp. 10151022. ACM.
Gabbay, D. M., Kurucz, A., Wolter, F., & Zakharyaschev, M. (2003). Many-dimensional
modal logics: theory applications. Elsevier.
Gasquet, O., & Herzig, A. (1994). Translating non-normal modal logics normal modal
logics.. Jones, A., & Sergot, M. (Eds.), Proceedings International Workshop
Deontic Logic Computer Science (DEON94).
Gerbrandy, J. (2006). Logics propositional control. Proceedings AAMAS06, pp.
193200. ACM.
Goldblatt, R. (1992). Logics Time Computation. CSLI.
Goranko, V. (2001). Coalition games alternating temporal logics. Proceedings
8th conference theoretical aspects rationality knowledge (TARK01), pp.
259272.
Goranko, V., & Jamroga, W. (2004). Comparing semantics logics multi-agent systems.
Synthese, 139, 241280.
124

fiThe Ceteris Paribus Structure Logics Game Forms

Goranko, V., Jamroga, W., & Turrini, P. (2013). Strategic games truly playable effectivity functions. Journal Autonomous Agents Multi-Agent Systems, pp.
288314.
Harel, D., Kozen, D., & Tiuryn, J. (2000). Dynamic Logic. MIT Press.
Harrenstein, P., van der Hoek, W., Meyer, J., & Witteveen, C. (2001). Boolean games.
van Benthem, J. (Ed.), Proceedings TARK01, pp. 287298. Morgan Kaufmann.
Herzig, A. (2014). Logics knowledge action: critical analysis challenges. Journal
Autonomous Agents Multi-Agent Systems, DOI: 10.1007/s10458-014-9267-z.
Herzig, A., Lorini, E., Moisan, F., & Troquard, N. (2011). dynamic logic normative
systems. Walsh, T. (Ed.), Proceedings Twenty-Second International Joint
Conference Artificial Intelligence (IJCAI 2011), pp. 228233. AAAI Press.
Herzig, A., & Schwarzentruber, F. (2008). Properties logics individual group
agency. Advances modal logic, 7, 133149.
Horty, J. F. (2001). Agency Deontic Logic. Oxford University Press, Oxford.
Krabbendam, J., & Meyer, J. (2003). Contextual deontic logics. McNamara, P., &
Prakken, H. (Eds.), Norms, Logics Information Systems, pp. 347362, Amsterdam. IOS Press.
Krabbendam, J., & Meyer, J. (2000). Release logics temporalizing dynamic logic, orthogonalising modal logics. Barringer, M., Fisher, M., Gabbay, D., & Gough, G.
(Eds.), Advances Temporal Logic, pp. 2145. Kluwer Academic Publisher.
Lorini, E., & Schwarzentruber, F. (2011). logic reasoning counterfactual emotions. Artificial Intelligence, 175 (3-4), 814847.
McCann, H. J. (1974). Volition basic action. Philosophical Review, 83, 451473.
Moulin, H., & Peleg, B. (1982). Cores effectivity functions implementation theory.
Journal Mathematical Economics, 10, 115145.
Osborne, M. J., & Rubinstein, A. (1994). Course Game Theory. MIT Press.
OShaughnessy, B. (1974). Trying (as mental pineal gland). Journal Philosophy,
70, 365386.
Pauly, M. (2001). logical framework coalitional effectivity dynamic procedures.
Bulletin Economic Research, 53 (4), 305324.
Pauly, M. (2002). modal logic coalitional power games. Journal Logic
Computation, 12 (1), 149166.
Schwarzentruber, F. (2012). Complexity results STIT fragments. Studia logica, 100 (5).
Tseitin, G. (1968). complexity derivation propositional calculus.. Structures
Constructive Mathematics Mathematical Logic, Part II, Seminars Mathematics (translated Russian). Steklov Mathematical Institute.
van Benthem, J., Girard, P., & Roy, O. (2009). Everything else equal: modal logic
ceteris paribus preferences. Journal Philosophical Logic, 38, 83125.
125

fiGrossi, Lorini, & Schwarzentruber

van der Hoek, W., & Pauly, M. (2007). Modal logic games information. Blackburn,
P., van Benthem, J., & Wolter, F. (Eds.), Handbook Modal Logic, pp. 10771146.
Elsevier.
van der Hoek, W., & Wooldridge, M. (2003). Cooperation, knowledge time: Alternatingtime temporal epistemic logic applications. Studia logica, 75 (1), 125157.
van der Hoek, W., & Wooldridge, M. (2005). logic cooperation propositional
control. Artificial Intelligence, 164, 81119.
van Ditmarsch, H., Kooi, B., & van der Hoek, W. (2007). Dynamic Epistemic Logic, Vol.
337 Synthese Library Series. Springer.
van Eijck, J. (2000). Making things happen. Studia logica, 66 (1), 4158.
Von Wright, G. H. (1963). Logic Preference. Edinburgh University Press.
Walther, D., van der Hoek, W., & Wooldridge, M. (2007). Alternating-time temporal logic
explicit strategies. Proceedings 11th conference Theoretical Aspects
Rationality Knowledge, pp. 269278. ACM Press.
Wang, Y., & Cao, Q. (2013). axiomatizations public announcement logic. Synthese,
190, 103134.
Wansing, H. (2006). Tableaux multi-agent deliberative-STIT logic. Governatori, G.,
Hodkinson, I., & Venema, Y. (Eds.), Advances Modal Logic, Volume 6, pp. 503520.
Kings College Publications.
Xu, M. (1998). Axioms deliberative STIT. Journal Philosophical Logic, 27, 505552.

126

fiJournal Artificial Intelligence Research 53 (2015) 223-270

Submitted 12/14; published 06/15

Probabilistic Inference Techniques Scalable
Multiagent Decision Making
Akshat Kumar

akshatkumar@smu.edu.sg

School Information Systems
Singapore Management University, Singapore

Shlomo Zilberstein

shlomo@cs.umass.edu

College Information Computer Sciences
University Massachusetts, Amherst, USA

Marc Toussaint

marc.toussaint@informatik.uni-stuttgart.de

Department Computer Science
University Stuttgart, Germany

Abstract
Decentralized POMDPs provide expressive framework multiagent sequential decision making. However, complexity modelsNEXP-Complete even two
agentshas limited scalability. present promising new class approximation algorithms developing novel connections multiagent planning machine
learning. show multiagent planning problem reformulated inference
mixture dynamic Bayesian networks (DBNs). planning-as-inference approach
paves way application efficient inference techniques DBNs multiagent
decision making. improve scalability, identify certain conditions sufficient extend approach multiagent systems dozens agents. Specifically,
show necessary inference within expectation-maximization framework
decomposed processes often involve small subset agents, thereby facilitating
scalability. show number existing multiagent planning models satisfy
conditions. Experiments large planning benchmarks confirm benefits
approach terms runtime scalability respect existing techniques.

1. Introduction
Decentralized partially observable MDPs (Dec-POMDPs) emerged recent years
prominent framework modeling sequential decision making team collaborating agents (Bernstein, Givan, Immerman, & Zilberstein, 2002). expressive power
makes possible tackle coordination problems agents must act based different partial information environment maximize
global reward function. Applications Dec-POMDPs include coordinating operation
planetary exploration rovers (Becker, Zilberstein, Lesser, & Goldman, 2004), coordinating
firefighting robots (Oliehoek, Spaan, & Vlassis, 2008), target tracking team sensor
agents (Nair, Varakantham, Tambe, & Yokoo, 2005) improving throughput wireless
networks (Pajarinen, Hottinen, & Peltonen, 2014).
rapid progress exact algorithms Dec-POMDPs (Oliehoek,
Spaan, Amato, & Whiteson, 2013), optimal solutions obtained relac
2015
AI Access Foundation. rights reserved.

fiKumar, Zilberstein, & Toussaint

tively smaller problems. terms computational complexity, optimally solving finitehorizon Dec-POMDP NEXP-Complete (Bernstein et al., 2002). contrast, finite-horizon
POMDPs PSPACE-complete (Mundhenk, Goldsmith, Lusena, & Allender, 2000),
strictly lower complexity class highlights difficulty solving Dec-POMDPs.
1.1 Related Work
finite-horizon case, substantial number promising point-based approximate
algorithms developed (Kumar & Zilberstein, 2010b; Wu, Zilberstein, & Chen,
2010; Dibangoye, Mouaddib, & Chaib-draa, 2009; Kumar & Zilberstein, 2009a; Seuken &
Zilberstein, 2007). However, unlike point-based counterparts POMDPs (Pineau,
Gordon, & Thrun, 2006; Smith & Simmons, 2004), cannot easily adopted
infinite-horizon case due variety reasons. example, POMDP algorithms represent
policy compact -vectors, whereas Dec-POMDP algorithms explicitly store
policy mapping observation sequences actions, making unsuitable
infinite-horizon case. motivated development alternative approaches,
approximating factored finite-horizon Dec-POMDPs series collaborative graphical
Bayesian games (Oliehoek, Whiteson, & Spaan, 2013) using genetic algorithms (Eker &
Akin, 2013).
Recently, number approaches developed transform Dec-POMDP
continuous-state MDP use techniques POMDP literature solve
continuous-state MDP (Dibangoye, Amato, Doniec, & Charpillet, 2013a; Dibangoye,
Amato, Buffet, & Charpillet, 2013b). state continuous MDP reformulation
Dec-POMDP, also called occupancy state, probability distribution world state
history observations agent received. Despite adoption efficient
POMDP techniques reformulation, drawback approach size
observation histories increases exponentially respect plan horizon. contrast,
approach uses notion finite-state controllers (FSCs) summarize relevant
features planning problem. Often, compact FSCs provide good approximation
large planning problems. occupancy state based formulation also applied
infinite-horizon problems converting infinite-horizon problem approximate
finite-horizon version. done using future reward discount factor derive
finite-horizon H remaining rewards negligible contribution
overall value function (Dibangoye, Buffet, & Charpillet, 2014). drawback
truncated horizon approach that, high discount factors, required horizon H
prohibitively large.
terms solution representation, algorithms infinite-horizon problems represent agent policies finite-state controllers (Amato, Bernstein, & Zilberstein, 2010; Bernstein, Amato, Hansen, & Zilberstein, 2009), unlike algorithms finite-horizon problems
often use policy trees (Hansen, Bernstein, & Zilberstein, 2004). resulting solution
approximate limited memory controllers optimizing
action selection transition parameters extremely hard. Previous approaches
optimize finite-state controller based policies include decentralized bounded policy iteration (DEC-BPI) (Bernstein et al., 2009) technique based non-linear programming
(NLP) (Amato et al., 2010). DEC-BPI algorithm uses linear programming formula224

fiProbabilistic Inference Multiagent Decision Making

tion improve parameters one node one finite-state controller time.
is, fixes parameters nodes controllers, except single node
particular agent. uses linear program find better action selection transition
parameters particular node. LP guarantees policy value increased
every belief state. major drawback scheme designed optimize value particular belief state. Therefore, produce good policy, DEC-BPI
may need large number controller nodes, reduces effectiveness LP
formulation.
contrast DEC-BPI approach, NLP formulation Amato et al. (2010)
optimize controllers given initial belief state. formulation linear objective
function. However, Bellman constraints, involve additional variables representing
value node, nonlinear non-convex variables. cause
NLP solver get stuck local optimum. Furthermore, empirically observed
performance state-of-the-art NLP solvers SNOPT (Gill, Murray, & Saunders,
2002) degrades quickly even moderate increase number nonlinear constraints.
highlights challenges presented scaling NLP approach larger ( 2 agents)
problems. complementary research direction investigate kind structure
controller enable better quality solutions. example, layered controllers
developed POMDPs Dec-POMDPs, optimized point based
approaches (Pajarinen & Peltonen, 2011b). EM based planning algorithms develop
work also take advantage controller structures. approaches
compute policies infinite-horizon Dec-POMDPs based controller
representation joint-policy (MacDermed & Isbell, 2013). However, key advantage
policies based finite-state controllers ease execution resource constrained
environments (Grzes, Poupart, & Hoey, 2013; Grzes, Poupart, Yang, & Hoey, 2015), without
expensive belief update operations required approaches. Furthermore, policies
represented finite-state controllers carry semantic information,
controller node summarizes relevant aspects observation history.
Generalizing Dec-POMDP algorithms two agents persistent
challenge problem representation algorithmic viewpoints. Many recent attempts increase scalability planners respect number agents impose
restrictions form interaction among agents. Examples restrictions include transition independence (Becker et al., 2004; Nair et al., 2005), weak-coupling among
agents limited certain states (Varakantham, Kwak, Taylor, Marecki, Scerri, &
Tambe, 2009), directional transition dependence (Witwicki & Durfee, 2010). One
earliest models demonstrated scalability limiting interactions among agents
transition-independent Dec-MDP (TI-Dec-MDP) (Becker, Zilberstein, Lesser, & Goldman,
2003). Agents models fully affect observe local state, cannot
affect local states observations agents. dependence among agents limited joint reward function. restricted model shown NP-Complete
Goldman Zilberstein (2004), also conducted detailed complexity analysis
different subclasses Dec-POMDPs various limitations agent interactions. extension TI-Dec-MDP proposed Becker, Zilberstein, Lesser (2004), introducing
structured transition dependencies.
225

fiKumar, Zilberstein, & Toussaint

TI-Dec-MDP model extended handle partial observability problem
instance Nair et al. (2005), resulting model called network-distributed POMDP
(ND-POMDP). shown value function ND-POMDPs factorizes among
smaller sub-groups agents based immediate reward decomposability. property
used develop number algorithms scale relatively well respect
number agents (Nair et al., 2005; Varakantham, Marecki, Yabu, Tambe, & Yokoo, 2007;
Marecki, Gupta, Varakantham, Tambe, & Yokoo, 2008). Another restricted class models
transition-decoupled POMDP (TD-POMDP) (Witwicki & Durfee, 2010). model
explicitly differentiates agents private state affected
agents local action shared states affected agents. Structured
interactions also used deciding communicate among agents (Mostafa
& Lesser, 2009, 2011). Within framework multiagent MDPs (MMDPs), submodularity property value function class sensor network planning problems
exploited Kumar Zilberstein (2009b).
large, models try identify restrictions agent interactions
facilitate scalable planning. exception work Witwicki Durfee (2011),
much work towards general characterization conditions
multiagent planning made scalable. Witwicki Durfee provide characterization
weak-coupling among agents similar work. However, significant difference
propose concrete algorithm efficiently exploit weak-coupling among
agents enable scalability large multiagent systems. algorithmic outline presented
Witwicki Durfee exploit weak interactions among agents mapping policy
optimization problem constraint optimization scalable involves enumerating
policy space agents.
article extends two conference papers published UAI10 (Kumar & Zilberstein,
2010a) IJCAI11 (Kumar, Zilberstein, & Toussaint, 2011) detailed background, new theorems proofs, simplified EM derivations, detailed derivation
EM updates ND-POMDP model. EM based policy optimization approach
developed foundation several efforts explore different aspects multiagent planning. example, Wu, Zilberstein, Jennings (2013) developed samplingbased E-step inference techniques. technique particularly useful model-free
setting underlying model known. Pajarinen Peltonen (2011a) extend EM approach factored Dec-POMDPs. present approximation
E-step using factored representation forward backward messages defined
Section 4.4. approach increases scalability EM algorithm w.r.t. number agents problem parameters expense making EM algorithm
approximate. is, E steps approximate may lead non-monotonic
improvement policy value. Pajarinen Peltonen (2013) extend EM
approach average reward Dec-POMDPs.
techniques present article differ previous approaches
rather approximating computationally challenging inference larger multiagent
systems, explore natural ways decompose inference process produce
exact, yet scalable EM algorithm. show necessary conditions
value factorization based decomposition satisfied several existing planning models,
confirming generality developed framework.
226

fiProbabilistic Inference Multiagent Decision Making

1.2 Summary Contributions
present promising new class algorithms combines planning probabilistic inference opens door application rich inference techniques solving
infinite-horizon Dec-POMDPs. approach based Toussaint et. al.s approach
transforming single-agent planning problem equivalent mixture dynamic Bayes
nets (DBNs) using likelihood maximization framework optimize policy
value (Toussaint & Storkey, 2006; Toussaint, Harmeling, & Storkey, 2006). approaches
successful solving MDPs POMDPs (Toussaint et al., 2006) easily extend factored hierarchical structures (Toussaint, Charlin, & Poupart, 2008).
Furthermore, handle continuous action state spaces thanks advanced probabilistic inference techniques (Hoffman, Kueck, de Freitas, & Doucet, 2009b). show
Dec-POMDPs, much harder solve MDPs POMDPs, also
reformulated mixture DBNs. present Expectation Maximization (EM)
algorithm (Dempster, Laird, & Rubin, 1977) maximize reward likelihood
policy value framework. approach offers attractive anytime algorithm EM improves likelihoodand hence policy valuewith iteration.
experiments benchmark domains show EM compares favorably previous
approaches optimize FSCs, DEC-BPI NLP-based optimization.
address scalability respect number agents, identify conditions
based value function factorization sufficient make planning amenable
scalable approximation. achieved constructing graphical model exploits
locality interactions among agents. show efficiently extend likelihood
maximization paradigm generalized graphical model. Furthermore, show
necessary inference decomposed processes involve small subset
agentsaccording interaction graphthereby facilitating scalability. derive
global update rule combines local inferences monotonically increase overall
solution quality. Several existing multiagent planning models shown satisfy
conditions, thereby validating generality value factorization property.
benefit approach amenable massively parallel implementation, since
relies local computations message-passing among neighboring agents.
Experiments large multiagent planning benchmark, joint state joint action
spaces 522 , 320 respectively, confirm approach scalable respect
number agents provide good quality solutions planning problems 20
agents, cannot handled best existing approaches. smaller multiagent
systems, approach provides better solution quality order-of-magnitude
faster previous best nonlinear programming approach optimizing FSCs.

2. Decentralized POMDP Model
Dec-POMDP model natural extension MDPs POMDPs. defined
tuple hI, S, {Ai }, P, R, {Y }, O, i, where:
denotes finite set n agents
denotes finite set states designated initial state distribution 0
227

fiKumar, Zilberstein, & Toussaint

Ai denotes finite set actions agent
P denotes state transition probabilities: P (s0 |s, ~a), probability transitioning
state s0 joint-action ~a taken agents
R denotes reward function: R(s, ~a) immediate reward state
joint-action taken ~a
denotes finite set observations agent
denotes observation probabilities: O(~y |s0 , ~a) probability receiving
joint-observation ~y last joint-action taken ~a resulted environment state s0
denotes reward discounting factor
agent policy, : Ai , maps set possible observation histories
actions. Solving Dec-POMDP entails finding joint-policy = h 1 , . . . , n
maximizes total expected reward.
X




E
R st , ~at ;

(1)

t=0

denotes joint-policy subscript denotes dependence time.
Dec-POMDP, agents acting uncertainty underlying environment state also other. Although joint-observation received agents
may correlated, agent observes component joint-observation.
makes coordination problem particularly challenging. Section 2.1, show
compact representation policy finite-state controllers, rather long sequences
observations.
two agents given multiagent system, adopt simplified notation
follows. action set agent 1 denoted agent 2 b B.
state transition probability P (s0 |s, a, b) depends upon actions agents.
Upon taking joint-action ha, bi state s, agents receive joint-reward R(s, a, b).
finite set observations agent 1 Z agent 2. O(yz | s, a, b) denotes
probability P (y, z|s, a, b) agent 1 observing agent 2 observing z Z
joint-action ha, bi taken resulted state s. infinite-horizon Dec-POMDPs,
reward discounting factor < 1 used.
2.1 Finite State Controllers
case infinite-horizon Dec-POMDPs, agents operate continuously immediate reward R discounted factor < 1. Representing agents local policies using
explicit tree structured representation feasible case. Therefore, agents
policies represented cyclic finite-state controllers (FSC).
represent agents policy bounded, finite state controller (FSC). approach used successfully POMDPs (Poupart & Boutilier, 2003; Amato,
Bernstein, & Zilberstein, 2007) Dec-POMDPs (Amato et al., 2010). case,
228

fiProbabilistic Inference Multiagent Decision Making

y1

z1

p2

q2
y2

y2

z2

z2
( )

p1 (a, p)

q1
z1

y1
Agent 1

Agent 2

Figure 1: two-agent infinite-horizon joint-policy represented using finite-state controllers.
node memory state. Edges represent node transition function. Agent
1 two observations, y1 y2. Agent 2 also two observations, z1 z2.
agent finite internal memory state, q Qi , summarizes crucial information obtained past observations support efficient action selection. size
set Qi determines expressiveness FSC based policy. POMDPs, FSCs
beneficial due compactness relative ease policy execution compared
full belief world states. Dec-POMDPs, belief world states cannot maintained
execution time due lack availability joint-observations. Therefore, FSCs
particularly useful executing FSC-based policies require maintaining belief
world states.
FSC ith agent parameterized = ( , , ) explained below.
agent chooses actions depending internal state q: P (a|q; ) = a,q .
internal state updated new observation, node transition function:
P (q 0 |q, y; ) = q0 ,q,y .
Finally, q0 initial node distribution P (q0 ) agent.

Figure 1 shows structure controllers two agents. action selection
parameter node transition parameter could deterministic stochastic.
optimize stochastic controllers work generally produce higher
values (Poupart & Boutilier, 2003).
Figure 2 shows complete DDN representation two-agent Dec-POMDP depicting
environment agents policies interact other. use convention
subscripts denote time superscripts, any, identify agents.
2.2 Objective Function
Considering two-agent case, denote controller nodes agent 1 p
agent 2 q. value starting controllers nodes hp, qi state given by:
X
V (p, q, s) =
a,p b,q
a,b

h

X
X
X
R(s, a, b) +
P (s0 | s, a, b)
O(yz | s0 , a, b)
p0 ,p,y q0 ,q,z V (p0 , q 0 , s0 )
s0

y,z

229

p0 q 0

fiAgent 1

Kumar, Zilberstein, & Toussaint

p1

p0
a0
s0

b0
Agent 2

y1

s1

a0
s0

z1
q1

q0

p1

p0

y1

s1
b0

p2
a1
s2

z1

b1

q1

q0

r0

Figure 2: two-time slice dynamic decision network (DDN) representation
two-agent
p1
Dec-POMDP. nodes random variables. Square nodes represent decisions;
diamond nodes represent reward; p q represent states policy
y1
agent 0 1 respectively; subscripts denote time. a0
goal set parameters h, , agents controllers
(of given size)
s1
maximize expected discounted reward initial belief 0 :
V (0 ) =

X

p q 0 (s)V (p, q, s) b0

z1

p,q,s

3. Dec-POMDPs Mixture DBNs

q1

section, describe Dec-POMDPs reformulated mixture DBNs,
maximizing reward likelihood defined equivalent optimizing
joint-policy. approach based framework proposed Toussaint et al. (2006)
Toussaint Storkey (2006) solve Markovian planning problems using probabilistic
inference. section, develop planning-as-inference strategy two-agent DecPOMDPs later extend multiple ( 2) agents. previous approach Toussaint
et al. (2006) Toussaint Storkey (2006) focused single agent MDPs POMDPs.
work, develop new mixture models allow us extend planning-asinference paradigm multiple agents, significant generalization single agent case.
First, briefly describe intuition behind reformulation describe
detail necessary modifications required Dec-POMDPs.
Dec-POMDP described using single DBN reward emitted
time step, unrolled DBN corresponding one shown Figure 2.
However, approach, described infinite mixture special type DBNs
reward emitted end. one mixture component
time period = 0 . Furthermore, simulate discounting rewards,
probability , acts mixture weight, set P (T = t) = (1 ). also
230

y2

z2
q2

fiProbabilistic Inference Multiagent Decision Making

p0

a0
s0

=0

r
b0

q0
p1

a0
s0

y1

s1
b0

Agent2

a0

p1

p0

z1

q1

q0
r0

Mixture finite-time Dec-POMDPs

Agent1

p0

s0

y1

s1
b0

z1

q1

p0

p1

a0

y1

s1
b0

b1

a1

p2

pT

y2

yT

s2
z1

q1

q0

=1

r

q0

s0

a1

b1


r

sT
z2

zT

q2

qT

bT

Figure 3: time-dependent DBN mixture (right) corresponding two-agent DecPOMDP (left). first DBN component mixture corresponds
reward time step 1, second DBN corresponds reward time step 2.
last DBN mixture shows general structure -step DBN.

231

fiKumar, Zilberstein, & Toussaint

P
ensures mixing weights normalized
t=0 P (T = t) = 1. describe
structure mixture component single -step DBN.
first DBN DBN mixture model shown Figure 3 describes DBN
time = 0. key intuition reward emitted time step ,
separate DBN general structure shown last -step DBN shown
Figure 3. DBN shows reward obtained time step depends policy
parameters underlying Dec-POMDP model.
random variable r shown DBN mixture Figure 3 binary variable
conditional distribution (for time ) described using normalized immediate
reward as:
Rsab = P (r = 1|sT = s, = a, bT = b) = (Rsab Rmin )/(Rmax Rmin ).
parameter Rmax maximum reward state action pair given DecPOMDP instance Rmin denotes minimum reward. scaling reward
key transforming optimization problem realm planning likelihood
maximization stated below. Let denote joint parameters h, , agents
controller.
Theorem 1. choosing conditional probability binary rewards r Rsab
Rsab introducing discounting time prior P (T ) = (1 ), joint-policy value V
relates linearly likelihood L observing reward variable 1:
V =

(Rmax Rmin )L
Rmin
+
(1 )
1

Proof. value function defined as:
V



X




=E
R st , ~at ;

(2)

t=0

Consider -step DBN mixture Figure 3. define likelihood time
step DBN follows:
LT = P (r = 1|T ; )

(3)

full mixture corresponding Dec-POMDP, have:
L =

X


P (T )LT = (1 )

X

P (r = 1|T ; )

(4)



already chose P (r = 1|sT = s, = a, bT = b) = (Rsab Rmin )/(Rmax Rmin ). Therefore,
using construction -step DBN, have:


E R(sT , ~aT ) Rmin
P (r = 1|T ; ) =
(5)
Rmax Rmin
232

fiProbabilistic Inference Multiagent Decision Making

Substituting back result expression L , get:


X E R(sT , ~aT Rmin


L = (1 )

Rmax Rmin
=


)V

(1
Rmin
Rmax Rmin

(6)
(7)

used linearity expectation
X



X

E R(sT , ~aT = E
R(sT , ~aT





Combining result definition value function Eq. (2), theorem
proved.
Using result, establish following result.
Lemma 1. Maximizing likelihood L = P (r = 1; ) mixture DBNs equivalent
optimizing Dec-POMDP policy.
Theorem 1 Lemma 1 show policy optimization problem reformulated
parameter learning problem suitable DBN mixture. immediately suggests
using machine learning approaches maximize likelihood. Furthermore, reformulation lossless sense optimizing likelihood would exactly optimize
joint-policy value. note never explicitly create mixture DBNs.
computations DBN mixture implemented message-passing original Dec-POMDP DDN Figure 2. additional computational requirement
scaling rewards using Rmax Rmin , done easily linear time.
next present Expectation-Maximization (EM), well known technique maximize likelihood.

4. Policy Optimization via Expectation Maximization
section describes application EM algorithm (Dempster et al., 1977)
maximizing reward likelihood mixture DBNs representing Dec-POMDP.
EM also possesses desirable anytime characteristic likelihood (and policy
value proportional likelihood) guaranteed increase per iteration
convergence. note EM guaranteed converge global optimum. However,
experiments show EM almost always achieves similar values NLP based
solver optimize FSCs (Amato et al., 2010) much better DEC-BPI (Bernstein
et al., 2009). Key potential advantages using EM lie ability easily generalize
much richer representations currently possible Dec-POMDPs hierarchical
controllers (Toussaint et al., 2008), continuous state action spaces (Hoffman et al.,
2009b). Another important advantage ability generalize solver larger multiagent systems 2 agents exploiting relative independence among
agents, show later sections.
233

fiKumar, Zilberstein, & Toussaint

l(; x)

Q( 2 , )

Q( 1 , )

2
1

Parameter space

Figure 4: coordinate ascent strategy EM algorithm
4.1 Overview EM Algorithm
first provide high level overview EM algorithm followed detailing adaptation planning Dec-POMDPs. EM algorithm general approach problem
maximum likelihood (ML) parameter estimation models latent variables.
given latent variable model, let X denote observable variables Z denote hidden
variables. Let denote model parameters. ML problem solve following
optimization problem:
X
max l(; x) = max log
p(x, z; )
(8)




z

hard optimize problem summation inside log. Furthermore,
maximizing log-likelihood l(; x) generally non-convex optimization problem
shown Figure 4. Therefore, EM algorithm iteratively performs coordinate ascent
parameter space. First, EM algorithm computes lower bound function
l(; x) lower bound touches l(; x), say point 1 . lower bound
denoted Q(1 , ), defined as:
X
X
Q(1 , ) =
p(z|x; 1 ) log p(x, z; )
p(z|x; 1 ) log p(z|x; 1 )
(9)
z

z

last term expression entropy variable Z|x. Figure 4 shows
lower bound Q(1 , ) blue curve. function Q(1 , ) also called expected complete
log-likelihood. Importantly, lower bound Q concave parameters thus,
optimized globally provide better parameter estimate 2 . process also shown
Figure 4. coordinate ascent continues iteratively defining new lower bound
Q(2 , ) point 2 also shown Figure 4, optimizing yield next
better parameter estimate convergence.
connect iterative maximization strategy planning Dec-POMDPs,
note likelihood function directly proportional joint-policy value policy
234

fiProbabilistic Inference Multiagent Decision Making

parameters (see Theorem 1). Therefore, adapting EM approach Dec-POMDPs,
need perform following steps:
1. (E-step) Formulate expected complete log-likelihood Q(i , ) DBN mixture
model Figure 3 iteration
2. (M-step) Maximize Q(i , ) w.r.t. yield better policy parameters i+1
3. Repeat steps 1 2 convergence, i.e., i+1
next explain steps 1 2 implemented specifically Dec-POMDPs.
4.2 Step 1: Formulating Expected Log-Likelihood Q(, ? )
DBN mixture Figure 3, every variable hidden observed data
binary reward variable r = 1. particular DBN time step ,
last DBN mixture Figure 3, let L = (P, Q, A, B, S, Y, Z) denote latent
variables T-step DBN, variable denotes sequence length . is,
P = p0:T , denotes -step long sequence controller state pt agent 1. EM maximizes
following expected complete log-likelihood Dec-POMDP DBN mixture. Let
denote previous iterations parameters ? denotes new parameters. expected
log-likelihood (ignoring entropy term independent ? ) given as:
Q(, ? ) =

X
X

P (r = 1, L, ; ) log P (r = 1, L, ; ? )

(10)

=0 L

rest section, derivations refer general -step DBN structure
shown Figure 3. also adopt convention random variable v, v 0 refers
next time slice v refers previous time slice. group variables v,
Pt (v, v0 ) refers P (vt = v, vt+1 = v0 ). joint probability variables is:






P (r = 1, L, ; ) = P (T ) Rsab t=T
ap bq Pssab Oyzsab ppy qqz
t=1



ap bq p q 0 (s) t=0

(11)



brackets indicate time slices, i.e., Rsab t=T = R(sT , , bT ). also used
shorthand Pssab = P (s|s, a, b); similarly Oyzsab . Taking log, get:
log P (r = 1, L, ) = . . . +

+


X
t=0

X

log pt +


X

log bt qt

t=0

log pt pt1 yt +

t=1


X

log qt qt1 zt + log p0 + log q0

(12)

t=1

missing terms represent quantities independent , affect
maximization . policy parameters h, , get separated
agent log above, expression expected log-likelihood also formulated
235

fiKumar, Zilberstein, & Toussaint

separately action parameters, controller node transition parameters initial node
distribution. action parameters agent, simplified expression as:
Qa,p (, ? ) =


X

P (T )

X
X

?
P (r = 1, = a, pt = p|T ; ) log ap

(13)

t=0 a,p

=0

P
expression derived substituting Tt=0 log pt log P (r = 1, L, ; ? )
Eq. (10) marginalizing remaining variables (See derivation Appendix A).
Analogous expected log-likelihood expressions written node transition
initial node distribution parameters.
4.3 Step 2: Maximizing Expected Log-Likelihood Q(, ? )
highlighted section 4.1, formulated expected log-likelihood, next
step maximize get better policy ? . show maximization first
action updates. expected log-likelihood action updates given as:
Qa,p (, ? ) =


X

P (T )

X
X

?
P (r = 1, = a, pt = p|T ; ) log ap

(14)

t=0 a,p

=0

maximization step (M-step) involves solving following convex optimization problem:
max Qa,p (, ? )

(15)

? }
{ap

subject to:

X


?
ap
= 1 p

(16)

optimization problem easily solved analytically solving KarushKuhn-Tucker (KKT) conditions (Boyd & Vandenberghe, 2004). resulting update
controller action parameters given as:
?
ap

=
=

P

=0 P (T )

PT

t=0 P (r = 1, = a, pt = p|T ; )

Cp
E [r = 1, a, p]
Cp

(17)
(18)

Cp normalization constant.
parameter updates: Analogous action updates above, write controller transition well initial node distribution updates follows:
E [r = 1, a, p]
Cp
E [r = 1, p, p, y]
?ppy =
Cpy
E [r = 1, p]
p? =
C
?
ap
=

236

(19)

fiProbabilistic Inference Multiagent Decision Making

have:
E [r = 1, p, p, y] =
E [r = 1, p] =


X
=1

X

P (T )


X

P (r = 1, pt = p, pt1 = p, yt = y|T ; )

(20)

t=1

P (T )P (r = 1, p0 = p|T ; )

(21)

=0

Sections 4.2 4.3 summarize two main steps form core EM algorithm. two steps applied iteratively convergence result monotonic
improvement solution quality.
4.4 Inference Parameter Updates
detail inference procedure computes different expectations E required
parameter updates shown Eq. (19). Computing expectations also forms E-step
EM algorithm. step, fixed parameter , forward messages backward
messages propagated. forward-backward message passing similar
message passing Baum-Welch algorithm parameter estimation hidden Markov
models (Koller & Friedman, 2009). First, define following Markovian transitions
(p, q, s) state -step DBN Figure 3. transitions independent
time due stationary joint-policy.
X
P (p0, q 0, s0 |p, q, s) =
p0 py0 q0 qz 0 Oy0 z 0 abs0 ap bq Ps0 sab
(22)
aby 0 z 0

Definition 1. forward message defined probability FSC agent
1 state p, FSC agent 2 state q world state time
(p, q, s) = P (pt = p, qt = q, st = s; ).
might appear need propagate messages DBN DBN mixture
separately, pointed Toussaint et al. (2006), one sweep required
head DBN shared among mixture components. is, 2
T-step DBNs 2. omit using long unambiguous.
0 (p, q, s) = p q 0 (s)
X
(p0 , q 0 , s0 ) =
P (p0 , q 0 , s0 |p, q, s)t1 (p, q, s)

(23)
(24)

p,q,s

messages propagated backwards defined Pt (r = 1|p, q, s; ). However,
particular definition would require separate inference DBN 0
step DBN, different due difference time-to-go (T 0 t).
circumvent problem, messages indexed backward time defined follows.
Definition 2. backward message defined probability variable r = 1
given FSC agent 1 state p, FSC agent 2 state q world
state steps-to-go -step DBN:
(p, q, s) = P(r = 1|pT = p, qT = q, sT = s)
237

fiKumar, Zilberstein, & Toussaint

= 0 denotes last time slice = . tails DBNs mixture
Figure 3 exactly same, backward indexing avoids performing separate inference
DBN. example, 3 DBNs length 3 3 computes
probability reward variable one given state Markov chain (p, q, s)
3 time steps go. recursive definition follows:
X
0 (p, q, s) =
Rsab ap bq
(25)
ab

X

(p, q, s) =

p0 ,q 0 ,s0

1 (p0 , q 0 , s0 )P (p0 , q 0 , s0 |p, q, s)

(26)

Based messages compute two quantities:
(p, q, s) =


X

P (T = t)t (p, q, s)

(27)

P (T = ) (p, q, s)

(28)

t=0

(p, q, s) =


X
=0

quantities used M-step. cut-off time message propagation either
fixed priori flexible based likelihood accumulation. messages
propagated t-steps -messages steps, likelihood = +
given as:
X
Lt+ = P (r = 1|T = + ; ) =
P (r = 1, pt = p, qt = q, st = s|T = + )
(29)
p,q,s

=

X

P (r = 1|pt = p, qt = q, st = s, = + )P (pt = p, qt = q, st = s|T = + )

(30)

(p, q, s) (p, q, s)

(31)

p,q,s

=

X
p,q,s

P

messages propagated k steps L2k 2k1
=0 LT ,
message propagation stopped. criterion simply means expected
value (or likelihood) time step = 2k small compared already
accumulated value time step 2k 1, message propagation stopped.
computed messages, compute expectations required
different updates Section 4.3. derivations updates provided
Appendix A.
Definition 3. Based computing quantities Eq. (27)- (28), parameters
agents controller updated EMs iteration follows:
?
ap
=

X
ap X

(p, q, s)
Rsab bq +
Cp qs
1
b

X

0

0

0

(p , q , )

p0 q 0 0 0 z 0

X
ppy X
(p, q, s)(p, q, s)qqz
Oyzsab Pssab ap bq
Cpy sqsqz
ab
p X
p? =
(p, q, s)q Ps 0 (s)
C qs

?ppy =

238

p0 py 0



q 0 qz 0

X
b




0 z 0 s0 ab

bq P

s0 sab

fiProbabilistic Inference Multiagent Decision Making

4.5 Complexity
Calculating Markov transitions (p, q, s) chain Section 4.4 complexity
O(|Q|4 |S|2 |A|2 |Y |2 ), |Q| maximum number nodes controller.
message propagation complexity O(Tmax |Q|4 |S|2 ). Techniques effectively reduce
complexity without sacrificing accuracy discussed experiments section.
complexity updating action parameters O(|Q|4 |S|2 |A||Y |2 ). Updating node
transitions requires O(|Q|4 |S|2 |Y |2 + |Q|2 |S|2 |Y |2 |A|2 ). relatively high compared single agent POMDP updates requiring O(|Q|2 |S|2 |A||Y |) mainly due
scale interactions present Dec-POMDPs.
experimental settings, observed relatively small sized controller
(|Q| 5) suffices yield good quality solutions. main contributor complexity
factor 2 experimented large domains nearly 250 states.
good news structure E M-step equations provides way effectively
reduce complexity significant factor without sacrificing accuracy. given state
s, joint-action ha, bi joint-observation hy, zi, possible next states calculated
follows: succ(s, a, b, y, z) = {s0 |P (s0 |s, a, b)O(y, z|s0 , a, b) > 0}. problems,
size set typically constant k < 10. simple reachability analysis
techniques speed EM algorithm order magnitude large
problems. effective complexity reduces O(|Q|4 |S||A||Y |2 k) action updates
O(|Q|4 |S||Y |2 k + |Q|2 |S||Y |2 |A|2 k) node transitions.
4.6 Intuition Behind EM Update Strategy
section, provide insights update strategies EM. action
parameter update according Section 4.3 given as:


E r = 1, a, p
?
ap =
(32)
Cp
Cp normalization constant. understand Eq. (32) clearly, consider
following iterative algorithm optimizing controller. First, fix every controller
nodes parameters every agent except parameters single controller node
particular agent. Now, deterministically try every action setting particular node
greedily set action parameter node action results maximum
joint value. Clearly, strategy monotonically improve policy value reaches
local optima. strategy used decision making models
influence diagrams referred Single Policy Update (SPU) algorithm (Lauritzen
& Nilsson, 2001).
updates EM algorithm essentially soft version greedy
deterministic rule. understand this, let a? denote action maximum expectation:


a? = arg max E r = 1, a, p
(33)
aA

consider applying update rule Eq. (32) infinitely many times without recomputing E-step. Clearly limit, a?? p = 1 rest action
parameters converge zero. essentially SPU algorithm.
239

fiKumar, Zilberstein, & Toussaint

connection also provides insight soft-max approach EM
may better strategy greedy deterministic update rule. First, greedy
update rule computes deterministic controllers agents. already
shown stochastic controllers achieve better solution quality deterministic
controllers (Poupart & Boutilier, 2003). EM updates provide stochastic controllers,
advantage. Second, already known graphical models community greedy update rule, also referred Hard-Assignment EM (Koller &
Friedman, 2009, ch. 19) EM algorithm optimize different objectives.
general lead different solutions, example, situations stochastic controllers
preferred deterministic ones. hard-assignment EM traverses combinatorial path
needs fix parameters except one. soft-assignment EM,
hand, simultaneously change parameters multiple nodes. Thus, moves
parameter space soft-assignment EM sophisticated general, infeasible hard-assignment EM, cannot simultaneously change multiple parameters.
Thus, soft-assignment EM converge better policy. Therefore, using soft-max
based update strategy EM algorithm advantageous greedy
deterministic rule.
4.7 Discussion
presented new approach solve Dec-POMDPs using inference mixture DBNs.
main benefit EM approach opens possibility using powerful
probabilistic inference techniques solve decentralized planning problems. Using graphical DBN structure, EM easily extend larger multi-agent systems 2
agents, shown following sections. Furthermore, planning-as-inference
viewpoint help generalize richer representations factored hierarchical controllers (Toussaint et al., 2008), continuous state action spaces (Hoffman,
de Freitas, Doucet, & Peters, 2009a).
Incidentally, increasing interest applying variational inference techniques
machine learning graphical models literature, marginal MAP inference
belief propagation (Liu & Ihler, 2013, 2012), planning uncertainty. Particularly
related work use marginal MAP (MMAP) based inference single agent
POMDP planning (Kiselev & Poupart, 2014a, 2014b). MMAP based planning,
single dynamic Bayesian network developed introducing additional binary variables
similar binary reward variable r case. single graphical model
developed POMDP model, shown maximizing likelihood observing
one special binary variable equal optimizing joint policy.
key difference approach Kiselev Poupart use
different graphical models represent underlying planning problem. approach
Kiselev Poupart uses two additional binary variables per time step represent
reward discounting value function, approach need. Furthermore,
approach, time indexing backward message propagation need
fixed priori shown Section 4.4, whereas fixed horizon DBN needs prespecified Kiselev Pouparts (2014b) method. Nonetheless, using MMAP inference
planning represents another variational inference-based approach applied
240

fiProbabilistic Inference Multiagent Decision Making

planning uncertainty problems. Similar development EM case,
one also develop EM algorithm policy optimization single DBN model
Kiselev Poupart. remains seen, however, approach Kiselev
Poupart (2014a, 2014b) gets translated multiagent setting w.r.t. scalability
solution quality.

5. Achieving Scalability Restricted Models
previous sections, developed probabilistic inference based approximate algorithms
efficiently solve 2-agent Dec-POMDPs. However, scaling even approximate
algorithms 2-agents non-trivial task. fact, naive extension leads
exponential increase complexity number agents. Therefore, following
sections, present general characterization interactions among agents
present multiagent planning model leads relatively scalable approximate algorithms.
section, identify conditions sufficient make multiagent planning
amenable scalable approximation w.r.t. number agents. achieved
constructing graphical model exploits restricted interactions among agents.
illustrate close relationship machine learning showing likelihood
maximization graphical model equivalent policy optimization. Using
Expectation-Maximization framework likelihood maximization, show necessary inference decomposed processes often involve small subset agents,
thereby facilitating scalability. derive global update rule combines local
inferences monotonically increase overall solution quality. Furthermore, approach
easily parallelizable takes form message-passing among agents, ideally suited
large multiagent systems.
Experiments large multiagent planning benchmark, joint state action
spaces 522 , 320 respectively, confirm approach scalable w.r.t. number
agents provide good quality solutions planning problems 20 agents,
cannot handled previous best approaches. smaller multiagent systems,
approach provides better solution quality order-of-magnitude faster
previous best nonlinear programming approach optimizing FSCs.
5.1 Value Factorization Framework
value factorization framework leads efficient inference large multiagent systems
general enough subsume several existing planning models. before, represent
agents policy bounded, finite state controller (FSC). assume state
space factored s.t. = (S 1 ... )a common assumption multiagent planning
models ND-POMDPs (Nair et al., 2005) TD-POMDPs (Witwicki & Durfee,
2010). Without making (conditional independence) assumptions problem
structure, general Dec-POMDP requires exact inference full corresponding (finitetime) DBNs, would exponential number state variables agents.
approach relies general simplifying property agent interaction, later show
consistent many existing multiagent planning models.
241

fi
f

f F

s#f

r
f F


q!




Kumar, Zilberstein, & Toussaint
q!



y!

y!



ai

qi#

qi

s#i

si

ai
Af

si

s#i

x

#

r
f F

1

yi#

x

(a)

(b)

Af

2
r f F

3

4

(c)

Figure 5: Value factorization property different models: (a) Plate notation transition
independent Dec-MDPs; (b) Plate notation ND-POMDPs; (c) Agent interaction digraph TD-POMDPs

Definition 4. value factor f defines subset Af {1, .., N } agents subset
Sf {1, .., } state variables.
Definition 5. multiagent planning problem satisfies value factorization jointpolicy value function decomposed sum value factors:
X
V (, s) =
Vf (f , sf ) ,
(34)
f F

F set value factors, f Af collection parameters agents
factor f , sf sSf collection state variables factor.
Even value factorization property holds, planning models still highly
coupled factors may overlap. is, agent appear multiple factors
state variables. Therefore, value factor cannot optimized independently. But,
show later, leads efficient Expectation Maximization algorithm. additive value
functions also used solve large factored MDPs (Koller & Parr, 1999). Witwicki
Durfee (2011) use factored value functions analyze complexity solving
multiagent planning problems. work, contrast, uses value factorization property conjunction graphical models probabilistic inference develop scalable
likelihood maximization based algorithm. require value factor Vf evaluated using DBN mixture based approach Section 3. However, limit
generality, DBN-based approach model arbitrary Markovian planning problems.
Theorem 2. worst case complexity optimally solving multiagent planning problem
satisfying value factorization property NEXP-Hard.
proof theorem straightforwardany two agent finite-horizon DecPOMDP NEXP-Complete also satisfies value factorization property
single factor involving two agents. fact, previous sections precisely addressed
issue using EM framework (see Section 4). Next, investigate property
holds computationally advantageous, establish following result.
242

fiProbabilistic Inference Multiagent Decision Making

Theorem 3. value factorization property holds Transition-Independent Dec-MDPs
(Becker et al., 2004), Network-Distributed POMDPs (Nair et al., 2005) TransitionDecoupled POMDPs (Witwicki & Durfee, 2010).
Proof. joint value shown factorized based immediate-reward factorization
transition independent Dec-MDPs (Becker et al., 2004) ND-POMDPs (Nair et al.,
2005). Figure 5 shows plate notation value factor representation
models. outer plate shows factor f inner plate depicts interaction
among agent parameters include state, action observation variables.
models, key assumption leads scalability agents involved
single reward function. Thus, value factor small leads efficient inference.
approach also model Transition-Decoupled POMDPs (TD-POMDPs) (Witwicki
& Durfee, 2010). case, agents local parameters (factored local state rewards). However, certain features local state depend agents actions.
features called nonlocal features agent i. dependency among agents
described using agent interaction digraph (Witwicki, 2011, Section 3.5.1.2).
node agent i. directed edge node node j agent affects
nonlocal feature agent j. Let (i) denote ancestors node agent
interaction digraph TD-POMDP. shown Witwicki (2011, Thm. 3.33), joint
value function TD-POMDP defined N agents factored as:
V () =

N
X
i=1

Vi , hj | j (i)i



(35)

state variables involved factor Vi local states agent {i}(i).
Furthermore, value factor Vi evaluated constructing DBN mixture involving
agents {i}(i). Therefore, TD-POMDP model satisfies value factorization
property. Consider example agent interaction digraph Figure 5(c). joint value
factorizes V () = V1 (1 ) + V2 (2 , 1 ) + V3 (3 , 1 ) + V4 (4 , 1 , 3 ).
Furthermore, TD-POMDPs mainly useful weakly-coupled planning problems
(Witwicki, 2011). implies number agents involved single value factor
small compared total number agents, potentially leading computational savings approaches exploit structure smaller value factors.
note value factorization property Eq. (34) trivially satisfied
agent state variables included single factor. Obviously, computational
advantages approach limited settings factor sparse, involving
much fewer agents entire team. allows efficient inference respective
DBNs (inference still efficient special cases TD-POMDPs larger
factors). general case, additive value function may include components depending
states agent parameters. analogous factored HMMs (Ghahramani
& Jordan, 1995) where, conditioned observations, Markov chains become coupled
exact E-step EM becomes infeasible. beyond scope paper, promising approach general case using variational methods approximate
posterior P (s1:M
1:T | r = 1) (minimizing KL-divergence factored representation true posterior) (Ghahramani & Jordan, 1995). Given approximate
243

fiKumar, Zilberstein, & Toussaint

posterior, M-step updates used realize approximate EM scheme, also
shown Pajarinen Peltonen (2011a).
next section, describe new DBN mixture model value factorization
framework. that, highlight key result behind scalability EM
algorithm
Theorem 4. models satisfying value factorization property, inferences required
E-step EM algorithm performed independently value factor f .
e.g., action updates agent j,
X f
E [r = 1, aj , q j ]
E [r = 1, aj , q j ] =
f F (j)

j denotes particular agent, F (j) denotes set value factors agent j
involved in, (aj , q j ) denote action controller state agent j, Ef [] (to defined
precisely Section 5.4.1) denotes inference DBN mixture corresponding
valued factor f . constructive proof result provided below. result
highlights generality scalability approach, whichunlike previous works
require independence assumptions.
next section, define latent variable model, based mixture
DBNs, likelihood maximization (LM) mixture model equivalent
joint-policy optimization. established relationship LM
policy optimization, show perform different steps EM mixture model
outlined section 4.1.
5.2 DBN Mixture Value Factors
Figure 6 shows new problem-independent DBN mixture, also called value factor mixture,
models Eq. (34). consists two mixture variables: F . F ranges 1
|F |, total number value factors. Intuitively, F = denotes time dependent
DBN mixture value factor i. zoomed-in view DBN mixture provided
Figure 6(b). mixture variable F fixed, uniform distribution (= 1/|F |).
distribution variable set Theorem 1.
model relies fact representation, value factor represented evaluated using time dependent DBN mixture Figure 6(b) binary
reward variable r, also shown Section 3. DBN mixture particular value
factor f contain variables agents involved factor f : actions, controller
nodes observations, state variables Sf . valuation Vf (f ) calculated finding likelihood Lf (f ; r = 1) = P (r = 1; f ) observing binary reward
variable r = 1 DBN mixture value factor f . Using Theorem 1,
following result:
Vf (f ) = kLf (f ; r = 1) + kf

(36)

k kf constants, k value factors. easily
ensured making original rewards positive adding suitable constant. Next
state one main results. also assuming policy optimized
244

fiProbabilistic Inference Multiagent Decision Making

x0

y0
r

x0

y0

x1

y1
r

F =1

F =2

F = |F |

Figure 6: (a) Value factor mixture; (b) Zoomed-in view mixture component (x,
generic placeholders random variables).

initial belief 0 . also use notational convenience
P
f F .

P|F |

F =1

equivalent

Theorem 5. Maximizing likelihood L(; r = 1) observing r = 1 value factor
mixture (Figure 6(a)) equivalent optimizing global policy .
Proof. overall likelihood given by:
L(; r = 1) = P (r = 1; ) =

X 1
Lf (f ; r = 1)
|F |

(37)

f F

theorem follows substituting value L(f ; r = 1) previous equation
Eq. (36) joint-policy value decomposition assumption Eq. (34).
5.3 Step 1: Formulating Expected Log-Likelihood Q(, ? )
formulate expected log-likelihood Q(, ? ) DBN mixture Figure 6(a).
r = 1 observed data, rest variables latent. Note derivations
differ markedly Toussaint Storkey (2006) focus single-agent problem
EM approach 2-agent Dec-POMDPs (see Section 4). focus scalability
w.r.t. number agents generality.
assignment mixture variables F = f denotes T-step DBN
value factor f . example, assume time dependent DBN mixture Figure 6(b)
value factor f . F = f = 1 denote 1-step DBN (the second DBN)
Figure 6(b). Let Z f denote complete assignment variables slice 0
T-step DBN factor f . assume simplicity value factor f involves k
agents. full joint mixture is:
k

k








P (r = 1, Z f , T, F = f ) = P (T )P (F = f ) Rsf af t=T
fi (a, q)
fi (q, q, y)
i=1 t=0

k

i=1

[fi (q)]0 P (Z f \(Af , Qf )|T, F = f )
245

i=1 t=1

(38)

fiKumar, Zilberstein, & Toussaint

index fi denotes respective parameters agent involved factor f .
square brackets denote dependence upon time: [fi (a, q)]t = fi (at = a, qt = q). also use
[P (v, v)]t denote P (vt = v, vt1 = v).
Let Z f \(Af , Qf ) denote variables DBN except action controller
nodes agents. Importantly, structure previous equation model independent conditional independence policy parameters ((a, q) = P (a|q)),
first part equation (the product terms) always written way. model independent, imply structure previous equation remains different
models value factorization property. Since EM maximizes expected log-likelihood,
take log get:
log P (r = 1, Z f , T, F = f ) =

k X

X


k X

X



log fi (a, q) +
log fi (q, q, y)

i=1 t=0

i=1 t=1

+

k
X

i=1


log fi (q) 0 + hother termsi

(39)

hother termsi denote terms independent policy parameters . EM maximizes
following expected log-likelihood:
?

Q(, ) =

X
XX
f F =0 Z f

?

P (r = 1, Z f , T, F = f ; f ) log P (r = 1, Z f , T, F = f ; f )

(40)

denotes previous iterations joint-policy ? current iterations policy
determined maximization. structure log term (Eq. (39)) particularly
advantageous allows us perform maximization parameter agent
independently. imply complete problem decoupling parameters still
depend previous iterations parameters agents.
5.4 Step 2: Maximizing Expected Log-Likelihood Q(, ? )
first derive update action parameters agent j. P (F) ignored
constant. expected log-likelihood action updates, Qja,q (, ? ), given by:
Qja,q (, ? )

=

X X

P (T )

f F (j)

=

X X
f F (j)

X
Zf

P (T )

X




?
P (r = 1, Z |T, f ; )
log j (a, q)
f

f

(41)

t=0

X
X
t=0 a,q

P (r = 1, = a, qt = q, |T, f ; f ) log j? (a, q)

(42)

F (j) set value factors involve agent j. M-step involves solving
following convex optimization problem:
max

Qja,q (, ? )

(43)

X

j? (a, q) = 1 q

(44)

{j? (a,q) a,q}

subject to:



246

fiProbabilistic Inference Multiagent Decision Making

f12

f23

f34

f12


Ag1

f23

f34


Ag2

Ag3

Ag4

Ag1

(a)

Ag2

Ag3

Ag4

(b)

Figure 7: Message passing value factor graph: (a) shows message direction
E-step; (b) shows M-step.

optimization problem easily solved analytically solving KarushKuhn-Tucker (KKT) conditions resulting following action parameter updates:
P
P
PT
f
f F (j)
=0 P (T )
t=0 P (r = 1, = a, qt = q|T, f ; )
?
j (a, q) =
(45)
Cq
P
f
f F (j) E [r = 1, a, q]
=
(46)
Cq
Cq normalization constant.
5.4.1 Parameter Updates
Analogous action updates previous section, write controller
sition well initial node distribution updates agent j follows:
P
f
f F (j) E [r = 1, a, q]
?
j (a, q) =
Cq
P
f
f F (j) E [r = 1, q, q, y]
?j (q, q, y) =
Cqy
P
f
f F (j) E [r = 1, q]
j? (q) =
C

tran-

(47)
(48)
(49)

omitted superscript j denote action controller variable
agent j avoid clutter. next two equations too, action, controller variables belong
agent j.
Ef [r

= 1, q, q, y] =
Ef [r = 1, q] =


X
=1

X

P (T )


X

P (r = 1, qt = q, qt1 = q, yt = y|T, f ; f )

(50)

t=1

P (T )P (r = 1, q0 = q|T, f ; f )

(51)

=0

5.5 Scalability Message Passing Implementation
parameter updates Section 5.4.1 highlight high scalability EM DecPOMDPs. Even though planning problem highly coupled agent state
247

fiKumar, Zilberstein, & Toussaint

variables allowed participate multiple value factors (see Eq. (34)), updating policy
parameters requires separate local inference, Ef [r = 1, , ], value factor.
global update rules (Eq. (47)(49)) combine local inferences provide
monotonic increase overall solution quality. local inference model dependent
computed using standard probabilistic techniques. problem setting
includes sparse factors, local inference computationally much simpler
performing complete planning model.
Furthermore, E M-steps implemented using parallel, distributed messagepassing bipartite value-factor graph G = (U, V, E). set U contains node uj
agent j. set V contains node vf factor f F . edge e = (uj , vf )
created agent j involved factor f . Figure 7 shows graph three value
factors black squares (the set V ) 4 agents (the set U ).
E-step, factor node vf computes sends message f j = Ef [r =
1, , ] node uj connected vf . Figure 7(a) shows step. agent node
uj upon receiving messages factor node connected it, updates
parameters Eq. (47)(49) sends updated policy parameters ? back
factor node connected (see Figure 7(b)). procedure repeats convergence.
Based message-passing interpretation EM, state following result:
Theorem 6. iteration EM algorithm linear complexity number
edges value factor graph exponential complexity respect maximum
number agents involved single value factor.
stated earlier, value factors sparse, EM algorithm provide significant
computational savings approach oblivious underlying interaction
among agents. Another significant advantage EM algorithm messages
computed parallel factor node. experiments, using 8-core CPU
resulted near linear speedup sequential version. characteristics EM
algorithm significantly enhance scalability large, sparse planning problems.
5.5.1 Nature Local Optima
Variants Dec-POMDP model often solved fixing policies group agents
finding best response policy agent interacts group (Nair,
Tambe, Yokoo, Pynadath, Marsella, Nair, & Tambe, 2003; Witwicki & Durfee, 2010). EM
offers significant advantages strategy. find local optima, EM
stringent satisfies Karush-Kuhn-Tucker conditions (Bertsekas, 1999),
norm nonlinear optimization. local optima EM refers stationary point
likelihood function (or value function) l(; x) Figure 4. parameter space
figure includes discrete parameters found local optimal
algorithms best response strategy continuous parameters found
algorithms EM.
local optima best response strategy simply refers fact particular algorithm cannot improve policy using best-response strategy. algorithm
specific local optima may stationary point value function Figure 4.
solution stationary point, EM would able improve upon
248

fiProbabilistic Inference Multiagent Decision Making

solution given EM guaranteed converge stationary point value
function. Thus, local optima provided EM satisfies stringent guarantee
stationary point value function. best-response strategy provides
guarantees.
5.6 Discussion
Despite rapid progress multiagent planning, scalability prevailing formal models
limited. developed new approach multiagent planning identifying
general property value factorization facilitates development scalable
approximate algorithm using probabilistic inference. show several existing classes
Dec-POMDPs satisfy property. contrast previous approaches, framework
impose restrictions agent interaction beyond property, thus
providing general solution value factorization based multiagent planning.
key result supports scalability approach that, within EM
framework, inference process decomposed separate components
much smaller complete model, thus avoiding exponential complexity
number agents. Additionally, EM algorithm allows distributed planning using
message-passing along edges value-factor graph, amenable parallelization. Results large sensor network problems confirm scalability approach.
Empirically, approach, linear complexity number edges agent
interaction graph could scale 20 agents, whereas previous best approach based
nonlinear programming could scale 5 agents due increase number
nonlinear constraints.
also highlight key differences approach previous approach
Toussaint et al. (2006, 2008) single-agent MDPs POMDPs. Although idea
decomposing planning problem time-dependent DBN mixture remains
approach, key differences lie structure DBNs two agent
Dec-POMDPs value factored Dec-POMDPs, derivation lower bound function
Q(, ? ) maximization Q function Dec-POMDPs required within
EM framework (see Section 4.1), computing required inferences underlying
Markov chain DBNs shown Section 4.4.
interactions FSC-based policy environment present
DBN MDPs POMDPs relatively simple compared interactions
present Dec-POMDPs. Dec-POMDPs, agents interact environment, also other. inter-agent interactions leads much different
DBN structure, planning challenges Dec-POMDPs. example, DBN mixture value factorization model nested shown Figure 6. unique
feature required formulation DBN approach, present POMDPs.
Due differences structure single DBN well mixture model,
adaptation EM requires different formulation alpha beta messages account
inter-agent influences shown Section 4.4. Similarly, structure Q(, ) function
different owing inter-agent influences (see Eq. (40)), leads different updates
provide scalability inter-agent message-passing structure multiagent systems
shown Sections 5.4.1 5.5. Therefore, adapting EM approach multiagent
249

fiKumar, Zilberstein, & Toussaint

Size
1
2
3
4

DEC-BPI
4.687
4.068
8.637
7.857

NLP
9.1
9.1
9.1
9.1

EM
9.05
9.05
9.05
9.05

DEC-BPI
< 1s
< 1s
2s
5s

EM
< 1s
< 1s
1.7s
4.62s

Table 1: Broadcast channel: Policy value, execution time

planning, one key contributions deliberately investigate exploit
independencies present multiagent system translate scalable algorithmic structure. Furthermore, also shown general applicability approach
previous multiagent planning models Theorem 3.

6. Empirical Evaluation
begin empirical evaluation experiments conducted 2-agent problems.
followed experiments larger problems involving 20 agents.
6.1 Two Agents Dec-POMDPs
experimented several standard 2-agent Dec-POMDP benchmarks discounting factor = 0.9. compare EM algorithm decentralized bounded policy
iteration (DEC-BPI) algorithm (Bernstein et al., 2009) non-linear, non-convex optimization solver (NLP) (Amato et al., 2010). DEC-BPI algorithm iteratively improves
parameters node using linear program keeping nodes parameters fixed. NLP approach, state-of-the-art infinite-horizon
Dec-POMDPs, recasts policy optimization problem non-linear program uses
off-the-shelf solver, Snopt (Gill et al., 2002), obtain solution. implemented
EM algorithm JAVA. experiments Mac 4GB RAM 2.4GHz
CPU. data point every algorithm tested parameter setting average 10
runs random initial controller parameters. terms solution quality, EM always
better DEC-BPI achieves similar higher solution quality NLP. note
NLP solver (Gill et al., 2002) optimized package therefore larger
two agent problems currently faster EM approach. EM algorithm,
implement optimizations parallel execution using multithreading,
decrease runtime significantly.
Table 1 shows results broadcast channel problem, 4 states, 2 actions per
agent 5 observations. networking problem agents must decide whether
send message shared channel must avoid collision get reward.
tested different controller sizes shown first column. problem,
algorithms compare reasonably well, EM better DEC-BPI close
value NLP. time NLP also 1s.
Figure 8(a) compares solution quality EM approach DEC-BPI
NLP varying controller sizes recycling robots problem. problem, two robots
250

fi65

8

60

7

55

6

50

Time (sec)

Policy Value

Probabilistic Inference Multiagent Decision Making

45
40
EM(2)
EM(4)
NLP(2)
NLP(4)
DEC-BPI(2)
DEC-BPI(4)

35
30
25
20
0

50

100

150 200
Iteration

250

5
4
3
2
1

300

0
350

EM(2)
EM(4)
0

50

100

(a) |S| = 3, |A| = 3, |Y | = 2

150
200
Iteration

250

300

350

300

350

(b)

8

60

7

50

5

Time (sec)

Policy Value

6

4
3
2

EM(2)
EM(3)
NLP(2)
NLP(3)

1
0
0

50

100

150
200
Iteration

250

40
30
20
10

300

0
350

(c) |S| = 16, |A| = 5, |Y | = 4

EM(2)
EM(3)
0

50

100

150 200
Iteration

250

(d)

Figure 8: Solution quality runtime recycling robots (a) & (b) meeting
grid (c) & (d)

task picking cans office building. search small can,
big recharge battery. large item retrievable joint action
two robots. goal coordinate actions maximize joint reward. EM(2)
NLP(2) show results controller size 2 agents Figure 8(a).
problem, EM works much better DEC-BPI NLP approach. EM achieves
value 62 controller sizes, providing nearly 12% improvement DEC-BPI
(= 55) 20% improvement NLP (= 51). Figure 8(b) shows time comparisons
EM different controller sizes. NLP DEC-BPI take nearly 1s
converge. EM controller size 2 comparable performance, expected, EM
4-node controllers takes longer complexity EM proportional O(|P|4 ),
|P| denotes controller size.
Figure 8(c) compares solution quality EM meeting grid problem.
problem, agents start diagonally across 2 2 grid goal take
actions meet (i.e., share square) much possible.
figure shows, EM provides much better solution quality NLP approach. EM
achieves value 7, nearly doubles solution quality achieved NLP (= 3.3).
DEC-BPI results plotted performs much worse achieves solution quality
0, essentially unable improve policy even large controllers. DECBPI NLP take around 1s converge. Figure 8(d) shows time comparison EM
versions. EM 2-node controllers fast takes < 1s converge (50 iterations).
251

fiKumar, Zilberstein, & Toussaint

0

0.85

-10

0.75
Likelihood

Policy Value

0.8

-20
-30

EM(2)
EM(4)
EM(10)
NLP(2)
NLP(5)
NLP(10)

-40
-50
0

100

200
Iteration

300

0.7
0.65
0.6
0.55
0.5
0.45

400

(a) |S| = 2, |A| = 3, |Y | = 2

0.4

EM(2)
EM(10)
0

100

200
Iteration

300

400

(b)

Figure 9: Solution quality (a) likelihood (b) multiagent tiger

Again, EMs quartic complexity controller size |P|, time required
larger controllers higher. Also note cases, EM could run much
larger controller sizes ( 10), increase size provide tangible improvement
solution quality.
Figure 9 shows results multi-agent tiger problem, involving two doors
tiger behind one door treasure behind other. Agents coordinate
open door leading treasure (Amato et al., 2010). Figure 9(a) shows quality
comparisons. EM perform well case; even increasing controller
size, achieves value 19. NLP works better large controller sizes. However,
experiment presents interesting insight workings EM related scaling
rewards. Recalling relation likelihood policy value
Theorem 1, equation problem is: V = 1210L 1004.5. EM achieve
solution best NLP setting (= 3), likelihood .827. Figure 9(b)
shows likelihood EM converges .813. Therefore, EMs perspective,
finding really good solution. Thus, scaling rewards significant impact (in
case, adverse) policy value. potential drawback EM approach,
applies Markovian planning problems using technique Toussaint
et al. (2006). Incidently, DEC-BPI performs much worse gets quality 77.
Figure 10 shows results two largest Dec-POMDP domainsBox pushing
Mars rovers. box pushing domain, agents need coordinate push boxes
goal area. Mars rovers domain, agents need coordinate actions perform
experiments multiple sites. Figure 10(a) shows EM performs much better DECBPI every controller size. controller size 2, EM achieves better quality NLP
comparable runtime (Figure 10(b), 500 iterations). However, larger controller
size (= 3), achieves slightly lower quality NLP. largest Mars rovers domain
(Figure 10(c)), EM achieves better solution quality (= 9.9) NLP (= 8.1). However,
EM also takes many iterations converge previous problems hence,
requires time NLP. EM also much better DEC-BPI, achieves
quality 1.18 takes even longer converge (Figure 10(d)). Mars rover
domain, NLP solver able run larger controller sizes due size
nonlinear program.
252

fiProbabilistic Inference Multiagent Decision Making

50

10000

Time (sec, logscale)

40

Policy Value

30
20
10
0

EM(2)
EM(3)
NLP(2)
NLP(3)
DEC-BPI(2)
DEC-BPI(3)

-10
-20
-30
0

200

400

1000
100
10

0.1

600 800 1000 1200 1400
Iteration

EM(2)
EM(3)
NLP(2)
NLP(3)
DEC-BPI(2)

1

0

200 400

(a) |S| = 100, |A| = 4, |Y | = 5

(b)
100000

10
Time (sec, logscale)

Policy Value

5
0
-5
-10
EM(2)
NLP(2)
DEC-BPI(2)

-15
-20

600 800 1000 1200 1400
Iteration

0

1000

2000
3000
Iteration

4000

10000
1000
100
10
1

5000

(c) |S| = 256, |A| = 6, |Y | = 8

EM(2)
NLP(2)
DEC-BPI(2)
0

1000

2000
3000
Iteration

4000

5000

(d)

Figure 10: Solution quality runtime box pushing (a) & (b) Mars rovers
(c) & (d)

summarise, simple implementation EM approach competitive
industrial strength off-the-shelf nonlinear programming solver. algorithm provided
similar better solution quality current best NLP approach. main benefit
EM approach lies fact opens possibility using powerful
probabilistic inference techniques solve decentralised planning problems. shall see
next section, EM scales significantly better NLP approach larger ( 2)
multiagent benchmarks NLP approach fails due large size resulting
nonlinear programs.
6.2 Larger Multiagent Benchmarks
experimented target tracking application sensor networks modeled NDPOMDP (Nair et al., 2005). Figure 11 shows four sensor topologies: 5P, 11H 15-3D
Marecki et al. (2008) largest 20D Kumar Zilberstein (2009b).
describe develop significantly enriched variant application better
test approach, originally introduced Nair et al. (2005). node graphs
sensor agent edges locations targets move. track target
gain reward (= +80), two sensors must scan target location simultaneously, otherwise
penalty (= 1) given. targets independent, stochastic trajectories
possible locations form external state-space, implying target movement affected
253

fiKumar, Zilberstein, & Toussaint

Figure 11: Benchmarks 20D (left), 15-3D, 5P 11H (right)
sensors actions. Sensors internal state, indication battery level
sensor. scan action depletes battery. addition scanning, sensors
two additional actionssensor recharge. sensor action allows sensors
conserve energy remaining idle. battery completely depleted, sensor
must perform recharge action, cost (= 1). sensor three observation:
target present, target absent idle. False positives/negatives allowed first
two observations. runtime, sensors operate decentralized manner without central
controller.
Note formulation sensor network application much richer challenging
previously used benchmarks (Marecki et al., 2008). Earlier benchmarks
include internal states sensors assumed unbounded battery life.
current formulation, planning much complex sensors must reason
scanning, also conserving energy, limited battery.
EM algorithm implemented JAVA. experiments done
8-core iMac 2GB RAM. implementation used multithreading parallelize EM
highlighted Section 5.5 utilized 8-cores. datapoint average 10
runs. speed EMs convergence, used greedy variant M-step presented
Toussaint et al. (2008). step positively affects rate convergence EM
relatively little affect solution quality. M-step essentially softer
version hard assignment EM (see Eq.(33)) follows design (Toussaint
et al., 2008). next describe problem sizes different instances.
5P domain 2 targets, 11H 3 targets, 15-3D 5 targets, 20D
6 targets. problems large state-spaces: 6 55 5P, 64 511 11H,
144 515 15-3D 2700 520 20D. Evidently, EM efficiently exploits factored
representation state action spaces highly scalable linear complexity
w.r.t. number edges graph. also note even solving underlying
factored MMDP optimally feasible due large state action spaces.
Figure 12 shows solution quality EM achieves benchmarks
different controller sizes. notable observation graphs EM converges
quickly greedy M-step Toussaint et al. (2008) , taking fewer 200 iterations even large multiagent planning problems. solution quality, expected,
increases monotonically iteration highlighting anytime property EM.
254

fiProbabilistic Inference Multiagent Decision Making

1400

1600
1400

1200

1200
1000

1000

800

800

600

600
400

400
200
0

200

EM(2)
EM(3)
EM(4)
EM(5)
0

20

40

60

EM(2)
EM(3)
EM(4)
EM(5)

0
-200

80 100 120 140 160 180 200

0

20

(a) 5P

40

60

80 100 120 140 160 180 200

(b) 11H

3500

4500
4000

3000

3500
2500

3000

2000

2500

1500

2000
1500

1000
500
0

1000

EM(2)
EM(3)
EM(4)
EM(5)
0

20

40

60

EM(2)
EM(3)
EM(4)
EM(5)

500
0

80 100 120 140 160 180 200

0

(c) 15-3D

20

40

60

80

100

120

140

160

(d) 20D

Figure 12: Solution quality achieved EM (y-axis denotes quality x-axis denotes
iteration number).

Instance\Size

2-Node

3-Node

4-Node

5-Node

5P
11H
15-3D
20D

.232
1.29
1.17
5.03

1.07
6.07
5.39
22.01

3.22
18.90
16.69
67.85

7.74
45.23
40.47
171.26

Table 2: Time seconds per iteration EM

general, solution quality increased number controller nodes. example,
20D, 2-node controller achieves quality 3585.06 5 node controller achieves
4154.04. However, 5P 15-3D, observe significant increase quality
increasing controller size, possibly due relative simplicity configurations.
Table 2 shows runtime per iteration EM different instances varying controller sizes. Encouragingly, runtime fairly smallparticularly smaller controller
sizeseven large problems 20D. decrease runtime larger
controllers, plan use Monte-Carlo sampling techniques future.
Table 3 shows solution quality comparison EM random controllers loose
upper bound. upper bound computed assuming target detected
every time step including battery recharge cost. random controllers, EM
255

fiKumar, Zilberstein, & Toussaint

Instance/Value

5P
11H
15-3D
20D

EM

1250.89
1509.27
3094.05
4154.04

(44.3%)
(35.6%)
(43.8%)
(49.1%)

U.B.

Random

2820
4230
7050
8460

61.23
8.41
104.2
31.67

Table 3: Quality comparisons loose upper bound random controllers
instances

N
2
3
4

Internal State = 2
EM
NLP
670.8/3.8
79/5.4
670.8/13.02 140.4/14.5
710.4/35.8
140.4/139.4

Internal
EM
972.5/8.9
1053.16/35.8
1062.4/107.4

State = 3
NLP
905.7/17.8
887.2/139
1024.8/1078.1

Table 4: Solution quality/time comparison EM (100 iterations) NLP 5P
domain, N denotes controller size, Time seconds

always achieves much better solution quality. compared upper bound,
see EM performs quite well. Despite loose bound, EM still achieves
quality within 49.1% bound largest 20D domaina solid performance.
Previously, algorithm could solve infinite-horizon ND-POMDPs (>2-agents).
assess EMs performance, developed nonlinear programming (NLP) formulation
problem used state-of-the-art NLP solver called Snopt (Gill et al., 2002). Snopt
could solve smallest 5P domain could scale beyond controller size 4
internal state 3 ran memory (=2GB). Table 4 shows solution quality
time comparisons. internal state size 2, Snopt gets stuck poor local optimum
compared EM. provides competitive solutions internal state 3, EM still
better solution quality. Furthermore, runtime Snopt degrades quickly
increase nonlinear constraints. makes Snopt order-of-magnitude slower
controller size 4 internal state 3. results highlight scalability
EM, could scale controller size 10 internal state 5 within 2GB RAM
4 hours 100 iterations.
Table 5 shows comparison EM handcrafted controllers designed take
account target trajectories partial observation 11H benchmark (Figure 11).
simplify problem handcrafted solution, penalties zero reward
detecting target 1. allowed continuous scan sensors without worrying
miscoordination penalty. first row table shows penalty case.
see EM competitive handcrafted controller. second row shows
results cost charge batteries. case, sensors need decide
become idle conserve power. handcrafted controller cannot learn behavior
hence EM produces much better quality case.
256

fiProbabilistic Inference Multiagent Decision Making

Version \ FSC Size Handcrafted 2 (EM) 3 (EM) 4 (EM)

penalty
Penalty (.25)

13.92
-3.36

13.95
5.27

15.48
5.27

15.7
5.27

Table 5: Quality handcrafted controllers vs. EM (11H)
Version \ FSC Size
Serial
Parallel

2
41.05
5.03

3
177.54
22.01

4
543.52
67.85

5
1308.20
171.26

Table 6: Serial vs. parallel execution times per EM iteration 20D.
Finally, Table 6 highlights significant opportunities EM provides parallel
computation. consistently obtained almost linear speedup using multithreading
8-core CPU (total possible parallel threads largest domain 20D 60).
using massively parallel platform Googles MapReduce,we could easily scale
much larger team decision problems currently possible.

7. Conclusion
Despite rapid progress multiagent planning, scalability prevailing formal
models algorithms limited. presented new approach multiagent planning developing novel connections multiagent planning machine learning.
showed multiagent planning problem reformulated inference mixture dynamic Bayesian networks. viewing multiagent planning lens
probabilistic inference, open door application efficient inference techniques
multiagent decision making.
improve scalability large multiagent systems, identified general condition called value factorization facilitated development scalable approximate
algorithm using probabilistic inference. showed several existing classes DecPOMDPs satisfy property. contrast previous approaches, framework
impose restrictions agent interaction beyond property, thus providing
general solution value factorization based structured multiagent planning. key
result supports scalability approach that, within EM framework,
inference process decomposed separate components much smaller
complete model, thus avoiding exponential complexity.
Empirically, experimented several standard large multiagent planning
benchmarks. inference-based approach competitive previous best approaches
based nonlinear linear programming. approach, linear complexity
number edges agent interaction graph could scale 20 agents, whereas
previous best approach based nonlinear programming could scale 5 agents
due increase number nonlinear constraints.
theoretical empirical results show exploring methods overlap machine learning planning great potential overcome practical limitations
existing multiagent planning algorithms. future work, plan explore several
257

fiKumar, Zilberstein, & Toussaint

directions. interested exploring overlap stochastic control theory multiagent planning continuous action state space models similar work Hoffman
et al. (2009a, 2009b). also plan explore ways overcome effect local
optima solution quality achieved EM algorithm. specifically plan investigate strategies escape local optima (Poupart, Lang, & Toussaint, 2011) adapt
multiagent setting.
Another key issue planning-as-inference strategy using EM algorithm
lack optimality guarantee upper bounds controller based joint-policy.
interesting recent research direction graphical models machine learning literature
development multiple inference strategies marginal MAP (Liu & Ihler, 2013).
shown EM algorithm used one inference approach solve
marginal MAP problem (Liu & Ihler, 2013). Planning uncertainty problems
categorized instance marginal MAP inference (Cheng, Liu, Chen, & Ihler,
2013). Therefore, developing graphical models exploit new inference approaches
marginal MAP problem provide quality guarantees interesting new direction
explore frontier planning machine learning.

Acknowledgments
work funded part National Science Foundation grants IIS-0812149
IIS-1116917, Air Force Office Scientific Research grant FA9550-08-1-0181,
EU 3rdHand project.

Appendix A. Proof EM Update Equations Definition 3
provide constructive proof, showing derivations relevant update equations.

A.1 Proof Eq. (13)
Q(, ? ) =

=

X
X


X

P (r = 1, L, ; )
log a?t pt

(52)

t=0

=0 L

X

X
X

=0

t=0 L

P (T )

P (r = 1, L|T ; ) log a?t pt

(53)

equation, variable L includes hidden variables DBN length
. simplify summation using marginalization variables
{at , pt }. also use fact policy stationary simplify as:
=

=


X

P (T )

X
X

=0

t=0 a,p


X

X
X

=0

P (T )

?
log ap

X
L\{at ,pt }

P (r = 1, = a, pt = p, L\{at , pt }|T ; )

?
log ap
P (r = 1, = a, pt = p|T ; )

t=0 a,p

258

(54)

(55)

fiProbabilistic Inference Multiagent Decision Making

A.2 Action Parameter Updates
expectation required action updates given Section 4.3 given as:
E [r = 1, a, p] =


X


X


P (T )
P (r = 1, a, p|T ; )

(56)

t=0

=0

breaking summation = = 0 1, get
E [r = 1, a, p] =


X


X
X
Rsab ap bq (p, q, s)+
P (T )
P (T )

=0

=0

qbs

1
X

X

t=0

p 0 q 0 s0

t1 (p0 , q 0 , s0 )Pt (a, p, p0 , q 0 , s0 )

(57)

equation, marginalized last time slice variables (q, b, s).
intermediate time slice t, condition upon variables (p0 , q 0 , s0 ) next time
slice + 1. use definition move summation time inside
last time slice marginalize remaining variables (q, s)
intermediate slice t:
E [r = 1, a, p] =

X

Rsab ap bq (p, q, s) +

X

t=0

p0 q 0 s0 sq

P (T )

=0

q,b,s

1
X


X

t1 (p0 , q 0 , s0 )ap P (p0 , q 0 , s0 |a, p, q, s)t (p, q, s)

(58)

Upon marginalizing joint observations 0 z 0 simplifying get:
E [r = 1, a, p] = ap

XX
qs

X

Rsab bq (p, q, s) +


X

P (T )

p0 q 0 s0 0 z 0 =0

b


1
X
t=0

t1 (p0 , q 0 , s0 )


P (s |a, q, s)p0 py0 q0 qz 0 P (y z |a, q, )t (p, q, s)
0

0 0

0

(59)

resolve time summation, Toussaint et al. (2006), based fact that:

1
X
X
=0 t=0

f (T 1)g(t) =

setting = 1 get
Finally get:

X

X
t=0 =t+1

P

t=0 g(t)

f (T 1)g(t)

P

=0 f ( ).

X


1


qs
b

X
0 0 0
0
0 0
0
(p , q , )p0 py0 q0 qz 0 P (s |a, q, s)P (y z |a, q, )

E [r = 1, a, p] = ap

X

(p, q, s)

p0 q 0 s0 0 z 0

259

Rsab bq +

(60)

fiKumar, Zilberstein, & Toussaint

product P (s0 |a, q, s)P (y 0 z 0 |a, q, s0 ) simplified marginalizing
actions b agent 2 follows:
E [r = 1, a, p] = ap

X

X
(p, q, s)
Rsab bq +

qs

X

0

0

b

0

(p , q , )p0 py0 q0 qz 0

p 0 q 0 s0 0 z 0

X


1


Oy0 z 0 s0 ab bq Ps0 sab

b

expectation E [r = 1, b, q] agent found similarly analogue
equation.
A.3 Controller Node Transition Parameter Updates
expectation required controller node transition parameters follows:
E [r = 1, p, p, y] =


X


X

P (T )

P (r = 1, pt = p, pt1 = p, yt = y|T ; )

(61)

t=1

=1

marginalizing variables (q, s) current time slice t, get

X
X
X
E [r = 1, p, p, y] =
P (T )
(p, q, s)Pt (p, p, y, s, q|T ; )

(62)

t=1 sq

=1

marginalizing variables (s, q) previous time slice
observations z agent, get
E [r = 1, p, p, y] = ppy


X

P (T )

X
X
t=1 sqsqz

=1

(p, q, s)qqz

P (yz|p, q, s)P (s|p, q, s)t1 (p, q, s)

(63)

equation simplified marginalizing product
P (yz|p, q, s)P (s|p, q, s) actions b agents follows:
E [r = 1, p, p, y] = ppy


X

P (T )

X
X

=1

t=1 sqsqz

(p, q, s)qqz t1 (p, q, s)

X

Oyzsab Pssab ap bq

ab

(64)
Upon resolving time summation before, get final expression as:
E [r = 1, p, p, y] = ppy

X

(p, q, s)(p, q, s)qqz

sqsqz

X

Oyzsab Pssab ap bq

(65)

ab

expectation E [r = 1, q, q, z] agent found analogous way.
260

fiProbabilistic Inference Multiagent Decision Making

A.4 Initial Node Distribution Update
expectation initial node distribution update given as:
E [r = 1, p] =


X

P (T )P (r = 1, p0 = p|T ; )

(66)

=0

expression computed follows:
E [r = 1, p] =
=
=


X
=0

X
=0

X

P (T )[P (r = 1, p|T ; )]t=0
P (T )

P0 (r = 1|p, q, s, ; )P0 (p, q, s)

(68)

(p, s, q)p q 0 (s)

(69)

qs

P (T )

=0

= p

X

(67)

X

X
qs

(p, s, q)q 0 (s)

(70)

qs

Appendix B. EM Derivation ND-POMDP Model
n-agent ND-POMDP following parameters:
= 1in Si Su , Si local state agent i; Su set uncontrollable
external states independent agents actions. sensor network
example, Si battery level, Su corresponds set locations
targets present.
= 1in Ai Ai set actions agent i. sensor network,
Ai ={l1 , . . . , lk ,Off, Recharge}, {l1 , . . . , lk } represents edges graph
scanned given sensor agent.
= 1in Yi joint observation set. sensor network case, Yi = {target
present, absent, sensor idle}. assume sensor observe internal state Si .
realistic assumption sensors normally monitor battery level.
noisy component observation set corresponds target locations.
Q
P P (s0 |s, a) = Pu (s0u |su ) ni=1 Pi (s0i |si , su , ai ) transition model, = ha1 , . . . ,
joint action taken joint state = hsu , s1 , . . . , sn resulting joint state s0 =
hs0u , s01 , . . . , s0n i. model relies conditional (on external state) transition independence among agents.
Q
O(y|s, a) = ni=1 Pi (yi |ai , su , si , ), joint observation taking joint
action transitioning joint state s. relies conditional observation independence.
P
R R(s, a) = l Rl (su , sl , al ) reward function, decomposable along subgroups
agents defined set links l. k agents i1 , . . . , ik members particular
261

fiKumar, Zilberstein, & Toussaint

p0

p1

a0

a1

y2

a2

p3

pT

y3

yT



u0

u1

u2

uT

s0

s1

s2

sT

v0

v1

v2

vT

b0

q0

y1

p2

z1

q1

b1

z2

b2

q2

z3

zT

q3

qT

r

bT

Figure 13: T-step DBN link involving two agents. one DBN
link l every time step .
top three layers, p denotes first agents (on
1
link l) controller nodes, denotes action u denotes internal state. layer
si denotes external state. bottom three layers, q denotes second agents
controller nodes, b denotes action v denotes internal state

subgroup l, sl = hsi1 , . . . , sik denotes internal states agents. Similarly,
al = hai1 , . . . , aik i. sensor network 5P Figure 11, reward decomposed
among five subgroups, one per edge. reward function thus induces interaction hypergraph hyperlink l connects subset agents form
reward component Rl .
bo bo = (buQ, b1 , . . . , bn ) initial belief joint state = hsu , s1 , . . . , sn b(s) =
bu (su ) ni=1 bi (si ).

joint-value function ND-POMDPs satisfies value factorization property follows (Nair et al., 2005):
X
V (, s) =
Vl (l , su , sl ).
l

one value factor Vl link l. next present T-step DBN factor l
involves two agents. DBN basis time-dependent DBN mixture
value factor l. ease exposition, nodes controller one agent denoted
p agent q. internal states, actions, observations
first agent denoted u, a, respectively v, b, z denote second
agent. external state denoted s. shown Section 5.4.1, E step
EM algorithm requires separate inference, one value factor Vl . Therefore,
derive inference required time dependent mixture corresponding DBN
Figure 13. Notice differs inference two-agent general Dec-POMDP
due presence conditional transition observation independence. property
exploited E-step. policy parameters optimized defined
262

fiProbabilistic Inference Multiagent Decision Making

agent 1 (analogously agent 2 well) as:
apu = P (a|p, u)
0

p0 py = P (p |p, y)

p = P (pt=0 = p)

(71)
(72)
(73)

Notice also included internal state u action parameter apu . represents expressive accurate policy agents full observability internal
state. Next, similar Section 4.4, define following Markovian chain DBN
Figure 13:
P (p0,q 0,s0,u0,v 0|p, q, s, u, v) = P (p0,u0|p, u, s)P (q 0,v 0|q, v, s)P (s0|s)
X
P (p0,u0 |p, u, s) =
p0 py Pu0 au Pyasu apu

(74)
(75)

a,y

P (q 0,v 0|q, v, s) expressed similarly. transitions independent time
use stationary policy. Based transitions, define forward messages
follows: = Pt (p, q, s, u, v; ). Intuitively, represents probability controllers
agents link state (p, q), internal state (u, v) external state
time t. messages defined as:
0 (p, q, s, u, v) = p q bo (s, u, v)
X
(p0,q 0,s0,u0,v 0 ) =
P (p0,q 0,s0,u0,v 0|p, q, s, u, v)t1 (p, q, s, u, v)

(76)
(77)

p,q,s,u,v

Similarly backward messages defined follows: = PT (r=1|p, q, s, u, v; ),
= 0 representing tail end DBN. shown Toussaint et al. (2006), thanks
notation, DBNs share tail. Hence need one sweep compute
messages. get:
X
0 (p, q, s, u, v)=
Rsuvab apu bqv

(78)

a,b

X
(p, q, s, u, v)= 1 (p0,q 0,s0,u0,v 0 )P (p0,q 0,s0,u0,v 0|p, q, s, u, v)

(79)

p0,q 0,s0,u0,v 0

represents normalized expected reward link controllers agents
state (p, q), internal state (u, v) external state time ,
given policy parameters . Based messages, also calculate two
quantities:
(p, q, s, u, v) =
(p, q, s, u, v) =


X
t=0

X

P (T = t)t (p, q, s, u, v),

(80)

P (T = ) (p, q, s, u, v).

(81)

=0

263

fiKumar, Zilberstein, & Toussaint

cutoff time message propagation fixed shown Section 4.4.
shown Section 5.4.1, expectation required action updates following
time dependent DBN mixture link l:
El [r = 1, a, p, u] =


X

P (T )


X

P (r = 1, = a, pt = p, ut = u|T ; l )

(82)

t=0

=0

Breaking inner summation last time step remainder, get:
=

=


X

P (T )PT (r = 1, a, p, u)+

=0
X
X



1
X
X
P (T )
Pt (r = 1, a, p, u)
t=0

=0



1 X
X
X
Rsuvab apu bqv (p, q, s, u, v)+ P (T )
t1 (p0,q 0,s0,u0,v 0 )Pt (a,p,u, p0,q 0,s0,u0,v 0 )

=0 svqb

t=0 p0 q 0 s0 u0 v 0

=0

last equality, marginalized variables intermediate time slice.
moving summation time inside last time slice, marginalizing
intermediate time slice (q, s, v), get:
= apu
0

X

Rsuvab bqv (p, q, s, u, v) +


X

P (T )

X
t1 (p0 , q 0 , s0 , u0 , v 0 )P (p0 , u0 |a, p, u, s)

t=0 qvsp0 q 0 s0 u0 v 0

=0

svqb
0


1
X

P (q , v |q, v, s)Ps0 apu (p, q, s, u, v)
Upon resolving time summation second part equation (Toussaint et al.,
2006), get final expression:

X
p0 q 0 s0 u0 v 0

X


1
qsv
b

0 0 0 0 0
0 0
0 0
0
(p , q , , u , v )P (p , u |a, p, u, s)P (q , v |q, v, s)Ps

El [r = 1, a, p, u]

= apu

X

(p, q, s, u, v)

Rsuvab bqv +

expectation El [r = 1, b, q, v] agent calculated analogous
manner.
derive expectation controller node transition update:
El [r = 1, p, p, y] =


X

P (T )

=1


X

P (r = 1, pt = p, pt1 = p, yt = y|T ; l )

t=1

simplifying equation, get:
=


X
=1

P (T )

X
X
t=1 qsuv

(p, q, s, u, v)Pt (p, q, s, u, v, p, y)
264

(83)

fiProbabilistic Inference Multiagent Decision Making

Upon marginalizing (q, s, u, v), get:
=


X

P (T )


X

X

t=1 qsuvqsuv

=1


(p, q, s, u, v)Pt (p, q, s, u, v|p, q, s, u, v, y)

P (y|p, u, s)t1 (p, q, s, u, v)

=


X

P (T )

=1


X
t=1

X

ppy

qsuvqsuv


(p, q, s, u, v)t1 (p, q, s, u, v)P (y|p, u, s)

P (u|p, u, y)Pss P (q, v|q, v, s)

= ppy

X

(p, q, s, u, v)(p, q, s, u, v)P (u, y|p, u, s)Pss P (q, v|q, v, s)

qsuvqsuv

P (u, y|p, u, s), P (q, v|q, v, s) defined as:
X
P (u, y|p, u, s) =
Puau Pyasu apu

(84)



P (q, v|q, v, s) =

X

qqz Pvbv Pz bsv bqv

(85)

bz

final equation El [r = 1, p, p, y] given by:
X
El [r = 1, p, p, y] = ppy
(p, q, s, u, v)(p, q, s, u, v)P (u, y|p, u, s)Pss P (q, v|q, v, s)
qsuvqsuv

(86)

References
Amato, C., Bernstein, D. S., & Zilberstein, S. (2007). Solving POMDPs using quadratically constrained linear programs. International Joint Conference Artificial
Intelligence, pp. 24182424.
Amato, C., Bernstein, D. S., & Zilberstein, S. (2010). Optimizing fixed-size stochastic
controllers POMDPs decentralized POMDPs. Autonomous Agents MultiAgent Systems, 21 (3), 293320.
Becker, R., Zilberstein, S., & Lesser, V. (2004). Decentralized Markov decision processes
event-driven interactions. Proceedings 3rd International Conference
Autonomous Agents Multiagent Systems, pp. 302309.
Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2003). Transition-independent
decentralized Markov decision processes. Proceedings 2nd International Conference Autonomous Agents Multi Agent Systems, pp. 4148.
Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2004). Solving transition independent decentralized Markov decision processes. Journal Artificial Intelligence
Research, 22, 423455.
265

fiKumar, Zilberstein, & Toussaint

Bernstein, D. S., Amato, C., Hansen, E. A., & Zilberstein, S. (2009). Policy iteration
decentralized control Markov decision processes. Journal Artificial Intelligence
Research, 34, 89132.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). complexity
decentralized control Markov decision processes. Mathematics Operations
Research, 27, 819840.
Bertsekas, D. P. (1999). Nonlinear Programming (2nd edition). Athena Scientific.
Boyd, S., & Vandenberghe, L. (2004). Convex Optimization. Cambridge University Press,
New York, NY, USA.
Cheng, Q., Liu, Q., Chen, F., & Ihler, A. (2013). Variational planning graph-based
MDPs. Advances Neural Information Processing Systems, pp. 29762984.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood incomplete
data via EM algorithm. Journal Royal Statistical society, Series B, 39 (1),
138.
Dibangoye, J. S., Amato, C., Doniec, A., & Charpillet, F. (2013a). Producing efficient errorbounded solutions transition independent decentralized MDPs. Proceedings
International Conference Autonomous Agents Multi-agent Systems, pp.
539546.
Dibangoye, J. S., Amato, C., Buffet, O., & Charpillet, F. (2013b). Optimally solving DecPOMDPs continuous-state MDPs. Proceedings 23rd International Joint
Conference Artificial Intelligence, pp. 9096.
Dibangoye, J. S., Buffet, O., & Charpillet, F. (2014). Error-bounded approximations
infinite-horizon discounted decentralized POMDPs. Proceedings European
Conference Machine Learning Knowledge Discovery Databases, pp. 338353.
Dibangoye, J. S., Mouaddib, A.-I., & Chaib-draa, B. (2009). Point-based incremental pruning heuristic solving finite-horizon DEC-POMDPs. Proceedings 8th International Joint Conference Autonomous Agents Multiagent Systems, pp.
569576.
Eker, B., & Akin, H. L. (2013). Solving decentralized POMDP problems using genetic
algorithms. Autonomous Agents Multi-Agent Systems, 27 (1), 161196.
Ghahramani, Z., & Jordan, M. I. (1995). Factorial hidden Markov models. Advances
Neural Information Processing Systems, Vol. 8, pp. 472478.
Gill, P. E., Murray, W., & Saunders, M. A. (2002). SNOPT: SQP algorithm largescale constrained optimization. SIAM Journal Optimization, 12 (4), 9791006.
Goldman, C. V., & Zilberstein, S. (2004). Decentralized control cooperative systems:
Categorization complexity analysis. Journal Artificial Intelligence Research,
22, 143174.
Grzes, M., Poupart, P., & Hoey, J. (2013). Controller compilation compression resource constrained applications. International Conference Algorithmic Decision
Theory, pp. 193207.
266

fiProbabilistic Inference Multiagent Decision Making

Grzes, M., Poupart, P., Yang, X., & Hoey, J. (2015). Energy efficient execution POMDP
policies. IEEE Transactions Cybernetics, preprint.
Hansen, E. A., Bernstein, D. S., & Zilberstein, S. (2004). Dynamic programming partially
observable stochastic games. Proceedings 19th AAAI Conference Artificial
Intelligence, pp. 709715.
Hoffman, M., de Freitas, N., Doucet, A., & Peters, J. (2009a). expectation maximization algorithm continuous Markov decision processes arbitrary rewards.
Proceedings International Conference Artificial Intelligence Statistics,
pp. 232239.
Hoffman, M., Kueck, H., de Freitas, N., & Doucet, A. (2009b). New inference strategies
solving Markov decision processes using reversible jump MCMC. Proceedings
International Conference Uncertainty Artificial Intelligence, pp. 223231.
Kiselev, I., & Poupart, P. (2014a). Policy optimization marginal-map probabilistic inference generative models. Proceedings International Conference Autonomous Agents Multi-agent Systems, pp. 16111612.
Kiselev, I., & Poupart, P. (2014b). POMDP planning marginal-MAP probabilistic inference generative models. Proceedings 2014 AAMAS Workshop Adaptive
Learning Agents.
Koller, D., & Parr, R. (1999). Computing factored value functions policies structured MDPs. Proceedings 16th International Joint Conference Artificial
Intelligence, pp. 13321339.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles Techniques. MIT Press.
Kumar, A., & Zilberstein, S. (2009a). Constraint-based dynamic programming decentralized POMDPs structured interactions. Proceedings Eighth International
Conference Autonomous Agents Multiagent Systems, pp. 561568.
Kumar, A., & Zilberstein, S. (2009b). Event-detecting multi-agent MDPs: Complexity
constant-factor approximation. Proceedings 21st International Joint
Conference Artificial Intelligence, pp. 201207.
Kumar, A., & Zilberstein, S. (2010a). Anytime planning decentralized POMDPs using expectation maximization. Proceedings Conference Uncertainty
Artificial Intelligence, pp. 294301.
Kumar, A., & Zilberstein, S. (2010b). Point-based backup decentralized POMDPs:
Complexity new algorithms. Proceedings 9th International Conference
Autonomous Agents Multiagent Systems, pp. 13151322.
Kumar, A., Zilberstein, S., & Toussaint, M. (2011). Scalable multiagent planning using
probabilistic inference. Proceedings 22nd International Joint Conference
Artificial Intelligence, pp. 21402146.
Lauritzen, S. L., & Nilsson, D. (2001). Representing solving decision problems
limited information. Management Science, 47, 12351251.
267

fiKumar, Zilberstein, & Toussaint

Liu, Q., & Ihler, A. T. (2012). Belief propagation structured decision making.
Proceedings Twenty-Eighth Conference Uncertainty Artificial Intelligence,
Catalina Island, CA, USA, August 14-18, 2012, pp. 523532.
Liu, Q., & Ihler, A. T. (2013). Variational algorithms marginal MAP. Journal
Machine Learning Research, 14 (1), 31653200.
MacDermed, L. C., & Isbell, C. (2013). Point based value iteration optimal belief compression Dec-POMDPs. Advances Neural Information Processing Systems,
pp. 100108.
Marecki, J., Gupta, T., Varakantham, P., Tambe, M., & Yokoo, M. (2008). agents
equal: Scaling distributed POMDPs agent networks. Proceedings
7th International Joint Conference Autonomous Agents Multiagent Systems,
pp. 485492.
Mostafa, H., & Lesser, V. R. (2009). Offline planning communication exploiting structured interactions decentralized MDPs. International Conference Intelligent
Agent Technology, pp. 193200.
Mostafa, H., & Lesser, V. R. (2011). Compact mathematical programs DEC-MDPs
structured agent interactions. International Conference Uncertainty
Artificial Intelligence, pp. 523530.
Mundhenk, M., Goldsmith, J., Lusena, C., & Allender, E. (2000). Complexity finitehorizon Markov decision process problems. J. ACM, 47 (4), 681720.
Nair, R., Varakantham, P., Tambe, M., & Yokoo, M. (2005). Networked distributed
POMDPs: synthesis distributed constraint optimization POMDPs. Proceedings 20th AAAI Conference Artificial Intelligence, pp. 133139.
Nair, R., Tambe, M., Yokoo, M., Pynadath, D., Marsella, S., Nair, R., & Tambe, M. (2003).
Taming decentralized POMDPs: Towards efficient policy computation multiagent
settings. Proceedings 18th International Joint Conference Artificial Intelligence, pp. 705711.
Oliehoek, F. A., Spaan, M. T. J., Amato, C., & Whiteson, S. (2013). Incremental clustering
expansion faster optimal planning Dec-POMDPs. Journal Artificial
Intelligence Research, 46, 449509.
Oliehoek, F. A., Spaan, M. T. J., & Vlassis, N. A. (2008). Optimal approximate Q-value
functions decentralized POMDPs. Journal Artificial Intelligence Research, 32,
289353.
Oliehoek, F. A., Whiteson, S., & Spaan, M. T. J. (2013). Approximate solutions factored
dec-pomdps many agents. Proceedings 12th International Conference
Autonomous Agents Multiagent Systems, pp. 563570.
Pajarinen, J., Hottinen, A., & Peltonen, J. (2014). Optimizing spatial temporal reuse
wireless networks decentralized partially observable Markov decision processes.
IEEE Transactions Mobile Computing, 13 (4), 866879.
Pajarinen, J., & Peltonen, J. (2011a). Efficient planning factored infinite-horizon DECPOMDPs. Proceedings 22nd International Joint Conference Artificial
Intelligence, pp. 325331.
268

fiProbabilistic Inference Multiagent Decision Making

Pajarinen, J., & Peltonen, J. (2011b). Periodic finite state controllers efficient POMDP
DEC-POMDP planning. Advances Neural Information Processing Systems,
pp. 26362644.
Pajarinen, J., & Peltonen, J. (2013). Expectation maximization average reward decentralized POMDPs. Proceedings European Conference Machine Learning,
pp. 129144.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations large
POMDPs. Journal Artificial Intelligence Research, 27, 335380.
Poupart, P., & Boutilier, C. (2003). Bounded finite state controllers. Advances Neural
Information Processing Systems.
Poupart, P., Lang, T., & Toussaint, M. (2011). Analyzing escaping local optima
planning inference partially observable domains. European Conference
Machine Learning, pp. 613628.
Seuken, S., & Zilberstein, S. (2007). Memory-bounded dynamic programming DECPOMDPs. Proceedings 20th International Joint Conference Artificial
Intelligences, pp. 20092015.
Smith, T., & Simmons, R. (2004). Heuristic search value iteration POMDPs. International Conference Uncertainty Artificial Intelligence, pp. 520527.
Toussaint, M., Harmeling, S., & Storkey, A. (2006). Probabilistic inference solving
(PO)MDPs. Tech. rep. EDIINF-RR-0934, University Edinburgh, School Informatics.
Toussaint, M., Charlin, L., & Poupart, P. (2008). Hierarchical POMDP controller optimization likelihood maximization. International Conference Uncertainty
Artificial Intelligence, pp. 562570.
Toussaint, M., & Storkey, A. J. (2006). Probabilistic inference solving discrete
continuous state Markov decision processes. International Conference Machine
Learning, pp. 945952.
Varakantham, P., Marecki, J., Yabu, Y., Tambe, M., & Yokoo, M. (2007). Letting loose
SPIDER network POMDPs: Generating quality guaranteed policies.
Proceedings 6th International Joint Conference Autonomous Agents
Multiagent Systems, pp. 18.
Varakantham, P., Kwak, J., Taylor, M. E., Marecki, J., Scerri, P., & Tambe, M. (2009).
Exploiting coordination locales distributed POMDPs via social model shaping.
Proceedings 19th International Conference Automated Planning Scheduling, pp. 313320.
Witwicki, S. J. (2011). Abstracting Influences Efficient Multiagent Coordination
Uncertainty. Ph.D. thesis, Department Computer Science, University Michigan,
Ann Arbor.
Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction weaklycoupled Dec-POMDPs. Proceedings 20th International Conference Automated Planning Scheduling, pp. 185192.
269

fiKumar, Zilberstein, & Toussaint

Witwicki, S. J., & Durfee, E. H. (2011). Towards unifying characterization quantifying
weak coupling Dec-POMDPs. Proceedings 10th International Conference
Autonomous Agents Multiagent Systems, pp. 2936.
Wu, F., Zilberstein, S., & Chen, X. (2010). Trial-based dynamic programming multiagent planning. Proceedings 24th AAAI Conference Artificial Intelligence,
pp. 908914.
Wu, F., Zilberstein, S., & Jennings, N. R. (2013). Monte-Carlo expectation maximization
decentralized POMDPs. Proceedings 23rd International Joint Conference
Artificial Intelligence, pp. 397403.

270

fiJournal Artificial Intelligence Research 53 (2015) 541-632

Submitted 01/15; published 07/15

ITSAT: Efficient SAT-Based Temporal Planner
Masood Feyzbakhsh Rankooh
Gholamreza Ghassem-Sani

feyzbakhsh@ce.sharif.edu
sani@sharif.edu

Computer Engineering Department,
Sharif University Technology,
Azadi ave., Tehran, Iran

Abstract
Planning satisfiability known efficient approach deal many types
planning problems. However, approach competitive state-space
based methods temporal planning. paper describes ITSAT efficient SAT-based
(satisfiability based) temporal planner capable temporally expressive planning.
novelty ITSAT lies way handles temporal constraints given problems without
getting involved difficulties introducing continuous variables corresponding
satisfiability problems. also show how, SAT-based classical planning, carefully
devised preprocessing encoding schemata considerably improve efficiency
SAT-based temporal planning. present two preprocessing methods mutex relation
extraction action compression. also show separation causal temporal
reasoning enables us employ compact encodings based concept parallel
execution semantics. Although encodings shown quite effective
classical planning, ITSAT first temporal planner utilizing type encoding.
empirical results show ITSAT outperform state-of-the-art temporally
expressive planners, also competitive fast temporal planners cannot
handle required concurrency.

1. Introduction
Temporal planning extension classical planning actions durative rather
instantaneous. introduction durative actions adds new dimension
solving planning problems, namely reasoning time. Temporal reasoning per se
different causal reasoning, time real-valued quantity, whereas causal
aspects planning normally represented propositions.
current standard language defining temporal planning problems PDDL2.1
(Fox & Long, 2003). Although PDDL+ (Fox & Long, 2002) introduced
planning community expressive language defining temporal numerical
planning problems, throughout paper, focus PDDL2.1, planning
problems tackled need expressive power PDDL+. PDDL2.1,
actions separate preconditions effects upon starting ending. temporal
action also invariants, must preserved execution
action. important subset problems defined PDDL2.1 problems every
valid plan includes concurrent execution two actions. subset called
problems required concurrency. shown concurrent execution two
actions may necessary solving temporal problems (Halsey, Long, & Fox, 2004;
Cushing, Kambhampati, Mausam, & Weld, 2007). instance, temporal planning
c
2015
AI Access Foundation. rights reserved.

fiRankooh & Ghassem-Sani

problems, actions may require proposition available execution
another action. cases, two actions must executed concurrently.
specific example given Section 2, describe Driverlogshift domain.
common approach many planners temporally expressive eliminate
cases compressing temporal actions create non-durative classical actions.
paper, describe ITSAT, temporally expressive SAT-based (i.e., satisfiability
based) planner. ITSAT uses approach takes advantage parallel execution semantics without rendering incomplete problems required concurrency.
approach, durations actions given problem first abstracted out.
done breaking temporal action two starting ending instantaneous events.
obtained temporally abstract problem encoded SAT formula using novel
-step -step semantics causally valid plans. show semantics
used encode given temporal planning problem SAT formula. Classical -step
-step encoding methods introduced (Rintanen, Heljanko, & Niemela,
2006). addition extending methods temporal planning context, also
introduce new encoding method based -step semantics causally valid plans.
show new encoding often results significant reduction number required
steps.
generating causally valid plan, ITSAT performs scheduling phase.
phase, ITSAT tries satisfy temporal constraints imposed considering
durations actions. done solving Simple Temporal Problem (STP) (Dechter,
Meiri, & Pearl, 1991). However, problems required concurrency, posed STP
may inconsistent. cases, cause inconsistency, manifests
negative cycle corresponding Simple Temporal Network (STN), detected. ITSAT
generates number clauses added SAT formula, collectively prevent
reoccurrence particular negative cycle occurred similar cycles.
process repeated temporally valid plan found.
Similar SAT-based planners, ITSAT takes advantage preprocessing phase
extract information structure problems. information used
throughout encoding phase produce formula whose satisfiability checked
efficiently SAT solver. Section 3, describe preprocessing phase
ITSAT, includes reasoning mutual exclusion so-called safe action
compression (Coles, Coles, Fox, & Long, 2009). Two propositions regarded mutually
exclusive never jointly true state valid temporal plan. Here,
show one detect mutually exclusive propositions temporal problems using
planning graph analysis (Blum & Furst, 1997). known employing mutual exclusion
reasoning significantly improve performance SAT-based planners (Gerevini &
Schubert, 1998).
mentioned earlier, ITSAT breaks temporal action two starting
ending instantaneous events. Although cases breaking might
necessary producing concurrent plans, situations necessary
finding valid plans. Section 3, show using mutual exclusion information,
one identify temporal actions safely compressed classical action
without falsifying validity temporal plans. analysis results smaller number
distinct events therefore simpler planning problem.
542

fiITSAT: Efficient SAT-Based Temporal Planner

empirically show taking advantage preprocessing, encoding,
scheduling phases, ITSAT significantly outperform state-of-the-art temporally expressive planners, also competitive best temporally simple planners
incapable solving problems required concurrency property. components ITSAT shown Figure 1. figure, processing components
ITSAT system shown rectangular blocks, links represents data produced
received components.

Figure 1. block diagram ITSAT

543

fiRankooh & Ghassem-Sani

1.1 Motivation
mentioned earlier, temporal planners need reason time, continuous
quantity. Nevertheless, causal structures problems temporal planning still
similar classical planning. existence abundant temporal planning domains
also classical versions regarded evidence claim. suggests
temporal planners benefit using approaches previously shown
effective dealing classical problems.
usage Boolean satisfiability checking well-known paradigm tackling classical
planning problems (Kautz & Selman, 1992). approach, given planning problem
translated formula propositional logic. variable SAT formula typically
represents occurrence corresponding action proposition certain place
potential plan. causal constraints planning problem represented number
ground clauses. output plan assumed finite number steps. step
may include one actions. original SAT-based planner allowed one action
per step (Kautz & Selman, 1992). However, previously introduced SAT-based planners
allow multiple occurrence actions step. produced formula given
input off-the-shelf SAT solver, tries find model it. model
found, plan extracted it. Otherwise, number steps output plan
increased one corresponding SAT formula given SAT solver.
process repeated valid plan extracted predefined termination condition
reached. order obtain efficient SAT-based planner, one important issue
considered encode given planning problem SAT formula.
SAT-based planning originally used find optimal plans, i.e., plans minimum
number actions (Kautz & Selman, 1992). guarantee optimality output plan,
formula must include certain clauses ban step containing one
action. However, so-called satisficing planning, optimality main
objective, forcing single-action steps necessary. alternative approach consider
actions executed parallel step output plan (Ernst, Millstein,
& Weld, 1997). Exploiting parallelism result smaller number steps
SAT formula. Another important benefit producing compact formulae lower memory
requirements. Several encoding methods introduced take advantage action
parallelism. encoding methods based so-called -step -step semantics
valid plans (Rintanen et al., 2006).
-step -step semantics different extent action parallelism
allow occur step. -step semantics allows set actions executed
parallel, actions executed every possible ordering without affecting
validity plan. -step semantics, hand, imposes weaker restriction:
step plan, must exist least one possible ordering actions
executed without falsifying validity plan. clear -step
semantics potentially allows parallelism permitted -step semantics.
fact, taking advantage -step semantics, efficient SAT-based classical planner,
i.e., Mp (Rintanen, 2012), competitive state-of-the-art state-space planners.
paper, show separation causal temporal reasoning phases temporal
planning enables us employ compact encodings efficient temporal planning.
544

fiITSAT: Efficient SAT-Based Temporal Planner

1.2 Related Work
Previous research field temporal planning benefited enormously employing
well-developed classical planning strategies. instance, many successful temporal planners utilized ideas partial order planning, e.g. VHPOP (Younes & Simmons,
2003) CPT (Vidal & Geffner, 2006). Planning graph analysis also adopted
temporal planners TGP (Smith & Weld, 1999) TPSYS (Garrido, Fox, & Long,
2002). temporal planners embedded temporal reasoning heuristic
state space search. TFD (Eyerich, Mattmuller, & Roger, 2009), LPG-td (Gerevini, Saetti,
& Serina, 2006), POPF (Coles, Coles, Fox, & Long, 2010) successful instances
latter approach.
usage Boolean satisfiability checking one well-known paradigms tackling classical planning problems (Kautz & Selman, 1992). order obtain efficient
SAT-based planner, one important issue considered encode
given planning problem SAT formula. fact, devising efficient encoding methods
important research trend field SAT-based planning. Examples
efficient encodings are: split action representation (Kautz & Selman, 1996; Ernst et al.,
1997; Robinson, Gretton, Pham, & Sattar, 2009), SAS+ based encoding (Huang, Chen,
& Zhang, 2012), compact mutual exclusion representation (Rintanen, 2006). Based
parallel semantics plans, another effective encoding method introduced (Rintanen et al., 2006). latter encoding method particular interest paper.
Satisfiability checking also employed field temporal planning. However,
SAT-based temporal planners encounter major challenge: representing temporal aspects problems. Since time continuous quantity, cannot treated exact
way discrete causality handled. tackle problem, STEP (Huang, Chen, &
Zhang, 2009), SCP2 (Lu, Huang, Chen, Xu, Zhang, & Chen, 2013), T-SATPLAN (Mali
& Liu, 2006) use discrete representation time. planners assign explicit discrete
time labels step encoding. Generally speaking, approach, step
exactly one time unit ahead step + 1. result, action duration starts
step i, forced end step + d. One immediate outcome approach
introduction enormous number steps encoding, many
contribute output plan. drawback explicit time representation causes
STEP, SCP2, T-SATPLAN inefficient terms speed memory usage. obtain better performance, SCP2 uses -step semantic allow causal relations
actions time point (Lu et al., 2013).
TM-LPSAT (Shin & Davis, 2005), designed solve planning problems
defined PDDL+ (Fox & Long, 2002), another SAT-based planner capable handling
temporal planning problems. Similar STEP T-SATPLAN, TM-LPSAT attaches
time labels step. However, TM-LPSAT, labels predefined discrete
numbers. Instead, label numeric variable whose value determined
problem solved SMT solver (Armando & Giunchiglia, 1993). approach
result encodings compact produced STEP TSATPLAN.
major disadvantage assigning time label step formula parallelism mentioned cannot exploited effectively. two events
545

fiRankooh & Ghassem-Sani

happen certain step plan, time labels must same, thus,
must simultaneous final plan executed. compulsory simultaneity
restriction reduces number events happen step final
plan, turn, increases number steps needed solving input problems.
implies efficiency gain one could obtain using parallel execution semantics
sacrificed achieve easy way deal temporal constraints. However,
majority current temporal planning problems, satisfying temporal constrains
hardest task finding valid plan. shown problems without required
concurrency, one omit temporal constraints altogether, find causally valid plan,
then, considering temporal constraints postproccessing step, schedule
actions plan find temporally valid plan (Cushing et al., 2007). approach
actually used many previous temporal planners including YAHSP3-mt (Vidal,
2014), winner temporal satisficing track IPC 2014. Despite efficient
solving many temporal problems, planners incomplete, incapable
solving problems required concurrency.
addition classical planning problems, SAT-based methods also used
deal categories planning problems. Examples planning uncertainty
(Castellini, Giunchiglia, & Tacchella, 2003), cost-optimal planning (Robinson, Gretton,
Pham, & Sattar, 2010) numerical planning (Hoffmann, Gomes, Selman, & Kautz,
2007).

2. Preliminaries
standard language used defining temporal planning problems PDDL2.1 (Fox &
Long, 2003). Figure 2 presents example PDDL2.1 representation temporal
planning domain. domain, simplified version Driverlogshift (Halsey, 2004),
referred several times throughout paper. Figure 2 shows, PDDL2.1,
action separate conditions effects upon starting ending. starting
ending conditions (or effects) action specified start end
tokens, respectively. action may also conditions need preserved
execution. conditions specified using token. Moreover,
duration action defined (= ?duration x) statement, x rational
number function specifying actual duration action.
Driverlogshift temporal version Driverlog domain IPC3.
classical counterpart, Driverlogshift, objective transfer several objects
original places destinations. object loaded unloaded
certain truck using LOAD UNLOAD operators, respectively. truck move
locations using MOVE operator. main difference Driverlogshift
Driverlog trucks must rested intervals working
shifts. working shift defined WORK operator, produces (working
truck) proposition upon starting, deletes proposition upon ending. LOAD, UNLOAD,
MOVE (working truck) invariant. (working truck) deleted
ending WORK, may reproduced REST operator, defines resting
shift certain truck.
546

fiITSAT: Efficient SAT-Based Temporal Planner

(define (domain driverlogshift)
(:requirements :typing :durative-actions)
(:types
location locatable - object
truck obj - locatable)
(:predicates
(at ?obj - locatable ?loc - location)
(in ?obj1 - obj ?obj - truck)
(link ?x ?y - location)
(working ?t - truck)
(need-rest - truck)
(rested - truck))
(:durative-action WORK
:parameters
(?truck - truck)
:duration (= ?duration 100)
:condition (and
(at start (rested ?truck)))
:effect (and (at start (working ?truck))
(at end (not (working ?truck)))
(at start (not (rested ?truck)))
(at end (need-rest ?truck))))
(:durative-action REST
:parameters
(?truck - truck)
:duration (= ?duration 20)
:condition (and
(at start (need_rest ?truck)))
:effect (and
(at start (not (need_rest ?truck)))
(at end (rested ?truck))))
(:durative-action LOAD
:parameters
(?obj - obj
?truck - truck
?loc - location)
:duration (= ?duration 10)
:condition (and
(over (at ?truck ?loc))
(over (working ?truck))
(at start (at ?obj ?loc)))
:effect (and
(at start (not (at ?obj ?loc)))
(at end (in ?obj ?truck))))

(:durative-action UNLOAD
:parameters
(?obj - obj
?truck - truck
?loc - location)
:duration (= ?duration 10)
:condition (and
(over (at ?truck ?loc))
(over (working ?truck))
(at start (in ?obj ?truck)))
:effect (and
(at start (not (in ?obj ?truck)))
(at end (at ?obj ?loc))))
(:durative-action MOVE
:parameters
(?truck - truck
?loc-from - location
?loc-to - location)
:duration (= ?duration 50)
:condition (and
(at start (at ?truck ?loc-from))
(at start (link ?loc-from ?loc-to))
(over (working ?truck)))
:effect (and
(at start (not (at ?truck ?loc-from)))
(at end (at ?truck ?loc-to)))))

Figure 2. PDDL2.1 description Driverlogshift domain

Note version Driverlogshift described Figure 2 slightly different
original version (Halsey, 2004), drivers walk to, board,
disembark trucks. Furthermore, REST WORK actions performed drivers
rather trucks. However, order make examples simpler, merged drivers
trucks single entity trucks.
simple example problems Driverlogshift shown Figure 3. problem,
three locations (s0, s1, s2), one truck (truck1), one object (package1).
initial state, truck1 package1 s0. objective problem
transfer package1 s2.
2.1 Formalism PDDL2.1
present formalism specifications PDDL2.1. formalism devised
way simplifies description preprocessing, encoding, scheduling phases
ITSAT. mention formalism limitations compared
full specifications PDDL2.1. limitations discussed details Section 2.2.
547

fiRankooh & Ghassem-Sani

(define (problem DLOG)
(:domain driverlogshift)
(:objects
truck1
- truck
package1 - obj
s0 s1 s2 - location)
(:init
(rested truck1)
(at truck1 s0)
(at package1 s0)
(link s0 s1)
(link s1 s0)
(link s2 s1)
(link s1 s2)
)
(:goal (and
(at package1 s2))))

Figure 3. PDDL2.1 description problem Driverlogshift domain

Definition 1 (events). event, e, triple (pre(e), add(e), del(e)), pre(e),
add(e), del(e) three sets atomic propositions (facts) representing preconditions,
positive effects, negative effects e, respectively.
Definition 2 (temporal actions) temporal action, a, quadruple (start(a), end(a),
inv(a), dur(a)), start(a) end(a) two events denoting starting ending
events a, inv(a) set atomic propositions representing invariants a,
dur(a) positive rational number specifying duration a.
Example 1. Figure 4 shows temporal action = LOAD(package1, truck1, s0),
instance LOAD operator defined Figure 2. Figure 4, depicted rectangular box. Conditions effects written box, respectively.
start conditions effects placed left hand side box,
end conditions effects placed right hand side box.
conditions placed middle box. Here, start(a) end(a)
two events, pre(start(a)) = {(at package1 s0)}, add(start(a)) = , del(start(a)) =
{(at package1 s0)}, pre(end(a)) = , add(end(a)) = {(at package1 truck1)}, also
del(end(a)) = . Moreover, inv(a) = {(at truck1 s0), (working truck1)},
dur(a) = 10.
548

fiITSAT: Efficient SAT-Based Temporal Planner

Figure 4. temporal action

Definition 3 (temporal states). temporal state, s, pair (state(s), agenda(s)),
state(s) classical planning state represented set atomic propositions,
agenda(s) contains finite set open actions (i.e., actions started prior yet
ended).
Definition 4 (applicability). starting event e action applicable state s,
following conditions hold:
(1) state(s) contains preconditions e
invariants (except
invariants added e): pre(e) (inv(a) add(e)) state(s)
(2) already open s:
/ agenda(s)
(3) eSdoes delete theTinvariants open action s:

del(e) =
agenda(s) inv(a )
ending event e action applicable state s, following conditions hold:
(1) state(s) contains preconditions e: pre(e) state(s)
(2) open s: agenda(s)
(3)
e delete invariants
open action (other a):

)
inv(a
del(e)
=
agenda(s){a}
Definition 5 (successors). starting event e action applicable state s,
change unique state satisfying following conditions:


set open
actions equal set open actions a: agenda(s ) =
agenda(s) {a}

positive negative effects
e respectively added deleted :

state(s ) = (state(s) del(e)) add(e)

ending event e action applicable state s, change unique state
satisfying following conditions:
549

fiRankooh & Ghassem-Sani

set open actions equal set open actions without a:
agenda(s ) = agenda(s) {a}
positive negative
effects e respectively added deleted : state(s ) =

(state(s) del(e)) add(e)
on, may use succ(s, e) represent successor state obtained applying
e s.
Definition 4 Definition 5 easily extended also cover sequence events:
succ(s, he1 , ..., en i) = succ(succ(s, he1 , ..., en1 i), en ), succ(s, hi) = s. sequence
events he1 , ..., en applicable temporal state s, succ(s, he1 , ..., en i) defined.
Example 2. Let temporal state
state(s) = {(at package1 s0), (at truck1 s0), (working truck1), (link s0 s1)}

agenda(s) = .
Let = LOAD(package1, truck1, s0) = MOVE(truck1, s0, s1) two temporal actions, respectively instances LOAD MOVE operators presented Figure
2. event start(a) applicable changes
state(s ) = {(at truck1 s0), (working truck1), (link s0 s1)}

agenda(s ) = {LOAD(package1, truck1, s0)}.
Now, start(a) applicable already open . isstart(a ) applicable , deletes (at truck1 s0) invariant a, still open .
However, end(a) applicable changes
state(s ) = {(at package1 truck1), (at truck1 s0), (working truck1), (link s0 s1)}

agenda(s ) = .

Definition 6 (temporal problems). temporal problem, P, triple (I, G, A),
I, representing initial state, temporal state agenda(I) = . G set
atomic propositions denoting goal conditions, finite set possible
temporal actions P.
Definition 7 (causally valid plans). Let P = (I, G, A) temporal problem
= he1 , ..., en sequence events i, ei starting ending event
action A. causally valid plan P, applicable I, G state(succ(s, )),
agenda(succ(s, )) = .
550

fiITSAT: Efficient SAT-Based Temporal Planner

Definition 8 (pairing events). Let = he1 , ..., en causally valid plan problem P = (I, G, A). Assume ei ej respectively starting ending events
certain action < j. k < k < j, ek neither starting
ending event a, say ei (ej ) pairing event ej (ei ) .
words, ei ej pairing events related occurrence .
Definition 9 (valid temporal plans makespan). Let = he1 , ..., en causally
valid plan P = (I, G, A), : {1, ..., n} Q scheduling function , Q
set rational numbers. (, ) valid temporal plan P following
properties:
i, (i) < (i + 1).
A, start(a) = ei , ej pairing event ei , (j) =
(i) + dur(a).
maximum value assigned events called makespan .
Example 3. Consider problem P = (I, G, A) depicted Figure 3, state(I)
G contain propositions listed labels :init :goal, respectively,
set possible instantiations operators presented Figure 2 objects
listed label :objects Figure 3. Let
= hstart(WORK(truck1)),
start(LOAD(truck1, package1, s0)),
end (LOAD(truck1, package1, s0)),
start(MOVE(truck1, s0, s1)),
end (MOVE(truck1, s0, s1)),
start(MOVE(truck1, s1, s2)),
end (MOVE(truck1, s1, s2)),
start(UNLOAD(truck1, package1, s2)),
end (UNLOAD(truck1, package1, s2)),
end (WORK(truck1))i
schematic representation depicted Figure 5. straightforward checking shows
causally valid plan P. However, valid temporal plan
duration WORK(truck1) 100, requires serial execution two MOVE actions, one
LOAD action, one UNLOAD action, total duration 120, WORK(truck1)
still open. words, one single working shift truck1 sufficient transfer
package1 s0 s2. Therefore, scheduling function properties
Definition 9 exists . valid temporal plan P depicted Figure 6.
plan, two working shifts truck1 used.
551

fiRankooh & Ghassem-Sani

Figure 5. causally valid plan

Figure 6. valid plan

2.2 Limitations
end section describing differences formalism valid temporal
plans PDDL2.1. main limitations formalism listed below:
According Definition 4, starting event action applicable state
already open s. means that, similar many previous
temporal planners, permit two versions action overlap.
Consequently, current implementation ITSAT allow self-overlapping
actions. However, specification PDDL2.1 allows plans actions,
shown necessary solving certain temporal problems (Fox &
Long, 2007). experimental results indicate restriction render
ITSAT incapable solving current benchmark problems. Nevertheless,
shown that, theory, self-overlapping actions may cause complexity
temporal planning become EXPSPACE-hard rather PSPACE-hard (Rintanen,
2007).
formalism allow two events simultaneously applied
state. example cases simultaneity required, consider two
temporal actions b, starting event adds invariant b,
552

fiITSAT: Efficient SAT-Based Temporal Planner

starting event b adds invariant a. case, might necessary
simultaneously apply starting event actions given state.
clear specification PDDL2.1 whether simultaneity permitted
not. hand, shown almost none current benchmark
problems require simultaneity solvable (Rankooh & Ghassem-Sani,
2013).
PDDL2.1 allows usage numerical variables. supported ITSAT.
PDDL2.1 also allows duration dependent effects state dependent durations
actions numerical planning problems. features supported ITSAT
either; ITSAT currently handle numerical fluents.
According formalism, duration temporal action defined (=
?duration x) assignment, x rational number function specifying
actual duration action. PDDL2.1, hand, also allows using
inequalities ( ?duration x) ( ?duration x) define range
duration temporal action. Nevertheless, current benchmark problems
include inequalities. Although current implementation ITSAT
support inequalities, quite easy include feature, kinds
constraints duration actions handled Simple Temporal Problems
(Dechter et al., 1991).

3. Preprocessing Phase
Preprocessing important phase many planners. main objective phase
extract certain information problem. information later used
enhance search performance. One important issue addressed devising
preprocessing method correctness extracted information. words,
constraints inferred preprocessing phase must correct sense that,
cause planner become incapable finding valid plans. Moreover,
preprocessing method effective, required performed polynomial
time. section, explain two different preprocessing methods used ITSAT: mutual
exclusion analysis action compression. also formally prove methods
correct performed polynomial time.
3.1 Mutual Exclusion Analysis
Mutual exclusion analysis preprocessing method find pairs propositions cannot mutually true state valid plan. SAT-based planners typically add
explicit clause SAT formula pair mutually exclusive propositions.
clauses prevent mutually exclusive pairs propositions true true
time. Although information obtained search phase itself, acquiring beforehand, one prune search tree SAT solver thereby improve
performance.
Polynomial time mutual exclusion analysis classical planning problems originally performed constructing planning graphs, data structure introduced
553

fiRankooh & Ghassem-Sani

GRAPHPLAN (Blum & Furst, 1997). shown mutual exclusion
information obtained planning graphs quite effective improving performance SAT-based planners (Gerevini & Schubert, 1998). methods also
introduced compute n-way mutexes (instead pairwise mutexes computed
planning graphs). hn heuristic (Haslum & Geffner, 2000), analyzes reachability set n propositions initial state, example methods.
shown generalization hn heuristic efficiently computed
using syntactic regression operation (Rintanen & Gretton, 2013).
method used ITSAT finding mutual exclusion relations based
planning graph analysis. classical planning graph layered structure. first layer
includes propositions present initial state problem.
layer planning graph, mutual exclusion (mutex ) relations pairs proposition
computed. Two propositions non-mutex first layer
present initial state. action applicable layer preconditions
non-mutex layer. Two different actions mutex layer i, least one
following conditions holds: 1) interference (i.e., one action
deletes effect action), 2) conflict (i.e., one action
deletes precondition action), 3) preconditions mutex layer i.
Layer + 1 includes effects actions applicable layer i. Two propositions
mutex layer become non-mutex layer + 1 produced non-mutex
actions layer i. transfer propositions one layer next layer, exists
special noopp action proposition p requires adds p. construction
planning graph may continue change take places two consecutive layers.
case, say graph leveled off.
Planning graphs previously employed tackle temporal planning problems
(Smith & Weld, 1999). fact, first completely domain-independent temporal planner
called TGP, extension GRAPHPLAN (Blum & Furst, 1997). TGP requires
preconditions temporal action preserved throughout time action
open, also allow actions effects upon starting. result, TGP
compatible requirements PDDL2.1. TPSYS (Garrido et al., 2002),
extension TGP, another planning graph based temporal planner produce
plans domains required concurrency. Similar GRAPHPLAN, addition
construction planning graph, TPSYS TGP perform backward search
valid temporal plan.
LPGP (Long & Fox, 2003) another planning graph based temporal planner. LPGP,
mutex relations proposition actions computed considering
causal constraints problem; whereas temporal constraints taken
account later plan extracted solving Linear Programming (LP) problem.
Omitting temporal constraints problem done converting given temporal
problem classical problem. result, graph construction LPGP
similar GRAPHPLAN.
mentioned earlier, ITSAT, temporal constraints problem considered
causally valid plan produced. Therefore, constraints needed
dealt planning graph construction phase. makes graph structure
LPGP suitable ITSAT. Here, explain graph construction phase LPGP.
554

fiITSAT: Efficient SAT-Based Temporal Planner

correctness mutual exclusion information obtained method essential
correctness action compression SAT encoding methods. However, description
LPGP accompanied formal proof correctness. Therefore, here,
formally prove correctness tractability preprocessing method.
Definition 10 (causal abstraction temporal problems). Let P = (I, G, A)
temporal planning problem Ac set classical actions
exactly three classical actions , ai , ae Ac , following properties:
pre(as ) = pre(start(a)) (inv(a) add(a))
add(as ) = add(start(a)) {opena }, opena new proposition specifying
started yet finished
del(as ) = del(start(a)) add(start(a))
pre(ai ) = inv(a) {opena }
add(ai ) = inv(a) {opena }
del(ai ) =
pre(ae ) = pre(end(a)) {opena }
add(ae ) = add(end(a))
del(ae ) = (del(end(a)) add(end(a))) {opena }
causal abstraction P classical problem P c = (state(I), G, Ac ).
fact, Definition 10, produce causal abstraction given temporal planning problem, split temporal action three classical actions , ai , ae .
Actions ae correspond respectively starting ending events a. addition normal effects preconditions, adds special proposition named opena ,
required deleted ae . action ai called invariant checking action
a, requires invariants plus opena preconditions, produces opena
effect.
given temporal planning problem P = (I, G, A), ITSAT produces
c
P = (state(I), G, Ac ) i.e., causal abstraction P. ITSAT constructs classical planning graph P c .
planning graph ITSAT similar GRAPHPLAN. one
difference planning graphs two planners. GRAPHPLAN, mentioned earlier, propositions propagated layers so-called noop actions.
However, ITSAT, exception usage noop actions: new proposition
form opena introduced causal abstraction action a. particular proposition
propagated ai , invariant checking action a. Therefore, ai seen new
kind noop action used cover invariants reasoning mutex relations.

555

fiRankooh & Ghassem-Sani

Theorem 1. Let P = (I, G, A) temporal planning problem P c = (state(I), G, Ac )
causal abstraction P. Let = he1 , ..., en finite sequence events
applicable I, sn = succ(I, ). following conditions must hold:
two propositions p q members state(sn ), p q non-mutex
layer n planning graph P c .
proposition p member state(sn ), action member agenda(sn ),
p opena non-mutex layer n planning graph P c .
Proof. See Appendix A.
planning graph leveled off, subsequent extensions graph
effect new layers. Therefore, two propositions mutex last layer
leveled-off graph, remain mutex subsequently produced layers. case,
Theorem 1 implies pairs propositions never appear temporal
state execution valid temporal plan. matter remains
show mutual exclusion analysis ITSAT performed polynomial time.
Let P temporal planning problem, P c causal abstraction P.
deduced Definition 10, size P c greater P constant
factor. process constructing planning graph P c obtained modifying
construction process planning graphs GRAPHPLAN planner, way
temporal action a, noopopena never used. GRAPHPLAN constructs planning
graphs polynomial time (Blum & Furst, 1997). Therefore, overall time needed
mutual exclusion analysis ITSAT also polynomial size given temporal
planning problem.
3.2 Action Compression
Temporal actions variety temporal relations one another. popular
model representing temporal relations actions initially introduced James
Allen (1984). model included 13 possible temporal relations two actions.
Allens temporal relations require starting and/or ending events actions
executed simultaneously. mentioned Section 2.2, none temporal plans
produced ITSAT necessitate simultaneity. result, set temporal
relations two temporal actions confined proper subset Allens
temporal relations. possible temporal relations depicted Figure 7.
shown Figure 7, 4 6 types relations, actions concurrent, i.e.,
exists time two actions executed. concurrency
unnecessary solving temporal planning problems. know two actions
required concurrently executed, order find valid plan, checking
two temporal relations depicted Figure 7-(c) sufficient searching phase
planner. However, valid plans include concurrent executions two actions,
restricting temporal relations actions two relations depicted Figure
7-(c) render planner incomplete.

556

fiITSAT: Efficient SAT-Based Temporal Planner

Figure 7. Temporal relations two PDDL2.1 actions

Definition 11 (compression-safe sets actions compressed plans). Let
P = (I, G, A) temporal planning problem exists least one valid
temporal plan, subset A. say compression-safe P, exists
causally valid plan P compressed respect . causally valid plan
= he1 , ..., en compressed respect following property:
k, ek starting event action , ek+1 ending event
a.
According Definition 11, starting ending events members
assumed executed consecutively least one causally valid plan. Therefore,
plan executed, event causally needed happen starting
ending member . suggests members regarded
single event environment, rather two separate starting ending events.
557

fiRankooh & Ghassem-Sani

words, member , compress starting ending events
single event without rendering problem unsolvable. example, consider
DRIVERLOGSHIFT temporal planning problem presented Example 3. plan presented
Example 3 shows set LOAD, MOVE, UNLOAD actions compressionsafe set actions problem. straightforward analysis example shows
neither WORK actions presented Example 3 member compression-safe
subset actions.
Note that, according Definition 11, causally valid plan regarded
compressed sequence events. Although concept compression extended
cover even sequences events lead goal state, sake
simplicity, focused attention sequences causally valid
plans, defined compression-safe actions solvable temporal planning problems.
explain later Section 4, information obtained compression-safety analysis
incorporated encoding problem adding extra SAT formulae,
makes problem hand tighter. words, information used prune
search space SAT solver. result, handling compression-safety
never cause planner produce (invalid) plan unsolvable planning problem.
Safe action compression employed field temporal planning
(Coles et al., 2009). shown temporal problems possess
property required concurrency, temporal actions safely compressed classical
actions (Cushing et al., 2007). temporal problem said required concurrency,
every valid temporal plan includes least one action whose execution overlaps
execution action. problems without required concurrency, temporal
actions compressed classical actions. case, problem transformed
classical planning problem. phenomenon completely consistent
semantics Definition 11, easily shown problems without required
concurrency, set actions indeed compression-safe set actions. However,
case Example 3, even problem required concurrency
property, may still exist non-empty compression-safe set actions.
CRIKEY3 successor, POPF, two state-space based temporal planners
detect compression-safe actions preprocessing task (Coles et al., 2009). However,
concept compression-safety planners different presented
Definition 11. CRIKEY3 assume ending event compression-safe
action must executed immediately corresponding starting event. Instead,
starting event compression-safe action applied state, using simple inference
method, CRIKEY3 determine apply corresponding ending event.
method reduce branching factor search space state-space based temporal
planning. Here, show using idea detecting compression-safe actions,
one significantly reduce search space satisfiability checking based temporal
planning. later explained Section 4.4, compression-safe action a, add
clause SAT formula guarantee starting event present step
ending event present step. clauses used
prune search tree SAT solver checking satisfiability produced
formula.
CRIKEY3 considers action compression-safe following two conditions hold:
558

fiITSAT: Efficient SAT-Based Temporal Planner

pre(end(a)) inv(a)
del(end(a)) =
Figure 8-(a) shows temporal plan executed reach proposition q. example ending event action b precondition delete effect. Therefore,
CRIKEY3 considers b compression safe. However, goal produce q,
singleton = {b} compression-safe set Definition 11. fact, method used
CRIKEY3 specifically devised state-space based temporal planners,
cannot easily employed SAT-based planners ITSAT. contrast,
later shown, method easily used state-space based temporal planners
SAT-based planners.
also cases method used CRIKEY3 cannot detect actions
compression-safe according Definition 11. Consider plan depicted Figure 8(b). Suppose proposition p member initial state, goal
produce proposition g. plan, actions b must executed consecutively
produce g. p q, respectively overall conditions
b mutually exclusive, never true together. However, neither b
second property required CRIKEY3 regarded compression-safe action.
section show mutex information used detecting compression-safe
actions.
Definition 12 (swappable events). Let two different temporal actions, e
starting ending event a, e starting ending event . say e
e swappable following conditions hold:
e e interference other: add(e) del(e ) = add(e )
del(e) = .
e e conflict other: del(e) (pre(e ) inv(a )) =
del(e ) (pre(e) inv(a)) = .
e e supporting other: add(e) (pre(e ) (inv(a ) add(e ))) =
add(e ) (pre(e) (inv(a) add(e))) = .
According Definition 12, two events swappable causal relation
them. means causally valid plan = he1 , ..., e, e , ..., en i, swap
e e reach another causally valid plan = he1 , ..., e , e, ..., en i. use
swapping reorder events given causally valid plan without falsifying it.
Consider causally valid plan = he1 , ..., en i. Let ei ej starting
ending event action. events plan swappable ej ,
then, repeatedly swapping, one reorder produce another causally valid plan
= he1 , ..., ei , ej , ei+1 , ..., ej1 , ej+1 , ..., en i, ei ej two consecutive events.
Therefore, {a} compression-safe set. case, say compressed
towards start. Similarly, every event plan ei ej swappable
ei , then, repeatedly swapping, one reorder produce causally valid
plan = he1 , ..., ei1 , ei+1 , ..., ej1 , ei , ej , ..., en i. again, conclude {a}
compression-safe set. latter case, say compressed towards end.
559

fiRankooh & Ghassem-Sani

Figure 8. Temporal actions regarded compressible ITSAT (a) CRIKEY3 (b)

find whether safe compress given action a, need check
events swappable starting and/or ending events a. fact, considering
mutex relations obtained planning graph problem, already know
events never executed open. information effectively used
find given set actions compression-safe.
Definition 13 (compressible actions). Let P = (I, G, A) temporal planning problem, particular temporal action. say compressible towards
start, every event e e starting ending event {a}, least
one following conditions holds:
precondition add effect e mutex opena last layer leveled-off
planning graph causal abstraction P.
e swappable end(a).
560

fiITSAT: Efficient SAT-Based Temporal Planner

Similarly, say compressible towards end, every event e e
starting ending event {a}, least one following conditions holds:
precondition add effect e mutex opena last layer leveled-off
planning graph causal abstraction P.
e swappable start(a).
Theorem 2. Let P = (I, G, A) solvable temporal planning problem. Let set
every member either compressible towards start compressible towards
end. compression-safe P.
Proof. See Appendix A.
give example clarification matter.
Example 4. Let P = (I, G, A) temporal planning problem, set
three temporal actions a, b, c. Consider hypothetical causally valid plan depicted
Figure (9-a), execution action includes execution action b
turn includes execution action c. Assume compressible towards start,
b compressible towards end. show plan converted another
causally valid plan a, b, c executed sequentially. Figures (9-b)
(9-c) show results two consecutive swaps b compressed towards
end. starting event b swapped starting event c transform
plan Figure (9-a) plan Figure (9-b). Since b compressible towards
end, swapping cannot result invalid plan. Similarly, starting event b
swapped ending event c transform plan Figure (9-b)
plan Figure (9-c). Figures (9-d) (9-g) show results four consecutive swaps
compressed towards start. result swaps, fully
sequential plan shown figure (9-g) produced. implies even planner
allow execution event b open, still capable producing
temporally valid plan Figure (9-g).
given problem P = (I, G, A), ITSAT computes compression-safe set
Theorem 2. check first condition Definition 13, ITSAT needs construct
planning graph causal abstraction P which, showed previous
subsection, done polynomial time. second condition Definition 13,
suffices check every possible pair events see swappable. Since
done pair constant time, total time O(|A|2 ). conclude
finding performed polynomial time.
method described finding compression-safe actions used statespace temporal planners, too. State-space temporal planners divided two categories. first category includes planners based so-called decision
epoch planning method (Cushing et al., 2007). Examples decision epoch planners
TP4 (Haslum, 2006), SAPA (Do & Kambhampati, 2003), TFD (Eyerich et al., 2009).
561

fiRankooh & Ghassem-Sani

Figure 9. Action compression

method, start action restricted immediately start
end another action. state explicit time-stamp. action applied
state, starting time action set time-stamp state. result,
starting event action added plan, time corresponding
ending event exactly known. searching valid plan, state,
562

fiITSAT: Efficient SAT-Based Temporal Planner

planner make decision either advancing time ending event
open action, open new action. However, know action compressionsafe, planner advance time ending action thereby prune
search space. Plans produced way might larger makespans comparison
produced without pruning search space. Nevertheless, produced plans
rescheduled find plans improved makespans method explain later
Section 6.
alternative approach state space search so-called temporally lifted
progression planning, proved complete PDDL2.1 (Fox & Long,
2003). CRIKEY3 POPF examples planners using approach.
state temporally lifted progression planning represents permutation
number events. state, consistency temporal constraints imposed
sequence events state checked solving Simple Temporal Problem (STP).
Similar decision epoch planning, state, may exist two possible choices:
add ending event open action, open new action. However, compressionsafe actions, ending event actions applied immediately starting event,
turn reduces future choices planner. show Section 6
taking advantage compression-safe actions manner, planner still visit
STPs causally valid permutations events.
Table 1 shows comparison average percentage actions regarded
compression-safe new method method used CRIKEY3 POPF, various temporal planning domains. explain information regarding benchmark
domains problems later Section 6. seen Table 1, compression
method detect significantly compressible actions number benchmark domain.

4. Encoding Phase
section, explain abstract causal problem associated given temporal
problem encoded SAT formula. classical planning, exist one
way translate particular planning problem corresponding SAT formula. Previous
investigations field classical planning show choice encoding method
major impact efficiency SAT-based planner. mentioned earlier,
successful SAT-based classical planners used special encoding methods
based so-called -step -step semantics valid plans (Rintanen et al., 2006).
section, define temporal versions classical -step -step plans.
also show exactly semantics used translate given temporal planning
problem SAT formula. introduce -step encoding two different types
-step encodings temporal planning. -step first -step encoding methods
temporal versions classical -step -step encodings. Similar classical
versions, new encodings, restrictive simplifying assumptions assumed
hold. second type -step encoding, however, obtained relaxing one
assumptions. later show, new -step encoding often requires fewer steps
one. Besides, experimental results show, among new encoding methods,
second -step encoding results best performance ITSAT terms speed
563

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandopen
tms
driverlogshift
matchlift

CRIKEY3
12
85
100
0
100
100
100
100
100
100
100
100
13
96
100
88
100
100
95
73
98
95

ITSAT
100
100
100
95
100
100
100
100
100
100
98
100
96
96
100
95
98
99
99
75
98
95

Table 1: Average Percentage Compressed Actions
memory usage planner. necessary proofs soundness completeness
encoding methods also given section.
4.1 Parallel Semantics Causally Valid Plans
mentioned earlier, classical -step semantics permits parallel execution
one action step, validity plan depend execution
order actions. simply guaranteed adding particular clause
pair mutually exclusive actions ensure actions included
step. However, strategy work temporal planning. temporal
planning, temporal constraints imposed starting ending events
actions, validity particular ordering events certain step, also depends
ordering events steps. Nevertheless, ITSAT problem
tackled separating causal temporal reasoning phases. general, focus
finding causally valid plans, postpone scheduling phase, mentioned problem,
checking feasibility imposing different orderings events step,
longer exist. next introduce semantics causally valid -step -step temporal
plans.

564

fiITSAT: Efficient SAT-Based Temporal Planner

Definition 14 (temporal -steps -steps). Let E = {e1 , ..., en } set events,
s1 s2 two temporal states. temporal -step s1 s2
one-to-one ordering functions : {1, ..., n} {1, ..., n} (i.e., permutations events),
have: s2 = succ(s1 , heO(1) , ..., eO(n) i). temporal -step s1 s2
exist least one-to-one ordering function : {1, ..., n} {1, ..., n} (i.e., least one
permutation events), that: s2 = succ(s1 , heO(1) , ..., eO(n) i).
Definition 15 (causally valid -step -step plans). Let P = (I, G, A) temporal planning problem. Suppose s0 , ..., sn sequence temporal states s0 = I,
G state(sn ), agenda(sn ) = . 1 n, Stepi -step (-step)
si1 si , call sequence = hStep1 , ..., Stepn i, causally valid -step (-step)
plan P. say hs0 , ..., sn state transition sequence .
Classical -step -step encodings (Rintanen et al., 2006) based -step
-step semantics classical valid plans, respectively. However, -step encoding,
sake improving efficiency planner, following restrictive rules
also enforced semantics.
Rule 1: Instead accepting possible orderings among actions step,
fixed arbitrary ordering allowed. result, rule, execution
step necessitates execution actions according fixed ordering.
Rule 2: Preconditions actions step must members state immediately step. Similarly, effects actions step must
consistent state reached immediately step.
section, present one -step two -step encodings planning causal
abstractions temporal planning. encodings based -step -step
semantics causally valid plans (Definition 15). considering events, instead actions,
rules applied temporal planning, too. first -step
encoding, respect rules, second -step encoding, second restrictive rule
relaxed.
fact, second rule imposes serious restrictions applicability actions
step. instance, prevents proposition produced used
step plan. Neither allow deletion production
particular proposition step. relaxing restrictions, encoding
compact, i.e., relaxation permits events occur step. classical
planning, less relaxed form Rule 2 introduced effects actions
step used actions step (Wehrle & Rintanen, 2007). Here,
however, totally relax Rule 2 allow proposition required, added,
deleted many times step.
explaining SAT encodings, first define SAT variables auxilary clauses
commonly used three encoding methods. Let = hStep1 , ..., Stepn causally
valid -step (or -step) plan given temporal planning problem P = (I, G, A),
hs0 , ..., sn state transition sequence . order encode P SAT formula
whose model translated back , use following SAT variables:
565

fiRankooh & Ghassem-Sani

proposition p, 0 n, define SAT variable pt .
Assigning true (f alse) pt implies p (is not) member state(st ).
action A, 0 n, define SAT variable .
Assigning true (f alse) implies (is not) member agenda(st ).
event e e starting ending event action A,
1 n, define SAT variable et . Assigning true (f alse) et
implies e (is not) member Stept .
SAT formula satisfiable exists model it. model binary function
assigns value true f alse variable formula way
formula satisfied. encoding methods, produced formula
model , one easily translate corresponding causally valid -step (or -step)
plan, using description given variables formula. denote
resulting plan plan(M ). showing correctness particular encoding method,
two issues must addressed. First, must show exists causally valid
plan temporal problem P, encoding P model. call
completeness encoding method. Second, must show encoding P
model , plan(M ) causally valid plan P. called soundness
encoding method.
Note here, prove finite-horizon completeness -completeness
encodings. words, prove exists -step (or -step) plan
l steps given problem, problem translated -step (or -step)
encoding satisfiable SAT formula l steps, model formula
translated back . hand, proof -completeness would need
value l determined. proofs finite-horizon completeness could implied
-completeness least upper bound value l determined. Recent
research field classical planning shown classical planning domains,
tight upper bounds length optimal plans determined (Rintanen & Gretton,
2013). However, determining upper bounds temporal planning beyond scope
current work. find causally valid plan, ITSAT starts encoding
one step, sequentially produces tries satisfy formulae increasing number
steps, satisfiable formula encountered predefined time limit
reached.
classical SAT-based planning, order produce linear-size encodings -step
-step semantics valid plans, special sets clauses, named chains, used
(Rintanen et al., 2006). Since also used chains ITSAT, formal definition
temporal version given here. Let e1 , ..., en arbitrary fixed ordering
events, E R two sets events, k natural number, special symbol
assigns unique name chain hand. define chain(e1 , ..., en ; E; R; k; m)
conjunction formulae (C-1) (C-3) stated below.
(C-1)

V

{eki bkj,m |i < j, ei E, ej R, {ei+1 , ..., ej1 } R = }

(C-2)

V

{bki,m bkj,m |i < j, {ei , ej } R, {ei+1 , ..., ej1 } R = }
566

fiITSAT: Efficient SAT-Based Temporal Planner

(C-3)

V

{bki,m eki |ei R}

formulae fact encodes message passing strategy. symbol specifies
name message used distinguish SAT variables certain chain
chains. number k specifies step whose variables affected
message produced. message may produced member E.
receivers message members R. bki,m true, means message
received i-th event k-th step formula. ei member E, eki
true, message produced sent ej , first member R
located ei fixed ordering. represented chain(e1 , ..., en ; E; R; k; m)
clauses form eki bkj,m formula (C-1). message produced,
transmitted forward according fixed ordering clauses form bki,m bkj,m
formula (C-2). event ei receives message, corresponding SAT variable
bef alse clauses form bki,m eki formula (C-3). fact, members R
receive message certainly excluded final plan.
present examples show chains practically used guarantee particular characteristics output plan have.
Example 5. Assume e1 , e2 , e3 , e4 four events. Suppose proposition x
required e1 e4 , deleted e2 , added e3 . Also assume four propositions
p1 , ..., p4 respectively added e1 , ..., e4 . Consider following two cases:
Case 1: want prevent proposition x required deleted
step, say k, final plan. purpose, add conjunction
chain(e1 , ..., e4 ; E; R; k; mx1 ) chain(e4 , ..., e1 ; E; R; k; mx2 ) formula, E
set events delete x (i.e., E = {e2 }), R set events
require x (i.e., R = {e1 , e4 }). Note mx1 mx2 two symbols enable us
distinguish SAT variables used two different chains. case,
adding chain(e1 , ..., e4 ; E; R; k; mx1 ) add following formulae encoding
problem:
ek2 bk4,mx
1



bk1,mx
1



bk4,mx
1

bk1,mx ek1
1

bk4,mx ek4
1

Assume exists model produced SAT encoding
(ek2 ) = true. case, since satisfies ek2 bk4,mx , (bk4,mx ) = true.
1
1
Consequently, since satisfies bk4,mx ek4 , (ek4 ) = f alse. words,
1
e2 member step k, e4 cannot member step. Similarly,
adding chain(e4 , ..., e1 ; E; R; k; mx2 ) add following formulae encoding
problem:
ek2 bk1,mx
2

567

fiRankooh & Ghassem-Sani

bk4,mx bk1,mx
2



bk4,mx
2

2



ek4

bk1,mx ek1
2

argument similar one given chain(e1 , ..., e4 ; E; R; k; mx1 ) shows
adding chain(e4 , ..., e1 ; E; R; k; x2 ), e2 member step k, e1 cannot
member step. result, adding mentioned chains SAT
formula, execution step k produces p2 , cannot produce p1 p4 .
actually occurrence conflicting actions step final plan
avoided linear-size classical -step encoding (Rintanen et al., 2006).
Case 2: allow proposition x required deleted particular step
k deleting event precede requiring event fixed ordering
he1 , e2 , e3 , s4 i. purpose, need add chain(e1 , ..., en ; E; R; k; mx )
formula, E R E R case 1. case,
execution step k produces p2 , also produce p1 , p4 . strategy, too,
initially introduced linear-size classical -step encoding (Rintanen et al.,
2006).
Note one admits second restrictive rule mentioned above, case
classical -step -step encodings, proposition added event step
deleted another event step. result, execution step
k produces p2 , cannot produce p3 cases.

4.2 Temporal Versions Classical -step -step Encodings
first present temporal versions classical -step -step encodings. Similar
classical forms, temporal versions encodings, assume arbitrary
fixed ordering e1 , ..., en events given temporal problem P = (I, G, A).
also assume output plan fixed number steps, denoted l.
Let = hStep1 , ..., Stepl output plan P, hs0 , ..., sl state transition
sequence . event e, let action(e) member whose starting
ending event equal e. Let P set propositions P. proposition
p P , let Ep = {e|p del(e)}, Ep+ = {e|p add(e)} Rp = {e|p pre(e)} {e|p
inv(action(e)) add(e)}. Moreover, assume two dummy events e0 en+1 ,
precondition, add effect, delete effect.
4.2.1 -step Encoding
Given temporal problem P = (I, G, A), produce SAT-formula l , based
-step semantics causally valid plans, P conjunction formulae
described below.
V
(-1) {p0 |p state(I)} {p0 |p
/ state(I)}
V l
(-2) {p |p G}
568

fiITSAT: Efficient SAT-Based Temporal Planner

(-3)

V

{a0 |a A}

(-4)

V

{al |a A}

(-5)

V

{ek pk1 |0 < k l, p P, e Rp }

(-6)

V

{ek pk |0 < k l, p P, e Ep+ }

(-7)

V

(-9)

V

(-10)

V

(-11)

V

(-12)

V

{ek ak1 ak |0 < k l, A, e = start(a)}

(-13)

V

{ek ak1 ak |0 < k l, A, e = end(a)}

{ek pk |0 < k l, p P, e Ep }
V
W
(-8) {pk1 pk eEp+ ek |0 < k l, p P }
{pk1 pk

W

eEp

ek |0 < k l, p P }

{chain(e1 , ..., en+1 ; Ep ; Rp {en+1 }; k; mp1 )|0 < k l, p P }
{(bkn+1,mp ak )|0 < k l, p inv(a)}
1

{chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp2 )|0 < k l, p P }
{(bk0,mp ak1 )|0 < k l, p inv(a)}
2

Formula (-1) indicates member state(s0 ) true iff present initial state. Similarly, formula (-2) states members goal state must true
state(sl ). Formulae (-3) (-4) imply agenda(s0 ) agenda(sl ) empty.
Formulae (-5) (-7) show event applied step k, preconditions must
present state(sk1 ), effects must consistent state(sk ). Formulae (8) (-9) responsible encoding so-called explanatory frame axioms: formula
(-8) implies p present step k, must exist least
one event step k p add effects. Similarly, formula (-9) implies p
present step k, must exist least one event step k
deletes p. Formulae (-10) (-11) added guarantee events step
executed possible ordering. Formula (-10) implies p deleted
event ei step k, p cannot required event ej step k j > i.
also implies p deleted event step k, action p invariant,
cannot member agenda(sk ). Note chain(e1 , ..., en+1 ; Ep ; Rp ; k; mp1 )
used formula (-10), value bn+1,mp1 indicates whether p deleted
event step k. reason using dummy event en+1
indicator. Analogously, formula (-11) implies p deleted event ei step k,
p cannot needed event ej step k j < i. Formula (-11)
also implies p deleted event step k, action p invariant,
cannot member agenda(sk1 ). Formulae (-12) (-13) responsible
applying appropriate changes agendas states located
step final plan. Formula (-12) implies starting event action
member step k output plan, must member agenda(sk )
agenda(sk1 ). Similarly, formula (-13) implies ending event action
569

fiRankooh & Ghassem-Sani

member step k plan, must member agenda(sk1 ) agenda(sk ).
Theorem 3 (completeness temporal -step encoding). Let P = (I, G, A)
solvable temporal planning problem, {e1 , ..., en } set events P, =
hStep1 , ..., Stepl causally valid -step plan P. exists model l
= plan(M ).
Proof. See Appendix A.
Theorem 4 (soundness -step encoding). Let P = (I, G, A) temporal planning
problem, {e1 , ..., en } set events P, l -step encoding P.
l model , plan(M ) causally valid -step plan P.
Proof. See Appendix A.
4.2.2 -step Encoding
part, present SAT-formula l , based -step semantics
causally valid plans. considering two restrictive rules stated above, -step
encoding similar -step encoding described previously section. However,
two major differences two kinds encoding. First, -step
encoding allows proposition required deleted step, provided
deleting event precede requiring event fixed ordering he1 , ..., sn i.
contrast -step encoding, proposition could deleted
required step final plan. Second, -step encoding,
step may also contain starting ending event action. Given
temporal problem P = (I, G, A), produce SAT-formula l , based
-step semantics causally valid plans, P conjunction formulae described
below.
V
(-1) {p0 |p state(I)} {p0 |p
/ state(I)}
V l
(-2) {p |p G}
V
(-3) {a0 |a A}
V
(-4) {al |a A}
V
(-5) {ek pk1 |0 < k l, p P, e Rp }
V
(-6) {ek pk |0 < k l, p P, e Ep+ }
V
(-7) {ek pk |0 < k l, p P, e Ep }
V
W
(-8) {pk1 pk eEp+ ek |0 < k l, p P }
(-9)

V

{pk1 pk

W

(-10)

V

{chain(e1 , ..., en+1 ; Ep ; Rp {en+1 }; k; mp1 )|0 < k l, p P } {(bkn+1,mp

eEp

ek |0 < k l, p P }
1

ak )|0 < k l, p inv(a)}
570

fiITSAT: Efficient SAT-Based Temporal Planner

(-11)

V

(-12)

V

(-13)

V

(-14)

V

(-15)

V

(-16)

V

(-17)

V

(-18)

V

(-19)

V

(-20)

V

{eki ak1 |0 < k l, A, ei = start(a), ej = end(a), < j}
{eki ak ekj |0 < k l, A, ei = start(a), ej = end(a), < j}
{ekj ak |0 < k l, A, ei = start(a), ej = end(a), < j}
{ekj ak1 eki |0 < k l, A, ei = start(a), ej = end(a), < j}
{eki ak1 ekj |0 < k l, A, ei = start(a), ej = end(a), j < i}
{eki ak |0 < k l, A, ei = start(a), ej = end(a), j < i}
{ekj ak eki |0 < k l, A, ei = start(a), ej = end(a), j < i}
{ekj ak1 |0 < k l, A, ei = start(a), ej = end(a), j < i}
{ak1 ak eki |0 < k l, A, ei = start(a)}
{ak1 ak ekj |0 < k l, A, ej = end(a)}

Note formulae (-1) (-9) exactly formulae (-1) (-9). Similar
-step encoding, formulae responsible validity initial state, goal
state, conditions effects events, also explanatory frame axioms explained
before. Moreover, notice formula (-10) also present -step encoding
formula (-10), formula (-11) present l . results first major difference
stated -step encoding -step encoding. Formulae (-11)to (-20)
enforce appropriate changes agenda(sk1 ) agenda(sk ), agendas
states immediately step k final plan. According definitions,
formulae (-11) (-14) added action property start(a)
located end(a) fixed ordering he1 , ..., en i. Formula (-11) ensures
started step k, open sk1 . Formula (-12) guarantees
started ended step k, must open sk . Formula (-13) ensures
ended step k, open sk . Formula (-14) implies ended
started step k, must open sk1 . Analogously, formulae (-15) (-18)
guarantee similar properties action property start(a) located
end(a) fixed ordering he1 , ..., en i. Formula (-19) ensures member
agenda(sk ) agenda(sk1 ), must started step k. Similarly, formula (-20)
ensures member agenda(sk1 ) agenda(sk ), must ended step
k.
Since -step encoding conforms two restrictive rules stated earlier
section, may exist -step causally valid plan l steps given problem
l would unsatisfiable problem. also case linear size step encoding classical planning problems (Rintanen et al., 2006). However, since
showed Theorem 3 -step encoding complete, completeness -step
encoding proved showing satisfiability l entails satisfiability l .
Theorem 5 (completeness -step encoding). Let P = (I, G, A) solvable temporal planning problem, {e1 , ..., en } set events P, = hStep1 , ..., Stepl
causally valid -step plan P. exists model l = plan(M ).
571

fiRankooh & Ghassem-Sani

Proof. See Appendix A.
Theorem 5 also shows -step encoding, number required steps
solve temporal planning problem less (or equal to) required -step
encoding. words, -step encoding compact -step counterpart.
Theorem 6 (soundness -step encoding). Let P = (I, G, A) temporal planning
problem, {e1 , ..., en } set events P, l -step encoding P.
l model , plan(M ) causally valid -step plan P.
Proof. See Appendix A.
4.3 Relaxed -step Encoding
mentioned Section 4.2.2, -step encoding allows proposition
required deleted two events step, deleting event
precede requiring event fixed ordering he1 , ..., en i. Besides, since formulae (-5)
(-6) present -step -step encodings, proposition
added deleted step encodings. restrictions,
also present classical -step -step encodings (Rintanen et al., 2006), lifted
new relaxed version -step encoding. result, proposition required,
added, deleted step many times needed. property
previously examined classical -step encoding, consequently, chaining mechanism
explained Section 4.1 compatible it. Here, introduce generalized version
chains explain conceptual difference used classical encodings.
also present new kinds chains used specially temporal planning preserving
invariants temporal actions plan produced. Note that, similar
non-relaxed -step encoding, assume events step executed
according fixed ordering he1 , ..., en i.
Let k natural number e1 , ..., en fixed ordering events. reasons discussed later, assume ei starting event action, ei+1
ending event action. words, assume ending event
action located immediately starting event fixed ordering. Note here,
demand end action immediately follow start final plan.
put constraint fixed ordering. cannot compromise completeness
ITSAT: SAT solver still choose start action step k, choose whatever
actions needed steps k k + arbitrary m, choose end
step k +m. Moreover, suppose two dummy events e0 en+1 ,
precondition, add-effect, delete-effect. Let P set propositions
P. proposition p P , let Ep = {e|p del(e)}, Ep+ = {e|p add(e)}, Op = {e|p
inv(action(e))} {e0 , en+1 }, Rp = {e|p pre(e)} {e|p inv(action(e)) add(e)}.
define chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) conjunction formulae (C -1)
(C -8) stated below. Note mp symbol used distinguishing SAT varibales
used formula chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) variables used
formulae.

572

fiITSAT: Efficient SAT-Based Temporal Planner

(C -1)

V

{eki bkj,mp |i < j, ei Ep+ , ej Rp Ep , {ei+1 , ..., ej1 } (Rp Ep ) = }

(C -2)

V

{eki bkj,mp |i < j, ei Ep , ej Rp Ep+ , {ei+1 , ..., ej1 } (Rp Ep+ ) = }

V

{bki,mp bkj,mp |i < j, ei Rp (Ep+ Ep ), ej R Ep+ Ep , {ei+1 , ..., ej1 }
(Rp Ep+ Ep ) = }
V
(C -4) {(bki,mp eki ) bkj,mp |i < j, {ei , ej } Rp Ep+ Ep , {ei+1 , ..., ej1 } (Rp Ep+
Ep ) = }
V
(C -5) {(bki,mp eki ) bkj,mp |i < j, {ei , ej } Rp Ep+ Ep , {ei+1 , ..., ej1 } (Rp
Ep+ Ep ) = }
V
(C -6) {bki,mp eki |ei Rp }

(C -3)

(C -7) bk0,mp pk1
(C -8) bkn+1,mp pk
fact, chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ) encodes message passing method
different chain(e1 , ..., en ; E; R; k; m). chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ),
conveyed message fact value proposition p, therefore either true
f alse. Similar message passing strategy chain(e1 , ..., en ; E; R; k; m), received
message transferred forward direction fixed ordering e1 , ..., en .
event Ep+ , Ep , Rp receives message previous event fixed ordering.
Every event may may change value received message. either cases,
message passed next event. events Ep+ change value
received message true, events p add-effects. Similarly,
events Ep change value received message f alse. formulae
(C -1) (C -2) impose changes value received message. event
member Ep+ Ep , neither adds deletes p, thus, pass received
message without altering value. enforced (C -3). (C -4) (C -5) ensure
received messages passed without changed events
chosen Stepk output plan. According (C -6), event Rp receives
message value f alse, event cannot chosen member Stepk .
members Rp require p, necessitates received messages
value true. (C -7) implies initial value message produced Stepk equal
value p state immediately execution Stepk . Similarly, (C -8)
implies value p state immediately execution Stepk
equal final value message Stepk .
Example 6. Consider events given Example 5. Let E + set events
add x (i.e., E + = {a3 }), E set events delete x (i.e., E = {a2 }),
R set events require x (i.e., R = {a1 , a4 }). Moreover, suppose
two dummy events e0 e5 , precondition, add-effect,
delete-effect. Assume added chain (e0 , ..., e5 ; E + ; E ; R {e0 , e5 }; k; mx )
573

fiRankooh & Ghassem-Sani

SAT formula. According formulae (C -1) (C -8), chain conjunction
following formulae:
ek3 bk4,mp
ek2 bk3,mp
bk0,mp bk1,mp
bk1,mp bk2,mp
bk4,mp bk5,mp
bk0,mp ek0 bk1,mp
bk1,mp ek1 bk2,mp
bk2,mp ek2 bk3,mp
bk3,mp ek3 bk4,mp
bk4,mp ek4 bk5,mp
bk0,mp ek0 bk1,mp
bk1,mp ek1 bk2,mp
bk2,mp ek2 bk3,mp
bk3,mp ek3 bk4,mp
bk4,mp ek4 bk5,mp
bk0,mp ek0
bk1,mp ek1
bk4,mp ek4
bk5,mp ek5
bk0,mp xk1
bk5,mp xk
574

fiITSAT: Efficient SAT-Based Temporal Planner

straightforward examination shows model chain mentioned (ek0 ) = (ek1 ) = (ek2 ) = (ek3 ) = (ek4 ) = (ek5 ) = true,
(bk0,mp ) = (bk1,mp ) = (bk2,mp ) = (bk4,mp ) = (bk5,mp ) = true, (bk3,mp ) = f alse.
words, x deleted e2 Stepk final plan, later produced
e3 , result, e4 appear Stepk , too. Here, (bk3,mp ) = f alse represents
fact x deleted execution e2 . example, four propositions
p1 , p2 , p3 , p4 produced single step final plan. Note neither
cases Example 5, producing propositions one step possible.
example new -step encoding, employs generalized message
passing strategy, permit parallelism allowed temporal versions
classical -step -step encodings.
addition chain (e0 , ..., en+1 ; Ep+ ; Ep ; Rp ; k; mp ), responsible tracking
value p inside Stepk , also need extra formulae prevent p deleted
whenever p invariant open temporal action. Therefore, introduce two new
ob

ob
chain formulae: chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p ) chain (e0 , ..., en ; Ep ; Op ; k; mp ).
Formula chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p ) produced conjunction formulae


(C -1) (C -4). Similar chains explained before, mof
p symbol used distinguish SAT varibales chain formulae.
V
(Cof -1) {eki bk |i < j, ei Ep , ej Op , {ei+1 , ..., ej1 } Op = }
j,mp

(Cof -2)

V

{bk

(Cof -3)

V

{(bk

ekj ) eki |ei Op , ei = start(a), ej = end(a)}

(Cof -4)

V

{(bk

ak ) eki |a A, ei = start(a), ei Op }

i,mof
p

bk

j,mof
p

j,mof
p

n+1,mof
p

|i < j, {ei , ej } Op , {ei+1 , ..., ej1 } Op = }

Similar chain(e1 , ..., en ; Ep ; Rp ; k; mp ), chainof (e1 , ..., en ; Ep ; Op ; k; mof
p ) represents
message produced sent forward direction fixed ordering, whenever
proposition p deleted event. (Cof -1) (Cof -2) responsible production
propagation mentioned message, respectively. (Cof -3), ending event
action p invariant receives message step k, step k must also
include starting event a. cases, (Cof -3) prevents open p
deleted. assume fixed ordering, ending event
action located immediately starting event. (Cof -4) guarantees p deleted
somewhere step k, action p invariant open step k, step
k must also include starting event (otherwise, open everywhere step k,
thus, p, invariant a, deleted open).
chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p ), message indicates p deleted sent
forward. Thus, cannot help preserving invariants members Op
started prior deletion p. tackle problem, add another chain,
namely chainob (e0 , ..., en ; Ep ; Op ; k; mob
p ), formula. chain quite analogous



chain (e1 , ..., en+1 ; Ep ; Op ; k; mp ), whenever p deleted event, chain sends
575

fiRankooh & Ghassem-Sani

message backward according fixed ordering. chainob (e0 , ..., en ; Ep ; Op ; k; mob
p )
ob
ob
produced conjunction formulae (C -1) (C -4).
(Cob -1)

V

{eki bkj,mob |j < i, ei Ep , ej Op , {ej+1 , ..., ei1 } Op = }

(Cob -2)

V

{bki,mob bkj,mob |j < i, {ei , ej } Op , {ej+1 , ..., ei1 } Op = }

(Cob -3)

V

{(bki,mob eki ) ekj |ei Op , ei = start(a), ej = end(a)}

(Cob -4)

V

{(bk0,mob ak1 ) ekj |a A, ej = end(a), ej Op }

p

p

p

p

p



present SAT-formula l , represents relaxed -step encoding

based -step semantics causally valid plans. l produced conjunction
formulae described below.
V
( -1) {p0 |p state(I)} {p0 |p
/ state(I)}
V
( -2) {pl |p G}
V
( -3) {a0 |a A}
V
( -4) {al |a A}
V
( -5) {chain (e0 , e1 , ..., en+1 ; Ep+ ; Ep ; Rp {e0 , en+1 }; k; mp )|0 < k l, p P }
( -6)

V

{chainof (e1 , ..., en+1 ; Ep ; Op ; k; mof
p )|0 < k l, p P }

( -7)

V

{chainob (e0 , ..., en ; Ep ; Op ; k; mob
p )|0 < k l, p P }

( -8)

V

( -9)

V

{eki ak1 |0 < k l, A, ei = start(a)}

( -10)

V

{ekj ak |0 < k l, A, ej = end(a)}

( -11)

V

{ekj ak1 eki |0 < k l, A, ei = start(a), ej = end(a)}

( -12)

V

( -13)

V

{ak1 ak eki |0 < k l, A, ei = start(a)}

{eki ak ekj |0 < k l, A, ei = start(a), ej = end(a)}

{ak1 ak ekj |0 < k l, A, ej = end(a)}

( -1) ensures member state(s0 ) true member present
initial state. Similarly, ( -2) guarantees members goal state true
state(sl ). ( -3) ( -4) imply agenda(s0 ) agenda(sl ) empty. ( -5),
explained before, responsible imposing appropriate changes value SAT
variables, whenever proposition p added deleted event certain step
output plan. ( -6) ( -7) prevent invariants action deleted
open. ( -8) ( -13) responsible enforcing appropriate changes
agenda(sk1 ) agenda(sk ), agendas states immediately
576

fiITSAT: Efficient SAT-Based Temporal Planner

step k output plan. ( -8) ensures started step k
open sk1 . ( -9) indicates started ended step k,
open sk . ( -10) ensures ended step k, open sk . ( -11)
implies ended started step k, open sk1 . ( -12)
ensures member agenda(sk ) member agenda(sk1 ),
started step k. Similarly, ( -13) ensures member agenda(sk1 )
agenda(sk ), ended step k.
Theorem 5, know temporal planning problem P satisfiable,
exists positive number l, non-relaxed -step encoding P l steps
(i.e., l ) satisfiable. Accordingly, completeness relaxed -step encoding

proved showing l satisfiable l also satisfiable.
Theorem 7 (completeness relaxed -step encoding). Let P = (I, G, A)

temporal planning problem formulae l l two -step encodings P explained

above. model l , l model plan(M ) = plan(M ).
Proof. See Appendix A.
Theorem 7 also shows that, -step encoding, number required steps
solve temporal planning problem less (or equal to) required -step
encoding, provided fixed ordering used two encodings.
words, -step encoding compact -step encoding.
Theorem 8 (soundness relaxed -step encoding). Let P = (I, G, A)

temporal planning problem, {e1 , ..., en } set events P, l relaxed

-step encoding P. l model , plan(M ) causally valid -step plan
P.
Proof. See Appendix A.
4.4 Mutual Exclusion Relations Action Compression
mentioned earlier Section 3, performance SAT-based temporal planner
improved mutual exclusion analysis action compression. section,
show information obtained tasks utilized ITSAT. Let
P = (I, G, A) temporal planning problem, MU set mutually exclusive
pairs propositions P, COM set compression-safe actions P (see

Section 3). Let l encoding P, l , l , l . taking
advantage mutual exclusion relations, add extra formula mut
l , mut
=
l
l
V
k
k
{p q |(p, q) MU , 1 k l}. Theorem 1 shows, two mutually exclusive
propositions p q never true state achieved execution
valid temporal plan starting I. result, adding mut
encoding cannot
l
render planner incapable finding valid plans.
Let compression-safe action. showed Section 3.2, safe
assume causally valid plan, ending event occurs immediately
starting event. One way impose constraint add extra clauses
577

fiRankooh & Ghassem-Sani

encoding guarantee starting ending events always included
step. However, two events may conflicting effects, case l
l allow events present step. Therefore, information

regarding compression-safe actions added
relexed -step encoding, l .
V

done adding com
l , com
= {eki eki+1 |a COM, ei = start(a), 1
l
l


k l}. Note l , ei starting event action, ei+1 denotes ending
event.

5. Scheduling Phase
section, describe causally valid plan augmented temporal information
produce valid temporal plan. Let = he1 , ..., en causally valid plan produced
planner. scheduling done defining scheduling function Definition
9, assigns rational number event execution time. Suppose
given different names different occurrences action plan,
events e1 , ..., en unique. assume i, (i) < (i + 1),
thereby satisfy first condition Definition 9. However, lead plans
unnecessarily large makespans. Alternatively, obtaining plans improved quality,
impose relaxed set constraints function .
Definition 16 (relaxed scheduling functions). Let causally valid plan.
scheduling function relaxed scheduling function following properties:
(S-1) j ei located ej , ei swappable ej
(cf. Definition 12), require (i) < (j).
(S-2) j, ei starting event particular action a, ej pairing
event ei (cf. Definition 8), require (j) = (i) + dur(a).
Theorem 9. Let P = (I, G, A) temporal planning problem, = he1 , ..., en
causally valid plan P, : {1, ..., n} Q relaxed scheduling function .
exists valid temporal plan P.
Proof. See Appendix A.
Theorem 9 shows whenever relaxed scheduling function exists causally valid
plan P, valid temporal plan produced P. prove scheduling
method render ITSAT incomplete, also need show P solvable,
planner able produce causally valid plan scheduling function
relaxed scheduling function . Let (, ) valid temporal plan
P. Every causally valid plan also regarded causally valid -step plan
singleton steps. Therefore, Theorem 3, l model = plan(M ).

Theorem 5, also satisfies l . Moreover, Theorem 7, l model
= plan(M ) = plan(M ). Therefore, encoding methods used
translating P SAT formula, resulting formula model translated
. hand, according Definition 9, satisfies constraints form
(S-1) (S-2), therefore, relaxed scheduling function . However, mentioned
578

fiITSAT: Efficient SAT-Based Temporal Planner

Section 4.2.4, may add certain clauses encoding ensure produced
causally valid plan always compressed (Definition 11). show solvable temporal plan, exists compressed causally valid plan scheduled
valid temporal plan relaxed scheduling function.
Theorem 10. Let P = (I, G, A) solvable temporal planning problem, COM
set every member either compressible towards start compressible towards end (Definition 13). exists valid temporal plan (, ) P
causally valid plan P, compressed respect COM,
relaxed scheduling function .
Proof. See Appendix A.
check existence function properties stated above, solve
instance Simple Temporal Problem (STP) (Dechter et al., 1991). STP associated
weighted graph named Simple Temporal Network (STN). construct STN
node xi corresponds event ei causally valid plan . Let arbitrary
small rational number. constraint form (i) < (j), add edge
weight xi xj . constraint form (j) = (i) + dur(a),
add edge weight -dur(a) xi xj , another edge weight dur(a)
xj xi . also add reference node x0 constructed STN. x0 edge
weight 0 every node. solution STP found computing
length shortest path form x0 nodes (Dechter et al., 1991). Suppose
shortest paths exist length shortest x0 xi shown
distance(x0 , xi ). event ei , define (i) equal distance(x0 , xi ).
case, Theorem 9 guarantees resulting plan specifications valid
temporal plan.
see intuition behind explained method defining function , suppose constructed STN, edge weight xi xj .
means distance(x0 , xj ) distance(x0 , xi ) , implies distance(x0 , xi )
distance(x0 , xj ) . This, turn, implies distance(x0 , xi ) < distance(x0 , xj ),
(i) < (j). Similarly, easily shown exists edge
weight -dur(a) xi xj , another edge weight dur(a) xj xi ,
have: (j) = (i) + dur(a). Bellman-Ford algorithm (Cormen, Leiserson, Rivest,
& Stein, 2009) used find single source shortest paths weighted graph
polynomial time. Besides, number nodes produced STN equal
number events causally valid plan. Therefore, conclude that,
mentioned shortest paths exist, (i) computed polynomial time.
However, situations shortest paths exist. happens
corresponding STN negative cycle. situations, STP inconsistent
consequently, temporal constraints cannot satisfied time.
example case depicted Figure 10.
Figure 10, action adds propositions p g starting ending events,
respectively. needs proposition q precondition ending event. Action b requires
p upon starting adds q upon ending. Durations actions b, 5 10,
respectively. goal planning reaching fact g. problem, = , bs , , ae
579

fiRankooh & Ghassem-Sani

Figure 10. Negative Cycles

causally valid plan, = start(a), ae = end(a), bs = start(b), = end(b).
plan depicted Figure 10-(a). plan, execution action b must entirely
inside action (i.e., b started starting ended ending a).
However, impossible considering fact duration less
b. invalidity plan caused fact producing causally valid
plan, durations abstracted out. STN constructed plan Figure
10-(a) depicted Figure 10-(b). bs ae negative cycle total weight
5 2.
5.1 Negative Cycle Prevention
STN causally valid plan includes negative cycle, plan cannot transformed
valid temporal plan. cases, SAT solver forced find different
solution. done adding extra clause least one events
current negative cycle prevented occurring current step. However,
adding blocking clause, planner still produce new plans basically
equivalent previous plan. instance, consider example given Figure 10.
Suppose , bs , , ae members steps 1 4, respectively. Assume
output plan 5 steps. forbid exact occurrence negative cycle,
580

fiITSAT: Efficient SAT-Based Temporal Planner

new causally valid plan still produced shifting ae layer 5 maintaining
events current steps. new solution negative cycle
therefore cannot transformed valid temporal plan. fact, cause
invalidity plan changed. show exploiting simple structure
negative cycles, one prevent reoccurrence cycles effectively.
discussion given above, clear main reason
negative cycles encountered STN particular causally valid plan,
specific order events plan. fact, events negative cycle reoccur
order new causally valid plan, new plan include negative
cycle, too.
temporal planning problem P, P
regard set possible sequences
events language alphabet
= {e1 , ..., en }, n number
events P. set sequences events certain P
events appeared
particular order also regarded another language . straightforward
show latter language fact regular language accepted
Finite State Machine (FSM). Figure 10-(c) shows Finite State Machine detects
sequences events , ae , bs , appear according order , bs , , ae i.
Note that, sake clarity, self-loop transitions Finite State Machine
shown Figure 10-(c).
P
Definition 17 (FSMs). AP
Finite State Machine 5-tuple (S , , , xP
0 , ),
finite set states,
finite set alphabet symbols, :

mapping defining transitions , x0 starting state, set
accepting states.
show adding certain formulae SAT encodings, one avoid
members given regular language
produced causally valid plans. Let
P
P temporal problem,P

= {e1 , ..., en } set events P. Let L
regular
. Assume L accepted P
Finite State Machine
P langaue

|T (xi , e) = xj , 6= j}
= (S , ,P
, ). xi , let Ei = {e
Eiin = {e
|T (xj , e) = xi , 6= j}. Assume two dummy events e0
en+1 , precondition, add effect, delete effect. define SAT
variable xk,i 1 k l, 0 n + 1, x . Assigning value true xk,i
means state x, operating sequence events steps 1
k 1 events step k indices less final plan. construct
formula
l conjunction formulae (-1) (-6) stated below:
(-1)

V

k,j
E {e
{eki xk,i
xt |1 k l, < j, (xs , ei ) = xt , ej Et
n+1 },



{ei+1 , ..., ej1 } (Et Et ) = }

(-2)

V

(-3)

V

k,j



{eki xk,i
xs |1 k l, < j, ei Es , ej Es Es {en+1 },


{ei+1 , ..., ej1 } (Es Es ) = }

k,i


{xk,0
xs |1 k l, 1 n, xs , ei Es Es ,


{e1 , ..., ei1 } (Es Es ) = }

581

fiRankooh & Ghassem-Sani

(-4)

V

{xk,n+1
xk+1,0
|1 k < l, xs }



(-5)

V

{xk,i
0 |1 k l, 1 n}

(-6)

V

{xk,i |x , 1 k l, 1 n + 1}

Adding
l encoding problem makes SAT solver somehow simulate
behavior , finding model represents causally valid plan. Assume
observing ei causes make transition xs xt . Moreover, let ej first event
ei (according fixed ordering e1 , ..., en ) may cause transition
xt . Formula (-1) guarantees ei member Stepk , state xs
time observing ei , state changed xt , next relevant event
xt (i.e., ej ) become aware transition. (-2) implies ei member
Stepk , state xs time observing ei , remain xs ,
next relevant event xs become aware current state . (-3) causes
information regarding state start step propagated first
relevant event step. (-4) propagates information regarding state
end step next step. (-5) ensures starting state
place final plan. means simulation started
anywhere plan produced. enables SAT solver detect
strings accepted , also strings subsequences accepted
. Finally, (-6) guarantees never one accepting states.

Example 7. Let Finite State Machine depicted Figure 10-(c). Finite
State Machine detects sequences events , ae , bs , appear according
order , bs , , ae i. Assume four events: e1 = , e2 = ae , e3 = bs ,
e4 = . Also assume two dummy events e0 e5 . sake simplicity,
suppose problem events e0 e5 , encoding
two steps. Consider boolean assignment , (e11 ) = (e13 ) = (e14 ) =
(e22 ) = true, (e12 ) = f alse. words, choosing , bs ,
first step, ae second step. fact, plan(M ) = , bs , , ae i.
example, E0in = {e2 }, e2 = ae event causes transition
state s0 . Similarly, have: E0out = {e1 }, E1in = {e1 }, E1out = {e2 , e3 }, E2in = {e3 },
E2out = {e2 , e4 }, E3in = {e4 }, E3out = {e2 }, E4in = {e2 }, E4out = . show
use formulae (-1) (-6) stated encode , cannot model
produced SAT formula. show contradiction. Assume model
produced SAT formula.
s0 starting state . Hence, according (-5), (s01,1 ) = true,
means state s0 , prior checking whether e1 present first
step final plan.
1
s1,2
According (-1), e11 s1,1
1 . Since (e1 ) = true
0
1,2
(s1,1
0 ) = true, must also (s1 ) = true. words, verifies e1
present first step final plan, causes current state

582

fiITSAT: Efficient SAT-Based Temporal Planner

changed s0 s1 . (s1,2
1 ) = true implies state s1 , prior checking
whether e2 present first step final plan.
1,3
1
According (-2), e12 s1,2
1 s1 . Since (e2 ) = f alse
1,3
1,2
(s1 ) = true, must also (s1 ) = true. words, verifies
e2 present first step final plan, causes state
remain s1 . (s1,3
1 ) = true implies state s1 , prior checking whether e3
present first step final plan.
1
According (-1), e13 s1,3
s1,4
1
2 . Since (e3 ) = true
1,4
1,3
(s1 ) = true, must (s2 ) = true. words, verifies e3
present first step final plan, causes state changed
s1 s2 . (s1,4
2 ) = true implies state s2 , prior checking whether
e4 present first step final plan.
1
s1,5
According (-1), e14 s1,4
3 . Since (e4 ) = true
2
1,5
(s1,4
2 ) = true, must (s3 ) = true. words, finds e4
present first step final plan, causes state changed
s2 s3 . (s1,5
3 ) = true implies state s3 , visiting events
first step final plan.
1,5
2,0
According (-4), s1,5
3 s3 . Since (s3 ) = true, must also
(s2,0
3 ) = true, implies state s3 , prior visiting event
second step final plan.
2,0
2,2
According (-3), s2,0
3 s3 . Since (s3 ) = true, must also
(s2,2
3 ) = true, implies state s3 , prior checking whether e2
present second step final plan.
2
s2,5
According (-1), e22 s2,2
4 . Since (e2 ) = true
3
2,5
(s2,2
3 ) = true, must also (s4 ) = true. words, verifies
e2 present second step final plan, causes state
changed s3 s4 . (s2,5
4 ) = true implies state s4 , visiting
events first two steps final plan. hand, s4 accepting
state . Hence, according (-6), (s2,5
4 ) = f alse. clearly
contradiction. Therefore, conclude cannot model produced
SAT formula.

prove adding
l encoding given problem, prevents planner
producing causally valid plans subsequence events equivalent
string accepted . means negative cycle translated
FSM, reoccurrence negative cycle avoided translating FSM
SAT formula, adding formula encoding problem.
P
Theorem 11. Let P = (I, G, A) temporal planning problem,
= {e1 , ..., en }




set events P, l three formulae l , l , l (defined Section
P 4),
non-empty causally valid plan P obtained solving l . Let = (S , , , x0 , )
583

fiRankooh & Ghassem-Sani

FSM accepts subsequence = he1 , ..., em ,
l encoding
presented (-1) (-6). exist model l
l
= plan(M ).
Proof. See Appendix A.
also need show adding
l encoding render planner incapable producing plans contain subsequence accepted .
P
Theorem 12. Let P = (I, G, A) temporal planning problem,
= {e1 , ..., en }

set events P, l three formulae l , l , l (defined
Section 4). Let model satisfies l , = he1 , ..., em = plan(M ). Let
P
= (S , , , x0 , ) FSM accept subsequence ,
l


encoding composed (-1) (-6). exists model l l
= plan(M ).
Proof. See Appendix A.
explain sequence events introduce negative cycle STN
causally valid plan used prevent similar negative cycles reoccurringP
future
plans produced problem hand. Let P temporal planning problem,

set events P, = e1 , ..., en causally valid plan P. Assume STN
representing scheduling function negative cycle N nodes xi1 , ..., xim . Note
xik node corresponding event eik . Without loss generality, assume
i1 < ... < im , i.e., events negative cycle ordered order
started finished
. Let Oik set temporal actions P
{e|action(e) Oik } {eik }.
reaching eik sequence ei1 , ..., eim , P
ik =
Consider regular language LN alphabet
defined LN = ei1 i2 ei2 ...im eim ,
ik denotes string symbols ik . fact, strings LN , events
already present current negative cycle inserted sequence
way temporal constraints among ei1 , ..., eim remain unchanged. see
exclude events open actions ik , consider two hypothetical events eij eij
respectively starting event ending event action a. Therefore,
temporal constraint scheduling function form (ij ) (ij ) = dur(a).
Here, insert another copy ending event two events,
ended execution eij and, result, eij longer pairing event
eij , mentioned constraint longer exist.
Theorem 13. Let N = xi1 , ..., xim negative cycle STN corresponding
causally valid plan = e1 , ..., en temporal problem P, xik node corresponding event eik . Let another causally valid plan P. subsequence
member LN (defined above), corresponding STN also N
negative cycle.
Proof. See Appendix A.
584

fiITSAT: Efficient SAT-Based Temporal Planner

Consrtucting FSM accepts LN straightforward. Let FSM. Theorem
13 shows added encoding input problem, ITSAT still
capable finding valid temporal plan, provided plan exists.

6. Empirical Results
section, show preprocessing, encoding, scheduling methods contribute overall performance ITSAT. Since contribution preprocessing
part investigated encoding fixed, first analyze performance
three encodings explained Section 4. also compare performance ITSAT
several state-of-the-art temporal planners non-numerical temporal planning problems
previous International Planning Competitions.
Section 4, theoretically showed novel relaxed -step encoding least
compact temporal versions -step -step encodings fixed ordering (i.e.,
number steps needed relaxed -step encoding solve given problem less
equal temporal versions -step -step encodings). Here,
empirically show relaxed -step often needs significantly smaller number steps,
compared -step -step encodings. also show mentioned compactness
causes relaxed -step significantly outperform -step -step encodings
benchmark problems terms memory speed.
Section 3, explained two preprocessing methods, namely mutual exclusion analysis
action compression. section show methods contribute
overall performance ITSAT benchmark problems. purpose, compare
four versions ITSAT: 1) ITSAT without preprocessing, 2) ITSAT mutual exclusion
analysis, 3) ITSAT action compression, 4) ITSAT mutual exclusion
analysis action compression. experimental results show methods
separately enhance performance ITSAT.
Section 5, discussed adding certain blocking clauses encoding
problem, one prevent negative cycles reoccurring STNs produced
causally valid plans. also introduced elaborate method preventing negative cycles, adding extra clauses based certain Finite State Machines.
Here, empirically show FSM-based method crucial efficiency ITSAT
problems required concurrency.
Finally, compare performance ITSAT state-of-the-art temporal planners, namely OPTIC (Coles et al., 2010), LPG-td (Gerevini et al., 2006),
TFD (Eyerich et al., 2009). OPTIC TFD different degrees temporal expressivity, whereas LPG-td temporally expressive (i.e., capable solving
problems required concurrency). show ITSAT significantly outperforms
OPTIC TFD, competitive LPG-td many domains.
6.1 Implementation Details
order parse planning problems domain, also validating output plans
produced ITSAT, used VAL, plan validation tool developed
organizers IPC 2011. schematic operators given domain instantiated
objects input problem produce possible valid ground temporal actions. ITSAT
585

fiRankooh & Ghassem-Sani

performs polynomial reachability analysis recognize actions prepositions
relevant given problem. purpose, goal conditions initially
assumed relevant propositions. action produces relevant proposition upon
starting ending considered relevant action. ITSAT adds preconditions
starting ending events relevant actions current set relevant propositions.
invariants relevant actions added set, too. Updating sets relevant
propositions actions repeated changes occur sets.
update set relevant propositions omitting relevant propositions
present initial state given problem. omitted propositions
deleted relevant action. propositions also omitted
at-start, at-end, invariants relevant actions. Mutual exclusion analysis action
compression methods described Section 3, performed sets relevant
actions propositions.
mentioned Section 4, encoding methods assume exists
predefined fixed ordering events given problem. current implementation
ITSAT, ordering events produced constructing ground actions,
taken presumed fixed ordering events. starting event action
placed immediately corresponding ending event mentioned ordering.
elaborate heuristic methods producing ordering may result compact
encoding (Rintanen et al., 2006). Investigating methods beyond scope
paper left future research.
current version ITSAT, use P recosat (Biere, 2009), free off-theshelf system, SAT solver. also examined two SAT solvers, namely
inisat (Een & Biere, 2005) Lingeling (Biere, 2013) satisfying formulae.
However, precosat best overall performance among three SAT solvers; though
Lingeling better performance terms memory usage.
Since P recosat accepts formulae Conjunctive Normal Form (CNF), formulae described throughout paper translated equivalent CNF formulae. performed simply using logical equivalence relations
(1 2 1 2 ) ((1 2 ) 1 2 ).
problem, start formula one step. set time limit
three minutes precosat find model formula. case failure,
add three steps formula repeat process either model
found predetermined maximum time 30 minutes reached. case success
finding model, causally valid plan extracted model. plan
given scheduling process find valid temporal plan. scheduling function
fails, appropriate FSM generated encoded problem formula (see Section
5) without increasing number steps. new formula given P recosat
find new model. Although parallel solving formulae different number steps
shown effective nave sequential approach (Rintanen et al., 2006;
Streeter & Smith, 2007), empirical results show even simple sequential method
sufficient outperform current temporal planners many planning domains. leave
investigation regarding effect using parallelism future research.
experiments explained section conducted 3.1GHz corei5
CPU 4GB main memory. benchmark problems, used problem
586

fiITSAT: Efficient SAT-Based Temporal Planner

sets previous IPCs. problems different planning domains including
zenotravel, rovers, depots IPC 2004, airport IPC 2006, pegsol, crewplanning,
openstacks, elevators, sokoban, parcprinter IPC 2011, driverlog, f loortile,
matchcellar, mapanalyser, parking, rtam, satellite, storage, turnandopen, tms
IPC 2014. Note domains used different IPCs.
domains, chosen problem set recent competition domains.
problem set IPC 2008 present experiments.
Among domains used previous IPCs, matchcellar, turnandopen, tms
include problems required concurrency. problem sets
temporally expressive planners capable producing valid plans. order achieve
better assessment ITSAT problems required concurrency, used two
extra domains driverlogshift matchlift (Halsey, 2004). also performed
experiments time-window variants satellite airport domains. domains,
used IPC 2004 required concurrency, referred throughout
section satellite-tw airport-tw, respectively. mentioned domains
required concurrency explained details Section 6.4.
6.2 Impact Different Encoding Methods
evaluate -step, -step, relaxed -step encodings produced three different versions ITSAT, namely, ITSAT-, ITSAT-, ITSAT- , respectively.
versions, formula mut , encodes mutex relations, also added
encoding. None versions take advantage action compression. negative cycle
prevention method described Section 5 used three versions ITSAT.
Table 2 shows comparison domain among versions regard number
solved problems.
seen Table 2, ITSAT- best performance among three
versions. fact, ITSAT- able solve 65 problems ITSAT-,
103 problems ITSAT-. Furthermore, almost problems solved ITSAT-
ITSAT- also solved ITSAT- . means relaxed -step encoding
significantly efficient temporal versions classical -step -step
encodings.
Table 3, shows detailed comparison among mentioned encodings. different columns Table 3 represent following items: name domain, problem
number, used encoding method, number steps encoding, result
P recosat terms satisfiability unsatisfiability formula, number clauses
variables divided 1000, amount time taken P recosat determine
result, amount memory needed solving formula. problem
encoding method, results presented two cases: unsatisfiable formula
highest number steps, satisfiable formula lowest number steps. Note
produce results, increased number steps one formula
unsatisfiable. Symbol used time column cases P recosat
failed find model formula 1800 seconds. results presented
domains least one problems solved least two
planners. Accordingly, openstacks, elevators, matchcellar, rtam omitted
587

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
satellite-tw
airport-tw
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandopen
tms
driverlogshift
matchlift
total

problems
20
20
22
36
50
50
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
10
14
542

ITSAT-
13
18
13
3
19
20
20
8
0
0
2
15
0
10
14
0
10
0
0
0
1
18
10
14
208

solved
ITSAT-
16
18
17
3
21
21
20
8
0
0
3
16
2
16
19
0
10
0
3
9
2
18
10
14
246

ITSAT-
16
20
19
3
21
38
20
20
9
0
2
17
3
20
19
18
10
0
3
9
2
18
10
14
311

Table 2: Overall Comparison Different Encoding Methods
Table 3. Moreover, satellite storage, results presented
-step -step encodings.
domain, Table 3 presents results hardest problem (i.e.,
problem greatest number propositions). experiments, observed
pattern similar chosen problems problems domain. Note
results presented Table 3 finding first causally valid plan. Therefore,
results include information regarding FSM encoding method described
Section 5. explain impact FSM-based negative cycle prevention later
section.

588

fiITSAT: Efficient SAT-Based Temporal Planner

domain

zenotravel

rovers

depots

satellite-tw

airport-tw

airport

prob encoding steps

10

4

13

3

11

5

4

26

25

18

2

27

26

3

10

6

17

3

11

7


4

12

12

3

5

13

13


6

72

33

19

7

73

34


8

70

31
20

5

71

32


6
Continued next page

result
F
F
F



F
F
F



F
F
F



F
F
F



F
F
F



F
F
F




589

C
1000

V
1000

474
133
69
521
167
92
5467
4444
375
5673
4618
511
7950
3256
1008
8747
3802
1336
33
26
7
36
28
8
5415
1811
243
5573
1817
270
9261
3189
430
9392
3290
506

136
33
23
150
42
32
560
412
15
581
428
24
1259
455
236
1387
534
326
9
7
3
10
8
3
1516
412
44
1541
439
49
1381
361
37
1401
373
44

time
(s)
25
0.4
0.38
33
0.54
0.56


0.14
89
47
0.36
6.6
2.2
1.39
8.9
3
2.1
1.2
1.4
0.1
0.7
0.7
0.1
24
3.7
0.43
19
4.1
0.5
27
3.5
0.16
21
4.3
0.62

mem
(MB)
131
18
10
146
20
17
413
244
12
353
220
12
598
284
129
1001
301
141
3
2
1
4
4
1
912
271
22
900
283
28
837
257
31
844
263
36

fiRankooh & Ghassem-Sani

domain

prob encoding steps

12

12

pegsol
20

5

13

13


6

69

69

crewplanning 8

4

70

70

5

19

13

sokoban
4

6

20

14

7

42

31

parcprinter
20

8

43

32


9

7

driverlog
2

5

8

6

22

11

floortile
10

6

23

12

7

17

9

mapanalyser 15

2
Continued next page

result
F
F
F



F
F
F



F
F
F



F
F
F



F
F


F
F
F



F
F
F

590

C
1000

V
1000

34
25
10
37
27
12
112
102
3
114
104
3
542
274
122
571
295
142
2325
1436
345
2380
1482
385
2634
2803
5248
3291
201
74
31
211
80
36
187009
101893
29988

9
6
3
10
7
4
34
29
1
35
30
1
143
64
37
150
69
43
382
198
51
391
205
58
258
184
294
221
21
11
6
22
12
7
1005
534
122

time
(s)


0.05
22.4
7.3
0.3


0
30
15
0

12
3.9
74
40
1.5

30
1.1
93
25
0.7
6.2
14
23
13.9
55
7
0.14
20
0.62
0.16
18
10
5.4

mem
(MB)
28
26
1
14
11
3
40
49
1
44
46
1
163
78
23
190
125
20
319
119
24
289
128
26
165
70
280
131
48
16
5
49
13
5
1196
519
75

fiITSAT: Efficient SAT-Based Temporal Planner

time
domain
prob encoding steps result
(s)

18

197433 1064
26

10

112123 593
11


3

40062
181
6.7

4
F
1769
150
2.5

2
F
605
75
0.5

parking
11

1
F
238
38
0.4

5

1868
187
4.2

3

911
112
2.5


2

470
75
2

11
F
870
221


satellite
3

5
F
294
91


12

950
244
157

6

352
110
4.9

11
F
1523
125


storage
9

8
F
633
84
48

12

1662
136
5.9


9

710
94
9.4

42
F
2416
203


22
F
944
106
33

turnandopen 1

10
F
371
53
1.1

43

2474
207
176

23

987
111
37

11

406
58
1.3

9
F
491
51
2.3

7
F
257
39
0.5

tms
18

3
F
91
18
0.1

10

546
56
1.4

8

284
43
0.5


4

115
23
0.3

18
F
373
65
1.5

15
F
235
37
0

driverlogshift 11

9
F
54
17
0

19

411
69
0.6

16

260
39
0.3


10

57
20
0.3
Table 3: Detailed Comparison Encoding Methods
C
1000

591

V
1000

mem
(MB)
1177
538
128
177
70
34
297
87
72
431
91
440
95
198
69
149
72
454
112
41
465
106
42
65
42
14
67
42
17
35
19
7
39
21
9

fiRankooh & Ghassem-Sani

Figure 11. Speed Comparison ITSAT- ITSAT-

Section 4, theoretically showed order solve given planning problem,
relaxed -step encoding requires fewer steps temporal versions classical
-step -step encodings ordering fixed. Table 3 shows ITSAT-
often needs considerably smaller number steps. phenomenon prominent
airport, crewplanning, mapanalyser. Moreover, openstacks matchcellar,
neither ITSAT- ITSAT- able solve problem due large number
steps required. suggests correlation performance
planner, compactness encoding. Generally speaking, relatively
high number steps needed -step encoding solve problem, deduce
strong causal connection actions produced plan.
hand, -step encoding devised take advantage causal connections.
Therefore, -step encoding expected advantage -step encoding
domains. phenomenon visible airport, crewplanning, openstacks,
matchcellar domains, numbers steps required -step encoding
domains exceptionally high. Table 3 also shows relaxed -step encoding results
significant improvement planner terms memory usage.
592

fiITSAT: Efficient SAT-Based Temporal Planner

Figure 12. Speed Comparison ITSAT- ITSAT-

also compared speed ITSAT- ITSAT- ITSAT-
solving benchmark problems. results depicted Figure 11 Figure 12.
seen, ITSAT- outperformed ITSAT- ITSAT- almost
problems.
6.3 Impact Mutual Exclusion Analysis Action Compression
Section 3, explained mutual exclusion analysis action compression performed preprocessing components ITSAT. Here, empirically show components quite effective enhancing performance planner. showed

before, encoding results best performance ITSAT. fixed
formula base comparison, produced three formulae investigate

impact preprocessing method. three formulae mut (the base encod
ing plus mutual exclusion information), com (the base encoding plus action

compression information), mut com (the base encoding plus mutual exclusion action compression information). Table 4 shows number problems solved
mentioned versions ITSAT.
593

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
satellite-tw
airport-tw
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandpen
tms
driverlogshift
matchlift
total

problems
20
20
22
36
50
50
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
20
10
14
542




13
20
11
3
21
38
20
20
1
0
1
17
0
3
14
0
3
0
0
0
2
0
10
14
211



mut
16
20
19
3
21
38
20
20
9
0
2
17
3
20
19
18
10
0
3
9
2
18
10
14
311



com
14
20
14
3
21
38
20
20
5
0
3
19
1
20
19
20
7
0
0
0
3
18
10
14
289



mut com
18
20
20
3
21
39
20
20
13
0
8
20
4
20
20
20
17
0
16
20
9
18
10
14
370

Table 4: Impact Mutual Exclusion Analysis Action Compression
seen Table 4, preprocessing methods result significant improvement terms overall coverage. fact, version ITSAT uses methods
solves 159 problems base planner. Besides, version uses methods even considerably outperforms two versions use one preprocessing
method. suggest preprocessing components necessary producing
best performance ITSAT.
investigate effectiveness action compression method domains
ITSAT compresses considerably actions CRIKEY, performed another
experiment. compressed actions ITSAT considers compression safe
CRIKEY3 not. new version ITSAT, also used mutual exclusion
information. version ITSAT solves six problems version
594

fiITSAT: Efficient SAT-Based Temporal Planner

mutual exclusion information used: six problems, four problems
zenotravel, one airport, one mapanalyser. results change
much domains. Note three mentioned domains ITSAT
compresses considerably actions CRIKEY.
6.4 Impact FSM-Based Negative Cycle Detection
mentioned earlier, among domains used evaluate ITSAT, matchcellar, turnandopen, tms, driverlogshift, matchlift, time-window versions airport satellite
problems required concurrency. fact, domains, may impossible
schedule causally valid plan produced solving SAT formula, valid temporal
plan. Here, briefly explain problems domains may require concurrency, may introduce negative cycles STN associated
causally valid plan.
matchcellar matchlift, exists action lighting match. action
produces light certain amount time. objective mend fuses.
actions mending fuse executed light. result, actions
lighting match mending fuse must executed concurrent. However, causally
valid plan, since planner consider durations actions, may assume
match remain lit fuses mended. discussed Section 5,
introduce negative cycle STN produced causally valid plan.
tms, objective produce certain number ceramic structures.
structures need several preparations done furnace producing
heat. clear domain similar matchcellar matchlift,
requires concurrency similar way.
simplified version driverlogshift introduced Section 2. difference
simplified version one used section evaluate planners,
here, drivers walk to, board, disembark trucks. Furthermore,
REST WORK actions performed drivers rather trucks. domain,
working shifts drivers analogous action lighting match
matchcellar domain.
turnandopen, exists robot needs move number rooms.
doors pair adjacent rooms. doors, closed
initial state, opened robot. robot open door
turning doorknob. domain, actions turning doorknob opening
door must executed concurrently. However, duration action turning
knob 3, whereas opening door 2. enables ITSAT schedule every
causally valid plan valid temporal plan. Therefore, preventing negative cycles
necessary domain.
time-window versions airport satellite, specific time
goals must obtained. deadline introduced problem using specific
frame action duration equal time deadline. actions
executed frame action executed. words, actions
must concurrent frame action. However, causally valid plan, since
planner consider durations actions, may assume frame action
595

fiRankooh & Ghassem-Sani

domain
problem
satellite-tw
3
airport-tw
21
matchcellar
20
tms
18
driverlogshift
10
matchlift
14

restarts
121
1
34
3
43
9

C
1000


12
552
44
121
68
72

FSM
1450
5
408
12
930
180

V
1000


3
65
22
23
26
15

FSM
318
2
203
10
280
112

memory (MB)

FSM
1
382
41
1
9
77
16
2
13
107
31
98

Table 5: Collective Size SAT Encodings FSMs
arbitrarily long, thereby neglect meet deadline achieving goals.
introduce negative cycles STNs produced causally valid plans.
explained Section 5, STN causally valid plan includes negative
cycle, must force SAT solver find different solution. done simply
adding extra blocking clause current SAT formula prevent least one
events negative cycle reoccurring current step. Alternatively,
introduced elaborate method thing, adding encoding
certain FSMs encoding. method, STN causally valid plan
k steps includes negative cycle, FSM detects negative cycle encoded
SAT formula, solver restarted. order decrease number
restarts, whenever sequence events corresponding negative cycle found, ITSAT
tries find potential negative cycles replacing actions current sequence
actions problem checking STN resulting sequence negative
cycles.
Table 5 shows collective size SAT encodings FSMs required solving
problems domains. base encoding, used relaxed
-step encoding mutual exclusion analysis action compression.
domain, results shown Table 5 hardest problem solved ITSAT.
turnandopen domain excluded Table 5, negative cycle encountered
solving problems domain. different columns Table 5 represent
following items: name domain, problem number, number clauses
variables divided 1000, amount memory needed produce formula.
results number causes, number variables, used memory presented
separated columns base encoding encoding FSMs.
seen Table 5, negative cycle prevention method helps ITSAT solve
considerable number problems required concurrency. Nevertheless, SAT encoding required FSMs significantly larger base encoding domains
number restarts relatively high. hand, number
restarts increase, speed ITSAT declines. restart, SAT
solver must verify satisfiability formula, scratch. fact, numerous
restarts main reason poor performance ITSAT time-window version
satellite.
596

fiITSAT: Efficient SAT-Based Temporal Planner

6.5 ITSAT Versus State-of-the-art Temporal Planners
compare ITSAT three efficient temporal planners, namely, OPTIC (Benton,
Coles, & Coles, 2012), TFD (Eyerich et al., 2009), LPG-td (Gerevini et al., 2006).
similarities approach used ITSAT SCP2 (Lu
et al., 2013), also included results planner experimental results.
OPTIC newest version POPF (Coles et al., 2010). heuristic state-space
temporal planner based so-called temporally-lifted progression planning (Cushing
et al., 2007). Using approach planning enables OPTIC solve problems
required concurrency. Besides, OPTIC handles self-overlapping actions, makes
expressive ITSAT. Although handling self-overlapping actions hardly necessary
solving non-numerical temporal planning problems (Fox & Long, 2007), among
current benchmark domains, zenotravel, rovers, airport permit actions due
modeling errors. fair comparison ITSAT OPTIC, used
corrected versions three domains1 evaluations. guiding search, OPTIC
benefits heuristic function based relaxed planning graph (Hoffmann
& Nebel, 2001).
TFD another heuristic state-space temporal planner. TFD based so-called
decision epoch planning (Cushing et al., 2007). planners use approach
temporally expressive planners based temporally lifted progression planning. words, theory, temporal planning problems defined
PDDL2.1 solved ITSAT OPTIC TFD. However, current benchmark problems potentially solved using decision epoch planning.
guiding search, TFD benefits temporal version so-called Context-enhanced
Additive Heuristic (Helmert & Geffner, 2008).
LPG-td fast temporal planner, temporally expressive. fact,
LPG-td first generates sequential plan given problem, tries reschedule
plan produce one improved quality. renders LPG-td incapable
solving problem matchcellar, turnandopen, tms, driverlogshift, matchlift. Similar
OPTIC, LPG-td benefits heuristic based relaxed planning graph. However,
instead searching state space problem, LPG-td performs search making
local improvements structure similar partial plans, called Linear
Action Graph. Two different configurations LPG-td used based whether
prefer speed planner quality produced plans. Here, present
results quality configuration LPG-td, produced better results speed
configuration experiments.
SCP2 (Lu et al., 2013), SAT-based temporal planner uses discrete representation time. planner assigns explicit discrete time labels step encoding.
approach, step exactly one time unit ahead step + 1. result,
action duration starts step i, forced end step + d. means
number layers required producing plan greater equal makespan
. SPC2 starts formula one step, increases number steps
one, every time formula unsatisfiable. enables SPC2 find optimal plan
1. corrected version mentioned domains downloaded official website POPF
planner.

597

fiRankooh & Ghassem-Sani

number given problems. obtain better performance, SCP2 uses -step semantic
allow causal relations actions time point.
compared ITSAT planners based number problems
solve domain also total score given planner using
scoring strategy recent IPCs; is, planner cannot solve problem, get
score 0 problem; Otherwise, score equal makespan best
produced plan divided makespan plan found planner. results
presented Table 6.
seen Table 6, ITSAT significantly outperforms OPTIC, TFD, SCP2.
fact, ITSAT solves 162 problems OPTIC, 145 problems TFD,
282 problems SCP2. ITSAT also solves 64 problems LPG-td. However,
mainly LPG-td incapable solving problems required concurrency.
exclude satellite-tw, airport-tw, matchcellar, turnandopen, tms, driverlogshift,
matchlift domains LPG-td cannot solve problem, ITSAT solves
31 problems less LPG-td. shows ITSAT quite competitive
LPG-td even solving problems without required concurrency.
shown Table 6, OPTIC solves zero problems parcprinter, driverlog, floortile,
mapanalyser, matchcellar, rtam, storage, tms. domains, main reason
poor performance OPTIC runs memory, early search. TFD
solves zero problems satellite-tw, airport-tw, parcprinter, driverlog, floortile, rtam, storage,
tms. Except parcprinter, TFD runs memory, domains
TFD performs poorly unable find plan within 1800 seconds.
mentioned before, LPG-td solves zero problems domains required concurrency.
performance SCP2 rather poor many benchmark domains. reason
poor performance SCP2 that, many benchmark problems, makespan
optimal plan relatively large. result, problems, SCP2 unable
check satisfiability formulae numbers steps less makespan
optimal plan, within 1800 seconds time limit.
compare quality plans produced ITSAT competing
planners, consider Table 7. numbers presented Table 7 average makespan
ratio plans mutually solved corresponding planner ITSAT corresponding
domain. Ratios less one indicate better average quality solutions produced
ITSAT comparison competing planners. cases neither ITSAT
competing planner able solve problem domain, corresponding
cell Table 7 remained blank.
also performed experiments based number two planners portfolios
different pairs planners. portfolios enabled us combine advantages
two planners. this, 30 minutes time limit divided equally pair
planners. results running portfolios presented Table 8. results
show best configuration obtained combining ITSAT LPG-td.
resulting planner capable solving 423 542 benchmark problems. Moreover,
planners produced best results combined ITSAT.

598

fiITSAT: Efficient SAT-Based Temporal Planner

solved

domain

N

zenotravel

20

18

rovers

20

depots

ITSAT

OPTIC

SCP2

IPC

score

ITSAT

OPTIC

TFD

LPG-td

SCP2

TFD

LPG-td

12

12

20

1

11.41

10.56

11.32

17.68

1

20

20

20

20

4

18.25

18.35

18.56

16.88

4

22

20

7

5

21

6

9.52

4.21

3.04

19.43

6

satellite-tw

36

3

4

0

0

0

3

4

0

0

0

airport-tw

50

21

7

0

0

0

21

7

0

0

0

airport

50

39

24

20

43

0

35.2

23.35

18.11

39.68

0

pegsol

20

20

19

18

20

20

19.36

18.02

17.24

18.98

20

crewplanning

20

20

20

14

9

0

18.37

20

11.94

7.82

0

openstacks

20

13

20

20

20

0

7.26

17.01

19.83

15.23

0

elevators

20

0

1

3

9

0

0

1

3

7.44

0

sokoban

20

8

2

3

5

1

7.64

1.72

3

3.26

1

parcprinter

20

20

0

0

7

0

20

0

0

5.72

0

driverlog

20

4

0

0

14

0

3.89

0

0

13.38

0

floortile

20

20

0

0

20

10

17.05

0

0

16.51

10

mapanalyser

20

20

0

19

20

0

18.48

0

15.62

14.81

0

matchcellar

20

20

20

20

0

0

20

20

16

0

0

parking

20

17

16

20

20

6

5.05

13.98

18.72

19.02

6

rtam

20

0

0

0

20

0

0

0

0

20

0

satellite

20

16

4

13

20

0

2.61

3.55

7.05

20

0

storage

20

20

0

0

18

20

18.77

0

0

1.45

20

turnandopen

20

9

9

18

0

1

9

6.52

13.34

0

1

tms

20

18

0

0

0

0

18

0

0

0

0

driverlogshift

10

10

10

6

0

9

8.01

9.48

5.03

0

9

matchlift

14

14

13

14

0

13

14

13

14

0

13

total

542 370

208

225

306

88

305.87 191.75 195.8

Table 6: ITSAT Versus State-of-the-art Temporal Planners

599

256.29 88

fiRankooh & Ghassem-Sani

domain
zenotravel
rovers
depots
satellite-tw
airport-tw
airport
pegsol
crewplanning
openstacks
elevators
sokoban
parcprinter
driverlog
floortile
mapanalyser
matchcellar
parking
rtam
satellite
storage
turnandopen
tms
driverlogshift
matchlift

OPTIC

TFD

LPG-td

SCP2

1.47
0.99
1.24
1
1
1.06
0.98
1.11
1.34

0.86




1
2.94

6.72

0.72

1.14
1

1.50
1.03
1.41


0.95
0.98
0.89
1.90

1.18



0.86
0.80
2.98

4.45

0.48

0.98
1

1.41
0.89
2.02


0.91
0.96
0.88
1.31

0.69
0.81
1.03
0.97
0.79

3.01

7.35
0.11





1
1.27
2.11



1.02



1


1.05


3.15


1.05
1

1.19
1

Table 7: Average Makespan Ratio

ITSAT
OPTIC
TFD
LPG-td
SCP2

ITSAT

375
385
423
348

OPTIC
375

262
350
237

TFD
385
262

360
256

Table 8: 2-planners Portfolio

600

LPG-td
423
350
360
302

SCP2
348
237
256
302


fiITSAT: Efficient SAT-Based Temporal Planner

Figure 13. Speed Comparison ITSAT OPTIC

Although ITSAT quite competitive state-of-the-art temporal planners,
empirical results reveal drawbacks planner. compared speed
ITSAT OPTIC, TFD, LPG-td, SCP2 benchmark problems.
results presented Figure 13, Figure 14, Figure 15, Figure 16, respectively.
figures, results required concurrency domains separated
domains using different symbols scatterplots: star symbol
represents problems required concurrency, diamond symbol represents
problems. seen, ITSAT slower OPTIC, TFD, LPG-td
number benchmark problems. major cause drawback ITSAT,
SAT solver spends much time refuting several formulae finally find
first satisfiable formula. shown case classical planning, speed
SAT-based planners significantly improved checking satisfiability several
formulae different number steps parallel. discuss detail Section
7 future research.
Another observation that, ITSAT performs rather slowly solving number
problems required concurrency quickly solved OPTIC TFD.
mainly due restarting SAT solver whenever negative cycles encountered.
601

fiRankooh & Ghassem-Sani

Figure 14. Speed Comparison ITSAT TFD

explained earlier, STN causally valid plan k steps includes negative
cycle, FSM detecting negative cycle encoded SAT formula,
solver try satisfy new formula k steps, scratch. domains
negative cycles abundant, performance ITSAT significantly affected
numerous restarts SAT solver.
performance ITSAT particularly poor three domains, namely elevators,
driverlog, rtam. domains, number ground actions higher
domains. linear increase number ground actions may cause
exponential growth size search space problem. tackle problem,
state-space based planners take advantage heuristic functions devised specially
pruning search space planning problems. also shown using SAT
solvers tailored solving planning problems result significant improvement
performance SAT-based classical planning (Rintanen, 2012). think employing
idea also improve speed ITSAT mentioned domains.
Another drawback ITSAT poor quality produced plans benchmark
domains. notably, although ITSAT solves problems depots, openstacks,
parking, satellite, quality plans rather low domains, according
602

fiITSAT: Efficient SAT-Based Temporal Planner

Figure 15. Speed Comparison ITSAT LPG-td

Table 7. mainly due fact ITSAT abstracts duration actions,
thus, SAT solver lacks competency evaluating quality plans
produced. Nevertheless, quality plans produced ITSAT generally
comparable planners benchmark domains. Section 7, explain
idea improving quality plans produced ITSAT.

7. Conclusions Future Research
paper, described ITSAT, temporally expressive SAT-based planner. ITSAT
based approach takes advantage parallel encodings. approach, first,
durations actions given problem abstracted out. abstract problem
encoded SAT formula using -step -step semantics causally valid plans.
generating causally valid plan, ITSAT performs scheduling process.
process, ITSAT tries satisfy temporal constraints imposed considering
durations actions. done solving Simple Temporal Problem (STP).
cases inconsistent STP, cause, negative cycle corresponding
Simple Temporal Network (STN), detected. ITSAT adds certain clauses SAT
formula hand prevent reoccurrence negative cycles. process
603

fiRankooh & Ghassem-Sani

Figure 16. Speed Comparison ITSAT SCP2

repeated temporally valid plan produced, predefined time limit
reached.
main contributions paper summarized follows:
introduced novel method detect temporal actions compressed
classical ones. new compression technique performed preprocessing task
thus independent planning algorithm used
temporal planner. makes compression technique general
POPF, specifically tailored planner. empirical results showed
action compression results improved performance ITSAT. also
empirically showed method capable detecting compression-safe
temporal actions previous action compression method, used POPF.
introduced three new encoding methods based concept parallel plans
SAT-based temporal planning. two methods adopted
classical planning, third method, produces compact formulae,
employed ITSAT first time. empirical results show new
encoding significantly enhance performance SAT-based temporal planning.
604

fiITSAT: Efficient SAT-Based Temporal Planner

introduced method avoid producing plans members given
regular language set events. done embedding SAT
encoding particular FSM accepts language SAT encoding
input problem. used method preventing temporal inconsistencies
produced causally valid plans reoccurring subsequent causally valid
plans. experiments showed method contributed considerably
performance ITSAT current benchmark problems required concurrency.
According empirical results, taking advantage new approaches,
ITSAT outperform state-of-the-art temporally expressive planners, also
competitive efficient temporal planners handle required concurrency. Nevertheless, believe performance ITSAT improved several
ways, discussed below.
current version ITSAT, satisfiability formulae different number
steps checked sequential manner, starting formula encoding one step.
means SAT solver refute several formulae finds first satisfiable
formula. time required checking satisfiability formulae increased
number steps, policy would result best performance ITSAT. However,
almost never case. shown case classical planning, fixed
planning problem, time needed finding model satisfiable formula usually
considerably less time needed refuting unsatisfiable formula (Rintanen et al.,
2006). Based experiments, phenomenon happens case temporal
planning, too. Similar SAT-based classical planning, one take advantage
phenomenon checking satisfiability formulae different numbers steps
parallel. applicability parallelisms sensistive amount
memory required saving formulae. shown Section 6, newly
introduced -step encoding considerably efficient temporal version
classical -step encoding terms memory usage. suggests -step
encoding suitable employing parallelism.
linear sized classical -step -step encodings, encoding methods,
assume exists predefined fixed ordering events given problem.
ordering great impact number steps needed solving input
problem. example, consider sequential plan ground action applied
once. potential plan subsequence mentioned fixed ordering,
one step sufficient finding plan. hand, case reversed
fixed ordering, number steps would required find model might
large size plan itself. current implementation ITSAT, ordering
events produced constructing ground actions, taken predefined
fixed ordering events. However, considering causal relationships among actions
given problem, one might able find effective orderings would result
fewer steps solving problem. believe enhancement would result
improved version ITSAT, efficient terms speed
memory usage.
current version ITSAT uses off-the-shelf general-purpose SAT solvers.
means advancement designing solvers also improve performance
ITSAT. Recent investigations field SAT-based classical planning shown
605

fiRankooh & Ghassem-Sani

designing SAT solver tailored solving planning problems result much improved
performance SAT-based planners. particular, efficient SAT-based classical
planner, Mp (Rintanen, 2012), able competitive sate-of-the-art
state-space based planners employing idea. Since causal structures temporal
planning problems generally similar classical planning problems,
believe ITSAT benefit enormously employing planning-oriented SAT solver.
mentioned Section 6, one main drawbacks ITSAT poor quality
produced plans benchmark domains. mainly due fact
ITSAT abstracts duration actions, thus, SAT solver
needed resources evaluating quality plans produced. Alternatively, one add explicit representation time encoding (Shin & Davis,
2005). done using SMT solvers (Armando & Giunchiglia, 1993), handle continuous variables. However, discussed Section 1, solution may result
considerably slower search. think ITSAT benefit combination
two approaches: first plan produced ITSAT, proceed
introducing appropriate numerical constraint SAT formula hand, use
SMT solver produce improved plans. subject ongoing research.
Finally, mention components ITSAT, also used
fields AI planning. notably, -step encoding also employed
SAT-based classical planning. empirical results show encoding method
quite effective reducing number steps needed produce valid plans several
temporal planning domains also classical version. think improved
performance -step encoding comparison -step encoding achieved
classical planning, too. Moreover, Section 5, showed prevent members
given regular language events input problem produced
output plan. used method prevent ITSAT producing temporally invalid
plans. method employed enforce variety constraints plan
produced. example, consider case require certain actions
executed specific order. must clear set plans violating
constraint regarded regular language set actions. Therefore,
constraint introduced encoding problem method
discussed Section 5.

Acknowledgments
authors would like thank handling editor, Jorg Hoffmann, anonymous
reviewers invaluable contributions quality paper.

Appendix A. Proofs
Theorem 1. Let P = (I, G, A) temporal planning problem P c = (state(I), G, Ac )
causal abstraction P. Assume = he1 , ..., en sequence events
applicable I, sn = succ(I, ). following conditions must hold:
two propositions p q members state(sn ), p q non-mutex
layer n planning graph P c .
606

fiITSAT: Efficient SAT-Based Temporal Planner

proposition p member state(sn ), action member agenda(sn ),
p opena non-mutex layer n planning graph P c .
Proof. give proof induction n (the length ). n = 0, i.e.,
event applied I, conclusions obviously hold every member state(I)
present first layer graph, mutex first layer,
agenda(I) = Definition 6. suppose conclusions hold n = k 1. show
also hold n = k. Assume = he1 , ..., ek sequence events
applicable I, sk = succ(I, ), sk1 = succ(I, he1 , ..., ek1 i).
Let p q two members state(sk ). three possible cases:
Case 1: p q members sk1 , induction hypothesis, p
q non-mutex layer k 1 planning graph P c thus noopp noopq
non-mutex layer k 1. Hence, p q mutex layer k.
Case 2: neither p q members state(sk ), Definition 5, p q
must members add(ek ). Assume ek ending event action
(the case ek starting event analogous thus omitted here).
Since ek applicable state sk1 , Definition 4, members pre(ek ) must
also members state(sk1 ), must member agenda(sk1 ). Therefore,
induction hypothesis, members pre(ae ) non-mutex layer k 1.
result, p q, based Definition 10 added ae , non-mutex
layer k.
Case 3: p member state(sk1 ), Definition 5, q must member
add(ek ), p cannot member del(ek ). Assume ek ending event
action (again, case ek starting event analogous thus
omitted here). induction hypothesis, members pre(ae ) non-mutex
layer k 1, Definition 10, ae delete p. Therefore, ae present
layer k 1 cannot mutex noopp . result, p q non-mutex
layer k.
Let p member state(sk ), action member agenda(sk ).
two possible cases:
Case 1: also member agenda(sk1 ), started yet ended
reaching sk1 , invariants members state(sk1 ).
induction hypothesis, invariants must non-mutex layer k 1. Hence, ai
present layer k 1. Definition 10, ai adds opena . Now, must show p
added action mutex ai layer k 1. p member
state(sk1 ), induction hypothesis, p present layer k 1. Therefore,
noopp , mutex ai , applicable layer k 1 and, result, p
opena mutex layer k. hand, p member
state(sk1 ), must added ek . Since ek applicable sk1 member
agenda(sk1 ), Definition 4, ek cannot delete invariant a. Assume ek
ending event action b (the case ek starting event b analogous
thus omitted here). induction hypothesis, , mutex
607

fiRankooh & Ghassem-Sani

ai must applicable layer k 1. means p opena mutex
layer k.
Case 2: member agenda(sk1 ), Definition 5, ek must
starting event a, delete p. Moreover, Definition 4, starting
invariants must present state(sk1 ). Therefore, induction hypothesis,
applicable layer k 1. p present state(sk1 ), must added
ek . Definition 10, propositions added starting event also
added . Since also adds opena , p opena cannot mutex layer k.
hand, p member state(sk1 ), induction hypothesis,
p present layer k 1. Therefore, noopp , mutex , applicable
layer k 1. means p opena mutex layer k.

Theorem 2. Let P = (I, G, A) solvable temporal planning problem. Let set
every member either compressible towards start compressible towards
end. compression-safe P.
Proof. Let 0 causally valid plan P (Such plan must exist P solvable).
Starting 0 , produce sequence causally valid plans swapping events
next plan hand. Assume arbitrary order ha1 , ...,
members . Without loss generality, assume action repeated
0 (otherwise, different names given different occurrences action
eliminate repetition). producing causally valid plan , consider
causally valid plan i1 . ai compressible towards start, keep swapping ending
event ai previous event i1 previous event becomes starting
event ai . fact, swaps collectively cause ai become compressed towards
start. swaps never falsify causally valid plan hand: assume
e event immediately prior ending event ai causally valid plan, e
starting event ai . precondition effect e must present
least one state whose agenda includes ai . Thus, Theorem 1, precondition
effect e mutex openai last layer levelled-off planning graph
causal abstraction P. Definition 13, e must swappable ending
event ai . Therefore, causally valid plan starting ending events
ai located next other. Similarly, ai compressible towards end, keep
swapping starting event ai next event i1 next event becomes
ending event ai . result, n , ending event members located
next corresponding starting events, therefore, according Definition 11,
compression-safe P.
Lemma 1. Let = {e1 , ..., en } set events, E R, two subsets S. Assume
subset ei E, ej
/ R j > i. Let
function defined following rules assigns value true f alse
SAT variable chain(e1 , ..., en ; E; R; k; m):
608

fiITSAT: Efficient SAT-Based Temporal Planner

i, (eki ) = true ei member .
i, (bki,m ) = true ej E j < i.
satisfies chain(e1 , ..., en ; E; R; k; m).
Proof. show satisfies formulae (C-1) (C-3), therefore satisfies
chain(e1 , ..., en ; E; R; k; m).
/
(C-1) Consider arbitrary formula eki bkj,m formula (C-1). ei
(eki ) = f alse, thus formula trivially satisfied. consider case
ei . definition formula (C-1), know < j ei E.
Therefore, according definition , must (bkj,m ) = true, thus
formula satisfied.
(C-2) Consider arbitrary formula bki,m bkj,m formula (C-2). (bki,m ) =
f alse, formula trivially satisfied. hand, (bki,m ) = true,
must exist l, l < el E. Since < j, must
l < j, therefore, (bkj,m ) = true, hence formula satisfied.
(C-3) Consider arbitrary formula bki,m eki formula (C-3). (bki,m ) =
f alse, formula trivially satisfied. hand, (bki,m ) = true,
must exist l, l < el E. according
properties , must ei
/ R. However, definition
chain(e1 , ..., en ; E; R; t; m), ei R and, result, ei
/ . Therefore,
k
(ei ) = f alse formula satisfied.

Lemma 2. Let = {e1 , ..., en } set events, E R two subsets S. Assume
model chain(e1 , ..., en ; E; R; k; m). ei E (eki ) = true,
j > ej R, (bkj,m ) = true, consequently (ekj ) = f alse.
Proof. Suppose sequence e1 , ..., en , event ej first event ei
ej R. Since formula (C-1) chain(e1 , ..., en ; E; R; k; m), eki bkj,m ,
(bkj,m ) = true. Similarly, sequence e1 , ..., en , event ej first event ej
ej R, must formula bkj,m bkj ,m (C-2), implies
(bkj ,m ) = true. repeating argument latter case, infer
j > ej R, (bkj,m ) = true, according (C-3),
(ekj ) = f alse.
Theorem 3 (completeness temporal -step encoding). Let P = (I, G, A)
solvable temporal planning problem, {e1 , ..., en } set events P, =
hStep1 , ..., Stepl causally valid -step plan P. exists model l
= plan(M ).
609

fiRankooh & Ghassem-Sani

Proof. construct function assigns true f alse SAT variables
formula l . Let hs0 , ..., sl state transition sequence . defined
following rules:
proposition p, k 0 k l, (pk ) = true iff p
member state(sk ).
action A, k 0 k l, (ak ) = true iff member
agenda(sk ).
1 n, k 1 k l, (eki ) = true
iff ei member Stepk . Moreover, k 1 k l, (ek0 ) =
(ekn+1 ) = f alse.
proposition p, 0 n + 1, k 0 k l,
(bki,mp ) = true iff exists event ej , j < i, ej Ep , ej Stepk .
1

proposition p, 0 n + 1, k 0 k l,
(bki,mp ) = true iff exists event ej , j > i, ej Ep , ej Stepk .
2

show satisfies formulae (-1) (-13), therefore model l . Note
way constructed, directly = plan(M ).
(-1) According Definition 15, s0 = I, thus formula (-1) clearly satisfied.
(-2) According Definition 15, G state(sl ), thus formula (-2) clearly
satisfied.
(-3) According Definition 6, agenda(I) = , thus formula (-3) clearly
satisfied.
(-4) According Definition 15, agenda(sl ) = , thus formula (-4) clearly
satisfied.
(-5) Let p arbitrary proposition, e event e Rp . e
/ Stepk ,
(ek ) = f alse and, therefore, formula (-5) trivially satisfied. Consider
case e Stepk . According Definition 15, Stepk must -step sk1
sk . Thus, Definition 14, possible ordering events Stepk ,
must able execute events according ordering, starting state
sk1 . One possible ordering specific ordering puts e front
events. Therefore, e must applicable sk1 . Then, Definition 4,
p state(sk1 ). implies (pk1 ) = true, satisfaction
formula (-5) easily follows.
/ Stepk ,
(-6) Let p arbitrary proposition, e event e Ep+ . e
(ek ) = f alse and, therefore, formula (-6) trivially satisfied. Consider
case e Stepk . Similar previous case, starting state sk1 ,
must able execute events Stepk possible ordering reach sk .
610

fiITSAT: Efficient SAT-Based Temporal Planner

One possible ordering one puts e events. Therefore, addeffects e must members state(sj ), Definition 5, p state(sk ).
implies (pk ) = true, satisfaction formula (-6) easily
follows.
/ Stepk
(-7) Let p arbitrary proposition, e event e Ep . e
k
(e ) = f alse and, therefore, formula (-7) trivially satisfied. Otherwise,
argument given case (-6), p
/ state(sk ), satisfaction
formula (-7) easily follows.
(-8) Let p arbitrary proposition. Consider nontrivial case p member
state(sk ) state(sk1 ). easily derived Definition 5, p
added application sequence events, least one events
must add p. implies satisfaction formula (-8).
(-9) case analogous case (-8)
(-10) Lemma 1 used prove satisfies chain(e1 , ..., en+1 ; Ep ; Rp {en+1 }; k; mp1 ).
straightforward see properties model Lemma
1. need show proposition p, provided ei Stepk Ep
j > i, ej
/ Stepk Rp . Suppose ej Stepk . Definition 14,
possible ordering events Stepk , must able execute events
according ordering, starting state sk1 . One possible ordering
one puts ei immediately ej . Notice ei deletes p,
ei Ep . Thus, ej cannot p precondition, ej
/ Rp . infer
ej
/ Stepk Rp . Therefore, Lemma 1, satisfies chain(e1 , ..., en+1 ; Ep ; Rp
{en+1 }; k; mp1 ). Now, show also satisfies bkn+1,mp ak . Consider
1

nontrivial case, (bkn+1,mp ) = true. Based way construct ,
1
least one e1 , ..., en , say ej , must delete p. Again, since Stepk -step sk1
sk , must able execute events Stepk possible ordering
reach sk . Consider specific ordering puts ej events. Now,
agenda(sk ), according Definition 5, ej cannot ending event a.
Therefore, Definition 4, also member agenda state
ej applied. clearly contradicts applicability ej , ej deletes p,
invariant a. Therefore, (ak ) = f alse, implies satisfies
bkn+1,mp ak .
1

(-11) case, too, Lemma 1 used prove satisfies chain(en , ..., e0 ; Ep ; Rp
{e0 }; k; mp1 ). Similar previous case, straightforward confirm
properties Lemma 1. Since ordering chain(e1 , ..., en+1 ; Ep ; Rp
{en+1 }; k; mp1 ) reversed chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp1 ), need show
proposition p, provided ei Stepk Ep j < i, ej
/
Stepk Rp . Suppose ej Stepk . Definition 14, possible ordering
events Stepk , must able execute events according
ordering, starting state sk1 . One possible ordering one
puts ei immediately ej . argument one given case
611

fiRankooh & Ghassem-Sani

(-10), infer ej
/ Stepk Rp and, therefore, Lemma 1, satisfies
chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp1 ). Now, show also satisfies bk0,mp
2

ak1 . Consider nontrivial case, (bk0,mp ) = true. Based way
2
construct , least one e1 , ..., en , say ej , must delete p. Again, Stepk
-step sk1 sk , starting state sk1 , must able execute
events Stepk possible ordering. Consider specific ordering puts ej
events. Definition 4, since ej deletes p, invariant
a, cannot member agenda(sk1 ). Therefore, (ak ) = f alse, implies
satisfies bk0,mp ak1 .
2

(-12) Assume e starting event action a. Stepk -step sk1
sk , starting state sk1 , must able execute events Stepk
possible ordering. Consider specific ordering puts e
events. Therefore, e must applicable sk1 . Then, Definition 4, cannot
member agenda(sk1 ), thus (ak1 ) = f alse. see (ak ) = true,
consider specific ordering events puts e events. events
executed ordering, results applying e appear state sk ,
thus must member agenda(sk ). Hence, satisfies ek ak1 ak .
(-13) Analogous case (-12), assume e ending event action a. Since Stepk
-step sk1 sk , starting state sk1 , must able execute
events Stepk possible ordering. Consider specific ordering puts e
events. Therefore, e must applicable sk1 . Then, Definition
4, must member agenda(sk1 ), thus (ak1 ) = true. see
(ak ) = f alse, consider specific ordering events puts e
events. events executed ordering, results applying e
appear state sk , thus cannot member agenda(sk ). conclude
satisfies ek ak1 ak .

Theorem 4 (soundness -step encoding). Let P = (I, G, A) temporal planning
problem, {e1 , ..., en } set events P, l -step encoding P.
l model , plan(M ) causally valid -step plan P.
Proof. obtain plan(M ) follows. k 1 k l, let Stepk
set events e (ek ) = true. k 0 k l, let
sk temporal state. Assume state(sk ) set propositions p
(pk ) = true, agenda(sk ) set actions (ak ) = true.
show = plan(M ) = hStep1 , ..., Stepl causally valid -step plan P
state transition sequence hs0 , ..., sl i.
formula (-1), immediately follows = state(s0 ). Formula (-2) implies
G state(sl ). Formulae (-3) (-4) respectively imply agenda(s0 )
agenda(sn ) empty sets. Now, need show k 1 k l,
Stepk = {e1 , ..., em } {e1 , ..., en } -step sk1 sk . first show
612

fiITSAT: Efficient SAT-Based Temporal Planner

proposition p, Stepk cannot include two different events ei ej ei Rp ,
ej Ep . j < i, since satisfies formula (-10), Lemma 2, infer (eki )
(ekj ) cannot equal true. hand, < j, since satisfies formula
(-11), Lemma 2, infer (eki ) (ekj ) cannot equal true.
Thus, ei ej cannot members Stepk . Let : {1, ..., m} {1, ..., m}
arbitrary ordering function. show induction k , k m, sequence
heO(1) , ..., eO(k ) applicable sk1 . k = 0 (i.e., case event
applied sk1 ), conclusion trivially holds. induction hypothesis, let sk
temporal state resulting applying sequence heO(1) , ..., eO(k ) sk1 . Let eO(k +1)
starting event action (we omit similar case eO(k +1) ending
event a). show conditions (1) (3) Definition 4 hold thereby eO(k +1)
applicable sk . result, heO(1) , ..., eO(k +1) applicable sk1 .
(1) formula (-5), easily follows preconditions eO(k +1) invariants (except invariants added eO(k +1) ) members
state(sk1 ). mentioned above, neither propositions deleted
another member Stepk . Thus, propositions also members state(sk ).
(2) formula (-7), easily follows member agenda(sk1 ). Notice
according Definition 5, starting event a, i.e., eO(k +1) , event
add agenda state. Therefore, cannot member agenda(sk ),
either.
(3) Let action invariant p p del(eO(k +1) ). Clearly
start(a ) Rp , thus, argued above, start(a ) eO(k+1) cannot
members Stepk . Hence, start(a )
/ Stepk . hand, since p deleted
step k, satisfies chain(en , ..., e0 ; Ep ; Rp {e0 }; k; mp2 ), according Lemma 2,
have: (b0,mp2 ) = true. Therefore, formula (-11), infer (ak1 ) =
f alse, thus,
/ agenda(sk1 ). start(a )
/ Stepk
/ agenda(sk1 ) jointly


imply
/ agenda(sk ).
show sm , result applying heO(1) , ..., eO(m) sk1 , equal
sk .
Let p arbitrary member state(sm ). formulae (-6) (-7) follows
p deleted member Stepk , cannot added member
). Therefore, p deleted
Stepk thus, p cannot member

Wof state(s
k
member Stepk , formula eEp e satisfied . Besides, p
added member Stepk , must member state(sk1 ), thus
(pk1 ) = true. Now, formula (-9), infer (pk ) = true, hence
p state(sk ). hand, p added member Stepk , formula
(-6), deduce (pk ) = true, p state(sk ). Therefore,
state(sm ) state(sk ).
Let p arbitrary member state(sk ). According formula (-7), p cannot
deleted member Stepk . Besides, formula (-8), p either member
613

fiRankooh & Ghassem-Sani

state(sk1 ) added member Stepk . cases, Definition 5 implies
p state(sm ). Therefore, state(sk ) state(sm ).
Let arbitrary member agenda(sm ). formulae (-12) (-13),
follows starting ending events single action members
Stepk . agenda(sk1 ), still open state sm , infer
end(a)
/ Stepk . Therefore, according formula (-13), (ak ) = true, must
member agenda(sk ). hand,
/ agenda(sk1 ), start(a)
must member Stepk . Then, formula (-12), have: (ak ) = true,
again, must member agenda(sk ). Therefore, agenda(sm ) agenda(sk ).
Let arbitrary member agenda(sk ). According formula (-13), start(a)
cannot member Stepk . Besides, formula (-12), either member
agenda(sk1 ) start(a) member Stepk . cases, Definition 5 implies
agenda(sm ). Therefore, agenda(sk ) agenda(sm ).
argument shows state(sk ) = state(sm ) agenda(sk ) = agenda(sm ). Hence,
sk = sm = succ(sk1 , heO(1) , ..., eO(m) i). Therefore, Stepk -step sk1 sk .
Theorem 5 (completeness -step encoding). Let P = (I, G, A) solvable temporal planning problem, {e1 , ..., en } set events P, = hStep1 , ..., Stepl
causally valid -step plan P. exists model l = plan(M ).
Proof. Theorem 3, exists model l = plan(M ). show
translated model l . Since formulae (1) (10) shared
l l , also satisfies formulae. show also satisfies
formulae (-11) (-20), therefore translated model l .
following cases, arbitrary temporal action, ei starting event a, ej
ending event a.
(-11) (eki ) = f alse, formula (-11) trivially satisfied. (eki ) = true,
formula (-12) have: (ak1 ) = f alse, therefore formula (-11) satisfied.
(-12) (eki ) = f alse, formula (-12) trivially satisfied. (eki ) = true,
formula (-12) have: (ak ) = true, therefore formula (-12) satisfied.
(-13) (ekj ) = f alse, formula (-13) trivially satisfied. (ekj ) = true,
formula (-13) have: (ak ) = f alse, therefore formula (-13) satisfied.
(-14) (ekj ) = f alse, formula (-14) trivially satisfied. (ekj ) = true,
formula (-13) have: (ak1 ) = true, therefore formula (-14) satisfied.
(-15) Exactly case (-11).
(-16) Exactly case (-12).
(-17) Exactly case (-13).
(-18) Exactly case (-14).
614

fiITSAT: Efficient SAT-Based Temporal Planner

(-19) Follows immediately fact satisfies formula (-12).
(-20) Follows immediately fact satisfies formula (-13).

Theorem 6 (soundness -step encoding). Let P = (I, G, A) temporal planning
problem, {e1 , ..., en } set events P, l -step encoding P.
l model , plan(M ) causally valid -step plan P.
Proof. obtain plan(M ) follows. k 1 k l, let Stepk
set events e (ek ) = true. Moreover, k
0 k l, let sk temporal state. Assume state(sk ) set propositions p
(pk ) = true agenda(sk ) set actions (ak ) = true.
construct = plan(M ) = hStep1 , ..., Stepl show causally valid -step
plan P state transition sequence hs0 , ..., sl i.
formula (-1), immediately follows = state(s0 ). Formula (-2) implies
G state(sl ). Formulae (-3) (-4) imply agenda(s0 ) agenda(sn )
empty sets. Now, need show k 1 k l,
Stepk = {e1 , ..., em } {e1 , ..., en } -step sk1 sk . Without loss generality,
assume sequence he1 , ..., em ordered fixed ordering he1 , ..., en i. Note
since satisfies formula (-10), Lemma 2, proposition p, Stepk cannot include
two events ei ej ei Rp , ej Ep , j < i. induction k , show
every k m, sequence he1 , ..., ek applicable sk1 . k = 0 (i.e.,
case event applied sk1 ), conclusion obviously holds. induction
hypothesis, let sk temporal state resulting applying sequence he1 , ..., ek
sk1 . Assume ek +1 starting event action (we omit similar case
ek +1 ending event a). show conditions (1) (3) Definition 4
hold thereby ek +1 applicable sk .
(1) formula (-5), clearly results preconditions ek +1 invariants
(except invariants added eO(k +1) ) members state(sk1 ).
stated before, neither propositions deleted ei < k . Thus,
propositions also members state(sk ).
(2) two possible cases. Consider first case, according fixed
ordering he1 , ..., en i, ending event located ek +1 . Formula (-11) implies
cannot member agenda(sk1 ). Notice according Definition 5,
starting event a, i.e., ek +1 , event add agenda
state. Therefore, cannot member agenda(sk ). case,
ending event located ek +1 , formula (-15) implies either
member agenda(sk1 ), end(a) member Stepk . However, end(a)
member Stepk , certainly remove agenda resulting state. Since
ek +1 event add agenda state, conclude
cannot member agenda(sk ). Therefore, neither two cases,
member agenda(sk ).
615

fiRankooh & Ghassem-Sani

(3) Let action p del(ek +1 ) invariant. Since p deleted step k,
satisfies chain(e1 , ..., en ; Ep ; Rp {en+1 }; k; mp1 ), according Lemma 2,
(bn+1,np1 ) = true. Therefore, formula (-10),
/ agenda(sk ).
hand, clearly end(a ) Rp , thus, argued before, end(a )
member Stepk , cannot located ek +1 fixed ordering he1 , ..., en i.
Hence, member agenda(sk ), cannot member agenda(sk ),
either. Therefore, infer
/ agenda(sk ).
show sm , result applying he1 , ..., em sk1 , equal sk .
argument given proof Theorem 4, state(sm ) state(sk )
state(sk ) state(sm ), hence, state(sm ) = state(sk ).
Let arbitrary member agenda(sm ). Let ei ej starting ending
events a, respectively. three possible cases. Consider first case
agenda(sk1 ), ei
/ Stepk , ej
/ Stepk (i.e., open immediately step
k neither started ended step k). case, since satisfies (-20),
(ak ) = true, therefore, agenda(sk ). Consider second case
agenda(sk1 ), ei Stepk , ej Stepk , j < (i.e., open immediately
step k, first ended started step k). case, since
satisfies formula (-16), (ak ) = true, therefore, agenda(sk ).
Finally, consider third case
/ agenda(sk1 ), ei Stepk , ej
/ Stepk
(i.e., open immediately step k, started ended
step k). case, j < i, must satisfy formula (-16)
(ak ) = true. hand, < j, must satisfy formula (-12) and,
since (ekj ) = f alse, must (ak ) = true, therefore, agenda(sk ).
Consequently, three cases, must member agenda(sk ); hence
agenda(sm ) agenda(sk ).
Let arbitrary member agenda(sk ), i.e., (ak ) = true. two
possible cases. Case 1) member agenda(sk1 ), hence (ak1 ) =
f alse. formula (-19), have: (eki ) = true. means started
step k. Now, j < i, ending event cannot happen starting event,
therefore, must remain open execution step k, i.e., agenda(sm ).
hand, < j, formula (-14) have: (ekj ) = f alse.
means started ended step k, therefore must remain open
execution step k, i.e., agenda(sm ). consider case 2)
member agenda(sk1 ), hence (ak1 ) = true. < j, formula (-11)
(eki ) = f alse, formula (-13) (ekj ) = f alse. means
open immediately execution step k, neither started
ended step k. Therefore, must also open execution step k, i.e.,
agenda(sm ). hand, j < i, since (ak ) (ak1 )
false, formulae (-15) (-17) combined form formula (eki ekj ).
means ended step k later started
step. Therefore, must open execution step k,
agenda(sm ). Therefore, agenda(sk ) agenda(sm ).
616

fiITSAT: Efficient SAT-Based Temporal Planner

arguments show state(sk ) = state(sm ) agenda(sk ) = agenda(sm ). Hence,
sk = sm = succ(sk1 , he1 , ..., em i). Therefore, ordering functions : {1, ..., m}
{1, ..., m}, O(i) = i, sk = succ(sk1 , heO(1) , ..., eO(m) i), thus Stepk
-step sk1 sk .
Lemma 3. Let model chain (e1 , ..., en ; Ep+ ; Ep ; Rp ; k; mp ), ej member
Rp , EpM = {e|e Ep+ Ep , (ek ) = true}. following properties:
exists event ei ei EpM < j, (bkj,mp ) = (pk1 ).
exists event ei ei Ep+ , < j, {ei+1 , ..., ej1 } EpM = ,
(eki ) = true, (bkj,mp ) = true.
exists event ei ei Ep , < j, {ei+1 , ..., ej1 } EpM = ,
(eki ) = true, (bkj,mp ) = f alse.
Proof.
Assume exists event ei ei EpM < j. Consider
case (pk1 ) = true. Let {ei0 , ..., eim } set events ei
ei Rp Ep+ Ep , 0 j. Without loss generality,
assume 0 = i0 < i1 < ... < im = j. Since must satisfy (C -7), know
(bki ,m ) = true. Assume arbitrary s, (bkis ,mp ) = true. eis Ep+ Ep ,
0

p

know (ekis ) = f alse, (C -4) (bki


s+1 ,mp

hand, eis

Rp Ep+ Ep ,



(C -3),



(bki ,m )
p
s+1

) = true.

= true. infer

1 j, (bkis ,mp ) = true, thereby (bkj,mp ) = (pk1 ).
proof case (pk1 ) = f alse analogous, except
instead (C -4), need use (C -5) .
Assume exists event ei ei Ep+ , < j, {ei+1 , ..., ej1 }
EpM = , (eki ) = true. Let {ei0 , ..., eim } set events ei
ei Rp Ep+ Ep , j. Without loss generality, assume =
i0 < i1 < ... < im = j. Since must satisfy (C -1), know (bki ,m ) = true.
1

p

Assume arbitrary 1, (bkis ,mp ) = true. eis Ep+ Ep ,
know (ekis ) = f alse, (C -4), (bki
hand, eis Rp

Ep+



) = true.
s+1 ,mp
k

(bi ,m ) = true. infer
p
s+1
k
(bis ,mp ) = true, thereby (bkj,mp ) = true.

Ep ,

1 j,

(C -3),

Assume exists event ei ei Ep , < j, {ei+1 , ..., ej1 }
EpM = , (eki ) = true. Let {ei0 , ..., eim } set events ei
ei Rp Ep+ Ep , j. Without loss generality, assume =
617

fiRankooh & Ghassem-Sani

i0 < i1 < ... < im = j. Since must satisfy (C -1), know (bki ,m ) = f alse.
1

p

Assume arbitrary 1, (bkis ,mp ) = f alse. eis Ep+ Ep ,
know (ekis ) = f alse, (C -5), (bki
hand, eis Rp

Ep+



) = f alse.
s+1 ,mp
k

(bi ,m ) = f alse. infer
p
s+1
k
(bis ,mp ) = f alse, thereby (bkj,mp ) = f alse.

Ep ,

1 j,

(C -3),


Lemma 4. Let model chain(e1 , ..., en+1 ; Ep ; Rp ; k; mof
p ). Assume ei Ep ,
(eki ) = true, p inv(a). Let ej ej+1 starting event ending event
a, respectively. following properties:

(ekj+1 ) = true, < j, (ekj ) = true.
(ak ) = true, (ekj ) = true.
Proof. Let {ei1 , ..., eim } equal set {es |es Op , < n + 1}. Without loss
generality, assume i1 < i2 < ... < im = n + 1. Since (eki ) = true,
(Cof -1), infer (bi1 ,mof ) = true. s, (bis ,mof ) = true,
p

p

(Cof -2), deduce (bis+1 ,mof ) = true. Therefore, (bn+1,mof ) = true.
p
p
Furthermore, < j, ej+1 {ei1 , ..., eim }, thus (bj+1,mof ) = true. Besides,
p

(ekj+1 ) = true, (Cof -3), (ekj ) = true. hand, (ak ) =
true, infer formula (Cof -4) (ekj ) = true.

Lemma 5. Let model chain(e0 , ..., en ; Ep ; Rp ; k; mob
p ). Assume ei Ep ,
(eki ) = true, p inv(a). Let ej ej+1 starting event ending event
a, respectively. following properties:

(ekj ) = true, j + 1 < i, (ekj+1 ) = true.
(ak1 ) = true, (ekj+1 ) = true.
Proof. proof analogous Lemma 4, thus omitted.
Theorem 7 (completeness relaxed -step encoding). Let P = (I, G, A)

temporal planning problem formulae l l two -step encodings

P explained Section 4. model l , l model
plan(M ) = plan(M ).
Proof. Let model l . construct function assign value true

f alse binary variable l , using following rules:
(R-1) 1 n 1 k l, (eki ) = (eki ).
618

fiITSAT: Efficient SAT-Based Temporal Planner

(R-2) 1 k l, (ek0 ) = (ekn+1 ) = f alse.
(R-3) 0 k l proposition p, (pk ) = (pk ).
(R-4) 0 k l action a, (ak ) = (ak ).
(R-5) 0 n + 1, 1 k l, proposition p, exist j <
(ekj ) = true ej Ep+ Ep (bki,mp ) = (pk ); otherwise, (bki,mp ) =
(pk1 ).
(R-6) 1 n + 1, 1 k l, proposition p, exist j <
(ekj ) = true ej Ep (bk ) = true; otherwise, (bk ) = f alse.
i,mp

i,mp

(R-7) 0 n, 1 k l, proposition p, exist j >
(ekj ) = true ej Ep (bki,mob ) = true; otherwise, (bki,mob ) = f alse.
p

p

show satisfies formulae ( -1) ( -13), therefore model

l . rules, clear plan(M ) = plan(M ).
( -1) Formula ( -1) exactly (-1). Besides, assign
value variable formula.
( -2) Formula ( -2) exactly (-2). Besides, assign
value variable formula.
( -3) Formula ( -3) exactly (-3). Besides, assign
value variable formula.
( -4) Formula ( -4) exactly (-4). Besides, assign
value variable formula.
( -5) Formula ( -4) conjunction formulae (C -1) (C -8). show
satisfies formulae (C -1) (C -8), thereby, satisfies ( -5).
Consider arbitrary formula eki bkj,mp (C -1). (eki ) = f alse,
formula trivially satisfied. (eki ) = true, (R-5),
(bki,mp ) = (pk ). hand, satisfies (-6),
(pk ) = true. Therefore, (bki,mp ) = true, formula satisfied again.
Consider arbitrary formula eki bkj,mp (C -2). (eki ) = f alse,
formula trivially satisfied. (eki ) = true, (R-5),
(bki,mp ) = (pk ). hand, satisfies (-7),
(pk ) = f alse. Therefore, (bki,mp ) = f alse, formula satisfied
again.
Consider arbitrary formula bki,mp bkj,mp (C -3). Since ei
member Ep+ Ep , none events located ei ej
fixed ordering members Ep+ Ep , (R-5), easily show
(bki,mp ) = (bkj,mp ). Thus, formula satisfied.
619

fiRankooh & Ghassem-Sani

Consider arbitrary formula bki,mp eki bkj,mp (C -4). (eki ) =
true, formula trivially satisfied. (eki ) = f alse, since none
events located ei ej fixed ordering members
Ep+ Ep , (R-5), easily show (bki,mp ) = (bkj,mp ). Thus,
formula satisfied.
Consider arbitrary formula bki,mp eki bkj,mp (C -5).
argument one given (C -4), infer (bki,mp ) = (bkj,mp ).
Thus, formula satisfied.
Consider arbitrary formula bki,mp eki (C -6). (bki,mp ) = true,
formula trivially satisfied. (bki,mp ) = f alse, exist two
possible cases. Case 1: exists event ej j < i, (ekj ) = true,
ej Ep+ Ep . case, (R-5), (pk ) = (bki,mp ) = f alse.
Since must also satisfy (-6), ej
/ Ep+ , thus ej Ep . Besides,
must satisfy (-10), implies (eki ) = f alse. (R-1),
(eki ) = (eki ) = f alse, therefore, formula satisfied. Case 2:
exist event ej j < i, (ekj ) = true, ej Ep+ Ep .
case, (R-5), (pk1 ) = (bki,mp ) = f alse. Now, since
must satisfy (-5), infer (eki ) = f alse. (R-1),
(eki ) = (eki ) = f alse, therefore, formula satisfied again.
Consider formula bk0,mp pk1 (C -6). (R-5), easily deducted (bk0,mp ) always equal (pk1 ). (R-3),
(pk1 ) = (pk1 ). result, (bk0,mp ) = (pk1 ), formula
satisfied.
Consider formula bkn+1,mp pk (C -6). two possible cases.
Case 1: exists event e (ek ) = true, e Ep+ Ep .
case, (R-5), (bn+1,mp ) = (pk ). Now, (R-5),
(pk ) = (pk ). Therefore, (bn+1,mp ) = (pk ), formula
satisfied. Case 2: exist event e (ek ) = true
e Ep+ Ep . case, (R-5), (bn+1,mp ) = (pk1 ). Besides,
since satisfies formulae (-8) right hand side (-8) becomes f alse,
left hand side (-8), i.e., pk1 pk , f alse, too. Thus,
(pk1 ) = f alse, (pk ) = f alse. similar argument
(-9) show (pk1 ) = true, (pk ) = true. Thus,
(pk1 ) = (pk ), (R-3), (pk ) = (pk1 ). Therefore,
(bn+1,mp ) = (pk1 ) = (pk ), formula satisfied again.
( -6) show satisfies formulae (Cof -1) (Cof -4), thereby, satisfies
( -6).
Consider arbitrary formula eki bk

j,mof
p

(Cof -1). know (Cof -

1) < j. (eki ) = f alse, formula trivially satisfied. (eki ) =
true, (R-6), (bj,mof ) = true, formula satisfied.
p

620

fiITSAT: Efficient SAT-Based Temporal Planner

Consider arbitrary formula bk

i,mof
p

(Cof -2). (bk

bk

j,mof
p

i,mof
p

= f alse, formula trivially satisfied. (bk

i,mof
p

)

) = true, rule



(R-6), must exist event ei ,
< i, (eki ) = true,
ei Ep . Since < j, must also < j. Now, (R-6),
(bj,mof ) = true, formula satisfied.
p

Consider arbitrary formula bk

j,mof
p

ekj eki (Cof -3). (bk

j,mof
p

f alse, formula trivially satisfied. (bk

j,mof
p

)=

) = true, (R-6),

must exist event ej j < j, (ekj ) = true, ej Ep . Now,
since satisfies (-10), infer (ekj ) = f alse. (R-1),
(ekj ) = (ekj ) = f alse, therefore, formula satisfied.
Consider arbitrary formula bk

n+1,mof
p

ak eki (Cof -4). (bk

n+1,mof
p

= f alse, formula trivially satisfied. (bk

)

) = true, (R-6),

n+1,mof
p
k
event ej (ej ) = true ej Ep . Now,
(-10), infer (ak ) = f alse. (R-4),

must exist
since satisfies
(ak ) = (ak ) = f alse, therefore, formula satisfied.

( -7) show satisfies formulae (Cob -1) (Cof -4), thereby, satisfies
( -7).
Consider arbitrary formula eki bkj,mob (Cob -1). know (Cob -1)
p

j < i. (eki ) = f alse, formula trivially satisfied. (eki ) =
true, (R-7), (bj,mob
) = true, formula satisfied.
p
Consider arbitrary formula bki,mob bkj,mob (Cob -2). (bki,mob ) =
p

p

p

f alse, formula trivially satisfied. (bki,mob ) = true, rule (R-7),
p

must exist event ei < , (eki ) = true, ei Ep .
Since j < i, must also j < . Now, (R-7),
) = true, formula satisfied.
(bj,mob
p
Consider arbitrary formula bki,mob eki ekj (Cob -3). (bki,mob ) =
p

p

f alse (eki ) = f alse, formula trivially satisfied. (bki,mob ) = true
p

(eki ) = true, (R-7), must exist event ei , < ,
(eki ) = true, ei Ep . Since satisfies (-10), infer
(ak ) = f alse. However, know = j 1 < j; thus must satisfy (12). Therefore, (ekj ) = true. (R-1), (ekj ) = (ekj ) =
true, therefore, formula satisfied.
Consider arbitrary formula bk0,mob ak1 ekj (Cob -4). (bk0,mob ) =
p

p

f alse (ak1 ) = f alse, formula trivially satisfied. (bk0,mob ) =
p

true (ak1 ) = true, (R-7), must exist event ei
(eki ) = true, ei Ep . Since satisfies (-10), infer
(ak ) = f alse. However, must satisfy (-20). Therefore, (ekj ) =
621

fiRankooh & Ghassem-Sani

true. (R-1), (ekj ) = (ekj ) = true, therefore, formula
satisfied.
( -8) Consider arbitrary formula eki ak1 ( -8). Let ej ending event
a. know = j 1 < j. Therefore, must satisfy (-11). ( -8)
exactly (-11). Besides, assign value
variable formulae. Thus, ( -8) satisfied .
( -9) Consider arbitrary formula eki ak ekj ( -9). know = j 1 < j.
Therefore, must satisfy formula (-12). ( -9) exactly (-12).
Besides, assign value variable formulae. Thus,
( -9) satisfied .
( -10) Consider arbitrary formula ekj ak ( -10). Let ei starting event
a. know = j 1 < j. Therefore, must satisfy (-13). ( -10)
exactly (-13). Besides, assign value
variable formulae. Thus,( -10) satisfied .
( -11) Consider arbitrary formula ekj ak1 eki ( -11). know =
j 1 < j. Therefore, must satisfy (-14). ( -11) exactly (-14).
Besides, assign value variable formulae. Thus,
( -11) satisfied .
( -12) ( -12) exactly (-19). Besides, assign value
variable formulae. Thus, ( -12) satisfied .
( -13) ( -13) exactly (-20). Besides, assign value
variable formulae. Thus, ( -13) satisfied .

Theorem 8 (soundness relaxed -step encoding). Let P = (I, G, A)

temporal planning problem, {e1 , ..., en } set events P, l relaxed

-step encoding P. l model , plan(M ) causally valid -step plan
P.
Proof. obtain plan(M ) follows. k 1 k l, let Stepk
set events e (ek ) = true. k 0 k l,
let sk temporal state. Assume state(sk ) set propositions p
(pk ) = true, agenda(sk ) set actions (ak ) = true.
construct = plan(M ) = hStep1 , ..., Stepl show causally valid -step plan
P state transition sequence hs0 , ..., sl i.
( -1), immediately follows = state(s0 ). Also, ( -2) implies G
state(sl ). Besides, ( -3) ( -4) imply agenda(s0 ) agenda(sn ) empty sets,
respectively. need show k 1 k l, Stepk =
{ei1 , ..., eim } {e1 , ..., en } -step sk1 sk . Without loss generality,
622

fiITSAT: Efficient SAT-Based Temporal Planner

assume sequence hei1 , ..., eim ordered according fixed ordering he1 , ..., en i,
i.e., i1 < i2 < ... < im .
induction k , conclude k m, sequence hei1 , ..., eik
applicable sk1 . k = 0 (i.e., case, event applied sk1 ), conclusion obviously holds. Let sk temporal state resulting applying hei1 , ..., eik
sk1 . Assume eik +1 starting event action a. omit similar case
eik +1 ending event a. show conditions (1) (3) Definition 4
holds thereby eik +1 applicable sk .
(1) Assume p
/ state(sk ), p either precondition eik +1 invariant
added eik +1 . two possible cases. Case 1: p
member state(sk1 ), added deleted member {ei1 , ..., eik }.
case, (pk1 ) = f alse. Moreover, exists event ei
ei Ep+ Ep , < k + 1, (eki ) = true. Case 2: p deleted event
ei Stepk added deleted event ej Stepk , < j k .
case, ei Ep , < ik +1 , {ei+1 , ..., eik +1 } EpM = , (eki ) = true,
EpM = {e|e Ep+ Ep , (ek ) = true}. cases, Lemma 3,
(bkik +1 ,mp ) = f alse, contradicts fact satisfies (C -6).
(2) Since satisfies ( -8), member agenda(sk1 ). However, eik +1
event Stepk add agenda state. Thus, member
agenda(sk ).
(3) Let b action a, invariant p del(eik +1 ). Let ej ej+1
starting ending events b, respectively. mentioned earlier, assume
ending event action located immediately starting event
fixed ordering. show b cannot member agenda(sk ).
two possible cases b may member agenda(sk ). Case 1: b open
action immediately execution Stepk ; b ended Stepk
eik +1 executed. case, (bk1 ) = true, (ekik +1 ) = true. Since
satisfies ( -7), Lemma 5, (ekj+1 ) = true. assumed b
ended execution eik +1 , ik +1 < j + 1. hand,
since ej starting event b, ik +1 6= j, thus, ik +1 < j. Therefore,
Lemma 4, (ekj ) = true. contradicts fact satisfies ( -8),
(bk1 ) = true, (ekj ) = true, ej = start(b). Case 2: b
started step k, ended step k execution eik +1 .
case, (ekj ) = true, (ekj+1 ) = f alse, j + 1 < ik +1 , (ekik +1 ) = true.
Since satisfies ( -7), Lemma 5, must (ekj+1 ) = true,
contradiction.
show sm , result applying hei1 , ..., eim sk1 , equal sk .
Let p arbitrary proposition. p state(sm ), two possible cases.
Case 1: p member state(sk1 ), added deleted member
{ei1 , ..., eim }. case, (pk1 ) = true. Moreover, exists event ei
ei Ep+ Ep , < n + 1, (eki ) = true. Case 2: p added event
623

fiRankooh & Ghassem-Sani

ei Stepk added deleted event ej Stepk , < n + 1.
case, ei Ep+ , < n + 1, {ei+1 , ..., en } EpM = , (eki ) = true,
EpM = {e|e Ep+ Ep , (ek ) = true}. cases, Lemma 3,
(bkn+1,mp ) = true. Since satisfies (C -8), (pk ) = true, thus
p state(sk ). Therefore, state(sm ) state(sk ).
Let p arbitrary proposition. p
/ state(sm ), two possible cases. Case
1: p member state(sk1 ), added deleted member
{ei1 , ..., eim }. case, (pk1 ) = f alse. Moreover, exists event
ei ei Ep+ Ep , < n + 1, (eki ) = true. Case 2: p deleted
event ei Stepk added deleted event ej Stepk ,
< j < n + 1. case, ei Ep , < n + 1, {ei+1 , ..., en } EpM = ,
(eki ) = true, EpM = {e|e Ep+ Ep , (ek ) = true}. cases, Lemma
3, (bkn+1,mp ) = f alse. Since satisfies (C -8), (pk ) = f alse,
thus p
/ state(sk ). Therefore, state(sk ) state(sm ).
Let arbitrary action, ei ej starting event ending event,
respectively. agenda(sm ), since assume ending event action
located immediately starting event fixed ordering, two
possible cases. Case 1: open immediately step k, ended
step k. case, (ak1 ) = true (ekj ) = f alse. Since satisfies
( -13), must (ak ) = true. Therefore, agenda(sk ). Case 2: started
ended step k. case, (eki ) = true (ekj ) = f alse.
satisfies ( -9), must (ak ) = true. Therefore, agenda(sk ). Since
cases, agenda(sk ), infer agenda(sm ) agenda(sk ).
Let arbitrary action, ei ej starting event ending event a,
respectively.
/ agenda(sm ), since assume ending event action
located immediately starting event fixed ordering, two
possible cases. Case 1: open immediately execution step k,
started step k. case, (ak1 ) = f alse (eki ) = f alse.
Since satisfies ( -12), must (ak ) = f alse. Therefore,
/ agenda(sk ).
k
Case 2: ended step k. case, (ej ) = true. Since satisfies
( -10), must (ak ) = f alse. Therefore,
/ agenda(sk ).
cases,
/ agenda(sk ), infer agenda(sk ) agenda(sm ).
arguments show state(sk ) = state(sm ) agenda(sk ) = agenda(sm ).
Hence, sk = sm sk = succ(sk1 , hei1 , ..., eim i). Therefore, ordering functions : {1, ..., m} {1, ..., m}, O(i) = i, sk = succ(sk1 , heO(i1 ) , ..., eO(im ) i),
thus Stepk -step sk1 sk .

Theorem 9. Let P = (I, G, A) temporal planning problem, = he1 , ..., en
causally valid plan P, : {1, ..., n} Q relaxed scheduling function .
exists valid temporal plan P.
624

fiITSAT: Efficient SAT-Based Temporal Planner

Proof. using bubble sort algorithm, sort events increasing order
according values given . algorithm takes two consecutive members
sequence, swaps value first one greater
second one. continues swaps whole sequence properly sorted. Let ei
ej two events swapped bubble sort stage algorithm (assume
ei located ej sequence prior swapping). Then, must (i) > (j).
Thus, according (S-1), know ei ej swappable (c.f., Definition 12).
result, whole sequence causally valid plan prior swapping, would also
causally valid plan swapping. means sorting according values
given result another causally valid plan, say . plan obviously satisfies
two conditions Definition 9, therefore, ( , ) valid temporal plan P.

Theorem 10. Let P = (I, G, A) solvable temporal planning problem, COM
set every member either compressible towards start compressible
towards end (Definition 13). exists valid temporal plan (, ) P
causally valid plan P, compressed respect COM, relaxed
scheduling function .
Proof. Let 1 = e1 , ..., ei , ei+1 , ..., en causally valid plan P ei ei+1
two swappable events. Let 2 = e1 , ..., ei+1 , ei , ..., en result swapping ei ei+1
1 . show relaxed scheduling function 1 , also relaxed
scheduling function 2 .
Consider two events ej ek 2 , ej located ek . j 6= + 1
k 6= i, 1 , ej definitely located ek , too, therefore property
(S-1) holds ej ek . hand, j = + 1 k = i, ej ek
swappable therefore property (S-1) trivially holds ej ek .
Assume ej starting event particular action a, ek pairing
event ej 2 . Definition 8, easily infer 2 , ei located
ej ek , ei cannot starting ending event a. Similarly,
ei+1 located ej ek , ei+1 cannot starting ending event
a. hand, since ei ei+1 swappable, know cannot
events action, therefore, either j 6= + 1 k 6= i. Thus,
swapping ei ei+1 cannot falsify fact ej ek pairing events.
words, 1 , too, ek pairing event ej . implies property (S-2)
holds ej ek .
Let ( , ) arbitrary valid temporal plan P. Since scheduling function
, obviously also regarded relaxed scheduling function . showed
Section 3.2, transformed causally valid plan compressed
respect COM, series swaps, swapping occurs pair
consecutive swappable events. Therefore, must also relaxed scheduling function
, (, ) valid temporal plan P, scheduling function
.
625

fiRankooh & Ghassem-Sani

P
Theorem 11. Let P = (I, G, A) temporal planning problem,
= {e1 , ..., en }




set events P, l three formulae l , l , l (defined Section
P 4),
non-empty causally valid plan P obtained solving l . Let = (S , , , x0 , )
FSM accepts subsequence = he1 , ..., em ,
l encoding
presented (-1) (-6). exist model l
l
= plan(M ).
Proof. give proof contradiction. Assume exists model l
l
= plan(M ). Let f : {1, ..., m} {1,P
..., n} function i,
f (i) equal index i-th event . Moreover, let g : {1, ..., m} {1, ..., l}
function i, g(i) equal step number SAT variable
l corresponds i-th event . Assume x0 , ..., xm sequence states
0 < m, xi = (xi1 , ef (i) ). Since accepts , must
f (1),g(1)

xm . satisfies (-5), (x0
) = true. Here, two cases
considered. case 1: g(2) = g(1). case, since = plan(M ), f (1) < j < f (2),
g(1)
must (ej ) = f alse. Now, considering ( 1) ( 2), infer
g(2),f (2)

(x1
) = true. Case 2: g(2) > g(1). case, considering ( 1) ( 2),
g(1),n+1
infer (x1
) = true. by, considering ( 4), deduce
g(1)+1,0
(x1
) = true. argument plus considering ( 3) show
g(2),f (2)
g(i),f (i)
(x1
) = true. whole deduction repeated show (xi1
) = true
g(m),f (m)

1 m. Therefore, (xm1
) = true. Since xm = (xm1 , ef (m) ),
E {e
considering ( 1), infer j, ej Em
n+1 }

g(m),j


) = true. However, since xm ,
{ef (m)+1 , ..., ej1 } (Em Em ) = , (xm
contradicts assumption satisfies ( 6).
P
Theorem 12. Let P = (I, G, A) temporal planning problem,
= {e1 , ..., en }



set events P, l three formulae l , l , l (defined
Section 4). Let model satisfies l , = he1 , ..., em = plan(M ). Let
P
= (S , , , x0 , ) FSM accept subsequence ,
l


encoding composed (-1) (-6). exists model l l
= plan(M ).
Proof. Let us introduce total order relation SAT variables l correspond


events input problem. two sat variables eki eki , eki eki
one following two conditions holds: 1) k < k . 2) k = k < .
Assume f : {1, ..., m} {1, ...,Pn} function i, f (i) equal
index i-th event . Moreover, assume g : {1, ..., m} {1, ..., l}
function k, g(k) equal step number SAT variable l
corresponds k-th event . Let uk,i = heu , ..., et denote subsequence
following properties:
g(t)

(ef (t) ) = true.
626

fiITSAT: Efficient SAT-Based Temporal Planner

g(t)





k ef (t) eki eki , (eki ) = f alse.
fact, uk,i substring spans u-th event last event
whose corresponding SAT variable located eki l . define model
l
l following rules:
(R-1) SAT variable v l , (v) = (v).
(R-2) 1 k l 1 n, (xk,i
0 ) = true.
(R-3) 1 k l, 1 < n, xs , (xk,i
) = true iff j, sequence
jk,i transforms x0 xs .
(R-1), infer satisfies l . show also satisfies
formulae (-1) (-6), thereby, satisfies
l .
xk,j
arbitrary formula (-1). (eki ) = f alse
(-1) Let eki xk,i


k,i
k
(xk,i
) = f alse, formula trivially satisfied. Assume (ei ) = (xs ) =
k,i
true. (R-3), u, sequence u transforms x0 xs . Since
eki ekj , way defined uk,j , deduce uk,j = uk,i hei , ()
denotes concatenation operator sequence events {ei+1 , ..., ej1 }.
(-1), (xs , ei ) = xt , therefore ei causes transit xs
xt . Besides, {ei+1 , ..., ej1 } Etout = , thus, member cause
transit state xt . Therefore, uk,j transforms x0 xt ,
(xk,j
) = true. Hence, formula satisfied.
k,j
arbitrary formula (-2). (eki ) = true
(-2) Let eki xk,i
xs
k
(xk,i
) = f alse, formula trivially satisfied. Assume (ei ) = f alse
k,i
(xk,i
) = true. (R-3), u, sequence u transforms x0 xs .
k,j
Since eki ekj , way defined u , deduce uk,j = uk,i ,
sequence events {ei+1 , ..., ej1 }. Besides, {ei+1 , ..., ej1 } Esout = ,
thus, member cause transit state xs . Therefore,
uk,j transforms x0 xs , (xk,j
) = true. Hence, formula satisfied.
k,i
k,0
(-3) Let xk,0
xs arbitrary formula (-3). (xs ) = f alse, formula
trivially satisfied. Assume (xk,0
) = true. (R-3), u,
k,0
sequence u transforms x0 xs . Since ek0 eki , way defined uk,i ,
deduce uk,i = uk,0 , sequence events {e1 , ..., ei1 }.
Besides, {e1 , ..., ei1 }Esout = , thus, member cause transit
state xs . Therefore, uk,i transforms x0 xs , (xk,i
) = true.
Hence, formula satisfied.

(-4) Let xk,n+1
xk+1,0
arbitrary formula (-4). way defined


k+1,0
) =
, deduce uk,n+1 = uk+1,0 every u. Therefore, (xk,n+1
u

k+1,0

(xs
). Hence, formula satisfied.
(-5) According (R-2), formula (-5) directly satisfied , .
627

fiRankooh & Ghassem-Sani

(-6) Let xk,i arbitrary formula (-6). Accorrding assumptions, uk,i
cannot cause transit accepting states. Since x , (R-3)
implies (xk,i ) = f alse. Hence, formula satisfied.

Theorem 13. Let N = xi1 , ..., xim negative cycle STN corresponding
causally valid plan = e1 , ..., en temporal problem P, xik node corresponding event eik . Let another causally valid plan P. subsequence
member LN (defined Section 5), corresponding STN also N
negative cycle.
Proof. Let ei1 , e2,1 ..., e2,k2 , ei2 , ..., eim1 , em,1 , ..., em,km , eim subsequence ,
ej,1 , ..., ej,kj string symbols j , 1 < j m. Consider two arbitraty events
eij eij sequence, ij < ij . show temporal constraints
(eij ) (eij ) also present (ij ) (ij ).
constraint (ij ) < (ij ), scheduling constraint (S-1)
explained Section 5, eij eij swappable. Besides, , eij clearly
located eij . Consequently, must (ij ) < (ij ) according
scheduling constraint (S-1).
constraint (ij ) (ij ) = dur(a), scheduling rule (S-2), eij
eij starting event ending event a, respectively. Moreover,
j < j < j , action(eij ) 6= a. indicates j < j j ,
Oj , therefore eij
/ j . Since ej ,1 ..., ej ,k string symbols j ,
j
conclude , yet ended reaching eij . means eij
eij pairing events . Thus, scheduling constraint (S-2),
(ij ) (ij ) = dur(a).
shows edge xij xij corresponding STN also present
corresponding STN , thus latter STN N negative cycle.

References
Allen, J. F. (1984). Towards general theory action time. Artif. Intell., 23 (2),
123154.
Armando, A., & Giunchiglia, E. (1993). Embedding complex decision procedures inside
interactive theorem prover. Ann. Math. Artif. Intell., 8 (3-4), 475502.
Benton, J., Coles, A. J., & Coles, A. (2012). Temporal planning preferences
time-dependent continuous costs. Proceedings Twenty-Second International
Conference Automated Planning Scheduling, ICAPS 2012, Atibaia, Sao Paulo,
Brazil, June 25-19, 2012.
Biere, A. (2009). P{re,i}cosat@sc09. solver description SAT competition 2009. SAT
2009 Competitive Event Booklet.
628

fiITSAT: Efficient SAT-Based Temporal Planner

Biere, A. (2013). Lingeling, Plingeling Treengeling entering sat competition 2013.
Proceedings SAT Competition 2013.
Blum, A., & Furst, M. L. (1997). Fast planning planning graph analysis. Artif.
Intell., 90 (1-2), 281300.
Castellini, C., Giunchiglia, E., & Tacchella, A. (2003). SAT-based planning complex
domains: Concurrency, constraints nondeterminism. Artif. Intell., 147 (1-2), 85
117.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2009). Extending use inference
temporal planning forwards search. Proceedings 19th International Conference Automated Planning Scheduling, ICAPS 2009, Thessaloniki, Greece,
September 19-23, 2009.
Coles, A. J., Coles, A., Fox, M., & Long, D. (2010). Forward-chaining partial-order planning. Proceedings 20th International Conference Automated Planning
Scheduling, ICAPS 2010, Toronto, Ontario, Canada, May 12-16, 2010, pp. 4249.
Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009). Introduction Algorithms
(3. ed.). MIT Press.
Cushing, W., Kambhampati, S., Mausam, & Weld, D. S. (2007). temporal planning
really temporal?. IJCAI 2007, Proceedings 20th International Joint Conference Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 18521859.
Dechter, R., Meiri, I., & Pearl, J. (1991). Temporal constraint networks. Artif. Intell.,
49 (1-3), 6195.
Do, M. B., & Kambhampati, S. (2003). Sapa: multi-objective metric temporal planner.
J. Artif. Intell. Res. (JAIR), 20, 155194.
Een, N., & Biere, A. (2005). Effective preprocessing SAT variable clause
elimination. Theory Applications Satisfiability Testing, 8th International
Conference, SAT 2005, St. Andrews, UK, June 19-23, 2005, Proceedings, pp. 6175.
Ernst, M. D., Millstein, T. D., & Weld, D. S. (1997). Automatic sat-compilation planning
problems. Proceedings Fifteenth International Joint Conference Artificial
Intelligence, IJCAI 97, Nagoya, Japan, August 23-29, 1997, 2 Volumes, pp. 1169
1177.
Eyerich, P., Mattmuller, R., & Roger, G. (2009). Using context-enhanced additive
heuristic temporal numeric planning. Proceedings 19th International Conference Automated Planning Scheduling, ICAPS 2009, Thessaloniki,
Greece, September 19-23, 2009.
Fox, M., & Long, D. (2002). PDDL+: Modelling continuous time-dependent effects.
Third International NASA Workshop Planning Scheduling Space.
Fox, M., & Long, D. (2003). PDDL2.1: extension PDDL expressing temporal
planning domains. J. Artif. Intell. Res. (JAIR), 20, 61124.
Fox, M., & Long, D. (2007). note concurrency complexity temporal planning.
26th Workshop UK Planning Scheduling Special Interest Group.
629

fiRankooh & Ghassem-Sani

Garrido, A., Fox, M., & Long, D. (2002). temporal planning system durative actions
PDDL2.1. Proceedings 15th Eureopean Conference Artificial Intelligence,
ECAI2002, Lyon, France, July 2002, pp. 586590.
Gerevini, A., Saetti, A., & Serina, I. (2006). approach temporal planning scheduling domains predictable exogenous events. J. Artif. Intell. Res. (JAIR), 25,
187231.
Gerevini, A., & Schubert, L. K. (1998). Inferring state constraints domain-independent
planning. Proceedings Fifteenth National Conference Artificial Intelligence
Tenth Innovative Applications Artificial Intelligence Conference, AAAI 98,
IAAI 98, July 26-30, 1998, Madison, Wisconsin, USA., pp. 905912.
Halsey, K. (2004). CRIKEY! Co-ordination Temporal Planning. Ph.D. thesis, University Durham.
Halsey, K., Long, D., & Fox, M. (2004). Multiple relaxations temporal planning.
Proceedings 16th Eureopean Conference Artificial Intelligence, ECAI2004,
including Prestigious Applicants Intelligent Systems, PAIS 2004, Valencia, Spain,
August 22-27, 2004, pp. 10291030.
Haslum, P. (2006). Improving heuristics relaxed search - analysis TP4
HSP*a 2004 planning competition. J. Artif. Intell. Res. (JAIR), 25, 233267.
Haslum, P., & Geffner, H. (2000). Admissible heuristics optimal planning. Proceedings Fifth International Conference Artificial Intelligence Planning Systems,
Breckenridge, CO, USA, April 14-17, 2000, pp. 140149.
Helmert, M., & Geffner, H. (2008). Unifying causal graph additive heuristics.
Proceedings Eighteenth International Conference Automated Planning
Scheduling, ICAPS 2008, Sydney, Australia, September 14-18, 2008, pp. 140147.
Hoffmann, J., Gomes, C. P., Selman, B., & Kautz, H. A. (2007). SAT encodings statespace reachability problems numeric domains. IJCAI 2007, Proceedings
20th International Joint Conference Artificial Intelligence, Hyderabad, India, January 6-12, 2007, pp. 19181923.
Hoffmann, J., & Nebel, B. (2001). FF planning system: Fast plan generation
heuristic search. J. Artif. Intell. Res. (JAIR), 14, 253302.
Huang, R., Chen, Y., & Zhang, W. (2009). optimal temporally expressive planner:
Initial results application P2P network optimization. Proceedings
19th International Conference Automated Planning Scheduling, ICAPS 2009,
Thessaloniki, Greece, September 19-23, 2009.
Huang, R., Chen, Y., & Zhang, W. (2012). SAS+ planning satisfiability. J. Artif. Intell.
Res. (JAIR), 43, 293328.
Kautz, H. A., & Selman, B. (1992). Planning satisfiability. ECAI, pp. 359363.
Kautz, H. A., & Selman, B. (1996). Pushing envelope: Planning, propositional logic
stochastic search. Proceedings Thirteenth National Conference Artificial
Intelligence Eighth Innovative Applications Artificial Intelligence Conference,
AAAI 96, IAAI 96, Portland, Oregon, August 4-8, 1996, Volume 2., pp. 11941201.
630

fiITSAT: Efficient SAT-Based Temporal Planner

Long, D., & Fox, M. (2003). Exploiting graphplan framework temporal planning.
Proceedings Thirteenth International Conference Automated Planning
Scheduling (ICAPS 2003), June 9-13, 2003, Trento, Italy, pp. 5261.
Lu, Q., Huang, R., Chen, Y., Xu, Y., Zhang, W., & Chen, G. (2013). SAT-based approach
cost-sensitive temporally expressive planning. ACM TIST, 5 (1), 18.
Mali, A. D., & Liu, Y. (2006). T-satplan: SAT-based temporal planner. International
Journal Artificial Intelligence Tools, 15 (5), 779802.
Rankooh, M. F., & Ghassem-Sani, G. (2013). New encoding methods sat-based temporal
planning. Proceedings Twenty-Third International Conference Automated
Planning Scheduling, ICAPS 2013, Rome, Italy, June 10-14, 2013.
Rintanen, J. (2006). Compact representation sets binary constraints. ECAI 2006,
17th European Conference Artificial Intelligence, August 29 - September 1, 2006,
Riva del Garda, Italy, Including Prestigious Applications Intelligent Systems (PAIS
2006), Proceedings, pp. 143147.
Rintanen, J. (2007). Complexity concurrent temporal planning. Proceedings
Seventeenth International Conference Automated Planning Scheduling, ICAPS
2007, Providence, Rhode Island, USA, September 22-26, 2007, pp. 280287.
Rintanen, J. (2012). Planning satisfiability: Heuristics. Artif. Intell., 193, 4586.
Rintanen, J., & Gretton, C. O. (2013). Computing upper bounds lengths transition
sequences. IJCAI 2013, Proceedings 23rd International Joint Conference
Artificial Intelligence, Beijing, China, August 3-9, 2013.
Rintanen, J., Heljanko, K., & Niemela, I. (2006). Planning satisfiability: parallel plans
algorithms plan search. Artif. Intell., 170 (12-13), 10311080.
Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2009). Sat-based parallel planning
using split representation actions. Proceedings 19th International Conference Automated Planning Scheduling, ICAPS 2009, Thessaloniki, Greece,
September 19-23, 2009.
Robinson, N., Gretton, C., Pham, D. N., & Sattar, A. (2010). Partial weighted MaxSAT
optimal planning. PRICAI 2010: Trends Artificial Intelligence, 11th Pacific
Rim International Conference Artificial Intelligence, Daegu, Korea, August 30September 2, 2010. Proceedings, pp. 231243.
Shin, J.-A., & Davis, E. (2005). Processes continuous change SAT-based planner.
Artif. Intell., 166 (1-2), 194253.
Smith, D. E., & Weld, D. S. (1999). Temporal planning mutual exclusion reasoning.
Proceedings Sixteenth International Joint Conference Artificial Intelligence,
IJCAI 99, Stockholm, Sweden, July 31 - August 6, 1999. 2 Volumes, 1450 pages, pp.
326337.
Streeter, M. J., & Smith, S. F. (2007). Using decision procedures efficiently optimization.
Proceedings Seventeenth International Conference Automated Planning
Scheduling, ICAPS 2007, Providence, Rhode Island, USA, September 22-26, 2007,
pp. 312319.
631

fiRankooh & Ghassem-Sani

Vidal, V. (2014). Yahsp3 Yahsp3-mt 8th international planning competition.
International Planning Competition.
Vidal, V., & Geffner, H. (2006). Branching pruning: optimal temporal POCL
planner based constraint programming. Artif. Intell., 170 (3), 298335.
Wehrle, M., & Rintanen, J. (2007). Planning satisfiability relaxed -Step plans.
AI 2007: Advances Artificial Intelligence, 20th Australian Joint Conference
Artificial Intelligence, Gold Coast, Australia, December 2-6, 2007, Proceedings, pp.
244253.
Younes, H. L. S., & Simmons, R. G. (2003). VHPOP: Versatile heuristic partial order
planner. J. Artif. Intell. Res. (JAIR), 20, 405430.

632

fiJournal Artificial Intelligence Research 53 (2015) 315374

Submitted 09/14; published 07/15

Regular Path Queries Lightweight Description Logics:
Complexity Algorithms
Meghyn Bienvenu

meghyn@lri.fr

Laboratoire de Recherche en Informatique,
CNRS & Universite Paris-Sud, France

Magdalena Ortiz
Mantas Simkus

ortiz@kr.tuwien.ac.at
simkus@dbai.tuwien.ac.at

Institute Information Systems,
TU Wien, Austria

Abstract
Conjunctive regular path queries expressive extension well-known class
conjunctive queries. queries extensively studied (graph) database
community, since support controlled form recursion enable sophisticated path
navigation. Somewhat surprisingly, little work aimed using queries
context description logic (DL) knowledge bases, particularly lightweight
DLs considered best suited data-intensive applications. paper aims
bridge gap providing algorithms tight complexity bounds answering twoway conjunctive regular path queries DL knowledge bases formulated lightweight
DLs DL-Lite EL families. results demonstrate data complexity,
cost moving richer query language low one could wish for:
problem NL-complete DL-Lite P-complete EL. combined complexity
query answering increases NP- PSpace-complete, two-way regular path
queries (without conjunction), show query answering tractable even respect
combined complexity. results reveal two-way conjunctive regular path queries
promising language querying data enriched ontologies formulated DLs
DL-Lite EL families corresponding OWL 2 QL EL profiles.

1. Introduction
Recent years seen rapidly growing interest using description logic (DL) ontologies
query instance data. setting seen generalization related problem
querying graph databases which, like DL instance data, sets ground facts using
unary binary predicates, i.e., node- edge-labeled graphs (Consens & Mendelzon,
1990; Barcelo, Libkin, Lin, & Wood, 2012). relevance problems lies
fact many application areas, data naturally represented form.
applies, particular, XML RDF data. presence DL ontology,
domain knowledge expressed ontology exploited querying data,
facilitate query formulation provide users complete answers
queries. DL database communities share common research goals,
research agendas pursued differ significantly. DL research, focus
studying computational complexity answering (unions of) plain conjunctive
queries (CQs) presence ontological constraints expressed different DLs,
c
2015
AI Access Foundation. rights reserved.

fiBienvenu, Ortiz, & Simkus

development efficient algorithms setting, see surveys Ortiz (2013)
Ortiz Simkus (2012). contrast, work graph databases typically
consider ontological knowledge, instead aims supporting expressive navigational
query languages.
Regular path queries (RPQs) constitute basic navigational query language. Formally, RPQ given regular language (represented regular expression finite
automaton) binary predicates database facts (arc labels, roles DL parlance), returns pairs objects connected path whose label word
belonging specified language. crucial feature queries allow
controlled form recursion computationally well behaved yet sufficient expressing reachability queries traversal paths unbounded length (Florescu, Levy, &
Suciu, 1998). two-way RPQs (2RPQs), regular expressions may use arc labels
backwards direction, allows flexible path navigation. Notably, comes
computational cost: answering RPQs 2RPQs (plain) graph databases
complete NL combined complexity (that is, complexity measured
terms whole input, case consists query data). Conjunctive (two-way) regular path queries (C(2)RPQs), one expressive
popular languages querying graph databases, simultaneously extend plain CQs
(2)RPQs allowing conjunctions atoms share variables arbitrary ways,
atoms may contain regular expressions navigate arcs database.
consider data complexity measure (in complexity measured
terms size data, inputs considered fixed), answering
C2RPQs still NL-complete. combined complexity, C2RPQ answering problem
NP-complete, fact lowest complexity could expected, given
CQ answering already NP-hard. note navigational capabilities provided
RPQs extensions long considered crucial querying data Web.
Indeed, navigation along regular paths heart XPath language querying
XML data (Berglund, Boag, Chamberlin, Fernandez, Kay, Robie, & Simeon, 2007),
SPARQL 1.1, language recently recommended World Wide Web Consortium
(W3C) new standard querying RDF data (Harris & Seaborne, 2013), adds
previous standard feature called property paths, roughly amounts extending
core SPARQL CQs C2RPQs.
comes surprise that, despite advantages relevance, RPQs extensions received rather little attention DL literature. first considered
seminal work Calvanese, de Giacomo, Lenzerini (1998) query answering
presence DL ontologies. However, vast majority subsequent research
targeted instance queries (IQs), conjunctive queries unions thereof, occasionally
positive first-order queries. handful works considered C2RPQs. Calvanese et
al. (2014, 2007, 2009) showed C2RPQ answering 2ExpTime-complete combined
complexity expressive DLs1 ZIQ, ZIO, ZOQ, allow regular
expressions role constructors. upper bound shown containment
C2RPQs presence rich ontological knowledge (Calvanese et al., 2009).
noteworthy since well-known fact forms recursion make query answer1. Z symbol introduced abbreviation ALCbSelf
reg (Calvanese et al., 2009).

316

fiRegular Path Queries Lightweight Description Logics

ing query containment undecidable presence ontological constraints (Levy &
Rousset, 1996). Moreover, complexity higher significantly
restricted settings, answering plain CQs DL ALCI (Lutz, 2008) positive first-order queries ALC (Ortiz & Simkus, 2014). However, hardness 2ExpTime
nevertheless prohibitively high complexity many applications. Even data complexity, algorithms underlying aforementioned results still need exponential time.
recently, algorithms answering C2RPQs Horn-SHOIQ Horn-SROIQ
proposed (Ortiz, Rudolph, & Simkus, 2011). algorithms run polynomial time
size data, may still require exponential time size ontology,
worst-case optimal logics. contrast, lightweight DLs DL-Lite
(Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007) EL (Baader, Brandt, &
Lutz, 2005) families, languages choice ontology-mediated query answering notably underlie OWL 2 QL EL profiles (Motik, Cuenca Grau, Horrocks,
Wu, Fokoue, & Lutz, 2012), precise complexity answering C2RPQs left open:
ExpTime upper bound combined complexity expressive Horn DLs
match NP lower bound stemming answering plain CQs, apparent
obtain better upper bounds C2RPQs adapting existing techniques.
DL-Lite family, data complexity also left open, gap NL-hardness
RPQ answering inherited graph database setting P upper bound
established expressive Horn DLs.
paper, close open questions presenting algorithms precise complexity bounds answering (C)2RPQs EL DL-Lite families lightweight DLs.
Many results first announced conference version paper (Bienvenu,
Ortiz, & Simkus, 2013), provide full proofs results, additional examples, discussion extensions results applicability OWL 2
profiles. also strengthen complexity lower bounds considering restricted classes queries (Proposition 4.5) succinct representations (Theorem 4.2)
identify interesting restrictions lead better combined complexity C2RPQs
(Theorems 6.10 6.11). main contributions summarized follows:
establish P lower bound combined complexity answering 2RPQs
DL-Lite, well RPQs DL-LiteR , contrasted NLcompleteness instance checking logics. result improves upon similar
lower bound conference version paper adopting (less succinct)
regular expression representation queries.
present algorithm answering 2RPQs DL-LiteR ELH knowledge
bases runs polynomial time combined complexity. tractability result
extended single-atom C2RPQs, including existential variables.
show answering CRPQs PSpace-hard DL-Lite EL. result
already shown conference version, provide different
proof holds even structurally-restricted class strongly acyclic CRPQs
regular expressions disjunction-free star-height two.
hardness result interesting compared graph database setting,
317

fiBienvenu, Ortiz, & Simkus

C2RPQ answering NP-complete (and thus harder CQs worst case)
becomes feasible polynomial time restricted strongly acyclic C2RPQs.
develop query rewriting procedure answering C2RPQs DL-LiteR
ELH, use show problem feasible PSpace logics.
PSpace upper bound ELH especially interesting, since C2RPQs allow
inverse roles well known adding inverse roles EL immediately leads
ExpTime-hardness query answering, even instance queries. result demonstrates including inverses query language, rather ontology
language, possible obtain algorithms use polynomial space.
Using algorithm, derive NL upper bound data complexity DLLiteR P upper bound ELH. cases, lowest data complexity
could expected light existing results.
also identify cases C2RPQ answering feasible NP, thus harder
answering plain CQs. case queries whose existential variables
occur joins (or occur joins restricted way), arbitrary C2RPQs
whenever ontology guaranteed finite canonical model.
new complexity results (and relevant existing results) summarized Figure 1.
paper organized follows. begin Section 2 introducing lightweight
description logics DL-LiteR ELH (and relevant sublogics) recalling basic
notions related regular languages computational complexity. Section 3, define
syntax semantics different types path queries considered paper.
Section 4 dedicated showing lower bounds, first RPQs CRPQs.
cases, start presenting easy bounds follow known results,
moving main results. Section 5 presents algorithmic techniques upper bounds
2RPQs, Section 6, show extended handle C2RPQs.
Section 7, give brief overview related results similar query languages
DLs discuss applicability results profiles OWL Web Ontology
Language. Conclusions directions future work given Section 8. improve
readability paper, one technical proofs deferred appendix.

2. Preliminaries
briefly recall basics description logics, computational complexity classes
relevant paper, notation regular languages.
2.1 Description Logics
first recall syntax semantics description logics, focusing lightweight
families logics DL-Lite (Calvanese et al., 2007) EL (Baader et al., 2005). also
recall definition canonical model logics.
318

fiRegular Path Queries Lightweight Description Logics

IQ

DL-LiteRDFS
DL-Lite(R)
EL(H)

data

combined

data

AC0

NL-c

NL-c

NL-c

(A)

(A)

Thm 5.2

AC0

NL-c

NL-c

P-c

(G)

(G)

Thm 5.9

Thm 4.2, Thm 5.9

P-c

P-c

P-c

P-c

(E)

(C)

Thm 5.9

Thm 5.9

CQ

DL-LiteRDFS
DL-Lite(R)
EL(H)

(2)RPQ
combined

C(2)RPQ
combined

data

combined

data

AC0

NP-c

NL-c

NP-c

(B)

Thm 6.8

Thm 6.8

AC0

NP-c

NL-c

PSpace-c

(D)

(D)

Thm 6.8

Prop 4.5, Thm 6.8

P-c

NP-c

P-c

PSpace-c

(F)

(F)

Thm 6.8

Prop 4.5, Thm 6.8

Figure 1: Complexity query answering. c indicates completeness results,
used upper lower bounds respectively. New results marked bold.
remaining annotations following meanings:
P-hardness RPQs applies DL-LiteR
(A) Easy reduction NL-complete directed reachability problem
(B) Follows NP-hardness CQ answering relational databases
(C) Baader et al. (2005)
(D) Calvanese et al. (2007)
(E) Calvanese, De Giacomo, Lembo, Lenzerini, Rosati (2006)
(F) Rosati (2007), Krisnadhi Lutz (2007), Krotzsch Rudolph (2007)
(G) Calvanese et al. (2007), Artale, Calvanese, Kontchakov, Zakharyaschev (2009)

2.1.1 Description Logic Syntax
usual, assume countably infinite, mutually disjoint sets NC , NR , NI concept
names, role names, individuals, respectively. inverse role takes form r



r NR . use N
R refer NR {r | r NR }, R NR , use R mean


r R = r r R = r .
description logic knowledge base (KB) K = (T , A) consists TBox
ABox A. former provides general domain knowledge, latter expresses facts
319

fiBienvenu, Ortiz, & Simkus

particular entities. Sometimes use generic terms ontology data(set)
place TBox ABox.
Formally, TBox finite set inclusions, whose form depends DL question.
DL-Lite, TBoxes consist set concept inclusions form B v C, B
C concepts constructed according following syntax:
B := | R

C := B | B

NC R N
R . DL-LiteR additionally allows role inclusions form
R1 v ()R2 , R1 , R2 N
R . logic DL-LiteRDFS obtained DL-LiteR
disallowing inclusions contain negation existential concepts (R) righthand side. DL-LiteR basis OWL 2 QL profile, DL-LiteRDFS corresponds
fragment DL-LiteR expressible RDF Schema ontology language
(Brickley & Guha, 2014).
EL, concept inclusions form C1 v C2 C1 , C2 complex concepts
constructed according following syntax:
C := > | | C u C | r.C
NC r NR . DL ELH additionally allows role inclusions form
r1 v r2 , r1 , r2 NR . Note EL(H) TBoxes, inverse roles permitted.
use sig(T ) denote signature TBox , is, set concept
role names appearing . also prove useful introduce set BCT basic
concepts TBox , defined follows: BCT = (NC sig(T )){r, r | r NR sig(T )}
DL-LiteR TBox, BCT = (NC sig(T )) {>} ELH TBox.
considered DLs, ABox finite set concept assertions form
A(b) role assertions form r(b, c), NC , r NR , b, c NI . use
Ind(A) refer set individuals appearing ABox A.
2.1.2 Description Logic Semantics
semantics DL KBs defined terms interpretations, take form =
(I , ), non-empty set maps individual NI aI ,
concept name NC AI , role name r NR rI .
function extended general concepts roles follows:
>I =
(A)I = \ AI
(R)I = (I ) \ RI

(r )I = {(c, d) | (d, c) rI }
(R)I = {c | : (c, d) RI }
(r.C)I = {c | : (c, d) rI , C }

interpretation satisfies inclusion G v H, denoted |= G v H, GI H .
Similarly, satisfies assertion A(a) aI AI , symbols |= A(a); satisfies
assertion r(a, b) (aI , bI ) rI , symbols |= r(a, b). interpretation model
, satisfies inclusions ; model satisfies assertions A;
model (T , A) model A. KB (T , A) satisfiable
possesses least one model, else unsatisfiable. Note ELH knowledge bases
320

fiRegular Path Queries Lightweight Description Logics

tramway:T1

sbHFT

TramwayLine

stop:cathSq

FT

b

subway:U1
SubwayLine

sb
H

Su

FT

sbSub


LF


locIn

theater:Volkstheater

sbLFT

locIn

park:huberPark
Park,FamFriendly

locIn

theater:opera

locIn

locIn

park:cityPark

locIn

trainSt:ViennaCenter
trainStation

EquipStop

playgr:cityPark
Playground

Park
locIn

Cafe:Sacher
Cafe

Theater

GLStop

stop:trainStation

Cafe:Hawelka
Cafe

Theater

GLStop

stop:cityPark

locIn

Square

EquipStop

F
sbL

TramwayLine

stop:Volkstheater

stop:opera

sb
Su
b
sb

tramway:T2

square:cathSq

Stop

sbH

sb

locIn

locIn

shopping:cityMall
ShoppingCenter

Figure 2: Example ABox Amob
always satisfiable. G TBox, ABox, KB, inclusion assertion, say
G entails , written G |= , |= every model G.
Observe make Unique Names Assumption (UNA), definition
interpretation allows distinct individuals mapped domain element.
remark however results paper hold equally well UNA.
Example 2.1. motivating example, consider domain public transport
urban mobility. partial database domain presented Figure 2. nodes
two leftmost columns (shaded blue) correspond public transport lines stations.
arrows represent existing connections, labeled according
type transport line serving them: sbSub stands served subway, sbLFT
sbHFT respectively stand served low-floor tramway served high-floor
tramway. Nodes also labeled classes participate. particular,
labels GLStop EquipStop indicate two specific kinds public transport stops: groundlevel stops, stops suitably equipped ramps elevators passengers
restricted mobility. remaining columns contain places interest, locInlabeled arrows represent located relation. Note nothing
else graphical representation DL ABox, call Amob , label
node b corresponds concept assertion A(b), arc labeled r node b
node c corresponds role assertion r(b, c).
example, assume information first two columns provided
maintained local public transport authorities, thus complete well structured.
contrast, remaining data crowd-sourced, thus likely incomplete may
adhere rigid, predefined structure.
order better respond user queries, data enriched domain knowledge
expressed EL ontology Figure 3. ontology defines subclass relations
concepts like stop specialized accessible stop, ground-level stop,
defines new terms present data may useful query time,
food services. also enhances possibly incomplete data asserting existence
places interest. example, family-friendly location dining
playground facilities.
321

fiBienvenu, Ortiz, & Simkus

(1) accessible stop (AccStop) public transport stop (Stop). ground-level stop (GLStop)
stop suitably equipped ramps
elevators (EquipStop) accessible stop.
(2) Restaurants cafes food services
(FoodServ).
(3) place family friendly (FamFriendly)
food service playground.

AccStop v Stop

(1a)

GLStop v AccStop

(1b)

EquipStop v AccStop

(1c)

Restaurant v FoodServ

(2a)

Cafe v FoodServ

(2b)

FamFriendly v hasFacility.FoodServ

(3a)

FamFriendly v hasFacility.Playground (3b)
ShoppingCenter v hasFacility.Foodcourt

(4a)

(4) shopping center supermarket
ShoppingCenter v hasFacility.Supermarket (4b)
food court.
Foodcourt v hasFacility.FoodServ

(5) food court food service.

(5a)

Figure 3: Example DL-Lite TBox Tmob expressing domain knowledge
keep example compact, chosen write example ontology EL,
knowledge expressed DL-LiteR using auxiliary roles simulate
concept inclusions qualified existential quantification right-hand-side.
instance, concept inclusion (3a) replaced following three inclusions
syntax DL-Lite:
FamFriendly v hasFoodServ
hasFoodServ v FoodServ
hasFoodServ v hasFacility
similarly (3b), (4a), (4b), (5a).
2.1.3 Normal Form ELH TBoxes
simplify presentation, assume throughout paper ELH TBoxes
normal form, meaning concept inclusions one following forms:
AvB

v r.B

1 u A2 v B

r.B v

A, A1 , A2 , B NC {>}. following well-known property (see (Baader et al., 2005))
shows assumption without loss generality.
Proposition 2.2. every ELH TBox , one construct polynomial time ELH
TBox 0 normal form (possibly using new concept names) 0 model
conservative extension , is, every model 0 model , every model
, model 0 0 0 domain coincide
interpretation concept role names except sig(T 0 ) \ sig(T ).
322

fiRegular Path Queries Lightweight Description Logics

2.1.4 Canonical Models
Canonical models key technical tool used study lightweight description logics,
use proofs many results.
recall definition canonical model ,A (alternatively denoted IK )
satisfiable DL-LiteR ELH KB K = (T , A). domain ,A consists sequences
form aR1 C1 . . . Rn Cn (n 0), Ind(A), Ci concept, Ri
(possibly inverse) role. exact definition depends logic consider:
(A) DL-LiteR TBox, domain ,A contains exactly sequences
aR1 R1 . . . Rn Rn satisfy:
n 1, , |= R1 (a)
1 < n, |= Ri v Ri+1 .
(B) ELH TBox,2 domain ,A contains exactly sequences
ar1 A1 . . . rn ri NR , and:
n 1, , |= r1 .A1 (a);
1 < n, |= Ai v ri+1 .Ai+1 .
elements e ,A \ Ind(A), use notation Tail(e) denote final concept
e. set TCT tail concepts TBox defined follows: TCT = {r, r | r
NR sig(T )} DL-LiteR TBox, TCT = BCT = (NC sig(T )) {>}
ELH TBox. Clearly, e ,A \ Ind(A), Tail(e) TCT .
complete definition ,A , must fix interpretation individual
names, concept names, role names. done follows:
AIT ,A = {a Ind(A) | , |= A(a)} {e ,A \ Ind(A) | |= Tail(e) v A}
rIT ,A = {(a, b) | , |= r(a, b)} {(e1 , e2 ) | e2 = e1 C |= v r}
{(e2 , e1 ) | e2 = e1 C |= v r }
aIT ,A =

Ind(A)

Note ,A composed core consisting ABox individuals anonymous part consisting (possibly infinite) trees rooted ABox individuals.
use ,A |e denote submodel ,A obtained restricting domain
elements containing e prefix. Observe that, construction, ,A |e ,A |e0
isomorphic whenever Tail(e) = Tail(e0 ).
verified IK |= K every satisfiable KB K. Moreover, well known
canonical model IK homomorphically embedded model K.
Example 2.3. canonical model (Tmob , Amob ) Example 2.1 depicted Figure 4. satisfy existential restrictions inclusions (3a) (5a) Tmob ,
2. Recall throughout paper, assume ELH KBs normal form, reason,
need consider existential concepts form r.A NC {>}.

323

fiBienvenu, Ortiz, & Simkus

tramway:T1

sbHFT

TramwayLine

stop:cathSq

b

subway:U1
SubwayLine

sb
H

FT

sbSub


LF

FT

TramwayLine

stop:Volkstheater

locIn

theater:Volkstheater

Park,FamFriendly

lo c

sbLFT

stop:trainStation

lo

cIn

hasFacility

e1
FoodServ



GLStop,AccStop,Stop

park:huberPark

hasFacility

stop:cityPark

sbL

locIn

Theater

GLStop,AccStop,Stop

EquipStop,AccStop,Stop

sb

tramway:T2

Cafe,FoodServ

stop:opera

sb
Su
b

Cafe:Hawelka

Square

FT

Su

locIn

square:cathSq

Stop

sbH

sb

locIn

theater:opera

e2
Playground

locIn

Cafe:Sacher
Cafe,FoodServ

Theater

EquipStop,AccStop,Stop

locIn



loc

park:cityPark

playgr:cityPark

Park

Playground

trainSt:ViennaCenter

locIn

shopping:cityMall

trainStation

ShoppingCenter
hasFacility

e3
Foodcourt

hasFacility

e4
Supermarket

hasFacility

e5
FoodServ

Figure 4: Canonical model ITmob ,Amob KB (Tmob , Amob )
canonical model contains following five anonymous elements e1 , . . . e5 , form two
tree-shaped structures rooted nodes park:huberPark shopping:cityMall:
e1 = park:huberPark hasFacility FoodServ
e2 = park:huberPark hasFacility Playground
e3 = shopping:cityMall hasFacility Foodcourt
e4 = shopping:cityMall hasFacility Supermarket
e5 = shopping:cityMall hasFacility Foodcourt hasFacility FoodServ

Example 2.4. illustrate canonical models infinite, present Figure 5
simple DL-LiteR knowledge base (T , A) depiction canonical model ,A .
preceding example, use names ei abbreviations anonymous objects
,A . Note tree rooted b2 infinite, since every object belongs
concept B r-child also belongs B.
2.2 Regular Languages
assume reader familiar regular languages, represented either regular
expressions nondeterministic finite state automata (NFAs). Regular expressions E
alphabet defined grammar
E | | E E | E E | E
denotes empty word (i.e., sequence length 0). NFA
alphabet tuple = (S, , , s0 , F ), finite set states,
324

fiRegular Path Queries Lightweight Description Logics

B,
r



b

B v r,
B v r1 ,

r v B,
r1 v r2

e1

}
e11

= { r(a, b), r2 (b, c), D(b) }

e2

B

r


r1 , r2

B

e12


r1 , r2

r

e111

c


r1 , r2

r

={

r2

e112

B

..
.

Figure 5: Example DL-LiteR knowledge base (T , A) canonical model ,A
transition relation, s0 initial state, F set final states. use L(E)
(resp. L()) denote language defined regular expression E (resp. NFA ).
recall NFAs exponentially succinct regular expressions,
exists polynomial translation regular expressions equivalent NFAs,
translation NFAs regular expressions may incur exponential blowup (Ehrenfeucht
& Zeiger, 1974). Thus, ensure complexity results hold regardless chosen
representation, prove complexity lower bounds using regular expression
representation, upper bounds, adopt NFA representation.
2.3 Computational Complexity
assume familiarity standard complexity classes, NL (problems solvable
non-deterministic logarithmic space), P (problems solvable polynomial time), NP (problems solvable non-deterministic polynomial time), PSpace (problems solvable polynomial space), NPspace (problems solvable non-deterministic polynomial space).
recall Savitchs theorem, NPspace = PSpace. shall also consider oracle classes NLNL NLP consisting problems solvable non-deterministic
logarithmic space given access NL (respectively, P) oracle. well-known
NLNL = NL NLP = P. circuit complexity class AC0 mentioned
Figure 1 comprises problems computed family unbounded fan-in circuits
constant depth polynomial size. preceding classes ordered follows:
AC0 ( NL P NP PSpace
precise definitions complexity classes, standard notions computational complexity, refer reader recent textbook Arora Barak (2009)
references therein.

3. Path Queries
section, introduce different query languages considered paper
define relevant computational problems.
325

fiBienvenu, Ortiz, & Simkus


q1 (x, y) = AccStop? (sbSub sbSub ) (sbLFT sbLFT ) AccStop?(x, y)

q2 (x, y) = z1 , z2 . AccStop? (sbSub sbSub ) (sbLFT sbLFT ) AccStop?(x, y)
locIn (locIn ) hasFacility FoodServ? (x, z1 )
locIn (locIn ) hasFacility Playground? (y, z2 )

Figure 6: Example queries
3.1 Syntax Path Queries
conjunctive (two-way) regular path query (C2RPQ) form q(~x) = ~y . ~x
~y disjoint tuples variables, conjunction atoms forms:
(i) A(t), NC NI ~x ~y
(ii) (t, t0 ), NFA regular expression defining regular language
0
x ~y
N
R {A? | NC }, t, NI ~
usual, variables individuals called terms, variables ~x called answer
variables, variables ~y called quantified variables. use terms(q), vars(q),
avars(q), qvars(q) refer respectively sets terms, variables, answer variables,
quantified variables appearing query q. query answer variables called
Boolean query. Note convenient treat query set atoms.
Conjunctive (one-way) regular path queries (CRPQs) obtained disallowing symbols N
R \ NR atoms type (ii), conjunctive queries (CQs) result
allowing type (ii) atoms form r(t, t0 ) r NR . Two-way regular path queries
(2RPQs) consist single atom type (ii) t0 answer variables.
Regular path queries (RPQs) 2RPQs use symbols N
R \NR . Finally,
instance queries (IQs) take form A(x) NC , r(x, y) r NR .
Note sometimes prove convenient treat queries sets atoms, using
notation q indicate atom q.
Example 3.1. Figure 6 shows two example queries. 2RPQ q1 retrieves pairs x,
public transport stops accessible connection, is, x
accessible stops, public transport route uses subway
low-floor tramway. query q2 retrieves pairs x, public transport stops
accessible connection (as q1 ) place eat location x
playground location y.
Note using Kleene star ( ), query services restaurants
playgrounds available location without take care different ways
places related. example, restaurant could location
stop, could food court inside shopping center
location stop. cases, q2 correctly identifies food service
location. useful feature RPQs extensions, particularly cases
data comply rigid schema.
326

fiRegular Path Queries Lightweight Description Logics

3.2 Semantics Path Queries
proceed define semantics C2RPQs. Given interpretation I, path
e0 en sequence e0 u1 e1 u2 . . . un en n 0 every ei element
, every ui symbol N
R {A? | NC }, every 1 n:
ui = A?, ei1 = ei AI ;

ui = R N
R , (ei1 , ei ) R .

label (p) path p = e0 u1 e1 u2 . . . un en word u1 u2 . . . un . Note p = e0 ,
define (p) .
every language L N
R {A? | NC }, semantics L w.r.t. interpretation defined follows:
LI = {(e0 , en ) | path p e0 en (p) L}
match C2RPQ q interpretation mapping terms q
elements
(c) = cI c NI ,
(t) AI atom A(t) q,
((t), (t0 )) L()I (t, t0 ) q.
Given C2RPQ q answer variables x1 , . . . , xk , say tuple individuals
(a1 , . . . , ak ) Ind(A) certain answer q w.r.t. KB K = (T , A) case
every model K match q (vi ) = aIi every 1 k.
use cert(q, K) denote set certain answers q w.r.t. KB K. Note
q Boolean query, either cert(q, K) = {()} (where () denotes empty tuple)
cert(q, K) = . former case, say q entailed K, write K |= q.
remark normal form ELH TBoxes also assumed without loss
generality query answering. Indeed, always assume fresh symbols
TBox 0 normal form occur q, follows Proposition 2.2
definition certain answers cert(q, (T , A)) = cert(q, (T 0 , A)) every C2RPQ q
use symbols sig(T 0 ) \ sig(T ).
definition certain answers involves models KB, DLs considered paper, fact sufficient look matches canonical model.
Lemma 3.2. every DL-LiteR ELH KB K = (T , A), C2RPQ q(~x) arity k,
k-tuple ~a individuals A: ~a cert(q, K) match q IK
(~x) = ~a.
Proof sketch. well known canonical model IK homomorphically embedded model K (Calvanese et al., 2007; Rosati, 2007; Krisnadhi & Lutz, 2007;
Krotzsch & Rudolph, 2007). follows whenever query matches preserved
homomorphisms, existence match IK implies existence match every
model. often observed CQs, applies equally well C2RPQs (Calvanese et al., 2014; Ortiz et al., 2011). Since converse trivially true, certain answers
coincide answers canonical model.
327

fiBienvenu, Ortiz, & Simkus





s0

s0

r
r

s0

e1 s01

b

c

s0f

r

x


e2

r

s0 sf
r

s0 s2
r1

e11

e12

s0

:

s00

r1

s1

r2

s2

r

sf

r

s01

r

s0f



r

e111

:



r

s00

r

e112

z



r2

e1111

s1 e1112
..
.

Figure 7: match witnessing cert(q, K) q K Example 3.4
Example 3.3. urban mobility example, stop cathedral square
known accessible (i.e., AccStop(stop:cathSq) entailed (Tmob , Amob )), hence
stop:cathSq cannot participate match q1 . stop theater accessible,
connected stops via high-floor tramway. Thus stop:Volkstheater
participates one mapping q1 ITmob ,Amob , namely (x) = (y) = stop:Volkstheater.
Indeed, path
stop:Volkstheater AccStop? stop:Volkstheater AccStop? stop:Volkstheater

witnesses (stop:Volkstheater, stop:Volkstheater) LI1 language L1 specified q1 ,
longer path starting ending stop:Volkstheater whose label belongs L1 .
stops stop:opera, stop:cityPark, stop:trainStation accessible mutually connected via accessible public transport (i.e., subway low-floor tramway lines). Hence,
find path pair whose label L1 , pairs certain
answers q1 . Thus cert(q1 , (Tmob , Amob )) contains (stop:Volkstheater, stop:Volkstheater),
pairs stops involving stop:opera, stop:cityPark, stop:trainStation.
certain answers q2 precisely pairs (s1 , s2 ) stops answer
q1 food service location s1 playground location
s2 . Since ITmob ,Amob , find food service playground location stop:Volkstheater, (stop:Volkstheater, stop:Volkstheater) cert(q2 , (Tmob , Amob )).
also find food services locations stop:opera stop:trainStation, playground location stop:cityPark, hence cert(q2 , (Tmob , Amob )) also contains pairs
(stop:opera, stop:cityPark) (stop:trainStation, stop:cityPark).
Example 3.4. also give example query KB (T , A) Figure 5:
q(x) = y, z. r r1 r2 r (x, y) r r (y, z) D(z)
cert(q, K) = {a, b}. see certain answer, consider mapping
(x) = a, (y) = e11 , (z) = b. path arbre1 re11 re111 r1 e1112 r2 e111 r e11 witnesses
(a, e11 ) L(r r1 r2 r )IT ,A , path e11 r e1 r b witnesses (e11 , b)
328

fiRegular Path Queries Lightweight Description Logics

L(r r )IT ,A . Since b DIT ,A , mapping match q. match depicted
Figure 7. see b also certain answer, consider 0 (x) = 0 (z) = b 0 (y) =
e11 , observe 0 also match bre1 re11 re111 r1 e1112 r2 e111 r e11 witnesses
(b, e11 ) L(r r1 r2 r )IT ,A .
Note matches, mapped element anonymous part,
match mapping individual. illustrates anonymous elements may play
decisive role query answering, every complete query answering algorithm must
consider possible matches possibly infinite anonymous part canonical models.
3.3 Computational Problems
paper, interested problem computing certain answers
C2RPQs, precisely, associated decision problem determining whether
given tuple certain answer query. follows, query language Q
{IQ, CQ, RPQ, CRPQ, 2RPQ, C2RPQ}, use term Q answering refer
problem deciding given KB K, tuple ~a, query q Q, whether ~a cert(q, K).
different ways measuring complexity query answering, depending
three parameters problem (T , A, q) considered inputs
considered fixed. work, consider two commonly used measures:
combined complexity data complexity. Combined complexity treats three parameters
inputs, complexity measured respect total size |T | + |A| + |q| (we use
| | denote size object, e.g. length string representation according
suitable encoding). Data complexity takes input assumes q fixed,
complexity measured respect |A|, |T | |q| treated constants.

4. Lower Bounds
section, establish required complexity lower bounds. begin
lower bounds RPQs straightforwardly obtained existing results.
Proposition 4.1. RPQ answering
1. NL-hard data complexity DL-LiteRDFS ;
2. P-hard data complexity EL;
Proof. Statement (1) follows analogous result graph databases (Consens &
Mendelzon, 1990). shown simple reduction NL-complete directed
reachability problem: vertex b reachable vertex directed graph G
(a, b) certain answer RPQ r (x, y) w.r.t. KB (, AG ),
AG = {r(v1 , v2 ) | directed edge v1 v2 G}.
Statement (2) direct consequence P-hardness data complexity instance
checking EL (Calvanese et al., 2006), since instance query A(x) computed
using RPQ A?(x, y).
case DL-Lite, establish P lower bound 2RPQs, contrasts
NL-completeness instance checking. remark similar result given
329

fiBienvenu, Ortiz, & Simkus

conference version paper (Bienvenu et al., 2013), reduction required
NFA representation regular language query. complexity 2RPQs using
(less succinct) regular expression representation left open resolved
following theorem.
Theorem 4.2. 2RPQ answering P-hard combined complexity DL-Lite.
Proof. give reduction P-complete entailment problem propositional definite Horn theories. Without loss generality, suppose given propositional
Horn theory variables v1 , . . . , vn consists
set rules = vi1 vi2 vi3 (1 m)
single initialization fact: v1 , v1 6= vn
Indeed, arbitrary propositional definite Horn theory 0 transformed
theory preceding form follows: take fresh variable v1 appearing 0 , add
v1 body every rule 0 , add fact v1 , finally perform standard syntactic
manipulations (possibly introducing additional fresh variables) ensure rules
initialization fact v1 contain exactly two body variables.
follows, show construct, given propositional Horn theory
form above, DL-Lite KB K = (T , A) Boolean 2RPQ q K |= q
|= vn . first provide informal description reduction, present
formally. well known, |= vn case exists proof tree vn
, defined binary tree node labeled variable
v1 , . . . , vn following conditions satisfied: (i) root labeled
vn , (ii) leaves labeled v1 , (iii) inner node d, labeled vk ,
rule vk = vi3 two children labeled
vi1 vi2 , respectively. existence node-labeled proof tree described
equivalent existence edge-labeled proof tree 0 , defined sibling-ordered
binary tree whose edges labeled rules follows. First, two edges
outgoing root labeled rule vi3 = vn . non-root node d`
`-th child parent d, ` {1, 2}, edge (d, d` ) labeled ,
either vi` = v1 , d` two outgoing edges E1 E2 labeled
rule j vj3 = vi` .
next show construct K q K |= q exists
edge-labeled proof tree 0 vn . Roughly speaking, use K generate
anonymous part tree contains possible edge-labeled proof trees. Since
proof trees based upon sibling-ordered trees, need distinguish first
second children node, use two roles ri,1 ri,2 rule .
edge-labeled proof tree 0 thus map subtree IK structure,
label replaced either ri,1 ri,2 , depending whether edge leads first
second child parent node. use 2RPQ q determine whether IK actually
contains subtree. intuition every path witnesses satisfaction
q corresponds complete depth-first traversal (the representation of) valid edgelabeled proof tree starts ends root, left subtree node
always visited right one.
330

fiRegular Path Queries Lightweight Description Logics




E =(

[

1im

ri,1 )

[

1im

ri,1

[
kF1


(rk,1
rk,2 )

[
kF2

[


(rk,2
(


ri,2
) (

1im

[


(ri,1
ri,2 ) ))

1im

Figure 8: Regular expression used proof Theorem 4.2.
ABox consists single assertion A(a), TBox contains following
concept inclusions:
v ri,` , ` {1, 2} 1 vi3 = vn

ri,`
v rk,j , `, j {1, 2} 1 i, k vi` = vk3

` {1, 2}, define set
F` = {k | 1 k m, vk` = v1 }.
Intuitively, F` contains index rule turn back since `-th variable
initial variable v1 , (and corresponding child node proof tree would
leaf). use F1 F2 define regular expression E Figure 8, use
define following 2RPQ:
q = E(a, a).
prove correctness reduction.
() Suppose K |= q. Lemma 3.2, match q canonical
model IK K. means (a, a) = (aIK , aIK ) L(E)IK , exists path
e0 1 . . . p ep IK whose label L(E) e0 = ep = a.
Claim 1. every 2 j p:

1. j = ri,1 , exists j 0 > j j 0 = ri,2
.


2. j = ri,2
, exists j 0 < j j 0 = ri,1
.

3. j = ri,1
6 F1 , j1 = ri0 ,2 vi03 = vi1 .

4. j = ri,2
6 F2 , j1 = ri0 ,2 vi03 = vi2 .

Proof claim. Point 1, remark IK roles directed away
ABox; formally, every role name s, (g, g 0 ) sIK , g 0 = gss . follows

j = ri,1 , ej = ej1 ri,1 ri,1
. Since sequence elements ej , . . . , ep defines path
IK ej ep = a, continuity, must j0 > j ej0 1 = ej

ej0 = ej1 , case must j0 = ri,1
. Next note structure E

ensures every occurrence ri,1 immediately followed ri,2 . repeating

argument, substituting ri,2 ri,1 , find j 0 > j0 j 0 = ri,2
.
Point 2, use fact roles IK directed away ABox.


Thus, j = ri,2
, ej1 = ej ri,2 ri,2
. sequence e0 , . . . , ej1 elements forms
331

fiBienvenu, Ortiz, & Simkus


path IK e0 = ej ri,2 ri,2
. Thus, continuity, must exist j 0 < j

ej 0 = ej , ej 0 +1 = ej ri,2 ri,2
, j 0 +1 = ri,2 . examining structure E,


see occurrence ri,2 must immediately preceded ri,1
, j 0 = ri,1
.

show Point 3, suppose j = ri,1
6 F1 . structure E ensures
IK
preceding symbol j1 takes form ri0 ,2 . thus (ej , ej1 ) ri,1


(ej1 , ej2 ) riI0K,2 . using fact elements IK contain inverse


role names, obtain ej2 = ej ri,1 ri,1
ri0 ,2 ri0 ,2 . follows |= ri,1
v ri0 ,2 ,
case vi03 = vi1 .

Finally, Point 4, suppose j = ri,2
6 F2 . Examining structure
E, clear preceding symbol j1 must form ri0 ,2 ,
IK

(ej , ej1 ) ri,2
(ej1 , ej2 ) riI0K,2 . means |= ri,2
v ri0 ,2 , hence
vi03 = vi2 . (end proof claim)

easy see first symbol 1 must form ri,1 ,
IK
IK

(e0 , e1 ) ri,1
. Since e0 = a, (a, ari,1 ri,1
) ri,1
. implies |= v ri,1 ,
hence vi3 = vn . Applying Points 1 2 preceding claim, find j, k


j = ri,1
k = ri,2
. complete proof direction, establish
following claim.

Claim 2. every 1 j p ` {1, 2}, j = ri,`
, |= vi` .

Proof claim. proceed induction j. base case, suppose j = ri,`
,

0
j < j j 0 = ri0 ,`0 . follows Claim 1 F1 ` = 1.
thus vi` = v1 , |= vi` trivially holds.

induction step, suppose claim holds j < k, consider k = ri,`
.
consider three cases:

F`
Case 1: k = ri,`
Since F` , vi` = v1 , |= vi` follows immediately.

Case 2: k = ri,1
6 F1
Point 3 Claim 1, k1 = ri0 ,2 vi03 = vi1 . Applying induction hypothesis
k1 , obtain |= vi02 . Point 2 Claim 2, exists j < k
j = ri0 ,1 . second application induction hypothesis yields |= vi01 .
rule vi01 vi02 vi03 belongs , must also |= vi03 . since vi03 = vi1 ,
obtain |= vi1 .

Case 3: k = ri,2
6 F2
use almost argument Case 2, except must use Point
4 Claim 1, rather Point 3. (end proof claim)

contains rule vi1 vi2 vi3 , follows Claim 2 |= vn .
() |= vn , must exist edge-labeled proof tree 0 vn
described beginning proof. define mapping f nodes 0
domain elements ,A follows:
332

fiRegular Path Queries Lightweight Description Logics

f (d) = root 0 ;
every non-root node d, first (resp., second) child parent dp


(dp , d) labeled , f (d) = f (dp )ri,1 ri,1
(resp. f (d) = f (dp )ri,2 ri,2
).
show following claim:
Claim 3: every non-leaf node 0 , (f (d), f (d)) L(E)IT ,A .
Proof claim. every non-leaf node d, consider depth-first traversal subtree
0 rooted always visits left subtree node visiting right one,
returns root. Let d1 , d2 , . . . , dn sequence nodes visited
traversal, d1 = dn = d, every 2 n, let i1,i follows:
i1,i = rj,1 di first child di1 (di1 , di ) labeled j ;
i1,i = rj,2 di second child di1 (di1 , di ) labeled j ;

i1,i = rj,1
di1 first child di (di , di1 ) labeled j ;

i1,i = rj,2
di1 second child di (di , di1 ) labeled j .

define path pd follows:
pd = f (d1 )1,2 f (d2 )2,3 . . . n1,n f (dn )
show claim, suffices show following every non-leaf node d:
() pd path ,A (pd ) L(E).
shown induction minimal distance leaf 0 . important
observation that, ` {1, 2}, `th child d` node 0 leaf, edge
d` labeled , definition F` .
order able easily argue words belong L(E), give names
relevant subexpressions E:
[
E1 =
ri,1
1im

E2 =

[


(rk,1
rk,2 )

kF1

E3 = (

[


ri,2
)

1im

E4 = (

[


(ri,1
ri,2 ) )

1im

E5 =

[


(rk,2
(

kF2

[


ri,2
) (

1im

[


(ri,1
ri,2 ) )

1im




E6 =

[
1im

ri,1

[
kF1


(rk,1
rk,2 )

[


(rk,2
(

[

1im

kF2

333


ri,2
) (

[


(ri,1
ri,2 ) ))

1im

fiBienvenu, Ortiz, & Simkus



Note E5 = kF2 (rk,2
E3 E4 ), E6 = (E1 E2 E5 ) , E = E1 E6 .
ready prove (). base case, children leaves,
let label edges children. construction ,A , f (d)


ri,1 -child ri,2 -child, pd path ,A (pd ) = ri,1 ri,1
ri,2 ri,2
.

children leaves, F1 F2 . thus ri,1 L(E1 ), ri,1 ri,2 L(E2 ),



ri,2
L(E5 ) = L( kF2 (rk,2
E3 E4 )) (for latter, observe L(E3 ) L(E4 )).



Using E6 = (E1 E2 E5 ) , get ri,1
ri,2 ri,2
L(E6 ), using E = E1 E6 , obtain


(pd ) = ri,1 ri,1 ri,2 ri,2 L(E).
induction step, let dL dR left right children respectively,
let rule used label edges dL dR .
construction ,A f , know f (dL ) ri,1 -child f (d) f (dR )
ri,2 -child f (d). distinguish three cases:
neither children dL dR leaf, know induction
hypothesis pdL pdR paths ,A start end f (dL )
f (dR ) respectively {(pdL ), (pdR )} L(E). follows pd =


f (d)ri,1 pdL ri,1
f (d)ri,2 pdR ri,2
f (d) path ,A . let kL (resp. kR ) label
L
R
linking (resp. ) two children. Note construction, (pdL ) (resp.
(pdL )) ends rkL ,1 (resp. rkL ,2 ). follows (pdL ) L(E1 E6 E5 )


ri,2 ) ) final E5 , must select .
subexpression E4 = ( 1im (ri,1


choosing instantiate E4 ri,1 ri,2 instead, show (pdL ) ri,1
ri,2

L(E6 ). similar argument (pdR ) used show (pdR ) ri,2
L(E6 ).


therefore obtain (pd ) = ri,1 (pd1 ) ri,1
ri,2 (pd1 ) ri,2
L(E1 E6 E6 ) L(E).
L
R
leaf is, apply induction hypothesis infer
pdL path ,A starts ends f (dL ) (pdL ) L(E).

using reasoning previous case, obtain (pdL ) ri,1
ri,2

R
L(E6 ). leaf, follows F2 , hence ri,2 L(E5 ) (here
choose satisfy subexpressions E3 E4 E5 ). Putting together, find


(pd ) = ri,1 (pd1 )ri,1
ri,2 ri,2
L(E1 E6 E5 ) L(E).
L
R
leaf not, argument analogous previous case.
(end proof claim)
Since f (d) = root 0 , follows preceding claim (a, a)
L(E)IT ,A , hence K |= q.
DL-LiteR , strengthen Theorem 4.2 using role inclusions eliminate inverse
roles query.
Corollary 4.3. RPQ answering P-hard combined complexity DL-LiteR .
Proof. Let q 2RPQ (T , A) DL-LiteR KB. inverse role r appearing
q, introduce new role name rinv . let q 0 RPQ obtained replacing
every occurrence r query rinv , let 0 extension
role inclusions r v rinv rinv v r new role name rinv . easy see
cert(q, (T , A)) = cert(q 0 , (T 0 , A)).
334

fiRegular Path Queries Lightweight Description Logics

leave open whether RPQ answering DL-Lite P-hard combined complexity.
next provide combined complexity lower bounds CRPQs. CRPQs generalize CQs, inherit NP lower bound well-known NP-hardness combined
complexity CQ answering relational databases (see (Abiteboul, Hull, & Vianu, 1995)):
Proposition 4.4. CRPQ answering NP-hard combined complexity DL-LiteRDFS .
DL-Lite EL, show CRPQ answering PSpace-hard combined
complexity, contrast CQ answering NP-complete. Interestingly, PSpacehardness holds even strong restrictions. particular, consider following
restrictions shape query form regular languages query atoms:
(Strong) acyclicity: C2RPQ q acyclic associated undirected graph Gq =
{{t, t0 } | L(t, t0 ) q} acyclic. strongly acyclic additionally (i)
contain atoms form L(t, t) (ii) every pair distinct atoms
L1 (t1 , t01 ), L2 (t2 , t02 ), {t1 , t01 } =
6 {t2 , t02 }.
Disjunction-freeness star-height regular expressions: regular expression
disjunction-free contain . star-height regular expression
defined maximum nesting depth stars appearing regular expression.
point graph database setting, (strong) acyclicity leads tractability:
acyclic C2RPQs evaluated polynomial time combined complexity (Barcelo
et al., 2012), strongly C2RPQs, evaluation even done linear time
size database (Barcelo, 2013). contrast, following result shows strong
acyclicity impact worst-case complexity CRPQ answering setting:
Theorem 4.5. CRPQ answering PSpace-hard combined complexity DL-Lite
EL. result applies even restriction strongly acyclic CRPQs whose regular
languages given disjunction-free regular expressions star-height two.
Proof. give reduction problem emptiness intersection arbitrary
number regular languages, known PSpace-hard. result first shown
Kozen (1977) regular languages given deterministic NFAs. recently, Bala
(2002) proved problem also PSpace-hard regular languages given
disjunction-free regular expressions star-height two. So, let E1 , . . . , En disjunctionfree regular expressions star-height two alphabet = {1 , . . . , }.
use symbols role names, also use concept names B.
reduction, consider following Boolean CRPQ:
q = x1 , . . . , xn , y. A(x1 ) . . . A(xn ) E1 (x1 , y) . . . En (xn , y)
Observe q satisfies restrictions proposition statement. KB, use
ABox = {A(a)} TBox whose form depends logic question.
DL-Lite, use
= {A v | } {i v j | , j }
335

fiBienvenu, Ortiz, & Simkus

EL, use instead:
= {A v B} {B v .B | }.
Notice cases canonical model IK K = (T , A) consists infinite tree
rooted every element interpretation unique -child
(and children). Thus, associate every domain element IK
word given sequence role names encountered along unique path
a, moreover, every word w find element ew sequence
role names path ew exactly w.
claim L(E1 ) . . . L(En ) non-empty K |= q. see why, first
note w L(E1 ) . . . L(En ), define match q canonical model
mapping variables x1 , . . . , xn ew . Conversely, q entailed K,
match q IK . Since AIK = {a}, must (xi ) = every
1 n. follows unique path (y) IK word belongs
every L(Ei ), means L(E1 ) . . . L(En ) non-empty.
note proof preceding theorem conference version (Bienvenu
et al., 2013) uses simpler query variables xi replaced atoms
A(xi ) dropped. However, query strongly acyclic. also remark
similar proof already used establish PSpace hardness CQs extension
ELH allows regular role hierarchies (Krotzsch & Rudolph, 2007).

5. Upper Bounds 2RPQs
next two sections, provide concrete query answering algorithms considered
classes path queries DLs, leverage derive matching upper bounds
complexity lower bounds Section 4. technical developments presented
stages. begin section giving simple algorithm answering 2RPQs DLLiteRDFS . remainder section devoted showing algorithm
extended handle DL-LiteR ELH. Afterwards, Section 6, introduce query
rewriting procedure that, combined algorithms present section,
yields method answering C2RPQs.
following section, assume binary atoms take form (t, t0 ),
NFA N
R {A? | NC }. without loss generality, since every
regular expression transformed equivalent NFA; examination standard
technique constructing NFAs regular expressions (Thompson, 1968) reveals
transformation fact performed deterministic logspace transducer.
also useful introduce notation NFAs result changing initial
final states NFA. follows, given NFA = (S, , , s0 , F ),
use s,G denote NFA (S, , , s, G), i.e., NFA states
transitions initial state final states G. single final state
s0 , write s,s0 place s,{s0 } .
336

fiRegular Path Queries Lightweight Description Logics

Algorithm BasicEval
Input: NFA = (S, , , s0 , F ) N
R {A? | NC }, DL-LiteRDFS KB (T , A),
(a, b) Ind(A) Ind(A)
1. Initialize current = (a, s0 ) count = 0. Set max = |A| |S|.
2. count < max current 6 {(b, sf ) | sf F }
(a) Let current = (c, s).
(b) Guess pair (d, s0 ) Ind(A) transition (s, , s0 )
N
R , verify , |= (c, d), return not.
= A?, verify c = , |= A(c), return not.
(c) Set current = (d, s0 ) increment count.
3. current = (b, sf ) sf F , return yes. Else return no.
Figure 9: Non-deterministic algorithm 2RPQ answering DL-LiteRDFS .
5.1 Warm-up: 2RPQ Answering DL-LiteRDFS
standard technique answering 2RPQs absence ontology nondeterministically guess path pair individuals labeled word
specified regular language. procedure made run logarithmic space
keeping small portion path memory time.
Figure 9, present simple non-deterministic algorithm BasicEval answering
2RPQs DL-LiteRDFS knowledge bases implements idea. algorithm takes
input NFA = (S, , , s0 , F ), DL-LiteRDFS KB K = (T , A), pair individuals
(a, b) A, decides whether (a, b) cert((x, y), K). Step 1, initialize current
pair (a, s0 ) counter count 0. also compute maximum value max
counter, corresponds largest length path needs considered.
every iteration loop (Step 2), start single pair (c, s) stored
current proceed guess new pair (d, s0 ) together transition form
(s, , s0 ). idea would like append path guessed far,
so, must ensure conditions paths satisfied. purpose
entailment checks Step 2(b). applicable check succeeds, place (d, s0 )
current increment count. exit loop reached maximum
counter value pair count takes form (b, sf ) sf final state. latter
case, managed guess path required properties, algorithm
returns yes.
use counter ensures algorithm terminates, following proposition proves always outputs correct result.
Proposition 5.1. every 2RPQ q = (x, y), DL-LiteRDFS KB K = (T , A), pair
individuals (a, b) Ind(A): (a, b) cert(q, K) execution
BasicEval(, K, (a, b)) returns yes.
337

fiBienvenu, Ortiz, & Simkus

Proof. Consider 2RPQ q = (x, y) = (S, , , s0 , F ), DL-LiteRDFS KB K =
(T , A), pair individuals (a, b) Ind(A).
First suppose (a, b) cert(q, K). path p = e0 u1 . . . un en IK
e0 = a, en = b, (p) L(). may assume without loss generality
path shorter length p satisfies conditions. DL-LiteRDFS
TBox, know IK = Ind(A), every ei Ind(A). Since (p) L(),
find sequence states s0 s1 . . . sn sn F every 1 n,
(si1 , ui , si ) . minimality assumption, know (ei , si ) 6= (ej , sj )
6= j, sequence pairs (e0 , s0 )(e1 , s1 ) . . . (en , sn ) length |A| |S|.
easily verified guessing sequence pairs, together corresponding
transitions (si1 , ui , si ), obtain execution BasicEval returns yes.
direction, suppose execution BasicEval(, K, (a, b))
returns yes, let (c0 , s0 )(a1 , s1 ) . . . (cn , sn ) sequence pairs guessed
execution. must c0 = a, cn = b, sn F . Moreover, every
1 n, must exist transition (si1 , ui , si ) , |= ui (ci1 , ci )
ui N
R , ci1 = ci , |= A(ci ) ui = A?. follows sequence
p = c0 u1 c1 . . . un cn path IK (p) L(), (c0 , cn ) = (a, b) cert(q, K).
analyzing complexity procedure BasicEval, obtain NL upper bound,
matches NL lower bound Proposition 4.1.
Theorem 5.2. 2RPQ answering NL combined complexity DL-LiteRDFS .
Proof. Proposition 5.1, know BasicEval decision procedure 2RPQ answering DL-LiteRDFS . see BasicEval runs non-deterministic logarithmic space,
note (i) utilizing binary encoding, logarithmic space needed store
value count, old new values current, guessed transition ,
(ii) entailment checks 2(b) performed non-deterministic logarithmic space.
latter follows fact instance checking NL combined complexity
superlogic DL-LiteR (Calvanese et al., 2007).
5.2 2RPQ Answering DL-LiteR ELH
turn problem answering 2RPQs DL-LiteR ELH knowledge bases.
following example shows basic evaluation algorithm used DL-LiteRDFS
incomplete logics. Intuitively, problem lies fact algorithm
considers paths along ABox individuals, whereas satisfy query may necessary
consider paths pass anonymous part.
Example 5.3. remaining paper, consider KB (T , A) =
{B v r, r v B, B v r1 , r1 v r2 } = {r(a, b), r2 (b, c), D(b)} Example 2.4.
example 2RPQ, consider q 0 (x, y) = (x, y), = hS, , , s0 , {sf }i
= {s0 , s1 , s2 , sf }
= {r, r1 , r2 , r }
= {(s0 , r, s0 ), (s0 , r1 , s1 ), (s1 , r2 , s2 ), (s2 , r , sf )}
338

fiRegular Path Queries Lightweight Description Logics




s0 sf

r
r

e1

c

b
s0 s2

r2

r1

r

x


s1 e2

:

s0

r1

s1

r2

s2

r

sf


e1111

e1112
..
.

Figure 10: match witnessing (a, a) cert(q, K) q(x, y) = (x, y)
NFA depicted upper right-hand-side Figure 10. Observe L() =
L(r r1 r2 r ) (i.e., language first atom C2RPQ q Example 3.4).
Note (a, a) cert(q, (T , A)), witnessed path arbr1 e2 r2 br a,
passes element e2 anonymous part ,A . input, algorithm
BasicEval would start (a, s0 ). first iteration loop, could guess
pair (b, s0 ) transition (s0 , r, s0 ), entailment check first item Step
2(b) would succeed since , |= r(a, b). However, next iteration transitions
s0 (s0 , r, s0 ), (s0 , r1 , s1 ), Ind(A) , |= r(b, d)
, |= r1 (b, d). Hence good pair guess Step 2(b) algorithm would
fail. Since possible guesses first iteration satisfy entailment
check, algorithm incorrectly returns no.
aim modify evaluation algorithm take account detours
anonymous part. observe path two ABox individuals IK
decomposed sequence paths two types:
paths whose elements belong ABox
paths begin end ABox individual whose intermediate
points belong anonymous part
Paths first type already handled evaluation algorithm. handle paths
second type, show check whether path form starts
ends given individual takes query automaton state state s0 .
loop exists individual a, query evaluation, allowed
jump directly (a, s) (a, s0 ). modifying evaluation algorithm allow
shortcuts addition normal transitions, ensure possible paths
canonical model taken account.
key observation decide whether loop available given ABox individual
sufficient consider basic concepts hold a. leads us define
table ALoop entry ALoop [s, s0 ] contains set basic concepts C
force existence path second type whose label takes query automaton
state state s0 . order define ALoop , require second table Loop
contain pair states (s, s0 ), set tail concepts guarantee existence
339

fiBienvenu, Ortiz, & Simkus

path anonymous element e takes query automaton s0
never leaving subtree IK rooted e (note allow e occur multiple
times along path).
Let us proceed definition tables ALoop Loop . DL-LiteR
TBox, Loop defined inductively using following rules:
(L1) every S: Loop [s, s] = TCT .
(L2) C Loop [s1 , s2 ] C Loop [s2 , s3 ], C Loop [s1 , s3 ].
(L3) C TCT , |= C v A, (s1 , A?, s2 ) , C Loop [s1 , s2 ].
(L4) C TCT , |= C v R, |= R v R0 , |= R v R00 , (s1 , R0 , s2 ) , R
Loop [s2 , s3 ], (s3 , R00 , s4 ) , C Loop [s1 , s4 ].
table ALoop constructed Loop using rule:
(L5) C BCT , |= C v R, |= R v R0 , |= R v R00 , (s1 , R0 , s2 ) , R
Loop [s2 , s3 ], (s3 , R00 , s4 ) , C ALoop [s1 , s4 ].
ELH, use definitions, except rules 4 5 replaced by:
(L4) C TCT , |= C v r.D, |= r v r0 , |= r v r00 , (s1 , r0 , s2 ) ,
Loop [s2 , s3 ], (s3 , r00 , s4 ) , C Loop [s1 , s4 ].
(L5) C BCT , |= C v r.D, |= r v r0 , |= r v r00 , (s1 , r0 , s2 ) ,
Loop [s2 , s3 ], (s3 , r00 , s4 ) , C ALoop [s1 , s4 ].
Note since TCT = BCT ELH, difference (L4) (L5)
former adds concepts table Loop , latter adds concepts ALoop .
following example illustrates construction tables Loop ALoop .
Example 5.4. Observe running example TCT = {r, r , r1 , r1 , r2 , r2 }
BCT = {B} TCT . first step loop computation 2RPQ q 0
Example 5.3, get Loop [s, s] = TCT every {s0 , s1 , s2 , sf }. infer
r Loop [s0 , s2 ] using rule L4 following facts:
|= r v r1

|= r1 v r1

(s0 , r1 , s1 )

r1 Loop [s1 , s1 ]

|= r1 v r2
(s1 , r2 , s2 )

Intuitively, every element e satisfies r r1 -child e0 (by |= r v r1 ),
e0 turn r2 -child e (by r1 v r2 ). Hence, starting element e,
always use transition (s0 , r1 , s1 ) go child e0 return e using
transition (s1 , r2 , s2 ), i.e., loop s0 s2 e.
step, infer r Loop [s0 , s3 ] using rule L4 together with:
|= r v r

|= r v r

(s0 , r, s0 )

r Loop [s0 , s2 ]
340

|= r v r
(s2 , r , sf )

fiRegular Path Queries Lightweight Description Logics

reflects whenever element satisfies r , loop s0 s3 follows:
move r-child (which exists |= r v r) staying state s0
(s0 , r, s0 ), use previously computed loop jump s2 element,
go back e transition (s2 , r , sf ).
One verify loops inferred rules, obtain:
Loop [si , si ] = TCT 0 3

Loop [s0 , s2 ] = {r }

Loop [s0 , s3 ] = {r }

compute ALoop . First note applications L5 analogous
two described applications L4, respectively result r ALoop [s0 , s2 ]
r ALoop [s0 , s3 ]. Moreover, similar applications using |= B v r1 instead
|= r v r1 |= B v r instead |= r v r yield B ALoop [s0 , s2 ]
B ALoop [s0 , s3 ]. applications L5 yield new loops, hence obtain:
ALoop [s0 , s2 ] = {r , B}

ALoop [s0 , s3 ] = {r , B}

observe tables Loop ALoop constructed polynomial time
|T | || since entailment inclusions P DL-LiteR ELH (Calvanese
et al., 2007; Baader et al., 2005). following propositions show Loop ALoop
desired meaning:
Proposition 5.5. every DL-LiteR ELH KB K = (T , A) IK \ Ind(A),
following equivalent:
1. Tail(d) Loop [s, s0 ];
2. path p = e0 u1 e1 . . . un en IK (p) L(s,s0 ), e0 = en = d,
ei IK |d every 0 n.
Proof. Consider KB K = (T , A) automaton = (S, , , s, F ). begin
proving first statement implies second. Fix sequence applications
rules L1, L2, L3, L4 (or L4) generates full table Loop , let k
length sequence. suffices show following claim 1 k:
Claim: C inserted Loop [s, s0 ] i-th rule application ,A \ Ind(A)
Tail(d) = C, path p = e0 u1 e1 . . . un en IK (p)
L(s,s0 ), e0 = en = d, ei IK |d every 0 n.
Proof claim. proof induction i. First suppose C inserted
Loop [s, s0 ] first rule application ,A \ Ind(A) Tail(d) = C.
either rule L1 rule L3 must applied. former case, = s0 ,
path p = satisfies required conditions (recall case (p) ).
instead rule L3 applied, must |= C v (s, A?, s0 )
concept name A. Since Tail(d) = C, must AIT ,A . follows
p = dA?d path satisfying required conditions.
induction step, suppose statement holds 1 < k, let
,A \ Ind(A) C = Tail(d) inserted Loop [s, s0 ] k-th rule
application. first possibility k-th rule application involves rules L1 L3,
case proceed base case. next possibility rule L2
341

fiBienvenu, Ortiz, & Simkus

applied. must exist s00 first k 1 rule applications,
C Loop [s, s00 ] C Loop [s00 , s0 ]. Applying induction hypothesis, find paths
p1 p2 begin end d, contain elements IK |d ,
(p1 ) L(s,s00 ) (p2 ) L(s00 ,s0 ). Let p3 path obtained taking p1
adding p2 first occurrence removed. p3 begins ends d, contains
elements IK |d , (p3 ) L(s,s0 ).
final possibility k-th rule application involves rule L4. proof
differs depending whether formulated DL-LiteR ELH. give proof
DL-LiteR ; proof ELH proceeds analogously. first note since
application rule L4 leads insertion C Loop [s, s0 ] stage k, must
00 000
case find R, R0 , R00 N
R ,
|= C v R, |= R v R0 , |= R v R00 ,
(s, R0 , s00 ) (s000 , R00 , s0 ) ,
R Loop [s00 , s000 ] (after k 1 rule applications).
Tail(d) = C |= C v R, element d0 = dRR must belong ,A .
applying induction hypothesis, infer path p0 begins
ends d0 , contains elements IK |d0 , (p0 ) L(s00 ,s000 ).
follows path p = dR0 p0 R00 satisfies requirements, particular,
(p) L(s,s0 ). (end proof claim)
show direction, proceed induction length path p =
e0 u1 e1 . . . un en . first base case n = 0, i.e., (p) = . L(s,s0 ),
implies = s0 . rule L1 definition Loop , must Tail(d)
Loop [s, s0 ]. second base case n = 1, i.e., p = dA?d. Since p path,
must AIT ,A , means |= Tail(d) v A. also know (p) = A?
L(s,s0 ), implies (s, A?, s0 ) . thus shown conditions rule
L3 satisfied, Tail(d) Loop [s, s0 ].
induction step, suppose second direction holds 0 ` < k,
suppose path p = e0 u1 e1 . . . uk ek IK k > 2 (p) L(s,s0 ),
e0 = ek = d, ei IK |d every 0 k. First suppose exists
ej 0 < j < k ej = d. Let p1 = e0 u1 e1 . . . ej p2 = ej uj . . . ek .
know (p) = (p1 )(p2 ) L(s,s0 ), must exist state s00
(p1 ) L(s,s00 ) (p2 ) L(s00 ,s0 ). Applying induction hypothesis p1 p2 ,
obtain Tail(d) Loop [s00 , s0 ] Tail(d) Loop [s, s00 ]. Hence, rule L2
construction Loop , must Tail(d) Loop [s, s0 ].
let us consider second possibility, ej 6= 0 < j < k. Since
,A |d tree-shaped, p path, must case e1 = ek1 = dRC ,A |d .
point, proof slightly differs depending whether DL-LiteR ELH.
present proof case ELH, case R = r NR |=
Tail(d) v r.C. (p) = u1 . . . uk L(s,s0 ), e0 = ek = d, e1 = ek1 = dRC, must
case
u1 N
R |= r v u1 ,
342

fiRegular Path Queries Lightweight Description Logics


uk N
R |= r v uk = .

also know must exist states s00 , s000
(s, u1 , s00 ) (s000 , uk , s0 ) ,
u2 . . . uk1 L(s00 ,s000 ).
apply induction hypothesis p0 = e1 u1 . . . uk1 ek1 infer Tail(e1 ) =
C Loop [s00 , s000 ]. thus satisfy required conditions applying rule L4
obtain Tail(d) Loop [s, s0 ]. proof DL-LiteR analogous.
Proposition 5.6. every DL-LiteR ELH KB K = (T , A), NFA containing states
s, s0 , Ind(A), following statements equivalent:
1. concept C ALoop [s, s0 ] , |= C(a).
2. path p = e0 u1 e1 u2 . . . un en IK (p) L(s,s0 ), e0 = en = a,
n > 1, ei 6 Ind(A) 0 < < n.
Proof. Fix DL-LiteR TBox NFA = (S, , , s, F ) (the proof ELH similar
left reader). first direction, suppose concept C ALoop [s, s0 ]
, |= C(a). follows definition ALoop exists roles
00 000
0

R, R0 , R00 N
R states , |= C v R, |= R v R , |= R v
00
000
000
00
0
00
0
00

R , (s, R , ) , R Loop [s , ], (s , R , ) . Since , |= C(a)
|= C v R, follows definition IK aRR IK . Proposition 5.5,
R Loop [s00 , s000 ] implies path p = e0 u0 . . . un en IK |aRR e0 =
en = aRR (p) L(s00 ,s000 ). verified taking p0 = aR0 pR00 a,
obtain path IK satisfies conditions second statement. particular,
since (s, R0 , s00 ) , (p) L(s00 ,s000 ), (s000 , R00 , s0 ) , (p0 ) L(s,s0 ).
second direction, suppose path p = e0 u1 e1 u2 . . . un en IK
(p) L(s,s0 ), e0 = en = a, n > 1, ei 6 Ind(A) 0 < < n. Since n > 1,
e1 6 Ind(A), p path, must case e1 = aRR R N
R.
Moreover, since IK |a tree, must en1 = e1 . definition paths,
must case
u1 N
R |= R v u1 ,

un N
R |= R v un .

also know must exist states s00 , s000 that:
(s, u1 , s00 ) (s000 , un , s0 )
u2 . . . un1 L(s00 ,s000 )
applying Proposition 5.5 p0 = e1 u1 . . . un1 en1 , infer R Loop [s00 , s000 ].
Since aRR IK , definition IK ensures C BCT
C IK |= C v R. conditions Rule 5 thus satisfied, C ALoop [s, s0 ].
343

fiBienvenu, Ortiz, & Simkus

Algorithm EvalAtom
Input: NFA = (S, , , s0 , F ) N
R {A? | NC }, DL-LiteR ELH KB
(T , A), (a, b) Ind(A) Ind(A)
1. Test whether (T , A) satisfiable, output yes not.
2. Initialize current = (a, s0 ) count = 0. Set max = |A| |S| + 1.
3. count < max current 6 {(b, sf ) | sf F }
(a) Let current = (c, s).
(b) Guess pair (d, s0 ) Ind(A) together either (s, , s0 ) B
ALoop [s, s0 ].
(c) (s, , s0 ) guessed
N
R , verify , |= (c, d), return not.
= A?, verify c = , |= A(c), return not.
(d) B guessed, verify c = , |= B(c), return not.
(e) Set current = (d, s0 ) increment count.
4. current = (b, sf ) sf F , return yes. Else return no.
Figure 11: Non-deterministic algorithm 2RPQ answering DL-LiteR ELH.
means determine loops anonymous part
available given ABox individual, ready present extended evaluation
algorithm EvalAtom Figure 11 handles DL-LiteR ELH KBs. algorithm
EvalAtom differs BasicEval two respects. First, DL-LiteR KBs may contain
contradictions, initial consistency check Step 1 determine whether input
KB satisfiable (this step skipped ELH KBs, always satisfiable).
KB shown unsatisfiable, query trivially holds, algorithm outputs
yes. second difference occurs Step 3(b) within loop,
choice guessing pair (d, s0 ) Ind(A) (as before) guessing concept
B ALoop [s, s0 ]. first option corresponds taking step ABox, whereas
second corresponds shortcut anonymous part. choose second
option, must check selected concept entailed current individual.
exit conditions loop criterion outputting yes Step 4 remain
unchanged.
Example 5.7. Algorithm EvalAtom correctly returns yes input (a, a) together
example query KB, contrast BasicEval (as shown Example 5.3). Indeed,
successful execution (illustrated pictorially Figure 12) starts (a, s0 ) guesses
pair (b, s0 ) transition (s0 , r, s0 ) first iteration loop.
checks Step 3(c) succeed , |= r(a, b). next iteration, guess (b, s2 ) and,
r ALoop [s0 , s2 ], also guess concept r . checks Step 3(d) succeed
, |= r (b). third iteration, guesses pair (a, sf ) transition
344

fiRegular Path Queries Lightweight Description Logics

r




s0 sf

r

s0 s2

r

e1

c

b



x
:

r2

r1

(s0 , s2 )-loop



s1 e2

s0

r1

s1

r2

s2

r

sf



r ALoop [s0 , s2 ]


e1111

e1112
..
.

Figure 12: Establishing (a, a) cert(q, K) using EvalAtom q(x, y) = (x, y)
(s2 , r , sf ). , |= r (b, a), checks Step 3(c) succeed again. Since sf F ,
last iteration, Step 4 algorithm returns yes.
Proposition 5.8. every 2RPQ q = (x, y), DL-LiteR ELH KB K = (T , A),
pair individuals (a, b) Ind(A): (a, b) cert(q, K) execution
EvalAtom(, K, (a, b)) returns yes.
Proof. Consider 2RPQ q = (x, y) = (S, , , s0 , F ), DL-LiteR ELH KB
K = (T , A), pair individuals (a, b) Ind(A).
first direction, suppose (a, b) cert(q, K). path p =
e0 u1 . . . un en IK e0 = a, en = b, (p) L(). may assume without
loss generality shorter path properties. Since (p) L(),
find sequence states s0 s1 . . . sn sn F every 1 n,
(si1 , ui , si ) . Let j1 < . . . < jm indices ei Ind(A),
consider sequence pairs = (ej1 , sj1 )(ej2 , sj2 ) . . . (ejm , sjm ). Observe j1 = 0
jm = n, ej1 = a, ejm = b, sjm F . Also observe must
(ej` , sj` ) 6= (ejk , sjk ) whenever ` 6= k, since otherwise, could construct shorter path
properties p, contradicting minimality assumption. follows
sequence contains |A| |S| pairs. Thus, prove sequence leads
execution EvalAtom returns yes, remains show always possible
guess transition concept 3(b) checks 3(c) 3(d) succeed. Thus,
let us suppose current = (ej` , sj` ) guess pair (ej`+1 , sj`+1 ) 3(b).
three cases consider:
Case 1: j`+1 = j` +1 uj`+1 = R N
R . earlier, (sj` , R, sj`+1 ) ,
since p path, know (ej` , ej`+1 ) RIK . latter implies
, |= R(ej` , ej`+1 ), choosing transition (sj` , R, sj`+1 ) 3(b), ensure
entailment check succeed 3(c).
Case 2: j`+1 = j` + 1 uj`+1 = A?. earlier, (sj` , A?, sj`+1 ) ,
since p path, know ej` = ej`+1 AIK . choosing transition
(sj` , A?, sj`+1 ), ensure conditions 3(c) satisfied.
Case 3: j`+1 > j` + 1. case, path p0 = ej` uj` +1 . . . uj`+1 ej`+1
(p0 ) L(sj` ,sj`+1 ), ej` = ej`+1 Ind(A), every j` < < j`+1 ,
345

fiBienvenu, Ortiz, & Simkus

ei 6 Ind(A). thus apply Lemma 5.6 find concept C ALoop [sj` , sj`+1 ]
, |= C(ej` ). choosing C 3(b), sure entailment
check 3(d) succeed.
direction, consider execution EvalAtom(, K, (a, b)) returns
yes, let (c0 , s0 )(a1 , s1 ) . . . (cn , sn ) sequence pairs guessed
execution. must c0 = a, cn = b, sn F . complete proof,
suffices establish following claim:
Claim: every 0 n, path pi c0 ci IK (pi ) L(s0 ,si ).
Proof claim. proof induction i. base case (i = 0), simply
take path p0 = c0 since (p0 ) = L(s0 ,s0 ). induction step,
suppose pk1 path c0 ck1 (pk1 ) L(s0 ,sk1 ), show
construct path pk required properties. three cases consider
depending transition concept guessed together (ck , sk ) Step 3(b).
Case 1: transition (sk1 , R, sk ) guessed. Since check 3(c) succeeded,
, |= R(ck1 , ck ). pk = pk1 Rck path IK c0 ck
(pk ) L(s0 ,sk ).
Case 2: transition (sk1 , A?, sk ) guessed. since check 3(c)
succeeded, ck = ck1 , |= A(ck1 ). pk = pk1 A?ck path
IK c0 ck (pk ) L(s0 ,sk ).
Case 3: concept B ALoop [sk1 , sk ]
succeeded, ck = ck1 , |=
find path p0 = e0 u1 e1 u2 . . . un en IK
en = ck1 . pk = pk1 u1 e1 u2 . . . un en
(pk1 )(p0 ) L(s0 ,sk ).

guessed. Since check 3(d)
B(ck1 ). applying Lemma 5.6,
(p0 ) L(sk1 ,sk ) e0 =
path c0 ck (pk ) =

analyzing complexity modified evaluation procedure, obtain upper
bounds match lower bounds Section 4.
Theorem 5.9. 2RPQ answering
1. NL data complexity DL-LiteR ;
2. P combined complexity DL-LiteR ;
3. P combined data complexity ELH.
Proof. procedure EvalAtom involves three different types checks: consistency
check performed Step 1 entailment loop checks take place Step 3.
cost checks depends choice DL complexity measure.
Aside checks, base procedure runs non-deterministic logarithmic space
combined complexity, logarithmic space needed keep track value
count, old new values current, guesses transitions concepts.
DL-LiteR , know existing results (Calvanese et al., 2007) consistency
entailment checks performed non-deterministic logarithmic space combined
346

fiRegular Path Queries Lightweight Description Logics

complexity (and hence also data complexity). also seen table ALoop
constructed polynomial time |T | , loop checks performed
constant time |A| polynomial time w.r.t. whole input. follows
EvalAtom runs non-deterministic logarithmic space w.r.t. |A|, yielding Statement (1).
Regarding Statement (2), note EvalAtom viewed NL procedure
uses P oracle handle loop checks. Since NLP = P, yields P upper bound
combined complexity 2RPQ answering DL-LiteR . proof Statement (3)
similar. simply note input TBox formulated ELH, three types
checks performed polynomial time w.r.t. whole input (Baader et al., 2005).
Using NLP = P, may conclude EvalAtom provides polynomial-time procedure
2RPQ answering ELH.

6. Upper Bounds C2RPQs
main objective section define procedure deciding, given KB K =
(T , A), C2RPQ q(~x) arity k, k-tuple ~a individuals A, whether
match q IK (~x) = ~a. nave approach might consist guessing
mapping query variables individuals core ,A checking
match running EvalAtom algorithm ((t), (t0 )) every query atom
(t, t0 ). algorithm would properly take account paths individuals
pass anonymous part, consider matches send variables
anonymous objects, would still incomplete. particular, procedure would
return b answers Example 3.4. regain completeness, one could instead
guess matches entire domain ,A , would yield decision procedure
since latter may infinite. Moreover, since matches C2RPQs involve domain
elements arbitrarily far apart, apparent identify suitable finite
subset domain guaranteed contain match query one exists.
address challenges, procedure propose section comprises two main
steps. first step, rewrite input query q set Q C2RPQs
match q ,A (~x) = ~a match 0 q 0 Q
,A 0 (~x) = ~a. advantage rewritten queries need
consider matches 0 map query variables Ind(A). second step decides
existence restricted matches rewritten queries using EvalAtom procedure
defined Section 5.
purposes section, prove convenient work DL-LiteR TBoxes
satisfy following condition: every role name r sig(T ), exists concept


names Ar ,
r contains inclusions Ar v r, r v Ar , Ar v r , r v
Ar , inclusions involving concept names Ar Ar . Note
satisfy condition, simply choose fresh concepts Ar , Ar
role name r sig(T ) add corresponding inclusions . resulting
TBox 0 model conservative extension , hence every ABox every
C2RPQ q sig(q) (sig(T 0 ) \ sig(T )) = , cert(q, (T , A)) = cert(q, (T 0 , A)).
may therefore assume without loss generality DL-LiteR TBoxes considered
section satisfy syntactic condition. follows, use concept name
AR , R N
R , assume TBox contains inclusions AR v R R v AR .
347

fiBienvenu, Ortiz, & Simkus

6.1 Query Rewriting
aim rewrite query way need map variables
anonymous part model. draw inspiration query rewriting
procedure Horn-SHIQ introduced Eiter, Ortiz, Simkus, Tran, Xiao (2012).
main intuition follows. Suppose match q maps variable
anonymous part, variable mapped (y). modify q
way resulting query q 0 match 0 except
variables mapped (y) mapped 0 (unique) parent (y)
,A . delicate point must split atoms form (t, t0 ) {t, t0 }
parts satisfied subtree ,A |(y) , occur
(y), whose satisfaction still needs determined thus must incorporated
new query. iteration rewriting procedure, obtain query
match maps variables closer core ,A , eventually obtain
query match maps terms Ind(A).
Figure 13, implement intuition defining algorithm OneStep performs single (non-deterministic) rewriting step. illustrate functioning OneStep
following examples.
Example 6.1. Recall query q(x) = y, z. r r1 r2 r (x, y) r r (y, z) D(z)
Example 3.4, KB (T , A) Example 2.4.
illustrate rewriting algorithm, first disregard first atom consider
simpler Boolean query q1 = y, z. (y, z) D(z), NFA language r r
depicted Figure 14. figure shows match q1 (y) = e11 (z) = b.
Since leaf image q1 , want modify q1 query q10
match 0 differs 0 (y) = e1 , e1 parent
(y) = e11 . Intuitively, done using OneStep choosing Leaf = {y}
variable moved up. choose concept B holds e1 ,
enforces existence r role child e1 (namely, e11 ) e1 . Hence,
checking B holds e1 , implicitly check first r needed satisfy holds
e1 . rewriting step illustrated upper part Figure 14. Formally,
Step 1 choose Leaf = {y}. Step 2 choose r (since, intuitively,
tail concept causes everything holds e11 ). Step 3, simply take
final state s0f , atom (z, y) remains same, Step 4 nothing.
two steps simple example complex paths query
match need deeper e11 . Next, Step 5, choose B, since |= r,
is, B enforces existence node satisfies tail concept r guessed
above. Step 5b need take care atom (y, z). choose s01
Step 6, replace s01 ,s0f . Step 7, add atom B(y), output query
B(y) s01 ,s0f (y, z) D(z).
lower part figure illustrates successive application OneStep
proceed analogously, dropping second r , adding atom B(y).
results query q100 = y, z. B(y)s0f ,s0f (y, z)D(z), match 00 (z) = 00 (y) = b
ranging individuals only. Note L(s0f ,s0f ) = {} query equivalent
y.B(y) D(y).
348

fiRegular Path Queries Lightweight Description Logics

Algorithm OneStep
Input: C2RPQ q binary atoms specified NFAs, DL-LiteR ELH TBox
1. Guess non-empty set Leaf qvars(q) Leaf.
Rename variables Leaf y.
2. Guess C TCT |= C v B every atom B(y) q. Drop atoms
q.
3. atom (t, t0 ) = (S, , , s, F ) NFA {t, t0 },
Guess sequence s1 , . . . , sn1 distinct states state sn F .
Replace (t, t0 ) atoms s,s1 (t, y), s1 ,s2 (y, y), . . . , sn2 ,sn1 (y, y),
sn1 ,sn (y, t0 ).
4. Drop atoms s,s0 (y, y) C Loop [s, s0 ].
5. Guess BCT R N
R that:
(a) C = R |= v R
R NR |= v R.C

(if DL-LiteR TBox)
(if ELH TBox)

(b) atom (y, t) = (S, , , s, F ), exists s0 U N
R
(s, U , s0 ) |= R v U .
(c) atom (t, y) = (S, , , s, F ), exists s00 S, sf F ,
00
U N
R (s , U, sf ) |= R v U .
atoms form (y, y), conditions (b) (c) must satisfied.
6. Replace
atom (y, t) 6= s0 ,F (y, t)
atom (t, y) 6= s,s00 (t, y)
atom (y, y) s0 ,s00 (y, y)
s, s0 , s00 , F Step 5.
7. NC concept chosen Step 5, add D(y) q. = P chosen
concept, add AP (y) q. Output q.
Figure 13: Non-deterministic query rewriting algorithm OneStep.

Example 6.2. illustrate two rewriting steps q(x) = y, z. r r1 r2 r (x, y)
r r (y, z) D(z) (see Figure 15). First, recall match Figure 7, also
reproduced top part Figure 15. Observe (y) = e11 leaf image
. move match one step, make initial choices Example 6.1,
setting Leaf = {y} Step 1 selecting tail concept r characterises e11
349

fiBienvenu, Ortiz, & Simkus





b



r

e1 s01

c

s0f




e2

B



B v r



r

e11 s00
..
.

b

e12

z



r

s00

e1 s01

e2

B

s0 ,s0
1

e11

e12

s01

r

s0f

s01

s01 ,s0f :

z





B

f

b
e1 s01

r

s0f

B,





c

s0f




r

e2

s0 ,s0

e12

z

b

B

1

e11



r

..
.
:

B

c

s0f



f

B

B v r



..
.

c

s0f

e1

e2

s0 ,s0
f

e11

e12

z

f



..
.
s01 ,s0f :

s01

r

s0f

s0f ,s0f :

s0f

Figure 14: Two successive applications OneStep q1 = y, z. r r (y, z) D(z)
Step 2. However, path satisfies goes deeper (y) = e11 , Step 3,
need separate path parts occur e11 occur
it. choose sequence states s0 , sf correspond states
automata visits e11 , replace (x, y) s0 ,s0 (x, y) s0 ,sf (y, y). Note
intermediate query illustrated top Figure 15. Since r Loop [s0 , sf ]
(see Example 5.4), drop second atom Step 4. move similarly
above, considering simultaneously atoms s0 ,s0 (x, y) (y, z). Step 5,
choose concept B, since satisfies |= B v r. atom (y, z) choose s01
U = r (Step 5(b)) s0 ,s0 (x, y), choose s0 U = r (Step 5(c)). Step 6,
replace two query atoms s0 ,s0 (x, y) s01 ,s0f (y, z), Step 7, add atom
B(y) output resulting query s0 ,s0 (x, y) B(y) s01 ,s0f (y, z), displayed
middle Figure 15. lower part figure depicts second, similar application
OneStep outputs query match ranging individuals only.
Slightly abusing notation, use OneStep(q, ) denote set queries
output execution OneStep input (q,T ). consider set Rewrite(q, )
consisting queries obtained (q,T ) zero applications
OneStep. Formally, define Rewrite(q, ) smallest set contains initial
query q closed applications OneStep, i.e., q 0 Rewrite(q, ) q 00
OneStep(q 0 , ), q 00 Rewrite(q, ).
next proposition shows using Rewrite(q, ), reduce problem
finding arbitrary query match finding match involving ABox individuals.

350

fiRegular Path Queries Lightweight Description Logics

r




s0

b

s0

r
r

r

e1 s01

s0

c

s0f

x

r

s0 sf
r

s0 s2

e11

r
s0 ,sf :


s00

:

e111

r1

s0

s1

r2

s2

r

sf

e12

r

r1

s0 ,sf



s00

s0

s0 ,s0

e2

r
(s0 , sf )-loop

s0 ,so :

e112

z

r

s01

r

s0f



r2

e1111

s1 e1112
..
.



r Loop [s0 , s0f ], B v r,
r

x


s0


r
r

b

s0

r

e1 s01

s0

c

s0f

s0 ,so :

s0

s01 ,s0f :

s01

s0 ,s0





e2

r

s0f

B

B

e11

s0 ,s0
1

e12

..
.

z



f



B v r
r

x

B,

s0



s0

r

e1

b

c

s0f
e2

s0 ,so :

s0

s0f ,s0f :

s0f

s0 ,s0


..
.

B

s0 ,s0
f

z

f



Figure 15: Two rewriting steps q(x) = y, z. r r1 r2 r (x, y) r r (y, z) D(z)
Proposition 6.3. every satisfiable DL-LiteR ELH KB (T , A) C2RPQ q:
~a cert(q, (T , A)) exists query q 0 (~x) Rewrite(q, ) match
q 0 ,A (~x) = ~a (z) Ind(A) every variable z q 0 .
split Proposition 6.3 two lemmas, first showing completeness Rewrite,
second showing correctness.
Lemma 6.4. ~a cert(q, (T , A)), exists query q 0 (~x) Rewrite(q, )
match q 0 ,A (~x) = ~a (z) Ind(A) every variable z q 0 .
351

fiBienvenu, Ortiz, & Simkus

Proof. Consider knowledge base (T , A) canonical model ,A . every element e ,A , define distance dist(e) e core ,A follows:
dist(aR1 C1 . . . Rn Cn ) = n. Observe dist(e) = 0 implies e Ind(A). Using notion
distance, define cost match query ,A vdom() distT ,A ((v)),
dom() domain . remark match cost equal zero
case maps query variables ABox individuals.
Suppose ~a cert(q, (T , A)), match q ,A (~x) = ~a.
maps variables q Ind(A), done. Otherwise, must exist
variable (y) = eSC z vars(q) (y) proper
prefix (z). aim construct match 0 query q 0 OneStep(q, )
(c1) 0 (t) = (t) every terms(q) (t) 6= (y);
(c2) 0 (t) = e every terms(q) (t) = (y).
words, 0 essentially except maps (t) = (y)
one step closer ABox. Observe (c1) (c2) together ensure cost
0 strictly inferior cost . Thus, repeatedly applying operation,
eventually obtain query q Rewrite(q, ) match q cost zero, i.e.,
(z) Ind(A) every variable z q .
show obtain query q 0 OneStep(q, ) match 0 properties
(c1) (c2). Step 1, set Leaf = {t terms(q) | (t) = (y) = eSC}. Note
Leaf qvars(q) since eSC 6 Ind(A). define function follows: (t) =
(t) 6= (y), else (t) = y. end Step 1, query:
{B((t)) | B(t) q0 } {((t), (t0 )) | (t, t0 ) q0 }
Step 2, choose concept C (note C TCT (y) = eSC). Consider
atom B(y) present end Step 1. existence atom B(y)
end step means must existed atom B(v) q v Leaf. Since
match q, know (v) = (y) B ,A . (y) = eSC, follows
definition ,A |= C v B, required Step 2.
Next show select states s1 , . . . , sn Step 3. Consider atom (t1 , t2 )
present query start Step 3, {t1 , t2 } = (S, , , s0 , F ).
know atom (t01 , t02 ) input query q t1 = (t01 )
t2 = (t02 ). Since match q (t1 ) = (t01 ) (t2 ) = (t02 ), know
((t1 ), (t2 )) L()IT ,A . follows find path p = e0 u1 e1 . . . um em
e0 = (t1 ), em = (t2 ), (p) L(). assume without loss generality
minimal, i.e., cannot find path satisfying properties shorter length.
let j1 < . . . < jn1 indices 0 < ` < e` = (y), consider
following paths:
p1 = e0 u1 . . . uj1 ej1
pi = eji1 uji1 +1 . . . uji eji 1 < < n
pn = ejn1 ujn1 +1 . . . um em
352

fiRegular Path Queries Lightweight Description Logics

also define sequence states s1 , . . . , sn
(p1 ) L(s0 ,s1 ),
(pi ) L(si1 ,si ) 1 < n,
sn F .
Note sequence states must exist since (p) = (p1 )(p2 ) . . . (pn ) L()
start state s0 final states F . Using fact eji = (y) 1 < n,
following:
((t1 ), (y)) = ((t01 ), (y)) L(s0 ,s1 )IT ,A .
((y), (y)) L(si1 ,si )IT ,A , 2 < n.

(?)

((y), (t2 )) = ((y), (t02 )) L(sn1 ,sn )IT ,A .
aim show si 6= sj every 1 k < ` < n. Suppose contradiction
sk = s` 1 k < ` < n, consider path p0 = e0 u1 . . . ujk ejk uj` +1 ej` +1 . . . um em .
(p0 ) = u1 . . . ujk uj` +1 . . . um , u1 . . . ujk L(s0 ,sk ), uj` +1 . . . um L(s` ,sn ) = L(sk ,sn ),
sn F , follows (p0 ) L(). However, means p0 satisfies conditions p strictly shorter length, contradicting minimality assumption. Hence
states sequence s1 , . . . , sn1 must distinct. thus choose sequence
states Step 3, replace atom (t1 , t2 ) = ((t01 ), (t02 )) atoms:
s0 ,s1 ((t01 ), y), s1 ,s2 (y, y), sn2 ,sn1 (y, y), sn1 ,sn (y, (t02 )).
final choices made occur Step 5, must choose concept BCT
role R N
R conditions (a), (b), (c) satisfied. set R = (recall
(y) = eSC). e 6 Ind(A), let unique concept e = e0 P D.
Note DL-LiteR , = P . follows definition canonical
models |= v (if DL-LiteR ) |= v S.C (for ELH),
condition (a) holds. instead e Ind, definition canonical models,
together normal form ELH TBoxes, guarantees BCT
e DIT ,A |= v (if DL-LiteR ) |= v S.C (for
ELH). Note case DL-LiteR , , |= S(e) implies one following
holds: (i) concept assertion A(e) |= v S, (ii) role
assertion 0 (e, e0 ) |= 0 v S, (iii) role assertion 0 (e0 , e)
|= (S 0 ) v S. Thus, always possible choose |= D(e),
assume follows property.
remains show conditions (b) (c) verified R = S. (b),
consider binary atom (y, t) belongs query start Step 5.
know must exist atom (t01 , t02 ) q = (S, , , s0 , F )
(y, t) equal one following atoms replaced ((t01 ), (t02 )) Step 3:
s0 ,s1 ((t01 ), y), s1 ,s2 (y, y), . . . , sn2 ,sn1 (y, y), sn1 ,sn (y, (t02 )). Thus, atom
form si1 ,si (y, t). Using property (?) considering different possible values
t, infer ((y), (t)) L(si1 ,si )IT ,A , witnessed path pi =
353

fiBienvenu, Ortiz, & Simkus

eji1 uji1 +1 . . . uji eji . also know e` 6= (y) every ji1 < ` < ji . particular,
means either path pi entirely contained subtree rooted (y)
never visits element (y). former option cannot hold, since would
imply = C Loop [si , si+1 ], atom would removed
Step 4. Thus, must case first step path pi goes (y)
,A . Since
parent e. follows uji1 +1 = U U N
R (e, (y)) U
(y) = eSC, must |= v U . Since (pi ) L(si1 ,si ), must exist state
s0 (si1 , U , s0 ) uji1 +2 . . . uji L(s0 ,si ). shows condition
(b) satisfied, also (e, (t)) L(s0 ,s )IT ,A
consider condition (c). Take atom form (t, y) appears
query start Step 5. know earlier find
atom (t01 , t02 ) q (where = (S, , , s0 , F )) (t, y) equal one
following atoms replaced ((t01 ), (t02 )) Step 3: s0 ,s1 ((t01 ), y), s1 ,s2 (y, y),
. . . , sn2 ,sn1 (y, y), sn1 ,sn (y, (t02 )). follows (t, y) form si ,si+1 (t, y).
Using property (?), considering two possible values t, deduce
((t), (y)) L(si ,si+1 )IT ,A , witnessed path pi = eji1 uji1 +1 . . . uji eji . Arguing
(b), show path pi entirely contained subtree rooted
(y) path never visits element (y). former option would imply
= C Loop [si , si+1 ], atom would removed Step 5. Thus,
must case last step path e (y), uji = U
,A . Since (y) = eSC, must |= v U . Since
U N
R (e, (y)) U
(pi ) L(si ,si+1 ), also know must exist state s00 (s00 , U, si+1 )
uji1 +1 . . . uji 1 L(si ,s00 ). shows condition (c) satisfied, also
((t), e) L(si ,s00 )IT ,A . also important note = y, apply
arguments conditions (b) (c) together show (e, e) L(s0 ,s00 )IT ,A (with state
s0 (b), s00 required (c)).
let q 0 query obtain end Step 7 non-deterministic choices
made manner described. Consider mapping 0 defined follows:
0 (t) = (t) every terms(q) (t) 6= (y).
0 (t) = e every terms(q) (t) = (y).
Note mapping 0 satisfies properties (c1) (c2). remains show 0
match q 0 .
Consider first concept atom B(t) q 0 . two possibilities. Either B(t) appears
q 6 Leaf, B(t) introduced Step 7. former case, know
satisfies B(t), since 0 (t) = (t) (since 6 Leaf), true 0 . latter
case, must = either B = NC B = AP = P . B = D,
use fact 0 (t) = e chosen e DIT ,A infer
0 satisfies B(t). B = AP , e (P )IT ,A . Since ,A model

P v AP , also e APT,A , means 0 satisfies B(t).
consider atom (t0 , t00 ) q 0 . 6 {t0 , t00 }, (t0 , t00 ) q.
match q ,A , must case ((t0 ), (t00 )) L()IT ,A . Since 0 (t0 ) = (t0 )
0 (t00 ) = (t00 ), holds 0 , atom (t0 , t00 ) satisfied 0 . Next
354

fiRegular Path Queries Lightweight Description Logics

suppose {t0 , t00 }. examination Rewrite shows (t0 , t00 ) must replaced
atom Step 6. distinguish three cases:
Case 1: (t0 , t00 ) replaces si ,si+1 (y, t) 6= y. (t0 , t00 ) must form
s0 ,si+1 (y, t), s0 state chosen ensure condition (b) Step 5.
recall s0 (e, (t)) L(s0 ,si+1 )IT ,A . Since 6= y, know
6 Leaf, (t) = 0 (t). follows ( 0 (y), 0 (t)) L(s0 ,si+1 )IT ,A ,
atom (t0 , t00 ) satisfied 0 .
Case 2: (t0 , t00 ) replaces si ,si+1 (t, y) 6= y. (t0 , t00 ) must form
si ,s00 (t, y), s00 state used condition 5(c). showed earlier
examining condition (c) ((t), e) L(si ,s00 )IT ,A . Using fact
0 (t) = (t) 0 (y) = e, infer ( 0 (t), 0 (y)) L(si ,s00 )IT ,A , hence 0
satisfies atom (t0 , t00 ).
Case 3: (t0 , t00 ) replaces si ,si+1 (y, y). (t0 , t00 ) must form s0 ,s00 (y, y),
s0 state 5(b) s00 state 5(c). ( 0 (y), 0 (y)) =
(e, e) L(s0 ,s00 )IT ,A , means 0 satisfies atom (t0 , t00 ).

0

shown every atom q 0 satisfied mapping 0 , follows
match q 0 ,A , completes proof.

Lemma 6.5. ~a cert(q 0 , (T , A)) q 0 Rewrite(q, ), ~a cert(q, (T , A)).
Proof. sufficient show q 0 OneStep(q, ) ~a cert(q 0 , (T , A)), ~a
cert(q, (T , A)). Fix C2RPQ q DL-LiteR ELH TBox , let q 0 OneStep(q, )
~a cert(q 0 , (T , A)). Lemma 3.2, exists match 0 q 0 ,A
0 (~x) = ~a, ~x answer variables q 0 .
Consider execution OneStep(q, ) leads query q 0 output. Let Leaf
non-empty subset qvars(q) selected Step 1, let variable
Leaf chosen Step 1, let C TCT concept selected Step 2, let BCT
R concept role selected Step 5. Step 7, NC , D(y) added,
= P , AP (y) added. former case, know 0 (y) DIT ,A
either (i) |= v R C = R , (ii) |= v R.C, hence must exist

R-child e 0 (y) ,A Tail(e) = C. latter case, 0 (y) APT,A .
assumption DL-LiteR TBoxes, must contain inclusion AP v P . Since ,A
model , yields 0 (y) (P )IT ,A , hence 0 (y) DIT ,A . use
fact |= v R C = R find R-child e 0 (y) ,A Tail(e) = C.
define mapping : terms(q) ,A setting (t) = e every Leaf
setting (t) = 0 (t) every terms(q 0 ) \ {y}. mapping well-defined since every
term q either belongs Leaf appears q 0 . Observe (~x) = ~a since 0 (~x) = ~a
Leaf contain answer variables. aim show match q ,A .
end, consider concept atom B(t) q. First suppose Leaf.
know concept C selected Step 2 |= C v B. use fact
since Leaf, (t) = e C ,A . 6 Leaf, B(t) q 0 . 0 match
q 0 , 0 (t) B ,A . Since 0 (t) = (t), get (t) B ,A .
355

fiBienvenu, Ortiz, & Simkus

consider atom form (t, t0 ) q, = (S, , , s0 , F ).
6 Leaf t0 6 Leaf, verified (t, t0 ) q 0 . 0 match
q 0 ,A , must case ( 0 (t), 0 (t0 )) L()IT ,A . Since 0 (t) = (t)
0 (t) = (t), holds . Let us next consider interesting case
{t, t0 } Leaf 6= . Step 3, query containing ((t), (t0 )), mapping
defined follows: (t00 ) = t00 t00 6 Leaf (t00 ) = t00 Leaf. Note
since {t, t0 } Leaf 6= , least one (t) (t0 ) must y. follows Step 3,
guess sequence s1 , . . . , sn1 distinct states state sn F ,
replace ((t), (t0 )) atoms: s0 ,s1 ((t), y), s1 ,s2 (y, y), . . . , sn2 ,sn1 (y, y),
sn1 ,sn (y, (t0 )). Let us denote set atoms Q . Slightly abusing terminology,
use phrase match Q refer match Boolean query given
conjunctions atoms Q . establish following claim:
Claim 1. match Q ,A , match (t, t0 ) ,A .
Proof claim. Suppose match atoms Q ,A . means
(((t)), (y)) L(s0 ,s1 )IT ,A ,
((y), (y)) L(si ,si+1 )IT ,A every 1 < n 1,
((y), ((t0 ))) L(sn1 ,sn )IT ,A .
remark language consisting words w1 . . . wn w1 L(s0 ,s1 ),
wi L(si ,si+1 ) every 1 < n 1, wn L(sn1 ,sn ) subset language
L(s0 ,sn ), hence L(). Thus, composing paths witnessing statements preceding list, show (((t), ((t0 )) L()IT ,A . complete
proof, simply note ((t)) = (t) ((t0 )) = (t), way
defined . (end proof claim)
Claim 1, complete proof match q ,A , sufficient
show match Q , established following claim:
Claim 2. every s,s0 (u, u0 ) Q : ((u), (u0 )) L(s,s0 )IT ,A .
Proof claim. Take s,s0 (u, u0 ) Q . start case u = u0 =
C Loop [s, s0 ]. (y) = e Tail(e) = C, Tail((y)) = C.
thus apply Proposition 5.5 infer ((y), (y)) L(s,s0 )IT ,A , yields desired
result given u = u0 = y. Next suppose either u 6= y, u0 6= y, C 6 Loop [s, s0 ].
remove s,s0 (u, u0 ) Step 4, still present Step 5.
three cases depending u u0 equals y. treat case separately:
Case 1: u = u0 6= y. follows (u) = e (u0 ) = 0 (u0 ). Step 6,
replace s,s0 (u, u0 ) s00 ,s0 (u, u0 ) s00 (s, U , s00 )
0
,A , (u) = e, |=
U N
R |= R v U . Using facts ( (y), e) R
R v U , (s, U , s00 ) , infer ((u), 0 (y)) L(s,s00 )IT ,A . also
know atom s00 ,s0 (u, u0 ) belongs q 0 , must satisfied 0 ,
yields( 0 (u), 0 (u0 )) L(s00 ,s0 )IT ,A . combining ((u), 0 (y)) L(s,s00 )IT ,A
( 0 (u), 0 (u0 )) L(s00 ,s0 )IT ,A , using fact ( 0 (u), 0 (u0 )) = ( 0 (y), (u0 )),
infer ((u), (u0 )) L(s,s0 )IT ,A .
356

fiRegular Path Queries Lightweight Description Logics

Case 2: u 6= u0 = y. follows (u) = 0 (u) (u0 ) = e. Step 6,
replace s,s0 (u, u0 ) atom s,s00 (u, u0 ) s00 (s00 , U, s0 )
U N
R |= R v U . Using similar arguments Case 1, show
((u), 0 (y)) L(s,s00 )IT ,A ( 0 (y), (u0 )) L(s00 ,s0 )IT ,A ,
deduce ((u), (u0 )) L(s,s0 )IT ,A .
Case 3: u = u0 = y. follows (u) = (u0 ) = e. Step 6, replace
s,s0 (u, u0 ) atom s00 ,s000 (u, u0 ) s00 , s000 (s, U , s00 )
0
(s00 , U 0 , s0 ) roles U, U 0 N
R |= R v U |= R v U . applying similar reasoning used Cases 1 2, show ((u), 0 (y))
L(s,s00 )IT ,A , ( 0 (y), 0 (y)) L(s00 ,s000 )IT ,A , ( 0 (y), (u0 )) L(s000 ,s0 )IT ,A .
this, infer ((u), (u0 )) L(s,s0 )IT ,A .
Together, Lemmas 6.4 6.5 establish Proposition 6.3. remark number
possible atoms appearing queries Rewrite(q, ) polynomially bounded
|q| + |T |. key property used show following:
Proposition 6.6. exponentially many queries Rewrite(q, ),
size polynomial |q| + |T |.
Proof. Consider DL-LiteR ELH TBox , C2RPQ q, q 0 Rewrite(q, ). first
note OneStep never introduces fresh variables, vars(q 0 ) vars(q). next note
OneStep introduce fresh concept names, introduces binary
atoms whose NFAs obtained one original NFAs changing initial
finite states. Thus, every atom q 0 takes one following forms:
A(v), NC sig(T ) v vars(q)
s,s0 (v, v 0 ), appears q, s, s0 states , v, v 0 vars(q)
easy see number atoms bounded polynomially |T | + |q|,
thus, single-exponentially many distinct queries Rewrite(q, ).
6.2 Query Evaluation
Figure 16, present non-deterministic algorithm EvalQuery C2RPQ answering
DL-LiteR ELH. algorithm starts checking whether input KB satisfiable.
check succeeds, algorithm guesses query Rewrite(q, ) variable
assignment calls evaluation algorithm3 EvalAtom Section 5 check whether
assignment yields match query IK . following proposition establishes
correctness EvalQuery.
Proposition 6.7. every C2RPQ q, DL-LiteR ELH KB K = (T , A), tuple
individuals ~a Ind(A) arity q: ~a cert(q, K)
execution EvalQuery(q, K, ~a) returns yes.
3. check KB satisfiability first step EvalQuery, may skip satisfiability checks
calls EvalAtom.

357

fiBienvenu, Ortiz, & Simkus

Algorithm EvalQuery
Input: C2RPQ q(x1 , . . . , xk ), DL-LiteR ELH KB K = hT , Ai, tuple ~a Ind(A)k
1. Test whether K satisfiable, output yes not.
2. Guess q 0 Rewrite(q, ) assignment ~b individuals qvars(q 0 ).
(a) Let q 00 query obtained substituting ~a (x1 , . . . , xk ) ~b qvars(q 0 ),
replacing atom form B(a) atom B? (a) B?
NFA L(B? ) = {B?} consisting initial state sB
0 , single final state
B
B
B
sf , single transition (s0 , B?, sf ).
(b) every atom (a, b) q 00
check EvalAtom(, K, (a, b)) = yes
(c) checks succeed, return yes.
3. Return no.
Figure 16: Non-deterministic C2RPQ answering algorithm EvalQuery.
Proof. Let ~x set answer variables q.
show first direction, consider execution EvalQuery input (q, K, ~a)
returns yes. algorithm returns yes Step 1, K unsatisfiable, trivially
~a cert(q, K). Otherwise, Step 2, algorithm guess query q 0 Rewrite(q, )
assignment ~b quantified variables ~y q 0 . Let q 00 query obtained
substituting ~a ~x ~b ~y , writing atoms form (a, b) NFA.
Step 2(c), every atom (a, b) q 00 , call EvalAtom input (, K, (a, b)). Since
algorithm returns yes Step 3, must case calls return yes,
Proposition 5.8, (a, b) cert(q, K) every atom (a, b) q 00 . follows
mapping sending ~x ~a ~y ~b defines match q 0 IK , ~a cert(q 0 , K).
Applying Proposition 6.3, obtain ~a cert(q, K).
Next suppose ~a cert(q, K). K unsatisfiable, algorithm return
yes Step 1. Otherwise, know Proposition 6.3 exists query q 0
Rewrite(q, ) match q 0 ,A maps variables Ind(A)
(~x) = ~a. Step 2, choose query q 0 tuple (~y ), ~y set
quantified variables q 0 . Let q 00 query obtained substituting ~a ~x ~b ~y ,
writing atoms form (a, b) NFA. match know
(a, b) cert(q, K) every atom (a, b) q 00 . follows Proposition 5.8
calls EvalAtom return yes, EvalQuery return yes Step 2(c).
analyzing complexity algorithm EvalQuery, obtain following upper
bounds C2RPQ answering, match lower bounds given Section 4.
Theorem 6.8. C2RPQ answering
1. NL data complexity DL-LiteR DL-LiteRDFS ;
358

fiRegular Path Queries Lightweight Description Logics

2. P data complexity ELH;
3. NP combined complexity DL-LiteRDFS ;
4. PSpace combined complexity DL-LiteR ELH.
Proof. Statement (1), consider resources required run EvalQuery input
(T , A, q), formulated DL-LiteR . consistency check Step 1
performed non-deterministic logarithmic space |A| (Calvanese et al., 2007). q
treated fixed, computing Rewrite(q, ) requires constant time (and space)
|A|. follows guessed query q 0 tuple ~b set atoms end
Step 2(a) stored using logarithmic space |A|. Step 2(b), call EvalAtom
stored atoms. Theorem 5.9, EvalAtom runs non-deterministic logarithmic
space |A|. Since NLNL = NL, obtain desired NL upper bound data complexity.
show Statement 2, consider happens input TBox formulated ELH.
case, consistency check Step 1 takes constant time (since every ELH KB
satisfiable), Theorem 5.9, EvalAtom runs polynomial time |A|. thus
decision procedure C2RPQ answering ELH runs non-deterministic logarithmic
space |A| access P oracle. Since NLP = P, yields membership P
data complexity.
establish Statement (3), first note DL-LiteRDFS TBox,
query cannot rewritten, i.e., Rewrite(q, ) = {q} (we cannot choose required
Step 5 Algorithm OneStep entail inclusions form v R).
Thus, Step 2 EvalQuery, need guess tuple ~b whose size polynomial |A|
|q|. calls EvalAtom Step 2(b) run polynomial time input (Theorem
5.2), overall procedure runs NP.
Statement (4), instead computing whole set Rewrite(q, ), contain
exponentially many queries, generate single q 0 Rewrite(q, ) non-deterministically.
Proposition 6.6, every query Rewrite(q, ) generated exponentially many steps, use polynomial-size counter check reached
limit. Since rewritten query polynomial size (Proposition 6.6), keep
one query memory time, generation single query Rewrite(q, ) requires
polynomial space. proceed statement 3, guessing (polynomialsize) tuple ~b performing polynomial number polynomial-time evaluation checks
(Theorem 5.9). yields non-deterministic polynomial space procedure deciding
~a cert(q, (T , A)). Using well-known fact NPSpace = PSpace, obtain
desired PSpace upper bound.
6.3 Cases Lower Complexity
Given substantial jump combined complexity NP PSpace moving
CQs C(2)RPQs, natural look interesting subcases offer lower complexity. pinpoint two subcases, first obtained restricting query language,
second obtained restricting class KBs.
359

fiBienvenu, Ortiz, & Simkus

Let us recall 2RPQs single-atom C2RPQs contain quantified variables. following theorem shows restriction inessential, complexity
results 2RPQs hold also single-atom queries quantified variables.4
Theorem 6.9. results Theorem 5.9 hold also single-atom C2RPQs.
Proof. Fix DL-LiteR ELH KB K = (T , A). six types single-atom queries
consider: y. (a, y) (with individual), y. (x, y) (with x answer variable),
y. (y, a) (with individual), y. (y, x) (with x answer variable), x, y. (x, y)
(with x 6= y), y. (y, y). first five types queries, simple reductions
2RPQs. q = x, y. (x, y) (with x 6= y), simply replace q 2RPQ
q 0 (x, y) = 0 (x, y),



L(0 ) = (N
R sig(T )) L() (NR sig(T )) .

following claim establishes correctness reduction.
Claim. K |= q cert(q 0 , K) 6= .
Proof claim. First suppose K |= q. K unsatisfiable, trivially
cert(q 0 , K) 6= . Otherwise, match q IK . means ((x), (y))
L()IK , must exist path p0 (x) (y) (p0 ) L(). Let
(x) either equal begins a, let p1 path
(x). Since (y) reachable (x), must also reachable a,
find path p2 (y) a. may choose p1 p2 (p1 ) (p2 ) belong

(N
R sig(T )) . combining paths p1 , p0 p2 (in order), obtain path



whose label belongs (N
R sig(T )) L() (NR sig(T )) . follows
0
(a, a) cert(q , K).
Suppose next (a, b) cert(q 0 , K) two (not necessarily distinct) individuals a, b.
K unsatisfiable L(), trivially K |= q. Otherwise, path p =



e0 u1 e1 u2 . . . un en IK e0 = a, en = b, (p) (N
R sig(T )) L()(NR sig(T )) .
Since 6 L(), exists 0 < < j n ui . . . uj1 L(). setting
(x) = ei1 (y) ej , obtain match q IK . (end proof claim)
four types queries containing distinct terms handled similarly:
y. (x, y), use 2RPQ q 00 (x, y) = 00 (x, y), L(00 ) = L() (N
R
sig(T )) . Arguing claim, show b cert(y. (x, y), K) iff (b, c)
cert(q 00 (x, y), K) c Ind(A).
y. (a, y), K |= y. (a, y) iff cert(y. (x, y), K), reuse
2RPQ preceding point.

y. (y, x), use 2RPQ q 000 (x, y) = 000 (y, x) L(000 ) = (N
R sig(T ))
L(). Using similar argument used preceding claim, show
b cert(y. (y, x), K) iff (b, c) cert(q 000 (x, y), K) c Ind(A).

4. preliminary version paper, fact used general notion single-atom queries
(possibly quantified variables) definition 2RPQs (Bienvenu et al., 2013).

360

fiRegular Path Queries Lightweight Description Logics

y. (y, a), K |= y. (y, a) iff cert(y. (y, x), K), reuse
2RPQ preceding point.
queries form x. (x, x), proof involved passes definition
alternative rewriting procedure 2RPQs, similar spirit algorithm
Rewrite guaranteed run polynomial time. Details given appendix.
interestingly, adapt techniques preceding proof order
provide NP upper bound class C2RPQ contain existential-join
variables, i.e., existentially quantified variables occur query.
Theorem 6.10. C2RPQ answering NP combined complexity DL-LiteR
ELH knowledge bases restricted C2RPQs without existential-join variables.
Proof. Consider DL-LiteR ELH KB K = (T , A) C2RPQ q answer variables
~x existential variables ~y every variable ~y occurs exactly q. let
q 0 C2RPQ obtained q follows:
Replace every atom (y1 , y2 ) y1 , y2 existential variables



atom 0 (y1 , y2 ) L(0 ) = (N
R sig(T )) L() (NR sig(T )) .
Replace every atom (t, y) existential variable individual

answer variable atom 00 (t, y) L(00 ) = L() (N
R sig(T )) .
Replace every atom (y, t) existential variable individual

answer variable atom 000 (y, t) L(000 ) = (N
R sig(T )) L().
Add ~y set answer variables.
Clearly, takes polynomial time construct C2RPQ q 0 . exploiting fact
every existential variable q occurs once, applying similar reasoning
used proof Theorem 6.9, show ~a cert(q, K) iff (~a, ~b) cert(q 0 , K)
tuple individuals ~b arity ~y . decide whether latter holds,
non-deterministically guess tuple ~b let variable assignment maps ~x
~a ~y ~b. use EvalAtom verify ((t1 ), (2 )) cert((t1 , t2 ), K)
every atom (t1 , t2 ) q 0 , return yes case. Correctness described
procedure follows correctness EvalAtom (Proposition 5.8). Since EvalAtom
implemented run polynomial time DL-LiteR ELH (Theorem 5.9),
obtain NP procedure answering C2RPQs without existential-join variables.
preceding result extended bit allow simple chains existential variables. Indeed, remark C2RPQ q contains atoms 1 (x, y) 2 (y, z)
z existential-join variable existential variable appearing two
atoms, replace {1 (x, y), 2 (y, z)} 3 (x, z) L(3 ) = {w1 w2 | w1
L(1 ), w2 L(2 )} (such NFA 3 easily constructed 1 , 2 polynomial time).
performing similar polynomial-time equivalence-preserving transformations,
eliminate existential-join variables thereby enlarge class C2RPQs
handled using NP procedure.
361

fiBienvenu, Ortiz, & Simkus

Finding interesting classes computationally well-behaved queries likely
prove difficult, given PSpace lower bound Section 4 shown hold even
strong structural restrictions C2RPQs. suggests may fruitful consider restrictions knowledge bases. next proposition identifies natural
restriction knowledge bases leads improved NP upper bound.
Theorem 6.11. C2RPQ answering NP combined complexity DL-LiteR
ELH knowledge bases whose canonical models finite domains.
Proof. Let K = (T , A) satisfiable DL-LiteR ELH knowledge base whose canonical
model IK contains finitely many elements (note K unsatisfiable,
trivial perform query answering). follows construction IK fact IK
finite every element aR1 C1 . . . Rn Cn IK Ci 6= Cj 6= j,
implies particular n |TCT | (indeed, Ci = Cj < j, domain ,A
would contain element aR1 C1 . . . Rj Cj (Ri+1 Ci+1 . . . Rj Cj )m every 0). rely
property devise non-deterministic algorithm deciding ~a cert(q, K)
runs polynomial time combined size inputs.
Without loss generality, may suppose input query q contains binary
atoms form (t, t0 ) NFA. first step, guess mapping terms
q sequences form aR1 C1 . . . Rn Cn Ri role, Ci concept
TCT , 0 n |TCT |. second step, verify indeed match q.
First, check (b) = b every individual b q, (~x) = ~a ~x
tuple answer variables q. Next, check whether (z) ,A every z qvars(q).
done polynomial number (polynomial-time) entailment checks
verify conditions (A) (B) definition canonical models Section 2.1.4.
remains check query atoms satisfied mapping . end,
construct new ABox follows. Let E set containing aR1 C1 . . . Rj Cj
1 j n aR1 C1 . . . Rj Cj . . . Rn Cn range .
introduce fresh individual name e E , let ABox obtained
adding following assertions:
R(a, ) R NR R (be , a) R NR e = aRC E NI
R(be , be0 ) R NR R (be0 , ) R NR , e0 = eRC E e E
C(be0 ) e0 = eRC E e E NI C NC
Define mapping 0 terms q individuals follows: 0 (t) = (t)
(t) Ind(A) 0 (t) = b(t) otherwise. every atom (t, t0 ) q, call EvalAtom
input (, (T , ), ( 0 (t), 0 (t0 ))); Theorem 5.9, calls needs polynomial
time. output yes case every call EvalAtom returns yes.
clear algorithm described runs non-deterministic polynomial
time. show algorithm sound, consider execution algorithm
returns yes, let mapping guessed. Since algorithm returned
yes, know every atom (t, t0 ) q, successful execution EvalAtom
input (, (T , ), ( 0 (t), 0 (t0 ))). Since EvalAtom known correct (Theorem 6.7),
shows 0 match q ,A . follows way defined
construction canonical models ,A homomorphically embedded ,A .
Moreover, choose homomorphism h h(be ) = e new
362

fiRegular Path Queries Lightweight Description Logics

individuals . Since matches C2RPQs preserved homomorphisms,
follows match q ,A (~x) = ~a, ~a cert(q, (T , A)).
show completeness, suppose match q ,A . construction,
homomorphism h ,A ,A maps every individual Ind(A)
every e E individual . Using fact query matches preserved
homomorphisms, 0 match q ,A . follows every atom
(t, t0 ) q, execution EvalAtom (, (T , ), ( 0 (t), 0 (t0 ))) returns
yes, algorithm returns yes guessing mapping .
point class knowledge bases considered Theorem 6.11 practical relevance. Indeed, several important large-scale ELH terminologies, like medical
ontology SNOMED5 , acyclic terminologies (see, e.g., (Haase & Lutz, 2008)),
guaranteed finite canonical models. Moreover, recently argued
real-world DL-LiteR ontologies often yield canonical models shallow depth (Kikot,
Kontchakov, Podolskii, & Zakharyaschev, 2013).

7. Beyond C2RPQs Lightweight DLs
section, discuss implications results give brief overview
related results similar settings.
7.1 Extensions C2RPQs
argued paper C2RPQs provide significantly expressiveness
plain CQs languages querying ontologies, moderate computational cost. However,
C2RPQs also many limitations, several application domains seem call even
expressive query languages. discuss extensions C2RPQs.
7.1.1 Complex Labels
preliminary version present work, added C2RPQs ability talk
combinations concepts roles appear along path (Bienvenu, Ortiz, & Simkus,
2012). language, called C2RPQs complex labels, one use,
example, expression (sbLFT sbLFSub) find paths stations served
low-floor tramway subway. Complex labels provide concise flexible syntax many queries, fact increase expressiveness C2RPQs.
particular DLs support role conjunction, like ones considered here,
standard C2RPQs query pairs stations connected two different
means transport, cannot require existence one route
fully served both. algorithms described paper extended straightforwardly C2RPQs complex labels, given complexity results apply also
expressive query language. However, extension complex labels causes
significant overhead notation technicalities algorithms. Hence,
sake readability, decided include extension paper.
5. http://www.ihtsdo.org/snomed-ct/

363

fiBienvenu, Ortiz, & Simkus

7.1.2 RPQs Nesting
Recent works database field advocate extension RPQs nesting, allowing
one require objects along path satisfy complex conditions, turn expressed
(nested) 2RPQs, line XML query language XPath. RPQs nesting
proposed basic component navigational language nSPARQL RDF
(Perez, Arenas, & Gutierrez, 2010) received attention setting
graph databases (Reutter, 2013; Barcelo, Perez, & Reutter, 2012).
Building conference version work, recently studied query answering
problem nested (C)2RPQs presence DL ontologies (Bienvenu, Calvanese, Ortiz,
& Simkus, 2014). establish tight complexity bounds data combined complexity
variety DLs, ranging lightweight DLs DL-Lite EL considered
present paper, highly expressive DLs. show adding nesting (C)2RPQs
increase worst-case data complexity query answering, leads ExpTimehardness combined complexity, even (non-conjunctive) 2RPQs lightweight
DLs DL-Lite EL. contrasts sharply tractability result obtained
paper setting without nesting.
authors considered nested navigational queries DL KBs. Stefanoni,
Motik, Krotzsch, Rudolph (2014) studied complexity answering certain types
nested path queries knowledge bases formulated OWL 2 EL, extends
ELH number constructs, notably complex role inclusions. establish
PSpace membership query language roughly corresponds nested (C)RPQs
mentioned earlier extended unary complex labels, show P membership
non-conjunctive fragment. results demonstrate nesting computationally
simpler inverse roles allowed neither queries, ontology language.
Kostylev, Reutter, Vrgoc (2015) recently investigated complexity socalled DLXPath family query languages knowledge bases expressed lightweight
DLs, particular emphasis connection propositional dynamic logic (PDL)
effects negation. expressive variant DLXPath used test
Boolean conditions nodes edges (and thus fully captures complex labels
previous subsection), unfortunately, answering queries undecidable even
simplest settings. Disallowing negation binary relations restores decidability,
query answering remains coNP-hard data complexity negation unary expressions
permitted. finally note Bourhis, Krotzsch, Rudolph (2014) recently explored several highly expressive extensions RPQs nesting query answering
remains decidable presence DL ontologies.
7.1.3 Path Variables Path Relations
area graph databases, argued C2RPQs sometimes weak
since neither output witnessing paths, talk relationships holding
different paths. motivated recent extension C2RPQs path
variables relations among tuples paths (Barcelo et al., 2012; Barcelo & Munoz,
2014). introduction path variables makes possible refer specific paths
(or precisely, labels paths) used witness satisfaction
query atoms. using path variable multiple atoms, one enforce paths
364

fiRegular Path Queries Lightweight Description Logics

label used connect different pairs points. Moreover, path variables
appear answer variables query, case compact representation
labels witnessing paths given output (Barcelo et al., 2012). extension
allows queries enforce tuple path labels belongs given relation, either via
regular relations prefix equal length (Barcelo et al., 2012), using common
non-regular relations like subword subsequence (Barcelo & Munoz, 2014).
in-depth study extensions presence DL ontologies ongoing work,
preliminary results suggest addition ontological knowledge makes things
significantly harder. instance, even presence simple DL-Lite ontologies,
labels paths witnessing query answer may form non-regular language, illustrated
following example.
Example 7.1. Consider DL-Lite KB K consisting TBox {A v R, R v R}
ABox {A(a)}, let q 2RPQ E(x, y) E = r (r ) . infinitely
many paths witnessing (a, a) answer q IK , obtained taking n steps
away via r, n steps back via r . follows set labels
witnessing paths forms non-regular language {rn (r )n | n 0}.
previous example crucially uses inverse roles, non-regular (indeed, non-contextfree!) languages also enforced using shared path variables:
Example 7.2. Consider EL KB K consisting TBox {A v r.A, v s.A}
ABox {A(a)}. Let q Boolean CRPQ x, y, z. E(x, y) E(y, z) E(x, z)
E = (r s) , suppose use path variables require label
path x label path z. every triple
paths (pxy , pyz , pxz ) witnessing satisfaction q (pxy ) = (pyz )
(pxz ) = (pxy )(pyz ). follows set labels witnessing paths third
atom yields language {ww | w L((r s) )}, neither regular context-free.
examples may seem artificial, highlight difficulties arise
combining path variables ontologies. particular, demonstrate cannot
use NFAs compact representation path labels (as case graph databases),
even path variables existentially quantified, sharing path variables
likely require significant modification query answering algorithms. Interestingly,
seems techniques based word equations regular constraints
recently explored handling non-regular path relations (Barcelo & Munoz, 2014) may
relevant presence ontologies already answering queries (existentially
quantified) path variables, possibly also simple regular relations.
7.2 DLs
rewriting algorithm C2RPQs inspired technique first proposed answering
CQs DL Horn-SHIQ (Eiter et al., 2012), extended constructs
logic. fact, similar algorithm nested C2RPQs already developed
DL ELHI subsumes DL-LiteR ELH (Bienvenu et al., 2014). ELHI
contains many constructors Horn-SHIQ, behave similarly terms
computational complexity. point transitive roles, often problematic
365

fiBienvenu, Ortiz, & Simkus

query answering algorithms, major issue setting. easily accommodated ELHI algorithm combining known techniques axiomatizing
TBox transitivity roles, machinery handling transitive closure
constructor queries. extension algorithm ELHI Horn-SHIQ runs
polynomial time size data, thus worst-case optimal data complexity. Naturally, combined complexity, may require exponential time cases,
always runs single-exponential time, worst-case optimal
DLs. Moreover, conjecture implemented smartly, exponential behavior
rarely occur real-world ontologies.
7.3 OWL 2 Profiles Query Answering Semantic Web
Web Ontology Language family languages specifying ontologies, endorsed
standard W3C. current version standard, called OWL 2 (OWL Working
Group, 2009), features three profiles (Motik et al., 2012) sublanguages restrict
expressivity way logical inference ontologies achieved efficient
algorithms. three profiles provide different modeling capabilities, making suitable
different applications: EL profile preferred language life science ontologies,
QL profile geared towards applications enrich relational data ontological
information, RL profile used mostly reasoning Web data.
information profiles, modeling capabilities supported inference services,
refer reader introductory text Krotzsch references therein (Krotzsch,
2012). EL DL-Lite families lightweight description logics studied present
paper provide logical underpinnings EL QL profiles (the third profile, RL,
based upon Datalog). consequence, results immediately relevant
problem answering regular path queries OWL 2 knowledge bases formulated using
QL EL profiles. particular, algorithms adapted querying datasets,
RDF triplestores, enriched ontological knowledge expressed fragments
profiles correspond DL-LiteR ELH.

8. Conclusion Future Work
paper, provided algorithms tight complexity bounds answering various forms regular path queries knowledge bases formulated lightweight DLs
DL-Lite EL families. results demonstrate query answering problem
richer query languages often much harder CQs IQs typically considered. Indeed, DL-LiteR ELH, query answering remains tractable
data complexity PSPACE combined complexity highly expressive class
C2RPQs, 2RPQs, even retain tractability combined complexity.
computational price seem high, particularly consider rich navigational features queries partially compensate limited expressiveness
lightweight ontology languages. thus believe C2RPQs constitute promising
language ontology-mediated query answering.
important challenge future work implement experimentally evaluate
developed algorithms. Although C2RPQs natural query language aim at,
believe makes sense start prototype implementation algorithm
366

fiRegular Path Queries Lightweight Description Logics

(2)RPQs. Indeed, algorithm (2)RPQs significantly lower
worst-case complexity, also considerably simpler rewriting-based approach
C2RPQs, confident easily translated practical procedure.
contrast, rewriting algorithm used establish PSpace upper bound C2RPQs
involves considerable amount non-determinism, nave implementation
expected perform poorly. nonetheless believe proposed rewriting approach,
suitably modified avoid unnecessary non-deterministic guesses, provides good
basis development practical methods C2RPQ answering. Finally, identifying
restrictions queries ontologies lead lower combined complexity
another interesting problem future study.

Acknowledgments
authors would like thank anonymous reviewers careful reading
paper many helpful comments. work supported French
National Research Agency (ANR) project PAGODA 12-JS02-007-01, Austrian Science
Fund (FWF) project T515, FWF project P25518 Vienna Science Technology Fund (WWTF) project ICT12-015.

Appendix A. Proof Theorem 6.9
complete proof Theorem 6.9, must show handle queries form
x. (x, x). seem simple reduction 2RPQs queries
form, propose instead approach based upon query rewriting.
define new query rewriting algorithm prove correctness, require
following notion. Given two concepts C, BCT , say C causes w.r.t.
TBox , denoted C D, every ABox model A,
C 6= implies DI 6= . difficult see checking C feasible
polynomial time:
Lemma A.1. following problem P: given DL-LiteR ELH TBox
concepts C, BCT , decide whether C D.
Proof. start case DL-LiteR TBox. easy see C
iff |= C v exists sequence role names R1 , . . . , Rn
|= C v R1 ,
|= Rn v D,
1 < n, |= Ri v Ri+1 .
observe existence sequence R1 , . . . , Rn satisfying conditions
decided polynomial time (i) initializing set Reach roles R1
|= C v R1 , (ii) saturating Reach adding role Reach whenever |= U v
U Reach, (iii) checking whether U Reach |=
U v D. Since TBox reasoning tractable DL-LiteR , procedure
described performed polynomial time.
Assume ELH TBox. C iff |= C v exists
sequence concepts r1 .A1 , . . . , rn .An , {A1 , . . . , } NC ,
367

fiBienvenu, Ortiz, & Simkus

|= C v r1 .A1 ,
|= v D,
1 < n, |= Ai v ri+1 .Ai+1 .
existence sequence r1 .A1 , . . . , rn .An satisfying conditions decided polynomial time, using saturation procedure analogus one used DLLiteR (recall TBox reasoning tractable ELH).
Figure 17, present deterministic query rewriting algorithm PolyRewrite takes
input NFA DL-LiteR ELH TBox outputs set queries,
denoted PolyRewrite(, ). case Section 6, purpose query rewriting
ensure need consider query matches map answer variables
ABox individuals. Since interested queries form x. (x, x), turns
aside trivial rewriting (x, x), sufficient consider rewritings
forms C(x) C(x) s1 ,s2 (x, x) C basic concept s1 s2 states
. Step 1, initialize Frontier tuples (C, s0 , sf ) C basic concept,
s0 initial state , sf final state. Then, iteration loop,
remove tuple (C, s1 , s2 ) Frontier add Visited record already
examined. C Loop [s1 , s2 ], corresponding query C(x) s1 ,s2 (x, x)
equivalent (under ) simpler query C(x), add Q queries D(x)
ensure x. C(x) holds. C 6 Loop [s1 , s2 ], add corresponding query
C(x) s1 ,s2 (x, x) Q. next add Frontier unvisited tuples (D, s5 , s6 )
match D(x) s5 ,s6 (x, x) maps x e implies existence match
C(x) s1 ,s2 (x, x) maps x child e anonymous part. operation
intuitively moves query match one step closer ABox viewed
analogue Steps 6 7 algorithm Rewrite Section 6.
simple inspection algorithm PolyRewrite reveals tuple BCT
examined once, |BCT | |S|2 iterations
loop Step 2. Since know loop, entailment, causation checks
carried polynomial time, obtain following:
Lemma A.2. algorithm PolyRewrite runs polynomial time || |T |, hence
PolyRewrite(, ) contains polynomial number queries.
next two lemmas establish correctness rewriting procedure.
Lemma A.3. , |= x. (x, x), exists query q(x) PolyRewrite(, )
match ,A (x) Ind(A).
Proof. Suppose , |= x. (x, x), let match x. (x, x) ,A .
(x) Ind(A), statement trivially holds since (x, x) added Q Step 1.
Thus, suppose (x) 6 Ind(A). start proving following claim, captures
query matches anonymous part canonical model moved closer
individuals:
Claim: Suppose (C, s1 , s2 ) added Frontier point execution
PolyRewrite input (, ). suppose C 6 Loop [s1 , s2 ], match
s1 ,s2 (x, x) ,A (x) = dRC ,A . tuple
368

fiRegular Path Queries Lightweight Description Logics

Algorithm PolyRewrite(, )
Input: NFA = (S, , , s0 , F ), DL-LiteR ELH TBox
1. Set Q = {(x, x)}, Visited = , Frontier = {(C, s0 , sf ) | C BCT , sf F }.
2. Frontier 6=
(a) Move tuple (C, s1 , s2 ) Frontier Visiteda .
(b) C Loop [s1 , s2 ],
every BCT



C, add D(x) Q.

(c) C 6 Loop [s1 , s2 ],
Add C(x) s1 ,s2 (x, x) Q.
4
every tuple (D, R, s3 , s4 , s5 , s6 ) BCT N
R
C Loop [s1 , s3 ] C Loop [s4 , s2 ],
|= v R C = R [DL-LiteR ] |= v R.C [ELH ],
exist roles R0 , R00 |= R v R0 , |= R v R00 , (s3 , R0 , s5 ) ,
(s6 , R00 , s4 ) ,
(D, s5 , s6 ) 6 (Frontier Visited),
add (D, s5 , s6 ) Frontier.
3. Output Q.
a. choose least tuple Frontier according arbitrary lexicographic ordering BCT SS.
note however particular choice tuple affect output procedure.

Figure 17: Query rewriting algorithm PolyRewrite.

(D, s5 , s6 ) added Frontier point query D(x) s5 ,s6 (x, x)
match 0 0 (x) = d, |= v R.C, either Ind(A) Tail(d) = D.
Proof claim. Suppose (C, s1 , s2 ) satisfy conditions claim. Since
(x) = dRC, follows definition canonical models concept
BCT DIT ,A either |= v R C = R (if formulated
DL-LiteR ), |= v R.C (for ELH TBox). Moreover, may choose
= Tail(d) 6 Ind(A). also know match s1 ,s2 (x, x),
exists path p = e0 u1 e1 u2 . . . un en e0 = en = (x) whose label (p) belongs
L(s1 ,s2 ). Since (p) L(s1 ,s2 ), find sequence states s00 s01 . . . s0n s00 = s1
s0n = s2 every 1 n, (s0i1 , ui , s0i ) . C 6 Loop [s1 , s2 ],
know match fully contained within ,A |(x) . Thus, must least
one occurrence parent (x) path p. Let ej ek respectively first
last occurrences p (if single occurrence d, j = k). Observe
ej1 = ek+1 = (x). Set s3 = s0j1 , s4 = s0k+1 , s5 = s0j , s6 = s0k . paths
e0 u1 e1 . . . uj1 ej1 ek+1 uk+2 ek+2 . . . un en witness ((x), (x)) L(s1 ,s3 )IT ,A
((x), (x)) L(s4 ,s2 )IT ,A . paths e0 . . . ej1 ek+1 . . . en begin end (x)
369

fiBienvenu, Ortiz, & Simkus

fully contained within ,A |(x) , obtain C Loop [s1 , s3 ] C Loop [s4 , s2 ].
Finally, know definiton paths construction canonical model
must exist roles R0 , R00 |= R v R0 , |= R v R00 , (s3 , R0 , s5 ) ,
(s6 , R00 , s4 ) .
assumption, tuple (C, s1 , s2 ) added Frontier point,
eventually selected Step 2. Moreover, since C 6 Loop [s1 , s2 ], enter 2(c)
examining (C, s1 , s2 ). shown above, know tuple
(D, R, s3 , s4 , s5 , s6 ) satisfies first three requirements for-loop Step 2(c).
fourth requirement also holds, means (D, s5 , s6 ) added Frontier,
fails, triple already added Frontier earlier
execution algorithm. complete proof claim, remark path
ej uj+1 . . . uk ek witnesses (d, d) L(s5 ,s6 )IT ,A . Moreover, seen DIT ,A .
follows setting 0 (x) = d, obtain match query D(x) s5 ,s6 (x, x)
required properties. (end proof claim)
Observe 0 described claim exists, 0 (x) parent (x)
canonical model ,A . finalize proof. Indeed, since (x) 6 Ind(A),
(x) = dRC R N
R C BCT . match (x, x), must also
match s0 ,sf (x, x) sf F . Step 1, tuple (C, s0 , sf ) added
Frontier. Repeated applications claim either yield query q(x) PolyRewrite(, )
match mapping x ABox, result insertion tuple (D, s1 , s2 )
Frontier D(x)s1 ,s2 (x, x) match ,A Loop [s1 , s2 ]. latter
case, let match D(x) s1 ,s2 (x, x), let Ind(A) (x) ,A |a .
follows definition canonical models E BCT
E E ,A . Thus, match E(x) PolyRewrite(, )
maps x Ind(A).
Lemma A.4. q(x) PolyRewrite(, ) match q(x) ,A (x)
Ind(A), , |= x. (x, x).
Proof. simplify presentation introduce notion containment Boolean queries
w.r.t. TBox. Given TBox two Boolean queries q1 , q2 , write q1 q2
every ABox , |= q1 implies , |= q2 . slight abuse notation
allow q1 q2 contain atoms form R(x). occurrence R(x)
query q shorthand R(x, y) variable occurs q.
start establishing following claim:
Claim: (C, s1 , s2 ) added Frontier point execution PolyRewrite
input (, ), x. C(x) s1 ,s2 (x, x) x. (x, x).
Proof claim. proof induction precedence relation obtained setting
(C, s, s0 ) (D, s00 , s000 ) tuple (D, s00 , s000 ) added Frontier examination
tuple (C, s, s0 ). base case, tuples (C, s0 , sf ) inserted
Step 1. Every tuple form (C, s0 , sf ), sf F , thus trivially
x. C(x) s0 ,sf (x, x) x. (x, x). Next suppose already shown
property (C, s1 , s2 ), let (D, s5 , s6 ) (C, s1 , s2 ) (D, s5 , s6 ).
suppose match D(x) s5 ,s6 (x, x) ,A . find path
p0 = e0 u1 e1 u2 . . . un en e0 = en = (x) (p) L(s5 ,s6 ). follows
370

fiRegular Path Queries Lightweight Description Logics

must exist sequence states s00 s01 . . . s0n s00 = s5 s0n = s6
every 1 n, (s0i1 , ui , s0i ) . (C, s1 , s2 ) (D, s5 , s6 ), must exist
tuple (D, R, s3 , s4 , s5 , s6 ) (D, s5 , s6 ) added Frontier examining
(D, R, s3 , s4 , s5 , s6 ). know tuple must satisfied four conditions,
must
|= v R C = R [DL-LiteR ] |= v R.C [ELH ],
C Loop [s1 , s3 ] C Loop [s4 , s2 ],
exist roles R0 , R00 |= R v R0 , |= R v R00 , (s3 , R0 , s5 ) ,
(s6 , R00 , s4 ) .
first point, element (x)RC belongs canonical model, second
point, find paths p1 = e00 . . . u0m e0m p2 = e000 . . . u00` e00` e00 = e000 = e0m =
e00` = (x)RC, (p1 ) L(s1 ,s3 ), (p2 ) L(s4 ,s2 ). Using third point,
show path p = p1 R0 p0 R00 p2 (p ) L(s1 ,s2 ). Since p begins
ends (x)RC (x)RC C ,A , follows , |= x. C(x) s1 ,s2 (x, x).
induction hypothesis, x. C(x) s1 ,s2 (x, x) x. (x, x), must also
, |= x. (x, x). establishes desired containment x. D(x) s5 ,s6 (x, x)
x. (x, x). (end proof claim)
suppose match q(x) PolyRewrite(, ) ,A (x)
Ind(A). three possibilities. first q(x) = (x, x), case
trivially , |= x. (x, x). next possibility q(x) = x. C(x) s,s0 (x, x),
case apply preceding claim show , |= x. (x, x). final
possibility q(x) = D(x), case must (C, s, s0 )
Frontier C Loop [s, s0 ] x. D(x) x. C(x). case,
x. D(x) x. C(x), x. C(x) x. C(x) s,s0 (x, x) (since C Loop [s, s0 ]),
x. C(x) s,s0 (x, x) x. (x, x) (by claim). Putting statements together,
obtain x. D(x) x. (x, x), yields , |= x. (x, x).
complete argument, observe queries output PolyRewrite either
2RPQs take form C(x) C(x)s,s0 (x, x), queries latter forms trivially
transformed 2RPQs. follows answer query form x. (x, x)
(i) computing set PolyRewrite(, ), (ii) using EvalAtom check, 2RPQ
0 (x, x) obtained PolyRewrite(, ), whether cert(0 (x, x), (T , A)) 6= . Correctness
procedure follows Proposition 5.8 Lemmas A.3 A.4, complexity
bounds follow Lemma A.2 Theorem 5.9.

References
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations Databases. Addison-Wesley.
Arora, S., & Barak, B. (2009). Computational Complexity - Modern Approach. Cambridge
University Press.
Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). DL-Lite family
relations. Journal Artificial Intelligence Research (JAIR), 36, 169.
371

fiBienvenu, Ortiz, & Simkus

Baader, F., Brandt, S., & Lutz, C. (2005). Pushing EL envelope. Proceedings
Nineteenth International Joint Conference Artificial Intelligence (IJCAI 2005).
Bala, S. (2002). Intersection regular languages star hierarchy. Proceedings
Twenty-Ninth International Colloquium Automata, Languages Programming
(ICALP 2002).
Barcelo, P. (2013). Querying graph databases. Proceedings Thirty-Second Symposium Principles Database Systems (PODS 2013).
Barcelo, P., Libkin, L., Lin, A. W., & Wood, P. T. (2012). Expressive languages path
queries graph-structured data. ACM Transactions Database Systems (TODS),
37 (4), 31.
Barcelo, P., & Munoz, P. (2014). Graph logics rational relations: role word
combinatorics. Proceedings Twenty-Ninth Annual ACM/IEEE Symposium
Logic Computer Science (LICS 2014).
Barcelo, P., Perez, J., & Reutter, J. L. (2012). Relative expressiveness nested regular
expressions. Proceedings Sixth Alberto Mendelzon International Workshop
Foundations Data Management (AMW 2012).
Berglund, A., Boag, S., Chamberlin, D., Fernandez, M. F., Kay, M., Robie, J., & Simeon,
J. (2007). XML Path Language (XPath) 2.0. W3C Recommendation. Available
http://www.w3.org/TR/xpath20/.
Bienvenu, M., Calvanese, D., Ortiz, M., & Simkus, M. (2014). Nested regular path queries
description logics. Proceedings Fourteenth International Conference
Principles Knowledge Representation Reasoning (KR 2014).
Bienvenu, M., Ortiz, M., & Simkus, M. (2012). Answering expressive path queries
lightweight DL knowledge bases. Proceedings Twenty-Fifth International
Workshop Description Logics (DL 2012).
Bienvenu, M., Ortiz, M., & Simkus, M. (2013). Conjunctive regular path queries
lightweight description logics. Proceedings Twenty-Third International Joint
Conference Artificial Intelligence (IJCAI 2013).
Bourhis, P., Krotzsch, M., & Rudolph, S. (2014). best nest regular path queries.
Proceedings Twenty-Seventh International Workshop Description Logics
(DL 2014).
Brickley, D., & Guha, R. (2014). RDF Schema 1.1. W3C Recommendation. Available
http://www.w3.org/TR/rdf-schema/.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Data
complexity query answering description logics. Proceedings Tenth
International Conference Principles Knowledge Representation Reasoning
(KR 2006).
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning efficient query answering description logics: DL-Lite family.
Journal Automated Reasoning, 39 (3), 385429.
372

fiRegular Path Queries Lightweight Description Logics

Calvanese, D., De Giacomo, G., & Lenzerini, M. (1998). decidability query containment constraints. Proceedings Seventeenth Symposium Principles Database Systems (PODS 1998).
Calvanese, D., Eiter, T., & Ortiz, M. (2007). Answering regular path queries expressive
description logics: automata-theoretic approach. Proceedings TwentySecond AAAI Conference Artificial Intelligence (AAAI 2007).
Calvanese, D., Eiter, T., & Ortiz, M. (2009). Regular path queries expressive description logics nominals. Proceedings Twenty-First International Joint
Conference Artificial Intelligence (IJCAI 2009).
Calvanese, D., Eiter, T., & Ortiz, M. (2014). Answering regular path queries expressive
description logics via alternating tree-automata. Information Computation, 237,
1255.
Consens, M. P., & Mendelzon, A. O. (1990). GraphLog: visual formalism real life
recursion. Proceedings Ninth Symposium Principles Database Systems
(PODS 1990).
Ehrenfeucht, A., & Zeiger, P. (1974). Complexity measures regular expressions.
Proceedings Sixth Annual ACM Symposium Theory Computing (STOC
1974).
Eiter, T., Ortiz, M., Simkus, M., Tran, T., & Xiao, G. (2012). Query rewriting HornSHIQ plus rules. Proceedings Twenty-Sixth AAAI Conference Artificial
Intelligence (AAAI 2012).
Florescu, D., Levy, A., & Suciu, D. (1998). Query containment conjunctive queries
regular expressions. Proceedings Seventeenth Symposium Principles
Database Systems (PODS 1998).
Haase, C., & Lutz, C. (2008). Complexity subsumption EL family description logics: Acyclic cyclic TBoxes. Proceedings Eighteenth European
Conference Artificial Intelligence (ECAI 2008).
Harris, S., & Seaborne, A. (2013). SPARQL 1.1 Query Language. W3C Recommendation.
Available http://www.w3.org/TR/sparql11-query/.
Kikot, S., Kontchakov, R., Podolskii, V. V., & Zakharyaschev, M. (2013). Query rewriting
shallow ontologies. Proceedings Twenty-Sixth International Workshop
Description Logics (DL 2013).
Kostylev, E. V., Reutter, J. L., & Vrgoc, D. (2015). XPath DL ontologies. Proceedings
Twenty-Ninth AAAI Conference Artificial Intelligence (AAAI 2015).
Kozen, D. (1977). Lower bounds natural proof systems. Proceedings Eighteenth
Annual Symposium Foundations Computer Science (SFCS 1977).
Krisnadhi, A., & Lutz, C. (2007). Data complexity EL family DLs. Proceedings
Twentieth International Workshop Description Logics (DL 2007).
Krotzsch, M. (2012). OWL 2 Profiles: introduction lightweight ontology languages.
Proceedings Eighth Reasoning Web Summer School (RW 2012).
373

fiBienvenu, Ortiz, & Simkus

Krotzsch, M., & Rudolph, S. (2007). Conjunctive queries EL composition roles.
Proceedings Twentieth International Workshop Description Logics (DL
2007).
Levy, A. Y., & Rousset, M. (1996). limits combining recursive Horn rules
description logics. Proceedings Thirteenth National Conference Artificial
Intelligence Eighth Innovative Applications Artificial Intelligence Conference
(AAAI 96).
Lutz, C. (2008). complexity conjunctive query answering expressive description
logics. Proceedings Fourth Joint Conference Automated Reasoning (IJCAR
2008).
Motik, B., Cuenca Grau, B., Horrocks, I., Wu, Z., Fokoue, A., & Lutz, C. (2012). OWL 2
Web Ontology Language Profiles. W3C Recommendation. Available http://www.
w3.org/TR/owl2-profiles/.
Ortiz, M. (2013). Ontology based query answering: story far. Proceedings
Seventh Alberto Mendelzon International Workshop Foundations Data Management (AMW 2013).
Ortiz, M., Rudolph, S., & Simkus, M. (2011). Query answering Horn fragments
description logics SHOIQ SROIQ. Proceedings Twenty-Second
International Joint Conference Artificial Intelligence (IJCAI 2011).
Ortiz, M., & Simkus, M. (2012). Reasoning query answering description logics.
Proceedings Eighth Reasoning Web Summer School (RW 2012).
Ortiz, M., & Simkus, M. (2014). Revisiting hardness query answering expressive
description logics. Proceedings Eighth International Conference Web
Reasoning Rule Systems (RR 2014).
OWL Working Group, W. (2009). OWL 2 Web Ontology Language: Document Overview.
W3C Recommendation. Available http://www.w3.org/TR/owl2-overview/.
Perez, J., Arenas, M., & Gutierrez, C. (2010). nSPARQL: navigational language RDF.
Journal Web Semantics, 8 (4), 255270.
Reutter, J. L. (2013). Containment nested regular expressions. CoRR, abs/1304.2637.
Rosati, R. (2007). conjunctive query answering EL. Proceedings Twentieth
International Workshop Description Logics (DL 2007).
Stefanoni, G., Motik, B., Krotzsch, M., & Rudolph, S. (2014). complexity answering
conjunctive navigational queries OWL 2 EL knowledge bases. Journal
Artificial Intelligence Research (JAIR), 51, 645705.
Thompson, K. (1968). Regular expression search algorithm. Communications ACM,
11 (6), 419422.

374

fiJournal Artificial Intelligence Research 53 (2015) 127-168

Submitted 1/15; published 6/15

Clause Elimination SAT QSAT
Marijn Heule

MARIJN @ CS . UTEXAS . EDU

Department Computer Science,
University Texas Austin, USA

Matti Jarvisalo

MATTI . JARVISALO @ CS . HELSINKI . FI

HIIT, Department Computer Science,
University Helsinki, Finland

Florian Lonsing

FLORIAN . LONSING @ TUWIEN . AC .

Institute Information Systems,
Vienna University Technology, Austria

Martina Seidl
Armin Biere

MARTINA . SEIDL @ JKU .
BIERE @ JKU .

Institute Formal Models Verification,
Johannes Kepler University Linz, Austria

Abstract
famous archetypical NP-complete problem Boolean satisfiability (SAT) PSPACEcomplete generalization quantified Boolean satisfiability (QSAT) become central declarative programming paradigms real-world instances various computationally hard
problems efficiently solved. success achieved several breakthroughs
practical implementations decision procedures SAT QSAT, is, SAT QSAT
solvers. Here, simplification techniques conjunctive normal form (CNF) SAT
prenex conjunctive normal form (PCNF) QSATthe standard input formats SAT QSAT
solvershave recently proven effective increasing solver efficiency applied
(i.e., preprocessing) (i.e., inprocessing) satisfiability search.
article, develop analyze clause elimination procedures pre- inprocessing.
Clause elimination procedures form family (P)CNF formula simplification techniques
remove clauses specific (in practice polynomial-time) redundancy properties maintaining satisfiability status formulas. Extending known procedures tautology,
subsumption, blocked clause elimination, introduce novel elimination procedures based
asymmetric variants techniques, also develop novel family so-called covered
clause elimination procedures, well natural liftings CNF-level procedures PCNF.
analyze considered clause elimination procedures various perspectives. Furthermore,
variants preserving logical equivalence clause elimination, show reconstruct solutions original CNFs satisfying assignments simplified CNFs, important practical applications procedures. Complementing theoretical analysis,
present results empirical evaluation practical importance clause elimination procedures terms effect solver runtimes standard real-world application benchmarks.
turns importance applying clause elimination procedures developed work
empirically emphasized context state-of-the-art QSAT solving.

c
2015
AI Access Foundation. rights reserved.

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

1. Introduction
Boolean satisfiability (SAT) problem determining whether given propositional logic formula solution. SAT become important declarative approach formulate solve
various NP-hard problemsa general coverage modern satisfiability research provided
Biere, Heule, van Maaren, Walsh (2009). Contrasting classical worst-case view NPcompleteness intractability (Cook, 1971; Garey & Johnson, 1979), central success
SAT-based approach major advances robust implementations decision procedures SAT,
i.e., SAT solvers. Modern SAT solvers routinely used vast number different industrial
artificial intelligence applications (Claessen, Een, Sheeran, & Sorensson, 2008; Marques-Silva,
2008), giving rise high demand new techniques improving robustness
efficiency current state-of-the-art SAT solvers.
SAT archetypical problem NP, quantified Boolean satisfiability (QSAT) problem
evaluating quantified Boolean formulas (QBF), well-known extension SAT, archetypical PSPACE, offering powerful framework modelling large range important
computational problems artificial intelligence, knowledge representation, verification, synthesis (Benedetti & Mangassarian, 2008). last decade, much effort spent
development efficient QSAT solvers. Despite several success stories, much research effort
needed QSAT solving reach level maturity modern SAT solvers. Due wide
range possible QSAT applications, developing efficient QSAT solver technology indeed
important on-going quest. major part quest lift techniques proven effective SAT
solving general framework QSAT solving analyze impact.
Simplification techniques applied (i.e., preprocessing) search
proven integral enabling efficient conjunctive normal form (CNF) level SAT solving realworld application domains. Indeed, large body work preprocessing CNF formulas (Freeman, 1995; Le Berre, 2001; Lynce & Marques-Silva, 2001; Bacchus, 2002; Ostrowski,
Gregoire, Mazure, & Sas, 2002; Brafman, 2004; Subbarayan & Pradhan, 2005; Gershman & Strichman, 2005; Een & Biere, 2005; Van Gelder, 2005; Fourdrinoy, Gregoire, Mazure, & Sas, 2007a,
2007b; Jin & Somenzi, 2005; Han & Somenzi, 2007; Piette, Hamadi, & Sas, 2008; Jarvisalo, Biere,
& Heule, 2010; Manthey, Heule, & Biere, 2013; Heule, Jarvisalo, & Biere, 2013b) based on,
examples, variable elimination equivalence reasoning. Further, many SAT solvers rely
mainly Boolean constraint propagation (that is, unit propagation) search, possible
improve solving efficiency applying additional simplification techniques also search.
dynamic interplay simplification search captured inprocessing SAT solving
paradigm (Jarvisalo, Heule, & Biere, 2012b). Inprocessing SAT solvers recently shown
push efficiency SAT solving, witnessed example L INGELING (Biere,
2013), one successful SAT solvers recent SAT Competitions (Jarvisalo, Le Berre,
Roussel, & Simon, 2012; SAT Competitions Organizing Committee, 2014). Importantly,
scheduling combinations simplification techniques search, even quite simple ideas,
removal subsumed clauses, bring additional gains enabling simplifications
techniques.
Motivated impact preprocessing SAT, preprocessors QSAT started
emerge, proven advantageous evaluation representative QSAT benchmarks (Samulowitz, Davies, & Bacchus, 2006; Bubeck & Kleine Buning, 2007; Giunchiglia, Marin, & Narizzano, 2010; Mangassarian, Le, Goultiaeva, Veneris, & Bacchus, 2010; Pigorsch & Scholl, 2010).
128

fiC LAUSE E LIMINATION



SAT



QSAT

fact, high promise achieving advances efficiency QSAT solvers
adding stronger simplification techniques solving flow. Intuitively, due fact
that, light simplification preprocessing techniques, real-world SAT QSAT instances
tend notably differ size characteristics. Real-world application SAT instances still solvable state-of-the-art SAT solvers today contain tens millions variables
clauses (Jarvisalo et al., 2012), restricts use theoretically interesting polynomial-time
simplification techniques practical applications due shear size input CNF formulas
solvers must able cope with. contrast, QSAT instances often relatively small, language QBF enables succinct encodings via quantification. Despite small
size, QBFs challenging state-of-the-art solvers solve. Hence room
successful applications computationally intensive (but still polynomial-time) simplification
rules. Inprocessing QSAT hardly considered far; solver TRU Q (Pulina &
Tacchella, 2009) combines search-based solving variable elimination may considered
step direction.
focus article preprocessing simplification techniques SAT QSAT
solving. work motivated one hand possibilities improving SAT QSAT
solving efficiency integrating additional simplification techniques solving process
and/or search, hand understanding relationships
different simplification techniques. Especially, concentrate developing analyzing clause
elimination procedures CNF (for SAT) PCNF formulas (for QSAT)the standard input
formats SAT QSAT solvers.
Clause elimination procedures form specific family simplification techniques focus
removing redundant clauseswith respect specific redundancy propertiesfrom CNF formulas satisfiability-preserving way. precisely, clause elimination procedure based
redundancy property P procedure which, given CNF (or PCNF) formula F , removes iteratively fixpoint F clauses P . well-defined redundancy property
P , holds clause C P (P)CNF formula F , F F without C
satisfiability-equivalent. words, F satisfiable whenever F without C satisfiable.
However, general redundancy property, simply requiring satisfiability-equivalence clause elimination, applicable practice, since checking whether clause C redundant
property co-NP-complete (Liberatore, 2005). connection practically relevant
clause elimination procedures, context work specific interest clause elimination procedures based polynomial-time checkable redundancy properties. simple
examples context SAT, two well-known redundancy properties tautology
subsumption. corresponding clause elimination procedures tautology elimination subsumption elimination (Een & Biere, 2005). sophisticated redundancy property blocked
clauses (Kullmann, 1999) allows blocked clause elimination (Ostrowski et al., 2002; Jarvisalo
et al., 2010).
extensions known procedures, work introduce novel elimination procedures
based asymmetric variants techniques. asymmetric variants, clause CNF
first augmented certain literals satisfiability CNF preserved. original
clause replaced augmented one. augmented clause turns redundancy
property, eliminated CNF. Otherwise, original clause restored. also
develop novel family so-called covered clause elimination procedures. applications
129

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

general setting QSAT, develop natural liftings CNF-level procedures PCNF,
turn outnaturallyto somewhat involved.
analyze resulting clause elimination procedures various perspectives. One property reduction power, is, ability remove clauses thus reduce size CNF
formula. relative reduction power two clause elimination procedures reveals potential
strengths procedures, subject practical realizations powerful procedures
fast enough speed total solving time. Another orthogonal property consider BCPpreservance, is, ability preserve possible unit propagations also done
original CNF. BCP-preservance amounts question whether different clause elimination procedures maintain arc consistency clausal level w.r.t. original CNF formula.
third property consider, confluence, implies procedure unique fixpoint; practical realizations, knowledge whether simplification procedure confluent interest.
non-confluent procedures, well-working elimination-ordering heuristics developed.
fourth property consider whether procedures maintain logical equivalence respect
original CNF, is, preserve set satisfying assignments. Maintaining logical equivalence
often necessary applications single solution sought for. However,
simplification techniques maintain satisfiability logical equivalence, important develop algorithms fast reconstruction satisfying assignment original CNF
assignment simplified instance. Motivated this, variants preserve logical equivalence, show efficiently reconstruct solutions original CNFs
satisfying assignments simplified CNFs.
Complementing analysis properties relationships considered clause
elimination procedures, also provide empirical results practical implications clause
elimination procedures terms runtime improvements state-of-the-art SAT QSAT
solvers real-world application benchmarks. empirical results show clause elimination procedures developed work clear positive effect performance various
state-of-the-art QSAT solvers, impact performance inprocessing SAT solving
less announced.
rest article organized follows. preliminaries SAT, QSAT, related necessary concepts (Section 2), present overview results properties
clause elimination procedures (Section 3). Technical analysis clause elimination procedures
SAT QSAT presented Sections 46, followed section solution reconstruction (Section 7). concluding, results empirical evaluation procedures
presented Section 8.
article extends thoroughly revises work presented earlier 17th International Conference Logic Programming, Artificial Intelligence Reasoning (LPAR 2010) (Heule,
Jarvisalo, & Biere, 2010, 2013a) 23rd International Conference Automated Deduction (CADE 2011) (Biere, Lonsing, & Seidl, 2011). variants quantified covered clause
elimination (in Section 6) published previously detail. Further, model reconstruction variants covered clause elimination (in Section 7) new. Compared earlier
publications, empirical evaluation presented article extended updated
recent state-of-the-art solvers benchmarks. Definitions clause elimination procedures, related analysis, updated better reflect current insights
procedures. Furthermore, discussions, examples, background extended.
130

fiC LAUSE E LIMINATION



SAT



QSAT

2. Preliminaries
section review necessary background concepts: Boolean satisfiability, resolution, Boolean
constraint propagation, well counterpart general context quantified Boolean
formulas.
2.1 Boolean Satisfiability
Boolean variable x, two literals, positive literal, denoted x, negative
literal, denoted x. clause disjunction literals CNF formula conjunction
clauses. clause seen finite set literals CNF formula finite set clauses.
set literals occurring CNF formula F denoted lits(F ). unit clause contains
exactly one literal. clause tautology contains x x variable x. Given
CNF formula F , clause C1 F subsumes (another) clause C2 F F C1 C2 .
C2 subsumed C1 .
truth assignment CNF formula F function maps variables F {t, f}.
(x) = v, (x) = v, = f f = t. clause C satisfied (l) =
l C. assignment satisfies F satisfies every clause F . assignment falsifies
clause C assigns literals occur C f.
Two CNF formulas logically equivalent set satisfying assignments
common variables.
2.1.1 R ESOLUTION



BCP

classical resolution proof system (Robinson, 1965) CNF formulas consists resolution
rule, states that, given two clauses C1 C2 l C1 l C2 , clause C =
(C1 \ {l}) (C2 \ {l}), called resolvent C1 C2 , inferred resolving literal
l. denoted C = C1 l C2 . resolution rule forms complete proof system
SAT, also important inference rule used preprocessing CNF formulas.
Boolean constraint propagation (BCP) unit propagation based applying unit resolution,
i.e., special case resolution rule one clauses C1 C2 unit clause.
BCP central propagation mechanism applied within typical DPLL CDCL-based SAT
solvers. CNF formula F , BCP propagates unit clauses, is, repeats following
fixpoint:
unit clause (l) F , remove F \ {(l)} clauses contain
literal l, remove literal l clauses F .
resulting formula referred BCP(F ). easy see BCP unique fixpoint
CNF formula. words, BCP confluent.
(l) BCP(F ) unit clause (l)
/ F , say BCP F assigns literal l


(and literal l f). (l), (l) BCP(F ) literal l
/ F (or, equivalently, BCP(F )),
say BCP derives conflict F . notational convenience, partial assignment
variables F , let BCP(F, ) := BCP(F F ), = {(x) | (x) = t}
F = {(x) | (x) = f}. words, BCP(F, ) denotes formula obtained adding F unit
clauses corresponding variable assignments .
131

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

2.2 Quantified Boolean Formulas
quantified Boolean formula G prenex conjunctive normal form (PCNF) structure .F
quantifier prefix propositional matrix F conjunctive normal form. quantifier
prefix ordered partition Q1 . . . Qn variables F . size quantifier prefix
= Q1 . . . Qn , denoted ||, |Q1 | + . . . + |Qn |. element Qi called scope
quantifier block. function quant(Qi ) assigns either universal quantifier existential
quantifier scope Qi way quant(Qi ) 6= quant(Qi+1 ). convenience also
write Qx1 , . . . , xn scope = {x1 , . . . , xn } quant(S) = Q Q {, }.
quantifier level variable x x Qi i, i.e., one plus number preceding scopes.
following, assume variable F occurs exactly prefix. say
variable x universal (existential) QBF .F x quant(S) = (quant(S) = ).
notions literals, clauses, tautologies follow SAT. function var(l) returns x
l form x x. l = x l = x else l = x. literal l var(l) S, quant(l) =
quant(S). clause C, existential universal literals given LQ (C) = {l C |
quant(l) = Q} Q {, }. literals l, l var(l) Qi var(l ) Qj , l l j.
Let G = .F QBF l literal. G[l] denotes QBF obtained G
deleting clause C l C, removing occurrence l, substituting scope
Qi var(l) Qi Qi \{var(l)}.
truth value QBF G = .F recursively defined follows.
F = G satisfiable, F G unsatisfiable.
quant(Q1 ) = x Q1 , G satisfiable iff G[x] G[x] satisfiable.
quant(Q1 ) = x Q1 , G satisfiable iff G[x] G[x] satisfiable.
definition QBF semantics indicates ordering variables prefix impacts
truth value formula. prefix ordering introduces ordering variables
variable x assigned variable x < y. restriction specific
QBF apply propositional logic variables assigned order.
following example illustrates consequences swapping quantifiers.
Example 1. QBF G = xy.((x y) (x y)) satisfiable, whereas QBF G =
yx.((x y) (x y)) obtained G swapping x prefix unsatisfiable.
Intuitively, semantics QBF also considered two-player game (Schaefer, 1978)
existential player universal player. former controls existentially quantified
variables goal satisfy formula latter controls universally quantified variables goal falsify formula. moves performed according order
variables quantifier prefix left right. Obviously, universal player takes
advantage CNF structure, conflicts easily detected. reduce bias
preserving benefits CNF, approaches realizing duality-aware reasoning presented (Zhang, 2006; Klieber, Sapra, Gao, & Clarke, 2010; Goultiaeva & Bacchus, 2013; Goultiaeva, Seidl, & Biere, 2013; Sabharwal, Ansotegui, Gomes, Hart, & Selman, 2006).
2.2.1 QBF ODELS
context QSAT different definitions models (satisfying assignments).
choice one particular definition motivated actual application underlying formal
132

fiC LAUSE E LIMINATION



SAT



QSAT

framework. theoretical setting, satisfiability models QBFs presented sets Skolem
functions (Kleine Buning & Bubeck, 2009). Skolem function fy models values existential
variable take satisfy matrix respect universal variables depends.
general, Skolem function fy one particular unique. Replacing fy produces
semantically equivalent formula. definition satisfiability models theoretical foundation certificate extraction QBFs resolution proofs (Balabanov & Jiang, 2011; Niemetz,
Preiner, Lonsing, Seidl, & Biere, 2012). context game-based view QBF semantics, similar approach extracting winning strategies introduced Goultiaeva, Van Gelder,
Bacchus (2011). approach directly produce Skolem functions symbolic skolemization (Benedetti, 2005a) implemented verify results solver K IZZO (Benedetti, 2005b).
Skolem function extraction so-called QRAT proofs recently proposed Heule, Seidl,
Biere (2014b).
certain applications related preprocessing QSAT, necessary explicitly distinguish
variable assignments satisfy matrix. Recursive semantics satisfiability models
coarse hence suitable purpose. Instead, tree-like models QBFs
applied (Samer, 2008; Samulowitz et al., 2006). tree-like model, every path root
tree leaf comprises variable assignment satisfies matrix. Assignments
universal variables reflected branches tree. Tree-like models formal foundation
preprocessing techniques QSAT hyper binary resolution (Samulowitz et al., 2006)
failed literal detection (Van Gelder, Wood, & Lonsing, 2012) also relevant theoretical
work dependency schemes (Samer, 2008).
different notions models give rise different definitions equivalence theory
QSAT. analogy SAT, equivalence two QBFs G1 G2 checked comparing
sets tree-like models G1 G2 , respectively. explicit comparison impossible
recursive semantics applied. example, definition recursive semantics (Kleine Buning
& Bubeck, 2009) distinguishes different assignments free variables QBF,
i.e., variables occur matrix explicitly quantified prefix.
paper, consider closed QBFs without free variables.
Two QBFs G G satisfiability-equivalent following holds: G satisfiable G satisfiable. simplicity, context QSAT write equivalent
instead satisfiability-equivalent.
2.2.2 Q-R ESOLUTION
Many techniques used SAT transferred QSAT certain adaptions preserve soundness. following, introduce techniques important rest
paper.
defining Q-resolution (Kleine Buning, Karpinski, & Flogel, 1995), lifting resolution
rule QSAT, first review concept universal reduction (UR) (Kleine Buning et al., 1995;
Cadoli, Giovanardi, & Schaerf, 1998).
Definition 1. universally reduced clause C obtained clause C applying universal
reduction fixpoint, i.e.,
C := C\{l C | quant(l) = , l C quant(l ) = l < l }.
133

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

removal universally quantified literal l clause contain existentially quantified literals higher level l called universal reduction.
easily shown application universal reduction confluent preserves
satisfiability formula, provided applied non-tautological clauses only. Based
universal reduction rule, Q-resolution combination resolution propositional logic
universal reduction.
Definition 2. Q-resolvent C1 l C2 two non-tautological clauses C1 C2 l C1 ,
l C2 , quant(l) = defined (C \ {l}) (C \ {l}) C C universally
1
2
1
2
reduced clauses obtained C1 C2 , respectively. literal l called pivot element.
construction rule Q-resolvents, enhanced universal reduction rule, forms
quantified resolution calculus sound refutationally-complete QSAT (Kleine Buning
et al., 1995): QBF G unsatisfiable empty clause derived G
Q-resolution universal reduction. combining universal reduction (as Definition 1)
Q-resolution (as Definition 2), restriction Q-resolution non-tautological clauses crucial
soundness, following example shows.
Example 2. Consider satisfiable QBF G = ax.C1 C2 , C1 = (a x)
C2 = (x). Universal reduction cannot reduce literals C1 C2 . Furthermore, C1 C2
Q-resolvent since C1 tautological. restriction Q-resolution non-tautological
clauses ignored, Q-resolvent C1 C2 C = C1 x C2 = (aa). Universal reduction
reduces C empty clause, erroneously determines G unsatisfiable.
2.2.3 U NIT



P URE L ITERALS



QSAT

unit literal rule QSAT, part definition BCP QSAT (QBCP) given
following, obtained extending SAT QSAT follows. variable unit literal
required existentially quantified, universal reduction immediately reduces clause
containing universal literal empty clause. taking universal reduction account,
arrive following rule unit propagations QSAT.
Definition 3. existentially quantified literal l unit QBF G = .F {l, l1 , . . . , lm } F
quant(li ) = l < li . l unit G, G equivalent G[l].
Obviously, QBF G contains non-tautological clause universally quantified literals
only, G unsatisfiable. Note unit literal elimination allows ignore quantifier ordering evaluation, i.e., assign variable member outermost quantifier
block.
Another important rule allowing assign variable occurring outermost quantifier
block quantified pure literal elimination.


Definition 4. literal l pure QBF G = Q1 . . . Qn .F l CF l 6 CF . G
equivalent G[l] quant(l) = equivalent G[l] quant(l) = .
addition unit propagation BCP SAT defined, QSAT-specific variant BCP (QBCP) includes quantified pure literal elimination universal reduction (UR) applied fixpoint. elimination universal pure literals universal reduction increase
134

fiC LAUSE E LIMINATION



SAT



QSAT

deductive power QBCP. words, successive application rules together
unit propagation allows identify unit clauses would missed unit propagation
applied.

3. Overview Contributions
section, give overview main results. overview, present several
important definitions basic clause elimination techniques. Further, introduce several measures
comparison, notion relative reduction power, allow detailed analysis
various techniques.
3.1 Clause Elimination Procedures SAT QSAT
Generally speaking, clause elimination procedure based redundancy property P procedure which, given CNF (or PCNF) formula F , removes iteratively fixpoint F clauses
P . well-defined redundancy property P , hold clause
C P (P)CNF formula F , F F \ {C} satisfiability-equivalent. connection
practically relevant clause elimination procedures, context work specific interest clause elimination procedures based polynomial-time checkable redundancy
properties. simple examples context SAT, two well-known redundancy properties tautology subsumption, give corresponding clause elimination procedures
tautology elimination subsumption elimination.
Definition 5 (Tautology Elimination). given formula F , tautology elimination (TE) repeats
following fixpoint: tautological clause C F , let F := F \ {C}. CNF
formula resulting applying TE F denoted TE(F ).
Definition 6 (Subsumption Elimination). given formula F , subsumption elimination (SE)
repeats following fixpoint: subsumed clause C F , let F := F \ {C}.
CNF formula resulting applying SE F denoted SE(F ).
third earlier definedbut somewhat involvedpolynomial-time checkable redundancy
property clause blocked1 (Kullmann, 1999), gives corresponding technique blocked clause elimination (BCE). Blocked clause elimination recently shown
surprisingly effective simulating various structure-based simplification mechanisms purely
CNF-level (Jarvisalo, Biere, & Heule, 2012a), motivating technique
theoretical practical perspectives.
Definition 7 (Blocked Clause Elimination SAT). Given CNF formula F , clause C,
literal l C, literal l blocks C w.r.t. F clause C F l C , C (C \ {l})
tautology. Given CNF formula F , clause C blocked w.r.t. F literal blocks
C w.r.t. F . CNF formula F , blocked clause elimination (BCE) repeats following
fixpoint: blocked clause C F w.r.t. F , let F := F \ {C}. CNF formula resulting
applying BCE F denoted BCE(F ).
1. Kullmann defines blocking literal l C literal holds resolvents C l l
tautologies. definition slightly different implies binary tautologies blocked clauses, contrast
Kullmanns definition. Apart detail, two definitions equivalent.

135

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Example 3. Consider following CNF formula, structure often observed CNF
encodings graph coloring problems. formula encodes graph two vertices v w
edge using three colors. variable vi (or wi ) interpretation vertex
v (or w) gets color i.
FBCE = (v1 v2 v3 ) (w1 w2 w3 ) (v1 w1 ) (v2 w2 ) (v3 w3 )
(v1 v2 ) (v1 v3 ) (v2 v3 ) (w1 w2 ) (w1 w3 ) (w2 w3 ).
first two clauses encode v w least one color. next three clauses force v
w cannot color. last six clauses denote v w one color.
easy check last six clauses blocked FBCE , since clauses,
two literals block clause. Thus BCE remove last six binary clauses
FBCE . Thus formula BCE(FBCE ) include at-most-one-color constraints
nodes v w, hence, contrast FBCE , BCE(FBCE ) satisfying assignments
v w assigned multiple colors. However, given satisfying assignment, simple
linear-time algorithm (see Section 7 details) reconstructing satisfying assignment FBCE ,
i.e., assignment v w assigned single color.
work, focus total eight different clause elimination procedures CNF formulas well PCNF formulas, based clause elimination techniques remove tautological,
subsumed, blocked, covered clauses. elimination techniques, consider
plain well call asymmetric variant. (plain) tautology elimination (TE),
introduce asymmetric tautology elimination (ATE). (plain) subsumption elimination (SE),
asymmetric variant ASE, (plain) blocked clause elimination (BCE), asymmetric variant ABCE, respectively. Additionally, develop novel family (including plain
(CCE) asymmetric (ACCE) variants) so-called covered clause elimination procedures.
context QSAT, propose natural liftings CNF-level clause elimination procedures.
redundancy properties tautology subsumed corresponding CNF-level clause
elimination procedures directly applicable ignoring quantifier prefix, PCNF-level procedures based properties blocked covered require care necessary take
quantifier prefix account.
Due somewhat involved definitions, postpone definitions clause elimination procedures based covered property Section 6 analyze procedures detail.
Similarly, liftings blocked covered clause elimination procedures QSAT defined
Sections 5 6, respectively. However, let us already define concept asymmetric clause
elimination procedures, generalizing (plain) clause elimination procedure. motivated
fact that, shown, asymmetric variants achieve simplification
plain procedures.
asymmetric variant clause elimination technique relies clause extension rule
asymmetric literal addition (ALA).
Definition 8 (Asymmetric Literal Addition). Given clause C CNF formula F , literal l
asymmetric literal clause C exist clause C Fl \ {C} C \ {l} subsumes
C. clause C CNF formula F , ALA(F, C) denotes unique clause resulting
repeating following fixpoint: l1 , . . . , lk C clause (l1 . . . lk l)
F \ {C} literal l, let C := C {l}.
136

fiC LAUSE E LIMINATION



SAT



QSAT

ALA(F, (a b c))
Example 4. Consider formula F = (a b c) (a b d) (a c d).
first adds asymmetric literals using (a b d) (a c d), respectively. Afterwards,
fixpoint
add asymmetric literals b using (a b d) c using (a c d).

ALA(F, (a b c)) (a b b c c d).
easy show replacement clause C occurring CNF F ALA(F, C)
preserves logical equivalence regardless whether F quantifier free propositional formula
matrix QBF. words, ALA agnostic quantifier prefix.
concrete examples, asymmetric tautology elimination, asymmetric subsumption elimination,
asymmetric blocked clause elimination defined follows.
Definition 9. clause C asymmetric tautology ALA(F, C) tautology.
Asymmetric tautology elimination (ATE) repeats following fixpoint: clause
C F ALA(F, C) tautology, let F := F \ {C}.
Example 4.
Example 5. Consider formula F = (a b c) (a b d) (a c d)

F , ALA(F, (a b c)) = (a b b c c d) tautology, hence removed
ATE F .
stated following lemma, ATE performs could called asymmetric branching clausesreferred UP-redundancy Fourdrinoy et al. (2007a, 2007a) Piette
et al. (2008)which used example technique clause distillation (Jin & Somenzi,
2005). gives alternative characterization ATE terms Boolean constraint propagation.

Lemma 1. ALA(F, C) tautology BCP (F \ {C}) lC {(l)}) derives
conflict.
definitions asymmetric subsumption elimination asymmetric blocked clause elimination analogous asymmetric tautology elimination.
Definition 10. Asymmetric subsumption elimination (ASE) repeats following fixpoint:
clause C F ALA(F, C) subsumed F , let F := F \ {C}.
ASE remove
Example 6. Consider formula FASE = (a b c) (a b d) (a c d).
subsumed (a b d)
(a b c) F , ALA(FASE , (a b c)) = (a b c d)

(a c d).
Definition 11. given CNF formula F , clause C F asymmetric(ally) blocked
ALA(F, C) blocked w.r.t. F . Asymmetric blocked clause elimination (ABCE) repeats following fixpoint: asymmetric blocked clause C F ALA(F, C)
blocked w.r.t. F , let F := F \ {C}.
(a d) (b d)
(c d).

Example 7. Consider formula FABCE = (a b c) (b c d)
ABCE eliminate (a b c), ALA(FABCE , (a b c)) = (a b c d) b
c blocking literals. Also, ABCE remove clauses FABCE .
turns clause elimination procedures preserve logical equivalence case
SAT, consider information quantifier ordering case QSAT, i.e.,
137

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

rules SAT QSAT. Procedures preserve satisfiability equivalence
SAT, however, would become unsound quantifier ordering ignored and, therefore,
restrictions imposed prefix considered definition procedures.
results quantified variants blocked clause elimination (QBCE) asymmetric blocked
clause elimination (AQBCE), detailed Section 5, well quantified variants covered clause elimination (QCCE) asymmetric covered clause elimination (AQCCE) detailed
Section 6).
3.2 Analyzing Clause Elimination Procedures
present detailed analysis relationships considered clause elimination
procedures, terms achieved level simplification (relative reduction power), level
equivalence maintained procedures (in terms sets models original simplified
formulas), confluence (i.e., whether procedures unique fixpoint), well level
constraint propagation maintained applying procedures. formally define
concepts give overview results. Detailed proofs results presented
Sections 46. Analysis procedures terms properties later (in Section 8)
complemented empirical evaluation effect clause elimination procedures
runtimes state-of-the-art SAT QSAT solvers.
relevant aspect simplification techniques question much specific technique
reduces size CNF (and PCNF) formulas. paper analyze relative reduction power
considered clause elimination procedures based clauses removed procedures.
apply following natural definition reduction power.
Definition 12 (Relative reduction power). Assume two clause elimination procedures S1 S2
take input arbitrary CNF formula F produce output CNF formula
consists subset F satisfiability-equivalent F .
S1 least powerful S2 if, F output S1 (F ) S2 (F ) S1 S2
input F , respectively, S1 (F ) S2 (F );
S2 powerful S1 F outputs S1 (F ) S2 (F )
S1 S2 , respectively, S1 (F ) S2 (F );
S1 powerful S2
(i) S1 least powerful S2 ,
(ii) S2 powerful S1 .
definition relative reduction power takes account non-confluent elimination procedures, is, procedures generally unique fixpoint may thus
one possible output given input. noted result non-confluent
simplification procedure unpredictable due non-uniqueness results.
definition relative reduction power extends naturally QSAT considering size
reduction matrix QBF. Hence, natural liftings2 QS1 QS2 two CNF-level clause
elimination procedures S1 S2 QBFs, hold S1 powerful S2 ,
QS1 powerful QS2 .
2. lifting QS1 S1 considered natural QS1 behaves exactly like S1 restricted QBFs without universally
quantified variables.

138

fiC LAUSE E LIMINATION

ASE



SAT



A(Q)BCE

ATE

QSAT

A(Q)CCE

logical equivalence
preserving

satisfiability-equivalence
preserving

SE

(Q)BCE

TE

(Q)CCE

SE: Subsumption elimination (same SAT QSAT).
TE: Tautology elimination (same SAT QSAT).
ASE: Asymmetric subsumption elimination (same SAT QSAT).
ATE: Asymmetric tautology elimination (same SAT QSAT).
(Q)BCE: (Quantified) blocked clause elimination.
(Q)CCE: (Quantified) covered clause elimination.
A(Q)BCE: Asymmetric (quantified) blocked clause elimination.
A(Q)CCE: Asymmetric (quantified) covered clause elimination.
Figure 1: Relative reduction power hierarchy clause elimination procedures. edge X
means X powerful Y. solid edge means corner cases. dashed
edge means property hold corner case formula contains
tautologies. dotted edge means property hold corner case
formula contains empty clause. missing edge X means X
powerful Y. However, notice transitive edges missing figure
clarity. Q prefix clause elimination technique indicates
differences QSAT SAT variant.

analysis results relative reduction power hierarchy (Figure 1) considered elimination procedures. example, show known plain techniques, asymmetric variants powerful. sense, novel variants proper generalizations
known plain techniques. also turns powerful technique asymmetric
variant covered clause elimination. figure slightly different earlier work (Heule et al.,
2010). changes based renewed view subsumption: tautology subsumed
clause.3 view justified fact C F subsumes another clause C F
CNF F due C C , C logically entailed F . Since tautological clause C F
trivially entailed F , regard C subsumed clause C F . note
one single corner case: formula contains tautologies, tautology elimination remove tautologies, subsumption elimination remove all, one. Using
definition, subsumption elimination techniques powerful tautology elimination techniques.
Additionally, consider properties listed Table 1 analysing clause elimination procedures SAT. easy see TE SE confluent BCP-preserving,
also CNF formula F , TE(F ) SE(F ) logically equivalent F . Furthermore,
QBF .F , tautology elimination subsumption elimination, well asymmetric
3. Donald Knuth convinced us view personal communication July 21, 2014.

139

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Table 1: Properties clause elimination procedures SAT.
Preserves logical eq. BCP-preserving Confluent
Subsumption-based
SE
yes
yes
yes
yes


ASE
Tautology-based
TE
yes
yes
yes
yes


ATE
Blocked clause
BCE


yes
ABCE



Covered clause
CCE


yes



ACCE
variants, use information variable ordering, i.e., S(.F ) := .S(F )
{TE, SE, ATE, ASE}. also holds BCE confluent (Jarvisalo et al., 2010).
techniques preserves satisfiability (and thus sound), turns
variants blocked clause elimination covered clause elimination preserve logical equivalence; motivation demonstrating Section 7 one efficiently reconstruct
original solutions based satisfying assignments CNFs simplified using variants.
property simplification techniques BCP-preservance, implies relevant unit
propagation (restricted remaining variables simplified CNF formula) possible
original CNF also possible simplified CNF partial assignment. property
solver-related much practically relevant, since BCP integral part vast majority
SAT solvers today.
Definition 13 (BCP-preserving). formula F , preprocessing procedure preserves BCP
F partial assignment variables F formula S(F ) resulting
applying F ,
(i) literal l occurring S(F ), (l) BCP(F, ) implies (l) BCP(S(F ), )
(ii) BCP(F, ) implies BCP(S(F ), ) (the empty clause obtained, is, BCP
derives conflict).
BCP-preserving preserves BCP every CNF formula.
Notice definition similar deductive power defined Han Somenzi (2007).
Also notice BCP-preserving implies logical equivalence also preserved. Interestingly,
turns BCP-preserving quite strict property, plain SE TE it.
note procedure BCP-preserving, procedure powerful
S, immediately BCP-preserving. Similarly, preserve
logical equivalence, preserve logical equivalence either. Furthermore, viewing
CNF formulas PCNF formulas variables existentially quantified, showing
CNF-level procedure BCP-preserving confluent typically directly implies
140

fiC LAUSE E LIMINATION



SAT



QSAT

negative result lifting PCNF formulas. Indeed, case procedures
considered article. Furthermore, since quantifier structure impose restrictions
behavior {TE, SE, ATE, ASE}, positive results BCP-preservance confluence
also directly translate level PCNF formulas. Hence focus analysis procedures
perspectives CNF-level.
following, proceed giving detailed analysis variants tautology, subsumption, blocked clause, covered clause based elimination procedures considering equivalence preserving techniques first followed discussion satisfiability preserving techniques.
Finally, experimental results practical effectiveness procedures presented Section 8.

4. Logical Equivalence Preserving Clause Elimination Techniques
start analysis shortly considering clause elimination procedures preserve logical
equivalence, namely, well-known tautology subsumption elimination, asymmetric
variants.
Lemma 2. ATE powerful TE.
Proof. ATE least powerful TE due C ALA(F, C): C tautology,
ALA(F, C). Moreover, let F = (ab)(bc)(ac). Since ALA(F, (ac)) = (aabbcc),
ATE remove (a c) F , contrast TE.
Proposition 1. ATE confluent.
Proof. Consider formula F = (ab)(ac)(ac)(bc)(bc). Now, ALA(F, (ab)) =
ALA(F, (a c)) = ALA(F, (b c)) = (a b b c c). ATE remove either (a b)
(a c), (b c).
Proposition 2. CNF formula F , ATE(F ) logically equivalent F .

Proof. clause C removed ATE, (F \ {C}) lC {(l)} unsatisfiable. implies
F \ {C} |= C, is, F \ {C} logically entails C.
Proposition 3. ATE BCP-preserving.
Proof. Consider standard CNF translation x = If-Then-Else(c, t, e) formula
(x c t) (x c t) (x c e) (x c e) (x e t) (x e t).
Notice ATE remove (x e t) (x e t). However, removing clauses,
BCP longer assign x truth assignment (e) = (t) = f. Also, BCP
longer assign x f truth assignment (e) = (t) = t.
Next consider asymmetric variants tautology elimination subsumption elimination.
Proposition 4. ASE powerful SE.
141

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Proof. ASE least powerful SE since CNF formula F , (i) every clause C F ,
C ALA(F, C), (ii) C subsumed clause C C subsumed. Moreover,
consider formula F = (a b c) (a b d) (b c). contrast SE, ASE remove
(a b d), ALA(F, (a b d)) = (a b c d) subsumed (a b c).
connection Proposition 4, note that, UP-redundancy terminology,
equivalently observed Fourdrinoy et al. (2007a) that, essentially, removing asymmetric tautologies fixpoint produces formula closed subsumption elimination.
Lemma 3. ATE least powerful ASE, except corner case formula contains
empty clause.
Proof. Consider corner case formula contains empty clause. case, ASE
remove clauses empty clause. However, let F := C C
tautology. ATE cannot remove C, ASE can.
see ATE least powerful ASE cases, consider following.
clause C F ALA(F, C) subsumed C F \ {C}, ALA(F, C)
tautology: say ALA(F, C) subsumed C = (l1 . . . lk ). definition ALA,
l1 , . . . , lk ALA(F, C).
Lemma 4. ASE least powerful ATE, except corner case formula consists
tautologies.
Proof. Consider corner case formula consists tautologies. case, ATE
remove clauses. However, ASE remove one clause.
see ASE least powerful ATE, consider following. tautology
subsumed clause. also holds asymmetric tautologies. Hence long
least one clause available subsumption (which case formula contains least
one non-tautological clause), ASE least powerful ATE.
Proposition 5. ASE confluent.
Proof. replacing ATE ASE proof Proposition 1.
Proposition 6. CNF formula F , ASE(F ) logically equivalent F .

Proof. clause C removed ASE, (F \ {C}) lC {(l)} unsatisfiable. implies
F \ {C} |= C, is, F \ {C} logically entails C.
replacing ATE ASE proof Lemma 3 following.
Proposition 7. ASE BCP-preserving.

5. Clause Elimination Procedures based Blocked Clauses
third family clause elimination procedures considered paper, analyze procedures eliminate blocked clauses (Kullmann, 1999) present generalizations thereof QSAT.
142

fiC LAUSE E LIMINATION



SAT



QSAT

5.1 Blocked Clause Elimination SAT
start plain variant blocked clause elimination, BCE.
Proposition 8. BCE powerful TE.
Proof. see BCE least powerful TE, notice tautology C, C
also tautology. case = C C \ {l} C l Definition 7 BCE. Moreover,
consider formula F := (a). BCE remove (a) F , contrast TE.
Proposition 9. CNF formula F , BCE(F ) logically equivalent F .
Proof. Recall formula FBCE Example 3. Consider truth assignment (v1 ) =
(v2 ) = (w3 ) = (v3 ) = (w1 ) = (w2 ) = f. Although satisfies BCE(FBCE ), clause
(v1 v2 ) FBCE falsified .
Proposition 10. BCE(F ) BCP-preserving.
Proof. Follows fact BCE preserve logical equivalence (Proposition 9).
turn asymmetric variant blocked clause elimination turns
powerful BCE.
Proposition 11. Removal asymmetric blocked clause preserves satisfiability.
Proof. Follows facts F logically equivalent (F \ {C}) {ALA(F, C)}
BCE preserves satisfiability.
Lemma 5. ABCE powerful (i) BCE, (ii) ATE.
Proof. ABCE least powerful BCE due C ALA(F, C): C tautology,
ALA(F, C) tautology. ABCE least powerful ATE since tautologies blocked
clauses. Moreover, recall Example 7, ABCE could eliminate clauses FABCE . Neither BCE ATE remove clause FABCE .
Proposition 12. ABCE confluent.
(b d) (c d). F contains four asymmetric
Proof. Let F = (a b) (a c) (a d)
blocking literal b, ALA(F, (a c)) =
blocked clauses: ALA(F, (a b)) = (a b c d)

(a b c d) blocking literal c, ALA(F, (b d)) = (a b c d) blocking literal b,
ALA(F, (c d)) = (a b c d) blocking literal c. ABCE removes either (a b)
(b d), (a c) (c d) F .
Replacing BCE ABCE proof Proposition 9, following.
Proposition 13. CNF formula F , ABCE(F ) logically equivalent F .
143

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

5.2 Quantified Blocked Clause Elimination
following, generalize notion blocked clauses blocked clause elimination (BCE)
QSAT. prove blocked clauses removed also case QSAT, discuss
differences propositional logic.
Definition 14. literal l quant(l) = clause C F QBF G = Q1 . . . Qn .F called
quantified blocking literal C F l C , literal l l l exists
l , l C (C \ {l}). clause quantified blocked contains quantified blocking literal.
QBF G PCNF, quantified blocked clause elimination repeats removal quantified
blocked clauses G fixpoint. resulting QBF denoted QBCE(G). definition
quantified blocking literals slightly differs original definition (Biere et al., 2011)
uses l , l C l C instead l , l C (C \ {l}). definition includes case either C
C tautology, i.e., C l C undefined. Apart this, definitions equivalent.
contrast propositional logic, two restrictions selection quantified blocking literals. blocking literal existential literals responsible tautology
resolvent smaller level blocking literal. Without restrictions, quantified
blocked clause elimination would sound, illustrated following examples.
Example 8. clauses satisfiable QBF G = xy.((x y)(xy)) quantified blocked
clauses since existential literals quantified blocking literals first second
clause, respectively. Note x < prefix ordering. Let G = xy.((x y) (x y))
obtained G changing quantifiers x prefix. QBF G unsatisfiable.
clause G quantified blocked since x existential x < y. ignored condition
level quantified blocking literal, erroneously clauses G would considered
quantified blocked, removing clause G results satisfiable QBF.
Example 9. Consider unsatisfiable QBF yxz.((y x z) (y x z) (y) (z)).
definition, literals universal variable x cannot quantified blocking. ignored
quantifier type x erroneously x x first second clause, respectively, would
considered quantified blocking literals. Note condition quantifier level holds,
is, < x responsible tautological resolvent two clauses containing
x. However, removing second clause, erroneously considered quantified blocked,
results satisfiable QBF.
following theorem shows, quantified blocked clauses contain redundant information only,
may therefore removed formula.
Theorem 1. Let G = Q1 . . . Qn .(F {C}) QBF let C quantified blocked clause
G blocking literal l. G Q1 . . . Qn .F equivalent.
Proof. Let C quantified blocked clause quantified blocking literal l var(l) Qi ,
n. direction G Q1 . . . Qn .F trivially holds. show Q1 . . . Qn .F G induction
q = |Q1 . . . Qi1 |.
base case, q = 0, i.e., var(l) Q1 quant(Q1 ) = . argument
SAT (Kullmann, 1999) applies: let satisfying assignment F , i.e., C F
exists literal l (l ) = t. satisfies C, implication Q1 .F G holds,
144

fiC LAUSE E LIMINATION



SAT



QSAT

otherwise construct satisfying assignment F {C} follows. Let (l ) = (l )
l 6= l (l) = t. satisfies C also clauses C F . l C ,
exists literal l 6= l l C l C , (l ) = (C) = (l ) = f thus
(C ) = (l ) = t. Note l Q1 due restriction l l.
induction step, assume q > 0. Let h literal var(h) = Q1 . Note
var(l) 6= y. show Q1 \{y} . . . Qn .F [h] G[h]. rest follows lifting
implication conjunction defines semantics universal quantification quant(Q1 )
= , and, respectively, disjunction defines semantics existential quantification
quant(Q1 ) = . Three cases considered showing C[h] blocked clause
removed F [h].
1. h C. C removed G[h].
2. h 6 C h 6 C. Consequently, C[h] = C. Furthermore, C still quantified blocked
clause G[h], since h used make resolvent l tautological. induction
hypothesis applicable.
3. h C. Consequently, C[h] = C\{h} quantified blocked clause G[h],
clause C h, h C l C removed G[h], clauses C k, k
C l C 6= var(k) still produce tautological resolvents C l. Note l C[h]
since l 6= h.
Theorem 2. application QBCE(G) QBF G confluent.
Proof. argument similar propositional logic (see Section 5).
soundness quantified blocked clause elimination QSAT, level blocking
literal must equal higher level literal making resolvent tautological,
following example illustrates.
Example 10. extended example related Example 8 universal reduction applicable
clause given unsatisfiable QBF
G = xyz.((x z) (x z) (y z) (y z)).
first two clauses G encode x z equivalent, last two clauses encode
z equivalent. variable z prohibits application universal reduction.
first two clauses x x, respectively, quantified blocking literals x < z.
clauses erroneously considered blocked removed, resulting QBF would
satisfiable.
Quantified blocked clauses may eliminated formula without changing truth value,
contain redundant information only. Hence, quantified blocked clause elimination
applied order remove clauses QBF may reduce number variables occurring
formula too. following properties established SAT (Kullmann, 1999; Heule et al.,
2010), also hold QSAT. sake compactness, omit prefix quantified
confusion arises.
145

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

1. Formulas smaller respect number clauses potentially contain
blocked clauses. matrix QBF G1 subset matrix QBF G2
might clauses blocked G1 , G2 . clause C
blocked G2 , G1 , C 6 G1 .
2. statement above, follows immediately QBCE unique fixpoint.
clause C blocked QBF G, clause C C 6= C blocked G also
blocked G\{C}.
3. clause C subsumed blocked clause C , i.e., C C, C also blocked
clause. Obviously, direction hold.
4. Clauses containing existential pure literal blocked. pure literal blocking
literal. fact, QBCE may considered generalization pure literal elimination rule
existentially quantified variables. However, elimination pure literals
universally quantified simulated QBCE. general, pure literal elimination
universal literals eliminate whole clauses, single literals.
5. clauses C1 . . . Cn clauses QBF G contain literal l,
clause C l C blocked clause Ci , clause C contains literal li
li Ci li < l. particular, QBF G contains equivalence form
(l, l1 , . . . , ln ), (l, l1 ), . . . , (l, ln ) l occurs clauses, equivalence may removed due QBCE.
fifth property indicates QBCE eliminates equivalences certain conditions.
fact, like BCE SAT (Jarvisalo et al., 2012a), QBCE achieves structure-based simplifications
defined circuit-based representations purely PCNF-level, without explicit knowledge
structure original representation.

6. Covered Clause Elimination Procedures
final family clause elimination procedures considered paper, introduce
analyze CNF PCNF-level procedures eliminate call covered clauses.
Covered clause elimination based successively adding certain literals clause C
CNF F = F {C} satisfiability-preserving way. Adding literal l C produces extended
clause C = C {l} replaces C F obtain F = F {C }. C becomes blocked due
adding literal l C removed F BCE, effectively eliminating one clause
F . literals added clause C extension steps called covered literals. literals
determined inspecting clauses which, resolved C, result non-tautological
resolvent. clause becomes blocked adding covered literals called covered clause.
application covered clause elimination practice, clause C extended covered literals
tentatively. extended clause C become blocked eventually, added
literals discarded original clause C restored.
following, formally define set covered literals, safely used
extend clauses CNF. introduce covered clause elimination SAT QSAT
analyze properties. Similar BCE, covered clause elimination preserve logical equivalence. Therefore, Section 7 present algorithm reconstruct solutions CNFs
covered clauses eliminated.
146

fiC LAUSE E LIMINATION



SAT



QSAT

6.1 Covered Clause Elimination Procedures SAT
Given CNF formula F , clause C, literal l C, set resolution candidates C w.r.t. l

RC(F, C, l) := {C | C Fl C l C tautology}.
words, set RC(F, C, l) resolution candidates consists clauses C contain opposite
literal l, meaning clauses resolved C literal l. Notice every clause
RC(F, C, l) contains literal
l. RC(F, C, l) = , C blocked w.r.t. F . literals

apart l occur clauses RC(F, C, l) form resolution intersection RI(F, C, l)
l C w.r.t. F , formally defined
\

RI(F, C, l) :=
RC(F, C, l) \{l}.
words, resolution intersection RI(F, C, l) set literals (apart l) occur
clause resolution candidate set RC(F, C, l). Given CNF formula F , clause C F ,
literal l C, say l covers literals RI(F, C, l) (w.r.t. F C). literal l
covered l C l RI(F, C, l). literal l C covering w.r.t. F C l covers least
one literal, is, RI(F, C, l) 6= .
Example 11. Consider formula
(a b c) (a b d)
(a c d)
FCLA = (a b c) (a b d) (a c d)
also visualized resolution graph Figure 2. resolution graph constructed
follows. clauses vertices vertices connected resolution
two clauses results non-tautological resolvent. words, vertices connected
exactly one clashing literal. edges label shows corresponding
variable clashing literal pair.
BCE cannot remove clause FCLA literal occurrence FCLA exists
non-tautological resolvent. Figure 2 illustrates literal clause least
one edge. Now, RC(FCLA , (a b c), b) = {(a, b, d)}, RI(FCLA , (a b c), b) = {a, d}.
words, literal b (a b c) covers literals d. discussed following, adding
(a b c) preserves satisfiability. 4
addition (a b c), several edges disappear. longer holds
literal occurrence corresponding edge. literals edge, (for example, c
become blocking literals.
(a c d)),
Lemma 6. CNF formula F , clause C F , literal l C, holds replacing C
C RI(F, C, l) F preserves satisfiability.
Proof. literal l C holds VE(F, l) = VE((F \ {C}) {C RI(F, C, l)}, l),
VE(F, l) denotes CNF formula resulting variable eliminating variable literal l
F (more formally, VE(F, l) = (Fl Fl ) (F \ (Fl Fl )), Fl Fl consist
clauses F contain l l, respectively, Fl Fl = {C l C | C Fl , C Fl ,
C l C tautology}).
4. fact, based reasoning, one could also eliminate literal (a b c).

147

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

abc


b

b
c




c

b

abcd


c


c









b

b c

b

b





c

c


c


b


b


b c

Figure 2: Two resolution graphs FCLA : graphs clause FCLA one vertex
vertices connected edge exactly one pair complementary
literals (hence resolvent non-tautological). edges labeled variable
complementary literals. top figure shows FCLA adding covered literal
(a b c) bottom figure shows FCLA addition. Notice
top figure edge literal. Literals bottom figure edge
associated them, c (a b c d) blocking literals.

given clause C CNF formula F , denote (covered literal addition) CLA(F, C)
clause resulting repeating following fixpoint:
literal l C RI(F, C, l) \ C 6= , let C := C RI(F, C, l).
Lemma 7. Replacing clause C F CLA(F, C) preserves satisfiability.
Proof. clause CLA(F, C) obtained iteratively applying Lemma 6 clause C.
Lemma 8. Assume two clauses C, l C two sets clauses F, G F
G. assume blocked w.r.t. F hence C blocked w.r.t. G.
RC(G, C, l) RC(F, D, l) 6= hence RI(G, C, l) RI(F, D, l).
Proof. Monotonicity RC w.r.t. first argument anti-monotonicity w.r.t. second argument
follows directly definition. RI, note intersection anti-monotonic non-empty
sets sets.
148

fiC LAUSE E LIMINATION



SAT



QSAT

Theorem 3. Given CNF formula F clause C F , CLA(F, C) blocked uniquely
defined.
Proof. Assume C blocked w.r.t. F contains two literals l1 , l2 , cover literals
Li = RI(F, C, li ) respectively. Consider clauses C1 = C L1 C2 = C L2 . assume
C1 , C2 blocked w.r.t. F . clauses RC(F, C1 , l2 ) RC(F, C, l2 )
contain literals L2 . Since C1 blocked thus RC(F, C1 , l2 ) empty, obtain
L2 RI(F, C1 , l2 ). case indices exchanged (i.e., L1 RI(F, C2 , l1 )) symmetric. Thus long clauses become blocked, covered literals added independently.
case C1 , C2 blocked trivial.
remains (by symmetry) case C2 blocked C1 not. Again, get L2
RI(F, C1 , l2 ). C1 = C1 RI(F, C1 , l2 ) C1 = C L1 RI(F, C1 , l2 ) L1 (C L2 )
C2 also blocked. generalizes following observation: non-deterministic
choice adding covered literals C, literal l2 remains covering. Further, process
clause become blocked, eventually become blocked covered literals l2
added.
needed preliminaries place, ready introduce covered clause elimination
procedures. first one plain variant, simply called covered clause elimination.
Definition 15. Given CNF formula F , clause C F covered CLA(F, C) blocked
w.r.t. F .
Example 12. Back Example 11. Recall RI(FCLA , (abc), b) = {a, d}. Also, RI(FCLA , (a
Therefore, depending order addition, CLA(FCLA , (a b c)) eib c), c) = {a, d}.
starting
ther (a b c d) starting covering literal b, (a b c d)
covering literal c. cases CLA(F CLA , (a b c)) blocked. replacing (a b c)
(a b c d), truth assignment (a) = (b) = (c) = f (d) = satisfies
new formula, falsifying (a b c) FCLA . fact, FCLA witnesses fact none
clause elimination procedures based covered clauses, introduced next, preserve logical
equivalence general.
illustration sis show Figure 2. shows resolution graph FCLA
adding covered literal.
Lemma 9. Removal arbitrary covered clause preserves satisfiability.
Proof. Clause C replaced CLA(F, C) (Lemma 7), C removed CLA(F, C)
blocked.
Definition 16 (Covered Clause Elimination). given formula F , covered clause elimination
(CCE) repeats following fixpoint: covered clause C F , let F := F \ {C}.
resulting unique formula denoted CCE(F ).
Confluence CCE follows following lemma.
Lemma 10. following holds CNF formula F , clause C F , set clauses F
C 6 S. C covered w.r.t. F , C covered w.r.t. F \ S.
149

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Proof. Let CLA(F, C) = Ck , C0 := C, Ci+1 := Ci RI(F, Ci , li ) = 0..k 1
li Ci . define D0 := C and, = 0..k1, Di+1 := Di Di blocked w.r.t. F \S
Di+1 := Di RI(F \ S, Di , li ) otherwise. Using Lemma 8, one show induction
either (i) Di blocked w.r.t. F \ S, (ii) RI(F \ S, Di , li ) RI(F, Ci , li ).
(i) holds i, CLA(F \ S, C) blocked w.r.t. F \ C. Di blocked w.r.t. F \
i, CLA(F \ S, C) CLA(F, C).
Theorem 4. CCE confluent.
Proof. Follows directly Lemma 10: two clauses C covered w.r.t. F , C
covered w.r.t. F \ {D}.
Lemma 11. CCE powerful BCE.
Proof. CCE least powerful BCE follows fact C CLA(C): C
blocked, CLA(C). Moreover, FCLA clause blocked. However, clauses covered.
Hence BCE remove single clause, CCE removes them.
fact, cases possible add covered literals ALA(F, CLA(F, C)): cases
adding asymmetric literals clause increase |RI(F, C, l)| non-asymmetric literal
l C.
Example 13. Consider CNF formula F = (a b) (b c) (a c) (a d). Notice
CLA(F, (a b), a) = (a b). Literal c asymmetric w.r.t. (a b) due (b c). adding c,
extended clause (a b c) covers d.
observation motivates following definition asymmetric covered clauses, based
extending clauses iteratively CLA ALA fixpoint reached. formally,
given CNF formula F , clause C F asymmetric covered clause resulting repeating
1. C := CLA(F, C).
2. C := ALA(F, C).
fixpoint blocked w.r.t. F . Based definition, arrive asymmetric covered clause
elimination, ACCE.
Definition 17. Asymmetric covered clause elimination (ACCE) repeats following fixpoint:
asymmetric covered clause C F , let F := F \ {C}.
Lemma 12. Removal arbitrary asymmetric covered clause preserves satisfiability.
Proof. Follows facts (i) F satisfiability-equivalent (F \ {C}) {CLA(F, C)};
(ii) F satisfiability-equivalent (F \{C}){ALA(F, C)}; (iii) BCE preserves satisfiability.

Lemma 13. ACCE powerful (i) ABCE, (ii) CCE.
150

fiC LAUSE E LIMINATION



SAT



QSAT

Proof. (i) replacing CCE BCE ACCE ABCE proof Lemma 11. (ii) Consider formula
FACCE = (a b c) (a b c) (a b c) (a b c)
(a b c) (a b c) (a b c) (a b c)
(a b d) (a b d).

(a b d) (a b d)
CLA cannot add literals clause FACCE . However, ALA add (a b c)
(a b d), respectively. ALA, (a b c) tautology, ACCE
using (a b d)
remove it.
6.2 Quantified Covered Clause Elimination
introduce lifting covered clause elimination QSAT. Thereby, covered clauses
clauses blocked enriched literals contained resolvent pivot
element l, covering literal. QBCE, prefix ordering taken account.
Definition 18. Let QRC denote set resolution candidates
QRC(G, C, l) := {C | C F, l C , 6 l : {l , l } C l C },
G QBF matrix F , C F , l C. resolution intersection QRI(G, C, l) l
C w.r.t. G given

\
{C | C QRC(G, C, l), C C , l C : l l} \{l}.
QRI(G, C, l) :=
literal l called covering literal QRI(G, C, l) 6= , i.e., l covers literals QRI(G, C, l).
Lemma 14. replacement clause C QBF G C QRI(G, C, l) preserves unsatisfiability.
Proof. show QBF G = .(F {C}) holds G unsatisfiable,
G = .(F QRI(G, C, l)). Assume G unsatisfiable, G not.
least one assignment (C) = f (QRI(G, C, l)) = t. consequence,
least one l QRI(G, C, l) (l ) = t. Due construction QRI, holds C F
l C , (C ) = t. means latest, assigning variables v v < l
value (v), l pure. means F satisfiable assignment (k) = (k)
k 6= l (l) = ( (l)), contradiction assumption G unsatisfiable.
following, QRI(G, C) denotes clause C extended quantified covered literals,
i.e., l QRI(G, C) holds QRI(G, C, l) QRI(G, C).
Lemma 15 (Quantified Covered Literal Addition). replacement clause C QBF G
QRI(G, C) preserves unsatisfiability.
Proof. Iterative application Lemma 14.
Definition 19 (Quantified Covered Clause). clause C QBF G covered QRI(G, C)
blocked w.r.t. G.
151

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Theorem 5. removal covered clause preserves unsatisfiability.
Proof. According Lemma 15, clause may replaced clause QRI(G, C).
clause blocked, may removed according Theorem 1. tautology, removed
due standard rewriting rules.
Example 14. QBF a, b, c x, y.((x a) (x b) (x c) (y a)) literal x
clause (x a) covers literal y. Therefore, replace clause (x y)
blocked due blocking literal y. Consequently, clause (x y) eliminated.
restriction literals resolution candidates smaller level according
pivot necessary correctness quantified covered clause elimination, shown
following example.
Example 15. Consider unsatisfiable QBF xay.((xy)(xa)(y a)). give
restriction selection resolution candidates, would obtain clause (x a)
blocked blocking literal y. remove clause, QBF becomes satisfiable.
Lemma 16. Covered clause elimination QSAT confluent.
Proof. Assume add literal l clause C order make C covered clause
removed blocked clause elimination. Assume l QRI(C, l ) literal l C.
show clause C l C removed due QCCE, either l may still added
C C blocked hence may removed. C clause containing l,
clause C l C . l pure C may removed. Otherwise, l
intersection resolvents pivot literal l hence l may added C.

7. Reconstructing Solutions
Since elimination procedures based blocked clauses covered clauses preserve
logical equivalence, truth assignment satisfying, example, BCE(F ) may satisfy F .
section shown solutions original CNF formulas reconstructed based
solutions CNF formulas resulting applying variations blocked clause covered
clause elimination.
7.1 Procedures Based Blocked Clauses
Jarvisalo Biere (2010) showed how, given CNF formula F truth assignment
satisfies BCE(F ), one construct satisfying assignment F : Add clauses C F \
BCE(F ) back opposite order elimination. case C satisfied , nothing.
Otherwise, assuming l C blocking C, flip truth value l t. clauses
added, modified satisfies F .
show procedure used reconstruct solutions formulas simplified
using ABCE.
Lemma 17. Given clause C F , ALA(F, C) blocked tautology,
literal l C blocking it.
152

fiC LAUSE E LIMINATION



SAT



QSAT

Proof. construction, literal l ALA(F, C) \ C, clause C F contains l
C \{l} ALA(F, C). Therefore, ALA(F, C) tautology, C l ALA(F, C) =
ALA(F, C) \ {l} tautology either. Hence l blocking ALA(F, C).
Lemma 18. Given CNF formula F truth assignment satisfying F , C
/ F falsified
, ALA(F, C) falsified .
Proof. Lemma 1 follows F {ALA(F, C)} logically equivalent F {C}. Therefore,
ALA(F, C) satisfied satisfies C.
Lemma 19. Given CNF formula F truth assignment satisfying F , C
/ F falsified
ALA(F, C) blocked w.r.t. F blocking literal l C, satisfies least two
literals clause C F
l C .
Proof. First, C F contain literal l satisfied . Second, l blocking,
clause C must contain one literal l 6= l l ALA(F, C). Since literals
ALA(F, C) falsified , l must satisfied .
Combining three lemmas, reconstruct solution F satisfying
assignment ABCE(F ). clauses C F \ ABCE(F ) added back reverse order
elimination ensure ALA(F, C) blocked. C satisfied F nothing. Otherwise,
know literal l C blocking ALA(F, C); recall Lemma 17. Furthermore,
literals ALA(F, C) falsified; recall Lemma 18. However, C F containing l two
satisfied literals; recall Lemma 19. Therefore, flipping truth assignment l t, C becomes
satisfied, C becomes falsified.
Theorem 6. following holds arbitrary CNF formula F truth assignment satisfying
F . clause C
/ F C, ALA(F, C) blocked w.r.t. F blocking literal l, either
(i) satisfies F {C}, (ii) , copy except (l) = t, satisfies F {C}.
reconstruction proof provides several useful elements used implement ABCE
efficiently. First, since original literals l C blocking ALA(F, C), avoid
blocking literal check literals l ALA(F, C) \ C. Second, enough save removed
original clause C. None additional literals extended clause ALA(F, C) occurring
C flipped.
implemented reconstruction follows. clause C eliminated procedure
based blocking literals (BCE ABCE), C together blocking literal l C pushed
reconstruction stack S: i.e., := S, hl:Ci. reconstruction, examine eliminated
clauses reverse order. clause top stack falsified, truth value
blocking literal flipped. Figure 3 shows pseudo-code algorithm.
7.2 Procedures Based Covered Clauses
covered clauses eliminated, reconstruction solutions becomes tricky. due
following. shown previous section, given satisfying formula F , clause
C falsified , Lemma 18 ALA(F, C) also falsified . However, analogous
claim CLA(F, C) true general.
153

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

reconstruction (CNF formula F , truth assignment , elimination sequence S)
empty
let hl:Ci := S.pop()
C falsified
flip truth value l
F := F {C}
return

Figure 3: Pseudo-code reconstructing solution F reduced formula, satisfying assignment F set eliminated clauses ordered last eliminated.

Proposition 14. CNF formula F satisfying truth assignment F
following holds. clause C F falsified , CLA(F, C) satisfied .
Proof. Let F = FCLA \ {(a b c)} assume truth assignment assigns (a) = (b) =

(c) = (d) = f. Let C = (a b c). Now, satisfies F , falsifies C. Since c C covers d,

satisfies CLA(F, C) = (a b c d).
Additionally, formula F clause C F , ALA(F, C) blocked w.r.t. F ,
literal l C blocking definition. However, case CLA(F, C) blocked, might
literal CLA(F, C) \ C blocking it.
Proposition 15. CNF formula F following holds. exist clause
C F C blocked w.r.t. F CLA(F, C) blocked (due blocking literal
l CLA(F, C) \ C).
Proof. Recall FCLA Section 6. FCLA , (a b c) blocked. However, extended
blocked blocking literal d.

clause CLA(FCLA , C) = (a b c d)
Due properties stated Propositions 14 15, given truth assignment satisfying
formula F covered clause C F , one may required flip truth values multiple
variables order construct satisfying assignments F {C} based . next
show achieved.
Theorem 7. Given CNF formula F truth assignment satisfying F . Let clause C
/ F
falsified , literal l C satisfies C RI(F, C, l), ,
copy l assigned t, satisfies F C.
Proof. need show flipping l t, clauses Fl still satisfied. two
cases. First, consider clause C Fl C l C tautology. must
x C x C . Since x falsified , C falsified , x satisfied
C . second case C Fl C l C tautology. definition,
RI(F, C, l) C . Since C falsified C RI(F, C, l) satisfied , RI(F, C, l)
satisfied C .
154

fiC LAUSE E LIMINATION



SAT



QSAT

Given CNF formula F , C
/ F CLA(F, C) blocked w.r.t. F , truth assignment
satisfying F . use observation Theorem 7 compute, given truth assignment
satisfies F {C}. case satisfies C trivial ( = ). Otherwise, sequence
C0 , C1 , . . . , Cc C0 := C, Cc := CLA(F, C), Ci+1 := Ci RI(F, Ci , li ) li Ci .
Now, let reconstruction stack contain sequence hl0 :C0 i, hl1 :C1 i, . . . , hlc :Cc i. Applying
= reconstruction(F, , S) using algorithm Figure 3 produces satisfies F C.
7.3 Solution Reconstruction QSAT
briefly review approaches obtaining satisfiability models preprocessed formulas
context QSAT. approaches classified two categories depending whether full
partial satisfiability models generated.
First, QSAT applications, sufficient extract partial model formula
preprocessed one. Often values leftmost existential block variables QBF
interest. case, partial model represents single assignment variables,
Skolem function zero arity. generate partial models practice, preprocessor
restricted apply preprocessing rules affect variables leftmost
quantifier block. variables declared dont touch variables (Seidl & Konighofer, 2014).
approach originates incremental bounded model checking based SAT (Kupferschmid,
Lewis, Schubert, & Becker, 2011) QSAT (Marin, Miller, & Becker, 2012).
alternative dont touch variables, preprocessor equipped partial tracing
capabilities (Heyman, Smith, Mahajan, Leong, & Abu-Haimed, 2014). Thereby, application
preprocessing rules restricted. Instead, information necessary reconstruct partial
model terms assignment leftmost existential variables collected preprocessing.
second category comprises methods extract full satisfiability models. Reconstruction
steps common preprocessing rules except expansion universal variables presented Janota, Grigore, Marques-Silva (2013). effect universal expansion cannot
expressed solely Q-resolution, contrast equivalence literal substitution, example,
hence causes complications. QRAT proof system (Heule, Seidl, & Biere, 2014a; Heule et al.,
2014b) first framework allow extraction full satisfiability models formulas preprocessed using currently implemented preprocessing techniques, including universal expansion.

8. Experimental Evaluation
Complementing theoretical analysis relationships properties considered
clause elimination procedures, present results empirical evaluation effect
applying clause elimination runtimes state-of-the-art SAT QSAT solvers. benchmarks, used standard competition benchmark sets recent SAT Competition (SAT
Competitions Organizing Committee, 2014) QSAT solver evaluation (Jordan & Seidl, 2014),
focusing real-world application instances. overview results, turned
clause elimination procedures developed work, applied within preprocessing, clear
positive effect performance various state-of-the-art QSAT solvers. pure CNF SAT formulas, effectswhile still positive non-negative wholeare modest,
applying clause elimination preprocessing, well within inprocessing. difference
partly explained follows: SAT benchmarks typically large relatively easy considering
155

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

size, whiledue succinct representation form enabled use quantifiers
QSAT benchmarks relatively small terms hard solve practice. Although
presented clause elimination techniques require polynomial timewhile solving procedures
exponentialthey times expensive practice, especially large CNF formulas
millions variables clauses.5
experiments performed cluster 2.8-GHz Intel Core 2 Quad machines
equipped 8-GB memory running Ubuntu 9.04.
8.1 Effectiveness Clause Elimination Context SAT
evaluated effectiveness clause elimination procedures context state-of-the-art
SAT solvers, specifically L INGELING version aqw (Biere, 2013), application track SAT competition 2013. L INGELING heavily relies concept inprocessing (Jarvisalo et al., 2012b). already discussed introduction, inprocessing based
idea interleaving preprocessing, including clause elimination procedures, search.
inprocessing paradigm enables use facts learned search, learned unit clauses,
subsequent inprocessing phases, simplified clauses search. Beside
synergistic effect, inprocessing allows preprocessing algorithms pre-empted search
resumed next inprocessing phase, avoid getting stuck too-costly preprocessing
stages.
difference cost, terms running time, specific inprocessing algorithms,
well issue certain simplification steps actually achieved different inprocessing
techniques. consequence, extremely difficult evaluate effect individual inprocessing techniques isolation precisely. alternative, investigated performance
competition version L INGELING affected disabling (i) clause elimination procedures,
(ii) pre- inprocessing techniques clause elimination procedures, (iii) preand inprocessing techniques. benchmark set used instances application
track SAT 2013 competition, time limit 5000 seconds per benchmark, running
hardware almost identical speed competition. essence, results show
L INGELING would performed competition without clause elimination comparison
using none pre- inprocessing techniques applied within solver.
note conducted experiment also using application track instances
SAT Competition 2014. modest improvements (as shown following) 2013
instances observed, 2014 instances clause elimination procedures noticeably
improve (nor degrade) performance L INGELING.6 Hence present details
results 2013 instances. general, appears clause elimination procedures provide
modest improvements SAT solvers, much substantial improvement QSAT
solversas demonstrate following.
5. fact, terms worst-case complexity, recently shown that, conditional so-called strong exponential time hypothesis (SETH) (Impagliazzo, Paturi, & Zane, 2001; Calabro, Impagliazzo, & Paturi, 2009)
true, checking whether given CNF formula contains clause cannot done sub-quadratic time, even
restricting Horn-3-CNF formulas (Jarvisalo & Korhonen, 2014).
6. suspect differences 2013 2014 benchmarks due benchmark selection procedure
applied competition organizers, extent balance performance differences set topperforming solvers previous year. benchmark selection procedure used main SAT competitions
20122014 described Balint, Belov, Jarvisalo, Sinz (2015).

156

fiC LAUSE E LIMINATION

configuration
pre- & inprocessing disabled
clause elimination enabled
base line without clause elimination
L INGELING version aqw (base line)



#sat
108
112
111
119

SAT



#unsat
83
86
112
113

QSAT

#total
191
198
223
232

avg
1254
1209
1111
1124

total
784440
749324
632852
600691

solved formulas
formulas

Table 2: L INGELING configurations application instances SAT Competition 2013.
Among inprocessing algorithms competition version L INGELING implements
following clause elimination procedures. separate BCE inprocessor scheduled inprocessing bounded variable elimination (VE) (Een & Biere, 2005) run-to-completion least
once. Note BCE implemented much faster variable elimination. However, since
latter often pronounced effect, run completion first, applying
BCE. Further, proposed Han Somenzi (2007), BCE partially performed on-the-fly
VE. configuration without clause elimination disable variants BCE.
special case on-the-fly subsumption on-the-fly strengthening conflict clause
learning (Han & Somenzi, 2009), also considered clause elimination procedure,
performed search. Thus keep enabled configurations L INGELING used
experiment. applies subsumption elimination (SE) (Een & Biere,
2005) subsumed clauses found lazy hyper binary resolution (Heule et al., 2013b). Another separate inprocessor performs transitive reduction binary implication graph. practice,
transitive reduction actually quite fast, unfortunately experience give much
benefit terms solving times.
L INGELING aqw also contains implementation ACCE, rather costly usually
never runs completion. also another simple partial variant ATE, called basic
ATE (BATE). computationally inexpensive detect asymmetric tautologies (AT)
(two-sided) literal probing (Le Berre, 2001), used basic probing technique various
inprocessing algorithms.
default configuration L INGELING aqw, discussed clause elimination procedures wait completed least once, BCE does, also require BCE
completed least (except BCE obviously). Concretely, configuration L GELING clause elimination procedures disabled called following command
line options: --no-bate --no-block --no-cce --no-transred. specifying --plain
compare configuration pre- inprocessing disabled configuration uses clause elimination procedures pre- inprocessing, using --plain
--bate --block --cce=3 --transred, first disables preprocessing selectively enables clause elimination procedure, combined --batewait=0 --blockwait=0
--ccewait=1, makes sure CCE started BCE run completion (as
default configuration) BCE delayed.
Results experiment shown Figure 4 Table 2. net result evaluation
default configuration L INGELING, entered competition, clause elimination procedures enabled, solves 9 instances; base line version solves 232 benchmarks
223 without clause elimination. nine instances, eight satisfiable, seems
157

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

5000
4500

pre- & inprocessing disabled
clause elimination enabled
base line without clause elimination
Lingeling version aqw (base line)

4000
Runtime (sec)

3500
3000
2500
2000
1500
1000
500
0
0

50

100

150

200

250

Number solved formulas
Figure 4: L INGELING version aqw without clause elimination procedures solves 9 instances less
application track benchmark set SAT 2013 Competition time limit
5000 seconds.

suggest additionally applying clause elimination beneficial especially satisfiable instances.
results suggest cases benefits using clause elimination procedures,
improvements scale enabling disabling (Een & Biere, 2005).
note that, explained detail (Jarvisalo et al., 2012a), BCE
extent orthogonal terms simplifications achieved CNF formulas, perform various types similar simplifications own. include, examples, various circuit-level
optimizations, cone-of-influence monotone input gate reductions, well CNF level
techniques pure literal eliminations.
8.2 Effectiveness Clause Elimination Context QSAT
following, empirically investigate impact PCNF-level clause elimination procedures
applied preprocessing QSAT. end, implemented techniques QSAT
preprocessor BLOQQER (version 35) (Seidl & Biere, 2015). core BLOQQER based
concept resolve expand realized QSAT solver Q UANTOR (Biere, 2005). Basically,
Q UANTOR complete solver using variable elimination remove existential variables
innermost quantifier block universal expansion remove variables innermost
universal quantifier block. Depending benchmark family, approach proved either
extremely efficient formulas hard solvers could solved within seconds
extremely memory-consuming. overcome limitation, developed preprocessor
158

fiC LAUSE E LIMINATION

900

SAT



QSAT

GhostQ
bloqqer + GhostQ
DepQBF
bloqqer + DepQBF
QuBE
bloqqer + QuBE
RAReQS
bloqqer + RAReQS

800
700
Runtime (sec)



600
500
400
300
200
100
0
0

50

100

150

200

250

Number solved formulas
Figure 5: Runtimes QBFLib Track Benchmarks QBF Gallery 2014.
BLOQQER applies resolve expand approach bounded manner. BLOQQER ,
preprocessed formula rewritten way complete solver benefit
careful application variable elimination universal expansion repeatedly applied
formula either change limits reached. (Note
formula might already solved preprocessing phase.) integrated clause elimination
techniques BLOQQER applied cycle variable elimination
universal expansion.
evaluating implementation, considered benchmarks QBFLib track
Application track QBF Gallery 2014 (Jordan & Seidl, 2014). formulas included
QBFLib track selection QBFLib, QBF community platform. set contains
345 formulas various benchmark families. competitive evaluation QBF Gallery
2014 subset 276 formulas directly solved preprocessors used. benchmark
set Application track consists 735 formulas recently presented encodings QSAT.
None formulas directly solved BLOQQER.
time memory limits set 900 seconds 7 GB, respectively. Time spent
preprocessing included time limit experiments involve QSAT solvers. preprocessor terminate 900 seconds, preprocessing aborted formula
considered unsolved. consider four participants QBF Gallery, publicly available: CDCL-based solver EP QBF (Lonsing & Biere, 2010; Egly, Lonsing, & Widl,
2013); CEGAR-based solver RAR E QS (Janota, Klieber, Marques-Silva, & Clarke, 2012);
G HOST Q solver (Klieber et al., 2010; Klieber, 2014) implementing CEGAR-based approach
combination so-called ghost variables, allowing duality-aware reasoning CNF level;
solver Q U includes preprocessor Q UEEZE BF (Giunchiglia et al., 2010).

159

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

900
800

Runtime (sec)

700
600
500

GhostQ
bloqqer + GhostQ
DepQBF
bloqqer + DepQBF
QuBE
bloqqer + QuBE
RAReQS
bloqqer + RAReQS

400
300
200
100
0
0

100

200

300

400

500

600

Number solved formulas
Figure 6: Runtimes Application Track Benchmarks QBF Gallery 2014.
configuration
preprocessing
VE/Expansion
QBCE
QCCE
asymmetric CE
full preprocessing

#sat
45
70 (2)
76 (27)
98 (32)
98 (28)
99 (33)

#unsat
74
72 (8)
91 (34)
98 (36)
94 (33)
98 (37)

#total
119
142 (10)
167 (61)
196 (68)
192 (61)
197 (70)

avg
56
66
47
42
53
38

total
210K
192K
168K
142K
148K
141K

vars
32925
32928
33306
33342
33310
33381

cls.
77710
36863
31776
28012
31642
27858

average runtime solved formulas
total runtime formulas

Table 3: Different BLOQQER configurations solver EP QBF QBFLib benchmarks.
preprocessor implements several techniques also included BLOQQER well special kind
equivalence substitution, clause elimination procedures like BCE CCE.
four solvers run standard configuration without BLOQQER.
results shown Figure 5 Figure 6. solvers except G HOST Q preprocessing
beneficial. Application track preprocessing hardly effect runtime
G HOST Q, QBFLib track performance G HOST Q decreased preprocessing.
G HOST Q relies structural patterns CNF application preprocessor seems
destroy patterns.
Since BLOQQER implements many preprocessing techniques, just-described experiment
directly indicate power PCNF-level clause elimination procedures. order
evaluate impact various techniques, run different configurations BLOQQER com160

fiC LAUSE E LIMINATION

configuration
preprocessing
VE/Expansion
QBCE
QCCE
asymmetric CE
full preprocessing

#sat
155
174
189
196
175
192

#unsat
128
219
202
213
213
217



#total
283
393
391
409
388
409

SAT



avg
62
36
60
69
41
70

QSAT

total
424K
322K
333K
322K
328K
322K

vars
11262
11283
11340
11356
11342
11358

cls.
227312
173487
186860
173454
174992
173402

average runtime solved formulas
total runtime formulas

Table 4: Different BLOQQER configurations solver EP QBF Application benchmarks.
bination solver EP QBF. results summarized Table 3 Table 4. tables
give number solved satisfiable unsatisfiable formulas well average runtimes
solved formulas total runtime complete benchmark set. last two columns
show average number variables clauses original formulas preprocessing configuration. configurations, average number variables clauses
preprocessed formulas given. Table 3 additionally contains information number
formulas directly solved BLOQQER (the number solved formulas brackets). ran
following configurations: (i) preprocessing, i.e., solver EP QBF, (ii) variable elimination expansion turned clause elimination techniques turned on, (iii) blocked clause
elimination turned off, (iv) covered clause elimination turned off, (v) asymmetric clause elimination
techniques turned off, (vi) preprocessing techniques turned on.
benchmark sets, observe application BLOQQER beneficial E P QBF. best performance achieved applying preprocessing techniques. turning
variable elimination universal expansion, see using clause elimination techniques already beneficial solver. results different BLOQQER configurations show
clause elimination techniques considerably improve runtimes number solved
formulas, especially case QBFLib track benchmarks. average, application
BLOQQER increases number variables. mainly due universal expansion. However,
also configuration expansion disabled, observe modest increase number
variables. BLOQQER splits large clauses smaller ones turned
beneficial EP QBF. Especially QBFLib track benchmarks, application BLOQQER
drastically decreases number clauses (more 50 percent configurations).

9. Conclusions
Preprocessing inprocessing (generally, formula simplification) techniques proven important speeding state-of-the-art SAT QSAT solving. Understanding effects relationships various simplification procedures important gaining better understanding procedures. article, focused specific type preprocessing techniques,
clause elimination procedures remove clauses CNF PCNF formulas based different polynomial-time checkable redundancy properties. introduced novel clause elimination
procedures CNF PCNF formulas asymmetric variants known techniques
tautology, subsumption, blocked clause elimination procedures, additionally developed
161

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

novel family (including plain asymmetric variants) so-called covered clause elimination procedures. analyzed variants various perspectivesrelative effectiveness,
BCP-preserving, confluence, logical equivalencehighlighting intricate differences
procedures. also resulted relative power hierarchy, reflecting relative strengths
procedures removing clauses. terms relative power, asymmetric variant covered
clause elimination dominates plain procedures, novel covered clause elimination procedures powerful ones among considered procedures. Complementing
theoretical analysis, presented results empirical evaluation practical effectiveness
procedures speeding-up overall solving runtime state-of-the-art SAT QSAT solvers
real-world benchmark instances. results show that, effects SAT-level
modest, applying clause elimination procedures clearly beneficial context QSAT
solving.
Many SAT-level clause elimination procedures already integrated inprocessing techniques state-of-the-art SAT solver. important aspect future work would
integrate procedures inprocessing techniques QSAT solver. motivation
similar current state-of-the-art inprocessing SAT solvers: speed satisfiability search via interleaving applications preprocessing techniques core search
routine. example, clauses may become blocked solving process removed.
additional question investigate whether possible loosen blocking criterion taking variable dependencies account. would also interesting perform thorough in-depth
study clause elimination context generalizations formalisms related SAT,
maximum satisfiability (MaxSAT) extraction minimally unsatisfiable subsets
(MUSes) CNF formulas. recent work looking possibilities applying
SAT-based preprocessing contexts MUS MaxSAT (Belov, Jarvisalo, & Marques-Silva,
2013a; Belov, Morgado, & Marques-Silva, 2013b; Berg, Saikko, & Jarvisalo, 2015)including
use BCEwe believe directions yet fully explored.

Acknowledgments
authors would like thank Donald Knuth comments helped improve article.
authors gratefully acknowledge financial support DARPA contract number N66001-102-4087 (MH); Academy Finland grants 251170 COIN Centre Excellence Computational Inference Research, 276412, 284591 (MJ); Austrian Science Foundation (FWF) NFN
Grants S11408-N23 RiSE (AB) S11409-N23 RiSE (FL); Vienna Science Technology
Fund (WWTF) grant ICT10-018 (MS).

References
Bacchus, F. (2002). Enhancing Davis Putnam extended binary clause reasoning. Dechter, R.,
& Sutton, R. S. (Eds.), Proceedings 18th National Conference Artificial Intelligence
(AAAI 2002), pp. 613619. AAAI Press.
Balabanov, V., & Jiang, J.-H. R. (2011). Resolution proofs Skolem functions QBF evaluation applications. Gopalakrishnan, G., & Qadeer, S. (Eds.), Proceedings 23rd
162

fiC LAUSE E LIMINATION



SAT



QSAT

International Conference Computer Aided Verification (CAV 2011), Vol. 6806 Lecture
Notes Computer Science, pp. 149164. Springer.
Balint, A., Belov, A., Jarvisalo, M., & Sinz, C. (2015). Overview analysis SAT Challenge
2012 solver competition. Artificial Intelligence, 223, 120155.
Belov, A., Jarvisalo, M., & Marques-Silva, J. (2013a). Formula preprocessing MUS extraction.
Piterman, N., & Smolka, S. A. (Eds.), Proceedings 19th International Conference
Tools Algorithms Construction Analysis Systems (TACAS 2013), Vol. 7795
Lecture Notes Computer Science, pp. 108123. Springer.
Belov, A., Morgado, A., & Marques-Silva, J. (2013b). SAT-based preprocessing MaxSAT.
McMillan, K. L., Middeldorp, A., & Voronkov, A. (Eds.), Proceedings 19th International Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR19), Vol. 8312 Lecture Notes Computer Science, pp. 96111. Springer.
Benedetti, M. (2005a). Extracting certificates quantified boolean formulas. Kaelbling, L. P.,
& Saffiotti, A. (Eds.), Proceedings 19th International Joint Conference Artificial
Intelligence (IJCAI 2005), pp. 4753. Professional Book Center.
Benedetti, M. (2005b). sKizzo: Suite Evaluate Certify QBFs. Nieuwenhuis, R. (Ed.),
Proceedings 20th International Conference Automated Deduction (CADE-20), Vol.
3632 Lecture Notes Computer Science, pp. 369376. Springer.
Benedetti, M., & Mangassarian, H. (2008). QBF-based formal verification: Experience perspectives. Journal Satisfiability, Boolean Modeling Computation, 5(1-4), 133191.
Berg, J., Saikko, P., & Jarvisalo, M. (2015). Improving effectiveness SAT-based preprocessing MaxSAT. Proceedings 24th International Joint Conference Artificial
Intelligence (IJCAI 2015). AAAI Press.
Biere, A. (2005). Resolve expand. Hoos, H. H., & Mitchell, D. G. (Eds.), Revised Selected Papers 7th International Conference Theory Applications Satisfiability
Testing (SAT 2004), Vol. 3542 Lecture Notes Computer Science, pp. 5970. Springer.
Biere, A. (2013). Lingeling, Plingeling Treengeling entering SAT Competition 2013.
Balint, A., Belov, A., Heule, M., & Jarvisalo, M. (Eds.), Proceedings SAT Competition
2013, Vol. B-2013-1 Department Computer Science Series Publications B, pp. 51
52. University Helsinki.
Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.). (2009). Handbook Satisfiability, Vol.
185 Frontiers Artificial Intelligence Applications. IOS Press.
Biere, A., Lonsing, F., & Seidl, M. (2011). Blocked clause elimination QBF. Bjrner, N.,
& Sofronie-Stokkermans, V. (Eds.), Proceedings 23rd International Conference
Automated Deduction (CADE 2011), Vol. 6803 Lecture Notes Computer Science, pp.
101115. Springer.
Brafman, R. I. (2004). simplifier propositional formulas many binary clauses. IEEE
Transactions Systems, Man, Cybernetics, Part B, 34(1), 5259.
Bubeck, U., & Kleine Buning, H. (2007). Bounded universal expansion preprocessing QBF.
Marques-Silva, J., & Sakallah, K. A. (Eds.), Proceedings 10th International Conference
163

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Theory Applications Satisfiability Testing (SAT 2007), Vol. 4501 Lecture Notes
Computer Science, pp. 244257. Springer.
Cadoli, M., Giovanardi, A., & Schaerf, M. (1998). algorithm evaluate quantified boolean
formulae. Mostow, J., & Rich, C. (Eds.), Proceedings 15th National Conference
Artificial Intelligence (AAAI 1998), pp. 262267. AAAI Press / MIT Press.
Calabro, C., Impagliazzo, R., & Paturi, R. (2009). complexity satisfiability small depth
circuits. Chen, J., & Fomin, F. V. (Eds.), Revised Selected Paper 4th International
Workshop Parameterized Exact Computation (IWPEC 2009), Vol. 5917 Lecture
Notes Computer Science, pp. 7585. Springer.
Claessen, K., Een, N., Sheeran, M., & Sorensson, N. (2008). SAT-solving practice. Proceedings 9th International Workshop Discrete Event Systems (WODES 2008), pp. 6167.
IEEE.
Cook, S. A. (1971). complexity theorem-proving procedures. Harrison, M. A., Banerji,
R. B., & Ullman, J. D. (Eds.), Proceedings 3rd Annual ACM Symposium Theory
Computing (STOC 1971), pp. 151158. ACM.
Een, N., & Biere, A. (2005). Effective preprocessing SAT variable clause elimination.
Bacchus, F., & Walsh, T. (Eds.), Proceedings 8th International Conference Theory
Applications Satisfiability Testing (SAT 2005), Vol. 3569 Lecture Notes Computer
Science, pp. 6175. Springer.
Egly, U., Lonsing, F., & Widl, M. (2013). Long-distance resolution: Proof generation strategy extraction search-based QBF solving. McMillan, K., Middeldorp, A., & Voronkov,
A. (Eds.), Proceedings 19th International Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR 2013), Vol. 8312 Lecture Notes Computer
Science, pp. 291308. Springer.
Fourdrinoy, O., Gregoire, E., Mazure, B., & Sas, L. (2007a). Eliminating redundant clauses SAT
instances. Hentenryck, P. V., & Wolsey, L. A. (Eds.), Proceedings 4th International
Conference Integration AI Techniques Constraint Programming (CPAIOR
2007), Vol. 4510 Lecture Notes Computer Science, pp. 7183. Springer.
Fourdrinoy, O., Gregoire, E., Mazure, B., & Sas, L. (2007b). Reducing hard SAT instances
polynomial ones. Proceedings 8th IEEE International Conference Information
Reuse Integration (IRI 2007), pp. 1823. IEEE.
Freeman, J. (1995). Improvements propositional satisfiability search algorithms. Ph.D. thesis,
University Pennsylvania.
Garey, M. R., & Johnson, D. S. (1979). Computers Intractability: Guide Theory
NP-Completeness. W. H. Freeman.
Gershman, R., & Strichman, O. (2005). Cost-effective hyper-resolution preprocessing CNF
formulas. Bacchus, F., & Walsh, T. (Eds.), Proceedings 8th International Conference
Theory Applications Satisfiability Testing (SAT 2005), Vol. 3569 Lecture Notes
Computer Science, pp. 423429. Springer.
Giunchiglia, E., Marin, P., & Narizzano, M. (2010). sQueezeBF: effective preprocessor
QBFs based equivalence reasoning. Strichman, O., & Szeider, S. (Eds.), Proceedings
164

fiC LAUSE E LIMINATION



SAT



QSAT

13th International Conference Theory Applications Satisfiability Testing (SAT
2010), Vol. 6175 Lecture Notes Computer Science, pp. 8598. Springer.
Goultiaeva, A., & Bacchus, F. (2013). Recovering utilizing partial duality QBF. Jarvisalo,
M., & Gelder, A. V. (Eds.), Proceedings 16th International Conference Theory
Applications Satisfiability Testing (SAT 2013), Vol. 7962 Lecture Notes Computer
Science, pp. 8399. Springer.
Goultiaeva, A., Seidl, M., & Biere, A. (2013). Bridging gap dual propagation
CNF-based QBF solving. Macii, E. (Ed.), Proceedings Design, Automation Test
Europe Conference & Exhibition (DATE 2013), pp. 811814. EDA Consortium / ACM DL.
Goultiaeva, A., Van Gelder, A., & Bacchus, F. (2011). uniform approach generating proofs
strategies true false QBF formulas. Walsh, T. (Ed.), Proceedings
22nd International Joint Conference Artificial Intelligence (IJCAI 2011), pp. 546553.
IJCAI/AAAI Press.
Han, H., & Somenzi, F. (2007). Alembic: efficient algorithm CNF preprocessing. Proceedings 44th Design Automation Conference (DAC 2007), pp. 582587. IEEE.
Han, H., & Somenzi, F. (2009). On-the-fly clause improvement. Kullmann, O. (Ed.), Proceedings
12th International Conference Theory Applications Satisfiability Testing (SAT
2009), Vol. 5584 Lecture Notes Computer Science, pp. 209222. Springer.
Heule, M., Jarvisalo, M., & Biere, A. (2010). Clause elimination procedures CNF formulas.
Fermuller, C., & Voronkov, A. (Eds.), Proceedings 17th International Conference
Logic Programming, Artificial Intelligence Reasoning (LPAR-17), Vol. 6397
Lecture Notes Computer Science, pp. 357371. Springer.
Heule, M., Jarvisalo, M., & Biere, A. (2013a). Covered clause elimination. Fermuller, C., &
Voronkov, A. (Eds.), Short Paper Proceedings 17th International Conference Logic
Programming, Artificial Intelligence Reasoning (LPAR-17), Vol. 13 EasyChair
Proceedings Computing, pp. 4146.
Heule, M., Jarvisalo, M., & Biere, A. (2013b). Revisiting hyper binary resolution. Gomes, C. P.,
& Sellmann, M. (Eds.), Proceedings 10th International Conference Integration
AI Techniques Constraint Programming Combinatorial Optimization Problems
(CPAIOR 2013), Vol. 7874 Lecture Notes Computer Science, pp. 7793. Springer.
Heule, M., Seidl, M., & Biere, A. (2014a). Unified Proof System QBF Preprocessing.
Demri, S., Kapur, D., & Weidenbach, C. (Eds.), Proceedings 7th International Joint
Conference Automated Reasoning (IJCAR 2014), Vol. 8562 Lecture Notes Computer
Science, pp. 91106. Springer.
Heule, M., Seidl, M., & Biere, A. (2014b). Efficient extraction Skolem functions QRAT
proofs. Claessen, K., & Kuncak, V. (Eds.), Proceedings 14th International Conference Formal Methods Computer-Aided Design (FMCAD 2014), pp. 107114. IEEE.
Heyman, T., Smith, D., Mahajan, Y., Leong, L., & Abu-Haimed, H. (2014). Dominant controllability
check using QBF-solver netlist optimizer. Sinz, C., & Egly, U. (Eds.), Proceedings
17th International Conference Theory Applications Satisfiability Testing (SAT
2014), Vol. 8561 Lecture Notes Computer Science, pp. 227242. Springer.
165

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Impagliazzo, R., Paturi, R., & Zane, F. (2001). problems strongly exponential complexity?. Journal Computer System Sciences, 63(4), 512530.
Janota, M., Grigore, R., & Marques-Silva, J. (2013). QBF proofs preprocessing. McMillan, K. L., Middeldorp, A., & Voronkov, A. (Eds.), Proceedings 19th International
Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR-19),
Vol. 8312 Lecture Notes Computer Science, pp. 473489. Springer.
Janota, M., Klieber, W., Marques-Silva, J., & Clarke, E. (2012). Solving QBF counterexample
guided refinement. Cimatti, A., & Sebastiani, R. (Eds.), Proceedings 15th International Conference Theory Applications Satisfiability Testing (SAT 2012), Vol. 7317
Lecture Notes Computer Science, pp. 114128. Springer.
Jarvisalo, M., & Biere, A. (2010). Reconstructing solutions blocked clause elimination.
Strichman, O., & Szeider, S. (Eds.), Proceedings 13th International Conference
Theory Applications Satisfiability Testing (SAT 2010), Vol. 6175 Lecture Notes
Computer Science, pp. 340345. Springer.
Jarvisalo, M., Biere, A., & Heule, M. (2010). Blocked clause elimination. Esparza, J., & Majumdar, R. (Eds.), Proceedings 16th International Conference Tools Algorithms
Construction Analysis Systems (TACAS 2010), Vol. 6015 Lecture Notes
Computer Science, pp. 129144. Springer.
Jarvisalo, M., Biere, A., & Heule, M. (2012a). Simulating circuit-level simplifications CNF.
Journal Automated Reasoning, 49(4), 583619.
Jarvisalo, M., Heule, M., & Biere, A. (2012b). Inprocessing rules. Gramlich, B., Miller, D.,
& Sattler, U. (Eds.), Proceedings 6th International Joint Conference Automated
Reasoning (IJCAR 2012), Vol. 7364 Lecture Notes Computer Science, pp. 355370.
Springer.
Jarvisalo, M., & Korhonen, J. H. (2014). Conditional lower bounds failed literals related
techniques. Sinz, C., & Egly, U. (Eds.), Proceedings 17th International Conference
Theory Applications Satisfiability Testing (SAT 2014), Vol. 8561 Lecture Notes
Computer Science, pp. 7584. Springer.
Jarvisalo, M., Le Berre, D., Roussel, O., & Simon, L. (2012). international SAT solver competitions. AI Magazine, 33(1), 8992.
Jin, H., & Somenzi, F. (2005). incremental algorithm check satisfiability bounded model
checking. Electronic Notes Theoretical Computer Science, 119(2), 5165.
Jordan, C., & Seidl, M. (2014). QBF Gallery 2014. http://qbf.satisfiability.org/
gallery/.
Kleine Buning, H., & Bubeck, U. (2009). Theory quantified Boolean formulas. Biere, A.,
Heule, M., van Maaren, H., & Walsh, T. (Eds.), Handbook Satisfiability, Vol. 185 Frontiers Artificial Intelligence Applications, pp. 735760. IOS Press.
Kleine Buning, H., Karpinski, M., & Flogel, A. (1995). Resolution Quantified Boolean Formulas. Information Computation, 117(1), 1218.
Klieber, W. (2014).
Formal Verification Using Quantified Boolean Formulas
(QBF).
Ph.D. thesis, Carnegie Mellon University, available http://reportsarchive.adm.cs.cmu.edu/anon/2014/CMU-CS-14-117.pdf.
166

fiC LAUSE E LIMINATION



SAT



QSAT

Klieber, W., Sapra, S., Gao, S., & Clarke, E. M. (2010). non-prenex, non-clausal QBF solver
game-state learning. Strichman, O., & Szeider, S. (Eds.), Proceedings 13th
International Conference Theory Applications Satisfiability Testing (SAT 2010),
Vol. 6175 Lecture Notes Computer Science, pp. 128142. Springer.
Kullmann, O. (1999). generalization extended resolution. Discrete Applied Mathematics,
9697, 149176.
Kupferschmid, S., Lewis, M. D. T., Schubert, T., & Becker, B. (2011). Incremental preprocessing
methods use BMC. Formal Methods System Design, 39(2), 185204.
Le Berre, D. (2001). Exploiting real power unit propagation lookahead. Electronic Notes
Discrete Mathematics, 9, 5980.
Liberatore, P. (2005). Redundancy logic I: CNF propositional formulae. Artificial Intelligence,
163(2), 203232.
Lonsing, F., & Biere, A. (2010). DepQBF: dependency-aware QBF solver. Journal Satisfiability, Boolean Modeling Computation, 7(2-3), 7176.
Lynce, I., & Marques-Silva, J. (2001). interaction simplification search propositional satisfiability. CP01 Workshop Modeling Problem Formulation.
Mangassarian, H., Le, B., Goultiaeva, A., Veneris, A. G., & Bacchus, F. (2010). Leveraging dominators preprocessing QBF. Design, Automation Test Europe (DATE 2010), pp.
16951700. IEEE.
Manthey, N., Heule, M., & Biere, A. (2013). Automated reencoding boolean formulas. Biere,
A., Nahir, A., & Vos, T. E. J. (Eds.), Revised Selected Papers 8th International Haifa
Verification Conference (HVC 2012), Vol. 7857 Lecture Notes Computer Science, pp.
102117. Springer.
Marin, P., Miller, C., & Becker, B. (2012). Incremental QBF preprocessing partial design verification - (poster presentation). Cimatti, A., & Sebastiani, R. (Eds.), Proceedings 15th
International Conference Theory Applications Satisfiability Testing (SAT 2012),
Vol. 7317 Lecture Notes Computer Science, pp. 473474. Springer.
Marques-Silva, J. (2008). Practical applications Boolean satisfiability. Proceedings 9th
International Workshop Discrete Event Systems (WODES 2008), pp. 7480. IEEE.
Niemetz, A., Preiner, M., Lonsing, F., Seidl, M., & Biere, A. (2012). Resolution-based certificate
extraction QBF - (tool presentation). Cimatti, A., & Sebastiani, R. (Eds.), Proceedings
15th International Conference Theory Applications Satisfiability Testing (SAT
2012), Vol. 7317 Lecture Notes Computer Science, pp. 430435. Springer.
Ostrowski, R., Gregoire, E., Mazure, B., & Sas, L. (2002). Recovering exploiting structural
knowledge CNF formulas. Hentenryck, P. V. (Ed.), Proceedings 8th International Conference Principles Practice Constraint Programming (CP 2002), Vol.
2470 Lecture Notes Computer Science, pp. 185199. Springer.
Piette, C., Hamadi, Y., & Sas, L. (2008). Vivifying propositional clausal formulae. Ghallab,
M., Spyropoulos, C. D., Fakotakis, N., & Avouris, N. M. (Eds.), Proceedings 18th European Conference Artificial Intelligence (ECAI 2008), Vol. 178 Frontiers Artificial
Intelligence Applications, pp. 525529. IOS Press.
167

fiH EULE , J ARVISALO , L ONSING , EIDL , & B IERE

Pigorsch, F., & Scholl, C. (2010). AIG-based QBF-solver using SAT preprocessing.
Sapatnekar, S. S. (Ed.), Proceedings 47th Design Automation Conference (DAC 2010),
pp. 170175. ACM.
Pulina, L., & Tacchella, A. (2009). structural approach reasoning quantified boolean
formulas. Boutilier, C. (Ed.), Proceedings 21st International Joint Conference
Artificial Intelligence (IJCAI 2009), pp. 596602.
Robinson, J. A. (1965). machine-oriented logic based resolution principle. Journal
ACM, 12(1), 2341.
Sabharwal, A., Ansotegui, C., Gomes, C. P., Hart, J. W., & Selman, B. (2006). QBF Modeling: Exploiting Player Symmetry Simplicity Efficiency. Biere, A., & Gomes, C. P. (Eds.),
Proceedings 9th International Conference Theory Applications Satisfiability
Testing (SAT 2006), Vol. 4121 Lecture Notes Computer Science, pp. 382395. Springer.
Samer, M. (2008). Variable dependencies quantified CSPs. Cervesato, I., Veith, H., &
Voronkov, A. (Eds.), Proceedings 15th International Conference Logic Programming, Artificial Intelligence, Reasoning (LPAR 2008), Vol. 5330 Lecture Notes
Computer Science, pp. 512527. Springer.
Samulowitz, H., Davies, J., & Bacchus, F. (2006). Preprocessing QBF. Benhamou, F. (Ed.),
Proceedings 12th International Conference Principles Practice Constraint
Programming (CP 2006), Vol. 4204 Lecture Notes Computer Science, pp. 514529.
Springer.
SAT Competitions Organizing Committee (2014). international SAT Competitions web page.
http://satcompetition.org/.
Schaefer, T. J. (1978). complexity two-person perfect-information games. Journal
Computer System Sciences, 16(2), 185225.
Seidl, M., & Biere, A. (2015). Bloqqer. http://fmv.jku.at/bloqqer.
Seidl, M., & Konighofer, R. (2014). Partial witnesses preprocessed quantified Boolean formulas. Proceedings Design, Automation & Test Europe Conference & Exhibition (DATE
2014), pp. 16. IEEE.
Subbarayan, S., & Pradhan, D. K. (2005). NiVER: Non-increasing variable elimination resolution
preprocessing SAT instances. Hoos, H. H., & Mitchell, D. G. (Eds.), Proceedings
7th International Conference Theory Applications Satisfiability Testing (SAT 2004),
Vol. 3542 Lecture Notes Computer Science, pp. 276291. Springer.
Van Gelder, A. (2005). Toward leaner binary-clause reasoning satisfiability solver. Annals
Mathematics Artificial Intelligence, 43(1), 239253.
Van Gelder, A., Wood, S. B., & Lonsing, F. (2012). Extended failed-literal preprocessing quantified boolean formulas. Cimatti, A., & Sebastiani, R. (Eds.), Proceedings 15th
International Conference Theory Applications Satisfiability Testing (SAT 2012),
Vol. 7317 Lecture Notes Computer Science, pp. 8699. Springer.
Zhang, L. (2006). Solving QBF combining conjunctive disjunctive normal forms. Gil, Y.,
& Mooney, R. J. (Eds.), Proceedings 21st National Conference Artificial Intelligence
(AAAI 2006), pp. 143150. AAAI Press.

168

fiJournal Artificial Intelligence Research 53 (2015) 41-90

Submitted 03/14; published 05/15

Learning Relational Event Models Video
Krishna S. R. Dubba
Anthony G. Cohn
David C. Hogg

krishna.dubba@gmail.com
a.g.cohn@leeds.ac.uk
d.c.hogg@leeds.ac.uk

School Computing, University Leeds,
Leeds, UK. LS2 9JT

Mehul Bhatt
Frank Dylla

bhatt@informatik.uni-bremen.de
dylla@informatik.uni-bremen.de

Cognitive Systems, SFB/TR 8 Spatial Cognition
University Bremen, Bremen 28334, Germany

Abstract
Event models obtained automatically video used applications ranging
abnormal event detection content based video retrieval. multiple agents
involved events, characterizing events naturally suggests encoding interactions
relations. Learning event models kind relational spatio-temporal data using
relational learning techniques Inductive Logic Programming (ILP) hold promise,
successfully applied large datasets result video data.
paper, present novel framework remind (Relational Event Model INDuction)
supervised relational learning event models large video datasets using ILP.
Efficiency achieved learning interpretations setting using typing
system exploits type hierarchy objects domain. use types also
helps prevent generalization. Furthermore, also present type-refining operator
prove optimal. learned models used recognizing events
previously unseen videos. also present extension framework integrating
abduction step improves learning performance noise input
data. experimental results several hours video data two challenging real
world domains (an airport domain physical action verbs domain) suggest
techniques suitable real world scenarios.

1. Introduction
advent digital technology wide availability cameras video recorders,
quantity video data increased enormously recent years, e.g., YouTube users
upload 100 hours video site every minute (YouTube, 2015). data
semantically rich lack algorithms process utilize data effectively.
number applications demand video processing, especially event modelling
recognition, content based video search, robotics, automatic description
activities, video surveillance etc. main objective work provide supervised
relational learning framework learn high level human understandable event models
use recognize events video. Supervised learning machine learning task
inferring model labelled training data.
c
2015
AI Access Foundation. rights reserved.

fiDubba, Cohn, Hogg, Bhatt & Dylla

Video considered sequence images area video analysis poses several
challenges. interesting aspect video compared images objects
(or parts objects) video perceived move space time. changes
state space dimension interesting call events satisfy certain
properties sufficiently frequent sufficiently well defined boundaries
etc. event change state single object, moving parts
body (for example people waving hands) interaction multiple
objects. interactions, context, mean movement objects relative
surroundings well relative other. example, interaction
two objects might objects moving towards one rest
moving away it. events recognized, assume objects involved
detected tracked source video. requirement general
since approaches (Laptev, 2005) require detection objects prior event
detection.
events involving multiple objects, interactions objects become distinguishing factor recognizing event instance. Capturing interactions crux
event modelling recognition hypothesis event distinguished
interactions objects involved. events might one
interaction pattern identifies event. One way capture interactions
abstract interactions relations objects. order represent interactions objects abstract form, use relations objects depend
spatial configuration motion pattern objects period time. call
spatio-temporal relations paper focus purely use qualitative
spatial relations since abstract away metric details particular object trajectories thus facilitate recognition interactions instances event
class (Cohn et al., 2006). unique way represent interactions using qualitative
spatio-temporal relations, best set relations use depends domain, kind
data available (speed, orientation, size moving objects, etc.) objectives
task.
Though event class distinguishing interaction patterns, two particular
challenges event learning examples expressed qualitative spatio-temporal relations. Firstly, automatic object detection tracking video perfect
introduce errors relations. Secondly, event may performed different
ways.
1.1 Overview Framework
follow relational learning approach cognitive vision task learning event
models videos using recognition (Cohn et al., 2006; Dubba, Cohn, &
Hogg, 2010). video data (sequence images pixel data) converted relational
facts involving qualitative spatio-temporal relations using tracking data objects
involved scenes. use several qualitative spatial calculi represent video
data relational form. Event instances annotated temporally spatially though
objects involved event delineated separately annotations used
obtaining positive negative examples events. learning procedure well
42

fiLearning Relational Event Models Video

extension procedure using abduction (explained later sections) applied
relational data obtain event models. event models form
Prolog rules used queries relational data unseen video.
answer substitutions extract spatial temporal extensions recognized event
instances.
main contributions1 paper are:
novel supervised relational learning framework remind learning event models
video recognizing event instances using models.
optimal Type Refinement operator upward refinement hypotheses exploits type hierarchy domain finding better event models.
extended framework integrate induction abduction interleaved fashion
embedded spatial theory improving learning event models.
evaluation framework two real world video data sets (aircraft turn-arounds
events include aircraft arrival, luggage loading human interactions
events common action verbs exchange, follow, dig etc).
Though concentrate relational data obtained tracking objects video,
principles techniques work equally apply spatio-temporal relational data
acquired non-visual sources (e.g. laser mapping, GPS tracks, textual descriptions etc).

2. Related Work
Much work event analysis (Ivanov & Bobick, 2000; Medioni, Cohen, Bremond,
Hongeng, & Nevatia, 2001; Vu, Bremond, & Thonnat, 2003; Albanese, Moscato, Picariello,
Subrahmanian, & Udrea, 2007; Ryoo & Aggarwal, 2009, 2011; Morariu & Davis, 2011),
involve learning models used. Instead high level event models hand-coded
using different representations (Nevatia, Hobbs, & Bolles, 2004; Hakeem, Sheikh, & Shah,
2004).
Techniques based similarity based metric space low level pixel based
features local space-time features (Laptev, 2005) frequently used modelling
recognizing events. generally suitable single agent events like human
activities based motion. kind activities generally include particular motion
signature event recognized running, jumping, waving hands
etc. event recognition systems, hand-coded high level event models used top
learned low level human activity models (Ivanov & Bobick, 2000; Ryoo & Aggarwal,
2009, 2011).
One best performances date event recognition using low level pixel-based
features obtained Stack convolutional Independent Subspace Analysis (ScISA) (Le,
Zou, Yeung, & Ng, 2011) algorithm. ScISA based pixel level flow based features
used model events using hierarchical representation using deep learning
techniques (Bengio, 2009). authors present extension Independent Subspace
1. paper extended version work Dubba et al. (2010, 2012).

43

fiDubba, Cohn, Hogg, Bhatt & Dylla

Analysis learn invariant spatio-temporal features unsupervised fashion instead
using predefined features.
events considered sequence primitive states events, state-space models
useful representing event models. also easy hand-code structure
state space models, though parameters better learned encoded hand.
provide robust statistical event model hand-coded models event recognition
done using inference models. Bayesian Networks popular event
modelling lack temporal aspect though state space models Hidden
Markov Models (HMM) (Rabiner, 1989) Dynamic Bayesian Networks (DBN) (Ghahramani, 1998) extensively used event modelling recognition. simple HMM
effective modelling complex events. Several extensions HMM used suit
context type event models. Hoogs Perera (2008) proposed DBN jointly
solving event recognition broken tracks linking problems. event model set
discrete states expresses actors event interact time. assume
states strictly ordered may limit learning events involve complex
temporal relations during, overlaps etc.
main problem state space models difficult encode high-level
temporal relations during, overlaps etc. states sub-events event
assumed sequential order case many domains. Also
states propositional nature hence semantically less complex relational
representation.
Veeraraghavan et al. (2007) learn Stochastic Context Free Grammar based models
traffic videos using predefined regions image. event model spatio-temporal
pattern primitive actions expressed string, = a1 , a2 , . . . , . event learning
algorithm aims find grammar generate corresponding pattern event.
primitive actions sequentially arranged, hence Allens temporal relations
used connect primitive actions. Gupta et al. (2009) claim fixed structure
DBNs poses serious limitations modelling events many variations
way event happen. Instead use AND-OR graphs modelling event models.
order nodes imposes causal relationship among nodes. this,
Allen relationships during, overlaps etc. cannot modelled limits
application since modelling relations important many domains.
Though low-level features state space models popular simple motion patterns,
possible build high-level event recognition systems several layers reasoning.
systems use simple pattern recognition techniques detect primitive events
use temporal structure reason complex events. main motivation using
high level temporal structure low level features (like bag-of-features) discard
information regarding relations different entities data
thus makes hard recognize events involving complex interactions multiple
objects.
Moyle Muggleton demonstrated using simple blocks world domain specific
axioms learned temporal observations using ILP framework (Moyle & Muggleton, 1997). work Needham et al. (2005), Progol system (Muggleton, 1995)
used learn protocols table top games real sensory data video camera microphone. key aspect work method spatio-temporal attention
44

fiLearning Relational Event Models Video

applied sensor data audio video devices. identifies subsets sensor
data relating discrete concepts. Symbolic description continuous data obtained
clustering within continuous feature spaces processed sensor data. Progol
ILP system subsequently used learn symbolic models temporal protocols present
presence noise over-representation symbolic input data. framework
based time points used successor temporal relation.
Konik Laird (2006) proposed learning observation framework learn agent
program mimics human experts behaviour domains games. learned
concepts used generate behaviour rather classification. applied ILP techniques artificially created examples expert behaviour traces goal annotations.
relational data used simple predicate valid situation (an abstract time
point) hence concepts sophisticated temporal relations Allens interval
algebra (Allen, 1983) use intervals cannot learned. limits real world applicability framework different events occurring parallel hence
requires using Allens interval algebra model them. framework uses positive
examples negative examples generated randomly controlled fashion.
Fern, Givan Siskind (2002) introduced system, leonard, learns event definitions videos following standard specific-to-general learning approach
positive data. seven simple event types learned system namely
pick up, put down, stack, unstack, move, assemble disassemble. relational data
obtained tracking objects indoor scenarios. negative examples supplied
event models found computing least-general covering formula (LGCF)
positive example computing least-general generalisation (LGG)
resulting formulae. computing LGCF example, resulting LGCF
interval information. Hence model support equal
temporal relations states.
important aspect note review work area
done either artificial simulated data (Moyle & Muggleton, 1997; Konik &
Laird, 2006) simple real world data (Fern et al., 2002; Needham et al., 2005)
involves objects, events short duration objects scene
involved events. case, tracked data videos large
time complex noisy contains objects.
Several attempts made literature integrating induction abduction
learning better theories. pointed Tammaddoni-Nezhad et al. (2006) abduction induction integrated general two conditions hold: background
knowledge incomplete hypothesis language disjoint observation language. setting latter condition holds called non Observation Predicate
Learning (non-OPL) setting (i.e. OPL setting, examples hypotheses define
predicate). assume existence theory connects hypothesis
language observation language start with. Since theory learned,
considered background theory. general strategy case abduce (Kakas & Riguzzi, 2000) missing observations using background theory use
abduced data inducing new theories. Muggleton Bryant (2000) proposed Theory Completion using Inverse Entailment (TCIE) non-OPL setting. TCIE abduces
adds facts called Start Set connect target predicate observable pred45

fiDubba, Cohn, Hogg, Bhatt & Dylla

icates observation data generalizes data. case, missing facts
noise observed data set target predicates set
observables whereas TCIE, target predicate observable
set target predicates set observables disjoint.
Moyle (2003) introduces ILP system (alecto) combines abduction induction learn theories robot navigation. One limitation system
restricted positive observations learning. integration interleaved nature abduction first used generate explanations example induction
applied set explanations. means abduction phase take
consideration concepts learned induction phase dealing noise data
left future work.

3. Relational Representation Scenes Video
represent interactions objects relational data, use spatial temporal relations.
Since input work video, spatial relations defined either
image plane ground plane (if homography used map image plane
ground plane). spatial relations necessary encode state particular pair
objects in. states two objects change time progresses, hence
need temporal relations connect states. section, explain objects
interactions converted relational data.
Notation: use first-order typed language (L) following alphabet: {, , ,
, , , ,R}. Let R = {r1 , r2 , . . . , rm } denote set qualitative spatial relationships
arbitrary qualitative spatial calculus. sorts (and corresponding variables)
given (upper case letter denotes set lower case letter denotes set element):
time points



time intervals



spatial objects



events

E

temporal relations



object types



special event-predicate tran(ri , ok , ol , tm ) E denotes transition spatial
relation ri objects ok ol time point tm . Note work,
take values set 13 Allens base relations (Allen, 1983) i.e. = {before, after,
meets, met by, overlaps, overlapped by, during, contains, equals, finishes, finished by, starts,
started by}. say two intervals disjoint Allen relation
set {before, after, meets, met by}.
3.1 Spatial Relations
order get high level description interactions objects videos, need relations encode interactions objects without loss essential information (Cohn
et al., 2006). several possibilities kind relations choose.
Since interactions objects video take place spatial dimensions, natural
46

fiLearning Relational Event Models Video



?







?





?











Figure 1: Qualitative Trajectory Calculus (QT CL1 ) (Van de Weghe et al., 2006):
blob possible QT CL1 spatial relation. blob, asterix (left object) circle (right
object) represent objects motion star black dot represent objects rest
direction arrow shows direction motion object. example,
top-left ellipse interpreted two objects moving towards bottom-left
ellipse interpreted right object moving away left object left
object moving towards right object (i.e left object chasing right object).
Though nine relations possible QT CL1 shown figure, practice
reduce six exploiting symmetry relations. one object changes
motion state (note object cannot change direction without going
rest state), QTC relation changes along thick line connecting two relations.
objects change motion state instantaneously, relation changes along dotted line.

use qualitative spatial calculi model interactions. interactions also
temporal dimension occur period time, extend spatial relations
arguments modelling temporal dimension. say interactions objects
mean interactions bounding boxes2 (aligned axes) objects
get tracking objects using computer vision algorithms (Yilmaz, Javed, & Shah,
2006). different kinds spatial calculi target different aspects object
interactions like topology, orientation, direction, trajectories etc. calculi use
domain dependent choice (Chen, Cohn, Liu, Wang, Ouyang, & Yu, 2015). primarily use three spatial relations encode object interactions topological level:
dc (Discrete) intersection pixels bounding boxes two objects empty,
(Inside) intersection pixels pixels bounding box
one objects touch every case. set simple topological relations
abstracted version3 RCC-8 (Randell, Cui, & Cohn, 1992) spatial calculus, reduced
practical purposes without loss essential information event analysis. also use
QT CL1 (Van de Weghe et al., 2006) (Fig.1) domain specific relations primitives
represent interactions objects videos.
2. principle, shape abstractions could used well, e.g. convex hulls, silhouettes, bounding ovals
etc.
3. two relations version RCC called RCC-5 equal contains (inverse in).
relation equal rarely occurs experiments use contains convert
reversing arguments.

47

fiDubba, Cohn, Hogg, Bhatt & Dylla

o1

o1

o1
o2

o2

1

3

2

dc

o2

touch



dc(o1 , o2 , 1 )
touch(o1 , o2 , 2 )
in(o2 , o1 , 3 )
meets(1 , 2 )
meets(2 , 3 )
before(1 , 3 )

Figure 2: Converting interactions objects relational data.
3.2 Temporal Interval Relations
define temporal relations time intervals based Allens interval algebra.
use start end frames interval represent intervals. advantage
approach is, precalculate temporal relations store beforehand
database inference. Instead, Prolog rules calculate temporal relations given start
end time points two intervals used. order incorporate temporal information
describing scenario, extend spatial relations temporal interval extra
argument.
3.2.1 Temporally Extending Spatial Relation
state spatial relation r objects o1 o2 holds throughout interval
represented r(o1 , o2 , ) r R , o1 , o2 . Grounding expression
objects intervals database provide us spatio-temporal facts.
temporal relation two spatio-temporal facts Allen relation
intervals spatio-temporal facts.
3.3 Representing Event Class
event class represented set Horn clauses head predicate
event name consideration body non empty conjunction atoms
consisting spatial temporal predicates.
structure clause event model event class follows:
() : 1 , . . . , , . . . , n
either form r(o1 , o2 , ) r R, o1 , o2 ,
form (1 , 2 ) 1 , 2 .
1
48

fiLearning Relational Event Models Video

4. Deictic Supervision
supervised learning, need positive preferably negative examples event
instances. One major problem supervised learning collecting labelled training
data. general ambiguity defining spatial particular temporal
extent event (i.e. events precisely start finish), difficult annotate
videos event labels. possible approach annotate objects involved
event give events temporal extent. annotating objects tedious prone
human error events may uncertainty objects involved.
avoid using Deictic Supervision (Dubba et al., 2010). Instead annotating
exact objects involved training event instances, give bounding spatial
temporal extent event instance may contain objects. spatial extent
region indicating event happening video. temporal extent
interval includes actual temporal extent event, may deliberately
longer order avoid accidentally truncating state changes relevant event.
makes preparation training data easier learning process robust less
biased labelling learning algorithm able induce reasonable
models even data.
Delineating spatio-temporal volumes videos learn feature-based representations actions hand gestures without precedent computer vision
literature (Laptev & Perez, 2007), use extends multiple simultaneous actors relational descriptions resilience perturbations placement cuboids
provided events fully enclosed.
4.1 Deictic Interval Region
work, deictic spatial region rectangle image plane indicating
event happened deictic interval time interval indicating event
happened. deictic spatial region obtained hand-delimiting event image
plane rectangle4 , hence represented using coordinate point (top-left corner
vertex), height width rectangle (x, y, h, w). deictic temporal interval provided
specifying start end time points interval. Together define space-time
cuboid delimits spatial temporal extension event.
deictic cuboid defines set spatial facts temporal relations them;
event instance subset facts corresponds positive example
learning interpretations setting. Obtaining positive negative examples learning
using event annotations form deictic spatial regions deictic temporal intervals
explained following sections. Note deictic interval region regarded
interval object respectively spatial relations
computed accordingly. positive negative examples computed, spatial
relations involving deictic regions one objects discarded database
use.
4. tracking data ground plane back-project rectangle automatically
minimum enclosing rectangle ground plane using homography (Hartley & Zisserman, 2004).

49

fiDubba, Cohn, Hogg, Bhatt & Dylla

4.2 Herbrand Interpretation Event
Let si deictic spatial region deictic temporal interval instance
event class video v. Let v set spatio-temporal facts present v, Ov
set objects v v set time intervals v. set facts Ei v
Herbrand Interpretation event v iff facts contained
entailed v , whose temporal intervals disjoint deictic interval whose
objects relation touch within deictic region.

Ei = {r(o1 , o2 , ) : v r(o1 , o2 , )
v (i , )
/ {before,after,meets,metby}
1 [v r1 (si , o1 , 1 ) r1 {touch,in}
v 1 (i , 1 ) 1
/ {before,after,meets,metby}]
2 [v r2 (si , o2 , 2 ) r2 {touch,in}
v 2 (i , 2 ) 2
/ {before,after,meets,metby}]
o1 , o2 , si Ov r R 1 , 2 v
}

example interpretation event instance AFT Bulk LoadUnload Airport
domain illustrated Fig.3. interpretation includes spatial facts involving
objects relation touch deictic region lie within
two vertical dashed lines (the deictic interval). set Herbrand Interpretations
corresponding set deictic regions intervals event form positive
examples learning phase. rest relational facts video form
negative example event model fires instance database, considered
false positive. Herbrand Interpretation extracted set spatiotemporal facts video, interpretation independent facts
spatio-temporal database5 video hence facts assumed false
interpretations point view.
Note definition spatio-temporal facts spatio-temporally overlap
deictic region interval event instance relevant event. Considering
facts outside indicated event occurrence increases size training data
also makes example instances different event classes less distinct.
One limitation using cuboid shaped deictic region delineating event instance
possible differentiate among multiple co-occurring instances
event type involving different objects region. One way overcome limitation
use one cuboid enclose event instance allowing elimination unwanted
facts.
5. spatio-temporal database subset Herbrand Base video obtained using
predicates (spatio-temporal relations) constants (objects time intervals) video.

50

fiLearning Relational Event Models Video

Figure 3: example interpretation event AFT Bulk LoadUnload Airport
domain. vertical black lines start end deictic interval. row
represents interactions two objects present deictic region
deictic interval video. colours lines represent spatial relations
pairs objects point time. figure show effect deictic
spatial region, would correspond elimination certain rows (where
objects spatial relation touch whilst deictic spatial region
deictic temporal interval.
4.3 Herbrand Interpretation Non-event Interval (Negative Example)
framework, negative examples explicitly labelled. negative example
given event video set spatio-temporal facts database
video present positive examples event video. Note
negative example general contain data might positive examples
event classes video. Another alternative use labelled positive examples
events negative examples event learning. convenient
classification purposes recognition tasks miss background data
might useful minimize detections background regions.
Let v union spatio-temporal facts Herbrand Interpretations
event video v. set facts NIv v Herbrand Interpretation negative
example event video v iff contains facts v v , i.e.,
NIv = v v .

5. Typed ILP
event learning recognition system, low level image processing computer
vision techniques may introduce noise system. One kind noise, particular
video quality bad videos CCTVs, wrong type may
assigned tracker object history. object detector typically trained
51

fiDubba, Cohn, Hogg, Bhatt & Dylla

Person
Aircraft
GPU
Transporter

Object

Light Vehicle
Push Back
Service Vehicle
Mobile Stairs
Vehicle
Loader
Conveyor Belt
Passenger Boarding Bridge
Heavy Vehicle
Container
Catering
Tanker
Bulk Loader

Figure 4: Tree-structured object type hierarchy Airport domain.
many example images objects detected. Even though many example images
given training, possible capture possible ways object appear
lighting, viewing direction, size, shape, etc. (Lowe, 2004). may result
correctly localized objects wrong categories objects, especially
look visually similar low contrast images.
input data huge noisy, several problems ILP system
face. One hypothesis evaluation take lot time size
data. Also noise tend make hypothesis specific system learns
rules cover inconsistent examples. Using typed ILP system speed
evaluation typed arguments hypothesis (Walther, 1985; Cohn, 1989)
also reduce number false positives avoiding certain cases types
arguments match. event model objects specialized type
fail recognize event instances object appears different type.
contrast, event model type system uses generic type
objects object, thing etc., approach many false positives
cannot differentiate events structure involving different types
objects. One possible approach find appropriate type generalization instead
using one two extremes: generic type specialized type.
ILP systems, type hierarchy objects integrated learning
process. example, Progol, types objects used mode declarations
since assumes flat type hierarchy domain, search procedure cannot
take type hierarchy consideration. example, tracking system sometimes
confuses two types objects (1 , 2 ) objects type 1 misclassified
52

fiLearning Relational Event Models Video

s2
s1

s4
s3
s5

Figure 5: Tree-structured example object type hierarchy. s1 general type
s2 , s4 , s5 specific types.
type 2 , Progol generates two rules, one 1 another 2 . Even
dealing vision system introduces noise high level learning
reasoning system, cases event might involve objects particular sub-group
objects. case, instead using generic type like object particular
types like type object itself, efficient use intermediate generic type
represents sub-group. variable without type restrictions satisfied
type object instantiating Horn clause. However, appropriate generalization
enforced learning system variable type 1 t2 type hierarchy,
satisfied6 objects type 1 2 , thereby reducing false positives.
5.1 Representing Typed Hierarchy
wish use existing Prolog engine hypothesis evaluation way
encoding type using terms must found. several ways depending
whether structure object type hierarchy tree lattice. use
type representation proposed Bundy, Byrd Mellish (1985) deal tree
structured type hierarchies; develop refinement operator incorporating
representation hypothesis search procedure. advantage using representation
ordinary unification used determine whether two types compatible.
write < j , subtype j 6= j . Every object type n
hypothesis represented term 1 (2 (. . . n (o) . . .)) 1 , . . . , n
maximal sequence types n < . . . < 2 < 1 . denote representation
function . Note need constraint, i.e. tree structured type hierarchy,
order guarantee uniqueness sequence 1 , . . . , n .
example, let s1 , s2 , s3 , s4 , s5 types s4 < s3 < s1 , s5 < s3 < s1
s2 < s1 shown Fig.5. object type s4 represented follows:
(o) = s1 (s3 (s4 (o)))

object oi compatible object oj hypothesis (oi ) unifiable
(oj ). example: s1 (s3 (o1 )) unify s1 (s2 (o2 )) unify
s1 (s3 (s4 (o3 ))) s1 (s3 (s5 (o4 ))), hence compatible.
5.1.1 Example Representing Type Hierarchy
object type hierarchy occurs one two domains used evaluation
section work shown Fig.4. hierarchy Fig.4 hand defined based
6. variable type 1 2 unify term type 1 2 .

53

fiDubba, Cohn, Hogg, Bhatt & Dylla

observed errors object classification tracking data Airport domain.
airport domain, ground power unit (GPU), transporter push back vehicle
small vehicles look similar videos CCTV cameras airport
low resolution contrast without much colour sharp edges. makes challenging
train object detector use detecting objects videos. objects
Verbs domain present particular challenges automatic classification point
view events involve objects particular subset objects, example,
throw event involves balls different types like small ball, basket ball, etc. Hence using
type hierarchy based utility expected help find event models better
performance detecting events unseen videos.
vehicle V type GPU represented obj(veh(light veh(gpu(V ))))7
V type light veh represented obj(veh(light veh(V ))). Note
obj(veh(light veh(V ))) unifies vehicles type GPU vehicles type Transporter. using obj(veh(light veh(V ))) model cover examples either
involve GPU Transporter hence handle noise object detector
confuses vehicles outputting GPU place Transporter vice versa.
5.2 Type Refinement Operator
refinement operator used traverse hypothesis lattice. two
types refinement operators: upward downward (Nienhuys-Cheng & De Wolf, 1997).
write Hg Hs Hg generic8 hypothesis Hs . assume
top element hypothesis lattice generic hypothesis bottom
hypothesis specific hypothesis, upward refinement operator
defined follows (the downward refinement operator defined similar fashion):
Let L set possible hypotheses. (upward) refinement operator defined
hypothesis H, produces generalizations H, (H) = {Hg | Hg
H, Hg L}.
define (upward) Type Refinement operator operator generalizes
object types H. Apart object types, structure H members (H)
identical.
define type generalizing operator follows:
generalize type(1 (2 (. . . n1 (n (o)) . . .))) = 1 (2 (. . . n1 (o) . . .))
Type Refinement operator, , applies generalize type operator selected
object type present hypothesis, resulting generic hypothesis moving
exactly one level type hierarchy.
Though specific current representation type hierarchy using functors requires
tree structured hierarchy, tree structured hierarchy beneficial computational viewpoint limiting type generalizations, i.e., multiple ancestors.
tree-like type hierarchy natural many domains though domains might
7. Note short forms used Object, Vehicle Light Vehicle.
8. several possible generality orders, important subsumption logical implication (Nienhuys-Cheng & De Wolf, 1997).

54

fiLearning Relational Event Models Video

well defined tree-like object type hierarchy. cases, lattice structured type
hierarchy suitable though increase size search space since
number possible refinements increased, particular tree structure type generalization deterministic whilst case lattice structure.
5.2.1 Optimality Type Refinement Operator
Refinement operators ideal optimal (Nienhuys-Cheng & De Wolf, 1997)9 .
optimal refinement operator generates hypothesis hypothesis lattice
unique way produce hypothesis. kind refinement operator
desirable complete search algorithms duplicate generation hypotheses increase
cost search procedure. optimality Type Refinement operator proved
Appendix A.

6. Learning Interpretations Setting Learning Event Models
result deictic supervision gives us examples sets spatio-temporal facts.
Though examples (sets facts) come different videos,
independent other, i.e., mapping example class independent
examples. kind learning setting example independent
example set facts, learning interpretations setting
apt choice (Blockeel, De Raedt, Jacobs, & Demoen, 1999). setting specified
formally thus:
Given:
set classes C (each class label c nullary predicate).
set classified examples E (each element E form (Ei , c) Ei set
facts c class label)
background theory B,
Find : hypothesis H (a set Horn clauses), (Ei , c) E:
H Ei B c,
c0 C {c} : H Ei B 2 c0
current event learning problem, setting applied event class
case set classes two elements, event class background class. Background class represents negative examples class label c
nullary predicate.
9. ideal refinement operator proper complete whereas optimal refinement operator weaklycomplete non-redundant. See Appendix formal definitions.

55

fiDubba, Cohn, Hogg, Bhatt & Dylla

6.1 Traversing Search Space
search process hypothesis starts initial hypothesis nullary
predicate head empty body. hypothesis lattice traversed using Progol
Type Refinement operators interleaved fashion. Progol refinement operator
specialization operator adds atoms bottom clause hypothesis.
specialization operator moves top (empty clause) bottom hypothesis
space lattice bounded bottom clause bottom. Adding atoms
bottom clause makes hypothesis specialized body
hypothesis conjunction atoms atom considered constraint.
Adding atoms body increases constraints satisfy become true.
Progol refinement operator use based bottom clause also
called most-specific clause non-redundant though weakly-complete
respect general subsumption order (Tamaddoni-Nezhad & Muggleton, 2009).
most-specific clause Progol refinement operator uses computed training examples, mode declarations background knowledge (Muggleton, 1995). Mode
declarations user defined syntactic biases form predicates specify
predicates background knowledge expected target hypothesis also
nature variables (input, output, constant). selection atoms
added hypothesis bottom clause done controlled manner. atoms
considered starting left moving right atom added
(Tamaddoni-Nezhad & Muggleton, 2009). constraints selection
atoms makes refinement process non-redundant, i.e., hypothesis generated twice.
additional refinement operator refines unifying two variables arbitrarily
selected hypothesis substituting variable constant. use
operator unifying two variables needs checking hypothesis consistency
respect underlying spatial theory fixed constants (apart frame
numbers) domain constants example independent constants
examples. example, consider three relations Section 4.1 spatial
theory Allens relations temporal relations: cannot unify two arguments
predicate (spatial temporal) violates semantics relations.
Type Refinement operator generalizes hypothesis generalizing type
object hypothesis (Fig.6). two possible approaches apply Type
Refinement operator: type first approach select type set types
hypothesis generalize type variables belong selected type
variable first approach select variable hypothesis generalize type
occurrences variable hypothesis. type first approach generalizes
selected type throughout hypothesis may involve several variables
variable first approach generalizes type one variable. work, use
type first approach fewer number refined hypotheses smaller search
space variable first approach larger number choices hence larger
search space. One reason use type first approach computer vision
algorithm might confuse type whole group objects belong particular
type rather single object video inaccurate object detector.
56

fiLearning Relational Event Models Video

Figure 6: Type refinement operator (generalization).
6.2 Searching Event Model
most-specific clause computed, sub-lattice bounded mostspecific clause searched using best-first search hypothesis maximum
score calculated based combination (1) number positive examples covered, (2)
number answer substitutions negative examples, (3) length hypothesis
(4) number distinct variables hypothesis subject given constraints
(discussed next subsection).
score(H) = p (% n + l + v)

= weight positive examples
p = number positive examples covered
% = weight answer substitutions negative examples
n = number answer substitutions negative examples
l = length hypothesis
v = number distinct variables hypothesis
answer substitution example e substitution grounds hypothesis,
h b1 , . . . , bn , query b1 , . . . , bn succeeds database e. Note
learning interpretations setting positive example separate database
hypothesis used Prolog query database, might result multiple
answer substitutions. example considered covered hypothesis one
answer substitutions. testing hypothesis test database, answer
substitution considered one recognized event instance. recognized event interval
falls outside event ground truth test video, considered false positive.
event recognition domain, hypothesis used recognizing events unseen videos
57

fiDubba, Cohn, Hogg, Bhatt & Dylla

instead classifying videos, hypothesis fewer false positives desirable. Hence
hypotheses penalized using number answer substitutions10 negative examples.
number positive negative examples disproportionate numbers, giving
weight positive examples negative examples using % result
hypothesis better performance test data.
Since starting hypothesis empty completely generic, cover
negative examples. hypothesis specialized Progols refinement operator,
number false positives decreases. score hypothesis longer increases,
Type Refinement operator used generalize types thereby increasing generality
hypothesis possible increase positive examples covered (as well false
positives). process interleaved application operators continued
hypothesis score longer increases.
satisfactory hypothesis found, argument representing temporal information
form list time intervals formed using time intervals body
event model introduced head order explicitly represent event
occurs useful using hypothesis event monitoring allows interval
event occurs explicitly flagged viewing video.
learning algorithm uses set covering method (Quinlan, 1990) learn event
model set clauses interpreted disjunction. covering method starts
empty model learns clause using provided positive negative examples
adds clause model. repeats procedure positive examples
covered earlier clause. process repeated positive
examples covered.
6.3 Constraining Search Space
size search space depends size bottom clause (Muggleton, 1995).
Thus, event learning domain, depends number spatial relations
used number objects event instances used positive examples. size
bottom clause increases number Allens temporal relations interval
atoms spatial predicates temporally connected every interval
atoms spatial predicates. creates many atoms temporal predicates
bottom clause.
order decrease size search space, algorithm makes use domaindependent domain-independent constraints structure hypothesis.
constraints algorithm uses restrictions hypothesis length number
variables hypothesis etc. domain-independent structural constraints
depend predicates used domain knowledge. following two
domain-dependent constraints reduce search space time thereby making
learning process efficient.
Upper bounds number atoms body rule.
10. Counting number answer substitutions instead number examples covered heuristic used
FOIL system (Quinlan & Cameron-Jones, 1993).

58

fiLearning Relational Event Models Video

interval atom spatial (temporal) predicate appear atom
temporal (spatial) predicate. hypothesis atoms satisfy
criteria semantically meaningful since might satisfied facts
related event question.
However constraints listed domain dependent constraints rather application specific constraints, i.e., constraints involve spatial temporal
predicates applicable most, event learning scenarios. Note
constraints hard (i.e. inviolate). hypothesis violates constraint,
discarded without scoring refining. example, domain-independent constraints
first domain-dependent constraint mentioned hard. contrast, hypothesis violates constraint hard, example, second domain-dependent
constraint listed above, scored discarded generating refined hypotheses it. discarding hypotheses without refining might obstruct
traversal lattice. example, current work, algorithm starts search
process empty hypothesis initial hypotheses obtained refining empty
hypothesis violate second domain-dependent constraint listed (since contain exactly one predicate therefore cannot contain spatial temporal
predicate).
6.4 Event Recognition
learned event models used event recognition unseen videos. purpose,
test video converted relational data used database event models
used Prolog queries. querying done whole database intervals
extracted answer substitutions queries give temporal extent
recognized instances events. order record event takes place, change
arity event predicate (the rule head) monadic argument
list interval variables occurring body. Note would also possible
introduce second argument record objects involved event (i.e. list
variables type object - equivalently occur first two arguments
spatial predicate body).
issue arises exactly event occurs given consists multiple
overlapping temporal intervals instantiated predicates given answer substitution. Given list intervals occurring instantiated body hypothesis,
various possibilities present themselves. One could take maximal interval exactly
spans intervals . one could take interval exactly spans interval
first transition (i.e. pair meeting intervals involving pair objects)
last transition. Clearly possibilities too. Ultimately probably
domain dependent decision. experiments, take list intervals
temporal extension event obtained taking minimum maximum
time points .
Note may several rules event class, rule capturing variation
event happen. rules weights specifying important
reliable rule recognizing events. recognizing events, rules event
class used may result multiple answer substitutions.
59

fiDubba, Cohn, Hogg, Bhatt & Dylla

7. Interleaved Induction Abduction (IIA)
previous section showed ILP applied learn rule-based relational
event/activity models, given observation dataset, positive negative examples
events whose models learnt. However, data visual sensors tend
noisy high variability sample space. leads over-fitted models (i.e.,
rules), model cover examples corrupt
sensor noise. model rules result many false positives used
event-recognition test data.
section, show well-fitted, semantically meaningful event models
learned noisy data interleaving induction abduction. acquires significance
cases training data scarce noisy. apply Typed ILP system presented
previous section learn event-based models using models domain
theory, explain examples/observations covered induced theory using
abduction. uncovered examples either noisy, examples event
reality happened different way. Using explanation rectify errors
noisy examples corrupted tracking errors thus reduce requirement additional
rules. framework, examples noisy (i.e. incorrect) thereby requiring
observation data revision manner consistent initially learned theory,
general common-sense knowledge space, spatial change, dynamics
domain. Note many ILP approaches discard examples considering noisy
using heuristic stopping criteria. acceptable cases scarcity
training data, learning every example potentially important.
7.1 Domain-Independent Spatial Theory
order pursue goal, Axiomatic Characterisation Spatial Theory necessary. Many spatial calculi exist, corresponding different aspect space. Here,
suffices focus one spatial domain, e.g., topology, corresponding mereotopological axiomatization way binary relationships RCC-8 fragment Rrcc8 .
axiomatic viewpoint, spatial calculus defined R general properties (P1P5),
assumed known apriori. realize domain-independent spatial theory
used reasoning (e.g., spatio-temporal abduction) across dynamic domains,
necessary formalize domain-independent spatial theory (space ) preserves
high-level axiomatic semantics generic properties. reasons space
sketch properties P1P5 neglect formal axiomatization.
(P1P2) Basic Calculus Properties (cp ) describe jointly exhaustive & pairwise disjoint (JEPD) property, i.e., two entities O, one one spatial
relationship R holds given situation. jointly exhaustive property n = |R|
base relations axiomatized n ordinary state constraints and, similarly, pairwise disjoint property axiomatized [n(n 1)/2)] constraints. miscellaneous
properties symmetry asymmetry expressed manner.
(P3) primitive relationships R continuity structure, referred Conceptual Neighbourhood (cn ) (CND) (Freksa, 1991), determines direct, continuous changes quality space (e.g., deformation and/or translational motion).
(P4) axiomatic viewpoint, spatial calculus defined R (primarily) based
60

fiLearning Relational Event Models Video

derivation set Composition Theorems (ct ) JEPD set R.
general, calculus consisting n JEPD relationships, [n n] compositions
precomputed. composition theorems equivalent ordinary state constraint, every n-clique spatial situation description satisfy.
(P5) Additionally, Axioms Interaction (ai ) necessary one spatial calculus modelled non-integrated manner (i.e., independent composition
theorems). axioms explicitly characterize relative entailments interdependent aspects space, e.g., topology size.
Now, let space def [cp cn ct ai ] denote domain-independent spatial theory
based axiomatizations encompassing (P1P5).
7.2 Physically Plausible Scenarios
Corresponding spatial situation (e.g., within hypothetical situation space),
exists situation description characterizes spatial state system. necessary spatial component state complete specification, possibly
disjunctive information. k spatial calculi modelled, initial situation description involving domain objects requires complete n-clique specification [m(m 1)/2]
spatial relationships calculus. Therefore, need define scene description
C-Consistent, i.e., compositionally consistent, n-clique state spatial situation
description corresponding situation satisfies composition constraints every
spatial domain (e.g., topology, orientation, size) modelled. one calculus
modelled inter-dependent constraints (P5) must hold well.
viewpoint model elimination narrative descriptions (abductive)
explanation process, C-Consistency scenario descriptions key (contributing) factor
determining commonsensical notion physically realizability (abduced) scenario completions. Bhatt Loke (2008) show standard completion semantics
causal minimization presence frame assumptions ramification constraints preserves notion C-Consistency space within logic programming framework,
well arbitrary basic action theories.
7.3 Inductive-Abductive Framework
interleave inductive abductive commonsense reasoning space, events
change within logic programming framework. Induction used means learn event
models generalizing sensory data, whereas abductive reasoning used noisy
data correction scenario narrative completion, thereby improving learning.
7.3.1 Explanation Abduction
Diametrically opposite projection planning task post-dictum explanation (Poole, Goebel, & Aleliunas, 1987), given set time-stamped observations
snap-shots, objective explain events and/or actions may caused
observed state-of-affairs. Explanation problems demand inclusion narrative
description, essentially distinguished course actual events may
incomplete information (Miller & Shanahan, 1994). Narrative descriptions typi61

fiDubba, Cohn, Hogg, Bhatt & Dylla

cally available sensory observations real execution system process. Given
narratives, objective often assimilate/explain respect underlying
process model.
abductive explanation problem stated follows (Kakas, Kowalski, & Toni,
1992):
Given: Theory observations G, find explanation 4 that:




4G





4 consistent

i.e., observation follows logically non trivially theory extended given
explanation. Abductive explanations usually restricted ground literals predicates undefined theory, namely abducibles. Abductive explanations
derived trying prove observation initial theory alone: whenever literal encountered clause resolve with, literal added
explanation.
abduction procedure results many valid explanations. order reduce
number explanations, several restrictions listed used (Kakas et al., 1992):
Explanations basic means one explanation explain another
explanation. enforced allowing abducibles head rule.
Explanations minimal means one explanation subsume another explanation.
Explanations satisfy integrity constraints restriction, obtain explanations valid domain consideration. work,
explanations satisfy spatial constraints underlying spatial theory.
7.3.2 Scenario Narrative Completion
easy intuitively infer general structure narrative completion abductive
explanation. Consider illustration Fig.7 hypothetical situation space characterizes complete evolution system. Fig.7 situation-based history given
solid arrows represents one path, corresponding actual time-line discretized
intervals h0 , 1 , . . . , i, within overall branching-tree structured situation space.
Given incomplete narrative descriptions, e.g., corresponding ordered intervals
terms high-level spatial (e.g., topological, orientation) occurrence information,
objective explanation derive one paths branching situation space,
could best-fit available narrative information. Formally:


1 touch(a, c, 1 )












dc(a,
c,

)

in(b,
a,

)

dc(b,
c,

)


2
4
4
4








[



]
|=

,



space
1
2


( , j ).[ meets(1 , ) bef ore(i , 4 ) dc(b, a, )






touch(a, c, ) dc(b, c, )]











[
meets(
,

)

meets(
,

)

touch(b,
a,

)



j
j
4
j






touch(a, c, j ) dc(b, c, j )]
62

(7.1)

fiLearning Relational Event Models Video




c

b


c


c

b



c


b
c

ab

c

b
c


b

c

Figure 7: Branching/Hypothetical Situation Space. possibilities shown.
clearly paths initial scenario target scenario. also
possible states.

(7.1), 1 denotes initial situation 2 denotes final situation represented
terms spatial relations (RCC-5) among objects present scene. abductive
derivation , explains scene changed situation 1 situation 2 ,
primarily involves non-monotonic reasoning form minimizing change, addition
making default assumptions inertia, appropriate treatment ramification
constraints (Bhatt & Loke, 2008).
7.4 IIA Algorithm
ILP systems use covering algorithm learn models examples. search
ranges hypothesis lattice hypothesis evaluated based number
positive negative examples covers. selected suitable hypothesis based
scoring function, hypothesis (rule) added model, covered examples
removed process repeated positive examples covered. Examples
corrupted noise resulting missing incorrect facts. cases,
rules learned necessary order cover examples. number
rules concept increases, may result many false positives rules
used classification/recognition test examples. order avoid learning corrupt
examples, framework identifies examples corrupted explaining
abduction using already induced model background theory (Dubba et al., 2012).
63

fiDubba, Cohn, Hogg, Bhatt & Dylla

main assumption make noise examples consistent.
noise consistent (i.e., present examples similar fashion)
becomes part pattern defines concept might learned learning
algorithm.
pseudo algorithm given Algorithm 1. induction algorithm induces
initial hypothesis based score function explained previous sections. positive
+
examples covered (ERule
) hypothesis removed list positive examples
yet covered. induced theory along background knowledge used explain
uncovered examples treating example narrative. Abduction gives several
possible explanations different cost (based nature number facts
explanation). explanations rejected cost specified
threshold. Furthermore, given formulation spatial theory space , C-Consistency
+
abduced explanations ensured. examples (E4
) explanation whose cost
less specified threshold removed positive examples list yet
covered, considered covered already induced model.
process induction abduction repeated positive examples covered.
Apart constraints enforced spatial theory filter abduced explanations,
several heuristics used give score explanation low cost consistent
explanation selected system. One several possible heuristics prefer
explanations number transitions spatial relations minimal (Hazarika &
Cohn, 2002). heuristic direct consequence McCarthys Common Sense Law
Inertia (McCarthy, 1986) states change abnormal persistence
preferred absence data. spatio-temporal domain, explanation abduced
absence data set spatio-temporal facts three ways add
explanation: (i) Extend current relation two objects (can done
directions timeline situation permits) (ii) change current relation
two objects neighbouring relation CND (iii) introduce new object (hypothetical)
scene spatial relations objects scene well. cost
explanation based type spatio-temporal fact chosen calculated
explained below.
7.4.1 Cost Abduced Explanation
Let 4 explanation abduction procedure 4 set grounded spatiotemporal facts form r(oi , oj , k ) denoted fijrk , Ep+ current positive example
(an interpretation, i.e., set facts) let r set spatial relations R
spatial calculus. Let set objects Ep+ . Let cfijrk cost abducing fijrk .
X
total cost 4 denoted C4
cfijrk .
fijrk 4

cost

,
,
cfl =

n,

abducing fijrk calculated follows:
exists fijrm Ep+ k disjoint
exists fijsm Ep+ k disjoint r =
6
n number hypothetical objects (objects O) fijrk

< < .
64

fiLearning Relational Event Models Video

first case cost function occurs system abduces fact extends
relation two objects temporal dimension. count spatial
transition hence low cost. contrast, second case occurs
system abduces fact extends existence two objects temporal dimension
different relation (the new spatial relation must neighbour existing relation
CND) one already exists them. counts spatial
transition cost first case. third case occurs necessary
hypothetical object satisfy hypothesis Ep+ . case used
object involved event completely missed object tracker first two cases
used scenarios object detected temporal slice life time.
Note first case clearly preferred abduction procedure find
low cost explanation third case expensive applies object
completely missed object tracker. Though possible avoid transitions
reduce score, sometimes mandatory consider transitions. example, consider
scenario two objects dc relation final state relation.
case, algorithm abduce facts two transitions (one
dc relation changes touch another touch changes relation). Note
necessary abduce temporal relational facts Prolog definitions temporal
relations background theory used compute needed.
achieved including temporal predicates list abducibles.
abduction procedure uses existing constants database one issue
though number relations objects small, number possible
intervals large constrained. order constrain possible explanations,
introduce intervals predefined duration database abduction uses
intervals abducing explanations. Note abduction defined
adds missing spatio-temporal information cannot used retract corrupted
data resulting noise.

Algorithm 1 Interleaved Induction Abduction algorithm (IIA)
procedure IIA(E + , E , B) . training sets background knowledge (includes spatial
theory)
H
4
E + 6=
Rule
Induce(B, E + , E )
H H {Rule}
+
E + E + ERule
4 Abduce(B, H, E + )
+
E + E + E4
end
return H
. Learned theory
end procedure

65

fiDubba, Cohn, Hogg, Bhatt & Dylla

Figure 8: Airport domain: videos recorded using 6 static cameras looking
scene different angles.

8. Experimental Results
section, present evaluation remind, well extension presented
Section 7. experiments, used two real world video datasets different
many aspects. videos datasets shot outdoor settings
different weather light conditions (rainy, cloudy, sunny, night). variations
videos present various challenges vision system subsequently learning
system training phase event recognition phase.
two datasets used work evaluation airport logistics verb
videos. datasets domains differ many aspects number objects
video, length video, duration events, background structures, number
cameras used capture events also plane (image plane ground plane)
tracking data made available. view differences datasets
positive aspect - framework shown work two different kinds scenarios.
remind11 implemented Python speed, modules implemented
Cython; SWI-Prolog used underlying Prolog engine storing querying
relational facts background knowledge.
8.1 Airport Logistics
experiments airport logistics domain, 15 turn-arounds12 used
turn-around shot using 6 cameras different angles (Fig.8) video
average one hour long (15 frames per sec).
following informal descriptions International Air Transport Association (IATA) events aim learn models for:
11. Available request first author made public near future.
12. turn-around duration plane entering leaving apron area.

66

fiLearning Relational Event Models Video

Aircraft Arrival

Aircraft comes apron

Aircraft Departure

Aircraft moves away position apron

GPU Positioning

Ground power unit comes positions zone

Left Refuelling

Fuel truck arrives left side aircraft refuelling

PB Positioning

Push-back vehicle positioning front aircraft

PBB Positioning

Passenger Boarding Bridge attaches aircraft

PBB Removing

Passenger Boarding Bridge detaches aircraft

FWD CN LoadUnload

Container Loading/Unloading front end aircraft

AFT CN LoadUnload

Container Loading/Unloading rear end aircraft

AFT Bulk LoadUnload

Baggage Loading/Unloading rear end aircraft

FWD Bulk LoadUnload

Catering Loading/Unloading front end aircraft

Within event, high variability noise tracking also
objects extraneous event entering event scene. Note events might
present may occur multiple times turn-arounds. scenes involve
interactions vehicles people zones apron. zones specified
ground plane according IATA specifications position zones
depends type aircraft. zones used parking steering vehicles
different operations carried turn-around. Note zones static
throughout video change size position, unlike bounding boxes
vehicles obtained tracking. Hence zones included type hierarchy used
domain (Fig.4) since suffer visual noise. main reason use
zones RCC-5 spatial relations bounding boxes vehicles people
ground plane rarely touch, hence interactions encoded dc zones
used. important use zones interactions happen
zones. According IATA specifications, vehicle transition zones
position vehicle particular zones important determine events.
use object tracks provided partner Co-Friend project (Ferryman,
Borg, Thirde, Fusier, Valentin, Bremond, Thonnat, Aguilera, & Kampel, 2005); certain
details events detectable tracking system direction
baggage rail loader vehicle whether trolleys empty arrive
scene. Load/Unload events obtained IATA events differ details (if
trolleys loaded arrive scene baggage moving towards
aircraft, event loading trolleys empty arrive
scene baggage moving away aircraft, event unloading). Apart
details, semantically similar hence regarded events (for
example, FWD CN Load FWD CN Unload regarded events named
FWD CN LoadUnload, strategy followed Load/Unload events).
8.1.1 Tracking Obtaining Relational Data
apron scene area large covered single static camera. events
apron occur sides aircraft difficult cover
67

fiDubba, Cohn, Hogg, Bhatt & Dylla

single camera size aircraft possible many occluded
objects scene. order solve problems, six cameras used shoot
scene different angles entire area covered number occluded
objects minimized. Working ground plane data results learned models
independent camera view airport models readily applied
different airports different camera configurations.
tracking data obtained videos six cameras turn-around
fused together get 3D data ground plane (Ferryman et al., 2005). tracking
data noisy low quality, bad light weather conditions low contrast
CCTV videos. noise presence phantom objects, missing objects,
wrong types vehicles, inaccurate bounding boxes, broken trajectories, object identity,
inconsistencies etc. typical problems computer vision tracking system.
turn-around separately processed get relational data consists set
spatial relations among vehicles zones apron. Prolog rules decide
temporal relationships among intervals considered background information ILP
system. data video 250 500 spatial relational facts (excluding
temporal relational facts) depending number objects interactions
objects.
Note event requires least one change state (here, spatio-temporal
relations pairs objects) objects. relation two objects
dc change life span objects, signifies objects
interacting relational fact discarded spatio-temporal facts
contain relevant information defining event models. tracking data also consists
bounding boxes people scenes, discarded people germane
semantics events also increase size relational data.
8.1.2 Annotation Events
supervised learning need positive preferably negative example instances
events. airport domain, temporal extent events provided individuals expertise IATA protocols apron activities, specifying
start end frame numbers event instance video. spatial extent
obtained using tool polygon drawn one image planes
corresponding ground plane region obtained using homography (it easier
human annotator watch actual video provide spatial annotation rather
view 3D visualization ground plane, fusion imperfectly
tracked data always show relevant objects). region gives spatial
extent event instance.
8.2 Physical Action Verbs Dataset
Action Verbs dataset13 corpus video vignettes (Fig.9) portray motion verbs
approach, exchange, jump, collide, etc. enacted natural environments like parks,
13. dataset (Minds Eye Year 1 recognition task videos) provided DARPA publicly available
http://www.visint.org/datasets

68

fiLearning Relational Event Models Video

(a) Approach event tracked objects

(b) Snatch event tracked objects

Figure 9: Example event instances Approach Snatch Action Verbs dataset
urban places, etc. vignettes short duration compared videos
airport domain, tens seconds. full list verbs given Table 3.
Though vignette shot portray single verb action, verbs inevitably
present well, sometimes overlapping time. primarily unavoidable, example,
vignette portrays verb carry, automatically include walk person carrying
object hand. aspect taken consideration annotating
vignettes. able obtain tracked data external source (Morariu, Harwood,
& Davis, 2013) including object type information (Fig.10).
new challenge using dataset different ways verb enacted.
48 verbs dataset total 1615 vignettes used training
2348 vignettes used testing.
8.2.1 Tracking Obtaining Relational Data
tracking data available us often suffers errors, e.g., bouncing ball often
tracked held fast moving objects running person missed.
used Qualitative Trajectory Calculus relations (QT CL1 ) (Van de Weghe et al., 2006)
primitive spatio-temporal relations. choose RCC dataset
seemed unlikely purely topological representation would sufficient. contrast,
QT CL1 relations capture typical movements verbs dataset like moving away,
approaching, follow etc. example, chase event one object following another
object relation dc, using RCC, also two objects standing still
distance between.
difficult model motion patterns objects like run, walk, raise, bend etc. using
relational data without referring parts person. verbs dataset contains
events involve motion patterns recognize these, pixel based models
appropriate. primitive events recognized videos using method
proposed Jiang, Lin Davis (2010), action represented sequence
joint HOG-flow descriptors (Dalal & Triggs, 2005) extracted independently
frame. Instead applying approach entire frame video proposed
Jiang et al. (2010), input restricted sliding temporal windows along spatio69

fiDubba, Cohn, Hogg, Bhatt & Dylla

Person
Object

Vehicle


Figure 10: Tree-structured object type hierarchy Action Verbs domain.
temporal volume defined persons bounding box. primitive events14 addition
QT CL1 relations provide relational data verbs domain.
8.2.2 Annotation Events
ground truth events verbs dataset vignettes different nature
ground truth airport domain. development test set annotated
10 people using Amazon Mechanical Turk (AMT). vignette presented
annotator 48 questions presented form: verb X present vignette?
verbs annotated 50% annotators considered events present
vignette. development set, annotations extended providing
event instance temporal extent.
8.3 Experimental Results Evaluation Typed ILP Framework
Sample rules15 learned Aircraft Arrival AFT Bulk LoadUnload events given
below. example, Aircraft Arrival rule interpreted as: aircraft arrives
aircraft bounding box relation right AFT Bulk TS Zone
moves forward thereby changing relation touch. happens aircraft
arrives moving position. rule also correctly identifies bounding
box belong object type aircraft. goals rule ordered
spatial predicates come (to left of) temporal predicates since
temporal facts16 compared spatial facts ordering speeds query execution.
aircraft arrival([intv(T1,T2), intv(T3,T4)]) :in(obj(aircraft(V)), right AFT Bulk TS Zone, intv(T1,T2)),
touch(right AFT Bulk TS Zone, obj(aircraft(V)), intv(T3,T4)),
meets(intv(T1,T2), intv(T3,T4)).
aft bulk loadunload([intv(T1,T2), intv(T3,T4)]) :touch(left TK Zone, obj(veh(heavy veh(V1))), intv(T1,T2)),
touch(obj(veh(V2)), left TK Zone, intv(T3,T4)),
meets(intv(T3,T4), intv(T1,T2)).
followed standard leave-one-out methodology testing performance
airport domain. turn-arounds except one used training remaining one
used test case. process iterated turn-around used test case
14. data provided Vlad Morariu University Maryland.
15. temporal interval represented intv(T1 , T2 ) programming convenience T1 T2
starting ending frame numbers interval.
16. already noted, temporal facts explicitly stored computed via background knowledge
rules.

70

fiLearning Relational Event Models Video

Event

#Examples

Without Type Generalization

Type Generalization

FWD CN LoadUnload

7

0.86

0.06

0.11

0.86

0.08

0.15

GPU Positioning

16

0.4

0.03

0.05

0.27

0.02

0.04

Aircraft Arrival

15

0.43

0.01

0.02

0.36

0.01

0.02

AFT Bulk LoadUnload

29

0.72

0.20

0.31

0.72

0.20

0.31

PBB Removing

15

0.43

0.06

0.10

0.36

0.12

0.18

Left Refuelling

8

0.25

0.03

0.05

0.12

0.10

0.11

PB Positioning

14

0.28

0.04

0.07

0.14

0.06

0.08

Aircraft Departure

12

0.41

0.11

0.17

0.33

0.19

0.24

AFT CN LoadUnload

15

0.80

0.05

0.09

0.67

0.07

0.13

PBB Positioning

15

0.73

0.16

0.26

0.67

0.34

0.45

FWD Bulk LoadUnload

3

1.00

0.24

0.39

1.00

1.00

1.00

Weighted Average

0.15

0.20

Table 1: Performance comparison models obtained without using types using
RCC-5 primitives airport domain. first, second third columns
category recall, precision f1 respectively. best f1 value case presented
bold. clear table using types improves overall performance.
without type generalization mean, type information tracker ignored (all objects
type) type generalization performed learning.

exactly once. results experiments summarised Table 1. third
fourth columns show recall precision without using types 15 turn-arounds
(i.e., type information tracker ignored, hence objects type
type generalization performed learning). fifth sixth columns show
recall precision using type hierarchy. tables clear using type
information increase accuracy event recognition. Also combined execution
time experiments using type generalization reduced roughly 30%
compared execution time experiments without type generalization.
detailed recognition results (temporal localization) events turn-around
shown Fig. 11 (best seen colour). plot shows turn-around one subplot showing ground truth event instances another subplot showing recognized instances
Typed ILP system turn-around. event colour coded comparing
ground truth recognized instance intervals. Note recognized event instance
considered true positive overlaps least 20% corresponding event ground
truth interval (Oh et al., 2011). cases temporal extent recognized event in71

fiDubba, Cohn, Hogg, Bhatt & Dylla

Figure 11: Recognition events turn-around 1 airport domain (best viewed
colour).

stances long spatial relations important event extend beyond
deictic interval event.
8.3.1 Evaluating Learned Event Models Hand-Coded Event Models
learned models also evaluated comparing hand-coded models.
hand-coded models provided domain experts using set domain-dependent
spatial relations (Ferryman et al., 2005). order directly compare performance without
change underlying representation, rather using RCC-5, recomputed
relational data remind using domain-dependent primitives. comparisons
given Table 2. clear table learned models better performance
event categories compared performance hand-coded models.
hand-coded models single primitives rather set primitives connected
temporal relations. kind models one single predicate far
false positives compared models set spatial relations connected
72

fiLearning Relational Event Models Video

Event

#Examples

Learned (RCC-5)

Learned (d-d)

Hand-coded (d-d)

FWD CN LoadUnload

7

0.86

0.08

0.15

0.14

0.50

0.22

0.71

0.04

0.07

GPU Positioning

16

0.27

0.02

0.04

0.44

0.03

0.05

0.00

1.00

0.00

Aircraft Arrival

15

0.36

0.01

0.02

0.07

0.01

0.01

0.07

0.05

0.06

AFT Bulk LoadUnload

29

0.72

0.20

0.31

0.59

0.27

0.37

0.03

0.05

0.04

PBB Removing

15

0.36

0.12

0.18

0.26

0.14

0.18

0.00

1.00

0.00

Left Refuelling

8

0.12

0.10

0.11

0.38

0.23

0.28

0.00

1.00

0.00

PB Positioning

14

0.14

0.06

0.08

0.07

0.08

0.07

0.21

0.09

0.12

Aircraft Departure

12

0.33

0.19

0.24

0.00

1.00

0.00

0.00

1.00

0.00

AFT CN LoadUnload

15

0.67

0.07

0.13

0.33

0.05

0.08

0.47

0.07

0.12

PBB Positioning

15

0.67

0.34

0.45

0.26

0.20

0.22

0.40

0.07

0.12

FWD Bulk LoadUnload

3

1.00

1.00

1.00

0.00

1.00

0.00

1.00

0.02

0.04

Weighted Average

0.20

0.16

0.05

Table 2: Table comparing learned (RCC-5), learned (domain-dependent) hand-coded
models performance (domain-dependent). first, second third columns
category recall, precision f1 respectively. best f1 value case presented
bold.
temporal relations. Also hand-coded models use specific vehicle type event
models affects performance reducing true positives noise
object type detection, whereas learned models use appropriate generalized object
type cover instances.
8.3.2 Evaluating Learned Event Models Different Spatial Relations
also performed evaluation investigate effects different spatial relations.
comparison used RCC-5 domain specific relations airport domain.
use QTC relations domain examples learn
many spatial relations QTC spatial calculus, patterns
events emerge. results given Table 2. table clear
models learned using RCC-5 better recognition performance (mean f1: 0.25)
compared models learned using domain-dependent relations (mean f1: 0.13). One
reason might RCC-5 better representation granularity compared
domain-dependent primitives. Also RCC-5 JEPD (jointly exhaustive pair-wise
disjoint) property domain-dependent primitives airport domain
(it lacks pair-wise disjoint property).
8.3.3 Evaluating Verbs Dataset
framework uses type generalization also applied verbs dataset
48 verbs. Table 3 shows precision, recall f1 scores classification task.
video test set, event models used queries event model
73

fiDubba, Cohn, Hogg, Bhatt & Dylla

succeeds, particular verb considered present video (and variable
bindings give time occurrence objects involved). compared
ground truth obtain precision recall values.
provide sample rules learned events Approach Snatch cover
instances shown Fig.9. QT CL1 relations moto (short form moving towards
stationary object), static depart (short form moving away stationary object)
corresponds relations blobs row 2 column 1, row 2 column 2, row 2
column 3 respectively Fig.1. Also note unlike models learned Airport
Dataset, list temporal intervals argument head rules here.
want recognize events videos Action Verbs
dataset videos short find temporal extent event.
approach() :moto(obj(vehicle(J)), obj(person(K)), intv(V 32,V 33)),
static(obj(vehicle(J)), obj(person(K)), intv(V 34,V 35)),
meets(intv(V 32,V 33), int(V 34,V 35)).
snatch() :static(obj(person(J)), obj(person(K)), intv(V 24,V 25)),
moto(obj(other(L)), obj(person(J)), intv(V 40,V 41)),
depart(obj(other(L)), obj(person(K)), intv(V 18,V 51)),
overlaps(intv(V 40,V 41), int(V 18,V 51)),
during(intv(V 40,V 41), intv(V 24,V 25)),
during(intv(V 18,V 51), intv(V 24,V 25)).
proposed framework, compared existing systems results
presented Tables 4-7. One systems compared with, RedVine
system, supervised learning version framework proposed Sridhar, Cohn
Hogg (2010). based graphical representation relational facts, event
represented histogram graphemes (small graphs represent spatio-temporal
interactions objects involved event) mapped vector space facilitate
classification. Stack convolutional Independent Subspace Analysis (ScISA) (Le et al.,
2011)17 based pixel level flow based features used model events
using neural network. spatio-temporal features used algorithm learned
unsupervised fashion instead using predefined features SIFT (Lowe, 2004),
HoG (Dalal & Triggs, 2005), etc.
evaluation dataset provided DARPA total 2348 vignettes.
found vignettes (1294) training set also appeared evaluation set.
call dataset 2348 vignettes Verb Evaluation Dataset-1 (VED1)
remaining vignettes discarding 1294 vignettes appeared training dataset
VED2. Evaluation VED1 gives interesting insights overfitting underfitting
different learning frameworks compared. chose two different average
mechanisms (macro micro)18 get overall f1 Matthews correlation coefficient
(MCC) scores verbs vignettes. True Negatives play role f1
17. Results using system provided Tuyen Huynh SRI.
18. Macro-average calculated first calculating precision recall category taking
average values, micro-average calculated constructing global contingency table
calculating precision recall using sums.

74

fiLearning Relational Event Models Video

Verb

precision recall

approach
arrive
attach
bounce
bury
carry
catch
chase
close
collide
dig
drop
enter
exchange
exit
fall

0.36
0.28
0.08
0.11
0.05
0.14
0.05
0.04
0.07
0.14
0.02
0.08
0.17
0.06
0.15
0.10

0.78
0.73
0.49
0.71
0.57
0.53
0.58
0.44
0.29
0.83
0.36
0.47
0.74
0.56
0.71
0.62

f1

Verb

0.49
0.40
0.14
0.19
0.10
0.22
0.10
0.07
0.11
0.24
0.04
0.14
0.28
0.11
0.25
0.17

flee
fly
follow
get
give
go
hand
haul

hit
hold
jump
kick
leave
lift
move

precision recall
0.07
0.06
0.09
0.15
0.11
0.52
0.10
0.09
0.46
0.14
0.47
0.06
0.07
0.29
1.00
0.76

0.82
0.42
0.62
0.50
0.66
0.79
0.66
0.46
0.60
0.64
0.69
0.25
0.38
0.76
0.00
0.74

f1
0.14
0.11
0.16
0.23
0.18
0.63
0.17
0.15
0.52
0.23
0.56
0.09
0.11
0.42
0.00
0.75

Verb
open
pass
pickup
push
putdown
raise
receive
replace
run
snatch
stop
take
throw
touch
turn
walk

precision recall
0.10
0.22
1.00
0.16
1.00
0.33
0.15
0.07
0.10
0.11
0.39
0.24
0.06
0.64
0.47
0.32

0.77
0.39
0.00
0.82
0.00
0.63
0.70
0.77
0.82
0.51
0.78
0.62
0.39
0.53
0.53
0.80

f1
0.17
0.28
0.00
0.27
0.00
0.44
0.25
0.13
0.18
0.19
0.52
0.35
0.10
0.58
0.50
0.45

Table 3: Classification results per verb physical action verbs domain.

scores considerable effect MCC scores MCC differentiate
positive negative classes. MCC give scores even class labels
interchanged f1 scores change. Note much work literature activity
recognition use f1 scores.
Tables 4-7, clear ScISA better MCC scores cases
remind better f1 score VED2, though lower MCC scores
MCC scores two algorithms. Also note drop performance ScISA
VED2 set compared VED1, whereas remind RedVine almost
performance indicating ScISA overfitting data remind RedVine
underfitting data. reason high f1 low MCC score remind
True Negatives.
ScISA performs quite well (w.r.t. MCC score) modelling capability
framework since underutilizes temporal domain. outperform
state-of-the-art evaluation measures, proposed scheme still general, i.e.,
(i) gives good interpretations activities video scenes; (ii) take temporal
domain account unlike ScISA therefore provides better modelling capabilities;
(iii) gives high recall precision improved post-processing
(iv) provides (elegant) logical rules easily interpreted human observer.
One major drawback ScISA lack spatio-temporal localization recognized
event. suitable event classification tasks (verbs dataset)
event recognition tasks (airport domain). Although report localization
(owing short videos data set), deriving localization (or position) information
remind trivial event recognized since intervals objects involved
explicitly identified rule body.
75

fiDubba, Cohn, Hogg, Bhatt & Dylla

Method
remind
RedVine
ScISA

avg-prec
0.24
0.32
0.91

avg-rec
0.56
0.24
0.54

f1
0.34
0.28
0.68

MCC
0.05
0.16
0.67

Table 4: Performance verbs domain: VED1, macro-average per verb.

Method
remind
RedVine
ScISA

total prec
0.21
0.37
0.92

total rec
0.59
0.24
0.60

f1
0.31
0.30
0.72

MCC
0.0
0.19
0.70

Table 5: Performance verbs domain: VED1, micro-average (total detection classification)

Method
remind
RedVine
ScISA

avg-prec
0.25
0.35
0.49

avg-rec
0.59
0.25
0.20

f1
0.35
0.29
0.29

MCC
0.04
0.17
0.21

Table 6: Performance verbs domain: VED2, macro-average per verb

Method
remind
RedVine
ScISA

total prec
0.21
0.40
0.59

total rec
0.63
0.26
0.29

f1
0.32
0.31
0.39

MCC
0.08
0.20
0.33

Table 7: Performance verbs domain: VED2, micro-average (total detection classification)

8.4 Experimental Results Evaluation IIA
IIA framework evaluated airport verb datasets. use
Hyprolog, logic programming framework capable abductive inference (Christiansen &
Dahl, 2005).
8.4.1 Embedding Spatial Theory Airport Domain
airport domain, encoded RCC-5 spatial theory space framework contains conceptual neighbourhood graph, JEPD relationships
composition theorems spatial relations used follows:
76

fiLearning Relational Event Models Video

% Sample
dc(X, Y,
dc(X, Y,
dc(X, Y,
dc(X, Y,
dc(X, Y,

JEPD
T) ,
T1),
T1),
T1),
T1),

constraints
touch(X, Y,
touch(X, Y,
touch(X, Y,
touch(X, Y,
touch(X, Y,

(P1 - P2) RCC-5
T)
T2), during(T1, T2)
T2), during(T2, T1)
T2), overlaps(T1, T2)
T2), overlaps(T2, T1)

<=>
<=>
<=>
<=>
<=>

fail.
fail.
fail.
fail.
fail.

% Conceptual Neighbourhood constraints (P3) RCC-5
dc(X, Y, T1), in(X, Y, T2), meets(T1, T2) <=> fail.
in(X, Y, T1), dc(X, Y, T2), meets(T1, T2) <=> fail.
% Sample Composition Theorem (P4) RCC-5
in(X, Y, T1), dc(Y, Z, T2), touch(X, Z, T3), during(T2, T1),
during(T3, T2) <=> fail.

JEPD CND property constraints forbid abduction facts contradict spatial theory thus avoiding physically impossible scenarios also helps
abduction complete reasonable time.
explain approach, consider following fragments actually occurring datasets
(Ex:1 - Ex:4) event Aircraft Arrival :

Ex:1

dc(arr zone,obj(aircraft(obj45)),intv(6661,7137))
touch(arr zone,obj(aircraft(obj45)),intv(7138,29114))
touch(arr zone,obj(veh(light veh(gpu(obj54)))),intv(7154,8161))
dc(arr zone,obj(veh(heavy veh(loader(obj2)))),intv(749,30380))

Ex:2

dc(arr zone,obj(aircraft(obj68)),intv(2342,2663))
touch(arr zone,obj(aircraft(obj68)),intv(2664,29524))

Ex:3

dc(arr zone,obj(veh(light veh(trolley(obj0)))),intv(285,21494))
touch(arr zone,obj(aircraft(obj41)),intv(4458,32404))
touch(arr zone,obj(veh(light veh(trolley(obj2)))),intv(1712,32405))

Ex:4

dc(arr zone,obj(aircraft(obj33)),intv(2435,6987))
touch(arr zone,obj(veh(heavy veh(loader(obj27)))),intv(2197,2310))
dc(arr zone,obj(veh(heavy veh(loader(obj27)))),intv(2311,2645))

obtain following model Aircraft Arrival event learned ILP approach
first two examples given examples arr zone denoting specific zone
apron Ti denotes time point. fact two time points indicating start
end interval spatio-temporal fact holds.

aircraft arrival([intv(T1,T2), intv(T3,T4)]) :dc(arr zone, obj(aircraft(V)), intv(T1,T2)),
touch(arr zone, obj(aircraft(V)), intv(T3,T4)),
meets(intv(T1,T2), intv(T3,T4)).
77

fiDubba, Cohn, Hogg, Bhatt & Dylla

obj

obj

Z1
Z2

Z1
Z2
Z3

Z3

arr_zone

Z4

Z5

arr_zone

Z4

Z5

time

aircraft_arrival(T1,T2)
dis(arr_zone,obj(aircraft(V)),T1,T)
con(arr_zone,obj(aircraft(V)),T+1,T2)
(a) Spatial primitive based event modelling

966

966

Z1
Z2
Z3
Z4

Z1
Z2
Z3

arr_zone
Z5

Z4

arr_zone
Z5

time

aircraft_arrival(5338,16868)
rel?(arr_zone,obj?,5338,16630)
con(arr_zone,obj(aircraft(obj996)),16631,16868)
(b) Narrative completion (of data video) previously learned model

Figure 12: IIA Scenario Narrative Completion; E.g., aircraft arrival
rule states aircraft arrival takes place interval
aircraft disconnected arr zone directly followed interval, i.e., meets,
aircraft connected arr zone. model cover examples
apart Ex:1 Ex:2. Ex:3 missing dc relation related aircraft whereas
Ex:4 missing touch relation (Fig. 12b). represent typical data corruption
higher level tracking error lower level video processing different stages
video.
8.4.2 Narrative Completion Airport Domain
Multiple explanations interesting give several possible scenarios consistent narrative. example, consider Ex:4 touch fact related aircraft
arrival event missing narrative. happens vision algorithm fails
detect aircraft coming towards parking zone big object changes
light conditions scene. abduction system comes two explanations (as
shown following sample interactive run system), one filling missed fact
consistent narrative background knowledge constraints. Another
explanation using hypothetical object ( G41673) present database.
78

fiLearning Relational Event Models Video

explanation expensive first explanation, system chose first
explanation.
%A small narrative three observations (The touch fact
%is missing, happens, vision algorithm fails
%to detect aicraft close: Approximate
%interval specified aircraft-arrival query
%dc(arr_zone,obj(aircraft(obj33)),intv(2435,6987))
%touch(arr_zone,obj(veh(heavy_veh(loader(obj7)))),intv(2197,2310))
%dc(arr_zone,obj(veh(heavy_veh(loader(obj7)))),intv(2311,2645))
?- aircraft_arrival(intv(2000,12000)).
touch(arr_zone,obj(aircraft(obj33)),intv(6988,7988))
true ;
dc(arr_zone,obj(aircraft(_G41673)),intv(2435,6987))
touch(arr_zone,obj(aircraft(_G41673)),intv(6988,7988))
true ; false.
narrative completion, possible cover examples given above, one
single Aircraft Arrival model learned. avoids learning spurious rules cover
corrupted examples thus giving us compact semantically meaningful models.
evaluate approach, compare rules learned using induction rules
learned using IIA algorithm. first column Table 8 shows events
considered experiments, second column shows number instances
particular event 15 turnarounds. third column shows number rules learned
using ILP fourth column shows results using IIA algorithm
fifth column shows number examples covered induced rules
explained using abduction hence rules learned them. interleaving
induction abduction, able avoid learning spurious rules shown
results. classes, number rules reduced 50% overall
performance also increased. also observed rules previously
learned examples covered abduction semantically correspond
events.
8.4.3 Evaluating IIA Verbs Dataset
verbs domain, encoded spatial theory QT CL1 spatial calculi. Though
also used domain-dependent primitive events domain besides QT CL1 ,
encode spatial theory relations well defined. example,
domain-dependent primitives domain neither jointly exhaustive pair-wise
disjoint. also avoided abducing explanations relations including
relations list abducibles. 10-fold cross-validation used evaluation verbs
dataset. Since video short duration around 200 frames, used classification
instead recognition. Table 9 clear using abduction reduces number
rules event model thereby giving compact model. verbs dataset results,
considerable change performance classification task rather
recognition task. main performance increase IIA inference comes
79

fiDubba, Cohn, Hogg, Bhatt & Dylla

Airport Events

#pos

FWD CN LoadUnload
5
GPU Positioning
15
Aircraft Arrival
15
Aircraft Departure
15
AFT Bulk LoadUnload
12
Left Refuelling
6
PB Positioning
15
AFT CN LoadUnload
7
PBB Positioning
15
PBB Removing
15
FWD Bulk LoadUnload
3
Num rules Induction 2

2
5
5
5
5
2
4
3
4
5
2
Num



2

RoI

PoI

RIA

PIA

1
2
0.8
0.3
0.8
3
4
1
0.2
1
2
5
0.38
0.26
0.33
2
7
0.8
0.15
0.71
2
4
0.63
0.43
0.63
1
2
0.66
0.5
0.66
3
2
0.33
0.34
0.33
1
3
0.57
0.4
0.57
3
2
1
0.57
1
2
5
0.54
0.23
0.54
1
1
1
1
1
rules IIA avg num examples covered

0.4
0.4
0.32
0.26
0.65
0.55
0.42
0.51
0.62
0.31
1
abd

Table 8: Airport domain IIA results averaged iterations leave-one-out testing.
RoI, PoI - recall precision induction: RIA, PIA - recall precision using
IIA.
Verb Events

#pos

2



RoI

Approach
584
12
5
45
0.73
Arrive
8
2
1
2
0.50
Attach
48
6
3
12
1.00
Bounce
22
2
2
0
0.95
Catch
201
7
4
31
0.59
Chase
108
11
7
19
0.59
Collide
101
6
4
14
0.98
Dig
140
10
7
21
0.96
Drop
44
2
2
0
1.00
Exchange
18
6
3
4
0.40
Fall
134
8
5
18
0.92
Give
552
27
20
54
0.94
Jump
150
6
4
14
0.98
Kick
48
4
3
6
1.00
Leave
116
10
4
34
0.67
Lift
78
8
5
17
0.67
Pass
76
8
4
13
0.87
Pickup
40
6
4
8
0.81
Run
76
7
5
7
0.57
Throw
26
3
2
5
0.67
Num rules Induction 2 Num rules IIA avg

PoI

RIA

0.12
0.74
0.05
0.50
0.14
1.00
0.06
0.95
0.11
0.56
0.08
0.57
0.16
0.98
0.38
0.96
0.16
1.00
0.03
0.40
0.35
0.90
0.56
0.94
0.13
0.98
0.15
1.00
0.20
0.67
0.24
0.67
0.10
0.87
0.13
0.81
0.12
0.57
0.11
0.67
num examples covered

PIA
0.12
0.05
0.17
0.08
0.11
0.08
0.18
0.39
0.16
0.03
0.35
0.60
0.13
0.15
0.22
0.24
0.12
0.16
0.12
0.11
abd

Table 9: Verbs dataset IIA results averaged iterations 10-fold cross-validation
testing. RoI, PoI - recall precision induction: RIA, PIA - recall precision
using IIA.

reduction false positives fewer rules recognition high
possibility multiple rules firing test data thereby giving many false positives.
classification, case, vignette classified member
particular event class rule, classification rules event class
affect overall outcome vignette.

80

fiLearning Relational Event Models Video

9. Limitations Future Work
models used remind local, i.e., without context wider activity model
could used filter recognized instances thereby increasing performance.
example, turn-arounds airport domain, Aircraft Departure event
sometimes recognized even Aircraft Arrival recognized resulting false positives
Aircraft Departure. Another limitation learned models lack representation
duration events. Many recognized event instances rejected system
temporal extent recognized instances long fails criteria 20% overlap
ground truth. reduced learning global model (Greenall, Cohn, &
Hogg, 2011) constrains ordering events Aircraft Departure detections
happen Aircraft Arrival. activity models also represent expected
duration events, temporal separation events number occurrences.
framework sensitive initial example selected start learning procedure.
induction system used based algorithm uses bottom clause (Muggleton,
1995) constructed selected example guide refinement hypothesis
searching lattice. Hence possible might select corrupted example initially
might affect whole induction process. typical problem machine learning
several ways avoid this. One promising approach followed
work repeat learning different examples chosen randomly starting point
selecting iteration gives minimum number rules.
Another limitation framework dependency tracking objects
uses interactions objects model events. Challenging scenarios object tracking
pose limitations current framework. current framework probabilistic, i.e.,
neither input data learned models probabilistic. One direction future work
extend framework using statistical relational learning use soft evidence
learn robust probabilistic relational models. Since current framework
handle hierarchies events, framework could extended handle hierarchical
composition events. One possible approach learn models events
particular layer using events lower layers primitives.

10. Conclusion
paper, proposed supervised relational learning framework, extension using abduction, learn event models complex videos. event models
used recognize event instances unseen videos. presented Type Refinement
operator exploits object type hierarchy domain search better hypotheses also proved optimal refinement operator. presented empirical
evaluation proposed framework two real world video data sets results
encouraging, showing framework effectively used real world systems
event recognition various domains. also showed proposed framework
better generalization capabilities performance compared state-of-the-art
systems event modelling. Finally, note although focused learning
video data here, fact approach would also suitable learning
data sources provide tracks interacting moving objects (e.g. GPS streams).
81

fiDubba, Cohn, Hogg, Bhatt & Dylla

Acknowledgements
thank colleagues CO-FRIEND, RACE, STRANDS VIGIL projects consortia
valuable inputs research, respective funding EU Framework
7 (FP7-ICT-214975, FP7-ICT-27752, FP7-ICT-600623) DARPA (W911NF-10-C-0083).
Also financial support Deutsche Forschungsgemeinschaft Transregional Collaborative Research Center SFB/TR 8 Spatial Cognition project R3-[Q-Shape] gratefully
acknowledged.

Appendix A. Proof Optimality Type Refinement Operator
Let type hierarchy tree set nodes TV , set leaf nodes TL , i.e.
specific types (TL TV ) r root tree (most generic type). type
parent node generic types children nodes write
= .
Let g function, g : TV TV , maps child node immediate parent.
function g considered generalizing operator generalizes type nearest
generic type. g applied long 6= r
Let Si ordered (from most-specific general) set possible generalizations including .
Si = {i , g(i ), g(g(i )), . . . , r }
set types {1 , 2 , . . . , n }, define corresponding sets S1 , S2 , . . . , Sn .
Let {h1 , h2 , . . . , hm } set types19 clause C {h1 , h2 , . . . , hm } TV .
{h1 , h2 , . . . , hm }, define Sh1 , Sh2 , . . . , Shm . make set {h1 , h2 , . . . , hm }
generic applying g (one times) arbitrarily selected subset types
one type time.
Cartesian product Sh1 Sh2 . . . Shm set tuples tuple
possible generalization {h1 , h2 , . . . , hm }.
Let l function mapping non-leaf type node integer specifies many
times g applied original leaf node obtain non-leaf node20 , l : TV N .
Using l, generate new set Nhi Shi replacing l(i ).
generate new Cartesian product Nh1 Nh2 . . . Nhm .
Example .1. Let (1 , 2 , 3 ) set types clause C let type hierarchy
given Fig.13. define S1 , S2 , S3 N1 , N2 , N3 follows
tree representation Cartesian products S1 S2 S3 N1 N2 N3 given
Fig.14 Fig.15 respectively.
19. consider list types clause C types may repeated
arguments type, results appendix still valid.
20. Note general, non-leaf node obtained leaf nodes descendants
unique leaf node obtained store original leaf node generalized using g
get non-leaf type node.

82

fiLearning Relational Event Models Video

r

1 g(2 ), g(3 )

2 3

Figure 13: example type hierarchy.

S1 = {1 , g(1 )}
S2 = {2 , g(2 ), g(g(2 ))}
S3 = {3 , g(3 ), g(g(3 ))}
N1 = {0, 1}
N2 = {0, 1, 2}
N3 = {0, 1, 2}

1
2

g(2 )

g(1 )
2

g(g(2 ))

g(2 )

g(g(2 ))

3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 )) 3 g(3 ) g(g(3 ))

Figure 14: Representing Cartesian product S1 S2 S3 tree. root empty
next layer corresponds S1 on. Note g(1 ) = g(g(2 )) = g(g(3 )) = r .
path tree leaf possible generalization (1 , 2 , 3 ) leftmost path
null generalization, i.e. (1 , 2 , 3 ).
Definition .2. (Type Substitution, ) type substitution set
{h1 /1 , h2 /2 , . . . , hn /n } hi type subset variables
clause C immediate generic type hi (parent node hi tree ).
say substituted hi clause. set {h1 , h2 , . . . , hn } called domain
, denoted dom( ) set (1 , 2 , . . . , n ) called range , denoted rng( ).
type substitution used generalize type subset variables clause.
Definition .3. (Most Generic Type Substitution, r ) generic type substitution
type substitution whose range set {r } r root type hierarchy tree .
generic type substitution used check two clauses structurally equivalent
(Def:4) substituting types variable r . Note every clause C unique
generic type substitution, Cr , whose domain set types C range
set {r }.
83

fiDubba, Cohn, Hogg, Bhatt & Dylla



0

0

1

1

2

0

1

2

0 1 2 0 1 2 0 1 2 0 1 2 0 1 2 0 1 2

Figure 15: Representing Cartesian product N1 N2 N3 tree. root empty
next layer corresponds N1 on. path leaf represents possible
generalization (1 , 2 , 3 ). generalization obtained following path
root leaf generalizing type layer number times indicated
node value. example, highlighted sequence (1,2,1) corresponds generalization
(g(1 ), g(g(2 )), g(3 )). obtained generalizing 1 generalizing 2
twice generalizing 3 once. top bottom order (left right case tuples)
followed, unique way achieve generalization (g(1 ), g(g(2 )), g(3 ))
(1 , 2 , 3 ).
Definition .4. (Structurally Equivalent, ) Two clauses, C C 0 structurally equiv0
alent, denoted C C 0 , CCr C 0 Cr .
clause C structurally equivalent clauses obtained replacing subset
types variables C generalizations.
Definition .5. (Generic Order w.r.t. types, ) clause C said general
w.r.t. type another clause C 0 , denoted C C 0 , iff C C 0 set types C
correspondingly generic set types C 0 .
Definition .6. (Type-Refinement Operator) Let clausal language, type hierarchy
C clause . CT subset defined C clause C 0 CT
structurally equivalent C, i.e., C C 0 . Let subsumption order defined above.
Type-Refinement operator hCT , function (C) {D|D C}.
One-step type refinement C defined applied once, i.e. 1 =
(C). n-step type refinement defined similarly, i.e. n = {D | E, E
n1
(C) (E)}. set type refinements C given

(C) = 1 (C) 2 (C) . . ..
locally finite every C , (C) finite computable.
proper every C , (C) {D|D C}.
complete every C, C, E (C)
E (i.e. E equivalent order).
84

fiLearning Relational Event Models Video

weakly complete hCT , (C) = CT .
non-redundant every C, D, E , E (C) E (D) implies
C (D) (C)
ideal locally finite, proper complete.
optimal locally finite, non-redundant weakly complete.
type refinement operator selects type hi set {h1 , h2 , . . . , hm } C applies type generalizing operator type resulting set {h1 , h2 , . . . , g(hi ), . . . , hm }
used substitution C obtain generic clause C 0 respect type, i.e.,
C 0 C . type refinement operator follows left right order generalizing types
avoid generating redundant clauses, i.e., type position generalized
next step refinement h0 type position j, j < selected generalizing.
Theorem .7. locally finite
Proof. Let type hierarchy tree TV set nodes TC =
{h1 , h2 , . . . , hm } set types clause C TC TV . Let g type
generalizing operator type refinement operator. operates C selecting
type set {h1 , h2 , . . . , hm } generalizing applying g. |TC |
possibilities select possible type selected one possible
generalization, type one parent tree . Also type
generalized finite number times (i.e., becomes r ). Hence number possible
refinements, i.e., | (C)| finite making locally finite.
Theorem .8. weakly complete
Proof. given clause C set types {h1 , h2 , . . . , hm } defined above.
1 , 1 , . . .} obtained one-step type refinement
Let X1 set substitutions {,1
,2
1 C 0 1 (C). Let X = X X . . . X set
Ci0 = C,i
1
2
2


1 , 1 , . . . , 1 }
substitutions obtained two-step type refinement {i1
i2
im
1 ).
rng(,i
1 , 1 , . . . , 1 ), . . . , ( 1 , 1 , . . . , 1 ), . . .}, i.e. 1
Let 1 set tuples {(11
12
1m
i1 i2
im
set tuples tuple represents possible type refinement {h1 , h2 , . . . , hm }
one-step type refinement let = 1 2 . . ..
easy observe tuple P also tuple Cartesian product
Sh1 Sh2 . . . Shm . fact exact one one matching members
members Sh1 Sh2 . . . Shm . easy obtain member tuple, say P
P = (1 , 2 , . . . , ) Cartesian product generalizing {h1 , h2 , . . . , hm }. type hi
generalized equal moving next type immediate right
hi . way possible type generalizations {h1 , h2 , . . . , hm } reachable
{h1 , h2 , . . . , hm }, i.e., possible type generalized clauses reachable C, hence
weakly complete.
Theorem .9. non-redundant
85

fiDubba, Cohn, Hogg, Bhatt & Dylla

Proof. Let Nh1 Nh2 . . . Nhm defined previously set types {h1 , h2 , . . . , hm }
clause C. Cartesian product represented tree root
empty next level elements Nh1 on. path leaf represents
possible generalization {h1 , h2 , . . . , hm }. generalization obtained following
path root leaf generalizing type layer number times
indicated node value. top bottom order (left right case tuples)
followed, unique way obtain generalization path generates. Hence
non-redundant.
Example .10. example Fig.15, sequence (1,2,1) bold corresponds generalization (g(1 ), g(g(2 )), g(3 )). obtained generalizing 1 generalizing
2 twice generalizing 3 once. top bottom order followed,
unique way achieve generalization (g(1 ), g(g(2 )), g(3 )) (1 , 2 , 3 ).
Theorem .11. optimal
Proof. Since type refinement operator locally finite, weakly complete non-redundant,
optimal.

References
Albanese, M., Moscato, V., Picariello, A., Subrahmanian, V., & Udrea, O. (2007). Detecting
stochastically scheduled activities video. Proceedings International Joint
Conference Aritificial Intelligence (IJCAI), pp. 18021807.
Allen, J. F. (1983). Maintaining knowledge temporal intervals. Communications
ACM, 26, 832843.
Bengio, Y. (2009). Learning deep architectures AI. Foundations Trends Machine
Learning, 2 (1), 1127.
Bhatt, M., & Loke, S. (2008). Modelling dynamic spatial systems situation calculus.
Spatial Cognition & Computation, 8 (1-2), 86130.
Blockeel, H., De Raedt, L., Jacobs, N., & Demoen, B. (1999). Scaling Inductive Logic
Programming learning interpretations. Data Mining Knowledge Discovery, 3 (1), 5993.
Bundy, A., Byrd, L., & Mellish, C. (1985). Special-purpose, domain-independent, inference mechanisms. Progress Artificial Intelligence, pp. 93111. London: Ellis
Horwood.
Chen, J., Cohn, A. G., Liu, D., Wang, S., Ouyang, J., & Yu, Q. (2015). survey
qualitative spatial representations. Knowledge Engineering Review, 30, 106136.
Christiansen, H., & Dahl, V. (2005). HYPROLOG: new logic programming language
assumptions abduction. Logic Programming, 159173.
Cohn, A. G. (1989). Taxonomic reasoning many-sorted logics. Artificial Intelligence
Review, 3 (2), 89128.
86

fiLearning Relational Event Models Video

Cohn, A. G., Hogg, D. C., Bennett, B., Devin, V., Galata, A., Magee, D. R., Needham, C.,
& Santos, P. (2006). Cognitive vision: integrating symbolic qualitative representations
computer vision.. Vol. 3948 LNCS, chap. 14, pp. 221246. Springer.
Dalal, N., & Triggs, B. (2005). Histograms oriented gradients human detection.
IEEE Conference Computer Vision Pattern Recognition (CVPR), Vol. 1, pp.
886893.
Dubba, K. S., Bhatt, M., Dylla, F., Hogg, D. C., & Cohn, A. G. (2012). Interleaved
inductive-abductive reasoning learning complex event models. Inductive Logic
Programming, pp. 113129. Springer.
Dubba, K. S., Cohn, A. G., & Hogg, D. C. (2010). Event model learning complex
videos using ILP. Proceedings European Conference Artificial Intelligence
(ECAI), Vol. 215, pp. 9398.
Fern, A., Givan, R., & Siskind, J. (2002). Specific-to-general learning temporal events
application learning event definitions video. Journal Artificial Intelligence Research, 17, 379449.
Ferryman, J., Borg, M., Thirde, D., Fusier, F., Valentin, V., Bremond, F., Thonnat, M.,
Aguilera, J., & Kampel, M. (2005). Automated scene understanding airport aprons.
LNCS-3809, Springer Verlag, 3809, 593.
Freksa, C. (1991). Conceptual neighborhood role temporal spatial reasoning.
Singh, M., & Trave-Massuyes, L. (Eds.), Decision Support Systems Qualitative
Reasoning, pp. 181187. North-Holland, Amsterdam.
Ghahramani, Z. (1998). Learning Dynamic Bayesian networks. Adaptive Processing
Sequences Data Structures, 168197.
Greenall, J., Cohn, A. G., & Hogg, D. C. (2011). Temporal structure models event
recognition. British Machine Vision Conference (BMVC).
Gupta, A., Srinivasan, P., Shi, J., & Davis, L. (2009). Understanding videos, constructing
plots learning visually grounded storyline model annotated videos. IEEE
Conference Computer Vision Pattern Recognition (CVPR), pp. 20042011.
Hakeem, A., Sheikh, Y., & Shah, M. (2004). CASEE : hierarchical event representation
analysis videos. Proceeding National Conference Artificial
Intelligence (AAAI), pp. 263268.
Hartley, R., & Zisserman, A. (2004). Multiple View Geometry Computer Vision (Second
edition). Cambridge University Press.
Hazarika, S. M., & Cohn, A. G. (2002). Abducing qualitative spatio-temporal histories
partial observations. International Conference Principles Knowledge
Representation Reasoning, pp. 1425.
Hoogs, A., & Perera, A. G. A. (2008). Video activity recognition real world.
Proceedings National Conference Artificial Intelligence (AAAI), pp. 1551
1554.
87

fiDubba, Cohn, Hogg, Bhatt & Dylla

Ivanov, Y., & Bobick, A. (2000). Recognition visual activities interactions stochastic parsing. IEEE Transactions Pattern Analysis Machine Intelligence (PAMI),
22 (8).
Jiang, Z., Lin, Z., & Davis, L. S. (2010). tree-based approach integrated action localization, recognition segmentation. Third Workshop Human Motion (in
conjuntion ECCV).
Kakas, A., Kowalski, R., & Toni, F. (1992). Abductive logic programming. Journal Logic
Computation, 2 (6), 719.
Kakas, A., & Riguzzi, F. (2000). Abductive concept learning. New Generation Computing,
18 (3), 243294.
Konik, T., & Laird, J. (2006). Learning goal hierarchies structured observations
expert annotations. Machine Learning, 64 (1), 263287.
Laptev, I. (2005). space-time interest points. International Journal Computer Vision,
64 (2), 107123.
Laptev, I., & Perez, P. (2007). Retrieving actions movies. IEEE International Conference Computer Vision (ICCV), pp. 18.
Le, Q., Zou, W., Yeung, S., & Ng, A. (2011). Learning hierarchical invariant spatio-temporal
features action recognition independent subspace analysis. IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 33613368. IEEE.
Lowe, D. (2004). Distinctive image features scale-invariant keypoints. International
Journal Computer Vision, 60 (2), 91110.
McCarthy, J. (1986). Applications circumscription formalizing common-sense knowledge. Artificial Intelligence, 28 (1), 89116.
Medioni, G., Cohen, I., Bremond, F., Hongeng, S., & Nevatia, R. (2001). Event detection
analysis video streams. IEEE Transactions Pattern Analysis Machine
Intelligence (PAMI), 23 (8), 873889.
Miller, R., & Shanahan, M. (1994). Narratives Situation Calculus. Journal Logic
Computation, 4 (5), 513530.
Morariu, V. I., & Davis, L. S. (2011). Multi-agent event recognition structured scenarios..
IEEE Conference Computer Vision Pattern Recognition (CVPR), pp. 3289
3296.
Morariu, V. I., Harwood, D., & Davis, L. S. (2013). Tracking peoples hands feet
using mixed network and/or search.. IEEE Transactions Pattern Analysis
Machine Intelligence (PAMI).
Moyle, S. (2003). Using theory completion learn robot navigation control program.
Proceedings International Conference ILP, 182197.
Moyle, S., & Muggleton, S. (1997). Learning programs Event Calculus. LNAI-1297,
Springer-Verlag, 205212.
Muggleton, S. (1995). Inverse entailment Progol. New Generation Computing, 13 (3&4),
245286.
88

fiLearning Relational Event Models Video

Muggleton, S., & Bryant, C. H. (2000). Theory completion using inverse entailment. Proceedings International Conference ILP, pp. 130146, UK. Springer-Verlag.
Needham, C., Santos, P., Magee, D., Devin, V., Hogg, D., & Cohn, A. (2005). Protocols
perceptual observations. Artificial Intelligence, 167 (1-2), 103136.
Nevatia, R., Hobbs, J., & Bolles, B. (2004). ontology video event representation.
Computer Vision Pattern Recognition Workshop (CVPRW-04), pp. 119119.
IEEE.
Nienhuys-Cheng, S., & De Wolf, R. (1997). Foundations Inductive Logic Programming,
Vol. 1228. Springer Verlag.
Oh, S., Hoogs, A., Perera, et al. (2011). large-scale benchmark dataset event recognition surveillance video. IEEE Conference Computer Vision Pattern
Recognition (CVPR), pp. 31533160.
Poole, D., Goebel, R., & Aleliunas, R. (1987). Theorist: logical reasoning system
defaults diagnosis. Knowledge Frontier, pp. 331352.
Quinlan, J., & Cameron-Jones, R. (1993). FOIL: midterm report. Proceedings
European Conference Machine Learning (ECML), pp. 120.
Quinlan, J. (1990). Learning logical definitions relations. Machine Learning, 5 (3),
239266.
Rabiner, L. (1989). tutorial Hidden Markov models selected applications speech
recognition. Proceedings IEEE, 77 (2), 257286.
Randell, D. A., Cui, Z., & Cohn, A. (1992). spatial logic based regions connection. Proceedings International Conference Knowledge Representation
Reasoning, pp. 165176. Morgan Kaufmann.
Ryoo, M. S., & Aggarwal, J. K. (2009). Semantic representation recognition continued
recursive human activities. International Journal Computer Vision, 82 (1), 1
24.
Ryoo, M., & Aggarwal, J. (2011). Stochastic representation recognition high-level
group activities. International Journal Computer Vision, 93 (2), 183200.
Sridhar, M., Cohn, A. G., & Hogg, D. C. (2010). Unsupervised learning event classes
video. Proceedings National Conference Artificial Intelligence (AAAI),
pp. 16311638.
Tamaddoni-Nezhad, A., Chaleil, R., Kakas, A., & Muggleton, S. (2006). Application
abductive ILP learning metabolic network inhibition temporal data. Machine
Learning, 64 (1), 209230.
Tamaddoni-Nezhad, A., & Muggleton, S. (2009). lattice structure refinement
operators hypothesis space bounded bottom clause. Machine learning,
76 (1), 3772.
Van de Weghe, N., Cohn, A., De Tre, G., & De Maeyer, P. (2006). qualitative trajectory calculus basis representing moving objects geographical information
systems. Control Cybernetics, 35 (1), 97.
89

fiDubba, Cohn, Hogg, Bhatt & Dylla

Veeraraghavan, H., Papanikolopoulos, N., & Schrater, P. (2007). Learning dynamic event
descriptions image sequences. IEEE Conference Computer Vision Pattern
Recognition (CVPR), pp. 16.
Vu, V.-T., Bremond, F., & Thonnat, M. (2003). Automatic video interpretation: novel
algorithm temporal scenario recognition. Proceedings International Joint
Conference Artifical Intelligence (IJCAI), Vol. 3, pp. 12951300.
Walther, C. (1985). mechanical solution Schuberts Steamroller many-sorted resolution. Artificial Intelligence, 26 (2), 217224.
Yilmaz, A., Javed, O., & Shah, M. (2006). Object tracking: survey. ACM Computing
Surveys (CSUR), 38 (4), 13.
YouTube (2015) http://www.youtube.com/yt/press/statistics.html. Accessed January 25, 2015.

90

fi
